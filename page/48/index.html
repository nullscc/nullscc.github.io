
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/48/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/cs.CV_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T13:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/cs.CV_2023_09_16/">cs.CV - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="FrameRS-A-Video-Frame-Compression-Model-Composed-by-Self-supervised-Video-Frame-Reconstructor-and-Key-Frame-Selector"><a href="#FrameRS-A-Video-Frame-Compression-Model-Composed-by-Self-supervised-Video-Frame-Reconstructor-and-Key-Frame-Selector" class="headerlink" title="FrameRS: A Video Frame Compression Model Composed by Self supervised Video Frame Reconstructor and Key Frame Selector"></a>FrameRS: A Video Frame Compression Model Composed by Self supervised Video Frame Reconstructor and Key Frame Selector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09083">http://arxiv.org/abs/2309.09083</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiqianfu/framemae">https://github.com/qiqianfu/framemae</a></li>
<li>paper_authors: Qiqian Fu, Guanhong Wang, Gaoang Wang</li>
<li>for: 本研究提出了一种框架重建模型：FrameRS，用于自动重建视频帧。</li>
<li>methods: 模型包括一个自我supervised的视频帧重建器和一个关键帧选择器。帧重建器FrameMAE是基于图像MAE的原理，适应视频上下文。关键帧选择器是基于CNN结构，通过从encoder中获取高级别semantic信息，可以低计算成本预测关键帧。</li>
<li>results: 模型可以有效地压缩视频clip，保留约30%的重要帧。性能方面，我们的模型在计算效率和竞争准确性方面表现出色，与传统的关键帧提取算法相比有所提升。代码可以在Github上下载。<details>
<summary>Abstract</summary>
In this paper, we present frame reconstruction model: FrameRS. It consists self-supervised video frame reconstructor and key frame selector. The frame reconstructor, FrameMAE, is developed by adapting the principles of the Masked Autoencoder for Images (MAE) for video context. The key frame selector, Frame Selector, is built on CNN architecture. By taking the high-level semantic information from the encoder of FrameMAE as its input, it can predicted the key frames with low computation costs. Integrated with our bespoke Frame Selector, FrameMAE can effectively compress a video clip by retaining approximately 30% of its pivotal frames. Performance-wise, our model showcases computational efficiency and competitive accuracy, marking a notable improvement over traditional Key Frame Extract algorithms. The implementation is available on Github
</details>
<details>
<summary>摘要</summary>
本文提出了一种框架重建模型：FrameRS。它包含自我超级视频框架重建器和关键帧选择器。框架重建器 FrameMAE 是基于图像隐藏autoencoder（MAE）的视频上的应用，而关键帧选择器 Frame Selector 是基于卷积神经网络架构。通过将高级 semantic 信息从 FrameMAE 的解码器作为输入，Frame Selector 可以预测关键帧，计算成本低。将 FrameMAE 与我们自己的 Frame Selector 结合使用，可以有效地压缩视频clip，保留约 30% 的关键帧。在性能方面，我们的模型表现出了计算效率和竞争性准确率，代表了传统关键帧提取算法的 Notable Improvement。实现可以在 Github 上找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-camera-Bird’s-Eye-View-Perception-for-Autonomous-Driving"><a href="#Multi-camera-Bird’s-Eye-View-Perception-for-Autonomous-Driving" class="headerlink" title="Multi-camera Bird’s Eye View Perception for Autonomous Driving"></a>Multi-camera Bird’s Eye View Perception for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09080">http://arxiv.org/abs/2309.09080</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Unger, Nikhil Gosala, Varun Ravi Kumar, Shubhankar Borse, Abhinav Valada, Senthil Yogamani</li>
<li>for: 这 paper 主要是为了探讨多摄像头基于深度学习模型在逻辑投影空间（BEV）中的物体表示方法。</li>
<li>methods: 这 paper 使用的方法主要是基于深度学习模型，将摄像头图像转换到逻辑投影空间（BEV）中，并使用几何约束来保证转换的准确性。</li>
<li>results: 这 paper 的结果表明，使用深度学习模型对摄像头图像的转换在逻辑投影空间（BEV）中可以实现更高的准确性和灵活性，并且可以与其他感知器结合进行有效的感知融合。<details>
<summary>Abstract</summary>
Most automated driving systems comprise a diverse sensor set, including several cameras, Radars, and LiDARs, ensuring a complete 360\deg coverage in near and far regions. Unlike Radar and LiDAR, which measure directly in 3D, cameras capture a 2D perspective projection with inherent depth ambiguity. However, it is essential to produce perception outputs in 3D to enable the spatial reasoning of other agents and structures for optimal path planning. The 3D space is typically simplified to the BEV space by omitting the less relevant Z-coordinate, which corresponds to the height dimension.The most basic approach to achieving the desired BEV representation from a camera image is IPM, assuming a flat ground surface. Surround vision systems that are pretty common in new vehicles use the IPM principle to generate a BEV image and to show it on display to the driver. However, this approach is not suited for autonomous driving since there are severe distortions introduced by this too-simplistic transformation method. More recent approaches use deep neural networks to output directly in BEV space. These methods transform camera images into BEV space using geometric constraints implicitly or explicitly in the network. As CNN has more context information and a learnable transformation can be more flexible and adapt to image content, the deep learning-based methods set the new benchmark for BEV transformation and achieve state-of-the-art performance. First, this chapter discusses the contemporary trends of multi-camera-based DNN (deep neural network) models outputting object representations directly in the BEV space. Then, we discuss how this approach can extend to effective sensor fusion and coupling downstream tasks like situation analysis and prediction. Finally, we show challenges and open problems in BEV perception.
</details>
<details>
<summary>摘要</summary>
现代自动驾驶系统通常包括多种感知器，包括数个摄像头、雷达和LiDAR，以确保完整的360度覆盖 both near and far regions。不同于雷达和LiDAR，摄像头会 Capture a 2D perspective projection with inherent depth ambiguity。然而，以便实现最佳路径规划，需要生成3D感知输出。为了简化3D空间，通常会将Z坐标（高度维度）排除，得到BEV空间（bird's eye view）。将摄像头图像转换为BEV空间的最基本方法是IPM（平面地面假设）。许多新车型的围视系统都使用IPM原理生成BEV图像，并将其显示给司机。然而，这种方法不适用于自动驾驶，因为它会引入严重的扭曲。更近期的方法使用深度神经网络直接将摄像头图像转换为BEV空间。这些方法使用摄像头图像中的几何约束，以及深度神经网络学习的变换，以生成BEV图像。由于神经网络具有更多的内容信息和可学习的变换，深度学习基于方法已经设置了新的标准 дляBEV转换，并实现了状态前景性的表现。本章首先介绍了当代多摄像头基于神经网络（deep neural network）模型，输出对象表示直接在BEV空间。然后，我们讨论了如何扩展到有效的感知融合和下游任务，如情况分析和预测。最后，我们介绍了BEV感知的挑战和开放问题。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Green-Object-Tracker-GOT-without-Offline-Pre-training"><a href="#Unsupervised-Green-Object-Tracker-GOT-without-Offline-Pre-training" class="headerlink" title="Unsupervised Green Object Tracker (GOT) without Offline Pre-training"></a>Unsupervised Green Object Tracker (GOT) without Offline Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09078">http://arxiv.org/abs/2309.09078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiruo Zhou, Suya You, C. -C. Jay Kuo</li>
<li>for: 提高单个目标跟踪精度，降低标注成本和计算复杂性，实现灵活可 deployment on edge devices。</li>
<li>methods:  ensemble of three prediction branches：1) 全局对象基 correlator，2) 本地 patch-based correlator，3) superpixel-based segmentator，使用了简单的模型和低计算复杂性。</li>
<li>results: 与现有的半监督跟踪器相当，需要大量的Offline预训练，但GOT具有较低的计算复杂性和小型模型大小，可以轻松部署于移动和边缘设备。<details>
<summary>Abstract</summary>
Supervised trackers trained on labeled data dominate the single object tracking field for superior tracking accuracy. The labeling cost and the huge computational complexity hinder their applications on edge devices. Unsupervised learning methods have also been investigated to reduce the labeling cost but their complexity remains high. Aiming at lightweight high-performance tracking, feasibility without offline pre-training, and algorithmic transparency, we propose a new single object tracking method, called the green object tracker (GOT), in this work. GOT conducts an ensemble of three prediction branches for robust box tracking: 1) a global object-based correlator to predict the object location roughly, 2) a local patch-based correlator to build temporal correlations of small spatial units, and 3) a superpixel-based segmentator to exploit the spatial information of the target frame. GOT offers competitive tracking accuracy with state-of-the-art unsupervised trackers, which demand heavy offline pre-training, at a lower computation cost. GOT has a tiny model size (<3k parameters) and low inference complexity (around 58M FLOPs per frame). Since its inference complexity is between 0.1%-10% of DL trackers, it can be easily deployed on mobile and edge devices.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>supervised trackers在标注数据上训练的场景下占据单个对象跟踪领域的先导地位，因为标签成本和计算复杂性而降低其应用于边缘设备。不supervised learning方法也被研究以减少标签成本，但它们的复杂度仍然高。为了实现轻量级高性能的跟踪，不需要线上预训练、算法透明度和可行性，我们在这里提出了一种新的单对象跟踪方法，称为绿色对象跟踪器（GOT）。GOT使用三个预测分支来提供粗略对象位置预测和高精度跟踪：1）全局对象基于相关器来预测对象位置，2）本地小区域基于相关器来建立时间相关性，3）超像素基于分割器来利用目标帧中的空间信息。GOT可以与现有的无监督跟踪器相比，它们需要大量的线上预训练，并且具有较低的计算成本（<3k参数）和低的计算复杂度（约58M FLOPs每帧）。由于其计算复杂度在0.1%-10%之间，因此它可以轻松部署在移动和边缘设备上。
</details></li>
</ul>
<hr>
<h2 id="MMST-ViT-Climate-Change-aware-Crop-Yield-Prediction-via-Multi-Modal-Spatial-Temporal-Vision-Transformer"><a href="#MMST-ViT-Climate-Change-aware-Crop-Yield-Prediction-via-Multi-Modal-Spatial-Temporal-Vision-Transformer" class="headerlink" title="MMST-ViT: Climate Change-aware Crop Yield Prediction via Multi-Modal Spatial-Temporal Vision Transformer"></a>MMST-ViT: Climate Change-aware Crop Yield Prediction via Multi-Modal Spatial-Temporal Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09067">http://arxiv.org/abs/2309.09067</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fudong03/mmst-vit">https://github.com/fudong03/mmst-vit</a></li>
<li>paper_authors: Fudong Lin, Summer Crawford, Kaleb Guillot, Yihe Zhang, Yan Chen, Xu Yuan, Li Chen, Shelby Williams, Robert Minvielle, Xiangming Xiao, Drew Gholson, Nicolas Ashwell, Tri Setiyono, Brenda Tubana, Lu Peng, Magdy Bayoumi, Nian-Feng Tzeng</li>
<li>for: 预测美国县级作物产量，考虑植物生长季节的天气变化和气候变化对作物的影响。</li>
<li>methods: 我们开发了一种深度学习基于解决方案，即多Modal Spatial-Temporal Vision Transformer（MMST-ViT），利用视觉遥感数据和短期天气数据来模型植物生长季节的天气变化对作物生长的影响。</li>
<li>results: 我们的MMST-ViT在200个美国县的实验中表现出色，与三个性能指标之间的比较结果都高于其他相似方法。<details>
<summary>Abstract</summary>
Precise crop yield prediction provides valuable information for agricultural planning and decision-making processes. However, timely predicting crop yields remains challenging as crop growth is sensitive to growing season weather variation and climate change. In this work, we develop a deep learning-based solution, namely Multi-Modal Spatial-Temporal Vision Transformer (MMST-ViT), for predicting crop yields at the county level across the United States, by considering the effects of short-term meteorological variations during the growing season and the long-term climate change on crops. Specifically, our MMST-ViT consists of a Multi-Modal Transformer, a Spatial Transformer, and a Temporal Transformer. The Multi-Modal Transformer leverages both visual remote sensing data and short-term meteorological data for modeling the effect of growing season weather variations on crop growth. The Spatial Transformer learns the high-resolution spatial dependency among counties for accurate agricultural tracking. The Temporal Transformer captures the long-range temporal dependency for learning the impact of long-term climate change on crops. Meanwhile, we also devise a novel multi-modal contrastive learning technique to pre-train our model without extensive human supervision. Hence, our MMST-ViT captures the impacts of both short-term weather variations and long-term climate change on crops by leveraging both satellite images and meteorological data. We have conducted extensive experiments on over 200 counties in the United States, with the experimental results exhibiting that our MMST-ViT outperforms its counterparts under three performance metrics of interest.
</details>
<details>
<summary>摘要</summary>
precise 农作物产量预测提供了重要的农业规划和决策过程中的信息。然而，在季节变化和气候变化的影响下，准确地预测农作物产量仍然是一项挑战。在这种情况下，我们开发了一种深度学习基于解决方案，即多Modal空间时间变换器（MMST-ViT），用于预测美国各县的农作物产量，并考虑了季节变化的短期天气影响和气候变化对农作物的影响。具体来说，我们的MMST-ViT包括多Modal变换器、空间变换器和时间变换器。多Modal变换器利用了远程感知数据和季节变化天气数据来模型季节变化对农作物生长的影响。空间变换器学习了高分辨率的空间相关性，以便准确地跟踪农作物的生长。时间变换器捕捉了长期时间相关性，以便学习气候变化对农作物的影响。此外，我们还开发了一种新的多Modal对比学习技术，以不需要大量的人工监督来预处理我们的模型。因此，我们的MMST-ViT可以 capture季节变化和气候变化对农作物的影响，并且在美国200多个县的实验结果表明，我们的MMST-ViT在三个关键性能指标上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Sub-action-Prototype-Learning-for-Point-level-Weakly-supervised-Temporal-Action-Localization"><a href="#Sub-action-Prototype-Learning-for-Point-level-Weakly-supervised-Temporal-Action-Localization" class="headerlink" title="Sub-action Prototype Learning for Point-level Weakly-supervised Temporal Action Localization"></a>Sub-action Prototype Learning for Point-level Weakly-supervised Temporal Action Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09060">http://arxiv.org/abs/2309.09060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yueyang Li, Yonghong Hou, Wanqing Li</li>
<li>for: 提高点级弱监督时间动作地理化（PWTAL）的性能，使其能够基于唯一时间戳注释每个动作实例。</li>
<li>methods: 提出了一种新的子动作原型学习框架（SPL-Loc），包括子动作原型归一化（SPC）和顺序原型对齐（OPA）。 SPC 适应性地提取了表现出时间尺度和空间内容变化的动作实例的表示性质。 OPA 选择了相关的原型，以提供完整性提示符 дляpseudo标签生成。</li>
<li>results: 与现有SOTA PWTAL方法进行了广泛的实验，并显示了提档SPL-Loc可以准确地地理化动作边界。<details>
<summary>Abstract</summary>
Point-level weakly-supervised temporal action localization (PWTAL) aims to localize actions with only a single timestamp annotation for each action instance. Existing methods tend to mine dense pseudo labels to alleviate the label sparsity, but overlook the potential sub-action temporal structures, resulting in inferior performance. To tackle this problem, we propose a novel sub-action prototype learning framework (SPL-Loc) which comprises Sub-action Prototype Clustering (SPC) and Ordered Prototype Alignment (OPA). SPC adaptively extracts representative sub-action prototypes which are capable to perceive the temporal scale and spatial content variation of action instances. OPA selects relevant prototypes to provide completeness clue for pseudo label generation by applying a temporal alignment loss. As a result, pseudo labels are derived from alignment results to improve action boundary prediction. Extensive experiments on three popular benchmarks demonstrate that the proposed SPL-Loc significantly outperforms existing SOTA PWTAL methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>点级弱监视时间动作地点（PWTAL）目标是在每个动作实例只有一个时间标签的情况下地址动作。现有方法通常是利用密集假标签来减轻标签稀疏性，但是忽略了可能存在的次动作时间结构，导致性能较差。为解决这个问题，我们提出了一种新的子动作原型学习框架（SPL-Loc），它包括子动作原型聚类（SPC）和有序原型对齐（OPA）。SPC可适应性EXTRACT Representative sub-action prototypes, which are capable of perceiving the temporal scale and spatial content variation of action instances. OPA选择相关的原型来提供完整的假标签生成的准备，通过应用时间对齐损失。因此，假标签来自对齐结果进行改进动作边界预测。广泛的实验表明，提出的 SPL-Loc 明显超过现有SOTA PWTAL方法。
</details></li>
</ul>
<hr>
<h2 id="Microscale-3-D-Capacitance-Tomography-with-a-CMOS-Sensor-Array"><a href="#Microscale-3-D-Capacitance-Tomography-with-a-CMOS-Sensor-Array" class="headerlink" title="Microscale 3-D Capacitance Tomography with a CMOS Sensor Array"></a>Microscale 3-D Capacitance Tomography with a CMOS Sensor Array</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09039">http://arxiv.org/abs/2309.09039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manar Abdelatty, Joseph Incandela, Kangping Hu, Joseph W. Larkin, Sherief Reda, Jacob K. Rosenstein</li>
<li>for: 这个论文主要是用来描述电容 Tomatoesography（ECT）技术在微型系统中的应用。</li>
<li>methods: 该论文使用了CMOS微电极阵列来实现ECT成像，并提出了一种深度学习架构和改进的多目标训练方法来重建射电常数图像。</li>
<li>results: 实验结果表明，提议的方法能够高精度地重建微型系统中的3D结构，包括精确地测量微球体积和细菌生物胶囊的尺寸。 predictions accuracy为91.5%和82.7%。<details>
<summary>Abstract</summary>
Electrical capacitance tomography (ECT) is a nonoptical imaging technique in which a map of the interior permittivity of a volume is estimated by making capacitance measurements at its boundary and solving an inverse problem. While previous ECT demonstrations have often been at centimeter scales, ECT is not limited to macroscopic systems. In this paper, we demonstrate ECT imaging of polymer microspheres and bacterial biofilms using a CMOS microelectrode array, achieving spatial resolution of 10 microns. Additionally, we propose a deep learning architecture and an improved multi-objective training scheme for reconstructing out-of-plane permittivity maps from the sensor measurements. Experimental results show that the proposed approach is able to resolve microscopic 3-D structures, achieving 91.5% prediction accuracy on the microsphere dataset and 82.7% on the biofilm dataset, including an average of 4.6% improvement over baseline computational methods.
</details>
<details>
<summary>摘要</summary>
电容测量探测技术（ECT）是一种非光学图像技术，可以测量物体内部电容 coefficient的地图，并解决一个倒逼问题。而在过去的ECT示范中，通常是在厘米级别进行，但ECT并不限于巨观系统。在这篇论文中，我们使用CMOS微电极阵列进行ECT探测，实现了10μ米的空间分辨率。此外，我们提出了深度学习架构和改进的多目标训练方案，用于从传感器测量数据中重建垂直电容地图。实验结果表明，我们的方法能够分解微观三维结构，达到91.5%的预测精度（在微球数据集上）和82.7%的预测精度（在生物质层数据集上），其中平均与基线计算方法相差4.6%。
</details></li>
</ul>
<hr>
<h2 id="RingMo-lite-A-Remote-Sensing-Multi-task-Lightweight-Network-with-CNN-Transformer-Hybrid-Framework"><a href="#RingMo-lite-A-Remote-Sensing-Multi-task-Lightweight-Network-with-CNN-Transformer-Hybrid-Framework" class="headerlink" title="RingMo-lite: A Remote Sensing Multi-task Lightweight Network with CNN-Transformer Hybrid Framework"></a>RingMo-lite: A Remote Sensing Multi-task Lightweight Network with CNN-Transformer Hybrid Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09003">http://arxiv.org/abs/2309.09003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuelei Wang, Ting Zhang, Liangjin Zhao, Lin Hu, Zhechao Wang, Ziqing Niu, Peirui Cheng, Kaiqiang Chen, Xuan Zeng, Zhirui Wang, Hongqi Wang, Xian Sun</li>
<li>for: 这个论文旨在提出一个轻量级的RS类型视觉基础模型，以便在边缘设备上进行RS影像解释。</li>
<li>methods: 这个论文使用了一个CNN-Transformer混合架构，具有一个双支结构，其中使用了Transformer模组作为低通架构，以EXTRACTRS影像的全球特征；而CNN模组则被用作堆叠高通架构，以EXTRACTRS影像的细节特征。</li>
<li>results: 相比于RingMo，这个提案的RingMo-lite将参数减少了大约60%，并在不同的RS影像解释任务中保持了缩减的几成比，而且在大多数场景下，其精度下降了不到2%。此外，这个研究将在未来与MindSpore computng平台集成。<details>
<summary>Abstract</summary>
In recent years, remote sensing (RS) vision foundation models such as RingMo have emerged and achieved excellent performance in various downstream tasks. However, the high demand for computing resources limits the application of these models on edge devices. It is necessary to design a more lightweight foundation model to support on-orbit RS image interpretation. Existing methods face challenges in achieving lightweight solutions while retaining generalization in RS image interpretation. This is due to the complex high and low-frequency spectral components in RS images, which make traditional single CNN or Vision Transformer methods unsuitable for the task. Therefore, this paper proposes RingMo-lite, an RS multi-task lightweight network with a CNN-Transformer hybrid framework, which effectively exploits the frequency-domain properties of RS to optimize the interpretation process. It is combined by the Transformer module as a low-pass filter to extract global features of RS images through a dual-branch structure, and the CNN module as a stacked high-pass filter to extract fine-grained details effectively. Furthermore, in the pretraining stage, the designed frequency-domain masked image modeling (FD-MIM) combines each image patch's high-frequency and low-frequency characteristics, effectively capturing the latent feature representation in RS data. As shown in Fig. 1, compared with RingMo, the proposed RingMo-lite reduces the parameters over 60% in various RS image interpretation tasks, the average accuracy drops by less than 2% in most of the scenes and achieves SOTA performance compared to models of the similar size. In addition, our work will be integrated into the MindSpore computing platform in the near future.
</details>
<details>
<summary>摘要</summary>
在近年，远程感知（RS）视觉基础模型如RingMo出现并在各种下游任务中表现出色。然而，计算资源的高需求限制了这些模型在边缘设备上的应用。为了解决这个问题，这篇论文提出了RingMo-lite，一种RS多任务轻量级网络，它采用了CNN-Transformer混合框架，并且有效地利用RS图像的频率频谱特性来优化解释过程。RingMo-lite由Transformer模块作为低通滤波器，EXTRACTRS图像的全面特征，而CNN模块作为堆叠高通滤波器，EXTRACTRS图像的细腻细节。此外，在预训练阶段，我们设计了频率频谱遮盲图像模型（FD-MIM），该模型可以有效地捕捉RS数据中各个图像块的高频和低频特征，从而获得RS数据的秘密特征表示。根据图1，相比RingMo，我们提出的RingMo-lite减少了参数超过60%，在各种RS图像解释任务中，均低于2%的场景下，保持了SOTA的性能。此外，我们计划将这些工作与MindSpore计算平台集成。
</details></li>
</ul>
<hr>
<h2 id="OmniLRS-A-Photorealistic-Simulator-for-Lunar-Robotics"><a href="#OmniLRS-A-Photorealistic-Simulator-for-Lunar-Robotics" class="headerlink" title="OmniLRS: A Photorealistic Simulator for Lunar Robotics"></a>OmniLRS: A Photorealistic Simulator for Lunar Robotics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08997">http://arxiv.org/abs/2309.08997</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antoinerichard/lunarsim">https://github.com/antoinerichard/lunarsim</a></li>
<li>paper_authors: Antoine Richard, Junnosuke Kamohara, Kentaro Uno, Shreya Santra, Dave van der Meer, Miguel Olivares-Mendez, Kazuya Yoshida</li>
<li>for: The paper is written for developers and researchers who are interested in developing algorithms for lunar robotic exploration and need a high-fidelity simulator to evaluate their algorithms.</li>
<li>methods: The paper proposes a new lunar simulator called OmniLRS, which is based on Nvidia’s robotic simulator Isaac Sim. The simulator provides fast procedural environment generation, multi-robot capabilities, and a synthetic data pipeline for machine-learning applications.</li>
<li>results: The paper demonstrates the effectiveness of the simulator for image-based perception by performing sim-to-real rock instance segmentation. The results show that a YOLOv8 model trained on the simulator’s synthetic data achieves performance close to a model trained on real-world data, with a 5% performance gap. When finetuned with real data, the model achieves 14% higher average precision than the model trained on real-world data, demonstrating the simulator’s photorealism.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为开发 lunar 机器人探索算法而写的，需要高度实验环境来评估其算法。</li>
<li>methods: 这篇论文提出了一个基于 Nvidia 的 Isaac Sim 的 lunar 模拟器 OmniLRS，它提供了快速的生成环境、多机器人能力以及机器学习应用程序的数据管道。</li>
<li>results: 论文通过进行 sim-to-real 矿石实例分割来证明其模拟器的效果，结果显示一个 YOLOv8 模型在模拟器上训练的数据上达到与实际数据训练的模型几乎相同的性能，差距仅5%。当再进行 fine-tuning 后，模型与实际数据训练的模型之间的差距提高了14%。这示明了模拟器的真实性。<details>
<summary>Abstract</summary>
Developing algorithms for extra-terrestrial robotic exploration has always been challenging. Along with the complexity associated with these environments, one of the main issues remains the evaluation of said algorithms. With the regained interest in lunar exploration, there is also a demand for quality simulators that will enable the development of lunar robots. % In this paper, we explain how we built a Lunar simulator based on Isaac Sim, Nvidia's robotic simulator. In this paper, we propose Omniverse Lunar Robotic-Sim (OmniLRS) that is a photorealistic Lunar simulator based on Nvidia's robotic simulator. This simulation provides fast procedural environment generation, multi-robot capabilities, along with synthetic data pipeline for machine-learning applications. It comes with ROS1 and ROS2 bindings to control not only the robots, but also the environments. This work also performs sim-to-real rock instance segmentation to show the effectiveness of our simulator for image-based perception. Trained on our synthetic data, a yolov8 model achieves performance close to a model trained on real-world data, with 5% performance gap. When finetuned with real data, the model achieves 14% higher average precision than the model trained on real-world data, demonstrating our simulator's photorealism.% to realize sim-to-real. The code is fully open-source, accessible here: https://github.com/AntoineRichard/LunarSim, and comes with demonstrations.
</details>
<details>
<summary>摘要</summary>
开发外星 robotic 探索算法总是是一个挑战。随着这些环境的复杂性，一个主要的问题是评估这些算法。与月球探索的重新兴起相关，有一个需求是高质量的月球 simulator，可以帮助月球探索机器人的开发。在这篇论文中，我们介绍了我们如何基于 Isaac Sim 和 Nvidia 的机器人 simulator 建立了一个名为 Omniverse Lunar Robotic-Sim（OmniLRS）的月球 simulator。这个 simulate 提供了快速的过程生成环境、多机器人功能以及synthetic data pipeline  для机器学习应用。它还包括 ROS1 和 ROS2 绑定，可以控制不仅机器人，还可以控制环境。此外，我们还实现了 sim-to-real 的岩Instance segmentation，以示我们的 simulate 的实用性。我们在我们的synthetic数据上训练了一个 yolov8 模型，与实际数据训练的模型之间的性能差距只有5%。当 fins 化 With real data 时，模型的性能高于实际数据训练的模型， demonstrating 我们的 simulate 的 photorealism。我们的代码是完全开源的，可以在以下 GitHub 上获取：https://github.com/AntoineRichard/LunarSim，并包括示例。
</details></li>
</ul>
<hr>
<h2 id="RMP-A-Random-Mask-Pretrain-Framework-for-Motion-Prediction"><a href="#RMP-A-Random-Mask-Pretrain-Framework-for-Motion-Prediction" class="headerlink" title="RMP: A Random Mask Pretrain Framework for Motion Prediction"></a>RMP: A Random Mask Pretrain Framework for Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08989">http://arxiv.org/abs/2309.08989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kth-rpl/rmp">https://github.com/kth-rpl/rmp</a></li>
<li>paper_authors: Yi Yang, Qingwen Zhang, Thomas Gilles, Nazre Batool, John Folkesson</li>
<li>for: 这篇论文是针对自驾车中的路径预测问题提出了一个框架。</li>
<li>methods: 本文使用了随机遮盾模型，将物体位置在随机时间步上遮盾，然后由学习的神经网络（NN）填充。可以根据遮盾profile的变化，轻松地切换到不同的动作相关任务。</li>
<li>results: 本文透过评估Argoverse和NuScenes dataset，表明我们的提案的预训框架可以处理噪音输入，提高路径预测精度和缺失率，特别是在时间遮盾下的物体遮盾。<details>
<summary>Abstract</summary>
As the pretraining technique is growing in popularity, little work has been done on pretrained learning-based motion prediction methods in autonomous driving. In this paper, we propose a framework to formalize the pretraining task for trajectory prediction of traffic participants. Within our framework, inspired by the random masked model in natural language processing (NLP) and computer vision (CV), objects' positions at random timesteps are masked and then filled in by the learned neural network (NN). By changing the mask profile, our framework can easily switch among a range of motion-related tasks. We show that our proposed pretraining framework is able to deal with noisy inputs and improves the motion prediction accuracy and miss rate, especially for objects occluded over time by evaluating it on Argoverse and NuScenes datasets.
</details>
<details>
<summary>摘要</summary>
As the pretraining technique becomes more popular, there has been little research on using learning-based motion prediction methods in autonomous driving. In this paper, we propose a framework to formalize the pretraining task for trajectory prediction of traffic participants. Our framework is inspired by the random masked model in natural language processing (NLP) and computer vision (CV), where the positions of objects at random timesteps are masked and then filled in by a learned neural network (NN). By changing the mask profile, our framework can easily switch among a range of motion-related tasks. We show that our proposed pretraining framework can handle noisy inputs and improve motion prediction accuracy and miss rate, especially for objects that are occluded over time, as evaluated on the Argoverse and NuScenes datasets.
</details></li>
</ul>
<hr>
<h2 id="Comparative-study-of-Deep-Learning-Models-for-Binary-Classification-on-Combined-Pulmonary-Chest-X-ray-Dataset"><a href="#Comparative-study-of-Deep-Learning-Models-for-Binary-Classification-on-Combined-Pulmonary-Chest-X-ray-Dataset" class="headerlink" title="Comparative study of Deep Learning Models for Binary Classification on Combined Pulmonary Chest X-ray Dataset"></a>Comparative study of Deep Learning Models for Binary Classification on Combined Pulmonary Chest X-ray Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10829">http://arxiv.org/abs/2309.10829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shabbir Ahmed Shuvo, Md Aminul Islam, Md. Mozammel Hoque, Rejwan Bin Sulaiman</li>
<li>for: 这个研究的目的是比较八种深度学习模型在同一个肺病影像数据集上的二分类表现。</li>
<li>methods: 这个研究使用了 eight 种深度学习模型，包括 DenseNet 121、DenseNet 169、DenseNet 201、EffecientNet b0、EffecientNet lite4、GoogleNet、MobileNet 和 ResNet18。</li>
<li>results: 研究发现，当应用于肺病影像数据集时，DenseNet 169 表现最佳，准确率为 89.38%，MobileNet 表现次之，准确率为 92.2%。<details>
<summary>Abstract</summary>
CNN-based deep learning models for disease detection have become popular recently. We compared the binary classification performance of eight prominent deep learning models: DenseNet 121, DenseNet 169, DenseNet 201, EffecientNet b0, EffecientNet lite4, GoogleNet, MobileNet, and ResNet18 for their binary classification performance on combined Pulmonary Chest Xrays dataset. Despite the widespread application in different fields in medical images, there remains a knowledge gap in determining their relative performance when applied to the same dataset, a gap this study aimed to address. The dataset combined Shenzhen, China (CH) and Montgomery, USA (MC) data. We trained our model for binary classification, calculated different parameters of the mentioned models, and compared them. The models were trained to keep in mind all following the same training parameters to maintain a controlled comparison environment. End of the study, we found a distinct difference in performance among the other models when applied to the pulmonary chest Xray image dataset, where DenseNet169 performed with 89.38 percent and MobileNet with 92.2 percent precision.   Keywords: Pulmonary, Deep Learning, Tuberculosis, Disease detection, Xray
</details>
<details>
<summary>摘要</summary>
Recently, CNN基于深度学习模型在疾病检测中获得了广泛应用。我们对8种知名深度学习模型进行比较：DenseNet 121、DenseNet 169、DenseNet 201、EffecientNet b0、EffecientNet lite4、GoogleNet、MobileNet和ResNet18，以确定它们在同一个 dataset 上的二分类性表现。尽管这些模型在医疗图像领域的不同应用场景中广泛使用，但是在应用于同一个 dataset 上的表现却存在知识空白，这项研究意图填补这个空白。我们使用了combined Shenzhen、China（CH）和Montgomery、USA（MC）的数据集。我们将模型进行二分类训练，计算了不同模型的参数，并进行了比较。所有模型均遵循同样的训练参数，以保证比较环境的控制。研究结束后，我们发现在肺部X射影像数据集上，DenseNet169表现出了89.38%的准确率，而MobileNet表现出了92.2%的准确率。关键词：肺部、深度学习、肺病、疾病检测、X射影像
</details></li>
</ul>
<hr>
<h2 id="FF-LOGO-Cross-Modality-Point-Cloud-Registration-with-Feature-Filtering-and-Local-to-Global-Optimization"><a href="#FF-LOGO-Cross-Modality-Point-Cloud-Registration-with-Feature-Filtering-and-Local-to-Global-Optimization" class="headerlink" title="FF-LOGO: Cross-Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization"></a>FF-LOGO: Cross-Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08966">http://arxiv.org/abs/2309.08966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Ma, Mohan Wang, Yiheng Han, Yong-Jin Liu</li>
<li>for: 本文是一篇关于多modal点云注册的研究 paper, aiming to address the challenges of cross-modality point cloud registration.</li>
<li>methods: 本文提出了一种名为 FF-LOGO 的多modal点云注册方法，包括Feature Filtering和本地 global optimization两个模块。Feature Filtering 模块可以抽象出不同感知器的点云特征，并通过特征匹配来进行点云选择。本地 Adaptive Key Region Aggregation 模块和全Modal Consistency Fusion Optimization 模块是为了优化点云注册精度。</li>
<li>results: 实验结果表明，我们的两阶段优化可以显著提高点云注册精度，特征关联和选择模块的准确率从40.59%提高到75.74%。这表明我们的方法可以有效地解决跨模态点云注册中的挑战。<details>
<summary>Abstract</summary>
Cross-modality point cloud registration is confronted with significant challenges due to inherent differences in modalities between different sensors. We propose a cross-modality point cloud registration framework FF-LOGO: a cross-modality point cloud registration method with feature filtering and local-global optimization. The cross-modality feature correlation filtering module extracts geometric transformation-invariant features from cross-modality point clouds and achieves point selection by feature matching. We also introduce a cross-modality optimization process, including a local adaptive key region aggregation module and a global modality consistency fusion optimization module. Experimental results demonstrate that our two-stage optimization significantly improves the registration accuracy of the feature association and selection module. Our method achieves a substantial increase in recall rate compared to the current state-of-the-art methods on the 3DCSR dataset, improving from 40.59% to 75.74%. Our code will be available at https://github.com/wangmohan17/FFLOGO.
</details>
<details>
<summary>摘要</summary>
cross-modality point cloud registration 面临着不同感知器的内生差异问题，我们提出了一种 cross-modality point cloud registration 框架 FF-LOGO：一种通过特征筛选和本地adaptive key region aggregation模块、全Modal consistency fusion优化模块实现的 cross-modality point cloud registration 方法。在Feature correlation filtering模块中，我们提取了不同感知器的Point cloud中的几何变换不变的特征，并通过特征匹配来实现点选择。我们还引入了一种 across-modality optimization process，包括一个本地adaptive key region aggregation模块和一个全Modal consistency fusion优化模块。实验结果表明，我们的两stage优化significantly improves the registration accuracy of the feature association and selection module。我们的方法在3DCSR dataset上实现了75.74%的回卷率提升，比前一个state-of-the-art方法提高了40.59%。我们的代码将在https://github.com/wangmohan17/FFLOGO上公开。
</details></li>
</ul>
<hr>
<h2 id="Tightening-Classification-Boundaries-in-Open-Set-Domain-Adaptation-through-Unknown-Exploitation"><a href="#Tightening-Classification-Boundaries-in-Open-Set-Domain-Adaptation-through-Unknown-Exploitation" class="headerlink" title="Tightening Classification Boundaries in Open Set Domain Adaptation through Unknown Exploitation"></a>Tightening Classification Boundaries in Open Set Domain Adaptation through Unknown Exploitation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08964">http://arxiv.org/abs/2309.08964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LucasFernando-aes/UnkE-OVANet">https://github.com/LucasFernando-aes/UnkE-OVANet</a></li>
<li>paper_authors: Lucas Fernando Alvarenga e Silva, Nicu Sebe, Jurandy Almeida</li>
<li>for: 本研究旨在提高Open Set Domain Adaptation (OSDA)方法的性能，以应对具有不同类别和预设变数的非控制环境。</li>
<li>methods: 本研究提出了一种基于高信度Unknown Instance的强制约束，以提高OSDA方法的分类精度。具体来说，我们采用了三种不同的损失函数来训练OSDA模型，包括直接使用静止负项目集，随机扭转负项目集使用数据增强技术，以及将Synthetically生成的负项目集中的反击特征加以训练。</li>
<li>results: 我们在OVANet上进行了广泛的实验，发现在Office-31和Office-Home dataset上，这些方法可以实现绝对改进，获得最大改进为1.3%的精度和5.8%的H-Score在Office-31 dataset上，以及4.7%的精度和5.8%的H-Score在Office-Home dataset上。<details>
<summary>Abstract</summary>
Convolutional Neural Networks (CNNs) have brought revolutionary advances to many research areas due to their capacity of learning from raw data. However, when those methods are applied to non-controllable environments, many different factors can degrade the model's expected performance, such as unlabeled datasets with different levels of domain shift and category shift. Particularly, when both issues occur at the same time, we tackle this challenging setup as Open Set Domain Adaptation (OSDA) problem. In general, existing OSDA approaches focus their efforts only on aligning known classes or, if they already extract possible negative instances, use them as a new category learned with supervision during the course of training. We propose a novel way to improve OSDA approaches by extracting a high-confidence set of unknown instances and using it as a hard constraint to tighten the classification boundaries of OSDA methods. Especially, we adopt a new loss constraint evaluated in three different means, (1) directly with the pristine negative instances; (2) with randomly transformed negatives using data augmentation techniques; and (3) with synthetically generated negatives containing adversarial features. We assessed all approaches in an extensive set of experiments based on OVANet, where we could observe consistent improvements for two public benchmarks, the Office-31 and Office-Home datasets, yielding absolute gains of up to 1.3% for both Accuracy and H-Score on Office-31 and 5.8% for Accuracy and 4.7% for H-Score on Office-Home.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）已经为许多研究领域带来了革命性的进步，因为它们可以从原始数据中学习。然而，当这些方法应用于不可控的环境时，许多不同的因素可以降低模型的预期性能，如不标注数据集中的不同水平域转移和类别转移。特别是当这两个问题同时出现时，我们称之为开放集领域适应（OSDA）问题。总的来说，现有的OSDA方法通常只关注知道的类别的Alignment，或者如果已经提取了可能的负样本，则在训练过程中使用它们作为新学习的类别。我们提出了一种新的方法来改进OSDA方法，通过提取高 confidence 的未知实例集并将其作为硬件约束使用，以紧张化OSDA方法的分类边界。特别是，我们采用了三种不同的损失约束，分别是：(1) 直接使用不损失的负样本；(2) 使用数据扩展技术生成的随机变换负样本；以及(3) 使用生成的负样本，含有抗击性特征。我们在一系列实验中评估了所有方法，基于 OVANet，可以看到在 Office-31 和 Office-Home 两个公共 benchmark 上，我们可以获得相对准确率和 H-Score 的绝对提升，最高达 1.3% 和 5.8%。
</details></li>
</ul>
<hr>
<h2 id="ExBluRF-Efficient-Radiance-Fields-for-Extreme-Motion-Blurred-Images"><a href="#ExBluRF-Efficient-Radiance-Fields-for-Extreme-Motion-Blurred-Images" class="headerlink" title="ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images"></a>ExBluRF: Efficient Radiance Fields for Extreme Motion Blurred Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08957">http://arxiv.org/abs/2309.08957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongwoo Lee, Jeongtaek Oh, Jaesung Lim, Sunghyun Cho, Kyoung Mu Lee</li>
<li>for: 本研究旨在提出一种基于高效光场优化的新视觉合成方法，用于处理极大运动模糊图像。</li>
<li>methods: 本方法包括两个主要组件：6DOF摄像机轨迹基于运动模糊形式和 voxel-based 光场。从极其模糊图像中，我们优化锐化的光场，并通过相互关联摄像机轨迹来生成极大运动模糊图像。在训练中，我们将多个射线与摄像机轨迹相集成，以重建单个模糊颜色图像，这与物理运动模糊操作相同。我们在模糊图像空间内减少照度一致损失，并通过摄像机轨迹来获得锐化的光场。</li>
<li>results: 与现有方法相比，我们的方法可以很好地还原极大运动模糊视图中的3D场景，并且具有训练时间和GPU内存占用的减少。<details>
<summary>Abstract</summary>
We present ExBluRF, a novel view synthesis method for extreme motion blurred images based on efficient radiance fields optimization. Our approach consists of two main components: 6-DOF camera trajectory-based motion blur formulation and voxel-based radiance fields. From extremely blurred images, we optimize the sharp radiance fields by jointly estimating the camera trajectories that generate the blurry images. In training, multiple rays along the camera trajectory are accumulated to reconstruct single blurry color, which is equivalent to the physical motion blur operation. We minimize the photo-consistency loss on blurred image space and obtain the sharp radiance fields with camera trajectories that explain the blur of all images. The joint optimization on the blurred image space demands painfully increasing computation and resources proportional to the blur size. Our method solves this problem by replacing the MLP-based framework to low-dimensional 6-DOF camera poses and voxel-based radiance fields. Compared with the existing works, our approach restores much sharper 3D scenes from challenging motion blurred views with the order of 10 times less training time and GPU memory consumption.
</details>
<details>
<summary>摘要</summary>
我们提出了ExBluRF，一种新的视图合成方法，用于处理极大运动模糊图像。我们的方法包括两个主要组成部分：基于6DOF相机轨迹的运动模糊形式和 voxel-based 辐射场。从极端模糊图像中，我们优化了锐利的辐射场，并同时估计相机轨迹，以生成模糊图像。在训练中，多个光束与相机轨迹相互垂直，以重建单个模糊颜色。我们在模糊图像空间中减少了照相一致损失，并从相机轨迹中获得了锐利的辐射场。我们的方法解决了训练时间和 GPU 内存占用的问题，相比之下，现有的方法可以在极大的运动模糊视图中还原许多更加锐利的3D场景，并且减少了训练时间和 GPU 内存占用的规模。
</details></li>
</ul>
<hr>
<h2 id="IntelliBeeHive-An-Automated-Honey-Bee-Pollen-and-Varroa-Destructor-Monitoring-System"><a href="#IntelliBeeHive-An-Automated-Honey-Bee-Pollen-and-Varroa-Destructor-Monitoring-System" class="headerlink" title="IntelliBeeHive: An Automated Honey Bee, Pollen, and Varroa Destructor Monitoring System"></a>IntelliBeeHive: An Automated Honey Bee, Pollen, and Varroa Destructor Monitoring System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08955">http://arxiv.org/abs/2309.08955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian I. Narcia-Macias, Joselito Guardado, Jocell Rodriguez, Joanne Rampersad-Ammons, Erik Enriquez, Dong-Chul Kim<br>for: 这个研究旨在提高我们对蜜蜂群体疾病、蜜蜂行为、人口减少和巢健康的理解，通过发展一个基于计算机视觉的蜜蜂监测系统。methods: 这个监测系统使用计算机视觉技术，包括机器学习算法，实时监测蜜蜂群体活动和健康状况，无需对蜜蜂进行干扰。results: 我们的监测系统可以准确地识别蜜蜂、识别蜜和检测 Varroa 螨，并且可以实时提供蜜蜂群体活动和健康状况的数据。系统的总性能达到 96.28%，蜜蜂模型的 F1 分数为 0.95，蜜模型的 F1 分数为 0.831。<details>
<summary>Abstract</summary>
Utilizing computer vision and the latest technological advancements, in this study, we developed a honey bee monitoring system that aims to enhance our understanding of Colony Collapse Disorder, honey bee behavior, population decline, and overall hive health. The system is positioned at the hive entrance providing real-time data, enabling beekeepers to closely monitor the hive's activity and health through an account-based website. Using machine learning, our monitoring system can accurately track honey bees, monitor pollen-gathering activity, and detect Varroa mites, all without causing any disruption to the honey bees. Moreover, we have ensured that the development of this monitoring system utilizes cost-effective technology, making it accessible to apiaries of various scales, including hobbyists, commercial beekeeping businesses, and researchers. The inference models used to detect honey bees, pollen, and mites are based on the YOLOv7-tiny architecture trained with our own data. The F1-score for honey bee model recognition is 0.95 and the precision and recall value is 0.981. For our pollen and mite object detection model F1-score is 0.95 and the precision and recall value is 0.821 for pollen and 0.996 for "mite". The overall performance of our IntelliBeeHive system demonstrates its effectiveness in monitoring the honey bee's activity, achieving an accuracy of 96.28 % in tracking and our pollen model achieved a F1-score of 0.831.
</details>
<details>
<summary>摘要</summary>
使用计算机视觉和最新的技术进步，在这项研究中，我们开发了一套蜜蜂监测系统，以提高我们对蜂巢病毒蜂巢病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒病毒��
</details></li>
</ul>
<hr>
<h2 id="Robust-Backdoor-Attacks-on-Object-Detection-in-Real-World"><a href="#Robust-Backdoor-Attacks-on-Object-Detection-in-Real-World" class="headerlink" title="Robust Backdoor Attacks on Object Detection in Real World"></a>Robust Backdoor Attacks on Object Detection in Real World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08953">http://arxiv.org/abs/2309.08953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang</li>
<li>for: 这个论文的目的是提出一种适应不同大小攻击对象的变量大小触发器，以及一种基于恶意对抗训练的后门训练方法，以提高在实际世界中的攻击成功率。</li>
<li>methods: 该论文使用的方法包括变量大小触发器和基于恶意对抗训练的后门训练方法，以适应不同大小攻击对象和物理干扰。</li>
<li>results: 实验结果显示，这种 Robust Backdoor Attack (RBA) 可以在实际世界中提高攻击成功率。<details>
<summary>Abstract</summary>
Deep learning models are widely deployed in many applications, such as object detection in various security fields. However, these models are vulnerable to backdoor attacks. Most backdoor attacks were intensively studied on classified models, but little on object detection. Previous works mainly focused on the backdoor attack in the digital world, but neglect the real world. Especially, the backdoor attack's effect in the real world will be easily influenced by physical factors like distance and illumination. In this paper, we proposed a variable-size backdoor trigger to adapt to the different sizes of attacked objects, overcoming the disturbance caused by the distance between the viewing point and attacked object. In addition, we proposed a backdoor training named malicious adversarial training, enabling the backdoor object detector to learn the feature of the trigger with physical noise. The experiment results show this robust backdoor attack (RBA) could enhance the attack success rate in the real world.
</details>
<details>
<summary>摘要</summary>
深度学习模型在多个应用领域广泛应用，如物体检测等安全领域。然而，这些模型容易受到后门攻击。大多数后门攻击研究targeted于分类模型，而对物体检测模型的研究很少。先前的工作主要集中在数字世界中进行后门攻击研究，忽略了实际世界。特别是，实际世界中后门攻击的效果会受到物体距离观察点以及照明等物理因素的影响。在这篇论文中，我们提出了可变大小的后门触发器，以适应不同大小的攻击对象，并且在不同距离和照明条件下对后门触发器进行了适应。此外，我们还提出了一种名为“邪恶学习训练”的后门训练方法，使得后门检测器能够学习触发器的特征与物理噪声。实验结果显示，我们的robust后门攻击（RBA）可以在实际世界中提高攻击成功率。
</details></li>
</ul>
<hr>
<h2 id="Staged-Contact-Aware-Global-Human-Motion-Forecasting"><a href="#Staged-Contact-Aware-Global-Human-Motion-Forecasting" class="headerlink" title="Staged Contact-Aware Global Human Motion Forecasting"></a>Staged Contact-Aware Global Human Motion Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08947">http://arxiv.org/abs/2309.08947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/l-scofano/stag">https://github.com/l-scofano/stag</a></li>
<li>paper_authors: Luca Scofano, Alessio Sampieri, Elisabeth Schiele, Edoardo De Matteis, Laura Leal-Taixé, Fabio Galasso<br>for:Scene-aware global human motion forecasting is critical for manifold applications, including virtual reality, robotics, and sports. The task combines human trajectory and pose forecasting within the provided scene context, which represents a significant challenge.methods:We propose a STAGed contact-aware global human motion forecasting STAG, a novel three-stage pipeline for predicting global human motion in a 3D environment. We first consider the scene and the respective human interaction as contact points. Secondly, we model the human trajectory forecasting within the scene, predicting the coarse motion of the human body as a whole. The third and last stage matches a plausible fine human joint motion to complement the trajectory considering the estimated contacts.results:Compared to the state-of-the-art (SoA), STAG achieves a 1.8% and 16.2% overall improvement in pose and trajectory prediction, respectively, on the scene-aware GTA-IM dataset. A comprehensive ablation study confirms the advantages of staged modeling over end-to-end approaches.<details>
<summary>Abstract</summary>
Scene-aware global human motion forecasting is critical for manifold applications, including virtual reality, robotics, and sports. The task combines human trajectory and pose forecasting within the provided scene context, which represents a significant challenge.   So far, only Mao et al. NeurIPS'22 have addressed scene-aware global motion, cascading the prediction of future scene contact points and the global motion estimation. They perform the latter as the end-to-end forecasting of future trajectories and poses. However, end-to-end contrasts with the coarse-to-fine nature of the task and it results in lower performance, as we demonstrate here empirically.   We propose a STAGed contact-aware global human motion forecasting STAG, a novel three-stage pipeline for predicting global human motion in a 3D environment. We first consider the scene and the respective human interaction as contact points. Secondly, we model the human trajectory forecasting within the scene, predicting the coarse motion of the human body as a whole. The third and last stage matches a plausible fine human joint motion to complement the trajectory considering the estimated contacts.   Compared to the state-of-the-art (SoA), STAG achieves a 1.8% and 16.2% overall improvement in pose and trajectory prediction, respectively, on the scene-aware GTA-IM dataset. A comprehensive ablation study confirms the advantages of staged modeling over end-to-end approaches. Furthermore, we establish the significance of a newly proposed temporal counter called the "time-to-go", which tells how long it is before reaching scene contact and endpoints. Notably, STAG showcases its ability to generalize to datasets lacking a scene and achieves a new state-of-the-art performance on CMU-Mocap, without leveraging any social cues. Our code is released at: https://github.com/L-Scofano/STAG
</details>
<details>
<summary>摘要</summary>
Scene-aware global human motion forecasting是应用广泛的领域之一，包括虚拟现实、 робо测控和体育等。这个任务需要在提供的场景上下文中预测人体轨迹和姿势，这是一项非常具有挑战性的任务。  到目前为止，只有Mao等人在NeuIPS'22中Addressed scene-aware global motion，通过综合预测未来场景接触点和全身运动的方式来完成。他们在预测未来轨迹和姿势方面进行了终端预测，但终端预测与场景中的运动预测不匹配，这会导致性能下降，我们在实验中证明了这一点。  我们提出了一种名为STAG的三个阶段管道，用于预测在3D环境中的全身人类运动。我们首先考虑场景和人类之间的接触点，然后预测场景内人体轨迹，并且预测全身人体的粗略运动。最后一个阶段是匹配合理的人体 JOINT 运动，以补做轨迹中的细微运动。  与现状的最佳实践（SoA）相比，STAG在Scene-aware GTA-IM dataset上表现出1.8%和16.2%的总体改进，分别是 pose 和轨迹预测。我们还进行了一项完整的减少研究，证明了分阶段模型的优势。此外，我们还证明了我们提出的一种新的时间对象“时间剩下”的重要性，该对象表示人体在场景接触点和终点之前剩下的时间。值得注意的是，STAG在缺少场景的 dataset 上表现出新的状态机制，并在CMU-Mocap dataset上 дости得了新的最佳实践，无需使用任何社会cue。我们的代码可以在https://github.com/L-Scofano/STAG 上获取。
</details></li>
</ul>
<hr>
<h2 id="AffordPose-A-Large-scale-Dataset-of-Hand-Object-Interactions-with-Affordance-driven-Hand-Pose"><a href="#AffordPose-A-Large-scale-Dataset-of-Hand-Object-Interactions-with-Affordance-driven-Hand-Pose" class="headerlink" title="AffordPose: A Large-scale Dataset of Hand-Object Interactions with Affordance-driven Hand Pose"></a>AffordPose: A Large-scale Dataset of Hand-Object Interactions with Affordance-driven Hand Pose</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08942">http://arxiv.org/abs/2309.08942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gentlesjan/affordpose">https://github.com/gentlesjan/affordpose</a></li>
<li>paper_authors: Juntao Jian, Xiuping Liu, Manyi Li, Ruizhen Hu, Jian Liu</li>
<li>for: 这篇论文主要针对的是人机交互中对象的函数角色如何影响人的手势，以及如何通过大量人类示例来学习和理解合适的手势交互。</li>
<li>methods: 该论文提出了AffordPose数据集，包括26.7K个手势交互示例，每个示例包括3D对象形状、部分可行性标签和手势位置。</li>
<li>results: 数据分析表明，手势交互中的具体手势pose受到对象的可行性影响，同时也展现了一定的多样性。实验表明，AffordPose数据集可以有效地学习和理解细腻的手势交互。<details>
<summary>Abstract</summary>
How human interact with objects depends on the functional roles of the target objects, which introduces the problem of affordance-aware hand-object interaction. It requires a large number of human demonstrations for the learning and understanding of plausible and appropriate hand-object interactions. In this work, we present AffordPose, a large-scale dataset of hand-object interactions with affordance-driven hand pose. We first annotate the specific part-level affordance labels for each object, e.g. twist, pull, handle-grasp, etc, instead of the general intents such as use or handover, to indicate the purpose and guide the localization of the hand-object interactions. The fine-grained hand-object interactions reveal the influence of hand-centered affordances on the detailed arrangement of the hand poses, yet also exhibit a certain degree of diversity. We collect a total of 26.7K hand-object interactions, each including the 3D object shape, the part-level affordance label, and the manually adjusted hand poses. The comprehensive data analysis shows the common characteristics and diversity of hand-object interactions per affordance via the parameter statistics and contacting computation. We also conduct experiments on the tasks of hand-object affordance understanding and affordance-oriented hand-object interaction generation, to validate the effectiveness of our dataset in learning the fine-grained hand-object interactions. Project page: https://github.com/GentlesJan/AffordPose.
</details>
<details>
<summary>摘要</summary>
人类与物体之间的互动取决于目标物体的功能角色，这引入了有关手持物体互动的具体性和适应性的问题。为了解决这个问题，需要大量的人类示例来学习和理解合适的手持物体互动。在这个工作中，我们提出了AffordPose数据集，包括手持物体互动中的具体部分可行性标签，如拧、拧、握持等，而不是通用的用途或交给意图。这些细腻的手持物体互动显示了手中心可行性对手姿的细部安排产生了影响，同时也表现出一定的多样性。我们收集了26700个手持物体互动样本，每个样本包括3D物体形状、部分可行性标签和手姿调整。经过全面的数据分析，我们发现每种可行性下的手持物体互动具有共同特征和多样性，并通过参数统计和接触计算 validate our dataset的有效性。我们还进行了手持物体可行性理解和手持物体互动生成任务的实验，以验证我们的数据集在学习细腻手持物体互动方面的效果。项目页面：https://github.com/GentlesJan/AffordPose。
</details></li>
</ul>
<hr>
<h2 id="Semantics-aware-LiDAR-Only-Pseudo-Point-Cloud-Generation-for-3D-Object-Detection"><a href="#Semantics-aware-LiDAR-Only-Pseudo-Point-Cloud-Generation-for-3D-Object-Detection" class="headerlink" title="Semantics-aware LiDAR-Only Pseudo Point Cloud Generation for 3D Object Detection"></a>Semantics-aware LiDAR-Only Pseudo Point Cloud Generation for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08932">http://arxiv.org/abs/2309.08932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiago Cortinhal, Idriss Gouigah, Eren Erdal Aksoy</li>
<li>for: 提高自动驾驶系统中LiDAR感知器的精度和精细度，使其能够更好地检测远距离的细节物体。</li>
<li>methods: 利用LiDAR感知器alone，通过提取场景 semantics并使用多Modal domain translator生成增强的Synthetic dense point clouds，提高3D对象检测性能。</li>
<li>results: 在不同的高级3D对象检测方法上实现了最多2.9%的性能提升，并在KITTI 3D对象检测数据集上达到了与其他状态体LiDAR-only探测器相当的性能。<details>
<summary>Abstract</summary>
Although LiDAR sensors are crucial for autonomous systems due to providing precise depth information, they struggle with capturing fine object details, especially at a distance, due to sparse and non-uniform data. Recent advances introduced pseudo-LiDAR, i.e., synthetic dense point clouds, using additional modalities such as cameras to enhance 3D object detection. We present a novel LiDAR-only framework that augments raw scans with denser pseudo point clouds by solely relying on LiDAR sensors and scene semantics, omitting the need for cameras. Our framework first utilizes a segmentation model to extract scene semantics from raw point clouds, and then employs a multi-modal domain translator to generate synthetic image segments and depth cues without real cameras. This yields a dense pseudo point cloud enriched with semantic information. We also introduce a new semantically guided projection method, which enhances detection performance by retaining only relevant pseudo points. We applied our framework to different advanced 3D object detection methods and reported up to 2.9% performance upgrade. We also obtained comparable results on the KITTI 3D object detection dataset, in contrast to other state-of-the-art LiDAR-only detectors.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管LiDAR传感器对自动驾驶系统非常重要，因为它们提供精确的深度信息，但它们在距离较远的场景中很难捕捉细节，主要是因为LiDAR数据 sparse和不均匀。最近，人们提出了 Pseudo-LiDAR，即使用其他感知模式，如摄像头，来增强3D物体检测。我们提出了一种完全依靠LiDAR感知器和场景 semantics的 LiDAR-only 框架，可以增强 raw 扫描数据的精度。我们的框架首先使用一种分割模型提取场景 semantics，然后使用一种多模态领域翻译器生成无需真正摄像头的Synthetic 图像段和深度cue。这将生成一个充满 semantic 信息的 dense pseudo point cloud。我们还引入了一种受 semantics 引导的投影方法，可以提高检测性能。我们将我们的框架应用到不同的高级3D物体检测方法上，并reported 提高性能达2.9%。我们还在 KITTI 3D 物体检测数据集上获得了与其他状态 искусternal LiDAR-only 检测器相比的相似结果。
</details></li>
</ul>
<hr>
<h2 id="In-Style-Bridging-Text-and-Uncurated-Videos-with-Style-Transfer-for-Text-Video-Retrieval"><a href="#In-Style-Bridging-Text-and-Uncurated-Videos-with-Style-Transfer-for-Text-Video-Retrieval" class="headerlink" title="In-Style: Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval"></a>In-Style: Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08928">http://arxiv.org/abs/2309.08928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ninatu/in_style">https://github.com/ninatu/in_style</a></li>
<li>paper_authors: Nina Shvetsova, Anna Kukleva, Bernt Schiele, Hilde Kuehne</li>
<li>for: 文章目的是提出一种新的文本视频检索任务 setting，即使没有手动标注的对应文本视频数据。</li>
<li>methods: 提出了一种名为 In-Style 的方法，可以学习文本查询的风格并将其传递给网络视频。此外，我们还提出了一种多种风格冲突训练方法，以提高模型的通用性。</li>
<li>results: 我们通过对多个数据集进行测试，证明了我们的风格传递框架可以在无需手动标注对应文本视频数据的情况下提高文本视频检索任务的性能，并超越了零shot文本视频检索任务的州OF-THE-ART表现。<details>
<summary>Abstract</summary>
Large-scale noisy web image-text datasets have been proven to be efficient for learning robust vision-language models. However, when transferring them to the task of video retrieval, models still need to be fine-tuned on hand-curated paired text-video data to adapt to the diverse styles of video descriptions. To address this problem without the need for hand-annotated pairs, we propose a new setting, text-video retrieval with uncurated & unpaired data, that during training utilizes only text queries together with uncurated web videos without any paired text-video data. To this end, we propose an approach, In-Style, that learns the style of the text queries and transfers it to uncurated web videos. Moreover, to improve generalization, we show that one model can be trained with multiple text styles. To this end, we introduce a multi-style contrastive training procedure that improves the generalizability over several datasets simultaneously. We evaluate our model on retrieval performance over multiple datasets to demonstrate the advantages of our style transfer framework on the new task of uncurated & unpaired text-video retrieval and improve state-of-the-art performance on zero-shot text-video retrieval.
</details>
<details>
<summary>摘要</summary>
大规模嘈吵网络图片文本数据集已经证明可以有效地学习Robust vision-language模型。然而，在将其转移到视频检索任务时，模型仍需要通过手动批注的文本视频数据进行微调以适应不同的视频描述风格。为解决这个问题而不需要手动批注对，我们提出了一个新的设定：文本视频检索无curated & unpaired数据。在训练时，我们只使用文本查询，并使用无curated的网络视频，没有任何文本视频批注数据。为此，我们提出了一种方法，In-Style，它可以学习文本查询的风格，并将其传递给无curated的网络视频。此外，为提高泛化性，我们表明一个模型可以通过多种文本风格进行训练。为此，我们引入了多种风格强制对照训练程序，以提高模型的泛化性。我们对多个数据集进行了检索性能评估，以证明我们的风格传递框架在新任务中的优势，并超越了零shot文本视频检索的州场性能。
</details></li>
</ul>
<hr>
<h2 id="DynaMoN-Motion-Aware-Fast-And-Robust-Camera-Localization-for-Dynamic-NeRF"><a href="#DynaMoN-Motion-Aware-Fast-And-Robust-Camera-Localization-for-Dynamic-NeRF" class="headerlink" title="DynaMoN: Motion-Aware Fast And Robust Camera Localization for Dynamic NeRF"></a>DynaMoN: Motion-Aware Fast And Robust Camera Localization for Dynamic NeRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08927">http://arxiv.org/abs/2309.08927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mert Asim Karaoglu, Hannah Schieber, Nicolas Schischka, Melih Görgülü, Florian Grötzner, Alexander Ladikos, Daniel Roth, Nassir Navab, Benjamin Busam</li>
<li>for: 该论文旨在提出一种基于同时定位和地图建模（SLAM）的动态重建方法，以便更好地处理动态场景中的相机位置和场景内容的变化。</li>
<li>methods: 该方法使用了同时定位和地图建模（SLAM）和动态掩码（motion masking）结合，以提高动态重建的精度和效率。</li>
<li>results: 广泛的实验 validate了该方法在真实世界 dataset 上的优势，包括 TUM RGB-D、BONN RGB-D 动态和 DyCheck 的 iPhone 数据集。该方法不仅提高了相机pose估计的精度，还提高了动态重建的质量。<details>
<summary>Abstract</summary>
Dynamic reconstruction with neural radiance fields (NeRF) requires accurate camera poses. These are often hard to retrieve with existing structure-from-motion (SfM) pipelines as both camera and scene content can change. We propose DynaMoN that leverages simultaneous localization and mapping (SLAM) jointly with motion masking to handle dynamic scene content. Our robust SLAM-based tracking module significantly accelerates the training process of the dynamic NeRF while improving the quality of synthesized views at the same time. Extensive experimental validation on TUM RGB-D, BONN RGB-D Dynamic and the DyCheck's iPhone dataset, three real-world datasets, shows the advantages of DynaMoN both for camera pose estimation and novel view synthesis.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用神经辐射场 (NeRF) 进行动态重建需要准确的摄像头位置。现有的结构从动作 (SfM) 管道通常Difficult to retrieve this information, as both the camera and scene content can change. We propose DynaMoN, which leverages simultaneous localization and mapping (SLAM) and motion masking to handle dynamic scene content. Our robust SLAM-based tracking module significantly accelerates the training process of the dynamic NeRF while improving the quality of synthesized views at the same time. Experimental validation on TUM RGB-D, BONN RGB-D Dynamic, and the DyCheck's iPhone dataset, three real-world datasets, shows the advantages of DynaMoN for both camera pose estimation and novel view synthesis.</SYS>>Here's the text with some notes on the translation:* "动态重建" (dòngtài chóngběn) is used to refer to the process of reconstructing a 3D scene from a set of 2D images.* "神经辐射场" (jīngxīn chángshì chǎng) is a neural network-based method for reconstructing 3D scenes from 2D images.* "摄像头位置" (shèxiàngtou weiità) refers to the position of the camera that took the images.* "结构从动作" (jiégòng cóng dòngwù) is a computer vision technique used to reconstruct 3D scenes from 2D images.* "同时地图" (tóngshí dìmào) is a technique used to create a map of an environment while simultaneously localizing a device within that environment.* "动态Scene" (dòngtài scēn) refers to a scene that is changing or dynamic.* "视图合成" (wèi vision hébìng) is the process of generating new views of a scene from a set of existing views.I hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Pixel-Adapter-A-Graph-Based-Post-Processing-Approach-for-Scene-Text-Image-Super-Resolution"><a href="#Pixel-Adapter-A-Graph-Based-Post-Processing-Approach-for-Scene-Text-Image-Super-Resolution" class="headerlink" title="Pixel Adapter: A Graph-Based Post-Processing Approach for Scene Text Image Super-Resolution"></a>Pixel Adapter: A Graph-Based Post-Processing Approach for Scene Text Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08919">http://arxiv.org/abs/2309.08919</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenyu1009/rtsrn">https://github.com/wenyu1009/rtsrn</a></li>
<li>paper_authors: Wenyu Zhang, Xin Deng, Baojun Jia, Xingtong Yu, Yifan Chen, jin Ma, Qing Ding, Xinming Zhang</li>
<li>For: 提高文本图像超分辨率图像生成的精度和效率。* Methods: 提出Pixel Adapter Module (PAM)基于图注意力来解决升采样导致的像素扭曲问题，并引入MLP-based Sequential Residual Block (MSRB)来提取文本图像的稳定特征。* Results: 在TextZoom上进行了广泛的实验，并取得了高质量的超分辨率图像生成结果，比现有方法提高了认知率。对单stage和多stage策略进行了改进，分别提高了0.7%和2.6%，从52.6%和53.7%提高到53.3%和56.3%。<details>
<summary>Abstract</summary>
Current Scene text image super-resolution approaches primarily focus on extracting robust features, acquiring text information, and complex training strategies to generate super-resolution images. However, the upsampling module, which is crucial in the process of converting low-resolution images to high-resolution ones, has received little attention in existing works. To address this issue, we propose the Pixel Adapter Module (PAM) based on graph attention to address pixel distortion caused by upsampling. The PAM effectively captures local structural information by allowing each pixel to interact with its neighbors and update features. Unlike previous graph attention mechanisms, our approach achieves 2-3 orders of magnitude improvement in efficiency and memory utilization by eliminating the dependency on sparse adjacency matrices and introducing a sliding window approach for efficient parallel computation. Additionally, we introduce the MLP-based Sequential Residual Block (MSRB) for robust feature extraction from text images, and a Local Contour Awareness loss ($\mathcal{L}_{lca}$) to enhance the model's perception of details. Comprehensive experiments on TextZoom demonstrate that our proposed method generates high-quality super-resolution images, surpassing existing methods in recognition accuracy. For single-stage and multi-stage strategies, we achieved improvements of 0.7\% and 2.6\%, respectively, increasing the performance from 52.6\% and 53.7\% to 53.3\% and 56.3\%. The code is available at https://github.com/wenyu1009/RTSRN.
</details>
<details>
<summary>摘要</summary>
当前场景文本图像超解像方法主要集中于提取稳定特征、获取文本信息和复杂的训练策略，以生成超解像图像。然而，upsampling模块，该模块在将低分辨率图像转换为高分辨率图像的过程中扮演关键角色，在现有工作中受到了少量关注。为了解决这个问题，我们提议使用图像注意力机制（PAM）来处理像素扭曲。PAM可以有效地捕捉本地结构信息，让每个像素与邻居像素进行互动，更新特征。与过去的图像注意力机制不同，我们的方法可以在效率和内存利用上实现2-3个数量级的提升，而不需要针对稀疏相邻矩阵的依赖。此外，我们还引入了多层感知核（MLP）基于的Sequential Residual Block（MSRB），用于robust特征提取从文本图像中，以及Local Contour Awareness损失（$\mathcal{L}_{lca}$），以提高模型对细节的感知。在TextZoom上进行了广泛的实验，我们的提议方法可以生成高质量的超解像图像，超过现有方法的认知率。对单阶段和多阶段策略，我们实现了提升0.7%和2.6%，从52.6%和53.7%提升到53.3%和56.3%。代码可以在https://github.com/wenyu1009/RTSRN中获取。
</details></li>
</ul>
<hr>
<h2 id="Delving-into-Multimodal-Prompting-for-Fine-grained-Visual-Classification"><a href="#Delving-into-Multimodal-Prompting-for-Fine-grained-Visual-Classification" class="headerlink" title="Delving into Multimodal Prompting for Fine-grained Visual Classification"></a>Delving into Multimodal Prompting for Fine-grained Visual Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08912">http://arxiv.org/abs/2309.08912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Jiang, Hao Tang, Junyao Gao, Xiaoyu Du, Shengfeng He, Zechao Li</li>
<li>for: 这个研究旨在应用多modal描述来解决细分类的挑战，特别是在细分类中存在轻微的间隔和大量内分量的情况下。</li>
<li>methods: 这个研究使用了对称语言图像模型（CLIP），并提出了一个新的多modal诱导解决方案（MP-FGVC），包括多modal诱导方案和多modal适应方案。多modal诱导方案包括特定分类的视觉推问（SsVP）和差异感知文本推问（DaTP），它们强调了特定分类的视觉和语言差异。多modal适应方案将视觉和文本推问元素调节到共同semantic空间，以便跨modal协力推理，并通过视觉语言融合模组（VLFM）进一步提高FGVC。</li>
<li>results: 实验结果显示MP-FGVC在四个FGVC数据集上具有优秀的效果。<details>
<summary>Abstract</summary>
Fine-grained visual classification (FGVC) involves categorizing fine subdivisions within a broader category, which poses challenges due to subtle inter-class discrepancies and large intra-class variations. However, prevailing approaches primarily focus on uni-modal visual concepts. Recent advancements in pre-trained vision-language models have demonstrated remarkable performance in various high-level vision tasks, yet the applicability of such models to FGVC tasks remains uncertain. In this paper, we aim to fully exploit the capabilities of cross-modal description to tackle FGVC tasks and propose a novel multimodal prompting solution, denoted as MP-FGVC, based on the contrastive language-image pertaining (CLIP) model. Our MP-FGVC comprises a multimodal prompts scheme and a multimodal adaptation scheme. The former includes Subcategory-specific Vision Prompt (SsVP) and Discrepancy-aware Text Prompt (DaTP), which explicitly highlights the subcategory-specific discrepancies from the perspectives of both vision and language. The latter aligns the vision and text prompting elements in a common semantic space, facilitating cross-modal collaborative reasoning through a Vision-Language Fusion Module (VLFM) for further improvement on FGVC. Moreover, we tailor a two-stage optimization strategy for MP-FGVC to fully leverage the pre-trained CLIP model and expedite efficient adaptation for FGVC. Extensive experiments conducted on four FGVC datasets demonstrate the effectiveness of our MP-FGVC.
</details>
<details>
<summary>摘要</summary>
低级分类视觉（FGVC）涉及到细分类划分，这会带来细腻的间隔差异和大量内类变化。然而，现有的方法主要集中于单模visual概念。 recent advances in pre-trained vision-language models have shown remarkable performance in various high-level vision tasks, but the applicability of such models to FGVC tasks remains uncertain. In this paper, we aim to fully exploit the capabilities of cross-modal description to tackle FGVC tasks and propose a novel multimodal prompting solution, denoted as MP-FGVC, based on the contrastive language-image pertaining (CLIP) model. Our MP-FGVC consists of a multimodal prompts scheme and a multimodal adaptation scheme. The former includes Subcategory-specific Vision Prompt (SsVP) and Discrepancy-aware Text Prompt (DaTP), which explicitly highlights the subcategory-specific discrepancies from the perspectives of both vision and language. The latter aligns the vision and text prompting elements in a common semantic space, facilitating cross-modal collaborative reasoning through a Vision-Language Fusion Module (VLFM) for further improvement on FGVC. Moreover, we tailor a two-stage optimization strategy for MP-FGVC to fully leverage the pre-trained CLIP model and expedite efficient adaptation for FGVC. Extensive experiments conducted on four FGVC datasets demonstrate the effectiveness of our MP-FGVC.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Visual-Perception-in-Novel-Environments-via-Incremental-Data-Augmentation-Based-on-Style-Transfer"><a href="#Enhancing-Visual-Perception-in-Novel-Environments-via-Incremental-Data-Augmentation-Based-on-Style-Transfer" class="headerlink" title="Enhancing Visual Perception in Novel Environments via Incremental Data Augmentation Based on Style Transfer"></a>Enhancing Visual Perception in Novel Environments via Incremental Data Augmentation Based on Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08851">http://arxiv.org/abs/2309.08851</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abhibha1807/robustifying_visual_perception">https://github.com/abhibha1807/robustifying_visual_perception</a></li>
<li>paper_authors: Abhibha Gupta, Rully Agus Hendrawan, Mansur Arief</li>
<li>for: 强化自适应代理在真实世界场景中的部署，应对“未知未知”（ novell 和不期望的环境）。</li>
<li>methods: 使用 Variational Prototyping Encoder (VPE) 实现可靠地识别和处理新Input，然后逐步增强数据使用神经抽象转移来增强受测数据。</li>
<li>results: 比较仅从原始数据训练的模型和从原始和增强数据训练的模型，发现增强数据训练对模型性能有着明显的改善，这证明了数据增强的重要性。<details>
<summary>Abstract</summary>
The deployment of autonomous agents in real-world scenarios is challenged by "unknown unknowns", i.e. novel unexpected environments not encountered during training, such as degraded signs. While existing research focuses on anomaly detection and class imbalance, it often fails to address truly novel scenarios. Our approach enhances visual perception by leveraging the Variational Prototyping Encoder (VPE) to adeptly identify and handle novel inputs, then incrementally augmenting data using neural style transfer to enrich underrepresented data. By comparing models trained solely on original datasets with those trained on a combination of original and augmented datasets, we observed a notable improvement in the performance of the latter. This underscores the critical role of data augmentation in enhancing model robustness. Our findings suggest the potential benefits of incorporating generative models for domain-specific augmentation strategies.
</details>
<details>
<summary>摘要</summary>
<<SYS>>实际场景中自动化代理的部署受到“未知未知”的挑战，即在训练中没有遇到的新不期望环境，如受损标志。现有研究主要关注异常检测和类别偏度，但经常无法处理真正新的场景。我们的方法通过利用变量抽象编码器（VPE）来有效地识别和处理新输入，然后逐步增强数据使用神经风格传输来润色不足表示。我们比较了固定在原始数据集上训练的模型和将原始数据集和增强数据集组合训练的模型，发现后者表现更佳。这表明数据增强对模型Robustness具有重要作用。我们的发现表明可能将生成模型integrated into domain-specific augmentation strategies中。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="MA-SAM-Modality-agnostic-SAM-Adaptation-for-3D-Medical-Image-Segmentation"><a href="#MA-SAM-Modality-agnostic-SAM-Adaptation-for-3D-Medical-Image-Segmentation" class="headerlink" title="MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image Segmentation"></a>MA-SAM: Modality-agnostic SAM Adaptation for 3D Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08842">http://arxiv.org/abs/2309.08842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cchen-cc/ma-sam">https://github.com/cchen-cc/ma-sam</a></li>
<li>paper_authors: Cheng Chen, Juzheng Miao, Dufan Wu, Zhiling Yan, Sekeun Kim, Jiang Hu, Aoxiao Zhong, Zhengliang Liu, Lichao Sun, Xiang Li, Tianming Liu, Pheng-Ann Heng, Quanzheng Li<br>for:* 这个研究是为了提高基于自然图像的图像分类模型（Segment Anything Model，SAM）在医疗图像分类任务中的表现。methods:* 这个研究使用了SAM的预训 weights，并在 fine-tuning 过程中添加了3D adapter，将3D信息融入到SAM的图像Encoder中。results:* 这个研究在4个医疗图像分类任务上进行了广泛的评估，并证明了MA-SAM在这些任务中的表现比其他竞争方法更好，包括nnU-Net。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM), a foundation model for general image segmentation, has demonstrated impressive zero-shot performance across numerous natural image segmentation tasks. However, SAM's performance significantly declines when applied to medical images, primarily due to the substantial disparity between natural and medical image domains. To effectively adapt SAM to medical images, it is important to incorporate critical third-dimensional information, i.e., volumetric or temporal knowledge, during fine-tuning. Simultaneously, we aim to harness SAM's pre-trained weights within its original 2D backbone to the fullest extent. In this paper, we introduce a modality-agnostic SAM adaptation framework, named as MA-SAM, that is applicable to various volumetric and video medical data. Our method roots in the parameter-efficient fine-tuning strategy to update only a small portion of weight increments while preserving the majority of SAM's pre-trained weights. By injecting a series of 3D adapters into the transformer blocks of the image encoder, our method enables the pre-trained 2D backbone to extract third-dimensional information from input data. The effectiveness of our method has been comprehensively evaluated on four medical image segmentation tasks, by using 10 public datasets across CT, MRI, and surgical video data. Remarkably, without using any prompt, our method consistently outperforms various state-of-the-art 3D approaches, surpassing nnU-Net by 0.9%, 2.6%, and 9.9% in Dice for CT multi-organ segmentation, MRI prostate segmentation, and surgical scene segmentation respectively. Our model also demonstrates strong generalization, and excels in challenging tumor segmentation when prompts are used. Our code is available at: https://github.com/cchen-cc/MA-SAM.
</details>
<details>
<summary>摘要</summary>
segments Anything Model (SAM)，一种基础模型 для通用图像分割，在各种自然图像分割任务上表现出色，但是在医疗图像上表现较差，主要是因为医疗图像和自然图像领域之间存在巨大的差异。为了有效地适应医疗图像，需要在精度调整中包含关键的三维信息，即体积或时间信息。同时，我们希望能充分利用SAM已经预训练的参数。在这篇文章中，我们提出了一种不同类型的SAM适应框架，名为MA-SAM，可以应用于各种体积和视频医疗数据。我们的方法基于精度调整策略，只更新一小部分的参数增量，保留SAM预训练的大部分参数。通过在图像编码器中插入3D适应器，我们的方法使得预训练的2D背景能够从输入数据中提取三维信息。我们的方法在四种医疗图像分割任务上进行了广泛的评估，使用了10个公共数据集，包括CT、MRI和手术视频数据。可见地，无需使用提示，我们的方法在各种状态前的3D方法之上升级，nnU-Net的Dice值上升9.9%、2.6%和0.9%。我们的模型还表现出了强大的泛化能力，在提示使用时也能够出色地完成肿瘤分割任务。我们的代码可以在https://github.com/cchen-cc/MA-SAM上获取。
</details></li>
</ul>
<hr>
<h2 id="AOSR-Net-All-in-One-Sandstorm-Removal-Network"><a href="#AOSR-Net-All-in-One-Sandstorm-Removal-Network" class="headerlink" title="AOSR-Net: All-in-One Sandstorm Removal Network"></a>AOSR-Net: All-in-One Sandstorm Removal Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08838">http://arxiv.org/abs/2309.08838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yazhong Si, Xulong Zhang, Fan Yang, Jianzong Wang, Ning Cheng, Jing Xiao</li>
<li>for: 本研究旨在解决现有的尘埃图像提高方法存在的应用限制和复杂算法结构问题。</li>
<li>methods: 该研究提出了一种全新的图像恢复模型，名为“一体化尘埃除网络”（AOSR-Net），该模型基于重新定义的尘埃散射模型，直接建立了图像映射关系，并且将中间参数集成到模型中，从而有效地解决了过强增强和Week Generalization问题。</li>
<li>results: 对于 synthetic 和实际尘埃图像进行了实验，结果显示，提出的 AOSR-Net 模型在对尘埃图像进行提高时表现出色，超过了当前最佳算法（SOTA）的性能。<details>
<summary>Abstract</summary>
Most existing sandstorm image enhancement methods are based on traditional theory and prior knowledge, which often restrict their applicability in real-world scenarios. In addition, these approaches often adopt a strategy of color correction followed by dust removal, which makes the algorithm structure too complex. To solve the issue, we introduce a novel image restoration model, named all-in-one sandstorm removal network (AOSR-Net). This model is developed based on a re-formulated sandstorm scattering model, which directly establishes the image mapping relationship by integrating intermediate parameters. Such integration scheme effectively addresses the problems of over-enhancement and weak generalization in the field of sand dust image enhancement. Experimental results on synthetic and real-world sandstorm images demonstrate the superiority of the proposed AOSR-Net over state-of-the-art (SOTA) algorithms.
</details>
<details>
<summary>摘要</summary>
现有的沙尘抑制方法多数基于传统理论和先知知识，这常限制其在实际场景中的应用。另外，这些方法通常采用色调修正后followed by dust removal的策略，使算法结构变得太复杂。为解决这问题，我们介绍了一种新的图像恢复模型，即全 inclusive sandstorm removal network (AOSR-Net)。该模型基于重新表述的沙尘散射模型，直接建立图像映射关系，并通过 интеGRATION scheme来有效地解决抑制过激和弱泛化问题。实验结果表明，提出的AOSR-Net在 synthetic和实际沙尘图像中的表现优于state-of-the-art（SOTA）算法。
</details></li>
</ul>
<hr>
<h2 id="Dual-Camera-Joint-Deblurring-Denoising"><a href="#Dual-Camera-Joint-Deblurring-Denoising" class="headerlink" title="Dual-Camera Joint Deblurring-Denoising"></a>Dual-Camera Joint Deblurring-Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08826">http://arxiv.org/abs/2309.08826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shayan Shekarforoush, Amanpreet Walia, Marcus A. Brubaker, Konstantinos G. Derpanis, Alex Levinshtein</li>
<li>for: 提高低光照照片质量</li>
<li>methods: 使用同步短暂曝光图像和长暂曝光图像，并将其进行拼接和权重调整</li>
<li>results: 实现了对同步双摄像头图像进行优化，并在实验中显示出比其他方法更高的质量和稳定性<details>
<summary>Abstract</summary>
Recent image enhancement methods have shown the advantages of using a pair of long and short-exposure images for low-light photography. These image modalities offer complementary strengths and weaknesses. The former yields an image that is clean but blurry due to camera or object motion, whereas the latter is sharp but noisy due to low photon count. Motivated by the fact that modern smartphones come equipped with multiple rear-facing camera sensors, we propose a novel dual-camera method for obtaining a high-quality image. Our method uses a synchronized burst of short exposure images captured by one camera and a long exposure image simultaneously captured by another. Having a synchronized short exposure burst alongside the long exposure image enables us to (i) obtain better denoising by using a burst instead of a single image, (ii) recover motion from the burst and use it for motion-aware deblurring of the long exposure image, and (iii) fuse the two results to further enhance quality. Our method is able to achieve state-of-the-art results on synthetic dual-camera images from the GoPro dataset with five times fewer training parameters compared to the next best method. We also show that our method qualitatively outperforms competing approaches on real synchronized dual-camera captures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现代低光照摄像头技术已经显示了使用两枚长和短曝光图像的优点。这两种图像模式具有补偿的优势和缺点。前者生成了清晰但涂抹的图像，由于摄像头或物体运动而导致涂抹；而后者具有高分辨率，但由于低光子数而导致噪声。我们受到现代智能手机搭载多个后置摄像头的启示，我们提出了一种新的双摄像头方法，以实现高质量图像。我们的方法使用同步短曝光快照集的一个摄像头，同时使用另一个摄像头拍摄长曝光图像。具有同步短曝光快照的存在，我们可以（i）通过快照集取得更好的噪声纠正，（ii）从快照集中回归运动，并用于运动感知滤除长曝光图像中的涂抹，以及（iii）将两个结果融合，进一步提高质量。我们的方法在GoPro数据集上实现了状态最佳的结果，与接下来最佳方法相比，训练参数只需五分之一。我们还显示了我们的方法在真实同步双摄像头捕捉中的质量超越竞争方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/cs.CV_2023_09_16/" data-id="clp89dod900jni788ccxog35t" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/cs.AI_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T12:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/cs.AI_2023_09_16/">cs.AI - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Interactively-Teaching-an-Inverse-Reinforcement-Learner-with-Limited-Feedback"><a href="#Interactively-Teaching-an-Inverse-Reinforcement-Learner-with-Limited-Feedback" class="headerlink" title="Interactively Teaching an Inverse Reinforcement Learner with Limited Feedback"></a>Interactively Teaching an Inverse Reinforcement Learner with Limited Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09095">http://arxiv.org/abs/2309.09095</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rzayanov/irl-teaching-limited-feedback">https://github.com/rzayanov/irl-teaching-limited-feedback</a></li>
<li>paper_authors: Rustam Zayanov, Francisco S. Melo, Manuel Lopes</li>
<li>for: 本研究强调教学via示例在顺序决策任务中，特别是教师无法访问学生模型和策略的情况下。</li>
<li>methods: 本文使用 inverse reinforcement learning 和 active learning 方法，教师可以通过选择开始状态和推断学生策略来解决这个教学问题。</li>
<li>results: 在一个人工汽车驾驶环境中测试了提议的算法，结果显示该算法在学生反馈有限时是一个有效的解决方案。<details>
<summary>Abstract</summary>
We study the problem of teaching via demonstrations in sequential decision-making tasks. In particular, we focus on the situation when the teacher has no access to the learner's model and policy, and the feedback from the learner is limited to trajectories that start from states selected by the teacher. The necessity to select the starting states and infer the learner's policy creates an opportunity for using the methods of inverse reinforcement learning and active learning by the teacher. In this work, we formalize the teaching process with limited feedback and propose an algorithm that solves this teaching problem. The algorithm uses a modified version of the active value-at-risk method to select the starting states, a modified maximum causal entropy algorithm to infer the policy, and the difficulty score ratio method to choose the teaching demonstrations. We test the algorithm in a synthetic car driving environment and conclude that the proposed algorithm is an effective solution when the learner's feedback is limited.
</details>
<details>
<summary>摘要</summary>
我们研究教学via示例在时序决策任务中。特别是在教师无法访问学生的模型和策略的情况下，并且学生对教师的反馈仅仅是从教师选择的状态开始的路径。因为选择开始状态和推理学生策略创造了教师可以使用反对抗学习和活动学习的机会。在这个研究中，我们将教学过程 formalize 为有限反馈的情况，并提出一个解决这个教学问题的算法。这个算法使用修改版的活跃值-at-risk方法选择开始状态，修改最大 causal entropy 算法推理学生策略，以及对教学示例选择的困难分数比率方法。我们在人工智能汽车驾驶环境中试验了这个算法，结果显示，我们的提案算法在学生的反馈有限时是一个有效的解决方案。
</details></li>
</ul>
<hr>
<h2 id="RMDM-A-Multilabel-Fakenews-Dataset-for-Vietnamese-Evidence-Verification"><a href="#RMDM-A-Multilabel-Fakenews-Dataset-for-Vietnamese-Evidence-Verification" class="headerlink" title="RMDM: A Multilabel Fakenews Dataset for Vietnamese Evidence Verification"></a>RMDM: A Multilabel Fakenews Dataset for Vietnamese Evidence Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09071">http://arxiv.org/abs/2309.09071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai-Long Nguyen, Thi-Kieu-Trang Pham, Thai-Son Le, Tan-Minh Nguyen, Thi-Hai-Yen Vuong, Ha-Thanh Nguyen</li>
<li>for: 这个研究是为了评估大语言模型（LLM）在电子信息相关法律上的性能，特别是用于识别假新闻作为电子证据的输入。</li>
<li>methods: 该研究使用了一个新的和挑战性的多标签越南语 dataset（RMDM），包括四个标签：实用、误差、恶意和恶假，表示实际信息、误差信息、恶意信息和假信息。</li>
<li>results: 研究发现，使用 GPT 和 BERT 模型测试 RMDM 数据集时，每个标签的性能异常，表明该数据集能够挑战不同语言模型对于识别各种类型的电子信息的能力。研究结果表明，用于识别电子信息相关法律上的 fake news 仍然是一个困难的问题，需要更多的研究人员投入，以提高 AI 模型的可靠性。<details>
<summary>Abstract</summary>
In this study, we present a novel and challenging multilabel Vietnamese dataset (RMDM) designed to assess the performance of large language models (LLMs), in verifying electronic information related to legal contexts, focusing on fake news as potential input for electronic evidence. The RMDM dataset comprises four labels: real, mis, dis, and mal, representing real information, misinformation, disinformation, and mal-information, respectively. By including these diverse labels, RMDM captures the complexities of differing fake news categories and offers insights into the abilities of different language models to handle various types of information that could be part of electronic evidence. The dataset consists of a total of 1,556 samples, with 389 samples for each label. Preliminary tests on the dataset using GPT-based and BERT-based models reveal variations in the models' performance across different labels, indicating that the dataset effectively challenges the ability of various language models to verify the authenticity of such information. Our findings suggest that verifying electronic information related to legal contexts, including fake news, remains a difficult problem for language models, warranting further attention from the research community to advance toward more reliable AI models for potential legal applications.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一个新的和挑战性的多标签越南语数据集（RMDM），用于评估大语言模型（LLM）在电子信息相关法律上下文中的性能，特点是通过假新闻作为电子证据的输入。RMDM数据集包括四个标签：真实、误information、 désinformation和mal-information，分别表示真实信息、误信息、恶意误导和危险信息。由于这些多样化的标签，RMDM数据集能够捕捉各种假新闻类型的复杂性，并为不同语言模型的性能进行评估。该数据集包括总共1556个样本，每个标签各有389个样本。初步测试表明，使用基于GPT和BERT模型的语言模型在不同标签上表现有很大差异，这表明RMDM数据集对不同语言模型的挑战性很高。我们的发现表明，在法律上下文中电子信息的验证仍然是一个具有挑战性的问题，需要研究人员继续努力，以提出更可靠的AI模型，用于 potential legal applications。
</details></li>
</ul>
<hr>
<h2 id="NOWJ1-ALQAC-2023-Enhancing-Legal-Task-Performance-with-Classic-Statistical-Models-and-Pre-trained-Language-Models"><a href="#NOWJ1-ALQAC-2023-Enhancing-Legal-Task-Performance-with-Classic-Statistical-Models-and-Pre-trained-Language-Models" class="headerlink" title="NOWJ1@ALQAC 2023: Enhancing Legal Task Performance with Classic Statistical Models and Pre-trained Language Models"></a>NOWJ1@ALQAC 2023: Enhancing Legal Task Performance with Classic Statistical Models and Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09070">http://arxiv.org/abs/2309.09070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tan-Minh Nguyen, Xuan-Hoa Nguyen, Ngoc-Duy Mai, Minh-Quan Hoang, Van-Huan Nguyen, Hoang-Viet Nguyen, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong</li>
<li>for: 本研究旨在提高法律任务性能，通过精心搭配经典统计模型和预训练语言模型（PLMs）。</li>
<li>methods: 我们实施了一个预处理步骤，以解决输入限制，并应用学习到rank方法，以整合各种模型中的特征。在问答任务中，我们分成两个子任务：句子分类和答案提取。我们采用了当今最佳实践，以开发每个子任务的独特系统，并利用经典统计模型和预训练语言模型。</li>
<li>results: 实验结果表明，我们提出的方法在比赛中具有扎实的潜力。<details>
<summary>Abstract</summary>
This paper describes the NOWJ1 Team's approach for the Automated Legal Question Answering Competition (ALQAC) 2023, which focuses on enhancing legal task performance by integrating classical statistical models and Pre-trained Language Models (PLMs). For the document retrieval task, we implement a pre-processing step to overcome input limitations and apply learning-to-rank methods to consolidate features from various models. The question-answering task is split into two sub-tasks: sentence classification and answer extraction. We incorporate state-of-the-art models to develop distinct systems for each sub-task, utilizing both classic statistical models and pre-trained Language Models. Experimental results demonstrate the promising potential of our proposed methodology in the competition.
</details>
<details>
<summary>摘要</summary>
Note: Simplified Chinese is also known as "简化字符" or "简体字".Here's the translation in Traditional Chinese:这份研究报告描述了NOWJ1队的2023年自动法律问题回答比赛（ALQAC）方法，强调通过结合古典统计模型和预训语言模型（PLMs）来提高法律任务性能。 для文档搜寻任务，我们实现了预处理步骤以超过输入限制，并使用学习排名方法将不同模型中的特征集成。问题回答任务分为两个子任务：句子分类和答案抽取。我们使用了现代模型，开发了两个不同的系统，一个是基于古典统计模型，另一个是基于预训语言模型。实验结果显示了我们的提案方法在比赛中的应用潜力。
</details></li>
</ul>
<hr>
<h2 id="GenDOM-Generalizable-One-shot-Deformable-Object-Manipulation-with-Parameter-Aware-Policy"><a href="#GenDOM-Generalizable-One-shot-Deformable-Object-Manipulation-with-Parameter-Aware-Policy" class="headerlink" title="GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy"></a>GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09051">http://arxiv.org/abs/2309.09051</a></li>
<li>repo_url: None</li>
<li>paper_authors: So Kuroki, Jiaxian Guo, Tatsuya Matsushima, Takuya Okubo, Masato Kobayashi, Yuya Ikeda, Ryosuke Takanami, Paul Yoo, Yutaka Matsuo, Yusuke Iwasawa</li>
<li>for: 一个可以实现单一示范的弹性物品操作框架 (a framework that can achieve one-shot deformable object manipulation)</li>
<li>methods: 使用弹性物品参数来条件政策并在训练过程中使用多种弹性物品模拟，以将政策适应不同弹性物品 (using deformable object parameters to condition the policy and training it with a diverse range of simulated deformable objects, so that the policy can adapt to different objects)</li>
<li>results: 实际验证范例显示，our方法可以实现不同弹性物品的一个示范操作 (empirical validations show that our method can manipulate different objects with a single demonstration)，并在实际环境中比基eline表现更好 (and significantly outperform the baseline in both simulation and real-world environments)<details>
<summary>Abstract</summary>
Due to the inherent uncertainty in their deformability during motion, previous methods in deformable object manipulation, such as rope and cloth, often required hundreds of real-world demonstrations to train a manipulation policy for each object, which hinders their applications in our ever-changing world. To address this issue, we introduce GenDOM, a framework that allows the manipulation policy to handle different deformable objects with only a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable object parameters and training it with a diverse range of simulated deformable objects so that the policy can adjust actions based on different object parameters. At the time of inference, given a new object, GenDOM can estimate the deformable object parameters with only a single real-world demonstration by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations in a differentiable physics simulator. Empirical validations on both simulated and real-world object manipulation setups clearly show that our method can manipulate different objects with a single demonstration and significantly outperforms the baseline in both environments (a 62% improvement for in-domain ropes and a 15% improvement for out-of-distribution ropes in simulation, as well as a 26% improvement for ropes and a 50% improvement for cloths in the real world), demonstrating the effectiveness of our approach in one-shot deformable object manipulation.
</details>
<details>
<summary>摘要</summary>
由于物体的自然变形性在运动中的不确定性，过去的方法在弹性物体把握中经常需要数百个实际世界示例来训练把握策略，这限制了它们在我们的变化世界中的应用。为解决这个问题，我们介绍GenDOM框架，它允许把握策略处理不同的弹性物体，只需要单个实际世界示例。为达到这个目标，我们在策略中添加了基于弹性物体参数的条件，并在训练策略时使用了多种 simulate 的弹性物体，以便策略可以根据不同的物体参数调整动作。在推理时，对于新的物体，GenDOM可以通过在一个分解器上进行最小化，使得策略可以在具有不同物体参数的情况下进行适应。我们的实验证明，我们的方法可以在各种 simulate 和实际环境中一shot 把握不同的弹性物体，并且明显超过基eline，这证明了我们的方法在一shot 弹性物体把握中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-Driven-Storytelling-A-New-Era-for-Marketing"><a href="#Generative-AI-Driven-Storytelling-A-New-Era-for-Marketing" class="headerlink" title="Generative AI-Driven Storytelling: A New Era for Marketing"></a>Generative AI-Driven Storytelling: A New Era for Marketing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09048">http://arxiv.org/abs/2309.09048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marko Vidrih, Shiva Mayahi</li>
<li>for: 这篇论文探讨了用生成AI驱动的故事创作在市场策略中的转变力。</li>
<li>methods: 该论文使用实际业界例子，如Google、Netflix和Stitch Fix，解释了如何使用此技术自定义消费者体验， navigate 相关挑战。</li>
<li>results: 论文描述了将来的发展方向和建议，包括实时个性化 Storytelling、 immerse  Storytelling 体验和社交媒体 Storytelling。In English, the three key points are:</li>
<li>for: This paper explores the transformative power of Generative AI-driven storytelling in marketing.</li>
<li>methods: The paper uses real-world examples from industry leaders like Google, Netflix, and Stitch Fix to illustrate how this technology personalizes consumer experiences and navigates challenges.</li>
<li>results: The paper describes future directions and recommendations for generative AI-driven storytelling, including prospective applications such as real-time personalized storytelling, immersive storytelling experiences, and social media storytelling.<details>
<summary>Abstract</summary>
This paper delves into the transformative power of Generative AI-driven storytelling in the realm of marketing. Generative AI, distinct from traditional machine learning, offers the capability to craft narratives that resonate with consumers on a deeply personal level. Through real-world examples from industry leaders like Google, Netflix and Stitch Fix, we elucidate how this technology shapes marketing strategies, personalizes consumer experiences, and navigates the challenges it presents. The paper also explores future directions and recommendations for generative AI-driven storytelling, including prospective applications such as real-time personalized storytelling, immersive storytelling experiences, and social media storytelling. By shedding light on the potential and impact of generative AI-driven storytelling in marketing, this paper contributes to the understanding of this cutting-edge approach and its transformative power in the field of marketing.
</details>
<details>
<summary>摘要</summary>
这篇论文探讨了生成AI驱动的故事创作在市场营销中的变革力。生成AI与传统机器学习不同，具有制作吸引消费者深层次共鸣的故事的能力。通过实业领导者如Google、Netflix和Stitch Fix的实践例子，我们详细介绍了该技术如何影响市场策略、个性化消费者经验和解决相关挑战。这篇论文还探讨了未来生成AI驱动的故事创作的发展趋势和建议，包括实时个性化storytelling、 immerse storytelling经验和社交媒体storytelling。这篇论文通过探讨生成AI驱动的故事创作在市场营销中的潜力和影响，贡献于这一领域的理解和发展。
</details></li>
</ul>
<hr>
<h2 id="A-store-and-forward-cloud-based-telemonitoring-system-for-automatic-assessing-dysarthria-evolution-in-neurological-diseases-from-video-recording-analysis"><a href="#A-store-and-forward-cloud-based-telemonitoring-system-for-automatic-assessing-dysarthria-evolution-in-neurological-diseases-from-video-recording-analysis" class="headerlink" title="A store-and-forward cloud-based telemonitoring system for automatic assessing dysarthria evolution in neurological diseases from video-recording analysis"></a>A store-and-forward cloud-based telemonitoring system for automatic assessing dysarthria evolution in neurological diseases from video-recording analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09038">http://arxiv.org/abs/2309.09038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucia Migliorelli, Daniele Berardini, Kevin Cela, Michela Coccia, Laura Villani, Emanuele Frontoni, Sara Moccia</li>
<li>For: This study aims to provide a remote telemonitoring system to support clinicians in monitoring the evolution of dysarthria in patients with neurological diseases.* Methods: The system uses a convolutional neural network (CNN) to analyze video recordings of individuals with dysarthria, and locates facial landmarks as a prior for assessing orofacial functions related to speech.* Results: The proposed CNN achieved a normalized mean error of 1.79 on localizing facial landmarks when tested on a public dataset, and showed promising outcomes in a real-life scenario with 11 bulbar-onset ALS subjects.<details>
<summary>Abstract</summary>
Background and objectives: Patients suffering from neurological diseases may develop dysarthria, a motor speech disorder affecting the execution of speech. Close and quantitative monitoring of dysarthria evolution is crucial for enabling clinicians to promptly implement patient management strategies and maximizing effectiveness and efficiency of communication functions in term of restoring, compensating or adjusting. In the clinical assessment of orofacial structures and functions, at rest condition or during speech and non-speech movements, a qualitative evaluation is usually performed, throughout visual observation. Methods: To overcome limitations posed by qualitative assessments, this work presents a store-and-forward self-service telemonitoring system that integrates, within its cloud architecture, a convolutional neural network (CNN) for analyzing video recordings acquired by individuals with dysarthria. This architecture, called facial landmark Mask RCNN, aims at locating facial landmarks as a prior for assessing the orofacial functions related to speech and examining dysarthria evolution in neurological diseases. Results: When tested on the Toronto NeuroFace dataset, a publicly available annotated dataset of video recordings from patients with amyotrophic lateral sclerosis (ALS) and stroke, the proposed CNN achieved a normalized mean error equal to 1.79 on localizing the facial landmarks. We also tested our system in a real-life scenario on 11 bulbar-onset ALS subjects, obtaining promising outcomes in terms of facial landmark position estimation. Discussion and conclusions: This preliminary study represents a relevant step towards the use of remote tools to support clinicians in monitoring the evolution of dysarthria.
</details>
<details>
<summary>摘要</summary>
背景和目标：神经疾病患者可能发展出语言障碍，称为肌肉语言障碍，影响语言执行。为了帮助临床医生尽快实施患者管理策略并最大化对语言功能的效果和效率，close和量化监测肌肉语言障碍的发展是非常重要的。在评估嘴部结构和功能方面，通常采用观察方式进行评估。方法：为了超越质量评估的限制，本工作提出了一个自助式抽象云端系统，其中包含一个基于卷积神经网络（CNN）的脸部特征检测模型，用于分析患者所录制的视频记录。这个架构被称为脸部特征Mask RCNN，旨在在视频记录中检测肌肉语言障碍的发展，并评估嘴部结构和功能相关的语言功能。结果：当测试在多伦多大学的脸部数据集上时，我们的CNN模型实现了1.79的正常化平均错误，用于定位脸部特征。我们还在11名有患有贝叶静脉性肌肉疾病的实际情况下测试了我们的系统，并获得了可观的结果，表明我们的系统可以准确地定位脸部特征。讨论和结论：这一初步研究表明了远程工具的使用可以帮助临床医生更好地监测肌肉语言障碍的发展。通过评估肌肉语言障碍的发展，可以帮助临床医生更好地评估患者的状况，并采取更加有效的治疗策略。此外，这种远程监测技术可以帮助患者更好地与医生进行沟通，从而提高患者的生活质量。
</details></li>
</ul>
<hr>
<h2 id="Improve-Deep-Forest-with-Learnable-Layerwise-Augmentation-Policy-Schedule"><a href="#Improve-Deep-Forest-with-Learnable-Layerwise-Augmentation-Policy-Schedule" class="headerlink" title="Improve Deep Forest with Learnable Layerwise Augmentation Policy Schedule"></a>Improve Deep Forest with Learnable Layerwise Augmentation Policy Schedule</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09030">http://arxiv.org/abs/2309.09030</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dbsxfz/augdf">https://github.com/dbsxfz/augdf</a></li>
<li>paper_authors: Hongyu Zhu, Sichu Liang, Wentao Hu, Fang-Qi Li, Yali yuan, Shi-Lin Wang, Guang Cheng</li>
<li>for: 提高 Deep Forest 模型的表现和泛化能力，对 tabular 数据进行更好的处理和分类。</li>
<li>methods: 使用可学习的层 wise 数据增强策略，包括 Cut Mix for Tabular data 技术，并使用人口基数搜索算法来调整增强程度。</li>
<li>results: 在多个 tabular 分类任务中达到新的 state-of-the-art 水平，超过了树ensemble、深度森林、深度神经网络和 AutoML 竞争对手。<details>
<summary>Abstract</summary>
As a modern ensemble technique, Deep Forest (DF) employs a cascading structure to construct deep models, providing stronger representational power compared to traditional decision forests. However, its greedy multi-layer learning procedure is prone to overfitting, limiting model effectiveness and generalizability. This paper presents an optimized Deep Forest, featuring learnable, layerwise data augmentation policy schedules. Specifically, We introduce the Cut Mix for Tabular data (CMT) augmentation technique to mitigate overfitting and develop a population-based search algorithm to tailor augmentation intensity for each layer. Additionally, we propose to incorporate outputs from intermediate layers into a checkpoint ensemble for more stable performance. Experimental results show that our method sets new state-of-the-art (SOTA) benchmarks in various tabular classification tasks, outperforming shallow tree ensembles, deep forests, deep neural network, and AutoML competitors. The learned policies also transfer effectively to Deep Forest variants, underscoring its potential for enhancing non-differentiable deep learning modules in tabular signal processing.
</details>
<details>
<summary>摘要</summary>
为了提高表格分类性能，我们提出了一种优化的深度森林（DF）技术，具有更强的表达力。这种技术利用级别结构来构建深度模型，从而提高模型的表达力。然而，这种积极多层学习的方法容易过拟合，导致模型的效果和泛化性受限。为了解决这个问题，我们在这篇论文中提出了一种可学习的层weise数据增强策略，包括了Cut Mix for Tabular data（CMT）增强技术来mitigate过拟合。此外，我们还提出了一种基于人口的搜索算法来调整增强intensity的每层策略。此外，我们还提出了将 intermediate层的输出集成到检查点ensemble中，以确保模型的稳定性。实验结果显示，我们的方法在不同的表格分类任务中设置了新的最佳性能记录（SOTA），超过了树ensemble、深度森林、深度神经网络和AutoML竞争对手。学习的策略也可以有效地传递到 Deep Forest 的变体中，这 подтвержда了其在表格信号处理中的潜在应用。
</details></li>
</ul>
<hr>
<h2 id="Earth-Virtualization-Engines-–-A-Technical-Perspective"><a href="#Earth-Virtualization-Engines-–-A-Technical-Perspective" class="headerlink" title="Earth Virtualization Engines – A Technical Perspective"></a>Earth Virtualization Engines – A Technical Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09002">http://arxiv.org/abs/2309.09002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Torsten Hoefler, Bjorn Stevens, Andreas F. Prein, Johanna Baehr, Thomas Schulthess, Thomas F. Stocker, John Taylor, Daniel Klocke, Pekka Manninen, Piers M. Forster, Tobias Kölling, Nicolas Gruber, Hartwig Anzt, Claudia Frauen, Florian Ziemen, Milan Klöwer, Karthik Kashinath, Christoph Schär, Oliver Fuhrer, Bryan N. Lawrence</li>
<li>for: 提高气候变化应对能力</li>
<li>methods: 结合物理模型和机器学习技术，提高气候预测的准确性、效率和可读性</li>
<li>results: 实现了高分辨率的气候数据访问和分析，为气候变化的研究和应对做出了重要贡献<details>
<summary>Abstract</summary>
Participants of the Berlin Summit on Earth Virtualization Engines (EVEs) discussed ideas and concepts to improve our ability to cope with climate change. EVEs aim to provide interactive and accessible climate simulations and data for a wide range of users. They combine high-resolution physics-based models with machine learning techniques to improve the fidelity, efficiency, and interpretability of climate projections. At their core, EVEs offer a federated data layer that enables simple and fast access to exabyte-sized climate data through simple interfaces. In this article, we summarize the technical challenges and opportunities for developing EVEs, and argue that they are essential for addressing the consequences of climate change.
</details>
<details>
<summary>摘要</summary>
BERLIN峰会上的地球虚拟化引擎（EVEs）参与者们讨论了如何改善对气候变化的应对能力。EVEs旨在提供互动性强、易于访问的气候模拟和数据，为广泛的用户群提供。它们结合高分辨率物理模型和机器学习技术，以提高模拟结果的准确性、效率和可解释性。EVEs的核心是一个联邦数据层，可以通过简单的接口访问数据，并且可以在毫秒级别进行数据交互。本文将讨论EVEs的技术挑战和机遇，并认为它们是Addressing the consequences of climate change的关键工具。
</details></li>
</ul>
<hr>
<h2 id="Deliberative-Context-Aware-Ambient-Intelligence-System-for-Assisted-Living-Homes"><a href="#Deliberative-Context-Aware-Ambient-Intelligence-System-for-Assisted-Living-Homes" class="headerlink" title="Deliberative Context-Aware Ambient Intelligence System for Assisted Living Homes"></a>Deliberative Context-Aware Ambient Intelligence System for Assisted Living Homes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08984">http://arxiv.org/abs/2309.08984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohannad Babli, Jaime A Rincon, Eva Onaindia, Carlos Carrascosa, Vicente Julian</li>
<li>for: 这个论文的目的是提出一种 ambient intelligence 健康应用的决策架构，用于舒缓受抚恤的老年人受到负面情绪的情况下，并在助生活机构中进行实施。</li>
<li>methods: 该架构使用了决策函数，以实现 Context-aware 的人机交互、感知、规划功能、反应性和环境意识等特性。文章还进行了一些实验研究，用以证明方法的效果和有效性。</li>
<li>results: 实验结果表明，提出的决策函数已经成功地实现了其决策目标，并且在 simulate 的助生活机构enario 中得到了有效的结果。<details>
<summary>Abstract</summary>
Monitoring wellbeing and stress is one of the problems covered by ambient intelligence, as stress is a significant cause of human illnesses directly affecting our emotional state. The primary aim was to propose a deliberation architecture for an ambient intelligence healthcare application. The architecture provides a plan for comforting stressed seniors suffering from negative emotions in an assisted living home and executes the plan considering the environment's dynamic nature. Literature was reviewed to identify the convergence between deliberation and ambient intelligence and the latter's latest healthcare trends. A deliberation function was designed to achieve context-aware dynamic human-robot interaction, perception, planning capabilities, reactivity, and context-awareness with regard to the environment. A number of experimental case studies in a simulated assisted living home scenario were conducted to demonstrate the approach's behavior and validity. The proposed methods were validated to show classification accuracy. The validation showed that the deliberation function has effectively achieved its deliberative objectives.
</details>
<details>
<summary>摘要</summary>
监测健康和压力是智能环境技术中一个主要问题，因为压力直接影响我们的情感状态，是人类疾病的直接原因之一。我们的目标是提议一种 ambient intelligence 健康应用的决策建构。这种建构提供了一个计划，用于使用智能环境技术来慰宠受到压力的长者，并在考虑环境的动态特点下执行该计划。我们查看了相关 литераature，以确定决策和智能环境之间的叉合，以及智能环境最新的医疗趋势。我们设计了一种决策函数，以实现 context-aware 的人机交互、感知、规划能力、感应性和对环境的Context-awareness。我们进行了一些在 simulated 助生活场景中的实验案例，以证明方法的行为和有效性。我们验证了提案的方法，并证明了决策函数已经成功完成了它的决策目标。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-In-Browser-Deep-Learning-Inference-on-Diverse-Edge-Clients-through-Just-in-Time-Kernel-Optimizations"><a href="#Accelerating-In-Browser-Deep-Learning-Inference-on-Diverse-Edge-Clients-through-Just-in-Time-Kernel-Optimizations" class="headerlink" title="Accelerating In-Browser Deep Learning Inference on Diverse Edge Clients through Just-in-Time Kernel Optimizations"></a>Accelerating In-Browser Deep Learning Inference on Diverse Edge Clients through Just-in-Time Kernel Optimizations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08978">http://arxiv.org/abs/2309.08978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fucheng Jia, Shiqi Jiang, Ting Cao, Wei Cui, Tianrui Xia, Xu Cao, Yuanchun Li, Deyu Zhang, Ju Ren, Yunxin Liu, Lili Qiu, Mao Yang</li>
<li>for: 这篇论文的目的是提出一个首个在浏览器中进行深度学习（DL）推理的系统，以提高浏览器中DL推理的性能。</li>
<li>methods: 这篇论文使用了两种新的网络编程技术来实现自动生成优化的加速器，包括：Tensor-Web Compiling Co-Design和Web-Specific Lite Kernel Optimization Space Design。这两种技术可以减少加速器生成成本，同时维持或甚至提高性能。</li>
<li>results: 对现代转换器模型进行评估，nn-JIT.web可以在各种客户端设备上实现到8.2倍的加速，包括ARM、Intel、AMD和Nvidia的主流CPUs和GPUs。<details>
<summary>Abstract</summary>
Web applications are increasingly becoming the primary platform for AI service delivery, making in-browser deep learning (DL) inference more prominent. However, current in-browser inference systems fail to effectively utilize advanced web programming techniques and customize kernels for various client devices, leading to suboptimal performance.   To address the issues, this paper presents the first in-browser inference system, nn-JIT.web, which enables just-in-time (JIT) auto-generation of optimized kernels for both CPUs and GPUs during inference. The system achieves this by using two novel web programming techniques that can significantly reduce kernel generation time, compared to other tensor compilers such as TVM, while maintaining or even improving performance. The first technique, Tensor-Web Compiling Co-Design, lowers compiling costs by unifying tensor and web compiling and eliminating redundant and ineffective compiling passes. The second technique, Web-Specific Lite Kernel Optimization Space Design, reduces kernel tuning costs by focusing on web programming requirements and efficient hardware resource utilization, limiting the optimization space to only dozens.   nn-JIT.web is evaluated for modern transformer models on a range of client devices, including the mainstream CPUs and GPUs from ARM, Intel, AMD and Nvidia. Results show that nn-JIT.web can achieve up to 8.2x faster within 30 seconds compared to the baselines across various models.
</details>
<details>
<summary>摘要</summary>
现代浏览器中的 Web 应用程序正在成为人工智能服务的主要平台，使得在浏览器内进行深度学习（DL）推理变得更加重要。然而，当前的浏览器推理系统无法有效利用高级网络编程技术和自定义核心 для各种客户端设备，导致性能下降。为解决这些问题，这篇论文提出了第一个在浏览器内进行推理的系统，即 nn-JIT.web。该系统可以在推理过程中通过实时生成优化的核心，以提高 CPU 和 GPU 的性能。该系统使用了两种新的网络编程技术来减少核心生成时间，相比于其他tensor编译器such as TVM，而无需增加编译成本。第一种技术是tensor-web编译合理化，它将tensor编译和网络编译融合起来，从而减少了无用的编译步骤。第二种技术是网络特定的轻量级核心优化空间设计，它将精力集中在了网络编程需求和高效硬件资源利用上，从而减少了优化空间的范围，只有几十。nn-JIT.web在多种现代转换器模型上进行了测试，包括ARM、Intel、AMD和Nvidia等主流CPU和GPU。结果显示，nn-JIT.web可以在30秒内达到8.2倍的速度提升，与基准值相比。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-Reachability-using-Christoffel-Functions-and-Conformal-Prediction"><a href="#Data-driven-Reachability-using-Christoffel-Functions-and-Conformal-Prediction" class="headerlink" title="Data-driven Reachability using Christoffel Functions and Conformal Prediction"></a>Data-driven Reachability using Christoffel Functions and Conformal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08976">http://arxiv.org/abs/2309.08976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelmouaiz Tebjou, Goran Frehse, Faïcel Chamroukhi</li>
<li>for: 本研究旨在提出一种数据驱动的方法，用于估计动力系统中可达的状态集（reach set），而无需知道系统动力学模型的准确参数。</li>
<li>methods: 本方法基于Christoffel函数的approximation来估计 reach set，并且通过使用数据驱动的方法来提高样本效率和鲁棒性。</li>
<li>results: 本研究显示，使用这种方法可以提高样本效率和鲁棒性，并且可以避免出现在训练集和校准集中的异常样本的影响。<details>
<summary>Abstract</summary>
An important mathematical tool in the analysis of dynamical systems is the approximation of the reach set, i.e., the set of states reachable after a given time from a given initial state. This set is difficult to compute for complex systems even if the system dynamics are known and given by a system of ordinary differential equations with known coefficients. In practice, parameters are often unknown and mathematical models difficult to obtain. Data-based approaches are promised to avoid these difficulties by estimating the reach set based on a sample of states. If a model is available, this training set can be obtained through numerical simulation. In the absence of a model, real-life observations can be used instead. A recently proposed approach for data-based reach set approximation uses Christoffel functions to approximate the reach set. Under certain assumptions, the approximation is guaranteed to converge to the true solution. In this paper, we improve upon these results by notably improving the sample efficiency and relaxing some of the assumptions by exploiting statistical guarantees from conformal prediction with training and calibration sets. In addition, we exploit an incremental way to compute the Christoffel function to avoid the calibration set while maintaining the statistical convergence guarantees. Furthermore, our approach is robust to outliers in the training and calibration set.
</details>
<details>
<summary>摘要</summary>
“一个重要的数学工具在动态系统分析中是精确地计算可达集，即从一个初始状态到一个给定时间后可达的状态集。这个集是复杂系统的情况下难以计算，即使系统动态知道并且以常微分方程表示。实际上，参数通常未知，数学模型难以取得。数据驱动的方法可以避免这些问题，通过基于数据的估计来Estimate the reach set。如果有模型可用，则可以通过数值 simulations obtain training set。在缺乏模型的情况下，则可以使用实际观察。一种最近提出的方法是使用Christoffel函数估计可达集。在某些假设下，这个估计将会趋向真实解。在这篇论文中，我们会提高这些结果，包括提高样本效率和松动一些假设，通过滤节点和训练集的统计保证。此外，我们还会利用增量式计算Christoffel函数，以避免训练集的需求，同时保持统计的测度保证。此外，我们的方法也能够抗抗噪。”
</details></li>
</ul>
<hr>
<h2 id="Multiagent-Reinforcement-Learning-with-an-Attention-Mechanism-for-Improving-Energy-Efficiency-in-LoRa-Networks"><a href="#Multiagent-Reinforcement-Learning-with-an-Attention-Mechanism-for-Improving-Energy-Efficiency-in-LoRa-Networks" class="headerlink" title="Multiagent Reinforcement Learning with an Attention Mechanism for Improving Energy Efficiency in LoRa Networks"></a>Multiagent Reinforcement Learning with an Attention Mechanism for Improving Energy Efficiency in LoRa Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08965">http://arxiv.org/abs/2309.08965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Zhang, Ziqi Lin, Shimin Gong, Bo Gu, Dusit Niyato</li>
<li>for: 该研究旨在提高LoRa网络的能源效率（EE），适用于工业互联网物联网（IIoT）。</li>
<li>methods: 该研究首先提出了一个分析模型来计算LoRa网络的系统EE性能。然后，基于多代理强化学习（MALoRa）算法，对LoRa网络中每个终端设备（ED）的传输参数分配进行优化，以最大化系统EE。</li>
<li>results:  simulation结果表明，相比基eline算法，MALoRa算法可以显著提高LoRa网络的系统EE，但是同时也导致了一定的数据包交换率（PDR）的下降。<details>
<summary>Abstract</summary>
Long Range (LoRa) wireless technology, characterized by low power consumption and a long communication range, is regarded as one of the enabling technologies for the Industrial Internet of Things (IIoT). However, as the network scale increases, the energy efficiency (EE) of LoRa networks decreases sharply due to severe packet collisions. To address this issue, it is essential to appropriately assign transmission parameters such as the spreading factor and transmission power for each end device (ED). However, due to the sporadic traffic and low duty cycle of LoRa networks, evaluating the system EE performance under different parameter settings is time-consuming. Therefore, we first formulate an analytical model to calculate the system EE. On this basis, we propose a transmission parameter allocation algorithm based on multiagent reinforcement learning (MALoRa) with the aim of maximizing the system EE of LoRa networks. Notably, MALoRa employs an attention mechanism to guide each ED to better learn how much ''attention'' should be given to the parameter assignments for relevant EDs when seeking to improve the system EE. Simulation results demonstrate that MALoRa significantly improves the system EE compared with baseline algorithms with an acceptable degradation in packet delivery rate (PDR).
</details>
<details>
<summary>摘要</summary>
长距离无线技术（LoRa）， caracterizada por baja consumición de energía y una comunicación larga distancia, es considerada una de las tecnologías clave para la Internet de las Cosas Industriales (IIoT). Sin embargo, a medida que se incrementa la escala de la red, la eficiencia energética (EE) de las redes LoRa disminuye drásticamente debido a colisiones de paquetes graves. Para abordar este problema, es esencial asignar los parámetros de transmisión, como el factor de spreading y la potencia de transmisión, de manera adecuada para cada dispositivo de end (ED). Sin embargo, debido al tráfico esporádico y baja tasa de actividad de las redes LoRa, evaluar el desempeño de sistema EE bajo diferentes configuraciones de parámetros es un proceso tiempoconsumidor. Por lo tanto, primero formulamos un modelo analítico para calcular el sistema EE. A partir de este modelo, propusimos un algoritmo de asignación de parámetros de transmisión basado en aprendizaje por refuerzo multientidad (MALoRa) con el objetivo de maximizar el sistema EE de las redes LoRa. Destacablemente, MALoRa utiliza un mecanismo de atención para guiar a cada ED en cómo asignar la atención adecuada a las asignaciones de parámetros relevantes para mejorar el sistema EE. Los resultados de la simulación demuestran que MALoRa mejora significativamente el sistema EE en comparación con los algoritmos de referencia con una degradación aceptable en la tasa de entrega de paquetes (PDR).
</details></li>
</ul>
<hr>
<h2 id="Monolingual-or-Multilingual-Instruction-Tuning-Which-Makes-a-Better-Alpaca"><a href="#Monolingual-or-Multilingual-Instruction-Tuning-Which-Makes-a-Better-Alpaca" class="headerlink" title="Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca"></a>Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08958">http://arxiv.org/abs/2309.08958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pinzhen Chen, Shaoxiong Ji, Nikolay Bogoychev, Barry Haddow, Kenneth Heafield</li>
<li>for: 本研究旨在探讨基础大语言模型（LLM）可以如何通过具体的指令微调来开发开放式问答能力，以便应用程序如AI助手等。</li>
<li>methods: 本研究采用了Alpaca数据集和机器翻译对其进行多语言训练数据的组合，然后通过低级别适应和全参数训练来微调LLMs。</li>
<li>results: 研究发现，虽然多语言微调不对英语表现有直接影响，但它对多语言环境下LLM的稳定性至关重要。具有固定预算的情况下，一个多语言指令微调模型，只需在减少数据上进行微调，可以和每种语言单独训练的模型相比。这些发现可以为减少计算资源的情况下扩展语言支持而提供指南。<details>
<summary>Abstract</summary>
Foundational large language models (LLMs) can be instruction-tuned to develop open-ended question-answering capability, facilitating applications such as the creation of AI assistants. While such efforts are often carried out in a single language, building on prior research, we empirically analyze cost-efficient approaches of monolingual and multilingual tuning, shedding light on the efficacy of LLMs in responding to queries across monolingual and multilingual contexts. Our study employs the Alpaca dataset and machine translations of it to form multilingual training data, which is then used to tune LLMs through low-rank adaptation and full-parameter training. Comparisons reveal that multilingual tuning is not crucial for an LLM's English performance, but is key to its robustness in a multilingual environment. With a fixed budget, a multilingual instruction-tuned model, merely trained on downsampled data, can be as powerful as training monolingual models for each language. Our findings serve as a guide for expanding language support through instruction tuning with constrained computational resources.
</details>
<details>
<summary>摘要</summary>
基础大语言模型（LLM）可以通过指令调整来发展开放式问答能力，用于应用程序，如创建人工智能助手。虽然这些努力通常在单语言上进行，基于先前的研究，但我们employs the Alpaca dataset and machine translations of it to form multilingual training data，然后使用低级别适应和全参数训练来调整LLM。对比发现，在多语言环境中，多语言调整对LLM的英语性能并无关系，但对多语言环境的稳定性至关重要。假设有固定预算，一个多语言指令调整模型，只需在减样数据上进行训练，可以与每种语言 separately 训练的模型相当有力。我们的发现可以 serve as a guide for expanding language support through instruction tuning with constrained computational resources。
</details></li>
</ul>
<hr>
<h2 id="Cross-Lingual-Knowledge-Editing-in-Large-Language-Models"><a href="#Cross-Lingual-Knowledge-Editing-in-Large-Language-Models" class="headerlink" title="Cross-Lingual Knowledge Editing in Large Language Models"></a>Cross-Lingual Knowledge Editing in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08952">http://arxiv.org/abs/2309.08952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, Jiarong Xu</li>
<li>for: 本研究旨在 investigate the cross-lingual effect of knowledge editing in natural language processing.</li>
<li>methods: 我们首先收集了一个大规模的 across-lingual synthetic dataset，并对不同知识编辑方法进行了英语编辑。然后，我们对这些编辑后的模型进行了中文评估，并 vice versa。</li>
<li>results: 我们发现了编辑后模型的可靠性、通用性、地域性和可移植性在不同语言之间存在差异。此外，我们还分析了编辑后模型的不一致行为和特定挑战。<details>
<summary>Abstract</summary>
Knowledge editing aims to change language models' performance on several special cases (i.e., editing scope) by infusing the corresponding expected knowledge into them. With the recent advancements in large language models (LLMs), knowledge editing has been shown as a promising technique to adapt LLMs to new knowledge without retraining from scratch. However, most of the previous studies neglect the multi-lingual nature of some main-stream LLMs (e.g., LLaMA, ChatGPT and GPT-4), and typically focus on monolingual scenarios, where LLMs are edited and evaluated in the same language. As a result, it is still unknown the effect of source language editing on a different target language. In this paper, we aim to figure out this cross-lingual effect in knowledge editing. Specifically, we first collect a large-scale cross-lingual synthetic dataset by translating ZsRE from English to Chinese. Then, we conduct English editing on various knowledge editing methods covering different paradigms, and evaluate their performance in Chinese, and vice versa. To give deeper analyses of the cross-lingual effect, the evaluation includes four aspects, i.e., reliability, generality, locality and portability. Furthermore, we analyze the inconsistent behaviors of the edited models and discuss their specific challenges.
</details>
<details>
<summary>摘要</summary>
知识编辑目标是改善语言模型在特定场景（即编辑范围）的表现，通过涂抹相应的预期知识到其中。随着大语言模型（LLM）的发展，知识编辑被证明为一种有希望的技术，可以在不重新训练的情况下，使LML在新的知识上进行适应。然而，大多数先前的研究忽视了主流LLM的多语言特性（例如LLaMA、ChatGPT和GPT-4），通常集中于单语言enario，而不是考虑多语言enario。因此， edit Language Model在不同目标语言下的效果仍然未知。在这篇论文中，我们想要解决这种跨语言效果。specifically，我们首先收集了一个大规模的跨语言合成数据集，将英语ZsRE翻译成中文。然后，我们对不同知识编辑方法进行英语编辑，并在中文和vice versa中进行评估。为了更深入地分析跨语言效果，评估包括四个方面：可靠性、通用性、本地性和可移植性。此外，我们还分析了编辑后模型的不一致行为，并讨论了其特定挑战。
</details></li>
</ul>
<hr>
<h2 id="Universal-Metric-Learning-with-Parameter-Efficient-Transfer-Learning"><a href="#Universal-Metric-Learning-with-Parameter-Efficient-Transfer-Learning" class="headerlink" title="Universal Metric Learning with Parameter-Efficient Transfer Learning"></a>Universal Metric Learning with Parameter-Efficient Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08944">http://arxiv.org/abs/2309.08944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungyeon Kim, Donghyun Kim, Suha Kwak</li>
<li>for: 本文提出了一种新的度量学习方法，即通用度量学习（UML），该方法可以捕捉多个不同分布数据之间的关系。</li>
<li>methods: 本文提出了一种新的度量学习方法，即通用度量学习（UML），该方法包括一个预先固定的模型和两个附加模块：随机适应器和提示池。这些模块可以捕捉 dataset-specific 知识，同时避免倾斜到主导分布的偏见。</li>
<li>results: 本文的实验结果表明，使用 Parametric Universal Metric leArning（PUMA）方法可以在多个不同分布数据上实现更好的性能，并使用约 69 倍 fewer 可变参数。<details>
<summary>Abstract</summary>
A common practice in metric learning is to train and test an embedding model for each dataset. This dataset-specific approach fails to simulate real-world scenarios that involve multiple heterogeneous distributions of data. In this regard, we introduce a novel metric learning paradigm, called Universal Metric Learning (UML), which learns a unified distance metric capable of capturing relations across multiple data distributions. UML presents new challenges, such as imbalanced data distribution and bias towards dominant distributions. To address these challenges, we propose Parameter-efficient Universal Metric leArning (PUMA), which consists of a pre-trained frozen model and two additional modules, stochastic adapter and prompt pool. These modules enable to capture dataset-specific knowledge while avoiding bias towards dominant distributions. Additionally, we compile a new universal metric learning benchmark with a total of 8 different datasets. PUMA outperformed the state-of-the-art dataset-specific models while using about 69 times fewer trainable parameters.
</details>
<details>
<summary>摘要</summary>
通常在 метри学习中，对每个数据集进行特定的模型训练和测试。这种数据集特定的方法无法模拟实际世界中存在多个不同类型数据的场景。为此，我们介绍了一种新的度量学习方法，即通用度量学习（UML），它学习了一个可以捕捉多个数据分布关系的统一距离度量。UML带来了新的挑战，如数据分布偏斜和主导分布的偏袋。为解决这些挑战，我们提出了Parameter-efficient Universal Metric leArning（PUMA），它包括一个预训练的冻结模型和两个附加模块，随机适应器和提示池。这些模块允许捕捉数据集特定的知识，而不是偏袋主导分布。此外，我们编译了一个新的通用度量学习Benchmark，包括8个不同的数据集。PUMA在比较州时表现了与当前最佳数据集特定模型相比，使用了约69倍少的可训练参数。
</details></li>
</ul>
<hr>
<h2 id="An-Unified-Search-and-Recommendation-Foundation-Model-for-Cold-Start-Scenario"><a href="#An-Unified-Search-and-Recommendation-Foundation-Model-for-Cold-Start-Scenario" class="headerlink" title="An Unified Search and Recommendation Foundation Model for Cold-Start Scenario"></a>An Unified Search and Recommendation Foundation Model for Cold-Start Scenario</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08939">http://arxiv.org/abs/2309.08939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, Guannan Zhang</li>
<li>for: 这种 paper 的目的是提出一种基于多个领域的搜索和推荐系统模型，以提高系统的性能和灵活性。</li>
<li>methods: 该 paper 使用了大语言模型（LLM）来提取域无关的文本特征，并使用方面闭合合并来将 ID 特征、域无关文本特征和任务特定的多元稀热特征 merge 到获得查询和 Item 的表示。同时，该 paper 还提出了多个搜索和推荐enario 的适应Multi-task 模块来训练多个领域的基础模型。</li>
<li>results: 该 paper 通过在冷启动场景中使用 pre-train finetune 方式应用 S&amp;R Multi-Domain Foundation 模型，实现了与其他 SOTA 传输学习方法相比较好的性能。此外，S&amp;R Multi-Domain Foundation 模型已经成功应用在阿里巴巴手机应用程序中的内容查询推荐和服务卡推荐等方面。<details>
<summary>Abstract</summary>
In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S\&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S\&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S\&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc.
</details>
<details>
<summary>摘要</summary>
现代商业搜索引擎和推荐系统中，数据来自多个领域可以共同训练多领域模型。传统方法在多任务设定下训练多领域模型，使分享参数学习多任务之间的相似性，而任务特定参数学习多任务之间的差异。随着大语言模型的发展，LLM可以提取全局领域不变的文本特征，用于搜索和推荐任务。我们提出了一种新的框架，即S\&R多领域基础框架，使用LLM提取领域不变特征，并使用方面闭合合并模块将ID特征、领域不变文本特征和任务特有的多样化稀缺特征拼接而成查询和物品的表示。此外，我们在多个搜索和推荐场景中共同训练域 adapted multi-task模块，以获得多领域基础模型。我们在寒冷开始场景中使用预训练- fine-tune方式应用S\&R多领域基础模型，实现了与其他SOTA传输学习方法相比较好的性能。S\&R多领域基础模型已经成功部署在阿里巴巴手机应用程序内的内容查询推荐和服务卡推荐等功能中。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Neural-symbolic-System-under-Statistical-Relational-Learning"><a href="#A-Novel-Neural-symbolic-System-under-Statistical-Relational-Learning" class="headerlink" title="A Novel Neural-symbolic System under Statistical Relational Learning"></a>A Novel Neural-symbolic System under Statistical Relational Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08931">http://arxiv.org/abs/2309.08931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongran Yu, Xueyan Liu, Shirui Pan, Anchen Li, Bo Yang</li>
<li>for: The paper aims to develop a cognitive model that can exhibit human-like intellectual capabilities through neural-symbolic systems, which combine the strengths of deep learning and symbolic reasoning.</li>
<li>methods: The proposed method is a general bi-level probabilistic graphical reasoning framework called GBPGR, which leverages statistical relational learning to effectively integrate deep learning models and symbolic reasoning in a mutually beneficial manner.</li>
<li>results: The approach achieves high performance and exhibits effective generalization in both transductive and inductive tasks, as demonstrated through extensive experiments.Here’s the same information in Simplified Chinese:</li>
<li>for: 本研究旨在通过神经符号系统实现人类智能水平的认知模型。</li>
<li>methods: 提议的方法是一种通用二级概率图解架构（GBPGR），利用统计关系学来有效地结合深度学习模型和符号逻辑。</li>
<li>results: 方法在推uctive和概率任务中具有高性能和有效的泛化能力，经过广泛的实验证明。<details>
<summary>Abstract</summary>
A key objective in field of artificial intelligence is to develop cognitive models that can exhibit human-like intellectual capabilities. One promising approach to achieving this is through neural-symbolic systems, which combine the strengths of deep learning and symbolic reasoning. However, current approaches in this area have been limited in their combining way, generalization and interpretability. To address these limitations, we propose a general bi-level probabilistic graphical reasoning framework called GBPGR. This framework leverages statistical relational learning to effectively integrate deep learning models and symbolic reasoning in a mutually beneficial manner. In GBPGR, the results of symbolic reasoning are utilized to refine and correct the predictions made by the deep learning models. At the same time, the deep learning models assist in enhancing the efficiency of the symbolic reasoning process. Through extensive experiments, we demonstrate that our approach achieves high performance and exhibits effective generalization in both transductive and inductive tasks.
</details>
<details>
<summary>摘要</summary>
“一个关键目标在人工智能领域是开发人工智能模型，能够展现人类智能水平的 cognitive 能力。一种具有推进性的方法是通过神经做数学系统，结合深度学习和符号推理。但现有方法在这个领域有限，导致混合、扩展和解释性不足。为了解决这些限制，我们提出一个通用二级概率 graf 推理框架 called GBPGR。这个框架利用 Statistical Relational Learning 技术，实现深度学习模型和符号推理的共同优化。在 GBPGR 中，符号推理的结果用于修正和改善深度学习模型的预测结果。另一方面，深度学习模型帮助提高符号推理的效率。经过广泛的实验，我们证明了我们的方法在转掌和推理任务中具有高性能和有效扩展。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="DOMAIN-MilDly-COnservative-Model-BAsed-OfflINe-Reinforcement-Learning"><a href="#DOMAIN-MilDly-COnservative-Model-BAsed-OfflINe-Reinforcement-Learning" class="headerlink" title="DOMAIN: MilDly COnservative Model-BAsed OfflINe Reinforcement Learning"></a>DOMAIN: MilDly COnservative Model-BAsed OfflINe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08925">http://arxiv.org/abs/2309.08925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao-Yin Liu, Xiao-Hu Zhou, Xiao-Liang Xie, Shi-Qi Liu, Zhen-Qiu Feng, Hao Li, Mei-Jiang Gui, Tian-Yu Xiang, De-Xing Huang, Zeng-Guang Hou</li>
<li>for: This paper proposes a new model-based reinforcement learning algorithm called DOMAIN to address the problem of distribution shift in offline RL.</li>
<li>methods: The DOMAIN algorithm uses adaptive sampling of model samples to adjust the model data penalty and does not rely on model uncertainty estimation.</li>
<li>results: The paper shows that the DOMAIN algorithm is less conservative than previous model-based offline RL algorithms and achieves better performance than other RL algorithms on tasks that require generalization.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文提出了一种新的基于模型的强化学习算法called DOMAIN，以解决停机shift问题。</li>
<li>methods: DOMAIN算法使用适应样本的模型样本抽象来调整模型数据罚款，不需要模型不确定性估计。</li>
<li>results: 论文表明DOMAIN算法比前一代基于模型的停机RL算法更加保守，并在需要总体化的任务上达到更好的性能。<details>
<summary>Abstract</summary>
Model-based reinforcement learning (RL), which learns environment model from offline dataset and generates more out-of-distribution model data, has become an effective approach to the problem of distribution shift in offline RL. Due to the gap between the learned and actual environment, conservatism should be incorporated into the algorithm to balance accurate offline data and imprecise model data. The conservatism of current algorithms mostly relies on model uncertainty estimation. However, uncertainty estimation is unreliable and leads to poor performance in certain scenarios, and the previous methods ignore differences between the model data, which brings great conservatism. Therefore, this paper proposes a milDly cOnservative Model-bAsed offlINe RL algorithm (DOMAIN) without estimating model uncertainty to address the above issues. DOMAIN introduces adaptive sampling distribution of model samples, which can adaptively adjust the model data penalty. In this paper, we theoretically demonstrate that the Q value learned by the DOMAIN outside the region is a lower bound of the true Q value, the DOMAIN is less conservative than previous model-based offline RL algorithms and has the guarantee of security policy improvement. The results of extensive experiments show that DOMAIN outperforms prior RL algorithms on the D4RL dataset benchmark, and achieves better performance than other RL algorithms on tasks that require generalization.
</details>
<details>
<summary>摘要</summary>
模型基于的再增强学习（RL），从偏置数据集中学习环境模型，并生成更多的不同于实际环境的模型数据，已成为解决偏移 Distribution shift 在线上 RL 中的有效方法。由于模型与实际环境之间的差距，需要在算法中加入保守性来平衡准确的偏置数据和不准确的模型数据。现有算法中的保守性主要基于模型uncertainty 估计。然而，不确定性估计不可靠，导致在某些场景下表现不佳，而之前的方法忽略了模型数据之间的差异，这会带来很大的保守性。因此，这篇论文提出了一种milDly cOnservative Model-bAsed offlINe RL算法（DOMAIN），不需要估计模型uncertainty，以解决上述问题。DOMAIN 引入适应样本分布的模型样本折扣，可以适应性地调整模型数据罚款。在本论文中，我们理论上展示了 DOMAIN 外部区域上学习的 Q 值是真实 Q 值的下界，DOMAIN 比前一代模型基于的offline RL算法更加保守，并且有安全政策改进的 garant。实验结果表明，DOMAIN 在 D4RL 数据集上比前一代 RL 算法表现出色，并在需要总结的任务上达到更好的表现。
</details></li>
</ul>
<hr>
<h2 id="Exploration-of-TPUs-for-AI-Applications"><a href="#Exploration-of-TPUs-for-AI-Applications" class="headerlink" title="Exploration of TPUs for AI Applications"></a>Exploration of TPUs for AI Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08918">http://arxiv.org/abs/2309.08918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diego Sanmartín Carrión, Vera Prohaska</li>
<li>for: 这篇论文主要是关于 tensor processing units (TPU) 的特有硬件加速器，用于深度学习，以及其在边缘计算中的实现。</li>
<li>methods: 论文首先提供了 TPU 的概述，包括神经网络设计、通用架构、编译技术和支持框架。然后进行了云和边缘 TPU 性能对比其他相似架构芯片。</li>
<li>results: 结果显示，TPU 可以在云和边缘计算中提供显著性能提升。同时，论文还提出了在边缘 TPU 上部署更多架构的需求，以及在边缘计算中需要更多robust的比较。<details>
<summary>Abstract</summary>
Tensor Processing Units (TPUs) are specialized hardware accelerators for deep learning developed by Google. This paper explores the performance of TPU with a focus on AI and its implementation in edge computing. It first provides an overview of TPUs, specifically their design in relation to neural networks, their general architecture, compilation techniques and supporting frameworks. Furthermore, we provide a comparative analysis of Cloud and Edge TPU performance against other counterpart chip architectures. It is then discussed how TPUs can be used to speed up AI workloads. The results show that TPUs can provide significant performance improvements both in cloud and edge computing. Additionally, we address the need for further research for the deployment of more architectures in the Edge TPU, as well as the need for the development of more robust comparisons in edge computing.
</details>
<details>
<summary>摘要</summary>
tensor 处理单元 (TPU) 是 Google 开发的特циализирован硬件加速器，用于深度学习。本文通过对 TPU 的性能进行分析，特别是在 AI 和边缘计算中的应用。首先，文章提供了 TPU 的概述，包括神经网络设计、通用架构、编译技术和支持框架。然后，文章进行了云和边缘 TPU 性能的比较分析，与其他相关芯片架构进行比较。最后，文章讨论了如何使用 TPU 加速 AI 工作负荷。结果表明，TPU 可以在云和边缘计算中提供显著性能提升。此外，文章还提出了进一步研究边缘 TPU 部署的需求，以及边缘计算中更加robust的比较开发需求。
</details></li>
</ul>
<hr>
<h2 id="Bidirectional-Graph-GAN-Representing-Brain-Structure-Function-Connections-for-Alzheimer’s-Disease"><a href="#Bidirectional-Graph-GAN-Representing-Brain-Structure-Function-Connections-for-Alzheimer’s-Disease" class="headerlink" title="Bidirectional Graph GAN: Representing Brain Structure-Function Connections for Alzheimer’s Disease"></a>Bidirectional Graph GAN: Representing Brain Structure-Function Connections for Alzheimer’s Disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08916">http://arxiv.org/abs/2309.08916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuqiang Wang, Chen Ding</li>
<li>for: 本研究旨在探讨脑结构和功能之间的关系，以揭示脑病、如阿尔茨海默病（AD）的发生机制。</li>
<li>methods: 本研究提出了一种bidirectional graph生成对抗网络（BGGAN），用于表征脑结构和功能之间的连接。 Specifically,  InnerGCN模块被设计来使生成器使用直接和间接脑区域的特征来学习映射函数。 另外，一个名为Balancer的模块被设计来对生成器和判别器进行平衡优化。</li>
<li>results: 对ADNI数据集进行实验表明，生成的结构连接和功能连接都可以提高识别AD的准确率。此外，基于提出的模型，发现脑结构和功能之间不是一对一的对应关系。脑结构是脑功能的基础，强的结构连接通常 accompanies 强的功能连接。<details>
<summary>Abstract</summary>
The relationship between brain structure and function is critical for revealing the pathogenesis of brain disease, including Alzheimer's disease (AD). However, it is a great challenge to map brain structure-function connections due to various reasons. In this work, a bidirectional graph generative adversarial networks (BGGAN) is proposed to represent brain structure-function connections. Specifically, by designing a module incorporating inner graph convolution network (InnerGCN), the generators of BGGAN can employ features of direct and indirect brain regions to learn the mapping function between structural domain and functional domain. Besides, a new module named Balancer is designed to counterpoise the optimization between generators and discriminators. By introducing the Balancer into BGGAN, both the structural generator and functional generator can not only alleviate the issue of mode collapse but also learn complementarity of structural and functional features. Experimental results using ADNI datasets show that the both the generated structure connections and generated function connections can improve the identification accuracy of AD. More importantly, based the proposed model, it is found that the relationship between brain structure and function is not a complete one-to-one correspondence. Brain structure is the basis of brain function. The strong structural connections are almost accompanied by strong functional connections.
</details>
<details>
<summary>摘要</summary>
《Brain Structure-Function Relationship and Alzheimer's Disease》Introduction: brain structure-function relationship is crucial for understanding the pathogenesis of brain diseases, including Alzheimer's disease (AD). However, mapping brain structure-function connections is a significant challenge due to various reasons. In this work, we propose a bidirectional graph generative adversarial networks (BGGAN) to represent brain structure-function connections.Methodology:1. Inner Graph Convolution Network (InnerGCN): We design a module incorporating InnerGCN to enable the generators of BGGAN to learn the mapping function between structural domain and functional domain using features of direct and indirect brain regions.2. Balancer: To counterpoise the optimization between generators and discriminators, we introduce a new module named Balancer. This module allows both the structural generator and functional generator to alleviate the issue of mode collapse and learn complementarity of structural and functional features.Results:1. Improved identification accuracy of AD: Experimental results using ADNI datasets show that the generated structure connections and functional connections can improve the identification accuracy of AD.2. Relationship between brain structure and function: Based on the proposed model, we found that the relationship between brain structure and function is not a complete one-to-one correspondence. Brain structure is the basis of brain function, and strong structural connections are almost accompanied by strong functional connections.Conclusion:BGGAN provides a novel approach to mapping brain structure-function connections, which can be used to better understand the pathogenesis of brain diseases such as AD. The proposed model highlights the importance of considering both structural and functional features when studying brain function and disease.
</details></li>
</ul>
<hr>
<h2 id="A-Statistical-Turing-Test-for-Generative-Models"><a href="#A-Statistical-Turing-Test-for-Generative-Models" class="headerlink" title="A Statistical Turing Test for Generative Models"></a>A Statistical Turing Test for Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08913">http://arxiv.org/abs/2309.08913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayden Helm, Carey E. Priebe, Weiwei Yang</li>
<li>for: 本研究旨在量化人类和机器生成内容的分布差异，以便评估生成模型是否具备人类化能力。</li>
<li>methods: 本研究使用统计模式识别语言框架，描述当前生成模型的评估方法，并用该框架进行生成模型的评估。</li>
<li>results: 研究发现，当前的生成模型在评估上的表现有所提高，但仍有一定的差异与人类生成内容的分布。<details>
<summary>Abstract</summary>
The emergence of human-like abilities of AI systems for content generation in domains such as text, audio, and vision has prompted the development of classifiers to determine whether content originated from a human or a machine. Implicit in these efforts is an assumption that the generation properties of a human are different from that of the machine. In this work, we provide a framework in the language of statistical pattern recognition that quantifies the difference between the distributions of human and machine-generated content conditioned on an evaluation context. We describe current methods in the context of the framework and demonstrate how to use the framework to evaluate the progression of generative models towards human-like capabilities, among many axes of analysis.
</details>
<details>
<summary>摘要</summary>
人类化能力的AI系统在文本、音频和视觉等领域的内容生成中得到了广泛应用，这导致了判断内容是人类还是机器生成的分类器的发展。这种假设是人类生成的特征和机器生成的特征不同。在这项工作中，我们提供了一个基于统计模式识别语言的框架，以量化人类和机器生成的内容在评估上下文中的分布差异。我们将当前方法与此框架中的方法进行描述，并通过这个框架来评估生成模型在多个轴上的进步，包括人类化能力。
</details></li>
</ul>
<hr>
<h2 id="V2CE-Video-to-Continuous-Events-Simulator"><a href="#V2CE-Video-to-Continuous-Events-Simulator" class="headerlink" title="V2CE: Video to Continuous Events Simulator"></a>V2CE: Video to Continuous Events Simulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08891">http://arxiv.org/abs/2309.08891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongyang Zhang, Shuyang Cui, Kaidong Chai, Haowen Yu, Subhasis Dasgupta, Upal Mahbub, Tauhidur Rahman</li>
<li>for: 本文旨在提出一种基于动态视场传感器（DVS）的视频转事件流转换方法，以提高DVS在计算机视觉任务中的表现。</li>
<li>methods: 本文提出了一种基于多视角的事件流转换方法，并采用了一系列特别设计的损失函数来提高生成的事件VOXEL的质量。此外，本文还提出了一种基于本地动态特征的时间推测策略，以准确地恢复事件时间排序和消除时间层次问题。</li>
<li>results: 根据对量化指标进行严格验证，本文的方法在所有阶段的管道中具有最高精度，可以视为当前最佳实践（SOTA）。<details>
<summary>Abstract</summary>
Dynamic Vision Sensor (DVS)-based solutions have recently garnered significant interest across various computer vision tasks, offering notable benefits in terms of dynamic range, temporal resolution, and inference speed. However, as a relatively nascent vision sensor compared to Active Pixel Sensor (APS) devices such as RGB cameras, DVS suffers from a dearth of ample labeled datasets. Prior efforts to convert APS data into events often grapple with issues such as a considerable domain shift from real events, the absence of quantified validation, and layering problems within the time axis. In this paper, we present a novel method for video-to-events stream conversion from multiple perspectives, considering the specific characteristics of DVS. A series of carefully designed losses helps enhance the quality of generated event voxels significantly. We also propose a novel local dynamic-aware timestamp inference strategy to accurately recover event timestamps from event voxels in a continuous fashion and eliminate the temporal layering problem. Results from rigorous validation through quantified metrics at all stages of the pipeline establish our method unquestionably as the current state-of-the-art (SOTA).
</details>
<details>
<summary>摘要</summary>
dynamically 视场传感器（DVS）基本解决方案在各种计算机视觉任务中受到了广泛的关注，提供了明显的优势，包括动态范围、时间分辨率和推理速度。然而，作为与活动像素感知器（APS）设备，如RGB摄像头相比较新的视觉传感器，DVS受到了充分的标注数据的缺乏问题。先前的尝试将APS数据转换为事件经常遇到问题，如实际事件与模拟事件之间的很大领域转移、缺乏量化验证和时间轴层叠问题。在本文中，我们提出了一种新的视频到事件流转换方法，考虑了DVS的特点。一系列仔细设计的损失函数可以提高生成的事件粒子质量。我们还提出了一种新的本地动态感知时间推断策略，可以准确地从事件粒子中恢复事件时间戳，消除时间轴层叠问题。经过严格的验证，我们的方法在所有阶段的管道中都有明显的优势，无疑成为当前最佳实践（SOTA）。
</details></li>
</ul>
<hr>
<h2 id="GCL-Gradient-Guided-Contrastive-Learning-for-Medical-Image-Segmentation-with-Multi-Perspective-Meta-Labels"><a href="#GCL-Gradient-Guided-Contrastive-Learning-for-Medical-Image-Segmentation-with-Multi-Perspective-Meta-Labels" class="headerlink" title="GCL: Gradient-Guided Contrastive Learning for Medical Image Segmentation with Multi-Perspective Meta Labels"></a>GCL: Gradient-Guided Contrastive Learning for Medical Image Segmentation with Multi-Perspective Meta Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08888">http://arxiv.org/abs/2309.08888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixuan Wu, Jintai Chen, Jiahuan Yan, Yiheng Zhu, Danny Z. Chen, Jian Wu</li>
<li>for: 降低错误标签成本，为医疗影像分类 зада增加效率的方法</li>
<li>methods: 利用Gradient Mitigator方法与Gradient Filter方法，将多种多面 semantics整合为一个单一的高级semantic recognition能力</li>
<li>results: 透过实验证明，新方法GCL可以从有限标签的情况下，学习出有用的医疗影像表示，并且在不同数据集上展现出良好的一致性和普遍性<details>
<summary>Abstract</summary>
Since annotating medical images for segmentation tasks commonly incurs expensive costs, it is highly desirable to design an annotation-efficient method to alleviate the annotation burden. Recently, contrastive learning has exhibited a great potential in learning robust representations to boost downstream tasks with limited labels. In medical imaging scenarios, ready-made meta labels (i.e., specific attribute information of medical images) inherently reveal semantic relationships among images, which have been used to define positive pairs in previous work. However, the multi-perspective semantics revealed by various meta labels are usually incompatible and can incur intractable "semantic contradiction" when combining different meta labels. In this paper, we tackle the issue of "semantic contradiction" in a gradient-guided manner using our proposed Gradient Mitigator method, which systematically unifies multi-perspective meta labels to enable a pre-trained model to attain a better high-level semantic recognition ability. Moreover, we emphasize that the fine-grained discrimination ability is vital for segmentation-oriented pre-training, and develop a novel method called Gradient Filter to dynamically screen pixel pairs with the most discriminating power based on the magnitude of gradients. Comprehensive experiments on four medical image segmentation datasets verify that our new method GCL: (1) learns informative image representations and considerably boosts segmentation performance with limited labels, and (2) shows promising generalizability on out-of-distribution datasets.
</details>
<details>
<summary>摘要</summary>
自带笔迹标注医疗图像分割任务的成本高昂，因此极其感到需要设计一种笔迹效率的方法，以减轻笔迹负担。近年来，对比学习表现出了巨大的潜力，可以通过有限的标签来提高后续任务的性能。在医疗图像场景中，已有的meta标签（即医疗图像特征信息）自然地暴露了图像之间的semantic关系，这些meta标签在过去的工作中已经被用来定义正例对。然而，医疗图像场景中的多个meta标签之间的semantic关系通常是不兼容的，这会导致"semantic contradiction"现象，从而使得组合不同meta标签的"semantic contradiction"变得不可持续。在这篇论文中，我们解决了"semantic contradiction"问题，我们提出了一种 Gradient Mitigator 方法，该方法可以系统地统一多个视角的 meta标签，使得预训练模型能够更好地捕捉高级别semantic认知能力。此外，我们强调了分割预训练中的细腻分辨率的重要性，我们开发了一种 Gradient Filter 方法，该方法可以根据梯度的大小来动态屏蔽图像对的最有分辨力的像素对。我们在四个医疗图像分割数据集进行了广泛的实验，结果表明，我们的新方法 GCL 可以：（1）学习有用的图像表示，对有限标签进行分割任务进行明显的提升，以及（2）在不同数据集上表现出良好的普适性。
</details></li>
</ul>
<hr>
<h2 id="Solving-Satisfiability-Modulo-Counting-for-Symbolic-and-Statistical-AI-Integration-With-Provable-Guarantees"><a href="#Solving-Satisfiability-Modulo-Counting-for-Symbolic-and-Statistical-AI-Integration-With-Provable-Guarantees" class="headerlink" title="Solving Satisfiability Modulo Counting for Symbolic and Statistical AI Integration With Provable Guarantees"></a>Solving Satisfiability Modulo Counting for Symbolic and Statistical AI Integration With Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08883">http://arxiv.org/abs/2309.08883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinzhao Li, Nan Jiang, Yexiang Xue</li>
<li>for: 这篇论文主要是解决 Symbolic Artificial Intelligence 和 Statistical Artificial Intelligence 的交叉问题，即 Satisfiability Modulo Counting (SMC) 问题。</li>
<li>methods: 该论文提出了一种基于 NP-oracle 的多项式算法 XOR-SMC，可以解决高度NP-完全的 SMC 问题，并提供了常量近似保证。 XOR-SMC 将 SMC 问题转化为满足随机 XOR 约束的 SAT 方程问题。</li>
<li>results:  experiments 表明，XOR-SMC 能够在解决重要的 SMC 问题时，与基线相比，提供更好的近似解决方案，并且其近似精度较高。<details>
<summary>Abstract</summary>
Satisfiability Modulo Counting (SMC) encompasses problems that require both symbolic decision-making and statistical reasoning. Its general formulation captures many real-world problems at the intersection of symbolic and statistical Artificial Intelligence. SMC searches for policy interventions to control probabilistic outcomes. Solving SMC is challenging because of its highly intractable nature($\text{NP}^{\text{PP}$-complete), incorporating statistical inference and symbolic reasoning. Previous research on SMC solving lacks provable guarantees and/or suffers from sub-optimal empirical performance, especially when combinatorial constraints are present. We propose XOR-SMC, a polynomial algorithm with access to NP-oracles, to solve highly intractable SMC problems with constant approximation guarantees. XOR-SMC transforms the highly intractable SMC into satisfiability problems, by replacing the model counting in SMC with SAT formulae subject to randomized XOR constraints. Experiments on solving important SMC problems in AI for social good demonstrate that XOR-SMC finds solutions close to the true optimum, outperforming several baselines which struggle to find good approximations for the intractable model counting in SMC.
</details>
<details>
<summary>摘要</summary>
满足性模ulo counting（SMC）包括问题需要 Both symbolic decision-making 和统计学推理。 Its general formulation capture 了许多实际世界问题的交叉点，位于符号AI和统计AI之间。 SMC寻找策略性的输入，以控制 probabilistic outcomes。解决 SMC 是困难的，因为它具有非常困难的性质（NP 完全），包括统计推理和符号推理。 Previous research on SMC solving 缺乏可证明的保证和/或具有不佳的实际性能，特别是在存在 combinatorial constraints 时。 We propose XOR-SMC，一种可 polynomials 算法，使用 NP-oracles，解决高度困难的 SMC 问题，并提供常量approximation guarantees。 XOR-SMC 将高度困难的 SMC 转换成满足性问题，通过将 SMC 中的模型计数换成 SAT 方程Subject to randomized XOR 约束。实验表明，XOR-SMC 能够在解决重要的 SMC 问题中，提供近似 true optimum 的解决方案，超越了许多基准值，它们在 intractable model counting 中的 SMC 中寻找具有好的approximation 的解决方案。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-4-with-Code-Interpreter-can-be-used-to-solve-introductory-college-level-vector-calculus-and-electromagnetism-problems"><a href="#ChatGPT-4-with-Code-Interpreter-can-be-used-to-solve-introductory-college-level-vector-calculus-and-electromagnetism-problems" class="headerlink" title="ChatGPT-4 with Code Interpreter can be used to solve introductory college-level vector calculus and electromagnetism problems"></a>ChatGPT-4 with Code Interpreter can be used to solve introductory college-level vector calculus and electromagnetism problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08881">http://arxiv.org/abs/2309.08881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanuj Kumar, Mikhail A. Kats</li>
<li>for: 这个论文是为了测试 chatGPT 3.5、4、4 with Code Interpreter 在大学二年级电工和电磁学问题上的性能。</li>
<li>methods: 作者使用了一组13个问题，并使用了不同的 chatGPT 实例来解决这些问题多次。</li>
<li>results: 结果显示，使用 Code Interpreter 的 chatGPT 4 可以成功解决大多数问题，而不使用 Code Interpreter 的 chatGPT 3.5 和 chatGPT 4 的性能较差。<details>
<summary>Abstract</summary>
We evaluated ChatGPT 3.5, 4, and 4 with Code Interpreter on a set of college-level engineering-math and electromagnetism problems, such as those often given to sophomore electrical engineering majors. We selected a set of 13 problems, and had ChatGPT solve them multiple times, using a fresh instance (chat) each time. We found that ChatGPT-4 with Code Interpreter was able to satisfactorily solve most problems we tested most of the time -- a major improvement over the performance of ChatGPT-4 (or 3.5) without Code Interpreter. The performance of ChatGPT was observed to be somewhat stochastic, and we found that solving the same problem N times in new ChatGPT instances and taking the most-common answer was an effective strategy. Based on our findings and observations, we provide some recommendations for instructors and students of classes at this level.
</details>
<details>
<summary>摘要</summary>
我们对 chatGPT 3.5、4 和 4 进行了测试，使用 college-level 工程学和电磁学问题，类似于第二年电机工程学生常 receives 的问题。我们选择了 13 个问题，让 chatGPT 多次解决这些问题，每次使用新的 chat 实例。我们发现，在使用 Code Interpreter 的情况下，chatGPT 4 能够大幅提高解决这些问题的能力，比不使用 Code Interpreter 的情况下要好。chatGPT 的性能被观察到有一定的随机性，我们发现，对同一个问题多次解决，并取得最常见的答案是一个有效的策略。根据我们的发现和观察，我们对教师和学生提供了一些建议。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-H-infinity-Control-with-a-Real-Time-and-Efficient-Reinforcement-Learning-Algorithm-An-Application-to-Autonomous-Mobility-on-Demand-Systems"><a href="#Data-Driven-H-infinity-Control-with-a-Real-Time-and-Efficient-Reinforcement-Learning-Algorithm-An-Application-to-Autonomous-Mobility-on-Demand-Systems" class="headerlink" title="Data-Driven H-infinity Control with a Real-Time and Efficient Reinforcement Learning Algorithm: An Application to Autonomous Mobility-on-Demand Systems"></a>Data-Driven H-infinity Control with a Real-Time and Efficient Reinforcement Learning Algorithm: An Application to Autonomous Mobility-on-Demand Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08880">http://arxiv.org/abs/2309.08880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Aalipour, Alireza Khani</li>
<li>for: 这篇论文旨在开发一个基于Q学习的无模型实时控制算法，用于解决线性碎时系统的H$_{\infty}$控制问题。</li>
<li>methods: 提议的算法使用了Q学习方法，并且在线性碎时系统中实现了实时和数据效率的控制。computational complexity降低至$\mathcal{O}(\underline{q}^2)$，比Literature中的$\mathcal{O}(\underline{q}^3)$更低。</li>
<li>results: 实验研究显示，提议的算法可以实现实时和数据效率的控制，并且不需要初始稳定政策。在一个实际应用中，将提议的算法应用到了一个自主移动需求系统中，并且得到了良好的效果。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) is a class of artificial intelligence algorithms being used to design adaptive optimal controllers through online learning. This paper presents a model-free, real-time, data-efficient Q-learning-based algorithm to solve the H$_{\infty}$ control of linear discrete-time systems. The computational complexity is shown to reduce from $\mathcal{O}(\underline{q}^3)$ in the literature to $\mathcal{O}(\underline{q}^2)$ in the proposed algorithm, where $\underline{q}$ is quadratic in the sum of the size of state variables, control inputs, and disturbance. An adaptive optimal controller is designed and the parameters of the action and critic networks are learned online without the knowledge of the system dynamics, making the proposed algorithm completely model-free. Also, a sufficient probing noise is only needed in the first iteration and does not affect the proposed algorithm. With no need for an initial stabilizing policy, the algorithm converges to the closed-form solution obtained by solving the Riccati equation. A simulation study is performed by applying the proposed algorithm to real-time control of an autonomous mobility-on-demand (AMoD) system for a real-world case study to evaluate the effectiveness of the proposed algorithm.
</details>
<details>
<summary>摘要</summary>
“强化学习（RL）是一类人工智能算法，用于设计适应最佳控制器通过在线学习。本文提出了一种无模型、实时、数据有效的Q学习基于算法，用于解决线性时间隔系统的H$_{\infty}$控制问题。在文章中，我们显示了计算复杂性从$\mathcal{O}(\underline{q}^3)$降低到$\mathcal{O}(\underline{q}^2)$，其中$\underline{q}$是状态变量、控制输入和干扰的总和的二次函数。我们实现了无模型的优化控制器，并在线学习行为和评价网络的参数，不需要系统动力学模型的知识，因此完全无模型。此外，我们只需在第一轮执行充分的探测噪声，并不影响提议算法。无需初始稳定策略，算法可以到达由解决里氏方程得到的闭合形解。我们对实时控制一个真实的自动化移动需求系统进行了一个实验研究，以评估提议算法的有效性。”Note: "Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="PDFTriage-Question-Answering-over-Long-Structured-Documents"><a href="#PDFTriage-Question-Answering-over-Long-Structured-Documents" class="headerlink" title="PDFTriage: Question Answering over Long, Structured Documents"></a>PDFTriage: Question Answering over Long, Structured Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08872">http://arxiv.org/abs/2309.08872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jon Saad-Falcon, Joe Barrow, Alexa Siu, Ani Nenkova, Ryan A. Rossi, Franck Dernoncourt</li>
<li>for: 本研究旨在解决大语言模型（LLM）在文档问答（QA）中遇到的问题，即当文档不能适应LLM的小上下文长度时。</li>
<li>methods: 本研究提议一种名为PDFTriage的方法，可以基于结构或内容来检索文档上下文。</li>
<li>results: 我们的实验显示，使用PDFTriage可以在多种问题类型中提高文档QA的效果，而现有的检索-加以LLM则失败。此外，我们还发布了一个包含80个结构化文档和900多个人工生成的问题的数据集，以便进一步研究这一基本问题。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have issues with document question answering (QA) in situations where the document is unable to fit in the small context length of an LLM. To overcome this issue, most existing works focus on retrieving the relevant context from the document, representing them as plain text. However, documents such as PDFs, web pages, and presentations are naturally structured with different pages, tables, sections, and so on. Representing such structured documents as plain text is incongruous with the user's mental model of these documents with rich structure. When a system has to query the document for context, this incongruity is brought to the fore, and seemingly trivial questions can trip up the QA system. To bridge this fundamental gap in handling structured documents, we propose an approach called PDFTriage that enables models to retrieve the context based on either structure or content. Our experiments demonstrate the effectiveness of the proposed PDFTriage-augmented models across several classes of questions where existing retrieval-augmented LLMs fail. To facilitate further research on this fundamental problem, we release our benchmark dataset consisting of 900+ human-generated questions over 80 structured documents from 10 different categories of question types for document QA.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MHLAT-Multi-hop-Label-wise-Attention-Model-for-Automatic-ICD-Coding"><a href="#MHLAT-Multi-hop-Label-wise-Attention-Model-for-Automatic-ICD-Coding" class="headerlink" title="MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding"></a>MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08868">http://arxiv.org/abs/2309.08868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwen Duan, Han Jiang, Ying Yu</li>
<li>for: 医疗记录编码（ICD编码）任务是将医疗记录中的病理诊断代码分配给临床病理诊断。</li>
<li>methods: 我们提出了一种简单 yet effective 的模型，即 Multi-Hop Label-wise ATtention（MHLAT），其中使用多步标签层权重来获得更精准和有用的表示。</li>
<li>results: 我们在三个 MIMIC 数据集上进行了广泛的实验，并证明了我们的方法在七个指标中具有显著更好或竞争性表现，并且具有更少的参数优化。<details>
<summary>Abstract</summary>
International Classification of Diseases (ICD) coding is the task of assigning ICD diagnosis codes to clinical notes. This can be challenging given the large quantity of labels (nearly 9,000) and lengthy texts (up to 8,000 tokens). However, unlike the single-pass reading process in previous works, humans tend to read the text and label definitions again to get more confident answers. Moreover, although pretrained language models have been used to address these problems, they suffer from huge memory usage. To address the above problems, we propose a simple but effective model called the Multi-Hop Label-wise ATtention (MHLAT), in which multi-hop label-wise attention is deployed to get more precise and informative representations. Extensive experiments on three benchmark MIMIC datasets indicate that our method achieves significantly better or competitive performance on all seven metrics, with much fewer parameters to optimize.
</details>
<details>
<summary>摘要</summary>
国际疾病分类 (ICD) 编码是将临床笔记中的 ICD 诊断代码赋予的任务。这可能是由于大量的标签（约9,000）和长文本（达8,000个token）所带来的挑战。然而，与之前的单一扫描过程不同，人类通常会重读文本和标签定义以获取更加自信的答案。此外，尽管已使用预训练语言模型来解决这些问题，但它们受到巨大的内存使用带来问题。为解决上述问题，我们提议一种简单 yet 有效的模型，称为多跳标签wise ATtention (MHLAT)，其中多跳标签wise ATtention 被部署以获取更加精确和有用的表示。我们在三个 MIMIC 数据集上进行了广泛的实验，结果显示，我们的方法在七个指标中均达到了显著更好或竞争性的性能，而且具有许多参数优化的多少。
</details></li>
</ul>
<hr>
<h2 id="Trajectory-Tracking-Control-of-Skid-Steering-Mobile-Robots-with-Slip-and-Skid-Compensation-using-Sliding-Mode-Control-and-Deep-Learning"><a href="#Trajectory-Tracking-Control-of-Skid-Steering-Mobile-Robots-with-Slip-and-Skid-Compensation-using-Sliding-Mode-Control-and-Deep-Learning" class="headerlink" title="Trajectory Tracking Control of Skid-Steering Mobile Robots with Slip and Skid Compensation using Sliding-Mode Control and Deep Learning"></a>Trajectory Tracking Control of Skid-Steering Mobile Robots with Slip and Skid Compensation using Sliding-Mode Control and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08863">http://arxiv.org/abs/2309.08863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Payam Nourizadeh, Fiona J Stevens McFadden, Will N Browne</li>
<li>For: 这篇研究旨在提供一种可行的线上运行于开放环境中的游戏机器人运行控制系统，以减少游戏机器人在不可预测的环境中的追踪错误。* Methods: 本研究使用陡缓度控制技术设计了一个可靠的轨迹追踪系统，并将两个先前开发的深度学习模型 [1], [2] 组合到控制反馈循环中，以实时估算游戏机器人的滑行和不适合的滑行，并将补偿值传递到补偿器中。* Results: 实验结果显示，提案的控制器与补偿器可以将轨迹追踪系统的表现提高超过27%。<details>
<summary>Abstract</summary>
Slip and skid compensation is crucial for mobile robots' navigation in outdoor environments and uneven terrains. In addition to the general slipping and skidding hazards for mobile robots in outdoor environments, slip and skid cause uncertainty for the trajectory tracking system and put the validity of stability analysis at risk. Despite research in this field, having a real-world feasible online slip and skid compensation is still challenging due to the complexity of wheel-terrain interaction in outdoor environments. This paper presents a novel trajectory tracking technique with real-world feasible online slip and skid compensation at the vehicle-level for skid-steering mobile robots in outdoor environments. The sliding mode control technique is utilized to design a robust trajectory tracking system to be able to consider the parameter uncertainty of this type of robot. Two previously developed deep learning models [1], [2] are integrated into the control feedback loop to estimate the robot's slipping and undesired skidding and feed the compensator in a real-time manner. The main advantages of the proposed technique are (1) considering two slip-related parameters rather than the conventional three slip parameters at the wheel-level, and (2) having an online real-world feasible slip and skid compensator to be able to reduce the tracking errors in unforeseen environments. The experimental results show that the proposed controller with the slip and skid compensator improves the performance of the trajectory tracking system by more than 27%.
</details>
<details>
<summary>摘要</summary>
滑动和滑倒补偿是移动机器人在户外环境中的导航关键，它们会导致轨迹追踪系统的不确定性和稳定分析的风险。尽管在这一领域进行了大量研究，但实现在线可行的滑动和滑倒补偿仍然是一个挑战，因为轮胎与地面的互动在户外环境中非常复杂。这篇论文提出了一种新的轨迹追踪技术，使用滑模控制技术设计一个可靠的轨迹追踪系统，并将两个先前开发的深度学习模型[1]、[2]integrated into the control feedback loop来估计机器人的滑动和不良滑倒，并在实时 manner中将其传递给补偿器。该技术的主要优点包括：一、考虑了机器人的两个滑动参数而不是传统的三个滑动参数，二、在实时可行的情况下实现了滑动和滑倒的补偿，从而降低了轨迹追踪系统的跟踪错误。实验结果显示，提案的控制器与滑动和滑倒补偿器可以提高轨迹追踪系统的性能，比例超过27%。
</details></li>
</ul>
<hr>
<h2 id="Emerging-Approaches-for-THz-Array-Imaging-A-Tutorial-Review-and-Software-Tool"><a href="#Emerging-Approaches-for-THz-Array-Imaging-A-Tutorial-Review-and-Software-Tool" class="headerlink" title="Emerging Approaches for THz Array Imaging: A Tutorial Review and Software Tool"></a>Emerging Approaches for THz Array Imaging: A Tutorial Review and Software Tool</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08844">http://arxiv.org/abs/2309.08844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josiah W. Smith, Murat Torlak</li>
<li>for: 该文章主要是为了介绍在近场TERAHertz频率域中的THzSynthetic Aperture Radar（SAR）系统和算法。</li>
<li>methods: 该文章提出了一种组合信号处理和机器学习技术的新算法，以及一些传统的CLASSICAL和数据驱动的THz SAR算法，包括物体检测和SAR图像超分辨。</li>
<li>results: 该文章提出了一些Future研究方向，包括系统和算法标准化测试、采用当前最佳的深度学习技术、信号处理优化机器学习算法和гибридного数据驱动信号处理算法。<details>
<summary>Abstract</summary>
Accelerated by the increasing attention drawn by 5G, 6G, and Internet of Things applications, communication and sensing technologies have rapidly evolved from millimeter-wave (mmWave) to terahertz (THz) in recent years. Enabled by significant advancements in electromagnetic (EM) hardware, mmWave and THz frequency regimes spanning 30 GHz to 300 GHz and 300 GHz to 3000 GHz, respectively, can be employed for a host of applications. The main feature of THz systems is high-bandwidth transmission, enabling ultra-high-resolution imaging and high-throughput communications; however, challenges in both the hardware and algorithmic arenas remain for the ubiquitous adoption of THz technology. Spectra comprising mmWave and THz frequencies are well-suited for synthetic aperture radar (SAR) imaging at sub-millimeter resolutions for a wide spectrum of tasks like material characterization and nondestructive testing (NDT). This article provides a tutorial review of systems and algorithms for THz SAR in the near-field with an emphasis on emerging algorithms that combine signal processing and machine learning techniques. As part of this study, an overview of classical and data-driven THz SAR algorithms is provided, focusing on object detection for security applications and SAR image super-resolution. We also discuss relevant issues, challenges, and future research directions for emerging algorithms and THz SAR, including standardization of system and algorithm benchmarking, adoption of state-of-the-art deep learning techniques, signal processing-optimized machine learning, and hybrid data-driven signal processing algorithms...
</details>
<details>
<summary>摘要</summary>
带动了5G、6G和物联网应用的增加关注，通信和感测技术在最近几年内快速发展从毫米波（mmWave）频率范围到tera响（THz）。通过电romagnetic（EM）硬件的重要进步，mmWave和THz频率范围分别是30GHz至300GHz和300GHz至3000GHz可以用于多种应用。THz系统的主要特点是高频带宽传输，使得超高分辨率成像和高速通信 possible;但是，硬件和算法领域中的挑战还需要解决才能广泛采用THz技术。包括mmWave和THz频率的spectrum适用于sub-millimeter分辨率的Synthetic Aperture Radar（SAR）成像，用于各种任务，如材料Characterization和非 destruктив测试（NDT）。本文提供了关于THz SAR的 tutorials review，强调emerging算法的发展，包括Signal Processing和机器学习技术的结合。本文还提供了经典和数据驱动THz SAR算法的概述，专注于安全应用中的对象探测。此外，我们还讨论了相关的问题、挑战和未来研究方向，包括系统和算法标准化、采用当前最佳的深度学习技术、Signal Processing优化的机器学习算法和混合数据驱动Signal Processing算法。
</details></li>
</ul>
<hr>
<h2 id="Bias-and-Fairness-in-Chatbots-An-Overview"><a href="#Bias-and-Fairness-in-Chatbots-An-Overview" class="headerlink" title="Bias and Fairness in Chatbots: An Overview"></a>Bias and Fairness in Chatbots: An Overview</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08836">http://arxiv.org/abs/2309.08836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jintang Xue, Yun-Cheng Wang, Chengwei Wei, Xiaofeng Liu, Jonghye Woo, C. -C. Jay Kuo</li>
<li>for: 本研究旨在提供一份对聊天机器人系统偏见和公平性的全面综述，以帮助开发者更好地设计和实现公平和无偏见的聊天机器人系统。</li>
<li>methods: 本研究使用了大量的文献综述和分析方法，检视了聊天机器人系统的历史和类别，分析了偏见的来源和应用中的可能的危害，并考虑了设计公平和无偏见的聊天机器人系统的因素。</li>
<li>results: 本研究结果表明，现代聊天机器人系统具有更高的功能和应用前景，但也存在偏见和公平性的担忧。通过分析偏见的来源和应用中的影响，以及考虑设计公平和无偏见的因素，可以更好地设计和实现公平和无偏见的聊天机器人系统。<details>
<summary>Abstract</summary>
Chatbots have been studied for more than half a century. With the rapid development of natural language processing (NLP) technologies in recent years, chatbots using large language models (LLMs) have received much attention nowadays. Compared with traditional ones, modern chatbots are more powerful and have been used in real-world applications. There are however, bias and fairness concerns in modern chatbot design. Due to the huge amounts of training data, extremely large model sizes, and lack of interpretability, bias mitigation and fairness preservation of modern chatbots are challenging. Thus, a comprehensive overview on bias and fairness in chatbot systems is given in this paper. The history of chatbots and their categories are first reviewed. Then, bias sources and potential harms in applications are analyzed. Considerations in designing fair and unbiased chatbot systems are examined. Finally, future research directions are discussed.
</details>
<details>
<summary>摘要</summary>
chatbots 已经被研究了 более than half a century。随着自然语言处理（NLP）技术的快速发展，使用大型语言模型（LLMs）的 chatbots 在最近几年收到了很多关注。相比传统的 chatbots，现代 chatbots 更加强大，已经在实际应用中使用。然而，现代 chatbots 中存在偏见和公平问题。由于庞大的训练数据、极大的模型大小和解释性的缺失，现代 chatbots 的偏见缓和和公平保持是挑战。这个论文提供了对偏见和公平问题在 chatbot 系统中的全面回顾。首先，摘要了 chatbots 的历史和类别。然后，分析了偏见的来源和应用中的潜在危害。考虑了设计公平和不偏见 chatbot 系统的因素。最后，讨论了未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="SLIDE-Reference-free-Evaluation-for-Machine-Translation-using-a-Sliding-Document-Window"><a href="#SLIDE-Reference-free-Evaluation-for-Machine-Translation-using-a-Sliding-Document-Window" class="headerlink" title="SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window"></a>SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08832">http://arxiv.org/abs/2309.08832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vikas Raunak, Tom Kocmi, Matt Post</li>
<li>for: 这篇论文是关于语义评估的研究，旨在检验文档中的句子上是否可以提供同样的信息，如同人工参考。</li>
<li>methods: 这篇论文使用了一个新的评估指标，即SLIDE（SLiding Document Evaluator），它在文档中的块 Sentence 上使用了一个滑动窗口，将每个块传递给一个未修改的、市场上可得的质量评估模型进行评估。</li>
<li>results: 研究发现，SLIDE 可以达到高级系统精度，在某些情况下，甚至可以与人工参考 metric 减少差距。这表明，文档中的源Context 可以提供同样的信息，如同人工参考。<details>
<summary>Abstract</summary>
Reference-based metrics that operate at the sentence level typically outperform quality estimation metrics, which have access only to the source and system output. This is unsurprising, since references resolve ambiguities that may be present in the source. We investigate whether additional source context can effectively substitute for a reference. We present a metric, SLIDE (SLiding Document Evaluator), which operates on blocks of sentences using a window that slides over each document in the test set, feeding each chunk into an unmodified, off-the-shelf quality estimation model. We find that SLIDE obtains significantly higher pairwise system accuracy than its sentence-level baseline, in some cases even eliminating the gap with reference-base metrics. This suggests that source context may provide the same information as a human reference.
</details>
<details>
<summary>摘要</summary>
通常情况下，参考基于的度量器在句子水平上表现比质量估计度量器更好，这不奇怪，因为参考可以解决源文本中的歧义。我们研究了 Whether additional source context can effectively substitute for a reference. We present a metric, SLIDE (SLiding Document Evaluator), which operates on blocks of sentences using a window that slides over each document in the test set, feeding each chunk into an unmodified, off-the-shelf quality estimation model. We find that SLIDE obtains significantly higher pairwise system accuracy than its sentence-level baseline, in some cases even eliminating the gap with reference-based metrics. This suggests that source context may provide the same information as a human reference.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="S3-DST-Structured-Open-Domain-Dialogue-Segmentation-and-State-Tracking-in-the-Era-of-LLMs"><a href="#S3-DST-Structured-Open-Domain-Dialogue-Segmentation-and-State-Tracking-in-the-Era-of-LLMs" class="headerlink" title="S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs"></a>S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08827">http://arxiv.org/abs/2309.08827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarkar Snigdha Sarathi Das, Chirag Shah, Mengting Wan, Jennifer Neville, Longqi Yang, Reid Andersen, Georg Buscher, Tara Safavi</li>
<li>for: 提高open-domain对话系统中 Dialogue State Tracking（DST）的精度和 robustness，以适应大语言模型（LLM）驱动的对话系统中的复杂性和多样性。</li>
<li>methods: 提出了一种joint dialogue segmentation和state tracking的方法，使用Pre-Analytical Recollection机制来改进长期上下文跟踪。</li>
<li>results: 在一个Proprietary anonymous open-domain对话数据集以及公共可用的DST和分割数据集上进行了评估，与现状态的最佳方法进行比较，结果表明S3-DST在joint segmentation和state tracking中具有强大和稳定的性能。<details>
<summary>Abstract</summary>
The traditional Dialogue State Tracking (DST) problem aims to track user preferences and intents in user-agent conversations. While sufficient for task-oriented dialogue systems supporting narrow domain applications, the advent of Large Language Model (LLM)-based chat systems has introduced many real-world intricacies in open-domain dialogues. These intricacies manifest in the form of increased complexity in contextual interactions, extended dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts. To handle these intricacies arising from evolving LLM-based chat systems, we propose joint dialogue segmentation and state tracking per segment in open-domain dialogue systems. Assuming a zero-shot setting appropriate to a true open-domain dialogue system, we propose S3-DST, a structured prompting technique that harnesses Pre-Analytical Recollection, a novel grounding mechanism we designed for improving long context tracking. To demonstrate the efficacy of our proposed approach in joint segmentation and state tracking, we evaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as well as publicly available DST and segmentation datasets. Across all datasets and settings, S3-DST consistently outperforms the state-of-the-art, demonstrating its potency and robustness the next generation of LLM-based chat systems.
</details>
<details>
<summary>摘要</summary>
traditional Dialogue State Tracking (DST) problem aims to track user preferences and intents in user-agent conversations. While sufficient for task-oriented dialogue systems supporting narrow domain applications, the advent of Large Language Model (LLM)-based chat systems has introduced many real-world intricacies in open-domain dialogues. These intricacies manifest in the form of increased complexity in contextual interactions, extended dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts. To handle these intricacies arising from evolving LLM-based chat systems, we propose joint dialogue segmentation and state tracking per segment in open-domain dialogue systems. Assuming a zero-shot setting appropriate to a true open-domain dialogue system, we propose S3-DST, a structured prompting technique that harnesses Pre-Analytical Recollection, a novel grounding mechanism we designed for improving long context tracking. To demonstrate the efficacy of our proposed approach in joint segmentation and state tracking, we evaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as well as publicly available DST and segmentation datasets. Across all datasets and settings, S3-DST consistently outperforms the state-of-the-art, demonstrating its potency and robustness for the next generation of LLM-based chat systems.Here's the breakdown of the translation:* "traditional Dialogue State Tracking (DST) problem" becomes "传统的对话状态追踪问题" (traditional DST problem)* "aims to track user preferences and intents in user-agent conversations" becomes "目标是跟踪用户首选和意图在用户代理对话中" (targets tracking user preferences and intents in user-agent conversations)* "While sufficient for task-oriented dialogue systems supporting narrow domain applications" becomes "然而对于支持窄领域应用的任务导向对话系统来说， sufficient" (However, for task-oriented dialogue systems supporting narrow domain applications, sufficient)* "the advent of Large Language Model (LLM)-based chat systems has introduced many real-world intricacies in open-domain dialogues" becomes "LLM基于对话系统的出现引入了许多实际世界中的复杂性，在开放领域对话中" (The advent of LLM-based chat systems has introduced many complexities in open-domain dialogues)* "These intricacies manifest in the form of increased complexity in contextual interactions, extended dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts" becomes "这些复杂性表现为对话中的增加复杂性，更长的对话会话，涵盖更多的话题，以及更频繁的上下文转换" (These complexities manifest as increased complexity in contextual interactions, longer dialogue sessions encompassing a diverse array of topics, and more frequent contextual shifts)* "To handle these intricacies arising from evolving LLM-based chat systems" becomes "面对这些来自演进的 LLM 基于对话系统的复杂性" (To handle these complexities arising from evolving LLM-based chat systems)* "we propose joint dialogue segmentation and state tracking per segment in open-domain dialogue systems" becomes "我们提议在开放领域对话系统中实现对话段化和状态追踪" (We propose joint dialogue segmentation and state tracking in open-domain dialogue systems)* "Assuming a zero-shot setting appropriate to a true open-domain dialogue system" becomes "假设真正的开放领域对话系统的零枪射设定" (Assuming a zero-shot setting appropriate to a true open-domain dialogue system)* "we propose S3-DST, a structured prompting technique that harnesses Pre-Analytical Recollection, a novel grounding mechanism we designed for improving long context tracking" becomes "我们提议 S3-DST，一种基于 Pre-Analytical Recollection 的结构化提示技术，用于改进长上下文跟踪" (We propose S3-DST, a structured prompting technique that harnesses Pre-Analytical Recollection, a novel grounding mechanism we designed for improving long context tracking)* "To demonstrate the efficacy of our proposed approach in joint segmentation and state tracking" becomes "用于证明我们提议的方法在对话段化和状态追踪中的有效性" (To demonstrate the efficacy of our proposed approach in joint segmentation and state tracking)* "we evaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as well as publicly available DST and segmentation datasets" becomes "我们在一个 propriety 隐私化的开放领域对话数据集上评估 S3-DST，以及公共可用的 DST 和分段数据集" (We evaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as well as publicly available DST and segmentation datasets)* "Across all datasets and settings, S3-DST consistently outperforms the state-of-the-art" becomes "在所有数据集和设定下，S3-DST 一直表现出优于当前领先的状态" (Across all datasets and settings, S3-DST consistently outperforms the state-of-the-art)* "demonstrating its potency and robustness for the next generation of LLM-based chat systems" becomes "这种表现力和可靠性为下一代 LLM 基于对话系统的发展提供了启示" (demonstrating its potency and robustness for the next generation of LLM-based chat systems)
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Post-hoc-Classifiers-under-Prior-Shifts"><a href="#Distributionally-Robust-Post-hoc-Classifiers-under-Prior-Shifts" class="headerlink" title="Distributionally Robust Post-hoc Classifiers under Prior Shifts"></a>Distributionally Robust Post-hoc Classifiers under Prior Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08825">http://arxiv.org/abs/2309.08825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weijiaheng/drops">https://github.com/weijiaheng/drops</a></li>
<li>paper_authors: Jiaheng Wei, Harikrishna Narasimhan, Ehsan Amid, Wen-Sheng Chu, Yang Liu, Abhishek Kumar</li>
<li>for: 本研究旨在强化机器学习模型对分布变化的抗预测能力。</li>
<li>methods: 我们提出了一种极其轻量级的后处理方法，通过在预训练模型上计算并应用批处理调整来减少一个目标分布下的抗预测损失。</li>
<li>results: 我们的方法可以提供减少分布变化导致的抗预测损失的保证，并且在实际实现中具有强大的表现。<details>
<summary>Abstract</summary>
The generalization ability of machine learning models degrades significantly when the test distribution shifts away from the training distribution. We investigate the problem of training models that are robust to shifts caused by changes in the distribution of class-priors or group-priors. The presence of skewed training priors can often lead to the models overfitting to spurious features. Unlike existing methods, which optimize for either the worst or the average performance over classes or groups, our work is motivated by the need for finer control over the robustness properties of the model. We present an extremely lightweight post-hoc approach that performs scaling adjustments to predictions from a pre-trained model, with the goal of minimizing a distributionally robust loss around a chosen target distribution. These adjustments are computed by solving a constrained optimization problem on a validation set and applied to the model during test time. Our constrained optimization objective is inspired by a natural notion of robustness to controlled distribution shifts. Our method comes with provable guarantees and empirically makes a strong case for distributional robust post-hoc classifiers. An empirical implementation is available at https://github.com/weijiaheng/Drops.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GPT-as-a-Baseline-for-Recommendation-Explanation-Texts"><a href="#GPT-as-a-Baseline-for-Recommendation-Explanation-Texts" class="headerlink" title="GPT as a Baseline for Recommendation Explanation Texts"></a>GPT as a Baseline for Recommendation Explanation Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08817">http://arxiv.org/abs/2309.08817</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joyce Zhou, Thorsten Joachims</li>
<li>for: 这个研究探讨了现代模型生成的电影推荐文本解释如何帮助用户，以及用户对不同组成部分的评价。</li>
<li>methods: 研究使用现代自然语言处理技术生成电影推荐文本解释，并对用户的评价进行分析。</li>
<li>results: 研究发现参与者对电影推荐文本解释的评价没有显著差异，但参与者对已经见过的电影的评价更高。此外，参与者 также标记了电影评论文本中重要的特征。<details>
<summary>Abstract</summary>
In this work, we establish a baseline potential for how modern model-generated text explanations of movie recommendations may help users, and explore what different components of these text explanations that users like or dislike, especially in contrast to existing human movie reviews. We found that participants gave no significantly different rankings between movies, nor did they give significantly different individual quality scores to reviews of movies that they had never seen before. However, participants did mark reviews as significantly better when they were movies they had seen before. We also explore specific aspects of movie review texts that participants marked as important for each quality. Overall, we establish that modern LLMs are a promising source of recommendation explanations, and we intend on further exploring personalizable text explanations in the future.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们建立了现代模型生成的电影推荐文本解释的基线潜力，并探索用户对不同组成部分的响应，特别是与现有人类电影评论相比。我们发现参与者没有提供不同电影的排名，也没有对每部电影的质量分数作出不同的评价。但参与者确实将已经见过的电影的评论标记为更好。我们还探究每部电影评论文本中各个重要方面，参与者认为哪些方面是重要的。总的来说，我们发现现代LLM是可靠的推荐解释来源，我们将在未来进一步探索个性化文本解释。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/cs.AI_2023_09_16/" data-id="clp89do8n003zi788h8wpdjgc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/cs.CL_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T11:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/cs.CL_2023_09_16/">cs.CL - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Impact-of-Debiasing-on-the-Performance-of-Language-Models-in-Downstream-Tasks-is-Underestimated"><a href="#The-Impact-of-Debiasing-on-the-Performance-of-Language-Models-in-Downstream-Tasks-is-Underestimated" class="headerlink" title="The Impact of Debiasing on the Performance of Language Models in Downstream Tasks is Underestimated"></a>The Impact of Debiasing on the Performance of Language Models in Downstream Tasks is Underestimated</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09092">http://arxiv.org/abs/2309.09092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masahiro Kaneko, Danushka Bollegala, Naoaki Okazaki</li>
<li>for: 这篇论文主要探讨了预训模型中的社会偏见，以及如何对这些偏见进行调整。</li>
<li>methods: 论文使用了多种方法来对预训模型进行调整，以消除社会偏见。</li>
<li>results: 论文的实验结果显示，对于不同的下游任务，调整预训模型的影响都是被低估的。此外，为了正确评估调整的影响，应该对 female、male 和传统词汇进行分开考虑。<details>
<summary>Abstract</summary>
Pre-trained language models trained on large-scale data have learned serious levels of social biases. Consequently, various methods have been proposed to debias pre-trained models. Debiasing methods need to mitigate only discriminatory bias information from the pre-trained models, while retaining information that is useful for the downstream tasks. In previous research, whether useful information is retained has been confirmed by the performance of downstream tasks in debiased pre-trained models. On the other hand, it is not clear whether these benchmarks consist of data pertaining to social biases and are appropriate for investigating the impact of debiasing. For example in gender-related social biases, data containing female words (e.g. ``she, female, woman''), male words (e.g. ``he, male, man''), and stereotypical words (e.g. ``nurse, doctor, professor'') are considered to be the most affected by debiasing. If there is not much data containing these words in a benchmark dataset for a target task, there is the possibility of erroneously evaluating the effects of debiasing. In this study, we compare the impact of debiasing on performance across multiple downstream tasks using a wide-range of benchmark datasets that containing female, male, and stereotypical words. Experiments show that the effects of debiasing are consistently \emph{underestimated} across all tasks. Moreover, the effects of debiasing could be reliably evaluated by separately considering instances containing female, male, and stereotypical words than all of the instances in a benchmark dataset.
</details>
<details>
<summary>摘要</summary>
各种方法已经被提议来减少预训练模型中的社会偏见。这些方法需要从预训练模型中除去排斥性偏见信息，而不是抹除有用的信息。在之前的研究中，已经证明了这些减少后的模型在下游任务中的表现。然而，不清楚这些标准 benchmark 数据是否包含社会偏见的信息，并不适用于研究减少的影响。例如，在性别相关的社会偏见中，包含女性词汇（如“她，女性，女人”）、男性词汇（如“他，男性，男人”）和 gender 刻板印象（如“护士，医生，教授”）被视为最受减少影响。如果 benchmark 数据中不含这些词汇的数据，那么可能会误判减少的影响。在这种研究中，我们比较了减少对多个下游任务的表现，使用包含女性、男性和 gender 刻板印象的多种 benchmark 数据。实验显示，减少的影响被一致地低估，并且可以通过分别考虑包含女性、男性和 gender 刻板印象的实例来可靠地评估减少的影响。
</details></li>
</ul>
<hr>
<h2 id="Improving-Speech-Recognition-for-African-American-English-With-Audio-Classification"><a href="#Improving-Speech-Recognition-for-African-American-English-With-Audio-Classification" class="headerlink" title="Improving Speech Recognition for African American English With Audio Classification"></a>Improving Speech Recognition for African American English With Audio Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09996">http://arxiv.org/abs/2309.09996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shefali Garg, Zhouyuan Huo, Khe Chai Sim, Suzan Schwartz, Mason Chua, Alëna Aksënova, Tsendsuren Munkhdalai, Levi King, Darryl Wright, Zion Mengesha, Dongseong Hwang, Tara Sainath, Françoise Beaufays, Pedro Moreno Mengibar</li>
<li>for: 提高短句子朗读识别系统的品质 disparities between different language varieties.</li>
<li>methods: 使用小量的out-of-domain(长形)非裔美国英语数据来改善US英语短句子朗读识别系统的Robustness.</li>
<li>results: 使用CORAAL、YouTube和Mozilla Common Voice等数据集来训练一个音频分类器，可以准确地判断一个utterance是非裔美国英语还是其他语种，包括主流美国英语。通过将这些分类器输出与杂合的地理信息相结合，可以在大规模的半监督学习中选择一组utterances进行 semi-supervised learning。经过精细调整，这些utterances的word error rate disparity reduction between AAE和MAE可以达到38.5%。<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) systems have been shown to have large quality disparities between the language varieties they are intended or expected to recognize. One way to mitigate this is to train or fine-tune models with more representative datasets. But this approach can be hindered by limited in-domain data for training and evaluation. We propose a new way to improve the robustness of a US English short-form speech recognizer using a small amount of out-of-domain (long-form) African American English (AAE) data. We use CORAAL, YouTube and Mozilla Common Voice to train an audio classifier to approximately output whether an utterance is AAE or some other variety including Mainstream American English (MAE). By combining the classifier output with coarse geographic information, we can select a subset of utterances from a large corpus of untranscribed short-form queries for semi-supervised learning at scale. Fine-tuning on this data results in a 38.5% relative word error rate disparity reduction between AAE and MAE without reducing MAE quality.
</details>
<details>
<summary>摘要</summary>
We use CORAAL, YouTube, and Mozilla Common Voice to train an audio classifier to approximately output whether an utterance is AAE or some other variety, including Mainstream American English (MAE). By combining the classifier output with coarse geographic information, we can select a subset of utterances from a large corpus of untranscribed short-form queries for semi-supervised learning at scale. Fine-tuning on this data results in a 38.5% relative word error rate disparity reduction between AAE and MAE without reducing MAE quality.
</details></li>
</ul>
<hr>
<h2 id="Constructing-a-Knowledge-Graph-for-Vietnamese-Legal-Cases-with-Heterogeneous-Graphs"><a href="#Constructing-a-Knowledge-Graph-for-Vietnamese-Legal-Cases-with-Heterogeneous-Graphs" class="headerlink" title="Constructing a Knowledge Graph for Vietnamese Legal Cases with Heterogeneous Graphs"></a>Constructing a Knowledge Graph for Vietnamese Legal Cases with Heterogeneous Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09069">http://arxiv.org/abs/2309.09069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi-Hai-Yen Vuong, Minh-Quan Hoang, Tan-Minh Nguyen, Hoang-Trung Nguyen, Ha-Thanh Nguyen</li>
<li>for: 本文提出了一种法律案例文档和相关法律知识图构建方法，以提高法律信息的有效组织和下游任务的提高。</li>
<li>methods: 本方法包括三个主要步骤：数据抓取、信息提取和知识图部署。首先，数据抓取器从多种来源收集了大量的法律案例文档和相关法律信息，为后续处理提供了丰富的数据库。然后，信息提取步骤使用自然语言处理技术提取了法律案例文档中的法院、案件、领域和法律等实体，以及它们之间的关系。最后，知识图被部署，将这些实体连接起来，创建了一个多元图，有效地表示了法律信息，且适用于法律领域的用户，如律师、法官和学者。</li>
<li>results: 建立的基线模型通过不监督学习方法，并通过知识图的支持，能够为给定的法律案例提取相关法律。这种方法开启了法律领域的多种应用，如法律案例分析、法律建议和决策支持。<details>
<summary>Abstract</summary>
This paper presents a knowledge graph construction method for legal case documents and related laws, aiming to organize legal information efficiently and enhance various downstream tasks. Our approach consists of three main steps: data crawling, information extraction, and knowledge graph deployment. First, the data crawler collects a large corpus of legal case documents and related laws from various sources, providing a rich database for further processing. Next, the information extraction step employs natural language processing techniques to extract entities such as courts, cases, domains, and laws, as well as their relationships from the unstructured text. Finally, the knowledge graph is deployed, connecting these entities based on their extracted relationships, creating a heterogeneous graph that effectively represents legal information and caters to users such as lawyers, judges, and scholars. The established baseline model leverages unsupervised learning methods, and by incorporating the knowledge graph, it demonstrates the ability to identify relevant laws for a given legal case. This approach opens up opportunities for various applications in the legal domain, such as legal case analysis, legal recommendation, and decision support.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Data crawling: Collect a large corpus of legal case documents and related laws from various sources, providing a rich database for further processing.2. Information extraction: Employ natural language processing techniques to extract entities such as courts, cases, domains, and laws, as well as their relationships from the unstructured text.3. Knowledge graph deployment: Connect these entities based on their extracted relationships, creating a heterogeneous graph that effectively represents legal information and caters to users such as lawyers, judges, and scholars.The established baseline model leverages unsupervised learning methods, and by incorporating the knowledge graph, it demonstrates the ability to identify relevant laws for a given legal case. This approach opens up opportunities for various applications in the legal domain, such as legal case analysis, legal recommendation, and decision support.</details></li>
</ol>
<hr>
<h2 id="Exploring-the-impact-of-low-rank-adaptation-on-the-performance-efficiency-and-regularization-of-RLHF"><a href="#Exploring-the-impact-of-low-rank-adaptation-on-the-performance-efficiency-and-regularization-of-RLHF" class="headerlink" title="Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of RLHF"></a>Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of RLHF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09055">http://arxiv.org/abs/2309.09055</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/simengsun/alpaca_farm_lora">https://github.com/simengsun/alpaca_farm_lora</a></li>
<li>paper_authors: Simeng Sun, Dhawal Gupta, Mohit Iyyer</li>
<li>for: 这个技术报告目的是 empirically investigating an efficient implementation of RLHF using low-rank adaptation (LoRA)，以便使用两个A100 GPUs进行RLHF，而不需要八个GPUs进行全模型精细化。</li>
<li>methods: 本文使用了LoRA来实现RLHF，并评估了各种LoRA-based PPO实现方式的效果，包括 removing KL regularization term、使用Jensen-Shannon divergence等其他 regularizers，以及trainining with LoRA的影响。</li>
<li>results: 本文发现：(1) 在LoRA设置下，移除KL正化term不会对AlpacaFarm评估集的性能造成负面影响; (2) 使用Jensen-Shannon divergence等其他正化器可以提高性能; (3) PPO训练会对模型生成的回答造成负面影响，但是使用LoRA可以几乎完全解除这个效应。<details>
<summary>Abstract</summary>
During the last stage of RLHF, a large language model is aligned to human intents via PPO training, a process that generally requires large-scale computational resources. In this technical report, we empirically investigate an efficient implementation of RLHF using low-rank adaptation (LoRA), which allows us to align the LLaMA 7B checkpoint on the Alpaca dataset using only two A100 GPUs instead of the eight required for full model fine-tuning. Despite tuning only 0.2% of LLaMA 7B's parameters, our implementation achieves better performance than the publicly-released AlpacaFarm checkpoint with full model fine-tuning. Next, we analyze several configurations of our LoRA-based PPO implementation, varying the form of the KL regularization term in the training objective. We find that (1) removing this penalty term does not harm performance on the AlpacaFarm evaluation set under our LoRA setup; (2) other regularizers, such as Jensen-Shannon divergence, lead to improved performance; and (3) while PPO training negatively impacts the factuality of model-generated responses, training with LoRA largely mitigates this effect. We release our code and pretrained checkpoints to facilitate future research on more efficient RLHF.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Removing the penalty term does not harm performance on the AlpacaFarm evaluation set under our LoRA setup.2. Other regularizers, such as Jensen-Shannon divergence, lead to improved performance.3. PPO training negatively impacts the factuality of model-generated responses, but training with LoRA largely mitigates this effect.We release our code and pretrained checkpoints to facilitate future research on more efficient RLHF.</details></li>
</ol>
<hr>
<h2 id="Context-aware-Adversarial-Attack-on-Named-Entity-Recognition"><a href="#Context-aware-Adversarial-Attack-on-Named-Entity-Recognition" class="headerlink" title="Context-aware Adversarial Attack on Named Entity Recognition"></a>Context-aware Adversarial Attack on Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08999">http://arxiv.org/abs/2309.08999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuguang Chen, Leonardo Neves, Thamar Solorio</li>
<li>for: 研究名实recognition任务中模型的Robustness，采用Context-aware adversarial attack方法。</li>
<li>methods: 提出 perturbing the most informative words for recognizing entities来创建攻击示例，并研究不同的候选替换方法来生成自然和可能的攻击示例。</li>
<li>results: 实验和分析表明，我们的方法比强基eline更有效地使模型作出错误预测。<details>
<summary>Abstract</summary>
In recent years, large pre-trained language models (PLMs) have achieved remarkable performance on many natural language processing benchmarks. Despite their success, prior studies have shown that PLMs are vulnerable to attacks from adversarial examples. In this work, we focus on the named entity recognition task and study context-aware adversarial attack methods to examine the model's robustness. Specifically, we propose perturbing the most informative words for recognizing entities to create adversarial examples and investigate different candidate replacement methods to generate natural and plausible adversarial examples. Experiments and analyses show that our methods are more effective in deceiving the model into making wrong predictions than strong baselines.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:近年来，大型预训语言模型（PLM）在自然语言处理benchmark上表现出色。然而，先前的研究表明PLM对攻击性例子有敏感性。在这项工作中，我们将焦点放在命名实体识别任务上，研究上下文意识攻击方法，以评估模型的可靠性。特别是，我们提议在识别实体时对最有用的词语进行拟合，并比较不同的候选替换方法来生成自然和可能的攻击示例。我们的实验和分析表明，我们的方法可以更有效地使模型进行错误预测。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-STS-and-NLI-in-Large-Language-Models"><a href="#Rethinking-STS-and-NLI-in-Large-Language-Models" class="headerlink" title="Rethinking STS and NLI in Large Language Models"></a>Rethinking STS and NLI in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08969">http://arxiv.org/abs/2309.08969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxia Wang, Minghan Wang, Preslav Nakov</li>
<li>for: 这个研究旨在重新思考大语言模型（LLM）时代的科学技术与社会（STS）和自然语言理解（NLI）。</li>
<li>methods: 我们首先评估了五个数据集上的科学技术与社会（STS）和自然语言理解（NLI）的准确率，然后评估LLM的预测信心和其能够捕捉人类集体意见的能力。</li>
<li>results: 我们发现LLM可以为特定话题提供个性化描述，或者生成不同语调的semantically相似内容，但现在LLM很难为个人提供个性化评价或决策。此外，我们发现零shot ChatGPT在临床和生物医学STS&#x2F;NLI中达到了竞争性的准确率，但是采样变化很大， ensemble结果表现最佳。<details>
<summary>Abstract</summary>
In this study, we aim to rethink STS and NLI in the era of large language models (LLMs). We first evaluate the accuracy of clinical/biomedical STS and NLI over five datasets, and then we assess LLM predictive confidence and their capability of capturing collective human opinions. We find that LLMs may be able to provide personalised descriptions for a specific topic, or to generate semantically similar content in different tones, but that this is hard for current LLMs to make personalised judgements or decisions. We further find that zero-shot ChatGPT achieves competitive accuracy over clinical and biomedical STS/NLI, constraining to the fine-tuned BERT-base. However, there is a large variation in sampling, ensembled results perform the best.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们想重新思考STS和NLI在大语言模型（LLM）时代中的应用。我们首先评估了五个数据集上的临床/生物医学STS和NLI的准确率，然后评估LLM的预测自信和人类集体意见的捕捉能力。我们发现LLM可能可以为特定主题提供个性化描述，或生成不同调式的含义相似内容，但当前LLM很难为个人作出个性化判断或决策。此外，我们发现零批量ChatGPT在临床和生物医学STS/NLI中 achieved competitive accuracy，但是精度受到 fine-tuned BERT-base 的限制。然而，采样方法的差异导致ensembled结果表现最佳。
</details></li>
</ul>
<hr>
<h2 id="Sorted-LLaMA-Unlocking-the-Potential-of-Intermediate-Layers-of-Large-Language-Models-for-Dynamic-Inference-Using-Sorted-Fine-Tuning-SoFT"><a href="#Sorted-LLaMA-Unlocking-the-Potential-of-Intermediate-Layers-of-Large-Language-Models-for-Dynamic-Inference-Using-Sorted-Fine-Tuning-SoFT" class="headerlink" title="Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference Using Sorted Fine-Tuning (SoFT)"></a>Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference Using Sorted Fine-Tuning (SoFT)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08968">http://arxiv.org/abs/2309.08968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parsa Kavehzadeh, Mojtaba Valipour, Marzieh Tahaei, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh</li>
<li>for: 这个论文旨在探讨如何使用SortedNet训练技术来实现大语言模型的动态推论，并且不需要预先训练和专门的硬件支持。</li>
<li>methods: 这个论文使用了SortedNet训练技术，将深度神经网络分成多个子模型，并且根据计算&#x2F;准确性特征进行排序，以获得不同 Computational loads的子模型。</li>
<li>results: 这个论文的结果显示，使用Sorted Fine-Tuning（SoFT）技术可以实现大语言模型的动态推论，并且可以提高模型的效率，不需要预先训练和专门的硬件支持。<details>
<summary>Abstract</summary>
The rapid advancement of large language models (LLMs) has revolutionized natural language processing (NLP). While these models excel at understanding and generating human-like text, their widespread deployment can be prohibitively expensive. SortedNet is a recent training technique for enabling dynamic inference for deep neural networks. It leverages network modularity to create sub-models with varying computational loads, sorting them based on computation/accuracy characteristics in a nested manner. We extend SortedNet to generative NLP tasks, making large language models dynamic without any pretraining and by only replacing standard Supervised Fine-Tuning (SFT) with Sorted Fine-Tuning (SoFT) at the same costs. Our approach boosts model efficiency, eliminating the need for multiple models for various scenarios during inference. We show that using this approach, we are able to unlock the potential of intermediate layers of transformers in generating the target output. Our sub-models remain integral components of the original model, minimizing storage requirements and transition costs between different computational/latency budgets. By applying this approach on LLaMa 2 13B for tuning on the Stanford Alpaca dataset and comparing it to normal tuning and early exit via PandaLM benchmark, we show that Sorted Fine-Tuning can deliver models twice as fast as the original model while maintaining or exceeding performance.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）的快速进步已经革命化自然语言处理（NLP）领域。虽然这些模型能够理解和生成人类语言样式的文本，但它们的广泛部署可能是非常昂贵的。SortedNet是一种最近的训练技术，用于启用深度神经网络的动态推理。它利用网络归一化来创建具有不同计算负担的子模型，并将它们按照计算/准确度特征进行嵌套排序。我们将SortedNet应用于生成型NLP任务，使得大语言模型在动态模式下运行，不需要预训练和只需要将标准超级精度训练（SFT）替换为Sorted Fine-Tuning（SoFT），并且可以保持模型的效率。我们的方法可以消除多个模型的需求，用于不同的执行环境。我们通过在LLaMa 2 13B上对斯坦福小羊数据集进行调整，并与标准训练和早期终止via PandaLM benchmark进行比较，显示Sorted Fine-Tuning可以提供比原始模型快 twice as fast的模型，同时保持或超越性能。
</details></li>
</ul>
<hr>
<h2 id="Struc-Bench-Are-Large-Language-Models-Really-Good-at-Generating-Complex-Structured-Data"><a href="#Struc-Bench-Are-Large-Language-Models-Really-Good-at-Generating-Complex-Structured-Data" class="headerlink" title="Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?"></a>Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08963">http://arxiv.org/abs/2309.08963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gersteinlab/struc-bench">https://github.com/gersteinlab/struc-bench</a></li>
<li>paper_authors: Xiangru Tang, Yiming Zong, Jason Phang, Yilun Zhao, Wangchunshu Zhou, Arman Cohan, Mark Gerstein</li>
<li>for: 这个研究是为了评估当前的大型自然语言模型（LLMs）在生成复杂结构数据方面的能力，并提出了一种结构意识细化适应方法来改进这种能力。</li>
<li>methods: 研究者们提出了Struc-Bench，一个包括五种代表性的LLMs（即GPT-NeoX 20B、GPT-3.5、GPT-4、Vicuna）的评估方法，并对这些模型在手动构建的文本、HTML和LaTeX表格上进行了全面的评估。</li>
<li>results: 研究者们发现了当前模型在处理复杂结构输出时存在一些共同的格式错误和改进的可能性，并使用FormatCoT（链式思维）生成Format指令从目标输出中提取了 Format 信息。在应用结构意识细化适应方法后，LLaMA-7B模型在遵守自然语言约束方面表现出色，超过了其他评估的LLMs。<details>
<summary>Abstract</summary>
Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraints, outperforming other evaluated LLMs. Based on these results, we present an ability map of model capabilities from six dimensions (i.e., coverage, formatting, reasoning, comprehension, pragmatics, and hallucination). This map highlights the weaknesses of LLMs in handling complex structured outputs and suggests promising directions for future work. Our code and models can be found at https://github.com/gersteinlab/Struc-Bench.
</details>
<details>
<summary>摘要</summary>
尽管大型语言模型（LLM）如GPT-4具有强大的语言生成能力，但它们仍然在需要生成复杂结构化输出的任务上遇到困难。在这项研究中，我们评估当今LLM在生成复杂结构数据方面的能力，并提出一种结构意识练化方法来改进这种能力。为了进行全面的评估，我们提出了Struc-Bench，包括5种代表性的LLM（即GPT-NeoX 20B、GPT-3.5、GPT-4、Vicuna），并对它们在我们手动构建的数据集上进行评估。根据我们对当前模型性能的分析，我们标识出了特定的公共格式错误和改进的 возмож性。为了处理复杂的格式要求，我们使用FormatCoT（链条思维）生成 Format  instrucions 从目标输出。我们的实验表明，当我们应用结构意识练化方法到 LLaMA-7B 时，可以显著提高遵从自然语言约束的能力，超过其他评估的LLMs。基于这些结果，我们提出了模型能力的六个维度（即覆盖率、格式、逻辑、理解、 Pragmatics 和 hallucination）能力图，这些能力图 highlights LLMs 在处理复杂结构输出的弱点，并提出了未来工作的优秀方向。我们的代码和模型可以在 https://github.com/gersteinlab/Struc-Bench 找到。
</details></li>
</ul>
<hr>
<h2 id="ODSum-New-Benchmarks-for-Open-Domain-Multi-Document-Summarization"><a href="#ODSum-New-Benchmarks-for-Open-Domain-Multi-Document-Summarization" class="headerlink" title="ODSum: New Benchmarks for Open Domain Multi-Document Summarization"></a>ODSum: New Benchmarks for Open Domain Multi-Document Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08960">http://arxiv.org/abs/2309.08960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijie Zhou, Kejian Shi, Wencai Zhang, Yixin Liu, Yilun Zhao, Arman Cohan<br>for:这个论文主要目标是提出一种基于规则的方法，用于从查询基于文档 summarization 数据集中生成 open-domain multi-document summarization（ODMDS）数据集。methods:这种方法基于 retrieve-then-summarize 方法，并使用了一个新的数据集 ODSum，该数据集的文档索引相互关联并经常相互关系。results:通过广泛的实验， authors 发现了评价指标的变化和其可靠性，以及 LLMS  Retrieving 错误导致的性能下降。 authors 还试图改进性能并调查其对不完全检索的 Robustness。<details>
<summary>Abstract</summary>
Open-domain Multi-Document Summarization (ODMDS) is a critical tool for condensing vast arrays of documents into coherent, concise summaries. With a more inter-related document set, there does not necessarily exist a correct answer for the retrieval, making it hard to measure the retrieving performance. We propose a rule-based method to process query-based document summarization datasets into ODMDS datasets. Based on this method, we introduce a novel dataset, ODSum, a sophisticated case with its document index interdependent and often interrelated. We tackle ODMDS with the \textit{retrieve-then-summarize} method, and the performance of a list of retrievers and summarizers is investigated. Through extensive experiments, we identify variances in evaluation metrics and provide insights into their reliability. We also found that LLMs suffer great performance loss from retrieving errors. We further experimented methods to improve the performance as well as investigate their robustness against imperfect retrieval. We will release our data and code at https://github.com/yale-nlp/ODSum.
</details>
<details>
<summary>摘要</summary>
开放领域多文摘要 (ODMDS) 是一种重要的工具，可以将庞大的文档缩写成一个准确、简洁的摘要。由于文档集之间存在较多的相互关联，因此在 Retrieval 中不存在答案，这使得评估表现变得更加困难。我们提出了一种基于规则的方法，用于将查询基于文档摘要 dataset 转换为 ODMDS dataset。基于这种方法，我们提出了一个新的 dataset，ODSum，它的文档索引相互关联，并且经常存在相互关联。我们使用“Retrieve-then-summarize”方法来解决 ODMDS，并investigate了一系列的检索和摘要器的性能。通过广泛的实验，我们发现了评估指标之间的差异和其可靠性。此外，我们还发现了 LLMS 在检索错误时的性能下降。我们进一步调查了改进性能的方法，以及其对不完整检索的Robustness。我们将在 GitHub 上发布数据和代码。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Large-Language-Model-Induced-Task-Oriented-Dialogue-Systems-Through-Look-Forward-Motivated-Goals"><a href="#Enhancing-Large-Language-Model-Induced-Task-Oriented-Dialogue-Systems-Through-Look-Forward-Motivated-Goals" class="headerlink" title="Enhancing Large Language Model Induced Task-Oriented Dialogue Systems Through Look-Forward Motivated Goals"></a>Enhancing Large Language Model Induced Task-Oriented Dialogue Systems Through Look-Forward Motivated Goals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08949">http://arxiv.org/abs/2309.08949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyuan Hu, Yue Feng, Yang Deng, Zekun Li, See-Kiong Ng, Anh Tuan Luu, Bryan Hooi</li>
<li>for: 提高对话系统的效率和成功率，以及用户满意度。</li>
<li>methods: 采用了前期预测对话动作的方法，并将目标奖励信号纳入对话系统中。</li>
<li>results: 在MultiWoZ 2.1 dataset上实现了比前一代完全监督模型更高的性能，同时用户满意度和系统效率也得到了提高。<details>
<summary>Abstract</summary>
Recently, the development of large language models (LLMs) has been significantly enhanced the question answering and dialogue generation, and makes them become increasingly popular in current practical scenarios. While unlike the general dialogue system which emphasizes the semantic performance, the task-oriented dialogue (ToD) systems aim to achieve the dialogue goal efficiently and successfully in multiple turns. Unfortunately, existing LLM-induced ToD systems lack the direct reward toward the final goal and do not take account of the dialogue proactivity that can strengthen the dialogue efficiency. To fill these gaps, we introduce the ProToD (Proactively Goal-Driven LLM-Induced ToD) approach, which anticipates the future dialogue actions and incorporates the goal-oriented reward signal to enhance ToD systems. Additionally, we present a novel evaluation method that assesses ToD systems based on goal-driven dialogue simulations. This method allows us to gauge user satisfaction, system efficiency and successful rate while overcoming the limitations of current Information and Success metrics. Empirical experiments conducted on the MultiWoZ 2.1 dataset demonstrate that our model can achieve superior performance using only 10% of the data compared to previous end-to-end fully supervised models. This improvement is accompanied by enhanced user satisfaction and efficiency.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)近期，大型语言模型（LLM）的开发已经大幅提高了问答和对话生成，使其在现实场景中越来越受欢迎。而不同于普通的对话系统，任务对话（ToD）系统的目标是在多个转换中efficiently完成对话目标。然而，现有的LLM引导的ToD系统缺乏直接奖励最终目标，并不考虑对话的积极性，这可以增强对话效率。为了填补这些空白，我们介绍了ProToD（主动目标驱动LLM引导ToD）方法，预测未来对话动作并将目标奖励信号纳入ToD系统。此外，我们还提出了一种新的评估方法，基于目标驱动对话 simulations，以评估ToD系统的用户满意度、系统效率和成功率。这种方法可以超越现有的信息和成功指标，评估ToD系统的性能。实验表明，我们的模型在MultiWoZ 2.1数据集上可以使用只有10%的数据达到前一个完全监督模型的性能，这种改进是由用户满意度和效率增加而成就的。
</details></li>
</ul>
<hr>
<h2 id="Contextual-Label-Projection-for-Cross-Lingual-Structure-Extraction"><a href="#Contextual-Label-Projection-for-Cross-Lingual-Structure-Extraction" class="headerlink" title="Contextual Label Projection for Cross-Lingual Structure Extraction"></a>Contextual Label Projection for Cross-Lingual Structure Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08943">http://arxiv.org/abs/2309.08943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanmay Parekh, I-Hung Hsu, Kuan-Hao Huang, Kai-Wei Chang, Nanyun Peng</li>
<li>For: The paper is written for the task of creating pseudo-training data in target languages for structure extraction tasks, specifically event argument extraction.* Methods: The paper proposes a method called CLAP, which translates text to the target language and performs contextual translation on the labels using the translated text as the context. The method uses instruction-tuned language models with multilingual capabilities as the contextual translator.* Results: The paper reports that CLAP improves the F1-score by 2-2.5 points over other label projection techniques on the Chinese and Arabic ACE05 datasets.<details>
<summary>Abstract</summary>
Translating training data into target languages has proven beneficial for cross-lingual transfer. However, for structure extraction tasks, translating data requires a label projection step, which translates input text and obtains translated labels in the translated text jointly. Previous research in label projection mostly compromises translation quality by either facilitating easy identification of translated labels from translated text or using word-level alignment between translation pairs to assemble translated phrase-level labels from the aligned words. In this paper, we introduce CLAP, which first translates text to the target language and performs contextual translation on the labels using the translated text as the context, ensuring better accuracy for the translated labels. We leverage instruction-tuned language models with multilingual capabilities as our contextual translator, imposing the constraint of the presence of translated labels in the translated text via instructions. We compare CLAP with other label projection techniques for creating pseudo-training data in target languages on event argument extraction, a representative structure extraction task. Results show that CLAP improves by 2-2.5 F1-score over other methods on the Chinese and Arabic ACE05 datasets.
</details>
<details>
<summary>摘要</summary>
训练数据的翻译到目标语言有助于cross-lingual transfer。然而， для结构提取任务，翻译数据的翻译需要一个标签投影步骤，该步骤将输入文本和其翻译后的文本一起翻译标签。过去的研究中，大多数标签投影方法会牺牲翻译质量， either by facilitating the identification of translated labels from the translated text or by using word-level alignment between translation pairs to assemble translated phrase-level labels from the aligned words。在这篇论文中，我们介绍了CLAP，它首先将文本翻译到目标语言，然后使用翻译后的文本作为 Context，以确保更高的翻译标签准确性。我们利用了Multilingual可调语言模型作为我们的上下文翻译器，并对翻译后的标签进行上下文翻译，以便在翻译后的文本中找到翻译标签。我们与其他标签投影技术进行比较，在目标语言中的ACE05数据集上进行pseudo-training数据的创建。结果显示，CLAP在中文和阿拉伯语ACE05数据集上提高了2-2.5个F1分的性能。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Multi-lingual-Positive-Instances-in-Contrastive-Learning-to-Improve-Sentence-Embedding"><a href="#Leveraging-Multi-lingual-Positive-Instances-in-Contrastive-Learning-to-Improve-Sentence-Embedding" class="headerlink" title="Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding"></a>Leveraging Multi-lingual Positive Instances in Contrastive Learning to Improve Sentence Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08929">http://arxiv.org/abs/2309.08929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiyan Zhao, Qiyu Wu, Xin-Qiang Cai, Yoshimasa Tsuruoka</li>
<li>for: 学习多语言句子表示是自然语言处理领域的基本和重要任务之一。</li>
<li>methods: 本文提出了一种新的方法MPCL，利用多个正例来改进学习多语言句子表示。</li>
<li>results: 我们的实验结果表明，相比 conventional CL，MPCL可以提高句子embedding模型的检索、Semantic相似性和分类性能。此外，我们还发现在未经看过的语言上，基于多个正例进行学习的句子embedding模型在跨语言传播性能更好。<details>
<summary>Abstract</summary>
Learning multi-lingual sentence embeddings is a fundamental and significant task in natural language processing. Recent trends of learning both mono-lingual and multi-lingual sentence embeddings are mainly based on contrastive learning (CL) with an anchor, one positive, and multiple negative instances. In this work, we argue that leveraging multiple positives should be considered for multi-lingual sentence embeddings because (1) positives in a diverse set of languages can benefit cross-lingual learning, and (2) transitive similarity across multiple positives can provide reliable structural information to learn. In order to investigate the impact of CL with multiple positives, we propose a novel approach MPCL to effectively utilize multiple positive instances to improve learning multi-lingual sentence embeddings. Our experimental results on various backbone models and downstream tasks support that compared with conventional CL, MPCL leads to better retrieval, semantic similarity, and classification performances. We also observe that on unseen languages, sentence embedding models trained on multiple positives have better cross-lingual transferring performance than models trained on a single positive instance.
</details>
<details>
<summary>摘要</summary>
学习多语言句子嵌入是自然语言处理中的基础和重要任务。现今的多语言句子嵌入学习主要基于对比学习（CL）的 anchor、一个正例和多个负例。在这项工作中，我们认为可以利用多个正例，因为（1）多语言正例可以提高语言之间的学习，和（2）多个正例之间的相互关系可以提供可靠的结构信息来学习。为了研究CL与多个正例的影响，我们提出了一种新的方法MPCL，可以有效地利用多个正例来提高多语言句子嵌入学习。我们的实验结果表明，与传统CL相比，MPCL在不同的基础模型和下游任务中都具有更好的检索、Semantic相似性和分类性能。此外，我们还发现在未看过的语言上，基于多个正例的句子嵌入模型在cross-lingual传输性能上比基于单个正例的模型更好。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Multi-Hop-Question-Answering-Through-a-Conversation-Between-Tools-and-Efficiently-Finetuned-Large-Language-Models"><a href="#Multimodal-Multi-Hop-Question-Answering-Through-a-Conversation-Between-Tools-and-Efficiently-Finetuned-Large-Language-Models" class="headerlink" title="Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models"></a>Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08922">http://arxiv.org/abs/2309.08922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Rajabzadeh, Suyuchen Wang, Hyock Ju Kwon, Bang Liu</li>
<li>for: Answering complex multimodal multi-hop questions</li>
<li>methods: 使用大语言模型（LLM）和预定的工具集来分解问题，并通过多模式多步骤的问题分解来提高 LLM 的理解能力</li>
<li>results: 在两个最新引入的复杂问答数据集上进行评估，实验结果显示了substantial improvement over existing state-of-the-art solutions， indicating the effectiveness and generality of the proposed strategy<details>
<summary>Abstract</summary>
We employ a tool-interacting divide-and-conquer strategy enabling large language models (LLMs) to answer complex multimodal multi-hop questions. In particular, we harness the power of large language models to divide a given multimodal multi-hop question into unimodal single-hop sub-questions to be answered by the appropriate tool from a predefined set of tools. After all corresponding tools provide the LLM with their answers, the LLM generates the next relevant unimodal single-hop question. To increase the reasoning ability of LLMs, we prompt chatGPT to generate a tool-interacting divide-and-conquer dataset. This dataset is then used to efficiently finetune the corresponding LLM. To assess the effectiveness of this approach, we conduct an evaluation on two recently introduced complex question-answering datasets. The experimental analysis demonstrate substantial improvements over existing state-of-the-art solutions, indicating the efficacy and generality of our strategy
</details>
<details>
<summary>摘要</summary>
我们采用工具互动分解胜利策略，让大型语言模型（LLM）能够回答复杂多Modal多步问题。具体来说，我们利用大型语言模型将给定的多Modal多步问题分解成单Modal单步问题，由预定的工具集中的相应工具来答复。接下来，所有相应工具提供其答案后，LLM生成下一个相关的单Modal单步问题。为了提高LLM的逻辑能力，我们让ChatGPT生成一个工具互动分解数据集。这个数据集然后用于高效地训练相应的LLM。为评估我们的方法效果，我们对两个最近引入的复杂问题回答数据集进行评估。实验分析表明，我们的策略具有显著的改善，表明我们的方法的有效性和通用性。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Subtler-Biases-in-LLMs-Ageism-Beauty-Institutional-and-Nationality-Bias-in-Generative-Models"><a href="#Investigating-Subtler-Biases-in-LLMs-Ageism-Beauty-Institutional-and-Nationality-Bias-in-Generative-Models" class="headerlink" title="Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models"></a>Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08902">http://arxiv.org/abs/2309.08902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim</li>
<li>for: 这 paper 探讨了 LLM 是否存在各种社会团体中的偏见，以及这些偏见是否对 consequential 决策产生影响，如employmnet、人性评价和刑事判决。</li>
<li>methods: 作者使用了 sentence completion task 来测试 LLM 的偏见，并使用了多种社会团体和不同的属性来检测偏见。</li>
<li>results: 作者发现了 LLM 在不同社会团体和属性之间的偏见，包括年龄和美貌等。这些偏见与人类在实验心理学中发现的偏见相似。<details>
<summary>Abstract</summary>
LLMs are increasingly powerful and widely used to assist users in a variety of tasks. This use risks the introduction of LLM biases to consequential decisions such as job hiring, human performance evaluation, and criminal sentencing. Bias in NLP systems along the lines of gender and ethnicity has been widely studied, especially for specific stereotypes (e.g., Asians are good at math). In this paper, we investigate bias along less studied, but still consequential, dimensions, such as age and beauty, measuring subtler correlated decisions that LLMs (specially autoregressive language models) make between social groups and unrelated positive and negative attributes. We ask whether LLMs hold wide-reaching biases of positive or negative sentiment for specific social groups similar to the ``what is beautiful is good'' bias found in people in experimental psychology. We introduce a template-generated dataset of sentence completion tasks that asks the model to select the most appropriate attribute to complete an evaluative statement about a person described as a member of a specific social group. We also reverse the completion task to select the social group based on an attribute. Finally, we report the correlations that we find for multiple cutting-edge LLMs. This dataset can be used as a benchmark to evaluate progress in more generalized biases and the templating technique can be used to expand the benchmark with minimal additional human annotation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Semantic-Information-Extraction-for-Text-Data-with-Probability-Graph"><a href="#Semantic-Information-Extraction-for-Text-Data-with-Probability-Graph" class="headerlink" title="Semantic Information Extraction for Text Data with Probability Graph"></a>Semantic Information Extraction for Text Data with Probability Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08879">http://arxiv.org/abs/2309.08879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhouxiang Zhao, Zhaohui Yang, Ye Hu, Licheng Lin, Zhaoyang Zhang</li>
<li>for: 本文研究了在有限通信资源下传输 semantic information，以提高文本数据的传输效率。</li>
<li>methods: 本文使用自然语言处理技术提取原始文本数据，然后将提取的semantic information capture在知识图中。提取semantic information的问题被设为优化框架，目标是提取最重要的semantic information进行传输。</li>
<li>results: 提议的算法可以减少semantic uncertainty和semantic similarity，并且与基于文本 Similarity的方法进行比较。<details>
<summary>Abstract</summary>
In this paper, the problem of semantic information extraction for resource constrained text data transmission is studied. In the considered model, a sequence of text data need to be transmitted within a communication resource-constrained network, which only allows limited data transmission. Thus, at the transmitter, the original text data is extracted with natural language processing techniques. Then, the extracted semantic information is captured in a knowledge graph. An additional probability dimension is introduced in this graph to capture the importance of each information. This semantic information extraction problem is posed as an optimization framework whose goal is to extract most important semantic information for transmission. To find an optimal solution for this problem, a Floyd's algorithm based solution coupled with an efficient sorting mechanism is proposed. Numerical results testify the effectiveness of the proposed algorithm with regards to two novel performance metrics including semantic uncertainty and semantic similarity.
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了在有限通信资源的文本数据传输中的Semantic信息提取问题。我们考虑的模型中，一个文本数据序列需要在有限通信资源的网络中传输，只允许有限的数据传输。因此，在发送器端，原始文本数据使用自然语言处理技术进行提取。然后，提取到的Semantic信息被 capture在一个知识图中。在这个图中，我们引入了一个概率维度，用于捕捉每个信息的重要性。这个Semantic信息提取问题被 pose为一个优化框架，其目标是提取最重要的Semantic信息进行传输。为了找到最优解，我们提出了基于Floyd的算法和高效排序机制的解决方案。数据测试表明了我们提出的算法的效果，并使用了两个新的性能指标：Semanticuncertainty和Semantic similarity。
</details></li>
</ul>
<hr>
<h2 id="X-PARADE-Cross-Lingual-Textual-Entailment-and-Information-Divergence-across-Paragraphs"><a href="#X-PARADE-Cross-Lingual-Textual-Entailment-and-Information-Divergence-across-Paragraphs" class="headerlink" title="X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs"></a>X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08873">http://arxiv.org/abs/2309.08873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Diego Rodriguez, Katrin Erk, Greg Durrett</li>
<li>for: 本研究的目的是解决跨语言文本之间的信息差异问题。</li>
<li>methods: 本研究使用了多种方法来解决这个问题，包括经典的机器翻译tokenAlignment、文本推理方法和大语言模型的推断。</li>
<li>results: 研究发现这些方法在处理可推理信息方面表现不一，但都落后于人类表现。<details>
<summary>Abstract</summary>
Understanding when two pieces of text convey the same information is a goal touching many subproblems in NLP, including textual entailment and fact-checking. This problem becomes more complex when those two pieces of text are in different languages. Here, we introduce X-PARADE (Cross-lingual Paragraph-level Analysis of Divergences and Entailments), the first cross-lingual dataset of paragraph-level information divergences. Annotators label a paragraph in a target language at the span level and evaluate it with respect to a corresponding paragraph in a source language, indicating whether a given piece of information is the same, new, or new but can be inferred. This last notion establishes a link with cross-language NLI. Aligned paragraphs are sourced from Wikipedia pages in different languages, reflecting real information divergences observed in the wild. Armed with our dataset, we investigate a diverse set of approaches for this problem, including classic token alignment from machine translation, textual entailment methods that localize their decisions, and prompting of large language models. Our results show that these methods vary in their capability to handle inferable information, but they all fall short of human performance.
</details>
<details>
<summary>摘要</summary>
理解两个文本具有相同信息是许多自然语言处理（NLP）问题的目标，包括文本推理和事实核查。当这两个文本在不同语言时，这个问题变得更加复杂。我们现在介绍了X-PARADE（跨语言段级分析异同和推理），这是首个跨语言段级信息异同数据集。注解员将目标语言中的一个段标记为源语言中的对应段之间的异同，并评估它们之间的关系，以确定一个信息是否相同、新的或新的但可以推理出来。这个概念与跨语言NLI（自然语言理解）建立了联系。我们使用了这些数据集，调查了一系列方法来解决这个问题，包括机器翻译的 класси型token对齐、文本推理方法的本地化和大语言模型的激励。我们的结果表明，这些方法在处理推理出来的信息方面表现不一样，但它们都不足以达到人类性能。
</details></li>
</ul>
<hr>
<h2 id="Has-Sentiment-Returned-to-the-Pre-pandemic-Level-A-Sentiment-Analysis-Using-U-S-College-Subreddit-Data-from-2019-to-2022"><a href="#Has-Sentiment-Returned-to-the-Pre-pandemic-Level-A-Sentiment-Analysis-Using-U-S-College-Subreddit-Data-from-2019-to-2022" class="headerlink" title="Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis Using U.S. College Subreddit Data from 2019 to 2022"></a>Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis Using U.S. College Subreddit Data from 2019 to 2022</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08845">http://arxiv.org/abs/2309.08845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alvayan/postcovidsentianalysis">https://github.com/alvayan/postcovidsentianalysis</a></li>
<li>paper_authors: Tian Yan, Fang Liu<br>for: 这项研究的目的是探讨2019年至2022年的情绪变化，特别是在疫情风险降低后情绪是否回归到了过去的水平。methods: 该研究使用Reddit数据收集于2019年、2020年、2021年和2022年，从128所美国大学&#x2F;学院的Subreddit中收集数据，并使用预训练的Robustly Optimized BERT预训练方法（RoBERTa）和图像注意网络（GAT）来预测情绪。results: 研究发现，相比2019年，2020年、2021年和2022年的负面情绪的可能性分别提高了24%、4.3%和10.3%，这些增长都是 statistically significant（适用 $p$ &lt;0.05）。这些结果表明在疫情风险降低后，情绪的组成部分在后疫情emergency era中进行了部分恢复。<details>
<summary>Abstract</summary>
As impact of COVID-19 pandemic winds down, both individuals and society gradually return to pre-pandemic activities. This study aims to explore how people's emotions have changed from the pre-pandemic during the pandemic to post-emergency period and whether it has returned to pre-pandemic level. We collected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and 2022 (late stages of pandemic, transitioning period to post-emergency period) from subreddits in 128 universities/colleges in the U.S., and a set of school-level characteristics. We predicted two sets of sentiments from a pre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph attention network (GAT) that leverages both rich semantic and relational information among posted messages and then applied a logistic stacking method to obtain the final sentiment classification. After obtaining sentiment label for each message, we used a generalized linear mixed-effects model to estimate temporal trend in sentiment from 2019 to 2022 and how school-level factors may affect sentiment. Compared to the year 2019, the odds of negative sentiment in years 2020, 2021, and 2022 are 24%, 4.3%, and 10.3% higher, respectively, which are all statistically significant(adjusted $p$<0.05). Our study findings suggest a partial recovery in the sentiment composition in the post-pandemic-emergency era. The results align with common expectations and provide a detailed quantification of how sentiments have evolved from 2019 to 2022.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行的影响逐渐减轻，个人和社会逐渐返回到前疫情时期的活动。这项研究旨在探讨人们在疫情期间和后emergency期间的情绪是否发生了变化，以及情绪是否回归到了前疫情水平。我们收集了2019年、2020年、2021年和2022年Reddit数据（来自128所美国大学/学院Subreddit），以及一组学校级特征。我们预测了两组情绪（来自Robustly Optimized BERT预训练方法（RoBERTa）和图像注意网络（GAT）），然后应用了ilogistic栈合并方法来获得最终的情绪分类。接下来，我们使用一种通用的线性混合效应模型来估计2019年至2022年间情绪的时间趋势，以及学校级因素是否影响情绪。相比2019年，2020年、2021年和2022年的负面情绪的 odds 分别高于24%、4.3%和10.3%，这些均为 statistically significant（ adjusted $p$ <0.05）。我们的研究发现，在后疫情emergency era，情绪结构有部分恢复。结果与常见预期相符，并为2019年至2022年间情绪的发展提供了详细的量化。
</details></li>
</ul>
<hr>
<h2 id="EchoPrompt-Instructing-the-Model-to-Rephrase-Queries-for-Improved-In-context-Learning"><a href="#EchoPrompt-Instructing-the-Model-to-Rephrase-Queries-for-Improved-In-context-Learning" class="headerlink" title="EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning"></a>EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10687">http://arxiv.org/abs/2309.10687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajasekhar Reddy Mekala, Yasaman Razeghi, Sameer Singh</li>
<li>for: 提高大型语言模型在上下文学习中的表现</li>
<li>methods: 引入EchoPrompt策略，让模型重复提问以提高它的答案</li>
<li>results: 实验结果表明，EchoPrompt可以在标准和链式提问下提高zero-shot和几少shot上下文学习的表现，并且在不同的数学计算（GSM8K、SVAMP、MultiArith、SingleOp）、阅读理解（DROP、SQuAD）和逻辑理解（Shuffled Objects、Date Understanding、Coin Flipping）任务中均有显著提高。<details>
<summary>Abstract</summary>
Large language models primarily rely on incontext learning to execute tasks. We introduce EchoPrompt, a simple yet effective approach to prompt the model to rephrase its queries before answering them. EchoPrompt is inspired by self-questioning, a cognitive strategy humans use to vocalize queries before providing answers, thereby reducing misconceptions. Experimental results demonstrate that EchoPrompt leads to substantial improvements in both zero-shot and few-shot in-context learning with standard and chain-of-thought prompting on four families of causal language models. These improvements are observed across various numerical reasoning (GSM8K, SVAMP, MultiArith, SingleOp), reading comprehension (DROP, SQuAD), and logical reasoning (Shuffled Objects, Date Understanding, Coin Flipping) tasks. On average, EchoPrompt improves the Zero-shot-CoT performance of code-davinci-002 by 5% in numerical tasks and 13% in reading comprehension tasks. We investigate the effectiveness of EchoPrompt through ablation studies, which reveal the significance of both original and rephrased queries for EchoPrompt's efficacy. Our empirical results show that EchoPrompt is an effective technique that can easily augment in-context learning for better performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/cs.CL_2023_09_16/" data-id="clp89doat00bpi78803136dg8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/cs.LG_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T10:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/cs.LG_2023_09_16/">cs.LG - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reducing-sequential-change-detection-to-sequential-estimation"><a href="#Reducing-sequential-change-detection-to-sequential-estimation" class="headerlink" title="Reducing sequential change detection to sequential estimation"></a>Reducing sequential change detection to sequential estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09111">http://arxiv.org/abs/2309.09111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubhanshu Shekhar, Aaditya Ramdas</li>
<li>for: 这个论文是为了解决数据流中参数或功能θ的变化检测问题，目标是设计一种具有小检测延迟，但保证在无变化情况下降低假阳性发生频率的变化检测方案。</li>
<li>methods: 这篇论文使用了信息理论Sequential estimation和 confidence sequences的方法，开始每个时间步骤上一个（1-α）信心序列，并在所有活跃信心序列交叉为空时宣布变化。</li>
<li>results: 论文证明了变化检测方案的平均运行长度至少为1&#x2F;α，从而实现了具有小结构假设（即可能存在依赖性观察和非 Parametric 分布类），但强制 garanties。<details>
<summary>Abstract</summary>
We consider the problem of sequential change detection, where the goal is to design a scheme for detecting any changes in a parameter or functional $\theta$ of the data stream distribution that has small detection delay, but guarantees control on the frequency of false alarms in the absence of changes. In this paper, we describe a simple reduction from sequential change detection to sequential estimation using confidence sequences: we begin a new $(1-\alpha)$-confidence sequence at each time step, and proclaim a change when the intersection of all active confidence sequences becomes empty. We prove that the average run length is at least $1/\alpha$, resulting in a change detection scheme with minimal structural assumptions~(thus allowing for possibly dependent observations, and nonparametric distribution classes), but strong guarantees. Our approach bears an interesting parallel with the reduction from change detection to sequential testing of Lorden (1971) and the e-detector of Shin et al. (2022).
</details>
<details>
<summary>摘要</summary>
我们考虑了时间序列变化检测问题，目标是设计一个检测数据流分布中参数或功能 $\theta$ 变化的方案，具有小检测延迟，但 garantuee控制不变数据流中噪声频率。在这篇论文中，我们描述了一种简单的减少从时间序列变化检测到时间序列估计的方法：我们在每个时间步骤开始一个新的 $(1-\alpha)$-信度序列，并在所有活动信度序列交集为空时宣布变化。我们证明了average run length至少为 $1/\alpha$，从而实现了变化检测方案，具有最小的结构假设（即允许可能相关的观察和非参数分布类型），但具有强 guarantees。我们的方法与 Lorden (1971) 的减少从变化检测到时间序列测试，以及 Shin et al. (2022) 的 e-detector 具有一定的平行。
</details></li>
</ul>
<hr>
<h2 id="Test-Time-Compensated-Representation-Learning-for-Extreme-Traffic-Forecasting"><a href="#Test-Time-Compensated-Representation-Learning-for-Extreme-Traffic-Forecasting" class="headerlink" title="Test-Time Compensated Representation Learning for Extreme Traffic Forecasting"></a>Test-Time Compensated Representation Learning for Extreme Traffic Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09074">http://arxiv.org/abs/2309.09074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Zhang, Weizhong Zhang, Yaowei Huang, Kani Chen</li>
<li>for: 预测交通流量是一项复杂的任务，因为交通系列具有复杂的空间时间相关性。这篇论文探讨了一个尚未得到充分关注的问题：极端事件。</li>
<li>methods: 我们提出了一种在测试阶段补偿表示学习框架，包括空间时间分解数据银行和多头空间变换模型（CompFormer）。前者分解所有训练数据的时间维度按照 periodic 特征，而后者通过空间注意力矩阵与最近观察和历史序列在数据银行之间建立连接，以便将稳定特征传递到抗EXTREME事件。</li>
<li>results: 我们的方法可以在极端事件下 достичь显著改进，比如METR-LA和PEMS-BAY 测试环境中的6个强基elines。总体而言，我们的方法可以提高交通预测的准确率，最高达28.2%。<details>
<summary>Abstract</summary>
Traffic forecasting is a challenging task due to the complex spatio-temporal correlations among traffic series. In this paper, we identify an underexplored problem in multivariate traffic series prediction: extreme events. Road congestion and rush hours can result in low correlation in vehicle speeds at various intersections during adjacent time periods. Existing methods generally predict future series based on recent observations and entirely discard training data during the testing phase, rendering them unreliable for forecasting highly nonlinear multivariate time series. To tackle this issue, we propose a test-time compensated representation learning framework comprising a spatio-temporal decomposed data bank and a multi-head spatial transformer model (CompFormer). The former component explicitly separates all training data along the temporal dimension according to periodicity characteristics, while the latter component establishes a connection between recent observations and historical series in the data bank through a spatial attention matrix. This enables the CompFormer to transfer robust features to overcome anomalous events while using fewer computational resources. Our modules can be flexibly integrated with existing forecasting methods through end-to-end training, and we demonstrate their effectiveness on the METR-LA and PEMS-BAY benchmarks. Extensive experimental results show that our method is particularly important in extreme events, and can achieve significant improvements over six strong baselines, with an overall improvement of up to 28.2%.
</details>
<details>
<summary>摘要</summary>
很多时候，交通预测是一项非常困难的任务，这是因为交通系列之间存在复杂的空间-时间相关性。在这篇论文中，我们提出了一个未得到足够关注的问题：极端事件。路口拥堵和高峰时段可能导致不同的交通枢纽的车速在相邻时期之间存在低相关性。现有的方法通常是根据最近观察值预测未来系列，并完全抛弃测试阶段的训练数据，这使得它们在预测非线性多变量时间系列方面不可靠。为解决这个问题，我们提议一个在测试阶段补偿表示学习框架，包括空间-时间分解的数据银行和多头空间变换模型（CompFormer）。前者组件可以显式分解所有的训练数据以 Temp 度量的时间维度，而后者组件可以通过空间注意力矩阵与最近观察值和历史系列在数据银行中建立连接，使CompFormer可以传递 Robust 特征以抵御特殊事件，并使用更少的计算资源。我们的模块可以与现有的预测方法进行灵活的集成，我们在 METR-LA 和 PEMS-BAY 测试准则上进行了综合实验，结果表明我们的方法在极端事件中尤为重要，可以在六个强大基准集上实现显著提高，最大提高达28.2%。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-personalised-thermal-comfort-models-with-Active-Learning-for-improved-HVAC-controls"><a href="#Enhancing-personalised-thermal-comfort-models-with-Active-Learning-for-improved-HVAC-controls" class="headerlink" title="Enhancing personalised thermal comfort models with Active Learning for improved HVAC controls"></a>Enhancing personalised thermal comfort models with Active Learning for improved HVAC controls</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09073">http://arxiv.org/abs/2309.09073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeynep Duygu Tekler, Yue Lei, Xilei Dai, Adrian Chong</li>
<li>for: 本研究旨在开发个性化thermal comfort模型，以便在建筑物中实现occupant-centric控制（OCC）系统。</li>
<li>methods: 本研究使用Active Learning（AL）技术， Addresses the data challenges related to real-world OCC implementations。</li>
<li>results: 研究结果表明，使用AL技术可以减少实际标注工作量（31.0%），同时仍能提高能效性和thermal satisfaction水平（1.3%和98%）。这表明，未来实际应用中可以部署这种系统，实现个性化的 COMFORT和能效的建筑操作。<details>
<summary>Abstract</summary>
Developing personalised thermal comfort models to inform occupant-centric controls (OCC) in buildings requires collecting large amounts of real-time occupant preference data. This process can be highly intrusive and labour-intensive for large-scale implementations, limiting the practicality of real-world OCC implementations. To address this issue, this study proposes a thermal preference-based HVAC control framework enhanced with Active Learning (AL) to address the data challenges related to real-world implementations of such OCC systems. The proposed AL approach proactively identifies the most informative thermal conditions for human annotation and iteratively updates a supervised thermal comfort model. The resulting model is subsequently used to predict the occupants' thermal preferences under different thermal conditions, which are integrated into the building's HVAC controls. The feasibility of our proposed AL-enabled OCC was demonstrated in an EnergyPlus simulation of a real-world testbed supplemented with the thermal preference data of 58 study occupants. The preliminary results indicated a significant reduction in overall labelling effort (i.e., 31.0%) between our AL-enabled OCC and conventional OCC while still achieving a slight increase in energy savings (i.e., 1.3%) and thermal satisfaction levels above 98%. This result demonstrates the potential for deploying such systems in future real-world implementations, enabling personalised comfort and energy-efficient building operations.
</details>
<details>
<summary>摘要</summary>
开发个性化thermal comfort模型，以便在建筑物中实现占位者-центric控制（OCC）需要收集大量实时占位者喜好数据。这个过程可能是非常干扰性的，特别是在大规模实施时，这会限制现实世界中OCC系统的实现可行性。为解决这个问题，本研究提出了基于Active Learning（AL）的thermal preference-based HVAC控制框架。该方法可以把实时占位者喜好数据用于训练监督thermal comfort模型，并在不同的thermalconditions下预测占位者的thermal喜好。这些喜好值后来将被集成到建筑物的HVAC控制系统中。我们在一个基于EnergyPlus的实验室中对一个真实的测试床进行了 simulate，并补充了58名学生的thermal喜好数据。初步结果表明，我们的AL-enabled OCC比 conventinal OCC减少了31.0%的标签努力（即标签每个占位者的thermal condition），同时仍保持了1.3%的能源节约和thermal满意度高于98%。这些结果表明，在未来实际世界中部署这些系统是可能的，以实现个性化的舒适性和能源效率的建筑物运行。
</details></li>
</ul>
<hr>
<h2 id="Recovering-Missing-Node-Features-with-Local-Structure-based-Embeddings"><a href="#Recovering-Missing-Node-Features-with-Local-Structure-based-Embeddings" class="headerlink" title="Recovering Missing Node Features with Local Structure-based Embeddings"></a>Recovering Missing Node Features with Local Structure-based Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09068">http://arxiv.org/abs/2309.09068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor M. Tenorio, Madeline Navarro, Santiago Segarra, Antonio G. Marques</li>
<li>for:  recover completely missing node features for a set of graphs</li>
<li>methods: incorporate prior information from both graph topology and existing nodal values, use a Graph AutoEncoder to train a node embedding space</li>
<li>results: accurate feature estimation approach, valuable for downstream graph classification<details>
<summary>Abstract</summary>
Node features bolster graph-based learning when exploited jointly with network structure. However, a lack of nodal attributes is prevalent in graph data. We present a framework to recover completely missing node features for a set of graphs, where we only know the signals of a subset of graphs. Our approach incorporates prior information from both graph topology and existing nodal values. We demonstrate an example implementation of our framework where we assume that node features depend on local graph structure. Missing nodal values are estimated by aggregating known features from the most similar nodes. Similarity is measured through a node embedding space that preserves local topological features, which we train using a Graph AutoEncoder. We empirically show not only the accuracy of our feature estimation approach but also its value for downstream graph classification. Our success embarks on and implies the need to emphasize the relationship between node features and graph structure in graph-based learning.
</details>
<details>
<summary>摘要</summary>
节点特征增强图基于学习，当它们与网络结构结合使用时。然而，graph数据中缺失节点特征非常普遍。我们提出了一种框架，可以完全重建缺失节点特征的集合，只要知道一部分图的信号。我们的方法利用图ptopology和已知节点值的先前信息。我们示例中的实现方式是假设节点特征取决于本地图STRUCTURE。缺失节点值可以通过已知节点特征的聚合来估计。相似性是通过一个节点嵌入空间来 preserve local topological features，我们使用一个图自动编码器来训练。我们实际上证明了我们的特征估计方法的准确性，以及其对下游图分类的价值。我们的成功表明了和节点特征和图结构之间的关系的重要性。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Smoothness-Regularisers-for-Neural-Link-Predictors"><a href="#Temporal-Smoothness-Regularisers-for-Neural-Link-Predictors" class="headerlink" title="Temporal Smoothness Regularisers for Neural Link Predictors"></a>Temporal Smoothness Regularisers for Neural Link Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09045">http://arxiv.org/abs/2309.09045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manuel Dileo, Pasquale Minervini, Matteo Zignani, Sabrina Gaito</li>
<li>for: 本研究旨在提高知识图中链接预测精度，并且可以处理时间约束。</li>
<li>methods: 本研究使用了四次tensor的 canonical decomposition 以及时间滤波 regularization 来预测知识图中链接。</li>
<li>results: 研究发现，通过选择合适的时间滤波 regularizer 和补偿量，简单的 TNTComplEx 方法可以在三个 temporal link prediction 数据集上 producenew state-of-the-art 结果，并且对两个 state-of-the-art 模型进行了评估。<details>
<summary>Abstract</summary>
Most algorithms for representation learning and link prediction on relational data are designed for static data. However, the data to which they are applied typically evolves over time, including online social networks or interactions between users and items in recommender systems. This is also the case for graph-structured knowledge bases -- knowledge graphs -- which contain facts that are valid only for specific points in time. In such contexts, it becomes crucial to correctly identify missing links at a precise time point, i.e. the temporal prediction link task. Recently, Lacroix et al. and Sadeghian et al. proposed a solution to the problem of link prediction for knowledge graphs under temporal constraints inspired by the canonical decomposition of 4-order tensors, where they regularise the representations of time steps by enforcing temporal smoothing, i.e. by learning similar transformation for adjacent timestamps. However, the impact of the choice of temporal regularisation terms is still poorly understood. In this work, we systematically analyse several choices of temporal smoothing regularisers using linear functions and recurrent architectures. In our experiments, we show that by carefully selecting the temporal smoothing regulariser and regularisation weight, a simple method like TNTComplEx can produce significantly more accurate results than state-of-the-art methods on three widely used temporal link prediction datasets. Furthermore, we evaluate the impact of a wide range of temporal smoothing regularisers on two state-of-the-art temporal link prediction models. Our work shows that simple tensor factorisation models can produce new state-of-the-art results using newly proposed temporal regularisers, highlighting a promising avenue for future research.
</details>
<details>
<summary>摘要</summary>
大多数 repreSentation learning 和链接预测算法是设计 для静态数据，但实际应用中的数据通常会随时间而变化，如在线社交网络或用户和物品之间的推荐系统中。这也是知识图的情况——知识graph——其中的事实只有在特定时间点才是有效的。在这些上下文中，正确地预测时间点缺失的链接变得非常重要，即时间预测链接任务。 Lacroix et al. 和 Sadeghian et al. 已经提出了为知识图链接预测问题的解决方案，基于四元tensor的 canonical decomposition，其中将时间步骤的表示正则化，即在邻近时间步骤上学习类似的变换。然而，选择时间平滑正则化项的影响仍未得到充分理解。在这种工作中，我们系统地分析了一些时间平滑正则化项，包括线性函数和循环架构。我们的实验表明，通过选择合适的时间平滑正则化项和正则化权重，简单的 TNTComplEx 方法可以在三个常用的时间链接预测数据集上生成较为准确的结果，并且超过当前的方法。此外，我们评估了一些时间平滑正则化项对两种当前的时间链接预测模型的影响。我们的工作显示，简单的tensor因子分解模型可以使用新的时间正则化项生成新的状态计算结果，标志着未来研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="Study-of-Enhanced-MISC-Based-Sparse-Arrays-with-High-uDOFs-and-Low-Mutual-Coupling"><a href="#Study-of-Enhanced-MISC-Based-Sparse-Arrays-with-High-uDOFs-and-Low-Mutual-Coupling" class="headerlink" title="Study of Enhanced MISC-Based Sparse Arrays with High uDOFs and Low Mutual Coupling"></a>Study of Enhanced MISC-Based Sparse Arrays with High uDOFs and Low Mutual Coupling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09044">http://arxiv.org/abs/2309.09044</a></li>
<li>repo_url: None</li>
<li>paper_authors: X. Sheng, D. Lu, Y. Li, R. C. de Lamare</li>
<li>for: 提高简洁数组（SA）的均匀度和干扰降低性。</li>
<li>methods: 基于最大间隔间距（IES）条件的加强最大间隔间距数组（EMISC SA），包括确定IES集和基于IES集的七个均匀线子数组（ULSAs）。</li>
<li>results: 比较研究表明，提出的EMISC SA在均匀度和干扰降低性方面表现更出色，在其他现有SA上显著优势。<details>
<summary>Abstract</summary>
In this letter, inspired by the maximum inter-element spacing (IES) constraint (MISC) criterion, an enhanced MISC-based (EMISC) sparse array (SA) with high uniform degrees-of-freedom (uDOFs) and low mutual-coupling (MC) is proposed, analyzed and discussed in detail. For the EMISC SA, an IES set is first determined by the maximum IES and number of elements. Then, the EMISC SA is composed of seven uniform linear sub-arrays (ULSAs) derived from an IES set. An analysis of the uDOFs and weight function shows that, the proposed EMISC SA outperforms the IMISC SA in terms of uDOF and MC. Simulation results show a significant advantage of the EMISC SA over other existing SAs.
</details>
<details>
<summary>摘要</summary>
在这封信中，启发于最大间元素间距（IES）约束（MISC） criterion，提出了一种增强型MISC-based（EMISC）稀疏阵列（SA），其具有高统一度数（uDOFs）和低相互干扰（MC）。为EMISC SA而确定了IES集，然后将其分成七个固定长度的uniform linear sub-arrays（ULSAs）。通过对uDOF和权重函数的分析，可以看出，提议的EMISC SA在uDOF和MC方面表现出了较好的性能。仔细的 simulations 表明，EMISC SA在其他现有的SA中具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Forward-Invariance-in-Neural-Network-Controlled-Systems"><a href="#Forward-Invariance-in-Neural-Network-Controlled-Systems" class="headerlink" title="Forward Invariance in Neural Network Controlled Systems"></a>Forward Invariance in Neural Network Controlled Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09043">http://arxiv.org/abs/2309.09043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gtfactslab/harapanahalli_lcss2024">https://github.com/gtfactslab/harapanahalli_lcss2024</a></li>
<li>paper_authors: Akash Harapanahalli, Saber Jafarpour, Samuel Coogan</li>
<li>for: 这个paper是为了证明和搜索非线性系统中神经网络控制器的前向不变集的 certificates。</li>
<li>methods: 该 frameworks使用了间隔分析和卷积系统理论，constructs localized first-order inclusion functions for the closed-loop system using Jacobian bounds and existing neural network verification tools，并builds a dynamical embedding system to directly correspond with a nested family of hyper-rectangles provably converging to an attractive set of the original system。</li>
<li>results: 该 Framework是自动化的，使用了interval analysis toolbox $\texttt{npinterval}$， along with the symbolic arithmetic toolbox $\texttt{sympy}$，demonstrated on an $8$-dimensional leader-follower system。<details>
<summary>Abstract</summary>
We present a framework based on interval analysis and monotone systems theory to certify and search for forward invariant sets in nonlinear systems with neural network controllers. The framework (i) constructs localized first-order inclusion functions for the closed-loop system using Jacobian bounds and existing neural network verification tools; (ii) builds a dynamical embedding system where its evaluation along a single trajectory directly corresponds with a nested family of hyper-rectangles provably converging to an attractive set of the original system; (iii) utilizes linear transformations to build families of nested paralleletopes with the same properties. The framework is automated in Python using our interval analysis toolbox $\texttt{npinterval}$, in conjunction with the symbolic arithmetic toolbox $\texttt{sympy}$, demonstrated on an $8$-dimensional leader-follower system.
</details>
<details>
<summary>摘要</summary>
我们提出了基于间隔分析和升降系统理论的框架，用于证明和搜索非线性系统中神经网络控制器的前向不变集。这个框架包括以下三个步骤：(i) 使用Jacobian bound和现有的神经网络验证工具来构建封闭循环系统的本地第一阶 inclusion函数;(ii) 使用动力系统来构建一个嵌入系统，其评估路径的评估直接对应于一个嵌入在原系统中的嵌入集;(iii) 使用线性变换来构建一个家族的嵌入多面体，这些多面体具有相同的性质。我们使用Python中的$\texttt{npinterval}$工具包，以及$\texttt{sympy}$工具包，在一个8维领导者-跟随者系统上进行了实验。
</details></li>
</ul>
<hr>
<h2 id="Solving-Quadratic-Systems-with-Full-Rank-Matrices-Using-Sparse-or-Generative-Priors"><a href="#Solving-Quadratic-Systems-with-Full-Rank-Matrices-Using-Sparse-or-Generative-Priors" class="headerlink" title="Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors"></a>Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09032">http://arxiv.org/abs/2309.09032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junren Chen, Shuai Huang, Michael K. Ng, Zhaoqiang Liu</li>
<li>For:  This paper addresses the problem of recovering a high-dimensional signal from a quadratic system with full-rank matrices, with a focus on incorporating prior knowledge of the signal to improve recovery performance.* Methods: The paper proposes two algorithms for signal recovery: the thresholded Wirtinger flow (TWF) algorithm and the projected gradient descent (PGD) algorithm. The TWF algorithm consists of a spectral initialization and a thresholded gradient descent step, while the PGD algorithm uses a projected power method and a projected gradient descent step.* Results: The paper reports experimental results that demonstrate the effectiveness of the proposed algorithms for signal recovery. Specifically, the results show that the proposed approach outperforms existing provable algorithms for the sparse case, and leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.<details>
<summary>Abstract</summary>
The problem of recovering a signal $\boldsymbol{x} \in \mathbb{R}^n$ from a quadratic system $\{y_i=\boldsymbol{x}^\top\boldsymbol{A}_i\boldsymbol{x},\ i=1,\ldots,m\}$ with full-rank matrices $\boldsymbol{A}_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\boldsymbol{A}_i$, this paper addresses the high-dimensional case where $m\ll n$ by incorporating prior knowledge of $\boldsymbol{x}$. First, we consider a $k$-sparse $\boldsymbol{x}$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\boldsymbol{x}$ (up to a sign flip) when $m=O(k^2\log n)$, and the thresholded gradient descent (with a good initialization) that produces a sequence linearly converging to $\boldsymbol{x}$ with $m=O(k\log n)$ measurements. Second, we explore the generative prior, assuming that $\boldsymbol{x}$ lies in the range of an $L$-Lipschitz continuous generative model with $k$-dimensional inputs in an $\ell_2$-ball of radius $r$. We develop the projected gradient descent (PGD) algorithm that also comprises two steps: the projected power method that provides an initial vector with $O\big(\sqrt{\frac{k \log L}{m}\big)$ $\ell_2$-error given $m=O(k\log(Lnr))$ measurements, and the projected gradient descent that refines the $\ell_2$-error to $O(\delta)$ at a geometric rate when $m=O(k\log\frac{Lrn}{\delta^2})$. Experimental results corroborate our theoretical findings and show that: (i) our approach for the sparse case notably outperforms the existing provable algorithm sparse power factorization; (ii) leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.
</details>
<details>
<summary>摘要</summary>
文本中的问题是从quadratic system $\{\mathbf{y}_i = \mathbf{x}^{\top}\mathbf{A}_i\mathbf{x}, \ i=1,\ldots,m\}$中recover $\mathbf{x} \in \mathbb{R}^n$的信号，其中 $\mathbf{A}_i$ 是高级别矩阵。这种问题在应用中如不分配距离几何和sub-波长成像频繁出现。本文使用独立标准 Gaussian 矩阵 $\mathbf{A}_i$ ，解决高维度情况($m \ll n$)，并借助先验知识来$\mathbf{x}$。首先，我们考虑 $k$-sparse $\mathbf{x}$ 情况，并引入 thresholded Wirtinger flow（TWF）算法，不需要稀疏程度 $k$。 TWF 包括两个步骤：spectral initialization，可以在 $m = O(k^2\log n)$ 个探测中找到一个 sufficiently close to $\mathbf{x}$ 的点（Up to a sign flip），以及 thresholded gradient descent（with good initialization），可以在 $m = O(k\log n)$ 个探测中产生一个线性收敛到 $\mathbf{x}$ 的序列。其次，我们探索生成先验，假设 $\mathbf{x}$ 在一个 $L$-Lipschitz 连续的生成模型中，其中输入是 $k$-维的 $\ell_2$ 球中的径 $r$。我们开发了 projected gradient descent（PGD）算法，该算法包括两个步骤：projected power method，可以在 $m = O\big(\sqrt{\frac{k \log L}{m}\big)$ 个探测中提供一个初始向量，其 $\ell_2$ 误差为 $O\big(\sqrt{\frac{k \log L}{m}\big)$；以及 projected gradient descent，可以在 $m = O(k\log\frac{Lrn}{\delta^2})$ 个探测中精确地将 $\ell_2$ 误差降至 $O(\delta)$ 的水平。实验结果证明了我们的理论发现，以及使用生成先验可以在 MNIST 数据集中从一小数量的quadratic measurements中准确地还原图像。 Specifically, our approach for the sparse case significantly outperforms the existing provable algorithm sparse power factorization; leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.
</details></li>
</ul>
<hr>
<h2 id="gym-saturation-Gymnasium-environments-for-saturation-provers-System-description"><a href="#gym-saturation-Gymnasium-environments-for-saturation-provers-System-description" class="headerlink" title="gym-saturation: Gymnasium environments for saturation provers (System description)"></a>gym-saturation: Gymnasium environments for saturation provers (System description)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09022">http://arxiv.org/abs/2309.09022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boris Shminke</li>
<li>for: 这篇论文描述了一个新版本的 Python 包 - gym-saturation，该包包含基于给定Clause算法的 OpenAI Gym 环境，用于导引滥化风格的证明器。</li>
<li>methods: 论文使用了两种不同的证明器：Vampire 和 iProver，并提供了解除证明状态表示与强化学习之间的关系的示例。此外，论文还提供了使用已知 ast2vec Python 代码嵌入模型作为一阶逻辑表示的示例。</li>
<li>results: 论文示例了如何使用 Ray RLlib 实现 Thompson 抽样和 proximal policy 优化两种强化学习算法，以便轻松实验新版本的 package。<details>
<summary>Abstract</summary>
This work describes a new version of a previously published Python package - gym-saturation: a collection of OpenAI Gym environments for guiding saturation-style provers based on the given clause algorithm with reinforcement learning. We contribute usage examples with two different provers: Vampire and iProver. We also have decoupled the proof state representation from reinforcement learning per se and provided examples of using a known ast2vec Python code embedding model as a first-order logic representation. In addition, we demonstrate how environment wrappers can transform a prover into a problem similar to a multi-armed bandit. We applied two reinforcement learning algorithms (Thompson sampling and Proximal policy optimisation) implemented in Ray RLlib to show the ease of experimentation with the new release of our package.
</details>
<details>
<summary>摘要</summary>
这个工作描述了一个新版本的Python包 - gym-saturation：一个基于给定的句法算法的OpenAI Gym环境，用于指导吸血者和iProver等逻辑推理器。我们提供了使用示例，包括使用known ast2vec Python代码嵌入模型作为逻辑表示。此外，我们还示出了如何使用环境包装器将推理器转化成多重机关问题。我们在Ray RLlib中实现了两种回归学习算法（托мп逊抽样和距离策略优化），以示新版本包的使用方便。
</details></li>
</ul>
<hr>
<h2 id="Regularized-Contrastive-Pre-training-for-Few-shot-Bioacoustic-Sound-Detection"><a href="#Regularized-Contrastive-Pre-training-for-Few-shot-Bioacoustic-Sound-Detection" class="headerlink" title="Regularized Contrastive Pre-training for Few-shot Bioacoustic Sound Detection"></a>Regularized Contrastive Pre-training for Few-shot Bioacoustic Sound Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08971">http://arxiv.org/abs/2309.08971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilyass Moummad, Romain Serizel, Nicolas Farrugia</li>
<li>for: bioacoustic sound event detection, 了解动物行为和监测生物多样性使用音频</li>
<li>methods: 深度学习系统和超级vised contrastive pre-training</li>
<li>results: 61.52%(0.48)和68.19%(0.75)的F-score，无需特定的 annotated data 训练<details>
<summary>Abstract</summary>
Bioacoustic sound event detection allows for better understanding of animal behavior and for better monitoring biodiversity using audio. Deep learning systems can help achieve this goal, however it is difficult to acquire sufficient annotated data to train these systems from scratch. To address this limitation, the Detection and Classification of Acoustic Scenes and Events (DCASE) community has recasted the problem within the framework of few-shot learning and organize an annual challenge for learning to detect animal sounds from only five annotated examples. In this work, we regularize supervised contrastive pre-training to learn features that can transfer well on new target tasks with animal sounds unseen during training, achieving a high F-score of 61.52%(0.48) when no feature adaptation is applied, and an F-score of 68.19%(0.75) when we further adapt the learned features for each new target task. This work aims to lower the entry bar to few-shot bioacoustic sound event detection by proposing a simple and yet effective framework for this task, by also providing open-source code.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UNIDEAL-Curriculum-Knowledge-Distillation-Federated-Learning"><a href="#UNIDEAL-Curriculum-Knowledge-Distillation-Federated-Learning" class="headerlink" title="UNIDEAL: Curriculum Knowledge Distillation Federated Learning"></a>UNIDEAL: Curriculum Knowledge Distillation Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08961">http://arxiv.org/abs/2309.08961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuwen Yang, Chang Liu, Xun Cai, Suizhi Huang, Hongtao Lu, Yue Ding</li>
<li>for: 该论文旨在解决跨Domain federated learning中的异常性问题，提出了一种名为UNIDEAL的新的 federated learning算法。</li>
<li>methods: 该算法使用了调整able Teacher-Student Mutual Evaluation Curriculum Learning，以进一步提高 federated learning 中的知识储存效果。</li>
<li>results: 对多个数据集进行了广泛的实验，与state-of-the-art基eline进行比较，结果显示，UNIDEAL可以在模型精度和通信效率两个方面达到更高的性能。此外，还提供了算法的收敛分析，显示其在非对称条件下的收敛率为O(1&#x2F;T)。<details>
<summary>Abstract</summary>
Federated Learning (FL) has emerged as a promising approach to enable collaborative learning among multiple clients while preserving data privacy. However, cross-domain FL tasks, where clients possess data from different domains or distributions, remain a challenging problem due to the inherent heterogeneity. In this paper, we present UNIDEAL, a novel FL algorithm specifically designed to tackle the challenges of cross-domain scenarios and heterogeneous model architectures. The proposed method introduces Adjustable Teacher-Student Mutual Evaluation Curriculum Learning, which significantly enhances the effectiveness of knowledge distillation in FL settings. We conduct extensive experiments on various datasets, comparing UNIDEAL with state-of-the-art baselines. Our results demonstrate that UNIDEAL achieves superior performance in terms of both model accuracy and communication efficiency. Additionally, we provide a convergence analysis of the algorithm, showing a convergence rate of O(1/T) under non-convex conditions.
</details>
<details>
<summary>摘要</summary>
《联合学习（FL）》已经出现为解决多个客户合作学习的有效方法，同时保护数据隐私。然而，跨Domain FL任务，客户拥有不同Domain或分布的数据，仍然是一个困难的问题，归因于内在的不一致性。本文提出了UNIDEAL算法，专门为跨Domainenario和多种模型架构设计。提议的方法 introduce Adjustable Teacher-Student Mutual Evaluation Curriculum Learning，对FL设置进行显著提升知识填充效果。我们在多个数据集上进行了广泛的实验，与现有的基线进行比较。我们的结果表明，UNIDEAL在模型准确率和通信效率两个方面均达到了Superior性能。此外，我们还提供了算法的收敛分析，显示其在非对称条件下的收敛率为O(1/T)。
</details></li>
</ul>
<hr>
<h2 id="Reducing-Memory-Requirements-for-the-IPU-using-Butterfly-Factorizations"><a href="#Reducing-Memory-Requirements-for-the-IPU-using-Butterfly-Factorizations" class="headerlink" title="Reducing Memory Requirements for the IPU using Butterfly Factorizations"></a>Reducing Memory Requirements for the IPU using Butterfly Factorizations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08946">http://arxiv.org/abs/2309.08946</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. -Kazem Shekofteh, Christian Alles, Holger Fröning</li>
<li>for: 本研究旨在探讨 Intellectual Processing Unit (IPU) 如何实现精简模型，提高高性能计算的可扩展性。</li>
<li>methods: 本研究使用了翅膀结构来取代完全连接和 convolutional 层，实现模型压缩。</li>
<li>results: 实验结果表明，使用翅膀结构可以提供 98.5% 压缩率，减少巨大的内存需求。IPU 实现可以获得 1.3x 和 1.6x 性能提升，并在实际数据集 CIFAR10 上达到 1.62x 训练时间速度提升。<details>
<summary>Abstract</summary>
High Performance Computing (HPC) benefits from different improvements during last decades, specially in terms of hardware platforms to provide more processing power while maintaining the power consumption at a reasonable level. The Intelligence Processing Unit (IPU) is a new type of massively parallel processor, designed to speedup parallel computations with huge number of processing cores and on-chip memory components connected with high-speed fabrics. IPUs mainly target machine learning applications, however, due to the architectural differences between GPUs and IPUs, especially significantly less memory capacity on an IPU, methods for reducing model size by sparsification have to be considered. Butterfly factorizations are well-known replacements for fully-connected and convolutional layers. In this paper, we examine how butterfly structures can be implemented on an IPU and study their behavior and performance compared to a GPU. Experimental results indicate that these methods can provide 98.5% compression ratio to decrease the immense need for memory, the IPU implementation can benefit from 1.3x and 1.6x performance improvement for butterfly and pixelated butterfly, respectively. We also reach to 1.62x training time speedup on a real-word dataset such as CIFAR10.
</details>
<details>
<summary>摘要</summary>
高性能计算（HPC）在过去几十年中得到了不同的改进，尤其是硬件平台，以提供更多的处理力而不超过合理的能耗水平。知识处理单元（IPU）是一种新型的极大并行处理器，旨在加速并行计算，特别是机器学习应用中的大量并行计算。由于IPU的architecture和GPU不同，特别是IPU的内存容量远少于GPU，因此需要考虑减少模型大小的方法。蝴蝶分解是机器学习中广泛使用的替换方法，可以完全或部分替换完全连接和卷积层。在这篇论文中，我们研究了如何在IPU上实现蝴蝶结构，并研究其行为和性能，与GPU相比。实验结果表明，这些方法可以提供98.5%的压缩率，减少巨大的内存需求，IPU实现可以 benefit From 1.3x和1.6x的性能提升，分别是蝴蝶和像素化蝴蝶。此外，我们还达到了1.62x的训练时间加速，在实际数据集CIFAR10上。
</details></li>
</ul>
<hr>
<h2 id="Inverse-classification-with-logistic-and-softmax-classifiers-efficient-optimization"><a href="#Inverse-classification-with-logistic-and-softmax-classifiers-efficient-optimization" class="headerlink" title="Inverse classification with logistic and softmax classifiers: efficient optimization"></a>Inverse classification with logistic and softmax classifiers: efficient optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08945">http://arxiv.org/abs/2309.08945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Á. Carreira-Perpiñán, Suryabhan Singh Hada</li>
<li>for: 本研究目的是解决 inverse classification 问题，即查询一个训练好的分类器的 closest instance，以使得分类器预测的标签发生某种旨在的变化。</li>
<li>methods: 本研究使用了逻辑回归和 softmax 分类器，并利用了这两种模型的特殊性，实现了快速的优化解决方案。</li>
<li>results: 研究人员表明，可以通过 closed form 的方法解决逻辑回归模型，并通过迭代但非常快的方法解决 softmax 模型，可以准确地解决 inverse classification 问题，并且可以在毫秒级别的时间内解决高维度的实例和多个类型。<details>
<summary>Abstract</summary>
In recent years, a certain type of problems have become of interest where one wants to query a trained classifier. Specifically, one wants to find the closest instance to a given input instance such that the classifier's predicted label is changed in a desired way. Examples of these ``inverse classification'' problems are counterfactual explanations, adversarial examples and model inversion. All of them are fundamentally optimization problems over the input instance vector involving a fixed classifier, and it is of interest to achieve a fast solution for interactive or real-time applications. We focus on solving this problem efficiently for two of the most widely used classifiers: logistic regression and softmax classifiers. Owing to special properties of these models, we show that the optimization can be solved in closed form for logistic regression, and iteratively but extremely fast for the softmax classifier. This allows us to solve either case exactly (to nearly machine precision) in a runtime of milliseconds to around a second even for very high-dimensional instances and many classes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fast-Approximation-of-the-Shapley-Values-Based-on-Order-of-Addition-Experimental-Designs"><a href="#Fast-Approximation-of-the-Shapley-Values-Based-on-Order-of-Addition-Experimental-Designs" class="headerlink" title="Fast Approximation of the Shapley Values Based on Order-of-Addition Experimental Designs"></a>Fast Approximation of the Shapley Values Based on Order-of-Addition Experimental Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08923">http://arxiv.org/abs/2309.08923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liuqing Yang, Yongdao Zhou, Haoda Fu, Min-Qian Liu, Wei Zheng</li>
<li>for: 评估多方协作中每个 player 的贡献，以便做出公平的分配成本和利润。</li>
<li>methods: 使用 Shapley value 算法，但是因为计算复杂度太高，采用随机抽样法来估算 Shapley value。采用了基于 эксперименталь设计的 combinatorial structures 来实现更高精度的估算。</li>
<li>results: 对比 SRS 随机抽样法，DOE 采样 schemes 具有更高精度和可靠性，并且在某些情况下可以 deterministically recover 原始 Shapley value。在实验和实际应用中，DOE 采样 schemes 也表现出较快的计算速度。<details>
<summary>Abstract</summary>
Shapley value is originally a concept in econometrics to fairly distribute both gains and costs to players in a coalition game. In the recent decades, its application has been extended to other areas such as marketing, engineering and machine learning. For example, it produces reasonable solutions for problems in sensitivity analysis, local model explanation towards the interpretable machine learning, node importance in social network, attribution models, etc. However, its heavy computational burden has been long recognized but rarely investigated. Specifically, in a $d$-player coalition game, calculating a Shapley value requires the evaluation of $d!$ or $2^d$ marginal contribution values, depending on whether we are taking the permutation or combination formulation of the Shapley value. Hence it becomes infeasible to calculate the Shapley value when $d$ is reasonably large. A common remedy is to take a random sample of the permutations to surrogate for the complete list of permutations. We find an advanced sampling scheme can be designed to yield much more accurate estimation of the Shapley value than the simple random sampling (SRS). Our sampling scheme is based on combinatorial structures in the field of design of experiments (DOE), particularly the order-of-addition experimental designs for the study of how the orderings of components would affect the output. We show that the obtained estimates are unbiased, and can sometimes deterministically recover the original Shapley value. Both theoretical and simulations results show that our DOE-based sampling scheme outperforms SRS in terms of estimation accuracy. Surprisingly, it is also slightly faster than SRS. Lastly, real data analysis is conducted for the C. elegans nervous system and the 9/11 terrorist network.
</details>
<details>
<summary>摘要</summary>
沙普利值是原本 econometrics 中的一种概念，用于公平分配合作者在协同游戏中的收益和成本。在过去几十年中，它的应用范围已经扩展到了其他领域，如市场营销、工程和机器学习。例如，它可以解决敏感分析、地方模型解释、社交网络中节点重要性、负责模型等问题。然而，它的计算束缚非常重，长期被注意。特别是在 d 个玩家协同游戏中，计算沙普利值需要评估 d! 或 2^d 个边缘贡献值，这取决于我们是使用 permutation 还是 combination 的 Shapley value  формулиров。当 d 较大时，计算沙晶利值变得不可能。通常的解决方案是随机抽样 permutations 来代替完整的 permutations 列表。我们发现了一种高级的随机抽样方案，可以为 estimation 提供更高的准确性。我们的采样方案基于设计实验 (DOE) 中的 combinatorial 结构，特别是 order-of-addition 实验设计，用于研究不同的组件顺序对输出的影响。我们证明了 obtained estimates 是无偏的，并可以 deterministically 恢复原始沙晶利值。 Both theoretical 和 simulations 结果表明，我们的 DOE-based 采样方案在 estimation 精度方面超过 SRS，并且在一些情况下可以 deterministically 恢复原始沙晶利值。 surprisingly，它还是微妙些快于 SRS。最后，我们对 C. elegans 神经系统和 9/11 恐怖袭击网络进行了实际数据分析。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Methods-for-Non-stationary-Online-Learning"><a href="#Efficient-Methods-for-Non-stationary-Online-Learning" class="headerlink" title="Efficient Methods for Non-stationary Online Learning"></a>Efficient Methods for Non-stationary Online Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08911">http://arxiv.org/abs/2309.08911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Zhao, Yan-Feng Xie, Lijun Zhang, Zhi-Hua Zhou</li>
<li>for: 这个论文主要针对非站点环境下的在线减少偏差和适应偏差的优化问题。</li>
<li>methods: 这个论文提出了一种基于 parameter-free online learning 的减少偏差和适应偏差优化方法，通过减少每轮投影数量从 $\mathcal{O}(\log T)$ 降低到 $1$，并且只需一次 gradient query 和一次函数评估。</li>
<li>results: 该论文的实验结果验证了论文中的理论结论，并且显示了该方法在非站点环境下的高效性和稳定性。<details>
<summary>Abstract</summary>
Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ to $1$. Moreover, our obtained algorithms require only one gradient query and one function evaluation at each round. Our technique hinges on the reduction mechanism developed in parameter-free online learning and requires non-trivial twists on non-stationary online methods. Empirical studies verify our theoretical findings.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出高效的方法来优化动态 regret和适应 regret，从而减少每个回合的射影数量从 $\mathcal{O}(\log T)$ 到 1。此外，我们的算法只需要一次 gradient query 和一次函数评估在每个回合。我们的技术基于在参数自由线上学习中的减少机制，需要非常简单的非站点线上方法的非常简单的非站点线上方法的修改。实验证明了我们的理论发现。
</details></li>
</ul>
<hr>
<h2 id="Robust-Online-Covariance-and-Sparse-Precision-Estimation-Under-Arbitrary-Data-Corruption"><a href="#Robust-Online-Covariance-and-Sparse-Precision-Estimation-Under-Arbitrary-Data-Corruption" class="headerlink" title="Robust Online Covariance and Sparse Precision Estimation Under Arbitrary Data Corruption"></a>Robust Online Covariance and Sparse Precision Estimation Under Arbitrary Data Corruption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08884">http://arxiv.org/abs/2309.08884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Yao, Shreyas Sundaram</li>
<li>for: 本研究旨在提出一种在在线enario中Robustly estimate covariance matrix的方法，以适应数据损害和攻击。</li>
<li>methods: 本文提出了一种基于trimmed-inner-product算法的在线方法，可以在面临arbitrary和敌意数据攻击的情况下 robustly estimate covariance matrix。</li>
<li>results: 本文提供了error bound和 convergence property的分析，证明了该方法可以准确地估计精度矩阵，即precision matrix。<details>
<summary>Abstract</summary>
Gaussian graphical models are widely used to represent correlations among entities but remain vulnerable to data corruption. In this work, we introduce a modified trimmed-inner-product algorithm to robustly estimate the covariance in an online scenario even in the presence of arbitrary and adversarial data attacks. At each time step, data points, drawn nominally independently and identically from a multivariate Gaussian distribution, arrive. However, a certain fraction of these points may have been arbitrarily corrupted. We propose an online algorithm to estimate the sparse inverse covariance (i.e., precision) matrix despite this corruption. We provide the error-bound and convergence properties of the estimates to the true precision matrix under our algorithms.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation: Gaussian 图模型广泛用于表示实体之间的相关性，但它们受到数据损害的威胁。在这项工作中，我们提出了一种修改后的内积法来在在线场景中稳定地估计协方差，即使在数据攻击中存在arbitrary和敌意的数据攻击。在每个时间步骤中，数据点会被独立地和identically从多变量 Gaussian 分布中采样，但一部分这些点可能被arbitrarily corrupted。我们提议一种在线算法来估计稀缺 inverse covariance（即精度）矩阵，即使在这些损害下。我们提供了估计错误 bound 和估计 converge 到真正精度矩阵的性质。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Learning-Rate-Tuning-in-the-Era-of-Large-Language-Models"><a href="#Rethinking-Learning-Rate-Tuning-in-the-Era-of-Large-Language-Models" class="headerlink" title="Rethinking Learning Rate Tuning in the Era of Large Language Models"></a>Rethinking Learning Rate Tuning in the Era of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08859">http://arxiv.org/abs/2309.08859</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlsysx/lrbenchplusplus">https://github.com/mlsysx/lrbenchplusplus</a></li>
<li>paper_authors: Hongpeng Jin, Wenqi Wei, Xuyu Wang, Wenbin Zhang, Yanzhao Wu</li>
<li>for: 本研究旨在探讨大语言模型（LLM）精度预测性能的最佳化问题，尤其是学习率的调整问题。</li>
<li>methods: 本研究使用了现有的学习率策略分析LLM fine-tuning中的挑战和机遇，并提出了LRBench++来 benchmark学习率策略并且为LLM fine-tuning和传统的深度神经网络（DNN）训练提供了一个共享的 benchmarking工具。</li>
<li>results: 实验分析表明，LRBench++可以帮助找到最佳的学习率策略，并且在LLM fine-tuning和传统DNN训练中显示出了不同的特点。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) represent the recent success of deep learning in achieving remarkable human-like predictive performance. It has become a mainstream strategy to leverage fine-tuning to adapt LLMs for various real-world applications due to the prohibitive expenses associated with LLM training. The learning rate is one of the most important hyperparameters in LLM fine-tuning with direct impacts on both fine-tuning efficiency and fine-tuned LLM quality. Existing learning rate policies are primarily designed for training traditional deep neural networks (DNNs), which may not work well for LLM fine-tuning. We reassess the research challenges and opportunities of learning rate tuning in the coming era of Large Language Models. This paper makes three original contributions. First, we revisit existing learning rate policies to analyze the critical challenges of learning rate tuning in the era of LLMs. Second, we present LRBench++ to benchmark learning rate policies and facilitate learning rate tuning for both traditional DNNs and LLMs. Third, our experimental analysis with LRBench++ demonstrates the key differences between LLM fine-tuning and traditional DNN training and validates our analysis.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:大型语言模型（LLM）表示深度学习最近的成功，它们可以达到人类预测性能的惊人水平。由于LLM训练的成本过高，因此现在主流的策略是通过微调来适应LLM应用。学习率是微调LLM中最重要的超参数，它直接影响微调效率和微调后LLM质量。现有的学习率策略主要适用于训练传统深度神经网络（DNN），可能不适用于LLM微调。我们重新评估LLM微调中的研究挑战和机遇，并提出三项原创贡献。首先，我们回顾现有的学习率策略，分析LLM微调中学习率的挑战。其次，我们提出LRBench++来评估学习率策略，并且为传统DNN和LLM进行微调。第三，我们通过LRBench++的实验分析，发现LLM微调和传统DNN训练存在重要的差异，并证明我们的分析。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-machines-work-in-unstructured-environments-by-differential-neural-computing"><a href="#Intelligent-machines-work-in-unstructured-environments-by-differential-neural-computing" class="headerlink" title="Intelligent machines work in unstructured environments by differential neural computing"></a>Intelligent machines work in unstructured environments by differential neural computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08835">http://arxiv.org/abs/2309.08835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengbo Wang, Shuo Gao, Chenyu Tang, Cong Li, Shurui Wang, Jiaqi Wang, Hubin Zhao, Guohua Hu, Arokia Nathan, Ravinder Dahiya, Luigi Occhipinti</li>
<li>for: 提高智能机器在实际世界中高效地处理未知环境信息，如人类一样。</li>
<li>methods: 基于卷积神经计算的干扰信号处理和学习方法，通过提取环境信息的主要特征并应用相关编码刺激到 memristors 中，成功实现了人类类似的处理未知环境信息能力，包括增强（&gt;720%）和适应（&lt;50%）机械刺激。</li>
<li>results: 方法在两种常见的智能机器应用中展现了良好的扩展性和泛化性，即物品抓取和自动驾驶。在前者中，通过学习未知物体特征（如锋利角和平滑表面），一个 memristor 在 1 ms 内实现了安全和稳定的抓取。在后者中，通过使用 40x25 个 memristor 数组，成功EXTRACTED 10 种未知环境决策信息（如超越车辆和行人），准确率达 94%。<details>
<summary>Abstract</summary>
Expecting intelligent machines to efficiently work in real world requires a new method to understand unstructured information in unknown environments with good accuracy, scalability and generalization, like human. Here, a memristive neural computing based perceptual signal differential processing and learning method for intelligent machines is presented, via extracting main features of environmental information and applying associated encoded stimuli to memristors, we successfully obtain human-like ability in processing unstructured environmental information, such as amplification (>720%) and adaptation (<50%) of mechanical stimuli. The method also exhibits good scalability and generalization, validated in two typical applications of intelligent machines: object grasping and autonomous driving. In the former, a robot hand experimentally realizes safe and stable grasping, through learning unknown object features (e.g., sharp corner and smooth surface) with a single memristor in 1 ms. In the latter, the decision-making information of 10 unstructured environments in autonomous driving (e.g., overtaking cars, pedestrians) are accurately (94%) extracted with a 40x25 memristor array. By mimicking the intrinsic nature of human low-level perception mechanisms in electronic memristive neural circuits, the proposed method is adaptable to diverse sensing technologies, helping intelligent machines to generate smart high-level decisions in real world.
</details>
<details>
<summary>摘要</summary>
要让智能机器在真实世界中有效工作，需要一种新的方法来理解未知环境中的无结构信息，具有人类水平的准确性、可扩展性和泛化能力。在这篇文章中，我们提出了基于干扰神经计算的嗅收信号处理和学习方法，通过提取环境信息的主要特征并将其与干扰器相关的编码刺激应用于干扰器中，成功地实现了人类水平的环境信息处理能力，包括增强（>720%）和适应（<50%）的机械刺激。这种方法还具有良好的扩展性和泛化能力，在智能机器的两个典型应用中进行验证：物体抓取和自动驾驶。在前者中，一个机器人手经过实验性地实现了安全和稳定的抓取，通过学习未知物体特征（如锋利角和平滑面）的一个干扰器，在1毫秒内完成。在后者中，一个40x25干扰器数组可以高精度地提取10种不同的自动驾驶环境中的决策信息（如超越车辆和步行人），准确率达94%。通过模仿人类低级感觉机制的内在性，我们的方法可以与多种感知技术结合，帮助智能机器在真实世界中产生智能高级决策。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/cs.LG_2023_09_16/" data-id="clp89doh600rii7880r4ga0vr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/eess.IV_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T09:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/eess.IV_2023_09_16/">eess.IV - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Wavelet-based-Topological-Loss-for-Low-Light-Image-Denoising"><a href="#Wavelet-based-Topological-Loss-for-Low-Light-Image-Denoising" class="headerlink" title="Wavelet-based Topological Loss for Low-Light Image Denoising"></a>Wavelet-based Topological Loss for Low-Light Image Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08975">http://arxiv.org/abs/2309.08975</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandra Malyugina, Nantheera Anantrasirichai, David Bull</li>
<li>for: 提高图像减雷的效果，增强图像的对比度和保留Texture信息</li>
<li>methods: 提出一种新的减雷损失函数，包括图像结构信息和常见的深度学习任务中的空间信息</li>
<li>results: 对BVI-Lowlight dataset进行训练，并在LPIPS metric中提高了25%，表明提出的损失函数能够更好地训练神经网络，提高图像减雷的效果。<details>
<summary>Abstract</summary>
Despite extensive research conducted in the field of image denoising, many algorithms still heavily depend on supervised learning and their effectiveness primarily relies on the quality and diversity of training data. It is widely assumed that digital image distortions are caused by spatially invariant Additive White Gaussian Noise (AWGN). However, the analysis of real-world data suggests that this assumption is invalid. Therefore, this paper tackles image corruption by real noise, providing a framework to capture and utilise the underlying structural information of an image along with the spatial information conventionally used for deep learning tasks. We propose a novel denoising loss function that incorporates topological invariants and is informed by textural information extracted from the image wavelet domain. The effectiveness of this proposed method was evaluated by training state-of-the-art denoising models on the BVI-Lowlight dataset, which features a wide range of real noise distortions. Adding a topological term to common loss functions leads to a significant increase in the LPIPS (Learned Perceptual Image Patch Similarity) metric, with the improvement reaching up to 25\%. The results indicate that the proposed loss function enables neural networks to learn noise characteristics better. We demonstrate that they can consequently extract the topological features of noise-free images, resulting in enhanced contrast and preserved textural information.
</details>
<details>
<summary>摘要</summary>
尽管在图像噪声除除领域进行了广泛的研究，许多算法仍然依赖于指导学习，其效果主要取决于训练数据的质量和多样性。通常认为数字图像扭曲是由空间不变的加速白噪声（AWGN）引起的，但是分析实际数据表示这个假设是无效的。因此，这篇论文通过图像扭曲实际噪声，提供了一个捕捉图像下的结构信息以及传统用于深度学习任务中的空间信息的框架。我们提议一种新的减噪损失函数，该函数包含拓扑 invariants 和通过图像振荡频谱领域提取的文本信息。我们通过在 BVI-Lowlight 数据集上训练现状顶峰的减噪模型，评估了该提议的效果。添加拓扑项到常见损失函数后，LPIPS（学习感知图像补充相似度）指标上的提升可达 25%。结果表明，我们的损失函数使得神经网络学习噪声特征更好。我们示出，神经网络可以根据噪声free图像的拓扑特征提取图像的增强对比度和保持文本信息。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/eess.IV_2023_09_16/" data-id="clp89doo101aai7886hbkhpti" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/16/eess.SP_2023_09_16/" class="article-date">
  <time datetime="2023-09-16T08:00:00.000Z" itemprop="datePublished">2023-09-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/16/eess.SP_2023_09_16/">eess.SP - 2023-09-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Optimal-Photodetector-Size-for-High-Speed-Free-Space-Optics-Receivers"><a href="#Optimal-Photodetector-Size-for-High-Speed-Free-Space-Optics-Receivers" class="headerlink" title="Optimal Photodetector Size for High-Speed Free-Space Optics Receivers"></a>Optimal Photodetector Size for High-Speed Free-Space Optics Receivers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09090">http://arxiv.org/abs/2309.09090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Salman Bashir, Qasim Zeeshan Ahmed, Mohamed-Slim Alouini</li>
<li>for: 优化光电器面积以实现高速度数据传输</li>
<li>methods: 使用closed-form解题法优化光电器面积，以 maximize通道容量</li>
<li>results: 实现了各种光无线通信系统的最大可达数据速率，包括长距离深空光链和短距离室内可见光通信系统<details>
<summary>Abstract</summary>
The selection of an optimal photodetector area is closely linked to the attainment of higher data rates in optical wireless communication receivers. If the photodetector area is too large, the channel capacity degrades due to lower modulation bandwidth of the detector. A smaller photodetector maximizes the bandwidth, but minimizes the captured signal power and the subsequent signal-to-noise ratio. Therein lies an opportunity in this trade-off to maximize the channel rate by choosing the optimal photodetector area. In this study, we have optimized the photodetector area in order to maximize the channel capacity of a free-space optical link for a diverse set of communication scenarios. We believe that the study in this paper in general -- and the closed-form solutions derived in this study in particular -- will be helpful to maximize achievable data rates of a wide gamut of optical wireless communication systems: from long range deep space optical links to short range indoor visible light communication systems.
</details>
<details>
<summary>摘要</summary>
选择最佳光探测面积对于光无线通信接收器的数据速率的实现具有紧密的关系。如果光探测面积太大，通道容量会降低因为探测器的模拟宽频率下降。小型光探测器可以最大化宽频率，但是它会降低捕获信号强度和相应的噪声比。这里就存在一个利点，通过选择最佳光探测面积可以最大化通道容量。在这项研究中，我们对光无线通信系统中的多种通信场景进行了优化光探测面积，以实现最大化通道容量。我们认为这项研究的总体成果以及 derive的关闭形解决方案会对各种光无线通信系统中的数据速率帮助提高。从深空光学链到indoor可见光通信系统，我们认为这项研究将对各种系统的实现数据速率具有帮助。
</details></li>
</ul>
<hr>
<h2 id="Split-Federated-Learning-for-6G-Enabled-Networks-Requirements-Challenges-and-Future-Directions"><a href="#Split-Federated-Learning-for-6G-Enabled-Networks-Requirements-Challenges-and-Future-Directions" class="headerlink" title="Split Federated Learning for 6G Enabled-Networks: Requirements, Challenges and Future Directions"></a>Split Federated Learning for 6G Enabled-Networks: Requirements, Challenges and Future Directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09086">http://arxiv.org/abs/2309.09086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Houda Hafi, Bouziane Brik, Pantelis A. Frangoudis, Adlen Ksentini</li>
<li>for: This paper is written to explore the potential of Split Federated Learning (SFL) in 6G wireless networks and its applications in various use cases.</li>
<li>methods: The paper uses a comprehensive study of SFL techniques and their deployment over 6G wireless networks, including an overview of three emerging collaborative learning paradigms and their comparison with existing approaches.</li>
<li>results: The paper highlights the need for SFL in 6G networks and its potential benefits in improving data privacy and reducing communication overhead, and identifies key technical challenges and future research directions in this area.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了探讨6G无线网络中使用Split Federated Learning（SFL）的潜力和其在不同应用场景中的运用。</li>
<li>methods: 论文采用了一项全面的SFL技术研究和其在6G无线网络上的部署，包括三种出现的共同学习方法的概述和与现有方法的比较。</li>
<li>results: 论文强调了SFL在6G网络中的需求和其可能提高数据隐私和通信负担的优点，并标识了这个领域的关键技术挑战和未来研究方向。<details>
<summary>Abstract</summary>
Sixth-generation (6G) networks anticipate intelligently supporting a wide range of smart services and innovative applications. Such a context urges a heavy usage of Machine Learning (ML) techniques, particularly Deep Learning (DL), to foster innovation and ease the deployment of intelligent network functions/operations, which are able to fulfill the various requirements of the envisioned 6G services. Specifically, collaborative ML/DL consists of deploying a set of distributed agents that collaboratively train learning models without sharing their data, thus improving data privacy and reducing the time/communication overhead. This work provides a comprehensive study on how collaborative learning can be effectively deployed over 6G wireless networks. In particular, our study focuses on Split Federated Learning (SFL), a technique recently emerged promising better performance compared with existing collaborative learning approaches. We first provide an overview of three emerging collaborative learning paradigms, including federated learning, split learning, and split federated learning, as well as of 6G networks along with their main vision and timeline of key developments. We then highlight the need for split federated learning towards the upcoming 6G networks in every aspect, including 6G technologies (e.g., intelligent physical layer, intelligent edge computing, zero-touch network management, intelligent resource management) and 6G use cases (e.g., smart grid 2.0, Industry 5.0, connected and autonomous systems). Furthermore, we review existing datasets along with frameworks that can help in implementing SFL for 6G networks. We finally identify key technical challenges, open issues, and future research directions related to SFL-enabled 6G networks.
</details>
<details>
<summary>摘要</summary>
We first provide an overview of three emerging collaborative learning paradigms, including federated learning, split learning, and split federated learning, as well as an overview of 6G networks along with their main vision and timeline of key developments. We then highlight the need for split federated learning towards the upcoming 6G networks in every aspect, including 6G technologies (e.g., intelligent physical layer, intelligent edge computing, zero-touch network management, intelligent resource management) and 6G use cases (e.g., smart grid 2.0, Industry 5.0, connected and autonomous systems). Furthermore, we review existing datasets along with frameworks that can help in implementing SFL for 6G networks.We finally identify key technical challenges, open issues, and future research directions related to SFL-enabled 6G networks. These include the need for better privacy guarantees, more efficient communication protocols, and better handling of non-iid data distributions. Additionally, there is a need for more research on the intersection of SFL and other emerging technologies such as edge computing, blockchain, and quantum computing.In summary, this work provides a comprehensive study on the potential of SFL for 6G networks, highlighting its benefits, challenges, and future research directions. The findings of this study can help researchers and practitioners to better understand the potential of SFL in 6G networks and to develop innovative solutions that can leverage the advantages of collaborative learning while ensuring data privacy and reducing communication overhead.
</details></li>
</ul>
<hr>
<h2 id="Blind-Deconvolution-of-Sparse-Graph-Signals-in-the-Presence-of-Perturbations"><a href="#Blind-Deconvolution-of-Sparse-Graph-Signals-in-the-Presence-of-Perturbations" class="headerlink" title="Blind Deconvolution of Sparse Graph Signals in the Presence of Perturbations"></a>Blind Deconvolution of Sparse Graph Signals in the Presence of Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09063">http://arxiv.org/abs/2309.09063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor M. Tenorio, Samuel Rey, Antonio G. Marques</li>
<li>for: 解压缩图像信号，以获取输入（源）和图像扩散过程中的筛选器（模型）。</li>
<li>methods: 提议使用优化算法来解压缩图像信号，并考虑图像扩散过程中的瑕疵。</li>
<li>results: 预liminary numerical experiments表明，提议的算法可以有效地解压缩图像信号。<details>
<summary>Abstract</summary>
Blind deconvolution over graphs involves using (observed) output graph signals to obtain both the inputs (sources) as well as the filter that drives (models) the graph diffusion process. This is an ill-posed problem that requires additional assumptions, such as the sources being sparse, to be solvable. This paper addresses the blind deconvolution problem in the presence of imperfect graph information, where the observed graph is a perturbed version of the (unknown) true graph. While not having perfect knowledge of the graph is arguably more the norm than the exception, the body of literature on this topic is relatively small. This is partly due to the fact that translating the uncertainty about the graph topology to standard graph signal processing tools (e.g. eigenvectors or polynomials of the graph) is a challenging endeavor. To address this limitation, we propose an optimization-based estimator that solves the blind identification in the vertex domain, aims at estimating the inverse of the generating filter, and accounts explicitly for additive graph perturbations. Preliminary numerical experiments showcase the effectiveness and potential of the proposed algorithm.
</details>
<details>
<summary>摘要</summary>
盲损减殖在图上 involve 使用（观察）输出图像信号来获得输入（源）以及驱动图像扩散过程的筛选器。这是一个不充分定义的问题，需要更多的假设，如源是稀疏的，才能解决。本文 Addresses 盲损减殖问题在不完整的图像信息下，其中观察到的图像是真实图像未知的 perturbed 版本。尽管不具备完整的图像信息是更常见的情况，但相关的文献较少，这可能是因为将图像 topology 不确定性翻译到标准的图像处理工具（例如对角线或图像权值）是一个困难的任务。为解决这些限制，我们提出了一种优化基于的估计器，解决盲损减殖问题在顶点域，计算出生成器的逆，并考虑到添加性的图像杂化。初步的数字实验显示了提案的算法的有效性和潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Low-Latency-FFT-IFFT-Cascade-Architecture"><a href="#A-Low-Latency-FFT-IFFT-Cascade-Architecture" class="headerlink" title="A Low-Latency FFT-IFFT Cascade Architecture"></a>A Low-Latency FFT-IFFT Cascade Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09035">http://arxiv.org/abs/2309.09035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keshab K. Parhi</li>
<li>for: 这篇论文描述了一种不需要中间缓冲的幂等快速傅立卷-快速傅立卷架构的设计。</li>
<li>methods: 该架构使用叠加来实现部分并行的FFT和IFFT架构。通过不同的叠加集来设计FFT和IFFT架构，但是对于给定的叠加FFT架构，存在一个唯一的叠加集来设计IFFT架构，无需中间缓冲。</li>
<li>results: 该方法可以避免中间缓冲，降低延迟和释放内存空间。此外，该方法还可以扩展到多通道时间序列的并行处理。相比一个具有相同叠加集的设计，该架构可以节省约N&#x2F;2个存储元素和N&#x2F;4个时钟周期的延迟。对于2个扩展FFT-IFFT架构，则分别节省约N&#x2F;2个存储元素和N&#x2F;2个时钟周期的延迟。<details>
<summary>Abstract</summary>
This paper addresses the design of a partly-parallel cascaded FFT-IFFT architecture that does not require any intermediate buffer. Folding can be used to design partly-parallel architectures for FFT and IFFT. While many cascaded FFT-IFFT architectures can be designed using various folding sets for the FFT and the IFFT, for a specified folded FFT architecture, there exists a unique folding set to design the IFFT architecture that does not require an intermediate buffer. Such a folding set is designed by processing the output of the FFT as soon as possible (ASAP) in the folded IFFT. Elimination of the intermediate buffer reduces latency and saves area. The proposed approach is also extended to interleaved processing of multi-channel time-series. The proposed FFT-IFFT cascade architecture saves about N/2 memory elements and N/4 clock cycles of latency compared to a design with identical folding sets. For the 2-interleaved FFT-IFFT cascade, the memory and latency savings are, respectively, N/2 units and N/2 clock cycles, compared to a design with identical folding sets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Localization-with-Noisy-Android-Raw-GNSS-Measurements"><a href="#Localization-with-Noisy-Android-Raw-GNSS-Measurements" class="headerlink" title="Localization with Noisy Android Raw GNSS Measurements"></a>Localization with Noisy Android Raw GNSS Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08936">http://arxiv.org/abs/2309.08936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Weng, Keck Voon Ling</li>
<li>for: 本研究旨在利用AndroidRaw全球导航卫星系统(GNSS)测量来进行高精度定位任务，传统上由特殊GNSS接收器进行。</li>
<li>methods: 本研究使用Moveing Horizon Estimation(MHE)、Extended Kalman Filter(EKF)和Rauch-Tung-Striebel(RTS)缓和器来抑制噪声。</li>
<li>results: 实验结果显示，RTS缓和器可以实现最佳的定位性能，在静止和动态情况下对应位置误差降低76.4%和46.5%，相比基准weighted least squares(WLS)方法。<details>
<summary>Abstract</summary>
Android raw Global Navigation Satellite System (GNSS) measurements are expected to bring power to take on demanding localization tasks that are traditionally performed by specialized GNSS receivers. The hardware constraints, however, make Android raw GNSS measurements much noisier than geodetic-quality ones. This study elucidates the principles of localization using Android raw GNSS measurements and leverages Moving Horizon Estimation (MHE), Extended Kalman Filter (EKF), and Rauch-Tung-Striebel (RTS) smoother for noise suppression. The experiment results showcase that RTS smoother achieves the best localization performance and yields a remarkable reduction of 76.4\% and 46.5\% in horizontal positioning error during static and dynamic scenarios compared to the baseline weighted least squares (WLS) method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Scalable-Multiuser-Immersive-Communications-with-Multi-numerology-and-Mini-slot"><a href="#Scalable-Multiuser-Immersive-Communications-with-Multi-numerology-and-Mini-slot" class="headerlink" title="Scalable Multiuser Immersive Communications with Multi-numerology and Mini-slot"></a>Scalable Multiuser Immersive Communications with Multi-numerology and Mini-slot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08906">http://arxiv.org/abs/2309.08906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Hu, Jiazhi Peng, Lifeng Wang, Kai-Kit Wong</li>
<li>for: 这个论文是为了研究多用户 immerse 通信网络，在这些网络中不同的用户设备可能需要不同的扩展现实（XR）服务。</li>
<li>methods: 该论文提出了一种可扩展的时间频率资源分配方法，基于多 numerology 和 mini-slot。</li>
<li>results: 该方法可以有效地提高多用户 immerse 通信网络中的总体品质经验（QoE），并且可以适应不同用户的 QoE 限制。<details>
<summary>Abstract</summary>
This paper studies multiuser immersive communications networks in which different user equipment may demand various extended reality (XR) services. In such heterogeneous networks, time-frequency resource allocation needs to be more adaptive since XR services are usually multi-modal and latency-sensitive. To this end, we develop a scalable time-frequency resource allocation method based on multi-numerology and mini-slot. To appropriately determining the discrete parameters of multi-numerology and mini-slot for multiuser immersive communications, the proposed method first presents a novel flexible time-frequency resource block configuration, then it leverages the deep reinforcement learning to maximize the total quality-of-experience (QoE) under different users' QoE constraints. The results confirm the efficiency and scalability of the proposed time-frequency resource allocation method.
</details>
<details>
<summary>摘要</summary>
To determine the appropriate discrete parameters of multi-numerology and mini-slot for multi-user immersive communications, the proposed method begins by presenting a flexible time-frequency resource block configuration. Then, it utilizes deep reinforcement learning to maximize the total quality-of-experience (QoE) while meeting the different users' QoE constraints.The results demonstrate the efficiency and scalability of the proposed time-frequency resource allocation method.
</details></li>
</ul>
<hr>
<h2 id="CDDM-Channel-Denoising-Diffusion-Models-for-Wireless-Semantic-Communications"><a href="#CDDM-Channel-Denoising-Diffusion-Models-for-Wireless-Semantic-Communications" class="headerlink" title="CDDM: Channel Denoising Diffusion Models for Wireless Semantic Communications"></a>CDDM: Channel Denoising Diffusion Models for Wireless Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08895">http://arxiv.org/abs/2309.08895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Wu, Zhiyong Chen, Dazhi He, Liang Qian, Yin Xu, Meixia Tao, Wenjun Zhang<br>for: 这篇论文主要目的是提出一种新的物理层模块——渠道减噪扩散模型（CDDM），用于semantic通信系统中减噪。methods: 该论文使用了扩散模型（DM），特别是针对渠道模型的扩散进行特定的设计，以及针对渠道模型的特殊化采样和训练算法。results: 实验结果表明，CDDM可以减少接收信号的条件熵，并且在小步骤下可以有效减少MSE。此外，joint CDDM和JSCC系统在图像传输中表现更好，并且比JSCC系统和传统的JPEG2000与LDPC编码方法更好。<details>
<summary>Abstract</summary>
Diffusion models (DM) can gradually learn to remove noise, which have been widely used in artificial intelligence generated content (AIGC) in recent years. The property of DM for eliminating noise leads us to wonder whether DM can be applied to wireless communications to help the receiver mitigate the channel noise. To address this, we propose channel denoising diffusion models (CDDM) for semantic communications over wireless channels in this paper. CDDM can be applied as a new physical layer module after the channel equalization to learn the distribution of the channel input signal, and then utilizes this learned knowledge to remove the channel noise. We derive corresponding training and sampling algorithms of CDDM according to the forward diffusion process specially designed to adapt the channel models and theoretically prove that the well-trained CDDM can effectively reduce the conditional entropy of the received signal under small sampling steps. Moreover, we apply CDDM to a semantic communications system based on joint source-channel coding (JSCC) for image transmission. Extensive experimental results demonstrate that CDDM can further reduce the mean square error (MSE) after minimum mean square error (MMSE) equalizer, and the joint CDDM and JSCC system achieves better performance than the JSCC system and the traditional JPEG2000 with low-density parity-check (LDPC) code approach.
</details>
<details>
<summary>摘要</summary>
Diffusion models (DM) 可以慢慢地学习去除噪音，已经广泛应用于人工智能生成内容 (AIGC) 领域的最新技术。DM 对于通信频率 Canal 的噪音 mitigation 提供了一个可能性，因此我们在本文中提出了通道减噪扩散模型 (CDDM)。CDDM 可以作为通信物理层模块，在通道均衡后学习通道输入信号的分布，然后利用这些学习知识来去除通道噪音。我们提出了对应的训练和采样算法，并经过特殊设计的前进扩散过程来适应通道模型，并理论上证明了充分训练 CDDM 可以在小步骤下降低接收信号的 conditional entropy。此外，我们应用 CDDM 到基于联合源-通道编码 (JSCC) 的图像传输系统中。实验结果表明，CDDM 可以在 MMSE 等式后进行加权平均值补做，并且联合 CDDM 和 JSCC 系统可以在 JSCC 系统和传统的 JPEG2000 低密度极性码 (LDPC) 方法之上具有更好的性能。
</details></li>
</ul>
<hr>
<h2 id="Demo-Intelligent-Radar-Detection-in-CBRS-Band-in-the-Colosseum-Wireless-Network-Emulator"><a href="#Demo-Intelligent-Radar-Detection-in-CBRS-Band-in-the-Colosseum-Wireless-Network-Emulator" class="headerlink" title="Demo: Intelligent Radar Detection in CBRS Band in the Colosseum Wireless Network Emulator"></a>Demo: Intelligent Radar Detection in CBRS Band in the Colosseum Wireless Network Emulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08861">http://arxiv.org/abs/2309.08861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Villa, Daniel Uvaydov, Leonardo Bonati, Pedram Johari, Josep Miquel Jornet, Tommaso Melodia</li>
<li>for: 这个论文是为了研究商业激光波形与无线网络共同运行的技术。</li>
<li>methods: 这个研究使用了Colosseum，全球最大的无线网络模拟器，以及硬件在回路的技术来模拟实际的无线网络环境。</li>
<li>results: 实验结果显示，使用机器学习代理人在基站中训练时，可以实现88%的检测精度，检测时间为137ms。<details>
<summary>Abstract</summary>
The ever-growing number of wireless communication devices and technologies demands spectrum-sharing techniques. Effective coexistence management is crucial to avoid harmful interference, especially with critical systems like nautical and aerial radars in which incumbent radios operate mission-critical communication links. In this demo, we showcase a framework that leverages Colosseum, the world's largest wireless network emulator with hardware-in-the-loop, as a playground to study commercial radar waveforms coexisting with a cellular network in CBRS band in complex environments. We create an ad-hoc high-fidelity spectrum-sharing scenario for this purpose. We deploy a cellular network to collect IQ samples with the aim of training an ML agent that runs at the base station. The agent has the goal of detecting incumbent radar transmissions and vacating the cellular bandwidth to avoid interfering with the radar operations. Our experiment results show an average detection accuracy of 88%, with an average detection time of 137 ms.
</details>
<details>
<summary>摘要</summary>
随着无线通信设备和技术的不断增加，需要 spectrum-sharing 技术来实现共享频率。有效地管理共享是关键，以避免干扰，特别是与航空和海上雷达系统相关的核心通信链接。在这个 demo 中，我们利用 Colosseum，全球最大的无线网络模拟器，作为一个实验室，研究商业雷达波形在 CBRS 频级上与无线网络共享资源的可行性。我们创建了一个高精度的 spectrum-sharing enario，并将一个 cellular 网络部署到收集 IQ 样本，以用于训练基站上运行的机器学习代理。这个代理的目标是检测 incumbent 雷达传输，并让 cellular 频率占用避免与雷达操作干扰。我们的实验结果显示，检测精度平均为 88%，检测时间平均为 137 ms。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/16/eess.SP_2023_09_16/" data-id="clp89dopp01e7i788gwml2c3v" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/15/cs.SD_2023_09_15/" class="article-date">
  <time datetime="2023-09-15T15:00:00.000Z" itemprop="datePublished">2023-09-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/15/cs.SD_2023_09_15/">cs.SD - 2023-09-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Stack-and-Delay-a-new-codebook-pattern-for-music-generation"><a href="#Stack-and-Delay-a-new-codebook-pattern-for-music-generation" class="headerlink" title="Stack-and-Delay: a new codebook pattern for music generation"></a>Stack-and-Delay: a new codebook pattern for music generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08804">http://arxiv.org/abs/2309.08804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gael Le Lan, Varun Nagaraja, Ernie Chang, David Kant, Zhaoheng Ni, Yangyang Shi, Forrest Iandola, Vikas Chandra</li>
<li>for: 这 paper 是为了提高语音生成模型的执行速度而写的。</li>
<li>methods: 这 paper 使用了一种新的 stack-and-delay 解码策略，以提高 auto-regressive 解码的速度。</li>
<li>results: 对于同等效果预算，这 paper 的新策略可以在对 GPU 进行批处理时提高生成速度，并且在对比 vanilla flat 解码法时，质量几乎相当。<details>
<summary>Abstract</summary>
In language modeling based music generation, a generated waveform is represented by a sequence of hierarchical token stacks that can be decoded either in an auto-regressive manner or in parallel, depending on the codebook patterns. In particular, flattening the codebooks represents the highest quality decoding strategy, while being notoriously slow. To this end, we propose a novel stack-and-delay style of decoding strategy to improve upon the flat pattern decoding where generation speed is four times faster as opposed to vanilla flat decoding. This brings the inference time close to that of the delay decoding strategy, and allows for faster inference on GPU for small batch sizes. For the same inference efficiency budget as the delay pattern, we show that the proposed approach performs better in objective evaluations, almost closing the gap with the flat pattern in terms of quality. The results are corroborated by subjective evaluations which show that samples generated by the new model are slightly more often preferred to samples generated by the competing model given the same text prompts.
</details>
<details>
<summary>摘要</summary>
在语言模型基于音乐生成中，生成波形被表示为一个层次化token堆，可以在某些情况下以自动递归方式或平行方式解码，具体取决于codebook Pattern。特别是，平滑codebooks表示最高质量解码策略，但却非常慢。为此，我们提出了一种新的堆延式解码策略，以提高对于平滑解码的速度。这将执行时间与延迟解码策略相似，并在小批处理时在GPU上进行更快的执行。对于同样的推理效率预算，我们表明了我们的方法在对象评价中比 delay Pattern 更好，几乎与平滑Pattern 相近的质量。结果得到了subjective评价的支持，显示新模型生成的样本在同一个文本提示下被轻微更多地选择。
</details></li>
</ul>
<hr>
<h2 id="Music-Source-Separation-Based-on-a-Lightweight-Deep-Learning-Framework-DTTNET-DUAL-PATH-TFC-TDF-UNET"><a href="#Music-Source-Separation-Based-on-a-Lightweight-Deep-Learning-Framework-DTTNET-DUAL-PATH-TFC-TDF-UNET" class="headerlink" title="Music Source Separation Based on a Lightweight Deep Learning Framework (DTTNET: DUAL-PATH TFC-TDF UNET)"></a>Music Source Separation Based on a Lightweight Deep Learning Framework (DTTNET: DUAL-PATH TFC-TDF UNET)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08684">http://arxiv.org/abs/2309.08684</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junyuchen-cjy/dttnet-pytorch">https://github.com/junyuchen-cjy/dttnet-pytorch</a></li>
<li>paper_authors: Junyu Chen, Susmitha Vekkot, Pancham Shukla</li>
<li>for: 本研究旨在提出一种轻量级的音乐源分离模型（DTTNet），以提高音乐源分离的效果。</li>
<li>methods: 本文使用了一种基于双路模块和时域频域卷积的时间分布式全连接卷积神经网络（TFC-TDF UNet），并对模型进行了训练。</li>
<li>results: 对于 vocals 部分，DTTNet 可以达到 10.12 dB cSDR，比 Bandsplit RNN (BSRNN) 高出 0.11 dB，但具有 86.7%  fewer 参数。<details>
<summary>Abstract</summary>
Music source separation (MSS) aims to extract 'vocals', 'drums', 'bass' and 'other' tracks from a piece of mixed music. While deep learning methods have shown impressive results, there is a trend toward larger models. In our paper, we introduce a novel and lightweight architecture called DTTNet, which is based on Dual-Path Module and Time-Frequency Convolutions Time-Distributed Fully-connected UNet (TFC-TDF UNet). DTTNet achieves 10.12 dB cSDR on 'vocals' compared to 10.01 dB reported for Bandsplit RNN (BSRNN) but with 86.7% fewer parameters. We also assess pattern-specific performance and model generalization for intricate audio patterns.
</details>
<details>
<summary>摘要</summary>
音乐源分离（MSS）目标是从混合音乐中提取“声乐”、“鼓”、“低音”和“其他”多个轨道。深度学习方法已经表现出色，但是现在有一趋势是增大模型。在我们的论文中，我们介绍了一种新的轻量级架构，称为DTTNet，它基于双路模块和时域频域卷积（TFC-TDF UNet）。DTTNet实现了10.12 dB的清晰度（cSDR），比BSRNN（Bandsplit RNN）的10.01 dB高，但具有86.7%的参数数量少。我们还评估了模型对复杂音乐 patrern的特定性能和通用性。
</details></li>
</ul>
<hr>
<h2 id="Chunked-Attention-based-Encoder-Decoder-Model-for-Streaming-Speech-Recognition"><a href="#Chunked-Attention-based-Encoder-Decoder-Model-for-Streaming-Speech-Recognition" class="headerlink" title="Chunked Attention-based Encoder-Decoder Model for Streaming Speech Recognition"></a>Chunked Attention-based Encoder-Decoder Model for Streaming Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08436">http://arxiv.org/abs/2309.08436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Zeineldeen, Albert Zeyer, Ralf Schlüter, Hermann Ney</li>
<li>for: 这篇论文旨在提出一种流处理的注意力基于encoder-decoder模型，其中 either the decoder, or both the encoder and decoder,  operate on pre-defined, fixed-size windows called chunks.</li>
<li>methods: 该模型使用特殊的 end-of-chunk (EOC) 符号来进行chunk boundaries的标识，而不是 convential end-of-sequence 符号。此外，模型还 explores 其他与标准转录器模型的差异。</li>
<li>results: 通过在 Librispeech 和 TED-LIUM-v2 上进行实验，并将 consecutives sequences concatenated for long-form trials，发现该流处理模型与非流处理模型的性能相对 compatible，并且在长型语音总结very well。<details>
<summary>Abstract</summary>
We study a streamable attention-based encoder-decoder model in which either the decoder, or both the encoder and decoder, operate on pre-defined, fixed-size windows called chunks. A special end-of-chunk (EOC) symbol advances from one chunk to the next chunk, effectively replacing the conventional end-of-sequence symbol. This modification, while minor, situates our model as equivalent to a transducer model that operates on chunks instead of frames, where EOC corresponds to the blank symbol. We further explore the remaining differences between a standard transducer and our model. Additionally, we examine relevant aspects such as long-form speech generalization, beam size, and length normalization. Through experiments on Librispeech and TED-LIUM-v2, and by concatenating consecutive sequences for long-form trials, we find that our streamable model maintains competitive performance compared to the non-streamable variant and generalizes very well to long-form speech.
</details>
<details>
<summary>摘要</summary>
我们研究了一个流处理器基于注意力的编解码器模型，其中编码器或解码器都操作在预定的固定大小窗口（chunk）上。特殊的结束chunk（EOC）符号在一个chunk到下一个chunk之间进行转移，从而替代传统的结束序列符号。这种修改虽小，但将我们的模型与帧模型等同起来，其中EOC符号与空符号相对应。我们进一步探讨了标准转录器和我们模型之间的剩余差异。我们还考虑了长форма语音总体化、扫描大小和长度 нормализация等相关因素。通过对Librispeech和TED-LIUM-v2上进行实验，并将 consecutivesequences concatenate для长形试验，我们发现我们的流处理器模型与非流处理器模型的性能相比具有竞争力，并且对长形语音总体化很好。
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Active-Speaker-Extraction-for-Sparsely-Overlapped-Multi-talker-Speech"><a href="#Audio-Visual-Active-Speaker-Extraction-for-Sparsely-Overlapped-Multi-talker-Speech" class="headerlink" title="Audio-Visual Active Speaker Extraction for Sparsely Overlapped Multi-talker Speech"></a>Audio-Visual Active Speaker Extraction for Sparsely Overlapped Multi-talker Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08408">http://arxiv.org/abs/2309.08408</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrjunjieli/activeextract">https://github.com/mrjunjieli/activeextract</a></li>
<li>paper_authors: Junjie Li, Ruijie Tao, Zexu Pan, Meng Ge, Shuai Wang, Haizhou Li</li>
<li>for: 本研究旨在提高target speaker抽取的精度，特别是在稀有 overlap的场景下。</li>
<li>methods: 本文提出了一种名为ActiveExtract的音频视频 speaker抽取模型，该模型利用音频视频活跃 speaker检测（ASD）来直接提供目标说话者的帧级活动信息，同时使用ASD的中间特征表示来鉴别说话lip同步。</li>
<li>results: 实验结果表明， compared to基线，我们的模型在不同的 overlap ratio下均表现出超过4dB的提升，这表明我们的模型可以在稀有 overlap的场景下提高target speaker抽取的精度。<details>
<summary>Abstract</summary>
Target speaker extraction aims to extract the speech of a specific speaker from a multi-talker mixture as specified by an auxiliary reference. Most studies focus on the scenario where the target speech is highly overlapped with the interfering speech. However, this scenario only accounts for a small percentage of real-world conversations. In this paper, we aim at the sparsely overlapped scenarios in which the auxiliary reference needs to perform two tasks simultaneously: detect the activity of the target speaker and disentangle the active speech from any interfering speech. We propose an audio-visual speaker extraction model named ActiveExtract, which leverages speaking activity from audio-visual active speaker detection (ASD). The ASD directly provides the frame-level activity of the target speaker, while its intermediate feature representation is trained to discriminate speech-lip synchronization that could be used for speaker disentanglement. Experimental results show our model outperforms baselines across various overlapping ratios, achieving an average improvement of more than 4 dB in terms of SI-SNR.
</details>
<details>
<summary>摘要</summary>
target speaker extraction aims to extract the speech of a specific speaker from a multi-talker mixture as specified by an auxiliary reference. most studies focus on the scenario where the target speech is highly overlapped with the interfering speech. however, this scenario only accounts for a small percentage of real-world conversations. in this paper, we aim at the sparsely overlapped scenarios in which the auxiliary reference needs to perform two tasks simultaneously: detect the activity of the target speaker and disentangle the active speech from any interfering speech. we propose an audio-visual speaker extraction model named activeextract, which leverages speaking activity from audio-visual active speaker detection (asd). the asd directly provides the frame-level activity of the target speaker, while its intermediate feature representation is trained to discriminate speech-lip synchronization that could be used for speaker disentanglement. experimental results show our model outperforms baselines across various overlapping ratios, achieving an average improvement of more than 4 dB in terms of si-snr.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Audio-free-Prompt-Tuning-for-Language-Audio-Models"><a href="#Audio-free-Prompt-Tuning-for-Language-Audio-Models" class="headerlink" title="Audio-free Prompt Tuning for Language-Audio Models"></a>Audio-free Prompt Tuning for Language-Audio Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08357">http://arxiv.org/abs/2309.08357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Li, Xiangdong Wang, Hong Liu</li>
<li>for: 这个论文想要协助CLAP模型从语言 Audio域预训练中提取特征，以便在不需要标注的域音频数据下进行适应。</li>
<li>methods: 我们提议一种不需要域音频数据的CLAP模型调教方法，通过利用CLAP模型的modalitiesAlignment来调整一些文本提示符，以便更好地调整模型空间，避免过拟合见到的类别。此外，我们还探索了多层排序提示的策略，以 fusionglobal和local信息。</li>
<li>results: 我们的方法可以提高CLAP模型的性能和训练效率，并在零例推理中对未经见的类别进行识别，并且比vanilla CLAP更好地转移知识。此外，我们的方法还可以在只知道下游类别名称的情况下进行适应。<details>
<summary>Abstract</summary>
Contrastive Language-Audio Pretraining (CLAP) is pre-trained to associate audio features with human language, making it a natural zero-shot classifier to recognize unseen sound categories. To adapt CLAP to downstream tasks, prior works inevitably require labeled domain audios, which limits their scalability under data scarcity and deprives them of the capability to detect novel classes as the original CLAP. In this work, by leveraging the modality alignment in CLAP, we propose an efficient audio-free prompt tuning scheme aimed at optimizing a few prompt tokens from texts instead of audios, which regularizes the model space to avoid overfitting the seen classes as well. Based on this, a multi-grained prompt design is further explored to fuse global and local information. Experiments on several tasks demonstrate that our approach can boost the CLAP and outperform other training methods on model performance and training efficiency. While conducting zero-shot inference on unseen categories, it still shows better transferability than the vanilla CLAP. Moreover, our method is flexible enough even if only knowing the downstream class names. The code will be released soon.
</details>
<details>
<summary>摘要</summary>
“对于语音识别任务，我们提出了一个有效的无音训练方法，可以将文本提示调整为CLAP模型的条件，以提高模型的性能和训练效率。这个方法基于CLAP模型中的modalità对齐，可以将文本提示调整为CLAP模型的条件，以避免模型过拟合见到的类别。我们还提出了一个多层次提示设计，可以融合全球和本地信息。实验结果显示，我们的方法可以提高CLAP模型的性能和训练效率，并且在零shot推断中也表现出比vanilla CLAP更好的转移性。此外，我们的方法可以让你只知道下游类别名称来进行训练，并且还可以在零shot推断中进行推断。我们将将代码发布 soon。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Sound-Event-Detection-with-Local-and-Global-Consistency-Regularization"><a href="#Semi-supervised-Sound-Event-Detection-with-Local-and-Global-Consistency-Regularization" class="headerlink" title="Semi-supervised Sound Event Detection with Local and Global Consistency Regularization"></a>Semi-supervised Sound Event Detection with Local and Global Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08355">http://arxiv.org/abs/2309.08355</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Li, Xiangdong Wang, Hong Liu, Rui Tao, Long Yan, Kazushige Ouchi</li>
<li>for: 这 paper 是为了提高 semi-supervised sound event detection 的性能而写的。</li>
<li>methods: 这 paper 使用了 Local and Global Consistency (LGC) regularization scheme，包括 audio CutMix 和特制的 contrastive loss，以促进模型在 label- 和 feature-level 上的改进。</li>
<li>results: 实验结果表明，LGC 超越了同等设置的基eline system，并且可以与现有方法相结合以实现进一步的改进。<details>
<summary>Abstract</summary>
Learning meaningful frame-wise features on a partially labeled dataset is crucial to semi-supervised sound event detection. Prior works either maintain consistency on frame-level predictions or seek feature-level similarity among neighboring frames, which cannot exploit the potential of unlabeled data. In this work, we design a Local and Global Consistency (LGC) regularization scheme to enhance the model on both label- and feature-level. The audio CutMix is introduced to change the contextual information of clips. Then, the local consistency is adopted to encourage the model to leverage local features for frame-level predictions, and the global consistency is applied to force features to align with global prototypes through a specially designed contrastive loss. Experiments on the DESED dataset indicate the superiority of LGC, surpassing its respective competitors largely with the same settings as the baseline system. Besides, combining LGC with existing methods can obtain further improvements. The code will be released soon.
</details>
<details>
<summary>摘要</summary>
学习有意义的帧级特征是 semi-supervised 音频事件检测中的关键。先前的工作ether maintain consistency on frame-level predictions or seek feature-level similarity among neighboring frames, 这些方法无法利用无标签数据的潜力。在这种工作中，我们设计了 Local and Global Consistency (LGC) 规范来提高模型在标签和特征水平上。音频 CutMix 被引入，改变clip的Contextual information。然后，本地一致性被采用，以便使模型利用本地特征进行帧级预测，而全球一致性被应用，通过特殊的对比损失来让特征与全球谱系对齐。DESED 数据集的实验表明 LGC 的优越性，大大超越了同样的设置的基eline system。此外，将 LGC 与现有方法结合可以获得进一步的改进。代码即将发布。
</details></li>
</ul>
<hr>
<h2 id="The-Multimodal-Information-Based-Speech-Processing-MISP-2023-Challenge-Audio-Visual-Target-Speaker-Extraction"><a href="#The-Multimodal-Information-Based-Speech-Processing-MISP-2023-Challenge-Audio-Visual-Target-Speaker-Extraction" class="headerlink" title="The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction"></a>The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08348">http://arxiv.org/abs/2309.08348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shilong Wu, Chenxi Wang, Hang Chen, Yusheng Dai, Chenyue Zhang, Ruoyu Wang, Hongbo Lan, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, Odette Scharenborg, Zhong-Qiu Wang, Jia Pan, Jianqing Gao</li>
<li>for: 本研究的目的是为了提高后端语音识别系统的准确率，通过使用音视频目标说话人抽取（AVTSE）任务。</li>
<li>methods: 本研究使用了音视频Speech Enhancement（MISP）挑战的数据集，并提供了一个基eline系统来支持参与者的参与。</li>
<li>results: 实验结果表明，AVTSE任务在真实的音响环境中非常具有挑战性，参与者可能会遇到各种问题。<details>
<summary>Abstract</summary>
Previous Multimodal Information based Speech Processing (MISP) challenges mainly focused on audio-visual speech recognition (AVSR) with commendable success. However, the most advanced back-end recognition systems often hit performance limits due to the complex acoustic environments. This has prompted a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE) task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand Challenges. Unlike existing audio-visual speech enhance-ment challenges primarily focused on simulation data, the MISP 2023 challenge uniquely explores how front-end speech processing, combined with visual clues, impacts back-end tasks in real-world scenarios. This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments. This paper delivers a thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge. It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Speech-dependent-Modeling-of-Own-Voice-Transfer-Characteristics-for-In-ear-Microphones-in-Hearables"><a href="#Speech-dependent-Modeling-of-Own-Voice-Transfer-Characteristics-for-In-ear-Microphones-in-Hearables" class="headerlink" title="Speech-dependent Modeling of Own Voice Transfer Characteristics for In-ear Microphones in Hearables"></a>Speech-dependent Modeling of Own Voice Transfer Characteristics for In-ear Microphones in Hearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08294">http://arxiv.org/abs/2309.08294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mattes Ohlenbusch, Christian Rollwage, Simon Doclo</li>
<li>for: 增强听力器中的耳壳内麦icrophone信号质量使用算法，以joint bandwidth extension、equalization和噪声减少。</li>
<li>methods: 基于phoneme认识的speech-dependent系统Identification模型，用于模拟耳壳内麦icrophone recording。</li>
<li>results: 使用提议的speech-dependent模型可以更好地模拟耳壳内麦icrophone recording，并且可以更好地泛化到不同的说话人。<details>
<summary>Abstract</summary>
Many hearables contain an in-ear microphone, which may be used to capture the own voice of its user in noisy environments. Since the in-ear microphone mostly records body-conducted speech due to ear canal occlusion, it suffers from band-limitation effects while only capturing a limited amount of external noise. To enhance the quality of the in-ear microphone signal using algorithms aiming at joint bandwidth extension, equalization, and noise reduction, it is desirable to have an accurate model of the own voice transfer characteristics between the entrance of the ear canal and the in-ear microphone. Such a model can be used, e.g., to simulate a large amount of in-ear recordings to train supervised learning-based algorithms. Since previous research on ear canal occlusion suggests that own voice transfer characteristics depend on speech content, in this contribution we propose a speech-dependent system identification model based on phoneme recognition. We assess the accuracy of simulating own voice speech by speech-dependent and speech-independent modeling and investigate how well modeling approaches are able to generalize to different talkers. Simulation results show that using the proposed speech-dependent model is preferable for simulating in-ear recordings compared to using a speech-independent model.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Head-Related-Transfer-Function-Interpolation-with-a-Spherical-CNN"><a href="#Head-Related-Transfer-Function-Interpolation-with-a-Spherical-CNN" class="headerlink" title="Head-Related Transfer Function Interpolation with a Spherical CNN"></a>Head-Related Transfer Function Interpolation with a Spherical CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08290">http://arxiv.org/abs/2309.08290</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xingyuaudio/HRTF-SCNN">https://github.com/xingyuaudio/HRTF-SCNN</a></li>
<li>paper_authors: Xingyu Chen, Fei Ma, Yile Zhang, Amy Bastine, Prasanga N. Samarasinghe</li>
<li>for: 这篇论文旨在提出一种基于深度学习的高分辨率 Head-related transfer functions (HRTFs)  interpolating方法，以便在虚拟现实应用中实现高精度的声场 reproduce。</li>
<li>methods: 该方法基于圆形卷积神经网络，通过对 HRTF 的分解和重建来实现卷积过程。使用 Spherical Harmonics (SHs) 作为卷积函数，使得卷积层能够有效地捕捉声场特征。</li>
<li>results:  simulations 结果表明，提出的方法能够准确地从稀疏测量 interpolate HRTF，高效地超过 SH 方法和学习基于方法。<details>
<summary>Abstract</summary>
Head-related transfer functions (HRTFs) are crucial for spatial soundfield reproduction in virtual reality applications. However, obtaining personalized, high-resolution HRTFs is a time-consuming and costly task. Recently, deep learning-based methods showed promise in interpolating high-resolution HRTFs from sparse measurements. Some of these methods treat HRTF interpolation as an image super-resolution task, which neglects spatial acoustic features. This paper proposes a spherical convolutional neural network method for HRTF interpolation. The proposed method realizes the convolution process by decomposing and reconstructing HRTF through the Spherical Harmonics (SHs). The SHs, an orthogonal function set defined on a sphere, allow the convolution layers to effectively capture the spatial features of HRTFs, which are sampled on a sphere. Simulation results demonstrate the effectiveness of the proposed method in achieving accurate interpolation from sparse measurements, outperforming the SH method and learning-based methods.
</details>
<details>
<summary>摘要</summary>
HEAD-RELATED TRANSFER FUNCTIONS (HRTFs) 是虚拟现实应用中重要的空间声场重建技术。然而，获取个人化、高分辨率 HRTFs 是一项时间consuming 和成本高的任务。最近，深度学习基于方法在 interpolating 高分辨率 HRTFs 中表现出了搭配。其中一些方法将 HRTF  interpolating 视为一种图像超分辨率任务，忽略了空间声学特征。本文提出了一种圆柱体 convolutional neural network 方法，用于 HRTF  interpolating。该方法通过分解和重建 HRTF 通过圆柱体快推函数 (SHs) 来实现卷积过程。SHs 是定义在球体上的正交函数集，使卷积层能够有效地捕捉 HRTFs 的空间特征，这些特征在球体上被采样。 simulation 结果表明，提议的方法可以准确地从稀疏测量中 interpolate HRTFs，超越 SH 方法和学习基于方法。
</details></li>
</ul>
<hr>
<h2 id="One-Class-Knowledge-Distillation-for-Spoofing-Speech-Detection"><a href="#One-Class-Knowledge-Distillation-for-Spoofing-Speech-Detection" class="headerlink" title="One-Class Knowledge Distillation for Spoofing Speech Detection"></a>One-Class Knowledge Distillation for Spoofing Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08285">http://arxiv.org/abs/2309.08285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingze Lu, Yuxiang Zhang, Wenchao Wang, Zengqiang Shang, Pengyuan Zhang</li>
<li>for: 本研究旨在解决未知算法生成的假语音杀毒检测问题，尤其是traditional检测系统无法通过二分类分类方法普适地检测假语音。</li>
<li>methods: 本研究提出了一种教师-学生框架，通过一个教师模型来引导学生模型学习一类模型，从而提高假语音检测的普适性。</li>
<li>results: 实验结果表明，提出的一类知识储存方法在ASVspoof 21DF数据集和InTheWild数据集上具有更高的普适性和检测精度，相比之下其他现有方法。<details>
<summary>Abstract</summary>
The detection of spoofing speech generated by unseen algorithms remains an unresolved challenge. One reason for the lack of generalization ability is traditional detecting systems follow the binary classification paradigm, which inherently assumes the possession of prior knowledge of spoofing speech. One-class methods attempt to learn the distribution of bonafide speech and are inherently suited to the task where spoofing speech exhibits significant differences. However, training a one-class system using only bonafide speech is challenging. In this paper, we introduce a teacher-student framework to provide guidance for the training of a one-class model. The proposed one-class knowledge distillation method outperforms other state-of-the-art methods on the ASVspoof 21DF dataset and InTheWild dataset, which demonstrates its superior generalization ability.
</details>
<details>
<summary>摘要</summary>
检测假声音仍然是一个未解决的挑战。一个原因是传统的检测系统采用二分类分类方式，这意味着它们假设攻击者拥有假声音的知识。一类方法尝试学习正常的声音分布，但是在训练时需要大量的正常声音数据。在本文中，我们介绍了一种教师-学生框架，以帮助一类模型的训练。我们提出的一类知识填充方法在ASVspoof 21DF数据集和InTheWild数据集上显示出优于其他现有方法的性能，这 demonstartes its 的普遍性能。
</details></li>
</ul>
<hr>
<h2 id="Improving-Short-Utterance-Anti-Spoofing-with-AASIST2"><a href="#Improving-Short-Utterance-Anti-Spoofing-with-AASIST2" class="headerlink" title="Improving Short Utterance Anti-Spoofing with AASIST2"></a>Improving Short Utterance Anti-Spoofing with AASIST2</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08279">http://arxiv.org/abs/2309.08279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhang, Jingze Lu, Zengqiang Shang, Wenchao Wang, Pengyuan Zhang</li>
<li>for: 防止声音伪造 (anti-spoofing)</li>
<li>methods: 使用 wave2vec 2.0 和 интегрированный спектро-временной графический注意力网络 (AASIST)，并在检测过程中应用动态尺寸大小调整 (DCS) 和自适应大margin精度调整 (ALMFT)</li>
<li>results: 提高短语音识别性能，同时保持不同数据集的常规评估性能<details>
<summary>Abstract</summary>
The wav2vec 2.0 and integrated spectro-temporal graph attention network (AASIST) based countermeasure achieves great performance in speech anti-spoofing. However, current spoof speech detection systems have fixed training and evaluation durations, while the performance degrades significantly during short utterance evaluation. To solve this problem, AASIST can be improved to AASIST2 by modifying the residual blocks to Res2Net blocks. The modified Res2Net blocks can extract multi-scale features and improve the detection performance for speech of different durations, thus improving the short utterance evaluation performance. On the other hand, adaptive large margin fine-tuning (ALMFT) has achieved performance improvement in short utterance speaker verification. Therefore, we apply Dynamic Chunk Size (DCS) and ALMFT training strategies in speech anti-spoofing to further improve the performance of short utterance evaluation. Experiments demonstrate that the proposed AASIST2 improves the performance of short utterance evaluation while maintaining the performance of regular evaluation on different datasets.
</details>
<details>
<summary>摘要</summary>
“wav2vec 2.0 和嵌入式спектро-时间图注意力网络（AASIST）基于的防范措施在语音骗取中表现出色。然而，现有的骗取语音检测系统具有固定的训练和评估时间，而性能在短语音评估中明显下降。为解决这问题，AASIST可以改进为AASIST2，通过修改剩下块为Res2Net块来提取多级特征，提高不同时长语音的检测性能，因此提高短语音评估性能。另一方面，适应大margin微调（ALMFT）在短语音 speaker认证中实现了性能提高。因此，我们在语音骗取中应用动态块大小（DCS）和ALMFT 训练策略，以进一步提高短语音评估性能。实验表明，提出的AASIST2可以在不同的数据集上维持短语音评估性能的同时，提高短语音评估性能。”
</details></li>
</ul>
<hr>
<h2 id="Improving-Voice-Conversion-for-Dissimilar-Speakers-Using-Perceptual-Losses"><a href="#Improving-Voice-Conversion-for-Dissimilar-Speakers-Using-Perceptual-Losses" class="headerlink" title="Improving Voice Conversion for Dissimilar Speakers Using Perceptual Losses"></a>Improving Voice Conversion for Dissimilar Speakers Using Perceptual Losses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08263">http://arxiv.org/abs/2309.08263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suhita Ghosh, Yamini Sinha, Ingo Siegert, Sebastian Stober</li>
<li>for: 保护用户隐私和数据安全</li>
<li>methods: 使用语音转换技术实现语音数据匿名化</li>
<li>results: 成功地隐藏了语音数据的来源 speaker<details>
<summary>Abstract</summary>
The rising trend of using voice as a means of interacting with smart devices has sparked worries over the protection of users' privacy and data security. These concerns have become more pressing, especially after the European Union's adoption of the General Data Protection Regulation (GDPR). The information contained in an utterance encompasses critical personal details about the speaker, such as their age, gender, socio-cultural origins and more. If there is a security breach and the data is compromised, attackers may utilise the speech data to circumvent the speaker verification systems or imitate authorised users. Therefore, it is pertinent to anonymise the speech data before being shared across devices, such that the source speaker of the utterance cannot be traced. Voice conversion (VC) can be used to achieve speech anonymisation, which involves altering the speaker's characteristics while preserving the linguistic content.
</details>
<details>
<summary>摘要</summary>
声音作为智能设备交互方式的升温趋势，引发了用户隐私和数据安全保护的worries。这些问题在欧盟通过《个人数据保护条例》（GDPR）之后变得更加紧迫。语音中含有关键个人信息，如speaker的年龄、性别、社会文化背景等。如果数据被泄露，攻击者可能利用语音数据绕过speaker验证系统或模仿已经授权的用户。因此，需要对语音数据进行匿名处理，以隐藏语音的来源speaker。声音转换（VC）可以实现匿名处理，即改变speaker的特征，保留语言内容不变。
</details></li>
</ul>
<hr>
<h2 id="TF-SepNet-An-Efficient-1D-Kernel-Design-in-CNNs-for-Low-Complexity-Acoustic-Scene-Classification"><a href="#TF-SepNet-An-Efficient-1D-Kernel-Design-in-CNNs-for-Low-Complexity-Acoustic-Scene-Classification" class="headerlink" title="TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity Acoustic Scene Classification"></a>TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity Acoustic Scene Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08200">http://arxiv.org/abs/2309.08200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiqiang Cai, Peihong Zhang, Shengchen Li</li>
<li>for: 这篇论文主要关注发展高效的语音Scene分类系统，使用扩展单元网络（CNNs），实现更好的效能和效率。</li>
<li>methods: 提案的TF-SepNet架构将特征处理分为时间和频率两个维度，并将每个维度的特征进行分类。相比于传统的二维（2D）核心，TF-SepNet使用一维（1D）核心，以减少计算成本。</li>
<li>results: 实验结果显示，TF-SepNet在TAU都市语音Scene 2022 Mobile development dataset上表现出色，较同类的State-of-the-arts之前。进一步的调查发现，TF-SepNet的分类器具有更大的有效接收场（ERF），使得更好地捕捉时间-频率特征。<details>
<summary>Abstract</summary>
Recent studies focus on developing efficient systems for acoustic scene classification (ASC) using convolutional neural networks (CNNs), which typically consist of consecutive kernels. This paper highlights the benefits of using separate kernels as a more powerful and efficient design approach in ASC tasks. Inspired by the time-frequency nature of audio signals, we propose TF-SepNet, a CNN architecture that separates the feature processing along the time and frequency dimensions. Features resulted from the separate paths are then merged by channels and directly forwarded to the classifier. Instead of the conventional two dimensional (2D) kernel, TF-SepNet incorporates one dimensional (1D) kernels to reduce the computational costs. Experiments have been conducted using the TAU Urban Acoustic Scene 2022 Mobile development dataset. The results show that TF-SepNet outperforms similar state-of-the-arts that use consecutive kernels. A further investigation reveals that the separate kernels lead to a larger effective receptive field (ERF), which enables TF-SepNet to capture more time-frequency features.
</details>
<details>
<summary>摘要</summary>
近期研究强调开发高效的听音场景分类（ASC）系统，使用核函数网络（CNN）来实现。通常情况下，CNN包含连续的核函数。这篇论文指出，使用独立的核函数可以作为更有力的和高效的设计方法。受听音信号的时间-频率特性启发，我们提出TF-SepNet架构，它在时间和频率维度上分离特征处理。从分离的道路中得到的特征然后通过通道直接传递给分类器。而不是传统的二维（2D）核函数，TF-SepNet使用一维（1D）核函数，以降低计算成本。经过实验，使用TAU都市听音场景2022移动开发 dataset，结果表明TF-SepNet超过了类似的状态艺术使用连续核函数的同类方法。进一步的调查表明，独立的核函数导致更大的有效收发场（ERF），这使得TF-SepNet能够捕捉更多的时间-频率特征。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Residual-Speaker-Representation-for-Voice-Conversion"><a href="#Controllable-Residual-Speaker-Representation-for-Voice-Conversion" class="headerlink" title="Controllable Residual Speaker Representation for Voice Conversion"></a>Controllable Residual Speaker Representation for Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08166">http://arxiv.org/abs/2309.08166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Xu, Jiangyan Yi, Jianhua Tao, Tao Wang, Yong Ren, Rongxiu Zhong</li>
<li>for: 提高voice conversion的高质量表现和 robustness</li>
<li>methods: 使用多层残差近似Token进行提高Robustness，并实现有效控制时声表现</li>
<li>results: 比基eline表现出色，在主观和客观评估中都达到了更高的性能和Robustness<details>
<summary>Abstract</summary>
Recently, there have been significant advancements in voice conversion, resulting in high-quality performance. However, there are still two critical challenges in this field. Firstly, current voice conversion methods have limited robustness when encountering unseen speakers. Secondly, they also have limited ability to control timbre representation. To address these challenges, this paper presents a novel approach leverages tokens of multi-layer residual approximations to enhance robustness when dealing with unseen speakers, called the residual speaker module. The introduction of multi-layer approximations facilitates the separation of information from the timbre, enabling effective control over timbre in voice conversion. The proposed method outperforms baselines in both subjective and objective evaluations, demonstrating superior performance and increased robustness. Our demo page is publicly available.
</details>
<details>
<summary>摘要</summary>
最近，voice conversion技术已经取得了 significative进步，以至于表现质量得到了提升。然而，这个领域仍然存在两个关键挑战。第一，现有的voice conversion方法在遇到未看过的speaker时，其Robustness具有有限的能力。第二，它们也有限制timbre表达的能力。为了解决这些挑战，本文提出了一种新的方法，利用多层径辐射近似token来增强对未看过的speaker的Robustness，称为剩余speaker模块。多层径辐射近似token的引入，使得信息从timbre中分离得到更好，以便有效控制timbre在voice conversion中。提议的方法在对比基准方法的主观和客观评估中表现出了superior的性能和更高的Robustness。我们的demo页面公开给公众。
</details></li>
</ul>
<hr>
<h2 id="RVAE-EM-Generative-speech-dereverberation-based-on-recurrent-variational-auto-encoder-and-convolutive-transfer-function"><a href="#RVAE-EM-Generative-speech-dereverberation-based-on-recurrent-variational-auto-encoder-and-convolutive-transfer-function" class="headerlink" title="RVAE-EM: Generative speech dereverberation based on recurrent variational auto-encoder and convolutive transfer function"></a>RVAE-EM: Generative speech dereverberation based on recurrent variational auto-encoder and convolutive transfer function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08157">http://arxiv.org/abs/2309.08157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-westlakeu/rvae-em">https://github.com/audio-westlakeu/rvae-em</a></li>
<li>paper_authors: Pengyu Wang, Xiaofei Li</li>
<li>for: 室内场景中的干扰声纳成为干扰speech质量和清晰度的主要因素。本文提出了一种生成抑干方法。</li>
<li>methods: 本方法基于一个概率模型，利用回卷变换自动编码器（RVAE）网络和卷积函数（CTF）的近似。与大多数前置方法不同，我们的输出是清晰speech的先验知识。我们通过预测最大 posteriori（MAP）算法来实现MAP估计清晰speech。</li>
<li>results: 对单通道speech抑干进行实验，我们发现提出的生成方法明显超过了先进的探测网络。<details>
<summary>Abstract</summary>
In indoor scenes, reverberation is a crucial factor in degrading the perceived quality and intelligibility of speech. In this work, we propose a generative dereverberation method. Our approach is based on a probabilistic model utilizing a recurrent variational auto-encoder (RVAE) network and the convolutive transfer function (CTF) approximation. Different from most previous approaches, the output of our RVAE serves as the prior of the clean speech. And our target is the maximum a posteriori (MAP) estimation of clean speech, which is achieved iteratively through the expectation maximization (EM) algorithm. The proposed method integrates the capabilities of network-based speech prior modelling and CTF-based observation modelling. Experiments on single-channel speech dereverberation show that the proposed generative method noticeably outperforms the advanced discriminative networks.
</details>
<details>
<summary>摘要</summary>
在室内场景中，干扰是影响speech perceived质量和 intelligibility的关键因素。在这项工作中，我们提出了一种生成抑干方法。我们的方法基于一个概率模型，使用回归变换自动编码器（RVAE）网络和卷积函数（CTF）的近似。与大多数前一代方法不同，我们的RVAE输出作为干扰前后的净speech的假设。我们的目标是使用期望最大化（EM）算法来实现MAP估计净speech。我们的方法结合了网络基于声音先验模型和CTF基于观察模型的能力。实验表明，我们的生成方法在单通道speech抑干方面明显超过了先进的探测网络。
</details></li>
</ul>
<hr>
<h2 id="Fine-tune-the-pretrained-ATST-model-for-sound-event-detection"><a href="#Fine-tune-the-pretrained-ATST-model-for-sound-event-detection" class="headerlink" title="Fine-tune the pretrained ATST model for sound event detection"></a>Fine-tune the pretrained ATST model for sound event detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08153">http://arxiv.org/abs/2309.08153</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Audio-WestlakeU/ATST-SED">https://github.com/Audio-WestlakeU/ATST-SED</a></li>
<li>paper_authors: Nian Shao, Xian Li, Xiaofei Li</li>
<li>for: 这种研究是为了解决音频事件检测（SED）问题中的数据不足问题。</li>
<li>methods: 这个研究使用了大量预训练的自动学习（SelfSL）模型，以便生成更有特征的特征来进行 SED。</li>
<li>results: 我们的实验表明，我们的 fine-tuning 方法可以超越大型预训练网络的过拟合问题，并实现新的最佳性表现（SOTA），得到了 DCASE 挑战任务4 dataset 的 PSDS1&#x2F;PSDS2 分数为 0.587&#x2F;0.812。<details>
<summary>Abstract</summary>
Sound event detection (SED) often suffers from the data deficiency problem. The recent baseline system in the DCASE2023 challenge task 4 leverages the large pretrained self-supervised learning (SelfSL) models to mitigate such restriction, where the pretrained models help to produce more discriminative features for SED. However, the pretrained models are regarded as a frozen feature extractor in the challenge baseline system and most of the challenge submissions, and fine-tuning of the pretrained models has been rarely studied. In this work, we study the fine-tuning method of the pretrained models for SED. We first introduce ATST-Frame, our newly proposed SelfSL model, to the SED system. ATST-Frame was especially designed for learning frame-level representations of audio signals and obtained state-of-the-art (SOTA) performances on a series of downstream tasks. We then propose a fine-tuning method for ATST-Frame using both (in-domain) unlabelled and labelled SED data. Our experiments show that, the proposed method overcomes the overfitting problem when fine-tuning the large pretrained network, and our SED system obtains new SOTA results of 0.587/0.812 PSDS1/PSDS2 scores on the DCASE challenge task 4 dataset.
</details>
<details>
<summary>摘要</summary>
声音事件检测（SED）经常面临数据不足问题。最近的基eline系统在DCASE2023挑战任务4中利用大规模预先自监学习（SelfSL）模型来缓解这种限制，其中预先学习的模型帮助生成更有特征的特征来进行SED。然而，预先学习的模型通常被视为DCASE2023挑战系统和大多数挑战提交中的冰结特征提取器，并且微调这些预先学习的模型的研究很少。在这项工作中，我们研究了SED中预先学习模型的微调方法。我们首先介绍了我们新提出的ATST-Frame模型，它专门用于学习音频信号帧级表示，并在一系列下游任务上达到了状态之arte（SOTA）性能。然后，我们提议一种微调方法，用于微调ATST-Frame模型使用（域内）无标签和标签SED数据。我们的实验结果表明，提议的方法可以在微调大规模预先学习网络时解决过拟合问题，并且我们的SED系统在DCASE挑战任务4数据集上获得了新的SOTA结果，即0.587/0.812 PSDS1/PSDS2分数。
</details></li>
</ul>
<hr>
<h2 id="t-SOT-FNT-Streaming-Multi-talker-ASR-with-Text-only-Domain-Adaptation-Capability"><a href="#t-SOT-FNT-Streaming-Multi-talker-ASR-with-Text-only-Domain-Adaptation-Capability" class="headerlink" title="t-SOT FNT: Streaming Multi-talker ASR with Text-only Domain Adaptation Capability"></a>t-SOT FNT: Streaming Multi-talker ASR with Text-only Domain Adaptation Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08131">http://arxiv.org/abs/2309.08131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Wu, Naoyuki Kanda, Takuya Yoshioka, Rui Zhao, Zhuo Chen, Jinyu Li</li>
<li>for: 这篇论文主要targets推广多说话者自动语音识别（ASR）的挑战，提出了Token-level serialized output training（t-SOT）方法。</li>
<li>methods: 该方法使用了$\langle \text{cc}\rangle$符号间适应多说话者转录，但使用简单的神经网络推导器结构限制了其应用范围。为解决这个问题，我们提出了一种新的t-SOT模型结构，即factorized neural transducers（FNT）。该方法将语言模型（LM）和推导器 Predictor 分离开，并对$\langle \text{cc}\rangle$符号的不自然的字符顺序进行处理。我们通过保持多个隐藏状态和对$\langle \text{cc}\rangle$符号进行特殊处理来实现这一点。</li>
<li>results: 我们的t-SOT FNT模型在单个和多个说话者 dataset 上的Word Error Rate（WER）减少表现和原始 t-SOT 模型相似，同时保持了文本适应的能力。<details>
<summary>Abstract</summary>
Token-level serialized output training (t-SOT) was recently proposed to address the challenge of streaming multi-talker automatic speech recognition (ASR). T-SOT effectively handles overlapped speech by representing multi-talker transcriptions as a single token stream with $\langle \text{cc}\rangle$ symbols interspersed. However, the use of a naive neural transducer architecture significantly constrained its applicability for text-only adaptation. To overcome this limitation, we propose a novel t-SOT model structure that incorporates the idea of factorized neural transducers (FNT). The proposed method separates a language model (LM) from the transducer's predictor and handles the unnatural token order resulting from the use of $\langle \text{cc}\rangle$ symbols in t-SOT. We achieve this by maintaining multiple hidden states and introducing special handling of the $\langle \text{cc}\rangle$ tokens within the LM. The proposed t-SOT FNT model achieves comparable performance to the original t-SOT model while retaining the ability to reduce word error rate (WER) on both single and multi-talker datasets through text-only adaptation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Diversity-based-core-set-selection-for-text-to-speech-with-linguistic-and-acoustic-features"><a href="#Diversity-based-core-set-selection-for-text-to-speech-with-linguistic-and-acoustic-features" class="headerlink" title="Diversity-based core-set selection for text-to-speech with linguistic and acoustic features"></a>Diversity-based core-set selection for text-to-speech with linguistic and acoustic features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08127">http://arxiv.org/abs/2309.08127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kentaro Seki, Shinnosuke Takamichi, Takaaki Saeki, Hiroshi Saruwatari</li>
<li>for: 提高语音识别系统的表达能力</li>
<li>methods: 使用多源数据集合（如audiobooks和YouTube）构建大规模的语音识别系统数据集，并使用多元度度量（measure the degree to which a subset encompasses a wide range）选择核心子集（known as \textit{core-set））</li>
<li>results: 对于不同语言和数据集大小，与基准方法相比，提议的方法表现出色，性能明显超过基准方法<details>
<summary>Abstract</summary>
This paper proposes a method for extracting a lightweight subset from a text-to-speech (TTS) corpus ensuring synthetic speech quality. In recent years, methods have been proposed for constructing large-scale TTS corpora by collecting diverse data from massive sources such as audiobooks and YouTube. Although these methods have gained significant attention for enhancing the expressive capabilities of TTS systems, they often prioritize collecting vast amounts of data without considering practical constraints like storage capacity and computation time in training, which limits the available data quantity. Consequently, the need arises to efficiently collect data within these volume constraints. To address this, we propose a method for selecting the core subset~(known as \textit{core-set}) from a TTS corpus on the basis of a \textit{diversity metric}, which measures the degree to which a subset encompasses a wide range. Experimental results demonstrate that our proposed method performs significantly better than the baseline phoneme-balanced data selection across language and corpus size.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文提出了一种方法，用于从文本到语音（TTS）集合中提取轻量级的子集，保证合成语音质量。在过去的几年中，有人提出了大规模的 TTS 集合建构方法，通过收集各种媒体资源，如 audiobooks 和 YouTube。虽然这些方法吸引了大量的注意力，但它们经常忽略实际的存储容量和训练时间限制，导致可用数据量受限。因此，需要有效地收集数据，以满足这些容量限制。为此，我们提出了一种基于 \textit{多样度度量} 的核心子集选择方法（known as \textit{core-set}），用于从 TTS 集合中选择最佳的子集。实验结果表明，我们的提议方法在语言和集合大小方面具有显著的优势，比基eline phoneme-balanced 数据选择更好。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-Assisted-Automatic-Speech-Emotion-Recognition-Transcribing-Annotating-and-Augmenting"><a href="#Foundation-Model-Assisted-Automatic-Speech-Emotion-Recognition-Transcribing-Annotating-and-Augmenting" class="headerlink" title="Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting"></a>Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08108">http://arxiv.org/abs/2309.08108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiantian Feng, Shrikanth Narayanan</li>
<li>for: 本研究旨在探讨使用基础模型自动化语音情感识别（SER），从杂音识别到增强。</li>
<li>methods: 本研究使用了基础模型进行自动化SER，包括自动生成转录和注释。</li>
<li>results: 研究发现，使用多个基础模型的输出可以提高情感注释质量，并且可以增强现有语音情感数据集的可用性。<details>
<summary>Abstract</summary>
Significant advances are being made in speech emotion recognition (SER) using deep learning models. Nonetheless, training SER systems remains challenging, requiring both time and costly resources. Like many other machine learning tasks, acquiring datasets for SER requires substantial data annotation efforts, including transcription and labeling. These annotation processes present challenges when attempting to scale up conventional SER systems. Recent developments in foundational models have had a tremendous impact, giving rise to applications such as ChatGPT. These models have enhanced human-computer interactions including bringing unique possibilities for streamlining data collection in fields like SER. In this research, we explore the use of foundational models to assist in automating SER from transcription and annotation to augmentation. Our study demonstrates that these models can generate transcriptions to enhance the performance of SER systems that rely solely on speech data. Furthermore, we note that annotating emotions from transcribed speech remains a challenging task. However, combining outputs from multiple LLMs enhances the quality of annotations. Lastly, our findings suggest the feasibility of augmenting existing speech emotion datasets by annotating unlabeled speech samples.
</details>
<details>
<summary>摘要</summary>
<<SYS>>大量的进步在语音情感识别（SER）领域中使用深度学习模型。然而，训练SER系统仍然具有挑战性，需要大量的时间和资源。与其他机器学习任务类似，获取SER数据集需要大量的数据注释和标注。这些注释和标注过程中存在挑战，尝试扩大传统的SER系统。最近的基础模型的发展对SER领域有益，如ChatGPT等模型，它们提高了人机交互，包括带来了对SER领域的数据收集方面的新可能性。在本研究中，我们explore使用基础模型来帮助自动化SER，从译文和注释到增强。我们的研究表明，这些模型可以生成提高SER系统的性能的译文。此外，我们注意到从译文中注释情感仍然是一个挑战。然而，将多个LLMs的输出结合起来可以提高注释质量。最后，我们的发现表明可以使用未标注的语音样本来增强现有的speech emotion数据集。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Libriheavy-a-50-000-hours-ASR-corpus-with-punctuation-casing-and-context"><a href="#Libriheavy-a-50-000-hours-ASR-corpus-with-punctuation-casing-and-context" class="headerlink" title="Libriheavy: a 50,000 hours ASR corpus with punctuation casing and context"></a>Libriheavy: a 50,000 hours ASR corpus with punctuation casing and context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08105">http://arxiv.org/abs/2309.08105</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k2-fsa/libriheavy">https://github.com/k2-fsa/libriheavy</a></li>
<li>paper_authors: Wei Kang, Xiaoyu Yang, Zengwei Yao, Fangjun Kuang, Yifan Yang, Liyong Guo, Long Lin, Daniel Povey</li>
<li>for: 本研究开发了一个大规模的语音识别 corpora，名为Libriheavy，包含50,000小时的英语朗读，来自LibriVox。这是目前所知道的最大的开源语音识别数据集。</li>
<li>methods: 作者提出了一种通用和高效的数据集创建管道，用于将Librilight中的音频与其相应的文本进行对应。同时，作者也提供了一些基线系统，包括CTC-Attention和探测器模型。</li>
<li>results: 作者在 Libriheavy 中建立了一个基eline系统，并对其进行了评估。研究结果显示，这个基线系统在 Libriheavy 中的识别精度高于其他相似的数据集。此外，作者还开源了其数据集创建管道，可以用于其他语音对应任务。<details>
<summary>Abstract</summary>
In this paper, we introduce Libriheavy, a large-scale ASR corpus consisting of 50,000 hours of read English speech derived from LibriVox. To the best of our knowledge, Libriheavy is the largest freely-available corpus of speech with supervisions. Different from other open-sourced datasets that only provide normalized transcriptions, Libriheavy contains richer information such as punctuation, casing and text context, which brings more flexibility for system building. Specifically, we propose a general and efficient pipeline to locate, align and segment the audios in previously published Librilight to its corresponding texts. The same as Librilight, Libriheavy also has three training subsets small, medium, large of the sizes 500h, 5000h, 50000h respectively. We also extract the dev and test evaluation sets from the aligned audios and guarantee there is no overlapping speakers and books in training sets. Baseline systems are built on the popular CTC-Attention and transducer models. Additionally, we open-source our dataset creatation pipeline which can also be used to other audio alignment tasks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了 Libriheavy，一个大规模的语音识别集合，包含50,000小时的英文语音，来自LibriVox。据我们所知，Libriheavy是目前最大的免费可用的语音识别集合。与其他开源数据集不同，Libriheavy包含更多的信息，例如括号、字母和文本上下文，这使得系统建设更加灵活。我们提出了一个通用和高效的管道来定位、对齐和分割 Librilight 中的音频。与 Librilight 相同，Libriheavy 也有三个训练subset：小、中、大，分别为 500h、5000h 和 50000h。我们还提取了评估集和测试集，并保证训练集中没有重复的 speaker 和书籍。基础系统使用了流行的 CTC-Attention 和批处理模型。此外，我们还开源了我们的数据创建管道，可以用于其他音频对齐任务。
</details></li>
</ul>
<hr>
<h2 id="SSL-Net-A-Synergistic-Spectral-and-Learning-based-Network-for-Efficient-Bird-Sound-Classification"><a href="#SSL-Net-A-Synergistic-Spectral-and-Learning-based-Network-for-Efficient-Bird-Sound-Classification" class="headerlink" title="SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient Bird Sound Classification"></a>SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient Bird Sound Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08072">http://arxiv.org/abs/2309.08072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Yang, Kaichen Zhou, Niki Trigoni, Andrew Markham</li>
<li>for: 鸟叫声分类是生态学、栖息地保护和科研中重要的任务，因为它对鸟种分布和数量进行监测起重要作用。</li>
<li>methods: 我们提出了一种高效和通用的框架called SSL-Net，它将spectral和学习特征相结合，以分类不同的鸟叫声。</li>
<li>results: 我们在一个标准的野外采集的鸟叫声数据集上获得了鼓舞人的实验结果，证明我们的方法可以高效地提取特征和实现鸟叫声分类的高性能，即使工作样本数量有限。此外，我们还提出了三种特征融合策略，以便工程师和研究人员在选择中受益。<details>
<summary>Abstract</summary>
Efficient and accurate bird sound classification is of important for ecology, habitat protection and scientific research, as it plays a central role in monitoring the distribution and abundance of species. However, prevailing methods typically demand extensively labeled audio datasets and have highly customized frameworks, imposing substantial computational and annotation loads. In this study, we present an efficient and general framework called SSL-Net, which combines spectral and learned features to identify different bird sounds. Encouraging empirical results gleaned from a standard field-collected bird audio dataset validate the efficacy of our method in extracting features efficiently and achieving heightened performance in bird sound classification, even when working with limited sample sizes. Furthermore, we present three feature fusion strategies, aiding engineers and researchers in their selection through quantitative analysis.
</details>
<details>
<summary>摘要</summary>
efficient和准确的鸟叫声分类对生态学、栖息地保护和科学研究非常重要，因为它在监测物种分布和数量方面扮演了中心角色。然而，现有的方法通常需要大量的标注音频数据和特定的框架，导致计算和标注负担很大。在这个研究中，我们提出了一种高效和通用的框架called SSL-Net，它将spectral和学习特征结合以分类不同的鸟叫声。我们从标准采集的鸟叫声数据集中获得了鼓舞人心的实验结果，证明了我们的方法可以高效地提取特征和实现鸟叫声分类 tasks，即使受限制的样本数量。此外，我们还提出了三种特征融合策略，以帮助工程师和研究人员在选择方面做出数据分析。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/15/cs.SD_2023_09_15/" data-id="clp89dojs00z8i788db1c1kh9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/15/cs.CV_2023_09_15/" class="article-date">
  <time datetime="2023-09-15T13:00:00.000Z" itemprop="datePublished">2023-09-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/15/cs.CV_2023_09_15/">cs.CV - 2023-09-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="EgoObjects-A-Large-Scale-Egocentric-Dataset-for-Fine-Grained-Object-Understanding"><a href="#EgoObjects-A-Large-Scale-Egocentric-Dataset-for-Fine-Grained-Object-Understanding" class="headerlink" title="EgoObjects: A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding"></a>EgoObjects: A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08816">http://arxiv.org/abs/2309.08816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/egoobjects">https://github.com/facebookresearch/egoobjects</a></li>
<li>paper_authors: Chenchen Zhu, Fanyi Xiao, Andres Alvarado, Yasmine Babaei, Jiabo Hu, Hichem El-Mohri, Sean Chang Culatana, Roshan Sumbaly, Zhicheng Yan</li>
<li>for: 本研究使用 Egocentric visual data 进行对象理解，这是 egocentric 视觉研究中的基础问题。</li>
<li>methods: 本研究使用了大规模的 Egocentric 数据集 EgoObjects，包含了250名参与者从50多个国家使用4种便携式设备录制了9K个视频，并且包含了368个对象类别的650K个对象标注。</li>
<li>results: EgoObjects 数据集包含了每个对象的实例级标识符，并且包含了14K个唯一的对象实例。此外，EgoObjects 还能够捕捉到不同背景复杂性、周围对象、距离、照明和摄像头运动等多种因素。为了促进 EgoObjects 的研究，本文还提出了4个benchmark任务，包括一个新的实例级对象检测任务和一个传统的类别级对象检测任务。此外，本文还引入了2个新的持续学习对象检测任务。EgoObjects 数据集和 API 可以在 <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/EgoObjects">https://github.com/facebookresearch/EgoObjects</a> 上下载。<details>
<summary>Abstract</summary>
Object understanding in egocentric visual data is arguably a fundamental research topic in egocentric vision. However, existing object datasets are either non-egocentric or have limitations in object categories, visual content, and annotation granularities. In this work, we introduce EgoObjects, a large-scale egocentric dataset for fine-grained object understanding. Its Pilot version contains over 9K videos collected by 250 participants from 50+ countries using 4 wearable devices, and over 650K object annotations from 368 object categories. Unlike prior datasets containing only object category labels, EgoObjects also annotates each object with an instance-level identifier, and includes over 14K unique object instances. EgoObjects was designed to capture the same object under diverse background complexities, surrounding objects, distance, lighting and camera motion. In parallel to the data collection, we conducted data annotation by developing a multi-stage federated annotation process to accommodate the growing nature of the dataset. To bootstrap the research on EgoObjects, we present a suite of 4 benchmark tasks around the egocentric object understanding, including a novel instance level- and the classical category level object detection. Moreover, we also introduce 2 novel continual learning object detection tasks. The dataset and API are available at https://github.com/facebookresearch/EgoObjects.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese Object understanding in egocentric visual data is a fundamental research topic in egocentric vision. However, existing object datasets are either non-egocentric or have limitations in object categories, visual content, and annotation granularities. In this work, we introduce EgoObjects, a large-scale egocentric dataset for fine-grained object understanding. Its Pilot version contains over 9,000 videos collected by 250 participants from 50+ countries using 4 wearable devices, and over 650,000 object annotations from 368 object categories. Unlike prior datasets containing only object category labels, EgoObjects also annotates each object with an instance-level identifier, and includes over 14,000 unique object instances. EgoObjects was designed to capture the same object under diverse background complexities, surrounding objects, distance, lighting, and camera motion. In parallel to the data collection, we conducted data annotation by developing a multi-stage federated annotation process to accommodate the growing nature of the dataset. To bootstrap the research on EgoObjects, we present a suite of 4 benchmark tasks around the egocentric object understanding, including a novel instance-level and classical category-level object detection. Moreover, we also introduce 2 novel continual learning object detection tasks. The dataset and API are available at https://github.com/facebookresearch/EgoObjects.Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="The-Use-of-Multi-Scale-Fiducial-Markers-To-Aid-Takeoff-and-Landing-Navigation-by-Rotorcraft"><a href="#The-Use-of-Multi-Scale-Fiducial-Markers-To-Aid-Takeoff-and-Landing-Navigation-by-Rotorcraft" class="headerlink" title="The Use of Multi-Scale Fiducial Markers To Aid Takeoff and Landing Navigation by Rotorcraft"></a>The Use of Multi-Scale Fiducial Markers To Aid Takeoff and Landing Navigation by Rotorcraft</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08769">http://arxiv.org/abs/2309.08769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jongwon Lee, Su Yeon Choi, Timothy Bretl</li>
<li>for: This paper is written to quantify the impact of adverse environmental conditions on the detection of fiducial markers by color cameras mounted on rotorcraft.</li>
<li>methods: The paper uses image sequences collected outdoors with cameras mounted on a quadrotor during semi-autonomous takeoff and landing operations under adverse environmental conditions.</li>
<li>results: The paper evaluates the performance of the marker detection system using various performance measures such as precision, recall, continuity, availability, robustness, resiliency, and coverage volume.<details>
<summary>Abstract</summary>
This paper quantifies the impact of adverse environmental conditions on the detection of fiducial markers (i.e., artificial landmarks) by color cameras mounted on rotorcraft. We restrict our attention to square markers with a black-and-white pattern of grid cells that can be nested to allow detection at multiple scales. These markers have the potential to enhance the reliability of precision takeoff and landing at vertiports by flying vehicles in urban settings. Prior work has shown, in particular, that these markers can be detected with high precision (i.e., few false positives) and high recall (i.e., few false negatives). However, most of this prior work has been based on image sequences collected indoors with hand-held cameras. Our work is based on image sequences collected outdoors with cameras mounted on a quadrotor during semi-autonomous takeoff and landing operations under adverse environmental conditions that include variations in temperature, illumination, wind speed, humidity, visibility, and precipitation. In addition to precision and recall, performance measures include continuity, availability, robustness, resiliency, and coverage volume. We release both our dataset and the code we used for analysis to the public as open source.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Biased-Attention-Do-Vision-Transformers-Amplify-Gender-Bias-More-than-Convolutional-Neural-Networks"><a href="#Biased-Attention-Do-Vision-Transformers-Amplify-Gender-Bias-More-than-Convolutional-Neural-Networks" class="headerlink" title="Biased Attention: Do Vision Transformers Amplify Gender Bias More than Convolutional Neural Networks?"></a>Biased Attention: Do Vision Transformers Amplify Gender Bias More than Convolutional Neural Networks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08760">http://arxiv.org/abs/2309.08760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aibhishek/Biased-Attention">https://github.com/aibhishek/Biased-Attention</a></li>
<li>paper_authors: Abhishek Mandal, Susan Leavy, Suzanne Little</li>
<li>for:  This paper aims to evaluate the potential for bias amplification in vision transformers (ViTs) and compare them to convolutional neural networks (CNNs) in the context of large multimodal models.</li>
<li>methods: The authors introduce a novel metric called Accuracy Difference to measure bias in architectures and use it to evaluate the performance of CNNs and ViTs in image classification tasks.</li>
<li>results: The results show that ViTs amplify gender bias to a greater extent than CNNs, highlighting the importance of considering the potential for bias amplification in the design and deployment of multimodal models.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在评估视transformer（ViTs）和卷积神经网络（CNNs）在大型多模态模型中的可能的偏见增强。</li>
<li>methods: 作者引入了一个新的度量方法called Accuracy Difference来衡量architecture中的偏见，并用其来评估CNNs和ViTs在图像分类任务中的性能。</li>
<li>results: 结果显示，ViTs在性别偏见方面比CNNs更加把握，强调考虑在设计和部署多模态模型时的偏见增强。<details>
<summary>Abstract</summary>
Deep neural networks used in computer vision have been shown to exhibit many social biases such as gender bias. Vision Transformers (ViTs) have become increasingly popular in computer vision applications, outperforming Convolutional Neural Networks (CNNs) in many tasks such as image classification. However, given that research on mitigating bias in computer vision has primarily focused on CNNs, it is important to evaluate the effect of a different network architecture on the potential for bias amplification. In this paper we therefore introduce a novel metric to measure bias in architectures, Accuracy Difference. We examine bias amplification when models belonging to these two architectures are used as a part of large multimodal models, evaluating the different image encoders of Contrastive Language Image Pretraining which is an important model used in many generative models such as DALL-E and Stable Diffusion. Our experiments demonstrate that architecture can play a role in amplifying social biases due to the different techniques employed by the models for feature extraction and embedding as well as their different learning properties. This research found that ViTs amplified gender bias to a greater extent than CNNs
</details>
<details>
<summary>摘要</summary>
深度神经网络在计算机视觉中已经展现出许多社会偏见，如性别偏见。视觉转换器（ViTs）在计算机视觉应用中变得越来越受欢迎，在许多任务中如图像分类任务中超越了卷积神经网络（CNNs）。然而，由于研究减少计算机视觉中偏见的研究主要集中在CNNs上，因此需要评估不同网络架构对偏见的可能性。因此，我们引入了一种新的准则来衡量偏见，即准确性差异指标（Accuracy Difference）。我们在使用这两种架构的模型作为大型多Modal模型的一部分时进行了评估，并评估了不同图像编码器的对比语言图像预训练模型，这是一个广泛使用的生成模型，如DALL-E和Stable Diffusion。我们的实验表明，网络架构可以影响社会偏见的加剧，因为不同的模型在特征提取和嵌入以及学习特性上employs不同的技术。我们的研究发现，ViTs对gender bias的加剧比CNNs更大。
</details></li>
</ul>
<hr>
<h2 id="Unified-Brain-MR-Ultrasound-Synthesis-using-Multi-Modal-Hierarchical-Representations"><a href="#Unified-Brain-MR-Ultrasound-Synthesis-using-Multi-Modal-Hierarchical-Representations" class="headerlink" title="Unified Brain MR-Ultrasound Synthesis using Multi-Modal Hierarchical Representations"></a>Unified Brain MR-Ultrasound Synthesis using Multi-Modal Hierarchical Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08747">http://arxiv.org/abs/2309.08747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reuben Dorent, Nazim Haouchine, Fryderyk Kögl, Samuel Joutard, Parikshit Juvekar, Erickson Torio, Alexandra Golby, Sebastien Ourselin, Sarah Frisken, Tom Vercauteren, Tina Kapur, William M. Wells</li>
<li>for: 这个论文是为了Synthesize missing images from various modalities, using a deep hierarchical variational autoencoder (VAE) with a probabilistic formulation for fusing multi-modal images in a common latent representation.</li>
<li>methods: 这个论文使用的方法包括 extending multi-modal VAEs with a hierarchical latent structure, adversarial learning, and a principled probabilistic fusion operation.</li>
<li>results: 经验表明，这个模型可以比multi-modal VAEs, conditional GANs, and the current state-of-the-art unified method (ResViT)更好地Synthesize missing images, demonstrating the advantage of using a hierarchical latent representation and a principled probabilistic fusion operation.<details>
<summary>Abstract</summary>
We introduce MHVAE, a deep hierarchical variational auto-encoder (VAE) that synthesizes missing images from various modalities. Extending multi-modal VAEs with a hierarchical latent structure, we introduce a probabilistic formulation for fusing multi-modal images in a common latent representation while having the flexibility to handle incomplete image sets as input. Moreover, adversarial learning is employed to generate sharper images. Extensive experiments are performed on the challenging problem of joint intra-operative ultrasound (iUS) and Magnetic Resonance (MR) synthesis. Our model outperformed multi-modal VAEs, conditional GANs, and the current state-of-the-art unified method (ResViT) for synthesizing missing images, demonstrating the advantage of using a hierarchical latent representation and a principled probabilistic fusion operation. Our code is publicly available \url{https://github.com/ReubenDo/MHVAE}.
</details>
<details>
<summary>摘要</summary>
我们介绍MHVAE，一种深度嵌入式多modal VAE，可以将多modal图像中缺失的图像合成为完整的图像。我们通过在共同层次结构中嵌入多modal图像的概率表示方式，实现了对多modal图像的不同模式进行共同表示，并且可以处理部分图像集为输入。此外，我们采用了对抗学习来生成更加锐化的图像。我们在挑战性的 JOINT INTRA-OPERATIVE ULTRASOUND（iUS）和磁共振（MR）合成问题进行了广泛的实验，并证明了MHVAE对于缺失图像的合成表现出色，超过了多modal VAE、conditioned GAN和当前状态的架构（ResViT）。我们的代码可以在 GitHub 上找到，链接如下：https://github.com/ReubenDo/MHVAE。
</details></li>
</ul>
<hr>
<h2 id="Improved-Breast-Cancer-Diagnosis-through-Transfer-Learning-on-Hematoxylin-and-Eosin-Stained-Histology-Images"><a href="#Improved-Breast-Cancer-Diagnosis-through-Transfer-Learning-on-Hematoxylin-and-Eosin-Stained-Histology-Images" class="headerlink" title="Improved Breast Cancer Diagnosis through Transfer Learning on Hematoxylin and Eosin Stained Histology Images"></a>Improved Breast Cancer Diagnosis through Transfer Learning on Hematoxylin and Eosin Stained Histology Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08745">http://arxiv.org/abs/2309.08745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fahad Ahmed, Reem Abdel-Salam, Leon Hamnett, Mary Adewunmi, Temitope Ayano</li>
<li>For: The paper aims to classify breast cancer tumors into seven subtypes using deep learning models on histological images.* Methods: The authors use pre-trained deep learning models such as Xception, EfficientNet, ResNet50, and InceptionResNet, and pre-process the BRACS ROI images with image augmentation, upsampling, and dataset split strategies.* Results: The best results were obtained by ResNet50 achieving 66% f1-score for the default dataset split, and 96.2% f1-score for the custom dataset split, with a significant reduction in false positive and false negative classifications.Here are the three points in Simplified Chinese text:* For: 这个研究旨在使用深度学习模型来分类乳腺癌into seven种亚型。* Methods: 作者使用了预训练的深度学习模型，如Xception、EfficientNet、ResNet50和InceptionResNet，并对BRACS ROI图像进行了预处理，包括图像增强、放大和数据分割策略。* Results: 最佳结果由ResNet50实现，达到了66%的f1分数，而自定义数据分割策略可以达到96.2%的f1分数，同时减少了false positive和false negative分类的数量。<details>
<summary>Abstract</summary>
Breast cancer is one of the leading causes of death for women worldwide. Early screening is essential for early identification, but the chance of survival declines as the cancer progresses into advanced stages. For this study, the most recent BRACS dataset of histological (H\&E) stained images was used to classify breast cancer tumours, which contains both the whole-slide images (WSI) and region-of-interest (ROI) images, however, for our study we have considered ROI images. We have experimented using different pre-trained deep learning models, such as Xception, EfficientNet, ResNet50, and InceptionResNet, pre-trained on the ImageNet weights. We pre-processed the BRACS ROI along with image augmentation, upsampling, and dataset split strategies. For the default dataset split, the best results were obtained by ResNet50 achieving 66\% f1-score. For the custom dataset split, the best results were obtained by performing upsampling and image augmentation which results in 96.2\% f1-score. Our second approach also reduced the number of false positive and false negative classifications to less than 3\% for each class. We believe that our study significantly impacts the early diagnosis and identification of breast cancer tumors and their subtypes, especially atypical and malignant tumors, thus improving patient outcomes and reducing patient mortality rates. Overall, this study has primarily focused on identifying seven (7) breast cancer tumor subtypes, and we believe that the experimental models can be fine-tuned further to generalize over previous breast cancer histology datasets as well.
</details>
<details>
<summary>摘要</summary>
乳癌是女性全球死亡率的主要原因之一。早期检测是锐意义的，但癌细胞阶段的检测难度增加。为了实现这一目标，我们使用了最新的BRACS数据集，包括整幅图像（WSI）和区域 интерес（ROI）图像，但我们只使用了ROI图像。我们使用了不同的预训练深度学习模型，如Xception、EfficientNet、ResNet50和InceptionResNet，预训练在ImageNet权重上。我们对BRACS ROI进行预处理，并使用图像增强、下采样和数据集分割策略。对于默认数据集分割，最佳结果由ResNet50实现66%的f1分数。对于自定义数据集分割，通过实施下采样和图像增强，我们获得了96.2%的f1分数。我们的第二种方法还将false正和false负分类数降低到每个类型下的less than 3%。我们认为这一研究对于早期诊断和识别乳癌癌症和其亚型具有重要意义，从而提高病人结果和减少病人死亡率。总之，这一研究主要关注了identifying seven（7）种乳癌癌症，并我们认为实验性模型可以进一步细化以泛化到之前的乳癌历史学数据集。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Food-Image-Classification-Benchmark-Datasets-and-New-Baseline"><a href="#Personalized-Food-Image-Classification-Benchmark-Datasets-and-New-Baseline" class="headerlink" title="Personalized Food Image Classification: Benchmark Datasets and New Baseline"></a>Personalized Food Image Classification: Benchmark Datasets and New Baseline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08744">http://arxiv.org/abs/2309.08744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Pan, Jiangpeng He, Fengqing Zhu</li>
<li>for: 本研究的目的是提出一种个性化食品分类方法，以便自动分析食品图像中的营养成分。</li>
<li>methods: 本研究使用了自适应神经网络和自我超vised学习技术，以利用食品图像的时间序列特征来提高个性化食品分类的精度。</li>
<li>results: 在两个个性化食品分类 benchmark dataset上进行测试，本研究的方法显示出与现有方法相比的改进性。 dataset可以在以下链接下下载：<a target="_blank" rel="noopener" href="https://skynet.ecn.purdue.edu/~pan161/dataset_personal.html">https://skynet.ecn.purdue.edu/~pan161/dataset_personal.html</a><details>
<summary>Abstract</summary>
Food image classification is a fundamental step of image-based dietary assessment, enabling automated nutrient analysis from food images. Many current methods employ deep neural networks to train on generic food image datasets that do not reflect the dynamism of real-life food consumption patterns, in which food images appear sequentially over time, reflecting the progression of what an individual consumes. Personalized food classification aims to address this problem by training a deep neural network using food images that reflect the consumption pattern of each individual. However, this problem is under-explored and there is a lack of benchmark datasets with individualized food consumption patterns due to the difficulty in data collection. In this work, we first introduce two benchmark personalized datasets including the Food101-Personal, which is created based on surveys of daily dietary patterns from participants in the real world, and the VFNPersonal, which is developed based on a dietary study. In addition, we propose a new framework for personalized food image classification by leveraging self-supervised learning and temporal image feature information. Our method is evaluated on both benchmark datasets and shows improved performance compared to existing works. The dataset has been made available at: https://skynet.ecn.purdue.edu/~pan161/dataset_personal.html
</details>
<details>
<summary>摘要</summary>
食物图像分类是图像基于营养评估的基本步骤，允许自动分析食物图像中的营养成分。许多当前方法使用深度神经网络训练在通用食物图像集合上，这些集合不会反映现实生活中食物消耗的动态特点，食物图像会随着时间的推移而变化，具有个人特定的食物消耗模式。个性化食物分类目标是解决这个问题，通过使用每个个体的食物消耗模式来训练深度神经网络。然而，这个问题还没有得到充分的研究，并且缺乏个性化食物消耗模式的标准benchmark数据集。在这个工作中，我们首先介绍了两个benchmark个性化数据集，包括Food101-Personal，该数据集基于参与者的实际生活情况进行了调查，以及VFNPersonal，该数据集基于一项营养研究。此外，我们还提出了一种新的个性化食物图像分类框架，利用自动学习和时间图像特征信息。我们的方法在两个benchmark数据集上进行了评估，并与现有的方法进行了比较。数据集可以在以下网址获取：https://skynet.ecn.purdue.edu/~pan161/dataset_personal.html。
</details></li>
</ul>
<hr>
<h2 id="Active-Learning-for-Fine-Grained-Sketch-Based-Image-Retrieval"><a href="#Active-Learning-for-Fine-Grained-Sketch-Based-Image-Retrieval" class="headerlink" title="Active Learning for Fine-Grained Sketch-Based Image Retrieval"></a>Active Learning for Fine-Grained Sketch-Based Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08743">http://arxiv.org/abs/2309.08743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Himanshu Thakur, Soumitri Chattopadhyay</li>
<li>for: 提高 Fine-grained sketch-based image retrieval (FG-SBIR) 的实际应用和扩展性，即使不需要大量的 faithful sketches。</li>
<li>methods: 提出了一种新的活动学样本选择技术，通过利用现有的 photo-sketch 对应关系和其中的中间表示来减少绘制照片笔记的努力。</li>
<li>results: 通过实验在 ChairV2 和 ShoeV2 两个公开的细化的 SBIR 数据集上，证明了我们的方法在 adapted baselines 上表现出优异性。<details>
<summary>Abstract</summary>
The ability to retrieve a photo by mere free-hand sketching highlights the immense potential of Fine-grained sketch-based image retrieval (FG-SBIR). However, its rapid practical adoption, as well as scalability, is limited by the expense of acquiring faithful sketches for easily available photo counterparts. A solution to this problem is Active Learning, which could minimise the need for labeled sketches while maximising performance. Despite extensive studies in the field, there exists no work that utilises it for reducing sketching effort in FG-SBIR tasks. To this end, we propose a novel active learning sampling technique that drastically minimises the need for drawing photo sketches. Our proposed approach tackles the trade-off between uncertainty and diversity by utilising the relationship between the existing photo-sketch pair to a photo that does not have its sketch and augmenting this relation with its intermediate representations. Since our approach relies only on the underlying data distribution, it is agnostic of the modelling approach and hence is applicable to other cross-modal instance-level retrieval tasks as well. With experimentation over two publicly available fine-grained SBIR datasets ChairV2 and ShoeV2, we validate our approach and reveal its superiority over adapted baselines.
</details>
<details>
<summary>摘要</summary>
可以通过免费手写绘制图像检索照片的能力，高举出 Fine-grained sketch-based image retrieval（FG-SBIR）的巨大潜力。然而，它的实用化和扩展受到获得准确的绘制图像的成本的限制。一种解决方案是活动学习，可以最小化绘制图像的需求，同时保证性能的最大化。尽管在这个领域进行了广泛的研究，但是没有任何一个使用活动学习来减少 FG-SBIR 任务中的绘制努力。为了解决这个问题，我们提出了一种新的活动学习采样技术，可以减少绘制图像的需求。我们的提出的方法利用现有照片-绘制图像对的关系，以及这些图像的中间表示，来解决不确定性和多样性之间的负担。由于我们的方法只依据数据分布，因此是无关于模型采样的，因此可以应用于其他跨模态实例级检索任务中。通过对 ChairV2 和 ShoeV2 两个公开的细化 SBIR 数据集进行实验，我们证明了我们的方法的有利性，并比适应基elines进行比较。
</details></li>
</ul>
<hr>
<h2 id="Concept-explainability-for-plant-diseases-classification"><a href="#Concept-explainability-for-plant-diseases-classification" class="headerlink" title="Concept explainability for plant diseases classification"></a>Concept explainability for plant diseases classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08739">http://arxiv.org/abs/2309.08739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jihen Amara, Birgitta König-Ries, Sheeba Samuel</li>
<li>for: 这个论文旨在提高植物疾病识别的准确率和可读性，以便更好地保护农业生产和食品安全。</li>
<li>methods: 这个研究使用了深度学习的 convolutional neural networks (CNN) 进行植物疾病类型的分类。在这种方法中，研究人员使用了一种名为 Testing with Concept Activation Vectors (TCAV) 的新方法，它可以帮助理解 deep learning 模型的决策过程。</li>
<li>results: 研究人员发现，使用 TCAV 方法可以提高植物疾病识别的准确率和可读性。这种方法可以帮助人们更好地理解 deep learning 模型的决策过程，从而提高植物疾病识别的可靠性和可读性。<details>
<summary>Abstract</summary>
Plant diseases remain a considerable threat to food security and agricultural sustainability. Rapid and early identification of these diseases has become a significant concern motivating several studies to rely on the increasing global digitalization and the recent advances in computer vision based on deep learning. In fact, plant disease classification based on deep convolutional neural networks has shown impressive performance. However, these methods have yet to be adopted globally due to concerns regarding their robustness, transparency, and the lack of explainability compared with their human experts counterparts. Methods such as saliency-based approaches associating the network output to perturbations of the input pixels have been proposed to give insights into these algorithms. Still, they are not easily comprehensible and not intuitive for human users and are threatened by bias. In this work, we deploy a method called Testing with Concept Activation Vectors (TCAV) that shifts the focus from pixels to user-defined concepts. To the best of our knowledge, our paper is the first to employ this method in the field of plant disease classification. Important concepts such as color, texture and disease related concepts were analyzed. The results suggest that concept-based explanation methods can significantly benefit automated plant disease identification.
</details>
<details>
<summary>摘要</summary>
To address these limitations, we propose a method called Testing with Concept Activation Vectors (TCAV), which shifts the focus from pixels to user-defined concepts. Our method provides a more intuitive and comprehensible explanation of the algorithm's decisions, reducing the bias and uncertainty of traditional pixel-based approaches.We applied TCAV to plant disease classification and analyzed important concepts such as color, texture, and disease-related concepts. Our results suggest that concept-based explanation methods can significantly benefit automated plant disease identification. This is the first study to employ TCAV in the field of plant disease classification, and our findings demonstrate the potential of this method for improving the accuracy and reliability of plant disease detection.
</details></li>
</ul>
<hr>
<h2 id="AV-MaskEnhancer-Enhancing-Video-Representations-through-Audio-Visual-Masked-Autoencoder"><a href="#AV-MaskEnhancer-Enhancing-Video-Representations-through-Audio-Visual-Masked-Autoencoder" class="headerlink" title="AV-MaskEnhancer: Enhancing Video Representations through Audio-Visual Masked Autoencoder"></a>AV-MaskEnhancer: Enhancing Video Representations through Audio-Visual Masked Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08738">http://arxiv.org/abs/2309.08738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingjian Diao, Ming Cheng, Shitong Cheng</li>
<li>for: 学习高质量视频表示，在计算机视觉中有广泛的应用并且 remains 挑战。previous work基于mask autoencoder，如ImageMAE和VideoMAE，已经证明通过重建策略在视觉modalities中学习表示有效。但这些模型具有内在的局限性，特别是在只能从视觉modalities中提取特征时，如low-resolution和模糊原始视频时。</li>
<li>methods: 我们提出了AV-MaskEnhancer，一种 combining visual和audio信息来学习高质量视频表示。我们的方法利用视觉和听频信息的衔接性，以提高视频表示质量。</li>
<li>results: 我们在UCf101 dataset上进行了视频分类任务，与existin work比较，我们的result达到了state-of-the-art，top-1准确率为98.8%，top-5准确率为99.9%。<details>
<summary>Abstract</summary>
Learning high-quality video representation has shown significant applications in computer vision and remains challenging. Previous work based on mask autoencoders such as ImageMAE and VideoMAE has proven the effectiveness of learning representations in images and videos through reconstruction strategy in the visual modality. However, these models exhibit inherent limitations, particularly in scenarios where extracting features solely from the visual modality proves challenging, such as when dealing with low-resolution and blurry original videos. Based on this, we propose AV-MaskEnhancer for learning high-quality video representation by combining visual and audio information. Our approach addresses the challenge by demonstrating the complementary nature of audio and video features in cross-modality content. Moreover, our result of the video classification task on the UCF101 dataset outperforms the existing work and reaches the state-of-the-art, with a top-1 accuracy of 98.8% and a top-5 accuracy of 99.9%.
</details>
<details>
<summary>摘要</summary>
学习高质量视频表示方法显示有 significante 应用于计算机视觉领域，但是仍然是挑战。先前的工作基于面卷 autoencoder 如 ImageMAE 和 VideoMAE 已经证明了通过重建策略在视觉模式中学习表示方法的效iveness。然而，这些模型具有内在的限制，特别是在仅从视觉模式提取特征时遇到低分辨率和模糊的原始视频时。基于这，我们提出了 AV-MaskEnhancer，一种结合视觉和音频信息来学习高质量视频表示方法的方法。我们的方法解决了这个挑战，并证明了音频和视觉内容之间的衔接性。此外，我们在 UCF101 数据集上进行了视频分类任务，与现有的工作相比，我们的结果达到了领先水平，top-1 准确率为 98.8%，top-5 准确率为 99.9%。
</details></li>
</ul>
<hr>
<h2 id="Segmentation-of-Tubular-Structures-Using-Iterative-Training-with-Tailored-Samples"><a href="#Segmentation-of-Tubular-Structures-Using-Iterative-Training-with-Tailored-Samples" class="headerlink" title="Segmentation of Tubular Structures Using Iterative Training with Tailored Samples"></a>Segmentation of Tubular Structures Using Iterative Training with Tailored Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08727">http://arxiv.org/abs/2309.08727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Liao</li>
<li>for: 该文章是为了同时计算管状结构的分割面和中心线的最小路径方法。</li>
<li>methods: 该方法使用了基于CNN的特征EXTRACTING，并且引入了一种新的迭代训练方案，以生成更加适合的训练样本，从而解决了训练和推理时样本之间的差异。</li>
<li>results: 与七种之前的方法进行比较，该方法在三个公共数据集上（包括卫星图像和医疗图像） achievements state-of-the-art 的结果 both for segmentation masks and centerlines。<details>
<summary>Abstract</summary>
We propose a minimal path method to simultaneously compute segmentation masks and extract centerlines of tubular structures with line-topology. Minimal path methods are commonly used for the segmentation of tubular structures in a wide variety of applications. Recent methods use features extracted by CNNs, and often outperform methods using hand-tuned features. However, for CNN-based methods, the samples used for training may be generated inappropriately, so that they can be very different from samples encountered during inference. We approach this discrepancy by introducing a novel iterative training scheme, which enables generating better training samples specifically tailored for the minimal path methods without changing existing annotations. In our method, segmentation masks and centerlines are not determined after one another by post-processing, but obtained using the same steps. Our method requires only very few annotated training images. Comparison with seven previous approaches on three public datasets, including satellite images and medical images, shows that our method achieves state-of-the-art results both for segmentation masks and centerlines.
</details>
<details>
<summary>摘要</summary>
我们提出了一种最小路径方法，同时计算 tubular 结构的分割掩模和中心线。最小路径方法广泛应用于 tubular 结构的分割多种应用场景。现有方法通常使用 CNN 提取特征，并经常超越手动调整特征的方法。然而，用于 CNN 基于方法的样本可能不当生成，因此在推断中遇到的样本可能很不同。我们解决这个差异的问题，通过引入一种新的迭代训练方案，可以无需更改现有的注释，生成更适合最小路径方法的训练样本。在我们的方法中，分割掩模和中心线不再是分别由 post-processing 确定的，而是通过同一步的步骤获得。我们的方法只需要很少的注释训练图像。与前七种方法进行比较，我们的方法在三个公共数据集上（卫星图像和医疗图像）上达到了状态的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Performance-Metrics-for-Probabilistic-Ordinal-Classifiers"><a href="#Performance-Metrics-for-Probabilistic-Ordinal-Classifiers" class="headerlink" title="Performance Metrics for Probabilistic Ordinal Classifiers"></a>Performance Metrics for Probabilistic Ordinal Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08701">http://arxiv.org/abs/2309.08701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Galdran</li>
<li>for: 这篇论文是关于如何评估排序类别器的概率性预测性能。</li>
<li>methods: 本文使用了一种名为Ranked Probability Score（RPS）的评估方法，这个方法在预测场景中很受欢迎，但在图像分析领域中却没有Received much attention。</li>
<li>results: 经过了四个大规模的生医图像分类任务和三个不同的数据集，结果显示RPS是一个更适合的表现度量指标 для排序类别器的概率性预测。<details>
<summary>Abstract</summary>
Ordinal classification models assign higher penalties to predictions further away from the true class. As a result, they are appropriate for relevant diagnostic tasks like disease progression prediction or medical image grading. The consensus for assessing their categorical predictions dictates the use of distance-sensitive metrics like the Quadratic-Weighted Kappa score or the Expected Cost. However, there has been little discussion regarding how to measure performance of probabilistic predictions for ordinal classifiers. In conventional classification, common measures for probabilistic predictions are Proper Scoring Rules (PSR) like the Brier score, or Calibration Errors like the ECE, yet these are not optimal choices for ordinal classification. A PSR named Ranked Probability Score (RPS), widely popular in the forecasting field, is more suitable for this task, but it has received no attention in the image analysis community. This paper advocates the use of the RPS for image grading tasks. In addition, we demonstrate a counter-intuitive and questionable behavior of this score, and propose a simple fix for it. Comprehensive experiments on four large-scale biomedical image grading problems over three different datasets show that the RPS is a more suitable performance metric for probabilistic ordinal predictions. Code to reproduce our experiments can be found at https://github.com/agaldran/prob_ord_metrics .
</details>
<details>
<summary>摘要</summary>
Ordinal 分类模型会对预测结果进行评分，以确定预测结果与实际类别之间的相似度。因此，它们适用于有关疾病进程预测或医疗图像等级分类等有关的诊断任务。然而，对于概率性预测的性能评价还没有得到过多的讨论。在普通的分类任务中，通用的评价指标包括 próper Scoring Rules（PSR）如布里分数，或者 calibration Errors 如 ECE，但这些指标并不适用于 ordinal 分类。一种 PSR 名为 Ranked Probability Score（RPS），在预测领域中广泛使用，更适合这种任务。然而，这个指标在图像分析社区中受到了少量的关注。本文提倡使用 RPS 来进行图像等级分类任务。此外，我们还发现了这个指标的一种Counter-intuitive和问题的行为，并提出了一个简单的修复方案。我们在四个大规模的生物医学图像等级分类问题上进行了四个不同的数据集的实验，并证明了 RPS 是适用于概率性 ordinal 预测的性能指标。可以在 GitHub 上找到我们的实验代码。
</details></li>
</ul>
<hr>
<h2 id="BANSAC-A-dynamic-BAyesian-Network-for-adaptive-SAmple-Consensus"><a href="#BANSAC-A-dynamic-BAyesian-Network-for-adaptive-SAmple-Consensus" class="headerlink" title="BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus"></a>BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08690">http://arxiv.org/abs/2309.08690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valter Piedade, Pedro Miraldo</li>
<li>for: 提高 robust estimation 算法的效率，使其能够更好地应用于计算机视觉领域。</li>
<li>methods: 使用随机抽样、计算假设、计算异常点数来实现 robust estimation。</li>
<li>results: 在多个实际 datasets 中，方法可以减少计算时间而不会降低准确性，并且在准确性和计算时间之间取得了平衡。<details>
<summary>Abstract</summary>
RANSAC-based algorithms are the standard techniques for robust estimation in computer vision. These algorithms are iterative and computationally expensive; they alternate between random sampling of data, computing hypotheses, and running inlier counting. Many authors tried different approaches to improve efficiency. One of the major improvements is having a guided sampling, letting the RANSAC cycle stop sooner. This paper presents a new adaptive sampling process for RANSAC. Previous methods either assume no prior information about the inlier/outlier classification of data points or use some previously computed scores in the sampling. In this paper, we derive a dynamic Bayesian network that updates individual data points' inlier scores while iterating RANSAC. At each iteration, we apply weighted sampling using the updated scores. Our method works with or without prior data point scorings. In addition, we use the updated inlier/outlier scoring for deriving a new stopping criterion for the RANSAC loop. We test our method in multiple real-world datasets for several applications and obtain state-of-the-art results. Our method outperforms the baselines in accuracy while needing less computational time.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-e-NeRF-NeRF-from-Sparse-Noisy-Events-under-Non-Uniform-Motion"><a href="#Robust-e-NeRF-NeRF-from-Sparse-Noisy-Events-under-Non-Uniform-Motion" class="headerlink" title="Robust e-NeRF: NeRF from Sparse &amp; Noisy Events under Non-Uniform Motion"></a>Robust e-NeRF: NeRF from Sparse &amp; Noisy Events under Non-Uniform Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08596">http://arxiv.org/abs/2309.08596</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wengflow/robust-e-nerf">https://github.com/wengflow/robust-e-nerf</a></li>
<li>paper_authors: Weng Fei Low, Gim Hee Lee</li>
<li>for: 这个论文的目的是探讨如何从移动事件相机中直接和可靠地重construct NeRF。</li>
<li>methods: 该方法使用了一种新的事件生成模型，该模型考虑了各种内在参数（如时间不变、非对称阈值和延迟时间）和寸努力（如像素到像素的阈值差异），以及一对归一的正常化损失函数，使得可以有效地泛化到任意速度配置和内在参数值。</li>
<li>results: 实验结果表明，该方法在真实的视频序列和新的真实 simulate的序列上具有高效性和可靠性，能够捕捉到较为复杂的场景特征。<details>
<summary>Abstract</summary>
Event cameras offer many advantages over standard cameras due to their distinctive principle of operation: low power, low latency, high temporal resolution and high dynamic range. Nonetheless, the success of many downstream visual applications also hinges on an efficient and effective scene representation, where Neural Radiance Field (NeRF) is seen as the leading candidate. Such promise and potential of event cameras and NeRF inspired recent works to investigate on the reconstruction of NeRF from moving event cameras. However, these works are mainly limited in terms of the dependence on dense and low-noise event streams, as well as generalization to arbitrary contrast threshold values and camera speed profiles. In this work, we propose Robust e-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving event cameras under various real-world conditions, especially from sparse and noisy events generated under non-uniform motion. It consists of two key components: a realistic event generation model that accounts for various intrinsic parameters (e.g. time-independent, asymmetric threshold and refractory period) and non-idealities (e.g. pixel-to-pixel threshold variation), as well as a complementary pair of normalized reconstruction losses that can effectively generalize to arbitrary speed profiles and intrinsic parameter values without such prior knowledge. Experiments on real and novel realistically simulated sequences verify our effectiveness. Our code, synthetic dataset and improved event simulator are public.
</details>
<details>
<summary>摘要</summary>
In this work, we propose Robust e-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving event cameras under various real-world conditions, including sparse and noisy events generated under non-uniform motion. Our method consists of two key components: a realistic event generation model that accounts for various intrinsic parameters (such as time-independent, asymmetric threshold, and refractory period) and non-idealities (such as pixel-to-pixel threshold variation), and a complementary pair of normalized reconstruction losses that can effectively generalize to arbitrary speed profiles and intrinsic parameter values without prior knowledge.Experiments on real and novel realistically simulated sequences have verified our effectiveness. Our code, synthetic dataset, and improved event simulator are publicly available.
</details></li>
</ul>
<hr>
<h2 id="Robust-Frame-to-Frame-Camera-Rotation-Estimation-in-Crowded-Scenes"><a href="#Robust-Frame-to-Frame-Camera-Rotation-Estimation-in-Crowded-Scenes" class="headerlink" title="Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes"></a>Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08588">http://arxiv.org/abs/2309.08588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Neabfi/robust-rotation-estimation">https://github.com/Neabfi/robust-rotation-estimation</a></li>
<li>paper_authors: Fabien Delattre, David Dirnfeld, Phat Nguyen, Stephen Scarano, Michael J. Jones, Pedro Miraldo, Erik Learned-Miller</li>
<li>for: 估计摄像头旋转在实际场景中，尤其是手持式单目视频中，是一个尚未得到充分研究的问题。</li>
<li>methods: 我们提出了一种使用HOUGH transform在SO(3)上进行高效和稳定的摄像头旋转估计方法。</li>
<li>results: 与其他比较快速的方法相比，我们的方法可以减少错误率大约50%，并且在任何情况下都比其他方法更加准确。这表示我们的方法在实际场景中表现出了强大的新表现点。<details>
<summary>Abstract</summary>
We present an approach to estimating camera rotation in crowded, real-world scenes from handheld monocular video. While camera rotation estimation is a well-studied problem, no previous methods exhibit both high accuracy and acceptable speed in this setting. Because the setting is not addressed well by other datasets, we provide a new dataset and benchmark, with high-accuracy, rigorously verified ground truth, on 17 video sequences. Methods developed for wide baseline stereo (e.g., 5-point methods) perform poorly on monocular video. On the other hand, methods used in autonomous driving (e.g., SLAM) leverage specific sensor setups, specific motion models, or local optimization strategies (lagging batch processing) and do not generalize well to handheld video. Finally, for dynamic scenes, commonly used robustification techniques like RANSAC require large numbers of iterations, and become prohibitively slow. We introduce a novel generalization of the Hough transform on SO(3) to efficiently and robustly find the camera rotation most compatible with optical flow. Among comparably fast methods, ours reduces error by almost 50\% over the next best, and is more accurate than any method, irrespective of speed. This represents a strong new performance point for crowded scenes, an important setting for computer vision. The code and the dataset are available at https://fabiendelattre.com/robust-rotation-estimation.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法来估计拍摄机器人的旋转角度在实际场景中，基于单目视频。而Camera rotation estimation是一个非常研究过的问题，但没有任何方法能同时具备高精度和可接受的速度。由于这种场景没有其他数据集可供参考，我们提供了一个新的数据集和benchmark，其中的高精度、严格验证的参考数据来自17个视频序列。广泛使用的五点方法（例如，用于宽基线探测）在单目视频中表现糟糕，而自动驾驶领域中使用的SLAM方法则具有特定的传感器设置、特定的运动模型或本地优化策略（延迟批处理），这些方法无法通过到手持视频。此外，对于动态场景，通常使用的Robustification技术，如RANSAC，需要大量的迭代，成为无法进行的慢卡。我们介绍了一种新的SO(3)上的投影变换的普适扩展，以高效和可靠地找到拍摄机器人的旋转角度。与其他快速方法相比，我们的方法可以减少错误率大约50%，并且在任何速度下都高于任何方法。这代表了一个新的性能点，在实际场景中具有重要意义。我们的代码和数据集可以在https://fabiendelattre.com/robust-rotation-estimation上获取。
</details></li>
</ul>
<hr>
<h2 id="Replacing-softmax-with-ReLU-in-Vision-Transformers"><a href="#Replacing-softmax-with-ReLU-in-Vision-Transformers" class="headerlink" title="Replacing softmax with ReLU in Vision Transformers"></a>Replacing softmax with ReLU in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08586">http://arxiv.org/abs/2309.08586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mitchell Wortsman, Jaehoon Lee, Justin Gilmer, Simon Kornblith</li>
<li>for: 这研究探讨了在替换注意力软 макс函数时对准确性的影响，并发现在视transformer上使用ReLU活动可以 Mitigate this degradation.</li>
<li>methods: 这研究使用了ImageNet-21k数据集训练小到大的视transformer，并 comparesthe performance of ReLU-attention和softmax-attention。</li>
<li>results: 结果表明，ReLU-attention可以与softmax-attention相比，在计算规模上Scaling behavior的表现相似或相当。<details>
<summary>Abstract</summary>
Previous research observed accuracy degradation when replacing the attention softmax with a point-wise activation such as ReLU. In the context of vision transformers, we find that this degradation is mitigated when dividing by sequence length. Our experiments training small to large vision transformers on ImageNet-21k indicate that ReLU-attention can approach or match the performance of softmax-attention in terms of scaling behavior as a function of compute.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)前期研究发现，当将注意力软 макс replaced with point-wise 活化函数如ReLU时，会导致准确性下降。在视觉转换器上，我们发现这种下降可以通过序列长度除法缓解。我们在ImageNet-21k上训练小到大的视觉转换器，发现ReLU-attention可以与softmax-attention相当，以计算行为为函数来规定缩放性能。
</details></li>
</ul>
<hr>
<h2 id="Viewpoint-Integration-and-Registration-with-Vision-Language-Foundation-Model-for-Image-Change-Understanding"><a href="#Viewpoint-Integration-and-Registration-with-Vision-Language-Foundation-Model-for-Image-Change-Understanding" class="headerlink" title="Viewpoint Integration and Registration with Vision Language Foundation Model for Image Change Understanding"></a>Viewpoint Integration and Registration with Vision Language Foundation Model for Image Change Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08585">http://arxiv.org/abs/2309.08585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaonan Lu, Jianlong Yuan, Ruigang Niu, Yuan Hu, Fan Wang</li>
<li>for: 本研究旨在解决现有的图像变换理解（ICU）任务中，已有的视觉语言基础模型（VLFM）的缺陷，即它们只能单独处理单个图像，而不能理解多个图像之间的变化。</li>
<li>methods: 我们提出了一种视角集成和准确处理方法，包括在预训练编码器中插入设计的可学习适配器和综合适配器，以有效地捕捉图像对的变化。此外，我们还设计了视角协调流和semantic强调模块，以降低视角变化对视觉和semantic空间的影响。</li>
<li>results: 我们在CLEVR-Change和Spot-the-Diff等测试集上进行了实验，结果显示，我们的方法可以在所有纬度上达到状态的排名，包括对应的语义描述和图像对比等。<details>
<summary>Abstract</summary>
Recently, the development of pre-trained vision language foundation models (VLFMs) has led to remarkable performance in many tasks. However, these models tend to have strong single-image understanding capability but lack the ability to understand multiple images. Therefore, they cannot be directly applied to cope with image change understanding (ICU), which requires models to capture actual changes between multiple images and describe them in language. In this paper, we discover that existing VLFMs perform poorly when applied directly to ICU because of the following problems: (1) VLFMs generally learn the global representation of a single image, while ICU requires capturing nuances between multiple images. (2) The ICU performance of VLFMs is significantly affected by viewpoint variations, which is caused by the altered relationships between objects when viewpoint changes. To address these problems, we propose a Viewpoint Integration and Registration method. Concretely, we introduce a fused adapter image encoder that fine-tunes pre-trained encoders by inserting designed trainable adapters and fused adapters, to effectively capture nuances between image pairs. Additionally, a viewpoint registration flow and a semantic emphasizing module are designed to reduce the performance degradation caused by viewpoint variations in the visual and semantic space, respectively. Experimental results on CLEVR-Change and Spot-the-Diff demonstrate that our method achieves state-of-the-art performance in all metrics.
</details>
<details>
<summary>摘要</summary>
近些年来，预训 vision language foundation models（VLFMs）的发展已经带来了多个任务的出色表现。然而，这些模型具有强大的单个图像理解能力，但缺乏多图像理解能力。因此，它们无法直接应用于图像变化理解（ICU）任务，ICU任务需要模型捕捉多个图像之间的实际变化并用语言描述。在这篇论文中，我们发现现有的 VLFMs 当直接应用于 ICU 时表现不佳，主要因为以下两个问题：（1） VLFMs 通常学习单个图像的全局表示，而 ICU 需要多图像之间的细节捕捉。（2） ICU 性能的变化会受到视角变化的影响，这是因为对象之间的关系变化导致的。为解决这些问题，我们提出了一种 Viewpoint Integration and Registration 方法。具体来说，我们引入了一个混合适配器图像编码器，通过插入设计的可学习适配器和混合适配器，有效地捕捉图像对的细节变化。此外，我们还设计了一种视角协调流和一种semantic Emphasizing模块，以降低由视角变化引起的视觉和semantic空间中的性能下降。实验结果表明，我们的方法在 CLEVR-Change 和 Spot-the-Diff 上达到了所有纪录的性能。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Different-Backbone-Architecture-on-Autonomous-Vehicle-Dataset"><a href="#The-Impact-of-Different-Backbone-Architecture-on-Autonomous-Vehicle-Dataset" class="headerlink" title="The Impact of Different Backbone Architecture on Autonomous Vehicle Dataset"></a>The Impact of Different Backbone Architecture on Autonomous Vehicle Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08564">http://arxiv.org/abs/2309.08564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Ding, Azim Eskandarian</li>
<li>for: 这研究旨在评估不同背部架构在自动驾驶环境中的对象检测性能。</li>
<li>methods: 研究使用了三个常见的自动驾驶数据集：KITTI、NuScenes和BDD，对不同背部架构进行对比，以评估它们在对象检测任务中的性能。</li>
<li>results: 研究发现，不同背部架构在不同数据集上的性能有很大差异，而且一些背部架构在某些数据集上表现更好。<details>
<summary>Abstract</summary>
Object detection is a crucial component of autonomous driving, and many detection applications have been developed to address this task. These applications often rely on backbone architectures, which extract representation features from inputs to perform the object detection task. The quality of the features extracted by the backbone architecture can have a significant impact on the overall detection performance. Many researchers have focused on developing new and improved backbone architectures to enhance the efficiency and accuracy of object detection applications. While these backbone architectures have shown state-of-the-art performance on generic object detection datasets like MS-COCO and PASCAL-VOC, evaluating their performance under an autonomous driving environment has not been previously explored. To address this, our study evaluates three well-known autonomous vehicle datasets, namely KITTI, NuScenes, and BDD, to compare the performance of different backbone architectures on object detection tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate(Object detection is a crucial component of autonomous driving, and many detection applications have been developed to address this task. These applications often rely on backbone architectures, which extract representation features from inputs to perform the object detection task. The quality of the features extracted by the backbone architecture can have a significant impact on the overall detection performance. Many researchers have focused on developing new and improved backbone architectures to enhance the efficiency and accuracy of object detection applications. While these backbone architectures have shown state-of-the-art performance on generic object detection datasets like MS-COCO and PASCAL-VOC, evaluating their performance under an autonomous driving environment has not been previously explored. To address this, our study evaluates three well-known autonomous vehicle datasets, namely KITTI, NuScenes, and BDD, to compare the performance of different backbone architectures on object detection tasks.)中文翻译：对于自动驾驶中的对象检测，有许多检测应用程序已经被开发出来解决这个问题。这些应用程序通常基于后凹结构，从输入中提取表示特征来进行对象检测任务。后凹结构的特征提取质量可以直接影响对象检测总性能。许多研究人员已经专注于开发新的和改进的后凹结构，以提高对象检测应用程序的效率和准确性。而这些后凹结构在通用对象检测数据集上表现出了state-of-the-art的性能，但是在自动驾驶环境中评估它们的性能尚未得到过探讨。为了解决这个问题，我们的研究对三个著名的自动驾驶数据集，namely KITTI, NuScenes, and BDD,进行对比不同后凹结构在对象检测任务中的性能。)
</details></li>
</ul>
<hr>
<h2 id="Automated-dermatoscopic-pattern-discovery-by-clustering-neural-network-output-for-human-computer-interaction"><a href="#Automated-dermatoscopic-pattern-discovery-by-clustering-neural-network-output-for-human-computer-interaction" class="headerlink" title="Automated dermatoscopic pattern discovery by clustering neural network output for human-computer interaction"></a>Automated dermatoscopic pattern discovery by clustering neural network output for human-computer interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08533">http://arxiv.org/abs/2309.08533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lidia Talavera-Martinez, Philipp Tschandl<br>for: 这项研究的目的是自动找到大量图像数据集中的可读性高的视觉模式，以便从中提取知识。methods: 该研究使用了k-means算法和神经网络提取的图像特征来自动对图像分类。results: 研究发现，通过使用优化的弯曲点方法或凝结度量来选择最佳分裂点，可以生成高度可读性的视觉模式，并且大多数分群可以与先前描述的皮肤病诊断模式相匹配。<details>
<summary>Abstract</summary>
Background: As available medical image datasets increase in size, it becomes infeasible for clinicians to review content manually for knowledge extraction. The objective of this study was to create an automated clustering resulting in human-interpretable pattern discovery.   Methods: Images from the public HAM10000 dataset, including 7 common pigmented skin lesion diagnoses, were tiled into 29420 tiles and clustered via k-means using neural network-extracted image features. The final number of clusters per diagnosis was chosen by either the elbow method or a compactness metric balancing intra-lesion variance and cluster numbers. The amount of resulting non-informative clusters, defined as those containing less than six image tiles, was compared between the two methods.   Results: Applying k-means, the optimal elbow cutoff resulted in a mean of 24.7 (95%-CI: 16.4-33) clusters for every included diagnosis, including 14.9% (95% CI: 0.8-29.0) non-informative clusters. The optimal cutoff, as estimated by the compactness metric, resulted in significantly fewer clusters (13.4; 95%-CI 11.8-15.1; p=0.03) and less non-informative ones (7.5%; 95% CI: 0-19.5; p=0.017). The majority of clusters (93.6%) from the compactness metric could be manually mapped to previously described dermatoscopic diagnostic patterns.   Conclusions: Automatically constraining unsupervised clustering can produce an automated extraction of diagnostically relevant and human-interpretable clusters of visual patterns from a large image dataset.
</details>
<details>
<summary>摘要</summary>
背景：随着医疗影像数据集的增加，为了EXTRACT知识，临床医生无法 manually review content。这项研究的目标是通过自动 clustering 实现人类可读的模式发现。方法：来自公共HAM10000数据集的皮肤悬液瘤病诊断图像，经过分割成29420个图像块，然后使用神经网络提取的图像特征进行k-means clustering。最终选择每个诊断的最佳割分数量是通过膝盖方法或尺度矩阵来决定。对于每个诊断，计算了非参考分布（即包含 menos than six 图像块的分布）的比例。结果：通过k-means clustering，使用最佳膝盖割分数量时，每个诊断的平均分布数量为24.7（95% CI：16.4-33），包含14.9%（95% CI：0.8-29.0）的非参考分布。使用尺度矩阵来选择割分数量时，得到的分布数量较少（13.4；95% CI：11.8-15.1），同时非参考分布的比例较低（7.5%; 95% CI：0-19.5）。大多数分布（93.6%）可以 manually mapping 到已知的DERMATOSCOPIC diagnostic pattern。结论：通过自动 constraining 不supervised clustering，可以生成一个自动EXTRACT的Visual pattern的diagnostically relevant和人类可读的分布。
</details></li>
</ul>
<hr>
<h2 id="Breathing-New-Life-into-3D-Assets-with-Generative-Repainting"><a href="#Breathing-New-Life-into-3D-Assets-with-Generative-Repainting" class="headerlink" title="Breathing New Life into 3D Assets with Generative Repainting"></a>Breathing New Life into 3D Assets with Generative Repainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08523">http://arxiv.org/abs/2309.08523</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toshas/remesh_isotropic_planar">https://github.com/toshas/remesh_isotropic_planar</a></li>
<li>paper_authors: Tianfu Wang, Menelaos Kanakis, Konrad Schindler, Luc Van Gool, Anton Obukhov</li>
<li>for: 这篇论文主要旨在提出一种基于扩散模型的3D资产重新绘制方法，以提高3D资产的生成质量。</li>
<li>methods: 该方法利用了2D扩散模型和3D神经场的共振，并通过独立使用这两种工具来实现模块化的重新绘制。</li>
<li>results: 通过大规模的实验， authors 发现了该方法的优势，包括对多种物体和类别的生成质量和速度。In English, that would be:</li>
<li>for: The paper primarily aims to propose a method for re-rendering 3D assets based on diffusion models, to improve the quality of 3D asset generation.</li>
<li>methods: The method utilizes the entanglement of 2D diffusion models and 3D neural fields, and achieves modularization by independently using these two tools.</li>
<li>results: Through large-scale experiments, the authors found advantages of their method, including improved generation quality and speed for multiple objects and categories.<details>
<summary>Abstract</summary>
Diffusion-based text-to-image models ignited immense attention from the vision community, artists, and content creators. Broad adoption of these models is due to significant improvement in the quality of generations and efficient conditioning on various modalities, not just text. However, lifting the rich generative priors of these 2D models into 3D is challenging. Recent works have proposed various pipelines powered by the entanglement of diffusion models and neural fields. We explore the power of pretrained 2D diffusion models and standard 3D neural radiance fields as independent, standalone tools and demonstrate their ability to work together in a non-learned fashion. Such modularity has the intrinsic advantage of eased partial upgrades, which became an important property in such a fast-paced domain. Our pipeline accepts any legacy renderable geometry, such as textured or untextured meshes, orchestrates the interaction between 2D generative refinement and 3D consistency enforcement tools, and outputs a painted input geometry in several formats. We conduct a large-scale study on a wide range of objects and categories from the ShapeNetSem dataset and demonstrate the advantages of our approach, both qualitatively and quantitatively. Project page: https://www.obukhov.ai/repainting_3d_assets
</details>
<details>
<summary>摘要</summary>
填充基于模型在图像创建领域内引起了广泛的关注，艺术家、内容创作者以及视觉社区。这些模型的广泛采用是因为它们在质量和多Modal Conditioning方面提供了显著改进。然而，将2D模型中的富有的生成假设提升到3D是一项挑战。最近的工作提出了基于填充模型和神经场的共融pipeline。我们研究了预训练的2D填充模型和标准3D神经辐射场的独立使用，以及它们之间的非学习协作。这种模块化的设计具有内置的升级优点，可以方便地更新和改进不同模块。我们的管道可以接受任何可 renderable 的geometry，如纹理或无纹理的三角形，并将2D生成精度和3D一致性检查工具相互协作，输出一个涂抹的输入geometry。我们对ShapeNetSem数据集上的各种物体和类型进行了大规模的研究，并证明了我们的方法的优势， both qualitatively和quantitatively。项目页面：https://www.obukhov.ai/repainting_3d_assets
</details></li>
</ul>
<hr>
<h2 id="Generalised-Probabilistic-Diffusion-Scale-Spaces"><a href="#Generalised-Probabilistic-Diffusion-Scale-Spaces" class="headerlink" title="Generalised Probabilistic Diffusion Scale-Spaces"></a>Generalised Probabilistic Diffusion Scale-Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08511">http://arxiv.org/abs/2309.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pascal Peter</li>
<li>for: 这篇论文是关于 probabilistic diffusion models 的研究，用于抽象新图像。</li>
<li>methods: 该方法基于物理中的漫游扩散概念，对图像进行噪声和模糊等perturbations，并使用概率分布来描述图像。</li>
<li>results: 该方法可以实现图像抽象，并且可以根据侧信息进行条件生成图像。目前大多数研究都是关注实践应用，而论文背景还有很多未解之处，尤其是与经典图像滤波器之间的关系。<details>
<summary>Abstract</summary>
Probabilistic diffusion models excel at sampling new images from learned distributions. Originally motivated by drift-diffusion concepts from physics, they apply image perturbations such as noise and blur in a forward process that results in a tractable probability distribution. A corresponding learned reverse process generates images and can be conditioned on side information, which leads to a wide variety of practical applications. Most of the research focus currently lies on practice-oriented extensions. In contrast, the theoretical background remains largely unexplored, in particular the relations to drift-diffusion. In order to shed light on these connections to classical image filtering, we propose a generalised scale-space theory for probabilistic diffusion models. Moreover, we show conceptual and empirical connections to diffusion and osmosis filters.
</details>
<details>
<summary>摘要</summary>
probabilistic diffusion models  excel at sampling new images from learned distributions. originally motivated by drift-diffusion concepts from physics, they apply image perturbations such as noise and blur in a forward process that results in a tractable probability distribution. a corresponding learned reverse process generates images and can be conditioned on side information, which leads to a wide variety of practical applications. most of the research focus currently lies on practice-oriented extensions. in contrast, the theoretical background remains largely unexplored, in particular the relations to drift-diffusion. in order to shed light on these connections to classical image filtering, we propose a generalised scale-space theory for probabilistic diffusion models. moreover, we show conceptual and empirical connections to diffusion and osmosis filters.Here's the text in Traditional Chinese:probabilistic diffusion models  excel at sampling new images from learned distributions. originally motivated by drift-diffusion concepts from physics, they apply image perturbations such as noise and blur in a forward process that results in a tractable probability distribution. a corresponding learned reverse process generates images and can be conditioned on side information, which leads to a wide variety of practical applications. most of the research focus currently lies on practice-oriented extensions. in contrast, the theoretical background remains largely unexplored, in particular the relations to drift-diffusion. in order to shed light on these connections to classical image filtering, we propose a generalised scale-space theory for probabilistic diffusion models. moreover, we show conceptual and empirical connections to diffusion and osmosis filters.
</details></li>
</ul>
<hr>
<h2 id="OccupancyDETR-Making-Semantic-Scene-Completion-as-Straightforward-as-Object-Detection"><a href="#OccupancyDETR-Making-Semantic-Scene-Completion-as-Straightforward-as-Object-Detection" class="headerlink" title="OccupancyDETR: Making Semantic Scene Completion as Straightforward as Object Detection"></a>OccupancyDETR: Making Semantic Scene Completion as Straightforward as Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08504">http://arxiv.org/abs/2309.08504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jypjypjypjyp/occupancydetr">https://github.com/jypjypjypjyp/occupancydetr</a></li>
<li>paper_authors: Yupeng Jia, Jie He, Runze Chen, Fang Zhao, Haiyong Luo</li>
<li>for: The paper is written for the purpose of proposing a novel 3D semantic occupancy perception method for robotic applications like autonomous driving, which can improve the ability of robots to understand their surroundings while reducing computational demand.</li>
<li>methods: The proposed method, OccupancyDETR, consists of a DETR-like object detection module and a 3D occupancy decoder module, which integrate object detection and 3D occupancy grid prediction to simplify the method and improve performance on small objects.</li>
<li>results: The proposed method is demonstrated on the SemanticKITTI dataset and achieves an mIoU of 23 and a processing speed of 6 frames per second, showcasing its effectiveness and potential for real-time 3D semantic scene completion.<details>
<summary>Abstract</summary>
Visual-based 3D semantic occupancy perception (also known as 3D semantic scene completion) is a new perception paradigm for robotic applications like autonomous driving. Compared with Bird's Eye View (BEV) perception, it extends the vertical dimension, significantly enhancing the ability of robots to understand their surroundings. However, due to this very reason, the computational demand for current 3D semantic occupancy perception methods generally surpasses that of BEV perception methods and 2D perception methods. We propose a novel 3D semantic occupancy perception method, OccupancyDETR, which consists of a DETR-like object detection module and a 3D occupancy decoder module. The integration of object detection simplifies our method structurally - instead of predicting the semantics of each voxels, it identifies objects in the scene and their respective 3D occupancy grids. This speeds up our method, reduces required resources, and leverages object detection algorithm, giving our approach notable performance on small objects. We demonstrate the effectiveness of our proposed method on the SemanticKITTI dataset, showcasing an mIoU of 23 and a processing speed of 6 frames per second, thereby presenting a promising solution for real-time 3D semantic scene completion.
</details>
<details>
<summary>摘要</summary>
visuomotive 3D semantic occupancy perception (也称为3D semantic scene completion) 是一种新的感知 paradigm for robotic applications like autonomous driving. 相比 Bird's Eye View (BEV) perception, 它扩展了垂直维度，明显提高了机器人的周围环境理解能力。然而，由于这个very reason, 当前3D semantic occupancy perception方法的计算需求通常超过 BEV perception方法和2D perception方法。我们提出了一种新的3D semantic occupancy perception方法，OccupancyDETR，该方法包括一个 DETR-like object detection模块和一个 3D occupancy decoder模块。该模块的结合使得我们的方法在结构上更加简单 - 而不是预测每个 voxel 的 semantics, 它将场景中的对象和它们的相对应的 3D occupancy 网格标识出来。这使得我们的方法更快速、需要 fewer resources，并且可以利用对象检测算法，从而实现了对小对象的出色表现。我们在 SemanticKITTI 数据集上展示了我们的提议方法的效果，其中 mIoU 为 23 和处理速度为 6 帧每秒，因此表现出了可靠的解决方案 для实时3D semantic scene completion。
</details></li>
</ul>
<hr>
<h2 id="YCB-Ev-Event-vision-dataset-for-6DoF-object-pose-estimation"><a href="#YCB-Ev-Event-vision-dataset-for-6DoF-object-pose-estimation" class="headerlink" title="YCB-Ev: Event-vision dataset for 6DoF object pose estimation"></a>YCB-Ev: Event-vision dataset for 6DoF object pose estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08482">http://arxiv.org/abs/2309.08482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paroj/ycbev">https://github.com/paroj/ycbev</a></li>
<li>paper_authors: Pavel Rojtberg, Thomas Pöllabauer</li>
<li>For:  Introduces the YCB-Ev dataset, a synchronized RGB-D and event data dataset for evaluating 6DoF object pose estimation algorithms.* Methods: Provides ground truth 6DoF object poses for the same 21 YCB objects as the YCB-Video dataset, enabling evaluation of algorithm performance when transferred across datasets.* Results: Evaluates the generalization capabilities of two state-of-the-art algorithms using the novel YCB-V sequences in the dataset.Here’s the full summary in Simplified Chinese:* For: 本研究 introduce YCB-Ev dataset，这是一个同步RGB-D和事件数据集，用于评估6DoF对象 pose 估计算法。* Methods: YCB-Ev dataset提供了同YCB-Video dataset中的21个物体的6DoF对象pose的ground truth数据，使得算法在不同dataset之间进行评估。* Results: 研究使用YCB-Ev dataset中的新的YCB-V序列评估了两种现状顶尖算法的泛化能力。<details>
<summary>Abstract</summary>
Our work introduces the YCB-Ev dataset, which contains synchronized RGB-D frames and event data that enables evaluating 6DoF object pose estimation algorithms using these modalities.   This dataset provides ground truth 6DoF object poses for the same 21 YCB objects \cite{calli2017yale} that were used in the YCB-Video (YCB-V) dataset, enabling the evaluation of algorithm performance when transferred across datasets.   The dataset consists of 21 synchronized event and RGB-D sequences, amounting to a total of 7:43 minutes of video. Notably, 12 of these sequences feature the same object arrangement as the YCB-V subset used in the BOP challenge.   Our dataset is the first to provide ground truth 6DoF pose data for event streams. Furthermore, we evaluate the generalization capabilities of two state-of-the-art algorithms, which were pre-trained for the BOP challenge, using our novel YCB-V sequences.   The proposed dataset is available at https://github.com/paroj/ycbev.
</details>
<details>
<summary>摘要</summary>
我们的工作介绍了YCB-Ev数据集，该数据集包含同步RGB-D帧和事件数据，可以用这些模式评估6DoF物体姿态估计算法。这个数据集提供了21个YCB物体的真实6DoF姿态标准，这些物体与YCB-Video（YCB-V）数据集中使用的同一个物体设置相同。因此，可以评估算法在不同数据集之间的性能转移。该数据集包含21个同步RGB-D序列，总计7分43秒的视频。值得注意的是，12个序列包含YCB-V数据集中使用的同一个物体设置。我们的数据集是首个提供事件流真实6DoF姿态数据的 dataset。此外，我们使用我们的YCB-V新序列评估了两个现状最佳算法的泛化能力。我们的数据集可以在https://github.com/paroj/ycbev上下载。
</details></li>
</ul>
<hr>
<h2 id="3D-Arterial-Segmentation-via-Single-2D-Projections-and-Depth-Supervision-in-Contrast-Enhanced-CT-Images"><a href="#3D-Arterial-Segmentation-via-Single-2D-Projections-and-Depth-Supervision-in-Contrast-Enhanced-CT-Images" class="headerlink" title="3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images"></a>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08481">http://arxiv.org/abs/2309.08481</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alinafdima/3dseg-mip-depth">https://github.com/alinafdima/3dseg-mip-depth</a></li>
<li>paper_authors: Alina F. Dima, Veronika A. Zimmer, Martin J. Menten, Hongwei Bran Li, Markus Graf, Tristan Lemke, Philipp Raffler, Robert Graf, Jan S. Kirschke, Rickmer Braren, Daniel Rueckert</li>
<li>for: 这个论文的目的是提出一种新的3D血管分割方法，以便更好地诊断和治疗许多血管疾病。</li>
<li>methods: 该方法使用深度学习技术，并且只需要一个已经标注过的2D图像来进行训练。</li>
<li>results: 该方法可以准确地分割3D血管，并且可以减少标注工作的努力。<details>
<summary>Abstract</summary>
Automated segmentation of the blood vessels in 3D volumes is an essential step for the quantitative diagnosis and treatment of many vascular diseases. 3D vessel segmentation is being actively investigated in existing works, mostly in deep learning approaches. However, training 3D deep networks requires large amounts of manual 3D annotations from experts, which are laborious to obtain. This is especially the case for 3D vessel segmentation, as vessels are sparse yet spread out over many slices and disconnected when visualized in 2D slices. In this work, we propose a novel method to segment the 3D peripancreatic arteries solely from one annotated 2D projection per training image with depth supervision. We perform extensive experiments on the segmentation of peripancreatic arteries on 3D contrast-enhanced CT images and demonstrate how well we capture the rich depth information from 2D projections. We demonstrate that by annotating a single, randomly chosen projection for each training sample, we obtain comparable performance to annotating multiple 2D projections, thereby reducing the annotation effort. Furthermore, by mapping the 2D labels to the 3D space using depth information and incorporating this into training, we almost close the performance gap between 3D supervision and 2D supervision. Our code is available at: https://github.com/alinafdima/3Dseg-mip-depth.
</details>
<details>
<summary>摘要</summary>
自动化分割血管在3DVolume中是诊断和治疗许多血管疾病的关键步骤。现有许多研究在深度学习方法中进行3D血管分割，但是训练3D深度网络需要大量的手动3D注解从专家手上，这很困难。特别是在3D血管分割方面，血管稀疏，分散在多个片段和2D片段中断掉，从而使得手动注解变得更加困难。在这种情况下，我们提出了一种新的方法，可以从单个注解的2D投影中分割3D血管，并且只需要每个训练样本一个随机选择的2D投影。我们对3D对照CT图像进行了广泛的实验，并证明我们可以从2D投影中获得丰富的深度信息，并将其纳入训练中。此外，我们将2D标签映射到3D空间中使用深度信息，并将其包含在训练中，从而减少了注解努力。此外，我们的代码可以在以下链接中找到：https://github.com/alinafdima/3Dseg-mip-depth。
</details></li>
</ul>
<hr>
<h2 id="PoseFix-Correcting-3D-Human-Poses-with-Natural-Language"><a href="#PoseFix-Correcting-3D-Human-Poses-with-Natural-Language" class="headerlink" title="PoseFix: Correcting 3D Human Poses with Natural Language"></a>PoseFix: Correcting 3D Human Poses with Natural Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08480">http://arxiv.org/abs/2309.08480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ginger Delmas, Philippe Weinzaepfel, Francesc Moreno-Noguer, Grégory Rogez</li>
<li>for:  corrections 3D human poses with natural language</li>
<li>methods:  introduce the PoseFix dataset, text-based pose editing, correctional text generation</li>
<li>results:  potential for assisted 3D character animation, robot teaching<details>
<summary>Abstract</summary>
Automatically producing instructions to modify one's posture could open the door to endless applications, such as personalized coaching and in-home physical therapy. Tackling the reverse problem (i.e., refining a 3D pose based on some natural language feedback) could help for assisted 3D character animation or robot teaching, for instance. Although a few recent works explore the connections between natural language and 3D human pose, none focus on describing 3D body pose differences. In this paper, we tackle the problem of correcting 3D human poses with natural language. To this end, we introduce the PoseFix dataset, which consists of several thousand paired 3D poses and their corresponding text feedback, that describe how the source pose needs to be modified to obtain the target pose. We demonstrate the potential of this dataset on two tasks: (1) text-based pose editing, that aims at generating corrected 3D body poses given a query pose and a text modifier; and (2) correctional text generation, where instructions are generated based on the differences between two body poses.
</details>
<details>
<summary>摘要</summary>
自动生成修改姿势的指令可以开启无数应用程序的 possibilties，如个性化指导和家庭物理治疗。解决反向问题（即基于自然语言反馈修改3D人体姿势）可以帮助助手动画或机器人教学等领域。虽然一些最近的研究探讨了自然语言与3D人体姿势之间的关系，但none of them focus on描述3D人体姿势的差异。在这篇论文中，我们面临着修正3D人体姿势的问题，并提出了PoseFix数据集，该数据集包括数千个对应的3D姿势和其相应的自然语言反馈，用于描述源姿势需要如何修改以获得目标姿势。我们在两个任务上示cases：（1）文本基于姿势编辑，即根据查询姿势和文本修改器生成修 corrected 3D人体姿势;和（2）修正文本生成，即根据两个人体姿势之间的差异生成指令。
</details></li>
</ul>
<hr>
<h2 id="TreeLearn-A-Comprehensive-Deep-Learning-Method-for-Segmenting-Individual-Trees-from-Forest-Point-Clouds"><a href="#TreeLearn-A-Comprehensive-Deep-Learning-Method-for-Segmenting-Individual-Trees-from-Forest-Point-Clouds" class="headerlink" title="TreeLearn: A Comprehensive Deep Learning Method for Segmenting Individual Trees from Forest Point Clouds"></a>TreeLearn: A Comprehensive Deep Learning Method for Segmenting Individual Trees from Forest Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08471">http://arxiv.org/abs/2309.08471</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ecker-lab/treelearn">https://github.com/ecker-lab/treelearn</a></li>
<li>paper_authors: Jonathan Henrich, Jan van Delden, Dominik Seidel, Thomas Kneib, Alexander Ecker</li>
<li>for: 该研究旨在提出一种基于深度学习的森林点云Semantic和实例分割方法，以提高森林管理中的信息提取。</li>
<li>methods: 该方法基于已经分割的点云数据，通过深度学习来学习Semantic和实例特征，而不需要手动设计特征和算法。</li>
<li>results: 对比Lidar360软件标注的点云数据，该方法在 benchmark 数据集上表现相当或更好，而且可以通过细化训练来大幅提高性能。<details>
<summary>Abstract</summary>
Laser-scanned point clouds of forests make it possible to extract valuable information for forest management. To consider single trees, a forest point cloud needs to be segmented into individual tree point clouds. Existing segmentation methods are usually based on hand-crafted algorithms, such as identifying trunks and growing trees from them, and face difficulties in dense forests with overlapping tree crowns. In this study, we propose \mbox{TreeLearn}, a deep learning-based approach for semantic and instance segmentation of forest point clouds. Unlike previous methods, TreeLearn is trained on already segmented point clouds in a data-driven manner, making it less reliant on predefined features and algorithms. Additionally, we introduce a new manually segmented benchmark forest dataset containing 156 full trees, and 79 partial trees, that have been cleanly segmented by hand. This enables the evaluation of instance segmentation performance going beyond just evaluating the detection of individual trees. We trained TreeLearn on forest point clouds of 6665 trees, labeled using the Lidar360 software. An evaluation on the benchmark dataset shows that TreeLearn performs equally well or better than the algorithm used to generate its training data. Furthermore, the method's performance can be vastly improved by fine-tuning on the cleanly labeled benchmark dataset. The TreeLearn code is availabe from https://github.com/ecker-lab/TreeLearn. The data as well as trained models can be found at https://doi.org/10.25625/VPMPID.
</details>
<details>
<summary>摘要</summary>
lazier-扫描的林地点云可以提供有价值的信息 для森林管理。为了考虑单个树木，林地点云需要被分割成 individuak树木点云。现有的分割方法通常基于手工编写的算法，如从树干上识别树木并在其上生长，并在稠密的林地中遇到树叶重叠时遇到困难。在这项研究中，我们提出了 \mbox{TreeLearn}，一种基于深度学习的 semantic和实例分割方法 для森林点云。与先前的方法不同，TreeLearn 通过数据驱动的方式进行训练，使其不依赖于预先定义的特征和算法。此外，我们还提供了一个新的手动分割的森林数据集，包含 156 棵完整的树木和 79 棵部分树木，这些树木已经被手动清洁分割。这使得我们可以评估实例分割性能，而不仅仅是评估检测 individuak 树木。我们在 6665 棵树木的点云上训练 TreeLearn，使用 Lidar360 软件标注。我们对 benchmark 数据集进行评估，发现 TreeLearn 与生成其训练数据的算法性能相似或更好。此外，通过精细调整 cleanly 标注的 benchmark 数据集，我们可以大幅提高方法的性能。TreeLearn 代码可以从 https://github.com/ecker-lab/TreeLearn 获取，数据和训练模型可以从 https://doi.org/10.25625/VPMPID 获取。
</details></li>
</ul>
<hr>
<h2 id="Segment-Anything-Model-for-Brain-Tumor-Segmentation"><a href="#Segment-Anything-Model-for-Brain-Tumor-Segmentation" class="headerlink" title="Segment Anything Model for Brain Tumor Segmentation"></a>Segment Anything Model for Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08434">http://arxiv.org/abs/2309.08434</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Zhang, Yaping Wang</li>
<li>for: 诊断和治疗 Glioma 脑肿的准确分 segmentation 是非常重要的。</li>
<li>methods: 本研究使用 Meta AI 发布的 Segment Anything Model(SAM) 进行图像分 segmentation，无需模型微调。</li>
<li>results: 研究发现，无需模型微调，SAM 在脑肿分 segmentation 中还有一定的差距与当前状态流行(SOTA) 模型。<details>
<summary>Abstract</summary>
Glioma is a prevalent brain tumor that poses a significant health risk to individuals. Accurate segmentation of brain tumor is essential for clinical diagnosis and treatment. The Segment Anything Model(SAM), released by Meta AI, is a fundamental model in image segmentation and has excellent zero-sample generalization capabilities. Thus, it is interesting to apply SAM to the task of brain tumor segmentation. In this study, we evaluated the performance of SAM on brain tumor segmentation and found that without any model fine-tuning, there is still a gap between SAM and the current state-of-the-art(SOTA) model.
</details>
<details>
<summary>摘要</summary>
glioma 是一种常见的脑肿瘤，对个人健康pose 一定的风险。确定脑肿瘤的准确分 segmentation 是诊断和治疗的关键。Meta AI 发布的 Segment Anything Model（SAM）是一种基本的图像分 segmentation 模型，具有出色的零样本泛化能力。因此，我们想用 SAM 进行脑肿瘤分 segmentation 的任务。在这个研究中，我们评估了 SAM 在脑肿瘤分 segmentation  task 的性能，发现没有任何模型细化，仍有与当前领先模型（SOTA）之间的差距。Note: "脑肿瘤" (glioma) is a type of brain tumor, and "风险" (pose) means "risk" in Chinese. "诊断" (diagnosis) and "治疗" (treatment) are also translated as expected. "零样本泛化能力" (zero-sample generalization capabilities) is a bit more difficult to translate, but I think "出色的零样本泛化能力" (excellent zero-sample generalization capabilities) conveys the meaning well.
</details></li>
</ul>
<hr>
<h2 id="X-PDNet-Accurate-Joint-Plane-Instance-Segmentation-and-Monocular-Depth-Estimation-with-Cross-Task-Distillation-and-Boundary-Correction"><a href="#X-PDNet-Accurate-Joint-Plane-Instance-Segmentation-and-Monocular-Depth-Estimation-with-Cross-Task-Distillation-and-Boundary-Correction" class="headerlink" title="X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Distillation and Boundary Correction"></a>X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Distillation and Boundary Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08424">http://arxiv.org/abs/2309.08424</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caodinhduc/x-pdnet-official">https://github.com/caodinhduc/x-pdnet-official</a></li>
<li>paper_authors: Duc Cao Dinh, J Lim</li>
<li>For: 本文目的是提出一种多任务学习框架，用于同时进行平面实例分割和深度估计。* Methods: 本文使用特征融合机制和几何约束损失来利用图像的视觉和几何特征。此外，本文还提出了跨任务特征储存设计，以便在早期共享双任务中提高特定任务的表现。* Results: 本文通过实验证明了其提出的方法的效果，在ScanNet和Stanford 2D-3D-S dataset上达到了大幅提高的量化结果，证明了其效果。<details>
<summary>Abstract</summary>
Segmentation of planar regions from a single RGB image is a particularly important task in the perception of complex scenes. To utilize both visual and geometric properties in images, recent approaches often formulate the problem as a joint estimation of planar instances and dense depth through feature fusion mechanisms and geometric constraint losses. Despite promising results, these methods do not consider cross-task feature distillation and perform poorly in boundary regions. To overcome these limitations, we propose X-PDNet, a framework for the multitask learning of plane instance segmentation and depth estimation with improvements in the following two aspects. Firstly, we construct the cross-task distillation design which promotes early information sharing between dual-tasks for specific task improvements. Secondly, we highlight the current limitations of using the ground truth boundary to develop boundary regression loss, and propose a novel method that exploits depth information to support precise boundary region segmentation. Finally, we manually annotate more than 3000 images from Stanford 2D-3D-Semantics dataset and make available for evaluation of plane instance segmentation. Through the experiments, our proposed methods prove the advantages, outperforming the baseline with large improvement margins in the quantitative results on the ScanNet and the Stanford 2D-3D-S dataset, demonstrating the effectiveness of our proposals.
</details>
<details>
<summary>摘要</summary>
Segmentation of planar regions from a single RGB image is a particularly important task in the perception of complex scenes. To utilize both visual and geometric properties in images, recent approaches often formulate the problem as a joint estimation of planar instances and dense depth through feature fusion mechanisms and geometric constraint losses. Despite promising results, these methods do not consider cross-task feature distillation and perform poorly in boundary regions. To overcome these limitations, we propose X-PDNet, a framework for the multitask learning of plane instance segmentation and depth estimation with improvements in the following two aspects:Firstly, we construct the cross-task distillation design, which promotes early information sharing between dual-tasks for specific task improvements.Secondly, we highlight the current limitations of using the ground truth boundary to develop boundary regression loss, and propose a novel method that exploits depth information to support precise boundary region segmentation.Finally, we manually annotate more than 3000 images from the Stanford 2D-3D-Semantics dataset and make them available for evaluation of plane instance segmentation. Through the experiments, our proposed methods prove the advantages, outperforming the baseline with large improvement margins in the quantitative results on the ScanNet and the Stanford 2D-3D-S dataset, demonstrating the effectiveness of our proposals.
</details></li>
</ul>
<hr>
<h2 id="MIML-Multiplex-Image-Machine-Learning-for-High-Precision-Cell-Classification-via-Mechanical-Traits-within-Microfluidic-Systems"><a href="#MIML-Multiplex-Image-Machine-Learning-for-High-Precision-Cell-Classification-via-Mechanical-Traits-within-Microfluidic-Systems" class="headerlink" title="MIML: Multiplex Image Machine Learning for High Precision Cell Classification via Mechanical Traits within Microfluidic Systems"></a>MIML: Multiplex Image Machine Learning for High Precision Cell Classification via Mechanical Traits within Microfluidic Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08421">http://arxiv.org/abs/2309.08421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khayrul Islam, Ratul Paul, Shen Wang, Yaling Liu</li>
<li>for:  This paper aims to develop a novel machine learning framework for label-free cell classification, addressing the limitations of existing techniques in terms of specificity and speed.</li>
<li>methods:  The proposed framework, called Multiplex Image Machine Learning (MIML), combines label-free cell images with biomechanical property data to offer a more holistic understanding of cellular properties.</li>
<li>results:  The MIML approach achieves a remarkable 98.3% accuracy in cell classification, outperforming models that only consider a single data type. It has been proven effective in classifying white blood cells and tumor cells, with potential for broader application due to its flexibility and transfer learning capability.<details>
<summary>Abstract</summary>
Label-free cell classification is advantageous for supplying pristine cells for further use or examination, yet existing techniques frequently fall short in terms of specificity and speed. In this study, we address these limitations through the development of a novel machine learning framework, Multiplex Image Machine Learning (MIML). This architecture uniquely combines label-free cell images with biomechanical property data, harnessing the vast, often underutilized morphological information intrinsic to each cell. By integrating both types of data, our model offers a more holistic understanding of the cellular properties, utilizing morphological information typically discarded in traditional machine learning models. This approach has led to a remarkable 98.3\% accuracy in cell classification, a substantial improvement over models that only consider a single data type. MIML has been proven effective in classifying white blood cells and tumor cells, with potential for broader application due to its inherent flexibility and transfer learning capability. It's particularly effective for cells with similar morphology but distinct biomechanical properties. This innovative approach has significant implications across various fields, from advancing disease diagnostics to understanding cellular behavior.
</details>
<details>
<summary>摘要</summary>
标签无Cell分类具有优势，可以提供不受损害的细胞用于进一步使用或检测，然而现有技术 frequently fall short in terms of specificity and speed. 在这种研究中，我们通过开发一种新的机器学习框架，Multiplex Image Machine Learning (MIML)，来解决这些局限性。这种架构独特地结合标签无Cell image和生物力学性数据，利用每个细胞内部的较为忽略的形态信息。通过将两种数据类型集成，我们的模型可以更全面地理解细胞的质量特征，使得模型具有98.3%的准确率。MIML已经成功地分类白血细胞和肿瘤细胞，并且具有更广泛的应用前景，因为它具有内置的灵活性和转移学习能力。它尤其有效于具有相似形态 yet distinct biomechanical properties的细胞。这种创新的方法对于不同领域的应用都具有深远的意义，从提高疾病诊断到理解细胞行为。
</details></li>
</ul>
<hr>
<h2 id="Deformable-Neural-Radiance-Fields-using-RGB-and-Event-Cameras"><a href="#Deformable-Neural-Radiance-Fields-using-RGB-and-Event-Cameras" class="headerlink" title="Deformable Neural Radiance Fields using RGB and Event Cameras"></a>Deformable Neural Radiance Fields using RGB and Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08416">http://arxiv.org/abs/2309.08416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Ma, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool</li>
<li>for: 用于模型快速变形的物体从可见数据中的快速变化。</li>
<li>methods: 使用RGB和事件摄像头，并将事件流处理为ynchronously数据，并对于不确定的摄像头位置进行估计。</li>
<li>results: 与现有方法比较，提供了更好的性能，并在实际的游戏和实际数据上进行了试验。Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究使用RGB和事件摄像头，从可见数据中模型快速变形的物体。</li>
<li>methods: 我们提出了一种新的方法，使用RGB和事件摄像头，并将事件流处理为ynchronously数据，并对于不确定的摄像头位置进行估计。</li>
<li>results: 实际实验结果显示，与现有方法比较，我们的方法提供了更好的性能，并在实际的游戏和实际数据上进行了试验。<details>
<summary>Abstract</summary>
Modeling Neural Radiance Fields for fast-moving deformable objects from visual data alone is a challenging problem. A major issue arises due to the high deformation and low acquisition rates. To address this problem, we propose to use event cameras that offer very fast acquisition of visual change in an asynchronous manner. In this work, we develop a novel method to model the deformable neural radiance fields using RGB and event cameras. The proposed method uses the asynchronous stream of events and calibrated sparse RGB frames. In our setup, the camera pose at the individual events required to integrate them into the radiance fields remains unknown. Our method jointly optimizes these poses and the radiance field. This happens efficiently by leveraging the collection of events at once and actively sampling the events during learning. Experiments conducted on both realistically rendered graphics and real-world datasets demonstrate a significant benefit of the proposed method over the state-of-the-art and the compared baseline.   This shows a promising direction for modeling deformable neural radiance fields in real-world dynamic scenes.
</details>
<details>
<summary>摘要</summary>
模型神经辐射场为快速变形物体从视觉数据中快速学习是一个挑战。主要问题在于高度变形和低收集率。为解决这个问题，我们提议使用事件摄像机，它们可以快速获取视觉变化的异步方式。在这个工作中，我们开发了一种新的方法，用于模型弹性神经辐射场，使用RGB和事件摄像机。我们的方法使用异步流动的事件，并在学习过程中活动地选择事件。在我们的设置中，摄像机的具体位置在个别事件中需要被集成到辐射场中。我们的方法同时优化这些位置和辐射场。这里我们可以高效地利用事件的批处理，并在学习过程中活动地选择事件。实验结果表明，我们的方法在实际render的图形和实际场景中具有显著的优势，比对比例的基eline。这表明了我们的方法在实际世界动态场景中具有扎实的批处理能力。
</details></li>
</ul>
<hr>
<h2 id="3D-SA-UNet-3D-Spatial-Attention-UNet-with-3D-ASPP-for-White-Matter-Hyperintensities-Segmentation"><a href="#3D-SA-UNet-3D-Spatial-Attention-UNet-with-3D-ASPP-for-White-Matter-Hyperintensities-Segmentation" class="headerlink" title="3D SA-UNet: 3D Spatial Attention UNet with 3D ASPP for White Matter Hyperintensities Segmentation"></a>3D SA-UNet: 3D Spatial Attention UNet with 3D ASPP for White Matter Hyperintensities Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08402">http://arxiv.org/abs/2309.08402</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hjkuijf/wmhchallenge">https://github.com/hjkuijf/wmhchallenge</a></li>
<li>paper_authors: Changlu Guo<br>for:* 这项研究旨在提高FLAIR图像中白 matter 高 INTENSITY 的自动分割精度，以便早期诊断多种疾病。methods:* 我们提出了一种名为3D Spatial Attention U-Net（3D SA-UNet）的深度学习模型，该模型使用仅FLAIR扫描图像进行自动WMH分割。* 3D SA-UNet引入了3D空间注意力模块，该模块可以高亮重要的疾病特征，如白 matter 高 INTENSITY，而且可以抑制无关的区域。* 我们还延展了Atrous Spatial Pyramid Pooling（ASPP）模块到3D版本，以捕捉不同级别的特征，从而提高网络的 segmentation 性能。results:* 我们对公共数据集进行了评估，并证明了3D空间注意力模块和3D ASPP在WMH分割中的效iveness。* 对比其他当前领域的3D卷积神经网络，我们的提出的3D SA-UNet模型在精度方面获得了更高的性能。<details>
<summary>Abstract</summary>
White Matter Hyperintensity (WMH) is an imaging feature related to various diseases such as dementia and stroke. Accurately segmenting WMH using computer technology is crucial for early disease diagnosis. However, this task remains challenging due to the small lesions with low contrast and high discontinuity in the images, which contain limited contextual and spatial information. To address this challenge, we propose a deep learning model called 3D Spatial Attention U-Net (3D SA-UNet) for automatic WMH segmentation using only Fluid Attenuation Inversion Recovery (FLAIR) scans. The 3D SA-UNet introduces a 3D Spatial Attention Module that highlights important lesion features, such as WMH, while suppressing unimportant regions. Additionally, to capture features at different scales, we extend the Atrous Spatial Pyramid Pooling (ASPP) module to a 3D version, enhancing the segmentation performance of the network. We evaluate our method on publicly available dataset and demonstrate the effectiveness of 3D spatial attention module and 3D ASPP in WMH segmentation. Through experimental results, it has been demonstrated that our proposed 3D SA-UNet model achieves higher accuracy compared to other state-of-the-art 3D convolutional neural networks.
</details>
<details>
<summary>摘要</summary>
白 matter 高度突出 (WMH) 是各种疾病的成像特征，如 деменcia 和 apoplexy。正确地使用计算机技术将 WMH 自动分割是早期疾病诊断的关键。然而，这项任务仍然具有挑战性，因为病理学图像中的小 lesions 具有低对比度和高终端不连续，含有有限的情况和空间信息。为解决这个挑战，我们提议一种深度学习模型called 3D Spatial Attention U-Net (3D SA-UNet)，用于自动 WMH 分割，只使用 Fluid Attenuation Inversion Recovery (FLAIR) 扫描图像。3D SA-UNet 中的 3D Spatial Attention Module 可以高亮突出重要的 lesion 特征，如 WMH，并且压制不重要的区域。此外，为了捕捉不同尺度的特征，我们扩展了 Atrous Spatial Pyramid Pooling (ASPP) 模块到 3D 版本，从而提高了网络的分割性能。我们对公共可用的数据集进行了评估，并证明了 3D spatial attention module 和 3D ASPP 在 WMH 分割中的效果。通过实验结果，我们的提出的 3D SA-UNet 模型在比较其他状态的情况下 achieve 更高的准确率。
</details></li>
</ul>
<hr>
<h2 id="An-inspection-technology-of-inner-surface-of-the-fine-hole-based-on-machine-vision"><a href="#An-inspection-technology-of-inner-surface-of-the-fine-hole-based-on-machine-vision" class="headerlink" title="An inspection technology of inner surface of the fine hole based on machine vision"></a>An inspection technology of inner surface of the fine hole based on machine vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08649">http://arxiv.org/abs/2309.08649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rongfang He, Weibin Zhang, Guofang Gao</li>
<li>for: detect the quality of the inner surface of fine holes in industrial components</li>
<li>methods: uses a special optical measurement system with a sight pipe and flexible light array to guide external illumination light into the fine hole and output relevant images</li>
<li>results: can measure the inner surface quality of fine holes with a diameter range of 4mm to 47mm and a depth of up to 47mm, with a maximum measurement error standard deviation of about 10um<details>
<summary>Abstract</summary>
Fine holes are an important structural component of industrial components, and their inner surface quality is closely related to their function.In order to detect the quality of the inner surface of the fine hole,a special optical measurement system was investigated in this paper. A sight pipe is employed to guide the external illumination light into the fine hole and output the relevant images simultaneously. A flexible light array is introduced to suit the narrow space, and the effective field of view is analyzed. Besides, the arc surface projection error and manufacturing assembly error of the device are analyzed, then compensated or ignored if small enough. In the test of prefabricated circular defects with the diameter {\phi}0.1mm, {\phi}0.2mm, 0.4mm distance distribution and the fissure defects with the width 0.3mm, the maximum measurement error standard deviation are all about 10{\mu}m. The minimum diameter of the measured fine hole is 4mm and the depth can reach 47mm.
</details>
<details>
<summary>摘要</summary>
细洞是工业Component的重要结构部件，其内部表面质量直接关系到它的功能。为了检测细洞内部质量，这篇论文提出了一种特殊的光学测量系统。使用视窗引导外部照明光入射细洞，并同时输出相关图像。还引入了 flexible 光 Array适应窄空间，分析了有效范围。此外，Device的弯曲面投影错误和生产组装错误也被分析了，并且可以根据小于一定的标准差忽略或补做。在尝试预制圆残渠defects with  диаметр（φ）0.1mm、0.2mm、0.4mm距离分布和尖极残渠with width 0.3mm时，最大测量错误标准差都在10μm之间。测量细洞的最小径度为4mm，深度可达47mm。
</details></li>
</ul>
<hr>
<h2 id="Double-Domain-Guided-Real-Time-Low-Light-Image-Enhancement-for-Ultra-High-Definition-Transportation-Surveillance"><a href="#Double-Domain-Guided-Real-Time-Low-Light-Image-Enhancement-for-Ultra-High-Definition-Transportation-Surveillance" class="headerlink" title="Double Domain Guided Real-Time Low-Light Image Enhancement for Ultra-High-Definition Transportation Surveillance"></a>Double Domain Guided Real-Time Low-Light Image Enhancement for Ultra-High-Definition Transportation Surveillance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08382">http://arxiv.org/abs/2309.08382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qujx/ddnet">https://github.com/qujx/ddnet</a></li>
<li>paper_authors: Jingxiang Qu, Ryan Wen Liu, Yuan Gao, Yu Guo, Fenghua Zhu, Fei-yue Wang</li>
<li>for: 这 paper 的目的是提出一种高效可靠的低光照图像增强网络 (DDNet)，用于实时交通监测系统 (ITS) 中的低光照图像增强。</li>
<li>methods: 这 paper 使用了一种 Encoder-Decoder 结构为主体网络 architecture，并将增强处理分解为两个子任务 (i.e., 色彩增强和梯度增强)，通过提出的 Course Enhancement Module (CEM) 和 LoG-based Gradient Enhancement Module (GEM)，以同时进行颜色和梯度特征的增强。</li>
<li>results: 评估实验表明，相比之前的方法，DDNet 可提供更高质量和更高效的低光照图像增强，并且在交通相关的数据集上进行物体检测和Scene Segmentation 实验也表明了DDNet 的实际应用价值。<details>
<summary>Abstract</summary>
Real-time transportation surveillance is an essential part of the intelligent transportation system (ITS). However, images captured under low-light conditions often suffer the poor visibility with types of degradation, such as noise interference and vague edge features, etc. With the development of imaging devices, the quality of the visual surveillance data is continually increasing, like 2K and 4K, which has more strict requirements on the efficiency of image processing. To satisfy the requirements on both enhancement quality and computational speed, this paper proposes a double domain guided real-time low-light image enhancement network (DDNet) for ultra-high-definition (UHD) transportation surveillance. Specifically, we design an encoder-decoder structure as the main architecture of the learning network. In particular, the enhancement processing is divided into two subtasks (i.e., color enhancement and gradient enhancement) via the proposed coarse enhancement module (CEM) and LoG-based gradient enhancement module (GEM), which are embedded in the encoder-decoder structure. It enables the network to enhance the color and edge features simultaneously. Through the decomposition and reconstruction on both color and gradient domains, our DDNet can restore the detailed feature information concealed by the darkness with better visual quality and efficiency. The evaluation experiments on standard and transportation-related datasets demonstrate that our DDNet provides superior enhancement quality and efficiency compared with the state-of-the-art methods. Besides, the object detection and scene segmentation experiments indicate the practical benefits for higher-level image analysis under low-light environments in ITS.
</details>
<details>
<summary>摘要</summary>
现实时交通监测是智能交通系统（ITS）的重要组成部分。然而，在低光照条件下捕捉的图像经常受到质量下降，如噪声干扰和模糊边缘等问题。随着捕捉设备的发展，视觉监测数据的质量不断提高，如2K和4K，这对图像处理效率的要求越来越高。为满足质量提高和计算速度的双重要求，本文提出了双Domain指导实时低光照图像增强网络（DDNet），用于ultra-high-definition（UHD）交通监测。具体来说，我们设计了编码器-解码器结构为主体网络学习架构。特别是，增强处理被分为两个子任务（即色彩增强和梯度增强）via提出的粗略增强模块（CEM）和LoG基于的梯度增强模块（GEM），这些模块在编码器-解码器结构中嵌入。这使得网络可以同时增强色彩和梯度特征。通过对颜色和梯度频谱进行分解和重建，我们的DDNet可以更好地恢复在黑暗中隐藏的细节特征，提供更高质量和效率的增强结果。实验表明，与现有方法相比，我们的DDNet在标准和交通相关的数据集上提供了更高质量和效率的增强结果。此外，对象检测和Scene分割实验表明，DDNet在低光照环境中的高级图像分析也具有实际应用价值。
</details></li>
</ul>
<hr>
<h2 id="Reconsidering-evaluation-practices-in-modular-systems-On-the-propagation-of-errors-in-MRI-prostate-cancer-detection"><a href="#Reconsidering-evaluation-practices-in-modular-systems-On-the-propagation-of-errors-in-MRI-prostate-cancer-detection" class="headerlink" title="Reconsidering evaluation practices in modular systems: On the propagation of errors in MRI prostate cancer detection"></a>Reconsidering evaluation practices in modular systems: On the propagation of errors in MRI prostate cancer detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08381">http://arxiv.org/abs/2309.08381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erlend Sortland Rolfsnes, Philip Thangngat, Trygve Eftestøl, Tobias Nordström, Fredrik Jäderling, Martin Eklund, Alvaro Fernandez-Quilez</li>
<li>for: 这篇论文主要是为了检测前列腺癌（PCa）的检测方法。</li>
<li>methods: 这篇论文使用人工智能（AI）系统来支持医学评估，包括范例分类和检测癌肿。</li>
<li>results: 这篇论文发现，使用不同的分类网络（s1和s2）会导致不同的检测结果，并且与理想的设定相比（s1：89.90+-2.23 vs 88.97+-3.06 ncsPCa，P&lt;.001，89.30+-4.07和88.12+-2.71 csPCa，P&lt;.001）。这些结果表明了评估整个系统的重要性，而不仅仅是单一模组。<details>
<summary>Abstract</summary>
Magnetic resonance imaging has evolved as a key component for prostate cancer (PCa) detection, substantially increasing the radiologist workload. Artificial intelligence (AI) systems can support radiological assessment by segmenting and classifying lesions in clinically significant (csPCa) and non-clinically significant (ncsPCa). Commonly, AI systems for PCa detection involve an automatic prostate segmentation followed by the lesion detection using the extracted prostate. However, evaluation reports are typically presented in terms of detection under the assumption of the availability of a highly accurate segmentation and an idealistic scenario, omitting the propagation of errors between modules. For that purpose, we evaluate the effect of two different segmentation networks (s1 and s2) with heterogeneous performances in the detection stage and compare it with an idealistic setting (s1:89.90+-2.23 vs 88.97+-3.06 ncsPCa, P<.001, 89.30+-4.07 and 88.12+-2.71 csPCa, P<.001). Our results depict the relevance of a holistic evaluation, accounting for all the sub-modules involved in the system.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-Domain-Gap-Exploiting-Subjectivity-in-Sketch-Based-Person-Retrieval"><a href="#Beyond-Domain-Gap-Exploiting-Subjectivity-in-Sketch-Based-Person-Retrieval" class="headerlink" title="Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person Retrieval"></a>Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08372">http://arxiv.org/abs/2309.08372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lin-kayla/subjectivity-sketch-reid">https://github.com/lin-kayla/subjectivity-sketch-reid</a></li>
<li>paper_authors: Kejun Lin, Zhixiang Wang, Zheng Wang, Yinqiang Zheng, Shin’ichi Satoh</li>
<li>for: 本研究targets person re-identification (re-ID) problem using sketches as the only available information.</li>
<li>methods: 本研究提出了两个新的设计方法来处理主观性的挑战：1) non-local (NL) fusion module，集成不同证人的绘画来减少主观性的影响；2) AttrAlign module，通过特征属性作为隐藏mask来对域隔的特征进行对齐。</li>
<li>results: 研究在三个benchmark中表现出色，包括大规模、多样化和跨风格 benchmark。<details>
<summary>Abstract</summary>
Person re-identification (re-ID) requires densely distributed cameras. In practice, the person of interest may not be captured by cameras and, therefore, needs to be retrieved using subjective information (e.g., sketches from witnesses). Previous research defines this case using the sketch as sketch re-identification (Sketch re-ID) and focuses on eliminating the domain gap. Actually, subjectivity is another significant challenge. We model and investigate it by posing a new dataset with multi-witness descriptions. It features two aspects. 1) Large-scale. It contains over 4,763 sketches and 32,668 photos, making it the largest Sketch re-ID dataset. 2) Multi-perspective and multi-style. Our dataset offers multiple sketches for each identity. Witnesses' subjective cognition provides multiple perspectives on the same individual, while different artists' drawing styles provide variation in sketch styles. We further have two novel designs to alleviate the challenge of subjectivity. 1) Fusing subjectivity. We propose a non-local (NL) fusion module that gathers sketches from different witnesses for the same identity. 2) Introducing objectivity. An AttrAlign module utilizes attributes as an implicit mask to align cross-domain features. To push forward the advance of Sketch re-ID, we set three benchmarks (large-scale, multi-style, cross-style). Extensive experiments demonstrate our leading performance in these benchmarks. Dataset and Codes are publicly available at: https://github.com/Lin-Kayla/subjectivity-sketch-reid
</details>
<details>
<summary>摘要</summary>
人识别（re-ID）需要密集分布的摄像头。在实践中，人物对摄像头不可见，因此需要使用主观信息（例如，见证人的素描）来检索。先前的研究定义这种情况为素描重新识别（Sketch re-ID），并将着眼点在消除领域差异。然而，主观性是另一个重要挑战。我们模型和调查这个问题，通过提供一个新的数据集，该数据集包含多个见证人的素描。它具有以下两个特点：1）大规模。该数据集包含超过4,763个素描和32,668个照片，是目前最大的Sketch re-ID数据集。2）多元 perspective和多样化。我们的数据集具有每个人物的多个素描，见证人的主观认知提供多个视角，而不同艺术家的绘制风格提供了多样化的素描风格。我们还有两项新的设计来缓解主观性挑战。1）素描 fusions。我们提议一种非本地（NL）融合模块，可以从不同见证人的素描中集成素描。2）引入对象性。我们引入一种特征对齐模块，使用特征作为隐藏的掩码，将不同领域的特征对齐。为推动Sketch re-ID的进步，我们设置了三个标准（大规模、多样化、跨领域）。广泛的实验表明我们在这些标准上显示出领先的性能。数据集和代码在 GitHub 上公开：https://github.com/Lin-Kayla/subjectivity-sketch-reid。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Wide-Range-Pseudo-3D-Vehicle-Detection-Using-A-Single-Camera"><a href="#An-Efficient-Wide-Range-Pseudo-3D-Vehicle-Detection-Using-A-Single-Camera" class="headerlink" title="An Efficient Wide-Range Pseudo-3D Vehicle Detection Using A Single Camera"></a>An Efficient Wide-Range Pseudo-3D Vehicle Detection Using A Single Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08369">http://arxiv.org/abs/2309.08369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhupeng Ye, Yinqi Li, Zejian Yuan</li>
<li>for: 这篇论文旨在提供一种新的宽范围 Pseudo-3D 车辆检测方法，以实现智能驾驶系统中的活跃安全功能。</li>
<li>methods: 本文使用单一摄取器的图像，并将它拼接成两个子窗口图像，以最大化图像分辨率的利用。然后，运用特别设计的检测头来检测宽范围车辆物件。这些检测头同时发出延展的 BBox 和 Side Projection Line（SPL）表示，以捕捉车辆的形状和位置。</li>
<li>results: 实验结果显示，本文的模型在多种评估指标上均 achieve 良好的表现，包括检测精度、稳定性和预测精度。详细的实验结果和评估Metrics可以参考我们的自建dataset和评估报告。<details>
<summary>Abstract</summary>
Wide-range and fine-grained vehicle detection plays a critical role in enabling active safety features in intelligent driving systems. However, existing vehicle detection methods based on rectangular bounding boxes (BBox) often struggle with perceiving wide-range objects, especially small objects at long distances. And BBox expression cannot provide detailed geometric shape and pose information of vehicles. This paper proposes a novel wide-range Pseudo-3D Vehicle Detection method based on images from a single camera and incorporates efficient learning methods. This model takes a spliced image as input, which is obtained by combining two sub-window images from a high-resolution image. This image format maximizes the utilization of limited image resolution to retain essential information about wide-range vehicle objects. To detect pseudo-3D objects, our model adopts specifically designed detection heads. These heads simultaneously output extended BBox and Side Projection Line (SPL) representations, which capture vehicle shapes and poses, enabling high-precision detection. To further enhance the performance of detection, a joint constraint loss combining both the object box and SPL is designed during model training, improving the efficiency, stability, and prediction accuracy of the model. Experimental results on our self-built dataset demonstrate that our model achieves favorable performance in wide-range pseudo-3D vehicle detection across multiple evaluation metrics. Our demo video has been placed at https://www.youtube.com/watch?v=1gk1PmsQ5Q8.
</details>
<details>
<summary>摘要</summary>
宽范围和细化的车辆检测在智能驾驶系统中扮演了关键的角色。然而，现有的基于矩形 bounding box（BBox）的车辆检测方法 frequently struggle with perceiving wide-range objects, especially small objects at long distances. BBox表达不能提供车辆的详细几何形状和姿态信息。这篇论文提出了一种基于单个摄像头的新型宽范围 Pseudo-3D 车辆检测方法。该模型使用组合两个子窗口图像的高分辨率图像来作为输入。这种图像格式可以最大化图像分辨率的利用，以保留车辆 объек 的重要信息。为检测 Pseudo-3D 对象，我们的模型采用特定的检测头。这些头同时输出扩展 BBox 和 Side Projection Line（SPL）表示，以捕捉车辆的形状和姿态，实现高精度检测。为了进一步提高检测性能，我们在模型训练中设计了联合约束损失，既包括对象框和 SPL 的损失。实验结果表明，我们的模型在多种评价指标上表现出色。我们的 Demo 视频已经上传到 YouTube 上，请参考 https://www.youtube.com/watch?v=1gk1PmsQ5Q8。
</details></li>
</ul>
<hr>
<h2 id="Robust-Burned-Area-Delineation-through-Multitask-Learning"><a href="#Robust-Burned-Area-Delineation-through-Multitask-Learning" class="headerlink" title="Robust Burned Area Delineation through Multitask Learning"></a>Robust Burned Area Delineation through Multitask Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08368">http://arxiv.org/abs/2309.08368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/links-ads/burned-area-seg">https://github.com/links-ads/burned-area-seg</a></li>
<li>paper_authors: Edoardo Arnaudo, Luca Barco, Matteo Merlo, Claudio Rossi</li>
<li>for: 这篇论文是用于精确地界定野火烧伤区域，以便环境监控和火灾后评估。</li>
<li>methods: 我们使用了一个多任务学习框架，其中包括土地覆盖分类作为助手任务，以增强火烧伤区域分类模型的稳定性和性能。我们还使用了Sentinel-2输入和Copernicus动作等数据来构建一个特殊的数据集，并提供了多个任务的标签，包括火烧伤区域分类和土地覆盖分类。</li>
<li>results: 我们与标准二分法进行比较，结果显示我们的方法在精确地界定火烧伤区域方面表现更好，并且可以增强模型的稳定性和性能。<details>
<summary>Abstract</summary>
In recent years, wildfires have posed a significant challenge due to their increasing frequency and severity. For this reason, accurate delineation of burned areas is crucial for environmental monitoring and post-fire assessment. However, traditional approaches relying on binary segmentation models often struggle to achieve robust and accurate results, especially when trained from scratch, due to limited resources and the inherent imbalance of this segmentation task. We propose to address these limitations in two ways: first, we construct an ad-hoc dataset to cope with the limited resources, combining information from Sentinel-2 feeds with Copernicus activations and other data sources. In this dataset, we provide annotations for multiple tasks, including burned area delineation and land cover segmentation. Second, we propose a multitask learning framework that incorporates land cover classification as an auxiliary task to enhance the robustness and performance of the burned area segmentation models. We compare the performance of different models, including UPerNet and SegFormer, demonstrating the effectiveness of our approach in comparison to standard binary segmentation.
</details>
<details>
<summary>摘要</summary>
Recently, wildfires have presented a significant challenge due to their increasing frequency and severity. Accurate delineation of burned areas is crucial for environmental monitoring and post-fire assessment. However, traditional approaches relying on binary segmentation models often struggle to achieve robust and accurate results, especially when trained from scratch, due to limited resources and the inherent imbalance of this segmentation task. We propose to address these limitations in two ways:First, we construct an ad-hoc dataset to cope with the limited resources, combining information from Sentinel-2 feeds with Copernicus activations and other data sources. In this dataset, we provide annotations for multiple tasks, including burned area delineation and land cover segmentation.Second, we propose a multitask learning framework that incorporates land cover classification as an auxiliary task to enhance the robustness and performance of the burned area segmentation models. We compare the performance of different models, including UPerNet and SegFormer, demonstrating the effectiveness of our approach in comparison to standard binary segmentation.
</details></li>
</ul>
<hr>
<h2 id="Continual-Learning-with-Deep-Streaming-Regularized-Discriminant-Analysis"><a href="#Continual-Learning-with-Deep-Streaming-Regularized-Discriminant-Analysis" class="headerlink" title="Continual Learning with Deep Streaming Regularized Discriminant Analysis"></a>Continual Learning with Deep Streaming Regularized Discriminant Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08353">http://arxiv.org/abs/2309.08353</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sonycslparis/deep_srda">https://github.com/sonycslparis/deep_srda</a></li>
<li>paper_authors: Joe Khawand, Peter Hanappe, David Colliaux</li>
<li>for: 提高实际机器学习应用中的持续学习能力，以实现更人类化的学习方式。</li>
<li>methods: 提出了一种流处理学习方法， combinestraditional continual learning methods with a convolutional neural network to improve performance on real-world datasets.</li>
<li>results: 在ImageNet ILSVRC-2012数据集上，与批量学习和现有流处理学习算法相比，该方法表现出色，得到了更高的性能。<details>
<summary>Abstract</summary>
Continual learning is increasingly sought after in real world machine learning applications, as it enables learning in a more human-like manner. Conventional machine learning approaches fail to achieve this, as incrementally updating the model with non-identically distributed data leads to catastrophic forgetting, where existing representations are overwritten. Although traditional continual learning methods have mostly focused on batch learning, which involves learning from large collections of labeled data sequentially, this approach is not well-suited for real-world applications where we would like new data to be integrated directly. This necessitates a paradigm shift towards streaming learning. In this paper, we propose a streaming version of regularized discriminant analysis as a solution to this challenge. We combine our algorithm with a convolutional neural network and demonstrate that it outperforms both batch learning and existing streaming learning algorithms on the ImageNet ILSVRC-2012 dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>continuous learning在现实世界机器学习应用中日益受到欢迎，因为它使得机器学习更像人类学习的方式。传统机器学习方法无法实现这一点，因为逐渐更新模型的非一致分布数据会导致扩散遗忘，已有表示被覆盖。 although traditional continual learning methods have mostly focused on batch learning, which involves learning from large collections of labeled data sequentially, this approach is not well-suited for real-world applications where we would like new data to be integrated directly. This necessitates a paradigm shift towards streaming learning. In this paper, we propose a streaming version of regularized discriminant analysis as a solution to this challenge. We combine our algorithm with a convolutional neural network and demonstrate that it outperforms both batch learning and existing streaming learning algorithms on the ImageNet ILSVRC-2012 dataset.<</SYS>>Here's the translation in Traditional Chinese:<<SYS>>不断学习在现实世界机器学习应用中日益受到欢迎，因为它使得机器学习更像人类学习的方式。传统机器学习方法无法实现这一点，因为逐渐更新模型的非一致分布数据会导致扩散遗忘，已有表示被覆盖。 although traditional continual learning methods have mostly focused on batch learning, which involves learning from large collections of labeled data sequentially, this approach is not well-suited for real-world applications where we would like new data to be integrated directly. This necessitates a paradigm shift towards streaming learning. In this paper, we propose a streaming version of regularized discriminant analysis as a solution to this challenge. We combine our algorithm with a convolutional neural network and demonstrate that it outperforms both batch learning and existing streaming learning algorithms on the ImageNet ILSVRC-2012 dataset.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="T-UDA-Temporal-Unsupervised-Domain-Adaptation-in-Sequential-Point-Clouds"><a href="#T-UDA-Temporal-Unsupervised-Domain-Adaptation-in-Sequential-Point-Clouds" class="headerlink" title="T-UDA: Temporal Unsupervised Domain Adaptation in Sequential Point Clouds"></a>T-UDA: Temporal Unsupervised Domain Adaptation in Sequential Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08302">http://arxiv.org/abs/2309.08302</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctu-vras/t-uda">https://github.com/ctu-vras/t-uda</a></li>
<li>paper_authors: Awet Haileslassie Gebrehiwot, David Hurych, Karel Zimmermann, Patrick Pérez, Tomáš Svoboda</li>
<li>for: 本研究旨在提高驾驶场景3D semantic segmentation模型的可靠性，使其在不同地区、感知器件、安装位置等不同域的开放世界设置下能够有效地适应。</li>
<li>methods: 本研究提出了一种新的频率适应方法，即Temporal UDA（T-UDA）方法，它结合输入数据的时间和交叉感知器件的准确性，并与mean teacher方法结合。</li>
<li>results: 经过实验表明，T-UDA方法在Waymo Open Dataset、nuScenes和SemanticKITTI等 datasets上对3D semantic segmentation任务具有显著的性能提升，并且对两种流行的3D点云架构（Cylinder3D和MinkowskiNet）都有优秀的效果。<details>
<summary>Abstract</summary>
Deep perception models have to reliably cope with an open-world setting of domain shifts induced by different geographic regions, sensor properties, mounting positions, and several other reasons. Since covering all domains with annotated data is technically intractable due to the endless possible variations, researchers focus on unsupervised domain adaptation (UDA) methods that adapt models trained on one (source) domain with annotations available to another (target) domain for which only unannotated data are available. Current predominant methods either leverage semi-supervised approaches, e.g., teacher-student setup, or exploit privileged data, such as other sensor modalities or temporal data consistency. We introduce a novel domain adaptation method that leverages the best of both trends. Our approach combines input data's temporal and cross-sensor geometric consistency with the mean teacher method. Dubbed T-UDA for "temporal UDA", such a combination yields massive performance gains for the task of 3D semantic segmentation of driving scenes. Experiments are conducted on Waymo Open Dataset, nuScenes and SemanticKITTI, for two popular 3D point cloud architectures, Cylinder3D and MinkowskiNet. Our codes are publicly available at https://github.com/ctu-vras/T-UDA.
</details>
<details>
<summary>摘要</summary>
深度感知模型需要可靠地处理开放世界的领域变化，包括不同的地理区域、感知器件属性、安装位置等多种原因。由于可获取的标注数据的可得性是技术上不可能的，因此研究人员将焦点放在无监督领域适应（UDA）方法上，以适应已经训练的一个（源）领域的模型，并使其适应另一个（目标）领域的无标注数据。目前主流的方法包括使用 semi-supervised 方法，如教师生Setup，或者利用特权数据，如其他感知模式或时间数据一致性。我们介绍了一种新的领域适应方法，它将输入数据的时间和跨感器几何一致性与“教师”方法结合。我们将这种方法称为“时间领域适应”（T-UDA）。实验在 Waymo 开放数据集、nuscenes 和 SemanticKITTI 上进行，使用两种流行的3D点云架构：Cylinder3D 和 MinkowskiNet。我们的代码公开在 GitHub 上，请参考 <https://github.com/ctu-vras/T-UDA>。
</details></li>
</ul>
<hr>
<h2 id="A-Real-Time-Active-Speaker-Detection-System-Integrating-an-Audio-Visual-Signal-with-a-Spatial-Querying-Mechanism"><a href="#A-Real-Time-Active-Speaker-Detection-System-Integrating-an-Audio-Visual-Signal-with-a-Spatial-Querying-Mechanism" class="headerlink" title="A Real-Time Active Speaker Detection System Integrating an Audio-Visual Signal with a Spatial Querying Mechanism"></a>A Real-Time Active Speaker Detection System Integrating an Audio-Visual Signal with a Spatial Querying Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08295">http://arxiv.org/abs/2309.08295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilya Gurvich, Ido Leichter, Dharmendar Reddy Palle, Yossi Asher, Alon Vinnikov, Igor Abramovski, Vishak Gopal, Ross Cutler, Eyal Krupka</li>
<li>for: 这篇论文是为了研究一种实时、 causal、基于神经网络的活动说话人检测系统，适用于低功耗边缘计算。</li>
<li>methods: 该系统使用了一个微phone阵列和360度摄像头提供的数据，并使用了一种具有127 MFLOPs每参与者的神经网络。与前一些工作不同，这里的网络会在计算预算 exhausted 情况下表现出“美味的衰弱”，使系统可以在这种情况下运行良好。</li>
<li>results: 作者在一个真实的会议数据集上训练和评估了自己的算法，并证明了其在多达14名参与者、叠加演讲、其他挑战性enario下的性能。<details>
<summary>Abstract</summary>
We introduce a distinctive real-time, causal, neural network-based active speaker detection system optimized for low-power edge computing. This system drives a virtual cinematography module and is deployed on a commercial device. The system uses data originating from a microphone array and a 360-degree camera. Our network requires only 127 MFLOPs per participant, for a meeting with 14 participants. Unlike previous work, we examine the error rate of our network when the computational budget is exhausted, and find that it exhibits graceful degradation, allowing the system to operate reasonably well even in this case. Departing from conventional DOA estimation approaches, our network learns to query the available acoustic data, considering the detected head locations. We train and evaluate our algorithm on a realistic meetings dataset featuring up to 14 participants in the same meeting, overlapped speech, and other challenging scenarios.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种特有的实时、因果的神经网络基于活动 speaker检测系统，适用于低功耗边缘计算。这个系统驱动了虚拟 cinematography 模块，并在商业设备上部署。系统使用来自麦克风阵列和360度摄像头的数据。我们的网络只需127 MFLOPs每参与者，对于参与者14人的会议。与前一项不同，我们研究了我们网络在计算预算尽用时的错误率，发现它具有很好的宽恒化特性，使系统可以在这种情况下运行良好。与传统的 DOA 估计方法不同，我们的网络学习了查询可用的声音数据，考虑检测到的头部位置。我们在实际会议 dataset 上训练和评估了我们的算法，该 dataset 包括最多14名参与者、重叠的说话、其他挑战性enario。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Disentangling-of-Facial-Representations-with-3D-aware-Latent-Diffusion-Models"><a href="#Unsupervised-Disentangling-of-Facial-Representations-with-3D-aware-Latent-Diffusion-Models" class="headerlink" title="Unsupervised Disentangling of Facial Representations with 3D-aware Latent Diffusion Models"></a>Unsupervised Disentangling of Facial Representations with 3D-aware Latent Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08273">http://arxiv.org/abs/2309.08273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruian He, Zhen Xing, Weimin Tan, Bo Yan</li>
<li>for: 提出了一种无监督的人脸表示学习方法，以提高无需大量标注数据的face理解能力。</li>
<li>methods: 提出了一种基于3D射频扩散模型的无监督分解方法，通过在幂空间进行分解，实现了人脸表示的分解和表示混合。</li>
<li>results: 通过对多个数据集进行测试，实现了无监督人脸表示学习模型的state-of-the-art性能，并且在人脸认证和表情识别等下游任务中达到了优秀的结果。<details>
<summary>Abstract</summary>
Unsupervised learning of facial representations has gained increasing attention for face understanding ability without heavily relying on large-scale annotated datasets. However, it remains unsolved due to the coupling of facial identities, expressions, and external factors like pose and light. Prior methods primarily focus on 2D factors and pixel-level consistency, leading to incomplete disentangling and suboptimal performance in downstream tasks. In this paper, we propose LatentFace, a novel unsupervised disentangling framework for facial expression and identity representation. We suggest the disentangling problem should be performed in latent space and propose the solution using a 3D-ware latent diffusion model. First, we introduce a 3D-aware autoencoder to encode face images into 3D latent embeddings. Second, we propose a novel representation diffusion model (RDM) to disentangle 3D latent into facial identity and expression. Consequently, our method achieves state-of-the-art performance in facial expression recognition and face verification among unsupervised facial representation learning models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>无监督学习的脸部表示学习在脸部理解能力方面受到了越来越多的关注，但它还未得到解决，因为脸部身份、表情和外部因素如pose和光照的关系。先前的方法主要关注于2D因素和像素级匹配，导致不完全分离和下游任务的下降性能。在本文中，我们提议在幂空间进行不监督分解，并提出一种3D-aware latent diffusion模型来解决这个问题。首先，我们引入3D-aware autoencoder来编码脸部图像到3D幂 embeddings。其次，我们提出一种新的表达分析模型（RDM），以分解3D幂到脸部身份和表情。因此，我们的方法在无监督脸部表示学习模型中实现了状态机器的表情识别和脸部验证性能。
</details></li>
</ul>
<hr>
<h2 id="Edge-Based-Oriented-Object-Detection"><a href="#Edge-Based-Oriented-Object-Detection" class="headerlink" title="Edge Based Oriented Object Detection"></a>Edge Based Oriented Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08265">http://arxiv.org/abs/2309.08265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pratishtha-agarwal/Automation-of-Attendance-montoring-system">https://github.com/pratishtha-agarwal/Automation-of-Attendance-montoring-system</a></li>
<li>paper_authors: Jianghu Shen, Xiaojun Wu</li>
<li>for: 提高遥感对象检测精度</li>
<li>methods: 使用旋转 bounding box (OBB) 约束对象，并基于边导向量的类似度measurement函数设计新的损失函数，同时实现边缘自注意模块以增强对象边缘的识别。</li>
<li>results: 对比基eline algorithm 的 Smooth L1 损失函数，提出的损失函数实现了0.6%的mAP提升，并且通过边缘自注意模块实现了1.3%的mAP提升在 DOTA 数据集上。<details>
<summary>Abstract</summary>
In the field of remote sensing, we often utilize oriented bounding boxes (OBB) to bound the objects. This approach significantly reduces the overlap among dense detection boxes and minimizes the inclusion of background content within the bounding boxes. To enhance the detection accuracy of oriented objects, we propose a unique loss function based on edge gradients, inspired by the similarity measurement function used in template matching task. During this process, we address the issues of non-differentiability of the function and the semantic alignment between gradient vectors in ground truth (GT) boxes and predicted boxes (PB). Experimental results show that our proposed loss function achieves $0.6\%$ mAP improvement compared to the commonly used Smooth L1 loss in the baseline algorithm. Additionally, we design an edge-based self-attention module to encourage the detection network to focus more on the object edges. Leveraging these two innovations, we achieve a mAP increase of 1.3% on the DOTA dataset.
</details>
<details>
<summary>摘要</summary>
在遥感领域中，我们经常使用方向 bounding box (OBB) 来约束 объек。这种方法可以减少密集检测框的重叠和背景内容的包含在 bounding box 中。为了提高方向 объек 的检测精度，我们提议一种基于边导向量的特有损失函数， inspirited by 模板匹配任务中的相似度测量函数。在这个过程中，我们解决了非 differentiability 问题和 GT 框和 PB 框中的semantic alignment问题。实验结果表明，我们的提议的损失函数可以与基eline algorithm 中的 Smooth L1 损失函数相比，提高了 $0.6\%$ mAP。此外，我们设计了一个基于边的自注意模块，以便检测网络更加注重对象边缘。通过这两个创新，我们在 DOTA 数据集上实现了 mAP 提高 $1.3\%$。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-the-Power-of-Data-Augmentation-for-Transformer-based-Tracking"><a href="#Leveraging-the-Power-of-Data-Augmentation-for-Transformer-based-Tracking" class="headerlink" title="Leveraging the Power of Data Augmentation for Transformer-based Tracking"></a>Leveraging the Power of Data Augmentation for Transformer-based Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08264">http://arxiv.org/abs/2309.08264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhao, Johan Edstedt, Michael Felsberg, Dong Wang, Huchuan Lu</li>
<li>for: 这篇 paper 的目的是探讨对于视觉物件追踪的表现进行改进，并且检查数据增强的影响。</li>
<li>methods: 这篇 paper 使用了 transformer 架构，并且提出了两种数据增强方法，包括一个静态搜寻半径 Mechanism 和一个对应� Feature Mixing augmentation strategy。</li>
<li>results: 实验结果显示，这两种数据增强方法可以提高 transformer 架构 的追踪性能，特别是在一些挑战性的情况下，如一击追踪和小图像分辨率。<details>
<summary>Abstract</summary>
Due to long-distance correlation and powerful pretrained models, transformer-based methods have initiated a breakthrough in visual object tracking performance. Previous works focus on designing effective architectures suited for tracking, but ignore that data augmentation is equally crucial for training a well-performing model. In this paper, we first explore the impact of general data augmentations on transformer-based trackers via systematic experiments, and reveal the limited effectiveness of these common strategies. Motivated by experimental observations, we then propose two data augmentation methods customized for tracking. First, we optimize existing random cropping via a dynamic search radius mechanism and simulation for boundary samples. Second, we propose a token-level feature mixing augmentation strategy, which enables the model against challenges like background interference. Extensive experiments on two transformer-based trackers and six benchmarks demonstrate the effectiveness and data efficiency of our methods, especially under challenging settings, like one-shot tracking and small image resolutions.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:因为长距离相关和强大预训模型，转换器基本方法在视觉对象跟踪性能中引入了一次突破。先前的工作主要关注设计适合跟踪的有效架构，而忽略了数据增强的重要性。在这篇论文中，我们首先通过系统实验研究 transformer 基本方法中的数据增强对应性的影响，并发现这些常见策略的有限效iveness。在实验结果的激发下，我们提出了两种特定于跟踪的数据增强方法。首先，我们通过动态搜索半径机制和模拟边缘样本来优化现有的随机裁剪。其次，我们提出了一种含义级别的特征混合增强策略，使模型在背景干扰等挑战下能够更有效。我们在两个 transformer 基本方法和六个标准测试集上进行了广泛的实验，特别是在一键跟踪和小图分辨率的情况下， demonstrating the effectiveness and data efficiency of our methods。
</details></li>
</ul>
<hr>
<h2 id="BROW-Better-featuRes-fOr-Whole-slide-image-based-on-self-distillation"><a href="#BROW-Better-featuRes-fOr-Whole-slide-image-based-on-self-distillation" class="headerlink" title="BROW: Better featuRes fOr Whole slide image based on self-distillation"></a>BROW: Better featuRes fOr Whole slide image based on self-distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08259">http://arxiv.org/abs/2309.08259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanfeng Wu, Shaojie Li, Zhiqiang Du, Wentao Zhu</li>
<li>for:  This paper aims to propose a foundation model for extracting better feature representations for whole slide images (WSIs) in clinical diagnosis.</li>
<li>methods:  The proposed model, called BROW, uses a transformer architecture and is pretrained using a self-distillation framework. It also employs techniques such as patch shuffling to improve the model’s robustness.</li>
<li>results:  The proposed model achieves high performance on various downstream tasks, including slide-level subtyping, patch-level classification, and nuclei instance segmentation. The results confirm the efficacy, robustness, and good generalization ability of the model, making it a promising foundation model for WSI feature extraction.Here are the three points in Simplified Chinese text:</li>
<li>for: 这个论文的目的是提出一个基础模型，用于抽取全像片（WSIs）的更好的特征表示。</li>
<li>methods: 该提案的模型，名为BROW，使用转换器架构，通过自我精炼框架进行预训练。它还使用了质patch混淆来提高模型的稳定性。</li>
<li>results: 该模型在各种下游任务上达到了高性能，包括滑块分类、谱片分类和核体实例分割。结果证明了模型的可靠性、稳定性和通用性，表明其可以作为WSIs特征EXTRACTING的基础模型。<details>
<summary>Abstract</summary>
Whole slide image (WSI) processing is becoming part of the key components of standard clinical diagnosis for various diseases. However, the direct application of conventional image processing algorithms to WSI faces certain obstacles because of WSIs' distinct property: the super-high resolution. The performance of most WSI-related tasks relies on the efficacy of the backbone which extracts WSI patch feature representations. Hence, we proposed BROW, a foundation model for extracting better feature representations for WSIs, which can be conveniently adapted to downstream tasks without or with slight fine-tuning. The model takes transformer architecture, pretrained using self-distillation framework. To improve model's robustness, techniques such as patch shuffling have been employed. Additionally, the model leverages the unique properties of WSIs, utilizing WSI's multi-scale pyramid to incorporate an additional global view, thereby further enhancing its performance. We used both private and public data to make up a large pretraining dataset, containing more than 11000 slides, over 180M extracted patches, encompassing WSIs related to various organs and tissues. To assess the effectiveness of \ourmodel, we run a wide range of downstream tasks, including slide-level subtyping, patch-level classification and nuclei instance segmentation. The results confirmed the efficacy, robustness and good generalization ability of the proposed model. This substantiates its potential as foundation model for WSI feature extraction and highlights promising prospects for its application in WSI processing.
</details>
<details>
<summary>摘要</summary>
整幕图像（WSI）处理已成为许多疾病的标准临床诊断中的关键组件。然而，直接将传统图像处理算法应用于WSI遇到了一些障碍，即WSI的超高分辨率。大多数WSI相关任务的性能取决于提取WSI补丁特征表示的后备模型的效果。因此，我们提出了BROW，一个用于提取WSI补丁特征表示的基本模型，可以无需或只需轻微微调整地应用于下游任务。该模型采用转换器架构，预训练使用自我混合框架。为了提高模型的Robustness，我们采用了补丁混淆技术。此外，模型利用WSI的多尺度 pyramid 特性，进一步增强其性能。我们使用了私人和公共数据构成了一个大型预训练数据集，包含超过11000幅整幕图像，18000万个提取的补丁，覆盖各种器官和组织的WSI。为评估 \ourmodel 的效果，我们运行了多种下游任务，包括板块分类、补丁级别分类和核体实例分割。结果证明了我们提出的模型的有效性、Robustness 和好的泛化能力，这证明了其作为WSI特征提取基本模型的潜在能力，并且表明了其在WSI处理领域的广阔前景。
</details></li>
</ul>
<hr>
<h2 id="Cartoondiff-Training-free-Cartoon-Image-Generation-with-Diffusion-Transformer-Models"><a href="#Cartoondiff-Training-free-Cartoon-Image-Generation-with-Diffusion-Transformer-Models" class="headerlink" title="Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models"></a>Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08251">http://arxiv.org/abs/2309.08251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feihong He, Gang Li, Lingyu Si, Leilei Yan, Shimeng Hou, Hongwei Dong, Fanzhang Li</li>
<li>for: 这个论文旨在提出一种无需训练的图像漫画化方法，使用扩散变换模型进行图像漫画化。</li>
<li>methods: 该方法基于扩散变换模型的反向过程，分为semantic生成阶段和细节生成阶段。图像漫画化过程中，通过特定的干扰步骤来减少高频信号的干扰。</li>
<li>results: EXTENSIVE experiment results show that CartoonDiff has powerful ability in image cartoonization, without requiring additional reference images, complex model designs, or tedious adjustment of multiple parameters. 详细的实验结果表明，CartoonDiff可以具有强大的图像漫画化能力，不需要额外的参考图像、复杂的模型设计或多参数的繁琐调整。<details>
<summary>Abstract</summary>
Image cartoonization has attracted significant interest in the field of image generation. However, most of the existing image cartoonization techniques require re-training models using images of cartoon style. In this paper, we present CartoonDiff, a novel training-free sampling approach which generates image cartoonization using diffusion transformer models. Specifically, we decompose the reverse process of diffusion models into the semantic generation phase and the detail generation phase. Furthermore, we implement the image cartoonization process by normalizing high-frequency signal of the noisy image in specific denoising steps. CartoonDiff doesn't require any additional reference images, complex model designs, or the tedious adjustment of multiple parameters. Extensive experimental results show the powerful ability of our CartoonDiff. The project page is available at: https://cartoondiff.github.io/
</details>
<details>
<summary>摘要</summary>
图像漫画化已经在图像生成领域引起了广泛的关注。然而，大多数现有的图像漫画化技术需要重新训练模型使用漫画风格图像。在这篇论文中，我们提出了CartoonDiff，一种新的无需训练的抽象采样方法，可以使用噪声变换模型来生成图像漫画化。我们将推理过程中的噪声变换模型分解成semantic生成阶段和细节生成阶段。此外，我们在特定的净化步骤中normalize高频信号，以实现图像漫画化过程。CartoonDiff不需要任何参考图像、复杂的模型设计或多个参数的繁琐调整。我们的实验结果表明CartoonDiff具有强大的能力。相关项目页面可以在以下地址找到：https://cartoondiff.github.io/
</details></li>
</ul>
<hr>
<h2 id="Optimization-of-Rank-Losses-for-Image-Retrieval"><a href="#Optimization-of-Rank-Losses-for-Image-Retrieval" class="headerlink" title="Optimization of Rank Losses for Image Retrieval"></a>Optimization of Rank Losses for Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08250">http://arxiv.org/abs/2309.08250</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cvdfoundation/google-landmark">https://github.com/cvdfoundation/google-landmark</a></li>
<li>paper_authors: Elias Ramzi, Nicolas Audebert, Clément Rambour, André Araujo, Xavier Bitot, Nicolas Thome</li>
<li>for: This paper focuses on improving the training of deep neural networks for image retrieval tasks using a new framework for robust and decomposable rank losses optimization.</li>
<li>methods: The proposed framework includes a general surrogate for ranking operators called SupRank, which provides an upperbound for rank losses and ensures robust training, as well as a simple yet effective loss function to reduce the decomposability gap between the averaged batch approximation of ranking losses and their values on the whole training set.</li>
<li>results: The authors apply their framework to two standard metrics for image retrieval (AP and R@k) and introduce an extension of AP called hierarchical average precision $\mathcal{H}$-AP, which is optimized as well. Additionally, they create the first hierarchical landmarks retrieval dataset using a semi-automatic pipeline to create hierarchical labels, and release the code at <a target="_blank" rel="noopener" href="https://github.com/elias-ramzi/SupRank">https://github.com/elias-ramzi/SupRank</a>.<details>
<summary>Abstract</summary>
In image retrieval, standard evaluation metrics rely on score ranking, \eg average precision (AP), recall at k (R@k), normalized discounted cumulative gain (NDCG). In this work we introduce a general framework for robust and decomposable rank losses optimization. It addresses two major challenges for end-to-end training of deep neural networks with rank losses: non-differentiability and non-decomposability. Firstly we propose a general surrogate for ranking operator, SupRank, that is amenable to stochastic gradient descent. It provides an upperbound for rank losses and ensures robust training. Secondly, we use a simple yet effective loss function to reduce the decomposability gap between the averaged batch approximation of ranking losses and their values on the whole training set. We apply our framework to two standard metrics for image retrieval: AP and R@k. Additionally we apply our framework to hierarchical image retrieval. We introduce an extension of AP, the hierarchical average precision $\mathcal{H}$-AP, and optimize it as well as the NDCG. Finally we create the first hierarchical landmarks retrieval dataset. We use a semi-automatic pipeline to create hierarchical labels, extending the large scale Google Landmarks v2 dataset. The hierarchical dataset is publicly available at https://github.com/cvdfoundation/google-landmark. Code will be released at https://github.com/elias-ramzi/SupRank.
</details>
<details>
<summary>摘要</summary>
在图像检索中，标准评估指标通常是基于分数排名的，例如平均精度（AP）和在k个结果中的恢复率（R@k）。在这项工作中，我们介绍了一种泛化框架，用于robust和可分解排名损失优化。它解决了深度神经网络在排名损失训练中的两个主要挑战：非导数性和非可分解性。我们首先提出了一种通用排名运算符的代理，即SupRank，该运算符是可以用于批量梯度下降的。它提供了排名损失的Upperbound，并确保了Robust训练。其次，我们使用一种简单 yet有效的损失函数，以减少排名损失的可分解差距。我们将我们的框架应用于AP和R@k两个标准指标，以及层次图像检索。我们引入了一个层次average precision（$\mathcal{H}$-AP），并且优化了NDCG。最后，我们创建了图像检索领域的首个层次标记集。我们使用一种 semi-自动化的管道来创建层次标记，扩展了Google Landmarks v2数据集。层次标记集公开可用于https://github.com/cvdfoundation/google-landmark。代码将在https://github.com/elias-ramzi/SupRank中发布。
</details></li>
</ul>
<hr>
<h2 id="A-Real-time-Faint-Space-Debris-Detector-With-Learning-based-LCM"><a href="#A-Real-time-Faint-Space-Debris-Detector-With-Learning-based-LCM" class="headerlink" title="A Real-time Faint Space Debris Detector With Learning-based LCM"></a>A Real-time Faint Space Debris Detector With Learning-based LCM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08244">http://arxiv.org/abs/2309.08244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zherui Lu, Gangyi Wang, Xinguo Wei, Jian Li</li>
<li>for: 这篇论文旨在提高空间 situational awareness (SSA) 系统的敏感性和效率，以应对增长的空间垃圾问题。</li>
<li>methods: 本论文提出了一种基于本地对比和最大可能性估计 (MLE) 的低信号干扰estreak抽取方法，可以快速和高精度地检测低信号目标。</li>
<li>results: 本论文透过实验和实际应用证明了本方法的高速和高精度，并且与现有的ODCC方法相比，本方法具有较高的效率和较低的中心误差。<details>
<summary>Abstract</summary>
With the development of aerospace technology, the increasing population of space debris has posed a great threat to the safety of spacecraft. However, the low intensity of reflected light and high angular velocity of space debris impede the extraction. Besides, due to the limitations of the ground observation methods, small space debris can hardly be detected, making it necessary to enhance the spacecraft's capacity for space situational awareness (SSA). Considering that traditional methods have some defects in low-SNR target detection, such as low effectiveness and large time consumption, this paper proposes a method for low-SNR streak extraction based on local contrast and maximum likelihood estimation (MLE), which can detect space objects with SNR 2.0 efficiently. In the proposed algorithm, local contrast will be applied for crude classifications, which will return connected components as preliminary results, and then MLE will be performed to reconstruct the connected components of targets via orientated growth, further improving the precision. The algorithm has been verified with both simulated streaks and real star tracker images, and the average centroid error of the proposed algorithm is close to the state-of-the-art method like ODCC. At the same time, the algorithm in this paper has significant advantages in efficiency compared with ODCC. In conclusion, the algorithm in this paper is of high speed and precision, which guarantees its promising applications in the extraction of high dynamic targets.
</details>
<details>
<summary>摘要</summary>
随着航天技术的发展，随空间垃圾的增加已经对航天器的安全提出了极大的威胁。然而，零intsity的反射光和高angular velocity的随空间垃圾使得extraction困难。此外，由于地面观测方法的限制，小型随空间垃圾几乎无法检测，因此需要提高航天器的空间 situational awareness（SSA）能力。由于传统方法在低Signal-to-Noise Ratio（SNR）目标检测中存在一些缺陷，这篇论文提出了一种基于本地对比和最大可能性估计（MLE）的低SNR扫描方法，可以高效地检测SNR 2.0的空间目标。在提案的算法中，本地对比将被应用于初步分类，返回连接组件作为先期结果，然后MLE将被执行以重建连接组件目标via oriented growth，进一步提高精度。这种算法已经在simulated streaks和实际星rack images中验证，并且算法的中心误差与 OdCC 类似。同时，这种算法在效率方面具有显著的优势。因此，这种算法在检测高动态目标方面具有承诺的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Human-Inspired-Topological-Representations-for-Visual-Object-Recognition-in-Unseen-Environments"><a href="#Human-Inspired-Topological-Representations-for-Visual-Object-Recognition-in-Unseen-Environments" class="headerlink" title="Human-Inspired Topological Representations for Visual Object Recognition in Unseen Environments"></a>Human-Inspired Topological Representations for Visual Object Recognition in Unseen Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08239">http://arxiv.org/abs/2309.08239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ekta U. Samani, Ashis G. Banerjee</li>
<li>for: 提高移动机器人在未看到和受阻的indoor环境中对物体认知的精度</li>
<li>methods: 使用TOPS2描述符和基于人类思维机制的THOR2认知框架，将Mapper算法获得的颜色嵌入与形态基于TOPS描述符进行混合</li>
<li>results: THOR2在两个真实世界数据集上（OCID和UW-IS Occluded）实现了比shape-based THOR框架和RGB-D ViT更高的认知精度，因此THOR2是实现低成本机器人中 robust认知的可能性的一步<details>
<summary>Abstract</summary>
Visual object recognition in unseen and cluttered indoor environments is a challenging problem for mobile robots. Toward this goal, we extend our previous work to propose the TOPS2 descriptor, and an accompanying recognition framework, THOR2, inspired by a human reasoning mechanism known as object unity. We interleave color embeddings obtained using the Mapper algorithm for topological soft clustering with the shape-based TOPS descriptor to obtain the TOPS2 descriptor. THOR2, trained using synthetic data, achieves substantially higher recognition accuracy than the shape-based THOR framework and outperforms RGB-D ViT on two real-world datasets: the benchmark OCID dataset and the UW-IS Occluded dataset. Therefore, THOR2 is a promising step toward achieving robust recognition in low-cost robots.
</details>
<details>
<summary>摘要</summary>
<<SYS>>transliteration: zhèng zhì wén tiě de rén shì yǐ jīn yì yì zhòng zhèng shì, dài zhèng zhì wén tiě de jīn yì yì zhòng zhèng shì, zhèng zhì wén tiě de rén shì yǐ jīn yì yì zhòng zhèng shì, yǐ jīn yì yì zhòng zhèng shì, dài zhèng zhì wén tiě de jīn yì yì zhòng zhèng shì, yǐ jīn yì yì zhòng zhèng shì.Translation:现代移动机器人可能需要在未看过和受损的indoor环境中进行视觉对象识别。为此，我们从我们之前的工作中扩展了TOPS描述器，并采用了人类思维机制known as object unity的灵感，提出了TOPS2描述器。我们将Mapper算法得到的颜色嵌入与TOPS描述器结合，以获得TOPS2描述器。THOR2，使用 sintetic数据进行训练，在两个实际 datasets上表现出了substantially higher的识别精度，比shape-based THOR框架和RGB-D ViT更高。因此，THOR2是一个有前途的步骤，可以帮助实现低成本机器人中的稳定识别。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Polyp-Segmentation-Via-Integrity-Learning"><a href="#Efficient-Polyp-Segmentation-Via-Integrity-Learning" class="headerlink" title="Efficient Polyp Segmentation Via Integrity Learning"></a>Efficient Polyp Segmentation Via Integrity Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08234">http://arxiv.org/abs/2309.08234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqiang Chen, Kang Wang, Yun Liu</li>
<li>for: 该研究旨在提高护肤诊断、指导 intervención 和 treatment 的准确性，通过解决质量不足问题，提高护肤诊断的准确性。</li>
<li>methods: 该研究提出了一种名为 Integrity Capturing Polyp Segmentation (IC-PolypSeg) 网络，该网络使用轻量级的骨干和三种关键组件来改善质量不足问题：1）像素级别特征重新分配模块（PFR），2）跨stage像素级别特征重新分配模块（CPFR），3）粗细调整模块。</li>
<li>results: 对于5个公共数据集，该研究表明，提出的 IC-PolypSeg 方法可以与8种现有方法进行比较，在准确率和计算效率两个方面具有显著优势。IC-PolypSeg-EF0 使用300次少于 PraNet 的参数，实现了实时处理速度235 FPS，并且可以减少 false negative 率。<details>
<summary>Abstract</summary>
Accurate polyp delineation in colonoscopy is crucial for assisting in diagnosis, guiding interventions, and treatments. However, current deep-learning approaches fall short due to integrity deficiency, which often manifests as missing lesion parts. This paper introduces the integrity concept in polyp segmentation at both macro and micro levels, aiming to alleviate integrity deficiency. Specifically, the model should distinguish entire polyps at the macro level and identify all components within polyps at the micro level. Our Integrity Capturing Polyp Segmentation (IC-PolypSeg) network utilizes lightweight backbones and 3 key components for integrity ameliorating: 1) Pixel-wise feature redistribution (PFR) module captures global spatial correlations across channels in the final semantic-rich encoder features. 2) Cross-stage pixel-wise feature redistribution (CPFR) module dynamically fuses high-level semantics and low-level spatial features to capture contextual information. 3) Coarse-to-fine calibration module combines PFR and CPFR modules to achieve precise boundary detection. Extensive experiments on 5 public datasets demonstrate that the proposed IC-PolypSeg outperforms 8 state-of-the-art methods in terms of higher precision and significantly improved computational efficiency with lower computational consumption. IC-PolypSeg-EF0 employs 300 times fewer parameters than PraNet while achieving a real-time processing speed of 235 FPS. Importantly, IC-PolypSeg reduces the false negative ratio on five datasets, meeting clinical requirements.
</details>
<details>
<summary>摘要</summary>
准确的肠癌腺分 segmentation在colonoscopy中非常重要，可以帮助诊断、引导 intervención和治疗。然而，现有的深度学习方法 often lack integrity, which can lead to missing lesion parts. This paper introduces the integrity concept in polyp segmentation at both macro and micro levels, aiming to alleviate integrity deficiency. Specifically, the model should distinguish entire polyps at the macro level and identify all components within polyps at the micro level. Our Integrity Capturing Polyp Segmentation (IC-PolypSeg) network uses lightweight backbones and 3 key components to improve integrity:1. 像素级别特征重定向（PFR）模块 capture global spatial correlations across channels in the final semantic-rich encoder features.2. 跨阶段像素级别特征重定向（CPFR）模块 dynamically fuses high-level semantics and low-level spatial features to capture contextual information.3. 粗细调整模块 combines PFR and CPFR modules to achieve precise boundary detection.我们在5个公共数据集上进行了广泛的实验，结果显示，我们的提posed IC-PolypSeg方法在精度和计算效率方面都有所提高，与8种现有方法进行比较。 IC-PolypSeg-EF0使用300次少于PraNet的参数，同时实现了235帧/秒的实时处理速度。进一步地，IC-PolypSeg可以减少在5个数据集上的假阳性比率，满足临床要求。
</details></li>
</ul>
<hr>
<h2 id="UniST-Towards-Unifying-Saliency-Transformer-for-Video-Saliency-Prediction-and-Detection"><a href="#UniST-Towards-Unifying-Saliency-Transformer-for-Video-Saliency-Prediction-and-Detection" class="headerlink" title="UniST: Towards Unifying Saliency Transformer for Video Saliency Prediction and Detection"></a>UniST: Towards Unifying Saliency Transformer for Video Saliency Prediction and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08220">http://arxiv.org/abs/2309.08220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwen Xiong, Peng Zhang, Chuanyue Li, Wei Huang, Yufei Zha, Tao You</li>
<li>for: 本研究旨在构建一个通用的视觉注意力模型框架，以实现视觉注意力预测和视觉关键物预测的融合。</li>
<li>methods: 本研究提出了一个具有视觉注意力属性的 transformer 架构，并将其应用于逐步增加分辨率的对照处理中，以获得更加积极的视觉注意力表示。此外，本研究还提出了一个任务特定的解码器，以进行最终的预测。</li>
<li>results: 实验结果显示，提出的 UniST 模型在七个挑战性的benchmark上表现出色，与其他现有的方法相比，具有更高的性能。<details>
<summary>Abstract</summary>
Video saliency prediction and detection are thriving research domains that enable computers to simulate the distribution of visual attention akin to how humans perceiving dynamic scenes. While many approaches have crafted task-specific training paradigms for either video saliency prediction or video salient object detection tasks, few attention has been devoted to devising a generalized saliency modeling framework that seamlessly bridges both these distinct tasks. In this study, we introduce the Unified Saliency Transformer (UniST) framework, which comprehensively utilizes the essential attributes of video saliency prediction and video salient object detection. In addition to extracting representations of frame sequences, a saliency-aware transformer is designed to learn the spatio-temporal representations at progressively increased resolutions, while incorporating effective cross-scale saliency information to produce a robust representation. Furthermore, a task-specific decoder is proposed to perform the final prediction for each task. To the best of our knowledge, this is the first work that explores designing a transformer structure for both saliency modeling tasks. Convincible experiments demonstrate that the proposed UniST achieves superior performance across seven challenging benchmarks for two tasks, and significantly outperforms the other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
视频注意力预测和检测是计算机视觉领域的兴旺研究领域，它们帮助计算机模拟人类看到动态场景中的注意力分布，类似于人类的视觉过程。虽然有很多方法已经为这两个独立的任务进行了特定任务训练 paradigma，但是很少人关注了开发一个涵盖这两个任务的通用注意力模型框架。在这种研究中，我们引入了统一注意力变换（UniST）框架，它利用视频注意力预测和视频突出对象检测中的重要特征进行了全面利用。此外，我们还设计了一个可靠的词法解码器，以便对每个任务进行最终预测。根据我们所知，这是第一个采用变换结构来解决两个注意力模型任务的研究。我们的实验表明，提案的 UniST 在七个挑战性的benchmark上表现出色，与其他现有方法相比，具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Salient-Object-Detection-in-Optical-Remote-Sensing-Images-Driven-by-Transformer"><a href="#Salient-Object-Detection-in-Optical-Remote-Sensing-Images-Driven-by-Transformer" class="headerlink" title="Salient Object Detection in Optical Remote Sensing Images Driven by Transformer"></a>Salient Object Detection in Optical Remote Sensing Images Driven by Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08206">http://arxiv.org/abs/2309.08206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mathlee/gelenet">https://github.com/mathlee/gelenet</a></li>
<li>paper_authors: Gongyang Li, Zhen Bai, Zhi Liu, Xinpeng Zhang, Haibin Ling</li>
<li>For: 本研究提出了一种全新的全球抽象本地探索网络（GeleNet），用于 óptical remote sensing 图像中的突出对象检测（ORSI-SOD）。* Methods: GeleNet 使用 transformer 背景进行四级特征嵌入，并使用方向感知杂化杂化精度探索模块（D-SWSAM）和简化版 SWSAM，以及知识传递模块（KTM）进行增强。* Results: 对三个公共数据集进行了广泛的实验，结果表明，提出的 GeleNet 方法在相关的州态艺术方法之上表现出色，并且可以更好地检测 óptical remote sensing 图像中的突出对象。<details>
<summary>Abstract</summary>
Existing methods for Salient Object Detection in Optical Remote Sensing Images (ORSI-SOD) mainly adopt Convolutional Neural Networks (CNNs) as the backbone, such as VGG and ResNet. Since CNNs can only extract features within certain receptive fields, most ORSI-SOD methods generally follow the local-to-contextual paradigm. In this paper, we propose a novel Global Extraction Local Exploration Network (GeleNet) for ORSI-SOD following the global-to-local paradigm. Specifically, GeleNet first adopts a transformer backbone to generate four-level feature embeddings with global long-range dependencies. Then, GeleNet employs a Direction-aware Shuffle Weighted Spatial Attention Module (D-SWSAM) and its simplified version (SWSAM) to enhance local interactions, and a Knowledge Transfer Module (KTM) to further enhance cross-level contextual interactions. D-SWSAM comprehensively perceives the orientation information in the lowest-level features through directional convolutions to adapt to various orientations of salient objects in ORSIs, and effectively enhances the details of salient objects with an improved attention mechanism. SWSAM discards the direction-aware part of D-SWSAM to focus on localizing salient objects in the highest-level features. KTM models the contextual correlation knowledge of two middle-level features of different scales based on the self-attention mechanism, and transfers the knowledge to the raw features to generate more discriminative features. Finally, a saliency predictor is used to generate the saliency map based on the outputs of the above three modules. Extensive experiments on three public datasets demonstrate that the proposed GeleNet outperforms relevant state-of-the-art methods. The code and results of our method are available at https://github.com/MathLee/GeleNet.
</details>
<details>
<summary>摘要</summary>
现有的 optical remote sensing images （ORSIs）中的醒目对象检测（SOD）方法主要采用卷积神经网络（CNN）作为背景，如 VGG 和 ResNet。由于 CNN 只能提取特定感受场的特征， większość ORSIs-SOD 方法通常采用本地到Contextual 方法。在这篇文章中，我们提出了一种全新的全球抽取本地探索网络（GeleNet） для ORSIs-SOD，采用全球到本地方法。具体来说，GeleNet 首先采用 transformer 背景来生成四级特征嵌入，并且使用方向感知杂合排序键控模块（D-SWSAM）和其简化版本（SWSAM）来增强本地互动。此外，我们还采用知识传递模块（KTM）来进一步增强跨级Contextual 互动。D-SWSAM 通过方向性杂合来完全感知最低级特征中的方向信息，以适应 ORSIs 中不同方向的醒目对象，并有效地提高醒目对象的细节。SWSAM 将 D-SWSAM 中的方向感知部分排除，以专注于 ORSIs 中醒目对象的本地化。KTM 基于自我注意机制，模型了两个中级特征的Contextual 相互关系知识，并将其传递给原始特征，以生成更有特征的特征。最后，我们使用 saliency predictor 来生成醒目度映射，基于上述三个模块的输出。我们在三个公共数据集上进行了广泛的实验，结果表明，提出的 GeleNet 方法在相关的状态 искусственный智能 方法中具有优势。我们的代码和结果可以在 GitHub 上找到：https://github.com/MathLee/GeleNet。
</details></li>
</ul>
<hr>
<h2 id="One-stage-Modality-Distillation-for-Incomplete-Multimodal-Learning"><a href="#One-stage-Modality-Distillation-for-Incomplete-Multimodal-Learning" class="headerlink" title="One-stage Modality Distillation for Incomplete Multimodal Learning"></a>One-stage Modality Distillation for Incomplete Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08204">http://arxiv.org/abs/2309.08204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shicai Wei, Yang Luo, Chunbo Luo</li>
<li>for:  Addresses the challenge of inferring with incomplete modality in multimodal learning.</li>
<li>methods:  Proposes a one-stage modality distillation framework that combines privileged knowledge transfer and modality information fusion via multi-task learning.</li>
<li>results:  Achieves state-of-the-art performance on RGB-D classification and segmentation tasks despite incomplete modality input in various scenes.<details>
<summary>Abstract</summary>
Learning based on multimodal data has attracted increasing interest recently. While a variety of sensory modalities can be collected for training, not all of them are always available in development scenarios, which raises the challenge to infer with incomplete modality. To address this issue, this paper presents a one-stage modality distillation framework that unifies the privileged knowledge transfer and modality information fusion into a single optimization procedure via multi-task learning. Compared with the conventional modality distillation that performs them independently, this helps to capture the valuable representation that can assist the final model inference directly. Specifically, we propose the joint adaptation network for the modality transfer task to preserve the privileged information. This addresses the representation heterogeneity caused by input discrepancy via the joint distribution adaptation. Then, we introduce the cross translation network for the modality fusion task to aggregate the restored and available modality features. It leverages the parameters-sharing strategy to capture the cross-modal cues explicitly. Extensive experiments on RGB-D classification and segmentation tasks demonstrate the proposed multimodal inheritance framework can overcome the problem of incomplete modality input in various scenes and achieve state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Learning based on multimodal data" becomes "学习基于多modal数据" (学习基于多modal数据) in Simplified Chinese.* "while a variety of sensory modalities can be collected for training" becomes "而可收集多种感知模式进行训练" (而可收集多种感知模式进行训练) in Simplified Chinese.* "not all of them are always available in development scenarios" becomes "不一定可用于开发场景" (不一定可用于开发场景) in Simplified Chinese.* "which raises the challenge to infer with incomplete modality" becomes "带来 incomplete modality 的挑战" (带来 incomplete modality 的挑战) in Simplified Chinese.* "To address this issue, this paper presents a one-stage modality distillation framework" becomes "为解决这个问题，本文提出了一个一stage modality distillation框架" (为解决这个问题，本文提出了一个一stage modality distillation 框架) in Simplified Chinese.* "Compared with the conventional modality distillation that performs them independently" becomes "与传统的 modality distillation 相比" (与传统的 modality distillation 相比) in Simplified Chinese.* "This helps to capture the valuable representation that can assist the final model's inference directly" becomes "可以直接帮助最终模型的推理" (可以直接帮助最终模型的推理) in Simplified Chinese.* "Specifically, we propose the joint adaptation network for the modality transfer task to preserve the privileged information" becomes "我们专门提出了一个 joint adaptation network 来保持特权信息" (我们专门提出了一个 joint adaptation network 来保持特权信息) in Simplified Chinese.* "Then, we introduce the cross translation network for the modality fusion task to aggregate the restored and available modality features" becomes "然后，我们引入了一个 cross translation network 来聚合恢复和可用的模式特征" (然后，我们引入了一个 cross translation network 来聚合恢复和可用的模式特征) in Simplified Chinese.* "Extensive experiments on RGB-D classification and segmentation tasks demonstrate the proposed multimodal inheritance framework can overcome the problem of incomplete modality input in various scenes and achieve state-of-the-art performance" becomes "广泛的RGB-D分类和 segmentation任务实验表明，我们提出的多modal继承框架可以在多种场景中superior performance" (广泛的RGB-D分类和 segmentation 任务实验表明，我们提出的多modal 继承框架可以在多种场景中superior performance) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Hyperspectral-Image-Denoising-via-Self-Modulating-Convolutional-Neural-Networks"><a href="#Hyperspectral-Image-Denoising-via-Self-Modulating-Convolutional-Neural-Networks" class="headerlink" title="Hyperspectral Image Denoising via Self-Modulating Convolutional Neural Networks"></a>Hyperspectral Image Denoising via Self-Modulating Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08197">http://arxiv.org/abs/2309.08197</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/orhan-t/sm-cnn">https://github.com/orhan-t/sm-cnn</a></li>
<li>paper_authors: Orhan Torun, Seniha Esen Yuksel, Erkut Erdem, Nevrez Imamoglu, Aykut Erdem</li>
<li>for: 本研究旨在提出一种基于自适应 spectral-spatial 信息的高spectral像像预处理方法，以提高现有高spectral像像预处理方法对实际复杂噪谱的性能。</li>
<li>methods: 该方法基于一种新的 spectral self-modulating residual block (SSMRB)，该块可以根据邻近 spectral 数据来自适应地变换输入高spectral像像的特征，从而提高网络对实际复杂噪谱的适应能力。</li>
<li>results: 实验表明，提出的 SM-CNN 方法在公共 benchmark 数据集上比其他当前领先的高spectral像像预处理方法表现更好 both quantitatively and qualitatively。<details>
<summary>Abstract</summary>
Compared to natural images, hyperspectral images (HSIs) consist of a large number of bands, with each band capturing different spectral information from a certain wavelength, even some beyond the visible spectrum. These characteristics of HSIs make them highly effective for remote sensing applications. That said, the existing hyperspectral imaging devices introduce severe degradation in HSIs. Hence, hyperspectral image denoising has attracted lots of attention by the community lately. While recent deep HSI denoising methods have provided effective solutions, their performance under real-life complex noise remains suboptimal, as they lack adaptability to new data. To overcome these limitations, in our work, we introduce a self-modulating convolutional neural network which we refer to as SM-CNN, which utilizes correlated spectral and spatial information. At the core of the model lies a novel block, which we call spectral self-modulating residual block (SSMRB), that allows the network to transform the features in an adaptive manner based on the adjacent spectral data, enhancing the network's ability to handle complex noise. In particular, the introduction of SSMRB transforms our denoising network into a dynamic network that adapts its predicted features while denoising every input HSI with respect to its spatio-spectral characteristics. Experimental analysis on both synthetic and real data shows that the proposed SM-CNN outperforms other state-of-the-art HSI denoising methods both quantitatively and qualitatively on public benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:与自然图像不同，光谱图像（HSIs）具有较多的频谱信息，每个频谱信息都是在某些波长上的特定信息，甚至是可见光spectrum之外的信息。这些光谱图像的特点使其在远程感知应用中非常有效。然而，现有的光谱成像设备会对HSIs进行严重的降解。因此，光谱图像去噪引起了社区的广泛关注。虽然最近的深度HSIs去噪方法提供了有效的解决方案，但它们在实际生成的复杂噪声下表现不佳，因为它们缺乏对新数据的适应性。为了解决这些限制，我们在这里引入一种自适应 convolutional neural network，即SM-CNN，该网络利用相关的 spectral和空间信息。SM-CNN的核心块是一种新的 spectral self-modulating residual block（SSMRB），该块使得网络可以根据邻近的spectral数据来适应性地变换特征，提高网络对复杂噪声的能力。具体来说，SSMRB将我们的去噪网络转化成一种动态网络，该网络在处理每个输入HSIs时对其进行适应性的预测。实验分析表明，我们提出的SM-CNN在 Synthetic和实际数据上都能够superior于其他状态的艺术HSIs去噪方法， both quantitatively and qualitatively。
</details></li>
</ul>
<hr>
<h2 id="ECEA-Extensible-Co-Existing-Attention-for-Few-Shot-Object-Detection"><a href="#ECEA-Extensible-Co-Existing-Attention-for-Few-Shot-Object-Detection" class="headerlink" title="ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection"></a>ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08196">http://arxiv.org/abs/2309.08196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhimeng Xin, Tianxu Wu, Shiming Chen, Yixiong Zou, Ling Shao, Xinge You</li>
<li>for: 提高ew-shot对象检测精度，使用两个阶段学习策略，但忽略了对象的局部到全局的转化。</li>
<li>methods: 提出了一种可扩展的合作注意力模块（ECEA），通过在基础阶段积累充足数据后，在新阶段进行可扩展的学习，使模型快速适应扩展局部区域到共存区域。</li>
<li>results: 在PASCAL VOC和COCO dataset上进行了广泛的实验，显示了ECEA模块可以帮助ew-shot检测器完全预测对象，即使一些地方在训练样本中不出现。 Comparing with现有的ew-shot对象检测方法，ECEA模块实现了新的最佳性。<details>
<summary>Abstract</summary>
Few-shot object detection (FSOD) identifies objects from extremely few annotated samples. Most existing FSOD methods, recently, apply the two-stage learning paradigm, which transfers the knowledge learned from abundant base classes to assist the few-shot detectors by learning the global features. However, such existing FSOD approaches seldom consider the localization of objects from local to global. Limited by the scarce training data in FSOD, the training samples of novel classes typically capture part of objects, resulting in such FSOD methods cannot detect the completely unseen object during testing. To tackle this problem, we propose an Extensible Co-Existing Attention (ECEA) module to enable the model to infer the global object according to the local parts. Essentially, the proposed module continuously learns the extensible ability on the base stage with abundant samples and transfers it to the novel stage, which can assist the few-shot model to quickly adapt in extending local regions to co-existing regions. Specifically, we first devise an extensible attention mechanism that starts with a local region and extends attention to co-existing regions that are similar and adjacent to the given local region. We then implement the extensible attention mechanism in different feature scales to progressively discover the full object in various receptive fields. Extensive experiments on the PASCAL VOC and COCO datasets show that our ECEA module can assist the few-shot detector to completely predict the object despite some regions failing to appear in the training samples and achieve the new state of the art compared with existing FSOD methods.
</details>
<details>
<summary>摘要</summary>
几个样本对象检测（FSOD）可以从极少量的标注样本中识别 объек。现有的大多数FSOD方法在最近使用两stage学习 парадиг，通过将丰富基类知识传递到帮助几个样本检测器学习全局特征。然而，现有的FSOD方法通常不考虑对象从本地到全局的地方化。由于FSOD的训练样本通常只包含部分 объек，因此这些方法在测试中无法完全识别未看过的对象。为解决这个问题，我们提议一个可扩展的共存注意力（ECEA）模块，使得模型可以根据本地部分来推断全局对象。具体来说，我们首先设计了一个可扩展注意力机制，从本地区域开始，扩展注意力到相似和邻近的共存区域。然后，我们在不同的特征缩放中实现了可扩展注意力机制，逐渐发现全对象在不同的感知场。广泛的实验表明，我们的ECEA模块可以帮助几个样本检测器快速适应延伸本地区域到共存区域，并在PASCAL VOC和COCO数据集上达到新的状态的艺术水平，比现有的FSOD方法更高。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-and-Smooth-3D-Multi-Person-Pose-Estimation-from-Monocular-Videos-in-the-Wild"><a href="#Towards-Robust-and-Smooth-3D-Multi-Person-Pose-Estimation-from-Monocular-Videos-in-the-Wild" class="headerlink" title="Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild"></a>Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08644">http://arxiv.org/abs/2309.08644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungchan Park, Eunyi You, Inhoe Lee, Joonseok Lee</li>
<li>for: 3DMPPE (3D pose estimation for multi-person from a monocular video)</li>
<li>methods:  sequence-to-sequence 2D-to-3D lifting model with novel geometry-aware data augmentation strategy</li>
<li>results: robust generalization to diverse unseen views, robust recovery against heavy occlusions, and more natural and smoother outputsHere’s the full summary in Simplified Chinese:</li>
<li>for: 3DMPPE 是计算机视觉中一项非常有价值的任务，尤其是在多人3Dpose estimation方面，现有的方法仍然处于不稳定的阶段，尚未应用于实际场景。我们提出了三个未解决的问题：在训练过程中不能处理未见视图，容易受到遮挡，并且输出存在剧烈晃动。</li>
<li>methods: 我们提出了一种基于序列到序列的2D-to-3D升级模型，利用了一种新的geometry-aware数据增强策略，可以生成无限多的视图数据，同时注意到地面和遮挡。</li>
<li>results: 我们的模型和数据增强方法可以稳定地处理多个未见视图，在压权遮挡下强健地恢复pose，并生成更自然和平滑的输出。我们的方法不仅在公共benchmark上实现了状态的最佳性能，还在更加挑战性的室内视频上取得了优秀的result。I hope that helps!<details>
<summary>Abstract</summary>
3D pose estimation is an invaluable task in computer vision with various practical applications. Especially, 3D pose estimation for multi-person from a monocular video (3DMPPE) is particularly challenging and is still largely uncharted, far from applying to in-the-wild scenarios yet. We pose three unresolved issues with the existing methods: lack of robustness on unseen views during training, vulnerability to occlusion, and severe jittering in the output. As a remedy, we propose POTR-3D, the first realization of a sequence-to-sequence 2D-to-3D lifting model for 3DMPPE, powered by a novel geometry-aware data augmentation strategy, capable of generating unbounded data with a variety of views while caring about the ground plane and occlusions. Through extensive experiments, we verify that the proposed model and data augmentation robustly generalizes to diverse unseen views, robustly recovers the poses against heavy occlusions, and reliably generates more natural and smoother outputs. The effectiveness of our approach is verified not only by achieving the state-of-the-art performance on public benchmarks, but also by qualitative results on more challenging in-the-wild videos. Demo videos are available at https://www.youtube.com/@potr3d.
</details>
<details>
<summary>摘要</summary>
“3Dpose estimation是计算机视觉中的一项无可取代任务，具有各种实际应用。特别是3DMPPE（多人3Dpose estimation from monocular video）在训练时没有看到视图的稳定性和 occlusion 问题，还尚未在实际场景中应用。我们提出了现有方法的三个未解问题：训练时没有看到视图的稳定性、 occlusion 的感受性和输出中的抖动。为了解决这些问题，我们提出了 POTR-3D，首个实现了sequence-to-sequence 2D-to-3D lifting模型，通过一种新的几何化数据增强策略，能够生成无限多个视图，同时注重地面和 occlusions。经过广泛的实验，我们证明了我们的模型和数据增强方法可以robustly泛化到多种未见过视图，对重重 occlusions 进行恢复，并且可以生成更自然和稳定的输出。我们的方法不仅在公共标准 bencmarks 上实现了state-of-the-art表现，还通过在更加挑战的in-the-wild视频中的质量结果证明了我们的方法的有效性。 Demo 视频可以在https://www.youtube.com/@potr3d 找到。”
</details></li>
</ul>
<hr>
<h2 id="STDG-Semi-Teacher-Student-Training-Paradigram-for-Depth-guided-One-stage-Scene-Graph-Generation"><a href="#STDG-Semi-Teacher-Student-Training-Paradigram-for-Depth-guided-One-stage-Scene-Graph-Generation" class="headerlink" title="STDG: Semi-Teacher-Student Training Paradigram for Depth-guided One-stage Scene Graph Generation"></a>STDG: Semi-Teacher-Student Training Paradigram for Depth-guided One-stage Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08179">http://arxiv.org/abs/2309.08179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xukun Zhou, Zhenbo Song, Jun He, Hongyan Liu, Zhaoxin Fan</li>
<li>for: 提高自动化 роботи系统的环境理解能力，尤其是在背景复杂度下</li>
<li>methods: 使用一stageScene Graph生成方法，包括自定义的HHA表示生成模块、 semi-teaching网络学习模块和Scene Graph生成模块</li>
<li>results: 对比基eline，本方法在一stageScene Graph生成任务上显著提高性能<details>
<summary>Abstract</summary>
Scene Graph Generation is a critical enabler of environmental comprehension for autonomous robotic systems. Most of existing methods, however, are often thwarted by the intricate dynamics of background complexity, which limits their ability to fully decode the inherent topological information of the environment. Additionally, the wealth of contextual information encapsulated within depth cues is often left untapped, rendering existing approaches less effective. To address these shortcomings, we present STDG, an avant-garde Depth-Guided One-Stage Scene Graph Generation methodology. The innovative architecture of STDG is a triad of custom-built modules: The Depth Guided HHA Representation Generation Module, the Depth Guided Semi-Teaching Network Learning Module, and the Depth Guided Scene Graph Generation Module. This trifecta of modules synergistically harnesses depth information, covering all aspects from depth signal generation and depth feature utilization, to the final scene graph prediction. Importantly, this is achieved without imposing additional computational burden during the inference phase. Experimental results confirm that our method significantly enhances the performance of one-stage scene graph generation baselines.
</details>
<details>
<summary>摘要</summary>
场景图生成是自主 роботи系统的关键能力之一，但大多数现有方法受到背景复杂性的限制，导致它们无法完全解码环境的内在拓扑信息。此外，现有方法通常会忽略depth缺失信息，使其效果相对较差。为解决这些缺陷，我们提出了STDG方法，这是一种革新的深度导航一stage场景图生成方法。STDG方法的核心是一个自定义的三部分模块：深度导航HHA表示生成模块、深度导航 semi-教学网络学习模块和深度导航场景图生成模块。这三个模块共同利用深度信息，从depth信号生成到depth特征利用，最后预测场景图。与传统方法相比，STDG方法不需要在推理阶段添加计算负担。实验结果表明，我们的方法可以明显提高一stage场景图生成基线性能。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Resolution-Compression-and-Alignment-for-Efficient-Video-Classification-and-Retrieval"><a href="#Differentiable-Resolution-Compression-and-Alignment-for-Efficient-Video-Classification-and-Retrieval" class="headerlink" title="Differentiable Resolution Compression and Alignment for Efficient Video Classification and Retrieval"></a>Differentiable Resolution Compression and Alignment for Efficient Video Classification and Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08167">http://arxiv.org/abs/2309.08167</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dun-research/drca">https://github.com/dun-research/drca</a></li>
<li>paper_authors: Rui Deng, Qian Wu, Yuke Li, Haoran Fu</li>
<li>for: 提高视频推理效率，应对各种场景中的快速变化和细化要求。</li>
<li>methods: 提出一种高效的视频表示网络，通过不同分辨率层次进行压缩和对齐，从早期网络阶段减少计算成本，保持时间相关性。</li>
<li>results: 实验结果显示，我们的方法在靠近重复视频检索和动态视频分类中实现了最佳的效率和性能协议，与当前状态艺术方法相比。代码：<a target="_blank" rel="noopener" href="https://github.com/dun-research/DRCA%E3%80%82">https://github.com/dun-research/DRCA。</a><details>
<summary>Abstract</summary>
Optimizing video inference efficiency has become increasingly important with the growing demand for video analysis in various fields. Some existing methods achieve high efficiency by explicit discard of spatial or temporal information, which poses challenges in fast-changing and fine-grained scenarios. To address these issues, we propose an efficient video representation network with Differentiable Resolution Compression and Alignment mechanism, which compresses non-essential information in the early stage of the network to reduce computational costs while maintaining consistent temporal correlations. Specifically, we leverage a Differentiable Context-aware Compression Module to encode the saliency and non-saliency frame features, refining and updating the features into a high-low resolution video sequence. To process the new sequence, we introduce a new Resolution-Align Transformer Layer to capture global temporal correlations among frame features with different resolutions, while reducing spatial computation costs quadratically by utilizing fewer spatial tokens in low-resolution non-saliency frames. The entire network can be end-to-end optimized via the integration of the differentiable compression module. Experimental results show that our method achieves the best trade-off between efficiency and performance on near-duplicate video retrieval and competitive results on dynamic video classification compared to state-of-the-art methods. Code:https://github.com/dun-research/DRCA
</details>
<details>
<summary>摘要</summary>
优化视频推理效率已成为不断增长的需求，尤其是在各个领域中进行视频分析。现有的方法可以通过显式抛弃空间或时间信息来实现高效性，但是这会在快速变化和细腻场景中带来挑战。为解决这些问题，我们提出了一种高效的视频表示网络，具有差分分辨率压缩和对齐机制。具体来说，我们利用了差分上下文感知压缩模块来编码不同分辨率的帧特征，并将其更新和修正为一个高低分辨率视频序列。为处理新的序列，我们引入了一个新的分辨率对齐转换层，以捕捉不同分辨率帧特征之间的全局时间相关性，同时减少空间计算成本平方根。整个网络可以通过差分压缩模块的结合来进行端到端优化。实验结果表明，我们的方法可以在靠近重复视频检索和动态视频分类中实现最佳的效率和性能，并且与当前状态OFTHE-ART方法相比，实现了竞争的结果。代码：https://github.com/dun-research/DRCA
</details></li>
</ul>
<hr>
<h2 id="A-Ground-Segmentation-Method-Based-on-Point-Cloud-Map-for-Unstructured-Roads"><a href="#A-Ground-Segmentation-Method-Based-on-Point-Cloud-Map-for-Unstructured-Roads" class="headerlink" title="A Ground Segmentation Method Based on Point Cloud Map for Unstructured Roads"></a>A Ground Segmentation Method Based on Point Cloud Map for Unstructured Roads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08164">http://arxiv.org/abs/2309.08164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Li, Haiying Lin, Zhangyu Wang, Huazhi Li, Miao Yu, Jie Wang</li>
<li>for: 提高不结构化道路Scene中的地面分割精度</li>
<li>methods: 基于点云地图的方法，包括区域兴趣EXTRACTION、点云地图与实时点云的位域关联、基于 Gaussian Distribution 的背景模型 subtract</li>
<li>results: 实验结果显示，正确地面点分割率为 99.95%，运行时间为 26ms，与 state of the art 方法 Patchwork++ 相比，平均地面点分割精度提高 7.43%，运行时间增加 17ms。<details>
<summary>Abstract</summary>
Ground segmentation, as the basic task of unmanned intelligent perception, provides an important support for the target detection task. Unstructured road scenes represented by open-pit mines have irregular boundary lines and uneven road surfaces, which lead to segmentation errors in current ground segmentation methods. To solve this problem, a ground segmentation method based on point cloud map is proposed, which involves three parts: region of interest extraction, point cloud registration and background subtraction. Firstly, establishing boundary semantic associations to obtain regions of interest in unstructured roads. Secondly, establishing the location association between point cloud map and the real-time point cloud of region of interest by semantics information. Thirdly, establishing a background model based on Gaussian distribution according to location association, and segments the ground in real-time point cloud by the background substraction method. Experimental results show that the correct segmentation rate of ground points is 99.95%, and the running time is 26ms. Compared with state of the art ground segmentation algorithm Patchwork++, the average accuracy of ground point segmentation is increased by 7.43%, and the running time is increased by 17ms. Furthermore, the proposed method is practically applied to unstructured road scenarios represented by open pit mines.
</details>
<details>
<summary>摘要</summary>
地面 segmentation，作为无人智能感知的基本任务，对目标检测任务提供了重要支持。不结构的公路场景，如开采场，具有不规则边界线和不平的路面，这会导致当前地面 segmentation 方法中的segmentation error。为解决这个问题，一种基于点云地图的地面 segmentation 方法被提出，该方法包括三部分：region of interest 提取、点云注册和背景 subtract。首先，通过边界semantic association establishment obtain regions of interest in unstructured roads。其次，通过semantics information establishment的point cloud map和实时点云的区域兴趣点cloud association。最后，根据该association establishment Gaussian distributionbased background model，并在实时点云中对ground进行background subtract。实验结果显示，正确地面点的分割率为99.95%，运行时间为26ms。相比之前的state-of-the-art ground segmentation algorithm Patchwork++, average accuracy of ground point segmentation提高了7.43%，运行时间提高了17ms。此外，提出的方法实际应用于无结构公路场景中，如开采场。
</details></li>
</ul>
<hr>
<h2 id="Cross-Modal-Synthesis-of-Structural-MRI-and-Functional-Connectivity-Networks-via-Conditional-ViT-GANs"><a href="#Cross-Modal-Synthesis-of-Structural-MRI-and-Functional-Connectivity-Networks-via-Conditional-ViT-GANs" class="headerlink" title="Cross-Modal Synthesis of Structural MRI and Functional Connectivity Networks via Conditional ViT-GANs"></a>Cross-Modal Synthesis of Structural MRI and Functional Connectivity Networks via Conditional ViT-GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08160">http://arxiv.org/abs/2309.08160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuda Bi, Anees Abrol, Jing Sui, Vince Calhoun</li>
<li>for: 本研究旨在透过条件Vision Transformer生成数学模型（cViT-GAN）Synthesize functional network connectivity（FNC）数据，并分析其与 estructural magnetic resonance imaging（sMRI）之间的交互关系。</li>
<li>methods: 本研究使用cViT-GAN模型，将sMRI资料作为输入，生成各个subject的FNC数据，并形成每个subject的FNC矩阵。最后，我们得到了一个群体差FNC矩阵，与实际FNC矩阵之间的相関系数为0.73。</li>
<li>results: 我们的FNC可视化结果显示了特定的下来部分脑区域之间的相关性，显示了模型的能力将结构功能关系纳入考虑。此表现与 conditional CNN-based GAN alternatives如Pix2Pix不同，实现了模型的优化。<details>
<summary>Abstract</summary>
The cross-modal synthesis between structural magnetic resonance imaging (sMRI) and functional network connectivity (FNC) is a relatively unexplored area in medical imaging, especially with respect to schizophrenia. This study employs conditional Vision Transformer Generative Adversarial Networks (cViT-GANs) to generate FNC data based on sMRI inputs. After training on a comprehensive dataset that included both individuals with schizophrenia and healthy control subjects, our cViT-GAN model effectively synthesized the FNC matrix for each subject, and then formed a group difference FNC matrix, obtaining a Pearson correlation of 0.73 with the actual FNC matrix. In addition, our FNC visualization results demonstrate significant correlations in particular subcortical brain regions, highlighting the model's capability of capturing detailed structural-functional associations. This performance distinguishes our model from conditional CNN-based GAN alternatives such as Pix2Pix. Our research is one of the first attempts to link sMRI and FNC synthesis, setting it apart from other cross-modal studies that concentrate on T1- and T2-weighted MR images or the fusion of MRI and CT scans.
</details>
<details>
<summary>摘要</summary>
cross-modal合成 между结构磁共振成像(sMRI)和功能网络连接(FNC)是医学成像领域中相对未曾开探的领域，特别是在偏头痛方面。本研究使用条件视觉变换生成敌对网络(cViT-GANs)来生成基于sMRI输入的FNC数据。经过训练一个包括偏头痛和健康控制者的全面数据集后，我们的cViT-GAN模型成功生成了每个素个的FNC矩阵，然后组成了群差FNC矩阵，并 obtient了与实际FNC矩阵的Spearson相关系数0.73。此外，我们的FNC视觉结果显示了特定的下侧大脑区域之间的相关性，ILLUMINATING模型的能力捕捉细致的结构-功能关系。这种性能与 conditional CNN-based GAN的Pix2Pix相比， distinguishes our model。本研究是医学成像领域中首次将sMRI和FNC合成联系起来，与其他交叠Modal Studies的T1-和T2-束磁共振图像或MRI和CT扫描的融合相比，更加独特。
</details></li>
</ul>
<hr>
<h2 id="AdSEE-Investigating-the-Impact-of-Image-Style-Editing-on-Advertisement-Attractiveness"><a href="#AdSEE-Investigating-the-Impact-of-Image-Style-Editing-on-Advertisement-Attractiveness" class="headerlink" title="AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness"></a>AdSEE: Investigating the Impact of Image Style Editing on Advertisement Attractiveness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08159">http://arxiv.org/abs/2309.08159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liyaojiang1998/adsee">https://github.com/liyaojiang1998/adsee</a></li>
<li>paper_authors: Liyao Jiang, Chenglin Li, Haolan Chen, Xiaodong Gao, Xinwang Zhong, Yang Qiu, Shani Ye, Di Niu</li>
<li>for: 这个论文研究了在线广告的 clicked 率是否受到图像的语义编辑的影响。</li>
<li>methods: 该论文使用了 StyleGAN 技术进行语义编辑和反编辑，并使用了传统的视觉和文本特征来预测 clicked 率。</li>
<li>results: 该论文通过一个大量的 collected 数据集（QQ-AD）进行了广泛的 offline 测试，发现不同的语义方向和编辑强度可以影响 clicked 率。此外，该论文还设计了一个基于进化算法的广告编辑器，可以高效地搜索最佳的编辑方向和强度。在在线 A&#x2F;B 测试中，对于 AdSEE 编辑的样本，与控制组的原始广告相比， click-through 率得到了提高。<details>
<summary>Abstract</summary>
Online advertisements are important elements in e-commerce sites, social media platforms, and search engines. With the increasing popularity of mobile browsing, many online ads are displayed with visual information in the form of a cover image in addition to text descriptions to grab the attention of users. Various recent studies have focused on predicting the click rates of online advertisements aware of visual features or composing optimal advertisement elements to enhance visibility. In this paper, we propose Advertisement Style Editing and Attractiveness Enhancement (AdSEE), which explores whether semantic editing to ads images can affect or alter the popularity of online advertisements. We introduce StyleGAN-based facial semantic editing and inversion to ads images and train a click rate predictor attributing GAN-based face latent representations in addition to traditional visual and textual features to click rates. Through a large collected dataset named QQ-AD, containing 20,527 online ads, we perform extensive offline tests to study how different semantic directions and their edit coefficients may impact click rates. We further design a Genetic Advertisement Editor to efficiently search for the optimal edit directions and intensity given an input ad cover image to enhance its projected click rates. Online A/B tests performed over a period of 5 days have verified the increased click-through rates of AdSEE-edited samples as compared to a control group of original ads, verifying the relation between image styles and ad popularity. We open source the code for AdSEE research at https://github.com/LiyaoJiang1998/adsee.
</details>
<details>
<summary>摘要</summary>
在电子商务平台、社交媒体平台和搜索引擎上，在线广告是重要的元素。随着移动浏览的增加 popularity，许多在线广告将视觉信息显示为封面图片的形式，以吸引用户的注意。 Various recent studies have focused on predicting the click rates of online advertisements based on visual features or composing optimal advertisement elements to enhance visibility. In this paper, we propose Advertisement Style Editing and Attractiveness Enhancement (AdSEE), which explores whether semantic editing to ads images can affect or alter the popularity of online advertisements. We introduce StyleGAN-based facial semantic editing and inversion to ads images and train a click rate predictor attributing GAN-based face latent representations in addition to traditional visual and textual features to click rates. Through a large collected dataset named QQ-AD, containing 20,527 online ads, we perform extensive offline tests to study how different semantic directions and their edit coefficients may impact click rates. We further design a Genetic Advertisement Editor to efficiently search for the optimal edit directions and intensity given an input ad cover image to enhance its projected click rates. Online A/B tests performed over a period of 5 days have verified the increased click-through rates of AdSEE-edited samples as compared to a control group of original ads, verifying the relation between image styles and ad popularity. We open source the code for AdSEE research at <https://github.com/LiyaoJiang1998/adsee>.
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Aware-Multi-View-Visual-Semantic-Embedding"><a href="#Uncertainty-Aware-Multi-View-Visual-Semantic-Embedding" class="headerlink" title="Uncertainty-Aware Multi-View Visual Semantic Embedding"></a>Uncertainty-Aware Multi-View Visual Semantic Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08154">http://arxiv.org/abs/2309.08154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhang Wei, Zhipeng Gui, Changguang Wu, Anqi Zhao, Xingguang Wang, Huayi Wu</li>
<li>for:  This paper aims to improve image-text retrieval by leveraging semantic information and modeling uncertainty in multi-modal understanding.</li>
<li>methods:  The proposed Uncertainty-Aware Multi-View Visual Semantic Embedding (UAMVSE) framework decomposes the overall image-text matching into multiple view-text matchings and uses an uncertainty-aware loss function (UALoss) to adaptively model the uncertainty in each view-text correspondence.</li>
<li>results:  Experimental results on the Flicker30k and MS-COCO datasets demonstrate that UAMVSE outperforms state-of-the-art models.<details>
<summary>Abstract</summary>
The key challenge in image-text retrieval is effectively leveraging semantic information to measure the similarity between vision and language data. However, using instance-level binary labels, where each image is paired with a single text, fails to capture multiple correspondences between different semantic units, leading to uncertainty in multi-modal semantic understanding. Although recent research has captured fine-grained information through more complex model structures or pre-training techniques, few studies have directly modeled uncertainty of correspondence to fully exploit binary labels. To address this issue, we propose an Uncertainty-Aware Multi-View Visual Semantic Embedding (UAMVSE)} framework that decomposes the overall image-text matching into multiple view-text matchings. Our framework introduce an uncertainty-aware loss function (UALoss) to compute the weighting of each view-text loss by adaptively modeling the uncertainty in each view-text correspondence. Different weightings guide the model to focus on different semantic information, enhancing the model's ability to comprehend the correspondence of images and texts. We also design an optimized image-text matching strategy by normalizing the similarity matrix to improve model performance. Experimental results on the Flicker30k and MS-COCO datasets demonstrate that UAMVSE outperforms state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
“图像文本检索的关键挑战是有效地利用semantic信息来衡量视觉和语言数据之间的相似性。然而，使用实例级binary标签，其中每个图像与一个文本相对应，无法捕捉不同semantic单元之间的多重匹配关系，从而导致多modal semantic理解的uncertainty。虽然latest research捕捉了细腻信息通过更复杂的模型结构或预训练技术，但很少研究直接模型匹配不确定性，以全面利用binary标签。为解决这个问题，我们提出了一种Uncertainty-Aware Multi-View Visual Semantic Embedding（UAMVSE） frameworks，它将整个图像文本匹配分解成多个视图文本匹配。我们的 frameworks introduce一种uncertainty-aware损失函数（UALoss）来计算每个视图文本损失的权重，通过自适应地模型不确定性来computing each view-text correspondence的uncertainty。不同的权重导引模型更好地理解图像和文本之间的匹配关系，提高模型对多modal semantic理解的能力。我们还设计了一种优化图像文本匹配策略，通过normalizing similarity Matrix来提高模型性能。实验结果表明，UAMVSE在Flicker30k和MS-COCO数据集上超过了当前状态的模型性能。”
</details></li>
</ul>
<hr>
<h2 id="DA-RAW-Domain-Adaptive-Object-Detection-for-Real-World-Adverse-Weather-Conditions"><a href="#DA-RAW-Domain-Adaptive-Object-Detection-for-Real-World-Adverse-Weather-Conditions" class="headerlink" title="DA-RAW: Domain Adaptive Object Detection for Real-World Adverse Weather Conditions"></a>DA-RAW: Domain Adaptive Object Detection for Real-World Adverse Weather Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08152">http://arxiv.org/abs/2309.08152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsik Jeon, Junwon Seo, Jihong Min</li>
<li>for: 提高 object detection 方法在不良天气 condition 中的可靠性</li>
<li>methods: 使用 unsupervised domain adaptation 方法，分别处理 style 和 weather 两个领域的差异，以提高 object detection 的可靠性</li>
<li>results: 对比其他方法，本方法在不良天气 condition 下的 object detection 性能更高<details>
<summary>Abstract</summary>
Despite the success of deep learning-based object detection methods in recent years, it is still challenging to make the object detector reliable in adverse weather conditions such as rain and snow. For the robust performance of object detectors, unsupervised domain adaptation has been utilized to adapt the detection network trained on clear weather images to adverse weather images. While previous methods do not explicitly address weather corruption during adaptation, the domain gap between clear and adverse weather can be decomposed into two factors with distinct characteristics: a style gap and a weather gap. In this paper, we present an unsupervised domain adaptation framework for object detection that can more effectively adapt to real-world environments with adverse weather conditions by addressing these two gaps separately. Our method resolves the style gap by concentrating on style-related information of high-level features using an attention module. Using self-supervised contrastive learning, our framework then reduces the weather gap and acquires instance features that are robust to weather corruption. Extensive experiments demonstrate that our method outperforms other methods for object detection in adverse weather conditions.
</details>
<details>
<summary>摘要</summary>
尽管深度学习基于对象检测方法在最近几年内取得了成功，但是在雨雪等不利天气条件下，对象检测器的可靠性仍然是一个挑战。为了增强对象检测器的可靠性，不经过监督的领域适应已经被应用于适应天气图像。而前一些方法并没有直接面对气候腐败的影响，但是领域差异 между晴天和不利天气可以分解为两个因素，它们具有不同的特征。在这篇论文中，我们提出了一种不经过监督的领域适应框架，可以更有效地适应实际环境中的不利天气条件。我们解决了风格差异的问题，通过集中于高级特征的风格相关信息使用注意力模块。然后，我们使用自我监督对比学习，减少气候差异，获得抵抗气候腐败的实例特征。我们的方法在不利天气下进行对象检测的实验表明，与其他方法相比，我们的方法表现更加出色。
</details></li>
</ul>
<hr>
<h2 id="Syn-Att-Synthetic-Speech-Attribution-via-Semi-Supervised-Unknown-Multi-Class-Ensemble-of-CNNs"><a href="#Syn-Att-Synthetic-Speech-Attribution-via-Semi-Supervised-Unknown-Multi-Class-Ensemble-of-CNNs" class="headerlink" title="Syn-Att: Synthetic Speech Attribution via Semi-Supervised Unknown Multi-Class Ensemble of CNNs"></a>Syn-Att: Synthetic Speech Attribution via Semi-Supervised Unknown Multi-Class Ensemble of CNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08146">http://arxiv.org/abs/2309.08146</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/awsaf49/synatt">https://github.com/awsaf49/synatt</a></li>
<li>paper_authors: Md Awsafur Rahman, Bishmoy Paul, Najibul Haque Sarker, Zaber Ibn Abdul Hakim, Shaikh Anowarul Fattah, Mohammad Saquib</li>
<li>for: 本研究旨在对伪造的语音识别和推断伪造工具，以提高伪造语音识别和追溯的能力。</li>
<li>methods: 本研究提出了一种新的推理策略，将伪造语音轨变换为峰低 spectrogram，使用 CNN 提取特征，并使用 semi-supervision 和 ensemble 进行强化和普适化。</li>
<li>results: 本研究在 IEEE SP Cup 挑战中，以12-13%的精度优势在强 perturbed 数据集上（Eval 2），以及1-2%的精度优势在弱 perturbed 数据集上（Eval 1），与其他顶尖队伍相比表现出色。<details>
<summary>Abstract</summary>
With the huge technological advances introduced by deep learning in audio & speech processing, many novel synthetic speech techniques achieved incredible realistic results. As these methods generate realistic fake human voices, they can be used in malicious acts such as people imitation, fake news, spreading, spoofing, media manipulations, etc. Hence, the ability to detect synthetic or natural speech has become an urgent necessity. Moreover, being able to tell which algorithm has been used to generate a synthetic speech track can be of preeminent importance to track down the culprit. In this paper, a novel strategy is proposed to attribute a synthetic speech track to the generator that is used to synthesize it. The proposed detector transforms the audio into log-mel spectrogram, extracts features using CNN, and classifies it between five known and unknown algorithms, utilizing semi-supervision and ensemble to improve its robustness and generalizability significantly. The proposed detector is validated on two evaluation datasets consisting of a total of 18,000 weakly perturbed (Eval 1) & 10,000 strongly perturbed (Eval 2) synthetic speeches. The proposed method outperforms other top teams in accuracy by 12-13% on Eval 2 and 1-2% on Eval 1, in the IEEE SP Cup challenge at ICASSP 2022.
</details>
<details>
<summary>摘要</summary>
随着深度学习在音频和语音处理领域的大量技术进步，许多新的合成语音技术实现了不可思议的真实效果。这些方法可以生成真实的假人声音，因此可以用于有害的行为，如人类模仿、假新闻、散播、骗取、媒体操纵等。因此，可以准确地检测合成或自然语音的能力变得非常重要。此外，能够判断哪种算法生成了合成语音轨迹也是非常重要的。在本文中，一种新的策略是提出的，用于归因合成语音轨迹到生成它的算法。提议的检测器将音频转换为径向mel spectrogram，提取特征使用CNN，并将其分类为五个已知和未知算法，使用semi-supervision和ensemble以提高其可靠性和泛化性。提议的检测器在两个评估数据集上进行验证，包括18,000个弱地扰动（Eval 1）和10,000个强地扰动（Eval 2）合成语音。提议的方法在IEEE SP杯比赛中于ICASSP 2022年的评估中，与其他顶尖队伍相比，准确率高出12-13%（Eval 2）和1-2%（Eval 1）。
</details></li>
</ul>
<hr>
<h2 id="Multi-Scale-Estimation-for-Omni-Directional-Saliency-Maps-Using-Learnable-Equator-Bias"><a href="#Multi-Scale-Estimation-for-Omni-Directional-Saliency-Maps-Using-Learnable-Equator-Bias" class="headerlink" title="Multi-Scale Estimation for Omni-Directional Saliency Maps Using Learnable Equator Bias"></a>Multi-Scale Estimation for Omni-Directional Saliency Maps Using Learnable Equator Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08139">http://arxiv.org/abs/2309.08139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/islab-sophia/odisal">https://github.com/islab-sophia/odisal</a></li>
<li>paper_authors: Takao Yamanaka, Tatsuya Suzuki, Taiki Nobutsune, Chenjunlin Wu</li>
<li>for: 这 paper 用于 estimating 镜像中的焦点点 cloud，以便在头戴式显示器上探测重要的区域。</li>
<li>methods: 该 paper 提出了一种基于抽象2D图像的新的焦点映射估计模型，通过在不同的方向和视角下提取 overlap 2D 图像来实现。</li>
<li>results: 该 paper 的实验结果表明，使用该模型可以提高镜像中焦点点云的准确性。<details>
<summary>Abstract</summary>
Omni-directional images have been used in wide range of applications. For the applications, it would be useful to estimate saliency maps representing probability distributions of gazing points with a head-mounted display, to detect important regions in the omni-directional images. This paper proposes a novel saliency-map estimation model for the omni-directional images by extracting overlapping 2-dimensional (2D) plane images from omni-directional images at various directions and angles of view. While 2D saliency maps tend to have high probability at the center of images (center bias), the high-probability region appears at horizontal directions in omni-directional saliency maps when a head-mounted display is used (equator bias). Therefore, the 2D saliency model with a center-bias layer was fine-tuned with an omni-directional dataset by replacing the center-bias layer to an equator-bias layer conditioned on the elevation angle for the extraction of the 2D plane image. The limited availability of omni-directional images in saliency datasets can be compensated by using the well-established 2D saliency model pretrained by a large number of training images with the ground truth of 2D saliency maps. In addition, this paper proposes a multi-scale estimation method by extracting 2D images in multiple angles of view to detect objects of various sizes with variable receptive fields. The saliency maps estimated from the multiple angles of view were integrated by using pixel-wise attention weights calculated in an integration layer for weighting the optimal scale to each object. The proposed method was evaluated using a publicly available dataset with evaluation metrics for omni-directional saliency maps. It was confirmed that the accuracy of the saliency maps was improved by the proposed method.
</details>
<details>
<summary>摘要</summary>
全irectional图像在各种应用中使用，为这些应用，可以使用头戴式显示器来估算 gazing point 的抽象图像，以检测图像中重要的区域。本文提出了一种基于全irectional图像的新的抽象图像估算模型，通过提取不同方向和视角的2D平面图像来生成 omni-directional 图像的抽象图像。在使用头戴式显示器时，2D抽象图像的高概率区域往往出现在水平方向上（equator bias），而不是在图像中心（center bias）。因此，该文件提出了一种基于2D抽象图像的中心偏好层的修正方法，通过将中心偏好层替换为基于扬角的 equator-bias 层来提高 omni-directional 图像的抽象图像估算精度。由于 omni-directional 图像的数据匮乏，本文还提出了一种使用已有的2D抽象图像模型，通过大量的训练图像和相关的地平面抽象图像来练习该模型，从而补做数据的不足。此外，本文还提出了一种多比例估算方法，通过提取多个视角的2D图像来检测不同尺度的对象，并使用每个对象的变量感知权重来权重每个对象的估算结果。该方法被评估使用公共可用的数据集，并证实了其精度的提高。
</details></li>
</ul>
<hr>
<h2 id="Let’s-Roll-Synthetic-Dataset-Analysis-for-Pedestrian-Detection-Across-Different-Shutter-Types"><a href="#Let’s-Roll-Synthetic-Dataset-Analysis-for-Pedestrian-Detection-Across-Different-Shutter-Types" class="headerlink" title="Let’s Roll: Synthetic Dataset Analysis for Pedestrian Detection Across Different Shutter Types"></a>Let’s Roll: Synthetic Dataset Analysis for Pedestrian Detection Across Different Shutter Types</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08136">http://arxiv.org/abs/2309.08136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Hu, Gourav Datta, Kira Beerel, Peter Beerel</li>
<li>for: 本研究旨在检验不同闭着机制对机器学习对象检测模型的影响，以确定是否存在严重差异在检测精度方面。</li>
<li>methods: 本研究使用Unreal Engine 5进行了 sintetic数据生成，并对主流检测模型进行了训练和评估。</li>
<li>results: 研究结果表明，闭着机制对检测精度的影响存在差异，特别是在检测低速对象（如行人）时。在粗粒度检测精度方面（mAP&#x3D;0.5），闭着机制对检测模型的影响几乎无效，但在细粒度检测精度方面（mAP&#x3D;0.5:0.95）存在显著差异。这表明，ML管道可能不需要显式修正RS，但为了提高RS对象检测的精度，可能需要进行进一步的研究。<details>
<summary>Abstract</summary>
Computer vision (CV) pipelines are typically evaluated on datasets processed by image signal processing (ISP) pipelines even though, for resource-constrained applications, an important research goal is to avoid as many ISP steps as possible. In particular, most CV datasets consist of global shutter (GS) images even though most cameras today use a rolling shutter (RS). This paper studies the impact of different shutter mechanisms on machine learning (ML) object detection models on a synthetic dataset that we generate using the advanced simulation capabilities of Unreal Engine 5 (UE5). In particular, we train and evaluate mainstream detection models with our synthetically-generated paired GS and RS datasets to ascertain whether there exists a significant difference in detection accuracy between these two shutter modalities, especially when capturing low-speed objects (e.g., pedestrians). The results of this emulation framework indicate the performance between them are remarkably congruent for coarse-grained detection (mean average precision (mAP) for IOU=0.5), but have significant differences for fine-grained measures of detection accuracy (mAP for IOU=0.5:0.95). This implies that ML pipelines might not need explicit correction for RS for many object detection applications, but mitigating RS effects in ISP-less ML pipelines that target fine-grained location of the objects may need additional research.
</details>
<details>
<summary>摘要</summary>
计算机视觉（CV）流水线通常会被评估使用图像信号处理（ISP）流水线处理的数据集，尽管在资源有限的应用中，一个重要的研究目标是避免最多的ISP步骤。尤其是，大多数CV数据集都是全球闭缝（GS）图像，而今天的大多数相机都使用滚动闭缝（RS）。这篇论文研究了不同闭缝机制对机器学习（ML）对象检测模型的影响，使用我们自己生成的synthetic数据集，并在Unreal Engine 5（UE5）的高级模拟功能下进行了模拟。具体来说，我们使用生成的paired GS和RS数据集来训练和评估主流检测模型，以确定这两种闭缝模式之间的检测精度差异，特别是检测低速对象（如人行道）。结果表明，这两种闭缝模式之间的性能差异不大（ Mean Average Precision（mAP）为IOU=0.5），但是在细化检测精度指标（mAP为IOU=0.5：0.95）时有显著差异。这表明，ML管道可能不需要显式修正RS，但是为了实现细化对象检测应用，可能需要进行进一步的研究以避免RS的影响。
</details></li>
</ul>
<hr>
<h2 id="AnyOKP-One-Shot-and-Instance-Aware-Object-Keypoint-Extraction-with-Pretrained-ViT"><a href="#AnyOKP-One-Shot-and-Instance-Aware-Object-Keypoint-Extraction-with-Pretrained-ViT" class="headerlink" title="AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with Pretrained ViT"></a>AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with Pretrained ViT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08134">http://arxiv.org/abs/2309.08134</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangbo Qin, Taogang Hou, Shan Lin, Kaiyuan Wang, Michael C. Yip, Shan Yu</li>
<li>for: 这个研究旨在提出一种具有多物件类别和实例意识的一击式物点键点抽象方法（AnyOKP），用于实现灵活的物象视觉感知。</li>
<li>methods: 这个方法利用预训transformer（ViT）的强大表示能力，并可以从支持图片学习而获得键点。首先使用训练自动找到最佳原型对（BPPs），然后根据图片的出现相似性搜寻候选键点。最后，分解整个图形为不同物体实例的子图形。</li>
<li>results: 这个方法在实验中显示了跨类别和实例意识的优异性，并且具有传播和类别转换的优秀适应能力。<details>
<summary>Abstract</summary>
Towards flexible object-centric visual perception, we propose a one-shot instance-aware object keypoint (OKP) extraction approach, AnyOKP, which leverages the powerful representation ability of pretrained vision transformer (ViT), and can obtain keypoints on multiple object instances of arbitrary category after learning from a support image. An off-the-shelf petrained ViT is directly deployed for generalizable and transferable feature extraction, which is followed by training-free feature enhancement. The best-prototype pairs (BPPs) are searched for in support and query images based on appearance similarity, to yield instance-unaware candidate keypoints.Then, the entire graph with all candidate keypoints as vertices are divided to sub-graphs according to the feature distributions on the graph edges. Finally, each sub-graph represents an object instance. AnyOKP is evaluated on real object images collected with the cameras of a robot arm, a mobile robot, and a surgical robot, which not only demonstrates the cross-category flexibility and instance awareness, but also show remarkable robustness to domain shift and viewpoint change.
</details>
<details>
<summary>摘要</summary>
向flexible对象中心视觉进化，我们提出了一种一shot实例感知对象关键点（OKP）提取方法，AnyOKP，它利用预训练的视transformer（ViT）的强大表示能力，可以在学习支持图片后，从多个对象实例中提取关键点。 directly使用已经训练的ViT进行通用和转移的特征提取，然后通过无需训练的特征增强。在支持图片和查询图片中基于外观相似性搜索最佳原型对（BPPs），然后将整个图像的所有候选关键点作为顶点组织成图像，最终每个子图像表示一个对象实例。 AnyOKP在实际对象图像中进行了测试，不仅表现出了跨类弹性和实例意识，而且还具有了remarkable的领域变化和视点变化的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Increasing-diversity-of-omni-directional-images-generated-from-single-image-using-cGAN-based-on-MLPMixer"><a href="#Increasing-diversity-of-omni-directional-images-generated-from-single-image-using-cGAN-based-on-MLPMixer" class="headerlink" title="Increasing diversity of omni-directional images generated from single image using cGAN based on MLPMixer"></a>Increasing diversity of omni-directional images generated from single image using cGAN based on MLPMixer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08129">http://arxiv.org/abs/2309.08129</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/islab-sophia/odigen-mlpmixer">https://github.com/islab-sophia/odigen-mlpmixer</a></li>
<li>paper_authors: Atsuya Nakata, Ryuto Miyazaki, Takao Yamanaka</li>
<li>for: 这个论文提出了一种生成全向图像的新方法，该方法可以将单张图像转换成全向图像。</li>
<li>methods: 该方法使用了多层感知器（MLPMixer）来取代传统的生成对抗网络（CNN），MLPMixer可以更好地传递信息，从而提高生成的全向图像的多样性和质量。</li>
<li>results: 该方法可以减少内存占用和计算成本，同时保持与传统方法相当的性能水平，并且可以生成更多样化的全向图像。<details>
<summary>Abstract</summary>
This paper proposes a novel approach to generating omni-directional images from a single snapshot picture. The previous method has relied on the generative adversarial networks based on convolutional neural networks (CNN). Although this method has successfully generated omni-directional images, CNN has two drawbacks for this task. First, since a convolutional layer only processes a local area, it is difficult to propagate the information of an input snapshot picture embedded in the center of the omni-directional image to the edges of the image. Thus, the omni-directional images created by the CNN-based generator tend to have less diversity at the edges of the generated images, creating similar scene images. Second, the CNN-based model requires large video memory in graphics processing units due to the nature of the deep structure in CNN since shallow-layer networks only receives signals from a limited range of the receptive field. To solve these problems, MLPMixer-based method was proposed in this paper. The MLPMixer has been proposed as an alternative to the self-attention in the transformer, which captures long-range dependencies and contextual information. This enables to propagate information efficiently in the omni-directional image generation task. As a result, competitive performance has been achieved with reduced memory consumption and computational cost, in addition to increasing diversity of the generated omni-directional images.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:这篇论文提出了一种新的方法，用于从单一的Snapshot图片中生成全irectional图像。过去的方法都是基于生成对抗网络（GAN），但是这些方法有两个缺点。首先，Convolutional Neural Networks（CNN）在生成全irectional图像时，很难将中心位置的Snapshot图片信息传递到图像的边缘。因此，由CNN生成的全irectional图像中的边缘图像会更为相似。其次，CNN模型需要大量的图像处理器内存，这是因为CNN的深度结构会导致模型具有较大的计算量和内存占用。为解决这些问题，这篇论文提出了基于多层杂化（MLPMixer）的方法。MLPMixer可以 capture长距离依赖关系和Contextual信息，因此可以高效地传递信息在全irectional图像生成任务中。因此，该方法可以实现与传统方法相同的性能，同时减少内存占用量和计算量。此外，该方法还可以增加生成的全irectional图像的多样性。
</details></li>
</ul>
<hr>
<h2 id="MetaF2N-Blind-Image-Super-Resolution-by-Learning-Efficient-Model-Adaptation-from-Faces"><a href="#MetaF2N-Blind-Image-Super-Resolution-by-Learning-Efficient-Model-Adaptation-from-Faces" class="headerlink" title="MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces"></a>MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08113">http://arxiv.org/abs/2309.08113</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yinzhicun/metaf2n">https://github.com/yinzhicun/metaf2n</a></li>
<li>paper_authors: Zhicun Yin, Ming Liu, Xiaoming Li, Hui Yang, Longan Xiao, Wangmeng Zuo</li>
<li>for: 提高低品质图像的超解析表现</li>
<li>methods: 利用 faces 内容为模型进行 fine-tuning，避免了低品质图像生成和优化不确定性</li>
<li>results: 在实验中，MetaF2N 可以从一次 fine-tuning 中获得良好的表现，并且可以适应不同的自然图像环境<details>
<summary>Abstract</summary>
Due to their highly structured characteristics, faces are easier to recover than natural scenes for blind image super-resolution. Therefore, we can extract the degradation representation of an image from the low-quality and recovered face pairs. Using the degradation representation, realistic low-quality images can then be synthesized to fine-tune the super-resolution model for the real-world low-quality image. However, such a procedure is time-consuming and laborious, and the gaps between recovered faces and the ground-truths further increase the optimization uncertainty. To facilitate efficient model adaptation towards image-specific degradations, we propose a method dubbed MetaF2N, which leverages the contained Faces to fine-tune model parameters for adapting to the whole Natural image in a Meta-learning framework. The degradation extraction and low-quality image synthesis steps are thus circumvented in our MetaF2N, and it requires only one fine-tuning step to get decent performance. Considering the gaps between the recovered faces and ground-truths, we further deploy a MaskNet for adaptively predicting loss weights at different positions to reduce the impact of low-confidence areas. To evaluate our proposed MetaF2N, we have collected a real-world low-quality dataset with one or multiple faces in each image, and our MetaF2N achieves superior performance on both synthetic and real-world datasets. Source code, pre-trained models, and collected datasets are available at https://github.com/yinzhicun/MetaF2N.
</details>
<details>
<summary>摘要</summary>
由于 faces 的高度结构化特征，因此可以更容易地进行匿名图像超解像。我们可以从低质量和恢复的人脸对 extracted degradation representation。使用这个表示，我们可以生成高质量的匿名图像，以便为超解像模型进行 fine-tuning。但是，这种过程时间consuming 和劳动密集，并且差距 между recovered faces 和真实值更大，这会增加优化的uncertainty。为了快速和高效地适应图像特定的降低，我们提议一种方法 MetaF2N，它利用 faces 来微调模型参数，以适应整个自然图像。在这种Meta-学框架中，我们可以 circumvent 低质量图像生成和降低表示步骤，只需要一次微调。考虑到差距 между recovered faces 和真实值，我们进一步部署了一个 MaskNet 来适应性地预测不同位置的损失权重，以降低低信任区域的影响。为了评估我们提议的 MetaF2N，我们收集了一个真实世界的低质量图像集，并且我们的 MetaF2N 在这些 synthetic 和真实世界的集合上都达到了更高的性能。代码、预训练模型和收集到的数据都可以在 <https://github.com/yinzhicun/MetaF2N> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Detail-Reinforcement-Diffusion-Model-Augmentation-Fine-Grained-Visual-Categorization-in-Few-Shot-Conditions"><a href="#Detail-Reinforcement-Diffusion-Model-Augmentation-Fine-Grained-Visual-Categorization-in-Few-Shot-Conditions" class="headerlink" title="Detail Reinforcement Diffusion Model: Augmentation Fine-Grained Visual Categorization in Few-Shot Conditions"></a>Detail Reinforcement Diffusion Model: Augmentation Fine-Grained Visual Categorization in Few-Shot Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08097">http://arxiv.org/abs/2309.08097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianxu Wu, Shuo Ye, Shuhuang Chen, Qinmu Peng, Xinge You</li>
<li>for: Addressing the challenge of fine-grained visual categorization with limited data.</li>
<li>methods: Proposes a novel approach called the detail reinforcement diffusion model (DRDM), which leverages rich knowledge from large models for data augmentation and includes two key components: discriminative semantic recombination (DSR) and spatial knowledge reference (SKR).</li>
<li>results: Demonstrates improved performance for fine-grained visual recognition tasks through effective utilization of knowledge from large models, despite limited data availability.<details>
<summary>Abstract</summary>
The challenge in fine-grained visual categorization lies in how to explore the subtle differences between different subclasses and achieve accurate discrimination. Previous research has relied on large-scale annotated data and pre-trained deep models to achieve the objective. However, when only a limited amount of samples is available, similar methods may become less effective. Diffusion models have been widely adopted in data augmentation due to their outstanding diversity in data generation. However, the high level of detail required for fine-grained images makes it challenging for existing methods to be directly employed. To address this issue, we propose a novel approach termed the detail reinforcement diffusion model~(DRDM), which leverages the rich knowledge of large models for fine-grained data augmentation and comprises two key components including discriminative semantic recombination (DSR) and spatial knowledge reference~(SKR). Specifically, DSR is designed to extract implicit similarity relationships from the labels and reconstruct the semantic mapping between labels and instances, which enables better discrimination of subtle differences between different subclasses. Furthermore, we introduce the SKR module, which incorporates the distributions of different datasets as references in the feature space. This allows the SKR to aggregate the high-dimensional distribution of subclass features in few-shot FGVC tasks, thus expanding the decision boundary. Through these two critical components, we effectively utilize the knowledge from large models to address the issue of data scarcity, resulting in improved performance for fine-grained visual recognition tasks. Extensive experiments demonstrate the consistent performance gain offered by our DRDM.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:细化图像分类的挑战在于如何探索不同 subclass 之间的细微差异并实现精准分类。先前的研究通过大量标注数据和预训练深度模型来实现目标。但当只有有限的样本可用时，类似的方法可能变得 menos有效。增殖模型在数据生成方面具有出色的多样性，但是高级别的细化图像需要大量的样本来进行训练，这使得现有的方法难以直接采用。为解决这个问题，我们提出了一种新的方法，称为细化强化增殖模型~(DRDM)。DRDM 利用大模型中的丰富知识来进行细化数据增殖，并包括两个关键组件：推理 semantic recombination~(DSR) 和空间知识引用~(SKR)。特别是，DSR 设计用于从标签中提取隐式相似关系，并重建类标签和实例之间的semantic mapping，从而提高细化差异的探索。此外，我们引入 SKR 模块，该模块在特征空间中引入不同数据集的分布作为参考。这使得 SKR 能够在少数shot FGVC 任务中聚合高维度的 subclass 特征分布，从而扩大决策边界。通过这两个关键组件，我们有效地利用大模型中的知识来解决数据稀缺性的问题，从而提高细化图像认知任务的性能。广泛的实验表明我们的 DRDM 具有稳定的性能提升。
</details></li>
</ul>
<hr>
<h2 id="hear-your-action-human-action-recognition-by-ultrasound-active-sensing"><a href="#hear-your-action-human-action-recognition-by-ultrasound-active-sensing" class="headerlink" title="hear-your-action: human action recognition by ultrasound active sensing"></a>hear-your-action: human action recognition by ultrasound active sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08087">http://arxiv.org/abs/2309.08087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Risako Tanigawa, Yasunori Ishii</li>
<li>for: 本研究旨在提出一种隐私保护的动作识别方法，使得通过视觉信息获取动作识别结果时，不会泄露用户的隐私信息。</li>
<li>methods: 本研究使用ultrasound active sensing技术进行动作识别，并创建了一个新的数据集来支持这种方法。研究人员计算了时间变化的声波反射波的强度特征值，并使用支持向量机和VGG进行分类。</li>
<li>results: 研究人员在同一个人和同一个环境下训练和测试时，达到了97.9%的准确率。此外，研究人员还对不同人进行训练和测试，并达到了89.5%的准确率。研究人员还进行了不同条件下的准确率分析和限制。<details>
<summary>Abstract</summary>
Action recognition is a key technology for many industrial applications. Methods using visual information such as images are very popular. However, privacy issues prevent widespread usage due to the inclusion of private information, such as visible faces and scene backgrounds, which are not necessary for recognizing user action. In this paper, we propose a privacy-preserving action recognition by ultrasound active sensing. As action recognition from ultrasound active sensing in a non-invasive manner is not well investigated, we create a new dataset for action recognition and conduct a comparison of features for classification. We calculated feature values by focusing on the temporal variation of the amplitude of ultrasound reflected waves and performed classification using a support vector machine and VGG for eight fundamental action classes. We confirmed that our method achieved an accuracy of 97.9% when trained and evaluated on the same person and in the same environment. Additionally, our method achieved an accuracy of 89.5% even when trained and evaluated on different people. We also report the analyses of accuracies in various conditions and limitations.
</details>
<details>
<summary>摘要</summary>
《动作识别是许多工业应用中的关键技术。图像信息的方法非常受欢迎，但是隐私问题限制了广泛的使用，因为图像中包含私人信息，如可见的脸和场景背景，这些信息不是必需的 для识别用户动作。在本文中，我们提出了一种隐私保护的动作识别方法，基于ultrasound活动感测。由于从ultrasound活动感测中得到动作识别的非侵入性方法未得到广泛的研究，我们创建了一个新的数据集，并进行了不同的特征比较。我们计算了时间变化的ultrasound反射波的幅值，并使用支持向量机和VGG进行分类。我们确认了我们的方法在同一个人和同一个环境中获得了97.9%的准确率，而且我们的方法在不同的人和环境中也获得了89.5%的准确率。此外，我们还报告了不同情况下的准确率分析和限制。》Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/15/cs.CV_2023_09_15/" data-id="clp89doda00jpi7884po87nby" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/15/cs.AI_2023_09_15/" class="article-date">
  <time datetime="2023-09-15T12:00:00.000Z" itemprop="datePublished">2023-09-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/15/cs.AI_2023_09_15/">cs.AI - 2023-09-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="URA-Uncertainty-aware-Path-Planning-using-Image-based-Aerial-to-Ground-Traversability-Estimation-for-Off-road-Environments"><a href="#URA-Uncertainty-aware-Path-Planning-using-Image-based-Aerial-to-Ground-Traversability-Estimation-for-Off-road-Environments" class="headerlink" title="URA*: Uncertainty-aware Path Planning using Image-based Aerial-to-Ground Traversability Estimation for Off-road Environments"></a>URA*: Uncertainty-aware Path Planning using Image-based Aerial-to-Ground Traversability Estimation for Off-road Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08814">http://arxiv.org/abs/2309.08814</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shaswata09/offroad-path-planning">https://github.com/shaswata09/offroad-path-planning</a></li>
<li>paper_authors: Charles Moore, Shaswata Mitra, Nisha Pillai, Marc Moore, Sudip Mittal, Cindy Bethel, Jingdao Chen</li>
<li>for: 提高自动驾驶车辆在非公路环境中的导航能力，即使环境不具备明确的地图或路标。</li>
<li>methods: 使用空中图像 ensemble convolutional neural network (CNN) 模型进行像素级游离性预测，并使用不确定性意识的规划算法计算基于这些不纯净的游离性预测值的最佳路径。</li>
<li>results: 在马萨诸塞路数据集、深度 globeb 数据集以及密西西比州大学的非公路试验场上评估了提案的图像分割和规划方法，结果显示，提案的方法在初始路径质量和在线机器人运行中的重新规划能力方面卓越于传统规划算法。<details>
<summary>Abstract</summary>
A major challenge with off-road autonomous navigation is the lack of maps or road markings that can be used to plan a path for autonomous robots. Classical path planning methods mostly assume a perfectly known environment without accounting for the inherent perception and sensing uncertainty from detecting terrain and obstacles in off-road environments. Recent work in computer vision and deep neural networks has advanced the capability of terrain traversability segmentation from raw images; however, the feasibility of using these noisy segmentation maps for navigation and path planning has not been adequately explored. To address this problem, this research proposes an uncertainty-aware path planning method, URA* using aerial images for autonomous navigation in off-road environments. An ensemble convolutional neural network (CNN) model is first used to perform pixel-level traversability estimation from aerial images of the region of interest. The traversability predictions are represented as a grid of traversal probability values. An uncertainty-aware planner is then applied to compute the best path from a start point to a goal point given these noisy traversal probability estimates. The proposed planner also incorporates replanning techniques to allow rapid replanning during online robot operation. The proposed method is evaluated on the Massachusetts Road Dataset, the DeepGlobe dataset, as well as a dataset of aerial images from off-road proving grounds at Mississippi State University. Results show that the proposed image segmentation and planning methods outperform conventional planning algorithms in terms of the quality and feasibility of the initial path, as well as the quality of replanned paths.
</details>
<details>
<summary>摘要</summary>
寻路自主导航在非公路环境中存在一个主要挑战，即缺乏地图或路标，可以用来规划自主机器人的路径。传统的寻路规划方法大多假设环境是完全知道的，而不考虑探测地形和障碍物时的感知和探测不确定性。现代计算机视觉和深度神经网络技术已经提高了从照片中提取地形可行性分割的能力，但是使用这些不稳定的分割图来 Navigation and path planning has not been fully explored. To address this problem, this research proposes an uncertainty-aware path planning method, URA* using aerial images for autonomous navigation in off-road environments. An ensemble convolutional neural network (CNN) model is first used to perform pixel-level traversability estimation from aerial images of the region of interest. The traversability predictions are represented as a grid of traversal probability values. An uncertainty-aware planner is then applied to compute the best path from a start point to a goal point given these noisy traversal probability estimates. The proposed planner also incorporates replanning techniques to allow rapid replanning during online robot operation. The proposed method is evaluated on the Massachusetts Road Dataset, the DeepGlobe dataset, as well as a dataset of aerial images from off-road proving grounds at Mississippi State University. Results show that the proposed image segmentation and planning methods outperform conventional planning algorithms in terms of the quality and feasibility of the initial path, as well as the quality of replanned paths.
</details></li>
</ul>
<hr>
<h2 id="SHAPNN-Shapley-Value-Regularized-Tabular-Neural-Network"><a href="#SHAPNN-Shapley-Value-Regularized-Tabular-Neural-Network" class="headerlink" title="SHAPNN: Shapley Value Regularized Tabular Neural Network"></a>SHAPNN: Shapley Value Regularized Tabular Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08799">http://arxiv.org/abs/2309.08799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qisen Cheng, Shuhui Qu, Janghwan Lee</li>
<li>for: 这篇论文是为了提出一种新的深度表格数据模型化架构，用于超级vised学习。</li>
<li>methods: 该方法使用了Shapley值，一种已有的解释黑盒模型的技术，并通过标准的反向传播优化方法来训练神经网络。</li>
<li>results: 该方法可以提供有效的解释，不带计算负担，对数据实例和数据集都适用。此外，预测与解释服务为训练提供了一种正则化，提高模型的性能。此外，正则化预测还提高了模型的持续学习能力。在各种公开数据集上进行了比较，SHAPNN在AUROC、透明度和流动数据Robustness等方面表现出色。<details>
<summary>Abstract</summary>
We present SHAPNN, a novel deep tabular data modeling architecture designed for supervised learning. Our approach leverages Shapley values, a well-established technique for explaining black-box models. Our neural network is trained using standard backward propagation optimization methods, and is regularized with realtime estimated Shapley values. Our method offers several advantages, including the ability to provide valid explanations with no computational overhead for data instances and datasets. Additionally, prediction with explanation serves as a regularizer, which improves the model's performance. Moreover, the regularized prediction enhances the model's capability for continual learning. We evaluate our method on various publicly available datasets and compare it with state-of-the-art deep neural network models, demonstrating the superior performance of SHAPNN in terms of AUROC, transparency, as well as robustness to streaming data.
</details>
<details>
<summary>摘要</summary>
我们提出了SHAPNN，一种新的深度表格数据建模架构，适用于指导学习。我们的方法利用了Shapley值，已经广泛应用于解释黑盒模型的技术。我们的神经网络通过标准的反向传播优化方法进行训练，并通过实时估算的Shapley值进行规regularization。我们的方法具有许多优势，包括无计算 overhead的数据实例和数据集解释能力，预测与解释服务为评估器，提高模型性能，以及对流动数据的强化。我们对多个公开的数据集进行了评估，并与现有的深度神经网络模型进行了比较，demonstrating SHAPNN在AUROC、透明度和流动数据的稳定性方面的超越性。
</details></li>
</ul>
<hr>
<h2 id="D3-Data-Diversity-Design-for-Systematic-Generalization-in-Visual-Question-Answering"><a href="#D3-Data-Diversity-Design-for-Systematic-Generalization-in-Visual-Question-Answering" class="headerlink" title="D3: Data Diversity Design for Systematic Generalization in Visual Question Answering"></a>D3: Data Diversity Design for Systematic Generalization in Visual Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08798">http://arxiv.org/abs/2309.08798</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amiroor/d3questiongenerationclevr">https://github.com/amiroor/d3questiongenerationclevr</a></li>
<li>paper_authors: Amir Rahimi, Vanessa D’Amario, Moyuru Yamada, Kentaro Takemoto, Tomotake Sasaki, Xavier Boix</li>
<li>for: This paper is written to investigate the role of data diversity in achieving systematic generalization in Visual Question Answering (VQA) tasks.</li>
<li>methods: The paper uses a combination of simple tasks and neural network architectures to study the effect of data diversity on systematic generalization.</li>
<li>results: The paper finds that the diversity of simple tasks is a key factor in achieving systematic generalization, and that neural module networks are better able to leverage all forms of data diversity than monolithic architectures.<details>
<summary>Abstract</summary>
Systematic generalization is a crucial aspect of intelligence, which refers to the ability to generalize to novel tasks by combining known subtasks and concepts. One critical factor that has been shown to influence systematic generalization is the diversity of training data. However, diversity can be defined in various ways, as data have many factors of variation. A more granular understanding of how different aspects of data diversity affect systematic generalization is lacking. We present new evidence in the problem of Visual Question Answering (VQA) that reveals that the diversity of simple tasks (i.e. tasks formed by a few subtasks and concepts) plays a key role in achieving systematic generalization. This implies that it may not be essential to gather a large and varied number of complex tasks, which could be costly to obtain. We demonstrate that this result is independent of the similarity between the training and testing data and applies to well-known families of neural network architectures for VQA (i.e. monolithic architectures and neural module networks). Additionally, we observe that neural module networks leverage all forms of data diversity we evaluated, while monolithic architectures require more extensive amounts of data to do so. These findings provide a first step towards understanding the interactions between data diversity design, neural network architectures, and systematic generalization capabilities.
</details>
<details>
<summary>摘要</summary>
系统化总结是智能的关键方面，它指的是将已知的子任务和概念结合起来应对新任务。一个重要的因素是训练数据的多样性，但是多样性的定义可以有多种方式。我们没有充分理解不同方面的数据多样性如何影响系统化总结。我们在视觉问答任务（VQA）中提供新的证据，显示了简单任务的多样性对系统化总结的关键作用。这意味着可能不需要收集大量和多样化的复杂任务，这些任务可能是成本高的获取。我们证明这结果不виси于训练和测试数据的相似性，并适用于常见的 neural network 架构（i.e. 单一架构和神经模块网络）。此外，我们发现神经模块网络可以利用我们评估的所有多样性，而单一架构则需要更多的数据来做到这一点。这些发现为我们理解数据多样性设计、神经网络架构和系统化总结能力之间的交互关系提供了一个第一步。
</details></li>
</ul>
<hr>
<h2 id="Privacy-preserving-Early-Detection-of-Epileptic-Seizures-in-Videos"><a href="#Privacy-preserving-Early-Detection-of-Epileptic-Seizures-in-Videos" class="headerlink" title="Privacy-preserving Early Detection of Epileptic Seizures in Videos"></a>Privacy-preserving Early Detection of Epileptic Seizures in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08794">http://arxiv.org/abs/2309.08794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DevD1092/seizure-detection">https://github.com/DevD1092/seizure-detection</a></li>
<li>paper_authors: Deval Mehta, Shobi Sivathamboo, Hugh Simpson, Patrick Kwan, Terence O&#96;Brien, Zongyuan Ge</li>
<li>for: 这 paper 的目的是开发一种隐私保护的视频 Epilepsy 病发识别方法。</li>
<li>methods: 该方法使用了 optical flow 特征从 Epilepsy 病发视频中提取信息，并利用 transformer 基于进行逐步知识储存，从而保持隐私。</li>
<li>results: 该方法可以在 Privacy-preserving 的情况下，准确地检测 TCS 病发，其准确率为 83.9%。In English:</li>
<li>for: The purpose of this paper is to develop a privacy-preserving video-based epileptic seizure classification method.</li>
<li>methods: The method uses optical flow features extracted from epileptic seizure videos and utilizes a transformer-based progressive knowledge distillation to preserve privacy.</li>
<li>results: The method can accurately detect tonic-clonic seizures (TCSs) in a privacy-preserving manner, with an accuracy of 83.9%.<details>
<summary>Abstract</summary>
In this work, we contribute towards the development of video-based epileptic seizure classification by introducing a novel framework (SETR-PKD), which could achieve privacy-preserved early detection of seizures in videos. Specifically, our framework has two significant components - (1) It is built upon optical flow features extracted from the video of a seizure, which encodes the seizure motion semiotics while preserving the privacy of the patient; (2) It utilizes a transformer based progressive knowledge distillation, where the knowledge is gradually distilled from networks trained on a longer portion of video samples to the ones which will operate on shorter portions. Thus, our proposed framework addresses the limitations of the current approaches which compromise the privacy of the patients by directly operating on the RGB video of a seizure as well as impede real-time detection of a seizure by utilizing the full video sample to make a prediction. Our SETR-PKD framework could detect tonic-clonic seizures (TCSs) in a privacy-preserving manner with an accuracy of 83.9% while they are only half-way into their progression. Our data and code is available at https://github.com/DevD1092/seizure-detection
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们贡献了视频基于癫痫病发迹的分类发展，通过引入一种新的框架（SETR-PKD），实现了隐私保护的早期发现癫痫病发。 Specifically，我们的框架有两个重要组成部分：（1）基于视频中癫痫病发动的Optical flow特征提取，这些特征可以储存癫痫病发动的semiotics，同时保护病人的隐私;（2）使用基于转换器的进行进行逐步知识储存，其中知识从网络训练在更长的视频批处理中进行储存，然后逐步储存到短视频批处理中。因此，我们的提出的SETR-PKD框架可以在隐私保护的情况下，将癫痫病发迹推断到83.9%的准确率，而这些癫痫病发迹只有在进程中的半段。我们的数据和代码可以在https://github.com/DevD1092/seizure-detection上获取。
</details></li>
</ul>
<hr>
<h2 id="Fin-Fact-A-Benchmark-Dataset-for-Multimodal-Financial-Fact-Checking-and-Explanation-Generation"><a href="#Fin-Fact-A-Benchmark-Dataset-for-Multimodal-Financial-Fact-Checking-and-Explanation-Generation" class="headerlink" title="Fin-Fact: A Benchmark Dataset for Multimodal Financial Fact Checking and Explanation Generation"></a>Fin-Fact: A Benchmark Dataset for Multimodal Financial Fact Checking and Explanation Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08793">http://arxiv.org/abs/2309.08793</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iit-dm/fin-fact">https://github.com/iit-dm/fin-fact</a></li>
<li>paper_authors: Aman Rangapur, Haoran Wang, Kai Shu</li>
<li>for: 这篇论文旨在提供一个Multimodal Fact-Checking数据集，用于combating misinformation in finance，提高金融报道和新闻传递的可靠性。</li>
<li>methods: 该论文使用了专业 fact-checker 的标注和解释，以及多Modal的内容，包括文本和视觉内容，以提高事实检查的准确性。</li>
<li>results: 该论文提供了一个名为 Fin-Fact 的数据集，包括专业 fact-checker 的标注和解释，以及多Modal的内容，可以帮助用户更好地理解事实检查的决策理由，提高事实检查的可靠性。<details>
<summary>Abstract</summary>
Fact-checking in financial domain is under explored, and there is a shortage of quality dataset in this domain. In this paper, we propose Fin-Fact, a benchmark dataset for multimodal fact-checking within the financial domain. Notably, it includes professional fact-checker annotations and justifications, providing expertise and credibility. With its multimodal nature encompassing both textual and visual content, Fin-Fact provides complementary information sources to enhance factuality analysis. Its primary objective is combating misinformation in finance, fostering transparency, and building trust in financial reporting and news dissemination. By offering insightful explanations, Fin-Fact empowers users, including domain experts and end-users, to understand the reasoning behind fact-checking decisions, validating claim credibility, and fostering trust in the fact-checking process. The Fin-Fact dataset, along with our experimental codes is available at https://github.com/IIT-DM/Fin-Fact/.
</details>
<details>
<summary>摘要</summary>
Fact-checking in the financial domain is under-explored, and there is a shortage of high-quality datasets in this domain. In this paper, we propose Fin-Fact, a benchmark dataset for multimodal fact-checking within the financial domain. Notably, it includes professional fact-checker annotations and justifications, providing expertise and credibility. With its multimodal nature encompassing both textual and visual content, Fin-Fact provides complementary information sources to enhance factuality analysis. Its primary objective is to combat misinformation in finance, promote transparency, and build trust in financial reporting and news dissemination. By offering insightful explanations, Fin-Fact empowers users, including domain experts and end-users, to understand the reasoning behind fact-checking decisions, validate claim credibility, and foster trust in the fact-checking process. The Fin-Fact dataset, along with our experimental codes, is available at <https://github.com/IIT-DM/Fin-Fact/>.
</details></li>
</ul>
<hr>
<h2 id="Projected-Task-Specific-Layers-for-Multi-Task-Reinforcement-Learning"><a href="#Projected-Task-Specific-Layers-for-Multi-Task-Reinforcement-Learning" class="headerlink" title="Projected Task-Specific Layers for Multi-Task Reinforcement Learning"></a>Projected Task-Specific Layers for Multi-Task Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08776">http://arxiv.org/abs/2309.08776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/josselinsomervilleroberts/ptsl">https://github.com/josselinsomervilleroberts/ptsl</a></li>
<li>paper_authors: Josselin Somerville Roberts, Julia Di</li>
<li>for: 这篇论文是为了探讨多任务强化学习如何帮助机器人在家居和办公室中扩展多种操作任务。</li>
<li>methods: 该论文提出了一种新的架构，即 Projected Task-Specific Layers (PTSL)，它使用公共策略和密集任务特定更正来更好地表达共享和变量任务信息。</li>
<li>results: 论文表明，PTSL模型在Meta-World benchmark上的MT10和MT50测试集上比现有的状态arius方法表现出色，为一个Sawyer机械臂完成了10和50个目标conditioned任务。<details>
<summary>Abstract</summary>
Multi-task reinforcement learning could enable robots to scale across a wide variety of manipulation tasks in homes and workplaces. However, generalizing from one task to another and mitigating negative task interference still remains a challenge. Addressing this challenge by successfully sharing information across tasks will depend on how well the structure underlying the tasks is captured. In this work, we introduce our new architecture, Projected Task-Specific Layers (PTSL), that leverages a common policy with dense task-specific corrections through task-specific layers to better express shared and variable task information. We then show that our model outperforms the state of the art on the MT10 and MT50 benchmarks of Meta-World consisting of 10 and 50 goal-conditioned tasks for a Sawyer arm.
</details>
<details>
<summary>摘要</summary>
多任务强化学习可以让机器人在家庭和办公室中扩展到各种抓取任务。然而，从一个任务到另一个任务的泛化和消除负面任务干扰仍然是挑战。我们认为，如果可以成功共享任务之间的信息，那么解决这一挑战就取决于任务结构的捕捉程度。在这篇文章中，我们介绍了我们的新架构，即项目化任务特定层（PTSL），它利用共享策略和密集任务特定修正来更好地表达共享和变量任务信息。我们然后证明，我们的模型在Meta-World的MT10和MT50标准准的10和50个目标决策任务中表现出色，超过了现有的状态艺术。
</details></li>
</ul>
<hr>
<h2 id="Enhance-audio-generation-controllability-through-representation-similarity-regularization"><a href="#Enhance-audio-generation-controllability-through-representation-similarity-regularization" class="headerlink" title="Enhance audio generation controllability through representation similarity regularization"></a>Enhance audio generation controllability through representation similarity regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08773">http://arxiv.org/abs/2309.08773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangyang Shi, Gael Le Lan, Varun Nagaraja, Zhaoheng Ni, Xinhao Mei, Ernie Chang, Forrest Iandola, Yang Liu, Vikas Chandra</li>
<li>for: 这个论文目的是提高语音生成的控制，使语音和文本表示之间更加一致。</li>
<li>methods: 这个论文使用了语音和文本token表示的整合，并在CFG阶段引入了表示规范，以避免语音和文本之间的差异。</li>
<li>results: 实验结果表明，该方法可以提高对audio和music生成的对象指标，以及人类对audio生成的感知。<details>
<summary>Abstract</summary>
This paper presents an innovative approach to enhance control over audio generation by emphasizing the alignment between audio and text representations during model training. In the context of language model-based audio generation, the model leverages input from both textual and audio token representations to predict subsequent audio tokens. However, the current configuration lacks explicit regularization to ensure the alignment between the chosen text representation and the language model's predictions. Our proposal involves the incorporation of audio and text representation regularization, particularly during the classifier-free guidance (CFG) phase, where the text condition is excluded from cross attention during language model training. The aim of this proposed representation regularization is to minimize discrepancies in audio and text similarity compared to other samples within the same training batch. Experimental results on both music and audio generation tasks demonstrate that our proposed methods lead to improvements in objective metrics for both audio and music generation, as well as an enhancement in the human perception for audio generation.
</details>
<details>
<summary>摘要</summary>
Our proposed method involves adding regularization to the audio and text representations, particularly during the classifier-free guidance (CFG) phase, where the text condition is excluded from cross attention during language model training. The goal of this regularization is to minimize the differences in audio and text similarity compared to other samples within the same training batch.Experimental results on both music and audio generation tasks show that our proposed methods lead to improvements in objective metrics for both audio and music generation, as well as an enhancement in human perception for audio generation.Translation notes:* "audio generation" is translated as "音频生成" (yīn yuè shēng chéng)* "text representation" is translated as "文本表示" (wén tè biǎo yì)* "audio token" is translated as "音频符" (yīn yuè fú)* "classifier-free guidance" is translated as "无类别指导" (wú lè bèi zhǐ dào)* "CFG phase" is translated as "CFG阶段" (CFG jiè dàn)Please note that the translation is in Simplified Chinese, and the word order may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Cross-Domain-Pedestrian-Detection-A-Background-Focused-Distribution-Alignment-Framework-for-Instance-Free-One-Stage-Detectors"><a href="#Rethinking-Cross-Domain-Pedestrian-Detection-A-Background-Focused-Distribution-Alignment-Framework-for-Instance-Free-One-Stage-Detectors" class="headerlink" title="Rethinking Cross-Domain Pedestrian Detection: A Background-Focused Distribution Alignment Framework for Instance-Free One-Stage Detectors"></a>Rethinking Cross-Domain Pedestrian Detection: A Background-Focused Distribution Alignment Framework for Instance-Free One-Stage Detectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08771">http://arxiv.org/abs/2309.08771</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caiyancheng/bfda">https://github.com/caiyancheng/bfda</a></li>
<li>paper_authors: Yancheng Cai, Bo Zhang, Baopu Li, Tao Chen, Hongliang Yan, Jingdong Zhang, Jiahao Xu</li>
<li>for: 这个研究旨在将步行人检测器从一个标签丰富的领域扩展到另一个标签缺乏的领域，以应对实际应用中的问题。</li>
<li>methods: 这篇研究使用了领域调整的方法，将领域整合到执行阶段，并且将执行阶段的整合与实际应用中的一阶段检测器结合起来。</li>
<li>results: 这篇研究提出了一个名为“背景注重分布对齐”（BFDA）的新框架，用于训练领域适应的一阶段检测器。BFDA首先将背景特征分离出来，然后使用一种新的长Short识别子来对背景特征进行对齐。<details>
<summary>Abstract</summary>
Cross-domain pedestrian detection aims to generalize pedestrian detectors from one label-rich domain to another label-scarce domain, which is crucial for various real-world applications. Most recent works focus on domain alignment to train domain-adaptive detectors either at the instance level or image level. From a practical point of view, one-stage detectors are faster. Therefore, we concentrate on designing a cross-domain algorithm for rapid one-stage detectors that lacks instance-level proposals and can only perform image-level feature alignment. However, pure image-level feature alignment causes the foreground-background misalignment issue to arise, i.e., the foreground features in the source domain image are falsely aligned with background features in the target domain image. To address this issue, we systematically analyze the importance of foreground and background in image-level cross-domain alignment, and learn that background plays a more critical role in image-level cross-domain alignment. Therefore, we focus on cross-domain background feature alignment while minimizing the influence of foreground features on the cross-domain alignment stage. This paper proposes a novel framework, namely, background-focused distribution alignment (BFDA), to train domain adaptive onestage pedestrian detectors. Specifically, BFDA first decouples the background features from the whole image feature maps and then aligns them via a novel long-short-range discriminator.
</details>
<details>
<summary>摘要</summary>
cross-domain pedestrian detection aim to generalize pedestrian detectors from one label-rich domain to another label-scarce domain, which is crucial for various real-world applications. Most recent works focus on domain alignment to train domain-adaptive detectors either at the instance level or image level. From a practical point of view, one-stage detectors are faster. Therefore, we concentrate on designing a cross-domain algorithm for rapid one-stage detectors that lacks instance-level proposals and can only perform image-level feature alignment. However, pure image-level feature alignment causes the foreground-background misalignment issue to arise, i.e., the foreground features in the source domain image are falsely aligned with background features in the target domain image. To address this issue, we systematically analyze the importance of foreground and background in image-level cross-domain alignment, and learn that background plays a more critical role in image-level cross-domain alignment. Therefore, we focus on cross-domain background feature alignment while minimizing the influence of foreground features on the cross-domain alignment stage. This paper proposes a novel framework, namely, background-focused distribution alignment (BFDA), to train domain adaptive one-stage pedestrian detectors. Specifically, BFDA first decouples the background features from the whole image feature maps and then aligns them via a novel long-short-range discriminator.
</details></li>
</ul>
<hr>
<h2 id="AlbNER-A-Corpus-for-Named-Entity-Recognition-in-Albanian"><a href="#AlbNER-A-Corpus-for-Named-Entity-Recognition-in-Albanian" class="headerlink" title="AlbNER: A Corpus for Named Entity Recognition in Albanian"></a>AlbNER: A Corpus for Named Entity Recognition in Albanian</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08741">http://arxiv.org/abs/2309.08741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erion Çano</li>
<li>for: 这篇论文是为了解决 Albanian 语言的自然语言处理和计算语言学研究中的资源短缺问题而写的。</li>
<li>methods: 该论文使用了 Albanian Wikipedia 文章中的 900 句话，并对其进行了标注名实体处理。</li>
<li>results: 根据BERT和RoBERTa变体在 AlbNER 数据上进行了微调和测试，结果显示，模型大小对 NER 性能有轻微的影响，而语言传递却有显著的影响。 AlbNER 数据集和这些结果可以作为未来实验的基线。<details>
<summary>Abstract</summary>
Scarcity of resources such as annotated text corpora for under-resourced languages like Albanian is a serious impediment in computational linguistics and natural language processing research. This paper presents AlbNER, a corpus of 900 sentences with labeled named entities, collected from Albanian Wikipedia articles. Preliminary results with BERT and RoBERTa variants fine-tuned and tested with AlbNER data indicate that model size has slight impact on NER performance, whereas language transfer has a significant one. AlbNER corpus and these obtained results should serve as baselines for future experiments.
</details>
<details>
<summary>摘要</summary>
资源短缺，如 Albanian 语言的注释文本库，是计算语言学和自然语言处理研究中的严重阻碍。本文提出了 AlbNER 词库，包含 900 句 sentences 的标注名实体，从 Albanian Wikipedia 文章中收集。初步结果表明，BERT 和 RoBERTa 变体在 AlbNER 数据上进行 fine-tuning 和测试后，模型大小对 NER 性能有轻微影响，而语言传递却有显著影响。AlbNER 词库和这些结果可作为未来实验的基线。
</details></li>
</ul>
<hr>
<h2 id="OpenAI-Cribbed-Our-Tax-Example-But-Can-GPT-4-Really-Do-Tax"><a href="#OpenAI-Cribbed-Our-Tax-Example-But-Can-GPT-4-Really-Do-Tax" class="headerlink" title="OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?"></a>OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09992">http://arxiv.org/abs/2309.09992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Blair-Stanek, Nils Holzenberger, Benjamin Van Durme</li>
<li>for: 本文解释OpenAI在其直播示例中使用GPT-4计算税务时取得的税法示例来源，以及GPT-4为什么得出错误答案，以及如何估算税务。</li>
<li>methods: GPT-4使用的方法是什么？</li>
<li>results: GPT-4的计算结果是什么？<details>
<summary>Abstract</summary>
The authors explain where OpenAI got the tax law example in its livestream demonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails to reliably calculate taxes.
</details>
<details>
<summary>摘要</summary>
文章讲述OpenAI在其直播中展示GPT-4时得到了税法示例，GPT-4为什么得到了错误答案，以及如何计算税金的问题。Note that "GPT-4" in the text is translated as "GPT-4" in Simplified Chinese, as there is no direct translation for "GPT-4" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="MusiLingo-Bridging-Music-and-Text-with-Pre-trained-Language-Models-for-Music-Captioning-and-Query-Response"><a href="#MusiLingo-Bridging-Music-and-Text-with-Pre-trained-Language-Models-for-Music-Captioning-and-Query-Response" class="headerlink" title="MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response"></a>MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08730">http://arxiv.org/abs/2309.08730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zihaod/musilingo">https://github.com/zihaod/musilingo</a></li>
<li>paper_authors: Zihao Deng, Yinghao Ma, Yudong Liu, Rongchen Guo, Ge Zhang, Wenhu Chen, Wenhao Huang, Emmanouil Benetos</li>
<li>for: 本研究旨在探讨大型语言模型（LLMs）在多媒体应用中的潜在性，特别是将文本和音乐领域融合在一起。</li>
<li>methods: 该研究提出了一种名为MusiLingo的音乐标题生成和音乐相关问题回答系统，使用单一投影层将音乐表示从预先冻结的MERT音乐抽象模型与预先冻结的LLaMA语言模型进行对应。</li>
<li>results: 经过训练和微调，MusiLingo在一个广泛的音乐标题集和 MusicInstruct（MI）集上表现竞争力强，能够生成高质量的音乐标题和音乐相关问题对。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains relatively unexplored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT with the frozen LLaMA language model, bridging the gap between music audio and textual contexts. We train it on an extensive music caption dataset and fine-tune it with instructional data. Due to the scarcity of high-quality music Q&A datasets, we created the MusicInstruct (MI) dataset from MusicCaps, tailored for open-ended music inquiries. Empirical evaluations demonstrate its competitive performance in generating music captions and composing music-related Q&A pairs. Our introduced dataset enables notable advancements beyond previous ones.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多模态应用中表现出了巨大的潜力，然而文字和音乐领域之间的融合仍然尚未得到充分的探索。为解决这个差距，我们介绍了MusiLingo，一种新的音乐标签生成和音乐相关问答系统。MusiLingo通过单一投影层将预训练的冻结音乐AUDIO模型MERT与预训练的LLaMA语言模型相关联，从而bridge音乐Audio和文字上下文之间的差距。我们在广泛的音乐标签数据集上训练并在指导数据上细化MusiLingo。由于音乐Q&A数据集的质量不够高，我们从MusicCaps中创建了MusicInstruct（MI）数据集，适用于开放式音乐问题。我们的实验表明MusiLingo在生成音乐标签和组合音乐相关问答对之间的表现具有竞争力。我们引入的数据集可以为之前的研究提供新的发展空间。
</details></li>
</ul>
<hr>
<h2 id="SculptBot-Pre-Trained-Models-for-3D-Deformable-Object-Manipulation"><a href="#SculptBot-Pre-Trained-Models-for-3D-Deformable-Object-Manipulation" class="headerlink" title="SculptBot: Pre-Trained Models for 3D Deformable Object Manipulation"></a>SculptBot: Pre-Trained Models for 3D Deformable Object Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08728">http://arxiv.org/abs/2309.08728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alison Bartsch, Charlotte Avra, Amir Barati Farimani</li>
<li>for: 这个论文旨在解决机器人 manipulate 塑料时存在的特殊挑战，包括高度自由度和自带遮挡。</li>
<li>methods: 该论文使用点云作为状态表示，并利用预训练的点云重建Transformer来学习材料塑形的积分动态模型，以预测抓取动作后材料的变形。</li>
<li>results: 实验表明提议的系统能够成功捕捉泥土的动态特征，并创造出简单的各种形状。<details>
<summary>Abstract</summary>
Deformable object manipulation presents a unique set of challenges in robotic manipulation by exhibiting high degrees of freedom and severe self-occlusion. State representation for materials that exhibit plastic behavior, like modeling clay or bread dough, is also difficult because they permanently deform under stress and are constantly changing shape. In this work, we investigate each of these challenges using the task of robotic sculpting with a parallel gripper. We propose a system that uses point clouds as the state representation and leverages pre-trained point cloud reconstruction Transformer to learn a latent dynamics model to predict material deformations given a grasp action. We design a novel action sampling algorithm that reasons about geometrical differences between point clouds to further improve the efficiency of model-based planners. All data and experiments are conducted entirely in the real world. Our experiments show the proposed system is able to successfully capture the dynamics of clay, and is able to create a variety of simple shapes.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT可变形物体控制存在机器人控制中的独特挑战，它们具有高度的自由度和严重的自遮挡。物体表示方面，模型粘土或面包皮的材料表示也是困难的，因为它们在压力下永久弯曲并不断变化形状。在这项工作中，我们通过机器人雕塑任务使用并列抓取器进行研究。我们提议一个使用点云作为状态表示的系统，利用预训练的点云重建Transformer来学习材料变形的秘密模型，以便根据抓取动作预测材料的弯曲。我们设计了一种新的行动抽样算法，该算法根据点云的几何差异来进一步改进模型基于 плаanner的效率。所有数据和实验都在实际世界中进行。我们的实验表明我们的提议系统能够成功地捕捉粘土的动态，并能够创造一些简单的形状。Note: The text has been translated using the Google Translate API, which may not be perfect and may not capture all the nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="Modelling-Irregularly-Sampled-Time-Series-Without-Imputation"><a href="#Modelling-Irregularly-Sampled-Time-Series-Without-Imputation" class="headerlink" title="Modelling Irregularly Sampled Time Series Without Imputation"></a>Modelling Irregularly Sampled Time Series Without Imputation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08698">http://arxiv.org/abs/2309.08698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rohit102497/slan">https://github.com/rohit102497/slan</a></li>
<li>paper_authors: Rohit Agarwal, Aman Sinha, Dilip K. Prasad, Marianne Clausel, Alexander Horsch, Mathieu Constant, Xavier Coubez</li>
<li>for: 实时系列时间序列 (ISTS) 模型化困难，因为有资料欠损。现有方法大多将 irregularly 标本资料转换为常规标本资料，并假设该欠损机制。我们提出了 SLAN（Switch LSTM Aggregate Network），它不需要假设任何背景过程，将 irregularly 标本资料模型化，并且在测量过程中动态地适应架构。</li>
<li>methods: SLAN 使用了一个包含 LSTM 的封包，并且透过在飞行器中动态地适应架构，以捕捉每个实验室的本地概要信息，并且保持全球概要状态。</li>
<li>results: 我们在 MIMIC-III、Physionet 2012 和 Physionet 2019 等公共资料集上显示了 SLAN 的优化性能，并且提供了可用的代码（<a target="_blank" rel="noopener" href="https://github.com/Rohit102497/SLAN%EF%BC%89%E3%80%82">https://github.com/Rohit102497/SLAN）。</a><details>
<summary>Abstract</summary>
Modelling irregularly-sampled time series (ISTS) is challenging because of missing values. Most existing methods focus on handling ISTS by converting irregularly sampled data into regularly sampled data via imputation. These models assume an underlying missing mechanism leading to unwanted bias and sub-optimal performance. We present SLAN (Switch LSTM Aggregate Network), which utilizes a pack of LSTMs to model ISTS without imputation, eliminating the assumption of any underlying process. It dynamically adapts its architecture on the fly based on the measured sensors. SLAN exploits the irregularity information to capture each sensor's local summary explicitly and maintains a global summary state throughout the observational period. We demonstrate the efficacy of SLAN on publicly available datasets, namely, MIMIC-III, Physionet 2012 and Physionet 2019. The code is available at https://github.com/Rohit102497/SLAN.
</details>
<details>
<summary>摘要</summary>
模型异常样本时序（ISTS）具有许多挑战，主要是因为缺失数据。现有的方法通常是将异常样本数据转换为常规样本数据，并通过插值来填充缺失数据。这些模型假设存在下面的缺失机制，从而导致不需要的偏见和优化性不佳。我们提出了SLAN（ Switch LSTM Aggregate Network），它利用一个包含LSTM的模型来模型异常样本时序，不需要任何下面缺失机制的假设。它在实际测量的感知器上动态地调整其架构，并且在观测期间保持全局摘要状态。SLAN利用异常性信息来显式地捕捉每个感知器的本地摘要，并且在观测期间保持全局摘要状态。我们在公共可用的数据集上展示了SLAN的效果，具体来说是MIMIC-III、Physionet 2012和Physionet 2019等数据集。代码可以在https://github.com/Rohit102497/SLAN上获取。
</details></li>
</ul>
<hr>
<h2 id="Resolving-Legalese-A-Multilingual-Exploration-of-Negation-Scope-Resolution-in-Legal-Documents"><a href="#Resolving-Legalese-A-Multilingual-Exploration-of-Negation-Scope-Resolution-in-Legal-Documents" class="headerlink" title="Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents"></a>Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08695">http://arxiv.org/abs/2309.08695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ramonachristen/multilingual_negation_scope_resolution_on_legal_data">https://github.com/ramonachristen/multilingual_negation_scope_resolution_on_legal_data</a></li>
<li>paper_authors: Ramona Christen, Anastassia Shaitarova, Matthias Stürmer, Joel Niklaus</li>
<li>for: 这个论文的目的是解决法律文本中的否定范围划分问题。</li>
<li>methods: 这个论文使用了语言模型，并在不同语言的文本上进行了精心的训练和评估。</li>
<li>results: 该论文的实验结果表明，使用语言模型进行法律文本中否定范围划分问题的解决可以达到token级别的86.7%的准确率，并在多种语言之间进行了跨语言比较。<details>
<summary>Abstract</summary>
Resolving the scope of a negation within a sentence is a challenging NLP task. The complexity of legal texts and the lack of annotated in-domain negation corpora pose challenges for state-of-the-art (SotA) models when performing negation scope resolution on multilingual legal data. Our experiments demonstrate that models pre-trained without legal data underperform in the task of negation scope resolution. Our experiments, using language models exclusively fine-tuned on domains like literary texts and medical data, yield inferior results compared to the outcomes documented in prior cross-domain experiments. We release a new set of annotated court decisions in German, French, and Italian and use it to improve negation scope resolution in both zero-shot and multilingual settings. We achieve token-level F1-scores of up to 86.7% in our zero-shot cross-lingual experiments, where the models are trained on two languages of our legal datasets and evaluated on the third. Our multilingual experiments, where the models were trained on all available negation data and evaluated on our legal datasets, resulted in F1-scores of up to 91.1%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fake-News-Detectors-are-Biased-against-Texts-Generated-by-Large-Language-Models"><a href="#Fake-News-Detectors-are-Biased-against-Texts-Generated-by-Large-Language-Models" class="headerlink" title="Fake News Detectors are Biased against Texts Generated by Large Language Models"></a>Fake News Detectors are Biased against Texts Generated by Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08674">http://arxiv.org/abs/2309.08674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyan Su, Terry Yue Zhuo, Jonibek Mansurov, Di Wang, Preslav Nakov</li>
<li>for: 本研究旨在评估假新闻检测器在人类写作和大语言模型生成的假信息场景下的性能。</li>
<li>methods: 本研究使用了一种新的评估方法，利用对真新闻文章的 adversarial 重写来 Mitigate 大语言模型生成的假信息。</li>
<li>results: 研究发现，现有的假新闻检测器往往偏好地标记大语言模型生成的内容为假新闻，而常常错将人类写作的假新闻标为真新闻。这种偏好源于 LLM 输出的语言特征。通过对真新闻文章进行 adversarial 重写，研究人员提出了一种纠正策略，以提高假新闻检测器的检测精度。<details>
<summary>Abstract</summary>
The spread of fake news has emerged as a critical challenge, undermining trust and posing threats to society. In the era of Large Language Models (LLMs), the capability to generate believable fake content has intensified these concerns. In this study, we present a novel paradigm to evaluate fake news detectors in scenarios involving both human-written and LLM-generated misinformation. Intriguingly, our findings reveal a significant bias in many existing detectors: they are more prone to flagging LLM-generated content as fake news while often misclassifying human-written fake news as genuine. This unexpected bias appears to arise from distinct linguistic patterns inherent to LLM outputs. To address this, we introduce a mitigation strategy that leverages adversarial training with LLM-paraphrased genuine news. The resulting model yielded marked improvements in detection accuracy for both human and LLM-generated news. To further catalyze research in this domain, we release two comprehensive datasets, \texttt{GossipCop++} and \texttt{PolitiFact++}, thus amalgamating human-validated articles with LLM-generated fake and real news.
</details>
<details>
<summary>摘要</summary>
假新闻的扩散已成为一项重要挑战，消除信任和对社会构成威胁。在大语言模型（LLM）时代，生成可信假内容的能力加剧了这些问题。在这项研究中，我们提出了一种新的评估假新闻检测器的方法，包括人类写的和 LLM 生成的谣言。结果显示，许多现有的检测器具有偏见：它们更容易将 LLM 生成的内容标记为假新闻，而常常错过人类写的假新闻。这种意外的偏见似乎 arise from LLM 输出中的特殊语言特征。为解决这一问题，我们提出了一种缓解策略，利用 LLM 生成的真实新闻进行对抗训练。这种策略使得检测器的检测精度得到了显著提高，包括人类写的和 LLM 生成的新闻。为了进一步推动这个领域的研究，我们发布了两个全面的数据集，即 \texttt{GossipCop++} 和 \texttt{PolitiFact++}，这两个数据集包括人类验证的文章以及 LLM 生成的假和真新闻。
</details></li>
</ul>
<hr>
<h2 id="Chain-of-Thought-Reasoning-is-a-Policy-Improvement-Operator"><a href="#Chain-of-Thought-Reasoning-is-a-Policy-Improvement-Operator" class="headerlink" title="Chain-of-Thought Reasoning is a Policy Improvement Operator"></a>Chain-of-Thought Reasoning is a Policy Improvement Operator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08589">http://arxiv.org/abs/2309.08589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugh Zhang, David C. Parkes</li>
<li>for: 这项研究的目的是证明语言模型可以通过自我教育来学习新的技能，不需要人类示范。</li>
<li>methods: 这项研究使用了链式思维理解来让语言模型自我教育，然后通过细化模型来生成相同的答案。</li>
<li>results: 研究发现，通过SECToR自我教育方法，语言模型可以自主地学习加法运算，并且可以在无法访问任何示例数据的情况下自动地计算29位数字。<details>
<summary>Abstract</summary>
Large language models have astounded the world with fascinating new capabilities. However, they currently lack the ability to teach themselves new skills, relying instead on being trained on large amounts of human-generated data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a proof-of-concept demonstration that language models can successfully teach themselves new skills using chain-of-thought reasoning. Inspired by previous work in both reinforcement learning (Silver et al., 2017) and human cognition (Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think its way through problems. SECToR then fine-tunes the model to generate those same answers, this time without using chain-of-thought reasoning. Language models trained via SECToR autonomously learn to add up to 29-digit numbers without any access to any ground truth examples beyond an initial supervised fine-tuning phase consisting only of numbers with 6 or fewer digits. Our central hypothesis is that chain-of-thought reasoning can act as a policy improvement operator, analogously to how Monte-Carlo Tree Search is used in AlphaZero. We hope that this research can lead to new directions in which language models can learn to teach themselves without the need for human demonstrations.
</details>
<details>
<summary>摘要</summary>
大型语言模型在全球引起了轰动，推出了新的可能性。然而，现在这些模型仍然无法自学新技能，它们需要在大量的人类生成的数据上接受训练。我们介绍了SECToR（自我教育via推理链），这是一个证明了语言模型可以通过推理链自我教育新技能的证明。这个想法源于之前的循环学习（Silver et al., 2017）和人类认知（Kahneman, 2011）的研究。SECToR首先使用推理链思考问题，然后精确地调整模型，以便在不使用推理链的情况下产生相同的答案。这些语言模型通过SECToR自主学习了添加29位数字的技能，而且无需任何真实的示例例外于初始的监督练习阶段，该阶段只包含6位或少数数字。我们的中心假设是，推理链可以作为政策改善算法，类似于AlphaZero中使用的Monte-Carlo Tree Search。我们希望这些研究可以带来新的方向，让语言模型可以自主学习而不需要人类示例。
</details></li>
</ul>
<hr>
<h2 id="Compositional-Foundation-Models-for-Hierarchical-Planning"><a href="#Compositional-Foundation-Models-for-Hierarchical-Planning" class="headerlink" title="Compositional Foundation Models for Hierarchical Planning"></a>Compositional Foundation Models for Hierarchical Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08587">http://arxiv.org/abs/2309.08587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anurag Ajay, Seungwook Han, Yilun Du, Shaung Li, Abhi Gupta, Tommi Jaakkola, Josh Tenenbaum, Leslie Kaelbling, Akash Srivastava, Pulkit Agrawal</li>
<li>for:  solves long-horizon tasks with hierarchical reasoning across spatial and temporal scales</li>
<li>methods:  leverages multiple expert foundation models trained on language, vision, and action data; constructs symbolic plans grounded in the environment; infers actions from generated videos</li>
<li>results:  illustrates efficacy and adaptability in three different long-horizon table-top manipulation tasks<details>
<summary>Abstract</summary>
To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustrate the efficacy and adaptability of our approach in three different long-horizon table-top manipulation tasks.
</details>
<details>
<summary>摘要</summary>
为了在新环境中做出有效的决策，需要进行层次的思考，覆盖空间和时间尺度。这意味着制定抽象子目标序列，视觉地理解下面的计划，并在计划中执行动作。我们提出了层次基础模型 для高级规划（HiP），一种基础模型，利用多个专家基础模型， individually jointly 处理语言、视觉和动作数据，解决长期任务。我们使用大型语言模型构建符号计划，将其grounded在环境中通过大型视频扩散模型。生成的视频计划然后grounded到视motor控制，通过反向动力学模型，从生成的视频中推算出动作。为了确保层次中的有效思考，我们在模型之间强制保持一致性，通过迭代纠正。我们在三个不同的长期表面 manipulate任务中证明了我们的方法的有效性和适应性。
</details></li>
</ul>
<hr>
<h2 id="How-Transferable-are-Attribute-Controllers-on-Pretrained-Multilingual-Translation-Models"><a href="#How-Transferable-are-Attribute-Controllers-on-Pretrained-Multilingual-Translation-Models" class="headerlink" title="How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?"></a>How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08565">http://arxiv.org/abs/2309.08565</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dannigt/attribute-controller-transfer">https://github.com/dannigt/attribute-controller-transfer</a></li>
<li>paper_authors: Danni Liu, Jan Niehues</li>
<li>for: 这篇论文旨在探讨如何通过将属性控制器转移到新语言中，提高自然语言处理器的形式识别能力。</li>
<li>methods: 该论文使用基于预训练大量多语言翻译模型的无监督学习方法，以转移属性控制器的能力到新语言中。</li>
<li>results: 该论文通过对多种数据enario进行分析，发现了在零shot情况下和不同领域中的改进，并通过人工评估确认了这些改进的有效性。<details>
<summary>Abstract</summary>
Customizing machine translation models to comply with fine-grained attributes such as formality has seen tremendous progress recently. However, current approaches mostly rely on at least some supervised data with attribute annotation. Data scarcity therefore remains a bottleneck to democratizing such customization possibilities to a wider range of languages, lower-resource ones in particular. Given recent progress in pretrained massively multilingual translation models, we use them as a foundation to transfer the attribute controlling capabilities to languages without supervised data. In this work, we present a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios, and uncover their relative strengths and weaknesses in zero-shot performance and domain robustness. We show that both paradigms are complementary, as shown by consistent improvements on 5 zero-shot directions. Moreover, a human evaluation on a real low-resource language, Bengali, confirms our findings on zero-shot transfer to new target languages. The code is $\href{https://github.com/dannigt/attribute-controller-transfer}{\text{here}$.
</details>
<details>
<summary>摘要</summary>
Recently, there has been significant progress in customizing machine translation models to accommodate fine-grained attributes, such as formality. However, most current approaches rely on at least some supervised data with attribute annotation, which can be a limiting factor in democratizing these customization possibilities to a wider range of languages, particularly lower-resource ones. To address this issue, we use pretrained massively multilingual translation models as a foundation to transfer the attribute controlling capabilities to languages without supervised data.In this study, we conduct a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios and compare their performance in zero-shot settings and domain robustness. Our results show that both paradigms are complementary, as evidenced by consistent improvements in five zero-shot directions. Additionally, a human evaluation on a real low-resource language, Bengali, confirms our findings on zero-shot transfer to new target languages. The code for this study is available at $\href{https://github.com/dannigt/attribute-controller-transfer}{\text{here}$.
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Efficient-and-Fair-Allocation-of-Health-Care-Resources"><a href="#Deep-Reinforcement-Learning-for-Efficient-and-Fair-Allocation-of-Health-Care-Resources" class="headerlink" title="Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources"></a>Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08560">http://arxiv.org/abs/2309.08560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikuan Li, Chengsheng Mao, Kaixuan Huang, Hanyin Wang, Zheng Yu, Mengdi Wang, Yuan Luo</li>
<li>for: 该研究旨在提出一种基于强化学习的医疗资源分配策略优化方法，以实现公平、有效地分配医疗资源，特别是在医疗资源紧缺的情况下。</li>
<li>methods: 该研究使用了转换器基本深度Q网络（Transformer-based deep Q-network）来集成病例患者的疾病进程和患者之间的交互效应，以优化医疗资源分配策略。</li>
<li>results: 研究结果表明，该方法可以减少过度死亡和提高分配公平性，特别在不同水平的呼吸器短缺情况下。与现有的严重程度和混合病理因素基于的方法相比，该方法可以更好地保护患者的生命和健康。<details>
<summary>Abstract</summary>
Scarcity of health care resources could result in the unavoidable consequence of rationing. For example, ventilators are often limited in supply, especially during public health emergencies or in resource-constrained health care settings, such as amid the pandemic of COVID-19. Currently, there is no universally accepted standard for health care resource allocation protocols, resulting in different governments prioritizing patients based on various criteria and heuristic-based protocols. In this study, we investigate the use of reinforcement learning for critical care resource allocation policy optimization to fairly and effectively ration resources. We propose a transformer-based deep Q-network to integrate the disease progression of individual patients and the interaction effects among patients during the critical care resource allocation. We aim to improve both fairness of allocation and overall patient outcomes. Our experiments demonstrate that our method significantly reduces excess deaths and achieves a more equitable distribution under different levels of ventilator shortage, when compared to existing severity-based and comorbidity-based methods in use by different governments. Our source code is included in the supplement and will be released on Github upon publication.
</details>
<details>
<summary>摘要</summary>
缺乏医疗资源可能导致不可避免的配分。例如，呼吸机在公共卫生紧急情况或资源受限的医疗设施中经常受限，特别是在COVID-19大流行期间。目前没有一个通用的医疗资源配分协议标准，因此不同政府会根据不同的标准和规则来优先级化患者。在这项研究中，我们研究了使用强化学习来优化护理资源配分策略，以确保公平和有效地配分资源。我们提出了基于转换器的深度Q网络，以捕捉患者个人疾病进程和患者之间交互效应。我们希望通过提高配分公平性和总体患者结果来改善医疗资源配分。我们的实验表明，我们的方法可以在不同程度的呼吸机短缺情况下，比已有严重程度和相关病理因素基于的方法减少过剩死亡和实现更公平的配分。我们的源代码将在附录中提供，并在发表后在Github上发布。
</details></li>
</ul>
<hr>
<h2 id="HINT-Healthy-Influential-Noise-based-Training-to-Defend-against-Data-Poisoning-Attacks"><a href="#HINT-Healthy-Influential-Noise-based-Training-to-Defend-against-Data-Poisoning-Attacks" class="headerlink" title="HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks"></a>HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08549">http://arxiv.org/abs/2309.08549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minh-Hao Van, Alycia N. Carey, Xintao Wu</li>
<li>for: 防止数据恶意攻击，提高深度学习模型的安全性</li>
<li>methods: 基于影响函数的健康干扰训练方法（Healthy Influential-Noise based Training，简称HINT），通过Influence functions减弱攻击者对模型的攻击，并且可以在部分训练数据被修改时仍然高效地防御</li>
<li>results: 对两个图像 dataset 进行了大量的实验，并在不同的实际攻击场景下显示了HINT 可以有效地防止深度学习模型受到攻击的影响，并且比traditional方法更具有抗性。<details>
<summary>Abstract</summary>
While numerous defense methods have been proposed to prohibit potential poisoning attacks from untrusted data sources, most research works only defend against specific attacks, which leaves many avenues for an adversary to exploit. In this work, we propose an efficient and robust training approach to defend against data poisoning attacks based on influence functions, named Healthy Influential-Noise based Training. Using influence functions, we craft healthy noise that helps to harden the classification model against poisoning attacks without significantly affecting the generalization ability on test data. In addition, our method can perform effectively when only a subset of the training data is modified, instead of the current method of adding noise to all examples that has been used in several previous works. We conduct comprehensive evaluations over two image datasets with state-of-the-art poisoning attacks under different realistic attack scenarios. Our empirical results show that HINT can efficiently protect deep learning models against the effect of both untargeted and targeted poisoning attacks.
</details>
<details>
<summary>摘要</summary>
多种防御方法已经提议用于禁止来自不可信数据源的毒化攻击，但大多数研究工作只防御特定的攻击，这留下了许多攻击途径。在这项工作中，我们提出了一种高效和可靠的训练方法，以防止数据毒化攻击，名为健康影响函数基本训练（HINT）。使用影响函数，我们制作了健康的噪音，以强化分类模型对毒化攻击的抵抗能力，而不会对测试数据造成显著影响。此外，我们的方法可以在部分训练数据被修改时进行有效地工作，而不是现有的所有示例都添加噪音的方法。我们在两个图像 dataset 上进行了全面的评估，并在不同的现实攻击场景下进行了 state-of-the-art 毒化攻击。我们的实验结果表明，HINT 可以高效地保护深度学习模型对毒化攻击的影响。
</details></li>
</ul>
<hr>
<h2 id="When-do-Generative-Query-and-Document-Expansions-Fail-A-Comprehensive-Study-Across-Methods-Retrievers-and-Datasets"><a href="#When-do-Generative-Query-and-Document-Expansions-Fail-A-Comprehensive-Study-Across-Methods-Retrievers-and-Datasets" class="headerlink" title="When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets"></a>When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08541">http://arxiv.org/abs/2309.08541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Orion Weller, Kyle Lo, David Wadden, Dawn Lawrie, Benjamin Van Durme, Arman Cohan, Luca Soldaini</li>
<li>for: 本研究用大型自然语言模型（LM）进行查询或文档扩展，以提高信息检索的通用性。</li>
<li>methods: 本研究使用了十一种扩展技术，并在十二个 datasets 上进行了多种分布差异的测试。</li>
<li>results: 研究发现，使用扩展技术可以提高弱化模型的表现，但是对于强化模型来说，通常会导致负面影响。通过质量错误分析，我们提出了一种recipe：在弱化模型或target dataset与训练 corpora 有显著差异时使用扩展技术，否则避免使用扩展技术，以保持 relevance signal 的清晰性。<details>
<summary>Abstract</summary>
Using large language models (LMs) for query or document expansion can improve generalization in information retrieval. However, it is unknown whether these techniques are universally beneficial or only effective in specific settings, such as for particular retrieval models, dataset domains, or query types. To answer this, we conduct the first comprehensive analysis of LM-based expansion. We find that there exists a strong negative correlation between retriever performance and gains from expansion: expansion improves scores for weaker models, but generally harms stronger models. We show this trend holds across a set of eleven expansion techniques, twelve datasets with diverse distribution shifts, and twenty-four retrieval models. Through qualitative error analysis, we hypothesize that although expansions provide extra information (potentially improving recall), they add additional noise that makes it difficult to discern between the top relevant documents (thus introducing false positives). Our results suggest the following recipe: use expansions for weaker models or when the target dataset significantly differs from training corpus in format; otherwise, avoid expansions to keep the relevance signal clear.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Visual-Speech-Recognition-for-Low-resource-Languages-with-Automatic-Labels-From-Whisper-Model"><a href="#Visual-Speech-Recognition-for-Low-resource-Languages-with-Automatic-Labels-From-Whisper-Model" class="headerlink" title="Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model"></a>Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08535">http://arxiv.org/abs/2309.08535</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeonghun0716/visual-speech-recognition-for-low-resource-languages">https://github.com/jeonghun0716/visual-speech-recognition-for-low-resource-languages</a></li>
<li>paper_authors: Jeong Hun Yeo, Minsu Kim, Shinji Watanabe, Yong Man Ro</li>
<li>for: 这个论文旨在提出一种可以处理多种语言的强大视说识别（VSR）方法，尤其是为低资源语言，即有限量的标注数据。</li>
<li>methods: 我们使用了一种叫做Whisper模型，它可以同时进行语言标识和音频基于的语音识别。它可以筛选出所需语言的数据，并从无标注的多语言视频数据池中提取标签。</li>
<li>results: 我们通过比较使用自动生成的标签和人工标注的标签来评估VSR模型的性能，发现我们可以达到与人工标注标签相同的VSR性能，不需要人工干预。通过自动标签过程，我们生成了大规模的无标注多语言数据库，包括VoxCeleb2和AVSpeech，共计1,002小时的数据。使用自动生成的标签，我们在四种低资源语言中实现了新的州OF-the-art性能，大幅超越之前的方法。自动生成的标签可以在线获取：<a target="_blank" rel="noopener" href="https://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages%E3%80%82">https://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages。</a><details>
<summary>Abstract</summary>
This paper proposes a powerful Visual Speech Recognition (VSR) method for multiple languages, especially for low-resource languages that have a limited number of labeled data. Different from previous methods that tried to improve the VSR performance for the target language by using knowledge learned from other languages, we explore whether we can increase the amount of training data itself for the different languages without human intervention. To this end, we employ a Whisper model which can conduct both language identification and audio-based speech recognition. It serves to filter data of the desired languages and transcribe labels from the unannotated, multilingual audio-visual data pool. By comparing the performances of VSR models trained on automatic labels and the human-annotated labels, we show that we can achieve similar VSR performance to that of human-annotated labels even without utilizing human annotations. Through the automated labeling process, we label large-scale unlabeled multilingual databases, VoxCeleb2 and AVSpeech, producing 1,002 hours of data for four low VSR resource languages, French, Italian, Spanish, and Portuguese. With the automatic labels, we achieve new state-of-the-art performance on mTEDx in four languages, significantly surpassing the previous methods. The automatic labels are available online: https://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Connecting-Large-Language-Models-with-Evolutionary-Algorithms-Yields-Powerful-Prompt-Optimizers"><a href="#Connecting-Large-Language-Models-with-Evolutionary-Algorithms-Yields-Powerful-Prompt-Optimizers" class="headerlink" title="Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers"></a>Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08532">http://arxiv.org/abs/2309.08532</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyegomez/EAOT">https://github.com/kyegomez/EAOT</a></li>
<li>paper_authors: Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang</li>
<li>for: 这个论文的目的是提出一种新的整数提示优化框架，即EvoPrompt，以优化大型自然语言模型（LLMs）的提示，以提高 LLMS 的性能。</li>
<li>methods: 这个论文使用了进化算法（EAs）来优化提示，并将 LLMS 与 EAs 连接起来，以同时利用 LLMS 的强大自然语言处理能力和 EAs 的高效优化能力。</li>
<li>results: 对于9个语言理解和生成任务的数据集，EvoPrompt 可以减少人工设计提示的努力，并在closed-和open-source LLMS 上提高提示的性能，相比之下，人工设计提示和现有的自动提示生成方法可以提高性能的14%和25%。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3.5 and Alpaca, on 9 datasets spanning language understanding and generation tasks. EvoPrompt significantly outperforms human-engineered prompts and existing methods for automatic prompt generation by up to 25% and 14% respectively. Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs creates synergies, which could inspire further research on the combination of LLMs and conventional algorithms.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种任务中表现出色，但它们依赖于考究制定的提示，这些提示frequently需要人类努力。为了自动化这个过程，在这篇论文中，我们提出了一种新的框架，called EvoPrompt，它借鉴了进化算法（EA）的好performanc和快速收敛特点。为了让EA工作于精确的提示上，我们将LLM与EA相连接。这种方法允许我们同时利用LLM的强大语言处理能力和EA的高效优化能力。具体来说，不需要任何梯度或参数，EvoPrompt从一个人工提示的population开始，逐渐通过进化运算器生成新的提示，以提高人工提示的质量。我们对closed-和open-source LLMs，包括GPT-3.5和Alpaca，在9个语言理解和生成任务上进行优化。EvoPrompt在人工制定提示和现有自动提示生成方法的基础上显著超越了，最高超过25%和14%。此外，EvoPrompt表明了将LLM与EA相连接可以创造共生，这可能会推动进一步的LLM和传统算法的组合研究。
</details></li>
</ul>
<hr>
<h2 id="SCT-A-Simple-Baseline-for-Parameter-Efficient-Fine-Tuning-via-Salient-Channels"><a href="#SCT-A-Simple-Baseline-for-Parameter-Efficient-Fine-Tuning-via-Salient-Channels" class="headerlink" title="SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels"></a>SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08513">http://arxiv.org/abs/2309.08513</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/showlab/sct">https://github.com/showlab/sct</a></li>
<li>paper_authors: Henry Hengyuan Zhao, Pichao Wang, Yuyang Zhao, Hao Luo, Fan Wang, Mike Zheng Shou</li>
<li>for: 提高下游任务的表示能力，降低 Parameters 成本</li>
<li>methods: 使用 Salient Channel Tuning（SCT）方法，通过在特定任务图像上进行前向传播，选择特定的通道，进行精细调整</li>
<li>results: 在 VTAB-1K benchmark 中，与全量 Fine-Tuning 相比，提高了 18 个任务中的 19 个任务，增加了只 0.11M 参数的 ViT-B，相比全量 Fine-Tuning 的 780 倍少于 Parameters 成本，并在领域总成本和少量学习中表现出色。<details>
<summary>Abstract</summary>
Pre-trained vision transformers have strong representation benefits to various downstream tasks. Recently, many parameter-efficient fine-tuning (PEFT) methods have been proposed, and their experiments demonstrate that tuning only 1% of extra parameters could surpass full fine-tuning in low-data resource scenarios. However, these methods overlook the task-specific information when fine-tuning diverse downstream tasks. In this paper, we propose a simple yet effective method called "Salient Channel Tuning" (SCT) to leverage the task-specific information by forwarding the model with the task images to select partial channels in a feature map that enables us to tune only 1/8 channels leading to significantly lower parameter costs. Experiments outperform full fine-tuning on 18 out of 19 tasks in the VTAB-1K benchmark by adding only 0.11M parameters of the ViT-B, which is 780$\times$ fewer than its full fine-tuning counterpart. Furthermore, experiments on domain generalization and few-shot learning surpass other PEFT methods with lower parameter costs, demonstrating our proposed tuning technique's strong capability and effectiveness in the low-data regime.
</details>
<details>
<summary>摘要</summary>
(Note: The text is translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The translation is written in the traditional Chinese character set.)
</details></li>
</ul>
<hr>
<h2 id="HealthFC-A-Dataset-of-Health-Claims-for-Evidence-Based-Medical-Fact-Checking"><a href="#HealthFC-A-Dataset-of-Health-Claims-for-Evidence-Based-Medical-Fact-Checking" class="headerlink" title="HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking"></a>HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08503">http://arxiv.org/abs/2309.08503</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jvladika/healthfc">https://github.com/jvladika/healthfc</a></li>
<li>paper_authors: Juraj Vladika, Phillip Schneider, Florian Matthes</li>
<li>for: 这 paper 是为了提高自动化医疗信息检验的技术水平，提供一个大量的医疗相关laims数据集，并对其进行分类和分析。</li>
<li>methods: 该 paper 使用了一种新的数据集，包含 750 个医疗相关的laims，每个laim都被医疗专家 manually 标记为真或假，并且具有相关的临床研究证据。 authors 还提供了一些基本的机器学习模型，以便自动检验医疗信息的真实性。</li>
<li>results: 该 paper 的分析表明，该数据集具有一定的特点和挑战，例如医疗相关的laims 的复杂性和多样性。 authors 还提供了一些基本的模型性能分析，以便用于自动医疗信息检验。<details>
<summary>Abstract</summary>
Seeking health-related advice on the internet has become a common practice in the digital era. Determining the trustworthiness of medical claims found online and finding appropriate evidence for this information is increasingly challenging. Fact-checking has emerged as an approach to assess the veracity of factual claims using evidence from credible knowledge sources. To help advance the automation of this task, in this paper, we introduce a novel dataset of 750 health-related claims, labeled for veracity by medical experts and backed with evidence from appropriate clinical studies. We provide an analysis of the dataset, highlighting its characteristics and challenges. The dataset can be used for Machine Learning tasks related to automated fact-checking such as evidence retrieval, veracity prediction, and explanation generation. For this purpose, we provide baseline models based on different approaches, examine their performance, and discuss the findings.
</details>
<details>
<summary>摘要</summary>
在数字时代，通过互联网寻求医疗相关建议已成为普遍的做法。但确定互联网上医疗laim的可靠性和找到相关证据已变得越来越困难。因此，Fact-checking作为一种方法，可以评估医疗声明的真实性，并提供来自可靠的知识源的证据。在这篇论文中，我们介绍了一个新的医疗声明数据集，包含750个医疗声明，每个声明都被医学专家标记为真实或假，并且与相关的临床研究证据相匹配。我们对这个数据集进行了分析，描述了其特点和挑战。这个数据集可以用于自动化Fact-checking任务，如证据检索、真实性预测和解释生成。为此，我们提供了基准模型，评估其表现，并讨论发现。
</details></li>
</ul>
<hr>
<h2 id="P-ROCKET-Pruning-Random-Convolution-Kernels-for-Time-Series-Classification"><a href="#P-ROCKET-Pruning-Random-Convolution-Kernels-for-Time-Series-Classification" class="headerlink" title="P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification"></a>P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08499">http://arxiv.org/abs/2309.08499</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shaowuchen/p-rocket">https://github.com/shaowuchen/p-rocket</a></li>
<li>paper_authors: Shaowu Chen, Weize Sun, Lei Huang, Xiaopeng Li, Qingyuan Wang, Deepu John</li>
<li>for: 这篇论文主要关注的是对时间序列资料进行分类，并且提出了一个名为P-ROCKET的新方法，以提高时间序列资料的分类精度和效率。</li>
<li>methods: 这篇论文使用了ROCKET和MINIROCKET两种时间序列分类模型，并且提出了一个名为S-ROCKET的进一步改进方法。S-ROCKET使用了一个轻量级的演化算法，并且对时间序列资料进行了快速的特征提取和分类。</li>
<li>results: 这篇论文的结果显示，P-ROCKET方法可以对时间序列资料进行高精度的分类，并且比ROCKET和MINIROCKET更具有时间效率。此外，P-ROCKET方法还可以实现资源受限的设备上的时间序列分类。<details>
<summary>Abstract</summary>
In recent years, two time series classification models, ROCKET and MINIROCKET, have attracted much attention for their low training cost and state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without training, ROCKET and MINIROCKET can rapidly extract features from time series data, allowing for the efficient fitting of linear classifiers. However, to comprehensively capture useful features, a large number of random kernels are required, which is incompatible for resource-constrained devices. Therefore, a heuristic evolutionary algorithm named S-ROCKET is devised to recognize and prune redundant kernels. Nevertheless, the inherent nature of evolutionary algorithms renders the evaluation of kernels within S-ROCKET an unacceptable time-consuming process. In this paper, diverging from S-ROCKET, which directly evaluates random kernels with nonsignificant differences, we remove kernels from a feature selection perspective by eliminating associating connections in the sequential classification layer. To this end, we start by formulating the pruning challenge as a Group Elastic Net classification problem and employ the ADMM method to arrive at a solution. Sequentially, we accelerate the aforementioned time-consuming solving process by bifurcating the $l_{2,1}$ and $l_2$ regularizations into two sequential stages and solve them separately, which ultimately forms our core algorithm, named P-ROCKET. Stage 1 of P-ROCKET employs group-wise regularization similarly to our initial ADMM-based Algorithm, but introduces dynamically varying penalties to greatly accelerate the process. To mitigate overfitting, Stage 2 of P-ROCKET implements element-wise regularization to refit a linear classifier, utilizing the retained features.
</details>
<details>
<summary>摘要</summary>
近年来，两种时序分类模型ROCKET和MINIROCKET吸引了很多关注，因为它们可以快速提取时序数据中的特征，并且可以使用随机1D卷积神经网络来适应不同的时序数据。然而，为了全面捕捉有用的特征，需要使用很多随机卷积神经网络，这对资源受限的设备来说是不可接受的。因此，我们提出了一种遗传演化算法名为S-ROCKET，以确定和剪枝无用的卷积神经网络。然而，遗传演化算法的自然特性使得在S-ROCKET中评估卷积神经网络的过程变得非常时间consuming。在这篇论文中，我们与S-ROCKET不同，直接从feature选择的角度来剪枝无用的卷积神经网络。为此，我们将剪枝挑战转化为一个Group Elastic Net分类问题，并使用ADMM方法解决。然后，我们通过将$l_{2,1}$和$l_2$正则化分为两个阶段，并在每个阶段解决它们，从而形成我们的核心算法P-ROCKET。P-ROCKET的第一个阶段使用了群体强制正则化，类似于我们的初始ADMM算法，但是引入了动态变化的罚状，以大大加速过程。为避免过拟合，P-ROCKET的第二个阶段实施元素级正则化，以重新适应保留的特征。
</details></li>
</ul>
<hr>
<h2 id="Using-Large-Language-Models-for-Knowledge-Engineering-LLMKE-A-Case-Study-on-Wikidata"><a href="#Using-Large-Language-Models-for-Knowledge-Engineering-LLMKE-A-Case-Study-on-Wikidata" class="headerlink" title="Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata"></a>Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08491">http://arxiv.org/abs/2309.08491</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bohuizhang/llmke">https://github.com/bohuizhang/llmke</a></li>
<li>paper_authors: Bohui Zhang, Ioannis Reklos, Nitisha Jain, Albert Meroño Peñuela, Elena Simperl</li>
<li>for: The paper is written for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge.</li>
<li>methods: The paper uses pre-trained Large Language Models (LLMs) to produce relevant objects in string format and link them to their respective Wikidata QIDs. The pipeline developed in the paper is called LLMKE, which combines knowledge probing and Wikidata entity mapping.</li>
<li>results: The paper achieved a macro-averaged F1-score of 0.701 across the properties, with scores varying from 1.00 to 0.328. The results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base completion and correction.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为了知识工程任务而写的，具体是在ISWC 2023 LM-KBC Challenge 的上下文中。</li>
<li>methods: 这篇论文使用预训练的大语言模型（LLMs）来生成相关的对象序列和将其与 Wikidata QID 相关联。提出的管道是LLMKE，它将知识探测和 Wikidata 实体映射相结合。</li>
<li>results: 这篇论文在不同属性上的平均 F1 分数为 0.701，分数从 1.00 到 0.328 不等。结果表明 LLM 的知识在不同领域存在显著差异，需要进一步的实验来确定 LLM 在自动知识基础（如 Wikidata）完成和修正的情况下是否有可能使用。<details>
<summary>Abstract</summary>
In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction. The investigation of the results also suggests the promising contribution of LLMs in collaborative knowledge engineering. LLMKE won Track 2 of the challenge. The implementation is available at https://github.com/bohuizhang/LLMKE.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们探索了大语言模型（LLM）在知识工程任务中的应用 potential。在ISWC 2023 LM-KBC Challenge 的上下文中，我们使用预训练的 LLM 生成基于 Wikidata 中的主题和关系对的相关对象，并将其与其相应的 Wikidata QID 相连接。我们开发了一个基于 LLM 的知识工程管道（LLMKE），结合了知识探测和 Wikidata 实体映射。该方法在不同属性上的macro-平均 F1 分数达0.701，分布范围从1.00到0.328。这些结果表明 LLM 在不同领域中知识的 vary 程度很大，需要进一步的实验来确定 LLMEn可以用于自动完成和修正 Wikidata 知识库。此外，我们发现 LLMKE 在合作知识工程中的承诺可能性非常高。LLMKE 赢得了 Track 2 的挑战。实现可以在 GitHub 上找到：https://github.com/bohuizhang/LLMKE。
</details></li>
</ul>
<hr>
<h2 id="XFedHunter-An-Explainable-Federated-Learning-Framework-for-Advanced-Persistent-Threat-Detection-in-SDN"><a href="#XFedHunter-An-Explainable-Federated-Learning-Framework-for-Advanced-Persistent-Threat-Detection-in-SDN" class="headerlink" title="XFedHunter: An Explainable Federated Learning Framework for Advanced Persistent Threat Detection in SDN"></a>XFedHunter: An Explainable Federated Learning Framework for Advanced Persistent Threat Detection in SDN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08485">http://arxiv.org/abs/2309.08485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huynh Thai Thi, Ngo Duc Hoang Son, Phan The Duy, Nghi Hoang Khoa, Khoa Ngo-Khanh, Van-Hau Pham</li>
<li>For: This paper proposes a framework for detecting Advanced Persistent Threats (APTs) in Software-Defined Networking (SDN) using Federated Learning (FL) and Explainable Artificial Intelligence (XAI).* Methods: The proposed framework, called XFedHunter, utilizes a combination of Graph Neural Networks (GNNs) and Deep Learning models to detect APTs in the network system. It also leverages local cyber threat knowledge from multiple training collaborators to improve the accuracy of APT detection.* Results: The experimental results on two datasets (NF-ToN-IoT and DARPA TCE3) show that XFedHunter can effectively enhance the trust and accountability of Machine Learning (ML)-based systems for cybersecurity purposes without compromising privacy.<details>
<summary>Abstract</summary>
Advanced Persistent Threat (APT) attacks are highly sophisticated and employ a multitude of advanced methods and techniques to target organizations and steal sensitive and confidential information. APT attacks consist of multiple stages and have a defined strategy, utilizing new and innovative techniques and technologies developed by hackers to evade security software monitoring. To effectively protect against APTs, detecting and predicting APT indicators with an explanation from Machine Learning (ML) prediction is crucial to reveal the characteristics of attackers lurking in the network system. Meanwhile, Federated Learning (FL) has emerged as a promising approach for building intelligent applications without compromising privacy. This is particularly important in cybersecurity, where sensitive data and high-quality labeling play a critical role in constructing effective machine learning models for detecting cyber threats. Therefore, this work proposes XFedHunter, an explainable federated learning framework for APT detection in Software-Defined Networking (SDN) leveraging local cyber threat knowledge from many training collaborators. In XFedHunter, Graph Neural Network (GNN) and Deep Learning model are utilized to reveal the malicious events effectively in the large number of normal ones in the network system. The experimental results on NF-ToN-IoT and DARPA TCE3 datasets indicate that our framework can enhance the trust and accountability of ML-based systems utilized for cybersecurity purposes without privacy leakage.
</details>
<details>
<summary>摘要</summary>
高级持续性威胁（APT）攻击非常复杂，使用多种先进技术和方法来目标组织和窃取敏感和机密信息。APT攻击包括多个阶段，并且具有定制化的策略，通过新创新的技术和技术来欺骗安全软件监控。为了有效地防茧APT，探测和预测APT指标是非常重要的，以揭示攻击者在网络系统中隐藏的特征。此外，联邦学习（FL）已经出现为建立智能应用程序而不损失隐私的有力方法。这是特别重要的在网络安全方面，因为敏感数据和高质量的标签具有重要的作用在建立有效的机器学习模型来检测网络威胁。因此，本工作提出了XFedHunter，一个可解释的联邦学习框架，用于SDN中的APT检测。在XFedHunter中，图 neural network（GNN）和深度学习模型被用来有效地揭示网络系统中的恶意事件，从多个培训合作者的本地网络威胁知识中获得了有用的信息。实验结果表明，XFedHunter可以提高机器学习系统在网络安全领域的信任和负责任性，而不导致隐私泄露。
</details></li>
</ul>
<hr>
<h2 id="VulnSense-Efficient-Vulnerability-Detection-in-Ethereum-Smart-Contracts-by-Multimodal-Learning-with-Graph-Neural-Network-and-Language-Model"><a href="#VulnSense-Efficient-Vulnerability-Detection-in-Ethereum-Smart-Contracts-by-Multimodal-Learning-with-Graph-Neural-Network-and-Language-Model" class="headerlink" title="VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model"></a>VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08474">http://arxiv.org/abs/2309.08474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phan The Duy, Nghi Hoang Khoa, Nguyen Huu Quyen, Le Cong Trinh, Vu Trung Kien, Trinh Minh Hoang, Van-Hau Pham</li>
<li>for: 本研究提出的 VulnSense 框架用于高效地检测 Ethereum 智能合约中的漏洞，使用多modal 学习方法在图像基本和自然语言处理（NLP）模型上。</li>
<li>methods: 我们的提议方案结合了三种智能合约中的特征，包括源代码、 opcode 序列和控制流图（CFG）从 bytecode 中提取。我们采用 BERT、BiLSTM 和 GNN 模型来提取和分析这些特征。</li>
<li>results: 我们的多modal 方法在 Ethereum 智能合约中检测漏洞的准确率达到 77.96%，胜过了单个特征或单个模型深度学习技术的限制。<details>
<summary>Abstract</summary>
This paper presents VulnSense framework, a comprehensive approach to efficiently detect vulnerabilities in Ethereum smart contracts using a multimodal learning approach on graph-based and natural language processing (NLP) models. Our proposed framework combines three types of features from smart contracts comprising source code, opcode sequences, and control flow graph (CFG) extracted from bytecode. We employ Bidirectional Encoder Representations from Transformers (BERT), Bidirectional Long Short-Term Memory (BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these features. The final layer of our multimodal approach consists of a fully connected layer used to predict vulnerabilities in Ethereum smart contracts. Addressing limitations of existing vulnerability detection methods relying on single-feature or single-model deep learning techniques, our method surpasses accuracy and effectiveness constraints. We assess VulnSense using a collection of 1.769 smart contracts derived from the combination of three datasets: Curated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with various unimodal and multimodal learning techniques contributed by GNN, BiLSTM and BERT architectures. The experimental outcomes demonstrate the superior performance of our proposed approach, achieving an average accuracy of 77.96\% across all three categories of vulnerable smart contracts.
</details>
<details>
<summary>摘要</summary>
Existing vulnerability detection methods have limitations, such as relying on single-feature or single-model deep learning techniques, which can lead to accuracy and effectiveness constraints. In contrast, VulnSense surpasses these limitations by using a multimodal approach that combines multiple features and models to improve accuracy and effectiveness.The framework is evaluated using a collection of 1,769 smart contracts derived from three datasets: Curated, SolidiFI-Benchmark, and Smartbugs Wild. The experimental results demonstrate the superior performance of VulnSense, achieving an average accuracy of 77.96% across all three categories of vulnerable smart contracts.In comparison with various unimodal and multimodal learning techniques contributed by GNN, BiLSTM, and BERT architectures, VulnSense outperforms them all, showcasing its effectiveness in detecting vulnerabilities in Ethereum smart contracts.
</details></li>
</ul>
<hr>
<h2 id="Explaining-Search-Result-Stances-to-Opinionated-People"><a href="#Explaining-Search-Result-Stances-to-Opinionated-People" class="headerlink" title="Explaining Search Result Stances to Opinionated People"></a>Explaining Search Result Stances to Opinionated People</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08460">http://arxiv.org/abs/2309.08460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Z. Wu, T. Draws, F. Cau, F. Barile, A. Rieger, N. Tintarev</li>
<li>for: 本研究旨在探讨在搜寻信息时，用户是否可以通过站点标签和其解释来避免认知偏见。</li>
<li>methods: 本研究使用自动分类和标签搜寻结果，并生成对这些标签的解释。研究采用用户研究（N &#x3D; 203）来检验搜寻结果的偏见程度影响用户的搜寻结果阅读。</li>
<li>results: 研究发现，站点标签和解释可以导致用户阅读更多的搜寻结果，但没有证据表明用户在这种情况下会有系统化的意见变化。这些结果可以帮助搜寻引擎设计师制定更 Informed 的设计决策。<details>
<summary>Abstract</summary>
People use web search engines to find information before forming opinions, which can lead to practical decisions with different levels of impact. The cognitive effort of search can leave opinionated users vulnerable to cognitive biases, e.g., the confirmation bias. In this paper, we investigate whether stance labels and their explanations can help users consume more diverse search results. We automatically classify and label search results on three topics (i.e., intellectual property rights, school uniforms, and atheism) as against, neutral, and in favor, and generate explanations for these labels. In a user study (N =203), we then investigate whether search result stance bias (balanced vs biased) and the level of explanation (plain text, label only, label and explanation) influence the diversity of search results clicked. We find that stance labels and explanations lead to a more diverse search result consumption. However, we do not find evidence for systematic opinion change among users in this context. We believe these results can help designers of search engines to make more informed design decisions.
</details>
<details>
<summary>摘要</summary>
（人们通过网络搜索引擎来获取信息，然后形成意见，这可能会导致不同的决策。搜索过程中的认知努力可能会使用户受到认知偏见，例如确认偏见。本文 investigate 是否可以通过立场标签和其解释来帮助用户遍历更多的搜索结果。我们自动分类和标签搜索结果的三个话题（知识产权、学校制服和无神论）为对、中立和赞成，并生成对这些标签的解释。在用户研究（N = 203）中，我们调查了搜索结果的立场偏豫（偏豫VS不偏豫）和解释水平（纯文本、标签仅、标签和解释）对搜索结果遍历的影响。我们发现，立场标签和解释可以帮助用户遍历更多的搜索结果。然而，我们没有发现在这种情况下用户的系统意见变化的证据。我们认为这些结果可以帮助搜索引擎的设计师做出更 Informed 的设计决策。）
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Attacks-on-Tables-with-Entity-Swap"><a href="#Adversarial-Attacks-on-Tables-with-Entity-Swap" class="headerlink" title="Adversarial Attacks on Tables with Entity Swap"></a>Adversarial Attacks on Tables with Entity Swap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08650">http://arxiv.org/abs/2309.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aneta Koleva, Martin Ringsquandl, Volker Tresp</li>
<li>for: 这个论文主要是为了研究表格理解的语言模型（LLMs）的可靠性和安全性。</li>
<li>methods: 这篇论文使用了一种新的黑盒子攻击方法，即Entity-swap攻击，用于测试表格语言模型的可靠性。</li>
<li>results: 实验结果显示，提议的攻击方法可以导致表格语言模型的性能下降达70%。<details>
<summary>Abstract</summary>
The capabilities of large language models (LLMs) have been successfully applied in the context of table representation learning. The recently proposed tabular language models have reported state-of-the-art results across various tasks for table interpretation. However, a closer look into the datasets commonly used for evaluation reveals an entity leakage from the train set into the test set. Motivated by this observation, we explore adversarial attacks that represent a more realistic inference setup. Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models. In this paper, we propose an evasive entity-swap attack for the column type annotation (CTA) task. Our CTA attack is the first black-box attack on tables, where we employ a similarity-based sampling strategy to generate adversarial examples. The experimental results show that the proposed attack generates up to a 70% drop in performance.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的能力已成功应用于表示学习上。最近提出的表格语言模型已经在不同任务上报告了最佳结果。然而，通过审查通常用于评估的数据集，发现了实体泄露问题，即在训练集中出现的实体在测试集中也出现。这一观察导致我们研究了更加现实的攻击场景。在文本上进行了广泛研究的 adversarial 攻击，但目前没有targeting表格语言模型的攻击。本文提出了一种逃脱实体替换攻击（CTA）任务的黑盒攻击。我们使用相似性基于采样策略生成了反恶意示例。实验结果表明，我们的攻击可以导致表格语言模型的性能下降达70%。
</details></li>
</ul>
<hr>
<h2 id="Toward-responsible-face-datasets-modeling-the-distribution-of-a-disentangled-latent-space-for-sampling-face-images-from-demographic-groups"><a href="#Toward-responsible-face-datasets-modeling-the-distribution-of-a-disentangled-latent-space-for-sampling-face-images-from-demographic-groups" class="headerlink" title="Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups"></a>Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08442">http://arxiv.org/abs/2309.08442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parsa Rahimi, Christophe Ecabert, Sebastien Marcel</li>
<li>for: 本研究旨在生成具有均衡和可能是偏好的人脸识别模型训练、规范或评估用的偏好自由的合成数据集。</li>
<li>methods: 我们提出使用StyleGAN中的抽象投影模型来生成任何权重组合的人脸（例如，西班牙裔女性）。我们的实验表明可以效果地生成任何权重组合，并且人脸的身份不同于原始训练数据集。</li>
<li>results: 我们的实验结果表明，我们可以生成任何权重组合的人脸，并且人脸的身份不同于原始训练数据集。此外，我们还发布了源代码。<details>
<summary>Abstract</summary>
Recently, it has been exposed that some modern facial recognition systems could discriminate specific demographic groups and may lead to unfair attention with respect to various facial attributes such as gender and origin. The main reason are the biases inside datasets, unbalanced demographics, used to train theses models. Unfortunately, collecting a large-scale balanced dataset with respect to various demographics is impracticable.   In this paper, we investigate as an alternative the generation of a balanced and possibly bias-free synthetic dataset that could be used to train, to regularize or to evaluate deep learning-based facial recognition models. We propose to use a simple method for modeling and sampling a disentangled projection of a StyleGAN latent space to generate any combination of demographic groups (e.g. $hispanic-female$). Our experiments show that we can synthesis any combination of demographic groups effectively and the identities are different from the original training dataset. We also released the source code.
</details>
<details>
<summary>摘要</summary>
最近，有些现代人脸识别系统的问题在社会中引起了关注，即这些系统可能会对某些民族或性别进行不公正的待遇。主要的原因是训练模型时使用的数据集中含有偏见，人口结构不均衡。然而，收集大规模的均衡数据集是不现实的。在这篇论文中，我们提出了一种代替方案：通过使用简单的方法模拟和采样StyleGAN的积分空间，生成任何民族或性别组合（如《hispanic-female》）。我们的实验表明，我们可以有效地生成任何组合，并且生成的人脸不同于原始训练数据集。我们还发布了源代码。
</details></li>
</ul>
<hr>
<h2 id="Learning-by-Self-Explaining"><a href="#Learning-by-Self-Explaining" class="headerlink" title="Learning by Self-Explaining"></a>Learning by Self-Explaining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08395">http://arxiv.org/abs/2309.08395</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abusufyanvu/6S191_MIT_DeepLearning">https://github.com/abusufyanvu/6S191_MIT_DeepLearning</a></li>
<li>paper_authors: Wolfgang Stammer, Felix Friedrich, David Steinmann, Hikaru Shindo, Kristian Kersting</li>
<li>for: The paper aims to improve the learning process of artificial intelligence (AI) models by incorporating self-explaining mechanisms, which are inspired by human psychology and have been neglected in current AI research.</li>
<li>methods: The proposed Learning by Self-Explaining (LSX) paradigm involves a learning module performing a base task and providing explanations for its decisions, which are then evaluated by an internal critic module. The learner is refined with the critic’s feedback, and the loop is repeated as needed. The paper provides distinct instantiations of LSX for two different learner models.</li>
<li>results: The paper shows that LSX not only boosts the generalization abilities of AI models, particularly in small-data regimes, but also aids in mitigating the influence of confounding factors and leads to more task-specific and faithful model explanations. The results provide experimental evidence of the potential of self-explaining within the learning phase of an AI model.Here are the three points in Simplified Chinese text:</li>
<li>for: 本研究旨在通过人类智能发现的自我解释机制，提高人工智能（AI）模型的学习过程。</li>
<li>methods: 提议的学习 by Self-Explaining（LSX）方法包括一个学习模块（学习者）完成基础任务，并提供解释其决策的。内部批评模块接着评估这些解释的质量，并将学习者通过批评反馈进行改进。</li>
<li>results: 研究表明，LSX不仅提高了AI模型在小数据 regime下的泛化能力，而且帮助降低干扰因素的影响，并导致更任务特定和 faithful 的模型解释。结果提供了实验证明自我解释在AI模型学习阶段的潜在力。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) research has a long track record of drawing inspirations from findings from biology, in particular human intelligence. In contrast to current AI research that mainly treats explanations as a means for model inspection, a somewhat neglected finding from human psychology is the benefit of self-explaining in an agents' learning process. Motivated by this, we introduce a novel learning paradigm, termed Learning by Self-Explaining (LSX). The underlying idea is that a learning module (learner) performs a base task, e.g. image classification, and provides explanations to its decisions. An internal critic module next evaluates the quality of these explanations given the original task. Finally, the learner is refined with the critic's feedback and the loop is repeated as required. The intuition behind this is that an explanation is considered "good" if the critic can perform the same task given the respective explanation. Despite many implementation possibilities the structure of any LSX instantiation can be taxonomized based on four learning modules which we identify as: Fit, Explain, Reflect and Revise. In our work, we provide distinct instantiations of LSX for two different learner models, each illustrating different choices for the various LSX components. We broadly evaluate these on several datasets and show that Learning by Self-Explaining not only boosts the generalization abilities of AI models, particularly in small-data regimes, but also aids in mitigating the influence of confounding factors, as well as leading to more task specific and faithful model explanations. Overall, our results provide experimental evidence of the potential of self-explaining within the learning phase of an AI model.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）研究有一长时间的传统是从生物发现中翔生新想法，特别是人类智能。与当前AI研究主要视解释为模型检查的工具而言，一种受欢迎的发现来自人类心理学是自我解释在智能代理人学习过程中的利好。为了推广这一想法，我们介绍了一种新的学习方法，称为自我解释学习（LSX）。这个想法的基本思想是，一个学习模块（学习者）在完成基础任务（例如图像分类）后，对自己的决策提供解释。一个内部批评模块（批评者）然后评估这些解释的质量，基于原始任务。最后，学习者通过批评者的反馈进行改进，并重复这个过程。我们认为，一个解释是“好”的，如果批评者可以通过该解释完成同样的任务。在我们的工作中，我们提供了不同的LSX实现方式，每个实现方式都是基于四个学习模块：适应、解释、反思和修复。我们在不同的学习器模型上实现了这些模块，并对其进行了广泛的评估。我们发现，通过自我解释学习不仅可以提高AI模型的总体化能力，特别是在小数据情况下，还可以减少干扰因素的影响，以及导致更任务特定和 faithful 的解释。总的来说，我们的结果提供了实验证据，证明了自我解释在智能代理人学习阶段的潜在力量。
</details></li>
</ul>
<hr>
<h2 id="MAPLE-Mobile-App-Prediction-Leveraging-Large-Language-model-Embeddings"><a href="#MAPLE-Mobile-App-Prediction-Leveraging-Large-Language-model-Embeddings" class="headerlink" title="MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings"></a>MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08648">http://arxiv.org/abs/2309.08648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonchanok Khaokaew, Hao Xue, Flora D. Salim</li>
<li>for: 这篇论文旨在预测移动应用程序的使用情况，以提高应用程序的使用体验和功能性。</li>
<li>methods: 该论文提出了一种基于大语言模型（LLM）的移动应用程序预测模型（MAPLE），通过利用 LLM 来准确预测应用程序的使用情况。</li>
<li>results: 经过对两个公共数据集的严格测试，MAPLE 模型能够准确地捕捉用户行为的复杂特征和上下文，并在不同情况下保持稳定性。这些结果证明了 MAPLE 模型在不同场景下的多样性和可靠性。<details>
<summary>Abstract</summary>
Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields.
</details>
<details>
<summary>摘要</summary>
尽管移动应用的快速发展，预测应用使用仍然是一项具有挑战性的任务，因为用户行为很复杂， Contexts 也在不断发展。为解决这些问题，这篇论文提出了 Mobile App Prediction Leveraging Large Language Model Embeddings（MAPLE）模型。这种创新的方法利用大型自然语言模型（LLMs）来准确预测应用使用。经过严谨的测试两个公共数据集，MAPLE 的 robust results 表明它可以准确地理解用户行为和上下文。这些结果也证明了 MAPLE 在不同情况下的 universality 和灵活性。虽然它的主要设计是为应用预测，但结果还证明了 LLMs 在不同领域中的应用性。通过这项研究，我们强调了 LLMs 在应用使用预测方面的潜在力量，并建议它们在不同领域中的模式化人类行为的能力。
</details></li>
</ul>
<hr>
<h2 id="Intent-Detection-at-Scale-Tuning-a-Generic-Model-using-Relevant-Intents"><a href="#Intent-Detection-at-Scale-Tuning-a-Generic-Model-using-Relevant-Intents" class="headerlink" title="Intent Detection at Scale: Tuning a Generic Model using Relevant Intents"></a>Intent Detection at Scale: Tuning a Generic Model using Relevant Intents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08647">http://arxiv.org/abs/2309.08647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nichal Narotamo, David Aparicio, Tiago Mesquita, Mariana Almeida</li>
<li>for: 提高客户支持请求的意图预测精度，以提高客户服务系统的效率，让客户服务代表快速理解消息并根据需要优先级化回复。</li>
<li>methods:  combining a single generic model with a per-client list of relevant intents，以降低训练和维护成本，同时为客户提供个性化体验，适应客户的变化需求。</li>
<li>results: 比较industry-specific模型，final system exhibits significantly superior performance，demonstrating its flexibility and ability to cater to diverse client needs。<details>
<summary>Abstract</summary>
Accurately predicting the intent of customer support requests is vital for efficient support systems, enabling agents to quickly understand messages and prioritize responses accordingly. While different approaches exist for intent detection, maintaining separate client-specific or industry-specific models can be costly and impractical as the client base expands.   This work proposes a system to scale intent predictions to various clients effectively, by combining a single generic model with a per-client list of relevant intents. Our approach minimizes training and maintenance costs while providing a personalized experience for clients, allowing for seamless adaptation to changes in their relevant intents. Furthermore, we propose a strategy for using the clients relevant intents as model features that proves to be resilient to changes in the relevant intents of clients -- a common occurrence in production environments.   The final system exhibits significantly superior performance compared to industry-specific models, showcasing its flexibility and ability to cater to diverse client needs.
</details>
<details>
<summary>摘要</summary>
correctly 预测客户支持请求的意图是支持系统的关键，允许代表快速理解消息并根据优先级回复。 although  different 方法 exists for intent detection, maintaining separate client-specific or industry-specific models can be expensive and impractical as the client base expands.   This work proposes a system to scale intent predictions to various clients effectively, by combining a single generic model with a per-client list of relevant intents. Our approach minimizes training and maintenance costs while providing a personalized experience for clients, allowing for seamless adaptation to changes in their relevant intents. Furthermore, we propose a strategy for using the clients relevant intents as model features that proves to be resilient to changes in the relevant intents of clients -- a common occurrence in production environments.   The final system exhibits significantly superior performance compared to industry-specific models, showcasing its flexibility and ability to cater to diverse client needs.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="M-3-Net-Multilevel-Mixed-and-Multistage-Attention-Network-for-Salient-Object-Detection"><a href="#M-3-Net-Multilevel-Mixed-and-Multistage-Attention-Network-for-Salient-Object-Detection" class="headerlink" title="M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection"></a>M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08365">http://arxiv.org/abs/2309.08365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/I2-Multimedia-Lab/M3Net">https://github.com/I2-Multimedia-Lab/M3Net</a></li>
<li>paper_authors: Yao Yuan, Pan Gao, XiaoYang Tan</li>
<li>For: 提高精准的焦点对象检测精度（Salient Object Detection）* Methods: 提出多层次、混合和多stage的注意力网络（M$^3$Net），包括多层次交互块和混合注意力块，以及多Stage超vision策略，以提高预测精度。* Results: 在六个复杂的 dataset 上进行实验，提出的 M$^3$Net 已经超过了最近的 CNN 和 Transformer 基于的 SOD 艺术，按照四个纪录metric 进行评估。<details>
<summary>Abstract</summary>
Most existing salient object detection methods mostly use U-Net or feature pyramid structure, which simply aggregates feature maps of different scales, ignoring the uniqueness and interdependence of them and their respective contributions to the final prediction. To overcome these, we propose the M$^3$Net, i.e., the Multilevel, Mixed and Multistage attention network for Salient Object Detection (SOD). Firstly, we propose Multiscale Interaction Block which innovatively introduces the cross-attention approach to achieve the interaction between multilevel features, allowing high-level features to guide low-level feature learning and thus enhancing salient regions. Secondly, considering the fact that previous Transformer based SOD methods locate salient regions only using global self-attention while inevitably overlooking the details of complex objects, we propose the Mixed Attention Block. This block combines global self-attention and window self-attention, aiming at modeling context at both global and local levels to further improve the accuracy of the prediction map. Finally, we proposed a multilevel supervision strategy to optimize the aggregated feature stage-by-stage. Experiments on six challenging datasets demonstrate that the proposed M$^3$Net surpasses recent CNN and Transformer-based SOD arts in terms of four metrics. Codes are available at https://github.com/I2-Multimedia-Lab/M3Net.
</details>
<details>
<summary>摘要</summary>
现有的突出对象检测方法大多使用U-Net或特征峰结构，这些方法简单地聚合不同级别的特征图，忽略这些特征图的独特性和互相关系，以及它们对最终预测的贡献。为了解决这些问题，我们提议M$^3$Net，即多级混合多 stagel attention网络 для突出对象检测（SOD）。首先，我们提出了多尺度交互块，这里引入了交叉注意方法，以实现不同级别特征之间的交互，使高级特征导导低级特征学习，从而提高突出区域。其次，由于前一些Transformer基于SOD方法只是通过全局自注意来定位突出区域，而忽略了复杂对象的详细特征，我们提出了混合注意块。这个块组合了全局自注意和窗口自注意，以实现在全局和局部两个水平上模型对象上下文，以进一步提高预测矩阵的准确性。最后，我们提出了一种多级超vision策略，以逐步优化聚合特征的结果。实验结果表明，提案的M$^3$Net在六个复杂的数据集上超过了最近的CNN和Transformer基于SOD艺术，以四个纪录为评价指标。代码可以在https://github.com/I2-Multimedia-Lab/M3Net 中找到。
</details></li>
</ul>
<hr>
<h2 id="Data-Distribution-Bottlenecks-in-Grounding-Language-Models-to-Knowledge-Bases"><a href="#Data-Distribution-Bottlenecks-in-Grounding-Language-Models-to-Knowledge-Bases" class="headerlink" title="Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases"></a>Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08345">http://arxiv.org/abs/2309.08345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiheng Shu, Zhiwei Yu</li>
<li>for: 本研究旨在探讨语言模型（LM）在大规模知识库（KB）环境中的可靠性问题。</li>
<li>methods: 本研究采用了多种数据增强技术来提高LM的抗耗性和通用性。</li>
<li>results: 实验结果显示，even with 我们的数据增强技术，当前的LM技术在各种环境下表现不佳，尤其是面临不同语言变体和数据分布问题时。<details>
<summary>Abstract</summary>
Language models (LMs) have already demonstrated remarkable abilities in understanding and generating both natural and formal language. Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in "hallucinated" information. This paper is an experimental investigation aimed at uncovering the robustness challenges that LMs encounter when tasked with knowledge base question answering (KBQA). The investigation covers scenarios with inconsistent data distribution between training and inference, such as generalization to unseen domains, adaptation to various language variations, and transferability across different datasets. Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the LM is a promising technology, the robustness of the current form in dealing with complex environments is fragile and of limited practicality because of the data distribution issue. This calls for future research on data collection and LM learning paradims.
</details>
<details>
<summary>摘要</summary>
语言模型（LM）已经表现出了对自然语言和正式语言的理解和生成的很好的能力。然而，它们在大规模知识库（KB）中的集成仍然是一个未发掘的领域，这限制了应用程序的 semantic parsing 和 indulging in "hallucinated" information 等应用。这篇论文是一项实验性调查，旨在探讨语言模型在知识库问答（KBQA）中遇到的Robustness挑战。调查覆盖了训练和推理数据分布不均的场景，如泛化到未看过的领域、语言变化的适应以及不同数据集之间的传输性。我们的全面实验表明，即使使用我们提议的数据扩充技术，先进的小型和大型语言模型在多个维度上表现不佳。而当前的语言模型技术在复杂环境中的可靠性是脆弱的，这限制了它们的实际应用。这叫喊未来的研究投入数据收集和LM学习 парадиг。
</details></li>
</ul>
<hr>
<h2 id="Let’s-Predict-Who-Will-Move-to-a-New-Job"><a href="#Let’s-Predict-Who-Will-Move-to-a-New-Job" class="headerlink" title="Let’s Predict Who Will Move to a New Job"></a>Let’s Predict Who Will Move to a New Job</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08333">http://arxiv.org/abs/2309.08333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MarkipTheMudkip/in-class-project-2">https://github.com/MarkipTheMudkip/in-class-project-2</a></li>
<li>paper_authors: Rania Mkhinini Gahar, Adel Hidri, Minyar Sassi Hidri</li>
<li>for: The paper is written to discuss the use of machine learning (ML) to predict whether an applicant will search for a new job or stay with the company.</li>
<li>methods: The paper uses data pre-processing, data encoding, and several ML algorithms such as Random Forest (RF), Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting (XGBoost) to predict job mobility. The synthetic minority oversampling technique (SMOTE) is also used to retain minority classes.</li>
<li>results: The paper assesses the performance of the ML models using decision support metrics such as precision, recall, F1-Score, and accuracy.Here are the three points in Simplified Chinese text:</li>
<li>for: 本研究使用机器学习（ML）预测候选人是否将搜索新工作或留在公司。</li>
<li>methods: 本研究使用数据预处理、数据编码和多种ML算法（Random Forest、Logistic Regression、Decision Tree和eXtreme Gradient Boosting）预测工作流动。同时，使用Synthetic Minority Oversampling Technique（SMOTE）保留少数类。</li>
<li>results: 本研究使用决策支持指标（精度、准确率、F1-Score和准确率）评估ML模型的性能。<details>
<summary>Abstract</summary>
Any company's human resources department faces the challenge of predicting whether an applicant will search for a new job or stay with the company. In this paper, we discuss how machine learning (ML) is used to predict who will move to a new job. First, the data is pre-processed into a suitable format for ML models. To deal with categorical features, data encoding is applied and several MLA (ML Algorithms) are performed including Random Forest (RF), Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting (XGBoost). To improve the performance of ML models, the synthetic minority oversampling technique (SMOTE) is used to retain them. Models are assessed using decision support metrics such as precision, recall, F1-Score, and accuracy.
</details>
<details>
<summary>摘要</summary>
任何公司的人力资源部门面临着预测申请人员是否会寻找新工作的挑战。在这篇论文中，我们讨论了如何使用机器学习（ML）预测申请人员会离开公司。首先，数据进行了适应ML模型的处理。为处理 categorical 特征，数据编码是应用到了数据中。然后，我们使用了多种MLA（ML算法），包括随机森林（RF）、логистиック回归（LR）、决策树（DT）和极限梯度提升（XGBoost）。为了提高ML模型的性能，我们使用了人工少数样本填充技术（SMOTE）保留它们。模型的评估使用了决策支持度量标准，如准确率、回归率、F1-Score 和准确率。
</details></li>
</ul>
<hr>
<h2 id="Large-Intestine-3D-Shape-Refinement-Using-Point-Diffusion-Models-for-Digital-Phantom-Generation"><a href="#Large-Intestine-3D-Shape-Refinement-Using-Point-Diffusion-Models-for-Digital-Phantom-Generation" class="headerlink" title="Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation"></a>Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08289">http://arxiv.org/abs/2309.08289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaouther Mouheb, Mobina Ghojogh Nejad, Lavsen Dahal, Ehsan Samei, W. Paul Segars, Joseph Y. Lo</li>
<li>for:  precisely modeling the surface of the large intestine for virtual imaging trials</li>
<li>methods:  using geometric deep learning and denoising diffusion probabilistic models to refine segmentation results, and incorporating a state-of-the-art surface reconstruction model</li>
<li>results:  significantly improved surface representation compared to initial segmentation, with a 70% reduction in Chamfer distance, a 32% reduction in Hausdorff distance, and a 6% reduction in Earth Mover’s distance<details>
<summary>Abstract</summary>
Accurate 3D modeling of human organs plays a crucial role in building computational phantoms for virtual imaging trials. However, generating anatomically plausible reconstructions of organ surfaces from computed tomography scans remains challenging for many structures in the human body. This challenge is particularly evident when dealing with the large intestine. In this study, we leverage recent advancements in geometric deep learning and denoising diffusion probabilistic models to refine the segmentation results of the large intestine. We begin by representing the organ as point clouds sampled from the surface of the 3D segmentation mask. Subsequently, we employ a hierarchical variational autoencoder to obtain global and local latent representations of the organ's shape. We train two conditional denoising diffusion models in the hierarchical latent space to perform shape refinement. To further enhance our method, we incorporate a state-of-the-art surface reconstruction model, allowing us to generate smooth meshes from the obtained complete point clouds. Experimental results demonstrate the effectiveness of our approach in capturing both the global distribution of the organ's shape and its fine details. Our complete refinement pipeline demonstrates remarkable enhancements in surface representation compared to the initial segmentation, reducing the Chamfer distance by 70%, the Hausdorff distance by 32%, and the Earth Mover's distance by 6%. By combining geometric deep learning, denoising diffusion models, and advanced surface reconstruction techniques, our proposed method offers a promising solution for accurately modeling the large intestine's surface and can easily be extended to other anatomical structures.
</details>
<details>
<summary>摘要</summary>
准确的3D人体器官模型在计算机phantom中扮演了关键角色。然而，从计算机扫描图像中生成人体器官表面的准确重建仍然是许多人体器官的挑战。特别是对大肠的重建。在这项研究中，我们利用最新的几何深度学习和减噪概率模型来改进大肠的分 segmentation结果。我们首先将器官表示为点云，从3D分 segmentation掩模中采样的表面。然后，我们使用层次的自变量autoencoder来获得全局和局部的准确表达。我们在层次的准确空间中训练了两个条件减噪液体模型，以进行形态纠正。为了进一步增强我们的方法，我们添加了当前的Surface reconstruction模型，以生成完整的点云。实验结果表明，我们的方法可以准确地捕捉大肠的全局分布和细节。我们的完整的纠正管道可以大幅提高表面的表达，减少Chamfer距离70%，减少 Hausdorff距离32%，减少地球货物距离6%。通过结合几何深度学习、减噪液体模型和高级Surface reconstruction技术，我们提出了一种准确地模型大肠表面的方法，可以轻松扩展到其他 анатомиче结构。
</details></li>
</ul>
<hr>
<h2 id="Cure-the-headache-of-Transformers-via-Collinear-Constrained-Attention"><a href="#Cure-the-headache-of-Transformers-via-Collinear-Constrained-Attention" class="headerlink" title="Cure the headache of Transformers via Collinear Constrained Attention"></a>Cure the headache of Transformers via Collinear Constrained Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08646">http://arxiv.org/abs/2309.08646</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luban-agi/coca">https://github.com/luban-agi/coca</a></li>
<li>paper_authors: Shiyi Zhu, Jing Ye, Wei Jiang, Qi Zhang, Yifan Wu, Jianguo Li</li>
<li>for: 本研究旨在解决 transformer 模型中快速升级的问题，提高 extrapolating 性能。</li>
<li>methods: 我们提出了一种新的自注意力结构 named Collinear Constrained Attention (CoCA)，可以轻松地与现有的 extrapolation 和 interpoltion 方法集成。</li>
<li>results: 我们在推理阶段可以达到 16 倍至 24 倍的序列长度的极佳推理性能，无需 fine-tuning。同时，我们还提高了 CoCA 的计算和空间效率，确保其实用性。<details>
<summary>Abstract</summary>
As the rapid progression of practical applications based on Large Language Models continues, the importance of extrapolating performance has grown exponentially in the research domain. In our study, we identified an anomalous behavior in Transformer models that had been previously overlooked, leading to a chaos around closest tokens which carried the most important information. We've coined this discovery the "headache of Transformers". To address this at its core, we introduced a novel self-attention structure named Collinear Constrained Attention (CoCA). This structure can be seamlessly integrated with existing extrapolation, interpolation methods, and other optimization strategies designed for traditional Transformer models. We have achieved excellent extrapolating performance even for 16 times to 24 times of sequence lengths during inference without any fine-tuning on our model. We have also enhanced CoCA's computational and spatial efficiency to ensure its practicality. We plan to open-source CoCA shortly. In the meantime, we've made our code available in the appendix for reappearing experiments.
</details>
<details>
<summary>摘要</summary>
As the rapid progression of practical applications based on Large Language Models continues, the importance of extrapolating performance has grown exponentially in the research domain. In our study, we identified an anomalous behavior in Transformer models that had been previously overlooked, leading to a chaos around closest tokens which carried the most important information. We've coined this discovery the "headache of Transformers". To address this at its core, we introduced a novel self-attention structure named Collinear Constrained Attention (CoCA). This structure can be seamlessly integrated with existing extrapolation, interpolation methods, and other optimization strategies designed for traditional Transformer models. We have achieved excellent extrapolating performance even for 16 times to 24 times of sequence lengths during inference without any fine-tuning on our model. We have also enhanced CoCA's computational and spatial efficiency to ensure its practicality. We plan to open-source CoCA shortly. In the meantime, we've made our code available in the appendix for reappearing experiments.Here's the text in Traditional Chinese:为了推进大型语言模型的实用应用，研究领域中对于Transformer模型的推敲性能的重要性在不断增长。在我们的研究中，我们发现Transformer模型中的一个问题，即最重要的token附近的问题，导致了一个“Transformer的头痛”。为了解决这个问题的核心，我们提出了一个名为Collinear Constrained Attention（CoCA）的新型自我对应结构。这个结构可以与传统Transformer模型中的推敲、 interpolating 方法和其他优化策略一起使用。我们在推敲时可以 дости得出excel 的表现，而且不需要任何 fine-tuning。此外，我们还对CoCA进行了计算和空间的最佳化，以确保其实用性。我们计划将CoCA shortly 开源。在等待开源之前，我们的代码已经在附录中公开，供大家进行重复实验。
</details></li>
</ul>
<hr>
<h2 id="Quantitative-and-Qualitative-Evaluation-of-Reinforcement-Learning-Policies-for-Autonomous-Vehicles"><a href="#Quantitative-and-Qualitative-Evaluation-of-Reinforcement-Learning-Policies-for-Autonomous-Vehicles" class="headerlink" title="Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles"></a>Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08254">http://arxiv.org/abs/2309.08254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Ferrarotti, Massimiliano Luca, Gabriele Santin, Giorgio Previati, Gianpiero Mastinu, Elena Campi, Lorenzo Uccello, Antonino Albanese, Praveen Zalaya, Alessandro Roccasalva, Bruno Lepri</li>
<li>for: 优化交通流动在不断发展的交通环境中是非常重要，特别是在自动驾驶车辆（AV）与人类驾驶车辆共存的场景下。本文提出了一种使用Proximal Policy Optimization（PPO）束规学习算法优化AV的选择。我们学习了一个策略，以减少交通堵塞（即在enario中的时间）和减少污染。</li>
<li>methods: 我们使用了PPO算法来学习一个策略，并通过实验分析表明了我们的方法可以减少时间和污染水平。此外，我们使用了一个前沿的cockpit来评估学习的策略在实际情况下的性能。</li>
<li>results: 我们的实验结果表明，我们的方法可以减少时间和污染水平。此外，我们对参与了人类参与者使用的模拟器进行了评估，发现人驾驶车辆在优化AV动态时受益。此外，参与者们表示场景中80%的AV比20%的AV更安全和更流畅。<details>
<summary>Abstract</summary>
Optimizing traffic dynamics in an evolving transportation landscape is crucial, particularly in scenarios where autonomous vehicles (AVs) with varying levels of autonomy coexist with human-driven cars. This paper presents a novel approach to optimizing choices of AVs using Proximal Policy Optimization (PPO), a reinforcement learning algorithm. We learned a policy to minimize traffic jams (i.e., minimize the time to cross the scenario) and to minimize pollution in a roundabout in Milan, Italy. Through empirical analysis, we demonstrate that our approach can reduce time and pollution levels. Furthermore, we qualitatively evaluate the learned policy using a cutting-edge cockpit to assess its performance in near-real-world conditions. To gauge the practicality and acceptability of the policy, we conducted evaluations with human participants using the simulator, focusing on a range of metrics like traffic smoothness and safety perception. In general, our findings show that human-driven vehicles benefit from optimizing AVs dynamics. Also, participants in the study highlighted that the scenario with 80\% AVs is perceived as safer than the scenario with 20\%. The same result is obtained for traffic smoothness perception.
</details>
<details>
<summary>摘要</summary>
优化交通征动在发展中的交通环境中是非常重要，特别在自动驾驶车辆（AV）与人类驾驶车辆共存的场景下。这篇论文提出了一种使用 proximal policy optimization（PPO）算法来优化AV的选择。我们学习了一种缩减交通堵塞（即减少场景内的时间）和减少污染的策略，并在米兰市的一个环境中进行了实验性分析。我们的研究表明，我们的方法可以减少时间和污染水平。此外，我们使用 cutting-edge 车辆控制台进行了质量评估，以评估我们学习的策略在实际 Condition 下的性能。此外，我们对人类参与者使用 simulator 进行了评估，并考虑了一系列指标，如交通畅通性和安全感。我们的发现表明，人类驾驶车辆受益于优化AV征动，并且参与者认为80% AV scenario 比20% AV scenario 更安全和更畅通。
</details></li>
</ul>
<hr>
<h2 id="A-Geometric-Perspective-on-Autoencoders"><a href="#A-Geometric-Perspective-on-Autoencoders" class="headerlink" title="A Geometric Perspective on Autoencoders"></a>A Geometric Perspective on Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08247">http://arxiv.org/abs/2309.08247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clementchadebec/geometric_perspective_on_vaes">https://github.com/clementchadebec/geometric_perspective_on_vaes</a></li>
<li>paper_authors: Yonghyeon Lee</li>
<li>for: 该论文探讨了自动编码器框架中的几何方面，尽管这一方面在论文中得到了较少的关注。</li>
<li>methods: 该论文使用了高维数据点集合，以及一种低维拟合 manifold 的学习方法，同时学习 manifold 和坐标图。</li>
<li>results: 该论文发现了多个自动编码器可以对同一个数据集进行学习，并且这些自动编码器可能会生成错误的拟合 manifold 和扭曲的坐标图表示。<details>
<summary>Abstract</summary>
This paper presents the geometric aspect of the autoencoder framework, which, despite its importance, has been relatively less recognized. Given a set of high-dimensional data points that approximately lie on some lower-dimensional manifold, an autoencoder learns the \textit{manifold} and its \textit{coordinate chart}, simultaneously. This geometric perspective naturally raises inquiries like "Does a finite set of data points correspond to a single manifold?" or "Is there only one coordinate chart that can represent the manifold?". The responses to these questions are negative, implying that there are multiple solution autoencoders given a dataset. Consequently, they sometimes produce incorrect manifolds with severely distorted latent space representations. In this paper, we introduce recent geometric approaches that address these issues.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文探讨了自动编码器框架中的几何方面，这一方面尚未得到足够的认可，虽然它对于自动编码器的学习和应用非常重要。给定一个高维数据点集，这些数据点约束在一个lower维度的拟合上，自动编码器就会学习这个拟合和它的坐标系。这个几何视角自然地引出了一些问题，例如"finite数据点集是否对应一个唯一的拟合?"或"是否只有一个坐标系可以表示拟合?"。答案是否定的，表示给定一个数据集，存在多个解的自动编码器，这些自动编码器可能会生成错误的拟合和扭曲的几何空间表示。在这篇论文中，我们介绍了最新的几何方法，以解决这些问题。
</details></li>
</ul>
<hr>
<h2 id="VERSE-Virtual-Gradient-Aware-Streaming-Lifelong-Learning-with-Anytime-Inference"><a href="#VERSE-Virtual-Gradient-Aware-Streaming-Lifelong-Learning-with-Anytime-Inference" class="headerlink" title="VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime Inference"></a>VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08227">http://arxiv.org/abs/2309.08227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumya Banerjee, Vinay K. Verma, Avideep Mukherjee, Deepak Gupta, Vinay P. Namboodiri, Piyush Rai</li>
<li>for: 本研究旨在提出一种基于流处理的智能机器学习方法，可以在动态不确定环境中不断学习而不忘记之前学习的知识。</li>
<li>methods: 我们提出了一种基于虚拟梯度的 continual representation learning 方法，以防止忘记现象，并使用 exponential-moving-average-based semantic memory 进一步提高性能。</li>
<li>results: 我们的方法在多个 dataset 上进行了广泛的实验，并证明了与现有方法相比的优异性能。<details>
<summary>Abstract</summary>
Lifelong learning, also referred to as continual learning, is the problem of training an AI agent continuously while also preventing it from forgetting its previously acquired knowledge. Most of the existing methods primarily focus on lifelong learning within a static environment and lack the ability to mitigate forgetting in a quickly-changing dynamic environment. Streaming lifelong learning is a challenging setting of lifelong learning with the goal of continuous learning in a dynamic non-stationary environment without forgetting. We introduce a novel approach to lifelong learning, which is streaming, requires a single pass over the data, can learn in a class-incremental manner, and can be evaluated on-the-fly (anytime inference). To accomplish these, we propose virtual gradients for continual representation learning to prevent catastrophic forgetting and leverage an exponential-moving-average-based semantic memory to further enhance performance. Extensive experiments on diverse datasets demonstrate our method's efficacy and superior performance over existing methods.
</details>
<details>
<summary>摘要</summary>
人生学习，也称为不断学习，是训练AI机器人的问题，以及防止它忘记之前学习的知识。现有的方法主要集中在静止环境下的生命学习，缺乏适应快速变化的动态环境中减弱忘记的能力。流动生命学习是生命学习的挑战 Setting，旨在在动态不站ARY环境中不断学习，而无需忘记之前学习的知识。我们提出了一种新的生命学习方法，即流动学习，只需一次遍历数据，可以在类增量学习方式下进行学习，并可以在实时（任何时候）进行评估。为了实现这些目标，我们提出了虚拟梯度为持续表征学习防止悖论忘记，并利用加权平均值基于semantic Memory来进一步提高性能。我们在多种 datasets上进行了广泛的实验，并证明了我们的方法的有效性和超越现有方法的表现。
</details></li>
</ul>
<hr>
<h2 id="Using-Large-Language-Model-to-Solve-and-Explain-Physics-Word-Problems-Approaching-Human-Level"><a href="#Using-Large-Language-Model-to-Solve-and-Explain-Physics-Word-Problems-Approaching-Human-Level" class="headerlink" title="Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level"></a>Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08182">http://arxiv.org/abs/2309.08182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingzhe Ding, Yan Cen, Xinyuan Wei</li>
<li>for: 这paper的目的是证明大语言模型（LLM）可以解决物理问题，不仅是文本问题。</li>
<li>methods: 这paper使用OpenAI的GPT3.5模型，通过zero-shot learning和few-shot learning来解决物理问题。</li>
<li>results: GPT3.5可以自动解决49.3%的问题，并且可以summarize问题的知识和提供相关的解释。<details>
<summary>Abstract</summary>
Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems, whose solution requires calculation and inference based on prior physical knowledge. We collect and annotate the first physics word problem dataset-PhysQA, which contains over 1000 junior high school physics word problems (covering Kinematics, Mass&Density, Mechanics, Heat, Electricity). Then we use OpenAI' s GPT3.5 to generate the answer of these problems and found that GPT3.5 could automatically solve 49.3% of the problems through zero-shot learning and 73.2% through few-shot learning. This result demonstrates that by using similar problems and their answers as prompt, LLM could solve elementary physics word problems approaching human level performance. In addition to solving problems, GPT3.5 can also summarize the knowledge or topics covered by the problems, provide relevant explanations, and generate new physics word problems based on the input. Our work is the first research to focus on the automatic solving, explanation, and generation of physics word problems across various types and scenarios, and we achieve an acceptable and state-of-the-art accuracy. This underscores the potential of LLMs for further applications in secondary education.
</details>
<details>
<summary>摘要</summary>
我们的工作表明，大型语言模型（LLM）预训练在文本上可以解决纯数学问题，以及物理问题，其解决需要计算和推理基于先前的物理知识。我们收集和标注了首个物理问题集合-PhysQA，包含了1000多个初中物理问题（涵盖运动、质量和密度、力学、热和电）。然后我们使用OpenAI的GPT3.5来生成问题的答案，发现GPT3.5可以通过零批学习解决49.3%的问题和通过几批学习解决73.2%的问题。这一结果表明，通过使用相似的问题和答案作为提示，LLM可以解决初中物理问题，接近人类水平性能。此外，GPT3.5还可以概括问题中所覆盖的知识和主题，提供相关的解释，并生成基于输入的新的物理问题。我们的工作是首次关注自动解决、概括和生成物理问题的研究，并实现了可接受的和领先的准确率。这一结果强调了LLM的潜在应用在初等教育中。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Invariances-via-Neural-Network-Pruning"><a href="#Unveiling-Invariances-via-Neural-Network-Pruning" class="headerlink" title="Unveiling Invariances via Neural Network Pruning"></a>Unveiling Invariances via Neural Network Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08171">http://arxiv.org/abs/2309.08171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek Xu, Yizhou Sun, Wei Wang</li>
<li>for: 这篇论文是为了学习数据依赖的不变性而写的。</li>
<li>methods: 这篇论文使用了退化 neural network 来学习数据依赖的不变性，并通过剔除来捕捉这些不变性。</li>
<li>results: 这篇论文的结果表明，使用这种方法可以在视觉和表格数据集上以更高效和更高准确性进行预测。<details>
<summary>Abstract</summary>
Invariance describes transformations that do not alter data's underlying semantics. Neural networks that preserve natural invariance capture good inductive biases and achieve superior performance. Hence, modern networks are handcrafted to handle well-known invariances (ex. translations). We propose a framework to learn novel network architectures that capture data-dependent invariances via pruning. Our learned architectures consistently outperform dense neural networks on both vision and tabular datasets in both efficiency and effectiveness. We demonstrate our framework on multiple deep learning models across 3 vision and 40 tabular datasets.
</details>
<details>
<summary>摘要</summary>
“几何描述不变数据的本质不变。神经网络，保持自然的几何不变，可以捕捉好的归化假设，实现更好的性能。因此，现代网络通常是以知道的几何不变为设计。我们提出了一个架构，可以透过剪裁来学习资料相对的几何不变。我们的学习架构在多个深度学习模型和多个视觉和数据集上表现出色，并且在效率和有效性两方面具有优秀的表现。”
</details></li>
</ul>
<hr>
<h2 id="To-Predict-or-to-Reject-Causal-Effect-Estimation-with-Uncertainty-on-Networked-Data"><a href="#To-Predict-or-to-Reject-Causal-Effect-Estimation-with-Uncertainty-on-Networked-Data" class="headerlink" title="To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data"></a>To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08165">http://arxiv.org/abs/2309.08165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hechuan Wen, Tong Chen, Li Kheng Chai, Shazia Sadiq, Kai Zheng, Hongzhi Yin</li>
<li>for: 这篇论文旨在提出一个能够处理对称网络观察数据的不确定性的数据科学推理框架，以便更加可靠地估计个体水平的治疗效应。</li>
<li>methods: 这篇论文使用了深度kernel学习（GraphDKL）框架，具有体积约束（Lipschitz constraint），用于模型预测不确定性，并使用 Gaussian 过程来识别不可靠的估计。</li>
<li>results: 根据实验结果，这篇论文提出的方法能够更好地处理对称网络观察数据的不确定性，并且比传统方法更加可靠地估计个体水平的治疗效应。<details>
<summary>Abstract</summary>
Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. Nevertheless, this potential risk of individual-level treatment effect estimation on networked data has been largely under-explored. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework with Lipschitz constraint to model the prediction uncertainty with Gaussian process and identify unreliable estimations. To the best of our knowledge, GraphDKL is the first framework to tackle the violation of positivity assumption when performing causal effect estimation with graphs. With extensive experiments, we demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Investigating-the-Applicability-of-Self-Assessment-Tests-for-Personality-Measurement-of-Large-Language-Models"><a href="#Investigating-the-Applicability-of-Self-Assessment-Tests-for-Personality-Measurement-of-Large-Language-Models" class="headerlink" title="Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models"></a>Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08163">http://arxiv.org/abs/2309.08163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshat Gupta, Xiaoyang Song, Gopala Anumanchipalli</li>
<li>for: 这三篇研究旨在测量大语言模型（LLM）的个性，使用人类行为研究工具来量化LLM的行为。</li>
<li>methods: 这三篇研究使用人类自我评估测试来测量LLM的个性，并使用不同的提问来测量同一个LLM的个性。</li>
<li>results: 研究发现，不同的提问会导致LLM的个性分数异常大，表明人性自我评估测试不适用于LLM。此外，研究还发现，提问顺序对测量LLM个性的答案有影响。<details>
<summary>Abstract</summary>
As large language models (LLM) evolve in their capabilities, various recent studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is the measurement of "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for personality measurement of LLMs. Since most of the self-assessment tests exist in the form of multiple choice question (MCQ) questions, we argue that the scores should also be robust to not just the prompt template but also the order in which the options are presented. This test unsurprisingly reveals that the answers to the self-assessment tests are not robust to the order of the options. These simple tests, done on ChatGPT and Llama2 models show that self-assessment personality tests created for humans are not appropriate for measuring personality in LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的能力不断进步，latest studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is measuring the "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead to very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for personality measurement of LLMs. Since most self-assessment tests exist in the form of multiple choice questions (MCQ), we argue that the scores should also be robust to not just the prompt template but also the order in which the options are presented. This test unsurprisingly reveals that the answers to the self-assessment tests are not robust to the order of the options. These simple tests, done on ChatGPT and Llama2 models, show that self-assessment personality tests created for humans are not appropriate for measuring personality in LLMs.
</details></li>
</ul>
<hr>
<h2 id="Find-What-You-Want-Learning-Demand-conditioned-Object-Attribute-Space-for-Demand-driven-Navigation"><a href="#Find-What-You-Want-Learning-Demand-conditioned-Object-Attribute-Space-for-Demand-driven-Navigation" class="headerlink" title="Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation"></a>Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08138">http://arxiv.org/abs/2309.08138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongcheng Wang, Andy Guan Hong Chen, Xiaoqi Li, Mingdong Wu, Hao Dong<br>for: 提高人工智能Agent在Visual Object Navigation（VON）任务中的准确性和效率，特别是在实际场景中，用户可能不知道场景中的物品或者指定的物品不存在。methods: 提议使用Demand-driven Navigation（DDN）方法，将用户的需求作为任务指令，以寻找匹配用户需求的物品。DDN方法使用大语言模型中的共同知识来提取对象的文本特征，并使用Contrastive Language-Image Pre-training（CLIP）将文本特征与视觉特征相互对应。通过 incorporating 视觉特征作为先知，提高导航过程的准确性。results: 实验结果表明，DDN方法可以提高Agent的导航性能，并在AI2Thor中与常用的VON方法进行比较，得到更好的结果。<details>
<summary>Abstract</summary>
The task of Visual Object Navigation (VON) involves an agent's ability to locate a particular object within a given scene. In order to successfully accomplish the VON task, two essential conditions must be fulfilled:1) the user must know the name of the desired object; and 2) the user-specified object must actually be present within the scene. To meet these conditions, a simulator can incorporate pre-defined object names and positions into the metadata of the scene. However, in real-world scenarios, it is often challenging to ensure that these conditions are always met. Human in an unfamiliar environment may not know which objects are present in the scene, or they may mistakenly specify an object that is not actually present. Nevertheless, despite these challenges, human may still have a demand for an object, which could potentially be fulfilled by other objects present within the scene in an equivalent manner. Hence, we propose Demand-driven Navigation (DDN), which leverages the user's demand as the task instruction and prompts the agent to find the object matches the specified demand. DDN aims to relax the stringent conditions of VON by focusing on fulfilling the user's demand rather than relying solely on predefined object categories or names. We propose a method first acquire textual attribute features of objects by extracting common knowledge from a large language model. These textual attribute features are subsequently aligned with visual attribute features using Contrastive Language-Image Pre-training (CLIP). By incorporating the visual attribute features as prior knowledge, we enhance the navigation process. Experiments on AI2Thor with the ProcThor dataset demonstrate the visual attribute features improve the agent's navigation performance and outperform the baseline methods commonly used in VON.
</details>
<details>
<summary>摘要</summary>
视觉对象导航（VON）任务需要一个代理人能够在给定场景中找到特定的对象。为了成功完成VON任务，需满足两个必要条件：1）用户必须知道想要的对象的名称；2）用户指定的对象必须实际存在在场景中。为了满足这两个条件，一个模拟器可以将预定义的对象名称和位置添加到场景的元数据中。然而，在实际场景中，经常存在一些挑战。人们在不熟悉的环境中可能不知道场景中的对象，或者可能指定不存在的对象。然而，尽管存在这些挑战，人们仍然可能有对某个对象的需求，这可能可以通过场景中其他对象来满足。因此，我们提出了需求驱动导航（DDN），它利用用户的需求作为任务指令，并让代理人找到匹配用户需求的对象。DDN通过放弃VON中的严格条件，而转而ocus on 满足用户需求，从而提高导航性能。我们提出了一种方法，首先从大语言模型中提取对象的文本特征，然后将这些特征与图像特征进行对比，使用Contrastive Language-Image Pre-training（CLIP）。通过将视觉特征作为先知，我们提高了导航过程。在AI2Thor上使用ProcThor数据集进行实验，我们发现视觉特征可以提高代理人的导航性能，并超越常用的VON基线方法。
</details></li>
</ul>
<hr>
<h2 id="“I’m-Not-Confident-in-Debiasing-AI-Systems-Since-I-Know-Too-Little”-Teaching-AI-Creators-About-Gender-Bias-Through-Hands-on-Tutorials"><a href="#“I’m-Not-Confident-in-Debiasing-AI-Systems-Since-I-Know-Too-Little”-Teaching-AI-Creators-About-Gender-Bias-Through-Hands-on-Tutorials" class="headerlink" title="“I’m Not Confident in Debiasing AI Systems Since I Know Too Little”: Teaching AI Creators About Gender Bias Through Hands-on Tutorials"></a>“I’m Not Confident in Debiasing AI Systems Since I Know Too Little”: Teaching AI Creators About Gender Bias Through Hands-on Tutorials</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08121">http://arxiv.org/abs/2309.08121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyrie Zhixuan Zhou, Jiaxun Cao, Xiaowen Yuan, Daniel E. Weissglass, Zachary Kilhoffer, Madelyn Rose Sanfilippo, Xin Tong</li>
<li>for: 帮助AI创造者了解和 Mitigate gender bias in AI systems, improving user experience and reducing injustices and mental harm to women.</li>
<li>methods: 使用实践 oriented hands-on tutorials to raise AI creators’ awareness of gender bias in AI and enhance their knowledge of sources of gender bias and debiasing techniques.</li>
<li>results:  tutorials were evaluated with 18 AI creators, including AI researchers, AI industrial practitioners, and students who had learned AI, and their improved awareness and knowledge demonstrated the effectiveness of the tutorials.<details>
<summary>Abstract</summary>
Gender bias is rampant in AI systems, causing bad user experience, injustices, and mental harm to women. School curricula fail to educate AI creators on this topic, leaving them unprepared to mitigate gender bias in AI. In this paper, we designed hands-on tutorials to raise AI creators' awareness of gender bias in AI and enhance their knowledge of sources of gender bias and debiasing techniques. The tutorials were evaluated with 18 AI creators, including AI researchers, AI industrial practitioners (i.e., developers and product managers), and students who had learned AI. Their improved awareness and knowledge demonstrated the effectiveness of our tutorials, which have the potential to complement the insufficient AI gender bias education in CS/AI courses. Based on the findings, we synthesize design implications and a rubric to guide future research, education, and design efforts.
</details>
<details>
<summary>摘要</summary>
gender bias 在 AI 系统中严重存在，导致用户体验差、不公正和对女性造成心理伤害。学 curricula 不教育 AI 创建者关于这个话题，留下他们无准备 mitigate gender bias 在 AI 中。在这篇论文中，我们设计了有手验utorials，以提高 AI 创建者对 gender bias 在 AI 中的意识和debiasing 技术的知识。我们的 tutorials 被评估了 18 名 AI 创建者，包括 AI 研究人员、 AI 工业实践者（即开发人员和产品经理）以及学生们，他们已经学习 AI。他们的改善意识和知识表明了我们的 tutorials 的效果，这些 tutorials 有可能补充 CS/AI 课程中的 gender bias 教育不足。根据发现，我们合并了设计建议和指南，以导向未来的研究、教育和设计努力。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Goal-Recognition-in-Transhumeral-Prostheses-Using-Process-Mining-Techniques"><a href="#Data-Driven-Goal-Recognition-in-Transhumeral-Prostheses-Using-Process-Mining-Techniques" class="headerlink" title="Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques"></a>Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08106">http://arxiv.org/abs/2309.08106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihang Su, Tianshi Yu, Nir Lipovetzky, Alireza Mohammadi, Denny Oetomo, Artem Polyvyanyy, Sebastian Sardina, Ying Tan, Nick van Beest</li>
<li>for: 这个论文旨在研究如何使用时间序列数据来识别截肢者的目标姿势。</li>
<li>methods: 该论文使用表面电MYography电极和动态测量仪器收集的时间序列数据，并将其转化为离散事件，然后使用现有的进程挖掘学基于的目标识别系统进行训练。</li>
<li>results: 据收集在虚拟现实环境中的数据显示，该方法可以准确地识别截肢者的目标姿势，并且比州立艺术技术更加精准和更加不信任，这有利于估算肢体运动的更灵活移动。<details>
<summary>Abstract</summary>
A transhumeral prosthesis restores missing anatomical segments below the shoulder, including the hand. Active prostheses utilize real-valued, continuous sensor data to recognize patient target poses, or goals, and proactively move the artificial limb. Previous studies have examined how well the data collected in stationary poses, without considering the time steps, can help discriminate the goals. In this case study paper, we focus on using time series data from surface electromyography electrodes and kinematic sensors to sequentially recognize patients' goals. Our approach involves transforming the data into discrete events and training an existing process mining-based goal recognition system. Results from data collected in a virtual reality setting with ten subjects demonstrate the effectiveness of our proposed goal recognition approach, which achieves significantly better precision and recall than the state-of-the-art machine learning techniques and is less confident when wrong, which is beneficial when approximating smoother movements of prostheses.
</details>
<details>
<summary>摘要</summary>
一种跨肩 prosthesis 可以恢复下肩 absent 的解剖结构，包括手臂。活动 prostheses 使用实数据来识别病人目标姿势或目标，并激活人工肢体。先前的研究已经研究了不考虑时间步骤的数据是否可以帮助分类目标。在这篇案例研究中，我们将关注使用时间序列数据从表面电MYography 电极和运动传感器来顺序识别病人的目标。我们的方法包括将数据转换为精确的事件，并训练现有的过程挖掘-based 目标识别系统。从在虚拟现实环境中收集的十名参与者的数据显示，我们的建议的目标识别方法在精度和准确性方面具有显著的优势，并且当错误时具有较低的自信度，这有利于精制更平滑的人工肢体运动。
</details></li>
</ul>
<hr>
<h2 id="Research-on-Joint-Representation-Learning-Methods-for-Entity-Neighborhood-Information-and-Description-Information"><a href="#Research-on-Joint-Representation-Learning-Methods-for-Entity-Neighborhood-Information-and-Description-Information" class="headerlink" title="Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information"></a>Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08100">http://arxiv.org/abs/2309.08100</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Xiao, Xin Shan, Yuhua Wang, Miaolei Deng</li>
<li>for: address the issue of poor embedding performance in the knowledge graph of a programming design course</li>
<li>methods: 使用 joint representation learning model,  combining entity neighborhood information and description information</li>
<li>results: 实验结果表明，提议的模型在programming design course的知识图 dataset上 achieved favorable performance, outperforming other baseline models.<details>
<summary>Abstract</summary>
To address the issue of poor embedding performance in the knowledge graph of a programming design course, a joint represen-tation learning model that combines entity neighborhood infor-mation and description information is proposed. Firstly, a graph at-tention network is employed to obtain the features of entity neigh-boring nodes, incorporating relationship features to enrich the structural information. Next, the BERT-WWM model is utilized in conjunction with attention mechanisms to obtain the representation of entity description information. Finally, the final entity vector representation is obtained by combining the vector representations of entity neighborhood information and description information. Experimental results demonstrate that the proposed model achieves favorable performance on the knowledge graph dataset of the pro-gramming design course, outperforming other baseline models.
</details>
<details>
<summary>摘要</summary>
要解决程序设计课程知识图表中的埋点表现问题，提出了一种联合表示学习模型，结合实体邻居信息和描述信息。首先，使用图注意网络获取实体邻居节点特征，并将关系特征纳入结构信息。接着，使用BERT-WWM模型并加入注意机制来获取描述信息的表示。最后，将实体vector表示结果组合实体邻居信息和描述信息的vector表示。实验结果表明，提出的模型在程序设计课程知识图表 dataset上达到了优秀表现，比基eline模型高。
</details></li>
</ul>
<hr>
<h2 id="Fast-and-Accurate-Deep-Loop-Closing-and-Relocalization-for-Reliable-LiDAR-SLAM"><a href="#Fast-and-Accurate-Deep-Loop-Closing-and-Relocalization-for-Reliable-LiDAR-SLAM" class="headerlink" title="Fast and Accurate Deep Loop Closing and Relocalization for Reliable LiDAR SLAM"></a>Fast and Accurate Deep Loop Closing and Relocalization for Reliable LiDAR SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08086">http://arxiv.org/abs/2309.08086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghao Shi, Xieyuanli Chen, Junhao Xiao, Bin Dai, Huimin Lu</li>
<li>for: 本文旨在提出一种能够实现可靠和稳定长期SLAM的Loop Closing和Relocalization技术，以解决 pose estimation 漂移和缺失问题。</li>
<li>methods: 本文提出了一种多头网络LCR-Net，用于同时解决 Loop Closing 和 Relocalization 问题。该网络使用了新的特征提取和 pose-aware 注意力机制，以准确地估计相似性和 6-DoF 姿态。</li>
<li>results: Results 表明，LCR-Net 在三种设置中均表现出色，超越了现有方法，并且具有扩展性。特别是，LCR-Net 不需要使用时间消耗的稳定 pose estimator，使其适用于在线 SLAM 应用。根据我们所知，LCR-Net 是首个实现了 LiDAR SLAM 中的深度 Loop Closing 和 Relocalization 的方法。<details>
<summary>Abstract</summary>
Loop closing and relocalization are crucial techniques to establish reliable and robust long-term SLAM by addressing pose estimation drift and degeneration. This article begins by formulating loop closing and relocalization within a unified framework. Then, we propose a novel multi-head network LCR-Net to tackle both tasks effectively. It exploits novel feature extraction and pose-aware attention mechanism to precisely estimate similarities and 6-DoF poses between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a SLAM system and achieve robust and accurate online LiDAR SLAM in outdoor driving environments. We thoroughly evaluate our LCR-Net through three setups derived from loop closing and relocalization, including candidate retrieval, closed-loop point cloud registration, and continuous relocalization using multiple datasets. The results demonstrate that LCR-Net excels in all three tasks, surpassing the state-of-the-art methods and exhibiting a remarkable generalization ability. Notably, our LCR-Net outperforms baseline methods without using a time-consuming robust pose estimator, rendering it suitable for online SLAM applications. To our best knowledge, the integration of LCR-Net yields the first LiDAR SLAM with the capability of deep loop closing and relocalization. The implementation of our methods will be made open-source.
</details>
<details>
<summary>摘要</summary>
Loop closing和重新本地化是长期可靠的SLAM中重要的技巧，可以解决pose估计漂移和缺乏稳定性问题。本文首先将loop closing和重新本地化置于一个统一框架中，然后提出了一种新的多头网络LCR-Net，可以有效地处理这两个任务。LCR-Net使用了新的特征提取和pose相关注意机制，可以准确地估计相似性和6-DoF姿态之间的对应关系。文中还将LCR-Net与SLAM系统集成，并在户外驾驶环境中实现了稳定和准确的在线LiDAR SLAM。我们对LCR-Net进行了三种设置的评估，包括候选点云重新注册、循环关闭和连续重新本地化，并使用了多个数据集进行评估。结果表明，LCR-Net在这三个任务中均表现出色，超越了现有方法，并且具有很好的总体化能力。尤其是，LCR-Net不需要使用时间consuming的稳定pose估计器，因此适用于在线SLAM应用程序。到目前为止，我们的方法的实现将被开源。
</details></li>
</ul>
<hr>
<h2 id="A-Stochastic-Online-Forecast-and-Optimize-Framework-for-Real-Time-Energy-Dispatch-in-Virtual-Power-Plants-under-Uncertainty"><a href="#A-Stochastic-Online-Forecast-and-Optimize-Framework-for-Real-Time-Energy-Dispatch-in-Virtual-Power-Plants-under-Uncertainty" class="headerlink" title="A Stochastic Online Forecast-and-Optimize Framework for Real-Time Energy Dispatch in Virtual Power Plants under Uncertainty"></a>A Stochastic Online Forecast-and-Optimize Framework for Real-Time Energy Dispatch in Virtual Power Plants under Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08642">http://arxiv.org/abs/2309.08642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jiang, Zhongkai Yi, Li Wang, Hanwei Zhang, Jihai Zhang, Fangquan Lin, Cheng Yang</li>
<li>for: 这篇论文旨在为了提高分布式能源资源的组合和管理，减少不确定性，特别是绿色能源生产的波动。</li>
<li>methods: 本论文提出了一个实时不确定性感知能源分配框架，包括两个关键元素：（i）一个混合预测和优化的序列任务，结合深度学习预测和Stochastic优化，这两个阶段通过不确定性估计在多个时间分辨率连接。（ii）一个高效的线上数据增强计划，联合预训和线上细化阶段。</li>
<li>results: 本论文在CityLearn Challenge 2022中获得冠军，并进行了实验评估其在实际应用中的有效性。<details>
<summary>Abstract</summary>
Aggregating distributed energy resources in power systems significantly increases uncertainties, in particular caused by the fluctuation of renewable energy generation. This issue has driven the necessity of widely exploiting advanced predictive control techniques under uncertainty to ensure long-term economics and decarbonization. In this paper, we propose a real-time uncertainty-aware energy dispatch framework, which is composed of two key elements: (i) A hybrid forecast-and-optimize sequential task, integrating deep learning-based forecasting and stochastic optimization, where these two stages are connected by the uncertainty estimation at multiple temporal resolutions; (ii) An efficient online data augmentation scheme, jointly involving model pre-training and online fine-tuning stages. In this way, the proposed framework is capable to rapidly adapt to the real-time data distribution, as well as to target on uncertainties caused by data drift, model discrepancy and environment perturbations in the control process, and finally to realize an optimal and robust dispatch solution. The proposed framework won the championship in CityLearn Challenge 2022, which provided an influential opportunity to investigate the potential of AI application in the energy domain. In addition, comprehensive experiments are conducted to interpret its effectiveness in the real-life scenario of smart building energy management.
</details>
<details>
<summary>摘要</summary>
合并分布式能源资源在电力系统中会增加不确定性，尤其是可再生能源生产的波动。这种问题使得广泛利用先进预测控制技术在不确定环境下 Ensure long-term economics and decarbonization. 在这篇论文中，我们提出了实时不确定性意识能源分配框架，该框架由两个关键元素组成：1. hybrid预测和优化顺序任务，将深度学习预测和随机优化连接在多个时间分辨率上。2. 高效在线数据扩充方案，包括模型预训练和在线细化阶段。这种方案可以快速适应实时数据分布，同时Target uncertainties caused by data drift, model discrepancy, and environment perturbations in the control process, and finally achieve an optimal and robust dispatch solution.我们的框架在CityLearn Challenge 2022中赢得冠军，提供了一个有力的机会来调查AI应用在能源领域的潜力。此外，我们还进行了实验来解释其效果在智能建筑能源管理实际场景中。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/15/cs.AI_2023_09_15/" data-id="clp89do8n0041i7887tci7pno" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/15/cs.CL_2023_09_15/" class="article-date">
  <time datetime="2023-09-15T11:00:00.000Z" itemprop="datePublished">2023-09-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/15/cs.CL_2023_09_15/">cs.CL - 2023-09-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="An-Empirical-Study-on-Instance-Selection-Strategies-in-Self-training-for-Sentiment-Analysis"><a href="#An-Empirical-Study-on-Instance-Selection-Strategies-in-Self-training-for-Sentiment-Analysis" class="headerlink" title="An Empirical Study on Instance Selection Strategies in Self-training for Sentiment Analysis"></a>An Empirical Study on Instance Selection Strategies in Self-training for Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08777">http://arxiv.org/abs/2309.08777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochen Liu, Sai Krishna Rallabandi, Yijing Wu, Parag Pravin Dakle, Preethi Raghavan</li>
<li>for: 本研究旨在 investigate the influence of instance selection strategies and hyper-parameters on the performance of self-training in various few-shot settings for sentiment analysis.</li>
<li>methods: 本研究使用了自适应学习技术，并对不同的实例选择策略和超参数进行了 empirical study。</li>
<li>results: 研究发现，不同的实例选择策略和超参数对自适应学习的性能有很大的影响，并且在不同的几个 shot 设置下，不同的策略和超参数具有不同的最佳性能。<details>
<summary>Abstract</summary>
Sentiment analysis is a crucial task in natural language processing that involves identifying and extracting subjective sentiment from text. Self-training has recently emerged as an economical and efficient technique for developing sentiment analysis models by leveraging a small amount of labeled data and a larger amount of unlabeled data. However, the performance of a self-training procedure heavily relies on the choice of the instance selection strategy, which has not been studied thoroughly. This paper presents an empirical study on various instance selection strategies for self-training on two public sentiment datasets, and investigates the influence of the strategy and hyper-parameters on the performance of self-training in various few-shot settings.
</details>
<details>
<summary>摘要</summary>
自然语言处理中的情感分析是一项重要任务，它涉及到从文本中提取主观情感。自我培训是一种经济高效的技术，可以使用少量标注数据和更多的无标注数据来开发情感分析模型。然而，自我培训过程中的实例选择策略的选择对模型性能产生很大影响。这篇论文通过对两个公共情感数据集上的不同实例选择策略进行实证研究，探讨自我培训在不同几个尝试设置下的性能影响。
</details></li>
</ul>
<hr>
<h2 id="Generating-Semantic-Graph-Corpora-with-Graph-Expansion-Grammar"><a href="#Generating-Semantic-Graph-Corpora-with-Graph-Expansion-Grammar" class="headerlink" title="Generating Semantic Graph Corpora with Graph Expansion Grammar"></a>Generating Semantic Graph Corpora with Graph Expansion Grammar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08714">http://arxiv.org/abs/2309.08714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Andersson, Johanna Björklund, Frank Drewes, Anna Jonsson</li>
<li>for: 创建Semantic graphs的 corps</li>
<li>methods: 使用图解析语言，让用户通过定义 grammar来控制生成的图集</li>
<li>results: 可以生成符合 grammar 的图集，用于增强现有 corpus 和教学正式语言理论<details>
<summary>Abstract</summary>
We introduce Lovelace, a tool for creating corpora of semantic graphs. The system uses graph expansion grammar as a representational language, thus allowing users to craft a grammar that describes a corpus with desired properties. When given such grammar as input, the system generates a set of output graphs that are well-formed according to the grammar, i.e., a graph bank. The generation process can be controlled via a number of configurable parameters that allow the user to, for example, specify a range of desired output graph sizes. Central use cases are the creation of synthetic data to augment existing corpora, and as a pedagogical tool for teaching formal language theory.
</details>
<details>
<summary>摘要</summary>
我们介绍Lovelace，一个用于建立Semantic Graph的工具。这个系统使用图像扩展语法来描述图像的描述语言，因此让用户可以透过定义语法来制定图像的描述。当 given 这个语法为输入时，系统会生成一个符合语法的图像集合，即图像银行。生成过程可以通过一些可配置的参数控制，例如指定出力图像的大小范围。主要用途包括创建增强现有数据库的实验数据，以及教学正式语言理论的教学工具。
</details></li>
</ul>
<hr>
<h2 id="Frustratingly-Simple-Memory-Efficiency-for-Pre-trained-Language-Models-via-Dynamic-Embedding-Pruning"><a href="#Frustratingly-Simple-Memory-Efficiency-for-Pre-trained-Language-Models-via-Dynamic-Embedding-Pruning" class="headerlink" title="Frustratingly Simple Memory Efficiency for Pre-trained Language Models via Dynamic Embedding Pruning"></a>Frustratingly Simple Memory Efficiency for Pre-trained Language Models via Dynamic Embedding Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08708">http://arxiv.org/abs/2309.08708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlsw/dynamic-embedding-pruning">https://github.com/mlsw/dynamic-embedding-pruning</a></li>
<li>paper_authors: Miles Williams, Nikolaos Aletras</li>
<li>for: 这篇论文目的是简化预训练语言模型（PLM）的内存占用，以便在内存受限的云端环境或设备上部署。</li>
<li>methods: 论文使用嵌入矩阵来表示广泛的词汇，这些矩阵形成了模型参数的大部分。过往的工作已经对transformer层中的参数进行了删除，但是对嵌入矩阵的删除则没有被探讨。</li>
<li>results: 我们首先显示出，在这些情况下，词汇中有许多不会被使用。我们然后提出了一个简单 yet effective的方法，利用这个发现来删除嵌入矩阵中的部分参数。我们显示了这个方法可以在各种模型和任务上提供内存使用率的重要删除。值得注意的是，我们的方法可以保持下游任务的性能，并且让计算资源的使用更加有效率。<details>
<summary>Abstract</summary>
The extensive memory footprint of pre-trained language models (PLMs) can hinder deployment in memory-constrained settings, such as cloud environments or on-device. PLMs use embedding matrices to represent extensive vocabularies, forming a large proportion of the model parameters. While previous work towards parameter-efficient PLM development has considered pruning parameters within the transformer layers, pruning the embedding matrix as part of fine-tuning or inference has yet to be explored. We first demonstrate that a significant proportion of the vocabulary remains unused in these scenarios. We then propose a simple yet effective approach that leverages this finding to minimize the memory footprint of the embedding matrix. We show that this approach provides substantial reductions in memory usage across a wide range of models and tasks. Notably, our approach maintains equivalent downstream task performance while allowing a more efficient use of compute resources.
</details>
<details>
<summary>摘要</summary>
PLMs的庞大内存占用率可能会阻碍部署在内存受限的环境中，如云端环境或设备上。PLMs使用 embedding 矩阵来表示广泛的词汇表，占据模型参数的大部分。而以前的工作在开发减少 PLM 参数时已经考虑过杜refix 层中的参数，但是在 fine-tuning 或 inference 阶段对 embedding 矩阵进行减少还没有被探讨。我们首先表明，在这些场景下，许多词汇 remained 未使用。我们然后提出了一种简单 yet effective 的方法，利用这个发现来减少 embedding 矩阵的内存占用。我们显示了这种方法可以在各种模型和任务上提供了重要的内存占用减少，而且保持下游任务性能相同，使 compute 资源的使用更加高效。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Autoencoders-Find-Highly-Interpretable-Features-in-Language-Models"><a href="#Sparse-Autoencoders-Find-Highly-Interpretable-Features-in-Language-Models" class="headerlink" title="Sparse Autoencoders Find Highly Interpretable Features in Language Models"></a>Sparse Autoencoders Find Highly Interpretable Features in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08600">http://arxiv.org/abs/2309.08600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hoagyc/sparse_coding">https://github.com/hoagyc/sparse_coding</a></li>
<li>paper_authors: Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, Lee Sharkey</li>
<li>for: 本研究旨在解决神经网络内部具有多义性的问题，以提高神经网络的内部工作方式的理解。</li>
<li>methods: 本研究使用稀疏自编码器来重建语言模型的内部活动，并从中提取更有意义和单义的特征集。</li>
<li>results: 研究发现，通过稀疏自编码器来解决神经网络中的超position问题，可以提高模型的可解释性和可控性，并且可以精准地编辑模型。<details>
<summary>Abstract</summary>
One of the roadblocks to a better understanding of neural networks' internals is \textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Ablating these features enables precise model editing, for example, by removing capabilities such as pronoun prediction, while disrupting model behaviour less than prior techniques. This work indicates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our method may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability.
</details>
<details>
<summary>摘要</summary>
To address this issue, we use "sparse autoencoders" to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by other approaches. By ablating these features, we can precisely edit the model, for example, by removing capabilities such as pronoun prediction, while disrupting the model's behavior less than prior techniques.This work demonstrates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our approach may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability.
</details></li>
</ul>
<hr>
<h2 id="“Merge-Conflicts-”-Exploring-the-Impacts-of-External-Distractors-to-Parametric-Knowledge-Graphs"><a href="#“Merge-Conflicts-”-Exploring-the-Impacts-of-External-Distractors-to-Parametric-Knowledge-Graphs" class="headerlink" title="“Merge Conflicts!” Exploring the Impacts of External Distractors to Parametric Knowledge Graphs"></a>“Merge Conflicts!” Exploring the Impacts of External Distractors to Parametric Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08594">http://arxiv.org/abs/2309.08594</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiancheng0/ekd_impacts_pkg">https://github.com/qiancheng0/ekd_impacts_pkg</a></li>
<li>paper_authors: Cheng Qian, Xinran Zhao, Sherry Tongshuang Wu</li>
<li>for: 这 paper 探讨了大语言模型（LLM）在与用户交互时如何处理外部知识的问题。</li>
<li>methods: 作者们提出了一个框架，用于系统地探索 LLM 的 parametric knowledge 和外部知识之间的交互。他们构建了一个 parametric knowledge graph，以透视 LLM 的不同知识结构，并通过不同的方法、位置和格式引入外部知识。</li>
<li>results: 实验结果表明，当 LLM 遇到直接冲突或信息变化时，它们很可能会偏离其 parametric knowledge 提供的答案。它们还发现，即使外部知识的真实性高，LLM 仍可能受到不相关信息的干扰。这些发现指出了现有 LLM 在交互时 инте格外部知识时存在风险的问题。所有数据和结果都公开可用。<details>
<summary>Abstract</summary>
Large language models (LLMs) acquire extensive knowledge during pre-training, known as their parametric knowledge. However, in order to remain up-to-date and align with human instructions, LLMs inevitably require external knowledge during their interactions with users. This raises a crucial question: How will LLMs respond when external knowledge interferes with their parametric knowledge? To investigate this question, we propose a framework that systematically elicits LLM parametric knowledge and introduces external knowledge. Specifically, we uncover the impacts by constructing a parametric knowledge graph to reveal the different knowledge structures of LLMs, and introduce external knowledge through distractors of varying degrees, methods, positions, and formats. Our experiments on both black-box and open-source models demonstrate that LLMs tend to produce responses that deviate from their parametric knowledge, particularly when they encounter direct conflicts or confounding changes of information within detailed contexts. We also find that while LLMs are sensitive to the veracity of external knowledge, they can still be distracted by unrelated information. These findings highlight the risk of hallucination when integrating external knowledge, even indirectly, during interactions with current LLMs. All the data and results are publicly available.
</details>
<details>
<summary>摘要</summary>
Specifically, 我们 constructed a parametric knowledge graph 来揭露 LLMs 的不同知识结构，并通过对 LLMs 进行不同程度的外部知识引入，以发现它们在不同情况下的对应方式。我们的实验结果显示，当 LLMs 遇到直接冲突或干扰变化的情况时，它们往往会产生与 parametric knowledge 不符的回应。此外，我们发现 LLMS 对外部知识的敏感性可以在不同的情况下发挥作用，但是它们仍可以受到无关的信息所干扰。这些结果显示，当 LLMS 与外部知识进行互动时，存在诱导现象的风险。所有的数据和结果都公开可用。
</details></li>
</ul>
<hr>
<h2 id="Are-Multilingual-LLMs-Culturally-Diverse-Reasoners-An-Investigation-into-Multicultural-Proverbs-and-Sayings"><a href="#Are-Multilingual-LLMs-Culturally-Diverse-Reasoners-An-Investigation-into-Multicultural-Proverbs-and-Sayings" class="headerlink" title="Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings"></a>Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08591">http://arxiv.org/abs/2309.08591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UKPLab/maps">https://github.com/UKPLab/maps</a></li>
<li>paper_authors: Chen Cecilia Liu, Fajri Koto, Timothy Baldwin, Iryna Gurevych</li>
<li>for: 这 paper  investigate  whether multilingual language models (mLLMs) can reason with proverbs and sayings in a conversational context, and how well they understand these cultural references.</li>
<li>methods: The authors use a variety of state-of-the-art mLLMs to test the models’ ability to reason with proverbs and sayings, and they create a new evaluation dataset called MAPS (MulticultrAl Proverbs and Sayings) for six different languages.</li>
<li>results: The authors find that mLLMs have limited knowledge of proverbs and struggle to reason with figurative proverbs and sayings, and there is a “culture gap” in mLLMs when reasoning about proverbs and sayings translated from other languages.<details>
<summary>Abstract</summary>
Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in situational context, human expectations vary depending on the relevant cultural common ground. As human languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational context. Our experiments reveal that: (1) mLLMs 'knows' limited proverbs and memorizing proverbs does not mean understanding them within a conversational context; (2) mLLMs struggle to reason with figurative proverbs and sayings, and when asked to select the wrong answer (instead of asking it to select the correct answer); and (3) there is a "culture gap" in mLLMs when reasoning about proverbs and sayings translated from other languages. We construct and release our evaluation dataset MAPS (MulticultrAl Proverbs and Sayings) for proverb understanding with conversational context for six different languages.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>mLLMs have limited knowledge of proverbs and simply memorizing proverbs does not mean understanding them in a conversational context.2. mLLMs struggle to reason with figurative proverbs and sayings, and often choose the wrong answer when asked to select a response.3. There is a “culture gap” in mLLMs when reasoning about proverbs and sayings translated from other languages.To address these challenges, we have created and released an evaluation dataset called MAPS (MulticultrAl Proverbs and Sayings) for proverb understanding in six different languages. This dataset will help researchers to better understand the limitations and potential of mLLMs when it comes to reasoning across cultures.</details></li>
</ol>
<hr>
<h2 id="Neural-Machine-Translation-Models-Can-Learn-to-be-Few-shot-Learners"><a href="#Neural-Machine-Translation-Models-Can-Learn-to-be-Few-shot-Learners" class="headerlink" title="Neural Machine Translation Models Can Learn to be Few-shot Learners"></a>Neural Machine Translation Models Can Learn to be Few-shot Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08590">http://arxiv.org/abs/2309.08590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raphael Reinauer, Patrick Simianer, Kaden Uhlig, Johannes E. M. Mosig, Joern Wuebker</li>
<li>for: 这篇论文旨在探讨大语言模型在新领域和任务中具有快速学习能力，以及如何通过特殊的训练目标来减少模型的大小。</li>
<li>methods: 本研究使用了精心设计的训练目标，以实现在几个示例的情况下进行域 adapted 学习。</li>
<li>results: 研究结果表明，使用本方法可以实现高质量的翻译和快速适应率，并且在混合域批处理中进行批处理时能够更高效。<details>
<summary>Abstract</summary>
The emergent ability of Large Language Models to use a small number of examples to learn to perform in novel domains and tasks, also called in-context learning (ICL). In this work, we show that a much smaller model can be trained to perform ICL by fine-tuning towards a specialized training objective, exemplified on the task of domain adaptation for neural machine translation. With this capacity for ICL, the model can take advantage of relevant few-shot examples to adapt its output towards the domain. We compare the quality of this domain adaptation to traditional supervised techniques and ICL with a 40B-parameter Large Language Model. Our approach allows efficient batch inference on a mix of domains and outperforms state-of-the-art baselines in terms of both translation quality and immediate adaptation rate, i.e. the ability to reproduce a specific term after being shown a single example.
</details>
<details>
<summary>摘要</summary>
大型语言模型的新兴能力，即使用少量示例来在新领域和任务中学习，也称为内容学习（ICL）。在这项工作中，我们示出了一种较小的模型可以通过特殊化训练目标来进行ICL，并 exemplified 在神经机器翻译领域中进行领域适应。通过这种ICL能力，模型可以利用相关的几个示例来适应领域。我们与传统的直接训练技术和ICL的40B参数大型语言模型进行比较，并发现我们的方法可以具有高效批处理能力，并在混合领域下进行批处理。此外，我们的方法还可以在翻译质量和快速适应率（即在看到单个示例后能够重新生成特定词汇）两个方面超越当前的基elines。
</details></li>
</ul>
<hr>
<h2 id="ICLEF-In-Context-Learning-with-Expert-Feedback-for-Explainable-Style-Transfer"><a href="#ICLEF-In-Context-Learning-with-Expert-Feedback-for-Explainable-Style-Transfer" class="headerlink" title="ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer"></a>ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08583">http://arxiv.org/abs/2309.08583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asaakyan/explain-st">https://github.com/asaakyan/explain-st</a></li>
<li>paper_authors: Arkadiy Saakyan, Smaranda Muresan</li>
<li>for: 这个论文的目的是提出一种扩展和改进形式式转换数据集的解释框架，以便使用ChatGPT模型进行模型精炼，并通过人工指导来进一步修改生成的解释。</li>
<li>methods: 该论文使用了ChatGPT模型进行模型精炼，并通过ICLEF（In-Context Learning from Expert Feedback）技术来捕捉专家反馈。</li>
<li>results: 研究发现，现有的公开分布的 instruciton-tuned 模型（以及在某些设置下的ChatGPT）在这个任务上表现不佳，而通过 fine-tuning 在我们的高质量数据集上得到了显著提高。人工评估表明，比ChatGPT更小的模型在我们的数据集上进行 fine-tuning 后，与专家偏好更加相似。最后，论文还讨论了使用模型在解释式风格转换任务中的两种应用：可读性作者识别和可读性AI生成文本检测器的可读性针对攻击。<details>
<summary>Abstract</summary>
While state-of-the-art language models excel at the style transfer task, current work does not address explainability of style transfer systems. Explanations could be generated using large language models such as GPT-3.5 and GPT-4, but the use of such complex systems is inefficient when smaller, widely distributed, and transparent alternatives are available. We propose a framework to augment and improve a formality style transfer dataset with explanations via model distillation from ChatGPT. To further refine the generated explanations, we propose a novel way to incorporate scarce expert human feedback using in-context learning (ICLEF: In-Context Learning from Expert Feedback) by prompting ChatGPT to act as a critic to its own outputs. We use the resulting dataset of 9,960 explainable formality style transfer instances (e-GYAFC) to show that current openly distributed instruction-tuned models (and, in some settings, ChatGPT) perform poorly on the task, and that fine-tuning on our high-quality dataset leads to significant improvements as shown by automatic evaluation. In human evaluation, we show that models much smaller than ChatGPT fine-tuned on our data align better with expert preferences. Finally, we discuss two potential applications of models fine-tuned on the explainable style transfer task: interpretable authorship verification and interpretable adversarial attacks on AI-generated text detectors.
</details>
<details>
<summary>摘要</summary>
当前最先进的语言模型在Style Transfer任务上表现出色，但现有工作并没有解释Style Transfer系统的可读性。我们提出一个框架，使用ChatGPT模型协助生成Style Transfer数据集的解释，通过模型液化（distillation）来提高数据质量。为了进一步细化生成的解释，我们提出一种新的方法，通过在Context Learning from Expert Feedback（ICLEF）中提供专家反馈来进一步改进ChatGPT的输出。我们使用这些解释Style Transfer实例（e-GYAFC）来证明，当前公开分布的开源 instrucion-tuned 模型（以及在某些设置下的ChatGPT）在这个任务上表现不佳，而 fine-tuning 在我们的高质量数据集上导致了显著的改进，如自动评估中所示。在人工评估中，我们发现使用我们数据集进行 fine-tuning 的模型比ChatGPT更好地与专家偏好相吻合。最后，我们讨论了基于解释Style Transfer任务的模型在涉及性作者鉴别和AI生成文本检测器的可读性攻击中的两个可能应用。
</details></li>
</ul>
<hr>
<h2 id="Casteist-but-Not-Racist-Quantifying-Disparities-in-Large-Language-Model-Bias-between-India-and-the-West"><a href="#Casteist-but-Not-Racist-Quantifying-Disparities-in-Large-Language-Model-Bias-between-India-and-the-West" class="headerlink" title="Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West"></a>Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08573">http://arxiv.org/abs/2309.08573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khyati Khandelwal, Manuel Tonneau, Andrew M. Bean, Hannah Rose Kirk, Scott A. Hale</li>
<li>for: 本研究旨在评估大语言模型（LLMs）中存在的偏见问题，以及这些偏见在印度上的表现。</li>
<li>methods: 该研究采用了一种新的数据集——印度偏见评估 dataset（Indian-BhED），包含了印度社会中的阶层和宗教上的偏见和反偏见示例。通过对多种popular LLMs进行测试，研究人员发现了大多数LLMs在印度上具有强烈的偏见倾向。</li>
<li>results: 研究人员发现，在印度上，LLMs中的偏见倾向主要表现在阶层和宗教上，特别是与西方上的偏见倾向相比。此外，研究人员还发现了一种简单的调教技术——指令推荐——可以有效地减少LLMs中的偏见和反偏见。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), now used daily by millions of users, can encode societal biases, exposing their users to representational harms. A large body of scholarship on LLM bias exists but it predominantly adopts a Western-centric frame and attends comparatively less to bias levels and potential harms in the Global South. In this paper, we quantify stereotypical bias in popular LLMs according to an Indian-centric frame and compare bias levels between the Indian and Western contexts. To do this, we develop a novel dataset which we call Indian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and anti-stereotypical examples for caste and religion contexts. We find that the majority of LLMs tested are strongly biased towards stereotypes in the Indian context, especially as compared to the Western context. We finally investigate Instruction Prompting as a simple intervention to mitigate such bias and find that it significantly reduces both stereotypical and anti-stereotypical biases in the majority of cases for GPT-3.5. The findings of this work highlight the need for including more diverse voices when evaluating LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），每天使用了 millions of users，可以储存社会偏见，使用者接触到表现性危害。学术研究中存在大量LLM偏见，但这些研究通常采用西方中心的框架，对于全球南方的偏见水平和潜在危害相对较少关注。本文使用一个新的数据集——印度偏见评估集（Indian-BhED），测量各LLM在印度和西方上的偏见水平。我们发现大多数测试的LLM强烈储存印度上的偏见，特别是与西方上的偏见相比。最后，我们调查了“指示提示”作为简单的 Mitigation 方法，发现其可以有效地减少大多数情况下的偏见和反偏见偏见。这些发现强调了包括更多多样化的声音在LLM评估中的重要性。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-conformers-with-structured-state-space-models-for-online-speech-recognition"><a href="#Augmenting-conformers-with-structured-state-space-models-for-online-speech-recognition" class="headerlink" title="Augmenting conformers with structured state space models for online speech recognition"></a>Augmenting conformers with structured state space models for online speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08551">http://arxiv.org/abs/2309.08551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haozhe Shan, Albert Gu, Zhong Meng, Weiran Wang, Krzysztof Choromanski, Tara Sainath</li>
<li>for: 本研究探讨了在线语音识别系统中使用神经网络模型，只访问左侧上下文。</li>
<li>methods: 本文提出了一种基于结构化状态空间序列模型（S4）的增强神经网络模型，以提高在线ASR系统的性能。 authorsperform了系统的ablation Study来比较不同的S4模型变体，并提出了两种新的方法， combinig S4模型和卷积。</li>
<li>results: results show that the most effective design is to stack a small S4 using real-valued recurrent weights with a local convolution, allowing them to work complementarily. 最佳设计是将一小个S4模型与实数权重的卷积相结合，以实现它们的补充作用。 authors的best model achieves WERs of 4.01%&#x2F;8.53% on test sets from Librispeech, outperforming Conformers with extensively tuned convolution.<details>
<summary>Abstract</summary>
Online speech recognition, where the model only accesses context to the left, is an important and challenging use case for ASR systems. In this work, we investigate augmenting neural encoders for online ASR by incorporating structured state-space sequence models (S4), which are a family of models that provide a parameter-efficient way of accessing arbitrarily long left context. We perform systematic ablation studies to compare variants of S4 models and propose two novel approaches that combine them with convolutions. We find that the most effective design is to stack a small S4 using real-valued recurrent weights with a local convolution, allowing them to work complementarily. Our best model achieves WERs of 4.01%/8.53% on test sets from Librispeech, outperforming Conformers with extensively tuned convolution.
</details>
<details>
<summary>摘要</summary>
online speech recognition，其中模型只能访问左侧上下文，是ASR系统中的重要和挑战性用case。在这项工作中，我们研究了将神经编码器引入在线ASR中，通过结构化状态空间序列模型（S4）来提供高效的左侧上下文访问方式。我们进行了系统性的减少研究，比较不同的S4模型变体，并提出了两种新的方法，其中一种将S4模型与卷积结合。我们发现最有效的设计是将一小个S4模型使用实数Recurrent权重与地方卷积结合，使其在不同上下文中工作衔接地。我们的最佳模型在Librispeech测试集上 achieve WERs of 4.01%/8.53%，超过了经过了大量调整的卷积Conformers。
</details></li>
</ul>
<hr>
<h2 id="Towards-Practical-and-Efficient-Image-to-Speech-Captioning-with-Vision-Language-Pre-training-and-Multi-modal-Tokens"><a href="#Towards-Practical-and-Efficient-Image-to-Speech-Captioning-with-Vision-Language-Pre-training-and-Multi-modal-Tokens" class="headerlink" title="Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens"></a>Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08531">http://arxiv.org/abs/2309.08531</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ms-dot-k/Image-to-Speech-Captioning">https://github.com/ms-dot-k/Image-to-Speech-Captioning</a></li>
<li>paper_authors: Minsu Kim, Jeongsoo Choi, Soumi Maiti, Jeong Hun Yeo, Shinji Watanabe, Yong Man Ro</li>
<li>for: 这 paper 的目的是提出一种强大和高效的图像到语音captioning（Im2Sp）模型。</li>
<li>methods: 该 paper 使用了一种基于大规模预训练视觉语言模型的视觉语言概念和语言模型知识进行 imports，并将 Im2Sp 的输出设置为精度化的语音特征，以便 incorporate 语言模型化能力。</li>
<li>results: 通过使用视觉语言预训练策略，该 paper 在 COCO 和 Flickr8k 两个广泛使用的标准数据库上实现了新的 Im2Sp 性能记录。此外， paper 还提出了一种提高 Im2Sp 模型的效率的方法。<details>
<summary>Abstract</summary>
In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: https://ms-dot-k.github.io/Image-to-Speech-Captioning.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了构建一个强大和高效的图像到语音描述（Im2Sp）模型的方法。为此，我们从大规模预训练视觉语言模型中导入了丰富的图像理解和语言模型化知识。我们设置了Im2Sp的输出为步骤化的语音特征，即一种自适应语音模型的量化语音特征。这些语音特征主要包含语言信息，同时压缩其他语音特征。这样可以将预训练视觉语言模型中的语言模型化能力integrated into Im2Sp的语音模型。通过视觉语言预训练策略，我们在COCO和Flickr8k两个广泛使用的数据库上设置了新的Im2Sp性能记录。然后，我们进一步提高了Im2Sp模型的效率。与语音单元类似，我们将原始图像转换为图像单元，它们通过Raw image的vector quantization来 derivation。通过这些图像单元，我们可以压缩图像数据的存储需求，从原始图像数据的bits比例来看，减少了99.2%。 demo页面：https://ms-dot-k.github.io/Image-to-Speech-Captioning。
</details></li>
</ul>
<hr>
<h2 id="SilverRetriever-Advancing-Neural-Passage-Retrieval-for-Polish-Question-Answering"><a href="#SilverRetriever-Advancing-Neural-Passage-Retrieval-for-Polish-Question-Answering" class="headerlink" title="SilverRetriever: Advancing Neural Passage Retrieval for Polish Question Answering"></a>SilverRetriever: Advancing Neural Passage Retrieval for Polish Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08469">http://arxiv.org/abs/2309.08469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piotr Rybak, Maciej Ogrodniczuk</li>
<li>for: 这篇论文目的是为了开发一种基于神经网络的波兰语问答系统，以提高问答系统的准确率和效率。</li>
<li>methods: 这篇论文使用了神经网络来实现问答系统的检索部分，并在多个手动或弱 Label 的数据集上训练。</li>
<li>results: 根据论文的描述，SilverRetriever 比其他波兰语模型更好，并与大型多语言模型相当。同时，论文还开源了五个新的检索数据集。<details>
<summary>Abstract</summary>
Modern open-domain question answering systems often rely on accurate and efficient retrieval components to find passages containing the facts necessary to answer the question. Recently, neural retrievers have gained popularity over lexical alternatives due to their superior performance. However, most of the work concerns popular languages such as English or Chinese. For others, such as Polish, few models are available. In this work, we present SilverRetriever, a neural retriever for Polish trained on a diverse collection of manually or weakly labeled datasets. SilverRetriever achieves much better results than other Polish models and is competitive with larger multilingual models. Together with the model, we open-source five new passage retrieval datasets.
</details>
<details>
<summary>摘要</summary>
现代开放领域问答系统经常利用准确和高效的检索组件来找到包含问题答案所需的信息。近年来，神经检索器在英语或中文等Popular语言中得到了广泛的应用，但是对其他语言，如波兰语，有限的模型是可用的。在这项工作中，我们介绍SilverRetriever，一种基于神经网络的波兰语检索器，通过手动或弱 Label的数据集进行训练。SilverRetriever在波兰语检索方面达到了较好的结果，与大型多语言模型竞争。此外，我们还开源了五个新的段落检索数据集。
</details></li>
</ul>
<hr>
<h2 id="Mixture-Encoder-Supporting-Continuous-Speech-Separation-for-Meeting-Recognition"><a href="#Mixture-Encoder-Supporting-Continuous-Speech-Separation-for-Meeting-Recognition" class="headerlink" title="Mixture Encoder Supporting Continuous Speech Separation for Meeting Recognition"></a>Mixture Encoder Supporting Continuous Speech Separation for Meeting Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08454">http://arxiv.org/abs/2309.08454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Vieting, Simon Berger, Thilo von Neumann, Christoph Boeddeker, Ralf Schlüter, Reinhold Haeb-Umbach</li>
<li>for: 这项研究旨在提高自动语音识别（ASR）系统的性能，特别是处理重叠的语音场景。</li>
<li>methods: 这项研究使用了一种新的混合编码器，该编码器利用原始重叠的语音来减少由语音分离引入的噪声的影响。</li>
<li>results: 实验结果表明，使用这种混合编码器可以在LibriCSS数据集上达到顶峰性能，并且表明TF-GridNet模型具有强大的分离能力， largely closing the gap between previous methods and oracle separation.<details>
<summary>Abstract</summary>
Many real-life applications of automatic speech recognition (ASR) require processing of overlapped speech. A commonmethod involves first separating the speech into overlap-free streams and then performing ASR on the resulting signals. Recently, the inclusion of a mixture encoder in the ASR model has been proposed. This mixture encoder leverages the original overlapped speech to mitigate the effect of artifacts introduced by the speech separation. Previously, however, the method only addressed two-speaker scenarios. In this work, we extend this approach to more natural meeting contexts featuring an arbitrary number of speakers and dynamic overlaps. We evaluate the performance using different speech separators, including the powerful TF-GridNet model. Our experiments show state-of-the-art performance on the LibriCSS dataset and highlight the advantages of the mixture encoder. Furthermore, they demonstrate the strong separation of TF-GridNet which largely closes the gap between previous methods and oracle separation.
</details>
<details>
<summary>摘要</summary>
许多实际应用中的自动语音识别（ASR）需要处理重叠的语音。一种常见方法是首先将语音分解成不重叠的流程，然后对得到的信号进行 ASR 处理。最近，一种将混合编码器添加到 ASR 模型中的方法被提议。这种混合编码器利用原始的重叠语音来减轻由语音分离引入的artefacts的影响。然而，之前的方法只处理了两个人的场景。在这种工作中，我们扩展了这种方法，以适应更自然的会议场景，包括任意数量的说话者和动态重叠。我们使用不同的语音分离器进行评估，包括强大的 TF-GridNet 模型。我们的实验结果表明，我们的方法在 LibriCSS 数据集上达到了状态机器的性能，并且强调混合编码器的优势。此外，它们也证明了 TF-GridNet 的强大分离能力， largely 关闭了之前方法和oracle分离之间的差距。
</details></li>
</ul>
<hr>
<h2 id="Advancing-the-Evaluation-of-Traditional-Chinese-Language-Models-Towards-a-Comprehensive-Benchmark-Suite"><a href="#Advancing-the-Evaluation-of-Traditional-Chinese-Language-Models-Towards-a-Comprehensive-Benchmark-Suite" class="headerlink" title="Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite"></a>Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08448">http://arxiv.org/abs/2309.08448</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mtkresearch/mr-models">https://github.com/mtkresearch/mr-models</a></li>
<li>paper_authors: Chan-Jan Hsu, Chang-Le Liu, Feng-Ting Liao, Po-Chun Hsu, Yi-Chang Chen, Da-shan Shiu</li>
<li>for: 评估大语言模型的能力是语言理解和生成领域的关键任务。</li>
<li>methods: 我们提出了一种新的评估框架，利用英文数据集创建了一系列特有的 benchmark，用于评估语言模型在traditional Chinese 中的多种能力。</li>
<li>results: 我们在这些 benchmark 上评估了GPT-3.5、Taiwan-LLaMa-v1.0和我们自己的模型Model 7-C，结果显示我们的模型在一些评估能力上与GPT-3.5相当。<details>
<summary>Abstract</summary>
The evaluation of large language models is an essential task in the field of language understanding and generation. As language models continue to advance, the need for effective benchmarks to assess their performance has become imperative. In the context of Traditional Chinese, there is a scarcity of comprehensive and diverse benchmarks to evaluate the capabilities of language models, despite the existence of certain benchmarks such as DRCD, TTQA, CMDQA, and FGC dataset. To address this gap, we propose a novel set of benchmarks that leverage existing English datasets and are tailored to evaluate language models in Traditional Chinese. These benchmarks encompass a wide range of tasks, including contextual question-answering, summarization, classification, and table understanding. The proposed benchmarks offer a comprehensive evaluation framework, enabling the assessment of language models' capabilities across different tasks. In this paper, we evaluate the performance of GPT-3.5, Taiwan-LLaMa-v1.0, and Model 7-C, our proprietary model, on these benchmarks. The evaluation results highlight that our model, Model 7-C, achieves performance comparable to GPT-3.5 with respect to a part of the evaluated capabilities. In an effort to advance the evaluation of language models in Traditional Chinese and stimulate further research in this field, we have open-sourced our benchmark and opened the model for trial.
</details>
<details>
<summary>摘要</summary>
大型语言模型的评估是现场语言理解和生成领域的重要任务。随着语言模型不断进步，评估其性能的需求日益增加。在传统汉字中，对于语言模型的评估标准仅有一些限定的测试，如DRCD、TTQA、CMDQA和FGC数据集。为了填补这个空白，我们提出了一个新的测试集，利用现有的英文数据集，并特别针对传统汉字评估语言模型的多种能力。这个测试集包括了各种任务，例如对话问题答案、摘要、分类和表格理解。这些测试集提供了一个全面的评估框架，允许评估语言模型在不同任务上的能力。在这篇论文中，我们将评估GPT-3.5、Taiwan-LLaMa-v1.0和我们的专业模型（Model 7-C）的性能。评估结果显示，我们的模型（Model 7-C）在一部分评估能力方面与GPT-3.5相似。为了推进传统汉字语言模型的评估和促进这个领域的进一步研究，我们将测试集开源和模型公开试用。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-Potential-of-Evidence-in-Knowledge-Intensive-Dialogue-Generation"><a href="#Unleashing-Potential-of-Evidence-in-Knowledge-Intensive-Dialogue-Generation" class="headerlink" title="Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation"></a>Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08380">http://arxiv.org/abs/2309.08380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xianjie Wu, Jian Yang, Tongliang Li, Di Liang, Shiwei Zhang, Yiyang Du, Zhoujun Li</li>
<li>for: 提高对话回答的正确性，增强对话生成系统的知识内容。</li>
<li>methods: 利用大语言模型挖掘可靠的证据真实标签，并在对话生成过程中使用证据标签进行可靠的证据标识和集中注意力。</li>
<li>results: 在MultiDoc2Dial上实验表明，提供证据标签的增强和调整注意力机制可以提高模型性能，比基eline高3-5点，并且进一步验证了模型的可靠性和事实一致性。<details>
<summary>Abstract</summary>
Incorporating external knowledge into dialogue generation (KIDG) is crucial for improving the correctness of response, where evidence fragments serve as knowledgeable snippets supporting the factual dialogue replies. However, introducing irrelevant content often adversely impacts reply quality and easily leads to hallucinated responses. Prior work on evidence retrieval and integration in dialogue systems falls short of fully leveraging existing evidence since the model fails to locate useful fragments accurately and overlooks hidden evidence labels within the KIDG dataset. To fully Unleash the potential of evidence, we propose a framework to effectively incorporate Evidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we introduce an automatic evidence generation framework that harnesses the power of Large Language Models (LLMs) to mine reliable evidence veracity labels from unlabeled data. By utilizing these evidence labels, we train a reliable evidence indicator to effectively identify relevant evidence from retrieved passages. Furthermore, we propose an evidence-augmented generator with an evidence-focused attention mechanism, which allows the model to concentrate on evidenced segments. Experimental results on MultiDoc2Dial demonstrate the efficacy of evidential label augmentation and refined attention mechanisms in improving model performance. Further analysis confirms that the proposed method outperforms other baselines (+3~+5 points) regarding coherence and factual consistency.
</details>
<details>
<summary>摘要</summary>
通过 incorporating 外部知识 into 对话生成 (KIDG) 中的对话回复，可以提高对话回复的正确性。然而，引入不相关的内容可能会消耗对话质量和导致幻想回复。现有的对话系统中的证据检索和整合方法未能充分利用现有的证据，因为模型无法准确地检索有用的断片和忽略掉隐藏在 KIDG 数据集中的证据标签。为了全面发挥证据的潜力，我们提出了一个框架，称为 u-EIDG（知识Intensive对话生成框架）。具体来说，我们提出了一个自动生成证据框架，利用大型自然语言模型 (LLMs) 来挖掘可靠的证据真实标签。通过这些证据标签，我们训练了一个可靠的证据指标，以确定有用的证据从 retrieved 段落中选择。此外，我们提出了一个带有证据专注注意机制的证据扩充生成器，使模型能够专注于证据段落。实验结果表明，证据标签增强和专注注意机制可以提高模型性能。进一步分析表明，我们的方法在coherence和事实一致性方面 (+3~+5 点) 表现出色。
</details></li>
</ul>
<hr>
<h2 id="PatFig-Generating-Short-and-Long-Captions-for-Patent-Figures"><a href="#PatFig-Generating-Short-and-Long-Captions-for-Patent-Figures" class="headerlink" title="PatFig: Generating Short and Long Captions for Patent Figures"></a>PatFig: Generating Short and Long Captions for Patent Figures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08379">http://arxiv.org/abs/2309.08379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dana Aubakirova, Kim Gerdes, Lufei Liu</li>
<li>for: 该论文提出了一个新的大规模专利图像数据集，包含11,000多个欧洲专利申请的30,000多个专利图像。</li>
<li>methods: 该数据集每个图像都提供了短和长标题、参考 numerals、它们所对应的术语和图像中组件之间的最小索引。</li>
<li>results: 通过在Qatent PatFig上训练LVLM模型，可以生成短和长的描述，并 investigate了在专利图像描述过程中使用不同的文本基于cue的影响。<details>
<summary>Abstract</summary>
This paper introduces Qatent PatFig, a novel large-scale patent figure dataset comprising 30,000+ patent figures from over 11,000 European patent applications. For each figure, this dataset provides short and long captions, reference numerals, their corresponding terms, and the minimal claim set that describes the interactions between the components of the image. To assess the usability of the dataset, we finetune an LVLM model on Qatent PatFig to generate short and long descriptions, and we investigate the effects of incorporating various text-based cues at the prediction stage of the patent figure captioning process.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DiaCorrect-Error-Correction-Back-end-For-Speaker-Diarization"><a href="#DiaCorrect-Error-Correction-Back-end-For-Speaker-Diarization" class="headerlink" title="DiaCorrect: Error Correction Back-end For Speaker Diarization"></a>DiaCorrect: Error Correction Back-end For Speaker Diarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08377">http://arxiv.org/abs/2309.08377</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangyu Han, Federico Landini, Johan Rohdin, Mireia Diez, Lukas Burget, Yuhang Cao, Heng Lu, Jan Cernocky</li>
<li>for: 这个论文是为了提高 диари化系统的输出精度而设计的一种错误修正框架。</li>
<li>methods: 该方法基于自动语音识别中的错误修正技术，使用两个并行的卷积encoder和一个基于变换的decoder，通过利用输入录音和初始系统的输出之间的交互，自动修正初始说话人的活动，以最小化 диари化错误。</li>
<li>results: 对2个说话人电话数据进行实验表明，提案的 DiaCorrect 可以有效地提高初始模型的结果。<details>
<summary>Abstract</summary>
In this work, we propose an error correction framework, named DiaCorrect, to refine the output of a diarization system in a simple yet effective way. This method is inspired by error correction techniques in automatic speech recognition. Our model consists of two parallel convolutional encoders and a transform-based decoder. By exploiting the interactions between the input recording and the initial system's outputs, DiaCorrect can automatically correct the initial speaker activities to minimize the diarization errors. Experiments on 2-speaker telephony data show that the proposed DiaCorrect can effectively improve the initial model's results. Our source code is publicly available at https://github.com/BUTSpeechFIT/diacorrect.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们提出了一个错误修正框架，名为DiaCorrect，用于简化 диари化系统的输出。这种方法 draws inspiration from automatic speech recognition 的错误修正技术。我们的模型包括两个并行的卷积Encoder和一个基于 transform的解码器。通过利用输入录音和初始系统的输出之间的互动，DiaCorrect可以自动 correctionspeaker activities，以最小化 диари化错误。实验结果表明，我们的提posed DiaCorrect可以有效地提高初始模型的结果。我们的源代码可以在https://github.com/BUTSpeechFIT/diacorrect中获取。
</details></li>
</ul>
<hr>
<h2 id="Headless-Language-Models-Learning-without-Predicting-with-Contrastive-Weight-Tying"><a href="#Headless-Language-Models-Learning-without-Predicting-with-Contrastive-Weight-Tying" class="headerlink" title="Headless Language Models: Learning without Predicting with Contrastive Weight Tying"></a>Headless Language Models: Learning without Predicting with Contrastive Weight Tying</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08351">http://arxiv.org/abs/2309.08351</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NathanGodey/headless-lm">https://github.com/NathanGodey/headless-lm</a></li>
<li>paper_authors: Nathan Godey, Éric de la Clergerie, Benoît Sagot</li>
<li>for: 这篇研究旨在提出一种新的自主预训语言模型方法，它不再是预测字串probability分布，而是通过对输入嵌入重新构建的方式进行对比。</li>
<li>methods: 我们提出了一种叫做对比负载绑定（Contrastive Weight Tying，CWT）的方法，它可以在不同语言上预训头less language model。</li>
<li>results: 我们发现这种方法可以大幅提高GLUE分数和LAMBADA准确率，相比类别的语言模型在相似的计算预算下，具有更好的下游性能和数据效率。<details>
<summary>Abstract</summary>
Self-supervised pre-training of language models usually consists in predicting probability distributions over extensive token vocabularies. In this study, we propose an innovative method that shifts away from probability prediction and instead focuses on reconstructing input embeddings in a contrastive fashion via Constrastive Weight Tying (CWT). We apply this approach to pretrain Headless Language Models in both monolingual and multilingual contexts. Our method offers practical advantages, substantially reducing training computational requirements by up to 20 times, while simultaneously enhancing downstream performance and data efficiency. We observe a significant +1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement compared to classical LMs within similar compute budgets.
</details>
<details>
<summary>摘要</summary>
自我超级预训练语言模型通常是预测Token词汇的概率分布。在这项研究中，我们提出了一种创新的方法，即通过对比绑定权重（CWT）来重建输入嵌入。我们在单语言和多语言上应用这种方法来预训Headless语言模型。我们的方法具有实用优势，可以减少训练计算需求，同时提高下游性能和数据效率。我们发现在相同的计算预算下，our方法可以提高+1.6 GLUE分数和+2.7 LAMBADA准确率。
</details></li>
</ul>
<hr>
<h2 id="Reward-Engineering-for-Generating-Semi-structured-Explanation"><a href="#Reward-Engineering-for-Generating-Semi-structured-Explanation" class="headerlink" title="Reward Engineering for Generating Semi-structured Explanation"></a>Reward Engineering for Generating Semi-structured Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08347">http://arxiv.org/abs/2309.08347</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiuzhouh/reward-engineering-for-generating-seg">https://github.com/jiuzhouh/reward-engineering-for-generating-seg</a></li>
<li>paper_authors: Jiuzhou Han, Wray Buntine, Ehsan Shareghi</li>
<li>for: 本研究旨在解决语言模型生成结构化解释的挑战，尤其是不太大的语言模型（LM）在生成结构化解释时的问题。</li>
<li>methods: 本研究使用了强化学习（RL）和奖励工程学习（RE）来解决这个问题，并 investigate了多种奖励汇总方法。</li>
<li>results: 研究发现RL可以更好地解决生成结构化解释的问题，并在两个semi-structured解释生成Benchmark（ExplaGraph和COPA-SSE）上达到了新的状态体系。<details>
<summary>Abstract</summary>
Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs, as the reasoner is expected to couple a sequential answer with a structured explanation which embodies both the correct presentation and the correct reasoning process. In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a detailed discussion which sheds light on the promising potential of RL for future research. Our proposed reward on two semi-structured explanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
semi-structured 解释描述了推理者的隐式过程，并且这种解释强调了根据特定查询提供的信息以及reasoner内部的权重来生成答案。 Despite 最近的语言模型生成能力的改进，生成结构化解释以验证模型的真正推理能力仍然是一大挑战。 特别是对于小型LM，因为推理者需要同时生成序列答案和结构化解释，这种问题更加突出。 在这种工作中，我们首先强调了监督练习（SFT）的局限性，然后引入了仪器学习（RL）中的奖励工程学方法，以更好地解决这个问题。 我们 investigate多种奖励汇聚方法，并提供了详细的讨论，这有助于探讨RL在未来研究中的潜在潜力。 我们的提议的奖励在两个 semi-structured 解释生成 benchmark（ExplaGraph 和 COPA-SSE）上实现了新的状态 искусственный智能领域的最佳成绩。
</details></li>
</ul>
<hr>
<h2 id="Distributional-Inclusion-Hypothesis-and-Quantifications-Probing-Hypernymy-in-Functional-Distributional-Semantics"><a href="#Distributional-Inclusion-Hypothesis-and-Quantifications-Probing-Hypernymy-in-Functional-Distributional-Semantics" class="headerlink" title="Distributional Inclusion Hypothesis and Quantifications: Probing Hypernymy in Functional Distributional Semantics"></a>Distributional Inclusion Hypothesis and Quantifications: Probing Hypernymy in Functional Distributional Semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08325">http://arxiv.org/abs/2309.08325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chun Hei Lo, Guy Emerson</li>
<li>for: 本文探讨了函数分布semantics（FDS）模型词义的方法，以及如何通过这种方法学习词义的不同层次结构。</li>
<li>methods: 本文使用了FDS模型，并对其进行了训练，以便学习词义的不同层次结构。</li>
<li>results: 实验结果表明，当文本资料集 strictly follows Distributional Inclusion Hypothesis时，FDS模型就可以学习词义的层次结构，并且可以处理简单的通用量化。<details>
<summary>Abstract</summary>
Functional Distributional Semantics (FDS) models the meaning of words by truth-conditional functions. This provides a natural representation for hypernymy, but no guarantee that it is learnt when FDS models are trained on a corpus. We demonstrate that FDS models learn hypernymy when a corpus strictly follows the Distributional Inclusion Hypothesis. We further introduce a training objective that allows FDS to handle simple universal quantifications, thus enabling hypernymy learning under the reverse of DIH. Experimental results on both synthetic and real data sets confirm our hypotheses and the effectiveness of our proposed objective.
</details>
<details>
<summary>摘要</summary>
功能分布 semantics (FDS) 模型表示词语意义通过真理条件函数。这提供了自然的表示方式，但无 garantía que se aprenda hiperonimia when FDS 模型在一个 corpus 上训练。我们证明了 FDS 模型在 strictly following the Distributional Inclusion Hypothesis 的 corpus 上学习 hiperonimia。我们还引入了一个培训目标，allowing FDS 处理简单的通用量化，因此允许 hiperonimia 学习 under the reverse of DIH。实验结果表明我们的假设成立，并且我们的提议的目标有效。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Topic-Domain-and-Language-Shifts-An-Evaluation-of-Comprehensive-Out-of-Distribution-Scenarios"><a href="#Bridging-Topic-Domain-and-Language-Shifts-An-Evaluation-of-Comprehensive-Out-of-Distribution-Scenarios" class="headerlink" title="Bridging Topic, Domain, and Language Shifts: An Evaluation of Comprehensive Out-of-Distribution Scenarios"></a>Bridging Topic, Domain, and Language Shifts: An Evaluation of Comprehensive Out-of-Distribution Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08316">http://arxiv.org/abs/2309.08316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Waldis, Iryna Gurevych</li>
<li>for: 本研究旨在评估语言模型（LMs）在各种异常情况下的泛化能力，包括主题、领域和语言方面的偏差。</li>
<li>methods: 研究人员采用了各种方法，包括准备分析、推荐策略和语言模型的练习，以评估LMs的泛化能力。</li>
<li>results: 研究发现，在各种异常情况下，提示基本 fine-tuning 表现最佳，特别是当训练和测试数据主要差异 semantic 时。同时，在 context 学习比 prompt-based fine-tuning 和 vanilla fine-tuning 更有效，尤其是在训练数据中存在重要差异的情况下。这表明，梯度学习带来了一定的结构性偏见。<details>
<summary>Abstract</summary>
Language models (LMs) excel in in-distribution (ID) scenarios where train and test data are independent and identically distributed. However, their performance often degrades in real-world applications like argument mining. Such degradation happens when new topics emerge, or other text domains and languages become relevant. To assess LMs' generalization abilities in such out-of-distribution (OOD) scenarios, we simulate such distribution shifts by deliberately withholding specific instances for testing, as from the social media domain or the topic Solar Energy.   Unlike prior studies focusing on specific shifts and metrics in isolation, we comprehensively analyze OOD generalization. We define three metrics to pinpoint generalization flaws and propose eleven classification tasks covering topic, domain, and language shifts. Overall, we find superior performance of prompt-based fine-tuning, notably when train and test splits primarily differ semantically. Simultaneously, in-context learning is more effective than prompt-based or vanilla fine-tuning for tasks when training data embodies heavy discrepancies in label distribution compared to testing data. This reveals a crucial drawback of gradient-based learning: it biases LMs regarding such structural obstacles.
</details>
<details>
<summary>摘要</summary>
Unlike previous studies that focused on specific shifts and metrics in isolation, we comprehensively analyze OOD generalization by defining three metrics to identify generalization flaws. We also propose eleven classification tasks covering topic, domain, and language shifts. Our results show that prompt-based fine-tuning performs better than other methods, especially when the train and test splits differ semantically. Additionally, in-context learning is more effective than prompt-based or vanilla fine-tuning for tasks with significant differences in label distribution between training and testing data. This highlights a limitation of gradient-based learning, as it can bias LMs towards such structural obstacles.
</details></li>
</ul>
<hr>
<h2 id="Self-Consistent-Narrative-Prompts-on-Abductive-Natural-Language-Inference"><a href="#Self-Consistent-Narrative-Prompts-on-Abductive-Natural-Language-Inference" class="headerlink" title="Self-Consistent Narrative Prompts on Abductive Natural Language Inference"></a>Self-Consistent Narrative Prompts on Abductive Natural Language Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08303">http://arxiv.org/abs/2309.08303</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkust-knowcomp/alpha-pace">https://github.com/hkust-knowcomp/alpha-pace</a></li>
<li>paper_authors: Chunkit Chan, Xin Liu, Tsz Ho Chan, Jiayang Cheng, Yangqiu Song, Ginny Wong, Simon See</li>
<li>for: 本研究旨在提高αNLI任务（即叙述语言推理任务）中的自适应性和叙述连续性。</li>
<li>methods: 本研究提出了一种Prompt Tuning模型（α-PACE），该模型考虑了自适应性和叙述连续性。此外，本研究还提出了一种通用自适应框架，该框架可以指导预训练语言模型理解输入叙述文本的叙述Context。</li>
<li>results: 本研究通过广泛的实验和细化的降级研究表明了α-PACE模型的效果。与普通竞争对手相比，α-PACE模型的性能显著提高。<details>
<summary>Abstract</summary>
Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference ($\alpha$NLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model $\alpha$-PACE, which takes self-consistency and inter-sentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of $\alpha$-PACE. The performance of our method shows significant improvement against extensive competitive baselines.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference ($\alpha$NLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model $\alpha$-PACE, which takes self-consistency and inter-sentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of $\alpha$-PACE. The performance of our method shows significant improvement against extensive competitive baselines." into Simplified Chinese.以下是文本的中文翻译：<<SYS>>往日，强制被视为叙事理解和日常情境理解中的关键因素。 $\alpha$NLI任务已经被提出，这是基于文本的叙事任务，旨在从候选假设中选择最有可能性的假设。然而，之前的工作未能充分利用文本间的一致性和模型一致性。在这种情况下，我们提出了一种适应模型$\alpha$-PACE，该模型考虑了自我一致性和文本间一致性。此外，我们还提出了一种通用自一致框架，该框架考虑了不同的叙事顺序（例如，直线叙事和倒计时间顺序），以帮助预训练语言模型理解输入的叙事背景。我们进行了广泛的实验和细致的折衣研究，以证明 $\alpha$-PACE 的必要性和有效性。我们的方法在与多种竞争性基准模型进行比较时表现出了显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Structural-Self-Supervised-Objectives-for-Transformers"><a href="#Structural-Self-Supervised-Objectives-for-Transformers" class="headerlink" title="Structural Self-Supervised Objectives for Transformers"></a>Structural Self-Supervised Objectives for Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08272">http://arxiv.org/abs/2309.08272</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lucadiliello/transformers-framework">https://github.com/lucadiliello/transformers-framework</a></li>
<li>paper_authors: Luca Di Liello</li>
<li>for: 本研究旨在提高自然语言模型的预训练，使其更加效率和下游应用更加一致。</li>
<li>methods: 本研究引入了三种代替BERT的Masked Language Modeling（MLM）目标，namely Random Token Substitution（RTS）、Cluster-based Random Token Substitution（C-RTS）和Swapped Language Modeling（SLM）。这些目标使用Token替换而不是遮盖，RTS和C-RTS预测Token的原始性，SLM预测原始Token的值。 results show que RTS和C-RTS需要较少的预训练时间， yet maintains performance comparable to MLM。Surprisingly, SLM outperforms MLM on certain tasks despite using the same computational budget。</li>
<li>results: 本研究还提出了一些自然语言模型的自我超vised预训练任务，以适应下游应用。通过使用大量的文本数据，如Wikipedia和CC-News，我们训练模型可以识别文本段的来源，以及文本段是否来自同一篇文章或文档。通过不断的预训练，我们从现有的模型如RoBERTa、ELECTRA、DeBERTa、BART和T5开始，并示出了对各种任务的显著性提高，如 Fact Verification、Answer Sentence Selection和概要。这些提高尤其明显在有限的标注数据available。此外，我们还实现了多种标准 benchmark datasets的state-of-the-art results，包括 FEVER（开发集）、ASNQ、WikiQA和TREC-QA，以及提高概要的质量。<details>
<summary>Abstract</summary>
This thesis focuses on improving the pre-training of natural language models using unsupervised raw data to make them more efficient and aligned with downstream applications.   In the first part, we introduce three alternative pre-training objectives to BERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS), Cluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling (SLM). These objectives involve token swapping instead of masking, with RTS and C-RTS aiming to predict token originality and SLM predicting the original token values. Results show that RTS and C-RTS require less pre-training time while maintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on certain tasks despite using the same computational budget.   In the second part, we proposes self-supervised pre-training tasks that align structurally with downstream applications, reducing the need for labeled data. We use large corpora like Wikipedia and CC-News to train models to recognize if text spans originate from the same paragraph or document in several ways. By doing continuous pre-training, starting from existing models like RoBERTa, ELECTRA, DeBERTa, BART, and T5, we demonstrate significant performance improvements in tasks like Fact Verification, Answer Sentence Selection, and Summarization. These improvements are especially pronounced when limited annotation data is available. The proposed objectives also achieve state-of-the-art results on various benchmark datasets, including FEVER (dev set), ASNQ, WikiQA, and TREC-QA, as well as enhancing the quality of summaries. Importantly, these techniques can be easily integrated with other methods without altering the internal structure of Transformer models, making them versatile for various NLP applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Cross-lingual-Knowledge-Distillation-via-Flow-based-Voice-Conversion-for-Robust-Polyglot-Text-To-Speech"><a href="#Cross-lingual-Knowledge-Distillation-via-Flow-based-Voice-Conversion-for-Robust-Polyglot-Text-To-Speech" class="headerlink" title="Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech"></a>Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08255">http://arxiv.org/abs/2309.08255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dariusz Piotrowski, Renard Korzeniowski, Alessio Falai, Sebastian Cygert, Kamil Pokora, Georgi Tinchev, Ziyao Zhang, Kayoko Yanagisawa</li>
<li>for: 这个研究旨在提出一个跨语言语音合成框架，用于将原始语言的语音转换为目标语言的声音，以提高语音识别度和准确性。</li>
<li>methods: 本研究使用了一个四个阶段的框架，包括：在第一个阶段使用语音转换模型将目标语言的语音转换为目标声音的声音，在第二个阶段使用语音转换模型将目标语言的语音转换为目标声音的声音，在第三个阶段使用语音转换模型将目标语言的语音转换为目标声音的声音，最后一个阶段则是使用一个无地域预测器进行训练。</li>
<li>results: 本研究的实验结果显示，提出的框架在比较于现有的方法时表现较好，并且在不同的架构、语言、说话者和资料量下都能够获得良好的效果。此外，本研究的方法特别适合低资源环境。<details>
<summary>Abstract</summary>
In this work, we introduce a framework for cross-lingual speech synthesis, which involves an upstream Voice Conversion (VC) model and a downstream Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the first two stages, we use a VC model to convert utterances in the target locale to the voice of the target speaker. In the third stage, the converted data is combined with the linguistic features and durations from recordings in the target language, which are then used to train a single-speaker acoustic model. Finally, the last stage entails the training of a locale-independent vocoder. Our evaluations show that the proposed paradigm outperforms state-of-the-art approaches which are based on training a large multilingual TTS model. In addition, our experiments demonstrate the robustness of our approach with different model architectures, languages, speakers and amounts of data. Moreover, our solution is especially beneficial in low-resource settings.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们提出了一种跨语言语音合成框架，包括4个阶段。在第一两个阶段，我们使用一个语音转换（VC）模型将目标地区的语音转换为目标说话人的voice。在第三个阶段，转换后的数据与目标语言的语音特征和持续时间从录音中提取出来，并用于训练单个说话人的听音模型。最后一个阶段是训练无关地区的 vocoder。我们的评估表明，我们的方法超过了当前状态的方法，基于大量多语言 TTS 模型的训练。此外，我们的实验还证明了我们的方法在不同的模型架构、语言、说话人和数据量下都具有 robustness。此外，我们的解决方案特别有利于低资源的设置。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Answerability-of-LLMs-for-Long-Form-Question-Answering"><a href="#Investigating-Answerability-of-LLMs-for-Long-Form-Question-Answering" class="headerlink" title="Investigating Answerability of LLMs for Long-Form Question Answering"></a>Investigating Answerability of LLMs for Long-Form Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08210">http://arxiv.org/abs/2309.08210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meghana Moorthy Bhat, Rui Meng, Ye Liu, Yingbo Zhou, Semih Yavuz</li>
<li>for: 了解大量LLMs（如ChatGPT）和小型开源LLMs的差异，以及它们的抽象和缩短版本的不同特点。</li>
<li>methods: 基于抽象摘要生成问题的方法，用于测试LLMs的理解和推理能力。</li>
<li>results: 研究结果显示，使用抽象摘要生成问题可以为LLMs提供一个挑战性的测试环境，并显示了大量LLMs和开源LLMs之间的性能差异，特别是在 longer contexts（&gt;1024 tokens）下。<details>
<summary>Abstract</summary>
As we embark on a new era of LLMs, it becomes increasingly crucial to understand their capabilities, limitations, and differences. Toward making further progress in this direction, we strive to build a deeper understanding of the gaps between massive LLMs (e.g., ChatGPT) and smaller yet effective open-source LLMs and their distilled counterparts. To this end, we specifically focus on long-form question answering (LFQA) because it has several practical and impactful applications (e.g., troubleshooting, customer service, etc.) yet is still understudied and challenging for LLMs. We propose a question-generation method from abstractive summaries and show that generating follow-up questions from summaries of long documents can create a challenging setting for LLMs to reason and infer from long contexts. Our experimental results confirm that: (1) our proposed method of generating questions from abstractive summaries pose a challenging setup for LLMs and shows performance gaps between LLMs like ChatGPT and open-source LLMs (Alpaca, Llama) (2) open-source LLMs exhibit decreased reliance on context for generated questions from the original document, but their generation capabilities drop significantly on generated questions from summaries -- especially for longer contexts (>1024 tokens)
</details>
<details>
<summary>摘要</summary>
As we enter a new era of LLMs, it becomes increasingly important to understand their capabilities, limitations, and differences. To make further progress in this area, we aim to deepen our understanding of the gaps between massive LLMs (e.g., ChatGPT) and smaller yet effective open-source LLMs and their distilled counterparts. Specifically, we focus on long-form question answering (LFQA) as it has many practical and impactful applications (e.g., troubleshooting, customer service) yet is still understudied and challenging for LLMs. We propose a question-generation method from abstractive summaries and show that generating follow-up questions from summaries of long documents can create a challenging setting for LLMs to reason and infer from long contexts. Our experimental results confirm that:1. Our proposed method of generating questions from abstractive summaries poses a challenging setup for LLMs, and shows performance gaps between LLMs like ChatGPT and open-source LLMs (Alpaca, Llama).2. Open-source LLMs exhibit decreased reliance on context for generated questions from the original document, but their generation capabilities drop significantly on generated questions from summaries, especially for longer contexts (>1024 tokens).
</details></li>
</ul>
<hr>
<h2 id="Encoded-Summarization-Summarizing-Documents-into-Continuous-Vector-Space-for-Legal-Case-Retrieval"><a href="#Encoded-Summarization-Summarizing-Documents-into-Continuous-Vector-Space-for-Legal-Case-Retrieval" class="headerlink" title="Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval"></a>Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08187">http://arxiv.org/abs/2309.08187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vu Tran, Minh Le Nguyen, Satoshi Tojo, Ken Satoh</li>
<li>for: 这个论文是为了解决法律案例检索任务而提出的方法。</li>
<li>methods: 该方法利用深度神经网络来编码文档，将文档摘要化成连续的向量空间中。同时，该方法还利用神经网络生成的含义特征和语言特征来提高检索系统的性能。</li>
<li>results: 实验结果表明，利用提供的摘要和编码摘要可以提高检索系统的性能。此外，该方法的实验结果还表明，神经网络生成的含义特征和语言特征可以补充each other，以提高检索系统的性能。该方法在法律案例检索任务上达到了F1分数的65.6%和57.6%。<details>
<summary>Abstract</summary>
We present our method for tackling a legal case retrieval task by introducing our method of encoding documents by summarizing them into continuous vector space via our phrase scoring framework utilizing deep neural networks. On the other hand, we explore the benefits from combining lexical features and latent features generated with neural networks. Our experiments show that lexical features and latent features generated with neural networks complement each other to improve the retrieval system performance. Furthermore, our experimental results suggest the importance of case summarization in different aspects: using provided summaries and performing encoded summarization. Our approach achieved F1 of 65.6% and 57.6% on the experimental datasets of legal case retrieval tasks.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法来解决法律案件检索任务，通过我们的文档编码方法，将文档摘要到连续向量空间中。我们利用深度神经网络来实现文档编码，并 explore了将 lexical 特征和 latent 特征结合使用的好处。我们的实验结果表明，lexical 特征和 latent 特征在不同方面进行补做，可以提高检索系统的性能。此外，我们的实验结果还表明，案件摘要在不同方面具有重要性：使用提供的摘要和自动生成摘要。我们的方法在法律案件检索任务上实现了 F1 分数的 65.6% 和 57.6%。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Sentence-Level-Semantic-Search-using-Meta-Distillation-Learning"><a href="#Multilingual-Sentence-Level-Semantic-Search-using-Meta-Distillation-Learning" class="headerlink" title="Multilingual Sentence-Level Semantic Search using Meta-Distillation Learning"></a>Multilingual Sentence-Level Semantic Search using Meta-Distillation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08185">http://arxiv.org/abs/2309.08185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meryem M’hamdi, Jonathan May, Franck Dernoncourt, Trung Bui, Seunghyun Yoon</li>
<li>for: 本研究旨在提高多语言Semantic Search的精度和效率，使其能够更好地理解用户的意图和含义。</li>
<li>methods: 本研究使用了Meta-distillation学习方法，特性是利用Teacher模型T-MAML来传递知识到Student模型S-MAML，从而提高Student模型在多语言Semantic Search中的性能。</li>
<li>results: 实验结果表明，相比基础模型和naive fine-tuning方法， meta-distillation方法可以大幅提高MAML的性能，并且在未看到的语言上也有较好的一致性。<details>
<summary>Abstract</summary>
Multilingual semantic search is the task of retrieving relevant contents to a query expressed in different language combinations. This requires a better semantic understanding of the user's intent and its contextual meaning. Multilingual semantic search is less explored and more challenging than its monolingual or bilingual counterparts, due to the lack of multilingual parallel resources for this task and the need to circumvent "language bias". In this work, we propose an alignment approach: MAML-Align, specifically for low-resource scenarios. Our approach leverages meta-distillation learning based on MAML, an optimization-based Model-Agnostic Meta-Learner. MAML-Align distills knowledge from a Teacher meta-transfer model T-MAML, specialized in transferring from monolingual to bilingual semantic search, to a Student model S-MAML, which meta-transfers from bilingual to multilingual semantic search. To the best of our knowledge, we are the first to extend meta-distillation to a multilingual search application. Our empirical results show that on top of a strong baseline based on sentence transformers, our meta-distillation approach boosts the gains provided by MAML and significantly outperforms naive fine-tuning methods. Furthermore, multilingual meta-distillation learning improves generalization even to unseen languages.
</details>
<details>
<summary>摘要</summary>
多语言Semantic搜索是查询表达在不同语言组合中的相关内容。这需要更好地理解用户的意图和其语言上下文意义。由于多语言Semantic搜索相比于单语言或双语搜索更加不explored和更加挑战，因为缺乏多语言平行资源 для这个任务，并且需要绕过“语言偏见”。在这种工作中，我们提出了一种对齐方法：MAML-Align，专门针对低资源场景。我们的方法利用了meta-distillation学习基于MAML，一种基于Model-Agnostic Meta-Learner的优化算法。MAML-Align从一个特有的Teacher meta-传播模型T-MAML，该模型专门从单语言Semantic搜索转移到双语Semantic搜索，将知识传播到一个Student模型S-MAML，该模型从双语Semantic搜索转移到多语言Semantic搜索。根据我们所知，我们是首次将meta-distillation应用于多语言搜索应用。我们的实验结果表明，在一个强大的基础模型基于 sentence transformers 上，我们的meta-distillation方法可以提高MAML的效果，并且明显超过了简单的微调方法。此外，多语言meta-distillation学习还能提高到未看到的语言上的总体性能。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Failure-Mode-Classification-An-Investigation"><a href="#Large-Language-Models-for-Failure-Mode-Classification-An-Investigation" class="headerlink" title="Large Language Models for Failure Mode Classification: An Investigation"></a>Large Language Models for Failure Mode Classification: An Investigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08181">http://arxiv.org/abs/2309.08181</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nlp-tlp/chatgpt-fmc">https://github.com/nlp-tlp/chatgpt-fmc</a></li>
<li>paper_authors: Michael Stewart, Melinda Hodkiewicz, Sirui Li</li>
<li>for: 这个研究旨在评估大语言模型（LLMs）在失败模式分类（FMC）任务中的效果。</li>
<li>methods: 我们采用了提示工程来使一个GPT-3.5模型（F1&#x3D;0.80）预测给定观察的失败模式使用限定的编码列表。</li>
<li>results: 我们发现，使用精心预处理的数据集进行高质量的 fine-tuning可以提高GPT-3.5模型的性能（F1&#x3D;0.80），并且超过了现有的文本分类模型（F1&#x3D;0.60）和尝试模型（F1&#x3D;0.46）。<details>
<summary>Abstract</summary>
In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了大语言模型（LLM）的效果调查在故障模式分类（FMC）任务中。 FMC 是维保领域中的一项重要任务，它可以减少可靠工程师的时间 manually 分析工作订单。我们详细介绍了我们的激励程序工程来使得 LLM 可以使用限定的代码列表预测给定观察的故障模式。我们展示了一个 GPT-3.5 模型（F1=0.80）在注释数据上进行精度调整后的性能明显提高，与现有的文本分类模型（F1=0.60）在同一个注释数据集上进行训练后的性能相比。此外，我们还证明了 fine-tuned 模型在原始 GPT-3.5 模型（F1=0.46）上也表现出了显著的改善。这一调查证明了在域pecific任务中使用 LLM 需要高质量的 fine-tuning 数据集。
</details></li>
</ul>
<hr>
<h2 id="FedJudge-Federated-Legal-Large-Language-Model"><a href="#FedJudge-Federated-Legal-Large-Language-Model" class="headerlink" title="FedJudge: Federated Legal Large Language Model"></a>FedJudge: Federated Legal Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08173">http://arxiv.org/abs/2309.08173</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuelinan/fedjudge">https://github.com/yuelinan/fedjudge</a></li>
<li>paper_authors: Linan Yue, Qi Liu, Yichao Du, Weibo Gao, Ye Liu, Fangzhou Yao</li>
<li>for: 这篇论文旨在解决大语言模型在法律智能领域中的数据隐私问题，通过融合法律大语言模型和联邦学习方法。</li>
<li>methods: 这篇论文提出了一个名为 FedJudge 的框架，它使用了优化的法律大语言模型，并使用联邦学习方法进行本地化训练，以确保数据隐私。</li>
<li>results: 实验结果显示，FedJudge 能够有效地训练法律大语言模型，并且可以适应不同的数据分布。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have gained prominence in the field of Legal Intelligence, offering potential applications in assisting legal professionals and laymen. However, the centralized training of these Legal LLMs raises data privacy concerns, as legal data is distributed among various institutions containing sensitive individual information. This paper addresses this challenge by exploring the integration of Legal LLMs with Federated Learning (FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on devices or clients, and their parameters are aggregated and distributed on a central server, ensuring data privacy without directly sharing raw data. However, computation and communication overheads hinder the full fine-tuning of LLMs under the FL setting. Moreover, the distribution shift of legal data reduces the effectiveness of FL methods. To this end, in this paper, we propose the first Federated Legal Large Language Model (FedJudge) framework, which fine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge utilizes parameter-efficient fine-tuning methods to update only a few additional parameters during the FL training. Besides, we explore the continual learning methods to preserve the global model's important parameters when training local clients to mitigate the problem of data shifts. Extensive experimental results on three real-world datasets clearly validate the effectiveness of FedJudge. Code is released at https://github.com/yuelinan/FedJudge.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在法律智能领域的应用优势吸引了广泛的关注，可以帮助法律专业人员和非专业人员。然而，中央训练这些法律 LLM 会引起数据隐私问题，因为法律数据分散在各个机构中，每个机构都包含敏感个人信息。本文解决这个挑战，通过探讨法律 LLM 与联合学习（FL）方法的结合。通过使用 FL，法律 LLM 可以在设备或客户端上进行本地微调，并将参数集中到中央服务器上，保证数据隐私而无需直接分享原始数据。然而，在 FL 设置下 computation 和通信开销妨碍了法律 LLM 的全面微调。此外，法律数据的分布差shift 也减少了 FL 方法的有效性。为此，本文提出了首个 Federated Legal Large Language Model（FedJudge）框架，可以高效地微调法律 LLM。特别是，FedJudge 使用 parameter-efficient 微调方法来在 FL 训练中更新只几个额外参数。此外，我们还探讨了连续学习方法，以保持全局模型中重要参数的稳定性，从而 Mitigate 数据差shift 问题。实验结果表明，FedJudge 在三个实际数据集上具有极高的有效性。代码可以在 <https://github.com/yuelinan/FedJudge> 上下载。
</details></li>
</ul>
<hr>
<h2 id="LASER-LLM-Agent-with-State-Space-Exploration-for-Web-Navigation"><a href="#LASER-LLM-Agent-with-State-Space-Exploration-for-Web-Navigation" class="headerlink" title="LASER: LLM Agent with State-Space Exploration for Web Navigation"></a>LASER: LLM Agent with State-Space Exploration for Web Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08172">http://arxiv.org/abs/2309.08172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiaoman Pan, Dong Yu</li>
<li>for: 这个论文是为了解决大型语言模型在交互决策任务中的问题，例如网络浏览。</li>
<li>methods: 这个论文使用了模型州空间探索的方法，将大型语言模型 Agent 转移到一组已定义的状态中，并通过行动完成任务。</li>
<li>results: 实验结果显示，这个方法可以让大型语言模型 Agent 在网络浏览任务中表现出色，并且与人类性能更近。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been successfully adapted for interactive decision-making tasks like web navigation. While achieving decent performance, previous methods implicitly assume a forward-only execution mode for the model, where they only provide oracle trajectories as in-context examples to teach the model how to reason in the interactive environment. Consequently, the model could not handle more challenging scenarios not covered in the in-context examples, e.g., mistakes, leading to sub-optimal performance. To address this issue, we propose to model the interactive task as state space exploration, where the LLM agent transitions among a pre-defined set of states by performing actions to complete the task. This formulation enables flexible back-tracking, allowing the model to easily recover from errors. We evaluate our proposed LLM Agent with State-Space ExploRation (LASER) on the WebShop task. Experimental results show that our LASER agent significantly outperforms previous methods and closes the gap with human performance on the web navigation task.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose modeling the interactive task as state space exploration, where the LLM agent transitions among a pre-defined set of states by performing actions to complete the task. This formulation enables flexible back-tracking, allowing the model to easily recover from errors. We evaluate our proposed LLM Agent with State-Space ExploRation (LASER) on the WebShop task. Experimental results show that our LASER agent significantly outperforms previous methods and closes the gap with human performance on the web navigation task.Here's the text in Simplified Chinese:大型语言模型（LLM）已经成功地应用到互动决策任务中，如网络浏览。虽然取得了不错的表现，但前一些方法都是假设LLM模型在前进方式下执行，即只提供了oracle路径作为互动环境中的示范例子，教导模型在互动环境中如何思考。这限制了模型的能力，不能处理更加具体的情况，导致表现不佳。为了解决这个问题，我们提议将互动任务模型为州空间探索， LLM代理在预先定义的状态集中转移，通过执行动作完成任务。这种形式允许灵活的回溯，让模型轻松地复原自错误。我们将我们的LASER代理评估在WebShop任务上。实验结果显示，我们的LASER代理与前一些方法相比，表现出色，几乎与人类表现相同。
</details></li>
</ul>
<hr>
<h2 id="Draft-Verify-Lossless-Large-Language-Model-Acceleration-via-Self-Speculative-Decoding"><a href="#Draft-Verify-Lossless-Large-Language-Model-Acceleration-via-Self-Speculative-Decoding" class="headerlink" title="Draft &amp; Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding"></a>Draft &amp; Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08168">http://arxiv.org/abs/2309.08168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen, Gang Chen, Sharad Mehrotra</li>
<li>for: 加速大型自然语言模型（LLMs）的推理过程，无需额外模型。</li>
<li>methods: 提出了一种新的推理方案，即自我推测解oding，通过在推理过程中 selectively 跳过某些中间层来快速生成稿件，然后使用原始 LLMA 进行验证。</li>
<li>results: 对 LLaMA-2 和其精度模型进行了测试，获得了最高速up到 1.73 倍的加速效果。<details>
<summary>Abstract</summary>
We present a novel inference scheme, self-speculative decoding, for accelerating Large Language Models (LLMs) without the need for an auxiliary model. This approach is characterized by a two-stage process: drafting and verification. The drafting stage generates draft tokens at a slightly lower quality but more quickly, which is achieved by selectively skipping certain intermediate layers during drafting Subsequently, the verification stage employs the original LLM to validate those draft output tokens in one forward pass. This process ensures the final output remains identical to that produced by the unaltered LLM, thereby maintaining output quality. The proposed method requires no additional neural network training and no extra memory footprint, making it a plug-and-play and cost-effective solution for inference acceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a speedup up to 1.73$\times$.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的推理方案，自我推敲，用于加速大语言模型（LLM），无需额外模型。这种方法包括两个阶段：稿件阶段和验证阶段。在稿件阶段，我们选择性地跳过某些中间层，以更快速地生成稿件，但是这些稿件的质量可能会下降些。然后，验证阶段使用原始的 LLM 来验证这些稿件输出token，并在一个前进 pass 中确认它们的正确性。这个过程保证了最终输出的质量与原始 LLM 输出的质量一样，因此不需要进行额外的神经网络训练和额外的存储空间。我们在 LLMA-2 和其精度调整模型上进行了 benchmark，并达到了 1.73 倍的速度提升。
</details></li>
</ul>
<hr>
<h2 id="RADE-Reference-Assisted-Dialogue-Evaluation-for-Open-Domain-Dialogue"><a href="#RADE-Reference-Assisted-Dialogue-Evaluation-for-Open-Domain-Dialogue" class="headerlink" title="RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue"></a>RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08156">http://arxiv.org/abs/2309.08156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengliang Shi, Weiwei Sun, Shuo Zhang, Zhen Zhang, Pengjie Ren, Zhaochun Ren</li>
<li>For: 评估开放领域对话系统的自动评估方法，解决一个问题，即一个回答中有多种可能性。* Methods: 提出了Reference-Assisted Dialogue Evaluation（RADE）方法，利用预创建的对话utterance作为参考，相比金标签回答，解决一元多个问题。具体来说，RADE将参考和候选回答进行直接比较，预测回答的总分。此外，还添加了一个辅助回答生成任务，通过共享编码器提高预测。* Results: 在三个 dataset和两个现有的benchmark上进行了实验，与人类评估相比，Pearson、Spearman和Kendall相关度都高于现有基eline。<details>
<summary>Abstract</summary>
Evaluating open-domain dialogue systems is challenging for reasons such as the one-to-many problem, i.e., many appropriate responses other than just the golden response. As of now, automatic evaluation methods need better consistency with humans, while reliable human evaluation can be time- and cost-intensive. To this end, we propose the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which leverages the pre-created utterance as reference other than the gold response to relief the one-to-many problem. Specifically, RADE explicitly compares reference and the candidate response to predict their overall scores. Moreover, an auxiliary response generation task enhances prediction via a shared encoder. To support RADE, we extend three datasets with additional rated responses other than just a golden response by human annotation. Experiments on our three datasets and two existing benchmarks demonstrate the effectiveness of our method, where Pearson, Spearman, and Kendall correlations with human evaluation outperform state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
评估开放领域对话系统具有一些挑战，如一对多问题，即许多合适的回答而不仅是理想的回答。目前，自动评估方法需要更好的一致性与人类，而可靠的人类评估可能是时间和成本占用的。为此，我们提出了参考助力对话评估（RADE）方法，它利用预创建的话语作为参考而不是理想的回答来解决一对多问题。具体来说，RADE直接比较参考和候选答案的总分。此外，一个辅助回答生成任务通过共享Encoder来增强预测。为支持RADE，我们将三个数据集扩展为包括人类标注的多个评估答案。我们的实验表明，我们的方法可以在我们的三个数据集和两个现有的标准 benchmarke上具有更高的各种Spearman、Pearson和Kendall相关性 coefficient与人类评估，超过当前的基elines。
</details></li>
</ul>
<hr>
<h2 id="Unimodal-Aggregation-for-CTC-based-Speech-Recognition"><a href="#Unimodal-Aggregation-for-CTC-based-Speech-Recognition" class="headerlink" title="Unimodal Aggregation for CTC-based Speech Recognition"></a>Unimodal Aggregation for CTC-based Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08150">http://arxiv.org/abs/2309.08150</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Audio-WestlakeU/UMA-ASR">https://github.com/Audio-WestlakeU/UMA-ASR</a></li>
<li>paper_authors: Ying Fang, Xiaofei Li</li>
<li>for: 这 paper 是关于非autoregressive自动语音识别的研究，旨在学习更好的特征表示以提高识别精度和计算复杂度。</li>
<li>methods: 提议的方法是基于encoder获取帧 wise features和权重，然后通过decoder进行集成和处理。另外，还应用了CTC损失函数进行训练。</li>
<li>results: 对三个普通话 dataset 进行实验表明，提议的方法可以与其他高级非 autoregressive方法相比，并且可以降低识别错误率和计算复杂度。此外，通过将self-conditioned CTC integrate到提议的框架中，可以进一步提高性能。<details>
<summary>Abstract</summary>
This paper works on non-autoregressive automatic speech recognition. A unimodal aggregation (UMA) is proposed to segment and integrate the feature frames that belong to the same text token, and thus to learn better feature representations for text tokens. The frame-wise features and weights are both derived from an encoder. Then, the feature frames with unimodal weights are integrated and further processed by a decoder. Connectionist temporal classification (CTC) loss is applied for training. Compared to the regular CTC, the proposed method learns better feature representations and shortens the sequence length, resulting in lower recognition error and computational complexity. Experiments on three Mandarin datasets show that UMA demonstrates superior or comparable performance to other advanced non-autoregressive methods, such as self-conditioned CTC. Moreover, by integrating self-conditioned CTC into the proposed framework, the performance can be further noticeably improved.
</details>
<details>
<summary>摘要</summary>
这篇论文工作在非autoregressive自动语音识别领域。我们提议一种单modal聚合（UMA）来段化和集成相同文本 токен的特征帧，从而学习更好的特征表示。特征帧和权重都来自Encoder。然后，通过Decoder进行进一步处理。使用Connectionist Temporal Classification（CTC）损失来训练。与常规CTC相比，我们的方法学习的特征表示更好，序列长度更短，识别错误和计算复杂性都更低。在三个普通话 datasets上进行了实验，UMA表现出优于其他高级非autoregressive方法，如自conditioned CTC。此外，通过将自conditioned CTC integrate到我们的框架中，可以进一步提高表现。
</details></li>
</ul>
<hr>
<h2 id="PromptTTS-Controlling-Speaker-Identity-in-Prompt-Based-Text-to-Speech-Using-Natural-Language-Descriptions"><a href="#PromptTTS-Controlling-Speaker-Identity-in-Prompt-Based-Text-to-Speech-Using-Natural-Language-Descriptions" class="headerlink" title="PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions"></a>PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08140">http://arxiv.org/abs/2309.08140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reo Shimizu, Ryuichi Yamamoto, Masaya Kawamura, Yuma Shirahata, Hironori Doi, Tatsuya Komatsu, Kentaro Tachibana</li>
<li>for: This paper is written for researchers and developers interested in text-to-speech (TTS) synthesis, particularly those looking to control speaker identity using natural language descriptions.</li>
<li>methods: The paper proposes a prompt-based TTS synthesis system called PromptTTS++, which utilizes a diffusion-based acoustic model with mixture density networks to model diverse speaker factors in the training data. The system also introduces the concept of speaker prompts, which describe voice characteristics such as gender-neutral, young, old, and muffled.</li>
<li>results: The subjective evaluation results show that the proposed method can better control speaker characteristics than previous methods without the speaker prompt. The authors also provide audio samples to demonstrate the effectiveness of their approach.<details>
<summary>Abstract</summary>
We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system that allows control over speaker identity using natural language descriptions. To control speaker identity within the prompt-based TTS framework, we introduce the concept of speaker prompt, which describes voice characteristics (e.g., gender-neutral, young, old, and muffled) designed to be approximately independent of speaking style. Since there is no large-scale dataset containing speaker prompts, we first construct a dataset based on the LibriTTS-R corpus with manually annotated speaker prompts. We then employ a diffusion-based acoustic model with mixture density networks to model diverse speaker factors in the training data. Unlike previous studies that rely on style prompts describing only a limited aspect of speaker individuality, such as pitch, speaking speed, and energy, our method utilizes an additional speaker prompt to effectively learn the mapping from natural language descriptions to the acoustic features of diverse speakers. Our subjective evaluation results show that the proposed method can better control speaker characteristics than the methods without the speaker prompt. Audio samples are available at https://reppy4620.github.io/demo.promptttspp/.
</details>
<details>
<summary>摘要</summary>
我们提出PromptTTS++,一种基于提示的文本译为语音（TTS）生成系统，允许通过自然语言描述控制发音人的身份。在基于提示的TTS框架中控制发音人的身份，我们引入发音人提示，描述语言特征（例如，中性、年轻、老、嘴巴覆盖），这些特征被设计为基本独立于说话风格。由于没有大规模的发音人提示数据集，我们首先基于LibriTTS-R corpus构建了一个数据集，并手动标注了发音人提示。然后，我们使用扩散基于音频模型和混合密度网络来模型训练数据中的多个发音人因素。不同于先前的研究，我们的方法不仅通过说话风格提示（例如，音高、说话速度和能量）控制发音人的个性，而是通过添加一个额外的发音人提示，以更好地学习自然语言描述到不同发音人的声学特征的映射。我们的主观评估结果表明，我们的方法可以更好地控制发音人的特征，比以前没有提示的方法。听样本可以在https://reppy4620.github.io/demo.promptttspp/中找到。
</details></li>
</ul>
<hr>
<h2 id="Audio-Difference-Learning-for-Audio-Captioning"><a href="#Audio-Difference-Learning-for-Audio-Captioning" class="headerlink" title="Audio Difference Learning for Audio Captioning"></a>Audio Difference Learning for Audio Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08141">http://arxiv.org/abs/2309.08141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tatsuya Komatsu, Yusuke Fujita, Kazuya Takeda, Tomoki Toda</li>
<li>for: 本研究提出了一种新的训练方法，即音频差异学习，用于改进音频描述。</li>
<li>methods: 该方法基于创建一个保持音频关系的特征表示空间，以生成详细的音频信息描述。方法使用一个参考音频和输入音频，通过共享编码器转换为特征表示。然后，从这些差异特征生成描述。此外，提出了一种混合输入音频和其他音频的技术，使得混合后的音频与参考音频的差异恢复回原输入音频。</li>
<li>results: 在使用Clotho和ESC50数据集的实验中，提出的方法比传统方法提高了SPIDEr分数7%。<details>
<summary>Abstract</summary>
This study introduces a novel training paradigm, audio difference learning, for improving audio captioning. The fundamental concept of the proposed learning method is to create a feature representation space that preserves the relationship between audio, enabling the generation of captions that detail intricate audio information. This method employs a reference audio along with the input audio, both of which are transformed into feature representations via a shared encoder. Captions are then generated from these differential features to describe their differences. Furthermore, a unique technique is proposed that involves mixing the input audio with additional audio, and using the additional audio as a reference. This results in the difference between the mixed audio and the reference audio reverting back to the original input audio. This allows the original input's caption to be used as the caption for their difference, eliminating the need for additional annotations for the differences. In the experiments using the Clotho and ESC50 datasets, the proposed method demonstrated an improvement in the SPIDEr score by 7% compared to conventional methods.
</details>
<details>
<summary>摘要</summary>
这种研究引入了一种新的训练方法，即音频差异学习，以提高音频描述。该方法的基本概念是创建一个保持音频关系的特征表示空间，以便从音频中生成详细的描述。该方法使用一个参照音频以及输入音频，两者都经过共享编码器转换成特征表示。然后，从这些差异特征中生成描述。此外，该方法还提出了一种独特的技术，即将输入音频混合到其他音频中，并使用这个混合音频作为参照音频。这会使得混合音频与参照音频之间的差异恢复回原始输入音频，从而消除了需要额外注释的差异。在使用 clotho 和 esc50 数据集进行实验时，提出的方法在 SPIDEr 分数上提高了7%，比传统方法更高。
</details></li>
</ul>
<hr>
<h2 id="Characterizing-the-temporal-dynamics-of-universal-speech-representations-for-generalizable-deepfake-detection"><a href="#Characterizing-the-temporal-dynamics-of-universal-speech-representations-for-generalizable-deepfake-detection" class="headerlink" title="Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection"></a>Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08099">http://arxiv.org/abs/2309.08099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhu00121/universal-representation-dynamics-of-deepfake-speech">https://github.com/zhu00121/universal-representation-dynamics-of-deepfake-speech</a></li>
<li>paper_authors: Yi Zhu, Saurabh Powar, Tiago H. Falk</li>
<li>for: 本研究旨在提高现有深伪语音检测系统的普适性，以便在训练时未看到的攻击样本上进行检测。</li>
<li>methods: 本研究使用了新的方法来评估表示性动态，以提高检测深伪语音的能力。</li>
<li>results: 实验结果表明，使用该方法可以在训练时未看到的攻击样本上提高深伪语音检测的性能，并在ASVspoof 2019和2021 datasets上达到了显著的改进。<details>
<summary>Abstract</summary>
Existing deepfake speech detection systems lack generalizability to unseen attacks (i.e., samples generated by generative algorithms not seen during training). Recent studies have explored the use of universal speech representations to tackle this issue and have obtained inspiring results. These works, however, have focused on innovating downstream classifiers while leaving the representation itself untouched. In this study, we argue that characterizing the long-term temporal dynamics of these representations is crucial for generalizability and propose a new method to assess representation dynamics. Indeed, we show that different generative models generate similar representation dynamics patterns with our proposed method. Experiments on the ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to detect deepfakes from methods unseen during training, significantly improving on several benchmark methods.
</details>
<details>
<summary>摘要</summary>
现有的深伪演说检测系统缺乏对未经训练的攻击（即由生成算法生成的样本）的普适性。近年来的研究强调使用通用的speech表示方法来解决这个问题，并取得了激进的结果。然而，这些工作均将注意力集中在下游分类器的创新上，而忽略了表示自身的改进。在本研究中，我们 argue that描述长期时间的speech表示动态是普适性的关键，并提出了一种新的方法来评估表示动态。实际上，我们发现了不同的生成模型在我们提出的方法下都会生成相似的表示动态模式。在ASVspoof 2019和2021 datasets上进行了实验，并证明了我们提出的方法可以很好地检测未经训练的深伪演说，与许多标准方法相比有显著提高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/15/cs.CL_2023_09_15/" data-id="clp89doav00bvi788a1vh0f1m" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/47/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/46/">46</a><a class="page-number" href="/page/47/">47</a><span class="page-number current">48</span><a class="page-number" href="/page/49/">49</a><a class="page-number" href="/page/50/">50</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/49/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
