
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/43/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/cs.SD_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T15:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/cs.SD_2023_09_24/">cs.SD - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Cross-modal-Alignment-with-Optimal-Transport-for-CTC-based-ASR"><a href="#Cross-modal-Alignment-with-Optimal-Transport-for-CTC-based-ASR" class="headerlink" title="Cross-modal Alignment with Optimal Transport for CTC-based ASR"></a>Cross-modal Alignment with Optimal Transport for CTC-based ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13650">http://arxiv.org/abs/2309.13650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xugang Lu, Peng Shen, Yu Tsao, Hisashi Kawai</li>
<li>for: 提高 CTCAASR 系统的准确率，使其能够更好地利用语言模型（LM）中的语言知识。</li>
<li>methods: 使用 optimal transport（OT）算法实现语音特征与文本特征之间的交叉模式对应，从而让语音特征编码上下文 dependent 语言特征。</li>
<li>results: 在 AISHELL-1 数据集上，我们的系统达到了 3.96% 和 4.27% 字符错误率（CER），对比基eline 系统而言，相对提高了 28.39% 和 29.42%。<details>
<summary>Abstract</summary>
Temporal connectionist temporal classification (CTC)-based automatic speech recognition (ASR) is one of the most successful end to end (E2E) ASR frameworks. However, due to the token independence assumption in decoding, an external language model (LM) is required which destroys its fast parallel decoding property. Several studies have been proposed to transfer linguistic knowledge from a pretrained LM (PLM) to the CTC based ASR. Since the PLM is built from text while the acoustic model is trained with speech, a cross-modal alignment is required in order to transfer the context dependent linguistic knowledge from the PLM to acoustic encoding. In this study, we propose a novel cross-modal alignment algorithm based on optimal transport (OT). In the alignment process, a transport coupling matrix is obtained using OT, which is then utilized to transform a latent acoustic representation for matching the context-dependent linguistic features encoded by the PLM. Based on the alignment, the latent acoustic feature is forced to encode context dependent linguistic information. We integrate this latent acoustic feature to build conformer encoder-based CTC ASR system. On the AISHELL-1 data corpus, our system achieved 3.96% and 4.27% character error rate (CER) for dev and test sets, respectively, which corresponds to relative improvements of 28.39% and 29.42% compared to the baseline conformer CTC ASR system without cross-modal knowledge transfer.
</details>
<details>
<summary>摘要</summary>
temporal connectionist temporal classification（CTC）基于自动语音识别（ASR）系统是最成功的端到端（E2E）ASR框架之一。然而，由于decode进程中的令符独立假设，需要一个外部语言模型（LM），这样会消除它的快速并行解码性。多个研究已经提出将语言知识从预训练语言模型（PLM）传递到CTC基于ASR系统。由于PLM是由文本建立的，而语音模型则是通过语音训练的，因此需要在语音编码和PLM中的语言知识之间进行交叉模式对齐。在本研究中，我们提出了一种基于最优运输（OT）的交叉模式对齐算法。在对齐过程中，使用OT获得了交叉运输矩阵，然后将其用于将 latent acoustic representation 变换为与语言模型（LM）中的上下文依赖的语言特征匹配。根据对齐，latent acoustic feature 被迫编码上下文依赖的语言信息。我们将这个latent acoustic feature 集成到基于CTC的ASR系统中，并在AISHELL-1数据集上进行测试。测试结果表明，我们的系统在dev和test集上的字符错误率（CER）分别为3.96%和4.27%，相对于基eline conformer CTC ASR系统而言，升幅分别为28.39%和29.42%。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Black-Box-Speaker-Verification-Model-Adaptation-with-Reprogramming-and-Backend-Learning"><a href="#Efficient-Black-Box-Speaker-Verification-Model-Adaptation-with-Reprogramming-and-Backend-Learning" class="headerlink" title="Efficient Black-Box Speaker Verification Model Adaptation with Reprogramming and Backend Learning"></a>Efficient Black-Box Speaker Verification Model Adaptation with Reprogramming and Backend Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13605">http://arxiv.org/abs/2309.13605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyu Li, Tan Lee</li>
<li>for: 这篇论文的目的是提出一种基于深度神经网络的话语识别系统中的领域匹配问题的解决方案，并且透过对模型的数据类型进行修改，以提高SV系统的性能。</li>
<li>methods: 这篇论文使用了一种基于对模型的数据类型进行修改的方法，即利用对模型的预设值进行修改，以实现领域匹配。这种方法通过估计模型的参数 gradients，将模型视为黑盒模型，并使用两层背景学习模组进行最终的适应。</li>
<li>results: 实验结果显示，这种方法可以在语言匹配情况下，对SV系统进行领域匹配，并且使用了 much less computation cost，实现了与完全调整的模型相似的性能。<details>
<summary>Abstract</summary>
The development of deep neural networks (DNN) has significantly enhanced the performance of speaker verification (SV) systems in recent years. However, a critical issue that persists when applying DNN-based SV systems in practical applications is domain mismatch. To mitigate the performance degradation caused by the mismatch, domain adaptation becomes necessary. This paper introduces an approach to adapt DNN-based SV models by manipulating the learnable model inputs, inspired by the concept of adversarial reprogramming. The pre-trained SV model remains fixed and functions solely in the forward process, resembling a black-box model. A lightweight network is utilized to estimate the gradients for the learnable parameters at the input, which bypasses the gradient backpropagation through the black-box model. The reprogrammed output is processed by a two-layer backend learning module as the final adapted speaker embedding. The number of parameters involved in the gradient calculation is small in our design. With few additional parameters, the proposed method achieves both memory and parameter efficiency. The experiments are conducted in language mismatch scenarios. Using much less computation cost, the proposed method obtains close or superior performance to the fully finetuned models in our experiments, which demonstrates its effectiveness.
</details>
<details>
<summary>摘要</summary>
Deep neural networks (DNN) 的发展有助于提高 speaker verification (SV) 系统的性能，但是在实际应用中，域名匹配问题仍然是一个主要的问题。为了解决这个问题，我们需要进行域名适应。这篇文章介绍了一种将 DNN-based SV 模型适应到域名不同的方法，通过修改可学习的模型输入，以及基于反对抗整形的概念。先前训练的 SV 模型保持不变，只参与前向处理，类似于黑盒模型。我们使用轻量级网络计算输入中的梯度，以便更新可学习参数。最终，我们使用两层后端学习模块来处理整形后的输出，并生成最终的适应的 speaker 嵌入。我们的设计具有少量参数，同时具有内存和参数效率。我们的实验结果表明，使用许多更少的计算成本，我们的方法可以在语言匹配场景中实现与完全训练模型相当或更好的性能。
</details></li>
</ul>
<hr>
<h2 id="The-second-multi-channel-multi-party-meeting-transcription-challenge-M2MeT-2-0-A-benchmark-for-speaker-attributed-ASR"><a href="#The-second-multi-channel-multi-party-meeting-transcription-challenge-M2MeT-2-0-A-benchmark-for-speaker-attributed-ASR" class="headerlink" title="The second multi-channel multi-party meeting transcription challenge (M2MeT) 2.0): A benchmark for speaker-attributed ASR"></a>The second multi-channel multi-party meeting transcription challenge (M2MeT) 2.0): A benchmark for speaker-attributed ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13573">http://arxiv.org/abs/2309.13573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Liang, Mohan Shi, Fan Yu, Yangze Li, Shiliang Zhang, Zhihao Du, Qian Chen, Lei Xie, Yanmin Qian, Jian Wu, Zhuo Chen, Kong Aik Lee, Zhijie Yan, Hui Bu</li>
<li>for: 本文主要探讨了一个实际场景中的“谁说了什么， WHEN”问题，即speaker-attributed ASR (SA-ASR)问题。</li>
<li>methods: 本文使用了两个子track：固定训练条件子track和开放训练条件子track。固定训练条件子track限制了训练数据的使用，但允许参与者使用任何开源预训练模型。开放训练条件子track则允许参与者使用所有可用数据和模型。</li>
<li>results: 本文公布了一个新的10小时测试集，用于排名挑战。本文还提供了参与者提交系统的结果和分析，作为SA-ASR领域的现状标准。<details>
<summary>Abstract</summary>
With the success of the first Multi-channel Multi-party Meeting Transcription challenge (M2MeT), the second M2MeT challenge (M2MeT 2.0) held in ASRU2023 particularly aims to tackle the complex task of \emph{speaker-attributed ASR (SA-ASR)}, which directly addresses the practical and challenging problem of ``who spoke what at when" at typical meeting scenario. We particularly established two sub-tracks. The fixed training condition sub-track, where the training data is constrained to predetermined datasets, but participants can use any open-source pre-trained model. The open training condition sub-track, which allows for the use of all available data and models without limitation. In addition, we release a new 10-hour test set for challenge ranking. This paper provides an overview of the dataset, track settings, results, and analysis of submitted systems, as a benchmark to show the current state of speaker-attributed ASR.
</details>
<details>
<summary>摘要</summary>
在M2MeT挑战的成功之后，M2MeT 2.0挑战在ASRU2023中进一步挑战了复杂的 speaker-attributed ASR（SA-ASR）任务，直接面临typical会议场景中的“谁说了什么，何时”问题。我们设置了两个子轨道。固定培训条件子轨道，团队可以使用预先训练的任何开源模型，但是团队必须使用 predetermined datasets 进行培训。开放培训条件子轨道，允许使用所有可用的数据和模型。此外，我们发布了一个新的10小时测试集，用于挑战排名。本文提供了数据集、轨道设置、结果和分析 submitted系统的概述，作为SA-ASR现状的标准 referential。
</details></li>
</ul>
<hr>
<h2 id="Coco-Nut-Corpus-of-Japanese-Utterance-and-Voice-Characteristics-Description-for-Prompt-based-Control"><a href="#Coco-Nut-Corpus-of-Japanese-Utterance-and-Voice-Characteristics-Description-for-Prompt-based-Control" class="headerlink" title="Coco-Nut: Corpus of Japanese Utterance and Voice Characteristics Description for Prompt-based Control"></a>Coco-Nut: Corpus of Japanese Utterance and Voice Characteristics Description for Prompt-based Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13509">http://arxiv.org/abs/2309.13509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aya Watanabe, Shinnosuke Takamichi, Yuki Saito, Wataru Nakata, Detai Xin, Hiroshi Saruwatari</li>
<li>for: 研究控制语音特征的多目的语音合成。</li>
<li>methods: 使用文本conditioned生成，如文本-图像生成，以实现直觉和复杂的语音特征控制。</li>
<li>results: 开发了一个新的语音 corpus，包括多样化的日本语音样本，以及相应的文本转录和自由形式语音特征描述。<details>
<summary>Abstract</summary>
In text-to-speech, controlling voice characteristics is important in achieving various-purpose speech synthesis. Considering the success of text-conditioned generation, such as text-to-image, free-form text instruction should be useful for intuitive and complicated control of voice characteristics. A sufficiently large corpus of high-quality and diverse voice samples with corresponding free-form descriptions can advance such control research. However, neither an open corpus nor a scalable method is currently available. To this end, we develop Coco-Nut, a new corpus including diverse Japanese utterances, along with text transcriptions and free-form voice characteristics descriptions. Our methodology to construct this corpus consists of 1) automatic collection of voice-related audio data from the Internet, 2) quality assurance, and 3) manual annotation using crowdsourcing. Additionally, we benchmark our corpus on the prompt embedding model trained by contrastive speech-text learning.
</details>
<details>
<summary>摘要</summary>
<<SYS>>在文本到语音Synthesizer中，控制声音特征是关键以实现多种目标 speech synthesis。考虑到文本条件生成的成功，如文本到图像，自由形文本指令可以为Intuitive和复杂的声音控制提供便利。一个具有充分覆盖和多样性的声音样本库可以提高这种控制研究。然而，目前并没有公开的库 nor可扩展的方法。为此，我们开发了Coco-Nut，一个新的声音库，包括日本语音样本，以及文本转录和自由形声音特征描述。我们的方法包括：1. 自动从互联网上收集声音相关的音频数据2. 质量控制3. 使用人工投票来手动标注此外，我们对这个库进行了基于对比Speech-text学习的唤起式模型的测试。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/cs.SD_2023_09_24/" data-id="clpxp6c6z00zwee885h086bzf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/cs.CV_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T13:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/cs.CV_2023_09_24/">cs.CV - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Diffeomorphic-Multi-Resolution-Deep-Learning-Registration-for-Applications-in-Breast-MRI"><a href="#Diffeomorphic-Multi-Resolution-Deep-Learning-Registration-for-Applications-in-Breast-MRI" class="headerlink" title="Diffeomorphic Multi-Resolution Deep Learning Registration for Applications in Breast MRI"></a>Diffeomorphic Multi-Resolution Deep Learning Registration for Applications in Breast MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13777">http://arxiv.org/abs/2309.13777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew G. French, Gonzalo D. Maso Talou, Thiranja P. Babarenda Gamage, Martyn P. Nash, Poul M. Nielsen, Anthony J. Doyle, Juan Eugenio Iglesias, Yaël Balbastre, Sean I. Young</li>
<li>for: 静脉成像规划中的精准注册可以提高乳腺癌治疗中肿瘤的定位。</li>
<li>methods: 本文提出了一种learning-based注册方法，该方法遵循 diffeomorphic 约束，并且在静脉成像中提供了优秀的注册结果。</li>
<li>results: 本文的实验结果表明，该注册方法可以提供高质量的注册结果，同时也遵循 diffeomorphic 约束。<details>
<summary>Abstract</summary>
In breast surgical planning, accurate registration of MR images across patient positions has the potential to improve the localisation of tumours during breast cancer treatment. While learning-based registration methods have recently become the state-of-the-art approach for most medical image registration tasks, these methods have yet to make inroads into breast image registration due to certain difficulties-the lack of rich texture information in breast MR images and the need for the deformations to be diffeomophic. In this work, we propose learning strategies for breast MR image registration that are amenable to diffeomorphic constraints, together with early experimental results from in-silico and in-vivo experiments. One key contribution of this work is a registration network which produces superior registration outcomes for breast images in addition to providing diffeomorphic guarantees.
</details>
<details>
<summary>摘要</summary>
医学影像识别是一个重要的领域，它可以帮助医生更好地识别和治疗癌症。在乳腺癌治疗中，精准地将MR图像注册到患者的不同位置中有可能提高肿瘤的定位。然而，学习基本的注册方法在乳腺影像注册中尚未得到广泛应用，因为乳腺MR图像的纹理信息缺乏，并且需要的变换是 diffeomophic。在这种情况下，我们提出了一些学习策略，可以考虑到 diffeomorphic 约束，并且在实验中获得了出色的注册结果。我们的一个关键贡献是一种注册网络，可以生成高质量的注册结果，同时也提供 diffeomorphic  garanties。
</details></li>
</ul>
<hr>
<h2 id="Motion-Segmentation-from-a-Moving-Monocular-Camera"><a href="#Motion-Segmentation-from-a-Moving-Monocular-Camera" class="headerlink" title="Motion Segmentation from a Moving Monocular Camera"></a>Motion Segmentation from a Moving Monocular Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13772">http://arxiv.org/abs/2309.13772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Huang, John Zelek</li>
<li>for: 能够减少视觉SLAM或SFM中的运动物体识别，以便建立地图。</li>
<li>methods: synergistically fusing two popular branches of monocular motion segmentation approaches：point trajectory based和optical flow based methods。</li>
<li>results: 在KT3DMoSeg dataset上达到了状态计算机科学技术的表现水平，能够处理复杂的运动和场景结构。<details>
<summary>Abstract</summary>
Identifying and segmenting moving objects from a moving monocular camera is difficult when there is unknown camera motion, different types of object motions and complex scene structures. To tackle these challenges, we take advantage of two popular branches of monocular motion segmentation approaches: point trajectory based and optical flow based methods, by synergistically fusing these two highly complementary motion cues at object level. By doing this, we are able to model various complex object motions in different scene structures at once, which has not been achieved by existing methods. We first obtain object-specific point trajectories and optical flow mask for each common object in the video, by leveraging the recent foundational models in object recognition, segmentation and tracking. We then construct two robust affinity matrices representing the pairwise object motion affinities throughout the whole video using epipolar geometry and the motion information provided by optical flow. Finally, co-regularized multi-view spectral clustering is used to fuse the two affinity matrices and obtain the final clustering. Our method shows state-of-the-art performance on the KT3DMoSeg dataset, which contains complex motions and scene structures. Being able to identify moving objects allows us to remove them for map building when using visual SLAM or SFM.
</details>
<details>
<summary>摘要</summary>
Difficulties in identifying and segmenting moving objects from a moving monocular camera include unknown camera motion, diverse object motions, and complex scene structures. To address these challenges, we synergistically fuse two popular monocular motion segmentation approaches: point trajectory-based and optical flow-based methods, at the object level. This enables us to model various complex object motions in different scene structures simultaneously, which has not been achieved by existing methods.We first obtain object-specific point trajectories and optical flow masks for each common object in the video by leveraging recent foundational models in object recognition, segmentation, and tracking. We then construct two robust affinity matrices representing the pairwise object motion affinities throughout the entire video using epipolar geometry and motion information provided by optical flow. Finally, co-regularized multi-view spectral clustering is used to fuse the two affinity matrices, resulting in the final clustering. Our method achieves state-of-the-art performance on the KT3DMoSeg dataset, which contains complex motions and scene structures. By identifying moving objects, we can remove them for map building when using visual SLAM or SFM.
</details></li>
</ul>
<hr>
<h2 id="Devil-in-the-Number-Towards-Robust-Multi-modality-Data-Filter"><a href="#Devil-in-the-Number-Towards-Robust-Multi-modality-Data-Filter" class="headerlink" title="Devil in the Number: Towards Robust Multi-modality Data Filter"></a>Devil in the Number: Towards Robust Multi-modality Data Filter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13770">http://arxiv.org/abs/2309.13770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Xu, Zihan Xu, Wenhao Chai, Zhonghan Zhao, Enxin Song, Gaoang Wang</li>
<li>For: 这个研究的目的是为了提高CLIP的表现和降低训练成本，通过适当的筛选方法来筛选多modal资料集。* Methods: 这个研究使用了CLIP score筛选器和文本检测方法来筛选资料。在分析资料集时，我们发现了大量的重复信息，例如数字，在文本内容中。我们进行了实验，发现这些重复元素对CLIP scores有着内在的影响。* Results: 我们的文本基于CLIP筛选器在DataComp中的“小规模”频道上比顶尖方法表现出色，实现了3.6%的性能提升。实验还显示了我们提议的文本填充筛选器比原始CLIP score筛选器在选择顶尖40%的资料时表现更好。此外，我们的研究还发现了数字对CLIP和其处理的影响，具有价值的指导意义，包括语言重写技术。<details>
<summary>Abstract</summary>
In order to appropriately filter multi-modality data sets on a web-scale, it becomes crucial to employ suitable filtering methods to boost performance and reduce training costs. For instance, LAION papers employs the CLIP score filter to select data with CLIP scores surpassing a certain threshold. On the other hand, T-MARS achieves high-quality data filtering by detecting and masking text within images and then filtering by CLIP score. Through analyzing the dataset, we observe a significant proportion of redundant information, such as numbers, present in the textual content. Our experiments on a subset of the data unveil the profound impact of these redundant elements on the CLIP scores. A logical approach would involve reevaluating the CLIP scores after eliminating these influences. Experimentally, our text-based CLIP filter outperforms the top-ranked method on the ``small scale" of DataComp (a data filtering benchmark) on ImageNet distribution shifts, achieving a 3.6% performance improvement. The results also demonstrate that our proposed text-masked filter outperforms the original CLIP score filter when selecting the top 40% of the data. The impact of numbers on CLIP and their handling provide valuable insights for improving the effectiveness of CLIP training, including language rewrite techniques.
</details>
<details>
<summary>摘要</summary>
We observe a significant amount of redundant information, such as numbers, in the textual content of the dataset. Our experiments on a subset of the data reveal that these redundant elements have a profound impact on the CLIP scores. A logical approach would be to reevaluate the CLIP scores after eliminating these influences.Experimentally, our text-based CLIP filter outperforms the top-ranked method on the "small scale" of DataComp (a data filtering benchmark) on ImageNet distribution shifts, achieving a 3.6% performance improvement. The results also show that our proposed text-masked filter outperforms the original CLIP score filter when selecting the top 40% of the data. The impact of numbers on CLIP and their handling provide valuable insights for improving the effectiveness of CLIP training, including language rewrite techniques.
</details></li>
</ul>
<hr>
<h2 id="Combining-Two-Adversarial-Attacks-Against-Person-Re-Identification-Systems"><a href="#Combining-Two-Adversarial-Attacks-Against-Person-Re-Identification-Systems" class="headerlink" title="Combining Two Adversarial Attacks Against Person Re-Identification Systems"></a>Combining Two Adversarial Attacks Against Person Re-Identification Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13763">http://arxiv.org/abs/2309.13763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo de O. Andrade, Igor Garcia Ballhausen Sampaio, Joris Guérin, José Viterbo</li>
<li>for: 这个研究是针对人员识别系统（Re-ID）的安全性进行研究，尤其是运用深度神经网络来实现人员识别。</li>
<li>methods: 本研究使用了两种攻击方法：P-FGSM和Deep Mis-Ranking，并且将其应用到两个受测Re-ID模型：IDE（ResNet-50）和AlignedReID。</li>
<li>results: 研究结果显示，这些攻击方法可以对Re-ID模型造成较大的影响，其中AlignedReID在CUHK03 dataset上的 Rank-10 指数下降了3.36%。此外，研究者还尝试使用Dropout进行防护。<details>
<summary>Abstract</summary>
The field of Person Re-Identification (Re-ID) has received much attention recently, driven by the progress of deep neural networks, especially for image classification. The problem of Re-ID consists in identifying individuals through images captured by surveillance cameras in different scenarios. Governments and companies are investing a lot of time and money in Re-ID systems for use in public safety and identifying missing persons. However, several challenges remain for successfully implementing Re-ID, such as occlusions and light reflections in people's images. In this work, we focus on adversarial attacks on Re-ID systems, which can be a critical threat to the performance of these systems. In particular, we explore the combination of adversarial attacks against Re-ID models, trying to strengthen the decrease in the classification results. We conduct our experiments on three datasets: DukeMTMC-ReID, Market-1501, and CUHK03. We combine the use of two types of adversarial attacks, P-FGSM and Deep Mis-Ranking, applied to two popular Re-ID models: IDE (ResNet-50) and AlignedReID. The best result demonstrates a decrease of 3.36% in the Rank-10 metric for AlignedReID applied to CUHK03. We also try to use Dropout during the inference as a defense method.
</details>
<details>
<summary>摘要</summary>
人员重复识别（Re-ID）领域在最近几年内受到了广泛关注，启发于深度神经网络的进步，特别是图像分类。Re-ID问题的核心是通过不同场景的安全摄像头捕捉到人员的图像，并在不同的环境下进行人员识别。政府和公司在公共安全和失踪人员问题上投入了大量时间和资金，以实现Re-ID系统的应用。然而，Re-ID实施还存在一些挑战，如人像中的遮挡和反射光。在这种情况下，我们将关注Re-ID系统中的对抗攻击，这可能会对系统的性能产生重要的威胁。我们在三个数据集上进行了实验：DukeMTMC-ReID、Market-1501和CUHK03。我们将两种对抗攻击相结合：P-FGSM和Deep Mis-Ranking，并将其应用于两种流行的Re-ID模型：IDE（ResNet-50）和AlignedReID。最佳结果表明，对CUHK03数据集应用AlignedReID模型，P-FGSM和Deep Mis-Ranking的组合可以导致rank-10指标下的下降为3.36%。我们还尝试了在推理过程中使用Dropout作为防御方法。
</details></li>
</ul>
<hr>
<h2 id="Look-Ma-no-code-fine-tuning-nnU-Net-for-the-AutoPET-II-challenge-by-only-adjusting-its-JSON-plans"><a href="#Look-Ma-no-code-fine-tuning-nnU-Net-for-the-AutoPET-II-challenge-by-only-adjusting-its-JSON-plans" class="headerlink" title="Look Ma, no code: fine tuning nnU-Net for the AutoPET II challenge by only adjusting its JSON plans"></a>Look Ma, no code: fine tuning nnU-Net for the AutoPET II challenge by only adjusting its JSON plans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13747">http://arxiv.org/abs/2309.13747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabian Isensee, Klaus H. Maier-Hein</li>
<li>for: 提高 AutoPET II 挑战中 nnU-Net 的性能</li>
<li>methods: 通过 modifying nnU-Net 的 ‘nnUNetPlans.json’ 文件，switch to UNet with residual encoder，增加 batch size 和 patch size，以提高模型的性能</li>
<li>results: 比自动配置的 nnU-Net 基eline（5-fold cross-validation Dice score of 65.14 vs 33.28）substantially outperform，但是需要更多的计算资源来训练模型。最终提交ensemble两个最有前途的配置。当提交时，我们的方法在预测集上排名第一。<details>
<summary>Abstract</summary>
We participate in the AutoPET II challenge by modifying nnU-Net only through its easy to understand and modify 'nnUNetPlans.json' file. By switching to a UNet with residual encoder, increasing the batch size and increasing the patch size we obtain a configuration that substantially outperforms the automatically configured nnU-Net baseline (5-fold cross-validation Dice score of 65.14 vs 33.28) at the expense of increased compute requirements for model training. Our final submission ensembles the two most promising configurations. At the time of submission our method ranks first on the preliminary test set.
</details>
<details>
<summary>摘要</summary>
我们参加了AutoPET II挑战，只通过nnUNetPlans.json文件进行 modify nnU-Net。通过更改残差编码器，增加批处理大小和增加补做大小，我们获得了与自动配置的nnU-Net基线（5次交叉验证精度分数为65.14 vs 33.28）的性能显著提高，但是需要更高的计算资源来训练模型。我们最终提交的结果是两种最有前途的配置的ensemble。在提交时，我们的方法在预测集上排名第一。Note: "nnUNetPlans.json" is a JSON file that contains the architecture of the nnU-Net model, and it is "easy to understand and modify" as mentioned in the text.
</details></li>
</ul>
<hr>
<h2 id="DROP-Dynamics-Responses-from-Human-Motion-Prior-and-Projective-Dynamics"><a href="#DROP-Dynamics-Responses-from-Human-Motion-Prior-and-Projective-Dynamics" class="headerlink" title="DROP: Dynamics Responses from Human Motion Prior and Projective Dynamics"></a>DROP: Dynamics Responses from Human Motion Prior and Projective Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13742">http://arxiv.org/abs/2309.13742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifeng Jiang, Jungdam Won, Yuting Ye, C. Karen Liu</li>
<li>for: 这篇论文旨在实现人类动作的生成和跟踪，以满足计算机视觉、运动和医疗等领域的需求。</li>
<li>methods: 该论文提出了一种名为DROP的新框架，它利用生成式动作优先逻辑和投影动力来模型人类动作的响应。</li>
<li>results: 经过广泛的评估，DROP模型在不同的动作任务和物理干扰下表现出了可scalability和多样性的特点。<details>
<summary>Abstract</summary>
Synthesizing realistic human movements, dynamically responsive to the environment, is a long-standing objective in character animation, with applications in computer vision, sports, and healthcare, for motion prediction and data augmentation. Recent kinematics-based generative motion models offer impressive scalability in modeling extensive motion data, albeit without an interface to reason about and interact with physics. While simulator-in-the-loop learning approaches enable highly physically realistic behaviors, the challenges in training often affect scalability and adoption. We introduce DROP, a novel framework for modeling Dynamics Responses of humans using generative mOtion prior and Projective dynamics. DROP can be viewed as a highly stable, minimalist physics-based human simulator that interfaces with a kinematics-based generative motion prior. Utilizing projective dynamics, DROP allows flexible and simple integration of the learned motion prior as one of the projective energies, seamlessly incorporating control provided by the motion prior with Newtonian dynamics. Serving as a model-agnostic plug-in, DROP enables us to fully leverage recent advances in generative motion models for physics-based motion synthesis. We conduct extensive evaluations of our model across different motion tasks and various physical perturbations, demonstrating the scalability and diversity of responses.
</details>
<details>
<summary>摘要</summary>
实现人类动作的实惠真实、对环境 dynamically responsive 是动画人物的长期目标，应用于电脑感知、运动和医疗等领域，如动作预测和数据增强。现有的运动基础的生成动作模型可以实现广泛的动作数据模型，但是没有与物理相互作用的界面。而使用模拟器-在-the-loop 学习方法可以实现高度的物理真实行为，但是训练问题往往会影响数据量和采纳。我们介绍了 DROP，一个新的框架，用于模型人类动作的 Dynamics Responses，使用生成动作假设和投影动力学。 DROP 可以被视为一个高度稳定、最小化的物理基础的人类模拟器，与生成动作假设的投影动力学相互作用。通过将学习的动作假设作为投影能量的一部分，DROP 允许flexible和简单地整合已学习的动作假设和新频率动力学。作为一个模型无关的插件，DROP 允许我们充分利用最近的生成动作模型，以便实现物理基础的动作合成。我们在不同的动作任务和各种物理损害中进行了广泛的评估，证明了 DROP 的普遍性和多样性。
</details></li>
</ul>
<hr>
<h2 id="MOSAIC-Multi-Object-Segmented-Arbitrary-Stylization-Using-CLIP"><a href="#MOSAIC-Multi-Object-Segmented-Arbitrary-Stylization-Using-CLIP" class="headerlink" title="MOSAIC: Multi-Object Segmented Arbitrary Stylization Using CLIP"></a>MOSAIC: Multi-Object Segmented Arbitrary Stylization Using CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13716">http://arxiv.org/abs/2309.13716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prajwal Ganugula, Y S S S Santosh Kumar, N K Sagar Reddy, Prabhath Chellingi, Avinash Thakur, Neeraj Kasera, C Shyam Anand</li>
<li>for: 这篇论文的目的是提出一种基于文本提示的多对象分割自由风格化方法，以提高风格化图像的控制精度和扩展性。</li>
<li>methods: 该方法使用了视transformer架构进行文本基于分割和风格化模块，可以针对不同的对象进行精细的风格化控制。</li>
<li>results: 该方法可以生成高质量的风格化图像，并且可以在不同的对象类上进行扩展性测试，而且可以在不同的风格转换中保持图像的可读性。<details>
<summary>Abstract</summary>
Style transfer driven by text prompts paved a new path for creatively stylizing the images without collecting an actual style image. Despite having promising results, with text-driven stylization, the user has no control over the stylization. If a user wants to create an artistic image, the user requires fine control over the stylization of various entities individually in the content image, which is not addressed by the current state-of-the-art approaches. On the other hand, diffusion style transfer methods also suffer from the same issue because the regional stylization control over the stylized output is ineffective. To address this problem, We propose a new method Multi-Object Segmented Arbitrary Stylization Using CLIP (MOSAIC), that can apply styles to different objects in the image based on the context extracted from the input prompt. Text-based segmentation and stylization modules which are based on vision transformer architecture, were used to segment and stylize the objects. Our method can extend to any arbitrary objects, styles and produce high-quality images compared to the current state of art methods. To our knowledge, this is the first attempt to perform text-guided arbitrary object-wise stylization. We demonstrate the effectiveness of our approach through qualitative and quantitative analysis, showing that it can generate visually appealing stylized images with enhanced control over stylization and the ability to generalize to unseen object classes.
</details>
<details>
<summary>摘要</summary>
文本驱动的样式传递开创了一条新的创作图像样式化路径，而不需要实际收集样式图像。尽管有promising结果，文本驱动样式化方法还有一个问题：用户无法控制样式化的精度。如果用户想创造艺术图像，用户需要精准地控制图像中的多种实体的样式化。现有的approach都无法解决这个问题。另一方面，扩散样式传递方法也有同样的问题，因为对彩色输出的区域样式控制是无效的。为解决这个问题，我们提出了一种新的方法：多对象分割自由样式传递使用CLIP（MOSAIC）。我们使用了基于视力转换器架构的文本基于分割和样式化模块，可以将不同的对象在图像中应用不同的样式。我们的方法可以扩展到任意对象、样式和生成高质量图像，比现状态的方法更高效。我们知道，这是文本引导自由对象样式传递的首次尝试。我们通过质量和量化分析，证明我们的方法可以生成美观的样式化图像，并且可以增强样式化的控制和泛化到未看过的对象类型。
</details></li>
</ul>
<hr>
<h2 id="Sound-Print-Generalised-Face-Presentation-Attack-Detection-using-Deep-Representation-of-Sound-Echoes"><a href="#Sound-Print-Generalised-Face-Presentation-Attack-Detection-using-Deep-Representation-of-Sound-Echoes" class="headerlink" title="Sound-Print: Generalised Face Presentation Attack Detection using Deep Representation of Sound Echoes"></a>Sound-Print: Generalised Face Presentation Attack Detection using Deep Representation of Sound Echoes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13704">http://arxiv.org/abs/2309.13704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raghavendra Ramachandra, Jag Mohan Singh, Sushma Venkatesh</li>
<li>for: 这篇论文主要目的是提出一种基于阴投信号的声学回音攻击探测方法，以实现智能手机上的面部识别系统中的安全性。</li>
<li>methods: 本论文使用的方法包括对于声学回音的分析和模elling，并提出一种基于宽频脉冲的传输信号，以提高信号与噪音的比例。</li>
<li>results: 实验结果显示，提出的方法可以妥善地探测不同类型的面部攻击，包括印刷攻击、显示攻击和塑胶面伪攻击。<details>
<summary>Abstract</summary>
Facial biometrics are widely deployed in smartphone-based applications because of their usability and increased verification accuracy in unconstrained scenarios. The evolving applications of smartphone-based facial recognition have also increased Presentation Attacks (PAs), where an attacker can present a Presentation Attack Instrument (PAI) to maliciously gain access to the application. Because the materials used to generate PAI are not deterministic, the detection of unknown presentation attacks is challenging. In this paper, we present an acoustic echo-based face Presentation Attack Detection (PAD) on a smartphone in which the PAs are detected based on the reflection profiles of the transmitted signal. We propose a novel transmission signal based on the wide pulse that allows us to model the background noise before transmitting the signal and increase the Signal-to-Noise Ratio (SNR). The received signal reflections were processed to remove background noise and accurately represent reflection characteristics. The reflection profiles of the bona fide and PAs are different owing to the different reflection characteristics of the human skin and artefact materials. Extensive experiments are presented using the newly collected Acoustic Sound Echo Dataset (ASED) with 4807 samples captured from bona fide and four different types of PAIs, including print (two types), display, and silicone face-mask attacks. The obtained results indicate the robustness of the proposed method for detecting unknown face presentation attacks.
</details>
<details>
<summary>摘要</summary>
“人脸生物特征在智能手机应用中广泛应用，因为它们的使用性和无限制场景中的验证精度提高。随着智能手机上的人脸识别应用的发展，也增加了演示攻击（PA），其中攻击者可以使用演示攻击工具（PAI）来恶意获取应用程序。由于攻击工具的材料不决定性，检测未知的演示攻击是困难的。在这篇论文中，我们提出了基于声学回音的人脸演示攻击检测（PAD）方法，在智能手机上进行。我们提出了一种基于宽PULSE的新的传输信号，使得我们可以在传输信号之前模拟背景噪声，提高信号噪声比（SNR）。接收到的声学回音后，我们对噪声进行了处理，以便准确地表示回音特征。人脸和攻击工具的反射特征不同，因为人脸和 artifact材料的反射特征不同。我们在新收集的声学回音数据集（ASED）上进行了广泛的实验，该数据集包含4807个样本，其中有4种不同类型的PAI，包括印刷（两种）、显示和塑料面具攻击。获得的结果表明，我们提出的方法对于检测未知的人脸演示攻击具有坚定的Robustness。”
</details></li>
</ul>
<hr>
<h2 id="Video-Adverse-Weather-Component-Suppression-Network-via-Weather-Messenger-and-Adversarial-Backpropagation"><a href="#Video-Adverse-Weather-Component-Suppression-Network-via-Weather-Messenger-and-Adversarial-Backpropagation" class="headerlink" title="Video Adverse-Weather-Component Suppression Network via Weather Messenger and Adversarial Backpropagation"></a>Video Adverse-Weather-Component Suppression Network via Weather Messenger and Adversarial Backpropagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13700">http://arxiv.org/abs/2309.13700</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scott-yjyang/ViWS-Net">https://github.com/scott-yjyang/ViWS-Net</a></li>
<li>paper_authors: Yijun Yang, Angelica I. Aviles-Rivero, Huazhu Fu, Ye Liu, Weiming Wang, Lei Zhu</li>
<li>for:  Restoring videos degraded by any weather condition</li>
<li>methods:  Video adverse-weather-component suppression network (ViWS-Net), including a weather-agnostic video transformer encoder, long short-term temporal modeling mechanism, weather discriminator, and messenger-driven video transformer decoder</li>
<li>results:  Outperforms current state-of-the-art methods in restoring videos degraded by any weather condition, on benchmark datasets and real-world weather videos.<details>
<summary>Abstract</summary>
Although convolutional neural networks (CNNs) have been proposed to remove adverse weather conditions in single images using a single set of pre-trained weights, they fail to restore weather videos due to the absence of temporal information. Furthermore, existing methods for removing adverse weather conditions (e.g., rain, fog, and snow) from videos can only handle one type of adverse weather. In this work, we propose the first framework for restoring videos from all adverse weather conditions by developing a video adverse-weather-component suppression network (ViWS-Net). To achieve this, we first devise a weather-agnostic video transformer encoder with multiple transformer stages. Moreover, we design a long short-term temporal modeling mechanism for weather messenger to early fuse input adjacent video frames and learn weather-specific information. We further introduce a weather discriminator with gradient reversion, to maintain the weather-invariant common information and suppress the weather-specific information in pixel features, by adversarially predicting weather types. Finally, we develop a messenger-driven video transformer decoder to retrieve the residual weather-specific feature, which is spatiotemporally aggregated with hierarchical pixel features and refined to predict the clean target frame of input videos. Experimental results, on benchmark datasets and real-world weather videos, demonstrate that our ViWS-Net outperforms current state-of-the-art methods in terms of restoring videos degraded by any weather condition.
</details>
<details>
<summary>摘要</summary>
尽管卷积神经网络（CNNs）已经提议用单个预训练 веса来去除单个图像中的不良天气情况，但它们无法恢复天气视频，因为缺乏时间信息。此外，现有的天气视频修复方法只能处理一种类型的不良天气。在这种情况下，我们提出了第一个可以恢复所有不良天气视频的框架，即视频不良天气组件抑制网络（ViWS-Net）。以实现这一目标，我们首先设计了不同天气情况下的视频转换器编码器，其中包括多个转换器阶段。此外，我们还设计了一种长期短期模型来早期融合输入视频帧的邻近信息，以学习天气特定的信息。此外，我们还引入了一种天气预测器，以便对输入视频帧的像素特征进行拟合，并且通过对天气类型进行反向推导，以维护天气不变的通用信息，并抑制天气特定的信息。最后，我们开发了一种天气驱动的视频转换器解码器，以恢复输入视频中的剩余天气特定特征，并将其空间时间聚合和归一化，以预测输入视频的干净目标帧。实验结果，在标准测试集和实际天气视频上，表明我们的ViWS-Net可以超越当前状态的方法，在任何天气条件下恢复受损的视频。
</details></li>
</ul>
<hr>
<h2 id="Causal-DFQ-Causality-Guided-Data-free-Network-Quantization"><a href="#Causal-DFQ-Causality-Guided-Data-free-Network-Quantization" class="headerlink" title="Causal-DFQ: Causality Guided Data-free Network Quantization"></a>Causal-DFQ: Causality Guided Data-free Network Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13682">http://arxiv.org/abs/2309.13682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/42shawn/causal-dfq">https://github.com/42shawn/causal-dfq</a></li>
<li>paper_authors: Yuzhang Shang, Bingxin Xu, Gaowen Liu, Ramana Kompella, Yan Yan</li>
<li>For: 这个研究的目的是为了解决在实际应用中无法提供训练数据的情况下，深度神经网络协商过程中的问题。* Methods: 这个研究使用了 causal reasoning 来建立 causal 图模型，并提出了一个基于 causality 的 data-free network quantization 方法（Causal-DFQ），以消除依赖于数据的限制。* Results: 实验结果显示，Causal-DFQ 能够将深度神经网络协商到更小的网络，并且可以在不需要训练数据的情况下保持比较高的预测性能。<details>
<summary>Abstract</summary>
Model quantization, which aims to compress deep neural networks and accelerate inference speed, has greatly facilitated the development of cumbersome models on mobile and edge devices. There is a common assumption in quantization methods from prior works that training data is available. In practice, however, this assumption cannot always be fulfilled due to reasons of privacy and security, rendering these methods inapplicable in real-life situations. Thus, data-free network quantization has recently received significant attention in neural network compression. Causal reasoning provides an intuitive way to model causal relationships to eliminate data-driven correlations, making causality an essential component of analyzing data-free problems. However, causal formulations of data-free quantization are inadequate in the literature. To bridge this gap, we construct a causal graph to model the data generation and discrepancy reduction between the pre-trained and quantized models. Inspired by the causal understanding, we propose the Causality-guided Data-free Network Quantization method, Causal-DFQ, to eliminate the reliance on data via approaching an equilibrium of causality-driven intervened distributions. Specifically, we design a content-style-decoupled generator, synthesizing images conditioned on the relevant and irrelevant factors; then we propose a discrepancy reduction loss to align the intervened distributions of the pre-trained and quantized models. It is worth noting that our work is the first attempt towards introducing causality to data-free quantization problem. Extensive experiments demonstrate the efficacy of Causal-DFQ. The code is available at https://github.com/42Shawn/Causal-DFQ.
</details>
<details>
<summary>摘要</summary>
模型减量，用于压缩深度神经网络并加速推理速度，已经大大便化了移动和边缘设备上的模型开发。但是，现实中的假设是所有训练数据都可用，而在实际应用中，这个假设不一定成立，因为隐私和安全问题。因此，无数据网络减量在神经网络压缩中收到了重要注意。 causal reasoning提供了一种直观的方式来模型 causal 关系，以消除数据驱动的相关性，使 causality 成为分析无数据问题的关键组成部分。然而， literature 中关于无数据网络减量的 causal 表述不充分。为了bridging这个差距，我们构建了 causal 图来模型数据生成和差异减少 между 预训练和减量模型。 inspirited  by causal 理解，我们提出了 causality-guided 无数据网络减量方法（Causal-DFQ），以消除数据的依赖性。具体来说，我们设计了内容-风格-分解的生成器，通过conditioning 图像的相关和 irrelevant 因素来生成图像。然后，我们提出了干扰分布的减少损失，以将预训练和减量模型之间的 intervened 分布接近。值得注意的是，我们的工作是无数据网络减量问题中首次引入 causality 的尝试。extensive  experiments 表明了 Causal-DFQ 的有效性。代码可以在 https://github.com/42Shawn/Causal-DFQ 上获取。
</details></li>
</ul>
<hr>
<h2 id="BdSpell-A-YOLO-based-Real-time-Finger-Spelling-System-for-Bangla-Sign-Language"><a href="#BdSpell-A-YOLO-based-Real-time-Finger-Spelling-System-for-Bangla-Sign-Language" class="headerlink" title="BdSpell: A YOLO-based Real-time Finger Spelling System for Bangla Sign Language"></a>BdSpell: A YOLO-based Real-time Finger Spelling System for Bangla Sign Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13676">http://arxiv.org/abs/2309.13676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naimul Haque, Meraj Serker, Tariq Bin Bashar</li>
<li>for: 提高孟加拉手语（BdSL）解释的可用性和包容性，增进孟加拉手语社区中的语言平等。</li>
<li>methods: 基于YOLOv5架构的实时手势识别系统，采用特定规则和数字类作为触发器，高效生成隐藏和复合字符，消减用户的压力。</li>
<li>results: 实现字符识别时间优化为1.32秒，准确率达98%，YOLOv5模型在9147张图像上显示出极高的平均精度报告率（mAP）为96.4%。<details>
<summary>Abstract</summary>
In the domain of Bangla Sign Language (BdSL) interpretation, prior approaches often imposed a burden on users, requiring them to spell words without hidden characters, which were subsequently corrected using Bangla grammar rules due to the missing classes in BdSL36 dataset. However, this method posed a challenge in accurately guessing the incorrect spelling of words. To address this limitation, we propose a novel real-time finger spelling system based on the YOLOv5 architecture. Our system employs specified rules and numerical classes as triggers to efficiently generate hidden and compound characters, eliminating the necessity for additional classes and significantly enhancing user convenience. Notably, our approach achieves character spelling in an impressive 1.32 seconds with a remarkable accuracy rate of 98\%. Furthermore, our YOLOv5 model, trained on 9147 images, demonstrates an exceptional mean Average Precision (mAP) of 96.4\%. These advancements represent a substantial progression in augmenting BdSL interpretation, promising increased inclusivity and accessibility for the linguistic minority. This innovative framework, characterized by compatibility with existing YOLO versions, stands as a transformative milestone in enhancing communication modalities and linguistic equity within the Bangla Sign Language community.
</details>
<details>
<summary>摘要</summary>
在孟加拉手语（BdSL）解释领域，先前的方法经常对用户带来压力，需要他们在无隐藏字符的情况下寻找字符，然后根据孟加拉语法规则进行修正，由于在BdSL36数据集中缺失的类型。但这种方法难以准确地猜测错误的拼写。为解决这个限制，我们提出了一种新的实时手写系统，基于YOLOv5架构。我们的系统采用了特定的规则和数字类作为触发器，以高效地生成隐藏和复合字符，从而消除了额外的类和增加了用户的便利。特别是，我们的方法在1.32秒内完成字符拼写，并达到了98%的精度。此外，我们的YOLOv5模型，在9147张图像上训练，显示了极高的平均精度（mAP）96.4%。这些进步表明了在增强孟加拉手语解释方面的重要突破，这将为孟加拉手语社区提供更多的包容性和可用性。这种革命性的框架，具有与现有YOLO版本兼容的特点，代表了孟加拉手语解释领域的巨大进步，并将在语言平等和通信模式方面产生深远的影响。
</details></li>
</ul>
<hr>
<h2 id="Joint-inversion-of-Time-Lapse-Surface-Gravity-and-Seismic-Data-for-Monitoring-of-3D-CO-2-Plumes-via-Deep-Learning"><a href="#Joint-inversion-of-Time-Lapse-Surface-Gravity-and-Seismic-Data-for-Monitoring-of-3D-CO-2-Plumes-via-Deep-Learning" class="headerlink" title="Joint inversion of Time-Lapse Surface Gravity and Seismic Data for Monitoring of 3D CO$_2$ Plumes via Deep Learning"></a>Joint inversion of Time-Lapse Surface Gravity and Seismic Data for Monitoring of 3D CO$_2$ Plumes via Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04430">http://arxiv.org/abs/2310.04430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Celaya, Mauricio Araya-Polo</li>
<li>for: 预测地下CO2涡，作为监测CO2储存部署的辅助工具。</li>
<li>methods: 基于深度学习的3D结合时间差表地重力和地震数据重建地下密度和速度模型。</li>
<li>results: 与深度学习基于重力只和地震只的拟合模型相比，joint匹配模型得到了改善的密度和速度重建、准确的分割和高的R-squared系数。这些结果表明深度学习基于联合拟合是有效的CO2储存监测工具。<details>
<summary>Abstract</summary>
We introduce a fully 3D, deep learning-based approach for the joint inversion of time-lapse surface gravity and seismic data for reconstructing subsurface density and velocity models. The target application of this proposed inversion approach is the prediction of subsurface CO2 plumes as a complementary tool for monitoring CO2 sequestration deployments. Our joint inversion technique outperforms deep learning-based gravity-only and seismic-only inversion models, achieving improved density and velocity reconstruction, accurate segmentation, and higher R-squared coefficients. These results indicate that deep learning-based joint inversion is an effective tool for CO$_2$ storage monitoring. Future work will focus on validating our approach with larger datasets, simulations with other geological storage sites, and ultimately field data.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种完全三维、深度学习基于的方法，用于同时逆合时间序列表面重力和地震数据，以重建地下密度和速度模型。我们的目标应用是预测地下CO2泵，作为监测CO2储存部署的辅助工具。我们的联合逆合模型在密度和速度重建、准确分割和高R-平方 coefficient方面表现出色，这表明深度学习基于的联合逆合是有效的CO$_2$储存监测工具。未来工作将集中于验证我们的方法，使用更大的数据集、其他地质储存站的 simulate 和最终场景数据。
</details></li>
</ul>
<hr>
<h2 id="OneSeg-Self-learning-and-One-shot-Learning-based-Single-slice-Annotation-for-3D-Medical-Image-Segmentation"><a href="#OneSeg-Self-learning-and-One-shot-Learning-based-Single-slice-Annotation-for-3D-Medical-Image-Segmentation" class="headerlink" title="OneSeg: Self-learning and One-shot Learning based Single-slice Annotation for 3D Medical Image Segmentation"></a>OneSeg: Self-learning and One-shot Learning based Single-slice Annotation for 3D Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13671">http://arxiv.org/abs/2309.13671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixuan Wu, Bo Zheng, Jintai Chen, Danny Z. Chen, Jian Wu</li>
<li>for: 提高医疗图像分割精度，减少数据标注努力。</li>
<li>methods: 提议一种自学习和一键学习基于构建，只需要标注一个3D图像的一 slice，以提高3D医疗图像分割精度。</li>
<li>results: 比对完全监督方法，新方法可以达到相似的性能，仅需要0.1%的数据标注，并且在多个异常测试集上进行了广泛的实验验证。<details>
<summary>Abstract</summary>
As deep learning methods continue to improve medical image segmentation performance, data annotation is still a big bottleneck due to the labor-intensive and time-consuming burden on medical experts, especially for 3D images. To significantly reduce annotation efforts while attaining competitive segmentation accuracy, we propose a self-learning and one-shot learning based framework for 3D medical image segmentation by annotating only one slice of each 3D image. Our approach takes two steps: (1) self-learning of a reconstruction network to learn semantic correspondence among 2D slices within 3D images, and (2) representative selection of single slices for one-shot manual annotation and propagating the annotated data with the well-trained reconstruction network. Extensive experiments verify that our new framework achieves comparable performance with less than 1% annotated data compared with fully supervised methods and generalizes well on several out-of-distribution testing sets.
</details>
<details>
<summary>摘要</summary>
随着深度学习方法在医疗影像分割性能的提高，数据注释仍然是一个大的瓶颈，因为医疗专家需要投入大量的劳动和时间来进行注释，特别是 для 3D 影像。为了减少注释努力而获得竞争性的分割精度，我们提出了一个自学习和一次学习基于框架，只需要注释每个 3D 影像中的一个平面。我们的方法包括两步：（1）自学习一个重建网络，以学习 2D 影像内 3D 影像中的semantic相关性，以及（2）选择单个平面进行一次手动注释，并使用已经训练好的重建网络将注释数据传播到其他影像中。我们的新方法在多个out-of-distribution测试集上进行了广泛的实验，并证明了它可以与完全监督方法相比，并且在不同的测试集上具有良好的一致性。
</details></li>
</ul>
<hr>
<h2 id="Adaptation-of-the-super-resolution-SOTA-for-Art-Restoration-in-camera-capture-images"><a href="#Adaptation-of-the-super-resolution-SOTA-for-Art-Restoration-in-camera-capture-images" class="headerlink" title="Adaptation of the super resolution SOTA for Art Restoration in camera capture images"></a>Adaptation of the super resolution SOTA for Art Restoration in camera capture images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13655">http://arxiv.org/abs/2309.13655</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naagar/art_restoration_dm">https://github.com/naagar/art_restoration_dm</a></li>
<li>paper_authors: Sandeep Nagar, Abhinaba Bala, Sai Amrit Patnaik<br>for: 这项研究旨在开发一个基于计算机视觉模型的自动化艺术修复方法，以提高和重建受损艺术作品的视觉质量，保留原始特点和瑰宝。methods: 该研究采用了基于扩散模型（DM）的图像超分辨率技术，并对其进行了微调，以适应不同类型的受损，包括噪声、模糊、scratches、淡化等。results: 研究结果显示，通过微调一个超分辨率模型，可以处理多种受损类型，并且可以提高和重建受损艺术作品的视觉质量，而不需要专业知识和较长的时间。代码链接：<a target="_blank" rel="noopener" href="https://github.com/Naagar/art_restoration_DM%E3%80%82">https://github.com/Naagar/art_restoration_DM。</a><details>
<summary>Abstract</summary>
Preserving cultural heritage is of paramount importance. In the domain of art restoration, developing a computer vision model capable of effectively restoring deteriorated images of art pieces was difficult, but now we have a good computer vision state-of-art. Traditional restoration methods are often time-consuming and require extensive expertise. The aim of this work is to design an automated solution based on computer vision models that can enhance and reconstruct degraded artworks, improving their visual quality while preserving their original characteristics and artifacts. The model should handle a diverse range of deterioration types, including but not limited to noise, blur, scratches, fading, and other common forms of degradation. We adapt the current state-of-art for the image super-resolution based on the Diffusion Model (DM) and fine-tune it for Image art restoration. Our results show that instead of fine-tunning multiple different models for different kinds of degradation, fine-tuning one super-resolution. We train it on multiple datasets to make it robust. code link: https://github.com/Naagar/art_restoration_DM
</details>
<details>
<summary>摘要</summary>
保护文化遗产对于我们非常重要。在艺术修复领域，开发一个可以有效地恢复褪色的艺术作品图像的计算机视觉模型是一项具有挑战性的任务，但现在我们已经有了一个非常出色的计算机视觉状态。传统的修复方法通常是时间consuming且需要广泛的专业知识。我们的目标是设计一个自动化的解决方案，基于计算机视觉模型，可以提高褪色的艺术作品图像的视觉质量，同时保持原始特征和痕迹。我们采用当前状态的扩充模型（DM），并进行了精细调整，以适应不同类型的褪色，包括噪声、模糊、擦抹、淡化和其他常见的褪色形式。我们的结果表明，不同于先前的多个模型的微调，我们可以通过微调一个超解析模型来实现图像修复。我们在多个数据集上训练这个模型，以使其具有坚固性。更多信息请参考：https://github.com/Naagar/art_restoration_DM。
</details></li>
</ul>
<hr>
<h2 id="ILNet-Low-level-Matters-for-Salient-Infrared-Small-Target-Detection"><a href="#ILNet-Low-level-Matters-for-Salient-Infrared-Small-Target-Detection" class="headerlink" title="ILNet: Low-level Matters for Salient Infrared Small Target Detection"></a>ILNet: Low-level Matters for Salient Infrared Small Target Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13646">http://arxiv.org/abs/2309.13646</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/li-haoqing/ilnet">https://github.com/li-haoqing/ilnet</a></li>
<li>paper_authors: Haoqing Li, Jinfu Yang, Runshi Wang, Yifei Xu</li>
<li>for: 该文章目标是提出一种基于干扰低级网络（ILNet）的干扰小目标检测方法，以提高干扰小目标特征的表示能力。</li>
<li>methods: 该方法使用了一种新的轻量级特征融合模块（IPOF），将低级信息更加注重地融合到深层网络中，以提高干扰小目标的检测性能。此外，还使用了一种动态一维度聚合层（DODA）来动态调整低维度信息的聚合方式。此外，该方法还使用了 Representative Block（RB）来动态分配深层和浅层网络的权重。</li>
<li>results: 实验结果表明，提出的 ILNet 方法在NUAA-SIRST 数据集上取得了78.22% nIoU 和 1.33e-6 Fa 的最佳性能，并在 IRSTD-1K 数据集上取得了68.91% nIoU 和 3.23e-6 Fa 的最佳性能。此外，ILNet 还能够在数据量增加时获得更大的提升。<details>
<summary>Abstract</summary>
Infrared small target detection is a technique for finding small targets from infrared clutter background. Due to the dearth of high-level semantic information, small infrared target features are weakened in the deep layers of the CNN, which underachieves the CNN's representation ability. To address the above problem, in this paper, we propose an infrared low-level network (ILNet) that considers infrared small targets as salient areas with little semantic information. Unlike other SOTA methods, ILNet pays greater attention to low-level information instead of treating them equally. A new lightweight feature fusion module, named Interactive Polarized Orthogonal Fusion module (IPOF), is proposed, which integrates more important low-level features from the shallow layers into the deep layers. A Dynamic One-Dimensional Aggregation layers (DODA) are inserted into the IPOF, to dynamically adjust the aggregation of low dimensional information according to the number of input channels. In addition, the idea of ensemble learning is used to design a Representative Block (RB) to dynamically allocate weights for shallow and deep layers. Experimental results on the challenging NUAA-SIRST (78.22% nIoU and 1.33e-6 Fa) and IRSTD-1K (68.91% nIoU and 3.23e-6 Fa) dataset demonstrate that the proposed ILNet can get better performances than other SOTA methods. Moreover, ILNet can obtain a greater improvement with the increasement of data volume. Training code are available at https://github.com/Li-Haoqing/ILNet.
</details>
<details>
<summary>摘要</summary>
infrared小目标检测是一种技术，用于从抖抖辐射背景中检测小目标。由于高级 semantic信息的缺乏，小抖抖辐射目标特征在深层神经网络中弱化，这会导致神经网络的表征能力受到限制。为解决上述问题，本文提出了一种infrared低级网络（ILNet），它视小抖抖辐射目标为有少量semantic信息的突出区域。不同于其他SOTA方法，ILNet更加注重低级信息，而不是对其进行平等处理。为了更好地捕捉低级信息，我们提出了一种新的轻量级特征融合模块（IPOF），该模块将深层神经网络中的重要低级特征与浅层神经网络中的低级特征进行有效的融合。此外，我们还使用了 Representative Block（RB）来动态分配深浅层神经网络中的权重。实验结果表明，提出的ILNet可以在NUAA-SIRST（78.22% nIoU和1.33e-6 Fa）和IRSTD-1K（68.91% nIoU和3.23e-6 Fa） dataset上达到SOTA的性能。此外，ILNet可以随着数据量的增加而获得更大的改进。训练代码可以在https://github.com/Li-Haoqing/ILNet中找到。
</details></li>
</ul>
<hr>
<h2 id="Changes-Aware-Transformer-Learning-Generalized-Changes-Representation"><a href="#Changes-Aware-Transformer-Learning-Generalized-Changes-Representation" class="headerlink" title="Changes-Aware Transformer: Learning Generalized Changes Representation"></a>Changes-Aware Transformer: Learning Generalized Changes Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13619">http://arxiv.org/abs/2309.13619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Wang, Licheng Jiao, Jie Chen, Shuyuan Yang, Fang Liu</li>
<li>for: 本研究旨在提高 Change Detection (CD) 任务中的变化检测精度，通过学习多种变化的总体表示，并提出一种Changes-Aware Transformer (CAT) 来修正差异特征。</li>
<li>methods: 本研究使用了一种novel的 Changes-Aware Transformer (CAT) 来修正差异特征，CAT 通过栅格cosine cross-attention层和自我注意层来实现这一目的。</li>
<li>results: 实验结果表明，我们的方法可以在 remote sensing CD 数据集和街景 CD 数据集上达到状态之 arts 性能，并且具有良好的普适性。<details>
<summary>Abstract</summary>
Difference features obtained by comparing the images of two periods play an indispensable role in the change detection (CD) task. However, a pair of bi-temporal images can exhibit diverse changes, which may cause various difference features. Identifying changed pixels with differ difference features to be the same category is thus a challenge for CD. Most nowadays' methods acquire distinctive difference features in implicit ways like enhancing image representation or supervision information. Nevertheless, informative image features only guarantee object semantics are modeled and can not guarantee that changed pixels have similar semantics in the difference feature space and are distinct from those unchanged ones. In this work, the generalized representation of various changes is learned straightforwardly in the difference feature space, and a novel Changes-Aware Transformer (CAT) for refining difference features is proposed. This generalized representation can perceive which pixels are changed and which are unchanged and further guide the update of pixels' difference features. CAT effectively accomplishes this refinement process through the stacked cosine cross-attention layer and self-attention layer. After refinement, the changed pixels in the difference feature space are closer to each other, which facilitates change detection. In addition, CAT is compatible with various backbone networks and existing CD methods. Experiments on remote sensing CD data set and street scene CD data set show that our method achieves state-of-the-art performance and has excellent generalization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT diferenciales características obtenidas por comparar las imágenes de dos períodos juegan un papel fundamental en la tarea de detección de cambios (CD). Sin embargo, una pareja de imágenes bi-temporales puede exhibir cambios diversificados, lo que puede causar diferentes diferenciales características. Identificar pixels cambiados con diferenciales características similares es un desafío para la CD. La mayoría de los métodos actuales adquieren características diferenciales distintivas de manera implícita, como la mejora de la representación de la imagen o la información de supervisión. Sin embargo, las características de la imagen informativas solo garantizan que las semánticas de los objetos se modelen y no garantizan que los pixels cambiados tengan semánticas similares en el espacio de características de diferencia y se distingan de los pixels no cambiados. En este trabajo, se aprende una representación generalizada de los cambios en el espacio de características de diferencia y se propone un Novel Changes-Aware Transformer (CAT) para refinar las características de diferencia. Esta representación generalizada puede percibir qué pixels están cambiados y qué pixels no están cambiados y guiar el update de las características de diferencia de los pixels. CAT efectúa este proceso de refinamiento mediante capas de atención cruzada cosínica y de atención a sí misma. Después de la refinement, los pixels cambiados en el espacio de características de diferencia están más cercanos entre sí, lo que facilita la detección de cambios. Además, CAT es compatible con redes de soporte existentes y métodos de CD. Los experimentos en los conjuntos de datos de CD de áreas remotas y escenas de la calle muestran que nuestro método logra un rendimiento estatal de arte y tiene una excelente generalización.Note: The text is translated using the Google Translate API, and the translation may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="VisionKG-Unleashing-the-Power-of-Visual-Datasets-via-Knowledge-Graph"><a href="#VisionKG-Unleashing-the-Power-of-Visual-Datasets-via-Knowledge-Graph" class="headerlink" title="VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph"></a>VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13610">http://arxiv.org/abs/2309.13610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jicheng Yuan, Anh Le-Tuan, Manh Nguyen-Duc, Trung-Kien Tran, Manfred Hauswirth, Danh Le-Phuoc</li>
<li>for: 提供一个全面的 computer vision 数据资源，实现跨多个源、任务和分类的Visual dataset集成。</li>
<li>methods: 使用知识 graphs和Semantic Web技术来整合、组织和管理多种形式的Visual dataset，提供简单的存取和查询服务，并具有扩展性和可扩展性。</li>
<li>results: 组建了一个名为 Vision Knowledge Graph（VisionKG）的资源，它可以实现跨多个源、任务和分类的Visual dataset集成，并提供了多种数据 Retrieval 和探索服务。<details>
<summary>Abstract</summary>
The availability of vast amounts of visual data with heterogeneous features is a key factor for developing, testing, and benchmarking of new computer vision (CV) algorithms and architectures. Most visual datasets are created and curated for specific tasks or with limited image data distribution for very specific situations, and there is no unified approach to manage and access them across diverse sources, tasks, and taxonomies. This not only creates unnecessary overheads when building robust visual recognition systems, but also introduces biases into learning systems and limits the capabilities of data-centric AI. To address these problems, we propose the Vision Knowledge Graph (VisionKG), a novel resource that interlinks, organizes and manages visual datasets via knowledge graphs and Semantic Web technologies. It can serve as a unified framework facilitating simple access and querying of state-of-the-art visual datasets, regardless of their heterogeneous formats and taxonomies. One of the key differences between our approach and existing methods is that ours is knowledge-based rather than metadatabased. It enhances the enrichment of the semantics at both image and instance levels and offers various data retrieval and exploratory services via SPARQL. VisionKG currently contains 519 million RDF triples that describe approximately 40 million entities, and are accessible at https://vision.semkg.org and through APIs. With the integration of 30 datasets and four popular CV tasks, we demonstrate its usefulness across various scenarios when working with CV pipelines.
</details>
<details>
<summary>摘要</summary>
“现代计算机视觉（CV）算法和架构的开发、测试和评估中，庞大量的视觉数据的可用性是关键因素。大多数视觉数据集是为特定任务或有限的图像数据分布而创建和维护的，而且没有一种统一的方法来管理和访问它们。这不仅会增加建立可靠的视觉识别系统的开发成本，而且会引入偏见到学习系统中和限制数据驱动AI的能力。为解决这些问题，我们提议了视觉知识图（VisionKG），一种新的资源，通过知识图和Semantic Web技术来集成、组织和管理视觉数据集。它可以作为一个统一的框架，方便访问和查询多种不同的视觉任务和数据集，无论它们的格式和分类如何。我们的方法与现有方法的主要区别在于，我们的方法是基于知识图而不是基于元数据的。它可以增强图像和实例层次的 semantics，并提供了多种数据检索和探索服务via SPARQL。VisionKG目前包含519亿个RDF三元组，描述约40亿个实体，可以在https://vision.semkg.org和通过API访问。我们通过将30个数据集和4种常见CV任务集成到VisionKG中，证明了它在不同的场景中对CV管道的有用性。”
</details></li>
</ul>
<hr>
<h2 id="Vulnerabilities-in-Video-Quality-Assessment-Models-The-Challenge-of-Adversarial-Attacks"><a href="#Vulnerabilities-in-Video-Quality-Assessment-Models-The-Challenge-of-Adversarial-Attacks" class="headerlink" title="Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks"></a>Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13609">http://arxiv.org/abs/2309.13609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gzhu-dvl/attackvqa">https://github.com/gzhu-dvl/attackvqa</a></li>
<li>paper_authors: Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang</li>
<li>for: This paper focuses on evaluating the robustness of No-Reference Video Quality Assessment (NR-VQA) models against adversarial attacks, and proposing a patch-based random search method for black-box attacks.</li>
<li>methods: The paper uses Convolutional Neural Networks (CNNs) and Transformers as the base models for NR-VQA, and proposes a novel loss function called Score-Reversed Boundary Loss to evaluate the robustness of these models against adversarial attacks.</li>
<li>results: The paper presents the results of evaluating the robustness of NR-VQA models against adversarial attacks using the proposed Score-Reversed Boundary Loss, and shows that the proposed method can effectively launch both white-box and black-box attacks in an imperceptible manner.Here is the simplified Chinese text for the three information points:</li>
<li>for: 这篇论文关注NR-VQA模型对针对攻击的Robustness评估，并提出了一种基于随机搜索的黑盒攻击方法。</li>
<li>methods: 该论文使用Convolutional Neural Networks (CNNs)和Transformers作为NR-VQA模型的基础模型，并提出了一种新的损失函数called Score-Reversed Boundary Loss来评估NR-VQA模型对攻击的Robustness。</li>
<li>results: 该论文通过使用提出的Score-Reversed Boundary Loss来评估NR-VQA模型对攻击的Robustness，并显示了该方法可以效果地发起白盒和黑盒攻击，并且在无人知情的情况下进行。<details>
<summary>Abstract</summary>
No-Reference Video Quality Assessment (NR-VQA) plays an essential role in improving the viewing experience of end-users. Driven by deep learning, recent NR-VQA models based on Convolutional Neural Networks (CNNs) and Transformers have achieved outstanding performance. To build a reliable and practical assessment system, it is of great necessity to evaluate their robustness. However, such issue has received little attention in the academic community. In this paper, we make the first attempt to evaluate the robustness of NR-VQA models against adversarial attacks, and propose a patch-based random search method for black-box attack. Specifically, considering both the attack effect on quality score and the visual quality of adversarial video, the attack problem is formulated as misleading the estimated quality score under the constraint of just-noticeable difference (JND). Built upon such formulation, a novel loss function called Score-Reversed Boundary Loss is designed to push the adversarial video's estimated quality score far away from its ground-truth score towards a specific boundary, and the JND constraint is modeled as a strict $L_2$ and $L_\infty$ norm restriction. By this means, both white-box and black-box attacks can be launched in an effective and imperceptible manner. The source code is available at https://github.com/GZHU-DVL/AttackVQA.
</details>
<details>
<summary>摘要</summary>
“无参考视频质量评估（NR-VQA）在提高用户视频观看体验中扮演着关键性的角色。驱动深度学习，最新的NR-VQA模型基于卷积神经网络（CNNs）和变换器（Transformers）已经实现了出色的表现。为建立可靠和实用的评估系统，必须评估其可靠性。然而，这一问题在学术界得到了少量的关注。本文是首次评估NR-VQA模型对抗攻击的尝试，并提出了一种黑盒攻击方法基于补丁随机搜索。具体来说，我们认为攻击问题应该是让估计的质量分数受到攻击，同时保证视频质量的变化在可以快速感知的范围内。针对这一问题，我们提出了一种新的损失函数 called Score-Reversed Boundary Loss，它可以让攻击者通过控制估计质量分数的变化，使得攻击者可以在无法察觉的情况下发动白盒和黑盒攻击。源代码可以在https://github.com/GZHU-DVL/AttackVQA上获取。”
</details></li>
</ul>
<hr>
<h2 id="FaceAtt-Enhancing-Image-Captioning-with-Facial-Attributes-for-Portrait-Images"><a href="#FaceAtt-Enhancing-Image-Captioning-with-Facial-Attributes-for-Portrait-Images" class="headerlink" title="FaceAtt: Enhancing Image Captioning with Facial Attributes for Portrait Images"></a>FaceAtt: Enhancing Image Captioning with Facial Attributes for Portrait Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13601">http://arxiv.org/abs/2309.13601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naimul Haque, Iffat Labiba, Sadia Akter</li>
<li>for: This paper focuses on developing a novel approach to attribute-focused image captioning that accurately depicts facial attributes within images.</li>
<li>methods: The FaceAtt model uses deep learning techniques and annotated attributes of portraits as supplementary prior knowledge to improve caption quality.</li>
<li>results: The FaceAtt model yields a subtle yet discernible enhancement in resulting caption scores, demonstrating the effectiveness of incorporating additional attribute vectors during training.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文关注开发一种基于人脸特征的图像描述模型，以准确描述图像中的人脸特征。</li>
<li>methods:  FaceAtt模型使用深度学习技术和人脸特征注释作为辅助知识，以提高描述质量。</li>
<li>results: FaceAtt模型在训练时使用人脸特征注释可以提供微妙 yet 可识别的提升，表明注释的添加可以提高模型的表现。<details>
<summary>Abstract</summary>
Automated image caption generation is a critical area of research that enhances accessibility and understanding of visual content for diverse audiences. In this study, we propose the FaceAtt model, a novel approach to attribute-focused image captioning that emphasizes the accurate depiction of facial attributes within images. FaceAtt automatically detects and describes a wide range of attributes, including emotions, expressions, pointed noses, fair skin tones, hair textures, attractiveness, and approximate age ranges. Leveraging deep learning techniques, we explore the impact of different image feature extraction methods on caption quality and evaluate our model's performance using metrics such as BLEU and METEOR. Our FaceAtt model leverages annotated attributes of portraits as supplementary prior knowledge for our portrait images before captioning. This innovative addition yields a subtle yet discernible enhancement in the resulting scores, exemplifying the potency of incorporating additional attribute vectors during training. Furthermore, our research contributes to the broader discourse on ethical considerations in automated captioning. This study sets the stage for future research in refining attribute-focused captioning techniques, with a focus on enhancing linguistic coherence, addressing biases, and accommodating diverse user needs.
</details>
<details>
<summary>摘要</summary>
自动生成图像标签是一个关键的研究领域，它提高了视觉内容的可访问性和理解，便于不同的用户群体。在这项研究中，我们提出了FaceAtt模型，一种新的图像标签生成方法，强调在图像中准确描述人脸特征。FaceAtt自动检测和描述了各种特征，包括情感、表情、短脚、白肤肤、头发Texture、吸引力和年龄范围。我们利用深度学习技术，研究不同的图像特征提取方法对标签质量的影响，并使用BLEU和METEOR等 метри来评估我们的FaceAtt模型。我们的FaceAtt模型利用了人脸图像的注解特征作为额外知识来进行预处理，这种创新的添加带来了微妙 yet 可见的提高，表明了在训练时添加特征向量的力量。此外，我们的研究对自动标签技术的伦理考虑进行贡献。这项研究为未来更进一步的增强特征强调标签技术做出了平台，包括提高语言一致性、消除偏见和满足多样化用户需求。
</details></li>
</ul>
<hr>
<h2 id="Multi-Dimensional-Hyena-for-Spatial-Inductive-Bias"><a href="#Multi-Dimensional-Hyena-for-Spatial-Inductive-Bias" class="headerlink" title="Multi-Dimensional Hyena for Spatial Inductive Bias"></a>Multi-Dimensional Hyena for Spatial Inductive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13600">http://arxiv.org/abs/2309.13600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Itamar Zimerman, Lior Wolf</li>
<li>for: 这个论文是为了提出一种数据效率的视觉变换器，不需要自注意。它使用了一种新的多轴泛化方法，基于最近的Hyena层。</li>
<li>methods: 这个论文使用了一种新的泛化方法，即Hyena N-D层，以提高视觉变换器的性能。它还提出了多种不同的方法来实现这种泛化，并从实际和理论上进行了详细的分析。</li>
<li>results: 实验结果显示，Hyena N-D层能够提高多种视觉变换器架构的性能，如ViT、Swin和DeiT等。此外，在小数据集 régime中，Hyena-based ViT比特有些文献中提出的特定设计来解决这个问题的ViT变种更好。最后， authors表明了一种hybrid方法，将Hyena N-D层用于前几层，然后使用传统注意力层，能够持续提高不同的视觉变换器架构的性能。<details>
<summary>Abstract</summary>
In recent years, Vision Transformers have attracted increasing interest from computer vision researchers. However, the advantage of these transformers over CNNs is only fully manifested when trained over a large dataset, mainly due to the reduced inductive bias towards spatial locality within the transformer's self-attention mechanism. In this work, we present a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We propose several alternative approaches for obtaining this generalization and delve into their unique distinctions and considerations from both empirical and theoretical perspectives.   Our empirical findings indicate that the proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT is favorable to ViT variants from the recent literature that are specifically designed for solving the same challenge, i.e., working with small datasets or incorporating image-specific inductive bias into the self-attention mechanism. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures.
</details>
<details>
<summary>摘要</summary>
Recently, Vision Transformers have gained increasing attention from computer vision researchers. However, the advantage of these transformers over Convolutional Neural Networks (CNNs) is only fully manifested when trained on a large dataset, due to the reduced inductive bias towards spatial locality within the transformer's self-attention mechanism. In this work, we propose a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We present several alternative approaches for obtaining this generalization and discuss their unique distinctions and considerations from both empirical and theoretical perspectives.Our empirical findings indicate that the proposed Hyena N-D layer enhances the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT, across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT outperforms ViT variants from the recent literature that are specifically designed for solving the same challenge, i.e., working with small datasets or incorporating image-specific inductive bias into the self-attention mechanism. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures.
</details></li>
</ul>
<hr>
<h2 id="On-the-Posterior-Distribution-in-Denoising-Application-to-Uncertainty-Quantification"><a href="#On-the-Posterior-Distribution-in-Denoising-Application-to-Uncertainty-Quantification" class="headerlink" title="On the Posterior Distribution in Denoising: Application to Uncertainty Quantification"></a>On the Posterior Distribution in Denoising: Application to Uncertainty Quantification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13598">http://arxiv.org/abs/2309.13598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HilaManor/GaussianDenoisingPosterior">https://github.com/HilaManor/GaussianDenoisingPosterior</a></li>
<li>paper_authors: Hila Manor, Tomer Michaeli</li>
<li>for: 这篇论文主要针对的是降噪方法的应用，包括低级图像感知器的降噪、以及基于 Tweedie 公式的score-based生成模型。</li>
<li>methods: 该论文使用 Gaussian denoising 的 posterior distribution 链接到数据分布的 posterior mean，并 derivates 出高阶中心差的关系。</li>
<li>results: 该论文可以快速和减少内存占用来计算 posterior distribution 的主要方向和高阶中心差，不需要训练或精度调整降噪器。<details>
<summary>Abstract</summary>
Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of the denoiser. Code and examples are available on the project's webpage in https://hilamanor.github.io/GaussianDenoisingPosterior/
</details>
<details>
<summary>摘要</summary>
纹理恢复器在许多应用中扮演着中心角色，从噪声消除低级图像感知器到激发Score-based生成模型。后者使用Tweedie的公式，将 posterior mean在 Gaussian denoising 中相应的负面积最小化。我们 derivate 出 posterior distribution 的高级中心均值和 posterior mean 的高级导数之间的基本关系。我们利用这个结果进行uncertainty quantification of pre-trained denoisers。特别是，我们可以快速计算 posterior distribution 的主要Components在任意区域中，以及任意一个方向的全级分布。我们的方法快速，内存占用少，因为它不需要直接计算或存储高级 moment tensor，也不需要训练或微调denoiser。 codes 和示例可以在https://hilamanor.github.io/GaussianDenoisingPosterior/ 的项目网站上找到。
</details></li>
</ul>
<hr>
<h2 id="Advancements-in-3D-Lane-Detection-Using-LiDAR-Point-Clouds-From-Data-Collection-to-Model-Development"><a href="#Advancements-in-3D-Lane-Detection-Using-LiDAR-Point-Clouds-From-Data-Collection-to-Model-Development" class="headerlink" title="Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data Collection to Model Development"></a>Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data Collection to Model Development</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13596">http://arxiv.org/abs/2309.13596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runkai Zhao, Yuwen Heng, Yuanda Gao, Shilei Liu, Heng Wang, Changhao Yao, Jiawen Chen, Weidong Cai</li>
<li>for: 本研究旨在提高自动驾驶系统（ADAS）的车辆感知和决策能力，通过利用学习基于的技术。</li>
<li>methods: 本研究使用了LiDAR数据集，并设计了一个简单 yet effective的自动标注管线，以生成更加精细的车道标注。</li>
<li>results: 实验结果显示，LiLaDet模型在K-Lane数据集和LiSV-3DLane数据集上的3D车道检测任务中表现出色，超过了现有的摄像头和LiDAR基于的方法。<details>
<summary>Abstract</summary>
Advanced Driver-Assistance Systems (ADAS) have successfully integrated learning-based techniques into vehicle perception and decision-making. However, their application in 3D lane detection for effective driving environment perception is hindered by the lack of comprehensive LiDAR datasets. The sparse nature of LiDAR point cloud data prevents an efficient manual annotation process. To solve this problem, we present LiSV-3DLane, a large-scale 3D lane dataset that comprises 20k frames of surround-view LiDAR point clouds with enriched semantic annotation. Unlike existing datasets confined to a frontal perspective, LiSV-3DLane provides a full 360-degree spatial panorama around the ego vehicle, capturing complex lane patterns in both urban and highway environments. We leverage the geometric traits of lane lines and the intrinsic spatial attributes of LiDAR data to design a simple yet effective automatic annotation pipeline for generating finer lane labels. To propel future research, we propose a novel LiDAR-based 3D lane detection model, LiLaDet, incorporating the spatial geometry learning of the LiDAR point cloud into Bird's Eye View (BEV) based lane identification. Experimental results indicate that LiLaDet outperforms existing camera- and LiDAR-based approaches in the 3D lane detection task on the K-Lane dataset and our LiSV-3DLane.
</details>
<details>
<summary>摘要</summary>
高级驾驶辅助系统（ADAS）已成功地将学习基于的技术 integrate 到车辆的感知和决策中。然而，它们在3D车道检测中为有效的驾驶环境感知受到了LiDAR数据的缺乏全面的障碍。LiDAR点云数据的稀疏性阻碍了人工注释的效率。为解决这个问题，我们提出了LiSV-3DLane，一个大规模的3D车道数据集，包含20000帧的周围视野LiDAR点云数据，并且具有增强的semantic注释。与现有的前视角所限定的数据集不同，LiSV-3DLane提供了360度的全景视图，捕捉了城市和高速公路环境中复杂的车道模式。我们利用LiDAR数据的几何特征和点云数据的内在空间属性，设计了一个简单 yet effective的自动注释管道，以生成更细的车道标签。为未来的研究提供动力，我们提出了一种基于LiDAR的3D车道检测模型LiLaDet，该模型将LiDAR点云中的空间几何学学习 integrate 到基于bird's eye view（BEV）的车道标识中。实验结果表明，LiLaDet在K-Lane数据集和我们的LiSV-3DLane上的3D车道检测任务中表现出色，比摄像头和LiDAR基的方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Encoder-Decoder-Architectures-for-Biplanar-X-ray-to-3D-Shape-Reconstruction"><a href="#Benchmarking-Encoder-Decoder-Architectures-for-Biplanar-X-ray-to-3D-Shape-Reconstruction" class="headerlink" title="Benchmarking Encoder-Decoder Architectures for Biplanar X-ray to 3D Shape Reconstruction"></a>Benchmarking Encoder-Decoder Architectures for Biplanar X-ray to 3D Shape Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13587">http://arxiv.org/abs/2309.13587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahesh Shakya, Bishesh Khanal</li>
<li>for: 这些论文的目的是为了evaluate多种深度学习模型在2D-3D骨形状重建方面的性能，以便在临床应用中进行评估和选择最佳模型。</li>
<li>methods: 这些论文使用的方法包括多种深度学习模型，以及Automatic clinical parameter and landmark extraction methods。</li>
<li>results: 这些论文的结果表明，关注全域空间关系的注意力机制方法在所有骨性质和数据集上表现较好，但是在临床相关的 subgroup中表现可能会被过度估计，肋骨比 femur、hip 和脊梁更加困难重建，并且 dice score 改进不总是导致自动计算临床相关参数的改进。<details>
<summary>Abstract</summary>
Various deep learning models have been proposed for 3D bone shape reconstruction from two orthogonal (biplanar) X-ray images. However, it is unclear how these models compare against each other since they are evaluated on different anatomy, cohort and (often privately held) datasets. Moreover, the impact of the commonly optimized image-based segmentation metrics such as dice score on the estimation of clinical parameters relevant in 2D-3D bone shape reconstruction is not well known. To move closer toward clinical translation, we propose a benchmarking framework that evaluates tasks relevant to real-world clinical scenarios, including reconstruction of fractured bones, bones with implants, robustness to population shift, and error in estimating clinical parameters. Our open-source platform provides reference implementations of 8 models (many of whose implementations were not publicly available), APIs to easily collect and preprocess 6 public datasets, and the implementation of automatic clinical parameter and landmark extraction methods. We present an extensive evaluation of 8 2D-3D models on equal footing using 6 public datasets comprising images for four different anatomies. Our results show that attention-based methods that capture global spatial relationships tend to perform better across all anatomies and datasets; performance on clinically relevant subgroups may be overestimated without disaggregated reporting; ribs are substantially more difficult to reconstruct compared to femur, hip and spine; and the dice score improvement does not always bring a corresponding improvement in the automatic estimation of clinically relevant parameters.
</details>
<details>
<summary>摘要</summary>
各种深度学习模型已经提议用于从两个mutually orthogonal（biplanar）X射线图像中重建3D骨形状。然而，它们之间的比较很难，因为它们在不同的解剖学、人群和（常常是私人拥有）数据集上进行评估。此外，通常优化的图像基于分割指标如 dice score 对2D-3D骨形状重建中的临床参数的影响不够了解。为了更近地到临床翻译，我们提出了一个 benchmarking 框架，评估了实际临床情景中的任务，包括骨折重建、骨嵌入、人口变化的Robustness和临床参数的错误。我们的开源平台提供了8个模型的参考实现（许多实现没有公开）、6个公共数据集的自动化采集和处理API，以及自动提取临床参数和标记的实现。我们对8个2D-3D模型进行了平等评估，使用6个公共数据集，包括4种不同的解剖学。我们的结果显示： attention-based 方法， capture 全局空间关系，在所有解剖学和数据集上表现较好; 不分解的报告可能会过分估计临床重要 subgroup; 肋骨重建相比股骨、股骨和脊梁更加困难; 并 dice score 改进不总是导致自动计算临床参数的改进。
</details></li>
</ul>
<hr>
<h2 id="Solving-Low-Dose-CT-Reconstruction-via-GAN-with-Local-Coherence"><a href="#Solving-Low-Dose-CT-Reconstruction-via-GAN-with-Local-Coherence" class="headerlink" title="Solving Low-Dose CT Reconstruction via GAN with Local Coherence"></a>Solving Low-Dose CT Reconstruction via GAN with Local Coherence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13584">http://arxiv.org/abs/2309.13584</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lwjie595/GANLC">https://github.com/lwjie595/GANLC</a></li>
<li>paper_authors: Wenjie Liu</li>
<li>for: 用于诊断人体内部器官病变的计算Tomography（CT）成为医学影像领域的基本话题之一，低剂CT的使用被广泛采用，因此其重建方法得到了广泛的研究。</li>
<li>methods: 我们提出了一种基于生成对抗网络（GANs）的新方法，该方法可以利用运动场进行优化，从而提高重建图像的地方协调性和稳定性。</li>
<li>results: 我们对实验数据进行评估，结果表明，我们的提议方法可以与现有的状态对抗方法相比，显著提高重建图像的精度和稳定性。<details>
<summary>Abstract</summary>
The Computed Tomography (CT) for diagnosis of lesions in human internal organs is one of the most fundamental topics in medical imaging. Low-dose CT, which offers reduced radiation exposure, is preferred over standard-dose CT, and therefore its reconstruction approaches have been extensively studied. However, current low-dose CT reconstruction techniques mainly rely on model-based methods or deep-learning-based techniques, which often ignore the coherence and smoothness for sequential CT slices. To address this issue, we propose a novel approach using generative adversarial networks (GANs) with enhanced local coherence. The proposed method can capture the local coherence of adjacent images by optical flow, which yields significant improvements in the precision and stability of the constructed images. We evaluate our proposed method on real datasets and the experimental results suggest that it can outperform existing state-of-the-art reconstruction approaches significantly.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 用于人体内部肿瘤诊断是医学影像领域的基本话题之一。低剂量 CT 比标准剂量 CT 更受欢迎，因此其重建方法得到了广泛的研究。然而，现有的低剂量 CT 重建技术主要基于模型基本方法或深度学习基本方法，这些方法经常忽略邻域 CT slice 的协调性和平滑性。为解决这个问题，我们提出了一种使用生成对抗网络 (GANs) 增强本地协调性的新方法。该方法可以通过光流来捕捉邻域图像的本地协调性，从而实现显著提高重建图像的精度和稳定性。我们在实际数据集上测试了我们的提议方法，实验结果表明，它可以与现有的状态空间重建方法相比，显著提高重建图像的质量。
</details></li>
</ul>
<hr>
<h2 id="A-SAM-based-Solution-for-Hierarchical-Panoptic-Segmentation-of-Crops-and-Weeds-Competition"><a href="#A-SAM-based-Solution-for-Hierarchical-Panoptic-Segmentation-of-Crops-and-Weeds-Competition" class="headerlink" title="A SAM-based Solution for Hierarchical Panoptic Segmentation of Crops and Weeds Competition"></a>A SAM-based Solution for Hierarchical Panoptic Segmentation of Crops and Weeds Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13578">http://arxiv.org/abs/2309.13578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khoa Dang Nguyen, Thanh-Hai Phung, Hoang-Giang Cao</li>
<li>for: 这个论文旨在探讨农业领域的高级计算机视觉技术——泛型分割，以提高农业作物和杂草的识别和分类。</li>
<li>methods: 该论文提出了一种combines Segment AnyThing Model (SAM)和对象检测模型的方法，以实现高级分割任务。 specifically, 该方法 integrate了两种对象检测模型的特点，namely DINO和YOLO-v8。</li>
<li>results: 该论文的best-performing模型在竞赛中的PQ+分数为81.33。<details>
<summary>Abstract</summary>
Panoptic segmentation in agriculture is an advanced computer vision technique that provides a comprehensive understanding of field composition. It facilitates various tasks such as crop and weed segmentation, plant panoptic segmentation, and leaf instance segmentation, all aimed at addressing challenges in agriculture. Exploring the application of panoptic segmentation in agriculture, the 8th Workshop on Computer Vision in Plant Phenotyping and Agriculture (CVPPA) hosted the challenge of hierarchical panoptic segmentation of crops and weeds using the PhenoBench dataset. To tackle the tasks presented in this competition, we propose an approach that combines the effectiveness of the Segment AnyThing Model (SAM) for instance segmentation with prompt input from object detection models. Specifically, we integrated two notable approaches in object detection, namely DINO and YOLO-v8. Our best-performing model achieved a PQ+ score of 81.33 based on the evaluation metrics of the competition.
</details>
<details>
<summary>摘要</summary>
“对农业中的涵盖分割技术（panoptic segmentation）进行了进一步的探索，以获得农田场景的全面理解。这技术可以帮助农业面临的问题，例如作物和杂草分类、植物涵盖分类以及叶子实例分类。为了探索这些应用，CVPPA年会（8th Workshop on Computer Vision in Plant Phenotyping and Agriculture）举办了一个挑战，即使用PhenoBench数据集进行阶层涵盖分类。我们提出了一个结合SAM模型（Segment AnyThing Model）的实例分类方法，并与物件探测模型（DINO和YOLO-v8）进行了统合。我们的最佳模型在竞赛中的PQ+分数为81.33。”Note: "PQ+ score" is a combination of precision, recall, and F1-score, which is a common evaluation metric for segmentation tasks.
</details></li>
</ul>
<hr>
<h2 id="Matrix-Completion-Informed-Deep-Unfolded-Equilibrium-Models-for-Self-Supervised-k-Space-Interpolation-in-MRI"><a href="#Matrix-Completion-Informed-Deep-Unfolded-Equilibrium-Models-for-Self-Supervised-k-Space-Interpolation-in-MRI" class="headerlink" title="Matrix Completion-Informed Deep Unfolded Equilibrium Models for Self-Supervised k-Space Interpolation in MRI"></a>Matrix Completion-Informed Deep Unfolded Equilibrium Models for Self-Supervised k-Space Interpolation in MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13571">http://arxiv.org/abs/2309.13571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Luo, Huayu Wang, Taofeng Xie, Qiyu Jin, Guoqing Chen, Zhuo-Xu Cui, Dong Liang</li>
<li>for: 提高MRI图像的速度和质量，不需要完整的标签数据</li>
<li>methods: 利用深度学习模型，同时保留常规模型的理论保证</li>
<li>results: 提出一种自适应深度学习方法，可以在不具备完整标签数据的情况下，实现MRI图像的加速和提高Here is the full text in Simplified Chinese:</li>
<li>for: 本研究旨在提高MRI图像的速度和质量，不需要完整的标签数据。</li>
<li>methods: 我们提出了一种利用深度学习模型的自适应方法，同时保留常规模型的理论保证。</li>
<li>results: 我们的方法可以在不具备完整标签数据的情况下，实现MRI图像的加速和提高，并且超过了现有的自适应方法和传统正则化方法的性能。<details>
<summary>Abstract</summary>
Recently, regularization model-driven deep learning (DL) has gained significant attention due to its ability to leverage the potent representational capabilities of DL while retaining the theoretical guarantees of regularization models. However, most of these methods are tailored for supervised learning scenarios that necessitate fully sampled labels, which can pose challenges in practical MRI applications. To tackle this challenge, we propose a self-supervised DL approach for accelerated MRI that is theoretically guaranteed and does not rely on fully sampled labels. Specifically, we achieve neural network structure regularization by exploiting the inherent structural low-rankness of the $k$-space data. Simultaneously, we constrain the network structure to resemble a nonexpansive mapping, ensuring the network's convergence to a fixed point. Thanks to this well-defined network structure, this fixed point can completely reconstruct the missing $k$-space data based on matrix completion theory, even in situations where full-sampled labels are unavailable. Experiments validate the effectiveness of our proposed method and demonstrate its superiority over existing self-supervised approaches and traditional regularization methods, achieving performance comparable to that of supervised learning methods in certain scenarios.
</details>
<details>
<summary>摘要</summary>
We achieve neural network structure regularization by exploiting the inherent low-rankness of the $k$-space data. Simultaneously, we constrain the network structure to be nonexpansive, ensuring the network's convergence to a fixed point. Thanks to this well-defined network structure, this fixed point can completely reconstruct the missing $k$-space data based on matrix completion theory, even when full-sampled labels are unavailable.Experiments demonstrate the effectiveness of our proposed method and its superiority over existing self-supervised approaches and traditional regularization methods. In certain scenarios, our method achieves performance comparable to that of supervised learning methods.
</details></li>
</ul>
<hr>
<h2 id="Robust-Digital-Twin-Localization-via-An-RGBD-based-Transformer-Network-and-A-Comprehensive-Evaluation-on-a-Mobile-Dataset"><a href="#Robust-Digital-Twin-Localization-via-An-RGBD-based-Transformer-Network-and-A-Comprehensive-Evaluation-on-a-Mobile-Dataset" class="headerlink" title="Robust Digital-Twin Localization via An RGBD-based Transformer Network and A Comprehensive Evaluation on a Mobile Dataset"></a>Robust Digital-Twin Localization via An RGBD-based Transformer Network and A Comprehensive Evaluation on a Mobile Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13570">http://arxiv.org/abs/2309.13570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/augcog/dttd2">https://github.com/augcog/dttd2</a></li>
<li>paper_authors: Zixun Huang, Keling Yao, Seth Z. Zhao, Chuanyu Pan, Tianjian Xu, Weiyu Feng, Allen Y. Yang</li>
<li>for: 本研究旨在探讨数字双技术在3D物体跟踪和地理位置确定方面的潜在作用，并提出一种基于变换器的6DoF姿态估计器，以实现在真实世界噪声数据下的最佳准确性。</li>
<li>methods: 本研究使用变换器来实现6DoF姿态估计器，并通过对现有 литературы的全面验证，提出了一个新的RGBD数据集called Digital Twin Tracking Dataset v2 (DTTD2)，以适应iPhone感知器数据。</li>
<li>results: 经过广泛的实验和深入分析，本研究证明了我们的方法在面临深度数据错误时仍然能够表现出优于现有基elines的性能。<details>
<summary>Abstract</summary>
The potential of digital-twin technology, involving the creation of precise digital replicas of physical objects, to reshape AR experiences in 3D object tracking and localization scenarios is significant. However, enabling robust 3D object tracking in dynamic mobile AR environments remains a formidable challenge. These scenarios often require a more robust pose estimator capable of handling the inherent sensor-level measurement noise. In this paper, recognizing the challenges of comprehensive solutions in existing literature, we propose a transformer-based 6DoF pose estimator designed to achieve state-of-the-art accuracy under real-world noisy data. To systematically validate the new solution's performance against the prior art, we also introduce a novel RGBD dataset called Digital Twin Tracking Dataset v2 (DTTD2), which is focused on digital-twin object tracking scenarios. Expanded from an existing DTTD v1 (DTTD1), the new dataset adds digital-twin data captured using a cutting-edge mobile RGBD sensor suite on Apple iPhone 14 Pro, expanding the applicability of our approach to iPhone sensor data. Through extensive experimentation and in-depth analysis, we illustrate the effectiveness of our methods under significant depth data errors, surpassing the performance of existing baselines. Code and dataset are made publicly available at: https://github.com/augcog/DTTD2
</details>
<details>
<summary>摘要</summary>
“数字双身技术的潜在可能性，即创建精确的数字对象复制，对于3D对象跟踪和本地化场景的AR经验进行重塑，是非常 significannot。然而，在动态 mobil AR 环境中实现Robust 3D对象跟踪仍然是一大挑战。这些场景通常需要一个更加Robust的 pose estimator，可以处理潜在的 sensor-level 测量噪音。在这篇论文中，我们认为现有Literature中的全面解决方案存在挑战，因此我们提出了一种基于 transformer 的 6DoF pose estimator，可以在实际世界噪音数据下实现 state-of-the-art 精度。为了系统地验证我们的新解决方案的性能，我们还发布了一个名为 Digital Twin Tracking Dataset v2 (DTTD2) 的新数据集，该数据集专注于数字双身对象跟踪场景。DTTD2 是基于 DTTD1 的扩展，新增了使用高级 mobil RGBD 感知器 suite 在 Apple iPhone 14 Pro 上 captured 的数字双身数据，使我们的方法可以应用于 iPhone 感知器数据。通过广泛的实验和深入分析，我们证明了我们的方法在重大深度数据错误下可以实现更高的性能，超过现有的基准值。Code 和数据集在 GitHub 上公开，请参考：https://github.com/augcog/DTTD2。”
</details></li>
</ul>
<hr>
<h2 id="Multivariate-Prototype-Representation-for-Domain-Generalized-Incremental-Learning"><a href="#Multivariate-Prototype-Representation-for-Domain-Generalized-Incremental-Learning" class="headerlink" title="Multivariate Prototype Representation for Domain-Generalized Incremental Learning"></a>Multivariate Prototype Representation for Domain-Generalized Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13563">http://arxiv.org/abs/2309.13563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Can Peng, Piotr Koniusz, Kaiyu Guo, Brian C. Lovell, Peyman Moghadam</li>
<li>for: 这种研究旨在解决深度学习模型在新类样本微调时发生的灾难性忘记问题，以及这种问题在不同领域数据上进行测试时的域shift问题。</li>
<li>methods: 我们提出了一种Domain-Generalized Class-Incremental Learning（DGCIL）方法，该方法能够保持老类，适应新类，并可以在未看过的领域上进行可靠的分类。我们的损失函数保持分类boundary，并且降低每个类的域特定信息。无需保存老示例，我们使用知识传播和估计老类prototype偏移来进行逐步训练。我们的prototype表示基于多变量正态分布，其中的均值和协方差是随着模型特征的变化而不断地适应老类。为了保持老类的表示，我们采用Cholesky分解来采样pseudo-特征。相比之前的pseudo-特征采样策略，我们的方法能够更好地捕捉变异semantic信息。</li>
<li>results: 我们在多个benchmark上进行了实验，并证明了我们的方法的主张。<details>
<summary>Abstract</summary>
Deep learning models suffer from catastrophic forgetting when being fine-tuned with samples of new classes. This issue becomes even more pronounced when faced with the domain shift between training and testing data. In this paper, we study the critical and less explored Domain-Generalized Class-Incremental Learning (DGCIL). We design a DGCIL approach that remembers old classes, adapts to new classes, and can classify reliably objects from unseen domains. Specifically, our loss formulation maintains classification boundaries and suppresses the domain-specific information of each class. With no old exemplars stored, we use knowledge distillation and estimate old class prototype drift as incremental training advances. Our prototype representations are based on multivariate Normal distributions whose means and covariances are constantly adapted to changing model features to represent old classes well by adapting to the feature space drift. For old classes, we sample pseudo-features from the adapted Normal distributions with the help of Cholesky decomposition. In contrast to previous pseudo-feature sampling strategies that rely solely on average mean prototypes, our method excels at capturing varying semantic information. Experiments on several benchmarks validate our claims.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LOGICSEG-Parsing-Visual-Semantics-with-Neural-Logic-Learning-and-Reasoning"><a href="#LOGICSEG-Parsing-Visual-Semantics-with-Neural-Logic-Learning-and-Reasoning" class="headerlink" title="LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and Reasoning"></a>LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13556">http://arxiv.org/abs/2309.13556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liulei Li, Wenguan Wang, Yi Yang</li>
<li>for: 填充高性能semantic segmentation模型的潜在空白，使得模型能够更好地理解视觉世界的结构和抽象。</li>
<li>methods: 利用神经 inductive 学习和逻辑推理，将数据和符号知识结合在一起，从而实现视 semantic 解析。</li>
<li>results: 在四个 dataset 上进行了广泛的实验，证明了 LOGICSEG 的效果和通用性。<details>
<summary>Abstract</summary>
Current high-performance semantic segmentation models are purely data-driven sub-symbolic approaches and blind to the structured nature of the visual world. This is in stark contrast to human cognition which abstracts visual perceptions at multiple levels and conducts symbolic reasoning with such structured abstraction. To fill these fundamental gaps, we devise LOGICSEG, a holistic visual semantic parser that integrates neural inductive learning and logic reasoning with both rich data and symbolic knowledge. In particular, the semantic concepts of interest are structured as a hierarchy, from which a set of constraints are derived for describing the symbolic relations and formalized as first-order logic rules. After fuzzy logic-based continuous relaxation, logical formulae are grounded onto data and neural computational graphs, hence enabling logic-induced network training. During inference, logical constraints are packaged into an iterative process and injected into the network in a form of several matrix multiplications, so as to achieve hierarchy-coherent prediction with logic reasoning. These designs together make LOGICSEG a general and compact neural-logic machine that is readily integrated into existing segmentation models. Extensive experiments over four datasets with various segmentation models and backbones verify the effectiveness and generality of LOGICSEG. We believe this study opens a new avenue for visual semantic parsing.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:当前高性能semantic segmentation模型都是纯数据驱动的sub-symbolic方法，而这与人类认知的抽象Visual perception at multiple levels and symbolic reasoning with structured abstraction is in stark contrast. To fill these fundamental gaps, we propose LOGICSEG, a comprehensive visual semantic parser that combines neural inductive learning and logic reasoning with both rich data and symbolic knowledge. Specifically, the semantic concepts of interest are structured as a hierarchy, from which a set of constraints are derived for describing the symbolic relations and formalized as first-order logic rules. After fuzzy logic-based continuous relaxation, logical formulae are grounded onto data and neural computational graphs, thereby enabling logic-induced network training. During inference, logical constraints are packaged into an iterative process and injected into the network in the form of several matrix multiplications, thereby achieving hierarchy-coherent prediction with logic reasoning. These designs together make LOGICSEG a versatile and compact neural-logic machine that can be seamlessly integrated into existing segmentation models. Experimental results over four datasets with various segmentation models and backbones demonstrate the effectiveness and generality of LOGICSEG. We believe this study opens a new avenue for visual semantic parsing.
</details></li>
</ul>
<hr>
<h2 id="Generalized-Dice-Focal-Loss-trained-3D-Residual-UNet-for-Automated-Lesion-Segmentation-in-Whole-Body-FDG-PET-CT-Images"><a href="#Generalized-Dice-Focal-Loss-trained-3D-Residual-UNet-for-Automated-Lesion-Segmentation-in-Whole-Body-FDG-PET-CT-Images" class="headerlink" title="Generalized Dice Focal Loss trained 3D Residual UNet for Automated Lesion Segmentation in Whole-Body FDG PET&#x2F;CT Images"></a>Generalized Dice Focal Loss trained 3D Residual UNet for Automated Lesion Segmentation in Whole-Body FDG PET&#x2F;CT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13553">http://arxiv.org/abs/2309.13553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahxmeds/autosegnet">https://github.com/ahxmeds/autosegnet</a></li>
<li>paper_authors: Shadab Ahamed, Arman Rahmim</li>
<li>For: The paper is written for developing a comprehensive PET&#x2F;CT lesion segmentation model for routine quantitative image analysis.* Methods: The paper uses a 3D Residual UNet with Generalized Dice Focal Loss function on the AutoPET challenge 2023 training dataset, and develops the model in a 5-fold cross-validation setting with ensemble learning.* Results: The average ensemble achieved a Dice similarity coefficient (DSC) of 0.5417, false-positive volume (FPV) of 0.8261 ml, and false negative volume (FNV) of 0.2538 ml, while the weighted-average ensemble achieved similar results.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是为了开发一个 Routine 量化图像分析中的 PET&#x2F;CT 癌症分割模型。* Methods: 这篇论文使用了 3D Residual UNet 与 Generalized Dice Focal Loss 函数在 AutoPET 挑战 2023 训练集上进行了训练，并使用了 5-fold 交叉验证设置和 ensemble 学习。* Results: 平均ensemble 达到了 Dice 相似度系数 (DSC) 为 0.5417，false-positive volume (FPV) 为 0.8261 ml，false negative volume (FNV) 为 0.2538 ml，而 weighted-average ensemble 也达到了类似的结果。<details>
<summary>Abstract</summary>
Automated segmentation of cancerous lesions in PET/CT images is a vital initial task for quantitative analysis. However, it is often challenging to train deep learning-based segmentation methods to high degree of accuracy due to the diversity of lesions in terms of their shapes, sizes, and radiotracer uptake levels. These lesions can be found in various parts of the body, often close to healthy organs that also show significant uptake. Consequently, developing a comprehensive PET/CT lesion segmentation model is a demanding endeavor for routine quantitative image analysis. In this work, we train a 3D Residual UNet using Generalized Dice Focal Loss function on the AutoPET challenge 2023 training dataset. We develop our models in a 5-fold cross-validation setting and ensemble the five models via average and weighted-average ensembling. On the preliminary test phase, the average ensemble achieved a Dice similarity coefficient (DSC), false-positive volume (FPV) and false negative volume (FNV) of 0.5417, 0.8261 ml, and 0.2538 ml, respectively, while the weighted-average ensemble achieved 0.5417, 0.8186 ml, and 0.2538 ml, respectively. Our algorithm can be accessed via this link: https://github.com/ahxmeds/autosegnet.
</details>
<details>
<summary>摘要</summary>
自动 segmentation of cancerous lesions in PET/CT images 是一项非常重要的初始任务，用于量化分析。然而，由于肿瘤的多样性，包括形状、大小和辐射追踪水平，因此往往具有很高的学习难度。这些肿瘤可以在体内各个部位找到， часто靠近健康的器官，这些器官也会显示出明显的辐射吸收。因此，开发一个全面的 PET/CT 肿瘤 segmentation 模型是一项复杂的任务，用于日常量化图像分析。在这个工作中，我们使用 Generalized Dice Focal Loss 函数来训练一个 3D Residual UNet 模型。我们在 5-fold 跨Validation  Setting 中进行了模型开发，并使用 average 和 weighted-average  ensemble。在预liminary test阶段，average ensemble 达到了 Dice similarity coefficient (DSC)、false-positive volume (FPV) 和 false negative volume (FNV) 的值为 0.5417，0.8261 ml 和 0.2538 ml，分别。而 weighted-average ensemble 达到了 0.5417，0.8186 ml 和 0.2538 ml，分别。我们的算法可以通过以下链接访问：https://github.com/ahxmeds/autosegnet。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Robot-3D-Perception-in-Urban-Environments-The-UT-Campus-Object-Dataset"><a href="#Towards-Robust-Robot-3D-Perception-in-Urban-Environments-The-UT-Campus-Object-Dataset" class="headerlink" title="Towards Robust Robot 3D Perception in Urban Environments: The UT Campus Object Dataset"></a>Towards Robust Robot 3D Perception in Urban Environments: The UT Campus Object Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13549">http://arxiv.org/abs/2309.13549</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ut-amrl/coda-models">https://github.com/ut-amrl/coda-models</a></li>
<li>paper_authors: Arthur Zhang, Chaitanya Eranki, Christina Zhang, Ji-Hwan Park, Raymond Hong, Pranav Kalyani, Lochana Kalyanaraman, Arsh Gamare, Arnav Bagad, Maria Esteva, Joydeep Biswas</li>
<li>for: 这个论文是为了提供一个大学校园环境下的自主 Navigation 的数据集，用于 Egocentric 3D 识别和规划。</li>
<li>methods: 该论文使用了多 modal 感知器，包括 3D 点云和颜色视频，以及 RGB-D 视频和 IMU 传感器，并提供了大量的Annotation。</li>
<li>results: 该论文的实验结果表明，使用 CODa 数据集可以提高urban 环境中 3D  объек检测性能，并且 sensor-specific 细化调整和预训练可以进一步提高检测精度。<details>
<summary>Abstract</summary>
We introduce the UT Campus Object Dataset (CODa), a mobile robot egocentric perception dataset collected on the University of Texas Austin Campus. Our dataset contains 8.5 hours of multimodal sensor data: synchronized 3D point clouds and stereo RGB video from a 128-channel 3D LiDAR and two 1.25MP RGB cameras at 10 fps; RGB-D videos from an additional 0.5MP sensor at 7 fps, and a 9-DOF IMU sensor at 40 Hz. We provide 58 minutes of ground-truth annotations containing 1.3 million 3D bounding boxes with instance IDs for 53 semantic classes, 5000 frames of 3D semantic annotations for urban terrain, and pseudo-ground truth localization. We repeatedly traverse identical geographic locations for a wide range of indoor and outdoor areas, weather conditions, and times of the day. Using CODa, we empirically demonstrate that: 1) 3D object detection performance in urban settings is significantly higher when trained using CODa compared to existing datasets even when employing state-of-the-art domain adaptation approaches, 2) sensor-specific fine-tuning improves 3D object detection accuracy and 3) pretraining on CODa improves cross-dataset 3D object detection performance in urban settings compared to pretraining on AV datasets. Using our dataset and annotations, we release benchmarks for 3D object detection and 3D semantic segmentation using established metrics. In the future, the CODa benchmark will include additional tasks like unsupervised object discovery and re-identification. We publicly release CODa on the Texas Data Repository, pre-trained models, dataset development package, and interactive dataset viewer on our website at https://amrl.cs.utexas.edu/coda. We expect CODa to be a valuable dataset for research in egocentric 3D perception and planning for autonomous navigation in urban environments.
</details>
<details>
<summary>摘要</summary>
我们介绍UT кампус物件Dataset（CODa），是一个移动机器人自我观察 Dataset，在德州大学奥斯汀分校范围内收集到的8.5小时多modal感应数据。我们的数据包括同步3D点云和stereoRGB影像，来自128通道3D LiDAR和两个1.25MPRGB摄像头，每秒10帧;RGB-D影像从额外0.5MP感应器，每秒7帧，以及9DOF IMU感应器，每秒40Hz。我们提供58分钟的真实标注，包括1.3百万个3D bounding box，每个物体都有实体ID，分配到53个semantic class中;5000帧3D实体标注，用于城市地形的处理;以及假的地理位置标注。我们在同一个地理位置上重复探索了各种室内和室外区域，天气状况和时间。使用CODa，我们经过实验证明：1）在城市设置中，使用CODa进行训练后，3D物体检测性能高于现有数据集，即使使用现有的领域适应方法;2）感应器特定的精确调整可以提高3D物体检测精度;3）使用CODa进行预训可以在城市设置中提高交叉数据集3D物体检测性能。我们在我们的网站上公开了CODa，包括预训模型、数据开发套件和互动数据检视器，可以在https://amrl.cs.utexas.edu/coda 中找到。我们预期CODa将成为城市自主navigation egocentric 3D视察和规划的重要数据集。
</details></li>
</ul>
<hr>
<h2 id="DFRD-Data-Free-Robustness-Distillation-for-Heterogeneous-Federated-Learning"><a href="#DFRD-Data-Free-Robustness-Distillation-for-Heterogeneous-Federated-Learning" class="headerlink" title="DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning"></a>DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13546">http://arxiv.org/abs/2309.13546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kangyang Luo, Shuai Wang, Yexuan Fu, Xiang Li, Yunshi Lan, Ming Gao</li>
<li>for: 提出了一种隐私保护的分布式学习方法（DFRD），可以在数据不同和模型不同的场景下培养一个稳定和有效的全局模型。</li>
<li>methods: 在服务器端使用一个条件生成器来估算本地模型上传的训练空间，并系统地调查其训练的准确度、传输性和多样性。</li>
<li>results: 通过实验证明，DFRD在多个图像分类任务上比最佳参考模型具有显著的性能提升。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a privacy-constrained decentralized machine learning paradigm in which clients enable collaborative training without compromising private data. However, how to learn a robust global model in the data-heterogeneous and model-heterogeneous FL scenarios is challenging. To address it, we resort to data-free knowledge distillation to propose a new FL method (namely DFRD). DFRD equips a conditional generator on the server to approximate the training space of the local models uploaded by clients, and systematically investigates its training in terms of fidelity, transferability} and diversity. To overcome the catastrophic forgetting of the global model caused by the distribution shifts of the generator across communication rounds, we maintain an exponential moving average copy of the generator on the server. Additionally, we propose dynamic weighting and label sampling to accurately extract knowledge from local models. Finally, our extensive experiments on various image classification tasks illustrate that DFRD achieves significant performance gains compared to SOTA baselines.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种遵循 privacy 的分布式机器学习模式，在Client端实现协同训练而无需披露私人数据。然而，在数据不同和模型不同的 FL 场景中，学习 Robust 的全球模型是一个挑战。为此，我们通过不使用数据的知识热化来提出一种新的 FL 方法（namely DFRD）。DFRD 在服务器端安装一个Conditional generator，用于模拟客户端上传的本地模型的训练空间，并系统地研究其训练的准确性、传递性和多样性。为了解决由生成器在交流周期中的分布转移所引起的全球模型的忘却性，我们在服务器端维护一个指数移动平均的生成器复制。此外，我们提出了动态权重和标签采样，以准确地提取本地模型中的知识。最后，我们在不同的图像分类任务上进行了广泛的实验，结果显示，DFRD 与当前的标准基eline相比， achieved 显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Evaluation-of-Transfer-Learning-for-Classification-of-Brain-Tumor-Using-MRI"><a href="#Comparative-Evaluation-of-Transfer-Learning-for-Classification-of-Brain-Tumor-Using-MRI" class="headerlink" title="Comparative Evaluation of Transfer Learning for Classification of Brain Tumor Using MRI"></a>Comparative Evaluation of Transfer Learning for Classification of Brain Tumor Using MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.02270">http://arxiv.org/abs/2310.02270</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abu Kaisar Mohammad Masum, Nusrat Badhon, S. M. Saiful Islam Badhon, Nushrat Jahan Ria, Sheikh Abujar, Muntaser Mansur Syed, Naveed Mahmud</li>
<li>for: 这项研究旨在利用计算机助成诊断技术，尤其是机器学习和深度学习，以分类三种脑肿瘤。</li>
<li>methods: 我们使用了四种转移学习技术来分类脑肿瘤，并在一个标准数据集上进行测试，包括3064个MRI图像，表示三种脑肿瘤。</li>
<li>results: 我们发现，使用ResNet-50模型可以达到99.06%的准确率，超过其他模型。我们还证明了如何在均衡数据集上提高准确率，而无需使用扩展方法。<details>
<summary>Abstract</summary>
Abnormal growth of cells in the brain and its surrounding tissues is known as a brain tumor. There are two types, one is benign (non-cancerous) and another is malignant (cancerous) which may cause death. The radiologists' ability to diagnose malignancies is greatly aided by magnetic resonance imaging (MRI). Brain cancer diagnosis has been considerably expedited by the field of computer-assisted diagnostics, especially in machine learning and deep learning. In our study, we categorize three different kinds of brain tumors using four transfer learning techniques. Our models were tested on a benchmark dataset of $3064$ MRI pictures representing three different forms of brain cancer. Notably, ResNet-50 outperformed other models with a remarkable accuracy of $99.06\%$. We stress the significance of a balanced dataset for improving accuracy without the use of augmentation methods. Additionally, we experimentally demonstrate our method and compare with other classification algorithms on the CE-MRI dataset using evaluations like F1-score, AUC, precision and recall.
</details>
<details>
<summary>摘要</summary>
异常组织增长在脑和周围组织中 known as 脑肿瘤。这有两种，一种是非恶性（非癌细胞），另一种是恶性（癌细胞），可能导致死亡。医学影像识别异常性的能力得到了巨大的助益，特别是在电磁共振成像（MRI）和电脑协助诊断领域。在我们的研究中，我们分类了三种不同的脑肿瘤，使用四种转移学习技术。我们的模型在一个底本数据集上进行测试，包括3064幅 MRI 照片，代表三种不同的脑癌。值得注意的是，ResNet-50 的准确率达到了99.06%，在其他模型中具有卓越的表现。我们强调了统计数据的平衡性，以提高准确性，而不需使用增强方法。此外，我们实验性地评估了我们的方法，并与其他分类算法进行比较，使用评估指标如 F1 分数、AUC、精度和 recall。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Domain-Generalization-for-Object-Detection-via-Language-Guided-Feature-Alignment"><a href="#Semi-Supervised-Domain-Generalization-for-Object-Detection-via-Language-Guided-Feature-Alignment" class="headerlink" title="Semi-Supervised Domain Generalization for Object Detection via Language-Guided Feature Alignment"></a>Semi-Supervised Domain Generalization for Object Detection via Language-Guided Feature Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13525">http://arxiv.org/abs/2309.13525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sinamalakouti/CDDMSL">https://github.com/sinamalakouti/CDDMSL</a></li>
<li>paper_authors: Sina Malakouti, Adriana Kovashka</li>
<li>for: 这篇论文旨在解决半有 labels 的领域泛化（Domain Generalization，DG）和领域转换（Domain Adaptation，DA）问题，并且将vision-language预训应用于这个问题。</li>
<li>methods: 这篇论文使用了一种新的 Cross-Domain Descriptive Multi-Scale Learning（CDDMSL）方法，它通过将图像描述在语言空间中进行对领域特有特征的对应，以实现图像描述的协调。</li>
<li>results:  compared to existing methods, CDDMSL 在 DG 和 DA 环境中都有着重要的进步，实现了11.7%和7.5%的改善。<details>
<summary>Abstract</summary>
Existing domain adaptation (DA) and generalization (DG) methods in object detection enforce feature alignment in the visual space but face challenges like object appearance variability and scene complexity, which make it difficult to distinguish between objects and achieve accurate detection. In this paper, we are the first to address the problem of semi-supervised domain generalization by exploring vision-language pre-training and enforcing feature alignment through the language space. We employ a novel Cross-Domain Descriptive Multi-Scale Learning (CDDMSL) aiming to maximize the agreement between descriptions of an image presented with different domain-specific characteristics in the embedding space. CDDMSL significantly outperforms existing methods, achieving 11.7% and 7.5% improvement in DG and DA settings, respectively. Comprehensive analysis and ablation studies confirm the effectiveness of our method, positioning CDDMSL as a promising approach for domain generalization in object detection tasks.
</details>
<details>
<summary>摘要</summary>
现有的领域适应（DA）和通用化（DG）方法在物体检测中强制视觉空间中的特征对齐，但面临对象外观多样性和场景复杂性等挑战，这使得分辨对象并不容易，精度检测也不高。在这篇论文中，我们是首次解决半supervised领域通用化问题，通过探索视觉语言预训练和在语言空间强制特征对齐。我们提出了一种新的跨领域描述多Scale学习（CDDMSL），旨在 maximize图像的描述在嵌入空间中的一致性。CDDMSL与现有方法相比，显著提高了11.7%和7.5%的提升率，分别在DA和DG设置下。广泛的分析和缺省研究证明了我们的方法的有效性，positioning CDDMSL为领域通用化在物体检测任务中的可靠方法。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-UDA-Self-ensembling-Through-Time-for-Unsupervised-LiDAR-Domain-Adaptation"><a href="#LiDAR-UDA-Self-ensembling-Through-Time-for-Unsupervised-LiDAR-Domain-Adaptation" class="headerlink" title="LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation"></a>LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13523">http://arxiv.org/abs/2309.13523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirreza Shaban, JoonHo Lee, Sanghun Jung, Xiangyun Meng, Byron Boots</li>
<li>for: 这个研究是为了提出一个基于自适应领域对应（UDA）的 LiDAR 分类方法，以应对不同 LiDAR 感应器配置所带来的领域差异。</li>
<li>methods: 这个方法使用了两个技术来降低感应器差异和提高pseudo标签质量：1）LiDAR 焦点抽样，实现不同 LiDAR 扫描模式的模拟；2）跨帧聚合，利用 consecutive 帧的时间一致性来生成更可靠的pseudo标签。</li>
<li>results: 这个方法在多个公开 LiDAR 数据集上进行评估，与现有的方法相比，获得了更高的平均 mIoU 分量 ($3.9%$) 。<details>
<summary>Abstract</summary>
We introduce LiDAR-UDA, a novel two-stage self-training-based Unsupervised Domain Adaptation (UDA) method for LiDAR segmentation. Existing self-training methods use a model trained on labeled source data to generate pseudo labels for target data and refine the predictions via fine-tuning the network on the pseudo labels. These methods suffer from domain shifts caused by different LiDAR sensor configurations in the source and target domains. We propose two techniques to reduce sensor discrepancy and improve pseudo label quality: 1) LiDAR beam subsampling, which simulates different LiDAR scanning patterns by randomly dropping beams; 2) cross-frame ensembling, which exploits temporal consistency of consecutive frames to generate more reliable pseudo labels. Our method is simple, generalizable, and does not incur any extra inference cost. We evaluate our method on several public LiDAR datasets and show that it outperforms the state-of-the-art methods by more than $3.9\%$ mIoU on average for all scenarios. Code will be available at https://github.com/JHLee0513/LiDARUDA.
</details>
<details>
<summary>摘要</summary>
我们介绍了LiDAR-UDA，一种新的两阶段自我训练基于无监督领域适应（UDA）方法，用于LiDAR分割。现有的自我训练方法使用一个基于源数据的模型来生成目标数据的假标签，然后通过调整网络来提高预测。这些方法受到源和目标领域之间的频率差引起的频率差问题。我们提出了两种技术来减少探测器差异并提高假标签质量：1）LiDAR扫描方式抽样，可以模拟不同的LiDAR扫描方式，通过随机删除探测器来实现；2）同帧集成，可以利用连续帧的时间一致性来生成更可靠的假标签。我们的方法简单、普适，无需额外的推理成本。我们在一些公共LiDAR数据集上评估了我们的方法，并证明它在所有场景上超过了state-of-the-art方法的$3.9\%$ mIoU平均提升。代码将在https://github.com/JHLee0513/LiDARUDA上提供。
</details></li>
</ul>
<hr>
<h2 id="InSpaceType-Reconsider-Space-Type-in-Indoor-Monocular-Depth-Estimation"><a href="#InSpaceType-Reconsider-Space-Type-in-Indoor-Monocular-Depth-Estimation" class="headerlink" title="InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation"></a>InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13516">http://arxiv.org/abs/2309.13516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cho-Ying Wu, Quankai Gao, Chin-Cheng Hsu, Te-Lin Wu, Jing-Wen Chen, Ulrich Neumann</li>
<li>for: 本研究旨在探讨indoor monocular depth estimation方法在实际场景中的稳定性和泛化性，特别是在不同的空间类型下的表现。</li>
<li>methods: 本研究使用了11种最新的方法进行比较，并发现这些方法在不同的空间类型下存在明显的表现偏好。</li>
<li>results: 研究发现，现有的方法在不同的空间类型下存在明显的性能差异，表明这些方法存在偏好，而且在某些空间类型下表现非常差。<details>
<summary>Abstract</summary>
Indoor monocular depth estimation has attracted increasing research interest. Most previous works have been focusing on methodology, primarily experimenting with NYU-Depth-V2 (NYUv2) Dataset, and only concentrated on the overall performance over the test set. However, little is known regarding robustness and generalization when it comes to applying monocular depth estimation methods to real-world scenarios where highly varying and diverse functional \textit{space types} are present such as library or kitchen. A study for performance breakdown into space types is essential to realize a pretrained model's performance variance. To facilitate our investigation for robustness and address limitations of previous works, we collect InSpaceType, a high-quality and high-resolution RGBD dataset for general indoor environments. We benchmark 11 recent methods on InSpaceType and find they severely suffer from performance imbalance concerning space types, which reveals their underlying bias. We extend our analysis to 4 other datasets, 3 mitigation approaches, and the ability to generalize to unseen space types. Our work marks the first in-depth investigation of performance imbalance across space types for indoor monocular depth estimation, drawing attention to potential safety concerns for model deployment without considering space types, and further shedding light on potential ways to improve robustness. See \url{https://depthcomputation.github.io/DepthPublic} for data.
</details>
<details>
<summary>摘要</summary>
内部单目深度估计已经吸引了越来越多的研究兴趣。大多数前一些工作都是在方法ologies上进行了尝试，主要使用NYU-Depth-V2（NYUv2）数据集，并且只是对测试集的总性性能进行了评估。然而，对于实际世界场景中的应用，尚不甚了解单目深度估计方法的稳定性和泛化性。为了实现预训练模型的性能变化，我们需要进行空间类型的性能剖析。为了促进我们的调查和解决前一些工作的局限性，我们收集了InSpaceType，一个高质量、高分辨率的RGBD数据集，用于普遍的内部环境。我们对InSpaceType进行了11种最近的方法的测试，发现它们在不同的空间类型上表现出了严重的性能偏好。我们还扩展了我们的分析至4个其他数据集、3种缓解方法和无seen空间类型的能力。我们的工作是内部单目深度估计中首次对空间类型的性能偏好进行了深入的调查，这引起了关注在没有考虑空间类型的情况下部署模型可能存在的安全风险，以及如何提高模型的稳定性。参考链接：<https://depthcomputation.github.io/DepthPublic>。
</details></li>
</ul>
<hr>
<h2 id="Rewrite-Caption-Semantics-Bridging-Semantic-Gaps-for-Language-Supervised-Semantic-Segmentation"><a href="#Rewrite-Caption-Semantics-Bridging-Semantic-Gaps-for-Language-Supervised-Semantic-Segmentation" class="headerlink" title="Rewrite Caption Semantics: Bridging Semantic Gaps for Language-Supervised Semantic Segmentation"></a>Rewrite Caption Semantics: Bridging Semantic Gaps for Language-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13505">http://arxiv.org/abs/2309.13505</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xing0047/rewrite">https://github.com/xing0047/rewrite</a></li>
<li>paper_authors: Yun Xing, Jian Kang, Aoran Xiao, Jiahao Nie, Shao Ling, Shijian Lu</li>
<li>for: 增强语言授 зада务下的semantic segmentation的能力，使得图像可以通过文本描述进行空间localization。</li>
<li>methods: 利用CLIP来补做缺失的semantics，建立一个概念库，并通过群集导航 sampling来选择相关的概念，然后将其 feed into pre-training。</li>
<li>results: 在8个 segmentation benchmark上进行了广泛的实验，表明CoCu可以减轻语言授 зада务下的semantic gap，大幅提高语言授 зада务下的semantic segmentation的性能。<details>
<summary>Abstract</summary>
Vision-Language Pre-training has demonstrated its remarkable zero-shot recognition ability and potential to learn generalizable visual representations from language supervision. Taking a step ahead, language-supervised semantic segmentation enables spatial localization of textual inputs by learning pixel grouping solely from image-text pairs. Nevertheless, the state-of-the-art suffers from clear semantic gaps between visual and textual modality: plenty of visual concepts appeared in images are missing in their paired captions. Such semantic misalignment circulates in pre-training, leading to inferior zero-shot performance in dense predictions due to insufficient visual concepts captured in textual representations. To close such semantic gap, we propose Concept Curation (CoCu), a pipeline that leverages CLIP to compensate for the missing semantics. For each image-text pair, we establish a concept archive that maintains potential visually-matched concepts with our proposed vision-driven expansion and text-to-vision-guided ranking. Relevant concepts can thus be identified via cluster-guided sampling and fed into pre-training, thereby bridging the gap between visual and textual semantics. Extensive experiments over a broad suite of 8 segmentation benchmarks show that CoCu achieves superb zero-shot transfer performance and greatly boosts language-supervised segmentation baseline by a large margin, suggesting the value of bridging semantic gap in pre-training data.
</details>
<details>
<summary>摘要</summary>
“视言预训示出了无需示例数据的惊人识别能力和可能学习通用的视觉表示。尝试一步前进，语言指导的semantic segmentation可以将文本输入的空间局部化，通过从图像和文本对的学习像素组合。然而，当前的状态艺术受到清晰的Semantic Gap问题困扰，即图像中的许多视觉概念没有在其关联的文本中出现。这种semantic misalignment在预训练中循环，导致零例预测中的稠密预测性能下降，因为预训练中的文本表示中缺失的视觉概念。为了填充这种semantic gap，我们提出了Concept Curation（CoCu）管线，它利用CLIP来补偿缺失的semantics。对每个图像和文本对，我们建立了一个concept archive，该archive保存了可能与图像匹配的视觉概念，我们提出的视力驱动扩展和文本驱动的排名。通过群组指导采样，可以从concept archive中提取相关的概念，并将其传递给预训练，从而bridging视觉和文本semantic之间的 gap。我们对8种 segmentation benchmark进行了广泛的实验，结果表明CoCu可以 achieve superb zero-shot transfer performance，并大幅提高语言指导 segmentation baseline，这表明bridging semantic gap在预训练数据中的价值。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/cs.CV_2023_09_24/" data-id="clpxp6c1r00kiee88hjui4y4q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/cs.AI_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T12:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/cs.AI_2023_09_24/">cs.AI - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="GHN-QAT-Training-Graph-Hypernetworks-to-Predict-Quantization-Robust-Parameters-of-Unseen-Limited-Precision-Neural-Networks"><a href="#GHN-QAT-Training-Graph-Hypernetworks-to-Predict-Quantization-Robust-Parameters-of-Unseen-Limited-Precision-Neural-Networks" class="headerlink" title="GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust Parameters of Unseen Limited Precision Neural Networks"></a>GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust Parameters of Unseen Limited Precision Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13773">http://arxiv.org/abs/2309.13773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stone Yun, Alexander Wong</li>
<li>for: 这 paper 的目的是研究 Graph Hypernetworks (GHN) 可以预测 CNN 架构中不同参数的值，并且在预测过程中减少了大量的优化迭代。</li>
<li>methods: 这 paper 使用 GHN 预测 CNN 架构中的参数，并且对预测结果进行了量化化。</li>
<li>results: 这 paper 的结果表明，通过在量化 aware 训练中使用 GHN 预测参数，可以提高量化后 CNN 的准确率，并且在一些情况下可以达到随机 initialization 的水平。<details>
<summary>Abstract</summary>
Graph Hypernetworks (GHN) can predict the parameters of varying unseen CNN architectures with surprisingly good accuracy at a fraction of the cost of iterative optimization. Following these successes, preliminary research has explored the use of GHNs to predict quantization-robust parameters for 8-bit and 4-bit quantized CNNs. However, this early work leveraged full-precision float32 training and only quantized for testing. We explore the impact of quantization-aware training and/or other quantization-based training strategies on quantized robustness and performance of GHN predicted parameters for low-precision CNNs. We show that quantization-aware training can significantly improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs and even lead to greater-than-random accuracy for 2-bit quantized CNNs. These promising results open the door for future explorations such as investigating the use of GHN predicted parameters as initialization for further quantized training of individual CNNs, further exploration of "extreme bitwidth" quantization, and mixed precision quantization schemes.
</details>
<details>
<summary>摘要</summary>
格子嵌入网络（GHN）可以预测未seen convolutional neural network（CNN）的参数， surprisingly good accuracy at a fraction of the cost of iterative optimization. Following these successes, preliminary research has explored the use of GHNs to predict quantization-robust parameters for 8-bit and 4-bit quantized CNNs. However, this early work leveraged full-precision float32 training and only quantized for testing. We explore the impact of quantization-aware training and/or other quantization-based training strategies on quantized robustness and performance of GHN predicted parameters for low-precision CNNs. We show that quantization-aware training can significantly improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs and even lead to greater-than-random accuracy for 2-bit quantized CNNs. These promising results open the door for future explorations such as investigating the use of GHN predicted parameters as initialization for further quantized training of individual CNNs, further exploration of "extreme bitwidth" quantization, and mixed precision quantization schemes.Here's the text with the Chinese characters and English translation:格子嵌入网络（GHN）可以预测未seen convolutional neural network（CNN）的参数， surprisingly good accuracy at a fraction of the cost of iterative optimization.following these successes, preliminary research has explored the use of GHNs to predict quantization-robust parameters for 8-bit and 4-bit quantized CNNs.However, this early work leveraged full-precision float32 training and only quantized for testing.We explore the impact of quantization-aware training and/or other quantization-based training strategies on quantized robustness and performance of GHN predicted parameters for low-precision CNNs.We show that quantization-aware training can significantly improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs and even lead to greater-than-random accuracy for 2-bit quantized CNNs.These promising results open the door for future explorations such as investigating the use of GHN predicted parameters as initialization for further quantized training of individual CNNs, further exploration of "extreme bitwidth" quantization, and mixed precision quantization schemes.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Connector-Detection-for-Robotized-Assembly-of-Automotive-Wire-Harnesses"><a href="#Deep-Learning-Based-Connector-Detection-for-Robotized-Assembly-of-Automotive-Wire-Harnesses" class="headerlink" title="Deep Learning-Based Connector Detection for Robotized Assembly of Automotive Wire Harnesses"></a>Deep Learning-Based Connector Detection for Robotized Assembly of Automotive Wire Harnesses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13746">http://arxiv.org/abs/2309.13746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wang, Björn Johansson</li>
<li>for: 本研究旨在提高自动化汽车电子零部件的质量，通过深度学习方法探测汽车电缆套件中的连接器。</li>
<li>methods: 本研究使用了两种对象检测模型，一种是两stage模型，另一种是一stage模型，以 trains和评估数据集来检测汽车电缆套件中的连接器。</li>
<li>results: 实验结果表明，深度学习方法可以有效检测汽车电缆套件中的连接器，但连接器外部设计有限制。<details>
<summary>Abstract</summary>
The shift towards electrification and autonomous driving in the automotive industry results in more and more automotive wire harnesses being installed in modern automobiles, which stresses the great significance of guaranteeing the quality of automotive wire harness assembly. The mating of connectors is essential in the final assembly of automotive wire harnesses due to the importance of connectors on wire harness connection and signal transmission. However, the current manual operation of mating connectors leads to severe problems regarding assembly quality and ergonomics, where the robotized assembly has been considered, and different vision-based solutions have been proposed to facilitate a better perception of the robot control system on connectors. Nonetheless, there has been a lack of deep learning-based solutions for detecting automotive wire harness connectors in previous literature. This paper presents a deep learning-based connector detection for robotized automotive wire harness assembly. A dataset of twenty automotive wire harness connectors was created to train and evaluate a two-stage and a one-stage object detection model, respectively. The experiment results indicate the effectiveness of deep learning-based connector detection for automotive wire harness assembly but are limited by the design of the exteriors of connectors.
</details>
<details>
<summary>摘要</summary>
随着汽车业的电动化和自动驾驶技术的发展，现代汽车中的电动线套件越来越多，因此保证汽车电动线套件的质量变得非常重要。连接器的匹配在汽车电动线套件的最终组装中是非常重要的，因为连接器对电动线套件的连接和信号传输具有非常重要的作用。然而，现有的手动操作匹配连接器会导致组装质量和人机工程学习的严重问题，而Robotized assembly受到了考虑，不同的视觉基于解决方案也被提出，但在过去的文献中没有深入学习基于解决方案。本文提出了深入学习基于的汽车电动线套件连接器检测方法，并创建了20个汽车电动线套件连接器的数据集来训练和评估两个阶段和一个阶段对象检测模型。实验结果表明深入学习基于的连接器检测方法在汽车电动线套件组装中是有效的，但由于连接器的外部设计，其限制了检测的精度。
</details></li>
</ul>
<hr>
<h2 id="Computer-Vision-Technology-for-Robotized-Wire-Harness-Assembly"><a href="#Computer-Vision-Technology-for-Robotized-Wire-Harness-Assembly" class="headerlink" title="Computer Vision Technology for Robotized Wire Harness Assembly"></a>Computer Vision Technology for Robotized Wire Harness Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13745">http://arxiv.org/abs/2309.13745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wang, Omkar Salunkhe, Walter Quadrini, Dan Lämkull, Fredrik Ore, Björn Johansson, Johan Stahre</li>
<li>for: 本研究旨在提高汽车电子系统的绝缘电缆组装质量、效率和人机交互性，满足现代汽车电子系统的需求。</li>
<li>methods: 本研究使用计算机视觉技术来自动化绝缘电缆组装，以提高抗压缩性和抗摩擦性，并且可以在实际生产环境中实现自动化组装。</li>
<li>results: 本研究发现，计算机视觉技术可以帮助机器人更好地识别和操纵绝缘电缆，提高自动化组装的精度和效率。但是，还有一些研究 gap 需要进一步研究，以便在实际生产环境中实现更加实用的机器人自动化组装。<details>
<summary>Abstract</summary>
Wire harnesses are essential hardware for electronic systems in modern automotive vehicles. With a shift in the automotive industry towards electrification and autonomous driving, more and more automotive electronics are responsible for energy transmission and safety-critical functions such as maneuvering, driver assistance, and safety system. This paradigm shift places more demand on automotive wiring harnesses from the safety perspective and stresses the greater importance of high-quality wire harness assembly in vehicles. However, most of the current operations of wire harness assembly are still performed manually by skilled workers, and some of the manual processes are problematic from different perspectives, such as quality control and ergonomics. There is also a persistent demand in the industry to increase competitiveness and gain market share. Hence, assuring assembly quality while improving ergonomics and optimizing labor costs is desired. Robotized assembly, accomplished by robots or in human-robot collaboration, is a key enabler for fulfilling the increasingly demanding quality and safety as it enables more replicable, transparent, and comprehensible processes than completely manual operations. However, robotized assembly of wire harnesses is challenging in real environments due to the flexibility of the deformable objects, though many preliminary automation solutions have been proposed under simplified industrial configurations. Previous research efforts have proposed the use of computer vision technology to facilitate robotized automation of wire harness assembly, enabling the robots to better perceive and manipulate the flexible wire harness. This article presents an overview on computer vision technology proposed for robotized wire harness assembly and derives research gaps that require further study to facilitate a more practical robotized assembly of wire harness.
</details>
<details>
<summary>摘要</summary>
电子系统在现代汽车中的重要硬件是电缆集成。随着汽车工业向电气化和自动驾驶转变，电缆集成的重要性日益增加，它们不仅承担了能量传输，还承担了安全关键功能，如行驶助手、驾驶员助手和安全系统。这种平台转移增加了电缆集成的安全要求，同时也增加了对高质量电缆组装的需求。然而，大多数现有的电缆组装过程仍然是手动完成的，有些手动过程存在质量控制和人体工程学问题。此外，业界也有强烈的竞争和市场份额增长的需求。因此，保证组装质量的同时，改善人体工程学和优化劳动成本是需要的。 robotized assembly，通过机器人或人机合作，是实现提高质量和安全性的关键。然而，在真实环境中，机器人化电缆组装具有较大的挑战，主要是因为电缆是可变形的物体。虽然有许多先前的自动化解决方案在 simplifies 的工业配置下得到了应用，但是在真实环境中，这些解决方案很难实现。以前的研究努力已经提出了利用计算机视觉技术来实现机器人化电缆组装，使机器人可以更好地感知和操纵 flexible 的电缆。本文提供了计算机视觉技术在机器人化电缆组装中的概述，并确定了需要进一步研究的研究漏洞，以便更好地实现实用的机器人化电缆组装。
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Literature-Review-of-Computer-Vision-Applications-in-Robotized-Wire-Harness-Assembly"><a href="#A-Systematic-Literature-Review-of-Computer-Vision-Applications-in-Robotized-Wire-Harness-Assembly" class="headerlink" title="A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly"></a>A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13744">http://arxiv.org/abs/2309.13744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wang, Omkar Salunkhe, Walter Quadrini, Björn Johansson, Dan Lämkull, Fredrik Ore, Mélanie Despeisse, Luca Fumagalli, Johan Stahre</li>
<li>for: 这篇论文探讨了计算机视觉技术在机器人化电缆组装中的应用，挑战现有研究所出现的挑战，并提出未来研究的机遇以促进实用的机器人化电缆组装。</li>
<li>methods: 该论文采用了系统性的文献综述方法，检索了目前关于计算机视觉在机器人化电缆组装中的应用研究。</li>
<li>results: 该论文总结了现有研究中的挑战和未来研究的机遇，以促进实用的机器人化电缆组装。<details>
<summary>Abstract</summary>
This article presents a systematic literature review on computer vision applications that have been proposed for robotized wire harness assembly, derives challenges from existing studies, and identifies opportunities for future research to promote a more practical robotized assembly of wire harnesses.
</details>
<details>
<summary>摘要</summary>
这篇文章提出了一项系统性文献复查，探讨了计算机视觉技术在机器人化电缆组装中的应用，从现有研究中提取了挑战，并标识了未来研究的机遇，以促进更实用的机器人化电缆组装。Here's a breakdown of the translation:* "这篇文章" (zhè běn wén zhāng) - This article* "提出了一项" (tí shū le yī jiāng) - Proposes a systematic review* "系统性文献复查" (xì tǒng xìng běn bǎo) - Systematic literature review* "探讨了计算机视觉技术" (tàng shuō le jì shù zhì yè jì) - Explores computer vision technology* "在机器人化电缆组装中" (zhī zhì hóu diàn zhè bù zào) - In robotized wire harness assembly* "提取了挑战" (tí qū le bào zhèng) - Identifies challenges* "并标识了未来研究的机遇" (yuè yì le wèi lǎi yán jí de jī hǎng) - And identifies opportunities for future research* "以促进更实用的机器人化电缆组装" (yǐn jí yī jì zhèng zhì de jī zhì hóu diàn zhè bù zào) - To promote more practical robotized assembly of wire harnesses.
</details></li>
</ul>
<hr>
<h2 id="Use-of-Large-Language-Models-for-Stance-Classification"><a href="#Use-of-Large-Language-Models-for-Stance-Classification" class="headerlink" title="Use of Large Language Models for Stance Classification"></a>Use of Large Language Models for Stance Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13734">http://arxiv.org/abs/2309.13734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iain J. Cruickshank, Lynnette Hui Xian Ng</li>
<li>for: 本研究旨在探讨大型自然语言模型（LLM）在立场分类任务中的表现，以减少人工标注的使用。</li>
<li>methods: 我们使用四种不同的提问方案与LLM进行比较，以确定它们在不同的数据集中的精度。</li>
<li>results: 我们发现，虽然LLM可以与指导模型匹配或者超越它们的结果，但全局的精度并不是准确的。这表明LLM在立场分类方面还有一定的改进空间。然而，通过使用LLM，我们可以实现无监督的立场检测，从而降低人工标注的需求，并拓宽语言之间的应用范围。<details>
<summary>Abstract</summary>
Stance detection, the task of predicting an author's viewpoint towards a subject of interest, has long been a focal point of research. Current stance detection methods predominantly rely on manual annotation of sentences, followed by training a supervised machine learning model. This manual annotation process, however, imposes limitations on the model's ability to fully comprehend the stances in the sentence and hampers its potential to generalize across different contexts. In this study, we investigate the use of Large Language Models (LLMs) for the task of stance classification, with an absolute minimum use of human labels. We scrutinize four distinct types of prompting schemes combined with LLMs, comparing their accuracies with manual stance determination. Our study reveals that while LLMs can match or sometimes even exceed the benchmark results in each dataset, their overall accuracy is not definitively better than what can be produced by supervised models. This suggests potential areas for improvement in the stance classification for LLMs. The application of LLMs, however, opens up promising avenues for unsupervised stance detection, thereby curtailing the need for manual collection and annotation of stances. This not only streamlines the process but also paves the way for expanding stance detection capabilities across languages. Through this paper, we shed light on the stance classification abilities of LLMs, thereby contributing valuable insights that can guide future advancements in this domain.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>作者视点推断任务，长期是研究的焦点。当前的作者视点推断方法主要依靠手动标注句子，然后训练一个超级vised机器学习模型。然而，这个手动标注过程限制了模型对句子中作者视点的全面理解，使得其在不同上下文中的泛化能力受到限制。在本研究中，我们调查使用大型自然语言模型（LLM）进行作者视点分类任务，具有最小的人工标注使用。我们比较了四种不同的激励方案与LLMs的精度，并与手动决定作者视点的结果进行比较。我们的研究发现，虽然LLMs可以与或超过每个数据集的标准结果，但总的来说，它们的精度不是definitive更好于supervised模型。这表明了LLMs的作者视点分类方面可能存在改进的potential。不过，通过LLMs的应用，可以实现不需要手动收集和标注作者视点的不超级vised推断，这不仅简化了过程，还为推断语言的扩展开辟了道路。通过这篇论文，我们为LLMs的作者视点分类能力提供了有价值的反馈，以帮助未来在这个领域的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Arabic-Sentiment-Analysis-with-Noisy-Deep-Explainable-Model"><a href="#Arabic-Sentiment-Analysis-with-Noisy-Deep-Explainable-Model" class="headerlink" title="Arabic Sentiment Analysis with Noisy Deep Explainable Model"></a>Arabic Sentiment Analysis with Noisy Deep Explainable Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13731">http://arxiv.org/abs/2309.13731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Atabuzzaman, Md Shajalal, Maksuda Bilkis Baby, Alexander Boden</li>
<li>for: 本研究旨在提出一种可解释的情感分类框架，以解决现有的阿拉伯语情感分类模型中的黑盒问题。</li>
<li>methods: 该框架基于加入噪声层的Bi-Directional Long Short-Term Memory（BiLSTM）和Convolutional Neural Networks（CNN）-BiLSTM模型，可以解释特定预测的原因。</li>
<li>results: 实验结果表明，在公共 benchmark 阿拉伯语情感分类数据集上，加入噪声层可以改善阿拉伯语情感分类的性能，并且我们的方法比一些已知的状态作准方法表现更好。此外，引入的解释性噪声层可以使模型更透明和可负责任，有助于普及AI enabled系统。<details>
<summary>Abstract</summary>
Sentiment Analysis (SA) is an indispensable task for many real-world applications. Compared to limited resourced languages (i.e., Arabic, Bengali), most of the research on SA are conducted for high resourced languages (i.e., English, Chinese). Moreover, the reasons behind any prediction of the Arabic sentiment analysis methods exploiting advanced artificial intelligence (AI)-based approaches are like black-box - quite difficult to understand. This paper proposes an explainable sentiment classification framework for the Arabic language by introducing a noise layer on Bi-Directional Long Short-Term Memory (BiLSTM) and Convolutional Neural Networks (CNN)-BiLSTM models that overcome over-fitting problem. The proposed framework can explain specific predictions by training a local surrogate explainable model to understand why a particular sentiment (positive or negative) is being predicted. We carried out experiments on public benchmark Arabic SA datasets. The results concluded that adding noise layers improves the performance in sentiment analysis for the Arabic language by reducing overfitting and our method outperformed some known state-of-the-art methods. In addition, the introduced explainability with noise layer could make the model more transparent and accountable and hence help adopting AI-enabled system in practice.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-using-Cough-for-Respiratory-Disease-Diagnosis-by-leveraging-Artificial-Intelligence-A-Survey"><a href="#Towards-using-Cough-for-Respiratory-Disease-Diagnosis-by-leveraging-Artificial-Intelligence-A-Survey" class="headerlink" title="Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence: A Survey"></a>Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14383">http://arxiv.org/abs/2309.14383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aneeqa Ijaz, Muhammad Nabeel, Usama Masood, Tahir Mahmood, Mydah Sajid Hashmi, Iryna Posokhova, Ali Rizwan, Ali Imran</li>
<li>For: The paper is written for medical experts and AI scientists to analyze the decisive role of AI&#x2F;ML in detecting and diagnosing respiratory diseases based on cough acoustics.* Methods: The paper uses a comprehensive review of the literature on cough-based AI algorithms to demonstrate the significance of AI&#x2F;ML in detecting the onset of specific respiratory diseases. The authors also investigate the mechanism of cough and the latent cough features of respiratory modalities, and analyze customized cough monitoring applications and their AI-powered recognition algorithms.* Results: The paper provides a detailed list of significant features for cough data-driven ML&#x2F;DL detection and preliminary diagnosis frameworks, and discusses challenges and future research directions to develop practical, robust, and ubiquitous solutions for respiratory disease prediction.Here is the format you requested:* For: 论文是为医疗专家和人工智能科学家分析AI&#x2F;ML在抑制呼吸疾病中的重要作用。* Methods: 论文使用综述文献来展示呼吸学AI算法在诊断特定呼吸疾病的开头的重要性。文章还研究呼吸机制和呼吸模式的潜在特征，以及个性化呼吸监测应用程序和其AI驱动的识别算法。* Results: 论文提供了呼吸数据驱动ML&#x2F;DL检测和初步诊断框架中的重要特征列表，并讨论了实用、 Robust、和通用解决方案的挑战和未来研究方向。<details>
<summary>Abstract</summary>
Cough acoustics contain multitudes of vital information about pathomorphological alterations in the respiratory system. Reliable and accurate detection of cough events by investigating the underlying cough latent features and disease diagnosis can play an indispensable role in revitalizing the healthcare practices. The recent application of Artificial Intelligence (AI) and advances of ubiquitous computing for respiratory disease prediction has created an auspicious trend and myriad of future possibilities in the medical domain. In particular, there is an expeditiously emerging trend of Machine learning (ML) and Deep Learning (DL)-based diagnostic algorithms exploiting cough signatures. The enormous body of literature on cough-based AI algorithms demonstrate that these models can play a significant role for detecting the onset of a specific respiratory disease. However, it is pertinent to collect the information from all relevant studies in an exhaustive manner for the medical experts and AI scientists to analyze the decisive role of AI/ML. This survey offers a comprehensive overview of the cough data-driven ML/DL detection and preliminary diagnosis frameworks, along with a detailed list of significant features. We investigate the mechanism that causes cough and the latent cough features of the respiratory modalities. We also analyze the customized cough monitoring application, and their AI-powered recognition algorithms. Challenges and prospective future research directions to develop practical, robust, and ubiquitous solutions are also discussed in detail.
</details>
<details>
<summary>摘要</summary>
咳嗽学包含多种重要信息，可以帮助诊断呼吸系统的疾病变化。通过检测咳嗽特征来进行精准的疾病诊断，可以在医疗实践中发挥关键作用。现在，人工智能（AI）和 ubique computing 在呼吸疾病预测方面的应用正在迅速发展，这在医学领域创造了一种潜在的未来可能性。尤其是在机器学习（ML）和深度学习（DL）方面，已经出现了一种以咳嗽特征为基础的诊断算法的迅速增长趋势。但是，为了全面了解这些研究的结果，需要对所有相关的研究进行总结，以便医学专家和 AI 科学家进行分析。本调查概述了基于咳嗽数据的 ML/DL 检测和先期诊断框架，以及相关的重要特征。我们研究咳嗽的机制和呼吸Modalities 中的潜在特征。我们还分析了自定义咳嗽监测应用程序，以及它们的 AI 驱动的识别算法。挑战和未来研究方向也在详细地讨论。
</details></li>
</ul>
<hr>
<h2 id="Agree-To-Disagree"><a href="#Agree-To-Disagree" class="headerlink" title="Agree To Disagree"></a>Agree To Disagree</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14382">http://arxiv.org/abs/2309.14382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mpagli/Agree-to-Disagree">https://github.com/mpagli/Agree-to-Disagree</a></li>
<li>paper_authors: Abhinav Raghuvanshi, Siddhesh Pawar, Anirudh Mittal</li>
<li>for: 这篇论文是为了提供一种自动解析和概括长文档中重要信息的机器学习方法。</li>
<li>methods: 该方法使用机器学习算法对长文档进行自动解析和概括，以提供用户友好的摘要。</li>
<li>results: 该方法可以帮助用户快速理解长文档中的重要信息，从而减少用户对各种服务协议和软件使用协议的审核时间。<details>
<summary>Abstract</summary>
How frequently do individuals thoroughly review terms and conditions before proceeding to register for a service, install software, or access a website? The majority of internet users do not engage in this practice. This trend is not surprising, given that terms and conditions typically consist of lengthy documents replete with intricate legal terminology and convoluted sentences. In this paper, we introduce a Machine Learning-powered approach designed to automatically parse and summarize critical information in a user-friendly manner. This technology focuses on distilling the pertinent details that users should contemplate before committing to an agreement.
</details>
<details>
<summary>摘要</summary>
有多少人在注册服务、安装软件或访问网站之前， thorougly review terms and conditions？大多数互联网用户不这样做。这种趋势并不奇怪，因为条款和条件通常是长长的文档，拥有复杂的法律术语和句子结构。在这篇论文中，我们介绍了一种基于机器学习的方法，可以自动解析和概括重要信息，以便用户在决定时更好地了解。这种技术将关键信息简化，以便用户更好地理解。
</details></li>
</ul>
<hr>
<h2 id="ORLA-Mobile-Manipulator-Based-Object-Rearrangement-with-Lazy-A"><a href="#ORLA-Mobile-Manipulator-Based-Object-Rearrangement-with-Lazy-A" class="headerlink" title="ORLA*: Mobile Manipulator-Based Object Rearrangement with Lazy A*"></a>ORLA*: Mobile Manipulator-Based Object Rearrangement with Lazy A*</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13707">http://arxiv.org/abs/2309.13707</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gaokai15/ORLA-Star">https://github.com/gaokai15/ORLA-Star</a></li>
<li>paper_authors: Kai Gao, Yan Ding, Shiqi Zhang, Jingjin Yu</li>
<li>for: 这个论文主要针对的是移动搅拌器（如搅拌桌或吃卤桌）中的物体重新排序问题，即如何选择合适的物体重新排序策略以实现最佳的物体重新排序结果。</li>
<li>methods: 该论文提出了一种名为ORLA<em>的算法，该算法利用延迟评估（lazy evaluation）技术，搜索一个高质量的物体捕获和放置顺序，考虑了机器人手部和机器人基础的运动。同时，ORLA</em>还支持多层次重新排序任务，使用机器学习来保证物体堆积稳定。</li>
<li>results: 通过对大量的 simulate和减少研究，authors confirm了ORLA*的效果，能够提供高质量的重新排序解决方案，并且可以达到全球最佳性。<details>
<summary>Abstract</summary>
Effectively performing object rearrangement is an essential skill for mobile manipulators, e.g., setting up a dinner table or organizing a desk. A key challenge in such problems is deciding an appropriate manipulation order for objects to effectively untangle dependencies between objects while considering the necessary motions for realizing the manipulations (e.g., pick and place). To our knowledge, computing time-optimal multi-object rearrangement solutions for mobile manipulators remains a largely untapped research direction. In this research, we propose ORLA*, which leverages delayed (lazy) evaluation in searching for a high-quality object pick and place sequence that considers both end-effector and mobile robot base travel. ORLA* also supports multi-layered rearrangement tasks considering pile stability using machine learning. Employing an optimal solver for finding temporary locations for displacing objects, ORLA* can achieve global optimality. Through extensive simulation and ablation study, we confirm the effectiveness of ORLA* delivering quality solutions for challenging rearrangement instances. Supplementary materials are available at: https://gaokai15.github.io/ORLA-Star/
</details>
<details>
<summary>摘要</summary>
通过有效地重新排序物品，移动抓取机器人可以具备更高效的操作能力，例如设置晚餐桌或整理办公桌面。一个主要挑战在这些问题中是决定合适的物品重新排序顺序，以便有效地解决物品之间的依赖关系，同时考虑必要的动作（如找取和放置）。根据我们所知，计算时间最优的多物品重新排序解决方案仍然是移动抓取机器人研究的一个未探讨的方向。在这个研究中，我们提出了ORLA*，它利用延迟（懒散）评估来搜索高质量的物品找取和放置顺序，考虑了执行器和移动机器人基础体的必要运动。ORLA*还支持多层次重新排序任务，使用机器学习来考虑积累稳定性。通过优质的临时解决方案找取物品的位置，ORLA*可以 дости到全球优化。通过广泛的 simulations和减少研究，我们证明了ORLA*在具有挑战性的重新排序任务中的效果。补充材料可以在以下链接中找到：https://gaokai15.github.io/ORLA-Star/
</details></li>
</ul>
<hr>
<h2 id="A-Neural-Guided-Dynamic-Symbolic-Network-for-Exploring-Mathematical-Expressions-from-Data"><a href="#A-Neural-Guided-Dynamic-Symbolic-Network-for-Exploring-Mathematical-Expressions-from-Data" class="headerlink" title="A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data"></a>A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical Expressions from Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13705">http://arxiv.org/abs/2309.13705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqiang Li, Weijun Li, Lina Yu, Min Wu, Jingyi Liu, Yanjie Li</li>
<li>for: 本研究的目的是提出一种新的神经网络引导的动态符号网络方法（DySymNet），用于实现数据探索的符号回归问题。</li>
<li>methods: 本方法使用一种新的网络结构，并通过优化这些结构来找到更适合数据的表达。这种方法不仅能够处理高维问题，还能够优化常数。</li>
<li>results: 根据广泛的数值实验表示，DySymNet方法可以达到现有方法的最佳性能水平，并且在噪音较高的情况下保持稳定性。<details>
<summary>Abstract</summary>
Symbolic regression (SR) is a powerful technique for discovering the underlying mathematical expressions from observed data. Inspired by the success of deep learning, recent efforts have focused on two categories for SR methods. One is using a neural network or genetic programming to search the expression tree directly. Although this has shown promising results, the large search space poses difficulties in learning constant factors and processing high-dimensional problems. Another approach is leveraging a transformer-based model training on synthetic data and offers advantages in inference speed. However, this method is limited to fixed small numbers of dimensions and may encounter inference problems when given data is out-of-distribution compared to the synthetic data. In this work, we propose DySymNet, a novel neural-guided Dynamic Symbolic Network for SR. Instead of searching for expressions within a large search space, we explore DySymNet with various structures and optimize them to identify expressions that better-fitting the data. With a topology structure like neural networks, DySymNet not only tackles the challenge of high-dimensional problems but also proves effective in optimizing constants. Based on extensive numerical experiments using low-dimensional public standard benchmarks and the well-known SRBench with more variables, our method achieves state-of-the-art performance in terms of fitting accuracy and robustness to noise.
</details>
<details>
<summary>摘要</summary>
Symbolic regression (SR) 是一种强大的技术，用于从观察数据中发现下面的数学表达。随着深度学习的成功， latest efforts have focused on two categories of SR methods. One is to use a neural network or genetic programming to search the expression tree directly. Although this has shown promising results, the large search space poses difficulties in learning constant factors and processing high-dimensional problems. Another approach is to leverage a transformer-based model training on synthetic data, which offers advantages in inference speed. However, this method is limited to fixed small numbers of dimensions and may encounter inference problems when given data is out-of-distribution compared to the synthetic data.在这个工作中，我们提出了 DySymNet，一种新的神经网络引导的动态 симвоlic Network for SR. Instead of searching for expressions within a large search space, we explore DySymNet with various structures and optimize them to identify expressions that better-fitting the data. With a topology structure like neural networks, DySymNet not only tackles the challenge of high-dimensional problems but also proves effective in optimizing constants. Based on extensive numerical experiments using low-dimensional public standard benchmarks and the well-known SRBench with more variables, our method achieves state-of-the-art performance in terms of fitting accuracy and robustness to noise.
</details></li>
</ul>
<hr>
<h2 id="Skill-Check-Some-Considerations-on-the-Evaluation-of-Gamemastering-Models-for-Role-playing-Games"><a href="#Skill-Check-Some-Considerations-on-the-Evaluation-of-Gamemastering-Models-for-Role-playing-Games" class="headerlink" title="Skill Check: Some Considerations on the Evaluation of Gamemastering Models for Role-playing Games"></a>Skill Check: Some Considerations on the Evaluation of Gamemastering Models for Role-playing Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13702">http://arxiv.org/abs/2309.13702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sgongora27/skill-check-gm-tests">https://github.com/sgongora27/skill-check-gm-tests</a></li>
<li>paper_authors: Santiago Góngora, Luis Chiruzzo, Gonzalo Méndez, Pablo Gervás</li>
<li>for: 这篇论文是关于用Interactive Storytelling和自然语言处理方法模型游戏主持人（GM）的。</li>
<li>methods: 这篇论文使用了三个测试类划分来评估这些对话系统，并用它们测试了ChatGPT、Bard和OpenAssistant三个简单的GM。</li>
<li>results: 根据测试结果，这三个对话系统在不同的情况下都能够表现出不同的能力和缺点。<details>
<summary>Abstract</summary>
In role-playing games a Game Master (GM) is the player in charge of the game, who must design the challenges the players face and narrate the outcomes of their actions. In this work we discuss some challenges to model GMs from an Interactive Storytelling and Natural Language Processing perspective. Following those challenges we propose three test categories to evaluate such dialogue systems, and we use them to test ChatGPT, Bard and OpenAssistant as out-of-the-box GMs.
</details>
<details>
<summary>摘要</summary>
在角色扮演游戏中，游戏主持人（GM）是游戏中的主要玩家，负责设计玩家面临的挑战和描述玩家行动的结果。在这项工作中，我们讨论了对GM的模型化从互动故事与自然语言处理的角度来面临一些挑战。随后，我们提出了三个测试类别来评估这些对话系统，并使用它们测试ChatGPT、Bard和OpenAssistant作为直接GM。
</details></li>
</ul>
<hr>
<h2 id="ALLURE-Auditing-and-Improving-LLM-based-Evaluation-of-Text-using-Iterative-In-Context-Learning"><a href="#ALLURE-Auditing-and-Improving-LLM-based-Evaluation-of-Text-using-Iterative-In-Context-Learning" class="headerlink" title="ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning"></a>ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13701">http://arxiv.org/abs/2309.13701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hosein Hasanbeig, Hiteshi Sharma, Leo Betthauser, Felipe Vieira Frujeri, Ida Momennejad</li>
<li>for:  This paper aims to improve the ability of large language models (LLMs) to evaluate text by auditing and refining their performance.</li>
<li>methods: The authors introduce a systematic approach called ALLURE, which involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator. The evaluator leverages in-context learning (ICL) to enhance and improve the robust evaluation of text by LLMs.</li>
<li>results: The authors demonstrate the effectiveness of ALLURE in improving the performance of the evaluator LLM, reducing reliance on human annotators in the evaluation process. They anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarization, education, and productivity.<details>
<summary>Abstract</summary>
From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarization, education, and and productivity.
</details>
<details>
<summary>摘要</summary>
从分发纸到摘要医疗文档，大型自然语言模型（LLM）在评估人类和AI生成的文本中越来越广泛使用。然而，尽管它们的应用非常广泛，LLM仍然会出现不同的失败模式，因此需要进行系统性的审核和改进。在这篇文章中，我们介绍了ALLURE，一个系统性的方法来审核和改进LLM的文本评估能力。ALLURE通过比较LLM生成的评估和标注数据进行比较，并逐步包含具有重要差异的例子进入评估器中，以利用内容学习（ICL）来提高和改进LLM评估文本的能力。透过这个迭代过程，我们可以提高评估器LLM的性能，最终减少人类标注员在评估过程中的依赖。我们预计ALLURE将能够应用于各种领域中的LLM应用，例如医疗摘要、教育和生产力。
</details></li>
</ul>
<hr>
<h2 id="Smart-OMVI-Obfuscated-Malware-Variant-Identification-using-a-novel-dataset"><a href="#Smart-OMVI-Obfuscated-Malware-Variant-Identification-using-a-novel-dataset" class="headerlink" title="Smart OMVI: Obfuscated Malware Variant Identification using a novel dataset"></a>Smart OMVI: Obfuscated Malware Variant Identification using a novel dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10670">http://arxiv.org/abs/2310.10670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suleman Qamar</li>
<li>for: 这个论文是为了提供一个更真实和代表性的病毒分析环境，以evaluate病毒分析技术的效果。</li>
<li>methods: 这个论文使用了多种传统机器学习算法，包括但不限于支持向量机(SVM)、随机森林(RF)和极大梯度提升(XGBOOST)等。</li>
<li>results: XGBOOST算法在这些算法中表现最佳，具有82%的准确率、88%的精度、80%的回归率和83%的F1分数。<details>
<summary>Abstract</summary>
Cybersecurity has become a significant issue in the digital era as a result of the growth in everyday computer use. Cybercriminals now engage in more than virus distribution and computer hacking. Cyberwarfare has developed as a result because it has become a threat to a nation's survival. Malware analysis serves as the first line of defence against an attack and is a significant component of cybercrime. Every day, malware attacks target a large number of computer users, businesses, and governmental agencies, causing billions of dollars in losses. Malware may evade multiple AV software with a very minor, cunning tweak made by its designers, despite the fact that security experts have a variety of tools at their disposal to identify it. To address this challenge, a new dataset called the Obfuscated Malware Dataset (OMD) has been developed. This dataset comprises 40 distinct malware families having 21924 samples, and it incorporates obfuscation techniques that mimic the strategies employed by malware creators to make their malware variations different from the original samples. The purpose of this dataset is to provide a more realistic and representative environment for evaluating the effectiveness of malware analysis techniques. Different conventional machine learning algorithms including but not limited to Support Vector Machine (SVM), Random Forrest (RF), Extreme Gradient Boosting (XGBOOST) etc are applied and contrasted. The results demonstrated that XGBoost outperformed the other algorithms, achieving an accuracy of f 82%, precision of 88%, recall of 80%, and an F1-Score of 83%.
</details>
<details>
<summary>摘要</summary>
在数字时代，cybersecurity已成为一项重要的问题，归功于日常计算机使用的增长。现在，黑客不仅限于散发病毒和黑客行为，而且开发了cyberwarfare，这成为了国家存亡的威胁。针对这种挑战，一个新的数据集called the Obfuscated Malware Dataset (OMD)已经开发出来。这个数据集包含40种不同的黑客家族，共21924个样本，并包含了黑客创造者们使用的混淆技术来使其黑客变体与原始样本不同。该数据集的目的是为了提供更加现实和代表的环境，以评估黑客分析技术的效果。在这个数据集上，不同的传统机器学习算法，包括但不限于支持向量机 (SVM)、Random Forrest (RF) 和极限梯度提升 (XGBOOST) 等，被应用并比较。结果表明，XGBOOST在这些算法中表现出了最高的效果，具有82%的准确率、88%的精度、80%的回归率和83%的F1得分。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Image-to-Image-Translation"><a href="#Deep-Reinforcement-Learning-for-Image-to-Image-Translation" class="headerlink" title="Deep Reinforcement Learning for Image-to-Image Translation"></a>Deep Reinforcement Learning for Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13672">http://arxiv.org/abs/2309.13672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Algolzw/SPAC-Deformable-Registration">https://github.com/Algolzw/SPAC-Deformable-Registration</a></li>
<li>paper_authors: Xin Wang, Ziwei Luo, Jing Hu, Chengming Feng, Shu Hu, Bin Zhu, Xi Wu, Siwei Lyu</li>
<li>for: 本研究旨在提出一种基于深度学习和强化学习的图像转换方法，以解决现有的图像转换方法在某些任务上存在困难和过拟合的问题。</li>
<li>methods: 本研究使用了深度学习和强化学习的方法，特别是在一个步骤基础上，通过简单的决策进程来逐步转换源图像到目标图像。此外，本研究还提出了一种新的元策略，可以在标准的actor-critic模型中处理高维连续状态和动作空间，并且可以使得actor生成更加可追踪的高维动作。</li>
<li>results: 实验结果表明，提出的RL-I2IT方法在面临高维连续动作空间问题时表现高效和稳定，并且可以在多个图像转换任务上达到高度的性能。<details>
<summary>Abstract</summary>
Most existing Image-to-Image Translation (I2IT) methods generate images in a single run of a deep learning (DL) model. However, designing such a single-step model is always challenging, requiring a huge number of parameters and easily falling into bad global minimums and overfitting. In this work, we reformulate I2IT as a step-wise decision-making problem via deep reinforcement learning (DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The key feature in the RL-I2IT framework is to decompose a monolithic learning process into small steps with a lightweight model to progressively transform a source image successively to a target image. Considering that it is challenging to handle high dimensional continuous state and action spaces in the conventional RL framework, we introduce meta policy with a new concept Plan to the standard Actor-Critic model, which is of a lower dimension than the original image and can facilitate the actor to generate a tractable high dimensional action. In the RL-I2IT framework, we also employ a task-specific auxiliary learning strategy to stabilize the training process and improve the performance of the corresponding task. Experiments on several I2IT tasks demonstrate the effectiveness and robustness of the proposed method when facing high-dimensional continuous action space problems.
</details>
<details>
<summary>摘要</summary>
大多数现有的图像到图像翻译（I2IT）方法都是通过深度学习（DL）模型在单次训练中生成图像。然而，设计这种单步模型总是困难，需要很多参数，容易落入坏的全局最优点和过拟合。在这种工作中，我们将I2IT重新划为一个步骤性决策问题，并提出了一个新的框架——RL-I2IT。RL-I2IT框架的关键特征在于将绘制学习过程中的庞大学习过程拆分成小步骤，使用轻量级模型逐步将源图像转换成目标图像。由于传统RL框架中高维连续状态和动作空间的处理是困难的，我们引入了一种新的概念——计划，并将其添加到标准actor-critic模型中。在RL-I2IT框架中，我们还使用了一种任务特有的辅助学习策略，以稳定训练过程并提高相应任务的性能。在几个I2IT任务上进行了实验，我们发现提议的方法在面临高维连续动作空间问题时表现得非常有效和稳定。
</details></li>
</ul>
<hr>
<h2 id="Survey-of-Social-Bias-in-Vision-Language-Models"><a href="#Survey-of-Social-Bias-in-Vision-Language-Models" class="headerlink" title="Survey of Social Bias in Vision-Language Models"></a>Survey of Social Bias in Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14381">http://arxiv.org/abs/2309.14381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Nayeon Lee, Yejin Bang, Holy Lovenia, Samuel Cahyawijaya, Wenliang Dai, Pascale Fung</li>
<li>for: 这篇论文旨在探讨预训练模型中存在的社会偏见问题，以及如何在多模态场景中减少这些偏见。</li>
<li>methods: 该论文采用了文献综述的方法，检查了不同领域中预训练模型中的社会偏见问题，并提出了一些应对方法。</li>
<li>results: 该论文发现了预训练模型在不同领域中的社会偏见问题，并提出了一些可能的解决方案，以帮助研究人员在多模态场景中开发更公正的人工智能模型。<details>
<summary>Abstract</summary>
In recent years, the rapid advancement of machine learning (ML) models, particularly transformer-based pre-trained models, has revolutionized Natural Language Processing (NLP) and Computer Vision (CV) fields. However, researchers have discovered that these models can inadvertently capture and reinforce social biases present in their training datasets, leading to potential social harms, such as uneven resource allocation and unfair representation of specific social groups. Addressing these biases and ensuring fairness in artificial intelligence (AI) systems has become a critical concern in the ML community.   The recent introduction of pre-trained vision-and-language (VL) models in the emerging multimodal field demands attention to the potential social biases present in these models as well. Although VL models are susceptible to social bias, there is a limited understanding compared to the extensive discussions on bias in NLP and CV. This survey aims to provide researchers with a high-level insight into the similarities and differences of social bias studies in pre-trained models across NLP, CV, and VL. By examining these perspectives, the survey aims to offer valuable guidelines on how to approach and mitigate social bias in both unimodal and multimodal settings. The findings and recommendations presented here can benefit the ML community, fostering the development of fairer and non-biased AI models in various applications and research endeavors.
</details>
<details>
<summary>摘要</summary>
近年来，机器学习（ML）模型的快速发展，特别是基于转换器的预训练模型，对自然语言处理（NLP）和计算机视觉（CV）领域产生了革命性的变革。然而，研究人员发现，这些模型可能会不意imento capture和激发社会偏见，从而导致社会不公正和特定社会群体的不公正代表。解决这些偏见并确保人工智能（AI）系统的公正性已成为ML社区的关键问题。随着emerging multimodal领域中的视觉语言（VL）模型的出现，需要对这些模型中的社会偏见进行关注。虽然VL模型受到社会偏见的影响，但相比NLP和CV领域，对于VL模型的社会偏见还有很 limited的理解。本调查旨在为研究人员提供高级别的社会偏见研究在预训练模型中的类似和不同之处，以及NLP、CV和VL领域中社会偏见的研究方法和措施。通过对这些观点进行分析，本调查期望为ML社区提供有价值的指南，以帮助开发更公正、不偏见的AI模型，并在不同的应用和研究领域中做出贡献。
</details></li>
</ul>
<hr>
<h2 id="VoiceLDM-Text-to-Speech-with-Environmental-Context"><a href="#VoiceLDM-Text-to-Speech-with-Environmental-Context" class="headerlink" title="VoiceLDM: Text-to-Speech with Environmental Context"></a>VoiceLDM: Text-to-Speech with Environmental Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13664">http://arxiv.org/abs/2309.13664</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/glory20h/VoiceLDM">https://github.com/glory20h/VoiceLDM</a></li>
<li>paper_authors: Yeonghyeon Lee, Inmo Yeon, Juhan Nam, Joon Son Chung</li>
<li>for: 这个论文旨在生成准确地遵循两个自然语言文本提示：描述提示和内容提示。描述提示提供环境上下文信息，而内容提示则传达语言内容。</li>
<li>methods: 作者采用基于潜在扩散模型的文本到音频（TTA）模型，并将其扩展以接受额外的内容提示作为条件输入。通过使用预训练的对比语言-音频预训练（CLAP）和Whisper，作者在大量实际音频数据上进行了训练。此外，作者还使用了无束分类器自由指导来进一步提高VoiceLDM的可控性。</li>
<li>results: 实验结果表明，VoiceLDM可以生成准确地遵循两个输入条件的音频，甚至在AudioCaps测试集上超越原始音频的语音可解度。此外，作者还探索了TTS和零shot TTA的能力，并证明VoiceLDM可以达到竞争力的结果。<details>
<summary>Abstract</summary>
This paper presents VoiceLDM, a model designed to produce audio that accurately follows two distinct natural language text prompts: the description prompt and the content prompt. The former provides information about the overall environmental context of the audio, while the latter conveys the linguistic content. To achieve this, we adopt a text-to-audio (TTA) model based on latent diffusion models and extend its functionality to incorporate an additional content prompt as a conditional input. By utilizing pretrained contrastive language-audio pretraining (CLAP) and Whisper, VoiceLDM is trained on large amounts of real-world audio without manual annotations or transcriptions. Additionally, we employ dual classifier-free guidance to further enhance the controllability of VoiceLDM. Experimental results demonstrate that VoiceLDM is capable of generating plausible audio that aligns well with both input conditions, even surpassing the speech intelligibility of the ground truth audio on the AudioCaps test set. Furthermore, we explore the text-to-speech (TTS) and zero-shot text-to-audio capabilities of VoiceLDM and show that it achieves competitive results. Demos and code are available at https://voiceldm.github.io.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Machine-assisted-mixed-methods-augmenting-humanities-and-social-sciences-with-artificial-intelligence"><a href="#Machine-assisted-mixed-methods-augmenting-humanities-and-social-sciences-with-artificial-intelligence" class="headerlink" title="Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence"></a>Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14379">http://arxiv.org/abs/2309.14379</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andreskarjus/machineassistedmixedmethods">https://github.com/andreskarjus/machineassistedmixedmethods</a></li>
<li>paper_authors: Andres Karjus</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）在人文社科领域中的应用潜力，以帮助论文作者在数据分析 tasks 上增强和自动化人工劳动。</li>
<li>methods: 该论文提出了一种系统的混合方法 Framework，包括机器可观测和人类专家的协同分析、数据量化和可重复性的考虑。16个机器助手实践案例被用作证明。</li>
<li>results: 该论文的结果表明，在大多数情况下，LLM可以成功地执行许多质量分析任务，包括语言和дискурス分析、 lexical semantic change detection、采访分析、历史事件 causa inference 和文本挖掘、政治立场探测、文本和想法再利用、文学和电影类型组合、社交网络推理和自动 lexicography。此外，论文还发现，在使用LLM时，需要考虑人类专家的知识和经验，以确保结果的准确性和可靠性。<details>
<summary>Abstract</summary>
The increasing capacities of large language models (LLMs) present an unprecedented opportunity to scale up data analytics in the humanities and social sciences, augmenting and automating qualitative analytic tasks previously typically allocated to human labor. This contribution proposes a systematic mixed methods framework to harness qualitative analytic expertise, machine scalability, and rigorous quantification, with attention to transparency and replicability. 16 machine-assisted case studies are showcased as proof of concept. Tasks include linguistic and discourse analysis, lexical semantic change detection, interview analysis, historical event cause inference and text mining, detection of political stance, text and idea reuse, genre composition in literature and film; social network inference, automated lexicography, missing metadata augmentation, and multimodal visual cultural analytics. In contrast to the focus on English in the emerging LLM applicability literature, many examples here deal with scenarios involving smaller languages and historical texts prone to digitization distortions. In all but the most difficult tasks requiring expert knowledge, generative LLMs can demonstrably serve as viable research instruments. LLM (and human) annotations may contain errors and variation, but the agreement rate can and should be accounted for in subsequent statistical modeling; a bootstrapping approach is discussed. The replications among the case studies illustrate how tasks previously requiring potentially months of team effort and complex computational pipelines, can now be accomplished by an LLM-assisted scholar in a fraction of the time. Importantly, this approach is not intended to replace, but to augment researcher knowledge and skills. With these opportunities in sight, qualitative expertise and the ability to pose insightful questions have arguably never been more critical.
</details>
<details>
<summary>摘要</summary>
LLMS 的增长 capacities 提供了无 precedent 的机会，以扩大人文社科领域的数据分析，通过机器执行和人工协助，自动化和加强质量分析任务，提高研究效率和准确性。本贡献提出了一种系统性的混合方法框架，结合人类专家知识和机器可扩展性，并强调透明度和复制性。这些案例中的 16 个机器助手案例作为证明。任务包括语言和 Diskourse 分析、lexical  semantics 变化检测、采访分析、历史事件 causality 推断和文本挖掘、政治立场推断、文本和意义 reuse、文学和电影种类作品 genre 组合、社交网络推断、自动 lexicography、缺失 metadata 扩充和多媒体视觉文化分析。与英语emerging LLMS 应用性文献中的焦点不同，这些例子中的大多数例子 involve 小语言和历史文献，这些文献可能会受到数字化改变的影响。除了最复杂的任务需要专家知识外，LLM 可以成功地服务为可靠的研究工具。LLM 和人类注解可能会包含错误和变化，但协调率可以并被考虑在后续统计模型中。这种方法不是替换研究者知识和技能，而是增强它们。这些机遇在视野中，专业知识和能够提出有价值的问题的能力 arguably  nunca 这样重要。
</details></li>
</ul>
<hr>
<h2 id="Embers-of-Autoregression-Understanding-Large-Language-Models-Through-the-Problem-They-are-Trained-to-Solve"><a href="#Embers-of-Autoregression-Understanding-Large-Language-Models-Through-the-Problem-They-are-Trained-to-Solve" class="headerlink" title="Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve"></a>Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13638">http://arxiv.org/abs/2309.13638</a></li>
<li>repo_url: None</li>
<li>paper_authors: R. Thomas McCoy, Shunyu Yao, Dan Friedman, Matthew Hardy, Thomas L. Griffiths</li>
<li>for: 本研究旨在理解大语言模型（LLM）的优劣点，并推广其应用。</li>
<li>methods: 本研究使用了teleological approach，即认为LLM在解决下一个单词预测任务时的压力，并预测LLM会采取什么策略。</li>
<li>results: 研究发现，LLM的准确率受任务执行概率、目标输出概率和输入提供概率的影响。在 deterministic 环境中，LLM 的准确率高于低概率情况下。此外，研究还发现了一些奇异的失败模式，如 GPT-4 在解码简单密码时的准确率为 51%，但只有 13% 在低概率情况下。这些结果表明，AI 专家应该在低概率情况下使用 LLB 时需要谨慎。<details>
<summary>Abstract</summary>
The widespread adoption of large language models (LLMs) makes it important to recognize their strengths and limitations. We argue that in order to develop a holistic understanding of these systems we need to consider the problem that they were trained to solve: next-word prediction over Internet text. By recognizing the pressures that this task exerts we can make predictions about the strategies that LLMs will adopt, allowing us to reason about when they will succeed or fail. This approach - which we call the teleological approach - leads us to identify three factors that we hypothesize will influence LLM accuracy: the probability of the task to be performed, the probability of the target output, and the probability of the provided input. We predict that LLMs will achieve higher accuracy when these probabilities are high than when they are low - even in deterministic settings where probability should not matter. To test our predictions, we evaluate two LLMs (GPT-3.5 and GPT-4) on eleven tasks, and we find robust evidence that LLMs are influenced by probability in the ways that we have hypothesized. In many cases, the experiments reveal surprising failure modes. For instance, GPT-4's accuracy at decoding a simple cipher is 51% when the output is a high-probability word sequence but only 13% when it is low-probability. These results show that AI practitioners should be careful about using LLMs in low-probability situations. More broadly, we conclude that we should not evaluate LLMs as if they are humans but should instead treat them as a distinct type of system - one that has been shaped by its own particular set of pressures.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（LLM）的广泛采用，我们必须认可它们的优势和局限性。我们认为，为了发展它们的整体理解，我们需要考虑它们被训练的问题：以互联网文本为基础的下一个词预测。通过认真对待这些任务的压力，我们可以预测LLM会采取什么策略，从而对它们的成功和失败进行预测。我们称这种方法为“teleological approach”。我们认为，LLM的准确率受以下三个因素的影响：任务执行概率、目标输出概率和输入提供的概率。我们预测，当这些概率高时，LLM的准确率也将高；而当它们低时，准确率则将低，即使在deterministic Setting中，概率应该没有影响。为测试我们的预测，我们评估了两个LLM（GPT-3.5和GPT-4）在11个任务上的表现，并发现了robust的证据，证明了我们的假设。在许多情况下，实验发现了意外的失败模式。例如，GPT-4在解码简单密码的任务中的准确率为51%，但只有13% когда输出是低概率的word sequence。这些结果表明，AI实践者应该小心使用LLM在低概率情况下。更广泛地说，我们 concludeThat we should not evaluate LLMs as if they were humans, but rather as a distinct type of system that has been shaped by its own unique set of pressures.
</details></li>
</ul>
<hr>
<h2 id="Development-of-an-intelligent-system-for-the-detection-of-corona-virus-using-artificial-neural-network"><a href="#Development-of-an-intelligent-system-for-the-detection-of-corona-virus-using-artificial-neural-network" class="headerlink" title="Development of an intelligent system for the detection of corona virus using artificial neural network"></a>Development of an intelligent system for the detection of corona virus using artificial neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13636">http://arxiv.org/abs/2309.13636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nwafor Emmanuel O, Ngozi Maryrose Umeh, Ikechukwu Ekene Onyenwe</li>
<li>for: 本研究目的是开发一个人工神经网络检测新冠肺炎的智能系统。</li>
<li>methods: 本研究使用了文献综述和683组高烧 Body temperature数据（&gt;&#x3D; 38℃），从尼日利亚埃努古大学医院搜集到，用于训练人工神经网络检测模型。</li>
<li>results: 模型的评估结果显示，混淆矩阵、回归和方差平方误差（MSE）都是0.967，准确率是97%，这些结果显示新检测系统是可靠且高效。<details>
<summary>Abstract</summary>
This paper presents the development of an intelligent system for the detection of coronavirus using artificial neural network. This was done after series of literature review which indicated that high fever accounts for 87.9% of the COVID-19 symptoms. 683 temperature data of COVID-19 patients at >= 38C^o were collected from Colliery hospital Enugu, Nigeria and used to train an artificial neural network detective model for the detection of COVID-19. The reference model generated was used converted into Verilog codes using Hardware Description Language (HDL) and then burn into a Field Programming Gate Array (FPGA) controller using FPGA tool in Matlab. The performance of the model when evaluated using confusion matrix, regression and means square error (MSE) showed that the regression value is 0.967; the accuracy is 97% and then MSE is 0.00100Mu. These results all implied that the new detection system for is reliable and very effective for the detection of COVID-19.
</details>
<details>
<summary>摘要</summary>
本文介绍了一种人工神经网络系统的开发，用于检测新型冠状病毒（COVID-19）。这种系统是基于文献评审结果，表明高热会质量上占87.9%的COVID-19症状。我们收集了来自尼日利亚埃努古采矿医院的683例COVID-19患者体温大于或等于38℃的数据，并使用人工神经网络探测模型进行训练。模型生成的参考模型被转化为Verilog代码使用硬件描述语言（HDL），然后使用MATLAB中的FPGA工具烧录到场程控制器中。模型的性能测试结果表明，准确率为97%，回归值为0.967，平均方差为0.00100Mu。这些结果表明新检测系统具有可靠性和高效性，适用于COVID-19检测。
</details></li>
</ul>
<hr>
<h2 id="PanopticNDT-Efficient-and-Robust-Panoptic-Mapping"><a href="#PanopticNDT-Efficient-and-Robust-Panoptic-Mapping" class="headerlink" title="PanopticNDT: Efficient and Robust Panoptic Mapping"></a>PanopticNDT: Efficient and Robust Panoptic Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13635">http://arxiv.org/abs/2309.13635</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tui-nicr/panoptic-mapping">https://github.com/tui-nicr/panoptic-mapping</a></li>
<li>paper_authors: Daniel Seichter, Benedict Stephan, Söhnke Benedikt Fischedick, Steffen Müller, Leonard Rabes, Horst-Michael Gross</li>
<li>for: 本研究旨在提供高精度3D精细地图，以便移动机器人在室内环境中自动操作。</li>
<li>methods: 本文提出了一种基于占用normal distribution transform（NDT）地图的有效和可靠的精细地图方法，名为PanopticNDT。</li>
<li>results: 对于公共可用的Hypersim和ScanNetV2数据集，our approach可以在移动机器人上实现高级别的精细地图，并且在实时精细地图中表达精细信息。此外，我们还证明了PanopticNDT在实际应用中的可行性。<details>
<summary>Abstract</summary>
As the application scenarios of mobile robots are getting more complex and challenging, scene understanding becomes increasingly crucial. A mobile robot that is supposed to operate autonomously in indoor environments must have precise knowledge about what objects are present, where they are, what their spatial extent is, and how they can be reached; i.e., information about free space is also crucial. Panoptic mapping is a powerful instrument providing such information. However, building 3D panoptic maps with high spatial resolution is challenging on mobile robots, given their limited computing capabilities. In this paper, we propose PanopticNDT - an efficient and robust panoptic mapping approach based on occupancy normal distribution transform (NDT) mapping. We evaluate our approach on the publicly available datasets Hypersim and ScanNetV2. The results reveal that our approach can represent panoptic information at a higher level of detail than other state-of-the-art approaches while enabling real-time panoptic mapping on mobile robots. Finally, we prove the real-world applicability of PanopticNDT with qualitative results in a domestic application.
</details>
<details>
<summary>摘要</summary>
Note:* "application scenarios" is translated as "应用场景" (yìng yìng jīng xìng)* "mobile robots" is translated as "移动机器人" (í mouth jī hū rén)* "scene understanding" is translated as "场景理解" (chǎng jǐng lǐ jiě)* "panoptic mapping" is translated as "批量地图" (pīn liàng dì tú)* "occupancy normal distribution transform" is translated as "占据正态分布变换" (zhāng yù zhèng tài fāng zhāng biàn huà)* "real-time panoptic mapping" is translated as "实时批量地图" (shí shí pīn liàng dì tú)* "domestic application" is translated as "家庭应用" (jiā tíng yìng yòu)
</details></li>
</ul>
<hr>
<h2 id="EvalLM-Interactive-Evaluation-of-Large-Language-Model-Prompts-on-User-Defined-Criteria"><a href="#EvalLM-Interactive-Evaluation-of-Large-Language-Model-Prompts-on-User-Defined-Criteria" class="headerlink" title="EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria"></a>EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13633">http://arxiv.org/abs/2309.13633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, Juho Kim</li>
<li>for: 本研究旨在帮助开发人员通过使用大语言模型（LLM）创造新的生成应用程序，并通过多次修改提示来优化这些应用程序。</li>
<li>methods: 本研究使用了大语言模型（LLM）来评估提示的多个输出，以 помочь开发人员评估Context-specific和主观标准。</li>
<li>results: 对比手动评估，使用EvalLM系统可以帮助开发人员更快速地COMPOSE更多样化的提示，并且需要59% fewer revisions来达到满意的提示。<details>
<summary>Abstract</summary>
By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts.
</details>
<details>
<summary>摘要</summary>
通过简单地编写提示，开发者可以快速探索新的生成应用程序，使用大型自然语言模型（LLM）。但是，要将原型转化为产品，开发者需要不断修改提示，以评估输出的弱点。我们的研究发现，开发者在评估输出时投入了大量的时间和劳动，以评估Context-specific和主观的标准。我们提出了EvalLM，一个互动式系统，可以通过用户定义的标准来评估多个输出，并提供LLM-based评估器的反馈。通过自然语言描述标准，用户可以使用系统来评估输出的excel和不足，并根据评估器的反馈进行改进。我们的比较研究显示，EvalLM，相比于手动评估，帮助参与者编写更多样的标准，评估twice as many outputs，并在59% fewer revisions中得到满意的提示。此外，我们的工作可以扩展到增强特定应用场景中的模型评估和对齐。
</details></li>
</ul>
<hr>
<h2 id="A-Multi-channel-EEG-Data-Analysis-for-Poor-Neuro-prognostication-in-Comatose-Patients-with-Self-and-Cross-channel-Attention-Mechanism"><a href="#A-Multi-channel-EEG-Data-Analysis-for-Poor-Neuro-prognostication-in-Comatose-Patients-with-Self-and-Cross-channel-Attention-Mechanism" class="headerlink" title="A Multi-channel EEG Data Analysis for Poor Neuro-prognostication in Comatose Patients with Self and Cross-channel Attention Mechanism"></a>A Multi-channel EEG Data Analysis for Poor Neuro-prognostication in Comatose Patients with Self and Cross-channel Attention Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03756">http://arxiv.org/abs/2310.03756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hemin Ali Qadir, Naimahmed Nesaragi, Per Steiner Halvorsen, Ilangko Balasingham</li>
<li>for: 这个研究旨在利用双极电enzephalogram（EEG）记录来有效预测中枢神经系统疾病的不良结果。</li>
<li>methods: 该研究采用了混合深度学习方法，包括特征编码器、学习位编码、 context网络、注意机制和回归和分类块，以优化一个目标函数，即高特异性（true positive rate，TPR）和降低假阳性（&lt;0.05）。</li>
<li>results: 该研究的提出的框架，OUS IVS，在隐藏验证数据上验证后，得分为0.57。<details>
<summary>Abstract</summary>
This work investigates the predictive potential of bipolar electroencephalogram (EEG) recordings towards efficient prediction of poor neurological outcomes. A retrospective design using a hybrid deep learning approach is utilized to optimize an objective function aiming for high specificity, i.e., true positive rate (TPR) with reduced false positives (< 0.05). A multi-channel EEG array of 18 bipolar channel pairs from a randomly selected 5-minute segment in an hour is kept. In order to determine the outcome prediction, a combination of a feature encoder with 1-D convolutional layers, learnable position encoding, a context network with attention mechanisms, and finally, a regressor and classifier blocks are used. The feature encoder extricates local temporal and spatial features, while the following position encoding and attention mechanisms attempt to capture global temporal dependencies. Results: The proposed framework by our team, OUS IVS, when validated on the challenge hidden validation data, exhibited a score of 0.57.
</details>
<details>
<summary>摘要</summary>
这项研究探讨了使用双极电энце法记录（EEG）的预测潜在性，以提高不良神经学结果的预测精度。我们采用了混合深度学习方法，以优化一个目标函数，即高准确率（TPR），同时减少假阳性（<0.05）。我们使用的EEG数据包括18对双极通道，从一个随机选择的1小时内的5分钟段中选择。为了确定结果预测，我们使用了特征编码器、学习位编码、 Context网络和注意机制、以及最后的回归和分类块。特征编码器提取了本地时间和空间特征，而后续的位编码和注意机制尝试了捕捉全局时间相关性。结果：我们团队的提案方框，OUS IVS，在挑战隐藏验证数据上验证时达到了0.57分的得分。
</details></li>
</ul>
<hr>
<h2 id="GraphAdapter-Tuning-Vision-Language-Models-With-Dual-Knowledge-Graph"><a href="#GraphAdapter-Tuning-Vision-Language-Models-With-Dual-Knowledge-Graph" class="headerlink" title="GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph"></a>GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13625">http://arxiv.org/abs/2309.13625</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lixinustc/graphadapter">https://github.com/lixinustc/graphadapter</a></li>
<li>paper_authors: Xin Li, Dongze Lian, Zhihe Lu, Jiawang Bai, Zhibo Chen, Xinchao Wang</li>
<li>for: 提高vision-language模型（VLM）在低数据 régime下的表现，通过引入一些额外参数来挖掘任务特定的知识。</li>
<li>methods: 提出一种效果的 adapter-style tuning策略，名为GraphAdapter，它通过显式地模型两 modalities的结构知识来进一步提高文本特化器的表现。</li>
<li>results: 对11个标准 benchmark dataset进行了广泛的实验，并证明了 GraphAdapter 在前一个 adapter-based 方法之上具有显著的优势。<details>
<summary>Abstract</summary>
Adapter-style efficient transfer learning (ETL) has shown excellent performance in the tuning of vision-language models (VLMs) under the low-data regime, where only a few additional parameters are introduced to excavate the task-specific knowledge based on the general and powerful representation of VLMs. However, most adapter-style works face two limitations: (i) modeling task-specific knowledge with a single modality only; and (ii) overlooking the exploitation of the inter-class relationships in downstream tasks, thereby leading to sub-optimal solutions. To mitigate that, we propose an effective adapter-style tuning strategy, dubbed GraphAdapter, which performs the textual adapter by explicitly modeling the dual-modality structure knowledge (i.e., the correlation of different semantics/classes in textual and visual modalities) with a dual knowledge graph. In particular, the dual knowledge graph is established with two sub-graphs, i.e., a textual knowledge sub-graph, and a visual knowledge sub-graph, where the nodes and edges represent the semantics/classes and their correlations in two modalities, respectively. This enables the textual feature of each prompt to leverage the task-specific structure knowledge from both textual and visual modalities, yielding a more effective classifier for downstream tasks. Extensive experimental results on 11 benchmark datasets reveal that our GraphAdapter significantly outperforms previous adapter-based methods. The code will be released at https://github.com/lixinustc/GraphAdapter
</details>
<details>
<summary>摘要</summary>
adapter-style 高效传输学习（ETL）在视力语模型（VLM）的调整下表现出色，特别是在低数据条件下，只需要引入一些附加参数来挖掘任务特定知识基于通用和强大的 VLM 表示。然而，大多数 adapter-style 工作面临两个限制：（i）只使用单一模式来odel任务特定知识；（ii）忽略下游任务中间类关系的利用，导致优化解决方案。为了缓解这些问题，我们提出了一种有效的 adapter-style 调整策略，名为图像 adapter，它通过显式地模型两种模式之间的 dual-modality 结构知识（即文本和视觉模式之间的各种 semantics/classes 的相关性），使得文本特征可以从两种模式中获得任务特定的结构知识，从而更有效地进行下游任务。具体来说，我们建立了两个子图，即文本知识子图和视觉知识子图，其中节点和边表示两种模式中的 semantics/classes 和 их相关性。这使得文本特征可以从两种模式中获得任务特定的结构知识，从而更有效地进行下游任务。我们的 GraphAdapter 在 11 个 benchmark 数据集上进行了广泛的实验，结果显示，我们的 GraphAdapter 明显超越了前一代 adapter-based 方法。代码将在 https://github.com/lixinustc/GraphAdapter 上发布。
</details></li>
</ul>
<hr>
<h2 id="PRIS-Practical-robust-invertible-network-for-image-steganography"><a href="#PRIS-Practical-robust-invertible-network-for-image-steganography" class="headerlink" title="PRIS: Practical robust invertible network for image steganography"></a>PRIS: Practical robust invertible network for image steganography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13620">http://arxiv.org/abs/2309.13620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanghangai/pris">https://github.com/yanghangai/pris</a></li>
<li>paper_authors: Hang Yang, Yitian Xu, Xuhua Liu, Xiaodong Ma<br>for:PRIS is designed to improve the robustness of image steganography against distortion such as Gaussian noise and lossy compression.methods:PRIS uses invertible neural networks and two enhance modules before and after the extraction process, with a 3-step training strategy. It also considers rounding error, which is typically ignored by other methods, and proposes a gradient approximation function (GAF) to overcome the undifferentiable issue of rounding distortion.results:Experimental results show that PRIS outperforms state-of-the-art robust image steganography methods in both robustness and practicability.Here is the simplified Chinese text for the three key points:for:PRIS 是为了提高图像隐藏技术的鲁棒性，对容器图像受到的扰动（如 Gaussian 噪声和产生损失）进行鲁棒性测试。methods:PRIS 使用 invertible 神经网络，并在提取过程中添加了两个增强模块，使用三步训练策略。它还考虑了round error，通常被其他方法忽略，并提出了一种Gradient Approximation Function（GAF）来超越折射扰动的不可导性问题。results:实验结果表明，PRIS 在鲁棒性和实用性两个方面都超越了当前的图像隐藏方法。<details>
<summary>Abstract</summary>
Image steganography is a technique of hiding secret information inside another image, so that the secret is not visible to human eyes and can be recovered when needed. Most of the existing image steganography methods have low hiding robustness when the container images affected by distortion. Such as Gaussian noise and lossy compression. This paper proposed PRIS to improve the robustness of image steganography, it based on invertible neural networks, and put two enhance modules before and after the extraction process with a 3-step training strategy. Moreover, rounding error is considered which is always ignored by existing methods, but actually it is unavoidable in practical. A gradient approximation function (GAF) is also proposed to overcome the undifferentiable issue of rounding distortion. Experimental results show that our PRIS outperforms the state-of-the-art robust image steganography method in both robustness and practicability. Codes are available at https://github.com/yanghangAI/PRIS, demonstration of our model in practical at http://yanghang.site/hide/.
</details>
<details>
<summary>摘要</summary>
Image 隐藏技术是一种将秘密信息隐藏在另一个图像中，以便当需要时可以恢复。现有的大多数图像隐藏方法具有低的隐藏稳定性，容易受到扰动的影响。这篇论文提出了PRIS，用于提高图像隐藏的稳定性，基于可逆神经网络，并在提取过程前后加入了两个增强模块，采用3步训练策略。此外，我们还考虑了很多现实中常被忽略的圆拟误差问题，并提出了一种梯度近似函数（GAF）来解决圆拟误差问题。实验结果表明，我们的PRIS在稳定性和实用性两个方面都高于当前最佳的图像隐藏方法。代码可以在https://github.com/yanghangAI/PRIS找到，实验演示在http://yanghang.site/hide/.
</details></li>
</ul>
<hr>
<h2 id="Boosting-Offline-Reinforcement-Learning-for-Autonomous-Driving-with-Hierarchical-Latent-Skills"><a href="#Boosting-Offline-Reinforcement-Learning-for-Autonomous-Driving-with-Hierarchical-Latent-Skills" class="headerlink" title="Boosting Offline Reinforcement Learning for Autonomous Driving with Hierarchical Latent Skills"></a>Boosting Offline Reinforcement Learning for Autonomous Driving with Hierarchical Latent Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13614">http://arxiv.org/abs/2309.13614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zenan Li, Fan Nie, Qiao Sun, Fang Da, Hang Zhao</li>
<li>for: 本文是为了解决learning-based vehicle planning中的长期规划挑战。</li>
<li>methods: 我们使用了variational autoencoder（VAE）来学习从Offline示例中的练习。为了解决VAEs的后验塌缩，我们提出了一种两极Sequence Encoder，可以捕捉练习中的细致驾驶技能的 discrete 和连续变化。</li>
<li>results: 我们在CARLA上进行了广泛的试验，并证明了我们的模型可以在新的enario中比较强的表现。此外，我们还提供了更多的视觉化和实验，以证明学习的策略的可读性和传递性。<details>
<summary>Abstract</summary>
Learning-based vehicle planning is receiving increasing attention with the emergence of diverse driving simulators and large-scale driving datasets. While offline reinforcement learning (RL) is well suited for these safety-critical tasks, it still struggles to plan over extended periods. In this work, we present a skill-based framework that enhances offline RL to overcome the long-horizon vehicle planning challenge. Specifically, we design a variational autoencoder (VAE) to learn skills from offline demonstrations. To mitigate posterior collapse of common VAEs, we introduce a two-branch sequence encoder to capture both discrete options and continuous variations of the complex driving skills. The final policy treats learned skills as actions and can be trained by any off-the-shelf offline RL algorithms. This facilitates a shift in focus from per-step actions to temporally extended skills, thereby enabling long-term reasoning into the future. Extensive results on CARLA prove that our model consistently outperforms strong baselines at both training and new scenarios. Additional visualizations and experiments demonstrate the interpretability and transferability of extracted skills.
</details>
<details>
<summary>摘要</summary>
学习基于的自动驾驶规划正在随着多种驾驶 simulator 和大规模驾驶数据的出现而得到越来越多的注意。虽然线上 reinforcement learning (RL) 适用于这些安全关键任务，但它仍然很难计划长期。在这项工作中，我们提出了一个基于技能的框架，以增强线上 RL 以抵消长期自动驾驶规划挑战。 Specifically，我们设计了一个变量自动编码器 (VAE)，以从线上示范中学习技能。为了解决常见 VAE 的后退问题，我们引入了两个分支序列编码器，以捕捉细致的驾驶技能的分类选择和连续变化。最终策略将学习的技能作为动作，可以通过任何准备好的线上 RL 算法进行训练。这使得我们的模型可以强调长期的规划，而不是每步的动作，从而使得在未来中进行长期预测。我们在 CARLA 上进行了广泛的实验，并证明了我们的模型在训练和新的enario 中 consistently 超过了强的基elines。此外，我们还提供了可读性和传输性的图像和实验，以确认提取的技能的可读性和可传输性。
</details></li>
</ul>
<hr>
<h2 id="A-Text-Classification-Based-Approach-for-Evaluating-and-Enhancing-the-Machine-Interpretability-of-Building-Codes"><a href="#A-Text-Classification-Based-Approach-for-Evaluating-and-Enhancing-the-Machine-Interpretability-of-Building-Codes" class="headerlink" title="A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes"></a>A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14374">http://arxiv.org/abs/2309.14374</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skydustz/text-classification-based-approach-for-evaluating-and-enhancing-machine-interpretability-of-building">https://github.com/skydustz/text-classification-based-approach-for-evaluating-and-enhancing-machine-interpretability-of-building</a></li>
<li>paper_authors: Zhe Zheng, Yu-Cheng Zhou, Ke-Yin Chen, Xin-Zheng Lu, Zhong-Tian She, Jia-Rui Lin</li>
<li>for: 本研究旨在提出一种自动评估和提高建筑法规机器可读性的方法，以便将建筑法规转换成计算机处理可能的格式。</li>
<li>methods: 本研究使用了一种基于域专属语言模型和传输学习技术的高效文本分类模型，并提出了一种用于评估建筑法规机器可读性的量化评价方法。</li>
<li>results: 实验表明，提出的文本分类算法在比较建筑法规中的表现更高，提高了F1-score从72.16%到93.60%，同时也提高了下游自动规则解释方法的性能。<details>
<summary>Abstract</summary>
Interpreting regulatory documents or building codes into computer-processable formats is essential for the intelligent design and construction of buildings and infrastructures. Although automated rule interpretation (ARI) methods have been investigated for years, most of them highly depend on the early and manual filtering of interpretable clauses from a building code. While few of them considered machine interpretability, which represents the potential to be transformed into a computer-processable format, from both clause- and document-level. Therefore, this research aims to propose a novel approach to automatically evaluate and enhance the machine interpretability of single clause and building codes. First, a few categories are introduced to classify each clause in a building code considering the requirements for rule interpretation, and a dataset is developed for model training. Then, an efficient text classification model is developed based on a pretrained domain-specific language model and transfer learning techniques. Finally, a quantitative evaluation method is proposed to assess the overall interpretability of building codes. Experiments show that the proposed text classification algorithm outperforms the existing CNN- or RNN-based methods, improving the F1-score from 72.16% to 93.60%. It is also illustrated that the proposed classification method can enhance downstream ARI methods with an improvement of 4%. Furthermore, analyzing the results of more than 150 building codes in China showed that their average interpretability is 34.40%, which implies that it is still hard to fully transform the entire regulatory document into computer-processable formats. It is also argued that the interpretability of building codes should be further improved both from the human side and the machine side.
</details>
<details>
<summary>摘要</summary>
“理解法规文档或基础设计文档的自动转换为电脑处理可能是建筑和基础设施设计中的重要因素。 although automated rule interpretation (ARI) 方法已经在多年来进行研究，大多数它们仅仅依赖早期的手动筛选可解释的条款，而几乎没有考虑过机器可读性，这代表了可以转换为电脑处理格式的潜力。因此，本研究的目的是提出一种新的方法来自动评估和提高建筑法规的机器可读性。首先，我们引入了一些分类建议，以评估每个条款的需求，然后发展了一个可读性训练 datasets。接着，我们开发了一个高效的文本分类模型，基于预训练的专业语言模型和转移学习技术。最后，我们提出了一个量化评估方法，以评估建筑法规的全面可读性。实验结果显示，我们的文本分类算法在 CNN 和 RNN 基础上进行训练后，对 F1 分数进行了提高，从 72.16% 提高至 93.60%。此外，我们还发现，使用我们的分类方法可以对下游 ARI 方法进行改进，提高了 4%。此外，遍历了中国逾 150 份建筑法规，我们发现其平均可读性为 34.40%，这 implies that it is still difficult to fully transform the entire regulatory document into computer-processable formats。此外，我们还认为，建筑法规的可读性应该在人类和机器两方面进行进一步改进。”
</details></li>
</ul>
<hr>
<h2 id="MM-NeRF-Multimodal-Guided-3D-Multi-Style-Transfer-of-Neural-Radiance-Field"><a href="#MM-NeRF-Multimodal-Guided-3D-Multi-Style-Transfer-of-Neural-Radiance-Field" class="headerlink" title="MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance Field"></a>MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13607">http://arxiv.org/abs/2309.13607</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijiang Yang, Zhongwei Qiu, Chang Xu, Dongmei Fu</li>
<li>for: 本研究旨在实现高质量的3D多样化风格传输，使用神经辐射场（NeRF）来获取3D场景的高级别描述。</li>
<li>methods: 本研究提出了一种新的多Modal-guided 3D Multi-style transfer of NeRF（MM-NeRF），它可以实现高质量的3D多样化风格传输，并且可以根据多modal导向来指导风格传输。</li>
<li>results: 实验结果表明，MM-NeRF可以实现高质量的3D多样化风格传输，同时保持多视图一致性和多modal风格引导的semantic一致性。<details>
<summary>Abstract</summary>
3D style transfer aims to render stylized novel views of 3D scenes with the specified style, which requires high-quality rendering and keeping multi-view consistency. Benefiting from the ability of 3D representation from Neural Radiance Field (NeRF), existing methods learn the stylized NeRF by giving a reference style from an image. However, they suffer the challenges of high-quality stylization with texture details for multi-style transfer and stylization with multimodal guidance. In this paper, we reveal that the same objects in 3D scenes show various states (color tone, details, etc.) from different views after stylization since previous methods optimized by single-view image-based style loss functions, leading NeRF to tend to smooth texture details, further resulting in low-quality rendering. To tackle these problems, we propose a novel Multimodal-guided 3D Multi-style transfer of NeRF, termed MM-NeRF, which achieves high-quality 3D multi-style rendering with texture details and can be driven by multimodal-style guidance. First, MM-NeRF adopts a unified framework to project multimodal guidance into CLIP space and extracts multimodal style features to guide the multi-style stylization. To relieve the problem of lacking details, we propose a novel Multi-Head Learning Scheme (MLS), in which each style head predicts the parameters of the color head of NeRF. MLS decomposes the learning difficulty caused by the inconsistency of multi-style transfer and improves the quality of stylization. In addition, the MLS can generalize pre-trained MM-NeRF to any new styles by adding heads with small training costs (a few minutes). Extensive experiments on three real-world 3D scene datasets show that MM-NeRF achieves high-quality 3D multi-style stylization with multimodal guidance, keeps multi-view consistency, and keeps semantic consistency of multimodal style guidance. Codes will be released later.
</details>
<details>
<summary>摘要</summary>
三维样式传输目标是将三维场景渲染为指定的样式，需要高质量的渲染和保持多视图一致性。基于神经辐射场（NeRF）的存在，现有方法学习带有样式的NeRF，但它们面临高质量颜色细节的多样化颜色传输和多Modal导航颜色细节的渲染问题。在这篇论文中，我们发现在使用多视图颜色导航后，同一个三维对象在场景中会显示不同的颜色、细节等状态。这是因为前一代方法通过单视图图像基于风格损失优化NeRF，导致NeRF倾向于平滑Texture细节，从而导致低质量渲染。为解决这些问题，我们提出了一种新的多模态指导三维多样式传输NeRF（MM-NeRF），可以实现高质量三维多样式渲染，并且可以通过多模式导航颜色细节。首先，MM-NeRF采用一种统一框架，将多模态指导 проек到CLIP空间中，并提取多模式风格特征来引导多样式风格化。为解决缺乏细节的问题，我们提出了一种新的多头学习方案（MLS），每个风格头预测NeRF的颜色头的参数。MLS分解了多样式传输中学习的困难，并提高了风格化质量。此外，MLS可以将预训练MM-NeRF扩展到新的风格，只需要训练一些小时。广泛的实验表明，MM-NeRF可以实现高质量三维多样式渲染，保持多视图一致性，并保持多模式颜色导航的semantic一致性。代码将在未来发布。
</details></li>
</ul>
<hr>
<h2 id="Distribution-Aware-Continual-Test-Time-Adaptation-for-Semantic-Segmentation"><a href="#Distribution-Aware-Continual-Test-Time-Adaptation-for-Semantic-Segmentation" class="headerlink" title="Distribution-Aware Continual Test Time Adaptation for Semantic Segmentation"></a>Distribution-Aware Continual Test Time Adaptation for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13604">http://arxiv.org/abs/2309.13604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayi Ni, Senqiao Yang, Jiaming Liu, Xiaoqi Li, Wenyu Jiao, Ran Xu, Zehui Chen, Yi Liu, Shanghang Zhang<br>for: This paper proposes a distribution-aware tuning (DAT) method for efficient and practical continual test-time adaptation (CTTA) in semantic segmentation tasks.methods: The DAT method adaptively selects and updates two small groups of trainable parameters based on data distribution during the continual adaptation process, including domain-specific parameters (DSP) and task-relevant parameters (TRP).results: The proposed method achieves promising performance compared to previous state-of-the-art methods on two widely-used semantic segmentation CTTA benchmarks, demonstrating its effectiveness in mitigating the challenges of error accumulation and catastrophic forgetting.<details>
<summary>Abstract</summary>
Since autonomous driving systems usually face dynamic and ever-changing environments, continual test-time adaptation (CTTA) has been proposed as a strategy for transferring deployed models to continually changing target domains. However, the pursuit of long-term adaptation often introduces catastrophic forgetting and error accumulation problems, which impede the practical implementation of CTTA in the real world. Recently, existing CTTA methods mainly focus on utilizing a majority of parameters to fit target domain knowledge through self-training. Unfortunately, these approaches often amplify the challenge of error accumulation due to noisy pseudo-labels, and pose practical limitations stemming from the heavy computational costs associated with entire model updates. In this paper, we propose a distribution-aware tuning (DAT) method to make the semantic segmentation CTTA efficient and practical in real-world applications. DAT adaptively selects and updates two small groups of trainable parameters based on data distribution during the continual adaptation process, including domain-specific parameters (DSP) and task-relevant parameters (TRP). Specifically, DSP exhibits sensitivity to outputs with substantial distribution shifts, effectively mitigating the problem of error accumulation. In contrast, TRP are allocated to positions that are responsive to outputs with minor distribution shifts, which are fine-tuned to avoid the catastrophic forgetting problem. In addition, since CTTA is a temporal task, we introduce the Parameter Accumulation Update (PAU) strategy to collect the updated DSP and TRP in target domain sequences. We conduct extensive experiments on two widely-used semantic segmentation CTTA benchmarks, achieving promising performance compared to previous state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
自适应驾驶系统通常面临动态和不断变化的环境，因此提出了持续测试时适应（CTTA）作为将部署模型转移到不断变化的目标领域的策略。然而，追求长期适应通常会导致慢速忘记和错误积累问题，这些问题限制了CTTA在实际应用中的实施。现有的CTTA方法主要通过使用大量参数来适应目标领域知识进行自学习。然而，这些方法通常会增加 pseudo-标签 noise 的挑战，并且由于整个模型更新的重要计算成本，它们在实际应用中存在限制。在本文中，我们提出了分布意识调整（DAT）方法，以使得 semantic segmentation CTTA 在实际应用中变得有效和实用。DAT 在 continual adaptation 过程中适应ively 选择和更新两个小组trainable parameter，包括域pecific parameter（DSP）和任务相关 parameter（TRP）。具体来说，DSP 在输出具有显著分布差异时表现敏感，因此可以有效 mitigate 错误积累问题。相反，TRP 被分配到输出具有小分布差异的位置，并在避免慢速忘记问题的同时进行微调。此外，由于 CTTA 是一个时间任务，我们提出了 Parameter Accumulation Update（PAU）策略，用于在目标领域序列中收集更新的 DSP 和 TRP。我们在两个广泛使用的 semantic segmentation CTTA  bencmarks 上进行了广泛的实验，并 achieved 比前一个状态的方法更好的性能。
</details></li>
</ul>
<hr>
<h2 id="From-Cluster-Assumption-to-Graph-Convolution-Graph-based-Semi-Supervised-Learning-Revisited"><a href="#From-Cluster-Assumption-to-Graph-Convolution-Graph-based-Semi-Supervised-Learning-Revisited" class="headerlink" title="From Cluster Assumption to Graph Convolution: Graph-based Semi-Supervised Learning Revisited"></a>From Cluster Assumption to Graph Convolution: Graph-based Semi-Supervised Learning Revisited</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13599">http://arxiv.org/abs/2309.13599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Wang, Hongming Ding, Li Pan, Jianhua Li, Zhiguo Gong, Philip S. Yu</li>
<li>for: 本文研究 graph-based semi-supervised learning (GSSL) 的关系，并提出三种graph convolution方法来提高GSSL的性能。</li>
<li>methods: 本文使用了一种统一优化框架来探讨 traditional GSSL 方法和 graph convolutional networks (GCNs) 之间的关系。三种提议的graph convolution方法包括：1) supervised方法 OGC，使用标签来引导图 convolution 过程；2) 无标签方法 GGC，希望在图 convolution 过程中保持图结构信息；3) 多尺度版本 GGCM，将 GGC 应用到不同的尺度上。</li>
<li>results: 经过广泛的实验，本文证明了我们提出的三种方法都能够提高 GSSL 的性能。<details>
<summary>Abstract</summary>
Graph-based semi-supervised learning (GSSL) has long been a hot research topic. Traditional methods are generally shallow learners, based on the cluster assumption. Recently, graph convolutional networks (GCNs) have become the predominant techniques for their promising performance. In this paper, we theoretically discuss the relationship between these two types of methods in a unified optimization framework. One of the most intriguing findings is that, unlike traditional ones, typical GCNs may not jointly consider the graph structure and label information at each layer. Motivated by this, we further propose three simple but powerful graph convolution methods. The first is a supervised method OGC which guides the graph convolution process with labels. The others are two unsupervised methods: GGC and its multi-scale version GGCM, both aiming to preserve the graph structure information during the convolution process. Finally, we conduct extensive experiments to show the effectiveness of our methods.
</details>
<details>
<summary>摘要</summary>
Traditional GSSL methods are usually shallow learners, based on the cluster assumption. Recently, graph convolutional networks (GCNs) have become the predominant techniques for their promising performance. In this paper, we theoretically discuss the relationship between these two types of methods in a unified optimization framework. One of the most intriguing findings is that, unlike traditional ones, typical GCNs may not jointly consider the graph structure and label information at each layer. Motivated by this, we further propose three simple but powerful graph convolution methods. The first is a supervised method OGC, which guides the graph convolution process with labels. The others are two unsupervised methods: GGC and its multi-scale version GGCM, both aiming to preserve the graph structure information during the convolution process. Finally, we conduct extensive experiments to show the effectiveness of our methods.Here's the text with some notes on the translation:* "GSSL" is translated as "图像基于 semi-supervised learning" (tú xiàng bǐ yǐjīng xiǎng yù yì)* "traditional methods" is translated as "传统方法" (chuán chéng fāng fa)* "GCNs" is translated as "图aelastic networks" (tú yì xiǎng wǎng)* "unified optimization framework" is translated as "统一优化框架" (tǒng yī yǎo jì kōng jī)* "shallow learners" is translated as "浅学习" (shallow learners)* "cluster assumption" is translated as "团结假设" (cluster assumption)* "graph structure" is translated as "图 структура" (graph structure)* "label information" is translated as "标签信息" (label information)* "supervised method" is translated as "指导方法" (supervised method)* "unsupervised methods" is translated as "无指导方法" (unsupervised methods)* "GGC" is translated as "图structural preserved方法" (GGC)* "GGCM" is translated as "多级图structural preserved方法" (GGCM)Please note that the translation is done in a way that is consistent with the conventions of Simplified Chinese, and some of the terms used may not be exactly the same as the original English text.
</details></li>
</ul>
<hr>
<h2 id="Seeing-Is-Not-Always-Believing-Invisible-Collision-Attack-and-Defence-on-Pre-Trained-Models"><a href="#Seeing-Is-Not-Always-Believing-Invisible-Collision-Attack-and-Defence-on-Pre-Trained-Models" class="headerlink" title="Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models"></a>Seeing Is Not Always Believing: Invisible Collision Attack and Defence on Pre-Trained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13579">http://arxiv.org/abs/2309.13579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous10240/framework">https://github.com/anonymous10240/framework</a></li>
<li>paper_authors: Minghang Deng, Zhong Zhang, Junming Shao</li>
<li>For: This paper proposes a novel framework for an invisible attack on large-scale pre-trained models (PTMs) like BERT and GPT, which can be used to manipulate the predictions of the models without being detected.* Methods: The proposed attack leverages the MD5 chosen-prefix collision to generate two equal-size models with the same MD5 checksum, which are then deployed on public websites to induce victims to download the poisoned model.* Results: The paper demonstrates the effectiveness and stealthiness of the proposed attack and defensive method on different models and data sets, and provides a theoretical justification for its feasibility.<details>
<summary>Abstract</summary>
Large-scale pre-trained models (PTMs) such as BERT and GPT have achieved great success in diverse fields. The typical paradigm is to pre-train a big deep learning model on large-scale data sets, and then fine-tune the model on small task-specific data sets for downstream tasks. Although PTMs have rapidly progressed with wide real-world applications, they also pose significant risks of potential attacks. Existing backdoor attacks or data poisoning methods often build up the assumption that the attacker invades the computers of victims or accesses the target data, which is challenging in real-world scenarios. In this paper, we propose a novel framework for an invisible attack on PTMs with enhanced MD5 collision. The key idea is to generate two equal-size models with the same MD5 checksum by leveraging the MD5 chosen-prefix collision. Afterwards, the two ``same" models will be deployed on public websites to induce victims to download the poisoned model. Unlike conventional attacks on deep learning models, this new attack is flexible, covert, and model-independent. Additionally, we propose a simple defensive strategy for recognizing the MD5 chosen-prefix collision and provide a theoretical justification for its feasibility. We extensively validate the effectiveness and stealthiness of our proposed attack and defensive method on different models and data sets.
</details>
<details>
<summary>摘要</summary>
大规模预训练模型（PTM）如BERT和GPT在多个领域取得了很大成功。典型的假设是先预训大深度学习模型在大规模数据集上，然后在小任务特定数据集上细化模型以进行下游任务。although PTMs have rapidly progressed with wide real-world applications, they also pose significant risks of potential attacks. 现有的后门攻击或数据毒液方法通常假设攻击者可以入侵受害者的计算机或访问目标数据，这是现实世界中的挑战。在这篇论文中，我们提出了一种新的隐形攻击方法，通过提高MD5撞击的方式来实现。关键思想是通过MD5选择前缀撞击来生成两个相同大小的模型，并将这两个“相同”的模型部署到公共网站上，以引诱受害者下载毒化模型。与传统的深度学习模型攻击方法不同，这种新的攻击方法更加灵活、隐蔽和模型独立。此外，我们还提出了一种简单的防御策略，可以识别MD5选择前缀撞击，并提供了理论上的可行性。我们在不同的模型和数据集上进行了广泛验证和证明了攻击和防御方法的效果和隐蔽性。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Weight-Fixing-Large-scale-training-of-neural-network-weight-uncertainties-for-quantization"><a href="#Probabilistic-Weight-Fixing-Large-scale-training-of-neural-network-weight-uncertainties-for-quantization" class="headerlink" title="Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantization"></a>Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13575">http://arxiv.org/abs/2309.13575</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/subiawaud/PWFN">https://github.com/subiawaud/PWFN</a></li>
<li>paper_authors: Christopher Subia-Waud, Srinandan Dasmahapatra</li>
<li>for: 降低大神经网络的执行时间和能耗，通过尝试将权重限制到一个有限的值集。</li>
<li>methods: 使用 Bayesian neural networks (BNNs) 和一种简化的轻量级 relaxation 来确定权重可以被移动到哪些中心和多少，基于它们的具体位置特有的学习不确定性分布。</li>
<li>results: 比前方法更高的压缩率和更高的准确率，特别是在使用 DeiT-Tiny 模型和 transformer 模型时。在 ImageNet 上，我们的方法可以将 5000 万个权重压缩到 296 个唯一值上，并且与前方法的 top-1 准确率相比提高 1.6%。<details>
<summary>Abstract</summary>
Weight-sharing quantization has emerged as a technique to reduce energy expenditure during inference in large neural networks by constraining their weights to a limited set of values. However, existing methods for weight-sharing quantization often make assumptions about the treatment of weights based on value alone that neglect the unique role weight position plays. This paper proposes a probabilistic framework based on Bayesian neural networks (BNNs) and a variational relaxation to identify which weights can be moved to which cluster centre and to what degree based on their individual position-specific learned uncertainty distributions. We introduce a new initialisation setting and a regularisation term which allow for the training of BNNs under complex dataset-model combinations. By leveraging the flexibility of weight values captured through a probability distribution, we enhance noise resilience and downstream compressibility. Our iterative clustering procedure demonstrates superior compressibility and higher accuracy compared to state-of-the-art methods on both ResNet models and the more complex transformer-based architectures. In particular, our method outperforms the state-of-the-art quantization method top-1 accuracy by 1.6% on ImageNet using DeiT-Tiny, with its 5 million+ weights now represented by only 296 unique values.
</details>
<details>
<summary>摘要</summary>
大型神经网络中的权重共享量化技术可以降低推理过程中的能耗。然而，现有的权重共享量化方法通常假设权重值的处理方法是基于价值alone neglects 权重位置的特殊作用。这篇论文提出了基于 Bayesian neural networks（BNNs）的概率框架和一种可relaxation的方法，用于确定权重可以被移动到哪些集中心和多少基于它们的具体位置特定学习不确定分布。我们提出了一种新的初始化设定和一种正则化项，allowing for the training of BNNs under complex dataset-model combinations。通过利用权重值 captured through a probability distribution 的灵活性，我们提高了雷达鲁抗性和下游压缩性。我们的迭代归一化过程比前式-of-the-art方法更高的压缩率和更高的准确率，特别是在使用 DeiT-Tiny 模型和更复杂的 transformer-based 架构时。在这些模型中，我们的方法可以将 5000万+ 个权重表示为只 296 个唯一的值，与state-of-the-art 方法的 top-1 准确率相比，提高了 1.6%。
</details></li>
</ul>
<hr>
<h2 id="Keeping-in-Time-Adding-Temporal-Context-to-Sentiment-Analysis-Models"><a href="#Keeping-in-Time-Adding-Temporal-Context-to-Sentiment-Analysis-Models" class="headerlink" title="Keeping in Time: Adding Temporal Context to Sentiment Analysis Models"></a>Keeping in Time: Adding Temporal Context to Sentiment Analysis Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13562">http://arxiv.org/abs/2309.13562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean Ninalga</li>
<li>for: 提高和保持 sentiment analysis 模型的性能 across shorter and longer time periods.</li>
<li>methods: 使用日期前缀的文本输入，并使用自我标签法将无标签数据用于学习学生模型。 使用一种新的日期格式化策略来扩大自我标签过程。</li>
<li>results: 在 LongEval-Classification 评估集上实现了减少性能下降的最好 Result （RPD） (-0.0656)，并达到了总分 0.6923，位列第二名。<details>
<summary>Abstract</summary>
This paper presents a state-of-the-art solution to the LongEval CLEF 2023 Lab Task 2: LongEval-Classification. The goal of this task is to improve and preserve the performance of sentiment analysis models across shorter and longer time periods. Our framework feeds date-prefixed textual inputs to a pre-trained language model, where the timestamp is included in the text. We show date-prefixed samples better conditions model outputs on the temporal context of the respective texts. Moreover, we further boost performance by performing self-labeling on unlabeled data to train a student model. We augment the self-labeling process using a novel augmentation strategy leveraging the date-prefixed formatting of our samples. We demonstrate concrete performance gains on the LongEval-Classification evaluation set over non-augmented self-labeling. Our framework achieves a 2nd place ranking with an overall score of 0.6923 and reports the best Relative Performance Drop (RPD) of -0.0656 over the short evaluation set.
</details>
<details>
<summary>摘要</summary>
To further boost performance, we perform self-labeling on unlabeled data to train a student model. We augment the self-labeling process using a novel augmentation strategy that leverages the date-prefixed formatting of our samples. Our approach achieves concrete performance gains on the LongEval-Classification evaluation set compared to non-augmented self-labeling.Our framework achieved a 2nd place ranking with an overall score of 0.6923 and reported the best Relative Performance Drop (RPD) of -0.0656 over the short evaluation set.
</details></li>
</ul>
<hr>
<h2 id="Cordyceps-LT-EDI-Patching-Language-Specific-Homophobia-Transphobia-Classifiers-with-a-Multilingual-Understanding"><a href="#Cordyceps-LT-EDI-Patching-Language-Specific-Homophobia-Transphobia-Classifiers-with-a-Multilingual-Understanding" class="headerlink" title="Cordyceps@LT-EDI: Patching Language-Specific Homophobia&#x2F;Transphobia Classifiers with a Multilingual Understanding"></a>Cordyceps@LT-EDI: Patching Language-Specific Homophobia&#x2F;Transphobia Classifiers with a Multilingual Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13561">http://arxiv.org/abs/2309.13561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean Ninalga</li>
<li>For: 本研究旨在探讨识别社交媒体评论中的恐同和恐 транс人辱骂语言的方法，以优化识别率和准确率。* Methods: 本研究采用了多语言（M-L）和语言特定（L-S）方法的结合，通过简单的权重 interpolating 来融合两种方法，以优化识别率和准确率。* Results: 本研究在 task A 的 ‘Shared Task on Homophobia&#x2F;Transphobia Detection in social media comments’ 数据集上实现了最佳结果，在五种语言中取得了三个语言的最佳结果，并在马拉雅邦语文本上 achieve 0.997 的macro F1 分数。<details>
<summary>Abstract</summary>
Detecting transphobia, homophobia, and various other forms of hate speech is difficult. Signals can vary depending on factors such as language, culture, geographical region, and the particular online platform. Here, we present a joint multilingual (M-L) and language-specific (L-S) approach to homophobia and transphobic hate speech detection (HSD). M-L models are needed to catch words, phrases, and concepts that are less common or missing in a particular language and subsequently overlooked by L-S models. Nonetheless, L-S models are better situated to understand the cultural and linguistic context of the users who typically write in a particular language. Here we construct a simple and successful way to merge the M-L and L-S approaches through simple weight interpolation in such a way that is interpretable and data-driven. We demonstrate our system on task A of the 'Shared Task on Homophobia/Transphobia Detection in social media comments' dataset for homophobia and transphobic HSD. Our system achieves the best results in three of five languages and achieves a 0.997 macro average F1-score on Malayalam texts.
</details>
<details>
<summary>摘要</summary>
检测transphobia、homophobia和其他形式的仇恨言语困难。信号可以因语言、文化、地区和在线平台而异常。我们介绍了一种联合多语言（M-L）和语言特定（L-S）方法来检测同性恋和变性人仇恨言语检测（HSD）。M-L模型可以捕捉语言中不常见或缺失的词汇和短语，并被L-S模型所过look。然而，L-S模型更好地理解用户 Typically write in a particular language的文化和语言背景。我们构建了一种简单有效的方法来融合M-L和L-S方法，通过简单的权重 interpolating 的方式，以便可以解释和数据驱动。我们在task A of the 'Shared Task on Homophobia/Transphobia Detection in social media comments' dataset上展示了我们的系统，并在五种语言中获得了最佳结果，并在马拉雅拉姆语文本上达到了0.997macro average F1-score。
</details></li>
</ul>
<hr>
<h2 id="Decoding-Radiologists-Intense-Focus-for-Accurate-CXR-Diagnoses-A-Controllable-and-Interpretable-AI-System"><a href="#Decoding-Radiologists-Intense-Focus-for-Accurate-CXR-Diagnoses-A-Controllable-and-Interpretable-AI-System" class="headerlink" title="Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A Controllable and Interpretable AI System"></a>Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A Controllable and Interpretable AI System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13550">http://arxiv.org/abs/2309.13550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Trong Thang Pham, Jacob Brecheisen, Anh Nguyen, Hien Nguyen, Ngan Le</li>
<li>for: 这个论文目标是提出一种可控制可解释的护肺X光诊断管道，以帮助理解肺科医生在诊断过程中的认知过程。</li>
<li>methods: 该方法使用视Language模型，可以准确地控制诊断过程，并且可以排除不重要的特征。</li>
<li>results: 经过广泛的实验，表明该方法可以准确地 Classification tasks，只需使用护肺X光的一部分。<details>
<summary>Abstract</summary>
In the field of chest X-ray (CXR) diagnosis, existing works often focus solely on determining where a radiologist looks, typically through tasks such as detection, segmentation, or classification. However, these approaches are often designed as black-box models, lacking interpretability. In this paper, we introduce a novel and unified controllable interpretable pipeline for decoding the intense focus of radiologists in CXR diagnosis. Our approach addresses three key questions: where a radiologist looks, how long they focus on specific areas, and what findings they diagnose. By capturing the intensity of the radiologist's gaze, we provide a unified solution that offers insights into the cognitive process underlying radiological interpretation. Unlike current methods that rely on black-box machine learning models, which can be prone to extracting erroneous information from the entire input image during the diagnosis process, we tackle this issue by effectively masking out irrelevant information. Our approach leverages a vision-language model, allowing for precise control over the interpretation process while ensuring the exclusion of irrelevant features. To train our model, we utilize an eye gaze dataset to extract anatomical gaze information and generate ground truth heatmaps. Through extensive experimentation, we demonstrate the efficacy of our method. We showcase that the attention heatmaps, designed to mimic radiologists' focus, encode sufficient and relevant information, enabling accurate classification tasks using only a portion of CXR.
</details>
<details>
<summary>摘要</summary>
在胸部X射影（CXR）诊断领域，现有的工作通常围绕确定诊断人员的注意力点进行设计，通常通过检测、分割或分类等任务来完成。然而，这些方法经常设计成黑盒模型，缺乏可解释性。在这篇论文中，我们提出了一种新的可控可解释的扫描策略，用于解码诊断人员在CXR诊断过程中的焦点。我们的方法解决了三个关键问题：诊断人员注意力点在哪里、如何长时间关注特定区域，以及他们诊断了什么。我们通过捕捉诊断人员的眼动信息，提供了一种统一的解决方案，可以帮助理解诊断过程中的认知过程。不同于现有的黑盒机器学习模型，这些模型可能会从整个输入图像中提取错误信息，我们通过有效地遮盖无关信息来解决这个问题。我们的方法利用了视觉语言模型，可以准确控制解释过程，同时确保排除无关特征。为了训练我们的模型，我们使用了眼动数据集来提取 анатомиче gaze 信息，生成标准的热图。通过广泛的实验，我们证明了我们的方法的有效性。我们显示了注意力热图，设计用于模拟诊断人员的注意力，含有足够和相关的信息，可以使用CXR中的一部分进行准确的分类任务。
</details></li>
</ul>
<hr>
<h2 id="Related-Rhythms-Recommendation-System-To-Discover-Music-You-May-Like"><a href="#Related-Rhythms-Recommendation-System-To-Discover-Music-You-May-Like" class="headerlink" title="Related Rhythms: Recommendation System To Discover Music You May Like"></a>Related Rhythms: Recommendation System To Discover Music You May Like</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13544">http://arxiv.org/abs/2309.13544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Singh, Pranav Kanuparthi</li>
<li>for: 这 paper 的目的是提出一个分布式机器学习（ML）管道，用于从 Million Songs Dataset（MSD）中提取类似于输入subset的歌曲。</li>
<li>methods: 该 paper 使用的方法包括使用分布式 ML 管道，以便在 MSD 上进行音频轨道分析和推荐。</li>
<li>results: 该 paper 的结果显示，使用分布式 ML 管道可以提供高效的推荐系统，并且可以在 MSD 上进行大规模的音频轨道分析和推荐。<details>
<summary>Abstract</summary>
Machine Learning models are being utilized extensively to drive recommender systems, which is a widely explored topic today. This is especially true of the music industry, where we are witnessing a surge in growth. Besides a large chunk of active users, these systems are fueled by massive amounts of data. These large-scale systems yield applications that aim to provide a better user experience and to keep customers actively engaged. In this paper, a distributed Machine Learning (ML) pipeline is delineated, which is capable of taking a subset of songs as input and producing a new subset of songs identified as being similar to the inputted subset. The publicly accessible Million Songs Dataset (MSD) enables researchers to develop and explore reasonably efficient systems for audio track analysis and recommendations, without having to access a commercialized music platform. The objective of the proposed application is to leverage an ML system trained to optimally recommend songs that a user might like.
</details>
<details>
<summary>摘要</summary>
机器学习模型在推荐系统方面得到广泛应用，特别是在音乐行业，目前在快速发展。这主要归功于大量数据的支持以及高效的机器学习算法。这些大规模系统的应用旨在提供更好的用户体验，并保持用户高度参与。在这篇论文中，我们提出了一个分布式机器学习（ML）管道，可以将输入subset of songs中的一部分作为输入，并生成与输入相似的新subset of songs。可以通过公共可访问的Million Songs Dataset（MSD），让研究人员开发和探索reasonably efficient的音频轨道分析和推荐系统，不需要访问商业化音乐平台。我们的目标是使用ML系统来优化推荐用户可能喜欢的歌曲。
</details></li>
</ul>
<hr>
<h2 id="Human-Transcription-Quality-Improvement"><a href="#Human-Transcription-Quality-Improvement" class="headerlink" title="Human Transcription Quality Improvement"></a>Human Transcription Quality Improvement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14372">http://arxiv.org/abs/2309.14372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GenerateAI/LibriCrowd">https://github.com/GenerateAI/LibriCrowd</a></li>
<li>paper_authors: Jian Gao, Hanbo Sun, Cheng Cao, Zheng Du</li>
<li>for: 提高自动语音识别（ASR）系统的训练数据质量。</li>
<li>methods: 提出一种可靠的训练数据收集方法，包括对标注阶段进行信任度估计基于的重新处理，以及后置标注阶段的自动单词错误 corrections。</li>
<li>results: 实验显示，对100小时英语语音标注的Transcription WER减少了超过50%。进一步研究表明，错误的转录影响ASR模型性能强相关。改进转录质量提供了10%以上相对WER减少。发布了数据集和代码，为研究社区提供利益。<details>
<summary>Abstract</summary>
High quality transcription data is crucial for training automatic speech recognition (ASR) systems. However, the existing industry-level data collection pipelines are expensive to researchers, while the quality of crowdsourced transcription is low. In this paper, we propose a reliable method to collect speech transcriptions. We introduce two mechanisms to improve transcription quality: confidence estimation based reprocessing at labeling stage, and automatic word error correction at post-labeling stage. We collect and release LibriCrowd - a large-scale crowdsourced dataset of audio transcriptions on 100 hours of English speech. Experiment shows the Transcription WER is reduced by over 50%. We further investigate the impact of transcription error on ASR model performance and found a strong correlation. The transcription quality improvement provides over 10% relative WER reduction for ASR models. We release the dataset and code to benefit the research community.
</details>
<details>
<summary>摘要</summary>
高品质转录数据是自动语音识别（ASR）系统训练的关键。然而，现有的行业级数据采集管道对研究人员来说太costly，而且大众办理的转录质量低。在这篇论文中，我们提出一种可靠的方法来采集语音转录。我们提出了两种机制来提高转录质量：在标注阶段基于信息估计的重新处理，以及在后置阶段自动单词错误更正。我们采集并发布了LibriCrowd - 100小时英语语音转录的大规模众生采集数据集。实验表明，转录WER（识别错误率）下降了超过50%。我们进一步调查了转录错误对ASR模型性能的影响，发现了强相关性。高品质转录改善提供了10%以上相对WER降幅。我们发布数据集和代码，以便研究人员享受。
</details></li>
</ul>
<hr>
<h2 id="Speech-enhancement-with-frequency-domain-auto-regressive-modeling"><a href="#Speech-enhancement-with-frequency-domain-auto-regressive-modeling" class="headerlink" title="Speech enhancement with frequency domain auto-regressive modeling"></a>Speech enhancement with frequency domain auto-regressive modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13537">http://arxiv.org/abs/2309.13537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anurenjan Purushothaman, Debottam Dutta, Rohit Kumar, Sriram Ganapathy</li>
<li>for: 提高在远场实际场景中的speech质量和自动语音识别（ASR）性能</li>
<li>methods: 使用AR模型进行束子域speech信号的干扰分解，并使用 dual path long short term memory（DPLSTM）模型进行束子域束子域信号的增强</li>
<li>results: 在REVERB挑战数据集和VOiCES数据集上，与基准系统相比，jointly learns speech dereverberation network和E2E ASR模型可以获得显著性能提高（相对于基准系统的平均相对提高率为10-24%），并且通过主观听测试得到了提高的音频质量。<details>
<summary>Abstract</summary>
Speech applications in far-field real world settings often deal with signals that are corrupted by reverberation. The task of dereverberation constitutes an important step to improve the audible quality and to reduce the error rates in applications like automatic speech recognition (ASR). We propose a unified framework of speech dereverberation for improving the speech quality and the ASR performance using the approach of envelope-carrier decomposition provided by an autoregressive (AR) model. The AR model is applied in the frequency domain of the sub-band speech signals to separate the envelope and carrier parts. A novel neural architecture based on dual path long short term memory (DPLSTM) model is proposed, which jointly enhances the sub-band envelope and carrier components. The dereverberated envelope-carrier signals are modulated and the sub-band signals are synthesized to reconstruct the audio signal back. The DPLSTM model for dereverberation of envelope and carrier components also allows the joint learning of the network weights for the down stream ASR task. In the ASR tasks on the REVERB challenge dataset as well as on the VOiCES dataset, we illustrate that the joint learning of speech dereverberation network and the E2E ASR model yields significant performance improvements over the baseline ASR system trained on log-mel spectrogram as well as other benchmarks for dereverberation (average relative improvements of 10-24% over the baseline system). The speech quality improvements, evaluated using subjective listening tests, further highlight the improved quality of the reconstructed audio.
</details>
<details>
<summary>摘要</summary>
讲话应用程序在远场实际场景中经常会遇到受泛音损害的信号。去泛音是提高语音质量和降低自动语音识别（ASR）错误率的重要步骤。我们提出一个统一框架，用于提高语音质量和ASR性能，基于autoregressive（AR）模型的振荡分解。在各个子带语音信号的频域中，AR模型用于分离振荡和载波部分。我们提出了一种基于双路长短期记忆（DPLSTM）模型的新型神经网络架构，可以同时提高子带振荡和载波组件。去泛音后，振荡和载波组件被修改，并将子带信号重新 sinthezied 以重构音频信号。我们在REVERB挑战数据集和VOiCES数据集上进行了ASR任务，并证明了将批量学习网络参数与下游ASR任务相结合可以获得显著性能提升（相对于基准系统，平均提升10-24%）。此外，通过主观听测试，我们还证明了去泛音后的重构音频质量的提高。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Reachability-Estimation-for-Safe-Reinforcement-Learning"><a href="#Iterative-Reachability-Estimation-for-Safe-Reinforcement-Learning" class="headerlink" title="Iterative Reachability Estimation for Safe Reinforcement Learning"></a>Iterative Reachability Estimation for Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13528">http://arxiv.org/abs/2309.13528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Milan Ganai, Zheng Gong, Chenning Yu, Sylvia Herbert, Sicun Gao</li>
<li>for: 本研究旨在提供一个新的安全性权限执行学习（RL）框架，以确保RL在实际应用中的安全性。</li>
<li>methods: 本研究提出了一种新的 reachability estimation 函数，用于在涉及到不确定环境的通用情况下进行安全性权限执行学习。</li>
<li>results: 研究人员通过对一系列安全RL环境进行实验，证明了他们的算法可以在 reward performance 和安全性两个方面提供改进。<details>
<summary>Abstract</summary>
Ensuring safety is important for the practical deployment of reinforcement learning (RL). Various challenges must be addressed, such as handling stochasticity in the environments, providing rigorous guarantees of persistent state-wise safety satisfaction, and avoiding overly conservative behaviors that sacrifice performance. We propose a new framework, Reachability Estimation for Safe Policy Optimization (RESPO), for safety-constrained RL in general stochastic settings. In the feasible set where there exist violation-free policies, we optimize for rewards while maintaining persistent safety. Outside this feasible set, our optimization produces the safest behavior by guaranteeing entrance into the feasible set whenever possible with the least cumulative discounted violations. We introduce a class of algorithms using our novel reachability estimation function to optimize in our proposed framework and in similar frameworks such as those concurrently handling multiple hard and soft constraints. We theoretically establish that our algorithms almost surely converge to locally optimal policies of our safe optimization framework. We evaluate the proposed methods on a diverse suite of safe RL environments from Safety Gym, PyBullet, and MuJoCo, and show the benefits in improving both reward performance and safety compared with state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
保证安全是RL实践中非常重要的一点。various challenges需要被解决，例如在环境中处理随机性，提供坚实的状态级别安全满足保证，并避免过度保守的行为，这会损害性能。我们提出了一个新的框架，即Reachability Estimation for Safe Policy Optimization（RESPO），用于安全限制RL在一般随机环境中。在可行集（feasible set）中，我们优化奖励，同时保持持续安全。外部可行集，我们的优化生成最安全的行为， garantizesthat entrance into the feasible set whenever possible with the least cumulative discounted violations。我们引入了一类使用我们的新的达性估计函数来优化的算法，并在我们的框架和类似框架（如同时处理多个硬 soft constraints）中进行优化。我们证明了我们的算法在我们的安全优化框架中幂等 converges to locally optimal policies。我们对一个包含了安全RL环境的多样化集合进行评估，并显示了与现有基准点相比，提高了奖励性能和安全性。
</details></li>
</ul>
<hr>
<h2 id="Global-correlated-3D-decoupling-Transformer-for-Clothed-Avatar-Reconstruction"><a href="#Global-correlated-3D-decoupling-Transformer-for-Clothed-Avatar-Reconstruction" class="headerlink" title="Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction"></a>Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13524">http://arxiv.org/abs/2309.13524</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/river-zhang/gta">https://github.com/river-zhang/gta</a></li>
<li>paper_authors: Zechuan Zhang, Li Sun, Zongxin Yang, Ling Chen, Yi Yang</li>
<li>for:  reconstruction of 3D clothed human avatars from single images</li>
<li>methods: transformer-based architecture with global-correlated image features and 3D-decoupling decoder with cross-attention and learnable embeddings</li>
<li>results: outperforms state-of-the-art approaches in both geometry and texture reconstruction, with high robustness to challenging poses and loose clothing, and produces higher-resolution textures.Here’s the simplified Chinese text:</li>
<li>for: 用单张图像重建 clothed 人物模型</li>
<li>methods: 使用变换器建筑，利用全球相关的图像特征，并使用交叉注意力和学习嵌入来解耦三个平面特征</li>
<li>results: 在 CAPE 和 THuman2.0 数据集上表现出色，与现有方法相比，在几何和文本重建方面具有更高的精度和更高的纹理质量，并且具有更高的可靠性和更高的分辨率.<details>
<summary>Abstract</summary>
Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and prior-enhanced queries, leveraging the benefits of spatial localization and human body prior knowledge. Comprehensive experiments on CAPE and THuman2.0 datasets illustrate that our method outperforms state-of-the-art approaches in both geometry and texture reconstruction, exhibiting high robustness to challenging poses and loose clothing, and producing higher-resolution textures. Codes will be available at https://github.com/River-Zhang/GTA.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通过单个图像重建三维人物模拟是一项具有挑战性的任务，尤其是当遇到复杂的姿势和裤子时。现有方法具有不足的二维图像特征和不一致的查询方法，导致表现有限。为此，我们提出了全球相关的3D分解变换器（GTA），一种基于变换器架构的新建模，用于从单个图像中重建裤装人物模拟。我们的方法利用变换器模型作为编码器，以捕捉全球相关的图像特征。然后，我们的创新的3D分解解码器使用交叉注意力来分解三平面特征，并使用学习的嵌入作为交叉平面生成的查询。为了有效地增强特征融合三平面3D特征和人体先天知识，我们提议一种混合的先天知识融合策略，将空间和先天知识增强的查询混合使用，利用空间本地化和人体先天知识的优点。通过对CAPE和THuman2.0数据集进行广泛的实验，我们的方法在几何学和纹理重建方面超越了当前状态艺术，展现出高稳定性和高分辨率，并能够有效地处理复杂的姿势和裤子。代码将在https://github.com/River-Zhang/GTA上提供。
</details></li>
</ul>
<hr>
<h2 id="Cordyceps-LT-EDI-Depression-Detection-with-Reddit-and-Self-training"><a href="#Cordyceps-LT-EDI-Depression-Detection-with-Reddit-and-Self-training" class="headerlink" title="Cordyceps@LT-EDI: Depression Detection with Reddit and Self-training"></a>Cordyceps@LT-EDI: Depression Detection with Reddit and Self-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.01418">http://arxiv.org/abs/2310.01418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean Ninalga</li>
<li>for: 抑郁症是肇导病种之一，而且很普遍。研究发现过度社交媒体用户与抑郁症、ADHD等精神疾病存在相关性。鉴于这样一大量的人群，那么有很多可能未diagnosed的用户和他们创建的帖子。本文提出了一种抑郁严重程度检测系统，使用半指导学习技术预测用户是否经历严重、中度或低度（非诊断）抑郁。</li>
<li>methods: 我们使用一个训练好的模型来分类大量未标注的社交媒体帖子，然后使用生成的标签来训练更强大的分类器。</li>
<li>results: 我们在LT-EDI@RANLP 2023 shared task上展示了我们的框架，其中我们的框架在检测抑郁症的严重程度方面 ranks 3rd 总的。<details>
<summary>Abstract</summary>
Depression is debilitating, and not uncommon. Indeed, studies of excessive social media users show correlations with depression, ADHD, and other mental health concerns. Given that there is a large number of people with excessive social media usage, then there is a significant population of potentially undiagnosed users and posts that they create. In this paper, we propose a depression severity detection system using a semi-supervised learning technique to predict if a post is from a user who is experiencing severe, moderate, or low (non-diagnostic) levels of depression. Namely, we use a trained model to classify a large number of unlabelled social media posts from Reddit, then use these generated labels to train a more powerful classifier. We demonstrate our framework on Detecting Signs of Depression from Social Media Text - LT-EDI@RANLP 2023 shared task, where our framework ranks 3rd overall.
</details>
<details>
<summary>摘要</summary>
抑郁是毁伤性的，并不是罕见的。实际上，研究过度社交媒体用户表明了抑郁、ADHD和其他心理健康问题之间的相关性。 giventhat there is a large number of people with excessive social media usage, then there is a significant population of potentially undiagnosed users and posts that they create. 在这篇论文中，我们提出了一种抑郁严重程度检测系统，使用半指导学习技术来预测用户是否经历严重、中等或低（非诊断）度的抑郁。具体来说，我们使用一个训练好的模型来分类一大量的未标注社交媒体帖子，然后使用这些生成的标签来训练更强大的分类器。我们在LT-EDI@RANLP 2023共享任务上示出了我们的框架，其中我们的框架在总体排名第三。
</details></li>
</ul>
<hr>
<h2 id="Object-Classification-Model-Using-Ensemble-Learning-with-Gray-Level-Co-Occurrence-Matrix-and-Histogram-Extraction"><a href="#Object-Classification-Model-Using-Ensemble-Learning-with-Gray-Level-Co-Occurrence-Matrix-and-Histogram-Extraction" class="headerlink" title="Object Classification Model Using Ensemble Learning with Gray-Level Co-Occurrence Matrix and Histogram Extraction"></a>Object Classification Model Using Ensemble Learning with Gray-Level Co-Occurrence Matrix and Histogram Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13512">http://arxiv.org/abs/2309.13512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florentina Tatrin Kurniati, Daniel HF Manongga, Eko Sediyono, Sri Yulianto Joko Prasetyo, Roy Rudolf Huizen</li>
<li>for: 本研究旨在开发一种精准的物体分类方法，以便更好地识别和 отличать不同物体。</li>
<li>methods: 本研究使用了投票方法和组合分类器，其中包括Random Forest、K-NN、决策树、SVM和Naive Bayes等分类方法。</li>
<li>results: 测试结果表明，投票方法和组合分类器均取得了很好的结果，其中 ensemble voting 的准确率为92.4%，精度为78.6%，回归率为95.2%，F1-score为86.1%；组合分类器的准确率为99.3%，精度为97.6%，回归率为100%，F1-score为98.8%。根据测试结果，可以确定使用投票方法和组合分类器可以提高物体分类精度。<details>
<summary>Abstract</summary>
In the field of object classification, identification based on object variations is a challenge in itself. Variations include shape, size, color, and texture, these can cause problems in recognizing and distinguishing objects accurately. The purpose of this research is to develop a classification method so that objects can be accurately identified. The proposed classification model uses Voting and Combined Classifier, with Random Forest, K-NN, Decision Tree, SVM, and Naive Bayes classification methods. The test results show that the voting method and Combined Classifier obtain quite good results with each of them, ensemble voting with an accuracy value of 92.4%, 78.6% precision, 95.2% recall, and 86.1% F1-score. While the combined classifier with an accuracy value of 99.3%, a precision of 97.6%, a recall of 100%, and a 98.8% F1-score. Based on the test results, it can be concluded that the use of the Combined Classifier and voting methods is proven to increase the accuracy value. The contribution of this research increases the effectiveness of the Ensemble Learning method, especially the voting ensemble method and the Combined Classifier in increasing the accuracy of object classification in image processing.
</details>
<details>
<summary>摘要</summary>
在物体分类领域，基于物体变化的标识是一项挑战。这些变化包括形状、大小、颜色和文化，这些变化可能会导致对物体的识别和分类准确性受到影响。本研究的目的是开发一种精准的分类方法，以便更好地识别物体。提议的分类模型使用投票和组合分类器，其中包括随机森林、K-NN、决策树、支持向量机和愚蠢树分类方法。测试结果显示，投票方法和组合分类器各自取得了非常好的结果，其中投票方法的准确率为92.4%，命中率为78.6%，召回率为95.2%和准确率为86.1%。而组合分类器的准确率为99.3%，命中率为97.6%，召回率为100%和准确率为98.8%。根据测试结果，可以结论出，使用投票和组合分类器方法可以提高准确率。本研究的贡献是提高 ensemble learning 方法的效果，特别是投票ensemble方法和组合分类器在物体分类中的准确率。
</details></li>
</ul>
<hr>
<h2 id="Natural-Language-based-Context-Modeling-and-Reasoning-with-LLMs-A-Tutorial"><a href="#Natural-Language-based-Context-Modeling-and-Reasoning-with-LLMs-A-Tutorial" class="headerlink" title="Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial"></a>Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15074">http://arxiv.org/abs/2309.15074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyi Xiong, Jiang Bian, Sijia Yang, Xiaofei Zhang, Linghe Kong, Daqing Zhang</li>
<li>for: 这个研究是为了探讨大语言模型（LLM）在Context-aware computing中的应用，以及如何使用自然语言来建模上下文和进行上下文理解。</li>
<li>methods: 这个研究使用了各种人工智能技术，如 Ontology 和 OWL，来建模上下文和进行上下文理解。它还使用了自然语言处理技术，如 ChatGPT 和 GPT-4，来模拟用户的请求和上下文。</li>
<li>results: 研究人员在两个案例中证明了 LLMCaC 的可行性，包括在帮助生活中使用移动 z-arm 和规划旅行的上下文意识应用。<details>
<summary>Abstract</summary>
Large language models (LLMs) have become phenomenally surging, since 2018--two decades after introducing context-awareness into computing systems. Through taking into account the situations of ubiquitous devices, users and the societies, context-aware computing has enabled a wide spectrum of innovative applications, such as assisted living, location-based social network services and so on. To recognize contexts and make decisions for actions accordingly, various artificial intelligence technologies, such as Ontology and OWL, have been adopted as representations for context modeling and reasoning. Recently, with the rise of LLMs and their improved natural language understanding and reasoning capabilities, it has become feasible to model contexts using natural language and perform context reasoning by interacting with LLMs such as ChatGPT and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and autonomous agents (AutoAgents) that enable LLMs to perform context modeling and reasoning without requiring fine-tuning of the model. We organize and introduce works in the related field, and name this computing paradigm as the LLM-driven Context-aware Computing (LCaC). In the LCaC paradigm, users' requests, sensors reading data, and the command to actuators are supposed to be represented as texts. Given the text of users' request and sensor data, the AutoAgent models the context by prompting and sends to the LLM for context reasoning. LLM generates a plan of actions and responds to the AutoAgent, which later follows the action plan to foster context-awareness. To prove the concepts, we use two showcases--(1) operating a mobile z-arm in an apartment for assisted living, and (2) planning a trip and scheduling the itinerary in a context-aware and personalized manner.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在2018年以来，已经迅速增长，约二十年后引入了计算系统中的上下文意识。通过考虑设备、用户和社会的情况，上下文意识计算已经启动了一系列创新应用，例如协助生活、位置基于的社交网络服务等。为了识别上下文和根据此作出决策，人工智能技术，如 Ontology 和 OWL，已经被采用来表示上下文建模和推理。随着 LL M 的崛起和其改善的自然语言理解和推理能力，现在可以使用自然语言来建模上下文并通过与 LL M 交互，如 ChatGPT 和 GPT-4，进行上下文推理。在这个教程中，我们示例了使用文本、提示和自动代理（AutoAgent）来帮助 LL M 进行上下文建模和推理，不需要模型调整。我们组织和介绍相关领域的工作，并统称这个计算模式为 LLM-驱动的上下文意识计算（LCaC）。在 LCaC 模型中，用户的请求、感应器读取数据和 Command 到 actuator 是 supposed 为文本表示。当 AutoAgent 使用文本提示模型上下文时，LLM 将进行上下文推理，生成动作计划，并对 AutoAgent 回应。AutoAgent 接着根据动作计划进行行动，以实现上下文意识。为证明概念，我们使用了两个示例：在公寓内运作一个移动的 z-臂来协助生活，以及在上下文意识和个性化的方式规划旅行。
</details></li>
</ul>
<hr>
<h2 id="Guided-Cooperation-in-Hierarchical-Reinforcement-Learning-via-Model-based-Rollout"><a href="#Guided-Cooperation-in-Hierarchical-Reinforcement-Learning-via-Model-based-Rollout" class="headerlink" title="Guided Cooperation in Hierarchical Reinforcement Learning via Model-based Rollout"></a>Guided Cooperation in Hierarchical Reinforcement Learning via Model-based Rollout</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13508">http://arxiv.org/abs/2309.13508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoranwang-tj/gcmr_aclg_official">https://github.com/haoranwang-tj/gcmr_aclg_official</a></li>
<li>paper_authors: Haoran Wang, Yaoru Sun, Fang Wang, Yeming Chen</li>
<li>for: 这个论文的目的是提出一种goal-conditioned层次强化学习（HRL）框架，以便在复杂的长期强化学习任务中实现有效的探索。</li>
<li>methods: 这个论文使用了一种名为Guided Cooperation via Model-based Rollout（GCMR）的方法，该方法通过估算前向动力学来促进层次协作。此外，论文还使用了一种一步滚动计划来进一步促进层次协作。</li>
<li>results: 实验结果表明，将GCMR框架与ACLG（一种分离变体的HIGL）结合使用，可以比基eline和之前的状态 искусственный风险（SOTA）层次强化学习算法更加稳定和可靠地改进政策。<details>
<summary>Abstract</summary>
Goal-conditioned hierarchical reinforcement learning (HRL) presents a promising approach for enabling effective exploration in complex long-horizon reinforcement learning (RL) tasks via temporal abstraction. Yet, most goal-conditioned HRL algorithms focused on the subgoal discovery, regardless of inter-level coupling. In essence, for hierarchical systems, the increased inter-level communication and coordination can induce more stable and robust policy improvement. Here, we present a goal-conditioned HRL framework with Guided Cooperation via Model-based Rollout (GCMR), which estimates forward dynamics to promote inter-level cooperation. The GCMR alleviates the state-transition error within off-policy correction through a model-based rollout, further improving the sample efficiency. Meanwhile, to avoid being disrupted by these corrected but possibly unseen or faraway goals, lower-level Q-function gradients are constrained using a gradient penalty with a model-inferred upper bound, leading to a more stable behavioral policy. Besides, we propose a one-step rollout-based planning to further facilitate inter-level cooperation, where the higher-level Q-function is used to guide the lower-level policy by estimating the value of future states so that global task information is transmitted downwards to avoid local pitfalls. Experimental results demonstrate that incorporating the proposed GCMR framework with ACLG, a disentangled variant of HIGL, yields more stable and robust policy improvement than baselines and substantially outperforms previous state-of-the-art (SOTA) HRL algorithms in both hard-exploration problems and robotic control.
</details>
<details>
<summary>摘要</summary>
目标受控层次学习（HRL）提供了一种有效的探索方法，用于复杂的长期回归学习（RL）任务。然而，大多数目标受控HRL算法都专注于发现子目标，忽略了层次之间的交互。实际上，在层次系统中，增加层次之间的通信和协调可以提高稳定和可靠的策略改进。我们提出了一种目标受控HRL框架，称为指导合作via模型基于滚动（GCMR），该框架利用前向动力学预测来促进层次之间的合作。GCMR通过模型基于滚动来减少状态转移错误，从而提高样本效率。此外，我们还提出了一种一步滚动规划方法，以便更好地协调层次之间的行为策略。在这种方法中，高层Q函数用于指导低层策略，并且通过估算未来状态的值来传递全局任务信息下来，以避免地方坑拥。实验结果表明，将我们提出的GCMR框架与ACLG（一种分离的HIGL变体）结合使用，可以获得更稳定和可靠的策略改进，并在硬探索问题和机器人控制方面实现substantially outperform前一个状态的艺术algorithm。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/cs.AI_2023_09_24/" data-id="clpxp6bws004jee8828ajfq7f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/cs.CL_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T11:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/cs.CL_2023_09_24/">cs.CL - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Text-Classification-A-Perspective-of-Deep-Learning-Methods"><a href="#Text-Classification-A-Perspective-of-Deep-Learning-Methods" class="headerlink" title="Text Classification: A Perspective of Deep Learning Methods"></a>Text Classification: A Perspective of Deep Learning Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13761">http://arxiv.org/abs/2309.13761</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brijkishorsoni1210/Car-logo-classification">https://github.com/brijkishorsoni1210/Car-logo-classification</a></li>
<li>paper_authors: Zhongwei Wan</li>
<li>for: 本文旨在探讨深度学习方法在文本分类任务中的应用，以提高文本分类的准确率和效率。</li>
<li>methods: 本文 introduce了深度学习基于文本分类算法，包括特征提取、特征缩放和评价策略等重要步骤。</li>
<li>results: 文中对多种深度学习文本分类方法进行比较和总结，以便选择合适的方法 для实际应用。<details>
<summary>Abstract</summary>
In recent years, with the rapid development of information on the Internet, the number of complex texts and documents has increased exponentially, which requires a deeper understanding of deep learning methods in order to accurately classify texts using deep learning techniques, and thus deep learning methods have become increasingly important in text classification. Text classification is a class of tasks that automatically classifies a set of documents into multiple predefined categories based on their content and subject matter. Thus, the main goal of text classification is to enable users to extract information from textual resources and process processes such as retrieval, classification, and machine learning techniques together in order to classify different categories. Many new techniques of deep learning have already achieved excellent results in natural language processing. The success of these learning algorithms relies on their ability to understand complex models and non-linear relationships in data. However, finding the right structure, architecture, and techniques for text classification is a challenge for researchers. This paper introduces deep learning-based text classification algorithms, including important steps required for text classification tasks such as feature extraction, feature reduction, and evaluation strategies and methods. At the end of the article, different deep learning text classification methods are compared and summarized.
</details>
<details>
<summary>摘要</summary>
Recently, with the rapid development of information on the internet, the number of complex texts and documents has increased exponentially, requiring a deeper understanding of deep learning methods to accurately classify texts using deep learning techniques. As a result, deep learning methods have become increasingly important in text classification. Text classification is a type of task that automatically classifies a set of documents into multiple predefined categories based on their content and subject matter. Therefore, the main goal of text classification is to enable users to extract information from textual resources and perform processes such as retrieval, classification, and machine learning techniques together to classify different categories. Many new techniques of deep learning have already achieved excellent results in natural language processing. The success of these learning algorithms relies on their ability to understand complex models and non-linear relationships in data. However, finding the right structure, architecture, and techniques for text classification is a challenge for researchers. This paper introduces deep learning-based text classification algorithms, including important steps required for text classification tasks such as feature extraction, feature reduction, and evaluation strategies and methods. At the end of the article, different deep learning text classification methods are compared and summarized.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese writing systems. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Does-the-“most-sinfully-decadent-cake-ever”-taste-good-Answering-Yes-No-Questions-from-Figurative-Contexts"><a href="#Does-the-“most-sinfully-decadent-cake-ever”-taste-good-Answering-Yes-No-Questions-from-Figurative-Contexts" class="headerlink" title="Does the “most sinfully decadent cake ever” taste good? Answering Yes&#x2F;No Questions from Figurative Contexts"></a>Does the “most sinfully decadent cake ever” taste good? Answering Yes&#x2F;No Questions from Figurative Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13748">http://arxiv.org/abs/2309.13748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geetanjali Rakshit, Jeffrey Flanigan</li>
<li>for:  investigate the robustness of Question Answering (QA) models on figurative text</li>
<li>methods:  use yes&#x2F;no questions with figurative and non-figurative contexts to test the models’ ability to understand figurative language</li>
<li>results:  state-of-the-art BERT-based QA models perform poorly on figurative contexts, but models like GPT-3 and ChatGPT can handle them better, and further performance gains can be achieved by automatically simplifying the figurative contexts.<details>
<summary>Abstract</summary>
Figurative language is commonplace in natural language, and while making communication memorable and creative, can be difficult to understand. In this work, we investigate the robustness of Question Answering (QA) models on figurative text. Yes/no questions, in particular, are a useful probe of figurative language understanding capabilities of large language models. We propose FigurativeQA, a set of 1000 yes/no questions with figurative and non-figurative contexts, extracted from the domains of restaurant and product reviews. We show that state-of-the-art BERT-based QA models exhibit an average performance drop of up to 15\% points when answering questions from figurative contexts, as compared to non-figurative ones. While models like GPT-3 and ChatGPT are better at handling figurative texts, we show that further performance gains can be achieved by automatically simplifying the figurative contexts into their non-figurative (literal) counterparts. We find that the best overall model is ChatGPT with chain-of-thought prompting to generate non-figurative contexts. Our work provides a promising direction for building more robust QA models with figurative language understanding capabilities.
</details>
<details>
<summary>摘要</summary>
通用语言中的比喻语言非常普遍，它可以使交流更加生动、创新，但同时也可以使得理解变得更加困难。在这项工作中，我们研究了问答模型对比喻文本的Robustness。特别是yes/no问题，是 figural语言理解能力的一种有用的检验。我们提出了一个名为FigurativeQA的1000个yes/no问题的集合，其中包括了餐厅和产品评论中的figural和非 figural上下文。我们发现，当问答模型回答figural上下文中的问题时，其性能会下降15%左右，相比于非 figural上下文。虽然模型如GPT-3和ChatGPT能够更好地处理figural语言，但我们发现可以通过自动将figural上下文简化成非 figural（literal）上下文来提高性能。我们发现最佳的模型是ChatGPT加chain-of-thought提示，可以生成非 figural上下文。我们的工作提供了构建更加Robust的问答模型的可能方向。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Relations-Classification-using-Imbalanced-Predictions-Adaptation"><a href="#Multiple-Relations-Classification-using-Imbalanced-Predictions-Adaptation" class="headerlink" title="Multiple Relations Classification using Imbalanced Predictions Adaptation"></a>Multiple Relations Classification using Imbalanced Predictions Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13718">http://arxiv.org/abs/2309.13718</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sa5r/mrca">https://github.com/sa5r/mrca</a></li>
<li>paper_authors: Sakher Khalil Alqaaidi, Elika Bozorgi, Krzysztof J. Kochut</li>
<li>for: 这个论文主要用于关系分类任务中处理多个关系的问题。</li>
<li>methods: 该模型使用自定义输出架构和采用额外输入特征来解决不均匀预测问题。</li>
<li>results: 对于一些常用的数据集，模型表现出了显著的改善，尤其是在处理不均匀预测的情况下。<details>
<summary>Abstract</summary>
The relation classification task assigns the proper semantic relation to a pair of subject and object entities; the task plays a crucial role in various text mining applications, such as knowledge graph construction and entities interaction discovery in biomedical text. Current relation classification models employ additional procedures to identify multiple relations in a single sentence. Furthermore, they overlook the imbalanced predictions pattern. The pattern arises from the presence of a few valid relations that need positive labeling in a relatively large predefined relations set. We propose a multiple relations classification model that tackles these issues through a customized output architecture and by exploiting additional input features. Our findings suggest that handling the imbalanced predictions leads to significant improvements, even on a modest training design. The results demonstrate superiority performance on benchmark datasets commonly used in relation classification. To the best of our knowledge, this work is the first that recognizes the imbalanced predictions within the relation classification task.
</details>
<details>
<summary>摘要</summary>
“关系分类任务是将对象和主题实体对应的Semantic关系分类为正确的类别，这个任务在文本挖掘应用中扮演着关键角色，如知识图构建和生物医学文本中实体互动发现。现有关系分类模型采用多种方法来识别单句中的多个关系，但它们忽略了不均匀预测模式。这种模式来自于一些有效的关系，它们需要在大量预定的关系集中得到正面标注。我们提出了一种多关系分类模型，通过自定义输出架构和采用额外输入特征来解决这些问题。我们的发现表明，处理不均匀预测可以取得显著改善，即使在较小的训练设计下。结果表明我们的模型在常用的 benchmark 数据集上显示出了优秀的表现，并且根据我们所知，这是第一个认可关系分类任务中的不均匀预测问题的研究。”
</details></li>
</ul>
<hr>
<h2 id="MentaLLaMA-Interpretable-Mental-Health-Analysis-on-Social-Media-with-Large-Language-Models"><a href="#MentaLLaMA-Interpretable-Mental-Health-Analysis-on-Social-Media-with-Large-Language-Models" class="headerlink" title="MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models"></a>MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13567">http://arxiv.org/abs/2309.13567</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stevekgyang/mentallama">https://github.com/stevekgyang/mentallama</a></li>
<li>paper_authors: Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Sophia Ananiadou, Jimin Huang</li>
<li>for: 这个论文的目的是为了提供一个可解释的心理健康分析方法，使用大语言模型来提供详细的解释，并在社交媒体上进行自动心理健康分析。</li>
<li>methods: 这个论文使用了ChatGPT来生成可解释的回答，并使用专家写的少量提示来提高模型的性能。</li>
<li>results: 研究结果显示，MentalLLaMA可以与状态艺术方法匹配，并且生成高质量的解释。<details>
<summary>Abstract</summary>
With the development of web technology, social media texts are becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear the problem of low interpretability, the recent large language models have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions. The results show that ChatGPT can generate approaching-human explanations for its correct classifications. However, LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner. Domain-specific finetuning is an effective solution, but faces 2 challenges: 1) lack of high-quality training data. 2) no open-source LLMs for interpretable mental health analysis were released to lower the finetuning cost. To alleviate these problems, we build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset on social media, with 105K data samples. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We use expert-written few-shot prompts and collected labels to prompt ChatGPT and obtain explanations from its responses. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA, the first open-source LLM series for interpretable mental health analysis with instruction-following capability. We also evaluate the performance of MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their correctness for making predictions and the quality of explanations are examined. The results show that MentalLLaMA approaches state-of-the-art discriminative methods in correctness and generates high-quality explanations.
</details>
<details>
<summary>摘要</summary>
随着网络技术的发展，社交媒体文本正在成为自动心理健康分析的丰富来源。传统的排除性方法具有低可解释性问题，而最近的大语言模型在社交媒体上进行可解释心理健康分析，旨在提供详细的解释以及预测。结果显示，ChatGPT可以生成接近人类解释的正确分类结果。然而，LLMs仍在零容量/几容量情况下实现不满足的分类性能。预处理特定领域的训练是有效的解决方案，但面临两个挑战：1）缺乏高质量训练数据。2）没有开源LLMs для可解释心理健康分析，以降低训练成本。为解决这些问题，我们建立了首个多任务多源可解释心理健康指令（IMHI）数据集，包括105W个数据样本。 raw社交媒体数据由10个现有源收集，覆盖8个心理健康分析任务。我们使用专家写的少量示例和收集的标签来提取ChatGPT的回答，并对其生成的数据进行严格的自动和人类评估，以确保数据的正确性、一致性和质量。基于IMHI数据集和LLaMA2基础模型，我们训练了心理LLaMA，首个开源LLM系列 для可解释心理健康分析，并实现了指令遵循能力。我们还对IMHI评估标准测试集进行了10个测试集的性能评估，其中正确性和生成的解释质量均进行了评估。结果显示，心理LLaMA与状态艺术方法相当，并生成高质量的解释。
</details></li>
</ul>
<hr>
<h2 id="Substituting-Data-Annotation-with-Balanced-Updates-and-Collective-Loss-in-Multi-label-Text-Classification"><a href="#Substituting-Data-Annotation-with-Balanced-Updates-and-Collective-Loss-in-Multi-label-Text-Classification" class="headerlink" title="Substituting Data Annotation with Balanced Updates and Collective Loss in Multi-label Text Classification"></a>Substituting Data Annotation with Balanced Updates and Collective Loss in Multi-label Text Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13543">http://arxiv.org/abs/2309.13543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muberra Ozmen, Joseph Cotnareanu, Mark Coates</li>
<li>for: 这篇论文的目的是解决多标签文本分类（MLTC）任务，并且在没有足够标签数据的情况下进行分类。</li>
<li>methods: 本篇论文使用了自然语言推理来将输入文本转换为初步的标签可能性分布，然后使用标签描述来计算一个标签依赖关系表，最后使用讯息传递法更新初步的标签可能性分布，使用一个集体损失函数来注入预期的标签频率和预期的多标签卡дина优化。</li>
<li>results: 实验结果显示，提案的框架在具有仅具有几个标签的低监控情况下可以获得有效的性能，并且相比使用预训语言模型时，提案的方法可以提高性能 BY 70%。<details>
<summary>Abstract</summary>
Multi-label text classification (MLTC) is the task of assigning multiple labels to a given text, and has a wide range of application domains. Most existing approaches require an enormous amount of annotated data to learn a classifier and/or a set of well-defined constraints on the label space structure, such as hierarchical relations which may be complicated to provide as the number of labels increases. In this paper, we study the MLTC problem in annotation-free and scarce-annotation settings in which the magnitude of available supervision signals is linear to the number of labels. Our method follows three steps, (1) mapping input text into a set of preliminary label likelihoods by natural language inference using a pre-trained language model, (2) calculating a signed label dependency graph by label descriptions, and (3) updating the preliminary label likelihoods with message passing along the label dependency graph, driven with a collective loss function that injects the information of expected label frequency and average multi-label cardinality of predictions. The experiments show that the proposed framework achieves effective performance under low supervision settings with almost imperceptible computational and memory overheads added to the usage of pre-trained language model outperforming its initial performance by 70\% in terms of example-based F1 score.
</details>
<details>
<summary>摘要</summary>
多标签文本分类（MLTC）是将多个标签分配给一个文本的任务，具有广泛的应用领域。大多数现有方法需要巨大量的注释数据来学习一个分类器和/或一组定义的约束，例如层次关系，这些约束可能会变得复杂，特别是当标签数量增加时。在这篇论文中，我们研究了在无注释和缺乏注释的设置下进行MLTC问题。我们的方法包括以下三步：1. 将输入文本映射到一组初步的标签可能性，使用一个预训练的自然语言模型进行自然语言推理。2. 计算一个签名标签依赖图，使用标签描述来计算。3. 更新初步的标签可能性，使用消息传递算法在标签依赖图上进行更新，驱动一个集体损失函数，该函数注入预期的标签频率和预测多个标签 cardinality的信息。实验表明，我们的框架在低级注释设置下达到了有效性，并且增加了非常小的计算和存储开销，相对于使用预训练自然语言模型的使用，提高了70%的例子基于F1分数。
</details></li>
</ul>
<hr>
<h2 id="The-Study-of-Perceptual-Training-of-Chinese-Mandarin-Tones-for-Monolingual-Speakers-of-English-Using-Adaptive-Computer-Based-Training-Software"><a href="#The-Study-of-Perceptual-Training-of-Chinese-Mandarin-Tones-for-Monolingual-Speakers-of-English-Using-Adaptive-Computer-Based-Training-Software" class="headerlink" title="The Study of Perceptual Training of Chinese Mandarin Tones for Monolingual Speakers of English Using Adaptive Computer Based Training Software"></a>The Study of Perceptual Training of Chinese Mandarin Tones for Monolingual Speakers of English Using Adaptive Computer Based Training Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13513">http://arxiv.org/abs/2309.13513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuke Wang</li>
<li>for: 这个研究探讨了一种新的声调训练技术，可能对第二语言学习和声调训练产生积极影响。</li>
<li>methods: 该研究使用了一种新的声调训练技术，该技术基于语音识别和生成技术，可以帮助学生更好地学习和理解声调。</li>
<li>results: 研究发现，使用该新技术可以提高学生对声调的识别和生成能力，并且可以帮助学生更好地理解和使用声调。<details>
<summary>Abstract</summary>
The study explored a new technique of phonetic tone training, which may have a positive impact on second language learning and tone training.
</details>
<details>
<summary>摘要</summary>
研究探讨了一种新的声音训练技巧，这种技巧可能对第二语言学习和声音训练产生积极影响。Here's a breakdown of the translation:研究 (study)探讨 (explored)一种 (a new)声音 (phonetic)训练 (training)技巧 (technique)可能 (may)对 (positive impact on)第二语言 (second language)学习 (learning)和 (and)声音 (tone)训练 (training)产生 (have a positive impact)
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/cs.CL_2023_09_24/" data-id="clpxp6bz400chee884gdobdkh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/cs.LG_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T10:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/cs.LG_2023_09_24/">cs.LG - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Design-Principles-of-Robust-Multi-Armed-Bandit-Framework-in-Video-Recommendations"><a href="#Design-Principles-of-Robust-Multi-Armed-Bandit-Framework-in-Video-Recommendations" class="headerlink" title="Design Principles of Robust Multi-Armed Bandit Framework in Video Recommendations"></a>Design Principles of Robust Multi-Armed Bandit Framework in Video Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.01419">http://arxiv.org/abs/2310.01419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Belhassen Bayar, Phanideep Gampa, Ainur Yessenalina, Zhen Wen</li>
<li>for: 提出了一种新的多臂弓箭推荐系统设计原则，以抵御时变metadata信号的影响，避免item杀死和数据稀缺导致的弓箭模型异常。</li>
<li>methods: 提出了三种设计原则，包括：一、使用时变metadata信号进行适应；二、避免item杀死和数据稀缺导致弓箭模型异常；三、避免弓箭模型 weights 频繁变化。</li>
<li>results: 通过系列实验，证明了提出的设计原则的优势，包括：在ROC-AUC和PR-AUC中提高了相对增量达到11.88%和44.85%，并在推荐特定受欢迎和不受欢迎标题时保持了公平性。<details>
<summary>Abstract</summary>
Current multi-armed bandit approaches in recommender systems (RS) have focused more on devising effective exploration techniques, while not adequately addressing common exploitation challenges related to distributional changes and item cannibalization. Little work exists to guide the design of robust bandit frameworks that can address these frequent challenges in RS. In this paper, we propose a new design principles to (i) make bandit models robust to time-variant metadata signals, (ii) less prone to item cannibalization, and (iii) prevent their weights fluctuating due to data sparsity. Through a series of experiments, we systematically examine the influence of several important bandit design choices. We demonstrate the advantage of our proposed design principles at making bandit models robust to dynamic behavioral changes through in-depth analyses. Noticeably, we show improved relative gain compared to a baseline bandit model not incorporating our design choices of up to $11.88\%$ and $44.85\%$, respectively in ROC-AUC and PR-AUC. Case studies about fairness in recommending specific popular and unpopular titles are presented, to demonstrate the robustness of our proposed design at addressing popularity biases.
</details>
<details>
<summary>摘要</summary>
当前多臂罂缸方法在推荐系统（RS）中更多地关注了发展有效探索技术，而不够注意常见的利用探索挑战，如分布变化和物品吃掉。现有的工作不够引导设计Robust罂缸框架，以解决这些常见挑战。在这篇论文中，我们提出了一些新的设计原则，以使罂缸模型更加Robust于时变元数据信号， menos可害性和数据稀缺性。通过一系列实验，我们系统地检验了一些重要的罂缸设计选择的影响。我们示出了我们提出的设计原则的优势，使罂缸模型更加Robust于动态行为变化，并提高了相对增量比例，分别为11.88%和44.85%。我们还对推荐特定受欢迎和不受欢迎标题的公平性进行了案例研究，以示出我们的设计方法能够解决受欢迎性偏见。
</details></li>
</ul>
<hr>
<h2 id="The-Rashomon-Importance-Distribution-Getting-RID-of-Unstable-Single-Model-based-Variable-Importance"><a href="#The-Rashomon-Importance-Distribution-Getting-RID-of-Unstable-Single-Model-based-Variable-Importance" class="headerlink" title="The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance"></a>The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13775">http://arxiv.org/abs/2309.13775</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jdonnelly36/Rashomon_Importance_Distribution">https://github.com/jdonnelly36/Rashomon_Importance_Distribution</a></li>
<li>paper_authors: Jon Donnelly, Srikar Katta, Cynthia Rudin, Edward P. Browne</li>
<li>for: 这paper的目的是提出一种新的变量重要性评估框架，以便在不同的模型和数据集中Quantifying variable importance，并且可以针对不同的数据分布进行稳定的评估。</li>
<li>methods: 这paper使用了一种新的变量重要性评估方法，它可以考虑所有可能的解释，并且可以在不同的数据分布下保持稳定性。这个方法可以与大多数现有的模型类型和全局变量重要性指标集成。</li>
<li>results: 实验表明，这paper的方法可以在复杂的模拟场景中成功地评估变量重要性，并且可以准确地估计变量重要性的真实排名。此外，这paper还提供了理论保证和 finite sample error rates的分析，以及一个实际案例研究，以证明这paper的方法在实际应用中的效用。<details>
<summary>Abstract</summary>
Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We demonstrate through experiments that our framework recovers variable importance rankings for complex simulation setups where other methods fail. Further, we show that our framework accurately estimates the true importance of a variable for the underlying data distribution. We provide theoretical guarantees on the consistency and finite sample error rates for our estimator. Finally, we demonstrate its utility with a real-world case study exploring which genes are important for predicting HIV load in persons with HIV, highlighting an important gene that has not previously been studied in connection with HIV. Code is available here.
</details>
<details>
<summary>摘要</summary>
量化变量重要性是解决高负荷问题的关键在遗传学、公共政策和医学等领域。现有的方法通常计算变量重要性为给定模型和给定数据集中的。然而，对于给定数据集，可能有多个模型都能够准确地预测目标结果，而不同的研究人员可能因数据而得出不同的、尚未得到证明的结论。此外，即使考虑所有可能的解释，这些发现也可能不会普适化，因为不同的数据变换可能会导致不同的优秀模型。我们提出了一个新的变量重要性框架，可以评估变量重要性在所有好的模型中，并且在数据分布下是稳定的。我们的框架非常灵活，可以与大多数现有的模型类型和全局变量重要性度量结合使用。我们通过实验表明，我们的框架可以在复杂的模拟设置中成功地重新分配变量重要性。此外，我们证明了我们的框架可以准确地估计变量重要性的真实值，并提供了理论保证变量重要性的一致性和 finite sample error rate。最后，我们通过一个实际的案例研究，探讨了抑制HIV荷重的关键基因，并发现了一个没有在HIV相关研究中受到过关注的重要基因。代码可以在这里找到。
</details></li>
</ul>
<hr>
<h2 id="Improving-Robustness-of-Deep-Convolutional-Neural-Networks-via-Multiresolution-Learning"><a href="#Improving-Robustness-of-Deep-Convolutional-Neural-Networks-via-Multiresolution-Learning" class="headerlink" title="Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning"></a>Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13752">http://arxiv.org/abs/2309.13752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyan Zhou, Yao Liang</li>
<li>for: 提高深度学习模型的鲁棒性，包括对1D信号和2D图像预测问题的鲁棒性。</li>
<li>methods: 使用多分辨率学习，并证明多分辨率学习可以显著提高深度学习模型的鲁棒性，包括随机噪声和敌意攻击的鲁棒性。</li>
<li>results: our results show that multiresolution learning can significantly improve the robustness of DNN models for both 1D signal and 2D signal (image) prediction problems, and that this improvement can be achieved with small training dataset size and without sacrificing standard accuracy.<details>
<summary>Abstract</summary>
The current learning process of deep learning, regardless of any deep neural network (DNN) architecture and/or learning algorithm used, is essentially a single resolution training. We explore multiresolution learning and show that multiresolution learning can significantly improve robustness of DNN models for both 1D signal and 2D signal (image) prediction problems. We demonstrate this improvement in terms of both noise and adversarial robustness as well as with small training dataset size. Our results also suggest that it may not be necessary to trade standard accuracy for robustness with multiresolution learning, which is, interestingly, contrary to the observation obtained from the traditional single resolution learning setting.
</details>
<details>
<summary>摘要</summary>
当前深度学习的学习过程，无论使用哪种深度神经网络（DNN）架构和学习算法，都是单分辨率训练。我们研究多分辨率学习，并证明多分辨率学习可以显著提高深度神经网络模型对1D信号和2D图像预测问题的鲁棒性。我们通过对噪声和攻击性诊断的改进来证明这一点，同时也发现了训练集大小的影响。我们的结果还表明，在多分辨率学习Setting中，可能不需要在标准准确率和鲁棒性之间进行权衡，这与传统单分辨率学习Setting中所获得的观察相反。
</details></li>
</ul>
<hr>
<h2 id="Generative-Residual-Diffusion-Modeling-for-Km-scale-Atmospheric-Downscaling"><a href="#Generative-Residual-Diffusion-Modeling-for-Km-scale-Atmospheric-Downscaling" class="headerlink" title="Generative Residual Diffusion Modeling for Km-scale Atmospheric Downscaling"></a>Generative Residual Diffusion Modeling for Km-scale Atmospheric Downscaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15214">http://arxiv.org/abs/2309.15214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morteza Mardani, Noah Brenowitz, Yair Cohen, Jaideep Pathak, Chieh-Yu Chen, Cheng-Chin Liu, Arash Vahdat, Karthik Kashinath, Jan Kautz, Mike Pritchard</li>
<li>for: 这篇论文旨在提供一种可靠且cost-effective的物理隐患预测方法，以取代现有的 expensive km-scale数值 simulations。</li>
<li>methods: 这篇论文使用了一种叫做 ResDiff 的 two-step方法，其中第一步使用了一个（UNet）回归模型预测 Mean，第二步使用了一个扩散模型预测 Residual。这个方法可以对不同的物理过程和不同的尺度进行适当的调整。</li>
<li>results: 这篇论文的结果显示了 ResDiff 方法在 bulk RMSE 和 CRPS  scores 方面表现出了鼓舞人的能力。它还可以实现准确地预测风暴中的重要力学特征，例如降水和风速的分布。case studies 也显示了 ResDiff 方法在不同的气候现象中的适当运作。<details>
<summary>Abstract</summary>
The state of the art for physical hazard prediction from weather and climate requires expensive km-scale numerical simulations driven by coarser resolution global inputs. Here, a km-scale downscaling diffusion model is presented as a cost effective alternative. The model is trained from a regional high-resolution weather model over Taiwan, and conditioned on ERA5 reanalysis data. To address the downscaling uncertainties, large resolution ratios (25km to 2km), different physics involved at different scales and predict channels that are not in the input data, we employ a two-step approach (\textit{ResDiff}) where a (UNet) regression predicts the mean in the first step and a diffusion model predicts the residual in the second step. \textit{ResDiff} exhibits encouraging skill in bulk RMSE and CRPS scores. The predicted spectra and distributions from ResDiff faithfully recover important power law relationships regulating damaging wind and rain extremes. Case studies of coherent weather phenomena reveal appropriate multivariate relationships reminiscent of learnt physics. This includes the sharp wind and temperature variations that co-locate with intense rainfall in a cold front, and the extreme winds and rainfall bands that surround the eyewall of typhoons. Some evidence of simultaneous bias correction is found. A first attempt at downscaling directly from an operational global forecast model successfully retains many of these benefits. The implication is that a new era of fully end-to-end, global-to-regional machine learning weather prediction is likely near at hand.
</details>
<details>
<summary>摘要</summary>
现代物理危机预测技术需要使用高resolution数值 simulate，这些 simulate 通常需要很多的计算资源和高resolution的全球输入数据。在这篇文章中，我们提出了一种cost-effective的km级下采 diffusion模型，作为一种alternative。这个模型在台湾地区高resolution天气模型上训练，并使用ERA5分析数据进行条件。为了 Addressing downscaling uncertainties, we employ a two-step approach（ResDiff），其中一个（UNet）回归预报mean，而另一个是diffusion模型预报差异。ResDiff exhibits encouraging skill in bulk RMSE和CRPS分数。预测的spectrum和分布从ResDiff faithful recover了重要的power law关系，这些关系控制了wind和rain extrema的formation。case studies of coherent weather phenomena reveal appropriate multivariate relationships reminiscent of learnt physics, such as the sharp wind and temperature variations that co-locate with intense rainfall in a cold front, and the extreme winds and rainfall bands that surround the eyewall of typhoons。有些证据表明同时进行偏差修正。我们首次尝试了直接从运行的全球预测模型下采，成功保留了大多数的优点。这表明一个全新的end-to-end, global-to-regional机器学习天气预测时代可能即将到来。
</details></li>
</ul>
<hr>
<h2 id="Geometry-of-Linear-Neural-Networks-Equivariance-and-Invariance-under-Permutation-Groups"><a href="#Geometry-of-Linear-Neural-Networks-Equivariance-and-Invariance-under-Permutation-Groups" class="headerlink" title="Geometry of Linear Neural Networks: Equivariance and Invariance under Permutation Groups"></a>Geometry of Linear Neural Networks: Equivariance and Invariance under Permutation Groups</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13736">http://arxiv.org/abs/2309.13736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kathlén Kohn, Anna-Laura Sattelberger, Vahid Shahverdi</li>
<li>for:  investigate the subvariety of functions that are equivariant or invariant under the action of a permutation group.</li>
<li>methods: explicit description of their dimension, degree, Euclidean distance degree, and singularities.</li>
<li>results: fully characterize invariance for arbitrary permutation groups, and equivariance for cyclic groups, and prove that all invariant linear functions can be learned by linear autoencoders.Here’s the same information in Traditional Chinese:</li>
<li>for: 研究对应 Permutation group 的函数子集，包括对称函数和对称函数。</li>
<li>methods: 提供对应函数的精确描述，包括次数、度量、欧几何级数和缺陷。</li>
<li>results: 完全描述任意 Permutation group 的对称性，以及循环群的对称性，并证明所有对称函数可以通过线性自动化学习。<details>
<summary>Abstract</summary>
The set of functions parameterized by a linear fully-connected neural network is a determinantal variety. We investigate the subvariety of functions that are equivariant or invariant under the action of a permutation group. Examples of such group actions are translations or $90^\circ$ rotations on images. For such equivariant or invariant subvarieties, we provide an explicit description of their dimension, their degree as well as their Euclidean distance degree, and their singularities. We fully characterize invariance for arbitrary permutation groups, and equivariance for cyclic groups. We draw conclusions for the parameterization and the design of equivariant and invariant linear networks, such as a weight sharing property, and we prove that all invariant linear functions can be learned by linear autoencoders.
</details>
<details>
<summary>摘要</summary>
Set of functions parameterized by linear fully-connected neural network is a determinantal variety. We investigate subvariety of functions that are equivariant or invariant under action of permutation group. Examples of such group actions include translations or $90^\circ$ rotations on images. For such equivariant or invariant subvarieties, we provide explicit description of their dimension, degree, Euclidean distance degree, and singularities. We fully characterize invariance for arbitrary permutation groups and equivariance for cyclic groups. We draw conclusions for parameterization and design of equivariant and invariant linear networks, including weight sharing property, and prove that all invariant linear functions can be learned by linear autoencoders.
</details></li>
</ul>
<hr>
<h2 id="Towards-Tuning-Free-Minimum-Volume-Nonnegative-Matrix-Factorization"><a href="#Towards-Tuning-Free-Minimum-Volume-Nonnegative-Matrix-Factorization" class="headerlink" title="Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization"></a>Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13733">http://arxiv.org/abs/2309.13733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duc Toan Nguyen, Eric C. Chi</li>
<li>for: 这篇论文主要是为了探讨缺量矩阵因子分解（NMF）在数据矩阵中发现隐藏结构的方法。</li>
<li>methods: 这篇论文提出了一种基于最小体积的NMF方法，可以在噪声存在的情况下可靠地还原缺量矩阵。</li>
<li>results: 这篇论文提出了一种不需要选择医学参数的NMF方法，并且提供了一种基于主化最小化的逐步算法来实现。 employing this method, the authors show that the optimal choice of the tuning parameter is insensitive to the noise level in the data.<details>
<summary>Abstract</summary>
Nonnegative Matrix Factorization (NMF) is a versatile and powerful tool for discovering latent structures in data matrices, with many variations proposed in the literature. Recently, Leplat et al.\@ (2019) introduced a minimum-volume NMF for the identifiable recovery of rank-deficient matrices in the presence of noise. The performance of their formulation, however, requires the selection of a tuning parameter whose optimal value depends on the unknown noise level. In this work, we propose an alternative formulation of minimum-volume NMF inspired by the square-root lasso and its tuning-free properties. Our formulation also requires the selection of a tuning parameter, but its optimal value does not depend on the noise level. To fit our NMF model, we propose a majorization-minimization (MM) algorithm that comes with global convergence guarantees. We show empirically that the optimal choice of our tuning parameter is insensitive to the noise level in the data.
</details>
<details>
<summary>摘要</summary>
非负矩阵分解（NMF）是一种多变性强大的工具，用于找到数据矩阵中隐藏的结构，文献中有多种提案。最近，Leplat等人（2019）提出了一种可 identificable 的 minimum-volume NMF，用于在噪声存在的情况下 recuperate 缺rank 矩阵。然而，其表现需要选择一个调整参数，该参数的优化值取决于未知的噪声水平。在这篇文章中，我们提出了一种基于平方减法和其调整参数不виси的 minimum-volume NMF 形式化。我们的形式化也需要选择一个调整参数，但该参数的优化值不取决于噪声水平。为了适应我们的 NMF 模型，我们提出了一种majorization-minimization（MM）算法，该算法来with global convergence guarantees。我们通过实验表明，我们的调整参数的优化值对噪声水平的影响不大。
</details></li>
</ul>
<hr>
<h2 id="Deep-neural-networks-with-ReLU-leaky-ReLU-and-softplus-activation-provably-overcome-the-curse-of-dimensionality-for-Kolmogorov-partial-differential-equations-with-Lipschitz-nonlinearities-in-the-L-p-sense"><a href="#Deep-neural-networks-with-ReLU-leaky-ReLU-and-softplus-activation-provably-overcome-the-curse-of-dimensionality-for-Kolmogorov-partial-differential-equations-with-Lipschitz-nonlinearities-in-the-L-p-sense" class="headerlink" title="Deep neural networks with ReLU, leaky ReLU, and softplus activation provably overcome the curse of dimensionality for Kolmogorov partial differential equations with Lipschitz nonlinearities in the $L^p$-sense"></a>Deep neural networks with ReLU, leaky ReLU, and softplus activation provably overcome the curse of dimensionality for Kolmogorov partial differential equations with Lipschitz nonlinearities in the $L^p$-sense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13722">http://arxiv.org/abs/2309.13722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Ackermann, Arnulf Jentzen, Thomas Kruse, Benno Kuckuck, Joshua Lee Padgett</li>
<li>for: 这些深度学习方法用于近似高维partial differential equations（PDEs）的批处。</li>
<li>methods: 这些方法使用的是深度神经网络（DNNs），并且使用了ReLU激活函数。</li>
<li>results: 这些方法可以在PDEs中超越几何约束（COD），即计算量只增长为 polynomial 函数，而不是几何函数。这些方法还可以在$L^p$ norm下与高维PDE解决方法进行比较。<details>
<summary>Abstract</summary>
Recently, several deep learning (DL) methods for approximating high-dimensional partial differential equations (PDEs) have been proposed. The interest that these methods have generated in the literature is in large part due to simulations which appear to demonstrate that such DL methods have the capacity to overcome the curse of dimensionality (COD) for PDEs in the sense that the number of computational operations they require to achieve a certain approximation accuracy $\varepsilon\in(0,\infty)$ grows at most polynomially in the PDE dimension $d\in\mathbb N$ and the reciprocal of $\varepsilon$. While there is thus far no mathematical result that proves that one of such methods is indeed capable of overcoming the COD, there are now a number of rigorous results in the literature that show that deep neural networks (DNNs) have the expressive power to approximate PDE solutions without the COD in the sense that the number of parameters used to describe the approximating DNN grows at most polynomially in both the PDE dimension $d\in\mathbb N$ and the reciprocal of the approximation accuracy $\varepsilon>0$. Roughly speaking, in the literature it is has been proved for every $T>0$ that solutions $u_d\colon [0,T]\times\mathbb R^d\to \mathbb R$, $d\in\mathbb N$, of semilinear heat PDEs with Lipschitz continuous nonlinearities can be approximated by DNNs with ReLU activation at the terminal time in the $L^2$-sense without the COD provided that the initial value functions $\mathbb R^d\ni x\mapsto u_d(0,x)\in\mathbb R$, $d\in\mathbb N$, can be approximated by ReLU DNNs without the COD. It is the key contribution of this work to generalize this result by establishing this statement in the $L^p$-sense with $p\in(0,\infty)$ and by allowing the activation function to be more general covering the ReLU, the leaky ReLU, and the softplus activation functions as special cases.
</details>
<details>
<summary>摘要</summary>
近些时候，一些深度学习（DL）方法用于近似高维partial differential equations（PDEs）已经被提出。这些方法在文献中引起了广泛的关注，主要是因为这些方法可以在computational operations上减少高维维度的影响，即“掌数之咎”（COD）。虽然没有现有的数学结论证明其中一种方法可以完全超越COD，但现在有一些文献证明了深度神经网络（DNNs）具有表达力可以在PDE维度$d\in\mathbb N$和reciprocal of approximation accuracy $\varepsilon>0$之间 polynomially增长。粗略地说，在文献中已经证明了，对于任意$T>0$，solutions $u_d\colon [0,T]\times\mathbb R^d\to \mathbb R$, $d\in\mathbb N$, of semilinear heat PDEs with Lipschitz continuous nonlinearities可以通过DNNs with ReLU activation在终点时间 уровнем$L^2$上无COD的方式进行approximation， provided that the initial value functions $\mathbb R^d\ni x\mapsto u_d(0,x)\in\mathbb R$, $d\in\mathbb N$,可以通过ReLU DNNs without COD进行approximation。这是本研究的关键贡献，是通过将这个结论推广到$L^p$ norm中($p\in(0,\infty)$)，并允许activation function可以是更加一般的，涵盖ReLU、泄漏ReLU和softplus activation function的特殊情况。
</details></li>
</ul>
<hr>
<h2 id="Federated-Deep-Multi-View-Clustering-with-Global-Self-Supervision"><a href="#Federated-Deep-Multi-View-Clustering-with-Global-Self-Supervision" class="headerlink" title="Federated Deep Multi-View Clustering with Global Self-Supervision"></a>Federated Deep Multi-View Clustering with Global Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13697">http://arxiv.org/abs/2309.13697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Chen, Jie Xu, Yazhou Ren, Xiaorong Pu, Ce Zhu, Xiaofeng Zhu, Zhifeng Hao, Lifang He</li>
<li>for: 本研究旨在Addressing the challenges of incomplete multi-view data in distributed environments, where label information is unknown and data privacy must be preserved.</li>
<li>methods: 我们提出了一种novel federated deep multi-view clustering方法，包括sample alignment和data extension技术，以探索多个视图中的 complementary cluster结构。在服务器环境中，我们提出了一种global prototype和global pseudo-label的分布方式，以帮助客户端学习自我supervised信息。在客户端环境中，多个客户端使用全球自我supervised信息和深度自适应神经网络来学习视图特定的归一化分类结果和嵌入特征，并将其上传到服务器进行自我supervised信息的修正。</li>
<li>results: 我们的广泛实验结果表明，我们提出的方法可以有效地解决多视图数据的不完整性和隐私担忧问题，并且表现出色。<details>
<summary>Abstract</summary>
Federated multi-view clustering has the potential to learn a global clustering model from data distributed across multiple devices. In this setting, label information is unknown and data privacy must be preserved, leading to two major challenges. First, views on different clients often have feature heterogeneity, and mining their complementary cluster information is not trivial. Second, the storage and usage of data from multiple clients in a distributed environment can lead to incompleteness of multi-view data. To address these challenges, we propose a novel federated deep multi-view clustering method that can mine complementary cluster structures from multiple clients, while dealing with data incompleteness and privacy concerns. Specifically, in the server environment, we propose sample alignment and data extension techniques to explore the complementary cluster structures of multiple views. The server then distributes global prototypes and global pseudo-labels to each client as global self-supervised information. In the client environment, multiple clients use the global self-supervised information and deep autoencoders to learn view-specific cluster assignments and embedded features, which are then uploaded to the server for refining the global self-supervised information. Finally, the results of our extensive experiments demonstrate that our proposed method exhibits superior performance in addressing the challenges of incomplete multi-view data in distributed environments.
</details>
<details>
<summary>摘要</summary>
“联合多视角聚类”有可能从多个设备上的数据学习全球聚类模型。在这个设定下，标签信息未知，且需保持数据隐私，导致两个主要挑战。首先，不同客户的视野常有特征差异，采集其辅助聚类结构不单简。其次，在分布式环境中存储和使用多个客户的数据可能会导致多视角数据的不完整性。为解决这些挑战，我们提出了一个新的联合深度多视角聚类方法。在服务器环境中，我们提出了样本Alignment和数据扩展技术来探索多个视野之间的辅助聚类结构。服务器随后将全球原型和全球伪标给每个客户作为全球自我超级信息。在客户环境中，每个客户使用全球自我超级信息和深度自适应器来学习视野特定的聚类分配和嵌入特征，然后将结果上传到服务器进行改进全球自我超级信息。最后，我们的广泛实验结果显示，我们的提议方法在实际中处理多视角数据的不完整性时表现出色。”
</details></li>
</ul>
<hr>
<h2 id="Performance-Evaluation-of-Equal-Weight-Portfolio-and-Optimum-Risk-Portfolio-on-Indian-Stocks"><a href="#Performance-Evaluation-of-Equal-Weight-Portfolio-and-Optimum-Risk-Portfolio-on-Indian-Stocks" class="headerlink" title="Performance Evaluation of Equal-Weight Portfolio and Optimum Risk Portfolio on Indian Stocks"></a>Performance Evaluation of Equal-Weight Portfolio and Optimum Risk Portfolio on Indian Stocks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13696">http://arxiv.org/abs/2309.13696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhiraj Sen, Jaydip Sen<br>for: 这个论文目的是为了设计一个最佳投资组合，使得投资组合的返回和风险得到优化。methods: 这篇论文使用了三种方法来设计投资组合，包括最小风险方法、最大返回方法和等权分配方法。results: 根据实际股票市场数据，这篇论文发现了三个投资组合，每个组合包括10家公司，可以最大化返回和最小化风险。这些组合的性能被评估于2022年1月1日至2022年12月31日的股票价格数据上，并与市场数据进行比较。<details>
<summary>Abstract</summary>
Designing an optimum portfolio for allocating suitable weights to its constituent assets so that the return and risk associated with the portfolio are optimized is a computationally hard problem. The seminal work of Markowitz that attempted to solve the problem by estimating the future returns of the stocks is found to perform sub-optimally on real-world stock market data. This is because the estimation task becomes extremely challenging due to the stochastic and volatile nature of stock prices. This work illustrates three approaches to portfolio design minimizing the risk, optimizing the risk, and assigning equal weights to the stocks of a portfolio. Thirteen critical sectors listed on the National Stock Exchange (NSE) of India are first chosen. Three portfolios are designed following the above approaches choosing the top ten stocks from each sector based on their free-float market capitalization. The portfolios are designed using the historical prices of the stocks from Jan 1, 2017, to Dec 31, 2022. The portfolios are evaluated on the stock price data from Jan 1, 2022, to Dec 31, 2022. The performances of the portfolios are compared, and the portfolio yielding the higher return for each sector is identified.
</details>
<details>
<summary>摘要</summary>
设计最佳投资组合，以优化投资组合的回报和风险，是一个计算复杂的问题。markowitz的基础工作，尝试通过估算未来股票回报来解决问题，发现在实际股市数据上表现下相对较差。这是因为估算任务在股票价格的随机和波动性下变得极其困难。本文介绍了三种方法来设计投资组合，即最小化风险、最大化回报和均衡分配股票。选择了13个关键领域的上市公司（NSE）在印度股市。根据每个领域的自由悬挂市值，选择了每个领域的前十名股票。使用历史股票价格从2017年1月1日到2022年12月31日，设计了三个投资组合。对于2022年1月1日到2022年12月31日的股票价格，评估了投资组合的表现。对每个领域，比较了投资组合的表现，并标识出每个领域的最高回报投资组合。
</details></li>
</ul>
<hr>
<h2 id="Regularization-and-Optimal-Multiclass-Learning"><a href="#Regularization-and-Optimal-Multiclass-Learning" class="headerlink" title="Regularization and Optimal Multiclass Learning"></a>Regularization and Optimal Multiclass Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13692">http://arxiv.org/abs/2309.13692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Asilis, Siddartha Devic, Shaddin Dughmi, Vatsal Sharan, Shang-Hua Teng</li>
<li>for:  This paper is written to study the role of regularization in multiclass learning with arbitrary label sets, and to introduce optimal learning algorithms that incorporate regularization using one-inclusion graphs (OIGs).</li>
<li>methods: The paper uses OIGs to exhibit optimal learning algorithms that relax structural risk minimization on two dimensions: allowing the regularization function to be “local” to datapoints, and using an unsupervised learning stage to learn this regularizer at the outset. The paper also introduces a combinatorial sequence called the Hall complexity, which is the first to characterize a problem’s transductive error rate exactly.</li>
<li>results: The paper shows that the introduced optimal learner relaxes structural risk minimization on two dimensions and uses an unsupervised learning stage to learn a regularizer at the outset. The paper also demonstrates that an agnostic version of the Hall complexity characterizes error rates exactly, and exhibits an optimal learner using maximum entropy programs.<details>
<summary>Abstract</summary>
The quintessential learning algorithm of empirical risk minimization (ERM) is known to fail in various settings for which uniform convergence does not characterize learning. It is therefore unsurprising that the practice of machine learning is rife with considerably richer algorithmic techniques for successfully controlling model capacity. Nevertheless, no such technique or principle has broken away from the pack to characterize optimal learning in these more general settings.   The purpose of this work is to characterize the role of regularization in perhaps the simplest setting for which ERM fails: multiclass learning with arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal learning algorithms that dovetail with tried-and-true algorithmic principles: Occam's Razor as embodied by structural risk minimization (SRM), the principle of maximum entropy, and Bayesian reasoning. Most notably, we introduce an optimal learner which relaxes structural risk minimization on two dimensions: it allows the regularization function to be "local" to datapoints, and uses an unsupervised learning stage to learn this regularizer at the outset. We justify these relaxations by showing that they are necessary: removing either dimension fails to yield a near-optimal learner. We also extract from OIGs a combinatorial sequence we term the Hall complexity, which is the first to characterize a problem's transductive error rate exactly.   Lastly, we introduce a generalization of OIGs and the transductive learning setting to the agnostic case, where we show that optimal orientations of Hamming graphs -- judged using nodes' outdegrees minus a system of node-dependent credits -- characterize optimal learners exactly. We demonstrate that an agnostic version of the Hall complexity again characterizes error rates exactly, and exhibit an optimal learner using maximum entropy programs.
</details>
<details>
<summary>摘要</summary>
《 Quintessential 学习算法的实际风险最小化（ERM）在各种设置下失败，因此 machine learning 实践中的许多更加复杂的算法技巧成功地控制模型容量。然而，没有任何技巧或原则能够在更一般的设置下Characterize 优化学习。》本文的目的是在多类学习中使用一 inclusion 图（OIGs）来Characterize 识别器的角色，并使用structural risk minimization（SRM）、最大Entropy 原则和 Bayesian 思维来定义优化学习算法。我们介绍了一个优化学习算法，它在两个维度上relax 了SRM：允许正则化函数在数据点上本地化，并在无监督学习阶段使用一个不supervised 学习来学习这个正则化器。我们证明了这些relaxation 是必要的， otherwise 不能得到近似优化学习算法。我们还从 OIGs 中提取了一个 combinatorial sequence，我们称之为 Hall complexity，它可以 exactly Characterize 问题的推导性错误率。 finally，我们将 OIGs 和推导学习设定扩展到agnostic 情况下，并证明在这种情况下，optimal  orientations of Hamming graphs（judged by nodes' outdegrees minus a system of node-dependent credits）Characterize 优化学习算法 exactly。我们还证明了agnostic 版本的 Hall complexity 可以 exactly Characterize 错误率，并展示了一个使用最大Entropy 程序的优化学习算法。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Large-Batch-Training-via-Gradient-Signal-to-Noise-Ratio-GSNR"><a href="#Accelerating-Large-Batch-Training-via-Gradient-Signal-to-Noise-Ratio-GSNR" class="headerlink" title="Accelerating Large Batch Training via Gradient Signal to Noise Ratio (GSNR)"></a>Accelerating Large Batch Training via Gradient Signal to Noise Ratio (GSNR)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13681">http://arxiv.org/abs/2309.13681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guo-qing Jiang, Jinlong Liu, Zixiang Ding, Lin Guo, Wei Lin</li>
<li>for: 这paper的目的是提高大批量（LB）训练的通过率，但是训练LB任务经常遇到大的泛化差和下降最终精度，限制了扩大批量大小。</li>
<li>methods: 这paper提出了基于偏差信号噪声比（GSNR）的偏差减少技术（VRGD），并应用于流行的优化器 such as SGD&#x2F;Adam&#x2F;LARS&#x2F;LAMB。 authors还进行了关于整体趋势的分析和一般化分析，以解释它的快速训练动态和更小的泛化差。</li>
<li>results: 实验表明，VRGD可以加速训练（1-2倍），缩小泛化差和提高最终精度。 authors推进BERT预训练的批量大小到128k&#x2F;64k和DLRM到512k，而无需影响精度。 ImageNet Top-1准确率在96k上提高了0.52pp，比LARS更高。 总的来说，这paper的研究可以大幅减少BERT和ImageNet训练中的泛化差。<details>
<summary>Abstract</summary>
As models for nature language processing (NLP), computer vision (CV) and recommendation systems (RS) require surging computation, a large number of GPUs/TPUs are paralleled as a large batch (LB) to improve training throughput. However, training such LB tasks often meets large generalization gap and downgrades final precision, which limits enlarging the batch size. In this work, we develop the variance reduced gradient descent technique (VRGD) based on the gradient signal to noise ratio (GSNR) and apply it onto popular optimizers such as SGD/Adam/LARS/LAMB. We carry out a theoretical analysis of convergence rate to explain its fast training dynamics, and a generalization analysis to demonstrate its smaller generalization gap on LB training. Comprehensive experiments demonstrate that VRGD can accelerate training ($1\sim 2 \times$), narrow generalization gap and improve final accuracy. We push the batch size limit of BERT pretraining up to 128k/64k and DLRM to 512k without noticeable accuracy loss. We improve ImageNet Top-1 accuracy at 96k by $0.52pp$ than LARS. The generalization gap of BERT and ImageNet training is significantly reduce by over $65\%$.
</details>
<details>
<summary>摘要</summary>
为了提高自然语言处理（NLP）、计算机视觉（CV）和推荐系统（RS）的训练效率，常常使用大量的GPUs/TPUs并行为大批（LB）训练。然而，这些LB任务的训练经常会遇到大的泛化差异和下降最终精度，从而限制扩大批处理的大小。在这种情况下，我们开发了基于梯度信号噪声比（GSNR）的减少梯度下降技术（VRGD），并应用于流行的优化器如SGD/Adam/LAMB/LARS。我们进行了理论分析的速度和稳定性，以及通用的泛化分析，以证明它的快速训练特性和更小的泛化差异。实验表明，VRGD可以提高训练速度（1-2倍），缩小泛化差异和提高最终精度。我们把BERT预训练的批处理大小提高到128k/64k，而DLRM的批处理大小提高到512k，无需注意到精度下降。在ImageNet顶层1任务中，我们提高了LARS的性能，比原来的LARS提高了0.52pp。总的来说，我们通过减少BERT和ImageNet训练中的泛化差异，将其降低了65%以上。
</details></li>
</ul>
<hr>
<h2 id="Topology-Agnostic-Detection-of-Temporal-Money-Laundering-Flows-in-Billion-Scale-Transactions"><a href="#Topology-Agnostic-Detection-of-Temporal-Money-Laundering-Flows-in-Billion-Scale-Transactions" class="headerlink" title="Topology-Agnostic Detection of Temporal Money Laundering Flows in Billion-Scale Transactions"></a>Topology-Agnostic Detection of Temporal Money Laundering Flows in Billion-Scale Transactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13662">http://arxiv.org/abs/2309.13662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haseeb Tariq, Marwan Hassani</li>
<li>for: 这篇论文是为了探讨针对财务洗钱措施的检测系统弱点，并利用多个银行账户、层次化和转移 transactions 来隐藏财富的来源和流动。</li>
<li>methods: 该论文提出了一种名为 FaSTMAN 的框架，采用域特定约束适应而建立了一个时间图示 sequential transactions，并使用二阶 Graph 表示法来评估边的重要性。</li>
<li>results: 对于一个包含多个大 european 银行交易的数据集，该框架表现出了明显的高效性和实用性，在比较两种现有的探测恶意流动交易方法时。<details>
<summary>Abstract</summary>
Money launderers exploit the weaknesses in detection systems by purposefully placing their ill-gotten money into multiple accounts, at different banks. That money is then layered and moved around among mule accounts to obscure the origin and the flow of transactions. Consequently, the money is integrated into the financial system without raising suspicion. Path finding algorithms that aim at tracking suspicious flows of money usually struggle with scale and complexity. Existing community detection techniques also fail to properly capture the time-dependent relationships. This is particularly evident when performing analytics over massive transaction graphs. We propose a framework (called FaSTMAN), adapted for domain-specific constraints, to efficiently construct a temporal graph of sequential transactions. The framework includes a weighting method, using 2nd order graph representation, to quantify the significance of the edges. This method enables us to distribute complex queries on smaller and densely connected networks of flows. Finally, based on those queries, we can effectively identify networks of suspicious flows. We extensively evaluate the scalability and the effectiveness of our framework against two state-of-the-art solutions for detecting suspicious flows of transactions. For a dataset of over 1 Billion transactions from multiple large European banks, the results show a clear superiority of our framework both in efficiency and usefulness.
</details>
<details>
<summary>摘要</summary>
贩卖洗钱者利用检测系统的弱点，故意将黑钱分布到多个帐户，不同银行的帐户中。然后将这笔钱层层转移，以隐藏起点和转移流动的关系。因此，黑钱能够融入金融系统，无需引起怀疑。跟踪款流的算法通常在规模和复杂性方面遇到困难。现有社区检测技术也无法正确捕捉时间关系。特别是在处理庞大交易图时，这些技术的表现很差。我们提出了一个名为FaSTMAN的框架，适应域pecific约束，以生成Sequential Transactions的 temporal graph。该框架包括一种Edge重量方法，使用二次graph表示法，以衡量边的重要性。这种方法允许我们将复杂的查询分配到更小的、紧密连接的网络上。最后，基于这些查询，我们可以有效地认定涉嫌的款流网络。我们对两个国际领先的检测涉嫌款流解决方案进行了广泛的评估，并对一个包含多个大European银行的交易数据集进行了广泛的测试。结果表明，我们的框架在效率和有用性方面具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Fantastic-Generalization-Measures-are-Nowhere-to-be-Found"><a href="#Fantastic-Generalization-Measures-are-Nowhere-to-be-Found" class="headerlink" title="Fantastic Generalization Measures are Nowhere to be Found"></a>Fantastic Generalization Measures are Nowhere to be Found</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13658">http://arxiv.org/abs/2309.13658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Gastpar, Ido Nachum, Jonathan Shafer, Thomas Weinberger</li>
<li>for: 这个论文旨在探讨神经网络在过参数 Setting 下的泛化能力，以及相关的一般化 bound 的可能性。</li>
<li>methods: 作者使用了一些常见的一般化 bound 类型，包括依赖于训练集和输出学习算法的 bound，以及依赖于训练集和学习算法的稳定 bound。</li>
<li>results: 作者通过数学分析和实验研究发现，在过参数 Setting 下，无论使用哪种一般化 bound，都无法保证一般化能力的准确性。此外，如果学习算法在某些分布上具有良好的准确率，那么一般化 bound 就无法 uniformly 紧张。因此，作者结论认为，在过参数 Setting 下，一般化 bound 无法是紧张的，除非有适当的Assumption  sobre 人口分布。<details>
<summary>Abstract</summary>
Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, none of these bounds are tight. For instance, in their paper ``Fantastic Generalization Measures and Where to Find Them'', Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them imply guarantees that can explain the remarkable performance of neural networks. This raises the question of whether tight generalization bounds are at all possible. We consider two types of generalization bounds common in the literature: (1) bounds that depend on the training set and the output of the learning algorithm. There are multiple bounds of this type in the literature (e.g., norm-based and margin-based bounds), but we prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that depend on the training set and on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm's performance and the bound's tightness. Namely, if the algorithm achieves good accuracy on certain distributions in the overparameterized setting, then no generalization bound can be tight for it. We conclude that generalization bounds in the overparameterized setting cannot be tight without suitable assumptions on the population distribution.
</details>
<details>
<summary>摘要</summary>
很多通用 bound 在文献中被提出，以解释神经网络在过参数化设置下的泛化能力。然而，这些 bound 都不是紧张的。例如，在他们的 paper "Fantastic Generalization Measures and Where to Find Them" 中， Jiang et al. (2020)  examine over a dozen generalization bound, and show empirically that none of them can provide guarantees that can explain the remarkable performance of neural networks.这引起了是否存在紧张的 generalization bound 的问题。我们考虑了文献中两种常见的 generalization bound：1. 依赖于训练集和学习算法的 bound。文献中有多种这类 bound（例如，norm-based和margin-based bound），但我们证明了在过参数化设置下，无法得到一个 uniformly 紧张的 bound。2. 依赖于训练集和学习算法的 bound。例如，stability bound。我们显示出在某些分布下，如果学习算法 achieves 良好的准确率，那么不可能有一个紧张的 bound。我们结论是，在过参数化设置下，generalization bound 不可能是紧张的，除非有适当的人口分布假设。
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Model-for-Data-Redundancy-in-the-Feature-Domain"><a href="#A-Probabilistic-Model-for-Data-Redundancy-in-the-Feature-Domain" class="headerlink" title="A Probabilistic Model for Data Redundancy in the Feature Domain"></a>A Probabilistic Model for Data Redundancy in the Feature Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13657">http://arxiv.org/abs/2309.13657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ghurumuruhan Ganesan</li>
<li>for: 这个论文是用概率模型来估算大量数据中具有低相关性和低多相关性的特征数量。</li>
<li>methods: 这个论文使用概率方法来获得相同顺序的上下限，用于估算具有低相关性和低多相关性的特征集的大小。</li>
<li>results: 论文提供了一种用于估算大量数据中具有低相关性和低多相关性的特征集的方法，并证明了一个关于互助约束集的辅助结果，这结果是独立有价值的。<details>
<summary>Abstract</summary>
In this paper, we use a probabilistic model to estimate the number of uncorrelated features in a large dataset. Our model allows for both pairwise feature correlation (collinearity) and interdependency of multiple features (multicollinearity) and we use the probabilistic method to obtain upper and lower bounds of the same order, for the size of a feature set that exhibits low collinearity and low multicollinearity. We also prove an auxiliary result regarding mutually good constrained sets that is of independent interest.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们使用一种 probabilistic 模型来估计大数据集中具有低相关性的特征数量。我们的模型允许对特征之间的对比关系（杂相关）以及多个特征之间的相互关系（多相关），并使用 probabilistic 方法获取同样的订正范围，以便确定具有低相关性和低多相关性的特征集的大小。我们还证明了一个有益的副结果，即具有互助约束的特征集是独立有价值的。
</details></li>
</ul>
<hr>
<h2 id="REWAFL-Residual-Energy-and-Wireless-Aware-Participant-Selection-for-Efficient-Federated-Learning-over-Mobile-Devices"><a href="#REWAFL-Residual-Energy-and-Wireless-Aware-Participant-Selection-for-Efficient-Federated-Learning-over-Mobile-Devices" class="headerlink" title="REWAFL: Residual Energy and Wireless Aware Participant Selection for Efficient Federated Learning over Mobile Devices"></a>REWAFL: Residual Energy and Wireless Aware Participant Selection for Efficient Federated Learning over Mobile Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13643">http://arxiv.org/abs/2309.13643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Y. Li, X. Qin, J. Geng, R. Chen, Y. Hou, Y. Gong, M. Pan, P. Zhang</li>
<li>for: 本文旨在提高 federated learning（FL）训练的速度和效率，并且解决移动设备的剩余能量和无线传输速率的影响。</li>
<li>methods: 本文提出了一种基于剩余能量和无线传输速率的PS设计方法，其中引入了一个新的PS价值函数，该价值函数同时考虑了全局FL训练价值和本地能量价值。此外，本文还提出了一种基于REWAFL的剩余能量和无线传输速率aware的本地计算策略。</li>
<li>results: 实验结果表明，REWAFL可以提高训练精度和效率，同时避免移动设备”耗尽电池”的问题。<details>
<summary>Abstract</summary>
Participant selection (PS) helps to accelerate federated learning (FL) convergence, which is essential for the practical deployment of FL over mobile devices. While most existing PS approaches focus on improving training accuracy and efficiency rather than residual energy of mobile devices, which fundamentally determines whether the selected devices can participate. Meanwhile, the impacts of mobile devices' heterogeneous wireless transmission rates on PS and FL training efficiency are largely ignored. Moreover, PS causes the staleness issue. Prior research exploits isolated functions to force long-neglected devices to participate, which is decoupled from original PS designs. In this paper, we propose a residual energy and wireless aware PS design for efficient FL training over mobile devices (REWAFL). REW AFL introduces a novel PS utility function that jointly considers global FL training utilities and local energy utility, which integrates energy consumption and residual battery energy of candidate mobile devices. Under the proposed PS utility function framework, REW AFL further presents a residual energy and wireless aware local computing policy. Besides, REWAFL buries the staleness solution into its utility function and local computing policy. The experimental results show that REW AFL is effective in improving training accuracy and efficiency, while avoiding "flat battery" of mobile devices.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a residual energy and wireless aware PS design for efficient FL training over mobile devices (REWAFL). The proposed PS utility function jointly considers global FL training utilities and local energy utility, which integrates energy consumption and residual battery energy of candidate mobile devices. Under the proposed PS utility function framework, REW AFL further presents a residual energy and wireless aware local computing policy. Moreover, REWAFL buries the staleness solution into its utility function and local computing policy.The experimental results show that REWAFL is effective in improving training accuracy and efficiency while avoiding "flat battery" of mobile devices.
</details></li>
</ul>
<hr>
<h2 id="Crack-Net-Prediction-of-Crack-Propagation-in-Composites"><a href="#Crack-Net-Prediction-of-Crack-Propagation-in-Composites" class="headerlink" title="Crack-Net: Prediction of Crack Propagation in Composites"></a>Crack-Net: Prediction of Crack Propagation in Composites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13626">http://arxiv.org/abs/2309.13626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Xu, Wei Fan, Ambrose C. Taylor, Dongxiao Zhang, Lecheng Ruan, Rundong Shi</li>
<li>for: 这篇论文的目的是来提供一个基于深度学习的材料分子破坏预测模型，以便在结构应用中提高材料性能和微struktural设计。</li>
<li>methods: 这篇论文使用了一个名为Crack-Net的深度学习框架，这个框架可以模拟材料的破坏过程，并且可以考虑不同的微struktural设计。</li>
<li>results: 这篇论文的结果显示，Crack-Net可以高度准确地预测材料的破坏模式和压缩曲线，并且可以处理更复杂的微struktural设计。<details>
<summary>Abstract</summary>
Computational solid mechanics has become an indispensable approach in engineering, and numerical investigation of fracture in composites is essential as composites are widely used in structural applications. Crack evolution in composites is the bridge to elucidate the relationship between the microstructure and fracture performance, but crack-based finite element methods are computationally expensive and time-consuming, limiting their application in computation-intensive scenarios. Here we propose a deep learning framework called Crack-Net, which incorporates the relationship between crack evolution and stress response to predict the fracture process in composites. Trained on a high-precision fracture development dataset generated using the phase field method, Crack-Net demonstrates a remarkable capability to accurately forecast the long-term evolution of crack growth patterns and the stress-strain curve for a given composite design. The Crack-Net captures the essential principle of crack growth, which enables it to handle more complex microstructures such as binary co-continuous structures. Moreover, transfer learning is adopted to further improve the generalization ability of Crack-Net for composite materials with reinforcements of different strengths. The proposed Crack-Net holds great promise for practical applications in engineering and materials science, in which accurate and efficient fracture prediction is crucial for optimizing material performance and microstructural design.
</details>
<details>
<summary>摘要</summary>
computation solid mechanics 已成为工程领域必备的方法，数字调查对于复合材料的裂解是必要的，因为复合材料广泛应用于结构应用。 裂解进程中的裂解演化在复合材料中是关键，但是基于裂解的finite element方法 computationally expensive 和时间consuming，这限制了它们在 computation-intensive enario 中的应用。 我们提出了一个深度学习框架，叫做Crack-Net，它包含了裂解演化和压力应答之间的关系，以预测复合材料的裂解过程。 Crack-Net 在一个高精度的裂解发展数据集上训练，该数据集使用阶段场方法生成。 Crack-Net 能够准确预测复合材料的长期裂解趋势和压力-弹簧曲线。 Crack-Net 捕捉了裂解的基本原理，因此可以处理更复杂的微结构，例如二元共晶结构。 此外，我们采用了传输学习来进一步提高 Crack-Net 对于不同强度的增强材料的泛化能力。 我们提出的 Crack-Net 具有实际应用的潜在价值，在工程和材料科学中，准确和高效地预测裂解是关键的，以便优化材料性能和微结构设计。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Enhanced-Autoregressive-Feature-Transformation-Gradient-steered-Search-in-Continuous-Space-for-Postfix-Expressions"><a href="#Reinforcement-Enhanced-Autoregressive-Feature-Transformation-Gradient-steered-Search-in-Continuous-Space-for-Postfix-Expressions" class="headerlink" title="Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions"></a>Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13618">http://arxiv.org/abs/2309.13618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjie Wang, Meng Xiao, Min Wu, Pengfei Wang, Yuanchun Zhou, Yanjie Fu</li>
<li>for: This paper aims to improve the efficiency and effectiveness of feature transformation for machine learning tasks by reformulating the discrete search space into a continuous optimization task.</li>
<li>methods: The proposed method includes four steps: (1) reinforcement-enhanced data preparation, (2) feature transformation operation sequence embedding, (3) gradient-steered optimal embedding search, and (4) transformation operation sequence reconstruction.</li>
<li>results: The proposed method is expected to fundamentally fill the gap between efficiency and stability&#x2F;robustness in feature transformation, and to provide a more effective and efficient way to optimize feature transformation for machine learning tasks.<details>
<summary>Abstract</summary>
Feature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifices stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space.
</details>
<details>
<summary>摘要</summary>
<<SYS>>功能转换targets于生成新的特征分布，以提高下游机器学习（ML）任务表现。然而，原始特征的逐渐扩展的搜索空间会急剧增长，从低阶形式到高阶形式。现有的方法，如枚举搜索、减少扩展、进化算法、强化学习和迭代蜂巢，都受到搜索空间的限制。强调效率在算法设计中通常会牺牲稳定性或可靠性。为了彻底填补这个差距，我们将离散特征转换重新定义为连续空间优化任务，并开发一个嵌入优化重建框架。这个框架包括以下四个步骤：1. 增强驱动数据准备，目的是为特征转换精度训练数据做准备;2. 特征转换操作序列嵌入，旨在将准备好的训练数据中的知识嵌入到连续空间中;3. 梯度导航优化搜索，旨在在学习空间中找到可能更高质量的嵌入;4. 特征转换操作序列重建，努力将特征转换解决方案复制到特定的特征空间，以确定最佳特征空间。
</details></li>
</ul>
<hr>
<h2 id="DPA-WNO-A-gray-box-model-for-a-class-of-stochastic-mechanics-problem"><a href="#DPA-WNO-A-gray-box-model-for-a-class-of-stochastic-mechanics-problem" class="headerlink" title="DPA-WNO: A gray box model for a class of stochastic mechanics problem"></a>DPA-WNO: A gray box model for a class of stochastic mechanics problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15128">http://arxiv.org/abs/2309.15128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tushar, Souvik Chakraborty</li>
<li>for: 解决数据驱动模型缺乏解释性、占据大量数据和不能泛化问题，提出了数据物理融合方法，并提出了一种新的可微分物理增强波лет神经网络操作器（DPA-WNO），将数据驱动模型和物理解决方法融合在一起，以便利用数据驱动模型学习 FROM 数据，同时保留物理解决方法的解释性和泛化能力。</li>
<li>methods: 提出的DPA-WNO结合了可微分物理解决方法和波лет神经网络操作器，使得该方法可以利用数据驱动模型学习 FROM 数据，同时保留物理解决方法的解释性和泛化能力。</li>
<li>results: 对四个不同领域的科学和工程中的时间不确定性量化和可靠性分析问题进行了解决，并得到了有趣的结果，表明该方法可以有效地解决数据驱动模型中的缺乏解释性、占据大量数据和不能泛化等问题。<details>
<summary>Abstract</summary>
The well-known governing physics in science and engineering is often based on certain assumptions and approximations. Therefore, analyses and designs carried out based on these equations are also approximate. The emergence of data-driven models has, to a certain degree, addressed this challenge; however, the purely data-driven models often (a) lack interpretability, (b) are data-hungry, and (c) do not generalize beyond the training window. Operator learning has recently been proposed as a potential alternative to address the aforementioned challenges; however, the challenges are still persistent. We here argue that one of the possible solutions resides in data-physics fusion, where the data-driven model is used to correct/identify the missing physics. To that end, we propose a novel Differentiable Physics Augmented Wavelet Neural Operator (DPA-WNO). The proposed DPA-WNO blends a differentiable physics solver with the Wavelet Neural Operator (WNO), where the role of WNO is to model the missing physics. This empowers the proposed framework to exploit the capability of WNO to learn from data while retaining the interpretability and generalizability associated with physics-based solvers. We illustrate the applicability of the proposed approach in solving time-dependent uncertainty quantification problems due to randomness in the initial condition. Four benchmark uncertainty quantification and reliability analysis examples from various fields of science and engineering are solved using the proposed approach. The results presented illustrate interesting features of the proposed approach.
</details>
<details>
<summary>摘要</summary>
科学和工程中常见的管理物理是基于某些假设和简化的。因此，基于这些方程的分析和设计也是有误差的。数据驱动模型的出现有所解决了这个挑战，但是纯数据驱动模型常有两个缺点：一是不可解释性，二是吃掉数据。运维学学习已经被提议为可能的解决方案之一，但是这些挑战仍然存在。我们认为一种可能的解决方案在数据物理融合中，其中数据驱动模型用于 corrections/identification of missing physics。为此，我们提出了一种新的可微分物理增强波let神经网络算法（DPA-WNO）。我们的提议的DPA-WNO将一个可微分物理解决器与波let神经网络（WNO）融合在一起，WNO用于模拟缺失的物理。这使得我们的框架能够利用WNO从数据中学习，同时保持与物理基础模型相关的可解释性和泛化性。我们通过解决时间依赖不确定性量化和可靠性分析问题来证明提议的方法的可行性。我们在不同的科学和工程领域中使用提议的方法解决了四个标准不确定性量化和可靠性分析问题的例子。结果表明了我们的方法的有趣特点。
</details></li>
</ul>
<hr>
<h2 id="Self-Tuning-Hamiltonian-Monte-Carlo-for-Accelerated-Sampling"><a href="#Self-Tuning-Hamiltonian-Monte-Carlo-for-Accelerated-Sampling" class="headerlink" title="Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling"></a>Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13593">http://arxiv.org/abs/2309.13593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henrik Christiansen, Federico Errica, Francesco Alesiani</li>
<li>for: 本研究旨在自动调整哈密顿 Monte Carlo 方法的参数，以便快速探索参数空间。</li>
<li>methods: 本研究使用了完全可微分的设置和反射传播来优化参数。 furthermore, an attention-like loss is defined to allow for the gradient-driven learning of the distribution of integration steps.</li>
<li>results: 我们在一维振荡子和艾莫对蛋白质中进行了实验，发现我们的损失和自参数的散度之间存在良好的对映，从而获得了快速参数的调整。<details>
<summary>Abstract</summary>
The performance of Hamiltonian Monte Carlo crucially depends on its parameters, in particular the integration timestep and the number of integration steps. We present an adaptive general-purpose framework to automatically tune these parameters based on a loss function which promotes the fast exploration of phase-space. For this, we make use of a fully-differentiable set-up and use backpropagation for optimization. An attention-like loss is defined which allows for the gradient driven learning of the distribution of integration steps. We also highlight the importance of jittering for a smooth loss-surface. Our approach is demonstrated for the one-dimensional harmonic oscillator and alanine dipeptide, a small protein common as a test-case for simulation methods. We find a good correspondence between our loss and the autocorrelation times, resulting in well-tuned parameters for Hamiltonian Monte Carlo.
</details>
<details>
<summary>摘要</summary>
Hamiltonian Monte Carlo 的性能取决于它的参数，特别是 интеграル时步和integration step的数量。我们提出了一种自适应通用框架，通过损函数来促进快速探索phaspace的分布。我们利用了完全导数的设置，并使用反射进行优化。我们定义了一种注意力类损函数，允许通过梯度驱动学习的integration step的分布。我们 также强调了在损函数Surface上的缓冲作用。我们的方法在一维振荡体和 Alanine dipeptide 上进行了示例，发现我们的损函数和自相关时间之间存在良好的匹配，从而获得了良好地调整的 Hamiltonian Monte Carlo 参数。
</details></li>
</ul>
<hr>
<h2 id="Robust-Distributed-Learning-Tight-Error-Bounds-and-Breakdown-Point-under-Data-Heterogeneity"><a href="#Robust-Distributed-Learning-Tight-Error-Bounds-and-Breakdown-Point-under-Data-Heterogeneity" class="headerlink" title="Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity"></a>Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13591">http://arxiv.org/abs/2309.13591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youssef Allouah, Rachid Guerraoui, Nirupam Gupta, Rafaël Pinot, Geovani Rizk</li>
<li>for: 本研究旨在探讨鲁棒分布式学习算法的理论基础，以抵御邪恶机器学习模型。</li>
<li>methods: 本文使用(G,B)-梯度不同性模型来研究分布式学习下数据不均衡的情况，并提出了一种更加实际的不同性模型。</li>
<li>results: 本研究显示了现有理论下的学习误差下界不适用于实际场景中的数据不均衡情况，而且提出了一种新的下界。此外，我们还提出了一种robust变种的分布式梯度下降算法，并通过实验 validate our分析。<details>
<summary>Abstract</summary>
The theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. Under data heterogeneity however, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction 1/2. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice.
</details>
<details>
<summary>摘要</summary>
Theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. However, under data heterogeneity, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction 1/2. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice.Note: The translation is done using a machine translation tool, and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Neural-Network-Code-for-2D-Transient-Problems-PINN-2DT-Compatible-with-Google-Colab"><a href="#Physics-Informed-Neural-Network-Code-for-2D-Transient-Problems-PINN-2DT-Compatible-with-Google-Colab" class="headerlink" title="Physics Informed Neural Network Code for 2D Transient Problems (PINN-2DT) Compatible with Google Colab"></a>Physics Informed Neural Network Code for 2D Transient Problems (PINN-2DT) Compatible with Google Colab</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03755">http://arxiv.org/abs/2310.03755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paweł Maczuga, Maciej Skoczeń, Przemysław Rożnawski, Filip Tłuszcz, Marcin Szubert, Marcin Łoś, Witold Dzwinel, Keshav Pingali, Maciej Paszyński</li>
<li>For: The paper presents an open-source Physics Informed Neural Network (PINN) environment for simulating transient phenomena on two-dimensional rectangular domains.* Methods: The PINN environment uses a neural network to solve time-dependent partial differential equations (PDEs) and supports various boundary conditions, including Neumann and Dirichlet conditions. It also allows for customization of the number of layers and neurons per layer, as well as for arbitrary activation functions.* Results: The PINN environment provides a simple interface for defining the residual loss, boundary condition, and initial loss, together with their weights. It also includes a library of problems, such as non-stationary heat transfer, wave equation modeling a tsunami, atmospheric simulations including thermal inversion, and tumor growth simulations.<details>
<summary>Abstract</summary>
We present an open-source Physics Informed Neural Network environment for simulations of transient phenomena on two-dimensional rectangular domains, with the following features: (1) it is compatible with Google Colab which allows automatic execution on cloud environment; (2) it supports two dimensional time-dependent PDEs; (3) it provides simple interface for definition of the residual loss, boundary condition and initial loss, together with their weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it allows for customizing the number of layers and neurons per layer, as well as for arbitrary activation function; (6) the learning rate and number of epochs are available as parameters; (7) it automatically differentiates PINN with respect to spatial and temporal variables; (8) it provides routines for plotting the convergence (with running average), initial conditions learnt, 2D and 3D snapshots from the simulation and movies (9) it includes a library of problems: (a) non-stationary heat transfer; (b) wave equation modeling a tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor growth simulations.
</details>
<details>
<summary>摘要</summary>
我们提供一个开源的物理学 Informed Neural Network 环境，用于二维矩形领域上的脉冲现象模拟，其特点如下：1. 兼容 Google Colab，可以在云环境自动执行;2. 支持二维时间依赖的偏微分方程;3. 提供简单的接口 для定义剩余损失、边界条件和初始损失，以及其权重;4. 支持内壁和 Dirichlet 边界条件;5. 允许自定义层数和神经元数，以及任意活动函数;6. 学习率和迭代次数作为参数;7. 自动 differentiate PINN 对于空间和时间变量;8. 提供折线Plot 的初始条件、2D和3D 快照和电影等;9. 包含一个库，包括：a. 非站点热传输;b. 泪滤波方程模拟潮汐;c. 大气模拟，包括热层倒挪;d. 肿瘤增长模拟。
</details></li>
</ul>
<hr>
<h2 id="Graph-enhanced-Optimizers-for-Structure-aware-Recommendation-Embedding-Evolution"><a href="#Graph-enhanced-Optimizers-for-Structure-aware-Recommendation-Embedding-Evolution" class="headerlink" title="Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution"></a>Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03032">http://arxiv.org/abs/2310.03032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Xu, Jun Wang, Jianyong Wang, Wei Zhang</li>
<li>for: 提高现代推荐系统中的嵌入性能，即虚拟实体的虚拟表示和后续决策模型的基础。</li>
<li>methods: 提出了一种新的嵌入更新机制——结构意识嵌入演化（SEvo），使相关节点在每步中进行相似演化。与传统的图神经网络（GNN）不同，SEvo可以直接将图结构信息注入嵌入，无需较大的计算开销。</li>
<li>results: SEvo可以提高推荐系统性能，并且可以轻松地与现有优化器结合使用。具体来说，SEvo可以在不同的模型和数据集上保持稳定的性能提升。<details>
<summary>Abstract</summary>
Embedding plays a critical role in modern recommender systems because they are virtual representations of real-world entities and the foundation for subsequent decision models. In this paper, we propose a novel embedding update mechanism, Structure-aware Embedding Evolution (SEvo for short), to encourage related nodes to evolve similarly at each step. Unlike GNN (Graph Neural Network) that typically serves as an intermediate part, SEvo is able to directly inject the graph structure information into embedding with negligible computational overhead in training. The convergence properties of SEvo as well as its possible variants are theoretically analyzed to justify the validity of the designs. Moreover, SEvo can be seamlessly integrated into existing optimizers for state-of-the-art performance. In particular, SEvo-enhanced AdamW with moment estimate correction demonstrates consistent improvements across a spectrum of models and datasets, suggesting a novel technical route to effectively utilize graph structure information beyond explicit GNN modules.
</details>
<details>
<summary>摘要</summary>
嵌入具有重要作用在现代推荐系统中，因为它们是虚拟世界实体的虚拟表示和后续决策模型的基础。在这篇论文中，我们提出了一种新的嵌入更新机制，即结构意识 embedding 演化（SEvo），以促进相关节点在每步中进行相似演化。与传统的 GNN（图 neural network）不同，SEvo 能够直接将图结构信息注入嵌入中，在训练中减少计算开销。我们还对 SEvo 的收敛性和可能的变体进行了理论分析，以证明其设计的有效性。此外，SEvo 可以轻松地与现有优化器结合使用，以实现最佳性能。例如，SEvo 加强的 AdamW  WITH moment estimate correction 在不同的模型和数据集上都显示了稳定的改进表现，这表明了在图结构信息上超出 Explicit GNN 模块的新技术路径。
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Unlimited-Staleness-in-Federated-Learning-with-Intertwined-Data-and-Device-Heterogeneities"><a href="#Tackling-the-Unlimited-Staleness-in-Federated-Learning-with-Intertwined-Data-and-Device-Heterogeneities" class="headerlink" title="Tackling the Unlimited Staleness in Federated Learning with Intertwined Data and Device Heterogeneities"></a>Tackling the Unlimited Staleness in Federated Learning with Intertwined Data and Device Heterogeneities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13536">http://arxiv.org/abs/2309.13536</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pittisl/fl-with-intertwined-heterogeneity">https://github.com/pittisl/fl-with-intertwined-heterogeneity</a></li>
<li>paper_authors: Haoming Wang, Wei Gao</li>
<li>for: 本研究旨在提高 Federated Learning (FL) 的效率，解决数据和设备不同性的问题。</li>
<li>methods: 本研究提出了一种新的 FL 框架，利用梯度反转技术将停滞的客户端模型更新转化为非停滞的模型更新。</li>
<li>results: 实验结果表明，在面临无限停滞的情况下，本研究的方法可以提高训练模型准确率达到 20%，并提高 FL 训练进度达到 35%。<details>
<summary>Abstract</summary>
The efficiency of Federated Learning (FL) is often affected by both data and device heterogeneities. Data heterogeneity is defined as the heterogeneity of data distributions on different clients. Device heterogeneity is defined as the clients' variant latencies in uploading their local model updates due to heterogeneous conditions of local hardware resources, and causes the problem of staleness when being addressed by asynchronous FL. Traditional schemes of tackling the impact of staleness consider data and device heterogeneities as two separate and independent aspects in FL, but this assumption is unrealistic in many practical FL scenarios where data and device heterogeneities are intertwined. In these cases, traditional schemes of weighted aggregation in FL have been proved to be ineffective, and a better approach is to convert a stale model update into a non-stale one. In this paper, we present a new FL framework that leverages the gradient inversion technique for such conversion, hence efficiently tackling unlimited staleness in clients' model updates. Our basic idea is to use gradient inversion to get estimations of clients' local training data from their uploaded stale model updates, and use these estimations to compute non-stale client model updates. In this way, we address the problem of possible data quality drop when using gradient inversion, while still preserving the clients' local data privacy. We compared our approach with the existing FL strategies on mainstream datasets and models, and experiment results demonstrate that when tackling unlimited staleness, our approach can significantly improve the trained model accuracy by up to 20% and speed up the FL training progress by up to 35%.
</details>
<details>
<summary>摘要</summary>
受到数据和设备不同性的影响，联合学习（FL）的效率 часто受到数据和设备不同性的影响。数据不同性指的是客户端上的数据分布不同。设备不同性指的是客户端上的具有不同的本地硬件资源，导致异步FL Addressing staleness的问题。传统的FL方案将数据和设备不同性视为独立的两个方面，但这是在实际FL场景中不切实际的。在这些场景下，传统的权重汇集方法在FL中证明不效果，而一种更好的方法是将异步模型更新转换成非异步模型更新。在本文中，我们提出了一个新的FL框架，利用梯度反转技术来实现此类转换，从而高效地解决客户端模型更新中的无限异步问题。我们的基本思想是使用梯度反转获取客户端上传的异步模型更新中的本地训练数据估计，并使用这些估计来计算非异步客户端模型更新。这种方法可以解决使用梯度反转可能导致数据质量下降的问题，同时仍保持客户端本地数据隐私。我们与主流数据集和模型进行比较，实验结果表明，在面临无限异步情况下，我们的方法可以提高训练模型准确率达20%，并提高FL训练进度达35%。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Modeling-of-an-Unsaturated-Bentonite-Buffer-Model-Test-Under-High-Temperatures-Using-an-Enhanced-Axisymmetric-Reproducing-Kernel-Particle-Method"><a href="#Data-Driven-Modeling-of-an-Unsaturated-Bentonite-Buffer-Model-Test-Under-High-Temperatures-Using-an-Enhanced-Axisymmetric-Reproducing-Kernel-Particle-Method" class="headerlink" title="Data-Driven Modeling of an Unsaturated Bentonite Buffer Model Test Under High Temperatures Using an Enhanced Axisymmetric Reproducing Kernel Particle Method"></a>Data-Driven Modeling of an Unsaturated Bentonite Buffer Model Test Under High Temperatures Using an Enhanced Axisymmetric Reproducing Kernel Particle Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13519">http://arxiv.org/abs/2309.13519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonghyuk Baek, Yanran Wang, Xiaolong He, Yu Lu, John S. McCartney, J. S. Chen</li>
<li>for: 研究高级核废物深层地ологиRepository中焊铁粉抑融解行为下的高温环境下的焊铁粉 buffer 的THM行为。</li>
<li>methods: 使用深度神经网络(DNN)来模拟焊铁粉的水含量曲线，并将其 integrate into a Reproducing Kernel Particle Method (RKPM) 进行THM simulations。</li>
<li>results: 通过模拟一个焊铁粉层在中央加热的 tank-scale 实验，提出了一种新的抽象基函数，以便更好地模拟焊铁粉的THM行为。<details>
<summary>Abstract</summary>
In deep geological repositories for high level nuclear waste with close canister spacings, bentonite buffers can experience temperatures higher than 100 {\deg}C. In this range of extreme temperatures, phenomenological constitutive laws face limitations in capturing the thermo-hydro-mechanical (THM) behavior of the bentonite, since the pre-defined functional constitutive laws often lack generality and flexibility to capture a wide range of complex coupling phenomena as well as the effects of stress state and path dependency. In this work, a deep neural network (DNN)-based soil-water retention curve (SWRC) of bentonite is introduced and integrated into a Reproducing Kernel Particle Method (RKPM) for conducting THM simulations of the bentonite buffer. The DNN-SWRC model incorporates temperature as an additional input variable, allowing it to learn the relationship between suction and degree of saturation under the general non-isothermal condition, which is difficult to represent using a phenomenological SWRC. For effective modeling of the tank-scale test, new axisymmetric Reproducing Kernel basis functions enriched with singular Dirichlet enforcement representing heater placement and an effective convective heat transfer coefficient representing thin-layer composite tank construction are developed. The proposed method is demonstrated through the modeling of a tank-scale experiment involving a cylindrical layer of MX-80 bentonite exposed to central heating.
</details>
<details>
<summary>摘要</summary>
高度地储存核电废弃物的深层地储Repository中，бенто纳缓冲可能会面临高温（超过100℃），这个范围内的温度范围可能会导致现象学的定量关系不够捕捉潮湿-热-机械（THM）行为，因为现象学的定量关系通常缺乏普遍性和灵活性，无法捕捉各种复杂的交互效应以及压力状态和路径依赖的影响。在这种情况下，一种深度神经网络（DNN）基于的泥土水吸辊曲线（SWRC）模型被引入，并与基于 reproduce kernel particle method（RKPM）的THM模拟方法相结合。DNN-SWRC模型包含温度作为输入变量，以便学习在一般非同温度条件下湿度和吸附之间的关系，这是现象学SWRC难以表示的。为了有效地模拟储存试验，新的轴对称 reproduce kernel基函数，包括热器设置和热传递系数，被开发出来。该方法在一个筒形储存试验中，涉及一层MX-80泥土，在中央加热情况下进行模拟。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/cs.LG_2023_09_24/" data-id="clpxp6c4900scee881xlphn9s" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/eess.IV_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T09:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/eess.IV_2023_09_24/">eess.IV - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Autopet-Challenge-2023-nnUNet-based-whole-body-3D-PET-CT-Tumour-Segmentation"><a href="#Autopet-Challenge-2023-nnUNet-based-whole-body-3D-PET-CT-Tumour-Segmentation" class="headerlink" title="Autopet Challenge 2023: nnUNet-based whole-body 3D PET-CT Tumour Segmentation"></a>Autopet Challenge 2023: nnUNet-based whole-body 3D PET-CT Tumour Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13675">http://arxiv.org/abs/2309.13675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anissa Alloula, Daniel R McGowan, Bartłomiej W. Papież</li>
<li>For: 这个论文的目的是用nnUNet进行全身PET-CT扫描中的肿瘤分 segmentation，并对不同的训练和后处理策略进行调查。* Methods: 这个论文使用的方法是nnUNet，并进行了不同的训练和后处理策略的调查。* Results: 这个论文的最佳模型在内部测试集上获得了69%的Dice分数和6.27 mL的假正和5.78 mL的假负量。<details>
<summary>Abstract</summary>
Fluorodeoxyglucose Positron Emission Tomography (FDG-PET) combined with Computed Tomography (CT) scans are critical in oncology to the identification of solid tumours and the monitoring of their progression. However, precise and consistent lesion segmentation remains challenging, as manual segmentation is time-consuming and subject to intra- and inter-observer variability. Despite their promise, automated segmentation methods often struggle with false positive segmentation of regions of healthy metabolic activity, particularly when presented with such a complex range of tumours across the whole body. In this paper, we explore the application of the nnUNet to tumour segmentation of whole-body PET-CT scans and conduct different experiments on optimal training and post-processing strategies. Our best model obtains a Dice score of 69\% and a false negative and false positive volume of 6.27 and 5.78 mL respectively, on our internal test set. This model is submitted as part of the autoPET 2023 challenge. Our code is available at: https://github.com/anissa218/autopet\_nnunet
</details>
<details>
<summary>摘要</summary>
fluorodeoxyglucose positron emission tomography（FDG-PET）与计算机扫描（CT）扫描结合是肿瘤诊断和肿瘤进展评估中非常重要。然而，准确和一致性的肿瘤分割仍然是一项挑战，因为手动分割时间费时且存在内外观察者差异。尽管自动分割方法在承诺的表现不佳，特别是在面临整个身体的复杂肿瘤时，容易出现健康代谢活动的假阳性分割。在这篇论文中，我们探讨使用nnuNet进行肿瘤分割的整体PET-CT扫描，并进行了不同的训练和后处理策略的试验。我们的最佳模型在我们的内部测试集上得到了69%的Dice分数和6.27和5.78 mL的假阴性和假正面量。这个模型已经被提交到autoPET 2023挑战中。我们的代码可以在以下链接中找到：https://github.com/anissa218/autopet_nnunet。
</details></li>
</ul>
<hr>
<h2 id="Sparsity-regularized-coded-ptychography-for-robust-and-efficient-lensless-microscopy-on-a-chip"><a href="#Sparsity-regularized-coded-ptychography-for-robust-and-efficient-lensless-microscopy-on-a-chip" class="headerlink" title="Sparsity-regularized coded ptychography for robust and efficient lensless microscopy on a chip"></a>Sparsity-regularized coded ptychography for robust and efficient lensless microscopy on a chip</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13611">http://arxiv.org/abs/2309.13611</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ninghe Liu, Qianhao Zhao, Guoan Zheng</li>
<li>for: 提高ptychographic imaging的快速性和高分辨率</li>
<li>methods: 使用稀烈约束来减少测量频率，并通过梯度下降法进行优化</li>
<li>results: 能够生成高精度的重建图像，只需要八个Intensity测量值，并且可以在各种光学设备上实验 validate<details>
<summary>Abstract</summary>
In ptychographic imaging, the trade-off between the number of acquisitions and the resultant imaging quality presents a complex optimization problem. Increasing the number of acquisitions typically yields reconstructions with higher spatial resolution and finer details. Conversely, a reduction in measurement frequency often compromises the quality of the reconstructed images, manifesting as increased noise and coarser details. To address this challenge, we employ sparsity priors to reformulate the ptychographic reconstruction task as a total variation regularized optimization problem. We introduce a new computational framework, termed the ptychographic proximal total-variation (PPTV) solver, designed to integrate into existing ptychography settings without necessitating hardware modifications. Through comprehensive numerical simulations, we validate that PPTV-driven coded ptychography is capable of producing highly accurate reconstructions with a minimal set of eight intensity measurements. Convergence analysis further substantiates the robustness, stability, and computational feasibility of the proposed PPTV algorithm. Experimental results obtained from optical setups unequivocally demonstrate that the PPTV algorithm facilitates high-throughput, high-resolution imaging while significantly reducing the measurement burden. These findings indicate that the PPTV algorithm has the potential to substantially mitigate the resource-intensive requirements traditionally associated with high-quality ptychographic imaging, thereby offering a pathway toward the development of more compact and efficient ptychographic microscopy systems.
</details>
<details>
<summary>摘要</summary>
在ptychographic imaging中，数据量和图像质量之间的交换存在一个复杂的优化问题。增加数据量通常会提高图像的空间分辨率和细节，而减少测量频率则可能会丑化图像的重建效果，表现为增加杂变和粗化细节。为解决这个挑战，我们利用简约约束来修改ptychographic重建任务，将其转化为一个total variation regularized优化问题。我们提出了一种新的计算框架，名为ptychographic proximal total-variation（PPTV）解决方案，可以无需修改现有的ptychography设备。通过广泛的数字实验，我们验证了PPTV驱动的coded ptychography可以生成高精度的重建图像，只需要八个Intensity测量。对于PPTV算法的收敛分析，我们进一步证明了其稳定性、计算可行性和robustness。实验结果表明，PPTV算法可以提高高速、高分辨率的图像重建，同时减少测量负担。这些发现表明，PPTV算法有可能大幅减少传统ptychographic imaging中的资源占用，从而开 up a new pathway towards the development of more compact and efficient ptychographic microscopy systems。
</details></li>
</ul>
<hr>
<h2 id="MediViSTA-SAM-Zero-shot-Medical-Video-Analysis-with-Spatio-temporal-SAM-Adaptation"><a href="#MediViSTA-SAM-Zero-shot-Medical-Video-Analysis-with-Spatio-temporal-SAM-Adaptation" class="headerlink" title="MediViSTA-SAM: Zero-shot Medical Video Analysis with Spatio-temporal SAM Adaptation"></a>MediViSTA-SAM: Zero-shot Medical Video Analysis with Spatio-temporal SAM Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13539">http://arxiv.org/abs/2309.13539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sekeun Kim, Kyungsang Kim, Jiang Hu, Cheng Chen, Zhiliang Lyu, Ren Hui, Sunghwan Kim, Zhengliang Liu, Aoxiao Zhong, Xiang Li, Tianming Liu, Quanzheng Li</li>
<li>for: 这篇研究旨在适应医疗影像分类任务中使用Segmentation Anything Model (SAM)。</li>
<li>methods: 这篇研究引入了一种名为MediViSTA-SAM的新方法，它是一种适应医疗影像分类的Video Segmentation方法，使用了类似框架的对应运算，以及多尺度融合。</li>
<li>results: 实验结果显示，MediViSTA-SAM可以实现高准确性和有效性在医疗影像分类任务中。<details>
<summary>Abstract</summary>
In recent years, the Segmentation Anything Model (SAM) has attracted considerable attention as a foundational model well-known for its robust generalization capabilities across various downstream tasks. However, SAM does not exhibit satisfactory performance in the realm of medical image analysis. In this study, we introduce the first study on adapting SAM on video segmentation, called MediViSTA-SAM, a novel approach designed for medical video segmentation. Given video data, MediViSTA, spatio-temporal adapter captures long and short range temporal attention with cross-frame attention mechanism effectively constraining it to consider the immediately preceding video frame as a reference, while also considering spatial information effectively. Additionally, it incorporates multi-scale fusion by employing a U-shaped encoder and a modified mask decoder to handle objects of varying sizes. To evaluate our approach, extensive experiments were conducted using state-of-the-art (SOTA) methods, assessing its generalization abilities on multi-vendor in-house echocardiography datasets. The results highlight the accuracy and effectiveness of our network in medical video segmentation.
</details>
<details>
<summary>摘要</summary>
Recently, the Segmentation Anything Model (SAM) has gained significant attention as a foundational model known for its robust generalization capabilities across various downstream tasks. However, SAM does not exhibit satisfactory performance in the field of medical image analysis. In this study, we introduce the first study on adapting SAM for video segmentation, called MediViSTA-SAM, a novel approach designed for medical video segmentation. Given video data, MediViSTA, a spatio-temporal adapter, captures long and short range temporal attention with a cross-frame attention mechanism, effectively constraining it to consider the immediately preceding video frame as a reference while also considering spatial information effectively. Additionally, it incorporates multi-scale fusion by employing a U-shaped encoder and a modified mask decoder to handle objects of varying sizes. To evaluate our approach, extensive experiments were conducted using state-of-the-art (SOTA) methods, assessing its generalization abilities on multi-vendor in-house echocardiography datasets. The results highlight the accuracy and effectiveness of our network in medical video segmentation.Here's the word-for-word translation of the text into Simplified Chinese:近年来，Segmentation Anything Model（SAM）已经吸引了较大的关注，作为许多下游任务的基础模型，其robust generalization能力在各种领域得到了证明。然而，SAM在医学影像分析领域表现不 satisfactory。在这种研究中，我们介绍了首个采用SAM进行视频分 segmentation的研究，称为MediViSTA-SAM，这是一种专门为医学视频分 segmentation设计的新方法。给定视频数据，MediViSTA使用空间temporal adapter， capture long和short range temporal attention，通过跨帧注意力机制，有效地将其限制为考虑 immediately preceding video frame作为参考，同时也考虑空间信息。此外，它还 incorporates multi-scale fusion，通过使用U型编码器和修改的mask decoder来处理各种大小的对象。为了评估我们的方法，我们进行了广泛的实验，使用现有的state-of-the-art方法，评估我们的网络在医学视频分 segmentation领域的普适性。结果表明，我们的网络在医学视频分 segmentation中具有高度的准确性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-based-workflow-for-accelerated-industrial-X-ray-Computed-Tomography"><a href="#Deep-learning-based-workflow-for-accelerated-industrial-X-ray-Computed-Tomography" class="headerlink" title="Deep learning based workflow for accelerated industrial X-ray Computed Tomography"></a>Deep learning based workflow for accelerated industrial X-ray Computed Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14371">http://arxiv.org/abs/2309.14371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Obaidullah Rahman, Singanallur V. Venkatakrishnan, Luke Scime, Paul Brackman, Curtis Frederick, Ryan Dehoff, Vincent Paquit, Amirkoushyar Ziabari</li>
<li>for: 用于高精度非 destruktive characterization of additively-manufactured metal components</li>
<li>methods: 使用两个神经网络来获得快速加速的重建</li>
<li>results: 可以准确地检测瑕疵和损害，并且可以robustly generalizes across several alloys和不同的缺乏数据情况<details>
<summary>Abstract</summary>
X-ray computed tomography (XCT) is an important tool for high-resolution non-destructive characterization of additively-manufactured metal components. XCT reconstructions of metal components may have beam hardening artifacts such as cupping and streaking which makes reliable detection of flaws and defects challenging. Furthermore, traditional workflows based on using analytic reconstruction algorithms require a large number of projections for accurate characterization - leading to longer measurement times and hindering the adoption of XCT for in-line inspections. In this paper, we introduce a new workflow based on the use of two neural networks to obtain high-quality accelerated reconstructions from sparse-view XCT scans of single material metal parts. The first network, implemented using fully-connected layers, helps reduce the impact of BH in the projection data without the need of any calibration or knowledge of the component material. The second network, a convolutional neural network, maps a low-quality analytic 3D reconstruction to a high-quality reconstruction. Using experimental data, we demonstrate that our method robustly generalizes across several alloys, and for a range of sparsity levels without any need for retraining the networks thereby enabling accurate and fast industrial XCT inspections.
</details>
<details>
<summary>摘要</summary>
X射 Computed Tomography (XCT) 是一种重要的不破坏性高分辨材料成型件的测量工具。 XCT 重建结果可能受到材料硬化的影响，导致识别瑕疵和缺陷困难。此外，传统的工作流程基于使用分析重建算法，需要较多的投射来进行准确的测量 - 导致测量时间长，阻碍 XCT 在生产线上的应用。在这篇论文中，我们介绍了一种新的工作流程，基于使用两个神经网络来从稀疏视图 XCT 扫描数据中获得高质量加速重建。首先，我们使用全连接层实现的第一个神经网络，帮助减少投射数据中的硬化效应，无需任何准备或组合物质知识。其次，我们使用卷积神经网络将低质量的分析3D重建映射到高质量的重建。使用实验数据，我们表明了我们的方法可靠地在不同的合金和稀疏程度上进行泛化，无需任何重新训练神经网络，以便快速和准确地进行工业 XCT 检测。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/eess.IV_2023_09_24/" data-id="clpxp6cbe01azee88f6qz8bv0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/24/eess.SP_2023_09_24/" class="article-date">
  <time datetime="2023-09-24T08:00:00.000Z" itemprop="datePublished">2023-09-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/24/eess.SP_2023_09_24/">eess.SP - 2023-09-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Non-Uniform-Sampling-Reconstruction-for-Symmetrical-NMR-Spectroscopy-by-Exploiting-Inherent-Symmetry"><a href="#Non-Uniform-Sampling-Reconstruction-for-Symmetrical-NMR-Spectroscopy-by-Exploiting-Inherent-Symmetry" class="headerlink" title="Non-Uniform Sampling Reconstruction for Symmetrical NMR Spectroscopy by Exploiting Inherent Symmetry"></a>Non-Uniform Sampling Reconstruction for Symmetrical NMR Spectroscopy by Exploiting Inherent Symmetry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13660">http://arxiv.org/abs/2309.13660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enping Lin, Ze Fang, Yuqing Huang, Yu Yang, Zhong Chen</li>
<li>For: The paper is written for researchers and scientists who use NMR spectroscopy to study biological macromolecules, specifically those who use multidimensional NMR spectroscopy and non-uniform sampling (NUS) techniques.* Methods: The paper proposes a new sampling schedule called SCPG (Symmetrical Copy Poisson Gap) and uses compressed sensing (CS) methods for reconstruction. The authors theoretically prove that the symmetrical constraint in SCPG is equivalent to sparsity, which improves the accuracy of NUS reconstruction.* Results: The authors show that the proposed SCPG sampling schedule outperforms state-of-the-art 2D Woven PG in NUS reconstruction for symmetrical NMR spectroscopy, both in simulated and experimental data.Here are the three points in Simplified Chinese text:</li>
<li>for: 本文是为研究生物 macromolecules 的研究人员和科学家编写的，尤其是使用多维度 NMR  спектроскопия和非均匀抽样 (NUS) 技术。</li>
<li>methods: 本文提出了一种新的抽样时间表 called SCPG (Symmetrical Copy Poisson Gap)，并使用压缩感知 (CS) 方法进行重建。作者理论上证明 SCPG 中的对称约束等效地实现了简约性。</li>
<li>results: 作者表明，SCPG 抽样时间表在对 symmetrical NMR  спектроскопия的 NUS 重建中比 state-of-the-art 2D Woven PG 高效， both in 模拟和实验数据中。<details>
<summary>Abstract</summary>
Symmetrical NMR spectroscopy constitutes a vital branch of multidimensional NMR spectroscopy, providing a powerful tool for the structural elucidation of biological macromolecules. Non-Uniform Sampling (NUS) serves as an effective strategy for averting the prohibitive acquisition time of multidimensional NMR spectroscopy by only sampling a few points according to NUS sampling schedules and reconstructing missing points via algorithms. However, current sampling schedules are unable to maintain the accurate recovery of cross peaks that are weak but important. In this work, we propose a novel sampling schedule termed as SCPG (Symmetrical Copy Poisson Gap) and employ CS (Compressed Sensing) methods for reconstruction. We theoretically prove that the symmetrical constraint, apart from sparsity, is implicitly implemented when SCPG is combined with CS methods. The simulated and experimental data substantiate the advantage of SCPG over state-of-the-art 2D Woven PG in the NUS reconstruction of symmetrical NMR spectroscopy.
</details>
<details>
<summary>摘要</summary>
同对称NMR光谱学是生物大分子结构解析的重要分支，具有强大的工具。非均匀抽样（NUS）是一种有效的策略，以减少多维度NMR光谱学的质量点扩展时间。然而，目前的抽样计划无法确保强度较弱但重要的交叉峰织入的精确重建。在这个工作中，我们提出一个新的抽样计划，称为SCPG（对称复复点差隔），并使用CS（压缩感知）方法进行重建。我们 teorically证明，在SCPG与CS方法的结合下，还会隐式地实现对称限制。实验和资料 validate SCPG的优势，比顶部的2D维织PG在NUS重建中。
</details></li>
</ul>
<hr>
<h2 id="6G-Positioning-and-Sensing-Through-the-Lens-of-Sustainability-Inclusiveness-and-Trustworthiness"><a href="#6G-Positioning-and-Sensing-Through-the-Lens-of-Sustainability-Inclusiveness-and-Trustworthiness" class="headerlink" title="6G Positioning and Sensing Through the Lens of Sustainability, Inclusiveness, and Trustworthiness"></a>6G Positioning and Sensing Through the Lens of Sustainability, Inclusiveness, and Trustworthiness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13602">http://arxiv.org/abs/2309.13602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henk Wymeersch, Hui Chen, Hao Guo, Musa Furkan Keskin, Bahare M. Khorsandi, Mohammad H. Moghaddam, Alejandro Ramirez, Kim Schindhelm, Athanasios Stavridis, Tommy Svensson, Vijaya Yajnanarayana</li>
<li>for: 本研究旨在探讨6G技术如何实现可持续、包容和可信worthiness的价值观念，并与传统的性能指标之间的关系。</li>
<li>methods: 本研究采用了文献综述和理论分析的方法，探讨6G技术的可持续性、包容性和可信worthiness的实现方式，以及这些价值观念与传统的性能指标之间的关系。</li>
<li>results: 本研究发现，6G技术可以通过增强位置和感知的集成来提高通信性能，同时也可以实现包容性和可信worthiness的价值观念。然而，这些价值观念与传统的性能指标之间存在融合关系，需要在设计和实现6G技术时进行综合考虑。<details>
<summary>Abstract</summary>
6G promises a paradigm shift in which positioning and sensing are inherently integrated, enhancing not only the communication performance but also enabling location- and context-aware services. Historically, positioning and sensing have been viewed through the lens of cost and performance trade-offs, implying an escalated demand for resources, such as radio, physical, and computational resources, for improved performance. However, 6G goes beyond this traditional perspective to encompass a set of broader values, namely sustainability, inclusiveness, and trustworthiness. This paper aims to: (i) shed light on these important value indicators and their relationship with the conventional key performance indicators, and (ii) unveil the dual nature of 6G in relation to these key value indicators (i.e., ensuring operation according to the values and enabling services that affect the values).
</details>
<details>
<summary>摘要</summary>
6G 承诺一种 Paradigm shift， Positioning 和 Sensing 被内置地集成，不仅提高了通信性能，还启用了 Location-和 Context-aware 服务。历史上，Positioning 和 Sensing 通常被视为成本和性能之间的贸易OFF，这意味着需要更多的 radio、物理和计算资源来提高性能。然而，6G 超越了传统的视角，涵盖更广泛的价值观念，包括可持续性、包容性和信任性。本文的目标是：（i）探讨这些重要的价值指标与传统的关键性能指标之间的关系，（ii）揭示 6G 对这些价值指标的双重性质（即，根据价值来运行并提供影响价值的服务）。
</details></li>
</ul>
<hr>
<h2 id="Identification-of-Ghost-Targets-for-Automotive-Radar-in-the-Presence-of-Multipath"><a href="#Identification-of-Ghost-Targets-for-Automotive-Radar-in-the-Presence-of-Multipath" class="headerlink" title="Identification of Ghost Targets for Automotive Radar in the Presence of Multipath"></a>Identification of Ghost Targets for Automotive Radar in the Presence of Multipath</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13585">http://arxiv.org/abs/2309.13585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Zheng, Jiamin Long, Marco Lops, Fan Liu, Xueyao Hu<br>for:The paper is written for detecting the presence of ghosts in automotive radar systems due to multipath.methods:The paper uses a composite hypothesis testing approach based on the Generalized Likelihood Ratio Test (GLRT) philosophy, combined with a sparsity-enforced Compressed Sensing (CS) approach and Levenberg-Marquardt (LM) optimization to estimate the angular parameters in the continuous domain.results:The paper provides an extensive performance analysis to validate the proposed solution for detecting ghosts in automotive radar systems.<details>
<summary>Abstract</summary>
Colocated multiple-input multiple-output (MIMO) technology has been widely used in automotive radars as it provides accurate angular estimation of the objects with relatively small number of transmitting and receiving antennas. Since the Direction Of Departure (DOD) and the Direction Of Arrival (DOA) of line-of-sight targets coincide, MIMO signal processing allows forming a larger virtual array for angle finding. However, multiple paths impinging the receiver is a major limiting factor, in that radar signals may bounce off obstacles, creating echoes for which the DOD does not equal the DOA. Thus, in complex scenarios with multiple scatterers, the direct paths of the intended targets may be corrupted by indirect paths from other objects, which leads to inaccurate angle estimation or ghost targets. In this paper, we focus on detecting the presence of ghosts due to multipath by regarding it as the problem of deciding between a composite hypothesis, ${\cal H}_0$ say, that the observations only contain an unknown number of direct paths sharing the same (unknown) DOD's and DOA's, and a composite alternative, ${\cal H}_1$ say, that the observations also contain an unknown number of indirect paths, for which DOD's and DOA's do not coincide. We exploit the Generalized Likelihood Ratio Test (GLRT) philosophy to determine the detector structure, wherein the unknown parameters are replaced by carefully designed estimators. The angles of both the active direct paths and of the multi-paths are indeed estimated through a sparsity-enforced Compressed Sensing (CS) approach with Levenberg-Marquardt (LM) optimization to estimate the angular parameters in the continuous domain. An extensive performance analysis is finally offered in order to validate the proposed solution.
</details>
<details>
<summary>摘要</summary>
协同多输入多出口（MIMO）技术在汽车雷达中广泛应用，因为它可以准确地估算目标物的方向，只需使用相对较少的发射和接收天线。由于发射和接收方向的DOD和DOA相同，MIMO信号处理可以组成较大的虚拟数组，以便角度测量。但是，多路射雷达信号可以受到障碍物的反射，导致信号返回不同的方向，从而导致DOD不等于DOA。因此，在复杂的多散体场景下，直接目标的直接路径可能会受到其他 объек的 indirect 路径的扰动，从而导致角度估算不准确或鬼目标。在这篇论文中，我们关注在多射场景中 Ghost 的探测，即在雷达信号中检测到不同的 DOD 和 DOA 的射频信号是否来自于直接或间接的多射。我们采用 Generalized Likelihood Ratio Test（GLRT）哲学来确定探测结构，其中未知参数被换成精心设计的估计器。雷达信号中的直接路径和多射路径的角度都是通过一种减少维度的 Compressed Sensing（CS）方法和 Levenberg-Marquardt（LM）优化来估计的。 finally，我们提供了广泛的性能分析，以验证我们的提案的可行性。
</details></li>
</ul>
<hr>
<h2 id="Sparsity-Based-Channel-Estimation-Exploiting-Deep-Unrolling-for-Downlink-Massive-MIMO"><a href="#Sparsity-Based-Channel-Estimation-Exploiting-Deep-Unrolling-for-Downlink-Massive-MIMO" class="headerlink" title="Sparsity-Based Channel Estimation Exploiting Deep Unrolling for Downlink Massive MIMO"></a>Sparsity-Based Channel Estimation Exploiting Deep Unrolling for Downlink Massive MIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13545">http://arxiv.org/abs/2309.13545</a></li>
<li>repo_url: None</li>
<li>paper_authors: An Chen, Wenbo Xu, Liyang Lu, Yue Wang</li>
<li>for: 提高5G无线通信系统中大量多输入多出力（MIMO）的spectrum和能量效率，避免过多的射频过头增加频率占用。</li>
<li>methods: 通过抽象学模型驱动的压缩感知（CS）和数据驱动的深度卷积技术相结合，实现hybrid通道估计方案，包括粗略估计部分和精度修正部分，分别利用多普勒频率域和时域频率域的频率稀热性来大幅减少射频过头。</li>
<li>results: 理论结果表明，提案的方案可以减少射频过头量化频率域和时域频率域的频率稀热性，以实现低射频过头的多输入多出力通道估计，同时保证估计精度。实验结果表明，对于5G FDD巨量MIMO系统，提案的方案可以减少射频过头量化80%以上，而且估计精度与传统CS方案相当。<details>
<summary>Abstract</summary>
Massive multiple-input multiple-output (MIMO) enjoys great advantage in 5G wireless communication systems owing to its spectrum and energy efficiency. However, hundreds of antennas require large volumes of pilot overhead to guarantee reliable channel estimation in FDD massive MIMO system. Compressive sensing (CS) has been applied for channel estimation by exploiting the inherent sparse structure of massive MIMO channel but suffer from high complexity. To overcome this challenge, this paper develops a hybrid channel estimation scheme by integrating the model-driven CS and data-driven deep unrolling technique. The proposed scheme consists of a coarse estimation part and a fine correction part to respectively exploit the inter- and intraframe sparsities of channels to greatly reduce the pilot overhead. Theoretical result is provided to indicate the convergence of the fine correction and coarse estimation net. Simulation results are provided to verify that our scheme can estimate MIMO channels with low pilot overhead while guaranteeing estimation accuracy with relatively low complexity.
</details>
<details>
<summary>摘要</summary>
大量多输入多输出（MIMO）在5G无线通信系统中具有优异的优势，主要是在频率和能量方面。然而，数百个天线需要大量的射频过头来保证可靠的通道估计在FDD大量MIMO系统中。压缩感知（CS）已经应用于通道估计中，利用大量MIMO通道的自然稀畴结构。然而，它受到高复杂性的挑战。为了解决这个挑战，本文提出了一种混合模型驱动CS和数据驱动深层卷积技术的混合通道估计方案。该方案包括粗略估计部分和精度修正部分，分别利用通道之间和通道内部的稀畴性来大幅减少射频过头。我们提供了理论结果，证明了精度修正和粗略估计网的共振。实验结果表明，我们的方案可以在低射频过头下Estimation MIMO通道的精度，而且与相对较低的复杂性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/24/eess.SP_2023_09_24/" data-id="clpxp6cd701f3ee887tiof8ty" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.SD_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T15:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.SD_2023_09_23/">cs.SD - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Attention-Is-All-You-Need-For-Blind-Room-Volume-Estimation"><a href="#Attention-Is-All-You-Need-For-Blind-Room-Volume-Estimation" class="headerlink" title="Attention Is All You Need For Blind Room Volume Estimation"></a>Attention Is All You Need For Blind Room Volume Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13504">http://arxiv.org/abs/2309.13504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunxi Wang, Maoshen Jia, Meiran Li, Changchun Bao, Wenyu Jin</li>
<li>for: 这篇论文主要是针对听取环境动态参数化问题进行研究，具体来说是用于盲目估计室内声学参数。</li>
<li>methods: 这篇论文提出了一种基于注意力机制的纯注意力模型，用于盲目估计室内声学参数。模型使用了扩展的Transformer架构，并使用了多modal数据 Transfer learning来提高模型性能。</li>
<li>results: 实验结果表明，提出的模型在实际听取环境中表现出色，特别是在使用专门预训练和数据扩展方案时。模型的性能在各种听取环境中都有显著提高。<details>
<summary>Abstract</summary>
In recent years, dynamic parameterization of acoustic environments has raised increasing attention in the field of audio processing. One of the key parameters that characterize the local room acoustics in isolation from orientation and directivity of sources and receivers is the geometric room volume. Convolutional neural networks (CNNs) have been widely selected as the main models for conducting blind room acoustic parameter estimation, which aims to learn a direct mapping from audio spectrograms to corresponding labels. With the recent trend of self-attention mechanisms, this paper introduces a purely attention-based model to blindly estimate room volumes based on single-channel noisy speech signals. We demonstrate the feasibility of eliminating the reliance on CNN for this task and the proposed Transformer architecture takes Gammatone magnitude spectral coefficients and phase spectrograms as inputs. To enhance the model performance given the task-specific dataset, cross-modality transfer learning is also applied. Experimental results demonstrate that the proposed model outperforms traditional CNN models across a wide range of real-world acoustics spaces, especially with the help of the dedicated pretraining and data augmentation schemes.
</details>
<details>
<summary>摘要</summary>
最近几年，动态参数化的声学环境在声音处理领域受到了越来越多的关注。一个关键参数，用于隔离源和接收器的方向和方向性，是地形室内体积。深度学习神经网络（CNN）广泛选择为无目标声学参数估计的主要模型，该模型的目标是从声音спектрограм中直接学习到相应的标签。随着自动注意机制的潮流，这篇论文介绍了一种完全基于注意力的模型，用于无目标地估计室内体积，并将 Gammatone 大小 спектрограм和相位спектрограм作为输入。为了提高模型在这个任务上的表现，我们还应用了交叉模态转移学习。实验结果表明，我们提出的模型在真实世界的各种声学空间中， especial 在使用特定数据集和预训练 schemes 时，都能够超过传统的 CNN 模型。
</details></li>
</ul>
<hr>
<h2 id="Two-vs-Four-Channel-Sound-Event-Localization-and-Detection"><a href="#Two-vs-Four-Channel-Sound-Event-Localization-and-Detection" class="headerlink" title="Two vs. Four-Channel Sound Event Localization and Detection"></a>Two vs. Four-Channel Sound Event Localization and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13343">http://arxiv.org/abs/2309.13343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Wilkins, Magdalena Fuentes, Luca Bondi, Shabnam Ghaffarzadegan, Ali Abavisani, Juan Pablo Bello</li>
<li>for: 本研究旨在探讨DCASE 2022 SELD挑战 зада务中（任务3）模型在4个渠道设置下的性能，以及不同音频输入表示方式对SELD性能的影响。</li>
<li>methods: 本研究使用了DCASE 2022 SELD基线模型，并对不同音频输入表示方式进行比较分析，以评估它们对SELD性能的影响。</li>
<li>results: 研究发现，带声和ステレオ（即2个渠道）音频基于SELD模型仍然能够良好地定位和探测声源，尽管总体性能下降。此外，研究还 segmented 分析了不同场景中声源多样性的影响，以更好地理解不同音频输入表示方式对SELD性能的影响。<details>
<summary>Abstract</summary>
Sound event localization and detection (SELD) systems estimate both the direction-of-arrival (DOA) and class of sound sources over time. In the DCASE 2022 SELD Challenge (Task 3), models are designed to operate in a 4-channel setting. While beneficial to further the development of SELD systems using a multichannel recording setup such as first-order Ambisonics (FOA), most consumer electronics devices rarely are able to record using more than two channels. For this reason, in this work we investigate the performance of the DCASE 2022 SELD baseline model using three audio input representations: FOA, binaural, and stereo. We perform a novel comparative analysis illustrating the effect of these audio input representations on SELD performance. Crucially, we show that binaural and stereo (i.e. 2-channel) audio-based SELD models are still able to localize and detect sound sources laterally quite well, despite overall performance degrading as less audio information is provided. Further, we segment our analysis by scenes containing varying degrees of sound source polyphony to better understand the effect of audio input representation on localization and detection performance as scene conditions become increasingly complex.
</details>
<details>
<summary>摘要</summary>
听音事件地理位置和检测（SELD）系统估算听音源的方向到达（DOA）和时间上的类型。在DCASE 2022 SELD挑战（任务3）中，模型设计用4通道记录设置。虽然多通道记录设置可以进一步发展SELD系统，但大多数消费类电子设备通常只能记录两个通道。因此，在这个工作中，我们研究了DCASE 2022 SELD基准模型使用FOA、双耳和立体声三种听音输入表示方式的性能。我们进行了一项新的比较分析，描述这些听音输入表示方式对听音源的地理位置和检测性能的影响。我们发现，使用双耳和立体声（即2通道）听音基于SELD模型仍然能够准确地localize和检测听音源，尽管总体性能下降。此外，我们对不同场景中听音源的多重播放情况进行了分 segment 的分析，以更好地理解听音输入表示方式对听音源的地理位置和检测性能的影响，场景条件变得越来越复杂。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Speaker-Embedding-With-Sequential-Disentanglement"><a href="#Contrastive-Speaker-Embedding-With-Sequential-Disentanglement" class="headerlink" title="Contrastive Speaker Embedding With Sequential Disentanglement"></a>Contrastive Speaker Embedding With Sequential Disentanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13253">http://arxiv.org/abs/2309.13253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youzhi Tu, Man-Wai Mak, Jen-Tzung Chien</li>
<li>for: 本文旨在提出一种基于对比学习的语音说话人识别方法，该方法利用了顺序分解器（DSVAE）来除掉语言内容，从而使得只有说话人因素被用于构建对比损失目标。</li>
<li>methods: 本文提出的方法包括在传统的SimCLR框架中 incorporating 顺序分解器（DSVAE），以除掉语言内容，并使用对比学习来学习说话人特征。</li>
<li>results: 实验结果表明，提出的方法在 VoxCeleb1-test 上的表现Consistently 高于 SimCLR，这表明了应用顺序分解是有利于学习说话人特征的。<details>
<summary>Abstract</summary>
Contrastive speaker embedding assumes that the contrast between the positive and negative pairs of speech segments is attributed to speaker identity only. However, this assumption is incorrect because speech signals contain not only speaker identity but also linguistic content. In this paper, we propose a contrastive learning framework with sequential disentanglement to remove linguistic content by incorporating a disentangled sequential variational autoencoder (DSVAE) into the conventional SimCLR framework. The DSVAE aims to disentangle speaker factors from content factors in an embedding space so that only the speaker factors are used for constructing a contrastive loss objective. Because content factors have been removed from the contrastive learning, the resulting speaker embeddings will be content-invariant. Experimental results on VoxCeleb1-test show that the proposed method consistently outperforms SimCLR. This suggests that applying sequential disentanglement is beneficial to learning speaker-discriminative embeddings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate given text into Simplified Chinese.<</SYS>>对照性发言嵌入假设，即对于正例和负例对话段的差异归结于发言人身份。然而，这个假设是错误的，因为语音信号包含不仅发言人身份，还包含语言内容。在这篇论文中，我们提议一种含有顺序解解析的对照学习框架，使用嵌入空间中的分离顺序自动编码器（DSVAE）来除去语言内容。DSVAE的目标是在嵌入空间中分离发言人因素和语言因素，以便只使用发言人因素来构建对照损失对象。因此，在对照学习中移除了语言内容，得到的发言人嵌入将是内容不变的。实验结果表明，提议的方法在VoxCeleb1-test上一直高于SimCLR。这表明，在学习发言人特异性嵌入时，顺序解解析是有利的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.SD_2023_09_23/" data-id="clpxp6c700100ee880xsc8x9b" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.CV_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T13:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.CV_2023_09_23/">cs.CV - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Portrait-Stylization-Artistic-Style-Transfer-with-Auxiliary-Networks-for-Human-Face-Stylization"><a href="#Portrait-Stylization-Artistic-Style-Transfer-with-Auxiliary-Networks-for-Human-Face-Stylization" class="headerlink" title="Portrait Stylization: Artistic Style Transfer with Auxiliary Networks for Human Face Stylization"></a>Portrait Stylization: Artistic Style Transfer with Auxiliary Networks for Human Face Stylization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13492">http://arxiv.org/abs/2309.13492</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thiagoambiel/PortraitStylization">https://github.com/thiagoambiel/PortraitStylization</a></li>
<li>paper_authors: Thiago Ambiel</li>
<li>for: 提高图像风格传递中人脸个体特征的保留</li>
<li>methods: 使用辅助预训练人脸识别模型的嵌入来鼓励算法在内容图像上传递人脸特征到最终风格化结果中</li>
<li>results: 提高了图像风格传递中人脸个体特征的保留<details>
<summary>Abstract</summary>
Today's image style transfer methods have difficulty retaining humans face individual features after the whole stylizing process. This occurs because the features like face geometry and people's expressions are not captured by the general-purpose image classifiers like the VGG-19 pre-trained models. This paper proposes the use of embeddings from an auxiliary pre-trained face recognition model to encourage the algorithm to propagate human face features from the content image to the final stylized result.
</details>
<details>
<summary>摘要</summary>
今天的图像风格传递方法很难保持人脸个人特征 после整个风格化过程。这是因为人脸的特征，如人脸几何学和人们的表情，不被通用的图像分类器如VGG-19预训练模型捕捉。这篇论文提议使用auxiliary预训练人脸识别模型的嵌入来鼓励算法在内容图像上传递人脸特征到最终风格化结果中。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Systematic-Errors-in-Object-Detectors-with-the-SCROD-Pipeline"><a href="#Identifying-Systematic-Errors-in-Object-Detectors-with-the-SCROD-Pipeline" class="headerlink" title="Identifying Systematic Errors in Object Detectors with the SCROD Pipeline"></a>Identifying Systematic Errors in Object Detectors with the SCROD Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13489">http://arxiv.org/abs/2309.13489</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Valentyn Boreiko, Matthias Hein, Jan Hendrik Metzen</li>
<li>for: 本研究旨在提高对象检测器的系统性错误识别和除除，以便在自动驾驶和机器人应用中使用。</li>
<li>methods: 我们提出了一种新的框架， combinesPhysical simulators和生成模型的优点，以实现高级的自动控制和可扩展性。</li>
<li>results: 我们的框架可以自动生成街道场景，并且可以具有精细的控制。此外，我们还提出了一种评价设定，可以作为类似框架的标准测试进程。<details>
<summary>Abstract</summary>
The identification and removal of systematic errors in object detectors can be a prerequisite for their deployment in safety-critical applications like automated driving and robotics. Such systematic errors can for instance occur under very specific object poses (location, scale, orientation), object colors/textures, and backgrounds. Real images alone are unlikely to cover all relevant combinations. We overcome this limitation by generating synthetic images with fine-granular control. While generating synthetic images with physical simulators and hand-designed 3D assets allows fine-grained control over generated images, this approach is resource-intensive and has limited scalability. In contrast, using generative models is more scalable but less reliable in terms of fine-grained control. In this paper, we propose a novel framework that combines the strengths of both approaches. Our meticulously designed pipeline along with custom models enables us to generate street scenes with fine-grained control in a fully automated and scalable manner. Moreover, our framework introduces an evaluation setting that can serve as a benchmark for similar pipelines. This evaluation setting will contribute to advancing the field and promoting standardized testing procedures.
</details>
<details>
<summary>摘要</summary>
“系统性错误在物检测器中的识别和移除可以是安全应用程序like自动驾驶和机器人的必要条件。这些系统性错误可能会发生在非常特定的物品位置（位置、比例、姿态）、物品颜色/ texture 和背景下。实际的图像独立无法覆盖所有相关的 комbination。我们 overcome这个限制，通过生成Synthetic图像，并具有精细的控制。使用物理 simulator 和手动设计的 3D 资产来生成Synthetic图像可以实现精细的控制，但这种方法是资源耗尽和有限的可扩展性。相比之下，使用生成模型是更可扩展的，但是在精细控制方面 Less reliable。在这篇论文中，我们提出一个新的框架，让我们在自动化和可扩展的方式下，生成街景图像，并具有精细的控制。此外，我们的框架还引入了评估环境，可以作为类似框架的参考。这个评估环境将对领域的进步和标准化 testing  процедуures 做出贡献。”
</details></li>
</ul>
<hr>
<h2 id="Detecting-and-Mitigating-System-Level-Anomalies-of-Vision-Based-Controllers"><a href="#Detecting-and-Mitigating-System-Level-Anomalies-of-Vision-Based-Controllers" class="headerlink" title="Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers"></a>Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13475">http://arxiv.org/abs/2309.13475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aryaman Gupta, Kaustav Chakraborty, Somil Bansal</li>
<li>for: 本研究旨在提高自主系统的安全性和可靠性，通过在运行时检测和 Mitigate 视觉控制器的异常情况。</li>
<li>methods: 本研究使用了可达性基础结构来压测视觉控制器，并将其异常情况数据用于在线训练异常检测器。</li>
<li>results: 研究结果表明，提出的方法可以识别和处理视觉控制器的系统级异常情况，并在检测和 Mitigate 过程中提高自主系统的安全性和可靠性。<details>
<summary>Abstract</summary>
Autonomous systems, such as self-driving cars and drones, have made significant strides in recent years by leveraging visual inputs and machine learning for decision-making and control. Despite their impressive performance, these vision-based controllers can make erroneous predictions when faced with novel or out-of-distribution inputs. Such errors can cascade to catastrophic system failures and compromise system safety. In this work, we introduce a run-time anomaly monitor to detect and mitigate such closed-loop, system-level failures. Specifically, we leverage a reachability-based framework to stress-test the vision-based controller offline and mine its system-level failures. This data is then used to train a classifier that is leveraged online to flag inputs that might cause system breakdowns. The anomaly detector highlights issues that transcend individual modules and pertain to the safety of the overall system. We also design a fallback controller that robustly handles these detected anomalies to preserve system safety. We validate the proposed approach on an autonomous aircraft taxiing system that uses a vision-based controller for taxiing. Our results show the efficacy of the proposed approach in identifying and handling system-level anomalies, outperforming methods such as prediction error-based detection, and ensembling, thereby enhancing the overall safety and robustness of autonomous systems.
</details>
<details>
<summary>摘要</summary>
自主系统，如自驾车和无人机，在最近几年中取得了很大的进步，通过视觉输入和机器学习来做出决策和控制。尽管它们的表现非常出色，但这些视觉控制器在面对新或非标准的输入时可能会做出错误的预测。这些错误可能会导致系统失败和发生危机。在这个工作中，我们提出了一个在线运行的问题检测器，以检测和缓解这些关键的系统级别失败。具体来说，我们利用一个可以在线运行的抽象框架，对视觉控制器进行压力测试，并从这些资料中提取出可能会导致系统异常的特征。这些特征可以被用来训练一个在线运行的分类器，以检测和识别可能会导致系统异常的输入。这个问题检测器可以帮助检测和解决系统级别的问题，以提高自主系统的安全和可靠性。我们还设计了一个可靠的备援控制器，以确保系统在检测到问题时能够稳定地运行。我们验证了我们的方法在一个使用视觉控制器进行着陆的自主飞机系统中，结果显示了我们的方法能够优化自主系统的安全和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Edge-Aware-Learning-for-3D-Point-Cloud"><a href="#Edge-Aware-Learning-for-3D-Point-Cloud" class="headerlink" title="Edge Aware Learning for 3D Point Cloud"></a>Edge Aware Learning for 3D Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13472">http://arxiv.org/abs/2309.13472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Li<br>for:* 这种方法是为了处理点云数据中的噪声，提高物体认知和分割。methods:* 该方法使用了人类视觉系统中的边感知概念，并将其 интеグриinto了学习方法中，以提高物体识别和分割。results:* 该方法在ModelNet40和ShapeNet数据集上表现出色，在物体分类和分割任务中表现出了显著的优势。<details>
<summary>Abstract</summary>
This paper proposes an innovative approach to Hierarchical Edge Aware 3D Point Cloud Learning (HEA-Net) that seeks to address the challenges of noise in point cloud data, and improve object recognition and segmentation by focusing on edge features. In this study, we present an innovative edge-aware learning methodology, specifically designed to enhance point cloud classification and segmentation. Drawing inspiration from the human visual system, the concept of edge-awareness has been incorporated into this methodology, contributing to improved object recognition while simultaneously reducing computational time. Our research has led to the development of an advanced 3D point cloud learning framework that effectively manages object classification and segmentation tasks. A unique fusion of local and global network learning paradigms has been employed, enriched by edge-focused local and global embeddings, thereby significantly augmenting the model's interpretative prowess. Further, we have applied a hierarchical transformer architecture to boost point cloud processing efficiency, thus providing nuanced insights into structural understanding. Our approach demonstrates significant promise in managing noisy point cloud data and highlights the potential of edge-aware strategies in 3D point cloud learning. The proposed approach is shown to outperform existing techniques in object classification and segmentation tasks, as demonstrated by experiments on ModelNet40 and ShapeNet datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HAVE-Net-Hallucinated-Audio-Visual-Embeddings-for-Few-Shot-Classification-with-Unimodal-Cues"><a href="#HAVE-Net-Hallucinated-Audio-Visual-Embeddings-for-Few-Shot-Classification-with-Unimodal-Cues" class="headerlink" title="HAVE-Net: Hallucinated Audio-Visual Embeddings for Few-Shot Classification with Unimodal Cues"></a>HAVE-Net: Hallucinated Audio-Visual Embeddings for Few-Shot Classification with Unimodal Cues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13470">http://arxiv.org/abs/2309.13470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ankit Jha, Debabrata Pal, Mainak Singha, Naman Agarwal, Biplab Banerjee</li>
<li>for: 本研究旨在解决remote sensing（RS）频谱图像识别领域中的一个新的问题，即在meta-训练阶段可以同时使用视觉modalities，但在meta-测试阶段一个modalities可能缺失。</li>
<li>methods: 我们提出了一种新的几何学生成框架，即Hallucinated Audio-Visual Embeddings-Network（HAVE-Net），用于在限制性的单模态数据上meta-训练交叉模态特征。在推理阶段，我们使用这些幻想出的特征进行几何学分类。</li>
<li>results: 我们的实验结果表明，使用我们的幻想模态增强策略，在ADVANCE和AudioSetZSL数据集上的 benchmark dataset上，我们的几何学分类器在少数据情况下表现至少比基eline perfomance高出0.8-2%。<details>
<summary>Abstract</summary>
Recognition of remote sensing (RS) or aerial images is currently of great interest, and advancements in deep learning algorithms added flavor to it in recent years. Occlusion, intra-class variance, lighting, etc., might arise while training neural networks using unimodal RS visual input. Even though joint training of audio-visual modalities improves classification performance in a low-data regime, it has yet to be thoroughly investigated in the RS domain. Here, we aim to solve a novel problem where both the audio and visual modalities are present during the meta-training of a few-shot learning (FSL) classifier; however, one of the modalities might be missing during the meta-testing stage. This problem formulation is pertinent in the RS domain, given the difficulties in data acquisition or sensor malfunctioning. To mitigate, we propose a novel few-shot generative framework, Hallucinated Audio-Visual Embeddings-Network (HAVE-Net), to meta-train cross-modal features from limited unimodal data. Precisely, these hallucinated features are meta-learned from base classes and used for few-shot classification on novel classes during the inference phase. The experimental results on the benchmark ADVANCE and AudioSetZSL datasets show that our hallucinated modality augmentation strategy for few-shot classification outperforms the classifier performance trained with the real multimodal information at least by 0.8-2%.
</details>
<details>
<summary>摘要</summary>
现在远程感知（RS）或航空图像的认知是非常有趣，深度学习算法在最近几年中增添了一些风味。在训练神经网络时， occlusion、内类差异、照明等问题可能会出现。尽管将音频和视觉模式联合训练可以在数据缺乏的情况下提高分类性能，但是在RS领域还未得到过分析。在这里，我们想解决一个新的问题，即在meta-测试阶段缺失一个感知模式。这种问题在RS领域非常有 pertinence，因为数据收集或传感器故障是常见的问题。为了 mitigate，我们提出了一种新的几shot生成框架，即Hallucinated Audio-Visual Embeddings-Network（HAVE-Net）。具体来说，这些hallucinated特征是在基类上meta-学习的，并在推理阶段用于几shot分类 novel classes。实验结果表明，我们的 hallucinated感知特征增强策略在ADVANCE和AudioSetZSL数据集上的 benchmark 上超过了实际多modal信息下的类ifier性能，至少提高0.8-2%。
</details></li>
</ul>
<hr>
<h2 id="Turbulence-in-Focus-Benchmarking-Scaling-Behavior-of-3D-Volumetric-Super-Resolution-with-BLASTNet-2-0-Data"><a href="#Turbulence-in-Focus-Benchmarking-Scaling-Behavior-of-3D-Volumetric-Super-Resolution-with-BLASTNet-2-0-Data" class="headerlink" title="Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data"></a>Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13457">http://arxiv.org/abs/2309.13457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wai Tong Chung, Bassem Akoush, Pushan Sharma, Alex Tamkin, Ki Sung Jung, Jacqueline H. Chen, Jack Guo, Davy Brouzet, Mohsen Talei, Bruno Savard, Alexei Y. Poludnenko, Matthias Ihme<br>for:The paper aims to provide a large-scale dataset of 3D high-fidelity compressible turbulent flow simulations for training and benchmarking deep learning models.methods:The paper uses 744 full-domain samples from 34 high-fidelity direct numerical simulations to create a network-of-datasets called BLASTNet 2.0, which contains 49 variations of five deep learning approaches for 3D super-resolution.results:The paper performs a neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques, and demonstrates that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size.<details>
<summary>Abstract</summary>
Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution - which can be applied for improving scientific imaging, simulations, turbulence models, as well as in computer vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size. The outcomes of this benchmark study are anticipated to offer insights that can aid the design of 3D super-resolution models, especially for turbulence models, while this data is expected to foster ML methods for a broad range of flow physics applications. This data is publicly available with download links and browsing tools consolidated at https://blastnet.github.io.
</details>
<details>
<summary>摘要</summary>
We tested 49 variations of five deep learning approaches for 3D super-resolution using this dataset. Our results show that:1. Predictive performance can scale with model size and cost.2. Model architecture is crucial, especially for smaller models.3. Physics-based losses can provide significant benefits, even with larger models.These findings can aid the design of 3D super-resolution models, particularly for turbulence models. The BLASTNet 2.0 dataset is publicly available at <https://blastnet.github.io>, with download links and browsing tools. This dataset is expected to facilitate the development of machine learning methods for a wide range of flow physics applications.
</details></li>
</ul>
<hr>
<h2 id="Video-Timeline-Modeling-For-News-Story-Understanding"><a href="#Video-Timeline-Modeling-For-News-Story-Understanding" class="headerlink" title="Video Timeline Modeling For News Story Understanding"></a>Video Timeline Modeling For News Story Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13446">http://arxiv.org/abs/2309.13446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Meng Liu, Mingda Zhang, Jialu Liu, Hanjun Dai, Ming-Hsuan Yang, Shuiwang Ji, Zheyun Feng, Boqing Gong</li>
<li>For: The paper is written for exploring the problem of video timeline modeling, with the goal of creating a video-associated timeline to facilitate content and structure understanding of the story being told.* Methods: The paper proposes several deep learning approaches to tackling this problem, including the development of a realistic benchmark dataset (YouTube-News-Timeline) and the introduction of quantitative metrics to evaluate and compare methodologies.* Results: The paper anticipates that this exploratory work will pave the way for further research in video timeline modeling, and provides a testbed for researchers to build upon.Here’s the same information in Simplified Chinese text:* For: 本文探讨视频时间轴模型问题，目的是创建与特定主题相关的视频时间轴，以便更好地理解故事的内容和结构。* Methods: 本文提出了多种深度学习方法来解决这个问题，包括开发一个真实的 bencmark 数据集 (YouTube-News-Timeline) 和引入评估和比较方法的量化指标。* Results: 本文预计这项探讨工作将为视频时间轴模型的进一步研究开辟新的道路，并提供了研究者们可以进一步发展的测试平台。<details>
<summary>Abstract</summary>
In this paper, we present a novel problem, namely video timeline modeling. Our objective is to create a video-associated timeline from a set of videos related to a specific topic, thereby facilitating the content and structure understanding of the story being told. This problem has significant potential in various real-world applications, for instance, news story summarization. To bootstrap research in this area, we curate a realistic benchmark dataset, YouTube-News-Timeline, consisting of over $12$k timelines and $300$k YouTube news videos. Additionally, we propose a set of quantitative metrics to comprehensively evaluate and compare methodologies. With such a testbed, we further develop and benchmark several deep learning approaches to tackling this problem. We anticipate that this exploratory work will pave the way for further research in video timeline modeling. The assets are available via https://github.com/google-research/google-research/tree/master/video_timeline_modeling.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个新的问题，即视频时间轴建模。我们的目标是从一组关于特定主题的视频集合中生成一个视频相关的时间轴，以便更好地理解视频中的内容和结构。这个问题在实际应用中具有重要的潜在价值，例如新闻故事概要。为了推动这个领域的研究，我们制作了一个现实的测试集，YouTube-News-Timeline，包含超过12000个时间轴和300000个YouTube新闻视频。此外，我们提出了一些量化的评价指标，以全面评估和比较不同方法的性能。通过这些实验，我们预计会开拓视频时间轴建模的研究途径。资产可以通过https://github.com/google-research/google-research/tree/master/video_timeline_modeling获取。
</details></li>
</ul>
<hr>
<h2 id="Dream-the-Impossible-Outlier-Imagination-with-Diffusion-Models"><a href="#Dream-the-Impossible-Outlier-Imagination-with-Diffusion-Models" class="headerlink" title="Dream the Impossible: Outlier Imagination with Diffusion Models"></a>Dream the Impossible: Outlier Imagination with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13415">http://arxiv.org/abs/2309.13415</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/dream-ood">https://github.com/deeplearning-wisc/dream-ood</a></li>
<li>paper_authors: Xuefeng Du, Yiyou Sun, Xiaojin Zhu, Yixuan Li</li>
<li>for: 本研究旨在提出一种新的框架，以便生成高品质的异常样例，以提高机器学习模型的OOD检测和预测安全性。</li>
<li>methods: 该框架基于diffusion模型，通过文本条件的latent空间学习，生成高维像素空间中的异常样例。</li>
<li>results: 研究表明，通过使用DREAM-OOD生成的样例进行训练，可以提高OOD检测性能。<details>
<summary>Abstract</summary>
Utilizing auxiliary outlier datasets to regularize the machine learning model has demonstrated promise for out-of-distribution (OOD) detection and safe prediction. Due to the labor intensity in data collection and cleaning, automating outlier data generation has been a long-desired alternative. Despite the appeal, generating photo-realistic outliers in the high dimensional pixel space has been an open challenge for the field. To tackle the problem, this paper proposes a new framework DREAM-OOD, which enables imagining photo-realistic outliers by way of diffusion models, provided with only the in-distribution (ID) data and classes. Specifically, DREAM-OOD learns a text-conditioned latent space based on ID data, and then samples outliers in the low-likelihood region via the latent, which can be decoded into images by the diffusion model. Different from prior works, DREAM-OOD enables visualizing and understanding the imagined outliers, directly in the pixel space. We conduct comprehensive quantitative and qualitative studies to understand the efficacy of DREAM-OOD, and show that training with the samples generated by DREAM-OOD can benefit OOD detection performance. Code is publicly available at https://github.com/deeplearning-wisc/dream-ood.
</details>
<details>
<summary>摘要</summary>
使用辅助外围数据集规范机器学习模型，已经显示了出现在其他分布（OOD）探测和安全预测的承诺。由于数据收集和清洁的劳动性，自动生成外围数据变得非常感兴趣。尽管有吸引力，在高维像素空间中生成真实的外围数据仍然是领域的一个开放挑战。为解决这个问题，这篇论文提出了一个新的框架——DREAM-OOD，可以生成真实的外围数据。具体来说，DREAM-OOD学习了根据内 distribuition（ID）数据的文本 conditioned的隐藏空间，然后通过这个隐藏空间的低可能性区域进行采样，这些采样可以通过扩散模型进行解码，转换为图像。与先前的工作不同，DREAM-OOD可以直接在像素空间中可见和理解生成的外围数据。我们进行了全面的量化和质量研究，并证明了在训练中使用DREAM-OOD生成的样本可以提高OOD探测性能。代码可以在https://github.com/deeplearning-wisc/dream-ood中下载。
</details></li>
</ul>
<hr>
<h2 id="WS-YOLO-Weakly-Supervised-Yolo-Network-for-Surgical-Tool-Localization-in-Endoscopic-Videos"><a href="#WS-YOLO-Weakly-Supervised-Yolo-Network-for-Surgical-Tool-Localization-in-Endoscopic-Videos" class="headerlink" title="WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization in Endoscopic Videos"></a>WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization in Endoscopic Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13404">http://arxiv.org/abs/2309.13404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/breezewrf/weakly-supervised-yolov8">https://github.com/breezewrf/weakly-supervised-yolov8</a></li>
<li>paper_authors: Rongfeng Wei, Jinlin Wu, You Pang, Zhen Chen</li>
<li>for: 这个论文是为了提高endooscopic视频记录中手术工具的检测和跟踪而写的。</li>
<li>methods: 这个论文使用了Weakly Supervised Yolo Network (WS-YOLO)来生成endooscopic视频中手术工具的精细Semantic信息，包括工具的位置和类别。</li>
<li>results: 这个论文的实验结果表明，WS-YOLO可以准确地检测和跟踪手术工具，并且可以减少人工标注劳动量。 codes are available online。<details>
<summary>Abstract</summary>
Being able to automatically detect and track surgical instruments in endoscopic video recordings would allow for many useful applications that could transform different aspects of surgery. In robot-assisted surgery, the potentially informative data like categories of surgical tool can be captured, which is sparse, full of noise and without spatial information. We proposed a Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in Endoscopic Videos, to generate fine-grained semantic information with location and category from coarse-grained semantic information outputted by the da Vinci surgical robot, which significantly diminished the necessary human annotation labor while striking an optimal balance between the quantity of manually annotated data and detection performance. The source code is available at https://github.com/Breezewrf/Weakly-Supervised-Yolov8.
</details>
<details>
<summary>摘要</summary>
能够自动探测和跟踪针对endooscopic视频记录的手术工具，将有很多有用的应用程序，可以transform不同方面的手术。在机器助手手术中，可以捕捉可能有用的数据，如手术工具类别，但这些数据稀疏、充满噪音，无法提供空间信息。我们提出了一种Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in Endoscopic Videos，以生成细化的semantic信息，包括位置和类别，从粗化的semantic信息输出ted by the da Vinci surgical robot，这有效减少了人工标注劳动，同时 strike an optimal balance between the quantity of manually annotated data and detection performance。源代码可以在https://github.com/Breezewrf/Weakly-Supervised-Yolov8中找到。
</details></li>
</ul>
<hr>
<h2 id="Dual-Reference-Source-Free-Active-Domain-Adaptation-for-Nasopharyngeal-Carcinoma-Tumor-Segmentation-across-Multiple-Hospitals"><a href="#Dual-Reference-Source-Free-Active-Domain-Adaptation-for-Nasopharyngeal-Carcinoma-Tumor-Segmentation-across-Multiple-Hospitals" class="headerlink" title="Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals"></a>Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13401">http://arxiv.org/abs/2309.13401</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whq-xxh/Active-GTV-Seg">https://github.com/whq-xxh/Active-GTV-Seg</a></li>
<li>paper_authors: Hongqiu Wang, Jian Chen, Shichen Zhang, Yuan He, Jinfeng Xu, Mengwan Wu, Jinlan He, Wenjun Liao, Xiangde Luo</li>
<li>for: 这个论文旨在提高nasopharyngeal carcinoma（NPC）的肿体卷积（GTV）分割精度，以确保NPC radiotherapy的效果。</li>
<li>methods: 这个论文提出了一种源自free active domain adaptation（SFADA）框架，用于解决GTV分割任务中的领域适应问题。该框架使用了双参照策略，选择目标领域中具有适应性和特定性的样本进行标注和模型细化。</li>
<li>results: 实验结果表明， compared to unsupervised domain adaptation（UDA）方法，SFADA方法可以更好地适应领域适应问题，并且可以与完全监督Upper Bound（UB）相当，即使只有几个标注样本。此外，该论文还收集了1057名NPC患者的临床数据，以验证该方法的有效性。<details>
<summary>Abstract</summary>
Nasopharyngeal carcinoma (NPC) is a prevalent and clinically significant malignancy that predominantly impacts the head and neck area. Precise delineation of the Gross Tumor Volume (GTV) plays a pivotal role in ensuring effective radiotherapy for NPC. Despite recent methods that have achieved promising results on GTV segmentation, they are still limited by lacking carefully-annotated data and hard-to-access data from multiple hospitals in clinical practice. Although some unsupervised domain adaptation (UDA) has been proposed to alleviate this problem, unconditionally mapping the distribution distorts the underlying structural information, leading to inferior performance. To address this challenge, we devise a novel Sourece-Free Active Domain Adaptation (SFADA) framework to facilitate domain adaptation for the GTV segmentation task. Specifically, we design a dual reference strategy to select domain-invariant and domain-specific representative samples from a specific target domain for annotation and model fine-tuning without relying on source-domain data. Our approach not only ensures data privacy but also reduces the workload for oncologists as it just requires annotating a few representative samples from the target domain and does not need to access the source data. We collect a large-scale clinical dataset comprising 1057 NPC patients from five hospitals to validate our approach. Experimental results show that our method outperforms the UDA methods and achieves comparable results to the fully supervised upper bound, even with few annotations, highlighting the significant medical utility of our approach. In addition, there is no public dataset about multi-center NPC segmentation, we will release code and dataset for future research.
</details>
<details>
<summary>摘要</summary>
《nasopharyngeal carcinoma (NPC)是一种流行的且严重影响头颈部的恶性肿瘤，精准定义Gross Tumor Volume (GTV)对NPC有效 radiotherapy至关重要。 despite recent methods have achieved promising results in GTV segmentation, they are still limited by the lack of carefully-annotated data and hard-to-access data from multiple hospitals in clinical practice. although some unsupervised domain adaptation (UDA) has been proposed to alleviate this problem, unconditionally mapping the distribution distorts the underlying structural information, leading to inferior performance. to address this challenge, we propose a novel Source-Free Active Domain Adaptation (SFADA) framework to facilitate domain adaptation for the GTV segmentation task. specifically, we design a dual reference strategy to select domain-invariant and domain-specific representative samples from a specific target domain for annotation and model fine-tuning without relying on source-domain data. our approach not only ensures data privacy but also reduces the workload for oncologists as it only requires annotating a few representative samples from the target domain and does not need to access the source data. we collect a large-scale clinical dataset comprising 1057 NPC patients from five hospitals to validate our approach. experimental results show that our method outperforms the UDA methods and achieves comparable results to the fully supervised upper bound, even with few annotations, highlighting the significant medical utility of our approach. in addition, there is no public dataset about multi-center NPC segmentation, we will release code and dataset for future research.》Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-mirror-Unet-architecture-for-PET-CT-lesion-segmentation"><a href="#A-mirror-Unet-architecture-for-PET-CT-lesion-segmentation" class="headerlink" title="A mirror-Unet architecture for PET&#x2F;CT lesion segmentation"></a>A mirror-Unet architecture for PET&#x2F;CT lesion segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13398">http://arxiv.org/abs/2309.13398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yrotstein/autopet2023_mv1">https://github.com/yrotstein/autopet2023_mv1</a></li>
<li>paper_authors: Yamila Rotstein Habarnau, Mauro Namías</li>
<li>for: 这个研究的目的是为了自动检测和分类内科癌症的变化，并将其分类为不同的类型。</li>
<li>methods: 这个研究使用了一种深度学习方法，即 combining two UNet-3D branches，其中一个分支用于从 CT 图像中分类组织，另一个分支则用于从 PET 图像中分类变化。</li>
<li>results: 研究发现，这种深度学习方法可以实现高精度的变化检测和分类，并且可以将变化分类为不同的类型。<details>
<summary>Abstract</summary>
Automatic lesion detection and segmentation from [${}^{18}$F]FDG PET/CT scans is a challenging task, due to the diversity of shapes, sizes, FDG uptake and location they may present, besides the fact that physiological uptake is also present on healthy tissues. In this work, we propose a deep learning method aimed at the segmentation of oncologic lesions, based on a combination of two UNet-3D branches. First, one of the network's branches is trained to segment a group of tissues from CT images. The other branch is trained to segment the lesions from PET images, combining on the bottleneck the embedded information of CT branch, already trained. We trained and validated our networks on the AutoPET MICCAI 2023 Challenge dataset. Our code is available at: https://github.com/yrotstein/AutoPET2023_Mv1.
</details>
<details>
<summary>摘要</summary>
自动检测和分割肿瘤从 [${}^{18}$F]FDG PET/CT扫描图像是一项具有挑战性的任务，由于肿瘤的多样性、大小、FDG吸收和位置的不同，以及健康组织也会有physiological吸收。在这项工作中，我们提出了基于深度学习的肿瘤分割方法，通过两个UNet-3D支持树的组合来实现。第一个网络支持树被训练用于从CT图像中分割一组组织。另一个支持树则被训练用于从PET图像中分割肿瘤，并将 embedding在树的瓶颈中的CT支持树已经训练完成。我们在AutoPET MICCAI 2023 Challenge数据集上训练和验证了我们的网络。我们的代码可以在以下地址找到：https://github.com/yrotstein/AutoPET2023_Mv1。
</details></li>
</ul>
<hr>
<h2 id="YOLORe-IDNet-An-Efficient-Multi-Camera-System-for-Person-Tracking"><a href="#YOLORe-IDNet-An-Efficient-Multi-Camera-System-for-Person-Tracking" class="headerlink" title="YOLORe-IDNet: An Efficient Multi-Camera System for Person-Tracking"></a>YOLORe-IDNet: An Efficient Multi-Camera System for Person-Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13387">http://arxiv.org/abs/2309.13387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vipin Gautam, Shitala Prasad, Sharad Sinha</li>
<li>for: 实时多摄像头人识别和跟踪</li>
<li>methods:  correlate filters 和 Intersection Over Union (IOU) 约束，以及基于 YOLOv5 的深度学习人体重复识别 (Re-ID)</li>
<li>results: 高达 79% 的 F1-Score 和 59% 的 IOU，与现有状态的算法相当，在公共可用 OTB-100 数据集上进行评估。<details>
<summary>Abstract</summary>
The growing need for video surveillance in public spaces has created a demand for systems that can track individuals across multiple cameras feeds in real-time. While existing tracking systems have achieved impressive performance using deep learning models, they often rely on pre-existing images of suspects or historical data. However, this is not always feasible in cases where suspicious individuals are identified in real-time and without prior knowledge. We propose a person-tracking system that combines correlation filters and Intersection Over Union (IOU) constraints for robust tracking, along with a deep learning model for cross-camera person re-identification (Re-ID) on top of YOLOv5. The proposed system quickly identifies and tracks suspect in real-time across multiple cameras and recovers well after full or partial occlusion, making it suitable for security and surveillance applications. It is computationally efficient and achieves a high F1-Score of 79% and an IOU of 59% comparable to existing state-of-the-art algorithms, as demonstrated in our evaluation on a publicly available OTB-100 dataset. The proposed system offers a robust and efficient solution for the real-time tracking of individuals across multiple camera feeds. Its ability to track targets without prior knowledge or historical data is a significant improvement over existing systems, making it well-suited for public safety and surveillance applications.
</details>
<details>
<summary>摘要</summary>
随着公共空间内部照相设备的增加，需要一种可以在多个摄像头视频流中实时跟踪人员的系统。现有的跟踪系统已经使用深度学习模型实现了出色的性能，但是它们常常依赖于先前的图像或历史数据。然而，这并不总是可行的，特别是在实时发现疑犯并无先知的情况下。我们提议一种结合相关滤波器和交叉区域大小（IOU）约束的人员跟踪系统，并在YOLOv5之上使用深度学习模型进行交叉摄像头人员重新识别（Re-ID）。提议的系统可以快速地在多个摄像头视频流中识别和跟踪疑犯，并在全或部分遮挡后快速恢复，适用于安全监控应用。它的计算效率高，并在OTB-100公共数据集上实现了79%的F1分数和59%的IOU分数，与现有状态的算法相当。提议的系统提供了一种实时、有效的人员跟踪解决方案，无需先知或历史数据，对公共安全和监控应用有 significannot improvement。
</details></li>
</ul>
<hr>
<h2 id="Cine-cardiac-MRI-reconstruction-using-a-convolutional-recurrent-network-with-refinement"><a href="#Cine-cardiac-MRI-reconstruction-using-a-convolutional-recurrent-network-with-refinement" class="headerlink" title="Cine cardiac MRI reconstruction using a convolutional recurrent network with refinement"></a>Cine cardiac MRI reconstruction using a convolutional recurrent network with refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13385">http://arxiv.org/abs/2309.13385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vios-s/CMRxRECON_Challenge_EDIPO">https://github.com/vios-s/CMRxRECON_Challenge_EDIPO</a></li>
<li>paper_authors: Yuyang Xue, Yuning Du, Gianluca Carloni, Eva Pachetti, Connor Jordan, Sotirios A. Tsaftaris</li>
<li>for: 心脏功能和状态的非侵入性理解</li>
<li>methods: 使用 convolutional recurrent neural network (CRNN) 构成和单影像超解析模组</li>
<li>results: 比基eline情况下提高4.4%的结构相似性和3.9%的normalized mean square error<details>
<summary>Abstract</summary>
Cine Magnetic Resonance Imaging (MRI) allows for understanding of the heart's function and condition in a non-invasive manner. Undersampling of the $k$-space is employed to reduce the scan duration, thus increasing patient comfort and reducing the risk of motion artefacts, at the cost of reduced image quality. In this challenge paper, we investigate the use of a convolutional recurrent neural network (CRNN) architecture to exploit temporal correlations in supervised cine cardiac MRI reconstruction. This is combined with a single-image super-resolution refinement module to improve single coil reconstruction by 4.4\% in structural similarity and 3.9\% in normalised mean square error compared to a plain CRNN implementation. We deploy a high-pass filter to our $\ell_1$ loss to allow greater emphasis on high-frequency details which are missing in the original data. The proposed model demonstrates considerable enhancements compared to the baseline case and holds promising potential for further improving cardiac MRI reconstruction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-Grids-Exploring-Elastic-Input-Sampling-for-Vision-Transformers"><a href="#Beyond-Grids-Exploring-Elastic-Input-Sampling-for-Vision-Transformers" class="headerlink" title="Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers"></a>Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13353">http://arxiv.org/abs/2309.13353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam Pardyl, Grzegorz Kurzejamski, Jan Olszewski, Tomasz Trzciński, Bartosz Zieliński</li>
<li>for: 该论文旨在提高视transformer在实际应用中的表现和效率，通过提高输入灵活性。</li>
<li>methods: 论文提出了一种用于评估视transformer输入灵活性的评价协议，并提出了对transformer架构和训练策略的修改，以增强其输入灵活性。</li>
<li>results: 经过广泛的实验，论文发现了输入 sampling 策略的机会和挑战，并提供了关于视transformer在不同应用场景中的表现。<details>
<summary>Abstract</summary>
Vision transformers have excelled in various computer vision tasks but mostly rely on rigid input sampling using a fixed-size grid of patches. This limits their applicability in real-world problems, such as in the field of robotics and UAVs, where one can utilize higher input elasticity to boost model performance and efficiency. Our paper addresses this limitation by formalizing the concept of input elasticity for vision transformers and introducing an evaluation protocol, including dedicated metrics for measuring input elasticity. Moreover, we propose modifications to the transformer architecture and training regime, which increase its elasticity. Through extensive experimentation, we spotlight opportunities and challenges associated with input sampling strategies.
</details>
<details>
<summary>摘要</summary>
< translating into Simplified Chinese...</SYS>视力变换器在计算机视觉任务中表现出色，但它们通常采用固定大小网格的粒子 sampling 来输入数据。这限制了它们在实际应用中，如 роботи克和无人机领域， где可以使用更高的输入灵活性来提高模型性能和效率。我们的论文解决了这个限制，正式表述了视力变换器的输入灵活性概念，并提出了评估协议，包括专门为测量输入灵活性的指标。此外，我们还提出了 transformer 架构和训练方法的修改，以增加其灵活性。通过广泛的实验，我们把关注到输入采样策略的机会和挑战。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FedDrive-v2-an-Analysis-of-the-Impact-of-Label-Skewness-in-Federated-Semantic-Segmentation-for-Autonomous-Driving"><a href="#FedDrive-v2-an-Analysis-of-the-Impact-of-Label-Skewness-in-Federated-Semantic-Segmentation-for-Autonomous-Driving" class="headerlink" title="FedDrive v2: an Analysis of the Impact of Label Skewness in Federated Semantic Segmentation for Autonomous Driving"></a>FedDrive v2: an Analysis of the Impact of Label Skewness in Federated Semantic Segmentation for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13336">http://arxiv.org/abs/2309.13336</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Erosinho13/FedDrive">https://github.com/Erosinho13/FedDrive</a></li>
<li>paper_authors: Eros Fanì, Marco Ciccone, Barbara Caputo</li>
<li>for: 研究 semantic segmentation 在自动驾驶中的 federated learning  benchmark 的分布式skewness 的影响。</li>
<li>methods: 提出了 six 种新的 federated 场景，以研究 label skewness 对 segmentation 模型的性能的影响，并与域shift 的影响进行比较。</li>
<li>results: 研究了使用域信息 durante testing 的影响。Here’s the English version for reference:</li>
<li>for: Investigating the impact of distribution skewness on semantic segmentation in autonomous driving using federated learning benchmarks.</li>
<li>methods: Propose six new federated scenarios to study the effect of label skewness on segmentation models and compare it with the effect of domain shift.</li>
<li>results: Study the impact of using domain information during testing.<details>
<summary>Abstract</summary>
We propose FedDrive v2, an extension of the Federated Learning benchmark for Semantic Segmentation in Autonomous Driving. While the first version aims at studying the effect of domain shift of the visual features across clients, in this work, we focus on the distribution skewness of the labels. We propose six new federated scenarios to investigate how label skewness affects the performance of segmentation models and compare it with the effect of domain shift. Finally, we study the impact of using the domain information during testing. Official website: https://feddrive.github.io
</details>
<details>
<summary>摘要</summary>
我们提出了FedDrive v2，它是基于联合学习benchmark для自动驾驶 semantic segmentation的扩展。在前一版中，我们研究了视觉特征之间客户端域转换的效果，而在这次工作中，我们专注于标签的分布偏度。我们提出了六种新的联合场景，以研究标签偏度对 segmentation 模型的性能影响，并与域转换的影响进行比较。最后，我们研究了在测试时使用域信息的影响。官方网站：https://feddrive.github.ioNote: "联合学习" (federated learning) in Chinese is usually translated as "联合学习" (federated learning), but in this context, I used "基于联合学习benchmark" (based on federated learning benchmark) to emphasize that FedDrive is an extension of a existing benchmark.
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Incomplete-Annotation-Issue-in-Universal-Lesion-Detection-Task-By-Exploratory-Training"><a href="#Tackling-the-Incomplete-Annotation-Issue-in-Universal-Lesion-Detection-Task-By-Exploratory-Training" class="headerlink" title="Tackling the Incomplete Annotation Issue in Universal Lesion Detection Task By Exploratory Training"></a>Tackling the Incomplete Annotation Issue in Universal Lesion Detection Task By Exploratory Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13306">http://arxiv.org/abs/2309.13306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Bai, Benteng Ma, Changyang Li, Yong Xia</li>
<li>for: 这种研究的目的是提高非特征化图像诊断的精度，尤其是检测医疗图像中的多种器官 lesion。</li>
<li>methods: 该研究使用了深度学习方法，并利用 pseudo-label 技术来挖掘未标注的对象。</li>
<li>results: 研究表明，提出的方法可以superior表现于现有的方法，在两个医疗图像 datasets 上。<details>
<summary>Abstract</summary>
Universal lesion detection has great value for clinical practice as it aims to detect various types of lesions in multiple organs on medical images. Deep learning methods have shown promising results, but demanding large volumes of annotated data for training. However, annotating medical images is costly and requires specialized knowledge. The diverse forms and contrasts of objects in medical images make fully annotation even more challenging, resulting in incomplete annotations. Directly training ULD detectors on such datasets can yield suboptimal results. Pseudo-label-based methods examine the training data and mine unlabelled objects for retraining, which have shown to be effective to tackle this issue. Presently, top-performing methods rely on a dynamic label-mining mechanism, operating at the mini-batch level. However, the model's performance varies at different iterations, leading to inconsistencies in the quality of the mined labels and limits their performance enhancement. Inspired by the observation that deep models learn concepts with increasing complexity, we introduce an innovative exploratory training to assess the reliability of mined lesions over time. Specifically, we introduce a teacher-student detection model as basis, where the teacher's predictions are combined with incomplete annotations to train the student. Additionally, we design a prediction bank to record high-confidence predictions. Each sample is trained several times, allowing us to get a sequence of records for each sample. If a prediction consistently appears in the record sequence, it is likely to be a true object, otherwise it may just a noise. This serves as a crucial criterion for selecting reliable mined lesions for retraining. Our experimental results substantiate that the proposed framework surpasses state-of-the-art methods on two medical image datasets, demonstrating its superior performance.
</details>
<details>
<summary>摘要</summary>
全面搜寻检测在医疗实践中具有极高的价值，旨在多种器官的医学图像上检测不同类型的损害。深度学习方法在检测中表现出了扎根的成绩，但需要大量已注解数据进行训练。然而，注解医学图像是成本高昂的，需要专业知识。医学图像中 объек的多样性和对比性使得全面注解变得更加困难，从而导致了不完全的注解。直接在如此数据上训练 ULD 检测器可能会得到不佳的结果。基于 pseudo-label 方法，我们可以在训练数据中挖掘未注解的对象，以便重新训练。目前，最高级的方法通过动态标签采集机制，在小批量级别进行操作。然而，模型在不同迭代中的性能会变化，导致标签采集过程中的品质不稳定，限制了性能提高的可能性。我们从深度学习模型学习对象的复杂性的观察中灵感，并提出了一种创新的探索训练方法。具体来说，我们在教师-学生检测模型的基础上，将教师的预测与不完全注解结合使用，用于训练学生。此外，我们还设计了预测银行，以记录高置信预测。每个样本都会在多次训练中得到多个记录，这些记录中的一些预测可能是真实的对象，而其他的预测可能只是噪音。这些记录可以作为选择可靠挖掘的标准。我们的实验结果表明，我们的方法在两个医学图像数据集上超过了当前state-of-the-art方法的性能，这证明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="C-2-VAE-Gaussian-Copula-based-VAE-Differing-Disentangled-from-Coupled-Representations-with-Contrastive-Posterior"><a href="#C-2-VAE-Gaussian-Copula-based-VAE-Differing-Disentangled-from-Coupled-Representations-with-Contrastive-Posterior" class="headerlink" title="C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior"></a>C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13303">http://arxiv.org/abs/2309.13303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhangkai Wu, Longbing Cao</li>
<li>for: 学习分离的隐藏因素和相关的隐藏因素</li>
<li>methods: 使用自适应变换自动机（VAE）和循环优化</li>
<li>results: 提高分离表示学习的效果，并且解决了TC-基于VAE的不稳定性和表达和表示之间的负面效应<details>
<summary>Abstract</summary>
We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together with the TC loss for eliminating entangled factors and strengthening disentangled representations. C$^2$VAE demonstrates a strong effect in enhancing disentangled representation learning. C$^2$VAE further contributes to improved optimization addressing the TC-based VAE instability and the trade-off between reconstruction and representation.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自助学习的变分自动编码器（VAE），用于同时学习独立的隐藏因素和相关的隐藏因素。然后，我们使用一种自我超级vised类ifier来消除相关的表示，从而增强独立表示学习。为此，我们引入了一种叫做Contrastive Copula VAE（C$^2$VAE），不需要对数据的 probabilistic principle 进行严格的模型假设，同时可以学习分解 posterior（证明下界，ELBO）和总相关度（TC）驱动的分解，以学习独立的隐藏表示。然后，一种自我超级vised类ifier可以分辨出独立的表示和相关的表示，并通过对这两个类别进行对比来regular化这种对比分类。C$^2$VAE在提高独立表示学习的效果，同时也有助于改善优化，解决TC-基于VAE的不稳定性和表示重建之间的负面选择问题。
</details></li>
</ul>
<hr>
<h2 id="Gaining-the-Sparse-Rewards-by-Exploring-Binary-Lottery-Tickets-in-Spiking-Neural-Network"><a href="#Gaining-the-Sparse-Rewards-by-Exploring-Binary-Lottery-Tickets-in-Spiking-Neural-Network" class="headerlink" title="Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in Spiking Neural Network"></a>Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in Spiking Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13302">http://arxiv.org/abs/2309.13302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Cheng, Jiahang Cao, Erjia Xiao, Pu Zhao, Mengshu Sun, Jiaxu Wang, Jize Zhang, Xue Lin, Bhavya Kailkhura, Kaidi Xu, Renjing Xu</li>
<li>for: This paper aims to explore the efficiency of Spiking Neural Networks (SNNs) by investigating the existence of Lottery Tickets (LTs) in binary SNNs and comparing the spiking mechanism with simple model binarization.</li>
<li>methods: The paper proposes a sparse training method called Binary Weights Spiking Lottery Tickets (BinW-SLT) to find LTs in binary SNNs under different network structures.</li>
<li>results: The paper shows that BinW-SLT can achieve up to +5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary LTs, as well as achieve 1.86x and 8.92x energy saving compared with full-precision SNNs and ANNs.<details>
<summary>Abstract</summary>
Spiking Neural Network (SNN) as a brain-inspired strategy receives lots of attention because of the high-sparsity and low-power properties derived from its inherent spiking information state. To further improve the efficiency of SNN, some works declare that the Lottery Tickets (LTs) Hypothesis, which indicates that the Artificial Neural Network (ANN) contains a subnetwork without sacrificing the performance of the original network, also exists in SNN. However, the spiking information handled by SNN has a natural similarity and affinity with binarization in sparsification. Therefore, to further explore SNN efficiency, this paper focuses on (1) the presence or absence of LTs in the binary SNN, and (2) whether the spiking mechanism is a superior strategy in terms of handling binary information compared to simple model binarization. To certify these consumptions, a sparse training method is proposed to find Binary Weights Spiking Lottery Tickets (BinW-SLT) under different network structures. Through comprehensive evaluations, we show that BinW-SLT could attain up to +5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary LTs, as well as achieve 1.86x and 8.92x energy saving compared with full-precision SNN and ANN.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）因其自然的简约性和低功耗特性而受到了很多关注。一些研究表明，Artificial Neural Network（ANN）中的子网络也存在于SNN中，这被称为彩票假设（LTs）。然而，SNN处理的脉冲信息具有自然的相似性和亲和力，因此可以通过对binary化进行压缩来提高SNN的效率。为了进一步探索SNN的效率，本文主要研究了以下两个问题：（1）在二进制SNN中是否存在LTs，（2）脉冲机制是对binary信息处理的超越策略吗？为了证明这些消耗，我们提出了一种稀疏训练方法，可以在不同的网络结构下找到Binary Weights Spiking Lottery Tickets（BinW-SLT）。经过全面的评估，我们发现BinW-SLT可以在CIFAR-10和CIFAR-100上提高+5.86%和+3.17%，并且可以在full-precision SNN和ANN上实现1.86x和8.92x的能量减少。
</details></li>
</ul>
<hr>
<h2 id="MP-MVS-Multi-Scale-Windows-PatchMatch-and-Planar-Prior-Multi-View-Stereo"><a href="#MP-MVS-Multi-Scale-Windows-PatchMatch-and-Planar-Prior-Multi-View-Stereo" class="headerlink" title="MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo"></a>MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13294">http://arxiv.org/abs/2309.13294</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rongxuantan/mp-mvs">https://github.com/rongxuantan/mp-mvs</a></li>
<li>paper_authors: Rongxuan Tan, Qing Wang, Xueyan Wang, Chao Yan, Yang Sun, Youyang Feng</li>
<li>for: 提高多视图ステレオ（MVS）基于3D重建的准确性。</li>
<li>methods: 提出了一种可靠的多观察窗口PatchMatch（mPM），以获取无文本区域的可靠深度值。此外，我们还改进了现有的检查板样本方案，限制我们的样本到远距离区域，以提高空间卷积的效率，同时避免生成异常值。最后，我们引入并改进了平面假设辅助PatchMatch（ACMP），而不是依赖于光学一致性，我们利用多视图之间的几何一致信息选择可靠的三角形 vertices。</li>
<li>results: 我们的方法在ETH3D高分辨率多视图标准准测试集上与多个状态 искусственный智能方法进行比较，结果表明，我们的方法可以达到状态 искусственный智能水平。<details>
<summary>Abstract</summary>
Significant strides have been made in enhancing the accuracy of Multi-View Stereo (MVS)-based 3D reconstruction. However, untextured areas with unstable photometric consistency often remain incompletely reconstructed. In this paper, we propose a resilient and effective multi-view stereo approach (MP-MVS). We design a multi-scale windows PatchMatch (mPM) to obtain reliable depth of untextured areas. In contrast with other multi-scale approaches, which is faster and can be easily extended to PatchMatch-based MVS approaches. Subsequently, we improve the existing checkerboard sampling schemes by limiting our sampling to distant regions, which can effectively improve the efficiency of spatial propagation while mitigating outlier generation. Finally, we introduce and improve planar prior assisted PatchMatch of ACMP. Instead of relying on photometric consistency, we utilize geometric consistency information between multi-views to select reliable triangulated vertices. This strategy can obtain a more accurate planar prior model to rectify photometric consistency measurements. Our approach has been tested on the ETH3D High-res multi-view benchmark with several state-of-the-art approaches. The results demonstrate that our approach can reach the state-of-the-art. The associated codes will be accessible at https://github.com/RongxuanTan/MP-MVS.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified Chinese多视图ステレオ（MVS）ベースの3D复元において、精度が向上した进歩がありました。しかし、不安定な光学的一致性を持つ不染色领域がまだ不完全に复元されていることがあります。この论文では、抗强度的かつ效率的な多视点ステレオアプローチ（MP-MVS）を提案します。我々は、信赖性の高い深度を得るために、多スケールのウィンドウパッチマッチ（mPM）を设计しました。他の多スケールアプローチと异なり、我々のアプローチは速く、パッチマッチベースのMVSアプローチに容易に拡张できます。次に、我々は、离れた地域に限定されたサンプリングを行うことで、空间的な広がりを改善することができます。また、アウトライアーの生成を抑制することができます。最后に、我々は、写真的一致性を基准にしてパッチマッチをサポートする计画的な射影を提案します。このストラテジは、多视点间の几何学的一致性情报を利用して、信赖性の高い平面モデルを构筑することができます。我々のアプローチは、ETH3D High-res多视点ベンチマークで复数の现状最高のアプローチとの比较を行い、结果はstate-of-the-artに到达することを示しています。関连するコードは、https://github.com/RongxuanTan/MP-MVSにアクセスできます。
</details></li>
</ul>
<hr>
<h2 id="Domain-Guided-Conditional-Diffusion-Model-for-Unsupervised-Domain-Adaptation"><a href="#Domain-Guided-Conditional-Diffusion-Model-for-Unsupervised-Domain-Adaptation" class="headerlink" title="Domain-Guided Conditional Diffusion Model for Unsupervised Domain Adaptation"></a>Domain-Guided Conditional Diffusion Model for Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14360">http://arxiv.org/abs/2309.14360</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulong Zhang, Shuhao Chen, Weisen Jiang, Yu Zhang, Jiangang Lu, James T. Kwok</li>
<li>for: 提高深度学习模型在新应用场景中的性能，增强Unsupervised Domain Adaptation（UDA）技术的表现。</li>
<li>methods: 提出DomAin-guided Conditional Diffusion Model（DACDM），通过控制生成样本的标签信息和引入域类分类器，以生成高准确性和多样性的目标域样本，从而使得现有的UDA方法更容易在目标域上传输。</li>
<li>results: 经验表明，DACDM可以大幅提高现有UDA方法在多种标准权重环境下的表现。<details>
<summary>Abstract</summary>
Limited transferability hinders the performance of deep learning models when applied to new application scenarios. Recently, Unsupervised Domain Adaptation (UDA) has achieved significant progress in addressing this issue via learning domain-invariant features. However, the performance of existing UDA methods is constrained by the large domain shift and limited target domain data. To alleviate these issues, we propose DomAin-guided Conditional Diffusion Model (DACDM) to generate high-fidelity and diversity samples for the target domain. In the proposed DACDM, by introducing class information, the labels of generated samples can be controlled, and a domain classifier is further introduced in DACDM to guide the generated samples for the target domain. The generated samples help existing UDA methods transfer from the source domain to the target domain more easily, thus improving the transfer performance. Extensive experiments on various benchmarks demonstrate that DACDM brings a large improvement to the performance of existing UDA methods.
</details>
<details>
<summary>摘要</summary>
因深度学习模型在新应用场景中表现不佳的限制性，现在不监督领域适应（UDA）已经取得了显著的进步，通过学习领域共同特征来解决这一问题。然而，现有的 UDA 方法受到大领域差异和有限目标领域数据的限制。为了解决这些问题，我们提议了带有类信息的 DomAin-guided Conditional Diffusion Model (DACDM)，用于生成高准确性和多样性的目标领域样本。在我们的 DACDM 中，通过引入类信息，生成的样本的标签可以被控制，并在 DACDM 中引入了领域分类器，以便导引生成的样本到目标领域。这些生成的样本可以帮助现有的 UDA 方法更好地在源领域和目标领域之间传输，从而提高传输性能。我们在各种标准准点上进行了广泛的实验，并证明了 DACDM 可以大幅提高现有 UDA 方法的表现。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Reverse-Engineering-Creating-computer-aided-design-CAD-models-from-multi-view-images"><a href="#Automatic-Reverse-Engineering-Creating-computer-aided-design-CAD-models-from-multi-view-images" class="headerlink" title="Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images"></a>Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13281">http://arxiv.org/abs/2309.13281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henrik Jobczyk, Hanno Homann</li>
<li>for: automated reverse engineering task</li>
<li>methods:  combine three distinct stages: convolutional neural network, multi-view pooling, and transformer-based CAD sequence generator</li>
<li>results: successfully reconstructed valid CAD models from simulated test image data, and demonstrated some capabilities in real-world test with actual photographs of three-dimensional test objects, but limited to basic shapes.<details>
<summary>Abstract</summary>
Generation of computer-aided design (CAD) models from multi-view images may be useful in many practical applications. To date, this problem is usually solved with an intermediate point-cloud reconstruction and involves manual work to create the final CAD models. In this contribution, we present a novel network for an automated reverse engineering task. Our network architecture combines three distinct stages: A convolutional neural network as the encoder stage, a multi-view pooling stage and a transformer-based CAD sequence generator.   The model is trained and evaluated on a large number of simulated input images and extensive optimization of model architectures and hyper-parameters is performed. A proof-of-concept is demonstrated by successfully reconstructing a number of valid CAD models from simulated test image data. Various accuracy metrics are calculated and compared to a state-of-the-art point-based network.   Finally, a real world test is conducted supplying the network with actual photographs of two three-dimensional test objects. It is shown that some of the capabilities of our network can be transferred to this domain, even though the training exclusively incorporates purely synthetic training data. However to date, the feasible model complexity is still limited to basic shapes.
</details>
<details>
<summary>摘要</summary>
计算机支持设计（CAD）模型生成从多视图图像可能在很多实际应用中有用。目前，这个问题通常通过中间点云重建解决，并且需要手动创建最终CAD模型。在这篇论文中，我们提出了一种新的网络，用于自动反工程设计任务。我们的网络架构包括三个不同的阶段：一个卷积神经网络作为编码阶段，一个多视图池化阶段，以及一个基于变换器的CAD序列生成器。我们在一大量的模拟输入图像和优化模型结构和超参数方面进行了训练和评估。我们成功地从模拟测试数据中生成了一些有效的CAD模型。我们还计算了几个精度指标，并与当前点 cloud 网络进行比较。最后，我们在实际测试中使用实际照片对两个三维测试对象进行测试，并证明了我们的网络部分可以在这个领域中转移。然而，目前可能的模型复杂度仍然受限于基本形状。
</details></li>
</ul>
<hr>
<h2 id="Discwise-Active-Learning-for-LiDAR-Semantic-Segmentation"><a href="#Discwise-Active-Learning-for-LiDAR-Semantic-Segmentation" class="headerlink" title="Discwise Active Learning for LiDAR Semantic Segmentation"></a>Discwise Active Learning for LiDAR Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13276">http://arxiv.org/abs/2309.13276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ozan Unal, Dengxin Dai, Ali Tamer Unal, Luc Van Gool</li>
<li>For: This paper explores the use of active learning (AL) for LiDAR semantic segmentation, with a focus on improving annotation efficiency and reducing costs.* Methods: The proposed method, called DiAL, uses a discwise approach to query the region covered by a single frame on global coordinates, and labels all frames simultaneously. It also addresses two major challenges in discwise AL: a new acquisition function that takes 3D point density changes into consideration, and a mixed-integer linear program to select multiple frames while avoiding disc intersections.* Results: The proposed method is evaluated on a real-world LiDAR dataset, and shows improved performance and efficiency compared to traditional sequential labeling methods. Additionally, a semi-supervised learning approach is proposed to utilize all frames within the dataset and further improve performance.<details>
<summary>Abstract</summary>
While LiDAR data acquisition is easy, labeling for semantic segmentation remains highly time consuming and must therefore be done selectively. Active learning (AL) provides a solution that can iteratively and intelligently label a dataset while retaining high performance and a low budget. In this work we explore AL for LiDAR semantic segmentation. As a human expert is a component of the pipeline, a practical framework must consider common labeling techniques such as sequential labeling that drastically improve annotation times. We therefore propose a discwise approach (DiAL), where in each iteration, we query the region a single frame covers on global coordinates, labeling all frames simultaneously. We then tackle the two major challenges that emerge with discwise AL. Firstly we devise a new acquisition function that takes 3D point density changes into consideration which arise due to location changes or ego-vehicle motion. Next we solve a mixed-integer linear program that provides a general solution to the selection of multiple frames while taking into consideration the possibilities of disc intersections. Finally we propose a semi-supervised learning approach to utilize all frames within our dataset and improve performance.
</details>
<details>
<summary>摘要</summary>
利用LiDAR数据获取 relativamente fácil，但是用于 semantic segmentation 的标注仍然非常时间consuming，因此需要选择性地进行标注。活动学习（AL）提供了一个解决方案，可以逐步地、智能地标注数据集，同时保持高性能和低预算。在这项工作中，我们探索了 LiDAR semantic segmentation 中的 AL。作为人类专家是数据流水线的一部分，我们需要考虑常见的标注技术，如顺序标注，以提高标注时间的效率。因此，我们提出了一种区域方法（DiAL），其中，在每次迭代中，我们查询当前帧所覆盖的全球坐标范围，并同时标注所有帧。然后，我们解决了两个主要的挑战，即：1. 根据Location changes 或者自动车动的影响，3D 点云 density 发生变化，我们提出了一种新的获取函数，以便考虑这些变化。2. 我们解决了板块交叠的问题，通过一种混合整数线性Programming 提供一个通用的解决方案，以便选择多帧的板块。3. 最后，我们提出了一种半supervised learning 方法，以利用整个数据集，并提高性能。
</details></li>
</ul>
<hr>
<h2 id="GLOBER-Coherent-Non-autoregressive-Video-Generation-via-GLOBal-Guided-Video-DecodER"><a href="#GLOBER-Coherent-Non-autoregressive-Video-Generation-via-GLOBal-Guided-Video-DecodER" class="headerlink" title="GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER"></a>GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13274">http://arxiv.org/abs/2309.13274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iva-mzsun/glober">https://github.com/iva-mzsun/glober</a></li>
<li>paper_authors: Mingzhen Sun, Weining Wang, Zihan Qin, Jiahui Sun, Sihan Chen, Jing Liu</li>
<li>for: 这个论文目的是提出一种新的非 autoregressive 视频生成方法，以提高视频生成的全局性和本地性。</li>
<li>methods: 该方法首先生成全局特征，以获取全面的全局指导，然后基于全局特征，通过非 autoregressive 的方式，生成具有全局性和本地性的视频帧。特别是，我们提出了一个视频自编码器，该自编码器将视频转换为全局特征，并建立了一个基于扩散模型的视频解码器，该解码器通过非 autoregressive 的方式，生成视频帧。</li>
<li>results: 我们的实验结果表明，我们的提出的方法可以具有高效率和高质量的视频生成。我们在多个 benchmark 上达到了新的州OF-THE-ART 结果。<details>
<summary>Abstract</summary>
Video generation necessitates both global coherence and local realism. This work presents a novel non-autoregressive method GLOBER, which first generates global features to obtain comprehensive global guidance and then synthesizes video frames based on the global features to generate coherent videos. Specifically, we propose a video auto-encoder, where a video encoder encodes videos into global features, and a video decoder, built on a diffusion model, decodes the global features and synthesizes video frames in a non-autoregressive manner. To achieve maximum flexibility, our video decoder perceives temporal information through normalized frame indexes, which enables it to synthesize arbitrary sub video clips with predetermined starting and ending frame indexes. Moreover, a novel adversarial loss is introduced to improve the global coherence and local realism between the synthesized video frames. Finally, we employ a diffusion-based video generator to fit the global features outputted by the video encoder for video generation. Extensive experimental results demonstrate the effectiveness and efficiency of our proposed method, and new state-of-the-art results have been achieved on multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
视频生成需要both全局一致性和地方现实性。这项工作提出了一种新的非 autoregressive方法GLOBER，它首先生成全局特征来获得全面的全局指导，然后根据全局特征来生成协调的视频帧，以生成一致的视频。具体来说，我们提出了一个视频自编码器，其中视频编码器将视频编码成全局特征，而视频解码器，基于扩散模型，将全局特征解码并在非 autoregressive 方式下synthesize视频帧。为了保证最大的灵活性，我们的视频解码器通过normalized帧索引来感知时间信息，这使其能够synthesize任意的子视频片段，并且通过引入novel adversarial loss来提高全局一致性和地方现实性 между生成的视频帧。最后，我们使用扩散基于的视频生成器来适应GLOBER输出的全局特征。我们的实验结果表明，我们的提出的方法效果和效率都非常高，并在多个标准准则上达到了新的状态码。
</details></li>
</ul>
<hr>
<h2 id="Randomize-to-Generalize-Domain-Randomization-for-Runway-FOD-Detection"><a href="#Randomize-to-Generalize-Domain-Randomization-for-Runway-FOD-Detection" class="headerlink" title="Randomize to Generalize: Domain Randomization for Runway FOD Detection"></a>Randomize to Generalize: Domain Randomization for Runway FOD Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13264">http://arxiv.org/abs/2309.13264</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Javaria Farooq, Nayyer Aafaq, M Khizer Ali Khan, Ammar Saleem, M Ibraheem Siddiqui<br>for:* The paper aims to improve object detection in low-resolution images with small objects and diverse backgrounds, which is challenging for existing methods.methods:* The proposed method, Synthetic Randomized Image Augmentation (SRIA), consists of two stages: weakly supervised pixel-level segmentation mask generation and batch-wise synthesis of artificial images with diverse augmentations.results:* The proposed method significantly improves object detection accuracy on out-of-distribution (OOD) test sets, with a reported improvement from 41% to 92%. The method also outperforms several state-of-the-art (SOTA) models, including CenterNet, SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit, on a publicly available foreign object debris (FOD) dataset.<details>
<summary>Abstract</summary>
Tiny Object Detection is challenging due to small size, low resolution, occlusion, background clutter, lighting conditions and small object-to-image ratio. Further, object detection methodologies often make underlying assumption that both training and testing data remain congruent. However, this presumption often leads to decline in performance when model is applied to out-of-domain(unseen) data. Techniques like synthetic image generation are employed to improve model performance by leveraging variations in input data. Such an approach typically presumes access to 3D-rendered datasets. In contrast, we propose a novel two-stage methodology Synthetic Randomized Image Augmentation (SRIA), carefully devised to enhance generalization capabilities of models encountering 2D datasets, particularly with lower resolution which is more practical in real-world scenarios. The first stage employs a weakly supervised technique to generate pixel-level segmentation masks. Subsequently, the second stage generates a batch-wise synthesis of artificial images, carefully designed with an array of diverse augmentations. The efficacy of proposed technique is illustrated on challenging foreign object debris (FOD) detection. We compare our results with several SOTA models including CenterNet, SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit on a publicly available FOD-A dataset. We also construct an out-of-distribution test set encompassing 800 annotated images featuring a corpus of ten common categories. Notably, by harnessing merely 1.81% of objects from source training data and amalgamating with 29 runway background images, we generate 2227 synthetic images. Subsequent model retraining via transfer learning, utilizing enriched dataset generated by domain randomization, demonstrates significant improvement in detection accuracy. We report that detection accuracy improved from an initial 41% to 92% for OOD test set.
</details>
<details>
<summary>摘要</summary>
小 объек detection 是一个挑战，主要由于小型、低分辨率、 occlusion、背景噪音、照明条件以及小对图像比率而导致。此外，检测方法ologies 经常假设训练和测试数据保持一致，但这种假设常导致模型在未经验数据上下运行时表现下降。为了改善模型性能，人们通常采用生成 Synthetic 图像的技术。然而，这些技术通常假设有许多3D-rendered 数据可供使用。在这种情况下，我们提出了一种新的两Stage 方法，即Synthetic Randomized Image Augmentation（SRIA），旨在提高模型在2D数据上的泛化能力。首先，我们使用弱有监督技术生成像素级分割标记。然后，第二stage 使用批量 Synthesis 技术生成一批人工生成的假图像，并且特意设计了一系列多样化的增强。我们证明了我们的方法在困难的外部物杂（FOD）检测 task 上表现出色。我们与多个state-of-the-art（SOTA）模型，包括CenterNet、SSD、YOLOv3、YOLOv4、YOLOv5和Outer Vit进行比较。我们还构建了一个异常数据集，包括800个标注图像，其中包含10种常见类别。吸引地，我们只需使用来源训练数据中的1.81%的对象，并将其混合到29个runway背景图像中，就可以生成2227个假图像。然后，通过将模型重新训练，使用了增强的频率 randomization 数据集，我们可以看到检测精度从41%提高到92%。
</details></li>
</ul>
<hr>
<h2 id="Order-preserving-Consistency-Regularization-for-Domain-Adaptation-and-Generalization"><a href="#Order-preserving-Consistency-Regularization-for-Domain-Adaptation-and-Generalization" class="headerlink" title="Order-preserving Consistency Regularization for Domain Adaptation and Generalization"></a>Order-preserving Consistency Regularization for Domain Adaptation and Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13258">http://arxiv.org/abs/2309.13258</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengmeng Jing, Xiantong Zhen, Jingjing Li, Cees Snoek</li>
<li>for: 提高cross-domain任务中深度学习模型的Robustness，使其不受特定领域属性的影响。</li>
<li>methods: 采用数据增强和一致规范来使模型更不敏感于特定领域属性。</li>
<li>results: 对五种不同的cross-domain任务进行了全面的实验，得到了明显的优势。<details>
<summary>Abstract</summary>
Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same representation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regularization (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The comprehensive experiments show that our method achieves clear advantages on five different cross-domain tasks.
</details>
<details>
<summary>摘要</summary>
深度学习模型在跨频道挑战中失败，因为模型过敏于频道特有的特征，如闪电、背景、摄像头角度等。为解决这问题，数据增强和一致化 regularization 是常用的方法，以使模型对频道特有的特征更不敏感。一致性 regularization 要求模型对两个视图的同一张图像输出相同的表示或预测结果。然而，这些约束 Either too strict or not order-preserving for the classification probabilities。在这工作中，我们提出了Order-preserving Consistency Regularization (OCR) 方法，该方法的顺序性质使模型对任务不相关的变换具有鲁棒性。因此，模型对频道特有的特征变得更不敏感。我们的方法在五个不同的跨频道任务中实现了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="RTrack-Accelerating-Convergence-for-Visual-Object-Tracking-via-Pseudo-Boxes-Exploration"><a href="#RTrack-Accelerating-Convergence-for-Visual-Object-Tracking-via-Pseudo-Boxes-Exploration" class="headerlink" title="RTrack: Accelerating Convergence for Visual Object Tracking via Pseudo-Boxes Exploration"></a>RTrack: Accelerating Convergence for Visual Object Tracking via Pseudo-Boxes Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13257">http://arxiv.org/abs/2309.13257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guotian Zeng, Bi Zeng, Hong Zhang, Jianqi Liu, Qingmao Wei</li>
<li>for: 提高单目标跟踪（SOT）的性能，减少训练时间并靠近对象检测（OD）任务</li>
<li>methods: 使用一组样本点来获取pseudo bounding box，自动调整这些点来定义空间范围和强调本地区域</li>
<li>results: 在GOT-10k数据集上实现了与状态革新（SOTA）跟踪器相同的性能，减少训练时间到前一代跟踪器的10%，将SOT更近于OD任务，并且在各种情况下展现了更快的转化速度。<details>
<summary>Abstract</summary>
Single object tracking (SOT) heavily relies on the representation of the target object as a bounding box. However, due to the potential deformation and rotation experienced by the tracked targets, the genuine bounding box fails to capture the appearance information explicitly and introduces cluttered background. This paper proposes RTrack, a novel object representation baseline tracker that utilizes a set of sample points to get a pseudo bounding box. RTrack automatically arranges these points to define the spatial extents and highlight local areas. Building upon the baseline, we conducted an in-depth exploration of the training potential and introduced a one-to-many leading assignment strategy. It is worth noting that our approach achieves competitive performance to the state-of-the-art trackers on the GOT-10k dataset while reducing training time to just 10% of the previous state-of-the-art (SOTA) trackers' training costs. The substantial reduction in training costs brings single-object tracking (SOT) closer to the object detection (OD) task. Extensive experiments demonstrate that our proposed RTrack achieves SOTA results with faster convergence.
</details>
<details>
<summary>摘要</summary>
单一目标追踪（SOT）仅靠目标物体的包围盒来表示，但由于追踪目标的潜在偏移和旋转，真正的包围盒将显示出目标物体的外观信息，却会受到背景噪声的影响。本文提出了一个新的物体表现基准追踪器（RTrack），利用一组Sample Points来取得伪包围盒。RTrack可自动安排这些点来定义空间扩展和突出地方。基于这个基准，我们进行了深入的训练潜力探索和引入了一个一对多领导分配策略。值得注意的是，我们的方法在GOT-10k dataset上与现有的State-of-the-art（SOTA）追踪器相比，具有竞争性的性能，同时降低训练时间至前一个SOTA追踪器的10%。这个重要的减少训练时间将单一目标追踪（SOT）与物体检测（OD）任务逐渐接近。广泛的实验显示了我们提出的RTrack具有SOTA结果，并且更快地趋向稳定。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Amodal-Video-Segmentation-from-Learning-Supervised-Signals-with-Object-centric-Representation"><a href="#Rethinking-Amodal-Video-Segmentation-from-Learning-Supervised-Signals-with-Object-centric-Representation" class="headerlink" title="Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation"></a>Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13248">http://arxiv.org/abs/2309.13248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kfan21/eoras">https://github.com/kfan21/eoras</a></li>
<li>paper_authors: Ke Fan, Jingshi Lei, Xuelin Qian, Miaopeng Yu, Tianjun Xiao, Tong He, Zheng Zhang, Yanwei Fu</li>
<li>for: 这个论文的目的是提出一种高效的物体抽象分割方法，用于视频模态分割 tasks。</li>
<li>methods: 该方法利用了自主学习的方式，并使用了对象центric表示，以便在实际场景中使用对象特征来优化特征质量。具体来说，该方法包括一个翻译模块，用于将图像特征 proyect 到鸟瞰视图（BEV）中，以获得3D信息；以及一个多视图协同层，用于在不同视图之间进行对话 Mechanism，以完善对象表示。</li>
<li>results: 实验结果表明，该方法可以在实际场景中实现高效的物体抽象分割，并且在多个synthetic和实际 benchmark中达到了领先的性能。<details>
<summary>Abstract</summary>
Video amodal segmentation is a particularly challenging task in computer vision, which requires to deduce the full shape of an object from the visible parts of it. Recently, some studies have achieved promising performance by using motion flow to integrate information across frames under a self-supervised setting. However, motion flow has a clear limitation by the two factors of moving cameras and object deformation. This paper presents a rethinking to previous works. We particularly leverage the supervised signals with object-centric representation in \textit{real-world scenarios}. The underlying idea is the supervision signal of the specific object and the features from different views can mutually benefit the deduction of the full mask in any specific frame. We thus propose an Efficient object-centric Representation amodal Segmentation (EoRaS). Specially, beyond solely relying on supervision signals, we design a translation module to project image features into the Bird's-Eye View (BEV), which introduces 3D information to improve current feature quality. Furthermore, we propose a multi-view fusion layer based temporal module which is equipped with a set of object slots and interacts with features from different views by attention mechanism to fulfill sufficient object representation completion. As a result, the full mask of the object can be decoded from image features updated by object slots. Extensive experiments on both real-world and synthetic benchmarks demonstrate the superiority of our proposed method, achieving state-of-the-art performance. Our code will be released at \url{https://github.com/kfan21/EoRaS}.
</details>
<details>
<summary>摘要</summary>
视频无模板分割是计算机视觉中特别具有挑战性的任务，需要从可见部分中推断物体的全部形状。最近几年，一些研究已经取得了一定的成果，通过在无监督的设置下使用运动流来集成帧中的信息。然而，运动流受到两个因素的限制：摄像机的移动和物体的变形。本文提出了对前一些研究的重新思考。我们特别利用实际场景中的监督信号和不同视图中的特征进行协同协调，以解决任意帧中的全面 маска推断。我们因此提出了一种高效的物体中心表示协调分割（EoRaS）方法。具体来说，我们不仅仅依靠监督信号，还设计了一种将图像特征投影到鸟瞰视（BEV）中的翻译模块，以此增加图像特征的3D信息。此外，我们提出了基于多视图的协同协调层，该层配备了一组物体槽，通过注意机制与不同视图中的特征进行互动，以便填充物体的完整表示。因此，从图像特征更新后的物体槽中可以解码出物体的全面 маска。广泛的实验表明，我们提出的方法在实际和Syntheticbenchmark上具有最高性能，达到了状态盘的表现。我们的代码将在\url{https://github.com/kfan21/EoRaS}上发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Domain-Adaptation-for-REG-via-Relation-Transfer"><a href="#Multi-modal-Domain-Adaptation-for-REG-via-Relation-Transfer" class="headerlink" title="Multi-modal Domain Adaptation for REG via Relation Transfer"></a>Multi-modal Domain Adaptation for REG via Relation Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13247">http://arxiv.org/abs/2309.13247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Ding, Liqiang Wang, Boqing Gong</li>
<li>for: 本文旨在提出一种 novel 的多模式知识转移方法，用于解决 Referring Expression Grounding (REG) 问题。</li>
<li>methods: 我们提出的方法利用特定的关系修饰，同时增强多模式间关系和多模式与另一个模式之间的转移关系，以提高多模式领域的转移性能。</li>
<li>results: 我们的方法在实验中显著提高了多模式领域的转移性能，并且在 REG 问题中显著提高了地区localization的准确率。<details>
<summary>Abstract</summary>
Domain adaptation, which aims to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.
</details>
<details>
<summary>摘要</summary>
域适应，targeting to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.Here's the translation in Traditional Chinese as well:域适应，targeting to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.I hope this helps!
</details></li>
</ul>
<hr>
<h2 id="RBFormer-Improve-Adversarial-Robustness-of-Transformer-by-Robust-Bias"><a href="#RBFormer-Improve-Adversarial-Robustness-of-Transformer-by-Robust-Bias" class="headerlink" title="RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias"></a>RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13245">http://arxiv.org/abs/2309.13245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Cheng, Jinhao Duan, Hui Li, Lyutianyang Zhang, Jiahang Cao, Ping Wang, Jize Zhang, Kaidi Xu, Renjing Xu</li>
<li>for: 本研究旨在 investigate Transformer-based structure 的内在Robustness性能，而不是 introduce novel defense measures against adversarial attacks.</li>
<li>methods: 我们使用 rational structure design approach 来 mitigate the susceptibility to robustness issues, 具体来说是增加高频结构强度的偏好。</li>
<li>results: 我们的实验结果显示， compared to several existing baseline structures, RBFormer 表现出了 robust superiority, 在 CIFAR-10 和 ImageNet-1k 上的评价标准上减少了 +16.12% 和 +5.04%。<details>
<summary>Abstract</summary>
Recently, there has been a surge of interest and attention in Transformer-based structures, such as Vision Transformer (ViT) and Vision Multilayer Perceptron (VMLP). Compared with the previous convolution-based structures, the Transformer-based structure under investigation showcases a comparable or superior performance under its distinctive attention-based input token mixer strategy. Introducing adversarial examples as a robustness consideration has had a profound and detrimental impact on the performance of well-established convolution-based structures. This inherent vulnerability to adversarial attacks has also been demonstrated in Transformer-based structures. In this paper, our emphasis lies on investigating the intrinsic robustness of the structure rather than introducing novel defense measures against adversarial attacks. To address the susceptibility to robustness issues, we employ a rational structure design approach to mitigate such vulnerabilities. Specifically, we enhance the adversarial robustness of the structure by increasing the proportion of high-frequency structural robust biases. As a result, we introduce a novel structure called Robust Bias Transformer-based Structure (RBFormer) that shows robust superiority compared to several existing baseline structures. Through a series of extensive experiments, RBFormer outperforms the original structures by a significant margin, achieving an impressive improvement of +16.12% and +5.04% across different evaluation criteria on CIFAR-10 and ImageNet-1k, respectively.
</details>
<details>
<summary>摘要</summary>
近期，有一股关注和关注力在Transformer结构方面，如视觉转换器（ViT）和视觉多层感知器（VMLP）。与过去的卷积结构相比，Transformer结构在其特有的注意力基于输入token混合策略下显示了相当或更高的性能。在引入对抗示例作为Robustness考虑的情况下，已经证明了传统的卷积结构的内置敏感性。在这篇论文中，我们的注意点是研究Transformer结构的内置Robustness，而不是引入新的防御措施 против对抗攻击。为了解决敏感性问题，我们采用了合理的结构设计方法，增加高频结构Robust遗产偏好。因此，我们提出了一种新的结构，即Robust Bias Transformer-based Structure（RBFormer），它在不同评价标准下与多个基准结构进行比较，具有显著的超越性。通过一系列广泛的实验，RBFormer在CIFAR-10和ImageNet-1k上的表现都出色，与原始结构之间的提升为+16.12%和+5.04%。
</details></li>
</ul>
<hr>
<h2 id="NeRF-Enhanced-Outpainting-for-Faithful-Field-of-View-Extrapolation"><a href="#NeRF-Enhanced-Outpainting-for-Faithful-Field-of-View-Extrapolation" class="headerlink" title="NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation"></a>NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13240">http://arxiv.org/abs/2309.13240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Yu, Jiachen Liu, Zihan Zhou, Sharon X. Huang</li>
<li>for: 增强环境感知，如 робоット导航和远程视觉协助等应用场景中，扩大摄像头的视野范围有利于提高环境感知。</li>
<li>methods: 使用NeRF生成扩展视野图像，并使用这些图像培育场景特定的图像填充模型。</li>
<li>results: 对三个 fotorealistic 数据集和一个实际世界数据集进行了广泛的测试，并显示了方法的稳定性和潜力。<details>
<summary>Abstract</summary>
In various applications, such as robotic navigation and remote visual assistance, expanding the field of view (FOV) of the camera proves beneficial for enhancing environmental perception. Unlike image outpainting techniques aimed solely at generating aesthetically pleasing visuals, these applications demand an extended view that faithfully represents the scene. To achieve this, we formulate a new problem of faithful FOV extrapolation that utilizes a set of pre-captured images as prior knowledge of the scene. To address this problem, we present a simple yet effective solution called NeRF-Enhanced Outpainting (NEO) that uses extended-FOV images generated through NeRF to train a scene-specific image outpainting model. To assess the performance of NEO, we conduct comprehensive evaluations on three photorealistic datasets and one real-world dataset. Extensive experiments on the benchmark datasets showcase the robustness and potential of our method in addressing this challenge. We believe our work lays a strong foundation for future exploration within the research community.
</details>
<details>
<summary>摘要</summary>
在各种应用中，如 робоット导航和远程视觉协助，扩展相机的视场（FOV）有利于提高环境识别。不同于基于图像涂抹技术的艺术化视觉，这些应用需要一个扩展的视野，准确反映场景。为实现这一点，我们提出了一个新的 faithful FOV 拓展问题，利用场景中预 capture 的图像作为知识来培养场景特定的图像涂抹模型。为解决这个问题，我们提出了一种简单 yet effective 的解决方案called NeRF-Enhanced Outpainting（NEO），使用通过NeRF生成的扩展 FOV 图像来训练场景特定的图像涂抹模型。为评估 NEO 的性能，我们进行了三个实验室数据集和一个真实世界数据集的全面评估。广泛的实验表明我们的方法在解决这个挑战中具有强大的基础和潜力。我们认为我们的研究为未来研究社区提供了一个坚强的基础。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Knowledge-Embedded-Transformer-for-Video-Scene-Graph-Generation"><a href="#Spatial-Temporal-Knowledge-Embedded-Transformer-for-Video-Scene-Graph-Generation" class="headerlink" title="Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation"></a>Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13237">http://arxiv.org/abs/2309.13237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hcplab-sysu/stket">https://github.com/hcplab-sysu/stket</a></li>
<li>paper_authors: Tao Pu, Tianshui Chen, Hefeng Wu, Yongyi Lu, Liang Lin</li>
<li>for:  VidSGG aims to identify objects in visual scenes and infer their relationships for a given video.</li>
<li>methods:  The proposed method, STKET, incorporates prior spatial-temporal knowledge into the multi-head cross-attention mechanism to learn more representative relationship representations.</li>
<li>results:  STKET outperforms current competing algorithms by a large margin, with improvements of 8.1%, 4.7%, and 2.1% on different settings.<details>
<summary>Abstract</summary>
Video scene graph generation (VidSGG) aims to identify objects in visual scenes and infer their relationships for a given video. It requires not only a comprehensive understanding of each object scattered on the whole scene but also a deep dive into their temporal motions and interactions. Inherently, object pairs and their relationships enjoy spatial co-occurrence correlations within each image and temporal consistency/transition correlations across different images, which can serve as prior knowledge to facilitate VidSGG model learning and inference. In this work, we propose a spatial-temporal knowledge-embedded transformer (STKET) that incorporates the prior spatial-temporal knowledge into the multi-head cross-attention mechanism to learn more representative relationship representations. Specifically, we first learn spatial co-occurrence and temporal transition correlations in a statistical manner. Then, we design spatial and temporal knowledge-embedded layers that introduce the multi-head cross-attention mechanism to fully explore the interaction between visual representation and the knowledge to generate spatial- and temporal-embedded representations, respectively. Finally, we aggregate these representations for each subject-object pair to predict the final semantic labels and their relationships. Extensive experiments show that STKET outperforms current competing algorithms by a large margin, e.g., improving the mR@50 by 8.1%, 4.7%, and 2.1% on different settings over current algorithms.
</details>
<details>
<summary>摘要</summary>
视频场景图生成（VidSGG）目标是从视频中标识对象并推断它们之间的关系。这需要不仅对整个场景中每个对象进行全面的理解，还需要深入研究它们的时间变化和互动。自然地，对象对的关系具有在每个图像中的空间相互关联和在不同图像之间的时间相关性，这些知识可以用来促进VidSGG模型的学习和推断。在这种工作中，我们提出了一种具有空间-时间知识嵌入的变换器（STKET），它将在多头交叉关注机制中嵌入先前学习的空间-时间知识，以学习更加表示关系的表示。具体来说，我们首先在统计方面学习空间共occurrence和时间转换关系。然后，我们设计了空间和时间知识嵌入层，以全面地探索视觉表示和知识之间的交互，生成空间-时间嵌入表示。最后，我们对每个主体-对象对进行综合这些表示，以预测最终的semantic标签和其关系。广泛的实验显示，STKET在不同设置下比现有竞争算法大幅提高了性能，例如在不同设置下提高mR@50的表现，比如提高8.1%, 4.7%和2.1%。
</details></li>
</ul>
<hr>
<h2 id="M-3-CS-Multi-Target-Masked-Point-Modeling-with-Learnable-Codebook-and-Siamese-Decoders"><a href="#M-3-CS-Multi-Target-Masked-Point-Modeling-with-Learnable-Codebook-and-Siamese-Decoders" class="headerlink" title="M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders"></a>M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13235">http://arxiv.org/abs/2309.13235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qibo Qiu, Honghui Yang, Wenxiao Wang, Shun Zhang, Haiming Gao, Haochao Ying, Wei Hua, Xiaofei He</li>
<li>for: 本研究旨在提高点云自助预训练的表现，使模型具备低级和高级表示能力，捕捉点云的几何细节和 semantic上下文。</li>
<li>methods: 该方法使用 masked point cloud 作为输入，并引入两个解码器同时预测masked表示和原始点 cloud。在解码过程中，我们提出了 siamese decoder 技术，以保持学习参数的数量不变。此外，我们还提出了在线 codebook 技术，将连续的 tokens 映射到精确的 discrete tokens。</li>
<li>results: 实验结果显示，M$^3$CS 在类别和分割任务中表现出色，与现有方法进行比较，具有更高的表现。<details>
<summary>Abstract</summary>
Masked point modeling has become a promising scheme of self-supervised pre-training for point clouds. Existing methods reconstruct either the original points or related features as the objective of pre-training. However, considering the diversity of downstream tasks, it is necessary for the model to have both low- and high-level representation modeling capabilities to capture geometric details and semantic contexts during pre-training. To this end, M$^3$CS is proposed to enable the model with the above abilities. Specifically, with masked point cloud as input, M$^3$CS introduces two decoders to predict masked representations and the original points simultaneously. While an extra decoder doubles parameters for the decoding process and may lead to overfitting, we propose siamese decoders to keep the amount of learnable parameters unchanged. Further, we propose an online codebook projecting continuous tokens into discrete ones before reconstructing masked points. In such way, we can enforce the decoder to take effect through the combinations of tokens rather than remembering each token. Comprehensive experiments show that M$^3$CS achieves superior performance at both classification and segmentation tasks, outperforming existing methods.
</details>
<details>
<summary>摘要</summary>
受隐藏点模型的推广使得自我超视了点云的预训练 scheme 成为了可靠的方法。现有的方法都是在预训练中重建原始点或相关的特征作为目标。然而，考虑到下游任务的多样性，需要模型具备低层和高层表示模型化能力，以 Capture point clouds的几何细节和 semantics during pre-training。为此，我们提出了M$^3$CS。具体来说，输入隐藏点云后，M$^3$CS引入了两个解码器同时预测隐藏表示和原始点。虽然增加了一个解码器会增加参数的数量，可能导致过拟合，但我们提出了同源的解码器，以保持参数的数量不变。此外，我们还提出了在线代码库，将连续的 токен proyect 为离散的 токен。这样可以让解码器通过Token的组合来实现效果，而不是记忆每个Token。我们的实验表明，M$^3$CS在类别和分割任务中表现出色，超过了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Real3D-AD-A-Dataset-of-Point-Cloud-Anomaly-Detection"><a href="#Real3D-AD-A-Dataset-of-Point-Cloud-Anomaly-Detection" class="headerlink" title="Real3D-AD: A Dataset of Point Cloud Anomaly Detection"></a>Real3D-AD: A Dataset of Point Cloud Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13226">http://arxiv.org/abs/2309.13226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m-3lab/real3d-ad">https://github.com/m-3lab/real3d-ad</a></li>
<li>paper_authors: Jiaqi Liu, Guoyang Xie, Ruitao Chen, Xinpeng Li, Jinbao Wang, Yong Liu, Chengjie Wang, Feng Zheng</li>
<li>for: 高精度点云异常检测是精密制造和机器制造领域中的标准，用于检测机器制造过程中的缺陷。</li>
<li>methods: 我们提出了一种基于准备的3D异常检测方法，named Reg3D-AD，该方法包括一种新的特征记忆银行，可以保持本地和全局表示。</li>
<li>results: 我们在Real3D-AD dataset上进行了广泛的实验，并证明了Reg3D-AD的效果。Real3D-AD dataset是目前最大的高精度3D工业异常检测dataset，它包括1,254个高分辨率3D项，每个item有40,000到百万个点。<details>
<summary>Abstract</summary>
High-precision point cloud anomaly detection is the gold standard for identifying the defects of advancing machining and precision manufacturing. Despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items from forty thousand to millions of points for each item, Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), 360 degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To address this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our website:https://github.com/M-3LAB/Real3D-AD.
</details>
<details>
<summary>摘要</summary>
高精度点云异常检测是现代加工和精密制造中的标准。 despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items from forty thousand to millions of points for each item, Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), 360 degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To address this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our website:https://github.com/M-3LAB/Real3D-AD.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese scripts used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.CV_2023_09_23/" data-id="clpxp6c1p00kcee88f4kh1yia" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.AI_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T12:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.AI_2023_09_23/">cs.AI - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Student-Performance-Prediction-on-Learnersourced-Questions-with-SGNN-LLM-Synergy"><a href="#Enhancing-Student-Performance-Prediction-on-Learnersourced-Questions-with-SGNN-LLM-Synergy" class="headerlink" title="Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy"></a>Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13500">http://arxiv.org/abs/2309.13500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Ni, Sijie Wang, Zeyu Zhang, Xiaoxuan Li, Xianda Zheng, Paul Denny, Jiamou Liu</li>
<li>for: 这篇论文旨在提出一种新的学习战略——learnersourcing，并且解决学生发表问题时因为内在的噪声而难以预测学生表现的问题。</li>
<li>methods: 本文使用了签名双方 Graph Neural Networks (SGNNs) 和 Large Language Model (LLM) 的整合策略，实现了学生答案的全面模型化，并且使用了对照学习框架，增强了噪声抗性。</li>
<li>results: 本文针对五个真实世界的数据集，进行验证，结果显示了本方法的优越性，包括提高预测精度和类型抗性。<details>
<summary>Abstract</summary>
As an emerging education strategy, learnersourcing offers the potential for personalized learning content creation, but also grapples with the challenge of predicting student performance due to inherent noise in student-generated data. While graph-based methods excel in capturing dense learner-question interactions, they falter in cold start scenarios, characterized by limited interactions, as seen when questions lack substantial learner responses. In response, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially advantageous in addressing cold start scenarios characterized by limited graph data interactions. Validation across five real-world datasets sourced from the PeerWise platform underscores our approach's effectiveness. Our method outperforms baselines, showcasing enhanced predictive accuracy and robustness.
</details>
<details>
<summary>摘要</summary>
如一种出现的教育战略，学习者来源（learnersourcing）具有个性化学习内容创建的潜力，但同时也面临学生表现预测的挑战，因为学生自然生成的数据中含有噪声。Graph基的方法在学生-问题互动密集的情况下表现出色，但在冷启动场景下， caracterized by limited interactions, graph data interactions are limited. In response, we propose an innovative strategy that combines Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology uses a signed bipartite graph to comprehensively model student answers, and a contrastive learning framework that enhances noise resilience. Additionally, LLM's contribution lies in generating foundational question embeddings, which is especially advantageous in addressing cold start scenarios with limited graph data interactions. Our approach is validated across five real-world datasets sourced from the PeerWise platform, and outperforms baselines, demonstrating enhanced predictive accuracy and robustness.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Prediction-and-Analysis-of-UK-Road-Traffic-Accident-Severity-Using-AI-Integration-of-Machine-Learning-Econometric-Techniques-and-Time-Series-Forecasting-in-Public-Health-Research"><a href="#Enhancing-Prediction-and-Analysis-of-UK-Road-Traffic-Accident-Severity-Using-AI-Integration-of-Machine-Learning-Econometric-Techniques-and-Time-Series-Forecasting-in-Public-Health-Research" class="headerlink" title="Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research"></a>Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13483">http://arxiv.org/abs/2309.13483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Abu Sufian, Jayasree Varadarajan</li>
<li>for: 本研究旨在 investigate 英国道路交通事故严重程度，使用机器学习、 econometric 和统计方法处理历史数据。</li>
<li>methods: 我们使用了各种技术，包括相关分析、回归模型、GMM 处理错误项、时间序列预测VAR 和 ARIMA 模型。</li>
<li>results: 我们的方法比预测方法出perform better，MASE 0.800 和 ME -73.80。我们还建立了一个Random Forest 分类器，具有 73% 精度、78% 回归率和 73% F1-score。使用 H2O AutoML 优化后，我们获得了 XGBoost 模型，RMSE 0.176 和 MAE 0.087。因素分析确定了关键变量，并使用 SHAP 为 Explainable AI， highlighting 关键因素如 Driver_Home_Area_Type 和 Road_Type。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
This research investigates road traffic accident severity in the UK, using a combination of machine learning, econometric, and statistical methods on historical data. We employed various techniques, including correlation analysis, regression models, GMM for error term issues, and time-series forecasting with VAR and ARIMA models. Our approach outperforms naive forecasting with an MASE of 0.800 and ME of -73.80. We also built a random forest classifier with 73% precision, 78% recall, and a 73% F1-score. Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for Explainable AI, highlighting influential factors like Driver_Home_Area_Type and Road_Type. Our study enhances understanding of accident severity and offers insights for evidence-based road safety policies.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "machine learning" Machine Learning* "econometric"  econometric* "statistical"  statistical* "historical data" 历史数据* "correlation analysis" 相关分析* "regression models" 回归模型* "GMM" Generalized Method of Moments (GMM)* "error term issues" 错误项问题* "time-series forecasting" 时间序列预测* "VAR" VAR (Vector Autoregression)* "ARIMA"  ARIMA (AutoRegressive Integrated Moving Average)* "naive forecasting" 简单预测* "MASE"  Mean Absolute Scaled Error (MASE)* "ME"  Mean Error (ME)* "random forest classifier" 随机森林分类器* "H2O AutoML"  H2O AutoML (Automated Machine Learning)* "XGBoost"  XGBoost (eXtreme Gradient Boosting)* "Factor Analysis" 因素分析* "SHAP"  SHAP (SHapley Additive exPlanations)* "Explainable AI" 可解释AI
</details></li>
</ul>
<hr>
<h2 id="Personalised-and-Adjustable-Interval-Type-2-Fuzzy-Based-PPG-Quality-Assessment-for-the-Edge"><a href="#Personalised-and-Adjustable-Interval-Type-2-Fuzzy-Based-PPG-Quality-Assessment-for-the-Edge" class="headerlink" title="Personalised and Adjustable Interval Type-2 Fuzzy-Based PPG Quality Assessment for the Edge"></a>Personalised and Adjustable Interval Type-2 Fuzzy-Based PPG Quality Assessment for the Edge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13464">http://arxiv.org/abs/2309.13464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jose A. Miranda, Celia López-Ongil, Javier Andreu-Perez</li>
<li>for: 这篇论文主要是为了提出一种基于Interval Type-2 Fuzzy Logic System (IT2FLS)的个性化和可调PPG信号质量评估方法，以提高PPG信号处理的准确性和可靠性。</li>
<li>methods: 该方法使用了个性化的IT2FLS参数来适应每个个体PPG信号的特点，同时提供可调的个性化水平，让医疗提供者可以根据不同应用场景进行调整。</li>
<li>results: 实验结果显示，提出的方法可以达到93.72%的准确率，表明该方法可以实现高效、实时的PPG信号质量评估，并提高PPG信号处理系统的准确性和可靠性。<details>
<summary>Abstract</summary>
Most of today's wearable technology provides seamless cardiac activity monitoring. Specifically, the vast majority employ Photoplethysmography (PPG) sensors to acquire blood volume pulse information, which is further analysed to extract useful and physiologically related features. Nevertheless, PPG-based signal reliability presents different challenges that strongly affect such data processing. This is mainly related to the fact of PPG morphological wave distortion due to motion artefacts, which can lead to erroneous interpretation of the extracted cardiac-related features. On this basis, in this paper, we propose a novel personalised and adjustable Interval Type-2 Fuzzy Logic System (IT2FLS) for assessing the quality of PPG signals. The proposed system employs a personalised approach to adapt the IT2FLS parameters to the unique characteristics of each individual's PPG signals.Additionally, the system provides adjustable levels of personalisation, allowing healthcare providers to adjust the system to meet specific requirements for different applications. The proposed system obtained up to 93.72\% for average accuracy during validation. The presented system has the potential to enable ultra-low complexity and real-time PPG quality assessment, improving the accuracy and reliability of PPG-based health monitoring systems at the edge.
</details>
<details>
<summary>摘要</summary>
Therefore, in this paper, we propose a novel personalized and adjustable Interval Type-2 Fuzzy Logic System (IT2FLS) for assessing the quality of PPG signals. The proposed system employs a personalized approach to adapt the IT2FLS parameters to the unique characteristics of each individual's PPG signals. Additionally, the system provides adjustable levels of personalization, allowing healthcare providers to adjust the system to meet specific requirements for different applications.The proposed system obtained up to 93.72% for average accuracy during validation. The presented system has the potential to enable ultra-low complexity and real-time PPG quality assessment, improving the accuracy and reliability of PPG-based health monitoring systems at the edge.
</details></li>
</ul>
<hr>
<h2 id="A-Model-Agnostic-Graph-Neural-Network-for-Integrating-Local-and-Global-Information"><a href="#A-Model-Agnostic-Graph-Neural-Network-for-Integrating-Local-and-Global-Information" class="headerlink" title="A Model-Agnostic Graph Neural Network for Integrating Local and Global Information"></a>A Model-Agnostic Graph Neural Network for Integrating Local and Global Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13459">http://arxiv.org/abs/2309.13459</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhuo Zhou, Annie Qu, Keiland W. Cooper, Norbert Fortin, Babak Shahbaba</li>
<li>for: 提高图像任务的解释性和可解释性，以及提高图像任务的表现。</li>
<li>methods: 提出了一种新的模型独立图像神经网络（MaGNet）框架，可以逐渐融合不同阶次的信息，提取高阶几何结构中的知识，并提供可解释的结果。</li>
<li>results: 在 simulate 数据上进行了广泛的数值研究，并在一个真实世界的案例中对 brain activity 数据进行了应用，以确认 MaGNet 的效果。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its power to represent layer-wise neighborhood mixing. We conduct comprehensive numerical studies using simulated data to demonstrate the superior performance of MaGNet in comparison to several state-of-the-art alternatives. Furthermore, we apply MaGNet to a real-world case study aimed at extracting task-critical information from brain activity data, thereby highlighting its effectiveness in advancing scientific research.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 已经在各种图像任务中表现出色。 despite their success, existing GNNs 受到两个重要的限制：一是不能解释结果的黑盒特性，二是无法学习不同级别的表示。 为了解决这些问题，我们提出了一种新的Model-agnostic Graph Neural Network（MaGNet）框架，可以逐渐 интегриate不同级别的信息，提取高阶邻居的知识，并提供可靠和可解释的结果，通过标识重要的紧凑图结构。 具体来说，MaGNet 由两个组成部分：一个用于复杂关系的隐藏表示估计模型，和一个用于标识重要节点、边和节点特征的解释模型。 我们通过对Empirical Rademacher complexity的总化误差 bound来证明MaGNet 的总化误差 bound，并表明其可以具有层次混合的 neigh权。 我们在使用 simulated data 进行了广泛的数值研究，并证明 MaGNet 在与多种状态前的替代方案相比之下表现出优异性。 此外，我们使用 MaGNet 对 brain activity data 进行了实际应用，以验证其在科研中的效果。
</details></li>
</ul>
<hr>
<h2 id="EMGTFNet-Fuzzy-Vision-Transformer-to-decode-Upperlimb-sEMG-signals-for-Hand-Gestures-Recognition"><a href="#EMGTFNet-Fuzzy-Vision-Transformer-to-decode-Upperlimb-sEMG-signals-for-Hand-Gestures-Recognition" class="headerlink" title="EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for Hand Gestures Recognition"></a>EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for Hand Gestures Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03754">http://arxiv.org/abs/2310.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Cherre Córdova, Christian Flores, Javier Andreu-Perez</li>
<li>for: 这个论文是为了研究用于手势识别（HGR）的电Myoelectric控制而写的。</li>
<li>methods: 这篇论文使用机器学习和深度学习方法进行模式识别，并使用视Transformer（ViT）架构和粗糙神经块（FNB）组成EMGTFNet模型来实现手势识别。</li>
<li>results: 该模型可以准确地识别多种手势动作，而无需使用数据扩展技术、传输学习或增加网络参数的数量。实验结果显示，对于NinaPro数据集中的49种手势动作，测试准确率为83.57%和3.5%，使用200 ms窗口大小和56,793个可变参数。这些结果超越了不含FNB的ViT模型，因此证明了包含FNB可以提高其性能。<details>
<summary>Abstract</summary>
Myoelectric control is an area of electromyography of increasing interest nowadays, particularly in applications such as Hand Gesture Recognition (HGR) for bionic prostheses. Today's focus is on pattern recognition using Machine Learning and, more recently, Deep Learning methods. Despite achieving good results on sparse sEMG signals, the latter models typically require large datasets and training times. Furthermore, due to the nature of stochastic sEMG signals, traditional models fail to generalize samples for atypical or noisy values. In this paper, we propose the design of a Vision Transformer (ViT) based architecture with a Fuzzy Neural Block (FNB) called EMGTFNet to perform Hand Gesture Recognition from surface electromyography (sEMG) signals. The proposed EMGTFNet architecture can accurately classify a variety of hand gestures without any need for data augmentation techniques, transfer learning or a significant increase in the number of parameters in the network. The accuracy of the proposed model is tested using the publicly available NinaPro database consisting of 49 different hand gestures. Experiments yield an average test accuracy of 83.57\% \& 3.5\% using a 200 ms window size and only 56,793 trainable parameters. Our results outperform the ViT without FNB, thus demonstrating that including FNB improves its performance. Our proposal framework EMGTFNet reported the significant potential for its practical application for prosthetic control.
</details>
<details>
<summary>摘要</summary>
“我的电动控制是一个增加电omyography的兴趣领域，特别是在应用中有手势识别（HGR）的这些复义肢。今天的重点是使用机器学习和更深入的深度学习方法来进行模式识别。尽管可以取得好的结果，但这些模型通常需要大量的数据和训练时间。此外，由于随机的sEMG信号的性质，传统的模型无法扩展过去的样本，以致无法处理异常或噪音的值。在这篇文章中，我们提出了基于视觉 трансформа器（ViT）架构的EMGTFNet，以进行手势识别从表面电omyography（sEMG）信号。我们的提案的EMGTFNet架构可以将多种手势识别为无需增加资料增强技术、传统学习或网络中的参数数量。我们的实验结果显示，EMGTFNet可以高度精确地分类49种不同的手势，而且不需要增加训练数据或增加网络中的参数数量。我们的结果比ViT无FNB更好，这证明了包含FNB可以提高其表现。我们的建议框架EMGTFNet具有实际应用于复义控制的潜在性。”
</details></li>
</ul>
<hr>
<h2 id="AxOMaP-Designing-FPGA-based-Approximate-Arithmetic-Operators-using-Mathematical-Programming"><a href="#AxOMaP-Designing-FPGA-based-Approximate-Arithmetic-Operators-using-Mathematical-Programming" class="headerlink" title="AxOMaP: Designing FPGA-based Approximate Arithmetic Operators using Mathematical Programming"></a>AxOMaP: Designing FPGA-based Approximate Arithmetic Operators using Mathematical Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13445">http://arxiv.org/abs/2309.13445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siva Satyendra Sahoo, Salim Ullah, Akash Kumar</li>
<li>for: 本研究旨在设计低成本计算机算符 для遥感系统中的机器学习（ML）算法。</li>
<li>methods: 本研究使用了人工智能&#x2F;机器学习（AI&#x2F;ML）基于的方法来设计FPGA基于的伪函数。</li>
<li>results: 相比传统的进化算法基于优化方法，本研究使用了混合整数二次函数 constrained programs来实现更有向性的搜索，并提高了精度和性能。<details>
<summary>Abstract</summary>
With the increasing application of machine learning (ML) algorithms in embedded systems, there is a rising necessity to design low-cost computer arithmetic for these resource-constrained systems. As a result, emerging models of computation, such as approximate and stochastic computing, that leverage the inherent error-resilience of such algorithms are being actively explored for implementing ML inference on resource-constrained systems. Approximate computing (AxC) aims to provide disproportionate gains in the power, performance, and area (PPA) of an application by allowing some level of reduction in its behavioral accuracy (BEHAV). Using approximate operators (AxOs) for computer arithmetic forms one of the more prevalent methods of implementing AxC. AxOs provide the additional scope for finer granularity of optimization, compared to only precision scaling of computer arithmetic. To this end, designing platform-specific and cost-efficient approximate operators forms an important research goal. Recently, multiple works have reported using AI/ML-based approaches for synthesizing novel FPGA-based AxOs. However, most of such works limit usage of AI/ML to designing ML-based surrogate functions used during iterative optimization processes. To this end, we propose a novel data analysis-driven mathematical programming-based approach to synthesizing approximate operators for FPGAs. Specifically, we formulate mixed integer quadratically constrained programs based on the results of correlation analysis of the characterization data and use the solutions to enable a more directed search approach for evolutionary optimization algorithms. Compared to traditional evolutionary algorithms-based optimization, we report up to 21% improvement in the hypervolume, for joint optimization of PPA and BEHAV, in the design of signed 8-bit multipliers.
</details>
<details>
<summary>摘要</summary>
随着机器学习（ML）算法在嵌入式系统中的应用逐渐增加，需要设计低成本的计算机器 arithmetic 来支持这些资源受限的系统。为此，人们正在活跃探讨新的计算模型，如 aproximate 和 Stochastic computing，以利用 ML 算法的内置错误抗性来实现 ML 推理。approximate computing（AxC）目标是提供不均匀的 PPA 提升，而不是仅仅是精度的减少。使用 approximate 操作符（AxOs）来实现计算机器 arithmetic 是其中一种常见的方法。AxOs 提供了更高的优化精度，相比于仅仅是精度的缩放。为此，设计Platform-specific 和 cost-efficient approximate 操作符成为了一项重要的研究目标。最近，多种文献报道了使用 AI/ML 方法来 sinthez FPGA 基于 AxOs。然而，大多数这些工作都是限制使用 AI/ML 来设计 ML 基于 surrogate 函数，用于 iterative 优化过程中。因此，我们提出了一种数据分析驱动的数学编程方法来 sinthez approximate 操作符。 Specifically，我们使用权重分析结果来构建混合整数quadratically constrained 程序，并使用这些解决方案来实现更 direkt 的搜索方法。与传统的进化算法基于优化相比，我们报道了在设计 signed 8-bit 乘数器时，对 PPA 和 BEHAV 的共同优化中的21%提高。
</details></li>
</ul>
<hr>
<h2 id="How-Do-Drivers-Behave-at-Roundabouts-in-a-Mixed-Traffic-A-Case-Study-Using-Machine-Learning"><a href="#How-Do-Drivers-Behave-at-Roundabouts-in-a-Mixed-Traffic-A-Case-Study-Using-Machine-Learning" class="headerlink" title="How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study Using Machine Learning"></a>How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study Using Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13442">http://arxiv.org/abs/2309.13442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farah Abu Hamad, Rama Hasiba, Deema Shahwan, Huthaifa I. Ashqar</li>
<li>for: 这个研究旨在分类车手在环形巷与其他路用者之间的交互行为，以提高路面安全性。</li>
<li>methods: 使用数据驱动的无监督机器学习分类车手行为，使用车辆动力学数据，分为三种驾驶模式（保守、正常、强制）。</li>
<li>results: 研究发现，大多数车手在环形巷上的行为可以分为两种驾驶模式：保守和正常，因为环形巷的交通速度较低。此外，发现当车手与行人或自行车使用者互动时，大约77%的车手被分类为保守驾驶者，对于不参与互动的保守驾驶者而言，只有42%。这些结果显示车手在环形巷与其他路用者互动时可能会发生不寻常的行为，增加了交通碰撞的风险。<details>
<summary>Abstract</summary>
Driving behavior is considered a unique driving habit of each driver and has a significant impact on road safety. Classifying driving behavior and introducing policies based on the results can reduce the severity of crashes on the road. Roundabouts are particularly interesting because of the interconnected interaction between different road users at the area of roundabouts, which different driving behavior is hypothesized. This study investigates driving behavior at roundabouts in a mixed traffic environment using a data-driven unsupervised machine learning to classify driving behavior at three roundabouts in Germany. We used a dataset of vehicle kinematics to a group of different vehicles and vulnerable road users (VRUs) at roundabouts and classified them into three categories (i.e., conservative, normal, and aggressive). Results showed that most of the drivers proceeding through a roundabout can be mostly classified into two driving styles: conservative and normal because traffic speeds in roundabouts are relatively lower than in other signalized and unsignalized intersections. Results also showed that about 77% of drivers who interacted with pedestrians or cyclists were classified as conservative drivers compared to about 42% of conservative drivers that did not interact or about 51% from all drivers. It seems that drivers tend to behave abnormally as they interact with VRUs at roundabouts, which increases the risk of crashes when an intersection is multimodal. Results of this study could be helpful in improving the safety of roads by allowing policymakers to determine the effective and suitable safety countermeasures. Results will also be beneficial for the Advanced Driver Assistance System (ADAS) as the technology is being deployed in a mixed traffic environment.
</details>
<details>
<summary>摘要</summary>
驾驶行为被视为每位驾驶员的特有驾驶习惯，对路面安全有着重要影响。根据不同驾驶行为分类并采取相应政策可以减轻路面上的事故严重程度。圆形交叉口特别有趣，因为不同的驾驶行为在圆形交叉口的交叉点发生了互相关联的互动。本研究使用数据驱动无监督机器学习方法在德国三个圆形交叉口中分类驾驶行为。我们使用了车辆动态数据来分类不同的车辆和护理用路用户（VRU）在圆形交叉口中的驾驶行为，并将其分为三类（即保守、常规和强制）。结果显示，大多数通过圆形交叉口的驾驶员可以分为两种驾驶风格：保守和常规，因为圆形交叉口的交通速度相对较低。结果还显示，与步行者或自行车用户互动的77%的驾驶员被分类为保守驾驶员，与不与步行者或自行车用户互动的42%的保守驾驶员相比。这表明在多模式交叉口中，驾驶员在与VRU互动时有异常的行为，这会增加路面上的风险。本研究的结果可以帮助政策制定者确定有效和适当的安全防范措施。此外，这些结果还将有助于高等技术应用系统（ADAS）在混合交通环境中部署。
</details></li>
</ul>
<hr>
<h2 id="Finding-Order-in-Chaos-A-Novel-Data-Augmentation-Method-for-Time-Series-in-Contrastive-Learning"><a href="#Finding-Order-in-Chaos-A-Novel-Data-Augmentation-Method-for-Time-Series-in-Contrastive-Learning" class="headerlink" title="Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning"></a>Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13439">http://arxiv.org/abs/2309.13439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eth-siplab/Finding_Order_in_Chaos">https://github.com/eth-siplab/Finding_Order_in_Chaos</a></li>
<li>paper_authors: Berken Utku Demirel, Christian Holz</li>
<li>for: 这 paper 的目的是提出一种新的数据增强方法，用于 quasi-periodic 时间序列任务，以连接内类样本并找到隐藏空间中的顺序。</li>
<li>methods: 该方法基于 mixup 技术，并提出了一种新的方法，考虑非站ARY 时间序列的周期性。通过控制数据增强的混杂程度，该方法可以提高下游任务的表达特征和性能。</li>
<li>results: 对于三个时间序列任务（心率估算、人类活动识别和心血管疾病检测），该方法与州前工作相比，表现出了更好的数据生成和知道数据增强技术。<details>
<summary>Abstract</summary>
The success of contrastive learning is well known to be dependent on data augmentation. Although the degree of data augmentations has been well controlled by utilizing pre-defined techniques in some domains like vision, time-series data augmentation is less explored and remains a challenging problem due to the complexity of the data generation mechanism, such as the intricate mechanism involved in the cardiovascular system. Moreover, there is no widely recognized and general time-series augmentation method that can be applied across different tasks. In this paper, we propose a novel data augmentation method for quasi-periodic time-series tasks that aims to connect intra-class samples together, and thereby find order in the latent space. Our method builds upon the well-known mixup technique by incorporating a novel approach that accounts for the periodic nature of non-stationary time-series. Also, by controlling the degree of chaos created by data augmentation, our method leads to improved feature representations and performance on downstream tasks. We evaluate our proposed method on three time-series tasks, including heart rate estimation, human activity recognition, and cardiovascular disease detection. Extensive experiments against state-of-the-art methods show that the proposed approach outperforms prior works on optimal data generation and known data augmentation techniques in the three tasks, reflecting the effectiveness of the presented method. Source code: https://github.com/eth-siplab/Finding_Order_in_Chaos
</details>
<details>
<summary>摘要</summary>
成功的对比学习几乎总是受到数据增强的影响。虽然在某些领域如视觉领域中，数据增强的度已经很好地控制了，但时间序列数据增强仍然是一个挑战，因为时间序列数据生成机制的复杂性，如心血管系统的内部机制。此外，没有一种广泛认可和可适用于不同任务的时间序列数据增强方法。在这篇论文中，我们提出了一种新的时间序列数据增强方法，旨在连接同类样本 вместе，从而在隐藏空间找到顺序。我们的方法基于已知的mixup技术，并添加了一种新的方法，考虑非站ARY时间序列的周期性。此外，我们可控制数据增强中创造的混乱程度，从而获得改进的特征表示和下游任务的性能。我们在三个时间序列任务中进行了广泛的实验，包括心率估计、人员活动识别和冠状疾病检测。对比于现有的最佳数据生成和知道数据增强技术，我们的方法表现出色，反映了提出的方法的效iveness。源代码：https://github.com/eth-siplab/Finding_Order_in_Chaos
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Superpixel-Segmentation-from-Biologically-Inspired-Mechanisms"><a href="#Rethinking-Superpixel-Segmentation-from-Biologically-Inspired-Mechanisms" class="headerlink" title="Rethinking Superpixel Segmentation from Biologically Inspired Mechanisms"></a>Rethinking Superpixel Segmentation from Biologically Inspired Mechanisms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13438">http://arxiv.org/abs/2309.13438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingyu Zhao, Bo Peng, Yuan Sun, Daipeng Yang, Zhenguang Zhang, Xi Wu<br>for: 这个论文主要针对的是提高深度学习基于超像分割方法的效率和性能，但是在生成严格遵循物体边界的超像时，仍然存在一定的挑战。methods: 我们提出了一种基于生物网络架构的超像分割方法，包括增强检查模块（ESM）和新的边界意识标签（BAL）。ESM通过模拟视觉系统中的交互投影机制来增强semantic信息。BAL利用视觉 cortical cells的空间频率特点来促进生成强边界遵循的超像。results: 我们通过对BSDS500 dataset和NYUv2 dataset进行评估，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Recently, advancements in deep learning-based superpixel segmentation methods have brought about improvements in both the efficiency and the performance of segmentation. However, a significant challenge remains in generating superpixels that strictly adhere to object boundaries while conveying rich visual significance, especially when cross-surface color correlations may interfere with objects. Drawing inspiration from neural structure and visual mechanisms, we propose a biological network architecture comprising an Enhanced Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel segmentation. The ESM enhances semantic information by simulating the interactive projection mechanisms of the visual cortex. Additionally, the BAL emulates the spatial frequency characteristics of visual cortical cells to facilitate the generation of superpixels with strong boundary adherence. We demonstrate the effectiveness of our approach through evaluations on both the BSDS500 dataset and the NYUv2 dataset.
</details>
<details>
<summary>摘要</summary>
近些年，深度学习基于超像素分割方法的进步，使得分割效率和性能得到了改善。然而，仍然存在一大挑战，即生成严格遵循物体边界的超像素，同时捕捉富有视觉意义的信息，特别是当颜色相关性障碍物体时。 drawing inspiration from neural structure and visual mechanisms, we propose a biological network architecture consisting of an Enhanced Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel segmentation. The ESM enhances semantic information by simulating the interactive projection mechanisms of the visual cortex. Additionally, the BAL emulates the spatial frequency characteristics of visual cortical cells to facilitate the generation of superpixels with strong boundary adherence. We demonstrate the effectiveness of our approach through evaluations on both the BSDS500 dataset and the NYUv2 dataset.
</details></li>
</ul>
<hr>
<h2 id="SpeakEasy-A-Conversational-Intelligence-Chatbot-for-Enhancing-College-Students’-Communication-Skills"><a href="#SpeakEasy-A-Conversational-Intelligence-Chatbot-for-Enhancing-College-Students’-Communication-Skills" class="headerlink" title="SpeakEasy: A Conversational Intelligence Chatbot for Enhancing College Students’ Communication Skills"></a>SpeakEasy: A Conversational Intelligence Chatbot for Enhancing College Students’ Communication Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.14891">http://arxiv.org/abs/2310.14891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunbae Jeon, Rhea Ramachandran, Victoria Ploerer, Yella Diekmann, Max Bagga<br>for: The paper aims to help college students improve their communication skills through a chatbot that provides feedback on their conversational ability.methods: The chatbot, called SpeakEasy, uses a seven-minute spoken conversation with the user, analyzes the user’s responses with metrics based on previous research, and provides feedback on how to improve conversational ability.results: SpeakEasy evaluates the quality of the conversation using macros and provides elaborate feedback to the user on how to improve their conversations. The chatbot also updates its algorithms based on the user’s responses to questions about its performance.<details>
<summary>Abstract</summary>
Social interactions and conversation skills separate the successful from the rest and the confident from the shy. For college students in particular, the ability to converse can be an outlet for the stress and anxiety experienced on a daily basis along with a foundation for all-important career skills. In light of this, we designed SpeakEasy: a chatbot with some degree of intelligence that provides feedback to the user on their ability to engage in free-form conversations with the chatbot. SpeakEasy attempts to help college students improve their communication skills by engaging in a seven-minute spoken conversation with the user, analyzing the user's responses with metrics designed based on previous psychology and linguistics research, and providing feedback to the user on how they can improve their conversational ability. To simulate natural conversation, SpeakEasy converses with the user on a wide assortment of topics that two people meeting for the first time might discuss: travel, sports, and entertainment. Unlike most other chatbots with the goal of improving conversation skills, SpeakEasy actually records the user speaking, transcribes the audio into tokens, and uses macros-e.g., sequences that calculate the pace of speech, determine if the user has an over-reliance on certain words, and identifies awkward transitions-to evaluate the quality of the conversation. Based on the evaluation, SpeakEasy provides elaborate feedback on how the user can improve their conversations. In turn, SpeakEasy updates its algorithms based on a series of questions that the user responds to regarding SpeakEasy's performance.
</details>
<details>
<summary>摘要</summary>
社交交流和对话技巧对成功和自信心是非常重要的，尤其是 для大学生。在日常生活中受到压力和焦虑的情况下，与其他人交流可以是一种缓解压力的方式，同时也是职业技能的基础。为了帮助大学生提高communication skills，我们开发了SpeakEasy：一个具有一定程度的人工智能的chatbot，可以与用户进行7分钟的自由对话，并提供用户在对话中的表现评价。SpeakEasy使用了基于前期心理学和语言学研究的度量来评估用户的对话能力，并提供了用户如何改进对话技巧的具体反馈。与其他帮助提高对话技巧的chatbot不同，SpeakEasy实际记录用户的语音，将语音转录为符号，并使用抽象来评估对话质量。SpeakEasy使用的抽象包括语速度、用户语言使用情况和对话过渡的awkwardness等。基于这些评估结果，SpeakEasy提供了详细的反馈， помо助用户改进对话技巧。而SpeakEasy的算法则基于用户对SpeakEasy的表现进行评价的问题来进行更新。
</details></li>
</ul>
<hr>
<h2 id="Resolving-References-in-Visually-Grounded-Dialogue-via-Text-Generation"><a href="#Resolving-References-in-Visually-Grounded-Dialogue-via-Text-Generation" class="headerlink" title="Resolving References in Visually-Grounded Dialogue via Text Generation"></a>Resolving References in Visually-Grounded Dialogue via Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13430">http://arxiv.org/abs/2309.13430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/willemsenbram/reference-resolution-via-text-generation">https://github.com/willemsenbram/reference-resolution-via-text-generation</a></li>
<li>paper_authors: Bram Willemsen, Livia Qian, Gabriel Skantze</li>
<li>for: 用于解决基于对话语言的视觉引用解决方案，提高视觉语言模型（VLM）的对话处理能力。</li>
<li>methods: 使用修改的大语言模型（LLM）生成定语描述，捕捉对话语言上的核心相关信息；使用预训练的VLM来基于生成的定语描述进行零基本训练引用识别。</li>
<li>results: 在人工标注的视觉对话数据集上测试，与基eline比较的result exceeds，并发现使用更大的上下文窗口可以获得更高的返回率。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.
</details>
<details>
<summary>摘要</summary>
传感语言模型（VLM）在基于简单文本查询的图像检索方面表现出色，但基于对话输入的文本-图像检索仍然是一个挑战。因此，如果我们想使用VLM进行视觉定位对话，那么这些模型的语言处理能力需要进行增强。为解决这个问题，我们提议通过细化大语言模型（LLM）来生成定语描述，捕捉在语言上下文中的核心相关信息。然后，我们使用预训练的VLM来根据生成的描述来确定参照，无需训练。我们对手动标注的视觉定位对话集进行评估，并超越比较基线的性能。此外，我们发现使用基于更大上下文窗口的定语描述有可能带来更高的返回。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Student-Performance-in-Game-Based-Learning-Environments"><a href="#Modeling-Student-Performance-in-Game-Based-Learning-Environments" class="headerlink" title="Modeling Student Performance in Game-Based Learning Environments"></a>Modeling Student Performance in Game-Based Learning Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13429">http://arxiv.org/abs/2309.13429</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harryjeon24/student_performance">https://github.com/harryjeon24/student_performance</a></li>
<li>paper_authors: Hyunbae Jeon, Harry He, Anthony Wang, Susanna Spooner</li>
<li>for: 这项研究探讨了基于游戏学习的教育游戏”Jo Wilder和首都案例”，关注使用不同机器学习模型预测学生表现，包括K-最近邻居（KNN）、多层感知神经网络（MLP）和随机森林。研究目标是确定预测学生表现和正确问题答案的最有价值特征。</li>
<li>methods: 通过利用游戏数据，我们建立了完整的基准chmarks для这些模型，并探讨了如何应用正确的数据聚合方法。我们压缩了原始训练数据的大小从4.6 GB压缩到48 MB的预处理训练数据，保持了高F1分数和准确率。</li>
<li>results: 我们的发现表明，适当的预处理技术可以在不使用深度学习模型的情况下提高表现。MLP模型在French Touch模型当前状态的比较中表现出色，达到F-1分数0.83和准确率0.74，这表明其适用于这个数据集。未来的研究应该探索使用更大的数据集、其他预处理技术、更先进的深度学习技术和实际应用来为学生根据预测表现提供个性化学习建议。这项研究贡献于游戏学习理解和优化教育游戏经验，以提高学生的成绩和技能发展。<details>
<summary>Abstract</summary>
This study investigates game-based learning in the context of the educational game "Jo Wilder and the Capitol Case," focusing on predicting student performance using various machine learning models, including K-Nearest Neighbors (KNN), Multi-Layer Perceptron (MLP), and Random Forest. The research aims to identify the features most predictive of student performance and correct question answering. By leveraging gameplay data, we establish complete benchmarks for these models and explore the importance of applying proper data aggregation methods. By compressing all numeric data to min/max/mean/sum and categorical data to first, last, count, and nunique, we reduced the size of the original training data from 4.6 GB to 48 MB of preprocessed training data, maintaining high F1 scores and accuracy.   Our findings suggest that proper preprocessing techniques can be vital in enhancing the performance of non-deep-learning-based models. The MLP model outperformed the current state-of-the-art French Touch model, achieving an F-1 score of 0.83 and an accuracy of 0.74, suggesting its suitability for this dataset. Future research should explore using larger datasets, other preprocessing techniques, more advanced deep learning techniques, and real-world applications to provide personalized learning recommendations to students based on their predicted performance. This paper contributes to the understanding of game-based learning and provides insights into optimizing educational game experiences for improved student outcomes and skill development.
</details>
<details>
<summary>摘要</summary>
We preprocessed the original training data by compressing all numeric data to min/max/mean/sum and categorical data to first, last, count, and nunique, reducing the data size from 4.6 GB to 48 MB while maintaining high F1 scores and accuracy. Our findings suggest that proper preprocessing techniques can significantly enhance the performance of non-deep-learning-based models.The MLP model outperformed the current state-of-the-art French Touch model, achieving an F-1 score of 0.83 and an accuracy of 0.74, suggesting its suitability for this dataset. Future research should explore using larger datasets, other preprocessing techniques, more advanced deep learning techniques, and real-world applications to provide personalized learning recommendations to students based on their predicted performance.This study contributes to the understanding of game-based learning and provides insights into optimizing educational game experiences for improved student outcomes and skill development.
</details></li>
</ul>
<hr>
<h2 id="ECGNet-A-generative-adversarial-network-GAN-approach-to-the-synthesis-of-12-lead-ECG-signals-from-single-lead-inputs"><a href="#ECGNet-A-generative-adversarial-network-GAN-approach-to-the-synthesis-of-12-lead-ECG-signals-from-single-lead-inputs" class="headerlink" title="ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs"></a>ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03753">http://arxiv.org/abs/2310.03753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Bagga, Hyunbae Jeon, Alex Issokson</li>
<li>for: 这个论文的目的是生成完整的12导电cardiogram信号，并使用GAN模型来实现这一目标。</li>
<li>methods: 这个论文使用了GAN模型，bidirectional LSTM生成器和CNN抗对模型来生成12导电cardiogram信号。</li>
<li>results: 该模型可以很好地保留信号中的特有特征，例如P-Q段和R峰的特征，并且可以预测多种心血管疾病的发生。<details>
<summary>Abstract</summary>
Electrocardiography (ECG) signal generation has been heavily explored using generative adversarial networks (GAN) because the implementation of 12-lead ECGs is not always feasible. The GAN models have achieved remarkable results in reproducing ECG signals but are only designed for multiple lead inputs and the features the GAN model preserves have not been identified-limiting the generated signals use in cardiovascular disease (CVD)-predictive models. This paper presents ECGNet which is a procedure that generates a complete set of 12-lead ECG signals from any single lead input using a GAN framework with a bidirectional long short-term memory (LSTM) generator and a convolutional neural network (CNN) discriminator. Cross and auto-correlation analysis performed on the generated signals identifies features conserved during the signal generation-i.e., features that can characterize the unique-nature of each signal and thus likely indicators of CVD. Finally, by using ECG signals annotated with the CVD-indicative features detailed by the correlation analysis as inputs for a CVD-onset-predictive CNN model, we overcome challenges preventing the prediction of multiple-CVD targets. Our models are experimented on 15s 12-lead ECG dataset recorded using MyoVista's wavECG. Functional outcome data for each patient is recorded and used in the CVD-predictive model. Our best GAN model achieves state-of-the-art accuracy with Frechet Distance (FD) scores of 4.73, 4.89, 5.18, 4.77, 4.71, and 5.55 on the V1-V6 pre-cordial leads respectively and shows strength in preserving the P-Q segments and R-peaks in the generated signals. To the best of our knowledge, ECGNet is the first to predict all of the remaining eleven leads from the input of any single lead.
</details>
<details>
<summary>摘要</summary>
电rokardiography（ECG）信号生成已经得到了广泛的探索，使用生成对抗网络（GAN），因为实施12导ECG的实施不一定可行。GAN模型已经实现了对ECG信号的很好的重现，但是它们只是多导输入的，而且保留的特征没有得到了识别-这限制了生成的信号在冠军疾病预测中的使用。本文提出了ECGNet，一种可以从单个导入信号中生成完整的12导ECG信号的GAN框架，包括一个双向长短期记忆（LSTM）生成器和一个卷积神经网络（CNN）分类器。在生成的信号中进行了交叉和自相关分析，并识别了保留的特征-即可以Characterize每个信号的独特性，因此可能是冠军疾病的指标。最后，我们使用了标注了CVD指标的ECG信号作为输入，并使用了一个CVD发生预测的CNN模型，解决了由于多个CVD目标的预测而产生的挑战。我们对15秒12导ECG数据集进行了实验，该数据集使用MyoVista的wavECG记录。每个患者的功能结果数据都被记录，并用于CVD发生预测模型。我们的最佳GAN模型在V1-V6前心导电位上获得了state-of-the-art的准确率，FD分数分别为4.73、4.89、5.18、4.77、4.71和5.55，并且表现出了保持P-Q段和R-peak的强大能力。而且，根据我们知道，ECGNet是第一个可以从任何单个导入信号中预测所有的11导ECG信号。
</details></li>
</ul>
<hr>
<h2 id="A-Chat-About-Boring-Problems-Studying-GPT-based-text-normalization"><a href="#A-Chat-About-Boring-Problems-Studying-GPT-based-text-normalization" class="headerlink" title="A Chat About Boring Problems: Studying GPT-based text normalization"></a>A Chat About Boring Problems: Studying GPT-based text normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13426">http://arxiv.org/abs/2309.13426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Zhang, Travis M. Bartley, Mariana Graterol-Fuenmayor, Vitaly Lavrukhin, Evelina Bakhturina, Boris Ginsburg</li>
<li>for: 本研究旨在探讨语言模型是否可以有效地进行文本normalization，并提出了一种新的文本normalizationtask设计方法。</li>
<li>methods: 本研究使用了大型语言模型（LLM），结合自我一致性理解和语言知识引入的提问工程，以实践文本normalization的可行性。</li>
<li>results: 研究发现，使用LLM进行文本normalization可以在几个shotenario下实现错误率大约40%下降，而且通过分析错误原因，发现了传统文本normalization任务的一些限制。<details>
<summary>Abstract</summary>
Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Penalties-and-Rewards-for-Fair-Learning-in-Paired-Kidney-Exchange-Programs"><a href="#Penalties-and-Rewards-for-Fair-Learning-in-Paired-Kidney-Exchange-Programs" class="headerlink" title="Penalties and Rewards for Fair Learning in Paired Kidney Exchange Programs"></a>Penalties and Rewards for Fair Learning in Paired Kidney Exchange Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13421">http://arxiv.org/abs/2309.13421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Margarida Carvalho, Alison Caulfield, Yi Lin, Adrian Vetta</li>
<li>for: 这个论文旨在探讨了一种动态交换和分配机制，以提高生产力探讨机制的性能。</li>
<li>methods: 该论文使用了学习算法，以在动态模拟中学习优化患者-捐献者权重，以提高结果。</li>
<li>results: 研究发现，在加拿大生产力探讨计划中，使用学习算法可以提高平均等待时间、增加移植数量和提高群体公平。具体来说，最高表现的学习算法可以提高群体公平性 by 10%，同时增加移植数量 by 6%和降低等待时间 by 24%。但研究的核心结果却是，在提高生产力探讨计划的性能方面，不是将积极分配给患者-捐献者对的正面权重，而是通过对少量非指定捐献者的负面权重分配来实现。<details>
<summary>Abstract</summary>
A kidney exchange program, also called a kidney paired donation program, can be viewed as a repeated, dynamic trading and allocation mechanism. This suggests that a dynamic algorithm for transplant exchange selection may have superior performance in comparison to the repeated use of a static algorithm. We confirm this hypothesis using a full scale simulation of the Canadian Kidney Paired Donation Program: learning algorithms, that attempt to learn optimal patient-donor weights in advance via dynamic simulations, do lead to improved outcomes. Specifically, our learning algorithms, designed with the objective of fairness (that is, equity in terms of transplant accessibility across cPRA groups), also lead to an increased number of transplants and shorter average waiting times. Indeed, our highest performing learning algorithm improves egalitarian fairness by 10% whilst also increasing the number of transplants by 6% and decreasing waiting times by 24%. However, our main result is much more surprising. We find that the most critical factor in determining the performance of a kidney exchange program is not the judicious assignment of positive weights (rewards) to patient-donor pairs. Rather, the key factor in increasing the number of transplants, decreasing waiting times and improving group fairness is the judicious assignment of a negative weight (penalty) to the small number of non-directed donors in the kidney exchange program.
</details>
<details>
<summary>摘要</summary>
一个肾移植计划，也称为肾对肾移植计划，可以看作是一种循环、动态的交易和分配机制。这表明使用动态算法进行移植交易选择可能会有更高的性能。我们确认这一假设使用加拿大肾对肾移植计划的全规模模拟：学习算法，尝试通过动态模拟来学习患者-捐精对的优质量因子，实际上会导致改进的结果。Specifically, our learning algorithms, designed with the objective of fairness (that is, equity in terms of transplant accessibility across cPRA groups), also lead to an increased number of transplants and shorter average waiting times. Indeed, our highest performing learning algorithm improves egalitarian fairness by 10% whilst also increasing the number of transplants by 6% and decreasing waiting times by 24%. However, our main result is much more surprising. We find that the most critical factor in determining the performance of a kidney exchange program is not the judicious assignment of positive weights (rewards) to patient-donor pairs. Rather, the key factor in increasing the number of transplants, decreasing waiting times and improving group fairness is the judicious assignment of a negative weight (penalty) to the small number of non-directed donors in the kidney exchange program.
</details></li>
</ul>
<hr>
<h2 id="State-space-Models-with-Layer-wise-Nonlinearity-are-Universal-Approximators-with-Exponential-Decaying-Memory"><a href="#State-space-Models-with-Layer-wise-Nonlinearity-are-Universal-Approximators-with-Exponential-Decaying-Memory" class="headerlink" title="State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory"></a>State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13414">http://arxiv.org/abs/2309.13414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shida Wang, Beichen Xue</li>
<li>for: 这篇论文主要研究了使用层状态模型来模型连续序列之间的关系。</li>
<li>methods: 论文使用了层状态模型，并在每层添加非线性活化来提高模型的表达能力。</li>
<li>results: 研究表明，通过层状态模型和非线性活化的组合，可以有效地模型复杂的连续序列模式。但是，研究也表明，状态空间模型无法根本解决指数减少的内存问题。<details>
<summary>Abstract</summary>
State-space models have gained popularity in sequence modelling due to their simple and efficient network structures. However, the absence of nonlinear activation along the temporal direction limits the model's capacity. In this paper, we prove that stacking state-space models with layer-wise nonlinear activation is sufficient to approximate any continuous sequence-to-sequence relationship. Our findings demonstrate that the addition of layer-wise nonlinear activation enhances the model's capacity to learn complex sequence patterns. Meanwhile, it can be seen both theoretically and empirically that the state-space models do not fundamentally resolve the exponential decaying memory issue. Theoretical results are justified by numerical verifications.
</details>
<details>
<summary>摘要</summary>
状态空间模型在序列模型中得到了广泛应用，因为它们的简单和高效的网络结构。然而，在时间方向上缺乏非线性活化限制了模型的容量。在这篇论文中，我们证明了将层weise非线性活化核心到状态空间模型可以近似任何连续序列到序列关系。我们的发现表明，增加层wise非线性活化可以提高模型学习复杂序列模式的能力。同时，可以在理论和实验两个方面见到，状态空间模型并没有根本解决指数减少记忆问题。理论结果得到了数值验证。
</details></li>
</ul>
<hr>
<h2 id="Towards-Attributions-of-Input-Variables-in-a-Coalition"><a href="#Towards-Attributions-of-Input-Variables-in-a-Coalition" class="headerlink" title="Towards Attributions of Input Variables in a Coalition"></a>Towards Attributions of Input Variables in a Coalition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13411">http://arxiv.org/abs/2309.13411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Zheng, Huiqi Deng, Quanshi Zhang</li>
<li>for: 这paper的目的是开发一种新的贡献计算方法，以解释个体变量贡献和其党筹贡献之间的冲突。</li>
<li>methods: 该paper使用了一种全新的视角来推导贡献计算方法，包括将Harsanyi交互编码为AI模型中的交互分配，然后将Shapley值扩展到党筹贡献领域。</li>
<li>results: 该paper发现了冲突的基本机制，即党筹中包含部分变量的交互导致这种冲突。<details>
<summary>Abstract</summary>
This paper aims to develop a new attribution method to explain the conflict between individual variables' attributions and their coalition's attribution from a fully new perspective. First, we find that the Shapley value can be reformulated as the allocation of Harsanyi interactions encoded by the AI model. Second, based the re-alloction of interactions, we extend the Shapley value to the attribution of coalitions. Third we ective. We derive the fundamental mechanism behind the conflict. This conflict come from the interaction containing partial variables in their coalition.
</details>
<details>
<summary>摘要</summary>
这篇论文目的是开发一种新的归因方法，以解释个体变量归因和其党的归因之间的冲突。我们首先发现，夏普利值可以被重新解释为由人工智能模型编码的哈萨尼（Harsanyi）互动的分配。其次，基于重新分配互动，我们扩展了夏普利值来归因党。最后，我们 derive了这种冲突的基本机制，这种冲突来自各个变量在其党中的互动中含有部分变量。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Forecasting-Unleashing-Long-Term-Dependencies-with-Fractionally-Differenced-Data"><a href="#Time-Series-Forecasting-Unleashing-Long-Term-Dependencies-with-Fractionally-Differenced-Data" class="headerlink" title="Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data"></a>Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13409">http://arxiv.org/abs/2309.13409</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarit Maitra, Vivek Mishra, Srashti Dwivedi, Sukanya Kundu, Goutam Kumar Kundu</li>
<li>for: 这个研究旨在提出一种新的预测策略，利用分数差分（FD）来捕捉时间序列数据中的短期和长期依赖关系。</li>
<li>methods: 这个研究使用了FD法，与传统的整数差分方法不同，FD可以维护时间序列的记忆，同时为预测目的进行稳定化。研究还使用了新闻报道的 sentiment分析，将FD应用于股票指数SPY的金融数据。</li>
<li>results: 研究结果表明，FD在与目标变量进行binary分类时表现出优于整数差分，这得到了ROCAUC和MCC评价的证明。<details>
<summary>Abstract</summary>
This study introduces a novel forecasting strategy that leverages the power of fractional differencing (FD) to capture both short- and long-term dependencies in time series data. Unlike traditional integer differencing methods, FD preserves memory in series while stabilizing it for modeling purposes. By applying FD to financial data from the SPY index and incorporating sentiment analysis from news reports, this empirical analysis explores the effectiveness of FD in conjunction with binary classification of target variables. Supervised classification algorithms were employed to validate the performance of FD series. The results demonstrate the superiority of FD over integer differencing, as confirmed by Receiver Operating Characteristic/Area Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Unitary-Weights-Based-One-Iteration-Quantum-Perceptron-Algorithm-for-Non-Ideal-Training-Sets"><a href="#A-Unitary-Weights-Based-One-Iteration-Quantum-Perceptron-Algorithm-for-Non-Ideal-Training-Sets" class="headerlink" title="A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets"></a>A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14366">http://arxiv.org/abs/2309.14366</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Liu, Peipei Gao, Yuxiang Wang, Wenbin Yu, Maojun Zhang</li>
<li>for: 提高量子神经网络的训练集不完美问题和一次学习问题</li>
<li>methods: 提出了一种基于单位 weights 的高效量子见解算法，通过计算总加重矩阵的特征值分解来使加重矩阵变为单位矩阵</li>
<li>results: 示例验证了量子门 Warren  gates {H, S, T, CNOT, Toffoli, Fredkin} 的准确实现，并且与其他量子见解算法进行比较，显示了我们的算法在应用性、准确性和可用性等方面具有优势。此外，为了进一步验证我们的算法的可应用性，还提出了一种量子复合门，该门由多个基本量子门组成。<details>
<summary>Abstract</summary>
In order to solve the problem of non-ideal training sets (i.e., the less-complete or over-complete sets) and implement one-iteration learning, a novel efficient quantum perceptron algorithm based on unitary weights is proposed, where the singular value decomposition of the total weight matrix from the training set is calculated to make the weight matrix to be unitary. The example validation of quantum gates {H, S, T, CNOT, Toffoli, Fredkin} shows that our algorithm can accurately implement arbitrary quantum gates within one iteration. The performance comparison between our algorithm and other quantum perceptron algorithms demonstrates the advantages of our algorithm in terms of applicability, accuracy, and availability. For further validating the applicability of our algorithm, a quantum composite gate which consists of several basic quantum gates is also illustrated.
</details>
<details>
<summary>摘要</summary>
为解决非理想训练集（即部分或过complete的集）和实现一轮学习，一种新的高效量子批量算法基于单位Weightmatrix是提出的，其中来自训练集的总weight矩阵的singular value decomposition被计算以使weight矩阵变为单位矩阵。例子验证量子门{H, S, T, CNOT, Toffoli, Fredkin}表明，我们的算法可以在一轮内准确实现任意量子门。与其他量子批量算法相比，我们的算法在可用性、准确性和可用性等方面具有优势。为进一步验证我们的算法的可用性，一种量子复合门，由多个基本量子门组成，也被描述。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Image-text-Multimodal-Models"><a href="#A-Survey-on-Image-text-Multimodal-Models" class="headerlink" title="A Survey on Image-text Multimodal Models"></a>A Survey on Image-text Multimodal Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15857">http://arxiv.org/abs/2309.15857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i2vec/a-survey-on-image-text-multimodal-models">https://github.com/i2vec/a-survey-on-image-text-multimodal-models</a></li>
<li>paper_authors: Ruifeng Guo, Jingxuan Wei, Linzhuang Sun, Bihui Yu, Guiyong Chang, Dawei Liu, Sibo Zhang, Zhengbing Yao, Mingjun Xu, Liping Bu<br>for:This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories.methods:The paper revisits the basic concepts and developmental milestones of image-text multimodal models, introducing a novel classification that segments their evolution into three distinct phases, and proposes a categorization of the tasks associated with image-text multimodal models into five major types.results:The paper delves into the inherent challenges and limitations of image-text multimodal models and fosters the exploration of prospective research directions, offering an exhaustive overview of the present research landscape of image-text multimodal models and serving as a valuable reference for future scholarly endeavors.<details>
<summary>Abstract</summary>
Amidst the evolving landscape of artificial intelligence, the convergence of visual and textual information has surfaced as a crucial frontier, leading to the advent of image-text multimodal models. This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories. Initially, we revisit the basic concepts and developmental milestones of these models, introducing a novel classification that segments their evolution into three distinct phases, based on their time of introduction and subsequent impact on the discipline. Furthermore, based on the tasks' significance and prevalence in the academic landscape, we propose a categorization of the tasks associated with image-text multimodal models into five major types, elucidating the recent progress and key technologies within each category. Despite the remarkable accomplishments of these models, numerous challenges and issues persist. This paper delves into the inherent challenges and limitations of image-text multimodal models, fostering the exploration of prospective research directions. Our objective is to offer an exhaustive overview of the present research landscape of image-text multimodal models and to serve as a valuable reference for future scholarly endeavors. We extend an invitation to the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.
</details>
<details>
<summary>摘要</summary>
在人工智能的演化 landscape 中，图文合并成为了一个关键的前ier，导致了图文多modal模型的出现。本文提供了图文多modal模型的全面回顾和当前状况，探讨其应用价值、挑战和可能的研究车道。首先，我们回顾了这些模型的基本概念和发展历程，提出了一种新的分类方法，将其分为三个不同的阶段，根据它们的出现时间和对领域的影响。此外，根据学术景观中任务的重要性和普遍性，我们对图文多modal模型相关任务进行了五种主要类别的分类，阐述了最近的进步和关键技术在每个类别中。 despite the remarkable achievements of these models, numerous challenges and issues persist. This paper explores the inherent challenges and limitations of image-text multimodal models, and invites the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.Here's the word-for-word translation of the text into Simplified Chinese:在人工智能的演化 landscape 中，图文合并成为了一个关键的前ier，导致了图文多modal模型的出现。本文提供了图文多modal模型的全面回顾和当前状况，探讨其应用价值、挑战和可能的研究车道。首先，我们回顾了这些模型的基本概念和发展历程，提出了一种新的分类方法，将其分为三个不同的阶段，根据它们的出现时间和对领域的影响。此外，根据学术景观中任务的重要性和普遍性，我们对图文多modal模型相关任务进行了五种主要类别的分类，阐述了最近的进步和关键技术在每个类别中。 despite the remarkable achievements of these models, numerous challenges and issues persist. This paper explores the inherent challenges and limitations of image-text multimodal models, and invites the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.
</details></li>
</ul>
<hr>
<h2 id="Smart-City-Digital-Twin-Framework-for-Real-Time-Multi-Data-Integration-and-Wide-Public-Distribution"><a href="#Smart-City-Digital-Twin-Framework-for-Real-Time-Multi-Data-Integration-and-Wide-Public-Distribution" class="headerlink" title="Smart City Digital Twin Framework for Real-Time Multi-Data Integration and Wide Public Distribution"></a>Smart City Digital Twin Framework for Real-Time Multi-Data Integration and Wide Public Distribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13394">http://arxiv.org/abs/2309.13394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Adreani, Pierfrancesco Bellini, Marco Fanfani, Paolo Nesi, Gianni Pantaleo</li>
<li>for: 这个论文是为了介绍一种基于Snap4City IoT平台的城市数字孪生框架，用于支持城市规划和管理决策。</li>
<li>methods: 该框架使用了数据收集、索引、计算和信息分布等方法，并将这些方法集成到了一个跨多个数据源的平台上，以实现实时更新的数字孪生。</li>
<li>results: 该框架可以提供实时的城市情况描述、预测和仿真分析结果，包括交通拥堵、污染物分布、可能的结果等，并且支持公民参与城市决策过程。<details>
<summary>Abstract</summary>
Digital Twins are digital replica of real entities and are becoming fundamental tools to monitor and control the status of entities, predict their future evolutions, and simulate alternative scenarios to understand the impact of changes. Thanks to the large deployment of sensors, with the increasing information it is possible to build accurate reproductions of urban environments including structural data and real-time information. Such solutions help city councils and decision makers to face challenges in urban development and improve the citizen quality of life, by ana-lysing the actual conditions, evaluating in advance through simulations and what-if analysis the outcomes of infrastructural or political chang-es, or predicting the effects of humans and/or of natural events. Snap4City Smart City Digital Twin framework is capable to respond to the requirements identified in the literature and by the international forums. Differently from other solutions, the proposed architecture provides an integrated solution for data gathering, indexing, computing and information distribution offered by the Snap4City IoT platform, therefore realizing a continuously updated Digital Twin. 3D building models, road networks, IoT devices, WoT Entities, point of interests, routes, paths, etc., as well as results from data analytical processes for traffic density reconstruction, pollutant dispersion, predictions of any kind, what-if analysis, etc., are all integrated into an accessible web interface, to support the citizens participation in the city decision processes. What-If analysis to let the user performs simulations and observe possible outcomes. As case of study, the Digital Twin of the city of Florence (Italy) is presented. Snap4City platform, is released as open-source, and made available through GitHub and as docker compose.
</details>
<details>
<summary>摘要</summary>
“数字双”是数字世界中的实体复制品，它们在监测和控制实体状态、预测未来发展和模拟不同enario来理解改变的影响。随着丰富的传感器的扩散，可以建立 precisemodels of urban environments, including structural data and real-time information。这些解决方案帮助城市议会和决策者面对城市发展的挑战，提高公民的生活质量，通过实际情况分析、预测变化和“what-if”分析来评估基础设施或政策变化的影响。Snap4City Smart City Digital Twin框架能够应对文献和国际论坛中所提出的需求。与其他解决方案不同，我们的架构提供了一个集成的数据收集、索引、计算和信息分发的解决方案，以实现不断更新的数字双。3D建筑模型、路网、物联网设备、Web of Things实体、终端、路线、轨迹等都会被集成到一个可访问的Web界面中，以支持公民参与城市决策过程。“what-if”分析允许用户进行模拟和观察可能的结果。作为案例研究，我们介绍了 Florence（意大利）的数字双。Snap4City平台释放为开源，通过 GitHub和docker compose 进行分发。
</details></li>
</ul>
<hr>
<h2 id="AgriSORT-A-Simple-Online-Real-time-Tracking-by-Detection-framework-for-robotics-in-precision-agriculture"><a href="#AgriSORT-A-Simple-Online-Real-time-Tracking-by-Detection-framework-for-robotics-in-precision-agriculture" class="headerlink" title="AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture"></a>AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13393">http://arxiv.org/abs/2309.13393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Saraceni, Ionut M. Motoi, Daniele Nardi, Thomas A. Ciarfuglia</li>
<li>for: 这个论文是为了解决精准农业中的多目标跟踪问题，这个问题是机器人学中的一个挑战。</li>
<li>methods: 这篇论文提出了一种基于运动信息的实时跟踪检测管道，即AgriSORT，该管道可以快速和准确地在视频序列中传播跟踪。</li>
<li>results: 在一个特制的农业上的MOT benchмарck上测试了AgriSORT管道，并得到了高效和准确的跟踪结果。<details>
<summary>Abstract</summary>
The problem of multi-object tracking (MOT) consists in detecting and tracking all the objects in a video sequence while keeping a unique identifier for each object. It is a challenging and fundamental problem for robotics. In precision agriculture the challenge of achieving a satisfactory solution is amplified by extreme camera motion, sudden illumination changes, and strong occlusions. Most modern trackers rely on the appearance of objects rather than motion for association, which can be ineffective when most targets are static objects with the same appearance, as in the agricultural case. To this end, on the trail of SORT [5], we propose AgriSORT, a simple, online, real-time tracking-by-detection pipeline for precision agriculture based only on motion information that allows for accurate and fast propagation of tracks between frames. The main focuses of AgriSORT are efficiency, flexibility, minimal dependencies, and ease of deployment on robotic platforms. We test the proposed pipeline on a novel MOT benchmark specifically tailored for the agricultural context, based on video sequences taken in a table grape vineyard, particularly challenging due to strong self-similarity and density of the instances. Both the code and the dataset are available for future comparisons.
</details>
<details>
<summary>摘要</summary>
“多目标追踪（MOT）问题的挑战是在识别和追踪影像序列中的所有物件，并保留每个物件唯一的识别码。这是机器人学中的基本问题。在精确农业中，实现满意的解决方案受到极大的镜头运动、突然的照明变化和强大的遮蔽影响。现代追踪器多数依靠物件的外观而非运动进行相互关联，这在农业案例中可能无效，因为大多数目标是静止的物件，具有相同的外观。为此，我们基于SORT [5]的概念，提出了AgriSORT，一个简单、在线、实时的追踪-by-探测管线，仅基于运动资讯，可以实现精确和快速的探测迹踪转换。AgriSORT的主要专注点包括效率、灵活性、最小化依赖和机器人平台的易用性。我们将该管线评估在特有的农业上的MOT实验中，基于简体葡萄园的视频序列，特别是由于强大的自相似和物件的密度。管线和数据都可以供未来的比较。”
</details></li>
</ul>
<hr>
<h2 id="D-Separation-for-Causal-Self-Explanation"><a href="#D-Separation-for-Causal-Self-Explanation" class="headerlink" title="D-Separation for Causal Self-Explanation"></a>D-Separation for Causal Self-Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13391">http://arxiv.org/abs/2309.13391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jugechengzi/rationalization-mcd">https://github.com/jugechengzi/rationalization-mcd</a></li>
<li>paper_authors: Wei Liu, Jun Wang, Haozhao Wang, Ruixuan Li, Zhiying Deng, YuanKai Zhang, Yang Qiu</li>
<li>for: 提高 NLP 模型的解释性和精度</li>
<li>methods: 基于 Minimum Conditional Dependence（MCD） criterion，使用 KL-divergence 度量依赖性，提高 F1 分数</li>
<li>results: 与先前最佳 MMI-based 方法比较，MCD 方法可以提高 F1 分数达到 $13.7%$ 之间<details>
<summary>Abstract</summary>
Rationalization is a self-explaining framework for NLP models. Conventional work typically uses the maximum mutual information (MMI) criterion to find the rationale that is most indicative of the target label. However, this criterion can be influenced by spurious features that correlate with the causal rationale or the target label. Instead of attempting to rectify the issues of the MMI criterion, we propose a novel criterion to uncover the causal rationale, termed the Minimum Conditional Dependence (MCD) criterion, which is grounded on our finding that the non-causal features and the target label are \emph{d-separated} by the causal rationale. By minimizing the dependence between the unselected parts of the input and the target label conditioned on the selected rationale candidate, all the causes of the label are compelled to be selected. In this study, we employ a simple and practical measure of dependence, specifically the KL-divergence, to validate our proposed MCD criterion. Empirically, we demonstrate that MCD improves the F1 score by up to $13.7\%$ compared to previous state-of-the-art MMI-based methods. Our code is available at: \url{https://github.com/jugechengzi/Rationalization-MCD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这是一个自解释的框架 для NLP模型。传统工作通常使用最大共同信息（MMI） criterion 来找到这些模型的理由，但这个标准可能受到假冒的特征所影响，这些特征可能与目标标签或理由相关。而不是尝试修正 MMI 标准的问题，我们提出了一个新的标准，即最小侧项依存性（MCD）标准，这是基于我们发现非 causal 特征和目标标签在 causal 理由下是 d-separated 的现象。通过将选择的理由候选者中的非选择部分的输入与目标标签之间的依存关系降至最低，所有的 Label 的原因都会被选择。在这个研究中，我们使用了一个简单实用的依存度量，具体是 KL- divergence，以验证我们的提出的 MCD 标准。实验结果显示，MCD 可以与之前的 MMI 基于的方法相比，提高 F1 分数达 13.7%。我们的代码可以在：\url{https://github.com/jugechengzi/Rationalization-MCD} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Deciphering-Spatio-Temporal-Graph-Forecasting-A-Causal-Lens-and-Treatment"><a href="#Deciphering-Spatio-Temporal-Graph-Forecasting-A-Causal-Lens-and-Treatment" class="headerlink" title="Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment"></a>Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13378">http://arxiv.org/abs/2309.13378</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Yutong Xia, Yuxuan Liang, Haomin Wen, Xu Liu, Kun Wang, Zhengyang Zhou, Roger Zimmermann</li>
<li>for: 本文旨在解决预测空间时间图（STG）中的 temporal out-of-distribution（OoD）问题和动态空间 causation 问题。</li>
<li>methods: 本文提出了一种名为 CaST 的新框架，利用 causal 镜头来解读 STG 数据生成过程，并采用 back-door adjustment 和 front-door adjustment 等方法来处理 temporal OoD 问题和 causal 衍生效应。</li>
<li>results: 实验结果表明，CaST 可以准确地预测 STG，并且在三个实际数据集上表现出色，常常超过现有方法。此外，CaST 具有良好的解释性。<details>
<summary>Abstract</summary>
Spatio-Temporal Graph (STG) forecasting is a fundamental task in many real-world applications. Spatio-Temporal Graph Neural Networks have emerged as the most popular method for STG forecasting, but they often struggle with temporal out-of-distribution (OoD) issues and dynamic spatial causation. In this paper, we propose a novel framework called CaST to tackle these two challenges via causal treatments. Concretely, leveraging a causal lens, we first build a structural causal model to decipher the data generation process of STGs. To handle the temporal OoD issue, we employ the back-door adjustment by a novel disentanglement block to separate invariant parts and temporal environments from input data. Moreover, we utilize the front-door adjustment and adopt the Hodge-Laplacian operator for edge-level convolution to model the ripple effect of causation. Experiments results on three real-world datasets demonstrate the effectiveness and practicality of CaST, which consistently outperforms existing methods with good interpretability.
</details>
<details>
<summary>摘要</summary>
espacio-temporal graph (STG) 预测是现实世界中许多应用场景中的基本任务。  espacio-temporal graph neural networks (STGNNs) 已经成为 STG 预测的最受欢迎方法，但它们经常面临时间外部预测 (OoD) 问题和动态空间 causation。 在这篇论文中，我们提议一种名为 CaST 的框架，以解决这两个挑战。具体来说，我们首先利用 causal 镜头来理解 STG 数据生成过程。为了处理时间 OoD 问题，我们使用一种新的分离块来分离输入数据中的不变部分和时间环境。此外，我们使用 front-door 调整和霍迪-拉普拉斯算子来模型 causation 的涟漪效应。实验结果表明，CaST 在三个真实世界数据集上具有优秀的效果和可读性，并经常超越现有方法。
</details></li>
</ul>
<hr>
<h2 id="Limits-of-Actor-Critic-Algorithms-for-Decision-Tree-Policies-Learning-in-IBMDPs"><a href="#Limits-of-Actor-Critic-Algorithms-for-Decision-Tree-Policies-Learning-in-IBMDPs" class="headerlink" title="Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs"></a>Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13365">http://arxiv.org/abs/2309.13365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hecotr Kohler, Riad Akrour, Philippe Preux</li>
<li>for: 提高AI模型的可解释性，以便用户建立对其信任。</li>
<li>methods: 使用强化学习框架，在DT中探索特征之间的关系，以建立更加紧凑的DT。</li>
<li>results: 通过抽离特征之间的关系，可以减少DT的大小，同时保持模型的性能。<details>
<summary>Abstract</summary>
Interpretability of AI models allows for user safety checks to build trust in such AIs. In particular, Decision Trees (DTs) provide a global look at the learned model and transparently reveal which features of the input are critical for making a decision. However, interpretability is hindered if the DT is too large. To learn compact trees, a recent Reinforcement Learning (RL) framework has been proposed to explore the space of DTs using deep RL. This framework augments a decision problem (e.g. a supervised classification task) with additional actions that gather information about the features of an otherwise hidden input. By appropriately penalizing these actions, the agent learns to optimally trade-off size and performance of DTs. In practice, a reactive policy for a partially observable Markov decision process (MDP) needs to be learned, which is still an open problem. We show in this paper that deep RL can fail even on simple toy tasks of this class. However, when the underlying decision problem is a supervised classification task, we show that finding the optimal tree can be cast as a fully observable Markov decision problem and be solved efficiently, giving rise to a new family of algorithms for learning DTs that go beyond the classical greedy maximization ones.
</details>
<details>
<summary>摘要</summary>
“AI模型的可解释性允许用户建立信任，以建立可靠的AI。尤其是决策树（DT）可以提供全面的模型显示和对输入特征的透彻显示，从而帮助用户了解模型的问题。然而，如果DT太大，则可能会妨碍可解释性。为了学习尺寸小的DT，一个最近的强化学习（RL）框架已经被提议，通过将决策问题（例如分类任务）与额外的动作搜索整合，以便在搜索DT时，对输入特征进行有效的探索。在实践中，需要学习一个可 React的策略，这是一个 ainda 未解决的问题。我们在这篇论文中显示，深度RL可以在简单的玩具任务上失败，但当对决策问题时，我们可以将找到最佳树的问题转化为一个可观察的Markov决策过程（MDP），并有效地解决它，从而开启了一新的家族Algorithm для学习DT，与传统的单簇最大化算法不同。”
</details></li>
</ul>
<hr>
<h2 id="MLPST-MLP-is-All-You-Need-for-Spatio-Temporal-Prediction"><a href="#MLPST-MLP-is-All-You-Need-for-Spatio-Temporal-Prediction" class="headerlink" title="MLPST: MLP is All You Need for Spatio-Temporal Prediction"></a>MLPST: MLP is All You Need for Spatio-Temporal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13363">http://arxiv.org/abs/2309.13363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Zhang, Ze Huang, Zhiwei Hu, Xiangyu Zhao, Wanyu Wang, Zitao Liu, Junbo Zhang, S. Joe Qin, Hongwei Zhao</li>
<li>For: 预测交通流量，提高公共交通系统的运作效率和可靠性。* Methods: 提出了一种简单、轻量级的多层感知器（MLP）架构，通过快速和高效的MLP处理， capture 空间和时间关系，并且需要只有线性计算复杂度和模型参数数量相对较少。* Results: 经过广泛的实验 validate MLPST的高效性和灵活性，并且在模型准确率最高的情况下，MLPST achieves the best time and space efficiency。<details>
<summary>Abstract</summary>
Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.
</details>
<details>
<summary>摘要</summary>
很多人对汽车流量预测有很大的需求，因为它对城市交通系统的管理有着重要的作用。为了满足这些需求，我们认为一个理想的空间时间预测方法应该具备以下三个特点：高效、轻量级和有效。然而，目前的深度模型基于的空间时间预测解决方案通常具有复杂的体系和繁琐的优化，这些方法很难满足我们的期望。为了实现以上目标，我们提出了一种直观和新型的框架，即多层感知网络（MLPST）。特别是，我们首先从本地和全局感知场景中捕捉到空间关系。然后，在不同时间间隔中考虑到了时间关系。通过紧凑的MLP处理，MLPST可以很好地捕捉到空间和时间关系，同时计算复杂度只有线性增长，并且模型参数比基线模型高出一个数量级。我们进行了广泛的实验，并证明了MLPST在比较先进的基elines上的超越性和效率。在同等准确性下，MLPST在时间和空间效率方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="Probing-the-Moral-Development-of-Large-Language-Models-through-Defining-Issues-Test"><a href="#Probing-the-Moral-Development-of-Large-Language-Models-through-Defining-Issues-Test" class="headerlink" title="Probing the Moral Development of Large Language Models through Defining Issues Test"></a>Probing the Moral Development of Large Language Models through Defining Issues Test</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13356">http://arxiv.org/abs/2309.13356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Tanmay, Aditi Khandelwal, Utkarsh Agarwal, Monojit Choudhury</li>
<li>for: 这项研究用于测试LLMs的道德理解能力，使用定义问题测试（DIT），这是根据科尔堡认知道的道德发展模型（KCDM）而开发的一种心理测试。</li>
<li>methods: 这项研究使用DIT测试LLMs的道德理解能力，包括用道德决策问题和道德考虑因素，评估 respondent 对问题的解决方案和道德价值观的重要性。</li>
<li>results: 研究显示，早期LLMs如GPT-3的道德理解能力与随机基线相当，而ChatGPT、Llama2-Chat、PaLM-2和GPT-4则表现出较好的道德理解能力，与成年人相当。GPT-4的后konventional道德理解分数最高，与典型大学生相当。但是，模型在不同的决策问题上表现不一致，指出了其理解和解决能力的重要缺陷。<details>
<summary>Abstract</summary>
In this study, we measure the moral reasoning ability of LLMs using the Defining Issues Test - a psychometric instrument developed for measuring the moral development stage of a person according to the Kohlberg's Cognitive Moral Development Model. DIT uses moral dilemmas followed by a set of ethical considerations that the respondent has to judge for importance in resolving the dilemma, and then rank-order them by importance. A moral development stage score of the respondent is then computed based on the relevance rating and ranking.   Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans. GPT-4, in fact, has the highest post-conventional moral reasoning score, equivalent to that of typical graduate school students. However, we also observe that the models do not perform consistently across all dilemmas, pointing to important gaps in their understanding and reasoning abilities.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们测量了LLM的道德思维能力使用定义问题测试（DIT）——一种心理测量instrument，用于测量人类的道德发展阶段 according to Kohlberg's cognitive moral development model。DIT使用道德困境，然后提供一组伦理考虑，请求参与者根据其重要性来评价和排序。根据参与者的道德发展阶段分数， compute the moral development stage score。  our study shows that early LLMs such as GPT-3 do not exhibit any better moral reasoning ability than a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans. GPT-4, in fact, has the highest post-conventional moral reasoning score, equivalent to that of typical graduate school students. However, we also observe that the models do not perform consistently across all dilemmas, pointing to important gaps in their understanding and reasoning abilities.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Lexical-Squad-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Hate-Speech-Detection-using-Fused-Ensemble-Approach"><a href="#Lexical-Squad-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Hate-Speech-Detection-using-Fused-Ensemble-Approach" class="headerlink" title="Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal Hate Speech Detection using Fused Ensemble Approach"></a>Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal Hate Speech Detection using Fused Ensemble Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13354">http://arxiv.org/abs/2309.13354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m0hammad-kashif/multimodalhatespeech">https://github.com/m0hammad-kashif/multimodalhatespeech</a></li>
<li>paper_authors: Mohammad Kashif, Mohammad Zohair, Saquib Ali<br>for: 本研究旨在探讨如何使用多模态学习方法来检测仇恨言论。methods: 本研究使用了InceptionV3、BERT和XLNet等现状模型，并将其组合成一个ensemble模型来检测仇恨言论。results: 研究得出了75.21%的准确率和74.96%的F1分数，并进行了实验来证明模型在预测和分类上的性能。<details>
<summary>Abstract</summary>
With a surge in the usage of social media postings to express opinions, emotions, and ideologies, there has been a significant shift towards the calibration of social media as a rapid medium of conveying viewpoints and outlooks over the globe. Concurrently, the emergence of a multitude of conflicts between two entities has given rise to a stream of social media content containing propaganda, hate speech, and inconsiderate views. Thus, the issue of monitoring social media postings is rising swiftly, attracting major attention from those willing to solve such problems. One such problem is Hate Speech detection. To mitigate this problem, we present our novel ensemble learning approach for detecting hate speech, by classifying text-embedded images into two labels, namely "Hate Speech" and "No Hate Speech". We have incorporated state-of-art models including InceptionV3, BERT, and XLNet. Our proposed ensemble model yielded promising results with 75.21 and 74.96 as accuracy and F-1 score (respectively). We also present an empirical evaluation of the text-embedded images to elaborate on how well the model was able to predict and classify. We release our codebase here (https://github.com/M0hammad-Kashif/MultiModalHateSpeech).
</details>
<details>
<summary>摘要</summary>
受社交媒体发表意见、情感和意识形态的使用量增加，社交媒体已成为全球快速传递观点和视野的重要媒体。同时，全球多个问题的出现导致社交媒体内容中充斥着宣传、仇恨言论和不谨慎的观点。因此，监测社交媒体帖子的问题日益减少，引起了广泛的关注。其中，我们提出了一种新的ensemble学习方法，用于检测嫌 speech，通过将文本嵌入图像分为两个标签：“嫌 speech”和“无嫌 speech”。我们把state-of-art模型，如InceptionV3、BERT和XLNet纳入了我们的提案模型中。我们的提案模型在实验中达到了75.21%和74.96%的准确率和F-1分数（分别）。我们还进行了employnesian评估，以便更好地描述模型是如何预测和分类文本嵌入图像。我们在github上发布了代码库（https://github.com/M0hammad-Kashif/MultiModalHateSpeech）。
</details></li>
</ul>
<hr>
<h2 id="An-In-depth-Survey-of-Large-Language-Model-based-Artificial-Intelligence-Agents"><a href="#An-In-depth-Survey-of-Large-Language-Model-based-Artificial-Intelligence-Agents" class="headerlink" title="An In-depth Survey of Large Language Model-based Artificial Intelligence Agents"></a>An In-depth Survey of Large Language Model-based Artificial Intelligence Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14365">http://arxiv.org/abs/2309.14365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengyu Zhao, Zijian Jin, Ning Cheng</li>
<li>for: 本文主要研究大语言模型（LLM）与传统人工智能（AI）代理之间的主要区别和特点，以及 LLM 基于 AI 代理的可能性和潜力。</li>
<li>methods: 本文首先比较了这两种代理的基本特点，并详细分析了 AI 代理的关键组件，包括规划、记忆和工具使用。特别是在记忆方面，本文提出了一种创新的分类方法，不仅与传统分类方法不同，还为 AI 代理的记忆系统设计提供了新的视角。</li>
<li>results: 本文通过对核心组件的深入分析，为未来人工智能代理技术的发展提供了坚实的基础。文章最后还提出了进一步研究的方向，以便为学术研究人员提供价值的思路和指导。<details>
<summary>Abstract</summary>
Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance. In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents. Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities. Subsequently, we conducted an in-depth analysis of the key components of AI agents, including planning, memory, and tool use. Particularly, for the crucial component of memory, this paper introduced an innovative classification scheme, not only departing from traditional classification methods but also providing a fresh perspective on the design of an AI agent's memory system. We firmly believe that in-depth research and understanding of these core components will lay a solid foundation for the future advancement of AI agent technology. At the end of the paper, we provide directional suggestions for further research in this field, with the hope of offering valuable insights to scholars and researchers in the field.
</details>
<details>
<summary>摘要</summary>
因为大型语言模型（LLM）的强大能力，近期有大量努力尝试将其与人工智能代理 integrate 以提高性能。在这篇论文中，我们探讨了 LLM 基于代理的核心差异和特点。 Specifically，我们首先比较了这两种代理的基本特点，明确 LLM 基于代理在自然语言处理、知识存储和 raison d'être 能力方面的显著优势。接着，我们进行了深入的分析代理的关键组件，包括规划、记忆和工具使用。尤其是在关键组件中的记忆方面，这篇论文提出了一种创新的分类方法，不仅与传统分类方法不同，而且为 AI 代理的记忆系统设计提供了新的视角。我们认为深入研究和理解这些核心组件将为未来人工智能代理技术的发展 lay 下一定的基础。总之，在这篇论文的结尾，我们提出了一些方向性的建议，以期为学者和研究人员在这个领域提供价值的信息。
</details></li>
</ul>
<hr>
<h2 id="LLMs-as-Counterfactual-Explanation-Modules-Can-ChatGPT-Explain-Black-box-Text-Classifiers"><a href="#LLMs-as-Counterfactual-Explanation-Modules-Can-ChatGPT-Explain-Black-box-Text-Classifiers" class="headerlink" title="LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?"></a>LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13340">http://arxiv.org/abs/2309.13340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amrita Bhattacharjee, Raha Moraffah, Joshua Garland, Huan Liu</li>
<li>for: 本研究使用大语言模型（LLM）来解释黑obox文本分类器的决策，通过生成后续的、模型无关的counterfactual解释。</li>
<li>methods: 我们提出了一个管道，使用LLM来生成post-hoc、模型无关的counterfactual解释，通过（i）利用LLM的文本理解能力来标识和提取潜在特征，以及（ii）利用LLM的推倒和生成能力来生成counterfactual解释。</li>
<li>results: 我们在一组state-of-the-art LLM中评估了三种变体，包括不同的特征提取方法和Counterfactual解释生成方法。我们发现这些模型在不同的设置中的性能不同，一种基于两步特征提取的全变体在大多数情况下表现最佳。我们的管道可以用于自动解释系统，可能减少人工劳动。<details>
<summary>Abstract</summary>
Large language models (LLMs) are increasingly being used for tasks beyond text generation, including complex tasks such as data labeling, information extraction, etc. With the recent surge in research efforts to comprehend the full extent of LLM capabilities, in this work, we investigate the role of LLMs as counterfactual explanation modules, to explain decisions of black-box text classifiers. Inspired by causal thinking, we propose a pipeline for using LLMs to generate post-hoc, model-agnostic counterfactual explanations in a principled way via (i) leveraging the textual understanding capabilities of the LLM to identify and extract latent features, and (ii) leveraging the perturbation and generation capabilities of the same LLM to generate a counterfactual explanation by perturbing input features derived from the extracted latent features. We evaluate three variants of our framework, with varying degrees of specificity, on a suite of state-of-the-art LLMs, including ChatGPT and LLaMA 2. We evaluate the effectiveness and quality of the generated counterfactual explanations, over a variety of text classification benchmarks. Our results show varied performance of these models in different settings, with a full two-step feature extraction based variant outperforming others in most cases. Our pipeline can be used in automated explanation systems, potentially reducing human effort.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM） increasingly 用于 tasks beyond 文本生成，包括复杂的任务，如数据标签、信息提取等。 随着研究尝试理解 LLM 的全面能力，在这个工作中，我们 investigate LLM 作为 counterfactual explanation module，以解释黑色盒子文本分类器的决策。 灵感自 causal 思维，我们提出一个管道，使用 LLM 生成 post-hoc，model-agnostic counterfactual explanations 的方式，包括：(i) 利用 LLM 的文本理解能力，识别和提取 latent features，以及 (ii) 利用 LLM 的干扰和生成能力，对 input features 进行推变，生成 counterfactual explanation。 我们评估了三种不同的框架，以不同的具体性，在一些最新的 LLM 上，包括 ChatGPT 和 LLaMA 2。 我们评估这些模型在不同的设定下的效能和质量，并发现在大多数情况下，一个完整的 two-step 特征提取基于的Variant 表现较好。 我们的管道可以用于自动解释系统，可能将人类努力削减。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Zero-Shot-Chain-of-Thought-Reasoning-in-Large-Language-Models-through-Logic"><a href="#Enhancing-Zero-Shot-Chain-of-Thought-Reasoning-in-Large-Language-Models-through-Logic" class="headerlink" title="Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"></a>Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13339">http://arxiv.org/abs/2309.13339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xufeng Zhao, Mengdi Li, Wenhao Lu, Cornelius Weber, Jae Hee Lee, Kun Chu, Stefan Wermter</li>
<li>for: 提高大型自然语言模型的逻辑推理能力</li>
<li>methods: 基于符号逻辑原理的符号神经网络框架LogiCoT</li>
<li>results: 在不同领域的语言任务上，LogiCoT能够提高大型自然语言模型的逻辑推理能力，并且可以避免生成模型的幻觉现象<details>
<summary>Abstract</summary>
Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic.
</details>
<details>
<summary>摘要</summary>
recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic.Here's the word-for-word translation in Simplified Chinese:最近的大语言模型突破有让人印象深刻的多领域普适性。然而，它们的理解能力仍然有很大的改进空间，特别是在多步逻辑场景下。虽然大语言模型拥有庞大的知识，但它们的行为，尤其是在理解方面，经常不能充分利用这些知识来建立一个有效的思维模式。生成语言模型有时会出现幻见，因为它们的理解过程没有遵循逻辑原则。为了提高大语言模型的零shot逻辑链条理解能力，我们提出了Logical Chain-of-Thought（LogiCoT），一种符号逻辑框架，利用符号逻辑原理来验证和修改理解过程。在不同领域的语言任务上，包括算术、常识、符号、 causal inference 和社会问题，我们进行了实验评估，并证明了增强的理解模式的有效性。
</details></li>
</ul>
<hr>
<h2 id="Diversifying-Question-Generation-over-Knowledge-Base-via-External-Natural-Questions"><a href="#Diversifying-Question-Generation-over-Knowledge-Base-via-External-Natural-Questions" class="headerlink" title="Diversifying Question Generation over Knowledge Base via External Natural Questions"></a>Diversifying Question Generation over Knowledge Base via External Natural Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14362">http://arxiv.org/abs/2309.14362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shasha Guo, Jing Zhang, Xirui Ke, Cuiping Li, Hong Chen</li>
<li>for: 本研究旨在提高知识基础问题生成（KBQG）的质量。</li>
<li>methods: 本研究提出了一种新的多元评价指标，以度量生成的问题的多样性，并 introduces 一种双模型框架，通过两种选择策略来生成多元的问题。</li>
<li>results: 实验结果表明，提出的方法可以生成高度多元的问题，并提高问题回答 task 的性能。<details>
<summary>Abstract</summary>
Previous methods on knowledge base question generation (KBQG) primarily focus on enhancing the quality of a single generated question. Recognizing the remarkable paraphrasing ability of humans, we contend that diverse texts should convey the same semantics through varied expressions. The above insights make diversifying question generation an intriguing task, where the first challenge is evaluation metrics for diversity. Current metrics inadequately assess the above diversity since they calculate the ratio of unique n-grams in the generated question itself, which leans more towards measuring duplication rather than true diversity. Accordingly, we devise a new diversity evaluation metric, which measures the diversity among top-k generated questions for each instance while ensuring their relevance to the ground truth. Clearly, the second challenge is how to enhance diversifying question generation. To address this challenge, we introduce a dual model framework interwoven by two selection strategies to generate diverse questions leveraging external natural questions. The main idea of our dual framework is to extract more diverse expressions and integrate them into the generation model to enhance diversifying question generation. Extensive experiments on widely used benchmarks for KBQG demonstrate that our proposed approach generates highly diverse questions and improves the performance of question answering tasks.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a new evaluation metric for diversity that measures the diversity among the top-k generated questions for each instance while ensuring their relevance to the ground truth. Additionally, we introduce a dual model framework that leverages external natural questions to generate diverse questions. Our approach extracts more diverse expressions and integrates them into the generation model to enhance diversifying question generation.We demonstrate the effectiveness of our approach through extensive experiments on widely used benchmarks for KBQG. Our proposed approach generates highly diverse questions and improves the performance of question answering tasks.
</details></li>
</ul>
<hr>
<h2 id="Class-Attendance-System-in-Education-with-Deep-Learning-Method"><a href="#Class-Attendance-System-in-Education-with-Deep-Learning-Method" class="headerlink" title="Class Attendance System in Education with Deep Learning Method"></a>Class Attendance System in Education with Deep Learning Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13317">http://arxiv.org/abs/2309.13317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hüdaverdi Demir, Serkan Savaş</li>
<li>For: The paper is written for the purpose of developing a system using deep learning methods for object detection in images to record students’ entrance to educational institutions and to perform class attendance.* Methods: The paper uses deep learning methods, specifically object detection algorithms, to detect students’ entrance and attendance in educational institutions.* Results: The study successfully implemented the object detection system and will be applied to real-life problems in a school in the 2022-2023 academic year.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究旨在开发基于深度学习方法的对象检测系统，用于记录学生入学教育机构和进行课程参加。</li>
<li>methods: 本研究使用深度学习方法，具体来说是对象检测算法，来检测学生入学和课程参加。</li>
<li>results: 研究成功实现对象检测系统，将在2022-2023学年度应用到实际问题中。<details>
<summary>Abstract</summary>
With the advancing technology, the hardware gain of computers and the increase in the processing capacity of processors have facilitated the processing of instantaneous and real-time images. Face recognition processes are also studies in the field of image processing. Facial recognition processes are frequently used in security applications and commercial applications. Especially in the last 20 years, the high performances of artificial intelligence (AI) studies have contributed to the spread of these studies in many different fields. Education is one of them. The potential and advantages of using AI in education; can be grouped under three headings: student, teacher, and institution. One of the institutional studies may be the security of educational environments and the contribution of automation to education and training processes. From this point of view, deep learning methods, one of the sub-branches of AI, were used in this study. For object detection from images, a pioneering study has been designed and successfully implemented to keep records of students' entrance to the educational institution and to perform class attendance with images taken from the camera using image processing algorithms. The application of the study to real-life problems will be carried out in a school determined in the 2022-2023 academic year.
</details>
<details>
<summary>摘要</summary>
The potential benefits of using AI in education can be grouped into three categories: student, teacher, and institution. One of the institutional studies is the security of educational environments and the contribution of automation to education and training processes. In this study, deep learning methods, a sub-branch of AI, were used for object detection from images. The study was designed to record students' entrance to the educational institution and to perform class attendance using images taken from cameras and image processing algorithms. The application of the study to real-life problems will be carried out in a school during the 2022-2023 academic year.
</details></li>
</ul>
<hr>
<h2 id="USL-Net-Uncertainty-Self-Learning-Network-for-Unsupervised-Skin-Lesion-Segmentation"><a href="#USL-Net-Uncertainty-Self-Learning-Network-for-Unsupervised-Skin-Lesion-Segmentation" class="headerlink" title="USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation"></a>USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13289">http://arxiv.org/abs/2309.13289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaofan Li, Bo Peng, Daipeng Yang, Zhuyang Xie</li>
<li>for: 这个研究旨在提出一个无监督的皮肤条件分类方法，以解决无监督皮肤条件分类中的挑战。</li>
<li>methods: 本研究使用了自我学习网络（USL-Net），通过对照学习提取特征，然后生成分类对应的活化地图（CAM）来进行分类。高度活化的地图区域表示皮肤条件的重要性，而低度活化的区域则表示背景。</li>
<li>results: 实验结果显示，本方法可以与弱监督和监督方法相比，并且超过其他已有的无监督方法的性能。<details>
<summary>Abstract</summary>
Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-saliency regions represent the background. However, intermediate regions can be hard to classify, often due to their proximity to lesion edges or interference from hair or blisters. Rather than risk potential pseudo-labeling errors or learning confusion by forcefully classifying these regions, we consider them as uncertainty regions, exempting them from pseudo-labeling and allowing the network to self-learn. Further, we employ connectivity detection and centrality detection to refine foreground pseudo-labels and reduce noise-induced errors. The application of cycle refining enhances performance further. Our method underwent thorough experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets, demonstrating that its performance is on par with weakly supervised and supervised methods, and exceeds that of other existing unsupervised methods.
</details>
<details>
<summary>摘要</summary>
无监督皮肤病变分割具有多个优点，如保留专业人员资源、减少主观人类标注的差异和适应新环境。然而，在无人标注指导下对德朗斯科普图像进行分割存在 significanti挑战，主要是因为德朗斯科普图像的艺术ifacts，如毛发噪声、膨涨噪声和细微边缘差异。为解决这些挑战，我们提出了一种创新的不确定自学习网络（USL-Net），用于皮肤病变分割。USL-Net可以有效地分割多种病变，无需人工标注指导。首先，通过对比学习提取特征，然后通过这些特征生成类活动图（CAM）作为saliency map。不同的CAM位置对病变区域的重要性进行标识，高Saliency区域在Map中对病变区域具有高重要性，而低Saliency区域则代表背景。然而，中间区域可能具有困难分类，常常是因为 lesion edge 邻近或毛发/膨涨噪声的干扰。而不要强制性地将这些区域分类为病变区域，我们将其视为不确定区域，并将其除外。此外，我们还使用连接检测和中心检测来改进前景 pseudo-标注和减少噪声引起的错误。通过循环反馈，我们进一步提高性能。我们的方法在 ISIC-2017、ISIC-2018 和 PH2 数据集上进行了严格的实验验证，结果表明其性能与弱监督和监督方法相当，并超过了其他现有的无监督方法。
</details></li>
</ul>
<hr>
<h2 id="Collision-Avoidance-and-Navigation-for-a-Quadrotor-Swarm-Using-End-to-end-Deep-Reinforcement-Learning"><a href="#Collision-Avoidance-and-Navigation-for-a-Quadrotor-Swarm-Using-End-to-end-Deep-Reinforcement-Learning" class="headerlink" title="Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning"></a>Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13285">http://arxiv.org/abs/2309.13285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhehui Huang, Zhaojing Yang, Rahul Krupani, Baskın Şenbaşlar, Sumeet Batra, Gaurav S. Sukhatme</li>
<li>for: 这paper的目的是使用end-to-end深度强化学习控制带有障碍物的四旋翼机器人群体。</li>
<li>methods: 这paper使用的方法包括curriculum学习和归一化缓存，以及对邻居机器人和障碍物的注意机制。</li>
<li>results: 这paper的结果表明，通过使用这些方法，可以在带有障碍物的环境中控制四旋翼机器人群体，并且可以在真实的quadrotor上进行零shot传输。<details>
<summary>Abstract</summary>
End-to-end deep reinforcement learning (DRL) for quadrotor control promises many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80% obstacle density in simulation and 8 robots with 20% obstacle density in physical deployment. Video demonstrations are available on the project website at: https://sites.google.com/view/obst-avoid-swarm-rl.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTEnd-to-end deep reinforcement learning (DRL) for quadrotor control  quadrotor 执行 controller 承诺 many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80% obstacle density in simulation and 8 robots with 20% obstacle density in physical deployment. Video demonstrations are available on the project website at: https://sites.google.com/view/obst-avoid-swarm-rl.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Being-Aware-of-Localization-Accuracy-By-Generating-Predicted-IoU-Guided-Quality-Scores"><a href="#Being-Aware-of-Localization-Accuracy-By-Generating-Predicted-IoU-Guided-Quality-Scores" class="headerlink" title="Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores"></a>Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13269">http://arxiv.org/abs/2309.13269</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/panffeereal/clq">https://github.com/panffeereal/clq</a></li>
<li>paper_authors: Pengfei Liu, Weibo Wang, Yuhan Guo, Jiubin Tan</li>
<li>for: 提高检测性能，通过同时考虑分类分数和地址准确率，提高检测质量。</li>
<li>methods: 采用了新的检测架构，即CLQ，其包括一个简洁的LQE分支，用于获取地址质量分数指导。在训练和推理过程中，LQE分支与分类分支结合在一起，生成一个共同的分类-地址-质量表示。</li>
<li>results: 在COCO测试dev数据集上，CLQ实现了最新的状态艺术性能，具有47.8 AP和11.5 fps的速度，并且在ATSS上进行扩展，实现了可靠的1.2 AP提升。<details>
<summary>Abstract</summary>
Localization Quality Estimation (LQE) helps to improve detection performance as it benefits post processing through jointly considering classification score and localization accuracy. In this perspective, for further leveraging the close relationship between localization accuracy and IoU (Intersection-Over-Union), and for depressing those inconsistent predictions, we designed an elegant LQE branch to acquire localization quality score guided by predicted IoU. Distinctly, for alleviating the inconsistency of classification score and localization quality during training and inference, under which some predictions with low classification scores but high LQE scores will impair the performance, instead of separately and independently setting, we embedded LQE branch into classification branch, producing a joint classification-localization-quality representation. Then a novel one stage detector termed CLQ is proposed. Extensive experiments show that CLQ achieves state-of-the-arts' performance at an accuracy of 47.8 AP and a speed of 11.5 fps with ResNeXt-101 as backbone on COCO test-dev. Finally, we extend CLQ to ATSS, producing a reliable 1.2 AP gain, showing our model's strong adaptability and scalability. Codes are released at https://github.com/PanffeeReal/CLQ.
</details>
<details>
<summary>摘要</summary>
本文提出了一种新的一Stage检测器（CLQ），通过结合分类分支和本地化质量估计（LQE）分支，实现了分类、本地化和质量三者的共同表示。这种方法可以解决在训练和推断过程中分类分数和本地化质量之间的不一致问题，从而提高检测性能。实验表明，CLQ在COCO测试预训练集上达到了47.8 AP的最佳性能和11.5 fps的速度，并且对ATSS进行扩展，实现了可靠的1.2 AP提升。代码可以在github上找到。
</details></li>
</ul>
<hr>
<h2 id="Robust-Navigation-with-Cross-Modal-Fusion-and-Knowledge-Transfer"><a href="#Robust-Navigation-with-Cross-Modal-Fusion-and-Knowledge-Transfer" class="headerlink" title="Robust Navigation with Cross-Modal Fusion and Knowledge Transfer"></a>Robust Navigation with Cross-Modal Fusion and Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13266">http://arxiv.org/abs/2309.13266</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wzcai99/Distill-Navigator">https://github.com/wzcai99/Distill-Navigator</a></li>
<li>paper_authors: Wenzhe Cai, Guangran Cheng, Lingyue Kong, Lu Dong, Changyin Sun</li>
<li>for: 提高机器人Navigation技能的通用化和实际应用（improving the generalization of mobile robot navigation skills and achieving sim-to-real transfer）</li>
<li>methods: 跨模态融合方法和教师学生填充框架（cross-modal fusion method and teacher-student distillation architecture）</li>
<li>results: 比基eline表现出色，在 simulated和实际环境中实现了Robust Navigation性能（outperforms the baselines in both simulated and real-world environments, achieving robust navigation performance with varying working conditions）<details>
<summary>Abstract</summary>
Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions.
</details>
<details>
<summary>摘要</summary>
最近，学习基于方法在导航任务中显示了有前途的结果。然而，低泛化能力和实验室实际差距阻碍了广泛应用。我们对移动机器人的改进泛化和实际协同转移技能的问题进行了考虑。为达到这一目标，我们提出了跨模态融合方法和知识传递框架。这是通过教师学生热退架构实现的。教师在理想环境中学习一个抽象表示和准确策略。通过imiter教师的行为和表示，学生可以将多种不稳定的输入特征相互拟合，并减少导航策略中的变化影响。我们在模拟和实际环境中进行了测试，实验结果表明，我们的方法在基eline上大幅超越，并在不同工作条件下实现了稳定的导航性能。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Chance-Constrained-Submodular-Problems-with-Variable-Uncertainties"><a href="#Optimizing-Chance-Constrained-Submodular-Problems-with-Variable-Uncertainties" class="headerlink" title="Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties"></a>Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14359">http://arxiv.org/abs/2309.14359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiankun Yan, Anh Viet Do, Feng Shi, Xiaoyu Qin, Frank Neumann</li>
<li>for: 这个论文是关于概率性约束限制的实时优化问题的研究，具体来说是关于可变权重项目中的可变概率约束。</li>
<li>methods: 该论文使用了抽象搜索算法和随机搜索算法来解决可变权重项目中的可变概率约束问题。</li>
<li>results: 该论文通过分析和实验表明，使用抽象搜索算法和随机搜索算法可以在可变权重项目中提供高质量的解决方案，具体来说是一个常数近似比例的解决方案。<details>
<summary>Abstract</summary>
Chance constraints are frequently used to limit the probability of constraint violations in real-world optimization problems where the constraints involve stochastic components. We study chance-constrained submodular optimization problems, which capture a wide range of optimization problems with stochastic constraints. Previous studies considered submodular problems with stochastic knapsack constraints in the case where uncertainties are the same for each item that can be selected. However, uncertainty levels are usually variable with respect to the different stochastic components in real-world scenarios, and rigorous analysis for this setting is missing in the context of submodular optimization. This paper provides the first such analysis for this case, where the weights of items have the same expectation but different dispersion. We present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the deterministic setting. In the experiments, we demonstrate that the algorithms perform effectively on several chance-constrained instances of the maximum coverage problem and the influence maximization problem.
</details>
<details>
<summary>摘要</summary>
<font face="宋体">机会约束 frequently 用于限制实际问题中的约束违背 probabilities。我们研究 chance-constrained submodular optimization problems，这些问题涵盖了实际问题中具有恒等约束的变量组合。 previous studies 对 submodular problems with stochastic knapsack constraints 进行了研究，但是在实际情况中，不同的随机成分之间的不确定程度通常是不同的，而这项研究在 submodular optimization 的 context 中缺乏 rigorous analysis。 this paper 提供了 first such analysis for this case，where the weights of items have the same expectation but different dispersion. we present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the deterministic setting. in the experiments, we demonstrate that the algorithms perform effectively on several chance-constrained instances of the maximum coverage problem and the influence maximization problem.</font>Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="WikiMT-Dataset-Card"><a href="#WikiMT-Dataset-Card" class="headerlink" title="WikiMT++ Dataset Card"></a>WikiMT++ Dataset Card</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13259">http://arxiv.org/abs/2309.13259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Monan Zhou, Shangda Wu, Yuan Wang, Wei Li</li>
<li>for: 扩展和改进 WikiMusicText 数据集，用于音乐信息检索、条件音乐生成、自动作曲和情感分类等应用场景。</li>
<li>methods: 添加对象属性（专辑、歌词、视频）和主观情感属性（12种情感词），以及使用 CLaMP 进行属性修正，以提高数据集的准确性和完整性。</li>
<li>results: 提高了 WikiMT 的应用场景和可用性，并且通过添加新的属性和修正原始数据，提高了数据集的准确性和完整性。<details>
<summary>Abstract</summary>
WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.
</details>
<details>
<summary>摘要</summary>
<SYS><TRANSLATE>WikiMT++是 WikiMusicText（WikiMT）的扩展和改进版本，包含1010个精心编辑的领导Sheet在ABCnotation。为扩展 WikiMT 的应用场景，我们添加了对象（专辑、歌词、视频）和主观情感（12种情感形容词）以及 emo\_4q（Russell 4Q）属性，从而提高了音乐信息检索、 conditional music generation、自动作曲和情感分类等方面的可用性。此外，CLaMP 也被实现，以修正从 WikiMT 继承的属性，以降低在原始数据收集过程中引入的错误，提高数据集的准确性和完整性。</TRANSLATE></SYS>Note: "Simplified Chinese" is a romanization of the Chinese language that uses a simplified set of characters and pronunciation. It is commonly used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Defending-Pre-trained-Language-Models-as-Few-shot-Learners-against-Backdoor-Attacks"><a href="#Defending-Pre-trained-Language-Models-as-Few-shot-Learners-against-Backdoor-Attacks" class="headerlink" title="Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks"></a>Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13256">http://arxiv.org/abs/2309.13256</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaohan-xi/plm-prompt-defense">https://github.com/zhaohan-xi/plm-prompt-defense</a></li>
<li>paper_authors: Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang</li>
<li>for: This paper is written to investigate the security risks of pre-trained language models (PLMs) as few-shot learners and to propose a novel defense mechanism called MDP to address these risks.</li>
<li>methods: The paper uses a pilot study to demonstrate the vulnerability of PLMs to backdoor attacks in few-shot scenarios and proposes MDP as a lightweight, pluggable, and effective defense. MDP leverages the gap between the masking-sensitivity of poisoned and clean samples to identify poisoned samples.</li>
<li>results: The paper shows the efficacy of MDP through analytical analysis and empirical evaluation using benchmark datasets and representative attacks. The results demonstrate that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness.<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have demonstrated remarkable performance as few-shot learners. However, their security risks under such settings are largely unexplored. In this work, we conduct a pilot study showing that PLMs as few-shot learners are highly vulnerable to backdoor attacks while existing defenses are inadequate due to the unique challenges of few-shot scenarios. To address such challenges, we advocate MDP, a novel lightweight, pluggable, and effective defense for PLMs as few-shot learners. Specifically, MDP leverages the gap between the masking-sensitivity of poisoned and clean samples: with reference to the limited few-shot data as distributional anchors, it compares the representations of given samples under varying masking and identifies poisoned samples as ones with significant variations. We show analytically that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness. The empirical evaluation using benchmark datasets and representative attacks validates the efficacy of MDP.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Can-I-Trust-the-Explanations-Investigating-Explainable-Machine-Learning-Methods-for-Monotonic-Models"><a href="#Can-I-Trust-the-Explanations-Investigating-Explainable-Machine-Learning-Methods-for-Monotonic-Models" class="headerlink" title="Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models"></a>Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13246">http://arxiv.org/abs/2309.13246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dangxing Chen</li>
<li>for: 这个论文主要针对的是解释性机器学习方法在具有领域知识的模型上的应用。</li>
<li>methods: 这个论文使用了解释性机器学习方法，包括基准值法和集成梯度法，来解释具有领域知识的模型的决策过程。</li>
<li>results: 研究发现，当只有个体偏好 monotonicity 存在时，基准值法可以提供良好的解释；而当强对比 monotonicity 存在时，集成梯度法在平均情况下可以提供相对更好的解释。<details>
<summary>Abstract</summary>
In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UniHead-Unifying-Multi-Perception-for-Detection-Heads"><a href="#UniHead-Unifying-Multi-Perception-for-Detection-Heads" class="headerlink" title="UniHead: Unifying Multi-Perception for Detection Heads"></a>UniHead: Unifying Multi-Perception for Detection Heads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13242">http://arxiv.org/abs/2309.13242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zht8506/unihead">https://github.com/zht8506/unihead</a></li>
<li>paper_authors: Hantao Zhou, Rui Yang, Yachao Zhang, Haoran Duan, Yawen Huang, Runze Hu, Xiu Li, Yefeng Zheng<br>for:This paper aims to improve the object detection performance by developing a novel detection head called UniHead, which unifies three perceptual abilities simultaneously: deformation perception, global perception, and cross-task perception.methods:The proposed UniHead uses a Dual-axial Aggregation Transformer (DAT) to model long-range dependencies and adaptively sample object features, as well as a Cross-task Interaction Transformer (CIT) to facilitate interaction between the classification and localization branches.results:The proposed UniHead achieves significant improvements in object detection performance on the COCO dataset, with +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL, compared to the baseline methods. The code will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/zht8506/UniHead">https://github.com/zht8506/UniHead</a>.<details>
<summary>Abstract</summary>
The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and localization branches, thus aligning the two tasks. As a plug-and-play method, the proposed UniHead can be conveniently integrated with existing detectors. Extensive experiments on the COCO dataset demonstrate that our UniHead can bring significant improvements to many detectors. For instance, the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL. The code will be publicly available. Code Url: https://github.com/zht8506/UniHead.
</details>
<details>
<summary>摘要</summary>
历史头部是目标检测器中的关键组件，负责执行分类和 lokalisierung 功能。可惜，通常使用的并行头部frequentlylacks omni perceptual capabilities, such as deformation perception, global perception, and cross-task perception. Despite numerous methods attempting to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach:1. 引入了形态感知，使模型可以适应性地采样对象特征;2. 提出了 Dual-axial Aggregation Transformer (DAT)，以便模型长距离依赖关系，实现全球感知;3. 设计了 Cross-task Interaction Transformer (CIT)，以便类别和 lokalisierung 分支之间进行交互，使两个任务进行一致。作为一种插件式方法，我们的 UniHead 可以方便地与现有的检测器集成。广泛的实验表明，我们的 UniHead 可以为许多检测器带来显著改进。例如，UniHead 可以在 RetinaNet 中提高 +2.7 AP 得分，在 FreeAnchor 中提高 +2.9 AP 得分，和在 GFL 中提高 +2.1 AP 得分。代码将公开。代码Url：https://github.com/zht8506/UniHead。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Feature-Representation-for-Digital-Twin-Oriented-Complex-Networked-Systems"><a href="#Heterogeneous-Feature-Representation-for-Digital-Twin-Oriented-Complex-Networked-Systems" class="headerlink" title="Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems"></a>Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13229">http://arxiv.org/abs/2309.13229</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial</li>
<li>for: 这项研究旨在提高复杂网络系统（CNS）模型的表达能力，以更好地反映实际世界系统。</li>
<li>methods: 该研究使用了不同的特征表示原则，包括整数特征值和杂化集，以描述节点特征的客观和主观含义。</li>
<li>results: 研究发现，使用杂化集表示法可以提高模型的表达能力，并且不同的特征表示方法会影响网络结构和疫情蔓延速度，需要采取不同的缓冲策略来适应不同人群。<details>
<summary>Abstract</summary>
Building models of Complex Networked Systems (CNS) that can accurately represent reality forms an important research area. To be able to reflect real world systems, the modelling needs to consider not only the intensity of interactions between the entities but also features of all the elements of the system. This study aims to improve the expressive power of node features in Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous feature representation principles. This involves representing features with crisp feature values and fuzzy sets, each describing the objective and the subjective inductions of the nodes' features and feature differences. Our empirical analysis builds DT-CNSs to recreate realistic physical contact networks in different countries from real node feature distributions based on various representation principles and an optimised feature preference. We also investigate their respective disaster resilience to an epidemic outbreak starting from the most popular node. The results suggest that the increasing flexibility of feature representation with fuzzy sets improves the expressive power and enables more accurate modelling. In addition, the heterogeneous features influence the network structure and the speed of the epidemic outbreak, requiring various mitigation policies targeted at different people.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Complex Networked Systems" (CNS) is translated as "复杂网络系统" (CNS) in Simplified Chinese.* "Digital Twin-Oriented Complex Networked Systems" (DT-CNSs) is translated as "数字双向复杂网络系统" (DT-CNSs) in Simplified Chinese.* "heterogeneous feature representation principles" is translated as "不同类型特征表示原则" in Simplified Chinese.* "crisp feature values" is translated as "分割特征值" in Simplified Chinese.* "fuzzy sets" is translated as "柔软集" in Simplified Chinese.* "objective and subjective inductions of the nodes' features" is translated as "节点特征的客观和主观推导" in Simplified Chinese.* "feature differences" is translated as "特征差异" in Simplified Chinese.* "empirical analysis" is translated as "实证分析" in Simplified Chinese.* "physical contact networks" is translated as "物理接触网络" in Simplified Chinese.* "real node feature distributions" is translated as "真实节点特征分布" in Simplified Chinese.* "optimized feature preference" is translated as "优化特征偏好" in Simplified Chinese.* "disaster resilience" is translated as "灾害抗性" in Simplified Chinese.* "epidemic outbreak" is translated as "疫情爆发" in Simplified Chinese.* "most popular node" is translated as "最受欢迎的节点" in Simplified Chinese.* "mitigation policies" is translated as "缓解措施" in Simplified Chinese.* "different people" is translated as "不同人群" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Pick-Planning-Strategies-for-Large-Scale-Package-Manipulation"><a href="#Pick-Planning-Strategies-for-Large-Scale-Package-Manipulation" class="headerlink" title="Pick Planning Strategies for Large-Scale Package Manipulation"></a>Pick Planning Strategies for Large-Scale Package Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13224">http://arxiv.org/abs/2309.13224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Li, Azarakhsh Keipour, Kevin Jamieson, Nicolas Hudson, Sicong Zhao, Charles Swan, Kostas Bekris</li>
<li>for: 提高仓储运作效率，降低物流成本，提高交往速度，提高市场波动的抗性。</li>
<li>methods: 使用Robin营运系统进行大规模包裹排序和单独，每天处理600万个包裹，总共处理20亿个包裹。开发了各种论述方法，其中包括使用实际生产数据训练的抓取质量预测器。</li>
<li>results: 本研究是首次在真实生产环境中大规模应用学习抓取质量预测器。<details>
<summary>Abstract</summary>
Automating warehouse operations can reduce logistics overhead costs, ultimately driving down the final price for consumers, increasing the speed of delivery, and enhancing the resiliency to market fluctuations.   This extended abstract showcases a large-scale package manipulation from unstructured piles in Amazon Robotics' Robot Induction (Robin) fleet, which is used for picking and singulating up to 6 million packages per day and so far has manipulated over 2 billion packages. It describes the various heuristic methods developed over time and their successor, which utilizes a pick success predictor trained on real production data.   To the best of the authors' knowledge, this work is the first large-scale deployment of learned pick quality estimation methods in a real production system.
</details>
<details>
<summary>摘要</summary>
自动化仓库操作可以减少物流成本，最终降低消费者最终价格，提高快递速度，并增强对市场波动的抗颤势。  这个扩展摘要展示了亚马逊 робо拓客（Robin）车队的大规模套件搬运，可以每天搬运Up to 6 million个套件并已经搬运了超过20亿个套件。它描述了不同的论述方法，以及其继承者，该方法使用实际生产数据进行学习套件质量预测。  据作者所知，这是首次在真正生产环境中大规模应用学习套件质量预测方法。
</details></li>
</ul>
<hr>
<h2 id="Hindi-to-English-Transformer-Based-Neural-Machine-Translation"><a href="#Hindi-to-English-Transformer-Based-Neural-Machine-Translation" class="headerlink" title="Hindi to English: Transformer-Based Neural Machine Translation"></a>Hindi to English: Transformer-Based Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13222">http://arxiv.org/abs/2309.13222</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/1502shivam-singh/audio-vision-server">https://github.com/1502shivam-singh/audio-vision-server</a></li>
<li>paper_authors: Kavit Gangar, Hardik Ruparel, Shreyas Lele</li>
<li>for: 这个论文主要针对的是将印度语言希腊语译成英语的自动翻译问题，以提高翻译质量。</li>
<li>methods: 这个论文使用了深度学习技术，特别是Transformer模型，将希腊语译成英语。为了增强数据训练， authors还使用了回训练和字节对编码（BPE）进行 vocabulary 创建和tokenization。</li>
<li>results: 根据IIT Bombay英语-希腊语词库测试集，这个配置达到了当前最佳的BLEU分数24.53。<details>
<summary>Abstract</summary>
Machine Translation (MT) is one of the most prominent tasks in Natural Language Processing (NLP) which involves the automatic conversion of texts from one natural language to another while preserving its meaning and fluency. Although the research in machine translation has been going on since multiple decades, the newer approach of integrating deep learning techniques in natural language processing has led to significant improvements in the translation quality. In this paper, we have developed a Neural Machine Translation (NMT) system by training the Transformer model to translate texts from Indian Language Hindi to English. Hindi being a low resource language has made it difficult for neural networks to understand the language thereby leading to a slow growth in the development of neural machine translators. Thus, to address this gap, we implemented back-translation to augment the training data and for creating the vocabulary, we experimented with both word and subword level tokenization using Byte Pair Encoding (BPE) thereby ending up training the Transformer in 10 different configurations. This led us to achieve a state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay English-Hindi Corpus in one of the configurations.
</details>
<details>
<summary>摘要</summary>
机器翻译（MT）是自然语言处理（NLP）中最为出名的任务之一，它涉及自然语言之间文本的自动转换，保持意思和流畅性。虽然关于机器翻译的研究已经持续多个 décennia，但是在近年来，将深度学习技术应用于自然语言处理领域，带来了对翻译质量的显著改善。在这篇论文中，我们开发了一个基于Transformer模型的神经机器翻译系统，用于从印度语言希ن第语到英语的翻译。由于希第语是一种低资源语言，使得神经网络理解这种语言很困难，因此在神经机器翻译的发展中，进展较为缓慢。为了解决这个问题，我们实施了反向翻译以增加训练数据，并在 vocabulary 创建方面实验了字节对编码（BPE）的两种tokenization策略。经过10种不同的配置训练，我们最终实现了IIT Bombay英语-希第语词库测试集上的state-of-the-art BLEU分数24.53。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.AI_2023_09_23/" data-id="clpxp6bwq004fee885r4qa79l" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/42/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><a class="page-number" href="/page/42/">42</a><span class="page-number current">43</span><a class="page-number" href="/page/44/">44</a><a class="page-number" href="/page/45/">45</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/44/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
