
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/43/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.SD_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T15:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.SD_2023_09_23/">cs.SD - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Attention-Is-All-You-Need-For-Blind-Room-Volume-Estimation"><a href="#Attention-Is-All-You-Need-For-Blind-Room-Volume-Estimation" class="headerlink" title="Attention Is All You Need For Blind Room Volume Estimation"></a>Attention Is All You Need For Blind Room Volume Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13504">http://arxiv.org/abs/2309.13504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunxi Wang, Maoshen Jia, Meiran Li, Changchun Bao, Wenyu Jin</li>
<li>for: 这篇论文主要是针对听取环境动态参数化问题进行研究，具体来说是用于盲目估计室内声学参数。</li>
<li>methods: 这篇论文提出了一种基于注意力机制的纯注意力模型，用于盲目估计室内声学参数。模型使用了扩展的Transformer架构，并使用了多modal数据 Transfer learning来提高模型性能。</li>
<li>results: 实验结果表明，提出的模型在实际听取环境中表现出色，特别是在使用专门预训练和数据扩展方案时。模型的性能在各种听取环境中都有显著提高。<details>
<summary>Abstract</summary>
In recent years, dynamic parameterization of acoustic environments has raised increasing attention in the field of audio processing. One of the key parameters that characterize the local room acoustics in isolation from orientation and directivity of sources and receivers is the geometric room volume. Convolutional neural networks (CNNs) have been widely selected as the main models for conducting blind room acoustic parameter estimation, which aims to learn a direct mapping from audio spectrograms to corresponding labels. With the recent trend of self-attention mechanisms, this paper introduces a purely attention-based model to blindly estimate room volumes based on single-channel noisy speech signals. We demonstrate the feasibility of eliminating the reliance on CNN for this task and the proposed Transformer architecture takes Gammatone magnitude spectral coefficients and phase spectrograms as inputs. To enhance the model performance given the task-specific dataset, cross-modality transfer learning is also applied. Experimental results demonstrate that the proposed model outperforms traditional CNN models across a wide range of real-world acoustics spaces, especially with the help of the dedicated pretraining and data augmentation schemes.
</details>
<details>
<summary>摘要</summary>
最近几年，动态参数化的声学环境在声音处理领域受到了越来越多的关注。一个关键参数，用于隔离源和接收器的方向和方向性，是地形室内体积。深度学习神经网络（CNN）广泛选择为无目标声学参数估计的主要模型，该模型的目标是从声音спектрограм中直接学习到相应的标签。随着自动注意机制的潮流，这篇论文介绍了一种完全基于注意力的模型，用于无目标地估计室内体积，并将 Gammatone 大小 спектрограм和相位спектрограм作为输入。为了提高模型在这个任务上的表现，我们还应用了交叉模态转移学习。实验结果表明，我们提出的模型在真实世界的各种声学空间中， especial 在使用特定数据集和预训练 schemes 时，都能够超过传统的 CNN 模型。
</details></li>
</ul>
<hr>
<h2 id="Two-vs-Four-Channel-Sound-Event-Localization-and-Detection"><a href="#Two-vs-Four-Channel-Sound-Event-Localization-and-Detection" class="headerlink" title="Two vs. Four-Channel Sound Event Localization and Detection"></a>Two vs. Four-Channel Sound Event Localization and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13343">http://arxiv.org/abs/2309.13343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Wilkins, Magdalena Fuentes, Luca Bondi, Shabnam Ghaffarzadegan, Ali Abavisani, Juan Pablo Bello</li>
<li>for: 本研究旨在探讨DCASE 2022 SELD挑战 зада务中（任务3）模型在4个渠道设置下的性能，以及不同音频输入表示方式对SELD性能的影响。</li>
<li>methods: 本研究使用了DCASE 2022 SELD基线模型，并对不同音频输入表示方式进行比较分析，以评估它们对SELD性能的影响。</li>
<li>results: 研究发现，带声和ステレオ（即2个渠道）音频基于SELD模型仍然能够良好地定位和探测声源，尽管总体性能下降。此外，研究还 segmented 分析了不同场景中声源多样性的影响，以更好地理解不同音频输入表示方式对SELD性能的影响。<details>
<summary>Abstract</summary>
Sound event localization and detection (SELD) systems estimate both the direction-of-arrival (DOA) and class of sound sources over time. In the DCASE 2022 SELD Challenge (Task 3), models are designed to operate in a 4-channel setting. While beneficial to further the development of SELD systems using a multichannel recording setup such as first-order Ambisonics (FOA), most consumer electronics devices rarely are able to record using more than two channels. For this reason, in this work we investigate the performance of the DCASE 2022 SELD baseline model using three audio input representations: FOA, binaural, and stereo. We perform a novel comparative analysis illustrating the effect of these audio input representations on SELD performance. Crucially, we show that binaural and stereo (i.e. 2-channel) audio-based SELD models are still able to localize and detect sound sources laterally quite well, despite overall performance degrading as less audio information is provided. Further, we segment our analysis by scenes containing varying degrees of sound source polyphony to better understand the effect of audio input representation on localization and detection performance as scene conditions become increasingly complex.
</details>
<details>
<summary>摘要</summary>
听音事件地理位置和检测（SELD）系统估算听音源的方向到达（DOA）和时间上的类型。在DCASE 2022 SELD挑战（任务3）中，模型设计用4通道记录设置。虽然多通道记录设置可以进一步发展SELD系统，但大多数消费类电子设备通常只能记录两个通道。因此，在这个工作中，我们研究了DCASE 2022 SELD基准模型使用FOA、双耳和立体声三种听音输入表示方式的性能。我们进行了一项新的比较分析，描述这些听音输入表示方式对听音源的地理位置和检测性能的影响。我们发现，使用双耳和立体声（即2通道）听音基于SELD模型仍然能够准确地localize和检测听音源，尽管总体性能下降。此外，我们对不同场景中听音源的多重播放情况进行了分 segment 的分析，以更好地理解听音输入表示方式对听音源的地理位置和检测性能的影响，场景条件变得越来越复杂。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Speaker-Embedding-With-Sequential-Disentanglement"><a href="#Contrastive-Speaker-Embedding-With-Sequential-Disentanglement" class="headerlink" title="Contrastive Speaker Embedding With Sequential Disentanglement"></a>Contrastive Speaker Embedding With Sequential Disentanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13253">http://arxiv.org/abs/2309.13253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youzhi Tu, Man-Wai Mak, Jen-Tzung Chien</li>
<li>for: 本文旨在提出一种基于对比学习的语音说话人识别方法，该方法利用了顺序分解器（DSVAE）来除掉语言内容，从而使得只有说话人因素被用于构建对比损失目标。</li>
<li>methods: 本文提出的方法包括在传统的SimCLR框架中 incorporating 顺序分解器（DSVAE），以除掉语言内容，并使用对比学习来学习说话人特征。</li>
<li>results: 实验结果表明，提出的方法在 VoxCeleb1-test 上的表现Consistently 高于 SimCLR，这表明了应用顺序分解是有利于学习说话人特征的。<details>
<summary>Abstract</summary>
Contrastive speaker embedding assumes that the contrast between the positive and negative pairs of speech segments is attributed to speaker identity only. However, this assumption is incorrect because speech signals contain not only speaker identity but also linguistic content. In this paper, we propose a contrastive learning framework with sequential disentanglement to remove linguistic content by incorporating a disentangled sequential variational autoencoder (DSVAE) into the conventional SimCLR framework. The DSVAE aims to disentangle speaker factors from content factors in an embedding space so that only the speaker factors are used for constructing a contrastive loss objective. Because content factors have been removed from the contrastive learning, the resulting speaker embeddings will be content-invariant. Experimental results on VoxCeleb1-test show that the proposed method consistently outperforms SimCLR. This suggests that applying sequential disentanglement is beneficial to learning speaker-discriminative embeddings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate given text into Simplified Chinese.<</SYS>>对照性发言嵌入假设，即对于正例和负例对话段的差异归结于发言人身份。然而，这个假设是错误的，因为语音信号包含不仅发言人身份，还包含语言内容。在这篇论文中，我们提议一种含有顺序解解析的对照学习框架，使用嵌入空间中的分离顺序自动编码器（DSVAE）来除去语言内容。DSVAE的目标是在嵌入空间中分离发言人因素和语言因素，以便只使用发言人因素来构建对照损失对象。因此，在对照学习中移除了语言内容，得到的发言人嵌入将是内容不变的。实验结果表明，提议的方法在VoxCeleb1-test上一直高于SimCLR。这表明，在学习发言人特异性嵌入时，顺序解解析是有利的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.SD_2023_09_23/" data-id="clp9qz8a300zqok88hkyq338n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.CV_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T13:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.CV_2023_09_23/">cs.CV - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Portrait-Stylization-Artistic-Style-Transfer-with-Auxiliary-Networks-for-Human-Face-Stylization"><a href="#Portrait-Stylization-Artistic-Style-Transfer-with-Auxiliary-Networks-for-Human-Face-Stylization" class="headerlink" title="Portrait Stylization: Artistic Style Transfer with Auxiliary Networks for Human Face Stylization"></a>Portrait Stylization: Artistic Style Transfer with Auxiliary Networks for Human Face Stylization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13492">http://arxiv.org/abs/2309.13492</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thiagoambiel/PortraitStylization">https://github.com/thiagoambiel/PortraitStylization</a></li>
<li>paper_authors: Thiago Ambiel</li>
<li>for: 提高图像风格传递中人脸个体特征的保留</li>
<li>methods: 使用辅助预训练人脸识别模型的嵌入来鼓励算法在内容图像上传递人脸特征到最终风格化结果中</li>
<li>results: 提高了图像风格传递中人脸个体特征的保留<details>
<summary>Abstract</summary>
Today's image style transfer methods have difficulty retaining humans face individual features after the whole stylizing process. This occurs because the features like face geometry and people's expressions are not captured by the general-purpose image classifiers like the VGG-19 pre-trained models. This paper proposes the use of embeddings from an auxiliary pre-trained face recognition model to encourage the algorithm to propagate human face features from the content image to the final stylized result.
</details>
<details>
<summary>摘要</summary>
今天的图像风格传递方法很难保持人脸个人特征 после整个风格化过程。这是因为人脸的特征，如人脸几何学和人们的表情，不被通用的图像分类器如VGG-19预训练模型捕捉。这篇论文提议使用auxiliary预训练人脸识别模型的嵌入来鼓励算法在内容图像上传递人脸特征到最终风格化结果中。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Systematic-Errors-in-Object-Detectors-with-the-SCROD-Pipeline"><a href="#Identifying-Systematic-Errors-in-Object-Detectors-with-the-SCROD-Pipeline" class="headerlink" title="Identifying Systematic Errors in Object Detectors with the SCROD Pipeline"></a>Identifying Systematic Errors in Object Detectors with the SCROD Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13489">http://arxiv.org/abs/2309.13489</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Valentyn Boreiko, Matthias Hein, Jan Hendrik Metzen</li>
<li>for: 本研究旨在提高对象检测器的系统性错误识别和除除，以便在自动驾驶和机器人应用中使用。</li>
<li>methods: 我们提出了一种新的框架， combinesPhysical simulators和生成模型的优点，以实现高级的自动控制和可扩展性。</li>
<li>results: 我们的框架可以自动生成街道场景，并且可以具有精细的控制。此外，我们还提出了一种评价设定，可以作为类似框架的标准测试进程。<details>
<summary>Abstract</summary>
The identification and removal of systematic errors in object detectors can be a prerequisite for their deployment in safety-critical applications like automated driving and robotics. Such systematic errors can for instance occur under very specific object poses (location, scale, orientation), object colors/textures, and backgrounds. Real images alone are unlikely to cover all relevant combinations. We overcome this limitation by generating synthetic images with fine-granular control. While generating synthetic images with physical simulators and hand-designed 3D assets allows fine-grained control over generated images, this approach is resource-intensive and has limited scalability. In contrast, using generative models is more scalable but less reliable in terms of fine-grained control. In this paper, we propose a novel framework that combines the strengths of both approaches. Our meticulously designed pipeline along with custom models enables us to generate street scenes with fine-grained control in a fully automated and scalable manner. Moreover, our framework introduces an evaluation setting that can serve as a benchmark for similar pipelines. This evaluation setting will contribute to advancing the field and promoting standardized testing procedures.
</details>
<details>
<summary>摘要</summary>
“系统性错误在物检测器中的识别和移除可以是安全应用程序like自动驾驶和机器人的必要条件。这些系统性错误可能会发生在非常特定的物品位置（位置、比例、姿态）、物品颜色/ texture 和背景下。实际的图像独立无法覆盖所有相关的 комbination。我们 overcome这个限制，通过生成Synthetic图像，并具有精细的控制。使用物理 simulator 和手动设计的 3D 资产来生成Synthetic图像可以实现精细的控制，但这种方法是资源耗尽和有限的可扩展性。相比之下，使用生成模型是更可扩展的，但是在精细控制方面 Less reliable。在这篇论文中，我们提出一个新的框架，让我们在自动化和可扩展的方式下，生成街景图像，并具有精细的控制。此外，我们的框架还引入了评估环境，可以作为类似框架的参考。这个评估环境将对领域的进步和标准化 testing  процедуures 做出贡献。”
</details></li>
</ul>
<hr>
<h2 id="Detecting-and-Mitigating-System-Level-Anomalies-of-Vision-Based-Controllers"><a href="#Detecting-and-Mitigating-System-Level-Anomalies-of-Vision-Based-Controllers" class="headerlink" title="Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers"></a>Detecting and Mitigating System-Level Anomalies of Vision-Based Controllers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13475">http://arxiv.org/abs/2309.13475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aryaman Gupta, Kaustav Chakraborty, Somil Bansal</li>
<li>for: 本研究旨在提高自主系统的安全性和可靠性，通过在运行时检测和 Mitigate 视觉控制器的异常情况。</li>
<li>methods: 本研究使用了可达性基础结构来压测视觉控制器，并将其异常情况数据用于在线训练异常检测器。</li>
<li>results: 研究结果表明，提出的方法可以识别和处理视觉控制器的系统级异常情况，并在检测和 Mitigate 过程中提高自主系统的安全性和可靠性。<details>
<summary>Abstract</summary>
Autonomous systems, such as self-driving cars and drones, have made significant strides in recent years by leveraging visual inputs and machine learning for decision-making and control. Despite their impressive performance, these vision-based controllers can make erroneous predictions when faced with novel or out-of-distribution inputs. Such errors can cascade to catastrophic system failures and compromise system safety. In this work, we introduce a run-time anomaly monitor to detect and mitigate such closed-loop, system-level failures. Specifically, we leverage a reachability-based framework to stress-test the vision-based controller offline and mine its system-level failures. This data is then used to train a classifier that is leveraged online to flag inputs that might cause system breakdowns. The anomaly detector highlights issues that transcend individual modules and pertain to the safety of the overall system. We also design a fallback controller that robustly handles these detected anomalies to preserve system safety. We validate the proposed approach on an autonomous aircraft taxiing system that uses a vision-based controller for taxiing. Our results show the efficacy of the proposed approach in identifying and handling system-level anomalies, outperforming methods such as prediction error-based detection, and ensembling, thereby enhancing the overall safety and robustness of autonomous systems.
</details>
<details>
<summary>摘要</summary>
自主系统，如自驾车和无人机，在最近几年中取得了很大的进步，通过视觉输入和机器学习来做出决策和控制。尽管它们的表现非常出色，但这些视觉控制器在面对新或非标准的输入时可能会做出错误的预测。这些错误可能会导致系统失败和发生危机。在这个工作中，我们提出了一个在线运行的问题检测器，以检测和缓解这些关键的系统级别失败。具体来说，我们利用一个可以在线运行的抽象框架，对视觉控制器进行压力测试，并从这些资料中提取出可能会导致系统异常的特征。这些特征可以被用来训练一个在线运行的分类器，以检测和识别可能会导致系统异常的输入。这个问题检测器可以帮助检测和解决系统级别的问题，以提高自主系统的安全和可靠性。我们还设计了一个可靠的备援控制器，以确保系统在检测到问题时能够稳定地运行。我们验证了我们的方法在一个使用视觉控制器进行着陆的自主飞机系统中，结果显示了我们的方法能够优化自主系统的安全和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Edge-Aware-Learning-for-3D-Point-Cloud"><a href="#Edge-Aware-Learning-for-3D-Point-Cloud" class="headerlink" title="Edge Aware Learning for 3D Point Cloud"></a>Edge Aware Learning for 3D Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13472">http://arxiv.org/abs/2309.13472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Li<br>for:* 这种方法是为了处理点云数据中的噪声，提高物体认知和分割。methods:* 该方法使用了人类视觉系统中的边感知概念，并将其 интеグриinto了学习方法中，以提高物体识别和分割。results:* 该方法在ModelNet40和ShapeNet数据集上表现出色，在物体分类和分割任务中表现出了显著的优势。<details>
<summary>Abstract</summary>
This paper proposes an innovative approach to Hierarchical Edge Aware 3D Point Cloud Learning (HEA-Net) that seeks to address the challenges of noise in point cloud data, and improve object recognition and segmentation by focusing on edge features. In this study, we present an innovative edge-aware learning methodology, specifically designed to enhance point cloud classification and segmentation. Drawing inspiration from the human visual system, the concept of edge-awareness has been incorporated into this methodology, contributing to improved object recognition while simultaneously reducing computational time. Our research has led to the development of an advanced 3D point cloud learning framework that effectively manages object classification and segmentation tasks. A unique fusion of local and global network learning paradigms has been employed, enriched by edge-focused local and global embeddings, thereby significantly augmenting the model's interpretative prowess. Further, we have applied a hierarchical transformer architecture to boost point cloud processing efficiency, thus providing nuanced insights into structural understanding. Our approach demonstrates significant promise in managing noisy point cloud data and highlights the potential of edge-aware strategies in 3D point cloud learning. The proposed approach is shown to outperform existing techniques in object classification and segmentation tasks, as demonstrated by experiments on ModelNet40 and ShapeNet datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HAVE-Net-Hallucinated-Audio-Visual-Embeddings-for-Few-Shot-Classification-with-Unimodal-Cues"><a href="#HAVE-Net-Hallucinated-Audio-Visual-Embeddings-for-Few-Shot-Classification-with-Unimodal-Cues" class="headerlink" title="HAVE-Net: Hallucinated Audio-Visual Embeddings for Few-Shot Classification with Unimodal Cues"></a>HAVE-Net: Hallucinated Audio-Visual Embeddings for Few-Shot Classification with Unimodal Cues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13470">http://arxiv.org/abs/2309.13470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ankit Jha, Debabrata Pal, Mainak Singha, Naman Agarwal, Biplab Banerjee</li>
<li>for: 本研究旨在解决remote sensing（RS）频谱图像识别领域中的一个新的问题，即在meta-训练阶段可以同时使用视觉modalities，但在meta-测试阶段一个modalities可能缺失。</li>
<li>methods: 我们提出了一种新的几何学生成框架，即Hallucinated Audio-Visual Embeddings-Network（HAVE-Net），用于在限制性的单模态数据上meta-训练交叉模态特征。在推理阶段，我们使用这些幻想出的特征进行几何学分类。</li>
<li>results: 我们的实验结果表明，使用我们的幻想模态增强策略，在ADVANCE和AudioSetZSL数据集上的 benchmark dataset上，我们的几何学分类器在少数据情况下表现至少比基eline perfomance高出0.8-2%。<details>
<summary>Abstract</summary>
Recognition of remote sensing (RS) or aerial images is currently of great interest, and advancements in deep learning algorithms added flavor to it in recent years. Occlusion, intra-class variance, lighting, etc., might arise while training neural networks using unimodal RS visual input. Even though joint training of audio-visual modalities improves classification performance in a low-data regime, it has yet to be thoroughly investigated in the RS domain. Here, we aim to solve a novel problem where both the audio and visual modalities are present during the meta-training of a few-shot learning (FSL) classifier; however, one of the modalities might be missing during the meta-testing stage. This problem formulation is pertinent in the RS domain, given the difficulties in data acquisition or sensor malfunctioning. To mitigate, we propose a novel few-shot generative framework, Hallucinated Audio-Visual Embeddings-Network (HAVE-Net), to meta-train cross-modal features from limited unimodal data. Precisely, these hallucinated features are meta-learned from base classes and used for few-shot classification on novel classes during the inference phase. The experimental results on the benchmark ADVANCE and AudioSetZSL datasets show that our hallucinated modality augmentation strategy for few-shot classification outperforms the classifier performance trained with the real multimodal information at least by 0.8-2%.
</details>
<details>
<summary>摘要</summary>
现在远程感知（RS）或航空图像的认知是非常有趣，深度学习算法在最近几年中增添了一些风味。在训练神经网络时， occlusion、内类差异、照明等问题可能会出现。尽管将音频和视觉模式联合训练可以在数据缺乏的情况下提高分类性能，但是在RS领域还未得到过分析。在这里，我们想解决一个新的问题，即在meta-测试阶段缺失一个感知模式。这种问题在RS领域非常有 pertinence，因为数据收集或传感器故障是常见的问题。为了 mitigate，我们提出了一种新的几shot生成框架，即Hallucinated Audio-Visual Embeddings-Network（HAVE-Net）。具体来说，这些hallucinated特征是在基类上meta-学习的，并在推理阶段用于几shot分类 novel classes。实验结果表明，我们的 hallucinated感知特征增强策略在ADVANCE和AudioSetZSL数据集上的 benchmark 上超过了实际多modal信息下的类ifier性能，至少提高0.8-2%。
</details></li>
</ul>
<hr>
<h2 id="Turbulence-in-Focus-Benchmarking-Scaling-Behavior-of-3D-Volumetric-Super-Resolution-with-BLASTNet-2-0-Data"><a href="#Turbulence-in-Focus-Benchmarking-Scaling-Behavior-of-3D-Volumetric-Super-Resolution-with-BLASTNet-2-0-Data" class="headerlink" title="Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data"></a>Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13457">http://arxiv.org/abs/2309.13457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wai Tong Chung, Bassem Akoush, Pushan Sharma, Alex Tamkin, Ki Sung Jung, Jacqueline H. Chen, Jack Guo, Davy Brouzet, Mohsen Talei, Bruno Savard, Alexei Y. Poludnenko, Matthias Ihme<br>for:The paper aims to provide a large-scale dataset of 3D high-fidelity compressible turbulent flow simulations for training and benchmarking deep learning models.methods:The paper uses 744 full-domain samples from 34 high-fidelity direct numerical simulations to create a network-of-datasets called BLASTNet 2.0, which contains 49 variations of five deep learning approaches for 3D super-resolution.results:The paper performs a neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques, and demonstrates that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size.<details>
<summary>Abstract</summary>
Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution - which can be applied for improving scientific imaging, simulations, turbulence models, as well as in computer vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size. The outcomes of this benchmark study are anticipated to offer insights that can aid the design of 3D super-resolution models, especially for turbulence models, while this data is expected to foster ML methods for a broad range of flow physics applications. This data is publicly available with download links and browsing tools consolidated at https://blastnet.github.io.
</details>
<details>
<summary>摘要</summary>
We tested 49 variations of five deep learning approaches for 3D super-resolution using this dataset. Our results show that:1. Predictive performance can scale with model size and cost.2. Model architecture is crucial, especially for smaller models.3. Physics-based losses can provide significant benefits, even with larger models.These findings can aid the design of 3D super-resolution models, particularly for turbulence models. The BLASTNet 2.0 dataset is publicly available at <https://blastnet.github.io>, with download links and browsing tools. This dataset is expected to facilitate the development of machine learning methods for a wide range of flow physics applications.
</details></li>
</ul>
<hr>
<h2 id="Video-Timeline-Modeling-For-News-Story-Understanding"><a href="#Video-Timeline-Modeling-For-News-Story-Understanding" class="headerlink" title="Video Timeline Modeling For News Story Understanding"></a>Video Timeline Modeling For News Story Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13446">http://arxiv.org/abs/2309.13446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Meng Liu, Mingda Zhang, Jialu Liu, Hanjun Dai, Ming-Hsuan Yang, Shuiwang Ji, Zheyun Feng, Boqing Gong</li>
<li>For: The paper is written for exploring the problem of video timeline modeling, with the goal of creating a video-associated timeline to facilitate content and structure understanding of the story being told.* Methods: The paper proposes several deep learning approaches to tackling this problem, including the development of a realistic benchmark dataset (YouTube-News-Timeline) and the introduction of quantitative metrics to evaluate and compare methodologies.* Results: The paper anticipates that this exploratory work will pave the way for further research in video timeline modeling, and provides a testbed for researchers to build upon.Here’s the same information in Simplified Chinese text:* For: 本文探讨视频时间轴模型问题，目的是创建与特定主题相关的视频时间轴，以便更好地理解故事的内容和结构。* Methods: 本文提出了多种深度学习方法来解决这个问题，包括开发一个真实的 bencmark 数据集 (YouTube-News-Timeline) 和引入评估和比较方法的量化指标。* Results: 本文预计这项探讨工作将为视频时间轴模型的进一步研究开辟新的道路，并提供了研究者们可以进一步发展的测试平台。<details>
<summary>Abstract</summary>
In this paper, we present a novel problem, namely video timeline modeling. Our objective is to create a video-associated timeline from a set of videos related to a specific topic, thereby facilitating the content and structure understanding of the story being told. This problem has significant potential in various real-world applications, for instance, news story summarization. To bootstrap research in this area, we curate a realistic benchmark dataset, YouTube-News-Timeline, consisting of over $12$k timelines and $300$k YouTube news videos. Additionally, we propose a set of quantitative metrics to comprehensively evaluate and compare methodologies. With such a testbed, we further develop and benchmark several deep learning approaches to tackling this problem. We anticipate that this exploratory work will pave the way for further research in video timeline modeling. The assets are available via https://github.com/google-research/google-research/tree/master/video_timeline_modeling.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个新的问题，即视频时间轴建模。我们的目标是从一组关于特定主题的视频集合中生成一个视频相关的时间轴，以便更好地理解视频中的内容和结构。这个问题在实际应用中具有重要的潜在价值，例如新闻故事概要。为了推动这个领域的研究，我们制作了一个现实的测试集，YouTube-News-Timeline，包含超过12000个时间轴和300000个YouTube新闻视频。此外，我们提出了一些量化的评价指标，以全面评估和比较不同方法的性能。通过这些实验，我们预计会开拓视频时间轴建模的研究途径。资产可以通过https://github.com/google-research/google-research/tree/master/video_timeline_modeling获取。
</details></li>
</ul>
<hr>
<h2 id="Dream-the-Impossible-Outlier-Imagination-with-Diffusion-Models"><a href="#Dream-the-Impossible-Outlier-Imagination-with-Diffusion-Models" class="headerlink" title="Dream the Impossible: Outlier Imagination with Diffusion Models"></a>Dream the Impossible: Outlier Imagination with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13415">http://arxiv.org/abs/2309.13415</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/dream-ood">https://github.com/deeplearning-wisc/dream-ood</a></li>
<li>paper_authors: Xuefeng Du, Yiyou Sun, Xiaojin Zhu, Yixuan Li</li>
<li>for: 本研究旨在提出一种新的框架，以便生成高品质的异常样例，以提高机器学习模型的OOD检测和预测安全性。</li>
<li>methods: 该框架基于diffusion模型，通过文本条件的latent空间学习，生成高维像素空间中的异常样例。</li>
<li>results: 研究表明，通过使用DREAM-OOD生成的样例进行训练，可以提高OOD检测性能。<details>
<summary>Abstract</summary>
Utilizing auxiliary outlier datasets to regularize the machine learning model has demonstrated promise for out-of-distribution (OOD) detection and safe prediction. Due to the labor intensity in data collection and cleaning, automating outlier data generation has been a long-desired alternative. Despite the appeal, generating photo-realistic outliers in the high dimensional pixel space has been an open challenge for the field. To tackle the problem, this paper proposes a new framework DREAM-OOD, which enables imagining photo-realistic outliers by way of diffusion models, provided with only the in-distribution (ID) data and classes. Specifically, DREAM-OOD learns a text-conditioned latent space based on ID data, and then samples outliers in the low-likelihood region via the latent, which can be decoded into images by the diffusion model. Different from prior works, DREAM-OOD enables visualizing and understanding the imagined outliers, directly in the pixel space. We conduct comprehensive quantitative and qualitative studies to understand the efficacy of DREAM-OOD, and show that training with the samples generated by DREAM-OOD can benefit OOD detection performance. Code is publicly available at https://github.com/deeplearning-wisc/dream-ood.
</details>
<details>
<summary>摘要</summary>
使用辅助外围数据集规范机器学习模型，已经显示了出现在其他分布（OOD）探测和安全预测的承诺。由于数据收集和清洁的劳动性，自动生成外围数据变得非常感兴趣。尽管有吸引力，在高维像素空间中生成真实的外围数据仍然是领域的一个开放挑战。为解决这个问题，这篇论文提出了一个新的框架——DREAM-OOD，可以生成真实的外围数据。具体来说，DREAM-OOD学习了根据内 distribuition（ID）数据的文本 conditioned的隐藏空间，然后通过这个隐藏空间的低可能性区域进行采样，这些采样可以通过扩散模型进行解码，转换为图像。与先前的工作不同，DREAM-OOD可以直接在像素空间中可见和理解生成的外围数据。我们进行了全面的量化和质量研究，并证明了在训练中使用DREAM-OOD生成的样本可以提高OOD探测性能。代码可以在https://github.com/deeplearning-wisc/dream-ood中下载。
</details></li>
</ul>
<hr>
<h2 id="WS-YOLO-Weakly-Supervised-Yolo-Network-for-Surgical-Tool-Localization-in-Endoscopic-Videos"><a href="#WS-YOLO-Weakly-Supervised-Yolo-Network-for-Surgical-Tool-Localization-in-Endoscopic-Videos" class="headerlink" title="WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization in Endoscopic Videos"></a>WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization in Endoscopic Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13404">http://arxiv.org/abs/2309.13404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/breezewrf/weakly-supervised-yolov8">https://github.com/breezewrf/weakly-supervised-yolov8</a></li>
<li>paper_authors: Rongfeng Wei, Jinlin Wu, You Pang, Zhen Chen</li>
<li>for: 这个论文是为了提高endooscopic视频记录中手术工具的检测和跟踪而写的。</li>
<li>methods: 这个论文使用了Weakly Supervised Yolo Network (WS-YOLO)来生成endooscopic视频中手术工具的精细Semantic信息，包括工具的位置和类别。</li>
<li>results: 这个论文的实验结果表明，WS-YOLO可以准确地检测和跟踪手术工具，并且可以减少人工标注劳动量。 codes are available online。<details>
<summary>Abstract</summary>
Being able to automatically detect and track surgical instruments in endoscopic video recordings would allow for many useful applications that could transform different aspects of surgery. In robot-assisted surgery, the potentially informative data like categories of surgical tool can be captured, which is sparse, full of noise and without spatial information. We proposed a Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in Endoscopic Videos, to generate fine-grained semantic information with location and category from coarse-grained semantic information outputted by the da Vinci surgical robot, which significantly diminished the necessary human annotation labor while striking an optimal balance between the quantity of manually annotated data and detection performance. The source code is available at https://github.com/Breezewrf/Weakly-Supervised-Yolov8.
</details>
<details>
<summary>摘要</summary>
能够自动探测和跟踪针对endooscopic视频记录的手术工具，将有很多有用的应用程序，可以transform不同方面的手术。在机器助手手术中，可以捕捉可能有用的数据，如手术工具类别，但这些数据稀疏、充满噪音，无法提供空间信息。我们提出了一种Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in Endoscopic Videos，以生成细化的semantic信息，包括位置和类别，从粗化的semantic信息输出ted by the da Vinci surgical robot，这有效减少了人工标注劳动，同时 strike an optimal balance between the quantity of manually annotated data and detection performance。源代码可以在https://github.com/Breezewrf/Weakly-Supervised-Yolov8中找到。
</details></li>
</ul>
<hr>
<h2 id="Dual-Reference-Source-Free-Active-Domain-Adaptation-for-Nasopharyngeal-Carcinoma-Tumor-Segmentation-across-Multiple-Hospitals"><a href="#Dual-Reference-Source-Free-Active-Domain-Adaptation-for-Nasopharyngeal-Carcinoma-Tumor-Segmentation-across-Multiple-Hospitals" class="headerlink" title="Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals"></a>Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal Carcinoma Tumor Segmentation across Multiple Hospitals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13401">http://arxiv.org/abs/2309.13401</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whq-xxh/Active-GTV-Seg">https://github.com/whq-xxh/Active-GTV-Seg</a></li>
<li>paper_authors: Hongqiu Wang, Jian Chen, Shichen Zhang, Yuan He, Jinfeng Xu, Mengwan Wu, Jinlan He, Wenjun Liao, Xiangde Luo</li>
<li>for: 这个论文旨在提高nasopharyngeal carcinoma（NPC）的肿体卷积（GTV）分割精度，以确保NPC radiotherapy的效果。</li>
<li>methods: 这个论文提出了一种源自free active domain adaptation（SFADA）框架，用于解决GTV分割任务中的领域适应问题。该框架使用了双参照策略，选择目标领域中具有适应性和特定性的样本进行标注和模型细化。</li>
<li>results: 实验结果表明， compared to unsupervised domain adaptation（UDA）方法，SFADA方法可以更好地适应领域适应问题，并且可以与完全监督Upper Bound（UB）相当，即使只有几个标注样本。此外，该论文还收集了1057名NPC患者的临床数据，以验证该方法的有效性。<details>
<summary>Abstract</summary>
Nasopharyngeal carcinoma (NPC) is a prevalent and clinically significant malignancy that predominantly impacts the head and neck area. Precise delineation of the Gross Tumor Volume (GTV) plays a pivotal role in ensuring effective radiotherapy for NPC. Despite recent methods that have achieved promising results on GTV segmentation, they are still limited by lacking carefully-annotated data and hard-to-access data from multiple hospitals in clinical practice. Although some unsupervised domain adaptation (UDA) has been proposed to alleviate this problem, unconditionally mapping the distribution distorts the underlying structural information, leading to inferior performance. To address this challenge, we devise a novel Sourece-Free Active Domain Adaptation (SFADA) framework to facilitate domain adaptation for the GTV segmentation task. Specifically, we design a dual reference strategy to select domain-invariant and domain-specific representative samples from a specific target domain for annotation and model fine-tuning without relying on source-domain data. Our approach not only ensures data privacy but also reduces the workload for oncologists as it just requires annotating a few representative samples from the target domain and does not need to access the source data. We collect a large-scale clinical dataset comprising 1057 NPC patients from five hospitals to validate our approach. Experimental results show that our method outperforms the UDA methods and achieves comparable results to the fully supervised upper bound, even with few annotations, highlighting the significant medical utility of our approach. In addition, there is no public dataset about multi-center NPC segmentation, we will release code and dataset for future research.
</details>
<details>
<summary>摘要</summary>
《nasopharyngeal carcinoma (NPC)是一种流行的且严重影响头颈部的恶性肿瘤，精准定义Gross Tumor Volume (GTV)对NPC有效 radiotherapy至关重要。 despite recent methods have achieved promising results in GTV segmentation, they are still limited by the lack of carefully-annotated data and hard-to-access data from multiple hospitals in clinical practice. although some unsupervised domain adaptation (UDA) has been proposed to alleviate this problem, unconditionally mapping the distribution distorts the underlying structural information, leading to inferior performance. to address this challenge, we propose a novel Source-Free Active Domain Adaptation (SFADA) framework to facilitate domain adaptation for the GTV segmentation task. specifically, we design a dual reference strategy to select domain-invariant and domain-specific representative samples from a specific target domain for annotation and model fine-tuning without relying on source-domain data. our approach not only ensures data privacy but also reduces the workload for oncologists as it only requires annotating a few representative samples from the target domain and does not need to access the source data. we collect a large-scale clinical dataset comprising 1057 NPC patients from five hospitals to validate our approach. experimental results show that our method outperforms the UDA methods and achieves comparable results to the fully supervised upper bound, even with few annotations, highlighting the significant medical utility of our approach. in addition, there is no public dataset about multi-center NPC segmentation, we will release code and dataset for future research.》Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-mirror-Unet-architecture-for-PET-CT-lesion-segmentation"><a href="#A-mirror-Unet-architecture-for-PET-CT-lesion-segmentation" class="headerlink" title="A mirror-Unet architecture for PET&#x2F;CT lesion segmentation"></a>A mirror-Unet architecture for PET&#x2F;CT lesion segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13398">http://arxiv.org/abs/2309.13398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yrotstein/autopet2023_mv1">https://github.com/yrotstein/autopet2023_mv1</a></li>
<li>paper_authors: Yamila Rotstein Habarnau, Mauro Namías</li>
<li>for: 这个研究的目的是为了自动检测和分类内科癌症的变化，并将其分类为不同的类型。</li>
<li>methods: 这个研究使用了一种深度学习方法，即 combining two UNet-3D branches，其中一个分支用于从 CT 图像中分类组织，另一个分支则用于从 PET 图像中分类变化。</li>
<li>results: 研究发现，这种深度学习方法可以实现高精度的变化检测和分类，并且可以将变化分类为不同的类型。<details>
<summary>Abstract</summary>
Automatic lesion detection and segmentation from [${}^{18}$F]FDG PET/CT scans is a challenging task, due to the diversity of shapes, sizes, FDG uptake and location they may present, besides the fact that physiological uptake is also present on healthy tissues. In this work, we propose a deep learning method aimed at the segmentation of oncologic lesions, based on a combination of two UNet-3D branches. First, one of the network's branches is trained to segment a group of tissues from CT images. The other branch is trained to segment the lesions from PET images, combining on the bottleneck the embedded information of CT branch, already trained. We trained and validated our networks on the AutoPET MICCAI 2023 Challenge dataset. Our code is available at: https://github.com/yrotstein/AutoPET2023_Mv1.
</details>
<details>
<summary>摘要</summary>
自动检测和分割肿瘤从 [${}^{18}$F]FDG PET/CT扫描图像是一项具有挑战性的任务，由于肿瘤的多样性、大小、FDG吸收和位置的不同，以及健康组织也会有physiological吸收。在这项工作中，我们提出了基于深度学习的肿瘤分割方法，通过两个UNet-3D支持树的组合来实现。第一个网络支持树被训练用于从CT图像中分割一组组织。另一个支持树则被训练用于从PET图像中分割肿瘤，并将 embedding在树的瓶颈中的CT支持树已经训练完成。我们在AutoPET MICCAI 2023 Challenge数据集上训练和验证了我们的网络。我们的代码可以在以下地址找到：https://github.com/yrotstein/AutoPET2023_Mv1。
</details></li>
</ul>
<hr>
<h2 id="YOLORe-IDNet-An-Efficient-Multi-Camera-System-for-Person-Tracking"><a href="#YOLORe-IDNet-An-Efficient-Multi-Camera-System-for-Person-Tracking" class="headerlink" title="YOLORe-IDNet: An Efficient Multi-Camera System for Person-Tracking"></a>YOLORe-IDNet: An Efficient Multi-Camera System for Person-Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13387">http://arxiv.org/abs/2309.13387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vipin Gautam, Shitala Prasad, Sharad Sinha</li>
<li>for: 实时多摄像头人识别和跟踪</li>
<li>methods:  correlate filters 和 Intersection Over Union (IOU) 约束，以及基于 YOLOv5 的深度学习人体重复识别 (Re-ID)</li>
<li>results: 高达 79% 的 F1-Score 和 59% 的 IOU，与现有状态的算法相当，在公共可用 OTB-100 数据集上进行评估。<details>
<summary>Abstract</summary>
The growing need for video surveillance in public spaces has created a demand for systems that can track individuals across multiple cameras feeds in real-time. While existing tracking systems have achieved impressive performance using deep learning models, they often rely on pre-existing images of suspects or historical data. However, this is not always feasible in cases where suspicious individuals are identified in real-time and without prior knowledge. We propose a person-tracking system that combines correlation filters and Intersection Over Union (IOU) constraints for robust tracking, along with a deep learning model for cross-camera person re-identification (Re-ID) on top of YOLOv5. The proposed system quickly identifies and tracks suspect in real-time across multiple cameras and recovers well after full or partial occlusion, making it suitable for security and surveillance applications. It is computationally efficient and achieves a high F1-Score of 79% and an IOU of 59% comparable to existing state-of-the-art algorithms, as demonstrated in our evaluation on a publicly available OTB-100 dataset. The proposed system offers a robust and efficient solution for the real-time tracking of individuals across multiple camera feeds. Its ability to track targets without prior knowledge or historical data is a significant improvement over existing systems, making it well-suited for public safety and surveillance applications.
</details>
<details>
<summary>摘要</summary>
随着公共空间内部照相设备的增加，需要一种可以在多个摄像头视频流中实时跟踪人员的系统。现有的跟踪系统已经使用深度学习模型实现了出色的性能，但是它们常常依赖于先前的图像或历史数据。然而，这并不总是可行的，特别是在实时发现疑犯并无先知的情况下。我们提议一种结合相关滤波器和交叉区域大小（IOU）约束的人员跟踪系统，并在YOLOv5之上使用深度学习模型进行交叉摄像头人员重新识别（Re-ID）。提议的系统可以快速地在多个摄像头视频流中识别和跟踪疑犯，并在全或部分遮挡后快速恢复，适用于安全监控应用。它的计算效率高，并在OTB-100公共数据集上实现了79%的F1分数和59%的IOU分数，与现有状态的算法相当。提议的系统提供了一种实时、有效的人员跟踪解决方案，无需先知或历史数据，对公共安全和监控应用有 significannot improvement。
</details></li>
</ul>
<hr>
<h2 id="Cine-cardiac-MRI-reconstruction-using-a-convolutional-recurrent-network-with-refinement"><a href="#Cine-cardiac-MRI-reconstruction-using-a-convolutional-recurrent-network-with-refinement" class="headerlink" title="Cine cardiac MRI reconstruction using a convolutional recurrent network with refinement"></a>Cine cardiac MRI reconstruction using a convolutional recurrent network with refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13385">http://arxiv.org/abs/2309.13385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vios-s/CMRxRECON_Challenge_EDIPO">https://github.com/vios-s/CMRxRECON_Challenge_EDIPO</a></li>
<li>paper_authors: Yuyang Xue, Yuning Du, Gianluca Carloni, Eva Pachetti, Connor Jordan, Sotirios A. Tsaftaris</li>
<li>for: 心脏功能和状态的非侵入性理解</li>
<li>methods: 使用 convolutional recurrent neural network (CRNN) 构成和单影像超解析模组</li>
<li>results: 比基eline情况下提高4.4%的结构相似性和3.9%的normalized mean square error<details>
<summary>Abstract</summary>
Cine Magnetic Resonance Imaging (MRI) allows for understanding of the heart's function and condition in a non-invasive manner. Undersampling of the $k$-space is employed to reduce the scan duration, thus increasing patient comfort and reducing the risk of motion artefacts, at the cost of reduced image quality. In this challenge paper, we investigate the use of a convolutional recurrent neural network (CRNN) architecture to exploit temporal correlations in supervised cine cardiac MRI reconstruction. This is combined with a single-image super-resolution refinement module to improve single coil reconstruction by 4.4\% in structural similarity and 3.9\% in normalised mean square error compared to a plain CRNN implementation. We deploy a high-pass filter to our $\ell_1$ loss to allow greater emphasis on high-frequency details which are missing in the original data. The proposed model demonstrates considerable enhancements compared to the baseline case and holds promising potential for further improving cardiac MRI reconstruction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-Grids-Exploring-Elastic-Input-Sampling-for-Vision-Transformers"><a href="#Beyond-Grids-Exploring-Elastic-Input-Sampling-for-Vision-Transformers" class="headerlink" title="Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers"></a>Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13353">http://arxiv.org/abs/2309.13353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam Pardyl, Grzegorz Kurzejamski, Jan Olszewski, Tomasz Trzciński, Bartosz Zieliński</li>
<li>for: 该论文旨在提高视transformer在实际应用中的表现和效率，通过提高输入灵活性。</li>
<li>methods: 论文提出了一种用于评估视transformer输入灵活性的评价协议，并提出了对transformer架构和训练策略的修改，以增强其输入灵活性。</li>
<li>results: 经过广泛的实验，论文发现了输入 sampling 策略的机会和挑战，并提供了关于视transformer在不同应用场景中的表现。<details>
<summary>Abstract</summary>
Vision transformers have excelled in various computer vision tasks but mostly rely on rigid input sampling using a fixed-size grid of patches. This limits their applicability in real-world problems, such as in the field of robotics and UAVs, where one can utilize higher input elasticity to boost model performance and efficiency. Our paper addresses this limitation by formalizing the concept of input elasticity for vision transformers and introducing an evaluation protocol, including dedicated metrics for measuring input elasticity. Moreover, we propose modifications to the transformer architecture and training regime, which increase its elasticity. Through extensive experimentation, we spotlight opportunities and challenges associated with input sampling strategies.
</details>
<details>
<summary>摘要</summary>
< translating into Simplified Chinese...</SYS>视力变换器在计算机视觉任务中表现出色，但它们通常采用固定大小网格的粒子 sampling 来输入数据。这限制了它们在实际应用中，如 роботи克和无人机领域， где可以使用更高的输入灵活性来提高模型性能和效率。我们的论文解决了这个限制，正式表述了视力变换器的输入灵活性概念，并提出了评估协议，包括专门为测量输入灵活性的指标。此外，我们还提出了 transformer 架构和训练方法的修改，以增加其灵活性。通过广泛的实验，我们把关注到输入采样策略的机会和挑战。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FedDrive-v2-an-Analysis-of-the-Impact-of-Label-Skewness-in-Federated-Semantic-Segmentation-for-Autonomous-Driving"><a href="#FedDrive-v2-an-Analysis-of-the-Impact-of-Label-Skewness-in-Federated-Semantic-Segmentation-for-Autonomous-Driving" class="headerlink" title="FedDrive v2: an Analysis of the Impact of Label Skewness in Federated Semantic Segmentation for Autonomous Driving"></a>FedDrive v2: an Analysis of the Impact of Label Skewness in Federated Semantic Segmentation for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13336">http://arxiv.org/abs/2309.13336</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Erosinho13/FedDrive">https://github.com/Erosinho13/FedDrive</a></li>
<li>paper_authors: Eros Fanì, Marco Ciccone, Barbara Caputo</li>
<li>for: 研究 semantic segmentation 在自动驾驶中的 federated learning  benchmark 的分布式skewness 的影响。</li>
<li>methods: 提出了 six 种新的 federated 场景，以研究 label skewness 对 segmentation 模型的性能的影响，并与域shift 的影响进行比较。</li>
<li>results: 研究了使用域信息 durante testing 的影响。Here’s the English version for reference:</li>
<li>for: Investigating the impact of distribution skewness on semantic segmentation in autonomous driving using federated learning benchmarks.</li>
<li>methods: Propose six new federated scenarios to study the effect of label skewness on segmentation models and compare it with the effect of domain shift.</li>
<li>results: Study the impact of using domain information during testing.<details>
<summary>Abstract</summary>
We propose FedDrive v2, an extension of the Federated Learning benchmark for Semantic Segmentation in Autonomous Driving. While the first version aims at studying the effect of domain shift of the visual features across clients, in this work, we focus on the distribution skewness of the labels. We propose six new federated scenarios to investigate how label skewness affects the performance of segmentation models and compare it with the effect of domain shift. Finally, we study the impact of using the domain information during testing. Official website: https://feddrive.github.io
</details>
<details>
<summary>摘要</summary>
我们提出了FedDrive v2，它是基于联合学习benchmark для自动驾驶 semantic segmentation的扩展。在前一版中，我们研究了视觉特征之间客户端域转换的效果，而在这次工作中，我们专注于标签的分布偏度。我们提出了六种新的联合场景，以研究标签偏度对 segmentation 模型的性能影响，并与域转换的影响进行比较。最后，我们研究了在测试时使用域信息的影响。官方网站：https://feddrive.github.ioNote: "联合学习" (federated learning) in Chinese is usually translated as "联合学习" (federated learning), but in this context, I used "基于联合学习benchmark" (based on federated learning benchmark) to emphasize that FedDrive is an extension of a existing benchmark.
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Incomplete-Annotation-Issue-in-Universal-Lesion-Detection-Task-By-Exploratory-Training"><a href="#Tackling-the-Incomplete-Annotation-Issue-in-Universal-Lesion-Detection-Task-By-Exploratory-Training" class="headerlink" title="Tackling the Incomplete Annotation Issue in Universal Lesion Detection Task By Exploratory Training"></a>Tackling the Incomplete Annotation Issue in Universal Lesion Detection Task By Exploratory Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13306">http://arxiv.org/abs/2309.13306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Bai, Benteng Ma, Changyang Li, Yong Xia</li>
<li>for: 这种研究的目的是提高非特征化图像诊断的精度，尤其是检测医疗图像中的多种器官 lesion。</li>
<li>methods: 该研究使用了深度学习方法，并利用 pseudo-label 技术来挖掘未标注的对象。</li>
<li>results: 研究表明，提出的方法可以superior表现于现有的方法，在两个医疗图像 datasets 上。<details>
<summary>Abstract</summary>
Universal lesion detection has great value for clinical practice as it aims to detect various types of lesions in multiple organs on medical images. Deep learning methods have shown promising results, but demanding large volumes of annotated data for training. However, annotating medical images is costly and requires specialized knowledge. The diverse forms and contrasts of objects in medical images make fully annotation even more challenging, resulting in incomplete annotations. Directly training ULD detectors on such datasets can yield suboptimal results. Pseudo-label-based methods examine the training data and mine unlabelled objects for retraining, which have shown to be effective to tackle this issue. Presently, top-performing methods rely on a dynamic label-mining mechanism, operating at the mini-batch level. However, the model's performance varies at different iterations, leading to inconsistencies in the quality of the mined labels and limits their performance enhancement. Inspired by the observation that deep models learn concepts with increasing complexity, we introduce an innovative exploratory training to assess the reliability of mined lesions over time. Specifically, we introduce a teacher-student detection model as basis, where the teacher's predictions are combined with incomplete annotations to train the student. Additionally, we design a prediction bank to record high-confidence predictions. Each sample is trained several times, allowing us to get a sequence of records for each sample. If a prediction consistently appears in the record sequence, it is likely to be a true object, otherwise it may just a noise. This serves as a crucial criterion for selecting reliable mined lesions for retraining. Our experimental results substantiate that the proposed framework surpasses state-of-the-art methods on two medical image datasets, demonstrating its superior performance.
</details>
<details>
<summary>摘要</summary>
全面搜寻检测在医疗实践中具有极高的价值，旨在多种器官的医学图像上检测不同类型的损害。深度学习方法在检测中表现出了扎根的成绩，但需要大量已注解数据进行训练。然而，注解医学图像是成本高昂的，需要专业知识。医学图像中 объек的多样性和对比性使得全面注解变得更加困难，从而导致了不完全的注解。直接在如此数据上训练 ULD 检测器可能会得到不佳的结果。基于 pseudo-label 方法，我们可以在训练数据中挖掘未注解的对象，以便重新训练。目前，最高级的方法通过动态标签采集机制，在小批量级别进行操作。然而，模型在不同迭代中的性能会变化，导致标签采集过程中的品质不稳定，限制了性能提高的可能性。我们从深度学习模型学习对象的复杂性的观察中灵感，并提出了一种创新的探索训练方法。具体来说，我们在教师-学生检测模型的基础上，将教师的预测与不完全注解结合使用，用于训练学生。此外，我们还设计了预测银行，以记录高置信预测。每个样本都会在多次训练中得到多个记录，这些记录中的一些预测可能是真实的对象，而其他的预测可能只是噪音。这些记录可以作为选择可靠挖掘的标准。我们的实验结果表明，我们的方法在两个医学图像数据集上超过了当前state-of-the-art方法的性能，这证明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="C-2-VAE-Gaussian-Copula-based-VAE-Differing-Disentangled-from-Coupled-Representations-with-Contrastive-Posterior"><a href="#C-2-VAE-Gaussian-Copula-based-VAE-Differing-Disentangled-from-Coupled-Representations-with-Contrastive-Posterior" class="headerlink" title="C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior"></a>C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled Representations with Contrastive Posterior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13303">http://arxiv.org/abs/2309.13303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhangkai Wu, Longbing Cao</li>
<li>for: 学习分离的隐藏因素和相关的隐藏因素</li>
<li>methods: 使用自适应变换自动机（VAE）和循环优化</li>
<li>results: 提高分离表示学习的效果，并且解决了TC-基于VAE的不稳定性和表达和表示之间的负面效应<details>
<summary>Abstract</summary>
We present a self-supervised variational autoencoder (VAE) to jointly learn disentangled and dependent hidden factors and then enhance disentangled representation learning by a self-supervised classifier to eliminate coupled representations in a contrastive manner. To this end, a Contrastive Copula VAE (C$^2$VAE) is introduced without relying on prior knowledge about data in the probabilistic principle and involving strong modeling assumptions on the posterior in the neural architecture. C$^2$VAE simultaneously factorizes the posterior (evidence lower bound, ELBO) with total correlation (TC)-driven decomposition for learning factorized disentangled representations and extracts the dependencies between hidden features by a neural Gaussian copula for copula coupled representations. Then, a self-supervised contrastive classifier differentiates the disentangled representations from the coupled representations, where a contrastive loss regularizes this contrastive classification together with the TC loss for eliminating entangled factors and strengthening disentangled representations. C$^2$VAE demonstrates a strong effect in enhancing disentangled representation learning. C$^2$VAE further contributes to improved optimization addressing the TC-based VAE instability and the trade-off between reconstruction and representation.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自助学习的变分自动编码器（VAE），用于同时学习独立的隐藏因素和相关的隐藏因素。然后，我们使用一种自我超级vised类ifier来消除相关的表示，从而增强独立表示学习。为此，我们引入了一种叫做Contrastive Copula VAE（C$^2$VAE），不需要对数据的 probabilistic principle 进行严格的模型假设，同时可以学习分解 posterior（证明下界，ELBO）和总相关度（TC）驱动的分解，以学习独立的隐藏表示。然后，一种自我超级vised类ifier可以分辨出独立的表示和相关的表示，并通过对这两个类别进行对比来regular化这种对比分类。C$^2$VAE在提高独立表示学习的效果，同时也有助于改善优化，解决TC-基于VAE的不稳定性和表示重建之间的负面选择问题。
</details></li>
</ul>
<hr>
<h2 id="Gaining-the-Sparse-Rewards-by-Exploring-Binary-Lottery-Tickets-in-Spiking-Neural-Network"><a href="#Gaining-the-Sparse-Rewards-by-Exploring-Binary-Lottery-Tickets-in-Spiking-Neural-Network" class="headerlink" title="Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in Spiking Neural Network"></a>Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in Spiking Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13302">http://arxiv.org/abs/2309.13302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Cheng, Jiahang Cao, Erjia Xiao, Pu Zhao, Mengshu Sun, Jiaxu Wang, Jize Zhang, Xue Lin, Bhavya Kailkhura, Kaidi Xu, Renjing Xu</li>
<li>for: This paper aims to explore the efficiency of Spiking Neural Networks (SNNs) by investigating the existence of Lottery Tickets (LTs) in binary SNNs and comparing the spiking mechanism with simple model binarization.</li>
<li>methods: The paper proposes a sparse training method called Binary Weights Spiking Lottery Tickets (BinW-SLT) to find LTs in binary SNNs under different network structures.</li>
<li>results: The paper shows that BinW-SLT can achieve up to +5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary LTs, as well as achieve 1.86x and 8.92x energy saving compared with full-precision SNNs and ANNs.<details>
<summary>Abstract</summary>
Spiking Neural Network (SNN) as a brain-inspired strategy receives lots of attention because of the high-sparsity and low-power properties derived from its inherent spiking information state. To further improve the efficiency of SNN, some works declare that the Lottery Tickets (LTs) Hypothesis, which indicates that the Artificial Neural Network (ANN) contains a subnetwork without sacrificing the performance of the original network, also exists in SNN. However, the spiking information handled by SNN has a natural similarity and affinity with binarization in sparsification. Therefore, to further explore SNN efficiency, this paper focuses on (1) the presence or absence of LTs in the binary SNN, and (2) whether the spiking mechanism is a superior strategy in terms of handling binary information compared to simple model binarization. To certify these consumptions, a sparse training method is proposed to find Binary Weights Spiking Lottery Tickets (BinW-SLT) under different network structures. Through comprehensive evaluations, we show that BinW-SLT could attain up to +5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary LTs, as well as achieve 1.86x and 8.92x energy saving compared with full-precision SNN and ANN.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）因其自然的简约性和低功耗特性而受到了很多关注。一些研究表明，Artificial Neural Network（ANN）中的子网络也存在于SNN中，这被称为彩票假设（LTs）。然而，SNN处理的脉冲信息具有自然的相似性和亲和力，因此可以通过对binary化进行压缩来提高SNN的效率。为了进一步探索SNN的效率，本文主要研究了以下两个问题：（1）在二进制SNN中是否存在LTs，（2）脉冲机制是对binary信息处理的超越策略吗？为了证明这些消耗，我们提出了一种稀疏训练方法，可以在不同的网络结构下找到Binary Weights Spiking Lottery Tickets（BinW-SLT）。经过全面的评估，我们发现BinW-SLT可以在CIFAR-10和CIFAR-100上提高+5.86%和+3.17%，并且可以在full-precision SNN和ANN上实现1.86x和8.92x的能量减少。
</details></li>
</ul>
<hr>
<h2 id="MP-MVS-Multi-Scale-Windows-PatchMatch-and-Planar-Prior-Multi-View-Stereo"><a href="#MP-MVS-Multi-Scale-Windows-PatchMatch-and-Planar-Prior-Multi-View-Stereo" class="headerlink" title="MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo"></a>MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13294">http://arxiv.org/abs/2309.13294</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rongxuantan/mp-mvs">https://github.com/rongxuantan/mp-mvs</a></li>
<li>paper_authors: Rongxuan Tan, Qing Wang, Xueyan Wang, Chao Yan, Yang Sun, Youyang Feng</li>
<li>for: 提高多视图ステレオ（MVS）基于3D重建的准确性。</li>
<li>methods: 提出了一种可靠的多观察窗口PatchMatch（mPM），以获取无文本区域的可靠深度值。此外，我们还改进了现有的检查板样本方案，限制我们的样本到远距离区域，以提高空间卷积的效率，同时避免生成异常值。最后，我们引入并改进了平面假设辅助PatchMatch（ACMP），而不是依赖于光学一致性，我们利用多视图之间的几何一致信息选择可靠的三角形 vertices。</li>
<li>results: 我们的方法在ETH3D高分辨率多视图标准准测试集上与多个状态 искусственный智能方法进行比较，结果表明，我们的方法可以达到状态 искусственный智能水平。<details>
<summary>Abstract</summary>
Significant strides have been made in enhancing the accuracy of Multi-View Stereo (MVS)-based 3D reconstruction. However, untextured areas with unstable photometric consistency often remain incompletely reconstructed. In this paper, we propose a resilient and effective multi-view stereo approach (MP-MVS). We design a multi-scale windows PatchMatch (mPM) to obtain reliable depth of untextured areas. In contrast with other multi-scale approaches, which is faster and can be easily extended to PatchMatch-based MVS approaches. Subsequently, we improve the existing checkerboard sampling schemes by limiting our sampling to distant regions, which can effectively improve the efficiency of spatial propagation while mitigating outlier generation. Finally, we introduce and improve planar prior assisted PatchMatch of ACMP. Instead of relying on photometric consistency, we utilize geometric consistency information between multi-views to select reliable triangulated vertices. This strategy can obtain a more accurate planar prior model to rectify photometric consistency measurements. Our approach has been tested on the ETH3D High-res multi-view benchmark with several state-of-the-art approaches. The results demonstrate that our approach can reach the state-of-the-art. The associated codes will be accessible at https://github.com/RongxuanTan/MP-MVS.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified Chinese多视图ステレオ（MVS）ベースの3D复元において、精度が向上した进歩がありました。しかし、不安定な光学的一致性を持つ不染色领域がまだ不完全に复元されていることがあります。この论文では、抗强度的かつ效率的な多视点ステレオアプローチ（MP-MVS）を提案します。我々は、信赖性の高い深度を得るために、多スケールのウィンドウパッチマッチ（mPM）を设计しました。他の多スケールアプローチと异なり、我々のアプローチは速く、パッチマッチベースのMVSアプローチに容易に拡张できます。次に、我々は、离れた地域に限定されたサンプリングを行うことで、空间的な広がりを改善することができます。また、アウトライアーの生成を抑制することができます。最后に、我々は、写真的一致性を基准にしてパッチマッチをサポートする计画的な射影を提案します。このストラテジは、多视点间の几何学的一致性情报を利用して、信赖性の高い平面モデルを构筑することができます。我々のアプローチは、ETH3D High-res多视点ベンチマークで复数の现状最高のアプローチとの比较を行い、结果はstate-of-the-artに到达することを示しています。関连するコードは、https://github.com/RongxuanTan/MP-MVSにアクセスできます。
</details></li>
</ul>
<hr>
<h2 id="Domain-Guided-Conditional-Diffusion-Model-for-Unsupervised-Domain-Adaptation"><a href="#Domain-Guided-Conditional-Diffusion-Model-for-Unsupervised-Domain-Adaptation" class="headerlink" title="Domain-Guided Conditional Diffusion Model for Unsupervised Domain Adaptation"></a>Domain-Guided Conditional Diffusion Model for Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14360">http://arxiv.org/abs/2309.14360</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulong Zhang, Shuhao Chen, Weisen Jiang, Yu Zhang, Jiangang Lu, James T. Kwok</li>
<li>for: 提高深度学习模型在新应用场景中的性能，增强Unsupervised Domain Adaptation（UDA）技术的表现。</li>
<li>methods: 提出DomAin-guided Conditional Diffusion Model（DACDM），通过控制生成样本的标签信息和引入域类分类器，以生成高准确性和多样性的目标域样本，从而使得现有的UDA方法更容易在目标域上传输。</li>
<li>results: 经验表明，DACDM可以大幅提高现有UDA方法在多种标准权重环境下的表现。<details>
<summary>Abstract</summary>
Limited transferability hinders the performance of deep learning models when applied to new application scenarios. Recently, Unsupervised Domain Adaptation (UDA) has achieved significant progress in addressing this issue via learning domain-invariant features. However, the performance of existing UDA methods is constrained by the large domain shift and limited target domain data. To alleviate these issues, we propose DomAin-guided Conditional Diffusion Model (DACDM) to generate high-fidelity and diversity samples for the target domain. In the proposed DACDM, by introducing class information, the labels of generated samples can be controlled, and a domain classifier is further introduced in DACDM to guide the generated samples for the target domain. The generated samples help existing UDA methods transfer from the source domain to the target domain more easily, thus improving the transfer performance. Extensive experiments on various benchmarks demonstrate that DACDM brings a large improvement to the performance of existing UDA methods.
</details>
<details>
<summary>摘要</summary>
因深度学习模型在新应用场景中表现不佳的限制性，现在不监督领域适应（UDA）已经取得了显著的进步，通过学习领域共同特征来解决这一问题。然而，现有的 UDA 方法受到大领域差异和有限目标领域数据的限制。为了解决这些问题，我们提议了带有类信息的 DomAin-guided Conditional Diffusion Model (DACDM)，用于生成高准确性和多样性的目标领域样本。在我们的 DACDM 中，通过引入类信息，生成的样本的标签可以被控制，并在 DACDM 中引入了领域分类器，以便导引生成的样本到目标领域。这些生成的样本可以帮助现有的 UDA 方法更好地在源领域和目标领域之间传输，从而提高传输性能。我们在各种标准准点上进行了广泛的实验，并证明了 DACDM 可以大幅提高现有 UDA 方法的表现。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Reverse-Engineering-Creating-computer-aided-design-CAD-models-from-multi-view-images"><a href="#Automatic-Reverse-Engineering-Creating-computer-aided-design-CAD-models-from-multi-view-images" class="headerlink" title="Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images"></a>Automatic Reverse Engineering: Creating computer-aided design (CAD) models from multi-view images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13281">http://arxiv.org/abs/2309.13281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henrik Jobczyk, Hanno Homann</li>
<li>for: automated reverse engineering task</li>
<li>methods:  combine three distinct stages: convolutional neural network, multi-view pooling, and transformer-based CAD sequence generator</li>
<li>results: successfully reconstructed valid CAD models from simulated test image data, and demonstrated some capabilities in real-world test with actual photographs of three-dimensional test objects, but limited to basic shapes.<details>
<summary>Abstract</summary>
Generation of computer-aided design (CAD) models from multi-view images may be useful in many practical applications. To date, this problem is usually solved with an intermediate point-cloud reconstruction and involves manual work to create the final CAD models. In this contribution, we present a novel network for an automated reverse engineering task. Our network architecture combines three distinct stages: A convolutional neural network as the encoder stage, a multi-view pooling stage and a transformer-based CAD sequence generator.   The model is trained and evaluated on a large number of simulated input images and extensive optimization of model architectures and hyper-parameters is performed. A proof-of-concept is demonstrated by successfully reconstructing a number of valid CAD models from simulated test image data. Various accuracy metrics are calculated and compared to a state-of-the-art point-based network.   Finally, a real world test is conducted supplying the network with actual photographs of two three-dimensional test objects. It is shown that some of the capabilities of our network can be transferred to this domain, even though the training exclusively incorporates purely synthetic training data. However to date, the feasible model complexity is still limited to basic shapes.
</details>
<details>
<summary>摘要</summary>
计算机支持设计（CAD）模型生成从多视图图像可能在很多实际应用中有用。目前，这个问题通常通过中间点云重建解决，并且需要手动创建最终CAD模型。在这篇论文中，我们提出了一种新的网络，用于自动反工程设计任务。我们的网络架构包括三个不同的阶段：一个卷积神经网络作为编码阶段，一个多视图池化阶段，以及一个基于变换器的CAD序列生成器。我们在一大量的模拟输入图像和优化模型结构和超参数方面进行了训练和评估。我们成功地从模拟测试数据中生成了一些有效的CAD模型。我们还计算了几个精度指标，并与当前点 cloud 网络进行比较。最后，我们在实际测试中使用实际照片对两个三维测试对象进行测试，并证明了我们的网络部分可以在这个领域中转移。然而，目前可能的模型复杂度仍然受限于基本形状。
</details></li>
</ul>
<hr>
<h2 id="Discwise-Active-Learning-for-LiDAR-Semantic-Segmentation"><a href="#Discwise-Active-Learning-for-LiDAR-Semantic-Segmentation" class="headerlink" title="Discwise Active Learning for LiDAR Semantic Segmentation"></a>Discwise Active Learning for LiDAR Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13276">http://arxiv.org/abs/2309.13276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ozan Unal, Dengxin Dai, Ali Tamer Unal, Luc Van Gool</li>
<li>For: This paper explores the use of active learning (AL) for LiDAR semantic segmentation, with a focus on improving annotation efficiency and reducing costs.* Methods: The proposed method, called DiAL, uses a discwise approach to query the region covered by a single frame on global coordinates, and labels all frames simultaneously. It also addresses two major challenges in discwise AL: a new acquisition function that takes 3D point density changes into consideration, and a mixed-integer linear program to select multiple frames while avoiding disc intersections.* Results: The proposed method is evaluated on a real-world LiDAR dataset, and shows improved performance and efficiency compared to traditional sequential labeling methods. Additionally, a semi-supervised learning approach is proposed to utilize all frames within the dataset and further improve performance.<details>
<summary>Abstract</summary>
While LiDAR data acquisition is easy, labeling for semantic segmentation remains highly time consuming and must therefore be done selectively. Active learning (AL) provides a solution that can iteratively and intelligently label a dataset while retaining high performance and a low budget. In this work we explore AL for LiDAR semantic segmentation. As a human expert is a component of the pipeline, a practical framework must consider common labeling techniques such as sequential labeling that drastically improve annotation times. We therefore propose a discwise approach (DiAL), where in each iteration, we query the region a single frame covers on global coordinates, labeling all frames simultaneously. We then tackle the two major challenges that emerge with discwise AL. Firstly we devise a new acquisition function that takes 3D point density changes into consideration which arise due to location changes or ego-vehicle motion. Next we solve a mixed-integer linear program that provides a general solution to the selection of multiple frames while taking into consideration the possibilities of disc intersections. Finally we propose a semi-supervised learning approach to utilize all frames within our dataset and improve performance.
</details>
<details>
<summary>摘要</summary>
利用LiDAR数据获取 relativamente fácil，但是用于 semantic segmentation 的标注仍然非常时间consuming，因此需要选择性地进行标注。活动学习（AL）提供了一个解决方案，可以逐步地、智能地标注数据集，同时保持高性能和低预算。在这项工作中，我们探索了 LiDAR semantic segmentation 中的 AL。作为人类专家是数据流水线的一部分，我们需要考虑常见的标注技术，如顺序标注，以提高标注时间的效率。因此，我们提出了一种区域方法（DiAL），其中，在每次迭代中，我们查询当前帧所覆盖的全球坐标范围，并同时标注所有帧。然后，我们解决了两个主要的挑战，即：1. 根据Location changes 或者自动车动的影响，3D 点云 density 发生变化，我们提出了一种新的获取函数，以便考虑这些变化。2. 我们解决了板块交叠的问题，通过一种混合整数线性Programming 提供一个通用的解决方案，以便选择多帧的板块。3. 最后，我们提出了一种半supervised learning 方法，以利用整个数据集，并提高性能。
</details></li>
</ul>
<hr>
<h2 id="GLOBER-Coherent-Non-autoregressive-Video-Generation-via-GLOBal-Guided-Video-DecodER"><a href="#GLOBER-Coherent-Non-autoregressive-Video-Generation-via-GLOBal-Guided-Video-DecodER" class="headerlink" title="GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER"></a>GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13274">http://arxiv.org/abs/2309.13274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iva-mzsun/glober">https://github.com/iva-mzsun/glober</a></li>
<li>paper_authors: Mingzhen Sun, Weining Wang, Zihan Qin, Jiahui Sun, Sihan Chen, Jing Liu</li>
<li>for: 这个论文目的是提出一种新的非 autoregressive 视频生成方法，以提高视频生成的全局性和本地性。</li>
<li>methods: 该方法首先生成全局特征，以获取全面的全局指导，然后基于全局特征，通过非 autoregressive 的方式，生成具有全局性和本地性的视频帧。特别是，我们提出了一个视频自编码器，该自编码器将视频转换为全局特征，并建立了一个基于扩散模型的视频解码器，该解码器通过非 autoregressive 的方式，生成视频帧。</li>
<li>results: 我们的实验结果表明，我们的提出的方法可以具有高效率和高质量的视频生成。我们在多个 benchmark 上达到了新的州OF-THE-ART 结果。<details>
<summary>Abstract</summary>
Video generation necessitates both global coherence and local realism. This work presents a novel non-autoregressive method GLOBER, which first generates global features to obtain comprehensive global guidance and then synthesizes video frames based on the global features to generate coherent videos. Specifically, we propose a video auto-encoder, where a video encoder encodes videos into global features, and a video decoder, built on a diffusion model, decodes the global features and synthesizes video frames in a non-autoregressive manner. To achieve maximum flexibility, our video decoder perceives temporal information through normalized frame indexes, which enables it to synthesize arbitrary sub video clips with predetermined starting and ending frame indexes. Moreover, a novel adversarial loss is introduced to improve the global coherence and local realism between the synthesized video frames. Finally, we employ a diffusion-based video generator to fit the global features outputted by the video encoder for video generation. Extensive experimental results demonstrate the effectiveness and efficiency of our proposed method, and new state-of-the-art results have been achieved on multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
视频生成需要both全局一致性和地方现实性。这项工作提出了一种新的非 autoregressive方法GLOBER，它首先生成全局特征来获得全面的全局指导，然后根据全局特征来生成协调的视频帧，以生成一致的视频。具体来说，我们提出了一个视频自编码器，其中视频编码器将视频编码成全局特征，而视频解码器，基于扩散模型，将全局特征解码并在非 autoregressive 方式下synthesize视频帧。为了保证最大的灵活性，我们的视频解码器通过normalized帧索引来感知时间信息，这使其能够synthesize任意的子视频片段，并且通过引入novel adversarial loss来提高全局一致性和地方现实性 между生成的视频帧。最后，我们使用扩散基于的视频生成器来适应GLOBER输出的全局特征。我们的实验结果表明，我们的提出的方法效果和效率都非常高，并在多个标准准则上达到了新的状态码。
</details></li>
</ul>
<hr>
<h2 id="Randomize-to-Generalize-Domain-Randomization-for-Runway-FOD-Detection"><a href="#Randomize-to-Generalize-Domain-Randomization-for-Runway-FOD-Detection" class="headerlink" title="Randomize to Generalize: Domain Randomization for Runway FOD Detection"></a>Randomize to Generalize: Domain Randomization for Runway FOD Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13264">http://arxiv.org/abs/2309.13264</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Javaria Farooq, Nayyer Aafaq, M Khizer Ali Khan, Ammar Saleem, M Ibraheem Siddiqui<br>for:* The paper aims to improve object detection in low-resolution images with small objects and diverse backgrounds, which is challenging for existing methods.methods:* The proposed method, Synthetic Randomized Image Augmentation (SRIA), consists of two stages: weakly supervised pixel-level segmentation mask generation and batch-wise synthesis of artificial images with diverse augmentations.results:* The proposed method significantly improves object detection accuracy on out-of-distribution (OOD) test sets, with a reported improvement from 41% to 92%. The method also outperforms several state-of-the-art (SOTA) models, including CenterNet, SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit, on a publicly available foreign object debris (FOD) dataset.<details>
<summary>Abstract</summary>
Tiny Object Detection is challenging due to small size, low resolution, occlusion, background clutter, lighting conditions and small object-to-image ratio. Further, object detection methodologies often make underlying assumption that both training and testing data remain congruent. However, this presumption often leads to decline in performance when model is applied to out-of-domain(unseen) data. Techniques like synthetic image generation are employed to improve model performance by leveraging variations in input data. Such an approach typically presumes access to 3D-rendered datasets. In contrast, we propose a novel two-stage methodology Synthetic Randomized Image Augmentation (SRIA), carefully devised to enhance generalization capabilities of models encountering 2D datasets, particularly with lower resolution which is more practical in real-world scenarios. The first stage employs a weakly supervised technique to generate pixel-level segmentation masks. Subsequently, the second stage generates a batch-wise synthesis of artificial images, carefully designed with an array of diverse augmentations. The efficacy of proposed technique is illustrated on challenging foreign object debris (FOD) detection. We compare our results with several SOTA models including CenterNet, SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit on a publicly available FOD-A dataset. We also construct an out-of-distribution test set encompassing 800 annotated images featuring a corpus of ten common categories. Notably, by harnessing merely 1.81% of objects from source training data and amalgamating with 29 runway background images, we generate 2227 synthetic images. Subsequent model retraining via transfer learning, utilizing enriched dataset generated by domain randomization, demonstrates significant improvement in detection accuracy. We report that detection accuracy improved from an initial 41% to 92% for OOD test set.
</details>
<details>
<summary>摘要</summary>
小 объек detection 是一个挑战，主要由于小型、低分辨率、 occlusion、背景噪音、照明条件以及小对图像比率而导致。此外，检测方法ologies 经常假设训练和测试数据保持一致，但这种假设常导致模型在未经验数据上下运行时表现下降。为了改善模型性能，人们通常采用生成 Synthetic 图像的技术。然而，这些技术通常假设有许多3D-rendered 数据可供使用。在这种情况下，我们提出了一种新的两Stage 方法，即Synthetic Randomized Image Augmentation（SRIA），旨在提高模型在2D数据上的泛化能力。首先，我们使用弱有监督技术生成像素级分割标记。然后，第二stage 使用批量 Synthesis 技术生成一批人工生成的假图像，并且特意设计了一系列多样化的增强。我们证明了我们的方法在困难的外部物杂（FOD）检测 task 上表现出色。我们与多个state-of-the-art（SOTA）模型，包括CenterNet、SSD、YOLOv3、YOLOv4、YOLOv5和Outer Vit进行比较。我们还构建了一个异常数据集，包括800个标注图像，其中包含10种常见类别。吸引地，我们只需使用来源训练数据中的1.81%的对象，并将其混合到29个runway背景图像中，就可以生成2227个假图像。然后，通过将模型重新训练，使用了增强的频率 randomization 数据集，我们可以看到检测精度从41%提高到92%。
</details></li>
</ul>
<hr>
<h2 id="Order-preserving-Consistency-Regularization-for-Domain-Adaptation-and-Generalization"><a href="#Order-preserving-Consistency-Regularization-for-Domain-Adaptation-and-Generalization" class="headerlink" title="Order-preserving Consistency Regularization for Domain Adaptation and Generalization"></a>Order-preserving Consistency Regularization for Domain Adaptation and Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13258">http://arxiv.org/abs/2309.13258</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengmeng Jing, Xiantong Zhen, Jingjing Li, Cees Snoek</li>
<li>for: 提高cross-domain任务中深度学习模型的Robustness，使其不受特定领域属性的影响。</li>
<li>methods: 采用数据增强和一致规范来使模型更不敏感于特定领域属性。</li>
<li>results: 对五种不同的cross-domain任务进行了全面的实验，得到了明显的优势。<details>
<summary>Abstract</summary>
Deep learning models fail on cross-domain challenges if the model is oversensitive to domain-specific attributes, e.g., lightning, background, camera angle, etc. To alleviate this problem, data augmentation coupled with consistency regularization are commonly adopted to make the model less sensitive to domain-specific attributes. Consistency regularization enforces the model to output the same representation or prediction for two views of one image. These constraints, however, are either too strict or not order-preserving for the classification probabilities. In this work, we propose the Order-preserving Consistency Regularization (OCR) for cross-domain tasks. The order-preserving property for the prediction makes the model robust to task-irrelevant transformations. As a result, the model becomes less sensitive to the domain-specific attributes. The comprehensive experiments show that our method achieves clear advantages on five different cross-domain tasks.
</details>
<details>
<summary>摘要</summary>
深度学习模型在跨频道挑战中失败，因为模型过敏于频道特有的特征，如闪电、背景、摄像头角度等。为解决这问题，数据增强和一致化 regularization 是常用的方法，以使模型对频道特有的特征更不敏感。一致性 regularization 要求模型对两个视图的同一张图像输出相同的表示或预测结果。然而，这些约束 Either too strict or not order-preserving for the classification probabilities。在这工作中，我们提出了Order-preserving Consistency Regularization (OCR) 方法，该方法的顺序性质使模型对任务不相关的变换具有鲁棒性。因此，模型对频道特有的特征变得更不敏感。我们的方法在五个不同的跨频道任务中实现了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="RTrack-Accelerating-Convergence-for-Visual-Object-Tracking-via-Pseudo-Boxes-Exploration"><a href="#RTrack-Accelerating-Convergence-for-Visual-Object-Tracking-via-Pseudo-Boxes-Exploration" class="headerlink" title="RTrack: Accelerating Convergence for Visual Object Tracking via Pseudo-Boxes Exploration"></a>RTrack: Accelerating Convergence for Visual Object Tracking via Pseudo-Boxes Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13257">http://arxiv.org/abs/2309.13257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guotian Zeng, Bi Zeng, Hong Zhang, Jianqi Liu, Qingmao Wei</li>
<li>for: 提高单目标跟踪（SOT）的性能，减少训练时间并靠近对象检测（OD）任务</li>
<li>methods: 使用一组样本点来获取pseudo bounding box，自动调整这些点来定义空间范围和强调本地区域</li>
<li>results: 在GOT-10k数据集上实现了与状态革新（SOTA）跟踪器相同的性能，减少训练时间到前一代跟踪器的10%，将SOT更近于OD任务，并且在各种情况下展现了更快的转化速度。<details>
<summary>Abstract</summary>
Single object tracking (SOT) heavily relies on the representation of the target object as a bounding box. However, due to the potential deformation and rotation experienced by the tracked targets, the genuine bounding box fails to capture the appearance information explicitly and introduces cluttered background. This paper proposes RTrack, a novel object representation baseline tracker that utilizes a set of sample points to get a pseudo bounding box. RTrack automatically arranges these points to define the spatial extents and highlight local areas. Building upon the baseline, we conducted an in-depth exploration of the training potential and introduced a one-to-many leading assignment strategy. It is worth noting that our approach achieves competitive performance to the state-of-the-art trackers on the GOT-10k dataset while reducing training time to just 10% of the previous state-of-the-art (SOTA) trackers' training costs. The substantial reduction in training costs brings single-object tracking (SOT) closer to the object detection (OD) task. Extensive experiments demonstrate that our proposed RTrack achieves SOTA results with faster convergence.
</details>
<details>
<summary>摘要</summary>
单一目标追踪（SOT）仅靠目标物体的包围盒来表示，但由于追踪目标的潜在偏移和旋转，真正的包围盒将显示出目标物体的外观信息，却会受到背景噪声的影响。本文提出了一个新的物体表现基准追踪器（RTrack），利用一组Sample Points来取得伪包围盒。RTrack可自动安排这些点来定义空间扩展和突出地方。基于这个基准，我们进行了深入的训练潜力探索和引入了一个一对多领导分配策略。值得注意的是，我们的方法在GOT-10k dataset上与现有的State-of-the-art（SOTA）追踪器相比，具有竞争性的性能，同时降低训练时间至前一个SOTA追踪器的10%。这个重要的减少训练时间将单一目标追踪（SOT）与物体检测（OD）任务逐渐接近。广泛的实验显示了我们提出的RTrack具有SOTA结果，并且更快地趋向稳定。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Amodal-Video-Segmentation-from-Learning-Supervised-Signals-with-Object-centric-Representation"><a href="#Rethinking-Amodal-Video-Segmentation-from-Learning-Supervised-Signals-with-Object-centric-Representation" class="headerlink" title="Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation"></a>Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13248">http://arxiv.org/abs/2309.13248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kfan21/eoras">https://github.com/kfan21/eoras</a></li>
<li>paper_authors: Ke Fan, Jingshi Lei, Xuelin Qian, Miaopeng Yu, Tianjun Xiao, Tong He, Zheng Zhang, Yanwei Fu</li>
<li>for: 这个论文的目的是提出一种高效的物体抽象分割方法，用于视频模态分割 tasks。</li>
<li>methods: 该方法利用了自主学习的方式，并使用了对象центric表示，以便在实际场景中使用对象特征来优化特征质量。具体来说，该方法包括一个翻译模块，用于将图像特征 proyect 到鸟瞰视图（BEV）中，以获得3D信息；以及一个多视图协同层，用于在不同视图之间进行对话 Mechanism，以完善对象表示。</li>
<li>results: 实验结果表明，该方法可以在实际场景中实现高效的物体抽象分割，并且在多个synthetic和实际 benchmark中达到了领先的性能。<details>
<summary>Abstract</summary>
Video amodal segmentation is a particularly challenging task in computer vision, which requires to deduce the full shape of an object from the visible parts of it. Recently, some studies have achieved promising performance by using motion flow to integrate information across frames under a self-supervised setting. However, motion flow has a clear limitation by the two factors of moving cameras and object deformation. This paper presents a rethinking to previous works. We particularly leverage the supervised signals with object-centric representation in \textit{real-world scenarios}. The underlying idea is the supervision signal of the specific object and the features from different views can mutually benefit the deduction of the full mask in any specific frame. We thus propose an Efficient object-centric Representation amodal Segmentation (EoRaS). Specially, beyond solely relying on supervision signals, we design a translation module to project image features into the Bird's-Eye View (BEV), which introduces 3D information to improve current feature quality. Furthermore, we propose a multi-view fusion layer based temporal module which is equipped with a set of object slots and interacts with features from different views by attention mechanism to fulfill sufficient object representation completion. As a result, the full mask of the object can be decoded from image features updated by object slots. Extensive experiments on both real-world and synthetic benchmarks demonstrate the superiority of our proposed method, achieving state-of-the-art performance. Our code will be released at \url{https://github.com/kfan21/EoRaS}.
</details>
<details>
<summary>摘要</summary>
视频无模板分割是计算机视觉中特别具有挑战性的任务，需要从可见部分中推断物体的全部形状。最近几年，一些研究已经取得了一定的成果，通过在无监督的设置下使用运动流来集成帧中的信息。然而，运动流受到两个因素的限制：摄像机的移动和物体的变形。本文提出了对前一些研究的重新思考。我们特别利用实际场景中的监督信号和不同视图中的特征进行协同协调，以解决任意帧中的全面 маска推断。我们因此提出了一种高效的物体中心表示协调分割（EoRaS）方法。具体来说，我们不仅仅依靠监督信号，还设计了一种将图像特征投影到鸟瞰视（BEV）中的翻译模块，以此增加图像特征的3D信息。此外，我们提出了基于多视图的协同协调层，该层配备了一组物体槽，通过注意机制与不同视图中的特征进行互动，以便填充物体的完整表示。因此，从图像特征更新后的物体槽中可以解码出物体的全面 маска。广泛的实验表明，我们提出的方法在实际和Syntheticbenchmark上具有最高性能，达到了状态盘的表现。我们的代码将在\url{https://github.com/kfan21/EoRaS}上发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Domain-Adaptation-for-REG-via-Relation-Transfer"><a href="#Multi-modal-Domain-Adaptation-for-REG-via-Relation-Transfer" class="headerlink" title="Multi-modal Domain Adaptation for REG via Relation Transfer"></a>Multi-modal Domain Adaptation for REG via Relation Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13247">http://arxiv.org/abs/2309.13247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Ding, Liqiang Wang, Boqing Gong</li>
<li>for: 本文旨在提出一种 novel 的多模式知识转移方法，用于解决 Referring Expression Grounding (REG) 问题。</li>
<li>methods: 我们提出的方法利用特定的关系修饰，同时增强多模式间关系和多模式与另一个模式之间的转移关系，以提高多模式领域的转移性能。</li>
<li>results: 我们的方法在实验中显著提高了多模式领域的转移性能，并且在 REG 问题中显著提高了地区localization的准确率。<details>
<summary>Abstract</summary>
Domain adaptation, which aims to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.
</details>
<details>
<summary>摘要</summary>
域适应，targeting to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.Here's the translation in Traditional Chinese as well:域适应，targeting to transfer knowledge between domains, has been well studied in many areas such as image classification and object detection. However, for multi-modal tasks, conventional approaches rely on large-scale pre-training. But due to the difficulty of acquiring multi-modal data, large-scale pre-training is often impractical. Therefore, domain adaptation, which can efficiently utilize the knowledge from different datasets (domains), is crucial for multi-modal tasks. In this paper, we focus on the Referring Expression Grounding (REG) task, which is to localize an image region described by a natural language expression. Specifically, we propose a novel approach to effectively transfer multi-modal knowledge through a specially relation-tailored approach for the REG problem. Our approach tackles the multi-modal domain adaptation problem by simultaneously enriching inter-domain relations and transferring relations between domains. Experiments show that our proposed approach significantly improves the transferability of multi-modal domains and enhances adaptation performance in the REG problem.I hope this helps!
</details></li>
</ul>
<hr>
<h2 id="RBFormer-Improve-Adversarial-Robustness-of-Transformer-by-Robust-Bias"><a href="#RBFormer-Improve-Adversarial-Robustness-of-Transformer-by-Robust-Bias" class="headerlink" title="RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias"></a>RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13245">http://arxiv.org/abs/2309.13245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Cheng, Jinhao Duan, Hui Li, Lyutianyang Zhang, Jiahang Cao, Ping Wang, Jize Zhang, Kaidi Xu, Renjing Xu</li>
<li>for: 本研究旨在 investigate Transformer-based structure 的内在Robustness性能，而不是 introduce novel defense measures against adversarial attacks.</li>
<li>methods: 我们使用 rational structure design approach 来 mitigate the susceptibility to robustness issues, 具体来说是增加高频结构强度的偏好。</li>
<li>results: 我们的实验结果显示， compared to several existing baseline structures, RBFormer 表现出了 robust superiority, 在 CIFAR-10 和 ImageNet-1k 上的评价标准上减少了 +16.12% 和 +5.04%。<details>
<summary>Abstract</summary>
Recently, there has been a surge of interest and attention in Transformer-based structures, such as Vision Transformer (ViT) and Vision Multilayer Perceptron (VMLP). Compared with the previous convolution-based structures, the Transformer-based structure under investigation showcases a comparable or superior performance under its distinctive attention-based input token mixer strategy. Introducing adversarial examples as a robustness consideration has had a profound and detrimental impact on the performance of well-established convolution-based structures. This inherent vulnerability to adversarial attacks has also been demonstrated in Transformer-based structures. In this paper, our emphasis lies on investigating the intrinsic robustness of the structure rather than introducing novel defense measures against adversarial attacks. To address the susceptibility to robustness issues, we employ a rational structure design approach to mitigate such vulnerabilities. Specifically, we enhance the adversarial robustness of the structure by increasing the proportion of high-frequency structural robust biases. As a result, we introduce a novel structure called Robust Bias Transformer-based Structure (RBFormer) that shows robust superiority compared to several existing baseline structures. Through a series of extensive experiments, RBFormer outperforms the original structures by a significant margin, achieving an impressive improvement of +16.12% and +5.04% across different evaluation criteria on CIFAR-10 and ImageNet-1k, respectively.
</details>
<details>
<summary>摘要</summary>
近期，有一股关注和关注力在Transformer结构方面，如视觉转换器（ViT）和视觉多层感知器（VMLP）。与过去的卷积结构相比，Transformer结构在其特有的注意力基于输入token混合策略下显示了相当或更高的性能。在引入对抗示例作为Robustness考虑的情况下，已经证明了传统的卷积结构的内置敏感性。在这篇论文中，我们的注意点是研究Transformer结构的内置Robustness，而不是引入新的防御措施 против对抗攻击。为了解决敏感性问题，我们采用了合理的结构设计方法，增加高频结构Robust遗产偏好。因此，我们提出了一种新的结构，即Robust Bias Transformer-based Structure（RBFormer），它在不同评价标准下与多个基准结构进行比较，具有显著的超越性。通过一系列广泛的实验，RBFormer在CIFAR-10和ImageNet-1k上的表现都出色，与原始结构之间的提升为+16.12%和+5.04%。
</details></li>
</ul>
<hr>
<h2 id="NeRF-Enhanced-Outpainting-for-Faithful-Field-of-View-Extrapolation"><a href="#NeRF-Enhanced-Outpainting-for-Faithful-Field-of-View-Extrapolation" class="headerlink" title="NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation"></a>NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13240">http://arxiv.org/abs/2309.13240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Yu, Jiachen Liu, Zihan Zhou, Sharon X. Huang</li>
<li>for: 增强环境感知，如 робоット导航和远程视觉协助等应用场景中，扩大摄像头的视野范围有利于提高环境感知。</li>
<li>methods: 使用NeRF生成扩展视野图像，并使用这些图像培育场景特定的图像填充模型。</li>
<li>results: 对三个 fotorealistic 数据集和一个实际世界数据集进行了广泛的测试，并显示了方法的稳定性和潜力。<details>
<summary>Abstract</summary>
In various applications, such as robotic navigation and remote visual assistance, expanding the field of view (FOV) of the camera proves beneficial for enhancing environmental perception. Unlike image outpainting techniques aimed solely at generating aesthetically pleasing visuals, these applications demand an extended view that faithfully represents the scene. To achieve this, we formulate a new problem of faithful FOV extrapolation that utilizes a set of pre-captured images as prior knowledge of the scene. To address this problem, we present a simple yet effective solution called NeRF-Enhanced Outpainting (NEO) that uses extended-FOV images generated through NeRF to train a scene-specific image outpainting model. To assess the performance of NEO, we conduct comprehensive evaluations on three photorealistic datasets and one real-world dataset. Extensive experiments on the benchmark datasets showcase the robustness and potential of our method in addressing this challenge. We believe our work lays a strong foundation for future exploration within the research community.
</details>
<details>
<summary>摘要</summary>
在各种应用中，如 робоット导航和远程视觉协助，扩展相机的视场（FOV）有利于提高环境识别。不同于基于图像涂抹技术的艺术化视觉，这些应用需要一个扩展的视野，准确反映场景。为实现这一点，我们提出了一个新的 faithful FOV 拓展问题，利用场景中预 capture 的图像作为知识来培养场景特定的图像涂抹模型。为解决这个问题，我们提出了一种简单 yet effective 的解决方案called NeRF-Enhanced Outpainting（NEO），使用通过NeRF生成的扩展 FOV 图像来训练场景特定的图像涂抹模型。为评估 NEO 的性能，我们进行了三个实验室数据集和一个真实世界数据集的全面评估。广泛的实验表明我们的方法在解决这个挑战中具有强大的基础和潜力。我们认为我们的研究为未来研究社区提供了一个坚强的基础。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Knowledge-Embedded-Transformer-for-Video-Scene-Graph-Generation"><a href="#Spatial-Temporal-Knowledge-Embedded-Transformer-for-Video-Scene-Graph-Generation" class="headerlink" title="Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation"></a>Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13237">http://arxiv.org/abs/2309.13237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hcplab-sysu/stket">https://github.com/hcplab-sysu/stket</a></li>
<li>paper_authors: Tao Pu, Tianshui Chen, Hefeng Wu, Yongyi Lu, Liang Lin</li>
<li>for:  VidSGG aims to identify objects in visual scenes and infer their relationships for a given video.</li>
<li>methods:  The proposed method, STKET, incorporates prior spatial-temporal knowledge into the multi-head cross-attention mechanism to learn more representative relationship representations.</li>
<li>results:  STKET outperforms current competing algorithms by a large margin, with improvements of 8.1%, 4.7%, and 2.1% on different settings.<details>
<summary>Abstract</summary>
Video scene graph generation (VidSGG) aims to identify objects in visual scenes and infer their relationships for a given video. It requires not only a comprehensive understanding of each object scattered on the whole scene but also a deep dive into their temporal motions and interactions. Inherently, object pairs and their relationships enjoy spatial co-occurrence correlations within each image and temporal consistency/transition correlations across different images, which can serve as prior knowledge to facilitate VidSGG model learning and inference. In this work, we propose a spatial-temporal knowledge-embedded transformer (STKET) that incorporates the prior spatial-temporal knowledge into the multi-head cross-attention mechanism to learn more representative relationship representations. Specifically, we first learn spatial co-occurrence and temporal transition correlations in a statistical manner. Then, we design spatial and temporal knowledge-embedded layers that introduce the multi-head cross-attention mechanism to fully explore the interaction between visual representation and the knowledge to generate spatial- and temporal-embedded representations, respectively. Finally, we aggregate these representations for each subject-object pair to predict the final semantic labels and their relationships. Extensive experiments show that STKET outperforms current competing algorithms by a large margin, e.g., improving the mR@50 by 8.1%, 4.7%, and 2.1% on different settings over current algorithms.
</details>
<details>
<summary>摘要</summary>
视频场景图生成（VidSGG）目标是从视频中标识对象并推断它们之间的关系。这需要不仅对整个场景中每个对象进行全面的理解，还需要深入研究它们的时间变化和互动。自然地，对象对的关系具有在每个图像中的空间相互关联和在不同图像之间的时间相关性，这些知识可以用来促进VidSGG模型的学习和推断。在这种工作中，我们提出了一种具有空间-时间知识嵌入的变换器（STKET），它将在多头交叉关注机制中嵌入先前学习的空间-时间知识，以学习更加表示关系的表示。具体来说，我们首先在统计方面学习空间共occurrence和时间转换关系。然后，我们设计了空间和时间知识嵌入层，以全面地探索视觉表示和知识之间的交互，生成空间-时间嵌入表示。最后，我们对每个主体-对象对进行综合这些表示，以预测最终的semantic标签和其关系。广泛的实验显示，STKET在不同设置下比现有竞争算法大幅提高了性能，例如在不同设置下提高mR@50的表现，比如提高8.1%, 4.7%和2.1%。
</details></li>
</ul>
<hr>
<h2 id="M-3-CS-Multi-Target-Masked-Point-Modeling-with-Learnable-Codebook-and-Siamese-Decoders"><a href="#M-3-CS-Multi-Target-Masked-Point-Modeling-with-Learnable-Codebook-and-Siamese-Decoders" class="headerlink" title="M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders"></a>M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and Siamese Decoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13235">http://arxiv.org/abs/2309.13235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qibo Qiu, Honghui Yang, Wenxiao Wang, Shun Zhang, Haiming Gao, Haochao Ying, Wei Hua, Xiaofei He</li>
<li>for: 本研究旨在提高点云自助预训练的表现，使模型具备低级和高级表示能力，捕捉点云的几何细节和 semantic上下文。</li>
<li>methods: 该方法使用 masked point cloud 作为输入，并引入两个解码器同时预测masked表示和原始点 cloud。在解码过程中，我们提出了 siamese decoder 技术，以保持学习参数的数量不变。此外，我们还提出了在线 codebook 技术，将连续的 tokens 映射到精确的 discrete tokens。</li>
<li>results: 实验结果显示，M$^3$CS 在类别和分割任务中表现出色，与现有方法进行比较，具有更高的表现。<details>
<summary>Abstract</summary>
Masked point modeling has become a promising scheme of self-supervised pre-training for point clouds. Existing methods reconstruct either the original points or related features as the objective of pre-training. However, considering the diversity of downstream tasks, it is necessary for the model to have both low- and high-level representation modeling capabilities to capture geometric details and semantic contexts during pre-training. To this end, M$^3$CS is proposed to enable the model with the above abilities. Specifically, with masked point cloud as input, M$^3$CS introduces two decoders to predict masked representations and the original points simultaneously. While an extra decoder doubles parameters for the decoding process and may lead to overfitting, we propose siamese decoders to keep the amount of learnable parameters unchanged. Further, we propose an online codebook projecting continuous tokens into discrete ones before reconstructing masked points. In such way, we can enforce the decoder to take effect through the combinations of tokens rather than remembering each token. Comprehensive experiments show that M$^3$CS achieves superior performance at both classification and segmentation tasks, outperforming existing methods.
</details>
<details>
<summary>摘要</summary>
受隐藏点模型的推广使得自我超视了点云的预训练 scheme 成为了可靠的方法。现有的方法都是在预训练中重建原始点或相关的特征作为目标。然而，考虑到下游任务的多样性，需要模型具备低层和高层表示模型化能力，以 Capture point clouds的几何细节和 semantics during pre-training。为此，我们提出了M$^3$CS。具体来说，输入隐藏点云后，M$^3$CS引入了两个解码器同时预测隐藏表示和原始点。虽然增加了一个解码器会增加参数的数量，可能导致过拟合，但我们提出了同源的解码器，以保持参数的数量不变。此外，我们还提出了在线代码库，将连续的 токен proyect 为离散的 токен。这样可以让解码器通过Token的组合来实现效果，而不是记忆每个Token。我们的实验表明，M$^3$CS在类别和分割任务中表现出色，超过了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Real3D-AD-A-Dataset-of-Point-Cloud-Anomaly-Detection"><a href="#Real3D-AD-A-Dataset-of-Point-Cloud-Anomaly-Detection" class="headerlink" title="Real3D-AD: A Dataset of Point Cloud Anomaly Detection"></a>Real3D-AD: A Dataset of Point Cloud Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13226">http://arxiv.org/abs/2309.13226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m-3lab/real3d-ad">https://github.com/m-3lab/real3d-ad</a></li>
<li>paper_authors: Jiaqi Liu, Guoyang Xie, Ruitao Chen, Xinpeng Li, Jinbao Wang, Yong Liu, Chengjie Wang, Feng Zheng</li>
<li>for: 高精度点云异常检测是精密制造和机器制造领域中的标准，用于检测机器制造过程中的缺陷。</li>
<li>methods: 我们提出了一种基于准备的3D异常检测方法，named Reg3D-AD，该方法包括一种新的特征记忆银行，可以保持本地和全局表示。</li>
<li>results: 我们在Real3D-AD dataset上进行了广泛的实验，并证明了Reg3D-AD的效果。Real3D-AD dataset是目前最大的高精度3D工业异常检测dataset，它包括1,254个高分辨率3D项，每个item有40,000到百万个点。<details>
<summary>Abstract</summary>
High-precision point cloud anomaly detection is the gold standard for identifying the defects of advancing machining and precision manufacturing. Despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items from forty thousand to millions of points for each item, Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), 360 degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To address this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our website:https://github.com/M-3LAB/Real3D-AD.
</details>
<details>
<summary>摘要</summary>
高精度点云异常检测是现代加工和精密制造中的标准。 despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items from forty thousand to millions of points for each item, Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), 360 degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To address this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our website:https://github.com/M-3LAB/Real3D-AD.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese scripts used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.CV_2023_09_23/" data-id="clp9qz84700k3ok88d3jbfzkm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.AI_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T12:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.AI_2023_09_23/">cs.AI - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Student-Performance-Prediction-on-Learnersourced-Questions-with-SGNN-LLM-Synergy"><a href="#Enhancing-Student-Performance-Prediction-on-Learnersourced-Questions-with-SGNN-LLM-Synergy" class="headerlink" title="Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy"></a>Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13500">http://arxiv.org/abs/2309.13500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Ni, Sijie Wang, Zeyu Zhang, Xiaoxuan Li, Xianda Zheng, Paul Denny, Jiamou Liu</li>
<li>for: 这篇论文旨在提出一种新的学习战略——learnersourcing，并且解决学生发表问题时因为内在的噪声而难以预测学生表现的问题。</li>
<li>methods: 本文使用了签名双方 Graph Neural Networks (SGNNs) 和 Large Language Model (LLM) 的整合策略，实现了学生答案的全面模型化，并且使用了对照学习框架，增强了噪声抗性。</li>
<li>results: 本文针对五个真实世界的数据集，进行验证，结果显示了本方法的优越性，包括提高预测精度和类型抗性。<details>
<summary>Abstract</summary>
As an emerging education strategy, learnersourcing offers the potential for personalized learning content creation, but also grapples with the challenge of predicting student performance due to inherent noise in student-generated data. While graph-based methods excel in capturing dense learner-question interactions, they falter in cold start scenarios, characterized by limited interactions, as seen when questions lack substantial learner responses. In response, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially advantageous in addressing cold start scenarios characterized by limited graph data interactions. Validation across five real-world datasets sourced from the PeerWise platform underscores our approach's effectiveness. Our method outperforms baselines, showcasing enhanced predictive accuracy and robustness.
</details>
<details>
<summary>摘要</summary>
如一种出现的教育战略，学习者来源（learnersourcing）具有个性化学习内容创建的潜力，但同时也面临学生表现预测的挑战，因为学生自然生成的数据中含有噪声。Graph基的方法在学生-问题互动密集的情况下表现出色，但在冷启动场景下， caracterized by limited interactions, graph data interactions are limited. In response, we propose an innovative strategy that combines Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology uses a signed bipartite graph to comprehensively model student answers, and a contrastive learning framework that enhances noise resilience. Additionally, LLM's contribution lies in generating foundational question embeddings, which is especially advantageous in addressing cold start scenarios with limited graph data interactions. Our approach is validated across five real-world datasets sourced from the PeerWise platform, and outperforms baselines, demonstrating enhanced predictive accuracy and robustness.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Prediction-and-Analysis-of-UK-Road-Traffic-Accident-Severity-Using-AI-Integration-of-Machine-Learning-Econometric-Techniques-and-Time-Series-Forecasting-in-Public-Health-Research"><a href="#Enhancing-Prediction-and-Analysis-of-UK-Road-Traffic-Accident-Severity-Using-AI-Integration-of-Machine-Learning-Econometric-Techniques-and-Time-Series-Forecasting-in-Public-Health-Research" class="headerlink" title="Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research"></a>Enhancing Prediction and Analysis of UK Road Traffic Accident Severity Using AI: Integration of Machine Learning, Econometric Techniques, and Time Series Forecasting in Public Health Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13483">http://arxiv.org/abs/2309.13483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Abu Sufian, Jayasree Varadarajan</li>
<li>for: 本研究旨在 investigate 英国道路交通事故严重程度，使用机器学习、 econometric 和统计方法处理历史数据。</li>
<li>methods: 我们使用了各种技术，包括相关分析、回归模型、GMM 处理错误项、时间序列预测VAR 和 ARIMA 模型。</li>
<li>results: 我们的方法比预测方法出perform better，MASE 0.800 和 ME -73.80。我们还建立了一个Random Forest 分类器，具有 73% 精度、78% 回归率和 73% F1-score。使用 H2O AutoML 优化后，我们获得了 XGBoost 模型，RMSE 0.176 和 MAE 0.087。因素分析确定了关键变量，并使用 SHAP 为 Explainable AI， highlighting 关键因素如 Driver_Home_Area_Type 和 Road_Type。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
This research investigates road traffic accident severity in the UK, using a combination of machine learning, econometric, and statistical methods on historical data. We employed various techniques, including correlation analysis, regression models, GMM for error term issues, and time-series forecasting with VAR and ARIMA models. Our approach outperforms naive forecasting with an MASE of 0.800 and ME of -73.80. We also built a random forest classifier with 73% precision, 78% recall, and a 73% F1-score. Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for Explainable AI, highlighting influential factors like Driver_Home_Area_Type and Road_Type. Our study enhances understanding of accident severity and offers insights for evidence-based road safety policies.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "machine learning" Machine Learning* "econometric"  econometric* "statistical"  statistical* "historical data" 历史数据* "correlation analysis" 相关分析* "regression models" 回归模型* "GMM" Generalized Method of Moments (GMM)* "error term issues" 错误项问题* "time-series forecasting" 时间序列预测* "VAR" VAR (Vector Autoregression)* "ARIMA"  ARIMA (AutoRegressive Integrated Moving Average)* "naive forecasting" 简单预测* "MASE"  Mean Absolute Scaled Error (MASE)* "ME"  Mean Error (ME)* "random forest classifier" 随机森林分类器* "H2O AutoML"  H2O AutoML (Automated Machine Learning)* "XGBoost"  XGBoost (eXtreme Gradient Boosting)* "Factor Analysis" 因素分析* "SHAP"  SHAP (SHapley Additive exPlanations)* "Explainable AI" 可解释AI
</details></li>
</ul>
<hr>
<h2 id="Personalised-and-Adjustable-Interval-Type-2-Fuzzy-Based-PPG-Quality-Assessment-for-the-Edge"><a href="#Personalised-and-Adjustable-Interval-Type-2-Fuzzy-Based-PPG-Quality-Assessment-for-the-Edge" class="headerlink" title="Personalised and Adjustable Interval Type-2 Fuzzy-Based PPG Quality Assessment for the Edge"></a>Personalised and Adjustable Interval Type-2 Fuzzy-Based PPG Quality Assessment for the Edge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13464">http://arxiv.org/abs/2309.13464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jose A. Miranda, Celia López-Ongil, Javier Andreu-Perez</li>
<li>for: 这篇论文主要是为了提出一种基于Interval Type-2 Fuzzy Logic System (IT2FLS)的个性化和可调PPG信号质量评估方法，以提高PPG信号处理的准确性和可靠性。</li>
<li>methods: 该方法使用了个性化的IT2FLS参数来适应每个个体PPG信号的特点，同时提供可调的个性化水平，让医疗提供者可以根据不同应用场景进行调整。</li>
<li>results: 实验结果显示，提出的方法可以达到93.72%的准确率，表明该方法可以实现高效、实时的PPG信号质量评估，并提高PPG信号处理系统的准确性和可靠性。<details>
<summary>Abstract</summary>
Most of today's wearable technology provides seamless cardiac activity monitoring. Specifically, the vast majority employ Photoplethysmography (PPG) sensors to acquire blood volume pulse information, which is further analysed to extract useful and physiologically related features. Nevertheless, PPG-based signal reliability presents different challenges that strongly affect such data processing. This is mainly related to the fact of PPG morphological wave distortion due to motion artefacts, which can lead to erroneous interpretation of the extracted cardiac-related features. On this basis, in this paper, we propose a novel personalised and adjustable Interval Type-2 Fuzzy Logic System (IT2FLS) for assessing the quality of PPG signals. The proposed system employs a personalised approach to adapt the IT2FLS parameters to the unique characteristics of each individual's PPG signals.Additionally, the system provides adjustable levels of personalisation, allowing healthcare providers to adjust the system to meet specific requirements for different applications. The proposed system obtained up to 93.72\% for average accuracy during validation. The presented system has the potential to enable ultra-low complexity and real-time PPG quality assessment, improving the accuracy and reliability of PPG-based health monitoring systems at the edge.
</details>
<details>
<summary>摘要</summary>
Therefore, in this paper, we propose a novel personalized and adjustable Interval Type-2 Fuzzy Logic System (IT2FLS) for assessing the quality of PPG signals. The proposed system employs a personalized approach to adapt the IT2FLS parameters to the unique characteristics of each individual's PPG signals. Additionally, the system provides adjustable levels of personalization, allowing healthcare providers to adjust the system to meet specific requirements for different applications.The proposed system obtained up to 93.72% for average accuracy during validation. The presented system has the potential to enable ultra-low complexity and real-time PPG quality assessment, improving the accuracy and reliability of PPG-based health monitoring systems at the edge.
</details></li>
</ul>
<hr>
<h2 id="A-Model-Agnostic-Graph-Neural-Network-for-Integrating-Local-and-Global-Information"><a href="#A-Model-Agnostic-Graph-Neural-Network-for-Integrating-Local-and-Global-Information" class="headerlink" title="A Model-Agnostic Graph Neural Network for Integrating Local and Global Information"></a>A Model-Agnostic Graph Neural Network for Integrating Local and Global Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13459">http://arxiv.org/abs/2309.13459</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhuo Zhou, Annie Qu, Keiland W. Cooper, Norbert Fortin, Babak Shahbaba</li>
<li>for: 提高图像任务的解释性和可解释性，以及提高图像任务的表现。</li>
<li>methods: 提出了一种新的模型独立图像神经网络（MaGNet）框架，可以逐渐融合不同阶次的信息，提取高阶几何结构中的知识，并提供可解释的结果。</li>
<li>results: 在 simulate 数据上进行了广泛的数值研究，并在一个真实世界的案例中对 brain activity 数据进行了应用，以确认 MaGNet 的效果。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its power to represent layer-wise neighborhood mixing. We conduct comprehensive numerical studies using simulated data to demonstrate the superior performance of MaGNet in comparison to several state-of-the-art alternatives. Furthermore, we apply MaGNet to a real-world case study aimed at extracting task-critical information from brain activity data, thereby highlighting its effectiveness in advancing scientific research.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 已经在各种图像任务中表现出色。 despite their success, existing GNNs 受到两个重要的限制：一是不能解释结果的黑盒特性，二是无法学习不同级别的表示。 为了解决这些问题，我们提出了一种新的Model-agnostic Graph Neural Network（MaGNet）框架，可以逐渐 интегриate不同级别的信息，提取高阶邻居的知识，并提供可靠和可解释的结果，通过标识重要的紧凑图结构。 具体来说，MaGNet 由两个组成部分：一个用于复杂关系的隐藏表示估计模型，和一个用于标识重要节点、边和节点特征的解释模型。 我们通过对Empirical Rademacher complexity的总化误差 bound来证明MaGNet 的总化误差 bound，并表明其可以具有层次混合的 neigh权。 我们在使用 simulated data 进行了广泛的数值研究，并证明 MaGNet 在与多种状态前的替代方案相比之下表现出优异性。 此外，我们使用 MaGNet 对 brain activity data 进行了实际应用，以验证其在科研中的效果。
</details></li>
</ul>
<hr>
<h2 id="EMGTFNet-Fuzzy-Vision-Transformer-to-decode-Upperlimb-sEMG-signals-for-Hand-Gestures-Recognition"><a href="#EMGTFNet-Fuzzy-Vision-Transformer-to-decode-Upperlimb-sEMG-signals-for-Hand-Gestures-Recognition" class="headerlink" title="EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for Hand Gestures Recognition"></a>EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for Hand Gestures Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03754">http://arxiv.org/abs/2310.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Cherre Córdova, Christian Flores, Javier Andreu-Perez</li>
<li>for: 这个论文是为了研究用于手势识别（HGR）的电Myoelectric控制而写的。</li>
<li>methods: 这篇论文使用机器学习和深度学习方法进行模式识别，并使用视Transformer（ViT）架构和粗糙神经块（FNB）组成EMGTFNet模型来实现手势识别。</li>
<li>results: 该模型可以准确地识别多种手势动作，而无需使用数据扩展技术、传输学习或增加网络参数的数量。实验结果显示，对于NinaPro数据集中的49种手势动作，测试准确率为83.57%和3.5%，使用200 ms窗口大小和56,793个可变参数。这些结果超越了不含FNB的ViT模型，因此证明了包含FNB可以提高其性能。<details>
<summary>Abstract</summary>
Myoelectric control is an area of electromyography of increasing interest nowadays, particularly in applications such as Hand Gesture Recognition (HGR) for bionic prostheses. Today's focus is on pattern recognition using Machine Learning and, more recently, Deep Learning methods. Despite achieving good results on sparse sEMG signals, the latter models typically require large datasets and training times. Furthermore, due to the nature of stochastic sEMG signals, traditional models fail to generalize samples for atypical or noisy values. In this paper, we propose the design of a Vision Transformer (ViT) based architecture with a Fuzzy Neural Block (FNB) called EMGTFNet to perform Hand Gesture Recognition from surface electromyography (sEMG) signals. The proposed EMGTFNet architecture can accurately classify a variety of hand gestures without any need for data augmentation techniques, transfer learning or a significant increase in the number of parameters in the network. The accuracy of the proposed model is tested using the publicly available NinaPro database consisting of 49 different hand gestures. Experiments yield an average test accuracy of 83.57\% \& 3.5\% using a 200 ms window size and only 56,793 trainable parameters. Our results outperform the ViT without FNB, thus demonstrating that including FNB improves its performance. Our proposal framework EMGTFNet reported the significant potential for its practical application for prosthetic control.
</details>
<details>
<summary>摘要</summary>
“我的电动控制是一个增加电omyography的兴趣领域，特别是在应用中有手势识别（HGR）的这些复义肢。今天的重点是使用机器学习和更深入的深度学习方法来进行模式识别。尽管可以取得好的结果，但这些模型通常需要大量的数据和训练时间。此外，由于随机的sEMG信号的性质，传统的模型无法扩展过去的样本，以致无法处理异常或噪音的值。在这篇文章中，我们提出了基于视觉 трансформа器（ViT）架构的EMGTFNet，以进行手势识别从表面电omyography（sEMG）信号。我们的提案的EMGTFNet架构可以将多种手势识别为无需增加资料增强技术、传统学习或网络中的参数数量。我们的实验结果显示，EMGTFNet可以高度精确地分类49种不同的手势，而且不需要增加训练数据或增加网络中的参数数量。我们的结果比ViT无FNB更好，这证明了包含FNB可以提高其表现。我们的建议框架EMGTFNet具有实际应用于复义控制的潜在性。”
</details></li>
</ul>
<hr>
<h2 id="AxOMaP-Designing-FPGA-based-Approximate-Arithmetic-Operators-using-Mathematical-Programming"><a href="#AxOMaP-Designing-FPGA-based-Approximate-Arithmetic-Operators-using-Mathematical-Programming" class="headerlink" title="AxOMaP: Designing FPGA-based Approximate Arithmetic Operators using Mathematical Programming"></a>AxOMaP: Designing FPGA-based Approximate Arithmetic Operators using Mathematical Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13445">http://arxiv.org/abs/2309.13445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siva Satyendra Sahoo, Salim Ullah, Akash Kumar</li>
<li>for: 本研究旨在设计低成本计算机算符 для遥感系统中的机器学习（ML）算法。</li>
<li>methods: 本研究使用了人工智能&#x2F;机器学习（AI&#x2F;ML）基于的方法来设计FPGA基于的伪函数。</li>
<li>results: 相比传统的进化算法基于优化方法，本研究使用了混合整数二次函数 constrained programs来实现更有向性的搜索，并提高了精度和性能。<details>
<summary>Abstract</summary>
With the increasing application of machine learning (ML) algorithms in embedded systems, there is a rising necessity to design low-cost computer arithmetic for these resource-constrained systems. As a result, emerging models of computation, such as approximate and stochastic computing, that leverage the inherent error-resilience of such algorithms are being actively explored for implementing ML inference on resource-constrained systems. Approximate computing (AxC) aims to provide disproportionate gains in the power, performance, and area (PPA) of an application by allowing some level of reduction in its behavioral accuracy (BEHAV). Using approximate operators (AxOs) for computer arithmetic forms one of the more prevalent methods of implementing AxC. AxOs provide the additional scope for finer granularity of optimization, compared to only precision scaling of computer arithmetic. To this end, designing platform-specific and cost-efficient approximate operators forms an important research goal. Recently, multiple works have reported using AI/ML-based approaches for synthesizing novel FPGA-based AxOs. However, most of such works limit usage of AI/ML to designing ML-based surrogate functions used during iterative optimization processes. To this end, we propose a novel data analysis-driven mathematical programming-based approach to synthesizing approximate operators for FPGAs. Specifically, we formulate mixed integer quadratically constrained programs based on the results of correlation analysis of the characterization data and use the solutions to enable a more directed search approach for evolutionary optimization algorithms. Compared to traditional evolutionary algorithms-based optimization, we report up to 21% improvement in the hypervolume, for joint optimization of PPA and BEHAV, in the design of signed 8-bit multipliers.
</details>
<details>
<summary>摘要</summary>
随着机器学习（ML）算法在嵌入式系统中的应用逐渐增加，需要设计低成本的计算机器 arithmetic 来支持这些资源受限的系统。为此，人们正在活跃探讨新的计算模型，如 aproximate 和 Stochastic computing，以利用 ML 算法的内置错误抗性来实现 ML 推理。approximate computing（AxC）目标是提供不均匀的 PPA 提升，而不是仅仅是精度的减少。使用 approximate 操作符（AxOs）来实现计算机器 arithmetic 是其中一种常见的方法。AxOs 提供了更高的优化精度，相比于仅仅是精度的缩放。为此，设计Platform-specific 和 cost-efficient approximate 操作符成为了一项重要的研究目标。最近，多种文献报道了使用 AI/ML 方法来 sinthez FPGA 基于 AxOs。然而，大多数这些工作都是限制使用 AI/ML 来设计 ML 基于 surrogate 函数，用于 iterative 优化过程中。因此，我们提出了一种数据分析驱动的数学编程方法来 sinthez approximate 操作符。 Specifically，我们使用权重分析结果来构建混合整数quadratically constrained 程序，并使用这些解决方案来实现更 direkt 的搜索方法。与传统的进化算法基于优化相比，我们报道了在设计 signed 8-bit 乘数器时，对 PPA 和 BEHAV 的共同优化中的21%提高。
</details></li>
</ul>
<hr>
<h2 id="How-Do-Drivers-Behave-at-Roundabouts-in-a-Mixed-Traffic-A-Case-Study-Using-Machine-Learning"><a href="#How-Do-Drivers-Behave-at-Roundabouts-in-a-Mixed-Traffic-A-Case-Study-Using-Machine-Learning" class="headerlink" title="How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study Using Machine Learning"></a>How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study Using Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13442">http://arxiv.org/abs/2309.13442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farah Abu Hamad, Rama Hasiba, Deema Shahwan, Huthaifa I. Ashqar</li>
<li>for: 这个研究旨在分类车手在环形巷与其他路用者之间的交互行为，以提高路面安全性。</li>
<li>methods: 使用数据驱动的无监督机器学习分类车手行为，使用车辆动力学数据，分为三种驾驶模式（保守、正常、强制）。</li>
<li>results: 研究发现，大多数车手在环形巷上的行为可以分为两种驾驶模式：保守和正常，因为环形巷的交通速度较低。此外，发现当车手与行人或自行车使用者互动时，大约77%的车手被分类为保守驾驶者，对于不参与互动的保守驾驶者而言，只有42%。这些结果显示车手在环形巷与其他路用者互动时可能会发生不寻常的行为，增加了交通碰撞的风险。<details>
<summary>Abstract</summary>
Driving behavior is considered a unique driving habit of each driver and has a significant impact on road safety. Classifying driving behavior and introducing policies based on the results can reduce the severity of crashes on the road. Roundabouts are particularly interesting because of the interconnected interaction between different road users at the area of roundabouts, which different driving behavior is hypothesized. This study investigates driving behavior at roundabouts in a mixed traffic environment using a data-driven unsupervised machine learning to classify driving behavior at three roundabouts in Germany. We used a dataset of vehicle kinematics to a group of different vehicles and vulnerable road users (VRUs) at roundabouts and classified them into three categories (i.e., conservative, normal, and aggressive). Results showed that most of the drivers proceeding through a roundabout can be mostly classified into two driving styles: conservative and normal because traffic speeds in roundabouts are relatively lower than in other signalized and unsignalized intersections. Results also showed that about 77% of drivers who interacted with pedestrians or cyclists were classified as conservative drivers compared to about 42% of conservative drivers that did not interact or about 51% from all drivers. It seems that drivers tend to behave abnormally as they interact with VRUs at roundabouts, which increases the risk of crashes when an intersection is multimodal. Results of this study could be helpful in improving the safety of roads by allowing policymakers to determine the effective and suitable safety countermeasures. Results will also be beneficial for the Advanced Driver Assistance System (ADAS) as the technology is being deployed in a mixed traffic environment.
</details>
<details>
<summary>摘要</summary>
驾驶行为被视为每位驾驶员的特有驾驶习惯，对路面安全有着重要影响。根据不同驾驶行为分类并采取相应政策可以减轻路面上的事故严重程度。圆形交叉口特别有趣，因为不同的驾驶行为在圆形交叉口的交叉点发生了互相关联的互动。本研究使用数据驱动无监督机器学习方法在德国三个圆形交叉口中分类驾驶行为。我们使用了车辆动态数据来分类不同的车辆和护理用路用户（VRU）在圆形交叉口中的驾驶行为，并将其分为三类（即保守、常规和强制）。结果显示，大多数通过圆形交叉口的驾驶员可以分为两种驾驶风格：保守和常规，因为圆形交叉口的交通速度相对较低。结果还显示，与步行者或自行车用户互动的77%的驾驶员被分类为保守驾驶员，与不与步行者或自行车用户互动的42%的保守驾驶员相比。这表明在多模式交叉口中，驾驶员在与VRU互动时有异常的行为，这会增加路面上的风险。本研究的结果可以帮助政策制定者确定有效和适当的安全防范措施。此外，这些结果还将有助于高等技术应用系统（ADAS）在混合交通环境中部署。
</details></li>
</ul>
<hr>
<h2 id="Finding-Order-in-Chaos-A-Novel-Data-Augmentation-Method-for-Time-Series-in-Contrastive-Learning"><a href="#Finding-Order-in-Chaos-A-Novel-Data-Augmentation-Method-for-Time-Series-in-Contrastive-Learning" class="headerlink" title="Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning"></a>Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13439">http://arxiv.org/abs/2309.13439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eth-siplab/Finding_Order_in_Chaos">https://github.com/eth-siplab/Finding_Order_in_Chaos</a></li>
<li>paper_authors: Berken Utku Demirel, Christian Holz</li>
<li>for: 这 paper 的目的是提出一种新的数据增强方法，用于 quasi-periodic 时间序列任务，以连接内类样本并找到隐藏空间中的顺序。</li>
<li>methods: 该方法基于 mixup 技术，并提出了一种新的方法，考虑非站ARY 时间序列的周期性。通过控制数据增强的混杂程度，该方法可以提高下游任务的表达特征和性能。</li>
<li>results: 对于三个时间序列任务（心率估算、人类活动识别和心血管疾病检测），该方法与州前工作相比，表现出了更好的数据生成和知道数据增强技术。<details>
<summary>Abstract</summary>
The success of contrastive learning is well known to be dependent on data augmentation. Although the degree of data augmentations has been well controlled by utilizing pre-defined techniques in some domains like vision, time-series data augmentation is less explored and remains a challenging problem due to the complexity of the data generation mechanism, such as the intricate mechanism involved in the cardiovascular system. Moreover, there is no widely recognized and general time-series augmentation method that can be applied across different tasks. In this paper, we propose a novel data augmentation method for quasi-periodic time-series tasks that aims to connect intra-class samples together, and thereby find order in the latent space. Our method builds upon the well-known mixup technique by incorporating a novel approach that accounts for the periodic nature of non-stationary time-series. Also, by controlling the degree of chaos created by data augmentation, our method leads to improved feature representations and performance on downstream tasks. We evaluate our proposed method on three time-series tasks, including heart rate estimation, human activity recognition, and cardiovascular disease detection. Extensive experiments against state-of-the-art methods show that the proposed approach outperforms prior works on optimal data generation and known data augmentation techniques in the three tasks, reflecting the effectiveness of the presented method. Source code: https://github.com/eth-siplab/Finding_Order_in_Chaos
</details>
<details>
<summary>摘要</summary>
成功的对比学习几乎总是受到数据增强的影响。虽然在某些领域如视觉领域中，数据增强的度已经很好地控制了，但时间序列数据增强仍然是一个挑战，因为时间序列数据生成机制的复杂性，如心血管系统的内部机制。此外，没有一种广泛认可和可适用于不同任务的时间序列数据增强方法。在这篇论文中，我们提出了一种新的时间序列数据增强方法，旨在连接同类样本 вместе，从而在隐藏空间找到顺序。我们的方法基于已知的mixup技术，并添加了一种新的方法，考虑非站ARY时间序列的周期性。此外，我们可控制数据增强中创造的混乱程度，从而获得改进的特征表示和下游任务的性能。我们在三个时间序列任务中进行了广泛的实验，包括心率估计、人员活动识别和冠状疾病检测。对比于现有的最佳数据生成和知道数据增强技术，我们的方法表现出色，反映了提出的方法的效iveness。源代码：https://github.com/eth-siplab/Finding_Order_in_Chaos
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Superpixel-Segmentation-from-Biologically-Inspired-Mechanisms"><a href="#Rethinking-Superpixel-Segmentation-from-Biologically-Inspired-Mechanisms" class="headerlink" title="Rethinking Superpixel Segmentation from Biologically Inspired Mechanisms"></a>Rethinking Superpixel Segmentation from Biologically Inspired Mechanisms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13438">http://arxiv.org/abs/2309.13438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingyu Zhao, Bo Peng, Yuan Sun, Daipeng Yang, Zhenguang Zhang, Xi Wu<br>for: 这个论文主要针对的是提高深度学习基于超像分割方法的效率和性能，但是在生成严格遵循物体边界的超像时，仍然存在一定的挑战。methods: 我们提出了一种基于生物网络架构的超像分割方法，包括增强检查模块（ESM）和新的边界意识标签（BAL）。ESM通过模拟视觉系统中的交互投影机制来增强semantic信息。BAL利用视觉 cortical cells的空间频率特点来促进生成强边界遵循的超像。results: 我们通过对BSDS500 dataset和NYUv2 dataset进行评估，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Recently, advancements in deep learning-based superpixel segmentation methods have brought about improvements in both the efficiency and the performance of segmentation. However, a significant challenge remains in generating superpixels that strictly adhere to object boundaries while conveying rich visual significance, especially when cross-surface color correlations may interfere with objects. Drawing inspiration from neural structure and visual mechanisms, we propose a biological network architecture comprising an Enhanced Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel segmentation. The ESM enhances semantic information by simulating the interactive projection mechanisms of the visual cortex. Additionally, the BAL emulates the spatial frequency characteristics of visual cortical cells to facilitate the generation of superpixels with strong boundary adherence. We demonstrate the effectiveness of our approach through evaluations on both the BSDS500 dataset and the NYUv2 dataset.
</details>
<details>
<summary>摘要</summary>
近些年，深度学习基于超像素分割方法的进步，使得分割效率和性能得到了改善。然而，仍然存在一大挑战，即生成严格遵循物体边界的超像素，同时捕捉富有视觉意义的信息，特别是当颜色相关性障碍物体时。 drawing inspiration from neural structure and visual mechanisms, we propose a biological network architecture consisting of an Enhanced Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel segmentation. The ESM enhances semantic information by simulating the interactive projection mechanisms of the visual cortex. Additionally, the BAL emulates the spatial frequency characteristics of visual cortical cells to facilitate the generation of superpixels with strong boundary adherence. We demonstrate the effectiveness of our approach through evaluations on both the BSDS500 dataset and the NYUv2 dataset.
</details></li>
</ul>
<hr>
<h2 id="SpeakEasy-A-Conversational-Intelligence-Chatbot-for-Enhancing-College-Students’-Communication-Skills"><a href="#SpeakEasy-A-Conversational-Intelligence-Chatbot-for-Enhancing-College-Students’-Communication-Skills" class="headerlink" title="SpeakEasy: A Conversational Intelligence Chatbot for Enhancing College Students’ Communication Skills"></a>SpeakEasy: A Conversational Intelligence Chatbot for Enhancing College Students’ Communication Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.14891">http://arxiv.org/abs/2310.14891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunbae Jeon, Rhea Ramachandran, Victoria Ploerer, Yella Diekmann, Max Bagga<br>for: The paper aims to help college students improve their communication skills through a chatbot that provides feedback on their conversational ability.methods: The chatbot, called SpeakEasy, uses a seven-minute spoken conversation with the user, analyzes the user’s responses with metrics based on previous research, and provides feedback on how to improve conversational ability.results: SpeakEasy evaluates the quality of the conversation using macros and provides elaborate feedback to the user on how to improve their conversations. The chatbot also updates its algorithms based on the user’s responses to questions about its performance.<details>
<summary>Abstract</summary>
Social interactions and conversation skills separate the successful from the rest and the confident from the shy. For college students in particular, the ability to converse can be an outlet for the stress and anxiety experienced on a daily basis along with a foundation for all-important career skills. In light of this, we designed SpeakEasy: a chatbot with some degree of intelligence that provides feedback to the user on their ability to engage in free-form conversations with the chatbot. SpeakEasy attempts to help college students improve their communication skills by engaging in a seven-minute spoken conversation with the user, analyzing the user's responses with metrics designed based on previous psychology and linguistics research, and providing feedback to the user on how they can improve their conversational ability. To simulate natural conversation, SpeakEasy converses with the user on a wide assortment of topics that two people meeting for the first time might discuss: travel, sports, and entertainment. Unlike most other chatbots with the goal of improving conversation skills, SpeakEasy actually records the user speaking, transcribes the audio into tokens, and uses macros-e.g., sequences that calculate the pace of speech, determine if the user has an over-reliance on certain words, and identifies awkward transitions-to evaluate the quality of the conversation. Based on the evaluation, SpeakEasy provides elaborate feedback on how the user can improve their conversations. In turn, SpeakEasy updates its algorithms based on a series of questions that the user responds to regarding SpeakEasy's performance.
</details>
<details>
<summary>摘要</summary>
社交交流和对话技巧对成功和自信心是非常重要的，尤其是 для大学生。在日常生活中受到压力和焦虑的情况下，与其他人交流可以是一种缓解压力的方式，同时也是职业技能的基础。为了帮助大学生提高communication skills，我们开发了SpeakEasy：一个具有一定程度的人工智能的chatbot，可以与用户进行7分钟的自由对话，并提供用户在对话中的表现评价。SpeakEasy使用了基于前期心理学和语言学研究的度量来评估用户的对话能力，并提供了用户如何改进对话技巧的具体反馈。与其他帮助提高对话技巧的chatbot不同，SpeakEasy实际记录用户的语音，将语音转录为符号，并使用抽象来评估对话质量。SpeakEasy使用的抽象包括语速度、用户语言使用情况和对话过渡的awkwardness等。基于这些评估结果，SpeakEasy提供了详细的反馈， помо助用户改进对话技巧。而SpeakEasy的算法则基于用户对SpeakEasy的表现进行评价的问题来进行更新。
</details></li>
</ul>
<hr>
<h2 id="Resolving-References-in-Visually-Grounded-Dialogue-via-Text-Generation"><a href="#Resolving-References-in-Visually-Grounded-Dialogue-via-Text-Generation" class="headerlink" title="Resolving References in Visually-Grounded Dialogue via Text Generation"></a>Resolving References in Visually-Grounded Dialogue via Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13430">http://arxiv.org/abs/2309.13430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/willemsenbram/reference-resolution-via-text-generation">https://github.com/willemsenbram/reference-resolution-via-text-generation</a></li>
<li>paper_authors: Bram Willemsen, Livia Qian, Gabriel Skantze</li>
<li>for: 用于解决基于对话语言的视觉引用解决方案，提高视觉语言模型（VLM）的对话处理能力。</li>
<li>methods: 使用修改的大语言模型（LLM）生成定语描述，捕捉对话语言上的核心相关信息；使用预训练的VLM来基于生成的定语描述进行零基本训练引用识别。</li>
<li>results: 在人工标注的视觉对话数据集上测试，与基eline比较的result exceeds，并发现使用更大的上下文窗口可以获得更高的返回率。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.
</details>
<details>
<summary>摘要</summary>
传感语言模型（VLM）在基于简单文本查询的图像检索方面表现出色，但基于对话输入的文本-图像检索仍然是一个挑战。因此，如果我们想使用VLM进行视觉定位对话，那么这些模型的语言处理能力需要进行增强。为解决这个问题，我们提议通过细化大语言模型（LLM）来生成定语描述，捕捉在语言上下文中的核心相关信息。然后，我们使用预训练的VLM来根据生成的描述来确定参照，无需训练。我们对手动标注的视觉定位对话集进行评估，并超越比较基线的性能。此外，我们发现使用基于更大上下文窗口的定语描述有可能带来更高的返回。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Student-Performance-in-Game-Based-Learning-Environments"><a href="#Modeling-Student-Performance-in-Game-Based-Learning-Environments" class="headerlink" title="Modeling Student Performance in Game-Based Learning Environments"></a>Modeling Student Performance in Game-Based Learning Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13429">http://arxiv.org/abs/2309.13429</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harryjeon24/student_performance">https://github.com/harryjeon24/student_performance</a></li>
<li>paper_authors: Hyunbae Jeon, Harry He, Anthony Wang, Susanna Spooner</li>
<li>for: 这项研究探讨了基于游戏学习的教育游戏”Jo Wilder和首都案例”，关注使用不同机器学习模型预测学生表现，包括K-最近邻居（KNN）、多层感知神经网络（MLP）和随机森林。研究目标是确定预测学生表现和正确问题答案的最有价值特征。</li>
<li>methods: 通过利用游戏数据，我们建立了完整的基准chmarks для这些模型，并探讨了如何应用正确的数据聚合方法。我们压缩了原始训练数据的大小从4.6 GB压缩到48 MB的预处理训练数据，保持了高F1分数和准确率。</li>
<li>results: 我们的发现表明，适当的预处理技术可以在不使用深度学习模型的情况下提高表现。MLP模型在French Touch模型当前状态的比较中表现出色，达到F-1分数0.83和准确率0.74，这表明其适用于这个数据集。未来的研究应该探索使用更大的数据集、其他预处理技术、更先进的深度学习技术和实际应用来为学生根据预测表现提供个性化学习建议。这项研究贡献于游戏学习理解和优化教育游戏经验，以提高学生的成绩和技能发展。<details>
<summary>Abstract</summary>
This study investigates game-based learning in the context of the educational game "Jo Wilder and the Capitol Case," focusing on predicting student performance using various machine learning models, including K-Nearest Neighbors (KNN), Multi-Layer Perceptron (MLP), and Random Forest. The research aims to identify the features most predictive of student performance and correct question answering. By leveraging gameplay data, we establish complete benchmarks for these models and explore the importance of applying proper data aggregation methods. By compressing all numeric data to min/max/mean/sum and categorical data to first, last, count, and nunique, we reduced the size of the original training data from 4.6 GB to 48 MB of preprocessed training data, maintaining high F1 scores and accuracy.   Our findings suggest that proper preprocessing techniques can be vital in enhancing the performance of non-deep-learning-based models. The MLP model outperformed the current state-of-the-art French Touch model, achieving an F-1 score of 0.83 and an accuracy of 0.74, suggesting its suitability for this dataset. Future research should explore using larger datasets, other preprocessing techniques, more advanced deep learning techniques, and real-world applications to provide personalized learning recommendations to students based on their predicted performance. This paper contributes to the understanding of game-based learning and provides insights into optimizing educational game experiences for improved student outcomes and skill development.
</details>
<details>
<summary>摘要</summary>
We preprocessed the original training data by compressing all numeric data to min/max/mean/sum and categorical data to first, last, count, and nunique, reducing the data size from 4.6 GB to 48 MB while maintaining high F1 scores and accuracy. Our findings suggest that proper preprocessing techniques can significantly enhance the performance of non-deep-learning-based models.The MLP model outperformed the current state-of-the-art French Touch model, achieving an F-1 score of 0.83 and an accuracy of 0.74, suggesting its suitability for this dataset. Future research should explore using larger datasets, other preprocessing techniques, more advanced deep learning techniques, and real-world applications to provide personalized learning recommendations to students based on their predicted performance.This study contributes to the understanding of game-based learning and provides insights into optimizing educational game experiences for improved student outcomes and skill development.
</details></li>
</ul>
<hr>
<h2 id="ECGNet-A-generative-adversarial-network-GAN-approach-to-the-synthesis-of-12-lead-ECG-signals-from-single-lead-inputs"><a href="#ECGNet-A-generative-adversarial-network-GAN-approach-to-the-synthesis-of-12-lead-ECG-signals-from-single-lead-inputs" class="headerlink" title="ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs"></a>ECGNet: A generative adversarial network (GAN) approach to the synthesis of 12-lead ECG signals from single lead inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03753">http://arxiv.org/abs/2310.03753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Bagga, Hyunbae Jeon, Alex Issokson</li>
<li>for: 这个论文的目的是生成完整的12导电cardiogram信号，并使用GAN模型来实现这一目标。</li>
<li>methods: 这个论文使用了GAN模型，bidirectional LSTM生成器和CNN抗对模型来生成12导电cardiogram信号。</li>
<li>results: 该模型可以很好地保留信号中的特有特征，例如P-Q段和R峰的特征，并且可以预测多种心血管疾病的发生。<details>
<summary>Abstract</summary>
Electrocardiography (ECG) signal generation has been heavily explored using generative adversarial networks (GAN) because the implementation of 12-lead ECGs is not always feasible. The GAN models have achieved remarkable results in reproducing ECG signals but are only designed for multiple lead inputs and the features the GAN model preserves have not been identified-limiting the generated signals use in cardiovascular disease (CVD)-predictive models. This paper presents ECGNet which is a procedure that generates a complete set of 12-lead ECG signals from any single lead input using a GAN framework with a bidirectional long short-term memory (LSTM) generator and a convolutional neural network (CNN) discriminator. Cross and auto-correlation analysis performed on the generated signals identifies features conserved during the signal generation-i.e., features that can characterize the unique-nature of each signal and thus likely indicators of CVD. Finally, by using ECG signals annotated with the CVD-indicative features detailed by the correlation analysis as inputs for a CVD-onset-predictive CNN model, we overcome challenges preventing the prediction of multiple-CVD targets. Our models are experimented on 15s 12-lead ECG dataset recorded using MyoVista's wavECG. Functional outcome data for each patient is recorded and used in the CVD-predictive model. Our best GAN model achieves state-of-the-art accuracy with Frechet Distance (FD) scores of 4.73, 4.89, 5.18, 4.77, 4.71, and 5.55 on the V1-V6 pre-cordial leads respectively and shows strength in preserving the P-Q segments and R-peaks in the generated signals. To the best of our knowledge, ECGNet is the first to predict all of the remaining eleven leads from the input of any single lead.
</details>
<details>
<summary>摘要</summary>
电rokardiography（ECG）信号生成已经得到了广泛的探索，使用生成对抗网络（GAN），因为实施12导ECG的实施不一定可行。GAN模型已经实现了对ECG信号的很好的重现，但是它们只是多导输入的，而且保留的特征没有得到了识别-这限制了生成的信号在冠军疾病预测中的使用。本文提出了ECGNet，一种可以从单个导入信号中生成完整的12导ECG信号的GAN框架，包括一个双向长短期记忆（LSTM）生成器和一个卷积神经网络（CNN）分类器。在生成的信号中进行了交叉和自相关分析，并识别了保留的特征-即可以Characterize每个信号的独特性，因此可能是冠军疾病的指标。最后，我们使用了标注了CVD指标的ECG信号作为输入，并使用了一个CVD发生预测的CNN模型，解决了由于多个CVD目标的预测而产生的挑战。我们对15秒12导ECG数据集进行了实验，该数据集使用MyoVista的wavECG记录。每个患者的功能结果数据都被记录，并用于CVD发生预测模型。我们的最佳GAN模型在V1-V6前心导电位上获得了state-of-the-art的准确率，FD分数分别为4.73、4.89、5.18、4.77、4.71和5.55，并且表现出了保持P-Q段和R-peak的强大能力。而且，根据我们知道，ECGNet是第一个可以从任何单个导入信号中预测所有的11导ECG信号。
</details></li>
</ul>
<hr>
<h2 id="A-Chat-About-Boring-Problems-Studying-GPT-based-text-normalization"><a href="#A-Chat-About-Boring-Problems-Studying-GPT-based-text-normalization" class="headerlink" title="A Chat About Boring Problems: Studying GPT-based text normalization"></a>A Chat About Boring Problems: Studying GPT-based text normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13426">http://arxiv.org/abs/2309.13426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Zhang, Travis M. Bartley, Mariana Graterol-Fuenmayor, Vitaly Lavrukhin, Evelina Bakhturina, Boris Ginsburg</li>
<li>for: 本研究旨在探讨语言模型是否可以有效地进行文本normalization，并提出了一种新的文本normalizationtask设计方法。</li>
<li>methods: 本研究使用了大型语言模型（LLM），结合自我一致性理解和语言知识引入的提问工程，以实践文本normalization的可行性。</li>
<li>results: 研究发现，使用LLM进行文本normalization可以在几个shotenario下实现错误率大约40%下降，而且通过分析错误原因，发现了传统文本normalization任务的一些限制。<details>
<summary>Abstract</summary>
Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Penalties-and-Rewards-for-Fair-Learning-in-Paired-Kidney-Exchange-Programs"><a href="#Penalties-and-Rewards-for-Fair-Learning-in-Paired-Kidney-Exchange-Programs" class="headerlink" title="Penalties and Rewards for Fair Learning in Paired Kidney Exchange Programs"></a>Penalties and Rewards for Fair Learning in Paired Kidney Exchange Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13421">http://arxiv.org/abs/2309.13421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Margarida Carvalho, Alison Caulfield, Yi Lin, Adrian Vetta</li>
<li>for: 这个论文旨在探讨了一种动态交换和分配机制，以提高生产力探讨机制的性能。</li>
<li>methods: 该论文使用了学习算法，以在动态模拟中学习优化患者-捐献者权重，以提高结果。</li>
<li>results: 研究发现，在加拿大生产力探讨计划中，使用学习算法可以提高平均等待时间、增加移植数量和提高群体公平。具体来说，最高表现的学习算法可以提高群体公平性 by 10%，同时增加移植数量 by 6%和降低等待时间 by 24%。但研究的核心结果却是，在提高生产力探讨计划的性能方面，不是将积极分配给患者-捐献者对的正面权重，而是通过对少量非指定捐献者的负面权重分配来实现。<details>
<summary>Abstract</summary>
A kidney exchange program, also called a kidney paired donation program, can be viewed as a repeated, dynamic trading and allocation mechanism. This suggests that a dynamic algorithm for transplant exchange selection may have superior performance in comparison to the repeated use of a static algorithm. We confirm this hypothesis using a full scale simulation of the Canadian Kidney Paired Donation Program: learning algorithms, that attempt to learn optimal patient-donor weights in advance via dynamic simulations, do lead to improved outcomes. Specifically, our learning algorithms, designed with the objective of fairness (that is, equity in terms of transplant accessibility across cPRA groups), also lead to an increased number of transplants and shorter average waiting times. Indeed, our highest performing learning algorithm improves egalitarian fairness by 10% whilst also increasing the number of transplants by 6% and decreasing waiting times by 24%. However, our main result is much more surprising. We find that the most critical factor in determining the performance of a kidney exchange program is not the judicious assignment of positive weights (rewards) to patient-donor pairs. Rather, the key factor in increasing the number of transplants, decreasing waiting times and improving group fairness is the judicious assignment of a negative weight (penalty) to the small number of non-directed donors in the kidney exchange program.
</details>
<details>
<summary>摘要</summary>
一个肾移植计划，也称为肾对肾移植计划，可以看作是一种循环、动态的交易和分配机制。这表明使用动态算法进行移植交易选择可能会有更高的性能。我们确认这一假设使用加拿大肾对肾移植计划的全规模模拟：学习算法，尝试通过动态模拟来学习患者-捐精对的优质量因子，实际上会导致改进的结果。Specifically, our learning algorithms, designed with the objective of fairness (that is, equity in terms of transplant accessibility across cPRA groups), also lead to an increased number of transplants and shorter average waiting times. Indeed, our highest performing learning algorithm improves egalitarian fairness by 10% whilst also increasing the number of transplants by 6% and decreasing waiting times by 24%. However, our main result is much more surprising. We find that the most critical factor in determining the performance of a kidney exchange program is not the judicious assignment of positive weights (rewards) to patient-donor pairs. Rather, the key factor in increasing the number of transplants, decreasing waiting times and improving group fairness is the judicious assignment of a negative weight (penalty) to the small number of non-directed donors in the kidney exchange program.
</details></li>
</ul>
<hr>
<h2 id="State-space-Models-with-Layer-wise-Nonlinearity-are-Universal-Approximators-with-Exponential-Decaying-Memory"><a href="#State-space-Models-with-Layer-wise-Nonlinearity-are-Universal-Approximators-with-Exponential-Decaying-Memory" class="headerlink" title="State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory"></a>State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13414">http://arxiv.org/abs/2309.13414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shida Wang, Beichen Xue</li>
<li>for: 这篇论文主要研究了使用层状态模型来模型连续序列之间的关系。</li>
<li>methods: 论文使用了层状态模型，并在每层添加非线性活化来提高模型的表达能力。</li>
<li>results: 研究表明，通过层状态模型和非线性活化的组合，可以有效地模型复杂的连续序列模式。但是，研究也表明，状态空间模型无法根本解决指数减少的内存问题。<details>
<summary>Abstract</summary>
State-space models have gained popularity in sequence modelling due to their simple and efficient network structures. However, the absence of nonlinear activation along the temporal direction limits the model's capacity. In this paper, we prove that stacking state-space models with layer-wise nonlinear activation is sufficient to approximate any continuous sequence-to-sequence relationship. Our findings demonstrate that the addition of layer-wise nonlinear activation enhances the model's capacity to learn complex sequence patterns. Meanwhile, it can be seen both theoretically and empirically that the state-space models do not fundamentally resolve the exponential decaying memory issue. Theoretical results are justified by numerical verifications.
</details>
<details>
<summary>摘要</summary>
状态空间模型在序列模型中得到了广泛应用，因为它们的简单和高效的网络结构。然而，在时间方向上缺乏非线性活化限制了模型的容量。在这篇论文中，我们证明了将层weise非线性活化核心到状态空间模型可以近似任何连续序列到序列关系。我们的发现表明，增加层wise非线性活化可以提高模型学习复杂序列模式的能力。同时，可以在理论和实验两个方面见到，状态空间模型并没有根本解决指数减少记忆问题。理论结果得到了数值验证。
</details></li>
</ul>
<hr>
<h2 id="Towards-Attributions-of-Input-Variables-in-a-Coalition"><a href="#Towards-Attributions-of-Input-Variables-in-a-Coalition" class="headerlink" title="Towards Attributions of Input Variables in a Coalition"></a>Towards Attributions of Input Variables in a Coalition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13411">http://arxiv.org/abs/2309.13411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Zheng, Huiqi Deng, Quanshi Zhang</li>
<li>for: 这paper的目的是开发一种新的贡献计算方法，以解释个体变量贡献和其党筹贡献之间的冲突。</li>
<li>methods: 该paper使用了一种全新的视角来推导贡献计算方法，包括将Harsanyi交互编码为AI模型中的交互分配，然后将Shapley值扩展到党筹贡献领域。</li>
<li>results: 该paper发现了冲突的基本机制，即党筹中包含部分变量的交互导致这种冲突。<details>
<summary>Abstract</summary>
This paper aims to develop a new attribution method to explain the conflict between individual variables' attributions and their coalition's attribution from a fully new perspective. First, we find that the Shapley value can be reformulated as the allocation of Harsanyi interactions encoded by the AI model. Second, based the re-alloction of interactions, we extend the Shapley value to the attribution of coalitions. Third we ective. We derive the fundamental mechanism behind the conflict. This conflict come from the interaction containing partial variables in their coalition.
</details>
<details>
<summary>摘要</summary>
这篇论文目的是开发一种新的归因方法，以解释个体变量归因和其党的归因之间的冲突。我们首先发现，夏普利值可以被重新解释为由人工智能模型编码的哈萨尼（Harsanyi）互动的分配。其次，基于重新分配互动，我们扩展了夏普利值来归因党。最后，我们 derive了这种冲突的基本机制，这种冲突来自各个变量在其党中的互动中含有部分变量。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Forecasting-Unleashing-Long-Term-Dependencies-with-Fractionally-Differenced-Data"><a href="#Time-Series-Forecasting-Unleashing-Long-Term-Dependencies-with-Fractionally-Differenced-Data" class="headerlink" title="Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data"></a>Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13409">http://arxiv.org/abs/2309.13409</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarit Maitra, Vivek Mishra, Srashti Dwivedi, Sukanya Kundu, Goutam Kumar Kundu</li>
<li>for: 这个研究旨在提出一种新的预测策略，利用分数差分（FD）来捕捉时间序列数据中的短期和长期依赖关系。</li>
<li>methods: 这个研究使用了FD法，与传统的整数差分方法不同，FD可以维护时间序列的记忆，同时为预测目的进行稳定化。研究还使用了新闻报道的 sentiment分析，将FD应用于股票指数SPY的金融数据。</li>
<li>results: 研究结果表明，FD在与目标变量进行binary分类时表现出优于整数差分，这得到了ROCAUC和MCC评价的证明。<details>
<summary>Abstract</summary>
This study introduces a novel forecasting strategy that leverages the power of fractional differencing (FD) to capture both short- and long-term dependencies in time series data. Unlike traditional integer differencing methods, FD preserves memory in series while stabilizing it for modeling purposes. By applying FD to financial data from the SPY index and incorporating sentiment analysis from news reports, this empirical analysis explores the effectiveness of FD in conjunction with binary classification of target variables. Supervised classification algorithms were employed to validate the performance of FD series. The results demonstrate the superiority of FD over integer differencing, as confirmed by Receiver Operating Characteristic/Area Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Unitary-Weights-Based-One-Iteration-Quantum-Perceptron-Algorithm-for-Non-Ideal-Training-Sets"><a href="#A-Unitary-Weights-Based-One-Iteration-Quantum-Perceptron-Algorithm-for-Non-Ideal-Training-Sets" class="headerlink" title="A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets"></a>A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14366">http://arxiv.org/abs/2309.14366</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Liu, Peipei Gao, Yuxiang Wang, Wenbin Yu, Maojun Zhang</li>
<li>for: 提高量子神经网络的训练集不完美问题和一次学习问题</li>
<li>methods: 提出了一种基于单位 weights 的高效量子见解算法，通过计算总加重矩阵的特征值分解来使加重矩阵变为单位矩阵</li>
<li>results: 示例验证了量子门 Warren  gates {H, S, T, CNOT, Toffoli, Fredkin} 的准确实现，并且与其他量子见解算法进行比较，显示了我们的算法在应用性、准确性和可用性等方面具有优势。此外，为了进一步验证我们的算法的可应用性，还提出了一种量子复合门，该门由多个基本量子门组成。<details>
<summary>Abstract</summary>
In order to solve the problem of non-ideal training sets (i.e., the less-complete or over-complete sets) and implement one-iteration learning, a novel efficient quantum perceptron algorithm based on unitary weights is proposed, where the singular value decomposition of the total weight matrix from the training set is calculated to make the weight matrix to be unitary. The example validation of quantum gates {H, S, T, CNOT, Toffoli, Fredkin} shows that our algorithm can accurately implement arbitrary quantum gates within one iteration. The performance comparison between our algorithm and other quantum perceptron algorithms demonstrates the advantages of our algorithm in terms of applicability, accuracy, and availability. For further validating the applicability of our algorithm, a quantum composite gate which consists of several basic quantum gates is also illustrated.
</details>
<details>
<summary>摘要</summary>
为解决非理想训练集（即部分或过complete的集）和实现一轮学习，一种新的高效量子批量算法基于单位Weightmatrix是提出的，其中来自训练集的总weight矩阵的singular value decomposition被计算以使weight矩阵变为单位矩阵。例子验证量子门{H, S, T, CNOT, Toffoli, Fredkin}表明，我们的算法可以在一轮内准确实现任意量子门。与其他量子批量算法相比，我们的算法在可用性、准确性和可用性等方面具有优势。为进一步验证我们的算法的可用性，一种量子复合门，由多个基本量子门组成，也被描述。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Image-text-Multimodal-Models"><a href="#A-Survey-on-Image-text-Multimodal-Models" class="headerlink" title="A Survey on Image-text Multimodal Models"></a>A Survey on Image-text Multimodal Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15857">http://arxiv.org/abs/2309.15857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i2vec/a-survey-on-image-text-multimodal-models">https://github.com/i2vec/a-survey-on-image-text-multimodal-models</a></li>
<li>paper_authors: Ruifeng Guo, Jingxuan Wei, Linzhuang Sun, Bihui Yu, Guiyong Chang, Dawei Liu, Sibo Zhang, Zhengbing Yao, Mingjun Xu, Liping Bu<br>for:This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories.methods:The paper revisits the basic concepts and developmental milestones of image-text multimodal models, introducing a novel classification that segments their evolution into three distinct phases, and proposes a categorization of the tasks associated with image-text multimodal models into five major types.results:The paper delves into the inherent challenges and limitations of image-text multimodal models and fosters the exploration of prospective research directions, offering an exhaustive overview of the present research landscape of image-text multimodal models and serving as a valuable reference for future scholarly endeavors.<details>
<summary>Abstract</summary>
Amidst the evolving landscape of artificial intelligence, the convergence of visual and textual information has surfaced as a crucial frontier, leading to the advent of image-text multimodal models. This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories. Initially, we revisit the basic concepts and developmental milestones of these models, introducing a novel classification that segments their evolution into three distinct phases, based on their time of introduction and subsequent impact on the discipline. Furthermore, based on the tasks' significance and prevalence in the academic landscape, we propose a categorization of the tasks associated with image-text multimodal models into five major types, elucidating the recent progress and key technologies within each category. Despite the remarkable accomplishments of these models, numerous challenges and issues persist. This paper delves into the inherent challenges and limitations of image-text multimodal models, fostering the exploration of prospective research directions. Our objective is to offer an exhaustive overview of the present research landscape of image-text multimodal models and to serve as a valuable reference for future scholarly endeavors. We extend an invitation to the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.
</details>
<details>
<summary>摘要</summary>
在人工智能的演化 landscape 中，图文合并成为了一个关键的前ier，导致了图文多modal模型的出现。本文提供了图文多modal模型的全面回顾和当前状况，探讨其应用价值、挑战和可能的研究车道。首先，我们回顾了这些模型的基本概念和发展历程，提出了一种新的分类方法，将其分为三个不同的阶段，根据它们的出现时间和对领域的影响。此外，根据学术景观中任务的重要性和普遍性，我们对图文多modal模型相关任务进行了五种主要类别的分类，阐述了最近的进步和关键技术在每个类别中。 despite the remarkable achievements of these models, numerous challenges and issues persist. This paper explores the inherent challenges and limitations of image-text multimodal models, and invites the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.Here's the word-for-word translation of the text into Simplified Chinese:在人工智能的演化 landscape 中，图文合并成为了一个关键的前ier，导致了图文多modal模型的出现。本文提供了图文多modal模型的全面回顾和当前状况，探讨其应用价值、挑战和可能的研究车道。首先，我们回顾了这些模型的基本概念和发展历程，提出了一种新的分类方法，将其分为三个不同的阶段，根据它们的出现时间和对领域的影响。此外，根据学术景观中任务的重要性和普遍性，我们对图文多modal模型相关任务进行了五种主要类别的分类，阐述了最近的进步和关键技术在每个类别中。 despite the remarkable achievements of these models, numerous challenges and issues persist. This paper explores the inherent challenges and limitations of image-text multimodal models, and invites the broader community to collaborate in enhancing the image-text multimodal model community, accessible at: \href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.
</details></li>
</ul>
<hr>
<h2 id="Smart-City-Digital-Twin-Framework-for-Real-Time-Multi-Data-Integration-and-Wide-Public-Distribution"><a href="#Smart-City-Digital-Twin-Framework-for-Real-Time-Multi-Data-Integration-and-Wide-Public-Distribution" class="headerlink" title="Smart City Digital Twin Framework for Real-Time Multi-Data Integration and Wide Public Distribution"></a>Smart City Digital Twin Framework for Real-Time Multi-Data Integration and Wide Public Distribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13394">http://arxiv.org/abs/2309.13394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Adreani, Pierfrancesco Bellini, Marco Fanfani, Paolo Nesi, Gianni Pantaleo</li>
<li>for: 这个论文是为了介绍一种基于Snap4City IoT平台的城市数字孪生框架，用于支持城市规划和管理决策。</li>
<li>methods: 该框架使用了数据收集、索引、计算和信息分布等方法，并将这些方法集成到了一个跨多个数据源的平台上，以实现实时更新的数字孪生。</li>
<li>results: 该框架可以提供实时的城市情况描述、预测和仿真分析结果，包括交通拥堵、污染物分布、可能的结果等，并且支持公民参与城市决策过程。<details>
<summary>Abstract</summary>
Digital Twins are digital replica of real entities and are becoming fundamental tools to monitor and control the status of entities, predict their future evolutions, and simulate alternative scenarios to understand the impact of changes. Thanks to the large deployment of sensors, with the increasing information it is possible to build accurate reproductions of urban environments including structural data and real-time information. Such solutions help city councils and decision makers to face challenges in urban development and improve the citizen quality of life, by ana-lysing the actual conditions, evaluating in advance through simulations and what-if analysis the outcomes of infrastructural or political chang-es, or predicting the effects of humans and/or of natural events. Snap4City Smart City Digital Twin framework is capable to respond to the requirements identified in the literature and by the international forums. Differently from other solutions, the proposed architecture provides an integrated solution for data gathering, indexing, computing and information distribution offered by the Snap4City IoT platform, therefore realizing a continuously updated Digital Twin. 3D building models, road networks, IoT devices, WoT Entities, point of interests, routes, paths, etc., as well as results from data analytical processes for traffic density reconstruction, pollutant dispersion, predictions of any kind, what-if analysis, etc., are all integrated into an accessible web interface, to support the citizens participation in the city decision processes. What-If analysis to let the user performs simulations and observe possible outcomes. As case of study, the Digital Twin of the city of Florence (Italy) is presented. Snap4City platform, is released as open-source, and made available through GitHub and as docker compose.
</details>
<details>
<summary>摘要</summary>
“数字双”是数字世界中的实体复制品，它们在监测和控制实体状态、预测未来发展和模拟不同enario来理解改变的影响。随着丰富的传感器的扩散，可以建立 precisemodels of urban environments, including structural data and real-time information。这些解决方案帮助城市议会和决策者面对城市发展的挑战，提高公民的生活质量，通过实际情况分析、预测变化和“what-if”分析来评估基础设施或政策变化的影响。Snap4City Smart City Digital Twin框架能够应对文献和国际论坛中所提出的需求。与其他解决方案不同，我们的架构提供了一个集成的数据收集、索引、计算和信息分发的解决方案，以实现不断更新的数字双。3D建筑模型、路网、物联网设备、Web of Things实体、终端、路线、轨迹等都会被集成到一个可访问的Web界面中，以支持公民参与城市决策过程。“what-if”分析允许用户进行模拟和观察可能的结果。作为案例研究，我们介绍了 Florence（意大利）的数字双。Snap4City平台释放为开源，通过 GitHub和docker compose 进行分发。
</details></li>
</ul>
<hr>
<h2 id="AgriSORT-A-Simple-Online-Real-time-Tracking-by-Detection-framework-for-robotics-in-precision-agriculture"><a href="#AgriSORT-A-Simple-Online-Real-time-Tracking-by-Detection-framework-for-robotics-in-precision-agriculture" class="headerlink" title="AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture"></a>AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13393">http://arxiv.org/abs/2309.13393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Saraceni, Ionut M. Motoi, Daniele Nardi, Thomas A. Ciarfuglia</li>
<li>for: 这个论文是为了解决精准农业中的多目标跟踪问题，这个问题是机器人学中的一个挑战。</li>
<li>methods: 这篇论文提出了一种基于运动信息的实时跟踪检测管道，即AgriSORT，该管道可以快速和准确地在视频序列中传播跟踪。</li>
<li>results: 在一个特制的农业上的MOT benchмарck上测试了AgriSORT管道，并得到了高效和准确的跟踪结果。<details>
<summary>Abstract</summary>
The problem of multi-object tracking (MOT) consists in detecting and tracking all the objects in a video sequence while keeping a unique identifier for each object. It is a challenging and fundamental problem for robotics. In precision agriculture the challenge of achieving a satisfactory solution is amplified by extreme camera motion, sudden illumination changes, and strong occlusions. Most modern trackers rely on the appearance of objects rather than motion for association, which can be ineffective when most targets are static objects with the same appearance, as in the agricultural case. To this end, on the trail of SORT [5], we propose AgriSORT, a simple, online, real-time tracking-by-detection pipeline for precision agriculture based only on motion information that allows for accurate and fast propagation of tracks between frames. The main focuses of AgriSORT are efficiency, flexibility, minimal dependencies, and ease of deployment on robotic platforms. We test the proposed pipeline on a novel MOT benchmark specifically tailored for the agricultural context, based on video sequences taken in a table grape vineyard, particularly challenging due to strong self-similarity and density of the instances. Both the code and the dataset are available for future comparisons.
</details>
<details>
<summary>摘要</summary>
“多目标追踪（MOT）问题的挑战是在识别和追踪影像序列中的所有物件，并保留每个物件唯一的识别码。这是机器人学中的基本问题。在精确农业中，实现满意的解决方案受到极大的镜头运动、突然的照明变化和强大的遮蔽影响。现代追踪器多数依靠物件的外观而非运动进行相互关联，这在农业案例中可能无效，因为大多数目标是静止的物件，具有相同的外观。为此，我们基于SORT [5]的概念，提出了AgriSORT，一个简单、在线、实时的追踪-by-探测管线，仅基于运动资讯，可以实现精确和快速的探测迹踪转换。AgriSORT的主要专注点包括效率、灵活性、最小化依赖和机器人平台的易用性。我们将该管线评估在特有的农业上的MOT实验中，基于简体葡萄园的视频序列，特别是由于强大的自相似和物件的密度。管线和数据都可以供未来的比较。”
</details></li>
</ul>
<hr>
<h2 id="D-Separation-for-Causal-Self-Explanation"><a href="#D-Separation-for-Causal-Self-Explanation" class="headerlink" title="D-Separation for Causal Self-Explanation"></a>D-Separation for Causal Self-Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13391">http://arxiv.org/abs/2309.13391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jugechengzi/rationalization-mcd">https://github.com/jugechengzi/rationalization-mcd</a></li>
<li>paper_authors: Wei Liu, Jun Wang, Haozhao Wang, Ruixuan Li, Zhiying Deng, YuanKai Zhang, Yang Qiu</li>
<li>for: 提高 NLP 模型的解释性和精度</li>
<li>methods: 基于 Minimum Conditional Dependence（MCD） criterion，使用 KL-divergence 度量依赖性，提高 F1 分数</li>
<li>results: 与先前最佳 MMI-based 方法比较，MCD 方法可以提高 F1 分数达到 $13.7%$ 之间<details>
<summary>Abstract</summary>
Rationalization is a self-explaining framework for NLP models. Conventional work typically uses the maximum mutual information (MMI) criterion to find the rationale that is most indicative of the target label. However, this criterion can be influenced by spurious features that correlate with the causal rationale or the target label. Instead of attempting to rectify the issues of the MMI criterion, we propose a novel criterion to uncover the causal rationale, termed the Minimum Conditional Dependence (MCD) criterion, which is grounded on our finding that the non-causal features and the target label are \emph{d-separated} by the causal rationale. By minimizing the dependence between the unselected parts of the input and the target label conditioned on the selected rationale candidate, all the causes of the label are compelled to be selected. In this study, we employ a simple and practical measure of dependence, specifically the KL-divergence, to validate our proposed MCD criterion. Empirically, we demonstrate that MCD improves the F1 score by up to $13.7\%$ compared to previous state-of-the-art MMI-based methods. Our code is available at: \url{https://github.com/jugechengzi/Rationalization-MCD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这是一个自解释的框架 для NLP模型。传统工作通常使用最大共同信息（MMI） criterion 来找到这些模型的理由，但这个标准可能受到假冒的特征所影响，这些特征可能与目标标签或理由相关。而不是尝试修正 MMI 标准的问题，我们提出了一个新的标准，即最小侧项依存性（MCD）标准，这是基于我们发现非 causal 特征和目标标签在 causal 理由下是 d-separated 的现象。通过将选择的理由候选者中的非选择部分的输入与目标标签之间的依存关系降至最低，所有的 Label 的原因都会被选择。在这个研究中，我们使用了一个简单实用的依存度量，具体是 KL- divergence，以验证我们的提出的 MCD 标准。实验结果显示，MCD 可以与之前的 MMI 基于的方法相比，提高 F1 分数达 13.7%。我们的代码可以在：\url{https://github.com/jugechengzi/Rationalization-MCD} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Deciphering-Spatio-Temporal-Graph-Forecasting-A-Causal-Lens-and-Treatment"><a href="#Deciphering-Spatio-Temporal-Graph-Forecasting-A-Causal-Lens-and-Treatment" class="headerlink" title="Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment"></a>Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13378">http://arxiv.org/abs/2309.13378</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Yutong Xia, Yuxuan Liang, Haomin Wen, Xu Liu, Kun Wang, Zhengyang Zhou, Roger Zimmermann</li>
<li>for: 本文旨在解决预测空间时间图（STG）中的 temporal out-of-distribution（OoD）问题和动态空间 causation 问题。</li>
<li>methods: 本文提出了一种名为 CaST 的新框架，利用 causal 镜头来解读 STG 数据生成过程，并采用 back-door adjustment 和 front-door adjustment 等方法来处理 temporal OoD 问题和 causal 衍生效应。</li>
<li>results: 实验结果表明，CaST 可以准确地预测 STG，并且在三个实际数据集上表现出色，常常超过现有方法。此外，CaST 具有良好的解释性。<details>
<summary>Abstract</summary>
Spatio-Temporal Graph (STG) forecasting is a fundamental task in many real-world applications. Spatio-Temporal Graph Neural Networks have emerged as the most popular method for STG forecasting, but they often struggle with temporal out-of-distribution (OoD) issues and dynamic spatial causation. In this paper, we propose a novel framework called CaST to tackle these two challenges via causal treatments. Concretely, leveraging a causal lens, we first build a structural causal model to decipher the data generation process of STGs. To handle the temporal OoD issue, we employ the back-door adjustment by a novel disentanglement block to separate invariant parts and temporal environments from input data. Moreover, we utilize the front-door adjustment and adopt the Hodge-Laplacian operator for edge-level convolution to model the ripple effect of causation. Experiments results on three real-world datasets demonstrate the effectiveness and practicality of CaST, which consistently outperforms existing methods with good interpretability.
</details>
<details>
<summary>摘要</summary>
espacio-temporal graph (STG) 预测是现实世界中许多应用场景中的基本任务。  espacio-temporal graph neural networks (STGNNs) 已经成为 STG 预测的最受欢迎方法，但它们经常面临时间外部预测 (OoD) 问题和动态空间 causation。 在这篇论文中，我们提议一种名为 CaST 的框架，以解决这两个挑战。具体来说，我们首先利用 causal 镜头来理解 STG 数据生成过程。为了处理时间 OoD 问题，我们使用一种新的分离块来分离输入数据中的不变部分和时间环境。此外，我们使用 front-door 调整和霍迪-拉普拉斯算子来模型 causation 的涟漪效应。实验结果表明，CaST 在三个真实世界数据集上具有优秀的效果和可读性，并经常超越现有方法。
</details></li>
</ul>
<hr>
<h2 id="Limits-of-Actor-Critic-Algorithms-for-Decision-Tree-Policies-Learning-in-IBMDPs"><a href="#Limits-of-Actor-Critic-Algorithms-for-Decision-Tree-Policies-Learning-in-IBMDPs" class="headerlink" title="Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs"></a>Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13365">http://arxiv.org/abs/2309.13365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hecotr Kohler, Riad Akrour, Philippe Preux</li>
<li>for: 提高AI模型的可解释性，以便用户建立对其信任。</li>
<li>methods: 使用强化学习框架，在DT中探索特征之间的关系，以建立更加紧凑的DT。</li>
<li>results: 通过抽离特征之间的关系，可以减少DT的大小，同时保持模型的性能。<details>
<summary>Abstract</summary>
Interpretability of AI models allows for user safety checks to build trust in such AIs. In particular, Decision Trees (DTs) provide a global look at the learned model and transparently reveal which features of the input are critical for making a decision. However, interpretability is hindered if the DT is too large. To learn compact trees, a recent Reinforcement Learning (RL) framework has been proposed to explore the space of DTs using deep RL. This framework augments a decision problem (e.g. a supervised classification task) with additional actions that gather information about the features of an otherwise hidden input. By appropriately penalizing these actions, the agent learns to optimally trade-off size and performance of DTs. In practice, a reactive policy for a partially observable Markov decision process (MDP) needs to be learned, which is still an open problem. We show in this paper that deep RL can fail even on simple toy tasks of this class. However, when the underlying decision problem is a supervised classification task, we show that finding the optimal tree can be cast as a fully observable Markov decision problem and be solved efficiently, giving rise to a new family of algorithms for learning DTs that go beyond the classical greedy maximization ones.
</details>
<details>
<summary>摘要</summary>
“AI模型的可解释性允许用户建立信任，以建立可靠的AI。尤其是决策树（DT）可以提供全面的模型显示和对输入特征的透彻显示，从而帮助用户了解模型的问题。然而，如果DT太大，则可能会妨碍可解释性。为了学习尺寸小的DT，一个最近的强化学习（RL）框架已经被提议，通过将决策问题（例如分类任务）与额外的动作搜索整合，以便在搜索DT时，对输入特征进行有效的探索。在实践中，需要学习一个可 React的策略，这是一个 ainda 未解决的问题。我们在这篇论文中显示，深度RL可以在简单的玩具任务上失败，但当对决策问题时，我们可以将找到最佳树的问题转化为一个可观察的Markov决策过程（MDP），并有效地解决它，从而开启了一新的家族Algorithm для学习DT，与传统的单簇最大化算法不同。”
</details></li>
</ul>
<hr>
<h2 id="MLPST-MLP-is-All-You-Need-for-Spatio-Temporal-Prediction"><a href="#MLPST-MLP-is-All-You-Need-for-Spatio-Temporal-Prediction" class="headerlink" title="MLPST: MLP is All You Need for Spatio-Temporal Prediction"></a>MLPST: MLP is All You Need for Spatio-Temporal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13363">http://arxiv.org/abs/2309.13363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Zhang, Ze Huang, Zhiwei Hu, Xiangyu Zhao, Wanyu Wang, Zitao Liu, Junbo Zhang, S. Joe Qin, Hongwei Zhao</li>
<li>For: 预测交通流量，提高公共交通系统的运作效率和可靠性。* Methods: 提出了一种简单、轻量级的多层感知器（MLP）架构，通过快速和高效的MLP处理， capture 空间和时间关系，并且需要只有线性计算复杂度和模型参数数量相对较少。* Results: 经过广泛的实验 validate MLPST的高效性和灵活性，并且在模型准确率最高的情况下，MLPST achieves the best time and space efficiency。<details>
<summary>Abstract</summary>
Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.
</details>
<details>
<summary>摘要</summary>
很多人对汽车流量预测有很大的需求，因为它对城市交通系统的管理有着重要的作用。为了满足这些需求，我们认为一个理想的空间时间预测方法应该具备以下三个特点：高效、轻量级和有效。然而，目前的深度模型基于的空间时间预测解决方案通常具有复杂的体系和繁琐的优化，这些方法很难满足我们的期望。为了实现以上目标，我们提出了一种直观和新型的框架，即多层感知网络（MLPST）。特别是，我们首先从本地和全局感知场景中捕捉到空间关系。然后，在不同时间间隔中考虑到了时间关系。通过紧凑的MLP处理，MLPST可以很好地捕捉到空间和时间关系，同时计算复杂度只有线性增长，并且模型参数比基线模型高出一个数量级。我们进行了广泛的实验，并证明了MLPST在比较先进的基elines上的超越性和效率。在同等准确性下，MLPST在时间和空间效率方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="Probing-the-Moral-Development-of-Large-Language-Models-through-Defining-Issues-Test"><a href="#Probing-the-Moral-Development-of-Large-Language-Models-through-Defining-Issues-Test" class="headerlink" title="Probing the Moral Development of Large Language Models through Defining Issues Test"></a>Probing the Moral Development of Large Language Models through Defining Issues Test</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13356">http://arxiv.org/abs/2309.13356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Tanmay, Aditi Khandelwal, Utkarsh Agarwal, Monojit Choudhury</li>
<li>for: 这项研究用于测试LLMs的道德理解能力，使用定义问题测试（DIT），这是根据科尔堡认知道的道德发展模型（KCDM）而开发的一种心理测试。</li>
<li>methods: 这项研究使用DIT测试LLMs的道德理解能力，包括用道德决策问题和道德考虑因素，评估 respondent 对问题的解决方案和道德价值观的重要性。</li>
<li>results: 研究显示，早期LLMs如GPT-3的道德理解能力与随机基线相当，而ChatGPT、Llama2-Chat、PaLM-2和GPT-4则表现出较好的道德理解能力，与成年人相当。GPT-4的后konventional道德理解分数最高，与典型大学生相当。但是，模型在不同的决策问题上表现不一致，指出了其理解和解决能力的重要缺陷。<details>
<summary>Abstract</summary>
In this study, we measure the moral reasoning ability of LLMs using the Defining Issues Test - a psychometric instrument developed for measuring the moral development stage of a person according to the Kohlberg's Cognitive Moral Development Model. DIT uses moral dilemmas followed by a set of ethical considerations that the respondent has to judge for importance in resolving the dilemma, and then rank-order them by importance. A moral development stage score of the respondent is then computed based on the relevance rating and ranking.   Our study shows that early LLMs such as GPT-3 exhibit a moral reasoning ability no better than that of a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans. GPT-4, in fact, has the highest post-conventional moral reasoning score, equivalent to that of typical graduate school students. However, we also observe that the models do not perform consistently across all dilemmas, pointing to important gaps in their understanding and reasoning abilities.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们测量了LLM的道德思维能力使用定义问题测试（DIT）——一种心理测量instrument，用于测量人类的道德发展阶段 according to Kohlberg's cognitive moral development model。DIT使用道德困境，然后提供一组伦理考虑，请求参与者根据其重要性来评价和排序。根据参与者的道德发展阶段分数， compute the moral development stage score。  our study shows that early LLMs such as GPT-3 do not exhibit any better moral reasoning ability than a random baseline, while ChatGPT, Llama2-Chat, PaLM-2 and GPT-4 show significantly better performance on this task, comparable to adult humans. GPT-4, in fact, has the highest post-conventional moral reasoning score, equivalent to that of typical graduate school students. However, we also observe that the models do not perform consistently across all dilemmas, pointing to important gaps in their understanding and reasoning abilities.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Lexical-Squad-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Hate-Speech-Detection-using-Fused-Ensemble-Approach"><a href="#Lexical-Squad-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Hate-Speech-Detection-using-Fused-Ensemble-Approach" class="headerlink" title="Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal Hate Speech Detection using Fused Ensemble Approach"></a>Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal Hate Speech Detection using Fused Ensemble Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13354">http://arxiv.org/abs/2309.13354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m0hammad-kashif/multimodalhatespeech">https://github.com/m0hammad-kashif/multimodalhatespeech</a></li>
<li>paper_authors: Mohammad Kashif, Mohammad Zohair, Saquib Ali<br>for: 本研究旨在探讨如何使用多模态学习方法来检测仇恨言论。methods: 本研究使用了InceptionV3、BERT和XLNet等现状模型，并将其组合成一个ensemble模型来检测仇恨言论。results: 研究得出了75.21%的准确率和74.96%的F1分数，并进行了实验来证明模型在预测和分类上的性能。<details>
<summary>Abstract</summary>
With a surge in the usage of social media postings to express opinions, emotions, and ideologies, there has been a significant shift towards the calibration of social media as a rapid medium of conveying viewpoints and outlooks over the globe. Concurrently, the emergence of a multitude of conflicts between two entities has given rise to a stream of social media content containing propaganda, hate speech, and inconsiderate views. Thus, the issue of monitoring social media postings is rising swiftly, attracting major attention from those willing to solve such problems. One such problem is Hate Speech detection. To mitigate this problem, we present our novel ensemble learning approach for detecting hate speech, by classifying text-embedded images into two labels, namely "Hate Speech" and "No Hate Speech". We have incorporated state-of-art models including InceptionV3, BERT, and XLNet. Our proposed ensemble model yielded promising results with 75.21 and 74.96 as accuracy and F-1 score (respectively). We also present an empirical evaluation of the text-embedded images to elaborate on how well the model was able to predict and classify. We release our codebase here (https://github.com/M0hammad-Kashif/MultiModalHateSpeech).
</details>
<details>
<summary>摘要</summary>
受社交媒体发表意见、情感和意识形态的使用量增加，社交媒体已成为全球快速传递观点和视野的重要媒体。同时，全球多个问题的出现导致社交媒体内容中充斥着宣传、仇恨言论和不谨慎的观点。因此，监测社交媒体帖子的问题日益减少，引起了广泛的关注。其中，我们提出了一种新的ensemble学习方法，用于检测嫌 speech，通过将文本嵌入图像分为两个标签：“嫌 speech”和“无嫌 speech”。我们把state-of-art模型，如InceptionV3、BERT和XLNet纳入了我们的提案模型中。我们的提案模型在实验中达到了75.21%和74.96%的准确率和F-1分数（分别）。我们还进行了employnesian评估，以便更好地描述模型是如何预测和分类文本嵌入图像。我们在github上发布了代码库（https://github.com/M0hammad-Kashif/MultiModalHateSpeech）。
</details></li>
</ul>
<hr>
<h2 id="An-In-depth-Survey-of-Large-Language-Model-based-Artificial-Intelligence-Agents"><a href="#An-In-depth-Survey-of-Large-Language-Model-based-Artificial-Intelligence-Agents" class="headerlink" title="An In-depth Survey of Large Language Model-based Artificial Intelligence Agents"></a>An In-depth Survey of Large Language Model-based Artificial Intelligence Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14365">http://arxiv.org/abs/2309.14365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengyu Zhao, Zijian Jin, Ning Cheng</li>
<li>for: 本文主要研究大语言模型（LLM）与传统人工智能（AI）代理之间的主要区别和特点，以及 LLM 基于 AI 代理的可能性和潜力。</li>
<li>methods: 本文首先比较了这两种代理的基本特点，并详细分析了 AI 代理的关键组件，包括规划、记忆和工具使用。特别是在记忆方面，本文提出了一种创新的分类方法，不仅与传统分类方法不同，还为 AI 代理的记忆系统设计提供了新的视角。</li>
<li>results: 本文通过对核心组件的深入分析，为未来人工智能代理技术的发展提供了坚实的基础。文章最后还提出了进一步研究的方向，以便为学术研究人员提供价值的思路和指导。<details>
<summary>Abstract</summary>
Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance. In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents. Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities. Subsequently, we conducted an in-depth analysis of the key components of AI agents, including planning, memory, and tool use. Particularly, for the crucial component of memory, this paper introduced an innovative classification scheme, not only departing from traditional classification methods but also providing a fresh perspective on the design of an AI agent's memory system. We firmly believe that in-depth research and understanding of these core components will lay a solid foundation for the future advancement of AI agent technology. At the end of the paper, we provide directional suggestions for further research in this field, with the hope of offering valuable insights to scholars and researchers in the field.
</details>
<details>
<summary>摘要</summary>
因为大型语言模型（LLM）的强大能力，近期有大量努力尝试将其与人工智能代理 integrate 以提高性能。在这篇论文中，我们探讨了 LLM 基于代理的核心差异和特点。 Specifically，我们首先比较了这两种代理的基本特点，明确 LLM 基于代理在自然语言处理、知识存储和 raison d'être 能力方面的显著优势。接着，我们进行了深入的分析代理的关键组件，包括规划、记忆和工具使用。尤其是在关键组件中的记忆方面，这篇论文提出了一种创新的分类方法，不仅与传统分类方法不同，而且为 AI 代理的记忆系统设计提供了新的视角。我们认为深入研究和理解这些核心组件将为未来人工智能代理技术的发展 lay 下一定的基础。总之，在这篇论文的结尾，我们提出了一些方向性的建议，以期为学者和研究人员在这个领域提供价值的信息。
</details></li>
</ul>
<hr>
<h2 id="LLMs-as-Counterfactual-Explanation-Modules-Can-ChatGPT-Explain-Black-box-Text-Classifiers"><a href="#LLMs-as-Counterfactual-Explanation-Modules-Can-ChatGPT-Explain-Black-box-Text-Classifiers" class="headerlink" title="LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?"></a>LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13340">http://arxiv.org/abs/2309.13340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amrita Bhattacharjee, Raha Moraffah, Joshua Garland, Huan Liu</li>
<li>for: 本研究使用大语言模型（LLM）来解释黑obox文本分类器的决策，通过生成后续的、模型无关的counterfactual解释。</li>
<li>methods: 我们提出了一个管道，使用LLM来生成post-hoc、模型无关的counterfactual解释，通过（i）利用LLM的文本理解能力来标识和提取潜在特征，以及（ii）利用LLM的推倒和生成能力来生成counterfactual解释。</li>
<li>results: 我们在一组state-of-the-art LLM中评估了三种变体，包括不同的特征提取方法和Counterfactual解释生成方法。我们发现这些模型在不同的设置中的性能不同，一种基于两步特征提取的全变体在大多数情况下表现最佳。我们的管道可以用于自动解释系统，可能减少人工劳动。<details>
<summary>Abstract</summary>
Large language models (LLMs) are increasingly being used for tasks beyond text generation, including complex tasks such as data labeling, information extraction, etc. With the recent surge in research efforts to comprehend the full extent of LLM capabilities, in this work, we investigate the role of LLMs as counterfactual explanation modules, to explain decisions of black-box text classifiers. Inspired by causal thinking, we propose a pipeline for using LLMs to generate post-hoc, model-agnostic counterfactual explanations in a principled way via (i) leveraging the textual understanding capabilities of the LLM to identify and extract latent features, and (ii) leveraging the perturbation and generation capabilities of the same LLM to generate a counterfactual explanation by perturbing input features derived from the extracted latent features. We evaluate three variants of our framework, with varying degrees of specificity, on a suite of state-of-the-art LLMs, including ChatGPT and LLaMA 2. We evaluate the effectiveness and quality of the generated counterfactual explanations, over a variety of text classification benchmarks. Our results show varied performance of these models in different settings, with a full two-step feature extraction based variant outperforming others in most cases. Our pipeline can be used in automated explanation systems, potentially reducing human effort.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM） increasingly 用于 tasks beyond 文本生成，包括复杂的任务，如数据标签、信息提取等。 随着研究尝试理解 LLM 的全面能力，在这个工作中，我们 investigate LLM 作为 counterfactual explanation module，以解释黑色盒子文本分类器的决策。 灵感自 causal 思维，我们提出一个管道，使用 LLM 生成 post-hoc，model-agnostic counterfactual explanations 的方式，包括：(i) 利用 LLM 的文本理解能力，识别和提取 latent features，以及 (ii) 利用 LLM 的干扰和生成能力，对 input features 进行推变，生成 counterfactual explanation。 我们评估了三种不同的框架，以不同的具体性，在一些最新的 LLM 上，包括 ChatGPT 和 LLaMA 2。 我们评估这些模型在不同的设定下的效能和质量，并发现在大多数情况下，一个完整的 two-step 特征提取基于的Variant 表现较好。 我们的管道可以用于自动解释系统，可能将人类努力削减。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Zero-Shot-Chain-of-Thought-Reasoning-in-Large-Language-Models-through-Logic"><a href="#Enhancing-Zero-Shot-Chain-of-Thought-Reasoning-in-Large-Language-Models-through-Logic" class="headerlink" title="Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"></a>Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13339">http://arxiv.org/abs/2309.13339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xufeng Zhao, Mengdi Li, Wenhao Lu, Cornelius Weber, Jae Hee Lee, Kun Chu, Stefan Wermter</li>
<li>for: 提高大型自然语言模型的逻辑推理能力</li>
<li>methods: 基于符号逻辑原理的符号神经网络框架LogiCoT</li>
<li>results: 在不同领域的语言任务上，LogiCoT能够提高大型自然语言模型的逻辑推理能力，并且可以避免生成模型的幻觉现象<details>
<summary>Abstract</summary>
Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic.
</details>
<details>
<summary>摘要</summary>
recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic.Here's the word-for-word translation in Simplified Chinese:最近的大语言模型突破有让人印象深刻的多领域普适性。然而，它们的理解能力仍然有很大的改进空间，特别是在多步逻辑场景下。虽然大语言模型拥有庞大的知识，但它们的行为，尤其是在理解方面，经常不能充分利用这些知识来建立一个有效的思维模式。生成语言模型有时会出现幻见，因为它们的理解过程没有遵循逻辑原则。为了提高大语言模型的零shot逻辑链条理解能力，我们提出了Logical Chain-of-Thought（LogiCoT），一种符号逻辑框架，利用符号逻辑原理来验证和修改理解过程。在不同领域的语言任务上，包括算术、常识、符号、 causal inference 和社会问题，我们进行了实验评估，并证明了增强的理解模式的有效性。
</details></li>
</ul>
<hr>
<h2 id="Diversifying-Question-Generation-over-Knowledge-Base-via-External-Natural-Questions"><a href="#Diversifying-Question-Generation-over-Knowledge-Base-via-External-Natural-Questions" class="headerlink" title="Diversifying Question Generation over Knowledge Base via External Natural Questions"></a>Diversifying Question Generation over Knowledge Base via External Natural Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14362">http://arxiv.org/abs/2309.14362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shasha Guo, Jing Zhang, Xirui Ke, Cuiping Li, Hong Chen</li>
<li>for: 本研究旨在提高知识基础问题生成（KBQG）的质量。</li>
<li>methods: 本研究提出了一种新的多元评价指标，以度量生成的问题的多样性，并 introduces 一种双模型框架，通过两种选择策略来生成多元的问题。</li>
<li>results: 实验结果表明，提出的方法可以生成高度多元的问题，并提高问题回答 task 的性能。<details>
<summary>Abstract</summary>
Previous methods on knowledge base question generation (KBQG) primarily focus on enhancing the quality of a single generated question. Recognizing the remarkable paraphrasing ability of humans, we contend that diverse texts should convey the same semantics through varied expressions. The above insights make diversifying question generation an intriguing task, where the first challenge is evaluation metrics for diversity. Current metrics inadequately assess the above diversity since they calculate the ratio of unique n-grams in the generated question itself, which leans more towards measuring duplication rather than true diversity. Accordingly, we devise a new diversity evaluation metric, which measures the diversity among top-k generated questions for each instance while ensuring their relevance to the ground truth. Clearly, the second challenge is how to enhance diversifying question generation. To address this challenge, we introduce a dual model framework interwoven by two selection strategies to generate diverse questions leveraging external natural questions. The main idea of our dual framework is to extract more diverse expressions and integrate them into the generation model to enhance diversifying question generation. Extensive experiments on widely used benchmarks for KBQG demonstrate that our proposed approach generates highly diverse questions and improves the performance of question answering tasks.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a new evaluation metric for diversity that measures the diversity among the top-k generated questions for each instance while ensuring their relevance to the ground truth. Additionally, we introduce a dual model framework that leverages external natural questions to generate diverse questions. Our approach extracts more diverse expressions and integrates them into the generation model to enhance diversifying question generation.We demonstrate the effectiveness of our approach through extensive experiments on widely used benchmarks for KBQG. Our proposed approach generates highly diverse questions and improves the performance of question answering tasks.
</details></li>
</ul>
<hr>
<h2 id="Class-Attendance-System-in-Education-with-Deep-Learning-Method"><a href="#Class-Attendance-System-in-Education-with-Deep-Learning-Method" class="headerlink" title="Class Attendance System in Education with Deep Learning Method"></a>Class Attendance System in Education with Deep Learning Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13317">http://arxiv.org/abs/2309.13317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hüdaverdi Demir, Serkan Savaş</li>
<li>For: The paper is written for the purpose of developing a system using deep learning methods for object detection in images to record students’ entrance to educational institutions and to perform class attendance.* Methods: The paper uses deep learning methods, specifically object detection algorithms, to detect students’ entrance and attendance in educational institutions.* Results: The study successfully implemented the object detection system and will be applied to real-life problems in a school in the 2022-2023 academic year.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究旨在开发基于深度学习方法的对象检测系统，用于记录学生入学教育机构和进行课程参加。</li>
<li>methods: 本研究使用深度学习方法，具体来说是对象检测算法，来检测学生入学和课程参加。</li>
<li>results: 研究成功实现对象检测系统，将在2022-2023学年度应用到实际问题中。<details>
<summary>Abstract</summary>
With the advancing technology, the hardware gain of computers and the increase in the processing capacity of processors have facilitated the processing of instantaneous and real-time images. Face recognition processes are also studies in the field of image processing. Facial recognition processes are frequently used in security applications and commercial applications. Especially in the last 20 years, the high performances of artificial intelligence (AI) studies have contributed to the spread of these studies in many different fields. Education is one of them. The potential and advantages of using AI in education; can be grouped under three headings: student, teacher, and institution. One of the institutional studies may be the security of educational environments and the contribution of automation to education and training processes. From this point of view, deep learning methods, one of the sub-branches of AI, were used in this study. For object detection from images, a pioneering study has been designed and successfully implemented to keep records of students' entrance to the educational institution and to perform class attendance with images taken from the camera using image processing algorithms. The application of the study to real-life problems will be carried out in a school determined in the 2022-2023 academic year.
</details>
<details>
<summary>摘要</summary>
The potential benefits of using AI in education can be grouped into three categories: student, teacher, and institution. One of the institutional studies is the security of educational environments and the contribution of automation to education and training processes. In this study, deep learning methods, a sub-branch of AI, were used for object detection from images. The study was designed to record students' entrance to the educational institution and to perform class attendance using images taken from cameras and image processing algorithms. The application of the study to real-life problems will be carried out in a school during the 2022-2023 academic year.
</details></li>
</ul>
<hr>
<h2 id="USL-Net-Uncertainty-Self-Learning-Network-for-Unsupervised-Skin-Lesion-Segmentation"><a href="#USL-Net-Uncertainty-Self-Learning-Network-for-Unsupervised-Skin-Lesion-Segmentation" class="headerlink" title="USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation"></a>USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13289">http://arxiv.org/abs/2309.13289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaofan Li, Bo Peng, Daipeng Yang, Zhuyang Xie</li>
<li>for: 这个研究旨在提出一个无监督的皮肤条件分类方法，以解决无监督皮肤条件分类中的挑战。</li>
<li>methods: 本研究使用了自我学习网络（USL-Net），通过对照学习提取特征，然后生成分类对应的活化地图（CAM）来进行分类。高度活化的地图区域表示皮肤条件的重要性，而低度活化的区域则表示背景。</li>
<li>results: 实验结果显示，本方法可以与弱监督和监督方法相比，并且超过其他已有的无监督方法的性能。<details>
<summary>Abstract</summary>
Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-saliency regions represent the background. However, intermediate regions can be hard to classify, often due to their proximity to lesion edges or interference from hair or blisters. Rather than risk potential pseudo-labeling errors or learning confusion by forcefully classifying these regions, we consider them as uncertainty regions, exempting them from pseudo-labeling and allowing the network to self-learn. Further, we employ connectivity detection and centrality detection to refine foreground pseudo-labels and reduce noise-induced errors. The application of cycle refining enhances performance further. Our method underwent thorough experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets, demonstrating that its performance is on par with weakly supervised and supervised methods, and exceeds that of other existing unsupervised methods.
</details>
<details>
<summary>摘要</summary>
无监督皮肤病变分割具有多个优点，如保留专业人员资源、减少主观人类标注的差异和适应新环境。然而，在无人标注指导下对德朗斯科普图像进行分割存在 significanti挑战，主要是因为德朗斯科普图像的艺术ifacts，如毛发噪声、膨涨噪声和细微边缘差异。为解决这些挑战，我们提出了一种创新的不确定自学习网络（USL-Net），用于皮肤病变分割。USL-Net可以有效地分割多种病变，无需人工标注指导。首先，通过对比学习提取特征，然后通过这些特征生成类活动图（CAM）作为saliency map。不同的CAM位置对病变区域的重要性进行标识，高Saliency区域在Map中对病变区域具有高重要性，而低Saliency区域则代表背景。然而，中间区域可能具有困难分类，常常是因为 lesion edge 邻近或毛发/膨涨噪声的干扰。而不要强制性地将这些区域分类为病变区域，我们将其视为不确定区域，并将其除外。此外，我们还使用连接检测和中心检测来改进前景 pseudo-标注和减少噪声引起的错误。通过循环反馈，我们进一步提高性能。我们的方法在 ISIC-2017、ISIC-2018 和 PH2 数据集上进行了严格的实验验证，结果表明其性能与弱监督和监督方法相当，并超过了其他现有的无监督方法。
</details></li>
</ul>
<hr>
<h2 id="Collision-Avoidance-and-Navigation-for-a-Quadrotor-Swarm-Using-End-to-end-Deep-Reinforcement-Learning"><a href="#Collision-Avoidance-and-Navigation-for-a-Quadrotor-Swarm-Using-End-to-end-Deep-Reinforcement-Learning" class="headerlink" title="Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning"></a>Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13285">http://arxiv.org/abs/2309.13285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhehui Huang, Zhaojing Yang, Rahul Krupani, Baskın Şenbaşlar, Sumeet Batra, Gaurav S. Sukhatme</li>
<li>for: 这paper的目的是使用end-to-end深度强化学习控制带有障碍物的四旋翼机器人群体。</li>
<li>methods: 这paper使用的方法包括curriculum学习和归一化缓存，以及对邻居机器人和障碍物的注意机制。</li>
<li>results: 这paper的结果表明，通过使用这些方法，可以在带有障碍物的环境中控制四旋翼机器人群体，并且可以在真实的quadrotor上进行零shot传输。<details>
<summary>Abstract</summary>
End-to-end deep reinforcement learning (DRL) for quadrotor control promises many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80% obstacle density in simulation and 8 robots with 20% obstacle density in physical deployment. Video demonstrations are available on the project website at: https://sites.google.com/view/obst-avoid-swarm-rl.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTEnd-to-end deep reinforcement learning (DRL) for quadrotor control  quadrotor 执行 controller 承诺 many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80% obstacle density in simulation and 8 robots with 20% obstacle density in physical deployment. Video demonstrations are available on the project website at: https://sites.google.com/view/obst-avoid-swarm-rl.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Being-Aware-of-Localization-Accuracy-By-Generating-Predicted-IoU-Guided-Quality-Scores"><a href="#Being-Aware-of-Localization-Accuracy-By-Generating-Predicted-IoU-Guided-Quality-Scores" class="headerlink" title="Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores"></a>Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13269">http://arxiv.org/abs/2309.13269</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/panffeereal/clq">https://github.com/panffeereal/clq</a></li>
<li>paper_authors: Pengfei Liu, Weibo Wang, Yuhan Guo, Jiubin Tan</li>
<li>for: 提高检测性能，通过同时考虑分类分数和地址准确率，提高检测质量。</li>
<li>methods: 采用了新的检测架构，即CLQ，其包括一个简洁的LQE分支，用于获取地址质量分数指导。在训练和推理过程中，LQE分支与分类分支结合在一起，生成一个共同的分类-地址-质量表示。</li>
<li>results: 在COCO测试dev数据集上，CLQ实现了最新的状态艺术性能，具有47.8 AP和11.5 fps的速度，并且在ATSS上进行扩展，实现了可靠的1.2 AP提升。<details>
<summary>Abstract</summary>
Localization Quality Estimation (LQE) helps to improve detection performance as it benefits post processing through jointly considering classification score and localization accuracy. In this perspective, for further leveraging the close relationship between localization accuracy and IoU (Intersection-Over-Union), and for depressing those inconsistent predictions, we designed an elegant LQE branch to acquire localization quality score guided by predicted IoU. Distinctly, for alleviating the inconsistency of classification score and localization quality during training and inference, under which some predictions with low classification scores but high LQE scores will impair the performance, instead of separately and independently setting, we embedded LQE branch into classification branch, producing a joint classification-localization-quality representation. Then a novel one stage detector termed CLQ is proposed. Extensive experiments show that CLQ achieves state-of-the-arts' performance at an accuracy of 47.8 AP and a speed of 11.5 fps with ResNeXt-101 as backbone on COCO test-dev. Finally, we extend CLQ to ATSS, producing a reliable 1.2 AP gain, showing our model's strong adaptability and scalability. Codes are released at https://github.com/PanffeeReal/CLQ.
</details>
<details>
<summary>摘要</summary>
本文提出了一种新的一Stage检测器（CLQ），通过结合分类分支和本地化质量估计（LQE）分支，实现了分类、本地化和质量三者的共同表示。这种方法可以解决在训练和推断过程中分类分数和本地化质量之间的不一致问题，从而提高检测性能。实验表明，CLQ在COCO测试预训练集上达到了47.8 AP的最佳性能和11.5 fps的速度，并且对ATSS进行扩展，实现了可靠的1.2 AP提升。代码可以在github上找到。
</details></li>
</ul>
<hr>
<h2 id="Robust-Navigation-with-Cross-Modal-Fusion-and-Knowledge-Transfer"><a href="#Robust-Navigation-with-Cross-Modal-Fusion-and-Knowledge-Transfer" class="headerlink" title="Robust Navigation with Cross-Modal Fusion and Knowledge Transfer"></a>Robust Navigation with Cross-Modal Fusion and Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13266">http://arxiv.org/abs/2309.13266</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wzcai99/Distill-Navigator">https://github.com/wzcai99/Distill-Navigator</a></li>
<li>paper_authors: Wenzhe Cai, Guangran Cheng, Lingyue Kong, Lu Dong, Changyin Sun</li>
<li>for: 提高机器人Navigation技能的通用化和实际应用（improving the generalization of mobile robot navigation skills and achieving sim-to-real transfer）</li>
<li>methods: 跨模态融合方法和教师学生填充框架（cross-modal fusion method and teacher-student distillation architecture）</li>
<li>results: 比基eline表现出色，在 simulated和实际环境中实现了Robust Navigation性能（outperforms the baselines in both simulated and real-world environments, achieving robust navigation performance with varying working conditions）<details>
<summary>Abstract</summary>
Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions.
</details>
<details>
<summary>摘要</summary>
最近，学习基于方法在导航任务中显示了有前途的结果。然而，低泛化能力和实验室实际差距阻碍了广泛应用。我们对移动机器人的改进泛化和实际协同转移技能的问题进行了考虑。为达到这一目标，我们提出了跨模态融合方法和知识传递框架。这是通过教师学生热退架构实现的。教师在理想环境中学习一个抽象表示和准确策略。通过imiter教师的行为和表示，学生可以将多种不稳定的输入特征相互拟合，并减少导航策略中的变化影响。我们在模拟和实际环境中进行了测试，实验结果表明，我们的方法在基eline上大幅超越，并在不同工作条件下实现了稳定的导航性能。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Chance-Constrained-Submodular-Problems-with-Variable-Uncertainties"><a href="#Optimizing-Chance-Constrained-Submodular-Problems-with-Variable-Uncertainties" class="headerlink" title="Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties"></a>Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14359">http://arxiv.org/abs/2309.14359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiankun Yan, Anh Viet Do, Feng Shi, Xiaoyu Qin, Frank Neumann</li>
<li>for: 这个论文是关于概率性约束限制的实时优化问题的研究，具体来说是关于可变权重项目中的可变概率约束。</li>
<li>methods: 该论文使用了抽象搜索算法和随机搜索算法来解决可变权重项目中的可变概率约束问题。</li>
<li>results: 该论文通过分析和实验表明，使用抽象搜索算法和随机搜索算法可以在可变权重项目中提供高质量的解决方案，具体来说是一个常数近似比例的解决方案。<details>
<summary>Abstract</summary>
Chance constraints are frequently used to limit the probability of constraint violations in real-world optimization problems where the constraints involve stochastic components. We study chance-constrained submodular optimization problems, which capture a wide range of optimization problems with stochastic constraints. Previous studies considered submodular problems with stochastic knapsack constraints in the case where uncertainties are the same for each item that can be selected. However, uncertainty levels are usually variable with respect to the different stochastic components in real-world scenarios, and rigorous analysis for this setting is missing in the context of submodular optimization. This paper provides the first such analysis for this case, where the weights of items have the same expectation but different dispersion. We present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the deterministic setting. In the experiments, we demonstrate that the algorithms perform effectively on several chance-constrained instances of the maximum coverage problem and the influence maximization problem.
</details>
<details>
<summary>摘要</summary>
<font face="宋体">机会约束 frequently 用于限制实际问题中的约束违背 probabilities。我们研究 chance-constrained submodular optimization problems，这些问题涵盖了实际问题中具有恒等约束的变量组合。 previous studies 对 submodular problems with stochastic knapsack constraints 进行了研究，但是在实际情况中，不同的随机成分之间的不确定程度通常是不同的，而这项研究在 submodular optimization 的 context 中缺乏 rigorous analysis。 this paper 提供了 first such analysis for this case，where the weights of items have the same expectation but different dispersion. we present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the deterministic setting. in the experiments, we demonstrate that the algorithms perform effectively on several chance-constrained instances of the maximum coverage problem and the influence maximization problem.</font>Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="WikiMT-Dataset-Card"><a href="#WikiMT-Dataset-Card" class="headerlink" title="WikiMT++ Dataset Card"></a>WikiMT++ Dataset Card</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13259">http://arxiv.org/abs/2309.13259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Monan Zhou, Shangda Wu, Yuan Wang, Wei Li</li>
<li>for: 扩展和改进 WikiMusicText 数据集，用于音乐信息检索、条件音乐生成、自动作曲和情感分类等应用场景。</li>
<li>methods: 添加对象属性（专辑、歌词、视频）和主观情感属性（12种情感词），以及使用 CLaMP 进行属性修正，以提高数据集的准确性和完整性。</li>
<li>results: 提高了 WikiMT 的应用场景和可用性，并且通过添加新的属性和修正原始数据，提高了数据集的准确性和完整性。<details>
<summary>Abstract</summary>
WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.
</details>
<details>
<summary>摘要</summary>
<SYS><TRANSLATE>WikiMT++是 WikiMusicText（WikiMT）的扩展和改进版本，包含1010个精心编辑的领导Sheet在ABCnotation。为扩展 WikiMT 的应用场景，我们添加了对象（专辑、歌词、视频）和主观情感（12种情感形容词）以及 emo\_4q（Russell 4Q）属性，从而提高了音乐信息检索、 conditional music generation、自动作曲和情感分类等方面的可用性。此外，CLaMP 也被实现，以修正从 WikiMT 继承的属性，以降低在原始数据收集过程中引入的错误，提高数据集的准确性和完整性。</TRANSLATE></SYS>Note: "Simplified Chinese" is a romanization of the Chinese language that uses a simplified set of characters and pronunciation. It is commonly used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Defending-Pre-trained-Language-Models-as-Few-shot-Learners-against-Backdoor-Attacks"><a href="#Defending-Pre-trained-Language-Models-as-Few-shot-Learners-against-Backdoor-Attacks" class="headerlink" title="Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks"></a>Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13256">http://arxiv.org/abs/2309.13256</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaohan-xi/plm-prompt-defense">https://github.com/zhaohan-xi/plm-prompt-defense</a></li>
<li>paper_authors: Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang</li>
<li>for: This paper is written to investigate the security risks of pre-trained language models (PLMs) as few-shot learners and to propose a novel defense mechanism called MDP to address these risks.</li>
<li>methods: The paper uses a pilot study to demonstrate the vulnerability of PLMs to backdoor attacks in few-shot scenarios and proposes MDP as a lightweight, pluggable, and effective defense. MDP leverages the gap between the masking-sensitivity of poisoned and clean samples to identify poisoned samples.</li>
<li>results: The paper shows the efficacy of MDP through analytical analysis and empirical evaluation using benchmark datasets and representative attacks. The results demonstrate that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness.<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have demonstrated remarkable performance as few-shot learners. However, their security risks under such settings are largely unexplored. In this work, we conduct a pilot study showing that PLMs as few-shot learners are highly vulnerable to backdoor attacks while existing defenses are inadequate due to the unique challenges of few-shot scenarios. To address such challenges, we advocate MDP, a novel lightweight, pluggable, and effective defense for PLMs as few-shot learners. Specifically, MDP leverages the gap between the masking-sensitivity of poisoned and clean samples: with reference to the limited few-shot data as distributional anchors, it compares the representations of given samples under varying masking and identifies poisoned samples as ones with significant variations. We show analytically that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness. The empirical evaluation using benchmark datasets and representative attacks validates the efficacy of MDP.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Can-I-Trust-the-Explanations-Investigating-Explainable-Machine-Learning-Methods-for-Monotonic-Models"><a href="#Can-I-Trust-the-Explanations-Investigating-Explainable-Machine-Learning-Methods-for-Monotonic-Models" class="headerlink" title="Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models"></a>Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13246">http://arxiv.org/abs/2309.13246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dangxing Chen</li>
<li>for: 这个论文主要针对的是解释性机器学习方法在具有领域知识的模型上的应用。</li>
<li>methods: 这个论文使用了解释性机器学习方法，包括基准值法和集成梯度法，来解释具有领域知识的模型的决策过程。</li>
<li>results: 研究发现，当只有个体偏好 monotonicity 存在时，基准值法可以提供良好的解释；而当强对比 monotonicity 存在时，集成梯度法在平均情况下可以提供相对更好的解释。<details>
<summary>Abstract</summary>
In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UniHead-Unifying-Multi-Perception-for-Detection-Heads"><a href="#UniHead-Unifying-Multi-Perception-for-Detection-Heads" class="headerlink" title="UniHead: Unifying Multi-Perception for Detection Heads"></a>UniHead: Unifying Multi-Perception for Detection Heads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13242">http://arxiv.org/abs/2309.13242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zht8506/unihead">https://github.com/zht8506/unihead</a></li>
<li>paper_authors: Hantao Zhou, Rui Yang, Yachao Zhang, Haoran Duan, Yawen Huang, Runze Hu, Xiu Li, Yefeng Zheng<br>for:This paper aims to improve the object detection performance by developing a novel detection head called UniHead, which unifies three perceptual abilities simultaneously: deformation perception, global perception, and cross-task perception.methods:The proposed UniHead uses a Dual-axial Aggregation Transformer (DAT) to model long-range dependencies and adaptively sample object features, as well as a Cross-task Interaction Transformer (CIT) to facilitate interaction between the classification and localization branches.results:The proposed UniHead achieves significant improvements in object detection performance on the COCO dataset, with +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL, compared to the baseline methods. The code will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/zht8506/UniHead">https://github.com/zht8506/UniHead</a>.<details>
<summary>Abstract</summary>
The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and localization branches, thus aligning the two tasks. As a plug-and-play method, the proposed UniHead can be conveniently integrated with existing detectors. Extensive experiments on the COCO dataset demonstrate that our UniHead can bring significant improvements to many detectors. For instance, the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL. The code will be publicly available. Code Url: https://github.com/zht8506/UniHead.
</details>
<details>
<summary>摘要</summary>
历史头部是目标检测器中的关键组件，负责执行分类和 lokalisierung 功能。可惜，通常使用的并行头部frequentlylacks omni perceptual capabilities, such as deformation perception, global perception, and cross-task perception. Despite numerous methods attempting to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach:1. 引入了形态感知，使模型可以适应性地采样对象特征;2. 提出了 Dual-axial Aggregation Transformer (DAT)，以便模型长距离依赖关系，实现全球感知;3. 设计了 Cross-task Interaction Transformer (CIT)，以便类别和 lokalisierung 分支之间进行交互，使两个任务进行一致。作为一种插件式方法，我们的 UniHead 可以方便地与现有的检测器集成。广泛的实验表明，我们的 UniHead 可以为许多检测器带来显著改进。例如，UniHead 可以在 RetinaNet 中提高 +2.7 AP 得分，在 FreeAnchor 中提高 +2.9 AP 得分，和在 GFL 中提高 +2.1 AP 得分。代码将公开。代码Url：https://github.com/zht8506/UniHead。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Feature-Representation-for-Digital-Twin-Oriented-Complex-Networked-Systems"><a href="#Heterogeneous-Feature-Representation-for-Digital-Twin-Oriented-Complex-Networked-Systems" class="headerlink" title="Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems"></a>Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13229">http://arxiv.org/abs/2309.13229</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial</li>
<li>for: 这项研究旨在提高复杂网络系统（CNS）模型的表达能力，以更好地反映实际世界系统。</li>
<li>methods: 该研究使用了不同的特征表示原则，包括整数特征值和杂化集，以描述节点特征的客观和主观含义。</li>
<li>results: 研究发现，使用杂化集表示法可以提高模型的表达能力，并且不同的特征表示方法会影响网络结构和疫情蔓延速度，需要采取不同的缓冲策略来适应不同人群。<details>
<summary>Abstract</summary>
Building models of Complex Networked Systems (CNS) that can accurately represent reality forms an important research area. To be able to reflect real world systems, the modelling needs to consider not only the intensity of interactions between the entities but also features of all the elements of the system. This study aims to improve the expressive power of node features in Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous feature representation principles. This involves representing features with crisp feature values and fuzzy sets, each describing the objective and the subjective inductions of the nodes' features and feature differences. Our empirical analysis builds DT-CNSs to recreate realistic physical contact networks in different countries from real node feature distributions based on various representation principles and an optimised feature preference. We also investigate their respective disaster resilience to an epidemic outbreak starting from the most popular node. The results suggest that the increasing flexibility of feature representation with fuzzy sets improves the expressive power and enables more accurate modelling. In addition, the heterogeneous features influence the network structure and the speed of the epidemic outbreak, requiring various mitigation policies targeted at different people.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Complex Networked Systems" (CNS) is translated as "复杂网络系统" (CNS) in Simplified Chinese.* "Digital Twin-Oriented Complex Networked Systems" (DT-CNSs) is translated as "数字双向复杂网络系统" (DT-CNSs) in Simplified Chinese.* "heterogeneous feature representation principles" is translated as "不同类型特征表示原则" in Simplified Chinese.* "crisp feature values" is translated as "分割特征值" in Simplified Chinese.* "fuzzy sets" is translated as "柔软集" in Simplified Chinese.* "objective and subjective inductions of the nodes' features" is translated as "节点特征的客观和主观推导" in Simplified Chinese.* "feature differences" is translated as "特征差异" in Simplified Chinese.* "empirical analysis" is translated as "实证分析" in Simplified Chinese.* "physical contact networks" is translated as "物理接触网络" in Simplified Chinese.* "real node feature distributions" is translated as "真实节点特征分布" in Simplified Chinese.* "optimized feature preference" is translated as "优化特征偏好" in Simplified Chinese.* "disaster resilience" is translated as "灾害抗性" in Simplified Chinese.* "epidemic outbreak" is translated as "疫情爆发" in Simplified Chinese.* "most popular node" is translated as "最受欢迎的节点" in Simplified Chinese.* "mitigation policies" is translated as "缓解措施" in Simplified Chinese.* "different people" is translated as "不同人群" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Pick-Planning-Strategies-for-Large-Scale-Package-Manipulation"><a href="#Pick-Planning-Strategies-for-Large-Scale-Package-Manipulation" class="headerlink" title="Pick Planning Strategies for Large-Scale Package Manipulation"></a>Pick Planning Strategies for Large-Scale Package Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13224">http://arxiv.org/abs/2309.13224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Li, Azarakhsh Keipour, Kevin Jamieson, Nicolas Hudson, Sicong Zhao, Charles Swan, Kostas Bekris</li>
<li>for: 提高仓储运作效率，降低物流成本，提高交往速度，提高市场波动的抗性。</li>
<li>methods: 使用Robin营运系统进行大规模包裹排序和单独，每天处理600万个包裹，总共处理20亿个包裹。开发了各种论述方法，其中包括使用实际生产数据训练的抓取质量预测器。</li>
<li>results: 本研究是首次在真实生产环境中大规模应用学习抓取质量预测器。<details>
<summary>Abstract</summary>
Automating warehouse operations can reduce logistics overhead costs, ultimately driving down the final price for consumers, increasing the speed of delivery, and enhancing the resiliency to market fluctuations.   This extended abstract showcases a large-scale package manipulation from unstructured piles in Amazon Robotics' Robot Induction (Robin) fleet, which is used for picking and singulating up to 6 million packages per day and so far has manipulated over 2 billion packages. It describes the various heuristic methods developed over time and their successor, which utilizes a pick success predictor trained on real production data.   To the best of the authors' knowledge, this work is the first large-scale deployment of learned pick quality estimation methods in a real production system.
</details>
<details>
<summary>摘要</summary>
自动化仓库操作可以减少物流成本，最终降低消费者最终价格，提高快递速度，并增强对市场波动的抗颤势。  这个扩展摘要展示了亚马逊 робо拓客（Robin）车队的大规模套件搬运，可以每天搬运Up to 6 million个套件并已经搬运了超过20亿个套件。它描述了不同的论述方法，以及其继承者，该方法使用实际生产数据进行学习套件质量预测。  据作者所知，这是首次在真正生产环境中大规模应用学习套件质量预测方法。
</details></li>
</ul>
<hr>
<h2 id="Hindi-to-English-Transformer-Based-Neural-Machine-Translation"><a href="#Hindi-to-English-Transformer-Based-Neural-Machine-Translation" class="headerlink" title="Hindi to English: Transformer-Based Neural Machine Translation"></a>Hindi to English: Transformer-Based Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13222">http://arxiv.org/abs/2309.13222</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/1502shivam-singh/audio-vision-server">https://github.com/1502shivam-singh/audio-vision-server</a></li>
<li>paper_authors: Kavit Gangar, Hardik Ruparel, Shreyas Lele</li>
<li>for: 这个论文主要针对的是将印度语言希腊语译成英语的自动翻译问题，以提高翻译质量。</li>
<li>methods: 这个论文使用了深度学习技术，特别是Transformer模型，将希腊语译成英语。为了增强数据训练， authors还使用了回训练和字节对编码（BPE）进行 vocabulary 创建和tokenization。</li>
<li>results: 根据IIT Bombay英语-希腊语词库测试集，这个配置达到了当前最佳的BLEU分数24.53。<details>
<summary>Abstract</summary>
Machine Translation (MT) is one of the most prominent tasks in Natural Language Processing (NLP) which involves the automatic conversion of texts from one natural language to another while preserving its meaning and fluency. Although the research in machine translation has been going on since multiple decades, the newer approach of integrating deep learning techniques in natural language processing has led to significant improvements in the translation quality. In this paper, we have developed a Neural Machine Translation (NMT) system by training the Transformer model to translate texts from Indian Language Hindi to English. Hindi being a low resource language has made it difficult for neural networks to understand the language thereby leading to a slow growth in the development of neural machine translators. Thus, to address this gap, we implemented back-translation to augment the training data and for creating the vocabulary, we experimented with both word and subword level tokenization using Byte Pair Encoding (BPE) thereby ending up training the Transformer in 10 different configurations. This led us to achieve a state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay English-Hindi Corpus in one of the configurations.
</details>
<details>
<summary>摘要</summary>
机器翻译（MT）是自然语言处理（NLP）中最为出名的任务之一，它涉及自然语言之间文本的自动转换，保持意思和流畅性。虽然关于机器翻译的研究已经持续多个 décennia，但是在近年来，将深度学习技术应用于自然语言处理领域，带来了对翻译质量的显著改善。在这篇论文中，我们开发了一个基于Transformer模型的神经机器翻译系统，用于从印度语言希ن第语到英语的翻译。由于希第语是一种低资源语言，使得神经网络理解这种语言很困难，因此在神经机器翻译的发展中，进展较为缓慢。为了解决这个问题，我们实施了反向翻译以增加训练数据，并在 vocabulary 创建方面实验了字节对编码（BPE）的两种tokenization策略。经过10种不同的配置训练，我们最终实现了IIT Bombay英语-希第语词库测试集上的state-of-the-art BLEU分数24.53。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.AI_2023_09_23/" data-id="clp9qz7za004dok88hmh7a37a" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.CL_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T11:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.CL_2023_09_23/">cs.CL - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Hierarchical-attention-interpretation-an-interpretable-speech-level-transformer-for-bi-modal-depression-detection"><a href="#Hierarchical-attention-interpretation-an-interpretable-speech-level-transformer-for-bi-modal-depression-detection" class="headerlink" title="Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection"></a>Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13476">http://arxiv.org/abs/2309.13476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingkun Deng, Saturnino Luz, Sofia de la Fuente Garcia</li>
<li>For: The paper aims to improve the accuracy and interpretability of automatic depression detection tools using speech, which can help early screening of depression.* Methods: The proposed bi-modal speech-level transformer model avoids segment-level labelling and provides both speech-level and sentence-level interpretations using gradient-weighted attention maps.* Results: The proposed model outperforms a model that learns at a segment level, with improved accuracy and interpretability. The model can identify the most relevant sentences and text tokens within a given speech that are indicative of depression.<details>
<summary>Abstract</summary>
Depression is a common mental disorder. Automatic depression detection tools using speech, enabled by machine learning, help early screening of depression. This paper addresses two limitations that may hinder the clinical implementations of such tools: noise resulting from segment-level labelling and a lack of model interpretability. We propose a bi-modal speech-level transformer to avoid segment-level labelling and introduce a hierarchical interpretation approach to provide both speech-level and sentence-level interpretations, based on gradient-weighted attention maps derived from all attention layers to track interactions between input features. We show that the proposed model outperforms a model that learns at a segment level ($p$=0.854, $r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model interpretation, using one true positive sample, we show which sentences within a given speech are most relevant to depression detection; and which text tokens and Mel-spectrogram regions within these sentences are most relevant to depression detection. These interpretations allow clinicians to verify the validity of predictions made by depression detection tools, promoting their clinical implementations.
</details>
<details>
<summary>摘要</summary>
抑郁是一种常见的心理疾病。使用机器学习技术实现的自动抑郁检测工具可以帮助早期检测抑郁。这篇论文解决了两个可能阻碍临床应用的限制： segment-level 标注导致的噪音和模型解释性不足。我们提议使用双模块的speech-level transformer来避免 segment-level 标注，并提出一种层次解释方法，以提供 both speech-level 和 sentence-level 的解释，基于所有注意层的梯度权重注意力地图来跟踪输入特征之间的交互。我们表明，提议的模型在比较 segment level 学习的模型（$p$=0.732， $r$=0.808， $F1$=0.768）的情况下表现出色，其中 $p$=0.854， $r$=0.947， $F1$=0.897。为了解释模型，我们使用一个真正正确的样本，显示某些speech中的哪些句子是抑郁检测中最重要的，以及哪些文本字符和 Mel-spectrogram 区域在这些句子中对抑郁检测最重要。这些解释可以帮助临床专业人员验证抑郁检测工具的预测结果，从而促进其临床应用。
</details></li>
</ul>
<hr>
<h2 id="Grounding-Description-Driven-Dialogue-State-Trackers-with-Knowledge-Seeking-Turns"><a href="#Grounding-Description-Driven-Dialogue-State-Trackers-with-Knowledge-Seeking-Turns" class="headerlink" title="Grounding Description-Driven Dialogue State Trackers with Knowledge-Seeking Turns"></a>Grounding Description-Driven Dialogue State Trackers with Knowledge-Seeking Turns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13448">http://arxiv.org/abs/2309.13448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandru Coca, Bo-Hsiang Tseng, Jinghong Chen, Weizhe Lin, Weixuan Zhang, Tisha Anders, Bill Byrne</li>
<li>for: 提高对话管理模型的稳定性和泛化能力</li>
<li>methods: 使用对话 corpora 和知识图来固定状态跟踪模型，并在推理和训练过程中添加知识图 turns</li>
<li>results: 对比原始模型，新的方法可以大幅提高对话管理模型的平均共同目标准确率和schema敏感度<details>
<summary>Abstract</summary>
Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control. We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.
</details>
<details>
<summary>摘要</summary>
Schema-guided dialogue state trackers可以通过新领域掌握而无需进一步训练，但它们受到文本风格的影响很sensitive。增加训练集中的人工或 sintetic schema paraphrase可以提高模型的可靠性，但这可能会成本高或控制困难。我们提议通过将知识寻求turns集成到对话 corpus和schema中来固定状态跟踪模型。在训练和推理中包含这些turns的提问可以获得显著改进，如joint目标准确率和schema敏感度的提高，如SGD和SGD-X所示。
</details></li>
</ul>
<hr>
<h2 id="My-Science-Tutor-MyST-–-A-Large-Corpus-of-Children’s-Conversational-Speech"><a href="#My-Science-Tutor-MyST-–-A-Large-Corpus-of-Children’s-Conversational-Speech" class="headerlink" title="My Science Tutor (MyST) – A Large Corpus of Children’s Conversational Speech"></a>My Science Tutor (MyST) – A Large Corpus of Children’s Conversational Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13347">http://arxiv.org/abs/2309.13347</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sameer S. Pradhan, Ronald A. Cole, Wayne H. Ward</li>
<li>for: This paper describes the development of the MyST corpus, a large collection of children’s conversational speech, which can be used to improve automatic speech recognition algorithms, build and evaluate conversational AI agents for education, and develop multimodal applications to improve children’s learning.</li>
<li>methods: The MyST corpus was developed as part of the My Science Tutor project, which involves 100K utterances transcribed from approximately 10.5K virtual tutor sessions by 1.3K third, fourth, and fifth grade students. The corpus is available for non-commercial and commercial use under a creative commons license.</li>
<li>results: To date, ten organizations have licensed the corpus for commercial use, and approximately 40 university and other not-for-profit research groups have downloaded the corpus. The corpus has the potential to be used to improve children’s learning and excitement about science, and to help them learn remotely.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文描述了MyST corpus的开发，这是一个儿童对话语音集，可以用于改进自动语音识别算法、建立和评估教育机器人、并开发多Modal应用程序，以提高儿童学习科学的兴趣和成就。</li>
<li>methods: MyST corpus是My Science Tutor项目的一部分，涉及100万句话的对话语音，来自约10.5万个虚拟导师会议，由1.3万名第三、四、五年级学生提供。这个 corpus 是可以免费使用（<a target="_blank" rel="noopener" href="https://myst.cemantix.org),也可以用于商业用途(https//boulderlearning.com/resources/myst-corpus/%EF%BC%89%E3%80%82%E5%88%B0%E7%9B%AE%E5%89%8D%E4%B8%BA%E6%AD%A2%EF%BC%8C%E6%9C%89%E5%8D%81%E5%AE%B6%E7%BB%84%E7%BB%87%E5%B7%B2%E7%BB%8F%E8%B4%AD%E4%B9%B0%E4%BA%86%E8%BF%99%E4%B8%AA">https://myst.cemantix.org），也可以用于商业用途（https://boulderlearning.com/resources/myst-corpus/）。到目前为止，有十家组织已经购买了这个</a> corpus 的商业授权，并且有约40个大学和其他非营利研究机构下载了这个 corpus。</li>
<li>results: 这个 corpus 的开发可以用于改进儿童学习科学的方法，并且可以帮助儿童在远程学习中学习更好地。到目前为止，有十家组织已经购买了这个 corpus 的商业授权，并且有约40个大学和其他非营利研究机构下载了这个 corpus。<details>
<summary>Abstract</summary>
This article describes the MyST corpus developed as part of the My Science Tutor project -- one of the largest collections of children's conversational speech comprising approximately 400 hours, spanning some 230K utterances across about 10.5K virtual tutor sessions by around 1.3K third, fourth and fifth grade students. 100K of all utterances have been transcribed thus far. The corpus is freely available (https://myst.cemantix.org) for non-commercial use using a creative commons license. It is also available for commercial use (https://boulderlearning.com/resources/myst-corpus/). To date, ten organizations have licensed the corpus for commercial use, and approximately 40 university and other not-for-profit research groups have downloaded the corpus. It is our hope that the corpus can be used to improve automatic speech recognition algorithms, build and evaluate conversational AI agents for education, and together help accelerate development of multimodal applications to improve children's excitement and learning about science, and help them learn remotely.
</details>
<details>
<summary>摘要</summary>
这篇文章介绍了MyST资料集，这是My Science Tutor项目中的一个大型儿童对话语音资料集，包含约400个小时的对话语音，涵盖约230万个语音词汇，分别来自约1.3万名第三、四、五年级学生的10.5万个虚拟教学会话。目前已经转录100万个语音。MyST资料集是免费使用（https://myst.cemantix.org），通过创意共用许可证，用于非商业用途。同时，也可以用于商业用途（https://boulderlearning.com/resources/myst-corpus/），至今已有10家组织购买了商业许可证。我们希望通过这些资料来提高自动语音识别算法，建立和评估教育对话AI代理人，以及在远程学习方面提高儿童对科学的兴趣和学习。
</details></li>
</ul>
<hr>
<h2 id="BAMBOO-A-Comprehensive-Benchmark-for-Evaluating-Long-Text-Modeling-Capacities-of-Large-Language-Models"><a href="#BAMBOO-A-Comprehensive-Benchmark-for-Evaluating-Long-Text-Modeling-Capacities-of-Large-Language-Models" class="headerlink" title="BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models"></a>BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13345">http://arxiv.org/abs/2309.13345</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rucaibox/bamboo">https://github.com/rucaibox/bamboo</a></li>
<li>paper_authors: Zican Dong, Tianyi Tang, Junyi Li, Wayne Xin Zhao, Ji-Rong Wen</li>
<li>for: 本研究旨在评估大型自然语言处理（NLP）模型在长文本理解任务上的能力，并提供多任务长文本测试集（BAMBOO）。</li>
<li>methods: 本研究使用了五种长文本模型，在BAMBOO上进行了实验，并评估了这些模型在不同任务上的性能。</li>
<li>results: 研究发现，现有的长文本模型在某些任务上表现出色，但在其他任务上表现较差。研究还指出了未来可以采取的方法来提高长文本模型的能力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have achieved dramatic proficiency over NLP tasks with normal length. Recently, multiple studies have committed to extending the context length and enhancing the long text modeling capabilities of LLMs. To comprehensively evaluate the long context ability of LLMs, we propose BAMBOO, a multi-task long context benchmark. BAMBOO has been designed with four principles: comprehensive capacity evaluation, avoidance of data contamination, accurate automatic evaluation, and different length levels. It consists of 10 datasets from 5 different long text understanding tasks, i.e. question answering, hallucination detection, text sorting, language modeling, and code completion, to cover core capacities and various domains of LLMs. We conduct experiments with five long context models on BAMBOO and further discuss four key research questions of long text. We also qualitatively analyze current long context models and point out future directions for enhancing long text modeling capacities. We release our data, prompts, and code at https://github.com/RUCAIBox/BAMBOO.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经在普通长度的NLPT任务上达到了戏剑性能。在最近的几项研究中，研究者们努力扩展了LLM的上下文长度和长文本模型化能力。为全面评估LLM的长文本能力，我们提出了BAMBOO，一个多任务长文本benchmark。BAMBOO遵循四个原则：全面评估能力、数据污染避免、自动评估精度和不同长度级别。它包括10个来自5个不同长文理解任务的数据集，例如问答、幻觉检测、文本排序、语言模型和代码完成等，以覆盖LLM的核心能力和不同领域。我们在BAMBOO上进行了5个长文本模型的实验，并讨论了长文本模型的四个关键研究问题。我们还进行了现有长文本模型的Qualitative分析，并指出了未来扩展长文本模型能力的方向。我们在GitHub上发布了数据、提示和代码，请参考https://github.com/RUCAIBox/BAMBOO。
</details></li>
</ul>
<hr>
<h2 id="From-Text-to-Source-Results-in-Detecting-Large-Language-Model-Generated-Content"><a href="#From-Text-to-Source-Results-in-Detecting-Large-Language-Model-Generated-Content" class="headerlink" title="From Text to Source: Results in Detecting Large Language Model-Generated Content"></a>From Text to Source: Results in Detecting Large Language Model-Generated Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13322">http://arxiv.org/abs/2309.13322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Wissam Antoun, Benoît Sagot, Djamé Seddah</li>
<li>for: 本研究旨在 investigate Cross-Model Detection，探讨一个基于源LM的泛型分类器是否可以探测目标LM生成的文本。</li>
<li>methods: 本研究使用了多种LM大小和家族，并评估了对分类器泛化的影响。</li>
<li>results: 研究发现，模型大小与泛型分类器效果之间存在明显的反相关关系，大LM更难于探测，特别是当泛型分类器在小LM上训练时。同时，使用相同大小LM的数据进行训练可以提高大LM的探测性能，但可能会导致小LM的性能下降。模型归因实验也表明，LM生成的文本中含有可识别的签名特征。<details>
<summary>Abstract</summary>
The widespread use of Large Language Models (LLMs), celebrated for their ability to generate human-like text, has raised concerns about misinformation and ethical implications. Addressing these concerns necessitates the development of robust methods to detect and attribute text generated by LLMs. This paper investigates "Cross-Model Detection," evaluating whether a classifier trained to distinguish between source LLM-generated and human-written text can also detect text from a target LLM without further training. The study comprehensively explores various LLM sizes and families, and assesses the impact of conversational fine-tuning techniques on classifier generalization. The research also delves into Model Attribution, encompassing source model identification, model family classification, and model size classification. Our results reveal several key findings: a clear inverse relationship between classifier effectiveness and model size, with larger LLMs being more challenging to detect, especially when the classifier is trained on data from smaller models. Training on data from similarly sized LLMs can improve detection performance from larger models but may lead to decreased performance when dealing with smaller models. Additionally, model attribution experiments show promising results in identifying source models and model families, highlighting detectable signatures in LLM-generated text. Overall, our study contributes valuable insights into the interplay of model size, family, and training data in LLM detection and attribution.
</details>
<details>
<summary>摘要</summary>
广泛使用大型语言模型（LLM），被夸大为能生成人类语言文本的能力，已引起关于误导和伦理问题的担忧。为解决这些问题，需要开发robust的检测和归因方法。本文研究“交叉模型检测”，检查一个基于源LLM生成文本和人类写作文本的分类器能否检测目标LLM生成的文本。研究全面探讨了不同的LLM大小和家族，以及对分类器泛化的影响。研究还探讨了模型归因，包括来源模型标识、模型家族分类和模型大小分类。我们的结果显示了一些关键发现：与分类器效果相对关系，大型LLM更难于检测，特别是当分类器被训练使用小型LLM的数据时。使用同样大小的LLM数据进行训练可以提高大型LLM的检测性能，但可能导致对小型LLM的性能下降。此外，模型归因实验显示了LLM生成文本中的可察性特征，这些特征可以用于归因LLM。总的来说，我们的研究为LLM检测和归因提供了有价值的发现。
</details></li>
</ul>
<hr>
<h2 id="GlotScript-A-Resource-and-Tool-for-Low-Resource-Writing-System-Identification"><a href="#GlotScript-A-Resource-and-Tool-for-Low-Resource-Writing-System-Identification" class="headerlink" title="GlotScript: A Resource and Tool for Low Resource Writing System Identification"></a>GlotScript: A Resource and Tool for Low Resource Writing System Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13320">http://arxiv.org/abs/2309.13320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cisnlp/GlotScript">https://github.com/cisnlp/GlotScript</a></li>
<li>paper_authors: Amir Hossein Kargaran, François Yvon, Hinrich Schütze</li>
<li>for: 用于identifying low-resource writing systems</li>
<li>methods: 使用存储的writing system resources和Unicode 15.0 scripts</li>
<li>results: 支持清理多语言 corpus和分析语言模型的TokenizationHere’s the same information in Simplified Chinese:</li>
<li>for: 用于识别低资源文字系统</li>
<li>methods: 使用存储的文字系统资源和Unicode 15.0 字体</li>
<li>results: 支持清理多语言 corpus和分析语言模型的Tokenization<details>
<summary>Abstract</summary>
We present GlotScript, an open resource and tool for low resource writing system identification. GlotScript-R is a resource that provides the attested writing systems for more than 7,000 languages. It is compiled by aggregating information from existing writing system resources. GlotScript-T is a writing system identification tool that covers all 161 Unicode 15.0 scripts. For an input text, it returns its script distribution where scripts are identified by ISO 15924 codes. We also present two use cases for GlotScript. First, we demonstrate that GlotScript supports cleaning multilingual corpora such as mC4 and OSCAR. Second, we analyze the tokenization of a number of language models such as GPT-4 using GlotScript and provide insights on the coverage of low resource scripts and languages by each language model. We hope that GlotScript will become a useful resource for work on low resource languages in the NLP community. GlotScript-R and GlotScript-T are available at https://github.com/cisnlp/GlotScript.
</details>
<details>
<summary>摘要</summary>
我们介绍GlotScript，一个开源资源和工具，用于低资源文字系统识别。GlotScript-R是一个提供了超过7,000种语言的验证文字系统资源。它通过将现有文字系统资源集成起来编译而成。GlotScript-T是一个可以识别所有Unicode 15.0 编码中的161种文字系统的写作系统识别工具。对于输入文本，它返回该文本的文字系统分布，并将文字系统用ISO 15924 编码来标识。我们还介绍了GlotScript的两个使用场景。首先，我们示例了GlotScript可以清洁多语言 corpus，如mC4和OSCAR。其次，我们分析了一些语言模型，如GPT-4，使用GlotScript进行分词，并提供了低资源文字和语言的覆盖率的视图。我们希望GlotScript可以成为NPLTcommunity中工作低资源语言的有用资源。GlotScript-R和GlotScript-T可以在https://github.com/cisnlp/GlotScript 上获取。
</details></li>
</ul>
<hr>
<h2 id="Spanish-Resource-Grammar-version-2023"><a href="#Spanish-Resource-Grammar-version-2023" class="headerlink" title="Spanish Resource Grammar version 2023"></a>Spanish Resource Grammar version 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13318">http://arxiv.org/abs/2309.13318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olga Zamaraeva, Carlos Gómez-Rodríguez</li>
<li>for: 这个论文是为了语言研究和自然语言处理应用开发而写的。</li>
<li>methods: 这个论文使用了最新版本的Freeling morphological analyzer和tagger，并提供了手动验证的treebank和问题列表。</li>
<li>results: 这个论文提供了一个新的研究方向，并在一小部分学习 corpus 上测试了 grammar 的覆盖率和过度生成。<details>
<summary>Abstract</summary>
We present the latest version of the Spanish Resource Grammar (SRG). The new SRG uses the recent version of Freeling morphological analyzer and tagger and is accompanied by a manually verified treebank and a list of documented issues. We also present the grammar's coverage and overgeneration on a small portion of a learner corpus, an entirely new research line with respect to the SRG. The grammar can be used for linguistic research, such as for empirically driven development of syntactic theory, and in natural language processing applications such as computer-assisted language learning. Finally, as the treebanks grow, they can be used for training high-quality semantic parsers and other systems which may benefit from precise and detailed semantics.
</details>
<details>
<summary>摘要</summary>
我们现在发布最新版的西班牙资源语法（SRG）。新的SRG使用了最新版的Freeling morphological analyzer和标注器，并附有手动验证的树链和问题列表。我们还对一小部分学习语料进行了覆盖率和过度生成的测试，这是SRG的全新研究方向。这个语法可以用于语言科研，如逐渐驱动发展 syntax理论，以及自然语言处理应用，如计算机助教语言学习。随着树链的增长，它们可以用于训练高质量semantic parser和其他可能受益于精确和详细 semantics的系统。
</details></li>
</ul>
<hr>
<h2 id="Calibrating-LLM-Based-Evaluator"><a href="#Calibrating-LLM-Based-Evaluator" class="headerlink" title="Calibrating LLM-Based Evaluator"></a>Calibrating LLM-Based Evaluator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13308">http://arxiv.org/abs/2309.13308</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang</li>
<li>for: 这 paper 的目的是提出一种自动调整和人类偏好Alignment的方法，以便使用大型自然语言模型（LLM）进行自然语言生成质量评估。</li>
<li>methods: 该方法包括Multi-stage, gradient-free Approach，首先在不同的几个阶段中使用语言模型自己学习不同的几个例子，然后选择最佳表现者进行自我反调。</li>
<li>results: 对多个文本质量评估数据集进行实验，显示该方法可以有效地提高与专家评估的相关性。同时，对于各种有效的评价标准的Qualitative分析提供了深入的直观启示和观察。<details>
<summary>Abstract</summary>
Recent advancements in large language models (LLMs) on language modeling and emergent capabilities make them a promising reference-free evaluator of natural language generation quality, and a competent alternative to human evaluation. However, hindered by the closed-source or high computational demand to host and tune, there is a lack of practice to further calibrate an off-the-shelf LLM-based evaluator towards better human alignment. In this work, we propose AutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate and align an LLM-based evaluator toward human preference. Instead of explicitly modeling human preferences, we first implicitly encompass them within a set of human labels. Then, an initial set of scoring criteria is drafted by the language model itself, leveraging in-context learning on different few-shot examples. To further calibrate this set of criteria, we select the best performers and re-draft them with self-refinement. Our experiments on multiple text quality evaluation datasets illustrate a significant improvement in correlation with expert evaluation through calibration. Our comprehensive qualitative analysis conveys insightful intuitions and observations on the essence of effective scoring criteria.
</details>
<details>
<summary>摘要</summary>
近期大语言模型（LLM）的进步在语言生成质量评估方面，使得它们成为了无参考的自然语言评估器和人类评估器的有力竞争对手。然而，由于某些原因，很多LLM-based评估器受到了封闭的源代码或高计算需求的限制，导致它们的评估器没有得到进一步的精心调整。在这项工作中，我们提出了一种多stage、gradient-free的自动调整方法，以使得LLM-based评估器更加准确地对应人类的喜好。而不是直接模型人类喜好，我们将人类标签集成到了一个集合中，然后由语言模型自己提出了初始的评估标准。然后，我们选择了最佳表现者，并通过自我修复来重新绘制这些标准。我们在多个文本质量评估数据集上进行了多项实验，并证明了与专家评估的强相关性。我们还提供了深入的Qualitative分析，帮助理解有效的评估标准的本质。
</details></li>
</ul>
<hr>
<h2 id="OATS-Opinion-Aspect-Target-Sentiment-Quadruple-Extraction-Dataset-for-Aspect-Based-Sentiment-Analysis"><a href="#OATS-Opinion-Aspect-Target-Sentiment-Quadruple-Extraction-Dataset-for-Aspect-Based-Sentiment-Analysis" class="headerlink" title="OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis"></a>OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for Aspect-Based Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13297">http://arxiv.org/abs/2309.13297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siva Uday Sampreeth Chebolu, Franck Dernoncourt, Nedim Lipka, Thamar Solorio</li>
<li>for: 本研究旨在掌握用户生成的评论中的具体元素之情感分析，以提高对文本内容的情感分析和评估。</li>
<li>methods: 本研究使用了新的OATS dataset，包括三个新领域的评论，以及20,000个句子四重和13,000个评论二重。实验还包括了内部和跨领域的实验，以探索不同的ABSA子 зада业和OATS的潜力。</li>
<li>results: 本研究通过实验获得了OATSdataset的初步基线，并证明了OATS可以解决现有的ABSA领域问题，例如餐厅和笔记型评价等领域的问题。<details>
<summary>Abstract</summary>
Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments specific to distinct elements within textual content. It aims to analyze user-generated reviews to determine a) the target entity being reviewed, b) the high-level aspect to which it belongs, c) the sentiment words used to express the opinion, and d) the sentiment expressed toward the targets and the aspects. While various benchmark datasets have fostered advancements in ABSA, they often come with domain limitations and data granularity challenges. Addressing these, we introduce the OATS dataset, which encompasses three fresh domains and consists of 20,000 sentence-level quadruples and 13,000 review-level tuples. Our initiative seeks to bridge specific observed gaps: the recurrent focus on familiar domains like restaurants and laptops, limited data for intricate quadruple extraction tasks, and an occasional oversight of the synergy between sentence and review-level sentiments. Moreover, to elucidate OATS's potential and shed light on various ABSA subtasks that OATS can solve, we conducted in-domain and cross-domain experiments, establishing initial baselines. We hope the OATS dataset augments current resources, paving the way for an encompassing exploration of ABSA.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Natural-Language-Processing-for-Requirements-Formalization-How-to-Derive-New-Approaches"><a href="#Natural-Language-Processing-for-Requirements-Formalization-How-to-Derive-New-Approaches" class="headerlink" title="Natural Language Processing for Requirements Formalization: How to Derive New Approaches?"></a>Natural Language Processing for Requirements Formalization: How to Derive New Approaches?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13272">http://arxiv.org/abs/2309.13272</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ifak-prototypes/nlp_reform">https://github.com/ifak-prototypes/nlp_reform</a></li>
<li>paper_authors: Viju Sudhi, Libin Kutty, Robin Gröpler<br>for: 本研究旨在提供一种 semi-自动化的需求ormalization方法，以帮助industry和研究人员尽可能自动化软件开发和测试过程。methods: 本研究使用自然语言处理（NLP）技术，包括创建规则集和iterative开发rule sets，以自动化需求ormalization过程。results: 研究表明，使用现有的预训练NLP模型可以减少创建规则集的努力，并且可以轻松适应特定用例和领域。两个 industriuse cases from the automotive and railway domains are used to demonstrate the effectiveness of the proposed methods.<details>
<summary>Abstract</summary>
It is a long-standing desire of industry and research to automate the software development and testing process as much as possible. In this process, requirements engineering (RE) plays a fundamental role for all other steps that build on it. Model-based design and testing methods have been developed to handle the growing complexity and variability of software systems. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. Numerous approaches based on natural language processing (NLP) have been proposed in the literature to generate requirements models using mainly syntactic properties. Recent advances in NLP show that semantic quantities can also be identified and used to provide better assistance in the requirements formalization process. In this work, we present and discuss principal ideas and state-of-the-art methodologies from the field of NLP in order to guide the readers on how to create a set of rules and methods for the semi-automated formalization of requirements according to their specific use case and needs. We discuss two different approaches in detail and highlight the iterative development of rule sets. The requirements models are represented in a human- and machine-readable format in the form of pseudocode. The presented methods are demonstrated on two industrial use cases from the automotive and railway domains. It shows that using current pre-trained NLP models requires less effort to create a set of rules and can be easily adapted to specific use cases and domains. In addition, findings and shortcomings of this research area are highlighted and an outlook on possible future developments is given.
</details>
<details>
<summary>摘要</summary>
industry和研究界长期希望自动化软件开发和测试过程，并且需求工程（RE）在这些步骤上扮演了基本角色。基于模型的设计和测试方法已经为软件系统的增长复杂性和可变性提供了解决方案。然而，从大量函циональ需求提供的自然语言处理（NLP）技术仍然需要大量的努力来生成需求模型。在文献中，许多基于NLP的方法已经被提出，主要基于语法特征来生成需求模型。然而，现在的NLP进步还表明可以利用semantic量来提供更好的帮助在需求正式化过程中。在这个工作中，我们将介绍和讨论一些在NLP领域的主要想法和现状技术，以帮助读者创建一套 semi-自动化需求正式化的规则和方法。我们在详细介绍了两种方法，并强调了迭代发展规则集的重要性。需求模型被表示为人类和机器可读的形式，即pseudocode。我们的方法在两个工业用例中（来自汽车和铁路领域）得到了证明，显示使用当前预训练的NLP模型需要较少的努力来创建规则集，并且可以轻松地适应特定用例和领域。此外，我们还高亮了这个研究领域的发现和缺陷，并提供了未来可能发展的前景。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Document-Level-Information-Extraction"><a href="#A-Survey-of-Document-Level-Information-Extraction" class="headerlink" title="A Survey of Document-Level Information Extraction"></a>A Survey of Document-Level Information Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13249">http://arxiv.org/abs/2309.13249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Don-No7/Hack-SQL">https://github.com/Don-No7/Hack-SQL</a></li>
<li>paper_authors: Hanwen Zheng, Sijia Wang, Lifu Huang</li>
<li>for: 本文是一篇文献综述，旨在为NLП领域的研究人员提供更多的启示，以进一步提高文档级别的自然语言处理（NLP）性能。</li>
<li>methods: 本文使用了现有的国际先进算法进行了系统性的错误分析，并识别了当前的限制和NLП领域的留下的挑战。</li>
<li>results: 根据我们的发现，标注噪音、实体核心匹配和无理解能力是文档级别IE性能的主要限制因素。<details>
<summary>Abstract</summary>
Document-level information extraction (IE) is a crucial task in natural language processing (NLP). This paper conducts a systematic review of recent document-level IE literature. In addition, we conduct a thorough error analysis with current state-of-the-art algorithms and identify their limitations as well as the remaining challenges for the task of document-level IE. According to our findings, labeling noises, entity coreference resolution, and lack of reasoning, severely affect the performance of document-level IE. The objective of this survey paper is to provide more insights and help NLP researchers to further enhance document-level IE performance.
</details>
<details>
<summary>摘要</summary>
文档级信息提取（IE）是自然语言处理（NLP）中关键的任务。本文进行了最新文档级IE литературе的系统性评审。此外，我们还进行了当前状态的算法评估，并确定了现有算法的局限性以及文档级IE任务中仍存在的挑战。根据我们的发现，标注噪音、实体核心归并和不足的逻辑，对文档级IE性能产生了严重的影响。本文的目标是为NLP研究人员提供更多的洞察和帮助，以进一步提高文档级IE性能。
</details></li>
</ul>
<hr>
<h2 id="ChEDDAR-Student-ChatGPT-Dialogue-in-EFL-Writing-Education"><a href="#ChEDDAR-Student-ChatGPT-Dialogue-in-EFL-Writing-Education" class="headerlink" title="ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education"></a>ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13243">http://arxiv.org/abs/2309.13243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jieun Han, Haneul Yoo, Junho Myung, Minsun Kim, Tak Yeon Lee, So-Yeon Ahn, Alice Oh</li>
<li>for: 这个研究旨在探讨大规模实际场景下学生和AI系统之间的交互，以推动教育领域中AI生成技术的应用。</li>
<li>methods: 这个研究使用了对212名英语为外语学生进行了一个学期长的实验，他们被要求通过对ChatGPT进行对话来修改他们的作业。研究收集了对话记录、utterance-level作业修改历史、自我评价和学生的意图，以及每个会话的前后调查记录学生的目标和总体经验。</li>
<li>results: 研究发现学生在使用生成AI时的使用模式和满意度与他们的意图有直接关系，并提出了基准结果为两个关键任务在教育上的对话系统中：意图检测和满意度估计。研究建议进一步调整教育中AI生成技术的应用，并提出了可能的使用Scenario使用ChEDDAR。ChEDDAR公共可用于<a target="_blank" rel="noopener" href="https://github.com/zeunie/ChEDDAR%E3%80%82">https://github.com/zeunie/ChEDDAR。</a><details>
<summary>Abstract</summary>
The integration of generative AI in education is expanding, yet empirical analyses of large-scale, real-world interactions between students and AI systems still remain limited. In this study, we present ChEDDAR, ChatGPT & EFL Learner's Dialogue Dataset As Revising an essay, which is collected from a semester-long longitudinal experiment involving 212 college students enrolled in English as Foreign Langauge (EFL) writing courses. The students were asked to revise their essays through dialogues with ChatGPT. ChEDDAR includes a conversation log, utterance-level essay edit history, self-rated satisfaction, and students' intent, in addition to session-level pre-and-post surveys documenting their objectives and overall experiences. We analyze students' usage patterns and perceptions regarding generative AI with respect to their intent and satisfaction. As a foundational step, we establish baseline results for two pivotal tasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation. We finally suggest further research to refine the integration of generative AI into education settings, outlining potential scenarios utilizing ChEDDAR. ChEDDAR is publicly available at https://github.com/zeunie/ChEDDAR.
</details>
<details>
<summary>摘要</summary>
整合生成AI在教育中的推广正在进行，但实际的大规模实验却仍然受到限制。本研究公布了ChEDDAR，ChatGPT & EFL Learner's Dialogue Dataset As Revising an essay，这是基于一个半年长的实验，其中212名大学生参与了英语作为外语写作课程。这些学生被要求通过对ChatGPT的对话来修改他们的文章。ChEDDAR包括对话记录、文章修改历史记录、自我评价满意度，以及学生的意图，以及每个会话的前后调查，记录了学生的目标和总体体验。我们分析学生对生成AI的使用方式和满意度的关系，并为两个关键任务在教育上的对话系统提供基线结果：检测意图和满意度估计。最后，我们建议进一步推进生成AI的教育集成，并提出了可能的应用场景，使用ChEDDAR可以在https://github.com/zeunie/ChEDDAR获取。
</details></li>
</ul>
<hr>
<h2 id="User-Simulation-with-Large-Language-Models-for-Evaluating-Task-Oriented-Dialogue"><a href="#User-Simulation-with-Large-Language-Models-for-Evaluating-Task-Oriented-Dialogue" class="headerlink" title="User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue"></a>User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13233">http://arxiv.org/abs/2309.13233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Davidson, Salvatore Romeo, Raphael Shu, James Gung, Arshit Gupta, Saab Mansour, Yi Zhang</li>
<li>for: 提高自动评估新任务对话系统（TOD）的发展，避免人工评估的多个阶段和迭代过程中的阻碍。</li>
<li>methods: 使用最近发展的大型预训练语言模型（LLM）建立新的用户模拟器，通过受 Context 学习提高语言多样性，模拟人类对话伙伴的行为。</li>
<li>results: 比前一工作更高的语言多样性和语义多样性，能够与多个 TOD 系统进行有效交流，尤其是单意对话目标，而且生成的语音和语法多样性比前一工作更高。<details>
<summary>Abstract</summary>
One of the major impediments to the development of new task-oriented dialogue (TOD) systems is the need for human evaluation at multiple stages and iterations of the development process. In an effort to move toward automated evaluation of TOD, we propose a novel user simulator built using recently developed large pretrained language models (LLMs). In order to increase the linguistic diversity of our system relative to the related previous work, we do not fine-tune the LLMs used by our system on existing TOD datasets; rather we use in-context learning to prompt the LLMs to generate robust and linguistically diverse output with the goal of simulating the behavior of human interlocutors. Unlike previous work, which sought to maximize goal success rate (GSR) as the primary metric of simulator performance, our goal is a system which achieves a GSR similar to that observed in human interactions with TOD systems. Using this approach, our current simulator is effectively able to interact with several TOD systems, especially on single-intent conversational goals, while generating lexically and syntactically diverse output relative to previous simulators that rely upon fine-tuned models. Finally, we collect a Human2Bot dataset of humans interacting with the same TOD systems with which we experimented in order to better quantify these achievements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unify-word-level-and-span-level-tasks-NJUNLP’s-Participation-for-the-WMT2023-Quality-Estimation-Shared-Task"><a href="#Unify-word-level-and-span-level-tasks-NJUNLP’s-Participation-for-the-WMT2023-Quality-Estimation-Shared-Task" class="headerlink" title="Unify word-level and span-level tasks: NJUNLP’s Participation for the WMT2023 Quality Estimation Shared Task"></a>Unify word-level and span-level tasks: NJUNLP’s Participation for the WMT2023 Quality Estimation Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13230">http://arxiv.org/abs/2309.13230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njunlp/njuqe">https://github.com/njunlp/njuqe</a></li>
<li>paper_authors: Xiang Geng, Zhejian Lai, Yu Zhang, Shimin Tao, Hao Yang, Jiajun Chen, Shujian Huang</li>
<li>for: 这个研究是为了提出一种基于NJUQE框架的pseudo数据方法，以提高 Machine Translation 的质量预测（QE）性能。</li>
<li>methods: 该研究使用了Parallel Data从WMT翻译任务中生成pseudo MQM数据，然后使用XLMR大型模型在pseudo QE数据上进行预训练，并在实际QE数据上进行细化调整。同时，该研究jointly学习了句子级分数和单词级标签。</li>
<li>results: 该研究在英文-德文语对的 sentence-level和word-level质量预测两个子任务上达到了最佳性能，在两个子任务上的margin上提高了较大的性能。<details>
<summary>Abstract</summary>
We introduce the submissions of the NJUNLP team to the WMT 2023 Quality Estimation (QE) shared task. Our team submitted predictions for the English-German language pair on all two sub-tasks: (i) sentence- and word-level quality prediction; and (ii) fine-grained error span detection. This year, we further explore pseudo data methods for QE based on NJUQE framework (https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel data from the WMT translation task. We pre-train the XLMR large model on pseudo QE data, then fine-tune it on real QE data. At both stages, we jointly learn sentence-level scores and word-level tags. Empirically, we conduct experiments to find the key hyper-parameters that improve the performance. Technically, we propose a simple method that covert the word-level outputs to fine-grained error span results. Overall, our models achieved the best results in English-German for both word-level and fine-grained error span detection sub-tasks by a considerable margin.
</details>
<details>
<summary>摘要</summary>
我们介绍NJUNLP团队在WMT 2023质量估计（QE）共享任务中的提交。我们对英语-德语语对 submitting 预测，包括两个子任务：（i）句子和单词水平质量预测，以及（ii）细化错误范围检测。本年，我们进一步探索基于NJUQE框架（https://github.com/NJUNLP/njuqe）的pseudo数据方法 для QE。我们使用WMT翻译任务的平行数据生成pseudo MQM数据，然后在这些数据上预训练XLMR大型模型，然后精度调整在真实QE数据上。在两个阶段中，我们同时学习句子级分数和单词级标签。实际上，我们进行了实验来找到提高性能的关键超参数。技术上，我们提出了一种简单的方法，将单词级输出转换为细化错误范围结果。总的来说，我们的模型在英语-德语语对上的 both word-level 和细化错误范围检测子任务上 achieved 最佳成绩，差距非常明显。
</details></li>
</ul>
<hr>
<h2 id="COCO-Counterfactuals-Automatically-Constructed-Counterfactual-Examples-for-Image-Text-Pairs"><a href="#COCO-Counterfactuals-Automatically-Constructed-Counterfactual-Examples-for-Image-Text-Pairs" class="headerlink" title="COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs"></a>COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14356">http://arxiv.org/abs/2309.14356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiep Le, Vasudev Lal, Phillip Howard</li>
<li>for: 这篇论文的目的是提出一种可扩展的框架，用于自动生成多模态的反例，以提高自然语言处理（NLP）领域中模型对数据中的偶极相关性的耐误性。</li>
<li>methods: 这篇论文使用了文本到图像扩散模型来生成反例。</li>
<li>results: 作者通过人工评估 validate了 COCO-Counterfactuals 多模态反例集的质量，并表明了现有的多模态模型在这些反例中表现不佳。此外，作者还示出了通过使用 COCO-Counterfactuals 进行训练数据增强来提高多模态视语言模型的对外域数据的泛化能力。<details>
<summary>Abstract</summary>
Counterfactual examples have proven to be valuable in the field of natural language processing (NLP) for both evaluating and improving the robustness of language models to spurious correlations in datasets. Despite their demonstrated utility for NLP, multimodal counterfactual examples have been relatively unexplored due to the difficulty of creating paired image-text data with minimal counterfactual changes. To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffusion models. We use our framework to create COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multimodal vision-language models via training data augmentation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用卷积神经网络生成对应的图像和文本描述的对称对话实例，以便用于评估和改进自然语言处理（NLP）模型对偶合关系在数据集中的Robustness。 DESPITE THEIR DEMONSTRATED UTILITY FOR NLP, multimodal counterfactual examples have been relatively unexplored due to the difficulty of creating paired image-text data with minimal counterfactual changes. To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffusion models. We use our framework to create COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multimodal vision-language models via training data augmentation.难以创建具有最小对称变化的对应图像和文本描述的对称对话实例，这些实例在自然语言处理（NLP）领域已经证明具有检验和改进模型Robustness的价值。 DESPITE THEIR DEMONSTRATED UTILITY FOR NLP, multimodal counterfactual examples have been relatively unexplored。 To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffusion models. We use our framework to create COCO-Counterfactuals, a multimodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multimodal vision-language models via training data augmentation.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.CL_2023_09_23/" data-id="clp9qz81o00c6ok88c0i54i1e" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/cs.LG_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T10:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/cs.LG_2023_09_23/">cs.LG - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Interpretable-and-Flexible-Target-Conditioned-Neural-Planners-For-Autonomous-Vehicles"><a href="#Interpretable-and-Flexible-Target-Conditioned-Neural-Planners-For-Autonomous-Vehicles" class="headerlink" title="Interpretable and Flexible Target-Conditioned Neural Planners For Autonomous Vehicles"></a>Interpretable and Flexible Target-Conditioned Neural Planners For Autonomous Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13485">http://arxiv.org/abs/2309.13485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haolan Liu, Jishen Zhao, Liangjun Zhang</li>
<li>for: 这 paper 是为了解决自动驾驶车辆 плаanner 中的多个可接受的计划问题而写的。</li>
<li>methods: 这 paper 使用了一种可解释的神经网络执行器，通过灵活的 Gaussian 几何函数和放松的小时钟损失函数来更好地捕捉规划问题的不确定性。</li>
<li>results: 作者在 Lyft 开放数据集上进行系统性的评估，发现其模型在真实世界驾驶enario 中比 Priors 性能更好，具有更安全和更灵活的驾驶性能。<details>
<summary>Abstract</summary>
Learning-based approaches to autonomous vehicle planners have the potential to scale to many complicated real-world driving scenarios by leveraging huge amounts of driver demonstrations. However, prior work only learns to estimate a single planning trajectory, while there may be multiple acceptable plans in real-world scenarios. To solve the problem, we propose an interpretable neural planner to regress a heatmap, which effectively represents multiple potential goals in the bird's-eye view of an autonomous vehicle. The planner employs an adaptive Gaussian kernel and relaxed hourglass loss to better capture the uncertainty of planning problems. We also use a negative Gaussian kernel to add supervision to the heatmap regression, enabling the model to learn collision avoidance effectively. Our systematic evaluation on the Lyft Open Dataset across a diverse range of real-world driving scenarios shows that our model achieves a safer and more flexible driving performance than prior works.
</details>
<details>
<summary>摘要</summary>
学习基本的自动驾驶车辆规划方法有可能在许多复杂的实际驾驶场景中扩大，通过利用庞大量驾驶员示例来担快学习。然而，先前的工作只 learns to estimate 一个规划路径，而实际场景可能存在多个可接受的规划方案。为解决这个问题，我们提议一种可解释性神经网络规划器，使用折衔函数来回归热图，该热图有效表示自动驾驶车辆的飞行视图中的多个可能目标。我们的规划器使用适应 Gaussian 核函数和松弛小时钟损失函数，以更好地捕捉规划问题的不确定性。此外，我们还使用负 Gaussian 核函数来给热图回归添加监督，使模型能够有效地学习避免碰撞。我们对 Lyft 开放数据集进行系统性评估，并在实际驾驶场景中表明我们的模型可以比先前的工作更安全和更灵活地驾驶。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Scheme-of-ResNet-and-Softmax"><a href="#A-Unified-Scheme-of-ResNet-and-Softmax" class="headerlink" title="A Unified Scheme of ResNet and Softmax"></a>A Unified Scheme of ResNet and Softmax</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13482">http://arxiv.org/abs/2309.13482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhao Song, Weixin Wang, Junze Yin</li>
<li>for: 这 paper 旨在提供一种统一的分析方法，用于研究深度学习中的 softmax 回归和 residual neural network（ResNet）两种技术的关系。</li>
<li>methods: 这 paper 使用了 theoretically 分析方法，对 regression 问题 $| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b |_2^2$ 进行了分析。</li>
<li>results: 这 paper 得到了 loss 函数的梯度、Hessian 和 Lipschitz 性质的分析结果，并证明了梯度和 Hessian 都是正semidefinite matrix，这使得可以使用高效的 approximate Newton 方法优化。这种统一的方法可以连接两个之前认为是无关的领域，并提供了新的视角 для深度学习模型的优化。<details>
<summary>Abstract</summary>
Large language models (LLMs) have brought significant changes to human society. Softmax regression and residual neural networks (ResNet) are two important techniques in deep learning: they not only serve as significant theoretical components supporting the functionality of LLMs but also are related to many other machine learning and theoretical computer science fields, including but not limited to image classification, object detection, semantic segmentation, and tensors.   Previous research works studied these two concepts separately. In this paper, we provide a theoretical analysis of the regression problem: $\| \langle \exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$, where $A$ is a matrix in $\mathbb{R}^{n \times d}$, $b$ is a vector in $\mathbb{R}^n$, and ${\bf 1}_n$ is the $n$-dimensional vector whose entries are all $1$. This regression problem is a unified scheme that combines softmax regression and ResNet, which has never been done before. We derive the gradient, Hessian, and Lipschitz properties of the loss function. The Hessian is shown to be positive semidefinite, and its structure is characterized as the sum of a low-rank matrix and a diagonal matrix. This enables an efficient approximate Newton method.   As a result, this unified scheme helps to connect two previously thought unrelated fields and provides novel insight into loss landscape and optimization for emerging over-parameterized neural networks, which is meaningful for future research in deep learning models.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）对人类社会带来了重要的变革。软极值回归和差异神经网络（ResNet）是深度学习中两种重要的技术：它们不仅支持 LLM 的功能，而且与其他机器学习和理论计算机科学领域有着密切的关系，包括图像分类、物体检测、 semantic 分割和矩阵等。在过去的研究中，这两个概念分别得到了研究。在这篇文章中，我们提供了对 regression 问题的理论分析：$\| \langle \exp(Ax) + A x , \mathbf{1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$, 其中 $A$ 是一个 $n \times d$ 维度的矩阵，$b$ 是一个 $n$ 维度的向量，${\bf 1}_n$ 是一个 $n$ 维度的向量，其中每个元素都是 1。这个 regression 问题是融合软极值回归和 ResNet 的统一方案，这是之前从未有过的。我们 derive 了梯度、Hessian 和 Lipschitz 性质。Hessian 显示为正定定义的矩阵，其结构可以分解为低级matrix 和 диагональ矩阵。这使得我们可以使用高效的approximate Newton 方法。因此，这个统一方案可以将两个 formerly 不相关的领域相连接，提供了新的视角，对深度学习模型的未来研究具有深刻的意义。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Bandwidth-Estimation-from-Offline-Expert-Demonstrations"><a href="#Real-time-Bandwidth-Estimation-from-Offline-Expert-Demonstrations" class="headerlink" title="Real-time Bandwidth Estimation from Offline Expert Demonstrations"></a>Real-time Bandwidth Estimation from Offline Expert Demonstrations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13481">http://arxiv.org/abs/2309.13481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aashish Gottipati, Sami Khairy, Gabriel Mittag, Vishak Gopal, Ross Cutler</li>
<li>for: 该论文targets the problem of bandwidth estimation (BWE) for real-time communication systems, with a focus on integrating data-driven bandwidth estimators into real-time systems.</li>
<li>methods: 该论文提出了一种名为Merlin的完全OFFLINE的数据驱动方法，将先前的追溯方法与深度学习技术相结合，以提高BWE的准确性和可靠性。</li>
<li>results: 实验表明，Merlin在对比WebRTC的视频会议中具有42.85%和12.8%的包丢失和延迟减少，分别。这些结果表明Merlin可以在实时网络控制中提供高质量的带宽估计。<details>
<summary>Abstract</summary>
In this work, we tackle the problem of bandwidth estimation (BWE) for real-time communication systems; however, in contrast to previous works, we leverage the vast efforts of prior heuristic-based BWE methods and synergize these approaches with deep learning-based techniques. Our work addresses challenges in generalizing to unseen network dynamics and extracting rich representations from prior experience, two key challenges in integrating data-driven bandwidth estimators into real-time systems. To that end, we propose Merlin, the first purely offline, data-driven solution to BWE that harnesses prior heuristic-based methods to extract an expert BWE policy. Through a series of experiments, we demonstrate that Merlin surpasses state-of-the-art heuristic-based and deep learning-based bandwidth estimators in terms of objective quality of experience metrics while generalizing beyond the offline world to in-the-wild network deployments where Merlin achieves a 42.85% and 12.8% reduction in packet loss and delay, respectively, when compared against WebRTC in inter-continental videoconferencing calls. We hope that Merlin's offline-oriented design fosters new strategies for real-time network control.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们解决了实时通信系统中的带宽估计（BWE）问题，但是与前一些工作不同，我们利用了过去的规则基本方法的巨大努力和深度学习基本技术的相互作用。我们的工作解决了在总结到未经见过的网络动态和从前经验中提取丰富表示的两个关键挑战，以使得数据驱动的带宽估计器可以成功地集成到实时系统中。为此，我们提出了Merlin，第一个完全OFFLINE、数据驱动的BWE解决方案，利用了过去的规则基本方法提取出专家级带宽估计策略。经过一系列实验，我们证明Merlin在对象质量体验指标方面超过了现有的规则基本方法和深度学习基本方法的带宽估计器，并在实际网络部署中实现了42.85%和12.8%的数据损失和延迟减少，分别与WebRTC在跨洲视频会议中比较。我们希望Merlin的OFFLINE-oriented设计会激发新的实时网络控制策略。
</details></li>
</ul>
<hr>
<h2 id="CA-PCA-Manifold-Dimension-Estimation-Adapted-for-Curvature"><a href="#CA-PCA-Manifold-Dimension-Estimation-Adapted-for-Curvature" class="headerlink" title="CA-PCA: Manifold Dimension Estimation, Adapted for Curvature"></a>CA-PCA: Manifold Dimension Estimation, Adapted for Curvature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13478">http://arxiv.org/abs/2309.13478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anna C. Gilbert, Kevin O’Neill</li>
<li>for: 本文旨在提出一种基于拟合 embedding 的维度估计方法，以改进现有的维度估计方法，以便更好地分析高维数据。</li>
<li>methods: 本文使用了本地 PCA 方法，基于拟合 embedding 来进行维度估计。</li>
<li>results: 经过严格的实验表明，本文提出的 CA-PCA 方法在各种设定下都有所改进，可以更好地估计高维数据的维度。<details>
<summary>Abstract</summary>
The success of algorithms in the analysis of high-dimensional data is often attributed to the manifold hypothesis, which supposes that this data lie on or near a manifold of much lower dimension. It is often useful to determine or estimate the dimension of this manifold before performing dimension reduction, for instance. Existing methods for dimension estimation are calibrated using a flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based instead on a calibration of a quadratic embedding, acknowledging the curvature of the underlying manifold. Numerous careful experiments show that this adaptation improves the estimator in a wide range of settings.
</details>
<details>
<summary>摘要</summary>
高维数据分析中算法的成功常被归结于 manifold 假设，即数据位于或靠近一个低维度的抽象 manifold。在进行维度减少之前，常常需要先确定或估算 manifold 的维度。现有的维度估算方法通常使用平坦单位球进行准备。本文提出了 CA-PCA，基于 quadratic embedding 的本地 PCA 方法，考虑到 manifold 的曲率性。详细的实验表明，这种改进可以在各种场景中提高估计器的性能。Note: "高维数据" (gāo wèi xué) in Chinese refers to data with many features or dimensions, and "抽象 manifold" (chōu xiǎng jiāo) refers to a hypothetical lower-dimensional space that the high-dimensional data is assumed to lie on or near.
</details></li>
</ul>
<hr>
<h2 id="SUDS-Sanitizing-Universal-and-Dependent-Steganography"><a href="#SUDS-Sanitizing-Universal-and-Dependent-Steganography" class="headerlink" title="SUDS: Sanitizing Universal and Dependent Steganography"></a>SUDS: Sanitizing Universal and Dependent Steganography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13467">http://arxiv.org/abs/2309.13467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pkrobinette/suds-ecai-2023">https://github.com/pkrobinette/suds-ecai-2023</a></li>
<li>paper_authors: Preston K. Robinette, Hanchen D. Wang, Nishan Shehadeh, Daniel Moyer, Taylor T. Johnson</li>
<li>for: This paper focuses on developing a deep learning sanitization technique called SUDS to mitigate the shortcomings of steganalysis in detecting steganography.</li>
<li>methods: The paper uses a deep learning approach called SUDS that is not reliant on prior knowledge of steganographic hiding techniques and can sanitize universal and dependent steganography.</li>
<li>results: The paper demonstrates the capabilities and limitations of SUDS through five research questions, including baseline comparisons and an ablation study, and shows that SUDS can increase the resistance of a poisoned classifier against attacks by 1375%.Here’s the Chinese translation of the three key information points:</li>
<li>for: 这篇论文关注开发一种基于深度学习的清洁技术called SUDS，以mitigate隐藏分析的缺陷。</li>
<li>methods: 这篇论文使用一种基于深度学习的方法called SUDS，该方法不依赖于隐藏技术的先前知识，可以清洁universal和依赖隐藏。</li>
<li>results: 这篇论文通过五个研究问题，包括基线比较和减少研究，展示了SUDS的能力和局限性。此外，SUDS在一个实际场景中能够提高恶意分类器对攻击的抵抗力 by 1375%.<details>
<summary>Abstract</summary>
Steganography, or hiding messages in plain sight, is a form of information hiding that is most commonly used for covert communication. As modern steganographic mediums include images, text, audio, and video, this communication method is being increasingly used by bad actors to propagate malware, exfiltrate data, and discreetly communicate. Current protection mechanisms rely upon steganalysis, or the detection of steganography, but these approaches are dependent upon prior knowledge, such as steganographic signatures from publicly available tools and statistical knowledge about known hiding methods. These dependencies render steganalysis useless against new or unique hiding methods, which are becoming increasingly common with the application of deep learning models. To mitigate the shortcomings of steganalysis, this work focuses on a deep learning sanitization technique called SUDS that is not reliant upon knowledge of steganographic hiding techniques and is able to sanitize universal and dependent steganography. SUDS is tested using least significant bit method (LSB), dependent deep hiding (DDH), and universal deep hiding (UDH). We demonstrate the capabilities and limitations of SUDS by answering five research questions, including baseline comparisons and an ablation study. Additionally, we apply SUDS to a real-world scenario, where it is able to increase the resistance of a poisoned classifier against attacks by 1375%.
</details>
<details>
<summary>摘要</summary>
《隐藏信息在明目张观的形式》，也称为隐藏通信，是一种常用于推广邮件、披露数据和秘密交流的信息隐藏方法。现代隐藏媒体包括图像、文本、音频和视频，这种通信方式在不良行为者中日益普及，以散播蠕虫、披露数据和秘密交流。现有的保护机制主要基于隐藏分析（steganalysis），但这些方法依赖于已知的隐藏技术和统计知识，因此对新或独特的隐藏方法无效。为了解决隐藏分析的缺陷，本研究提出了一种基于深度学习的清洁技术called SUDS，不依赖于隐藏技术的知识，可以清洁universal和依赖隐藏。SUDS在LSB、DDH和UDH方法上进行测试，我们通过 five 个研究问题回答了SUDS的能力和局限性，并进行了减少研究。此外，我们将SUDS应用于实际场景，其能够增加毒性分类器的抵抗力，达到1375%。
</details></li>
</ul>
<hr>
<h2 id="Tight-bounds-on-Pauli-channel-learning-without-entanglement"><a href="#Tight-bounds-on-Pauli-channel-learning-without-entanglement" class="headerlink" title="Tight bounds on Pauli channel learning without entanglement"></a>Tight bounds on Pauli channel learning without entanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13461">http://arxiv.org/abs/2309.13461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Senrui Chen, Changhun Oh, Sisi Zhou, Hsin-Yuan Huang, Liang Jiang</li>
<li>for: 这个论文主要研究了无共振学习算法的优势，具体来说是研究了不使用共振状态、测量和操作来学习Pauli通道的算法。</li>
<li>methods: 这个论文使用了无共振学习算法，具体来说是使用分离状态、测量和操作来学习Pauli通道。这种算法等同于在主系统上执行量子电路，并在电路中进行中间测量和классификация。</li>
<li>results: 论文提出了一个紧binding的下界 bounds for 无共振学习Pauli通道，这个下界是cubic gap 的关键。具体来说， authors 证明了需要 $\Theta(2^n\varepsilon^{-2})$ 轮 measurements来估算Pauli通道的每个特征值到 $\varepsilon$ 错误的高概率。与此相比，一个具有共振的学习算法只需要 $\Theta(\varepsilon^{-2})$ 轮 measurements。这个下界加强了实验准确地示出了共振增强的优势。<details>
<summary>Abstract</summary>
Entanglement is a useful resource for learning, but a precise characterization of its advantage can be challenging. In this work, we consider learning algorithms without entanglement to be those that only utilize separable states, measurements, and operations between the main system of interest and an ancillary system. These algorithms are equivalent to those that apply quantum circuits on the main system interleaved with mid-circuit measurements and classical feedforward. We prove a tight lower bound for learning Pauli channels without entanglement that closes a cubic gap between the best-known upper and lower bound. In particular, we show that $\Theta(2^n\varepsilon^{-2})$ rounds of measurements are required to estimate each eigenvalue of an $n$-qubit Pauli channel to $\varepsilon$ error with high probability when learning without entanglement. In contrast, a learning algorithm with entanglement only needs $\Theta(\varepsilon^{-2})$ rounds of measurements. The tight lower bound strengthens the foundation for an experimental demonstration of entanglement-enhanced advantages for characterizing Pauli noise.
</details>
<details>
<summary>摘要</summary>
Entanglement 是一种有用的资源 для学习，但准确地量ify its advantage 可以具有挑战。在这项工作中，我们认为不使用束缚状态的学习算法Equivalent to those that apply quantum circuits on the main system interleaved with mid-circuit measurements and classical feedforward。我们证明了无束缚状态学习Pauli通道的下界， closing a cubic gap between the best-known upper and lower bound。specifically, we show that $\Theta(2^n\varepsilon^{-2})$ rounds of measurements are required to estimate each eigenvalue of an $n$-qubit Pauli channel to $\varepsilon$ error with high probability when learning without entanglement. In contrast, a learning algorithm with entanglement only needs $\Theta(\varepsilon^{-2})$ rounds of measurements. The tight lower bound strengthens the foundation for an experimental demonstration of entanglement-enhanced advantages for characterizing Pauli noise.
</details></li>
</ul>
<hr>
<h2 id="Monotonic-Neural-Ordinary-Differential-Equation-Time-series-Forecasting-for-Cumulative-Data"><a href="#Monotonic-Neural-Ordinary-Differential-Equation-Time-series-Forecasting-for-Cumulative-Data" class="headerlink" title="Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data"></a>Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13452">http://arxiv.org/abs/2309.13452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Chen, Leilei Ding, Zhixuan Chu, Yucheng Qi, Jianmin Huang, Hao Wang</li>
<li>for: 预测时间序数据（TSFCD）是决策过程中的关键问题，但现有的时间序预测方法通常忽略了积累数据中的幂等性和不规则性，限制其实际应用。</li>
<li>methods: 我们提出了一种原理驱动的方法called Monotonic neural Ordinary Differential Equation (MODE)，该方法基于神经ordinary differential equations框架，能够有效捕捉和表示积累数据中的幂等性和不规则性。</li>
<li>results: 通过对奖金分配场景的广泛实验，我们展示了MODE的优异性，能够处理积累数据中的幂等性和不规则性，并提供了更好的预测性能。<details>
<summary>Abstract</summary>
Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem in decision-making across various industrial scenarios. However, existing time-series forecasting methods often overlook two important characteristics of cumulative data, namely monotonicity and irregularity, which limit their practical applicability. To address this limitation, we propose a principled approach called Monotonic neural Ordinary Differential Equation (MODE) within the framework of neural ordinary differential equations. By leveraging MODE, we are able to effectively capture and represent the monotonicity and irregularity in practical cumulative data. Through extensive experiments conducted in a bonus allocation scenario, we demonstrate that MODE outperforms state-of-the-art methods, showcasing its ability to handle both monotonicity and irregularity in cumulative data and delivering superior forecasting performance.
</details>
<details>
<summary>摘要</summary>
时序预测基于累积数据（TSFCD）是决策中的一项重要问题，存在许多工业场景中。然而，现有的时序预测方法通常忽视累积数据中的两个重要特征： monotonicity 和 irregularity，这限制了它们的实际应用。为解决这一限制，我们提议一种原则正的方法 called Monotonic Neural Ordinary Differential Equation（MODE），基于神经常微方程。通过利用 MODE，我们可以有效地捕捉和表示实际累积数据中的 monotonicity 和 irregularity。经过广泛的奖励分配场景的实验，我们示出 MODE 可以在 monotonicity 和 irregularity 的情况下提供更好的预测性能，超过现有的方法。
</details></li>
</ul>
<hr>
<h2 id="NetDiffus-Network-Traffic-Generation-by-Diffusion-Models-through-Time-Series-Imaging"><a href="#NetDiffus-Network-Traffic-Generation-by-Diffusion-Models-through-Time-Series-Imaging" class="headerlink" title="NetDiffus: Network Traffic Generation by Diffusion Models through Time-Series Imaging"></a>NetDiffus: Network Traffic Generation by Diffusion Models through Time-Series Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04429">http://arxiv.org/abs/2310.04429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirhoshan Sivaroopan, Dumindu Bandara, Chamara Madarasingha, Guilluame Jourjon, Anura Jayasumana, Kanchana Thilakarathna</li>
<li>for: 这篇论文的目的是如何使用扩散模型生成假设数据，以便解决现代网络数据的有限访问问题。</li>
<li>methods: 这篇论文使用了Diffusion Models（DM），将一维时间序列网络流量转换为二维图像，然后生成代表性图像。</li>
<li>results: 论文表明，使用NetDiffus可以提高66.4%的数据准确性和18.1%的下游机器学习任务。在七种不同的流量轨迹上进行评估， synthetic数据可以显著改善流量识别、异常检测和流量分类。<details>
<summary>Abstract</summary>
Network data analytics are now at the core of almost every networking solution. Nonetheless, limited access to networking data has been an enduring challenge due to many reasons including complexity of modern networks, commercial sensitivity, privacy and regulatory constraints. In this work, we explore how to leverage recent advancements in Diffusion Models (DM) to generate synthetic network traffic data. We develop an end-to-end framework - NetDiffus that first converts one-dimensional time-series network traffic into two-dimensional images, and then synthesizes representative images for the original data. We demonstrate that NetDiffus outperforms the state-of-the-art traffic generation methods based on Generative Adversarial Networks (GANs) by providing 66.4% increase in fidelity of the generated data and 18.1% increase in downstream machine learning tasks. We evaluate NetDiffus on seven diverse traffic traces and show that utilizing synthetic data significantly improves traffic fingerprinting, anomaly detection and traffic classification.
</details>
<details>
<summary>摘要</summary>
网络数据分析现在成为网络解决方案的核心。然而，因为现代网络的复杂性、商业敏感性、隐私和法规限制等多种原因，实际网络数据访问受到了限制。在这种情况下，我们探讨了如何利用最近的扩散模型（DM）来生成合成网络流量数据。我们开发了一个端到端框架——NetDiffus，它首先将一维时间序列网络流量转换为二维图像，然后将原始数据生成 representativeness 的图像。我们证明了 NetDiffus 比基于生成对抗网络（GANs）的现有流量生成方法提供了66.4% 的真实性提升和18.1% 的下游机器学任务提升。我们对七个多样化的流量轨迹进行了评估，并显示了利用合成数据可以显著提高流量识别、异常检测和流量分类。
</details></li>
</ul>
<hr>
<h2 id="Early-Classification-for-Dynamic-Inference-of-Neural-Networks"><a href="#Early-Classification-for-Dynamic-Inference-of-Neural-Networks" class="headerlink" title="Early Classification for Dynamic Inference of Neural Networks"></a>Early Classification for Dynamic Inference of Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13443">http://arxiv.org/abs/2309.13443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingcun Wang, Bing Li, Grace Li Zhang</li>
<li>for: 降低edge设备上深度神经网络（DNNs）的计算成本，以便在资源有限的平台上应用。</li>
<li>methods: 使用动态神经网络（Dynamic Neural Networks）实现结构适应，并在不同输入上进行早期退出。</li>
<li>results: 通过各级别分类器来除外不相关的类别，从而使后续层只需要确定剩下的目标类别。实验结果表明，可以有效降低DNNs在推理中的计算成本。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have been successfully applied in various fields. In DNNs, a large number of multiply-accumulate (MAC) operations is required to be performed, posing critical challenges in applying them in resource-constrained platforms, e.g., edge devices. Dynamic neural networks have been introduced to allow a structural adaption, e.g., early-exit, according to different inputs to reduce the computational cost of DNNs. Existing early-exit techniques deploy classifiers at intermediate layers of DNNs to push them to make a classification decision as early as possible. However, the learned features at early layers might not be sufficient to exclude all the irrelevant classes and decide the correct class, leading to suboptimal results. To address this challenge, in this paper, we propose a class-based early-exit for dynamic inference. Instead of pushing DNNs to make a dynamic decision at intermediate layers, we take advantages of the learned features in these layers to exclude as many irrelevant classes as possible, so that later layers only have to determine the target class among the remaining classes. Until at a layer only one class remains, this class is the corresponding classification result. To realize this class-based exclusion, we assign each class with a classifier at intermediate layers and train the networks together with these classifiers. Afterwards, an exclusion strategy is developed to exclude irrelevant classes at early layers. Experimental results demonstrate the computational cost of DNNs in inference can be reduced significantly.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a class-based early-exit for dynamic inference. Instead of pushing DNNs to make a dynamic decision at intermediate layers, we take advantage of the learned features in these layers to exclude as many irrelevant classes as possible. We assign each class with a classifier at intermediate layers and train the networks together with these classifiers. An exclusion strategy is then developed to exclude irrelevant classes at early layers.Experimental results demonstrate that the computational cost of DNNs in inference can be significantly reduced using our approach.Simplified Chinese translation:深度神经网络（DNN）在各个领域得到了成功应用，但是它们需要大量的 multiply-accumulate（MAC）操作，这对于具有限制的资源的平台，如边缘设备，具有挑战性。动态神经网络被引入以实现结构适应，例如早期离开，以降低 DNN 的计算成本。现有的早期离开技术是通过在 DNN 中的中间层添加分类器，以便在不同的输入上使 DNN 尽早做出分类决策。然而，学习在中间层的特征可能不够用于排除所有无关的类并决定正确的类，从而导致低效果。为了解决这个挑战，我们在这篇论文中提出了类型基于的早期离开。而不是在 DNN 中的中间层强制做出动态决策，我们利用中间层学习的特征来排除最多的无关类。在每个层只剩下一个类时，这个类就是对应的分类结果。为实现这种类型基于的排除，我们将每个类分配了中间层的分类器，并与这些分类器一起训练 DNN。后续，我们开发了一种排除策略，以便在早期层中排除无关的类。实验结果表明，使用我们的方法可以在 DNN 的推理中减少计算成本。
</details></li>
</ul>
<hr>
<h2 id="MiliPoint-A-Point-Cloud-Dataset-for-mmWave-Radar"><a href="#MiliPoint-A-Point-Cloud-Dataset-for-mmWave-Radar" class="headerlink" title="MiliPoint: A Point Cloud Dataset for mmWave Radar"></a>MiliPoint: A Point Cloud Dataset for mmWave Radar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13425">http://arxiv.org/abs/2309.13425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Cui, Shu Zhong, Jiacheng Wu, Zichao Shen, Naim Dahnoun, Yiren Zhao</li>
<li>for: 这项研究是为了开发更有效的点集基于深度学习方法，以激发mmWave雷达技术的应用在人类活动识别领域。</li>
<li>methods: 该研究使用了大规模的开放数据集，并在这些数据集上进行了多种点基的深度神经网络模型的实现，包括DGCNN、PointNet++和PointTransformer等。</li>
<li>results: 研究发现，使用点基的深度神经网络可以在mmWave雷达数据上实现更高的人类活动识别精度。此外，该研究还提供了一个大规模的开放数据集，可供研究者进一步探索mmWave雷达技术在人类活动识别领域的应用。<details>
<summary>Abstract</summary>
Millimetre-wave (mmWave) radar has emerged as an attractive and cost-effective alternative for human activity sensing compared to traditional camera-based systems. mmWave radars are also non-intrusive, providing better protection for user privacy. However, as a Radio Frequency (RF) based technology, mmWave radars rely on capturing reflected signals from objects, making them more prone to noise compared to cameras. This raises an intriguing question for the deep learning community: Can we develop more effective point set-based deep learning methods for such attractive sensors?   To answer this question, our work, termed MiliPoint, delves into this idea by providing a large-scale, open dataset for the community to explore how mmWave radars can be utilised for human activity recognition. Moreover, MiliPoint stands out as it is larger in size than existing datasets, has more diverse human actions represented, and encompasses all three key tasks in human activity recognition. We have also established a range of point-based deep neural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint, which can serve to set the ground baseline for further development.
</details>
<details>
<summary>摘要</summary>
幂米波（mmWave）雷达已成为人类活动感知的吸引人和经济实惠的替代方案，比传统的摄像头系统更加cost-effective。另外，mmWave雷达也是不侵入的，为用户隐私提供更好的保护。然而，作为一种Radio Frequency（RF）基于的技术，mmWave雷达需要捕捉到物体上的反射信号，这使其更容易受到噪声的影响，与摄像头相比。这引发了深度学习社区的一个感人问题：可以开发更有效的点集基于深度学习方法吗？为回答这个问题，我们的工作，称为MiliPoint，探讨了这一想法，提供了一个大规模、开放的数据集，让社区可以探索mmWave雷达如何用于人类活动识别。此外，MiliPoint更大、更多样化的人类行为被表示出来，并包括人类活动识别的三个关键任务。我们还在MiliPoint上建立了一些点基的深度神经网络，如DGCNN、PointNet++和PointTransformer，以设置基准 для后续的发展。
</details></li>
</ul>
<hr>
<h2 id="DenMune-Density-peak-based-clustering-using-mutual-nearest-neighbors"><a href="#DenMune-Density-peak-based-clustering-using-mutual-nearest-neighbors" class="headerlink" title="DenMune: Density peak based clustering using mutual nearest neighbors"></a>DenMune: Density peak based clustering using mutual nearest neighbors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13420">http://arxiv.org/abs/2309.13420</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scikit-learn-contrib/denmune-clustering-algorithm">https://github.com/scikit-learn-contrib/denmune-clustering-algorithm</a></li>
<li>paper_authors: Mohamed Abbas, Adel El-Zoghobi, Amin Shoukry</li>
<li>for: 该论文是为了解决聚类算法在具有不规则形状、不均匀密度和数据类别受到近似影响的情况下失效问题。</li>
<li>methods: 该论文提出了一种新的聚类算法，即 DenMune，该算法基于在K个最近邻域中查找密集区域，K是用户需要提供的唯一参数，并遵循最近邻域一致原理。</li>
<li>results: 该论文表明，DenMune算法能够在低维和高维数据集上 produz 稳定和Robust的聚类结果，并能自动除掉聚类过程中的噪音和找到目标聚类。<details>
<summary>Abstract</summary>
Many clustering algorithms fail when clusters are of arbitrary shapes, of varying densities, or the data classes are unbalanced and close to each other, even in two dimensions. A novel clustering algorithm, DenMune is presented to meet this challenge. It is based on identifying dense regions using mutual nearest neighborhoods of size K, where K is the only parameter required from the user, besides obeying the mutual nearest neighbor consistency principle. The algorithm is stable for a wide range of values of K. Moreover, it is able to automatically detect and remove noise from the clustering process as well as detecting the target clusters. It produces robust results on various low and high-dimensional datasets relative to several known state-of-the-art clustering algorithms.
</details>
<details>
<summary>摘要</summary>
很多聚类算法在聚类形状不规则、密度不同、数据类型近似的情况下失败。一种新的聚类算法，DenMune，以解决这些挑战。该算法基于在尺度K中的积 nearest neighborhoods，K是用户需要提供的唯一参数，同时遵循积 nearest neighbor consistency principle。算法在不同的K值下具有稳定性，并且可以自动除掉聚类过程中的噪声，同时检测目标聚类。它在各种低维和高维数据集上显示出了相对稳定的结果，与许多已知的状态 искусственный智能算法相比。
</details></li>
</ul>
<hr>
<h2 id="Learning-Large-Scale-MTP-2-Gaussian-Graphical-Models-via-Bridge-Block-Decomposition"><a href="#Learning-Large-Scale-MTP-2-Gaussian-Graphical-Models-via-Bridge-Block-Decomposition" class="headerlink" title="Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition"></a>Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13405">http://arxiv.org/abs/2309.13405</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiwen1997/mtp2-bbd">https://github.com/xiwen1997/mtp2-bbd</a></li>
<li>paper_authors: Xiwen Wang, Jiaxi Ying, Daniel P. Palomar</li>
<li>for: 本研究实际问题是学习大规模的 Gaussian  graficial 模型（MTP}_2），通过引入桥梁的概念，将整个问题分解为较小的scale的子问题，并提出一些可诠释的解决方案，从实际上来说，这个简单可诠释的架构可以将大问题分解为小 tractable 问题，实现了巨大的计算复杂度削减和现有算法的重要提升。</li>
<li>methods: 本研究使用了桥梁分解法，将大规模 Gaussian  graficial 模型（MTP}_2）分解为较小的scale的子问题，并提出了一些可诠释的解决方案。</li>
<li>results: 实验结果显示， compared to state-of-the-art 参考标准，本研究的提案方法具有重要的速度优化。<details>
<summary>Abstract</summary>
This paper studies the problem of learning the large-scale Gaussian graphical models that are multivariate totally positive of order two ($\text{MTP}_2$). By introducing the concept of bridge, which commonly exists in large-scale sparse graphs, we show that the entire problem can be equivalently optimized through (1) several smaller-scaled sub-problems induced by a \emph{bridge-block decomposition} on the thresholded sample covariance graph and (2) a set of explicit solutions on entries corresponding to bridges. From practical aspect, this simple and provable discipline can be applied to break down a large problem into small tractable ones, leading to enormous reduction on the computational complexity and substantial improvements for all existing algorithms. The synthetic and real-world experiments demonstrate that our proposed method presents a significant speed-up compared to the state-of-the-art benchmarks.
</details>
<details>
<summary>摘要</summary>
这篇论文研究大规模的高斯图模型，即多变量完全正的第二阶（MTP2）。我们引入了桥梁概念，这种概念在大规模稀疏图中广泛存在。我们显示，整个问题可以等价地通过以下两个步骤优化：1. 使用桥梁块分解法对阈值矩阵相关的一些更小规模的子问题进行优化。2. 对桥梁相对应的输入进行直观的解决方案。从实践角度来看，这种简单可证的方法可以将大问题分解成小可解决的问题，从而减少计算复杂性和提高所有现有算法的性能。实验表明，我们提出的方法与现有的标准准则相比，具有显著的速度提升。
</details></li>
</ul>
<hr>
<h2 id="ML-Algorithm-Synthesizing-Domain-Knowledge-for-Fungal-Spores-Concentration-Prediction"><a href="#ML-Algorithm-Synthesizing-Domain-Knowledge-for-Fungal-Spores-Concentration-Prediction" class="headerlink" title="ML Algorithm Synthesizing Domain Knowledge for Fungal Spores Concentration Prediction"></a>ML Algorithm Synthesizing Domain Knowledge for Fungal Spores Concentration Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13402">http://arxiv.org/abs/2309.13402</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/azminewasi/qcre23-finalist">https://github.com/azminewasi/qcre23-finalist</a></li>
<li>paper_authors: Md Asif Bin Syed, Azmine Toushik Wasi, Imtiaz Ahmed</li>
<li>for: 提高纸品质量控制的效率和可持续性，实现实时精度测试和纠正控制。</li>
<li>methods: 利用时间序列数据和领域知识，采用机器学习算法进行精度预测。</li>
<li>results: 实现实时精度测试和纠正控制，提高纸品质量和可持续性。<details>
<summary>Abstract</summary>
The pulp and paper manufacturing industry requires precise quality control to ensure pure, contaminant-free end products suitable for various applications. Fungal spore concentration is a crucial metric that affects paper usability, and current testing methods are labor-intensive with delayed results, hindering real-time control strategies. To address this, a machine learning algorithm utilizing time-series data and domain knowledge was proposed. The optimal model employed Ridge Regression achieving an MSE of 2.90 on training and validation data. This approach could lead to significant improvements in efficiency and sustainability by providing real-time predictions for fungal spore concentrations. This paper showcases a promising method for real-time fungal spore concentration prediction, enabling stringent quality control measures in the pulp-and-paper industry.
</details>
<details>
<summary>摘要</summary>
《纸品生产业需要精准质量控制，以 Ensure 纸品具备不同应用的纯度和不损害性。蕈菌苗量是影响纸品使用性的关键指标，现有的测试方法具有劳动 INTENSIVE 和延迟结果，使得实时控制策略受阻。为此，一种机器学习算法使用时序数据和领域知识进行建模，选择最佳模型为ridge regression，实现了训练和验证数据的MSE为2.90。这种方法可能会在效率和可持续性方面提供重要的改进，并为纸品生产业提供实时蕈菌苗量预测，帮助实施严格的质量控制措施。本文介绍了实时蕈菌苗量预测的有效方法，为纸品生产业带来更好的质量控制和可持续发展。》Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-Sweet-Spot-of-Contrastive-Views-for-Knowledge-enhanced-Recommendation"><a href="#On-the-Sweet-Spot-of-Contrastive-Views-for-Knowledge-enhanced-Recommendation" class="headerlink" title="On the Sweet Spot of Contrastive Views for Knowledge-enhanced Recommendation"></a>On the Sweet Spot of Contrastive Views for Knowledge-enhanced Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13384">http://arxiv.org/abs/2309.13384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haibo Ye, Xinjie Li, Yuan Yao, Hanghang Tong</li>
<li>for: 这个论文旨在提高推荐系统的效果，通过在知识图（KG）和用户项交互图（IG）之间建立对应关系。</li>
<li>methods: 该论文提出了一种新的对照学习框架，通过在IG和KG之间建立两个不同的对照视图，并将IG中的知识信息与KG进行一个方向的融合，以便更好地利用知识。</li>
<li>results: 对于三个实际 dataset，该方法的实验结果显示，相比之前的状态 искус技术，该方法能够更高效地提高推荐系统的效果。代码可以通过以下隐藏链接获取：<a target="_blank" rel="noopener" href="https://figshare.com/articles/conference_contribution/SimKGCL/22783382">https://figshare.com/articles/conference_contribution/SimKGCL/22783382</a><details>
<summary>Abstract</summary>
In recommender systems, knowledge graph (KG) can offer critical information that is lacking in the original user-item interaction graph (IG). Recent process has explored this direction and shows that contrastive learning is a promising way to integrate both. However, we observe that existing KG-enhanced recommenders struggle in balancing between the two contrastive views of IG and KG, making them sometimes even less effective than simply applying contrastive learning on IG without using KG. In this paper, we propose a new contrastive learning framework for KG-enhanced recommendation. Specifically, to make full use of the knowledge, we construct two separate contrastive views for KG and IG, and maximize their mutual information; to ease the contrastive learning on the two views, we further fuse KG information into IG in a one-direction manner.Extensive experimental results on three real-world datasets demonstrate the effectiveness and efficiency of our method, compared to the state-of-the-art. Our code is available through the anonymous link:https://figshare.com/articles/conference_contribution/SimKGCL/22783382
</details>
<details>
<summary>摘要</summary>
在推荐系统中，知识图（KG）可以提供用户-ITEM互动图（IG）缺失的关键信息。近期的进程探索了这个方向，并显示了对照学习是一种有前途的方法来整合两者。然而，我们发现现有的KG强化推荐器在平衡两个对照视图IG和KG的视图之间很困难，有时甚至比不用对IG进行对照学习更不有效。在本文中，我们提出了一个新的对照学习框架 для KG强化推荐。具体来说，为了充分利用知识，我们构建了两个独立的对照视图 для KG和IG，并尽可能地增加它们之间的相互信息。此外，为了让对照学习在两个视图之间更加容易，我们进一步将KG信息集成到IG中一irectionally。我们的实验结果表明，我们的方法比现有的状态前方法更有效和高效，并且可以在三个实际 dataset上进行证明。我们的代码可以通过以下匿名链接获取：https://figshare.com/articles/conference_contribution/SimKGCL/22783382
</details></li>
</ul>
<hr>
<h2 id="Learning-Invariant-Representations-with-a-Nonparametric-Nadaraya-Watson-Head"><a href="#Learning-Invariant-Representations-with-a-Nonparametric-Nadaraya-Watson-Head" class="headerlink" title="Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head"></a>Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13377">http://arxiv.org/abs/2309.13377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alanqrwang/nwhead">https://github.com/alanqrwang/nwhead</a></li>
<li>paper_authors: Alan Q. Wang, Minh Nguyen, Mert R. Sabuncu</li>
<li>for: 本研究旨在提出一种非 Parametric 的协同学习方法，以实现在不同环境下的数据分布不同时，机器学习模型的可重用性。</li>
<li>methods: 本研究使用 Nadaraya-Watson (NW) 头，该头通过比较学习的表示与支持集中的标注数据进行比较，来预测。通过控制支持集，可以编码不同的 causal 假设。</li>
<li>results: 通过在三个实际世界领域的域泛化任务上进行验证，表明本方法可以学习不受环境影响的抽象特征，并且可以在不同环境下提供好的预测性能。<details>
<summary>Abstract</summary>
Machine learning models will often fail when deployed in an environment with a data distribution that is different than the training distribution. When multiple environments are available during training, many methods exist that learn representations which are invariant across the different distributions, with the hope that these representations will be transportable to unseen domains. In this work, we present a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head. The NW head makes a prediction by comparing the learned representations of the query to the elements of a support set that consists of labeled data. We demonstrate that by manipulating the support set, one can encode different causal assumptions. In particular, restricting the support set to a single environment encourages the model to learn invariant features that do not depend on the environment. We present a causally-motivated setup for our modeling and training strategy and validate on three challenging real-world domain generalization tasks in computer vision.
</details>
<details>
<summary>摘要</summary>
机器学习模型经常在培育环境不同于训练环境下部署时失败。当有多个环境可用于训练时，许多方法可以学习不受环境影响的表示，以期这些表示可以在未见领域中传输。在这种工作中，我们提出了一种非 Parametric 策略，基于最近提出的 Nadaraya-Watson（NW）头来学习不受环境影响的表示。NW 头通过比较学习的表示和一个支持集中的标注数据进行比较，来预测。我们表明，通过修改支持集，可以编码不同的 causal 假设。例如，限制支持集为单个环境，使模型学习不受环境的无关特征。我们采用 causally-motivated 的模型和训练策略，并在计算机视觉领域中进行了三个复杂的实际领域泛化任务的验证。
</details></li>
</ul>
<hr>
<h2 id="Asca-less-audio-data-is-more-insightful"><a href="#Asca-less-audio-data-is-more-insightful" class="headerlink" title="Asca: less audio data is more insightful"></a>Asca: less audio data is more insightful</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13373">http://arxiv.org/abs/2309.13373</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leeciang/asca">https://github.com/leeciang/asca</a></li>
<li>paper_authors: Xiang Li, Junhao Chen, Chao Li, Hongwu Lv</li>
<li>for: 本研究旨在提高特殊领域中的专业音频识别，如鸟叫声和潜水声频率的标准化和预测。</li>
<li>methods: 本研究使用了Audio Spectrogram Convolution Attention（ASCA）模型，结合了Transformer和卷积储存架构，同时还具有新的网络设计和注意技术，以及资料增强和调整策略。</li>
<li>results: 在BirdCLEF2023和AudioSet（平衡） datasets上，ASCA模型实现了81.2%和35.1%的准确率，均高于竞争方法。<details>
<summary>Abstract</summary>
Audio recognition in specialized areas such as birdsong and submarine acoustics faces challenges in large-scale pre-training due to the limitations in available samples imposed by sampling environments and specificity requirements. While the Transformer model excels in audio recognition, its dependence on vast amounts of data becomes restrictive in resource-limited settings. Addressing this, we introduce the Audio Spectrogram Convolution Attention (ASCA) based on CoAtNet, integrating a Transformer-convolution hybrid architecture, novel network design, and attention techniques, further augmented with data enhancement and regularization strategies. On the BirdCLEF2023 and AudioSet(Balanced), ASCA achieved accuracies of 81.2% and 35.1%, respectively, significantly outperforming competing methods. The unique structure of our model enriches output, enabling generalization across various audio detection tasks. Our code can be found at https://github.com/LeeCiang/ASCA.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>特殊领域的音频识别，如鸟唱和潜船音频识别，由样本环境和特定要求所限制大规模预训练的样本数量。虽然Transformer模型在音频识别方面表现出色，但它在资源有限的设置下变得有限制。为此，我们介绍Audio Spectrogram Convolution Attention（ASCA），基于CoAtNet的干扰混合架构，加入了Transformer- convolution 混合 Architecture，新型网络设计，以及注意技术，并进一步使用数据增强和常规化策略。在BirdCLEF2023和AudioSet（平衡）上，ASCA实现了81.2%和35.1%的准确率，分别大幅超越竞争方法。ASCA的独特结构使得输出更加丰富，使得泛化到不同的音频检测任务。我们的代码可以在https://github.com/LeeCiang/ASCA中找到。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-with-Chaotic-Strange-Attractors"><a href="#Machine-Learning-with-Chaotic-Strange-Attractors" class="headerlink" title="Machine Learning with Chaotic Strange Attractors"></a>Machine Learning with Chaotic Strange Attractors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13361">http://arxiv.org/abs/2309.13361</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Bahadır Utku Kesgin, Uğur Teğin</li>
<li>for: 这个论文是为了解决机器学习中的高功耗问题，通过使用混沌非线性吸引器来实现低功耗的机器学习任务。</li>
<li>methods: 该论文提出了一种基于混沌非线性吸引器的分析计算方法，该方法可以高效地进行机器学习任务，而且具有可编程、通用和泛化的特点。</li>
<li>results: 研究发现，使用该方法可以在批量处理和神经网络训练中实现低功耗，并且在分类和回归学习任务中达到了高准确率和低误差。<details>
<summary>Abstract</summary>
Machine learning studies need colossal power to process massive datasets and train neural networks to reach high accuracies, which have become gradually unsustainable. Limited by the von Neumann bottleneck, current computing architectures and methods fuel this high power consumption. Here, we present an analog computing method that harnesses chaotic nonlinear attractors to perform machine learning tasks with low power consumption. Inspired by neuromorphic computing, our model is a programmable, versatile, and generalized platform for machine learning tasks. Our mode provides exceptional performance in clustering by utilizing chaotic attractors' nonlinear mapping and sensitivity to initial conditions. When deployed as a simple analog device, it only requires milliwatt-scale power levels while being on par with current machine learning techniques. We demonstrate low errors and high accuracies with our model for regression and classification-based learning tasks.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:机器学习研究需要巨大的能源来处理庞大的数据集和训练神经网络以达到高精度，这已经变得不可持续。由于 von Neumann 瓶颈，当前的计算架构和方法都在提高能 consumption。在这里，我们提出了一种 Analog computing 方法，利用混沌非线性吸引器来实现机器学习任务，具有低功耗Characteristics。 draw inspiration from neuromorphic computing， our model is a programmable, versatile, and generalized platform for machine learning tasks. Our model shows excellent performance in clustering by leveraging chaotic attractors' nonlinear mapping and sensitivity to initial conditions. When deployed as a simple analog device, it only requires milliwatt-scale power levels while being on par with current machine learning techniques. We demonstrate low errors and high accuracies with our model for regression and classification-based learning tasks.
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Particle-and-Fluid-Simulations-with-Differentiable-Graph-Networks-for-Solving-Forward-and-Inverse-Problems"><a href="#Accelerating-Particle-and-Fluid-Simulations-with-Differentiable-Graph-Networks-for-Solving-Forward-and-Inverse-Problems" class="headerlink" title="Accelerating Particle and Fluid Simulations with Differentiable Graph Networks for Solving Forward and Inverse Problems"></a>Accelerating Particle and Fluid Simulations with Differentiable Graph Networks for Solving Forward and Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13348">http://arxiv.org/abs/2309.13348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krishna Kumar, Yongjin Choi</li>
<li>for: 加速粒子和液体 simulations，解决前向和 inverse problems。</li>
<li>methods: 使用物理嵌入的分发式图网络模型（GNS），通过学习Edge messages来学习本地互动规则，提高对新环境的泛化能力。</li>
<li>results: 对于 granular flow prediction 比 CPU 平行数值计算 Speedup 达到 165 倍，提议一种 hybrid GNS&#x2F;Material Point Method（MPM），能够在 GNS rollouts 中插入 MPM，以满足保守量和误差最小化，实现了对数值计算的 24 倍加速。 GNS 还可以解决 inverse problems，通过自动导数来计算摩擦角的梯度，并且可以逐步更新摩擦角，以实现最佳匹配目标跑道距离。<details>
<summary>Abstract</summary>
We leverage physics-embedded differentiable graph network simulators (GNS) to accelerate particulate and fluid simulations to solve forward and inverse problems. GNS represents the domain as a graph with particles as nodes and learned interactions as edges. Compared to modeling global dynamics, GNS enables learning local interaction laws through edge messages, improving its generalization to new environments. GNS achieves over 165x speedup for granular flow prediction compared to parallel CPU numerical simulations. We propose a novel hybrid GNS/Material Point Method (MPM) to accelerate forward simulations by minimizing error on a pure surrogate model by interleaving MPM in GNS rollouts to satisfy conservation laws and minimize errors achieving 24x speedup compared to pure numerical simulations. The differentiable GNS enables solving inverse problems through automatic differentiation, identifying material parameters that result in target runout distances. We demonstrate the ability of GNS to solve inverse problems by iteratively updating the friction angle (a material property) by computing the gradient of a loss function based on the final and target runouts, thereby identifying the friction angle that best matches the observed runout. The physics-embedded and differentiable simulators open an exciting new paradigm for AI-accelerated design, control, and optimization.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:我们利用嵌入物理的分解urable图示网络优化器（GNS）加速粒子和流体 simulations以解决前向和反向问题。GNS将Domain表示为一个图，粒子作为节点，学习交互作为边。与模型全局动力学相比，GNS可以通过边上消息学习地方交互规则，提高其适应新环境的能力。GNS在粒子流预测方面实现了165倍的加速，比CPU并行数值 simulations 高得多。我们提出了一种新的混合GNS/物理点方法（MPM），通过混合MPM在GNS扫描中来加速前向 simulations，以满足保守法和降低误差，实现24倍的加速比例。可微的GNS可以通过自动导数来解决反向问题，Material angle （一种材料属性）的迭代更新，以实现最佳匹配目标跑道距离。我们示出了GNS可以解决反向问题，通过计算目标跑道距离和最终跑道距离的损失函数梯度来更新Friction angle。物理嵌入和可微的模拟器开启了一个新的AI加速设计、控制和优化的新时代。
</details></li>
</ul>
<hr>
<h2 id="On-the-Asymptotic-Learning-Curves-of-Kernel-Ridge-Regression-under-Power-law-Decay"><a href="#On-the-Asymptotic-Learning-Curves-of-Kernel-Ridge-Regression-under-Power-law-Decay" class="headerlink" title="On the Asymptotic Learning Curves of Kernel Ridge Regression under Power-law Decay"></a>On the Asymptotic Learning Curves of Kernel Ridge Regression under Power-law Decay</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13337">http://arxiv.org/abs/2309.13337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicheng Li, Haobo Zhang, Qian Lin</li>
<li>for: 本研究探讨了 neural network 中广泛观察到的 ‘benign overfitting’ 现象，这个现象对 statistical learning theory 中的 ‘bias-variance trade-off’ 假设提出了挑战。</li>
<li>methods: 本研究使用了 kernel ridge regression 来描述 neural network 的学习曲线，并提供了一个准确的学习曲线 Characterization，包括 regulatory parameter 的选择、source condition 和 noise 的效应。</li>
<li>results: 研究结果表明，在小量噪声下，very wide neural network 才存在 ‘benign overfitting’ 现象。<details>
<summary>Abstract</summary>
The widely observed 'benign overfitting phenomenon' in the neural network literature raises the challenge to the 'bias-variance trade-off' doctrine in the statistical learning theory. Since the generalization ability of the 'lazy trained' over-parametrized neural network can be well approximated by that of the neural tangent kernel regression, the curve of the excess risk (namely, the learning curve) of kernel ridge regression attracts increasing attention recently. However, most recent arguments on the learning curve are heuristic and are based on the 'Gaussian design' assumption. In this paper, under mild and more realistic assumptions, we rigorously provide a full characterization of the learning curve: elaborating the effect and the interplay of the choice of the regularization parameter, the source condition and the noise. In particular, our results suggest that the 'benign overfitting phenomenon' exists in very wide neural networks only when the noise level is small.
</details>
<details>
<summary>摘要</summary>
widely observed "benign overfitting phenomenon" in the neural network literature raises the challenge to the "bias-variance trade-off" doctrine in the statistical learning theory. Since the generalization ability of the "lazy trained" over-parametrized neural network can be well approximated by that of the neural tangent kernel regression, the curve of the excess risk (namely, the learning curve) of kernel ridge regression attracts increasing attention recently. However, most recent arguments on the learning curve are heuristic and are based on the "Gaussian design" assumption. In this paper, under mild and more realistic assumptions, we rigorously provide a full characterization of the learning curve: elaborating the effect and the interplay of the choice of the regularization parameter, the source condition, and the noise. In particular, our results suggest that the "benign overfitting phenomenon" exists in very wide neural networks only when the noise level is small.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Temperature-of-Major-Cities-Using-Machine-Learning-and-Deep-Learning"><a href="#Predicting-Temperature-of-Major-Cities-Using-Machine-Learning-and-Deep-Learning" class="headerlink" title="Predicting Temperature of Major Cities Using Machine Learning and Deep Learning"></a>Predicting Temperature of Major Cities Using Machine Learning and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13330">http://arxiv.org/abs/2309.13330</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wasiou Jaharabi, MD Ibrahim Al Hossain, Rownak Tahmid, Md. Zuhayer Islam, T. M. Saad Rayhan</li>
<li>For: The paper aims to develop an accurate temperature prediction method using machine learning algorithms and time series analysis, specifically focusing on the temperature data of major cities.* Methods: The authors use a dataset provided by the University of Dayton, which includes temperature data from major cities. They apply time series analysis techniques such as ARIMA, SARIMA, and Prophet, and incorporate the concept of RNN and LSTM to filter out abnormalities, preprocess the data, and make predictions of future temperature trends.* Results: The authors achieve accurate predictions of temperature in major cities based on the available data, and demonstrate the effectiveness of their method in combating climate change by providing accurate temperature predictions for future reference.<details>
<summary>Abstract</summary>
Currently, the issue that concerns the world leaders most is climate change for its effect on agriculture, environment and economies of daily life. So, to combat this, temperature prediction with strong accuracy is vital. So far, the most effective widely used measure for such forecasting is Numerical weather prediction (NWP) which is a mathematical model that needs broad data from different applications to make predictions. This expensive, time and labor consuming work can be minimized through making such predictions using Machine learning algorithms. Using the database made by University of Dayton which consists the change of temperature in major cities we used the Time Series Analysis method where we use LSTM for the purpose of turning existing data into a tool for future prediction. LSTM takes the long-term data as well as any short-term exceptions or anomalies that may have occurred and calculates trend, seasonality and the stationarity of a data. By using models such as ARIMA, SARIMA, Prophet with the concept of RNN and LSTM we can, filter out any abnormalities, preprocess the data compare it with previous trends and make a prediction of future trends. Also, seasonality and stationarity help us analyze the reoccurrence or repeat over one year variable and removes the constrain of time in which the data was dependent so see the general changes that are predicted. By doing so we managed to make prediction of the temperature of different cities during any time in future based on available data and built a method of accurate prediction. This document contains our methodology for being able to make such predictions.
</details>
<details>
<summary>摘要</summary>
To develop our methodology, we used a database of temperature changes in major cities, provided by the University of Dayton. We employed Time Series Analysis, specifically Long Short-Term Memory (LSTM) models, to turn existing data into a tool for future prediction. LSTM models can capture long-term trends, seasonality, and stationarity in the data, allowing us to make accurate predictions.We used models such as ARIMA, SARIMA, and Prophet, all of which incorporate the concept of Recurrent Neural Networks (RNN) and LSTM. These models can filter out anomalies, preprocess the data, and compare it with previous trends to make accurate predictions. Additionally, seasonality and stationarity help us analyze the reoccurrence of variables over one year and remove the constraints of time, allowing us to see general changes predicted.By using this methodology, we were able to make accurate predictions of temperature in different cities at any time in the future based on available data. This document outlines our methodology for making such predictions.
</details></li>
</ul>
<hr>
<h2 id="An-Interpretable-Systematic-Review-of-Machine-Learning-Models-for-Predictive-Maintenance-of-Aircraft-Engine"><a href="#An-Interpretable-Systematic-Review-of-Machine-Learning-Models-for-Predictive-Maintenance-of-Aircraft-Engine" class="headerlink" title="An Interpretable Systematic Review of Machine Learning Models for Predictive Maintenance of Aircraft Engine"></a>An Interpretable Systematic Review of Machine Learning Models for Predictive Maintenance of Aircraft Engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13310">http://arxiv.org/abs/2309.13310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdullah Al Hasib, Ashikur Rahman, Mahpara Khabir, Md. Tanvir Rouf Shawon</li>
<li>For: This paper aims to predict aircraft engine failure using machine learning and deep learning models to avoid any kind of disaster.* Methods: The paper utilizes sensor data and employs various machine learning and deep learning models such as LSTM, Bi-LSTM, RNN, Bi-RNN, GRU, Random Forest, KNN, Naive Bayes, and Gradient Boosting to predict aircraft engine failure within a predetermined number of cycles.* Results: The paper achieves a lucrative accuracy of 97.8%, 97.14%, and 96.42% using GRU, Bi-LSTM, and LSTM respectively, demonstrating the capability of the models to predict maintenance at an early stage.<details>
<summary>Abstract</summary>
This paper presents an interpretable review of various machine learning and deep learning models to predict the maintenance of aircraft engine to avoid any kind of disaster. One of the advantages of the strategy is that it can work with modest datasets. In this study, sensor data is utilized to predict aircraft engine failure within a predetermined number of cycles using LSTM, Bi-LSTM, RNN, Bi-RNN GRU, Random Forest, KNN, Naive Bayes, and Gradient Boosting. We explain how deep learning and machine learning can be used to generate predictions in predictive maintenance using a straightforward scenario with just one data source. We applied lime to the models to help us understand why machine learning models did not perform well than deep learning models. An extensive analysis of the model's behavior is presented for several test data to understand the black box scenario of the models. A lucrative accuracy of 97.8%, 97.14%, and 96.42% are achieved by GRU, Bi-LSTM, and LSTM respectively which denotes the capability of the models to predict maintenance at an early stage.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CORE-Common-Random-Reconstruction-for-Distributed-Optimization-with-Provable-Low-Communication-Complexity"><a href="#CORE-Common-Random-Reconstruction-for-Distributed-Optimization-with-Provable-Low-Communication-Complexity" class="headerlink" title="CORE: Common Random Reconstruction for Distributed Optimization with Provable Low Communication Complexity"></a>CORE: Common Random Reconstruction for Distributed Optimization with Provable Low Communication Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13307">http://arxiv.org/abs/2309.13307</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengyun Yue, Hanzhen Zhao, Cong Fang, Di He, Liwei Wang, Zhouchen Lin, Song-chun Zhu</li>
<li>For: 降低分布式机器学习中的通信复杂度，以提高训练速度和扩展机器数。* Methods: 提出了一新技术 named Common randOm REconstruction(CORE), 可以压缩在机器之间传输的信息，以降低通信复杂度，不受其他严格条件限制。 CORE 将 вектор值信息投影到低维度的归一化向量上，并在通信后重建信息，通过共同Random vectors。* Results: 应用 CORE 到两个分布式任务，分别是线性模型的凸优化和通用非凸优化，设计了新的分布式算法，可以证明性地降低通信复杂度。例如，我们示出对线性模型，CORE 基于算法可以编码梯度 вектор到 $\mathcal{O}(1)$-bits（对 $\mathcal{O}(d)$ 比），并保持不变的整体趋势，超过现有结果。<details>
<summary>Abstract</summary>
With distributed machine learning being a prominent technique for large-scale machine learning tasks, communication complexity has become a major bottleneck for speeding up training and scaling up machine numbers. In this paper, we propose a new technique named Common randOm REconstruction(CORE), which can be used to compress the information transmitted between machines in order to reduce communication complexity without other strict conditions. Especially, our technique CORE projects the vector-valued information to a low-dimensional one through common random vectors and reconstructs the information with the same random noises after communication. We apply CORE to two distributed tasks, respectively convex optimization on linear models and generic non-convex optimization, and design new distributed algorithms, which achieve provably lower communication complexities. For example, we show for linear models CORE-based algorithm can encode the gradient vector to $\mathcal{O}(1)$-bits (against $\mathcal{O}(d)$), with the convergence rate not worse, preceding the existing results.
</details>
<details>
<summary>摘要</summary>
With 分布式机器学习技术在大规模机器学习任务中成为主要瓶颈，交流复杂性已成为加速训练和扩大机器数量的关键问题。在这篇论文中，我们提出一种新的技术名为通用随机重建（CORE），可以减少机器之间的信息传输量，从而降低交流复杂性，而无需其他严格条件。尤其是，我们的CORE技术将向量值信息映射到低维度的均匀随机向量上，并在通信后重建信息，同时保留了同样的随机噪声。我们在两个分布式任务中应用CORE技术，分别是线性模型的凸优化和非凸优化，并设计了新的分布式算法，实现了可靠性下降的交流复杂性。例如，我们示出了对线性模型的CORE-based算法可以将梯度向量编码为$\mathcal{O}(1)$-比特（对$\mathcal{O}(d)$比特），并且保持不变的整体性能。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Fairness-Age-Harmless-Parkinson’s-Detection-via-Voice"><a href="#Beyond-Fairness-Age-Harmless-Parkinson’s-Detection-via-Voice" class="headerlink" title="Beyond Fairness: Age-Harmless Parkinson’s Detection via Voice"></a>Beyond Fairness: Age-Harmless Parkinson’s Detection via Voice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13292">http://arxiv.org/abs/2309.13292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicheng Wang, Xiaotian Han, Leisheng Yu, Na Zou</li>
<li>for: 这个研究旨在提高 Parkinson’s disease（PD）早期识别的准确性，特别是针对年轻人群（age ≤ 55），因为现有的深度学习模型具有年龄问题。</li>
<li>methods: 我们使用 GradCAM-based 特征遮罩和组合模型来解决年龄问题，保持公平性和准确性。特别是，GradCAM-based 特征遮罩 selectively 隐藏年龄相关的特征，以保持关键的PD检测信息。组合模型进一步提高了少数群（年轻人群）的预测精度。</li>
<li>results: 我们的方法可以增强PD早期识别的准确性，不会对老年人群（age &gt; 55）的预测精度造成影响。此外，我们也提出了一个两步检测策略，以便评估年轻人群中可能的PD早期病人。<details>
<summary>Abstract</summary>
Parkinson's disease (PD), a neurodegenerative disorder, often manifests as speech and voice dysfunction. While utilizing voice data for PD detection has great potential in clinical applications, the widely used deep learning models currently have fairness issues regarding different ages of onset. These deep models perform well for the elderly group (age $>$ 55) but are less accurate for the young group (age $\leq$ 55). Through our investigation, the discrepancy between the elderly and the young arises due to 1) an imbalanced dataset and 2) the milder symptoms often seen in early-onset patients. However, traditional debiasing methods are impractical as they typically impair the prediction accuracy for the majority group while minimizing the discrepancy. To address this issue, we present a new debiasing method using GradCAM-based feature masking combined with ensemble models, ensuring that neither fairness nor accuracy is compromised. Specifically, the GradCAM-based feature masking selectively obscures age-related features in the input voice data while preserving essential information for PD detection. The ensemble models further improve the prediction accuracy for the minority (young group). Our approach effectively improves detection accuracy for early-onset patients without sacrificing performance for the elderly group. Additionally, we propose a two-step detection strategy for the young group, offering a practical risk assessment for potential early-onset PD patients.
</details>
<details>
<summary>摘要</summary>
帕金森病（PD），一种神经退化疾病，经常表现为语音和嗓音畸形。使用语音数据进行PD检测具有很大的优势，但目前广泛使用的深度学习模型存在年龄偏见问题。这些深度模型对于年龄大于55岁的老年组（age>55）表现良好，但对年龄小于或等于55岁的青年组（age<=55）表现不准确。经过我们的调查，年龄偏见的原因包括1）数据集偏见和2）早期病人的轻微症状。然而，传统的偏见纠正方法不实用，因为它们通常会降低主要组（老年组）的预测精度。为解决这个问题，我们提出了一种新的偏见纠正方法，利用GradCAM基于特征遮盖和ensemble模型，以确保不会降低公平性和精度。具体来说，GradCAM基于特征遮盖选择性地遮盖语音数据中年龄相关的特征，保留PD检测中必要的信息。而ensemble模型进一步提高了少数群（年龄小于或等于55岁）的预测精度。我们的方法可以提高早期PD检测的准确率，而不会损害老年组的表现。此外，我们还提议了一种两步检测策略，为 potential early-onset PD 患者提供实用的风险评估。
</details></li>
</ul>
<hr>
<h2 id="Distributional-Shift-Aware-Off-Policy-Interval-Estimation-A-Unified-Error-Quantification-Framework"><a href="#Distributional-Shift-Aware-Off-Policy-Interval-Estimation-A-Unified-Error-Quantification-Framework" class="headerlink" title="Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework"></a>Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13278">http://arxiv.org/abs/2309.13278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhuo Zhou, Yuhan Li, Ruoqing Zhu, Annie Qu</li>
<li>for: 该文章的目的是为了在无法预测行为政策下验证高置信度的策略评估。</li>
<li>methods: 该文章使用了一种新的统一错误分析，它同时量化了两种错误来源：模型缺陷和采样统计变化。</li>
<li>results: 该文章的方法可以在无需假设任何弱依赖关系的情况下，对无限时间执行 Markov 决策过程中的目标策略值进行高置信度评估，并且可以适应不同的分布转换。<details>
<summary>Abstract</summary>
We study high-confidence off-policy evaluation in the context of infinite-horizon Markov decision processes, where the objective is to establish a confidence interval (CI) for the target policy value using only offline data pre-collected from unknown behavior policies. This task faces two primary challenges: providing a comprehensive and rigorous error quantification in CI estimation, and addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process. Motivated by an innovative unified error analysis, we jointly quantify the two sources of estimation errors: the misspecification error on modeling marginalized importance weights and the statistical uncertainty due to sampling, within a single interval. This unified framework reveals a previously hidden tradeoff between the errors, which undermines the tightness of the CI. Relying on a carefully designed discriminator function, the proposed estimator achieves a dual purpose: breaking the curse of the tradeoff to attain the tightest possible CI, and adapting the CI to ensure robustness against distributional shifts. Our method is applicable to time-dependent data without assuming any weak dependence conditions via leveraging a local supermartingale/martingale structure. Theoretically, we show that our algorithm is sample-efficient, error-robust, and provably convergent even in non-linear function approximation settings. The numerical performance of the proposed method is examined in synthetic datasets and an OhioT1DM mobile health study.
</details>
<details>
<summary>摘要</summary>
我们研究高自信度偏离策略评估在无穷远 horizon Markov决策过程中，目标是使用偏离策略评估数据来建立一个信息interval（CI）的目标策略价值。这个任务面临两个主要挑战：一是提供全面和准确的误差量化，二是Addressing the distributional shift that results from discrepancies between the distribution induced by the target policy and the offline data-generating process。我们受益于一种创新的统一错误分析，可以同时量化两个来源的误差：模型缺陷导致的重要性加权的误差和采样统计误差。这种统一框架显示了一个隐藏的贸易关系，这种关系使得CI的紧密性受到影响。我们采用一种特制的探测函数，该函数可以实现两个目的：打破贸易关系，以便获得最紧密的CI，并适应CI以确保对分布差异的Robustness。我们的方法可以在没有任何弱依赖条件下应用于时间相关的数据，通过利用本地超martingale/martingale结构。理论上，我们显示了我们的算法是样本效率的，误差稳定的，并在非线性函数近似设定下可靠地收敛。我们的方法的数学性能在 sintetic数据和OhioT1DM移动医学研究中进行了数值验证。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Sequential-Decoder-for-Transient-High-Density-Electromyography-in-Hand-Gesture-Recognition-Using-Subject-Embedded-Transfer-Learning"><a href="#A-Deep-Learning-Sequential-Decoder-for-Transient-High-Density-Electromyography-in-Hand-Gesture-Recognition-Using-Subject-Embedded-Transfer-Learning" class="headerlink" title="A Deep Learning Sequential Decoder for Transient High-Density Electromyography in Hand Gesture Recognition Using Subject-Embedded Transfer Learning"></a>A Deep Learning Sequential Decoder for Transient High-Density Electromyography in Hand Gesture Recognition Using Subject-Embedded Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03752">http://arxiv.org/abs/2310.03752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Golara Ahmadi Azar, Qin Hu, Melika Emami, Alyson Fletcher, Sundeep Rangan, S. Farokh Atashzar</li>
<li>for: 这个研究旨在提高人工智能与人类肢体互动的整合，使用深度学习方法来识别手势。</li>
<li>methods: 这个研究使用了深度学习模型，并将Subject-specific transfer learning和多因素混合结构组合在一起，以提高手势识别精度。</li>
<li>results: 研究获得了73%的平均准确率，在65个手势中预测了73%的手势，并且在有限的训练数据下表现比subject-specific方法更好。<details>
<summary>Abstract</summary>
Hand gesture recognition (HGR) has gained significant attention due to the increasing use of AI-powered human-computer interfaces that can interpret the deep spatiotemporal dynamics of biosignals from the peripheral nervous system, such as surface electromyography (sEMG). These interfaces have a range of applications, including the control of extended reality, agile prosthetics, and exoskeletons. However, the natural variability of sEMG among individuals has led researchers to focus on subject-specific solutions. Deep learning methods, which often have complex structures, are particularly data-hungry and can be time-consuming to train, making them less practical for subject-specific applications. In this paper, we propose and develop a generalizable, sequential decoder of transient high-density sEMG (HD-sEMG) that achieves 73% average accuracy on 65 gestures for partially-observed subjects through subject-embedded transfer learning, leveraging pre-knowledge of HGR acquired during pre-training. The use of transient HD-sEMG before gesture stabilization allows us to predict gestures with the ultimate goal of counterbalancing system control delays. The results show that the proposed generalized models significantly outperform subject-specific approaches, especially when the training data is limited, and there is a significant number of gesture classes. By building on pre-knowledge and incorporating a multiplicative subject-embedded structure, our method comparatively achieves more than 13% average accuracy across partially observed subjects with minimal data availability. This work highlights the potential of HD-sEMG and demonstrates the benefits of modeling common patterns across users to reduce the need for large amounts of data for new users, enhancing practicality.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）激活人机界面（HGR）已经吸引了广泛的关注，因为它可以通过解读 périphérique nervous system的深度空间动态特征，如表面电MYography（sEMG）来控制虚拟现实、迅速 prótesis 和 exoskeletons。然而，人类的自然变化导致研究人员更加注重具体化解决方案。深度学习方法，经常具有复杂结构，需要大量数据和训练时间，使其更难实现具体化应用。在这篇论文中，我们提出和开发了一种通用的、顺序解码器，可以在部分观察者下达73%的平均准确率，对65个手势进行预测，通过在pre-training中获得的HGR知识进行嵌入式传播学习。使用transient HD-sEMG передgesture稳定化可以预测手势，以ultimate goal of counterbalancing system control delays。结果表明，我们的总体模型在限制数据量的情况下，特别是有许多手势类型的情况下，较subject-specific方法表现出优异。通过建立在pre-knowledge基础上，并通过multiplicative subject-embedded结构，我们的方法可以在有限的数据可用性下，实现更高的13%的平均准确率。这种工作展示了HD-sEMG的潜力，并证明了模型Users across common patterns可以降低新用户需要的数据量，提高实用性。
</details></li>
</ul>
<hr>
<h2 id="Zen-Near-Optimal-Sparse-Tensor-Synchronization-for-Distributed-DNN-Training"><a href="#Zen-Near-Optimal-Sparse-Tensor-Synchronization-for-Distributed-DNN-Training" class="headerlink" title="Zen: Near-Optimal Sparse Tensor Synchronization for Distributed DNN Training"></a>Zen: Near-Optimal Sparse Tensor Synchronization for Distributed DNN Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13254">http://arxiv.org/abs/2309.13254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuang Wang, Zhaozhuo Xu, Anshumali Shrivastava, T. S. Eugene Ng</li>
<li>for: 这篇论文的目的是提出一个最佳的通信方案，以缩小在分布式训练深度神经网络（DNNs）中的交通量，并提高总训练效率。</li>
<li>methods: 这篇论文使用了系统性地探索了对缓冲量矩阵的通信方案设计空间，以找出最佳的方案。它还开发了一个称为Zen的Gradient Synchronization系统，可以实现这个最佳方案。</li>
<li>results: 这篇论文的结果显示，使用Zen的Gradient Synchronization系统可以实现至多5.09倍的交通时间减少和训练过程中的对比增加，相比之前的方法。<details>
<summary>Abstract</summary>
Distributed training is the de facto standard to scale up the training of Deep Neural Networks (DNNs) with multiple GPUs. The performance bottleneck of distributed training lies in communications for gradient synchronization. Recently, practitioners have observed sparsity in gradient tensors, suggesting the potential to reduce the traffic volume in communication and improve end-to-end training efficiency. Yet, the optimal communication scheme to fully leverage sparsity is still missing. This paper aims to address this gap. We first analyze the characteristics of sparse tensors in popular DNN models to understand the fundamentals of sparsity. We then systematically explore the design space of communication schemes for sparse tensors and find the optimal one. % We then find the optimal scheme based on the characteristics by systematically exploring the design space. We also develop a gradient synchronization system called Zen that approximately realizes it for sparse tensors. We demonstrate that Zen can achieve up to 5.09x speedup in communication time and up to 2.48x speedup in training throughput compared to the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
分布式训练是深度神经网络（DNN）训练的标准化方法，以多个GPU进行扩大。但是，分布式训练的性能瓶颈在交换梯度同步方面。在实践中，人们发现了梯度矩阵中的稀疏性，这表明可以减少交换的流量并提高端到端训练效率。然而，完全利用稀疏性的最佳通信方案仍然缺失。这篇论文的目的是填补这个差距。我们首先分析了流行的DNN模型中稀疏矩阵的特点，以了解稀疏性的基础。然后，我们系统地探索了稀疏矩阵的通信方案的设计空间，并找到最佳的一种。我们还开发了一个名为“Zen”的梯度同步系统，可以对稀疏矩阵进行约束式实现。我们 demonstarte了Zen可以在交换时间方面实现5.09倍的速度提高和在训练吞吐量方面实现2.48倍的速度提高，比现有方法更高。
</details></li>
</ul>
<hr>
<h2 id="Importance-of-negative-sampling-in-weak-label-learning"><a href="#Importance-of-negative-sampling-in-weak-label-learning" class="headerlink" title="Importance of negative sampling in weak label learning"></a>Importance of negative sampling in weak label learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13227">http://arxiv.org/abs/2309.13227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ankit Shah, Fuyu Tang, Zelin Ye, Rita Singh, Bhiksha Raj</li>
<li>for: 这个论文的目的是研究如何在弱标注学习中选择最有用的负例。</li>
<li>methods: 该论文使用了多种采样策略来评估负例的用于弱标注学习中的有用性，并选择其中的最有用的负例。</li>
<li>results: 该论文在CIFAR-10和AudioSet datasets上进行测试，并显示了减少计算成本和提高弱标注分类性能的result。<details>
<summary>Abstract</summary>
Weak-label learning is a challenging task that requires learning from data "bags" containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.
</details>
<details>
<summary>摘要</summary>
弱标记学习是一项具有挑战性的任务，需要从包含正例和负例的数据袋中学习，但只知道包袋标签。负例pool通常比正例pool更大，因此选择每个包袋中最有用的负例是一个开放的问题，尚未得到了充分的研究。在这篇论文中，我们研究了一些采样策略，可以衡量负例对弱标记学习的用于fulfillment，并根据此选择负例。我们在CIFAR-10和AudioSet数据集上测试了我们的方法，并证明它可以提高弱标记分类性能和降低计算成本，相比随机采样方法。我们的工作表明，负例不是一样无关，选择它们谨慎可以帮助弱标记学习。
</details></li>
</ul>
<hr>
<h2 id="Grad-DFT-a-software-library-for-machine-learning-enhanced-density-functional-theory"><a href="#Grad-DFT-a-software-library-for-machine-learning-enhanced-density-functional-theory" class="headerlink" title="Grad DFT: a software library for machine learning enhanced density functional theory"></a>Grad DFT: a software library for machine learning enhanced density functional theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15127">http://arxiv.org/abs/2309.15127</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XanaduAI/GradDFT">https://github.com/XanaduAI/GradDFT</a></li>
<li>paper_authors: Pablo A. M. Casares, Jack S. Baker, Matija Medvidovic, Roberto dos Reis, Juan Miguel Arrazola</li>
<li>for: 本研究旨在扩展density functional theory（DFT）的可Accuracy，特别是在强 correlate系统中。</li>
<li>methods: 该研究使用机器学习技术来扩展DFT的能力，并采用了一种新的 exchange-correlation functional parametrization方法，其中使用神经网络确定函数的重要性。</li>
<li>results: 研究人员开发了一个名为Grad DFT的完全可导的JAX基础库，可以快速实现和试验机器学习提高DFT的exchange-correlation能量函数。此外，研究人员还编译了一个精心选择的实验数据集，用于训练和测试模型的准确性。<details>
<summary>Abstract</summary>
Density functional theory (DFT) stands as a cornerstone method in computational quantum chemistry and materials science due to its remarkable versatility and scalability. Yet, it suffers from limitations in accuracy, particularly when dealing with strongly correlated systems. To address these shortcomings, recent work has begun to explore how machine learning can expand the capabilities of DFT; an endeavor with many open questions and technical challenges. In this work, we present Grad DFT: a fully differentiable JAX-based DFT library, enabling quick prototyping and experimentation with machine learning-enhanced exchange-correlation energy functionals. Grad DFT employs a pioneering parametrization of exchange-correlation functionals constructed using a weighted sum of energy densities, where the weights are determined using neural networks. Moreover, Grad DFT encompasses a comprehensive suite of auxiliary functions, notably featuring a just-in-time compilable and fully differentiable self-consistent iterative procedure. To support training and benchmarking efforts, we additionally compile a curated dataset of experimental dissociation energies of dimers, half of which contain transition metal atoms characterized by strong electronic correlations. The software library is tested against experimental results to study the generalization capabilities of a neural functional across potential energy surfaces and atomic species, as well as the effect of training data noise on the resulting model accuracy.
</details>
<details>
<summary>摘要</summary>
density functional theory（DFT）是计算量子化学和材料科学中的一种重要方法，它具有优秀的 universality 和可扩展性。然而，它在强 correlate 系统中的准确性有限制。为了解决这些缺陷，最近的工作开始使用机器学习技术来扩展 DFT 的能力；这是一个充满开放 вопросов和技术挑战的尝试。在这个工作中，我们提出了 Grad DFT：一个完全可导的 JAX 基础库，允许快速的原型和机器学习增强 exchange-correlation 能量函数的 экспериментирование。Grad DFT 使用一种先进的 exchange-correlation 函数的参数化方法，该方法通过使用神经网络确定的权重，将 exchange-correlation 函数转化为一个可导的形式。此外，Grad DFT 还包括一系列辅助函数，其中包括一个可编译的和完全可导的自 consistent 迭代过程。为支持训练和测试努力，我们还编译了一个权威的对应的实验性离解能量数据集，该数据集包括含有过渡金属原子的 dimer 的实验离解能量，这些金属原子具有强电子 correlate 性。软件库在实验结果上进行测试，以研究一个神经函数在 potential energy surface 和原子种之间的泛化能力，以及训练数据噪声对模型准确性的影响。
</details></li>
</ul>
<hr>
<h2 id="Causal-Reasoning-Charting-a-Revolutionary-Course-for-Next-Generation-AI-Native-Wireless-Networks"><a href="#Causal-Reasoning-Charting-a-Revolutionary-Course-for-Next-Generation-AI-Native-Wireless-Networks" class="headerlink" title="Causal Reasoning: Charting a Revolutionary Course for Next-Generation AI-Native Wireless Networks"></a>Causal Reasoning: Charting a Revolutionary Course for Next-Generation AI-Native Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13223">http://arxiv.org/abs/2309.13223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christo Kurisummoottil Thomas, Christina Chaccour, Walid Saad, Merouane Debbah, Choong Seon Hong</li>
<li>for: 本文提出了一种全面、前瞻的视野，以响应现有的 wireless 网络挑战，通过 causal reasoning 建立可解释、理解、可持续的无线网络。</li>
<li>methods: 本文提出了一种基于 causal discovery、causal representation learning 和 causal inference 的新框架，用于建立 AI-native 无线网络。</li>
<li>results: 本文指出，通过 incorporating causal discovery，可以解决无线网络中的一些挑战，如 ultra-reliable beamforming、near-accurate physical twin modeling、training data augmentation 和 semantic communication。同时，本文还提出了一些可能的框架，用于通过 causal inference 实现未来无线网络的总体目标，包括意图管理、动态适应性、人类水平的认知和理解。<details>
<summary>Abstract</summary>
Despite the basic premise that next-generation wireless networks (e.g., 6G) will be artificial intelligence (AI)-native, to date, most existing efforts remain either qualitative or incremental extensions to existing ``AI for wireless'' paradigms. Indeed, creating AI-native wireless networks faces significant technical challenges due to the limitations of data-driven, training-intensive AI. These limitations include the black-box nature of the AI models, their curve-fitting nature, which can limit their ability to reason and adapt, their reliance on large amounts of training data, and the energy inefficiency of large neural networks. In response to these limitations, this article presents a comprehensive, forward-looking vision that addresses these shortcomings by introducing a novel framework for building AI-native wireless networks; grounded in the emerging field of causal reasoning. Causal reasoning, founded on causal discovery, causal representation learning, and causal inference, can help build explainable, reasoning-aware, and sustainable wireless networks. Towards fulfilling this vision, we first highlight several wireless networking challenges that can be addressed by causal discovery and representation, including ultra-reliable beamforming for terahertz (THz) systems, near-accurate physical twin modeling for digital twins, training data augmentation, and semantic communication. We showcase how incorporating causal discovery can assist in achieving dynamic adaptability, resilience, and cognition in addressing these challenges. Furthermore, we outline potential frameworks that leverage causal inference to achieve the overarching objectives of future-generation networks, including intent management, dynamic adaptability, human-level cognition, reasoning, and the critical element of time sensitivity.
</details>
<details>
<summary>摘要</summary>
尽管下一代无线网络（如6G）将是人工智能（AI）Native，但到目前为止，大多数现有努力仍然是质量的或增量的对现有“AI for wireless” paradigms的扩展。实际上，创建AI Native的无线网络面临着 significativetchnical挑战，主要是因为AI模型的黑盒性、curve-fitting性、需要大量训练数据、以及大 neural networks的能源浪费。为了解决这些挑战，这篇文章提出了一个全面的、前瞻的视野，通过引入一种新的AI Native无线网络框架来解决这些缺陷。这个框架基于emerging field of causal reasoning，可以帮助建立可解释、 reasoning-aware 和可持续的无线网络。为实现这个视野，我们首先 highlight了一些无线网络挑战可以通过 causal discovery 和 representation learning来解决，包括THz系统中的可靠性 beamforming、数字 twin 模型化、训练数据增强和semantic communication。我们示出了如何通过 causal discovery 来实现动态适应、抗难以适应和认知的能力。此外，我们还 outline了可以利用 causal inference 来实现未来 generation networks 的主要目标，包括意图管理、动态适应、人类水平的认知、reasoning 和时间敏感性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/cs.LG_2023_09_23/" data-id="clp9qz87900s4ok88aoze9um3" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/eess.IV_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T09:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/eess.IV_2023_09_23/">eess.IV - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Gaining-Insights-into-Denoising-by-Inpainting"><a href="#Gaining-Insights-into-Denoising-by-Inpainting" class="headerlink" title="Gaining Insights into Denoising by Inpainting"></a>Gaining Insights into Denoising by Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13486">http://arxiv.org/abs/2309.13486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Gaa, Vassillen Chizhov, Pascal Peter, Joachim Weickert, Robin Dirk Adam</li>
<li>for: 这个论文的目的是研究一种基于扩散过程的图像分析技术，包括填充-基于压缩和稠密运动计算。</li>
<li>methods: 这个论文使用了多种方法，包括多个不同的扩散子集的填充结果的平均值，以及改变函数值的方法来提高全局逼近质量。</li>
<li>results: 实验表明，使用不同的扩散方法不会提高重建质量，而是数据适应性更重要。此外，这个论文还提出了一些基本的理论和估计结果，包括在1-D情况下的等价关系。<details>
<summary>Abstract</summary>
The filling-in effect of diffusion processes is a powerful tool for various image analysis tasks such as inpainting-based compression and dense optic flow computation. For noisy data, an interesting side effect occurs: The interpolated data have higher confidence, since they average information from many noisy sources. This observation forms the basis of our denoising by inpainting (DbI) framework. It averages multiple inpainting results from different noisy subsets. Our goal is to obtain fundamental insights into key properties of DbI and its connections to existing methods. Like in inpainting-based image compression, we choose homogeneous diffusion as a very simple inpainting operator that performs well for highly optimized data. We propose several strategies to choose the location of the selected pixels. Moreover, to improve the global approximation quality further, we also allow to change the function values of the noisy pixels. In contrast to traditional denoising methods that adapt the operator to the data, our approach adapts the data to the operator. Experimentally we show that replacing homogeneous diffusion inpainting by biharmonic inpainting does not improve the reconstruction quality. This again emphasizes the importance of data adaptivity over operator adaptivity. On the foundational side, we establish deterministic and probabilistic theories with convergence estimates. In the non-adaptive 1-D case, we derive equivalence results between DbI on shifted regular grids and classical homogeneous diffusion filtering via an explicit relation between the density and the diffusion time.
</details>
<details>
<summary>摘要</summary>
Diffusion 过程中的填充效果是许多图像分析任务的有力工具，如填充基于压缩和稠密光流计算。对于噪声污染的数据，有一个 interessante 的侧效： interpolated 数据具有更高的信任度，因为它们平均了许多噪声来源的信息。这个观察成为我们denoising by inpainting（DbI）框架的基础。DbI 平均了不同噪声子集的多个填充结果。我们的目标是获得基本的洞察和现有方法的连接。与填充基于图像压缩类似，我们选择了高度一致的扩散作为非常简单的填充算子，它在高度优化的数据上表现良好。我们还提出了多种选择选择的像素位置策略，以及改进全局approximation质量的方法。与传统的噪声除法方法不同，我们的方法将数据适应到算子而不是适应到数据。实验表明，将Homogeneous替换为Biharmonic不会提高重建质量。这再次强调了数据适应性的重要性，而不是算子适应性。在基础方面，我们建立了deterministic和probabilistic 理论，并提供了收敛估计。在非适应的1-D情况下，我们 derivation 了DbI 在偏移的正规网格上和经典扩散滤波器之间的等价关系，这种关系可以用来描述density 和扩散时间之间的直接关系。
</details></li>
</ul>
<hr>
<h2 id="Design-of-Novel-Loss-Functions-for-Deep-Learning-in-X-ray-CT"><a href="#Design-of-Novel-Loss-Functions-for-Deep-Learning-in-X-ray-CT" class="headerlink" title="Design of Novel Loss Functions for Deep Learning in X-ray CT"></a>Design of Novel Loss Functions for Deep Learning in X-ray CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14367">http://arxiv.org/abs/2309.14367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Obaidullah Rahman, Ken D. Sauer, Madhuri Nagare, Charles A. Bouman, Roman Melnyk, Jie Tang, Brian Nett</li>
<li>for: 提高透射计算机断层（CT）图像质量</li>
<li>methods: 使用深度学习（DL）方法，包括在数据频谱域和重建图像域中进行训练</li>
<li>results: 提出创新的损失函数方法，以更好地衡量图像质量和频谱内容的损失，以提高CT图像重建的精度<details>
<summary>Abstract</summary>
Deep learning (DL) shows promise of advantages over conventional signal processing techniques in a variety of imaging applications. The networks' being trained from examples of data rather than explicitly designed allows them to learn signal and noise characteristics to most effectively construct a mapping from corrupted data to higher quality representations. In inverse problems, one has options of applying DL in the domain of the originally captured data, in the transformed domain of the desired final representation, or both.   X-ray computed tomography (CT), one of the most valuable tools in medical diagnostics, is already being improved by DL methods. Whether for removal of common quantum noise resulting from the Poisson-distributed photon counts, or for reduction of the ill effects of metal implants on image quality, researchers have begun employing DL widely in CT. The selection of training data is driven quite directly by the corruption on which the focus lies. However, the way in which differences between the target signal and measured data is penalized in training generally follows conventional, pointwise loss functions.   This work introduces a creative technique for favoring reconstruction characteristics that are not well described by norms such as mean-squared or mean-absolute error. Particularly in a field such as X-ray CT, where radiologists' subjective preferences in image characteristics are key to acceptance, it may be desirable to penalize differences in DL more creatively. This penalty may be applied in the data domain, here the CT sinogram, or in the reconstructed image. We design loss functions for both shaping and selectively preserving frequency content of the signal.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在各种成像应用中显示出优势，比如传统的信号处理技术。DL网络从数据示例而不是直接设计，因此可以学习信号和噪声特征，以最有效地构建受损数据到高质量表示的映射。在逆问题中，可以在原始数据频谱中应用DL，在愿望的最终表示频谱中应用DL，或者两者都应用。X射针 Computed Tomography（CT）是医学诊断中最重要的工具，已经由DL方法进行改进。DL可以用于去除常见的量子噪声，或者去除金属implant的影响而导致的图像质量下降。选择训练数据的驱动因素受到受损的影响很直接。然而，在训练中对目标信号和测量数据之间的差别进行惩罚通常采用传统的点均方差或点绝对差惩罚函数。本工作介绍了一种创新的技术，即在DL中不以均方或绝对差惩罚函数来惩罚差别。特别在X射针CT领域， где radiologists的主观偏好在图像特征上对接受性至关重要。在这种情况下，可能需要通过更创新的惩罚方式来惩罚DL。我们设计了在数据频谱中和重建图像中应用的损失函数，以Shape和选择性保留信号的频谱特征。
</details></li>
</ul>
<hr>
<h2 id="Statistically-Adaptive-Filtering-for-Low-Signal-Correction-in-X-ray-Computed-Tomography"><a href="#Statistically-Adaptive-Filtering-for-Low-Signal-Correction-in-X-ray-Computed-Tomography" class="headerlink" title="Statistically Adaptive Filtering for Low Signal Correction in X-ray Computed Tomography"></a>Statistically Adaptive Filtering for Low Signal Correction in X-ray Computed Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13406">http://arxiv.org/abs/2309.13406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Obaidullah Rahman, Ken D. Sauer, Charles A. Bouman, Roman Melnyk, Brian Nett</li>
<li>for: 实现低X射线剂量CT图像成像，并且维护适当的医学效果。</li>
<li>methods: 使用灵活范围滤波器来缓和低信号领域的残留artefacts。</li>
<li>results: 提高低频率偏好、条状artefacts、本地平均值和标准差、模拟转换函数和杂音功率спектrum等指标。<details>
<summary>Abstract</summary>
Low x-ray dose is desirable in x-ray computed tomographic (CT) imaging due to health concerns. But low dose comes with a cost of low signal artifacts such as streaks and low frequency bias in the reconstruction. As a result, low signal correction is needed to help reduce artifacts while retaining relevant anatomical structures.   Low signal can be encountered in cases where sufficient number of photons do not reach the detector to have confidence in the recorded data. % NOTE: SNR is ratio of powers, not std. dev. X-ray photons, assumed to have Poisson distribution, have signal to noise ratio proportional to the dose, with poorer SNR in low signal areas. Electronic noise added by the data acquisition system further reduces the signal quality.   In this paper we will demonstrate a technique to combat low signal artifacts through adaptive filtration. It entails statistics-based filtering on the uncorrected data, correcting the lower signal areas more aggressively than the high signal ones. We look at local averages to decide how aggressive the filtering should be, and local standard deviation to decide how much detail preservation to apply. Implementation consists of a pre-correction step i.e. local linear minimum mean-squared error correction, followed by a variance stabilizing transform, and finally adaptive bilateral filtering. The coefficients of the bilateral filter are computed using local statistics. Results show that improvements were made in terms of low frequency bias, streaks, local average and standard deviation, modulation transfer function and noise power spectrum.
</details>
<details>
<summary>摘要</summary>
低剂量X射线是在X射线计算机断层成像（CT）中所需的，因为它可以降低健康风险。然而，低剂量也会导致低信号artefacts，如斜线和低频偏好。为了减少这些artefacts，而不失去有关生物结构的信息，需要进行低信号修正。低信号可以在具有不足的X射线 фотоン数据 recording 时出现，这会导致信号质量下降。在这种情况下，X射线 photons 的信号噪声比（SNR）会随剂量的增加。electronic noise 由数据获取系统添加到数据中，进一步减少信号质量。本文将介绍一种用于解决低信号artefacts的技术 - 适应 filters。这种技术基于统计分析，通过对未经修正的数据进行统计分析，更加严格地修正低信号区域。我们根据本地平均值和本地标准差来决定修正的程度，以保留生物结构的细节。实现方式包括先进行本地线性最小二乘均值修正，然后应用变量稳定化变换，最后使用适应二值滤波。适应滤波的系数是根据本地统计来计算的。结果表明，该技术可以提高低频偏好、斜线、本地平均值和标准差、模ulation transfer function 和噪声电力谱的性能。
</details></li>
</ul>
<hr>
<h2 id="MBIR-Training-for-a-2-5D-DL-network-in-X-ray-CT"><a href="#MBIR-Training-for-a-2-5D-DL-network-in-X-ray-CT" class="headerlink" title="MBIR Training for a 2.5D DL network in X-ray CT"></a>MBIR Training for a 2.5D DL network in X-ray CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13399">http://arxiv.org/abs/2309.13399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Obaidullah Rahman, Madhuri Nagare, Ken D. Sauer, Charles A. Bouman, Roman Melnyk, Brian Nett, Jie Tang</li>
<li>for: 这个论文目的是使用深度学习模型来快速实现基于模型的迭代重建图像技术（MBIR）的高品质图像。</li>
<li>methods: 这个论文使用了一种基于Unet的modified 2.5D深度学习网络来模仿MBIR图像。</li>
<li>results: 研究发现，使用这种深度学习模型可以快速获得高品质MBIR图像，并且计算成本远低于传统的MBIR方法。图像的文本特征和噪声功率谱都与MBIR图像相似，表明深度学习模型成功模拟了MBIR操作。<details>
<summary>Abstract</summary>
In computed tomographic imaging, model based iterative reconstruction methods have generally shown better image quality than the more traditional, faster filtered backprojection technique. The cost we have to pay is that MBIR is computationally expensive. In this work we train a 2.5D deep learning (DL) network to mimic MBIR quality image. The network is realized by a modified Unet, and trained using clinical FBP and MBIR image pairs. We achieve the quality of MBIR images faster and with a much smaller computation cost. Visually and in terms of noise power spectrum (NPS), DL-MBIR images have texture similar to that of MBIR, with reduced noise power. Image profile plots, NPS plots, standard deviation, etc. suggest that the DL-MBIR images result from a successful emulation of an MBIR operator.
</details>
<details>
<summary>摘要</summary>
在计算tomografic imaging中，基于模型的迭代重建方法通常会提供更好的图像质量，相比较传统的快速滤波后 проекcion技术。然而，MBIR是计算成本高的。在这项工作中，我们使用一个modified U-Net架构来模拟MBIR图像质量。我们使用临床FBP和MBIR图像对的 pairs来训练网络，并在计算成本下降的情况下实现MBIR图像质量。视觉和噪声电磁谱（NPS）等指标表明，DL-MBIR图像具有与MBIR图像相似的 текстура，噪声电磁谱下降。图像profile plot、NPS plot等指标表明，DL-MBIR图像是一个成功地模拟MBIROperator的结果。
</details></li>
</ul>
<hr>
<h2 id="Direct-Iterative-Reconstruction-of-Multiple-Basis-Material-Images-in-Photon-counting-Spectral-CT"><a href="#Direct-Iterative-Reconstruction-of-Multiple-Basis-Material-Images-in-Photon-counting-Spectral-CT" class="headerlink" title="Direct Iterative Reconstruction of Multiple Basis Material Images in Photon-counting Spectral CT"></a>Direct Iterative Reconstruction of Multiple Basis Material Images in Photon-counting Spectral CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13397">http://arxiv.org/abs/2309.13397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Obaidullah Rahman, Ken Sauer, Connor Evans, Ryan Roeder</li>
<li>for: 这项研究旨在利用基于模型的迭代重建(MBIR)方法直接从спектральCT数据中重建材料。</li>
<li>methods: 该方法使用了一种基于模型的迭代重建方法，其中材料含量测量为体积分数，总为最大值 unity。使用了iodine和gadolinium作为常见的contrast agent，并使用了一个包含这两种材料的phantom。</li>
<li>results: 在low-concentration scan中，使用了这种方法可以在ROIs中获得volume fractions的 Close to ground truth值。这项研究旨在为将来包含空间含义和&#x2F;或材料含量regularization的phantoms、动物成像和临床应用铺垫。<details>
<summary>Abstract</summary>
In this work, we perform direct material reconstruction from spectral CT data using a model based iterative reconstruction (MBIR) approach. Material concentrations are measured in volume fractions, whose total is constrained by a maximum of unity. A phantom containing a combination of 4 basis materials (water, iodine, gadolinium, calcium) was scanned using a photon-counting detector. Iodine and gadolinium were chosen because of their common use as contrast agents in CT imaging. Scan data was binned into 5 energy (keV) levels. Each energy bin in a calibration scan was reconstructed, allowing the linear attenuation coefficient of each material for every energy to be estimated by a least-squares fit to ground truth in the image domain. The resulting $5\times 4$ matrix, for $5$ energies and $4$ materials, is incorporated into the forward model in direct reconstruction of the $4$ basis material images with spatial and/or inter-material regularization. In reconstruction from a subsequent low-concentration scan, volume fractions within regions of interest (ROIs) are found to be close to the ground truth. This work is meant to lay the foundation for further work with phantoms including spatially coincident mixtures of contrast materials and/or contrast agents in widely varying concentrations, molecular imaging from animal scans, and eventually clinical applications.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们使用基于模型的迭代重建（MBIR）方法直接重建物质图像从 spectral CT 数据。物质浓度表示为体积分数，总是受限于最大unity。一个包含四种基本材料（水、iodine、gadolinium、 calcium）的phantom在一个photon-counting 探测器上进行了扫描。iodine 和 gadolinium 选择是因为它们在 CT 图像中广泛使用为contrast agent。扫描数据被分割成5个能量（keV）层。每个能量层在一个calibration scan中的每个像素的直线吸收系数可以通过对真实图像中的图像域最小二乘来估算。这个 $5\times 4$ 矩阵，其中有5个能量和4种材料，被 incorporated 到了直接重建的 forward 模型中。在重建从后续的低浓度扫描中，ROIs 中的体积分数几乎与真实值一致。这项工作的目的是为了铺垫将来的灵活材料混合物和高级分子成像、动物扫描和临床应用。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Communications-using-Foundation-Models-Design-Approaches-and-Open-Issues"><a href="#Semantic-Communications-using-Foundation-Models-Design-Approaches-and-Open-Issues" class="headerlink" title="Semantic Communications using Foundation Models: Design Approaches and Open Issues"></a>Semantic Communications using Foundation Models: Design Approaches and Open Issues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13315">http://arxiv.org/abs/2309.13315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiwen Jiang, Chao-Kai Wen, Xinping Yi, Xiao Li, Shi Jin, Jun Zhang</li>
<li>for: This paper aims to investigate the impact of foundation models (FMs) on different system levels, including computation and memory complexity, and to explore the use of compact models to balance performance and complexity.</li>
<li>methods: The paper uses universal knowledge to profoundly transform system design and employs three separate approaches that employ FMs to balance performance and complexity.</li>
<li>results: The study highlights unresolved issues in the field that need addressing, and provides insights into the effectiveness, semantic, and physical levels of system design.<details>
<summary>Abstract</summary>
Foundation models (FMs), including large language models, have become increasingly popular due to their wide-ranging applicability and ability to understand human-like semantics. While previous research has explored the use of FMs in semantic communications to improve semantic extraction and reconstruction, the impact of these models on different system levels, considering computation and memory complexity, requires further analysis. This study focuses on integrating FMs at the effectiveness, semantic, and physical levels, using universal knowledge to profoundly transform system design. Additionally, it examines the use of compact models to balance performance and complexity, comparing three separate approaches that employ FMs. Ultimately, the study highlights unresolved issues in the field that need addressing.
</details>
<details>
<summary>摘要</summary>
基于语言模型（FM）的应用，包括大型语言模型，在各种领域得到广泛应用，这主要归功于它们能够理解人类语言 semantics。 although previous research has explored the use of FMs in semantic communications to improve semantic extraction and reconstruction, the impact of these models on different system levels, considering computation and memory complexity, requires further analysis.本研究强调在效iveness、semantic和physical各级别中集成FMs，使用通用知识进行深度变换系统设计。此外，它还研究了使用压缩模型来平衡性能和复杂性，对三种使用FMs的方法进行比较。最终，研究披露了这个领域中还有待解决的问题。Here's the word-for-word translation:基于语言模型（FM）的应用，包括大型语言模型，在各种领域得到广泛应用，这主要归功于它们能够理解人类语言 semantics。 although previous research has explored the use of FMs in semantic communications to improve semantic extraction and reconstruction, the impact of these models on different system levels, considering computation and memory complexity, requires further analysis.本研究强调在效iveness、semantic和physical各级别中集成FMs，使用通用知识进行深度变换系统设计。此外，它还研究了使用压缩模型来平衡性能和复杂性，对三种使用FMs的方法进行比较。最终，研究披露了这个领域中还有待解决的问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/eess.IV_2023_09_23/" data-id="clp9qz8ee01awok88bs6dcsi5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_23" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/23/eess.SP_2023_09_23/" class="article-date">
  <time datetime="2023-09-23T08:00:00.000Z" itemprop="datePublished">2023-09-23</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/23/eess.SP_2023_09_23/">eess.SP - 2023-09-23</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Sens-BERT-Enabling-Transferability-and-Re-calibration-of-Calibration-Models-for-Low-cost-Sensors-under-Reference-Measurements-Scarcity"><a href="#Sens-BERT-Enabling-Transferability-and-Re-calibration-of-Calibration-Models-for-Low-cost-Sensors-under-Reference-Measurements-Scarcity" class="headerlink" title="Sens-BERT: Enabling Transferability and Re-calibration of Calibration Models for Low-cost Sensors under Reference Measurements Scarcity"></a>Sens-BERT: Enabling Transferability and Re-calibration of Calibration Models for Low-cost Sensors under Reference Measurements Scarcity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13390">http://arxiv.org/abs/2309.13390</a></li>
<li>repo_url: None</li>
<li>paper_authors: M V Narayana, Kranthi Kumar Rachvarapu, Devendra Jalihal, Shiva Nagendra S M<br>for:这个研究旨在提高低成本测器（LCS）的精确性，以便在空气质量监控中大规模地应用。methods:这个研究使用了一种基于BERT的学习方法，称为Sens-BERT，来对LCS进行准确化。这个方法分成两个阶段：自主学习预训和精确训练。在预训阶段，Sens-BERT被训练以使其学习LCS测器的资料分布特征，并生成对应的嵌入。在精确训练阶段，我们使用Sens-BERT嵌入来学习一个准确化模型。results:这个研究的结果显示，Sens-BERT可以对LCS进行高精确性的准确化，而且不需要大量的对照站资料或频繁的重新准确化。此外，Sens-BERT可以跨测器和位置进行转移学习，因此可以在不同的测器和位置上进行准确化。<details>
<summary>Abstract</summary>
Low-cost sensors measurements are noisy, which limits large-scale adaptability in airquality monitoirng. Calibration is generally used to get good estimates of air quality measurements out from LCS. In order to do this, LCS sensors are typically co-located with reference stations for some duration. A calibration model is then developed to transfer the LCS sensor measurements to the reference station measurements. Existing works implement the calibration of LCS as an optimization problem in which a model is trained with the data obtained from real-time deployments; later, the trained model is employed to estimate the air quality measurements of that location. However, this approach is sensor-specific and location-specific and needs frequent re-calibration. The re-calibration also needs massive data like initial calibration, which is a cumbersome process in practical scenarios.   To overcome these limitations, in this work, we propose Sens-BERT, a BERT-inspired learning approach to calibrate LCS, and it achieves the calibration in two phases: self-supervised pre-training and supervised fine-tuning. In the pre-training phase, we train Sens-BERT with only LCS data (without reference station observations) to learn the data distributional features and produce corresponding embeddings. We then use the Sens-BERT embeddings to learn a calibration model in the fine-tuning phase. Our proposed approach has many advantages over the previous works. Since the Sens-BERT learns the behaviour of the LCS, it can be transferable to any sensor of the same sensing principle without explicitly training on that sensor. It requires only LCS measurements in pre-training to learn the characters of LCS, thus enabling calibration even with a tiny amount of paired data in fine-tuning. We have exhaustively tested our approach with the Community Air Sensor Network (CAIRSENSE) data set, an open repository for LCS.
</details>
<details>
<summary>摘要</summary>
低成本感测数据具有噪声，限制了大规模适应性在空气质量监测中。通常情况下，使用均拌法来获得良好的空气质量测量结果。为了实现这一点，低成本感测器通常会与参照站同时进行数据采集。然后，通过开发一个均拌模型，将低成本感测器的测量结果转换为参照站的测量结果。现有的方法通常是通过实时部署来训练一个模型，然后使用这个训练好的模型来估计当地的空气质量测量结果。然而，这种方法具有感测器和地点特定的限制，需要频繁重新均拌，并且重新均拌需要大量的数据，如初始均拌，这在实际应用中是一个繁琐的过程。为了解决这些限制，在这项工作中，我们提出了一种基于BERT的学习方法来均拌低成本感测器。我们的方法分为两个阶段：自主启动阶段和精度调整阶段。在自主启动阶段，我们使用只有低成本感测器数据（没有参照站观测）来帮助Sens-BERT学习数据分布特征，并生成相应的嵌入。然后，在精度调整阶段，我们使用Sens-BERT嵌入来学习一个均拌模型。我们的方法具有许多优势。因为Sens-BERT学习了低成本感测器的行为，因此它可以在任何相同感测原理的感测器上进行传输学习，不需要单独对每个感测器进行均拌。此外，我们只需要在启动阶段使用低成本感测器数据来学习低成本感测器的特征，因此在精度调整阶段只需要小量的配对数据，这在实际应用中是一个方便的。我们在社区空气感测网络（CAIRSENSE）数据集上进行了广泛的测试，并证明了我们的方法的可行性。
</details></li>
</ul>
<hr>
<h2 id="Multi-Static-ISAC-in-Cell-Free-Massive-MIMO-Precoder-Design-and-Privacy-Assessment"><a href="#Multi-Static-ISAC-in-Cell-Free-Massive-MIMO-Precoder-Design-and-Privacy-Assessment" class="headerlink" title="Multi-Static ISAC in Cell-Free Massive MIMO: Precoder Design and Privacy Assessment"></a>Multi-Static ISAC in Cell-Free Massive MIMO: Precoder Design and Privacy Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13368">http://arxiv.org/abs/2309.13368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/isabella-gomes/globecom2023">https://github.com/isabella-gomes/globecom2023</a></li>
<li>paper_authors: Isabella W. G. da Silva, Diana P. M. Osorio, Markku Juntti</li>
<li>for: 本研究旨在提高 Cell-free 大量多输入多输出基础设施上的感知通信网络的多样性和功率消耗。</li>
<li>methods: 本文使用了jointly optimizes 的秘密预编码器设计来满足感知和通信需求，并考虑了内部敌对者的攻击。</li>
<li>results: 结果表明，在多Static 环境中，可以更精准地估算目标位置，比单Static 实现更好。<details>
<summary>Abstract</summary>
A multi-static sensing-centric integrated sensing and communication (ISAC) network can take advantage of the cell-free massive multiple-input multiple-output infrastructure to achieve remarkable diversity gains and reduced power consumption. While the conciliation of sensing and communication requirements is still a challenge, the privacy of the sensing information is a growing concern that should be seriously taken on the design of these systems to prevent other attacks. This paper tackles this issue by assessing the probability of an internal adversary to infer the target location information from the received signal by considering the design of transmit precoders that jointly optimizes the sensing and communication requirements in a multi-static-based cell-free ISAC network. Our results show that the multi-static setting facilitates a more precise estimation of the location of the target than the mono-static implementation.
</details>
<details>
<summary>摘要</summary>
一种多Static感知中心Integrated sensing and communication（ISAC）网络可以利用无细结构巨量多输入多输出基础设施，实现Remarkable的多样性增强和降低功率消耗。虽然感知和通信需求的妥协仍然是一个挑战，但感知信息的隐私问题在这些系统的设计中应该严重考虑，以防止其他攻击。本文通过评估接收信号中target位置信息的泄露概率，来评估 transmit precoder的设计，并jointly optimizes the sensing and communication requirements in a multi-static-based cell-free ISAC network。我们的结果表明，在多Static设计下，可以更准确地估计目标的位置，比单Static实现更高精度。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Robust-Header-Compression-under-Model-Uncertainty"><a href="#Reinforcement-Learning-for-Robust-Header-Compression-under-Model-Uncertainty" class="headerlink" title="Reinforcement Learning for Robust Header Compression under Model Uncertainty"></a>Reinforcement Learning for Robust Header Compression under Model Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13291">http://arxiv.org/abs/2309.13291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shusen Jing, Songyang Zhang, Zhi Ding</li>
<li>For: This paper investigates the integration of bi-directional header compression (BD-ROHC) with reinforcement learning (RL) to improve data efficiency in modern wireless communication systems.* Methods: The paper formulates a partially observable Markov decision process (POMDP) to model the compression process, and uses a deep Q-network (DQN) to learn the optimal compression policy.* Results: Compared to ideal dynamic programming (DP), the proposed method is more scalable and does not require prior knowledge of the transition dynamics or accurate observation dependency of the model.<details>
<summary>Abstract</summary>
Robust header compression (ROHC), critically positioned between the network and the MAC layers, plays an important role in modern wireless communication systems for improving data efficiency. This work investigates bi-directional ROHC (BD-ROHC) integrated with a novel architecture of reinforcement learning (RL). We formulate a partially observable \emph{Markov} decision process (POMDP), in which agent is the compressor, and the environment consists of the decompressor, channel and header source. Our work adopts the well-known deep Q-network (DQN), which takes the history of actions and observations as inputs, and outputs the Q-values of corresponding actions. Compared with the ideal dynamic programming (DP) proposed in the existing works, our method is scalable to the state, action and observation spaces. In contrast, DP often suffers from formidable computational complexity when the number of states becomes large due to long decompressor feedback delay and complex channel models. In addition, our method does not require prior knowledge of the transition dynamics and accurate observation dependency of the model, which are often not available in many practical applications.
</details>
<details>
<summary>摘要</summary>
Robust header compression（ROHC），位于网络和 MAC 层之间，在现代无线通信系统中扮演着重要的角色，以提高数据效率。这项工作 investigate 双向 ROHC（BD-ROHC）与 reinforcement learning（RL）新的架构相结合。我们将 partially observable 马尔可夫决策过程（POMDP）形式ulated，其中 compressor 是 agent，环境包括 decompressor、通道和 header source。我们采用了著名的深度优化网络（DQN），它接受了历史动作和观察输入，并输出对应动作的 Q-值。相比于现有的理想动态计划（DP），我们的方法可扩展到状态、动作和观察空间。而 DP 则经常由长 decompressor 反馈延迟和复杂的通道模型而受到强大的计算复杂度限制。此外，我们的方法不需要transition dynamics 和 observation dependency 的准确知识，这些知识在许多实际应用中通常不可获得。
</details></li>
</ul>
<hr>
<h2 id="How-to-Differentiate-between-Near-Field-and-Far-Field-Revisiting-the-Rayleigh-Distance"><a href="#How-to-Differentiate-between-Near-Field-and-Far-Field-Revisiting-the-Rayleigh-Distance" class="headerlink" title="How to Differentiate between Near Field and Far Field: Revisiting the Rayleigh Distance"></a>How to Differentiate between Near Field and Far Field: Revisiting the Rayleigh Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13238">http://arxiv.org/abs/2309.13238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shu Sun, Renwang Li, Xingchen Liu, Liuxun Xue, Chong Han, Meixia Tao</li>
<li>for: This paper aims to provide a comprehensive overview of the existing near field (NF) and far field (FF) boundaries in wireless communication systems, and to introduce a novel NF-FF demarcation method based on effective degrees of freedom (EDoF) of the channel.</li>
<li>methods: The proposed method uses EDoF to characterize the channel and demarcate the NF and FF regions. The authors analyze the main features of the EDoF-based NF-FF boundary and provide insights into wireless system design.</li>
<li>results: The authors demonstrate that the EDoF-based border is able to characterize key channel performance more accurately than the classic Rayleigh distance, and provide insights into wireless system design.Here is the result in Simplified Chinese text:</li>
<li>for: 这篇论文旨在提供无线通信系统中现有的近场（NF）和远场（FF）边界的总览，并提出一种基于有效度分度（EDoF）的信道边界分类方法。</li>
<li>methods: 该方法使用EDoF来特征化信道并分类NF和FF区域。作者分析了EDoF基于的NF-FF边界的主要特征，并提供无线系统设计的启示。</li>
<li>results: 作者表明，EDoF基于的边界能够更准确地特征化频率响应的关键性能特征，并提供无线系统设计的启示。<details>
<summary>Abstract</summary>
Future wireless communication systems are likely to adopt extremely large aperture arrays and millimeter-wave/sub-THz frequency bands to achieve higher throughput, lower latency, and higher energy efficiency. Conventional wireless systems predominantly operate in the far field (FF) of the radiation source of signals. As the array size increases and the carrier wavelength shrinks, however, the near field (NF) becomes non-negligible. Since the NF and FF differ in many aspects, it is essential to distinguish their corresponding regions. In this article, we first provide a comprehensive overview of the existing NF-FF boundaries, then introduce a novel NF-FF demarcation method based on effective degrees of freedom (EDoF) of the channel. Since EDoF is intimately related to spectral efficiency, the EDoF-based border is able to characterize key channel performance more accurately, as compared with the classic Rayleigh distance. Furthermore, we analyze the main features of the EDoF-based NF-FF boundary and provide insights into wireless system design.
</details>
<details>
<summary>摘要</summary>
未来无线通信系统可能会采用非常大的天线数组和毫米波/亿赫兹频段来实现更高的传输速率、更低的延迟时间和更高的能效率。传统无线系统主要在辐射源信号的远场（FF）中运行。然而，随着天线数组的增大和辐射波长的减小，近场（NF）变得不可或缺。由于NF和FF在多方面存在差异，因此需要明确NF-FF的分界线。在这篇文章中，我们首先提供了NF-FF分界线的全面回顾，然后介绍了一种基于效果度量（EDoF）的通道分界方法。由于EDoF与spectral efficiency之间存在紧密的关系，EDoF-based分界线能够更加准确地描述通道性能的关键特征，相比于 классический辐射距离。此外，我们还分析了NF-FF分界线的主要特征，并对无线系统设计提供了深入的理解。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/23/eess.SP_2023_09_23/" data-id="clp9qz8gd01ewok882lxnd1r8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/cs.SD_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T15:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/cs.SD_2023_09_22/">cs.SD - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Massive-End-to-end-Models-for-Short-Search-Queries"><a href="#Massive-End-to-end-Models-for-Short-Search-Queries" class="headerlink" title="Massive End-to-end Models for Short Search Queries"></a>Massive End-to-end Models for Short Search Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12963">http://arxiv.org/abs/2309.12963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiran Wang, Rohit Prabhavalkar, Dongseong Hwang, Qiujia Li, Khe Chai Sim, Bo Li, James Qin, Xingyu Cai, Adam Stooke, Zhong Meng, CJ Zheng, Yanzhang He, Tara Sainath, Pedro Moreno Mengibar</li>
<li>for:  investigate two popular end-to-end automatic speech recognition (ASR) models, namely Connectionist Temporal Classification (CTC) and RNN-Transducer (RNN-T), for offline recognition of voice search queries.</li>
<li>methods:  use the neural architecture of Google’s universal speech model (USM), with additional funnel pooling layers to significantly reduce the frame rate and speed up training and inference.</li>
<li>results:  despite the speculation that larger CTC models can perform as well as RNN-T models, the authors observe that a 900M RNN-T model outperforms a 1.8B CTC model and is more tolerant to severe time reduction, although the WER gap can be largely removed by LM shallow fusion.<details>
<summary>Abstract</summary>
In this work, we investigate two popular end-to-end automatic speech recognition (ASR) models, namely Connectionist Temporal Classification (CTC) and RNN-Transducer (RNN-T), for offline recognition of voice search queries, with up to 2B model parameters. The encoders of our models use the neural architecture of Google's universal speech model (USM), with additional funnel pooling layers to significantly reduce the frame rate and speed up training and inference. We perform extensive studies on vocabulary size, time reduction strategy, and its generalization performance on long-form test sets. Despite the speculation that, as the model size increases, CTC can be as good as RNN-T which builds label dependency into the prediction, we observe that a 900M RNN-T clearly outperforms a 1.8B CTC and is more tolerant to severe time reduction, although the WER gap can be largely removed by LM shallow fusion.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们研究了两种流行的端到端自动语音识别（ASR）模型，即Connectionist Temporal Classification（CTC）和RNN-Transducer（RNN-T），用于离线识别voice搜索 queries，模型参数达2B。我们的模型encoder使用Google的通用语音模型（USM）的神经网络结构，并添加了挥发池化层以大幅降低帧率和加速训练和推理。我们进行了广泛的词汇大小、时间减少策略和长形测试集的总体性能研究。虽然有人推测，随着模型参数的增加，CTC可能与RNN-T相当，但我们发现一个900M RNN-T明显超过了1.8B CTC，并且更具耐用性。虽然WER差距可以通过LM浅合并大大减少，但CTC的性能仍然落后RNN-T。
</details></li>
</ul>
<hr>
<h2 id="VIC-KD-Variance-Invariance-Covariance-Knowledge-Distillation-to-Make-Keyword-Spotting-More-Robust-Against-Adversarial-Attacks"><a href="#VIC-KD-Variance-Invariance-Covariance-Knowledge-Distillation-to-Make-Keyword-Spotting-More-Robust-Against-Adversarial-Attacks" class="headerlink" title="VIC-KD: Variance-Invariance-Covariance Knowledge Distillation to Make Keyword Spotting More Robust Against Adversarial Attacks"></a>VIC-KD: Variance-Invariance-Covariance Knowledge Distillation to Make Keyword Spotting More Robust Against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12914">http://arxiv.org/abs/2309.12914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heitor R. Guimarães, Arthur Pimentel, Anderson Avila, Tiago H. Falk</li>
<li>for: 这个论文的目的是提出一种robust distillation recipe，用于压缩模型并提高对抗攻击性能。</li>
<li>methods: 该论文使用了自动学习的speech representation，并在教师和学生模型中强制实施几何约束，以提高模型的Robustness和鲁棒性。</li>
<li>results: 实验结果显示，提出的方法可以提高对current state-of-the-art robust distillation方法（ARD和RSLAD）的robust准确率，分别提高12%和8%。<details>
<summary>Abstract</summary>
Keyword spotting (KWS) refers to the task of identifying a set of predefined words in audio streams. With the advances seen recently with deep neural networks, it has become a popular technology to activate and control small devices, such as voice assistants. Relying on such models for edge devices, however, can be challenging due to hardware constraints. Moreover, as adversarial attacks have increased against voice-based technologies, developing solutions robust to such attacks has become crucial. In this work, we propose VIC-KD, a robust distillation recipe for model compression and adversarial robustness. Using self-supervised speech representations, we show that imposing geometric priors to the latent representations of both Teacher and Student models leads to more robust target models. Experiments on the Google Speech Commands datasets show that the proposed methodology improves upon current state-of-the-art robust distillation methods, such as ARD and RSLAD, by 12% and 8% in robust accuracy, respectively.
</details>
<details>
<summary>摘要</summary>
键词检索（KWS）是指在语音流中确定一组预定义的词语的任务。随着深度神经网络的发展，KWS已成为许多小设备，如语音助手的激活和控制技术。但是，基于这些模型的边缘设备可能会受到硬件限制。此外，对语音技术的敌意攻击也在增加，因此开发对抗这些攻击的解决方案已经成为一项重要任务。在这种情况下，我们提出了VIC-KD，一种鲁棒的混合整合法。我们使用自我supervised的语音表示，并在教师和学生模型的秘密表示中加入几何约束，以便更加鲁棒的目标模型。在Google Speech Commands数据集上进行了实验，结果显示，我们的方法性比现有的State-of-the-art robust distillation方法，如ARD和RSLAD，提高了12%和8%的鲁棒精度，分别。
</details></li>
</ul>
<hr>
<h2 id="DurIAN-E-Duration-Informed-Attention-Network-For-Expressive-Text-to-Speech-Synthesis"><a href="#DurIAN-E-Duration-Informed-Attention-Network-For-Expressive-Text-to-Speech-Synthesis" class="headerlink" title="DurIAN-E: Duration Informed Attention Network For Expressive Text-to-Speech Synthesis"></a>DurIAN-E: Duration Informed Attention Network For Expressive Text-to-Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12792">http://arxiv.org/abs/2309.12792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Gu, Yianrao Bian, Guangzhi Lei, Chao Weng, Dan Su</li>
<li>for: 本研究提出了一种改进的时间知识注意力神经网络（DurIAN-E），用于实现高质量和高准确度的文本读音合成。</li>
<li>methods: 该模型采用了自适应的核心层结构，并使用多层核心层-based Transformer块作为语言编码器。此外，文本编码器还采用了样式适应的实例normalization（SAIN）层以提高表达能力。</li>
<li>results: 实验结果表明，提出的表达力强的TTS模型在对比前一个状态的方法的测试中表现出色，在主观意见分数（MOS）和偏好测试中都达到了更高的水平。<details>
<summary>Abstract</summary>
This paper introduces an improved duration informed attention neural network (DurIAN-E) for expressive and high-fidelity text-to-speech (TTS) synthesis. Inherited from the original DurIAN model, an auto-regressive model structure in which the alignments between the input linguistic information and the output acoustic features are inferred from a duration model is adopted. Meanwhile the proposed DurIAN-E utilizes multiple stacked SwishRNN-based Transformer blocks as linguistic encoders. Style-Adaptive Instance Normalization (SAIN) layers are exploited into frame-level encoders to improve the modeling ability of expressiveness. A denoiser incorporating both denoising diffusion probabilistic model (DDPM) for mel-spectrograms and SAIN modules is conducted to further improve the synthetic speech quality and expressiveness. Experimental results prove that the proposed expressive TTS model in this paper can achieve better performance than the state-of-the-art approaches in both subjective mean opinion score (MOS) and preference tests.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这篇论文介绍了一种改进的文本识别模型（DurIAN-E），它继承了原始DurIAN模型的自适应模型结构，并在语言编码器中使用多层折衔RNN-基于Transformer块。此外，提议中的DurIAN-E还利用了frame级别编码器中的样式适应实例归一化（SAIN）层，以提高模型的表达能力。此外，通过混合DDPM和SAIN模块，提高了生成的语音质量和表达性。实验结果表明，提议的表达力TTS模型在主观意见分数（MOS）和偏好测试中表现更好于当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-Incorporating-Whisper-for-Robust-Speech-Assessment"><a href="#A-Study-on-Incorporating-Whisper-for-Robust-Speech-Assessment" class="headerlink" title="A Study on Incorporating Whisper for Robust Speech Assessment"></a>A Study on Incorporating Whisper for Robust Speech Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12766">http://arxiv.org/abs/2309.12766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryandhimas E. Zezario, Yu-Wen Chen, Szu-Wei Fu, Yu Tsao, Hsin-Min Wang, Chiou-Shann Fuh</li>
<li>for: 这个研究旨在提出一个基于多目标批判学习的声音评估模型，即MOSA-Net+，通过利用大规模预训练的弱监督模型Whisper的声学特征来创建嵌入特征。</li>
<li>methods: 这个研究的第一部分investigates the correlation between Whisper的嵌入特征和两种自动学习（SSL）模型的主观质量和语言可理解得分。第二部分评估了Whisper在实施更加稳定的声音评估模型方面的可用性。第三部分分析了将Whisper和SSL模型的表示结合在MOSA-Net+中的可能性。</li>
<li>results: 实验结果表明，Whisper的嵌入特征与主观质量和语言可理解得分更加强相关，从而提高MOSA-Net+的预测性能。此外，将Whisper和SSL模型的表示结合只会导致微妙的改善。相比MOSA-Net和其他基于SSL的声音评估模型，MOSA-Net+在评估主观质量和语言可理解得分上具有显著的改善。此外，MOSA-Net+在VoiceMOS挑战2023的Track 3上获得了总成绩的第一名。<details>
<summary>Abstract</summary>
This research introduces an enhanced version of the multi-objective speech assessment model, called MOSA-Net+, by leveraging the acoustic features from large pre-trained weakly supervised models, namely Whisper, to create embedding features. The first part of this study investigates the correlation between the embedding features of Whisper and two self-supervised learning (SSL) models with subjective quality and intelligibility scores. The second part evaluates the effectiveness of Whisper in deploying a more robust speech assessment model. Third, the possibility of combining representations from Whisper and SSL models while deploying MOSA-Net+ is analyzed. The experimental results reveal that Whisper's embedding features correlate more strongly with subjective quality and intelligibility than other SSL's embedding features, contributing to more accurate prediction performance achieved by MOSA-Net+. Moreover, combining the embedding features from Whisper and SSL models only leads to marginal improvement. As compared to MOSA-Net and other SSL-based speech assessment models, MOSA-Net+ yields notable improvements in estimating subjective quality and intelligibility scores across all evaluation metrics. We further tested MOSA-Net+ on Track 3 of the VoiceMOS Challenge 2023 and obtained the top-ranked performance.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这项研究引入了一个改进版的多目标语音评估模型，称为MOSA-Net+，通过利用大型预训练的弱监督模型Whisper的语音特征来生成嵌入特征。研究的第一部分 investigate了Whisper和两个自动学习（SSL）模型的嵌入特征与主观质量和听解能力分数之间的相关性。研究的第二部分评估了Whisper是否可以提供更加可靠的语音评估模型。第三部分分析了将Whisper和SSL模型的表示结合使用时MOSA-Net+的效果。实验结果表明，Whisper的嵌入特征与主观质量和听解能力分数相关性更高，对MOSA-Net+的预测性能产生了较大的贡献。此外，将Whisper和SSL模型的表示结合使用只导致了微妙的改进。相比MOSA-Net和其他基于SSL的语音评估模型，MOSA-Net+在所有评价指标上具有显著的改善。我们将MOSA-Net+测试在2023年语音评估挑战赛（VoiceMOS Challenge 2023）的Track 3上，并取得了排名第一的表现。
</details></li>
</ul>
<hr>
<h2 id="CrossSinger-A-Cross-Lingual-Multi-Singer-High-Fidelity-Singing-Voice-Synthesizer-Trained-on-Monolingual-Singers"><a href="#CrossSinger-A-Cross-Lingual-Multi-Singer-High-Fidelity-Singing-Voice-Synthesizer-Trained-on-Monolingual-Singers" class="headerlink" title="CrossSinger: A Cross-Lingual Multi-Singer High-Fidelity Singing Voice Synthesizer Trained on Monolingual Singers"></a>CrossSinger: A Cross-Lingual Multi-Singer High-Fidelity Singing Voice Synthesizer Trained on Monolingual Singers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12672">http://arxiv.org/abs/2309.12672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xintong Wang, Chang Zeng, Jun Chen, Chunhui Wang</li>
<li>for: 这个论文的目的是构建一个多人高准确的唱歌声音合成系统，并且能够在不同语言之间进行跨语言合成。</li>
<li>methods: 这个论文使用了Xiaoicesing2作为基础，并使用国际音声字母表来统一所有语言训练数据的表示。此外，文章还利用了condition层正规化来吸收语言信息，使模型在遇到未看过的语言时能够更好地发音。最后，文章还使用了梯度反转层（GRL）来消除歌手偏见，因为所有歌手都是单语言的，这意味着歌手的身份是隐式地与文本相关联的。</li>
<li>results: 实验结果表明，CrossSinger可以高准确地合成不同歌手的歌曲，并且能够在不同语言之间进行跨语言合成，包括code-switch情况。<details>
<summary>Abstract</summary>
It is challenging to build a multi-singer high-fidelity singing voice synthesis system with cross-lingual ability by only using monolingual singers in the training stage. In this paper, we propose CrossSinger, which is a cross-lingual singing voice synthesizer based on Xiaoicesing2. Specifically, we utilize International Phonetic Alphabet to unify the representation for all languages of the training data. Moreover, we leverage conditional layer normalization to incorporate the language information into the model for better pronunciation when singers meet unseen languages. Additionally, gradient reversal layer (GRL) is utilized to remove singer biases included in lyrics since all singers are monolingual, which indicates singer's identity is implicitly associated with the text. The experiment is conducted on a combination of three singing voice datasets containing Japanese Kiritan dataset, English NUS-48E dataset, and one internal Chinese dataset. The result shows CrossSinger can synthesize high-fidelity songs for various singers with cross-lingual ability, including code-switch cases.
</details>
<details>
<summary>摘要</summary>
“建立一个多人高精当唱歌声合成系统以采用单语言训练数据是挑战。本研究提出了 CrossSinger，它是一个基于 Xiaoicesing2 的跨语言唱歌声合成器。我们使用国际音标字母来统一所有语言训练数据的表示。此外，我们运用了条件层normalization来将语言信息 incorporated 到模型中，以更好地处理 singer 遇到未见的语言时的发音。此外，我们还使用了 Gradient Reversal Layer (GRL) 来移除 singer 的偏好，因为所有 singer 都是单语言，这意味着 singer 的识别是隐式地与文本相关。实验使用了三个唱歌声数据集，包括日本 Kiritan 数据集、英国 NUS-48E 数据集和一个内部的中文数据集。结果显示 CrossSinger 可以实现高精当度的唱歌声合成，包括 code-switch 情况。”
</details></li>
</ul>
<hr>
<h2 id="NTT-speaker-diarization-system-for-CHiME-7-multi-domain-multi-microphone-End-to-end-and-vector-clustering-diarization"><a href="#NTT-speaker-diarization-system-for-CHiME-7-multi-domain-multi-microphone-End-to-end-and-vector-clustering-diarization" class="headerlink" title="NTT speaker diarization system for CHiME-7: multi-domain, multi-microphone End-to-end and vector clustering diarization"></a>NTT speaker diarization system for CHiME-7: multi-domain, multi-microphone End-to-end and vector clustering diarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12656">http://arxiv.org/abs/2309.12656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naohiro Tawara, Marc Delcroix, Atsushi Ando, Atsunori Ogawa</li>
<li>for: 这篇论文描述了一种为多个频率域、多个麦克风的便衣对话进行的Speaker diarization系统。</li>
<li>methods: 该排序管道使用了weighted prediction error（WPE）为前端，然后使用end-to-end神经网络分类（EEND-VC）对每个通道进行分类。它将每个通道的排序结果结合在一起使用排序输出投票错误减少（DOVER-LAP）。</li>
<li>results: 该系统在NTT的CHiME-7挑战中的远程自动语音识别任务中被提交，并在开发集和评估集上分别提高了65%和62%的相对提升，相比于提供的VC-基础系统。<details>
<summary>Abstract</summary>
This paper details our speaker diarization system designed for multi-domain, multi-microphone casual conversations. The proposed diarization pipeline uses weighted prediction error (WPE)-based dereverberation as a front end, then applies end-to-end neural diarization with vector clustering (EEND-VC) to each channel separately. It integrates the diarization result obtained from each channel using diarization output voting error reduction plus overlap (DOVER-LAP). To harness the knowledge from the target domain and results integrated across all channels, we apply self-supervised adaptation for each session by retraining the EEND-VC with pseudo-labels derived from DOVER-LAP. The proposed system was incorporated into NTT's submission for the distant automatic speech recognition task in the CHiME-7 challenge. Our system achieved 65 % and 62 % relative improvements on development and eval sets compared to the organizer-provided VC-based baseline diarization system, securing third place in diarization performance.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这篇论文介绍了一个针对多个频道、多个麦克风的休闲对话中的 speaker diarization 系统。提posed系统使用了weighted prediction error（WPE）基于的前端，然后应用每个通道的端到端神经网络抽取（EEND-VC）。系统将每个通道的抽取结果集成使用抽取输出误差减少加上重叠（DOVER-LAP）。为了利用目标频道的知识和所有通道的结果的组合，系统使用了无监督适应（self-supervised adaptation），通过在DOVER-LAP中生成pseudo-labels来重新训练EEND-VC。提posed系统在CHiME-7 challenge中提交了，并在发展集和评估集上分别 achieved 65%和62%的相对提升，与组织者提供的基eline diarization系统相比，获得了第三名的表现。
</details></li>
</ul>
<hr>
<h2 id="SPGM-Prioritizing-Local-Features-for-enhanced-speech-separation-performance"><a href="#SPGM-Prioritizing-Local-Features-for-enhanced-speech-separation-performance" class="headerlink" title="SPGM: Prioritizing Local Features for enhanced speech separation performance"></a>SPGM: Prioritizing Local Features for enhanced speech separation performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12608">http://arxiv.org/abs/2309.12608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia Qi Yip, Shengkui Zhao, Yukun Ma, Chongjia Ni, Chong Zhang, Hao Wang, Trung Hieu Nguyen, Kun Zhou, Dianwen Ng, Eng Siong Chng, Bin Ma</li>
<li>for: 提高Speech separation模型（如Sepformer）的性能，减少参数数量。</li>
<li>methods: 使用Single-Path Global Modulation（SPGM）块取代inter-blocks，SPGM块具有无参数全球 Pooling模块和Modulation模块，共计2%的模型参数。</li>
<li>results: SPGM在WSJ0-2Mix和Libri2Mix上达到22.1 dB SI-SDRi和20.4 dB SI-SDRi，超过Sepformer的性能，并与最新的SOTA模型几乎匹配，但具有8倍少的参数数量。<details>
<summary>Abstract</summary>
Dual-path is a popular architecture for speech separation models (e.g. Sepformer) which splits long sequences into overlapping chunks for its intra- and inter-blocks that separately model intra-chunk local features and inter-chunk global relationships. However, it has been found that inter-blocks, which comprise half a dual-path model's parameters, contribute minimally to performance. Thus, we propose the Single-Path Global Modulation (SPGM) block to replace inter-blocks. SPGM is named after its structure consisting of a parameter-free global pooling module followed by a modulation module comprising only 2% of the model's total parameters. The SPGM block allows all transformer layers in the model to be dedicated to local feature modelling, making the overall model single-path. SPGM achieves 22.1 dB SI-SDRi on WSJ0-2Mix and 20.4 dB SI-SDRi on Libri2Mix, exceeding the performance of Sepformer by 0.5 dB and 0.3 dB respectively and matches the performance of recent SOTA models with up to 8 times fewer parameters.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>双路是一种流行的语音分离模型（例如 Sepformer）的架构，将长序列分割成 overlap 的块，以便在块内和块间分别模型 intra-chunk 的本地特征和 inter-chunk 的全局关系。然而，在这种情况下，inter-blocks 占用了模型的一半参数，但是它们却对性能的贡献很小。因此，我们提出了单路全球修饰（SPGM）块来取代 inter-blocks。SPGM 得名于它的结构，包括一个无参数的全球汇集模块和一个修饰模块，该模块仅占用了模型总参数的 2%。SPGM 块使得所有转换层在模型中都专注于本地特征修饰，从而使整个模型变成单路。SPGM 在 WSJ0-2Mix 和 Libri2Mix 上 достиieves 22.1 dB SI-SDRi 和 20.4 dB SI-SDRi，超过 Sepformer 的性能 by 0.5 dB 和 0.3 dB，并与最新的 SOTA 模型几乎相当。
</details></li>
</ul>
<hr>
<h2 id="ICASSP-2023-Acoustic-Echo-Cancellation-Challenge"><a href="#ICASSP-2023-Acoustic-Echo-Cancellation-Challenge" class="headerlink" title="ICASSP 2023 Acoustic Echo Cancellation Challenge"></a>ICASSP 2023 Acoustic Echo Cancellation Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12553">http://arxiv.org/abs/2309.12553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/AEC-Challenge">https://github.com/microsoft/AEC-Challenge</a></li>
<li>paper_authors: Ross Cutler, Ando Saabas, Tanel Parnamaa, Marju Purin, Evgenii Indenbom, Nicolae-Catalin Ristea, Jegor Gužvin, Hannes Gamper, Sebastian Braun, Robert Aichner</li>
<li>For: 这个挑战的目的是促进静音干扰（AEC）研究，提高语音干扰和音频通信中的声音质量。* Methods: 挑战使用了两个追踪器，包括一个基于人工智能的追踪器和一个基于模型的追踪器，以及一个全带宽AECMOS。* Results: 挑战开源了两个大规模的训练数据集，包括来自更多于10,000个真实的音频设备和人类说话者的实际环境记录，以及一个 sintetic 数据集。winning 的result是基于所有场景的平均意见度（MOS）和单词准确率（WAcc）。<details>
<summary>Abstract</summary>
The ICASSP 2023 Acoustic Echo Cancellation Challenge is intended to stimulate research in acoustic echo cancellation (AEC), which is an important area of speech enhancement and is still a top issue in audio communication. This is the fourth AEC challenge and it is enhanced by adding a second track for personalized acoustic echo cancellation, reducing the algorithmic + buffering latency to 20ms, as well as including a full-band version of AECMOS. We open source two large datasets to train AEC models under both single talk and double talk scenarios. These datasets consist of recordings from more than 10,000 real audio devices and human speakers in real environments, as well as a synthetic dataset. We open source an online subjective test framework and provide an objective metric for researchers to quickly test their results. The winners of this challenge were selected based on the average mean opinion score (MOS) achieved across all scenarios and the word accuracy (WAcc) rate.
</details>
<details>
<summary>摘要</summary>
ICASSP 2023 听音障碍挑战是要促进听音障碍（AEC）领域的研究，这是一个重要的声音提升领域，仍然是音频通信中的主要问题。这是第四个AEC挑战，它的改进包括添加个性化听音障碍追踪，降低算法+缓冲延迟至20毫秒，以及包括全带AECMOS。我们对AEC模型进行训练提供了两个大型数据集，包括单个说话和双个说话场景。这些数据集包括来自 более чем10,000个真实的音频设备和人类说话者在真实环境中的录音，以及一个 sintetic 数据集。我们提供了在线主观测试框架，并提供了一个对研究人员快速测试结果的 объек metric。挑战赛中的赢家是根据所有场景的平均主观评分（MOS）和单词准确率（WAcc）而选择的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/cs.SD_2023_09_22/" data-id="clp9qz8a200zook88e66jay7f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/cs.CV_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T13:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/cs.CV_2023_09_22/">cs.CV - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ClusterFormer-Clustering-As-A-Universal-Visual-Learner"><a href="#ClusterFormer-Clustering-As-A-Universal-Visual-Learner" class="headerlink" title="ClusterFormer: Clustering As A Universal Visual Learner"></a>ClusterFormer: Clustering As A Universal Visual Learner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13196">http://arxiv.org/abs/2309.13196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clusterformer/clusterformer">https://github.com/clusterformer/clusterformer</a></li>
<li>paper_authors: James C. Liang, Yiming Cui, Qifan Wang, Tong Geng, Wenguan Wang, Dongfang Liu</li>
<li>for: 这个研究旨在提出一个基于CLUSTERing的概念的普遍性视觉模型，即CLUSTERFORMER，并将其应用于多种视觉任务中，包括图像分类、物体检测和图像分割等。</li>
<li>methods: 这个模型使用了两个新的设计：1. 回归十字运算实现了Transformer中的十字运算机制，并允许逐层更新团中心以便强化表示学习; 2. 图像特征重新分配使用更新的团中心，通过相似度基准来重新分配图像特征，实现了透明的管道。</li>
<li>results: 实验结果显示CLUSTERFORMER可以超过多种知名的特化架构，包括图像分类、物体检测和图像分割等任务，并在不同的团粒度（即图像、方巢和像素粒度）下实现高效性。<details>
<summary>Abstract</summary>
This paper presents CLUSTERFORMER, a universal vision model that is based on the CLUSTERing paradigm with TransFORMER. It comprises two novel designs: 1. recurrent cross-attention clustering, which reformulates the cross-attention mechanism in Transformer and enables recursive updates of cluster centers to facilitate strong representation learning; and 2. feature dispatching, which uses the updated cluster centers to redistribute image features through similarity-based metrics, resulting in a transparent pipeline. This elegant design streamlines an explainable and transferable workflow, capable of tackling heterogeneous vision tasks (i.e., image classification, object detection, and image segmentation) with varying levels of clustering granularity (i.e., image-, box-, and pixel-level). Empirical results demonstrate that CLUSTERFORMER outperforms various well-known specialized architectures, achieving 83.41% top-1 acc. over ImageNet-1K for image classification, 54.2% and 47.0% mAP over MS COCO for object detection and instance segmentation, 52.4% mIoU over ADE20K for semantic segmentation, and 55.8% PQ over COCO Panoptic for panoptic segmentation. For its efficacy, we hope our work can catalyze a paradigm shift in universal models in computer vision.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Recurrent cross-attention clustering: This reformulates the cross-attention mechanism in Transformer to enable recursive updates of cluster centers, facilitating strong representation learning.2. Feature dispatching: This uses updated cluster centers to redistribute image features through similarity-based metrics, resulting in a transparent pipeline.This elegant design enables a streamlined, explainable, and transferable workflow for tackling heterogeneous vision tasks (image classification, object detection, and image segmentation) with varying levels of clustering granularity (image-, box-, and pixel-level). Empirical results show that CLUSTERFORMER outperforms various well-known specialized architectures, achieving:* 83.41% top-1 accuracy over ImageNet-1K for image classification* 54.2% and 47.0% mAP over MS COCO for object detection and instance segmentation* 52.4% mIoU over ADE20K for semantic segmentation* 55.8% PQ over COCO Panoptic for panoptic segmentation.We hope that our work will catalyze a paradigm shift in universal models in computer vision, demonstrating the efficacy of the CLUSTERing paradigm in achieving strong representation learning and transferability across diverse vision tasks.</details></li>
</ol>
<hr>
<h2 id="Spatial-frequency-channels-shape-bias-and-adversarial-robustness"><a href="#Spatial-frequency-channels-shape-bias-and-adversarial-robustness" class="headerlink" title="Spatial-frequency channels, shape bias, and adversarial robustness"></a>Spatial-frequency channels, shape bias, and adversarial robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13190">http://arxiv.org/abs/2309.13190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ajaysub110/critical-band-masking">https://github.com/ajaysub110/critical-band-masking</a></li>
<li>paper_authors: Ajay Subramanian, Elena Sizikova, Najib J. Majaj, Denis G. Pelli<br>for:这种研究旨在探索人类和神经网络在认知物体方面使用的频谱信息是什么。methods:研究人员使用了 crítical band masking 技术，该技术可以揭示人类和神经网络在认知物体过程中使用的频谱滤波器（或“渠道”）的宽度。results:研究发现，人类在自然图像中认知物体时使用的频谱滤波器与人类在字体和梯形图像中认知时使用的频谱滤波器一致，宽度都是一个 octave。然而，神经网络渠道在不同的架构和训练策略下表现为 2-4 倍于人类渠道宽度，这意味着神经网络对高频和低频噪声敏感，而人类不是。 adversarial 和扩展图像训练通常用于提高网络的Robustness和形态偏好。这种训练是否将网络和人类的物体认知渠道进行对接？<details>
<summary>Abstract</summary>
What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or "channel'') that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. On the other hand, the neural network channel, across various architectures and training strategies, is 2-4 times as wide as the human channel. In other words, networks are vulnerable to high and low frequency noise that does not affect human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (53% variance explained) and with robustness of adversarially-trained networks (74% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further away from the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only increases this difference.
</details>
<details>
<summary>摘要</summary>
人类和神经网络在认知物体时使用哪些空间频率信息？在神经科学中，关键带掩蔽是一种已知的工具，可以揭示人类和神经网络在认知物体时使用的频率选择性滤波器。关键带掩蔽测量人类和神经网络在噪声添加后的认知性能的敏感度。现有的关键带掩蔽研究表明，人类认知 periodic patterns（格拉丁）和字母使用一个频率带宽（ doubles 频率）的空间频率滤波器（或“渠道”）来认知物体。我们在人类和神经网络之间进行关键带掩蔽任务，并测试了14名人类和76个神经网络在16种 ImageNet 分类任务中的表现。我们发现，人类在自然图像中认知物体使用了同样的一个频率带宽的渠道，这是人类物体认知的启示性特征。然而，神经网络渠道，不同架构和训练策略，宽度为2-4倍于人类渠道。即神经网络具有高频和低频噪声不affects human performance的敏感性。常见的图像增强和抗击训练被用来提高网络的Robustness和形态偏好。这种训练是否与人类物体认知渠道相align？神经网络渠道的三个特性（带宽、中心频率、峰噪敏感度）与形态偏好（53% 额外变化）以及对抗训练后网络的Robustness（74% 额外变化）存在强相关性。抗击训练可以提高网络的Robustness，但是同时也使得网络渠道的宽度更加远离人类渠道。因此，关键带掩蔽表明，神经网络渠道比人类渠道更加宽，并且抗击训练只会进一步扩大这个差距。
</details></li>
</ul>
<hr>
<h2 id="Flow-Factorized-Representation-Learning"><a href="#Flow-Factorized-Representation-Learning" class="headerlink" title="Flow Factorized Representation Learning"></a>Flow Factorized Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13167">http://arxiv.org/abs/2309.13167</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kingjamessong/latent-flow">https://github.com/kingjamessong/latent-flow</a></li>
<li>paper_authors: Yue Song, T. Anderson Keller, Nicu Sebe, Max Welling</li>
<li>for: 本研究的主要目标是学习表示，以达到对真实因素的分解。</li>
<li>methods: 我们提出了一种新的视角，即流动因素化表示学习（Flow Factorized Representation Learning），并在这种结构下学习更有效和更有用的表示。</li>
<li>results: 我们的模型在标准表示学习 bencmarks 上达到更高的likelihood，同时也更接近于相对平衡模型。此外，我们还证明了我们的变换是可以composite和适用于新数据，这表明我们的表示学习模型具有一定的抗预测和普适性。<details>
<summary>Abstract</summary>
A prominent goal of representation learning research is to achieve representations which are factorized in a useful manner with respect to the ground truth factors of variation. The fields of disentangled and equivariant representation learning have approached this ideal from a range of complimentary perspectives; however, to date, most approaches have proven to either be ill-specified or insufficiently flexible to effectively separate all realistic factors of interest in a learned latent space. In this work, we propose an alternative viewpoint on such structured representation learning which we call Flow Factorized Representation Learning, and demonstrate it to learn both more efficient and more usefully structured representations than existing frameworks. Specifically, we introduce a generative model which specifies a distinct set of latent probability paths that define different input transformations. Each latent flow is generated by the gradient field of a learned potential following dynamic optimal transport. Our novel setup brings new understandings to both \textit{disentanglement} and \textit{equivariance}. We show that our model achieves higher likelihoods on standard representation learning benchmarks while simultaneously being closer to approximately equivariant models. Furthermore, we demonstrate that the transformations learned by our model are flexibly composable and can also extrapolate to new data, implying a degree of robustness and generalizability approaching the ultimate goal of usefully factorized representation learning.
</details>
<details>
<summary>摘要</summary>
prominent goal of representation learning research 是 achiev representations 是 factorized in a useful manner with respect to the ground truth factors of variation. disentangled and equivariant representation learning  approached this ideal from a range of complimentary perspectives; however, to date, most approaches have proven to either be ill-specified or insufficiently flexible to effectively separate all realistic factors of interest in a learned latent space. In this work, we propose an alternative viewpoint on such structured representation learning, which we call Flow Factorized Representation Learning, and demonstrate it to learn both more efficient and more usefully structured representations than existing frameworks. Specifically, we introduce a generative model that specifies a distinct set of latent probability paths that define different input transformations. Each latent flow is generated by the gradient field of a learned potential following dynamic optimal transport. Our novel setup brings new understandings to both disentanglement and equivariance. We show that our model achieves higher likelihoods on standard representation learning benchmarks while simultaneously being closer to approximately equivariant models. Furthermore, we demonstrate that the transformations learned by our model are flexibly composable and can also extrapolate to new data, implying a degree of robustness and generalizability approaching the ultimate goal of usefully factorized representation learning.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries. The translation is based on the standard Chinese characters and grammar, and may be slightly different from the traditional Chinese used in Hong Kong and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Pixel-wise-Smoothing-for-Certified-Robustness-against-Camera-Motion-Perturbations"><a href="#Pixel-wise-Smoothing-for-Certified-Robustness-against-Camera-Motion-Perturbations" class="headerlink" title="Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations"></a>Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13150">http://arxiv.org/abs/2309.13150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanjiang Hu, Zuxin Liu, Linyi Li, Jiacheng Zhu, Ding Zhao<br>for:* 这种方法用于证明深度学习视觉模型对摄像头运动干扰的Robustness。methods:* 该方法使用了一种新的、高效的和实用的框架，利用了像素空间的平滑分布，从而消除了贵重的摄像头运动采样成本，提高了证明Robustness的效率。results:* 通过广泛的实验证明，该方法可以很好地平衡证明效果和计算效率。例如，该方法可以在使用只有30%的投影图像框架的情况下实现约80%的证明准确率。<details>
<summary>Abstract</summary>
In recent years, computer vision has made remarkable advancements in autonomous driving and robotics. However, it has been observed that deep learning-based visual perception models lack robustness when faced with camera motion perturbations. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. This is achieved by deriving Lipschitz-based approximated partition intervals. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames.
</details>
<details>
<summary>摘要</summary>
现在的计算机视觉技术在自动驾驶和机器人控制方面已经取得了非常出色的进步。然而，已经观察到深度学习基于视觉模型对摄像头运动干扰的Robustness有所不足。现有的证明过程对摄像头运动干扰的Robustness进行评估是非常昂贵和时间consuming的，因为需要进行大量的图像投影以实现Monte Carlo抽象在3D摄像头运动空间中。为解决这些挑战，我们提出了一种新的、高效、实用的框架，用于证明3D-2D投影变换对摄像头运动干扰的Robustness。我们的方法利用2D像素空间中的平滑分布而不是3D物理空间中的平滑分布，从而消除了高昂的摄像头运动样本成本和大量的图像投影。通过使用像素空间平滑分布，我们可以完全上界投影错误，使用一种基于均匀分区的技术来实现Camera motion空间中的均匀分区。此外，我们将证明框架扩展到一个更加通用的场景，只需要提供单帧点云作为投影oracle。我们通过 derivation Lipschitz-basedapproximated partition intervals来实现这一点。通过广泛的实验，我们证明了我们的提出的方法的效率和可靠性之间的trade-off。特别是，我们的方法可以在30%的图像投影帧上达到约80%的证明精度。
</details></li>
</ul>
<hr>
<h2 id="Trading-off-Mutual-Information-on-Feature-Aggregation-for-Face-Recognition"><a href="#Trading-off-Mutual-Information-on-Feature-Aggregation-for-Face-Recognition" class="headerlink" title="Trading-off Mutual Information on Feature Aggregation for Face Recognition"></a>Trading-off Mutual Information on Feature Aggregation for Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13137">http://arxiv.org/abs/2309.13137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Akyash, Ali Zafari, Nasser M. Nasrabadi<br>for: 提高人脸识别精度methods:  aggregate ArcFace和AdaFace两个state-of-the-art深度人脸识别模型的输出，通过利用trasnformer注意机制来把扩展两个特征地图之间的关系，从而提高人脸识别系统的总体识别能力。results: 通过对比多个标准 bencmark 结果，我们观察到了我们的方法在人脸识别 tasks 中的一致性提高。<details>
<summary>Abstract</summary>
Despite the advances in the field of Face Recognition (FR), the precision of these methods is not yet sufficient. To improve the FR performance, this paper proposes a technique to aggregate the outputs of two state-of-the-art (SOTA) deep FR models, namely ArcFace and AdaFace. In our approach, we leverage the transformer attention mechanism to exploit the relationship between different parts of two feature maps. By doing so, we aim to enhance the overall discriminative power of the FR system. One of the challenges in feature aggregation is the effective modeling of both local and global dependencies. Conventional transformers are known for their ability to capture long-range dependencies, but they often struggle with modeling local dependencies accurately. To address this limitation, we augment the self-attention mechanism to capture both local and global dependencies effectively. This allows our model to take advantage of the overlapping receptive fields present in corresponding locations of the feature maps. However, fusing two feature maps from different FR models might introduce redundancies to the face embedding. Since these models often share identical backbone architectures, the resulting feature maps may contain overlapping information, which can mislead the training process. To overcome this problem, we leverage the principle of Information Bottleneck to obtain a maximally informative facial representation. This ensures that the aggregated features retain the most relevant and discriminative information while minimizing redundant or misleading details. To evaluate the effectiveness of our proposed method, we conducted experiments on popular benchmarks and compared our results with state-of-the-art algorithms. The consistent improvement we observed in these benchmarks demonstrates the efficacy of our approach in enhancing FR performance.
</details>
<details>
<summary>摘要</summary>
尽管面Recognition（FR）领域已经取得了一些进步，但FR方法的精度仍然不够高。为了提高FR性能，这篇论文提议了一种将两种现有的深度FR模型，即ArcFace和AdaFace，的输出聚合的技术。在我们的方法中，我们利用了变换器注意机制，以利用两个特征图的不同部分之间的关系。这样做的目的是提高总的识别力。一个挑战在特征聚合中是有效地模型本地和全局依赖关系。传统的变换器通常能够很好地捕捉长距离依赖关系，但它们经常在本地依赖关系上做出不准确的预测。为了解决这个限制，我们在自我注意机制中进行了修改，以同时 capture本地和全局依赖关系。这使得我们的模型能够利用特征图中相互重叠的区域的拥有的相互关系。然而，将两个特征图从不同的FR模型融合可能会导致人脸嵌入中的纬度冗余。这是因为这些模型通常具有相同的背部架构，导致生成的特征图可能包含重复的信息。为了解决这个问题，我们利用信息瓶颈原理，从人脸嵌入中提取最大可能的信息，以确保聚合的特征保留了最有用和权威的信息，同时减少不必要或误导的细节。为了评估我们的提议的效果，我们在popular benchmark上进行了实验，并与当前的算法进行比较。我们在这些benchmark中经常观察到了一致性提高，这表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Calibration-of-Deep-Neural-Networks-for-Medical-Image-Classification"><a href="#Understanding-Calibration-of-Deep-Neural-Networks-for-Medical-Image-Classification" class="headerlink" title="Understanding Calibration of Deep Neural Networks for Medical Image Classification"></a>Understanding Calibration of Deep Neural Networks for Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13132">http://arxiv.org/abs/2309.13132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Singh Sambyal, Usma Niyaz, Narayanan C. Krishnan, Deepti R. Bathula</li>
<li>for: 这篇论文旨在探讨医疗影像分析中，使用深度神经网络时，确保模型的准确性和可靠性是非常重要的。</li>
<li>methods: 这篇论文使用了多种训练方法，包括全supervised training和旋转自给supervised learning，以了解不同训练方法对模型准确性和可靠性的影响。</li>
<li>results: 研究发现，使用旋转自给supervised learning的训练方法可以将模型的准确性和可靠性提高，并且可以实现比全supervised training更好的准确性和可靠性。<details>
<summary>Abstract</summary>
In the field of medical image analysis, achieving high accuracy is not enough; ensuring well-calibrated predictions is also crucial. Confidence scores of a deep neural network play a pivotal role in explainability by providing insights into the model's certainty, identifying cases that require attention, and establishing trust in its predictions. Consequently, the significance of a well-calibrated model becomes paramount in the medical imaging domain, where accurate and reliable predictions are of utmost importance. While there has been a significant effort towards training modern deep neural networks to achieve high accuracy on medical imaging tasks, model calibration and factors that affect it remain under-explored. To address this, we conducted a comprehensive empirical study that explores model performance and calibration under different training regimes. We considered fully supervised training, which is the prevailing approach in the community, as well as rotation-based self-supervised method with and without transfer learning, across various datasets and architecture sizes. Multiple calibration metrics were employed to gain a holistic understanding of model calibration. Our study reveals that factors such as weight distributions and the similarity of learned representations correlate with the calibration trends observed in the models. Notably, models trained using rotation-based self-supervised pretrained regime exhibit significantly better calibration while achieving comparable or even superior performance compared to fully supervised models across different medical imaging datasets. These findings shed light on the importance of model calibration in medical image analysis and highlight the benefits of incorporating self-supervised learning approach to improve both performance and calibration.
</details>
<details>
<summary>摘要</summary>
在医疗影像分析领域，即使达到高精度也不够；保证准确的预测也非常重要。深度神经网络的自信分数在解释性方面发挥关键作用，为模型的certainty提供了信息， помо助分析出需要注意的案例，并建立对预测的信任。因此，在医疗影像领域，准确可靠的预测是非常重要的。虽然社区内有很大的努力，以使现代深度神经网络在医疗影像任务上达到高精度，但模型准确性和可靠性的调整仍然受到了少数研究。为了解决这个问题，我们进行了全面的实验研究，探讨了不同的训练方法对模型性能和准确性的影响。我们考虑了完全监督学习，这是社区中最常用的方法，以及旋转基于自动学习的方法，包括无扩展和带扩展的方法，在不同的数据集和模型大小上进行了测试。我们使用多种准确度指标来了解模型准确性的多方面特性。我们的研究发现，模型的weight分布和学习的表示相似性与模型准确性的趋势相关。特别是，通过旋转基于自动学习的预训练方法进行训练的模型在不同的医疗影像数据集上显示出了显著更好的准确性，而且与完全监督学习模型相比，它们在不同的模型大小上实现了相似或更高的性能。这些发现 shed light on the importance of model calibration in medical image analysis, and highlight the benefits of incorporating self-supervised learning approaches to improve both performance and calibration.
</details></li>
</ul>
<hr>
<h2 id="Robotic-Offline-RL-from-Internet-Videos-via-Value-Function-Pre-Training"><a href="#Robotic-Offline-RL-from-Internet-Videos-via-Value-Function-Pre-Training" class="headerlink" title="Robotic Offline RL from Internet Videos via Value-Function Pre-Training"></a>Robotic Offline RL from Internet Videos via Value-Function Pre-Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13041">http://arxiv.org/abs/2309.13041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chethan Bhateja, Derek Guo, Dibya Ghosh, Anikait Singh, Manan Tomar, Quan Vuong, Yevgen Chebotar, Sergey Levine, Aviral Kumar</li>
<li>for: 这个论文是为了帮助机器人学习学习掌控技能，尤其是在没有奖励信号的情况下。</li>
<li>methods: 这个论文使用了视频数据来适应机器人的学习，通过时间差学习来学习值函数，并将其应用于机器人掌控任务中。</li>
<li>results: 这个论文在多个机器人掌控任务上取得了良好的结果，其中包括在一个真实的WidowX机器人上进行的多个掌控任务。政策比之前的方法更好，更加稳定，并能够广泛应用。<details>
<summary>Abstract</summary>
Pre-training on Internet data has proven to be a key ingredient for broad generalization in many modern ML systems. What would it take to enable such capabilities in robotic reinforcement learning (RL)? Offline RL methods, which learn from datasets of robot experience, offer one way to leverage prior data into the robotic learning pipeline. However, these methods have a "type mismatch" with video data (such as Ego4D), the largest prior datasets available for robotics, since video offers observation-only experience without the action or reward annotations needed for RL methods. In this paper, we develop a system for leveraging large-scale human video datasets in robotic offline RL, based entirely on learning value functions via temporal-difference learning. We show that value learning on video datasets learns representations that are more conducive to downstream robotic offline RL than other approaches for learning from video data. Our system, called V-PTR, combines the benefits of pre-training on video data with robotic offline RL approaches that train on diverse robot data, resulting in value functions and policies for manipulation tasks that perform better, act robustly, and generalize broadly. On several manipulation tasks on a real WidowX robot, our framework produces policies that greatly improve over prior methods. Our video and additional details can be found at https://dibyaghosh.com/vptr/
</details>
<details>
<summary>摘要</summary>
在现代机器学习系统中，预训练在互联网数据上有证明是一种关键因素，以实现广泛的通用化。在机器人学习上，可以通过在机器人经验数据集上进行预训练来实现这种能力。然而，这些方法与视频数据（如Ego4D）存在类型匹配问题，因为视频只提供了观察经验，而不提供动作或奖励注释，这些注释是机器人学习方法所需的。在这篇论文中，我们开发了一种将大规模人类视频数据集成入机器人预训练的系统，基于完全通过时间差学习学习值函数。我们表明，在视频数据集上学习值函数可以学习更适合下游机器人预训练的表示，比其他视频数据学习方法更好。我们的系统，即V-PTR，将预训练在视频数据集上的好处与多种机器人数据预训练相结合，以生成更好的 manipulate 任务的价值函数和策略。在一个真实的 WidowX 机器人上，我们的框架可以大幅提高先前方法的政策。我们的视频和其他细节可以在 <https://dibyaghosh.com/vptr/> 找到。
</details></li>
</ul>
<hr>
<h2 id="NeRRF-3D-Reconstruction-and-View-Synthesis-for-Transparent-and-Specular-Objects-with-Neural-Refractive-Reflective-Fields"><a href="#NeRRF-3D-Reconstruction-and-View-Synthesis-for-Transparent-and-Specular-Objects-with-Neural-Refractive-Reflective-Fields" class="headerlink" title="NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields"></a>NeRRF: 3D Reconstruction and View Synthesis for Transparent and Specular Objects with Neural Refractive-Reflective Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13039">http://arxiv.org/abs/2309.13039</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawning77/nerrf">https://github.com/dawning77/nerrf</a></li>
<li>paper_authors: Xiaoxue Chen, Junchen Liu, Hao Zhao, Guyue Zhou, Ya-Qin Zhang</li>
<li>for: 这篇论文是关于图像基于视图合成的研究，旨在解决NeRF无法处理复杂的光路变化问题，导致无法成功合成透明或镜面物体的问题。</li>
<li>methods: 作者们提出了吸收射镜场（Refractive-Reflective Field，RRF），通过使用进攻四面体和进攻编码来重建非LAMBERTIAN对象的几何结构，并使用费勒涅尔定律来模型物体的折射和反射效果。同时，为了实现高效和有效的抑杂，提出了虚拟圆锥超抽样技术。</li>
<li>results: 作者们在不同的形状、背景和费勒涅尔定律上进行了多种实验，并对不同的编辑应用进行了质量和量化的比较，包括材质编辑、物体替换&#x2F;插入和环境照明估计。<details>
<summary>Abstract</summary>
Neural radiance fields (NeRF) have revolutionized the field of image-based view synthesis. However, NeRF uses straight rays and fails to deal with complicated light path changes caused by refraction and reflection. This prevents NeRF from successfully synthesizing transparent or specular objects, which are ubiquitous in real-world robotics and A/VR applications. In this paper, we introduce the refractive-reflective field. Taking the object silhouette as input, we first utilize marching tetrahedra with a progressive encoding to reconstruct the geometry of non-Lambertian objects and then model refraction and reflection effects of the object in a unified framework using Fresnel terms. Meanwhile, to achieve efficient and effective anti-aliasing, we propose a virtual cone supersampling technique. We benchmark our method on different shapes, backgrounds and Fresnel terms on both real-world and synthetic datasets. We also qualitatively and quantitatively benchmark the rendering results of various editing applications, including material editing, object replacement/insertion, and environment illumination estimation. Codes and data are publicly available at https://github.com/dawning77/NeRRF.
</details>
<details>
<summary>摘要</summary>
“对象基于图像的视 synthesis 领域受到对应� Neural Radiance Fields（NeRF）的革命性影响。然而，NeRF 使用直线光束，无法处理由折射和反射导致的复杂光束变化，这限制了 NeRF 在透明或 Specular 物体的成功实现。在这篇论文中，我们介绍了 Refractive-Reflective Field（RRF）。我们将物体照片为输入，首先使用进攻四边形（Marching Tetrahedra）进行非 Lambertian 物体的重建，然后在一个统一框架中模型物体的折射和反射效应，使用 Fresnel 表达。此外，为了获得高效和有效的抑挡遮瑕，我们提出了虚拟圆锥超推数技术。我们在不同的形状、背景和 Fresnel 表达下进行了不同的测试，并评估了不同的编辑应用，包括材料编辑、物体取代/插入和环境照明估计。我们的代码和数据公开在 GitHub 上，请参考 https://github.com/dawning77/NeRRF。”
</details></li>
</ul>
<hr>
<h2 id="Privacy-Assessment-on-Reconstructed-Images-Are-Existing-Evaluation-Metrics-Faithful-to-Human-Perception"><a href="#Privacy-Assessment-on-Reconstructed-Images-Are-Existing-Evaluation-Metrics-Faithful-to-Human-Perception" class="headerlink" title="Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?"></a>Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13038">http://arxiv.org/abs/2309.13038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxiao Sun, Nidham Gazagnadou, Vivek Sharma, Lingjuan Lyu, Hongdong Li, Liang Zheng</li>
<li>for: 这篇论文主要是为了研究现有的手工图像质量指标是否能够准确反映人类对隐私信息的识别度。</li>
<li>methods: 这篇论文使用了4种现有的攻击方法来重建图像，并询问多个人标注者判断重建图像是否可识。</li>
<li>results: 研究发现现有的手工指标与人类对隐私信息的识别度强度不匹配，甚至自身差异也很大。提出了一种学习基于的measure called SemSim来评估重建图像的semantic相似性，并证明SemSim具有更高的人类评价相关性。<details>
<summary>Abstract</summary>
Hand-crafted image quality metrics, such as PSNR and SSIM, are commonly used to evaluate model privacy risk under reconstruction attacks. Under these metrics, reconstructed images that are determined to resemble the original one generally indicate more privacy leakage. Images determined as overall dissimilar, on the other hand, indicate higher robustness against attack. However, there is no guarantee that these metrics well reflect human opinions, which, as a judgement for model privacy leakage, are more trustworthy. In this paper, we comprehensively study the faithfulness of these hand-crafted metrics to human perception of privacy information from the reconstructed images. On 5 datasets ranging from natural images, faces, to fine-grained classes, we use 4 existing attack methods to reconstruct images from many different classification models and, for each reconstructed image, we ask multiple human annotators to assess whether this image is recognizable. Our studies reveal that the hand-crafted metrics only have a weak correlation with the human evaluation of privacy leakage and that even these metrics themselves often contradict each other. These observations suggest risks of current metrics in the community. To address this potential risk, we propose a learning-based measure called SemSim to evaluate the Semantic Similarity between the original and reconstructed images. SemSim is trained with a standard triplet loss, using an original image as an anchor, one of its recognizable reconstructed images as a positive sample, and an unrecognizable one as a negative. By training on human annotations, SemSim exhibits a greater reflection of privacy leakage on the semantic level. We show that SemSim has a significantly higher correlation with human judgment compared with existing metrics. Moreover, this strong correlation generalizes to unseen datasets, models and attack methods.
</details>
<details>
<summary>摘要</summary>
手工制作的图像质量指标，如PSNR和SSIM，通常用于评估模型隐私风险的重建攻击。在这些指标下，可以重建的图像，如果与原始图像相似，则表示更大的隐私泄露。相反，如果图像与原始图像不相似，则表示更高的鲁棒性。但是，这些指标并不能保证与人类意见相符，人类意见是评估模型隐私泄露的更可靠的判断标准。在这篇论文中，我们全面研究了这些手工制作的指标是否能够准确反映人类对重建图像中的隐私信息的评估。在5个不同类型的数据集上，我们使用4种不同的攻击方法来重建图像，并对每个重建图像请多名人工标注者评估这个图像是否可识别。我们的研究发现，这些手工制作的指标与人类对隐私信息的评估存在较弱的相关性，甚至这些指标本身经常相互矛盾。这些观察表明了现有的指标在社区中的风险。为了解决这个潜在的风险，我们提议一种学习基于的度量方法，即SemSim，用于评估重建图像与原始图像之间的semantic相似性。SemSim通过使用标准的 triplet损失函数，使用原始图像作为固定点，一个可识别的重建图像作为正样本，一个不可识别的重建图像作为负样本进行训练。通过人工标注，SemSim能够更好地反映隐私信息的semantic水平上的泄露。我们展示SemSim与现有指标之间存在高度相关性，并且这种相关性可以在未看到的数据集、模型和攻击方法上进行扩展。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-UNet-and-Variants-for-Medical-Image-Segmentation"><a href="#Performance-Analysis-of-UNet-and-Variants-for-Medical-Image-Segmentation" class="headerlink" title="Performance Analysis of UNet and Variants for Medical Image Segmentation"></a>Performance Analysis of UNet and Variants for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13013">http://arxiv.org/abs/2309.13013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walid Ehab, Yongmin Li</li>
<li>for: 本研究旨在探讨深度学习模型在医疗图像分割中的应用，特别是UNet架构和其变种的表现。</li>
<li>methods: 本研究使用了深度学习模型，包括标准UNet、Res-UNet和Attention Res-UNet三种架构，对多种医疗图像分割任务进行评估。</li>
<li>results: 研究发现，扩展UNet架构具有优秀的医疗图像分割能力，而Res-UNet和Attention Res-UNet架构具有更平滑的整合和更高的性能，特别是处理细节图像时。<details>
<summary>Abstract</summary>
Medical imaging plays a crucial role in modern healthcare by providing non-invasive visualisation of internal structures and abnormalities, enabling early disease detection, accurate diagnosis, and treatment planning. This study aims to explore the application of deep learning models, particularly focusing on the UNet architecture and its variants, in medical image segmentation. We seek to evaluate the performance of these models across various challenging medical image segmentation tasks, addressing issues such as image normalization, resizing, architecture choices, loss function design, and hyperparameter tuning. The findings reveal that the standard UNet, when extended with a deep network layer, is a proficient medical image segmentation model, while the Res-UNet and Attention Res-UNet architectures demonstrate smoother convergence and superior performance, particularly when handling fine image details. The study also addresses the challenge of high class imbalance through careful preprocessing and loss function definitions. We anticipate that the results of this study will provide useful insights for researchers seeking to apply these models to new medical imaging problems and offer guidance and best practices for their implementation.
</details>
<details>
<summary>摘要</summary>
医学影像在现代医疗中扮演着重要的角色，通过非侵入性的视觉化内部结构和异常，提高疾病早期检测、精准诊断和治疗规划。本研究旨在探讨深度学习模型，尤其是UNet架构和其变体，在医学图像分割任务中的应用。我们希望通过不同的挑战性医学图像分割任务来评估这些模型的表现，解决问题如图像normalization、resize、架构选择、损失函数设计和Hyperparameter优化。研究发现，标准的UNet架构，当扩展了深度网络层时，是一个高效的医学图像分割模型，而Res-UNet和Attention Res-UNet架构在处理细节时表现更好，特别是在处理细节时。此外，我们还 Addresses the challenge of high class imbalance through careful preprocessing and loss function definitions。我们预计这些结果将为研究人员在新的医学影像问题上应用这些模型提供有用的指导和最佳实践。
</details></li>
</ul>
<hr>
<h2 id="Deep3DSketch-Rapid-3D-Modeling-from-Single-Free-hand-Sketches"><a href="#Deep3DSketch-Rapid-3D-Modeling-from-Single-Free-hand-Sketches" class="headerlink" title="Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches"></a>Deep3DSketch+: Rapid 3D Modeling from Single Free-hand Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13006">http://arxiv.org/abs/2309.13006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianrun Chen, Chenglong Fu, Ying Zang, Lanyun Zhu, Jia Zhang, Papa Mao, Lingyun Sun</li>
<li>for:  This paper aims to provide an end-to-end approach for 3D modeling using only a single free-hand sketch, without requiring multiple sketches or view information.</li>
<li>methods: The proposed approach, called Deep3DSketch+, uses a lightweight generation network for efficient inference in real-time, and a structural-aware adversarial training approach with a Stroke Enhancement Module (SEM) to capture the structural information and facilitate learning of realistic and fine-detailed shape structures.</li>
<li>results: The proposed approach achieved state-of-the-art (SOTA) performance on both synthetic and real datasets, demonstrating its effectiveness in generating high-fidelity 3D models from a single free-hand sketch.<details>
<summary>Abstract</summary>
The rapid development of AR/VR brings tremendous demands for 3D content. While the widely-used Computer-Aided Design (CAD) method requires a time-consuming and labor-intensive modeling process, sketch-based 3D modeling offers a potential solution as a natural form of computer-human interaction. However, the sparsity and ambiguity of sketches make it challenging to generate high-fidelity content reflecting creators' ideas. Precise drawing from multiple views or strategic step-by-step drawings is often required to tackle the challenge but is not friendly to novice users. In this work, we introduce a novel end-to-end approach, Deep3DSketch+, which performs 3D modeling using only a single free-hand sketch without inputting multiple sketches or view information. Specifically, we introduce a lightweight generation network for efficient inference in real-time and a structural-aware adversarial training approach with a Stroke Enhancement Module (SEM) to capture the structural information to facilitate learning of the realistic and fine-detailed shape structures for high-fidelity performance. Extensive experiments demonstrated the effectiveness of our approach with the state-of-the-art (SOTA) performance on both synthetic and real datasets.
</details>
<details>
<summary>摘要</summary>
rapid development of AR/VR 带来巨大的三维内容需求，而传统的计算机支持设计（CAD）方法需要时间consuming 和 labor-intensive modeling process， sketch-based 三维模型化呈现了一个可能的解决方案，但是绘制缺乏和模糊性使得模型化困难以实现创作者的想法。需要精确地从多个视图或步骤性的绘制来解决这个挑战，但是这并不友好于初学者。在这种工作中，我们介绍了一种新的端到端方法，即 Deep3DSketch+，它可以通过单个自由手绘制来完成3D模型化，不需要多个绘制或视图信息输入。我们还引入了轻量级生成网络以实现实时执行，以及一种结构意识的对抗训练方法和笔触提升模块（SEM），以捕捉结构信息，使模型学习真实和细节rich shape结构，以实现高精度性。我们的实验表明，我们的方法可以与当前最佳性（SOTA）在synthetic和实际数据集上达到最高性能。
</details></li>
</ul>
<hr>
<h2 id="Point-Cloud-Network-An-Order-of-Magnitude-Improvement-in-Linear-Layer-Parameter-Count"><a href="#Point-Cloud-Network-An-Order-of-Magnitude-Improvement-in-Linear-Layer-Parameter-Count" class="headerlink" title="Point Cloud Network: An Order of Magnitude Improvement in Linear Layer Parameter Count"></a>Point Cloud Network: An Order of Magnitude Improvement in Linear Layer Parameter Count</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12996">http://arxiv.org/abs/2309.12996</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/chetterich/pcn-paper-and-materials">https://gitlab.com/chetterich/pcn-paper-and-materials</a></li>
<li>paper_authors: Charles Hetterich</li>
<li>for: 本文介绍了Point Cloud Network（PCN）架构，一种新的深度学习网络实现方式，并提供了实验证明PCN的优越性比多层感知器（MLP）。</li>
<li>methods: 本文使用了MLP和PCN两种不同的架构来训练多个模型，包括原始的AlexNet模型，以便对直接比较线性层的性能。</li>
<li>results: 研究发现，使用PCN架构的AlexNet-PCN16模型可以与原始AlexNet模型具有相同的测试准确率（test accuracy），仅占AlexNet模型的99.5%参数量。所有训练都在云端RTX 4090 GPU上进行，使用了pytorch库进行模型构建和训练。<details>
<summary>Abstract</summary>
This paper introduces the Point Cloud Network (PCN) architecture, a novel implementation of linear layers in deep learning networks, and provides empirical evidence to advocate for its preference over the Multilayer Perceptron (MLP) in linear layers. We train several models, including the original AlexNet, using both MLP and PCN architectures for direct comparison of linear layers (Krizhevsky et al., 2012). The key results collected are model parameter count and top-1 test accuracy over the CIFAR-10 and CIFAR-100 datasets (Krizhevsky, 2009). AlexNet-PCN16, our PCN equivalent to AlexNet, achieves comparable efficacy (test accuracy) to the original architecture with a 99.5% reduction of parameters in its linear layers. All training is done on cloud RTX 4090 GPUs, leveraging pytorch for model construction and training. Code is provided for anyone to reproduce the trials from this paper.
</details>
<details>
<summary>摘要</summary></li>
<li>The PCN architecture has fewer parameters (99.5% fewer in the linear layers) but still achieves the same level of accuracy as the original AlexNet.* The PCN architecture performs well on both the CIFAR-10 and CIFAR-100 datasets.All of the training was done on cloud RTX 4090 GPUs using PyTorch for model construction and training. The code for reproducing the trials is provided.</details></li>
</ul>
<hr>
<h2 id="License-Plate-Recognition-Based-On-Multi-Angle-View-Model"><a href="#License-Plate-Recognition-Based-On-Multi-Angle-View-Model" class="headerlink" title="License Plate Recognition Based On Multi-Angle View Model"></a>License Plate Recognition Based On Multi-Angle View Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12972">http://arxiv.org/abs/2309.12972</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeniSoida/pl1">https://github.com/zeniSoida/pl1</a></li>
<li>paper_authors: Dat Tran-Anh, Khanh Linh Tran, Hoai-Nam Vu</li>
<li>for: 本研究旨在解决图像&#x2F;视频中文检测问题，尤其是识别车牌上的文字。</li>
<li>methods: 本方法 combinates multiple views of license plates to improve text detection accuracy. 具体来说，我们使用三个视角（view-1、view-2、view-3）来识别车牌上的文字组成部分，并使用相似度和距离度量来确定最佳匹配。</li>
<li>results: 实验结果表明，提出的方法在自主收集的PTITPlates dataset和Stanford Cars Dataset上具有较高的识别精度，较exist方法有所提高。<details>
<summary>Abstract</summary>
In the realm of research, the detection/recognition of text within images/videos captured by cameras constitutes a highly challenging problem for researchers. Despite certain advancements achieving high accuracy, current methods still require substantial improvements to be applicable in practical scenarios. Diverging from text detection in images/videos, this paper addresses the issue of text detection within license plates by amalgamating multiple frames of distinct perspectives. For each viewpoint, the proposed method extracts descriptive features characterizing the text components of the license plate, specifically corner points and area. Concretely, we present three viewpoints: view-1, view-2, and view-3, to identify the nearest neighboring components facilitating the restoration of text components from the same license plate line based on estimations of similarity levels and distance metrics. Subsequently, we employ the CnOCR method for text recognition within license plates. Experimental results on the self-collected dataset (PTITPlates), comprising pairs of images in various scenarios, and the publicly available Stanford Cars Dataset, demonstrate the superiority of the proposed method over existing approaches.
</details>
<details>
<summary>摘要</summary>
在研究领域中，图像/视频中的文本检测/识别问题对研究人员来说是非常困难的。尽管有一些进步，但现有方法仍然需要进一步改进才能在实际场景中应用。与图像/视频中的文本检测方法不同，这篇论文强调车牌上的文本检测，通过将多个视角的帧合并来实现。对于每个视角，我们提出的方法可以提取描述文本组件的特征，包括角点和面积。具体来说，我们提出了三个视角：视角1、视角2和视角3，用于标识同一个车牌线上的相邻组件，并且根据相似度和距离度量来重建车牌上的文本组件。接着，我们使用CnOCR方法进行车牌上文本识别。实验结果表明，我们的提议方法在自己收集的数据集（PTITPlates）和公共可用的 stanford cars 数据集上具有显著优势，超过现有方法。
</details></li>
</ul>
<hr>
<h2 id="PI-RADS-v2-Compliant-Automated-Segmentation-of-Prostate-Zones-Using-co-training-Motivated-Multi-task-Dual-Path-CNN"><a href="#PI-RADS-v2-Compliant-Automated-Segmentation-of-Prostate-Zones-Using-co-training-Motivated-Multi-task-Dual-Path-CNN" class="headerlink" title="PI-RADS v2 Compliant Automated Segmentation of Prostate Zones Using co-training Motivated Multi-task Dual-Path CNN"></a>PI-RADS v2 Compliant Automated Segmentation of Prostate Zones Using co-training Motivated Multi-task Dual-Path CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12970">http://arxiv.org/abs/2309.12970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arnab Das, Suhita Ghosh, Sebastian Stober</li>
<li>for: 这个论文的目的是提供一种自动化的检测和评估肾脏癌病变的方法，以帮助提高诊断和治疗的精度。</li>
<li>methods: 这个方法使用了一种双树 convolutional neural network (CNN)，每个树分别捕捉不同的区域（PZ、TZ、DPU和AFS）的表示。在第二个训练阶段，不同的树的表示进行了互补性的调整，以提高 segmentation 精度。此外，这个方法还 integrate 了多任务学习来进一步提高 segmentation 精度。</li>
<li>results: 根据这个方法，误差（mean absolute symmetric distance）的提高量为7.56%、11.00%、58.43%和19.67%对PZ、TZ、DPU和AFS区域进行了提高。<details>
<summary>Abstract</summary>
The detailed images produced by Magnetic Resonance Imaging (MRI) provide life-critical information for the diagnosis and treatment of prostate cancer. To provide standardized acquisition, interpretation and usage of the complex MRI images, the PI-RADS v2 guideline was proposed. An automated segmentation following the guideline facilitates consistent and precise lesion detection, staging and treatment. The guideline recommends a division of the prostate into four zones, PZ (peripheral zone), TZ (transition zone), DPU (distal prostatic urethra) and AFS (anterior fibromuscular stroma). Not every zone shares a boundary with the others and is present in every slice. Further, the representations captured by a single model might not suffice for all zones. This motivated us to design a dual-branch convolutional neural network (CNN), where each branch captures the representations of the connected zones separately. Further, the representations from different branches act complementary to each other at the second stage of training, where they are fine-tuned through an unsupervised loss. The loss penalises the difference in predictions from the two branches for the same class. We also incorporate multi-task learning in our framework to further improve the segmentation accuracy. The proposed approach improves the segmentation accuracy of the baseline (mean absolute symmetric distance) by 7.56%, 11.00%, 58.43% and 19.67% for PZ, TZ, DPU and AFS zones respectively.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging (MRI) 提供了生命critical的信息，用于诊断和治疗前列腺癌。为了提供标准化的获取、解释和使用复杂的MRI图像，PI-RADS v2指南被提出。一个自动 segmentation 可以确保consistent和精确的肿坏检测、stage和治疗。指南建议将前列腺分成四个区域：PZ（周边区）、TZ（过渡区）、DPU（后束肠URETHRA）和AFS（前锥形connective tissue）。不是每个区域都与其他区域接壤，而且不同的区域在每个层次中的表现不同。这种情况motivates我们设计了一个双支分布式 convolutional neural network (CNN)，其中每支分布式 CNN 分别捕捉connected zones 的表现。此外，不同支分布式 CNN 在第二个训练阶段 fine-tune 的损失中进行互补作用，这种损失penalizes 两支分布式 CNN 对同一类型的预测差异。我们还在我们的框架中包含多任务学习，以进一步提高 segmentation 精度。提出的方法与基准（mean absolute symmetric distance）的 segmentation 精度相比，提高了7.56%、11.00%、58.43%和19.67%  respectivly 的PZ、TZ、DPU和AFS区域。
</details></li>
</ul>
<hr>
<h2 id="Detect-Every-Thing-with-Few-Examples"><a href="#Detect-Every-Thing-with-Few-Examples" class="headerlink" title="Detect Every Thing with Few Examples"></a>Detect Every Thing with Few Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12969">http://arxiv.org/abs/2309.12969</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlzxy/devit">https://github.com/mlzxy/devit</a></li>
<li>paper_authors: Xinyu Zhang, Yuting Wang, Abdeslam Boularias</li>
<li>for: 这个论文目的是开发一种基于视觉语言的开放类型物体检测器，可以检测到训练时没有看到的类别。</li>
<li>methods: 这个论文使用了视觉只的DINOv2背景，并通过示例图像来学习新的类别。它还提出了一种将多类分类任务转换为 binary 分类任务的技术，以及一种地区卷积技术来优化本地化检测。</li>
<li>results: 在COCO和LVIS测试集上，DE-ViT比开放类型SoTA高6.9个AP50，并在新类中达到50个AP50。在几shot和一shot SoTA上，DE-ViT比较高7.2个mAP和2.8个AP50。在LVIS测试集上，DE-ViT比开放类型SoTA高2.2个mask AP，达到34.3个mask APr。<details>
<summary>Abstract</summary>
Open-set object detection aims at detecting arbitrary categories beyond those seen during training. Most recent advancements have adopted the open-vocabulary paradigm, utilizing vision-language backbones to represent categories with language. In this paper, we introduce DE-ViT, an open-set object detector that employs vision-only DINOv2 backbones and learns new categories through example images instead of language. To improve general detection ability, we transform multi-classification tasks into binary classification tasks while bypassing per-class inference, and propose a novel region propagation technique for localization. We evaluate DE-ViT on open-vocabulary, few-shot, and one-shot object detection benchmark with COCO and LVIS. For COCO, DE-ViT outperforms the open-vocabulary SoTA by 6.9 AP50 and achieves 50 AP50 in novel classes. DE-ViT surpasses the few-shot SoTA by 15 mAP on 10-shot and 7.2 mAP on 30-shot and one-shot SoTA by 2.8 AP50. For LVIS, DE-ViT outperforms the open-vocabulary SoTA by 2.2 mask AP and reaches 34.3 mask APr. Code is available at https://github.com/mlzxy/devit.
</details>
<details>
<summary>摘要</summary>
“开放集Object检测目标在训练时未经看过的类型检测。最新的进展都采用了开放词汇思想，通过视力语言核心来表示类别。本文介绍DE-ViT，一种基于视力只的DINOv2核心实现开放集Object检测，不需要语言。为提高检测能力，我们将多类型分类任务转化为二分类任务，并提出一种新的区域卷积技术。我们在COCO和LVIS上进行了开放集、少量和一个批量Object检测测试，对COCO的开放集SoTA进行了6.9 AP50的超越和50 AP50的新类表现。对于少量和一个批量SoTA，DE-ViT也进行了15 mAP和7.2 mAP的超越。对于LVIS，DE-ViT超越了开放集SoTA2.2个面积AP和34.3个面积APr。代码可以在https://github.com/mlzxy/devit中下载。”
</details></li>
</ul>
<hr>
<h2 id="Deformable-3D-Gaussians-for-High-Fidelity-Monocular-Dynamic-Scene-Reconstruction"><a href="#Deformable-3D-Gaussians-for-High-Fidelity-Monocular-Dynamic-Scene-Reconstruction" class="headerlink" title="Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction"></a>Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13101">http://arxiv.org/abs/2309.13101</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ingra14m/Deformable-3D-Gaussians">https://github.com/ingra14m/Deformable-3D-Gaussians</a></li>
<li>paper_authors: Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, Xiaogang Jin</li>
<li>for: 本研究旨在解决现有的动态场景重建和渲染方法中的缺陷，提供更高质量和实时速度的方法。</li>
<li>methods: 我们提出了一种基于显式3D高斯函数的弹性3D高斯拼接法，通过对可见空间中的高斯函数进行扭曲学习，来模型单目动态场景。我们还提出了一种缓解训练过程中偏差pose的技术，以提高时间 interpolate任务的平滑性。</li>
<li>results: 我们的方法在渲染质量和实时速度两个方面具有显著优势，与现有方法相比显著提高了渲染质量和速度。这使得我们的方法适用于多视图合成、时间合成和实时渲染等任务。<details>
<summary>Abstract</summary>
Implicit neural representation has opened up new avenues for dynamic scene reconstruction and rendering. Nonetheless, state-of-the-art methods of dynamic neural rendering rely heavily on these implicit representations, which frequently struggle with accurately capturing the intricate details of objects in the scene. Furthermore, implicit methods struggle to achieve real-time rendering in general dynamic scenes, limiting their use in a wide range of tasks. To address the issues, we propose a deformable 3D Gaussians Splatting method that reconstructs scenes using explicit 3D Gaussians and learns Gaussians in canonical space with a deformation field to model monocular dynamic scenes. We also introduced a smoothing training mechanism with no extra overhead to mitigate the impact of inaccurate poses in real datasets on the smoothness of time interpolation tasks. Through differential gaussian rasterization, the deformable 3D Gaussians not only achieve higher rendering quality but also real-time rendering speed. Experiments show that our method outperforms existing methods significantly in terms of both rendering quality and speed, making it well-suited for tasks such as novel-view synthesis, time synthesis, and real-time rendering.
</details>
<details>
<summary>摘要</summary>
匿名神经表示法已经开启了新的动态场景重建和渲染领域。然而，现状的动态神经渲染方法通常依赖于这些匿名表示法，它们经常快速捕捉场景中对象的细节。此外，匿名方法在普通的动态场景中实时渲染通常困难，限制了它们在各种任务中的使用。为了解决这些问题，我们提出了使用可变的3DGAUSSIAN分辨率拼接法来重建场景，这种方法使用显式的3DGAUSSIAN和 canonical space中的扭曲场来模型单目动态场景。我们还提出了一种缓和训练机制，可以在真实数据集中减少不准确的姿势的影响，以提高时间插值任务的平滑性。通过差分 Gaussian 渲染，可变的3DGAUSSIAN不仅实现了更高的渲染质量，还具有实时渲染速度。实验表明，我们的方法与现有方法相比，在渲染质量和速度两个方面具有显著的优势，适用于如新视角合成、时间插值和实时渲染等任务。
</details></li>
</ul>
<hr>
<h2 id="On-Data-Fabrication-in-Collaborative-Vehicular-Perception-Attacks-and-Countermeasures"><a href="#On-Data-Fabrication-in-Collaborative-Vehicular-Perception-Attacks-and-Countermeasures" class="headerlink" title="On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures"></a>On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12955">http://arxiv.org/abs/2309.12955</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zqzqz/advcollaborativeperception">https://github.com/zqzqz/advcollaborativeperception</a></li>
<li>paper_authors: Qingzhao Zhang, Shuowei Jin, Ruiyang Zhu, Jiachen Sun, Xumiao Zhang, Qi Alfred Chen, Z. Morley Mao</li>
<li>for: 这篇论文旨在探讨Connected and Autonomous Vehicles (CAVs) 在协同感知系统中的安全隐患，以及如何通过协同感知系统中的数据来实现安全驱动。</li>
<li>methods: 本论文使用了现场实验和仿真方法来研究协同感知系统中的数据攻击和防御策略。</li>
<li>results: 本论文的实验结果显示，攻击者可以通过提供假数据来让CAVs做出错误的驾驶决策，导致减速或增加碰撞风险。而提出的异常检测方法可以检测91.5%的攻击，并在实际场景中减少了攻击的影响。<details>
<summary>Abstract</summary>
Collaborative perception, which greatly enhances the sensing capability of connected and autonomous vehicles (CAVs) by incorporating data from external resources, also brings forth potential security risks. CAVs' driving decisions rely on remote untrusted data, making them susceptible to attacks carried out by malicious participants in the collaborative perception system. However, security analysis and countermeasures for such threats are absent. To understand the impact of the vulnerability, we break the ground by proposing various real-time data fabrication attacks in which the attacker delivers crafted malicious data to victims in order to perturb their perception results, leading to hard brakes or increased collision risks. Our attacks demonstrate a high success rate of over 86% on high-fidelity simulated scenarios and are realizable in real-world experiments. To mitigate the vulnerability, we present a systematic anomaly detection approach that enables benign vehicles to jointly reveal malicious fabrication. It detects 91.5% of attacks with a false positive rate of 3% in simulated scenarios and significantly mitigates attack impacts in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
将文本翻译成简化中文：协同感知，它使connected and autonomous vehicles (CAVs) 的感知能力得到了大幅提高，但也涉及到了安全隐患。CAVs 的驾驶决策取决于外部不可靠数据，使其易受到来自collaborative perception系统中的恶意参与者的攻击。然而，对于这些威胁的安全分析和对策缺乏。为了了解攻击的影响，我们开辟了一个研究，在协同感知系统中提出了不同的实时数据造假攻击。攻击者通过向受害者传递预制作的假数据来干扰受害者的感知结果，导致停车或增加碰撞风险。我们的攻击得到了高于86%的成功率在高精度的模拟场景中，并在实际场景中也是可行的。为了缓解攻击，我们提出了一种系统化异常检测方法，它能够在benign vehicles之间共同披露恶意fabrication。它在模拟场景中检测到91.5%的攻击， false positive率仅3%。在实际场景中，它能够有效地缓解攻击的影响。
</details></li>
</ul>
<hr>
<h2 id="Inter-vendor-harmonization-of-Computed-Tomography-CT-reconstruction-kernels-using-unpaired-image-translation"><a href="#Inter-vendor-harmonization-of-Computed-Tomography-CT-reconstruction-kernels-using-unpaired-image-translation" class="headerlink" title="Inter-vendor harmonization of Computed Tomography (CT) reconstruction kernels using unpaired image translation"></a>Inter-vendor harmonization of Computed Tomography (CT) reconstruction kernels using unpaired image translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12953">http://arxiv.org/abs/2309.12953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aravind R. Krishnan, Kaiwen Xu, Thomas Li, Chenyu Gao, Lucas W. Remedios, Praitayini Kanakaraj, Ho Hin Lee, Shunxing Bao, Kim L. Sandler, Fabien Maldonado, Ivana Isgum, Bennett A. Landman</li>
<li>for: This paper aims to investigate the harmonization of computed tomography (CT) scans from different manufacturers using an unpaired image translation approach.</li>
<li>methods: The authors use a multipath cycle generative adversarial network (GAN) to harmonize the CT scans and evaluate the effect of harmonization on the reconstruction kernels.</li>
<li>results: The authors find that their approach minimizes differences in emphysema measurement and highlights the impact of age, sex, smoking status, and vendor on emphysema quantification.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是通过不同生产厂商的计算Tomography（CT）扫描图像的不同构成器进行协调。</li>
<li>methods: 作者使用了一种多路径循环生成算法网络（GAN）来协调CT扫描图像，并评估构成器的影响。</li>
<li>results: 作者发现，他们的方法可以减少不同构成器的差异，并且高亮年龄、性别、吸烟状况和生产厂商对emphysema量化的影响。<details>
<summary>Abstract</summary>
The reconstruction kernel in computed tomography (CT) generation determines the texture of the image. Consistency in reconstruction kernels is important as the underlying CT texture can impact measurements during quantitative image analysis. Harmonization (i.e., kernel conversion) minimizes differences in measurements due to inconsistent reconstruction kernels. Existing methods investigate harmonization of CT scans in single or multiple manufacturers. However, these methods require paired scans of hard and soft reconstruction kernels that are spatially and anatomically aligned. Additionally, a large number of models need to be trained across different kernel pairs within manufacturers. In this study, we adopt an unpaired image translation approach to investigate harmonization between and across reconstruction kernels from different manufacturers by constructing a multipath cycle generative adversarial network (GAN). We use hard and soft reconstruction kernels from the Siemens and GE vendors from the National Lung Screening Trial dataset. We use 50 scans from each reconstruction kernel and train a multipath cycle GAN. To evaluate the effect of harmonization on the reconstruction kernels, we harmonize 50 scans each from Siemens hard kernel, GE soft kernel and GE hard kernel to a reference Siemens soft kernel (B30f) and evaluate percent emphysema. We fit a linear model by considering the age, smoking status, sex and vendor and perform an analysis of variance (ANOVA) on the emphysema scores. Our approach minimizes differences in emphysema measurement and highlights the impact of age, sex, smoking status and vendor on emphysema quantification.
</details>
<details>
<summary>摘要</summary>
computed tomography（CT）生成中的重建核心（kernel）会决定图像的文字。保持重建核心的一致性非常重要，因为下面的CT文字可能会影响量化图像分析中的测量结果。为了解决这个问题，我们采用了一种不带对的图像翻译方法，并使用多条路径生成反向传播神经网络（GAN）来调整不同制造商的重建核心。我们使用来自SIEMENS和GE两家公司的硬件和软件重建核心，从国家肺癌检测试验数据集中选择50个扫描。我们使用50个扫描来训练多条路径GAN，并对每个重建核心进行调整。为了评估调整后的重建核心的影响，我们对SIEMENS硬件重建核心、GE软件重建核心和GE硬件重建核心进行调整，并对每个扫描进行50次评估。我们使用年龄、吸烟状况、性别和制造商作为 Linear 模型的可变量，并对抑瘤率进行分析变异（ANOVA）。我们的方法可以减少不同重建核心之间的差异，并高亮制造商、性别、吸烟状况和年龄对抑瘤率的影响。
</details></li>
</ul>
<hr>
<h2 id="Background-Activation-Suppression-for-Weakly-Supervised-Object-Localization-and-Semantic-Segmentation"><a href="#Background-Activation-Suppression-for-Weakly-Supervised-Object-Localization-and-Semantic-Segmentation" class="headerlink" title="Background Activation Suppression for Weakly Supervised Object Localization and Semantic Segmentation"></a>Background Activation Suppression for Weakly Supervised Object Localization and Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12943">http://arxiv.org/abs/2309.12943</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wpy1999/bas-extension">https://github.com/wpy1999/bas-extension</a></li>
<li>paper_authors: Wei Zhai, Pingyu Wu, Kai Zhu, Yang Cao, Feng Wu, Zheng-Jun Zha</li>
<li>For: 本研究旨在提高弱度指导对象本地化和 semantic segmentation的性能，通过生成foreground prediction map（FPM）来实现像素级本地化。* Methods: 该研究提出了两个关键的实验观察：1）当已经训练过的网络中的foreground mask扩展时，cross-entropy会 converge to zero，而且activation value会持续增加 until the foreground mask扩展到对象边界。基于这两个观察，该研究提出了一种Background Activation Suppression（BAS）方法，通过Activation Map Constraint（AMC）模块来减少背景活动值，同时通过foreground region guidance和面积约束来学习整个对象区域。* Results: 对CUB-200-2011和ILSVRC dataset进行了广泛的实验，显示BAS可以 achieve significant and consistent improvement over baseline methods。此外，该方法还 achieve state-of-the-art weakly supervised semantic segmentation性能在PASCAL VOC 2012和MS COCO 2014 dataset上。<details>
<summary>Abstract</summary>
Weakly supervised object localization and semantic segmentation aim to localize objects using only image-level labels. Recently, a new paradigm has emerged by generating a foreground prediction map (FPM) to achieve pixel-level localization. While existing FPM-based methods use cross-entropy to evaluate the foreground prediction map and to guide the learning of the generator, this paper presents two astonishing experimental observations on the object localization learning process: For a trained network, as the foreground mask expands, 1) the cross-entropy converges to zero when the foreground mask covers only part of the object region. 2) The activation value continuously increases until the foreground mask expands to the object boundary. Therefore, to achieve a more effective localization performance, we argue for the usage of activation value to learn more object regions. In this paper, we propose a Background Activation Suppression (BAS) method. Specifically, an Activation Map Constraint (AMC) module is designed to facilitate the learning of generator by suppressing the background activation value. Meanwhile, by using foreground region guidance and area constraint, BAS can learn the whole region of the object. In the inference phase, we consider the prediction maps of different categories together to obtain the final localization results. Extensive experiments show that BAS achieves significant and consistent improvement over the baseline methods on the CUB-200-2011 and ILSVRC datasets. In addition, our method also achieves state-of-the-art weakly supervised semantic segmentation performance on the PASCAL VOC 2012 and MS COCO 2014 datasets. Code and models are available at https://github.com/wpy1999/BAS-Extension.
</details>
<details>
<summary>摘要</summary>
弱地监督对象定位和 semantic segmentation 目标是通过只使用图像级别标签来 lokalisieren objects。 最近，一种新的 paradigm 出现，即通过生成 foreground prediction map (FPM) 来实现像素级定位。 而现有的 FPM 基于方法使用 cross-entropy 来评估 foreground prediction map 并帮助生成器学习，而这篇文章则发现了对对象定位学习过程的两个 astonishing experimental observation：1) 当 foreground mask 扩展时，cross-entropy 会 converge to zero 只有部分object region 被 mask 覆盖; 2) 在 foreground mask 扩展到 object boundary 时，activation value 会不断增加。因此，我们认为使用 activation value 可以更好地学习更多的 object regions。在这篇文章中，我们提出了 Background Activation Suppression (BAS) 方法。具体来说，我们设计了 Activation Map Constraint (AMC) 模块，以便通过压制背景 activation value 来促进生成器的学习。同时，通过使用 foreground region guidance 和 area constraint，BAS 可以学习整个 object 的区域。在推理阶段，我们考虑了不同类别的预测图共同来获得最终的定位结果。我们的实验表明，BAS 可以在 CUB-200-2011 和 ILSVRC 数据集上 achieves 显著和稳定的改进，并且我们的方法也可以在 PASCAL VOC 2012 和 MS COCO 2014 数据集上实现 state-of-the-art 的弱监督 semantic segmentation性能。代码和模型可以在 <https://github.com/wpy1999/BAS-Extension> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Object-Counting-with-Language-Vision-Models"><a href="#Zero-Shot-Object-Counting-with-Language-Vision-Models" class="headerlink" title="Zero-Shot Object Counting with Language-Vision Models"></a>Zero-Shot Object Counting with Language-Vision Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13097">http://arxiv.org/abs/2309.13097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Xu, Hieu Le, Dimitris Samaras</li>
<li>for: 本研究旨在实现无需人工标注的物体数量计算，即针对任意类型的物体进行测试时的自动化计数。</li>
<li>methods: 我们提出了一种新的设定方法，即零例SHOT对象计数（ZSC），只需要在测试时提供类名即可。这种方法不需要人工标注，可以自动化操作。我们首先从输入图像中检索一些物体裁剪，然后使用这些裁剪作为计数例子。目标是找到包含目标物体的裁剪，同时也是所有图像中所有物体的视觉表示。我们首先使用大型语言视觉模型，包括CLIP和Stable Diffusion，构建类型质量标准，然后选择包含目标物体的裁剪。此外，我们还提出了一种排名模型，以估算每个裁剪的计数错误，从而选择最适合计数的例子。</li>
<li>results: 我们在最新的无类别物体数量 datasets（FSC-147）上进行了实验，结果表明我们的方法效果很高。<details>
<summary>Abstract</summary>
Class-agnostic object counting aims to count object instances of an arbitrary class at test time. It is challenging but also enables many potential applications. Current methods require human-annotated exemplars as inputs which are often unavailable for novel categories, especially for autonomous systems. Thus, we propose zero-shot object counting (ZSC), a new setting where only the class name is available during test time. This obviates the need for human annotators and enables automated operation. To perform ZSC, we propose finding a few object crops from the input image and use them as counting exemplars. The goal is to identify patches containing the objects of interest while also being visually representative for all instances in the image. To do this, we first construct class prototypes using large language-vision models, including CLIP and Stable Diffusion, to select the patches containing the target objects. Furthermore, we propose a ranking model that estimates the counting error of each patch to select the most suitable exemplars for counting. Experimental results on a recent class-agnostic counting dataset, FSC-147, validate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
“类型无关对象计数”targets counting object instances of an arbitrary class at test time, which is challenging but also enables many potential applications. Current methods require human-annotated exemplars as inputs, which are often unavailable for novel categories, especially for autonomous systems. Therefore, we propose zero-shot object counting (ZSC), a new setting where only the class name is available during test time. This eliminates the need for human annotators and enables automated operation.To perform ZSC, we propose finding a few object crops from the input image and using them as counting exemplars. The goal is to identify patches containing the objects of interest while also being visually representative for all instances in the image. To do this, we first construct class prototypes using large language-vision models, such as CLIP and Stable Diffusion, to select the patches containing the target objects. Additionally, we propose a ranking model that estimates the counting error of each patch to select the most suitable exemplars for counting.Experimental results on a recent class-agnostic counting dataset, FSC-147, validate the effectiveness of our method.
</details></li>
</ul>
<hr>
<h2 id="Bridging-Sensor-Gaps-via-Single-Direction-Tuning-for-Hyperspectral-Image-Classification"><a href="#Bridging-Sensor-Gaps-via-Single-Direction-Tuning-for-Hyperspectral-Image-Classification" class="headerlink" title="Bridging Sensor Gaps via Single-Direction Tuning for Hyperspectral Image Classification"></a>Bridging Sensor Gaps via Single-Direction Tuning for Hyperspectral Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12865">http://arxiv.org/abs/2309.12865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cecilia-xue/hyt-nas">https://github.com/cecilia-xue/hyt-nas</a></li>
<li>paper_authors: Xizhe Xue, Haokui Zhang, Ying Li, Liuwei Wan, Zongwen Bai, Mike Zheng Shou</li>
<li>for:  This paper aims to address the challenge of training ViT models on hyperspectral images (HSIs) with limited training samples.</li>
<li>methods: The proposed method is called single-direction tuning (SDT) and it leverages existing labeled HSI datasets and RGB datasets to enhance the performance on new HSI datasets. SDT uses a parallel architecture, asynchronous cold-hot gradient update strategy, and unidirectional interaction.</li>
<li>results: The proposed Triplet-structured transformer (Tri-Former) achieves better performance compared to several state-of-the-art methods on three representative HSI datasets. Homologous, heterologous and cross-modal tuning experiments verified the effectiveness of the proposed SDT.Here’s the Chinese translation of the three key points:</li>
<li>for: 本研究目的是解决训练 ViT 模型在有限样本的高spectral 图像（HSIs）中的挑战。</li>
<li>methods: 提议的方法是单向调整策略（SDT），它利用现有标注的 HSI 数据集和 RGB 数据集来提高新的 HSI 数据集的性能。SDT 使用并行架构、异步冷热梯度更新策略和单向互动。</li>
<li>results: 提议的 Triplet-structured transformer (Tri-Former) 在三个代表性的 HSI 数据集上达到了许多现状方法的更好性能。同源、异源和跨模态调整实验证明了提议的 SDT 的有效性。<details>
<summary>Abstract</summary>
Recently, some researchers started exploring the use of ViTs in tackling HSI classification and achieved remarkable results. However, the training of ViT models requires a considerable number of training samples, while hyperspectral data, due to its high annotation costs, typically has a relatively small number of training samples. This contradiction has not been effectively addressed. In this paper, aiming to solve this problem, we propose the single-direction tuning (SDT) strategy, which serves as a bridge, allowing us to leverage existing labeled HSI datasets even RGB datasets to enhance the performance on new HSI datasets with limited samples. The proposed SDT inherits the idea of prompt tuning, aiming to reuse pre-trained models with minimal modifications for adaptation to new tasks. But unlike prompt tuning, SDT is custom-designed to accommodate the characteristics of HSIs. The proposed SDT utilizes a parallel architecture, an asynchronous cold-hot gradient update strategy, and unidirectional interaction. It aims to fully harness the potent representation learning capabilities derived from training on heterologous, even cross-modal datasets. In addition, we also introduce a novel Triplet-structured transformer (Tri-Former), where spectral attention and spatial attention modules are merged in parallel to construct the token mixing component for reducing computation cost and a 3D convolution-based channel mixer module is integrated to enhance stability and keep structure information. Comparison experiments conducted on three representative HSI datasets captured by different sensors demonstrate the proposed Tri-Former achieves better performance compared to several state-of-the-art methods. Homologous, heterologous and cross-modal tuning experiments verified the effectiveness of the proposed SDT.
</details>
<details>
<summary>摘要</summary>
近些时候，一些研究人员开始使用ViT来解决高spectralInterval（HSI）分类问题，并取得了显著的成果。然而，ViT模型的训练需要一大量的训练样本，而高spectralInterval数据由于注解成本高，通常只有限量的训练样本。这个矛盾尚未得到有效解决。在这篇论文中，我们提议单向调整（SDT）策略，作为一个桥梁，允许我们通过现有的标注HSI数据集和RGB数据集来提高新的HSI数据集的性能。我们的SDT继承了提前调整的想法，即 reuse pre-trained models with minimal modifications for adaptation to new tasks。不同于提前调整，SDT是特地针对HSIs的定制设计的。我们的SDT采用并行架构、异步冷热Gradient更新策略和单向交互。它旨在完全利用训练在不同数据集上的hetrologous和cross-modal数据的强大表示学习能力。此外，我们还介绍了一种新的Triplet-structured transformer（Tri-Former），其中spectral attention和spatial attention模块在并行的构建token混合组件，以减少计算成本，并integrate了3D卷积基本 Channel mixer模块以提高稳定性和保持结构信息。在三个代表性的HSI数据集上进行了比较实验，我们的Tri-Former表现比一些当前的方法更好。同义、异义和cross-modal调整实验证明了SDT的有效性。
</details></li>
</ul>
<hr>
<h2 id="Associative-Transformer-Is-A-Sparse-Representation-Learner"><a href="#Associative-Transformer-Is-A-Sparse-Representation-Learner" class="headerlink" title="Associative Transformer Is A Sparse Representation Learner"></a>Associative Transformer Is A Sparse Representation Learner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12862">http://arxiv.org/abs/2309.12862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuwei Sun, Hideya Ochiai, Zhirong Wu, Stephen Lin, Ryota Kanai</li>
<li>for: 这篇论文旨在探讨如何使用弹性交互来更好地模拟生物学原理，并提出了一种基于全球工作空间理论和相关记忆的Associative Transformer（AiT）模型。</li>
<li>methods: AiT模型使用了跨层聚合的核心空间，并通过结合缓存的方式实现瓶颈式注意力。这些瓶颈式注意力会限制注意力的容量，从而模拟生物学中的弹性交互。</li>
<li>results: 对于多种视觉任务，AiT模型表现出了superiority，可以学习不同的特征弹性，并且可以在不同的输入量和维度上保持复杂度的不变性。<details>
<summary>Abstract</summary>
Emerging from the monolithic pairwise attention mechanism in conventional Transformer models, there is a growing interest in leveraging sparse interactions that align more closely with biological principles. Approaches including the Set Transformer and the Perceiver employ cross-attention consolidated with a latent space that forms an attention bottleneck with limited capacity. Building upon recent neuroscience studies of Global Workspace Theory and associative memory, we propose the Associative Transformer (AiT). AiT induces low-rank explicit memory that serves as both priors to guide bottleneck attention in the shared workspace and attractors within associative memory of a Hopfield network. Through joint end-to-end training, these priors naturally develop module specialization, each contributing a distinct inductive bias to form attention bottlenecks. A bottleneck can foster competition among inputs for writing information into the memory. We show that AiT is a sparse representation learner, learning distinct priors through the bottlenecks that are complexity-invariant to input quantities and dimensions. AiT demonstrates its superiority over methods such as the Set Transformer, Vision Transformer, and Coordination in various vision tasks.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)由传统的对称Transformer模型中的单一对对注意机制而出发，有一种增长的兴趣是利用稀疏的交互来更加准确地遵循生物学原理。包括Set Transformer和Perceiver在内的方法都使用了混合注意力，并通过限制容量的瓶颈注意力来实现稀疏的交互。基于最近的 neuroscience研究的全球工作区理论和相关记忆，我们提出了相关转换器（AiT）。AiT通过强制实现低级别的显式记忆，使得瓶颈注意力在共享工作区中服务为导向注意力的先验知识，并在相关记忆中形成吸引器。通过联合的终端训练，这些先验知识自然发展出模块特化，每个模块增加了不同的抽象偏好，以形成注意瓶颈。这个瓶颈可以促进输入竞争对写入记忆。我们显示AiT是一种稀疏表示学习器，通过瓶颈学习出不同的先验知识，这些先验知识是输入量和维度的复杂性不变的。AiT在不同的视觉任务中表现出优势。
</details></li>
</ul>
<hr>
<h2 id="Cross-Modal-Translation-and-Alignment-for-Survival-Analysis"><a href="#Cross-Modal-Translation-and-Alignment-for-Survival-Analysis" class="headerlink" title="Cross-Modal Translation and Alignment for Survival Analysis"></a>Cross-Modal Translation and Alignment for Survival Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12855">http://arxiv.org/abs/2309.12855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ft-zhou-zzz/cmta">https://github.com/ft-zhou-zzz/cmta</a></li>
<li>paper_authors: Fengtao Zhou, Hao Chen</li>
<li>for: 这篇论文的目的是提出一个 Cross-Modal Translation and Alignment (CMTA) 框架，以探索不同模式之间的自然联系，并将不同模式之间的资讯转换为彼此对应的形式，以提高统计分析的精度和准确性。</li>
<li>methods: 这篇论文使用了两个平行的encoder-decoder结构，将多modal资料融合为单一的数据表现，并通过将生成的跨模式表现与原始模式表现进行对应，以提高模式之间的联系和转换资讯。此外，这篇论文还提出了一个跨模式注意力模组，作为不同模式之间的资讯桥梁，以实现跨模式的互动和资讯转换。</li>
<li>results: 这篇论文的实验结果显示，跨模式转换和对应的CMTA框架能够在五个公共TCGA数据集上实现更高的统计分析精度和准确性，比起现有的方法。<details>
<summary>Abstract</summary>
With the rapid advances in high-throughput sequencing technologies, the focus of survival analysis has shifted from examining clinical indicators to incorporating genomic profiles with pathological images. However, existing methods either directly adopt a straightforward fusion of pathological features and genomic profiles for survival prediction, or take genomic profiles as guidance to integrate the features of pathological images. The former would overlook intrinsic cross-modal correlations. The latter would discard pathological information irrelevant to gene expression. To address these issues, we present a Cross-Modal Translation and Alignment (CMTA) framework to explore the intrinsic cross-modal correlations and transfer potential complementary information. Specifically, we construct two parallel encoder-decoder structures for multi-modal data to integrate intra-modal information and generate cross-modal representation. Taking the generated cross-modal representation to enhance and recalibrate intra-modal representation can significantly improve its discrimination for comprehensive survival analysis. To explore the intrinsic crossmodal correlations, we further design a cross-modal attention module as the information bridge between different modalities to perform cross-modal interactions and transfer complementary information. Our extensive experiments on five public TCGA datasets demonstrate that our proposed framework outperforms the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
随着高通量测序技术的快速发展，生存分析的注意点从临床指标转移到了将 genomic  profil 与生理图像 incorporate 到生存预测中。现有方法可以分为两类：直接将生理特征和 genomic profil 简单地拼接起来进行生存预测，或者将 genomic profil 作为引导，将生理图像的特征 integrate 到生存预测中。前者可能会忽略不同Modal 之间的自然相关性。后者可能会丢弃不相关于蛋白表达的生理信息。为解决这些问题，我们提出了一种 Cross-Modal Translation and Alignment (CMTA) 框架，用于探索不同Modal 之间的自然相关性，并将 complementary 信息传递。 Specifically, we construct two parallel encoder-decoder structures for multi-modal data to integrate intra-modal information and generate cross-modal representation. Taking the generated cross-modal representation to enhance and recalibrate intra-modal representation can significantly improve its discrimination for comprehensive survival analysis. To explore the intrinsic crossmodal correlations, we further design a cross-modal attention module as the information bridge between different modalities to perform cross-modal interactions and transfer complementary information. Our extensive experiments on five public TCGA datasets demonstrate that our proposed framework outperforms the state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="SRFNet-Monocular-Depth-Estimation-with-Fine-grained-Structure-via-Spatial-Reliability-oriented-Fusion-of-Frames-and-Events"><a href="#SRFNet-Monocular-Depth-Estimation-with-Fine-grained-Structure-via-Spatial-Reliability-oriented-Fusion-of-Frames-and-Events" class="headerlink" title="SRFNet: Monocular Depth Estimation with Fine-grained Structure via Spatial Reliability-oriented Fusion of Frames and Events"></a>SRFNet: Monocular Depth Estimation with Fine-grained Structure via Spatial Reliability-oriented Fusion of Frames and Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12842">http://arxiv.org/abs/2309.12842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Tianbo-Pan/SRFNet">https://github.com/Tianbo-Pan/SRFNet</a></li>
<li>paper_authors: Tianbo Pan, Zidong Cao, Lin Wang</li>
<li>for: 本研究旨在提高单目视频中的深度估计精度，以便应用于机器人导航和自动驾驶等场景。</li>
<li>methods: 本研究提出了一种名为SRFNet的新网络模型，包括两个关键技术组件：一是基于注意力的互动式融合模块（AIF），二是可靠性 oriented 深度修正模块（RDR）。AIF模块使用事件和帧的空间偏好作为初始 máscara 来引导多模态特征融合，并通过反馈增强帧和事件特征学习。RDR模块使用融合的特征和 máscara 来估计精度高的深度结构。</li>
<li>results: 本研究在 synthetic 和实际世界数据集上评估了SRFNet的效果，结果显示，无需预训练，SRFNet可以在夜景中比 Priors 等方法更高的性能。<details>
<summary>Abstract</summary>
Monocular depth estimation is a crucial task to measure distance relative to a camera, which is important for applications, such as robot navigation and self-driving. Traditional frame-based methods suffer from performance drops due to the limited dynamic range and motion blur. Therefore, recent works leverage novel event cameras to complement or guide the frame modality via frame-event feature fusion. However, event streams exhibit spatial sparsity, leaving some areas unperceived, especially in regions with marginal light changes. Therefore, direct fusion methods, e.g., RAMNet, often ignore the contribution of the most confident regions of each modality. This leads to structural ambiguity in the modality fusion process, thus degrading the depth estimation performance. In this paper, we propose a novel Spatial Reliability-oriented Fusion Network (SRFNet), that can estimate depth with fine-grained structure at both daytime and nighttime. Our method consists of two key technical components. Firstly, we propose an attention-based interactive fusion (AIF) module that applies spatial priors of events and frames as the initial masks and learns the consensus regions to guide the inter-modal feature fusion. The fused feature are then fed back to enhance the frame and event feature learning. Meanwhile, it utilizes an output head to generate a fused mask, which is iteratively updated for learning consensual spatial priors. Secondly, we propose the Reliability-oriented Depth Refinement (RDR) module to estimate dense depth with the fine-grained structure based on the fused features and masks. We evaluate the effectiveness of our method on the synthetic and real-world datasets, which shows that, even without pretraining, our method outperforms the prior methods, e.g., RAMNet, especially in night scenes. Our project homepage: https://vlislab22.github.io/SRFNet.
</details>
<details>
<summary>摘要</summary>
单目深度估计是一个重要的任务，用于测量相机附近的距离，这对于自动驾驶和机器人定位等应用非常重要。传统的帧基本方法受限于对应数范围和运动模糊的问题，因此latest works将event camera整合或导引帧模式的特性。然而，event流拥有空间罕见性，特别是在光度变化较小的区域，导致direct fusion方法，例如RAMNet，忽略了每个模式的最有信心区域的贡献。这会导致多模式融合过程中的结构混乱，进而下降深度估计性能。在这篇论文中，我们提出了一个名为Spatial Reliability-oriented Fusion Network（SRFNet）的新方法，可以在日间和夜间都 estimate fine-grained的深度结构。我们的方法包括两个关键技术部分。首先，我们提出了一个注意力基于的互动式融合（AIF）模组，它根据事件和帧的空间假设作为初始mask，并学习导引多modal feature融合的共识区域。融合后的特征被反馈以提高帧和事件特征学习。同时，它还使用一个output head生成融合mask，并轮询更新以学习共识的空间假设。其次，我们提出了可靠性对适定深度修正（RDR）模组，用于根据融合特征和mask估计精确的深度结构。我们将这个方法评估在实验和真实世界数据上，结果显示，不需要预训，我们的方法在夜间场景中表现更好，比如RAMNet等先前的方法。更多详细信息可以通过我们的项目首页：<https://vlislab22.github.io/SRFNet>。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptive-Few-Shot-Open-Set-Learning"><a href="#Domain-Adaptive-Few-Shot-Open-Set-Learning" class="headerlink" title="Domain Adaptive Few-Shot Open-Set Learning"></a>Domain Adaptive Few-Shot Open-Set Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12814">http://arxiv.org/abs/2309.12814</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/debabratapal7/dafosnet">https://github.com/debabratapal7/dafosnet</a></li>
<li>paper_authors: Debabrata Pal, Deeptej More, Sai Bhargav, Dipesh Tamboli, Vaneet Aggarwal, Biplab Banerjee</li>
<li>for: 解决目标查询集中未知样本和Visual shift问题，同时可以快速适应新场景。</li>
<li>methods: 提出了一种新的方法called Domain Adaptive Few-Shot Open Set Recognition (DA-FSOS)，并使用了一种名为DAFOSNET的meta-learning-based架构。在训练过程中，模型学习了共享和特异 embedding space，并创建了一个pseudo open-space决策边界。</li>
<li>results: 通过使用一对 conditional adversarial networks和domain-specific batch-normalized class prototypes alignment strategy，模型能够快速适应新场景并提高数据密度。<details>
<summary>Abstract</summary>
Few-shot learning has made impressive strides in addressing the crucial challenges of recognizing unknown samples from novel classes in target query sets and managing visual shifts between domains. However, existing techniques fall short when it comes to identifying target outliers under domain shifts by learning to reject pseudo-outliers from the source domain, resulting in an incomplete solution to both problems. To address these challenges comprehensively, we propose a novel approach called Domain Adaptive Few-Shot Open Set Recognition (DA-FSOS) and introduce a meta-learning-based architecture named DAFOSNET. During training, our model learns a shared and discriminative embedding space while creating a pseudo open-space decision boundary, given a fully-supervised source domain and a label-disjoint few-shot target domain. To enhance data density, we use a pair of conditional adversarial networks with tunable noise variances to augment both domains closed and pseudo-open spaces. Furthermore, we propose a domain-specific batch-normalized class prototypes alignment strategy to align both domains globally while ensuring class-discriminativeness through novel metric objectives. Our training approach ensures that DAFOS-NET can generalize well to new scenarios in the target domain. We present three benchmarks for DA-FSOS based on the Office-Home, mini-ImageNet/CUB, and DomainNet datasets and demonstrate the efficacy of DAFOS-NET through extensive experimentation
</details>
<details>
<summary>摘要</summary>
几个步学习已经在面临未知样本从新类目标查询集中识别难题和处理视觉变化 между领域方面做出了很好的进展。然而，现有技术在确定目标异常点下存在缺陷，即通过学习源领域中的 pseudo-outlier 来拒绝，导致解决这两个问题的答案不完整。为了全面解决这些挑战，我们提出了一种新的方法calledDomain Adaptive Few-Shot Open Set Recognition（DA-FSOS），并介绍了一种基于meta-学习的架构 named DAFOSNET。在训练过程中，我们的模型学习了共享和特异的嵌入空间，同时创建了一个 Pseudo open-space 决策边界，使用完全supervised的源领域和一个标签分离的少量目标领域。为了增强数据密度，我们使用了一对 conditional adversarial networks  WITH tunable noise variances 来扩展两个领域的closed和pseudo-open空间。此外，我们提出了一种适应域特化的batch normalized class prototypes alignment策略，用于对两个领域进行全球协调，并确保类别特异性通过新的度量目标。我们的训练方法确保了 DAFOS-NET 在新enario中能够通过��������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������
</details></li>
</ul>
<hr>
<h2 id="Automatic-view-plane-prescription-for-cardiac-magnetic-resonance-imaging-via-supervision-by-spatial-relationship-between-views"><a href="#Automatic-view-plane-prescription-for-cardiac-magnetic-resonance-imaging-via-supervision-by-spatial-relationship-between-views" class="headerlink" title="Automatic view plane prescription for cardiac magnetic resonance imaging via supervision by spatial relationship between views"></a>Automatic view plane prescription for cardiac magnetic resonance imaging via supervision by spatial relationship between views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12805">http://arxiv.org/abs/2309.12805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wd111624/cmr_plan">https://github.com/wd111624/cmr_plan</a></li>
<li>paper_authors: Dong Wei, Yawen Huang, Donghuan Lu, Yuexiang Li, Yefeng Zheng<br>for: 这种系统的目的是自动化卡路里MR图像的规划，以帮助临床实践中的医生和技术人员更加快速和准确地完成图像规划。methods: 该系统使用了深度学习网络，通过挖掘数据中的空间关系来自动地确定目标平面和源视图之间的交叉线，并通过堆栈锥体网络来逐步提高回归。此外，该系统还使用了多视图规划策略，将所有源视图中的预测热图聚合以获得全球最优的规划。results: 实验结果显示，该系统可以准确地预测四个标准的卡路里MR图像平面，并且比现有的方法更加精准，包括传统的Atlas-based和 newer deep-learning-based方法。此外，该系统还可以预测第一个Cardiac-anatomy-oriented平面（或多个平面），从body-oriented扫描中获得。<details>
<summary>Abstract</summary>
Background: View planning for the acquisition of cardiac magnetic resonance (CMR) imaging remains a demanding task in clinical practice. Purpose: Existing approaches to its automation relied either on an additional volumetric image not typically acquired in clinic routine, or on laborious manual annotations of cardiac structural landmarks. This work presents a clinic-compatible, annotation-free system for automatic CMR view planning. Methods: The system mines the spatial relationship, more specifically, locates the intersecting lines, between the target planes and source views, and trains deep networks to regress heatmaps defined by distances from the intersecting lines. The intersection lines are the prescription lines prescribed by the technologists at the time of image acquisition using cardiac landmarks, and retrospectively identified from the spatial relationship. As the spatial relationship is self-contained in properly stored data, the need for additional manual annotation is eliminated. In addition, the interplay of multiple target planes predicted in a source view is utilized in a stacked hourglass architecture to gradually improve the regression. Then, a multi-view planning strategy is proposed to aggregate information from the predicted heatmaps for all the source views of a target plane, for a globally optimal prescription, mimicking the similar strategy practiced by skilled human prescribers. Results: The experiments include 181 CMR exams. Our system yields the mean angular difference and point-to-plane distance of 5.68 degrees and 3.12 mm, respectively. It not only achieves superior accuracy to existing approaches including conventional atlas-based and newer deep-learning-based in prescribing the four standard CMR planes but also demonstrates prescription of the first cardiac-anatomy-oriented plane(s) from the body-oriented scout.
</details>
<details>
<summary>摘要</summary>
背景：卡路里变 imagine（CMR）成像取得的规划仍然是艰辛的任务在临床实践中。目的：现有的自动化方法都是基于不常见的三维图像或劳累的手动标注卡ди亚Structural landmarks。这个工作提出了一个可以在临床实践中使用的无需标注的自动CMR规划系统。方法：系统利用目标平面和源视图之间的空间关系，具体来说是找出目标平面和源视图之间的交叉点，并使用深度网络来回归定距离 définition heatmaps。交叉点是由技术人员在图像取得时使用卡ди亚Structural landmarks预scribed的规则，并在后续从空间关系中回拟。由于空间关系自身含有所需的信息，因此无需额外的手动标注。此外，系统还利用多个目标平面预测的多个源视图之间的互动，在堆栈ourglass架构中进行渐进改进。然后，提议一种多视图规划策略，将所有源视图中的预测热图集成，以实现全局优化的规划，类似于人类资深决策者的做法。结果：实验包括181个CMR试验。我们的系统的平均角度差和点到平面距离为5.68度和3.12mm。不仅达到了现有方法的精度，还可以成功地预scribed四个标准CMR平面，以及首次预scribedBody-oriented scout中的cardiac-anatomy-oriented平面。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Semantic-3D-Mapping-of-Coral-Reefs-with-Deep-Learning"><a href="#Scalable-Semantic-3D-Mapping-of-Coral-Reefs-with-Deep-Learning" class="headerlink" title="Scalable Semantic 3D Mapping of Coral Reefs with Deep Learning"></a>Scalable Semantic 3D Mapping of Coral Reefs with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12804">http://arxiv.org/abs/2309.12804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Sauder, Guilhem Banc-Prandi, Anders Meibom, Devis Tuia</li>
<li>for: This paper aims to develop a new method for mapping underwater environments from ego-motion video, with a focus on coral reef monitoring.</li>
<li>methods: The method uses machine learning to adapt to challenging underwater conditions and combines 3D mapping with semantic segmentation of images.</li>
<li>results: The method achieves high-precision 3D semantic mapping at unprecedented scale with significantly reduced labor costs, making it possible to monitor coral reefs more efficiently and effectively.Here’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文目的是开发一种基于ego-motion视频的海洋环境地图方法，主要关注珊瑚礁监测。</li>
<li>methods: 该方法使用机器学习适应海洋下难以控制的环境，并将3D地图与图像Semantic分割相结合。</li>
<li>results: 该方法实现了高精度3DSemantic地图，并在减少劳动成本方面取得了显著进步，使得珊瑚礁监测更加高效和可靠。<details>
<summary>Abstract</summary>
Coral reefs are among the most diverse ecosystems on our planet, and are depended on by hundreds of millions of people. Unfortunately, most coral reefs are existentially threatened by global climate change and local anthropogenic pressures. To better understand the dynamics underlying deterioration of reefs, monitoring at high spatial and temporal resolution is key. However, conventional monitoring methods for quantifying coral cover and species abundance are limited in scale due to the extensive manual labor required. Although computer vision tools have been employed to aid in this process, in particular SfM photogrammetry for 3D mapping and deep neural networks for image segmentation, analysis of the data products creates a bottleneck, effectively limiting their scalability. This paper presents a new paradigm for mapping underwater environments from ego-motion video, unifying 3D mapping systems that use machine learning to adapt to challenging conditions under water, combined with a modern approach for semantic segmentation of images. The method is exemplified on coral reefs in the northern Gulf of Aqaba, Red Sea, demonstrating high-precision 3D semantic mapping at unprecedented scale with significantly reduced required labor costs: a 100 m video transect acquired within 5 minutes of diving with a cheap consumer-grade camera can be fully automatically analyzed within 5 minutes. Our approach significantly scales up coral reef monitoring by taking a leap towards fully automatic analysis of video transects. The method democratizes coral reef transects by reducing the labor, equipment, logistics, and computing cost. This can help to inform conservation policies more efficiently. The underlying computational method of learning-based Structure-from-Motion has broad implications for fast low-cost mapping of underwater environments other than coral reefs.
</details>
<details>
<summary>摘要</summary>
珊瑚礁是地球上最多样化的生态系统之一，并且有百万人的生存受其影响。然而，大多数珊瑚礁面临全球气候变化和地方人类活动的威胁。为了更好地理解珊瑚礁的衰退机制，高精度空间和时间分辨率的监测是关键。although computer vision工具已经被应用于这一过程，特别是使用SfM摄ogrammetry для3D地图和深度神经网络 для图像分割，但是分析数据产品创造了瓶颈，从而限制了其扩展性。这篇文章介绍了一种新的珊瑚礁监测方法，基于自己的运动来自视频，结合机器学习来适应水下挑战的3D地图系统，并与现代图像分割方法相结合。这种方法在北红海的珊瑚礁中进行了高精度3Dsemantic地图，覆盖100米视频 transect，只需5分钟投入和分析时间。我们的方法可以快速扩大珊瑚礁监测，减少劳动、设备、运输和计算成本，从而更有效地 Inform conservation policies。我们的方法可以把珊瑚礁 transect democratized，减少劳动和设备成本，以便更多的人可以参与监测和保护。这种方法的计算方法，基于学习的Structure-from-Motion，对于快速低成本地图的水下环境的应用有广泛的应用前景。
</details></li>
</ul>
<hr>
<h2 id="NOC-High-Quality-Neural-Object-Cloning-with-3D-Lifting-of-Segment-Anything"><a href="#NOC-High-Quality-Neural-Object-Cloning-with-3D-Lifting-of-Segment-Anything" class="headerlink" title="NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything"></a>NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12790">http://arxiv.org/abs/2309.12790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobao Wei, Renrui Zhang, Jiarui Wu, Jiaming Liu, Ming Lu, Yandong Guo, Shanghang Zhang</li>
<li>for: 本研究旨在提出一种基于神经场的高品质3D对象重建方法，以便在用户指定的实时下重建目标对象。</li>
<li>methods: 本方法基于神经场和Segment Anything Model (SAM)的优点，首先将多视图2D分割Masks lifted到3D变化场中，然后将2D特征 lifted到3D SAM场中以提高重建质量。</li>
<li>results: 在多个 benchmark 数据集上进行了详细的实验，表明本方法能够提供高品质的目标对象重建结果。<details>
<summary>Abstract</summary>
With the development of the neural field, reconstructing the 3D model of a target object from multi-view inputs has recently attracted increasing attention from the community. Existing methods normally learn a neural field for the whole scene, while it is still under-explored how to reconstruct a certain object indicated by users on-the-fly. Considering the Segment Anything Model (SAM) has shown effectiveness in segmenting any 2D images, in this paper, we propose Neural Object Cloning (NOC), a novel high-quality 3D object reconstruction method, which leverages the benefits of both neural field and SAM from two aspects. Firstly, to separate the target object from the scene, we propose a novel strategy to lift the multi-view 2D segmentation masks of SAM into a unified 3D variation field. The 3D variation field is then projected into 2D space and generates the new prompts for SAM. This process is iterative until convergence to separate the target object from the scene. Then, apart from 2D masks, we further lift the 2D features of the SAM encoder into a 3D SAM field in order to improve the reconstruction quality of the target object. NOC lifts the 2D masks and features of SAM into the 3D neural field for high-quality target object reconstruction. We conduct detailed experiments on several benchmark datasets to demonstrate the advantages of our method. The code will be released.
</details>
<details>
<summary>摘要</summary>
随着神经场的发展，从多视图输入中重建目标对象的3D模型已经吸引了社区的越来越多的关注。现有方法通常学习一个整个场景的神经场，而即时根据用户指定的对象进行重建仍然是一个未探索的领域。尝试 Segment Anything Model (SAM) 可以效果地 segment any 2D 图像，在这篇论文中，我们提出了一种新的高质量3D对象重建方法——神经对象复制（NOC），该方法利用了神经场和 SAM 的优点，从两个方面进行了利用。首先，为了将目标对象从场景中分离，我们提出了一种新的策略，即将多视图2D 分割面的 SAM 编码器输出 lift 到一个统一的3D 变化场，然后将这个3D 变化场 проек 到2D 空间，生成新的提示，这个过程是迭代的，直到达到对象分离的 converges。然后，除了2D 面，我们还 lift 了 SAM 编码器的2D 特征到3D SAM 场，以提高目标对象的重建质量。NOC 将 SAM 的2D 面和特征 lift 到神经场中，以实现高质量的目标对象重建。我们对多个标准数据集进行了详细的实验，以示出我们的方法的优势。代码将会发布。
</details></li>
</ul>
<hr>
<h2 id="EMS-3D-Eyebrow-Modeling-from-Single-view-Images"><a href="#EMS-3D-Eyebrow-Modeling-from-Single-view-Images" class="headerlink" title="EMS: 3D Eyebrow Modeling from Single-view Images"></a>EMS: 3D Eyebrow Modeling from Single-view Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12787">http://arxiv.org/abs/2309.12787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghong Li, Leyang Jin, Yujian Zheng, Yizhou Yu, Xiaoguang Han</li>
<li>for: 这个论文的目的是提出一种基于学习的方法来实现单视图3D眉毛重建。</li>
<li>methods: 这个方法使用了三个模块：RootFinder、OriPredictor和FiberEnder。RootFinder用于Localizing fiber root positions，OriPredictor用于预测3D空间中的方向场，FiberEnder用于确定每个纤维的长度。</li>
<li>results: 该方法在不同的眉毛样式和长度上表现了效果，并且可以处理部分受阻的根位置问题。<details>
<summary>Abstract</summary>
Eyebrows play a critical role in facial expression and appearance. Although the 3D digitization of faces is well explored, less attention has been drawn to 3D eyebrow modeling. In this work, we propose EMS, the first learning-based framework for single-view 3D eyebrow reconstruction. Following the methods of scalp hair reconstruction, we also represent the eyebrow as a set of fiber curves and convert the reconstruction to fibers growing problem. Three modules are then carefully designed: RootFinder firstly localizes the fiber root positions which indicates where to grow; OriPredictor predicts an orientation field in the 3D space to guide the growing of fibers; FiberEnder is designed to determine when to stop the growth of each fiber. Our OriPredictor is directly borrowing the method used in hair reconstruction. Considering the differences between hair and eyebrows, both RootFinder and FiberEnder are newly proposed. Specifically, to cope with the challenge that the root location is severely occluded, we formulate root localization as a density map estimation task. Given the predicted density map, a density-based clustering method is further used for finding the roots. For each fiber, the growth starts from the root point and moves step by step until the ending, where each step is defined as an oriented line with a constant length according to the predicted orientation field. To determine when to end, a pixel-aligned RNN architecture is designed to form a binary classifier, which outputs stop or not for each growing step. To support the training of all proposed networks, we build the first 3D synthetic eyebrow dataset that contains 400 high-quality eyebrow models manually created by artists. Extensive experiments have demonstrated the effectiveness of the proposed EMS pipeline on a variety of different eyebrow styles and lengths, ranging from short and sparse to long bushy eyebrows.
</details>
<details>
<summary>摘要</summary>
眉毛在面部表情和外貌中扮演了关键角色，尽管3D人脸数字化已得到了广泛的研究，但3D眉毛模型化却受到了较少的关注。在这项工作中，我们提出了EMS框架，是首个基于学习的单视角3D眉毛重建框架。我们将眉毛表示为一组纤维曲线，并将重建转化为纤维增长问题。为确定眉毛的长度和形状，我们设计了三个模块：RootFinder、OriPredictor和FiberEnder。RootFinder先地本地化眉毛根部位置，以便于纤维增长；OriPredictor预测了3D空间中纤维的方向场，以帮助纤维增长；FiberEnder用于确定每个纤维的增长结束点。我们的OriPredictor直接借鉴了毛发重建中使用的方法。由于眉毛和毛发之间存在差异，因此RootFinder和FiberEnder均需要新的设计。具体来说，为了处理眉毛根部位置严重受遮挡的挑战，我们将根部地图估计任务转化为一个density map估计任务。给出预测的density map，然后使用密度基于的划分方法来找到根部。对于每个纤维，增长从根部开始，每步长度为constanteorientation field的oriented line。直到结束，每个步骤都需要通过一个像素对齐的RNN架构来判断是否需要停止增长。为支持所提出的网络的训练，我们建立了首个3D人工眉毛数据集，该数据集包含400个高质量眉毛模型，由艺术家手工创建。广泛的实验证明了我们提出的EMS管道的效果，可以处理不同的眉毛风格和长度，从短毛到长毛。
</details></li>
</ul>
<hr>
<h2 id="LMC-Large-Model-Collaboration-with-Cross-assessment-for-Training-Free-Open-Set-Object-Recognition"><a href="#LMC-Large-Model-Collaboration-with-Cross-assessment-for-Training-Free-Open-Set-Object-Recognition" class="headerlink" title="LMC: Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition"></a>LMC: Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12780">http://arxiv.org/abs/2309.12780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harryqu123/lmc">https://github.com/harryqu123/lmc</a></li>
<li>paper_authors: Haoxuan Qu, Xiaofei Hui, Yujun Cai, Jun Liu</li>
<li>for: 这 paper 的目的是如何精确地进行开放集object recognition，以减少依赖伪阳特征。</li>
<li>methods: 本 paper 提出了一个名为 Large Model Collaboration (LMC) 的新框架，通过多个 off-the-shelf 大型模型的协力来解决这个问题。此外，paper 还提出了多个新的设计来有效地从大型模型中提取隐藏知识。</li>
<li>results: 实验结果显示了我们提出的框架的有效性。可以在 <a target="_blank" rel="noopener" href="https://github.com/Harryqu123/LMC">https://github.com/Harryqu123/LMC</a> 获取代码。<details>
<summary>Abstract</summary>
Open-set object recognition aims to identify if an object is from a class that has been encountered during training or not. To perform open-set object recognition accurately, a key challenge is how to reduce the reliance on spurious-discriminative features. In this paper, motivated by that different large models pre-trained through different paradigms can possess very rich while distinct implicit knowledge, we propose a novel framework named Large Model Collaboration (LMC) to tackle the above challenge via collaborating different off-the-shelf large models in a training-free manner. Moreover, we also incorporate the proposed framework with several novel designs to effectively extract implicit knowledge from large models. Extensive experiments demonstrate the efficacy of our proposed framework. Code is available https://github.com/Harryqu123/LMC
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="WiCV-CVPR2023-The-Eleventh-Women-In-Computer-Vision-Workshop-at-the-Annual-CVPR-Conference"><a href="#WiCV-CVPR2023-The-Eleventh-Women-In-Computer-Vision-Workshop-at-the-Annual-CVPR-Conference" class="headerlink" title="WiCV@CVPR2023: The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference"></a>WiCV@CVPR2023: The Eleventh Women In Computer Vision Workshop at the Annual CVPR Conference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12768">http://arxiv.org/abs/2309.12768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doris Antensteiner, Marah Halawa, Asra Aslam, Ivaxi Sheth, Sachini Herath, Ziqi Huang, Sunnie S. Y. Kim, Aparna Akula, Xin Wang</li>
<li>for: The paper is written to present the details of the Women in Computer Vision Workshop - WiCV 2023, which aims to amplify the voices of underrepresented women in the computer vision community.</li>
<li>methods: The paper uses a comprehensive report on the workshop program, historical trends from past WiCV@CVPR events, and a summary of statistics related to presenters, attendees, and sponsorship for the WiCV 2023 workshop.</li>
<li>results: The paper presents a detailed report on the WiCV 2023 workshop, including the program, historical trends, and statistics related to presenters, attendees, and sponsorship. The paper also highlights the importance of such events in addressing gender imbalances within the field of computer vision.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍女性计算机视觉工作坊（WiCV 2023）的详细信息。WiCV 的目标是促进计算机视觉领域中少数女性的声音，并且推动该领域的多样性和平等。</li>
<li>methods: 这篇论文使用了 WiCV 2023 工作坊的全面报告，以及过去 WiCV@CVPR 事件的历史趋势和统计数据，以描述 WiCV 2023 工作坊的进程和成果。</li>
<li>results: 这篇论文提供了 WiCV 2023 工作坊的详细报告，包括工作坊的程序、历史趋势和统计数据，以及参与者和赞助商的相关信息。论文还强调了计算机视觉领域内的性别不平衡问题，并认为这类活动对于解决这一问题具有重要意义。<details>
<summary>Abstract</summary>
In this paper, we present the details of Women in Computer Vision Workshop - WiCV 2023, organized alongside the hybrid CVPR 2023 in Vancouver, Canada. WiCV aims to amplify the voices of underrepresented women in the computer vision community, fostering increased visibility in both academia and industry. We believe that such events play a vital role in addressing gender imbalances within the field. The annual WiCV@CVPR workshop offers a) opportunity for collaboration between researchers from minority groups, b) mentorship for female junior researchers, c) financial support to presenters to alleviate finanacial burdens and d) a diverse array of role models who can inspire younger researchers at the outset of their careers. In this paper, we present a comprehensive report on the workshop program, historical trends from the past WiCV@CVPR events, and a summary of statistics related to presenters, attendees, and sponsorship for the WiCV 2023 workshop.
</details>
<details>
<summary>摘要</summary>
在本文中，我们介绍了2023年度的女性计算机视觉工作坊（WiCV 2023），该活动与CVPR 2023合办于加拿大温尼伯市。WiCV 的目标是扩大计算机视觉领域下的弱调女性人群的声音，提高学术和产业领域中的女性 visibility。我们认为这些活动对于解决计算机视觉领域中的性别偏见非常重要。每年的 WiCV@CVPR 工作坊提供了以下机会：（a）少数民族研究者之间的合作，（b）为女性新手研究者提供导师，（c）为参会者提供论文发表支持，以及（d）多样化的角色模范，以激励年轻研究者在职业开始时。在本文中，我们提供了2023年 WiCV@CVPR 工作坊的工作计划、过去事件的历史趋势以及2023年工作坊的统计数据。
</details></li>
</ul>
<hr>
<h2 id="S3TC-Spiking-Separated-Spatial-and-Temporal-Convolutions-with-Unsupervised-STDP-based-Learning-for-Action-Recognition"><a href="#S3TC-Spiking-Separated-Spatial-and-Temporal-Convolutions-with-Unsupervised-STDP-based-Learning-for-Action-Recognition" class="headerlink" title="S3TC: Spiking Separated Spatial and Temporal Convolutions with Unsupervised STDP-based Learning for Action Recognition"></a>S3TC: Spiking Separated Spatial and Temporal Convolutions with Unsupervised STDP-based Learning for Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12761">http://arxiv.org/abs/2309.12761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mireille El-Assal, Pierre Tirilly, Ioan Marius Bilasco<br>for:This paper focuses on developing a more efficient video analysis method using Spiking Neural Networks (SNNs) and Spiking Separated Spatial and Temporal Convolutions (S3TCs).methods:The authors use unsupervised learning with the Spike Timing-Dependent Plasticity (STDP) rule and introduce S3TCs to reduce the number of parameters required for video analysis.results:The proposed method successfully extracts spatio-temporal information from videos, increases the output spiking activity, and outperforms spiking 3D convolutions on the KTH, Weizmann, and IXMAS datasets.Here is the answer in Simplified Chinese text:for: 这篇论文关注开发更高效的视频分析方法，使用神经网络和分离空间和时间卷积（S3TCs）。methods: 作者使用无监督学习和脉冲时间依赖性变化（STDP）规则，并引入S3TCs来降低视频分析所需的参数数量。results: 提议的方法在KTH、Weizmann和IXMAS数据集上成功提取空间-时间信息，提高输出脉冲活动，并超越了脉冲3D卷积。<details>
<summary>Abstract</summary>
Video analysis is a major computer vision task that has received a lot of attention in recent years. The current state-of-the-art performance for video analysis is achieved with Deep Neural Networks (DNNs) that have high computational costs and need large amounts of labeled data for training. Spiking Neural Networks (SNNs) have significantly lower computational costs (thousands of times) than regular non-spiking networks when implemented on neuromorphic hardware. They have been used for video analysis with methods like 3D Convolutional Spiking Neural Networks (3D CSNNs). However, these networks have a significantly larger number of parameters compared with spiking 2D CSNN. This, not only increases the computational costs, but also makes these networks more difficult to implement with neuromorphic hardware. In this work, we use CSNNs trained in an unsupervised manner with the Spike Timing-Dependent Plasticity (STDP) rule, and we introduce, for the first time, Spiking Separated Spatial and Temporal Convolutions (S3TCs) for the sake of reducing the number of parameters required for video analysis. This unsupervised learning has the advantage of not needing large amounts of labeled data for training. Factorizing a single spatio-temporal spiking convolution into a spatial and a temporal spiking convolution decreases the number of parameters of the network. We test our network with the KTH, Weizmann, and IXMAS datasets, and we show that S3TCs successfully extract spatio-temporal information from videos, while increasing the output spiking activity, and outperforming spiking 3D convolutions.
</details>
<details>
<summary>摘要</summary>
视频分析是计算机视觉中的一项重要任务，在过去几年内受到了很多关注。当前的状态艺术性表现在视频分析方面是通过深度神经网络（DNNs）实现的，其计算成本较高，需要大量标注数据进行训练。神经元网络（SNNs）在神经模拟硬件上实现时有 thousands 万次更低的计算成本，但它们的参数数量相对较多，使得它们更难于实现。在这项工作中，我们使用 CSNNs 在无监督的方式进行训练，并 introduce 一种新的 Spiking Separated Spatial and Temporal Convolutions（S3TCs），以降低视频分析所需的参数数量。这种无监督学习具有不需要大量标注数据进行训练的优点。将一个综合空间时间射阻挡分解成空间射阻挡和时间射阻挡，可以降低网络的参数数量。我们在 KTH、Weizmann 和 IXMAS 数据集上测试了我们的网络，并显示了 S3TCs 成功地从视频中提取空间时间信息，提高输出脉冲活动，并超过了射阻挡三维 convolution。
</details></li>
</ul>
<hr>
<h2 id="Transformer-based-Image-Compression-with-Variable-Image-Quality-Objectives"><a href="#Transformer-based-Image-Compression-with-Variable-Image-Quality-Objectives" class="headerlink" title="Transformer-based Image Compression with Variable Image Quality Objectives"></a>Transformer-based Image Compression with Variable Image Quality Objectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12717">http://arxiv.org/abs/2309.12717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chia-Hao Kao, Yi-Hsin Chen, Cheng Chien, Wei-Chen Chiu, Wen-Hsiao Peng</li>
<li>for: 该 paper 是为了提供一种可变图像质量目标的 transformer 基于压缩系统，以满足用户的偏好。</li>
<li>methods: 该方法使用 learned codec 进行优化，以实现不同质量目标下的图像重建。用户可以通过单一的模型来选择一个质量目标的交易off。</li>
<li>results: 该方法可以通过使用 prompt tokens 来condition transformer 基于 autoencoder，并通过学习 prompt generation network 来生成适应用户偏好和输入图像的 prompt tokens。对于常见的质量指标，广泛的实验表明该方法可以适应不同的质量目标，并且与单一质量目标方法相比，其表现相对较好。<details>
<summary>Abstract</summary>
This paper presents a Transformer-based image compression system that allows for a variable image quality objective according to the user's preference. Optimizing a learned codec for different quality objectives leads to reconstructed images with varying visual characteristics. Our method provides the user with the flexibility to choose a trade-off between two image quality objectives using a single, shared model. Motivated by the success of prompt-tuning techniques, we introduce prompt tokens to condition our Transformer-based autoencoder. These prompt tokens are generated adaptively based on the user's preference and input image through learning a prompt generation network. Extensive experiments on commonly used quality metrics demonstrate the effectiveness of our method in adapting the encoding and/or decoding processes to a variable quality objective. While offering the additional flexibility, our proposed method performs comparably to the single-objective methods in terms of rate-distortion performance.
</details>
<details>
<summary>摘要</summary>
Inspired by the success of prompt-tuning techniques, the system introduces prompt tokens to condition the Transformer-based autoencoder. These prompt tokens are generated adaptively based on the user's preference and input image through learning a prompt generation network. Extensive experiments on commonly used quality metrics demonstrate the effectiveness of the method in adapting the encoding and/or decoding processes to a variable quality objective. Notably, the proposed method offers the additional flexibility while performing comparably to single-objective methods in terms of rate-distortion performance.
</details></li>
</ul>
<hr>
<h2 id="mixed-attention-auto-encoder-for-multi-class-industrial-anomaly-detection"><a href="#mixed-attention-auto-encoder-for-multi-class-industrial-anomaly-detection" class="headerlink" title="mixed attention auto encoder for multi-class industrial anomaly detection"></a>mixed attention auto encoder for multi-class industrial anomaly detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12700">http://arxiv.org/abs/2309.12700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangqi Liu, Feng Wang</li>
<li>for: 本研究旨在提出一种可以实现多类异常检测的单一模型，以解决现有方法的高存储成本和训练效率低下问题。</li>
<li>methods: 该方法使用混合注意力自适应Encoder（MAAE），并采用空间注意力和通道注意力来有效地捕捉多类特征分布的全球category信息，以及模型多个类别特征分布的模型。此外，该方法还提出了适应噪声生成器和多尺度融合模块，以适应实际噪声和保持不同类别物体表面 semantics。</li>
<li>results: MAAE在 benchmark 数据集上达到了比state-of-the-art 方法更高的性能。<details>
<summary>Abstract</summary>
Most existing methods for unsupervised industrial anomaly detection train a separate model for each object category. This kind of approach can easily capture the category-specific feature distributions, but results in high storage cost and low training efficiency. In this paper, we propose a unified mixed-attention auto encoder (MAAE) to implement multi-class anomaly detection with a single model. To alleviate the performance degradation due to the diverse distribution patterns of different categories, we employ spatial attentions and channel attentions to effectively capture the global category information and model the feature distributions of multiple classes. Furthermore, to simulate the realistic noises on features and preserve the surface semantics of objects from different categories which are essential for detecting the subtle anomalies, we propose an adaptive noise generator and a multi-scale fusion module for the pre-trained features. MAAE delivers remarkable performances on the benchmark dataset compared with the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
现有的方法 для无监督工业异常检测通常将每个物件类别 trains一个分开的模型。这种方法可以轻松地捕捉每个类别的特征分布，但会导致存储成本高且训练效率低。在这篇论文中，我们提出了一个整合式混合注意力自动编码器（MAAE），以实现多类别异常检测的单一模型。为了解决不同类别的特征分布多样性导致性能下降的问题，我们使用空间注意力和通道注意力来有效地捕捉全类别信息和多类别特征分布。其次，为了模拟实际上的噪声和保持不同类别物件表面 semantics，我们提出了适应式噪声生成器和多尺度融合模组。MAAE在比较 dataset 上 delivert 了非常出色的性能，与当前方法相比。
</details></li>
</ul>
<hr>
<h2 id="eWand-A-calibration-framework-for-wide-baseline-frame-based-and-event-based-camera-systems"><a href="#eWand-A-calibration-framework-for-wide-baseline-frame-based-and-event-based-camera-systems" class="headerlink" title="eWand: A calibration framework for wide baseline frame-based and event-based camera systems"></a>eWand: A calibration framework for wide baseline frame-based and event-based camera systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12685">http://arxiv.org/abs/2309.12685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Gossard, Andreas Ziegler, Levin Kolmar, Jonas Tebbe, Andreas Zell</li>
<li>for: 用于高精度对象位置三角推算的精准准确calibration</li>
<li>methods: 使用闪烁LED闪烁在透明球体内，代替传统的印刷或显示 Pattern</li>
<li>results: 提供高精度、易于使用的多摄像头外部坐标calibration方法，适用于frame-和事件基camera<details>
<summary>Abstract</summary>
Accurate calibration is crucial for using multiple cameras to triangulate the position of objects precisely. However, it is also a time-consuming process that needs to be repeated for every displacement of the cameras. The standard approach is to use a printed pattern with known geometry to estimate the intrinsic and extrinsic parameters of the cameras. The same idea can be applied to event-based cameras, though it requires extra work. By using frame reconstruction from events, a printed pattern can be detected. A blinking pattern can also be displayed on a screen. Then, the pattern can be directly detected from the events. Such calibration methods can provide accurate intrinsic calibration for both frame- and event-based cameras. However, using 2D patterns has several limitations for multi-camera extrinsic calibration, with cameras possessing highly different points of view and a wide baseline. The 2D pattern can only be detected from one direction and needs to be of significant size to compensate for its distance to the camera. This makes the extrinsic calibration time-consuming and cumbersome. To overcome these limitations, we propose eWand, a new method that uses blinking LEDs inside opaque spheres instead of a printed or displayed pattern. Our method provides a faster, easier-to-use extrinsic calibration approach that maintains high accuracy for both event- and frame-based cameras.
</details>
<details>
<summary>摘要</summary>
准确的均衡是多摄像头三角测量物体位置精准的关键。然而，这也是一项时间消耗的过程，需要每次移动摄像头时重新进行。标准方法是使用印刷的模式来估算摄像头的内参和外参参数。这种方法可以应用于事件基图像，尽管需要额外的工作。通过从事件中重建幻象，可以直接检测印刷的模式。然后，可以使用幻象的检测来提供内参均衡。但是，使用2D模式有多个相机的外参均衡的限制，因为相机具有不同的视角和广泛的基线。2D模式只能从一个方向检测，需要很大的尺寸来补偿其与摄像头的距离。这使得外参均衡变得时间消耗和困难。为了缓解这些限制，我们提出了ewand，一种新的方法，使用LED灯光在透明球体中闪烁。我们的方法提供了一种更快、更容易使用的外参均衡方法，可以保持高精度 для both事件基图像和帧基图像。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Modality-Specific-Features-For-Multi-Modal-Manipulation-Detection-And-Grounding"><a href="#Exploiting-Modality-Specific-Features-For-Multi-Modal-Manipulation-Detection-And-Grounding" class="headerlink" title="Exploiting Modality-Specific Features For Multi-Modal Manipulation Detection And Grounding"></a>Exploiting Modality-Specific Features For Multi-Modal Manipulation Detection And Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12657">http://arxiv.org/abs/2309.12657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazhen Wang, Bin Liu, Changtao Miao, Zhiwei Zhao, Wanyi Zhuang, Qi Chu, Nenghai Yu</li>
<li>for: 本研究旨在提出一种简单且有效的 transformer 基本框架，用于检测和稳定多模态束缚 manipulation。</li>
<li>methods: 我们首先构造了视 language 预训练Encoder，并使用 dual-branch cross-attention (DCA) 技术来抽取和融合模态特有的特征。此外，我们还设计了分离精细类ifier (DFC)，以提高模态特有的特征挖掘和避免模态竞争。</li>
<li>results: 我们在 $\rm DGM^4$ 数据集上进行了广泛的实验，并证明了我们提出的模型在对 state-of-the-art 方法的比较中表现出色。<details>
<summary>Abstract</summary>
AI-synthesized text and images have gained significant attention, particularly due to the widespread dissemination of multi-modal manipulations on the internet, which has resulted in numerous negative impacts on society. Existing methods for multi-modal manipulation detection and grounding primarily focus on fusing vision-language features to make predictions, while overlooking the importance of modality-specific features, leading to sub-optimal results. In this paper, we construct a simple and novel transformer-based framework for multi-modal manipulation detection and grounding tasks. Our framework simultaneously explores modality-specific features while preserving the capability for multi-modal alignment. To achieve this, we introduce visual/language pre-trained encoders and dual-branch cross-attention (DCA) to extract and fuse modality-unique features. Furthermore, we design decoupled fine-grained classifiers (DFC) to enhance modality-specific feature mining and mitigate modality competition. Moreover, we propose an implicit manipulation query (IMQ) that adaptively aggregates global contextual cues within each modality using learnable queries, thereby improving the discovery of forged details. Extensive experiments on the $\rm DGM^4$ dataset demonstrate the superior performance of our proposed model compared to state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
人工智能生成的文本和图像在互联网上广泛传播，尤其是多模态杂化的 manipulate 问题，导致社会受到了负面影响。现有的多模态杂化检测和定位方法主要是通过视觉语言特征的融合来进行预测，而忽略了特定模式特征的重要性，从而导致低效的结果。在这篇论文中，我们提出了一种简单而新的 transformer 基于的多模态杂化检测和定位框架。我们的框架同时探索特定模式的特征，保留多模态对齐的能力。为此，我们引入视觉语言预训练encoder和双支分支交叉注意力（DCA），以EXTRACT和融合特定模式的特征。此外，我们设计了独立细致分类器（DFC），以提高特定模式的特征挖掘和避免模式竞争。此外，我们还提出了适应性 manipulate 查询（IMQ），可以在每个模式中适应学习查询，以提高对伪造细节的发现。我们对 $\rm DGM^4$ 数据集进行了广泛的实验，并证明了我们的提出的模型在对state-of-the-art方法的比较中表现出色。
</details></li>
</ul>
<hr>
<h2 id="FP-PET-Large-Model-Multiple-Loss-And-Focused-Practice"><a href="#FP-PET-Large-Model-Multiple-Loss-And-Focused-Practice" class="headerlink" title="FP-PET: Large Model, Multiple Loss And Focused Practice"></a>FP-PET: Large Model, Multiple Loss And Focused Practice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12650">http://arxiv.org/abs/2309.12650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Chen, Ourui Fu, Wenrui Shao, Zhaoheng Xie</li>
<li>for: 这项研究旨在提出FP-PET方法，用于医学图像分割，尤其是CT和PET图像。</li>
<li>methods: 该研究使用了多种机器学习模型，包括STUNet-large、SwinUNETR和VNet，以实现最新的分割性能。</li>
<li>results: 研究提出了一个综合评价指标，将多个评价指标（如 dice分数、false positive volume 和 false negative volume）加权平均，以提供全面的模型效果评价。<details>
<summary>Abstract</summary>
This study presents FP-PET, a comprehensive approach to medical image segmentation with a focus on CT and PET images. Utilizing a dataset from the AutoPet2023 Challenge, the research employs a variety of machine learning models, including STUNet-large, SwinUNETR, and VNet, to achieve state-of-the-art segmentation performance. The paper introduces an aggregated score that combines multiple evaluation metrics such as Dice score, false positive volume (FPV), and false negative volume (FNV) to provide a holistic measure of model effectiveness. The study also discusses the computational challenges and solutions related to model training, which was conducted on high-performance GPUs. Preprocessing and postprocessing techniques, including gaussian weighting schemes and morphological operations, are explored to further refine the segmentation output. The research offers valuable insights into the challenges and solutions for advanced medical image segmentation.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这项研究提出了FP-PET，一种涵盖CT和PET图像分割的全面方法。利用AutoPet2023 Challenge数据集，研究使用了多种机器学习模型，包括STUNet-large、SwinUNETR和VNet，以实现最新的分割性能。文章引入了一个汇总分数，将多个评估指标，如 dice分数、false positive volume (FPV) 和 false negative volume (FNV) 汇总而成一个整体评价指标，以提供更全面的模型效果评估。研究还讨论了模型训练中的计算挑战和解决方案，并在高性能GPU上进行训练。研究还探讨了预处理和后处理技术，包括高斯权重方案和形态运算，以进一步细化分割输出。研究提供了进一步了解高级医学图像分割的挑战和解决方案。
</details></li>
</ul>
<hr>
<h2 id="RHINO-Regularizing-the-Hash-based-Implicit-Neural-Representation"><a href="#RHINO-Regularizing-the-Hash-based-Implicit-Neural-Representation" class="headerlink" title="RHINO: Regularizing the Hash-based Implicit Neural Representation"></a>RHINO: Regularizing the Hash-based Implicit Neural Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12642">http://arxiv.org/abs/2309.12642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhu, Fengyi Liu, Qi Zhang, Xun Cao, Zhan Ma</li>
<li>for: 提高Hash表示法中的Regularization，以提高 interpolate 的可靠性和稳定性。</li>
<li>methods: 引入一个连续分析函数，以便在Hash表示法中增强Regularization，不需要修改当前的Hash表示法架构。</li>
<li>results: RHINO在多种任务上表现出色，如图像适应、签名距离函数表示、5D静止&#x2F;6D动态神经辐射场优化等，并且在质量和速度两个方面超过当前状态态技术。<details>
<summary>Abstract</summary>
The use of Implicit Neural Representation (INR) through a hash-table has demonstrated impressive effectiveness and efficiency in characterizing intricate signals. However, current state-of-the-art methods exhibit insufficient regularization, often yielding unreliable and noisy results during interpolations. We find that this issue stems from broken gradient flow between input coordinates and indexed hash-keys, where the chain rule attempts to model discrete hash-keys, rather than the continuous coordinates. To tackle this concern, we introduce RHINO, in which a continuous analytical function is incorporated to facilitate regularization by connecting the input coordinate and the network additionally without modifying the architecture of current hash-based INRs. This connection ensures a seamless backpropagation of gradients from the network's output back to the input coordinates, thereby enhancing regularization. Our experimental results not only showcase the broadened regularization capability across different hash-based INRs like DINER and Instant NGP, but also across a variety of tasks such as image fitting, representation of signed distance functions, and optimization of 5D static / 6D dynamic neural radiance fields. Notably, RHINO outperforms current state-of-the-art techniques in both quality and speed, affirming its superiority.
</details>
<details>
<summary>摘要</summary>
使用含义神经表示（INR）通过哈希表实现了非常出色的效果和效率，可是现有的状态 искусственный интеллект技术表现不够稳定，经常产生不可靠和噪音的结果 durante interpolaciones. 我们认为这个问题的根本原因在于哈希键和输入坐标之间的梯度流不畅，链式规则尝试模型离散的哈希键，而不是连续的坐标。为解决这个问题，我们介绍了犀牛（RHINO），它是一种连续的分析函数，可以在不修改现有哈希基于INR的网络架构的情况下，提供更好的规范。这种连接确保了输入坐标和网络的输出之间的精准的梯度传递，从而提高了规范。我们的实验结果不仅表明了不同的哈希基于INR如DINER和快速NP的规范能力的扩展，还在图像适应、签证距离函数表示和5D静态/6D动态神经辐射场的优化中达到了更高的质量和速度，并且超过了当前状态 искусственный интеллект技术的性能。
</details></li>
</ul>
<hr>
<h2 id="Global-Context-Aggregation-Network-for-Lightweight-Saliency-Detection-of-Surface-Defects"><a href="#Global-Context-Aggregation-Network-for-Lightweight-Saliency-Detection-of-Surface-Defects" class="headerlink" title="Global Context Aggregation Network for Lightweight Saliency Detection of Surface Defects"></a>Global Context Aggregation Network for Lightweight Saliency Detection of Surface Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12641">http://arxiv.org/abs/2309.12641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Yan, Xiaoheng Jiang, Yang Lu, Lisha Cui, Shupan Li, Jiale Cao, Mingliang Xu, Dacheng Tao</li>
<li>for: 这个论文主要目的是提出一种轻量级的抗余损检测方法，以提高检测效率和精度。</li>
<li>methods: 本文提出了一种基于encoder-decoder结构的Global Context Aggregation Network (GCANet)，包括一种新的transformerEncoder和Channel Reference Attention (CRA)模块，以提高多层特征表示的综合性。</li>
<li>results: 对三个公共的损害数据集进行实验表明，GCANet可以与17种state-of-the-art方法进行比较，并且在精度和运行效率之间做出了一个更好的平衡。具体来说，GCANet在SD-saliency-900上 achieve了91.79% $F_{\beta}^{w}$, 93.55% $S_\alpha$,和97.35% $E_\phi$的精度，并且在单个GPU上运行272fps。<details>
<summary>Abstract</summary>
Surface defect inspection is a very challenging task in which surface defects usually show weak appearances or exist under complex backgrounds. Most high-accuracy defect detection methods require expensive computation and storage overhead, making them less practical in some resource-constrained defect detection applications. Although some lightweight methods have achieved real-time inference speed with fewer parameters, they show poor detection accuracy in complex defect scenarios. To this end, we develop a Global Context Aggregation Network (GCANet) for lightweight saliency detection of surface defects on the encoder-decoder structure. First, we introduce a novel transformer encoder on the top layer of the lightweight backbone, which captures global context information through a novel Depth-wise Self-Attention (DSA) module. The proposed DSA performs element-wise similarity in channel dimension while maintaining linear complexity. In addition, we introduce a novel Channel Reference Attention (CRA) module before each decoder block to strengthen the representation of multi-level features in the bottom-up path. The proposed CRA exploits the channel correlation between features at different layers to adaptively enhance feature representation. The experimental results on three public defect datasets demonstrate that the proposed network achieves a better trade-off between accuracy and running efficiency compared with other 17 state-of-the-art methods. Specifically, GCANet achieves competitive accuracy (91.79% $F_{\beta}^{w}$, 93.55% $S_\alpha$, and 97.35% $E_\phi$) on SD-saliency-900 while running 272fps on a single gpu.
</details>
<details>
<summary>摘要</summary>
surface defect inspection 是一项非常具有挑战性的任务， surface defects 通常会出现弱化的外观或者在复杂的背景下出现。大多数高精度的缺陷检测方法需要昂贵的计算和存储开销，使其在一些资源受限的缺陷检测应用中不实用。 although some lightweight methods have achieved real-time inference speed with fewer parameters, they show poor detection accuracy in complex defect scenarios. 为了解决这个问题，我们开发了一个全球上下文聚合网络（GCANet），用于轻量级的缺陷检测。我们在轻量级的后ION上加入了一个新的 transformer Encoder，以便在全球上下文信息中捕捉全球上下文信息。我们引入了一种新的 Depth-wise Self-Attention（DSA）模块，用于在通道维度进行元素对元素的相似性检测，同时保持线性复杂度。此外，我们在每个解码块前加入了一个 Channel Reference Attention（CRA）模块，以强化底层特征表示。CRA模块利用不同层次特征之间的通道相关性来适应性地增强特征表示。我们在三个公共缺陷数据集上进行了实验，结果显示，我们的网络在缺陷检测精度和运行效率之间做出了更好的平衡，相比于其他 17 种国际前沿方法。具体来说，GCANet 在 SD-saliency-900 上达到了同等精度（91.79% $F_{\beta}^{w}$, 93.55% $S_\alpha$, 和 97.35% $E_\phi$），而且在单个 GPU 上运行速度为 272 fps。
</details></li>
</ul>
<hr>
<h2 id="CINFormer-Transformer-network-with-multi-stage-CNN-feature-injection-for-surface-defect-segmentation"><a href="#CINFormer-Transformer-network-with-multi-stage-CNN-feature-injection-for-surface-defect-segmentation" class="headerlink" title="CINFormer: Transformer network with multi-stage CNN feature injection for surface defect segmentation"></a>CINFormer: Transformer network with multi-stage CNN feature injection for surface defect segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12639">http://arxiv.org/abs/2309.12639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoheng Jiang, Kaiyi Guo, Yang Lu, Feng Yan, Hao Liu, Jiale Cao, Mingliang Xu, Dacheng Tao</li>
<li>for: 这个研究旨在提高工业生产中的表面缺陷检测精度，并解决深度学习方法中的一些挑战，如微弱缺陷和背景中的干扰。</li>
<li>methods: 本研究提出了一个基于 transformer 网络的 CINFormer，具有多Stage CNN 特征插入和 Top-K 自我注意模组。这个架构可以维持 CNN 捕捉细部特征和 transformer 抑制背景干扰的优点，以提高缺陷检测精度。</li>
<li>results: 实验结果显示，提出的 CINFormer 在 DAGM 2007、Magnetic tile 和 NEU 等表面缺陷数据集上实现了顶尖性能，并且在不同的缺陷类型和背景干扰下都能够获得高度的精度。<details>
<summary>Abstract</summary>
Surface defect inspection is of great importance for industrial manufacture and production. Though defect inspection methods based on deep learning have made significant progress, there are still some challenges for these methods, such as indistinguishable weak defects and defect-like interference in the background. To address these issues, we propose a transformer network with multi-stage CNN (Convolutional Neural Network) feature injection for surface defect segmentation, which is a UNet-like structure named CINFormer. CINFormer presents a simple yet effective feature integration mechanism that injects the multi-level CNN features of the input image into different stages of the transformer network in the encoder. This can maintain the merit of CNN capturing detailed features and that of transformer depressing noises in the background, which facilitates accurate defect detection. In addition, CINFormer presents a Top-K self-attention module to focus on tokens with more important information about the defects, so as to further reduce the impact of the redundant background. Extensive experiments conducted on the surface defect datasets DAGM 2007, Magnetic tile, and NEU show that the proposed CINFormer achieves state-of-the-art performance in defect detection.
</details>
<details>
<summary>摘要</summary>
surface defect inspection 是现代工业生产中非常重要的一环。尽管基于深度学习的抗损检测方法已经取得了 significiant progress，但还有一些挑战，如微弱损害难以辨别和背景中的干扰。为解决这些问题，我们提出了一种基于 transformer 网络的多stage CNN 特征注入的表面抗损分割方法，即 CINFormer。 CINFormer 提供了一种简单 yet 有效的特征集成机制，通过在 transformer 网络的编码器中注入不同级别的 CNN 特征，以维持 CNN 捕捉细节特征的优点，同时使用 transformer 网络压缩背景干扰的优点。此外，CINFormer 还提供了 Top-K 自注意模块，以便更好地强调损害的关键信息，从而进一步减少背景干扰的影响。经过对 DAGM 2007、Magnetic 块和 NEU 等表面抗损数据集的广泛实验，我们发现，提议的 CINFormer 可以达到现代表面抗损检测的州标性性能。
</details></li>
</ul>
<hr>
<h2 id="Auto-Lesion-Segmentation-with-a-Novel-Intensity-Dark-Channel-Prior-for-COVID-19-Detection"><a href="#Auto-Lesion-Segmentation-with-a-Novel-Intensity-Dark-Channel-Prior-for-COVID-19-Detection" class="headerlink" title="Auto-Lesion Segmentation with a Novel Intensity Dark Channel Prior for COVID-19 Detection"></a>Auto-Lesion Segmentation with a Novel Intensity Dark Channel Prior for COVID-19 Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12638">http://arxiv.org/abs/2309.12638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Basma Jumaa Saleh, Zaid Omar, Vikrant Bhateja, Lila Iznita Izhar<br>for: 本研究旨在开发一种基于 computed tomography (CT) 图像的 COVID-19 诊断方法，以帮助诊断可疑 COVID-19 患者。methods: 本研究使用了 radiomic 特征，并采用了强化自动分割原理（IDCP）和深度神经网络（ALS-IDCP-DNN），在定义的分析阈值范围内进行图像分类。results: 验证性 dataset 上，提议的模型实现了98.8%的平均准确率、99%的准确率、98%的 recall 和98%的 F1 score。这些结果表明，我们的模型可以准确地分类 COVID-19 图像，可以帮助 radiologists 诊断可疑 COVID-19 患者。此外，我们的模型表现得更好于现有的10多个国际研究。<details>
<summary>Abstract</summary>
During the COVID-19 pandemic, medical imaging techniques like computed tomography (CT) scans have demonstrated effectiveness in combating the rapid spread of the virus. Therefore, it is crucial to conduct research on computerized models for the detection of COVID-19 using CT imaging. A novel processing method has been developed, utilizing radiomic features, to assist in the CT-based diagnosis of COVID-19. Given the lower specificity of traditional features in distinguishing between different causes of pulmonary diseases, the objective of this study is to develop a CT-based radiomics framework for the differentiation of COVID-19 from other lung diseases. The model is designed to focus on outlining COVID-19 lesions, as traditional features often lack specificity in this aspect. The model categorizes images into three classes: COVID-19, non-COVID-19, or normal. It employs enhancement auto-segmentation principles using intensity dark channel prior (IDCP) and deep neural networks (ALS-IDCP-DNN) within a defined range of analysis thresholds. A publicly available dataset comprising COVID-19, normal, and non-COVID-19 classes was utilized to validate the proposed model's effectiveness. The best performing classification model, Residual Neural Network with 50 layers (Resnet-50), attained an average accuracy, precision, recall, and F1-score of 98.8%, 99%, 98%, and 98% respectively. These results demonstrate the capability of our model to accurately classify COVID-19 images, which could aid radiologists in diagnosing suspected COVID-19 patients. Furthermore, our model's performance surpasses that of more than 10 current state-of-the-art studies conducted on the same dataset.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在COVID-19疫情期间，计算机成像技术如计算机tomography（CT）扫描已经表现出效iveness在防止病毒的迅速传播。因此，需要进行计算机模型的研究，以便使用CT成像来诊断COVID-19。我们开发了一种新的处理方法，利用 радиомics特征，以帮助CT成像诊断COVID-19。传统的特征 oft lack specificity in distinguishing between different causes of pulmonary diseases，因此我们的目标是开发一个基于CT成像的radiomics框架，以区分COVID-19和其他肺病。模型设计用于强调COVID-19斑点，以便更好地识别COVID-19。模型将图像分类为三类：COVID-19、非COVID-19或正常。它使用了增强自动分割原理，使用暗色通道优先预测（IDCP）和深度神经网络（ALS-IDCP-DNN），在定义的分析阈值范围内。一个公共可用的数据集，包括COVID-19、正常和非COVID-19类别，用于验证我们的模型效果。使用最佳表现的分类模型，即Residual Neural Network with 50 layers（Resnet-50），在COVID-19、非COVID-19和正常类别之间达到了平均准确率、精度、回归率和F1分数的98.8%、99%、98%和98%。这些结果表明我们的模型可以准确地分类COVID-19图像，这将助力放医生诊断可能的COVID-19患者。此外，我们的模型性能超过了现有的10个以上state-of-the-art研究，同一个数据集。
</details></li>
</ul>
<hr>
<h2 id="Learning-Actions-and-Control-of-Focus-of-Attention-with-a-Log-Polar-like-Sensor"><a href="#Learning-Actions-and-Control-of-Focus-of-Attention-with-a-Log-Polar-like-Sensor" class="headerlink" title="Learning Actions and Control of Focus of Attention with a Log-Polar-like Sensor"></a>Learning Actions and Control of Focus of Attention with a Log-Polar-like Sensor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12634">http://arxiv.org/abs/2309.12634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin Göransson, Volker Krueger</li>
<li>for: 提高自动移动机器人图像处理速度</li>
<li>methods: 使用径向尺度图像数据和 gaze 控制</li>
<li>results: 成功降低图像像素数量，不影响游戏性能Here’s a breakdown of each point:</li>
<li>for: The paper aims to improve the image processing speed of an autonomous mobile robot.</li>
<li>methods: The paper explores the use of log-polar like image data with gaze control, and extends an A3C deep RL approach with an LSTM network to learn the policy for playing Atari games and gaze control.</li>
<li>results: The paper successfully reduces the amount of image pixels by a factor of 5 without losing any gaming performance.<details>
<summary>Abstract</summary>
With the long-term goal of reducing the image processing time on an autonomous mobile robot in mind we explore in this paper the use of log-polar like image data with gaze control. The gaze control is not done on the Cartesian image but on the log-polar like image data. For this we start out from the classic deep reinforcement learning approach for Atari games. We extend an A3C deep RL approach with an LSTM network, and we learn the policy for playing three Atari games and a policy for gaze control. While the Atari games already use low-resolution images of 80 by 80 pixels, we are able to further reduce the amount of image pixels by a factor of 5 without losing any gaming performance.
</details>
<details>
<summary>摘要</summary>
这里使用简化中文翻译文本。</SYS>为了实现机器人自动运行中的图像处理时间缩短，这篇论文探讨了使用对应的对应图像数据，并将控制 gaze 在这些图像数据上。我们从 класи的深度学习游戏方法开始，并将 A3C 深度RL 方法与 LSTM 网络扩展。我们学习了三个 Atari 游戏和一个 gaze 控制策略。 Although Atari games already use low-resolution images of 80 by 80 pixels, we are able to further reduce the amount of image pixels by a factor of 5 without losing any gaming performance.
</details></li>
</ul>
<hr>
<h2 id="Decision-Fusion-Network-with-Perception-Fine-tuning-for-Defect-Classification"><a href="#Decision-Fusion-Network-with-Perception-Fine-tuning-for-Defect-Classification" class="headerlink" title="Decision Fusion Network with Perception Fine-tuning for Defect Classification"></a>Decision Fusion Network with Perception Fine-tuning for Defect Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12630">http://arxiv.org/abs/2309.12630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoheng Jiang, Shilong Tian, Zhiwen Zhu, Yang Lu, Hao Liu, Li Chen, Shupan Li, Mingliang Xu</li>
<li>for: 卷积 neural network 用于Surface defect inspection 中的检测和分类任务</li>
<li>methods: 提出了一种决策融合网络（DFNet），通过将semantic decision和feature decision融合来强化网络的决策能力，同时提出了一种感知细化模块（PFM）来优化前景和背景的分割结果</li>
<li>results: 对于公开的数据集KolektorSDD2和Magnetic-tile-defect-datasets进行了实验，实现了96.1% AP和94.6% mAP的效果<details>
<summary>Abstract</summary>
Surface defect inspection is an important task in industrial inspection. Deep learning-based methods have demonstrated promising performance in this domain. Nevertheless, these methods still suffer from misjudgment when encountering challenges such as low-contrast defects and complex backgrounds. To overcome these issues, we present a decision fusion network (DFNet) that incorporates the semantic decision with the feature decision to strengthen the decision ability of the network. In particular, we introduce a decision fusion module (DFM) that extracts a semantic vector from the semantic decision branch and a feature vector for the feature decision branch and fuses them to make the final classification decision. In addition, we propose a perception fine-tuning module (PFM) that fine-tunes the foreground and background during the segmentation stage. PFM generates the semantic and feature outputs that are sent to the classification decision stage. Furthermore, we present an inner-outer separation weight matrix to address the impact of label edge uncertainty during segmentation supervision. Our experimental results on the publicly available datasets including KolektorSDD2 (96.1% AP) and Magnetic-tile-defect-datasets (94.6% mAP) demonstrate the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
superficie defecto inspección es una tarea importante en la inspección industrial. los métodos basados en aprendizaje profundo han demostrado un rendimiento prometedor en este dominio. sin embargo, estos métodos todavía sufren de mal juzgar cuando se encuentran desafíos como defectos de baja contraste y fondos complejos. para superar estos problemas, presentamos una red de fusión de decisiones (DFNet) que integra la decisión semántica con la decisión de características para fortalecer la capacidad de toma de decisiones del réseau. en particular, introducimos un módulo de fusión de decisiones (DFM) que extrae un vector semántico de la rama de decisión semántica y un vector de características de la rama de decisión de características y los fusiona para tomar la decisión de clasificación final. Además, propusimos un módulo de finuración de percepción (PFM) que realiza la fine-tuning de la percepción durante la etapa de segmentación. PFM genera las salidas semánticas y de características que se envían a la etapa de toma de decisiones de clasificación. Además, presentamos una matriz de pesos de separación interior-exterior para abordar el impacto de la incertidumbre de la etiqueta en la supervisión de segmentación. nuestros resultados experimentales en los conjuntos de datos públicos, incluyendo KolektorSDD2 (96.1% AP) y Magnetic-tile-defect-datasets (94.6% mAP), demuestran la eficacia de la método propuesto.
</details></li>
</ul>
<hr>
<h2 id="DeFormer-Integrating-Transformers-with-Deformable-Models-for-3D-Shape-Abstraction-from-a-Single-Image"><a href="#DeFormer-Integrating-Transformers-with-Deformable-Models-for-3D-Shape-Abstraction-from-a-Single-Image" class="headerlink" title="DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image"></a>DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12594">http://arxiv.org/abs/2309.12594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Liu, Xiang Yu, Meng Ye, Qilong Zhangli, Zhuowei Li, Zhixing Zhang, Dimitris N. Metaxas</li>
<li>for: 提出了一种新的bi-channel Transformer架构，用于同时估计全局和局部变形。</li>
<li>methods: 使用了一种参数化的塑形模型，称为DeFormer，以便更好地抽象复杂的物体形状。</li>
<li>results: 在ShapeNet上进行了广泛的实验，并达到了比之前最佳的重建精度，并且可以Visualize了更加准确的semantic相关性。<details>
<summary>Abstract</summary>
Accurate 3D shape abstraction from a single 2D image is a long-standing problem in computer vision and graphics. By leveraging a set of primitives to represent the target shape, recent methods have achieved promising results. However, these methods either use a relatively large number of primitives or lack geometric flexibility due to the limited expressibility of the primitives. In this paper, we propose a novel bi-channel Transformer architecture, integrated with parameterized deformable models, termed DeFormer, to simultaneously estimate the global and local deformations of primitives. In this way, DeFormer can abstract complex object shapes while using a small number of primitives which offer a broader geometry coverage and finer details. Then, we introduce a force-driven dynamic fitting and a cycle-consistent re-projection loss to optimize the primitive parameters. Extensive experiments on ShapeNet across various settings show that DeFormer achieves better reconstruction accuracy over the state-of-the-art, and visualizes with consistent semantic correspondences for improved interpretability.
</details>
<details>
<summary>摘要</summary>
通过使用一组基本形状来表示目标形状，现代方法已经实现了在计算机视觉和图形领域中准确地抽象三维形状。然而，这些方法可能使用相对较多的基本形状，或者由于基本形状的有限表达能力而缺乏几何可动性。在本文中，我们提出了一种新的双渠道变换器架构，并结合参数化可变模型，称为DeFormer，以同时估计全局和局部几何变换。这样，DeFormer可以抽象复杂的物体形状，使用少量的基本形状，并且具有更广泛的几何覆盖和细节。然后，我们引入了力场驱动的动态适应和цикли性征重 Projekt loss 来优化基本形状参数。通过对ShapeNet进行了多种设置的实验，我们发现DeFormer可以在计算机视觉和图形领域中实现更好的重建精度，并且可以visualize与更高度的 semantic correspondence  для改进释plausibility。
</details></li>
</ul>
<hr>
<h2 id="Improving-Machine-Learning-Robustness-via-Adversarial-Training"><a href="#Improving-Machine-Learning-Robustness-via-Adversarial-Training" class="headerlink" title="Improving Machine Learning Robustness via Adversarial Training"></a>Improving Machine Learning Robustness via Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12593">http://arxiv.org/abs/2309.12593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin</li>
<li>for: 本研究旨在 investigate 机器学习（ML）Robustness 在中央化和分散化环境中，以帮助设计更加Robust 的 ML 算法。</li>
<li>methods: 本研究使用了 adversarial training 方法在中央化和分散化环境中进行 ML 训练和测试，并使用了 Fast Gradient Sign Method 和 DeepFool 生成抗性例子。</li>
<li>results: 在中央化环境中，我们实现了测试准确率为 65.41% 和 83.0%，比现有研究提高了 18.41% 和 47%。在分散化环境中，我们研究了 Federated learning（FL）的Robustness，并使用了 adversarial training 方法与独立同分布（IID）和非IID数据进行比较。在 IID 数据 caso，我们可以实现类似于中央化环境的Robust准确率。在非IID 数据 caso，自然准确率下降了 25% 和 23.4%，对比 IID 数据 caso，分别是。我们还提出了一种 IID 数据共享方法，可以提高自然准确率到 85.04% 和 Robust准确率从 57% 提高到 72% 和 67%，分别是。<details>
<summary>Abstract</summary>
As Machine Learning (ML) is increasingly used in solving various tasks in real-world applications, it is crucial to ensure that ML algorithms are robust to any potential worst-case noises, adversarial attacks, and highly unusual situations when they are designed. Studying ML robustness will significantly help in the design of ML algorithms. In this paper, we investigate ML robustness using adversarial training in centralized and decentralized environments, where ML training and testing are conducted in one or multiple computers. In the centralized environment, we achieve a test accuracy of 65.41% and 83.0% when classifying adversarial examples generated by Fast Gradient Sign Method and DeepFool, respectively. Comparing to existing studies, these results demonstrate an improvement of 18.41% for FGSM and 47% for DeepFool. In the decentralized environment, we study Federated learning (FL) robustness by using adversarial training with independent and identically distributed (IID) and non-IID data, respectively, where CIFAR-10 is used in this research. In the IID data case, our experimental results demonstrate that we can achieve such a robust accuracy that it is comparable to the one obtained in the centralized environment. Moreover, in the non-IID data case, the natural accuracy drops from 66.23% to 57.82%, and the robust accuracy decreases by 25% and 23.4% in C&W and Projected Gradient Descent (PGD) attacks, compared to the IID data case, respectively. We further propose an IID data-sharing approach, which allows for increasing the natural accuracy to 85.04% and the robust accuracy from 57% to 72% in C&W attacks and from 59% to 67% in PGD attacks.
</details>
<details>
<summary>摘要</summary>
随着机器学习（ML）在实际应用中的广泛使用， Ensuring the robustness of ML algorithms against potential worst-case noises, adversarial attacks, and highly unusual situations during their design has become crucial. Studying ML robustness can significantly help in the design of ML algorithms. In this paper, we investigate ML robustness using adversarial training in centralized and decentralized environments, where ML training and testing are conducted in one or multiple computers.在中央化环境中，我们通过对快速梯度方法和深度欺骗的挑战性例子进行反对抗教程，实现了测试精度为65.41%和83.0%。相比已有研究，这些结果表明了18.41%的提高 для快速梯度方法和47%的提高 для深度欺骗。在分布式学习（FL）环境中，我们研究了 Federated learning（FL）的可靠性，使用反对抗教程与独立且相同分布（IID）和非IID数据进行研究，其中CIFAR-10被用于这项研究。在IID数据情况下，我们的实验结果表明，我们可以实现与中央化环境相同的可靠性。此外，在非IID数据情况下，自然精度从66.23%降低到57.82%，而可靠精度下降25%和23.4%在C&W和投影梯度下降（PGD）攻击中，相比IID数据情况下。我们还提出了一种IID数据分享方法，可以提高自然精度到85.04%和可靠精度从57%提高到72%在C&W攻击中，并提高到67%在PGD攻击中。
</details></li>
</ul>
<hr>
<h2 id="BGF-YOLO-Enhanced-YOLOv8-with-Multiscale-Attentional-Feature-Fusion-for-Brain-Tumor-Detection"><a href="#BGF-YOLO-Enhanced-YOLOv8-with-Multiscale-Attentional-Feature-Fusion-for-Brain-Tumor-Detection" class="headerlink" title="BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for Brain Tumor Detection"></a>BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for Brain Tumor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12585">http://arxiv.org/abs/2309.12585</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkang315/bgf-yolo">https://github.com/mkang315/bgf-yolo</a></li>
<li>paper_authors: Ming Kang, Chee-Ming Ting, Fung Fung Ting, Raphaël C. -W. Phan</li>
<li>for: automated brain tumor detection</li>
<li>methods:  integrate Bi-level Routing Attention (BRA), Generalized feature pyramid networks (GFPN), and Fourth detecting head into YOLOv8</li>
<li>results: 4.7% absolute increase of mAP$_{50}$ compared to YOLOv8x, and achieves state-of-the-art on the brain tumor detection dataset Br35H.Here’s the full Chinese text:</li>
<li>for: 本研究旨在 automatized 脑癌检测</li>
<li>methods:  integrate Bi-level Routing Attention (BRA), Generalized feature pyramid networks (GFPN), 和 Fourth detecting head into YOLOv8</li>
<li>results: 与 YOLOv8x 相比，BGF-YOLO 提供 4.7% 的统计提升，并在脑癌检测 dataset Br35H 上 achievement state-of-the-art.I hope this helps!<details>
<summary>Abstract</summary>
You Only Look Once (YOLO)-based object detectors have shown remarkable accuracy for automated brain tumor detection. In this paper, we develop a novel BGF-YOLO architecture by incorporating Bi-level Routing Attention (BRA), Generalized feature pyramid networks (GFPN), and Fourth detecting head into YOLOv8. BGF-YOLO contains an attention mechanism to focus more on important features, and feature pyramid networks to enrich feature representation by merging high-level semantic features with spatial details. Furthermore, we investigate the effect of different attention mechanisms and feature fusions, detection head architectures on brain tumor detection accuracy. Experimental results show that BGF-YOLO gives a 4.7% absolute increase of mAP$_{50}$ compared to YOLOv8x, and achieves state-of-the-art on the brain tumor detection dataset Br35H. The code is available at https://github.com/mkang315/BGF-YOLO.
</details>
<details>
<summary>摘要</summary>
“你只需要看一次”（YOLO）基本的物体探测器已经在自动脑肿检测中表现出色。在这篇论文中，我们开发了一种新的BGF-YOLO架构，并将Bi-level Routing Attention（BRA）、Generalized feature pyramid networks（GFPN）和第四个探测头纳入YOLOv8。BGF-YOLO包含一种注意机制，以增强关键特征的注意力，并通过将高级 semantic features与空间细节合并来增强特征表示。此外，我们还 investigate了不同的注意机制和特征融合、探测头架构对脑肿检测精度的影响。实验结果表明，BGF-YOLO与YOLOv8x相比，提高了4.7%的mAP$_{50}$精度，并在脑肿检测数据集Br35H中达到了状态机。代码可以在https://github.com/mkang315/BGF-YOLO中获取。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-Alzheimers-Disease-with-Deep-Learning-on-Eye-tracking-Data"><a href="#Classification-of-Alzheimers-Disease-with-Deep-Learning-on-Eye-tracking-Data" class="headerlink" title="Classification of Alzheimers Disease with Deep Learning on Eye-tracking Data"></a>Classification of Alzheimers Disease with Deep Learning on Eye-tracking Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12574">http://arxiv.org/abs/2309.12574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshinee Sriram, Cristina Conati, Thalia Field</li>
<li>For: This paper aims to classify Alzheimer’s Disease (AD) from eye-tracking (ET) data using a Deep-Learning classifier trained end-to-end on raw ET data.* Methods: The proposed method, called VTNet, uses a GRU and a CNN in parallel to leverage both visual (V) and temporal (T) representations of ET data.* Results: VTNet outperforms the state-of-the-art approaches in AD classification, providing encouraging evidence on the generality of this model to make predictions from ET data.Here’s the Chinese translation of the three pieces of information:* For: 这篇论文目标是使用 Raw 眼动追踪数据进行扩散性疾病分类 (AD)。* Methods: 提议的方法是 VTNet，它使用 GRU 和 CNN 并行使用，以利用眼动数据中的视觉 (V) 和时间 (T) 表示。* Results: VTNet 在 AD 分类任务上表现出色，超过了现有的方法，提供了对这种模型在眼动数据上的预测性的有力证明。<details>
<summary>Abstract</summary>
Existing research has shown the potential of classifying Alzheimers Disease (AD) from eye-tracking (ET) data with classifiers that rely on task-specific engineered features. In this paper, we investigate whether we can improve on existing results by using a Deep-Learning classifier trained end-to-end on raw ET data. This classifier (VTNet) uses a GRU and a CNN in parallel to leverage both visual (V) and temporal (T) representations of ET data and was previously used to detect user confusion while processing visual displays. A main challenge in applying VTNet to our target AD classification task is that the available ET data sequences are much longer than those used in the previous confusion detection task, pushing the limits of what is manageable by LSTM-based models. We discuss how we address this challenge and show that VTNet outperforms the state-of-the-art approaches in AD classification, providing encouraging evidence on the generality of this model to make predictions from ET data.
</details>
<details>
<summary>摘要</summary>
先前的研究已经证明了通过眼动跟踪（ET）数据进行阿尔茨heimer病（AD）分类的潜在性。在这篇论文中，我们调查了是否可以通过使用深度学习的分类器，对直接使用原始ET数据进行分类，以提高现有结果。我们称之为VTNet，它使用GRU和CNN并行使用视觉（V）和时间（T）表示，曾用于检测视觉显示的混乱。主要挑战在应用VTNet到我们的target AD分类任务中是，ET数据序列的可用性远比先前的混乱检测任务更长，这使得LSTM模型管理的范围受到挑战。我们详细介绍了我们如何解决这个挑战，并示出VTNet在AD分类任务中的表现，超越了当前的状态艺术方法，提供了对ET数据进行预测的鼓励性证据。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-3D-Multi-Modal-Residual-Convolutional-Neural-Network-for-Mild-Traumatic-Brain-Injury-Diagnosis"><a href="#Interpretable-3D-Multi-Modal-Residual-Convolutional-Neural-Network-for-Mild-Traumatic-Brain-Injury-Diagnosis" class="headerlink" title="Interpretable 3D Multi-Modal Residual Convolutional Neural Network for Mild Traumatic Brain Injury Diagnosis"></a>Interpretable 3D Multi-Modal Residual Convolutional Neural Network for Mild Traumatic Brain Injury Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12572">http://arxiv.org/abs/2309.12572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanem Ellethy, Viktor Vegh, Shekhar S. Chandra</li>
<li>for: 这个研究旨在提高轻度头部创伤（mTBI）的诊断精度，并且使用多Modal的残差算法（MRCNN）和Occlusion Sensitivity Maps（OSM）来增强诊断模型的解释力。</li>
<li>methods: 这个研究使用了一个 interpretable 的 3D Multi-Modal Residual Convolutional Neural Network（MRCNN）模型，并且将 Occlusion Sensitivity Maps（OSM）加入了诊断模型中，以增强诊断的精度。</li>
<li>results: 研究结果显示，MRCNN 模型在 mTBI 诊断中表现出色，精度达 82.4%，sensitivity 达 82.6%，特异性达 81.6%，并且比 CT 基于的 Residual Convolutional Neural Network（RCNN）模型提高了 4.4% 的特异性和 9.0% 的精度。<details>
<summary>Abstract</summary>
Mild Traumatic Brain Injury (mTBI) is a significant public health challenge due to its high prevalence and potential for long-term health effects. Despite Computed Tomography (CT) being the standard diagnostic tool for mTBI, it often yields normal results in mTBI patients despite symptomatic evidence. This fact underscores the complexity of accurate diagnosis. In this study, we introduce an interpretable 3D Multi-Modal Residual Convolutional Neural Network (MRCNN) for mTBI diagnostic model enhanced with Occlusion Sensitivity Maps (OSM). Our MRCNN model exhibits promising performance in mTBI diagnosis, demonstrating an average accuracy of 82.4%, sensitivity of 82.6%, and specificity of 81.6%, as validated by a five-fold cross-validation process. Notably, in comparison to the CT-based Residual Convolutional Neural Network (RCNN) model, the MRCNN shows an improvement of 4.4% in specificity and 9.0% in accuracy. We show that the OSM offers superior data-driven insights into CT images compared to the Grad-CAM approach. These results highlight the efficacy of the proposed multi-modal model in enhancing the diagnostic precision of mTBI.
</details>
<details>
<summary>摘要</summary>
轻度头部Trauma (mTBI) 是一个重要的公共卫生挑战，因其高频率和长期健康影响的可能性。 Despite Computed Tomography (CT) 是 mTBI 的标准诊断工具，它经常在 mTBI 患者中显示正常结果，这再次 highlights 诊断的复杂性。 在这项研究中，我们介绍了一种可解释的 3D 多模态异常感知 Convolutional Neural Network (MRCNN) 模型，用于 mTBI 诊断。我们的 MRCNN 模型在 mTBI 诊断中表现出色，其中的平均准确率为 82.4%，敏感性为 82.6%，特异性为 81.6%，这些结果通过五次交叉验证过程得到验证。尤其是，相比 CT-based Residual Convolutional Neural Network (RCNN) 模型，我们的 MRCNN 模型在特异性和准确率方面增加了4.4%和9.0%。我们表明 OSM 在 CT 图像中提供了更高的数据驱动的权重，相比 Grad-CAM 方法。这些结果表明我们的多模态模型在 mTBI 诊断中增强了诊断精度。
</details></li>
</ul>
<hr>
<h2 id="Wave-informed-dictionary-learning-for-high-resolution-imaging-in-complex-media"><a href="#Wave-informed-dictionary-learning-for-high-resolution-imaging-in-complex-media" class="headerlink" title="Wave-informed dictionary learning for high-resolution imaging in complex media"></a>Wave-informed dictionary learning for high-resolution imaging in complex media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.12990">http://arxiv.org/abs/2310.12990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Moscoso, Alexei Novikov, George Papanicolaou, Chrysoula Tsogka</li>
<li>for: 这个论文目的是提出一种用于吸收媒体成像的方法，当有大量和多样化的数据集available时。</li>
<li>methods: 该方法有两个步骤：第一步使用字典学习算法来估计真正的绿函数向量，并将其作为列存储在一个不ordered的感测矩阵中。第二步使用多维度排序法来让列表的排序，并使用连接信息来 derive from cross-correlations of its columns，如时间反转。</li>
<li>results: 通过 simulation experiments，我们示出了该方法能够在复杂媒体中提供高分辨率的成像图像。<details>
<summary>Abstract</summary>
We propose an approach for imaging in scattering media when large and diverse data sets are available. It has two steps. Using a dictionary learning algorithm the first step estimates the true Green's function vectors as columns in an unordered sensing matrix. The array data comes from many sparse sets of sources whose location and strength are not known to us. In the second step, the columns of the estimated sensing matrix are ordered for imaging using Multi-Dimensional Scaling with connectivity information derived from cross-correlations of its columns, as in time reversal. For these two steps to work together we need data from large arrays of receivers so the columns of the sensing matrix are incoherent for the first step, as well as from sub-arrays so that they are coherent enough to obtain the connectivity needed in the second step. Through simulation experiments, we show that the proposed approach is able to provide images in complex media whose resolution is that of a homogeneous medium.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，用于在散射媒体中进行成像，当有大量多样化的数据集 disponible。该方法包括两步。在第一步中，使用一个词汇学算法，我们估算了真实的绿函数向量作为排序后的感知矩阵的列。数组数据来自多个稀疏的源集，其位置和强度不知道我们。在第二步中，我们使用多维度尺度学（Multi-Dimensional Scaling）将排序后的感知矩阵的列轴进行了排序，并使用这些列的垂直相关性来获得连接信息。为了使这两个步骤可以共同工作，我们需要从大型接收器阵列中获得数据，以确保感知矩阵的列不受相关性的限制。通过实验 simulate, we show that the proposed approach can provide images in complex media with resolution comparable to that of a homogeneous medium.Note: The translation is provided "as is" and may not be perfect. Please let me know if you need any further assistance or clarification.
</details></li>
</ul>
<hr>
<h2 id="Triple-View-Knowledge-Distillation-for-Semi-Supervised-Semantic-Segmentation"><a href="#Triple-View-Knowledge-Distillation-for-Semi-Supervised-Semantic-Segmentation" class="headerlink" title="Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation"></a>Triple-View Knowledge Distillation for Semi-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12557">http://arxiv.org/abs/2309.12557</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Ping Li, Junjie Chen, Li Yuan, Xianghua Xu, Mingli Song</li>
<li>for: 提高 semi-supervised semantic segmentation 的效果，使用少量标注图像和大量非标注图像预测像素级标签图。</li>
<li>methods: 使用 tri-training 和 triple-view encoder 来捕捉多样化特征，并通过知识储存技术学习对应的 semantics。 dual-frequency decoder 选择重要特征，并通过双频道注意机制来评估特征重要性。</li>
<li>results: 在 Pascal VOC 2012 和 Cityscapes 两个标准测试集上进行了广泛的实验，结果表明提出的方法在精度和推理速度之间做出了好的平衡，并且与其他方法相比具有更好的性能。<details>
<summary>Abstract</summary>
To alleviate the expensive human labeling, semi-supervised semantic segmentation employs a few labeled images and an abundant of unlabeled images to predict the pixel-level label map with the same size. Previous methods often adopt co-training using two convolutional networks with the same architecture but different initialization, which fails to capture the sufficiently diverse features. This motivates us to use tri-training and develop the triple-view encoder to utilize the encoders with different architectures to derive diverse features, and exploit the knowledge distillation skill to learn the complementary semantics among these encoders. Moreover, existing methods simply concatenate the features from both encoder and decoder, resulting in redundant features that require large memory cost. This inspires us to devise a dual-frequency decoder that selects those important features by projecting the features from the spatial domain to the frequency domain, where the dual-frequency channel attention mechanism is introduced to model the feature importance. Therefore, we propose a Triple-view Knowledge Distillation framework, termed TriKD, for semi-supervised semantic segmentation, including the triple-view encoder and the dual-frequency decoder. Extensive experiments were conducted on two benchmarks, \ie, Pascal VOC 2012 and Cityscapes, whose results verify the superiority of the proposed method with a good tradeoff between precision and inference speed.
</details>
<details>
<summary>摘要</summary>
要解决高严格的人类标注成本高昂，半supervised semantic segmentation使用一些标注图像和大量无标注图像预测像素级标签地图，同时使用两个 convolutional network 的不同初始化来提高分类精度。以前的方法通常采用两个 convolutional network 的同 architectures 的 co-training，但这会遗漏重要的多样化特征。这种情况驱使我们使用 tri-training 和三个视角编码器，以利用不同的架构来获得多样化的特征，并利用知识填充技术来学习这些编码器之间的补做 semantics。此外，现有的方法通常将编码器和解码器的特征直接 concatenate，从而导致缓存成本过高。这个灵感我们提出了一种 dual-frequency decoder，可以选择重要的特征，并通过将特征从空间频谱中 проек到频谱频率上，实现了 dual-frequency channel attention mechanism。因此，我们提出了一种 Triple-view Knowledge Distillation框架，称之为 TriKD，用于半supervised semantic segmentation，包括三个视角编码器和 dual-frequency decoder。我们在 Pascal VOC 2012 和 Cityscapes 两个标准benchmark上进行了广泛的实验，结果证明了我们提出的方法具有较好的平衡性和推理速度。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/cs.CV_2023_09_22/" data-id="clp9qz84a00kbok88h1n6fjfo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/cs.AI_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T12:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/cs.AI_2023_09_22/">cs.AI - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Poster-Self-Supervised-Quantization-Aware-Knowledge-Distillation"><a href="#Poster-Self-Supervised-Quantization-Aware-Knowledge-Distillation" class="headerlink" title="Poster: Self-Supervised Quantization-Aware Knowledge Distillation"></a>Poster: Self-Supervised Quantization-Aware Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13220">http://arxiv.org/abs/2309.13220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiqi Zhao, Ming Zhao</li>
<li>for: 提高量化敏感模型的性能</li>
<li>methods: 提出了一种新的无监督自适应量化敏感知识传递（SQAKD）框架，通过同时Minimize KL损失和精度损失来协调量化和敏感知识传递。</li>
<li>results: 对多种现有QAT研究进行评估，显示SQAKD可以显著提高量化敏感模型的性能，并不需要大量标注数据。<details>
<summary>Abstract</summary>
Quantization-aware training (QAT) starts with a pre-trained full-precision model and performs quantization during retraining. However, existing QAT works require supervision from the labels and they suffer from accuracy loss due to reduced precision. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation framework (SQAKD). SQAKD first unifies the forward and backward dynamics of various quantization functions and then reframes QAT as a co-optimization problem that simultaneously minimizes the KL-Loss and the discretization error, in a self-supervised manner. The evaluation shows that SQAKD significantly improves the performance of various state-of-the-art QAT works. SQAKD establishes stronger baselines and does not require extensive labeled training data, potentially making state-of-the-art QAT research more accessible.
</details>
<details>
<summary>摘要</summary>
Quantization-aware training (QAT) 开始于一个预训练的全精度模型，并在重新训练期间进行量化。然而，现有的 QAT 工作受到标签的监督，并且受到精度降低的影响，导致准确性下降。为解决这些限制，本文提出了一种新的 Self-Supervised Quantization-Aware Knowledge Distillation 框架 (SQAKD)。SQAKD 首先将量化函数的前向和反向动力统一，然后将 QAT 重新定义为一个同时减少 KL-损失和精度损失的合理化问题，在自我监督的方式下进行解决。评估结果表明，SQAKD 可以显著提高不同的状态前训练 QAT 工作的性能。SQAKD 设立了更强的基线，并不需要大量的标签训练数据，可能使状态前训练 QAT 研究更加可 accessible。
</details></li>
</ul>
<hr>
<h2 id="AI-Copilot-for-Business-Optimisation-A-Framework-and-A-Case-Study-in-Production-Scheduling"><a href="#AI-Copilot-for-Business-Optimisation-A-Framework-and-A-Case-Study-in-Production-Scheduling" class="headerlink" title="AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling"></a>AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13218">http://arxiv.org/abs/2309.13218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pivithuru Thejan Amarasinghe, Su Nguyen, Yuan Sun, Damminda Alahakoon</li>
<li>for: 这个论文的目的是提出一种基于大语言模型（LLM）的企业优化问题表述 Synthesizer，以减少人工智能的参与度。</li>
<li>methods: 该论文采用了练好LLM的 fine-tuning方法，并提出了一种AI copilot的设计方法以及模块化和提示工程技术来解决问题表述中的卡通问题。</li>
<li>results: 实验结果显示，通过该方法可以synthesize大型和复杂的企业优化问题表述，并且可以在生产规划中应用。<details>
<summary>Abstract</summary>
Business optimisation refers to the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation, which relies on human expertise to construct problem formulations using optimisation languages. Interestingly, with advancements in Large Language Models (LLMs), the human expertise needed in problem formulation can be minimized. However, developing an LLM for problem formulation is challenging, due to training data, token limitations, and lack of appropriate performance metrics. For the requirement of training data, recent attention has been directed towards fine-tuning pre-trained LLMs for downstream tasks rather than training an LLM from scratch for a specific task. In this paper, we adopt an LLM fine-tuning approach and propose an AI-Copilot for business optimisation problem formulation. For token limitations, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. Additionally, we design performance evaluation metrics that are better suited for assessing the accuracy and quality of problem formulations. The experiment results demonstrate that with this approach we can synthesize complex and large problem formulations for a typical business optimisation problem in production scheduling.
</details>
<details>
<summary>摘要</summary>
Despite the potential benefits of using LLMs for problem formulation, there are several challenges that need to be addressed. One of the main challenges is the lack of training data, which makes it difficult to train an LLM from scratch for a specific task. To address this challenge, recent attention has been directed towards fine-tuning pre-trained LLMs for downstream tasks.In this paper, we adopt an LLM fine-tuning approach and propose an AI-Copilot for business optimization problem formulation. To overcome the token limitations of LLMs, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. Additionally, we design performance evaluation metrics that are better suited for assessing the accuracy and quality of problem formulations.The experiment results demonstrate that with this approach, we can synthesize complex and large problem formulations for a typical business optimization problem in production scheduling. This shows that our proposed AI-Copilot can effectively assist businesses in optimizing their operations and gaining a competitive advantage.
</details></li>
</ul>
<hr>
<h2 id="MISFIT-V-Misaligned-Image-Synthesis-and-Fusion-using-Information-from-Thermal-and-Visual"><a href="#MISFIT-V-Misaligned-Image-Synthesis-and-Fusion-using-Information-from-Thermal-and-Visual" class="headerlink" title="MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual"></a>MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13216">http://arxiv.org/abs/2309.13216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aadharc/Visual_Thermal_Image_Fusion">https://github.com/Aadharc/Visual_Thermal_Image_Fusion</a></li>
<li>paper_authors: Aadhar Chauhan, Isaac Remy, Danny Broyles, Karen Leung</li>
<li>for: 本研究旨在提高搜救队伍在霍尔风景中从空中视觉和热成像中检测人员，以提高搜救效率和准确率。</li>
<li>methods: 该研究提出了一种基于Generative Adversarial Network（GAN）和带通信机制的两元深度学习方法，名为Misaligned Image Synthesis and Fusion using Information from Thermal and Visual（MISFIT-V），用于把视觉和热成像模态进行图像 fusión。</li>
<li>results: 实验结果表明，MISFIT-V方法在环境因素不利的情况下具有更高的 robustness 性和精度，比如融合图像中的人员检测结果。<details>
<summary>Abstract</summary>
Detecting humans from airborne visual and thermal imagery is a fundamental challenge for Wilderness Search-and-Rescue (WiSAR) teams, who must perform this function accurately in the face of immense pressure. The ability to fuse these two sensor modalities can potentially reduce the cognitive load on human operators and/or improve the effectiveness of computer vision object detection models. However, the fusion task is particularly challenging in the context of WiSAR due to hardware limitations and extreme environmental factors. This work presents Misaligned Image Synthesis and Fusion using Information from Thermal and Visual (MISFIT-V), a novel two-pronged unsupervised deep learning approach that utilizes a Generative Adversarial Network (GAN) and a cross-attention mechanism to capture the most relevant features from each modality. Experimental results show MISFIT-V offers enhanced robustness against misalignment and poor lighting/thermal environmental conditions compared to existing visual-thermal image fusion methods.
</details>
<details>
<summary>摘要</summary>
搜寻人员从空中视觉和热影像中识别是搜寻和救援队（WiSAR）的基本挑战，需要在压力很大的情况下准确完成。将这两种感知模式融合可能可以减轻人工操作员的认知负担和/或提高计算机视觉对象检测模型的效果。然而，在WiSAR中融合任务 particullay challenging due to hardware limitations and extreme environmental factors。这篇文章介绍了一种新的两重无监督深度学习方法，即 Misaligned Image Synthesis and Fusion using Information from Thermal and Visual（MISFIT-V）。该方法使用生成 adversarial network（GAN）和跨注意机制来捕捉每个模式中最相关的特征。实验结果表明，MISFIT-V在不同的拍摄角度和热环境下具有更高的鲁棒性，相比之下现有的视觉热像重构方法。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Impact-of-Personality-on-Affective-States-from-Video-Game-Communication"><a href="#Assessing-the-Impact-of-Personality-on-Affective-States-from-Video-Game-Communication" class="headerlink" title="Assessing the Impact of Personality on Affective States from Video Game Communication"></a>Assessing the Impact of Personality on Affective States from Video Game Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13214">http://arxiv.org/abs/2309.13214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atieh Kashani, Johannes Pfau, Magy Seif El-Nasr</li>
<li>for: This paper explores the impact of personality on the way players express themselves affectively in a team-based collaborative alternate reality game.</li>
<li>methods: The authors collected chat logs from eleven players over two weeks, labeled them according to their affective state, and assessed the connection between them and the five-factor personality domains and facets using multi-linear regression.</li>
<li>results: The study found a series of reasonable correlations between (combinations of) personality variables and expressed affect, including increased confusion predicted by lower self-competence, personal annoyance predicted by vulnerability to stress, and expressing anger more often in players prone to anxiety.<details>
<summary>Abstract</summary>
Individual differences in personality determine our preferences, traits and values, which should similarly hold for the way we express ourselves. With current advancements and transformations of technology and society, text-based communication has become ordinary and often even surpasses natural voice conversations -- with distinct challenges and opportunities. In this exploratory work, we investigate the impact of personality on the tendency how players of a team-based collaborative alternate reality game express themselves affectively. We collected chat logs from eleven players over two weeks, labeled them according to their affective state, and assessed the connection between them and the five-factor personality domains and facets. After applying multi-linear regression, we found a series of reasonable correlations between (combinations of) personality variables and expressed affect -- as increased confusion could be predicted by lower self-competence (C1), personal annoyance by vulnerability to stress (N6) and expressing anger occured more often in players that are prone to anxiety (N1), less humble and modest (A5), think less carefully before they act (C6) and have higher neuroticism (N). Expanding the data set, sample size and input modalities in subsequent work, we aim to confirm these findings and reveal even more interesting connections that could inform affective computing and games user research equally.
</details>
<details>
<summary>摘要</summary>
人类个体差异对我们的偏好、特质和价值产生影响，这一点应该在我们的表达方式上也有影响。随着技术和社会的发展，文本基本上已经成为了日常交流的一种常见方式，有时甚至超过了自然语音交流。在这项探索性研究中，我们 investigate了玩家在团队合作 alternate reality 游戏中表达情感的影响。我们收集了11名玩家的聊天记录，将其分为不同情感状态，并评估了这些状态与五大人格特征域和特征之间的连接。经多线性回归分析，我们发现了一系列合理的相关关系，例如：增加混乱可以预测低自我竞争力（C1）、个人恼怒可以预测脆弱性（N6），表达愤怒更常见于具有 anxiety（N1）、不谦虚和谨慎（A5）、不思议行为（C6）和高度neurótico（N）。在后续工作中，我们计划扩大数据集、样本大小和输入模式，以确认这些发现和揭示更多的 interessante 连接，以便在情感计算和游戏用户研究中具有参考意义。
</details></li>
</ul>
<hr>
<h2 id="Intent-Aware-Autonomous-Driving-A-Case-Study-on-Highway-Merging-Scenarios"><a href="#Intent-Aware-Autonomous-Driving-A-Case-Study-on-Highway-Merging-Scenarios" class="headerlink" title="Intent-Aware Autonomous Driving: A Case Study on Highway Merging Scenarios"></a>Intent-Aware Autonomous Driving: A Case Study on Highway Merging Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13206">http://arxiv.org/abs/2309.13206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nishtha Mahajan, Qi Zhang</li>
<li>for: 本研究使用汽车自动控制器之间的意图交换来促进协作。</li>
<li>methods: 我们在高速公路环境 simulator 中实现了意图分享任务，并在两个代理之间进行了 investigate  highway 合并场景中意图分享如何 помо助接收方调整其行为。</li>
<li>results: 我们发现，通过意图分享，接收方可以更好地适应高速公路合并场景，提高了合并效率和安全性。<details>
<summary>Abstract</summary>
In this work, we use the communication of intent as a means to facilitate cooperation between autonomous vehicle agents. Generally speaking, intents can be any reliable information about its future behavior that a vehicle communicates with another vehicle. We implement this as an intent-sharing task atop the merging environment in the simulator of highway-env, which provides a collection of environments for learning decision-making strategies for autonomous vehicles. Under a simple setting between two agents, we carefully investigate how intent-sharing can aid the receiving vehicle in adjusting its behavior in highway merging scenarios.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们使用意图通信作为自动驾驶车辆间合作的方式。一般来说，意图可以是任何可靠地关于未来行为的信息，车辆通过这些信息与另一辆车辆进行交流。我们在高速公路环境 simulator 中实现了意图分享任务，提供了一个收集多种决策策略学习自动驾驶车辆的环境。在简单的两辆车辆之间的设定下，我们仔细研究了意图分享如何帮助接收车辆在高速公路做入道场景中调整其行为。
</details></li>
</ul>
<hr>
<h2 id="A-Practical-Survey-on-Zero-shot-Prompt-Design-for-In-context-Learning"><a href="#A-Practical-Survey-on-Zero-shot-Prompt-Design-for-In-context-Learning" class="headerlink" title="A Practical Survey on Zero-shot Prompt Design for In-context Learning"></a>A Practical Survey on Zero-shot Prompt Design for In-context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13205">http://arxiv.org/abs/2309.13205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinheng Li<br>for: 这篇论文旨在探讨各种提示技术，包括简洁、连续、几何shot和零shot提示，以及它们对大语言模型（LLM）性能的影响。methods: 论文检讨了不同提示设计方法，包括手动设计、优化算法和评估方法，以优化LLM在多种任务上的性能。results: 论文总结了关键的研究成果，包括提示工程的方法学和贡献，以及评估提示性能的挑战。<details>
<summary>Abstract</summary>
The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques, focusing on different types of prompts, including discrete, continuous, few-shot, and zero-shot, and their impact on LLM performance. We explore various approaches to prompt design, such as manual design, optimization algorithms, and evaluation methods, to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering, discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance, given the absence of a single "best" prompt and the importance of considering multiple metrics. In conclusion, the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design, optimization techniques, and rigorous evaluation for more effective and efficient use of LLMs in various NLP tasks.
</details>
<details>
<summary>摘要</summary>
LLMs 的卓越发展对自然语言处理(NLP)任务带来了重要的改善。本文提供了对Context Learning技术的完整回顾，包括不同类型的提示，如离散、连续、少量和零 shot，以及它们对 LLM 性能的影响。我们探讨了不同的提示设计方法，如手动设计、优化算法和评估方法，以优化 LLM 在多种任务上的性能。我们的回顾包括关键的研究成果在提示工程学，讨论了他们的方法和贡献。此外，我们还探讨了评估提示性能的挑战，因为没有单一的 "最佳" 提示，以及考虑多种维度的益虑。结束语，本文强调了提示设计的重要性，并提供了手动设计、优化技术和严格评估的组合，以更有效地和高效地使用 LLM 在多种 NLP 任务中。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Control-Mechanisms-Improve-Text-Readability-of-Biomedical-Abstracts"><a href="#Large-Language-Models-and-Control-Mechanisms-Improve-Text-Readability-of-Biomedical-Abstracts" class="headerlink" title="Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts"></a>Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13202">http://arxiv.org/abs/2309.13202</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hecta-uom/plaba-mu">https://github.com/hecta-uom/plaba-mu</a></li>
<li>paper_authors: Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic<br>for: 本研究旨在提高生物医学领域文献的可读性，使用自然语言处理（NLP）模型自动化报告简化任务，提高公共健康文化知识。methods: 本研究使用现代大语言模型（LLMs）对生物医学报告简化任务进行研究，包括领域细化和提示基本学习（PBL），以及控制符 token 机制。results: 研究使用了多种自动评价指标，包括 BLEU、ROUGE、SARI 和 BERTscore，以及人类评价。 BART-Large  WITH Control Token（BART-L-w-CT）机制得到了最高 SARI 分数46.54，T5-base 得到了最高 BERTscore 72.62。在人类评价中，BART-L-w-CTs 获得了更好的简单性分数（2.9 vs. 2.2），而 T5-Base 获得了更好的意义保持分数（3.1 vs. 2.6）。<details>
<summary>Abstract</summary>
Biomedical literature often uses complex language and inaccessible professional terminologies. That is why simplification plays an important role in improving public health literacy. Applying Natural Language Processing (NLP) models to automate such tasks allows for quick and direct accessibility for lay readers. In this work, we investigate the ability of state-of-the-art large language models (LLMs) on the task of biomedical abstract simplification, using the publicly available dataset for plain language adaptation of biomedical abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT, and 3) Control-token mechanisms on BART-based models. We used a range of automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT) mechanisms reported the highest SARI score of 46.54 and T5-base reported the highest BERTscore 72.62. In human evaluation, BART-L-w-CTs achieved a better simplicity score over T5-Base (2.9 vs. 2.2), while T5-Base achieved a better meaning preservation score over BART-L-w-CTs (3.1 vs. 2.6). We also categorised the system outputs with examples, hoping this will shed some light for future research on this task. Our code, fine-tuned models, and data splits are available at \url{https://github.com/HECTA-UoM/PLABA-MU}
</details>
<details>
<summary>摘要</summary>
生物医学文献经常使用复杂的语言和不可接触的专业术语，这使得公众健康文化知识的提高受到了限制。因此，简化对于改善公众健康文化知识具有重要的作用。在这项工作中，我们研究了现状最佳的大型自然语言处理（NLP）模型在生物医学摘要简化任务上的能力，使用公共可用的PLABA数据集（plain language adaptation of biomedical abstracts）。我们使用的方法包括域特化 fine-tuning 和提示基本学习（PBL），其中包括：1）Encoder-decoder模型（T5、SciFive和BART），2）Decoder-only GPT模型（GPT-3.5和GPT-4）和3）BART基于模型中的控制符机制。我们使用了一系列自动评估指标，包括BLEU、ROUGE、SARI和BERTscore，并也进行了人类评估。BART-Large with Control Token（BART-L-w-CT）机制获得了46.54的SARI分数，T5-base获得了72.62的BERTscore。在人类评估中，BART-L-w-CTs在 simplicity 分数上赢得了2.9 VS T5-Base的2.2，而T5-Base在 meaning preservation 分数上赢得了3.1 VS BART-L-w-CTs的2.6。我们还将系统输出分类并提供了示例，希望这可以为未来这个任务提供一些灯光。我们的代码、精度调整模型和数据分割可以在https://github.com/HECTA-UoM/PLABA-MU 中获取。
</details></li>
</ul>
<hr>
<h2 id="Towards-Green-AI-in-Fine-tuning-Large-Language-Models-via-Adaptive-Backpropagation"><a href="#Towards-Green-AI-in-Fine-tuning-Large-Language-Models-via-Adaptive-Backpropagation" class="headerlink" title="Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation"></a>Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13192">http://arxiv.org/abs/2309.13192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pittisl/greentrainer">https://github.com/pittisl/greentrainer</a></li>
<li>paper_authors: Kai Huang, Hanyun Yin, Heng Huang, Wei Gao</li>
<li>for: 这个研究旨在提高大型自然语言模型（LLM）的精细化过程中的能效性，以减少环境影响。</li>
<li>methods: 这个研究使用了一新的绿色精细化技术（GreenTrainer），可以根据不同的网络层次和精细化目标，选择最适合的网络层次和精细化方法，以最大化精细化效率和降低总计算量（FLOPs）。</li>
<li>results: 实验结果显示，比较于精细化整个LLM模型，GreenTrainer可以降低总计算量（FLOPs）达64%，而且与其他已有的精细化技术相比，GreenTrainer可以实现更高的模型准确度和相似的总计算量降低。<details>
<summary>Abstract</summary>
Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most appropriate set of tensors in training. Such selection in GreenTrainer is made based on a given objective of FLOPs reduction, which can flexibly adapt to the carbon footprint in energy supply and the need in Green AI. Experiment results over multiple open-sourced LLM models and abstractive summarization datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy loss. Compared to the existing fine-tuning techniques such as LoRa, GreenTrainer can achieve up to 4% improvement on model accuracy with on-par FLOPs reduction.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）的先进修改是下游应用最有效的方法。随着AI应用的快速发展和开源LLM的普及，非专家个人也可以进行修改，但是全球范围内的修改具有极高的能源消耗和碳脚印，可能对环境产生很大的影响。为了 Mitigating这些环境影响，我们在这篇论文中提出了GreenTrainer，一种新的LLM修改技术，可以自动评估不同张量的反射成本和精度贡献，以最小化修改成本。这种选择在GreenTrainer中是基于一个给定的硬件成本目标，可以适应不同的能源供应和绿色AI的需求。实验结果表明，相比于整个LLM模型的修改，GreenTrainer可以在不同的开源LLM模型和概括摘要 datasets 上节省到64%的FLOPs，而无需 sacrifiSing model精度。相比之下，与LoRa等现有的修改技术，GreenTrainer可以达到4%的模型精度提升，同时具有相同的FLOPs减少。
</details></li>
</ul>
<hr>
<h2 id="Masked-Discriminators-for-Content-Consistent-Unpaired-Image-to-Image-Translation"><a href="#Masked-Discriminators-for-Content-Consistent-Unpaired-Image-to-Image-Translation" class="headerlink" title="Masked Discriminators for Content-Consistent Unpaired Image-to-Image Translation"></a>Masked Discriminators for Content-Consistent Unpaired Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13188">http://arxiv.org/abs/2309.13188</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bonifazstuhr/feamgan">https://github.com/bonifazstuhr/feamgan</a></li>
<li>paper_authors: Bonifaz Stuhr, Jürgen Brauer, Bernhard Schick, Jordi Gonzàlez</li>
<li>for: 这篇论文的目的是提高零对零图像转换的效能，尤其是在实际应用中遇到的问题，例如内容不一致和模式转换问题。</li>
<li>methods: 这篇论文使用的方法包括对全球检测器的输入进行封页，并使用对照抽样法选取小图像组合，以及对生成器流中的内容统计进行选择性标准化。</li>
<li>results: 这篇论文的实验结果显示，使用这些方法可以大幅提高零对零图像转换的效能，特别是在实际应用中的图像转换和天气转换领域。此外，论文还提出了一个新的评估指标（cKVD），可以更好地评估图像转换的质量。<details>
<summary>Abstract</summary>
A common goal of unpaired image-to-image translation is to preserve content consistency between source images and translated images while mimicking the style of the target domain. Due to biases between the datasets of both domains, many methods suffer from inconsistencies caused by the translation process. Most approaches introduced to mitigate these inconsistencies do not constrain the discriminator, leading to an even more ill-posed training setup. Moreover, none of these approaches is designed for larger crop sizes. In this work, we show that masking the inputs of a global discriminator for both domains with a content-based mask is sufficient to reduce content inconsistencies significantly. However, this strategy leads to artifacts that can be traced back to the masking process. To reduce these artifacts, we introduce a local discriminator that operates on pairs of small crops selected with a similarity sampling strategy. Furthermore, we apply this sampling strategy to sample global input crops from the source and target dataset. In addition, we propose feature-attentive denormalization to selectively incorporate content-based statistics into the generator stream. In our experiments, we show that our method achieves state-of-the-art performance in photorealistic sim-to-real translation and weather translation and also performs well in day-to-night translation. Additionally, we propose the cKVD metric, which builds on the sKVD metric and enables the examination of translation quality at the class or category level.
</details>
<details>
<summary>摘要</summary>
通常的目标对于无配对图像到图像翻译是保持源图像和翻译图像的内容一致性，同时模仿目标领域的样式。由于两个频谱的数据集之间存在偏见，许多方法受到翻译过程中的不一致性的影响。大多数引入的方法不约束探测器，导致训练 setup 更加不确定。此外，这些方法没有考虑更大的融合尺度。在这种情况下，我们表明，对两个频谱的总探测器的输入进行内容基于的蒙版是可以减少内容不一致性的。然而，这种策略会导致蒙版过程中的痕迹。为了减少这些痕迹，我们引入了一个本地探测器，该探测器在两个小尺度的匹配对上运行。此外，我们采用这种匹配策略来选择全局输入尺度上的源和目标数据集的输入。此外，我们提出了内容基于的降ormalization来选择性地包含生成器流中的内容统计。在我们的实验中，我们发现我们的方法可以在实际图像到图像翻译中达到领先的性能，并且在天气翻译和白天到夜晚翻译中也表现良好。此外，我们提出了 cKVD 指标，它基于 sKVD 指标，可以对翻译质量进行分类或类别级别的评估。
</details></li>
</ul>
<hr>
<h2 id="Diagnosing-and-exploiting-the-computational-demands-of-videos-games-for-deep-reinforcement-learning"><a href="#Diagnosing-and-exploiting-the-computational-demands-of-videos-games-for-deep-reinforcement-learning" class="headerlink" title="Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning"></a>Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13181">http://arxiv.org/abs/2309.13181</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lakshmi Narasimhan Govindarajan, Rex G Liu, Drew Linsley, Alekh Karkada Ashok, Max Reuter, Michael J Frank, Thomas Serre</li>
<li>for: 这篇论文旨在探讨深度强化学习（dRL）算法是否可以在视频游戏中学习如人类一样，以及这些成功是由视觉表示学习或强化学习算法的发现更好策略带来的。</li>
<li>methods: 作者提出了学习挑战诊断器（LCD）工具，用于分解任务中的视觉学习和强化学习需求。通过LCD，作者在Procgenbenchmark中发现了一种新的挑战分类，并证明这些预测具有高可靠性和可以指导算法开发。</li>
<li>results: 作者通过LCD发现了多种在优化dRL算法上整个视频游戏benchmark时出现的失败案例，并提供了更有效的进程路径。<details>
<summary>Abstract</summary>
Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like Procgen, and provides a pathway towards more efficient progress.
</details>
<details>
<summary>摘要</summary>
人类学习通过与环境互动和行为结果互动。人工智能领域的一个里程碑是开发深度奖励学习（dRL）算法，能够在电子游戏中学习，与人类或更好的性能。然而，未知 Whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both。为解决这个问题，我们引入学习挑战评价器（LCD），一种能够分解任务的视觉和奖励学习需求。我们使用LCD发现了Procgenbenchmark中的一种新分类器，并证明这些预测具有高可靠性和可以指导算法开发。更广泛地说，LCD揭示了优化dRL算法整个电子游戏benchmark like Procgen时可能出现的多种失败情况，并提供了更有效的进程。
</details></li>
</ul>
<hr>
<h2 id="AI-Risk-Profiles-A-Standards-Proposal-for-Pre-Deployment-AI-Risk-Disclosures"><a href="#AI-Risk-Profiles-A-Standards-Proposal-for-Pre-Deployment-AI-Risk-Disclosures" class="headerlink" title="AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures"></a>AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13176">http://arxiv.org/abs/2309.13176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eli Sherman, Ian W. Eisenberg</li>
<li>for: 本研究旨在提出一种风险评估标准，用于导引下游决策，包括评估风险、购买和部署，以及指导法规制定。</li>
<li>methods: 本研究使用了作者提出的AI风险分类法，将广泛的风险提议分类到高级分类层次。furthermore, the authors propose a template-based methodology for collating risk information into a standard, yet flexible, structure.</li>
<li>results: 作者采用公开可用信息，应用这种方法对许多知名的AI系统进行了风险评估。结果显示，这种方法可以帮助consumers更好地理解AI系统的风险，并且可以导引下游决策。<details>
<summary>Abstract</summary>
As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide variety of risks proposed in the literature. We outline the myriad data sources needed to construct informative Risk Profiles and propose a template-based methodology for collating risk information into a standard, yet flexible, structure. We apply this methodology to a number of prominent AI systems using publicly available information. To conclude, we discuss design decisions for the profiles and future work.
</details>
<details>
<summary>摘要</summary>
随着人工智能系统的复杂性和普及度的增加，关注这些风险的意识也在不断增长（索金等2023年）。作为回应，各方强调了更加强制的披透和透明度在人工智能业务中（NTIA等2023年；OpenAI等2023年），并提出了从技术披透标准化到未定许可证 regime（ sindhu等2023年）。由于人工智能价值链非常复杂，各个参与者具有不同的专业知识、观点和价值观，因此在下游决策过程中，披透报告的消费者必须能够理解关注的人工智能系统风险。在这篇论文中，我们提议了一个风险评估标准，可以导引下游决策，包括抢救进一步风险评估、指导采购和部署，以及指导法规框架。这个标准基于我们提议的人工智能风险分类体系，该分类体系反映了Literature中提出的广泛的风险。我们描述了构建信息的各种数据来源，并提议一种模板基于的方法来整理风险信息 into a standard， yet flexible 的结构。我们应用这种方法到了一些公开available的人工智能系统上。最后，我们讨论了配置风险profile的设计决策和未来工作。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Efficient-Deep-Learning-Architectures-For-Side-Channel-Attacks-on-AES"><a href="#Investigating-Efficient-Deep-Learning-Architectures-For-Side-Channel-Attacks-on-AES" class="headerlink" title="Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES"></a>Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13170">http://arxiv.org/abs/2309.13170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yohaï-Eliel Berreby, Laurent Sauvage</li>
<li>for: 这项研究是为了提高深度学习在嵌入式 криптографических应用中的攻击效率，并减少计算资源和数据量的成本。</li>
<li>methods: 这项研究使用了 JAX 框架，并 investigate 了不同的 Transformer 模型，以便复制和提高先前的结果。</li>
<li>results: 研究人员在 ANSSI Side-Channel Attack Database (ASCAD) 上实现了一些先前已知的攻击结果，并在这些结果的基础之上做出了进一步的改进。<details>
<summary>Abstract</summary>
Over the past few years, deep learning has been getting progressively more popular for the exploitation of side-channel vulnerabilities in embedded cryptographic applications, as it offers advantages in terms of the amount of attack traces required for effective key recovery. A number of effective attacks using neural networks have already been published, but reducing their cost in terms of the amount of computing resources and data required is an ever-present goal, which we pursue in this work. We focus on the ANSSI Side-Channel Attack Database (ASCAD), and produce a JAX-based framework for deep-learning-based SCA, with which we reproduce a selection of previous results and build upon them in an attempt to improve their performance. We also investigate the effectiveness of various Transformer-based models.
</details>
<details>
<summary>摘要</summary>
在过去几年，深度学习在嵌入式加密应用中利用侧渠攻击的潜力得到了普遍的推广，因为它在关键恢复方面提供了更多的优势。许多使用神经网络的有效攻击已经发表，但减少计算资源和数据需求的成本仍然是一个持续的目标。我们在这种工作中关注ASCAD侧渠攻击数据库（ANSSI Side-Channel Attack Database），并基于JAX框架开发了深度学习基于SCA的框架，可以重现一些先前的结果并将其扩展以提高性能。我们还研究了不同的Transformer模型的效果。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Are-Also-Good-Prototypical-Commonsense-Reasoners"><a href="#Large-Language-Models-Are-Also-Good-Prototypical-Commonsense-Reasoners" class="headerlink" title="Large Language Models Are Also Good Prototypical Commonsense Reasoners"></a>Large Language Models Are Also Good Prototypical Commonsense Reasoners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13165">http://arxiv.org/abs/2309.13165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenin Li, Qianglong Chen, Yin Zhang, Yifei Zhang, Hongxiang Yao</li>
<li>For: The paper aims to improve the performance of large language models on complex reasoning tasks by developing novel prompts that better support the models’ commonsense reasoning abilities.* Methods: The authors draw inspiration from the outputs of large models for tailored tasks and semi-automatically develop a set of novel prompts from multiple perspectives, including task-relevance, supportive evidence generation, and diverse path decoding.* Results: The experimental results on the ProtoQA dataset demonstrate that the proposed prompts can achieve a new state-of-the-art (SOTA) on the ProtoQA leaderboard, with improvements of 8% and 4% in the Max Answer@1 and Max Incorrect@1 scores, respectively, compared to the previous SOTA model. The generated Chain-of-Thought and knowledge also improve the interpretability of the model.<details>
<summary>Abstract</summary>
Commonsense reasoning is a pivotal skill for large language models, yet it presents persistent challenges in specific tasks requiring this competence. Traditional fine-tuning approaches can be resource-intensive and potentially compromise a model's generalization capacity. Furthermore, state-of-the-art language models like GPT-3.5 and Claude are primarily accessible through API calls, which makes fine-tuning models challenging. To address these challenges, we draw inspiration from the outputs of large models for tailored tasks and semi-automatically developed a set of novel prompts from several perspectives, including task-relevance, supportive evidence generation (e.g. chain-of-thought and knowledge), diverse path decoding to aid the model. Experimental results on ProtoQA dataset demonstrate that with better designed prompts we can achieve the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for the first time) compared to the previous SOTA model and achieved an improvement on StrategyQA and CommonsenseQA2.0 (3% and 1%, respectively). Furthermore, with the generated Chain-of-Thought and knowledge, we can improve the interpretability of the model while also surpassing the previous SOTA models. We hope that our work can provide insight for the NLP community to develop better prompts and explore the potential of large language models for more complex reasoning tasks.
</details>
<details>
<summary>摘要</summary>
大型语言模型的通质性理解是一项重要的技能，但是在特定任务中表现出 persistente 挑战。传统的精度调整方法可能是资源占用的和可能妨碍模型的总体化能力。此外，当前的语言模型如 GPT-3.5 和 Claude 都是通过 API 调用来访问，这使得模型的调整变得困难。为了解决这些挑战，我们从大型模型的输出中提取了特定任务的输出，并 semi-自动生成了一组新的提示，包括任务相关性、证据生成（如链条思维和知识）和多种路径解码，以帮助模型。实验结果表明，我们的提示设计可以超越前一个 SOTA 模型在 ProtoQA 数据集上的 Max Answer@1 得分，提高了8%，并且在 Max Incorrect@1 得分上提高了4%（打破了50%的首次纪录）。此外，我们还可以通过生成的链条思维和知识提高模型的解释性，并超越了前一个 SOTA 模型。我们希望，我们的工作可以为 NLP 社区提供灵感，开发更好的提示，探索大型语言模型在更复杂的理解任务中的潜在能力。
</details></li>
</ul>
<hr>
<h2 id="GAMIX-VAE-A-VAE-with-Gaussian-Mixture-Based-Posterior"><a href="#GAMIX-VAE-A-VAE-with-Gaussian-Mixture-Based-Posterior" class="headerlink" title="GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior"></a>GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13160">http://arxiv.org/abs/2309.13160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariano Rivera</li>
<li>for: 这篇论文探讨了变量自动编码器（VAEs）中关键的底下勒比级（KL）差异，它是生成模型和表示学习中机器学习中的一个重要组成部分。</li>
<li>methods: 该论文提出了一种新的ELBO定义，使用混合 Gaussian 来描述 posterior 概率分布，并在权重抑制方面添加了一个正则化项以避免减少抖动。它还使用 PatchGAN 探测器来提高 texture 的真实感。</li>
<li>results: 实验表明该方法可以生成真实的面孔，提供了一种可行的解决方案来增强 VAE 基于的生成模型。<details>
<summary>Abstract</summary>
Variational Autoencoders (VAEs) have become a cornerstone in generative modeling and representation learning within machine learning. This paper explores a nuanced aspect of VAEs, focusing on interpreting the Kullback Leibler (KL) Divergence, a critical component within the Evidence Lower Bound (ELBO) that governs the trade-off between reconstruction accuracy and regularization. While the KL Divergence enforces alignment between latent variable distributions and a prior imposing a structure on the overall latent space but leaves individual variable distributions unconstrained. The proposed method redefines the ELBO with a mixture of Gaussians for the posterior probability, introduces a regularization term to prevent variance collapse, and employs a PatchGAN discriminator to enhance texture realism. Implementation details involve ResNetV2 architectures for both the Encoder and Decoder. The experiments demonstrate the ability to generate realistic faces, offering a promising solution for enhancing VAE based generative models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Contextual-Emotion-Estimation-from-Image-Captions"><a href="#Contextual-Emotion-Estimation-from-Image-Captions" class="headerlink" title="Contextual Emotion Estimation from Image Captions"></a>Contextual Emotion Estimation from Image Captions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13136">http://arxiv.org/abs/2309.13136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vera Yang, Archita Srivastava, Yasaman Etesam, Chuxuan Zhang, Angelica Lim</li>
<li>for: 这 paper 探索了 Whether Large Language Models (LLMs) 可以支持情绪 estimation 任务，通过首先生成图像描述，然后使用 LLM 进行推理。</li>
<li>methods: 这 paper 使用了 Computer Vision 方法来直接测量人们的情绪，并使用 LLM 进行推理。</li>
<li>results: 研究发现，GPT-3.5 模型可以提供 surprisingly 合理的情绪预测，但是准确度可以随情绪概念而变化。  Overall, the results suggest promise in the image captioning and LLM approach.<details>
<summary>Abstract</summary>
Emotion estimation in images is a challenging task, typically using computer vision methods to directly estimate people's emotions using face, body pose and contextual cues. In this paper, we explore whether Large Language Models (LLMs) can support the contextual emotion estimation task, by first captioning images, then using an LLM for inference. First, we must understand: how well do LLMs perceive human emotions? And which parts of the information enable them to determine emotions? One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. Towards this goal, we propose a set of natural language descriptors for faces, bodies, interactions, and environments. We use them to manually generate captions and emotion annotations for a subset of 331 images from the EMOTIC dataset. These captions offer an interpretable representation for emotion estimation, towards understanding how elements of a scene affect emotion perception in LLMs and beyond. Secondly, we test the capability of a large language model to infer an emotion from the resulting image captions. We find that GPT-3.5, specifically the text-davinci-003 model, provides surprisingly reasonable emotion predictions consistent with human annotations, but accuracy can depend on the emotion concept. Overall, the results suggest promise in the image captioning and LLM approach.
</details>
<details>
<summary>摘要</summary>
人工智能识别人类情感是一项复杂的任务，通常使用计算机视觉方法直接测量人脸、姿势和上下文信息来确定人们的情感。在这篇论文中，我们考虑了使用大型自然语言模型（LLM）来支持情感识别任务。我们首先需要了解： LLM 如何识别人类情感吗？哪些信息使得它们能够确定情感呢？我们的首要挑战是构建一个描述人在场景中的自然语言描述，以便用 LLM 进行推理。为此，我们提出了一组面部、身体、互动和环境等自然语言描述器。我们使用它们手动生成了331个图像集EMOTIC中的图像caption和情绪标注。这些caption提供了可解释的表示方式，用于了解场景元素对情感识别在 LLM 和其他方法中的影响。其次，我们测试了一个大型自然语言模型（GPT-3.5）是否可以从图像caption中推断出情绪。我们发现，特别是text-davinci-003模型，能够提供相对准确的情绪预测，但是准确程度可能取决于情绪概念。总的来说，结果表明了图像captioning和LLM方法的潜在优势。
</details></li>
</ul>
<hr>
<h2 id="Insights-from-an-OTTR-centric-Ontology-Engineering-Methodology"><a href="#Insights-from-an-OTTR-centric-Ontology-Engineering-Methodology" class="headerlink" title="Insights from an OTTR-centric Ontology Engineering Methodology"></a>Insights from an OTTR-centric Ontology Engineering Methodology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13130">http://arxiv.org/abs/2309.13130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moritz Blum, Basil Ell, Philipp Cimiano</li>
<li>for: This paper is written for the purpose of discussing the use of OTTR templates in ontology engineering for the domain of Material Science.</li>
<li>methods: The paper uses a bottom-up and top-down approach to ontology engineering, starting with existing data and using OTTR templates to feed the data into a knowledge graph.</li>
<li>results: The paper finds that OTTR templates are useful for communicating with domain experts and that the engineering process becomes flexible as a result of encapsulating modeling decisions.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍使用OTTR模板在材料科学领域的ontology工程。</li>
<li>methods: 这篇论文使用底层和顶层的方法来实现ontology工程，从现有数据开始，使用OTTR模板将数据feed到知识图。</li>
<li>results: 这篇论文发现OTTR模板在与领域专家交流时非常有用，并且因为模板封装了设计决策，因此工程过程变得更加灵活，可以轻松地修改设计决策。<details>
<summary>Abstract</summary>
OTTR is a language for representing ontology modeling patterns, which enables to build ontologies or knowledge bases by instantiating templates. Thereby, particularities of the ontological representation language are hidden from the domain experts, and it enables ontology engineers to, to some extent, separate the processes of deciding about what information to model from deciding about how to model the information, e.g., which design patterns to use. Certain decisions can thus be postponed for the benefit of focusing on one of these processes. To date, only few works on ontology engineering where ontology templates are applied are described in the literature.   In this paper, we outline our methodology and report findings from our ontology engineering activities in the domain of Material Science. In these activities, OTTR templates play a key role. Our ontology engineering process is bottom-up, as we begin modeling activities from existing data that is then, via templates, fed into a knowledge graph, and it is top-down, as we first focus on which data to model and postpone the decision of how to model the data.   We find, among other things, that OTTR templates are especially useful as a means of communication with domain experts. Furthermore, we find that because OTTR templates encapsulate modeling decisions, the engineering process becomes flexible, meaning that design decisions can be changed at little cost.
</details>
<details>
<summary>摘要</summary>
OTTR 是一种用于表示 ontology 模式的语言，它可以帮助建立 ontology 或知识库 by instantiating 模板。因此，ontological 表示语言中的特定特点被隐藏，使得域专家不必关注这些特点，可以更专注于决定需要模型的信息和使用哪些设计模式。这样可以抽象出一些决策，以便更专注于一个过程中。在现有文献中，只有一些关于 ontology 工程的研究描述了使用 ontology 模板。在本文中，我们介绍了我们的方法和在材料科学领域中的 ontology 工程活动的发现。在这些活动中，OTTR 模板扮演了关键的角色。我们的 ontology 工程过程是底向的，我们从现有数据开始，将其通过模板feed into 知识图，并是顶向的，我们首先决定需要模型的数据，然后决定如何模型数据。我们发现 OTTR 模板非常有用作域专家与之交流的工具。此外，我们发现因为 OTTR 模板封装了模型决策，工程过程变得灵活，可以在低成本下更改设计决策。
</details></li>
</ul>
<hr>
<h2 id="E-2-Equivariant-Graph-Planning-for-Navigation"><a href="#E-2-Equivariant-Graph-Planning-for-Navigation" class="headerlink" title="E(2)-Equivariant Graph Planning for Navigation"></a>E(2)-Equivariant Graph Planning for Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13043">http://arxiv.org/abs/2309.13043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linfeng Zhao, Hongyu Li, Taskin Padir, Huaizu Jiang, Lawson L. S. Wong</li>
<li>for: 提高机器人导航的学习效率和稳定性，满足实际应用中的需求。</li>
<li>methods: 利用欧几何同态性在规划中，实现参数共享和稳定的训练。在不结构化环境中，通过几何图形规划和对称性保持的消息传递网络实现值迭代。还提出了一种可学习的协变层，将特征映射到 DESIRED 空间。</li>
<li>results: 在五种多样化任务中，包括结构化和不结构化环境，以及已知和未知的目标点或Semantic goal，实现了训练效率、稳定性和泛化性的显著改进。<details>
<summary>Abstract</summary>
Learning for robot navigation presents a critical and challenging task. The scarcity and costliness of real-world datasets necessitate efficient learning approaches. In this letter, we exploit Euclidean symmetry in planning for 2D navigation, which originates from Euclidean transformations between reference frames and enables parameter sharing. To address the challenges of unstructured environments, we formulate the navigation problem as planning on a geometric graph and develop an equivariant message passing network to perform value iteration. Furthermore, to handle multi-camera input, we propose a learnable equivariant layer to lift features to a desired space. We conduct comprehensive evaluations across five diverse tasks encompassing structured and unstructured environments, along with maps of known and unknown, given point goals or semantic goals. Our experiments confirm the substantial benefits on training efficiency, stability, and generalization.
</details>
<details>
<summary>摘要</summary>
学习 robot 导航存在一个极其紧迫和挑战性的任务。因为实际世界数据的稀缺和高价，我们需要开发高效的学习方法。在本文中，我们利用二维 Navigation 中的欧几何 симметрия，来实现参数共享。为了处理无结构环境，我们将导航问题定义为在几何图形上进行规划，并开发了一个对称报essage passing网络来实现值迭代。此外，我们还提出了一个可学习的对称层，以提高多摄像头输入的特征提取。我们在五种不同的任务中进行了广泛的评估，包括结构化和无结构化环境，以及已知和未知的点目标或semantic目标。我们的实验表明，我们的方法可以提高训练效率、稳定性和泛化能力。
</details></li>
</ul>
<hr>
<h2 id="MosaicFusion-Diffusion-Models-as-Data-Augmenters-for-Large-Vocabulary-Instance-Segmentation"><a href="#MosaicFusion-Diffusion-Models-as-Data-Augmenters-for-Large-Vocabulary-Instance-Segmentation" class="headerlink" title="MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation"></a>MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13042">http://arxiv.org/abs/2309.13042</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiahao000/mosaicfusion">https://github.com/jiahao000/mosaicfusion</a></li>
<li>paper_authors: Jiahao Xie, Wei Li, Xiangtai Li, Ziwei Liu, Yew Soon Ong, Chen Change Loy</li>
<li>for: 这篇论文是为了提出一种新的扩展数据生成方法，以提高大词汇实例分割器的性能。</li>
<li>methods: 该方法使用了 diffusion-based 数据生成方法，不需要任何标注数据，可以使用存在的文本至图生成器来生成多个实例。</li>
<li>results: 实验结果表明，使用该方法可以生成大量的合理标注数据，特别是对于罕见和新类别。这有助于提高现有的实例分割器的性能，特别是对于罕见和新类别。<details>
<summary>Abstract</summary>
We present MosaicFusion, a simple yet effective diffusion-based data augmentation approach for large vocabulary instance segmentation. Our method is training-free and does not rely on any label supervision. Two key designs enable us to employ an off-the-shelf text-to-image diffusion model as a useful dataset generator for object instances and mask annotations. First, we divide an image canvas into several regions and perform a single round of diffusion process to generate multiple instances simultaneously, conditioning on different text prompts. Second, we obtain corresponding instance masks by aggregating cross-attention maps associated with object prompts across layers and diffusion time steps, followed by simple thresholding and edge-aware refinement processing. Without bells and whistles, our MosaicFusion can produce a significant amount of synthetic labeled data for both rare and novel categories. Experimental results on the challenging LVIS long-tailed and open-vocabulary benchmarks demonstrate that MosaicFusion can significantly improve the performance of existing instance segmentation models, especially for rare and novel categories. Code will be released at https://github.com/Jiahao000/MosaicFusion.
</details>
<details>
<summary>摘要</summary>
我们介绍MosaicFusion，一种简单 yet effective的扩散基于数据增强方法，用于大词汇实例分割。我们的方法不需要任何标注指导。我们使用两个关键设计来使用市场上可用的文本到图像扩散模型来生成对象实例和mask注释。首先，我们将图像canvas分成多个区域，并在不同的文本提示下进行单次扩散过程，以同时生成多个实例。其次，我们通过聚合层和扩散时间步骤之间的交叉注意力图来获得对象提示的集合，然后进行简单的阈值设定和边缘敏感处理来获得实例mask。无论精雕的设计，MosaicFusion可以生成大量的合成标注数据，特别是为罕见和新类别。我们的实验结果表明，MosaicFusion可以大幅提高现有实例分割模型的性能，特别是为罕见和新类别。代码将在https://github.com/Jiahao000/MosaicFusion中发布。
</details></li>
</ul>
<hr>
<h2 id="Memory-augmented-conformer-for-improved-end-to-end-long-form-ASR"><a href="#Memory-augmented-conformer-for-improved-end-to-end-long-form-ASR" class="headerlink" title="Memory-augmented conformer for improved end-to-end long-form ASR"></a>Memory-augmented conformer for improved end-to-end long-form ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13029">http://arxiv.org/abs/2309.13029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miamoto/conformer-ntm">https://github.com/miamoto/conformer-ntm</a></li>
<li>paper_authors: Carlos Carvalho, Alberto Abad</li>
<li>for: 用于自动语音识别（ASR）模型的改进，特别是对长句子的表现。</li>
<li>methods: 使用外部可微分储存网络（NTM）和encoder-decoder结构的协同作用，以扩展对长句子的泛化能力。</li>
<li>results: 在使用Librispeech数据集的train-clean-100和train-960集上，提出的模型比基eline conformer ohne memory更高的表现于长句子。<details>
<summary>Abstract</summary>
Conformers have recently been proposed as a promising modelling approach for automatic speech recognition (ASR), outperforming recurrent neural network-based approaches and transformers. Nevertheless, in general, the performance of these end-to-end models, especially attention-based models, is particularly degraded in the case of long utterances. To address this limitation, we propose adding a fully-differentiable memory-augmented neural network between the encoder and decoder of a conformer. This external memory can enrich the generalization for longer utterances since it allows the system to store and retrieve more information recurrently. Notably, we explore the neural Turing machine (NTM) that results in our proposed Conformer-NTM model architecture for ASR. Experimental results using Librispeech train-clean-100 and train-960 sets show that the proposed system outperforms the baseline conformer without memory for long utterances.
</details>
<details>
<summary>摘要</summary>
具有最新提议的具有竞争力的模型方法（Conformer）在自动语音识别（ASR）中表现出色，超过了基于回归神经网络的方法和变换器。然而，在总体来说，这些端到端模型，特别是带有注意力的模型，在长句子情况下表现较差。为解决这一限制，我们提议在编码器和解码器之间添加一个可微分的内存增强神经网络。这个外部内存可以为长句子提供更多的信息，从而提高系统的总体化能力。我们研究了神经图理 machine（NTM），从而得到我们的提议的 Conformer-NTM 模型体系结构。实验结果表明，提议的系统在 Librispeech train-clean-100 和 train-960 集上比基础 Conformer  ohne 内存表现出色。
</details></li>
</ul>
<hr>
<h2 id="OpportunityFinder-A-Framework-for-Automated-Causal-Inference"><a href="#OpportunityFinder-A-Framework-for-Automated-Causal-Inference" class="headerlink" title="OpportunityFinder: A Framework for Automated Causal Inference"></a>OpportunityFinder: A Framework for Automated Causal Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13103">http://arxiv.org/abs/2309.13103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huy Nguyen, Prince Grover, Devashish Khatwani</li>
<li>for: 用于执行对屏幕数据进行多种 causal inference 研究，为非专家用户提供可编程代码的框架。</li>
<li>methods: 使用 raw 观察数据和配置文件，触发管道进行数据检查&#x2F;处理，选择适合的算法执行 causal 研究，并返回对 outcome 的 causal 影响，以及敏感性和稳定性结果。</li>
<li>results: 返回 causal 影响的结果，包括对 outcome 的 causal 影响，以及敏感性和稳定性结果。<details>
<summary>Abstract</summary>
We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts and Scientists, (2) abstraction of multiple algorithms under a single I/O interface, (3) support for causal impact analysis under binary treatment with panel data and (4) dynamic selection of algorithm based on scale of data.
</details>
<details>
<summary>摘要</summary>
我们介绍OpportunityFinder，一个无程式码框架，用于实现各种对组合数据进行可能性推论的不专家用户。目前情况下，OpportunityFinder只需用户提供原始观察数据和配置文件，然后触发一个管道，将数据进行检查和处理，选择适当的算法来执行可能性研究。它返回对定结果的影响，以及敏感度和稳定性结果。可能性推论广泛研究和使用，用于估计个人对产品和功能互动所产生的下游影响。这些可能性研究通常由科学家和/或经济学家定期进行。企业决策者往往因为科学家或经济学家的专业压力而受到瓶颈。我们提供OpportunityFinder作为常见的可能性研究解决方案，具有以下四个关键特点：1. 易用，适合商业分析师和科学家使用。2. 多种算法的抽象，通过单一的输入界面进行处理。3. 支持对组合数据进行可能性影响分析，并且仅需进行二进制对待。4. 基于数据的尺度进行动态算法选择。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Deep-Learning-based-Approach-for-Optimal-Genotype-by-Environment-Selection"><a href="#A-Hybrid-Deep-Learning-based-Approach-for-Optimal-Genotype-by-Environment-Selection" class="headerlink" title="A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection"></a>A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13021">http://arxiv.org/abs/2309.13021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Khalilzadeh, Motahareh Kashanian, Saeed Khaki, Lizhi Wang</li>
<li>For: The paper aims to improve crop yield prediction by integrating weather data across the growing season, especially for different crop varieties, to understand their adaptability in the face of climate change.* Methods: The authors used a dataset of 93,028 training records and 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). They developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model and the CNN-LSTM-DNN model. They also used the Generalized Ensemble Method (GEM) to determine optimal model weights.* Results: The GEM model achieved lower RMSE (5.55% to 39.88%), reduced MAE (5.34% to 43.76%), and higher correlation coefficients (1.1% to 10.79%) compared to baseline models. The CNN-DNN model was used to identify top-performing genotypes for various locations and weather conditions, aiding genotype selection based on weather variables.Here are the three points in Simplified Chinese text:* For: 这个论文目的是提高农业实践中的作物产量预测，以便更好地理解气候变化对作物的适应性。* Methods: 作者使用了一个包含93,028个训练记录和10,337个测试记录的数据集，覆盖了28个美国州和加拿大省的159个地点，时间跨度为13年（2003-2015）。他们开发了两种新的卷积神经网络模型：CNN-DNN模型和CNN-LSTM-DNN模型。他们还使用了通用ensemble方法（GEM）来确定优化模型的权重。* Results: GEM模型在测试数据上实现了较低的RMSE（5.55%到39.88%）、reduced MAE（5.34%到43.76%）和高于基eline模型的 correlation coefficient（1.1%到10.79%）。CNN-DNN模型用于在不同的地点和气候条件下预测最高产量的种子，帮助选择基于气候变量的种子。<details>
<summary>Abstract</summary>
Precise crop yield prediction is essential for improving agricultural practices and ensuring crop resilience in varying climates. Integrating weather data across the growing season, especially for different crop varieties, is crucial for understanding their adaptability in the face of climate change. In the MLCAS2021 Crop Yield Prediction Challenge, we utilized a dataset comprising 93,028 training records to forecast yields for 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). This dataset included details on 5,838 distinct genotypes and daily weather data for a 214-day growing season, enabling comprehensive analysis. As one of the winning teams, we developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model, combining CNN and fully-connected networks, and the CNN-LSTM-DNN model, with an added LSTM layer for weather variables. Leveraging the Generalized Ensemble Method (GEM), we determined optimal model weights, resulting in superior performance compared to baseline models. The GEM model achieved lower RMSE (5.55% to 39.88%), reduced MAE (5.34% to 43.76%), and higher correlation coefficients (1.1% to 10.79%) when evaluated on test data. We applied the CNN-DNN model to identify top-performing genotypes for various locations and weather conditions, aiding genotype selection based on weather variables. Our data-driven approach is valuable for scenarios with limited testing years. Additionally, a feature importance analysis using RMSE change highlighted the significance of location, MG, year, and genotype, along with the importance of weather variables MDNI and AP.
</details>
<details>
<summary>摘要</summary>
precisión del cultivo de precisión es esencial para mejorar las prácticas agrícolas y asegurar la resistencia de los cultivos en climas variables. Integrar los datos meteorológicos durante la temporada de crecimiento, especialmente para diferentes variedades de cultivos, es crucial para comprender su adaptabilidad enfrentada al cambio climático. En el Desafío de Predicción de Yield de MLCAS2021, utilizamos un conjunto de datos de entrenamiento que comprendía 93,028 registros para predecir los rendimientos para 10,337 registros de prueba, que cubrían 159 ubicaciones en 28 estados y provincias canadiences durante 13 años (2003-2015). Este conjunto de datos incluyó detalles sobre 5,838 genotipos distinctos y datos meteorológicos diarios para una temporada de crecimiento de 214 días, lo que permitió un análisis exhaustivo. Como uno de los equipos ganadores, desarrollamos dos arquitecturas de red neuronal convolutional (CNN) nuevas: el modelo CNN-DNN, que combina redes neuronales convolutional y fully connected, y el modelo CNN-LSTM-DNN, con una capa adicional de LSTM para variables meteorológicas. Al utilizar el Método de Ensemble Generalizado (GEM), determinamos los pesos óptimos del modelo, lo que resultó en una performance superior a los modelos de referencia. El modelo GEM obtuvo una RMSE reducida (del 5,55% al 39,88%), una MAE reducida (del 5,34% al 43,76%) y coeficientes de correlación más altos (del 1,1% al 10,79%) cuando se evaluó en datos de prueba. Aplicamos el modelo CNN-DNN para identificar los genotipos más renderos para diferentes ubicaciones y condiciones meteorológicas, lo que es útil para la selección de genotipos basada en variables meteorológicas. Nuestra aproximación basada en datos es valiosa para escenarios con años de prueba limitados. Además, un análisis de importancia de características utilizando el cambio de RMSE destacó la importancia de la ubicación, MG, año y genotipo, así como la importancia de las variables meteorológicas MDNI y AP.
</details></li>
</ul>
<hr>
<h2 id="Efficient-N-M-Sparse-DNN-Training-Using-Algorithm-Architecture-and-Dataflow-Co-Design"><a href="#Efficient-N-M-Sparse-DNN-Training-Using-Algorithm-Architecture-and-Dataflow-Co-Design" class="headerlink" title="Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design"></a>Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13015">http://arxiv.org/abs/2309.13015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Fang, Wei Sun, Aojun Zhou, Zhongfeng Wang</li>
<li>for: 这个论文主要针对的是如何使用粗糙训练来降低深度神经网络（DNN）的计算成本，同时保持高度准确性。</li>
<li>methods: 本论文提出了一种 computation-efficient 的训练方案，包括算法、架构和数据流程合理设计。在算法层面，提出了一种双向权重剔除方法（BDWP），可以在前向和反向传播中利用 N：M 粗糙性来减少计算成本，同时保持模型准确性。在架构层面，提出了一种专门用于 DNN 训练的粗糙加速器（SAT），可以支持常见的稠密操作以及计算效率高的 N：M 粗糙操作。在数据流程层面，提出了多种优化方法，包括交叉映射、预生成 N：M 粗糙权重和离线调度等，以提高 SAT 的计算效率。</li>
<li>results: 实验结果显示，使用 SAT 加速器和 BDWP 粗糙训练方法，在 Xilinx VCU1525 FPGA 卡上使用不同的 DNN 模型和数据集，可以实现 average 速度提升1.75倍，同时减少了模型精度下降的0.56%。此外，我们的训练方案可以提高训练吞吐量2.97<del>25.22倍和能效率1.36</del>3.58倍 compared to 先前的 FPGA 加速器。<details>
<summary>Abstract</summary>
Sparse training is one of the promising techniques to reduce the computational cost of DNNs while retaining high accuracy. In particular, N:M fine-grained structured sparsity, where only N out of consecutive M elements can be nonzero, has attracted attention due to its hardware-friendly pattern and capability of achieving a high sparse ratio. However, the potential to accelerate N:M sparse DNN training has not been fully exploited, and there is a lack of efficient hardware supporting N:M sparse training. To tackle these challenges, this paper presents a computation-efficient training scheme for N:M sparse DNNs using algorithm, architecture, and dataflow co-design. At the algorithm level, a bidirectional weight pruning method, dubbed BDWP, is proposed to leverage the N:M sparsity of weights during both forward and backward passes of DNN training, which can significantly reduce the computational cost while maintaining model accuracy. At the architecture level, a sparse accelerator for DNN training, namely SAT, is developed to neatly support both the regular dense operations and the computation-efficient N:M sparse operations. At the dataflow level, multiple optimization methods ranging from interleave mapping, pre-generation of N:M sparse weights, and offline scheduling, are proposed to boost the computational efficiency of SAT. Finally, the effectiveness of our training scheme is evaluated on a Xilinx VCU1525 FPGA card using various DNN models and datasets. Experimental results show the SAT accelerator with the BDWP sparse training method under 2:8 sparse ratio achieves an average speedup of 1.75x over that with the dense training, accompanied by a negligible accuracy loss of 0.56% on average. Furthermore, our proposed training scheme significantly improves the training throughput by 2.97~25.22x and the energy efficiency by 1.36~3.58x over prior FPGA-based accelerators.
</details>
<details>
<summary>摘要</summary>
\begin{blockquote}稀疏训练是深度学习模型的一种有前途的技术，可以降低深度学习模型的计算成本，保持高度准确。特别是N：M精细结构稀疏，在N个连续M个元素中只有N个可以非零，这种硬件友好的模式和高度稀疏比例的实现，引起了关注。然而，N：M稀疏深度学习训练的潜在加速仍未得到完全利用，缺少高效的硬件支持。为了解决这些挑战，本文提出了一种计算效率高的训练方案 для N：M稀疏深度学习模型，通过算法、建筑和数据流合理设计。在算法层面，我们提出了一种双向权重减少方法，称为BDWP，可以在深度学习模型的前向和反向传播中利用N：M稀疏的权重，大幅降低计算成本，保持模型准确性。在建筑层面，我们开发了一种适用于深度学习训练的稀疏加速器，称为SAT，可以方便支持常见的密集操作以及计算效率的N：M稀疏操作。在数据流层面，我们提出了多种优化方法，从批量映射、预生成N：M稀疏权重到离线调度，以提高SAT的计算效率。实验结果表明，使用我们的训练方案和SAT加速器，N：M稀疏深度学习模型在Xilinx VCU1525 FPGA卡上实现了1.75倍的速度提升，相对于密集训练方案，平均准确性损失为0.56%。此外，我们的训练方案可以提高训练吞吐量2.97~25.22倍和能效率1.36~3.58倍，至于先前的FPGA加速器。\end{blockquote}Note that the translation is done using the Simplified Chinese language setting, which may not be exactly the same as the Traditional Chinese language setting used in Taiwan.
</details></li>
</ul>
<hr>
<h2 id="ReConcile-Round-Table-Conference-Improves-Reasoning-via-Consensus-among-Diverse-LLMs"><a href="#ReConcile-Round-Table-Conference-Improves-Reasoning-via-Consensus-among-Diverse-LLMs" class="headerlink" title="ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs"></a>ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13007">http://arxiv.org/abs/2309.13007</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dinobby/reconcile">https://github.com/dinobby/reconcile</a></li>
<li>paper_authors: Justin Chih-Yao Chen, Swarnadeep Saha, Mohit Bansal</li>
<li>for: 提高大型自然语言模型（LLM）的复杂理解能力</li>
<li>methods: 提出ReConcile模型，利用多个LLM代理在圆桌会议中互动，提高代理之间的多样化思维和沟通，以提高LLM的复杂理解能力</li>
<li>results: 在多个benchmark上实验表明，ReConcile模型可以大幅提高LLM的复杂理解能力，比对 Singleshot baseline和多代理baseline高出7.7%，并且在一些数据集上甚至超过GPT-4的表现。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcile determines the final answer by leveraging the confidence of each agent in a weighted voting scheme. We implement ReConcile with ChatGPT, Bard, and Claude2 as the three agents. Our experimental results on various benchmarks demonstrate that ReConcile significantly enhances the reasoning performance of the agents (both individually and as a team), surpassing prior single-agent and multi-agent baselines by 7.7% and also outperforming GPT-4 on some of these datasets. We also experiment with GPT-4 itself as one of the agents in ReConcile and demonstrate that its initial performance also improves by absolute 10.0% through discussion and feedback from other agents. Finally, we also analyze the accuracy after every round and observe that ReConcile achieves better and faster consensus between agents, compared to a multi-agent debate baseline. Our code is available at: https://github.com/dinobby/ReConcile
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）仍然面临复杂的理解任务。 motivated by the society of minds（Minsky，1988），我们提议ReConcile，一种多模型多代理框架，设计为多个LLM代理在多种不同的思路和讨论中促进多元思维和讨论，以提高共识。ReConcile通过多轮讨论、学习感SErrors他们的答案，并使用可信度权重投票机制来提高LLMs的理解能力。在每轮讨论中，ReConcile通过'讨论提示'来initiate discussion between agents，该提示包括每个代理在上一轮的答案和解释、uncertainties，以及answer-rectifying human explanations，用于说服其他代理。这些讨论提示使每个代理可以根据其他代理的启示修改其答案。当讨论结束并达成共识时，ReConcile使用每个代理的可信度在权重投票机制中确定最终答案。我们在ChatGPT、Bard和Claude2作为三个代理来实现ReConcile。我们的实验结果表明，ReConcile可以明显提高LLMs的理解能力（both individually and as a team），比对前的单机和多机基线高出7.7%，同时也超过GPT-4在一些数据集上的性能。我们还在GPT-4作为一个代理参与ReConcile，并证明其初始性能也提高了绝对10.0%通过对其他代理的讨论和反馈。最后，我们还分析了每轮的准确率，发现ReConcile在多个代理之间达成共识的速度和准确率比multi-agent debate基线更高。我们的代码可以在https://github.com/dinobby/ReConcile上获取。
</details></li>
</ul>
<hr>
<h2 id="Pursuing-Counterfactual-Fairness-via-Sequential-Autoencoder-Across-Domains"><a href="#Pursuing-Counterfactual-Fairness-via-Sequential-Autoencoder-Across-Domains" class="headerlink" title="Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains"></a>Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13005">http://arxiv.org/abs/2309.13005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujie Lin, Chen Zhao, Minglai Shao, Baoluo Meng, Xujiang Zhao, Haifeng Chen</li>
<li>for: 提高机器学习系统在不同频率的数据上的性能，并在数据分布逐渐发展的过程中保持公平性。</li>
<li>methods: 提出了一种名为Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder（CDSAE）的创新框架，该框架可以分离类别特征中的环境信息和敏感特征，从而提高模型在多样化和不 Familiar 频率上的泛化性能，同时也能够有效地解决不公正分类问题。</li>
<li>results: 通过在 sintetic 和实际世界数据集上的验证，证明了我们的方法可以提高准确率，同时保持公平性在数据分布逐渐发展的过程中。<details>
<summary>Abstract</summary>
Recognizing the prevalence of domain shift as a common challenge in machine learning, various domain generalization (DG) techniques have been developed to enhance the performance of machine learning systems when dealing with out-of-distribution (OOD) data. Furthermore, in real-world scenarios, data distributions can gradually change across a sequence of sequential domains. While current methodologies primarily focus on improving model effectiveness within these new domains, they often overlook fairness issues throughout the learning process. In response, we introduce an innovative framework called Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder (CDSAE). This approach effectively separates environmental information and sensitive attributes from the embedded representation of classification features. This concurrent separation not only greatly improves model generalization across diverse and unfamiliar domains but also effectively addresses challenges related to unfair classification. Our strategy is rooted in the principles of causal inference to tackle these dual issues. To examine the intricate relationship between semantic information, sensitive attributes, and environmental cues, we systematically categorize exogenous uncertainty factors into four latent variables: 1) semantic information influenced by sensitive attributes, 2) semantic information unaffected by sensitive attributes, 3) environmental cues influenced by sensitive attributes, and 4) environmental cues unaffected by sensitive attributes. By incorporating fairness regularization, we exclusively employ semantic information for classification purposes. Empirical validation on synthetic and real-world datasets substantiates the effectiveness of our approach, demonstrating improved accuracy levels while ensuring the preservation of fairness in the evolving landscape of continuous domains.
</details>
<details>
<summary>摘要</summary>
recognizing the prevalence of domain shift as a common challenge in machine learning, various domain generalization (DG) techniques have been developed to enhance the performance of machine learning systems when dealing with out-of-distribution (OOD) data. Furthermore, in real-world scenarios, data distributions can gradually change across a sequence of sequential domains. While current methodologies primarily focus on improving model effectiveness within these new domains, they often overlook fairness issues throughout the learning process. In response, we introduce an innovative framework called Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder (CDSAE). This approach effectively separates environmental information and sensitive attributes from the embedded representation of classification features. This concurrent separation not only greatly improves model generalization across diverse and unfamiliar domains but also effectively addresses challenges related to unfair classification. Our strategy is rooted in the principles of causal inference to tackle these dual issues. To examine the intricate relationship between semantic information, sensitive attributes, and environmental cues, we systematically categorize exogenous uncertainty factors into four latent variables: 1) semantic information influenced by sensitive attributes, 2) semantic information unaffected by sensitive attributes, 3) environmental cues influenced by sensitive attributes, and 4) environmental cues unaffected by sensitive attributes. By incorporating fairness regularization, we exclusively employ semantic information for classification purposes. Empirical validation on synthetic and real-world datasets substantiates the effectiveness of our approach, demonstrating improved accuracy levels while ensuring the preservation of fairness in the evolving landscape of continuous domains.
</details></li>
</ul>
<hr>
<h2 id="Audience-specific-Explanations-for-Machine-Translation"><a href="#Audience-specific-Explanations-for-Machine-Translation" class="headerlink" title="Audience-specific Explanations for Machine Translation"></a>Audience-specific Explanations for Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12998">http://arxiv.org/abs/2309.12998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renhan Lou, Jan Niehues</li>
<li>for: 解决机器翻译中存在的certain words even if translated can cause incomprehension of the target language audience due to different cultural backgrounds.</li>
<li>methods: 我们提出了一种 semi-automatic technique to extract these explanations from a large parallel corpus.</li>
<li>results: 我们的方法能够从英语-&gt;德语、英语-&gt;法语和英语-&gt;中文语对取得较好的结果，其中有超过10%的句子包含解释，而原始句子中只有1.9%包含解释。<details>
<summary>Abstract</summary>
In machine translation, a common problem is that the translation of certain words even if translated can cause incomprehension of the target language audience due to different cultural backgrounds. A solution to solve this problem is to add explanations for these words. In a first step, we therefore need to identify these words or phrases. In this work we explore techniques to extract example explanations from a parallel corpus. However, the sparsity of sentences containing words that need to be explained makes building the training dataset extremely difficult. In this work, we propose a semi-automatic technique to extract these explanations from a large parallel corpus. Experiments on English->German language pair show that our method is able to extract sentence so that more than 10% of the sentences contain explanation, while only 1.9% of the original sentences contain explanations. In addition, experiments on English->French and English->Chinese language pairs also show similar conclusions. This is therefore an essential first automatic step to create a explanation dataset. Furthermore we show that the technique is robust for all three language pairs.
</details>
<details>
<summary>摘要</summary>
在机器翻译中，一个常见的问题是翻译某些词汇，即使翻译成功，也可能导致目标语言群体的不理解，因为不同的文化背景。为解决这问题，一种解决方案是添加解释。在这项工作中，我们 explore 技术来提取示例解释。然而，在建立训练集时，由于翻译后的句子中包含需要解释的词汇的稀缺性，使得建立训练集非常困难。因此，我们提出了一种半自动的提取方法，来从大量的平行词典中提取示例解释。实验表明，我们的方法可以从英语->德语、英语->法语和英语->中文三种语言对的平行词典中提取句子，使得超过10%的句子包含解释，而原始句子中只有1.9%的句子包含解释。此外，我们还展示了该技术在三种语言对上的稳定性。因此，这是一项重要的自动第一步，用于创建解释数据集。
</details></li>
</ul>
<hr>
<h2 id="Higher-order-Graph-Convolutional-Network-with-Flower-Petals-Laplacians-on-Simplicial-Complexes"><a href="#Higher-order-Graph-Convolutional-Network-with-Flower-Petals-Laplacians-on-Simplicial-Complexes" class="headerlink" title="Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes"></a>Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12971">http://arxiv.org/abs/2309.12971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeniSoida/pl1">https://github.com/zeniSoida/pl1</a></li>
<li>paper_authors: Yiming Huang, Yujie Zeng, Qiang Wu, Linyuan Lü</li>
<li>for: 这 paper 的目的是提出一种基于 simplicial complexes (SCs) 的高级别征特征学习方法，以增强 graph neural network (GNN) 的表达能力。</li>
<li>methods: 该方法基于 Flower-Petals (FP) 模型，并使用 learnable graph filters 来识别不同的高级别交互强度。</li>
<li>results: 实验结果表明，提出的模型可以在多种图任务上达到 state-of-the-art (SOTA) 性能，并且提供一个可扩展和灵活的解决方案来探索图中的高级别交互。<details>
<summary>Abstract</summary>
Despite the recent successes of vanilla Graph Neural Networks (GNNs) on many tasks, their foundation on pairwise interaction networks inherently limits their capacity to discern latent higher-order interactions in complex systems. To bridge this capability gap, we propose a novel approach exploiting the rich mathematical theory of simplicial complexes (SCs) - a robust tool for modeling higher-order interactions. Current SC-based GNNs are burdened by high complexity and rigidity, and quantifying higher-order interaction strengths remains challenging. Innovatively, we present a higher-order Flower-Petals (FP) model, incorporating FP Laplacians into SCs. Further, we introduce a Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians, capable of discerning intrinsic features across varying topological scales. By employing learnable graph filters, a parameter group within each FP Laplacian domain, we can identify diverse patterns where the filters' weights serve as a quantifiable measure of higher-order interaction strengths. The theoretical underpinnings of HiGCN's advanced expressiveness are rigorously demonstrated. Additionally, our empirical investigations reveal that the proposed model accomplishes state-of-the-art (SOTA) performance on a range of graph tasks and provides a scalable and flexible solution to explore higher-order interactions in graphs.
</details>
<details>
<summary>摘要</summary>
尽管最近的vanilla图 neural network (GNN)在许多任务上表现出色，但它们的基础是对应的对之间互动网络，因此它们无法自然地捕捉复杂系统中隐藏的高阶互动。为bridge这个能力差距，我们提出了一种新的方法，利用 simplicial complexes (SC) 的丰富数学理论 - 一种可靠的工具 для模型高阶互动。现有的 SC 基于 GNN 受到高复杂性和僵化的限制，同时量化高阶互动强度仍然是挑战。我们创新地提出了一种高阶花 petal (FP) 模型，将 FP  Laplacians 引入 SC 中。此外，我们还介绍了一种基于 FP Laplacians 的高阶图卷积网络 (HiGCN)，可以在不同的 topological scale 上捕捉到系统内部的自适应特征。通过使用可学习的图滤波器，每个 FP Laplacian 域中的参数组，我们可以识别出多种具有不同特征的图pattern，其中滤波器的权重serve as a quantifiable measure of high-order interaction strengths。我们的理论基础的进一步证明和实验研究表明，提出的模型可以在许多图任务上达到领先的性能水平，并提供一个可扩展和灵活的解决方案来探索图中的高阶互动。
</details></li>
</ul>
<hr>
<h2 id="Trusta-Reasoning-about-Assurance-Cases-with-Formal-Methods-and-Large-Language-Models"><a href="#Trusta-Reasoning-about-Assurance-Cases-with-Formal-Methods-and-Large-Language-Models" class="headerlink" title="Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models"></a>Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12941">http://arxiv.org/abs/2309.12941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zezhong Chen, Yuxin Deng, Wenjie Du</li>
<li>for:  This paper focuses on the development of a tool called Trustworthiness Derivation Tree Analyzer (Trusta) that automates the construction and verification of assurance cases for safety-critical systems.</li>
<li>methods:  The tool uses formal methods, such as Prolog and constraint solvers like Z3 and MONA, to automatically reason about assurance cases. It also utilizes large language models like ChatGPT-3.5, ChatGPT-4, and PaLM 2 to generate and evaluate assurance cases, allowing for interactive human examination and modification.</li>
<li>results:  The paper presents several industrial case studies that demonstrate the practical value of Trusta in finding subtle issues that are typically missed in manual inspection, and shows that the tool can quickly and efficiently enhance the assurance case development process.<details>
<summary>Abstract</summary>
Assurance cases can be used to argue for the safety of products in safety engineering. In safety-critical areas, the construction of assurance cases is indispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases by incorporating formal methods, rendering it possible for automatic reasoning about assurance cases. We present Trustworthiness Derivation Tree Analyzer (Trusta), a desktop application designed to automatically construct and verify TDTs. The tool has a built-in Prolog interpreter in its backend, and is supported by the constraint solvers Z3 and MONA. Therefore, it can solve constraints about logical formulas involving arithmetic, sets, Horn clauses etc. Trusta also utilizes large language models to make the creation and evaluation of assurance cases more convenient. It allows for interactive human examination and modification. We evaluated top language models like ChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests showed a 50%-80% similarity between machine-generated and human-created cases. In addition, Trusta can extract formal constraints from text in natural languages, facilitating an easier interpretation and validation process. This extraction is subject to human review and correction, blending the best of automated efficiency with human insight. To our knowledge, this marks the first integration of large language models in automatic creating and reasoning about assurance cases, bringing a novel approach to a traditional challenge. Through several industrial case studies, Trusta has proven to quickly find some subtle issues that are typically missed in manual inspection, demonstrating its practical value in enhancing the assurance case development process.
</details>
<details>
<summary>摘要</summary>
可信度证明（Assurance Case）可以用于安全工程中证明产品的安全性。在安全关键领域，构建可信度证明是必备的。可信度推导树（TDT）可以增强可信度证明，使其可以进行自动的逻辑推理。我们介绍了一款名为“信任worthiness Derivation Tree Analyzer”（Trusta）的桌面应用程序，用于自动构建和验证TDT。Trusta具有内置的Prolog解释器，并支持Z3和MONA等约束解决器。因此，它可以解决包括逻辑形式中的数学、集合、扩展等约束。Trusta还利用大型自然语言模型来使创建和评估可信度证明更加方便。它允许交互式的人工检查和修改。我们对ChatGPT-3.5、ChatGPT-4和PaLM 2等大型自然语言模型进行测试，测试结果表明，机器生成的可信度证明与人类创建的可信度证明之间存在50%-80%的相似性。此外，Trusta可以从自然语言文本中提取形式约束，使评估和验证过程更加容易。这种提取是人类审核和修正的，将机器自动效率与人类智慧相结合。在我们所知道的情况下，Trusta是首次将大型自然语言模型 integrate into automatic creation and reasoning about assurance cases，为传统挑战提供了一种新的方法。通过多个工业案例研究，Trusta已经证明了它能够快速发现一些通常被人工检查掉的细微问题，表明了它在提高可信度证明开发过程的实际价值。
</details></li>
</ul>
<hr>
<h2 id="Self-Explanation-Prompting-Improves-Dialogue-Understanding-in-Large-Language-Models"><a href="#Self-Explanation-Prompting-Improves-Dialogue-Understanding-in-Large-Language-Models" class="headerlink" title="Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models"></a>Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12940">http://arxiv.org/abs/2309.12940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Gao, Ting-En Lin, Hangyu Li, Min Yang, Yuchuan Wu, Wentao Ma, Yongbin Li</li>
<li>for: 提高大语言模型在多回话对话中的理解能力</li>
<li>methods: 使用自我解释提示策略，让模型在对话开始前分析每个对话语言，提高对话中任务执行的表现</li>
<li>results: 经过实验证明，该策略可以在六个 benchmark 数据集中 consistently 超越零shot 提示和几个 shot 提示，达到或超过少量提示的效果，表明其可以强大地增强大语言模型在复杂对话任务中的理解能力。<details>
<summary>Abstract</summary>
Task-oriented dialogue (TOD) systems facilitate users in executing various activities via multi-turn dialogues, but Large Language Models (LLMs) often struggle to comprehend these intricate contexts. In this study, we propose a novel "Self-Explanation" prompting strategy to enhance the comprehension abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires the model to analyze each dialogue utterance before task execution, thereby improving performance across various dialogue-centric tasks. Experimental results from six benchmark datasets confirm that our method consistently outperforms other zero-shot prompts and matches or exceeds the efficacy of few-shot prompts, demonstrating its potential as a powerful tool in enhancing LLMs' comprehension in complex dialogue tasks.
</details>
<details>
<summary>摘要</summary>
干预对话（TOD）系统通过多回对话来帮助用户执行各种活动，但大语言模型（LLM）经常在复杂的上下文中困难理解。在这项研究中，我们提出了一种新的“自我解释”提示策略，以提高LLM在多回对话中的理解能力。这种任务无关的方法需要模型在对话过程中分析每个语音，从而提高对各种对话中心任务的表现。六个基准数据集的实验结果表明，我们的方法在其他零批提示和几批提示之间具有优异的表现，并且能够与或超过几批提示的效果，这表明了这种方法在复杂对话任务中提高LLM的理解能力的潜力。
</details></li>
</ul>
<hr>
<h2 id="Frustrated-with-Code-Quality-Issues-LLMs-can-Help"><a href="#Frustrated-with-Code-Quality-Issues-LLMs-can-Help" class="headerlink" title="Frustrated with Code Quality Issues? LLMs can Help!"></a>Frustrated with Code Quality Issues? LLMs can Help!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12938">http://arxiv.org/abs/2309.12938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nalin Wadhwa, Jui Pradhan, Atharv Sonwane, Surya Prakash Sahu, Nagarajan Natarajan, Aditya Kanade, Suresh Parthasarathy, Sriram Rajamani</li>
<li>for: 这种论文主要是为了提高代码质量，提高软件的可靠性、维护性和安全性。</li>
<li>methods: 这个论文使用了大型自然语言模型（LLM）来帮助开发者修复代码质量问题。具体来说，这个工具使用了一对LLM组成的“推荐-评分”结构，其中一个LLM提供修复建议，另一个LLM则根据开发者的acceptance criterion评分这些建议。</li>
<li>results: 这个论文的实验结果显示，使用CORE工具可以提高Python文件的修复率达59.2%，同时减少了 False Positive 的比例。此外，在Java文件中，CORE工具可以达到76.8%的修复率，与专门的程序修复工具相当。<details>
<summary>Abstract</summary>
As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts.
</details>
<details>
<summary>摘要</summary>
随着软件项目的进行，代码质量的重要性日益增加，因为它直接影响软件的可靠性、维护性和安全性。为此，开发者在开发过程中使用静态分析工具来检测代码质量问题。然而，开发者需要额外努力来修改代码，以便通过工具的检测。在这个工作中，我们研究了使用大型自然语言模型（LLM）来帮助开发者修改代码，以解决代码质量问题。我们提出了一个工具，称为 CORE（简称代码修订），其核心思想是使用一对LLM组成的“提案-评分”机制。提案LLM使用同样的推荐方法，将static分析工具的推荐改进应用于代码修订。提案LLM生成的候选修订检查通过静态质量检查。然而，LLM可能引入微妙的、意外的功能变化，这些变化可能被静态分析工具忽略。评分LLM使用一个仅次于开发者的接受标准来评价修订。CORE使用评分LLM的分数来排序候选修订，然后向开发者展示。CORE可以在52个质量检查中，对59.2%的Python文件进行修订，使其通过静态分析工具和人工审查。评分LLM可以在这些案例中减少false positives的比例为25.8%。CORE生成的修订可以在76.8%的Java文件中通过静态分析工具，与专门的修复工具相当，但需要的工程努力明显更少。
</details></li>
</ul>
<hr>
<h2 id="On-Separate-Normalization-in-Self-supervised-Transformers"><a href="#On-Separate-Normalization-in-Self-supervised-Transformers" class="headerlink" title="On Separate Normalization in Self-supervised Transformers"></a>On Separate Normalization in Self-supervised Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12931">http://arxiv.org/abs/2309.12931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohui Chen, Yinkai Wang, Yuanqi Du, Soha Hassoun, Li-Ping Liu</li>
<li>for: 本文提出了一种简单的修改，即在masked autoencoders（MAE）中使用分开的normalization层来更好地捕捉token和[CLS]符号的不同特征，以提高下游任务性能。</li>
<li>methods: 本文提出的方法是，在MAE模型中，为token和[CLS]符号分别使用分开的normalization层，以便更好地捕捉它们的不同特征。</li>
<li>results: 经验表明，通过使用分开的normalization层，[CLS] embedding可以更好地编码全局Contextual信息，并且在它的不规则空间中分布更加均匀。 replaced conventional normalization layer with two separate layers, we observe an average performance improvement of 2.7% over the image, natural language, and graph domains.<details>
<summary>Abstract</summary>
Self-supervised training methods for transformers have demonstrated remarkable performance across various domains. Previous transformer-based models, such as masked autoencoders (MAE), typically utilize a single normalization layer for both the [CLS] symbol and the tokens. We propose in this paper a simple modification that employs separate normalization layers for the tokens and the [CLS] symbol to better capture their distinct characteristics and enhance downstream task performance. Our method aims to alleviate the potential negative effects of using the same normalization statistics for both token types, which may not be optimally aligned with their individual roles. We empirically show that by utilizing a separate normalization layer, the [CLS] embeddings can better encode the global contextual information and are distributed more uniformly in its anisotropic space. When replacing the conventional normalization layer with the two separate layers, we observe an average 2.7% performance improvement over the image, natural language, and graph domains.
</details>
<details>
<summary>摘要</summary>
自我超vision方法对transformer模型表现非常出色，在不同领域中达到了优秀的result。以前的transformer模型，如masked autoencoders（MAE），通常使用单个normalization层来处理[CLS]符号和token。我们在这篇论文中提出了一个简单的修改，即在token和[CLS]符号之间使用分开的normalization层，以更好地捕捉它们的特点和提高下游任务表现。我们的方法的目标是解决使用同一个normalization统计数据来处理token和[CLS]符号可能存在的负面影响，这可能不是最佳的对齐。我们在实验中发现，通过使用两个分开的normalization层，[CLS]嵌入可以更好地编码全局上下文信息，并且在其不对称空间中分布更加均匀。当将传统的normalization层替换为两个分开的normalization层时，我们在图像、自然语言和图形领域的average表现提高了2.7%。
</details></li>
</ul>
<hr>
<h2 id="Lamarck’s-Revenge-Inheritance-of-Learned-Traits-Can-Make-Robot-Evolution-Better"><a href="#Lamarck’s-Revenge-Inheritance-of-Learned-Traits-Can-Make-Robot-Evolution-Better" class="headerlink" title="Lamarck’s Revenge: Inheritance of Learned Traits Can Make Robot Evolution Better"></a>Lamarck’s Revenge: Inheritance of Learned Traits Can Make Robot Evolution Better</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13099">http://arxiv.org/abs/2309.13099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Luo, Karine Miras, Jakub Tomczak, Agoston E. Eiben</li>
<li>for: 研究“如果18世纪生物学家拉马克不完全错误，个体特征通过遗传继承给后代？”问题。</li>
<li>methods: 使用进化机器人框架进行模拟，其中机器人体型（身体）和控制器（大脑）都可以进化，同时机器人也可以通过学习在生命中提高控制器。</li>
<li>results: 对拉马克主义系统和达尔文主义系统进行比较，发现拉马克主义系统会增强机器人体型智能的出现，并确定了这种成功的原因：新生机器人的遗传大脑与身体更好匹配，因此其遗传率比达尔文主义系统高。<details>
<summary>Abstract</summary>
Evolutionary robot systems offer two principal advantages: an advanced way of developing robots through evolutionary optimization and a special research platform to conduct what-if experiments regarding questions about evolution. Our study sits at the intersection of these. We investigate the question ``What if the 18th-century biologist Lamarck was not completely wrong and individual traits learned during a lifetime could be passed on to offspring through inheritance?'' We research this issue through simulations with an evolutionary robot framework where morphologies (bodies) and controllers (brains) of robots are evolvable and robots also can improve their controllers through learning during their lifetime. Within this framework, we compare a Lamarckian system, where learned bits of the brain are inheritable, with a Darwinian system, where they are not. Analyzing simulations based on these systems, we obtain new insights about Lamarckian evolution dynamics and the interaction between evolution and learning. Specifically, we show that Lamarckism amplifies the emergence of `morphological intelligence', the ability of a given robot body to acquire a good brain by learning, and identify the source of this success: `newborn' robots have a higher fitness because their inherited brains match their bodies better than those in a Darwinian system.
</details>
<details>
<summary>摘要</summary>
生化机器系统提供了两大优势：一是通过进化优化发展机器人的先进方法，二是一种特殊的研究平台来进行关于进化的问题的什么样的实验。我们的研究位于这两个方面之间。我们研究“如果18世纪的生物学家拉马克不完全错误，个体特征在生命周期中学习得来的不能被遗传下来？”这个问题，通过使用进化机器人框架进行模拟，在这个框架中，机器人的形态（身体）和控制器（脑）都可以进化，同时机器人也可以通过学习提高控制器的性能。在这个框架中，我们比较了拉马克主义系统和达尔文主义系统两种不同的进化方式。通过分析这些系统的模拟结果，我们获得了新的理解关于拉马克主义进化动力学和进化和学习之间的互动。具体来说，我们发现拉马克主义会增强机器人身体的智能化，即机器人身体可以通过学习获得一个好的脑。而这种成功的原因是“新生”机器人的遗传因素更好地匹配其身体，因此它们在达尔文主义系统中的遗传因素更高。
</details></li>
</ul>
<hr>
<h2 id="A-matter-of-attitude-Focusing-on-positive-and-active-gradients-to-boost-saliency-maps"><a href="#A-matter-of-attitude-Focusing-on-positive-and-active-gradients-to-boost-saliency-maps" class="headerlink" title="A matter of attitude: Focusing on positive and active gradients to boost saliency maps"></a>A matter of attitude: Focusing on positive and active gradients to boost saliency maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12913">http://arxiv.org/abs/2309.12913</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oscarllorente/positive_active_saliency_maps">https://github.com/oscarllorente/positive_active_saliency_maps</a></li>
<li>paper_authors: Oscar Llorente, Jaime Boal, Eugenio F. Sánchez-Úbeda</li>
<li>for: 这篇论文旨在探讨如何通过修复权重映射的缺陷，提高多类分类问题中神经网络的解释性。</li>
<li>methods: 该论文使用了修复权重映射的方法，通过恢复权重映射中的符号，提高了对多类分类问题中神经网络的解释性。</li>
<li>results: 研究发现，通过考虑正确类和其他类之间的关系，可以更好地了解神经网络对图像中各个像素的关注。此外，隐藏或改变这些像素会对结果产生什么影响也变得更加清晰。<details>
<summary>Abstract</summary>
Saliency maps have become one of the most widely used interpretability techniques for convolutional neural networks (CNN) due to their simplicity and the quality of the insights they provide. However, there are still some doubts about whether these insights are a trustworthy representation of what CNNs use to come up with their predictions. This paper explores how rescuing the sign of the gradients from the saliency map can lead to a deeper understanding of multi-class classification problems. Using both pretrained and trained from scratch CNNs we unveil that considering the sign and the effect not only of the correct class, but also the influence of the other classes, allows to better identify the pixels of the image that the network is really focusing on. Furthermore, how occluding or altering those pixels is expected to affect the outcome also becomes clearer.
</details>
<details>
<summary>摘要</summary>
静观地図（Saliency map）已成为 convolutional neural network（CNN）的解释技术中最广泛使用的一种，这主要是因为它的简单性和解释的质量。然而，有些人仍存在对静观地図是否准确反映CNN的预测过程中的信息的 doubts。这篇文章探讨了如何从静观地図中救出梯度的正负信息，以便更深入地理解多类分类问题。我们使用预训练和从scratch预测的CNN，发现考虑正负信息和其他类的影响，可以更好地定位图像中网络是真正关注的像素。此外，对这些像素进行遮盖或修改也会对结果产生什么影响也变得更加清楚。
</details></li>
</ul>
<hr>
<h2 id="KG-MDL-Mining-Graph-Patterns-in-Knowledge-Graphs-with-the-MDL-Principle"><a href="#KG-MDL-Mining-Graph-Patterns-in-Knowledge-Graphs-with-the-MDL-Principle" class="headerlink" title="KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle"></a>KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12908">http://arxiv.org/abs/2309.12908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Bariatti, Peggy Cellier, Sébastien Ferré</li>
<li>for: 本文targets the problem of extracting meaningful graph patterns from large knowledge graphs (KGs), which are difficult to mine due to their size and complexity.</li>
<li>methods: 本文提出了一种基于最小描述长度（MDL）原理的图Pattern mining approach called KG-MDL, which generates a human-sized and descriptive set of graph patterns for a given KG.</li>
<li>results: 实验表明，KG-MDL可以生成小 enough to be interpreted by humans yet descriptive of the KG的pattern set, highlighting both the schema used to create the data and the concrete facts it contains.<details>
<summary>Abstract</summary>
Nowadays, increasingly more data are available as knowledge graphs (KGs). While this data model supports advanced reasoning and querying, they remain difficult to mine due to their size and complexity. Graph mining approaches can be used to extract patterns from KGs. However this presents two main issues. First, graph mining approaches tend to extract too many patterns for a human analyst to interpret (pattern explosion). Second, real-life KGs tend to differ from the graphs usually treated in graph mining: they are multigraphs, their vertex degrees tend to follow a power-law, and the way in which they model knowledge can produce spurious patterns. Recently, a graph mining approach named GraphMDL+ has been proposed to tackle the problem of pattern explosion, using the Minimum Description Length (MDL) principle. However, GraphMDL+, like other graph mining approaches, is not suited for KGs without adaptations. In this paper we propose KG-MDL, a graph pattern mining approach based on the MDL principle that, given a KG, generates a human-sized and descriptive set of graph patterns, and so in a parameter-less and anytime way. We report on experiments on medium-sized KGs showing that our approach generates sets of patterns that are both small enough to be interpreted by humans and descriptive of the KG. We show that the extracted patterns highlight relevant characteristics of the data: both of the schema used to create the data, and of the concrete facts it contains. We also discuss the issues related to mining graph patterns on knowledge graphs, as opposed to other types of graph data.
</details>
<details>
<summary>摘要</summary>
现在，知识图（KG）中的数据越来越多，这种数据模型支持高级推理和查询，但它们仍然具有困难 mine 的问题。图минаING Approaches可以提取图中的模式，但这有两个主要问题。首先，图MINING Approaches通常会提取太多的模式，让人类分析者难以处理（pattern explosion）。其次，实际的 KG 与通常在图MINING 中处理的图不同：它们是多 graphs，顶点度遵循力� law，以及知识表示方式可能会生成假Pattern。最近，一种名为 GraphMDL+ 的图MINING Approach 被提出，使用最小描述长度（MDL）原理来解决pattern explosion问题。然而，GraphMDL+ 和其他图MINING Approaches不适用于 KG 而不需要更多的参数。在这篇论文中，我们提出了基于 MDL 原理的图模式挖掘方法，可以给 KG 生成一个人类可以理解的、描述性的图模式集，并且在无参数和实时的情况下进行。我们对中等规模的 KG 进行了实验，并证明了我们的方法可以生成小 enough 且描述性的图模式集，并且这些模式集可以高亮 KG 中的schema和具体事实。我们还讨论了对知识图进行图模式挖掘的问题，与其他类型的图数据进行比较。
</details></li>
</ul>
<hr>
<h2 id="ProtoEM-A-Prototype-Enhanced-Matching-Framework-for-Event-Relation-Extraction"><a href="#ProtoEM-A-Prototype-Enhanced-Matching-Framework-for-Event-Relation-Extraction" class="headerlink" title="ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction"></a>ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12892">http://arxiv.org/abs/2309.12892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhilei Hu, Zixuan Li, Daozhu Xu, Long Bai, Cheng Jin, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng</li>
<li>for: 本研究旨在提取文本中的多种事件关系，并尝试更好地捕捉这些关系的内在 semantics。</li>
<li>methods: 本研究使用 Prototype-Enhanced Matching (ProtoEM) 框架，包括 prototype representing 和 prototype matching 两个步骤。在第一步中，使用例子来表示不同类型的事件关系的词义特征。在第二步中，使用图 neural network (GNN) 模块来模型事件关系之间的依赖关系。</li>
<li>results: 实验结果表明，ProtoEM 框架可以有效地表示事件关系的词义特征，并在 MAVEN-ERE 数据集上具有显著的提高效果 compared to baseline models。<details>
<summary>Abstract</summary>
Event Relation Extraction (ERE) aims to extract multiple kinds of relations among events in texts. However, existing methods singly categorize event relations as different classes, which are inadequately capturing the intrinsic semantics of these relations. To comprehensively understand their intrinsic semantics, in this paper, we obtain prototype representations for each type of event relation and propose a Prototype-Enhanced Matching (ProtoEM) framework for the joint extraction of multiple kinds of event relations. Specifically, ProtoEM extracts event relations in a two-step manner, i.e., prototype representing and prototype matching. In the first step, to capture the connotations of different event relations, ProtoEM utilizes examples to represent the prototypes corresponding to these relations. Subsequently, to capture the interdependence among event relations, it constructs a dependency graph for the prototypes corresponding to these relations and utilized a Graph Neural Network (GNN)-based module for modeling. In the second step, it obtains the representations of new event pairs and calculates their similarity with those prototypes obtained in the first step to evaluate which types of event relations they belong to. Experimental results on the MAVEN-ERE dataset demonstrate that the proposed ProtoEM framework can effectively represent the prototypes of event relations and further obtain a significant improvement over baseline models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>prototype representing：通过使用例子来表示不同的事件关系的核心含义。2. prototype matching：使用一个基于图 neural network (GNN) 的模块来模型事件关系之间的依赖关系，然后将新的事件对比与已有的原型来评估它们属于哪种事件关系。实验结果表明，ProtoEM 框架可以有效地表示事件关系的原型，并在基eline模型上获得了显著改进。</details></li>
</ol>
<hr>
<h2 id="Gravity-Network-for-end-to-end-small-lesion-detection"><a href="#Gravity-Network-for-end-to-end-small-lesion-detection" class="headerlink" title="Gravity Network for end-to-end small lesion detection"></a>Gravity Network for end-to-end small lesion detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12876">http://arxiv.org/abs/2309.12876</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cirorusso2910/gravitynet">https://github.com/cirorusso2910/gravitynet</a></li>
<li>paper_authors: Ciro Russo, Alessandro Bria, Claudio Marrocco</li>
<li>for: 检测医疗影像中的小 lesion</li>
<li>methods: 提出了一种新的一stage末端检测器，通过引入新的像素基于气场点，动态追踪目标小 lesion进行检测</li>
<li>results: 在两个常见的医疗影像任务中（数字乳腺影像和数字胆囊影像），方法展现出了有效地检测小 lesion的表现<details>
<summary>Abstract</summary>
This paper introduces a novel one-stage end-to-end detector specifically designed to detect small lesions in medical images. Precise localization of small lesions presents challenges due to their appearance and the diverse contextual backgrounds in which they are found. To address this, our approach introduces a new type of pixel-based anchor that dynamically moves towards the targeted lesion for detection. We refer to this new architecture as GravityNet, and the novel anchors as gravity points since they appear to be "attracted" by the lesions. We conducted experiments on two well-established medical problems involving small lesions to evaluate the performance of the proposed approach: microcalcifications detection in digital mammograms and microaneurysms detection in digital fundus images. Our method demonstrates promising results in effectively detecting small lesions in these medical imaging tasks.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的一stage端到端检测器，用于检测医疗图像中的小肿。由于小肿的外观和背景的多样性，精准地定位小肿呈现了挑战。为解决这个问题，我们的方法引入了一种新的像素基的锚点，这些锚点在检测过程中会动态向着目标小肿移动。我们称这种新架构为重力网络（GravityNet），这些新锚点为重力点（Gravity Point），因为它们看起来像是吸引小肿的。我们在两个常见的医学问题中进行了实验：数字乳腺癌检测和数字血管图像中的微血管检测。我们的方法在这些医学检测任务中表现出色，能够有效地检测小肿。
</details></li>
</ul>
<hr>
<h2 id="AnglE-optimized-Text-Embeddings"><a href="#AnglE-optimized-Text-Embeddings" class="headerlink" title="AnglE-optimized Text Embeddings"></a>AnglE-optimized Text Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12871">http://arxiv.org/abs/2309.12871</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SeanLee97/AnglE">https://github.com/SeanLee97/AnglE</a></li>
<li>paper_authors: Xianming Li, Jing Li</li>
<li>for: 提高Semantic Textual Similarity（STS）任务的质量文本嵌入，帮助提高Large Language Model（LLM）应用程序的性能。</li>
<li>methods: 提出了一种新的角度优化文本嵌入模型AnglE，通过引入角度优化来解决cosine函数中的恶性区域问题，从而提高 gradient 的演化和优化过程。</li>
<li>results: 对于短文本STS任务和新收集的长文本STS任务以及域специфи STS任务，AnglE 比State-of-the-art（SOTA）STS模型表现更好， demonstrating the ability of AnglE to generate high-quality text embeddings and the usefulness of angle optimization in STS.<details>
<summary>Abstract</summary>
High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works with LLM-annotated data. Extensive experiments were conducted on various tasks including short-text STS, long-text STS, and domain-specific STS tasks. The results show that AnglE outperforms the state-of-the-art (SOTA) STS models that ignore the cosine saturation zone. These findings demonstrate the ability of AnglE to generate high-quality text embeddings and the usefulness of angle optimization in STS.
</details>
<details>
<summary>摘要</summary>
高品质文本嵌入是 LLM 应用中关键的Semantic Textual Similarity (STS) 任务的提高的关键，但是现有的文本嵌入模型面临着让 Gradient 消失的挑战，主要是因为它们对 cosine 函数在优化目标中的使用，这会导致缺失区域。为解决这个问题，本文提出了一种新的角度优化文本嵌入模型 called AnglE。 AnglE 的核心思想是在复杂空间中引入角度优化。这种新的方法可以有效地减轻 cosine 函数的缺失区域的影响，从而使得梯度和优化过程得到改善。为进行全面的 STS 评估，我们对现有的短文本 STS 数据集和从 GitHub Issues 上收集的新的长文本 STS 数据集进行实验。此外，我们还研究了受限制的数据集和使用 LLM 标注数据的域特性 STS 场景。我们进行了各种任务，包括短文本 STS、长文本 STS 和域特性 STS 任务。结果表明，AnglE 在忽略 cosine 缺失区域的 SOTA STS 模型之上表现出色，这些发现证明了 AnglE 的能力生成高质量文本嵌入和角度优化在 STS 中的有用性。
</details></li>
</ul>
<hr>
<h2 id="Accurate-and-Fast-Compressed-Video-Captioning"><a href="#Accurate-and-Fast-Compressed-Video-Captioning" class="headerlink" title="Accurate and Fast Compressed Video Captioning"></a>Accurate and Fast Compressed Video Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12867">http://arxiv.org/abs/2309.12867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/acherstyx/CoCap">https://github.com/acherstyx/CoCap</a></li>
<li>paper_authors: Yaojie Shen, Xin Gu, Kai Xu, Heng Fan, Longyin Wen, Libo Zhang</li>
<li>for: 这种论文是为了提出一种新的视频描述方法，以解决现有视频描述方法中的扫描缺陷。</li>
<li>methods: 该方法使用了压缩视频域的特征，包括I帧、运动向量和差异，并设计了一种特殊的变换器来学习描述视频。</li>
<li>results: 该方法可以在不同的benchmark上达到状态 arts的性能，同时运行速度比现有方法快得多。<details>
<summary>Abstract</summary>
Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet effective end-to-end transformer in the compressed domain for video captioning that enables learning from the compressed video for captioning. We show that even with a simple design, our method can achieve state-of-the-art performance on different benchmarks while running almost 2x faster than existing approaches. Code is available at https://github.com/acherstyx/CoCap.
</details>
<details>
<summary>摘要</summary>
传统的视频描述方法通常需要先从解码后的视频抽取一些帧并进行后续处理（例如特征提取和/或描述模型学习）。在这个管道中，人工抽取帧可能会忽略视频中的关键信息，从而降低性能。此外，抽取的帧中可能包含重复的信息，导致在视频描述中的效率低下。为了解决这些问题，我们从压缩频道的视角研究视频描述，它带来了多重优势：1）相比于解码后的原始图像，压缩视频中的I-帧、运动向量和差异，具有高度可识别性，允许我们通过特殊的模型设计不需要人工抽取来学习整个视频;2）描述模型在推理中更高效，因为处理的信息更小和更少重复。我们提出了一种简单 yet 有效的终端转换器在压缩频道中进行视频描述，允许我们从压缩视频中学习描述。我们示出了我们的方法可以在不同的标准上达到领先的性能，同时运行速度比现有方法快得多于2倍。代码可以在https://github.com/acherstyx/CoCap中获取。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-for-Arabic-Machine-Translation-The-Case-of-Financial-Texts"><a href="#Domain-Adaptation-for-Arabic-Machine-Translation-The-Case-of-Financial-Texts" class="headerlink" title="Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts"></a>Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12863">http://arxiv.org/abs/2309.12863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emad A. Alghamdi, Jezia Zakraoui, Fares A. Abanmy</li>
<li>for: 本研究目的是探讨阿拉伯语机器翻译（AMT）在未曾探讨的领域中的效果，具体来说是在金融新闻文章的翻译中。</li>
<li>methods: 我们开发了一个精心制作的阿拉伯语-英语（AR-EN）翻译并 fine-tuning 多种预训练的神经机器翻译和大语言模型，包括 ChatGPT-3.5 Turbo。</li>
<li>results: 我们发现，只需要一些良好的AR-EN对应的域 adaptation  segments， fine-tuning 就能够成功。 ChatGPT 的翻译质量较高，超过其他模型的自动和人工评估。 这是首次将 ChatGPT  fine-tuning 应用于金融领域域传输学习。<details>
<summary>Abstract</summary>
Neural machine translation (NMT) has shown impressive performance when trained on large-scale corpora. However, generic NMT systems have demonstrated poor performance on out-of-domain translation. To mitigate this issue, several domain adaptation methods have recently been proposed which often lead to better translation quality than genetic NMT systems. While there has been some continuous progress in NMT for English and other European languages, domain adaption in Arabic has received little attention in the literature. The current study, therefore, aims to explore the effectiveness of domain-specific adaptation for Arabic MT (AMT), in yet unexplored domain, financial news articles. To this end, we developed carefully a parallel corpus for Arabic-English (AR- EN) translation in the financial domain for benchmarking different domain adaptation methods. We then fine-tuned several pre-trained NMT and Large Language models including ChatGPT-3.5 Turbo on our dataset. The results showed that the fine-tuning is successful using just a few well-aligned in-domain AR-EN segments. The quality of ChatGPT translation was superior than other models based on automatic and human evaluations. To the best of our knowledge, this is the first work on fine-tuning ChatGPT towards financial domain transfer learning. To contribute to research in domain translation, we made our datasets and fine-tuned models available at https://huggingface.co/asas-ai/.
</details>
<details>
<summary>摘要</summary>
神经机器翻译（NMT）在大规模训练 corpora 上显示了很好的性能。然而，通用 NMT 系统在域外翻译中表现不佳。为了解决这个问题，一些域 adaptation 方法在过去几年得到了广泛的关注，并常常比通用 NMT 系统的翻译质量更高。英语和其他欧洲语言的 NMT 曾经得到了相当的研究，但在阿拉伯语中的域 adaptation 却受到了 littlet 的关注。因此，本研究的目的是探索在金融新闻文章中使用域adaptation 技术来提高阿拉伯语翻译质量。为此，我们开发了一个精心制作的阿拉伯语-英语（AR-EN）翻译 parallel corpus，并在这个dataset上练习了多种域 adaptation 方法。我们还对多种预训练的 NMT 和 Large Language 模型进行了练习，包括 ChatGPT-3.5 Turbo。结果表明，只需要几个Well-aligned in-domain AR-EN段，我们可以成功地进行了练习。ChatGPT 的翻译质量比其他模型更高，根据自动和人类评估。据我们所知，这是首次在金融域转移学习中使用 ChatGPT 进行了 fine-tuning。为了贡献到域翻译研究，我们将我们的dataset和练习模型上传到了https://huggingface.co/asas-ai/。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Augmentation-for-Sequential-Recommendation"><a href="#Diffusion-Augmentation-for-Sequential-Recommendation" class="headerlink" title="Diffusion Augmentation for Sequential Recommendation"></a>Diffusion Augmentation for Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12858">http://arxiv.org/abs/2309.12858</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuqidong07/diffuasr">https://github.com/liuqidong07/diffuasr</a></li>
<li>paper_authors: Qidong Liu, Fan Yan, Xiangyu Zhao, Zhaocheng Du, Huifeng Guo, Ruiming Tang, Feng Tian</li>
<li>for: 这篇论文的目的是解决紧缩式推荐（SRS）中的数据罕见问题和长尾用户问题。</li>
<li>methods: 这篇论文提出了一种叫做散射增强（DiffuASR）的方法，它可以生成高质量的增强数据，并且可以直接使用这些增强数据来训练紧缩式推荐模型。</li>
<li>results: 根据实验结果，DiffuASR 能够有效地解决紧缩式推荐中的数据罕见问题和长尾用户问题，并且可以提高紧缩式推荐模型的表现。<details>
<summary>Abstract</summary>
Sequential recommendation (SRS) has become the technical foundation in many applications recently, which aims to recommend the next item based on the user's historical interactions. However, sequential recommendation often faces the problem of data sparsity, which widely exists in recommender systems. Besides, most users only interact with a few items, but existing SRS models often underperform these users. Such a problem, named the long-tail user problem, is still to be resolved. Data augmentation is a distinct way to alleviate these two problems, but they often need fabricated training strategies or are hindered by poor-quality generated interactions. To address these problems, we propose a Diffusion Augmentation for Sequential Recommendation (DiffuASR) for a higher quality generation. The augmented dataset by DiffuASR can be used to train the sequential recommendation models directly, free from complex training procedures. To make the best of the generation ability of the diffusion model, we first propose a diffusion-based pseudo sequence generation framework to fill the gap between image and sequence generation. Then, a sequential U-Net is designed to adapt the diffusion noise prediction model U-Net to the discrete sequence generation task. At last, we develop two guide strategies to assimilate the preference between generated and origin sequences. To validate the proposed DiffuASR, we conduct extensive experiments on three real-world datasets with three sequential recommendation models. The experimental results illustrate the effectiveness of DiffuASR. As far as we know, DiffuASR is one pioneer that introduce the diffusion model to the recommendation.
</details>
<details>
<summary>摘要</summary>
受sequential recommendation（SRS）技术支持，许多应用程序在最近得到了技术基础。SRS的目标是根据用户的历史交互来推荐下一个项目，但是SRS经常面临数据稀缺的问题，这种问题广泛存在于推荐系统中。另外，大多数用户只与几个项目进行交互，而现有的SRS模型往往不能满足这些用户。这种问题被称为长尾用户问题，仍需解决。数据扩展是一种有效的解决方法，但是它们通常需要复杂的训练策略或低质量生成的交互。为解决这些问题，我们提出了一种增强的数据扩展方法，即增强数据扩展（DiffuASR），可以为高质量生成提供基础。DiffuASR生成的扩展数据可以直接用于训练SRS模型，不需训练复杂的策略。为了利用扩展模型的生成能力，我们首先提出了一种基于扩散的pseudo序列生成框架，用于填充图像和序列生成之间的差异。然后，我们设计了一种序列U-Net，用于适应扩散噪声预测模型U-Net。最后，我们开发了两种引导策略，以便在生成和原始序列之间融合喜好。为验证我们提出的DiffuASR，我们在三个真实世界数据集上进行了广泛的实验，使用三种序列推荐模型。实验结果表明，DiffuASR是有效的。到目前为止，DiffuASR是对推荐领域中的扩展模型做出的开创性贡献。
</details></li>
</ul>
<hr>
<h2 id="AxOCS-Scaling-FPGA-based-Approximate-Operators-using-Configuration-Supersampling"><a href="#AxOCS-Scaling-FPGA-based-Approximate-Operators-using-Configuration-Supersampling" class="headerlink" title="AxOCS: Scaling FPGA-based Approximate Operators using Configuration Supersampling"></a>AxOCS: Scaling FPGA-based Approximate Operators using Configuration Supersampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12830">http://arxiv.org/abs/2309.12830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siva Satyendra Sahoo, Salim Ullah, Soumyo Bhattacharjee, Akash Kumar</li>
<li>For: 这个研究旨在提供一个基于机器学习的精简数据类型设计方法，以减少嵌入式系统中的机器学习实现成本。* Methods: 本研究使用了机器学习基于设计空间探索技术，并利用了机器学习方法来预测PPA和BEHAV的影响。* Results: 实验结果显示，提案的AxOCS方法可以对FPGA优化的精简数据类型进行多目标优化，并获得了较高的品质结果范围。<details>
<summary>Abstract</summary>
The rising usage of AI and ML-based processing across application domains has exacerbated the need for low-cost ML implementation, specifically for resource-constrained embedded systems. To this end, approximate computing, an approach that explores the power, performance, area (PPA), and behavioral accuracy (BEHAV) trade-offs, has emerged as a possible solution for implementing embedded machine learning. Due to the predominance of MAC operations in ML, designing platform-specific approximate arithmetic operators forms one of the major research problems in approximate computing. Recently there has been a rising usage of AI/ML-based design space exploration techniques for implementing approximate operators. However, most of these approaches are limited to using ML-based surrogate functions for predicting the PPA and BEHAV impact of a set of related design decisions. While this approach leverages the regression capabilities of ML methods, it does not exploit the more advanced approaches in ML. To this end, we propose AxOCS, a methodology for designing approximate arithmetic operators through ML-based supersampling. Specifically, we present a method to leverage the correlation of PPA and BEHAV metrics across operators of varying bit-widths for generating larger bit-width operators. The proposed approach involves traversing the relatively smaller design space of smaller bit-width operators and employing its associated Design-PPA-BEHAV relationship to generate initial solutions for metaheuristics-based optimization for larger operators. The experimental evaluation of AxOCS for FPGA-optimized approximate operators shows that the proposed approach significantly improves the quality-resulting hypervolume for multi-objective optimization-of 8x8 signed approximate multipliers.
</details>
<details>
<summary>摘要</summary>
随着人工智能和机器学习处理的应用领域扩大，低成本机器学习实现成为了一个紧迫的需求，特别是 для具有限制的嵌入式系统。为此，精确计算，一种探讨功能、性能、面积（PPA）和行为准确率（BEHAV）的负担规划，已经出现为实现嵌入式机器学习的可能解决方案。由于机器学习中的主要操作是 MAC 操作，因此设计特定平台的精确计算操作成为了研究中的主要问题。最近，人工智能/机器学习基于的设计空间探索技术已经广泛应用于实现精确操作。然而，大多数这些方法仅通过使用机器学习基于的代表函数预测 PPA 和 BEHAV 指标的影响来进行设计。这种方法利用机器学习方法的回归能力，但并不利用更高级别的机器学习方法。为此，我们提出了 AxOCS，一种通过机器学习基于supersampling的精确计算操作设计方法。具体来说，我们提出了一种利用不同位数的运算符之间的 correlation 关系来生成更大位数的运算符的方法。我们的方法是在更小的设计空间中查找更小的位数运算符的解决方案，并使用其相关的 Design-PPA-BEHAV 关系来生成初始的优化解决方案。我们的实验表明，AxOCS 可以对 FPGA 优化的精确 multiply 操作进行多目标优化，并显著提高了质量结果的卷积体积。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Boost-Leveraging-Synthetic-Data-for-Enhanced-Vision-Language-Segmentation-in-Echocardiography"><a href="#Synthetic-Boost-Leveraging-Synthetic-Data-for-Enhanced-Vision-Language-Segmentation-in-Echocardiography" class="headerlink" title="Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography"></a>Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12829">http://arxiv.org/abs/2309.12829</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naamiinepal/synthetic-boost">https://github.com/naamiinepal/synthetic-boost</a></li>
<li>paper_authors: Rabin Adhikari, Manish Dhakal, Safal Thapaliya, Kanchan Poudel, Prasiddha Bhandari, Bishesh Khanal</li>
<li>for: 本研究旨在提高echocardiography图像分割的准确率，使用视力语言分割模型（VLSM），并利用Semantic Diffusion Models（SDM）生成的synthetic图像来增强VLSM的表现。</li>
<li>methods: 本研究使用了两种popular VLSMs（CLIPSeg和CRIS），并使用了七种不同的语言提示（derived from several attributes，自动提取自echocardiography图像、分割masks和metadata）。</li>
<li>results: 研究结果表明，在使用SDM生成的synthetic图像进行预训练后，VLSM的表现得到了提高，并且 convergence faster。code、配置和提示可以在<a target="_blank" rel="noopener" href="https://github.com/naamiinepal/synthetic-boost%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/naamiinepal/synthetic-boost上获取。</a><details>
<summary>Abstract</summary>
Accurate segmentation is essential for echocardiography-based assessment of cardiovascular diseases (CVDs). However, the variability among sonographers and the inherent challenges of ultrasound images hinder precise segmentation. By leveraging the joint representation of image and text modalities, Vision-Language Segmentation Models (VLSMs) can incorporate rich contextual information, potentially aiding in accurate and explainable segmentation. However, the lack of readily available data in echocardiography hampers the training of VLSMs. In this study, we explore using synthetic datasets from Semantic Diffusion Models (SDMs) to enhance VLSMs for echocardiography segmentation. We evaluate results for two popular VLSMs (CLIPSeg and CRIS) using seven different kinds of language prompts derived from several attributes, automatically extracted from echocardiography images, segmentation masks, and their metadata. Our results show improved metrics and faster convergence when pretraining VLSMs on SDM-generated synthetic images before finetuning on real images. The code, configs, and prompts are available at https://github.com/naamiinepal/synthetic-boost.
</details>
<details>
<summary>摘要</summary>
准确的分割是诊断卡地狱疾病（CVD）的关键。然而，医生之间的差异和超声图像本身的挑战使得准确的分割受到阻碍。通过利用图像和文本Modalities的共同表示，视觉语言分割模型（VLSM）可以捕捉更多的上下文信息，可能帮助实现准确和可解释的分割。然而，有限的实际数据使得训练VLSM困难。在这项研究中，我们探讨使用Semantic Diffusion Models（SDM）生成的 sintetic dataset来增强VLSM的echocardiography分割。我们对两种流行的VLSM（CLIPSeg和CRIS）进行评估，使用七种不同的语言提示，自动从echocardiography图像、分割mask和其Metadata中提取的多种属性。我们的结果表明，在先行训练VLSM在SDM生成的 sintetic图像后，再进行 fine-tuning on real images 中，可以提高 metric 并且更快地 converges。代码、配置和提示可以在https://github.com/naamiinepal/synthetic-boost中找到。
</details></li>
</ul>
<hr>
<h2 id="OmniDrones-An-Efficient-and-Flexible-Platform-for-Reinforcement-Learning-in-Drone-Control"><a href="#OmniDrones-An-Efficient-and-Flexible-Platform-for-Reinforcement-Learning-in-Drone-Control" class="headerlink" title="OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control"></a>OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12825">http://arxiv.org/abs/2309.12825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Botian Xu, Feng Gao, Chao Yu, Ruize Zhang, Yi Wu, Yu Wang</li>
<li>for: 本研究提出了一个高效可扩展的平台，用于在凝视掌控中应用强化学习，基于Nvidia的Omniverse Isaac Sim。</li>
<li>methods: 该平台采用底层设计方法，允许用户轻松设计和实验各种应用场景，并在GPU并行的 simulations 上进行加速。</li>
<li>results: 该平台提供了多种标准任务，包括单批静止、多批静止和过 actuated 系统跟踪等，并提供了一些广泛使用的RL基elines。作者还提供了一些先行结果，以示Platform的能力和支持未来研究。<details>
<summary>Abstract</summary>
In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia's Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们介绍OmniDrones，一个高效和灵活的平台，适用于强化学习控制飞行器，基于Nvidia的Omniverse Isaac Sim。它采用底层设计方法，允许用户轻松地设计和实验各种应用场景，并在GPU平行化的 simulations 上进行了加速。它还提供了一系列的 benchmark 任务，展示了从单架飞行器停在位pto 多架飞行器跟踪系统的挑战。总之，我们提出了一个开源的飞行器 simulate平台，具有广泛的工具，用于飞行器学习。它包括4架飞行器模型、5种感知模式、4种控制方式、超过10个 benchmark 任务，以及一些通用的RL基elines。为了证明OmniDrones的能力和支持未来研究，我们也提供了先行结果这些 benchmark 任务。我们希望这个平台能够鼓励更多的研究人员通过应用RL来解决实际飞行器系统的问题。
</details></li>
</ul>
<hr>
<h2 id="A-Spectral-Theory-of-Neural-Prediction-and-Alignment"><a href="#A-Spectral-Theory-of-Neural-Prediction-and-Alignment" class="headerlink" title="A Spectral Theory of Neural Prediction and Alignment"></a>A Spectral Theory of Neural Prediction and Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12821">http://arxiv.org/abs/2309.12821</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdulkadir Canatar, Jenelle Feather, Albert Wakhloo, SueYeon Chung</li>
<li>for: 这个论文的目的是尝试理解深度神经网络如何预测神经活动。</li>
<li>methods: 该论文使用了一种新的理论框架，将泛化误差与模型活动的 спектраль偏好以及神经响应的对齐关系联系起来。</li>
<li>results: 研究发现，使用多种深度神经网络可以获得低级别神经预测误差，且每种神经网络都有不同的表达形式。这些结果表明，可以通过分析表达形式来了解神经网络如何捕捉神经活动。<details>
<summary>Abstract</summary>
The representations of neural networks are often compared to those of biological systems by performing regression between the neural network responses and those measured from biological systems. Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral bias of the model activations and the alignment of the neural responses onto the learnable subspace of the model. We extend this theory to the case of regression between model activations and neural responses, and define geometrical properties describing the error embedding geometry. We test a large number of deep neural networks that predict visual cortical activity and show that there are multiple types of geometries that result in low neural prediction error as measured via regression. The work demonstrates that carefully decomposing representational metrics can provide interpretability of how models are capturing neural activity and points the way towards improved models of neural activity.
</details>
<details>
<summary>摘要</summary>
neural network 的表示方式 часто和生物系统相比，通过 regression 来比较 neural network 的响应和生物系统测量的响应。许多 state-of-the-art deep neural network 具有类似的预测性能，但是还不清楚如何区分这些模型在预测 neural network 响应的时候表现出类似的性能。为了增加这些信息，我们使用了最近的理论框架，将泛化误差从回归相关到模型活动的spectral bias和模型学习的子空间对齐。我们将这些理论扩展到模型活动和 neural network 之间的回归问题，并定义了 geometrical properties 描述错误嵌入几何。我们测试了许多 deep neural network，它们预测的视觉 Cortical activity 和实际测量的响应之间存在多种几何，这些几何都能够实现低级别预测错误。这项工作显示，细分表示度量可以提供如何模型捕捉 neural activity的解释，并指向了改进的 neural activity 模型。
</details></li>
</ul>
<hr>
<h2 id="Computational-Natural-Philosophy-A-Thread-from-Presocratics-through-Turing-to-ChatGPT"><a href="#Computational-Natural-Philosophy-A-Thread-from-Presocratics-through-Turing-to-ChatGPT" class="headerlink" title="Computational Natural Philosophy: A Thread from Presocratics through Turing to ChatGPT"></a>Computational Natural Philosophy: A Thread from Presocratics through Turing to ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13094">http://arxiv.org/abs/2309.13094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gordana Dodig-Crnkovic</li>
<li>for: 这篇论文旨在探讨计算自然哲学如何理解自然世界，以及如何通过计算机科学和人工智能技术来研究认知和智能。</li>
<li>methods: 这篇论文使用了计算机科学和人工智能的方法，包括深度神经网络和强化学习。</li>
<li>results: 这篇论文描述了一种基于深度神经网络的大语言模型（LLM），并通过人类反馈强化学习（RLHF）来训练这种模型。<details>
<summary>Abstract</summary>
Modern computational natural philosophy conceptualizes the universe in terms of information and computation, establishing a framework for the study of cognition and intelligence. Despite some critiques, this computational perspective has significantly influenced our understanding of the natural world, leading to the development of AI systems like ChatGPT based on deep neural networks. Advancements in this domain have been facilitated by interdisciplinary research, integrating knowledge from multiple fields to simulate complex systems. Large Language Models (LLMs), such as ChatGPT, represent this approach's capabilities, utilizing reinforcement learning with human feedback (RLHF). Current research initiatives aim to integrate neural networks with symbolic computing, introducing a new generation of hybrid computational models.
</details>
<details>
<summary>摘要</summary>
现代计算自然哲学将宇宙视为信息和计算的框架，为认知和智能的研究提供了一个框架。虽有一些批评，但这种计算视角已经对自然世界的理解产生了深远的影响，导致了基于深度神经网络的AI系统，如ChatGPT。这个领域的进步得益于多学科研究的整合，将多个领域的知识融合到模拟复杂系统中。大语言模型（LLMs），如ChatGPT，表示这种方法的能力，通过人工增强学习（RLHF）。当前的研究启动旨在将神经网络与符号计算结合，推出一代新的混合计算模型。
</details></li>
</ul>
<hr>
<h2 id="Masking-Improves-Contrastive-Self-Supervised-Learning-for-ConvNets-and-Saliency-Tells-You-Where"><a href="#Masking-Improves-Contrastive-Self-Supervised-Learning-for-ConvNets-and-Saliency-Tells-You-Where" class="headerlink" title="Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where"></a>Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12757">http://arxiv.org/abs/2309.12757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhi-Yi Chin, Chieh-Ming Jiang, Ching-Chun Huang, Pin-Yu Chen, Wei-Chen Chiu</li>
<li>for: 提高 ConvNet 自动学习效果，使其能够更好地利用掩蔽操作进行自我超vision transformer 的学习。</li>
<li>methods: 在 ConvNet 框架中引入掩蔽操作，并考虑图像中重要对象的焦点分布，以避免掩蔽操作对图像的损害。另外，引入硬negative sample，使用更大的掩蔽区域来提高对抗样本的精度。</li>
<li>results: 在多个数据集、对抗学习机制和下游任务中，提出的方法在许多情况下表现出优于多个基eline。<details>
<summary>Abstract</summary>
While image data starts to enjoy the simple-but-effective self-supervised learning scheme built upon masking and self-reconstruction objective thanks to the introduction of tokenization procedure and vision transformer backbone, convolutional neural networks as another important and widely-adopted architecture for image data, though having contrastive-learning techniques to drive the self-supervised learning, still face the difficulty of leveraging such straightforward and general masking operation to benefit their learning process significantly. In this work, we aim to alleviate the burden of including masking operation into the contrastive-learning framework for convolutional neural networks as an extra augmentation method. In addition to the additive but unwanted edges (between masked and unmasked regions) as well as other adverse effects caused by the masking operations for ConvNets, which have been discussed by prior works, we particularly identify the potential problem where for one view in a contrastive sample-pair the randomly-sampled masking regions could be overly concentrated on important/salient objects thus resulting in misleading contrastiveness to the other view. To this end, we propose to explicitly take the saliency constraint into consideration in which the masked regions are more evenly distributed among the foreground and background for realizing the masking-based augmentation. Moreover, we introduce hard negative samples by masking larger regions of salient patches in an input image. Extensive experiments conducted on various datasets, contrastive learning mechanisms, and downstream tasks well verify the efficacy as well as the superior performance of our proposed method with respect to several state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
而图像数据在使用简单 yet effective的自我超vised学习算法基于masking和自我重建目标时，卷积神经网络作为图像数据的另一个重要和广泛采用的建筑物，虽然通过对它们的contrastive学习技术进行驱动，仍然面临masking操作不能够帮助它们的学习过程获得显著改进的问题。在这项工作中，我们想要解除对ConvNet的contrastive学习框架中masking操作的添加，以避免在contrastive样本对中 randomly sampling masking区域导致重要/焦点对象上的排序。此外，我们还发现在一个视图中，随机 sampling masking区域可能会过度集中在重要/焦点对象上，从而导致对另一个视图的错误对比性。为了解决这个问题，我们提出了一种explicitly considering saliency constraint的方法，以确保masked区域在背景和前景中具有更均匀的分布。此外，我们还引入硬negative samples，通过在输入图像中masking更大的salient patches来提高对downstream任务的适应性。我们的提议方法在多种dataset、contrastive学习机制和下游任务上进行了广泛的实验，并证明了与一些state-of-the-art基eline相比，我们的方法具有更高的效果和性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-an-MLOps-Architecture-for-XAI-in-Industrial-Applications"><a href="#Towards-an-MLOps-Architecture-for-XAI-in-Industrial-Applications" class="headerlink" title="Towards an MLOps Architecture for XAI in Industrial Applications"></a>Towards an MLOps Architecture for XAI in Industrial Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12756">http://arxiv.org/abs/2309.12756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonhard Faubel, Thomas Woudsma, Leila Methnani, Amir Ghorbani Ghezeljhemeidan, Fabian Buelow, Klaus Schmid, Willem D. van Driel, Benjamin Kloepper, Andreas Theodorou, Mohsen Nosratinia, Magnus Bång</li>
<li>for: 本研究旨在提高机器学习操作（MLOps）中的模型解释和反馈能力，以提高用户信任和采纳率。</li>
<li>methods: 本研究使用了一种新的MLOps软件架构，包括在实际用例中实现了解释和反馈功能。</li>
<li>results: 该软件架构具有高效地管理ML模型生产环境的能力，同时允许 интеграción of 解释和反馈功能。<details>
<summary>Abstract</summary>
Machine learning (ML) has become a popular tool in the industrial sector as it helps to improve operations, increase efficiency, and reduce costs. However, deploying and managing ML models in production environments can be complex. This is where Machine Learning Operations (MLOps) comes in. MLOps aims to streamline this deployment and management process. One of the remaining MLOps challenges is the need for explanations. These explanations are essential for understanding how ML models reason, which is key to trust and acceptance. Better identification of errors and improved model accuracy are only two resulting advantages. An often neglected fact is that deployed models are bypassed in practice when accuracy and especially explainability do not meet user expectations. We developed a novel MLOps software architecture to address the challenge of integrating explanations and feedback capabilities into the ML development and deployment processes. In the project EXPLAIN, our architecture is implemented in a series of industrial use cases. The proposed MLOps software architecture has several advantages. It provides an efficient way to manage ML models in production environments. Further, it allows for integrating explanations into the development and deployment processes.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we developed a novel MLOps software architecture that integrates explanations and feedback capabilities into the ML development and deployment processes. This architecture was implemented in the project EXPLAIN, using a series of industrial use cases. The proposed MLOps software architecture offers several advantages, including an efficient way to manage ML models in production environments and the ability to integrate explanations into the development and deployment processes.
</details></li>
</ul>
<hr>
<h2 id="OpenAi’s-GPT4-as-coding-assistant"><a href="#OpenAi’s-GPT4-as-coding-assistant" class="headerlink" title="OpenAi’s GPT4 as coding assistant"></a>OpenAi’s GPT4 as coding assistant</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12732">http://arxiv.org/abs/2309.12732</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lmous/openai-gpt4-coding-assistant">https://github.com/lmous/openai-gpt4-coding-assistant</a></li>
<li>paper_authors: Lefteris Moussiades, George Zografos</li>
<li>for: 本研究使用GPT3.5和GPT4作为代码生成助手，以检验它们在代码开发过程中的能力。</li>
<li>methods: 研究人员采用了适当的测试来检验GPT3.5和GPT4的能力，包括回答常见代码开发中的问题、生成可靠的代码和帮助代码调试。</li>
<li>results: 测试结果吸引人，GPT4的表现出色，表明这些新工具将提高程序员的产效和重新定义软件开发流程。<details>
<summary>Abstract</summary>
Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools.
</details>
<details>
<summary>摘要</summary>
近期，大型自然语言模型在代码生成方面广泛应用。GPT4被视为Openai中最强大的大型自然语言模型。本文我们将 examine GPT3.5和GPT4作为代码助手。更specifically，我们构建了适当的测试，检查这两个系统是否可以：a) 回答代码开发中可能出现的常见问题，b) 生成可靠的代码，c) 帮助代码调试。测试结果印象良好，GPT4的表现出色，这 signal了程序员的产出力和基于这些新工具的软件开发流程的重新组织。
</details></li>
</ul>
<hr>
<h2 id="Defeasible-Reasoning-with-Knowledge-Graphs"><a href="#Defeasible-Reasoning-with-Knowledge-Graphs" class="headerlink" title="Defeasible Reasoning with Knowledge Graphs"></a>Defeasible Reasoning with Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12731">http://arxiv.org/abs/2309.12731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dave Raggett</li>
<li>for: 本文旨在解决人类知识中的不确定性、不精确性、不完整性和不一致性问题，以及这些问题对semantic web的影响。</li>
<li>methods: 本文提出了一种直观notation和模型，用于解决不确定性推理，并与前期工作关于理据论相关。PKN与N3相比， defeasible reasoning是deductive logic的一种替换。</li>
<li>results: 本文结束时提出了一些关于使用声明性语言描述推理策略和战术的想法，以及基于AIF ontology的灵感。此外，文章还讨论了大语言模型时代的符号approaches。<details>
<summary>Abstract</summary>
Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models.
</details>
<details>
<summary>摘要</summary>
人类知识受到不确定性、不精确性、不完整性和不一致性的影响。此外，许多日常用语的意义取决于上下文。这 pose 巨大挑战 дляsemantic web。本文介绍了一种直观 notation 和模型，用于解决不确定性推理，并与之前的 argumentation theory 相关。PKN 相当于 N3，而 defeasible reasoning 相当于deductive logic。进一步的工作需要对推理策略和 тактики的描述使用声明性语言， drawing upon the AIF ontology for inspiration。文章结束时，讨论了使用 symbolic approaches in the era of large language models。Note: "PKN" stands for "Prefered Knowledge Network", and "AIF" stands for "Approximate Inference Framework".
</details></li>
</ul>
<hr>
<h2 id="In-context-Interference-in-Chat-based-Large-Language-Models"><a href="#In-context-Interference-in-Chat-based-Large-Language-Models" class="headerlink" title="In-context Interference in Chat-based Large Language Models"></a>In-context Interference in Chat-based Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12727">http://arxiv.org/abs/2309.12727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Nuertey Coleman, Julio Hurtado, Vincenzo Lomonaco</li>
<li>for: This paper aims to study the limitations of in-context learning in large language models (LLMs) and its impact on the model’s performance.</li>
<li>methods: The paper uses a black-box scenario to evaluate the in-context learning ability of LLMs, and proposes an evaluation benchmark based on the bAbI dataset.</li>
<li>results: The study shows that in-context learning can lead to interference between information continually flowing in the context, causing the model to forget previously learned knowledge and reducing its performance.<details>
<summary>Abstract</summary>
Large language models (LLMs) have had a huge impact on society due to their impressive capabilities and vast knowledge of the world. Various applications and tools have been created that allow users to interact with these models in a black-box scenario. However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction. This learning process is called in-context training, and it refers to training that is confined to the user's current session or context. In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from interference between information that continually flows in the context, causing it to forget previously learned knowledge, which can reduce the model's performance. Along with showing the problem, we propose an evaluation benchmark based on the bAbI dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="H2O-An-Improved-Framework-for-Hybrid-Offline-and-Online-RL-with-Dynamics-Gaps"><a href="#H2O-An-Improved-Framework-for-Hybrid-Offline-and-Online-RL-with-Dynamics-Gaps" class="headerlink" title="H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps"></a>H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12716">http://arxiv.org/abs/2309.12716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyi Niu, Tianying Ji, Bingqi Liu, Haocheng Zhao, Xiangyu Zhu, Jianying Zheng, Pengfei Huang, Guyue Zhou, Jianming Hu, Xianyuan Zhan</li>
<li>for: This paper focuses on solving real-world complex tasks using reinforcement learning (RL) in imperfect simulation environments and with limited data.</li>
<li>methods: The authors propose a new algorithm called H2O+, which combines offline and online learning methods to address the challenges of sim-to-real transfer and dynamics gaps.</li>
<li>results: The proposed algorithm demonstrates superior performance and flexibility in both simulation and real-world robotics experiments compared to advanced cross-domain online and offline RL algorithms.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文关注使用强化学习（RL）解决实际世界中复杂任务，不需要高精度模拟环境或大量的离线数据。</li>
<li>methods: 作者提出了一种新的算法H2O+，它结合了离线和在线学习方法，以弥补模拟环境和实际环境之间的动态差异。</li>
<li>results: 提出的算法在实验和实际 робо术中表现出了superior性能和灵活性，与高级跨领域在线和离线RL算法相比。<details>
<summary>Abstract</summary>
Solving real-world complex tasks using reinforcement learning (RL) without high-fidelity simulation environments or large amounts of offline data can be quite challenging. Online RL agents trained in imperfect simulation environments can suffer from severe sim-to-real issues. Offline RL approaches although bypass the need for simulators, often pose demanding requirements on the size and quality of the offline datasets. The recently emerged hybrid offline-and-online RL provides an attractive framework that enables joint use of limited offline data and imperfect simulator for transferable policy learning. In this paper, we develop a new algorithm, called H2O+, which offers great flexibility to bridge various choices of offline and online learning methods, while also accounting for dynamics gaps between the real and simulation environment. Through extensive simulation and real-world robotics experiments, we demonstrate superior performance and flexibility over advanced cross-domain online and offline RL algorithms.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:解决实际世界中复杂任务使用回归学习（RL）无需高精度模拟环境或大量的离线数据可以很困难。在线RL代理在不完美的模拟环境中训练后可能会受到严重的模拟到实际（sim-to-real）问题。离线RL方法虽然不需要模拟器，但通常有训练离线数据的质量和量的严格要求。最近出现的混合在线-离线RL提供了一个吸引人的框架，允许在有限的离线数据和不完美的模拟器之间进行可转移的政策学习。在这篇论文中，我们开发了一个新的算法 called H2O+，它提供了很大的灵活性，可以将不同的在线和离线学习方法相互连接，同时也考虑到实际和模拟环境之间的动力差异。通过了较为广泛的模拟和实际机器人实验，我们展示了superior的性能和灵活性，与先进的跨Domain在线和离线RL算法相比。
</details></li>
</ul>
<hr>
<h2 id="The-Mathematical-Game"><a href="#The-Mathematical-Game" class="headerlink" title="The Mathematical Game"></a>The Mathematical Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12711">http://arxiv.org/abs/2309.12711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xploitspeeds/Bookmarklet-Hacks-For-School">https://github.com/xploitspeeds/Bookmarklet-Hacks-For-School</a></li>
<li>paper_authors: Marc Pierre, Quentin Cohen-Solal, Tristan Cazenave</li>
<li>for: 这 paper 用于提高 Holophrasm theorem prover 的性能，使用其他游戏搜索算法。</li>
<li>methods: 这 paper 使用 MCTS combined with 神经网络来实现自动证明。</li>
<li>results: 该 paper 提出了一种基于 MCTS 和神经网络的自动证明方法，以提高 Holophrasm theorem prover 的性能。<details>
<summary>Abstract</summary>
Monte Carlo Tree Search can be used for automated theorem proving. Holophrasm is a neural theorem prover using MCTS combined with neural networks for the policy and the evaluation. In this paper we propose to improve the performance of the Holophrasm theorem prover using other game tree search algorithms.
</details>
<details>
<summary>摘要</summary>
“蒙特卡罗树搜寻”可以用于自动证明。“Holophrasm”是一个使用蒙特卡罗树搜寻和神经网络来决策和评估的神经证明器。在这篇论文中，我们提议使用其他游戏树搜寻算法来提高Holophrasm证明器的性能。
</details></li>
</ul>
<hr>
<h2 id="PointSSC-A-Cooperative-Vehicle-Infrastructure-Point-Cloud-Benchmark-for-Semantic-Scene-Completion"><a href="#PointSSC-A-Cooperative-Vehicle-Infrastructure-Point-Cloud-Benchmark-for-Semantic-Scene-Completion" class="headerlink" title="PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion"></a>PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12708">http://arxiv.org/abs/2309.12708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Yan, Boda Liu, Jianfei Ai, Qinbu Li, Ru Wan, Jian Pu</li>
<li>for: 该论文旨在提出一个 Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion，用于驱动semantic point cloud completion的技术进步。</li>
<li>methods: 该论文使用了一种基于LiDAR的模型，包括一个Spatial-Aware Transformer для全球和本地特征提取，以及一个Completion and Segmentation Cooperative Module для联合完成和分类。</li>
<li>results: 该论文提出了一个名为PointSSC的共同自动车辆-基础设施点云benchmark，用于测试和评估semantic point cloud completion技术的进步。<details>
<summary>Abstract</summary>
Semantic Scene Completion (SSC) aims to jointly generate space occupancies and semantic labels for complex 3D scenes. Most existing SSC models focus on volumetric representations, which are memory-inefficient for large outdoor spaces. Point clouds provide a lightweight alternative but existing benchmarks lack outdoor point cloud scenes with semantic labels. To address this, we introduce PointSSC, the first cooperative vehicle-infrastructure point cloud benchmark for semantic scene completion. These scenes exhibit long-range perception and minimal occlusion. We develop an automated annotation pipeline leveraging Segment Anything to efficiently assign semantics. To benchmark progress, we propose a LiDAR-based model with a Spatial-Aware Transformer for global and local feature extraction and a Completion and Segmentation Cooperative Module for joint completion and segmentation. PointSSC provides a challenging testbed to drive advances in semantic point cloud completion for real-world navigation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Label-Noise-Transition-Matrix-Estimation-with-Label-Correlations-Theory-and-Algorithm"><a href="#Multi-Label-Noise-Transition-Matrix-Estimation-with-Label-Correlations-Theory-and-Algorithm" class="headerlink" title="Multi-Label Noise Transition Matrix Estimation with Label Correlations: Theory and Algorithm"></a>Multi-Label Noise Transition Matrix Estimation with Label Correlations: Theory and Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12706">http://arxiv.org/abs/2309.12706</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tmllab/Multi-Label-T">https://github.com/tmllab/Multi-Label-T</a></li>
<li>paper_authors: Shikun Li, Xiaobo Xia, Hansong Zhang, Shiming Ge, Tongliang Liu</li>
<li>for: 这篇论文旨在解决多标签学习中的噪声问题，因为收集大规模准确标签变得更加困难。</li>
<li>methods: 这篇论文提出了一种使用过渡矩阵来模型多标签噪声的方法，并利用标签相互关系来估计噪声过渡矩阵。</li>
<li>results: 这篇论文提出了一种新的估计器，可以在不需要 anchor point 或准确适应噪声类 posterior 的情况下估计多标签噪声过渡矩阵。这种估计器基于标签相互关系，并使用样本选择技术来提取净标签相互关系所含信息。<details>
<summary>Abstract</summary>
Noisy multi-label learning has garnered increasing attention due to the challenges posed by collecting large-scale accurate labels, making noisy labels a more practical alternative. Motivated by noisy multi-class learning, the introduction of transition matrices can help model multi-label noise and enable the development of statistically consistent algorithms for noisy multi-label learning. However, estimating multi-label noise transition matrices remains a challenging task, as most existing estimators in noisy multi-class learning rely on anchor points and accurate fitting of noisy class posteriors, which is hard to satisfy in noisy multi-label learning. In this paper, we address this problem by first investigating the identifiability of class-dependent transition matrices in noisy multi-label learning. Building upon the identifiability results, we propose a novel estimator that leverages label correlations without the need for anchor points or precise fitting of noisy class posteriors. Specifically, we first estimate the occurrence probability of two noisy labels to capture noisy label correlations. Subsequently, we employ sample selection techniques to extract information implying clean label correlations, which are then used to estimate the occurrence probability of one noisy label when a certain clean label appears. By exploiting the mismatches in label correlations implied by these occurrence probabilities, we demonstrate that the transition matrix becomes identifiable and can be acquired by solving a bilinear decomposition problem. Theoretically, we establish an estimation error bound for our multi-label transition matrix estimator and derive a generalization error bound for our statistically consistent algorithm. Empirically, we validate the effectiveness of our estimator in estimating multi-label noise transition matrices, leading to excellent classification performance.
</details>
<details>
<summary>摘要</summary>
噪声多标签学习已经吸引了越来越多的关注，因为收集大规模准确标签变得更加困难。为了模型多标签噪声，引入过渡矩阵可以帮助模型多标签噪声。然而，估计多标签噪声过渡矩阵仍然是一个挑战，因为大多数现有的估计器在噪声多类学习中使用锚点和准确地适应噪声类 posterior，这在多标签噪声学习中很难实现。在这篇论文中，我们解决这个问题，首先研究多标签噪声过渡矩阵的可识别性。基于可识别性结果，我们提出了一种新的估计器，它利用标签相互关系来估计噪声标签的过渡矩阵。具体来说，我们首先估计两个噪声标签之间的发生概率，以捕捉噪声标签之间的相互关系。然后，我们使用样本选择技术提取信息，以便从中提取净标签相关信息。最后，我们使用这些发生概率来估计一个噪声标签的过渡矩阵，并解决一个二元分解问题来获取过渡矩阵。理论上，我们建立了估计误差 bound 和一般化误差 bound，以证明我们的多标签过渡矩阵估计器的可靠性。实验证明了我们的估计器在估计多标签噪声过渡矩阵时的效果。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Conservative-Q-Learning-for-Offline-Multi-agent-Reinforcement-Learning"><a href="#Counterfactual-Conservative-Q-Learning-for-Offline-Multi-agent-Reinforcement-Learning" class="headerlink" title="Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning"></a>Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12696">http://arxiv.org/abs/2309.12696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-rllab/CFCQL">https://github.com/thu-rllab/CFCQL</a></li>
<li>paper_authors: Jianzhun Shao, Yun Qu, Chen Chen, Hongchang Zhang, Xiangyang Ji</li>
<li>for: 解决多智能机器人在离线多智能学习中的分布偏移和维度高问题，提高行动外部分布(OOD)和价值误差现象的问题。</li>
<li>methods: 提出了一种新的多智能离线Q学习算法CounterFactual Conservative Q-Learning（CFCQL），通过计算每个机器人的保守补偿来实现保守价值估计。</li>
<li>results: 在四个环境中，包括整数和浮点动作的设定，以及现有和自己制作的数据集上，CFCQL比既有方法高效，尤其是当机器人数量很大时。<details>
<summary>Abstract</summary>
Offline multi-agent reinforcement learning is challenging due to the coupling effect of both distribution shift issue common in offline setting and the high dimension issue common in multi-agent setting, making the action out-of-distribution (OOD) and value overestimation phenomenon excessively severe. Tomitigate this problem, we propose a novel multi-agent offline RL algorithm, named CounterFactual Conservative Q-Learning (CFCQL) to conduct conservative value estimation. Rather than regarding all the agents as a high dimensional single one and directly applying single agent methods to it, CFCQL calculates conservative regularization for each agent separately in a counterfactual way and then linearly combines them to realize an overall conservative value estimation. We prove that it still enjoys the underestimation property and the performance guarantee as those single agent conservative methods do, but the induced regularization and safe policy improvement bound are independent of the agent number, which is therefore theoretically superior to the direct treatment referred to above, especially when the agent number is large. We further conduct experiments on four environments including both discrete and continuous action settings on both existing and our man-made datasets, demonstrating that CFCQL outperforms existing methods on most datasets and even with a remarkable margin on some of them.
</details>
<details>
<summary>摘要</summary>
偏向多智能体异线上学习是因为偏向分布shift问题和高维度问题的交互作用，导致行为out-of-distribution (OOD)和价值误估现象过于严重。为了解决这个问题，我们提出了一种新的多智能体异线上RL算法，名为CounterFactual Conservative Q-Learning (CFCQL)，用于进行保守的价值估计。而不是将所有智能体视为一个高维度单一的智能体并直接应用单个智能体方法，CFCQL计算每个智能体的保守补偿 separately在反对方法下，然后将其线性组合以实现全局保守价值估计。我们证明了它仍然具有下预测性和性能保证，但是引入的补偿和安全策略改进 bound 独立于智能体数量，因此是理论上的超越直接处理。我们进一步在四个环境中进行了实验，包括 both 某些精度和连续动作设置，并在我们自己制作的数据集上进行了实验，示出CFCQL在大多数数据集上表现出优于现有方法，甚至在一些数据集上具有很大的差距。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Graph-Representation-of-the-Environment-through-Local-and-Cloud-Computation"><a href="#Enhancing-Graph-Representation-of-the-Environment-through-Local-and-Cloud-Computation" class="headerlink" title="Enhancing Graph Representation of the Environment through Local and Cloud Computation"></a>Enhancing Graph Representation of the Environment through Local and Cloud Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12692">http://arxiv.org/abs/2309.12692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Francesco Argenziano, Vincenzo Suriani, Daniele Nardi</li>
<li>for:  bridging the gap between low-level sensor readings and high-level semantic understanding</li>
<li>methods: combines classical computer vision tools with modern computer vision cloud services, incorporates an ontology hierarchy with over 800 object classes</li>
<li>results: allows for the handling of small objects and integration into the semantic representation of the environment<details>
<summary>Abstract</summary>
Enriching the robot representation of the operational environment is a challenging task that aims at bridging the gap between low-level sensor readings and high-level semantic understanding. Having a rich representation often requires computationally demanding architectures and pure point cloud based detection systems that struggle when dealing with everyday objects that have to be handled by the robot. To overcome these issues, we propose a graph-based representation that addresses this gap by providing a semantic representation of robot environments from multiple sources. In fact, to acquire information from the environment, the framework combines classical computer vision tools with modern computer vision cloud services, ensuring computational feasibility on onboard hardware. By incorporating an ontology hierarchy with over 800 object classes, the framework achieves cross-domain adaptability, eliminating the need for environment-specific tools. The proposed approach allows us to handle also small objects and integrate them into the semantic representation of the environment. The approach is implemented in the Robot Operating System (ROS) using the RViz visualizer for environment representation. This work is a first step towards the development of a general-purpose framework, to facilitate intuitive interaction and navigation across different domains.
</details>
<details>
<summary>摘要</summary>
Our approach combines classical computer vision tools with modern computer vision cloud services to acquire information from the environment. By incorporating an ontology hierarchy with over 800 object classes, our framework achieves cross-domain adaptability, eliminating the need for environment-specific tools. This allows us to handle small objects and integrate them into the semantic representation of the environment.We have implemented our approach in the Robot Operating System (ROS) using the RViz visualizer for environment representation. This is a first step towards the development of a general-purpose framework for intuitive interaction and navigation across different domains.
</details></li>
</ul>
<hr>
<h2 id="QAL-BP-An-Augmented-Lagrangian-Quantum-Approach-for-Bin-Packing-Problem"><a href="#QAL-BP-An-Augmented-Lagrangian-Quantum-Approach-for-Bin-Packing-Problem" class="headerlink" title="QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem"></a>QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12678">http://arxiv.org/abs/2309.12678</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lorenz92/qal-bp">https://github.com/lorenz92/qal-bp</a></li>
<li>paper_authors: Lorenzo Cellini, Antonio Macaluso, Michele Lombardi</li>
<li>for: 解决 bin packing 问题，一个 NP-hard 问题，寻找高效的解决方案。</li>
<li>methods: 使用 quantum technologies，尤其是 quantum computing，来解决这个问题。提出了一种新的 Quadratic Unconstrained Binary Optimization (QUBO) 模型，可以更好地处理这个问题。</li>
<li>results: 实验结果表明，使用 quantum annealing Device 可以更有效地解决 bin packing 问题，并且比 classical solvers 更快。<details>
<summary>Abstract</summary>
The bin packing is a well-known NP-Hard problem in the domain of artificial intelligence, posing significant challenges in finding efficient solutions. Conversely, recent advancements in quantum technologies have shown promising potential for achieving substantial computational speedup, particularly in certain problem classes, such as combinatorial optimization. In this study, we introduce QAL-BP, a novel Quadratic Unconstrained Binary Optimization (QUBO) formulation designed specifically for bin packing and suitable for quantum computation. QAL-BP utilizes the augmented Lagrangian method to incorporate the bin packing constraints into the objective function while also facilitating an analytical estimation of heuristic, but empirically robust, penalty multipliers. This approach leads to a more versatile and generalizable model that eliminates the need for empirically calculating instance-dependent Lagrangian coefficients, a requirement commonly encountered in alternative QUBO formulations for similar problems. To assess the effectiveness of our proposed approach, we conduct experiments on a set of bin-packing instances using a real Quantum Annealing device. Additionally, we compare the results with those obtained from two different classical solvers, namely simulated annealing and Gurobi. The experimental findings not only confirm the correctness of the proposed formulation but also demonstrate the potential of quantum computation in effectively solving the bin-packing problem, particularly as more reliable quantum technology becomes available.
</details>
<details>
<summary>摘要</summary>
bin packing 是人工智能领域的一个非常知名的 NP-硬Problem，它提出了很大的计算挑战。然而，最近的量子技术发展有显著的潜在能力，特别是在 combinatorial optimization 中，以获得显著的计算速度提升。在这项研究中，我们介绍了 QAL-BP，一种特有的 Quadratic Unconstrained Binary Optimization (QUBO) 形式，适用于 bin packing 问题并且适用于量子计算。QAL-BP 利用了扩展拉格朗日方法，将箱包约束直接添加到目标函数中，同时还可以 analytically 计算 heuristic，但是实际上是可靠的 penalty multipliers。这种方法使得我们的模型更加通用和可重用，消除了对实际计算 instance-dependent Lagrangian coefficients 的需求，这种需求通常在类似问题的alternative QUBO formulations中出现。为评估我们提出的方法的有效性，我们在一组 bin-packing 实例上进行了实验，使用了真实的 Quantum Annealing 设备。此外，我们还与 simulated annealing 和 Gurobi 两种类型的 classical solver进行了比较。实验结果不仅证明了我们的提出的形式的正确性，还表明了量子计算在解决箱包问题上的潜在能力，特别是随着可靠的量子技术的发展。
</details></li>
</ul>
<hr>
<h2 id="TrTr-A-Versatile-Pre-Trained-Large-Traffic-Model-based-on-Transformer-for-Capturing-Trajectory-Diversity-in-Vehicle-Population"><a href="#TrTr-A-Versatile-Pre-Trained-Large-Traffic-Model-based-on-Transformer-for-Capturing-Trajectory-Diversity-in-Vehicle-Population" class="headerlink" title="TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population"></a>TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12677">http://arxiv.org/abs/2309.12677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Feng, Zhibin Li, Bowen Liu, Yan Ding, Ou Zheng</li>
<li>For: The paper aims to learn the diversity of trajectories within vehicle populations using the Transformer architecture, which can handle large-scale parameters and capture the spatial distribution of vehicles.* Methods: The authors apply the Transformer architecture to traffic tasks and design specific pre-training tasks to improve the model’s performance. They also create a data structure tailored to the attention mechanism and introduce noises that correspond to spatio-temporal demands.* Results: The pre-trained model demonstrates excellent performance in capturing the spatial distribution of the vehicle population, with no instances of vehicle overlap and an RMSE of 0.6059 compared to ground truth values. In the context of time series prediction, approximately 95% of the predicted trajectories’ speeds closely align with the true speeds, within a deviation of 7.5144m&#x2F;s. The model also exhibits robustness in the stability test and provides a good basis for downstream fine-tuning tasks.Here’s the format you requested:* For: 学习车辆群体的路径多样性* Methods: 使用变换器架构，设计特定的预训练任务，创建适合注意机制的数据结构，引入相应的空间时间噪声* Results: 预训练模型在捕捉车辆群体的空间分布方面表现出色，无车辆重叠，RMSE为0.6059；在时间序列预测任务中，预测速度与真实速度相似，偏差为7.5144m&#x2F;s；模型在稳定性测试中表现稳定，可以长期预测时间序列，并且展现出多样化的驾驶行为。<details>
<summary>Abstract</summary>
Understanding trajectory diversity is a fundamental aspect of addressing practical traffic tasks. However, capturing the diversity of trajectories presents challenges, particularly with traditional machine learning and recurrent neural networks due to the requirement of large-scale parameters. The emerging Transformer technology, renowned for its parallel computation capabilities enabling the utilization of models with hundreds of millions of parameters, offers a promising solution. In this study, we apply the Transformer architecture to traffic tasks, aiming to learn the diversity of trajectories within vehicle populations. We analyze the Transformer's attention mechanism and its adaptability to the goals of traffic tasks, and subsequently, design specific pre-training tasks. To achieve this, we create a data structure tailored to the attention mechanism and introduce a set of noises that correspond to spatio-temporal demands, which are incorporated into the structured data during the pre-training process. The designed pre-training model demonstrates excellent performance in capturing the spatial distribution of the vehicle population, with no instances of vehicle overlap and an RMSE of 0.6059 when compared to the ground truth values. In the context of time series prediction, approximately 95% of the predicted trajectories' speeds closely align with the true speeds, within a deviation of 7.5144m/s. Furthermore, in the stability test, the model exhibits robustness by continuously predicting a time series ten times longer than the input sequence, delivering smooth trajectories and showcasing diverse driving behaviors. The pre-trained model also provides a good basis for downstream fine-tuning tasks. The number of parameters of our model is over 50 million.
</details>
<details>
<summary>摘要</summary>
理解轨迹多样性是实际交通任务的基本方面。然而，捕捉轨迹多样性带来挑战，特别是使用传统的机器学习和回归神经网络，因为它们需要庞大的参数量。然而，出现的Transformer技术，因其可平行计算能力，使得使用大量参数的模型变得可能。在这个研究中，我们将Transformer架构应用到交通任务中，以学习车辆人口中的轨迹多样性。我们分析Transformer的注意机制和它的适应性，然后设计特定的预训练任务。为此，我们创建了适应注意机制的数据结构，并引入了相应的噪声，这些噪声在预训练过程中被包含到结构化数据中。预训练模型显示出色的性能，可以准确地捕捉车辆人口的空间分布，没有车辆重叠，RMSE为0.6059，相比真实值。在时间序列预测任务中，大约95%的预测轨迹速度与真实速度高度相似，差异在7.5144米/秒之间。此外，在稳定测试中，模型表现了稳定性，连续预测了10个输入序列的时间序列，输出了平滑的轨迹和多样的驾驶行为。预训练模型还提供了下游细化任务的良好基础。我们的模型参数数量超过5000万。
</details></li>
</ul>
<hr>
<h2 id="Vision-Transformers-for-Computer-Go"><a href="#Vision-Transformers-for-Computer-Go" class="headerlink" title="Vision Transformers for Computer Go"></a>Vision Transformers for Computer Go</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12675">http://arxiv.org/abs/2309.12675</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/assasinator/Swin_Transformers">https://github.com/assasinator/Swin_Transformers</a></li>
<li>paper_authors: Amani Sagri, Tristan Cazenave, Jérôme Arjonilla, Abdallah Saffidine</li>
<li>for:  investigate the application of transformers in the game of Go, specifically in the analysis of the Transformer in Vision.</li>
<li>methods: compare transformers to usual Residual Networks.</li>
<li>results: highlight the substantial role that transformers can play in the game of Go, through a detailed analysis of numerous points such as prediction accuracy, win rates, memory, speed, size, or even learning rate.<details>
<summary>Abstract</summary>
Motivated by the success of transformers in various fields, such as language understanding and image analysis, this investigation explores their application in the context of the game of Go. In particular, our study focuses on the analysis of the Transformer in Vision. Through a detailed analysis of numerous points such as prediction accuracy, win rates, memory, speed, size, or even learning rate, we have been able to highlight the substantial role that transformers can play in the game of Go. This study was carried out by comparing them to the usual Residual Networks.
</details>
<details>
<summary>摘要</summary>
受到 transformer 在不同领域的成功启发，本研究探讨它们在围棋游戏中的应用。特别是我们在视觉领域中使用 transformer 进行分析。通过对各种指标（如预测精度、赢局率、内存、速度、大小、学习率等）的细致分析，我们得出了 transformer 在围棋游戏中的重要作用。这个研究通过与常见的 Residual Networks 进行比较，得出了这种结论。
</details></li>
</ul>
<hr>
<h2 id="On-Sparse-Modern-Hopfield-Model"><a href="#On-Sparse-Modern-Hopfield-Model" class="headerlink" title="On Sparse Modern Hopfield Model"></a>On Sparse Modern Hopfield Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12673">http://arxiv.org/abs/2309.12673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jerry Yao-Chieh Hu, Donglin Yang, Dennis Wu, Chenwei Xu, Bo-Yu Chen, Han Liu</li>
<li>For: 本文提出了一种含有稀畴结构的现代戴维尔模型（Sparse Modern Hopfield Model），作为现代戴维尔模型的稀畴扩展。* Methods: 本文使用了稀畴注意机制，并提出了一种关于稀畴能函数的关闭式表示，以及基于此的稀畴记忆抽取动力学。* Results: 本文提出了一种基于稀畴结构的记忆抽取动力学，并证明其一步采样等价于稀畴结构的注意机制。此外，本文还提供了稀畴取决因子的记忆抽取误差 bound，并证明其比密集模型更紧。<details>
<summary>Abstract</summary>
We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. Theoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer. Building upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention. Importantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog. The conditions for the benefits of sparsity to arise are therefore identified and discussed. In addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point convergence and exponential memory capacity. Empirically, we use both synthetic and real-world datasets to demonstrate that the sparse Hopfield model outperforms its dense counterpart in many situations.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个对� tenir 的现代丰码模型，这是一个对于现代丰码模型的延伸。这个模型具有一个备受归属的记忆回传动态，它的一步近似对应于简短的注意力机制。理论上，我们的主要贡献是通过对简短Entropic regularizer的对偶函数而 derive 一个关闭的简短丰码能量函数。建基于这个能量函数，我们 derive 简短的记忆回传动态，并证明它的一步近似与简短结构的注意力相等。更重要的是，我们提供了一个对简短性的记忆回传错误 bound，这是与对简短性的预设相比较为紧的。因此，我们可以识别出简短性在哪些情况下获得好的情况，并讨论这些情况。此外，我们显示了对简短性的丰码模型保持了现代丰码模型的理论性质，包括快速的稳定点收敛和exponential的记忆容量。实验上，我们使用了 synthetic 和实际世界数据来显示，简短丰码模型在许多情况下比对简短性的丰码模型表现更好。
</details></li>
</ul>
<hr>
<h2 id="How-to-Fine-tune-the-Model-Unified-Model-Shift-and-Model-Bias-Policy-Optimization"><a href="#How-to-Fine-tune-the-Model-Unified-Model-Shift-and-Model-Bias-Policy-Optimization" class="headerlink" title="How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization"></a>How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12671">http://arxiv.org/abs/2309.12671</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/betray12138/unified-model-shift-and-model-bias-policy-optimization">https://github.com/betray12138/unified-model-shift-and-model-bias-policy-optimization</a></li>
<li>paper_authors: Hai Zhang, Hang Yu, Junqiao Zhao, Di Zhang, Chang Huang, Hongtu Zhou, Xiao Zhang, Chen Ye</li>
<li>for: 这篇论文主要目标是提出一种能够满足性能保证的模型基于强化学习（MBRL）算法设计方法。</li>
<li>methods: 该方法使用返回差值来导引模型学习，并通过自适应调整模型更新来保证性能提升。</li>
<li>results: 实验结果表明，该算法在多个复杂任务上达到了状态之最的性能。<details>
<summary>Abstract</summary>
Designing and deriving effective model-based reinforcement learning (MBRL) algorithms with a performance improvement guarantee is challenging, mainly attributed to the high coupling between model learning and policy optimization. Many prior methods that rely on return discrepancy to guide model learning ignore the impacts of model shift, which can lead to performance deterioration due to excessive model updates. Other methods use performance difference bound to explicitly consider model shift. However, these methods rely on a fixed threshold to constrain model shift, resulting in a heavy dependence on the threshold and a lack of adaptability during the training process. In this paper, we theoretically derive an optimization objective that can unify model shift and model bias and then formulate a fine-tuning process. This process adaptively adjusts the model updates to get a performance improvement guarantee while avoiding model overfitting. Based on these, we develop a straightforward algorithm USB-PO (Unified model Shift and model Bias Policy Optimization). Empirical results show that USB-PO achieves state-of-the-art performance on several challenging benchmark tasks.
</details>
<details>
<summary>摘要</summary>
“设计和推导具有性能改善保证的模型基于学习（MBRL）算法是具有挑战，主要是因为模型学习和政策优化之间存在高度的整合。许多先前的方法将返回差异用来引导模型学习，忽略模型转移的影响，可能导致因为过度更新模型而导致性能下降。其他方法使用性能差异 bound来考虑模型转移，但这些方法靠摄设定的阈值来限制模型转移，导致执行过程中的依赖性和缺乏灵活性。在这篇文章中，我们理论上 derive 一个优化目标，可以将模型转移和模型偏差统一，然后构成一个精致调整过程。这个过程可以适应性地调整模型更新，以确保性能改善保证，同时避免模型过滤。基于这些，我们开发了一个简单的算法 USB-PO（对于模型转移和模型偏差的政策优化）。实验结果显示，USB-PO 在一些具有挑战性的 bencark task 上实现了顶尖性能。”
</details></li>
</ul>
<hr>
<h2 id="Natural-revision-is-contingently-conditionalized-revision"><a href="#Natural-revision-is-contingently-conditionalized-revision" class="headerlink" title="Natural revision is contingently-conditionalized revision"></a>Natural revision is contingently-conditionalized revision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12655">http://arxiv.org/abs/2309.12655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paolo Liberatore</li>
<li>for: 本研究旨在探讨自然修订的扩展，以满足更复杂的条件。</li>
<li>methods: 本研究使用了自然修订的基本原则，包括最小变化、等同和纯洁。</li>
<li>results: 研究发现，自然修订的扩展可以帮助解决一些Counterexample，但也存在一些限制。<details>
<summary>Abstract</summary>
Natural revision seems so natural: it changes beliefs as little as possible to incorporate new information. Yet, some counterexamples show it wrong. It is so conservative that it never fully believes. It only believes in the current conditions. This is right in some cases and wrong in others. Which is which? The answer requires extending natural revision from simple formulae expressing universal truths (something holds) to conditionals expressing conditional truth (something holds in certain conditions). The extension is based on the basic principles natural revision follows, identified as minimal change, indifference and naivety: change beliefs as little as possible; equate the likeliness of scenarios by default; believe all until contradicted. The extension says that natural revision restricts changes to the current conditions. A comparison with an unrestricting revision shows what exactly the current conditions are. It is not what currently considered true if it contradicts the new information. It includes something more and more unlikely until the new information is at least possible.
</details>
<details>
<summary>摘要</summary>
自然修订似乎很自然：它最小化信念更改，以接纳新信息。然而，一些例外证明它错误。它太保守，从未全heartedly 信任。它只信任当前情况。这对于一些情况是正确的，对于另外一些情况是错误的。哪些是哪些？答案需要扩展自然修订从简单的公式表达universal truth（something holds）扩展到 conditionals表达条件真理（something holds in certain conditions）。这种扩展基于自然修订的基本原则：变化信念最少化，默许enario  equality 和简单信任（change beliefs as little as possible; equate the likeliness of scenarios by default; believe all until contradicted）。这种扩展说明自然修订限制更改到当前情况。与不限制的修订进行比较显示了现在所考虑的真实情况是什么。不是现在被认为是真的，如果它与新信息相 contradicted。而是更加不可能的事情，直到新信息至少可能。
</details></li>
</ul>
<hr>
<h2 id="Are-Deep-Learning-Classification-Results-Obtained-on-CT-Scans-Fair-and-Interpretable"><a href="#Are-Deep-Learning-Classification-Results-Obtained-on-CT-Scans-Fair-and-Interpretable" class="headerlink" title="Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?"></a>Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12632">http://arxiv.org/abs/2309.12632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamad M. A. Ashames, Ahmet Demir, Omer N. Gerek, Mehmet Fidan, M. Bilginer Gulmezoglu, Semih Ergin, Mehmet Koc, Atalay Barkana, Cuneyt Calisir</li>
<li>for: 这篇研究的目的是提高医学影像识别的可解释性和准确性。</li>
<li>methods: 这篇研究使用了深度学习方法，并将患者级别分类 strict 地隔离在训练、验证和测试数据集中。</li>
<li>results: 研究发现，使用传统的不平等排序方法训练深度学习模型可能会报告误导性的准确率，并且学习无关的特征。但是，使用严格的患者级别分类方法训练深度学习模型可以保持其准确率，并且在新患者影像上进行测试时仍然表现出高度的可解释性。<details>
<summary>Abstract</summary>
Following the great success of various deep learning methods in image and object classification, the biomedical image processing society is also overwhelmed with their applications to various automatic diagnosis cases. Unfortunately, most of the deep learning-based classification attempts in the literature solely focus on the aim of extreme accuracy scores, without considering interpretability, or patient-wise separation of training and test data. For example, most lung nodule classification papers using deep learning randomly shuffle data and split it into training, validation, and test sets, causing certain images from the CT scan of a person to be in the training set, while other images of the exact same person to be in the validation or testing image sets. This can result in reporting misleading accuracy rates and the learning of irrelevant features, ultimately reducing the real-life usability of these models. When the deep neural networks trained on the traditional, unfair data shuffling method are challenged with new patient images, it is observed that the trained models perform poorly. In contrast, deep neural networks trained with strict patient-level separation maintain their accuracy rates even when new patient images are tested. Heat-map visualizations of the activations of the deep neural networks trained with strict patient-level separation indicate a higher degree of focus on the relevant nodules. We argue that the research question posed in the title has a positive answer only if the deep neural networks are trained with images of patients that are strictly isolated from the validation and testing patient sets.
</details>
<details>
<summary>摘要</summary>
Traditional deep learning methods for image and object classification have achieved great success, and the biomedical image processing community has also applied these methods to various automatic diagnosis cases. However, most deep learning-based classification attempts in the literature focus solely on achieving high accuracy scores without considering interpretability or patient-wise separation of training and test data. For example, most lung nodule classification papers using deep learning randomly shuffle data and split it into training, validation, and test sets, causing certain images from the same person's CT scan to be in the training set, while other images of the exact same person are in the validation or testing image sets. This can lead to misleading accuracy rates and the learning of irrelevant features, ultimately reducing the real-life usability of these models. When the deep neural networks trained on the traditional, unfair data shuffling method are challenged with new patient images, they perform poorly. In contrast, deep neural networks trained with strict patient-level separation maintain their accuracy rates even when new patient images are tested. Heat-map visualizations of the activations of the deep neural networks trained with strict patient-level separation indicate a higher degree of focus on the relevant nodules. We argue that the research question posed in the title has a positive answer only if the deep neural networks are trained with images of patients that are strictly isolated from the validation and testing patient sets.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Quantum-Computing-based-System-for-Portfolio-Optimization-using-Future-Asset-Values-and-Automatic-Reduction-of-the-Investment-Universe"><a href="#A-Quantum-Computing-based-System-for-Portfolio-Optimization-using-Future-Asset-Values-and-Automatic-Reduction-of-the-Investment-Universe" class="headerlink" title="A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe"></a>A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12627">http://arxiv.org/abs/2309.12627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eneko Osaba, Guillaume Gelabert, Esther Villar-Rodriguez, Antón Asla, Izaskun Oregi</li>
<li>for: 这个研究是为了解决股票 portefolio优化问题，并使用量子计算技术来解决。</li>
<li>methods: 这个系统使用了未来资产预测值来模型，而不是历史值；此外，它还包括自动宇宙减少模块，以降低问题的复杂性。</li>
<li>results: 作者们提出了一个概述性的讨论，描述了不同模块的先进性表现。<details>
<summary>Abstract</summary>
One of the problems in quantitative finance that has received the most attention is the portfolio optimization problem. Regarding its solving, this problem has been approached using different techniques, with those related to quantum computing being especially prolific in recent years. In this study, we present a system called Quantum Computing-based System for Portfolio Optimization with Future Asset Values and Automatic Universe Reduction (Q4FuturePOP), which deals with the Portfolio Optimization Problem considering the following innovations: i) the developed tool is modeled for working with future prediction of assets, instead of historical values; and ii) Q4FuturePOP includes an automatic universe reduction module, which is conceived to intelligently reduce the complexity of the problem. We also introduce a brief discussion about the preliminary performance of the different modules that compose the prototypical version of Q4FuturePOP.
</details>
<details>
<summary>摘要</summary>
一个在量化金融中受到最多关注的问题是资产配置优化问题（Portfolio Optimization Problem）。它的解决方法有很多，其中使用量子计算技术的方法在过去几年中特别繁荣。在这篇研究中，我们介绍了一个名为量子计算基于系统 для资产配置优化与未来资产价值预测（Q4FuturePOP）的系统，它解决了资产配置优化问题，并包括以下两点创新：首先，该工具采用未来预测资产价值，而不是历史数据；其次，Q4FuturePOP包括自动宇宙减少模块，以智能减少问题的复杂性。我们还介绍了批处理版Q4FuturePOP的不同模块的初步性能。
</details></li>
</ul>
<hr>
<h2 id="Construction-contract-risk-identification-based-on-knowledge-augmented-language-model"><a href="#Construction-contract-risk-identification-based-on-knowledge-augmented-language-model" class="headerlink" title="Construction contract risk identification based on knowledge-augmented language model"></a>Construction contract risk identification based on knowledge-augmented language model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12626">http://arxiv.org/abs/2309.12626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saika Wong, Chunmo Zheng, Xing Su, Yinqiu Tang</li>
<li>for: 本研究旨在提高建筑项目合同审核效果，以避免潜在的损失。</li>
<li>methods: 本研究使用大型自然语言处理模型（LLM），并通过适应 contruction 合同知识来增强语言模型的风险识别能力。</li>
<li>results: 我们对实际的建筑合同进行了评估，并实现了良好的性能。此外，我们还研究了LLM如何在这种任务中运用逻辑思维，并提供了未来研究的建议。<details>
<summary>Abstract</summary>
Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of a natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how large language models employ logical thinking during the task and provide insights and recommendations for future research.
</details>
<details>
<summary>摘要</summary>
CONTRACT REVIEW IS AN ESSENTIAL STEP IN CONSTRUCTION PROJECTS TO PREVENT POTENTIAL LOSSES. HOWEVER, THE CURRENT METHODS FOR REVIEWING CONSTRUCTION CONTRACTS LACK EFFECTIVENESS AND RELIABILITY, LEADING TO TIME-CONSUMING AND ERROR-PRONE PROCESSES. WHILE LARGE LANGUAGE MODELS (LLMs) HAVE SHOWN PROMISE IN REVOLUTIONIZING NATURAL LANGUAGE PROCESSING (NLP) TASKS, THEY STRUGGLE WITH DOMAIN-SPECIFIC KNOWLEDGE AND ADDRESSING SPECIALIZED ISSUES. THIS PAPER PRESENTS A NOVEL APPROACH THAT LEVERAGES LLMs WITH CONSTRUCTION CONTRACT KNOWLEDGE TO EMULATE THE PROCESS OF CONTRACT REVIEW BY HUMAN EXPERTS. OUR TUNING-FREE APPROACH INCORPORATES CONSTRUCTION CONTRACT DOMAIN KNOWLEDGE TO ENHANCE LANGUAGE MODELS FOR IDENTIFYING CONSTRUCTION CONTRACT RISKS. THE USE OF A NATURAL LANGUAGE WHEN BUILDING THE DOMAIN KNOWLEDGE BASE FACILITATES PRACTICAL IMPLEMENTATION. WE EVALUATED OUR METHOD ON REAL CONSTRUCTION CONTRACTS AND ACHIEVED SOLID PERFORMANCE. ADDITIONALLY, WE INVESTIGATED HOW LARGE LANGUAGE MODELS EMPLOY LOGICAL THINKING DURING THE TASK AND PROVIDE INSIGHTS AND RECOMMENDATIONS FOR FUTURE RESEARCH.
</details></li>
</ul>
<hr>
<h2 id="DRG-LLaMA-Tuning-LLaMA-Model-to-Predict-Diagnosis-related-Group-for-Hospitalized-Patients"><a href="#DRG-LLaMA-Tuning-LLaMA-Model-to-Predict-Diagnosis-related-Group-for-Hospitalized-Patients" class="headerlink" title="DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients"></a>DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12625">http://arxiv.org/abs/2309.12625</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanyin88/drg-llama">https://github.com/hanyin88/drg-llama</a></li>
<li>paper_authors: Hanyin Wang, Chufan Gao, Christopher Dantona, Bryan Hull, Jimeng Sun</li>
<li>For: This paper aims to improve the efficiency of the Diagnosis-Related Group (DRG) assignment process in the U.S. inpatient payment system by using an advanced large language model (LLM) fine-tuned on clinical notes.* Methods: The paper introduces DRG-LLaMA, a LLM fine-tuned on 236,192 MIMIC-IV discharge summaries using Low-Rank Adaptation (LoRA) to enhance DRG assignment. The model uses a maximum input token length of 512 and achieves a noteworthy macro-averaged F1 score of 0.327, a top-1 prediction accuracy of 52.0%, and a macro-averaged AUC of 0.986.* Results: The DRG-LLaMA model surpassed the performance of prior leading models in DRG prediction, showing a relative improvement of 40.3% and 35.7% in macro-averaged F1 score compared to ClinicalBERT and CAML, respectively. The model also achieved a top-1 prediction accuracy of 67.8% and 67.5% for base DRG and CC&#x2F;MCC prediction, respectively.<details>
<summary>Abstract</summary>
In the U.S. inpatient payment system, the Diagnosis-Related Group (DRG) is pivotal, but its assignment process is inefficient. The study introduces DRG-LLaMA, an advanced large language model (LLM) fine-tuned on clinical notes to enhance DRGs assignment. Utilizing LLaMA as the foundational model and optimizing it through Low-Rank Adaptation (LoRA) on 236,192 MIMIC-IV discharge summaries, our DRG-LLaMA-7B model exhibited a noteworthy macro-averaged F1 score of 0.327, a top-1 prediction accuracy of 52.0%, and a macro-averaged Area Under the Curve (AUC) of 0.986, with a maximum input token length of 512. This model surpassed the performance of prior leading models in DRG prediction, showing a relative improvement of 40.3% and 35.7% in macro-averaged F1 score compared to ClinicalBERT and CAML, respectively. Applied to base DRG and complication or comorbidity (CC)/major complication or comorbidity (MCC) prediction, DRG-LLaMA achieved a top-1 prediction accuracy of 67.8% and 67.5%, respectively. Additionally, our findings indicate that DRG-LLaMA's performance correlates with increased model parameters and input context lengths.
</details>
<details>
<summary>摘要</summary>
在美国医疗机构中，诊断相关组（DRG）是关键，但其分配过程不具有效率。这项研究介绍DRG-LLaMA，一种基于临床笔记的大型自然语言模型（LLM）进行DRG分配的提高。通过将LLaMA作为基础模型，并通过对236,192份MIMIC-IV病卷摘要进行低级适应（LoRA）优化，我们的DRG-LLaMA-7B模型在macro-averaged F1分数上表现出了很好的成绩，即0.327，Top-1预测精度为52.0%，和macro-averaged AUC为0.986，最大输入符号长度为512。这个模型在DRG预测中超越了先前的主导模型，显示了相对提升40.3%和35.7%的macro-averaged F1分数相比于ClinicalBERT和CAML，分别。应用于基本DRG和complication或comorbidity（CC）/主要complication或comorbidity（MCC）预测中，DRG-LLaMA达到了Top-1预测精度为67.8%和67.5%，分别。此外，我们的发现表明DRG-LLaMA的性能与模型参数和输入上下文长度相关。
</details></li>
</ul>
<hr>
<h2 id="From-Text-to-Trends-A-Unique-Garden-Analytics-Perspective-on-the-Future-of-Modern-Agriculture"><a href="#From-Text-to-Trends-A-Unique-Garden-Analytics-Perspective-on-the-Future-of-Modern-Agriculture" class="headerlink" title="From Text to Trends: A Unique Garden Analytics Perspective on the Future of Modern Agriculture"></a>From Text to Trends: A Unique Garden Analytics Perspective on the Future of Modern Agriculture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12579">http://arxiv.org/abs/2309.12579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parag Saxena</li>
<li>for: 这个研究报告旨在提高现代农业中的数据驱动智能，即通过机器学习框架来改善农业教育和沟通。</li>
<li>methods: 该研究使用了机器学习模型和自然语言处理（NLP）技术，将问题分类并预测未来的趋势。</li>
<li>results: 研究结果表明，机器学习可以预测园艺趋势，并且可以预测未来园艺问题的主题和趋势。这些结果表明，大规模农业产业可以通过积累和维护文本数据来预测趋势和实施战略农业规划。<details>
<summary>Abstract</summary>
Data-driven insights are essential for modern agriculture. This research paper introduces a machine learning framework designed to improve how we educate and reach out to people in the field of horticulture. The framework relies on data from the Horticulture Online Help Desk (HOHD), which is like a big collection of questions from people who love gardening and are part of the Extension Master Gardener Program (EMGP). This framework has two main parts. First, it uses special computer programs (machine learning models) to sort questions into categories. This helps us quickly send each question to the right expert, so we can answer it faster. Second, it looks at when questions are asked and uses that information to guess how many questions we might get in the future and what they will be about. This helps us plan on topics that will be really important. It's like knowing what questions will be popular in the coming months. We also take into account where the questions come from by looking at the Zip Code. This helps us make research that fits the challenges faced by gardeners in different places. In this paper, we demonstrate the potential of machine learning techniques to predict trends in horticulture by analyzing textual queries from homeowners. We show that NLP, classification, and time series analysis can be used to identify patterns in homeowners' queries and predict future trends in horticulture. Our results suggest that machine learning could be used to predict trends in other agricultural sectors as well. If large-scale agriculture industries curate and maintain a comparable repository of textual data, the potential for trend prediction and strategic agricultural planning could be revolutionized. This convergence of technology and agriculture offers a promising pathway for the future of sustainable farming and data-informed agricultural practices
</details>
<details>
<summary>摘要</summary>
“数据驱动的洞察力是现代农业的关键。这项研究发表在园艺领域的机器学习框架，旨在提高我们向园艺领域人员的教育和沟通方式。该框架包括两个主要部分。首先，它使用特殊的计算机程序（机器学习模型）将问题分类。这有助于我们快速将每个问题传递给相应的专家，以便更快地回答。其次，它考虑问题的提交时间，并使用这些信息预测将来的问题数量和主题。这有助于我们在未来准备相关的研究和规划。我们还考虑问题来源的ZipCode，以便制定地域化的研究。我们的研究表明，机器学习技术可以通过分析家庭主持人的文本查询来预测园艺领域的趋势。我们的结果表明，机器学习可以预测其他农业领域的趋势。如果大规模农业产业积累和维护类似的文本数据库，那么机器学习的潜力可以为未来的可持续农业和数据驱动农业实践带来革命性的改变。这种技术和农业的融合将为未来的可持续农业和数据驱动农业实践提供了一条优秀的道路。”
</details></li>
</ul>
<hr>
<h2 id="Understanding-Patterns-of-Deep-Learning-ModelEvolution-in-Network-Architecture-Search"><a href="#Understanding-Patterns-of-Deep-Learning-ModelEvolution-in-Network-Architecture-Search" class="headerlink" title="Understanding Patterns of Deep Learning ModelEvolution in Network Architecture Search"></a>Understanding Patterns of Deep Learning ModelEvolution in Network Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12576">http://arxiv.org/abs/2309.12576</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Underwood, Meghana Madhastha, Randal Burns, Bogdan Nicolae</li>
<li>for: 这个论文主要探讨了深度学习模型的结构优化方法，具体来说是用于研究模型在时间推移中的Empirical Evolution Patterns，以便为缓存策略、优化搜索算法和其他应用场景设计。</li>
<li>methods: 这个论文使用了Regularized Evolution algorithm来研究模型的进化趋势，并对Candle项目和Nasbench-201搜索空间中的模型进行了算法性分析和量化Characterization。</li>
<li>results: 研究发现，Regularized Evolution algorithm会影响模型结构的进化趋势，而且在分布式环境中，模型的进化 Patterns可以被利用来优化缓存和调度策略。此外，研究还发现了一些影响模型结构的升降温度的 Condition。<details>
<summary>Abstract</summary>
Network Architecture Search and specifically Regularized Evolution is a common way to refine the structure of a deep learning model.However, little is known about how models empirically evolve over time which has design implications for designing caching policies, refining the search algorithm for particular applications, and other important use cases.In this work, we algorithmically analyze and quantitatively characterize the patterns of model evolution for a set of models from the Candle project and the Nasbench-201 search space.We show how the evolution of the model structure is influenced by the regularized evolution algorithm. We describe how evolutionary patterns appear in distributed settings and opportunities for caching and improved scheduling. Lastly, we describe the conditions that affect when particular model architectures rise and fall in popularity based on their frequency of acting as a donor in a sliding window.
</details>
<details>
<summary>摘要</summary>
网络建构搜索和特别是减少演化是深度学习模型结构的常见方法。然而，有很 little is known about如何模型实际在时间演化，这有关缓存策略、改进搜索算法、特定应用场景等重要用例的设计假设。在这项工作中，我们使用算法分析和量化描述了一组 Candle 项目和 Nasbench-201 搜索空间中模型的演化趋势。我们表明了减少演化算法如何影响模型结构的演化。我们还描述了分布式设置中的演化趋势以及缓存和调度的机会。最后，我们描述了模型结构的崛起和衰落的条件，基于它们在滚动窗口中的频率被用作donor。
</details></li>
</ul>
<hr>
<h2 id="Creativity-Support-in-the-Age-of-Large-Language-Models-An-Empirical-Study-Involving-Emerging-Writers"><a href="#Creativity-Support-in-the-Age-of-Large-Language-Models-An-Empirical-Study-Involving-Emerging-Writers" class="headerlink" title="Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers"></a>Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12570">http://arxiv.org/abs/2309.12570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuhin Chakrabarty, Vishakh Padmakumar, Faeze Brahman, Smaranda Muresan</li>
<li>for: 这个论文旨在探讨现代大型自然语言模型（LLM）在职业写作支持工具中的可用性。</li>
<li>methods: 这个研究采用了实证研究方法（n&#x3D;30），检查了现代LLM在助手写作过程中的可用性。</li>
<li>results: 研究发现，写作者在不同的认知活动中寻求LLM的帮助，尤其是在翻译和审阅阶段。<details>
<summary>Abstract</summary>
The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research directions in creative writing assistance using LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的发展，能够跟随 instrux 和进行对话交互，对各种支持工具的应用产生了增加的兴趣。我们通过实验用户研究（n=30）进行了 LLM 在职业作家助手方面的可用性检查。我们的协作写作界面设计基于写作认知过程模型，视写作为一个目标导向的思考过程，包括观察、翻译和审核等非线性认知活动。参与者被要求提供完成后的调查，以提供 LLM 作为写作伙伴的潜在和障碍。我们分析了写作者与 LLM 之间的互动，发现写作者对 LLM 的帮助最多是在翻译和审核阶段。我们从分析互动和调查回应中获得了未来创作写作助手领域的研究方向。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-Learning-Social-Robot-Navigation-with-Multimodal-Perception"><a href="#A-Study-on-Learning-Social-Robot-Navigation-with-Multimodal-Perception" class="headerlink" title="A Study on Learning Social Robot Navigation with Multimodal Perception"></a>A Study on Learning Social Robot Navigation with Multimodal Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12568">http://arxiv.org/abs/2309.12568</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/robotixx/multimodal-fusion-network">https://github.com/robotixx/multimodal-fusion-network</a></li>
<li>paper_authors: Bhabaranjan Panigrahi, Amir Hossain Raj, Mohammad Nazeri, Xuesu Xiao</li>
<li>for: 本研究旨在开发一种能够在人类 inhabited 的公共空间中自主移动的 robot，并能够根据围绕着它的人类行为和意图进行相应的导航决策。</li>
<li>methods: 本研究使用机器学习方法来捕捉人类社交互动的复杂和微妙性，从数据驱动的角度来capture这些互动。研究者使用多个可用的感知模式，包括 LiDAR 和 RGB 摄像头，并对不同的社交情境进行了比较。</li>
<li>results: 研究结果显示，使用多模态感知可以在社交导航决策中获得明显的优势，并且在人类研究中也被证明。研究者还分析了学习过程中的训练和普适性性能。开源代码可供社区未来研究多模态感知导航。<details>
<summary>Abstract</summary>
Autonomous mobile robots need to perceive the environments with their onboard sensors (e.g., LiDARs and RGB cameras) and then make appropriate navigation decisions. In order to navigate human-inhabited public spaces, such a navigation task becomes more than only obstacle avoidance, but also requires considering surrounding humans and their intentions to somewhat change the navigation behavior in response to the underlying social norms, i.e., being socially compliant. Machine learning methods are shown to be effective in capturing those complex and subtle social interactions in a data-driven manner, without explicitly hand-crafting simplified models or cost functions. Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and local planning levels and contrasts unimodal and multimodal learning against a set of classical navigation approaches in different social scenarios, while also analyzing the training and generalizability performance from the learning perspective. We also conduct a human study on how learning with multimodal perception affects the perceived social compliance. The results show that multimodal learning has a clear advantage over unimodal learning in both dataset and human studies. We open-source our code for the community's future use to study multimodal perception for learning social robot navigation.
</details>
<details>
<summary>摘要</summary>
自适应移动 робоッツ需要通过其 бордов的感知器 (例如 LiDAR 和 RGB 摄像头) 识别环境，然后采取相应的导航决策。在人类居住的公共空间中导航，这种导航任务不仅仅是避免障碍物，还需要考虑周围的人和他们的意图，并根据下面社会规范进行相应的导航行为变化。机器学习方法可以有效地捕捉这些复杂和柔和的社会互动，无需显式地手工设计简化模型或成本函数。 Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and local planning levels and contrasts unimodal and multimodal learning against a set of classical navigation approaches in different social scenarios, while also analyzing the training and generalizability performance from the learning perspective. We also conduct a human study on how learning with multimodal perception affects the perceived social compliance. The results show that multimodal learning has a clear advantage over unimodal learning in both dataset and human studies. We open-source our code for the community's future use to study multimodal perception for learning social robot navigation.
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Meets-Advanced-Robotic-Manipulation"><a href="#Machine-Learning-Meets-Advanced-Robotic-Manipulation" class="headerlink" title="Machine Learning Meets Advanced Robotic Manipulation"></a>Machine Learning Meets Advanced Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12560">http://arxiv.org/abs/2309.12560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeid Nahavandi, Roohallah Alizadehsani, Darius Nahavandi, Chee Peng Lim, Kevin Kelly, Fernando Bello</li>
<li>for: 提高自动化生产质量、降低生产成本和更好地利用人员资源</li>
<li>methods: 机器学习方法</li>
<li>results: 提高安全性、可靠性和效率Here is a more detailed explanation of each point:</li>
<li>for: The paper is written to discuss the application of machine learning methods in automation and robotics, specifically in the context of manipulation tasks. The goal is to improve the quality, efficiency, and safety of automation systems.</li>
<li>methods: The paper reviews cutting-edge technologies and recent trends in machine learning methods applied to real-world manipulation tasks. It covers a wide range of applications in different domains, including industry, healthcare, agriculture, space, military, and search and rescue.</li>
<li>results: The paper highlights the potential of machine learning methods to improve the safety, reliability, and efficiency of automation systems. It provides an overview of the current state of the field and identifies important research directions for future works.<details>
<summary>Abstract</summary>
Automated industries lead to high quality production, lower manufacturing cost and better utilization of human resources. Robotic manipulator arms have major role in the automation process. However, for complex manipulation tasks, hard coding efficient and safe trajectories is challenging and time consuming. Machine learning methods have the potential to learn such controllers based on expert demonstrations. Despite promising advances, better approaches must be developed to improve safety, reliability, and efficiency of ML methods in both training and deployment phases. This survey aims to review cutting edge technologies and recent trends on ML methods applied to real-world manipulation tasks. After reviewing the related background on ML, the rest of the paper is devoted to ML applications in different domains such as industry, healthcare, agriculture, space, military, and search and rescue. The paper is closed with important research directions for future works.
</details>
<details>
<summary>摘要</summary>
自动化业务会导致高质量生产、低成本生产和更好的人员资源利用。 robotic manipulator arms 在自动化过程中扮演着重要的角色。然而，对于复杂的抓拍任务，使用硬编程方法设计有效和安全的轨迹是挑战和时间consuming。机器学习方法有 potential 可以学习出专家示范的控制器。 despite promising advances, 以下是未来研究的重要方向：1. 提高安全性、可靠性和效率的机器学习方法，包括在训练和部署阶段。2. 应用机器学习方法到不同领域，如工业、医疗、农业、航天、军事和搜救等。3. 开发出可靠的机器学习模型，以满足实际应用需求。本文首先介绍了机器学习的相关背景，然后分别介绍了机器学习在不同领域的应用，包括工业、医疗、农业、航天、军事和搜救等。 finally, 本文结束于未来研究的重要方向。
</details></li>
</ul>
<hr>
<h2 id="Invariant-Learning-via-Probability-of-Sufficient-and-Necessary-Causes"><a href="#Invariant-Learning-via-Probability-of-Sufficient-and-Necessary-Causes" class="headerlink" title="Invariant Learning via Probability of Sufficient and Necessary Causes"></a>Invariant Learning via Probability of Sufficient and Necessary Causes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12559">http://arxiv.org/abs/2309.12559</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ymy4323460/casn">https://github.com/ymy4323460/casn</a></li>
<li>paper_authors: Mengyue Yang, Zhen Fang, Yonggang Zhang, Yali Du, Furui Liu, Jean-Francois Ton, Jun Wang</li>
<li>for: 提高模型在未知训练分布下的泛化能力（OOD generalization）</li>
<li>methods: 利用 causality 的方法，具体是计算可能性极值（PNS），来捕捉可能性的必要和充分条件，并利用 PNS 风险来学习表示</li>
<li>results: 对synthetic和实际数据进行了实验，证明提出的方法有效，并进行了理论分析和证明，证明方法的泛化性。更多细节可以查看 GitHub 仓库：<a target="_blank" rel="noopener" href="https://github.com/ymy4323460/CaSN%E3%80%82">https://github.com/ymy4323460/CaSN。</a><details>
<summary>Abstract</summary>
Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of \textit{sufficiency} and \textit{necessity} conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. The details of the implementation can be found at the GitHub repository: https://github.com/ymy4323460/CaSN.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION（OOD）通用性是学习模型的必要条件，因为测试分布通常不同于训练分布。 recent methods based on causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of \textit{sufficiency} and \textit{necessity} conditions. Specifically, a necessary but insufficient cause (feature) is invariant to distribution shift, but it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose PNS risk and formulate an algorithm to learn representation with a high PNS value. We theoretically analyze and prove the generalizability of the PNS risk. Experiments on both synthetic and real-world benchmarks demonstrate the effectiveness of the proposed method. For more details, please refer to the GitHub repository: <https://github.com/ymy4323460/CaSN>.
</details></li>
</ul>
<hr>
<h2 id="PlanFitting-Tailoring-Personalized-Exercise-Plans-with-Large-Language-Models"><a href="#PlanFitting-Tailoring-Personalized-Exercise-Plans-with-Large-Language-Models" class="headerlink" title="PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models"></a>PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12555">http://arxiv.org/abs/2309.12555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghoon Shin, Gary Hsieh, Young-Ho Kim</li>
<li>for: 本研究旨在帮助用户创建个性化的锻炼计划，以满足用户的具体需求和基本原则。</li>
<li>methods: 本研究使用了大语言模型的生成能力，让用户通过自然语言描述约束和查询，以生成和优化用户每周的锻炼计划。</li>
<li>results: 经过用户研究（N&#x3D;18）和专家评估（N&#x3D;3），研究发现PlanFitting可以生成个性化、可行、基于证据的锻炼计划。未来，研究人员可以通过AI助手创建计划，更好地遵循锻炼原则，并更好地适应用户的个性约束。<details>
<summary>Abstract</summary>
A personally tailored exercise regimen is crucial to ensuring sufficient physical activities, yet challenging to create as people have complex schedules and considerations and the creation of plans often requires iterations with experts. We present PlanFitting, a conversational AI that assists in personalized exercise planning. Leveraging generative capabilities of large language models, PlanFitting enables users to describe various constraints and queries in natural language, thereby facilitating the creation and refinement of their weekly exercise plan to suit their specific circumstances while staying grounded in foundational principles. Through a user study where participants (N=18) generated a personalized exercise plan using PlanFitting and expert planners (N=3) evaluated these plans, we identified the potential of PlanFitting in generating personalized, actionable, and evidence-based exercise plans. We discuss future design opportunities for AI assistants in creating plans that better comply with exercise principles and accommodate personal constraints.
</details>
<details>
<summary>摘要</summary>
一个专门设计的运动计划是不可或缺的，以确保人们有足够的身体活动，但创建计划可以是具有复杂的时间表和考虑的挑战。我们介绍PlanFitting，一个以语言模型为基础的对话式人工智能，可以帮助用户创建个性化的运动计划。通过让用户使用自然语言描述各种限制和查询，PlanFitting可以帮助用户创建和调整每周的运动计划，以满足他们的具体情况，同时尊重基本的运动原则。经过一次用户研究（N=18）和专家规划师（N=3）评估这些计划，我们发现PlanFitting具有创建个性化、可行、基于证据的运动计划的潜力。我们讨论未来的设计机会，以更好地让人工智能助手遵循运动原则，并考虑个人的限制。
</details></li>
</ul>
<hr>
<h2 id="Provably-Robust-and-Plausible-Counterfactual-Explanations-for-Neural-Networks-via-Robust-Optimisation"><a href="#Provably-Robust-and-Plausible-Counterfactual-Explanations-for-Neural-Networks-via-Robust-Optimisation" class="headerlink" title="Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation"></a>Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12545">http://arxiv.org/abs/2309.12545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junqi-jiang/proplace">https://github.com/junqi-jiang/proplace</a></li>
<li>paper_authors: Junqi Jiang, Jianglin Lan, Francesco Leofante, Antonio Rago, Francesca Toni</li>
<li>for: 这篇论文的目的是解释神经网络分类器的counterfactual explanations（CEs）。</li>
<li>methods: 这篇论文提出了一种名为PROPLACE的方法，利用Robust optimization技术来解释神经网络分类器的CEs。</li>
<li>results: 对比六种基eline，PROPLACE在三个评价方面的表现最佳，其中五种基eline都是targeting robustness。<details>
<summary>Abstract</summary>
Counterfactual Explanations (CEs) have received increasing interest as a major methodology for explaining neural network classifiers. Usually, CEs for an input-output pair are defined as data points with minimum distance to the input that are classified with a different label than the output. To tackle the established problem that CEs are easily invalidated when model parameters are updated (e.g. retrained), studies have proposed ways to certify the robustness of CEs under model parameter changes bounded by a norm ball. However, existing methods targeting this form of robustness are not sound or complete, and they may generate implausible CEs, i.e., outliers wrt the training dataset. In fact, no existing method simultaneously optimises for proximity and plausibility while preserving robustness guarantees. In this work, we propose Provably RObust and PLAusible Counterfactual Explanations (PROPLACE), a method leveraging on robust optimisation techniques to address the aforementioned limitations in the literature. We formulate an iterative algorithm to compute provably robust CEs and prove its convergence, soundness and completeness. Through a comparative experiment involving six baselines, five of which target robustness, we show that PROPLACE achieves state-of-the-art performances against metrics on three evaluation aspects.
</details>
<details>
<summary>摘要</summary>
counterfactual explanations (CEs) 已经收到了增加的关注，作为神经网络分类器的主要方法ологи。通常，对输入输出对的 CE 是指最近输入的数据点，被分类为不同的标签。为解决已经存在的问题， CE 在模型参数更新（例如 retrained）后会被无效化，研究者们已经提出了保证 CE 在模型参数变化下的稳定性的方法。然而，现有的方法不具备完善性和准确性，可能生成不合理的 CE，即训练数据集中的异常值。事实上，现有的方法没有同时优化 proximity 和 plausibility，保持robustness guarantees。在这种情况下，我们提出了可证实 Robust and PLAusible Counterfactual Explanations (PROPLACE)，一种基于robust optimization技术来解决现有文献中的限制。我们设计了一种迭代算法来计算可证实的 CE，并证明其 converges，完整性和准确性。通过对六个基elines进行比较实验，我们显示了 PROPLACE 在三个评价方面的状态前 performances。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/cs.AI_2023_09_22/" data-id="clp9qz7z9004bok889witenpc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/42/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><a class="page-number" href="/page/42/">42</a><span class="page-number current">43</span><a class="page-number" href="/page/44/">44</a><a class="page-number" href="/page/45/">45</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/44/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
