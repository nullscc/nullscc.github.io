
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/43/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.LG_2023_09_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/04/cs.LG_2023_09_04/" class="article-date">
  <time datetime="2023-09-04T10:00:00.000Z" itemprop="datePublished">2023-09-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/04/cs.LG_2023_09_04/">cs.LG - 2023-09-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Delegating-Data-Collection-in-Decentralized-Machine-Learning"><a href="#Delegating-Data-Collection-in-Decentralized-Machine-Learning" class="headerlink" title="Delegating Data Collection in Decentralized Machine Learning"></a>Delegating Data Collection in Decentralized Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01837">http://arxiv.org/abs/2309.01837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nivasini Ananthakrishnan, Stephen Bates, Michael I. Jordan, Nika Haghtalab</li>
<li>for: 研究了数据收集委托的优化问题，尤其是面临不确定评估模型质量和无知对优化模型性能的两个基本机器学习挑战。</li>
<li>methods: 基于合同理论开始，设计优化和近优化合同来解决两个挑战，并通过简单的线性合同实现1-1&#x2F;e的最优Utility，即使主体只有小考试集。此外，我们还给出了测试集大小的条件，以实现趋近于优化Utility的添加性近似。</li>
<li>results: 我们显示了在不确定评估模型质量和无知对优化模型性能的情况下，可以通过简单的线性合同和可靠的算法来解决这两个挑战，并实现高效的数据收集委托。<details>
<summary>Abstract</summary>
Motivated by the emergence of decentralized machine learning ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental machine learning challenges: lack of certainty in the assessment of model quality and lack of knowledge regarding the optimal performance of any model. We show that lack of certainty can be dealt with via simple linear contracts that achieve 1-1/e fraction of the first-best utility, even if the principal has a small test set. Furthermore, we give sufficient conditions on the size of the principal's test set that achieves a vanishing additive approximation to the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract.
</details>
<details>
<summary>摘要</summary>
驱动了分布式机器学习生态系统的出现，我们研究数据采集委托的问题。从ontract理论为起点，我们设计优化和近似优化的合同，解决机器学习中两个基本挑战：评估模型质量的不确定性和任何模型的优化性知识不够。我们显示，不确定性可以通过简单的线性合同来处理，实现1-1/e的首选utililty，即使主体只有一小部分的测试集。此外，我们给出了测试集的大小必须满足的条件，以实现趋近于优化的utililty。为了解决无先知道优化性的问题，我们给出了一种可靠和高效的 convex program，可以动态计算优化的合同。</systext>Note: "systext" is the Simplified Chinese character set, which is a standardized form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Soft-Dropout-A-Practical-Approach-for-Mitigating-Overfitting-in-Quantum-Convolutional-Neural-Networks"><a href="#Soft-Dropout-A-Practical-Approach-for-Mitigating-Overfitting-in-Quantum-Convolutional-Neural-Networks" class="headerlink" title="Soft-Dropout: A Practical Approach for Mitigating Overfitting in Quantum Convolutional Neural Networks"></a>Soft-Dropout: A Practical Approach for Mitigating Overfitting in Quantum Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01829">http://arxiv.org/abs/2309.01829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aakash Ravindra Shinde, Charu Jain, Amir Kalev</li>
<li>for: 这 paper 是为了研究量子卷积神经网络（QCNN）中的过拟合问题。</li>
<li>methods: 这 paper 使用了一种经典的过拟合 mitigation 方法，即在训练后添加 dropout 方法。</li>
<li>results: 研究发现，在量子设定下直接实现 dropout 方法会导致 QCNN 的成功率减少。此外，提出了一种更加温和的 dropout 方法，可以成功地处理 QCNN 中的过拟合问题。<details>
<summary>Abstract</summary>
Quantum convolutional neural network (QCNN), an early application for quantum computers in the NISQ era, has been consistently proven successful as a machine learning (ML) algorithm for several tasks with significant accuracy. Derived from its classical counterpart, QCNN is prone to overfitting. Overfitting is a typical shortcoming of ML models that are trained too closely to the availed training dataset and perform relatively poorly on unseen datasets for a similar problem. In this work we study the adaptation of one of the most successful overfitting mitigation method, knows as the (post-training) dropout method, to the quantum setting. We find that a straightforward implementation of this method in the quantum setting leads to a significant and undesirable consequence: a substantial decrease in success probability of the QCNN. We argue that this effect exposes the crucial role of entanglement in QCNNs and the vulnerability of QCNNs to entanglement loss. To handle overfitting, we proposed a softer version of the dropout method. We find that the proposed method allows us to handle successfully overfitting in the test cases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Secure-and-Efficient-Federated-Learning-in-LEO-Constellations-using-Decentralized-Key-Generation-and-On-Orbit-Model-Aggregation"><a href="#Secure-and-Efficient-Federated-Learning-in-LEO-Constellations-using-Decentralized-Key-Generation-and-On-Orbit-Model-Aggregation" class="headerlink" title="Secure and Efficient Federated Learning in LEO Constellations using Decentralized Key Generation and On-Orbit Model Aggregation"></a>Secure and Efficient Federated Learning in LEO Constellations using Decentralized Key Generation and On-Orbit Model Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01828">http://arxiv.org/abs/2309.01828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Elmahallawy, Tie Luo, Mohamed I. Ibrahem</li>
<li>for: 这篇论文是为了解决在低地球轨道（LEO）上运行小卫星的资料下载和联合学习问题。</li>
<li>methods: 这篇论文提出了一个名为 FedSecure 的安全联合学习方法，它包括两个新的 ком成分：（1）分散的钥匙生成，以保护卫星数据的隐私使用函数加密方案，和（2）在轨道上进行模型传输和聚合，从而实现每个轨道的部分全球模型，以最小化遗失可见区域的对等待时间。</li>
<li>results: 我们的分析和结果显示，FedSecure 可以保护每个卫星的数据免受窃听者、curious server 或 curious satellite 的披露，并且具有较低的通信和计算负载，从而实现高精度（达85.35%）的联合学习。<details>
<summary>Abstract</summary>
Satellite technologies have advanced drastically in recent years, leading to a heated interest in launching small satellites into low Earth orbit (LEOs) to collect massive data such as satellite imagery. Downloading these data to a ground station (GS) to perform centralized learning to build an AI model is not practical due to the limited and expensive bandwidth. Federated learning (FL) offers a potential solution but will incur a very large convergence delay due to the highly sporadic and irregular connectivity between LEO satellites and GS. In addition, there are significant security and privacy risks where eavesdroppers or curious servers/satellites may infer raw data from satellites' model parameters transmitted over insecure communication channels. To address these issues, this paper proposes FedSecure, a secure FL approach designed for LEO constellations, which consists of two novel components: (1) decentralized key generation that protects satellite data privacy using a functional encryption scheme, and (2) on-orbit model forwarding and aggregation that generates a partial global model per orbit to minimize the idle waiting time for invisible satellites to enter the visible zone of the GS. Our analysis and results show that FedSecure preserves the privacy of each satellite's data against eavesdroppers, a curious server, or curious satellites. It is lightweight with significantly lower communication and computation overheads than other privacy-preserving FL aggregation approaches. It also reduces convergence delay drastically from days to only a few hours, yet achieving high accuracy of up to 85.35% using realistic satellite images.
</details>
<details>
<summary>摘要</summary>
卫星技术在最近几年内发展了非常快，导致低地球轨道（LEO）上发射小卫星来收集大量数据，如卫星成像。由于下载这些数据到地面站（GS）以进行中央学习并建立人工智能模型是不实际的，因为卫星和GS之间的带宽是有限且昂贵的。联邦学习（FL）提供了一个可能的解决方案，但是它会产生非常大的融合延迟，因为LEO卫星和GS之间的连接是不规则和不可预测的。此外，在卫星和GS之间的通信频道上存在严重的安全和隐私风险，可能导致卫星数据的泄露。为解决这些问题，这篇论文提出了FedSecure，一种安全的联邦学习方法，包括两个新的组件：1. 分布式密钥生成，通过功能加密方案保护卫星数据隐私。2. 在轨道上进行模型转发和聚合，每次轨道执行一个部分全球模型，以最小化隐藏在视野外的卫星等待时间。我们的分析和结果表明，FedSecure可以保护每个卫星的数据隐私，并且具有较低的通信和计算开销，相比其他隐私保护的聚合方法。它还可以减少融合延迟从几天减少到只需几个小时，同时实现高准确率（达85.35%）。
</details></li>
</ul>
<hr>
<h2 id="LoopTune-Optimizing-Tensor-Computations-with-Reinforcement-Learning"><a href="#LoopTune-Optimizing-Tensor-Computations-with-Reinforcement-Learning" class="headerlink" title="LoopTune: Optimizing Tensor Computations with Reinforcement Learning"></a>LoopTune: Optimizing Tensor Computations with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01825">http://arxiv.org/abs/2309.01825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dejan Grubisic, Bram Wasti, Chris Cummins, John Mellor-Crummey, Aleksandar Zlateski</li>
<li>for: 这篇论文是为了解决高性能机器学习应用在新硬件上运行的问题，但传统的编译器无法提供性能。</li>
<li>methods: 这篇论文使用了深度学习自适应优化技术，开发了一个名为LoopTune的深度学习编译器，可以优化深度学习模型中的矩阵计算在CPU上。LoopTune使用了ultra-fast lightweight代码生成器LoopNest进行硬件特定优化。</li>
<li>results: LoopTune可以减少LoopNest的搜索时间，并且可以生成论文速度比TVM、MetaSchedule和AutoTVM快，consistently performing at the level of the hand-tuned library Numpy。此外，LoopTune可以在秒钟级别进行代码优化。<details>
<summary>Abstract</summary>
Advanced compiler technology is crucial for enabling machine learning applications to run on novel hardware, but traditional compilers fail to deliver performance, popular auto-tuners have long search times and expert-optimized libraries introduce unsustainable costs. To address this, we developed LoopTune, a deep reinforcement learning compiler that optimizes tensor computations in deep learning models for the CPU. LoopTune optimizes tensor traversal order while using the ultra-fast lightweight code generator LoopNest to perform hardware-specific optimizations. With a novel graph-based representation and action space, LoopTune speeds up LoopNest by 3.2x, generating an order of magnitude faster code than TVM, 2.8x faster than MetaSchedule, and 1.08x faster than AutoTVM, consistently performing at the level of the hand-tuned library Numpy. Moreover, LoopTune tunes code in order of seconds.
</details>
<details>
<summary>摘要</summary>
高级编译技术对机器学习应用的运行是关键，但传统的编译器无法提供性能。常用的自动调参器有很长的搜索时间，专家优化库会带来不可持续的成本。为解决这问题，我们开发了 LoopTune，一种基于深度学习的编译器，用于优化深度学习模型中的矩阵计算。LoopTune优化矩阵游标顺序，并使用 ultra-fast 轻量级代码生成器 LoopNest 进行硬件特定优化。使用图表 Representation 和 Action 空间，LoopTune 将 LoopNest 加速了 3.2 倍，生成的代码比 TVM 快了一个数量级，比 MetaSchedule 快了 2.8 倍，和 AutoTVM 快了 1.08 倍，一直保持与手动优化库 Numpy 的水平。此外，LoopTune 只需几秒钟来调参代码。
</details></li>
</ul>
<hr>
<h2 id="Computation-and-Communication-Efficient-Federated-Learning-over-Wireless-Networks"><a href="#Computation-and-Communication-Efficient-Federated-Learning-over-Wireless-Networks" class="headerlink" title="Computation and Communication Efficient Federated Learning over Wireless Networks"></a>Computation and Communication Efficient Federated Learning over Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01816">http://arxiv.org/abs/2309.01816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaonan Liu, Tharmalingam Ratnarajah</li>
<li>for: 提高 Federated Learning （FL）模型训练的精度和效率，同时保持数据隐私。</li>
<li>methods: 提出一种基于 partial model pruning 和个性化的 FL 框架，将学习模型分为全球部分和个性化部分，以适应各个设备的非独立同分布（non IID）数据。</li>
<li>results: 通过数学分析和优化问题的解法，提高 FL 框架的计算和通信负载，同时提高学习精度和速度。实验结果显示，提议的 FL 框架可以降低大约 50% 的计算和通信负载。<details>
<summary>Abstract</summary>
Federated learning (FL) allows model training from local data by edge devices while preserving data privacy. However, the learning accuracy decreases due to the heterogeneity of devices data, and the computation and communication latency increase when updating large scale learning models on devices with limited computational capability and wireless resources. To overcome these challenges, we consider a novel FL framework with partial model pruning and personalization. This framework splits the learning model into a global part with model pruning shared with all devices to learn data representations and a personalized part to be fine tuned for a specific device, which adapts the model size during FL to reduce both computation and communication overhead and minimize the overall training time, and increases the learning accuracy for the device with non independent and identically distributed (non IID) data. Then, the computation and communication latency and the convergence analysis of the proposed FL framework are mathematically analyzed. Based on the convergence analysis, an optimization problem is formulated to maximize the convergence rate under a latency threshold by jointly optimizing the pruning ratio and wireless resource allocation. By decoupling the optimization problem and deploying Karush Kuhn Tucker (KKT) conditions, we derive the closed form solutions of pruning ratio and wireless resource allocation. Finally, experimental results demonstrate that the proposed FL framework achieves a remarkable reduction of approximately 50 percents computation and communication latency compared with the scheme only with model personalization.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）允许本地数据进行模型训练，同时保持数据隐私。然而，由于设备数据的不同性，学习准确率减少，并且更新大规模学习模型在设备上的计算和通信负担增加。为了解决这些挑战，我们提出了一种新的FL框架，其中分解学习模型为全球部分和个性化部分。全球部分通过模型剔除来学习数据表示，而个性化部分在特定设备上进行细化调整，以适应非独立同分布（non IID）数据。这种框架可以降低计算和通信延迟，提高学习精度，并最大化 converges 率。然后，我们数学分析了计算和通信延迟以及折衔率的影响。基于折衔率的最大化，我们提出了一个优化问题，以提高 converges 率下的延迟阈值。通过分解优化问题并应用 KKT 条件，我们得到了封闭式的解决方案。最后，我们通过实验证明，提出的FL框架可以降低约50%的计算和通信延迟。
</details></li>
</ul>
<hr>
<h2 id="Asymmetric-matrix-sensing-by-gradient-descent-with-small-random-initialization"><a href="#Asymmetric-matrix-sensing-by-gradient-descent-with-small-random-initialization" class="headerlink" title="Asymmetric matrix sensing by gradient descent with small random initialization"></a>Asymmetric matrix sensing by gradient descent with small random initialization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01796">http://arxiv.org/abs/2309.01796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johan S. Wind</li>
<li>for:  matrix sensing problem, reconstructing low-rank matrix from linear measurements</li>
<li>methods: factorized gradient descent, continuous differential equation (perturbed gradient flow)</li>
<li>results: quick convergence to true target matrix with bounded perturbation, novel proof of asymmetric matrix sensing<details>
<summary>Abstract</summary>
We study matrix sensing, which is the problem of reconstructing a low-rank matrix from a few linear measurements. It can be formulated as an overparameterized regression problem, which can be solved by factorized gradient descent when starting from a small random initialization.   Linear neural networks, and in particular matrix sensing by factorized gradient descent, serve as prototypical models of non-convex problems in modern machine learning, where complex phenomena can be disentangled and studied in detail. Much research has been devoted to studying special cases of asymmetric matrix sensing, such as asymmetric matrix factorization and symmetric positive semi-definite matrix sensing.   Our key contribution is introducing a continuous differential equation that we call the $\textit{perturbed gradient flow}$. We prove that the perturbed gradient flow converges quickly to the true target matrix whenever the perturbation is sufficiently bounded. The dynamics of gradient descent for matrix sensing can be reduced to this formulation, yielding a novel proof of asymmetric matrix sensing with factorized gradient descent. Compared to directly analyzing the dynamics of gradient descent, the continuous formulation allows bounding key quantities by considering their derivatives, often simplifying the proofs. We believe the general proof technique may prove useful in other settings as well.
</details>
<details>
<summary>摘要</summary>
我们研究矩阵感知问题，即从一些线性测量中重建一个低级矩阵的问题。可以将其形式化为过参数化回归问题，可以通过分解梯度下降来解决，当起始于一个小random initialization时。  linear neural networks 和特别是矩阵感知通过分解梯度下降是现代机器学习中非 convex 问题的典型模型，其中复杂现象可以分解和研究在详细的方式上。许多研究者已经投入到 изучение特殊情况的偏 asymmetric matrix sensing 中，如偏 asymmetric matrix factorization 和Symmetric positive semi-definite matrix sensing。我们的关键贡献在于引入一个名为 $\textit{perturbed gradient flow}$ 的连续偏微分方程。我们证明了当perturbation够小时，这个方程快速地 converge 到真正的目标矩阵。矩阵感知的梯度下降动力学可以被归纳到这个形式化中，从而得到一种新的证明方式。与直接分析梯度下降动力学相比，连续形式化允许通过考虑其导数来简化证明。我们认为这种普适的证明技巧可能在其他情况下也会有用。
</details></li>
</ul>
<hr>
<h2 id="Composite-federated-learning-with-heterogeneous-data"><a href="#Composite-federated-learning-with-heterogeneous-data" class="headerlink" title="Composite federated learning with heterogeneous data"></a>Composite federated learning with heterogeneous data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01795">http://arxiv.org/abs/2309.01795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaojiao Zhang, Jiang Hu, Mikael Johansson</li>
<li>for: 解决复杂的 Federated Learning（FL）问题</li>
<li>methods: 使用战略性分解质量梯度和通信，并不假设数据相似性来避免客户端漂移</li>
<li>results: 比前者更高效，可以 linearly 收敛到一个 neighborhood 的优解Here’s a breakdown of each point:1. for: The paper is written to solve the composite Federated Learning (FL) problem.2. methods: The paper proposes a novel algorithm that manages non-smooth regularization by decoupling the proximal operator and communication, and addresses client drift without assuming data similarity. Each worker uses local updates to reduce communication frequency with the server and transmits only a $d$-dimensional vector per communication round.3. results: The algorithm is proven to converge linearly to a neighborhood of the optimal solution, and the paper demonstrates the superiority of the algorithm over state-of-the-art methods in numerical experiments.<details>
<summary>Abstract</summary>
We propose a novel algorithm for solving the composite Federated Learning (FL) problem. This algorithm manages non-smooth regularization by strategically decoupling the proximal operator and communication, and addresses client drift without any assumptions about data similarity. Moreover, each worker uses local updates to reduce the communication frequency with the server and transmits only a $d$-dimensional vector per communication round. We prove that our algorithm converges linearly to a neighborhood of the optimal solution and demonstrate the superiority of our algorithm over state-of-the-art methods in numerical experiments.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的 Federation Learning（FL）问题的算法。该算法在规范化正则化中使用推迟分离 proximal 算符和通信，并 Addresses 客户端漂移无需数据相似性假设。另外，每个工作者使用本地更新减少与服务器之间的通信频率，并只在通信轮次中发送 $d$-维向量。我们证明了我们的算法 linearly 收敛到优解附近的解，并在数值实验中证明了我们的算法与现状算法的超越性。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Grammar-Induced-Geometry-for-Data-Efficient-Molecular-Property-Prediction"><a href="#Hierarchical-Grammar-Induced-Geometry-for-Data-Efficient-Molecular-Property-Prediction" class="headerlink" title="Hierarchical Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction"></a>Hierarchical Grammar-Induced Geometry for Data-Efficient Molecular Property Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01788">http://arxiv.org/abs/2309.01788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gmh14/geo-deg">https://github.com/gmh14/geo-deg</a></li>
<li>paper_authors: Minghao Guo, Veronika Thost, Samuel W Song, Adithya Balachandran, Payel Das, Jie Chen, Wojciech Matusik</li>
<li>for: 这项研究的目的是提出一种数据效率的物理属性预测方法，以便在材料和药物发现领域中进行预测。</li>
<li>methods: 该方法使用学习式层次分子 grammar，可以生成分子结构从 grammar 生成规则。这种 grammar 适应了分子结构空间的显式几何结构，从而提供了有用的分子结构相似性的几何信息。 property 预测使用图 neural diffusion 在 grammar-induced 几何空间中进行。</li>
<li>results: 在小规模和大规模数据集上，我们的评估表明，这种方法可以比supervised和预训练图 neural network 等基准方法表现出色，并且在具有极其有限数据情况下进行预测时表现出色。我们还包括了细化的减少研究和进一步分析，以证明我们的解决方案的有效性。<details>
<summary>Abstract</summary>
The prediction of molecular properties is a crucial task in the field of material and drug discovery. The potential benefits of using deep learning techniques are reflected in the wealth of recent literature. Still, these techniques are faced with a common challenge in practice: Labeled data are limited by the cost of manual extraction from literature and laborious experimentation. In this work, we propose a data-efficient property predictor by utilizing a learnable hierarchical molecular grammar that can generate molecules from grammar production rules. Such a grammar induces an explicit geometry of the space of molecular graphs, which provides an informative prior on molecular structural similarity. The property prediction is performed using graph neural diffusion over the grammar-induced geometry. On both small and large datasets, our evaluation shows that this approach outperforms a wide spectrum of baselines, including supervised and pre-trained graph neural networks. We include a detailed ablation study and further analysis of our solution, showing its effectiveness in cases with extremely limited data. Code is available at https://github.com/gmh14/Geo-DEG.
</details>
<details>
<summary>摘要</summary>
“分子性能预测是物质和药物搜索领域中的一项关键任务。 latest literature 中的 potential benefits 反映了使用深度学习技术的可能性。然而，这些技术在实践中受到一种常见的挑战：标注数据受到文献EXTRACTION AND laborious experimentation的成本限制。在这种情况下，我们提出了一种数据效率的属性预测器，利用可学习的分子语法树来生成分子。这种语法树 induces 分子图的Explicit geometry，提供了有用的分子结构相似性的假设。我们使用图解 diffusion 来预测分子的属性，并在小和大数据集上评估了我们的方法。结果表明，我们的方法可以比supervised和预训练图神经网络Outperform。我们还进行了详细的折衣分析和进一步的分析，证明了我们的解决方案在数据受限情况下的有效性。代码可以在https://github.com/gmh14/Geo-DEG中找到。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="ATMS-Algorithmic-Trading-Guided-Market-Simulation"><a href="#ATMS-Algorithmic-Trading-Guided-Market-Simulation" class="headerlink" title="ATMS: Algorithmic Trading-Guided Market Simulation"></a>ATMS: Algorithmic Trading-Guided Market Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01784">http://arxiv.org/abs/2309.01784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Wei, Andrea Coletta, Svitlana Vyetrenko, Tucker Balch</li>
<li>For: The paper aims to propose a metric to quantify market discrepancy and develop an Algorithmic Trading-guided Market Simulation (ATMS) to improve the realism of market simulations.* Methods: The proposed metric measures the difference between a causal effect from underlying market unique characteristics and is evaluated through the interaction between the AT agent and the market. ATMS formulates the simulator as a stochastic policy in reinforcement learning (RL) to account for the sequential nature of trading, and utilizes the policy gradient update to bypass differentiating the proposed metric.* Results: The proposed metric and ATMS are demonstrated to be effective through extensive experiments on semi-real market data, showing improved similarity to reality compared to the state-of-the-art conditional Wasserstein Generative Adversarial Network (cWGAN) approach, and producing market data with more balanced BUY and SELL volumes.<details>
<summary>Abstract</summary>
The effective construction of an Algorithmic Trading (AT) strategy often relies on market simulators, which remains challenging due to existing methods' inability to adapt to the sequential and dynamic nature of trading activities. This work fills this gap by proposing a metric to quantify market discrepancy. This metric measures the difference between a causal effect from underlying market unique characteristics and it is evaluated through the interaction between the AT agent and the market. Most importantly, we introduce Algorithmic Trading-guided Market Simulation (ATMS) by optimizing our proposed metric. Inspired by SeqGAN, ATMS formulates the simulator as a stochastic policy in reinforcement learning (RL) to account for the sequential nature of trading. Moreover, ATMS utilizes the policy gradient update to bypass differentiating the proposed metric, which involves non-differentiable operations such as order deletion from the market. Through extensive experiments on semi-real market data, we demonstrate the effectiveness of our metric and show that ATMS generates market data with improved similarity to reality compared to the state-of-the-art conditional Wasserstein Generative Adversarial Network (cWGAN) approach. Furthermore, ATMS produces market data with more balanced BUY and SELL volumes, mitigating the bias of the cWGAN baseline approach, where a simple strategy can exploit the BUY/SELL imbalance for profit.
</details>
<details>
<summary>摘要</summary>
通常，建立一个Algorithmic Trading（AT）策略的有效构造往往依赖市场模拟器，但是现有方法很难适应交易活动的顺序和动态性。这种工作填补了这一空白，提出了一个用于量化市场差异的度量。这个度量测量了 causal effect的差异，它通过AT代理和市场的交互来评估。更重要的是，我们引入了Algorithmic Trading-guided Market Simulation（ATMS），通过优化我们的提出的度量来寻找最佳的市场模拟器。受SeqGAN的启发，ATMS将市场模拟器形式化为一个随机政策，以便考虑交易的顺序性。此外，ATMS使用策略梯度更新来绕过非导数的操作，如市场中的订单删除。通过对半实际市场数据进行了广泛的实验，我们证明了我们的度量的有效性，并显示ATMS生成的市场数据与现有的conditional Wasserstein Generative Adversarial Network（cWGAN）方法相比，具有更高的实际性。此外，ATMS生成的市场数据具有更好的BUY和SELL量均衡，从而减轻cWGAN基础方法的偏见，其中一个简单的策略可以通过BUY/SELL偏见来获得利润。
</details></li>
</ul>
<hr>
<h2 id="Survival-Prediction-from-Imbalance-colorectal-cancer-dataset-using-hybrid-sampling-methods-and-tree-based-classifiers"><a href="#Survival-Prediction-from-Imbalance-colorectal-cancer-dataset-using-hybrid-sampling-methods-and-tree-based-classifiers" class="headerlink" title="Survival Prediction from Imbalance colorectal cancer dataset using hybrid sampling methods and tree-based classifiers"></a>Survival Prediction from Imbalance colorectal cancer dataset using hybrid sampling methods and tree-based classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01783">http://arxiv.org/abs/2309.01783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadegh Soleimani, Mahsa Bahrami, Mansour Vali</li>
<li>for: 预测COLRET cancer patients的1、3、5年生存率</li>
<li>methods: 使用优化的预处理技术、标准平衡技术、 Synthetic Minority Over-sampling Techniques (SMOTE) 和 pipelines of SMOTE和RENN方法来平衡数据，并使用 Decision Trees、Random Forest、Extra Tree、eXtreme Gradient Boosting 和 Light Gradient Boosting (LGBM) 等树型分类算法进行预测</li>
<li>results: 使用5-fold cross-validation方法进行性能评估，在高度不平衡的1年生存任务中，提出的方法与LGBM combinatorial方法达到了72.30%的敏感性；在3年生存任务中，combine RENN和LGBM方法达到了80.81%的敏感性，表明提出的方法在高度不平衡的数据集上表现最佳。<details>
<summary>Abstract</summary>
Background and Objective: Colorectal cancer is a high mortality cancer. Clinical data analysis plays a crucial role in predicting the survival of colorectal cancer patients, enabling clinicians to make informed treatment decisions. However, utilizing clinical data can be challenging, especially when dealing with imbalanced outcomes. This paper focuses on developing algorithms to predict 1-, 3-, and 5-year survival of colorectal cancer patients using clinical datasets, with particular emphasis on the highly imbalanced 1-year survival prediction task. To address this issue, we propose a method that creates a pipeline of some of standard balancing techniques to increase the true positive rate. Evaluation is conducted on a colorectal cancer dataset from the SEER database. Methods: The pre-processing step consists of removing records with missing values and merging categories. The minority class of 1-year and 3-year survival tasks consists of 10% and 20% of the data, respectively. Edited Nearest Neighbor, Repeated edited nearest neighbor (RENN), Synthetic Minority Over-sampling Techniques (SMOTE), and pipelines of SMOTE and RENN approaches were used and compared for balancing the data with tree-based classifiers. Decision Trees, Random Forest, Extra Tree, eXtreme Gradient Boosting, and Light Gradient Boosting (LGBM) are used in this article. Method. Results: The performance evaluation utilizes a 5-fold cross-validation approach. In the case of highly imbalanced datasets (1-year), our proposed method with LGBM outperforms other sampling methods with the sensitivity of 72.30%. For the task of imbalance (3-year survival), the combination of RENN and LGBM achieves a sensitivity of 80.81%, indicating that our proposed method works best for highly imbalanced datasets. Conclusions: Our proposed method significantly improves mortality prediction for the minority class of colorectal cancer patients.
</details>
<details>
<summary>摘要</summary>
背景和目标：肠Rectal癌是高 Mortality癌症，临床数据分析对于预测肠Rectal癌患者的存活率起着关键作用，帮助临床医生制定 Informed 治疗决策。然而，利用临床数据可能会困难，特别是面临异常尝试的情况。这篇论文关注了开发用来预测肠Rectal癌患者1-, 3-, 5年存活率的算法，特别是面临异常尝试的1年存活预测任务。为解决这一问题，我们提议一种方法，该方法包括一系列标准平衡技术，以增加真正正确率。我们对一个肠Rectal癌数据集进行评估。方法：数据预处理步骤包括去除异常值和合并类别。肠Rectal癌1年和3年存活任务中的少数类刚占数据集的10%和20%。我们使用编辑最近邻国（Edited Nearest Neighbor，RENN）、重复编辑最近邻国（Repeated edited nearest neighbor，SMOTE）、Synthetic Minority Over-sampling Techniques（SMOTE）和这些技术的组合来平衡数据，并与树型分类器结合。我们使用的分类器包括决策树、Random Forest、Extra Tree、eXtreme Gradient Boosting和Light Gradient Boosting（LGBM）。结果：我们使用5-fold Cross-validation方法进行性能评估。在面临异常尝试的1年存活任务中，我们提议的方法与LGBM结合的sensitivity达到72.30%，表明我们的方法在高度偏置的数据集中表现出色。在3年存活任务中，我们 combinational RENN和LGBM的方法达到了80.81%的sensitivity， indicating that our proposed method works best for highly imbalanced datasets。结论：我们的提议方法能够显著提高肠Rectal癌患者少数类的存活预测率。
</details></li>
</ul>
<hr>
<h2 id="Self-concordant-Smoothing-for-Convex-Composite-Optimization"><a href="#Self-concordant-Smoothing-for-Convex-Composite-Optimization" class="headerlink" title="Self-concordant Smoothing for Convex Composite Optimization"></a>Self-concordant Smoothing for Convex Composite Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01781">http://arxiv.org/abs/2309.01781</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adeyemiadeoye/SelfConcordantSmoothOptimization.jl">https://github.com/adeyemiadeoye/SelfConcordantSmoothOptimization.jl</a></li>
<li>paper_authors: Adeyemi D. Adeoye, Alberto Bemporad</li>
<li>for: 本研究旨在提出一种自相关平滑方法，用于最小化两个凸函数之和，其中一个是平滑的，另一个可能是非凸的。</li>
<li>methods: 本研究使用了部分平滑技术，只平滑了一部分非凸函数。研究者提出了一种自然的问题结构，以及一种变量 метриック选择方法和一种步长选择规则，特别适合 proximal Newton 类算法。</li>
<li>results: 研究者证明了本方法的本地二次quadratic convergence 率，并在两种算法中实现了这一点：Prox-N-SCORE 算法和 Prox-GGN-SCORE 算法。其中 Prox-GGN-SCORE 算法包含一种重要的近似过程，可以减少大多数计算开销，特别是在过parameterized 机器学习模型和 mini-batch  Settings 中。 numerics 示例表明了本方法的高效性和其他方法的不平等。<details>
<summary>Abstract</summary>
We introduce the notion of self-concordant smoothing for minimizing the sum of two convex functions: the first is smooth and the second may be nonsmooth. Our framework results naturally from the smoothing approximation technique referred to as partial smoothing in which only a part of the nonsmooth function is smoothed. The key highlight of our approach is in a natural property of the resulting problem's structure which provides us with a variable-metric selection method and a step-length selection rule particularly suitable for proximal Newton-type algorithms. In addition, we efficiently handle specific structures promoted by the nonsmooth function, such as $\ell_1$-regularization and group-lasso penalties. We prove local quadratic convergence rates for two resulting algorithms: Prox-N-SCORE, a proximal Newton algorithm and Prox-GGN-SCORE, a proximal generalized Gauss-Newton (GGN) algorithm. The Prox-GGN-SCORE algorithm highlights an important approximation procedure which helps to significantly reduce most of the computational overhead associated with the inverse Hessian. This approximation is essentially useful for overparameterized machine learning models and in the mini-batch settings. Numerical examples on both synthetic and real datasets demonstrate the efficiency of our approach and its superiority over existing approaches.
</details>
<details>
<summary>摘要</summary>
我们引入自己协调缓和的减少方法，用于减少两个凸函数：第一个是光滑的，第二个可能是不凸的。我们的框架从partial smoothing技术发展而来，仅将部分不凸函数缓和。我们的方法的关键特点在于它具有自然的变量 метри选择方法和步长选择规则，特别适合 proximal Newton 类型的算法。此外，我们可以有效地处理特定结构，它们由不凸函数带来，例如 $\ell_1$-调整和群lasso 罚则。我们证明了两个结果算法的本地quadratic convergence 率：Prox-N-SCORE 算法和 Prox-GGN-SCORE 算法。Prox-GGN-SCORE 算法显示了一个重要的近似程序，它可以帮助将大多数的计算负担与 inverse Hessian 相关联结。这个近似是在过parameterized machine learning 模型和 mini-batch 设定下特别有用。numero examples 表明我们的方法的效率和其他方法的优势。
</details></li>
</ul>
<hr>
<h2 id="Measuring-Interpreting-and-Improving-Fairness-of-Algorithms-using-Causal-Inference-and-Randomized-Experiments"><a href="#Measuring-Interpreting-and-Improving-Fairness-of-Algorithms-using-Causal-Inference-and-Randomized-Experiments" class="headerlink" title="Measuring, Interpreting, and Improving Fairness of Algorithms using Causal Inference and Randomized Experiments"></a>Measuring, Interpreting, and Improving Fairness of Algorithms using Causal Inference and Randomized Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01780">http://arxiv.org/abs/2309.01780</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Enouen, Tianshu Sun, Yan Liu</li>
<li>For: The paper is written to address the problem of algorithm fairness in real-world AI production systems, with a focus on developing a practical and easy-to-implement measurement framework and a systematic approach to correcting detected sources of bias.* Methods: The paper uses recent advances in causal inference and interpretable machine learning to develop an algorithm-agnostic framework called MIIF (Measure, Interpret, and Improve the Fairness of an algorithmic decision). The framework includes randomized experiments to measure algorithm bias and an explainable machine learning model to interpret and distill the beliefs of a blackbox algorithm.* Results: The paper demonstrates the effectiveness of MIIF in measuring algorithm bias and improving fairness in practical applications like e-commerce and targeted advertising, where industry A&#x2F;B testing is already abundant. The framework is shown to be simple and powerful, and the results suggest that it can be used to study algorithm fairness in a wide range of applications.<details>
<summary>Abstract</summary>
Algorithm fairness has become a central problem for the broad adoption of artificial intelligence. Although the past decade has witnessed an explosion of excellent work studying algorithm biases, achieving fairness in real-world AI production systems has remained a challenging task. Most existing works fail to excel in practical applications since either they have conflicting measurement techniques and/ or heavy assumptions, or require code-access of the production models, whereas real systems demand an easy-to-implement measurement framework and a systematic way to correct the detected sources of bias.   In this paper, we leverage recent advances in causal inference and interpretable machine learning to present an algorithm-agnostic framework (MIIF) to Measure, Interpret, and Improve the Fairness of an algorithmic decision. We measure the algorithm bias using randomized experiments, which enables the simultaneous measurement of disparate treatment, disparate impact, and economic value. Furthermore, using modern interpretability techniques, we develop an explainable machine learning model which accurately interprets and distills the beliefs of a blackbox algorithm. Altogether, these techniques create a simple and powerful toolset for studying algorithm fairness, especially for understanding the cost of fairness in practical applications like e-commerce and targeted advertising, where industry A/B testing is already abundant.
</details>
<details>
<summary>摘要</summary>
“算法公平性已成为人工智能广泛采用的中心问题。过去十年内，我们已经见证了优秀的研究算法偏见，但在实际应用中实现算法公平性仍然是一项挑战。现有大多数工作具有冲突的测量技术和假设，或者需要生产模型的代码访问，而实际应用需要一个简单易用的测量框架和一个系统atic的方法来纠正检测到的偏见来源。在这篇论文中，我们利用了最新的 causal inference 和可解释机器学习来提出一个算法无关的框架（MIIF），用于测量、解释和改进算法决策中的偏见。我们使用随机实验来测量算法偏见，这使得同时测量不同对待、不同影响和经济价值的可能性。此外，我们使用现代可解释技术来开发一个可解释的机器学习模型，可以准确地解释和概括黑盒算法的信仰。总之，这些技术创造了一个简单强大的工具集，用于研究算法公平性，特别是在实际应用中的电商和目标广告等场景，其中产业A/B测试已经充沛。”
</details></li>
</ul>
<hr>
<h2 id="DRAG-Divergence-based-Adaptive-Aggregation-in-Federated-learning-on-Non-IID-Data"><a href="#DRAG-Divergence-based-Adaptive-Aggregation-in-Federated-learning-on-Non-IID-Data" class="headerlink" title="DRAG: Divergence-based Adaptive Aggregation in Federated learning on Non-IID Data"></a>DRAG: Divergence-based Adaptive Aggregation in Federated learning on Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01779">http://arxiv.org/abs/2309.01779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Zhu, Jingjing Zhang, Shengyun Liu, Xin Wang</li>
<li>for: 这个论文的目的是提高 Federated Learning（FL）中的通信效率，以及解决因为不同的训练数据分布而导致的“客户端滑块”现象。</li>
<li>methods: 这个论文提出了一个新的度量“拟合度”，用于量度每个客户端的本地更新与全域尺度方向之间的夹角。然后，这个度量被用来实现在每个环境中动态地“拖”本地更新，以避免额外的通信过程。</li>
<li>results: 这个论文透过实验证明了DRAG算法在实际应用中具有优异的性能，能够有效地控制“客户端滑块”现象，并且具有不断性和稳定性。此外，DRAG算法还能够对某些Byzantine攻击进行有效的防护。<details>
<summary>Abstract</summary>
Local stochastic gradient descent (SGD) is a fundamental approach in achieving communication efficiency in Federated Learning (FL) by allowing individual workers to perform local updates. However, the presence of heterogeneous data distributions across working nodes causes each worker to update its local model towards a local optimum, leading to the phenomenon known as ``client-drift" and resulting in slowed convergence. To address this issue, previous works have explored methods that either introduce communication overhead or suffer from unsteady performance. In this work, we introduce a novel metric called ``degree of divergence," quantifying the angle between the local gradient and the global reference direction. Leveraging this metric, we propose the divergence-based adaptive aggregation (DRAG) algorithm, which dynamically ``drags" the received local updates toward the reference direction in each round without requiring extra communication overhead. Furthermore, we establish a rigorous convergence analysis for DRAG, proving its ability to achieve a sublinear convergence rate. Compelling experimental results are presented to illustrate DRAG's superior performance compared to state-of-the-art algorithms in effectively managing the client-drift phenomenon. Additionally, DRAG exhibits remarkable resilience against certain Byzantine attacks. By securely sharing a small sample of the client's data with the FL server, DRAG effectively counters these attacks, as demonstrated through comprehensive experiments.
</details>
<details>
<summary>摘要</summary>
本文提出了一种新的度量量名为“分布度”，用于量化当前工作节点的本地梯度和全局参考方向之间的角度。基于这个度量量，我们提出了一种名为“分布度基于的自适应聚合”（DRAG）算法，可以在每个轮次中动态地“拖”收到的本地更新向参考方向。这种算法不需要额外的通信开销，同时能够有效地控制客户端漂移现象。此外，我们也提供了一种准确的收敛分析，证明DRAG可以实现下线性收敛率。实验结果表明，DRAG在面临客户端漂移现象时表现出了显著的优势，并且具有remarkable的抗拒攻击能力。
</details></li>
</ul>
<hr>
<h2 id="CONFIDERAI-a-novel-CONFormal-Interpretable-by-Design-score-function-for-Explainable-and-Reliable-Artificial-Intelligence"><a href="#CONFIDERAI-a-novel-CONFormal-Interpretable-by-Design-score-function-for-Explainable-and-Reliable-Artificial-Intelligence" class="headerlink" title="CONFIDERAI: a novel CONFormal Interpretable-by-Design score function for Explainable and Reliable Artificial Intelligence"></a>CONFIDERAI: a novel CONFormal Interpretable-by-Design score function for Explainable and Reliable Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01778">http://arxiv.org/abs/2309.01778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Carlevaro, Sara Narteni, Fabrizio Dabbene, Marco Muselli, Maurizio Mongelli</li>
<li>For: The paper proposes a methodology for linking conformal prediction with explainable machine learning, with the goal of creating more reliable and trustworthy artificial intelligence systems.* Methods: The paper introduces a new score function called CONFIDERAI, which leverages both the predictive ability of rules and their geometric position within boundaries. Additionally, the paper addresses the problem of defining regions in feature space where conformal guarantees are satisfied using techniques to control the number of non-conformal samples in conformal regions based on support vector data description (SVDD).* Results: The paper reports promising results on benchmark and real datasets, such as DNS tunneling detection and cardiovascular disease prediction.<details>
<summary>Abstract</summary>
Everyday life is increasingly influenced by artificial intelligence, and there is no question that machine learning algorithms must be designed to be reliable and trustworthy for everyone. Specifically, computer scientists consider an artificial intelligence system safe and trustworthy if it fulfills five pillars: explainability, robustness, transparency, fairness, and privacy. In addition to these five, we propose a sixth fundamental aspect: conformity, that is, the probabilistic assurance that the system will behave as the machine learner expects. In this paper, we propose a methodology to link conformal prediction with explainable machine learning by defining CONFIDERAI, a new score function for rule-based models that leverages both rules predictive ability and points geometrical position within rules boundaries. We also address the problem of defining regions in the feature space where conformal guarantees are satisfied by exploiting techniques to control the number of non-conformal samples in conformal regions based on support vector data description (SVDD). The overall methodology is tested with promising results on benchmark and real datasets, such as DNS tunneling detection or cardiovascular disease prediction.
</details>
<details>
<summary>摘要</summary>
每天生活都在人工智能的影响下，机器学习算法必须设计为可靠和信任worthy。特别是计算机科学家认为一个人工智能系统安全和可靠的五大基础：解释性、可靠性、透明度、公平性和隐私。此外，我们还提出了第六个基本方面：准确性，即机器学习者期望的系统行为的概率ensure。在这篇论文中，我们提出了将CONFIDERAI作为新的分数函数，用于规则型模型，该函数利用规则预测的能力和点在规则边界的几何位置。我们还解决了定义特征空间中符合 garanties的问题，通过控制特征空间中非符合 garanties样本的数量来基于支持向量数据描述（SVDD）。总的来说，我们的方法ологи是在 benchmark和实际数据集上测试，如 DNS 隧道检测或心血管疾病预测。
</details></li>
</ul>
<hr>
<h2 id="Gated-recurrent-neural-networks-discover-attention"><a href="#Gated-recurrent-neural-networks-discover-attention" class="headerlink" title="Gated recurrent neural networks discover attention"></a>Gated recurrent neural networks discover attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01775">http://arxiv.org/abs/2309.01775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Zucchet, Seijin Kobayashi, Yassir Akram, Johannes von Oswald, Maxime Larcher, Angelika Steger, João Sacramento</li>
<li>for: 这个论文主要探讨了使用现代RNN的可能性，以及RNN如何通过线性循环层和Feedforward层实现自注意力。</li>
<li>methods: 这个论文使用了现代RNN的设计元素，包括线性循环层和Feedforward层，以及reverse工程技术来探讨RNN如何实现自注意力。</li>
<li>results: 研究发现，通过使用gradient descent优化器，RNN可以在具有简单学习任务的情况下实现同Transformers一样的性能，并且发现RNN在具有自注意力性的任务上实现了同Transformers一样的 Algorithm。<details>
<summary>Abstract</summary>
Recent architectural developments have enabled recurrent neural networks (RNNs) to reach and even surpass the performance of Transformers on certain sequence modeling tasks. These modern RNNs feature a prominent design pattern: linear recurrent layers interconnected by feedforward paths with multiplicative gating. Here, we show how RNNs equipped with these two design elements can exactly implement (linear) self-attention, the main building block of Transformers. By reverse-engineering a set of trained RNNs, we find that gradient descent in practice discovers our construction. In particular, we examine RNNs trained to solve simple in-context learning tasks on which Transformers are known to excel and find that gradient descent instills in our RNNs the same attention-based in-context learning algorithm used by Transformers. Our findings highlight the importance of multiplicative interactions in neural networks and suggest that certain RNNs might be unexpectedly implementing attention under the hood.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:现代建筑设计使得回归神经网络（RNN）能够在某些序列模型任务上与变换器相当或超越其性能。这些现代RNN具有一种明确的设计模式：线性循环层与Feedforward层之间的乘法关系。我们示出了RNN具有这两个元素可以直接实现线性自注意力，变换器的核心组件。通过分析训练过的RNN，我们发现在实际的梯度下降过程中，Gradient Descent实际上找到了我们的结构。具体来说，我们研究了在解决简单的上下文学习任务上训练过的RNN，这些任务在变换器上很出色，并发现了Gradient Descent在我们的RNN中实际上填充了同样的注意力基于上下文学习算法，与变转器一样。我们的发现表明多元互作在神经网络中的重要性，并且可能存在某些RNN在实际中无意识地实现注意力。
</details></li>
</ul>
<hr>
<h2 id="ADC-DAC-Free-Analog-Acceleration-of-Deep-Neural-Networks-with-Frequency-Transformation"><a href="#ADC-DAC-Free-Analog-Acceleration-of-Deep-Neural-Networks-with-Frequency-Transformation" class="headerlink" title="ADC&#x2F;DAC-Free Analog Acceleration of Deep Neural Networks with Frequency Transformation"></a>ADC&#x2F;DAC-Free Analog Acceleration of Deep Neural Networks with Frequency Transformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01771">http://arxiv.org/abs/2309.01771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nastaran Darabi, Maeesha Binte Hashem, Hongyi Pan, Ahmet Cetin, Wilfred Gomes, Amit Ranjan Trivedi<br>for: 这篇论文旨在提出一种能效的频域运算深度神经网络（DNN）加速方法，以减少网络的耗电和延迟。methods: 本文使用频域运算，例如华氏-哈达姆转换（WHT），并提出了一种新的类比频域运算的能效加速方法，通过利用类比频域的tensor Transformation。results: 根据16×16核心阵列，对8位输入处理，提出的方法可以在VDD &#x3D; 0.8 V下达到1602兆操作每秒每瓦（TOPS&#x2F;W）的能效率，而且可以透过早期终止策略提高到5311 TOPS&#x2F;W。<details>
<summary>Abstract</summary>
The edge processing of deep neural networks (DNNs) is becoming increasingly important due to its ability to extract valuable information directly at the data source to minimize latency and energy consumption. Frequency-domain model compression, such as with the Walsh-Hadamard transform (WHT), has been identified as an efficient alternative. However, the benefits of frequency-domain processing are often offset by the increased multiply-accumulate (MAC) operations required. This paper proposes a novel approach to an energy-efficient acceleration of frequency-domain neural networks by utilizing analog-domain frequency-based tensor transformations. Our approach offers unique opportunities to enhance computational efficiency, resulting in several high-level advantages, including array micro-architecture with parallelism, ADC/DAC-free analog computations, and increased output sparsity. Our approach achieves more compact cells by eliminating the need for trainable parameters in the transformation matrix. Moreover, our novel array micro-architecture enables adaptive stitching of cells column-wise and row-wise, thereby facilitating perfect parallelism in computations. Additionally, our scheme enables ADC/DAC-free computations by training against highly quantized matrix-vector products, leveraging the parameter-free nature of matrix multiplications. Another crucial aspect of our design is its ability to handle signed-bit processing for frequency-based transformations. This leads to increased output sparsity and reduced digitization workload. On a 16$\times$16 crossbars, for 8-bit input processing, the proposed approach achieves the energy efficiency of 1602 tera operations per second per Watt (TOPS/W) without early termination strategy and 5311 TOPS/W with early termination strategy at VDD = 0.8 V.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）的边缘处理在不断增长的重要性，这是因为它可以直接从数据源提取有价值信息，以降低延迟和能耗。频域模型压缩，如沃尔夏-哈达姆变换（WHT），已被证明是一种有效的方法。然而，频域处理的优点通常被增加的 multiply-accumulate（MAC）操作所抵消。这篇论文提出了一种新的能效加速频域神经网络的方法，利用频域频率基于的分析频率转换。我们的方法具有增强计算效率的多种优点，包括数组微架构的并行计算、ADC/DAC无计算、和输出稀疏化。我们的方法可以减少转换矩阵中的可训练参数，从而实现更加紧凑的维度。此外，我们的新的数组微架构可以在某些列和行上进行可靠的缝合，以便实现完全的并行计算。此外，我们的方法可以避免 ADC/DAC 计算，通过对高度量化矩阵-向量乘法进行训练，利用矩阵乘法的参数自由性。此外，我们的方法还可以处理signed-bit转换，从而提高输出稀疏化和减少数字化工作负担。在0.8 V 的电压下，我们的方法在16x16 核心上实现了1602 TOPS/W 的能效率，而不需要早期终止策略，并在使用早期终止策略时实现了5311 TOPS/W 的能效率。
</details></li>
</ul>
<hr>
<h2 id="On-Penalty-Methods-for-Nonconvex-Bilevel-Optimization-and-First-Order-Stochastic-Approximation"><a href="#On-Penalty-Methods-for-Nonconvex-Bilevel-Optimization-and-First-Order-Stochastic-Approximation" class="headerlink" title="On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation"></a>On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01753">http://arxiv.org/abs/2309.01753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeongyeol Kwon, Dohyun Kwon, Steve Wright, Robert Nowak</li>
<li>for: 本文研究了一种基于 penalty 方法的 first-order 算法，用于解决精度优化（BO）问题，其中目标函数都是平滑的，但可能不具有凸性。</li>
<li>methods: 本文使用 penalty 方法来把上下水平的目标函数 combine 成一个权重和 penalty 参数 $\sigma &gt; 0$ 的和。并通过准确地Characterizing 下水平目标函数和上水平目标函数的值和导数在 $\sigma $ 的关系，得出了 penalty 函数的梯度。</li>
<li>results: 本文提出了一种 first-order 算法，可以在 $\epsilon $ 精度下找到一个 $\epsilon $ 站ARY点，并且需要 $O(\epsilon^{-3})$ 和 $O(\epsilon^{-7})$ 访问 first-order (随机) 梯度或acles。在 deterministic 梯度或acles 的情况下，算法可以在一个完全单loop 方式下实现，并且可以在 $O(1)$ 扫描每次迭代。<details>
<summary>Abstract</summary>
In this work, we study first-order algorithms for solving Bilevel Optimization (BO) where the objective functions are smooth but possibly nonconvex in both levels and the variables are restricted to closed convex sets. As a first step, we study the landscape of BO through the lens of penalty methods, in which the upper- and lower-level objectives are combined in a weighted sum with penalty parameter $\sigma > 0$. In particular, we establish a strong connection between the penalty function and the hyper-objective by explicitly characterizing the conditions under which the values and derivatives of the two must be $O(\sigma)$-close. A by-product of our analysis is the explicit formula for the gradient of hyper-objective when the lower-level problem has multiple solutions under minimal conditions, which could be of independent interest. Next, viewing the penalty formulation as $O(\sigma)$-approximation of the original BO, we propose first-order algorithms that find an $\epsilon$-stationary solution by optimizing the penalty formulation with $\sigma = O(\epsilon)$. When the perturbed lower-level problem uniformly satisfies the small-error proximal error-bound (EB) condition, we propose a first-order algorithm that converges to an $\epsilon$-stationary point of the penalty function, using in total $O(\epsilon^{-3})$ and $O(\epsilon^{-7})$ accesses to first-order (stochastic) gradient oracles when the oracle is deterministic and oracles are noisy, respectively. Under an additional assumption on stochastic oracles, we show that the algorithm can be implemented in a fully {\it single-loop} manner, i.e., with $O(1)$ samples per iteration, and achieves the improved oracle-complexity of $O(\epsilon^{-3})$ and $O(\epsilon^{-5})$, respectively.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们研究了一种基于权重方法的首选算法来解决层次优化问题（BO），其中目标函数是连续的，但可能非几何的在两个水平上。作为第一步，我们通过对层次优化问题进行负权重方法的分析，特别是通过Explicitly characterizing the conditions under which the values and derivatives of the two must be $O(\sigma)$-close。这个分析中的结果还包括了层次优化问题的下面解的梯度的表达式，这可能有独立的应用价值。然后，我们视权重方法为$O(\sigma)$-近似于原始BO的方法，并提出了一种首选算法，它可以在$\sigma = O(\epsilon)$下找到一个$\epsilon$-稳定的解。当下面问题的较小精度预测误差Bound（EB）条件满足时，我们提出了一种首选算法，它可以在$O(\epsilon^{-3})$和$O(\epsilon^{-7})$的访问次数下 converge to an $\epsilon$-稳定点，其中可能存在随机 oracle的假设。在这种假设下，我们表明了该算法可以在单 loop（即每个迭代只需要 $O(1)$ 样本）下实现，并且实现了改进的oracle-复杂度 $O(\epsilon^{-3})$和 $O(\epsilon^{-5})$。
</details></li>
</ul>
<hr>
<h2 id="Turbulent-Flow-Simulation-using-Autoregressive-Conditional-Diffusion-Models"><a href="#Turbulent-Flow-Simulation-using-Autoregressive-Conditional-Diffusion-Models" class="headerlink" title="Turbulent Flow Simulation using Autoregressive Conditional Diffusion Models"></a>Turbulent Flow Simulation using Autoregressive Conditional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01745">http://arxiv.org/abs/2309.01745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Kohl, Li-Wei Chen, Nils Thuerey</li>
<li>for: 这篇论文主要是为了解决机器学习基于PDE解决方法中的稳定性问题。</li>
<li>methods: 这篇论文使用了一种基于 conditional diffusion 模型的抽象扩展，以提高学习型PDE解决方法的稳定性。</li>
<li>results: 论文表明，这种方法可以在各种复杂的液体流动场景中提供稳定的解决方案，并且可以在不同的流动参数范围内进行扩展。同时，这种方法还可以借助概率性的推 diffusion 方法来预测流体物理统计学上的性质。<details>
<summary>Abstract</summary>
Simulating turbulent flows is crucial for a wide range of applications, and machine learning-based solvers are gaining increasing relevance. However, achieving stability when generalizing to longer rollout horizons remains a persistent challenge for learned PDE solvers. We address this challenge by introducing a fully data-driven fluid solver that utilizes an autoregressive rollout based on conditional diffusion models. We show that this approach offers clear advantages in terms of rollout stability compared to other learned baselines. Remarkably, these improvements in stability are achieved without compromising the quality of generated samples, and our model successfully generalizes to flow parameters beyond the training regime. Additionally, the probabilistic nature of the diffusion approach allows for inferring predictions that align with the statistics of the underlying physics. We quantitatively and qualitatively evaluate the performance of our method on a range of challenging scenarios, including incompressible and transonic flows, as well as isotropic turbulence.
</details>
<details>
<summary>摘要</summary>
模拟湍流是许多应用领域的关键，而机器学习基于的解决方案在不断增长。然而，在扩展到更长的执行 horizon 时，学习得到的稳定性仍然是一个棘手的挑战。我们解决这个挑战 by introducing a fully data-driven fluid solver that utilizes an autoregressive rollout based on conditional diffusion models.我们发现这种方法可以在其他学习基准下提供明显的稳定性改进，而不需要牺牲生成样本的质量。另外，Diffusion 方法的 probabilistic nature 允许我们生成与物理统计相符的预测。我们对一系列复杂的场景进行量化和质量evaluate our method，包括不压缩和超音速流体动理，以及各向异otropic turbulence。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Resource-Allocation-for-Virtualized-Base-Stations-in-O-RAN-with-Online-Learning"><a href="#Adaptive-Resource-Allocation-for-Virtualized-Base-Stations-in-O-RAN-with-Online-Learning" class="headerlink" title="Adaptive Resource Allocation for Virtualized Base Stations in O-RAN with Online Learning"></a>Adaptive Resource Allocation for Virtualized Base Stations in O-RAN with Online Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01730">http://arxiv.org/abs/2309.01730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michail Kalntis, George Iosifidis, Fernando A. Kuipers</li>
<li>for:  optimize the allocation of resources in virtualized base stations (vBSs) to balance effective throughput and energy consumption, even in challenging environments.</li>
<li>methods:  online learning algorithm and meta-learning scheme to adapt to non-stationary or adversarial traffic demands and choose the best performing algorithm for different environments.</li>
<li>results:  sub-linear regret and up to 64.5% power consumption savings compared to state-of-the-art benchmarks, evaluated with real-world data and trace-driven evaluations.<details>
<summary>Abstract</summary>
Open Radio Access Network systems, with their virtualized base stations (vBSs), offer operators the benefits of increased flexibility, reduced costs, vendor diversity, and interoperability. Optimizing the allocation of resources in a vBS is challenging since it requires knowledge of the environment, (i.e., "external'' information), such as traffic demands and channel quality, which is difficult to acquire precisely over short intervals of a few seconds. To tackle this problem, we propose an online learning algorithm that balances the effective throughput and vBS energy consumption, even under unforeseeable and "challenging'' environments; for instance, non-stationary or adversarial traffic demands. We also develop a meta-learning scheme, which leverages the power of other algorithmic approaches, tailored for more "easy'' environments, and dynamically chooses the best performing one, thus enhancing the overall system's versatility and effectiveness. We prove the proposed solutions achieve sub-linear regret, providing zero average optimality gap even in challenging environments. The performance of the algorithms is evaluated with real-world data and various trace-driven evaluations, indicating savings of up to 64.5% in the power consumption of a vBS compared with state-of-the-art benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-Online-Classification-From-Estimation-to-Denoising"><a href="#Robust-Online-Classification-From-Estimation-to-Denoising" class="headerlink" title="Robust Online Classification: From Estimation to Denoising"></a>Robust Online Classification: From Estimation to Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01698">http://arxiv.org/abs/2309.01698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changlong Wu, Ananth Grama, Wojciech Szpankowski</li>
<li>for: 研究在含有噪声标签的在线分类中的噪声干扰。噪声机制由一个通用的kernel模型，对任何特征标签对而指定一个已知的分布集合，而选择器在每个时间步骤上选择未知分布，并生成噪声标签。</li>
<li>methods: 研究者使用了在线条件分布估计的概念，来扩展和涵盖了一般的噪声kernel和选择器，以及无限类型和随机生成的特征。</li>
<li>results: 研究者表明，对于许多自然的噪声kernel，选择器和标签函数的finite类型， minimax风险可以独立于时间跨度和对征函数的对数幂级别下降。此外，研究者还扩展了结果到无限类型和随机生成的特征。<details>
<summary>Abstract</summary>
We study online classification in the presence of noisy labels. The noise mechanism is modeled by a general kernel that specifies, for any feature-label pair, a (known) set of distributions over noisy labels. At each time step, an adversary selects an unknown distribution from the distribution set specified by the kernel based on the actual feature-label pair, and generates the noisy label from the selected distribution. The learner then makes a prediction based on the actual features and noisy labels observed thus far, and incurs loss $1$ if the prediction differs from the underlying truth (and $0$ otherwise). The prediction quality is quantified through minimax risk, which computes the cumulative loss over a finite horizon $T$. We show that for a wide range of natural noise kernels, adversarially selected features, and finite class of labeling functions, minimax risk can be upper bounded independent of the time horizon and logarithmic in the size of labeling function class. We then extend these results to inifinite classes and stochastically generated features via the concept of stochastic sequential covering. Our results extend and encompass findings of Ben-David et al. (2009) through substantial generality, and provide intuitive understanding through a novel reduction to online conditional distribution estimation.
</details>
<details>
<summary>摘要</summary>
我们研究在含杂标签下的在线分类。杂标机制是通过一个通用的核函数来模型，该函数指定了任何特征标签对的（已知）分布过滤器。在每个时间步骤中，一个对手选择一个未知分布从选择的分布集中，并生成含杂标签。学习者根据实际特征和含杂标签所见而进行预测，并且如果预测与真实真实值不同，则输入1，否则输入0。预测质量通过最小最大风险来衡量，该风险计算了时间 horizon $T$ 内的总损失。我们证明，对于许多自然的杂标核函数、对手选择的特征和finite类标签函数，最小最大风险可以独立于时间桢和对数型的总体规模而上下界。然后，我们扩展这些结果到无限类和随机生成的特征上，通过离散顺序覆盖的概念。我们的结果超越和涵盖了Ben-David等人（2009）的发现，并提供了直观的理解，通过一种新的减少到在线条件分布估计的概念。
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Polynomial-Chaos-Expansions"><a href="#Physics-Informed-Polynomial-Chaos-Expansions" class="headerlink" title="Physics-Informed Polynomial Chaos Expansions"></a>Physics-Informed Polynomial Chaos Expansions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01697">http://arxiv.org/abs/2309.01697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukáš Novák, Himanshu Sharma, Michael D. Shields<br>for: 本研究旨在构造physics-informed多项式泛化(PCE)，以推优化既有数据约束又有物理约束的泛化过程。methods: 本研究使用了一种新的方法，即将实验设计与模型物理约束相结合，以构造physics-informed PCE。这种方法通过利用物理约束来提高泛化精度，而不需要评估原始模型。results: 研究结果表明，提出的方法可以提高泛化精度，而且不加增计算负担。此外，通过对一些具有不同复杂性的决定性例子进行应用，还可以通过分析减少后的PCE滤波来进行不确定性评估。<details>
<summary>Abstract</summary>
Surrogate modeling of costly mathematical models representing physical systems is challenging since it is typically not possible to create a large experimental design. Thus, it is beneficial to constrain the approximation to adhere to the known physics of the model. This paper presents a novel methodology for the construction of physics-informed polynomial chaos expansions (PCE) that combines the conventional experimental design with additional constraints from the physics of the model. Physical constraints investigated in this paper are represented by a set of differential equations and specified boundary conditions. A computationally efficient means for construction of physically constrained PCE is proposed and compared to standard sparse PCE. It is shown that the proposed algorithms lead to superior accuracy of the approximation and does not add significant computational burden. Although the main purpose of the proposed method lies in combining data and physical constraints, we show that physically constrained PCEs can be constructed from differential equations and boundary conditions alone without requiring evaluations of the original model. We further show that the constrained PCEs can be easily applied for uncertainty quantification through analytical post-processing of a reduced PCE filtering out the influence of all deterministic space-time variables. Several deterministic examples of increasing complexity are provided and the proposed method is applied for uncertainty quantification.
</details>
<details>
<summary>摘要</summary>
实验设计较少的mathematical model预测physical system的成本高，因此实验设计是准确描述physical system的关键。这篇论文提出了一种新的方法，即physics-informed polynomial chaos expansions（PCE）的建构，融合实验设计和物理模型的条件。这些物理条件是通过 differential equations和specified boundary conditions表示的。提出了一种 computationally efficient的建构方法，并与标准的罕见PCE进行比较。结果显示，提案的方法可以提高 aproximation的精度，而且不会增加computational burden。虽然主要的目的是将data和物理条件融合，但我们显示可以从 differential equations和boundary conditions aloneconstruct physically constrained PCE，不需要评估原始模型。此外，我们还显示了 constrained PCE可以通过analytical post-processing的方式，范围内的所有决定性空间时间变量 filtering out。提供了一些 deterministic example of increasing complexity，并应用于uncertainty quantification。
</details></li>
</ul>
<hr>
<h2 id="Blind-Biological-Sequence-Denoising-with-Self-Supervised-Set-Learning"><a href="#Blind-Biological-Sequence-Denoising-with-Self-Supervised-Set-Learning" class="headerlink" title="Blind Biological Sequence Denoising with Self-Supervised Set Learning"></a>Blind Biological Sequence Denoising with Self-Supervised Set Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01670">http://arxiv.org/abs/2309.01670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Ng, Ji Won Park, Jae Hyeon Lee, Ryan Lewis Kelly, Stephen Ra, Kyunghyun Cho</li>
<li>for: 这个论文的目的是为了实现高通量DNA测序数据中的下游科学应用，特别是为了更好地清除Sequencing plataforms中的错误读取。</li>
<li>methods: 这个论文提出了一种新的自主学习方法，叫做Self-Supervised Set Learning (SSSL)，可以将多个受挤的序列读取到一个嵌入空间中，并且估算这些序列的集合嵌入。这个集合嵌入可以用来预测受挤的清洁序列。</li>
<li>results: 在实验中，SSSL方法可以较前一个基准下降17%的错误率，并且在实际数据中也有好的表现，尤其是在小序列上（小于6个受挤），可以大幅降低错误率。<details>
<summary>Abstract</summary>
Biological sequence analysis relies on the ability to denoise the imprecise output of sequencing platforms. We consider a common setting where a short sequence is read out repeatedly using a high-throughput long-read platform to generate multiple subreads, or noisy observations of the same sequence. Denoising these subreads with alignment-based approaches often fails when too few subreads are available or error rates are too high. In this paper, we propose a novel method for blindly denoising sets of sequences without directly observing clean source sequence labels. Our method, Self-Supervised Set Learning (SSSL), gathers subreads together in an embedding space and estimates a single set embedding as the midpoint of the subreads in both the latent and sequence spaces. This set embedding represents the "average" of the subreads and can be decoded into a prediction of the clean sequence. In experiments on simulated long-read DNA data, SSSL methods denoise small reads of $\leq 6$ subreads with 17% fewer errors and large reads of $>6$ subreads with 8% fewer errors compared to the best baseline. On a real dataset of antibody sequences, SSSL improves over baselines on two self-supervised metrics, with a significant improvement on difficult small reads that comprise over 60% of the test set. By accurately denoising these reads, SSSL promises to better realize the potential of high-throughput DNA sequencing data for downstream scientific applications.
</details>
<details>
<summary>摘要</summary>
生物序列分析需要去除测序平台输出的不精准数据。我们考虑一种常见的情况，在高通量长读平台上重复读取短序列，以生成多个噪声观测。对这些噪声观测进行对Alignment基于的去噪方法经常失败，当有太少的噪声观测或错误率太高时。在这篇论文中，我们提出了一种新的方法，即Self-Supervised Set Learning（SSSL）。这种方法将噪声观测集成到一个映射空间中，并估算这些噪声观测的集中点，作为latent空间和序列空间中的midpoint。这个集中点表示“平均”的噪声观测，可以被解码成一个clean序列预测。在对模拟长读DNA数据进行实验中，SSSL方法可以对小读数据（≤6个噪声观测）和大读数据（>6个噪声观测）进行去噪，相比best baseline，减少了17%和8%的错误。在一个真实的抗体序列数据集上，SSSL方法超过了基准值，尤其是在difficult小读中，这些小读占检测集的60%以上。通过准确地去噪这些小读，SSSL方法承诺可以更好地实现高通量DNA测序数据的下游科学应用。
</details></li>
</ul>
<hr>
<h2 id="Robust-penalized-least-squares-of-depth-trimmed-residuals-regression-for-high-dimensional-data"><a href="#Robust-penalized-least-squares-of-depth-trimmed-residuals-regression-for-high-dimensional-data" class="headerlink" title="Robust penalized least squares of depth trimmed residuals regression for high-dimensional data"></a>Robust penalized least squares of depth trimmed residuals regression for high-dimensional data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01666">http://arxiv.org/abs/2309.01666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijun Zuo</li>
<li>for: 本研究旨在探讨高维度数据分析中遇到的挑战，包括维度大于样本大小（i）和异常点或杂质点隐藏和更难检测（ii）。</li>
<li>methods: 本文使用了许多现代整合 penalty 方法来分析高维度数据，其中包括惩罚方法和深度trimmed residuals 方法。</li>
<li>results: 研究发现，大多数整合 penalty 方法在面对异常点或杂质点时会失效，而新提出的最小最小二乘法depth trimmed residuals方法可以更好地处理这些情况，并在实验中表现出较高的估计和预测精度。<details>
<summary>Abstract</summary>
Challenges with data in the big-data era include (i) the dimension $p$ is often larger than the sample size $n$ (ii) outliers or contaminated points are frequently hidden and more difficult to detect. Challenge (i) renders most conventional methods inapplicable. Thus, it attracts tremendous attention from statistics, computer science, and bio-medical communities. Numerous penalized regression methods have been introduced as modern methods for analyzing high-dimensional data. Disproportionate attention has been paid to the challenge (ii) though. Penalized regression methods can do their job very well and are expected to handle the challenge (ii) simultaneously. Most of them, however, can break down by a single outlier (or single adversary contaminated point) as revealed in this article.   The latter systematically examines leading penalized regression methods in the literature in terms of their robustness, provides quantitative assessment, and reveals that most of them can break down by a single outlier. Consequently, a novel robust penalized regression method based on the least sum of squares of depth trimmed residuals is proposed and studied carefully. Experiments with simulated and real data reveal that the newly proposed method can outperform some leading competitors in estimation and prediction accuracy in the cases considered.
</details>
<details>
<summary>摘要</summary>
大数据时代的数据分析挑战包括（i）维度pfrequently大于样本size n（ii）异常值或杂质点隐藏更难于探测。挑战（i）使得大多数传统方法无法应用。这引起了统计、计算机科学和生物医学领域的极大关注。许多惩罚回归方法被引入为现代高维数据分析的方法。虽然挑战（ii）得到了过度的关注，但是惩罚回归方法可以很好地处理它。然而，大多数方法都可以被单个异常值（或单个杂质点）所破坏，这在本文中得到了证明。为了解决这个问题，一种基于深度剔除差异的最小二乘方法被提出并且仔细研究了。实验表明，新提出的方法在预测和估计精度方面在考虑的情况下能够超越一些竞争对手。
</details></li>
</ul>
<hr>
<h2 id="Locally-Stationary-Graph-Processes"><a href="#Locally-Stationary-Graph-Processes" class="headerlink" title="Locally Stationary Graph Processes"></a>Locally Stationary Graph Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01657">http://arxiv.org/abs/2309.01657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdullah Canbolat, Elif Vural</li>
<li>for: 本文旨在提出一种基于不规则网络结构的局部站立图像处理方法，以满足实际问题中的局部特点变化。</li>
<li>methods: 本文提出了一种基于组件过程的局部站立图像模型（LSGP），通过表示过程的总体为多个组件过程的组合，来表示图像在不同区域的局部站立性。提出了一种计算LSGP模型的算法，以及本地使用WSS过程的近似方法。</li>
<li>results: 实验表明，提出的过程模型可以与现有技术竞争，并且在信号 interpolating 问题中提供了高精度的信号表示。<details>
<summary>Abstract</summary>
Stationary graph process models are commonly used in the analysis and inference of data sets collected on irregular network topologies. While most of the existing methods represent graph signals with a single stationary process model that is globally valid on the entire graph, in many practical problems, the characteristics of the process may be subject to local variations in different regions of the graph. In this work, we propose a locally stationary graph process (LSGP) model that aims to extend the classical concept of local stationarity to irregular graph domains. We characterize local stationarity by expressing the overall process as the combination of a set of component processes such that the extent to which the process adheres to each component varies smoothly over the graph. We propose an algorithm for computing LSGP models from realizations of the process, and also study the approximation of LSGPs locally with WSS processes. Experiments on signal interpolation problems show that the proposed process model provides accurate signal representations competitive with the state of the art.
</details>
<details>
<summary>摘要</summary>
stationary graph process models 常用于非 régulière 网络 topology 上的数据集分析和推理。大多数现有方法使用 globally 有效的站ARY graph signal 模型来表示整个图的信号，但在实际问题中，过程的特性可能会在不同地方的图中具有本地差异。在这种情况下，我们提出了一种 Locally Stationary Graph Process (LSGP) 模型，旨在扩展传统的本地站ARY性概念到不规则图域。我们通过表示过程的总体作为不同地方的组件过程的组合来 caracterize 本地站ARY性。我们还提出了一种计算 LSGP 模型的算法，以及对 LSGP 模型进行本地approximation的 WSS 过程的研究。实验表明，提出的过程模型可以与当前状态齐的精度地表示信号。
</details></li>
</ul>
<hr>
<h2 id="Representing-Edge-Flows-on-Graphs-via-Sparse-Cell-Complexes"><a href="#Representing-Edge-Flows-on-Graphs-via-Sparse-Cell-Complexes" class="headerlink" title="Representing Edge Flows on Graphs via Sparse Cell Complexes"></a>Representing Edge Flows on Graphs via Sparse Cell Complexes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01632">http://arxiv.org/abs/2309.01632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Hoppe, Michael T. Schaub</li>
<li>for: 获取对数据的稀疏、可解释性表示是机器学习和信号处理任务中的关键。</li>
<li>methods: 将图结构提升到 simplicial complex 中，然后使用 Hodge-Laplacian 的特征值和相应的 incidence matrix 来实现 Hodge 分解，从而将观察数据表示为梯度、旋转和响应流。</li>
<li>results: 在实际数据和 sintetic 数据上，我们的算法可以高效地解决 cell inference 优化问题，并且比现有的方法更高效。<details>
<summary>Abstract</summary>
Obtaining sparse, interpretable representations of observable data is crucial in many machine learning and signal processing tasks. For data representing flows along the edges of a graph, an intuitively interpretable way to obtain such representations is to lift the graph structure to a simplicial complex: The eigenvectors of the associated Hodge-Laplacian, respectively the incidence matrices of the corresponding simplicial complex then induce a Hodge decomposition, which can be used to represent the observed data in terms of gradient, curl, and harmonic flows. In this paper, we generalize this approach to cellular complexes and introduce the cell inference optimization problem, i.e., the problem of augmenting the observed graph by a set of cells, such that the eigenvectors of the associated Hodge Laplacian provide a sparse, interpretable representation of the observed edge flows on the graph. We show that this problem is NP-hard and introduce an efficient approximation algorithm for its solution. Experiments on real-world and synthetic data demonstrate that our algorithm outperforms current state-of-the-art methods while being computationally efficient.
</details>
<details>
<summary>摘要</summary>
获取稀疏、可解释的数据表示是许多机器学习和信号处理任务中的关键。为了在图structure上获取这些表示，一种直观可解的方法是将图结构升级到 simplicial complex：图结构的特征值和相应的 simplicial complex 的 incidence matrix  THEN INDUCE A Hodge decomposition, 可以用来表示观察到的边流在图上。在这篇论文中，我们扩展了这种方法到细胞复杂体系，并引入细胞推理优化问题，即在观察到的图上添加一组细胞，以便将 graph 的特征值和 incidence matrix 转化为稀疏、可解释的表示。我们证明了这个问题是NP困难的，并提出了一种有效的近似算法来解决它。实验表明，我们的算法在实际数据和synthetic数据上都能够超越当前状态的方法，而且 Computationally efficient。
</details></li>
</ul>
<hr>
<h2 id="Dropout-Attacks"><a href="#Dropout-Attacks" class="headerlink" title="Dropout Attacks"></a>Dropout Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01614">http://arxiv.org/abs/2309.01614</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngunnar/Robustness_tutorial">https://github.com/ngunnar/Robustness_tutorial</a></li>
<li>paper_authors: Andrew Yuan, Alina Oprea, Cheng Tan</li>
<li>for: 本研究旨在攻击深度学习模型中的Dropout操作，以防止过拟合。</li>
<li>methods: 本文引入了一种新的Dropout攻击方法，称为DROPOUTATTACK，通过 manipulate dropout operator 中选择的 neuron 而不是随机选择。</li>
<li>results: 在训练 VGG-16 模型在 CIFAR-100 上，我们的攻击可以将受到攻击的级别降低至 34.6% (从 81.7% 降至 47.1%)，而无需对模型精度做出任何干扰。<details>
<summary>Abstract</summary>
Dropout is a common operator in deep learning, aiming to prevent overfitting by randomly dropping neurons during training. This paper introduces a new family of poisoning attacks against neural networks named DROPOUTATTACK. DROPOUTATTACK attacks the dropout operator by manipulating the selection of neurons to drop instead of selecting them uniformly at random. We design, implement, and evaluate four DROPOUTATTACK variants that cover a broad range of scenarios. These attacks can slow or stop training, destroy prediction accuracy of target classes, and sabotage either precision or recall of a target class. In our experiments of training a VGG-16 model on CIFAR-100, our attack can reduce the precision of the victim class by 34.6% (from 81.7% to 47.1%) without incurring any degradation in model accuracy
</details>
<details>
<summary>摘要</summary>
Dropout 是深度学习中常用的操作，目的是防止适应性过度 Training 中的 neuron 被随机Dropout 操作。这篇论文介绍了一种新的毒素攻击 named DROPOUTATTACK，该攻击targets  dropout 操作，而不是随机选择 neuron。我们设计了四种 DROPOUTATTACK 变种，覆盖了广泛的场景。这些攻击可以降低目标类准确率，甚至使模型训练失败。在我们对 VGG-16 模型在 CIFAR-100 上训练的实验中，我们的攻击可以降低目标类准确率 by 34.6%（从 81.7% 降至 47.1%），而无需模型精度下降。
</details></li>
</ul>
<hr>
<h2 id="Fair-Ranking-under-Disparate-Uncertainty"><a href="#Fair-Ranking-under-Disparate-Uncertainty" class="headerlink" title="Fair Ranking under Disparate Uncertainty"></a>Fair Ranking under Disparate Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01610">http://arxiv.org/abs/2309.01610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richa Rastogi, Thorsten Joachims</li>
<li>for: 提高排序系统的公平性，即使数据量不均衡时仍能保证各个群体的排名公平。</li>
<li>methods: 提出Equal-Opportunity Ranking（EOR）作为公平排序标准，并实现了一种可行的算法来实现EOR排名，时间复杂度为O(n * log(n))。</li>
<li>results: 经过synthetic数据、美国人口普查数据和Amazon搜索关键词数据的实验表明，该算法可靠地保证EOR公平性，同时提供有效的排名。<details>
<summary>Abstract</summary>
Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use ranges from surfacing potentially relevant products on an e-commerce site to prioritizing college applications for human review. While ranking can make human evaluation far more effective by focusing attention on the most promising options, we argue that it can introduce unfairness if the uncertainty of the underlying relevance model differs between groups of options. Unfortunately, such disparity in uncertainty appears widespread, since the relevance estimates for minority groups tend to have higher uncertainty due to a lack of data or appropriate features. To overcome this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking that provably corrects for the disparity in uncertainty between groups. Furthermore, we present a practical algorithm for computing EOR rankings in time $O(n \log(n))$ and prove its close approximation guarantee to the globally optimal solution. In a comprehensive empirical evaluation on synthetic data, a US Census dataset, and a real-world case study of Amazon search queries, we find that the algorithm reliably guarantees EOR fairness while providing effective rankings.
</details>
<details>
<summary>摘要</summary>
“排名是一种普遍存在的方法，用于集中人类评估者的注意力于可管理的子集中。它的应用范围从电子商务网站上浮出潜在有用的产品到审核大学申请。尽管排名可以使人类评估变得非常有效，但它可能引入不公正性，因为不同群体选项的后台相关性模型的不确定性差异较大。实际上，这种差异在少数群体选项中的相关性估计通常更高，因为这些选项的数据或特征不够。为解决这个公正性问题，我们提出了平等机会排名（EOR）作为一种新的公正性标准，可以正确地纠正不同群体选项之间的不确定性差异。此外，我们提出了一种实用的算法来计算EOR排名，时间复杂度为O(nlog(n))，并证明其与全球最佳解决方案的快近优化 garantia。在synthetic数据、US Census数据和amazon搜索查询的实际评估中，我们发现了这种算法可靠地保证EOR公正性，同时提供有效的排名。”
</details></li>
</ul>
<hr>
<h2 id="Drifter-Efficient-Online-Feature-Monitoring-for-Improved-Data-Integrity-in-Large-Scale-Recommendation-Systems"><a href="#Drifter-Efficient-Online-Feature-Monitoring-for-Improved-Data-Integrity-in-Large-Scale-Recommendation-Systems" class="headerlink" title="Drifter: Efficient Online Feature Monitoring for Improved Data Integrity in Large-Scale Recommendation Systems"></a>Drifter: Efficient Online Feature Monitoring for Improved Data Integrity in Large-Scale Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08617">http://arxiv.org/abs/2309.08617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Blaž Škrlj, Nir Ki-Tov, Lee Edelist, Natalia Silberstein, Hila Weisman-Zohar, Blaž Mramor, Davorin Kopič, Naama Ziporin</li>
<li>for: 这个论文是为了解决大规模、动态流中数据质量维护问题。</li>
<li>methods: 这个系统使用了新的在线特征监测和验证技术，以提供快速、有效、适应性强的数据质量监测，并能够实时检测数据质量问题的根本原因。</li>
<li>results: 对实际数据集进行评估，这个系统能够有效地发送警示并解决数据质量问题，提高了实时live推荐系统的可靠性和性能。<details>
<summary>Abstract</summary>
Real-world production systems often grapple with maintaining data quality in large-scale, dynamic streams. We introduce Drifter, an efficient and lightweight system for online feature monitoring and verification in recommendation use cases. Drifter addresses limitations of existing methods by delivering agile, responsive, and adaptable data quality monitoring, enabling real-time root cause analysis, drift detection and insights into problematic production events. Integrating state-of-the-art online feature ranking for sparse data and anomaly detection ideas, Drifter is highly scalable and resource-efficient, requiring only two threads and less than a gigabyte of RAM per production deployments that handle millions of instances per minute. Evaluation on real-world data sets demonstrates Drifter's effectiveness in alerting and mitigating data quality issues, substantially improving reliability and performance of real-time live recommender systems.
</details>
<details>
<summary>摘要</summary>
现实生产环境中， oftentimes 面临着大规模、动态流中数据质量维护的挑战。我们介绍了 Drifter，一种高效、轻量级的在线特征监测和验证系统，用于推荐使用情况下的数据质量监测。 Drifter 超越了现有方法的局限性，提供了快速、敏感、适应性的数据质量监测，允许实时根本原因分析、漂移检测和问题生成的生产事件中的深入洞察。 Drifter  integrate 最新的在线特征排名技术和罕见检测思想，可扩展性强，只需两个线程和 less than 一 gigabyte 的内存，可执行 millions 个实例每分钟的生产部署。 评估实际数据集表明， Drifter 可以有效地预警和解决数据质量问题，substantially 提高实时live 推荐系统的可靠性和性能。
</details></li>
</ul>
<hr>
<h2 id="Active-flow-control-for-three-dimensional-cylinders-through-deep-reinforcement-learning"><a href="#Active-flow-control-for-three-dimensional-cylinders-through-deep-reinforcement-learning" class="headerlink" title="Active flow control for three-dimensional cylinders through deep reinforcement learning"></a>Active flow control for three-dimensional cylinders through deep reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02462">http://arxiv.org/abs/2309.02462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pol Suárez, Francisco Alcántara-Ávila, Arnau Miró, Jean Rabault, Bernat Font, Oriol Lehmkuhl, R. Vinuesa</li>
<li>for: 降低缩扰系数（drag coefficient）</li>
<li>methods: 多个独立控制的零负质流体推进器（synthetic jets），基于深度学习托管的液体动力学解算器，以及一个使用质量优化算法的代理人</li>
<li>results: 在三种不同的问题配置中，实现了显著的缩扰减少<details>
<summary>Abstract</summary>
This paper presents for the first time successful results of active flow control with multiple independently controlled zero-net-mass-flux synthetic jets. The jets are placed on a three-dimensional cylinder along its span with the aim of reducing the drag coefficient. The method is based on a deep-reinforcement-learning framework that couples a computational-fluid-dynamics solver with an agent using the proximal-policy-optimization algorithm. We implement a multi-agent reinforcement-learning framework which offers numerous advantages: it exploits local invariants, makes the control adaptable to different geometries, facilitates transfer learning and cross-application of agents and results in significant training speedup. In this contribution we report significant drag reduction after applying the DRL-based control in three different configurations of the problem.
</details>
<details>
<summary>摘要</summary>
We implement a multi-agent reinforcement-learning framework, which has several advantages:1. It exploits local invariants, making the control adaptable to different geometries.2. It facilitates transfer learning and cross-application of agents.3. It results in significant training speedup.In this contribution, we report significant drag reduction after applying the DRL-based control in three different configurations of the problem.
</details></li>
</ul>
<hr>
<h2 id="Passing-Heatmap-Prediction-Based-on-Transformer-Model-and-Tracking-Data"><a href="#Passing-Heatmap-Prediction-Based-on-Transformer-Model-and-Tracking-Data" class="headerlink" title="Passing Heatmap Prediction Based on Transformer Model and Tracking Data"></a>Passing Heatmap Prediction Based on Transformer Model and Tracking Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01526">http://arxiv.org/abs/2309.01526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yisheng Pei, Varuna De Silva, Mike Caine</li>
<li>For: 这个研究旨在提供一种能够预测传球的可能性和传球前运动影响最终结果的深度学习网络架构，以更正查评球员的表现。* Methods: 该研究使用了深度学习网络模型，分析了超过28,000个传球事件，并达到了0.7以上的顶部一级准确率。* Results: 该研究表明，通过分析球员的运动动作，可以更好地理解球场控制和传球选择对防御性表现的影响，并为足球分析师提供一个更好的工具和指标来评估球员的运动贡献。<details>
<summary>Abstract</summary>
Although the data-driven analysis of football players' performance has been developed for years, most research only focuses on the on-ball event including shots and passes, while the off-ball movement remains a little-explored area in this domain. Players' contributions to the whole match are evaluated unfairly, those who have more chances to score goals earn more credit than others, while the indirect and unnoticeable impact that comes from continuous movement has been ignored. This research presents a novel deep-learning network architecture which is capable to predict the potential end location of passes and how players' movement before the pass affects the final outcome. Once analysed more than 28,000 pass events, a robust prediction can be achieved with more than 0.7 Top-1 accuracy. And based on the prediction, a better understanding of the pitch control and pass option could be reached to measure players' off-ball movement contribution to defensive performance. Moreover, this model could provide football analysts a better tool and metric to understand how players' movement over time contributes to the game strategy and final victory.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Blackbox-Model-Is-All-You-Need-to-Breach-Privacy-Smart-Grid-Forecasting-Models-as-a-Use-Case"><a href="#A-Blackbox-Model-Is-All-You-Need-to-Breach-Privacy-Smart-Grid-Forecasting-Models-as-a-Use-Case" class="headerlink" title="A Blackbox Model Is All You Need to Breach Privacy: Smart Grid Forecasting Models as a Use Case"></a>A Blackbox Model Is All You Need to Breach Privacy: Smart Grid Forecasting Models as a Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01523">http://arxiv.org/abs/2309.01523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hussein Aly, Abdulaziz Al-Ali, Abdullah Al-Ali, Qutaibah Malluhi</li>
<li>for: 这篇论文研究了智能电网中预测模型的隐私风险，尤其是深度学习和预测模型在智能电网中的应用。</li>
<li>methods: 本研究使用了深度学习和预测模型，包括长期快速响应神经网络 (LSTM)，分析了预测模型是否泄露敏感信息的风险。</li>
<li>results: 研究发现，使用预测模型可以泄露智能电网系统中的全局性和隐私威胁，特别是通过黑盒访问LSTM模型可以泄露大量信息，与数据直接访问的情况相似（差异在1%以下，在ROC曲线下的面积）。这说明需要对预测模型进行保护，与数据一样重要。<details>
<summary>Abstract</summary>
This paper investigates the potential privacy risks associated with forecasting models, with specific emphasis on their application in the context of smart grids. While machine learning and deep learning algorithms offer valuable utility, concerns arise regarding their exposure of sensitive information. Previous studies have focused on classification models, overlooking risks associated with forecasting models. Deep learning based forecasting models, such as Long Short Term Memory (LSTM), play a crucial role in several applications including optimizing smart grid systems but also introduce privacy risks. Our study analyzes the ability of forecasting models to leak global properties and privacy threats in smart grid systems. We demonstrate that a black box access to an LSTM model can reveal a significant amount of information equivalent to having access to the data itself (with the difference being as low as 1% in Area Under the ROC Curve). This highlights the importance of protecting forecasting models at the same level as the data.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "smart grids" is translated as "智能电网" (zìnéng diànwǎng)* "forecasting models" is translated as "预测模型" (yùzhèng módelǐ)* "machine learning" is translated as "机器学习" (jīshì xuéxí)* "deep learning" is translated as "深度学习" (shēngrù xuéxí)* "Long Short Term Memory" is translated as "长期短 память" (chángzhì duǎnjiàng)* "black box access" is translated as "黑盒访问" (hēi bāo fāngwù)* "privacy risks" is translated as "隐私风险" (yìnwèi fēngxì)
</details></li>
</ul>
<hr>
<h2 id="Hawkeye-Change-targeted-Testing-for-Android-Apps-based-on-Deep-Reinforcement-Learning"><a href="#Hawkeye-Change-targeted-Testing-for-Android-Apps-based-on-Deep-Reinforcement-Learning" class="headerlink" title="Hawkeye: Change-targeted Testing for Android Apps based on Deep Reinforcement Learning"></a>Hawkeye: Change-targeted Testing for Android Apps based on Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01519">http://arxiv.org/abs/2309.01519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Peng, Zhengwei Lv, Jiarong Fu, Jiayuan Liang, Zhao Zhang, Ajitha Rajan, Ping Yang</li>
<li>for: 本研究的目的是提高Android应用程序更新的正确性，以避免在用户端出现漏洞。</li>
<li>methods: 本研究提出了一种指导测试方法，使用深度强化学习来优先执行更新后影响的GUI操作。</li>
<li>results: 对于10个开源App和1个商业App，研究发现，使用 Hawkeye 可以更可靠地生成targeting更改的GUI事件序列，比 FastBot2 和 ARES 更高效。 Hawkeye 在小型开源App上表现相当，但在大型商业App上表现较低。在实际生产环境中，Hawkeye 也能够成功地进行烟测测试。<details>
<summary>Abstract</summary>
Android Apps are frequently updated to keep up with changing user, hardware, and business demands. Ensuring the correctness of App updates through extensive testing is crucial to avoid potential bugs reaching the end user. Existing Android testing tools generate GUI events focussing on improving the test coverage of the entire App rather than prioritising updates and its impacted elements. Recent research has proposed change-focused testing but relies on random exploration to exercise the updates and impacted GUI elements that is ineffective and slow for large complex Apps with a huge input exploration space. We propose directed testing of App updates with Hawkeye that is able to prioritise executing GUI actions associated with code changes based on deep reinforcement learning from historical exploration data. Our empirical evaluation compares Hawkeye with state-of-the-art model-based and reinforcement learning-based testing tools FastBot2 and ARES using 10 popular open-source and 1 commercial App. We find that Hawkeye is able to generate GUI event sequences targeting changed functions more reliably than FastBot2 and ARES for the open source Apps and the large commercial App. Hawkeye achieves comparable performance on smaller open source Apps with a more tractable exploration space. The industrial deployment of Hawkeye in the development pipeline also shows that Hawkeye is ideal to perform smoke testing for merge requests of a complicated commercial App.
</details>
<details>
<summary>摘要</summary>
我们提出了directed testing of App updates with Hawkeye，它可以根据深度学习历史探索数据来优先执行更改后的GUI操作。我们的实验比较了Hawkeye与当前最佳的模型基于和学习基于的测试工具FastBot2和ARES，使用10个流行的开源App和1个商业App。我们发现Hawkeye可以更可靠地对更改后的函数生成GUI事件序列，比FastBot2和ARES更高效。 Hawkeye在小型开源App上也有类似的性能，而且在商业App的开发pipeline中的实际部署中也显示了Hawkeye的适用性。 Hawkeye可以快速完成 merge requests 的烟测，为复杂的商业App提供了一个 идеal testing solution。
</details></li>
</ul>
<hr>
<h2 id="Federated-cINN-Clustering-for-Accurate-Clustered-Federated-Learning"><a href="#Federated-cINN-Clustering-for-Accurate-Clustered-Federated-Learning" class="headerlink" title="Federated cINN Clustering for Accurate Clustered Federated Learning"></a>Federated cINN Clustering for Accurate Clustered Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01515">http://arxiv.org/abs/2309.01515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Zhou, Minjia Shi, Yuxin Tian, Yuanxi Li, Qing Ye, Jiancheng Lv</li>
<li>For: 本研究旨在 Addressing the challenge of coordinating Federated Learning (FL) with crowd intelligence, particularly when client groups have disparate objectives due to data heterogeneity or distinct tasks.* Methods: 提议了一种 Federated cINN Clustering Algorithm (FCCA)，通过对每个客户端的私有数据进行全局编码，并使用生成模型进行最大可能性估计，以避免模式折射和优化难度。* Results: 对多种模型和数据集进行了广泛的实验，并证明了 FCCA 的超越性，比如其能够更好地减少客户端之间的干扰和提高全局模型的准确率。<details>
<summary>Abstract</summary>
Federated Learning (FL) presents an innovative approach to privacy-preserving distributed machine learning and enables efficient crowd intelligence on a large scale. However, a significant challenge arises when coordinating FL with crowd intelligence which diverse client groups possess disparate objectives due to data heterogeneity or distinct tasks. To address this challenge, we propose the Federated cINN Clustering Algorithm (FCCA) to robustly cluster clients into different groups, avoiding mutual interference between clients with data heterogeneity, and thereby enhancing the performance of the global model. Specifically, FCCA utilizes a global encoder to transform each client's private data into multivariate Gaussian distributions. It then employs a generative model to learn encoded latent features through maximum likelihood estimation, which eases optimization and avoids mode collapse. Finally, the central server collects converged local models to approximate similarities between clients and thus partition them into distinct clusters. Extensive experimental results demonstrate FCCA's superiority over other state-of-the-art clustered federated learning algorithms, evaluated on various models and datasets. These results suggest that our approach has substantial potential to enhance the efficiency and accuracy of real-world federated learning tasks.
</details>
<details>
<summary>摘要</summary>
《联邦学习（FL）》提出了一种创新的隐私保护分布式机器学习方法，可以实现大规模的群体智能。然而，在与群体智能协调FL时， Client groups possessing diverse objectives due to data heterogeneity or distinct tasks poses a significant challenge. To address this challenge, we propose the Federated cINN Clustering Algorithm (FCCA) to robustly cluster clients into different groups, avoiding mutual interference between clients with data heterogeneity, and thereby enhancing the performance of the global model. Specifically, FCCA utilizes a global encoder to transform each client's private data into multivariate Gaussian distributions. It then employs a generative model to learn encoded latent features through maximum likelihood estimation, which eases optimization and avoids mode collapse. Finally, the central server collects converged local models to approximate similarities between clients and thus partition them into distinct clusters. Extensive experimental results demonstrate FCCA's superiority over other state-of-the-art clustered federated learning algorithms, evaluated on various models and datasets. These results suggest that our approach has substantial potential to enhance the efficiency and accuracy of real-world federated learning tasks.
</details></li>
</ul>
<hr>
<h2 id="Layer-wise-training-for-self-supervised-learning-on-graphs"><a href="#Layer-wise-training-for-self-supervised-learning-on-graphs" class="headerlink" title="Layer-wise training for self-supervised learning on graphs"></a>Layer-wise training for self-supervised learning on graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01503">http://arxiv.org/abs/2309.01503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oscar Pina, Verónica Vilaplana</li>
<li>for: 训练大 graphs上的端到端图 neural networks (GNN) 存在多种内存和计算挑战，限制了深度的应用，因为深度会导致内存和空间复杂度的剧烈增长。</li>
<li>methods: 我们提出了层 wise Regularized Graph Infomax算法，通过自我超vised的方式来训练 GNN 层次。我们将 GNN 中的特征传播和特征变换分解出来，以学习节点表示，并从未来输入预测的基础上 derivate 一个损失函数。</li>
<li>results: 我们在 inductive 大 graphs 中评估了我们的算法，与其他端到端方法相当，并且显著提高了效率，可以在一个单个设备上训练更加复杂的模型。此外，我们的算法还可以避免深度 GNN 中的抖搅现象。<details>
<summary>Abstract</summary>
End-to-end training of graph neural networks (GNN) on large graphs presents several memory and computational challenges, and limits the application to shallow architectures as depth exponentially increases the memory and space complexities. In this manuscript, we propose Layer-wise Regularized Graph Infomax, an algorithm to train GNNs layer by layer in a self-supervised manner. We decouple the feature propagation and feature transformation carried out by GNNs to learn node representations in order to derive a loss function based on the prediction of future inputs. We evaluate the algorithm in inductive large graphs and show similar performance to other end to end methods and a substantially increased efficiency, which enables the training of more sophisticated models in one single device. We also show that our algorithm avoids the oversmoothing of the representations, another common challenge of deep GNNs.
</details>
<details>
<summary>摘要</summary>
大型图格神经网络（GNN）的端到端训练存在许多内存和计算挑战，深度随着增加而 exponentially 增加内存和空间复杂性。在这篇论文中，我们提出层wise Regularized Graph Infomax算法，用于层段式自我监督的GNN训练。我们将GNN中的特征传播和特征转换分解开来，以学习节点表示，并从未来输入预测得出损失函数。我们在大型 inductive 图上评估了算法，并与其他端到端方法相当，同时有substantially 提高效率，这使得可以在一个设备上训练更复杂的模型。此外，我们还证明了我们的算法可以避免深度GNN的过滤 representations。
</details></li>
</ul>
<hr>
<h2 id="FinDiff-Diffusion-Models-for-Financial-Tabular-Data-Generation"><a href="#FinDiff-Diffusion-Models-for-Financial-Tabular-Data-Generation" class="headerlink" title="FinDiff: Diffusion Models for Financial Tabular Data Generation"></a>FinDiff: Diffusion Models for Financial Tabular Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01472">http://arxiv.org/abs/2309.01472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timur Sattarov, Marco Schreyer, Damian Borth</li>
<li>for: 这个论文的目的是为了生成真实世界金融数据表格，以便于经济enario模型、压力测试和诈骗探测等下游任务。</li>
<li>methods: 这篇论文使用了扩散模型，特别是噪声扩散模型，来生成模拟真实数据的数据。它使用嵌入编码来处理金融数据的混合类型特征，包括分类和数值特征。</li>
<li>results: 实验结果表明，FinDiff可以生成高准确性、隐私和实用性的 sintetic tabular financial data。与现有基线模型进行比较，FinDiff在三个真实世界金融数据集上表现出色。<details>
<summary>Abstract</summary>
The sharing of microdata, such as fund holdings and derivative instruments, by regulatory institutions presents a unique challenge due to strict data confidentiality and privacy regulations. These challenges often hinder the ability of both academics and practitioners to conduct collaborative research effectively. The emergence of generative models, particularly diffusion models, capable of synthesizing data mimicking the underlying distributions of real-world data presents a compelling solution. This work introduces 'FinDiff', a diffusion model designed to generate real-world financial tabular data for a variety of regulatory downstream tasks, for example economic scenario modeling, stress tests, and fraud detection. The model uses embedding encodings to model mixed modality financial data, comprising both categorical and numeric attributes. The performance of FinDiff in generating synthetic tabular financial data is evaluated against state-of-the-art baseline models using three real-world financial datasets (including two publicly available datasets and one proprietary dataset). Empirical results demonstrate that FinDiff excels in generating synthetic tabular financial data with high fidelity, privacy, and utility.
</details>
<details>
<summary>摘要</summary>
共享微数据，如基金投资和 derivate 工具，由 regulatory 机构提供的存在着独特的挑战，主要是由于严格的数据保密和隐私法规。这些挑战通常会阻碍学者和实践者进行有效的合作研究。随着生成模型的出现，特别是扩散模型，可以Synthesize 数据，模拟实际世界数据的下面分布。本文介绍了 'FinDiff'，一种扩散模型，用于生成实际世界金融表格数据，用于经济enario模拟、压力测试和欺诈探测等下游任务。FinDiff 使用 embedding 编码来模型金融数据的混合模式，包括 both categorical 和 numeric 特征。FinDiff 在生成 synthetic 金融表格数据方面的性能被评估于现有的基eline 模型，使用三个实际世界金融数据集（包括两个公共可用数据集和一个专有数据集）。实际结果表明，FinDiff 可以高效地生成 synthetic 金融表格数据，具有高准确性、隐私和实用性。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Reward-Consistency-for-Interpretable-Feature-Discovery-in-Reinforcement-Learning"><a href="#Leveraging-Reward-Consistency-for-Interpretable-Feature-Discovery-in-Reinforcement-Learning" class="headerlink" title="Leveraging Reward Consistency for Interpretable Feature Discovery in Reinforcement Learning"></a>Leveraging Reward Consistency for Interpretable Feature Discovery in Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01458">http://arxiv.org/abs/2309.01458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qisen Yang, Huanqian Wang, Mukun Tong, Wenjie Shi, Gao Huang, Shiji Song</li>
<li>for: 解释和解释深度强化学习（RL）Agent的行为</li>
<li>methods: 提出了一种新的框架（RL-in-RL），通过解决动作和奖励之间的连接问题，来保证奖励一致性 during interpretable feature发现</li>
<li>results: 在Atari 2600游戏和Duckietown自驾车 simulator环境中测试和评估了该方法，结果表明方法可以保持奖励一致性，并实现高质量的特征归属。进一步的分析实验也 validate了动作匹配原则的局限性。<details>
<summary>Abstract</summary>
The black-box nature of deep reinforcement learning (RL) hinders them from real-world applications. Therefore, interpreting and explaining RL agents have been active research topics in recent years. Existing methods for post-hoc explanations usually adopt the action matching principle to enable an easy understanding of vision-based RL agents. In this paper, it is argued that the commonly used action matching principle is more like an explanation of deep neural networks (DNNs) than the interpretation of RL agents. It may lead to irrelevant or misplaced feature attribution when different DNNs' outputs lead to the same rewards or different rewards result from the same outputs. Therefore, we propose to consider rewards, the essential objective of RL agents, as the essential objective of interpreting RL agents as well. To ensure reward consistency during interpretable feature discovery, a novel framework (RL interpreting RL, denoted as RL-in-RL) is proposed to solve the gradient disconnection from actions to rewards. We verify and evaluate our method on the Atari 2600 games as well as Duckietown, a challenging self-driving car simulator environment. The results show that our method manages to keep reward (or return) consistency and achieves high-quality feature attribution. Further, a series of analytical experiments validate our assumption of the action matching principle's limitations.
</details>
<details>
<summary>摘要</summary>
深度强化学习（RL）的黑盒特性使其在实际应用中受到限制。因此，解释和解释RL代理的研究在最近几年得到了广泛的关注。现有的后续解释方法通常采用行动匹配原理，以便轻松理解视觉RL代理。然而，这篇论文 argue互联网的行动匹配原理更多地是深度神经网络（DNN）的解释，而不是RL代理的解释。这可能会导致不相关或错位的特征归因，因为不同的DNN输出可能导致同一个奖励，或者不同的奖励可能来自同一个输出。因此，我们建议将奖励作为RL代理的解释的关键目标，以确保解释过程中的奖励一致性。为保证解释过程中的奖励一致性，我们提出了一种RL解释RL的框架（denoted as RL-in-RL），解决了动作和奖励之间的梯度分离问题。我们在Atari 2600游戏和DUCKIETOWN自驾车模拟环境中进行了证明和评估。结果表明，我们的方法能够保持奖励一致性，并实现高质量的特征归因。此外，一系列的分析实验 validate了我们对行动匹配原理的假设的局限性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Consistency-and-Robustness-of-Saliency-Explanations-for-Time-Series-Classification"><a href="#On-the-Consistency-and-Robustness-of-Saliency-Explanations-for-Time-Series-Classification" class="headerlink" title="On the Consistency and Robustness of Saliency Explanations for Time Series Classification"></a>On the Consistency and Robustness of Saliency Explanations for Time Series Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01457">http://arxiv.org/abs/2309.01457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chiara Balestra, Bin Li, Emmanuel Müller</li>
<li>for: 这 paper aims to analyze the consistency and robustness of saliency maps for time series features and temporal attribution in a time series classification task.</li>
<li>methods: 该 paper uses perturbation-based and gradient-based explanation models to generate saliency explanations, and examines their consistency and robustness on five real-world datasets.</li>
<li>results: The experimental results show that the saliency explanations from both models lack consistent and robust performances to some extent, highlighting the need for developing more reliable explanation methods for time series classification.<details>
<summary>Abstract</summary>
Interpretable machine learning and explainable artificial intelligence have become essential in many applications. The trade-off between interpretability and model performance is the traitor to developing intrinsic and model-agnostic interpretation methods. Although model explanation approaches have achieved significant success in vision and natural language domains, explaining time series remains challenging. The complex pattern in the feature domain, coupled with the additional temporal dimension, hinders efficient interpretation. Saliency maps have been applied to interpret time series windows as images. However, they are not naturally designed for sequential data, thus suffering various issues.   This paper extensively analyzes the consistency and robustness of saliency maps for time series features and temporal attribution. Specifically, we examine saliency explanations from both perturbation-based and gradient-based explanation models in a time series classification task. Our experimental results on five real-world datasets show that they all lack consistent and robust performances to some extent. By drawing attention to the flawed saliency explanation models, we motivate to develop consistent and robust explanations for time series classification.
</details>
<details>
<summary>摘要</summary>
<div><p> interpreter 机器学习和解释人工智能在许多应用中变得必需。模型性能和可解释性的交易是发展内置和模型无关的解释方法的障碍。虽然模型解释方法在视觉和自然语言领域得到了显著成功，但是解释时序序列仍然是挑战。时序序列特征空间复杂，加上额外的时间维度，使得有效的解释受到阻碍。</p><p>Saliency maps 已经应用于解释时序序列窗口，但它们不是特定适用于顺序数据，因此受到各种问题的担忧。本文进行了严格的分析和对比，发现这些解释模型在时序序列分类任务中缺乏一致性和可靠性。我们在五个真实的实际数据集上进行了实验，结果表明它们都缺乏一定程度的一致性和可靠性。我们通过吸引注意力于缺陷的解释模型，激励开发一致和可靠的解释方法 для时序序列分类。</p><p>针对这些问题，我们提出了一种新的解释方法，即基于窗口的时序序列解释方法。这种方法可以快速地生成可解释的时序序列特征，并且可以减少对解释模型的依赖性。我们在实验中证明了这种方法的有效性和可靠性。</p><p>总之，我们的研究表明，为了解释时序序列分类模型的决策，需要开发一致和可靠的解释方法。我们的新的解释方法可以帮助解决这一问题，并且可以应用于实际的应用场景。</p></div>Note: Some of the words and phrases in the text may not be exactly the same as their Simplified Chinese translations, but they should be close enough to be understood.
</details></li>
</ul>
<hr>
<h2 id="Hundreds-Guide-Millions-Adaptive-Offline-Reinforcement-Learning-with-Expert-Guidance"><a href="#Hundreds-Guide-Millions-Adaptive-Offline-Reinforcement-Learning-with-Expert-Guidance" class="headerlink" title="Hundreds Guide Millions: Adaptive Offline Reinforcement Learning with Expert Guidance"></a>Hundreds Guide Millions: Adaptive Offline Reinforcement Learning with Expert Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01448">http://arxiv.org/abs/2309.01448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qisen Yang, Shenzhi Wang, Qihang Zhang, Gao Huang, Shiji Song</li>
<li>for: 提高OFFLINE强化学习（RL）中的策略优化，以便在已经收集的数据集上无需与环境交互时仍能够得到优化的策略。</li>
<li>methods: 提出了一种基于导航网络的插件方法，名为指导OFFLINERL（GORL），该方法可以自动确定每个样本的策略改进和策略限制的相对重要性。</li>
<li>results: 经过广泛的实验表明，GORL可以轻松地与大多数OFFLINERL算法结合使用，并且在各种环境中提供了 statistically significant 的性能提升。<details>
<summary>Abstract</summary>
Offline reinforcement learning (RL) optimizes the policy on a previously collected dataset without any interactions with the environment, yet usually suffers from the distributional shift problem. To mitigate this issue, a typical solution is to impose a policy constraint on a policy improvement objective. However, existing methods generally adopt a ``one-size-fits-all'' practice, i.e., keeping only a single improvement-constraint balance for all the samples in a mini-batch or even the entire offline dataset. In this work, we argue that different samples should be treated with different policy constraint intensities. Based on this idea, a novel plug-in approach named Guided Offline RL (GORL) is proposed. GORL employs a guiding network, along with only a few expert demonstrations, to adaptively determine the relative importance of the policy improvement and policy constraint for every sample. We theoretically prove that the guidance provided by our method is rational and near-optimal. Extensive experiments on various environments suggest that GORL can be easily installed on most offline RL algorithms with statistically significant performance improvements.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translation into Simplified ChineseOffline 学习优化策略（Offline Reinforcement Learning）通常会遇到分布shift问题，这是因为学习策略时不能直接与环境交互。为解决这个问题，常见的方法是通过策略约束来限制策略改进的目标。然而，现有的方法通常采用“一size-fits-all”的做法，即在一个mini-batch或整个Offline dataset中都保留单一的改进约束平衡。在这个工作中，我们 argue That different samples should be treated with different策略约束强度。基于这个想法，我们提出了一种名为Guided Offline RL（GORL）的新插件方法。GORL使用一个引导网络，以及只需几个专家示范，来动态确定每个样本的策略改进和策略约束的相对重要性。我们证明了我们的方法的引导是理性的和近似优化的。广泛的实验表明，GORL可以轻松地安装在大多数Offline RL算法上，并且具有 statistically significant的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Expanding-Mars-Climate-Modeling-Interpretable-Machine-Learning-for-Modeling-MSL-Relative-Humidity"><a href="#Expanding-Mars-Climate-Modeling-Interpretable-Machine-Learning-for-Modeling-MSL-Relative-Humidity" class="headerlink" title="Expanding Mars Climate Modeling: Interpretable Machine Learning for Modeling MSL Relative Humidity"></a>Expanding Mars Climate Modeling: Interpretable Machine Learning for Modeling MSL Relative Humidity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01424">http://arxiv.org/abs/2309.01424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nour Abdelmoneim, Dattaraj B. Dhuri, Dimitra Atri, Germán Martínez</li>
<li>for: 这个研究的目的是为了模拟火星气候，具体来说是在加乐沟地区测量的相对湿度。</li>
<li>methods: 这个研究使用的方法是基于机器学习技术，使用了一个深度神经网络模型，使用了火星气候模型生成的数据进行训练。</li>
<li>results: 研究结果表明，这个神经网络模型可以准确地预测加乐沟地区的相对湿度，误差在3%以内，$R^2$分数为0.92。此外，研究还发现了一种方法可以预测相对湿度的范围，这有助于应用需要范围值的场合。<details>
<summary>Abstract</summary>
For the past several decades, numerous attempts have been made to model the climate of Mars with extensive studies focusing on the planet's dynamics and the understanding of its climate. While physical modeling and data assimilation approaches have made significant progress, uncertainties persist in comprehensively capturing and modeling the complexities of Martian climate. In this work, we propose a novel approach to Martian climate modeling by leveraging machine learning techniques that have shown remarkable success in Earth climate modeling. Our study presents a deep neural network designed to accurately model relative humidity in Gale Crater, as measured by NASA's Mars Science Laboratory ``Curiosity'' rover. By utilizing simulated meteorological variables produced by the Mars Planetary Climate Model, a robust Global Circulation Model, our model accurately predicts relative humidity with a mean error of 3\% and an $R^2$ score of 0.92. Furthermore, we present an approach to predict quantile ranges of relative humidity, catering to applications that require a range of values. To address the challenge of interpretability associated with machine learning models, we utilize an interpretable model architecture and conduct an in-depth analysis of its internal mechanisms and decision making processes. We find that our neural network can effectively model relative humidity at Gale crater using a few meteorological variables, with the monthly mean surface H$_2$O layer, planetary boundary layer height, convective wind speed, and solar zenith angle being the primary contributors to the model predictions. In addition to providing a fast and efficient method to modeling climate variables on Mars, this modeling approach can also be used to expand on current datasets by filling spatial and temporal gaps in observations.
</details>
<details>
<summary>摘要</summary>
For the past several decades, numerous attempts have been made to model the climate of Mars, with extensive studies focusing on the planet's dynamics and understanding its climate. Although physical modeling and data assimilation approaches have made significant progress, uncertainties still exist in comprehensively capturing and modeling the complexities of Martian climate. In this study, we propose a novel approach to Martian climate modeling by leveraging machine learning techniques that have shown remarkable success in Earth climate modeling. Our study presents a deep neural network designed to accurately model relative humidity in Gale Crater, as measured by NASA's Mars Science Laboratory "Curiosity" rover. By utilizing simulated meteorological variables produced by the Mars Planetary Climate Model, a robust Global Circulation Model, our model accurately predicts relative humidity with a mean error of 3% and an $R^2$ score of 0.92. Furthermore, we present an approach to predict quantile ranges of relative humidity, catering to applications that require a range of values. To address the challenge of interpretability associated with machine learning models, we utilize an interpretable model architecture and conduct an in-depth analysis of its internal mechanisms and decision-making processes. We find that our neural network can effectively model relative humidity at Gale crater using a few meteorological variables, with the monthly mean surface H$_2$O layer, planetary boundary layer height, convective wind speed, and solar zenith angle being the primary contributors to the model predictions. In addition to providing a fast and efficient method to modeling climate variables on Mars, this modeling approach can also be used to expand on current datasets by filling spatial and temporal gaps in observations.
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Bayesian-Structure-Learning-with-Acyclicity-Assurance"><a href="#Differentiable-Bayesian-Structure-Learning-with-Acyclicity-Assurance" class="headerlink" title="Differentiable Bayesian Structure Learning with Acyclicity Assurance"></a>Differentiable Bayesian Structure Learning with Acyclicity Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01392">http://arxiv.org/abs/2309.01392</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang-Duy Tran, Phuoc Nguyen, Bao Duong, Thin Nguyen</li>
<li>for: 本研究旨在提出一种具有约束性的循环自适应方法，以确保生成的图Structures是有向无环的。</li>
<li>methods: 本研究使用了一种结合排序知识的方法，以确保生成的图Structures是有向无环的。</li>
<li>results: 实验表明，我们的方法可以比相关的 bayesian 分数基于方法更好地降低推理复杂性，同时确保生成的图Structures是有向无环的。<details>
<summary>Abstract</summary>
Score-based approaches in the structure learning task are thriving because of their scalability. Continuous relaxation has been the key reason for this advancement. Despite achieving promising outcomes, most of these methods are still struggling to ensure that the graphs generated from the latent space are acyclic by minimizing a defined score. There has also been another trend of permutation-based approaches, which concern the search for the topological ordering of the variables in the directed acyclic graph in order to limit the search space of the graph. In this study, we propose an alternative approach for strictly constraining the acyclicty of the graphs with an integration of the knowledge from the topological orderings. Our approach can reduce inference complexity while ensuring the structures of the generated graphs to be acyclic. Our empirical experiments with simulated and real-world data show that our approach can outperform related Bayesian score-based approaches.
</details>
<details>
<summary>摘要</summary>
score-based方法在结构学任务中得到了广泛应用，主要是因为它们可以扩展到大规模的数据集。连续放松是这些方法的关键原因。尽管它们在实现出色的结果，但大多数这些方法仍然无法确保生成的图从幂等空间中是无环的，通过定义得分来减少搜索空间。此外，有一种排序基于方法，它们关注在搜索变量的顺序问题上，以限制搜索空间。在这种研究中，我们提出了一种新的方法，通过结合知识来限制图的环的数量。我们的方法可以减少推理复杂性，同时确保生成的图是无环的。我们的实验表明，我们的方法可以超越相关的 bayesian 分数基于方法。
</details></li>
</ul>
<hr>
<h2 id="Classic-algorithms-are-fair-learners-Classification-Analysis-of-natural-weather-and-wildfire-occurrences"><a href="#Classic-algorithms-are-fair-learners-Classification-Analysis-of-natural-weather-and-wildfire-occurrences" class="headerlink" title="Classic algorithms are fair learners: Classification Analysis of natural weather and wildfire occurrences"></a>Classic algorithms are fair learners: Classification Analysis of natural weather and wildfire occurrences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01381">http://arxiv.org/abs/2309.01381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sengopal/classic-ml-review-paper">https://github.com/sengopal/classic-ml-review-paper</a></li>
<li>paper_authors: Senthilkumar Gopal</li>
<li>for: 这个论文旨在对常见的监督学习算法进行实际运行和数学分析，以了解它们在不同情况下的性能和特性。</li>
<li>methods: 这篇论文使用了多种常见的监督学习算法，包括决策树、扩展、支持向量机和k-最近邻居。</li>
<li>results: 该论文通过对稀疏表格数据进行分类任务的实验，发现这些经典算法在面对噪声和稀疏数据时仍然能够保持良好的泛化能力，并且可以通过不同的参数来提高分类精度。<details>
<summary>Abstract</summary>
Classic machine learning algorithms have been reviewed and studied mathematically on its performance and properties in detail. This paper intends to review the empirical functioning of widely used classical supervised learning algorithms such as Decision Trees, Boosting, Support Vector Machines, k-nearest Neighbors and a shallow Artificial Neural Network. The paper evaluates these algorithms on a sparse tabular data for classification task and observes the effect on specific hyperparameters on these algorithms when the data is synthetically modified for higher noise. These perturbations were introduced to observe these algorithms on their efficiency in generalizing for sparse data and their utility of different parameters to improve classification accuracy. The paper intends to show that these classic algorithms are fair learners even for such limited data due to their inherent properties even for noisy and sparse datasets.
</details>
<details>
<summary>摘要</summary>
经典机器学习算法已经被详细地研究和分析其性能和特性。这篇论文的目的是对广泛使用的经典超级vised学习算法进行实证性的评估，包括决策树、提升、支持向量机器、k最近邻居和杂层人工神经网络。这篇论文将这些算法应用于稀疏表格数据进行分类任务，并观察这些算法对不同的超参数的影响，当数据被人工修改以增加噪音时。这些干扰是为了评估这些算法在普适数据上的泛化能力和不同参数的用于提高分类精度。论文的目的是表明这些经典算法是有效的学习者，即使只有有限的数据。
</details></li>
</ul>
<hr>
<h2 id="Mutual-Information-Maximizing-Quantum-Generative-Adversarial-Network-and-Its-Applications-in-Finance"><a href="#Mutual-Information-Maximizing-Quantum-Generative-Adversarial-Network-and-Its-Applications-in-Finance" class="headerlink" title="Mutual Information Maximizing Quantum Generative Adversarial Network and Its Applications in Finance"></a>Mutual Information Maximizing Quantum Generative Adversarial Network and Its Applications in Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01363">http://arxiv.org/abs/2309.01363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingyu Lee, Myeongjin Shin, Junseo Lee, Kabgyun Jeong</li>
<li>for: 本研究旨在应用于NISQ计算时代的量子机器学习领域，即使用量子机器学习来解决各种领域的问题。</li>
<li>methods: 本研究使用量子生成对抗网络（QGAN），并在QGAN中引入了误差度量 neural network（MINE）来解决模式塌陷问题。</li>
<li>results: 研究表明， InfoQGAN 可以成功地解决模式塌陷问题，并在金融场景中应用于动态资产配置问题来生成 portefolio 返报分布。<details>
<summary>Abstract</summary>
One of the most promising applications in the era of NISQ (Noisy Intermediate-Scale Quantum) computing is quantum machine learning. Quantum machine learning offers significant quantum advantages over classical machine learning across various domains. Specifically, generative adversarial networks have been recognized for their potential utility in diverse fields such as image generation, finance, and probability distribution modeling. However, these networks necessitate solutions for inherent challenges like mode collapse. In this study, we capitalize on the concept that the estimation of mutual information between high-dimensional continuous random variables can be achieved through gradient descent using neural networks. We introduce a novel approach named InfoQGAN, which employs the Mutual Information Neural Estimator (MINE) within the framework of quantum generative adversarial networks to tackle the mode collapse issue. Furthermore, we elaborate on how this approach can be applied to a financial scenario, specifically addressing the problem of generating portfolio return distributions through dynamic asset allocation. This illustrates the potential practical applicability of InfoQGAN in real-world contexts.
</details>
<details>
<summary>摘要</summary>
一个有前途的应用在NISQ（杂AX）计算时代是量子机器学习。量子机器学习在各个领域提供了明显的量子优势。例如，生成对抗网络在图像生成、金融和概率分布模型方面具有潜在的应用前景。然而，这些网络面临的挑战包括模式塌缩。在本研究中，我们利用潜在的思路，即高维连续随机变量之间的相互信息的估计可以通过梯度下降使用神经网络来实现。我们提出一种名为InfoQGAN的新方法，该方法在量子生成对抗网络框架中使用神经网络来解决模式塌缩问题。此外，我们还详细介绍了如何在金融场景中应用InfoQGAN，具体是通过动态资产配置来生成 portefolio返杂分布。这说明InfoQGAN在实际场景中的应用前景非常广阔。
</details></li>
</ul>
<hr>
<h2 id="Random-Projections-of-Sparse-Adjacency-Matrices"><a href="#Random-Projections-of-Sparse-Adjacency-Matrices" class="headerlink" title="Random Projections of Sparse Adjacency Matrices"></a>Random Projections of Sparse Adjacency Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01360">http://arxiv.org/abs/2309.01360</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank Qiu</li>
<li>for: 该论文旨在研究随机投影方法，用于表示稀疏图。</li>
<li>methods: 该论文使用随机投影方法，以保留图的功能性。</li>
<li>results: 该论文显示，随机投影方法可以在同一空间中表示不同大小的图和顶点集，并且可以精确地执行图算子。<details>
<summary>Abstract</summary>
We analyze a random projection method for adjacency matrices, studying its utility in representing sparse graphs. We show that these random projections retain the functionality of their underlying adjacency matrices while having extra properties that make them attractive as dynamic graph representations. In particular, they can represent graphs of different sizes and vertex sets in the same space, allowing for the aggregation and manipulation of graphs in a unified manner. We also provide results on how the size of the projections need to scale in order to preserve accurate graph operations, showing that the size of the projections can scale linearly with the number of vertices while accurately retaining first-order graph information. We conclude by characterizing our random projection as a distance-preserving map of adjacency matrices analogous to the usual Johnson-Lindenstrauss map.
</details>
<details>
<summary>摘要</summary>
我们分析了一种随机投影方法 для邻接矩阵，研究其在表示稀疏图的有用性。我们显示这些随机投影可以保持它们的下面矩阵的功能性，同时具有一些有利的特性，使得它们成为动态图表示的优选。具体来说，它们可以将不同大小的图和顶点集表示在同一个空间中，allowing for the aggregation and manipulation of graphs in a unified manner。我们还提供了保持准确图操作的尺度规则，显示随机投影的大小可以与顶点数 linearly 增长，并准确地保留首领信息。我们最后characterize our random projection as a distance-preserving map of adjacency matrices analogous to the usual Johnson-Lindenstrauss map.
</details></li>
</ul>
<hr>
<h2 id="MalwareDNA-Simultaneous-Classification-of-Malware-Malware-Families-and-Novel-Malware"><a href="#MalwareDNA-Simultaneous-Classification-of-Malware-Malware-Families-and-Novel-Malware" class="headerlink" title="MalwareDNA: Simultaneous Classification of Malware, Malware Families, and Novel Malware"></a>MalwareDNA: Simultaneous Classification of Malware, Malware Families, and Novel Malware</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01350">http://arxiv.org/abs/2309.01350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov, Charles Nicholas</li>
<li>for: 本研究旨在提出一种新的机器学习方法，用于准确地识别新型恶意软件家族，同时整合了恶意软件&#x2F;良好软件分类和恶意软件家族分类的能力。</li>
<li>methods: 该方法使用机器学习技术，并利用了各种特征和数据来进行分类。</li>
<li>results: 本研究的初步结果表明，该方法可以准确地识别新型恶意软件家族，并且可以整合恶意软件&#x2F;良好软件分类和恶意软件家族分类的能力。<details>
<summary>Abstract</summary>
Malware is one of the most dangerous and costly cyber threats to national security and a crucial factor in modern cyber-space. However, the adoption of machine learning (ML) based solutions against malware threats has been relatively slow. Shortcomings in the existing ML approaches are likely contributing to this problem. The majority of current ML approaches ignore real-world challenges such as the detection of novel malware. In addition, proposed ML approaches are often designed either for malware/benign-ware classification or malware family classification. Here we introduce and showcase preliminary capabilities of a new method that can perform precise identification of novel malware families, while also unifying the capability for malware/benign-ware classification and malware family classification into a single framework.
</details>
<details>
<summary>摘要</summary>
马拉ware是现代网络空间中最危险和最昂贵的Cyber安全威胁之一，但是使用机器学习（ML）技术对抗马拉ware威胁的采用速度相对较慢。现有的ML方法存在缺陷，主要是忽略现实中的新型马拉ware检测。此外，大多数当前ML方法都是为马拉ware/非恶意软件分类或马拉ware家族分类而设计的。我们介绍了一种新的方法，可以精准地识别新型马拉ware家族，同时整合了马拉ware/非恶意软件分类和马拉ware家族分类的能力。
</details></li>
</ul>
<hr>
<h2 id="In-processing-User-Constrained-Dominant-Sets-for-User-Oriented-Fairness-in-Recommender-Systems"><a href="#In-processing-User-Constrained-Dominant-Sets-for-User-Oriented-Fairness-in-Recommender-Systems" class="headerlink" title="In-processing User Constrained Dominant Sets for User-Oriented Fairness in Recommender Systems"></a>In-processing User Constrained Dominant Sets for User-Oriented Fairness in Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01335">http://arxiv.org/abs/2309.01335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongxuan Han, Chaochao Chen, Xiaolin Zheng, Weiming Liu, Jun Wang, Wenjie Cheng, Yuyuan Li<br>for: 本研究旨在解决推荐系统中的用户方向偏袋问题（User-Oriented Fairness，UOF），即推荐性能对特定用户群体的不公正。methods: 本研究提出了一种基于backbone推荐模型的In-processing User Constrained Dominant Sets（In-UCDS）框架，包括两个阶段：UCDS模型阶段和在处理阶段。在UCDS模型阶段，对每个劣位用户，提取一个约束主集（user cluster），包含一些有利用户的高质量用户。在处理阶段，通过计算公平损失，将劣位用户的表示向其相应的cluster移动 closer。这种结合公平损失和原始backbone模型损失的方法，可以同时解决UOF问题和保持总的推荐性能。results: 实验表明，In-UCDS在三个真实世界数据集上表现出色，与状态前的方法相比，具有更高的公平性和更好的总推荐性能。<details>
<summary>Abstract</summary>
Recommender systems are typically biased toward a small group of users, leading to severe unfairness in recommendation performance, i.e., User-Oriented Fairness (UOF) issue. The existing research on UOF is limited and fails to deal with the root cause of the UOF issue: the learning process between advantaged and disadvantaged users is unfair. To tackle this issue, we propose an In-processing User Constrained Dominant Sets (In-UCDS) framework, which is a general framework that can be applied to any backbone recommendation model to achieve user-oriented fairness. We split In-UCDS into two stages, i.e., the UCDS modeling stage and the in-processing training stage. In the UCDS modeling stage, for each disadvantaged user, we extract a constrained dominant set (a user cluster) containing some advantaged users that are similar to it. In the in-processing training stage, we move the representations of disadvantaged users closer to their corresponding cluster by calculating a fairness loss. By combining the fairness loss with the original backbone model loss, we address the UOF issue and maintain the overall recommendation performance simultaneously. Comprehensive experiments on three real-world datasets demonstrate that In-UCDS outperforms the state-of-the-art methods, leading to a fairer model with better overall recommendation performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CN<</SYS>>推荐系统通常偏向一小组用户，导致推荐性能不公，即用户 ориентирован的公平问题 (UOF)。现有的 UOF 研究有限，并未能够解决 UOF 问题的根本原因：推荐模型学习过程中受欢迎和受惩罚用户之间的不公。为解决此问题，我们提出了内部用户受限 dominant set (In-UCDS) 框架，这是一个通用的框架，可以应用于任何基础推荐模型，以实现用户 Oriented 公平。我们将 In-UCDS 分成两个阶段：UCDS 模型化阶段和在处理阶段。在 UCDS 模型化阶段，为每个受欢迎用户，我们提取一个受限 dominant set (用户集)，包含一些受欢迎用户和受惩罚用户之间的相似性。在处理阶段，我们通过计算公平损失，使得受欢迎用户的表示更加接近它所对应的用户集。通过将公平损失与原始基础模型损失相加，我们同时解决 UOF 问题和保持总体推荐性能。广泛的实验表明，In-UCDS 在三个实际数据集上表现出色，与当前状态的方法相比，它可以实现更加公平的推荐模型，同时保持总体推荐性能。
</details></li>
</ul>
<hr>
<h2 id="An-ML-assisted-OTFS-vs-OFDM-adaptable-modem"><a href="#An-ML-assisted-OTFS-vs-OFDM-adaptable-modem" class="headerlink" title="An ML-assisted OTFS vs. OFDM adaptable modem"></a>An ML-assisted OTFS vs. OFDM adaptable modem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01319">http://arxiv.org/abs/2309.01319</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. Zakir Ahmed, Hamid R. Sadjadpour</li>
<li>for: 提高高速移动场景下的通信性能</li>
<li>methods: 使用深度神经网络（DNN）自适应 switching between OTFS 和 OFDM 信号处理链</li>
<li>results: 对比 OTFS、OFDM 和提议的 switching waveform  scheme，得到了显著改善的 Mean-Squared-Error（MSE）性能<details>
<summary>Abstract</summary>
The Orthogonal-Time-Frequency-Space (OTFS) signaling is known to be resilient to doubly-dispersive channels, which impacts high mobility scenarios. On the other hand, the Orthogonal-Frequency-Division-Multiplexing (OFDM) waveforms enjoy the benefits of the reuse of legacy architectures, simplicity of receiver design, and low-complexity detection. Several studies that compare the performance of OFDM and OTFS have indicated mixed outcomes due to the plethora of system parameters at play beyond high-mobility conditions. In this work, we exemplify this observation using simulations and propose a deep neural network (DNN)-based adaptation scheme to switch between using either an OTFS or OFDM signal processing chain at the transmitter and receiver for optimal mean-squared-error (MSE) performance. The DNN classifier is trained to switch between the two schemes by observing the channel condition, received SNR, and modulation format. We compare the performance of the OTFS, OFDM, and the proposed switched-waveform scheme. The simulations indicate superior performance with the proposed scheme with a well-trained DNN, thus improving the MSE performance of the communication significantly.
</details>
<details>
<summary>摘要</summary>
Orthogonal-Time-Frequency-Space (OTFS) 信号处理可以抗抗双折射通道，这对高移动场景有着积极的影响。然而，Orthogonal-Frequency-Division-Multiplexing (OFDM) 波形具有重用现有架构、接收器设计简单、检测低复杂性的优点。但由于系统参数的各种变化，各种研究表明OFDM和OTFS的性能表现存在混乱。在这项工作中，我们通过simeulations进行了证明，并提出了基于深度神经网络（DNN）的适应方案，以实现在传输和接收端使用OTFS或OFDM信号处理链的优化。DNN分类器根据通道条件、接收SNR和调制格式进行选择。我们对OTFS、OFDM和我们提议的切换波形 schemes进行比较。Simulations表明，具有良好训练的DNN，提出的方案可以明显提高通信的MSE性能。
</details></li>
</ul>
<hr>
<h2 id="Communication-Efficient-Design-of-Learning-System-for-Energy-Demand-Forecasting-of-Electrical-Vehicles"><a href="#Communication-Efficient-Design-of-Learning-System-for-Energy-Demand-Forecasting-of-Electrical-Vehicles" class="headerlink" title="Communication-Efficient Design of Learning System for Energy Demand Forecasting of Electrical Vehicles"></a>Communication-Efficient Design of Learning System for Energy Demand Forecasting of Electrical Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01297">http://arxiv.org/abs/2309.01297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiacong Xu, Riley Kilfoyle, Zixiang Xiong, Ligang Lu</li>
<li>for: 这篇论文是用于提出一种可以实现时间序列能源利用预测的机器学习模型，并且可以在各地的电动车充电站进行分布式训练。</li>
<li>methods: 这篇论文使用了最新的 transformer 架构和分布式学习（Federated Learning）的组合，以提高时间序列预测性能。</li>
<li>results: 比较这篇论文的时间序列预测性能和训练资料量，与其他模型的比较显示，这篇论文的模型可以与其他模型相比，同时具有更低的训练资料量。<details>
<summary>Abstract</summary>
Machine learning (ML) applications to time series energy utilization forecasting problems are a challenging assignment due to a variety of factors. Chief among these is the non-homogeneity of the energy utilization datasets and the geographical dispersion of energy consumers. Furthermore, these ML models require vast amounts of training data and communications overhead in order to develop an effective model. In this paper, we propose a communication-efficient time series forecasting model combining the most recent advancements in transformer architectures implemented across a geographically dispersed series of EV charging stations and an efficient variant of federated learning (FL) to enable distributed training. The time series prediction performance and communication overhead cost of our FL are compared against their counterpart models and shown to have parity in performance while consuming significantly lower data rates during training. Additionally, the comparison is made across EV charging as well as other time series datasets to demonstrate the flexibility of our proposed model in generalized time series prediction beyond energy demand. The source code for this work is available at https://github.com/XuJiacong/LoGTST_PSGF
</details>
<details>
<summary>摘要</summary>
机器学习（ML）应用于时间序列能源利用预测问题是一项复杂的任务，主要原因是时间序列数据的非均匀性和能源消耗者的地理分散。此外，这些ML模型需要大量的训练数据和通信占用量来建立有效的模型。在这篇论文中，我们提出了一种具有最新的变换架构和 federated learning（FL）的通信高效的时间序列预测模型，用于在地理分散的电动车充电站上进行分布式训练。我们对比了我们的FL模型和其他模型的时间序列预测性能和通信负担，并证明了我们的模型在通信成本下降的情况下保持了与其他模型相当的性能。此外，我们还对EV充电和其他时间序列数据集进行了比较，以示我们的模型在泛化时间序列预测中的灵活性。模型的源代码可以在https://github.com/XuJiacong/LoGTST_PSGF 上获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/04/cs.LG_2023_09_04/" data-id="cloh3sqzp00nth6881msiastq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/04/eess.IV_2023_09_04/" class="article-date">
  <time datetime="2023-09-04T09:00:00.000Z" itemprop="datePublished">2023-09-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/04/eess.IV_2023_09_04/">eess.IV - 2023-09-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Effects-of-Material-Mapping-Agnostic-Partial-Volume-Correction-for-Subject-Specific-Finite-Elements-Simulations"><a href="#Effects-of-Material-Mapping-Agnostic-Partial-Volume-Correction-for-Subject-Specific-Finite-Elements-Simulations" class="headerlink" title="Effects of Material Mapping Agnostic Partial Volume Correction for Subject Specific Finite Elements Simulations"></a>Effects of Material Mapping Agnostic Partial Volume Correction for Subject Specific Finite Elements Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01769">http://arxiv.org/abs/2309.01769</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adbeagley/pvcpy">https://github.com/adbeagley/pvcpy</a></li>
<li>paper_authors: Aren Beagley, Hannah Richards, Joshua W. Giles</li>
<li>for:  correction of partial volume effects in CT images</li>
<li>methods:  new algorithm based on previous work, no pre-processing or user input required, applied directly to CT images</li>
<li>results:  improved accuracy of surface strain predictions in experimental three point bending tests compared to original, uncorrected CT images<details>
<summary>Abstract</summary>
Partial Volume effects are present at the boundary between any two types of material in a CT image due to the scanner's Point Spread Function, finite voxel resolution, and importantly, the discrepancy in radiodensity between the two materials. In this study a new algorithm is developed and validated that builds on previously published work to enable the correction of partial volume effects at cortical bone boundaries. Unlike past methods, this algorithm does not require pre-processing or user input to achieve the correction, and the correction is applied directly onto a set of CT images, which enables it to be used in existing computational modelling workflows. The algorithm was validated by performing experimental three point bending tests on porcine fibulae specimen and comparing the experimental results to finite element results for models created using either the original, uncorrected CT images or the partial volume corrected images. Results demonstrated that the models created using the partial volume corrected images did improved the accuracy of the surface strain predictions. Given this initial validation, this algorithm is a viable method for overcoming the challenge of partial volume effects in CT images. Thus, future work should be undertaken to further validate the algorithm with human tissues and through coupling it with a range of different finite element creation workflows to verify that it is robust and agnostic to the chosen material mapping strategy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> CT 图像中的部分体积效应出现在任何两种材料之间的边界上，这是因为扫描仪的点扩散函数、粒子分辨率以及材料的辐射密度差异。在这项研究中，一种新的算法被开发并验证，以解决在 cortical bone 边界上的部分体积效应。与过去的方法不同的是，这种算法不需要先期处理或用户输入来实现修正，而且修正直接应用于 CT 图像集，因此可以在现有的计算模型工作流程中使用。这种算法在使用三点弯曲试验和猪骨脚模型进行验证后得到了证明，模型使用未修正 CT 图像时的表面弯曲预测结果比较准确。基于这个初步验证，这种算法是一种可靠的方法，未来的工作应该继续验证这种算法在人类组织中的效果，并通过将其与不同的材料映射策略集成来验证其是否具有抗耗荷性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Approach-for-Large-Scale-Real-Time-Quantification-of-Green-Fluorescent-Protein-Labeled-Biological-Samples-in-Microreactors"><a href="#Deep-Learning-Approach-for-Large-Scale-Real-Time-Quantification-of-Green-Fluorescent-Protein-Labeled-Biological-Samples-in-Microreactors" class="headerlink" title="Deep Learning Approach for Large-Scale, Real-Time Quantification of Green Fluorescent Protein-Labeled Biological Samples in Microreactors"></a>Deep Learning Approach for Large-Scale, Real-Time Quantification of Green Fluorescent Protein-Labeled Biological Samples in Microreactors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01384">http://arxiv.org/abs/2309.01384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Wei, Sai Mu Dalike Abaxi, Nawaz Mehmood, Luoquan Li, Fuyang Qu, Guangyao Cheng, Dehua Hu, Yi-Ping Ho, Scott Wu Yuan, Ho-Pui Ho<br>for: 这个研究旨在开发一种基于深度学习的批处理管线，以自动分类和量化GFP标记的微反应器。methods: 该方法使用深度学习算法自动分类和量化GFP标记的微反应器，并且可以在标准实验室fluorescence Mikroskop用于实时精确量化。results: 该研究发现，使用该方法可以准确预测微反应器的大小和占据状态，并且可以在2.5秒钟内量化超过2,000个微反应器（在10张图像中），并且具有1000倍的分辨率。<details>
<summary>Abstract</summary>
Absolute quantification of biological samples entails determining expression levels in precise numerical copies, offering enhanced accuracy and superior performance for rare templates. However, existing methodologies suffer from significant limitations: flow cytometers are both costly and intricate, while fluorescence imaging relying on software tools or manual counting is time-consuming and prone to inaccuracies. In this study, we have devised a comprehensive deep-learning-enabled pipeline that enables the automated segmentation and classification of GFP (green fluorescent protein)-labeled microreactors, facilitating real-time absolute quantification. Our findings demonstrate the efficacy of this technique in accurately predicting the sizes and occupancy status of microreactors using standard laboratory fluorescence microscopes, thereby providing precise measurements of template concentrations. Notably, our approach exhibits an analysis speed of quantifying over 2,000 microreactors (across 10 images) within remarkably 2.5 seconds, and a dynamic range spanning from 56.52 to 1569.43 copies per micron-liter. Furthermore, our Deep-dGFP algorithm showcases remarkable generalization capabilities, as it can be directly applied to various GFP-labeling scenarios, including droplet-based, microwell-based, and agarose-based biological applications. To the best of our knowledge, this represents the first successful implementation of an all-in-one image analysis algorithm in droplet digital PCR (polymerase chain reaction), microwell digital PCR, droplet single-cell sequencing, agarose digital PCR, and bacterial quantification, without necessitating any transfer learning steps, modifications, or retraining procedures. We firmly believe that our Deep-dGFP technique will be readily embraced by biomedical laboratories and holds potential for further development in related clinical applications.
</details>
<details>
<summary>摘要</summary>
全程量化生物样本的实现需要确定表达水平的准确数值，提供了更高的精度和性能，特别是对于罕见模板。然而，现有的方法ologies有限，流率计价仪器costly和复杂，而基于软件工具或手动计数的抗体影像分析方法时间consuming和不准确。在本研究中，我们开发了一个涵盖全 Deep-learning-enabled 管道，可以自动 segmentation和类型化 GFP（绿色抗体）标记的微反应器，实现实时全程量化。我们的发现表明该技术可以准确预测微反应器的大小和占用状态，从而提供精确的模板浓度测量。另外，我们的 Deep-dGFP 算法展示了杰出的通用能力，可以直接应用于多种 GFP 标记方式，包括滴度基本、微瓶基本、agarose基本生物应用。根据我们所知，这是首次实现了无需转移学习步骤、修改或重训练的全程量化图像分析算法，可以应用于批量数计、微瓶数计、滴度单细Sequencing、agarose数计和细菌量化。我们 firmly believe 的 Deep-dGFP 技术将被生物医学实验室广泛采用，并具有进一步发展的临床应用潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/04/eess.IV_2023_09_04/" data-id="cloh3sr650141h688bchs6hp8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/04/eess.SP_2023_09_04/" class="article-date">
  <time datetime="2023-09-04T08:00:00.000Z" itemprop="datePublished">2023-09-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/04/eess.SP_2023_09_04/">eess.SP - 2023-09-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="FlexRDZ-Autonomous-Mobility-Management-for-Radio-Dynamic-Zones"><a href="#FlexRDZ-Autonomous-Mobility-Management-for-Radio-Dynamic-Zones" class="headerlink" title="FlexRDZ: Autonomous Mobility Management for Radio Dynamic Zones"></a>FlexRDZ: Autonomous Mobility Management for Radio Dynamic Zones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01861">http://arxiv.org/abs/2309.01861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aashish Gottipati, Jacobus Van der Merwe</li>
<li>for: 这个论文旨在为广播动态频率区（RDZ）的安全运行提供自动化管理方式，使得测试发射机可以在实时控制下运行。</li>
<li>methods: 这篇论文使用层次任务网络和数字双树模型来在实时控制下规划和解决RDZ违反。</li>
<li>results:  simulations 显示，使用 FlexRDZ 可以减少移动设备干扰的干扰强度达20dBm，同时保持测试发射机的通信能力和上线率。<details>
<summary>Abstract</summary>
FlexRDZ is an online, autonomous manager for radio dynamic zones (RDZ) that seeks to enable the safe operation of RDZs through real-time control of deployed test transmitters. FlexRDZ leverages Hierarchical Task Networks and digital twin modeling to plan and resolve RDZ violations in near real-time. We prototype FlexRDZ with GTPyhop and the Terrain Integrated Rough Earth Model (TIREM). We deploy and evaluate FlexRDZ within a simulated version of the Salt Lake City POWDER testbed, a potential urban RDZ environment. Our simulations show that FlexRDZ enables up to a 20 dBm reduction in mobile interference and a significant reduction in the total power of leaked transmissions while preserving the overall communication capabilities and uptime of test transmitters. To our knowledge, FlexRDZ is the first autonomous system for RDZ management.
</details>
<details>
<summary>摘要</summary>
flexrdz 是一个在线、自主的电台动态区域（rdz）管理器，旨在通过实时控制部署的测试发射器来确保rdz的安全运行。 flexrdz 利用层次任务网络和数字双子模型来在实时内计划和解决rdz 违反。我们使用gtpyhop 和 terrain 集成粗地模型（tirem）来详细描述flexrdz。我们在一个模拟的盐湖城powder测试环境中部署并评估flexrdz，我们的仿真结果表明，flexrdz 可以减少移动设备干扰的干扰范围，并减少泄漏的发射功率，同时保持测试发射器的通信能力和上线率。在我们所知道的情况下，flexrdz 是首个自主的rdz管理系统。
</details></li>
</ul>
<hr>
<h2 id="Variational-Tracking-and-Redetection-for-Closely-spaced-Objects-in-Heavy-Clutter"><a href="#Variational-Tracking-and-Redetection-for-Closely-spaced-Objects-in-Heavy-Clutter" class="headerlink" title="Variational Tracking and Redetection for Closely-spaced Objects in Heavy Clutter"></a>Variational Tracking and Redetection for Closely-spaced Objects in Heavy Clutter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01774">http://arxiv.org/abs/2309.01774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runze Gan, Qing Li, Simon Godsill</li>
<li>for: 该论文旨在提出一种基于均值极值推理框架的非均匀波谱过程跟踪器（VB-AbNHPP），可以高效地在高密度的 closely-spaced objects 和重重雷区域中跟踪目标。</li>
<li>methods: 该论文基于一种基于均值极值推理框架的变分极值筛选法（VB-AbNHPP），并提出了一种可ralealisable的并行实现方法。此外，该论文还提出了一种变分地理学策略，可以快速 rediscover 丢失的目标在极大的监测区域中。</li>
<li>results: 该论文的实验结果表明，VB-AbNHPP 跟踪器在具有高密度的 closely-spaced objects 和重重雷区域的情况下，比较高效和准确地跟踪目标。此外，该论文还提出了一种自动检测和恢复丢失跟踪的方法，可以在极大的监测区域中快速 rediscover 丢失的目标。<details>
<summary>Abstract</summary>
The non-homogeneous Poisson process (NHPP) is a widely used measurement model that allows for an object to generate multiple measurements over time. However, it can be difficult to efficiently and reliably track multiple objects under this NHPP model in scenarios with a high density of closely-spaced objects and heavy clutter. Therefore, based on the general coordinate ascent variational filtering framework, this paper presents a variational Bayes association-based NHPP tracker (VB-AbNHPP) that can efficiently perform tracking, data association, and learning of target and clutter rates with a parallelisable implementation. In addition, a variational localisation strategy is proposed, which enables rapid rediscovery of missed targets from a large surveillance area under extremely heavy clutter. This strategy is integrated into the VB-AbNHPP tracker, resulting in a robust methodology that can automatically detect and recover from track loss. This tracker demonstrates improved tracking performance compared with existing trackers in challenging scenarios, in terms of both accuracy and efficiency.
</details>
<details>
<summary>摘要</summary>
非均匀波恩斯过程（NHPP）是一种广泛使用的测量模型，允许对象在时间上产生多个测量。然而，在高密度的 closely-spaced 对象和重重干扰的情况下，可能difficult to efficiently and reliably track multiple objects under this NHPP model。因此，基于通用坐标征枢点升级滤波框架，这篇论文提出了一种基于变分浓 Bayes 协同跟踪（VB-AbNHPP）算法，可以高效地进行跟踪、数据协同和学习目标和干扰率的学习。此外，一种变分本地化策略也被提出，可以快速 rediscover 丢失的目标在极高干扰的情况下。这种策略被纳入 VB-AbNHPP 跟踪器中，导致了一种自动探测和恢复失踪的方法。这种跟踪器在复杂的情况下表现出了改善的跟踪性能，比如精度和效率。
</details></li>
</ul>
<hr>
<h2 id="Pupillary-activity-in-areas-of-interest-from-visual-stimuli-for-neonatal-pain-assessment"><a href="#Pupillary-activity-in-areas-of-interest-from-visual-stimuli-for-neonatal-pain-assessment" class="headerlink" title="Pupillary activity in areas of interest from visual stimuli for neonatal pain assessment"></a>Pupillary activity in areas of interest from visual stimuli for neonatal pain assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01738">http://arxiv.org/abs/2309.01738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roberto Magalhaes Jr, Rafael Orsi, Marina Barros, Ruth Guinsburg, Carlos E Thomaz</li>
<li>for: 这种研究旨在比较腕动活动指数与传统的眼动追踪指标（如fixation数量和持续时间），以评估新生儿的痛苦。</li>
<li>methods: 这种研究使用了眼动追踪系统Tobii TX300，记录新生儿脸部的视线活动。我们还引入了低&#x2F;高指数腕动活动计算法，以评估健康专业人员和非专业人员在分析疼痛和无疼痛脸部图像时的视觉注意力。</li>
<li>results: 研究结果表明，传统的视觉追踪指标可能并不直接关联到相应的认知负荷。两个样本组参与者在分析疼痛和无疼痛脸部图像时，视觉注意力反映在传统指标中可能不同。<details>
<summary>Abstract</summary>
This paper compares the pupillary activity index to traditional eye-tracking metrics like the fixation count and duration in assessing neonatal pain. It explores the benefits of incorporating pupillary activity measures to improve methods that lead to an understanding of cognitive processing and performance evaluation. The estimation of cognitive load using pupil diameter typically involves measures relative to a baseline. Instead, we conducted an eye-tracking study using the Low/High Index of Pupillary Activity to evaluate healthcare experts and non-experts analyzing the faces with and without pain from a dataset of newborn faces. This data was recorded by the Tobii TX300 eye-tracking system in a closed room with controlled lighting. Our contribution is to introduce the LHIPA calculation considering the areas of interest segments of the pupil diameter signal. The results suggest that the visual attention reflected by the traditional metrics may not correspond directly to the respective cognitive load for both sample groups of participants.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文比较了腔Activity指数与传统的眼动跟踪指标，如fixation count和持续时间，以评估新生儿痛苦。它探讨了通过包含腔Activity测量来改进认知处理和性能评估方法的优点。通常来说，计算腔Activity需要相对于基准值进行估算。而我们则通过使用TX300眼动跟踪系统在控制的照明下录制了新生儿脸部图像，并使用低/高腔Activity指数来评估医疗专业人员和非专业人员对无痛和痛苦脸部图像的分析。我们的贡献在于在计算LHIPA时考虑了脸部图像中的区域关注段。结果表明，传统指标中的视觉注意力可能并不直接对应认知负荷的各个组合。
</details></li>
</ul>
<hr>
<h2 id="Output-only-Modal-Identification-of-beams-with-different-boundary-condition"><a href="#Output-only-Modal-Identification-of-beams-with-different-boundary-condition" class="headerlink" title="Output-only Modal Identification of beams with different boundary condition"></a>Output-only Modal Identification of beams with different boundary condition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01719">http://arxiv.org/abs/2309.01719</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. R. Davoodi, S. A. Mostafavian, S. R. Nabavian, GH. R. Jahangiri</li>
<li>for: 本研究旨在evaluating the integrity of civil structures by observing their dynamic responses over time, specifically focusing on identifying the modal parameters of structures using output-only identification techniques.</li>
<li>methods: 该研究使用了Finite Element Method (FEM) and MATLAB software to model and analyze the behavior of four beams with different boundary conditions and arbitrary loading. The modal parameters were identified using Frequency Domain Decomposition (FDD) and Peak Picking (PP) methods, and the results were compared with the input-output method using Frequency Relation Function (FRF).</li>
<li>results: 研究结果显示了三种方法之间的好匹配，即FDD、PP和FRF方法对梁的动态特性具有良好的一致性。<details>
<summary>Abstract</summary>
Structural Health Monitoring (SHM) evaluates the integrity of a structure by observing its dynamic responses by an array of sensors over time to determine the current health state of the structure. The most important step of SHM is system identification which in civil structures is the identification of modal parameters of structures. Due to numerous limitations of input-output methods, system identification of ambient vibration structures using output-only identification techniques has become a key issue in structural health monitoring and assessment of engineering structures. In this paper, four beams with different boundary conditions and with arbitrary loading have been modeled in finite element software, ANSYS, and the responses (Acceleration of nodes) have been achieved. By using these data and the codes written in MATLAB software, the modal parameters (natural frequencies, mode shapes) of the beams are identified with FDD (frequency Domain Decomposition) and PP (Peak Picking) methods and then justified with the results of input-output method which was determined by frequency relation function (FRF). The results indicate a good agreement between the three methods for determining the dynamic characteristics of beams.
</details>
<details>
<summary>摘要</summary>
Structural Health Monitoring (SHM) 评估结构的完整性 by 观察其动态响应，通过数组传感器在时间上观察，以确定结构当前的健康状态。结构体系识别是结构体系的关键步骤，在 Civil 结构中最重要的是模式参数的识别。由于输入输出方法的限制，结构体系识别使用输出只识别技术在结构健康监测和工程结构评估中变得非常重要。在本文中，我们使用 ANSYS 软件模拟了四根不同边界条件的梁，并在这些梁上应用了任意的荷载。通过这些数据和 MATLAB 软件中写的代码，我们使用 FDD（频域分解）和 PP（峰挑出）方法来识别梁的模式参数（自然频率、模式形），并与输入输出方法确定的频率关系函数（FRF）的结果进行比较。结果表明，三种方法在梁的动态特性方面具有良好的一致性。
</details></li>
</ul>
<hr>
<h2 id="Direction-of-arrival-estimation-with-conventional-co-prime-arrays-using-deep-learning-based-probablistic-Bayesian-neural-networks"><a href="#Direction-of-arrival-estimation-with-conventional-co-prime-arrays-using-deep-learning-based-probablistic-Bayesian-neural-networks" class="headerlink" title="Direction-of-arrival estimation with conventional co-prime arrays using deep learning-based probablistic Bayesian neural networks"></a>Direction-of-arrival estimation with conventional co-prime arrays using deep learning-based probablistic Bayesian neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01690">http://arxiv.org/abs/2309.01690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wael Elshennawy</li>
<li>for:  investigate the direction-of-arrival (DOA) estimation of narrow band signals with conventional co-prime arrays</li>
<li>methods:  probabilistic Bayesian neural networks (PBNN) and a super resolution DOA estimation method based on Bayesian neural networks</li>
<li>results:  enhances the generalization of untrained scenarios and provides robustness to non-ideal conditions, such as small angle separation, data scarcity, and imperfect arrays.<details>
<summary>Abstract</summary>
The paper investigates the direction-of-arrival (DOA) estimation of narrow band signals with conventional co-prime arrays by using probabilistic Bayesian neural networks (PBNN). A super resolution DOA estimation method based on Bayesian neural networks and a spatially overcomplete array output formulation overcomes the pre-assumption dependencies of the model-driven DOA estimation methods. The proposed DOA estimation method utilizes a PBNN model to capture both data and model uncertainty. The developed PBNN model is trained to do the mapping from the pseudo-spectrum to the super resolution spectrum. This learning-based method enhances the generalization of untrained scenarios, and it provides robustness to non-ideal conditions, e.g., small angle separation, data scarcity, and imperfect arrays, etc. Simulation results demonstrate the loss curves of the PBNN model and deterministic model. Simulations are carried out to validate the performance of PBNN model compared to a deterministic model of conventional neural networks (CNN).
</details>
<details>
<summary>摘要</summary>
文章 investigate 方向来源（DOA）估算窄频信号的传统伙 Prime 阵列上的应用，使用概率 Bayesian 神经网络（PBNN）。一种基于 Bayesian 神经网络的超解析 DOA 估算方法，扩展了模型驱动 DOA 估算方法的假设dependencies。提案的 DOA 估算方法利用 PBNN 模型捕捉数据和模型不确定性。开发的 PBNN 模型是将 pseudo-spectrum 与超解析 specturm 之间的映射执行。这个学习基于方法提高了无条件enario 的通用性，并提供了不IDEAL 状况下的Robustness，例如小角分离、数据缺乏、不完整阵列等等。在 Simulation 中，文章显示了 PBNN 模型和决定性模型的损失曲线。透过实验 validate  PBNN 模型与传统神经网络（CNN）的决定性模型之间的表现差异。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Velocity-and-Position-Estimation-of-Opponents-for-Autonomous-Racing-Using-Low-Power-Radar"><a href="#Towards-Robust-Velocity-and-Position-Estimation-of-Opponents-for-Autonomous-Racing-Using-Low-Power-Radar" class="headerlink" title="Towards Robust Velocity and Position Estimation of Opponents for Autonomous Racing Using Low-Power Radar"></a>Towards Robust Velocity and Position Estimation of Opponents for Autonomous Racing Using Low-Power Radar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01647">http://arxiv.org/abs/2309.01647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Ronco, Nicolas Baumann, Marco Giordano, Michele Magno</li>
<li>for: 这个论文是为了设计和开发一个智能子系统，该系统包括一种新型的低功耗雷达传感器，并将其集成到自动驾驶赛车视觉管道中，以精准估计动态障碍物的位置和速度。</li>
<li>methods: 该论文使用了Infineon BGT60TR13D雷达传感器，并进行了实际场景中的评估。论文还探讨了使用这种传感器子系统的优缺点，并基于场景中采集的数据进行了结论。</li>
<li>results: 论文的结果表明，使用该系统可以在10个毫瓦特的电力消耗下实现距离估计的误差在0.21+-0.29米之间，速度估计的误差在0.39+-0.19米&#x2F;秒之间。这个系统可以与其他感知器如LiDAR和摄像头结合使用，并可以在许多应用场景中使用。<details>
<summary>Abstract</summary>
This paper presents the design and development of an intelligent subsystem that includes a novel low-power radar sensor integrated into an autonomous racing perception pipeline to robustly estimate the position and velocity of dynamic obstacles. The proposed system, based on the Infineon BGT60TR13D radar, is evaluated in a real-world scenario with scaled race cars. The paper explores the benefits and limitations of using such a sensor subsystem and draws conclusions based on field-collected data. The results demonstrate a tracking error up to 0.21 +- 0.29 m in distance estimation and 0.39 +- 0.19 m/s in velocity estimation, despite the power consumption in the range of 10s of milliwatts. The presented system provides complementary information to other sensors such as LiDAR and camera, and can be used in a wide range of applications beyond autonomous racing.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "infineon" is translated as " infinion" (因 Finland) in Simplified Chinese, as it is a German company.* "BGT60TR13D" is translated as "BGT60TR13D" in Simplified Chinese, as it is a product name and not a Chinese word.* "scaled race cars" is translated as "缩小赛车" (scaled down race cars) in Simplified Chinese.* "tracking error" is translated as "跟踪误差" (tracking error) in Simplified Chinese.* "power consumption" is translated as "能源消耗" (power consumption) in Simplified Chinese.* "milliwatts" is translated as "毫瓦" (milliwatts) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-balanced-Memristor-CMOS-ternary-logic-family-and-its-application"><a href="#A-balanced-Memristor-CMOS-ternary-logic-family-and-its-application" class="headerlink" title="A balanced Memristor-CMOS ternary logic family and its application"></a>A balanced Memristor-CMOS ternary logic family and its application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01615">http://arxiv.org/abs/2309.01615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao-Yuan Wang, Jia-Wei Zhou, Chuan-Tao Dong, Xin-Hui Chen, Sanjoy Kumar Nandi, Robert G. Elliman, Sung-Mo Kang, Herbert Ho-Ching Iu</li>
<li>for: 该研究提出了基于memristors和CMOS设备的平衡三值逻辑电路设计。</li>
<li>methods: 该研究使用了系统的设计和仿真来设计和验证平衡三值最小门TMIN、最大门TMAX和三值逻辑滤波器。然后，基于这些设计的逻辑电路，如三值编码器、解码器和多路复用器，被设计出来。</li>
<li>results: 研究人员通过对两种设计方案的比较和分析，提供了后续三值逻辑电路的参考。<details>
<summary>Abstract</summary>
The design of balanced ternary digital logic circuits based on memristors and conventional CMOS devices is proposed. First, balanced ternary minimum gate TMIN, maximum gate TMAX and ternary inverters are systematically designed and verified by simulation, and then logic circuits such as ternary encoders, decoders and multiplexers are designed on this basis. Two different schemes are then used to realize the design of functional combinational logic circuits such as a balanced ternary half adder, multiplier, and numerical comparator. Finally, we report a series of comparisons and analyses of the two design schemes, which provide a reference for subsequent research and development of three-valued logic circuits.
</details>
<details>
<summary>摘要</summary>
“提出了基于抗阻门和CMOS设备的均衡三值逻辑电路设计。首先，设计了均衡三值最小门TMIN、最大门TMAX和三值逻辑滤波器，并通过仿真验证。然后，基于这些设计，设计了三值编码器、解码器和多路复用器。接着，采用了两种不同的实现方案，实现了功能 combinational 逻辑电路的设计，如均衡三值半加器、乘法器和数字比较器。最后，对两个设计方案进行了比较和分析，以供后续研究和发展三值逻辑电路的参考。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Half-Duplex-APs-with-Dynamic-TDD-vs-Full-Duplex-APs-in-Cell-Free-Systems"><a href="#Half-Duplex-APs-with-Dynamic-TDD-vs-Full-Duplex-APs-in-Cell-Free-Systems" class="headerlink" title="Half-Duplex APs with Dynamic TDD vs. Full-Duplex APs in Cell-Free Systems"></a>Half-Duplex APs with Dynamic TDD vs. Full-Duplex APs in Cell-Free Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01481">http://arxiv.org/abs/2309.01481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhab Chowdhury, Chandra R. Murthy</li>
<li>for: 这个论文研究了半通信（HD）无线点对（AP）在无基站（CF）系统中的比较研究，包括动态时分多播（DTDD）和全通信（FD）AP。</li>
<li>methods: 论文提出了一种新的频道分配方案，以最小化由多个基站服务的用户设备（UE）之间的干扰。然后，对于DTDD系统，提出了一种可提升总 spectral efficiency（SE）的封闭式公式，考虑了零干扰组合和预编码。同时，提出了一种可 garantía convergent 的算法，用于联合上下行功率分配和上下行模式调度。</li>
<li>results: 数值结果表明，论文的提案方法可以与多种 referential 相比，并且在相同的天线密度下，DTDD系统可以与FD系统具有相同的性能，而不需要进行内部基站干扰抑制。因此，DTDD与CF结合是一种可行的代替方案，可以在HD AP上实现类似的性能，而不需要进行FD系统的干扰抑制。<details>
<summary>Abstract</summary>
In this paper, we present a comparative study of half-duplex (HD) access points (APs) with dynamic time-division duplex (DTDD) and full-duplex (FD) APs in cell-free (CF) systems. Although both DTDD and FD CF systems support concurrent downlink transmission and uplink reception capability, the sum spectral efficiency (SE) is limited by various cross-link interferences. We first present a novel pilot allocation scheme that minimizes the pilot length required to ensure no pilot contamination among the user equipments (UEs) served by at least one common AP. Then, we derive the sum SE in closed form, considering zero-forcing combining and precoding along with the signal-to-interference plus noise ratio optimal weighting at the central processing unit. We also present a provably convergent algorithm for joint uplink-downlink power allocation and uplink/downlink mode scheduling of the APs (for DTDD) to maximize the sum SE. Our numerical results illustrate the superiority of the proposed algorithms over several benchmarks and show that the sum SE with DTDD can outperform an FD CF system with similar antenna density. Thus, DTDD combined with CF is a promising alternative to FD that attains the same performance using HD APs, while obviating the burden of intra-AP interference cancellation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们进行了半杂推测点（HD）接入点（AP）与动态时分多杂分多杂（DTDD）和全杂推测点（FD）CF系统的比较研究。虽然DTDD和FD CF系统都支持同时下行传输和上行接收能力，但它们的总spectral efficiency（SE）受到各个横向交叉干扰的限制。我们首先提出了一种新的频道分配方案，以最小化UE被至少一个共享AP的 Pilot 污染。然后，我们 derive了总SE的closed form，考虑了零强制合并和预编码，以及在中央处理单元中的信号噪听比优化。我们还提出了一种可证确定性的算法，用于CF系统中的接入点的共同下行-上行功率分配和下行/上行模式调度，以最大化总SE。我们的数值结果表明，提议的算法在多个参考模型之上具有superiority，并且表明DTDD和FD CF系统之间的差异可以通过使用HD AP来实现，而不需要内部AP干扰消除。因此，DTDD与CF结合可以作为一个有 promise的FD替代方案，以实现相同的性能，使用HD AP，而不需要FD CF系统中的相同antenna density。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Framework-for-Guiding-Generative-AI-with-Wireless-Perception-in-Resource-Constrained-Mobile-Edge-Networks"><a href="#A-Unified-Framework-for-Guiding-Generative-AI-with-Wireless-Perception-in-Resource-Constrained-Mobile-Edge-Networks" class="headerlink" title="A Unified Framework for Guiding Generative AI with Wireless Perception in Resource Constrained Mobile Edge Networks"></a>A Unified Framework for Guiding Generative AI with Wireless Perception in Resource Constrained Mobile Edge Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01426">http://arxiv.org/abs/2309.01426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiacheng Wang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Deepu Rajan, Shiwen Mao, Xuemin, Shen</li>
<li>for: 这 paper 是为了提供一种基于无线感知的生成式人工智能 (WiPe-GAI) 技术，用于在有限的移动边缘网络中提供数字内容生成服务 (AIGC)。</li>
<li>methods: 这 paper 使用了一种新的序列多尺度感知 (SMSP) 算法，使用无线信号中的通道状态信息 (CSI) 预测用户的skeleton。此外，它还使用了一种基于奖励机制的价格分配策略，以确保在有限的网络资源下，提供高质量的 AIGC。</li>
<li>results: 实验结果表明，提案的 frameworks 可以比其他现有解决方案更高效地预测用户的skeleton和生成价格策略。<details>
<summary>Abstract</summary>
With the significant advancements in artificial intelligence (AI) technologies and powerful computational capabilities, generative AI (GAI) has become a pivotal digital content generation technique for offering superior digital services. However, directing GAI towards desired outputs still suffer the inherent instability of the AI model. In this paper, we design a novel framework that utilizes wireless perception to guide GAI (WiPe-GAI) for providing digital content generation service, i.e., AI-generated content (AIGC), in resource-constrained mobile edge networks. Specifically, we first propose a new sequential multi-scale perception (SMSP) algorithm to predict user skeleton based on the channel state information (CSI) extracted from wireless signals. This prediction then guides GAI to provide users with AIGC, such as virtual character generation. To ensure the efficient operation of the proposed framework in resource constrained networks, we further design a pricing-based incentive mechanism and introduce a diffusion model based approach to generate an optimal pricing strategy for the service provisioning. The strategy maximizes the user's utility while enhancing the participation of the virtual service provider (VSP) in AIGC provision. The experimental results demonstrate the effectiveness of the designed framework in terms of skeleton prediction and optimal pricing strategy generation comparing with other existing solutions.
</details>
<details>
<summary>摘要</summary>
With the significant advancements in artificial intelligence (AI) technologies and powerful computational capabilities, generative AI (GAI) has become a pivotal digital content generation technique for offering superior digital services. However, directing GAI towards desired outputs still suffers from the inherent instability of the AI model. In this paper, we design a novel framework that utilizes wireless perception to guide GAI (WiPe-GAI) for providing digital content generation service, i.e., AI-generated content (AIGC), in resource-constrained mobile edge networks. Specifically, we first propose a new sequential multi-scale perception (SMSP) algorithm to predict user skeleton based on the channel state information (CSI) extracted from wireless signals. This prediction then guides GAI to provide users with AIGC, such as virtual character generation. To ensure the efficient operation of the proposed framework in resource-constrained networks, we further design a pricing-based incentive mechanism and introduce a diffusion model based approach to generate an optimal pricing strategy for the service provisioning. The strategy maximizes the user's utility while enhancing the participation of the virtual service provider (VSP) in AIGC provision. The experimental results demonstrate the effectiveness of the designed framework in terms of skeleton prediction and optimal pricing strategy generation comparing with other existing solutions.
</details></li>
</ul>
<hr>
<h2 id="Detection-of-Pedestrian-Turning-Motions-to-Enhance-Indoor-Map-Matching-Performance"><a href="#Detection-of-Pedestrian-Turning-Motions-to-Enhance-Indoor-Map-Matching-Performance" class="headerlink" title="Detection of Pedestrian Turning Motions to Enhance Indoor Map Matching Performance"></a>Detection of Pedestrian Turning Motions to Enhance Indoor Map Matching Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01405">http://arxiv.org/abs/2309.01405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seunghyeon Park, Taewon Kang, Seungjae Lee, Joon Hyo Rhee</li>
<li>for: 本研究旨在提高indoor pedestrian dead reckoning (PDR)和map matching技术性能，通过利用智能手机陀螺仪数据和进一步的算法进行人行走姿态探测。</li>
<li>methods: 本研究使用了三种方法进行人行走姿态探测，包括阈值基于的方法、隐马尔可夫模型（HMM）基于的方法和逐步级数（PELT）算法基于的方法。</li>
<li>results: 在场测试中，使用阈值基于的方法时，错过检测率为20.35%，假阳性率为7.65%；使用PELT基于的方法时，错过检测率为8.93%，假阳性率为6.97%；使用HMM基于的方法时，错过检测率为5.14%，假阳性率为2.00%。结果表明，本研究提出了一种更加准确和可靠的人行走导航系统。<details>
<summary>Abstract</summary>
A pedestrian navigation system (PNS) in indoor environments, where global navigation satellite system (GNSS) signal access is difficult, is necessary, particularly for search and rescue (SAR) operations in large buildings. This paper focuses on studying pedestrian walking behaviors to enhance the performance of indoor pedestrian dead reckoning (PDR) and map matching techniques. Specifically, our research aims to detect pedestrian turning motions using smartphone inertial measurement unit (IMU) information in a given PDR trajectory. To improve existing methods, including the threshold-based turn detection method, hidden Markov model (HMM)-based turn detection method, and pruned exact linear time (PELT) algorithm-based turn detection method, we propose enhanced algorithms that better detect pedestrian turning motions. During field tests, using the threshold-based method, we observed a missed detection rate of 20.35% and a false alarm rate of 7.65%. The PELT-based method achieved a significant improvement with a missed detection rate of 8.93% and a false alarm rate of 6.97%. However, the best results were obtained using the HMM-based method, which demonstrated a missed detection rate of 5.14% and a false alarm rate of 2.00%. In summary, our research contributes to the development of a more accurate and reliable pedestrian navigation system by leveraging smartphone IMU data and advanced algorithms for turn detection in indoor environments.
</details>
<details>
<summary>摘要</summary>
pedestrian navigation system (PNS) 在室内环境中是必需的，特别是在大型建筑物的搜索和救援 (SAR) 操作中。这篇论文关注了人行走行为，以提高室内人行走推断 (PDR) 和地图匹配技术的性能。具体来说，我们的研究旨在通过使用手机陀螺仪测量单元 (IMU) 信息探测人行走转弯动作。为了改进现有方法，包括阈值基于的转弯检测方法、隐马尔可夫模型 (HMM) 基于的转弯检测方法和剪辑精确时间 (PELT) 算法基于的转弯检测方法，我们提出了改进的算法，以更好地检测人行走转弯动作。在实验中，使用阈值基于的方法时，我们观察到了20.35%的失败检测率和7.65%的假阳性率。使用 PELT 基于的方法时，获得了显著的改进，失败检测率为8.93%，假阳性率为6.97%。然而，最佳结果是通过使用 HMM 基于的方法获得， missed detection rate 为5.14%， false alarm rate 为2.00%。总之，我们的研究为室内人行走系统的开发提供了更加准确和可靠的 pedestrian navigation system。
</details></li>
</ul>
<hr>
<h2 id="Unlabelled-Sensing-with-Priors-Algorithm-and-Bounds"><a href="#Unlabelled-Sensing-with-Priors-Algorithm-and-Bounds" class="headerlink" title="Unlabelled Sensing with Priors: Algorithm and Bounds"></a>Unlabelled Sensing with Priors: Algorithm and Bounds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01397">http://arxiv.org/abs/2309.01397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Garweet Sresth, Ajit Rajwade, Satish Mulleti</li>
<li>for: 这种研究是关于无标签感知的一种变体， measurements 是稀疏排序的，同时知道一些对应关系。</li>
<li>methods: 这种方法使用一个估计器来解决未知向量的问题。</li>
<li>results: 经过数学实验表明，在高排序 режиmess（&gt;30%）下，我们的方法可以与 классиical robust regression estimator相比，在减小化恢复错误度metric上提高到20%。此外，我们还应用了我们的框架在一个非rigid运动估计问题中，并证明了使用一些准确知道的对应关系可以改善运动估计。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
In this study, we consider a variant of unlabelled sensing where the measurements are sparsely permuted, and additionally, a few correspondences are known. We present an estimator to solve for the unknown vector. We derive a theoretical upper bound on the $\ell_2$ reconstruction error of the unknown vector. Through numerical experiments, we demonstrate that the additional known correspondences result in a significant improvement in the reconstruction error. Additionally, we compare our estimator with the classical robust regression estimator and we find that our method outperforms it on the normalized reconstruction error metric by up to $20\%$ in the high permutation regimes $(>30\%)$. Lastly, we showcase the practical utility of our framework on a non-rigid motion estimation problem. We show that using a few manually annotated points along point pairs with the key-point (SIFT-based) descriptor pairs with unknown or incorrectly known correspondences can improve motion estimation.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们考虑了一种杂乱感知变体，其中测量结果 sparse permuted。此外，我们还知道一些对应关系。我们提出了一种解决未知向量的估计器。我们 derivated一个对 $\ell_2$ 重建误差的理论上限。通过数学实验，我们发现附加知道的对应关系导致重建误差显著下降。此外，我们与经典稳定回归估计器进行比较，发现我们的方法在 норми化重建误差指标上比 classical robust regression estimator 高效，在高排序域（>30%）下出现至多20%的提高。最后，我们展示了我们的框架在点对点匹配问题中的实际应用。我们表明，使用一些手动标注的点并将 SIFT 基于描述对照点对进行匹配可以改善无拘束运动估计。
</details></li>
</ul>
<hr>
<h2 id="White-paper-on-LiDAR-performance-against-selected-Automotive-Paints"><a href="#White-paper-on-LiDAR-performance-against-selected-Automotive-Paints" class="headerlink" title="White paper on LiDAR performance against selected Automotive Paints"></a>White paper on LiDAR performance against selected Automotive Paints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01346">http://arxiv.org/abs/2309.01346</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Lee Wei Shung, Paul Hibbard, Roshan Vijay, Lincoln Ang Hon Kin, Niels de Boer</li>
<li>for: 本研究的目的是了解汽车涂料对激光探测器性能的影响。</li>
<li>methods: 本研究使用了评估不同汽车涂料类型对不同激光探测器模型的反射INTENSITY输出的方法。</li>
<li>results: 研究发现，折衣色涂料的反射INTENSITY较低，而淡色涂料呈高INTENSITY值。<details>
<summary>Abstract</summary>
LiDAR (Light Detection and Ranging) is a useful sensing technique and an important source of data for autonomous vehicles (AVs). In this publication we present the results of a study undertaken to understand the impact of automotive paint on LiDAR performance along with a methodology used to conduct this study. Our approach consists of evaluating the average reflected intensity output by different LiDAR sensor models when tested with different types of automotive paints. The paints were chosen to represent common paints found on vehicles in Singapore.   The experiments were conducted with LiDAR sensors commonly used by autonomous vehicle (AV) developers and OEMs. The paints used were also selected based on those observed in real-world conditions. This stems from a desire to model real-world performance of actual sensing systems when exposed to the physical world. The goal is then to inform regulators of AVs in Singapore of the impact of automotive paint on LiDAR performance, so that they can determine testing standards and specifications which will better reflect real-world performance and also better assess the adequacy of LiDAR systems installed for local AV operations.   The tests were conducted for a combination of 13 different paint panels and 3 LiDAR sensors. In general, it was observed that darker coloured paints have lower reflection intensity whereas lighter coloured paints exhibited higher intensity values.
</details>
<details>
<summary>摘要</summary>
李达（Light Detection and Ranging）是一种有用的探测技术，也是自动驾驶车辆（AV）的重要数据来源。在这篇论文中，我们介绍了对汽车涂料对李达性能的影响，以及对这种研究的方法。我们的方法是通过不同的李达传感器模型和不同类型的汽车涂料进行评估，并测试了常用于自动驾驶车辆开发商和OEM的李达仪。这些涂料被选择，以模拟在实际情况下所见到的涂料。我们想通过模拟实际探测系统在物理世界中的表现，以便为新加坡自动驾驶车辆的 regulators 提供更加准确地表现测试标准和规范。我们对13种不同涂料板和3种李达仪进行了测试。在一般情况下，抹上颜色比较浅的涂料具有较低的反射强度，而抹上颜色比较深的涂料则具有较高的强度值。
</details></li>
</ul>
<hr>
<h2 id="Fault-Point-Detection-for-Recovery-Planning-of-Resilient-Grid"><a href="#Fault-Point-Detection-for-Recovery-Planning-of-Resilient-Grid" class="headerlink" title="Fault Point Detection for Recovery Planning of Resilient Grid"></a>Fault Point Detection for Recovery Planning of Resilient Grid</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01345">http://arxiv.org/abs/2309.01345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hideya Yoshiuchi, Haruna Takaaki, Swapnil Bembde</li>
<li>for: 降低自然灾害导致的经济损失，日本也面临大规模的天气灾害增加。</li>
<li>methods: 本文提出了一种基于投影杆对角和方向的 POLES-Aware 移动成本估算方法，用于决定异常点间的行驶成本。</li>
<li>results: 评估结果显示，目标区域的总复原时间可以降低28%。<details>
<summary>Abstract</summary>
Large-scale meteorological disasters are increasing around the world, and power outage damage by natural disaster such as typhoons and earthquakes is increasing in Japan as well. Corresponding to the need of reduction of economic losses due to power outages, we are promoting research of resilient grids that minimizes power outage duration. In this report, we propose PACEM (Poles-Aware moving Cost Estimation Method) for determining travel costs between failure points based on the tilt angle and direction of electric poles obtained from pole-mounted sensors and road condition data. Evaluation result shows that the total recovery time can be reduced by 28% in the target area.
</details>
<details>
<summary>摘要</summary>
全球大规模气象灾害在增加，日本也有增加由自然灾害如风暴和地震等所导致的电力截断损害。为了减少经济损失，我们正在推广可靠网络的研究，以尽可能快地缩短停电时间。本报告提出了基于杆上设置的感知器和路况数据来计算停电时间的PACEM方法（杆相关运动成本估算法）。评估结果显示，目标区域的总恢复时间可以减少28%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/04/eess.SP_2023_09_04/" data-id="cloh3sr7a016yh68844zs9a6h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.SD_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T15:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.SD_2023_09_03/">cs.SD - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NADiffuSE-Noise-aware-Diffusion-based-Model-for-Speech-Enhancement"><a href="#NADiffuSE-Noise-aware-Diffusion-based-Model-for-Speech-Enhancement" class="headerlink" title="NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement"></a>NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01212">http://arxiv.org/abs/2309.01212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wen Wang, Dongchao Yang, Qichen Ye, Bowen Cao, Yuexian Zou</li>
<li>for: 这种paper的目的是提高干扰除 noise 的speech增强技术。</li>
<li>methods: 这种paper使用的方法包括 diffusion models (DM) 和 generator-plus-conditioner (GPC) 结构，以及多stage frameworks。</li>
<li>results: 实验结果表明，这种 noise-aware diffusion-based speech enhancement 模型（NADiffuSE）可以提高干扰除 noise 的性能，并且可以在不同的干扰环境下保持良好的声音质量。<details>
<summary>Abstract</summary>
The goal of speech enhancement (SE) is to eliminate the background interference from the noisy speech signal. Generative models such as diffusion models (DM) have been applied to the task of SE because of better generalization in unseen noisy scenes. Technical routes for the DM-based SE methods can be summarized into three types: task-adapted diffusion process formulation, generator-plus-conditioner (GPC) structures and the multi-stage frameworks. We focus on the first two approaches, which are constructed under the GPC architecture and use the task-adapted diffusion process to better deal with the real noise. However, the performance of these SE models is limited by the following issues: (a) Non-Gaussian noise estimation in the task-adapted diffusion process. (b) Conditional domain bias caused by the weak conditioner design in the GPC structure. (c) Large amount of residual noise caused by unreasonable interpolation operations during inference. To solve the above problems, we propose a noise-aware diffusion-based SE model (NADiffuSE) to boost the SE performance, where the noise representation is extracted from the noisy speech signal and introduced as a global conditional information for estimating the non-Gaussian components. Furthermore, the anchor-based inference algorithm is employed to achieve a compromise between the speech distortion and noise residual. In order to mitigate the performance degradation caused by the conditional domain bias in the GPC framework, we investigate three model variants, all of which can be viewed as multi-stage SE based on the preprocessing networks for Mel spectrograms. Experimental results show that NADiffuSE outperforms other DM-based SE models under the GPC infrastructure. Audio samples are available at: https://square-of-w.github.io/NADiffuSE-demo/.
</details>
<details>
<summary>摘要</summary>
目标是减少背景干扰，使得听写 speech 信号中的干扰消失。生成模型如扩散模型（DM）已经应用于干扰消除任务，因为它们在未看到的干扰场景中更好地泛化。技术 Routes 可以概括为三种：任务适应扩散过程的形ulation，生成器+条件器（GPC）结构和多Stage 框架。我们主要关注前两种方法，它们在 GPC 架构下使用任务适应扩散过程来更好地处理实际的干扰。然而，这些干扰消除模型的性能受以下问题的限制：(a) 任务适应扩散过程中的非高斯噪声估计。(b) GPC 结构中弱条件器设计引起的 conditional 领域偏见。(c) 推理过程中不合理的插值操作导致的大量剩余噪声。为解决以上问题，我们提出了一种噪声意识 diffusion-based SE 模型（NADiffuSE），其中噪声表示被提取自听写 speech 信号，并作为全局条件信息来估计非高斯噪声成分。此外，我们采用了 anchor-based 推理算法以实现权衡 speech 损害和剩余噪声。为了 Mitigate GPC 框架中的 conditional 领域偏见问题，我们进行了三种模型变体的研究，它们都可以视为基于 Mel spectrograms 的多Stage SE。实验结果表明，NADiffuSE 在 GPC 结构下的性能明显超越了其他 DM-based SE 模型。听写样本可以在以下网站上找到：https://square-of-w.github.io/NADiffuSE-demo/。
</details></li>
</ul>
<hr>
<h2 id="MSM-VC-High-fidelity-Source-Style-Transfer-for-Non-Parallel-Voice-Conversion-by-Multi-scale-Style-Modeling"><a href="#MSM-VC-High-fidelity-Source-Style-Transfer-for-Non-Parallel-Voice-Conversion-by-Multi-scale-Style-Modeling" class="headerlink" title="MSM-VC: High-fidelity Source Style Transfer for Non-Parallel Voice Conversion by Multi-scale Style Modeling"></a>MSM-VC: High-fidelity Source Style Transfer for Non-Parallel Voice Conversion by Multi-scale Style Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01142">http://arxiv.org/abs/2309.01142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Wang, Xinsheng Wang, Qicong Xie, Tao Li, Lei Xie, Qiao Tian, Yuping Wang</li>
<li>for: 这篇论文主要针对的是voice conversion（VC）任务中保持源语音的发音风格，并且实现高质量的转换。</li>
<li>methods: 该论文提出了一种多级风格模型法（MSM-VC），该法利用不同级别的特征来模型源语音的发音风格。具体来说，该法使用了不同级别的特征，包括末尾特征、本地特征和全局特征，来模型语音的帧级、本地级和全局级风格。此外，该法还引入了一个Explicit Constraint Module，以确保源语音的风格模型和目标说话人的特征 preserved。</li>
<li>results: 实验表明，MSM-VC方法可以高效地模型源语音的风格，同时保持高质量的语音转换和说话人相似性。<details>
<summary>Abstract</summary>
In addition to conveying the linguistic content from source speech to converted speech, maintaining the speaking style of source speech also plays an important role in the voice conversion (VC) task, which is essential in many scenarios with highly expressive source speech, such as dubbing and data augmentation. Previous work generally took explicit prosodic features or fixed-length style embedding extracted from source speech to model the speaking style of source speech, which is insufficient to achieve comprehensive style modeling and target speaker timbre preservation. Inspired by the style's multi-scale nature of human speech, a multi-scale style modeling method for the VC task, referred to as MSM-VC, is proposed in this paper. MSM-VC models the speaking style of source speech from different levels. To effectively convey the speaking style and meanwhile prevent timbre leakage from source speech to converted speech, each level's style is modeled by specific representation. Specifically, prosodic features, pre-trained ASR model's bottleneck features, and features extracted by a model trained with a self-supervised strategy are adopted to model the frame, local, and global-level styles, respectively. Besides, to balance the performance of source style modeling and target speaker timbre preservation, an explicit constraint module consisting of a pre-trained speech emotion recognition model and a speaker classifier is introduced to MSM-VC. This explicit constraint module also makes it possible to simulate the style transfer inference process during the training to improve the disentanglement ability and alleviate the mismatch between training and inference. Experiments performed on the highly expressive speech corpus demonstrate that MSM-VC is superior to the state-of-the-art VC methods for modeling source speech style while maintaining good speech quality and speaker similarity.
</details>
<details>
<summary>摘要</summary>
在voice conversion（VC）任务中，保持源语音的说话风格也非常重要，特别在高度表情化的源语音中，如重 lip-sync 和数据增强。先前的工作通常使用源语音中的显式 просодические特征或固定长度的风格嵌入来模拟源语音的说话风格，但这并不能实现完整的风格模型化和目标 speaker timbre 保持。受到人类语音的风格多尺度性的启发，本文提出了一种多尺度风格模型化方法（MSM-VC）。MSM-VC 模拟源语音的说话风格从不同的水平，以达到更好的风格模型化和目标 speaker timbre 保持。具体来说，在不同水平上，采用不同的表示方式来模拟风格。例如，在帧水平上采用抑制特征、在本地水平上采用预训练 ASR 模型的瓶颈特征，在全局水平上采用通过自我超VI的方法提取的特征。此外，为了平衡源风格模型化和目标 speaker timbre 保持，我们引入了一个explicit constraint module，包括一个预训练的语音情感认知模型和一个 speaker classifier。这个explicit constraint module 也使得在训练过程中可以模拟风格传递INFERENCE进程，以提高分离度和减少训练和测试之间的差异。实验表明，在高度表情化语音库中，MSM-VC 比状态之前的VC方法更好地模拟源语音的说话风格，同时保持良好的语音质量和 speaker similarity。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.SD_2023_09_03/" data-id="cloh3sr1y00u7h688dfzb2mre" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.CV_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T13:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.CV_2023_09_03/">cs.CV - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MAP-Domain-Generalization-via-Meta-Learning-on-Anatomy-Consistent-Pseudo-Modalities"><a href="#MAP-Domain-Generalization-via-Meta-Learning-on-Anatomy-Consistent-Pseudo-Modalities" class="headerlink" title="MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"></a>MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01286">http://arxiv.org/abs/2309.01286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dewei Hu, Hao Li, Han Liu, Xing Yao, Jiacheng Wang, Ipek Oguz</li>
<li>for: 提高深度模型的 клиниче应用性，即增强模型对未经见的领域的泛化能力。</li>
<li>methods: 我们提出了一种名为Meta learning on Anatomy-consistent Pseudo-modalities（MAP）的方法，该方法通过学习结构特征来提高模型的泛化能力。我们首先使用特征提取网络生成了三种不同的 Pseudo-modalities，然后使用 episodic learning 模式，选择一个 Pseudo-modalities 作为元训练集，并在一个通过 Dirichlet mixup 生成的连续变换图像空间中进行元测试。此外，我们还引入了两种捕捉形态信息的损失函数，以便模型更好地关注形态特征。</li>
<li>results: 我们在七个公共 datasets 上进行了测试，并证明了 MAP 在不同的Retinal imaging modalities上有substantially better的泛化能力。<details>
<summary>Abstract</summary>
Deep models suffer from limited generalization capability to unseen domains, which has severely hindered their clinical applicability. Specifically for the retinal vessel segmentation task, although the model is supposed to learn the anatomy of the target, it can be distracted by confounding factors like intensity and contrast. We propose Meta learning on Anatomy-consistent Pseudo-modalities (MAP), a method that improves model generalizability by learning structural features. We first leverage a feature extraction network to generate three distinct pseudo-modalities that share the vessel structure of the original image. Next, we use the episodic learning paradigm by selecting one of the pseudo-modalities as the meta-train dataset, and perform meta-testing on a continuous augmented image space generated through Dirichlet mixup of the remaining pseudo-modalities. Further, we introduce two loss functions that facilitate the model's focus on shape information by clustering the latent vectors obtained from images featuring identical vasculature. We evaluate our model on seven public datasets of various retinal imaging modalities and we conclude that MAP has substantially better generalizability. Our code is publically available at https://github.com/DeweiHu/MAP.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FOR-instance-a-UAV-laser-scanning-benchmark-dataset-for-semantic-and-instance-segmentation-of-individual-trees"><a href="#FOR-instance-a-UAV-laser-scanning-benchmark-dataset-for-semantic-and-instance-segmentation-of-individual-trees" class="headerlink" title="FOR-instance: a UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees"></a>FOR-instance: a UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01279">http://arxiv.org/abs/2309.01279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Puliti, Grant Pearse, Peter Surový, Luke Wallace, Markus Hollaus, Maciej Wielgosz, Rasmus Astrup</li>
<li>for: 这个论文是为了提高 dense airborne laser scanning 数据的Instance和Semantic segmentation技术而写的。</li>
<li>methods: 该论文使用了 UAV 上的激光扫描数据，并对其进行手动标注，以获得不同类别的树实体和 semantic classes。</li>
<li>results: 该论文提供了一个标准化的 benchmarking 数据集，用于提高Instance和Semantic segmentation技术的发展，并且可以适应不同的深度学习框架和 segmentation 策略。<details>
<summary>Abstract</summary>
The FOR-instance dataset (available at https://doi.org/10.5281/zenodo.8287792) addresses the challenge of accurate individual tree segmentation from laser scanning data, crucial for understanding forest ecosystems and sustainable management. Despite the growing need for detailed tree data, automating segmentation and tracking scientific progress remains difficult. Existing methodologies often overfit small datasets and lack comparability, limiting their applicability. Amid the progress triggered by the emergence of deep learning methodologies, standardized benchmarking assumes paramount importance in these research domains. This data paper introduces a benchmarking dataset for dense airborne laser scanning data, aimed at advancing instance and semantic segmentation techniques and promoting progress in 3D forest scene segmentation. The FOR-instance dataset comprises five curated and ML-ready UAV-based laser scanning data collections from diverse global locations, representing various forest types. The laser scanning data were manually annotated into individual trees (instances) and different semantic classes (e.g. stem, woody branches, live branches, terrain, low vegetation). The dataset is divided into development and test subsets, enabling method advancement and evaluation, with specific guidelines for utilization. It supports instance and semantic segmentation, offering adaptability to deep learning frameworks and diverse segmentation strategies, while the inclusion of diameter at breast height data expands its utility to the measurement of a classic tree variable. In conclusion, the FOR-instance dataset contributes to filling a gap in the 3D forest research, enhancing the development and benchmarking of segmentation algorithms for dense airborne laser scanning data.
</details>
<details>
<summary>摘要</summary>
《FOR-instance数据集》（可在https://doi.org/10.5281/zenodo.8287792中获取）是一个关键性的三维森林景象分割数据集，用于提高受众树 segmentation 技术的精度。despite the growing need for detailed tree data, automating segmentation and tracking scientific progress remains difficult. Existing methodologies often overfit small datasets and lack comparability, limiting their applicability. With the emergence of deep learning methodologies, standardized benchmarking assumes paramount importance in these research domains. This data paper introduces a benchmarking dataset for dense airborne laser scanning data, aimed at advancing instance and semantic segmentation techniques and promoting progress in 3D forest scene segmentation.The FOR-instance dataset includes five curated and ML-ready UAV-based laser scanning data collections from diverse global locations, representing various forest types. The laser scanning data were manually annotated into individual trees (instances) and different semantic classes (e.g. stem, woody branches, live branches, terrain, low vegetation). The dataset is divided into development and test subsets, enabling method advancement and evaluation, with specific guidelines for utilization. It supports instance and semantic segmentation, offering adaptability to deep learning frameworks and diverse segmentation strategies, while the inclusion of diameter at breast height data expands its utility to the measurement of a classic tree variable. In conclusion, the FOR-instance dataset contributes to filling a gap in the 3D forest research, enhancing the development and benchmarking of segmentation algorithms for dense airborne laser scanning data.
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-with-Deterministic-Normalizing-Flow-Priors"><a href="#Diffusion-Models-with-Deterministic-Normalizing-Flow-Priors" class="headerlink" title="Diffusion Models with Deterministic Normalizing Flow Priors"></a>Diffusion Models with Deterministic Normalizing Flow Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01274">http://arxiv.org/abs/2309.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mohsenzand/dinof">https://github.com/mohsenzand/dinof</a></li>
<li>paper_authors: Mohsen Zand, Ali Etemad, Michael Greenspan</li>
<li>for: 提高样本质量和采样速度</li>
<li>methods: 使用normalizing flows和diffusion模型</li>
<li>results: 在标准图像生成数据集上达到了比较出色的表现，包括FID和inception分数<details>
<summary>Abstract</summary>
For faster sampling and higher sample quality, we propose DiNof ($\textbf{Di}$ffusion with $\textbf{No}$rmalizing $\textbf{f}$low priors), a technique that makes use of normalizing flows and diffusion models. We use normalizing flows to parameterize the noisy data at any arbitrary step of the diffusion process and utilize it as the prior in the reverse diffusion process. More specifically, the forward noising process turns a data distribution into partially noisy data, which are subsequently transformed into a Gaussian distribution by a nonlinear process. The backward denoising procedure begins with a prior created by sampling from the Gaussian distribution and applying the invertible normalizing flow transformations deterministically. To generate the data distribution, the prior then undergoes the remaining diffusion stochastic denoising procedure. Through the reduction of the number of total diffusion steps, we are able to speed up both the forward and backward processes. More importantly, we improve the expressive power of diffusion models by employing both deterministic and stochastic mappings. Experiments on standard image generation datasets demonstrate the advantage of the proposed method over existing approaches. On the unconditional CIFAR10 dataset, for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method also demonstrates competitive performance on CelebA-HQ-256 dataset as it obtains an FID score of 7.11. Code is available at https://github.com/MohsenZand/DiNof.
</details>
<details>
<summary>摘要</summary>
For faster sampling and higher sample quality, we propose DiNof (diffusion with normalizing flow priors), a technique that combines normalizing flows and diffusion models. We use normalizing flows to parameterize the noisy data at any arbitrary step of the diffusion process and use it as the prior in the reverse diffusion process. Specifically, the forward noising process converts a data distribution into partially noisy data, which are then transformed into a Gaussian distribution through a nonlinear process. The backward denoising process starts with a prior created by sampling from the Gaussian distribution and applying invertible normalizing flow transformations deterministically. The prior then undergoes the remaining diffusion stochastic denoising procedure to generate the data distribution. By reducing the number of total diffusion steps, we can speed up both the forward and backward processes. Moreover, we improve the expressive power of diffusion models by using both deterministic and stochastic mappings. Experimental results on standard image generation datasets show the advantage of our proposed method over existing approaches. On the unconditional CIFAR10 dataset, for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method also demonstrates competitive performance on the CelebA-HQ-256 dataset, with an FID score of 7.11. Code is available at https://github.com/MohsenZand/DiNof.Here's the translation in Traditional Chinese:为了更快速的抽样和提高抽样质量，我们提出了DiNof（diffusion with normalizing flow priors）技术，该技术结合了normalizing flows和diffusion models。我们使用normalizing flows来对任意步骤的diffusion проце程中的噪声数据进行参数化，并将其用作反diffusion проце程中的假设。具体来说，前向噪声过程将数据分布转换成部分噪声的数据，然后通过非线性过程将其转换为Gaussian分布。反对噪声过程从Gaussian分布中随机抽样获得一个假设，并通过实现可逆的normalizing flow对应映射来确定性地将其转换为数据分布。通过缩减总diffusion步骤数量，我们可以快速化前向和反对噪声过程。更重要的是，我们通过使用deterministic和stochastic mapping来提高diffusion模型的表达力。实验结果显示，我们在标准的图像生成 dataset上比较其他方法表现出色，例如在CIFAR10 dataset上，我们获得了FID值为2.01和inception值为9.96。我们的方法也在CelebA-HQ-256 dataset上表现出色，FID值为7.11。相关的代码可以在https://github.com/MohsenZand/DiNof上获取。
</details></li>
</ul>
<hr>
<h2 id="SOAR-Scene-debiasing-Open-set-Action-Recognition"><a href="#SOAR-Scene-debiasing-Open-set-Action-Recognition" class="headerlink" title="SOAR: Scene-debiasing Open-set Action Recognition"></a>SOAR: Scene-debiasing Open-set Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01265">http://arxiv.org/abs/2309.01265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yhZhai/SOAR">https://github.com/yhZhai/SOAR</a></li>
<li>paper_authors: Yuanhao Zhai, Ziyi Liu, Zhenyu Wu, Yi Wu, Chunluan Zhou, David Doermann, Junsong Yuan, Gang Hua</li>
<li>for:  mitigating the risk of utilizing spurious clues in open-set action recognition</li>
<li>methods:  adversarial scene reconstruction module, adaptive adversarial scene classification module</li>
<li>results:  better mitigation of scene bias, outperformance of state-of-the-art methodsHere’s the simplified Chinese text:</li>
<li>for: 开普设置动作识别中减少背景信息</li>
<li>methods:  adversarial scene reconstruction module, adaptive adversarial scene classification module</li>
<li>results: 更好地减少场景偏见, 超过当前最佳方法表现I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Deep learning models have a risk of utilizing spurious clues to make predictions, such as recognizing actions based on the background scene. This issue can severely degrade the open-set action recognition performance when the testing samples have different scene distributions from the training samples. To mitigate this problem, we propose a novel method, called Scene-debiasing Open-set Action Recognition (SOAR), which features an adversarial scene reconstruction module and an adaptive adversarial scene classification module. The former prevents the decoder from reconstructing the video background given video features, and thus helps reduce the background information in feature learning. The latter aims to confuse scene type classification given video features, with a specific emphasis on the action foreground, and helps to learn scene-invariant information. In addition, we design an experiment to quantify the scene bias. The results indicate that the current open-set action recognizers are biased toward the scene, and our proposed SOAR method better mitigates such bias. Furthermore, our extensive experiments demonstrate that our method outperforms state-of-the-art methods, and the ablation studies confirm the effectiveness of our proposed modules.
</details>
<details>
<summary>摘要</summary>
深度学习模型可能会利用干扰信号来做预测，如recognize动作基于背景场景。这个问题可能会严重降低开集动作认识性能，因为测试样本的场景分布与训练样本不同。为了解决这个问题，我们提出了一种新方法，叫做Scene-debiasing Open-set Action Recognition（SOAR），它包括一个对抗场景重建模块和一个适应对抗场景分类模块。前者防止解码器基于视频特征重建视频背景，从而减少视频背景的影响。后者强调动作前景，尝试使场景类型分类不分化，以学习场景不变的信息。此外，我们设计了一个测量场景偏见的实验。结果表明，当前的开集动作认识器偏向场景，而我们提出的SOAR方法更好地 mitigates such bias。此外，我们的广泛实验表明，我们的方法高效地超过了当前的状态实验，而ablation studies也证明了我们的提出的模块的效果。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Contrastive-Learning-with-Hard-Negative-Sampling-for-Human-Activity-Recognition"><a href="#Multimodal-Contrastive-Learning-with-Hard-Negative-Sampling-for-Human-Activity-Recognition" class="headerlink" title="Multimodal Contrastive Learning with Hard Negative Sampling for Human Activity Recognition"></a>Multimodal Contrastive Learning with Hard Negative Sampling for Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01262">http://arxiv.org/abs/2309.01262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeongju Choi, Apoorva Beedu, Irfan Essa</li>
<li>for: 这种研究旨在提高人员活动识别（HAR）系统的性能，特别是在日常生活中使用自助学习方法，以减少 annotated data 的成本和困难。</li>
<li>methods: 我们提出了一种基于强负样本选择的自助学习方法，使用硬负样本损失函数，并在 Camera 和 IMU 感知器数据集上进行实验。</li>
<li>results: 我们的方法在两个标准 benchmark 数据集上（UTD-MHAD 和 MMAct）表现出色，在有限数据设置下学习强的特征表示，并在下游活动识别任务中超过了所有现有的状态艺术方法。<details>
<summary>Abstract</summary>
Human Activity Recognition (HAR) systems have been extensively studied by the vision and ubiquitous computing communities due to their practical applications in daily life, such as smart homes, surveillance, and health monitoring.   Typically, this process is supervised in nature and the development of such systems requires access to large quantities of annotated data.   However, the higher costs and challenges associated with obtaining good quality annotations have rendered the application of self-supervised methods an attractive option and contrastive learning comprises one such method.   However, a major component of successful contrastive learning is the selection of good positive and negative samples.   Although positive samples are directly obtainable, sampling good negative samples remain a challenge.   As human activities can be recorded by several modalities like camera and IMU sensors, we propose a hard negative sampling method for multimodal HAR with a hard negative sampling loss for skeleton and IMU data pairs.   We exploit hard negatives that have different labels from the anchor but are projected nearby in the latent space using an adjustable concentration parameter.   Through extensive experiments on two benchmark datasets: UTD-MHAD and MMAct, we demonstrate the robustness of our approach forlearning strong feature representation for HAR tasks, and on the limited data setting.   We further show that our model outperforms all other state-of-the-art methods for UTD-MHAD dataset, and self-supervised methods for MMAct: Cross session, even when uni-modal data are used during downstream activity recognition.
</details>
<details>
<summary>摘要</summary>
人工活动识别（HAR）系统在视觉和无限计算领域得到了广泛的研究，因为它在日常生活中有很多实际应用，如智能家居、监测和健康监测。 Typically, this process is supervised in nature, and the development of such systems requires access to large amounts of annotated data. However, the higher costs and challenges associated with obtaining good quality annotations have made self-supervised methods an attractive option. Contrastive learning is one such method, but selecting good positive and negative samples is a major challenge. Although positive samples are directly obtainable, sampling good negative samples remains a challenge.为解决这个问题，我们提出了一种困难的负样本选择方法 для多modal HAR，并使用一个可调的集中参数来选择硬负样本。 We exploit hard negatives that have different labels from the anchor but are projected nearby in the latent space. Through extensive experiments on two benchmark datasets: UTD-MHAD and MMAct, we demonstrate the robustness of our approach for learning strong feature representations for HAR tasks, and on limited data settings. We further show that our model outperforms all other state-of-the-art methods for UTD-MHAD dataset, and self-supervised methods for MMAct: Cross session, even when uni-modal data are used during downstream activity recognition.
</details></li>
</ul>
<hr>
<h2 id="S2RF-Semantically-Stylized-Radiance-Fields"><a href="#S2RF-Semantically-Stylized-Radiance-Fields" class="headerlink" title="S2RF: Semantically Stylized Radiance Fields"></a>S2RF: Semantically Stylized Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01252">http://arxiv.org/abs/2309.01252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dishani Lahiri, Neeraj Panse, Moneish Kumar</li>
<li>for: 提供一种将任意图像中的风格传递到3D场景中的对象上的方法。</li>
<li>methods: 提议一种 nearest neighborhood-based loss 的新方法，以实现更好的3D场景重建和灵活的风格定制，同时保证多视角准确性。</li>
<li>results: 方法可以实现自由的3D场景重建和灵活的风格定制，并保证多视角准确性。<details>
<summary>Abstract</summary>
We present our method for transferring style from any arbitrary image(s) to object(s) within a 3D scene. Our primary objective is to offer more control in 3D scene stylization, facilitating the creation of customizable and stylized scene images from arbitrary viewpoints. To achieve this, we propose a novel approach that incorporates nearest neighborhood-based loss, allowing for flexible 3D scene reconstruction while effectively capturing intricate style details and ensuring multi-view consistency.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，可以将任意图像中的风格传递到3D场景中的对象上。我们的主要目标是为3D场景增加个性化风格控制，以便从任意视角创建个性化和风格化的场景图像。为 достичь这个目标，我们提议一种新的方法，该方法包括最近邻域基于的损失函数，可以在3D场景重建中 flexible 地捕捉细节，同时保证多视角一致性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Generic-Image-Manipulation-Detection-with-Weakly-Supervised-Self-Consistency-Learning"><a href="#Towards-Generic-Image-Manipulation-Detection-with-Weakly-Supervised-Self-Consistency-Learning" class="headerlink" title="Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning"></a>Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01246">http://arxiv.org/abs/2309.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yhZhai/WSCL">https://github.com/yhZhai/WSCL</a></li>
<li>paper_authors: Yuanhao Zhai, Tianyu Luan, David Doermann, Junsong Yuan<br>for: 本文主要针对于强制性较低的图像修饰检测问题，以便利用更多的训练图像和快速适应新的修饰技术。methods: 本文提出了一种弱类supervised自适应学习方法，仅需要图像水平的二分类标签（真实或修饰）进行训练。该方法利用了多种内容无关的信息，通过在线pseudo标签生成和优化过程实现了跨源学习。此外，本文还提出了一种inter-patch consistency（IPC）方法，可以找到整个修饰区域。results: 实验表明，even though our方法是弱类supervised的，它在受检测图像是否修饰的情况下，与完全supervised方法相比，具有竞争性的性能，并且可以准确地找到修饰区域。<details>
<summary>Abstract</summary>
As advanced image manipulation techniques emerge, detecting the manipulation becomes increasingly important. Despite the success of recent learning-based approaches for image manipulation detection, they typically require expensive pixel-level annotations to train, while exhibiting degraded performance when testing on images that are differently manipulated compared with training images. To address these limitations, we propose weakly-supervised image manipulation detection, such that only binary image-level labels (authentic or tampered with) are required for training purpose. Such a weakly-supervised setting can leverage more training images and has the potential to adapt quickly to new manipulation techniques. To improve the generalization ability, we propose weakly-supervised self-consistency learning (WSCL) to leverage the weakly annotated images. Specifically, two consistency properties are learned: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits different content-agnostic information and enables cross-source learning via an online pseudo label generation and refinement process. IPC performs global pair-wise patch-patch relationship reasoning to discover a complete region of manipulation. Extensive experiments validate that our WSCL, even though is weakly supervised, exhibits competitive performance compared with fully-supervised counterpart under both in-distribution and out-of-distribution evaluations, as well as reasonable manipulation localization ability.
</details>
<details>
<summary>摘要</summary>
As advanced image manipulation techniques emerge, detecting the manipulation becomes increasingly important. Despite the success of recent learning-based approaches for image manipulation detection, they typically require expensive pixel-level annotations to train, while exhibiting degraded performance when testing on images that are differently manipulated compared with training images. To address these limitations, we propose weakly-supervised image manipulation detection, such that only binary image-level labels (authentic or tampered with) are required for training purpose. Such a weakly-supervised setting can leverage more training images and has the potential to adapt quickly to new manipulation techniques. To improve the generalization ability, we propose weakly-supervised self-consistency learning (WSCL) to leverage the weakly annotated images. Specifically, two consistency properties are learned: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits different content-agnostic information and enables cross-source learning via an online pseudo label generation and refinement process. IPC performs global pair-wise patch-patch relationship reasoning to discover a complete region of manipulation. Extensive experiments validate that our WSCL, even though is weakly supervised, exhibits competitive performance compared with fully-supervised counterpart under both in-distribution and out-of-distribution evaluations, as well as reasonable manipulation localization ability.Here's the translation in Traditional Chinese:为了应对进阶图像修饰技术的出现，检测修饰成本日益重要。 despite recent learning-based approaches for image manipulation detection的成功，它们通常需要高昂的像素级标注来训练，而且在训练和测试图像不同的修饰方法时，表现会下降。为了解决这些限制，我们提出了弱型图像修饰检测，仅需要图像水平标注（真实或伪造）来训练。这样的弱型设定可以对更多的训练图像进行学习，并且具有适应新修饰技术的潜力。为了提高普遍性，我们提出了弱型自适应学习（WSCL），以利用弱型标注图像。具体来说，我们学习了两种一致性属性：多源一致性（MSC）和间接图像一致性（IPC）。MSC 利用不同内容不相关的信息，并允许跨源学习 via 线上 pseudo 标签生成和修正过程。IPC 执行全域对 patch-patch 关系的全球推理，以发现修饰区域。实验显示，我们的 WSCL ，即使是弱型学习，在两个分布中的评估中表现竞争性好，以及修饰地域的实际能力。
</details></li>
</ul>
<hr>
<h2 id="BodySLAM-Fast-and-Tightly-Coupled-Visual-Inertial-Camera-and-Human-Motion-Tracking"><a href="#BodySLAM-Fast-and-Tightly-Coupled-Visual-Inertial-Camera-and-Human-Motion-Tracking" class="headerlink" title="BodySLAM++: Fast and Tightly-Coupled Visual-Inertial Camera and Human Motion Tracking"></a>BodySLAM++: Fast and Tightly-Coupled Visual-Inertial Camera and Human Motion Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01236">http://arxiv.org/abs/2309.01236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dorian F. Henning, Christopher Choi, Simon Schaefer, Stefan Leutenegger</li>
<li>for: 这篇论文是为了解决人体状态估计问题，尤其是在实际应用中需要实时估计人体状态的情况下。</li>
<li>methods: 该论文使用了视觉感知和自适应器来实现人体和摄像头状态估计，并将现有的视觉感知状态估计框架OKVIS2扩展到同时解决人体和摄像头状态估计的双重任务。</li>
<li>results: 相比基准方法，该方法可以提高人体状态估计的准确性和摄像头状态估计的准确性，并在Intel i7-模型CPU上实现15+帧每秒的实时性。<details>
<summary>Abstract</summary>
Robust, fast, and accurate human state - 6D pose and posture - estimation remains a challenging problem. For real-world applications, the ability to estimate the human state in real-time is highly desirable. In this paper, we present BodySLAM++, a fast, efficient, and accurate human and camera state estimation framework relying on visual-inertial data. BodySLAM++ extends an existing visual-inertial state estimation framework, OKVIS2, to solve the dual task of estimating camera and human states simultaneously. Our system improves the accuracy of both human and camera state estimation with respect to baseline methods by 26% and 12%, respectively, and achieves real-time performance at 15+ frames per second on an Intel i7-model CPU. Experiments were conducted on a custom dataset containing both ground truth human and camera poses collected with an indoor motion tracking system.
</details>
<details>
<summary>摘要</summary>
Robust、快速、精确的人体状态估算——6D姿态和姿态——仍然是一个挑战性的问题。在实际应用中，可以在实时中估算人体状态是非常感兴趣的。在这篇论文中，我们提出了BodySLAM++，一种基于视觉-陀螺数据的人体和摄像头状态估算框架。BodySLAM++在OKVIS2视觉-陀螺状态估算框架的基础上进行了扩展，同时解决了同时估算摄像头和人体状态的两个任务。我们的系统相比基准方法提高了人体和摄像头状态估算的准确性，增加了26%和12%，并在Intel i7-型CPU上实现了15+帧每秒的实时性。我们在一个自定义的人体和摄像头pose的数据集上进行了实验。
</details></li>
</ul>
<hr>
<h2 id="Generalizability-and-Application-of-the-Skin-Reflectance-Estimate-Based-on-Dichromatic-Separation-SREDS"><a href="#Generalizability-and-Application-of-the-Skin-Reflectance-Estimate-Based-on-Dichromatic-Separation-SREDS" class="headerlink" title="Generalizability and Application of the Skin Reflectance Estimate Based on Dichromatic Separation (SREDS)"></a>Generalizability and Application of the Skin Reflectance Estimate Based on Dichromatic Separation (SREDS)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01235">http://arxiv.org/abs/2309.01235</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/josephdrahos/sreds">https://github.com/josephdrahos/sreds</a></li>
<li>paper_authors: Joseph Drahos, Richard Plesh, Keivan Bahmani, Mahesh Banavar, Stephanie Schuckers</li>
<li>for: 本研究旨在提供一种可靠的皮肤颜色度量，以便在面 recognition系统中减少因皮肤颜色而导致的性能差异。</li>
<li>methods: 本研究使用了基于 dichromatic separation 的皮肤颜色度量（SREDS），并对其进行了进一步的分析和评估。</li>
<li>results: 研究发现，SREDS 能够创造一个具有较低差异的皮肤颜色度量，并且可以作为自我报告的种族标签的替代方案。此外，研究还提供了一个开源的 SREDS 实现，以帮助研究人员。<details>
<summary>Abstract</summary>
Face recognition (FR) systems have become widely used and readily available in recent history. However, differential performance between certain demographics has been identified within popular FR models. Skin tone differences between demographics can be one of the factors contributing to the differential performance observed in face recognition models. Skin tone metrics provide an alternative to self-reported race labels when such labels are lacking or completely not available e.g. large-scale face recognition datasets. In this work, we provide a further analysis of the generalizability of the Skin Reflectance Estimate based on Dichromatic Separation (SREDS) against other skin tone metrics and provide a use case for substituting race labels for SREDS scores in a privacy-preserving learning solution. Our findings suggest that SREDS consistently creates a skin tone metric with lower variability within each subject and SREDS values can be utilized as an alternative to the self-reported race labels at minimal drop in performance. Finally, we provide a publicly available and open-source implementation of SREDS to help the research community. Available at https://github.com/JosephDrahos/SREDS
</details>
<details>
<summary>摘要</summary>
人脸识别（FR）系统在近代历史中广泛使用和可用。然而， differential performance between certain demographics 在流行的 FR 模型中被识别出来。skin tone differences between demographics can be one of the factors contributing to the differential performance observed in face recognition models。skin tone metrics provide an alternative to self-reported race labels when such labels are lacking or completely not available, for example, large-scale face recognition datasets.在这项工作中，我们进一步分析了Skin Reflectance Estimate based on Dichromatic Separation（SREDS）与其他皮肤颜色指标的一致性，并提供了使用 SREDS  scores substitute for race labels in a privacy-preserving learning solution的用例。我们发现，SREDS  consistently creates a skin tone metric with lower variability within each subject, and SREDS values can be used as an alternative to self-reported race labels at minimal drop in performance。最后，我们提供了一个公共可用的和开源的 SREDS 实现，以帮助研究社区。可以在 <https://github.com/JosephDrahos/SREDS> 查看。
</details></li>
</ul>
<hr>
<h2 id="Spectral-Adversarial-MixUp-for-Few-Shot-Unsupervised-Domain-Adaptation"><a href="#Spectral-Adversarial-MixUp-for-Few-Shot-Unsupervised-Domain-Adaptation" class="headerlink" title="Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation"></a>Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01207">http://arxiv.org/abs/2309.01207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RPIDIAL/SAMix">https://github.com/RPIDIAL/SAMix</a></li>
<li>paper_authors: Jiajin Zhang, Hanqing Chao, Amit Dhurandhar, Pin-Yu Chen, Ali Tajer, Yangyang Xu, Pingkun Yan</li>
<li>for: 本研究旨在 Addressing the challenging problem of few-shot unsupervised domain adaptation (FSUDA) in clinical applications, where only a limited number of unlabeled target domain samples are available for training.</li>
<li>methods: 我们提出了一种新的方法，即 spectral sensitivity map 和 sensitivity-guided spectral adversarial mixup (SAMix) 方法，以强化模型在目标频谱中的一致性和模型通用性。</li>
<li>results: 我们在多个任务和数据集上进行了严谨的评估，并证明了我们的方法可以有效地提高模型在目标频谱中的一致性和模型通用性。<details>
<summary>Abstract</summary>
Domain shift is a common problem in clinical applications, where the training images (source domain) and the test images (target domain) are under different distributions. Unsupervised Domain Adaptation (UDA) techniques have been proposed to adapt models trained in the source domain to the target domain. However, those methods require a large number of images from the target domain for model training. In this paper, we propose a novel method for Few-Shot Unsupervised Domain Adaptation (FSUDA), where only a limited number of unlabeled target domain samples are available for training. To accomplish this challenging task, first, a spectral sensitivity map is introduced to characterize the generalization weaknesses of models in the frequency domain. We then developed a Sensitivity-guided Spectral Adversarial MixUp (SAMix) method to generate target-style images to effectively suppresses the model sensitivity, which leads to improved model generalizability in the target domain. We demonstrated the proposed method and rigorously evaluated its performance on multiple tasks using several public datasets.
</details>
<details>
<summary>摘要</summary>
域名转换是在医疗应用中的一个常见问题，source domain 和 target domain 的图像分布不同。不supervised Domain Adaptation（UDA）技术已经被提议，以适应source domain 中训练的模型到 target domain。然而，这些方法需要大量的target domain图像来训练模型。在这篇论文中，我们提出了一种新的方法：Few-Shot Unsupervised Domain Adaptation（FSUDA），只需要有限量的target domain样本进行训练。为了实现这个复杂的任务，我们首先引入了一个spectral sensitivity map来描述模型在频率域的泛化弱点。然后，我们开发了一种Sensitivity-guided Spectral Adversarial MixUp（SAMix）方法，可以生成target-style图像，以有效地减少模型的敏感性，从而提高模型在target domain的泛化性。我们证明了我们的方法的可行性和对多个任务的精心评估。
</details></li>
</ul>
<hr>
<h2 id="MAGMA-Music-Aligned-Generative-Motion-Autodecoder"><a href="#MAGMA-Music-Aligned-Generative-Motion-Autodecoder" class="headerlink" title="MAGMA: Music Aligned Generative Motion Autodecoder"></a>MAGMA: Music Aligned Generative Motion Autodecoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01202">http://arxiv.org/abs/2309.01202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sohan Anisetty, Amit Raj, James Hays</li>
<li>for: 这 paper 的目的是解决将乐曲映射到舞蹈中的问题，以实现空间和时间协调，同时与乐曲的进程保持同步。</li>
<li>methods: 作者使用 Vector Quantized-Variational Autoencoder (VQ-VAE) 和 Transformer 解码器，将动作划分成基本 primitives，并通过对音乐表示的比较来评估音乐表示的重要性。</li>
<li>results: 作者的方法可以实现州际最佳的音乐到动作生成效果，并可以生成较长的动作序列，易于自定义动作序列以满足风格要求。<details>
<summary>Abstract</summary>
Mapping music to dance is a challenging problem that requires spatial and temporal coherence along with a continual synchronization with the music's progression. Taking inspiration from large language models, we introduce a 2-step approach for generating dance using a Vector Quantized-Variational Autoencoder (VQ-VAE) to distill motion into primitives and train a Transformer decoder to learn the correct sequencing of these primitives. We also evaluate the importance of music representations by comparing naive music feature extraction using Librosa to deep audio representations generated by state-of-the-art audio compression algorithms. Additionally, we train variations of the motion generator using relative and absolute positional encodings to determine the effect on generated motion quality when generating arbitrarily long sequence lengths. Our proposed approach achieve state-of-the-art results in music-to-motion generation benchmarks and enables the real-time generation of considerably longer motion sequences, the ability to chain multiple motion sequences seamlessly, and easy customization of motion sequences to meet style requirements.
</details>
<details>
<summary>摘要</summary>
将音乐映射到舞蹈是一个挑战性的问题，需要空间和时间协调以及 continual 同步音乐的进程。引用大语言模型，我们提出了一种 two-step 方法，使用 вектор量化-自适应编码器（VQ-VAE）来压缩动作并训练 transformer 解码器来学习正确的动作顺序。我们还评估音乐表示的重要性，比较 naive 音乐特征提取使用 Librosa 和深度音频表示生成器生成的音频特征。此外，我们在不同的 poz 编码器和绝对 poz 编码器进行训练，以确定在生成长序列时的影响。我们的提出方法在音乐到动作生成标准准则中实现了状态顶峰的结果，可以实时生成较长的动作序列，链接多个动作序列，以及根据风格要求自由定制动作序列。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Dynamic-Frequency-Transformer-for-Image-Fusion-and-Exposure-Correction"><a href="#Holistic-Dynamic-Frequency-Transformer-for-Image-Fusion-and-Exposure-Correction" class="headerlink" title="Holistic Dynamic Frequency Transformer for Image Fusion and Exposure Correction"></a>Holistic Dynamic Frequency Transformer for Image Fusion and Exposure Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01183">http://arxiv.org/abs/2309.01183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoke Shang, Gehui Li, Zhiying Jiang, Shaomin Zhang, Nai Ding, Jinyuan Liu</li>
<li>for: 提高图像质量，解决曝光相关问题</li>
<li>methods: 利用频域回归，替代传统的相关计算，使用全息频域注意力和动态频域前向网络来提取全息信息，并使用拉普拉斯 pyramid  decomposes 图像为不同频率带信息，然后使用多个修复器来恢复特定频率带信息</li>
<li>results: 实现了主流数据集上的最佳Result，为曝光 corrections 等computer vision任务提供了更加细致和协调的解决方案<details>
<summary>Abstract</summary>
The correction of exposure-related issues is a pivotal component in enhancing the quality of images, offering substantial implications for various computer vision tasks. Historically, most methodologies have predominantly utilized spatial domain recovery, offering limited consideration to the potentialities of the frequency domain. Additionally, there has been a lack of a unified perspective towards low-light enhancement, exposure correction, and multi-exposure fusion, complicating and impeding the optimization of image processing. In response to these challenges, this paper proposes a novel methodology that leverages the frequency domain to improve and unify the handling of exposure correction tasks. Our method introduces Holistic Frequency Attention and Dynamic Frequency Feed-Forward Network, which replace conventional correlation computation in the spatial-domain. They form a foundational building block that facilitates a U-shaped Holistic Dynamic Frequency Transformer as a filter to extract global information and dynamically select important frequency bands for image restoration. Complementing this, we employ a Laplacian pyramid to decompose images into distinct frequency bands, followed by multiple restorers, each tuned to recover specific frequency-band information. The pyramid fusion allows a more detailed and nuanced image restoration process. Ultimately, our structure unifies the three tasks of low-light enhancement, exposure correction, and multi-exposure fusion, enabling comprehensive treatment of all classical exposure errors. Benchmarking on mainstream datasets for these tasks, our proposed method achieves state-of-the-art results, paving the way for more sophisticated and unified solutions in exposure correction.
</details>
<details>
<summary>摘要</summary>
correction of exposure-related issues 是图像质量进步的关键组件，具有广泛的计算机视觉应用场景。历史上，大多数方法ologies 都是在空间领域进行恢复，忽略了频率领域的潜在优势。此外，对于低光照修复、曝光修复和多曝光融合，缺乏一个统一的视角，使得图像处理优化受到妨碍。为了解决这些挑战，本文提出了一种新的方法，利用频率领域来改善和统一曝光修复任务。我们的方法引入全局频率注意力和动态频率预测网络，取代了传统的空间领域相关计算。它们组成了基本建构块，使得U-形全局动态频率变换器作为筛选器，以EXTRACT全局信息和动态选择重要的频率带width。此外，我们采用拉普拉斯 pyramid  decomposed 图像到不同的频率带width，然后使用多个恢复器，每个恢复器都是针对特定频率带width 的信息恢复。pyramid 融合allowing 更加细致和细腻的图像修复过程。最终，我们的结构统一了三个任务：低光照修复、曝光修复和多曝光融合，使得全面地处理所有传统曝光错误。在主流数据集上 benchmarking，我们提出的方法实现了状态之前的成绩，开启了更加复杂和统一的曝光修复解决方案。
</details></li>
</ul>
<hr>
<h2 id="Deep-Unfolding-Convolutional-Dictionary-Model-for-Multi-Contrast-MRI-Super-resolution-and-Reconstruction"><a href="#Deep-Unfolding-Convolutional-Dictionary-Model-for-Multi-Contrast-MRI-Super-resolution-and-Reconstruction" class="headerlink" title="Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction"></a>Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01171">http://arxiv.org/abs/2309.01171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lpcccc-cv/mc-cdic">https://github.com/lpcccc-cv/mc-cdic</a></li>
<li>paper_authors: Pengcheng Lei, Faming Fang, Guixu Zhang, Ming Xu</li>
<li>for: 这个论文主要是为了提出一个基于深度学习的多测量MRI超解析和重建方法，以探索多测量图像之间的联乘关系。</li>
<li>methods: 本文提出了一个叫做多测量 convolutional dictionary（MC-CDic）模型，利用优化算法和构造资料实际关系来实现多测量图像之间的联乘。MC-CDic模型包括建立观察模型、构造多测量字典和使用 proximal 算法来优化模型。</li>
<li>results: 实验结果显示，MC-CDic模型在多测量MRI超解析和重建任务中具有较高的性能，较以前的State-of-the-Art方法。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) tasks often involve multiple contrasts. Recently, numerous deep learning-based multi-contrast MRI super-resolution (SR) and reconstruction methods have been proposed to explore the complementary information from the multi-contrast images. However, these methods either construct parameter-sharing networks or manually design fusion rules, failing to accurately model the correlations between multi-contrast images and lacking certain interpretations. In this paper, we propose a multi-contrast convolutional dictionary (MC-CDic) model under the guidance of the optimization algorithm with a well-designed data fidelity term. Specifically, we bulid an observation model for the multi-contrast MR images to explicitly model the multi-contrast images as common features and unique features. In this way, only the useful information in the reference image can be transferred to the target image, while the inconsistent information will be ignored. We employ the proximal gradient algorithm to optimize the model and unroll the iterative steps into a deep CDic model. Especially, the proximal operators are replaced by learnable ResNet. In addition, multi-scale dictionaries are introduced to further improve the model performance. We test our MC-CDic model on multi-contrast MRI SR and reconstruction tasks. Experimental results demonstrate the superior performance of the proposed MC-CDic model against existing SOTA methods. Code is available at https://github.com/lpcccc-cv/MC-CDic.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging (MRI) 任务 oftentimes involve multiple contrasts. Recently, numerous deep learning-based multi-contrast MRI super-resolution (SR) and reconstruction methods have been proposed to explore the complementary information from the multi-contrast images. However, these methods either construct parameter-sharing networks or manually design fusion rules, failing to accurately model the correlations between multi-contrast images and lacking certain interpretations.In this paper, we propose a multi-contrast convolutional dictionary (MC-CDic) model under the guidance of the optimization algorithm with a well-designed data fidelity term. Specifically, we bulid an observation model for the multi-contrast MR images to explicitly model the multi-contrast images as common features and unique features. In this way, only the useful information in the reference image can be transferred to the target image, while the inconsistent information will be ignored.We employ the proximal gradient algorithm to optimize the model and unroll the iterative steps into a deep CDic model. Especially, the proximal operators are replaced by learnable ResNet. In addition, multi-scale dictionaries are introduced to further improve the model performance.We test our MC-CDic model on multi-contrast MRI SR and reconstruction tasks. Experimental results demonstrate the superior performance of the proposed MC-CDic model against existing state-of-the-art (SOTA) methods. Code is available at https://github.com/lpcccc-cv/MC-CDic.
</details></li>
</ul>
<hr>
<h2 id="An-Asynchronous-Linear-Filter-Architecture-for-Hybrid-Event-Frame-Cameras"><a href="#An-Asynchronous-Linear-Filter-Architecture-for-Hybrid-Event-Frame-Cameras" class="headerlink" title="An Asynchronous Linear Filter Architecture for Hybrid Event-Frame Cameras"></a>An Asynchronous Linear Filter Architecture for Hybrid Event-Frame Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01159">http://arxiv.org/abs/2309.01159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ziweiwwang/event-asynchronous-filter">https://github.com/ziweiwwang/event-asynchronous-filter</a></li>
<li>paper_authors: Ziwei Wang, Yonhon Ng, Cedric Scheerlinck, Robert Mahony</li>
<li>for: 这篇论文是为了描述一种基于事件和帧camera数据的协同筛选框架，用于重建HDR视频和空间卷积。</li>
<li>methods: 该框架使用了 asynchronous linear filter architecture，将事件和帧camera数据 fusion，以优化HDR视频重建和空间卷积。</li>
<li>results: 对于公共的 datasets，该方法与其他状态艺法比较，在灰度误差率（69.4%减少）和图像相似性指标（均提高35.5%）中表现出色。此外，该框架还可以将图像卷积与线性空间核积合并应用。<details>
<summary>Abstract</summary>
Event cameras are ideally suited to capture High Dynamic Range (HDR) visual information without blur but provide poor imaging capability for static or slowly varying scenes. Conversely, conventional image sensors measure absolute intensity of slowly changing scenes effectively but do poorly on HDR or quickly changing scenes. In this paper, we present an asynchronous linear filter architecture, fusing event and frame camera data, for HDR video reconstruction and spatial convolution that exploits the advantages of both sensor modalities. The key idea is the introduction of a state that directly encodes the integrated or convolved image information and that is updated asynchronously as each event or each frame arrives from the camera. The state can be read-off as-often-as and whenever required to feed into subsequent vision modules for real-time robotic systems. Our experimental results are evaluated on both publicly available datasets with challenging lighting conditions and fast motions, along with a new dataset with HDR reference that we provide. The proposed AKF pipeline outperforms other state-of-the-art methods in both absolute intensity error (69.4% reduction) and image similarity indexes (average 35.5% improvement). We also demonstrate the integration of image convolution with linear spatial kernels Gaussian, Sobel, and Laplacian as an application of our architecture.
</details>
<details>
<summary>摘要</summary>
The key idea is to introduce a state that encodes the integrated or convolved image information and is updated asynchronously as each event or frame arrives from the camera. This state can be read off as often as required to feed into subsequent vision modules for real-time robotic systems. Our experimental results are evaluated on publicly available datasets with challenging lighting conditions and fast motions, as well as a new dataset with HDR reference that we provide.Compared to other state-of-the-art methods, our proposed asynchronous kernel filter (AKF) pipeline achieves a 69.4% reduction in absolute intensity error and an average 35.5% improvement in image similarity indexes. We also demonstrate the integration of image convolution with linear spatial kernels, such as Gaussian, Sobel, and Laplacian, as an application of our architecture.
</details></li>
</ul>
<hr>
<h2 id="LoGoPrompt-Synthetic-Text-Images-Can-Be-Good-Visual-Prompts-for-Vision-Language-Models"><a href="#LoGoPrompt-Synthetic-Text-Images-Can-Be-Good-Visual-Prompts-for-Vision-Language-Models" class="headerlink" title="LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models"></a>LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01155">http://arxiv.org/abs/2309.01155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 提高预训练模型在下游任务中的性能，尤其是图像识别领域</li>
<li>methods: 使用生成的文本图像作为视觉提示，并解决了鸡蛋问题</li>
<li>results: 在16个 datasets上，方法 consistently outperforms 州际方法，包括几个shot学习、基础到新的泛化和领域泛化<details>
<summary>Abstract</summary>
Prompt engineering is a powerful tool used to enhance the performance of pre-trained models on downstream tasks. For example, providing the prompt ``Let's think step by step" improved GPT-3's reasoning accuracy to 63% on MutiArith while prompting ``a photo of" filled with a class name enables CLIP to achieve $80$\% zero-shot accuracy on ImageNet. While previous research has explored prompt learning for the visual modality, analyzing what constitutes a good visual prompt specifically for image recognition is limited. In addition, existing visual prompt tuning methods' generalization ability is worse than text-only prompting tuning. This paper explores our key insight: synthetic text images are good visual prompts for vision-language models! To achieve that, we propose our LoGoPrompt, which reformulates the classification objective to the visual prompt selection and addresses the chicken-and-egg challenge of first adding synthetic text images as class-wise visual prompts or predicting the class first. Without any trainable visual prompt parameters, experimental results on 16 datasets demonstrate that our method consistently outperforms state-of-the-art methods in few-shot learning, base-to-new generalization, and domain generalization.
</details>
<details>
<summary>摘要</summary>
Prompt engineering是一种强大的工具，可以提高预训练模型在下游任务中表现。例如，提供“思考步骤”的提示可以提高GPT-3的逻辑准确率到63%在MutiArith上，而提示“一张”filled with类名可以使CLIP achieve ImageNet上零基本精度80%。而前期研究已经探索了文本模式下的提示学习，但是对于图像识别领域的视觉提示特别是有限的研究。此外，现有的视觉提示调整方法的通用能力比文本只提示调整更差。这篇论文探讨了我们的关键发现：Synthetic text images是良好的视觉提示 для视觉语言模型！为实现这一点，我们提出了LoGoPrompt，它将类型化目标重新定义为视觉提示选择，并解决了鸡蛋问题，即首先添加synthetic text images为类别视觉提示或预测类型。无需任何可训练的视觉提示参数，我们的方法在16个数据集上实验表明， consistently outperform了当前状态的方法在少shot学习、基础到新的泛化和频率泛化上。
</details></li>
</ul>
<hr>
<h2 id="EdaDet-Open-Vocabulary-Object-Detection-Using-Early-Dense-Alignment"><a href="#EdaDet-Open-Vocabulary-Object-Detection-Using-Early-Dense-Alignment" class="headerlink" title="EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment"></a>EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01151">http://arxiv.org/abs/2309.01151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 提高开放词汇物体检测性能，使检测器在基础类别上训练， yet 能够检测新类别。</li>
<li>methods: 使用 CLIP 强大的零上shot认知能力对象级别的嵌入进行对应。</li>
<li>results: 比如，使用 CLIP 对象级别对接 resulted in overfitting to base categories, i.e., novel categories most similar to base categories have particularly poor performance as they are recognized as similar base categories。 In this paper, we propose Early Dense Alignment (EDA) to bridge the gap between generalizable local semantics and object-level prediction.<details>
<summary>Abstract</summary>
Vision-language models such as CLIP have boosted the performance of open-vocabulary object detection, where the detector is trained on base categories but required to detect novel categories. Existing methods leverage CLIP's strong zero-shot recognition ability to align object-level embeddings with textual embeddings of categories. However, we observe that using CLIP for object-level alignment results in overfitting to base categories, i.e., novel categories most similar to base categories have particularly poor performance as they are recognized as similar base categories. In this paper, we first identify that the loss of critical fine-grained local image semantics hinders existing methods from attaining strong base-to-novel generalization. Then, we propose Early Dense Alignment (EDA) to bridge the gap between generalizable local semantics and object-level prediction. In EDA, we use object-level supervision to learn the dense-level rather than object-level alignment to maintain the local fine-grained semantics. Extensive experiments demonstrate our superior performance to competing approaches under the same strict setting and without using external training resources, i.e., improving the +8.4% novel box AP50 on COCO and +3.9% rare mask AP on LVIS.
</details>
<details>
<summary>摘要</summary>
现代视力语言模型，如CLIP，已经提高了开放词汇物体检测的性能，其中检测器在基本类别上训练，但需要检测新类别。现有方法利用CLIP强大的零shot识别能力将对象级别的嵌入与文本类别嵌入相对 alignment。然而，我们发现使用CLIP进行对象级别对 alignment 会导致基本类别最 Similar novel categories 的表现特别差，即基本类别最 Similar novel categories 的表现特别差。在这篇论文中，我们首先发现了现有方法无法具备强大的基础-to-新泛化的能力，因为loss of critical fine-grained local image semantics 阻碍了现有方法的提升。然后，我们提出了 Early Dense Alignment (EDA) 方法，用于补做这个障碍。在 EDA 中，我们使用对象级别的超级vised learning 来学习 dense-level 的对ignment，以保持本地细致的 semantics。我们的实验表明，我们在同样的严格设定下，不使用外部训练资源，可以提高 COCO 上的 +8.4% novel box AP50 和 LVIS 上的 +3.9% rare mask AP。
</details></li>
</ul>
<hr>
<h2 id="VGDiffZero-Text-to-image-Diffusion-Models-Can-Be-Zero-shot-Visual-Grounders"><a href="#VGDiffZero-Text-to-image-Diffusion-Models-Can-Be-Zero-shot-Visual-Grounders" class="headerlink" title="VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders"></a>VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01141">http://arxiv.org/abs/2309.01141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuyang Liu, Siteng Huang, Yachen Kang, Honggang Chen, Donglin Wang</li>
<li>for: 这个研究的目的是寻找一个可以实现零shot visual grounding的方法，不需要任何调整和额外的训练数据。</li>
<li>methods: 这个方法基于文本与图像散射模型，并提出了一个简单又有效的零shot visual grounding框架，另外还设计了一个考虑全局和局部 контекст的区域评分方法。</li>
<li>results: 实验结果显示，这个方法在RefCOCO、RefCOCO+和RefCOCOg上实现了优秀的零shot visual grounding性能。<details>
<summary>Abstract</summary>
Large-scale text-to-image diffusion models have shown impressive capabilities across various generative tasks, enabled by strong vision-language alignment obtained through pre-training. However, most vision-language discriminative tasks require extensive fine-tuning on carefully-labeled datasets to acquire such alignment, with great cost in time and computing resources. In this work, we explore directly applying a pre-trained generative diffusion model to the challenging discriminative task of visual grounding without any fine-tuning and additional training dataset. Specifically, we propose VGDiffZero, a simple yet effective zero-shot visual grounding framework based on text-to-image diffusion models. We also design a comprehensive region-scoring method considering both global and local contexts of each isolated proposal. Extensive experiments on RefCOCO, RefCOCO+, and RefCOCOg show that VGDiffZero achieves strong performance on zero-shot visual grounding.
</details>
<details>
<summary>摘要</summary>
大规模文本到图像扩散模型已经在多种生成任务中展现出了吸引人的能力，得益于在预训练中获得的强视语对应性。然而，大多数视语识别任务需要大量的时间和计算资源进行精心 Labeling 数据集来获得这种对应性。在这种情况下，我们研究直接将预训练的生成扩散模型应用到挑战性的视觉识别任务中，无需任何 fine-tuning 和额外的训练数据集。特别是，我们提出了一种简单 yet effective 的零shot 视觉定位框架，称为 VGDiffZero。我们还设计了一种全面的区域分配方法，考虑了每个隔离提案的全局和地方上下文。广泛的实验表明，VGDiffZero 在 RefCOCO、RefCOCO+ 和 RefCOCOg 上达到了零shot 视觉定位的强性表现。
</details></li>
</ul>
<hr>
<h2 id="RSDiff-Remote-Sensing-Image-Generation-from-Text-Using-Diffusion-Model"><a href="#RSDiff-Remote-Sensing-Image-Generation-from-Text-Using-Diffusion-Model" class="headerlink" title="RSDiff: Remote Sensing Image Generation from Text Using Diffusion Model"></a>RSDiff: Remote Sensing Image Generation from Text Using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02455">http://arxiv.org/abs/2309.02455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Sebaq, Mohamed ElHelw</li>
<li>for: This paper is written for remote sensing tasks that require high-quality, detailed satellite images for accurate analysis and decision-making.</li>
<li>methods: The paper proposes an innovative and lightweight approach that employs two-stage diffusion models to generate high-resolution satellite images purely based on text prompts. The approach consists of two interconnected diffusion models: a Low-Resolution Generation Diffusion Model (LR-GDM) and a Super-Resolution Diffusion Model (SRDM).</li>
<li>results: The approach outperforms existing state-of-the-art (SoTA) models in generating satellite images with realistic geographical features, weather conditions, and land structures while achieving remarkable super-resolution results for increased spatial precision.Here’s the Chinese version of the information points:</li>
<li>for: 这篇论文是为Remote Sensing任务而写的，需要高质量、细节准确的卫星图像进行准确分析和决策。</li>
<li>methods: 这篇论文提出了一种创新的、轻量级的方法，使用两个阶段的扩散模型来基于文本提示生成高分辨率卫星图像。该方法包括两个相连的扩散模型：一个低分辨率生成扩散模型（LR-GDM）和一个超分辨率扩散模型（SRDM）。</li>
<li>results: 该方法比现有的State-of-the-Art（SoTA）模型在生成卫星图像方面更高效，能够实现更高的地理特征、天气条件和土地结构的准确描述，同时实现了显著的超分辨率效果以提高空间精度。<details>
<summary>Abstract</summary>
Satellite imagery generation and super-resolution are pivotal tasks in remote sensing, demanding high-quality, detailed images for accurate analysis and decision-making. In this paper, we propose an innovative and lightweight approach that employs two-stage diffusion models to gradually generate high-resolution Satellite images purely based on text prompts. Our innovative pipeline comprises two interconnected diffusion models: a Low-Resolution Generation Diffusion Model (LR-GDM) that generates low-resolution images from text and a Super-Resolution Diffusion Model (SRDM) conditionally produced. The LR-GDM effectively synthesizes low-resolution by (computing the correlations of the text embedding and the image embedding in a shared latent space), capturing the essential content and layout of the desired scenes. Subsequently, the SRDM takes the generated low-resolution image and its corresponding text prompts and efficiently produces the high-resolution counterparts, infusing fine-grained spatial details and enhancing visual fidelity. Experiments are conducted on the commonly used dataset, Remote Sensing Image Captioning Dataset (RSICD). Our results demonstrate that our approach outperforms existing state-of-the-art (SoTA) models in generating satellite images with realistic geographical features, weather conditions, and land structures while achieving remarkable super-resolution results for increased spatial precision.
</details>
<details>
<summary>摘要</summary>
卫星图像生成和超解像是远程感知领域的关键任务，需要高质量、详细的图像 для准确的分析和决策。在这篇论文中，我们提出了一种创新的和轻量级的方法，使用两个链接的扩散模型来逐渐生成高分辨率的卫星图像， purely based on text prompts。我们的创新管道包括两个相连的扩散模型：一个低分辨率生成扩散模型（LR-GDM），通过（计算文本嵌入和图像嵌入在共享尺度空间中的相关性）来有效地生成低分辨率图像，捕捉整个场景的主要内容和布局。然后，SRDM模型会使用生成的低分辨率图像和其相应的文本提示，生成高分辨率对应的图像，注入细致的空间细节，提高视觉准确性。我们在Remote Sensing Image Captioning Dataset（RSICD）上进行了实验，我们的方法比现有的SoTA模型在生成卫星图像的realistic geographical features、天气条件和地形结构方面表现出色，同时实现了很高的超分辨率效果，提高了空间精度。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Supervised-Dual-Search-Leveraging-Automatic-Learning-for-Loss-free-Multi-Exposure-Image-Fusion"><a href="#Hybrid-Supervised-Dual-Search-Leveraging-Automatic-Learning-for-Loss-free-Multi-Exposure-Image-Fusion" class="headerlink" title="Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for Loss-free Multi-Exposure Image Fusion"></a>Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for Loss-free Multi-Exposure Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01113">http://arxiv.org/abs/2309.01113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanyao Wu, Hongming Fu, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 本研究目的是解决多 expose 图像融合中的限制，提高图像的Authentic Representation。</li>
<li>methods: 本文提出了一种 Hybrid-Supervised Dual-Search 方法（HSDS-MEF），它使用自动化设计网络结构和损失函数的双级优化搜索算法。</li>
<li>results: 对比Various competitive schemes，本文实现了state-of-the-art表现，在Visual Information Fidelity（VIF）指标上提高10.61%和4.38%，并提供高对比度、丰富细节和颜色的结果。<details>
<summary>Abstract</summary>
Multi-exposure image fusion (MEF) has emerged as a prominent solution to address the limitations of digital imaging in representing varied exposure levels. Despite its advancements, the field grapples with challenges, notably the reliance on manual designs for network structures and loss functions, and the constraints of utilizing simulated reference images as ground truths. Consequently, current methodologies often suffer from color distortions and exposure artifacts, further complicating the quest for authentic image representation. In addressing these challenges, this paper presents a Hybrid-Supervised Dual-Search approach for MEF, dubbed HSDS-MEF, which introduces a bi-level optimization search scheme for automatic design of both network structures and loss functions. More specifically, we harnesses a unique dual research mechanism rooted in a novel weighted structure refinement architecture search. Besides, a hybrid supervised contrast constraint seamlessly guides and integrates with searching process, facilitating a more adaptive and comprehensive search for optimal loss functions. We realize the state-of-the-art performance in comparison to various competitive schemes, yielding a 10.61% and 4.38% improvement in Visual Information Fidelity (VIF) for general and no-reference scenarios, respectively, while providing results with high contrast, rich details and colors.
</details>
<details>
<summary>摘要</summary>
多曝光图像融合（MEF）已成为现代图像捕捉技术的一个主要解决方案，以 Addressing the limitations of digital imaging in representing varied exposure levels. Despite its advancements, the field is still facing challenges, such as the reliance on manual designs for network structures and loss functions, and the constraints of using simulated reference images as ground truths. As a result, current methodologies often suffer from color distortions and exposure artifacts, further complicating the quest for authentic image representation.To address these challenges, this paper proposes a Hybrid-Supervised Dual-Search approach for MEF, called HSDS-MEF, which introduces a bi-level optimization search scheme for automatic design of both network structures and loss functions. Specifically, we leverage a unique dual research mechanism rooted in a novel weighted structure refinement architecture search. Moreover, a hybrid supervised contrast constraint seamlessly guides and integrates with the searching process, facilitating a more adaptive and comprehensive search for optimal loss functions.We demonstrate the state-of-the-art performance of HSDS-MEF compared to various competitive schemes, with a 10.61% and 4.38% improvement in Visual Information Fidelity (VIF) for general and no-reference scenarios, respectively. The results show high contrast, rich details, and vivid colors.
</details></li>
</ul>
<hr>
<h2 id="ArSDM-Colonoscopy-Images-Synthesis-with-Adaptive-Refinement-Semantic-Diffusion-Models"><a href="#ArSDM-Colonoscopy-Images-Synthesis-with-Adaptive-Refinement-Semantic-Diffusion-Models" class="headerlink" title="ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models"></a>ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01111">http://arxiv.org/abs/2309.01111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/duyooho/arsdm">https://github.com/duyooho/arsdm</a></li>
<li>paper_authors: Yuhao Du, Yuncheng Jiang, Shuangyi Tan, Xusheng Wu, Qi Dou, Zhen Li, Guanbin Li, Xiang Wan</li>
<li>For: 协助临床诊断和治疗，提高残渣检测和识别精度。* Methods: 利用扩展的Diffusion模型，根据扩展的数据分布进行数据生成，并在训练过程中使用基于预训练的分割模型进行纠正。* Results: 对残渣检测和识别任务进行了广泛的实验，发现生成的数据可以显著提高基eline方法的性能。<details>
<summary>Abstract</summary>
Colonoscopy analysis, particularly automatic polyp segmentation and detection, is essential for assisting clinical diagnosis and treatment. However, as medical image annotation is labour- and resource-intensive, the scarcity of annotated data limits the effectiveness and generalization of existing methods. Although recent research has focused on data generation and augmentation to address this issue, the quality of the generated data remains a challenge, which limits the contribution to the performance of subsequent tasks. Inspired by the superiority of diffusion models in fitting data distributions and generating high-quality data, in this paper, we propose an Adaptive Refinement Semantic Diffusion Model (ArSDM) to generate colonoscopy images that benefit the downstream tasks. Specifically, ArSDM utilizes the ground-truth segmentation mask as a prior condition during training and adjusts the diffusion loss for each input according to the polyp/background size ratio. Furthermore, ArSDM incorporates a pre-trained segmentation model to refine the training process by reducing the difference between the ground-truth mask and the prediction mask. Extensive experiments on segmentation and detection tasks demonstrate the generated data by ArSDM could significantly boost the performance of baseline methods.
</details>
<details>
<summary>摘要</summary>
colonoscopy分析，特别是自动复合体划分和检测，对诊断和治疗提供了重要支持。然而，医疗图像注释是劳动和资源浪费的，缺乏注释数据限制了现有方法的效iveness和泛化。尽管最近的研究将着眼于数据生成和扩展来解决这一问题，但生成的数据质量仍然是挑战，这限制了后续任务的贡献。 inspirited by diffuse models的优势在适应数据分布和生成高质量数据，在这篇论文中，我们提出了一种适应改进 semantic diffusion model（ArSDM），用于生成帮助下游任务的colonoscopy图像。具体来说，ArSDM在训练过程中使用了真实分 segmentation mask作为假设条件，并根据复合体/背景大小比进行了diffusion损失的调整。此外，ArSDM还 integrate了预训练分 segmentation模型，以减少真实分 mask和预测 mask之间的差异。对于分 segmentation和检测任务进行了广泛的实验， demonstrate that ArSDM生成的数据可以对基eline方法提供显著的提高。
</details></li>
</ul>
<hr>
<h2 id="AdvMono3D-Advanced-Monocular-3D-Object-Detection-with-Depth-Aware-Robust-Adversarial-Training"><a href="#AdvMono3D-Advanced-Monocular-3D-Object-Detection-with-Depth-Aware-Robust-Adversarial-Training" class="headerlink" title="AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training"></a>AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01106">http://arxiv.org/abs/2309.01106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyuan Li, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 增强monocular 3D对象检测模型的鲁棒性，以应对针对这些模型的攻击。</li>
<li>methods: 我们提出了一种深度意识 adversarial training 方法，包括设计了一种基于 IDP 的攻击，以及一种基于uncertainty的征还学习方法。</li>
<li>results: 我们在 KITTI 3D 数据集上进行了广泛的实验，发现 DART3D 在对抗攻击时比直接对抗训练（最流行的方法）提高了 $AP_{R40}$ 的车类分类表现，升准4.415%、4.112% 和 3.195%。<details>
<summary>Abstract</summary>
Monocular 3D object detection plays a pivotal role in the field of autonomous driving and numerous deep learning-based methods have made significant breakthroughs in this area. Despite the advancements in detection accuracy and efficiency, these models tend to fail when faced with such attacks, rendering them ineffective. Therefore, bolstering the adversarial robustness of 3D detection models has become a crucial issue that demands immediate attention and innovative solutions. To mitigate this issue, we propose a depth-aware robust adversarial training method for monocular 3D object detection, dubbed DART3D. Specifically, we first design an adversarial attack that iteratively degrades the 2D and 3D perception capabilities of 3D object detection models(IDP), serves as the foundation for our subsequent defense mechanism. In response to this attack, we propose an uncertainty-based residual learning method for adversarial training. Our adversarial training approach capitalizes on the inherent uncertainty, enabling the model to significantly improve its robustness against adversarial attacks. We conducted extensive experiments on the KITTI 3D datasets, demonstrating that DART3D surpasses direct adversarial training (the most popular approach) under attacks in 3D object detection $AP_{R40}$ of car category for the Easy, Moderate, and Hard settings, with improvements of 4.415%, 4.112%, and 3.195%, respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>三元射顶3D物体探测在自动驾驶领域扮演重要角色，许多深度学习基础方法在这个领域中获得了重要突破。然而，这些模型对于这些攻击时往往会失败，导致它们无效。因此，增强3D物体探测模型的敌意耐袭性成为了一个紧要的问题，需要获得优先顾及和创新解决方案。为了解决这个问题，我们提出了一个深度感知敌意耐袭训练方法，名为DART3D。具体来说，我们首先设计了一个攻击，逐步对3D物体探测模型（IDP）进行损害， serve as the foundation for our subsequent defense mechanism。对于这个攻击，我们提出了一种不确定性基于的剩余学习方法 для adversarial training。我们的对抗训练方法利用模型的不确定性，使模型能够在攻击下提高其 robustness。我们对KITTI 3D数据集进行了广泛的实验，结果显示，DART3D 在3D物体探测 $AP_{R40}$ 的车辆类别下，在Easy、Moderate和Hard设定下，与直接对抗训练（最受欢迎的方法）相比，增加了4.415%, 4.112%, 3.195%。
</details></li>
</ul>
<hr>
<h2 id="Turn-Fake-into-Real-Adversarial-Head-Turn-Attacks-Against-Deepfake-Detection"><a href="#Turn-Fake-into-Real-Adversarial-Head-Turn-Attacks-Against-Deepfake-Detection" class="headerlink" title="Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection"></a>Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01104">http://arxiv.org/abs/2309.01104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Wang, Zhengyu Zhao, Nicu Sebe, Bruno Lepri</li>
<li>for: 评估深伪检测器的可靠性，检测到深伪视频中的人脸变化。</li>
<li>methods: 基于单个假图像Synthesize face view的方法，实现3D对抗性评估。</li>
<li>results: 对多种检测器进行了广泛的实验， validate了攻击者可以通过AdvHeat在真实场景下取得高攻击成功率（96.8%），并且可以降低步骤数到50。<details>
<summary>Abstract</summary>
Malicious use of deepfakes leads to serious public concerns and reduces people's trust in digital media. Although effective deepfake detectors have been proposed, they are substantially vulnerable to adversarial attacks. To evaluate the detector's robustness, recent studies have explored various attacks. However, all existing attacks are limited to 2D image perturbations, which are hard to translate into real-world facial changes. In this paper, we propose adversarial head turn (AdvHeat), the first attempt at 3D adversarial face views against deepfake detectors, based on face view synthesis from a single-view fake image. Extensive experiments validate the vulnerability of various detectors to AdvHeat in realistic, black-box scenarios. For example, AdvHeat based on a simple random search yields a high attack success rate of 96.8% with 360 searching steps. When additional query access is allowed, we can further reduce the step budget to 50. Additional analyses demonstrate that AdvHeat is better than conventional attacks on both the cross-detector transferability and robustness to defenses. The adversarial images generated by AdvHeat are also shown to have natural looks. Our code, including that for generating a multi-view dataset consisting of 360 synthetic views for each of 1000 IDs from FaceForensics++, is available at https://github.com/twowwj/AdvHeaT.
</details>
<details>
<summary>摘要</summary>
恶意使用深度模仿导致公众对数字媒体的信任减退。虽然有效的深度模仿检测器已经提出，但它们却容易受到反对攻击。为评估检测器的可靠性，latest studies have explored various attacks。然而，所有的攻击都是基于二维图像干扰，这些干扰难以在真实的人脸变化中翻译。在这篇论文中，我们提出了第一个基于三维面视 synthesis的深度模仿攻击方法——对深度模仿检测器的反抗头部攻击（AdvHeat）。我们进行了广泛的实验，证明了各种检测器对AdvHeat的攻击成功率在真实的黑盒enario中很高，例如，基于随机搜索的AdvHeat可以达到96.8%的攻击成功率，只需360步。当允许更多的查询访问时，我们可以进一步降低步数到50。additional analyses表明，AdvHeat比传统攻击更好地在跨检测器的转移性和防御机制上。生成的反对图像也被证明为具有自然的外观。我们的代码，包括生成360个视图的多视图数据集，可以在https://github.com/twowwj/AdvHeaT上下载。
</details></li>
</ul>
<hr>
<h2 id="Dual-Adversarial-Resilience-for-Collaborating-Robust-Underwater-Image-Enhancement-and-Perception"><a href="#Dual-Adversarial-Resilience-for-Collaborating-Robust-Underwater-Image-Enhancement-and-Perception" class="headerlink" title="Dual Adversarial Resilience for Collaborating Robust Underwater Image Enhancement and Perception"></a>Dual Adversarial Resilience for Collaborating Robust Underwater Image Enhancement and Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01102">http://arxiv.org/abs/2309.01102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxi Zhang, Zhiying Jiang, Zeru Shi, Jinyuan Liu, Risheng Liu</li>
<li>for: 提高水下图像的可见度和色彩稳定性，并且提高后续识别任务的精度。</li>
<li>methods: 提出了一种协同对抗鲁棒网络（CARNet），包括一个可逆网络、一种同步进行攻击训练和攻击检测、以及一个攻击模式识别器，以提高图像增强和识别任务的Robustness。</li>
<li>results: 实验结果表明，提出的方法可以输出高质量的增强图像，并且与前STATE-OF-THE-ART方法相比，其识别精度提高了6.71%。<details>
<summary>Abstract</summary>
Due to the uneven scattering and absorption of different light wavelengths in aquatic environments, underwater images suffer from low visibility and clear color deviations. With the advancement of autonomous underwater vehicles, extensive research has been conducted on learning-based underwater enhancement algorithms. These works can generate visually pleasing enhanced images and mitigate the adverse effects of degraded images on subsequent perception tasks. However, learning-based methods are susceptible to the inherent fragility of adversarial attacks, causing significant disruption in results. In this work, we introduce a collaborative adversarial resilience network, dubbed CARNet, for underwater image enhancement and subsequent detection tasks. Concretely, we first introduce an invertible network with strong perturbation-perceptual abilities to isolate attacks from underwater images, preventing interference with image enhancement and perceptual tasks. Furthermore, we propose a synchronized attack training strategy with both visual-driven and perception-driven attacks enabling the network to discern and remove various types of attacks. Additionally, we incorporate an attack pattern discriminator to heighten the robustness of the network against different attacks. Extensive experiments demonstrate that the proposed method outputs visually appealing enhancement images and perform averagely 6.71% higher detection mAP than state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a collaborative adversarial resilience network (CARNet) for underwater image enhancement and detection tasks. The key idea is to use an invertible network with strong perturbation-perceptual abilities to isolate attacks from underwater images, preventing interference with image enhancement and perceptual tasks. Additionally, we propose a synchronized attack training strategy that incorporates both visual-driven and perception-driven attacks, allowing the network to distinguish and remove various types of attacks. To further enhance the robustness of the network, we also incorporate an attack pattern discriminator.Experimental results show that the proposed method outputs visually appealing enhancement images and achieves an average detection mAP of 6.71% higher than state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Infrared-Small-Target-Detection-Robustness-with-Bi-Level-Adversarial-Framework"><a href="#Enhancing-Infrared-Small-Target-Detection-Robustness-with-Bi-Level-Adversarial-Framework" class="headerlink" title="Enhancing Infrared Small Target Detection Robustness with Bi-Level Adversarial Framework"></a>Enhancing Infrared Small Target Detection Robustness with Bi-Level Adversarial Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01099">http://arxiv.org/abs/2309.01099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Liu, Zihang Chen, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 提高小型红外目标检测 against 模糊和干扰背景的稳定性。</li>
<li>methods: 提出了一种 би低级对抗框架，包括learnable生成干扰并 Maximize losses as lower-level objective，以及提高检测器的Robustness promotion as upper-level objective。还提出了一种层次强化学习策略，以发现最有害的干扰并均衡性能和稳定性。</li>
<li>results: 在各种干扰下，提高了21.96% IOU，并在总benchmark上提高了4.97% IOU。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
The detection of small infrared targets against blurred and cluttered backgrounds has remained an enduring challenge. In recent years, learning-based schemes have become the mainstream methodology to establish the mapping directly. However, these methods are susceptible to the inherent complexities of changing backgrounds and real-world disturbances, leading to unreliable and compromised target estimations. In this work, we propose a bi-level adversarial framework to promote the robustness of detection in the presence of distinct corruptions. We first propose a bi-level optimization formulation to introduce dynamic adversarial learning. Specifically, it is composited by the learnable generation of corruptions to maximize the losses as the lower-level objective and the robustness promotion of detectors as the upper-level one. We also provide a hierarchical reinforced learning strategy to discover the most detrimental corruptions and balance the performance between robustness and accuracy. To better disentangle the corruptions from salient features, we also propose a spatial-frequency interaction network for target detection. Extensive experiments demonstrate our scheme remarkably improves 21.96% IOU across a wide array of corruptions and notably promotes 4.97% IOU on the general benchmark. The source codes are available at https://github.com/LiuZhu-CV/BALISTD.
</details>
<details>
<summary>摘要</summary>
探测小型红外目标在杂乱背景下是一个长期不断挑战。在最近几年，学习基于的方法成为了主流方法来建立映射。然而，这些方法容易受到变化背景和真实世界干扰的影响，导致目标估计不可靠和妥协。在这种情况下，我们提出了一种bi-level对抗框架，以提高探测中的Robustness。我们首先提出了bi-level优化形式来引入动态对抗学习。具体来说，它由learnable生成损害来最大化损害作为下一级目标，并且通过提高检测器的Robustness来作为上一级目标。我们还提供了层次强化学习策略，以发现最有害的损害和平衡性能和准确性。为了更好地分离损害和突出特征，我们还提出了一种空间频率交互网络 для目标探测。广泛的实验表明，我们的方案可以remarkably提高21.96% IOU在各种损害下，并且明显提高4.97% IOU在总benchmark上。源代码可以在https://github.com/LiuZhu-CV/BALISTD中下载。
</details></li>
</ul>
<hr>
<h2 id="CoTDet-Affordance-Knowledge-Prompting-for-Task-Driven-Object-Detection"><a href="#CoTDet-Affordance-Knowledge-Prompting-for-Task-Driven-Object-Detection" class="headerlink" title="CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection"></a>CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01093">http://arxiv.org/abs/2309.01093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiajin Tang, Ge Zheng, Jingyi Yu, Sibei Yang</li>
<li>for: 本研究旨在检测图像中适合完成任务的对象实例，挑战在于对象类型过多，不能仅仅依据传统对象检测中的Category列表。</li>
<li>methods: 我们提出了基于基本可行性（Fundamental Affordances）而不是对象类型的方法，即从大量语言模型中提取可行知识，并使用多层链式思维（MLCoT）提取可行知识。</li>
<li>results: 我们的CoTDet方法在比较性评价中表现出色，与状态前方法相比，提高了15.6个盒子AP和14.8个面积AP，并能够生成对象检测的合理理由。<details>
<summary>Abstract</summary>
Task driven object detection aims to detect object instances suitable for affording a task in an image. Its challenge lies in object categories available for the task being too diverse to be limited to a closed set of object vocabulary for traditional object detection. Simply mapping categories and visual features of common objects to the task cannot address the challenge. In this paper, we propose to explore fundamental affordances rather than object categories, i.e., common attributes that enable different objects to accomplish the same task. Moreover, we propose a novel multi-level chain-of-thought prompting (MLCoT) to extract the affordance knowledge from large language models, which contains multi-level reasoning steps from task to object examples to essential visual attributes with rationales. Furthermore, to fully exploit knowledge to benefit object recognition and localization, we propose a knowledge-conditional detection framework, namely CoTDet. It conditions the detector from the knowledge to generate object queries and regress boxes. Experimental results demonstrate that our CoTDet outperforms state-of-the-art methods consistently and significantly (+15.6 box AP and +14.8 mask AP) and can generate rationales for why objects are detected to afford the task.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose exploring fundamental affordances rather than object categories. Affordances are common attributes that enable different objects to accomplish the same task. We also propose a novel multi-level chain-of-thought prompting (MLCoT) to extract affordance knowledge from large language models. This contains multiple levels of reasoning steps from the task to object examples to essential visual attributes with rationales.Furthermore, to fully utilize knowledge to benefit object recognition and localization, we propose a knowledge-conditional detection framework, named CoTDet. This framework conditions the detector based on the knowledge to generate object queries and regress boxes. Experimental results show that our CoTDet outperforms state-of-the-art methods by a consistent and significant margin (+15.6 box AP and +14.8 mask AP) and can generate rationales for why objects are detected to afford the task.
</details></li>
</ul>
<hr>
<h2 id="Face-Clustering-for-Connection-Discovery-from-Event-Images"><a href="#Face-Clustering-for-Connection-Discovery-from-Event-Images" class="headerlink" title="Face Clustering for Connection Discovery from Event Images"></a>Face Clustering for Connection Discovery from Event Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01092">http://arxiv.org/abs/2309.01092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Cheung</li>
<li>for: 这篇论文旨在提出一种基于事件图像的社交连接发现系统，以便无需在线社交图像上获取数据。</li>
<li>methods: 该论文提出了一种基于面 clustering的方法，通过分析事件图像中的人脸印象，找到社交连接。</li>
<li>results: 经过实验， authors 发现可以使用事件图像中的人脸印象来构建社交图，并且可以达到 80% 的 F1 分数。<details>
<summary>Abstract</summary>
Social graphs are very useful for many applications, such as recommendations and community detections. However, they are only accessible to big social network operators due to both data availability and privacy concerns. Event images also capture the interactions among the participants, from which social connections can be discovered to form a social graph. Unlike online social graphs, social connections carried by event images can be extracted without user inputs, and hence many social graph-based applications become possible, even without access to online social graphs. This paper proposes a system to discover social connections from event images. By utilizing the social information from even images, such as co-occurrence, a face clustering method is proposed and implemented, and connections can be discovered without the identity of the event participants. By collecting over 40000 faces from over 3000 participants, it is shown that the faces can be well clustered with 80% in F1 score, and social graphs can be constructed. Utilizing offline event images may create a long-term impact on social network analytics.
</details>
<details>
<summary>摘要</summary>
社交图是非常有用于多种应用程序，如推荐和社群检测。然而，它们只能被大型社交网络运营商访问，因为数据可用性和隐私问题。事件图像也捕捉参与者之间的互动，从而可以构建社交图。与在线社交图不同，基于事件图像的社交连接可以无需用户输入抽象，因此许多基于社交图应用程序变得可能，甚至无需访问在线社交图。这篇论文提议一种基于事件图像的社交连接发现系统。通过使用事件图像中的社交信息，如共处，一种面 clustering 方法被提出并实现，并可以无需参与者身份信息发现社交连接。通过收集超过 40000 张面和超过 3000 名参与者，显示可以很好地将面 clustering 得到 80% 的 F1 分数，并构建社交图。使用离线事件图像可能会对社交网络分析产生长期影响。
</details></li>
</ul>
<hr>
<h2 id="MILA-Memory-Based-Instance-Level-Adaptation-for-Cross-Domain-Object-Detection"><a href="#MILA-Memory-Based-Instance-Level-Adaptation-for-Cross-Domain-Object-Detection" class="headerlink" title="MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection"></a>MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01086">http://arxiv.org/abs/2309.01086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onkar Krishna, Hiroki Ohashi, Saptarshi Sinha</li>
<li>for: 这种论文是为了解决跨Domain对象检测中的困难问题，特别是对于不同领域之间的对应关系的建立。</li>
<li>methods: 这种方法使用了对抗学习来对像级和实例级的特征进行对齐。具体来说，它使用了一个内存模块来存储所有标注源实例的卷积特征，并使用一个简单 yet effective的内存检索模块来为目标实例检索最相似的源实例。</li>
<li>results: 这种方法在不同领域之间的对应关系建立方面具有显著的优势，比如在不同领域的对象检测任务中，它的性能都高于非内存基于的方法。<details>
<summary>Abstract</summary>
Cross-domain object detection is challenging, and it involves aligning labeled source and unlabeled target domains. Previous approaches have used adversarial training to align features at both image-level and instance-level. At the instance level, finding a suitable source sample that aligns with a target sample is crucial. A source sample is considered suitable if it differs from the target sample only in domain, without differences in unimportant characteristics such as orientation and color, which can hinder the model's focus on aligning the domain difference. However, existing instance-level feature alignment methods struggle to find suitable source instances because their search scope is limited to mini-batches. Mini-batches are often so small in size that they do not always contain suitable source instances. The insufficient diversity of mini-batches becomes problematic particularly when the target instances have high intra-class variance. To address this issue, we propose a memory-based instance-level domain adaptation framework. Our method aligns a target instance with the most similar source instance of the same category retrieved from a memory storage. Specifically, we introduce a memory module that dynamically stores the pooled features of all labeled source instances, categorized by their labels. Additionally, we introduce a simple yet effective memory retrieval module that retrieves a set of matching memory slots for target instances. Our experiments on various domain shift scenarios demonstrate that our approach outperforms existing non-memory-based methods significantly.
</details>
<details>
<summary>摘要</summary>
域外对象检测是一项挑战性任务，需要对来源和目标域进行对齐。先前的方法通过对抗学习来实现对像水平和实例水平的对齐。在实例水平上，找到一个适合的来源实例是关键。一个来源实例被视为适合的，只要它与目标实例在域之间差异，而不是在不重要的特征如旋转和颜色上差异，这些特征可能会使模型忽略对域差异的对齐。然而，现有的实例级别的特征对齐方法很难找到适合的来源实例，因为它们的搜索范围仅限于 мини-批。 мини-批通常很小，因此不一定包含适合的来源实例。这种缺乏多样性的问题特别是在目标实例具有高内类变异时变得更加突出。为解决这个问题，我们提出了一种带有内存的实例级别域适应框架。我们的方法将目标实例与同类标签的最相似来源实例进行对齐，而不是通过搜索 mini-批中的来源实例。具体来说，我们引入了一个内存模块，该模块在 Label 分类下将所有标注源实例的归一化特征存储在内存中。此外，我们还引入了一个简单 yet effective的内存检索模块，该模块可以将目标实例与内存中的匹配记录进行对比。我们的实验表明，我们的方法在不同的域转移enario中与非带内存的方法相比显著性能更高。
</details></li>
</ul>
<hr>
<h2 id="Chinese-Text-Recognition-with-A-Pre-Trained-CLIP-Like-Model-Through-Image-IDS-Aligning"><a href="#Chinese-Text-Recognition-with-A-Pre-Trained-CLIP-Like-Model-Through-Image-IDS-Aligning" class="headerlink" title="Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning"></a>Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01083">http://arxiv.org/abs/2309.01083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Yu, Xiaocong Wang, Bin Li, Xiangyang Xue</li>
<li>for: 提高中文文本识别精度和普适性</li>
<li>methods: 使用人工智能模型进行中文字符预训练，并将学习的表示映射到文本识别模型中进行优化</li>
<li>results: 在中文字符识别和文本识别任务中表现出色，超过了之前的方法在大多数场景下Translation:</li>
<li>for: 提高中文文本识别精度和普适性</li>
<li>methods: 使用人工智能模型进行中文字符预训练，并将学习的表示映射到文本识别模型中进行优化</li>
<li>results: 在中文字符识别和文本识别任务中表现出色，超过了之前的方法在大多数场景下<details>
<summary>Abstract</summary>
Scene text recognition has been studied for decades due to its broad applications. However, despite Chinese characters possessing different characteristics from Latin characters, such as complex inner structures and large categories, few methods have been proposed for Chinese Text Recognition (CTR). Particularly, the characteristic of large categories poses challenges in dealing with zero-shot and few-shot Chinese characters. In this paper, inspired by the way humans recognize Chinese texts, we propose a two-stage framework for CTR. Firstly, we pre-train a CLIP-like model through aligning printed character images and Ideographic Description Sequences (IDS). This pre-training stage simulates humans recognizing Chinese characters and obtains the canonical representation of each character. Subsequently, the learned representations are employed to supervise the CTR model, such that traditional single-character recognition can be improved to text-line recognition through image-IDS matching. To evaluate the effectiveness of the proposed method, we conduct extensive experiments on both Chinese character recognition (CCR) and CTR. The experimental results demonstrate that the proposed method performs best in CCR and outperforms previous methods in most scenarios of the CTR benchmark. It is worth noting that the proposed method can recognize zero-shot Chinese characters in text images without fine-tuning, whereas previous methods require fine-tuning when new classes appear. The code is available at https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR.
</details>
<details>
<summary>摘要</summary>
scene文本识别已经受到了多年的研究，因为它有广泛的应用场景。然而，尽管中文字体具有不同的特点，如复杂的内部结构和大量的类别，但只有少数方法被提出来用于中文文本识别（CTR）。特别是，大类划分带来了对零Instance和少Instance中文字体的挑战。在这篇论文中，我们提出了一个基于人类识别中文文本的两stage框架。首先，我们通过对印刷字体图像和意图描述序列（IDS）进行对齐，预训练一个类似于CLIP的模型。这个预训练阶段模拟了人类识别中文字体，并从图像和IDS获得了每个字体的征识性表示。然后，学习的表示被用来监督CTR模型，以改进传统的单个字体识别，并将其扩展到文本图像与IDS匹配。为评估提案的效果，我们进行了广泛的实验，包括中文字体识别（CCR）和CTR。实验结果显示，提案的方法在CCR中表现最佳，并在大多数CTR标准各种场景中超过了先前的方法。值得注意的是，提案的方法可以在文本图像中识别零Instance中文字体，而不需要调整。相比之下，先前的方法在新类型出现时需要调整。代码可以在https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR中找到。
</details></li>
</ul>
<hr>
<h2 id="Orientation-Independent-Chinese-Text-Recognition-in-Scene-Images"><a href="#Orientation-Independent-Chinese-Text-Recognition-in-Scene-Images" class="headerlink" title="Orientation-Independent Chinese Text Recognition in Scene Images"></a>Orientation-Independent Chinese Text Recognition in Scene Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01081">http://arxiv.org/abs/2309.01081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Yu, Xiaocong Wang, Bin Li, Xiangyang Xue</li>
<li>for: 本文是为了提高自然场景中的中文文本识别精度而提出的。</li>
<li>methods: 本文使用了一种新的Character Image Reconstruction Network（CIRN）来提取文本图像中的 orientation-independent 视觉特征，以便在自然场景中Robustly 识别水平和垂直文本。</li>
<li>results: 实验结果表明，在一个场景集上，提取Content和orientation信息的方法可以提高文本识别性能，而且在特制的Vertical Chinese Text Recognition（VCTR）集上，该方法可以提高45.63%。<details>
<summary>Abstract</summary>
Scene text recognition (STR) has attracted much attention due to its broad applications. The previous works pay more attention to dealing with the recognition of Latin text images with complex backgrounds by introducing language models or other auxiliary networks. Different from Latin texts, many vertical Chinese texts exist in natural scenes, which brings difficulties to current state-of-the-art STR methods. In this paper, we take the first attempt to extract orientation-independent visual features by disentangling content and orientation information of text images, thus recognizing both horizontal and vertical texts robustly in natural scenes. Specifically, we introduce a Character Image Reconstruction Network (CIRN) to recover corresponding printed character images with disentangled content and orientation information. We conduct experiments on a scene dataset for benchmarking Chinese text recognition, and the results demonstrate that the proposed method can indeed improve performance through disentangling content and orientation information. To further validate the effectiveness of our method, we additionally collect a Vertical Chinese Text Recognition (VCTR) dataset. The experimental results show that the proposed method achieves 45.63% improvement on VCTR when introducing CIRN to the baseline model.
</details>
<details>
<summary>摘要</summary>
Scene文本识别（STR）在广泛应用领域中受到了广泛关注。先前的研究更多地关注了处理复杂背景的拉丁文本图像的识别，通过语言模型或其他辅助网络。与拉丁文本不同，自然场景中存在许多垂直的中文文本，这带来了当前状态的STR方法的困难。在这篇论文中，我们首次尝试提取不受方向影响的视觉特征，通过分离内容和方向信息来识别自然场景中的垂直和水平文本。我们引入了Character Image Reconstruction Network（CIRN）来重建相应的打印字符图像，并提取了内容和方向信息的分离。我们对一个场景集进行了测试，并得到了提高性的结果。为了进一步验证我们的方法的有效性，我们还收集了一个垂直中文文本识别（VCTR）集。实验结果表明，当我们将CIRN添加到基eline模型时，提高了45.63%的性能。
</details></li>
</ul>
<hr>
<h2 id="Robust-Adversarial-Defense-by-Tensor-Factorization"><a href="#Robust-Adversarial-Defense-by-Tensor-Factorization" class="headerlink" title="Robust Adversarial Defense by Tensor Factorization"></a>Robust Adversarial Defense by Tensor Factorization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01077">http://arxiv.org/abs/2309.01077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manish Bhattarai, Mehmet Cagri Kaymak, Ryan Barron, Ben Nebgen, Kim Rasmussen, Boian Alexandrov</li>
<li>for: 防御机器学习模型受到敌意攻击的难题，这种攻击可能会导致模型的性能下降或甚至失败。</li>
<li>methods: 我们的方法利用输入数据的矩阵化和神经网络参数的矩阵化，并将其组合成一种强大的防御策略。</li>
<li>results: 我们的方法能够保持高度的鲁棒性，即使面临最强大的自动攻击也能够维持Robust性。对比已有的防御策略，我们的结果不仅与之匹配，而且还超过了它们。这个研究证明了将矩阵化和低级别分解结合使用的可能性。<details>
<summary>Abstract</summary>
As machine learning techniques become increasingly prevalent in data analysis, the threat of adversarial attacks has surged, necessitating robust defense mechanisms. Among these defenses, methods exploiting low-rank approximations for input data preprocessing and neural network (NN) parameter factorization have shown potential. Our work advances this field further by integrating the tensorization of input data with low-rank decomposition and tensorization of NN parameters to enhance adversarial defense. The proposed approach demonstrates significant defense capabilities, maintaining robust accuracy even when subjected to the strongest known auto-attacks. Evaluations against leading-edge robust performance benchmarks reveal that our results not only hold their ground against the best defensive methods available but also exceed all current defense strategies that rely on tensor factorizations. This study underscores the potential of integrating tensorization and low-rank decomposition as a robust defense against adversarial attacks in machine learning.
</details>
<details>
<summary>摘要</summary>
随着机器学习技术在数据分析中的普及，对抗攻击的威胁也在不断增加，需要开发有力的防御机制。在这些防御机制中，利用输入数据的低级别拟合和神经网络（NN）参数的因式分解方法已经显示出了潜在的可能性。我们的工作将这些方法进一步推广，通过将输入数据的维度化和NN参数的维度化结合使用，以增强对抗攻击的防御能力。我们的提案方法在面对最强大的自动攻击时仍能保持坚固的准确率，并在与现有的防御策略相比表现出色。这一研究表明，将维度化和低级别拟合结合使用可以成为机器学习中对抗攻击的有力防御策略。
</details></li>
</ul>
<hr>
<h2 id="Muti-Stage-Hierarchical-Food-Classification"><a href="#Muti-Stage-Hierarchical-Food-Classification" class="headerlink" title="Muti-Stage Hierarchical Food Classification"></a>Muti-Stage Hierarchical Food Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01075">http://arxiv.org/abs/2309.01075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Pan, Jiangpeng He, Fengqing Zhu</li>
<li>for: 本研究旨在提高食品图像分类的精度，以便从捕捉的食品图像中提取营养成分信息。</li>
<li>methods: 我们提出了一种多stage层次结构的方法，通过Iteratively clustering和合并食品项目 during the training process，使深度模型能够提取图像特征，这些特征在不同的标签之间具有很好的拟合度。</li>
<li>results: 我们在VFN-nutrient数据集上进行了测试，并获得了与现有工作相比的出色的结果，包括食品类别和食品项目分类。<details>
<summary>Abstract</summary>
Food image classification serves as a fundamental and critical step in image-based dietary assessment, facilitating nutrient intake analysis from captured food images. However, existing works in food classification predominantly focuses on predicting 'food types', which do not contain direct nutritional composition information. This limitation arises from the inherent discrepancies in nutrition databases, which are tasked with associating each 'food item' with its respective information. Therefore, in this work we aim to classify food items to align with nutrition database. To this end, we first introduce VFN-nutrient dataset by annotating each food image in VFN with a food item that includes nutritional composition information. Such annotation of food items, being more discriminative than food types, creates a hierarchical structure within the dataset. However, since the food item annotations are solely based on nutritional composition information, they do not always show visual relations with each other, which poses significant challenges when applying deep learning-based techniques for classification. To address this issue, we then propose a multi-stage hierarchical framework for food item classification by iteratively clustering and merging food items during the training process, which allows the deep model to extract image features that are discriminative across labels. Our method is evaluated on VFN-nutrient dataset and achieve promising results compared with existing work in terms of both food type and food item classification.
</details>
<details>
<summary>摘要</summary>
We introduce the VFN-nutrient dataset, annotating each food image in VFN with a food item including nutritional composition information. This hierarchical structure allows for more discriminative annotation of food items. However, the nutritional composition information does not always correspond to visual relations, posing challenges for deep learning-based classification.To address this, we propose a multi-stage hierarchical framework for food item classification. We iteratively cluster and merge food items during training, allowing the deep model to extract image features that are discriminative across labels. Our method is evaluated on the VFN-nutrient dataset and achieves promising results compared to existing works in terms of both food type and food item classification.
</details></li>
</ul>
<hr>
<h2 id="Spatial-and-Visual-Perspective-Taking-via-View-Rotation-and-Relation-Reasoning-for-Embodied-Reference-Understanding"><a href="#Spatial-and-Visual-Perspective-Taking-via-View-Rotation-and-Relation-Reasoning-for-Embodied-Reference-Understanding" class="headerlink" title="Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding"></a>Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01073">http://arxiv.org/abs/2309.01073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ChengShiest/REP-ERU">https://github.com/ChengShiest/REP-ERU</a></li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 本研究的目的是研究语言和姿势的参照理解，即接受者需要根据发送者的语言和姿势在共享物理环境中找到target对象。</li>
<li>methods: 本研究提出了一种基于自己视角的参照理解方法，称为REasoning from your Perspective（REP），该方法通过建立发送者和接受者之间的关系和对象与发送者之间的关系来解决主要挑战。</li>
<li>results: 实验结果表明，REP方法在YouRefIt上的精度达到+5.22%，与所有现有的状态 искусственный智能算法相比，占据了大幅度的优势。<details>
<summary>Abstract</summary>
Embodied Reference Understanding studies the reference understanding in an embodied fashion, where a receiver is required to locate a target object referred to by both language and gesture of the sender in a shared physical environment. Its main challenge lies in how to make the receiver with the egocentric view access spatial and visual information relative to the sender to judge how objects are oriented around and seen from the sender, i.e., spatial and visual perspective-taking. In this paper, we propose a REasoning from your Perspective (REP) method to tackle the challenge by modeling relations between the receiver and the sender and the sender and the objects via the proposed novel view rotation and relation reasoning. Specifically, view rotation first rotates the receiver to the position of the sender by constructing an embodied 3D coordinate system with the position of the sender as the origin. Then, it changes the orientation of the receiver to the orientation of the sender by encoding the body orientation and gesture of the sender. Relation reasoning models the nonverbal and verbal relations between the sender and the objects by multi-modal cooperative reasoning in gesture, language, visual content, and spatial position. Experiment results demonstrate the effectiveness of REP, which consistently surpasses all existing state-of-the-art algorithms by a large margin, i.e., +5.22% absolute accuracy in terms of Prec0.5 on YouRefIt.
</details>
<details>
<summary>摘要</summary>
“人体参照理解”研究者强调在与另一个人共享的物理环境中，语言和手势都指向某个目标物件，并且需要接受者对 sender 的 egocentric 视角进行诠释。这个挑战在于如何让接受者获取 sender 的位置和方向信息，以便对于 sender 所看到的物品进行诠释。在这篇论文中，我们提出了一种基于你的视角（REP）方法，以解决这个挑战。REP 方法包括两个主要步骤：一、使用视角转换来让接受者视角与 sender 的视角进行对接，并且将接受者的视角转换为 sender 的视角。二、使用多modal 协同理解来模型非语言和语言之间的关系，以及物品和接受者之间的关系。实验结果显示，REP 方法能够优于所有现有的州际算法，具体而言，在 YouRefIt 上的 Prec0.5 上提高了 +5.22% 的绝对精度。
</details></li>
</ul>
<hr>
<h2 id="Channel-Attention-Separable-Convolution-Network-for-Skin-Lesion-Segmentation"><a href="#Channel-Attention-Separable-Convolution-Network-for-Skin-Lesion-Segmentation" class="headerlink" title="Channel Attention Separable Convolution Network for Skin Lesion Segmentation"></a>Channel Attention Separable Convolution Network for Skin Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01072">http://arxiv.org/abs/2309.01072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changlu Guo, Jiangyan Dai, Marton Szemenyei, Yugen Yi</li>
<li>for: 静观皮肤恶性肿瘤早期诊断，提高检测精度和效率。</li>
<li>methods: 基于U-Net、DenseNet、分割核、通道注意力和离散尺度 pyramid pooling（ASPP）的新网络：通道注意力分割卷积网络（CASCN）。</li>
<li>results: 在PH2数据集上进行了评估，没有过多预&#x2F;后处理图像，CASCN实现了PH2数据集的最佳性能，Dice相似度0.9461，准确率0.9645。<details>
<summary>Abstract</summary>
Skin cancer is a frequently occurring cancer in the human population, and it is very important to be able to diagnose malignant tumors in the body early. Lesion segmentation is crucial for monitoring the morphological changes of skin lesions, extracting features to localize and identify diseases to assist doctors in early diagnosis. Manual de-segmentation of dermoscopic images is error-prone and time-consuming, thus there is a pressing demand for precise and automated segmentation algorithms. Inspired by advanced mechanisms such as U-Net, DenseNet, Separable Convolution, Channel Attention, and Atrous Spatial Pyramid Pooling (ASPP), we propose a novel network called Channel Attention Separable Convolution Network (CASCN) for skin lesions segmentation. The proposed CASCN is evaluated on the PH2 dataset with limited images. Without excessive pre-/post-processing of images, CASCN achieves state-of-the-art performance on the PH2 dataset with Dice similarity coefficient of 0.9461 and accuracy of 0.9645.
</details>
<details>
<summary>摘要</summary>
皮肤癌是人类常见的癌症，早期诊断非常重要。 lesion segmentation 是监测皮肤损害的重要步骤，提取特征以地址和诊断疾病，帮助医生早期诊断。 手动减少 dermoscopic 图像的步骤是时间consuming 和 error-prone，因此需要精准和自动化的分 segmentation 算法。  Drawing inspiration from advanced mechanisms such as U-Net, DenseNet, Separable Convolution, Channel Attention, and Atrous Spatial Pyramid Pooling (ASPP), we propose a novel network called Channel Attention Separable Convolution Network (CASCN) for skin lesions segmentation. The proposed CASCN is evaluated on the PH2 dataset with limited images. Without excessive pre-/post-processing of images, CASCN achieves state-of-the-art performance on the PH2 dataset with Dice similarity coefficient of 0.9461 and accuracy of 0.9645.Here's the breakdown of the translation:* "皮肤癌" (pí shèi gān) - skin cancer* "常见" (cháng jiàn) - frequently occurring* "早期诊断" (zhāo qiér xiǎng dài) - early diagnosis* "lesion segmentation" (lé shion segmenation) - segmentation of lesions* "重要步骤" (zhòng yào bù shè) - crucial step* "提取特征" (tixiāo tè xíng) - extract features* "地址和诊断" (dì yì yè shì) - localize and identify diseases* "帮助医生" (bāng zhù yī shēng) - assist doctors* "早期诊断" (zhāo qiér xiǎng dài) - early diagnosis* "精准和自动化" (jīn chūn yǔ zì zhì) - precise and automated* "分 segmentation" (fēn biao) - segmentation* "算法" (suān fǎ) - algorithm* "Channel Attention Separable Convolution Network" (CHannel Attention Separable Convolution Network) - proposed network* "PH2 dataset" (PH2 dataset) - dataset used for evaluation* "limited images" (liù yǐng) - limited number of images* "without excessive pre-/post-processing" (yīn wèi zhèng yǐn yǐn) - without extensive pre-/post-processing* "achieves state-of-the-art performance" (dào zhèng yì yì) - achieves state-of-the-art performance* "Dice similarity coefficient" (Dice similarity coefficient) - evaluation metric* "accuracy" ( accuracy) - evaluation metric
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-3D-Video-Information-Retrieval-with-Deep-Neural-Network-and-Bi-directional-Dynamic-time-Warping-Algorithm"><a href="#Semi-supervised-3D-Video-Information-Retrieval-with-Deep-Neural-Network-and-Bi-directional-Dynamic-time-Warping-Algorithm" class="headerlink" title="Semi-supervised 3D Video Information Retrieval with Deep Neural Network and Bi-directional Dynamic-time Warping Algorithm"></a>Semi-supervised 3D Video Information Retrieval with Deep Neural Network and Bi-directional Dynamic-time Warping Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01063">http://arxiv.org/abs/2309.01063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yintai Ma, Diego Klabjan</li>
<li>for: 本研究提出了一种基于视觉内容的半监督深度学习算法，用于检索相似的2D和3D视频。</li>
<li>methods: 该方法结合深度卷积神经网络和循环神经网络，并使用动态时间戳对相似度进行评估。</li>
<li>results: 该方法在多个公共数据集上进行测试，并与状态元深度学习模型进行比较，结果显示该方法在视频检索任务中具有良好的性能。<details>
<summary>Abstract</summary>
This paper presents a novel semi-supervised deep learning algorithm for retrieving similar 2D and 3D videos based on visual content. The proposed approach combines the power of deep convolutional and recurrent neural networks with dynamic time warping as a similarity measure. The proposed algorithm is designed to handle large video datasets and retrieve the most related videos to a given inquiry video clip based on its graphical frames and contents. We split both the candidate and the inquiry videos into a sequence of clips and convert each clip to a representation vector using an autoencoder-backed deep neural network. We then calculate a similarity measure between the sequences of embedding vectors using a bi-directional dynamic time-warping method. This approach is tested on multiple public datasets, including CC\_WEB\_VIDEO, Youtube-8m, S3DIS, and Synthia, and showed good results compared to state-of-the-art. The algorithm effectively solves video retrieval tasks and outperforms the benchmarked state-of-the-art deep learning model.
</details>
<details>
<summary>摘要</summary>
To implement the algorithm, we split both the candidate and the inquiry videos into a sequence of clips and convert each clip to a representation vector using an autoencoder-backed deep neural network. We then calculate a similarity measure between the sequences of embedding vectors using a bi-directional dynamic time-warping method.We test the algorithm on multiple public datasets, including CC\_WEB\_VIDEO, Youtube-8m, S3DIS, and Synthia, and show that it outperforms state-of-the-art deep learning models. The algorithm effectively solves video retrieval tasks and demonstrates good performance.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Curriculum-based-Continual-Learning-with-Informative-Subset-Selection-for-Remote-Sensing-Scene-Classification"><a href="#Efficient-Curriculum-based-Continual-Learning-with-Informative-Subset-Selection-for-Remote-Sensing-Scene-Classification" class="headerlink" title="Efficient Curriculum based Continual Learning with Informative Subset Selection for Remote Sensing Scene Classification"></a>Efficient Curriculum based Continual Learning with Informative Subset Selection for Remote Sensing Scene Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01050">http://arxiv.org/abs/2309.01050</a></li>
<li>repo_url: None</li>
<li>paper_authors: S Divakar Bhat, Biplab Banerjee, Subhasis Chaudhuri, Avik Bhattacharya</li>
<li>for: 这个论文探讨了从光学远程测量图像中的地面分类问题，并提出了一个基于现有数据的类别增cremental learning（CIL）框架。</li>
<li>methods: 本文提出了一个独特的CIL方法，据建立了一个专门的curriculum来学习新的类别，并采用了一种对于旧的流程进行选择的sample选择策略来减少错误的影响。</li>
<li>results: 实验结果显示，提出的方法可以提高CIL性能，并且比过去的方法更好地调节稳定性和柔软性的贡献。<details>
<summary>Abstract</summary>
We tackle the problem of class incremental learning (CIL) in the realm of landcover classification from optical remote sensing (RS) images in this paper. The paradigm of CIL has recently gained much prominence given the fact that data are generally obtained in a sequential manner for real-world phenomenon. However, CIL has not been extensively considered yet in the domain of RS irrespective of the fact that the satellites tend to discover new classes at different geographical locations temporally. With this motivation, we propose a novel CIL framework inspired by the recent success of replay-memory based approaches and tackling two of their shortcomings. In order to reduce the effect of catastrophic forgetting of the old classes when a new stream arrives, we learn a curriculum of the new classes based on their similarity with the old classes. This is found to limit the degree of forgetting substantially. Next while constructing the replay memory, instead of randomly selecting samples from the old streams, we propose a sample selection strategy which ensures the selection of highly confident samples so as to reduce the effects of noise. We observe a sharp improvement in the CIL performance with the proposed components. Experimental results on the benchmark NWPU-RESISC45, PatternNet, and EuroSAT datasets confirm that our method offers improved stability-plasticity trade-off than the literature.
</details>
<details>
<summary>摘要</summary>
我们在这篇论文中处理了Remote Sensing（RS）图像中的类增长学习（CIL）问题。CIL的概念在真实世界中的数据采集中变得越来越重要，因为数据通常是在序列化的方式获取的。然而，CIL在RS领域还没有得到广泛的考虑，即使卫星在不同的地理位置上发现新的类型。为了解决这个问题，我们提出了一种基于最近的replay-memory基本方法的新CIL框架，并解决了两个缺点。首先，我们学习新类的curriculum，基于其与旧类的相似性，以限制淘汰旧类的影响。我们发现这可以减少淘汰的影响。然后，在构建replay内存时，而不是随机选择旧流中的样本，我们提议一种样本选择策略，以确保选择高度确定的样本，以降低噪声的影响。我们发现这些组件对CIL性能带来了明显的改善。实验结果表明，我们的方法在NWPU-RESISC45、PatternNet和EuroSAT数据集上提供了与文献中的稳定- пластично性质量Trade-off更好的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.CV_2023_09_03/" data-id="cloh3sqxk00gwh6883fkohx0t" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.AI_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T12:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.AI_2023_09_03/">cs.AI - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Generative-Social-Choice"><a href="#Generative-Social-Choice" class="headerlink" title="Generative Social Choice"></a>Generative Social Choice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01291">http://arxiv.org/abs/2309.01291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/babatundeibukun/simple-social-learning-environment">https://github.com/babatundeibukun/simple-social-learning-environment</a></li>
<li>paper_authors: Sara Fish, Paul Gölz, David C. Parkes, Ariel D. Procaccia, Gili Rusak, Itai Shapira, Manuel Wüthrich</li>
<li>for: 这篇论文是为了探讨人工智能在民主过程中的应用，具体来说是如何使用自然语言处理技术来实现民主选举。</li>
<li>methods: 这篇论文使用了社会选择理论的数学严谨性和大自然语言模型的文本生成能力，提出了一个生成社会选择框架，可以帮助解决复杂的民主选举问题。</li>
<li>results: 通过应用这个框架，可以生成一个代表民意的评论文本，例如在在线审议过程中。<details>
<summary>Abstract</summary>
Traditionally, social choice theory has only been applicable to choices among a few predetermined alternatives but not to more complex decisions such as collectively selecting a textual statement. We introduce generative social choice, a framework that combines the mathematical rigor of social choice theory with large language models' capability to generate text and extrapolate preferences. This framework divides the design of AI-augmented democratic processes into two components: first, proving that the process satisfies rigorous representation guarantees when given access to oracle queries; second, empirically validating that these queries can be approximately implemented using a large language model. We illustrate this framework by applying it to the problem of generating a slate of statements that is representative of opinions expressed as free-form text, for instance in an online deliberative process.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版本）传统上，社会选择理论只适用于一些已经预先确定的选项之间的选择，而不适用于更复杂的决策，如通过人工智能支持的民主过程中的 коллектив选择文本声明。我们介绍了生成社会选择框架，这个框架将社会选择理论的数学严谨性与大自然语言模型的文本生成能力相结合，以便更好地满足民主过程中的多样化需求。这个框架将民主过程的设计分为两个组成部分：首先，证明过程满足严谨的表达保证，当给定询问 oracle 时；其次，通过实际验证来证明这些询问可以使用大自然语言模型来近似实现。我们通过应用这个框架来解决在 он线协商过程中收集和代表表达出的意见的问题，例如生成一份代表多种意见的文本声明。
</details></li>
</ul>
<hr>
<h2 id="Traveling-Waves-Encode-the-Recent-Past-and-Enhance-Sequence-Learning"><a href="#Traveling-Waves-Encode-the-Recent-Past-and-Enhance-Sequence-Learning" class="headerlink" title="Traveling Waves Encode the Recent Past and Enhance Sequence Learning"></a>Traveling Waves Encode the Recent Past and Enhance Sequence Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08045">http://arxiv.org/abs/2309.08045</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anon-neurips-2023/wave-rnn">https://github.com/anon-neurips-2023/wave-rnn</a></li>
<li>paper_authors: T. Anderson Keller, Lyle Muller, Terrence Sejnowski, Max Welling</li>
<li>for: 这个论文的目的是解释 cortical sheet 中的 neural activity 是如何实现短期记忆的。</li>
<li>methods: 这个论文使用了一种简单的 recurrent neural network 模型，称为 Wave-RNN (wRNN)，来实现wave-like dynamics。</li>
<li>results: 研究发现，使用 wRNN 模型可以快速地学习并表现出优于不含wave的模型，并且在更复杂的序列模型任务中也表现出类似的性能。<details>
<summary>Abstract</summary>
Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically grounded hypothesis suggests that the cortical sheet may act like a wave-field capable of storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both connectivity constraints and initialization play a crucial role in the emergence of wave-like dynamics. We then empirically show how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and perform significantly better than wave-free counterparts. Finally, we explore the implications of this memory storage system on more complex sequence modeling tasks such as sequential image classification and find that wave-based models not only again outperform comparable wave-free RNNs while using significantly fewer parameters, but additionally perform comparably to more complex gated architectures such as LSTMs and GRUs. We conclude with a discussion of the implications of these results for both neuroscience and machine learning.
</details>
<details>
<summary>摘要</summary>
旅行波的神经活动已在脑部多个区域和尺度上观察到;然而，它们的具体计算作用仍在讨论中。一种物理上基础的假设是，质神经层可能 acts like a wave-field，可以在启发了扩散的 cortical surface 上存储短期内存。然而，这个想法的计算影响仍然是假设，因为没有一个简单的循环神经网络架构可以实现这种波动。在这种工作中，我们提出了一种模型，我们称之为 wave-RNN（wRNN），并证明了连接约束和初始化对波动的出现具有关键作用。然后，我们employmultiple synthetic memory tasks to demonstrate that wRNNs learn faster and perform significantly better than wave-free counterparts。最后，我们探讨了这种内存存储系统在更复杂的序列模型任务中的表现，并发现波动基本模型不仅在相对较少的参数下比wave-free RNNs快速学习，而且与更复杂的闭合架构，如LSTMs和GRUs，相当。我们 conclude with a discussion of the implications of these results for both neuroscience and machine learning.
</details></li>
</ul>
<hr>
<h2 id="Bayesian-inference-of-composition-dependent-phase-diagrams"><a href="#Bayesian-inference-of-composition-dependent-phase-diagrams" class="headerlink" title="Bayesian inference of composition-dependent phase diagrams"></a>Bayesian inference of composition-dependent phase diagrams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01271">http://arxiv.org/abs/2309.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timofei Miryashkin, Olga Klimanova, Vladimir Ladygin, Alexander Shapeev</li>
<li>for: This paper was written to develop a method for constructing temperature-concentration phase diagrams for materials using Bayesian inference and molecular dynamics simulations.</li>
<li>methods: The paper uses Bayesian inference to combine thermodynamic data from molecular dynamics simulations, melting point simulations, and phonon calculations, and to extrapolate the results to the infinite-atom limit.</li>
<li>results: The paper reports the development of an algorithm that can be used to construct temperature-concentration phase diagrams for materials with a high degree of accuracy and precision, and demonstrates the effectiveness of the algorithm on two binary systems, Ge-Si and K-Na.<details>
<summary>Abstract</summary>
Phase diagrams serve as a highly informative tool for materials design, encapsulating information about the phases that a material can manifest under specific conditions. In this work, we develop a method in which Bayesian inference is employed to combine thermodynamic data from molecular dynamics (MD), melting point simulations, and phonon calculations, process these data, and yield a temperature-concentration phase diagram. The employed Bayesian framework yields us not only the free energies of different phases as functions of temperature and concentration but also the uncertainties of these free energies originating from statistical errors inherent to finite-length MD trajectories. Furthermore, it extrapolates the results of the finite-atom calculations to the infinite-atom limit and facilitates the choice of temperature, chemical potentials, and the number of atoms conducting the next simulation with which will be the most efficient in reducing the uncertainty of the phase diagram. The developed algorithm was successfully tested on two binary systems, Ge-Si and K-Na, in the full range of concentrations and temperatures.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版）phas diagrams serve as a highly informative tool for materials design, encapsulating information about the phases that a material can manifest under specific conditions. In this work, we develop a method in which Bayesian inference is employed to combine thermodynamic data from molecular dynamics (MD), melting point simulations, and phonon calculations, process these data, and yield a temperature-concentration phase diagram. The employed Bayesian framework yields us not only the free energies of different phases as functions of temperature and concentration but also the uncertainties of these free energies originating from statistical errors inherent to finite-length MD trajectories. Furthermore, it extrapolates the results of the finite-atom calculations to the infinite-atom limit and facilitates the choice of temperature, chemical potentials, and the number of atoms conducting the next simulation with which will be the most efficient in reducing the uncertainty of the phase diagram. The developed algorithm was successfully tested on two binary systems, Ge-Si and K-Na, in the full range of concentrations and temperatures.
</details></li>
</ul>
<hr>
<h2 id="COMEDIAN-Self-Supervised-Learning-and-Knowledge-Distillation-for-Action-Spotting-using-Transformers"><a href="#COMEDIAN-Self-Supervised-Learning-and-Knowledge-Distillation-for-Action-Spotting-using-Transformers" class="headerlink" title="COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers"></a>COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01270">http://arxiv.org/abs/2309.01270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliendenize/eztorch">https://github.com/juliendenize/eztorch</a></li>
<li>paper_authors: Julien Denize, Mykola Liashuha, Jaonary Rabarisoa, Astrid Orcesi, Romain Hérault</li>
<li>for: 这 paper 是为了提出一种用于动作检测的 Initialization 管道，即 COMEDIAN，该管道包括自动学习和知识储存两个 initialization 阶段。</li>
<li>methods: 该 paper 使用了两个 initialization 阶段，首先是使用短视频作为输入进行自动学习初始化 spatial transformer，然后是通过知识储存来增强 spatial transformer 的输出，并在最后一步进行 fine-tuning。</li>
<li>results: 实验结果表明，COMEDIAN 的预训练方法可以在 SoccerNet-v2 数据集上达到状态作卷积的性能，并且比非预训练模型更快地 converges。这些结果表明 COMEDIAN 的预训练管道的有效性。<details>
<summary>Abstract</summary>
We present COMEDIAN, a novel pipeline to initialize spatio-temporal transformers for action spotting, which involves self-supervised learning and knowledge distillation. Action spotting is a timestamp-level temporal action detection task. Our pipeline consists of three steps, with two initialization stages. First, we perform self-supervised initialization of a spatial transformer using short videos as input. Additionally, we initialize a temporal transformer that enhances the spatial transformer's outputs with global context through knowledge distillation from a pre-computed feature bank aligned with each short video segment. In the final step, we fine-tune the transformers to the action spotting task. The experiments, conducted on the SoccerNet-v2 dataset, demonstrate state-of-the-art performance and validate the effectiveness of COMEDIAN's pretraining paradigm. Our results highlight several advantages of our pretraining pipeline, including improved performance and faster convergence compared to non-pretrained models.
</details>
<details>
<summary>摘要</summary>
我们提出了COMEDIAN，一个新的 Initialize Pipeline，用于时间action spotting任务的spatio-temporal transformer的初始化。action spotting是一个时间戳级的动作检测任务。我们的管道包括三个步骤，其中有两个初始化阶段。首先，我们使用短视频作为输入进行自我超vised学习初始化一个空间变换器。其次，我们使用知识填充学习增强空间变换器的输出，通过对每个短视频分段预计算的特征库进行知识填充。最后，我们精度调整transformer到动作检测任务。我们在SoccerNet-v2数据集上进行了实验，并证明了COMEDIAN的预训练方案的效iveness。我们的结果显示了预训练模型的性能提高和更快的收敛速度。
</details></li>
</ul>
<hr>
<h2 id="Learning-Aware-Safety-for-Interactive-Autonomy"><a href="#Learning-Aware-Safety-for-Interactive-Autonomy" class="headerlink" title="Learning-Aware Safety for Interactive Autonomy"></a>Learning-Aware Safety for Interactive Autonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01267">http://arxiv.org/abs/2309.01267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haimin Hu, Zixu Zhang, Kensuke Nakamura, Andrea Bajcsy, Jaime F. Fisac</li>
<li>for: 本研究旨在提供一种新的关闭Loop方法，以确保机器人系统在实时学习和适应的情况下保持安全交互。</li>
<li>methods: 该方法使用反抗搅ء深度学习来规避未来可能的enario，并同时考虑机器人学习算法的内部信念的变化。</li>
<li>results: 研究人员使用这种方法可以 tractable safety analysis，并且可以处理高维度的情况。此外，他们还能够证明这种方法可以与 bayesian belief propagation和大型预训练神经轨迹预测器结合使用。<details>
<summary>Abstract</summary>
One of the outstanding challenges for the widespread deployment of robotic systems like autonomous vehicles is ensuring safe interaction with humans without sacrificing efficiency. Existing safety analysis methods often neglect the robot's ability to learn and adapt at runtime, leading to overly conservative behavior. This paper proposes a new closed-loop paradigm for synthesizing safe control policies that explicitly account for the system's evolving uncertainty under possible future scenarios. The formulation reasons jointly about the physical dynamics and the robot's learning algorithm, which updates its internal belief over time. We leverage adversarial deep reinforcement learning (RL) for scaling to high dimensions, enabling tractable safety analysis even for implicit learning dynamics induced by state-of-the-art prediction models. We demonstrate our framework's ability to work with both Bayesian belief propagation and the implicit learning induced by a large pre-trained neural trajectory predictor.
</details>
<details>
<summary>摘要</summary>
一个现代化的挑战是在广泛部署自动化系统时确保安全地与人类交互，不会牺牲效率。现有的安全分析方法经常忽略机器人的学习和运行时 adaptability，导致行为过于保守。这篇论文提出了一种新的封闭循环方案，用于生成安全控制策略，并且考虑了系统的演变不确定性。我们利用对抗式深度学习来扩展到高维度，使得安全分析可以承受大数据量，并且可以 tractable 地分析隐式学习动力，即使使用现代预测模型。我们示例中使用了 bayesian belief propagation 和大型预训练神经网络轨迹预测器来演示我们的框架的可行性。
</details></li>
</ul>
<hr>
<h2 id="Large-AI-Model-Empowered-Multimodal-Semantic-Communications"><a href="#Large-AI-Model-Empowered-Multimodal-Semantic-Communications" class="headerlink" title="Large AI Model Empowered Multimodal Semantic Communications"></a>Large AI Model Empowered Multimodal Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01249">http://arxiv.org/abs/2309.01249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You</li>
<li>for: 提供一个具有低延迟和高质量的Semantic Communication（SC）体验，使用多Modal Signal（文本、音频、图像和视频）。</li>
<li>methods: 利用大AI模型，具体是Multimodal Language Model（MLM）和Large Language Model（LLM）来解决数据不一致性、semantic ambiguity和信号抖动等问题。</li>
<li>results: 提出一个基于大AI模型的多Modal SC（LAM-MSC）框架，包括MLM-based Multimodal Alignment（MMA）、个性化的LKB和Conditional Generative Adversarial Networks-based Channel Estimation（CGE）等技术，可以有效地提高SC的性能。<details>
<summary>Abstract</summary>
Multimodal signals, including text, audio, image and video, can be integrated into Semantic Communication (SC) for providing an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal fading. Recent advancements in large AI models, particularly in Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential solutions for these issues. To this end, we propose a Large AI Model-based Multimodal SC (LAM-MSC) framework, in which we first present the MLM-based Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery through the LLM. This effectively addresses the semantic ambiguity. Finally, we apply the Conditional Generative adversarial networks-based channel Estimation (CGE) to obtain Channel State Information (CSI). This approach effectively mitigates the impact of fading channels in SC. Finally, we conduct simulations that demonstrate the superior performance of the LAM-MSC framework.
</details>
<details>
<summary>摘要</summary>
多模式信号（包括文本、音频、图像和视频）可以在semantic Communication（SC）中集成，以提供具有低延迟和高质量的 immerse 体验。然而，多模式SC 存在许多挑战，包括数据不一致、semantic 抽象和信号衰减。最近的大AI模型，特别是多模式语言模型（MLM）和大语言模型（LLM），提供了解决这些问题的可能性。为此，我们提出了基于大AI模型的多模式SC 框架（LAM-MSC），其中我们首先提出了基于 MLM 的多模式对应（MMA），使得在多模式和单模式数据之间进行转换，保持 semantic 一致性。然后，我们提出了基于 LLM 的个性化知识库（LKB），允许用户进行个性化semantic 提取或恢复，从而有效解决semantic 抽象问题。最后，我们应用Conditional Generative Adversarial Networks（CGE）来获取通道状态信息（CSI），这种方法有效地减轻了混叠通道的影响。我们进行了实验，并证明了 LAM-MSC 框架的超越性。
</details></li>
</ul>
<hr>
<h2 id="Representations-Matter-Embedding-Modes-of-Large-Language-Models-using-Dynamic-Mode-Decomposition"><a href="#Representations-Matter-Embedding-Modes-of-Large-Language-Models-using-Dynamic-Mode-Decomposition" class="headerlink" title="Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition"></a>Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01245">http://arxiv.org/abs/2309.01245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Akrout</li>
<li>for: 本研究旨在检测大型自然语言模型（LLM）生成的“妄想”内容，即不基础的文本内容。</li>
<li>methods: 本研究使用动态模式分解（DMD）工具分析生成文本的词嵌入空间的模式演化。</li>
<li>results: 研究发现，生成文本的词嵌入spectrum随着句子的排序逐渐降低，与真实文本的词嵌入spectrum不同。此外，评估 случа件中存在LLM妄想时，真实文本的词嵌入模式具有更多的模式被LLM嵌入模式不好地拟合。这表明，妄想结果归因于生成技术和基础表示。<details>
<summary>Abstract</summary>
Existing large language models (LLMs) are known for generating "hallucinated" content, namely a fabricated text of plausibly looking, yet unfounded, facts. To identify when these hallucination scenarios occur, we examine the properties of the generated text in the embedding space. Specifically, we draw inspiration from the dynamic mode decomposition (DMD) tool in analyzing the pattern evolution of text embeddings across sentences. We empirically demonstrate how the spectrum of sentence embeddings over paragraphs is constantly low-rank for the generated text, unlike that of the ground-truth text. Importantly, we find that evaluation cases having LLM hallucinations correspond to ground-truth embedding patterns with a higher number of modes being poorly approximated by the few modes associated with LLM embedding patterns. In analogy to near-field electromagnetic evanescent waves, the embedding DMD eigenmodes of the generated text with hallucinations vanishes quickly across sentences as opposed to those of the ground-truth text. This suggests that the hallucinations result from both the generation techniques and the underlying representation.
</details>
<details>
<summary>摘要</summary>
现有大型语言模型（LLM）已知能生成“幻想”内容，即fabricated文本中的虚假信息。为了识别这些幻想场景，我们研究生成文本在嵌入空间的属性。 Specifically, we draw inspiration from动态模式分解（DMD）工具来分析文本嵌入的模式进化。我们实际示例中，生成文本的句子嵌入spectrum across paragraphs是常 Low-rank的，与真实文本的嵌入spectrum不同。进一步，我们发现评测 случа件具有LLM幻想的情况与真实文本的嵌入模式数量更高，但这些模式与LLM嵌入模式之间的相似性较低。在近场电磁波的类比中，生成文本幻想的嵌入DMD eigenmodes在句子之间变得越来越小，与真实文本的嵌入DMD eigenmodes不同。这表明幻想的结果来自生成技术和下面的表示。
</details></li>
</ul>
<hr>
<h2 id="Saturn-An-Optimized-Data-System-for-Large-Model-Deep-Learning-Workloads"><a href="#Saturn-An-Optimized-Data-System-for-Large-Model-Deep-Learning-Workloads" class="headerlink" title="Saturn: An Optimized Data System for Large Model Deep Learning Workloads"></a>Saturn: An Optimized Data System for Large Model Deep Learning Workloads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01226">http://arxiv.org/abs/2309.01226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knagrecha/saturn">https://github.com/knagrecha/saturn</a></li>
<li>paper_authors: Kabir Nagrecha, Arun Kumar</li>
<li>for: 本研究旨在帮助深度学习（DL）用户更好地选择并运行大型模型，解决DL用户面临的三大负担：并行选择、资源分配和任务调度。</li>
<li>methods: 本研究提出了一种新的信息系统架构，用于解决DL用户面临的三大负担。该架构包括一种可编程的实验室 Profiler，一种MILP（分配优化问题）模型，以及一种自适应调度策略。</li>
<li>results: 实验结果表明，使用MILP解决器可以significantly reduces model selection runtimes（39-49%），而且可以进一步 optimize system runtime through introspective scheduling approach。这些技术在一个新的数据系统中被实现，称为Saturn。<details>
<summary>Abstract</summary>
Large language models such as GPT-3 & ChatGPT have transformed deep learning (DL), powering applications that have captured the public's imagination. These models are rapidly being adopted across domains for analytics on various modalities, often by finetuning pre-trained base models. Such models need multiple GPUs due to both their size and computational load, driving the development of a bevy of "model parallelism" techniques & tools. Navigating such parallelism choices, however, is a new burden for end users of DL such as data scientists, domain scientists, etc. who may lack the necessary systems knowhow. The need for model selection, which leads to many models to train due to hyper-parameter tuning or layer-wise finetuning, compounds the situation with two more burdens: resource apportioning and scheduling. In this work, we tackle these three burdens for DL users in a unified manner by formalizing them as a joint problem that we call SPASE: Select a Parallelism, Allocate resources, and SchedulE. We propose a new information system architecture to tackle the SPASE problem holistically, representing a key step toward enabling wider adoption of large DL models. We devise an extensible template for existing parallelism schemes and combine it with an automated empirical profiler for runtime estimation. We then formulate SPASE as an MILP.   We find that direct use of an MILP-solver is significantly more effective than several baseline heuristics. We optimize the system runtime further with an introspective scheduling approach. We implement all these techniques into a new data system we call Saturn. Experiments with benchmark DL workloads show that Saturn achieves 39-49% lower model selection runtimes than typical current DL practice.
</details>
<details>
<summary>摘要</summary>
大型语言模型如GPT-3和ChatGPT已经改变深度学习（DL），推动了许多应用程序，吸引了大众的注意。这些模型在不同领域中被快速适用，通常是通过调整预训模型来进行调整。这些模型需要多个GPU，因为它们的大小和计算负载，这驱使了模型平行化技术和工具的发展。但是，为DL使用者如数据科学家和领域科学家等选择和管理这些平行化方案，则增加了新的负担。因为模型选择和层级调整导致了多个模型需要训练，这个问题更加复杂。在这个研究中，我们将这三个负担视为一个共同问题，我们统称为SPASE：选择平行、分配资源和安排。我们提出了一个新的资讯系统架构，来解决SPASE问题。我们创建了一个可扩展的平行方案模板，并与一个自动化的实验性质估计器结合。我们将SPASE视为一个MILP（内置搜索）。我们发现，直接使用MILP解决方案比基eline变数估计法更有效。我们进一步优化系统执行时间使用一种自我反思的安排方法。我们实现了这些技术在我们的新数据系统Saturn上。实验结果显示，Saturn在常用DL工作负载上降低了39-49%的模型选择执行时间。
</details></li>
</ul>
<hr>
<h2 id="Siren’s-Song-in-the-AI-Ocean-A-Survey-on-Hallucination-in-Large-Language-Models"><a href="#Siren’s-Song-in-the-AI-Ocean-A-Survey-on-Hallucination-in-Large-Language-Models" class="headerlink" title="Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models"></a>Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01219">http://arxiv.org/abs/2309.01219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hillzhang1999/llm-hallucination-survey">https://github.com/hillzhang1999/llm-hallucination-survey</a></li>
<li>paper_authors: Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, Shuming Shi</li>
<li>for: 本研究旨在探讨大语言模型（LLM）在实际应用中的可靠性问题，即 LLM  occasional hallucination 问题。</li>
<li>methods: 本研究对现有的检测、解释和缓解 LLM  hallucination 方法进行了检视和分析，并讨论了未来研究的可能方向。</li>
<li>results: 研究发现了 LLM  hallucination 现象的多种类型和评价指标，分析了现有的缓解方法的效果，并提出了未来研究的潜在方向。<details>
<summary>Abstract</summary>
While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种下游任务中表现出色，但也存在一定的问题：LLM occasional generation content diverges from user input, contradicts previously generated context, or misaligns with established world knowledge。这种现象对 LLM 在实际应用场景中的可靠性带来了极大的挑战。在这篇论文中，我们对 LLM 幻觉现象进行了检测、解释和避免的各种尝试，并分析了现有的避免方法，以及未来研究的可能性。Here's the text with some notes on the translation:* "大型语言模型" (LLM) is translated as "大型语言模型" (also known as "large language models" or "LLMs").* "幻觉" (hallucination) is translated as "幻觉" (also known as "hallucination" or "LLM hallucination").* " contradicts" is translated as " contradicts" (同义词).* "misaligns" is translated as "misaligns" (同义词).* "established world knowledge" is translated as "已知世界知识" (also known as "common knowledge" or "established knowledge").Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Physics-inspired-Neural-Networks-for-Parameter-Learning-of-Adaptive-Cruise-Control-Systems"><a href="#Physics-inspired-Neural-Networks-for-Parameter-Learning-of-Adaptive-Cruise-Control-Systems" class="headerlink" title="Physics-inspired Neural Networks for Parameter Learning of Adaptive Cruise Control Systems"></a>Physics-inspired Neural Networks for Parameter Learning of Adaptive Cruise Control Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01211">http://arxiv.org/abs/2309.01211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Theocharis Apostolakis, Konstantinos Ampountolas</li>
<li>for: 本研究提出了一种基于物理学的神经网络（PiNN），用于学习商业实施的自适应速度控制系统（ACC）的参数。</li>
<li>methods: 本研究使用了多层人工神经网络作为通用函数approximator，并采用了常数时间头额策略（CTHP）来模拟ACC系统的长向 Dynamics。</li>
<li>results: 研究结果表明，提出的PiNN可以高效地学习未知ACC系统的参数，并且对于不同的汽车制造商的ACC系统进行了严格的评估。结果还表明，ACC系统的设计参数不是$L_2$也不是$L_\infty$的 string stable。<details>
<summary>Abstract</summary>
This paper proposes and develops a physics-inspired neural network (PiNN) for learning the parameters of commercially implemented adaptive cruise control (ACC) systems in automotive industry. To emulate the core functionality of stock ACC systems, which have proprietary control logic and undisclosed parameters, the constant time-headway policy (CTHP) is adopted. Leveraging the multi-layer artificial neural networks as universal approximators, the developed PiNN serves as a surrogate model for the longitudinal dynamics of ACC-engaged vehicles, efficiently learning the unknown parameters of the CTHP. The ability of the PiNN to infer the unknown ACC parameters is meticulous evaluated using both synthetic and high-fidelity empirical data of space-gap and relative velocity involving ACC-engaged vehicles in platoon formation. The results have demonstrated the superior predictive ability of the proposed PiNN in learning the unknown design parameters of stock ACC systems from different car manufacturers. The set of ACC model parameters obtained from the PiNN revealed that the stock ACC systems of the considered vehicles in three experimental campaigns are neither $L_2$ nor $L_\infty$ string stable.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "stock ACC systems" is translated as "商业实现的适应速度控制系统" (shāngchǎng jítuō de suīyìng yìjīng zhìxīng zhì)* "proprietary control logic" is translated as "专有控制逻辑" (zhuān yǒu kòng zhì lógí)* "undisclosed parameters" is translated as "未公开的参数" (wèi gōngkāi de ciàngxiàng)* "constant time-headway policy" is translated as "常数时间间隔策略" (chángshuō shíjiān jiāngrá zhùlü)* "multi-layer artificial neural networks" is translated as "多层人工神经网络" (duōcéng rénshēng jīngxīn wǎngwǎng)* "surrogate model" is translated as "代理模型" (dài lǐ móde)* "longitudinal dynamics" is translated as "长度动力学" (chángduō dònglì xué)* "ACC-engaged vehicles" is translated as "适应速度控制车辆" (suīyìng yìjīng chēliàng)* "platoon formation" is translated as "队列形式" (duì liè xíngshì)* "high-fidelity empirical data" is translated as "高准确的实验数据" (gāo zhèngqì de shíyàn shùdà)* "string stability" is translated as "串稳定" (chuī jìdìng)
</details></li>
</ul>
<hr>
<h2 id="A-Visual-Interpretation-Based-Self-Improved-Classification-System-Using-Virtual-Adversarial-Training"><a href="#A-Visual-Interpretation-Based-Self-Improved-Classification-System-Using-Virtual-Adversarial-Training" class="headerlink" title="A Visual Interpretation-Based Self-Improved Classification System Using Virtual Adversarial Training"></a>A Visual Interpretation-Based Self-Improved Classification System Using Virtual Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01196">http://arxiv.org/abs/2309.01196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Jiang, Sayaka Kamei, Chen Li, Shengzhe Hou, Yasuhiko Morimoto<br>for: 这篇论文旨在提出一个可以实现Visual Interpretation-based Self-Improving Classification的模型，以解决BERT模型在自然语言处理中的黑盒问题。methods: 本文提出的方法包括：使用精进BERT模型作为文本类别器，然后使用这些预测的类别标签来在另一个BERT模型中进行类别训练，同时使用VAT技术进行自适应训练。results: 实验结果显示，提出的模型在Twitter的短讯数据集上实现了高效的类别性能。此外，ablation study结果显示不同模型的Component对于类别结果的影响。<details>
<summary>Abstract</summary>
The successful application of large pre-trained models such as BERT in natural language processing has attracted more attention from researchers. Since the BERT typically acts as an end-to-end black box, classification systems based on it usually have difficulty in interpretation and low robustness. This paper proposes a visual interpretation-based self-improving classification model with a combination of virtual adversarial training (VAT) and BERT models to address the above problems. Specifically, a fine-tuned BERT model is used as a classifier to classify the sentiment of the text. Then, the predicted sentiment classification labels are used as part of the input of another BERT for spam classification via a semi-supervised training manner using VAT. Additionally, visualization techniques, including visualizing the importance of words and normalizing the attention head matrix, are employed to analyze the relevance of each component to classification accuracy. Moreover, brand-new features will be found in the visual analysis, and classification performance will be improved. Experimental results on Twitter's tweet dataset demonstrate the effectiveness of the proposed model on the classification task. Furthermore, the ablation study results illustrate the effect of different components of the proposed model on the classification results.
</details>
<details>
<summary>摘要</summary>
成功应用大型预训模型，如BERT，在自然语言处理中吸引了更多研究者的注意。由于BERT通常作为终端黑盒模型，因此基于它的分类系统通常具有低可解释性和低Robustness。本文提出了基于可见解释的自我改进分类模型，通过结合虚拟对抗训练（VAT）和BERT模型来解决上述问题。具体来说，一个精度调整后的BERT模型被用作文本情感分类器。然后，预测的情感分类标签被用作另一个BERT模型的敏感训练数据，通过semi-supervised的方式使用VAT进行训练。此外，使用视觉化技术，包括Word的重要性可见化和注意头矩阵的 норmalizaition，以分析每个组件对分类精度的 relevance。此外，Visual分析还可以找到新的特征。实验结果表明，提议的模型在Twitter tweet数据集上对分类任务具有效果。此外，ablation study结果表明不同组件对分类结果的影响。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Service-Route-and-Time-Prediction-in-Instant-Delivery-Taxonomy-Progress-and-Prospects"><a href="#A-Survey-on-Service-Route-and-Time-Prediction-in-Instant-Delivery-Taxonomy-Progress-and-Prospects" class="headerlink" title="A Survey on Service Route and Time Prediction in Instant Delivery: Taxonomy, Progress, and Prospects"></a>A Survey on Service Route and Time Prediction in Instant Delivery: Taxonomy, Progress, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01194">http://arxiv.org/abs/2309.01194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Wen, Youfang Lin, Lixia Wu, Xiaowei Mao, Tianyue Cai, Yunfeng Hou, Shengnan Guo, Yuxuan Liang, Guangyin Jin, Yiji Zhao, Roger Zimmermann, Jieping Ye, Huaiyu Wan</li>
<li>for: 这篇论文的目的是为服务平台的路由和时间预测（RTP）提供一个系统性的概述，帮助研究人员更好地了解这个领域。</li>
<li>methods: 这篇论文使用了一种新的分类方法，将RTP方法分为三类：任务类型、模型架构和学习态度。这些方法包括单路预测、单时预测和共同路径时间预测等。</li>
<li>results: 这篇论文提供了一个全面的概述，把现有的RTP方法分类和总结，并指出了当前研究的局限性和未来可能的发展方向。<details>
<summary>Abstract</summary>
Instant delivery services, such as food delivery and package delivery, have achieved explosive growth in recent years by providing customers with daily-life convenience. An emerging research area within these services is service Route\&Time Prediction (RTP), which aims to estimate the future service route as well as the arrival time of a given worker. As one of the most crucial tasks in those service platforms, RTP stands central to enhancing user satisfaction and trimming operational expenditures on these platforms. Despite a plethora of algorithms developed to date, there is no systematic, comprehensive survey to guide researchers in this domain. To fill this gap, our work presents the first comprehensive survey that methodically categorizes recent advances in service route and time prediction. We start by defining the RTP challenge and then delve into the metrics that are often employed. Following that, we scrutinize the existing RTP methodologies, presenting a novel taxonomy of them. We categorize these methods based on three criteria: (i) type of task, subdivided into only-route prediction, only-time prediction, and joint route\&time prediction; (ii) model architecture, which encompasses sequence-based and graph-based models; and (iii) learning paradigm, including Supervised Learning (SL) and Deep Reinforcement Learning (DRL). Conclusively, we highlight the limitations of current research and suggest prospective avenues. We believe that the taxonomy, progress, and prospects introduced in this paper can significantly promote the development of this field.
</details>
<details>
<summary>摘要</summary>
快速配送服务，如食物配送和快递服务，在最近几年内取得了极大的增长，提供了日常生活的便利。一个快速发展的研究领域是服务路径预测（RTP），旨在预测未来服务路径以及工作者的到达时间。作为服务平台中最重要的任务之一，RTP对于提高用户满意度和降低运营成本具有重要意义。然而，迄今为止，没有一份系统性、全面的评论指导研究人员在这个领域。为了填补这一空白，我们的工作提供了首次的全面评论，系统地分类了最新的服务路径预测方法。我们首先定义RTP挑战，然后详细介绍使用的指标。接着，我们仔细检查现有的RTP方法，并对其进行新的分类。我们根据三个 критери予分类这些方法：（一）任务类型，分为单独的路径预测、时间预测和路径\&时间预测；（二）模型结构，包括序列基的和图基的模型；（三）学习思想，包括超级学习（SL）和深度优化学习（DRL）。最后，我们强调现有研究的局限性，并建议未来的方向。我们认为这种分类、进步和前瞻在这篇论文中具有重要的促进作用，可以推动这个领域的发展。
</details></li>
</ul>
<hr>
<h2 id="LogGPT-Exploring-ChatGPT-for-Log-Based-Anomaly-Detection"><a href="#LogGPT-Exploring-ChatGPT-for-Log-Based-Anomaly-Detection" class="headerlink" title="LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection"></a>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01189">http://arxiv.org/abs/2309.01189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Qi, Shaohan Huang, Zhongzhi Luan, Carol Fung, Hailong Yang, Depei Qian</li>
<li>for: 这个研究旨在提出一个基于 ChatGPT 的传统系统logs 异常检测方法，以解决高维度和噪音 logs 资料的分析问题。</li>
<li>methods: 本研究使用了 ChatGPT 的语言解释能力，实现了将大规模文本库中的知识转移到 logs 异常检测中。</li>
<li>results: 我们的实验结果显示，LogGPT 可以获得良好的效果，并且具有良好的解释性。这个研究提供了对传统系统logs 异常检测任务中 prompt-based 模型的初步探索。<details>
<summary>Abstract</summary>
The increasing volume of log data produced by software-intensive systems makes it impractical to analyze them manually. Many deep learning-based methods have been proposed for log-based anomaly detection. These methods face several challenges such as high-dimensional and noisy log data, class imbalance, generalization, and model interpretability. Recently, ChatGPT has shown promising results in various domains. However, there is still a lack of study on the application of ChatGPT for log-based anomaly detection. In this work, we proposed LogGPT, a log-based anomaly detection framework based on ChatGPT. By leveraging the ChatGPT's language interpretation capabilities, LogGPT aims to explore the transferability of knowledge from large-scale corpora to log-based anomaly detection. We conduct experiments to evaluate the performance of LogGPT and compare it with three deep learning-based methods on BGL and Spirit datasets. LogGPT shows promising results and has good interpretability. This study provides preliminary insights into prompt-based models, such as ChatGPT, for the log-based anomaly detection task.
</details>
<details>
<summary>摘要</summary>
随着软件敏感系统中的日志数据量的增加，手动分析变得不切实际。许多深度学习基本方法已经为日志异常检测提出了多种方案。这些方法面临着高维度和噪声的日志数据、类别不均衡、泛化和模型解释性等挑战。最近，ChatGPT已经在不同领域展示了有前途的成绩。然而，针对日志异常检测的ChatGPT的应用研究仍然缺乏。本文提出了基于ChatGPT的日志异常检测框架——LogGPT。通过利用ChatGPT的语言解释能力，LogGPT希望能够利用大规模文献中的知识传递到日志异常检测中。我们对LogGPT进行了实验，并与三种深度学习基本方法进行比较。LogGPT显示了良好的性能和解释性。这项研究提供了推特模型（如ChatGPT）在日志异常检测任务中的初步洞察。
</details></li>
</ul>
<hr>
<h2 id="Pre-trained-Neural-Recommenders-A-Transferable-Zero-Shot-Framework-for-Recommendation-Systems"><a href="#Pre-trained-Neural-Recommenders-A-Transferable-Zero-Shot-Framework-for-Recommendation-Systems" class="headerlink" title="Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems"></a>Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01188">http://arxiv.org/abs/2309.01188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junting Wang, Adit Krishnan, Hari Sundaram, Yunzhe Li</li>
<li>for: 该研究旨在开发一种基于现代神经网络的协同推荐技术，以满足电商、社交媒体和内容分享平台的成功。</li>
<li>methods: 该研究使用了预训练的视觉和语言模型，并explores the possibility of pre-trained recommender models that支持在新领域建立推荐系统，无需重新训练或使用auxiliary user或item信息。</li>
<li>results: 研究表明，通过利用用户-项目交互矩阵的统计特征，可以学习不需要用户或项目 auxillary信息的零式推荐模型，并且这些模型可以在不同领域和数据集上进行适应。<details>
<summary>Abstract</summary>
Modern neural collaborative filtering techniques are critical to the success of e-commerce, social media, and content-sharing platforms. However, despite technical advances -- for every new application domain, we need to train an NCF model from scratch. In contrast, pre-trained vision and language models are routinely applied to diverse applications directly (zero-shot) or with limited fine-tuning. Inspired by the impact of pre-trained models, we explore the possibility of pre-trained recommender models that support building recommender systems in new domains, with minimal or no retraining, without the use of any auxiliary user or item information. Zero-shot recommendation without auxiliary information is challenging because we cannot form associations between users and items across datasets when there are no overlapping users or items. Our fundamental insight is that the statistical characteristics of the user-item interaction matrix are universally available across different domains and datasets. Thus, we use the statistical characteristics of the user-item interaction matrix to identify dataset-independent representations for users and items. We show how to learn universal (i.e., supporting zero-shot adaptation without user or item auxiliary information) representations for nodes and edges from the bipartite user-item interaction graph. We learn representations by exploiting the statistical properties of the interaction data, including user and item marginals, and the size and density distributions of their clusters.
</details>
<details>
<summary>摘要</summary>
现代神经网络合作推荐技术对电商、社交媒体和内容分享平台的成功起到了关键作用。然而，尽管技术上有所进步，但为每个新应用领域，我们仍需要从零开始训练NCF模型。相比之下，预训练视觉和语言模型可以直接应用于多个应用领域，或者只需要限定的微调。受预训练模型的影响启发了我们，我们试图开发预训练推荐模型，以支持在新领域建立推荐系统，无需重新训练，无需使用任何辅助用户或者物品信息。零shot推荐 без辅助信息是一项挑战，因为在不同的用户和物品之间没有共同的用户或者物品。我们的基本想法是，用户-物品交互矩阵的统计特征是透传的，可以在不同的领域和数据集之间形成共同的表征。因此，我们使用用户-物品交互矩阵的统计特征来定义数据集独立的用户和物品表征。我们展示了如何从二分图中学习universal（即无需用户或物品辅助信息进行适应）的表征。我们利用交互数据的统计特征，包括用户和物品的独立分布、以及用户和物品的尺寸和密度分布，来学习表征。
</details></li>
</ul>
<hr>
<h2 id="Cognition-Mode-Aware-Variational-Representation-Learning-Framework-for-Knowledge-Tracing"><a href="#Cognition-Mode-Aware-Variational-Representation-Learning-Framework-for-Knowledge-Tracing" class="headerlink" title="Cognition-Mode Aware Variational Representation Learning Framework for Knowledge Tracing"></a>Cognition-Mode Aware Variational Representation Learning Framework for Knowledge Tracing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01179">http://arxiv.org/abs/2309.01179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zmy-9/CMVF">https://github.com/zmy-9/CMVF</a></li>
<li>paper_authors: Moyu Zhang, Xinning Zhu, Chunhong Zhang, Feng Pan, Wenchen Qian, Hui Zhao</li>
<li>for: 这篇论文的目的是帮助学生Personalized Learning中的知识追踪（KT）任务，解决该任务的资料罕见问题，以及将学生的实际状态转换为更加Robust的表现。</li>
<li>methods: 这篇论文提出了一个Cognition-Mode Aware Variational Representation Learning Framework（CMVF），可以直接应用于现有的KT方法。CMVF使用一个几率模型来生成每个学生的分布，考虑到有限实践记录的不确定性，并使用variational inference（VI）估计学生的分布。此外，我们还引入了一个认知模式意识的多元分布作为专家知识，以避免学生对于有限实践记录的过度个性化。</li>
<li>results: 实验结果显示，CMVF可以有效地帮助现有的KT方法学习更加Robust的学生表现。<details>
<summary>Abstract</summary>
The Knowledge Tracing (KT) task plays a crucial role in personalized learning, and its purpose is to predict student responses based on their historical practice behavior sequence. However, the KT task suffers from data sparsity, which makes it challenging to learn robust representations for students with few practice records and increases the risk of model overfitting. Therefore, in this paper, we propose a Cognition-Mode Aware Variational Representation Learning Framework (CMVF) that can be directly applied to existing KT methods. Our framework uses a probabilistic model to generate a distribution for each student, accounting for uncertainty in those with limited practice records, and estimate the student's distribution via variational inference (VI). In addition, we also introduce a cognition-mode aware multinomial distribution as prior knowledge that constrains the posterior student distributions learning, so as to ensure that students with similar cognition modes have similar distributions, avoiding overwhelming personalization for students with few practice records. At last, extensive experimental results confirm that CMVF can effectively aid existing KT methods in learning more robust student representations. Our code is available at https://github.com/zmy-9/CMVF.
</details>
<details>
<summary>摘要</summary>
知识跟踪（KT）任务在个性化学习中扮演着关键角色，其目的是预测学生的回答基于他们历史实践行为序列。然而，KT任务受到数据稀缺的影响，这使得学习 robust 的学生表示变得更加挑战，同时增加了模型适应过拟合的风险。因此，在这篇论文中，我们提出了一种基于变量学习框架（CMVF），可以直接应用于现有的 KT 方法。我们的框架使用一种 probabilistic 模型来生成每个学生的分布，考虑到有限实践记录下的不确定性，并通过变量推理（VI）来估计学生的分布。此外，我们还引入了认知模式意识的多omial分布作为先验知识，以避免学生具有少量实践记录的情况下过度个性化。最后，我们进行了广泛的实验研究，证明CMVF可以有效地帮助现有的 KT 方法学习更加 robust 的学生表示。我们的代码可以在 https://github.com/zmy-9/CMVF 上获取。
</details></li>
</ul>
<hr>
<h2 id="Logic-of-subjective-probability"><a href="#Logic-of-subjective-probability" class="headerlink" title="Logic of subjective probability"></a>Logic of subjective probability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01173">http://arxiv.org/abs/2309.01173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vladimir Vovk</li>
<li>for: 本文研究对主观概率的 sintax和 semantics。</li>
<li>methods: 本文使用多种方法来测试概率陈述，包括间subjective概率和不人性概率。</li>
<li>results: 本文 argue that已经被测试过的不人性概率具有对象概率的特征，并采用 Jeffreys’s law来支持这一想法。<details>
<summary>Abstract</summary>
In this paper I discuss both syntax and semantics of subjective probability. The semantics determines ways of testing probability statements. Among important varieties of subjective probabilities are intersubjective probabilities and impersonal probabilities, and I will argue that well-tested impersonal probabilities acquire features of objective probabilities. Jeffreys's law, my next topic, states that two successful probability forecasters must issue forecasts that are close to each other, thus supporting the idea of objective probabilities. Finally, I will discuss connections between subjective and frequentist probability.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我讨论了主观概率的语法和 semantics。 semantics 确定了概率声明的测试方法。重要的主观概率包括 между人共识概率和无人共识概率，我会 argue 这些经过测试的无人共识概率具有目的对象概率的特征。 Jeffreys's law 是我下一个话题，它表明两个成功的概率预测人必须发布的预测结果几乎相同，从而支持目的对象概率的想法。最后，我会讨论主观概率和频率主义概率之间的关系。
</details></li>
</ul>
<hr>
<h2 id="FusionAI-Decentralized-Training-and-Deploying-LLMs-with-Massive-Consumer-Level-GPUs"><a href="#FusionAI-Decentralized-Training-and-Deploying-LLMs-with-Massive-Consumer-Level-GPUs" class="headerlink" title="FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs"></a>FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01172">http://arxiv.org/abs/2309.01172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenheng Tang, Yuxin Wang, Xin He, Longteng Zhang, Xinglin Pan, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Bingsheng He, Xiaowen Chu</li>
<li>for: 这篇论文旨在解决大型自然语言模型（LLM）的内存和计算需求快速增长，对于没有大规模高端GPU的人员而言，训练或部署LLM受到阻碍。但是，consumer-level GPU却通常被LLM忽略，因为它们的计算能力较弱，储存容量较小，并且通信带宽较低。此外，用户可能有隐私问题在与远端LLM进行互动。</li>
<li>methods: 这篇论文提出了一个分散式系统，以解开consumer-level GPU的潜力在预训、推导和精度调整 LLM 中。但是，这个系统面临了重要挑战，包括CPU和GPU内存有限，低网络带宽，节点和设备多样性。</li>
<li>results: 我们的系统设计包括：1）一个中继处理器，以实现动态加入和退出计算提供者；2）任务排程，以提高系统效率；3）将机器学习过程抽象为指向无顺序图（DAG），以实现模型和任务通用性。我们的性能分析显示，50个RTX 3080 GPU可以 дости持比4个H100 GPU，它们都是许多更昂贵的。<details>
<summary>Abstract</summary>
The rapid growth of memory and computation requirements of large language models (LLMs) has outpaced the development of hardware, hindering people who lack large-scale high-end GPUs from training or deploying LLMs. However, consumer-level GPUs, which constitute a larger market share, are typically overlooked in LLM due to their weaker computing performance, smaller storage capacity, and lower communication bandwidth. Additionally, users may have privacy concerns when interacting with remote LLMs. In this paper, we envision a decentralized system unlocking the potential vast untapped consumer-level GPUs in pre-training, inference and fine-tuning of LLMs with privacy protection. However, this system faces critical challenges, including limited CPU and GPU memory, low network bandwidth, the variability of peer and device heterogeneity. To address these challenges, our system design incorporates: 1) a broker with backup pool to implement dynamic join and quit of computing providers; 2) task scheduling with hardware performance to improve system efficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to achieve model and task universality; 4) abstracting intermediate represention and execution planes to ensure compatibility of various devices and deep learning (DL) frameworks. Our performance analysis demonstrates that 50 RTX 3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are significantly more expensive.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的快速增长对于硬件的开发落后，使得没有大规模高端GPU的人员无法训练或部署LLM。然而，consumer-level GPU占了更大的市场份额，但它们通常在LLM中被忽略因为它们的计算性能较弱、存储容量较小、通信带宽较低。此外，用户可能有隐私问题在与远程LLM互动。本文描述了一个分布式系统，让consumer-level GPU在预训、处理和精确化LLM中发挥潜力，并提供隐私保护。然而，这个系统面临着重要的挑战，包括CPU和GPU内存有限、低网络带宽、执行环境和设备多样性。为解决这些挑战，我们的系统设计包括：1. 中介人员伙伴库，以进行动态加入和退出计算提供者的实现。2. 根据硬件性能进行任务调度，以提高系统效率。3. 将机器学习过程抽象为指向的无向 graphs（DAGs），以实现模型和任务通用性。4. 将中间表示和执行计划抽象为保证不同设备和深度学习（DL）框架的相容性。我们的性能分析显示，50个RTX 3080 GPU可以 achievable throughputs comparable to those of 4个H100 GPU，这些 GPU 的成本很高。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Learning-on-Multimodal-Knowledge-Graphs"><a href="#End-to-End-Learning-on-Multimodal-Knowledge-Graphs" class="headerlink" title="End-to-End Learning on Multimodal Knowledge Graphs"></a>End-to-End Learning on Multimodal Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01169">http://arxiv.org/abs/2309.01169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/wxwilcke/mrgcn">https://gitlab.com/wxwilcke/mrgcn</a></li>
<li>paper_authors: W. X. Wilcke, P. Bloem, V. de Boer, R. H. van t Veer</li>
<li>for:  This paper aims to enable data scientists to learn end-to-end on heterogeneous knowledge by proposing a multimodal message passing network that can learn from the structure of graphs and multimodal node features.</li>
<li>methods:  The proposed model uses dedicated neural encoders to learn embeddings for node features belonging to five different types of modalities, which are then projected into a joint representation space together with their relational information.</li>
<li>results:  The authors implement and demonstrate their model on node classification and link prediction for artificial and real-world datasets, and conduct an inverse ablation study to evaluate the effect that each modality has on the overall performance. The results show that end-to-end multimodal learning from any arbitrary knowledge graph is possible, and that including multimodal information can significantly affect performance, but much depends on the characteristics of the data.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目的是帮助数据科学家通过多Modal的消息传递网络来学习综合知识。</li>
<li>methods: 提议的模型使用专门的神经网络编码器来学习节点特征所属不同类型的多Modalities，然后将其投影到共同表示空间中。</li>
<li>results: 作者实现并在人工和实际世界数据集上进行节点分类和链接预测，并进行反归消除研究来评估每种Modalities对总性能的影响。结果表明，任意知识图Multimodal端到端学习是可能的，并且包含多Modal信息可以对性能产生显著影响，但是这取决于数据的特点。<details>
<summary>Abstract</summary>
Knowledge graphs enable data scientists to learn end-to-end on heterogeneous knowledge. However, most end-to-end models solely learn from the relational information encoded in graphs' structure: raw values, encoded as literal nodes, are either omitted completely or treated as regular nodes without consideration for their values. In either case we lose potentially relevant information which could have otherwise been exploited by our learning methods. We propose a multimodal message passing network which not only learns end-to-end from the structure of graphs, but also from their possibly divers set of multimodal node features. Our model uses dedicated (neural) encoders to naturally learn embeddings for node features belonging to five different types of modalities, including numbers, texts, dates, images and geometries, which are projected into a joint representation space together with their relational information. We implement and demonstrate our model on node classification and link prediction for artificial and real-worlds datasets, and evaluate the effect that each modality has on the overall performance in an inverse ablation study. Our results indicate that end-to-end multimodal learning from any arbitrary knowledge graph is indeed possible, and that including multimodal information can significantly affect performance, but that much depends on the characteristics of the data.
</details>
<details>
<summary>摘要</summary>
知识 graphs 启用数据科学家学习终端到不同类型的知识。然而，大多数终端模型只学习图structure中的关系信息，Raw values 作为literal nodes被完全 omitted 或者 treated as regular nodes without consideration for their values。在这种情况下，我们可能会产生可以利用我们学习方法的潜在信息。我们提议一种多modal message passing network，不仅学习终端从图structure，还从图中可能多样化的多modal node features。我们的模型使用专门（神经网络）编码器来自然学习节点特征的嵌入，包括数字、文本、日期、图像和几何特征，这些特征被投影到共同表示空间中，与关系信息一起。我们实现并示cases on node classification和链接预测任务上，并通过反向减少研究来评估每个模式对总性能的影响。我们的结果表明，从任何arbitrary知识图中进行终端多modal学习是可能的，并且包含多modal信息可以对性能产生重要影响，但是具体取决于数据的特点。
</details></li>
</ul>
<hr>
<h2 id="Spatial-temporal-Vehicle-Re-identification"><a href="#Spatial-temporal-Vehicle-Re-identification" class="headerlink" title="Spatial-temporal Vehicle Re-identification"></a>Spatial-temporal Vehicle Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01166">http://arxiv.org/abs/2309.01166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Zhongdao/VehicleReIDKeyPointData">https://github.com/Zhongdao/VehicleReIDKeyPointData</a></li>
<li>paper_authors: Hye-Geun Kim, YouKyoung Na, Hae-Won Joe, Yong-Hyuk Moon, Yeong-Jun Cho</li>
<li>for: 解决大规模摄像头网络中的车辆重新识别问题，提高公共安全、交通管理和安全性。</li>
<li>methods: 基于可适应Parzen窗法估算相机网络拓扑，并将相机空间temporal相似性和外观相似性合理地融合，使用协调网络进行组合。</li>
<li>results: 在公共数据集（VeRi776）上实现了99.64%的排名1准确率，表明利用空间和时间信息可以提高外观基于方法的准确率，有效地处理车辆外观模糊问题。<details>
<summary>Abstract</summary>
Vehicle re-identification (ReID) in a large-scale camera network is important in public safety, traffic control, and security. However, due to the appearance ambiguities of vehicle, the previous appearance-based ReID methods often fail to track vehicle across multiple cameras. To overcome the challenge, we propose a spatial-temporal vehicle ReID framework that estimates reliable camera network topology based on the adaptive Parzen window method and optimally combines the appearance and spatial-temporal similarities through the fusion network. Based on the proposed methods, we performed superior performance on the public dataset (VeRi776) by 99.64% of rank-1 accuracy. The experimental results support that utilizing spatial and temporal information for ReID can leverage the accuracy of appearance-based methods and effectively deal with appearance ambiguities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-for-Generative-Recommendation-A-Survey-and-Visionary-Discussions"><a href="#Large-Language-Models-for-Generative-Recommendation-A-Survey-and-Visionary-Discussions" class="headerlink" title="Large Language Models for Generative Recommendation: A Survey and Visionary Discussions"></a>Large Language Models for Generative Recommendation: A Survey and Visionary Discussions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01157">http://arxiv.org/abs/2309.01157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Li, Yongfeng Zhang, Dugang Liu, Li Chen</li>
<li>for: 这篇论文主要是为了探讨大语言模型（LLM）在推荐系统（RS）中的应用和发展。</li>
<li>methods: 这篇论文使用了大量的文献研究和分析，探讨了LLM在RS中的应用，包括直接从整个item池中生成推荐。</li>
<li>results: 论文发现，LLM可以在RS中提供更加准确和个性化的推荐，同时也可以简化推荐过程，从而提高推荐系统的效率和可靠性。<details>
<summary>Abstract</summary>
Recent years have witnessed the wide adoption of large language models (LLM) in different fields, especially natural language processing and computer vision. Such a trend can also be observed in recommender systems (RS). However, most of related work treat LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor) which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that the survey can provide the context and guidance needed to explore this interesting and emerging topic.
</details>
<details>
<summary>摘要</summary>
近年来，大语言模型（LLM）在不同领域得到广泛应用，特别是自然语言处理和计算机视觉。这种趋势也可以在推荐系统（RS）中见到。然而，大多数相关工作都将 LLM 视为传统推荐管道的一部分（例如特征提取器），这可能无法充分利用 LLM 的生成能力。相反，可以将推荐过程简化为一个阶段， directly generating recommendations from the complete pool of items，而不是将推荐过程分解为多个阶段，如分数计算和重新排序。本文将评查 LLM 基于生成推荐的进步、方法和未来发展方向。 Specifically, we will examine three questions: 1) What is generative recommendation, 2) Why should RS advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that this survey can provide the necessary context and guidance to explore this interesting and emerging topic.
</details></li>
</ul>
<hr>
<h2 id="FedFwd-Federated-Learning-without-Backpropagation"><a href="#FedFwd-Federated-Learning-without-Backpropagation" class="headerlink" title="FedFwd: Federated Learning without Backpropagation"></a>FedFwd: Federated Learning without Backpropagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01150">http://arxiv.org/abs/2309.01150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seonghwan Park, Dahun Shin, Jinseok Chung, Namhoon Lee</li>
<li>for: 降低 federated learning（FL）中客户端的资源限制，提高训练效率。</li>
<li>methods: 利用 Hinton（2022）提出的 recent BP-free method，即 Forward Forward algorithm，在本地训练过程中进行 layer-wise 地本地更新参数。</li>
<li>results: 在标准dataset上进行了多种实验，如 MNIST 和 CIFAR-10，并显示 FedFwd 与其他 BP-dependent FL 方法相当竞争。<details>
<summary>Abstract</summary>
In federated learning (FL), clients with limited resources can disrupt the training efficiency. A potential solution to this problem is to leverage a new learning procedure that does not rely on backpropagation (BP). We present a novel approach to FL called FedFwd that employs a recent BP-free method by Hinton (2022), namely the Forward Forward algorithm, in the local training process. FedFwd can reduce a significant amount of computations for updating parameters by performing layer-wise local updates, and therefore, there is no need to store all intermediate activation values during training. We conduct various experiments to evaluate FedFwd on standard datasets including MNIST and CIFAR-10, and show that it works competitively to other BP-dependent FL methods.
</details>
<details>
<summary>摘要</summary>
在联合学习（FL）中，客户端具有有限资源可能会干扰训练效率。我们提出一种新的学习方法，不依赖于反卷推（BP）。我们称之为FedFwd，它利用截止往返算法（Hinton，2022），在本地训练过程中进行层次分解更新参数。因此，无需在训练过程中存储所有中间活动值。我们在标准数据集上进行了多种实验，包括MNIST和CIFAR-10，并证明FedFwd与其他依赖于BP的FL方法相当竞争。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Sequence-Clustering"><a href="#Interpretable-Sequence-Clustering" class="headerlink" title="Interpretable Sequence Clustering"></a>Interpretable Sequence Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01140">http://arxiv.org/abs/2309.01140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jd445/Interpretable-Sequence-Clustering-Tree">https://github.com/jd445/Interpretable-Sequence-Clustering-Tree</a></li>
<li>paper_authors: Junjie Dong, Xinyi Yang, Mudi Jiang, Lianyu Hu, Zengyou He</li>
<li>for: 解决 categorical sequence clustering 中 interpretability 问题，提供一种可解释的树结构。</li>
<li>methods:  combinatorial patterns 和 boosting-based construction strategy，first project sequences into random subspaces, then use k-means algorithm to obtain initial cluster assignments, and construct a pattern-based decision tree.</li>
<li>results: 实验结果表明，提posed method 可以提供可解释的树结构，同时具有快速和准确的cluster assignments。<details>
<summary>Abstract</summary>
Categorical sequence clustering plays a crucial role in various fields, but the lack of interpretability in cluster assignments poses significant challenges. Sequences inherently lack explicit features, and existing sequence clustering algorithms heavily rely on complex representations, making it difficult to explain their results. To address this issue, we propose a method called Interpretable Sequence Clustering Tree (ISCT), which combines sequential patterns with a concise and interpretable tree structure. ISCT leverages k-1 patterns to generate k leaf nodes, corresponding to k clusters, which provides an intuitive explanation on how each cluster is formed. More precisely, ISCT first projects sequences into random subspaces and then utilizes the k-means algorithm to obtain high-quality initial cluster assignments. Subsequently, it constructs a pattern-based decision tree using a boosting-based construction strategy in which sequences are re-projected and re-clustered at each node before mining the top-1 discriminative splitting pattern. Experimental results on 14 real-world data sets demonstrate that our proposed method provides an interpretable tree structure while delivering fast and accurate cluster assignments.
</details>
<details>
<summary>摘要</summary>
Note:* "可解释" (可解释) in Chinese means "interpretable" or "explainable".* "序列" (序列) in Chinese means "sequence".* "划分" (划分) in Chinese means "clustering" or "partitioning".* "树" (树) in Chinese means "tree".
</details></li>
</ul>
<hr>
<h2 id="Financial-Fraud-Detection-using-Quantum-Graph-Neural-Networks"><a href="#Financial-Fraud-Detection-using-Quantum-Graph-Neural-Networks" class="headerlink" title="Financial Fraud Detection using Quantum Graph Neural Networks"></a>Financial Fraud Detection using Quantum Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01127">http://arxiv.org/abs/2309.01127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nouhaila Innan, Abhishek Sawaika, Ashim Dhor, Siddhant Dutta, Sairupa Thota, Husayn Gokal, Nandan Patel, Muhammad Al-Zafar Khan, Ioannis Theodonis, Mohamed Bennai</li>
<li>for: 防止金融欺诈和保持金融机构的声誉</li>
<li>methods: 使用量子图 neural network (QGNN) 和变量量子电路 (VQC)</li>
<li>results: 在实际金融欺诈检测数据集上，QGNN 的 AUC 为 0.85，高于 classical GNNHere’s the full translation of the abstract in Simplified Chinese:防止金融欺诈和保持金融机构的声誉是非常重要的。然而，现有的金融欺诈检测方法有限制性，需要新的方法来提高检测率。在这篇论文中，我们提出了一种使用量子图 neural network (QGNN) 和变量量子电路 (VQC) 的新方法，用于检测金融欺诈。我们使用了一个实际的金融欺诈检测数据集，并将 QGNN 与 classical GNN 进行比较。结果显示，QGNN 的 AUC 为 0.85，高于 classical GNN。这些研究表明了 QGNN 的潜在优势，并建议 QGNN 作为改进金融欺诈检测的新方法。<details>
<summary>Abstract</summary>
Financial fraud detection is essential for preventing significant financial losses and maintaining the reputation of financial institutions. However, conventional methods of detecting financial fraud have limited effectiveness, necessitating the need for new approaches to improve detection rates. In this paper, we propose a novel approach for detecting financial fraud using Quantum Graph Neural Networks (QGNNs). QGNNs are a type of neural network that can process graph-structured data and leverage the power of Quantum Computing (QC) to perform computations more efficiently than classical neural networks. Our approach uses Variational Quantum Circuits (VQC) to enhance the performance of the QGNN. In order to evaluate the efficiency of our proposed method, we compared the performance of QGNNs to Classical Graph Neural Networks using a real-world financial fraud detection dataset. The results of our experiments showed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs. Our research highlights the potential of QGNNs and suggests that QGNNs are a promising new approach for improving financial fraud detection.
</details>
<details>
<summary>摘要</summary>
财务欺诈检测是预防重大财务损失和保持金融机构声誉的关键。然而，传统的金融欺诈检测方法有限制，需要新的方法来提高检测率。在这篇论文中，我们提出了一种使用量子图神经网络（QGNN）来检测金融欺诈的新方法。QGNN是一种可以处理图 струкured 数据的神经网络，并且可以利用量子计算（QC）来进行计算，比 классические神经网络更高效。我们的方法使用变量量子电路（VQC）来增强QGNN的性能。为了评估我们的提议的效果，我们比较了QGNN和经典的图神经网络（GNN）在一个真实的金融欺诈检测数据集上的性能。实验结果表明，QGNN达到了 AUC 的 $0.85$，高于经典 GNN。我们的研究表明了 QGNN 的潜在优势，并建议 QGNN 是一种有前途的新方法，可以改善金融欺诈检测。
</details></li>
</ul>
<hr>
<h2 id="MedChatZH-a-Better-Medical-Adviser-Learns-from-Better-Instructions"><a href="#MedChatZH-a-Better-Medical-Adviser-Learns-from-Better-Instructions" class="headerlink" title="MedChatZH: a Better Medical Adviser Learns from Better Instructions"></a>MedChatZH: a Better Medical Adviser Learns from Better Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01114">http://arxiv.org/abs/2309.01114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tyang816/medchatzh">https://github.com/tyang816/medchatzh</a></li>
<li>paper_authors: Yang Tan, Mingchen Li, Zijie Huang, Huiqun Yu, Guisheng Fan</li>
<li>for: 这个研究是为了提高特殊领域的中医Question Answering（QA）系统，使用Generative大型自然语言模型（LLMs）。</li>
<li>methods: 我们使用了特定领域的中医书籍进行预训，并与精心挑选的医疗指令集进行微调。</li>
<li>results: 我们的模型在一个真实的医疗对话数据集上表现出色，超过了几个固定基准的模型。我们释出了我们的模型、代码和数据集，并且鼓励更多的研究者参与这个领域的研究。<details>
<summary>Abstract</summary>
Generative large language models (LLMs) have shown great success in various applications, including question-answering (QA) and dialogue systems. However, in specialized domains like traditional Chinese medical QA, these models may perform unsatisfactorily without fine-tuning on domain-specific datasets. To address this, we introduce MedChatZH, a dialogue model designed specifically for traditional Chinese medical QA. Our model is pre-trained on Chinese traditional medical books and fine-tuned with a carefully curated medical instruction dataset. It outperforms several solid baselines on a real-world medical dialogue dataset. We release our model, code, and dataset on https://github.com/tyang816/MedChatZH to facilitate further research in the domain of traditional Chinese medicine and LLMs.
</details>
<details>
<summary>摘要</summary>
大型生成语言模型（LLMs）在不同应用领域中表现出色，包括问答（QA）和对话系统。然而，在专门的中文传统医学问答领域中，这些模型可能无法达到预期的性能，需要进行域pecific的 fine-tuning。为解决这个问题，我们介绍了MedChatZH，一种专门为中文传统医学问答设计的对话模型。我们的模型在中文传统医学书籍上进行预训练，并与仔细编辑的医学指导数据集进行了精度调整。与几个固定基eline相比，我们的模型在真实的医学对话数据集上表现出色。我们将我们的模型、代码和数据集发布到https://github.com/tyang816/MedChatZH，以便进一步的研究在中文传统医学领域和LLMs之间的关系。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Implementation-of-Generative-AI-Services-Using-an-Enterprise-Data-Based-LLM-Application-Architecture"><a href="#A-Study-on-the-Implementation-of-Generative-AI-Services-Using-an-Enterprise-Data-Based-LLM-Application-Architecture" class="headerlink" title="A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture"></a>A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01105">http://arxiv.org/abs/2309.01105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheonsu Jeong</li>
<li>for: 本研究旨在提供一种基于大语言模型（LLM）应用架构的生成AI服务实现方法。</li>
<li>methods: 本研究使用精度调整技术和直接文档 интеграción来缓解数据缺乏问题，并开发了一种名为Retrieval-Augmented Generation（RAG）模型，以提高信息存储和检索过程，从而改善内容生成。</li>
<li>results: 研究表明，RAG模型能够有效地缓解数据缺乏问题，并且可以在实际应用中提高LLM服务的可用性。<details>
<summary>Abstract</summary>
This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings.
</details>
<details>
<summary>摘要</summary>
The study introduces a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges by enhancing information storage and retrieval processes. The RAG model is carefully designed to improve content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model, and a comprehensive analysis of these steps is undertaken to emphasize their significance in addressing data scarcity.The study demonstrates the efficacy of the proposed method through illustrative instances, showcasing its applicability within enterprises utilizing LLMs. By implementing the RAG model for information storage and retrieval, the research contributes to a deeper understanding of generative AI technology and facilitates its practical usability within corporate settings. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services.
</details></li>
</ul>
<hr>
<h2 id="M2HGCL-Multi-Scale-Meta-Path-Integrated-Heterogeneous-Graph-Contrastive-Learning"><a href="#M2HGCL-Multi-Scale-Meta-Path-Integrated-Heterogeneous-Graph-Contrastive-Learning" class="headerlink" title="M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive Learning"></a>M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01101">http://arxiv.org/abs/2309.01101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Guo, Yu Xia, Rui Wang, Rongcheng Duan, Lu Li, Jiangmeng Li</li>
<li>for:  This paper focuses on improving the performance of heterogeneous graph contrastive learning models by proposing a new multi-scale meta-path integrated model (M2HGCL) that captures discriminative information from various types of meta-paths.</li>
<li>methods:  The proposed M2HGCL model discards the conventional heterogeneity-homogeneity transformation and performs graph contrastive learning in a joint manner, aggregating direct neighbor information, initial meta-path neighbor information, and expanded meta-path neighbor information to capture sufficient discriminative information.</li>
<li>results:  The proposed M2HGCL model outperforms current state-of-the-art baseline models on three real-world datasets through extensive experiments, demonstrating its effectiveness in improving the performance of heterogeneous graph contrastive learning models.<details>
<summary>Abstract</summary>
Inspired by the successful application of contrastive learning on graphs, researchers attempt to impose graph contrastive learning approaches on heterogeneous information networks. Orthogonal to homogeneous graphs, the types of nodes and edges in heterogeneous graphs are diverse so that specialized graph contrastive learning methods are required. Most existing methods for heterogeneous graph contrastive learning are implemented by transforming heterogeneous graphs into homogeneous graphs, which may lead to ramifications that the valuable information carried by non-target nodes is undermined thereby exacerbating the performance of contrastive learning models. Additionally, current heterogeneous graph contrastive learning methods are mainly based on initial meta-paths given by the dataset, yet according to our deep-going exploration, we derive empirical conclusions: only initial meta-paths cannot contain sufficiently discriminative information; and various types of meta-paths can effectively promote the performance of heterogeneous graph contrastive learning methods. To this end, we propose a new multi-scale meta-path integrated heterogeneous graph contrastive learning (M2HGCL) model, which discards the conventional heterogeneity-homogeneity transformation and performs the graph contrastive learning in a joint manner. Specifically, we expand the meta-paths and jointly aggregate the direct neighbor information, the initial meta-path neighbor information and the expanded meta-path neighbor information to sufficiently capture discriminative information. A specific positive sampling strategy is further imposed to remedy the intrinsic deficiency of contrastive learning, i.e., the hard negative sample sampling issue. Through extensive experiments on three real-world datasets, we demonstrate that M2HGCL outperforms the current state-of-the-art baseline models.
</details>
<details>
<summary>摘要</summary>
研究人员受到同化学习在图上的成功应用的启发，尝试将同化学习方法应用于不同类型节点和边的异质图。与同质图不同的是，异质图中节点和边的类型多样化，因此需要特化的同化学习方法。现有的异质图同化学习方法大多是通过将异质图转化为同质图来实现，这可能会导致非目标节点上的有价信息被抑制，从而降低同化学习模型的性能。另外，现有的异质图同化学习方法主要基于数据集提供的初始元PATH，但根据我们的深入探索，我们得出了实证结论：只有初始元PATH不能含有足够的分化信息；而不同类型的元PATH可以有效提高异质图同化学习模型的性能。为此，我们提出了一种新的多级元PATH集成的异质图同化学习（M2HGCL）模型，该模型不需要将异质图转化为同质图，而是直接在异质图上进行同化学习。具体来说，我们将元PATH扩展，并同时对直接邻居信息、初始元PATH邻居信息和扩展元PATH邻居信息进行联合聚合，以足够捕捉分化信息。此外，我们还采用了一种特定的正样本采样策略，以解决对异质图同化学习的内在缺陷，即困难的负样本采样问题。通过对三个实际数据集进行广泛的实验，我们证明了M2HGCL模型比现状之最先进基eline模型具有更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Stabilize-to-Act-Learning-to-Coordinate-for-Bimanual-Manipulation"><a href="#Stabilize-to-Act-Learning-to-Coordinate-for-Bimanual-Manipulation" class="headerlink" title="Stabilize to Act: Learning to Coordinate for Bimanual Manipulation"></a>Stabilize to Act: Learning to Coordinate for Bimanual Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01087">http://arxiv.org/abs/2309.01087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jennifer Grannen, Yilin Wu, Brandon Vu, Dorsa Sadigh</li>
<li>for: 这篇论文旨在提供一种解决高维控制问题的策略，以便在两手控制系统中实现高级别的掌控能力。</li>
<li>methods: 该策略基于人类的启发，提出了一种新的角色分配框架，其中一个稳定臂用于保持物品不变，而另一个执行臂用于完成任务。该框架使用一个学习的稳定 repositing 类型来 alternate между维护稳定位置和执行任务。</li>
<li>results: 在四种不同复杂度的双手任务上，BUDS 使用 20 个示例并达到 76.9% 的任务成功率，并能够在不同类型的对象上进行扩展。相比之下，不结构化基线方法只能达到 43.3% 的成功率。<details>
<summary>Abstract</summary>
Key to rich, dexterous manipulation in the real world is the ability to coordinate control across two hands. However, while the promise afforded by bimanual robotic systems is immense, constructing control policies for dual arm autonomous systems brings inherent difficulties. One such difficulty is the high-dimensionality of the bimanual action space, which adds complexity to both model-based and data-driven methods. We counteract this challenge by drawing inspiration from humans to propose a novel role assignment framework: a stabilizing arm holds an object in place to simplify the environment while an acting arm executes the task. We instantiate this framework with BimanUal Dexterity from Stabilization (BUDS), which uses a learned restabilizing classifier to alternate between updating a learned stabilization position to keep the environment unchanged, and accomplishing the task with an acting policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of varying complexities on real-world robots, such as zipping jackets and cutting vegetables. Given only 20 demonstrations, BUDS achieves 76.9% task success across our task suite, and generalizes to out-of-distribution objects within a class with a 52.7% success rate. BUDS is 56.0% more successful than an unstructured baseline that instead learns a BC stabilizing policy due to the precision required of these complex tasks. Supplementary material and videos can be found at https://sites.google.com/view/stabilizetoact .
</details>
<details>
<summary>摘要</summary>
针对实际世界中的灵活操作，关键是在两手之间协调控制。然而，建立双手自主系统的控制策略具有内在的挑战。一个这样的挑战是双手动作空间的高维度，这会使模型基于方法和数据驱动方法都变得复杂。我们从人类的经验中着想出一种新的角色分配框架：一个稳定化手持物体以简化环境，而另一个执行手执行任务。我们实现了这种框架，并命名为BUDS（双手稳定到行动），它使用一个学习的稳定化分类器来 alternate между更新一个学习的稳定化位置，以保持环境不变，并使用一个学习来自示例的行动策略来完成任务。我们在四个不同复杂度的双手任务上进行了实验，包括zip Jackets和切 vegetables，并只需20个示例来 achieve 76.9%的任务成功率。此外，BUDS还能够在不同类型的物体上generalize，并在不同的环境中保持52.7%的成功率。相比之下，不结构化的基准模型只能达到56.0%的成功率。详细的材料和视频可以在https://sites.google.com/view/stabilizetoact找到。
</details></li>
</ul>
<hr>
<h2 id="UnsMOT-Unified-Framework-for-Unsupervised-Multi-Object-Tracking-with-Geometric-Topology-Guidance"><a href="#UnsMOT-Unified-Framework-for-Unsupervised-Multi-Object-Tracking-with-Geometric-Topology-Guidance" class="headerlink" title="UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with Geometric Topology Guidance"></a>UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with Geometric Topology Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01078">http://arxiv.org/abs/2309.01078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Son Tran, Cong Tran, Anh Tran, Cuong Pham</li>
<li>for: 提高无监督多目标跟踪（MOT）方法的性能，避免高昂的数据标注成本。</li>
<li>methods: 提出了一种名为UnsMOT的新框架，其将视觉特征和动作特征与几何信息结合，以提供更准确的跟踪。</li>
<li>results: 实验结果表明，与现有方法相比，UnsMOT方法在HOTA、IDF1和MOTA指标上表现出色。<details>
<summary>Abstract</summary>
Object detection has long been a topic of high interest in computer vision literature. Motivated by the fact that annotating data for the multi-object tracking (MOT) problem is immensely expensive, recent studies have turned their attention to the unsupervised learning setting. In this paper, we push forward the state-of-the-art performance of unsupervised MOT methods by proposing UnsMOT, a novel framework that explicitly combines the appearance and motion features of objects with geometric information to provide more accurate tracking. Specifically, we first extract the appearance and motion features using CNN and RNN models, respectively. Then, we construct a graph of objects based on their relative distances in a frame, which is fed into a GNN model together with CNN features to output geometric embedding of objects optimized using an unsupervised loss function. Finally, associations between objects are found by matching not only similar extracted features but also geometric embedding of detections and tracklets. Experimental results show remarkable performance in terms of HOTA, IDF1, and MOTA metrics in comparison with state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
We first extract object appearance features using a convolutional neural network (CNN) and motion features using a recurrent neural network (RNN). Then, we create a graph of objects based on their relative distances in a frame, which is fed into a graph neural network (GNN) together with CNN features. The GNN outputs geometric embeddings of objects that are optimized using an unsupervised loss function. Finally, we use both feature extraction and geometric embedding to associate objects, by matching not only similar extracted features but also the geometric embeddings of detections and tracklets.Our experimental results show impressive performance in terms of HOTA, IDF1, and MOTA metrics, outperforming state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Multidomain-transformer-based-deep-learning-for-early-detection-of-network-intrusion"><a href="#Multidomain-transformer-based-deep-learning-for-early-detection-of-network-intrusion" class="headerlink" title="Multidomain transformer-based deep learning for early detection of network intrusion"></a>Multidomain transformer-based deep learning for early detection of network intrusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01070">http://arxiv.org/abs/2309.01070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinxin Liu, Murat Simsek, Michele Nogueira, Burak Kantarci</li>
<li>For: This paper aims to improve the timeliness of Network Intrusion Detection Systems (NIDS) by using Multivariate Time Series (MTS) early detection to identify malicious flows before they reach their target systems.* Methods: The paper proposes a novel feature extractor called Time Series Network Flow Meter (TS-NFM) to represent network flows as MTS with explainable features. It also introduces a new deep learning-based early detection model called Multi-Domain Transformer (MDT) that incorporates the frequency domain into Transformer, and a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve feature extraction.* Results: The proposed methodology improves the earliness of conventional NIDS by 5x10^4 times and duration-based earliness by a factor of 60, resulting in a 84.1% macro F1 score (31% higher than Transformer) on the SCVIC-TS-2022 dataset. The proposed MDT also outperforms state-of-the-art early detection methods by 5% and 6% on ECG and Wafer datasets, respectively.<details>
<summary>Abstract</summary>
Timely response of Network Intrusion Detection Systems (NIDS) is constrained by the flow generation process which requires accumulation of network packets. This paper introduces Multivariate Time Series (MTS) early detection into NIDS to identify malicious flows prior to their arrival at target systems. With this in mind, we first propose a novel feature extractor, Time Series Network Flow Meter (TS-NFM), that represents network flow as MTS with explainable features, and a new benchmark dataset is created using TS-NFM and the meta-data of CICIDS2017, called SCVIC-TS-2022. Additionally, a new deep learning-based early detection model called Multi-Domain Transformer (MDT) is proposed, which incorporates the frequency domain into Transformer. This work further proposes a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve the ability of MDT to extract better features. Based on the experimental results, the proposed methodology improves the earliness of the conventional NIDS (i.e., percentage of packets that are used for classification) by 5x10^4 times and duration-based earliness (i.e., percentage of duration of the classified packets of a flow) by a factor of 60, resulting in a 84.1% macro F1 score (31% higher than Transformer) on SCVIC-TS-2022. Additionally, the proposed MDT outperforms the state-of-the-art early detection methods by 5% and 6% on ECG and Wafer datasets, respectively.
</details>
<details>
<summary>摘要</summary>
timely response of Network Intrusion Detection Systems (NIDS) 是受流生成过程的限制，需要accumulation of network packets。这篇论文介绍了Multivariate Time Series (MTS) early detection into NIDS，以识别恶意流之前到达目标系统。为此，我们首先提出了一种新的特征提取器，Time Series Network Flow Meter (TS-NFM)，它将网络流转换为MTS，并提取可解释的特征。此外，我们还创建了一个新的benchmark dataset，使用TS-NFM和CICIDS2017的元数据，称为SCVIC-TS-2022。此外，我们还提出了一种新的深度学习基于Transformer的早期检测模型，即Multi-Domain Transformer (MDT)，它在频率频谱中包含Transformer。此外，我们还提出了一种Multi-Domain Multi-Head Attention (MD-MHA)机制，以提高MTD的特征提取能力。根据实验结果，我们的方法提高了传统NIDS的早期响应（即流经过核心率）5x10^4倍，并提高了持续时间基于的早期响应（即分类后的流 duration）的因子60，从而达到了84.1%的macro F1分数（31%高于Transformer）。此外，我们的MTD还超过了当前早期检测方法的状态。
</details></li>
</ul>
<hr>
<h2 id="Separable-Hamiltonian-Neural-Networks"><a href="#Separable-Hamiltonian-Neural-Networks" class="headerlink" title="Separable Hamiltonian Neural Networks"></a>Separable Hamiltonian Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01069">http://arxiv.org/abs/2309.01069</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zykhoo/separablenns">https://github.com/zykhoo/separablenns</a></li>
<li>paper_authors: Zi-Yu Khoo, Jonathan Sze Choong Low, Stéphane Bressan</li>
<li>for: 用于透过确定数据库中的问题，推断汉密尔数据的问题。</li>
<li>methods: 使用汉密尔神经网络，将汉密尔系统的问题转化为确定的数据库中的问题，并将问题转化为确定的数据库中的问题。</li>
<li>results: 透过将问题转化为确定的数据库中的问题，使得汉密尔神经网络可以更好地预测汉密尔系统的问题。<details>
<summary>Abstract</summary>
The modelling of dynamical systems from discrete observations is a challenge faced by modern scientific and engineering data systems. Hamiltonian systems are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian neural networks are state-of-the-art models that unsupervised-ly regress the Hamiltonian of a dynamical system from discrete observations of its vector field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics are often complicated, especially in higher dimensions where the state space of the Hamiltonian system is large relative to the number of samples. A recently discovered remedy to alleviate the complexity between state variables in the state space is to leverage the additive separability of the Hamiltonian system and embed that additive separability into the Hamiltonian neural network. Following the nomenclature of physics-informed machine learning, we propose three separable Hamiltonian neural networks. These models embed additive separability within Hamiltonian neural networks. The first model uses additive separability to quadratically scale the amount of data for training Hamiltonian neural networks. The second model embeds additive separability within the loss function of the Hamiltonian neural network. The third model embeds additive separability through the architecture of the Hamiltonian neural network using conjoined multilayer perceptions. We empirically compare the three models against state-of-the-art Hamiltonian neural networks, and demonstrate that the separable Hamiltonian neural networks, which alleviate complexity between the state variables, are more effective at regressing the Hamiltonian and its vector field.
</details>
<details>
<summary>摘要</summary>
现代科学和工程数据系统中模拟动力系统从离散观察数据是一个挑战。哈密顿系统是这种基本和普遍的动力系统之一。哈密顿神经网络是目前的状态艺术模型，可以无监督地将哈密顿系统的劳动量从离散观察数据的向量场中预测。然而，哈密顿动力学在更高维度时可能会变得复杂，特别是当状态空间的维度远大于样本数时。为了缓解状态变量之间的复杂性，我们提出了利用哈密顿系统的添加性分解性来附加到哈密顿神经网络中。根据物理学教育机器学习的命名，我们提出了三种分解哈密顿神经网络。这些模型在哈密顿神经网络中嵌入添加性分解性。第一个模型通过添加性来幂等增加训练哈密顿神经网络的数据量。第二个模型在哈密顿神经网络的损失函数中嵌入添加性。第三个模型通过哈密顿神经网络的建筑嵌入添加性，使用共同多层感知。我们对现有的哈密顿神经网络进行了比较，并证明了分解哈密顿神经网络在预测哈密顿和其向量场方面更有效。
</details></li>
</ul>
<hr>
<h2 id="AB2CD-AI-for-Building-Climate-Damage-Classification-and-Detection"><a href="#AB2CD-AI-for-Building-Climate-Damage-Classification-and-Detection" class="headerlink" title="AB2CD: AI for Building Climate Damage Classification and Detection"></a>AB2CD: AI for Building Climate Damage Classification and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01066">http://arxiv.org/abs/2309.01066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Nitsche, S. Karthik Mukkavilli, Niklas Kühl, Thomas Brunschwiler</li>
<li>for: 本研究旨在应用深度学习技术精确评估自然灾害中的建筑物损坏，使用遥测数据。</li>
<li>methods: 我们使用了不同的深度学习模型，包括差分径等径网络、内部对称网络和双路网络，以及ensemble技术，并评估了不同对应的测试集。</li>
<li>results: 我们的研究结果显示，使用3米以下的卫星影像分辨率可以实现高精度的建筑物损坏推断，并且使用不同的深度学习模型可以实现不同程度的准确性。<details>
<summary>Abstract</summary>
We explore the implementation of deep learning techniques for precise building damage assessment in the context of natural hazards, utilizing remote sensing data. The xBD dataset, comprising diverse disaster events from across the globe, serves as the primary focus, facilitating the evaluation of deep learning models. We tackle the challenges of generalization to novel disasters and regions while accounting for the influence of low-quality and noisy labels inherent in natural hazard data. Furthermore, our investigation quantitatively establishes that the minimum satellite imagery resolution essential for effective building damage detection is 3 meters and below 1 meter for classification using symmetric and asymmetric resolution perturbation analyses. To achieve robust and accurate evaluations of building damage detection and classification, we evaluated different deep learning models with residual, squeeze and excitation, and dual path network backbones, as well as ensemble techniques. Overall, the U-Net Siamese network ensemble with F-1 score of 0.812 performed the best against the xView2 challenge benchmark. Additionally, we evaluate a Universal model trained on all hazards against a flood expert model and investigate generalization gaps across events, and out of distribution from field data in the Ahr Valley. Our research findings showcase the potential and limitations of advanced AI solutions in enhancing the impact assessment of climate change-induced extreme weather events, such as floods and hurricanes. These insights have implications for disaster impact assessment in the face of escalating climate challenges.
</details>
<details>
<summary>摘要</summary>
我们探讨了深度学习技术的应用于精准建筑损害评估中，利用遥感数据，在自然灾害背景下。xBD数据集，包括全球各地不同类型灾害事件，作为主要关注对象，以评估深度学习模型。我们解决了对新灾害和地区总结的挑战，同时考虑了自然灾害数据中的低质量和噪音标签的影响。进一步，我们发现了卫星遥感分辨率最低为3米以下，以下1米为类型分类使用对称和非对称分辨率扰动分析。为实现Robust和准确的建筑损害检测和分类，我们评估了不同的深度学习模型，包括剩余、挤压和激活、双路网络框架。综合来说，U-Net Siamese网络集成 Ensemble架构，F-1分数0.812，在xView2挑战benchmark中表现最佳。此外，我们还评估了对所有灾害的通用模型，并 investigate了不同事件之间的总结差和场景数据外部的差异。我们的研究发现，高级AI解决方案在气候变化引起的极端天气事件的影响评估中具有潜力，但同时也存在局限性。这些发现对气候变化的挑战下的灾害影响评估产生了重要的意义。
</details></li>
</ul>
<hr>
<h2 id="Generative-Data-Augmentation-using-LLMs-improves-Distributional-Robustness-in-Question-Answering"><a href="#Generative-Data-Augmentation-using-LLMs-improves-Distributional-Robustness-in-Question-Answering" class="headerlink" title="Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering"></a>Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06358">http://arxiv.org/abs/2309.06358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Ghosh Chowdhury, Aman Chadha</li>
<li>for:  investigate the influence of generated datasets on the performance of QA models under natural distribution shifts</li>
<li>methods:  two-step generation approach, generating both contexts and QA pairs to augment existing datasets</li>
<li>results:  augmenting reading comprehension datasets with generated data leads to better robustness towards natural distribution shifts<details>
<summary>Abstract</summary>
Robustness in Natural Language Processing continues to be a pertinent issue, where state of the art models under-perform under naturally shifted distributions. In the context of Question Answering, work on domain adaptation methods continues to be a growing body of research. However, very little attention has been given to the notion of domain generalization under natural distribution shifts, where the target domain is unknown. With drastic improvements in the quality and access to generative models, we answer the question: How do generated datasets influence the performance of QA models under natural distribution shifts? We perform experiments on 4 different datasets under varying amounts of distribution shift, and analyze how "in-the-wild" generation can help achieve domain generalization. We take a two-step generation approach, generating both contexts and QA pairs to augment existing datasets. Through our experiments, we demonstrate how augmenting reading comprehension datasets with generated data leads to better robustness towards natural distribution shifts.
</details>
<details>
<summary>摘要</summary>
natural language processing 的 robustness 仍然是一个有问题的issue, 现代模型在自然地shifted distributions下表现不佳。在问答领域中, 关于领域适应方法的研究继续增长。然而, 很少注意到target domain是未知的情况下的领域普遍化。随着生成模型的提高和生成数据的可用性的提高, 我们回答了 Question Answering 模型在自然分布shift下的性能如何受到生成数据的影响。我们在4个不同的 dataset上进行了不同量的分布shift的实验，并分析了如何在�nit-in-the-wild�生成数据的帮助下实现领域普遍化。我们采用了two-step generation方法，首先生成了上下文，然后生成了问题和答案的对。通过我们的实验，我们证明了增强阅读理解dataset的可Generated data可以提高模型对自然分布shift的 Robustness。
</details></li>
</ul>
<hr>
<h2 id="Integration-of-Vision-based-Object-Detection-and-Grasping-for-Articulated-Manipulator-in-Lunar-Conditions"><a href="#Integration-of-Vision-based-Object-Detection-and-Grasping-for-Articulated-Manipulator-in-Lunar-Conditions" class="headerlink" title="Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions"></a>Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01055">http://arxiv.org/abs/2309.01055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Camille Boucher, Gustavo H. Diaz, Shreya Santra, Kentaro Uno, Kazuya Yoshida</li>
<li>for: 这篇论文是为了开发 lunar robot 应用程序而写的。</li>
<li>methods: 这篇论文使用了视觉基础框架，包括物体检测、实例分割和抓取检测，以实现不同应用程序的 integrate。</li>
<li>results: 在具有不平面表面和困难照明条件的情况下，这篇论文达到了92%的成功率，并实现了使用视觉系统结果进行不同应用程序的 assemble 任务。<details>
<summary>Abstract</summary>
The integration of vision-based frameworks to achieve lunar robot applications faces numerous challenges such as terrain configuration or extreme lighting conditions. This paper presents a generic task pipeline using object detection, instance segmentation and grasp detection, that can be used for various applications by using the results of these vision-based systems in a different way. We achieve a rock stacking task on a non-flat surface in difficult lighting conditions with a very good success rate of 92%. Eventually, we present an experiment to assemble 3D printed robot components to initiate more complex tasks in the future.
</details>
<details>
<summary>摘要</summary>
具有视觉基础框架的月球机器人应用面临许多挑战，如地形配置和极端照明条件。本文提出了一个通用任务管道，使用物体检测、实例分割和抓取检测来实现多种应用。我们在非平面表面下实现了一个石堆任务，并在困难的照明条件下达到了92%的成功率。最后，我们展示了将3D打印机器人组件 assembling 以实现更复杂的任务。Note: Please keep in mind that the translation is Simplified Chinese, and some words or phrases may have different translations in Traditional Chinese.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.AI_2023_09_03/" data-id="cloh3sqtb003dh688edp90klz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.CL_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T11:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.CL_2023_09_03/">cs.CL - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="BDC-Adapter-Brownian-Distance-Covariance-for-Better-Vision-Language-Reasoning"><a href="#BDC-Adapter-Brownian-Distance-Covariance-for-Better-Vision-Language-Reasoning" class="headerlink" title="BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning"></a>BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01256">http://arxiv.org/abs/2309.01256</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rambo-coder/BDC-Adapter">https://github.com/rambo-coder/BDC-Adapter</a></li>
<li>paper_authors: Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He</li>
<li>for: 本研究旨在开发轻量级 fine-tuning 技术，以适应下游视觉任务。</li>
<li>methods: 本研究提出了 Brownian Distance Covariance (BDC)  метри克，用于度量视觉语言理解中的特征相依关系。基于该 metric，我们提出了一种名为 BDC-Adapter 的新方法，该方法通过组合 BDC  прототипы相似预测和多模态预测网络来实现分类任务。</li>
<li>results: 我们的实验结果表明，BDC-Adapter 可以自由处理非线性关系，全面捕捉独立性，与当前状态的方法相比，具有大幅度的提升。<details>
<summary>Abstract</summary>
Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP and ALIGN, have introduced a new paradigm for learning transferable visual representations. Recently, there has been a surge of interest among researchers in developing lightweight fine-tuning techniques to adapt these models to downstream visual tasks. We recognize that current state-of-the-art fine-tuning methods, such as Tip-Adapter, simply consider the covariance between the query image feature and features of support few-shot training samples, which only captures linear relations and potentially instigates a deceptive perception of independence. To address this issue, in this work, we innovatively introduce Brownian Distance Covariance (BDC) to the field of vision-language reasoning. The BDC metric can model all possible relations, providing a robust metric for measuring feature dependence. Based on this, we present a novel method called BDC-Adapter, which integrates BDC prototype similarity reasoning and multi-modal reasoning network prediction to perform classification tasks. Our extensive experimental results show that the proposed BDC-Adapter can freely handle non-linear relations and fully characterize independence, outperforming the current state-of-the-art methods by large margins.
</details>
<details>
<summary>摘要</summary>
大规模预训练视语模型（VLM），如CLIP和ALIGN，已经引入了学习可转移的视觉表示的新 paradigm。最近，研究人员对下游视觉任务适应这些模型的轻量级练习技术表示了很大的兴趣。我们认为现今最佳练习方法，如Tip-Adapter，只考虑了查询图像特征和支持几个少量训练样本的特征之间的covariance，这只captures linear relations,可能导致误导性的独立性概念。为解决这个问题，在这项工作中，我们创新地引入了浮动距离covariance（BDC）到视觉语言理解领域。BDC指标可以模型所有可能的关系，提供一种可靠的指标来衡量特征相互关系。基于这，我们提出了一种新方法called BDC-Adapter，它通过组合BDC原型相似性逻辑和多模态逻辑网络预测来实现分类任务。我们的广泛实验结果表明，我们的提议的BDC-Adapter可以自由地处理非线性关系，具有完全characterize独立性的优势，在与当前状态艺术方法比较大的差异。
</details></li>
</ul>
<hr>
<h2 id="Attention-Where-It-Matters-Rethinking-Visual-Document-Understanding-with-Selective-Region-Concentration"><a href="#Attention-Where-It-Matters-Rethinking-Visual-Document-Understanding-with-Selective-Region-Concentration" class="headerlink" title="Attention Where It Matters: Rethinking Visual Document Understanding with Selective Region Concentration"></a>Attention Where It Matters: Rethinking Visual Document Understanding with Selective Region Concentration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01131">http://arxiv.org/abs/2309.01131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Cao, Changcun Bao, Chaohu Liu, Huang Chen, Kun Yin, Hao Liu, Yinsong Liu, Deqiang Jiang, Xing Sun</li>
<li>for: 提高文档理解效率和精度</li>
<li>methods: 使用选择性区域理解模型（SeRum），该模型将文档图像理解和识别任务转化为地图上的本地解码过程，使模型更加注意力集中于Query解码器生成的区域关键。</li>
<li>results: 实验结果表明，SeRum在文档理解任务中达到了国际级性能，并在文本检索任务中获得了竞争力。<details>
<summary>Abstract</summary>
We propose a novel end-to-end document understanding model called SeRum (SElective Region Understanding Model) for extracting meaningful information from document images, including document analysis, retrieval, and office automation.   Unlike state-of-the-art approaches that rely on multi-stage technical schemes and are computationally expensive,   SeRum converts document image understanding and recognition tasks into a local decoding process of the visual tokens of interest, using a content-aware token merge module.   This mechanism enables the model to pay more attention to regions of interest generated by the query decoder, improving the model's effectiveness and speeding up the decoding speed of the generative scheme.   We also designed several pre-training tasks to enhance the understanding and local awareness of the model.   Experimental results demonstrate that SeRum achieves state-of-the-art performance on document understanding tasks and competitive results on text spotting tasks.   SeRum represents a substantial advancement towards enabling efficient and effective end-to-end document understanding.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的综合型文档理解模型，叫做SeRum（选择区域理解模型），用于从文档图像中提取有意义信息，包括文档分析、检索和办公自动化。 unlike现有的方法，SeRum不仅通过多个阶段技术实现，而且计算成本较高。 SeRum将文档图像理解和识别任务转化为当地解码过程，使用内容相关的字符串融合模块。这种机制使得模型更加注重查询解码器生成的区域兴趣，从而提高模型的效果和加速生成方案的解码速度。我们还设计了一些预训练任务，以增强模型的理解和地方意识。实验结果表明，SeRum在文档理解任务上达到了现有最佳性能，并在文本检索任务上获得了竞争性的成绩。SeRum代表了综合型文档理解的重要进步，它可以帮助实现高效、高效的文档理解。
</details></li>
</ul>
<hr>
<h2 id="Business-Process-Text-Sketch-Automation-Generation-Using-Large-Language-Model"><a href="#Business-Process-Text-Sketch-Automation-Generation-Using-Large-Language-Model" class="headerlink" title="Business Process Text Sketch Automation Generation Using Large Language Model"></a>Business Process Text Sketch Automation Generation Using Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01071">http://arxiv.org/abs/2309.01071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Zhu, Quanzhou Hu, Wenxin Li, Honghao Xiao, Chaogang Wang, Zixin Zhou<br>for: This paper aims to address the challenge of business process document generation in the absence of datasets, and to provide a solution for improving the correctness of data-driven deep learning techniques in this domain.methods: The authors propose an approach that transforms Conditional Process Trees (CPTs) into Business Process Text Sketches (BPTSs) using Large Language Models (LLMs). They also introduce a divide-and-conquer strategy to break down difficult CPTs into smaller, more manageable parts.results: The authors report a correct rate of 93.42% using their proposed method, which is 45.17% better than traditional prompting methods. Their approach has the potential to provide a large number of datasets for the process model extraction (PME) domain.<details>
<summary>Abstract</summary>
Business Process Management (BPM) is gaining increasing attention as it has the potential to cut costs while boosting output and quality. Business process document generation is a crucial stage in BPM. However, due to a shortage of datasets, data-driven deep learning techniques struggle to deliver the expected results. We propose an approach to transform Conditional Process Trees (CPTs) into Business Process Text Sketches (BPTSs) using Large Language Models (LLMs). The traditional prompting approach (Few-shot In-Context Learning) tries to get the correct answer in one go, and it can find the pattern of transforming simple CPTs into BPTSs, but for close-domain and CPTs with complex hierarchy, the traditional prompts perform weakly and with low correctness. We suggest using this technique to break down a difficult CPT into a number of basic CPTs and then solve each one in turn, drawing inspiration from the divide-and-conquer strategy. We chose 100 process trees with depths ranging from 2 to 5 at random, as well as CPTs with many nodes, many degrees of selection, and cyclic nesting. Experiments show that our method can achieve a correct rate of 93.42%, which is 45.17% better than traditional prompting methods. Our proposed method provides a solution for business process document generation in the absence of datasets, and secondly, it becomes potentially possible to provide a large number of datasets for the process model extraction (PME) domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.CL_2023_09_03/" data-id="cloh3sqv8009xh6889d591sop" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.LG_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T10:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.LG_2023_09_03/">cs.LG - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Federated-Orthogonal-Training-Mitigating-Global-Catastrophic-Forgetting-in-Continual-Federated-Learning"><a href="#Federated-Orthogonal-Training-Mitigating-Global-Catastrophic-Forgetting-in-Continual-Federated-Learning" class="headerlink" title="Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"></a>Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01289">http://arxiv.org/abs/2309.01289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yavuz Faruk Bakman, Duygu Nur Yaldiz, Yahya H. Ezzeldin, Salman Avestimehr</li>
<li>for: 本文探讨了隐私保护训练在分布式数据上的 Federated Learning (FL) 中的持续学习问题，具体来说是 Continual Federated Learning (CFL) 问题。</li>
<li>methods: 本文提出了一种新的方法 called Federated Orthogonal Training (FOT)，它利用层的全球输入子空间来避免全球忘记现象，并通过对新任务的聚合更新进行修正，使其与老任务的全球主方向 orthogonal。</li>
<li>results: 实验表明，FOT 方法可以在 CFL  Setting 中超过现有状态的持续学习方法，实现了最高的准确率提升（最高达 15%），同时具有较低的计算和通信成本（27% 下降），而且不违反隐私原则。<details>
<summary>Abstract</summary>
Federated Learning (FL) has gained significant attraction due to its ability to enable privacy-preserving training over decentralized data. Current literature in FL mostly focuses on single-task learning. However, over time, new tasks may appear in the clients and the global model should learn these tasks without forgetting previous tasks. This real-world scenario is known as Continual Federated Learning (CFL). The main challenge of CFL is Global Catastrophic Forgetting, which corresponds to the fact that when the global model is trained on new tasks, its performance on old tasks decreases. There have been a few recent works on CFL to propose methods that aim to address the global catastrophic forgetting problem. However, these works either have unrealistic assumptions on the availability of past data samples or violate the privacy principles of FL. We propose a novel method, Federated Orthogonal Training (FOT), to overcome these drawbacks and address the global catastrophic forgetting in CFL. Our algorithm extracts the global input subspace of each layer for old tasks and modifies the aggregated updates of new tasks such that they are orthogonal to the global principal subspace of old tasks for each layer. This decreases the interference between tasks, which is the main cause for forgetting. We empirically show that FOT outperforms state-of-the-art continual learning methods in the CFL setting, achieving an average accuracy gain of up to 15% with 27% lower forgetting while only incurring a minimal computation and communication cost.
</details>
<details>
<summary>摘要</summary>
受到隐私保护训练 Decentralized 数据的 Federated Learning (FL) 技术在最近得到了广泛关注，因为它可以实现隐私保护训练。然而，目前的文献主要关注单任务学习。然而，随着时间的推移，客户端上可能会出现新的任务，global model需要学习这些任务而不是忘记之前的任务。这种real-world scenario被称为 Continual Federated Learning (CFL)。CFL 的主要挑战是全球性衰减，即当全球模型在新任务上训练时，其对于旧任务的性能下降。有些最近的工作在 CFL 中提出了方法，以解决全球性衰减问题，但这些方法 either 假设了过去数据样本的可用性或者违反了 Federated Learning 的隐私原则。我们提出了一种新的方法，即 Federated Orthogonal Training (FOT)，以解决这些挑战。我们的算法从旧任务中提取每层的全球输入子空间，并将新任务的聚合更新修改为在每层上保持垂直于旧任务的全球主成分空间。这种方法降低了任务之间的干扰，这是主要的忘记原因。我们实验表明，FOT 可以在 CFL 设置中击败当前状态的 continual learning 方法，实现了最多15%的准确率提升，同时减少了27%的忘记水平，只占了最小的计算和通信成本。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Evaluation-of-FedAvg-and-Per-FedAvg-Algorithms-for-Dirichlet-Distributed-Heterogeneous-Data"><a href="#A-Comparative-Evaluation-of-FedAvg-and-Per-FedAvg-Algorithms-for-Dirichlet-Distributed-Heterogeneous-Data" class="headerlink" title="A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for Dirichlet Distributed Heterogeneous Data"></a>A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for Dirichlet Distributed Heterogeneous Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01275">http://arxiv.org/abs/2309.01275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Reguieg, Mohammed El Hanjri, Mohamed El Kamili, Abdellatif Kobbane</li>
<li>for:  investigate Federated Learning (FL) and compare two strategies within this paradigm: Federated Averaging (FedAvg) and Personalized Federated Averaging (Per-FedAvg)</li>
<li>methods:  use Non-Identically and Independently Distributed (Non-IID) data to evaluate the performance of both strategies</li>
<li>results:  Per-FedAvg shows superior robustness in conditions of high data heterogeneity, and our results provide insights into the development of more effective and efficient machine learning strategies in a decentralized setting.Here’s the full translation in Simplified Chinese:</li>
<li>for: 本研究 investigate Federated Learning (FL)，并比较这种 paradigm 中两种策略：Federated Averaging (FedAvg) 和 Personalized Federated Averaging (Per-FedAvg)。</li>
<li>methods: 使用 Non-Identically and Independently Distributed (Non-IID) 数据来评估这两种策略的性能。</li>
<li>results: Per-FedAvg 在高度不同数据中显示出更高的 Robustness，而我们的结果可以帮助开发更有效和高效的机器学习策略在分布式环境中。<details>
<summary>Abstract</summary>
In this paper, we investigate Federated Learning (FL), a paradigm of machine learning that allows for decentralized model training on devices without sharing raw data, there by preserving data privacy. In particular, we compare two strategies within this paradigm: Federated Averaging (FedAvg) and Personalized Federated Averaging (Per-FedAvg), focusing on their performance with Non-Identically and Independently Distributed (Non-IID) data. Our analysis shows that the level of data heterogeneity, modeled using a Dirichlet distribution, significantly affects the performance of both strategies, with Per-FedAvg showing superior robustness in conditions of high heterogeneity. Our results provide insights into the development of more effective and efficient machine learning strategies in a decentralized setting.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了联邦学习（Federated Learning，FL），这是一种机器学习的平台，允许在设备上进行分布式模型训练，而不需要共享原始数据，从而保持数据隐私。我们特别比较了两种策略在这个平台上：联邦平均（FedAvg）和个性化联邦平均（Per-FedAvg），并将注重在非同一样分布（Non-IID）数据上的性能。我们的分析表明，数据不同程度的不同，使用 Dirichlet 分布来模型，对两种策略的性能产生了显著影响，Per-FedAvg 在高度不同程度下表现出了更高的鲁棒性。我们的结果提供了开发更有效率的机器学习策略在分布式环境下的指导。
</details></li>
</ul>
<hr>
<h2 id="Modified-Step-Size-for-Enhanced-Stochastic-Gradient-Descent-Convergence-and-Experiments"><a href="#Modified-Step-Size-for-Enhanced-Stochastic-Gradient-Descent-Convergence-and-Experiments" class="headerlink" title="Modified Step Size for Enhanced Stochastic Gradient Descent: Convergence and Experiments"></a>Modified Step Size for Enhanced Stochastic Gradient Descent: Convergence and Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01248">http://arxiv.org/abs/2309.01248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shamaeem/lnsqrtstepsize">https://github.com/shamaeem/lnsqrtstepsize</a></li>
<li>paper_authors: M. Soheil Shamaee, S. Fathi Hafshejani</li>
<li>for: 提高 Stochastic Gradient Descent（SGD）算法的性能</li>
<li>methods: 使用修改后的衰减步长，其中包括对 Logarithmic 函数的 интегра</li>
<li>results: 在 Smooth 非 convex 函数上达到 $O(\frac{\ln T}{\sqrt{T})$ 的 converge 速率，并通过数据集的实验表明了该方法的效果。Here’s the breakdown of each point:1. for: The paper is written to enhance the performance of the SGD algorithm.2. methods: The paper proposes a modified decay step size based on $\frac{1}{\sqrt{t}$ with a logarithmic term, which leads to the selection of smaller values in the final iterations.3. results: The paper achieves a convergence rate of $O(\frac{\ln T}{\sqrt{T})$ for smooth non-convex functions without the Polyak-{\L}ojasiewicz condition, and the numerical experiments on image classification tasks demonstrate significant improvements in accuracy compared to the traditional $\frac{1}{\sqrt{t}$ step size.<details>
<summary>Abstract</summary>
This paper introduces a novel approach to enhance the performance of the stochastic gradient descent (SGD) algorithm by incorporating a modified decay step size based on $\frac{1}{\sqrt{t}$. The proposed step size integrates a logarithmic term, leading to the selection of smaller values in the final iterations. Our analysis establishes a convergence rate of $O(\frac{\ln T}{\sqrt{T})$ for smooth non-convex functions without the Polyak-{\L}ojasiewicz condition. To evaluate the effectiveness of our approach, we conducted numerical experiments on image classification tasks using the FashionMNIST, and CIFAR10 datasets, and the results demonstrate significant improvements in accuracy, with enhancements of $0.5\%$ and $1.4\%$ observed, respectively, compared to the traditional $\frac{1}{\sqrt{t}$ step size. The source code can be found at \\\url{https://github.com/Shamaeem/LNSQRTStepSize}.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的方法，用于提高泛率下降（SGD）算法的性能。该方法基于$\frac{1}{\sqrt{t}$的修改步长，其中包含了对数函数，从而选择小于最终迭代的值。我们的分析表明，对于非 convex 函数，该方法可以达到$O(\frac{\ln T}{\sqrt{T})$的 converges 速率，而不需要波佳-{\L}ojasiewicz 条件。为证明该方法的有效性，我们在图像分类任务上进行了数值实验，使用了 FashionMNIST 和 CIFAR10 数据集，结果显示，与传统 $\frac{1}{\sqrt{t}$ 步长相比，该方法可以提高准确率，具体提高了 $0.5\%$ 和 $1.4\%$。源代码可以在 \url{https://github.com/Shamaeem/LNSQRTStepSize} 找到。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Utility-Tradeoff-of-OLS-with-Random-Projections"><a href="#Privacy-Utility-Tradeoff-of-OLS-with-Random-Projections" class="headerlink" title="Privacy-Utility Tradeoff of OLS with Random Projections"></a>Privacy-Utility Tradeoff of OLS with Random Projections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01243">http://arxiv.org/abs/2309.01243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Lu, Malik Magdon-Ismail, Yu Wei, Vassilis Zikas</li>
<li>for: 本研究探讨了Linear Ordinary Least Squares（OLS）问题的分布式隐私（DP）性。</li>
<li>methods: 本研究使用了Sarlos（2006）提出的Approximate LS Algorithm（ALS），以及Dwork et al.（2014）的标准 Gaussian Mechanism。我们还提出了一种新的DP分析方法，以及一些可能是独立有用的工具。</li>
<li>results: 我们的研究结果表明，ALS算法可以保持隐私，而无需修改或噪声加工。我们还提供了第一个精确的DP分析方法，以及一些改进的DP分析工具。此外，我们还证明了，在大规模数据集中，计算DP级别可能是不可能的。因此，需要开发黑obox DP估计器，以便在实际应用中 empirically  estimating 数据中的隐私级别。<details>
<summary>Abstract</summary>
We study the differential privacy (DP) of a core ML problem, linear ordinary least squares (OLS), a.k.a. $\ell_2$-regression. Our key result is that the approximate LS algorithm (ALS) (Sarlos, 2006), a randomized solution to the OLS problem primarily used to improve performance on large datasets, also preserves privacy. ALS achieves a better privacy/utility tradeoff, without modifications or further noising, when compared to alternative private OLS algorithms which modify and/or noise OLS. We give the first {\em tight} DP-analysis for the ALS algorithm and the standard Gaussian mechanism (Dwork et al., 2014) applied to OLS. Our methodology directly improves the privacy analysis of (Blocki et al., 2012) and (Sheffet, 2019)) and introduces new tools which may be of independent interest: (1) the exact spectrum of $(\epsilon, \delta)$-DP parameters (``DP spectrum") for mechanisms whose output is a $d$-dimensional Gaussian, and (2) an improved DP spectrum for random projection (compared to (Blocki et al., 2012) and (Sheffet, 2019)).   All methods for private OLS (including ours) assume, often implicitly, restrictions on the input database, such as bounds on leverage and residuals. We prove that such restrictions are necessary. Hence, computing the privacy of mechanisms such as ALS must estimate these database parameters, which can be infeasible in big datasets. For more complex ML models, DP bounds may not even be tractable. There is a need for blackbox DP-estimators (Lu et al., 2022) which empirically estimate a data-dependent privacy. We demonstrate the effectiveness of such a DP-estimator by empirically recovering a DP-spectrum that matches our theory for OLS. This validates the DP-estimator in a nontrivial ML application, opening the door to its use in more complex nonlinear ML settings where theory is unavailable.
</details>
<details>
<summary>摘要</summary>
我们研究了线性最小二乘（OLS）问题中的分数隐私（DP）。我们的关键结论是，偏相对最小二乘（ALS）算法（Sarlos，2006），一种用于提高大型数据集的性能的随机解决方案，同时也保持隐私。相比于其他修改和噪声OLS算法，ALS实现了更好的隐私/用途质量比，无需进一步修改或噪声。我们提供了首个紧密的DP分析 дляALS算法和标准 Gaussian机制（Dwork等，2014）应用于OLS问题。我们的方法直接改进了（Blocki等，2012）和（Sheffet，2019）中的隐私分析，并 introduce了新的工具：（1）DP分布的准确谱（DP spectrum），其中输出是一个$d$-维 Gaussian 分布，以及（2）改进的DP分布 для随机投影。所有私有OLS（包括我们的）都假设了输入数据库中的约束，例如，约束在输入数据中的倾斜和差异。我们证明了这些约束是必需的。因此，计算私有OLS的隐私必须估计这些数据库参数，这可能是大型数据集中的不可能任务。为更复杂的机器学习模型，DP bound可能无法可读。这需要黑盒DP估计器（Lu等，2022），它可以在数据中使用随机方法来估计数据依赖的隐私。我们证明了这种DP估计器的有效性，通过 empirically recovering a DP spectrum that matches our theory for OLS。这将开启黑盒DP估计器的使用在更复杂的非线性机器学习设置中，where theory is unavailable。
</details></li>
</ul>
<hr>
<h2 id="lfads-torch-A-modular-and-extensible-implementation-of-latent-factor-analysis-via-dynamical-systems"><a href="#lfads-torch-A-modular-and-extensible-implementation-of-latent-factor-analysis-via-dynamical-systems" class="headerlink" title="lfads-torch: A modular and extensible implementation of latent factor analysis via dynamical systems"></a>lfads-torch: A modular and extensible implementation of latent factor analysis via dynamical systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01230">http://arxiv.org/abs/2309.01230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arsedler9/lfads-torch">https://github.com/arsedler9/lfads-torch</a></li>
<li>paper_authors: Andrew R. Sedler, Chethan Pandarinath</li>
<li>for: 这篇论文是为了减少高维度神经活动中的噪音，以便在科学和工程领域中使用。</li>
<li>methods: 这篇论文使用了一种名为“Latent Factor Analysis via Dynamical Systems”的Variational Sequential Autoencoder（RNN-based），以解决高维度神经活动中的噪音问题。</li>
<li>results: 这篇论文的结果显示，这种方法可以实现高度的表现，并且可以应用到许多 neuroscience 中的问题上。<details>
<summary>Abstract</summary>
Latent factor analysis via dynamical systems (LFADS) is an RNN-based variational sequential autoencoder that achieves state-of-the-art performance in denoising high-dimensional neural activity for downstream applications in science and engineering. Recently introduced variants and extensions continue to demonstrate the applicability of the architecture to a wide variety of problems in neuroscience. Since the development of the original implementation of LFADS, new technologies have emerged that use dynamic computation graphs, minimize boilerplate code, compose model configuration files, and simplify large-scale training. Building on these modern Python libraries, we introduce lfads-torch -- a new open-source implementation of LFADS that unifies existing variants and is designed to be easier to understand, configure, and extend. Documentation, source code, and issue tracking are available at https://github.com/arsedler9/lfads-torch .
</details>
<details>
<summary>摘要</summary>
Latent Factor Analysis via Dynamical Systems（LFADS）是一种基于RNN的变量序列自动编码器，可以在科学和工程领域中实现高级别噪声去除神经活动数据。最近的变体和扩展继续证明了该架构在神经科学中的广泛应用。自LFADS原始实现以来，新的技术出现了，包括动态计算图、最小化boilerplate代码、组合模型配置文件和大规模训练。基于这些现代Python库，我们介绍lfads-torch---一个新的开源实现，它将 существующие变体集成起来，并设计为更容易理解、配置和扩展。文档、源代码和问题跟踪可以在https://github.com/arsedler9/lfads-torch 上找到。
</details></li>
</ul>
<hr>
<h2 id="Implicit-regularization-of-deep-residual-networks-towards-neural-ODEs"><a href="#Implicit-regularization-of-deep-residual-networks-towards-neural-ODEs" class="headerlink" title="Implicit regularization of deep residual networks towards neural ODEs"></a>Implicit regularization of deep residual networks towards neural ODEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01213">http://arxiv.org/abs/2309.01213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Marion, Yu-Han Wu, Michael E. Sander, Gérard Biau<br>for: 这篇论文的目的是为了建立深度学习模型之间的数学基础，具体来说是将残留神经网络与神经� differential equations（ODEs）之间的连接固化。methods: 这篇论文使用了一种叫做偏微分流的方法来训练深度学习模型，并且证明了如果初始化了一个神经网络为一个残留神经网络的离散化，那么这个离散化会在训练过程中保持不变。results: 这篇论文的结果表明，如果神经网络满足一个Polyak-Lojasiewicz条件，那么 gradient flow 会收敛到一个全局最小值。此外，这个条件适用于一家 residual networks，其中每层的偏微分是一个二层感知器，并且它们在宽度方向上有一定的过度参数。numerical experiments 验证了这些结果。<details>
<summary>Abstract</summary>
Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to a global minimum. Numerical experiments illustrate our results.
</details>
<details>
<summary>摘要</summary>
深度学习模型中的剩余神经网络是当前最佳实践。它们的连续深度类型，神经 diferencial equations（ODEs）也广泛使用。尽管它们的成功，但是这两种模型之间的数学基础仍然缺乏固定的连接。在这篇文章中，我们向这个方向致力于建立深度神经网络向神经ODE的隐式规范，对非线性网络进行梯度流训练。我们证明，如果网络在训练开始时初始化为神经ODE的离散化，那么这种离散化会在训练过程中保持不变。我们的结果适用于有限的训练时间和训练时间趋于无穷大，只要网络满足一个Polyak-Lojasiewicz条件。这个条件适用于一家具有线性增强的二层感知机的残差神经网络，并且 garantía 梯度流 converges to a global minimum。实验证明了我们的结果。
</details></li>
</ul>
<hr>
<h2 id="Symbolically-integrating-tensor-networks-over-various-random-tensors-by-the-second-version-of-Python-RTNI"><a href="#Symbolically-integrating-tensor-networks-over-various-random-tensors-by-the-second-version-of-Python-RTNI" class="headerlink" title="Symbolically integrating tensor networks over various random tensors by the second version of Python RTNI"></a>Symbolically integrating tensor networks over various random tensors by the second version of Python RTNI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01167">http://arxiv.org/abs/2309.01167</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/motohisafukuda/pyrtni2">https://github.com/motohisafukuda/pyrtni2</a></li>
<li>paper_authors: Motohisa Fukuda</li>
<li>for: 这个论文是为了介绍PyRTNI2库的升级版本，该库可以 симвоlic integrate tensor networks over Haar-distributed unitary matrices。</li>
<li>methods: 这篇论文使用了element-wise moment calculus的方法，以及将tensor network diagrams和delta functions相关联的方法。</li>
<li>results: PyRTNI2可以处理Haar-distributed orthogonal matrices和实数和复数正态分布tensor，并可以导出tensor networks的格式为TensorNetwork，以便进行进一步的计算，包括低维度的情况，where Weingarten functions differ from high-dimensional cases。<details>
<summary>Abstract</summary>
We are upgrading the Python-version of RTNI, which symbolically integrates tensor networks over the Haar-distributed unitary matrices. Now, PyRTNI2 can treat the Haar-distributed orthogonal matrices and the real and complex normal Gaussian tensors as well. Moreover, it can export tensor networks in the format of TensorNetwork so that one can make further calculations with concrete tensors, even for low dimensions, where the Weingarten functions differ from the ones for high dimensions. The tutorial notebooks are found at GitHub: https://github.com/MotohisaFukuda/PyRTNI2. In this paper, we explain maths behind the program and show what kind of tensor network calculations can be made with it. For the former, we interpret the element-wise moment calculus of the above random matrices and tensors in terms of tensor network diagrams, and argue that the view is natural, relating delta functions in the calculus to edges in tensor network diagrams.
</details>
<details>
<summary>摘要</summary>
我们正在升级Python版本的RTNI，这个symbolically组合了tensor network的程式。现在PyRTNI2可以处理哈aar分布的对称矩阵和实部和复部的正 Gaussian 网络，并且可以将网络出口到TensorNetwork格式，以便进一步计算具体的网络，甚至低维度的网络，其中Weingarten函数与高维度不同。教程 Notebook可以在GitHub上找到：https://github.com/MotohisaFukuda/PyRTNI2。在这篇论文中，我们解释了软件的数学基础和展示了它可以进行哪些网络计算。对于前者，我们将元素级数律calculus of the above random matrices and tensors interpreting as tensor network diagrams, and argue that the view is natural, relating delta functions in the calculus to edges in tensor network diagrams.
</details></li>
</ul>
<hr>
<h2 id="Noise-robust-speech-emotion-recognition-with-signal-to-noise-ratio-adapting-speech-enhancement"><a href="#Noise-robust-speech-emotion-recognition-with-signal-to-noise-ratio-adapting-speech-enhancement" class="headerlink" title="Noise robust speech emotion recognition with signal-to-noise ratio adapting speech enhancement"></a>Noise robust speech emotion recognition with signal-to-noise ratio adapting speech enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01164">http://arxiv.org/abs/2309.01164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wen Chen, Julia Hirschberg, Yu Tsao</li>
<li>for: 提高Speech Emotion Recognition（SER）系统的防噪性能。</li>
<li>methods: 提出了一种听力噪声降低（SE）技术，并使用了Signal-to-Noise-Ratio（SNR）水平检测结构和波形重建策略来减少噪声降低对语音信号的负面影响。</li>
<li>results: 实验结果表明，NRSER可以有效地提高SER系统的防噪性能，包括防止系统对完全背景噪声的识别。此外，提出的SNR水平检测结构可以独立地用于数据选择等任务。<details>
<summary>Abstract</summary>
Speech emotion recognition (SER) often experiences reduced performance due to background noise. In addition, making a prediction on signals with only background noise could undermine user trust in the system. In this study, we propose a Noise Robust Speech Emotion Recognition system, NRSER. NRSER employs speech enhancement (SE) to effectively reduce the noise in input signals. Then, the signal-to-noise-ratio (SNR)-level detection structure and waveform reconstitution strategy are introduced to reduce the negative impact of SE on speech signals with no or little background noise. Our experimental results show that NRSER can effectively improve the noise robustness of the SER system, including preventing the system from making emotion recognition on signals consisting solely of background noise. Moreover, the proposed SNR-level detection structure can be used individually for tasks such as data selection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。<</SYS>>听话情感识别（SER）经常受到背景噪声的影响，这会导致系统的性能下降。此外，基于背景噪声的预测可能会使用户对系统失去信任。在这种情况下，我们提出了一种防止噪声的Speech Emotion Recognition系统（NRSER）。NRSER使用了Speech Enhancement（SE）技术来有效地减少输入信号中的噪声。然后，我们引入了信号噪声比（SNR）水平检测结构和波形重建策略，以降低SE对无或少背景噪声的语音信号的负面影响。我们的实验结果表明，NRSER可以有效地提高噪声鲁棒性，包括避免系统对背景噪声只作出情感识别。此外，我们提出的SNR水平检测结构可以独立地应用于数据选择等任务。
</details></li>
</ul>
<hr>
<h2 id="An-Accurate-Graph-Generative-Model-with-Tunable-Features"><a href="#An-Accurate-Graph-Generative-Model-with-Tunable-Features" class="headerlink" title="An Accurate Graph Generative Model with Tunable Features"></a>An Accurate Graph Generative Model with Tunable Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01158">http://arxiv.org/abs/2309.01158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takahiro Yokoyama, Yoshiki Sato, Sho Tsugawa, Kohei Watabe</li>
<li>for: 这 paper 是为了提高 GraphTune 模型中 graph 特征的调整精度而写的。</li>
<li>methods: 这 paper 使用了一种新的Feedback Error Mechanism，将错误反馈到 GraphTune 模型中，并在独立地进行 Alternate Training，以提高 graph 特征的调整精度。</li>
<li>results: 实验结果表明，使用新的Feedback Error Mechanism 可以准确地调整 GraphTune 模型中的 graph 特征，比 conventinal models 更高精度。<details>
<summary>Abstract</summary>
A graph is a very common and powerful data structure used for modeling communication and social networks. Models that generate graphs with arbitrary features are important basic technologies in repeated simulations of networks and prediction of topology changes. Although existing generative models for graphs are useful for providing graphs similar to real-world graphs, graph generation models with tunable features have been less explored in the field. Previously, we have proposed GraphTune, a generative model for graphs that continuously tune specific graph features of generated graphs while maintaining most of the features of a given graph dataset. However, the tuning accuracy of graph features in GraphTune has not been sufficient for practical applications. In this paper, we propose a method to improve the accuracy of GraphTune by adding a new mechanism to feed back errors of graph features of generated graphs and by training them alternately and independently. Experiments on a real-world graph dataset showed that the features in the generated graphs are accurately tuned compared with conventional models.
</details>
<details>
<summary>摘要</summary>
一个图是非常常见和有力的数据结构，用于模型交流和社交网络。生成图模型是重要的基础技术，可以重复 simulate 网络和预测网络结构变化。虽然现有的生成图模型很有用，但是可调特征的图生成模型在领域中尚未得到充分发掘。我们之前已经提出了 GraphTune，一种可生成图模型，可以在生成图时连续调整特定图特征，保持大多数图集特征。但是，GraphTune 中的调整精度并没有达到实际应用中的需求。在这篇论文中，我们提出了一种方法来提高 GraphTune 的调整精度，通过添加一种反馈错误图特征的机制，并在独立地训练它们。实验表明，对实际图集进行生成后，图中的特征都能够准确地调整，比较于传统模型更加精准。
</details></li>
</ul>
<hr>
<h2 id="Advances-in-machine-learning-based-sampling-motivated-by-lattice-quantum-chromodynamics"><a href="#Advances-in-machine-learning-based-sampling-motivated-by-lattice-quantum-chromodynamics" class="headerlink" title="Advances in machine-learning-based sampling motivated by lattice quantum chromodynamics"></a>Advances in machine-learning-based sampling motivated by lattice quantum chromodynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01156">http://arxiv.org/abs/2309.01156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Cranmer, Gurtej Kanwar, Sébastien Racanière, Danilo J. Rezende, Phiala E. Shanahan</li>
<li>for: 这篇论文旨在探讨机器学习（ML）模型在计算物理学中的应用，尤其是在凝聚态场论中。</li>
<li>methods: 论文使用了特定的机器学习算法来采样概率分布，并利用了超级计算机来实现大规模的计算。</li>
<li>results: 论文的结果表明，使用机器学习模型可以有效地采样凝聚态场论中的结构和交互，并且可以实现first-principles的物理计算。<details>
<summary>Abstract</summary>
Sampling from known probability distributions is a ubiquitous task in computational science, underlying calculations in domains from linguistics to biology and physics. Generative machine-learning (ML) models have emerged as a promising tool in this space, building on the success of this approach in applications such as image, text, and audio generation. Often, however, generative tasks in scientific domains have unique structures and features -- such as complex symmetries and the requirement of exactness guarantees -- that present both challenges and opportunities for ML. This Perspective outlines the advances in ML-based sampling motivated by lattice quantum field theory, in particular for the theory of quantum chromodynamics. Enabling calculations of the structure and interactions of matter from our most fundamental understanding of particle physics, lattice quantum chromodynamics is one of the main consumers of open-science supercomputing worldwide. The design of ML algorithms for this application faces profound challenges, including the necessity of scaling custom ML architectures to the largest supercomputers, but also promises immense benefits, and is spurring a wave of development in ML-based sampling more broadly. In lattice field theory, if this approach can realize its early promise it will be a transformative step towards first-principles physics calculations in particle, nuclear and condensed matter physics that are intractable with traditional approaches.
</details>
<details>
<summary>摘要</summary>
伪乱分布的抽样是计算科学中的一项普遍任务，从语言学到生物和物理等领域都有广泛的应用。生成机器学习（ML）模型在这个领域得到了成功，基于图像、文本和音频生成等应用的成功。然而，在科学领域的生成任务中有独特的结构和特点，例如复杂的对称和精确性保证的要求，这对ML技术提出了挑战和机遇。这篇观点文章描述了基于ML的抽样技术的进步，特别是基于粒子物理学的假想场论。通过实现对物质结构和互动的计算，假想场论成为了物理学界最大的开源超级计算的主要用户。设计为这种应用的ML算法面临着巨大挑战，包括扩展自定义ML架构到最大超级计算机上的必要性，但也承诺巨大的利益，并在ML基于抽样技术的开发中促进了广泛的进步。在粒子物理学中，如果这种方法能实现早期的承诺，那么将是对first-principles物理计算的一个转变步骤，包括粒子、核和 condensed matter 物理的计算，这些计算是使用传统方法不可能完成的。
</details></li>
</ul>
<hr>
<h2 id="AutoML-GPT-Large-Language-Model-for-AutoML"><a href="#AutoML-GPT-Large-Language-Model-for-AutoML" class="headerlink" title="AutoML-GPT: Large Language Model for AutoML"></a>AutoML-GPT: Large Language Model for AutoML</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01125">http://arxiv.org/abs/2309.01125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Da Tsai, Yu-Che Tsai, Bo-Wei Huang, Chun-Pai Yang, Shou-De Lin</li>
<li>For: The paper is written for users who want to perform machine learning tasks but do not have deep domain knowledge. The paper aims to provide a framework called AutoML-GPT that simplifies the machine learning pipeline and reduces the time and effort required for these tasks.* Methods: The paper uses a conversational interface to allow users to specify their requirements, constraints, and evaluation metrics. The system employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance.* Results: The paper demonstrates through experimental results on diverse datasets that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. The system’s ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.<details>
<summary>Abstract</summary>
With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.
</details>
<details>
<summary>摘要</summary>
With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.Here's the translation in Traditional Chinese:With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.
</details></li>
</ul>
<hr>
<h2 id="AI-driven-B-cell-Immunotherapy-Design"><a href="#AI-driven-B-cell-Immunotherapy-Design" class="headerlink" title="AI driven B-cell Immunotherapy Design"></a>AI driven B-cell Immunotherapy Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01122">http://arxiv.org/abs/2309.01122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruna Moreira da Silva, David B. Ascher, Nicholas Geard, Douglas E. V. Pires</li>
<li>for: 本文旨在探讨人工智能和机器学习方法在B细胞免疫疗法设计方面的进步，包括线性和 conformational 蛋白结构预测、蛋白质预测、抗体设计等方面。</li>
<li>methods: 本文使用的方法包括线性和 conformational 蛋白结构预测、蛋白质预测、抗体设计等，以支持免疫疗法设计。</li>
<li>results: 本文结合了多种数据源、评估指标和方法，对Machine learning-based 工具和框架在B细胞免疫疗法设计方面的进步进行了评估和检验，并描述了主要挑战和未来发展的方向。<details>
<summary>Abstract</summary>
Antibodies, a prominent class of approved biologics, play a crucial role in detecting foreign antigens. The effectiveness of antigen neutralisation and elimination hinges upon the strength, sensitivity, and specificity of the paratope-epitope interaction, which demands resource-intensive experimental techniques for characterisation. In recent years, artificial intelligence and machine learning methods have made significant strides, revolutionising the prediction of protein structures and their complexes. The past decade has also witnessed the evolution of computational approaches aiming to support immunotherapy design. This review focuses on the progress of machine learning-based tools and their frameworks in the domain of B-cell immunotherapy design, encompassing linear and conformational epitope prediction, paratope prediction, and antibody design. We mapped the most commonly used data sources, evaluation metrics, and method availability and thoroughly assessed their significance and limitations, discussing the main challenges ahead.
</details>
<details>
<summary>摘要</summary>
抗体，一种已批准的生物药物，在检测外源抗原方面发挥重要作用。抗体中和降解的效果取决于蛋白质-蛋白质复合物之间的强度、敏感性和特异性，这些特性需要资源充沛的实验技术进行Characterization。在最近几年，人工智能和机器学习方法在蛋白质结构预测和其复合物预测方面做出了重要进步，对免疫疗法设计提供了支持。本文将关注使用机器学习技术支持B细胞免疫疗法设计的进展，包括线性和 conformational 抗体蛋白质预测、蛋白质预测和抗体设计。我们将最常用的数据源、评价指标和方法可用性进行映射，并且详细评估了它们的重要性和局限性，讨论了未来的主要挑战。
</details></li>
</ul>
<hr>
<h2 id="Double-Clipping-Less-Biased-Variance-Reduction-in-Off-Policy-Evaluation"><a href="#Double-Clipping-Less-Biased-Variance-Reduction-in-Off-Policy-Evaluation" class="headerlink" title="Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation"></a>Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01120">http://arxiv.org/abs/2309.01120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Malte Lichtenberg, Alexander Buchholz, Giuseppe Di Benedetto, Matteo Ruffini, Ben London</li>
<li>for: 本研究旨在提出一种简单的扩展，以减少 clipping  estimator 的偏差，保持 variance 减少性能。</li>
<li>methods: 本研究使用的方法是 double clipping，它是一种基于 clipping 的 variance-reduction 技术，可以减少偏差，同时保持 variance 减少性能。</li>
<li>results: 研究表明，double clipping 可以减少 estimator 的偏差，同时保持 variance 减少性能，提高计算效率。<details>
<summary>Abstract</summary>
"Clipping" (a.k.a. importance weight truncation) is a widely used variance-reduction technique for counterfactual off-policy estimators. Like other variance-reduction techniques, clipping reduces variance at the cost of increased bias. However, unlike other techniques, the bias introduced by clipping is always a downward bias (assuming non-negative rewards), yielding a lower bound on the true expected reward. In this work we propose a simple extension, called $\textit{double clipping}$, which aims to compensate this downward bias and thus reduce the overall bias, while maintaining the variance reduction properties of the original estimator.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Carbon-Emission-Prediction-and-Clean-Industry-Transformation-Based-on-Machine-Learning-A-Case-Study-of-Sichuan-Province"><a href="#Carbon-Emission-Prediction-and-Clean-Industry-Transformation-Based-on-Machine-Learning-A-Case-Study-of-Sichuan-Province" class="headerlink" title="Carbon Emission Prediction and Clean Industry Transformation Based on Machine Learning: A Case Study of Sichuan Province"></a>Carbon Emission Prediction and Clean Industry Transformation Based on Machine Learning: A Case Study of Sichuan Province</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01115">http://arxiv.org/abs/2309.01115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanming Zhang, Xiaoxue Wang, Yonghang Chen</li>
<li>For: 本研究使用矩阵正常化处理2000-2019年四川省46个键盘产业的能源消耗数据，使用DBSCAN封顶分析 objective 分类行业。* Methods: 本研究使用DBSCAN封顶分析 objective 分类行业，并使用罚款回归模型来控制过采样、处理高维数据和选择特征。* Results: 研究发现第二个群around coal有最高排放，这主要归结于生产需求。 gasoline-focused和coke-focused 群也有显著的排放。根据这些结果，提出了使用清洁煤矿技术、交通管理、钢铁行业电力取代煤炭、行业标准化等减排策略。<details>
<summary>Abstract</summary>
This study preprocessed 2000-2019 energy consumption data for 46 key Sichuan industries using matrix normalization. DBSCAN clustering identified 16 feature classes to objectively group industries. Penalized regression models were then applied for their advantages in overfitting control, high-dimensional data processing, and feature selection - well-suited for the complex energy data. Results showed the second cluster around coal had highest emissions due to production needs. Emissions from gasoline-focused and coke-focused clusters were also significant. Based on this, emission reduction suggestions included clean coal technologies, transportation management, coal-electricity replacement in steel, and industry standardization. The research introduced unsupervised learning to objectively select factors and aimed to explore new emission reduction avenues. In summary, the study identified industry groupings, assessed emissions drivers, and proposed scientific reduction strategies to better inform decision-making using algorithms like DBSCAN and penalized regression models.
</details>
<details>
<summary>摘要</summary>
这个研究对2000-2019年四川46个重点产业的能源消耗数据进行了归一化处理。使用DBSCAN划分 clustering 方法对行业进行了 объектив分类。然后，对高维数据进行了惩罚回归模型的应用，以便控制过拟合、处理高维数据和选择特征。研究结果显示，第二个群组织煤矿产业占据了最高排出水平，这是因为生产需要。汽油和焦炭专注的群组也有显著的排出水平。根据这些结果，提出了清洁煤技术、交通管理、钢铁产业煤电replace和产业标准化等减排策略。这项研究通过不监督学习方法选择因素，探索了新的减排途径，以更好地 Inform 决策。In summary, the study used unsupervised learning techniques like DBSCAN clustering and penalized regression models to identify industry groupings, assess emissions drivers, and propose scientific reduction strategies for better decision-making. The research aimed to explore new emission reduction avenues by introducing unsupervised learning to objectively select factors.
</details></li>
</ul>
<hr>
<h2 id="Acoustic-to-articulatory-inversion-for-dysarthric-speech-Are-pre-trained-self-supervised-representations-favorable"><a href="#Acoustic-to-articulatory-inversion-for-dysarthric-speech-Are-pre-trained-self-supervised-representations-favorable" class="headerlink" title="Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?"></a>Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01108">http://arxiv.org/abs/2309.01108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarthak Kumar Maharana, Krishna Kamal Adidam, Shoumik Nandi, Ajitesh Srivastava</li>
<li>for: 这个研究旨在用自动学习模型（SSL）来实现声学到词语运动的映射（AAI），并研究不同的训练方案对于慢性肢骨疾病（dysarthria）的影响。</li>
<li>methods: 研究使用了不同的SSL模型，包括wav2vec、APC和DeCoAR，并使用了x-vector来训练一个BLSTM网络。不同的训练方案包括subject-specific、pooled和精度调整。</li>
<li>results: 研究发现，在seen和unseen情况下，使用SSL模型对于dysarthria患者的词语运动预测具有显著改善，相比MFCC。DeCoAR在精度调整方案下，对于健康人和患者都显示了${\sim}1.81%}$和${\sim}4.56%}$的Relative Improvement of Pearson Correlation Coefficient（CC）。<details>
<summary>Abstract</summary>
$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the acoustic space to the articulatory space. Signal-processing features like the MFCCs, have been widely used for the AAI task. For subjects with dysarthric speech, AAI is challenging because of an imprecise and indistinct pronunciation. In this work, we perform AAI for dysarthric speech using representations from pre-trained self-supervised learning (SSL) models. We demonstrate the impact of different pre-trained features on this challenging AAI task, at low-resource conditions. In addition, we also condition x-vectors to the extracted SSL features to train a BLSTM network. In the seen case, we experiment with three AAI training schemes (subject-specific, pooled, and fine-tuned). The results, consistent across training schemes, reveal that DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the Pearson Correlation Coefficient (CC) by ${\sim}$1.81\% and ${\sim}$4.56\% for healthy controls and patients, respectively, over MFCCs. In the unseen case, we observe similar average trends for different SSL features. Overall, SSL networks like wav2vec, APC, and DeCoAR, which are trained with feature reconstruction or future timestep prediction tasks, perform well in predicting dysarthric articulatory trajectories.
</details>
<details>
<summary>摘要</summary>
$ $音律-语音映射（AAI）是将音律空间映射到语音空间。信号处理特征如MFCCs，已广泛用于AAI任务。对于具有异常语音的主题而言，AAI是一项挑战，因为它们的发音不准确和模糊。在这项工作中，我们使用预训练的自然语言学习（SSL）模型来实现AAI。我们表明了不同预训练特征对于这项具有挑战性的AAI任务的影响。此外，我们还将x-vector conditioning到提取的SSL特征来训练BLSTM网络。在可见情况下，我们尝试了三种AAI训练方案（主体特定、混合和细化）。结果显示，在细化方案下，DeCoAR achieved relative improvement of Pearson Correlation Coefficient (CC) by approximately 1.81% and 4.56% for healthy controls and patients, respectively, over MFCCs.在未见情况下，我们观察到了不同的SSL特征对于不同的语音特征的平均趋势。总的来说，SSL网络如wav2vec、APC和DeCoAR，通过特征重建或未来时间步预测任务进行训练，在预测异常语音的语音映射方面表现良好。
</details></li>
</ul>
<hr>
<h2 id="Solving-Non-Rectangular-Reward-Robust-MDPs-via-Frequency-Regularization"><a href="#Solving-Non-Rectangular-Reward-Robust-MDPs-via-Frequency-Regularization" class="headerlink" title="Solving Non-Rectangular Reward-Robust MDPs via Frequency Regularization"></a>Solving Non-Rectangular Reward-Robust MDPs via Frequency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01107">http://arxiv.org/abs/2309.01107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uri Gadot, Esther Derman, Navdeep Kumar, Maxence Mohamed Elfatihi, Kfir Levy, Shie Mannor</li>
<li>for: 本文研究了强化环境中的回报 Markov 决策过程（RMDP），具体来说是研究在固定转移核函数下，回报函数在一定范围内变化的情况下的 RMDP。</li>
<li>methods: 本文提出了一种基于策略访问频率规范化的方法，并证明其 converges。</li>
<li>results: 数值实验表明，该方法可以学习出一个更加稳健和 menos conservative 的策略，与传统的 rectangular uncertainty 相比。<details>
<summary>Abstract</summary>
In robust Markov decision processes (RMDPs), it is assumed that the reward and the transition dynamics lie in a given uncertainty set. By targeting maximal return under the most adversarial model from that set, RMDPs address performance sensitivity to misspecified environments. Yet, to preserve computational tractability, the uncertainty set is traditionally independently structured for each state. This so-called rectangularity condition is solely motivated by computational concerns. As a result, it lacks a practical incentive and may lead to overly conservative behavior. In this work, we study coupled reward RMDPs where the transition kernel is fixed, but the reward function lies within an $\alpha$-radius from a nominal one. We draw a direct connection between this type of non-rectangular reward-RMDPs and applying policy visitation frequency regularization. We introduce a policy-gradient method, and prove its convergence. Numerical experiments illustrate the learned policy's robustness and its less conservative behavior when compared to rectangular uncertainty.
</details>
<details>
<summary>摘要</summary>
在robust markov decision processes（RMDPs）中，假设奖励和转移动力在给定的不确定集中。通过targeting最大返回在最敌对模型下，RMDPs  Address performance sensitivity to misspecified environments.然而，为保持计算 tractability，不确定集通常是独立结构的每个状态。这种called rectangularity condition 仅由计算问题所衍生，而且缺乏实践驱动力，可能会导致过度保守的行为。在这项工作中，我们研究了奖励RMDPs，其中转移函数固定，但奖励函数在一个α-距离 nominated one 内。我们 drew a direct connection between这种非正方形奖励-RMDPs 和应用策略访问频率规范化。我们介绍了一种策略梯度法，并证明其 convergence。numerical experiments 表明学习策略的 robustness 和与矩形不确定相比较保守的行为。
</details></li>
</ul>
<hr>
<h2 id="Tropical-Geometric-Tools-for-Machine-Learning-the-TML-package"><a href="#Tropical-Geometric-Tools-for-Machine-Learning-the-TML-package" class="headerlink" title="Tropical Geometric Tools for Machine Learning: the TML package"></a>Tropical Geometric Tools for Machine Learning: the TML package</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01082">http://arxiv.org/abs/2309.01082</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/barnhilldave/tml">https://github.com/barnhilldave/tml</a></li>
<li>paper_authors: David Barnhill, Ruriko Yoshida, Georges Aliatimis, Keiji Miura</li>
<li>for: 该论文主要用于描述一个基于 тропикаль几何的R包（TML包），该包包含了基本的 tropos 计算、视觉化 tropos 几何体以及基于 max-plus 代数的超vised 和无关 learn 模型。</li>
<li>methods: 该论文使用 Hit and Run Markov chain Monte Carlo 采样器和 тропи metric 进行统计推断。此外，论文还介绍了一些基于 tropos 的超vised 和无关 learn 方法，包括 tropos 主成分分析、 tropos 逻辑回归和 tropos 核密度估计。</li>
<li>results: 论文的结果主要表明，使用 tropically 的 HAR 采样器可以有效地进行统计推断，并且可以应用于多种超vised 和无关 learn 问题。此外，论文还提出了一些基于 tropos 的新的方法和应用，例如 tropos 主成分分析和 tropos 核密度估计。<details>
<summary>Abstract</summary>
In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
</details>
<details>
<summary>摘要</summary>
在过去一个十年中， тропическая геометрия的发展已经为统计学学习带来了许多直接适用的应用。TML包是R包中的第一个包含涵盖тропические几何基本计算、视觉化 тропически几何集以及使用极大加法代数下的极大值推论的完整工具集。主要地，TML包使用 тропи metric来进行统计推论，使用射击和逃跑Markov链式 Monte Carlo抽样法。此外，TML包还包括了一些基本计算和各种应用，如тропические主成分分析、тропические逻辑回归和 тропические核密度估计。
</details></li>
</ul>
<hr>
<h2 id="Federated-Few-shot-Learning-for-Cough-Classification-with-Edge-Devices"><a href="#Federated-Few-shot-Learning-for-Cough-Classification-with-Edge-Devices" class="headerlink" title="Federated Few-shot Learning for Cough Classification with Edge Devices"></a>Federated Few-shot Learning for Cough Classification with Edge Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01076">http://arxiv.org/abs/2309.01076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngandh/F2LCough">https://github.com/ngandh/F2LCough</a></li>
<li>paper_authors: Ngan Dao Hoang, Dat Tran-Anh, Manh Luong, Cong Tran, Cuong Pham</li>
<li>for: 这份研究的目的是为了开发一个能够有效地分类喀丙 зву频的框架，并且在没有庞大量标注数据的情况下进行分类，同时也考虑到隐私问题。</li>
<li>methods: 这份研究使用了少数据学和联合学来设计一个称为F2LCough的新框架，以解决这个新的问题。</li>
<li>results: 我们的结果显示，F2LCough在COVID-19 Thermal Face &amp; Cough数据集上取得了86%的F1-Score，较其他方法为高。这显示了几据学和联合学可以在数据缺乏情况下建立一个分类模型，并且维护了隐私性。<details>
<summary>Abstract</summary>
Automatically classifying cough sounds is one of the most critical tasks for the diagnosis and treatment of respiratory diseases. However, collecting a huge amount of labeled cough dataset is challenging mainly due to high laborious expenses, data scarcity, and privacy concerns. In this work, our aim is to develop a framework that can effectively perform cough classification even in situations when enormous cough data is not available, while also addressing privacy concerns. Specifically, we formulate a new problem to tackle these challenges and adopt few-shot learning and federated learning to design a novel framework, termed F2LCough, for solving the newly formulated problem. We illustrate the superiority of our method compared with other approaches on COVID-19 Thermal Face & Cough dataset, in which F2LCough achieves an average F1-Score of 86%. Our results show the feasibility of few-shot learning combined with federated learning to build a classification model of cough sounds. This new methodology is able to classify cough sounds in data-scarce situations and maintain privacy properties. The outcomes of this work can be a fundamental framework for building support systems for the detection and diagnosis of cough-related diseases.
</details>
<details>
<summary>摘要</summary>
自动分类咳声是肺病诊断和治疗中最关键的任务之一，但收集庞大量标注咳数据却具有高度劳动成本、数据缺乏和隐私问题。在这种情况下，我们的目标是开发一个能够有效地进行咳类型分类的框架，同时解决隐私问题。我们将问题重新定义为新的问题，并采用少量学习和联合学习来设计一个名为F2LCough的新框架。我们在COVID-19 thermal face & cough数据集上进行了比较，发现F2LCough在average F1-Score方面达到86%。这些结果表明了少量学习与联合学习的可行性，可以在数据缺乏情况下分类咳声并保持隐私性。这种新的方法可以为诊断咳病提供支持。
</details></li>
</ul>
<hr>
<h2 id="Towards-Efficient-Modeling-and-Inference-in-Multi-Dimensional-Gaussian-Process-State-Space-Models"><a href="#Towards-Efficient-Modeling-and-Inference-in-Multi-Dimensional-Gaussian-Process-State-Space-Models" class="headerlink" title="Towards Efficient Modeling and Inference in Multi-Dimensional Gaussian Process State-Space Models"></a>Towards Efficient Modeling and Inference in Multi-Dimensional Gaussian Process State-Space Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01074">http://arxiv.org/abs/2309.01074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhidilin/gpssmproj">https://github.com/zhidilin/gpssmproj</a></li>
<li>paper_authors: Zhidi Lin, Juan Maroñas, Ying Li, Feng Yin, Sergios Theodoridis</li>
<li>for: 用于模型复杂非线性动力系统</li>
<li>methods: 使用高效变换 Gaussian 过程（ETGP）和相应的变量推断算法</li>
<li>results: 实验结果表明，提议方法可以减少参数数量和计算复杂性，同时可以与现有方法相比做出类似的推断性能。<details>
<summary>Abstract</summary>
The Gaussian process state-space model (GPSSM) has attracted extensive attention for modeling complex nonlinear dynamical systems. However, the existing GPSSM employs separate Gaussian processes (GPs) for each latent state dimension, leading to escalating computational complexity and parameter proliferation, thus posing challenges for modeling dynamical systems with high-dimensional latent states. To surmount this obstacle, we propose to integrate the efficient transformed Gaussian process (ETGP) into the GPSSM, which involves pushing a shared GP through multiple normalizing flows to efficiently model the transition function in high-dimensional latent state space. Additionally, we develop a corresponding variational inference algorithm that surpasses existing methods in terms of parameter count and computational complexity. Experimental results on diverse synthetic and real-world datasets corroborate the efficiency of the proposed method, while also demonstrating its ability to achieve similar inference performance compared to existing methods. Code is available at \url{https://github.com/zhidilin/gpssmProj}.
</details>
<details>
<summary>摘要</summary>
Gaussian  процесс状态空间模型 (GPSSM) 已经吸引了广泛的关注，用于模型复杂非线性动力系统。然而，现有的 GPSSM 使用每个隐藏状态维度之间的分离 Gaussian 过程 (GP)，导致计算复杂性和参数增加，从而对高维隐藏状态系统的模型 pose 了挑战。为了缓解这个困难，我们提议将高效转换 Gaussian 过程 (ETGP) 集成到 GPSSM 中，该方法涉及将共享 GP Push 多个 normalizing flows，以高效地模型高维隐藏状态空间中的过渡函数。此外，我们还开发了相应的变量推理算法，它在参数计数和计算复杂性方面超过了现有方法。实验结果表明，提议的方法在多种 sintetic 和实际世界数据上具有高效性，同时也能够达到与现有方法相似的推理性能。代码可以在 \url{https://github.com/zhidilin/gpssmProj} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MQENet-A-Mesh-Quality-Evaluation-Neural-Network-Based-on-Dynamic-Graph-Attention"><a href="#MQENet-A-Mesh-Quality-Evaluation-Neural-Network-Based-on-Dynamic-Graph-Attention" class="headerlink" title="MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph Attention"></a>MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01067">http://arxiv.org/abs/2309.01067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoxuan Zhang, Haisheng Li, Nan Li, Xiaochuan Wang</li>
<li>for: 这个论文的目的是提出一种基于动态图注意力的结构网格质量评估神经网络（MQENet），以便评估计算流体力学应用中的网格质量。</li>
<li>methods: 该论文使用了两种新的结构网格处理算法，以提高结构网格数据的转换效率。它还将网格评估任务定义为一种图分类任务，以 классифици�ayerStructured mesh quality evaluation task.</li>
<li>results: 实验结果表明，MQENet可以有效地评估结构网格的质量，并且在NACA-Market benchmark dataset上达到了高度的评估精度。<details>
<summary>Abstract</summary>
With the development of computational fluid dynamics, the requirements for the fluid simulation accuracy in industrial applications have also increased. The quality of the generated mesh directly affects the simulation accuracy. However, previous mesh quality metrics and models cannot evaluate meshes comprehensively and objectively. To this end, we propose MQENet, a structured mesh quality evaluation neural network based on dynamic graph attention. MQENet treats the mesh evaluation task as a graph classification task for classifying the quality of the input structured mesh. To make graphs generated from structured meshes more informative, MQENet introduces two novel structured mesh preprocessing algorithms. These two algorithms can also improve the conversion efficiency of structured mesh data. Experimental results on the benchmark structured mesh dataset NACA-Market show the effectiveness of MQENet in the mesh quality evaluation task.
</details>
<details>
<summary>摘要</summary>
随着计算流体动力学的发展，工业应用中流体模拟精度的要求也在不断提高。mesh质量直接影响模拟精度。然而，过去的网格质量指标和模型无法全面、 объектив地评估网格质量。为此，我们提出MQENet，一种基于动态图注意力的结构化网格质量评估神经网络。MQENet将网格评估任务视为一种图分类任务，用于评估输入结构网格的质量。为了使结构网格生成的图更加有用，MQENet引入了两种新的结构网格预处理算法。这两种算法还可以提高结构网格数据的转换效率。实验结果表明，MQENet在标准网格数据集NACA-Market上得到了较高的评估精度。
</details></li>
</ul>
<hr>
<h2 id="Distribution-learning-via-neural-differential-equations-a-nonparametric-statistical-perspective"><a href="#Distribution-learning-via-neural-differential-equations-a-nonparametric-statistical-perspective" class="headerlink" title="Distribution learning via neural differential equations: a nonparametric statistical perspective"></a>Distribution learning via neural differential equations: a nonparametric statistical perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01043">http://arxiv.org/abs/2309.01043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youssef Marzouk, Zhi Ren, Sven Wang, Jakob Zech</li>
<li>for: 这篇论文的目的是研究几何 diffeomorphism 模型在机器学习中的统计性质。</li>
<li>methods: 这篇论文使用了 likelihood 最大化 方法来训练几何 diffeomorphism 模型，并提出了一个通用的非Parametric 统计收敛分析方法。</li>
<li>results: 这篇论文提出了一个普适的统计收敛分析方法，并在 $C^k$ 平滑目标分布和神经网络类型中实现了nearly minimax-optimal 的收敛率。<details>
<summary>Abstract</summary>
Ordinary differential equations (ODEs), via their induced flow maps, provide a powerful framework to parameterize invertible transformations for the purpose of representing complex probability distributions. While such models have achieved enormous success in machine learning, particularly for generative modeling and density estimation, little is known about their statistical properties. This work establishes the first general nonparametric statistical convergence analysis for distribution learning via ODE models trained through likelihood maximization. We first prove a convergence theorem applicable to arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple boundary constraints. This general result captures the trade-off between approximation error (`bias') and the complexity of the ODE model (`variance'). We show that the latter can be quantified via the $C^1$-metric entropy of the class $\mathcal F$. We then apply this general framework to the setting of $C^k$-smooth target densities, and establish nearly minimax-optimal convergence rates for two relevant velocity field classes $\mathcal F$: $C^k$ functions and neural networks. The latter is the practically important case of neural ODEs.   Our proof techniques require a careful synthesis of (i) analytical stability results for ODEs, (ii) classical theory for sieved M-estimators, and (iii) recent results on approximation rates and metric entropies of neural network classes. The results also provide theoretical insight on how the choice of velocity field class, and the dependence of this choice on sample size $n$ (e.g., the scaling of width, depth, and sparsity of neural network classes), impacts statistical performance.
</details>
<details>
<summary>摘要</summary>
ordinary differential equations (ODEs) 通过它们引入的流动图，提供了一个强大的框架来Parameterize invertible transformations，以便表示复杂的概率分布。而这些模型在机器学习中已经取得了巨大的成功，特别是在生成模型和概率预测方面。然而，对这些模型的统计性质所知之少。这个工作首次提供了对ODE模型通过最大化likelihood进行学习的统计收敛分析。我们首先证明了适用于任何速度场类$\mathcal{F}$满足某些简单的边界约束的收敛定理。这个总体结果捕捉了在approximation error('bias')和ODE模型('variance')之间的负责任。我们表明了后者可以通过$\mathcal{F}$的$C^1$度量 entropy来衡量。然后，我们将这个总体框架应用于$C^k$平滑目标分布的设置，并确定了相对迫近最优的收敛率。其中，$C^k$函数和神经网络是两个有实际意义的速度场类。我们的证明技术需要结合(i) ODEs的分析稳定性结果，(ii) Sieved M-estimators的经典理论，以及(iii)近期关于应用率和度量Entropy的神经网络类的结果。结果还提供了对速度场类选择和样本大小 $n$（例如，宽度、深度和稀疏性的神经网络类的依赖关系）的统计性能的理论启示。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.LG_2023_09_03/" data-id="cloh3sqzn00nnh688d1qy58g5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/eess.IV_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T09:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/eess.IV_2023_09_03/">eess.IV - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Breast-MRI-radiomics-and-machine-learning-radiomics-based-predictions-of-response-to-neoadjuvant-chemotherapy-–-how-are-they-affected-by-variations-in-tumour-delineation"><a href="#Breast-MRI-radiomics-and-machine-learning-radiomics-based-predictions-of-response-to-neoadjuvant-chemotherapy-–-how-are-they-affected-by-variations-in-tumour-delineation" class="headerlink" title="Breast MRI radiomics and machine learning radiomics-based predictions of response to neoadjuvant chemotherapy – how are they affected by variations in tumour delineation?"></a>Breast MRI radiomics and machine learning radiomics-based predictions of response to neoadjuvant chemotherapy – how are they affected by variations in tumour delineation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01210">http://arxiv.org/abs/2309.01210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepideh Hatamikia, Geevarghese George, Florian Schwarzhans, Amirreza Mahbod, Ramona Woitek<br>for: 这个研究的目的是为了evaluating the impact of variations in manual delineations of volumes of interest (VOIs) on the performance of radiomics predictors in breast cancer subtypes.methods: 这个研究使用了contrast-enhanced magnetic resonance imaging (MRI) acquired prior to treatment (baseline MRI scans)，并使用了不同的mathematical operations such as erosion, smoothing, dilation, randomization, and ellipse fitting to simulate variations of segmentation masks.results: 研究发现，使用不同的VOI delineation methods can significantly affect the number of robust features and prediction performance in radiomics analysis. Specifically, smoothing and erosion yielded the highest number of robust features and the best prediction performance, while ellipse fitting and dilation led to the lowest robustness and prediction performance for both breast cancer subtypes. Additionally, the study found that at most 28% of the selected features were similar to manual VOIs when different VOI delineation data were used.<details>
<summary>Abstract</summary>
Manual delineation of volumes of interest (VOIs) by experts is considered the gold-standard method in radiomics analysis. However, it suffers from inter- and intra-operator variability. A quantitative assessment of the impact of variations in these delineations on the performance of the radiomics predictors is required to develop robust radiomics based prediction models. In this study, we developed radiomics models for the prediction of pathological complete response to neoadjuvant chemotherapy in patients with two different breast cancer subtypes based on contrast-enhanced magnetic resonance imaging acquired prior to treatment (baseline MRI scans). Different mathematical operations such as erosion, smoothing, dilation, randomization, and ellipse fitting were applied to the original VOIs delineated by experts to simulate variations of segmentation masks. The effects of such VOI modifications on various steps of the radiomics workflow, including feature extraction, feature selection, and prediction performance, were evaluated. Using manual tumor VOIs and radiomics features extracted from baseline MRI scans, an AUC of up to 0.96 and 0.89 was achieved for human epidermal growth receptor 2 positive and triple-negative breast cancer, respectively. For smoothing and erosion, VOIs yielded the highest number of robust features and the best prediction performance, while ellipse fitting and dilation lead to the lowest robustness and prediction performance for both breast cancer subtypes. At most 28% of the selected features were similar to manual VOIs when different VOI delineation data were used. Differences in VOI delineation affects different steps of radiomics analysis, and their quantification is therefore important for development of standardized radiomics research.
</details>
<details>
<summary>摘要</summary>
临床验证是验证分析的标准方法，但它受到Operator variability的影响。为了开发可靠的验证模型，我们需要评估随着分割masks的变化而导致的预测器性能的影响。我们在基线MRI扫描前进行了针对不同乳腺癌分型的预后化学治疗的预测，并使用不同的数学操作来模拟分割masks的变化。我们评估了这些变化对验证过程中的特征提取、特征选择和预测性能的影响。使用手动肿瘤分割和基线MRI扫描中提取的验证特征，我们可以达到0.96和0.89的AUC，分别为人类肿瘤抑制剂2阳性和三重阴性乳腺癌。对于平滑和减小操作，分割masks具有最高的Robust特征数和最好的预测性能，而 для�elia和扩大操作，分割masks具有最低的Robust特征数和预测性能。最多28%的选择特征与手动分割数据相同。不同的分割masks导致不同的预测过程中的不同步骤受到影响，因此其量化对于开发标准化验证研究非常重要。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/eess.IV_2023_09_03/" data-id="cloh3sr63013xh6886m1034fz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.SD_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T15:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.SD_2023_09_02/">cs.SD - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Timbre-reserved-Adversarial-Attack-in-Speaker-Identification"><a href="#Timbre-reserved-Adversarial-Attack-in-Speaker-Identification" class="headerlink" title="Timbre-reserved Adversarial Attack in Speaker Identification"></a>Timbre-reserved Adversarial Attack in Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00929">http://arxiv.org/abs/2309.00929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie</li>
<li>for: 本研究旨在使SID系统遭受攻击时，不仅利用攻击者模型的漏洞，而且保留目标话者的时变特征。</li>
<li>methods: 本研究使用了voice conversion（VC）模型的不同训练阶段来生成具有攻击者识别label的对抗攻击音频。具体来说，在VC模型的训练过程中，透过将攻击者识别label加入模型训练，以便控制VC模型生成的音频具有目标话者的时变特征。</li>
<li>results: 本研究发现，透过将攻击者识别label加入VC模型训练，可以生成timbre-reserved的对抗攻击音频，具有目标话者的时变特征。这些对抗攻击音频可以让SID系统错误识别攻击者，并且保留目标话者的时变特征。<details>
<summary>Abstract</summary>
As a type of biometric identification, a speaker identification (SID) system is confronted with various kinds of attacks. The spoofing attacks typically imitate the timbre of the target speakers, while the adversarial attacks confuse the SID system by adding a well-designed adversarial perturbation to an arbitrary speech. Although the spoofing attack copies a similar timbre as the victim, it does not exploit the vulnerability of the SID model and may not make the SID system give the attacker's desired decision. As for the adversarial attack, despite the SID system can be led to a designated decision, it cannot meet the specified text or speaker timbre requirements for the specific attack scenarios. In this study, to make the attack in SID not only leverage the vulnerability of the SID model but also reserve the timbre of the target speaker, we propose a timbre-reserved adversarial attack in the speaker identification. We generate the timbre-reserved adversarial audios by adding an adversarial constraint during the different training stages of the voice conversion (VC) model. Specifically, the adversarial constraint is using the target speaker label to optimize the adversarial perturbation added to the VC model representations and is implemented by a speaker classifier joining in the VC model training. The adversarial constraint can help to control the VC model to generate the speaker-wised audio. Eventually, the inference of the VC model is the ideal adversarial fake audio, which is timbre-reserved and can fool the SID system.
</details>
<details>
<summary>摘要</summary>
为了使骗谋攻击（SID）系统不仅利用骗谋模型的漏洞，还保留目标说话人的时征特征，我们在这种研究中提出了一种具有时征保留的敌意攻击。我们在不同的训练阶段中添加了一个敌意约束，以控制VC模型生成说话人级别的声音。具体来说，我们使用目标说话人标签来优化骗谋模型表示中的敌意干扰，通过一个说话人分类器参与VC模型训练。这种敌意约束可以帮助控制VC模型生成说话人级别的声音，最终得到骗谋模型的恶意假声音，这个声音保留了目标说话人的时征特征。
</details></li>
</ul>
<hr>
<h2 id="DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin"><a href="#DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin" class="headerlink" title="DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin"></a>DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00883">http://arxiv.org/abs/2309.00883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Li, Chenxu Hu, Jian Cong, Xinfa Zhu, Jingbei Li, Qiao Tian, Yuping Wang, Lei Xie</li>
<li>for: 这篇研究旨在提高cross-lingual TTS的自然度和情感表达能力。</li>
<li>methods: 提出了一个基于传播过程的Diffusion model based Cross-Lingual Emotion Transfer方法（DiCLET-TTS），通过将情感从源语言 speaker 转移到内部和跨语言目标 speaker 上，以提高语言转移后的自然度和情感表达能力。</li>
<li>results: 试验结果显示DiCLET-TTS 比较优秀于多种竞争模型，并且OP-EDM 能够学习 speaker-irrelevant yet emotion-discriminative embedding。<details>
<summary>Abstract</summary>
While the performance of cross-lingual TTS based on monolingual corpora has been significantly improved recently, generating cross-lingual speech still suffers from the foreign accent problem, leading to limited naturalness. Besides, current cross-lingual methods ignore modeling emotion, which is indispensable paralinguistic information in speech delivery. In this paper, we propose DiCLET-TTS, a Diffusion model based Cross-Lingual Emotion Transfer method that can transfer emotion from a source speaker to the intra- and cross-lingual target speakers. Specifically, to relieve the foreign accent problem while improving the emotion expressiveness, the terminal distribution of the forward diffusion process is parameterized into a speaker-irrelevant but emotion-related linguistic prior by a prior text encoder with the emotion embedding as a condition. To address the weaker emotional expressiveness problem caused by speaker disentanglement in emotion embedding, a novel orthogonal projection based emotion disentangling module (OP-EDM) is proposed to learn the speaker-irrelevant but emotion-discriminative embedding. Moreover, a condition-enhanced DPM decoder is introduced to strengthen the modeling ability of the speaker and the emotion in the reverse diffusion process to further improve emotion expressiveness in speech delivery. Cross-lingual emotion transfer experiments show the superiority of DiCLET-TTS over various competitive models and the good design of OP-EDM in learning speaker-irrelevant but emotion-discriminative embedding.
</details>
<details>
<summary>摘要</summary>
Traditional cross-lingual TTS methods based on monolingual corpora have made significant progress in recent years, but they still suffer from the problem of foreign accents, which limits the naturalness of the speech. Moreover, current methods ignore the modeling of emotion, which is essential paralinguistic information in speech delivery. In this paper, we propose DiCLET-TTS, a diffusion model-based cross-lingual emotion transfer method that can transfer emotion from a source speaker to the intra- and cross-lingual target speakers. To address the foreign accent problem and improve emotion expressiveness, we use a prior text encoder with an emotion embedding as a condition to parameterize the terminal distribution of the forward diffusion process. To further improve emotion expressiveness, we propose a novel orthogonal projection-based emotion disentangling module (OP-EDM) to learn speaker-irrelevant but emotion-discriminative embeddings. In addition, we introduce a condition-enhanced DPM decoder to strengthen the modeling ability of the speaker and the emotion in the reverse diffusion process. Cross-lingual emotion transfer experiments show that DiCLET-TTS outperforms various competitive models and demonstrates the effectiveness of OP-EDM in learning speaker-irrelevant but emotion-discriminative embeddings.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.SD_2023_09_02/" data-id="cloh3sr1y00u5h68827vo5ez0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/42/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/41/">41</a><a class="page-number" href="/page/42/">42</a><span class="page-number current">43</span><a class="page-number" href="/page/44/">44</a><a class="page-number" href="/page/45/">45</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/44/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
