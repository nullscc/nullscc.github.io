
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/79/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.CV_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T13:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.CV_2023_07_07/">cs.CV - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery"><a href="#Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery" class="headerlink" title="Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery"></a>Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03662">http://arxiv.org/abs/2307.03662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/br0202/sensing_area_detection">https://github.com/br0202/sensing_area_detection</a></li>
<li>paper_authors: Baoru Huang, Yicheng Hu, Anh Nguyen, Stamatia Giannarou, Daniel S. Elson</li>
<li>for: 针对于医学领域中的外科手术预测和肿瘤检测。</li>
<li>methods: 使用了一种新型的缚定式 Laparoscope γ射测定器，以实时地local化预先注射的辐源追踪剂。</li>
<li>results: 通过利用高维度的图像特征和探针位置信息，成功解决了γ活动视图化的问题，并创造了一个新的性能标准。<details>
<summary>Abstract</summary>
In surgical oncology, it is challenging for surgeons to identify lymph nodes and completely resect cancer even with pre-operative imaging systems like PET and CT, because of the lack of reliable intraoperative visualization tools. Endoscopic radio-guided cancer detection and resection has recently been evaluated whereby a novel tethered laparoscopic gamma detector is used to localize a preoperatively injected radiotracer. This can both enhance the endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and it does not visibly indicate the activity origination on the tissue surface. Initial failed attempts used segmentation or geometric methods, but led to the discovery that it could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through intensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at https://github.com/br0202/Sensing_area_detection.git
</details>
<details>
<summary>摘要</summary>
在外科onkology中，外科医生很难识别lymph nodes和完全 remove cancer，即使使用预先的内分析系统如PET和CT。这是因为在手术中没有可靠的实时显示工具。Recently, endoscopic radio-guided cancer detection and resection has been evaluated, which uses a novel tethered laparoscopic gamma detector to localize a preoperatively injected radiotracer. This can both enhance endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and does not visibly indicate the activity origination on the tissue surface. Initial attempts used segmentation or geometric methods, but these were unsuccessful. Instead, we found that the problem could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through intensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at <https://github.com/br0202/Sensing_area_detection.git>.
</details></li>
</ul>
<hr>
<h2 id="Robust-Human-Detection-under-Visual-Degradation-via-Thermal-and-mmWave-Radar-Fusion"><a href="#Robust-Human-Detection-under-Visual-Degradation-via-Thermal-and-mmWave-Radar-Fusion" class="headerlink" title="Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion"></a>Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03623">http://arxiv.org/abs/2307.03623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ramdrop/utm">https://github.com/ramdrop/utm</a></li>
<li>paper_authors: Kaiwen Cai, Qiyue Xia, Peize Li, John Stankovic, Chris Xiaoxuan Lu</li>
<li>for: 本研究旨在提出一种多模态人体检测系统，用于解决在质量不佳的视觉条件下人体检测的问题。</li>
<li>methods: 本研究使用了可携带式热成像相机和单芯片mm波雷达，并提出了一种bayesian特征提取器和一种uncertainty-guided融合方法来减少热成像检测特征的噪音和雷达点云的多 PATH噪声。</li>
<li>results: 本研究对实际数据集进行评估，并证明了我们的方法在多种竞争方法中具有显著的优势，包括单模态和多模态方法。<details>
<summary>Abstract</summary>
The majority of human detection methods rely on the sensor using visible lights (e.g., RGB cameras) but such sensors are limited in scenarios with degraded vision conditions. In this paper, we present a multimodal human detection system that combines portable thermal cameras and single-chip mmWave radars. To mitigate the noisy detection features caused by the low contrast of thermal cameras and the multi-path noise of radar point clouds, we propose a Bayesian feature extractor and a novel uncertainty-guided fusion method that surpasses a variety of competing methods, either single-modal or multi-modal. We evaluate the proposed method on real-world data collection and demonstrate that our approach outperforms the state-of-the-art methods by a large margin.
</details>
<details>
<summary>摘要</summary>
大多数人员探测方法都是使用可见光（例如RGB摄像头），但这些感知器在有很差视力条件下效果有限。在这篇论文中，我们提出了一种多模态人员探测系统，该系统结合携带式热成像镜头和单 chip MM 微波雷达。为了减少热成像镜头的噪声探测特征和雷达点云的多重反射噪声，我们提议了一种 bayesian 特征提取器和一种新的不确定性导向融合方法。我们对实际数据收集进行了评估，并证明了我们的方法在比较方法中具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Depth-Estimation-Analysis-of-Orthogonally-Divergent-Fisheye-Cameras-with-Distortion-Removal"><a href="#Depth-Estimation-Analysis-of-Orthogonally-Divergent-Fisheye-Cameras-with-Distortion-Removal" class="headerlink" title="Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal"></a>Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03602">http://arxiv.org/abs/2307.03602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matvei Panteleev, Houari Bettahar</li>
<li>for: 提高 fisheye 相机镜像干扰矫正和深度估计精度</li>
<li>methods: 使用两个虚拟平铺相机（VPC），每个VPC捕捉小区域，并将其呈现无镜面偏扭变，模拟平铺相机的行为</li>
<li>results: 对虚拟环境和实际相机实验结果进行比较，显示提案方法可以减少干扰和改善深度估计精度<details>
<summary>Abstract</summary>
Stereo vision systems have become popular in computer vision applications, such as 3D reconstruction, object tracking, and autonomous navigation. However, traditional stereo vision systems that use rectilinear lenses may not be suitable for certain scenarios due to their limited field of view. This has led to the popularity of vision systems based on one or multiple fisheye cameras in different orientations, which can provide a field of view of 180x180 degrees or more. However, fisheye cameras introduce significant distortion at the edges that affects the accuracy of stereo matching and depth estimation. To overcome these limitations, this paper proposes a method for distortion-removal and depth estimation analysis for stereovision system using orthogonally divergent fisheye cameras (ODFC). The proposed method uses two virtual pinhole cameras (VPC), each VPC captures a small portion of the original view and presents it without any lens distortions, emulating the behavior of a pinhole camera. By carefully selecting the captured regions, it is possible to create a stereo pair using two VPCs. The performance of the proposed method is evaluated in both simulation using virtual environment and experiments using real cameras and their results compared to stereo cameras with parallel optical axes. The results demonstrate the effectiveness of the proposed method in terms of distortion removal and depth estimation accuracy.
</details>
<details>
<summary>摘要</summary>
三角视系统在计算机视觉应用中变得流行，如3D重建、对象跟踪和自动导航。然而，传统的三角视系统使用直线镜头可能无法适用于某些场景，因为它们的视场有限。这导致了基于一或多个折衣镜头的不同orientation的视系统的 Popularity，这些系统可以提供180x180度或更大的视场。然而，折衣镜头会在边缘 introduce significant distortion，影响三角匹配和深度估计的准确性。为了解决这些限制，本文提出了一种基于折衣镜头的三角视系统中的distortion-removal和深度估计分析方法。该方法使用两个虚拟缩影镜头（VPC），每个VPC捕捉一小部分的原始视图，并无镜头扭曲的情况下，表现出pinhole镜头的行为。通过精心选择捕捉的区域，可以创建一个三角对Using two VPCs。实验结果表明，提议的方法可以减少折衣的影响，并提高深度估计的准确性。
</details></li>
</ul>
<hr>
<h2 id="GPT4RoI-Instruction-Tuning-Large-Language-Model-on-Region-of-Interest"><a href="#GPT4RoI-Instruction-Tuning-Large-Language-Model-on-Region-of-Interest" class="headerlink" title="GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest"></a>GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03601">http://arxiv.org/abs/2307.03601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jshilong/gpt4roi">https://github.com/jshilong/gpt4roi</a></li>
<li>paper_authors: Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Kai Chen, Ping Luo</li>
<li>for: 这 paper 的目的是提高大型语言模型（LLM）在图像和文本对应中的细腻多模态理解能力，通过在区域水平上调整 instruciton。</li>
<li>methods: 该 paper 使用了重新编写 bounding box 为空间指令的方法，将视觉特征与语言嵌入拼接在一起，输入到 LLM 进行训练。</li>
<li>results: 该 paper 提出了一种基于区域水平的视觉语言模型（GPT4RoI），可以提供更多的区域级多模态能力，如细腻区域描述和复杂区域逻辑。用户可以通过语言和空间指令来互动，并可以通过不同的区域指令来控制细腻程度。<details>
<summary>Abstract</summary>
Instruction tuning large language model (LLM) on image-text pairs has achieved unprecedented vision-language multimodal abilities. However, their vision-language alignments are only built on image-level, the lack of region-level alignment limits their advancements to fine-grained multimodal understanding. In this paper, we propose instruction tuning on region-of-interest. The key design is to reformulate the bounding box as the format of spatial instruction. The interleaved sequences of visual features extracted by the spatial instruction and the language embedding are input to LLM, and trained on the transformed region-text data in instruction tuning format. Our region-level vision-language model, termed as GPT4RoI, brings brand new conversational and interactive experience beyond image-level understanding. (1) Controllability: Users can interact with our model by both language and spatial instructions to flexibly adjust the detail level of the question. (2) Capacities: Our model supports not only single-region spatial instruction but also multi-region. This unlocks more region-level multimodal capacities such as detailed region caption and complex region reasoning. (3) Composition: Any off-the-shelf object detector can be a spatial instruction provider so as to mine informative object attributes from our model, like color, shape, material, action, relation to other objects, etc. The code, data, and demo can be found at https://github.com/jshilong/GPT4RoI.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的指令调整在图像和文本对数据上实现了前无之例的视觉语言融合能力。然而，这些视觉语言对应只基于图像水平，缺失地区水平对应限制了其细化多模态理解的进步。在这篇论文中，我们提议在地区水平上调整指令。我们的关键设计是将 bounding box 转换为空间指令的格式。批处视觉特征和语言嵌入被输入到 LLM，并在转换后的地区文本数据上进行了 instrucion 调整。我们称之为 GPT4RoI 的 Region-level 视觉语言模型，它为用户提供了新的对话和交互体验，跻身于图像水平的理解之外。（1）可控性：用户可以通过语言和空间指令来灵活地调整问题的细节水平。（2）能力：我们的模型支持单个地区空间指令以及多个地区。这解锁了更多的地区多模态能力，如详细地区描述和复杂地区逻辑。（3）组合：任何准备好的物体检测器都可以提供空间指令，从而挖掘出模型中的有用对象特征，如颜色、形状、材质、动作、与其他对象的关系等。代码、数据和示例可以在 GitHub 上找到：https://github.com/jshilong/GPT4RoI。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Segmentation-of-Fetal-Brain-MRI-using-Deep-Learning-Cascaded-Registration"><a href="#Unsupervised-Segmentation-of-Fetal-Brain-MRI-using-Deep-Learning-Cascaded-Registration" class="headerlink" title="Unsupervised Segmentation of Fetal Brain MRI using Deep Learning Cascaded Registration"></a>Unsupervised Segmentation of Fetal Brain MRI using Deep Learning Cascaded Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03579">http://arxiv.org/abs/2307.03579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/valbcn/casreg">https://github.com/valbcn/casreg</a></li>
<li>paper_authors: Valentin Comte, Mireia Alenya, Andrea Urru, Judith Recober, Ayako Nakaki, Francesca Crovetto, Oscar Camara, Eduard Gratacós, Elisenda Eixarch, Fàtima Crispi, Gemma Piella, Mario Ceresa, Miguel A. González Ballester</li>
<li>for: 这研究的目的是为了提高胎儿脑 magnetic resonance imaging（MRI）的自动分割精度，以便分析胎儿脑发育和检测可能的脑发育异常。</li>
<li>methods: 该研究提出了一种新的无监督分割方法，基于多个Atlas分割。该方法使用了一个卷积神经网络来进行3D图像 региSTRATION，并通过计算小、增量的变形来将移动图像精确地对齐到固定图像。这个卷积神经网络可以用来注册多个标注图像，并将其组合成一个精确的分割结果。</li>
<li>results: 该研究的实验结果表明，提出的卷积神经网络注册和多Atlas分割方法可以超越现有的注册方法，并且与使用大量标注数据进行训练的nnU-Net相当。此外，该方法只需使用一小部分的标注数据来进行多Atlas分割任务，而不需要任何数据来训练网络。<details>
<summary>Abstract</summary>
Accurate segmentation of fetal brain magnetic resonance images is crucial for analyzing fetal brain development and detecting potential neurodevelopmental abnormalities. Traditional deep learning-based automatic segmentation, although effective, requires extensive training data with ground-truth labels, typically produced by clinicians through a time-consuming annotation process. To overcome this challenge, we propose a novel unsupervised segmentation method based on multi-atlas segmentation, that accurately segments multiple tissues without relying on labeled data for training. Our method employs a cascaded deep learning network for 3D image registration, which computes small, incremental deformations to the moving image to align it precisely with the fixed image. This cascaded network can then be used to register multiple annotated images with the image to be segmented, and combine the propagated labels to form a refined segmentation. Our experiments demonstrate that the proposed cascaded architecture outperforms the state-of-the-art registration methods that were tested. Furthermore, the derived segmentation method achieves similar performance and inference time to nnU-Net while only using a small subset of annotated data for the multi-atlas segmentation task and none for training the network. Our pipeline for registration and multi-atlas segmentation is publicly available at https://github.com/ValBcn/CasReg.
</details>
<details>
<summary>摘要</summary>
准确 segmentation of fetal brain magnetic resonance images 是关键 для分析胎儿脑部发展和检测可能的神经发育畸形。传统的深度学习自动 segmentation 方法，虽然有效，但需要大量的训练数据并有标注数据，通常由临床医生通过时间consuming 的标注过程生成。为了解决这个挑战，我们提出了一种新的无监督分割方法，基于多个 Atlas segmentation，可以准确地分割多种组织而无需训练数据。我们的方法使用了堆叠的深度学习网络 для 3D 图像匹配，计算小、增量的形变来将移动图像精准地对齐于静止图像。这个堆叠网络可以用来对多个标注图像与要分割的图像进行匹配，并将传播的标签组合成为精度的分割。我们的实验表明，我们提出的堆叠体系超越了测试中的状态态术方法。此外，我们的分割方法可以与 nnU-Net 的性能相似，只需使用小数量的标注数据进行多个Atlas segmentation 任务，并无需训练网络。我们的注册和多个Atlas segmentation 管道可以在 GitHub 上获得，请参考 https://github.com/ValBcn/CasReg。
</details></li>
</ul>
<hr>
<h2 id="SpawnNet-Learning-Generalizable-Visuomotor-Skills-from-Pre-trained-Networks"><a href="#SpawnNet-Learning-Generalizable-Visuomotor-Skills-from-Pre-trained-Networks" class="headerlink" title="SpawnNet: Learning Generalizable Visuomotor Skills from Pre-trained Networks"></a>SpawnNet: Learning Generalizable Visuomotor Skills from Pre-trained Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03567">http://arxiv.org/abs/2307.03567</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/johnrso/spawnnet">https://github.com/johnrso/spawnnet</a></li>
<li>paper_authors: Xingyu Lin, John So, Sashwat Mahalingam, Fangchen Liu, Pieter Abbeel</li>
<li>for: 本研究旨在探讨使用预训练视觉表征的可行性，以便提高学习策略的通用能力。</li>
<li>methods: 本研究使用了一种新的两树架构，即SpawnNet，来将预训练多层表征融合到一个独立的网络中，以学习一个Robust的策略。</li>
<li>results: 对于实验和实际场景，SpawnNet表现出了明显的可 categorical 泛化能力，比之前的方法更好。<details>
<summary>Abstract</summary>
The existing internet-scale image and video datasets cover a wide range of everyday objects and tasks, bringing the potential of learning policies that have broad generalization. Prior works have explored visual pre-training with different self-supervised objectives, but the generalization capabilities of the learned policies remain relatively unknown. In this work, we take the first step towards this challenge, focusing on how pre-trained representations can help the generalization of the learned policies. We first identify the key bottleneck in using a frozen pre-trained visual backbone for policy learning. We then propose SpawnNet, a novel two-stream architecture that learns to fuse pre-trained multi-layer representations into a separate network to learn a robust policy. Through extensive simulated and real experiments, we demonstrate significantly better categorical generalization compared to prior approaches in imitation learning settings.
</details>
<details>
<summary>摘要</summary>
现有的互联网级图像和视频数据集覆盖了广泛的日常物品和任务，这对学习策略的泛化潜力具有很大的潜力。先前的工作已经探索了不同的自我超vised目标，但已经学习的策略的泛化能力仍然不够了解。在这项工作中，我们首次面临这个挑战，我们关注使用预训练的表示来帮助策略的泛化。我们首先确定采用静止预训练视觉背bone的主要瓶颈，然后我们提出了SpawnNet，一种新的两核 architecture，它学习将预训练的多层表示融合到一个分离的网络中，以学习一个稳定的策略。通过了详细的 simulate和实际实验，我们证明了SpawnNet在模仿学习设置下的分类泛化性能明显更好，比先前的方法更好。
</details></li>
</ul>
<hr>
<h2 id="VariGrad-A-Novel-Feature-Vector-Architecture-for-Geometric-Deep-Learning-on-Unregistered-Data"><a href="#VariGrad-A-Novel-Feature-Vector-Architecture-for-Geometric-Deep-Learning-on-Unregistered-Data" class="headerlink" title="VariGrad: A Novel Feature Vector Architecture for Geometric Deep Learning on Unregistered Data"></a>VariGrad: A Novel Feature Vector Architecture for Geometric Deep Learning on Unregistered Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03553">http://arxiv.org/abs/2307.03553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/emmanuel-hartman/pytorch_varigrad">https://github.com/emmanuel-hartman/pytorch_varigrad</a></li>
<li>paper_authors: Emmanuel Hartman, Emery Pierson</li>
<li>for: 本研究提出了一种新的几何深度学习层，使用变量梯度（VariGrad）计算3D几何数据的特征向量表示。这些特征向量可以用于多种下游学习任务，如分类、匹配和形态重建。</li>
<li>methods: 本研究使用了无关于参数化的变量表示方法，以便在数据独立于采样或参数化的情况下训练和测试模型。</li>
<li>results: 研究表明，提出的VariGrad层具有高效、普适和对采样重新采样的可靠性。<details>
<summary>Abstract</summary>
We present a novel geometric deep learning layer that leverages the varifold gradient (VariGrad) to compute feature vector representations of 3D geometric data. These feature vectors can be used in a variety of downstream learning tasks such as classification, registration, and shape reconstruction. Our model's use of parameterization independent varifold representations of geometric data allows our model to be both trained and tested on data independent of the given sampling or parameterization. We demonstrate the efficiency, generalizability, and robustness to resampling demonstrated by the proposed VariGrad layer.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的几何深度学习层，利用变量Gradient（VariGrad）计算三维几何数据的特征向量表示。这些特征向量可以用于多种下游学习任务，如分类、注册和形状重建。我们的模型使用独立参数的变量表示方法，使得我们的模型可以在不同的抽象和参数下进行训练和测试。我们展示了提议的VariGrad层的效率、通用性和对抽样的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Language-free-Compositional-Action-Generation-via-Decoupling-Refinement"><a href="#Language-free-Compositional-Action-Generation-via-Decoupling-Refinement" class="headerlink" title="Language-free Compositional Action Generation via Decoupling Refinement"></a>Language-free Compositional Action Generation via Decoupling Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03538">http://arxiv.org/abs/2307.03538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement">https://github.com/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement</a></li>
<li>paper_authors: Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Ser-Nam Lim</li>
<li>for: 本研究旨在生成3D动作，无需依赖于庞大的神经网络语言注释。</li>
<li>methods: 我们提出了一个新的框架，包括动作对接、条件动作生成和解除精度提升。动作对接使用能量模型提取每个子动作的注意力掩模，然后将两个动作结合使用这些注意力来生成pseudo训练示例。然后，我们使用条件生成模型CVAE来学习一个latent空间，使得动作生成更加多样化。最后，我们提出了解除精度提升，使用自我supervised预训练模型MAE来保证子动作和组合动作之间的semantic一致性。这个进程包括将生成的3D动作映射到2D空间，分解这些图像为两个子segments，使用MAE模型重建完整的图像从子segments，并强制恢复的图像与原始子动作映射的图像一致。</li>
<li>results: 我们创建了两个新的 datasets，名为HumanAct-C和UESTC-C，并提出了相应的评价度量。我们进行了 both qualitative和量化的评估，以证明我们的方法的效果。<details>
<summary>Abstract</summary>
Composing simple elements into complex concepts is crucial yet challenging, especially for 3D action generation. Existing methods largely rely on extensive neural language annotations to discern composable latent semantics, a process that is often costly and labor-intensive. In this study, we introduce a novel framework to generate compositional actions without reliance on language auxiliaries. Our approach consists of three main components: Action Coupling, Conditional Action Generation, and Decoupling Refinement. Action Coupling utilizes an energy model to extract the attention masks of each sub-action, subsequently integrating two actions using these attentions to generate pseudo-training examples. Then, we employ a conditional generative model, CVAE, to learn a latent space, facilitating the diverse generation. Finally, we propose Decoupling Refinement, which leverages a self-supervised pre-trained model MAE to ensure semantic consistency between the sub-actions and compositional actions. This refinement process involves rendering generated 3D actions into 2D space, decoupling these images into two sub-segments, using the MAE model to restore the complete image from sub-segments, and constraining the recovered images to match images rendered from raw sub-actions. Due to the lack of existing datasets containing both sub-actions and compositional actions, we created two new datasets, named HumanAct-C and UESTC-C, and present a corresponding evaluation metric. Both qualitative and quantitative assessments are conducted to show our efficacy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese:Composing simple elements into complex concepts is crucial yet challenging, especially for 3D action generation. Existing methods largely rely on extensive neural language annotations to discern composable latent semantics, a process that is often costly and labor-intensive. In this study, we introduce a novel framework to generate compositional actions without reliance on language auxiliaries. Our approach consists of three main components: Action Coupling, Conditional Action Generation, and Decoupling Refinement. Action Coupling utilizes an energy model to extract the attention masks of each sub-action, subsequently integrating two actions using these attentions to generate pseudo-training examples. Then, we employ a conditional generative model, CVAE, to learn a latent space, facilitating the diverse generation. Finally, we propose Decoupling Refinement, which leverages a self-supervised pre-trained model MAE to ensure semantic consistency between the sub-actions and compositional actions. This refinement process involves rendering generated 3D actions into 2D space, decoupling these images into two sub-segments, using the MAE model to restore the complete image from sub-segments, and constraining the recovered images to match images rendered from raw sub-actions. Due to the lack of existing datasets containing both sub-actions and compositional actions, we created two new datasets, named HumanAct-C and UESTC-C, and present a corresponding evaluation metric. Both qualitative and quantitative assessments are conducted to show our efficacy.Translation:<<SYS>>组合简单元素成复杂概念是关键，特别是在3D动作生成中。现有方法主要依赖于广泛的神经语言标注来 отлича出可组合的含义，这个过程经常是费时和劳动密集的。在这种研究中，我们提出了一种新的框架，可以生成无语言助记的compositional动作。我们的方法包括三个主要组成部分：Action Coupling、Conditional Action Generation和Decoupling Refinement。Action Coupling使用能量模型提取每个子动作的注意力映射，然后将两个动作使用这些注意力进行拼接，生成 pseudo-training 示例。然后，我们使用Conditional Generative Model（CVAE）来学习一个含义空间，促进多样化生成。最后，我们提出了Decoupling Refinement，使用预训练的MAE模型来保证子动作和compositional动作之间的semantic consistency。这个修正过程包括将生成的3D动作映射到2D空间，将这些图像分解成两个子图像，使用MAE模型重建完整的图像，并使其与原始子图像匹配。由于现有的数据集没有包含子动作和compositional动作，我们创建了两个新的数据集，名为HumanAct-C和UESTC-C，并提出了相应的评价指标。我们进行了质量和量化评价，以展示我们的效果。
</details></li>
</ul>
<hr>
<h2 id="Joint-Perceptual-Learning-for-Enhancement-and-Object-Detection-in-Underwater-Scenarios"><a href="#Joint-Perceptual-Learning-for-Enhancement-and-Object-Detection-in-Underwater-Scenarios" class="headerlink" title="Joint Perceptual Learning for Enhancement and Object Detection in Underwater Scenarios"></a>Joint Perceptual Learning for Enhancement and Object Detection in Underwater Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03536">http://arxiv.org/abs/2307.03536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenping Fu, Wanqi Yuan, Jiewen Xiao, Risheng Liu, Xin Fan</li>
<li>for: jointly learn underwater object detection and image enhancement</li>
<li>methods: 使用着色矩阵和卷积神经网络，并提出了一种双层优化方法</li>
<li>results: 实现了更好的图像增强和物体检测精度<details>
<summary>Abstract</summary>
Underwater degraded images greatly challenge existing algorithms to detect objects of interest. Recently, researchers attempt to adopt attention mechanisms or composite connections for improving the feature representation of detectors. However, this solution does \textit{not} eliminate the impact of degradation on image content such as color and texture, achieving minimal improvements. Another feasible solution for underwater object detection is to develop sophisticated deep architectures in order to enhance image quality or features. Nevertheless, the visually appealing output of these enhancement modules do \textit{not} necessarily generate high accuracy for deep detectors. More recently, some multi-task learning methods jointly learn underwater detection and image enhancement, accessing promising improvements. Typically, these methods invoke huge architecture and expensive computations, rendering inefficient inference. Definitely, underwater object detection and image enhancement are two interrelated tasks. Leveraging information coming from the two tasks can benefit each task. Based on these factual opinions, we propose a bilevel optimization formulation for jointly learning underwater object detection and image enhancement, and then unroll to a dual perception network (DPNet) for the two tasks. DPNet with one shared module and two task subnets learns from the two different tasks, seeking a shared representation. The shared representation provides more structural details for image enhancement and rich content information for object detection. Finally, we derive a cooperative training strategy to optimize parameters for DPNet. Extensive experiments on real-world and synthetic underwater datasets demonstrate that our method outputs visually favoring images and higher detection accuracy.
</details>
<details>
<summary>摘要</summary>
水下降低图像对现有算法检测对象存在挑战。研究人员尝试采用注意力机制或复合连接来改善检测器的特征表示。然而，这种解决方案不能完全消除水下图像内容的影响，如颜色和xture，只能获得有限的改进。另一个可行的水下对象检测解决方案是开发高级深度架构，以增强图像质量或特征。然而，这些美化模块的输出不一定能够提高深度检测器的准确率。在最近几年，一些多任务学习方法同时学习水下检测和图像改善，并取得了有望的改进。这些方法通常需要庞大的架构和昂贵的计算，导致效率低下。 Based on these facts, we propose a bilevel optimization formulation for jointly learning water下 object detection and image enhancement, and then unroll to a dual perception network (DPNet) for the two tasks. DPNet with one shared module and two task subnets learns from the two different tasks, seeking a shared representation. The shared representation provides more structural details for image enhancement and rich content information for object detection. Finally, we derive a cooperative training strategy to optimize parameters for DPNet. Extensive experiments on real-world and synthetic underwater datasets demonstrate that our method outputs visually pleasing images and higher detection accuracy.
</details></li>
</ul>
<hr>
<h2 id="Matching-in-the-Wild-Learning-Anatomical-Embeddings-for-Multi-Modality-Images"><a href="#Matching-in-the-Wild-Learning-Anatomical-Embeddings-for-Multi-Modality-Images" class="headerlink" title="Matching in the Wild: Learning Anatomical Embeddings for Multi-Modality Images"></a>Matching in the Wild: Learning Anatomical Embeddings for Multi-Modality Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03535">http://arxiv.org/abs/2307.03535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Bai, Fan Bai, Xiaofei Huo, Jia Ge, Tony C. W. Mok, Zi Li, Minfeng Xu, Jingren Zhou, Le Lu, Dakai Jin, Xianghua Ye, Jingjing Lu, Ke Yan</li>
<li>for: 这个研究旨在提高内部模组之间的对 alignment 的精度，以便更好地利用 CT 和 MRI 两种不同模式之间的信息。</li>
<li>methods: 我们提出了一种新的方法，叫做 Cross-SAM，它利用了一个新的迭代过程，将 embedding learning 和 CT-MRI registrations 融合在一起，以提高对 alignment 的精度。</li>
<li>results: 我们在两个 CT-MRI 融合注册dataset上进行了评估，发现 Cross-SAM 能够实现了 CT 和 MRI 之间的稳定融合注册，并且与其他方法相比，表现出了州域之最。<details>
<summary>Abstract</summary>
Radiotherapists require accurate registration of MR/CT images to effectively use information from both modalities. In a typical registration pipeline, rigid or affine transformations are applied to roughly align the fixed and moving images before proceeding with the deformation step. While recent learning-based methods have shown promising results in the rigid/affine step, these methods often require images with similar field-of-view (FOV) for successful alignment. As a result, aligning images with different FOVs remains a challenging task. Self-supervised landmark detection methods like self-supervised Anatomical eMbedding (SAM) have emerged as a useful tool for mapping and cropping images to similar FOVs. However, these methods are currently limited to intra-modality use only. To address this limitation and enable cross-modality matching, we propose a new approach called Cross-SAM. Our approach utilizes a novel iterative process that alternates between embedding learning and CT-MRI registration. We start by applying aggressive contrast augmentation on both CT and MRI images to train a SAM model. We then use this SAM to identify corresponding regions on paired images using robust grid-points matching, followed by a point-set based affine/rigid registration, and a deformable fine-tuning step to produce registered paired images. We use these registered pairs to enhance the matching ability of SAM, which is then processed iteratively. We use the final model for cross-modality matching tasks. We evaluated our approach on two CT-MRI affine registration datasets and found that Cross-SAM achieved robust affine registration on both datasets, significantly outperforming other methods and achieving state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
医 Physicists需要准确地将MR/CT图像 регистрирова到以便使用这两种模式中的信息。在一般的注册管道中，使用精度的旋转或相对变换来粗略地将固定图像和移动图像对齐，然后进行塑形步骤。而最近的学习基于方法已经在精度步骤中表现出了有前途的结果，但这些方法经常需要具有相似的视野范围（FOV）的图像进行成功的对齐。因此，将图像 WITH 不同的 FOV 进行对齐仍然是一个挑战。自动找到自我医学特征的自适应检测方法，如自适应Anatomical eMbedding（SAM），已经作为一种有用的工具来映射和剪辑图像，但这些方法目前只能在同一种模式中使用。为了解决这种限制并启用跨模式匹配，我们提出了一种新的方法，即 Cross-SAM。我们的方法利用了一种新的迭代过程，它 alternate между embedding learning和CT-MRI注册。我们首先在CT和MRI图像上应用了强制对比增强，然后使用这些SAM来标识对应的区域，并使用精度的grid-points匹配和点集基于的旋转/相对变换注册步骤，最后使用可动的精度调整步骤来生成注册的对应图像。我们使用这些注册对来增强SAM的匹配能力，然后重复处理，并使用最终模型进行跨模式匹配任务。我们在两个CT-MRI注册数据集上进行了评估，并发现 Cross-SAM在两个数据集上都达到了稳定的Affine注册，与其他方法相比，表现出了显著的优势，并达到了领域的前景性表现。
</details></li>
</ul>
<hr>
<h2 id="HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution"><a href="#HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution" class="headerlink" title="HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution"></a>HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03494">http://arxiv.org/abs/2307.03494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Qi Zhang, Hao-Bin Duan, Jun-Long Chen, Ariel Shamir, Miao Wang</li>
<li>for: 提高自动驾驶中车道检测的精度和可靠性，解决车道检测复杂的问题。</li>
<li>methods: 提出了一种基于幂函数变换的层次结构，将整个图像中的所有车道特征整合到幂函数参数空间中，并采用了动态 convolution模块来有效地分解每个车道特征。</li>
<li>results: 实验结果表明，提出的方法可以更好地检测受阻或损坏的车道图像，并且与当前最佳方法相当或超过其性能。<details>
<summary>Abstract</summary>
The task of lane detection has garnered considerable attention in the field of autonomous driving due to its complexity. Lanes can present difficulties for detection, as they can be narrow, fragmented, and often obscured by heavy traffic. However, it has been observed that the lanes have a geometrical structure that resembles a straight line, leading to improved lane detection results when utilizing this characteristic. To address this challenge, we propose a hierarchical Deep Hough Transform (DHT) approach that combines all lane features in an image into the Hough parameter space. Additionally, we refine the point selection method and incorporate a Dynamic Convolution Module to effectively differentiate between lanes in the original image. Our network architecture comprises a backbone network, either a ResNet or Pyramid Vision Transformer, a Feature Pyramid Network as the neck to extract multi-scale features, and a hierarchical DHT-based feature aggregation head to accurately segment each lane. By utilizing the lane features in the Hough parameter space, the network learns dynamic convolution kernel parameters corresponding to each lane, allowing the Dynamic Convolution Module to effectively differentiate between lane features. Subsequently, the lane features are fed into the feature decoder, which predicts the final position of the lane. Our proposed network structure demonstrates improved performance in detecting heavily occluded or worn lane images, as evidenced by our extensive experimental results, which show that our method outperforms or is on par with state-of-the-art techniques.
</details>
<details>
<summary>摘要</summary>
自动驾驶领域内，车道检测已经引起了非常大的关注，因为它的复杂性。车道可能会变窄、分 Fragmented 或者受到压杂的交通影响，但是观察到车道有一定的几何结构，这使得通过利用这个特点可以提高车道检测的结果。为解决这个挑战，我们提议使用层次深度霍夫变换（DHT）方法，将整个图像中的所有车道特征 combine 到霍夫参数空间中。此外，我们还改进了点选择方法，并将动态卷积模块 incorporate 到图像原像中，以有效地区分每条车道。我们的网络架构包括后ION 网络（ResNet 或 Pyramid Vision Transformer）、特征峰网络作为 neck 提取多比例特征，以及层次 DHT 基于特征聚合头来准确地分类每条车道。通过利用车道特征在霍夫参数空间中，网络学习了对应每条车道的动态卷积参数，使得动态卷积模块可以有效地区分每条车道。最后，车道特征被传递到特征解码器，解码器预测了最终车道的位置。我们的提议的网络结构在检测受到压杂或损坏的车道图像时表现出了改进的性能，这得到了我们的广泛实验结果的支持，其中我们的方法与现有技术相当或超越。
</details></li>
</ul>
<hr>
<h2 id="Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching"><a href="#Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching" class="headerlink" title="Unpaired Multi-View Graph Clustering with Cross-View Structure Matching"></a>Unpaired Multi-View Graph Clustering with Cross-View Structure Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03476">http://arxiv.org/abs/2307.03476</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wy1019/upmgc-sm">https://github.com/wy1019/upmgc-sm</a></li>
<li>paper_authors: Yi Wen, Siwei Wang, Qing Liao, Weixuan Liang, Ke Liang, Xinhang Wan, Xinwang Liu</li>
<li>for: 提高多视图数据的群集效果，这个 paper 写的目的是创建一个无 Parameters 的 гра clustering 框架，可以处理不完整的数据对。</li>
<li>methods: 本 paper 使用的方法是一个 Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM)，这个方法 使用多视图数据的结构资讯来优化 cross-view 对应关系。</li>
<li>results: 实验结果显示，本 paper 的提案可以有效地处理不完整的数据对，并且可以与已有的 graph clustering 方法整合来增强它们的效能。<details>
<summary>Abstract</summary>
Multi-view clustering (MVC), which effectively fuses information from multiple views for better performance, has received increasing attention. Most existing MVC methods assume that multi-view data are fully paired, which means that the mappings of all corresponding samples between views are pre-defined or given in advance. However, the data correspondence is often incomplete in real-world applications due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks: 1) Most methods focus on the feature representation while ignoring the structural information of multi-view data, which is essential for clustering tasks; 2) Existing methods for partially unpaired problems rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems; 3) Their inevitable parameters degrade the efficiency and applicability of the models. To tackle these issues, we propose a novel parameter-free graph clustering framework termed Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM effectively utilizes the structural information from each view to refine cross-view correspondences. Besides, our UPMGC-SM is a unified framework for both the fully and partially unpaired multi-view graph clustering. Moreover, existing graph clustering methods can adopt our UPMGC-SM to enhance their ability for unpaired scenarios. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both paired and unpaired datasets.
</details>
<details>
<summary>摘要</summary>
多视图聚合（MVC），已经得到了更好的性能的注意。大多数现有的MVC方法假设多视图数据是完全对应的，这意味着所有视图之间的样本映射都是先前定义或提供的。然而，在实际应用中，数据对应性 oftentimes incomplete due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks:1. 大多数方法只注重特征表示，忽略了多视图数据的结构信息，这是 clustering 任务中非常重要的;2. 现有的部分对应问题方法 rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems;3. 它们的参数会影响模型的效率和可应用性。为了解决这些问题，我们提出了一个新的参数自由的图 clustering 框架，称为 Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM 能够充分利用每视图中的结构信息来修正交叉视图对应关系。此外，我们的 UPMGC-SM 是一个统一的框架，可以处理完全和部分对应的多视图图 clustering。此外，现有的图 clustering 方法可以采用我们的 UPMGC-SM 来增强它们对无对应场景的能力。广泛的实验表明我们提出的框架对于 paired 和 unpaired 数据均有效和普适。
</details></li>
</ul>
<hr>
<h2 id="Freezing-of-Gait-Prediction-From-Accelerometer-Data-Using-a-Simple-1D-Convolutional-Neural-Network-–-8th-Place-Solution-for-Kaggle’s-Parkinson’s-Freezing-of-Gait-Prediction-Competition"><a href="#Freezing-of-Gait-Prediction-From-Accelerometer-Data-Using-a-Simple-1D-Convolutional-Neural-Network-–-8th-Place-Solution-for-Kaggle’s-Parkinson’s-Freezing-of-Gait-Prediction-Competition" class="headerlink" title="Freezing of Gait Prediction From Accelerometer Data Using a Simple 1D-Convolutional Neural Network – 8th Place Solution for Kaggle’s Parkinson’s Freezing of Gait Prediction Competition"></a>Freezing of Gait Prediction From Accelerometer Data Using a Simple 1D-Convolutional Neural Network – 8th Place Solution for Kaggle’s Parkinson’s Freezing of Gait Prediction Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03475">http://arxiv.org/abs/2307.03475</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/janbrederecke/fog">https://github.com/janbrederecke/fog</a></li>
<li>paper_authors: Jan Brederecke</li>
<li>For: 这个研究的目的是检测parkinson病人的停止行动（Freezing of Gait，FOG）事件，以便提供更好的 intervención和管理策略。* Methods: 该研究使用了patient-worn加速度计数据，并使用了一种简单的1-D卷积神经网络来检测FOG事件。* Results: 研究结果表明，使用这种方法可以在实时中检测FOG事件，并在Kaggle上的私人领导板上达到了0.356的平均准确率，并最终排名了1379个équipe中的第8名。<details>
<summary>Abstract</summary>
Freezing of Gait (FOG) is a common motor symptom in patients with Parkinson's disease (PD). During episodes of FOG, patients suddenly lose their ability to stride as intended. Patient-worn accelerometers can capture information on the patient's movement during these episodes and machine learning algorithms can potentially classify this data. The combination therefore holds the potential to detect FOG in real-time. In this work I present a simple 1-D convolutional neural network that was trained to detect FOG events in accelerometer data. Model performance was assessed by measuring the success of the model to discriminate normal movement from FOG episodes and resulted in a mean average precision of 0.356 on the private leaderboard on Kaggle. Ultimately, the model ranked 8th out of 1379 teams in the Parkinson's Freezing of Gait Prediction competition. The results underscore the potential of Deep Learning-based solutions in advancing the field of FOG detection, contributing to improved interventions and management strategies for PD patients.
</details>
<details>
<summary>摘要</summary>
困难步行（FOG）是许多parkinson病患者的常见运动症状之一。在FOG发作时，患者可能会突然失去步行的能力。患者穿戴的加速度仪可以记录患者的运动信息，机器学习算法可以可能地分类这些数据。因此，这两种技术的结合具有检测FOG的潜在力。在这项工作中，我提出了一种简单的1-D convolutional neural network，用于在加速度仪数据中检测FOG事件。模型性能由normal运动和FOG发作之间的分类成功率来衡量，并达到了0.356的mean average precision在Kaggle私人领先板上。最终，模型在1379个组合中排名第8位。这些结果表明深度学习基本解决方案在FOG检测方面具有潜在的优势，可能导致parkinson病患者的 intervención和管理策略的改善。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts"><a href="#A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts" class="headerlink" title="A Deep Active Contour Model for Delineating Glacier Calving Fronts"></a>A Deep Active Contour Model for Delineating Glacier Calving Fronts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03461">http://arxiv.org/abs/2307.03461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konrad Heidler, Lichao Mou, Erik Loebel, Mirko Scheinert, Sébastien Lefèvre, Xiao Xiang Zhu</li>
<li>for: 这个论文主要针对的是如何将现实世界中的冰川陷阱问题编码为机器学习任务。</li>
<li>methods: 该论文提出了一种新的方法，即将冰川陷阱模型转换为 outline 检测问题，并使用 Convolutional Neural Networks (CNNs) 和 active contour 模型来实现。</li>
<li>results: 该论文通过对格陵兰冰川的多个大规模数据集进行训练和评估，显示了该方法的优越性，并且还展示了这种方法在计算模型预测结果的不确定性方面的优势。<details>
<summary>Abstract</summary>
Choosing how to encode a real-world problem as a machine learning task is an important design decision in machine learning. The task of glacier calving front modeling has often been approached as a semantic segmentation task. Recent studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called ``Charting Outlines by Recurrent Adaptation'' (COBRA), combines Convolutional Neural Networks (CNNs) for feature extraction and active contour models for the delineation. By training and evaluating on several large-scale datasets of Greenland's outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models' prediction uncertainties. The project page containing the code and animated model predictions can be found at \url{https://khdlr.github.io/COBRA/}.
</details>
<details>
<summary>摘要</summary>
选择如何编码现实世界问题为机器学习任务是机器学习设计决策中非常重要的一步。 glacier calving front 问题经常被视为semantic segmentation任务。  latest studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called "Charting Outlines by Recurrent Adaptation" (COBRA), combines Convolutional Neural Networks (CNNs) for feature extraction and active contour models for the delineation. By training and evaluating on several large-scale datasets of Greenland's outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models' prediction uncertainties.  project page containing the code and animated model predictions can be found at \url{https://khdlr.github.io/COBRA/}.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Universal-Semi-supervised-Model-Adaptation-via-Collaborative-Consistency-Training"><a href="#Universal-Semi-supervised-Model-Adaptation-via-Collaborative-Consistency-Training" class="headerlink" title="Universal Semi-supervised Model Adaptation via Collaborative Consistency Training"></a>Universal Semi-supervised Model Adaptation via Collaborative Consistency Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03449">http://arxiv.org/abs/2307.03449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizheng Yan, Yushuang Wu, Yipeng Qin, Xiaoguang Han, Shuguang Cui, Guanbin Li</li>
<li>for: 本研究提出了一个实际和挑战性的领域适应问题，即通用半监督模型适应（USMA），该问题只需要一个预训练的源模型，并且源和目标领域的标签集可以不同。</li>
<li>methods: 我们提出了一种协作一致培训框架，该框架规范了两个模型（源模型和目标数据只预训练的变体模型）的预测一致性，并将其们的优势融合以学习更强大的模型。</li>
<li>results: 我们的方法在多个 benchmark 数据集上实现了显著的效果。<details>
<summary>Abstract</summary>
In this paper, we introduce a realistic and challenging domain adaptation problem called Universal Semi-supervised Model Adaptation (USMA), which i) requires only a pre-trained source model, ii) allows the source and target domain to have different label sets, i.e., they share a common label set and hold their own private label set, and iii) requires only a few labeled samples in each class of the target domain. To address USMA, we propose a collaborative consistency training framework that regularizes the prediction consistency between two models, i.e., a pre-trained source model and its variant pre-trained with target data only, and combines their complementary strengths to learn a more powerful model. The rationale of our framework stems from the observation that the source model performs better on common categories than the target-only model, while on target-private categories, the target-only model performs better. We also propose a two-perspective, i.e., sample-wise and class-wise, consistency regularization to improve the training. Experimental results demonstrate the effectiveness of our method on several benchmark datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一个实际和挑战性的领域适应问题，即通用半监督模型适应（USMA）。该问题的要求如下：1. 仅使用源模型的预训练结果；2. 源频率和目标频率的标签集不同，即它们共享一个标签集，但各自拥有私有的标签集；3. 每个目标频率类只需几个标注样本。为解决USMA问题，我们提出了一个协同一致训练框架。该框架通过规范源模型和目标数据只预训练的变体模型之间的预测一致性，并将其们的优势融合起来培养更强大的模型。我们的框架的基本思想是，源模型在共同类别上表现更好，而目标模型在目标私有类别上表现更好。我们还提出了两种视角（样本级和类别级）的一致训练 regularization来提高训练。实验结果表明我们的方法在多个标准数据集上具有抗预测能力。
</details></li>
</ul>
<hr>
<h2 id="NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction"><a href="#NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction" class="headerlink" title="NOFA: NeRF-based One-shot Facial Avatar Reconstruction"></a>NOFA: NeRF-based One-shot Facial Avatar Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03441">http://arxiv.org/abs/2307.03441</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wangbo Yu, Yanbo Fan, Yong Zhang, Xuan Wang, Fei Yin, Yunpeng Bai, Yan-Pei Cao, Ying Shan, Yang Wu, Zhongqian Sun, Baoyuan Wu</li>
<li>for: 一shot 3D facial avatar reconstruction, only requires a single source image for high-fidelity reconstruction.</li>
<li>methods: 利用3D GAN的生成先验和高效编码器-解码器网络重建源图像的 canoncial neural volume，并提出补做网络来补充面部细节。使用扭变场来折叠 canoncial volume 到表达驱动。</li>
<li>results: 通过广泛的实验比较，实现了较高的同构结果，比如果数据量更大的state-of-the-art方法。<details>
<summary>Abstract</summary>
3D facial avatar reconstruction has been a significant research topic in computer graphics and computer vision, where photo-realistic rendering and flexible controls over poses and expressions are necessary for many related applications. Recently, its performance has been greatly improved with the development of neural radiance fields (NeRF). However, most existing NeRF-based facial avatars focus on subject-specific reconstruction and reenactment, requiring multi-shot images containing different views of the specific subject for training, and the learned model cannot generalize to new identities, limiting its further applications. In this work, we propose a one-shot 3D facial avatar reconstruction framework that only requires a single source image to reconstruct a high-fidelity 3D facial avatar. For the challenges of lacking generalization ability and missing multi-view information, we leverage the generative prior of 3D GAN and develop an efficient encoder-decoder network to reconstruct the canonical neural volume of the source image, and further propose a compensation network to complement facial details. To enable fine-grained control over facial dynamics, we propose a deformation field to warp the canonical volume into driven expressions. Through extensive experimental comparisons, we achieve superior synthesis results compared to several state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
三维人脸模型重建已经是计算机图形和计算机视觉领域的一个重要研究主题，需要高真实度的渲染和对姿态和表情的灵活控制，以满足许多相关应用。在最近，通过神经辐射场（NeRF）的发展，其性能得到了显著改进。然而，大多数现有的NeRF基于的人脸模型都是面向特定主体的重建和reenactment，需要多张不同视角的图像进行训练，并且学习的模型无法泛化到新的人脸主体，这限制了其进一步的应用。在这种情况下，我们提出了一种只需要单个源图像来重建高质量三维人脸模型的框架。为了解决缺乏泛化能力和缺失多视角信息的挑战，我们利用了3D GAN的生成预设，并开发了高效的编码器-解码器网络来重建源图像的神经体积，并提出了补做网络来补充人脸细节。为了实现细腻的表情控制，我们提出了扭曲场来扭曲神经体积到驱动表情。通过广泛的实验比较，我们实现了与一些当前领先方法相比的超过其表 sintesis结果。
</details></li>
</ul>
<hr>
<h2 id="Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer"><a href="#Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer" class="headerlink" title="Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer"></a>Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03427">http://arxiv.org/abs/2307.03427</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/survival-xsurv">https://github.com/mungomeng/survival-xsurv</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim</li>
<li>for: 预测乳腺癌患者存活情况，提供早期诊断和治疗规划的信息。</li>
<li>methods: 基于深度学习和医疗图像的深度存存模型，结合多Modalities图像（如PET-CT），并提取特定区域（如主要肿瘤区和迁徙门节区）的预测信息。</li>
<li>results: 在HEAD和NeCK淋巴肿瘤癌数据集上，我们的XSurv方法比前一代存存预测方法高效，能够结合PET和CT图像的补做性信息，并提取特定区域的预测信息。<details>
<summary>Abstract</summary>
Survival prediction is crucial for cancer patients as it provides early prognostic information for treatment planning. Recently, deep survival models based on deep learning and medical images have shown promising performance for survival prediction. However, existing deep survival models are not well developed in utilizing multi-modality images (e.g., PET-CT) and in extracting region-specific information (e.g., the prognostic information in Primary Tumor (PT) and Metastatic Lymph Node (MLN) regions). In view of this, we propose a merging-diverging learning framework for survival prediction from multi-modality images. This framework has a merging encoder to fuse multi-modality information and a diverging decoder to extract region-specific information. In the merging encoder, we propose a Hybrid Parallel Cross-Attention (HPCA) block to effectively fuse multi-modality features via parallel convolutional layers and cross-attention transformers. In the diverging decoder, we propose a Region-specific Attention Gate (RAG) block to screen out the features related to lesion regions. Our framework is demonstrated on survival prediction from PET-CT images in Head and Neck (H&N) cancer, by designing an X-shape merging-diverging hybrid transformer network (named XSurv). Our XSurv combines the complementary information in PET and CT images and extracts the region-specific prognostic information in PT and MLN regions. Extensive experiments on the public dataset of HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR 2022) demonstrate that our XSurv outperforms state-of-the-art survival prediction methods.
</details>
<details>
<summary>摘要</summary>
生存预测对 cancer 患者非常重要，因为它提供了早期的诊断信息，用于治疗规划。在最近几年，深度存活模型基于深度学习和医疗图像已经显示出了惊人的表现。然而，现有的深度存活模型并没有充分利用多Modalities 图像（例如 PET-CT），也没有充分提取区域特定的信息（例如 Primary Tumor （PT）和 Metastatic Lymph Node （MLN）区域的诊断信息）。为了解决这个问题，我们提出了一种融合-分化学习框架，用于存活预测从多Modalities 图像。这个框架包括一个融合Encoder，用于融合多Modalities 信息，以及一个分化Decoder，用于提取区域特定的信息。在融合Encoder中，我们提出了一种Hybrid Parallel Cross-Attention（HPCA）块，用于有效地融合多Modalities 特征，并通过并行卷积层和交叉注意力变换器来实现。在分化Decoder中，我们提出了一种Region-specific Attention Gate（RAG）块，用于筛选出病变区域相关的特征。我们的框架在 Head and Neck 癌症的存活预测中使用 X-shape 融合-分化混合变换网络（名为 XSurv），把 PET 和 CT 图像的补充性信息融合在一起，并提取 PT 和 MLN 区域的区域特定诊断信息。我们的 XSurv 在 HEAD and neCK TumOR segmentation and outcome prediction challenge 2022 公共数据集上进行了广泛的实验，并证明了我们的 XSurv 在存活预测方面超过了当前的状态艺。
</details></li>
</ul>
<hr>
<h2 id="Registration-Free-Hybrid-Learning-Empowers-Simple-Multimodal-Imaging-System-for-High-quality-Fusion-Detection"><a href="#Registration-Free-Hybrid-Learning-Empowers-Simple-Multimodal-Imaging-System-for-High-quality-Fusion-Detection" class="headerlink" title="Registration-Free Hybrid Learning Empowers Simple Multimodal Imaging System for High-quality Fusion Detection"></a>Registration-Free Hybrid Learning Empowers Simple Multimodal Imaging System for High-quality Fusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03425">http://arxiv.org/abs/2307.03425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinghan Guan, Haoran Dai, Zekuan Yu, Shouyu Wang, Yuanjie Gu</li>
<li>for:  smoke and wildfire detection</li>
<li>methods:  CNN-Transformer hybrid learning framework with unified high-quality multimodal feature matching module and fusion module</li>
<li>results:  superior detection performance compared to other state-of-the-art methods under conventional registered conditions, and the first unregistered multimodal smoke and wildfire detection benchmark is openly available.Here’s the full text in Simplified Chinese:</li>
<li>for: 这个论文是为了实现烟火检测而写的。</li>
<li>methods: 该论文提出了一种基于CNN-Transformer混合学习框架的高质量多Modal特征匹配模块（AKM）和拟合模块（WDAF），通过AKM和WDAF的合作来实现高质量红外意识可见混合检测。</li>
<li>results:  experiments on M3FD dataset表明，提出的方法在已有的注册条件下达到了最佳检测性能，并且在未注册的情况下开设了第一个多Modal烟火检测benchmark。<details>
<summary>Abstract</summary>
Multimodal fusion detection always places high demands on the imaging system and image pre-processing, while either a high-quality pre-registration system or image registration processing is costly. Unfortunately, the existing fusion methods are designed for registered source images, and the fusion of inhomogeneous features, which denotes a pair of features at the same spatial location that expresses different semantic information, cannot achieve satisfactory performance via these methods. As a result, we propose IA-VFDnet, a CNN-Transformer hybrid learning framework with a unified high-quality multimodal feature matching module (AKM) and a fusion module (WDAF), in which AKM and DWDAF work in synergy to perform high-quality infrared-aware visible fusion detection, which can be applied to smoke and wildfire detection. Furthermore, experiments on the M3FD dataset validate the superiority of the proposed method, with IA-VFDnet achieving the best detection performance than other state-of-the-art methods under conventional registered conditions. In addition, the first unregistered multimodal smoke and wildfire detection benchmark is openly available in this letter.
</details>
<details>
<summary>摘要</summary>
多模态融合检测总是对图像系统和图像预处理做出高要求，而ither高质量预注册系统或图像注册处理成本较高。可惜，现有的融合方法都是为注册源图像设计的，因此无法实现满意的性能via这些方法。为此，我们提议IA-VFDnet，一种基于CNN-Transformer混合学习框架的高质量多模态特征匹配模块（AKM）和融合模块（WDAF），其中AKM和WDAF在同工 synergy中实现高质量红外意识可见融合检测，可应用于烟和野火检测。此外，在M3FD数据集上进行的实验 validate了我们提议的方法的优越性，IA-VFDnet在 convential注册条件下实现了其他状态对照方法的最佳检测性能。此外，我们还公开提供了首个无注册多模态烟和野火检测benchmark。
</details></li>
</ul>
<hr>
<h2 id="Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model"><a href="#Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model"></a>Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03423">http://arxiv.org/abs/2307.03423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/ddpmfus">https://github.com/shuaikaishi/ddpmfus</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Jie Chen</li>
<li>for: 这个论文主要是为了提出一种基于深度学习的卷积混合方法，以提高卷积图像的空间和spectral分辨率。</li>
<li>methods: 该方法基于conditioned denoising diffusion probabilistic model（DDPM），包括一个前向扩散过程和一个反向denoising过程。前向扩散过程逐渐添加 Gaussian 噪声到高空间分辨率卷积图像（HrHSI），而反向denoising过程通过学习预测desired HrHSI的高空间分辨率版本，条件于对应的高空间分辨率多spectral图像（HrMSI）和low空间分辨率卷积图像（LrHSI）。</li>
<li>results: 对一个indoor和两个遥感数据集进行了实验，并与其他先进的深度学习基于混合方法进行了比较。结果显示，提出的方法在混合过程中具有superiority。codes of this work将被opensourced于以下地址：<a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/DDPMFus%EF%BC%8C%E4%BB%A5%E4%BE%BF%E8%BF%9B%E8%A1%8C%E5%8F%AF%E9%87%8D%E7%8E%B0%E3%80%82">https://github.com/shuaikaishi/DDPMFus，以便进行可重现。</a><details>
<summary>Abstract</summary>
Hyperspectral images (HSI) have a large amount of spectral information reflecting the characteristics of matter, while their spatial resolution is low due to the limitations of imaging technology. Complementary to this are multispectral images (MSI), e.g., RGB images, with high spatial resolution but insufficient spectral bands. Hyperspectral and multispectral image fusion is a technique for acquiring ideal images that have both high spatial and high spectral resolution cost-effectively. Many existing HSI and MSI fusion algorithms rely on known imaging degradation models, which are often not available in practice. In this paper, we propose a deep fusion method based on the conditional denoising diffusion probabilistic model, called DDPM-Fus. Specifically, the DDPM-Fus contains the forward diffusion process which gradually adds Gaussian noise to the high spatial resolution HSI (HrHSI) and another reverse denoising process which learns to predict the desired HrHSI from its noisy version conditioning on the corresponding high spatial resolution MSI (HrMSI) and low spatial resolution HSI (LrHSI). Once the training is completes, the proposed DDPM-Fus implements the reverse process on the test HrMSI and LrHSI to generate the fused HrHSI. Experiments conducted on one indoor and two remote sensing datasets show the superiority of the proposed model when compared with other advanced deep learningbased fusion methods. The codes of this work will be opensourced at this address: https://github.com/shuaikaishi/DDPMFus for reproducibility.
</details>
<details>
<summary>摘要</summary>
干ogram (HSI) 具有大量的spectral信息，反映物质特性，但其 spatial resolution受到成像技术限制而低。与之相结合的是多spectral图像 (MSI)，如 RGB 图像，具有高 spatial resolution，但lack spectral band。干ogram和多spectral图像合并是一种获得理想图像，具有高 spatial 和高 spectral resolution的方法。许多现有的 HSI 和 MSI 合并算法 rely on known imaging degradation models，往往不在实践中可用。在这篇文章中，我们提出了基于 conditional denoising diffusion probabilistic model (DDPM) 的深度融合方法，称为 DDPM-Fus。具体来说，DDPM-Fus 包括将高 spatial resolution HSI (HrHSI) 逐渐添加 Gaussian noise 的前进 diffusion process，以及 conditioning on 高 spatial resolution MSI (HrMSI) 和 low spatial resolution HSI (LrHSI) 的reverse denoising process，学习预测 Desired HrHSI。一旦训练完成，我们的 DDPM-Fus 实现了 reverse process 在 test HrMSI 和 LrHSI 上，生成融合后的 HrHSI。我们在一个indoor和两个遥感数据集上进行了实验，并证明了我们的方法在其他高级深度学习基于融合方法之上的比较优势。我们将在这里公开源代码：https://github.com/shuaikaishi/DDPMFus，以便重现。
</details></li>
</ul>
<hr>
<h2 id="Learning-Adversarial-Semantic-Embeddings-for-Zero-Shot-Recognition-in-Open-Worlds"><a href="#Learning-Adversarial-Semantic-Embeddings-for-Zero-Shot-Recognition-in-Open-Worlds" class="headerlink" title="Learning Adversarial Semantic Embeddings for Zero-Shot Recognition in Open Worlds"></a>Learning Adversarial Semantic Embeddings for Zero-Shot Recognition in Open Worlds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03416">http://arxiv.org/abs/2307.03416</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lhrst/ase">https://github.com/lhrst/ase</a></li>
<li>paper_authors: Tianqi Li, Guansong Pang, Xiao Bai, Jin Zheng, Lei Zhou, Xin Ning</li>
<li>for: 这个研究是为了解决Zero-Shot Open-Set Recognition（ZS-OSR）任务，即在Zero-Shot Learning（ZSL） Setting下需要精确地分类未见类别的样本，并能够拒绝未知类别的样本。</li>
<li>methods: 我们使用了现有的State-of-the-art ZSL和OSR模型，并引入了一个新的方法，即生成unknown classes的对抗性semantic embeddings，以训练一个unknowns-informed ZS-OSR分类器。</li>
<li>results: 我们的方法substantially outperforms the combined solutions in detecting unknown classes while retaining the classification accuracy on unseen classes，并在 generalized ZS-OSR settings中也 achieve similar superiority.<details>
<summary>Abstract</summary>
Zero-Shot Learning (ZSL) focuses on classifying samples of unseen classes with only their side semantic information presented during training. It cannot handle real-life, open-world scenarios where there are test samples of unknown classes for which neither samples (e.g., images) nor their side semantic information is known during training. Open-Set Recognition (OSR) is dedicated to addressing the unknown class issue, but existing OSR methods are not designed to model the semantic information of the unseen classes. To tackle this combined ZSL and OSR problem, we consider the case of "Zero-Shot Open-Set Recognition" (ZS-OSR), where a model is trained under the ZSL setting but it is required to accurately classify samples from the unseen classes while being able to reject samples from the unknown classes during inference. We perform large experiments on combining existing state-of-the-art ZSL and OSR models for the ZS-OSR task on four widely used datasets adapted from the ZSL task, and reveal that ZS-OSR is a non-trivial task as the simply combined solutions perform badly in distinguishing the unseen-class and unknown-class samples. We further introduce a novel approach specifically designed for ZS-OSR, in which our model learns to generate adversarial semantic embeddings of the unknown classes to train an unknowns-informed ZS-OSR classifier. Extensive empirical results show that our method 1) substantially outperforms the combined solutions in detecting the unknown classes while retaining the classification accuracy on the unseen classes and 2) achieves similar superiority under generalized ZS-OSR settings.
</details>
<details>
<summary>摘要</summary>
Zero-Shot Learning (ZSL) 专注于在训练过程中只使用类型相关信息来分类未经见过的样本。它无法处理生活中的开放世界enario，那里有测试样本的未知类型， neither samples（例如，图像） nor their type-related information is known during training。Open-Set Recognition (OSR) 专门解决未知类型问题，但现有的 OSR 方法没有考虑类型信息的 semantic information。为了解决这个 ZSL 和 OSR 的共同问题，我们提出了 "Zero-Shot Open-Set Recognition" (ZS-OSR) 任务，其中模型在 ZSL Setting 下进行训练，但需要在推理时准确地分类未经见过的样本，并能够拒绝未知样本。我们在四个广泛使用的数据集上进行了大规模的实验，发现 ZS-OSR 是一个非常复杂的任务，简单地将 ZSL 和 OSR 模型结合起来的方法表现不佳。我们还提出了一种专门为 ZS-OSR 设计的新方法，其中我们的模型学习生成未知类型的敌意Semantic embedding，以训练一个不知情 ZS-OSR 分类器。我们的方法在检测未知类型的同时保持分类精度，并在总体 ZS-OSR 设定下实现了类似的superiority。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency"><a href="#Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency" class="headerlink" title="Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency"></a>Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03413">http://arxiv.org/abs/2307.03413</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/CycFusion">https://github.com/shuaikaishi/CycFusion</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Yoann Altmann, Jie Chen</li>
<li>for: 本研究旨在提出一种不需要known spatial degradation parameters的Unsupervised hyperspectral and multispectral image fusion方法，以提高图像的空间分辨率和спектраль特征的精度。</li>
<li>methods: 该方法基于循环一致性，学习了低分辨率多spectral图像（LrHSI）和高分辨率多spectral图像（HrMSI）之间的频谱域转换，并将恰好的高分辨率 hyperspectral图像（HrHSI）视为中间特征图。</li>
<li>results: 实验结果表明，对多个数据集进行比较，该方法在无监督的情况下，与其他所有不监督拟合方法相比，具有更高的精度和稳定性。<details>
<summary>Abstract</summary>
Hyperspectral images (HSI) with abundant spectral information reflected materials property usually perform low spatial resolution due to the hardware limits. Meanwhile, multispectral images (MSI), e.g., RGB images, have a high spatial resolution but deficient spectral signatures. Hyperspectral and multispectral image fusion can be cost-effective and efficient for acquiring both high spatial resolution and high spectral resolution images. Many of the conventional HSI and MSI fusion algorithms rely on known spatial degradation parameters, i.e., point spread function, spectral degradation parameters, spectral response function, or both of them. Another class of deep learning-based models relies on the ground truth of high spatial resolution HSI and needs large amounts of paired training images when working in a supervised manner. Both of these models are limited in practical fusion scenarios. In this paper, we propose an unsupervised HSI and MSI fusion model based on the cycle consistency, called CycFusion. The CycFusion learns the domain transformation between low spatial resolution HSI (LrHSI) and high spatial resolution MSI (HrMSI), and the desired high spatial resolution HSI (HrHSI) are considered to be intermediate feature maps in the transformation networks. The CycFusion can be trained with the objective functions of marginal matching in single transform and cycle consistency in double transforms. Moreover, the estimated PSF and SRF are embedded in the model as the pre-training weights, which further enhances the practicality of our proposed model. Experiments conducted on several datasets show that our proposed model outperforms all compared unsupervised fusion methods. The codes of this paper will be available at this address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
</details>
<details>
<summary>摘要</summary>
干支spectral图像（HSI）具有丰富的spectral信息，通常因hardware限制而具有低空间分辨率。而多spectral图像（MSI），例如RGB图像，具有高空间分辨率，但缺乏spectral特征。干支spectral和多spectral图像 fusión可以是成本效益和高效的方式，以获取高空间分辨率和高spectral分辨率图像。许多传统的HSI和MSI fusión算法依赖于已知的空间退化参数，例如点扩散函数、spectral退化参数、spectral响应函数或其中之一。另一类的深度学习基于模型则需要大量的协同训练图像，并且需要高度的精度和可靠性。在这篇文章中，我们提出了一种不需要supervision的HSI和MSI fusión模型，称为CycFusion。CycFusion学习了干支spectral和多spectral图像之间的域转换，并将愿望的高空间分辨率HSI视为转换网络中的中间特征图。CycFusion可以通过单个transform和双transform的对应函数来进行训练，并且可以在不同的datasets上进行模型验证。实验结果表明，我们提出的模型在与其他不需要supervision的fusión方法进行比较时表现出色。codes of this paper will be available at this address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
</details></li>
</ul>
<hr>
<h2 id="Distilling-Self-Supervised-Vision-Transformers-for-Weakly-Supervised-Few-Shot-Classification-Segmentation"><a href="#Distilling-Self-Supervised-Vision-Transformers-for-Weakly-Supervised-Few-Shot-Classification-Segmentation" class="headerlink" title="Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification &amp; Segmentation"></a>Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification &amp; Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03407">http://arxiv.org/abs/2307.03407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dahyun Kang, Piotr Koniusz, Minsu Cho, Naila Murray</li>
<li>for: 这个论文的目的是解决弱监督少量图像分类和 segmentation 问题，通过利用一个自我监督的视觉转移（ViT）预训练模型。</li>
<li>methods: 该方法使用自我监督 ViT 生成的token表示，通过自我注意力来生成分类和 segmentation 预测，通过两个任务头。</li>
<li>results: 实验结果表明，在不同的监督情况下，该方法可以具有显著的性能提升，特别是在没有像素级标签的情况下。<details>
<summary>Abstract</summary>
We address the task of weakly-supervised few-shot image classification and segmentation, by leveraging a Vision Transformer (ViT) pretrained with self-supervision. Our proposed method takes token representations from the self-supervised ViT and leverages their correlations, via self-attention, to produce classification and segmentation predictions through separate task heads. Our model is able to effectively learn to perform classification and segmentation in the absence of pixel-level labels during training, using only image-level labels. To do this it uses attention maps, created from tokens generated by the self-supervised ViT backbone, as pixel-level pseudo-labels. We also explore a practical setup with ``mixed" supervision, where a small number of training images contains ground-truth pixel-level labels and the remaining images have only image-level labels. For this mixed setup, we propose to improve the pseudo-labels using a pseudo-label enhancer that was trained using the available ground-truth pixel-level labels. Experiments on Pascal-5i and COCO-20i demonstrate significant performance gains in a variety of supervision settings, and in particular when little-to-no pixel-level labels are available.
</details>
<details>
<summary>摘要</summary>
我们Addresses the task of weakly-supervised few-shot image classification和 segmentation，通过利用Vision Transformer（ViT）预训练自我supervision。我们提议的方法利用自我supervision ViT 中的token表示，通过自我注意力，生成分类和 segmentation预测。我们的模型可以有效地在没有像素级标签的情况下，使用只有图像级标签进行训练，学习进行分类和 segmentation。为此，它使用来自自我supervision ViT 中生成的token的注意力地图，作为像素级 pseudo-标签。我们还探讨了一种实用的混合supervision设置，其中一些训练图像包含ground-truth像素级标签，剩下的图像只有图像级标签。为这种混合设置，我们提议使用pseudo-标签增强器，该模型在可用的ground-truth像素级标签的基础上训练。我们的实验在 Pascal-5i 和 COCO-20i 上达到了多种supervision设置下的显著性能提升，特别是在没有或少像素级标签的情况下。
</details></li>
</ul>
<hr>
<h2 id="RGB-D-Mapping-and-Tracking-in-a-Plenoxel-Radiance-Field"><a href="#RGB-D-Mapping-and-Tracking-in-a-Plenoxel-Radiance-Field" class="headerlink" title="RGB-D Mapping and Tracking in a Plenoxel Radiance Field"></a>RGB-D Mapping and Tracking in a Plenoxel Radiance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03404">http://arxiv.org/abs/2307.03404</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas L. Teigen, Yeonsoo Park, Annette Stahl, Rudolf Mester<br>for:* 这个技术报告主要写于哪些领域？methods:* 这个技术使用了哪些方法？results:* 这个技术实现了哪些成果？Here are the answers in Simplified Chinese:for:* 这个技术报告主要写于 Computer Vision 和 Robotics 领域。methods:* 这个技术使用了 Plenoxel 频谱场模型，以及RGB-D数据无需神经网络的分析差分方法。results:* 这个技术实现了state-of-the-art的映射和跟踪任务结果，同时比 neural network-based 方法更快。<details>
<summary>Abstract</summary>
Building on the success of Neural Radiance Fields (NeRFs), recent years have seen significant advances in the domain of novel view synthesis. These models capture the scene's volumetric radiance field, creating highly convincing dense photorealistic models through the use of simple, differentiable rendering equations. Despite their popularity, these algorithms suffer from severe ambiguities in visual data inherent to the RGB sensor, which means that although images generated with view synthesis can visually appear very believable, the underlying 3D model will often be wrong. This considerably limits the usefulness of these models in practical applications like Robotics and Extended Reality (XR), where an accurate dense 3D reconstruction otherwise would be of significant value. In this technical report, we present the vital differences between view synthesis models and 3D reconstruction models. We also comment on why a depth sensor is essential for modeling accurate geometry in general outward-facing scenes using the current paradigm of novel view synthesis methods. Focusing on the structure-from-motion task, we practically demonstrate this need by extending the Plenoxel radiance field model: Presenting an analytical differential approach for dense mapping and tracking with radiance fields based on RGB-D data without a neural network. Our method achieves state-of-the-art results in both the mapping and tracking tasks while also being faster than competing neural network-based approaches.
</details>
<details>
<summary>摘要</summary>
在最近几年，因为神经辐射场（NeRF）的成功， novel view synthesis 领域有了 significiant advances。这些模型可以 capture 场景的三维辐射场，通过简单的可导渠 Equations 来创建高效的、 photorealistic 模型。 despite their popularity, these algorithms suffer from severe ambiguities in visual data inherent to the RGB sensor, which means that although images generated with view synthesis can visually appear very believable, the underlying 3D model will often be wrong. This considerably limits the usefulness of these models in practical applications like Robotics and Extended Reality (XR), where an accurate dense 3D reconstruction otherwise would be of significant value.在这份技术报告中，我们展示了视图synthesis 模型和 3D 重建模型之间的重要差异。我们还评论了为了在现今的 novel view synthesis 方法中模型 precisions 的 accurate geometry 的深度感知器的重要性。在structure-from-motion 任务中，我们实际地示出了这种需求。我们通过扩展 Plenoxel 辐射场模型，提出了一种基于 RGB-D 数据的分析差分方法 для dense mapping 和 tracking。我们的方法可以在 mapping 和 tracking 任务中达到状态艺术 Results，同时也比竞争的神经网络基于方法更快。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Geo-localization-Fine-grained-Orientation-of-Street-view-Images-by-Cross-view-Matching-with-Satellite-Imagery-with-Supplementary-Materials"><a href="#Beyond-Geo-localization-Fine-grained-Orientation-of-Street-view-Images-by-Cross-view-Matching-with-Satellite-Imagery-with-Supplementary-Materials" class="headerlink" title="Beyond Geo-localization: Fine-grained Orientation of Street-view Images by Cross-view Matching with Satellite Imagery with Supplementary Materials"></a>Beyond Geo-localization: Fine-grained Orientation of Street-view Images by Cross-view Matching with Satellite Imagery with Supplementary Materials</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03398">http://arxiv.org/abs/2307.03398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenmiao Hu, Yichen Zhang, Yuxuan Liang, Yifang Yin, Andrei Georgescu, An Tran, Hannes Kruppa, See-Kiong Ng, Roger Zimmermann<br>for:This paper focuses on improving the accuracy of fine-grained orientation estimation for street-view images.methods:The proposed methods use a combination of feature extraction and deep learning techniques to estimate the orientation of street-view images.results:The proposed methods achieve high accuracy on orientation estimation, with an average improvement of 34.9% and 28.2% compared to previous works. Integrating fine-grained orientation estimation in training also improves the performance on geo-localization.<details>
<summary>Abstract</summary>
Street-view imagery provides us with novel experiences to explore different places remotely. Carefully calibrated street-view images (e.g. Google Street View) can be used for different downstream tasks, e.g. navigation, map features extraction. As personal high-quality cameras have become much more affordable and portable, an enormous amount of crowdsourced street-view images are uploaded to the internet, but commonly with missing or noisy sensor information. To prepare this hidden treasure for "ready-to-use" status, determining missing location information and camera orientation angles are two equally important tasks. Recent methods have achieved high performance on geo-localization of street-view images by cross-view matching with a pool of geo-referenced satellite imagery. However, most of the existing works focus more on geo-localization than estimating the image orientation. In this work, we re-state the importance of finding fine-grained orientation for street-view images, formally define the problem and provide a set of evaluation metrics to assess the quality of the orientation estimation. We propose two methods to improve the granularity of the orientation estimation, achieving 82.4% and 72.3% accuracy for images with estimated angle errors below 2 degrees for CVUSA and CVACT datasets, corresponding to 34.9% and 28.2% absolute improvement compared to previous works. Integrating fine-grained orientation estimation in training also improves the performance on geo-localization, giving top 1 recall 95.5%/85.5% and 86.8%/80.4% for orientation known/unknown tests on the two datasets.
</details>
<details>
<summary>摘要</summary>
街景图像提供了许多不同的地方的远程探索。高级别的街景图像（例如Google街景图）可以用于不同的下游任务，如导航和地图特征提取。随着个人高质量相机的成本下降和 portaбеility提高，互联网上上传了大量的拍摄街景图像，但通常缺失或含有噪音的感知信息。为了准备这些隐藏的财富，确定缺失的地理位置信息和摄像机方向角度是两个等 importante的任务。现有方法已经达到了高性能的地图化街景图像，但大多数现有的工作更注重地图化than estimating图像方向。在这个工作中，我们重申了找到细化的图像方向的重要性，正式定义问题，并提供了评价图像方向估计质量的测试 метрик。我们提出了两种方法来改进细化图像方向估计，实现了82.4%和72.3%的准确率，对于CVUSA和CACT datasets的图像的估计角度错误小于2度，相对于先前的工作提高了34.9%和28.2%的绝对改进。将细化的图像方向估计integrated into training还提高了地图化性能，在两个dataset上取得了 recall 95.5%/85.5%和86.8%/80.4%，对于orientationknown/unknown测试。
</details></li>
</ul>
<hr>
<h2 id="General-Purpose-Multimodal-Transformer-meets-Remote-Sensing-Semantic-Segmentation"><a href="#General-Purpose-Multimodal-Transformer-meets-Remote-Sensing-Semantic-Segmentation" class="headerlink" title="General-Purpose Multimodal Transformer meets Remote Sensing Semantic Segmentation"></a>General-Purpose Multimodal Transformer meets Remote Sensing Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03388">http://arxiv.org/abs/2307.03388</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhikieu/spatialvolumetricmultimodal">https://github.com/nhikieu/spatialvolumetricmultimodal</a></li>
<li>paper_authors: Nhi Kieu, Kien Nguyen, Sridha Sridharan, Clinton Fookes</li>
<li>for: 这个研究探讨了 PerceiverIO 综合多模式网络在遥测Semantic Segmentation 领域的表现。</li>
<li>methods: 研究使用了一个 UNit-inspired 模组，该模组使用三维核算法来汇入本地信息，同时学习跨模式特征。</li>
<li>results: 研究发现，提案的方法可以与专门架构 like UNetFormer 和 SwinUNet 相比，达到了竞争性的结果，显示了该方法在优化网络架构设计方面的潜在。<details>
<summary>Abstract</summary>
The advent of high-resolution multispectral/hyperspectral sensors, LiDAR DSM (Digital Surface Model) information and many others has provided us with an unprecedented wealth of data for Earth Observation. Multimodal AI seeks to exploit those complementary data sources, particularly for complex tasks like semantic segmentation. While specialized architectures have been developed, they are highly complicated via significant effort in model design, and require considerable re-engineering whenever a new modality emerges. Recent trends in general-purpose multimodal networks have shown great potential to achieve state-of-the-art performance across multiple multimodal tasks with one unified architecture. In this work, we investigate the performance of PerceiverIO, one in the general-purpose multimodal family, in the remote sensing semantic segmentation domain. Our experiments reveal that this ostensibly universal network struggles with object scale variation in remote sensing images and fails to detect the presence of cars from a top-down view. To address these issues, even with extreme class imbalance issues, we propose a spatial and volumetric learning component. Specifically, we design a UNet-inspired module that employs 3D convolution to encode vital local information and learn cross-modal features simultaneously, while reducing network computational burden via the cross-attention mechanism of PerceiverIO. The effectiveness of the proposed component is validated through extensive experiments comparing it with other methods such as 2D convolution, and dual local module (\ie the combination of Conv2D 1x1 and Conv2D 3x3 inspired by UNetFormer). The proposed method achieves competitive results with specialized architectures like UNetFormer and SwinUNet, showing its potential to minimize network architecture engineering with a minimal compromise on the performance.
</details>
<details>
<summary>摘要</summary>
“现代高分辨率多spectral/干spectral传感器、LiDAR DSM（数字地面模型）等数据源的出现，为地球观测带来了前所未有的数据 богат度。多Modal AI 利用这些补充数据源，特别是 для复杂任务 like semantic segmentation。虽然专门的架构有出现，但它们具有较高的复杂度，需要较大的模型设计和重新引擎，每当新的模态出现时。 current trend in general-purpose multimodal networks has shown great potential to achieve state-of-the-art performance across multiple multimodal tasks with one unified architecture. In this work, we investigate the performance of PerceiverIO, one in the general-purpose multimodal family, in the remote sensing semantic segmentation domain. Our experiments reveal that this ostensibly universal network struggles with object scale variation in remote sensing images and fails to detect the presence of cars from a top-down view. To address these issues, we propose a spatial and volumetric learning component. Specifically, we design a UNet-inspired module that employs 3D convolution to encode vital local information and learn cross-modal features simultaneously, while reducing network computational burden via the cross-attention mechanism of PerceiverIO. The effectiveness of the proposed component is validated through extensive experiments comparing it with other methods such as 2D convolution and dual local module (\ie the combination of Conv2D 1x1 and Conv2D 3x3 inspired by UNetFormer). The proposed method achieves competitive results with specialized architectures like UNetFormer and SwinUNet, showing its potential to minimize network architecture engineering with a minimal compromise on the performance.”
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-Contrastive-Learning-for-Unsupervised-Object-Discovery"><a href="#Weakly-supervised-Contrastive-Learning-for-Unsupervised-Object-Discovery" class="headerlink" title="Weakly-supervised Contrastive Learning for Unsupervised Object Discovery"></a>Weakly-supervised Contrastive Learning for Unsupervised Object Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03376">http://arxiv.org/abs/2307.03376</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/npucvr/wscuod">https://github.com/npucvr/wscuod</a></li>
<li>paper_authors: Yunqiu Lv, Jing Zhang, Nick Barnes, Yuchao Dai</li>
<li>for: 本研究旨在提出一种新的无监督物体发现方法，以提高物体检测和分割的精度。</li>
<li>methods: 我们提出了一种基于自我超vised学习模型的方法，通过弱监督对比学习（WCL）增强 semantic信息探索。我们还使用了原始数据的主成分分析（PCA）来本地化物体区域。</li>
<li>results: 我们在一些无监督物体发现数据集上进行了广泛的实验，并证明了我们的提议的有效性。source code和实验结果可以通过我们的项目页面获取：<a target="_blank" rel="noopener" href="https://github.com/npucvr/WSCUOD.git%E3%80%82">https://github.com/npucvr/WSCUOD.git。</a><details>
<summary>Abstract</summary>
Unsupervised object discovery (UOD) refers to the task of discriminating the whole region of objects from the background within a scene without relying on labeled datasets, which benefits the task of bounding-box-level localization and pixel-level segmentation. This task is promising due to its ability to discover objects in a generic manner. We roughly categorise existing techniques into two main directions, namely the generative solutions based on image resynthesis, and the clustering methods based on self-supervised models. We have observed that the former heavily relies on the quality of image reconstruction, while the latter shows limitations in effectively modeling semantic correlations. To directly target at object discovery, we focus on the latter approach and propose a novel solution by incorporating weakly-supervised contrastive learning (WCL) to enhance semantic information exploration. We design a semantic-guided self-supervised learning model to extract high-level semantic features from images, which is achieved by fine-tuning the feature encoder of a self-supervised model, namely DINO, via WCL. Subsequently, we introduce Principal Component Analysis (PCA) to localize object regions. The principal projection direction, corresponding to the maximal eigenvalue, serves as an indicator of the object region(s). Extensive experiments on benchmark unsupervised object discovery datasets demonstrate the effectiveness of our proposed solution. The source code and experimental results are publicly available via our project page at https://github.com/npucvr/WSCUOD.git.
</details>
<details>
<summary>摘要</summary>
无监督物体发现（UOD）指的是在场景中分别背景和物体的整个区域，不使用标注数据，这对绑定框位置和像素级划分具有推动作用。这个任务有前途，因为它可以在通用的方式下发现物体。我们约分exist的技术为两大方向，即基于图像重新synthesis的生成解决方案，以及基于自我超vised模型的聚类方法。我们发现了，前者强调图像重建质量，而后者在模型 semantic关系模型化有限。为直接实现物体发现，我们选择后者，并提出一种新的解决方案，即通过弱监督对比学习（WCL）增强 semantic信息探索。我们设计了一种带有高级 semantic特征的自然语言处理模型，通过练习 DINO 模型的特征编码器，并通过 WCL 进行 fine-tuning。然后，我们引入Principal Component Analysis（PCA）来地址 object 区域。对于无监督物体发现数据集进行了广泛的实验，证明了我们的提议的有效性。项目代码和实验结果可以通过我们的项目页面https://github.com/npucvr/WSCUOD.git获取。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Deep-Learning-in-Sports-Applications-Perception-Comprehension-and-Decision"><a href="#A-Survey-of-Deep-Learning-in-Sports-Applications-Perception-Comprehension-and-Decision" class="headerlink" title="A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision"></a>A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03353">http://arxiv.org/abs/2307.03353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang</li>
<li>for: 这篇论文旨在探讨深度学习在体育性能方面的应用，包括识别、理解和决策等三个方面。</li>
<li>methods: 论文提出了深度学习算法的层次结构，并对现有的数据集进行了综述，同时描述了现有的挑战和未来发展趋势。</li>
<li>results: 论文通过对现有数据集的分析和对深度学习在体育应用的概述，提供了对深度学习在体育性能方面的研究 Referenced.<details>
<summary>Abstract</summary>
Deep learning has the potential to revolutionize sports performance, with applications ranging from perception and comprehension to decision. This paper presents a comprehensive survey of deep learning in sports performance, focusing on three main aspects: algorithms, datasets and virtual environments, and challenges. Firstly, we discuss the hierarchical structure of deep learning algorithms in sports performance which includes perception, comprehension and decision while comparing their strengths and weaknesses. Secondly, we list widely used existing datasets in sports and highlight their characteristics and limitations. Finally, we summarize current challenges and point out future trends of deep learning in sports. Our survey provides valuable reference material for researchers interested in deep learning in sports applications.
</details>
<details>
<summary>摘要</summary>
深度学习有可能对体育表现进行革命性的改变，其应用范围从感知和理解到决策。本文提供了深度学习在体育表现方面的全面评论，主要涵盖三大方面：算法、数据集和虚拟环境，以及挑战。首先，我们介绍了深度学习算法在体育表现中的层次结构，并对它们的优缺点进行比较。其次，我们列出了常用的体育数据集，并将其特点和局限性作出描述。最后，我们summarized current challenges and highlighted future trends of deep learning in sports.本文提供的参考资料有价值，对深度学习在体育应用领域的研究人员非常有帮助。Here's the translation of the text into Traditional Chinese:深度学习有可能对体育表现进行革命性的改变，其应用范围从感知和理解到决策。本文提供了深度学习在体育表现方面的全面评论，主要涵盖三大方面：算法、数据集和虚拟环境，以及挑战。首先，我们介绍了深度学习算法在体育表现中的层次结构，并对它们的优缺点进行比较。其次，我们列出了常用的体育数据集，并将其特点和局限性作出描述。最后，我们summarized current challenges and highlighted future trends of deep learning in sports.本文提供的参考资料有价值，对深度学习在体育应用领域的研究人员非常有帮助。
</details></li>
</ul>
<hr>
<h2 id="Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat"><a href="#Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat" class="headerlink" title="Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat"></a>Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05350">http://arxiv.org/abs/2307.05350</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a></li>
<li>paper_authors: Shantanu Ghosh, Ke Yu, Forough Arabshahi, Kayhan Batmanghelich</li>
<li>for: This paper aims to blur the distinction between post hoc explanation of a Blackbox and constructing interpretable models, by iteratively carving out a mixture of interpretable experts (MoIE) and a residual network.</li>
<li>methods: The paper uses a route, interpret, and repeat approach, starting with a Blackbox and iteratively carving out MoIE and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), while the residual network handles the remaining samples.</li>
<li>results: The extensive experiments show that the approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising performance, (2) identifies the relatively “harder” samples to explain via residuals, (3) outperforms interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目标是将黑盒模型的Post hoc解释与构建可解释模型相分离，通过迭代挖出一个混合型可解释专家（MoIE）和剩余网络。</li>
<li>methods: 论文使用一种路径、解释、重复的方法，从黑盒模型开始，迭代挖出MoIE和剩余网络。每个可解释模型专门处理一部分样本，使用First Order Logic（FOL）进行基本的推理，以解释黑盒模型中的概念。剩余网络处理剩下的样本。</li>
<li>results: 广泛的实验结果表明，该方法（1）通过MoIE无需性能下降，identify一个多样化的实例特定概念集，具有高概念完整性，（2）通过剩余网络处理 harder 的样本，（3）在测试时间 intervención中，与可解释设计模型相比，具有显著的性能优势，（4）修复黑盒模型中学习的短cut。MoIE代码可以在：<a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a> 。<details>
<summary>Abstract</summary>
ML model design either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible and underperforming than their Blackbox variants. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Beginning with a Blackbox, we iteratively carve out a mixture of interpretable experts (MoIE) and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our route, interpret, and repeat approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising in performance, (2) identifies the relatively ``harder'' samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox. The code for MoIE is publicly available at: \url{https://github.com/batmanlab/ICML-2023-Route-interpret-repeat}
</details>
<details>
<summary>摘要</summary>
机器学习模型设计可以从可解释模型或黑盒开始，然后进行后处解释。黑盒模型灵活，但难以解释，而可解释模型具有内置的解释功能。然而，可解释模型需要广泛的机器学习知识，并且通常比其黑盒变体表现不佳。本文旨在融合后处解释和构建可解释模型。从黑盒开始，我们逐渐刻意挖掘一个混合可解释专家（MoIE）和剩下的剩下网络。每个可解释模型专门处理一 subset of samples，并使用首险逻辑（FOL）进行基本的推理，提供黑盒中概念的基本理解。我们通过剩下网络将剩下的样本传递给灵活的剩下网络。我们在这个过程中重复多次，直到所有的可解释模型解释愿望的数据分量。我们的广泛实验表明，我们的路由、解释和重复方法（1）可以通过MoIE无需牺牲性能来获得多样化的实例特有概念，（2）可以通过剩下网络来确定难以解释的样本，（3）在测试时间 intervención中大幅度超越可解释设计模型，以及（4）修复黑盒学习的快捷。MoIE代码可以在以下链接获取：https://github.com/batmanlab/ICML-2023-Route-interpret-repeat
</details></li>
</ul>
<hr>
<h2 id="Open-Vocabulary-Object-Detection-via-Scene-Graph-Discovery"><a href="#Open-Vocabulary-Object-Detection-via-Scene-Graph-Discovery" class="headerlink" title="Open-Vocabulary Object Detection via Scene Graph Discovery"></a>Open-Vocabulary Object Detection via Scene Graph Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03339">http://arxiv.org/abs/2307.03339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengcan Shi, Munawar Hayat, Jianfei Cai</li>
<li>for: 这篇论文是为了解决开放词汇对象检测问题，即不同于传统检测，只检测固定类别对象，而是检测开放类别集中的对象。</li>
<li>methods: 该论文提出了一种新的场景图基于发现网络（SGDN），利用场景图指示来检测开放词汇对象。具体来说，包括稀疏场景图指导注意力（SSGA）的场景图解码器（SGDecoder），以及场景图基于预测（SGPred）机制。</li>
<li>results: 实验结果表明，该方法可以有效地解决开放词汇对象检测问题，并且可以进行开放Scene Graph检测。此外，该方法还可以提高对象本地化的准确率。<details>
<summary>Abstract</summary>
In recent years, open-vocabulary (OV) object detection has attracted increasing research attention. Unlike traditional detection, which only recognizes fixed-category objects, OV detection aims to detect objects in an open category set. Previous works often leverage vision-language (VL) training data (e.g., referring grounding data) to recognize OV objects. However, they only use pairs of nouns and individual objects in VL data, while these data usually contain much more information, such as scene graphs, which are also crucial for OV detection. In this paper, we propose a novel Scene-Graph-Based Discovery Network (SGDN) that exploits scene graph cues for OV detection. Firstly, a scene-graph-based decoder (SGDecoder) including sparse scene-graph-guided attention (SSGA) is presented. It captures scene graphs and leverages them to discover OV objects. Secondly, we propose scene-graph-based prediction (SGPred), where we build a scene-graph-based offset regression (SGOR) mechanism to enable mutual enhancement between scene graph extraction and object localization. Thirdly, we design a cross-modal learning mechanism in SGPred. It takes scene graphs as bridges to improve the consistency between cross-modal embeddings for OV object classification. Experiments on COCO and LVIS demonstrate the effectiveness of our approach. Moreover, we show the ability of our model for OV scene graph detection, while previous OV scene graph generation methods cannot tackle this task.
</details>
<details>
<summary>摘要</summary>
近年来，开放词汇（OV）对象检测已经吸引了越来越多的研究者的注意力。与传统检测不同，OV检测targets不同的开放类别对象。先前的工作frequently使用视觉语言（VL）训练数据（例如，referring grounding data）来认识OV对象。然而，这些数据通常包含更多的信息，例如场景图，这些信息也是OV检测的关键。在本文中，我们提出了一种新的场景图基于发现网络（SGDN），它利用场景图指示进行OV检测。首先，我们提出了场景图基本解码器（SGDecoder），包括稀疏场景图指导的注意力（SSGA）。它捕捉场景图并利用它们来发现OV对象。其次，我们提出了场景图基本预测（SGPred），我们构建了场景图基本偏移预测（SGOR）机制，以便对场景图EXTRACTION和对象LOCALIZATION进行互相增强。最后，我们设计了一种 crossed-modal学习机制。它通过场景图作为桥接，以提高不同模态嵌入的一致性，以便对开放类别对象进行分类。在COCO和LVIS上进行了实验，并证明了我们的方法的有效性。此外，我们还示出了我们的模型对开放场景图检测的能力，而之前的OV场景图生成方法无法完成这个任务。
</details></li>
</ul>
<hr>
<h2 id="Facial-Landmark-Detection-Evaluation-on-MOBIO-Database"><a href="#Facial-Landmark-Detection-Evaluation-on-MOBIO-Database" class="headerlink" title="Facial Landmark Detection Evaluation on MOBIO Database"></a>Facial Landmark Detection Evaluation on MOBIO Database</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03329">http://arxiv.org/abs/2307.03329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Na Zhang</li>
<li>for: 该论文旨在提高移动设备上部署生物特征技术的研究，特别是面部识别和语音识别等技术在移动设备上的应用。</li>
<li>methods: 该论文使用了多种现有的面部特征检测方法，以评估其性能在移动设备上。</li>
<li>results: 研究发现，面部特征检测在移动设备上的性能较为挑战，MOBIO数据库可以作为一个新的挑战数据库。<details>
<summary>Abstract</summary>
MOBIO is a bi-modal database that was captured almost exclusively on mobile phones. It aims to improve research into deploying biometric techniques to mobile devices. Research has been shown that face and speaker recognition can be performed in a mobile environment. Facial landmark localization aims at finding the coordinates of a set of pre-defined key points for 2D face images. A facial landmark usually has specific semantic meaning, e.g. nose tip or eye centre, which provides rich geometric information for other face analysis tasks such as face recognition, emotion estimation and 3D face reconstruction. Pretty much facial landmark detection methods adopt still face databases, such as 300W, AFW, AFLW, or COFW, for evaluation, but seldomly use mobile data. Our work is first to perform facial landmark detection evaluation on the mobile still data, i.e., face images from MOBIO database. About 20,600 face images have been extracted from this audio-visual database and manually labeled with 22 landmarks as the groundtruth. Several state-of-the-art facial landmark detection methods are adopted to evaluate their performance on these data. The result shows that the data from MOBIO database is pretty challenging. This database can be a new challenging one for facial landmark detection evaluation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images"><a href="#CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images" class="headerlink" title="CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images"></a>CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03293">http://arxiv.org/abs/2307.03293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngaggion/chexmask-database">https://github.com/ngaggion/chexmask-database</a></li>
<li>paper_authors: Nicolás Gaggion, Candelaria Mosquera, Lucas Mansilla, Martina Aineseder, Diego H. Milone, Enzo Ferrante</li>
<li>for: 这个论文的目的是为了提供一个大型、多中心的胸部X射线分割数据集，以便用于胸部X射线分析方法的开发。</li>
<li>methods: 这个论文使用了HybridGNet模型来确保所有数据集中的分割结果具有一致性和高质量。</li>
<li>results: 这个论文提供了676,803个分割mask，并通过专业医生评估和自动化质量控制来验证这些mask。 Additionally, the paper provides individualized quality indices per mask and an overall quality estimation per dataset.<details>
<summary>Abstract</summary>
The development of successful artificial intelligence models for chest X-ray analysis relies on large, diverse datasets with high-quality annotations. While several databases of chest X-ray images have been released, most include disease diagnosis labels but lack detailed pixel-level anatomical segmentation labels. To address this gap, we introduce an extensive chest X-ray multi-center segmentation dataset with uniform and fine-grain anatomical annotations for images coming from six well-known publicly available databases: CANDID-PTX, ChestX-ray8, Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in 676,803 segmentation masks. Our methodology utilizes the HybridGNet model to ensure consistent and high-quality segmentations across all datasets. Rigorous validation, including expert physician evaluation and automatic quality control, was conducted to validate the resulting masks. Additionally, we provide individualized quality indices per mask and an overall quality estimation per dataset. This dataset serves as a valuable resource for the broader scientific community, streamlining the development and assessment of innovative methodologies in chest X-ray analysis. The CheXmask dataset is publicly available at: \url{https://physionet.org/content/chexmask-cxr-segmentation-data/}.
</details>
<details>
<summary>摘要</summary>
发展成功人工智能模型 для胸部X射影分析需要大量多样化的数据集，其中包括高质量的注解标注。虽然数据库胸部X射影图像已经发布，但大多数只包含疾病诊断标签，缺乏细腻像素级别的解剖学分割标注。为了解决这个问题，我们介绍了一个广泛的胸部X射影多中心分割数据集，其中包含来自六个公共可用的数据库：CANDID-PTX、ChestX-ray8、Chexpert、MIMIC-CXR-JPG、Padchest和VinDr-CXR，共计676,803个分割mask。我们的方法使用HybridGNet模型来确保分割结果具有一致性和高质量。我们进行了严格的验证，包括专业医生评估和自动化质量控制，以验证结果。此外，我们还提供了每个mask的个性化质量指标以及每个数据集的总质量估计。这个数据集作为科学社区的资源，可以促进胸部X射影分析领域的创新和评估。CheXmask数据集公共可用于：\url{https://physionet.org/content/chexmask-cxr-segmentation-data/}.
</details></li>
</ul>
<hr>
<h2 id="To-pretrain-or-not-to-pretrain-A-case-study-of-domain-specific-pretraining-for-semantic-segmentation-in-histopathology"><a href="#To-pretrain-or-not-to-pretrain-A-case-study-of-domain-specific-pretraining-for-semantic-segmentation-in-histopathology" class="headerlink" title="To pretrain or not to pretrain? A case study of domain-specific pretraining for semantic segmentation in histopathology"></a>To pretrain or not to pretrain? A case study of domain-specific pretraining for semantic segmentation in histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03275">http://arxiv.org/abs/2307.03275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tushar Kataria, Beatrice Knudsen, Shireen Elhabian</li>
<li>for: 这个研究是为了检查 histopathology 领域特有的预训练模型是否能提供更好的初始化，以提高病理学影像应用程序的性能。</li>
<li>methods: 研究使用了不同类型的预训练模型，包括 histopathology 领域特有的预训练模型和 real-world 影像预训练模型，并 Comparing 它们的表现。</li>
<li>results: 研究结果显示，使用 histopathology 领域特有的预训练模型可以提高病理学影像识别和分类的表现，但是这些表现取决于任务和训练数据集的大小。此外，研究也发现使用这些预训练模型可以提高病理学影像中的细胞和腺体分类表现，但是这些表现仅在特定的任务和训练数据集中出现。<details>
<summary>Abstract</summary>
Annotating medical imaging datasets is costly, so fine-tuning (or transfer learning) is the most effective method for digital pathology vision applications such as disease classification and semantic segmentation. However, due to texture bias in models trained on real-world images, transfer learning for histopathology applications might result in underperforming models, which necessitates the need for using unlabeled histopathology data and self-supervised methods to discover domain-specific characteristics. Here, we tested the premise that histopathology-specific pretrained models provide better initializations for pathology vision tasks, i.e., gland and cell segmentation. In this study, we compare the performance of gland and cell segmentation tasks with histopathology domain-specific and non-domain-specific (real-world images) pretrained weights. Moreover, we investigate the dataset size at which domain-specific pretraining produces significant gains in performance. In addition, we investigated whether domain-specific initialization improves the effectiveness of out-of-distribution testing on distinct datasets but the same task. The results indicate that performance gain using domain-specific pretrained weights depends on both the task and the size of the training dataset. In instances with limited dataset sizes, a significant improvement in gland segmentation performance was also observed, whereas models trained on cell segmentation datasets exhibit no improvement.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本为：批注医学影像数据集是成本高的，因此 Fine-tuning（或传输学习）是数字 PATHOLOGY 视觉应用，如疾病分类和semantic segmentation 中最有效的方法。然而，由于图像世界中的 texture bias，传输学习 для histopathology 应用可能会导致模型表现不佳，这种情况下需要使用无标注 histopathology 数据和自我supervised 方法来发现领域特有的特征。本研究检验了假设，即 histopathology 特定的预训练模型为 PATHOLOGY 视觉任务提供更好的初始化，即腺体和细胞 segmentation。本研究 comparing 腺体和细胞 segmentation 任务使用 histopathology 领域特定和非领域特定（实际世界图像）预训练 веса的表现。此外，我们还研究了领域特定预训练生成的性能提升的数据集大小。在这些研究中，我们发现了领域特定预训练在某些任务上的性能提升取决于任务和领域特定预训练数据集的大小。在有限的数据集大小下，领域特定预训练可以获得显著的性能提升，而模型在 cell segmentation 任务上表现不变。Translation:<<SYS>>输入文本为：批注医学影像数据集是成本高的，因此 Fine-tuning（或传输学习）是数字 PATHOLOGY 视觉应用，如疾病分类和semantic segmentation 中最有效的方法。然而，由于图像世界中的 texture bias，传输学习 для histopathology 应用可能会导致模型表现不佳，这种情况下需要使用无标注 histopathology 数据和自我supervised 方法来发现领域特有的特征。本研究检验了假设，即 histopathology 特定的预训练模型为 PATHOLOGY 视觉任务提供更好的初始化，即腺体和细胞 segmentation。本研究 comparing 腺体和细胞 segmentation 任务使用 histopathology 领域特定和非领域特定（实际世界图像）预训练 веса的表现。此外，我们还研究了领域特定预训练生成的性能提升的数据集大小。在这些研究中，我们发现了领域特定预训练在某些任务上的性能提升取决于任务和领域特定预训练数据集的大小。在有限的数据集大小下，领域特定预训练可以获得显著的性能提升，而模型在 cell segmentation 任务上表现不变。
</details></li>
</ul>
<hr>
<h2 id="ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images"><a href="#ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images" class="headerlink" title="ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images"></a>ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03273">http://arxiv.org/abs/2307.03273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mokshagna Sai Teja Karanam, Tushar Kataria, Krithika Iyer, Shireen Elhabian</li>
<li>for: 这篇论文旨在提出一种新的数据增强策略，以适应图像到统计形态模型（SSM）框架中的数据缺乏问题。</li>
<li>methods: 该策略基于数据依存的噪声生成或文本增强技术，通过在图像到SSM网络中作为对手训练，生成多样化和挑战性的噪声样本。</li>
<li>results: 该策略可以提高图像到SSM网络的准确率，使模型更加注重下面形态，而不是固定在像素值上。<details>
<summary>Abstract</summary>
Statistical shape models (SSM) have been well-established as an excellent tool for identifying variations in the morphology of anatomy across the underlying population. Shape models use consistent shape representation across all the samples in a given cohort, which helps to compare shapes and identify the variations that can detect pathologies and help in formulating treatment plans. In medical imaging, computing these shape representations from CT/MRI scans requires time-intensive preprocessing operations, including but not limited to anatomy segmentation annotations, registration, and texture denoising. Deep learning models have demonstrated exceptional capabilities in learning shape representations directly from volumetric images, giving rise to highly effective and efficient Image-to-SSM networks. Nevertheless, these models are data-hungry and due to the limited availability of medical data, deep learning models tend to overfit. Offline data augmentation techniques, that use kernel density estimation based (KDE) methods for generating shape-augmented samples, have successfully aided Image-to-SSM networks in achieving comparable accuracy to traditional SSM methods. However, these augmentation methods focus on shape augmentation, whereas deep learning models exhibit image-based texture bias resulting in sub-optimal models. This paper introduces a novel strategy for on-the-fly data augmentation for the Image-to-SSM framework by leveraging data-dependent noise generation or texture augmentation. The proposed framework is trained as an adversary to the Image-to-SSM network, augmenting diverse and challenging noisy samples. Our approach achieves improved accuracy by encouraging the model to focus on the underlying geometry rather than relying solely on pixel values.
</details>
<details>
<summary>摘要</summary>
各种统计形态模型（SSM）在识别人体解剖学变化方面已经得到了广泛的应用，它们使用一致的形态表示方式来比较形态，从而检测疾病和制定治疗方案。在医疗影像中，从CT/MRI扫描获取形态表示需要耗时的预处理步骤，包括但不限于解剖部分标注、注册和图像减震。深度学习模型直接从三维图像中学习形态表示，这些模型已经取得了非常高效和可靠的成果，并且被称为高效的图像-SSM网络。然而，这些模型需要大量的数据，由于医疗数据的有限性，这些模型往往遇到过拟合问题。在线数据增强技术，使用基于KDE方法生成的形态增强样本，已经成功地帮助图像-SSM网络实现与传统SSM方法相当的准确性。然而，这些增强技术主要关注形态增强，而深度学习模型具有图像基于的文本偏好，导致模型表现不佳。本文提出了一种新的在线数据增强策略，通过利用数据依赖的噪声生成或文本增强来帮助图像-SSM网络。该方法在训练过程中作为对图像-SSM网络的反对手，生成多样化和挑战性的噪声样本，以提高模型的准确性。我们的方法通过让模型关注下面的结构，而不是仅仅依赖像素值，从而提高模型的表现。
</details></li>
</ul>
<hr>
<h2 id="Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging"><a href="#Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging" class="headerlink" title="Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging"></a>Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03266">http://arxiv.org/abs/2307.03266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heejong Kim, Victor Ion Butoi, Adrian V. Dalca, Daniel J. A. Margolis, Mert R. Sabuncu<br>for:This paper is written for the purpose of evaluating the effectiveness of a foundation model for medical image segmentation, specifically in the context of prostate imaging.methods:The paper uses a recently developed foundation model called UniverSeg, which is trained on a large dataset of images and can be customized for various downstream tasks with little to no labeled data.results:The paper compares the performance of UniverSeg against conventional task-specific segmentation models and highlights several important factors that will likely be important in the development and adoption of foundation models for medical image segmentation. The results show that UniverSeg achieves competitive performance against task-specific models while requiring significantly less labeled data.<details>
<summary>Abstract</summary>
Most state-of-the-art techniques for medical image segmentation rely on deep-learning models. These models, however, are often trained on narrowly-defined tasks in a supervised fashion, which requires expensive labeled datasets. Recent advances in several machine learning domains, such as natural language generation have demonstrated the feasibility and utility of building foundation models that can be customized for various downstream tasks with little to no labeled data. This likely represents a paradigm shift for medical imaging, where we expect that foundation models may shape the future of the field. In this paper, we consider a recently developed foundation model for medical image segmentation, UniverSeg. We conduct an empirical evaluation study in the context of prostate imaging and compare it against the conventional approach of training a task-specific segmentation model. Our results and discussion highlight several important factors that will likely be important in the development and adoption of foundation models for medical image segmentation.
</details>
<details>
<summary>摘要</summary>
现代医疗影像分割技术多数采用深度学习模型。然而，这些模型通常需要严格定义的任务和质量验证数据，这会导致成本增加。在其他机器学习领域，如自然语言生成，最近的进展表明可以建立基础模型，可以通过少量或无标注数据来适应多个下游任务。这可能会对医疗影像领域造成一种 парадигShift。在这篇论文中，我们考虑了一种新发展的基础模型，即UniverSeg。我们对抗比较这种基础模型与专门为医疗影像分割训练的模型。我们的结果和讨论描述了一些重要的因素，这些因素将影响基础模型在医疗影像分割领域的发展和采纳。
</details></li>
</ul>
<hr>
<h2 id="A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia"><a href="#A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia" class="headerlink" title="A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia"></a>A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03757">http://arxiv.org/abs/2307.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam J Shephard, Raja Muhammad Saad Bashir, Hanya Mahmood, Mostafa Jahanifar, Fayyaz Minhas, Shan E Ahmed Raza, Kris D McCombe, Stephanie G Craig, Jacqueline James, Jill Brooks, Paul Nankivell, Hisham Mehanna, Syed Ali Khurram, Nasir M Rajpoot</li>
<li>for: 预防唾液腺癌的诊断和预测</li>
<li>methods: 使用人工智能算法，基于历史Patterns in Haematoxylin and Eosin染色整个扫描图像中的核lei，分配唾液腺癌转化风险分数（OMT分数），以衡量唾液腺癌的转化风险。</li>
<li>results: 在内部十进制验证集（Sheffield）和两个外部验证集（Birmingham和Belfast）上，提出了一个AUROC &#x3D; 0.74的预测模型，可以预测唾液腺癌是否会转化为癌症。此外，存在证明了OMT分数的诊断价值，并且在预测转化过程中发现了 péripheral和epithelium-infiltrating免疫细胞的存在。<details>
<summary>Abstract</summary>
Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis given to lesions of the oral cavity. Its grading suffers from significant inter-/intra- observer variability, and does not reliably predict malignancy progression, potentially leading to suboptimal treatment decisions. To address this, we developed a novel artificial intelligence algorithm that can assign an Oral Malignant Transformation (OMT) risk score, based on histological patterns in the in Haematoxylin and Eosin stained whole slide images, to quantify the risk of OED progression. The algorithm is based on the detection and segmentation of nuclei within (and around) the epithelium using an in-house segmentation model. We then employed a shallow neural network fed with interpretable morphological/spatial features, emulating histological markers. We conducted internal cross-validation on our development cohort (Sheffield; n = 193 cases) followed by independent validation on two external cohorts (Birmingham and Belfast; n = 92 cases). The proposed OMTscore yields an AUROC = 0.74 in predicting whether an OED progresses to malignancy or not. Survival analyses showed the prognostic value of our OMTscore for predicting malignancy transformation, when compared to the manually-assigned WHO and binary grades. Analysis of the correctly predicted cases elucidated the presence of peri-epithelial and epithelium-infiltrating lymphocytes in the most predictive patches of cases that transformed (p < 0.0001). This is the first study to propose a completely automated algorithm for predicting OED transformation based on interpretable nuclear features, whilst being validated on external datasets. The algorithm shows better-than-human-level performance for prediction of OED malignant transformation and offers a promising solution to the challenges of grading OED in routine clinical practice.
</details>
<details>
<summary>摘要</summary>
口腔质变性病（OED）是口腔腺肿的先癌诊断，但其分级受到许多内外观察员的变化带来不确定性，并不能准确预测肿瘤转化，可能导致不佳的治疗决策。为解决这个问题，我们开发了一种新的人工智能算法，可以基于口腔染色涂抹整个扫描图像中的历史学特征，分配口腔肿瘤转化风险分数（OMT分数）。该算法基于识别和分割细胞核的自己 segmentation 模型，然后使用一个浅层神经网络，以便模拟历史学特征。我们在 Sheffield 开发团队（n = 193 例）进行了内部十字验证，然后在 Birmingham 和 Belfast 两个外部团队（n = 92 例）进行了独立验证。我们的提议的 OMT 分数可以在预测口腔肿瘤转化是否发生的问题上达到 AUROC = 0.74 的表现。 survival 分析表明我们的 OMT 分数具有预测肿瘤转化的诊断价值，比 manually-assigned WHO 和二分阶段的分数更高。分析正确预测的 случа件表明，在转化的 случа件中存在辐射性和 epithelium 滥入的 T 细胞，这些特征在最预测性的补丁中具有显著性（p < 0.0001）。这是首次提出一种完全自动化的 OED 转化预测算法，基于可读性的核型特征，并在外部数据集上进行了验证。该算法在预测 OED 肿瘤转化的问题上达到了人类水平以上的表现，并且提供了一个有前途的解决方案，以便在日常临床医学实践中改善 OED 的分级。
</details></li>
</ul>
<hr>
<h2 id="PSDR-Room-Single-Photo-to-Scene-using-Differentiable-Rendering"><a href="#PSDR-Room-Single-Photo-to-Scene-using-Differentiable-Rendering" class="headerlink" title="PSDR-Room: Single Photo to Scene using Differentiable Rendering"></a>PSDR-Room: Single Photo to Scene using Differentiable Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03244">http://arxiv.org/abs/2307.03244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Yan, Fujun Luan, MiloŠ HaŠAn, Thibault Groueix, Valentin Deschaintre, Shuang Zhao</li>
<li>for: 用于快速匹配目标图像中的室内场景，需要艺术和技术素养。</li>
<li>methods: 使用最新的路径空间可微 Rendering 方法，通过Gradient Descent 优化灯光和物体姿态，以及材质等参数，以达到视觉匹配目标图像。</li>
<li>results: 可以使用单张图像场景理解方法来初始化优化，并搜索适当的3D模型和材质。实验表明，方法可以 editing 室内场景中的各种元素。Here’s the translation in English for reference:</li>
<li>for: Designed to quickly match the appearance of a target image of an indoor scene, requiring both artistic and technical skills.</li>
<li>methods: Leveraging a recent path-space differentiable rendering approach to provide unbiased gradients of the rendering with respect to geometry, lighting, and procedural materials, allowing for optimization of all these components using gradient descent to visually match the input photo appearance.</li>
<li>results: Can use recent single-image scene understanding methods to initialize the optimization and search for appropriate 3D models and materials. Experimental results demonstrate the editability of the resulting scene components.<details>
<summary>Abstract</summary>
A 3D digital scene contains many components: lights, materials and geometries, interacting to reach the desired appearance. Staging such a scene is time-consuming and requires both artistic and technical skills. In this work, we propose PSDR-Room, a system allowing to optimize lighting as well as the pose and materials of individual objects to match a target image of a room scene, with minimal user input. To this end, we leverage a recent path-space differentiable rendering approach that provides unbiased gradients of the rendering with respect to geometry, lighting, and procedural materials, allowing us to optimize all of these components using gradient descent to visually match the input photo appearance. We use recent single-image scene understanding methods to initialize the optimization and search for appropriate 3D models and materials. We evaluate our method on real photographs of indoor scenes and demonstrate the editability of the resulting scene components.
</details>
<details>
<summary>摘要</summary>
一幅3D数字场景包含多个组件：灯光、材料和几何体，这些组件相互交互以达到所需的外观。设置这种场景是时间consuming的，需要艺术和技术技巧。在这种工作中，我们提议PSDR-Room，一个系统，允许用户最小化输入来优化灯光和个体物体的 pose 和材料，以匹配目标图像中的房间场景的外观，并且可以通过梯度 descent来优化这些组件。我们利用最近的路径空间微分渲染方法，以获取不偏梯度图像渲染中的geometry、灯光和材料的梯度，这些梯度可以用于优化这些组件。我们使用最近的单图像场景理解方法来初始化优化和搜索适合的3D模型和材料。我们对实际拍摄的室内场景照片进行评估，并证明可以编辑场景中的组件。
</details></li>
</ul>
<hr>
<h2 id="That’s-BAD-Blind-Anomaly-Detection-by-Implicit-Local-Feature-Clustering"><a href="#That’s-BAD-Blind-Anomaly-Detection-by-Implicit-Local-Feature-Clustering" class="headerlink" title="That’s BAD: Blind Anomaly Detection by Implicit Local Feature Clustering"></a>That’s BAD: Blind Anomaly Detection by Implicit Local Feature Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03243">http://arxiv.org/abs/2307.03243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Masanori Suganuma, Takayuki Okatani</li>
<li>for: 这篇论文探讨了无监督的工业物体&#x2F;文瑞异常探测（AD），并提出了一个更加具有挑战性的无监督AD设定，即在一个给定的图像集中探测异常 sample，这个设定不需要人工标注，与过去的研究不同。</li>
<li>methods: 我们提出了一个名为PatchCluster的 novel方法，将这个问题转换为一个本地异常探测问题，并使用了一个新的分割方法来检测图像和像素层次的异常 sample。</li>
<li>results: 实验结果显示，PatchCluster在没有知情normal数据的情况下可以实现高度的异常探测性能，甚至与需要知情normal数据的SOTA方法相比。<details>
<summary>Abstract</summary>
Recent studies on visual anomaly detection (AD) of industrial objects/textures have achieved quite good performance. They consider an unsupervised setting, specifically the one-class setting, in which we assume the availability of a set of normal (\textit{i.e.}, anomaly-free) images for training. In this paper, we consider a more challenging scenario of unsupervised AD, in which we detect anomalies in a given set of images that might contain both normal and anomalous samples. The setting does not assume the availability of known normal data and thus is completely free from human annotation, which differs from the standard AD considered in recent studies. For clarity, we call the setting blind anomaly detection (BAD). We show that BAD can be converted into a local outlier detection problem and propose a novel method named PatchCluster that can accurately detect image- and pixel-level anomalies. Experimental results show that PatchCluster shows a promising performance without the knowledge of normal data, even comparable to the SOTA methods applied in the one-class setting needing it.
</details>
<details>
<summary>摘要</summary>
最近的图像异常检测研究（AD）已经达到了非常好的性能。它们假设了一个无监督的设置，具体是一个一类设置，在这里我们假设了一组正常（即异常free）图像用于训练。在这篇论文中，我们考虑了更加具有挑战性的无监督AD场景，在这里我们检测图像中的异常 sample，这些图像可能包含正常和异常样本。这个设置不需要人类注释，与标准的AD不同。为了便于描述，我们称之为盲目异常检测（BAD）。我们表明了BAD可以转化为本地异常检测问题，并提出了一种名为PatchCluster的新方法，可以准确地检测图像和像素级异常。实验结果表明，PatchCluster在没有正常数据知识的情况下可以达到高度的性能，甚至与需要正常数据的SOTA方法相当。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Generation-of-Privileged-Intermediate-Information-for-Visible-Infrared-Person-Re-Identification"><a href="#Adaptive-Generation-of-Privileged-Intermediate-Information-for-Visible-Infrared-Person-Re-Identification" class="headerlink" title="Adaptive Generation of Privileged Intermediate Information for Visible-Infrared Person Re-Identification"></a>Adaptive Generation of Privileged Intermediate Information for Visible-Infrared Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03240">http://arxiv.org/abs/2307.03240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Alehdaghi, Arthur Josi, Pourya Shamsolmoali, Rafael M. O. Cruz, Eric Granger</li>
<li>for: 本研究的目的是提高Visible-infrared人识别（V-I ReID）的精度，通过在RGB和IR感知器上建立一个共享表征空间，以便在不同感知器上捕捉到同一个人的图像。</li>
<li>methods: 本研究提出了一种名为Adaptive Generation of Privileged Intermediate Information（AGPI^2）的训练方法，用于生成一个虚拟频谱域，以bridging V和I模式之间的数据分布差异。AGPI^2使用非线性生成模块和嵌入模块，通过对RGB图像进行非线性变换，生成一个中间频谱域中的图像，并且使得这些中间图像具有较小的频谱域差异。</li>
<li>results: 实验结果表明，AGPI^2可以提高V-I ReID的匹配精度，而无需额外的计算资源在推理过程中。<details>
<summary>Abstract</summary>
Visible-infrared person re-identification seeks to retrieve images of the same individual captured over a distributed network of RGB and IR sensors. Several V-I ReID approaches directly integrate both V and I modalities to discriminate persons within a shared representation space. However, given the significant gap in data distributions between V and I modalities, cross-modal V-I ReID remains challenging. Some recent approaches improve generalization by leveraging intermediate spaces that can bridge V and I modalities, yet effective methods are required to select or generate data for such informative domains. In this paper, the Adaptive Generation of Privileged Intermediate Information training approach is introduced to adapt and generate a virtual domain that bridges discriminant information between the V and I modalities. The key motivation behind AGPI^2 is to enhance the training of a deep V-I ReID backbone by generating privileged images that provide additional information. These privileged images capture shared discriminative features that are not easily accessible within the original V or I modalities alone. Towards this goal, a non-linear generative module is trained with an adversarial objective, translating V images into intermediate spaces with a smaller domain shift w.r.t. the I domain. Meanwhile, the embedding module within AGPI^2 aims to produce similar features for both V and generated images, encouraging the extraction of features that are common to all modalities. In addition to these contributions, AGPI^2 employs adversarial objectives for adapting the intermediate images, which play a crucial role in creating a non-modality-specific space to address the large domain shifts between V and I domains. Experimental results conducted on challenging V-I ReID datasets indicate that AGPI^2 increases matching accuracy without extra computational resources during inference.
</details>
<details>
<summary>摘要</summary>
visible-infrared人识别方法目的是检索RGB和IR感知器上捕捉的同一个人的图像。一些V-I ReID方法直接将V和I模式集成到共同表示空间中，但由于V和I模式的数据分布差距较大，跨模式V-I ReID仍然是一个挑战。一些最近的方法利用中间空间来bridge V和I模式，但需要有效的数据选择或生成方法。在这篇论文中，我们提出了适应生成特权中间信息训练方法（AGPI^2），用于适应和生成一个可以bridge V和I模式之间的虚拟频谱。我们的关键想法是通过生成特权图像来增强深度V-I ReID背景模型的训练，这些特权图像包含共享特征信息，这些信息在原始V或I模式中很难访问。为了实现这一目标，我们在AGPI^2中训练了一个非线性生成模块，通过对V图像进行非线性映射，将其转换为中间空间中的一个更小的频谱差距。同时， embedding模块在AGPI^2中尝试生成V和生成图像之间的相似特征，以便提取这些特征是所有模式共享的。此外，AGPI^2还使用了对中间图像的对抗目标，这些目标在创建一个不受模式限制的空间中扮演了关键的角色，以Addressing the large domain shift between V and I domains。实验结果表明，AGPI^2可以提高匹配精度，不需要额外的计算资源在推理过程中。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Artistic-Cinemagraphs-from-Text"><a href="#Synthesizing-Artistic-Cinemagraphs-from-Text" class="headerlink" title="Synthesizing Artistic Cinemagraphs from Text"></a>Synthesizing Artistic Cinemagraphs from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03190">http://arxiv.org/abs/2307.03190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/text2cinemagraph/text2cinemagraph">https://github.com/text2cinemagraph/text2cinemagraph</a></li>
<li>paper_authors: Aniruddha Mahapatra, Aliaksandr Siarohin, Hsin-Ying Lee, Sergey Tulyakov, Jun-Yan Zhu</li>
<li>for: 这个论文是为了创建基于文本描述的电影场景（电影场景）的自动化方法。</li>
<li>methods: 该方法使用了图像双生技术，从单个文本提示中生成一对图像：一个艺术性的图像和一个自然looking的图像。该艺术性图像描绘文本提示中的风格和外观，而自然looking图像简化了布局和动作分析。然后，通过使用现有的自然图像和视频数据集，准确地分割自然looking图像并预测可能的动作，并将这些动作传递给艺术性图像来创建最终的电影场景。</li>
<li>results: 该方法比现有的方法在创建电影场景时表现出色，特别是在自然风景和艺术性场景以及其他世界的场景中。这被证明了通过自动化指标和用户研究。此外，该方法还可以用于动画现有的画作，以及通过文本控制动作方向。<details>
<summary>Abstract</summary>
We introduce Text2Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images. Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static. To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin. While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis. Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information. The predicted motion can then be transferred to the artistic image to create the final cinemagraph. Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies. Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text.
</details>
<details>
<summary>摘要</summary>
我们介绍Text2Cinemagraph，一种完全自动的方法，可以将文本描述转化成动画照片 - 特别是当提示中包含想象力和艺术风格时，这是一项非常具有挑战性的任务，因为解决含义和动作的含义需要进行复杂的解释。现有的单张图像动画方法在艺术输入下表现不佳，而最近的文本基于视频方法经常出现时间不一致，尝试维持某些区域静止。为解决这些挑战，我们提出了一个合成文本描述中的图像双胞胎的想法 - 一对一个艺术风格和自然风格相似的图像对。而艺术图像将文本中的风格和形象细节呈现出来，而自然图像则大大简化了布局和动作分析。利用现有的自然图像和视频数据集，我们可以准确地分割自然图像，并预测文本中的Semantic信息所决定的合理动作。然后将预测的动作转移到艺术图像中，以创建最终的动画照片。我们的方法在创建自然风景以及艺术和其他世界的场景中的动画照片方面表现出色，并经过自动度量和用户测试 Validation。最后，我们还展示了两个扩展：将现有的画作动画和通过文本控制动作方向。
</details></li>
</ul>
<hr>
<h2 id="IPO-LDM-Depth-aided-360-degree-Indoor-RGB-Panorama-Outpainting-via-Latent-Diffusion-Model"><a href="#IPO-LDM-Depth-aided-360-degree-Indoor-RGB-Panorama-Outpainting-via-Latent-Diffusion-Model" class="headerlink" title="IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model"></a>IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03177">http://arxiv.org/abs/2307.03177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianhao Wu, Chuanxia Zheng, Tat-Jen Cham</li>
<li>for: 这篇论文的目的是创建高质量的360度RGB投影图，并使用Latent Diffusion Models（LDM）来实现。</li>
<li>methods: 这篇论文使用了一种新的双模态潜在扩散结构，该结构在训练时使用RGB和深度投影数据，但在推理时可以使用 нормаль的深度值。此外，论文还提出了一种进步的摄像头旋转技术，以提高投影图的绕ounding一致性。</li>
<li>results: 论文的IPO-LDM模型不仅在RGB投影图外绘制方面具有显著的优势，还可以生成多种不同类型的面孔，并且每个面孔具有良好的结构。<details>
<summary>Abstract</summary>
Generating complete 360-degree panoramas from narrow field of view images is ongoing research as omnidirectional RGB data is not readily available. Existing GAN-based approaches face some barriers to achieving higher quality output, and have poor generalization performance over different mask types. In this paper, we present our 360-degree indoor RGB panorama outpainting model using latent diffusion models (LDM), called IPO-LDM. We introduce a new bi-modal latent diffusion structure that utilizes both RGB and depth panoramic data during training, but works surprisingly well to outpaint normal depth-free RGB images during inference. We further propose a novel technique of introducing progressive camera rotations during each diffusion denoising step, which leads to substantial improvement in achieving panorama wraparound consistency. Results show that our IPO-LDM not only significantly outperforms state-of-the-art methods on RGB panorama outpainting, but can also produce multiple and diverse well-structured results for different types of masks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将宽角度图像转换为全景360度图像是当前研究的热点问题，因为无法直接获得全景RGB数据。现有的基于GAN的方法具有较差的输出质量和不同掩码类型的泛化性能。在本文中，我们提出了一种基于缓动扩散模型（LDM）的360度室内RGB全景抹雷模型，称之为IPO-LDM。我们在训练时使用了RGB和深度全景数据的双模态缓动扩散结构，但在推理时可以使用depth-freeRGB图像进行抹雷。我们还提出了在每个扩散推净步中逐渐添加摄像头旋转的技术，这会导致全景包袋的实现。结果表明，我们的IPO-LDM不仅可以明显超越当前状态的RGB全景抹雷方法，还可以生成多种不同类型的掩码下的多个高质量结构。
</details></li>
</ul>
<hr>
<h2 id="VideoGLUE-Video-General-Understanding-Evaluation-of-Foundation-Models"><a href="#VideoGLUE-Video-General-Understanding-Evaluation-of-Foundation-Models" class="headerlink" title="VideoGLUE: Video General Understanding Evaluation of Foundation Models"></a>VideoGLUE: Video General Understanding Evaluation of Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03166">http://arxiv.org/abs/2307.03166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangzhe Yuan, Nitesh Bharadwaj Gundavarapu, Long Zhao, Hao Zhou, Yin Cui, Lu Jiang, Xuan Yang, Menglin Jia, Tobias Weyand, Luke Friedman, Mikhail Sirotenko, Huisheng Wang, Florian Schroff, Hartwig Adam, Ming-Hsuan Yang, Ting Liu, Boqing Gong</li>
<li>for: 本研究用于评估现有基础模型（Foundation Model，FM）在视频理解任务上的能力，并提出一种简单的 VideoGLUE 分数（VGS）来衡量 FM 在适应通用视频理解任务时的效果和效率。</li>
<li>methods: 本研究使用了三项hallmark task（行动识别、时间Localization和空间时间Localization）、八个社区广泛接受的数据集，以及四种适应基础模型的方法进行研究。</li>
<li>results: 主要发现结果包括：一、任务特化模型在六个FM studied 的情况下表现出色，与自然语言和图像理解领域中FM的表现形成鲜明的对比；二、视频本地FM在分析动态视频时表现更好，特别是在时间地址和多个动作理解方面；三、视频本地FM可以在轻量适应下（例如冻结FM干部）完成视频任务，而图像本地FM则在全面练习下表现较好。<details>
<summary>Abstract</summary>
We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task. Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks. Our main findings are as follows. First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs.
</details>
<details>
<summary>摘要</summary>
我们使用了一个仔细设计的实验协议来评估现有基础模型（FM）的视频理解能力，包括三项标志性任务（动作识别、时间地址和空间时间地址）、八个社区广泛接受的数据集，以及四种适应方法为基础模型进行下游任务的调整。此外，我们提出了一个名为视频GLUE分数（VGS）的scalar来衡量基础模型在普通视频理解任务上的效果和效率。我们的主要发现包括以下几点：首先，任务特化的模型在我们所研究的六个FM中显著超越了其他模型，这与自然语言和图像理解领域中FM的表现形成鲜明的对比。其次，视频本地FM，即在预训练数据中包含视频模式的FM，在分析动作丰富视频、时间地址动作和视频中的多个动作方面表现更好。最后，视频本地FM可以通过轻度适应下游任务（例如冻结FM的背bone）来达到良好的视频任务性能，而图像本地FM则在全面练习下达到更好的性能。这三个发现表明了视频关注FM的研究需求和机遇，以及任务和适应方法对FM的评估的重要性。
</details></li>
</ul>
<hr>
<h2 id="Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification"><a href="#Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification" class="headerlink" title="Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?"></a>Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03157">http://arxiv.org/abs/2307.03157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janet Wang, Yunbei Zhang, Zhengming Ding, Jihun Hamm</li>
<li>for: 本研究旨在 investigate 多个皮肤病变数据集中的无监督领域适应（UDA）方法在 binary 和多类皮肤病变分类中的可行性。</li>
<li>methods: 我们使用了单源、合并源和多源的 UDA 训练方案，以解决皮肤病变分类中的数据不均衡问题。</li>
<li>results: 我们的实验结果表明，UDA 可以有效地在 binary 分类任务中，并且可以减轻数据不均衡问题。在多类分类任务中，UDA 的性能较弱，需要特别处理数据不均衡问题以达到上乘基eline的准确率。此外，我们发现 Label Shift 对测试错误强相关，而Feature-level UDA 方法在处理不均衡数据集时存在限制。最后，我们发现 UDA 可以有效地减少对少数群体的偏见，无需显式使用 fairness-focused 技术。<details>
<summary>Abstract</summary>
Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant. However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system. In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification. In particular, we assess three UDA training schemes: single-, combined-, and multi-source. Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated. In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy. Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets. Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MultiVENT-Multilingual-Videos-of-Events-with-Aligned-Natural-Text"><a href="#MultiVENT-Multilingual-Videos-of-Events-with-Aligned-Natural-Text" class="headerlink" title="MultiVENT: Multilingual Videos of Events with Aligned Natural Text"></a>MultiVENT: Multilingual Videos of Events with Aligned Natural Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03153">http://arxiv.org/abs/2307.03153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kate Sanders, David Etter, Reno Kriz, Benjamin Van Durme</li>
<li>for: 这个论文的目的是构建一个多语言、事件中心视频集合（MultiVENT），以便使用这些视频教学模型受益于现代新闻报道的多样化表达方式。</li>
<li>methods: 该论文使用了多种方法，包括构建多语言、事件中心视频集合（MultiVENT）、分析在线新闻视频的状况以及如何使用这些视频建立准确、多语言的模型。</li>
<li>results: 该论文提供了一个基线模型 для复杂、多语言视频检索，以便使用MultiVENT进行信息检索。<details>
<summary>Abstract</summary>
Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage. Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages. MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models. Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.
</details>
<details>
<summary>摘要</summary>
每天新闻报道很多样化，从传统广播转向多种形式的直播视频。现有的新闻视频数据集都是为英语观众制作的传统新闻广播，我们解决这个局限性的问题，构建了MultiVENT数据集，包含多种语言的事件中心视频和文档。MultiVENT包括新闻广播视频和非专业事件录像，我们通过分析在线新闻视频的状况，探讨如何使用MultiVENT建立强大、准确的模型。最后，我们提供了一种复杂的多语言视频检索模型，作为MultiVENT中的基线模型。
</details></li>
</ul>
<hr>
<h2 id="Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images"><a href="#Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images" class="headerlink" title="Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images"></a>Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03137">http://arxiv.org/abs/2307.03137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seher Ozcelik, Sinan Unver, Ilke Ali Gurses, Rustu Turkay, Cigdem Gunduz-Demir</li>
<li>for: 这个论文是为了解决基于计算机 Tomatoes（CT）图像中血管和大动脉的分割问题。</li>
<li>methods: 这个论文使用了一种新的topology-aware损失函数，该函数通过 persist  homology 来衡量预测和真实值之间的拓扑不同。</li>
<li>results: 实验表明，使用该损失函数可以获得更好的结果， indicating 该方法的有效性。<details>
<summary>Abstract</summary>
Segmentation networks are not explicitly imposed to learn global invariants of an image, such as the shape of an object and the geometry between multiple objects, when they are trained with a standard loss function. On the other hand, incorporating such invariants into network training may help improve performance for various segmentation tasks when they are the intrinsic characteristics of the objects to be segmented. One example is segmentation of aorta and great vessels in computed tomography (CT) images where vessels are found in a particular geometry in the body due to the human anatomy and they mostly seem as round objects on a 2D CT image. This paper addresses this issue by introducing a new topology-aware loss function that penalizes topology dissimilarities between the ground truth and prediction through persistent homology. Different from the previously suggested segmentation network designs, which apply the threshold filtration on a likelihood function of the prediction map and the Betti numbers of the ground truth, this paper proposes to apply the Vietoris-Rips filtration to obtain persistence diagrams of both ground truth and prediction maps and calculate the dissimilarity with the Wasserstein distance between the corresponding persistence diagrams. The use of this filtration has advantage of modeling shape and geometry at the same time, which may not happen when the threshold filtration is applied. Our experiments on 4327 CT images of 24 subjects reveal that the proposed topology-aware loss function leads to better results than its counterparts, indicating the effectiveness of this use.
</details>
<details>
<summary>摘要</summary>
Segmentation 网络不会显式地学习图像中全局不变量，如物体形状和多个物体之间的几何关系，当它们在标准损失函数下训练时。然而，将这些不变量 incorporated 到网络训练中可能会提高不同的 segmentation 任务的性能，因为它们是物体被分 segmentation 的内在特征。例如，在计算机断层成像（CT）图像中分割血管和大血管，血管在人体 анаatomy 中具有特定的几何结构，在2D CT 图像上通常看起来是圆形的物体。这篇论文解决这个问题，通过引入一种新的 topology-aware 损失函数， penalty  topology 异常 между真实值和预测值通过不变式 homology。与之前的 segmentation 网络设计不同，这篇论文提议使用 Vietoris-Rips 滤波来获取 both ground truth 和预测图像的 persistence 图，并计算它们之间的 Wasserstein 距离。这种 filtration 的优点在于同时模型形状和几何，这可能不会在应用 threshold 滤波时发生。我们在 4327 CT 图像上进行了 24 个人的实验，发现提议的 topology-aware 损失函数比其他方法更有效，这表明该用法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification"><a href="#Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification" class="headerlink" title="Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification"></a>Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03133">http://arxiv.org/abs/2307.03133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuyongcan/benchmark-tta">https://github.com/yuyongcan/benchmark-tta</a></li>
<li>paper_authors: Yongcan Yu, Lijun Sheng, Ran He, Jian Liang</li>
<li>for: 本研究旨在提供一个可靠的测试时适应（TTA）方法评估 benchmark，以便研究人员和实践者可以准确地评估和比较不同的 TTA 方法在改进模型的Robustness和泛化性能方面的效果。</li>
<li>methods: 本研究评估了 13 种知名的 TTA 方法和其变种，并在 five 个广泛使用的图像分类 datasets（CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home）上进行了系统性的评估。这些方法包括不同的适应enario（如在线适应 versus 离线适应、实例适应 versus 批量适应 versus 频率适应）。此外，我们还探索了不同的 TTA 方法与不同的网络后处理器之间的兼容性。</li>
<li>results: 我们的研究发现，不同的 TTA 方法在不同的预测场景下的效果有所不同。 Specifically, we found that some methods perform better in certain scenarios, while others may not be as effective. Additionally, we observed that some methods are more compatible with certain network backbones than others. Our findings provide valuable insights into the strengths and limitations of different TTA methods and can help guide future research in this area.<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.
</details>
<details>
<summary>摘要</summary>
测试时适应（TTA）是一种技术，旨在通过使用无标示样本来提高模型的总体性表现。由于神经网络系统面临到分布转移时的稳定性问题，有很多TTA方法被提出。然而，评估这些方法的时候通常采用不同的设置，例如不同的分布转移、后端和设计方案，这导致了评估效果的不一致和公平性的问题。为解决这个问题，我们提出了一个基准，系统地评估13种知名TTA方法和其变体在五种广泛使用的图像分类dataset上：CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home。这些方法涵盖了各种适应enario（例如在线适应vs.离线适应、实例适应vs.批适应vs.领域适应）。此外，我们还探索了不同TTA方法与不同后端网络的Compatibility。为实现这个基准，我们在PyTorch中开发了一个统一的框架，允许在不同的dataset和网络架构上一致性地评估和比较TTA方法的效果。通过建立这个基准，我们希望为研究者和实践者提供一个可靠的方式来评估和比较TTA方法在提高模型的Robustness和总体性表现方面的效果。我们的代码可以在https://github.com/yuyongcan/Benchmark-TTA上获取。
</details></li>
</ul>
<hr>
<h2 id="Principal-subbundles-for-dimension-reduction"><a href="#Principal-subbundles-for-dimension-reduction" class="headerlink" title="Principal subbundles for dimension reduction"></a>Principal subbundles for dimension reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03128">http://arxiv.org/abs/2307.03128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morten Akhøj, James Benn, Erlend Grong, Stefan Sommer, Xavier Pennec</li>
<li>for: 用于构成和重建表面</li>
<li>methods: 使用本地线性近似来获取低维 bundle</li>
<li>results: 可以成功应用于许多重要问题，如构建 Approximating 子 manifold、计算观察之间的距离等。<details>
<summary>Abstract</summary>
In this paper we demonstrate how sub-Riemannian geometry can be used for manifold learning and surface reconstruction by combining local linear approximations of a point cloud to obtain lower dimensional bundles. Local approximations obtained by local PCAs are collected into a rank $k$ tangent subbundle on $\mathbb{R}^d$, $k<d$, which we call a principal subbundle. This determines a sub-Riemannian metric on $\mathbb{R}^d$. We show that sub-Riemannian geodesics with respect to this metric can successfully be applied to a number of important problems, such as: explicit construction of an approximating submanifold $M$, construction of a representation of the point-cloud in $\mathbb{R}^k$, and computation of distances between observations, taking the learned geometry into account. The reconstruction is guaranteed to equal the true submanifold in the limit case where tangent spaces are estimated exactly. Via simulations, we show that the framework is robust when applied to noisy data. Furthermore, the framework generalizes to observations on an a priori known Riemannian manifold.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们示示了如何使用非柯尼希 геометрия来进行拟合 manifold 和表面重建，通过将本地线性近似合集到一个降维Bundle 中。这个降维Bundle 在 $\mathbb{R}^d$ 上定义为 rank $k$ 的 tangent 子bundle，其中 $k<d$。我们称之为主Bundle。这个主Bundle 定义了一个非柯尼希 metric 在 $\mathbb{R}^d$ 上。我们证明了这个 metric 下的非柯尼希 geodesics 可以成功地应用于一些重要问题，例如：构造一个approximating submanifold $M$，构造一个点云在 $\mathbb{R}^k$ 上的表示，并计算observations 之间的距离，考虑到学习的geometry。在极限情况下，如果 tangent space 是准确地估计的，则重建是确定的。通过实验，我们表明了这种框架在噪声数据上是稳定的。此外，这种框架还可以推广到已知的里曼尼 manifold 上的observations。
</details></li>
</ul>
<hr>
<h2 id="LISSNAS-Locality-based-Iterative-Search-Space-Shrinkage-for-Neural-Architecture-Search"><a href="#LISSNAS-Locality-based-Iterative-Search-Space-Shrinkage-for-Neural-Architecture-Search" class="headerlink" title="LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search"></a>LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03110">http://arxiv.org/abs/2307.03110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bhavna Gopal, Arjun Sridhar, Tunhou Zhang, Yiran Chen</li>
<li>for: 这篇论文旨在提出一个自动化的搜索空间缩小算法，以提高搜索性能和搜索空间的多样性。</li>
<li>methods: 本论文使用了本地性和结构相似性的关系来优化搜索空间，实现了高效的搜索和多样性保持。</li>
<li>results: 本论文在不同的搜索空间和数据集上进行了实验，结果显示了LISSNAS算法在搜索性能和多样性方面的最佳性能，包括ImageNet上的手动搜索中的最高Top-1精度（77.6%）、Kendall-Tau指数、搜索空间大小等。<details>
<summary>Abstract</summary>
Search spaces hallmark the advancement of Neural Architecture Search (NAS). Large and complex search spaces with versatile building operators and structures provide more opportunities to brew promising architectures, yet pose severe challenges on efficient exploration and exploitation. Subsequently, several search space shrinkage methods optimize by selecting a single sub-region that contains some well-performing networks. Small performance and efficiency gains are observed with these methods but such techniques leave room for significantly improved search performance and are ineffective at retaining architectural diversity. We propose LISSNAS, an automated algorithm that shrinks a large space into a diverse, small search space with SOTA search performance. Our approach leverages locality, the relationship between structural and performance similarity, to efficiently extract many pockets of well-performing networks. We showcase our method on an array of search spaces spanning various sizes and datasets. We accentuate the effectiveness of our shrunk spaces when used in one-shot search by achieving the best Top-1 accuracy in two different search spaces. Our method achieves a SOTA Top-1 accuracy of 77.6\% in ImageNet under mobile constraints, best-in-class Kendal-Tau, architectural diversity, and search space size.
</details>
<details>
<summary>摘要</summary>
搜索空间的特征标志了神经建筑搜索（NAS）的进步。大型和复杂的搜索空间，具有多样化的建筑元素和结构，提供了更多的可能性来生成出色的建筑，但也对有效地探索和利用 pose 严重挑战。为此，许多搜索空间缩小方法通过选择单个子区域来找到一些表现良好的网络。这些方法可以提供小幅提高性和效率，但是这些技术留下大量可以进一步提高搜索性能的空间，并且无法保持建筑多样性。我们提出了 LISSNAS，一种自动化算法，可以将大型空间缩小到多样性强、性能优秀的小搜索空间。我们的方法利用了地方性，建筑和性能之间的相似关系，以高效地提取许多表现良好的网络。我们在多个搜索空间中进行了证明，并在 ImageNet 下实现了移动端的 SOTA Top-1 准确率为 77.6%，同时保持了 Kendall-Tau 最佳、建筑多样性和搜索空间大小。
</details></li>
</ul>
<hr>
<h2 id="How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models"><a href="#How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models" class="headerlink" title="How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models"></a>How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03108">http://arxiv.org/abs/2307.03108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenting Wang, Chen Chen, Yuchen Liu, Lingjuan Lyu, Dimitris Metaxas, Shiqing Ma</li>
<li>for: 防止文本到图像扩散模型中的数据非法使用</li>
<li>methods: 植入干扰记忆法，通过分析模型是否记忆植入内容来检测非法数据使用</li>
<li>results: 在Stable Diffusion和LoRA模型上进行了实验，得到了效果的检测非法数据使用结果<details>
<summary>Abstract</summary>
Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages.
</details>
<details>
<summary>摘要</summary>
近期文本到图像扩散模型已经显示出了高质量图像生成的出色表现。然而，有关数据非法使用的担忧也在提出。一个例子是模型训练者收集了某个艺术家创作的图像集并尝试通过不取得艺术家的授权来训练一个能够生成类似图像的模型。为解决这个问题，检测非法数据使用变得非常重要。在这篇论文中，我们提议一种方法，通过在受保护图像集中添加特有的内容，例如隐形图像包装函数，使得扩散模型能够吸收这些内容并且记忆它们。然后，通过判断模型是否具有这些内容的记忆（即是否通过选择的后处理函数处理生成的图像），可以检测模型是否使用了非法数据。我们在Stable Diffusion和LoRA模型上进行了实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Contextual-Affinity-Distillation-for-Image-Anomaly-Detection"><a href="#Contextual-Affinity-Distillation-for-Image-Anomaly-Detection" class="headerlink" title="Contextual Affinity Distillation for Image Anomaly Detection"></a>Contextual Affinity Distillation for Image Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03101">http://arxiv.org/abs/2307.03101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Masanori Suganuma, Takayuki Okatani<br>for:本研究旨在提高无监督工业异常检测的性能，特别是对逻辑异常进行检测，而不需要训练繁重的模型。methods:本研究基于先前的知识塑化工作，使用两名学生（本地学生和全球学生）来更好地模仿教师的行为。本地学生主要用于检测结构异常，而全球学生则关注逻辑异常。为了进一步鼓励全球学生学习捕捉长距离依赖关系，我们设计了全球上下文维度压缩块（GCCB），并提出了上下文相互关联损失。results:实验结果表明，提议方法不需要训练复杂的模型，可以达到新的领先性水平在MVTec LOCO AD数据集上。<details>
<summary>Abstract</summary>
Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset.
</details>
<details>
<summary>摘要</summary>
先前的工业异常检测研究主要关注本地结构异常，如裂隙和颜色杂散。尽管达到了本地异常检测的显著高效性，但它们面临着跨距离相互关联的逻辑异常，如正常对象被错误地放置。在这篇论文中，基于先前的知识塑模工作，我们提议使用两名学生（本地和全球）来更好地模仿教师的行为。本地学生，在先前的研究中主要用于结构异常检测，而全球学生则关注逻辑异常。为了进一步鼓励全球学生学习捕捉长距离相互关联，我们设计了全球上下文缩合块（GCCB）并提出了上下文相互关系损失。实验结果表明，我们提议的方法不需要复杂的训练技术，并达到了MVTec LOCO AD数据集的新的状态之平台。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.CV_2023_07_07/" data-id="clogyj8x700dy7cra13pp7is0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.AI_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T12:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.AI_2023_07_07/">cs.AI - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Decomposing-the-Generalization-Gap-in-Imitation-Learning-for-Visual-Robotic-Manipulation"><a href="#Decomposing-the-Generalization-Gap-in-Imitation-Learning-for-Visual-Robotic-Manipulation" class="headerlink" title="Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation"></a>Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03659">http://arxiv.org/abs/2307.03659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RLAgent/factor-world">https://github.com/RLAgent/factor-world</a></li>
<li>paper_authors: Annie Xie, Lisa Lee, Ted Xiao, Chelsea Finn</li>
<li>for: 本研究的目的是探讨视觉机器人 manipulate 演示中的模仿学习困难的原因，以及这些困难的评估方法。</li>
<li>methods: 我们使用了 simulation 和真实机器人语言条件 manipulate 任务来评估模仿学习策略的泛化能力，并设计了一个新的 simulated 测试环境来更加控制地评估不同因素的泛化难度。</li>
<li>results: 我们的研究表明，不同因素的泛化难度存在很大差异，并且这些差异是相对稳定的。我们还发现，某些因素的泛化难度较高，而另外的因素则较低。<details>
<summary>Abstract</summary>
What makes generalization hard for imitation learning in visual robotic manipulation? This question is difficult to approach at face value, but the environment from the perspective of a robot can often be decomposed into enumerable factors of variation, such as the lighting conditions or the placement of the camera. Empirically, generalization to some of these factors have presented a greater obstacle than others, but existing work sheds little light on precisely how much each factor contributes to the generalization gap. Towards an answer to this question, we study imitation learning policies in simulation and on a real robot language-conditioned manipulation task to quantify the difficulty of generalization to different (sets of) factors. We also design a new simulated benchmark of 19 tasks with 11 factors of variation to facilitate more controlled evaluations of generalization. From our study, we determine an ordering of factors based on generalization difficulty, that is consistent across simulation and our real robot setup.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个问题是非常Difficult to approach directly, because the environment from the perspective of a robot can often be decomposed into多种因素的变化，例如照明条件或摄像头的位置。验证性地，对一些这些因素的泛化呈现了更大的困难，但现有的工作却没有提供具体如何量化每个因素对泛化差距的信息。为了回答这个问题，我们研究了模仿学习策略在模拟和真实机器人语言conditioned manipulation任务中的泛化困难。我们还设计了一个新的模拟benchmark，包含19个任务和11个因素的变化，以便更好地评估泛化的控制性。从我们的研究中，我们确定了因素的排序，这一结果在模拟和真实机器人设置中均是一致的。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Variable-Binding-Circuitry-with-Desiderata"><a href="#Discovering-Variable-Binding-Circuitry-with-Desiderata" class="headerlink" title="Discovering Variable Binding Circuitry with Desiderata"></a>Discovering Variable Binding Circuitry with Desiderata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03637">http://arxiv.org/abs/2307.03637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xander Davies, Max Nadeau, Nikhil Prakash, Tamar Rott Shaham, David Bau</li>
<li>for: 本研究旨在提出一种方法，以自动地归因模型组件负责执行特定子任务的 causal  attribute。</li>
<li>methods: 本研究使用了 causal mediation experiments 来自动归因模型组件，并且只需要指定模型组件执行子任务的 causal attribute。</li>
<li>results: 研究成果显示，可以成功地自动发现 LLama-13B 模型中的共享变量绑定电路，并且只需要9个注意头和1个MLP来执行多个数学任务中的变量绑定。<details>
<summary>Abstract</summary>
Recent work has shown that computation in language models may be human-understandable, with successful efforts to localize and intervene on both single-unit features and input-output circuits. Here, we introduce an approach which extends causal mediation experiments to automatically identify model components responsible for performing a specific subtask by solely specifying a set of \textit{desiderata}, or causal attributes of the model components executing that subtask. As a proof of concept, we apply our method to automatically discover shared \textit{variable binding circuitry} in LLaMA-13B, which retrieves variable values for multiple arithmetic tasks. Our method successfully localizes variable binding to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.
</details>
<details>
<summary>摘要</summary>
最近的研究表明，计算机语言模型中的计算可能是人类理解的，有成功的尝试将单元特征和输入输出电路 lokalisirui和 intervene。在这里，我们介绍了一种方法，可以自动确定模型组件负责执行特定子任务，只需提供一组 \textit{desiderata}，或模型组件执行该子任务的 causal 特征。作为证明，我们应用了我们的方法，自动发现 LLama-13B 中的共享 \textit{变量绑定Circuitry}，该模型可以为多个数学任务获取变量值。我们的方法成功地将变量绑定Localized to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.
</details></li>
</ul>
<hr>
<h2 id="Over-the-Air-Computation-in-OFDM-Systems-with-Imperfect-Channel-State-Information"><a href="#Over-the-Air-Computation-in-OFDM-Systems-with-Imperfect-Channel-State-Information" class="headerlink" title="Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information"></a>Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05357">http://arxiv.org/abs/2307.05357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yilong Chen, Huijun Xing, Jie Xu, Lexi Xu, Shuguang Cui<br>for:这个论文研究了在无线电通信系统中进行空中计算（AirComp），特别是在无线电信道状态信息（CSI）不准确时，多个单antenna无线设备（WD）同时向多antenna访问点（AP）上传uncoded信号进行分布式功能计算。methods:在这种情况下，我们考虑了两种enario：一种是最大化average计算平均方差（MSE），另一种是最小化计算失败概率（outage probability）。为了实现这两个目标，我们同时优化了WDs发射器和AP接收扫描器在子载波上的传输系数和接收扫描器。results:我们在这篇论文中提出了两种特殊情况的解：一种是单个AP接收天线的情况，另一种是多个AP接收天线的情况。在单个AP接收天线情况下，我们使用 Lagrange-duality 方法提出了半闭形 globally 优化解。在多个AP接收天线情况下，我们提出了高效的 alternate 优化和几何优化算法来找到 converges 解。<details>
<summary>Abstract</summary>
This paper studies the over-the-air computation (AirComp) in an orthogonal frequency division multiplexing (OFDM) system with imperfect channel state information (CSI), in which multiple single-antenna wireless devices (WDs) simultaneously send uncoded signals to a multi-antenna access point (AP) for distributed functional computation over multiple subcarriers. In particular, we consider two scenarios with best-effort and error-constrained computation tasks, with the objectives of minimizing the average computation mean squared error (MSE) and the computation outage probability over the multiple subcarriers, respectively. Towards this end, we jointly optimize the transmit coefficients at the WDs and the receive beamforming vectors at the AP over subcarriers, subject to the maximum transmit power constraints at individual WDs. First, for the special case with a single receive antenna at the AP, we propose the semi-closed-form globally optimal solutions to the two problems using the Lagrange-duality method. It is shown that at each subcarrier, the WDs' optimized power control policy for average MSE minimization follows a regularized channel inversion structure, while that for computation outage probability minimization follows an on-off regularized channel inversion, with the regularization dependent on the transmit power budget and channel estimation error. Next, for the general case with multiple receive antennas at the AP, we present efficient algorithms based on alternating optimization and convex optimization to find converged solutions to both problems.
</details>
<details>
<summary>摘要</summary>
For the special case with a single receive antenna at the AP, we propose semi-closed-form globally optimal solutions to the two problems using the Lagrange-duality method. The results show that at each subcarrier, the WDs' optimized power control policy for average MSE minimization follows a regularized channel inversion structure, while that for computation outage probability minimization follows an on-off regularized channel inversion, with the regularization dependent on the transmit power budget and channel estimation error.For the general case with multiple receive antennas at the AP, we present efficient algorithms based on alternating optimization and convex optimization to find converged solutions to both problems. These algorithms take into account the coupling between the transmit coefficients and the receive beamforming vectors, and the non-convexity of the optimization problems.In summary, this paper investigates the optimization of AirComp in an OFDM system with imperfect CSI, and proposes algorithms to minimize the average MSE and computation outage probability over multiple subcarriers. The proposed solutions take into account the maximum transmit power constraints and the coupling between the transmit coefficients and the receive beamforming vectors.
</details></li>
</ul>
<hr>
<h2 id="Brain-in-a-Vat-On-Missing-Pieces-Towards-Artificial-General-Intelligence-in-Large-Language-Models"><a href="#Brain-in-a-Vat-On-Missing-Pieces-Towards-Artificial-General-Intelligence-in-Large-Language-Models" class="headerlink" title="Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models"></a>Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03762">http://arxiv.org/abs/2307.03762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Ma, Chi Zhang, Song-Chun Zhu</li>
<li>for: 这篇论文主要是为了探讨大语言模型（LLM）的评估方法和人工通用智能的定义。</li>
<li>methods: 论文首先对现有的LLM评估方法进行了全面回顾，并指出了评估方法中的一些问题，这些问题会导致LLM的能力被过分评估。然后，文章提出了人工通用智能应包含以下四个特征：1）可以完成无数量的任务；2）可以在 Context中生成新任务；3）基于值系统来生成任务；4）具有基于现实的世界模型，这种世界模型影响了它与世界的交互。</li>
<li>results: 文章认为，现有的人工智能研究仅仅是模拟智能，而不是真正的通用智能。它们缺乏了知识获得和行为的一体化，而且知识获得不仅仅靠 passive input，还需要重复的尝试和错误。文章结束时，提出了人工智能未来研究的可能性。<details>
<summary>Abstract</summary>
In this perspective paper, we first comprehensively review existing evaluations of Large Language Models (LLMs) using both standardized tests and ability-oriented benchmarks. We pinpoint several problems with current evaluation methods that tend to overstate the capabilities of LLMs. We then articulate what artificial general intelligence should encompass beyond the capabilities of LLMs. We propose four characteristics of generally intelligent agents: 1) they can perform unlimited tasks; 2) they can generate new tasks within a context; 3) they operate based on a value system that underpins task generation; and 4) they have a world model reflecting reality, which shapes their interaction with the world. Building on this viewpoint, we highlight the missing pieces in artificial general intelligence, that is, the unity of knowing and acting. We argue that active engagement with objects in the real world delivers more robust signals for forming conceptual representations. Additionally, knowledge acquisition isn't solely reliant on passive input but requires repeated trials and errors. We conclude by outlining promising future research directions in the field of artificial general intelligence.
</details>
<details>
<summary>摘要</summary>
在这篇观点论文中，我们首先进行了涵盖现有大语言模型（LLM）评估的全面审查，使用标准化测试和能力尺度标准。我们指出了现有评估方法存在一些问题，导致LLM的能力被过度评估。然后，我们详细说明了人工总智能应包括以下四个特点：1）可以完成无数项任务；2）可以在 Context 中生成新任务；3）基于值系统来决定任务生成；4）具有对实际世界的认知，影响其与世界的互动。基于这种视角，我们强调了人工总智能缺失的一部分，即知识和行为的一体性。我们 argued That active engagement with objects in the real world provides more robust signals for forming conceptual representations. In addition, knowledge acquisition is not solely reliant on passive input, but requires repeated trials and errors. Finally, we outline promising future research directions in the field of artificial general intelligence.
</details></li>
</ul>
<hr>
<h2 id="GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting"><a href="#GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting" class="headerlink" title="GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting"></a>GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03595">http://arxiv.org/abs/2307.03595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Vincent Quenneville-Belair, Ronak Metha, Michael W. Mahoney</li>
<li>for: 解决“冷启”时间序列预测问题，即预测缺乏历史数据的时间序列。</li>
<li>methods: 利用图神经网络（GNN）作为编码器增强器，通过生成GNN基于的特征来捕捉时间序列之间的复杂关系。</li>
<li>results: 在实际应用中，对一家大型电商商户的需求预测 task 中，我们的方法可以提高总表现，并更重要的是，对“冷启”产品（新上市或者刚下架）的预测带来显著改善。<details>
<summary>Abstract</summary>
Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting, especially in real-world applications. However, to forecast accurately, these sophisticated models typically rely on a large number of time series examples with substantial history. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data -- often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships, and their generation process can be optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge-defined graphs, scaling to incorporate information from multiple very large graphs with millions of nodes. In our target application of demand forecasting for a large e-commerce retailer, we demonstrate on both a small dataset of 100K products and a large dataset with over 2 million products that our method improves overall performance over competitive baseline models. More importantly, we show that it brings substantially more gains to ``cold start'' products such as those newly launched or recently out-of-stock.
</details>
<details>
<summary>摘要</summary>
深度神经网络在多个时间水平预测方面得到了越来越多的研究，特别是在实际应用中。然而，为了准确预测，这些复杂的模型通常需要大量的时间序列示例，其中具有充分的历史记录。一个迅速增长的研究领域是缺少历史数据的时间序列预测问题，通常被称为“冷开始”问题。在这篇论文中，我们介绍了一种新的、简单的方法，通过利用图神经网络（GNN）作为编码器增强器来解决这个问题。这些GNN基于的特征可以捕捉到时间序列之间的复杂关系，并且其生成过程可以与预测任务结合optimized。我们示出了我们的架构可以使用数据驱动或域知识定义的图，可涵盖多个具有百万个节点的图。在我们的目标应用中，我们在10万个产品的小数据集和超过2万个产品的大数据集上进行了实验，并证明了我们的方法可以在比较基eline模型的情况下提供更好的总体性能。更重要的是，我们发现我们的方法对“冷开始”产品（如新上市或者刚出库）的预测具有显著的改善。
</details></li>
</ul>
<hr>
<h2 id="VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis"><a href="#VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis" class="headerlink" title="VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis"></a>VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03592">http://arxiv.org/abs/2307.03592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paula Feldman, Miguel Fainstein, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi</li>
<li>for: 这篇论文的目的是为了 Synthesizing blood vessel 3D geometry, 即生成血管三维几何结构。</li>
<li>methods: 该论文使用的方法是 recursive variational Neural Network (VesselVAE)，它可以完全利用血管的层次结构，学习低维抽象表示分支连接性以及表示目标表面的几何特征。</li>
<li>results: 该论文的实验结果显示，VesselVAE可以生成高度准确和多样化的血管三维模型，并且与实际数据的相似性达到了&#x2F;.97、&#x2F;.95和&#x2F;.96三个指标。这些结果表明，VesselVAE可以用于医疗和手术训练、血液动力学 simulations 等多种目的。<details>
<summary>Abstract</summary>
We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we generate 3D models of blood vessels that are both accurate and diverse, which is crucial for medical and surgical training, hemodynamic simulations, and many other purposes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于数据的生成框架，用于synthesizing血管三维几何结构。这是一项具有挑战性的任务，因为血液系统的复杂性和多样性很高，它们的形态、大小和结构各不相同。现有的模型基本方法可以提供一定的控制和变化，但是无法捕捉实际生物学数据的多样性。我们开发了VesselVAE，一种嵌入式的可变量神经网络，它完全利用血管的层次结构，学习低维度抽象表示分支连接以及表面特征，描述目标表面的几何特征。经过训练，VesselVAE的幂数空间可以采样新的血管几何结构。根据我们所知，这是第一次利用这种技术来生成血管。我们实现了真实数据和生成数据之间的相似性（.97），（.95）和（.96）。通过利用深度神经网络的力量，我们生成了准确且多样的血管三维模型，这对医疗和手术培训、血液动力学计算以及许多其他目的都是关键。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Deep-Learning-for-Personalized-Renal-Cell-Carcinoma-Prognosis-Integrating-CT-Imaging-and-Clinical-Data"><a href="#Multimodal-Deep-Learning-for-Personalized-Renal-Cell-Carcinoma-Prognosis-Integrating-CT-Imaging-and-Clinical-Data" class="headerlink" title="Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data"></a>Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03575">http://arxiv.org/abs/2307.03575</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mahootiha-maryam/Survival_CTplusClinical">https://github.com/mahootiha-maryam/Survival_CTplusClinical</a></li>
<li>paper_authors: Maryamalsadat Mahootiha, Hemin Ali Qadir, Jacob Bergsland, Ilangko Balasingham<br>for:这项研究的目的是开发一个全面的深度学习模型，用于预测renoocellular carcinoma患者的生存可能性，通过结合CT成像和临床数据，并解决过去研究中出现的局限性。methods:该研究提posed一个框架，包括三个模块：3D图像特征提取器、临床变量选择和生存预测。图像特征提取器模块基于3D CNN架构，预测CT成像中renoocellular carcinoma肿瘤的ISUP分期，与死亡率相关。临床变量选择使用Spearman分数和Random Forest重要性分数作为标准，系统地选择临床变量。生存预测使用深度学习网络，以Discrete LogisticHazard-based损失函数进行训练。results:我们的发现表明，提出的策略超过了当前renoocellular carcinoma预测Literature中基于CT成像和临床因素的研究。最佳实验在测试集上达到了 concordance index 0.84和area under the curve 0.8 的水平，这表明了该方法在预测renoocellular carcinoma患者的生存可能性方面具有强大的预测力。<details>
<summary>Abstract</summary>
Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework comprises three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments are performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on: \href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}
</details>
<details>
<summary>摘要</summary>
“肾细胞癌 represents a significant global health challenge with a low survival rate. This research aimed to develop a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data, and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework consists of three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments were performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on GitHub.”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Why-machines-do-not-understand-A-response-to-Sogaard"><a href="#Why-machines-do-not-understand-A-response-to-Sogaard" class="headerlink" title="Why machines do not understand: A response to Søgaard"></a>Why machines do not understand: A response to Søgaard</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04766">http://arxiv.org/abs/2307.04766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jobst Landgrebe, Barry Smith</li>
<li>for: 本文针对一些人认为机器人可以理解语言的观点进行批判，具体来说是关于索加德（Sogaard）在这本杂志上提出的一种这样的thesis，基于语言学习和机器学习的概念。</li>
<li>methods: 本文使用了对索加德的论点进行分析和批判的方法，包括对语言的使用和存储方式的分析，以及对机器学习和人工智能的批判。</li>
<li>results: 本文表明了索加德的论点存在问题，主要是因为他忽视了人类语言使用和计算机语言存储的区别，从而导致了机器人理解语言的困难。<details>
<summary>Abstract</summary>
Some defenders of so-called `artificial intelligence' believe that machines can understand language. In particular, S{\o}gaard has argued in this journal for a thesis of this sort, on the basis of the idea (1) that where there is semantics there is also understanding and (2) that machines are not only capable of what he calls `inferential semantics', but even that they can (with the help of inputs from sensors) `learn' referential semantics \parencite{sogaard:2022}. We show that he goes wrong because he pays insufficient attention to the difference between language as used by humans and the sequences of inert of symbols which arise when language is stored on hard drives or in books in libraries.
</details>
<details>
<summary>摘要</summary>
一些人认为论称的人工智能可以理解语言。特别是，S{\o}gaard在这份报告中提出了这种thesis，基于两点：一是语言存在 semantics 就是理解的 garantor（1），二是机器不仅可以进行他所称的“推理 semantics”，而且可以（通过感知器的输入）“学习” referential semantics（\parencite{sogaard:2022）。我们展示了他的错误是因为他忽视了人类使用语言和存储在硬盘或图书馆中的语言序列的差异。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks"><a href="#Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks" class="headerlink" title="Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks"></a>Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03761">http://arxiv.org/abs/2307.03761</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MengjieZhao/dygatad">https://github.com/MengjieZhao/dygatad</a></li>
<li>paper_authors: Mengjie Zhao, Olga Fink</li>
<li>for: 本文针对的是随着互联网 Things (IIoTs) 系统中的多变量时间序列 (MTS) 数据的异常检测，即使在感知器网络中存在复杂性和互相关系的情况下。</li>
<li>methods: 本文提出了 DyGATAD (动态图注意力异常检测) 方法，该方法利用注意力机制构建了多变量时间序列上的连续图表示，并通过推断动态边来检测关系变化。 DyGATAD 还包括了基于操作条件的重建和 topology 基于异常分数，从而提高了异常检测的能力。</li>
<li>results: 根据一个控制变量的 synthetic 数据集和一个实际 industrials 的多相流设备数据集，我们证明了 DyGATAD 在感知器网络中的异常检测性能非常高，特别是在早期疾病检测和轻度疾病检测方面表现出色。<details>
<summary>Abstract</summary>
In the era of digital transformation, systems monitored by the Industrial Internet of Things (IIoTs) generate large amounts of Multivariate Time Series (MTS) data through heterogeneous sensor networks. While this data facilitates condition monitoring and anomaly detection, the increasing complexity and interdependencies within the sensor network pose significant challenges for anomaly detection. Despite progress in this field, much of the focus has been on point anomalies and contextual anomalies, with lesser attention paid to collective anomalies. A less addressed but common variant of collective anomalies is when the abnormal collective behavior is caused by shifts in interrelationships within the system. This can be due to abnormal environmental conditions like overheating, improper operational settings resulting from cyber-physical attacks, or system-level faults. To address these challenges, this paper proposes DyGATAD (Dynamic Graph Attention for Anomaly Detection), a graph-based anomaly detection framework that leverages the attention mechanism to construct a continuous graph representation of multivariate time series by inferring dynamic edges between time series. DyGATAD incorporates an operating condition-aware reconstruction combined with a topology-based anomaly score, thereby enhancing the detection ability of relationship shifts. We evaluate the performance of DyGATAD using both a synthetic dataset with controlled varying fault severity levels and an industrial-scale multiphase flow facility benchmark featuring various fault types with different detection difficulties. Our proposed approach demonstrated superior performance in collective anomaly detection for sensor networks, showing particular strength in early-stage fault detection, even in the case of faults with minimal severity.
</details>
<details>
<summary>摘要</summary>
在数字变革时代，由IIoT系统监测的系统生成大量多变量时间序列（MTS）数据，这些数据可以帮助 condition monitoring 和异常检测。然而，随着传感器网络的复杂性和互相关系的增加，异常检测遇到了 significiant 挑战。虽然在这一领域已经做出了很多进展，但是大多数研究都是关注点异常和上下文异常，而忽略了集体异常。这是一种较少地研究的，但是非常普遍的 коллектив异常情况，即传感器网络中的异常行为是由系统间关系的变化引起的。这可能是因为环境条件异常、操作设置不当或系统级别的故障所致。为解决这些挑战，本文提出了 DyGATAD（动态图注意力检测），一种基于图的异常检测框架。DyGATAD 利用注意力机制来构建多变量时间序列中的连续图表示，并通过推理出动态边的方式来捕捉系统间的关系变化。DyGATAD 还包括了根据操作条件进行修正的重构，以及基于 topological 异常分数的检测，从而提高了异常检测的能力。我们对一个合成数据集和一个实际工业级多相流设施的数据进行了评估，结果表明，DyGATAD 在传感器网络中的集体异常检测中表现出色，特别是在初期疾病检测中，甚至是在疾病严重程度较低的情况下。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-as-Batteries-Included-Zero-Shot-ESCO-Skills-Matchers"><a href="#Large-Language-Models-as-Batteries-Included-Zero-Shot-ESCO-Skills-Matchers" class="headerlink" title="Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers"></a>Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03539">http://arxiv.org/abs/2307.03539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Clavié, Guillaume Soulié<br>for:这篇论文的目的是提出一个零上下测试的自动技能抽出系统，用于对雇佣广告中的技能抽出。methods:这个系统使用大型自然语言模型（LLM）来生成Synthetic训练数据，并使用一个分类器来从雇佣广告中提取技能提及。然后使用另一个LLM进行相似预测，以重新排序技能候选人。results:这篇论文的结果显示，使用合成数据可以在技能抽出 задачі中取得10个RP@10分的高分，比前一些距离指导方法高出10个分。同时，添加GPT-4重新排序可以提高RP@10的表现，高于前一些方法的22个分。此外，将任务框架为“假程式”的提示，可以让LLM表现更好，特别是使用较弱的LLM。<details>
<summary>Abstract</summary>
Understanding labour market dynamics requires accurately identifying the skills required for and possessed by the workforce. Automation techniques are increasingly being developed to support this effort. However, automatically extracting skills from job postings is challenging due to the vast number of existing skills. The ESCO (European Skills, Competences, Qualifications and Occupations) framework provides a useful reference, listing over 13,000 individual skills. However, skills extraction remains difficult and accurately matching job posts to the ESCO taxonomy is an open problem. In this work, we propose an end-to-end zero-shot system for skills extraction from job descriptions based on large language models (LLMs). We generate synthetic training data for the entirety of ESCO skills and train a classifier to extract skill mentions from job posts. We also employ a similarity retriever to generate skill candidates which are then re-ranked using a second LLM. Using synthetic data achieves an RP@10 score 10 points higher than previous distant supervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22 points over previous methods. We also show that Framing the task as mock programming when prompting the LLM can lead to better performance than natural language prompts, especially with weaker LLMs. We demonstrate the potential of integrating large language models at both ends of skills matching pipelines. Our approach requires no human annotations and achieve extremely promising results on skills extraction against ESCO.
</details>
<details>
<summary>摘要</summary>
理解劳动市场动态需要准确地确定工作人员所需和拥有的技能。自动化技术在支持这一努力方面发展得越来越好。然而，从工作岗posts中自动提取技能是一项挑战，因为存在庞大的技能数量。欧洲技能、COMPETENCES、资格和职业（ESCO）框架提供了有用的参考，列出了13,000多个具体的技能。然而，技能提取仍然具有挑战性，并且准确匹配工作岗posts到ESCO分类是一个打开的问题。在这种工作中，我们提议一种终端零批量系统，使用大型自然语言模型（LLMs）进行技能提取从工作岗posts。我们生成了ESCO技能整体的合成训练数据，并使用一个分类器提取技能提及从工作岗posts。此外，我们使用一个相似搜索器生成技能候选人选，然后使用第二个LLM进行重新排序。使用合成数据实现RP@10分数10点高于前一种远程指导方法。另外，添加GPT-4重新排序可以提高RP@10分数22点以上。我们还证明，将任务fram为Mock编程时请求LLM的提示可以提高性能，特别是使用较弱的LLM。我们展示了将大型自然语言模型 integrate到技能匹配管道的潜在优势，并实现了无需人工标注的技能提取 противESCO。
</details></li>
</ul>
<hr>
<h2 id="Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis"><a href="#Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis" class="headerlink" title="Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis"></a>Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05519">http://arxiv.org/abs/2307.05519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyi Ji, Richard Salmon, Nita Mulliqi, Umair Khan, Yinxi Wang, Anders Blilie, Henrik Olsson, Bodil Ginnerup Pedersen, Karina Dalsgaard Sørensen, Benedicte Parm Ulhøi, Svein R Kjosavik, Emilius AM Janssen, Mattias Rantalainen, Lars Egevad, Pekka Ruusuvuori, Martin Eklund, Kimmo Kartasalo</li>
<li>for: 这项研究旨在解决数位patology中人工智能（AI）的潜力受到技术不一致的抑制，从而使AI在临床应用中受到挑战。</li>
<li>methods: 研究者使用了物理色彩准确的扫描仪进行了四个实验室的色彩准确性标准化，以确定这种方法对抗癌诊断模型的影响。</li>
<li>results: 研究结果表明，物理色彩准确的扫描仪可以标准化整个报告图像的出现，从而提高AI模型的准确性和Gleason分级表现。这项研究验证了物理色彩准确的扫描仪可以解决不同扫描仪 introduce的变化，使AI基于的肿瘤诊断变得更加可靠和在临床设置中可行。<details>
<summary>Abstract</summary>
The potential of artificial intelligence (AI) in digital pathology is limited by technical inconsistencies in the production of whole slide images (WSIs), leading to degraded AI performance and posing a challenge for widespread clinical application as fine-tuning algorithms for each new site is impractical. Changes in the imaging workflow can also lead to compromised diagnoses and patient safety risks. We evaluated whether physical color calibration of scanners can standardize WSI appearance and enable robust AI performance. We employed a color calibration slide in four different laboratories and evaluated its impact on the performance of an AI system for prostate cancer diagnosis on 1,161 WSIs. Color standardization resulted in consistently improved AI model calibration and significant improvements in Gleason grading performance. The study demonstrates that physical color calibration provides a potential solution to the variation introduced by different scanners, making AI-based cancer diagnostics more reliable and applicable in clinical settings.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在数字 PATHOLOGY 中的潜力受到扫描机器（Whole Slide Images，WSIs）技术不一致的限制，导致 AI 性能下降，并对营养广泛临床应用 pose 挑战。工作流程变化也可能导致诊断错误和 patient safety 风险。我们评估了扫描机器的物理色彩准确性是否可以标准化 WSI 的外观，并对抗肉癌诊断 AI 系统的1,161 WSI 的表现。色彩标准化导致 AI 模型准确性的改进，并且在 Gleason 分期性能中得到了显著改进。这项研究表明，物理色彩准确性提供了扫描机器间变化引入的解决方案，使 AI 基于肉癌诊断更可靠和在临床设置中应用。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks"><a href="#Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks" class="headerlink" title="Contrastive Graph Pooling for Explainable Classification of Brain Networks"></a>Contrastive Graph Pooling for Explainable Classification of Brain Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11133">http://arxiv.org/abs/2307.11133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Xu, Qingtian Bian, Xinhang Li, Aihu Zhang, Yiping Ke, Miao Qiao, Wei Zhang, Wei Khang Jeremy Sim, Balázs Gulyás</li>
<li>for: 这个论文的目的是提出一种适用于Functional magnetic resonance imaging (fMRI)数据的图 neural network (GNN) 模型，以提高对大脑网络的理解和描述。</li>
<li>methods: 这个论文使用的方法包括一种对比性双注意力块和一种可微graph pooling方法，以便更好地利用GNN来描述大脑网络。</li>
<li>results: 该论文在5个休息态fMRI大脑网络数据集上进行了应用，并证明了其在比基elines上表现出优异。此外，研究还发现了与 neuroscience 文献中的知识匹配的特征特征，并提供了直观和有趣的探索。<details>
<summary>Abstract</summary>
Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions.
</details>
<details>
<summary>摘要</summary>
Functional magnetic resonance imaging (fMRI) 是一种广泛使用的技术来测量神经活动。其应用在识别下面的神经退化疾病，如 Parkinson's、Alzheimer's 和 Autism 等方面特别重要。最近的 fMRI 数据分析模型将大脑视为图，通过图神经网络（GNN）提取特征。然而，fMRI 数据的特殊性需要特殊的 GNN 设计。适应 GNN 生成有效和域 explainable 特征仍然是挑战。在这篇论文中，我们提出了对比 dual-attention 块和可导图聚合方法，称之为 ContrastPool，以更好地利用 GNN 对大脑网络。我们在 5 个休息态 fMRI 大脑网络数据集上应用了我们的方法，并证明我们的方法在比基eline上显著superior。我们的案例研究表明，我们的方法提取的特征与 neuroscience 文献中的领域知识匹配，并且揭示了直观和有趣的发现。我们的贡献表明 ContrastPool 在理解大脑网络和神经退化疾病方面具有潜力。
</details></li>
</ul>
<hr>
<h2 id="Procedurally-generating-rules-to-adapt-difficulty-for-narrative-puzzle-games"><a href="#Procedurally-generating-rules-to-adapt-difficulty-for-narrative-puzzle-games" class="headerlink" title="Procedurally generating rules to adapt difficulty for narrative puzzle games"></a>Procedurally generating rules to adapt difficulty for narrative puzzle games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05518">http://arxiv.org/abs/2307.05518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Volden, Djordje Grbic, Paolo Burelli</li>
<li>for: 这篇论文旨在透过生成规则和通过玩家来调整难度。这是一个更大的项目，旨在收集和适应教育游戏 для小学生使用数字谜题游戏，设计给幼儿园。</li>
<li>methods: 这篇论文使用了遗传算法和难度度量来找到目标解集和大型自然语言模型来通过narativeContext来交流规则。</li>
<li>results: 在测试中，该方法能够在平均24个代表中找到规则，以达到目标难度。将来的实验计划提高评估、特化语言模型到儿童文学，并收集多modal数据来引导适应。<details>
<summary>Abstract</summary>
This paper focuses on procedurally generating rules and communicating them to players to adjust the difficulty. This is part of a larger project to collect and adapt games in educational games for young children using a digital puzzle game designed for kindergarten. A genetic algorithm is used together with a difficulty measure to find a target number of solution sets and a large language model is used to communicate the rules in a narrative context. During testing the approach was able to find rules that approximate any given target difficulty within two dozen generations on average. The approach was combined with a large language model to create a narrative puzzle game where players have to host a dinner for animals that can't get along. Future experiments will try to improve evaluation, specialize the language model on children's literature, and collect multi-modal data from players to guide adaptation.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "procedurally generating" 生成过程中的 (shēngchǎng yǔ xiǎngchǎng)* "difficulty" 难度 (nándù)* "target number of solution sets" 目标解决方案的数量 (mùzhì jiějué fāng'àn de shùliàng)* "large language model" 大型自然语言模型 (dàxíng zìrán yǔyán módelì)* "narrative context" 叙事上下文 (jiùshì shàngxìa)* "genetic algorithm" 遗传算法 (lìchǎng suànfǎ)* "solution sets" 解决方案 (jiějué fāng'àn)
</details></li>
</ul>
<hr>
<h2 id="Tranfer-Learning-of-Semantic-Segmentation-Methods-for-Identifying-Buried-Archaeological-Structures-on-LiDAR-Data"><a href="#Tranfer-Learning-of-Semantic-Segmentation-Methods-for-Identifying-Buried-Archaeological-Structures-on-LiDAR-Data" class="headerlink" title="Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data"></a>Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03512">http://arxiv.org/abs/2307.03512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paolo Soleni, Wouter B. Verschoof-van der Vaart, Žiga Kokalj, Arianna Traviglia, Marco Fiorucci</li>
<li>for: 用深度学习技术进行远程感知数据在考古研究中应用，一个主要障碍是训练模型所需的数据的有限可用性。</li>
<li>methods: 本研究使用了传输学习技术，并对两个semantic segmentation深度神经网络在两个LiDAR数据集上进行了比较。</li>
<li>results: 实验结果表明，在考古领域中使用传输学习配置可以提高性能，但尚未观察到系统性的提高。我们提供了特定的应用场景，以供未来研究的参考。<details>
<summary>Abstract</summary>
When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.
</details>
<details>
<summary>摘要</summary>
当应用深度学习到远程感知数据中的考古研究中，一个显著的障碍是训练模型的数据减少的限制。通常使用传输学习来缓解这个问题。然而，还需要探索它在不同的考古数据集之间的效果。这篇论文比较了不同的传输学习配置使用两种semantic segmentation深度神经网络在两个LiDAR数据集上的性能。实验结果表明，在考古领域中使用传输学习可以提高性能，但是还没有系统地提高。我们提供了特定的洞察，以供未来研究的参考。
</details></li>
</ul>
<hr>
<h2 id="Derivative-Free-Weight-space-Ensembling"><a href="#Derivative-Free-Weight-space-Ensembling" class="headerlink" title="Derivative Free Weight-space Ensembling"></a>Derivative Free Weight-space Ensembling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03506">http://arxiv.org/abs/2307.03506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean Ninalga</li>
<li>for: 本研究的目的是提出一种新的几个样本任务传递方法，以便在开放领域对话中进行有效的任务传递。</li>
<li>methods: 本研究使用了Derivative Free Weight-space Ensembling（DFWE）策略，该策略创建了一组多样化的专家语言模型，每个专家模型通过预定的源任务进行训练。然后，每个专家模型都进行了精度调整，以便更好地适应目标任务。最后，我们使用了一种无级优化算法来线性 interpolate  между模型的权重，以达到有效地找到一个好的权重混合。</li>
<li>results: 我们在FETA-Friends上进行了实验，并证明了DFWE的效果。相比标准的预训练-精度调整方法，DFWE能够更好地传递知识并提高任务表现。<details>
<summary>Abstract</summary>
Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
</details>
<details>
<summary>摘要</summary>
研究表明，在两个特殊化语言模型之间 interpolate 知识可以在任务之间传递知识，而多任务学习则无法实现。然而，很少人研究了超过两个模型的 interpolate。在这篇论文中，我们介绍了 Derivative Free Weight-space Ensembling (DFWE)，一种新的几个样本任务传递方法，用于开放领域对话。我们的框架创建了一组多样化的专家语言模型，每个模型通过预定的源任务进行训练。然后，我们每个专家模型都在目标任务上精度调整，从多个不同的知识基础上进行 approached。最后，我们使用一个 gradient-free-optimization 算法来线性 interpolate 模型的 weights，以效率地找到一个好的 interpolate 权重。我们在 FETA-Friends 上 demonstrate 了方法的效果，超过标准预训练-精度调整方法。
</details></li>
</ul>
<hr>
<h2 id="RCDN-–-Robust-X-Corner-Detection-Algorithm-based-on-Advanced-CNN-Model"><a href="#RCDN-–-Robust-X-Corner-Detection-Algorithm-based-on-Advanced-CNN-Model" class="headerlink" title="RCDN – Robust X-Corner Detection Algorithm based on Advanced CNN Model"></a>RCDN – Robust X-Corner Detection Algorithm based on Advanced CNN Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03505">http://arxiv.org/abs/2307.03505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Chen, Caihua Xiong, Quanlin Li, Zhonghua Wan</li>
<li>for: 提高机器视觉和机器人领域中X-角落检测和地理化的精度和可靠性。</li>
<li>methods: 提出了一种新的检测算法，可以在多种干扰下保持高比素精度，包括镜头扭曲、极端pose和噪声。该算法采用了一个粗粒度检测网络和三种后处理技术来筛选正确的角度候选者，以及一种混合比素精度修正技术和改进的区域增长策略来自动地恢复部分可见或遮挡的检查板图样。</li>
<li>results: 对实际和 sintetic 图像进行评估，表明提出的算法在检测率、比素精度和Robustness方面比其他常用方法更高。此外，camera calibration和pose estimation实验也表明，该算法可以更好地实现相机参数的调整和pose的估计。<details>
<summary>Abstract</summary>
Accurate detection and localization of X-corner on both planar and non-planar patterns is a core step in robotics and machine vision. However, previous works could not make a good balance between accuracy and robustness, which are both crucial criteria to evaluate the detectors performance. To address this problem, in this paper we present a novel detection algorithm which can maintain high sub-pixel precision on inputs under multiple interference, such as lens distortion, extreme poses and noise. The whole algorithm, adopting a coarse-to-fine strategy, contains a X-corner detection network and three post-processing techniques to distinguish the correct corner candidates, as well as a mixed sub-pixel refinement technique and an improved region growth strategy to recover the checkerboard pattern partially visible or occluded automatically. Evaluations on real and synthetic images indicate that the presented algorithm has the higher detection rate, sub-pixel accuracy and robustness than other commonly used methods. Finally, experiments of camera calibration and pose estimation verify it can also get smaller re-projection error in quantitative comparisons to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
通过精准探测和定位X角的算法， robotics和机器视觉中的核心步骤是检测X角。然而，过去的方法无法保持高精度和可靠性的平衡，这两个 критери㪨都是评估探测器性能的关键因素。为解决这个问题，在这篇论文中，我们提出了一种新的探测算法，可以在多种干扰下保持高分辨率，包括镜头扭曲、极端pose和噪声。该算法采用了粗粒度探测网络和三种后处理技术来分辨正确的角度候选者，以及混合分辨率纠正技术和改进的区域增长策略来自动地恢复部分可见或遮挡的Checkerboard模式。实验表明，提出的算法在真实和 sintetic 图像上具有更高的检测率、分辨率和可靠性，并且在相机准备和pose估计方面也能够获得更小的重映射误差。
</details></li>
</ul>
<hr>
<h2 id="Large-AI-Model-Based-Semantic-Communications"><a href="#Large-AI-Model-Based-Semantic-Communications" class="headerlink" title="Large AI Model-Based Semantic Communications"></a>Large AI Model-Based Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03492">http://arxiv.org/abs/2307.03492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You</li>
<li>for: 这篇论文旨在解决现有的智能通信系统中知识基础构建问题，提出一种基于大机器学习模型的智能通信框架（LAM-SC），用于处理图像数据。</li>
<li>methods: 该框架首先设计了基于universal semantic knowledge的图像分割模型（SAM）知识基础（SKB），然后提出一种基于注意力的Semantic Integration（ASI）方法，以及一种适应性压缩（ASC）编码方法来减少通信开销。</li>
<li>results: 通过实验，论文示出了LAM-SC框架的效果和未来智能通信模式中大机器学习模型基础知识的重要性。<details>
<summary>Abstract</summary>
Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC) encoding to remove redundant information in semantic features, thereby reducing communication overhead. Finally, through simulations, we demonstrate the effectiveness of the LAM-SC framework and the significance of the large AI model-based KB development in future SC paradigms.
</details>
<details>
<summary>摘要</summary>
semantic communication (SC) 是一种emerging intelligent paradigm，提供未来应用程序，如 metaverse、混合现实和 everything 互联网。然而，在当前 SC 系统中，知识库（KB）的构建面临多种问题，包括有限的知识表示、频繁的知识更新和不安全的知识分享。幸运的是，大型 AI 模型的开发提供了新的解决方案。我们在这里提出一个基于大型 AI 模型的 SC 框架（LAM-SC），专门设计为图像数据处理。我们首先设计了基于universal semantic knowledge的segment anything model（SAM）知识库（SKB），可以将原始图像分解成不同的semantic segment。然后，我们提出了无人参与的注意力基本（ASI），可以对 SKB 生成的semantic segment进行权重，并将它们集成为具有semantic-aware的图像。此外，我们还提出了自适应semantic compression（ASC）编码，可以从semantic features中去除冗余信息，以减少通信开销。最后，通过 simulated experiments，我们证明了 LAM-SC 框架的有效性和未来 SC  парадигms中大型 AI 模型基本知识库的发展的重要性。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Eye-for-the-Blind"><a href="#Artificial-Eye-for-the-Blind" class="headerlink" title="Artificial Eye for the Blind"></a>Artificial Eye for the Blind</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00801">http://arxiv.org/abs/2308.00801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deepususeel/SmartEye">https://github.com/deepususeel/SmartEye</a></li>
<li>paper_authors: Abhinav Benagi, Dhanyatha Narayan, Charith Rage, A Sushmitha</li>
<li>for: 这个论文的目的是提供一种基于Raspberry Pi3的人工智能眼模型，帮助盲人进行交通导航和日常生活中的行动决策。</li>
<li>methods: 该模型使用了raspberry pi3，webcam，ultrasonic proximity sensor， speaker和多种软件模型，包括物体检测、文本识别、Google文本识别和Mycroft语音助手模型。</li>
<li>results: 模型可以帮助盲人在交通导航和日常生活中更加灵活和自信，同时还可以提供语音援助和文本援助。<details>
<summary>Abstract</summary>
The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection model to detect the objects in fronrson by converting the texts to speech by using the gTTS module. Along with the above mentioned process going on there will be an active MYCROFT voice assistant model which can be used to interact with the blind person. The blind person can ask about the weather , daily news , any information on the internet ,etc
</details>
<details>
<summary>摘要</summary>
主要脊梁我们的人工智能眼镜模型是Raspberry Pi3，与摄像头、超音波距离仪、喇叭和我们的软件模型（物品检测、字符识别、Google文本转语音和Mycroft语音助手模型）连接在一起。在 primeros，超音波距离仪将测量自己和前方任何障碍物的距离。当超音波距离仪检测到前方 Within its specified range 的障碍物时，盲人将听到一个语音提醒，表示有障碍物在他的路线上。在这个时候，摄像头将拍摄前方的图像，并将图像传递给Raspberry Pi进行处理。在处理过程中，我们使用Tesseract OCR模块来检测图像中的文本，然后将文本转换为语音，使用gTTS模块进行转换。同时，我们还会有一个活跃的MYCROFT语音助手模型，可以让盲人与其进行互动，盲人可以询问天气、每日新闻、网络上的信息等。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning"><a href="#Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning" class="headerlink" title="Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning"></a>Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03486">http://arxiv.org/abs/2307.03486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seungyong Moon, Junyoung Yeom, Bumsoo Park, Hyun Oh Song</li>
<li>for: 本研究旨在探索在生成型环境中发现具有层次结构的成就，并且需要代理人类 possess 一系列能力，如总结和长期理解。</li>
<li>methods: 本研究使用 proximal policy optimization (PPO) 算法，一种简单而多功能的无模型学习方法，并且发现 PPO 代理人类可以预测下一个成就的可能性，虽然 confidence 较低。</li>
<li>results: 研究发现，使用 PPO 算法和我们提出的新的准则学习方法 achievement distillation，可以强化代理人类对下一个成就的预测，并且在挑战性的 Crafter 环境中显示出状态的术语表现。<details>
<summary>Abstract</summary>
Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the agent's capability to predict the next achievement. Our method exhibits a strong capacity for discovering hierarchical achievements and shows state-of-the-art performance on the challenging Crafter environment using fewer model parameters in a sample-efficient regime.
</details>
<details>
<summary>摘要</summary>
发现具有层次结构的成就需要智能体具备广泛的能力，包括总结和长期逻辑。许多先前方法基于模型或层次结构，以为存在明确的长期规划模块可以帮助学习层次成就。然而，这些方法需要大量的环境互动或庞大的模型大小，限制了它们的实用性。在这项工作中，我们发现，近似策略优化（PPO），一种简单和多样的模型自由算法，在现有实现方法中表现出色，并且我们发现PPOAgent可以预测下一个成就的概率，虽然有一定的不确定性。基于这个观察，我们提出了一种新的对比学习方法，即成就萃取，以强化智能体的下一个成就预测能力。我们的方法在挑战性高的Crafter环境中展现出了优秀的成就发现能力和模型参数更少的样本效率。
</details></li>
</ul>
<hr>
<h2 id="TBGC-Task-level-Backbone-Oriented-Gradient-Clip-for-Multi-Task-Foundation-Model-Learning"><a href="#TBGC-Task-level-Backbone-Oriented-Gradient-Clip-for-Multi-Task-Foundation-Model-Learning" class="headerlink" title="TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning"></a>TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03465">http://arxiv.org/abs/2307.03465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zelun Zhang, Xue Pan</li>
<li>for: 提高多任务学习中回归梯度偏导问题</li>
<li>methods: 提出了任务级别梯度剪裁策略和多支分支数据增强策略</li>
<li>results: 实验结果表明，该策略可以减轻回归梯度偏导问题，并在CVPR2023 Foundation Model Challenge中获得1名和2名。<details>
<summary>Abstract</summary>
The AllInOne training paradigm squeezes a wide range of tasks into a unified model in a multi-task learning manner. However, optimization in multi-task learning is more challenge than single-task learning, as the gradient norm from different tasks may vary greatly, making the backbone overly biased towards one specific task. To address this issue, we propose the task-level backbone-oriented gradient clip paradigm, compared with the vanilla gradient clip method, it has two points of emphasis:1) gradient clip is performed independently for each task. 2) backbone gradients generated from each task are rescaled to the same norm scale. Based on the experimental results, we argue that the task-level backbone-oriented gradient clip paradigm can relieve the gradient bias problem to some extent. We also propose a novel multi-branch data augmentation strategy where conflict augmentations are placed in different branches. Our approach has been shown to be effective and finally achieve 1st place in the Leaderboard A and 2nd place in the Leaderboard B of the CVPR2023 Foundation Model Challenge. It's worth noting that instead of evaluating all three tasks(detection, segmentation and fine-grained classification) in Leaderboard A, the segmentation task is not evaluated in Leaderboard B, in which our team has a huge advantage.
</details>
<details>
<summary>摘要</summary>
全面一体训练模式将多种任务集成到一个多任务学习模型中，但是多任务学习中的优化具有更大的挑战，因为不同任务的梯度范围可能很大，导致支持结构偏向某一个特定任务。为解决这个问题，我们提出了任务级别支持结构折叠梯度剪辑方法，相比于普通梯度剪辑方法，它具有两点优势：1）梯度剪辑独立进行每个任务；2）每个任务生成的支持结构梯度都被缩放到同一个范围尺度。根据实验结果，我们认为任务级别支持结构折叠梯度剪辑方法可以减轻梯度偏向问题至少一部分。此外，我们还提出了一种新的多支持分支数据增强策略，其中冲突增强被放置在不同支持中。我们的方法在CVPR2023基金会模型挑战中获得了1名和2名。值得注意的是，在Leaderboard A中评估所有三个任务（检测、 segmentation 和细化分类），而Leaderboard B中不评估 segmentation 任务，我们在这个任务上具有很大优势。
</details></li>
</ul>
<hr>
<h2 id="MultiQG-TI-Towards-Question-Generation-from-Multi-modal-Sources"><a href="#MultiQG-TI-Towards-Question-Generation-from-Multi-modal-Sources" class="headerlink" title="MultiQG-TI: Towards Question Generation from Multi-modal Sources"></a>MultiQG-TI: Towards Question Generation from Multi-modal Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04643">http://arxiv.org/abs/2307.04643</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moonlightlane/multiqg-ti">https://github.com/moonlightlane/multiqg-ti</a></li>
<li>paper_authors: Zichao Wang, Richard Baraniuk</li>
<li>for: 本研究探讨了自动生成问题（QG） FROM 多ModalSource中的图像和文本，扩展了大多数现有工作的范围，这些工作都专注于仅仅从文本源中生成问题。</li>
<li>methods: 我们提出了一个简单的解决方案，called MultiQG-TI，它使得文本只问题生成器能够处理视觉输入。我们利用图像描述模型和光学字符识别模型来获取图像的文本描述和图像中的文本，并将它们与输入文本一起传递给问题生成器。我们只是微调问题生成器，而保持其他组件不变。</li>
<li>results: 在 ScienceQA 数据集上，我们示出了 MultiQG-TI 在几个shot prompting 下Significantly outperform ChatGPT，即使它有百分之一的训练参数。Additional 分析也证明了视觉和文本信号的必要性，以及模型选择的影响。<details>
<summary>Abstract</summary>
We study the new problem of automatic question generation (QG) from multi-modal sources containing images and texts, significantly expanding the scope of most of the existing work that focuses exclusively on QG from only textual sources. We propose a simple solution for our new problem, called MultiQG-TI, which enables a text-only question generator to process visual input in addition to textual input. Specifically, we leverage an image-to-text model and an optical character recognition model to obtain the textual description of the image and extract any texts in the image, respectively, and then feed them together with the input texts to the question generator. We only fine-tune the question generator while keeping the other components fixed. On the challenging ScienceQA dataset, we demonstrate that MultiQG-TI significantly outperforms ChatGPT with few-shot prompting, despite having hundred-times less trainable parameters. Additional analyses empirically confirm the necessity of both visual and textual signals for QG and show the impact of various modeling choices.
</details>
<details>
<summary>摘要</summary>
我们研究一个新的自动问题生成（QG）问题，利用多Modal来源，包括图像和文本，从而扩大现有大多数工作的范围，这些工作都专注于只使用文本来源进行QG。我们提出了一个简单的解决方案，称为MultiQG-TI，它使得文本只的问题生成器能够处理视觉输入，同时还可以处理文本输入。我们利用图像到文本模型和光学字符识别模型来获得图像的文本描述和图像中的文本，然后将这些信息与输入文本一起传递给问题生成器。我们只是微调问题生成器，而不是其他组件。在 ScienceQA 数据集上，我们证明 MultiQG-TI 在少量提示下，以 hundred-times  fewer trainable parameters 的情况下， Significantly outperform ChatGPT。我们还进行了更多的分析，确认了视觉和文本信号的必要性，以及模型选择的影响。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection"><a href="#A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection" class="headerlink" title="A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection"></a>A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03759">http://arxiv.org/abs/2307.03759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kimmeen/awesome-gnn4ts">https://github.com/kimmeen/awesome-gnn4ts</a></li>
<li>paper_authors: Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geoffrey I. Webb, Irwin King, Shirui Pan</li>
<li>for: 本研究评论文章旨在概述图 neural network（GNN）在时间序列分析（TS）领域的应用，包括预测、分类、异常检测和填充等方面。</li>
<li>methods: 本文使用GNN来模型时间序列数据中的关系，包括时间序列之间和变量之间的关系。GNN可以更好地模型这些关系，比如传统的深度神经网络和其他GNN-based方法。</li>
<li>results: 本文提供了一个全面的任务-导向的分类法，并详细介绍了一些代表性的研究工作和应用。同时，文章还提出了未来研究的可能性，包括针对不同类型时间序列数据的GNN模型。<details>
<summary>Abstract</summary>
Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.
</details>
<details>
<summary>摘要</summary>
时间序列是主要数据类型，用于记录动态系统测量和生成大量数据，both physical sensors和在线过程（虚拟感知器）生成。时间序列分析因此是解锁可用数据中的巨量信息的关键。随着图 neural networks（GNNs）的最近进步，有一个浪涌GNN-based时间序列分析方法的出现。这些方法可以显式地模型时间序列和变量之间的关系，传统的和其他深度神经网络基于方法难以做到。在本survey中，我们提供了Graph Neural Networks for Time Series Analysis（GNN4TS）的全面评论，涵盖四个基本维度：预测、分类、异常检测和补做。我们的目标是引导设计者和实践者理解、建立应用和推动GNN4TS的研究。首先，我们提供了GNN4TS的任务 oriented 分类。然后，我们介绍了代表性的研究工作和主流应用GNN4TS。最后，我们进行了全面的未来研究方向的讨论，以帮助读者更好地理解GNN-based时间序列研究的基础、实践和未来发展。这是首次将GNN-based时间序列研究汇总起来，把涉及的知识集中起来，推动 Graph Neural Networks for Time Series Analysis的研究。
</details></li>
</ul>
<hr>
<h2 id="Towards-Deep-Network-Steganography-From-Networks-to-Networks"><a href="#Towards-Deep-Network-Steganography-From-Networks-to-Networks" class="headerlink" title="Towards Deep Network Steganography: From Networks to Networks"></a>Towards Deep Network Steganography: From Networks to Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03444">http://arxiv.org/abs/2307.03444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guobiao Li, Sheng Li, Meiling Li, Zhenxing Qian, Xinpeng Zhang</li>
<li>for: 这个论文主要针对的是如何在公共通道中隐藏深度神经网络（DNN）模型，特别是那些训练用于机密学习任务的模型。</li>
<li>methods: 我们提出了一种深度网络隐藏（Deep Network Steganography，DNS），将机密的DNN模型转换为一个普通的学习任务。这是由于我们的方法将机密模型中的一些重要位置装饰成普通的学习位置，并将这些位置隐藏在一个隐藏频道中。</li>
<li>results: 我们的实验结果显示，我们的方法可以实现隐藏DNN模型，并且可以在不同的学习任务之间进行隐藏。具体而言，我们在内部任务隐藏（Intra-task steganography）和多任务隐藏（Inter-task steganography）两种情况下实现了隐藏DNN模型的目标。<details>
<summary>Abstract</summary>
With the widespread applications of the deep neural network (DNN), how to covertly transmit the DNN models in public channels brings us the attention, especially for those trained for secret-learning tasks. In this paper, we propose deep network steganography for the covert communication of DNN models. Unlike the existing steganography schemes which focus on the subtle modification of the cover data to accommodate the secrets, our scheme is learning task oriented, where the learning task of the secret DNN model (termed as secret-learning task) is disguised into another ordinary learning task conducted in a stego DNN model (termed as stego-learning task). To this end, we propose a gradient-based filter insertion scheme to insert interference filters into the important positions in the secret DNN model to form a stego DNN model. These positions are then embedded into the stego DNN model using a key by side information hiding. Finally, we activate the interference filters by a partial optimization strategy, such that the generated stego DNN model works on the stego-learning task. We conduct the experiments on both the intra-task steganography and inter-task steganography (i.e., the secret and stego-learning tasks belong to the same and different categories), both of which demonstrate the effectiveness of our proposed method for covert communication of DNN models.
</details>
<details>
<summary>摘要</summary>
随着深度神经网络（DNN）的广泛应用，如何在公共频道上不显地传输已训练的DNN模型引发了关注，尤其是那些用于秘密学习任务的模型。在这篇论文中，我们提出了深度网络隐藏（DNN隐藏），用于不显地通信DNN模型。与现有的隐藏方案不同，我们的方案是任务 oriented，其中秘密学习任务（秘密学习任务）被隐藏到另一个普通的学习任务（隐藏学习任务）中。为此，我们提出了一种梯度基于的筛选插入方案，将重要的位置在秘密DNN模型中插入干扰筛选器，形成一个隐藏DNN模型。这些位置然后被嵌入到隐藏DNN模型中使用钥匙，并且使用侧信息隐藏。最后，我们使用部分优化策略启动干扰筛选器，使得生成的隐藏DNN模型在隐藏学习任务上工作。我们对两种情况进行实验：内任务隐藏（i.e., 秘密任务和隐藏学习任务属于同一类）和间任务隐藏（i.e., 秘密任务和隐藏学习任务属于不同类），两者均显示了我们提出的方法的效iveness。
</details></li>
</ul>
<hr>
<h2 id="Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration"><a href="#Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration" class="headerlink" title="Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration"></a>Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03421">http://arxiv.org/abs/2307.03421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/registration-nice-trans">https://github.com/mungomeng/registration-nice-trans</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim</li>
<li>for: 这paper是为了提出一种基于深度学习的非迭代粗细到细粒度图像匹配算法。</li>
<li>methods: 这paper使用了一种名为NICE-Trans的非迭代粗细到细粒度图像匹配网络，该网络结合了矩阵变换和扩展抽取器来实现粗细到细粒度的图像匹配。</li>
<li>results: 实验结果表明，NICE-Trans可以在七个公共数据集上击败现有的图像匹配方法，并且在注重精度和运行时间之间取得了一个良好的平衡。<details>
<summary>Abstract</summary>
Image registration is a fundamental requirement for medical image analysis. Deep registration methods based on deep learning have been widely recognized for their capabilities to perform fast end-to-end registration. Many deep registration methods achieved state-of-the-art performance by performing coarse-to-fine registration, where multiple registration steps were iterated with cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE) registration methods have been proposed to perform coarse-to-fine registration in a single network and showed advantages in both registration accuracy and runtime. However, existing NICE registration methods mainly focus on deformable registration, while affine registration, a common prerequisite, is still reliant on time-consuming traditional optimization-based methods or extra affine registration networks. In addition, existing NICE registration methods are limited by the intrinsic locality of convolution operations. Transformers may address this limitation for their capabilities to capture long-range dependency, but the benefits of using transformers for NICE registration have not been explored. In this study, we propose a Non-Iterative Coarse-to-finE Transformer network (NICE-Trans) for image registration. Our NICE-Trans is the first deep registration method that (i) performs joint affine and deformable coarse-to-fine registration within a single network, and (ii) embeds transformers into a NICE registration framework to model long-range relevance between images. Extensive experiments with seven public datasets show that our NICE-Trans outperforms state-of-the-art registration methods on both registration accuracy and runtime.
</details>
<details>
<summary>摘要</summary>
医疗影像分析中的图像 регистрация是一项基本要求。基于深度学习的深度 регистрация方法在最近几年内得到了广泛的认可，因为它们可以快速完成端到端的 регистрация。许多深度REGISTRATION方法在多个REGISTRATION步骤中采用了隐式的卷积神经网络，以实现粗细到细节的REGISTRATION。然而，现有的NICEREGISTRATION方法主要关注于弹性REGISTRATION，而平移REGISTRATION，是医疗影像分析中非常常见的前提，仍然是通过时间消耗的传统优化方法或额外的平移REGISTRATION网络来实现。此外，现有的NICEREGISTRATION方法受到卷积神经网络的本质性局部性的限制。使用变换器可能解决这个限制，因为它们可以捕捉图像之间的长距离相关性。但是，使用变换器来进行NICEREGISTRATION的好处尚未得到了足够的探讨。在本研究中，我们提出了一种Non-Iterative Coarse-to-finE Transformer网络（NICE-Trans），用于图像REGISTRATION。我们的NICE-Trans是第一个在单个网络中同时实现了平移和弹性的粗细到细节REGISTRATION，以及在NICEREGISTRATION框架中使用变换器来模型图像之间的长距离相关性。我们对七个公共数据集进行了广泛的实验，结果表明，我们的NICE-Trans在REGISTRATION精度和运行时间两个方面都超过了当前的REGISTRATION方法。
</details></li>
</ul>
<hr>
<h2 id="QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance"><a href="#QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance" class="headerlink" title="QI2 – an Interactive Tool for Data Quality Assurance"></a>QI2 – an Interactive Tool for Data Quality Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03419">http://arxiv.org/abs/2307.03419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Geerkens, Christian Sieberichs, Alexander Braun, Thomas Waschulzik</li>
<li>for: 本研究旨在提高机器学习系统和大数据的数据质量，以满足欧洲委员会的AI法案的数据质量要求。</li>
<li>methods: 本研究提出了一种新的数据质量检查方法，可以检查多个数据质量方面的数据。这种方法可以量化数据质量要求，并在小例子数据集上验证了其效果。</li>
<li>results: 本研究在well known MNIST数据集上应用了这种方法，并通过示例数据集展示了其工作原理和优势。<details>
<summary>Abstract</summary>
The importance of high data quality is increasing with the growing impact and distribution of ML systems and big data. Also the planned AI Act from the European commission defines challenging legal requirements for data quality especially for the market introduction of safety relevant ML systems. In this paper we introduce a novel approach that supports the data quality assurance process of multiple data quality aspects. This approach enables the verification of quantitative data quality requirements. The concept and benefits are introduced and explained on small example data sets. How the method is applied is demonstrated on the well known MNIST data set based an handwritten digits.
</details>
<details>
<summary>摘要</summary>
“高品质数据的重要性在机器学习系统和大数据的普及和影响力增长之际日益增加。欧盟委员会的AI法案也将提出严格的法律要求，尤其是在安全相关的机器学习系统上。本文介绍一种新的方法，以支持多种数据质量层面的质量确保过程。这种方法可以verify数据质量的量化要求。本文将 introduce和解释这个概念，并使用小型示例数据集来说明其工作方式。在著名的MNIST数据集上，我们将说明如何应用这个方法。”Here's the translation in Traditional Chinese:“高品质数据的重要性在机器学习系统和大数据的普及和影响力增长之际日益增加。欧盟委员会的AI法案也将提出严格的法律要求，尤其是在安全相关的机器学习系统上。本文介绍一种新的方法，以支持多种数据质量层面的质量确保过程。这种方法可以verify数据质量的量化要求。本文将 introduce和解释这个概念，并使用小型示例数据集来说明其工作方式。在著名的MNIST数据集上，我们将说明如何应用这个方法。”
</details></li>
</ul>
<hr>
<h2 id="Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning"><a href="#Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning" class="headerlink" title="Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning"></a>Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03406">http://arxiv.org/abs/2307.03406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilai Zeng, Ce Zhang, Shijie Wang, Chen Sun</li>
<li>for: 研究 whether sequence modeling can condense trajectories into useful representations for policy learning.</li>
<li>methods: 采用两阶段框架，首先使用序列模型技术简化轨迹数据，然后使用这些表示学习策略和愿景。</li>
<li>results: 在AntMaze、FrankaKitchen和Locomotion环境中进行了广泛的实验，发现序列模型对决策任务有显著影响，并且GCPC学习了一个目标状态相关的含义 reprehenstion，具有竞争性的性能。<details>
<summary>Abstract</summary>
Recent work has demonstrated the effectiveness of formulating decision making as a supervised learning problem on offline-collected trajectories. However, the benefits of performing sequence modeling on trajectory data is not yet clear. In this work we investigate if sequence modeling has the capability to condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques, and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an "implicit planner", and enables competitive performance on all three benchmarks.
</details>
<details>
<summary>摘要</summary>
To achieve this, we use a two-stage framework that first summarizes trajectories using sequence modeling techniques and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework.Within this framework, we introduce Goal-Conditioned Predictive Coding (GCPC), an approach that provides powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen, and Locomotion environments and find that sequence modeling has a significant impact on some decision-making tasks. Additionally, we demonstrate that GCPC learns a goal-conditioned latent representation of the future, which serves as an "implicit planner" and enables competitive performance on all three benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs"><a href="#Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs" class="headerlink" title="Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs"></a>Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03393">http://arxiv.org/abs/2307.03393</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CurryTang/Graph-LLM">https://github.com/CurryTang/Graph-LLM</a></li>
<li>paper_authors: Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, Jiliang Tang</li>
<li>for: 本文探讨了使用大语言模型（LLMs）在图机器学习中的潜在作用，特别是节点分类任务中的两种可能的管道：LLMs-as-Enhancers 和 LLMs-as-Predictors。</li>
<li>methods: 本文采用了两种管道进行研究：一是使用 LLMs 增强节点的文本特征，然后通过 GNNs 进行预测；二是直接使用 LLMs 作为独立预测器。</li>
<li>results: 经过系统的实验研究，本文发现了一些原创的观察和新的发现，包括使用 LLMs 可以提高节点分类的准确率和提高 GNNs 的性能。<details>
<summary>Abstract</summary>
Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at https://github.com/CurryTang/Graph-LLM.
</details>
<details>
<summary>摘要</summary>
学习图有吸引了巨大的注意力，因为它在实际应用中有广泛的应用前景。最受欢迎的图学习管道是使用图神经网络（GNNs），并使用文本节点特征的浅层嵌入，但这有限制在总体知识和深刻Semantic理解方面。在最近几年，大型自然语言模型（LLMs）已经被证明具有广泛的通用知识和强大的Semantic理解能力，这些能力在处理文本数据方面已经引起了革命。在这篇论文中，我们想要探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究两种可能的管道：LLMs-as-Enhancers和LLMs-as-Predictors。前者利用LLMs来增强节点的文本特征，然后通过GNNs生成预测。后者尝试直接使用LLMs作为独立预测器。我们在不同的设置下进行了系统的研究，从广泛的实验结果中，我们得到了原创的观察和新的发现，这些发现开启了新的可能性和建议，并指向了可以利用LLMs来学习图的新的方向。我们的代码和数据集可以在https://github.com/CurryTang/Graph-LLM上获取。
</details></li>
</ul>
<hr>
<h2 id="On-Formal-Feature-Attribution-and-Its-Approximation"><a href="#On-Formal-Feature-Attribution-and-Its-Approximation" class="headerlink" title="On Formal Feature Attribution and Its Approximation"></a>On Formal Feature Attribution and Its Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03380">http://arxiv.org/abs/2307.03380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ffattr/ffa">https://github.com/ffattr/ffa</a></li>
<li>paper_authors: Jinqiang Yu, Alexey Ignatiev, Peter J. Stuckey</li>
<li>for: 提高形式XAI的应用范围和效能，对feature attribution进行正式阐明和评估。</li>
<li>methods: 基于正式阐明数学基础的feature attribution方法，使用正式阐明分析器架构，并提出一个简洁的形式阐明方法。</li>
<li>results: 在实验中，提出的简洁形式阐明方法可以实现高精度的feature attribution，并且比以往的方法更具有实用性和可scalability。<details>
<summary>Abstract</summary>
Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution problem. Additionally, a formal explanation despite being formally sound is typically quite large, which hampers its applicability in practical settings. Motivated by the above, this paper proposes a way to apply the apparatus of formal XAI to the case of feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over the existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper then proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to the existing feature attribution algorithms not only in terms of feature importance and but also in terms of their relative order.
</details>
<details>
<summary>摘要</summary>
Motivated by these limitations, this paper proposes a way to apply formal XAI to feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to existing feature attribution algorithms in terms of feature importance and relative order.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Ground-Vehicle-Path-Following-in-Game-AI"><a href="#Efficient-Ground-Vehicle-Path-Following-in-Game-AI" class="headerlink" title="Efficient Ground Vehicle Path Following in Game AI"></a>Efficient Ground Vehicle Path Following in Game AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03379">http://arxiv.org/abs/2307.03379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rodrigue de Schaetzen, Alessandro Sestini</li>
<li>for: 这篇研究目的是为游戏AI中的地面车辆设计一个高效的路径追踪解决方案。</li>
<li>methods: 我们使用已有技术加以改进，设计了一个简单的解决方案，并调整参数以获得高效的benchmark路径追踪器。我们的解决方案特别注重计算路径曲率的 quadratic Bezier 曲线。</li>
<li>results: 我们透过在一个首人射击游戏中进行了多种测试enario，评估了提案的路径追踪器的效果和可靠性。与现有的路径追踪解决方案相比，我们获得了70%的缩减在统计上的困难事件。<details>
<summary>Abstract</summary>
This short paper presents an efficient path following solution for ground vehicles tailored to game AI. Our focus is on adapting established techniques to design simple solutions with parameters that are easily tunable for an efficient benchmark path follower. Our solution pays particular attention to computing a target speed which uses quadratic Bezier curves to estimate the path curvature. The performance of the proposed path follower is evaluated through a variety of test scenarios in a first-person shooter game, demonstrating its effectiveness and robustness in handling different types of paths and vehicles. We achieved a 70% decrease in the total number of stuck events compared to an existing path following solution.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="All-in-One-Exploring-Unified-Vision-Language-Tracking-with-Multi-Modal-Alignment"><a href="#All-in-One-Exploring-Unified-Vision-Language-Tracking-with-Multi-Modal-Alignment" class="headerlink" title="All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment"></a>All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03373">http://arxiv.org/abs/2307.03373</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/983632847/All-in-One">https://github.com/983632847/All-in-One</a></li>
<li>paper_authors: Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang</li>
<li>for: 提高视觉语言跟踪器的性能，使其能够更好地处理复杂的场景，如同源扰动和极端照明。</li>
<li>methods: 提出了一个All-in-One框架，将视觉和语言信号直接混合，并使用一个统一的变换块来学习协同提取和交互。还引入了一种多Modal匹配模块，使用交叉modal和自modal对比目标来提供更有理性的表示。</li>
<li>results: 经过广泛的实验，在五个 benchmark上都达到了现有状态 искусственный智能的最高水平，并且比之前的方法更加高效和可靠。<details>
<summary>Abstract</summary>
Current mainstream vision-language (VL) tracking framework consists of three parts, \ie a visual feature extractor, a language feature extractor, and a fusion model. To pursue better performance, a natural modus operandi for VL tracking is employing customized and heavier unimodal encoders, and multi-modal fusion models. Albeit effective, existing VL trackers separate feature extraction and feature integration, resulting in extracted features that lack semantic guidance and have limited target-aware capability in complex scenarios, \eg similar distractors and extreme illumination. In this work, inspired by the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks, we propose an All-in-One framework, which learns joint feature extraction and interaction by adopting a unified transformer backbone. Specifically, we mix raw vision and language signals to generate language-injected vision tokens, which we then concatenate before feeding into the unified backbone architecture. This approach achieves feature integration in a unified backbone, removing the need for carefully-designed fusion modules and resulting in a more effective and efficient VL tracking framework. To further improve the learning efficiency, we introduce a multi-modal alignment module based on cross-modal and intra-modal contrastive objectives, providing more reasonable representations for the unified All-in-One transformer backbone. Extensive experiments on five benchmarks, \ie OTB99-L, TNL2K, LaSOT, LaSOT$_{\rm Ext}$ and WebUAV-3M, demonstrate the superiority of the proposed tracker against existing state-of-the-arts on VL tracking. Codes will be made publicly available.
</details>
<details>
<summary>摘要</summary>
当前主流视觉语言（VL）跟踪框架包括三部分：视觉特征提取器、语言特征提取器和 fusions 模型。为了提高性能，常见的VL跟踪方法是采用自定义和更重的单模态编码器，以及多模态融合模型。虽然有效，现有VL跟踪器在特征提取和特征融合之间分离，导致提取出的特征缺乏 semantic 指导和具有有限的目标意识能力在复杂情况下，例如类似干扰和极端照明。在这种工作中，我们Draw inspiration from the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks，我们提出了一个All-in-One框架，该框架通过采用统一的 transformer 脊梁学习联合特征提取和交互。具体来说，我们将原始视觉和语言信号混合生成语言注入视觉 токен，然后将这些 токен concatenate 在统一脊梁架构中。这种方法实现了特征融合在统一脊梁中，从而废弃了需要 precisely 设计融合模块，并且导致更有效和高效的VL跟踪框架。为了进一步提高学习效率，我们引入了基于交叉模式和内部对比目标的多模态匹配模块，为统一 All-in-One transformer 脊梁提供更合理的表示。广泛的实验在五个标准测试集，即 OTB99-L、TNL2K、LaSOT、LaSOT$_{\rm Ext}$ 和 WebUAV-3M 上，证明我们的跟踪器在VL跟踪中超过现有状况。代码将公开。
</details></li>
</ul>
<hr>
<h2 id="Adaptation-and-Communication-in-Human-Robot-Teaming-to-Handle-Discrepancies-in-Agents’-Beliefs-about-Plans"><a href="#Adaptation-and-Communication-in-Human-Robot-Teaming-to-Handle-Discrepancies-in-Agents’-Beliefs-about-Plans" class="headerlink" title="Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents’ Beliefs about Plans"></a>Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents’ Beliefs about Plans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03362">http://arxiv.org/abs/2307.03362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuening Zhang, Brian C. Williams</li>
<li>for: 本研究旨在解决人机团队中agent之间不具备共同认知的问题，即agent可能遵循不同的习惯或只有一些agent知道的可能性。</li>
<li>methods: 本研究使用epistemic逻辑来帮助agent理解对方的信念不同，并动态计划行动以适应或通信以解决这些不同。</li>
<li>results: 我们的研究表明，使用我们提出的方法可以提高人机团队的成功率和扩展性，而不需要共同认知。<details>
<summary>Abstract</summary>
When agents collaborate on a task, it is important that they have some shared mental model of the task routines -- the set of feasible plans towards achieving the goals. However, in reality, situations often arise that such a shared mental model cannot be guaranteed, such as in ad-hoc teams where agents may follow different conventions or when contingent constraints arise that only some agents are aware of. Previous work on human-robot teaming has assumed that the team has a set of shared routines, which breaks down in these situations. In this work, we leverage epistemic logic to enable agents to understand the discrepancy in each other's beliefs about feasible plans and dynamically plan their actions to adapt or communicate to resolve the discrepancy. We propose a formalism that extends conditional doxastic logic to describe knowledge bases in order to explicitly represent agents' nested beliefs on the feasible plans and state of execution. We provide an online execution algorithm based on Monte Carlo Tree Search for the agent to plan its action, including communication actions to explain the feasibility of plans, announce intent, and ask questions. Finally, we evaluate the success rate and scalability of the algorithm and show that our agent is better equipped to work in teams without the guarantee of a shared mental model.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:当机器人合作完成任务时，重要的是他们有一个共享的心理模型，即任务routines的可行方案集。然而，在现实中，情况经常出现无法保证这种共享心理模型的情况，例如在协作团队中机器人可能遵循不同的 Convention或者在特殊的情况下存在只有一些机器人知道的隐式约束。过去的人机合作工作假设了团队有一组共享的routines，这会导致问题。在这种情况下，我们利用epistemic逻辑来让机器人理解对方可能的信念不同，并在运行时动态规划行动，以适应或通信解决这些不同。我们提出了一种基于 conditional doxastic逻辑的形式来描述知识库，以显式地表示机器人嵌套的信念结构。我们提供了基于Monte Carlo Tree Search的在线执行算法，让机器人在执行时计划行动，包括通信行动来解释计划的可行性、宣布意图和提问。最后，我们评估了算法的成功率和可扩展性，并显示我们的机器人在不假设共享心理模型的情况下更能够合作。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context"><a href="#Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context" class="headerlink" title="Evaluating Biased Attitude Associations of Language Models in an Intersectional Context"></a>Evaluating Biased Attitude Associations of Language Models in an Intersectional Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03360">http://arxiv.org/abs/2307.03360</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shivaomrani/llm-bias">https://github.com/shivaomrani/llm-bias</a></li>
<li>paper_authors: Shiva Omrani Sabbaghi, Robert Wolfe, Aylin Caliskan</li>
<li>for: 这个论文旨在研究英语语言模型中各种社会群体的偏见。</li>
<li>methods: 研究使用了一种句子模板，以提供多元化的社会背景，以评估语言模型中各种社会群体的偏见。</li>
<li>results: 研究发现，语言模型对性别认同、社会阶层和性 orientation等社会群体的偏见最为明显。此外，研究还发现，最大和最高性能的语言模型也是最偏见的。<details>
<summary>Abstract</summary>
Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.
</details>
<details>
<summary>摘要</summary>
Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.Here's the translation in Traditional Chinese:语模型是根据大规模数据库进行训练，这些数据库中嵌入了心理学中documented的隐式偏见。在社交认知中，社会群体的态度偏好（愉悦度/不愉悦度）determine the biased attitudes towards groups and concepts。根据已有的文献，我们量化英语语模型中社会群体的valence association。我们研究年龄、教育、性别、身高、智商、文化程度、种族、宗教、性别、性向、社会阶层和身高等社会群体的偏见。我们使用 sentence template 提供的交叉sectional context，以 capture the valence subspace through contextualized word embeddings of language models。我们运用对嵌入偏见的方法，以量化语模型对于性别识别、社会阶层和性向信号的偏见。我们发现，Language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language。我们还发现，我们研究的最大和最好的模型也是最偏见的，因为它很好地捕捉了社会文化资料中的偏见。我们验证了偏见评估方法的正确性，通过在内在愉悦评估任务中进行过 performs。这种方法可以量化复杂的交叉偏见，并且对于历史偏见的延续而言，我们的方法具有设计正义的功能，因为它研究了语言中underrepresented的群体，如 трансGENDER和同性恋者。
</details></li>
</ul>
<hr>
<h2 id="TRAC-Trustworthy-Retrieval-Augmented-Chatbot"><a href="#TRAC-Trustworthy-Retrieval-Augmented-Chatbot" class="headerlink" title="TRAC: Trustworthy Retrieval Augmented Chatbot"></a>TRAC: Trustworthy Retrieval Augmented Chatbot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04642">http://arxiv.org/abs/2307.04642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo Li, Sangdon Park, Insup Lee, Osbert Bastani</li>
<li>for: 提高问答系统的准确性和可靠性</li>
<li>methods: 组合强制预测和全球测试来提供统计保证，并使用泊利投 optimize 选择全球测试的 гипер参数以最大化系统性能</li>
<li>results: 在 Natural Questions 数据集上实验表明，我们的方法可以提供预期的覆盖保证，同时最小化平均预测集大小<details>
<summary>Abstract</summary>
Although conversational AIs have demonstrated fantastic performance, they often generate incorrect information, or hallucinations. Retrieval augmented generation has emerged as a promising solution to reduce these hallucinations. However, these techniques still cannot guarantee correctness. Focusing on question answering, we propose a framework that can provide statistical guarantees for the retrieval augmented question answering system by combining conformal prediction and global testing. In addition, we use Bayesian optimization to choose hyperparameters of the global test to maximize the performance of the system. Our empirical results on the Natural Questions dataset demonstrate that our method can provide the desired coverage guarantee while minimizing the average prediction set size.
</details>
<details>
<summary>摘要</summary>
Note:* "hallucinations" in the original text is translated as " incorrect information" in Simplified Chinese, as "hallucinations" is not a commonly used term in Chinese.* "retrieval augmented generation" is translated as " Retrieval 增强生成" in Simplified Chinese, as "augmented" is not a commonly used term in Chinese.* "conformal prediction" is translated as "准确预测" in Simplified Chinese, as "conformal" is not a commonly used term in Chinese.* "global testing" is translated as "全球测试" in Simplified Chinese, as "global" is not a commonly used term in Chinese.* "average prediction set size" is translated as "平均预测集大小" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access"><a href="#Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access" class="headerlink" title="Federated Learning over a Wireless Network: Distributed User Selection through Random Access"></a>Federated Learning over a Wireless Network: Distributed User Selection through Random Access</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03758">http://arxiv.org/abs/2307.03758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Sun, Shiyao Ma, Ce Zheng, Songtao Wu, Tao Cui, Lingjuan Lyu</li>
<li>for: 降低联合学习（Federated Learning）在无线网络上的通信成本。</li>
<li>methods: 使用网络内置的分布式用户选择方法，利用无线资源竞争机制。</li>
<li>results: 可以快速达到与中央用户选择方法相似的快速协调。<details>
<summary>Abstract</summary>
User selection has become crucial for decreasing the communication costs of federated learning (FL) over wireless networks. However, centralized user selection causes additional system complexity. This study proposes a network intrinsic approach of distributed user selection that leverages the radio resource competition mechanism in random access. Taking the carrier sensing multiple access (CSMA) mechanism as an example of random access, we manipulate the contention window (CW) size to prioritize certain users for obtaining radio resources in each round of training. Training data bias is used as a target scenario for FL with user selection. Prioritization is based on the distance between the newly trained local model and the global model of the previous round. To avoid excessive contribution by certain users, a counting mechanism is used to ensure fairness. Simulations with various datasets demonstrate that this method can rapidly achieve convergence similar to that of the centralized user selection approach.
</details>
<details>
<summary>摘要</summary>
用户选择已成为联合学习（FL）过无线网络的关键因素，但中央用户选择会增加系统复杂性。这项研究提出了基于网络内置的分布式用户选择方法，利用无线资源竞争机制。假设CSMA机制为随机访问，我们在每轮训练中 manipulate 竞争窗口（CW）大小，以优先给予certain用户 radio资源。使用训练数据偏见为FL用户选择目标场景。偏见基于上一轮训练的全球模型与当前轮训练的本地模型之间的距离。为避免某些用户的过度贡献，使用计数机制保持公平。通过 simulate 多个数据集，我们发现这种方法可快达到与中央用户选择方法相似的快速启合。
</details></li>
</ul>
<hr>
<h2 id="Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation"><a href="#Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation" class="headerlink" title="Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation"></a>Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03315">http://arxiv.org/abs/2307.03315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Xue, Ahmed Sameh Said, Ziqi Xu, Hanyang Liu, Neel Shah, Hanqing Yang, Philip Payne, Chenyang Lu</li>
<li>for: 这篇论文是为了支持医疗决策而提出的，旨在预测患者是否需要ECMO治疗，以及ECMO治疗后的可能性。</li>
<li>methods: 这篇论文提出了一种新的方法，即Treatment Variational AutoEncoder（TVAE），用于个性化治疗分析。TVAE模型了患者的治疗决策和可能的结果，并通过重构正则化和半监督来缓解干扰和缺乏治疗案例的问题。</li>
<li>results: 实验结果表明，TVAE在具有多样化COVID-19患者数据集上比州当前的治疗效果模型更高效，可以预测患者的可能性和实际结果。<details>
<summary>Abstract</summary>
Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.
</details>
<details>
<summary>摘要</summary>
《 экстракорпоральная мембрананой оксигенация (ЭКМО) 是 COVID-19 患者们无法接受常规治疗的关键生命支持 modalities。然而，正确的治疗决策仍然是争议的，尚未确定哪些患者会受益于这种罕见和技术复杂的治疗选择。为支持临床决策，我们需要预测治疗需求和可能的治疗和无治疗响应。针对这种临床挑战，我们提出了 Treatment Variational AutoEncoder (TVAE)，一种新的个性化治疗分析方法。TVAE 特别是为了解决 ECMO 强烈的选择偏见和罕见治疗案例的模型挑战。TVAE 将治疗决策视为多级问题，模型病人的可能的治疗分配和实际和 counterfactual 结果为其内在特征，可以通过深度卷积模型表示。实际和 counterfactual 预测错误被解决通过重建规则和半监督，并且选择偏见和罕见治疗案例被减轻通过分解和分布匹配的积分空间和标签均衡生成策略。我们在两个实际 COVID-19 数据集上评估了 TVAE：一个国际数据集从 1651 家医院 across 63 个国家收集，另一个 institutional 数据集从 15 家医院收集。结果显示，TVAE 在异质 COVID-19 数据集上预测实际分数和 factual 结果的性能较为前者。其他实验也表明 TVAE 在个体治疗效果预测方面超越了现有最佳模型。
</details></li>
</ul>
<hr>
<h2 id="On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data"><a href="#On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data" class="headerlink" title="On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data"></a>On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03311">http://arxiv.org/abs/2307.03311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janis Keuper</li>
<li>for: 本论文主要针对Machine Learning领域中圆形卷积（Spherical Harmonic，SH）表示的数学表述，尤其是对于旋转不变和对称的特征和卷积。</li>
<li>methods: 本论文提出了SH表示的理论基础和实践方法，包括旋转不变和对称特征和卷积，以及将scalar SH表示扩展到vector field on sphere上的VH表示。</li>
<li>results: 本论文summarizes the works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres, and extends these methods to 3d vector fields on spheres.<details>
<summary>Abstract</summary>
The mathematical representations of data in the Spherical Harmonic (SH) domain has recently regained increasing interest in the machine learning community. This technical report gives an in-depth introduction to the theoretical foundation and practical implementation of SH representations, summarizing works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. In extension, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), providing the same capabilities for 3d vector fields on spheres
</details>
<details>
<summary>摘要</summary>
Recently, the mathematical representations of data in the Spherical Harmonic (SH) domain have gained increasing interest in the machine learning community. This technical report provides an in-depth introduction to the theoretical foundation and practical implementation of SH representations, including works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. Additionally, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), allowing for 3D vector fields on spheres to have the same capabilities.Here's the word-for-word translation of the text into Simplified Chinese:近期，圆形哈密顿（SH）领域中数据的数学表示受到机器学习社区的越来越多的关注。本技术报告对SH表示的理论基础和实践进行了深入的介绍，包括对旋转不变和对称特征的研究，以及圆形上的信号卷积和精确相关性。此外，这些方法还被推广到 vectorial harmonics（VH）中，以便三维向量场在圆形上具有相同的能力。
</details></li>
</ul>
<hr>
<h2 id="S2vNTM-Semi-supervised-vMF-Neural-Topic-Modeling"><a href="#S2vNTM-Semi-supervised-vMF-Neural-Topic-Modeling" class="headerlink" title="S2vNTM: Semi-supervised vMF Neural Topic Modeling"></a>S2vNTM: Semi-supervised vMF Neural Topic Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04804">http://arxiv.org/abs/2307.04804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Xu, Jay Desai, Srinivasan Sengamedu, Xiaoyu Jiang, Francis Iannacci</li>
<li>for: 本研究旨在批处文本分类 зада务中提高效率和准确率，并允许使用少量关键词作为输入。</li>
<li>methods: 本研究提出了一种名为Semi-Supervised vMF Neural Topic Modeling（S2vNTM）的方法，它利用种子关键词来初始化主题，并通过关键词的模式来识别和优化主题的关键词集。</li>
<li>results: 在多个数据集上，S2vNTM的分类精度高于现有的半监督主题模型方法，而且速度至少 twice as fast as baselines。<details>
<summary>Abstract</summary>
Language model based methods are powerful techniques for text classification. However, the models have several shortcomings. (1) It is difficult to integrate human knowledge such as keywords. (2) It needs a lot of resources to train the models. (3) It relied on large text data to pretrain. In this paper, we propose Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM leverages the pattern of keywords to identify potential topics, as well as optimize the quality of topics' keywords sets. Across a variety of datasets, S2vNTM outperforms existing semi-supervised topic modeling methods in classification accuracy with limited keywords provided. S2vNTM is at least twice as fast as baselines.
</details>
<details>
<summary>摘要</summary>
语言模型基本方法是文本分类的强大技术。然而，这些模型有几个缺点。（1）它很难 интегра human knowledge，如关键词。（2）它需要训练模型很多资源。（3）它依赖于大量文本数据进行预训练。在这篇论文中，我们提出了半supervised vMF神经话题模型（S2vNTM）来解决这些困难。S2vNTM通过提供一些种子关键词来输入主题，并利用关键词的模式来确定主题的可能性，以及优化主题的关键词集。在多个数据集上，S2vNTM比现有的半supervised主题模型在分类精度方面表现出色，只需提供有限的关键词。此外，S2vNTM比基准方法快速。
</details></li>
</ul>
<hr>
<h2 id="A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores"><a href="#A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores" class="headerlink" title="A Vulnerability of Attribution Methods Using Pre-Softmax Scores"></a>A Vulnerability of Attribution Methods Using Pre-Softmax Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03305">http://arxiv.org/abs/2307.03305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlerma54/adversarial-attacks-on-saliency-maps">https://github.com/mlerma54/adversarial-attacks-on-saliency-maps</a></li>
<li>paper_authors: Miguel Lerma, Mirtha Lucas</li>
<li>for: 本研究探讨了一种类别神经网络输出解释方法的攻击方法。</li>
<li>methods: 本研究使用了小型修改模型来影响解释方法的输出，而不改变模型的输出。</li>
<li>results: 研究发现，这种修改方法可以导致解释方法的输出受到较大的影响，而无需改变模型的输出。<details>
<summary>Abstract</summary>
We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
</details>
<details>
<summary>摘要</summary>
我们讨论了一种类型的对应方法的漏洞，这种方法用于说明对应网络作为分类器的输出。已经知道这种网络受到了敌对攻击，这些攻击可能导致输入的无法识别的小变化，导致模型的输出变化。相反，我们在这里集中了对应方法的小修改会导致的效果，而不会改变模型的输出。
</details></li>
</ul>
<hr>
<h2 id="It-is-not-Sexually-Suggestive-It-is-Educative-Separating-Sex-Education-from-Suggestive-Content-on-TikTok-Videos"><a href="#It-is-not-Sexually-Suggestive-It-is-Educative-Separating-Sex-Education-from-Suggestive-Content-on-TikTok-Videos" class="headerlink" title="It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos"></a>It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03274">http://arxiv.org/abs/2307.03274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enfa George, Mihai Surdeanu</li>
<li>for: 本研究目的是为了创建一个多Modal数据集，以便分辨TikTok上的性 suggestive内容和虚拟性教育视频。</li>
<li>methods: 研究使用了TikTok上的视频URL和音频笔录，并采用了两种基于转换器的模型来分类视频。</li>
<li>results: 初步结果表明，分辨这些类型的视频是可学习的，但也是具有挑战性的。这些实验表明，这个数据集是有意义的，并邀请更多研究者来深入研究这个领域。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator's point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children's exposure to sexually suggestive videos has been shown to have adversarial effects on their development. Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable. The platform's current system removes or penalizes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments suggest that this dataset is meaningful and invites further study on the subject.
</details>
<details>
<summary>摘要</summary>
我们介绍SexTok数据集，这是一个包含TikTok视频被标记为性取向（由注释员看来）、性教育内容或者 neither 的多modal数据集。这样的数据集 необходимо用于解决TikTok上性取向内容和虚拟性教育视频的分类挑战。儿童接触性取向视频会对其发展产生有害影响。然而，虚拟性教育，特别是对LGBTQIA+社群更加重要的主题，对于儿童的性教育很有价值。 платформа当前的系统会将一些这些视频移除或处罚，尽管它们在不同的目的上服务。我们的数据集包含视频 URL，同时也有音频笔记。为验证其重要性，我们探索了两种基于 transformer 模型来分类视频。我们的初步结果表明，这种分类任务可以学习，但也是具有挑战性。这些实验表明，这个数据集是有意义的，并邀请进一步研究这个主题。
</details></li>
</ul>
<hr>
<h2 id="Vision-Language-Transformers-A-Survey"><a href="#Vision-Language-Transformers-A-Survey" class="headerlink" title="Vision Language Transformers: A Survey"></a>Vision Language Transformers: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03254">http://arxiv.org/abs/2307.03254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clayton Fields, Casey Kennington</li>
<li>for: 这个论文主要是为了探讨视Language模型的发展和应用。</li>
<li>methods: 这个论文使用了预训练的transformer架构，并通过将其应用到新任务上，以实现跨视与语言的模型。</li>
<li>results: 这个论文提供了视Language模型的广泛的研究和分析，以及其优点、局限性和未解决的问题。<details>
<summary>Abstract</summary>
Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations and some open questions that remain.
</details>
<details>
<summary>摘要</summary>
Computer vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform.  Recently, researchers have adapted the pre-trained transformer architecture introduced in vaswani2017attention to vision language modeling, which has greatly improved performance and versatility over previous vision language models. They do so by pre-training models on large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks that require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations, and some open questions that remain.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the standard Mandarin pronunciation and may not be exactly the same as the traditional Chinese used in Taiwan or other regions.
</details></li>
</ul>
<hr>
<h2 id="Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation"><a href="#Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation" class="headerlink" title="Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation"></a>Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05385">http://arxiv.org/abs/2307.05385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sully F. Chen, Zhicheng Guo, Cheng Ding, Xiao Hu, Cynthia Rudin</li>
<li>for: 本研究旨在提出一种可靠、有效、可解释的脉冲光谱学（PPG）信号质量评估和artefact分割方法，以提高PPG信号的精度和可靠性。</li>
<li>methods: 本研究使用了一种小型、可解释的卷积核来学习PPG信号中的质量特征，并与现有的深度神经网络（DNN）方法进行比较。</li>
<li>results: 研究结果表明，该小型卷积核方法可以与DNN方法相比，具有类似或更好的性能，同时具有许多个数据点的优势，如快速、可靠、可解释。<details>
<summary>Abstract</summary>
Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and interpretable signal quality assessment and artifact segmentation on low-power devices.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It"><a href="#Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It" class="headerlink" title="Push Past Green: Learning to Look Behind Plant Foliage by Moving It"></a>Push Past Green: Learning to Look Behind Plant Foliage by Moving It</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03175">http://arxiv.org/abs/2307.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Zhang, Saurabh Gupta</li>
<li>for: 这个论文旨在提出数据驱动的方法，用于自动化农业应用程序（如检查、评估、摘取水果）中 manipulating 植物叶子和枝干以查看后方空间。</li>
<li>methods: 这篇论文使用自我超级vision方法进行训练，使用SRPNet神经网络预测执行候选动作后可以查看的空间。</li>
<li>results: 实验表明，对于 synthetic 蔷薇和实际的 драцена植物，PPG方法在5个设定下表现出色，而SRPNet神经网络在5个设定下都超过了手动设计的探索方法和相关的ablations。<details>
<summary>Abstract</summary>
Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations. Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations.
</details>
<details>
<summary>摘要</summary>
自主农业应用（如检查、辐射类型、摘果）需要操作植物叶子和枝干，以便从后方看到叶子和枝干。但是叶子和枝干之间的部分可见性、极度拥挤、薄肉和植物的不确定geometry和动力学使得这种操作变得困难。我们通过数据驱动方法解决这些挑战。我们使用自我监督来训练SRPNet，一个神经网络，该网络预测执行给定植物的候选动作后可见的空间。我们使用SRPNet与十字积分法预测有效的动作，以便逐步揭示植物下方的空间。此外，SRPNet不仅预测执行动作后可见的空间量，还预测其在哪里被揭示，因此我们可以执行一系列的动作，以逐步揭示更多的植物下方的空间。我们在一个 sintetic（葡萄）和一个实际的植物（ драцена）上进行了在物理测试床上的实验，并在5个设定中测试了我们的总方法，包括2个设定，以测试扩展到新的植物配置。我们的实验表明我们的总方法PPG在比手工探索方法更有效，而SRPNet在手工动力学模型和相关的ablations中也表现出了效果。
</details></li>
</ul>
<hr>
<h2 id="LEO-Learning-Efficient-Orderings-for-Multiobjective-Binary-Decision-Diagrams"><a href="#LEO-Learning-Efficient-Orderings-for-Multiobjective-Binary-Decision-Diagrams" class="headerlink" title="LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams"></a>LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03171">http://arxiv.org/abs/2307.03171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khalil-research/leo">https://github.com/khalil-research/leo</a></li>
<li>paper_authors: Rahul Patel, Elias B. Khalil</li>
<li>for: 这个研究是为了解决多对象数据分析问题中的问题，特别是用BDDs来解决这些问题。</li>
<li>methods: 这个研究使用了BDDs来解决多对象数据分析问题，并且使用了一些新的变量排序方法来提高BDDs的效率和精度。</li>
<li>results: 研究发现，使用LEO这个超级vised学习方法可以快速地找到高效的变量排序方法，并且可以将PF枚举时间缩短。实验结果显示，LEO比常用的排序方法和算法配置更快速地完成PF枚举。<details>
<summary>Abstract</summary>
Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time. However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering. To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time. Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is ~30-300% and ~10-200% faster at PF enumeration than common ordering strategies and algorithm configuration. Our code and instances are available at https://github.com/khalil-research/leo.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用二进制决策图（BDD）的方法最近在多目标整数编程问题上实现了状态的杰出成绩。BDD中变量的排序可以影响其大小和含约环境中的缓和约束的质量。我们首先示出变量排序对多目标饶褔问题的Pareto前列（PF）枚举时间有着相似的影响。这表明需要开发可以提高多目标BDD方法的可扩展性的变量排序方法。为此，我们 derivate一个基于变量评价函数的新参数配置空间，该空间是线性的，且可以使用一小组简单易计算的变量特征来实现。我们表明该配置空间可以使用黑盒优化器高效地探索，并且可以快速找到好的排序，从而减少PF枚举时间。然而，黑盒优化器的计算开销会超过减少PF枚举时间的好变量排序的效果。为了解决这个问题，我们提出了LEO，一种监督学习方法，用于找到高效的变量排序，从而减少PF枚举时间。我们的实验结果表明，LEO比普通的排序策略和算法配置更快，在饶褔问题的 benchmark 集中，LEO的速度比Common ordering strategies和algorithm configuration快约30-300%和10-200%。我们的代码和实例可以在https://github.com/khalil-research/leo上获取。
</details></li>
</ul>
<hr>
<h2 id="Focused-Transformer-Contrastive-Training-for-Context-Scaling"><a href="#Focused-Transformer-Contrastive-Training-for-Context-Scaling" class="headerlink" title="Focused Transformer: Contrastive Training for Context Scaling"></a>Focused Transformer: Contrastive Training for Context Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03170">http://arxiv.org/abs/2307.03170</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cstankonrad/long_llama">https://github.com/cstankonrad/long_llama</a></li>
<li>paper_authors: Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, Piotr Miłoś</li>
<li>for: 提高大型语言模型在长 context 下的表现</li>
<li>methods: 通过对注意层进行修改，让其可以访问外部存储，并通过对应的键值对进行映射，提高模型的表现</li>
<li>results: 通过提出 Focused Transformer (FoT) 技术，可以延长效 context 的长度，并且可以细化现有大规模模型，以提高其在长 context 下的表现，并且在 passkey 检索任务中，模型可以 успеreich 处理 $256 k$ 长 context。<details>
<summary>Abstract</summary>
Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context. This is demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context. We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有卓越的Contextualized Embedding能力，可以将新信息给适当地融入到模型中。然而，这种方法的潜力经常受到Context Length的限制。为了解决这个问题，我们将Attention层给了External Memory的存取权，这个External Memory包含了(键、值)对。然而，当文档数量增加时，相关的键数量减少，使模型更加倾向于关注无关的键。我们称这个问题为分心问题，因为不同的Semantic Value之间的键可能会 overlap，使其困难分辨。为了解决这个问题，我们引入了Focused Transformer（FoT）技术，这是一种以Contrastive Learning为灵感的训练过程。这种新的方法可以将(键、值)空间的结构改善，从而延长Context Length。我们的方法可以让已有的大规模模型进行微调，以增加其有效Context Length。我们给了$3B$和$7B$ OpenLLaMA检查点进行微调，将其称为LongLLaMA。这些LongLLaMA模型在需要长Context的任务中表现出色。我们还证明了LongLLaMA模型可以efficaciously manage $256 k$ Context Length for passkey retrieval。
</details></li>
</ul>
<hr>
<h2 id="BrickPal-Augmented-Reality-based-Assembly-Instructions-for-Brick-Models"><a href="#BrickPal-Augmented-Reality-based-Assembly-Instructions-for-Brick-Models" class="headerlink" title="BrickPal: Augmented Reality-based Assembly Instructions for Brick Models"></a>BrickPal: Augmented Reality-based Assembly Instructions for Brick Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03162">http://arxiv.org/abs/2307.03162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shi, Xiaofeng Zhang, Ran zhang, Zhou Yang, Xiao Tang, Hongni Ye, Yi Wu</li>
<li>for: 帮助用户更加快速和精准地组装乐高积木，解决传统手动微调和纸质指南的问题。</li>
<li>methods: 利用可见语言处理（NLP）技术生成可能的组装序列，并在扩展现实头戴显示器提供实时指导。</li>
<li>results: 比传统组装方法更高效，NLP算法生成的组装序列可以达到同样的可用性。<details>
<summary>Abstract</summary>
The assembly instruction is a mandatory component of Lego-like brick sets.The conventional production of assembly instructions requires a considerable amount of manual fine-tuning, which is intractable for casual users and customized brick sets.Moreover, the traditional paper-based instructions lack expressiveness and interactivity.To tackle the two problems above, we present BrickPal, an augmented reality-based system, which visualizes assembly instructions in an augmented reality head-mounted display. It utilizes Natural Language Processing (NLP) techniques to generate plausible assembly sequences, and provide real-time guidance in the AR headset.Our user study demonstrates BrickPal's effectiveness at assisting users in brick assembly compared to traditional assembly methods. Additionally, the NLP algorithm-generated assembly sequences achieve the same usability with manually adapted sequences.
</details>
<details>
<summary>摘要</summary>
assembly instruction是乐高类积木sets中必备的一部分。传统生产assembly instruction需要较多的手动精度调整，这对普通用户和自定义积木sets来说是不可接受的。此外，传统的纸面指令缺乏表达力和互动性。为解决这两个问题，我们提出了BrickPal，一种基于扩展现实技术的系统，可以在扩展现实头戴display中可见化 assembly instruction。它利用自然语言处理（NLP）技术生成可能的积木组合序列，并在AR头戴display中提供实时指导。我们的用户研究表明，BrickPal可以较传统Assembly方法更好地帮助用户组装积木。此外，由NLP算法生成的积木组合序列与手动修改后的序列之间没有差异。
</details></li>
</ul>
<hr>
<h2 id="Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability"><a href="#Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability" class="headerlink" title="Distilling Large Vision-Language Model with Out-of-Distribution Generalizability"></a>Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03135">http://arxiv.org/abs/2307.03135</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuanlinli17/large_vlm_distillation_ood">https://github.com/xuanlinli17/large_vlm_distillation_ood</a></li>
<li>paper_authors: Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su</li>
<li>for: 这个研究的目的是将大型描述语言模型转换为轻量级快速模型，以便在有限的资源和时间上实现实际的应用。</li>
<li>methods: 这个研究使用了教师模型的描述语言表示空间内的学习，并将其转换为学生模型。它还提出了两个原则来增强学生的开 vocabulary out-of-distribution（OOD）泛化性：一是更好地模仿教师的描述语言表示空间，并谨慎地增强视语联系的一致性; 二是增强教师的语言表示具有有用和细部的Semantic Attribute，以便更好地区别不同的标签。</li>
<li>results: 这个研究的结果显示，使用了提出的方法可以实现零shot和几shot学生模型在开 vocabulary OOD分类任务中的显著改善，这说明了我们的提出的方法的有效性。<details>
<summary>Abstract</summary>
Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Code released at https://github.com/xuanlinli17/large_vlm_distillation_ood
</details>
<details>
<summary>摘要</summary>
大型视语模型已经实现出色的表现，但它们的大小和计算需求使其在有限的设备和时间上不太实用。模型缩小，将大型模型转换成更小、更快的模型，以保持其性能的方向是一个有前途的方向。这篇论文研究了将大教师视语模型中的视觉表示压缩到小学生模型中，使用小规模或中规模的数据集。尤其是这种研究强调了开放词汇 OUT-OF-DISTRIBUTION（OOD）泛化，这是之前的模型缩小文献中尚未得到足够的关注。我们提出了两个原则，一是在视觉表示空间上更好地模仿大教师，二是在视语对应上更加精细地协调大教师的语言表示。我们还提出了多个指标，并进行了广泛的实验来调查这些技术的效果。结果表明，我们的提议方法可以在零shot和几shot情况下提高小学生模型的OOD泛化性能，这证明了我们的方法的有效性。代码可以在https://github.com/xuanlinli17/large_vlm_distillation_ood上下载。
</details></li>
</ul>
<hr>
<h2 id="Frontier-AI-Regulation-Managing-Emerging-Risks-to-Public-Safety"><a href="#Frontier-AI-Regulation-Managing-Emerging-Risks-to-Public-Safety" class="headerlink" title="Frontier AI Regulation: Managing Emerging Risks to Public Safety"></a>Frontier AI Regulation: Managing Emerging Risks to Public Safety</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03718">http://arxiv.org/abs/2307.03718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Markus Anderljung, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O’Keefe, Jess Whittlestone, Shahar Avin, Miles Brundage, Justin Bullock, Duncan Cass-Beggs, Ben Chang, Tantum Collins, Tim Fist, Gillian Hadfield, Alan Hayes, Lewis Ho, Sara Hooker, Eric Horvitz, Noam Kolt, Jonas Schuett, Yonadav Shavit, Divya Siddarth, Robert Trager, Kevin Wolf<br>for:这篇论文关注于所谓的”前沿AI”模型，即具有危险能力的基础模型，可能会对公共安全造成严重威胁。这类模型的管理带来了新的挑战，包括：不可预期的危险能力出现，难以防止已经部署的模型被违用，以及模型能力的普及。methods:作者提出了三个建议来管理前沿AI模型的开发和部署：（1）为前沿AI开发者设置标准，（2）要求开发者登记和报送相关信息，以便让监管部门有visibility into前沿AI开发过程，（3）确保模型的开发和部署符合安全标准。results:作者认为，互联网产业自律管理是重要的首先步骤，但是更广泛的社会讨论和政府干预将是必要的，以创建标准并确保其遵守。他们还提出了一些选择，包括授予监管机构执法权和前沿AI模型的执照制度。最后，作者提出了一些安全标准，包括在部署之前进行风险评估，外部审查模型行为，根据风险评估决定部署，以及在部署后监测和应对新的模型能力和用途信息。<details>
<summary>Abstract</summary>
Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term "frontier AI" models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deployment of frontier AI models. Industry self-regulation is an important first step. However, wider societal discussions and government intervention will be needed to create standards and to ensure compliance with them. We consider several options to this end, including granting enforcement powers to supervisory authorities and licensure regimes for frontier AI models. Finally, we propose an initial set of safety standards. These include conducting pre-deployment risk assessments; external scrutiny of model behavior; using risk assessments to inform deployment decisions; and monitoring and responding to new information about model capabilities and uses post-deployment. We hope this discussion contributes to the broader conversation on how to balance public safety risks and innovation benefits from advances at the frontier of AI development.
</details>
<details>
<summary>摘要</summary>
高度智能化模型具有巨大的社会价值，但社会需要积极管理这些模型的风险。在这篇论文中，我们关注于我们称为“前沿AI”模型：高度可能的基础模型，它们可能具有严重危害公共安全的能力。前沿AI模型提出了一系列挑战：危险能力可能会不料出现；不可预料地使用已经部署的模型；模型的能力很难控制。为了解决这些挑战，至少需要三种建筑物来规范前沿AI模型的发展：（1）为前沿AI开发者设置标准；（2）要求开发者注册并报告Frontier AI的开发进度；（3）确保Frontier AI模型的安全标准的实施和部署。互联网自律管理是重要的首先步骤，但社会讨论和政府干预将是必要的，以创建标准并确保遵从其中。我们考虑了许多选项，包括授权监管机构执法权和Frontier AI模型的许可证制度。最后，我们提出了一组安全标准，包括在部署之前进行风险评估；对模型行为进行外部审查；使用风险评估来决定部署的决策；以及在部署后监测和回应新的模型能力和使用信息。我们希望这篇论文能够贡献到AI技术的前沿发展中公共安全风险和创新奖励之间的平衡。
</details></li>
</ul>
<hr>
<h2 id="Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance"><a href="#Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance" class="headerlink" title="Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance"></a>Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03119">http://arxiv.org/abs/2307.03119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, Tie-Yan Liu</li>
<li>for: 本研究的目的是提出一种基于多智能体学习（MARL）的多订单执行方法，以优化股票交易的执行效率。</li>
<li>methods: 本研究使用了模型自适应学习（RL）方法，并在多智能体学习（MARL）框架下进行了优化。在实际市场数据上进行了实验，并通过学习多轮通信协议来提高协作效果。</li>
<li>results: 实验结果显示，使用本研究的方法可以在股票交易中提高执行效率，并且与传统的单个订单执行方法相比，具有更好的协作效果。<details>
<summary>Abstract</summary>
Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market. To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly. It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient. The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method.
</details>
<details>
<summary>摘要</summary>
执行订单是金融科学中的基本任务，旨在完成购买或售卖特定资产的交易订单。现代无模型学习（RL）技术提供了一种数据驱动的解决方案，但现有的工作都是优化单个订单的执行，忽略了实际情况下多个订单同时执行的现象，从而导致优化不足和偏见。在本文中，我们首先提出了多个代理RL（MARL）方法，用于多订单执行，考虑到实际约束。具体来说，我们对每个代理视为一个个人操作者，负责交易一个特定的订单，同时与别的代理进行交流和合作，以最大化总收益。但现有的MARL算法通常通过交换只有各自部分观察信息来进行交流，这在复杂的金融市场中是不具有效果的。为了提高协作，我们 THEN propose了一种可学习的多轮交流协议，用于代理之间交换意图动作，并根据此进行修改。它是通过一种新的动作价值评估方法来优化的，该方法是原始学习目标的可靠的延展。实验结果表明，我们的方法在两个实际市场的数据上显示出了显著性的提高，并 achieves 更好的协作效果。
</details></li>
</ul>
<hr>
<h2 id="Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings"><a href="#Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings" class="headerlink" title="Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings"></a>Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03212">http://arxiv.org/abs/2307.03212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiliang Chan, Qianqian Ren</li>
<li>for: 这篇论文旨在 Addressing the challenges of urban region embedding by proposing a Region-Wise Multi-View Representation Learning (ROMER) model.</li>
<li>methods: 该模型使用多视角相关性 capture 和全球图注意力网络学习城市区域表示。</li>
<li>results: 实验结果表明，ROMER 模型在两个下游任务中比前STATE-OF-THE-ART 方法提高了17%。<details>
<summary>Abstract</summary>
Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\% improvement.
</details>
<details>
<summary>摘要</summary>
<style>.Simplified Chinese {font-family: "Microsoft YaHei";}</style>城市区域嵌入是一个重要且具有挑战性的问题，由于城市数据的复杂性和不断变化。为了解决这些挑战，我们提出了多视图表示学习（ROMER），用于捕捉多视图依赖关系并学习表达城市区域的表示。我们的模型专注于从多个城市数据源上学习城市区域表示。首先，我们捕捉了流动人员趋势、 POI  semantics 和检查入动态的多视图相关性。然后，我们采用全球图注意网络来学习图中任意两个顶点的相似性。为了全面考虑和共享多视图特征，我们提出了两个阶段融合模块，以外部注意力学习多视图嵌入的权重。广泛的实验表明，我们的模型在实际 datasets 上的两个下游任务上比状态革命方法提高了17%。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Evaluation-of-Large-Language-Models"><a href="#A-Survey-on-Evaluation-of-Large-Language-Models" class="headerlink" title="A Survey on Evaluation of Large Language Models"></a>A Survey on Evaluation of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03109">http://arxiv.org/abs/2307.03109</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlgroupjlu/llm-eval-survey">https://github.com/mlgroupjlu/llm-eval-survey</a></li>
<li>paper_authors: Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie</li>
<li>for: The paper is written to provide a comprehensive review of evaluation methods for large language models (LLMs), with a focus on three key dimensions: what to evaluate, where to evaluate, and how to evaluate.</li>
<li>methods: The paper uses a survey-based approach to evaluate LLMs, covering various evaluation tasks, benchmarks, and methods.</li>
<li>results: The paper summarizes the success and failure cases of LLMs in different tasks, and highlights several future challenges that lie ahead in LLMs evaluation.Here is the same information in Simplified Chinese text:</li>
<li>for: 该论文是为了提供大语言模型（LLMs）评估方法的全面回顾，强调三个关键维度：评估任务、评估场景和评估方法。</li>
<li>methods: 论文使用问卷方式进行评估，涵盖了各种评估任务、标准套件和评估方法。</li>
<li>results: 论文总结了不同任务中 LLMs 的成功和失败案例，并指出了未来评估领域的一些挑战。<details>
<summary>Abstract</summary>
Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Domain-Adaptation-of-Sentence-Embeddings-Using-Adapters"><a href="#Efficient-Domain-Adaptation-of-Sentence-Embeddings-Using-Adapters" class="headerlink" title="Efficient Domain Adaptation of Sentence Embeddings Using Adapters"></a>Efficient Domain Adaptation of Sentence Embeddings Using Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03104">http://arxiv.org/abs/2307.03104</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sebischair/efficient-domain-adaptation-of-sentence-embeddings-using-adapters">https://github.com/sebischair/efficient-domain-adaptation-of-sentence-embeddings-using-adapters</a></li>
<li>paper_authors: Tim Schopf, Dennis N. Schneider, Florian Matthes</li>
<li>for: 用于域 adaptation of sentence embeddings</li>
<li>methods: 使用lightweight adapters for parameter-efficient domain adaptation</li>
<li>results: 可以达到1%的竞争性表现，只需要训练约3.6%的参数。Here is the full sentence in Simplified Chinese:</li>
<li>for: 这篇论文是为了域 adaptation of sentence embeddings而写的。</li>
<li>methods: 这篇论文使用了lightweight adapters来实现 parameter-efficient domain adaptation。</li>
<li>results: 这篇论文可以达到1%的竞争性表现，只需要训练约3.6%的参数。<details>
<summary>Abstract</summary>
Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always using the same base model and only exchanging the domain-specific adapters to adapt sentence embeddings to a specific domain. We show that using adapters for parameter-efficient domain adaptation of sentence embeddings yields competitive performance within 1% of a domain-adapted, entirely fine-tuned sentence embedding model while only training approximately 3.6% of the parameters.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Structure-Guided-Multi-modal-Pre-trained-Transformer-for-Knowledge-Graph-Reasoning"><a href="#Structure-Guided-Multi-modal-Pre-trained-Transformer-for-Knowledge-Graph-Reasoning" class="headerlink" title="Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning"></a>Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03591">http://arxiv.org/abs/2307.03591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Liang, Sihang Zhou, Yue Liu, Lingyuan Meng, Meng Liu, Xinwang Liu</li>
<li>for: 本研究旨在提出一种基于多模态知识图(MKG)的多模态预训练 transformer 模型(SGMPT)，以提高多模态知识图理解(KGR)的性能。</li>
<li>methods: 本研究使用了图结构编码器来编码知识图的结构特征，并设计了一种结构指导合并模块，通过两种不同的策略（加权汇和对齐约束）将结构信息注入到文本和图像特征中。</li>
<li>results: 实验结果表明，我们提出的 SGMPT 模型在 FB15k-237-IMG 和 WN18-IMG 上对多模态 KGR  Task 表现出色，超过了现有的状态码模型，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph Structure Guided Multimodal Pretrained Transformer for knowledge graph reasoning, termed SGMPT. Specifically, the graph structure encoder is adopted for structural feature encoding. Then, a structure-guided fusion module with two different strategies, i.e., weighted summation and alignment constraint, is first designed to inject the structural information into both the textual and visual features. To the best of our knowledge, SGMPT is the first MPT model for multimodal KGR, which mines the structural information underlying the knowledge graph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that our SGMPT outperforms existing state-of-the-art models, and prove the effectiveness of the designed strategies.
</details>
<details>
<summary>摘要</summary>
多Modal知识图(MKG)可以有效地提高多种下游任务的性能,如推荐系统和视觉问答系统。然而，大多数MKG都还不够完整，这些 incomplete MKG 仍然需要大量的研究和发展。在 current 的普通人工智能架构下, 预训练变换器模型在多Modal场景中受到了越来越多的关注。然而, 关于多Modal预训练变换器(MPT)的研究在知识图理解(KGR)方面仍然处于早期阶段。与其他多Modal数据不同的是, 知识图下的丰富结构信息仍然无法得到完全利用。大多数模型只是将知识图作为图结构来匹配图像和文本相关的实体。这种方式限制了他们的理解性能。为此, 我们提出了基于图 структуры的多Modal预训练变换器(SGMPT)。具体来说, SGMPT 使用图结构编码器来编码结构特征。然后, 我们设计了一种结构指导融合模块，通过两种不同的策略，即Weighted Sum 和Alignment Constraint，将结构信息注入到文本和视觉特征中。我们知道, SGMPT 是首个在多Modal KGR 中使用结构信息的 MPT 模型，从而提高了知识图理解的性能。我们在 FB15k-237-IMG 和 WN18-IMG 上进行了广泛的实验，并证明了我们的SGMPT 超过了现有的状态对模型，并证明了我们的设计策略的有效性。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media"><a href="#A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media" class="headerlink" title="A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media"></a>A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.06775">http://arxiv.org/abs/2307.06775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Feldman<br>for: 这项研究旨在开发一种多modal深度学习模型，用于判断社交媒体上的帖子是否推广精神饮食疾病。methods: 这项研究使用了Twitter上的标注数据集，并训练了12个深度学习模型。最终，研究人员发现了一种将RoBERTa自然语言处理模型和MaxViT图像分类模型进行融合的多modal模型，其精度和F1分数分别为95.9%和0.959。results: 这项研究发现，使用这种多modal模型可以在不使用人工智能技术的前提下，对社交媒体上的帖子进行分类。此外，研究人员还通过对Twitter上的八个哈希标签的未看过的帖子进行时间序分析，发现自2014年以来，社交媒体上的精神饮食疾病推广内容的相对含量在这些社区内逐渐减少。然而，到2018年，这些内容的增长或已经停止下降，或者又开始增长。<details>
<summary>Abstract</summary>
Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. This study aimed to create a multimodal deep learning model that can determine if a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViT fusion model, deployed to classify an unlabeled dataset of posts from the social media sites Tumblr and Reddit, generated results akin to those of previous research studies that did not employ artificial intelligence-based techniques, indicating that deep learning models can develop insights congruent to those of researchers. Additionally, the model was used to conduct a timeseries analysis of yet unseen Tweets from eight Twitter hashtags, uncovering that, since 2014, the relative abundance of content that promotes eating disorders has decreased drastically within those communities. Despite this reduction, by 2018, content that promotes eating disorders had either stopped declining or increased in ampleness anew on these hashtags.
</details>
<details>
<summary>摘要</summary>
A labeled dataset of tweets was collected from Twitter, and twelve deep learning models were trained and tested. The best-performing model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, achieving accuracy and F1 scores of 95.9% and 0.959, respectively. This model was then applied to classify unlabeled posts from Tumblr and Reddit, producing results similar to previous research studies that did not use AI-based techniques.Moreover, the model was used to conduct a time series analysis of unseen tweets from eight Twitter hashtags, revealing that the relative abundance of content that promotes eating disorders has decreased significantly since 2014 within these communities. However, by 2018, the content that promotes eating disorders had either leveled off or increased again on these hashtags.In conclusion, this study demonstrates that deep learning models can identify content that promotes eating disorders on social media, and the results can be used to monitor and understand the trends of eating disorder-related content online.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.AI_2023_07_07/" data-id="clogyj8ul000d7cra912ig5f6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.CL_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T11:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.CL_2023_07_07/">cs.CL - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Testing-the-Predictions-of-Surprisal-Theory-in-11-Languages"><a href="#Testing-the-Predictions-of-Surprisal-Theory-in-11-Languages" class="headerlink" title="Testing the Predictions of Surprisal Theory in 11 Languages"></a>Testing the Predictions of Surprisal Theory in 11 Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03667">http://arxiv.org/abs/2307.03667</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ethan Gotlieb Wilcox, Tiago Pimentel, Clara Meister, Ryan Cotterell, Roger P. Levy</li>
<li>for:  investigate the relationship between surprisal and reading times in eleven different languages, distributed across five language families.</li>
<li>methods: derive estimates from language models trained on monolingual and multilingual corpora, and test three predictions associated with surprisal theory.</li>
<li>results: all three predictions are borne out crosslinguistically, offering the most robust link to-date between information theory and incremental language processing across languages.Here’s the Chinese translation of the three information points:</li>
<li>for:  investigate the relationship between surprisal和阅读时间在 eleven different languages中，分布在 five language families中。</li>
<li>methods: 使用语言模型在 monolingual和多语言 corpus 上 derivation estimates, 并测试 three predictions associated with surprisal theory.</li>
<li>results: 所有 three predictions 在 crosslinguistics 中得到证实，提供了最为稳固的 link 到 date  между信息理论和语言处理过程中的 language。<details>
<summary>Abstract</summary>
A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages.
</details>
<details>
<summary>摘要</summary>
一个基本的心理语言学结论是，更难预测的词语需要更长的时间来处理。一种理论解释是《不意外性理论》（Hale, 2001；Levy, 2008），它量化了一个词语在上下文中的难度为其不意外性，即其负梯度邻近概率。尽管这些预测得到了广泛的复制，但大多数研究都集中在了一个非常窄的数据集上：英语Native speaker reading English texts。实际上，没有一个全面的多语言分析。我们在现有文献中填补这个空白，通过 investigate the relationship between surprisal and reading times in eleven different languages, distributed across five language families. We derive estimates from language models trained on monolingual and multilingual corpora, and test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages.
</details></li>
</ul>
<hr>
<h2 id="The-distribution-of-discourse-relations-within-and-across-turns-in-spontaneous-conversation"><a href="#The-distribution-of-discourse-relations-within-and-across-turns-in-spontaneous-conversation" class="headerlink" title="The distribution of discourse relations within and across turns in spontaneous conversation"></a>The distribution of discourse relations within and across turns in spontaneous conversation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03645">http://arxiv.org/abs/2307.03645</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Magalí López Cortez, Cassandra L. Jacobs</li>
<li>for: 这篇论文是关于如何在快速对话中使用语言关系（DR）的。</li>
<li>methods: 这篇论文使用了一系列的语言模型和人工标注来适应快速对话中的语言关系。</li>
<li>results: 研究发现，不同的对话上下文会导致不同的语言关系分布，单个转折创造了最多的不确定性。此外，研究还发现，基于演示单元的嵌入可以预测语言关系。<details>
<summary>Abstract</summary>
Time pressure and topic negotiation may impose constraints on how people leverage discourse relations (DRs) in spontaneous conversational contexts. In this work, we adapt a system of DRs for written language to spontaneous dialogue using crowdsourced annotations from novice annotators. We then test whether discourse relations are used differently across several types of multi-utterance contexts. We compare the patterns of DR annotation within and across speakers and within and across turns. Ultimately, we find that different discourse contexts produce distinct distributions of discourse relations, with single-turn annotations creating the most uncertainty for annotators. Additionally, we find that the discourse relation annotations are of sufficient quality to predict from embeddings of discourse units.
</details>
<details>
<summary>摘要</summary>
时间压力和话题谈判可能会对人们在协说性谈话中使用语言关系（DR）所带来限制。在这个工作中，我们将写作语言系统的DR适用于精神对话使用拼写的观众标注。然后我们将检查DR在不同的多句子背景下是否被使用不同。我们比较说话者和说话之间的DR标注，以及说话者和说话之间的转折中的DR标注。最终，我们发现不同的谈话背景会生成不同的语言关系分布，单一说话标注最多对annotator造成不确定性。此外，我们发现DR标注足够高质量以预测对话单位的嵌入。
</details></li>
</ul>
<hr>
<h2 id="Text-Simplification-of-Scientific-Texts-for-Non-Expert-Readers"><a href="#Text-Simplification-of-Scientific-Texts-for-Non-Expert-Readers" class="headerlink" title="Text Simplification of Scientific Texts for Non-Expert Readers"></a>Text Simplification of Scientific Texts for Non-Expert Readers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03569">http://arxiv.org/abs/2307.03569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Björn Engelmann, Fabian Haak, Christin Katharina Kreutz, Narjes Nikzad Khasmakhi, Philipp Schaer</li>
<li>for: 这个研究是为了帮助非专家读者更好地理解科学报告摘要中的核心信息。</li>
<li>methods: 这个研究使用了三种现成的摘要模型（两个基于T5，一个基于PEGASUS）和一个使用复杂短语识别的ChatGPT模型来简化科学报告摘要。</li>
<li>results: 这些模型可以帮助非专家读者更好地理解报告摘要中的核心信息，并且可以帮助您更快地理解这些信息。<details>
<summary>Abstract</summary>
Reading levels are highly individual and can depend on a text's language, a person's cognitive abilities, or knowledge on a topic. Text simplification is the task of rephrasing a text to better cater to the abilities of a specific target reader group. Simplification of scientific abstracts helps non-experts to access the core information by bypassing formulations that require domain or expert knowledge. This is especially relevant for, e.g., cancer patients reading about novel treatment options. The SimpleText lab hosts the simplification of scientific abstracts for non-experts (Task 3) to advance this field. We contribute three runs employing out-of-the-box summarization models (two based on T5, one based on PEGASUS) and one run using ChatGPT with complex phrase identification.
</details>
<details>
<summary>摘要</summary>
阅读水平是非常个人化的，它可能受到文本的语言、读者的认知能力以及主题知识的影响。文本简化是将文本重新推理以更好地适应target读者群的能力。在科学报告中简化Abstract可以帮助非专家访问核心信息，这特别有 relevance для例如，癌症患者阅读新的治疗方案。我们在SimpleText lab中为非专家（任务3）进行科学报告简化，以推动这一领域的发展。我们提供了三个运行，其中两个基于T5摘要模型，一个基于PEGASUS摘要模型，以及一个使用ChatGPT复杂短语识别。
</details></li>
</ul>
<hr>
<h2 id="DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling"><a href="#DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling" class="headerlink" title="DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling"></a>DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03550">http://arxiv.org/abs/2307.03550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ipek Baris Schlicht, Lynn Khellaf, Defne Altiok</li>
<li>for: 这篇论文描述了我们在CheckThat! Lab中的主观检测任务提交。</li>
<li>methods: 为了解决任务中的分类偏见，我们使用GPT-3模型生成了不同风格的提示，基于新闻观点的主观检查表。我们使用了这些扩展训练集来练化语言特定的转换器模型。</li>
<li>results: 我们在英语、德语和土耳其语的实验中发现，不同的主观风格都能够在所有语言上得到效果。此外，我们发现在土耳其语和英语中，风格基本检测比重塑化更好。最后，GPT-3模型在非英语语言中生成风格基本文本时 occasional lacklustre 的结果。<details>
<summary>Abstract</summary>
This paper describes our submission for the subjectivity detection task at the CheckThat! Lab. To tackle class imbalances in the task, we have generated additional training materials with GPT-3 models using prompts of different styles from a subjectivity checklist based on journalistic perspective. We used the extended training set to fine-tune language-specific transformer models. Our experiments in English, German and Turkish demonstrate that different subjective styles are effective across all languages. In addition, we observe that the style-based oversampling is better than paraphrasing in Turkish and English. Lastly, the GPT-3 models sometimes produce lacklustre results when generating style-based texts in non-English languages.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在CheckThat! Lab中对主观偏见检测任务的提交。为了解决任务中的类别不均衡，我们使用GPT-3模型生成了更多的训练材料，使用基于新闻媒体的主观检查列表中的不同风格的提示。我们使用扩展的训练集来精度调整语言特定的转换器模型。我们的实验表明，不同的主观风格在所有语言中都有效。此外，我们发现在土耳其语和英语中，风格基于的增加 sampling 比较有效，而在非英语语言中，GPT-3模型 sometimes produce lacklustre results when generating style-based texts。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-perceptual-value-of-lexical-and-non-lexical-channels-in-speech"><a href="#Quantifying-the-perceptual-value-of-lexical-and-non-lexical-channels-in-speech" class="headerlink" title="Quantifying the perceptual value of lexical and non-lexical channels in speech"></a>Quantifying the perceptual value of lexical and non-lexical channels in speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03534">http://arxiv.org/abs/2307.03534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarenne Wallbridge, Peter Bell, Catherine Lai</li>
<li>for: 研究对话中非语言信息的值</li>
<li>methods: 引入一种通用的研究方法，利用准确率和信息 entropy 来衡量非语言信息的影响</li>
<li>results: 研究发现，非语言信息在对话中产生一致的影响，即使其不如语言内容alone 导致更好的分类性turn 判断，但是它们仍然能够提高参与者的一致性。<details>
<summary>Abstract</summary>
Speech is a fundamental means of communication that can be seen to provide two channels for transmitting information: the lexical channel of which words are said, and the non-lexical channel of how they are spoken. Both channels shape listener expectations of upcoming communication; however, directly quantifying their relative effect on expectations is challenging. Previous attempts require spoken variations of lexically-equivalent dialogue turns or conspicuous acoustic manipulations. This paper introduces a generalised paradigm to study the value of non-lexical information in dialogue across unconstrained lexical content. By quantifying the perceptual value of the non-lexical channel with both accuracy and entropy reduction, we show that non-lexical information produces a consistent effect on expectations of upcoming dialogue: even when it leads to poorer discriminative turn judgements than lexical content alone, it yields higher consensus among participants.
</details>
<details>
<summary>摘要</summary>
文本中的演讲是一种基本的交流方式，可以看作提供两个信息传输通道：言语上的字句，以及语言上的演讲方式。两个通道都会影响听众对后续交流的期望;然而，直接量化这两个通道之间的相对效果是困难的。先前的尝试需要使用语言上的变体或明显的声音修饰来实现对话的变化。本文介绍了一种通用的研究方法，用于研究对话中非语言信息的价值。通过量化非语言信息的听众对话的准确性和 entropy 减少，我们发现，非语言信息会在对话中产生一致的效果：即使导致语言内容alone 的较差分类判断，也会得到参与者的高度一致。
</details></li>
</ul>
<hr>
<h2 id="AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime"><a href="#AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime" class="headerlink" title="AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime"></a>AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03385">http://arxiv.org/abs/2307.03385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement">https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Giulia Rizzi, Elisabetta Fersini, Damiano Spina</li>
<li>for: The paper aims to develop an automated system for detecting sexism and other hateful behaviors on social media to promote a more inclusive and respectful online environment.</li>
<li>methods: The proposed approach uses large language models (mBERT and XLM-RoBERTa) and ensemble strategies to identify and classify sexism in English and Spanish, without relying on aggregated labels.</li>
<li>results: The system achieved fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79, outperforming the individual large language models.Here’s the simplified Chinese text for the three information points:</li>
<li>for: 本研究旨在开发一种自动检测社交媒体上的性别歧视和其他仇恨行为，以促进在线环境的包容性和尊重。</li>
<li>methods: 该方法使用大型自然语言模型（mBERT和XLM-RoBERTa）和集成策略来识别和分类社会性别歧视，不使用汇总标签。</li>
<li>results: 系统在EXIST Lab中取得了第四名的成绩（ Task 2）和第一名的成绩（ Task 3），ICM-Soft最高达{-2.32）和正常化ICM-Soft为0.79，超过了单独的大型自然语言模型。<details>
<summary>Abstract</summary>
With the increasing influence of social media platforms, it has become crucial to develop automated systems capable of detecting instances of sexism and other disrespectful and hateful behaviors to promote a more inclusive and respectful online environment. Nevertheless, these tasks are considerably challenging considering different hate categories and the author's intentions, especially under the learning with disagreements regime. This paper describes AI-UPV team's participation in the EXIST (sEXism Identification in Social neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task of sexism identification and characterization under the learning with disagreements paradigm by training directly from the data with disagreements, without using any aggregated label. Yet, performances considering both soft and hard evaluations are reported. The proposed system uses large language models (i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification and classification in English and Spanish. In particular, our system is articulated in three different pipelines. The ensemble approach outperformed the individual large language models obtaining the best performances both adopting a soft and a hard label evaluation. This work describes the participation in all the three EXIST tasks, considering a soft evaluation, it obtained fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of our approaches is publicly available at https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.
</details>
<details>
<summary>摘要</summary>
随着社交媒体平台的普及，已经成为必要的发展自动化系统，能够检测社交媒体上的性别歧视和其他不尊重和仇恨行为，以促进更加包容和尊重的在线环境。然而，这些任务非常困难，因为不同的仇恨类别和作者的意图，尤其是在学习各自意见的情况下。这篇文章描述了AI-UPV团队在CLEF 2023年的EXIST（性别歧视 Identification in Social neTworks）实验室中的参与。提出的方法是通过直接从数据中学习，不使用任何汇总标签，来解决性别歧视标识和分类问题。然而，我们还是报告了使用软和硬评估方法的性能。我们的系统使用了大型自然语言模型（i.e., mBERT和XLM-RoBERTa）和集成策略进行性别歧视标识和分类。具体来说，我们的系统由三个不同的管道组成。集成方法在使用软和硬标签评估方法时表现出色，在EXIST任务中获得了第四名（Task 2）和第一名（Task 3），其ICM-Soft=-2.32和 normalized ICM-Soft为0.79。我们的源代码可以在https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement上获得。
</details></li>
</ul>
<hr>
<h2 id="A-Side-by-side-Comparison-of-Transformers-for-English-Implicit-Discourse-Relation-Classification"><a href="#A-Side-by-side-Comparison-of-Transformers-for-English-Implicit-Discourse-Relation-Classification" class="headerlink" title="A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification"></a>A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03378">http://arxiv.org/abs/2307.03378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruce W. Lee, BongSeok Yang, Jason Hyung-Jong Lee</li>
<li>for: 这个论文的目的是对多种自然语言处理领域中的隐式 дискурс关系分类进行比较研究，以便研究人员可以充分利用公共可用的模型进行дискурс分析。</li>
<li>methods: 这篇论文使用了七种预训练语言模型，并通过对这些模型进行精细调整来进行比较性能测试。这些模型包括NSP、SBO、SOP等句子级预训练目标，以及MLM和全注意力等方法。</li>
<li>results: 这篇论文的结果显示，与之前报道的不同（Shi和Demberg，2019b），使用 sentence-level 预训练目标（NSP、SBO、SOP）并不总是生成最佳的隐式 дискурс关系分类模型。相反，使用相同大小的 PLMs  WITH MLM AND full attention 可以达到更高的性能（ACC &#x3D; 0.671）。<details>
<summary>Abstract</summary>
Though discourse parsing can help multiple NLP fields, there has been no wide language model search done on implicit discourse relation classification. This hinders researchers from fully utilizing public-available models in discourse analysis. This work is a straightforward, fine-tuned discourse performance comparison of seven pre-trained language models. We use PDTB-3, a popular discourse relation annotated dataset. Through our model search, we raise SOTA to 0.671 ACC and obtain novel observations. Some are contrary to what has been reported before (Shi and Demberg, 2019b), that sentence-level pre-training objectives (NSP, SBO, SOP) generally fail to produce the best performing model for implicit discourse relation classification. Counterintuitively, similar-sized PLMs with MLM and full attention led to better performance.
</details>
<details>
<summary>摘要</summary>
“对话分析可以帮助多个自然语言处理（NLP）领域，但是对于不直接的话语关系分类仍没有广泛的语言模型搜索。这限制了研究人员对话分析中的全面利用已有的模型。这项工作是一个简单、精确地 fine-tune 多个预训练语言模型的表现比较。我们使用 PDTB-3，一个受欢迎的话语关系标注数据集。通过我们的模型搜索，我们提高了ACC的最高分为0.671，并获得了新的观察。一些与过去报告不同（Shi和Demberg，2019b），具体是内置式预训练目标（NSP、SBO、SOP）通常无法生成最佳的模型 для implicit discourse relation classification。反意外地，相同大小的PLMs  WITH MLM和全域注意力可以获得更好的表现。”
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection"><a href="#Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection" class="headerlink" title="Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection"></a>Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03377">http://arxiv.org/abs/2307.03377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta">https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Paolo Rosso, Damiano Spina</li>
<li>for: 这篇论文的目的是如何 Mitigate the negative transfer problem in Multi-Task Learning (MTL)。</li>
<li>methods: 该论文提出了一种基于任务意识概念的新方法，使得避免了负性传递问题，同时提高了性能。这种方法基于在多个任务之间共享信息的思想。</li>
<li>results: 该论文在EXIST-2021和HatEval-2019测试准则上实现了新的状态态-of-the-art，并且在识别性别歧视、仇恨言语和恶意言语等领域中达到了最高的性能。<details>
<summary>Abstract</summary>
This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-Task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments"><a href="#Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments" class="headerlink" title="Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments"></a>Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03354">http://arxiv.org/abs/2307.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Papi, Peidong Wan, Junkun Chen, Jian Xue, Jinyu Li, Yashesh Gaur</li>
<li>for: 这篇论文主要用于提高实时涂抹翻译和自动听写的质量和效率。</li>
<li>methods: 这篇论文提出了一种串行传播变换器-变把（Transformer-Transducer），该模型同时生成自动听写（ASR）和翻译（ST）输出，使用单个解码器进行joint训练。</li>
<li>results: 实验结果表明，这种方法在单语言（it-en）和多语言（de,es,it）的设置下都能够实现最佳的质量-延迟平衡。模型的平均ASR延迟为1秒，ST延迟为1.3秒，而且与分开的ASR和ST模型相比，输出质量没有下降，甚至有所提高，增加了1.1个word error rate和0.4个bleu在多语言情况下。<details>
<summary>Abstract</summary>
In real-world applications, users often require both translations and transcriptions of speech to enhance their comprehension, particularly in streaming scenarios where incremental generation is necessary. This paper introduces a streaming Transformer-Transducer that jointly generates automatic speech recognition (ASR) and speech translation (ST) outputs using a single decoder. To produce ASR and ST content effectively with minimal latency, we propose a joint token-level serialized output training method that interleaves source and target words by leveraging an off-the-shelf textual aligner. Experiments in monolingual (it-en) and multilingual (\{de,es,it\}-en) settings demonstrate that our approach achieves the best quality-latency balance. With an average ASR latency of 1s and ST latency of 1.3s, our model shows no degradation or even improves output quality compared to separate ASR and ST models, yielding an average improvement of 1.1 WER and 0.4 BLEU in the multilingual case.
</details>
<details>
<summary>摘要</summary>
在实际应用场景中，用户经常需要同时获得翻译和转写的语音识别，特别在流处理方面，需要实时生成。这篇论文介绍了一种流处理Transformer-Transducer，可同时生成自动语音识别（ASR）和语音翻译（ST）输出，使用单个解码器。为了在最小的延迟下生成ASR和ST内容，我们提议了一种共同序列化输出训练方法，通过利用商业化的文本对齐器来扫描源和目标词语。实验表明，我们的方法在单语言（it-en）和多语言（de,es,it-en）设置下都可以达到最佳的质量-延迟平衡。我们的模型的平均ASR延迟为1秒，ST延迟为1.3秒，而且与分离ASR和ST模型不同，我们的模型无减性或甚至提高输出质量，平均提高1.1个WRR和0.4个BLEU在多语言情况下。
</details></li>
</ul>
<hr>
<h2 id="BiPhone-Modeling-Inter-Language-Phonetic-Influences-in-Text"><a href="#BiPhone-Modeling-Inter-Language-Phonetic-Influences-in-Text" class="headerlink" title="BiPhone: Modeling Inter Language Phonetic Influences in Text"></a>BiPhone: Modeling Inter Language Phonetic Influences in Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03322">http://arxiv.org/abs/2307.03322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhirut Gupta, Ananya B. Sai, Richard Sproat, Yuri Vasilevski, James S. Ren, Ambarish Jash, Sukhdeep S. Sodhi, Aravindan Raghuveer</li>
<li>for: 这个论文是为了研究在使用第二语言（L2）时，因技术不匹配而受到强制使用Web的人群中，受到语言一低文化水平的影响而导致的文本错误的问题。</li>
<li>methods: 这个论文使用了一种方法来挖掘L1和L2之间的音节混淆（即L1 speaker可能会混淆的L2音节），并将这些混淆音节输入到一个生成模型（Bi-Phone）中，以生成受混淆的L2文本。</li>
<li>results: 通过人工评估，这个方法可以生成具有各种L1特征的受混淆L2文本，并且在Web上有广泛的应用。此外，这个论文还将这种方法应用于SuperGLUE语言理解 benchmark 上，并证明了SoTA语言理解模型在受混淆情况下的表现不佳。此外，这个论文还提出了一种新的音节预测预训练任务，可以帮助字节模型重新获得SuperGLUE水平的表现。最后，这个论文还发布了FunGLUE benchmark，以便进一步研究具有phonetically robust的语言模型。<details>
<summary>Abstract</summary>
A large number of people are forced to use the Web in a language they have low literacy in due to technology asymmetries. Written text in the second language (L2) from such users often contains a large number of errors that are influenced by their native language (L1). We propose a method to mine phoneme confusions (sounds in L2 that an L1 speaker is likely to conflate) for pairs of L1 and L2. These confusions are then plugged into a generative model (Bi-Phone) for synthetically producing corrupted L2 text. Through human evaluations, we show that Bi-Phone generates plausible corruptions that differ across L1s and also have widespread coverage on the Web. We also corrupt the popular language understanding benchmark SuperGLUE with our technique (FunGLUE for Phonetically Noised GLUE) and show that SoTA language understating models perform poorly. We also introduce a new phoneme prediction pre-training task which helps byte models to recover performance close to SuperGLUE. Finally, we also release the FunGLUE benchmark to promote further research in phonetically robust language models. To the best of our knowledge, FunGLUE is the first benchmark to introduce L1-L2 interactions in text.
</details>
<details>
<summary>摘要</summary>
很多人被迫使用第二语言（L2）进行网络交互，但是由于技术不均衡，他们的written L2文本经常含有大量的错误，这些错误受到他们的Native Language（L1）的影响。我们提议一种方法， mines phoneme confusions（L2中的声音混淆），并将其与L1进行对应。这些混淆被用于生成Synthetically produced corrupted L2文本。我们通过人类评估表明，Bi-Phone生成的混淆是有可能的，并且在不同的L1上具有广泛的coverage。我们还将这种技术应用于SuperGLUE的人工语言理解 benchmark（FunGLUE for Phonetically Noised GLUE），并证明了SoTA语言理解模型在这种情况下表现不佳。我们还提出了一种新的声音预测预训练任务，帮助Byte模型在SuperGLUE中恢复性能。最后，我们还发布了FunGLUE benchmark，以便进一步研究在声音稳定的语言模型方面。我们知道，FunGLUE是首个引入L1-L2交互的文本 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Covering-Uncommon-Ground-Gap-Focused-Question-Generation-for-Answer-Assessment"><a href="#Covering-Uncommon-Ground-Gap-Focused-Question-Generation-for-Answer-Assessment" class="headerlink" title="Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment"></a>Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03319">http://arxiv.org/abs/2307.03319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roni Rabin, Alexandre Djerbetian, Roee Engelberg, Lidan Hackmon, Gal Elidan, Reut Tsarfaty, Amir Globerson</li>
<li>for: The paper is written for generating gap-focused questions (GFQs) in educational dialogues to create a rich and interactive learning experience.</li>
<li>methods: The paper proposes a model that uses natural language processing techniques to generate GFQs automatically, with a focus on key desired aspects such as relevance, specificity, and engagement.</li>
<li>results: The paper provides an evaluation of the generated questions against human-generated questions, demonstrating competitive performance and the effectiveness of the proposed model in generating GFQs.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了自动生成教育对话中的差距关注问题（GFQ），以创造一种丰富和互动的学习经验。</li>
<li>methods: 论文提出了一种使用自然语言处理技术来生成GFQ，注重关键所需的方面，如相关性、特定性和参与度。</li>
<li>results: 论文通过人工标注者对生成的问题和人类生成的问题进行评估，表明了提案模型的竞争力和生成GFQ的效果。<details>
<summary>Abstract</summary>
Human communication often involves information gaps between the interlocutors. For example, in an educational dialogue, a student often provides an answer that is incomplete, and there is a gap between this answer and the perfect one expected by the teacher. Successful dialogue then hinges on the teacher asking about this gap in an effective manner, thus creating a rich and interactive educational experience. We focus on the problem of generating such gap-focused questions (GFQs) automatically. We define the task, highlight key desired aspects of a good GFQ, and propose a model that satisfies these. Finally, we provide an evaluation by human annotators of our generated questions compared against human generated ones, demonstrating competitive performance.
</details>
<details>
<summary>摘要</summary>
人际交流经常会出现信息差距 между交流方。例如，在教学对话中，学生可能提供不够的答案，而教师期望的完整答案与此存在差距。成功的对话受到教师以有效的方式询问这个差距，从而创造出丰富且互动的教学经验。我们关注于自动生成这些差距关注的问题（GFQ）的问题。我们定义任务、标出了好的GFQ所应具备的关键特征，并提议一种满足这些特征的模型。最后，我们通过人类标注员对我们生成的问题与人类生成的问题进行评估，展示了竞争力强的性能。
</details></li>
</ul>
<hr>
<h2 id="InfoSync-Information-Synchronization-across-Multilingual-Semi-structured-Tables"><a href="#InfoSync-Information-Synchronization-across-Multilingual-Semi-structured-Tables" class="headerlink" title="InfoSync: Information Synchronization across Multilingual Semi-structured Tables"></a>InfoSync: Information Synchronization across Multilingual Semi-structured Tables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03313">http://arxiv.org/abs/2307.03313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Info-Sync/InfoSync">https://github.com/Info-Sync/InfoSync</a></li>
<li>paper_authors: Siddharth Khincha, Chelsi Jain, Vivek Gupta, Tushar Kataria, Shuo Zhang</li>
<li>for: 本研究旨在解决语言间 semi-结构化数据的信息同步问题，例如wikipedia 表格的同步化。</li>
<li>methods: 提出了一种新的数据集 InfoSyncC 和一种两步方法 для tabular 同步化。InfoSync 包含 100K 实体中心表格（wikipedia Infobox） Across 14 种语言，其中一部分（3.5K 对）是手动注释。提出的方法包括信息对齐和信息更新两个步骤。</li>
<li>results: 在 InfoSync 上进行了信息对齐，信息对齐得分为 87.91（en &lt;-&gt; non-en）。为了评估信息更新，我们对 Infoboxes 进行了603 个表格对的人工帮助编辑。我们的方法得到了wikipedia 上的77.28% 的接受率，表明了提出的方法的有效性。<details>
<summary>Abstract</summary>
Information Synchronization of semi-structured data across languages is challenging. For instance, Wikipedia tables in one language should be synchronized across languages. To address this problem, we introduce a new dataset InfoSyncC and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en <-> non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
信息同步问题在不结构化数据中是挑战。例如，wikipedia 表格在一种语言中应该与其他语言的表格进行同步。为解决这个问题，我们介绍了一个新的数据集 InfoSyncC 和一种两步方法 для表格同步。InfoSync 包含 100 万个实体中心表格（Wikipedia 信息框） Across 14 种语言，其中一 subset（3.5 千对）是 manually annotated。我们提议的方法包括 1) 信息对应和 2) 信息更新。当 evaluated on InfoSync 时，信息对应得到了 F1 分数为 87.91（en <-> non-en）。为评估信息更新，我们对 Infoboxes 进行了人工协助的 Wikipedia 编辑 603 对。我们的方法获得了 Wikipedia 上的接受率为 77.28%，显示了我们提议的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment"><a href="#Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment" class="headerlink" title="Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment"></a>Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03296">http://arxiv.org/abs/2307.03296</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech">https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech</a></li>
<li>paper_authors: Aref Farhadipour, Hadi Veisi</li>
<li>for: 这个研究旨在开发一个基于 convolutional neural network (CNN) 的语音识别系统，以提高智能家居中的语音识别率。</li>
<li>methods: 该研究使用 gammatonegram 方法将语音文件转换为图像，并使用 pre-trained Alexnet 基于 transfer learning 方法进行语音识别。</li>
<li>results: 根据 UA 数据集的结果，提议的语音识别系统在 speaker-dependent 模式下达到了 91.29% 的准确率，语音识别系统在 text-dependent 模式下达到了 87.74% 的准确率，而两类智能评估系统在 two-class 模式下达到了 96.47% 的准确率。<details>
<summary>Abstract</summary>
Dysarthria is a disability that causes a disturbance in the human speech system and reduces the quality and intelligibility of a person's speech. Because of this effect, the normal speech processing systems can not work properly on impaired speech. This disability is usually associated with physical disabilities. Therefore, designing a system that can perform some tasks by receiving voice commands in the smart home can be a significant achievement. In this work, we introduce gammatonegram as an effective method to represent audio files with discriminative details, which is used as input for the convolutional neural network. On the other word, we convert each speech file into an image and propose image recognition system to classify speech in different scenarios. Proposed CNN is based on the transfer learning method on the pre-trained Alexnet. In this research, the efficiency of the proposed system for speech recognition, speaker identification, and intelligibility assessment is evaluated. According to the results on the UA dataset, the proposed speech recognition system achieved 91.29% accuracy in speaker-dependent mode, the speaker identification system acquired 87.74% accuracy in text-dependent mode, and the intelligibility assessment system achieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network speech recognition system that works fully automatically. This system is located in a cascade arrangement with the two-class intelligibility assessment system, and the output of this system activates each one of the speech recognition networks. This architecture achieves an accuracy of 92.3% WRR. The source code of this paper is available.
</details>
<details>
<summary>摘要</summary>
《干扰性 speech 识别系统的设计》Introduction:难以说话（dysarthria）是一种影响人类语音系统的残疾，导致语音质量和可读性减退。由于这种影响，常规的语音处理系统无法正常工作。这种残疾通常与物理残疾相关。因此，设计一个可以通过声音命令在智能家居中进行一些任务的系统可以是一项重要的成就。在这项工作中，我们介绍了一种有效的方法，即《干扰性 grammatonegram》，用于将语音文件转换成可识别的图像，并提出了一种基于转移学习方法的 convolutional neural network（CNN）来分类不同场景的语音。Methodology:我们将每个语音文件转换成一幅图像，并使用pre-trained Alexnet进行转移学习。在这项研究中，我们评估了提案的语音识别、 speaker identification和可读性评估系统的效率。根据UA数据集的结果，提案的语音识别系统在 speaker-dependent 模式下达到了91.29%的准确率，speaker identification系统在 text-dependent 模式下达到了87.74%的准确率，而可读性评估系统在 two-class 模式下达到了96.47%的准确率。Results:我们还提出了一种多网络语音识别系统，其中每个语音识别网络都是通过两类可读性评估系统的输出来活化。这种架构可以达到92.3%的WRR精度。Conclusion:本文介绍了一种基于干扰性 grammatonegram 和转移学习的语音识别系统的设计。该系统可以在智能家居中进行一些任务，并且可以提高语音识别、 speaker identification和可读性评估的精度。ources code of this paper is available.
</details></li>
</ul>
<hr>
<h2 id="Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M"><a href="#Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M" class="headerlink" title="Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M"></a>Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04765">http://arxiv.org/abs/2307.04765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oyku Berfin Mercan, Sercan Cepni, Davut Emre Tasar, Sukru Ozan</li>
<li>for: 这个研究是为了测试两种预训练的多语言模型（Whisper-Small和Wav2Vec2-XLS-R-300M）在土耳其语言上的表现。</li>
<li>methods: 这个研究使用了Mozilla Common Voice版本11.0，这是一个在土耳其语言上制作的开源数据集。研究人员将这两个模型在这个数据集上进行了微调。</li>
<li>results: 研究人员计算了WER值，得到的结果是0.28和0.16，分别对应于Wav2Vec2-XLS-R-300M和Whisper-Small模型。此外，研究人员还测试了这两个模型在没有包含在训练和验证数据集中的回呼记录上的表现。<details>
<summary>Abstract</summary>
In this study, the performances of the Whisper-Small and Wav2Vec2-XLS-R-300M models which are two pre-trained multilingual models for speech to text were examined for the Turkish language. Mozilla Common Voice version 11.0 which is prepared in Turkish language and is an open-source data set, was used in the study. The multilingual models, Whisper- Small and Wav2Vec2-XLS-R-300M were fine-tuned with this data set which contains a small amount of data. The speech to text performance of the two models was compared. WER values are calculated as 0.28 and 0.16 for the Wav2Vec2-XLS- R-300M and the Whisper-Small models respectively. In addition, the performances of the models were examined with the test data prepared with call center records that were not included in the training and validation dataset.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们对两种预训练的多语言模型（Whisper-Small和Wav2Vec2-XLS-R-300M）进行了对 Turkish 语言的评估。我们使用了 Mozilla Common Voice 版本 11.0，这是一个开源的 Turkish 语言数据集。我们对这些数据集进行了精度的 fine-tuning，并计算了这两个模型在这些数据集上的 speech-to-text 性能。我们计算出的 WER 值为 0.28 和 0.16，对应的是 Whisper-Small 和 Wav2Vec2-XLS-R-300M 模型。此外，我们还对使用测试数据集，这些数据集不包括在训练和验证集中，进行了模型的评估。
</details></li>
</ul>
<hr>
<h2 id="Lost-in-the-Middle-How-Language-Models-Use-Long-Contexts"><a href="#Lost-in-the-Middle-How-Language-Models-Use-Long-Contexts" class="headerlink" title="Lost in the Middle: How Language Models Use Long Contexts"></a>Lost in the Middle: How Language Models Use Long Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03172">http://arxiv.org/abs/2307.03172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nelson-liu/lost-in-the-middle">https://github.com/nelson-liu/lost-in-the-middle</a></li>
<li>paper_authors: Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang</li>
<li>for: 本研究探讨了语言模型在长文本上的表现，以及它们如何使用长文本中的信息。</li>
<li>methods: 本研究使用了多文档问答和关键值检索两个任务来分析语言模型在长文本上的表现。</li>
<li>results: 研究发现，语言模型在长文本上的表现通常最高时 relevante信息出现在输入文本的开头或结尾，并且当模型需要在长文本中检索 relevante信息时，表现会明显下降。此外，研究还发现，even explicitly long-context models 的表现会随输入文本的长度增长而下降。这些发现可以帮助我们更好地理解语言模型如何使用输入文本，并提供新的评估协议 для未来的长文本模型。<details>
<summary>Abstract</summary>
While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.
</details>
<details>
<summary>摘要</summary>
Recent language models have the ability to take long contexts as input, but little is known about how well they use longer contexts. We analyze the performance of language models on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.Here's the text in Traditional Chinese:现代语言模型具有处理长文本上下文的能力，但知道它们如何使用长文本上下文的情况相对少。我们分析了语言模型在多文档问题回答和关键值搜寻两个任务中表现的情况，发现表现通常在输入上下文中的开头或结尾的位置最高，而在中间部分搜寻时表现则明显下降。此外，随着输入上下文的长度增加，表现也会随之下降，即使使用长文本模型。我们的分析可以帮助我们更好地理解语言模型如何使用输入上下文，并提供未来长文本模型的新评估协议。
</details></li>
</ul>
<hr>
<h2 id="T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning"><a href="#T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning" class="headerlink" title="T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"></a>T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03132">http://arxiv.org/abs/2307.03132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/locuslab/t-mars">https://github.com/locuslab/t-mars</a></li>
<li>paper_authors: Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan</li>
<li>for: 这篇论文主要目标是提出一种新的数据筛选方法，以提高计算机视觉领域的模型学习效果。</li>
<li>methods: 这篇论文使用了一种新的数据筛选方法，即T-MARS（文本蒙版和重新分配），它首先将文本蒙版出现的图像，然后使用CLIP相似性分数来筛选图像。</li>
<li>results: 实验表明，T-MARS在DataComp数据筛选benchmark中的中等规模上，与最佳方法的差距为6.5%（在ImageNet上）和4.7%（在VTAB上）。此外，在不同的数据池大小从2M到64M时，T-MARS的准确率随着数据和计算的扩展呈线性增长。<details>
<summary>Abstract</summary>
Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the "medium scale" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. Code is available at https://github.com/locuslab/T-MARS.
</details>
<details>
<summary>摘要</summary>
大量网络源的多模式数据集已经推动了一些新的方法来学习通用视觉表示，提高计算机视觉的状态艺术。一个重要的决策是如何CURATE这些越来越大的数据集。例如，LAION-5B数据集的创建者选择了只保留具有 CLIP 相似性分数超过设定的阈值的图像-标签对。在这篇论文中，我们提出了一种新的数据筛选方法， motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the "medium scale" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. 码可以在 https://github.com/locuslab/T-MARS 上获取。
</details></li>
</ul>
<hr>
<h2 id="BLEURT-Has-Universal-Translations-An-Analysis-of-Automatic-Metrics-by-Minimum-Risk-Training"><a href="#BLEURT-Has-Universal-Translations-An-Analysis-of-Automatic-Metrics-by-Minimum-Risk-Training" class="headerlink" title="BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training"></a>BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03131">http://arxiv.org/abs/2307.03131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/powerpuffpomelo/fairseq_mrt">https://github.com/powerpuffpomelo/fairseq_mrt</a></li>
<li>paper_authors: Yiming Yan, Tao Wang, Chengqi Zhao, Shujian Huang, Jiajun Chen, Mingxuan Wang</li>
<li>for: 这个研究旨在系统地分析和比较各种主流和前沿自动评价 metric，以了解它们在训练机器翻译系统时的导向性。</li>
<li>methods: 通过 Minimum Risk Training (MRT) 方法，研究发现了一些 metric 具有不稳定性问题，如 BLEURT 和 BARTScore 中的通用敌对翻译。经过深入分析，发现这些不稳定性的两个主要原因是训练数据集的分布偏见，以及评价metric的 парадиг。通过加入token级别的约束，提高了评价 metric 的稳定性，从而提高了机器翻译系统的性能。</li>
<li>results: 研究发现，通过提高评价 metric 的稳定性，可以提高机器翻译系统的性能。 codes 可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/powerpuffpomelo/fairseq_mrt%7D">https://github.com/powerpuffpomelo/fairseq_mrt}</a> 上获取。<details>
<summary>Abstract</summary>
Automatic metrics play a crucial role in machine translation. Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics. However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect. In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems. Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore. In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm. By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems. Codes are available at \url{https://github.com/powerpuffpomelo/fairseq_mrt}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VisKoP-Visual-Knowledge-oriented-Programming-for-Interactive-Knowledge-Base-Question-Answering"><a href="#VisKoP-Visual-Knowledge-oriented-Programming-for-Interactive-Knowledge-Base-Question-Answering" class="headerlink" title="VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering"></a>VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03130">http://arxiv.org/abs/2307.03130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijun Yao, Yuanyong Chen, Xin Lv, Shulin Cao, Amy Xin, Jifan Yu, Hailong Jin, Jianjun Xu, Peng Zhang, Lei Hou, Juanzi Li</li>
<li>for: 这个论文是关于Visual Knowledge oriented Programming platform（VisKoP），一种基于人工智能的知识基本问题回答（KBQA）系统，它可以将自然语言问题转化为知识导向程序语言（KoPL），并将 KoPL 程序映射到图形元素中，以便使用图形操作来编辑和调试知识基本（KB）查询。</li>
<li>methods: 这个论文使用了人工智能的神经网络程序生成模块，将自然语言问题转化为 KoPL 程序，并提供了一个高效的 KoPL 执行引擎，以便在大规模知识基本中进行实用KBQA。</li>
<li>results: 实验结果显示，VisKoP 可以高效地解决大规模知识基本中的问题，并且通过人工交互可以修复大量错误的 KoPL 程序，以获得正确的答案。<details>
<summary>Abstract</summary>
We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries. VisKoP not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements. KoPL programs can be edited with simple graphical operators, such as dragging to add knowledge operators and slot filling to designate operator arguments. Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results. To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end. Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer. The VisKoP online demo https://demoviskop.xlore.cn (Stable release of this paper) and https://viskop.xlore.cn (Beta release with new features), highly efficient KoPL engine https://pypi.org/project/kopl-engine, and screencast video https://youtu.be/zAbJtxFPTXo are now publicly available.
</details>
<details>
<summary>摘要</summary>
我们介绍Visual Knowledge oriented Programming平台（VisKoP），是一个基于问题回答（KBQA）系统，具有人类在循环中参与修改和验证知识库（KB）问题的功能。VisKoP不仅提供神经网络问题化模组，将自然语言问题转换为知识导向程式语言（KoPL），并将KoPL程式映射为图形元素。KoPL程式可以通过简单的图形操作进行修改，例如拖曳添加知识操作和填写操作符据。此外，VisKoP提供KBSchema自动完成和用户可以轻松地在KB中验证KoPL程式的中间结果。为了实现实用的KBQA，我们设计了高效的KoPL执行引擎。实验结果显示，VisKoP具有高效性，并且用户互动可以解决大量的错误KoPL程式，以获取正确答案。VisKoP在线demo：https://demoviskop.xlore.cn（稳定版本）和https://viskop.xlore.cn（beta版本，具有新功能），高效的KoPL执行引擎：https://pypi.org/project/kopl-engine，和萤幕录影影片：https://youtu.be/zAbJtxFPTXo现在公开available。
</details></li>
</ul>
<hr>
<h2 id="PREADD-Prefix-Adaptive-Decoding-for-Controlled-Text-Generation"><a href="#PREADD-Prefix-Adaptive-Decoding-for-Controlled-Text-Generation" class="headerlink" title="PREADD: Prefix-Adaptive Decoding for Controlled Text Generation"></a>PREADD: Prefix-Adaptive Decoding for Controlled Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03214">http://arxiv.org/abs/2307.03214</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jonnypei/acl23-preadd">https://github.com/jonnypei/acl23-preadd</a></li>
<li>paper_authors: Jonathan Pei, Kevin Yang, Dan Klein</li>
<li>for: 控制文本生成</li>
<li>methods:  prefix-adaptive decoding（PREADD）</li>
<li>results: 在三个任务中（抑制恶意输出、减少性别偏见、控制情感），PREADD比基eline和auxiliary-expert控制方法提高12%或更多的相对提升。<details>
<summary>Abstract</summary>
We propose Prefix-Adaptive Decoding (PREADD), a flexible method for controlled text generation. Unlike existing methods that use auxiliary expert models to control for attributes, PREADD does not require an external model, instead relying on linearly combining output logits from multiple prompts. Specifically, PREADD contrasts the output logits generated using a raw prompt against those generated using a prefix-prepended prompt, enabling both positive and negative control with respect to any attribute encapsulated by the prefix. We evaluate PREADD on three tasks -- toxic output mitigation, gender bias reduction, and sentiment control -- and find that PREADD outperforms not only prompting baselines, but also an auxiliary-expert control method, by 12% or more in relative gain on our main metrics for each task.
</details>
<details>
<summary>摘要</summary>
我们提出了预先适应编码（PREADD）方法，这是一种灵活的文本生成控制方法。与现有方法不同，PREADD不需要外部模型，而是通过将多个提示的输出拟合成为一个Linear Combination来实现控制。具体来说，PREADD比较使用 Raw Prompt 和Prefix-prepended Prompt两个提示生成的输出拟合，从而实现对任何Attributes所含的控制。我们对三个任务进行评估：毒瘤输出减少、性别偏见减少和 sentiment控制，并发现PREADD在每个任务上比基elinePrompting和auxiliary-expert控制方法提高12%或更多的相对提升。
</details></li>
</ul>
<hr>
<h2 id="Extracting-Multi-valued-Relations-from-Language-Models"><a href="#Extracting-Multi-valued-Relations-from-Language-Models" class="headerlink" title="Extracting Multi-valued Relations from Language Models"></a>Extracting Multi-valued Relations from Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03122">http://arxiv.org/abs/2307.03122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snehasinghania/multi_valued_slot_filling">https://github.com/snehasinghania/multi_valued_slot_filling</a></li>
<li>paper_authors: Sneha Singhania, Simon Razniewski, Gerhard Weikum</li>
<li>for: 这篇论文是为了探讨隐藏语言表示的多个对象关系知识是否可以提取出来的。</li>
<li>methods: 这篇论文使用了现有的提示技术和新的域知识 incorporating 提示技术来评价候选对象。</li>
<li>results: 研究发现，通过选择对象的可能性大于学习关系特定的阈值得分，可以达到49.5%的 F1 分数。这些结果表明使用LM进行多值槽填任务是具有挑战性，并且激励进一步研究提取隐藏语言表示中的关系知识。<details>
<summary>Abstract</summary>
The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge. However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct. To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge. We formulate the problem as a rank-then-select task. For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge. Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score. Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task and pave the way for further research on extracting relational knowledge from latent language representations.
</details>
<details>
<summary>摘要</summary>
广泛的语言表现库使用预训语言模型（LM）表明它们是有前途的结构知识来源。然而，现有的方法仅专注在单一物件之间的主题关系对，即使有多个物件是正确的。为了解决这个限制，我们分析这些表现的潜在可以产生实体多个物件关系知识。我们将这个问题推理为排名选择任务。为选择候选物件，我们评估现有的提示技术和新提出的内容知识技术。我们发现，选择关系特定阈值上的可能性大于学习的relation-specific阈值会获得49.5%的F1分数。我们的结果显示使用LM进行多値构造填充任务是具有挑战性的，并且点出了进一步研究抽取语言表现中的关系知识的可能性。
</details></li>
</ul>
<hr>
<h2 id="KoRC-Knowledge-oriented-Reading-Comprehension-Benchmark-for-Deep-Text-Understanding"><a href="#KoRC-Knowledge-oriented-Reading-Comprehension-Benchmark-for-Deep-Text-Understanding" class="headerlink" title="KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding"></a>KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03115">http://arxiv.org/abs/2307.03115</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-keg/korc">https://github.com/thu-keg/korc</a></li>
<li>paper_authors: Zijun Yao, Yantao Liu, Xin Lv, Shulin Cao, Jifan Yu, Lei Hou, Juanzi Li</li>
<li>for: 本文提出了一个新的 benchmark，以便检测深度文本理解的能力。</li>
<li>methods: 本文使用了大量知识库来引导注释或大型自然语言处理器（LLM）构建知识问题。</li>
<li>results: 实验结果显示，使用最佳基线方法只能在收odge Distribution test set中 achieve 68.3%和30.0% F1 measure。这表明深度文本理解仍然是一个未解决的挑战。<details>
<summary>Abstract</summary>
Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years. However, these benchmarks have encountered two major limitations. On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage. On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space. To overcome these limitations, we build a new challenging benchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format. Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions. Moreover, we use labels in knowledge bases rather than spans or choices as the final answers. We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the in-distribution and out-of-distribution test set, respectively. These results indicate that deep text understanding is still an unsolved challenge. The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/THU-KEG/KoRC.
</details>
<details>
<summary>摘要</summary>
深层文本理解，需要文档与知识之间的连接，在过去几年中得到了许多benchmark的注意。然而，这些benchmark都面临了两个主要的限制：一方面，大多数它们需要人工标注知识，导致知识覆盖率受限；另一方面，它们通常使用文本中的选择或范围作为答案，这导致答案空间过于窄。为了突破这些限制，我们在这篇论文中构建了一个新的挑战性benchmark名为KoRC。相比之前的benchmark，KoRC具有两个优势：一是广泛的知识覆盖率，二是灵活的答案格式。具体来说，我们利用大量知识库来引导注urger或大语言模型（LLM）构建知识问题。此外，我们使用知识库中的标签而不是选择或范围作为答案。我们对state-of-the-art模型进行测试，实验结果表明，最强基eline只能达到68.3%和30.0%的F1度在分布式和分布式测试集上。这些结果表明，深层文本理解仍然是一个未解决的挑战。benchmark dataset、排名和基eline方法在https://github.com/THU-KEG/KoRC中发布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.CL_2023_07_07/" data-id="clogyj8vv006t7crac4214rpj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.LG_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T10:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.LG_2023_07_07/">cs.LG - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Differentiable-Turbulence"><a href="#Differentiable-Turbulence" class="headerlink" title="Differentiable Turbulence"></a>Differentiable Turbulence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03683">http://arxiv.org/abs/2307.03683</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tumaer/JAXFLUIDS">https://github.com/tumaer/JAXFLUIDS</a></li>
<li>paper_authors: Varun Shankar, Romit Maulik, Venkatasubramanian Viswanathan</li>
<li>for: 这个论文旨在提出一种基于深度学习的大气动力学液体流动模型，以提高二维液体动力学中的涨潮层次粗细规范模型的准确性。</li>
<li>methods: 这个论文使用了可微分的液体动力学，并结合物理恰当的深度学习架构来学习高效和通用的涨潮层次粗细规范模型。</li>
<li>results: 研究发现，包含小规模非本地特征是最关键的，以实现有效的涨潮层次粗细规范模型，而大规模特征可以提高解 posteriori 解场的点对应精度。模型可以在不同的流动配置下进行普适化，包括不同的 Reynolds 数和冲击条件。<details>
<summary>Abstract</summary>
Deep learning is increasingly becoming a promising pathway to improving the accuracy of sub-grid scale (SGS) turbulence closure models for large eddy simulations (LES). We leverage the concept of differentiable turbulence, whereby an end-to-end differentiable solver is used in combination with physics-inspired choices of deep learning architectures to learn highly effective and versatile SGS models for two-dimensional turbulent flow. We perform an in-depth analysis of the inductive biases in the chosen architectures, finding that the inclusion of small-scale non-local features is most critical to effective SGS modeling, while large-scale features can improve pointwise accuracy of the a-posteriori solution field. The filtered velocity gradient tensor can be mapped directly to the SGS stress via decomposition of the inputs and outputs into isotropic, deviatoric, and anti-symmetric components. We see that the model can generalize to a variety of flow configurations, including higher and lower Reynolds numbers and different forcing conditions. We show that the differentiable physics paradigm is more successful than offline, a-priori learning, and that hybrid solver-in-the-loop approaches to deep learning offer an ideal balance between computational efficiency, accuracy, and generalization. Our experiments provide physics-based recommendations for deep-learning based SGS modeling for generalizable closure modeling of turbulence.
</details>
<details>
<summary>摘要</summary>
深度学习在提高大涨规（SGS）涨规模型精度方面表现越来越有前途。我们利用了可导ifferentiable turbulence的概念，其中一个可导ifferentiable solver与物理启发的深度学习架构结合使用，以学习高效和多样化的SGS模型。我们进行了深入的杂散偏见分析，发现包含小规模非本地特征是最重要的SGS模型化特征，而大规模特征可以提高 posteriori 解场中点精度。 filtered velocity gradient tensor 可以直接映射到 SGS 压力，通过输入和输出的归一化、异常值分解和反对映射。我们发现模型可以通过不同的流场配置和强制条件进行泛化，包括不同 Reynolds 数和强制条件。我们还证明了可导ifferentiable physics  парадиг是一个更成功的方法，而不是离线、先验学习。我们的实验结果为深度学习基于 SGS 模型的涨规模型化提供物理学习的建议。
</details></li>
</ul>
<hr>
<h2 id="GeoPhy-Differentiable-Phylogenetic-Inference-via-Geometric-Gradients-of-Tree-Topologies"><a href="#GeoPhy-Differentiable-Phylogenetic-Inference-via-Geometric-Gradients-of-Tree-Topologies" class="headerlink" title="GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies"></a>GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03675">http://arxiv.org/abs/2307.03675</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m1m0r1/geophy">https://github.com/m1m0r1/geophy</a></li>
<li>paper_authors: Takahiro Mimori, Michiaki Hamada</li>
<li>for: 理解生物数据中的演化关系，即使考虑分子遗传学模型的不确定性。</li>
<li>methods: 使用可 diferenciable 的形式ulation来进行phylogenetic inference，利用连续几何空间中的特有表示方式来表示树图分布。</li>
<li>results: 在使用实际 benchmark 数据进行实验中，GeoPhy 方法与其他 approximate Bayesian 方法相比，显著地提高了性能。<details>
<summary>Abstract</summary>
Phylogenetic inference, grounded in molecular evolution models, is essential for understanding the evolutionary relationships in biological data. Accounting for the uncertainty of phylogenetic tree variables, which include tree topologies and evolutionary distances on branches, is crucial for accurately inferring species relationships from molecular data and tasks requiring variable marginalization. Variational Bayesian methods are key to developing scalable, practical models; however, it remains challenging to conduct phylogenetic inference without restricting the combinatorially vast number of possible tree topologies. In this work, we introduce a novel, fully differentiable formulation of phylogenetic inference that leverages a unique representation of topological distributions in continuous geometric spaces. Through practical considerations on design spaces and control variates for gradient estimations, our approach, GeoPhy, enables variational inference without limiting the topological candidates. In experiments using real benchmark datasets, GeoPhy significantly outperformed other approximate Bayesian methods that considered whole topologies.
</details>
<details>
<summary>摘要</summary>
生物数据中的进化关系理解需要基于分子进化模型的phylogenetic inference。考虑phylogenetic树变量的不确定性，包括树 topology和演化距离在支持下，是准确推断物种关系和基于分子数据的任务需要变量聚合的关键。variational Bayesian方法是开发可扩展、实用模型的关键，但是不限定可能的树体系数量是一个挑战。在这种情况下，我们介绍了一种新的、完全 differentiable的phylogenetic inference形式，利用连续几何空间中特有的树分布表示。通过实践设计空间和控制变量的考虑，我们的方法GeoPhy可以在不限定树体系数量的情况下进行变量整合。在使用实际 benchmark数据进行实验中，GeoPhy表现出了与其他approximate Bayesian方法相比的显著优势。
</details></li>
</ul>
<hr>
<h2 id="Simulation-free-Schrodinger-bridges-via-score-and-flow-matching"><a href="#Simulation-free-Schrodinger-bridges-via-score-and-flow-matching" class="headerlink" title="Simulation-free Schrödinger bridges via score and flow matching"></a>Simulation-free Schrödinger bridges via score and flow matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03672">http://arxiv.org/abs/2307.03672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/atong01/conditional-flow-matching">https://github.com/atong01/conditional-flow-matching</a></li>
<li>paper_authors: Alexander Tong, Nikolay Malkin, Kilian Fatras, Lazar Atanackovic, Yanlei Zhang, Guillaume Huguet, Guy Wolf, Yoshua Bengio</li>
<li>for: 学习细胞动态模型，即生物学中细胞的行为和变化。</li>
<li>methods: 使用SF2M方法，即 simulation-free score and flow matching 方法，不需要 simulations 来学习细胞动态模型。这种方法基于 Schrödinger bridge 问题，使用 static entropy-regularized optimal transport 或者 minibatch approximation 来有效地学习 SB 问题。</li>
<li>results: 通过应用 SF2M 方法，可以准确地模型高维细胞动态模型，并且可以回归知道的基因调控网络。此外，SF2M 方法比之前的 simulate-based 方法更高效和更准确。<details>
<summary>Abstract</summary>
We present simulation-free score and flow matching ([SF]$^2$M), a simulation-free objective for inferring stochastic dynamics given unpaired source and target samples drawn from arbitrary distributions. Our method generalizes both the score-matching loss used in the training of diffusion models and the recently proposed flow matching loss used in the training of continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic generative modeling as a Schr\"odinger bridge (SB) problem. It relies on static entropy-regularized optimal transport, or a minibatch approximation, to efficiently learn the SB without simulating the learned stochastic process. We find that [SF]$^2$M is more efficient and gives more accurate solutions to the SB problem than simulation-based methods from prior work. Finally, we apply [SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably, [SF]$^2$M is the first method to accurately model cell dynamics in high dimensions and can recover known gene regulatory networks from simulated data.
</details>
<details>
<summary>摘要</summary>
我们提出了一个无 simulate 的得分和流动匹配（[SF]$^2$M），它是一个无 simulate 的目标，用于对未配对的源和目标样本进行推测 Stochastic 动力学。我们的方法扩展了对于传播模型的训练中使用的得分匹配损失，以及最近提出的流动匹配损失，用于对紧致常态流动的训练。[SF]$^2$M 视为连续时间的泊松桥（SB）问题，并且透过静止 entropy 调整的最佳运输或批处替代方法来快速学习 SB 无需运行学习的数学过程。我们发现 [SF]$^2$M 比从先前的作业中的 simulate 方法更加高效且更精准地解决 SB 问题。最后，我们应用 [SF]$^2$M 来学习细胞动力学从快照数据中。特别是，[SF]$^2$M 是高维度细胞动力学的首个精准模型，并且可以从实验数据中回传知名的遗传因子网络。
</details></li>
</ul>
<hr>
<h2 id="Online-Network-Source-Optimization-with-Graph-Kernel-MAB"><a href="#Online-Network-Source-Optimization-with-Graph-Kernel-MAB" class="headerlink" title="Online Network Source Optimization with Graph-Kernel MAB"></a>Online Network Source Optimization with Graph-Kernel MAB</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03641">http://arxiv.org/abs/2307.03641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Toni, Pascal Frossard</li>
<li>for: 学习在大规模网络中最优化来自未知网络过程的奖励。</li>
<li>methods: 使用图kernels多臂抽象算法和适应性图字典模型来实现在线学习，并使用 Grab-UCB 在线顺序决策策略来学习参数。</li>
<li>results: 在 simulations 中，提议的在线学习算法比基准Offline方法更高效，并且在聚合约束和计算复杂度方面具有更好的性能。<details>
<summary>Abstract</summary>
We propose Grab-UCB, a graph-kernel multi-arms bandit algorithm to learn online the optimal source placement in large scale networks, such that the reward obtained from a priori unknown network processes is maximized. The uncertainty calls for online learning, which suffers however from the curse of dimensionality. To achieve sample efficiency, we describe the network processes with an adaptive graph dictionary model, which typically leads to sparse spectral representations. This enables a data-efficient learning framework, whose learning rate scales with the dimension of the spectral representation model instead of the one of the network. We then propose Grab-UCB, an online sequential decision strategy that learns the parameters of the spectral representation while optimizing the action strategy. We derive the performance guarantees that depend on network parameters, which further influence the learning curve of the sequential decision strategy We introduce a computationally simplified solving method, Grab-arm-Light, an algorithm that walks along the edges of the polytope representing the objective function. Simulations results show that the proposed online learning algorithm outperforms baseline offline methods that typically separate the learning phase from the testing one. The results confirm the theoretical findings, and further highlight the gain of the proposed online learning strategy in terms of cumulative regret, sample efficiency and computational complexity.
</details>
<details>
<summary>摘要</summary>
我们提议Grab-UCB算法，用图kernel多臂牌 Algorithm to learn在大规模网络中的优化来源分配，以 Maximize the reward from a priori unknown network processes. 因为uncertainty calls for online learning, which suffers from the curse of dimensionality. To achieve sample efficiency, we use an adaptive graph dictionary model to describe the network processes, which typically leads to sparse spectral representations. This enables a data-efficient learning framework, whose learning rate scales with the dimension of the spectral representation model instead of the one of the network. We then propose Grab-UCB, an online sequential decision strategy that learns the parameters of the spectral representation while optimizing the action strategy. We derive the performance guarantees that depend on network parameters, which further influence the learning curve of the sequential decision strategy. We introduce a computationally simplified solving method, Grab-arm-Light, an algorithm that walks along the edges of the polytope representing the objective function. Simulation results show that the proposed online learning algorithm outperforms baseline offline methods that typically separate the learning phase from the testing one. The results confirm the theoretical findings, and further highlight the gain of the proposed online learning strategy in terms of cumulative regret, sample efficiency, and computational complexity.Note: The translation is in Simplified Chinese, which is a standardized form of Chinese used in mainland China and Singapore. The translation may vary depending on the region or dialect.
</details></li>
</ul>
<hr>
<h2 id="PAC-bounds-of-continuous-Linear-Parameter-Varying-systems-related-to-neural-ODEs"><a href="#PAC-bounds-of-continuous-Linear-Parameter-Varying-systems-related-to-neural-ODEs" class="headerlink" title="PAC bounds of continuous Linear Parameter-Varying systems related to neural ODEs"></a>PAC bounds of continuous Linear Parameter-Varying systems related to neural ODEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03630">http://arxiv.org/abs/2307.03630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dániel Rácz, Mihály Petreczky, Bálint Daróczy</li>
<li>for: 本研究考虑了使用神经ordinary differential equation（neural ODE）在连续时间中学习线性参数变化（LPV）系统。</li>
<li>methods: 本文使用了LPV系统中的 bilinear系统，并证明了一类神经ODE可以被LPV系统中嵌入。作者还提供了一种 Probably Approximately Correct（PAC） bound，用于量化LPV系统相关神经ODE的稳定性。</li>
<li>results: 本文的主要贡献是提供了不依赖于集成时间的PAC bound，用于量化LPV系统相关神经ODE的稳定性。<details>
<summary>Abstract</summary>
We consider the problem of learning Neural Ordinary Differential Equations (neural ODEs) within the context of Linear Parameter-Varying (LPV) systems in continuous-time. LPV systems contain bilinear systems which are known to be universal approximators for non-linear systems. Moreover, a large class of neural ODEs can be embedded into LPV systems. As our main contribution we provide Probably Approximately Correct (PAC) bounds under stability for LPV systems related to neural ODEs. The resulting bounds have the advantage that they do not depend on the integration interval.
</details>
<details>
<summary>摘要</summary>
我们考虑了内联神经ordinary differential equations（内联神经ODE）在连续时间中的学习问题，具体来说是在线性参数变量（LPV）系统中。LPV系统包含bilinear系统，这些系统是非线性系统的通用近似器。此外，大量的内联神经ODE可以被LPV系统中嵌入。作为我们的主要贡献，我们提供了可靠地近似正确（PAC）的下界，这些下界不依赖于集成时间。
</details></li>
</ul>
<hr>
<h2 id="Toward-High-Performance-Energy-and-Power-Battery-Cells-with-Machine-Learning-based-Optimization-of-Electrode-Manufacturing"><a href="#Toward-High-Performance-Energy-and-Power-Battery-Cells-with-Machine-Learning-based-Optimization-of-Electrode-Manufacturing" class="headerlink" title="Toward High-Performance Energy and Power Battery Cells with Machine Learning-based Optimization of Electrode Manufacturing"></a>Toward High-Performance Energy and Power Battery Cells with Machine Learning-based Optimization of Electrode Manufacturing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05521">http://arxiv.org/abs/2307.05521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Duquesnoy, Chaoyue Liu, Vishank Kumar, Elixabete Ayerbe, Alejandro A. Franco</li>
<li>for: 本研究旨在优化锂离子电池电极生产过程，以满足增长的能源需求。特别是锂离子电池生产的优化非常重要，因为它会影响电池在应用中的实际性能。</li>
<li>methods: 本研究提出了一种数据驱动的机器学习（ML）助记录管道，用于对电解质性能进行双目标优化。该管道使得可逆设计制造过程参数，以生产适用于能量或动力应用的电极。这与我们之前的研究相似，在改进电极微结构中提高了电解质传输性能。</li>
<li>results: 我们的结果表明，以高活跃物质和中间固体含量和满化程度为优化目标，可以获得优化的电极。<details>
<summary>Abstract</summary>
The optimization of the electrode manufacturing process is important for upscaling the application of Lithium Ion Batteries (LIBs) to cater for growing energy demand. In particular, LIB manufacturing is very important to be optimized because it determines the practical performance of the cells when the latter are being used in applications such as electric vehicles. In this study, we tackled the issue of high-performance electrodes for desired battery application conditions by proposing a powerful data-driven approach supported by a deterministic machine learning (ML)-assisted pipeline for bi-objective optimization of the electrochemical performance. This ML pipeline allows the inverse design of the process parameters to adopt in order to manufacture electrodes for energy or power applications. The latter work is an analogy to our previous work that supported the optimization of the electrode microstructures for kinetic, ionic, and electronic transport properties improvement. An electrochemical pseudo-two-dimensional model is fed with the electrode properties characterizing the electrode microstructures generated by manufacturing simulations and used to simulate the electrochemical performances. Secondly, the resulting dataset was used to train a deterministic ML model to implement fast bi-objective optimizations to identify optimal electrodes. Our results suggested a high amount of active material, combined with intermediate values of solid content in the slurry and calendering degree, to achieve the optimal electrodes.
</details>
<details>
<summary>摘要</summary>
降低锂离子电池（LIB）生产过程优化的重要性，是因为它会影响电池在实际应用中的实际性。例如，在电动汽车中使用的电池。在这种研究中，我们通过提出一种强大的数据驱动方法，支持由确定性机器学习（ML）托管的双目标优化管道，来解决高性能电极的问题。这个ML管道允许逆向设计生产参数，以生产适用于能量或功率应用的电极。这与我们之前的工作相似，曾经支持电极微结构优化，以提高电池的离子、镁和电子传输性能。一个电化学 Pseudo-二维模型，通过电极性能特征来模拟电化学性能。其次，生成的数据集用于训练一个确定性ML模型，以实现快速双目标优化，并提取最佳电极。我们的结果表明，高活性材料和中值的固体含量和滚筒度，可以实现最佳电极。
</details></li>
</ul>
<hr>
<h2 id="GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting"><a href="#GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting" class="headerlink" title="GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting"></a>GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03595">http://arxiv.org/abs/2307.03595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Vincent Quenneville-Belair, Ronak Metha, Michael W. Mahoney</li>
<li>for: 本研究旨在解决深度神经网络模型在缺乏历史数据的情况下进行多个时间序列预测，即“冷启动”问题。</li>
<li>methods: 该研究提出了一种使用图神经网络（GNN）作为预测器的数据增强方法，通过捕捉多个时间序列之间的复杂关系来增强预测器的编码器。</li>
<li>results: 研究在target应用中，对一家大型电子商务公司的需求预测 task 进行了测试，并表明其方法在小数据集（100K产品）和大数据集（超过200W产品）上均显著提高了模型的总性能，尤其是对于“冷启动”产品（新上市或者Recently out-of-stock）的预测性能具有显著的提升。<details>
<summary>Abstract</summary>
Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting, especially in real-world applications. However, to forecast accurately, these sophisticated models typically rely on a large number of time series examples with substantial history. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data -- often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships, and their generation process can be optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge-defined graphs, scaling to incorporate information from multiple very large graphs with millions of nodes. In our target application of demand forecasting for a large e-commerce retailer, we demonstrate on both a small dataset of 100K products and a large dataset with over 2 million products that our method improves overall performance over competitive baseline models. More importantly, we show that it brings substantially more gains to ``cold start'' products such as those newly launched or recently out-of-stock.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传输文本到Simplified Chinese表示。<</SYS>>深度神经网络（encoder-decoder）在实际应用中得到了更多研究，特别是用于多个时间序列预测。然而，为了准确预测，这些复杂的模型通常需要大量的时间序列示例，而且这些示例通常具有较长的历史记录。在这篇论文中，我们介绍了一种新的简单方法，利用图 neural network（GNN）作为编码器的数据扩充，以提高预测性能。这些GNN基于的特征可以捕捉复杂的时间序列之间关系，并且其生成过程可以通过预测任务进行END-TO-END优化。我们表明，我们的架构可以使用数据驱动或定义在领域知识图中的图，并可扩展到涉及多个巨大图的信息。在我们的目标应用中，我们在100000个产品的小数据集和超过2000000个产品的大数据集上进行了实验，并证明了我们的方法在相比基eline模型的情况下提高了总性能。更重要的是，我们发现在“冷启动”产品上（例如新推出或者售罄），我们的方法带来了极大的改善。
</details></li>
</ul>
<hr>
<h2 id="Accelerated-Optimization-Landscape-of-Linear-Quadratic-Regulator"><a href="#Accelerated-Optimization-Landscape-of-Linear-Quadratic-Regulator" class="headerlink" title="Accelerated Optimization Landscape of Linear-Quadratic Regulator"></a>Accelerated Optimization Landscape of Linear-Quadratic Regulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03590">http://arxiv.org/abs/2307.03590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lechen Feng, Yuan-Hua Ni</li>
<li>for: 这篇论文关注的是优化控制领域的线性quadratic regulator（LQR）问题。</li>
<li>methods: 该论文提出了一种基于首频减速优化框架的LQR问题解决方案，并对SLQR和OLQR两种不同情况进行了分别的分析。</li>
<li>results: 研究人员通过提出一种 Lipschitz Hessian 性质的LQR性能函数，以及利用 симплекс 牛顿方法和重启规则来保持连续时间的优化率，实现了对SLQR和OLQR问题的高精度解决。<details>
<summary>Abstract</summary>
Linear-quadratic regulator (LQR) is a landmark problem in the field of optimal control, which is the concern of this paper. Generally, LQR is classified into state-feedback LQR (SLQR) and output-feedback LQR (OLQR) based on whether the full state is obtained. It has been suggested in existing literature that both the SLQR and the OLQR could be viewed as \textit{constrained nonconvex matrix optimization} problems in which the only variable to be optimized is the feedback gain matrix. In this paper, we introduce a first-order accelerated optimization framework of handling the LQR problem, and give its convergence analysis for the cases of SLQR and OLQR, respectively.   Specifically, a Lipschiz Hessian property of LQR performance criterion is presented, which turns out to be a crucial property for the application of modern optimization techniques. For the SLQR problem, a continuous-time hybrid dynamic system is introduced, whose solution trajectory is shown to converge exponentially to the optimal feedback gain with Nesterov-optimal order $1-\frac{1}{\sqrt{\kappa}$ ($\kappa$ the condition number). Then, the symplectic Euler scheme is utilized to discretize the hybrid dynamic system, and a Nesterov-type method with a restarting rule is proposed that preserves the continuous-time convergence rate, i.e., the discretized algorithm admits the Nesterov-optimal convergence order. For the OLQR problem, a Hessian-free accelerated framework is proposed, which is a two-procedure method consisting of semiconvex function optimization and negative curvature exploitation. In a time $\mathcal{O}(\epsilon^{-7/4}\log(1/\epsilon))$, the method can find an $\epsilon$-stationary point of the performance criterion; this entails that the method improves upon the $\mathcal{O}(\epsilon^{-2})$ complexity of vanilla gradient descent. Moreover, our method provides the second-order guarantee of stationary point.
</details>
<details>
<summary>摘要</summary>
Linear-quadratic regulator (LQR) 是控制理论中的一个标志性问题，这篇文章的研究对象。通常情况下，LQR可以分为基于状态反馈（SLQR）和基于输出反馈（OLQR）两种，根据是否获得全状态。在现有文献中，有人提出了视为非对称矩阵优化问题的思路，其中仅仅是反馈矩阵进行优化。在这篇文章中，我们介绍了一种基于首频加速优化框架，并对 SLQR 和 OLQR 两种情况进行了分别的可控性分析。 Specifically, we present a Lipschitz Hessian property of LQR performance criterion, which turns out to be a crucial property for the application of modern optimization techniques. For the SLQR problem, we introduce a continuous-time hybrid dynamic system, whose solution trajectory is shown to converge exponentially to the optimal feedback gain with Nesterov-optimal order $1-\frac{1}{\sqrt{\kappa}$ ($\kappa$ the condition number). Then, the symplectic Euler scheme is utilized to discretize the hybrid dynamic system, and a Nesterov-type method with a restarting rule is proposed that preserves the continuous-time convergence rate, i.e., the discretized algorithm admits the Nesterov-optimal convergence order. For the OLQR problem, we propose a Hessian-free accelerated framework, which is a two-procedure method consisting of semiconvex function optimization and negative curvature exploitation. In a time $\mathcal{O}(\epsilon^{-7/4}\log(1/\epsilon))$, the method can find an $\epsilon$-stationary point of the performance criterion; this entails that the method improves upon the $\mathcal{O}(\epsilon^{-2})$ complexity of vanilla gradient descent. Moreover, our method provides the second-order guarantee of stationary point.
</details></li>
</ul>
<hr>
<h2 id="BOF-UCB-A-Bayesian-Optimistic-Frequentist-Algorithm-for-Non-Stationary-Contextual-Bandits"><a href="#BOF-UCB-A-Bayesian-Optimistic-Frequentist-Algorithm-for-Non-Stationary-Contextual-Bandits" class="headerlink" title="BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits"></a>BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03587">http://arxiv.org/abs/2307.03587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicklas Werge, Abdullah Akgül, Melih Kandemir</li>
<li>for: 这个论文旨在提出一种新的 bayesian-optimistic frequentist upper confidence bound（BOF-UCB）算法，用于 Stochastic Contextual Linear Bandits（SCLB）中的非站ARY环境。</li>
<li>methods: 这个算法利用累缲 Bayesian 更新来推算未知的回归参数 posterior distribution，然后使用频quentist方法计算 Upper Confidence Bound（UCB），将最大化预期回归在 posterior distribution 上。</li>
<li>results: 我们提供了 BOF-UCB 的性能理论保证，并在实验中显示它在 Synthetic 数据和 classical control 任务中能够平衡寻找和实现，并且在非站ARY环境中表现比 existing methods 更好。<details>
<summary>Abstract</summary>
We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的泛bayesian-Optimistic Frequentist Upper Confidence Bound（BOF-UCB）算法，用于非站点环境下的随机contextual linear bandit。这种独特的bayesian和频quentist原则的结合，提高了适应性和性能在动态环境下。BOF-UCB算法通过顺序的bayesian更新来推算未知回归参数的 posterior distribution，然后使用频quentist方法计算最大期望奖励的Upper Confidence Bound（UCB）。我们提供了BOF-UCB性能的理论保证，并在synthetic数据集和 классиcal控制任务中的reinforcement learning Setting中进行了实验证明。我们的结果表明，BOF-UCB超越了现有方法，这使得它成为非站点环境下的sequential decision-making的优秀解决方案。
</details></li>
</ul>
<hr>
<h2 id="ContextLabeler-Dataset-physical-and-virtual-sensors-data-collected-from-smartphone-usage-in-the-wild"><a href="#ContextLabeler-Dataset-physical-and-virtual-sensors-data-collected-from-smartphone-usage-in-the-wild" class="headerlink" title="ContextLabeler Dataset: physical and virtual sensors data collected from smartphone usage in-the-wild"></a>ContextLabeler Dataset: physical and virtual sensors data collected from smartphone usage in-the-wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03586">http://arxiv.org/abs/2307.03586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mattia Giovanni Campana, Franca Delmastro</li>
<li>for: 这 paper 描述了一个数据采集计划和从智能手机传感器获得的相关 daily life 活动的数据集，包括 3 名志愿者在 2 周的时间内进行的数据采集。这个数据集包含超过 45K 个数据样本，每个样本包含 1332 个特征，其中包括运动传感器、运行中的应用程序、附近设备和天气条件等多种物理和虚拟传感器。此外，每个数据样本还关联着一个真实的 Label，描述用户在感测实验中的活动和情况（例如，工作、在餐厅、进行体育活动等）。</li>
<li>methods: 作者使用了智能手机传感器进行数据采集，并没有对用户的行为做任何干扰或限制。这使得收集到的数据成为了一个不受干扰的、真实的数据集，可以用于定义和评估一 broad 范围内的 context-aware 解决方案（包括算法和协议），以适应移动环境中的用户情况变化。</li>
<li>results: 作者收集到了一个包含超过 45K 个数据样本的数据集，每个样本包含 1332 个特征。此外，每个数据样本还关联着一个真实的 Label，描述用户在感测实验中的活动和情况。这个数据集可以用于定义和评估 context-aware 解决方案，以适应移动环境中的用户情况变化。<details>
<summary>Abstract</summary>
This paper describes a data collection campaign and the resulting dataset derived from smartphone sensors characterizing the daily life activities of 3 volunteers in a period of two weeks. The dataset is released as a collection of CSV files containing more than 45K data samples, where each sample is composed by 1332 features related to a heterogeneous set of physical and virtual sensors, including motion sensors, running applications, devices in proximity, and weather conditions. Moreover, each data sample is associated with a ground truth label that describes the user activity and the situation in which she was involved during the sensing experiment (e.g., working, at restaurant, and doing sport activity). To avoid introducing any bias during the data collection, we performed the sensing experiment in-the-wild, that is, by using the volunteers' devices, and without defining any constraint related to the user's behavior. For this reason, the collected dataset represents a useful source of real data to both define and evaluate a broad set of novel context-aware solutions (both algorithms and protocols) that aim to adapt their behavior according to the changes in the user's situation in a mobile environment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Programmable-Synthetic-Tabular-Data-Generation"><a href="#Programmable-Synthetic-Tabular-Data-Generation" class="headerlink" title="Programmable Synthetic Tabular Data Generation"></a>Programmable Synthetic Tabular Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03577">http://arxiv.org/abs/2307.03577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Vero, Mislav Balunović, Martin Vechev</li>
<li>for: 生成具有约束的Tabular数据，以便在具有隐私、数据质量和数据共享限制的情况下进行大量数据的利用。</li>
<li>methods: ProgSyn使用了一种可编程的生成模型，通过在原始数据集上预训练并在基于提供的特定需求自动 derivation的梯度下细化，以确保生成的数据具有高质量并遵循特定需求。</li>
<li>results: ProgSyn在多种约束下达到了新的状态功能，如在Adult数据集上保持同等公平性水平下提高了下游预测性能2.3%。总的来说，ProgSyn提供了一个 versatile 和可 accessible的框架，用于生成具有约束的Tabular数据，并允许特定需求的扩展。<details>
<summary>Abstract</summary>
Large amounts of tabular data remain underutilized due to privacy, data quality, and data sharing limitations. While training a generative model producing synthetic data resembling the original distribution addresses some of these issues, most applications require additional constraints from the generated data. Existing synthetic data approaches are limited as they typically only handle specific constraints, e.g., differential privacy (DP) or increased fairness, and lack an accessible interface for declaring general specifications. In this work, we introduce ProgSyn, the first programmable synthetic tabular data generation algorithm that allows for comprehensive customization over the generated data. To ensure high data quality while adhering to custom specifications, ProgSyn pre-trains a generative model on the original dataset and fine-tunes it on a differentiable loss automatically derived from the provided specifications. These can be programmatically declared using statistical and logical expressions, supporting a wide range of requirements (e.g., DP or fairness, among others). We conduct an extensive experimental evaluation of ProgSyn on a number of constraints, achieving a new state-of-the-art on some, while remaining general. For instance, at the same fairness level we achieve 2.3% higher downstream accuracy than the state-of-the-art in fair synthetic data generation on the Adult dataset. Overall, ProgSyn provides a versatile and accessible framework for generating constrained synthetic tabular data, allowing for specifications that generalize beyond the capabilities of prior work.
</details>
<details>
<summary>摘要</summary>
大量的表格数据因为隐私、数据质量和数据共享限制而尚未得到充分利用。训练一个生成模型生成具有原始分布的 sintetic 数据可以解决一些问题，但大多数应用需要更多的约束来限制生成的数据。现有的 sintetic 数据方法有限，它们通常只能处理特定的约束，如差分隐私（DP）或增强公平，而且缺乏可访问的接口来声明通用规则。在这项工作中，我们介绍ProgSyn，首个可编程的 sintetic 表格数据生成算法，允许用户根据需要进行全面的定制。为保证高质量的生成数据，ProgSyn在原始数据集上预训练生成模型，然后在基于提供的规则自动生成的差分损失上进行细化。这些规则可以使用统计和逻辑表达式进行程序matically声明，支持广泛的要求（例如DP或公平等）。我们在一些约束下进行了广泛的实验测试， achieved 新的状态 искусственный数据生成的状态之一，在一些约束下达到了新的状态之一，而且可以泛化。例如，在保持同等公平水平下，我们在Adult数据集上 achieved 2.3% 更高的下游准确率，比之前的最佳状态更高。总之，ProgSyn 提供了一个通用、可访问的 sintetic 表格数据生成框架，允许用户根据需要声明约束，这些约束可以超越现有的工作的能力。
</details></li>
</ul>
<hr>
<h2 id="One-Step-of-Gradient-Descent-is-Provably-the-Optimal-In-Context-Learner-with-One-Layer-of-Linear-Self-Attention"><a href="#One-Step-of-Gradient-Descent-is-Provably-the-Optimal-In-Context-Learner-with-One-Layer-of-Linear-Self-Attention" class="headerlink" title="One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"></a>One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03576">http://arxiv.org/abs/2307.03576</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arvind Mahankali, Tatsunori B. Hashimoto, Tengyu Ma</li>
<li>for: 本研究目的是研究一层线性自注意力层（Transformer）在各种不同噪音和回归函数下的学习行为。</li>
<li>methods: 本研究使用了一层线性自注意力层，并在各种噪音和回归函数下进行了预训练。</li>
<li>results: 研究发现，当covariate从标准高斯分布中采样时，一层线性自注意力层会在最小二乘回归目标下进行单步Gradient Descent（GD）。而在非标准高斯分布下，改变weight vector和响应变量的分布会导致学习的算法发生显著变化。<details>
<summary>Abstract</summary>
Recent works have empirically analyzed in-context learning and shown that transformers trained on synthetic linear regression tasks can learn to implement ridge regression, which is the Bayes-optimal predictor, given sufficient capacity [Aky\"urek et al., 2023], while one-layer transformers with linear self-attention and no MLP layer will learn to implement one step of gradient descent (GD) on a least-squares linear regression objective [von Oswald et al., 2022]. However, the theory behind these observations remains poorly understood. We theoretically study transformers with a single layer of linear self-attention, trained on synthetic noisy linear regression data. First, we mathematically show that when the covariates are drawn from a standard Gaussian distribution, the one-layer transformer which minimizes the pre-training loss will implement a single step of GD on the least-squares linear regression objective. Then, we find that changing the distribution of the covariates and weight vector to a non-isotropic Gaussian distribution has a strong impact on the learned algorithm: the global minimizer of the pre-training loss now implements a single step of $\textit{pre-conditioned}$ GD. However, if only the distribution of the responses is changed, then this does not have a large effect on the learned algorithm: even when the response comes from a more general family of $\textit{nonlinear}$ functions, the global minimizer of the pre-training loss still implements a single step of GD on a least-squares linear regression objective.
</details>
<details>
<summary>摘要</summary>
近期研究探讨了在上下文中学习，并证明了使用生成的线性回归任务训练的变换器可以学习实现ridge回归，即极值优化预测器，只要容量足够大 [Aky\"urek et al., 2023]。另一方面，一层变换器 WITH linear self-attention 和无MLP层会学习实现一步Gradient Descent（GD）在最小二乘线性回归目标上 [von Oswald et al., 2022]。然而，这些观察的理论基础还未得到充分理解。我们在变换器中使用单层线性自注意力进行理论研究，并在生成噪声线性回归数据上训练。我们首先 математиче地表明，当covariates从标准 Gaussian 分布中采样时，一层变换器最小化预训练损失将实现一步GD在最小二乘线性回归目标上。然后，我们发现将covariates和重量 вектор从标准 Gaussian 分布更改为非均勋 Gaussian 分布会导致学习的算法强烈受到影响：全局最小化预训练损失的算法将实现一步pre-conditioned GD。但是，只是更改响应的分布而不是weight vector的分布，则不会导致很大的影响：即使响应来自更一般的非线性函数家族，全局最小化预训练损失的算法仍然会实现一步GD在最小二乘线性回归目标上。
</details></li>
</ul>
<hr>
<h2 id="Smoothing-the-Edges-A-General-Framework-for-Smooth-Optimization-in-Sparse-Regularization-using-Hadamard-Overparametrization"><a href="#Smoothing-the-Edges-A-General-Framework-for-Smooth-Optimization-in-Sparse-Regularization-using-Hadamard-Overparametrization" class="headerlink" title="Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization"></a>Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03571">http://arxiv.org/abs/2307.03571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chris Kolb, Christian L. Müller, Bernd Bischl, David Rügamer</li>
<li>for: 本文提出了一种框架，用于平滑优化目标函数中的 $\ell_q$ 和 $\ell_{p,q}$ 正则化，以实现结构化稀疏性。</li>
<li>methods: 本方法使用了常用的随机梯度下降算法，而不需要特殊的优化算法，从而实现了可导的稀疏正则化无需简化。</li>
<li>results: 我们的方法可以具有与普通的 convex 正则化一样的全局最优解，并且可以保证地具有原始参数化中的本地最优解。此外，我们还提供了一个整合的视角，汇集了不同的参数化Literature中的概念，并对现有方法进行了meaningful扩展。在数值实验中，我们证明了我们的方法的可行性和效果，与常见的凸和非凸正则化相比，能够匹配或超越。<details>
<summary>Abstract</summary>
This paper presents a framework for smooth optimization of objectives with $\ell_q$ and $\ell_{p,q}$ regularization for (structured) sparsity. Finding solutions to these non-smooth and possibly non-convex problems typically relies on specialized optimization routines. In contrast, the method studied here is compatible with off-the-shelf (stochastic) gradient descent that is ubiquitous in deep learning, thereby enabling differentiable sparse regularization without approximations. The proposed optimization transfer comprises an overparametrization of selected model parameters followed by a change of penalties. In the overparametrized problem, smooth and convex $\ell_2$ regularization induces non-smooth and non-convex regularization in the original parametrization. We show that the resulting surrogate problem not only has an identical global optimum but also exactly preserves the local minima. This is particularly useful in non-convex regularization, where finding global solutions is NP-hard and local minima often generalize well. We provide an integrative overview that consolidates various literature strands on sparsity-inducing parametrizations in a general setting and meaningfully extend existing approaches. The feasibility of our approach is evaluated through numerical experiments, demonstrating its effectiveness by matching or outperforming common implementations of convex and non-convex regularizers.
</details>
<details>
<summary>摘要</summary>
（简化中文）这篇论文提出了一种基于 $\ell_q$ 和 $\ell_{p,q}$ 正则化的对象函数的平滑优化框架，用于Structured sparsity。现有的特殊化优化方法通常用于解决这些非短途和非凸问题。然而，提出的方法与深度学习中广泛使用的Stochastic gradient descent（SGD）兼容，可以无需 aproximations 实现 differentiable sparse regularization。优化转移包括在选择的模型参数上进行过参数化，然后改变 penalty。过参数化的问题会导致 smooth 和 convex $\ell_2$ regularization 在原始参数化中induces non-smooth 和 non-convex regularization。我们证明了这个代理问题不仅有identical global optimum，还能够 exactly preserve local minima。这 particualrly useful in non-convex regularization，因为找到全局解是NP-hard，而local minima通常 generalize well。我们提供了一个整合性的Overview，汇集了不同的文献弦线程在一个通用的设定下，并meaningfully extends existing approaches。 feasibility of our approach is evaluated through numerical experiments, demonstrating its effectiveness by matching or outperforming common implementations of convex and non-convex regularizers。
</details></li>
</ul>
<hr>
<h2 id="MALIBO-Meta-learning-for-Likelihood-free-Bayesian-Optimization"><a href="#MALIBO-Meta-learning-for-Likelihood-free-Bayesian-Optimization" class="headerlink" title="MALIBO: Meta-learning for Likelihood-free Bayesian Optimization"></a>MALIBO: Meta-learning for Likelihood-free Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03565">http://arxiv.org/abs/2307.03565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiarong Pan, Stefan Falkner, Felix Berkenkamp, Joaquin Vanschoren</li>
<li>for: 这个研究的目的是提出一种基于meta-学习的bayesian搜寻（BO）方法，以便更快地优化成本高的黑盒函数。</li>
<li>methods: 这个方法不使用代理模型，而是直接从不同任务之间的相似性学习query的价值。它还包括一个辅助模型，以便在新任务中进行稳定的适应。</li>
<li>results: 实验结果显示，这个方法在不同的benchmark中展示了强大的任何时间性和超越了现有的meta-学习BO方法。<details>
<summary>Abstract</summary>
Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that our method demonstrates strong anytime performance and outperforms state-of-the-art meta-learning BO methods in various benchmarks.
</details>
<details>
<summary>摘要</summary>
bayesian 优化（BO）是一种常用的优化昂贵黑色函数的方法。而传统的 BO 每次新的目标任务都从scratch开始优化，而 meta-learning 则是一种能够借鉴相关任务来快速优化新任务的方法。然而，现有的 meta-learning BO 方法通常依赖于不准确的代理模型，这些模型受到任务规模和噪声的影响，导致缺乏可扩展性和可靠性。此外，它们经常忽略任务之间的uncertainty。这会导致在只有有限的观察数据时或者新任务与相关任务存在差异时，task adaptation 不可靠。为了解决这些限制，我们提出了一种新的 meta-learning BO 方法，该方法 circumvents 代理模型，直接在任务间学习查询的用于性。我们的方法显式地模型任务的uncertainty，并采用 auxilary 模型来实现鲁棒的任务适应性。我们的实验表明，我们的方法在不同的 benchmark 中具有强大的任何时间性和超越了当前的 meta-learning BO 方法。
</details></li>
</ul>
<hr>
<h2 id="DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling"><a href="#DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling" class="headerlink" title="DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling"></a>DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03550">http://arxiv.org/abs/2307.03550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ipek Baris Schlicht, Lynn Khellaf, Defne Altiok</li>
<li>for: 本研究投稿于CheckThat! Lab的主观检测任务中，以解决任务中的类别不均衡问题。</li>
<li>methods: 使用GPT-3模型生成基于新闻方面的主观检查列表的提问，并使用这些提问生成更多的训练材料。使用扩展的训练集进行语言特定的变换器模型的练习。</li>
<li>results: 在英语、德语和土耳其语中，发现不同的主观风格都是有效的，而风格基本替换在土耳其语和英语中效果更好。然而，GPT-3模型在非英语语言中生成风格基本文本时有时会表现不佳。<details>
<summary>Abstract</summary>
This paper describes our submission for the subjectivity detection task at the CheckThat! Lab. To tackle class imbalances in the task, we have generated additional training materials with GPT-3 models using prompts of different styles from a subjectivity checklist based on journalistic perspective. We used the extended training set to fine-tune language-specific transformer models. Our experiments in English, German and Turkish demonstrate that different subjective styles are effective across all languages. In addition, we observe that the style-based oversampling is better than paraphrasing in Turkish and English. Lastly, the GPT-3 models sometimes produce lacklustre results when generating style-based texts in non-English languages.
</details>
<details>
<summary>摘要</summary>
这份论文描述了我们在CheckThat! Lab中的主观检测任务提交。为了解决任务中的类别不均衡，我们使用基于新闻业观点的主观检查表 generator GPT-3 模型生成了额外的训练材料。我们使用这些扩展训练集来练化语言特定的转换器模型。我们的实验表明，不同的主观风格在所有语言中都是有效的。此外，我们发现在土耳其语和英语中，风格基本替换比paraphrasing更有效。最后，GPT-3 模型在非英语语言中生成风格基本文本时有时会表现平庸。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks"><a href="#Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks" class="headerlink" title="Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks"></a>Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03761">http://arxiv.org/abs/2307.03761</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MengjieZhao/dygatad">https://github.com/MengjieZhao/dygatad</a></li>
<li>paper_authors: Mengjie Zhao, Olga Fink</li>
<li>for: 这篇论文主要是为了探讨运算系统监控中的异常探测问题，尤其是运算系统监控数据中的多变量时间序列（MTS）数据，并提出了一个基于图形的异常探测方法来解决这个问题。</li>
<li>methods: 这篇论文提出了一个名为 DyGATAD（动态图形注意力异常探测）的图形基于异常探测方法，这个方法利用注意力机制来建构一个当前运算系统监控数据中的连续图形表示，并且考虑了系统中各个时间序列之间的关系变化。</li>
<li>results: 这篇论文透过使用实验和工业规模的多相运输设备实验，证明了 DyGATAD 方法在运算系统监控数据中的异常探测能力，特别是在早期发现 fault 的情况下表现出色，甚至在 fault 的严重程度很低时也能够实现高精度的探测。<details>
<summary>Abstract</summary>
In the era of digital transformation, systems monitored by the Industrial Internet of Things (IIoTs) generate large amounts of Multivariate Time Series (MTS) data through heterogeneous sensor networks. While this data facilitates condition monitoring and anomaly detection, the increasing complexity and interdependencies within the sensor network pose significant challenges for anomaly detection. Despite progress in this field, much of the focus has been on point anomalies and contextual anomalies, with lesser attention paid to collective anomalies. A less addressed but common variant of collective anomalies is when the abnormal collective behavior is caused by shifts in interrelationships within the system. This can be due to abnormal environmental conditions like overheating, improper operational settings resulting from cyber-physical attacks, or system-level faults. To address these challenges, this paper proposes DyGATAD (Dynamic Graph Attention for Anomaly Detection), a graph-based anomaly detection framework that leverages the attention mechanism to construct a continuous graph representation of multivariate time series by inferring dynamic edges between time series. DyGATAD incorporates an operating condition-aware reconstruction combined with a topology-based anomaly score, thereby enhancing the detection ability of relationship shifts. We evaluate the performance of DyGATAD using both a synthetic dataset with controlled varying fault severity levels and an industrial-scale multiphase flow facility benchmark featuring various fault types with different detection difficulties. Our proposed approach demonstrated superior performance in collective anomaly detection for sensor networks, showing particular strength in early-stage fault detection, even in the case of faults with minimal severity.
</details>
<details>
<summary>摘要</summary>
在数字转型时代，由工业互联网Of Things（IIoT）监控的系统会生成大量多变量时间序列（MTS）数据，该数据可以帮助condition monitoring和异常检测。然而，随着传感器网络的复杂度和互相关系的增加，异常检测受到了重大挑战。虽然在这个领域已经有了很多进展，但是大多数注意力是集中在点异常和上下文异常上，对集体异常的研究相对较少。一种较少被关注但很常见的集体异常情况是，在系统中的异常 коллектив行为是由系统间关系的变化引起的。这可能是因为环境条件异常（如过热）、不正确的操作设置（由于Cyber-physical attacks）或系统级别的故障。为解决这些挑战，这篇论文提出了 DyGATAD（动态图注意力异常检测），一种基于图的异常检测框架，通过注意力机制来构建多变量时间序列中的连续图表示。DyGATAD结合了运行条件感知重建和图形异常分数，从而提高了关系变化的检测能力。我们使用了一个synthetic数据集和一个工业级多相流设施测试数据来评估DyGATAD的性能。我们的提出的方法在感知器网络中的集体异常检测方面表现出色，特别是在早期异常检测和轻度异常检测方面。
</details></li>
</ul>
<hr>
<h2 id="Roman-Numeral-Analysis-with-Graph-Neural-Networks-Onset-wise-Predictions-from-Note-wise-Features"><a href="#Roman-Numeral-Analysis-with-Graph-Neural-Networks-Onset-wise-Predictions-from-Note-wise-Features" class="headerlink" title="Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features"></a>Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03544">http://arxiv.org/abs/2307.03544</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manoskary/chordgnn">https://github.com/manoskary/chordgnn</a></li>
<li>paper_authors: Emmanouil Karystinaios, Gerhard Widmer</li>
<li>for: 本研究旨在提出一种新的自动罗马数分析方法，用于把纯 симвоlic music 转化为罗马数表示。</li>
<li>methods: 该方法基于图神经网络（GNNs），可以直接处理每个音符的特征和间接关系。具有新的边减法，使得模型可以生成音符层次的表示。</li>
<li>results: 对于参考数据集，提出的 ChordGNN 模型表现更高精度，比对 existed 状态的艺术模型更高。此外，我们还 investigate 了模型的 variant，包括 NADE 和后处理技术。完整的代码可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Roman Numeral analysis is the important task of identifying chords and their functional context in pieces of tonal music. This paper presents a new approach to automatic Roman Numeral analysis in symbolic music. While existing techniques rely on an intermediate lossy representation of the score, we propose a new method based on Graph Neural Networks (GNNs) that enable the direct description and processing of each individual note in the score. The proposed architecture can leverage notewise features and interdependencies between notes but yield onset-wise representation by virtue of our novel edge contraction algorithm. Our results demonstrate that ChordGNN outperforms existing state-of-the-art models, achieving higher accuracy in Roman Numeral analysis on the reference datasets. In addition, we investigate variants of our model using proposed techniques such as NADE, and post-processing of the chord predictions. The full source code for this work is available at https://github.com/manoskary/chordgnn
</details>
<details>
<summary>摘要</summary>
Symbolic music中的罗马数字分析是一项重要的任务，旨在识别乐曲中的和声和其功能上下文。这篇论文提出了一种新的自动罗马数字分析方法，基于图神经网络（GNNs），可以直接描述乐曲中每个个音的特征和相互关系。我们的建议可以利用每个音的特征和间隔之间的相互关系，并通过我们的新的边缩合算法将每个音转换为和声表示。我们的结果表明，ChordGNN比现有的状态当前模型高效，在参照数据集上达到更高的罗马数字分析准确率。此外，我们还考虑了我们的模型的变体，使用提出的技术如NADE，以及后处理矩阵预测结果。完整的代码可以在https://github.com/manoskary/chordgnn上获取。
</details></li>
</ul>
<hr>
<h2 id="Do-DL-models-and-training-environments-have-an-impact-on-energy-consumption"><a href="#Do-DL-models-and-training-environments-have-an-impact-on-energy-consumption" class="headerlink" title="Do DL models and training environments have an impact on energy consumption?"></a>Do DL models and training environments have an impact on energy consumption?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05520">http://arxiv.org/abs/2307.05520</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GAISSA-UPC/seaa2023_ect">https://github.com/GAISSA-UPC/seaa2023_ect</a></li>
<li>paper_authors: Santiago del Rey, Silverio Martínez-Fernández, Luís Cruz, Xavier Franch</li>
<li>for: 降低深度学习模型训练时的碳脚印。</li>
<li>methods: 分析模型架构和训练环境对训练更绿色计算机视觉模型的影响。</li>
<li>results: 选择合适的模型架构和训练环境可以减少能源消耗（最高达98.83%），但 Correctness 下降很小。 GPU 适应模型计算复杂性的增长，以提高能效性。<details>
<summary>Abstract</summary>
Current research in the computer vision field mainly focuses on improving Deep Learning (DL) correctness and inference time performance. However, there is still little work on the huge carbon footprint that has training DL models. This study aims to analyze the impact of the model architecture and training environment when training greener computer vision models. We divide this goal into two research questions. First, we analyze the effects of model architecture on achieving greener models while keeping correctness at optimal levels. Second, we study the influence of the training environment on producing greener models. To investigate these relationships, we collect multiple metrics related to energy efficiency and model correctness during the models' training. Then, we outline the trade-offs between the measured energy efficiency and the models' correctness regarding model architecture, and their relationship with the training environment. We conduct this research in the context of a computer vision system for image classification. In conclusion, we show that selecting the proper model architecture and training environment can reduce energy consumption dramatically (up to 98.83%) at the cost of negligible decreases in correctness. Also, we find evidence that GPUs should scale with the models' computational complexity for better energy efficiency.
</details>
<details>
<summary>摘要</summary>
现有研究主要集中在深度学习（DL）正确性和推理速度表现 improvemen。然而，还没有很多关于训练DL模型的巨大碳脚印的工作。这种研究目标是分析训练绿色计算机视觉模型时的模型架构和训练环境的影响。我们将这个目标分成两个研究问题。第一个问题是分析保持正确性水平时实现绿色模型的模型架构的影响。第二个问题是研究训练环境对生成绿色模型的影响。为了调查这些关系，我们收集了多个能效性和模型正确性的指标 during 模型的训练。然后，我们描述了在模型架构和训练环境的影响下，能效性和正确性之间的交易。我们在图像分类计算机视觉系统中进行了这种研究。结果表明，选择合适的模型架构和训练环境可以减少能 consumption (最多98.83%)，同时对正确性的影响很小。此外，我们发现GPU在模型的计算复杂性增加时应该呈现加速的趋势，以实现更好的能效性。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks"><a href="#Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks" class="headerlink" title="Contrastive Graph Pooling for Explainable Classification of Brain Networks"></a>Contrastive Graph Pooling for Explainable Classification of Brain Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11133">http://arxiv.org/abs/2307.11133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Xu, Qingtian Bian, Xinhang Li, Aihu Zhang, Yiping Ke, Miao Qiao, Wei Zhang, Wei Khang Jeremy Sim, Balázs Gulyás</li>
<li>for: 这paper是用来探讨Functional magnetic resonance imaging (fMRI)数据的分析方法，特别是用于发现神经退化疾病如parkinson’s disease, Alzheimer’s disease 和autism spectrum disorder.</li>
<li>methods: 这paper使用了图神经网络（GNN）来提取特征，但是需要特殊的设计来适应fMRI数据的特点。该paper提出了一种对比性双重注意块和可微的图汇聚方法（ContrastPool），以更好地利用GNN来挖掘脑网络中的特征。</li>
<li>results: 该paper在5个休息态fMRI脑网络数据集上进行了应用，并证明了其在比较现有基线上的超越。case study表明，该方法提取的特征与 neuroscience文献中的领域知识匹配，并揭示了直观的发现。该paper的贡献表明了ContrastPool在理解脑网络和神经退化疾病方面的潜力。<details>
<summary>Abstract</summary>
Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions.
</details>
<details>
<summary>摘要</summary>
функциональная магнитная резонансная томография (fMRI) 是一种常用的技术来测量神经活化。它的应用尤其重要在发现下面的 нейродегенератив Conditions  such as Parkinson's, Alzheimer's, and Autism.  current analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions.Here's the translation in Traditional Chinese as well: функціональна магнітна резонансна томографія (fMRI) 是一种常用的技术来测量神经活化。它的应用尤其重要在发现下面的 нейродегенератив Conditions  such as Parkinson's, Alzheimer's, and Autism.  current analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions.
</details></li>
</ul>
<hr>
<h2 id="Incentive-Allocation-in-Vertical-Federated-Learning-Based-on-Bankruptcy-Problem"><a href="#Incentive-Allocation-in-Vertical-Federated-Learning-Based-on-Bankruptcy-Problem" class="headerlink" title="Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem"></a>Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03515">http://arxiv.org/abs/2307.03515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Afsana Khan, Marijn ten Thij, Frank Thuijsman, Anna Wilbik</li>
<li>for: 这篇论文探讨了如何为在Vertically Federated Learning（VFL）中活动党（具有标签的数据的党）对不活跃党（没有标签的数据的党）的参与进行奖励。</li>
<li>methods: 本论文使用了 банкрот游戏理论的变形，known as the Bankruptcy Problem，并使用了塔尔散分法解决问题。</li>
<li>results: 本论文透过实验和实际数据显示，证明了其可以保证参与者受益，并且比较了旧的计算Shapley值的方法，表明了其的方法更加有效，需要 fewer computations。<details>
<summary>Abstract</summary>
Vertical federated learning (VFL) is a promising approach for collaboratively training machine learning models using private data partitioned vertically across different parties. Ideally in a VFL setting, the active party (party possessing features of samples with labels) benefits by improving its machine learning model through collaboration with some passive parties (parties possessing additional features of the same samples without labels) in a privacy preserving manner. However, motivating passive parties to participate in VFL can be challenging. In this paper, we focus on the problem of allocating incentives to the passive parties by the active party based on their contributions to the VFL process. We formulate this problem as a variant of the Nucleolus game theory concept, known as the Bankruptcy Problem, and solve it using the Talmud's division rule. We evaluate our proposed method on synthetic and real-world datasets and show that it ensures fairness and stability in incentive allocation among passive parties who contribute their data to the federated model. Additionally, we compare our method to the existing solution of calculating Shapley values and show that our approach provides a more efficient solution with fewer computations.
</details>
<details>
<summary>摘要</summary>
纵向联合学习（VFL）是一种有前途的方法，通过私有数据分区Vertically Across不同的方针进行机器学习模型的共同训练。在VFLSetting中，活跃的方（具有标签的样本的特征）可以通过与一些被动方（不具有标签的样本的特征）的合作来改进其机器学习模型，这样做得有隐私保护的方式。然而，鼓励被动方参与VFL可以是困难的。在这篇论文中，我们关注在给被动方分配奖励的问题上。我们将这个问题定义为变种的核心游戏理论概念——银行rup难题，并使用塔尔摩德分配规则解决。我们对 synthetic 和实际数据集进行了评估，并证明了我们的提议方法能确保在被动方参与VFL过程中奖励分配是公平和稳定的。此外，我们与现有的计算Shapley值的方法进行比较，并证明了我们的方法提供了更高效的解决方案，计算量更少。
</details></li>
</ul>
<hr>
<h2 id="DEFT-Exploiting-Gradient-Norm-Difference-between-Model-Layers-for-Scalable-Gradient-Sparsification"><a href="#DEFT-Exploiting-Gradient-Norm-Difference-between-Model-Layers-for-Scalable-Gradient-Sparsification" class="headerlink" title="DEFT: Exploiting Gradient Norm Difference between Model Layers for Scalable Gradient Sparsification"></a>DEFT: Exploiting Gradient Norm Difference between Model Layers for Scalable Gradient Sparsification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03500">http://arxiv.org/abs/2307.03500</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kljp/deft">https://github.com/kljp/deft</a></li>
<li>paper_authors: Daegun Yoon, Sangyoon Oh</li>
<li>for: 提高分布式深度学习中通信压力过大的问题，提出了一种新的梯度简化方法，即DEFT。</li>
<li>methods: DEFT将梯度选择任务分解成多个子任务，并将其分配给工作者进行并行计算，从而降低了计算成本，并且可以避免梯度积累问题。</li>
<li>results: DEFT在实验中显示出了与现有简化器相比明显的提高，同时保持高度的收敛性。<details>
<summary>Abstract</summary>
Gradient sparsification is a widely adopted solution for reducing the excessive communication traffic in distributed deep learning. However, most existing gradient sparsifiers have relatively poor scalability because of considerable computational cost of gradient selection and/or increased communication traffic owing to gradient build-up. To address these challenges, we propose a novel gradient sparsification scheme, DEFT, that partitions the gradient selection task into sub tasks and distributes them to workers. DEFT differs from existing sparsifiers, wherein every worker selects gradients among all gradients. Consequently, the computational cost can be reduced as the number of workers increases. Moreover, gradient build-up can be eliminated because DEFT allows workers to select gradients in partitions that are non-intersecting (between workers). Therefore, even if the number of workers increases, the communication traffic can be maintained as per user requirement.   To avoid the loss of significance of gradient selection, DEFT selects more gradients in the layers that have a larger gradient norm than the other layers. Because every layer has a different computational load, DEFT allocates layers to workers using a bin-packing algorithm to maintain a balanced load of gradient selection between workers. In our empirical evaluation, DEFT shows a significant improvement in training performance in terms of speed in gradient selection over existing sparsifiers while achieving high convergence performance.
</details>
<details>
<summary>摘要</summary>
分布式深度学习中的梯度简化是一种广泛采用的解决方案，以减少分布式学习中的过度通信交流。然而，现有的大多数梯度简化方法具有较差的可扩展性，因为梯度选择和/或梯度积累带来了较高的计算成本。为了解决这些挑战，我们提出了一种新的梯度简化方案，即DEFT。DEFT方案将梯度选择任务分解成多个子任务，并将它们分配给工作者。与现有的简化方法不同，DEFT中每个工作者不需要选择所有的梯度。因此，计算成本可以随着工作者数量的增加而减少。此外，梯度积累可以被消除，因为DEFT允许工作者在不相交的 partition（ между工作者）中选择梯度。因此，即使工作者数量增加，通信交流也可以保持在用户需求的水平。为了保持梯度选择的重要性，DEFT在各层中选择更多的梯度，以避免梯度简化导致的数据损失。由于每层都有不同的计算负担，DEFT使用一种堆叠算法将层分配给工作者，以保持各个层的梯度选择均衡。在我们的实验评估中，DEFT在速度和稳定性两个方面显示出了明显的改善，而且可以实现高度的并行化。
</details></li>
</ul>
<hr>
<h2 id="HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution"><a href="#HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution" class="headerlink" title="HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution"></a>HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03494">http://arxiv.org/abs/2307.03494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Qi Zhang, Hao-Bin Duan, Jun-Long Chen, Ariel Shamir, Miao Wang</li>
<li>for: 本研究旨在提高自动驾驶车辆 Lane detection 的精度，以便更好地满足自动驾驶技术的需求。</li>
<li>methods: 本研究提出了一种基于 hierarchical Deep Hough Transform (DHT) 的方法，利用图像中所有的 Lane 特征在 Hough 参数空间进行组合。此外，还提出了一种改进点选择方法和一种动态卷积模块，以更好地 differentiate  между各个 Lane 特征。</li>
<li>results: 实验结果表明，提出的方法在检测受掩蔽或损坏的 Lane 图像时表现出色，与现有技术相比，其性能有所提高。<details>
<summary>Abstract</summary>
The task of lane detection has garnered considerable attention in the field of autonomous driving due to its complexity. Lanes can present difficulties for detection, as they can be narrow, fragmented, and often obscured by heavy traffic. However, it has been observed that the lanes have a geometrical structure that resembles a straight line, leading to improved lane detection results when utilizing this characteristic. To address this challenge, we propose a hierarchical Deep Hough Transform (DHT) approach that combines all lane features in an image into the Hough parameter space. Additionally, we refine the point selection method and incorporate a Dynamic Convolution Module to effectively differentiate between lanes in the original image. Our network architecture comprises a backbone network, either a ResNet or Pyramid Vision Transformer, a Feature Pyramid Network as the neck to extract multi-scale features, and a hierarchical DHT-based feature aggregation head to accurately segment each lane. By utilizing the lane features in the Hough parameter space, the network learns dynamic convolution kernel parameters corresponding to each lane, allowing the Dynamic Convolution Module to effectively differentiate between lane features. Subsequently, the lane features are fed into the feature decoder, which predicts the final position of the lane. Our proposed network structure demonstrates improved performance in detecting heavily occluded or worn lane images, as evidenced by our extensive experimental results, which show that our method outperforms or is on par with state-of-the-art techniques.
</details>
<details>
<summary>摘要</summary>
自动驾驶领域内，车道检测已经吸引了非常大的关注，因为它的复杂性。车道可能会变窄、散乱或者受到交通干扰，但是观察到的是车道具有几何结构，这使得使用这个特点可以提高车道检测的结果。为了解决这个挑战，我们提出了层次式深度投影变换（DHT）方法，将整个图像中的所有车道特征都归类到投影参数空间中。此外，我们还改进了点选择方法，并在原始图像中添加了动态卷积模块，以有效地将车道特征分化开。我们的网络架构包括后备网络（可以是ResNet或Pyramid Vision Transformer）、特征层次网络作为颈部EXTRACT多个尺度特征，以及层次DHT基于特征归一化头来准确地分类每条车道。通过利用车道特征在投影参数空间中，网络学习了动态卷积kernel参数相应于每条车道，使得动态卷积模块能够有效地分化开车道特征。最后，车道特征被传递给特征解码器，解码器预测了车道的最终位置。我们提出的网络结构在实际实验中表现出色，证明我们的方法在检测受阻或损坏车道图像时表现出优于或与当前领先技术相当。
</details></li>
</ul>
<hr>
<h2 id="ITA-An-Energy-Efficient-Attention-and-Softmax-Accelerator-for-Quantized-Transformers"><a href="#ITA-An-Energy-Efficient-Attention-and-Softmax-Accelerator-for-Quantized-Transformers" class="headerlink" title="ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers"></a>ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03493">http://arxiv.org/abs/2307.03493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gamze İslamoğlu, Moritz Scherer, Gianna Paulin, Tim Fischer, Victor J. B. Jung, Angelo Garofalo, Luca Benini</li>
<li>for: 本研究旨在提出一种高效的Transformer网络加速器，用于适应嵌入式系统中的自然语言处理任务。</li>
<li>methods: 该研究使用8位量化和创新的软MAX实现，实现在流式模式下计算，从而减少数据移动和能耗。</li>
<li>results: ITA在22nm Fully-Depleted Silicon-on-Insulator技术下，在0.8V voltage下达到16.9 TOPS&#x2F;W的能效率，同时在面积效率方面超过现有的Transformer加速器。<details>
<summary>Abstract</summary>
Transformer networks have emerged as the state-of-the-art approach for natural language processing tasks and are gaining popularity in other domains such as computer vision and audio processing. However, the efficient hardware acceleration of transformer models poses new challenges due to their high arithmetic intensities, large memory requirements, and complex dataflow dependencies. In this work, we propose ITA, a novel accelerator architecture for transformers and related models that targets efficient inference on embedded systems by exploiting 8-bit quantization and an innovative softmax implementation that operates exclusively on integer values. By computing on-the-fly in streaming mode, our softmax implementation minimizes data movement and energy consumption. ITA achieves competitive energy efficiency with respect to state-of-the-art transformer accelerators with 16.9 TOPS/W, while outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nm fully-depleted silicon-on-insulator technology at 0.8 V.
</details>
<details>
<summary>摘要</summary>
transformer 网络已经成为自然语言处理任务的状态泰斗方法，而在计算机视觉和音频处理领域也越来越受欢迎。然而，加速transformer模型的高精度计算和大量内存需求带来新的挑战。在这篇文章中，我们提出了一种名为ITA的新加速架构，这种架构 targets高效的在嵌入式系统上进行推理，通过8位量化和一种新的软 макс实现，该实现具有快速计算和减少数据移动的特点。ITA在0.8V 22nm Fully-depleted silicon-on-insulator技术中实现了0.8V 22nm Fully-depleted silicon-on-insulator技术中实现了16.9 TOPS/W的能效率，同时也超过了现有的state-of-the-art transformer加速器的5.93 TOPS/mm$^2$ 。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Graph-Convolution-Networks-for-Traffic-Flow-Forecasting"><a href="#Adaptive-Graph-Convolution-Networks-for-Traffic-Flow-Forecasting" class="headerlink" title="Adaptive Graph Convolution Networks for Traffic Flow Forecasting"></a>Adaptive Graph Convolution Networks for Traffic Flow Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05517">http://arxiv.org/abs/2307.05517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhengdaoli/agc-net">https://github.com/zhengdaoli/agc-net</a></li>
<li>paper_authors: Zhengdao Li, Wei Li, Kai Hwang</li>
<li>for: 预测交通流速度是一项非常具有挑战性的任务，因为道路条件在空间和时间两个维度上是动态变化的。</li>
<li>methods: 本文提出了一种新的 adaptive graph convolution network (AGC-net)，用于解决现有的 graph neural network (GNN) 中忽略时间变化道路条件的问题。AGC-net 基于一种新的上下文注意机制，包括一系列可学习的扩散尺度的 graph wavelets。</li>
<li>results: 实验结果表明，AGC-net 可以准确预测交通流速度，并且与其他基eline模型相比，有 significannot 的提高。两个公共的交通数据集上的实验结果都表明了 AGC-net 的效果。<details>
<summary>Abstract</summary>
Traffic flow forecasting is a highly challenging task due to the dynamic spatial-temporal road conditions. Graph neural networks (GNN) has been widely applied in this task. However, most of these GNNs ignore the effects of time-varying road conditions due to the fixed range of the convolution receptive field. In this paper, we propose a novel Adaptive Graph Convolution Networks (AGC-net) to address this issue in GNN. The AGC-net is constructed by the Adaptive Graph Convolution (AGC) based on a novel context attention mechanism, which consists of a set of graph wavelets with various learnable scales. The AGC transforms the spatial graph representations into time-sensitive features considering the temporal context. Moreover, a shifted graph convolution kernel is designed to enhance the AGC, which attempts to correct the deviations caused by inaccurate topology. Experimental results on two public traffic datasets demonstrate the effectiveness of the AGC-net\footnote{Code is available at: https://github.com/zhengdaoli/AGC-net} which outperforms other baseline models significantly.
</details>
<details>
<summary>摘要</summary>
traffic flow forecasting 是一个非常具有挑战性的任务，因为道路条件在空间和时间上都是动态的。 graph neural networks (GNN) 已经广泛应用于这个任务。然而，大多数这些 GNN 忽略了时间变化的道路条件，因为它们的固定范围的卷积感知场所不能考虑时间上的变化。在这篇论文中，我们提出了一种新的 Adaptive Graph Convolution Networks (AGC-net)，用于解决 GNN 中的这个问题。AGC-net 由 Adaptive Graph Convolution (AGC) 基于一种新的上下文注意机制组成，该机制包括一组可学习的扩散尺度的图波лет。AGC 将空间图表示转化为时间敏感的特征，考虑到时间上的上下文。此外，我们还设计了一个偏移 graph convolution kernel，用于强化 AGC，以尝试修正因为不准确的 topology 所导致的偏差。实验结果表明，AGC-net 在两个公共的交通数据集上表现出色，与其他基准模型相比，具有显著的优势。Note: Please note that the translation is in Simplified Chinese, and the word order may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Learning-Theory-of-Distribution-Regression-with-Neural-Networks"><a href="#Learning-Theory-of-Distribution-Regression-with-Neural-Networks" class="headerlink" title="Learning Theory of Distribution Regression with Neural Networks"></a>Learning Theory of Distribution Regression with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03487">http://arxiv.org/abs/2307.03487</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Zhongjie Shi, Zhan Yu, Ding-Xuan Zhou</li>
<li>for: 本文目的是建立分布回归的近似理论和学习理论，使用完全连接神经网络(FNN)来实现。</li>
<li>methods: 本文使用了一种新的神经网络结构，即分布输入神经网络，来解决传统神经网络不能直接使用于分布输入的问题。</li>
<li>results: 本文通过一种新的两阶段错误分解技术， derivation of almost optimal learning rates for the proposed distribution regression model up to logarithmic terms。<details>
<summary>Abstract</summary>
In this paper, we aim at establishing an approximation theory and a learning theory of distribution regression via a fully connected neural network (FNN). In contrast to the classical regression methods, the input variables of distribution regression are probability measures. Then we often need to perform a second-stage sampling process to approximate the actual information of the distribution. On the other hand, the classical neural network structure requires the input variable to be a vector. When the input samples are probability distributions, the traditional deep neural network method cannot be directly used and the difficulty arises for distribution regression. A well-defined neural network structure for distribution inputs is intensively desirable. There is no mathematical model and theoretical analysis on neural network realization of distribution regression. To overcome technical difficulties and address this issue, we establish a novel fully connected neural network framework to realize an approximation theory of functionals defined on the space of Borel probability measures. Furthermore, based on the established functional approximation results, in the hypothesis space induced by the novel FNN structure with distribution inputs, almost optimal learning rates for the proposed distribution regression model up to logarithmic terms are derived via a novel two-stage error decomposition technique.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们目标是建立分布回归的近似理论和学习理论，通过全连接神经网络（FNN）来实现。与传统的回归方法不同，分布回归的输入变量是概率度量。因此，我们需要进行第二阶采样过程来近似实际分布的信息。然而，传统的神经网络结构需要输入变量为向量。当输入样本是概率分布时，传统的深度神经网络方法无法直接使用，这会导致技术困难。我们需要一种具有良好定义的神经网络结构来处理分布输入。在现有的数学模型和理论分析之外，我们在FNN结构中建立了一个新的分布输入神经网络框架，以实现函数als定义在柯博尔概率度量空间上的近似理论。此外，基于建立的函数近似结果，我们通过一种新的两阶错 decomposition技术，在带有分布输入的FNN结构下， derivation almost optimal learning rate的提案 Distribution Regression模型，即使到对数阶段。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning"><a href="#Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning" class="headerlink" title="Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning"></a>Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03486">http://arxiv.org/abs/2307.03486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seungyong Moon, Junyoung Yeom, Bumsoo Park, Hyun Oh Song</li>
<li>for: 这种研究旨在解决在生成的环境中发现层次结构的成就所存在的挑战。</li>
<li>methods: 该研究使用的方法包括 proximal policy optimization (PPO) 和 achievement distillation。</li>
<li>results: PPO  Agent 可以预测下一个成就的解锁程度，并且通过 achievement distillation 方法强化了 agent 的成就预测能力，显示了在具有更多的模型参数和更高效的样本收集方法下达到了 state-of-the-art 性能。<details>
<summary>Abstract</summary>
Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the agent's capability to predict the next achievement. Our method exhibits a strong capacity for discovering hierarchical achievements and shows state-of-the-art performance on the challenging Crafter environment using fewer model parameters in a sample-efficient regime.
</details>
<details>
<summary>摘要</summary>
发现具有层次结构的成就需要智能体具备广泛的能力，包括通用化和长期逻辑。许多先前方法基于模型化或层次方法，假设有一个显式的长期规划模块可以帮助学习层次成就。然而，这些方法需要很多环境互动或大型模型，限制其实用性。在这种情况下，我们发现，靠近策略优化（PPO）算法，一种简单而多功能的模型自由算法，在当前实施方法下表现出色，超越先前的方法。此外，我们发现PPO Agent可以预测下一个成就的概率，虽然 confidence 较低。基于这个观察，我们提出了一种新的对比学习方法，即成就馆定，该方法可以增强智能体预测下一个成就的能力。我们的方法在挑战性的 Crafter 环境中表现出色，使用更少的模型参数在样本效率的 régime 中达到了领先的性能。
</details></li>
</ul>
<hr>
<h2 id="Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching"><a href="#Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching" class="headerlink" title="Unpaired Multi-View Graph Clustering with Cross-View Structure Matching"></a>Unpaired Multi-View Graph Clustering with Cross-View Structure Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03476">http://arxiv.org/abs/2307.03476</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wy1019/upmgc-sm">https://github.com/wy1019/upmgc-sm</a></li>
<li>paper_authors: Yi Wen, Siwei Wang, Qing Liao, Weixuan Liang, Ke Liang, Xinhang Wan, Xinwang Liu</li>
<li>for:  addresses the data-unpaired problem (DUP) in multi-view literature by proposing a novel parameter-free graph clustering framework.</li>
<li>methods:  utilizes the structural information from each view to refine cross-view correspondences, and is a unified framework for both fully and partially unpaired multi-view graph clustering.</li>
<li>results:  extensive experiments demonstrate the effectiveness and generalization of the proposed framework for both paired and unpaired datasets.Here’s the full text in Simplified Chinese:</li>
<li>for:  Addresses the data-unpaired problem (DUP) in multi-view literature by proposing a novel parameter-free graph clustering framework.</li>
<li>methods:  Utilizes the structural information from each view to refine cross-view correspondences, and is a unified framework for both fully and partially unpaired multi-view graph clustering.</li>
<li>results:  Extensive experiments demonstrate the effectiveness and generalization of the proposed framework for both paired and unpaired datasets.<details>
<summary>Abstract</summary>
Multi-view clustering (MVC), which effectively fuses information from multiple views for better performance, has received increasing attention. Most existing MVC methods assume that multi-view data are fully paired, which means that the mappings of all corresponding samples between views are pre-defined or given in advance. However, the data correspondence is often incomplete in real-world applications due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks: 1) Most methods focus on the feature representation while ignoring the structural information of multi-view data, which is essential for clustering tasks; 2) Existing methods for partially unpaired problems rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems; 3) Their inevitable parameters degrade the efficiency and applicability of the models. To tackle these issues, we propose a novel parameter-free graph clustering framework termed Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM effectively utilizes the structural information from each view to refine cross-view correspondences. Besides, our UPMGC-SM is a unified framework for both the fully and partially unpaired multi-view graph clustering. Moreover, existing graph clustering methods can adopt our UPMGC-SM to enhance their ability for unpaired scenarios. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both paired and unpaired datasets.
</details>
<details>
<summary>摘要</summary>
多视图划分（MVC），能够有效地将多个视图中的信息结合起来，在最近几年内受到了越来越多的关注。大多数现有的MVC方法假设所有视图中的样本都是已知的，即所有样本之间的映射都是先前定义的。然而，在实际应用中，数据对应关系 oftentimes 是不完全的，这被称为多视图数据不对应问题（DUP）。虽然有几种尝试 Addressing the DUP issue，但它们受到以下缺点的限制：1）大多数方法专注于特征表示，而忽略多视图数据的结构信息，这是 clustering 任务中非常重要的; 2）现有的方法只适用于部分不对应的问题，它们无法处理完全不对应的问题; 3）它们的参数会降低模型的效率和可应用性。为了解决这些问题，我们提出了一种无参数的图 clustering 框架，名为无参数多视图图 clustering 框架 with Cross-View Structure Matching（UPMGC-SM）。与现有方法不同的是，UPMGC-SM 可以充分利用每个视图中的结构信息，以改进 cross-view 对应关系。此外，我们的 UPMGC-SM 是一种通用的框架，可以处理完全不对应和部分不对应的多视图图 clustering 问题。此外，现有的图 clustering 方法可以采用我们的 UPMGC-SM 来增强它们对不对应场景的能力。广泛的实验表明我们提出的框架在 paired 和 unpaired 数据集上的效果和通用性都很强。
</details></li>
</ul>
<hr>
<h2 id="Action-State-Dependent-Dynamic-Model-Selection"><a href="#Action-State-Dependent-Dynamic-Model-Selection" class="headerlink" title="Action-State Dependent Dynamic Model Selection"></a>Action-State Dependent Dynamic Model Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04754">http://arxiv.org/abs/2307.04754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Cordoni, Alessio Sancetta</li>
<li>for: 这篇论文目的是为了找到在某些世界状态下最佳的模型，以及在这些状态下如何动态地选择模型。</li>
<li>methods: 这篇论文使用了强化学习算法来近似地解决这个动态程序问题，并且可以从数据中估计最佳策略。</li>
<li>results: 实际应用中，这种方法能够在使用macro经济变量和价格数据时，超过选择最佳股票模型的寻找方法。<details>
<summary>Abstract</summary>
A model among many may only be best under certain states of the world. Switching from a model to another can also be costly. Finding a procedure to dynamically choose a model in these circumstances requires to solve a complex estimation procedure and a dynamic programming problem. A Reinforcement learning algorithm is used to approximate and estimate from the data the optimal solution to this dynamic programming problem. The algorithm is shown to consistently estimate the optimal policy that may choose different models based on a set of covariates. A typical example is the one of switching between different portfolio models under rebalancing costs, using macroeconomic information. Using a set of macroeconomic variables and price data, an empirical application to the aforementioned portfolio problem shows superior performance to choosing the best portfolio model with hindsight.
</details>
<details>
<summary>摘要</summary>
一个模型在多种状况下只是最佳的。从一个模型到另一个的转换也可能是昂贵的。在这些情况下，找到一种动态选择模型的过程需要解决一个复杂的估计问题和动态programming问题。一种强化学习算法可以从数据中approxiamte和估计最佳解决方案。这种算法能够适应不同状况下的模型选择。一个典型的应用是在划转成本下选择不同的投资模型，使用macro经济信息。使用一组macro经济变量和价格数据，对投资问题的一个empirical应用表现出色，比选择划算后的最佳投资模型更高效。
</details></li>
</ul>
<hr>
<h2 id="Solvent-A-Framework-for-Protein-Folding"><a href="#Solvent-A-Framework-for-Protein-Folding" class="headerlink" title="Solvent: A Framework for Protein Folding"></a>Solvent: A Framework for Protein Folding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04603">http://arxiv.org/abs/2307.04603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kakaobrain/solvent">https://github.com/kakaobrain/solvent</a></li>
<li>paper_authors: Jaemyung Lee, Kyeongtak Han, Jaehoon Kim, Hasun Yu, Youhan Lee</li>
<li>For: The paper aims to provide a unified research framework for protein folding, called Solvent, which supports various state-of-the-art models and enables consistent and fair comparisons among different approaches.* Methods: Solvent is built with a modular design, allowing for different models to be easily integrated and trained on the same dataset. The framework includes implementations of several well-known algorithms and their components, and provides a variety of training and evaluation options.* Results: The paper presents experiments using Solvent to benchmark well-known algorithms and their components, providing insights into the protein structure modeling field. The results demonstrate the potential of Solvent to increase the reliability and consistency of proposed models, as well as improve efficiency in both speed and costs.<details>
<summary>Abstract</summary>
Consistency and reliability are crucial for conducting AI research. Many famous research fields, such as object detection, have been compared and validated with solid benchmark frameworks. After AlphaFold2, the protein folding task has entered a new phase, and many methods are proposed based on the component of AlphaFold2. The importance of a unified research framework in protein folding contains implementations and benchmarks to consistently and fairly compare various approaches. To achieve this, we present Solvent, a protein folding framework that supports significant components of state-of-the-art models in the manner of an off-the-shelf interface Solvent contains different models implemented in a unified codebase and supports training and evaluation for defined models on the same dataset. We benchmark well-known algorithms and their components and provide experiments that give helpful insights into the protein structure modeling field. We hope that Solvent will increase the reliability and consistency of proposed models and give efficiency in both speed and costs, resulting in acceleration on protein folding modeling research. The code is available at https://github.com/kakaobrain/solvent, and the project will continue to be developed.
</details>
<details>
<summary>摘要</summary>
“一致性和可靠性是AI研究中非常重要的。许多著名的研究领域，如对象检测，都已经被比较和验证了坚实的 bencmark 框架。 alphaFold2 后，蛋白质折叠任务进入了新的阶段，许多方法都是基于 alphaFold2 的组件。一个统一的研究框架在蛋白质折叠中的重要性，它可以一直支持当前领先的模型组件，并且可以在同一个代码库中实现和评估定义的模型。我们称之为 Solvent，它支持当前领先的模型组件，并且可以在同一个代码库中实现和评估定义的模型。我们对一些知名的算法和其组件进行了比较，并提供了有用的实验结果，它们可以帮助我们更好地理解蛋白质结构模型领域。我们希望 Solvent 能够增加提案模型的一致性和可靠性，并且能够提高速度和成本的效率，从而加速蛋白质结构模型研究。代码可以在 https://github.com/kakaobrain/solvent 上获取，项目将继续开发。”
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection"><a href="#A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection" class="headerlink" title="A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection"></a>A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03759">http://arxiv.org/abs/2307.03759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kimmeen/awesome-gnn4ts">https://github.com/kimmeen/awesome-gnn4ts</a></li>
<li>paper_authors: Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geoffrey I. Webb, Irwin King, Shirui Pan</li>
<li>for: 本文主要针对时间序列分析领域的研究，旨在帮助设计者和实践者更好地理解、建立应用和推动关于图 neuronal networks for time series analysis（GNN4TS）的研究。</li>
<li>methods: 本文使用了图 neuronal networks（GNN）来分析时间序列数据，并对时间序列分析领域的各种任务进行了分类和推导。</li>
<li>results: 本文对GNN4TS的研究进行了全面的回顾和评估，并介绍了一些代表性的研究和应用例子，同时也预测了未来研究的发展趋势。<details>
<summary>Abstract</summary>
Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.
</details>
<details>
<summary>摘要</summary>
时序序列是主要数据类型，用于记录动态系统测量结果，并且由物理感知器和在线过程生成大量数据（虚拟感知器）。时序序列分析是解锁可用数据中的宝库的关键。随着图神经网络（GNN）的最近进步，GNN-based时序序列分析方法在不断增长。这些方法可以直接模型时间和空间关系，传统和其他深度神经网络基于方法难以完成。在这项调查中，我们提供了完整的图神经网络时序序列分析（GNN4TS）评论，涵盖四个基本维度：预测、分类、异常检测和补做。我们的目标是帮助设计者和实践者理解、建立应用和推动GNN4TS研究。首先，我们提供了完整的任务导向的分类法GNN4TS。然后，我们展示和讨论了代表性的研究工作，并介绍了主流应用GNN4TS。最后，我们对未来研究方向进行了全面的讨论，这项调查，是首次将大量关于GNN基于时序序列研究的知识集中，把注重Foundations、实践应用和机遇的图神经网络时序序列分析。
</details></li>
</ul>
<hr>
<h2 id="Differential-Privacy-for-Clustering-Under-Continual-Observation"><a href="#Differential-Privacy-for-Clustering-Under-Continual-Observation" class="headerlink" title="Differential Privacy for Clustering Under Continual Observation"></a>Differential Privacy for Clustering Under Continual Observation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03430">http://arxiv.org/abs/2307.03430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Dupré la Tour, Monika Henzinger, David Saulpic</li>
<li>for: 隐私 clustering一个在 $\mathbb{R}^d$ 上的数据集，该数据集在插入和删除点时进行更新。</li>
<li>methods: 提供了一种 $\varepsilon$-分割隐私 clustering机制，用于实现 $k$-means 目标，并且在 continual observation 下实现。这是首次对这个问题提供了一个增量隐私的解决方案，其损耗因数只是对数增长。</li>
<li>results: 提出了一种基于私有隐私 greedy 近似算法和维度减少算法的方法，可以实现高效的隐私 clustering。此外， partial 扩展了结果到 $k$-medians 问题。<details>
<summary>Abstract</summary>
We consider the problem of clustering privately a dataset in $\mathbb{R}^d$ that undergoes both insertion and deletion of points. Specifically, we give an $\varepsilon$-differentially private clustering mechanism for the $k$-means objective under continual observation. This is the first approximation algorithm for that problem with an additive error that depends only logarithmically in the number $T$ of updates. The multiplicative error is almost the same as non privately. To do so we show how to perform dimension reduction under continual observation and combine it with a differentially private greedy approximation algorithm for $k$-means. We also partially extend our results to the $k$-median problem.
</details>
<details>
<summary>摘要</summary>
我们考虑一个隐私 clustering 问题，对于一个在 $\mathbb{R}^d$ 上的资料集，该资料集会在批量更新的情况下进行插入和删除点。我们提供了一个 $\varepsilon$-隐私 clustering 机制，用于 $k$-means 目标下，并且这个方法具有对数幂递增的误差。我们还详细说明了如何在批量更新下进行维度缩减，并且与隐私保证的暴末搜索法相结合。此外，我们也对 $k$-medians 问题进行了一定的扩展。
</details></li>
</ul>
<hr>
<h2 id="Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer"><a href="#Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer" class="headerlink" title="Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer"></a>Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03427">http://arxiv.org/abs/2307.03427</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/survival-xsurv">https://github.com/mungomeng/survival-xsurv</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim<br>for:This paper aims to improve survival prediction for cancer patients by developing a deep learning model that can effectively fuse multi-modality images (e.g., PET-CT) and extract region-specific information.methods:The proposed method uses a merging-diverging learning framework, which consists of a merging encoder and a diverging decoder. The merging encoder uses a Hybrid Parallel Cross-Attention (HPCA) block to fuse multi-modality features, while the diverging decoder uses a Region-specific Attention Gate (RAG) block to screen out features related to lesion regions.results:The proposed method (XSurv) outperforms state-of-the-art survival prediction methods on the public dataset of HECKTOR 2022. Specifically, XSurv combines the complementary information in PET and CT images and extracts region-specific prognostic information in PT and MLN regions, leading to improved survival prediction accuracy.<details>
<summary>Abstract</summary>
Survival prediction is crucial for cancer patients as it provides early prognostic information for treatment planning. Recently, deep survival models based on deep learning and medical images have shown promising performance for survival prediction. However, existing deep survival models are not well developed in utilizing multi-modality images (e.g., PET-CT) and in extracting region-specific information (e.g., the prognostic information in Primary Tumor (PT) and Metastatic Lymph Node (MLN) regions). In view of this, we propose a merging-diverging learning framework for survival prediction from multi-modality images. This framework has a merging encoder to fuse multi-modality information and a diverging decoder to extract region-specific information. In the merging encoder, we propose a Hybrid Parallel Cross-Attention (HPCA) block to effectively fuse multi-modality features via parallel convolutional layers and cross-attention transformers. In the diverging decoder, we propose a Region-specific Attention Gate (RAG) block to screen out the features related to lesion regions. Our framework is demonstrated on survival prediction from PET-CT images in Head and Neck (H&N) cancer, by designing an X-shape merging-diverging hybrid transformer network (named XSurv). Our XSurv combines the complementary information in PET and CT images and extracts the region-specific prognostic information in PT and MLN regions. Extensive experiments on the public dataset of HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR 2022) demonstrate that our XSurv outperforms state-of-the-art survival prediction methods.
</details>
<details>
<summary>摘要</summary>
生存预测对于癌症患者非常重要，因为它提供了早期的诊断信息，以便为治疗规划。最近，深度存生模型基于深度学习和医疗图像已经展示了有前景的表现。然而，现有的深度存生模型尚未充分利用多Modalities图像（例如PET-CT），也没有充分提取区域特定信息（例如主要肿瘤（PT）和肿瘤静脉节（MLN）区域的诊断信息）。为了解决这一问题，我们提出了一种合并-分化学习框架 для存生预测。这个框架包括一个合并编码器，用于融合多Modalities信息，以及一个分化解码器，用于提取区域特定信息。在合并编码器中，我们提出了一种Hybrid Parallel Cross-Attention（HPCA）块，用于有效地融合多Modalities特征，并通过并行的卷积层和交互变换器来实现。在分化解码器中，我们提出了一种Region-specific Attention Gate（RAG）块，用于筛选出病理区域相关的特征。我们的框架在PET-CT图像上进行存生预测，并通过设计一个X-形合并-分化混合变换网络（名为XSurv）来组合PET和CT图像的补做信息，并提取PT和MLN区域的区域特定诊断信息。我们的XSurv在HECKTOR2022公共数据集上进行了广泛的实验，并证明了它的出色表现。
</details></li>
</ul>
<hr>
<h2 id="Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model"><a href="#Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model"></a>Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03423">http://arxiv.org/abs/2307.03423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/ddpmfus">https://github.com/shuaikaishi/ddpmfus</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Jie Chen</li>
<li>for: 这 paper 是为了提出一种基于深度学习的干扰推理模型，用于折衔高spectral像和多spectral像。</li>
<li>methods: 该方法基于 Conditional Denoising Diffusion Probabilistic Model（DDPM），包括前向扩散过程和反向去干扰过程。</li>
<li>results: 实验表明，该方法在一个室内和两个遥感数据集上显示出了比其他高级深度学习基于合并方法更高的性能。<details>
<summary>Abstract</summary>
Hyperspectral images (HSI) have a large amount of spectral information reflecting the characteristics of matter, while their spatial resolution is low due to the limitations of imaging technology. Complementary to this are multispectral images (MSI), e.g., RGB images, with high spatial resolution but insufficient spectral bands. Hyperspectral and multispectral image fusion is a technique for acquiring ideal images that have both high spatial and high spectral resolution cost-effectively. Many existing HSI and MSI fusion algorithms rely on known imaging degradation models, which are often not available in practice. In this paper, we propose a deep fusion method based on the conditional denoising diffusion probabilistic model, called DDPM-Fus. Specifically, the DDPM-Fus contains the forward diffusion process which gradually adds Gaussian noise to the high spatial resolution HSI (HrHSI) and another reverse denoising process which learns to predict the desired HrHSI from its noisy version conditioning on the corresponding high spatial resolution MSI (HrMSI) and low spatial resolution HSI (LrHSI). Once the training is completes, the proposed DDPM-Fus implements the reverse process on the test HrMSI and LrHSI to generate the fused HrHSI. Experiments conducted on one indoor and two remote sensing datasets show the superiority of the proposed model when compared with other advanced deep learningbased fusion methods. The codes of this work will be opensourced at this address: https://github.com/shuaikaishi/DDPMFus for reproducibility.
</details>
<details>
<summary>摘要</summary>
干扰图像（HSI）具有大量的spectral信息，反映物质特点，但其空间分辨率受成像技术限制而受到限制。与此相对的是多spectral图像（MSI），如RGB图像，具有高空间分辨率，但lack spectral bands。干扰图像和多spectral图像的图像混合是一种获得理想图像，即高空间和高spectral分辨率的图像，可以在成本效益的情况下获得。现有的HSI和MSI混合算法多数基于知名的损坏模型，这些模型在实践中经常不可用。在这篇文章中，我们提出了基于条件滤波泛化模型的深度混合方法，称为DDPM-Fus。具体来说，DDPM-Fus包括前向滤波过程，逐渐添加高斯噪声到高空间分辨率干扰图像（HrHSI），以及另一个反向恢复过程，学习预测desired HrHSI的噪声版本，条件在HrMSI和LrHSI的帮助下。一旦训练完成，我们的DDPM-Fus会在测试HrMSI和LrHSI上实现反向过程，生成混合后的HrHSI。我们在一个室内和两个遥感数据集上进行了实验，并证明了我们的方法在其他先进的深度学习基于混合方法之上具有superiority。我们将在这个地址上开源我们的代码：https://github.com/shuaikaishi/DDPMFus，以便复制。
</details></li>
</ul>
<hr>
<h2 id="QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance"><a href="#QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance" class="headerlink" title="QI2 – an Interactive Tool for Data Quality Assurance"></a>QI2 – an Interactive Tool for Data Quality Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03419">http://arxiv.org/abs/2307.03419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Geerkens, Christian Sieberichs, Alexander Braun, Thomas Waschulzik</li>
<li>for: 这篇论文主要用于提高机器学习系统和大数据的数据质量，以满足欧盟的AI法规要求，特别是安全相关的机器学习系统的市场引入。</li>
<li>methods: 本论文提出了一种新的数据质量检查方法，可以同时检查多个数据质量方面的要求。这种方法基于量化的数据质量标准，可以帮助确保数据的质量符合要求。</li>
<li>results: 在小例子数据集上，本方法能够成功地检查数据质量，并且在知名的MNIST数据集上进行了实践示例。<details>
<summary>Abstract</summary>
The importance of high data quality is increasing with the growing impact and distribution of ML systems and big data. Also the planned AI Act from the European commission defines challenging legal requirements for data quality especially for the market introduction of safety relevant ML systems. In this paper we introduce a novel approach that supports the data quality assurance process of multiple data quality aspects. This approach enables the verification of quantitative data quality requirements. The concept and benefits are introduced and explained on small example data sets. How the method is applied is demonstrated on the well known MNIST data set based an handwritten digits.
</details>
<details>
<summary>摘要</summary>
“高品质的数据价值在机器学习系统和大数据的普及和影响力增长的同时也在提高。欧盟委员会的AI法案也将要求严格的数据质量标准，特别是在安全相关的机器学习系统上市。本文将介绍一种支持多种数据质量方面的质量保证过程的新方法。这种方法可以评估量数据质量要求的实施情况。本文将以小型数据集作为例子，介绍概念和优点，并在知名的MNIST数据集上显示如何实施。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="AdaptiveRec-Adaptively-Construct-Pairs-for-Contrastive-Learning-in-Sequential-Recommendation"><a href="#AdaptiveRec-Adaptively-Construct-Pairs-for-Contrastive-Learning-in-Sequential-Recommendation" class="headerlink" title="AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in Sequential Recommendation"></a>AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05469">http://arxiv.org/abs/2307.05469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaeheyoung Jeon, Jung Hyun Ryu, Jewoong Cho, Myungjoo Kang</li>
<li>for: 解决Sequential recommendation systems中的对比学习挑战，特别是false negative问题，提高推荐算法效果。</li>
<li>methods: 提出了一种进步的对比学习方法，改进了物品嵌入的质量，避免了类似实例被误分类为不相似的问题。</li>
<li>results: 实验结果表明，提出的方法能够提高推荐系统的性能，比 EXISTS 系统更高效。此外，该方法在不同的推荐场景下也有广泛的应用前景。<details>
<summary>Abstract</summary>
This paper presents a solution to the challenges faced by contrastive learning in sequential recommendation systems. In particular, it addresses the issue of false negative, which limits the effectiveness of recommendation algorithms. By introducing an advanced approach to contrastive learning, the proposed method improves the quality of item embeddings and mitigates the problem of falsely categorizing similar instances as dissimilar. Experimental results demonstrate performance enhancements compared to existing systems. The flexibility and applicability of the proposed approach across various recommendation scenarios further highlight its value in enhancing sequential recommendation systems.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:这篇论文提出了对比学习在序列推荐系统中的挑战，特别是False Negative问题，这限制了推荐算法的效iveness。通过引入高级的对比学习方法，提议方法可以改善item embedding的质量，避免错误地将相似的实例分类为不相似。实验结果表明，提议方法比现有系统有所提高，并且可以适用于不同的推荐enario，进一步强调它在序列推荐系统中的价值。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Heterogeneity-A-Dynamic-Learning-Framework-for-Hypergraphs"><a href="#Learning-from-Heterogeneity-A-Dynamic-Learning-Framework-for-Hypergraphs" class="headerlink" title="Learning from Heterogeneity: A Dynamic Learning Framework for Hypergraphs"></a>Learning from Heterogeneity: A Dynamic Learning Framework for Hypergraphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03411">http://arxiv.org/abs/2307.03411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiehua Zhang, Yuze Liu, Zhishu Shen, Xingjun Ma, Xin Chen, Xiaowei Huang, Jun Yin, Jiong Jin</li>
<li>for: 这篇论文的目的是提出一种基于hypergraph学习的图学习框架，以捕捉图中隐藏的高阶相关性。</li>
<li>methods: 该框架使用动态hyperedge构建和注意力更新来利用图中不同特征的多样性。首先，通过对应式融合策略生成高质量特征，然后通过动态分组生成hypergraph，并进行类型特定的hypergraph学习过程。</li>
<li>results: 经过对多个popular数据集的广泛测试， comparing with11种现有的状态对节点分类和链接预测任务，该框架表现出了显著的性能提升（平均12.5%在节点分类任务上，13.3%在链接预测任务上），证明了该框架的有效性。<details>
<summary>Abstract</summary>
Graph neural network (GNN) has gained increasing popularity in recent years owing to its capability and flexibility in modeling complex graph structure data. Among all graph learning methods, hypergraph learning is a technique for exploring the implicit higher-order correlations when training the embedding space of the graph. In this paper, we propose a hypergraph learning framework named LFH that is capable of dynamic hyperedge construction and attentive embedding update utilizing the heterogeneity attributes of the graph. Specifically, in our framework, the high-quality features are first generated by the pairwise fusion strategy that utilizes explicit graph structure information when generating initial node embedding. Afterwards, a hypergraph is constructed through the dynamic grouping of implicit hyperedges, followed by the type-specific hypergraph learning process. To evaluate the effectiveness of our proposed framework, we conduct comprehensive experiments on several popular datasets with eleven state-of-the-art models on both node classification and link prediction tasks, which fall into categories of homogeneous pairwise graph learning, heterogeneous pairwise graph learning, and hypergraph learning. The experiment results demonstrate a significant performance gain (average 12.5% in node classification and 13.3% in link prediction) compared with recent state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORK (GNN) 在最近几年内得到了越来越多的推广，这主要归功于它在处理复杂图结构数据时的能力和灵活性。在所有图学习方法中，超 graf学习是一种技术，用于在训练图的嵌入空间时探索隐藏的高阶相关性。在这篇论文中，我们提出了一个名为LFH的超 graf学习框架，可以在动态组成hyperedge并通过heterogeneity attribute来进行注意力更新。具体来说，在我们的框架中，高质量的特征首先通过对称的对抗策略生成初始节点嵌入。接着，通过动态分组的超 graf组建，然后进行类型特定的超 graf学习过程。为了评估我们提出的框架的效果，我们在多个popular dataset上进行了对 eleven state-of-the-art模型的比较，包括节点分类和链接预测任务，这些任务可以分为同质对策graph学习、不同质对策graph学习和超 graf学习。实验结果表明，我们的提出的框架在节点分类和链接预测任务中表现出了显著的性能提升（平均12.5%和13.3%），相比最近的state-of-the-art方法。
</details></li>
</ul>
<hr>
<h2 id="Scalable-High-Dimensional-Multivariate-Linear-Regression-for-Feature-Distributed-Data"><a href="#Scalable-High-Dimensional-Multivariate-Linear-Regression-for-Feature-Distributed-Data" class="headerlink" title="Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data"></a>Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03410">http://arxiv.org/abs/2307.03410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo-Chieh Huang, Ruey S. Tsay</li>
<li>for: 这篇论文是为了应用多变量线性回传数据，并且能够处理Feature-分布式数据，这种数据在应用中日益增加。</li>
<li>methods: 本论文提出了一个两阶段松弛迪的漫游算法（TSRGA），用于应用多变量线性回传数据。TSRGA的通信复杂度不随特征维度而增加，因此具有高可扩展性。在多变量回应变数情况下，TSRGA可以获得低阶系数估计。</li>
<li>results: 在模拟实验中，TSRGA具有快速对准性。最后，本论文应用了提案的TSRGA在金融应用中，利用10-K报告中的无结构数据，证明了其在具有多个紧密大维度矩阵的应用中的有用性。<details>
<summary>Abstract</summary>
Feature-distributed data, referred to data partitioned by features and stored across multiple computing nodes, are increasingly common in applications with a large number of features. This paper proposes a two-stage relaxed greedy algorithm (TSRGA) for applying multivariate linear regression to such data. The main advantage of TSRGA is that its communication complexity does not depend on the feature dimension, making it highly scalable to very large data sets. In addition, for multivariate response variables, TSRGA can be used to yield low-rank coefficient estimates. The fast convergence of TSRGA is validated by simulation experiments. Finally, we apply the proposed TSRGA in a financial application that leverages unstructured data from the 10-K reports, demonstrating its usefulness in applications with many dense large-dimensional matrices.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>应用中逐渐增长的分布式数据（即根据特征分区存储在多个计算节点上的数据），这篇论文提出了一种两阶段松弛抽象算法（TSRGA）用于应用多变量直线回归。TSRGA的优点在于，它的通信复杂度不随特征维度增长，因此对很大数据集进行扩展非常可行。此外，对多变量响应变量，TSRGA可以生成低级卷积系数估计。在实验中，TSRGA的快速收敛性得到了验证。最后，我们在金融应用中使用了提案的 TSRGA，通过利用10-K报告中的无结构数据，示出了在具有多个稠密大维度矩阵的应用中的实用性。
</details></li>
</ul>
<hr>
<h2 id="A-Self-Supervised-Algorithm-for-Denoising-Photoplethysmography-Signals-for-Heart-Rate-Estimation-from-Wearables"><a href="#A-Self-Supervised-Algorithm-for-Denoising-Photoplethysmography-Signals-for-Heart-Rate-Estimation-from-Wearables" class="headerlink" title="A Self-Supervised Algorithm for Denoising Photoplethysmography Signals for Heart Rate Estimation from Wearables"></a>A Self-Supervised Algorithm for Denoising Photoplethysmography Signals for Heart Rate Estimation from Wearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05339">http://arxiv.org/abs/2307.05339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranay Jain, Cheng Ding, Cynthia Rudin, Xiao Hu</li>
<li>for: 本研究旨在提高智能手表和其他穿戴式设备中的心率监测精度，通过去噪掉噪音和运动干扰的PPG信号。</li>
<li>methods: 我们提出了一种基于自我超视的净化算法，利用大量的清晰PPG信号数据进行自动编码器的训练，以重建受损PPG信号。</li>
<li>results: 我们的算法可以提供更好的心率估计，并且对PPG信号的各种健康指标进行下游分析也显示了明显的改善。<details>
<summary>Abstract</summary>
Smart watches and other wearable devices are equipped with photoplethysmography (PPG) sensors for monitoring heart rate and other aspects of cardiovascular health. However, PPG signals collected from such devices are susceptible to corruption from noise and motion artifacts, which cause errors in heart rate estimation. Typical denoising approaches filter or reconstruct the signal in ways that eliminate much of the morphological information, even from the clean parts of the signal that would be useful to preserve. In this work, we develop an algorithm for denoising PPG signals that reconstructs the corrupted parts of the signal, while preserving the clean parts of the PPG signal. Our novel framework relies on self-supervised training, where we leverage a large database of clean PPG signals to train a denoising autoencoder. As we show, our reconstructed signals provide better estimates of heart rate from PPG signals than the leading heart rate estimation methods. Further experiments show significant improvement in Heart Rate Variability (HRV) estimation from PPG signals using our algorithm. We conclude that our algorithm denoises PPG signals in a way that can improve downstream analysis of many different health metrics from wearable devices.
</details>
<details>
<summary>摘要</summary>
智能手表和其他穿戴式设备通常配备了光谱 plethysmography (PPG) 传感器，用于监测心率和其他循环征象。然而，PPG 信号从这些设备中收集的信号受到噪声和运动artefacts的污染，导致心率估计出错。现有的减噪方法通常使用过滤或重建信号的方式，以消除大量的形态信息，包括净化部分的PPG信号，这些信号是有用的保留。在这种工作中，我们开发了一种用于减噪PPG信号的算法，可以重建污染的部分信号，同时保留净化部分的PPG信号。我们的新框架基于自我超vised学习，我们利用大量的净化PPG信号数据库来训练一个减噪自适应神经网络。我们的重建信号提供了更好的心率估计，与主流心率估计方法相比。进一步的实验表明，我们的算法可以大幅提高来自PPG信号的循环变化估计（HRV）。我们 conclude that我们的算法可以有效地减噪PPG信号，以提高来自穿戴式设备的多种健康指标的分析。
</details></li>
</ul>
<hr>
<h2 id="Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning"><a href="#Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning" class="headerlink" title="Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning"></a>Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03406">http://arxiv.org/abs/2307.03406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilai Zeng, Ce Zhang, Shijie Wang, Chen Sun</li>
<li>for: 本研究旨在调查 Whether sequence modeling can condense trajectories into useful representations that contribute to policy learning.</li>
<li>methods: 本研究采用了一个 Two-stage 框架，首先使用Sequence modeling技术Summary trajectories,然后使用这些表示来学习策略和愿景目标。</li>
<li>results: 研究发现，Sequence modeling 有效地减少了一些决策任务的训练时间，并且可以学习出高性能的策略。此外，GCPC 方法学习了一个 Conditioned 的未来 Representation，并在 AntMaze、FrankaKitchen 和 Locomotion 环境中达到了竞争性的性能。<details>
<summary>Abstract</summary>
Recent work has demonstrated the effectiveness of formulating decision making as a supervised learning problem on offline-collected trajectories. However, the benefits of performing sequence modeling on trajectory data is not yet clear. In this work we investigate if sequence modeling has the capability to condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques, and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an "implicit planner", and enables competitive performance on all three benchmarks.
</details>
<details>
<summary>摘要</summary>
最近的工作已经证明了将决策问题定义为有监督学习问题的可行性。然而，使用序列模型处理轨迹数据的利点还不够清晰。在这种情况下，我们 investigate whether sequence modeling can condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an "implicit planner" and enables competitive performance on all three benchmarks.Here's the word-for-word translation of the given text into Simplified Chinese:最近的工作已经证明了将决策问题定义为有监督学习问题的可行性。然而，使用序列模型处理轨迹数据的利点还不够清晰。在这种情况下，我们 investigate whether sequence modeling can condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an "implicit planner" and enables competitive performance on all three benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs"><a href="#Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs" class="headerlink" title="Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs"></a>Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03393">http://arxiv.org/abs/2307.03393</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CurryTang/Graph-LLM">https://github.com/CurryTang/Graph-LLM</a></li>
<li>paper_authors: Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, Jiliang Tang</li>
<li>for: 本文探讨了大语言模型（LLMs）在图机器学习中的潜力，特别是节点分类任务中。</li>
<li>methods: 本文提出了两种可能的管道： LLMS-as-Enhancers 和 LLMS-as-Predictors。前者利用 LLMS 增强节点的文本特征，然后通过 GNNs 生成预测结果。后者直接使用 LLMS 作为独立预测器。</li>
<li>results: 本文通过了多种设定下的全面和系统的实验研究，从实验结果中得出了原创的观察和新的发现，开启了新的可能性和建议，并提出了潜在的方向，以便更好地利用 LLMS 进行图学习。<details>
<summary>Abstract</summary>
Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at https://github.com/CurryTang/Graph-LLM.
</details>
<details>
<summary>摘要</summary>
学习图有很多应用，吸引了很多人的注意。最受欢迎的图学习管道是使用图神经网络（GNNs），并使用图节点特征的浅层文本嵌入，这有限制在普遍知识和深层semantic理解方面。在过去几年，大型自然语言模型（LLMs）已经证明了具有广泛的通用知识和强大的semantic理解能力，这些能力在处理文本数据方面引发了革命。在这篇论文中，我们想要探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究了两个可能的管道：LLMs-as-Enhancers和LLMs-as-Predictors。前者利用LLMs来增强节点的文本特征，然后通过GNNs生成预测结果。后者尝试直接使用LLMs作为独立预测器。我们在不同的设置下进行了全面和系统的研究，从实验结果中得出了原创的观察和新的发现，这些发现开启了新的可能性和建议了潜在的方向，以便利用LLMs进行图学习。我们的代码和数据集可以在https://github.com/CurryTang/Graph-LLM上下载。
</details></li>
</ul>
<hr>
<h2 id="AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime"><a href="#AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime" class="headerlink" title="AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime"></a>AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03385">http://arxiv.org/abs/2307.03385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement">https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Giulia Rizzi, Elisabetta Fersini, Damiano Spina</li>
<li>for: 本研究旨在开发自动检测社交媒体上的性别歧视和其他不尊重和仇恨行为，以促进在线环境中的包容和尊重。</li>
<li>methods: 本研究使用大型自然语言模型（i.e., mBERT和XLM-RoBERTa）和 ensemble策略进行性别歧视 Identification和分类，并在英语和西班牙语之间进行了比较。</li>
<li>results: 本研究在EXIST实验室2023中参与了三个任务，其中在第2任务中以软评估方式获得了第四名，并在第3任务中获得了最高ICM-Soft&#x3D;-2.32和normalized ICM-Soft&#x3D;0.79。<details>
<summary>Abstract</summary>
With the increasing influence of social media platforms, it has become crucial to develop automated systems capable of detecting instances of sexism and other disrespectful and hateful behaviors to promote a more inclusive and respectful online environment. Nevertheless, these tasks are considerably challenging considering different hate categories and the author's intentions, especially under the learning with disagreements regime. This paper describes AI-UPV team's participation in the EXIST (sEXism Identification in Social neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task of sexism identification and characterization under the learning with disagreements paradigm by training directly from the data with disagreements, without using any aggregated label. Yet, performances considering both soft and hard evaluations are reported. The proposed system uses large language models (i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification and classification in English and Spanish. In particular, our system is articulated in three different pipelines. The ensemble approach outperformed the individual large language models obtaining the best performances both adopting a soft and a hard label evaluation. This work describes the participation in all the three EXIST tasks, considering a soft evaluation, it obtained fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of our approaches is publicly available at https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.
</details>
<details>
<summary>摘要</summary>
随着社交媒体平台的普及，已成为必要的开发自动化系统，以检测社交媒体上的性别歧视和其他不尊重和仇恨行为，以促进更加包容和尊重的在线环境。然而，这些任务具有不同的仇恨类别和作者意图，特别是在学习各种不同的观点下。这篇文章描述了AI-UPV团队在EXIST（sEXism Identification in Social neTworks）实验室中的参与。提议的方法是通过直接从数据中学习，不使用任何综合标签，来解决性别歧视的识别和分类问题。然而，我们还是根据软和硬评估进行了性能评估。我们使用了大型语言模型（i.e., mBERT和XLM-RoBERTa）和ensemble策略进行性别歧视识别和分类。特别是，我们的系统是由三个不同的管道组成。 ensemble方法在软和硬评估中都表现出了最佳性能，并在EXIST任务中获得了第四名（Task 2）和第一名（Task 3），其ICM-Soft=-2.32和normalized ICM-Soft为0.79。我们的代码可以在https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement上获取。
</details></li>
</ul>
<hr>
<h2 id="Teaching-Arithmetic-to-Small-Transformers"><a href="#Teaching-Arithmetic-to-Small-Transformers" class="headerlink" title="Teaching Arithmetic to Small Transformers"></a>Teaching Arithmetic to Small Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03381">http://arxiv.org/abs/2307.03381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lee-ny/teaching_arithmetic">https://github.com/lee-ny/teaching_arithmetic</a></li>
<li>paper_authors: Nayoung Lee, Kartik Sreenivasan, Jason D. Lee, Kangwook Lee, Dimitris Papailiopoulos</li>
<li>for: 这个研究旨在探讨使用自然语言数据来快速启动大型语言模型的算术能力。</li>
<li>methods: 研究使用无监督下一个词预测目标进行 arithmetic 操作的学习，包括加法、乘法和平方根等操作。</li>
<li>results: 研究发现，通过使用简单的 transformer 模型和适当的数据格式化，可以使用 next-token prediction 目标来快速学习算术操作，并且这种方法可以同时提高准确率、样本复杂度和 converges 速度。<details>
<summary>Abstract</summary>
Large language models like GPT-4 exhibit emergent capabilities across general-purpose tasks, such as basic arithmetic, when trained on extensive text data, even though these tasks are not explicitly encoded by the unsupervised, next-token prediction objective. This study investigates how small transformers, trained from random initialization, can efficiently learn arithmetic operations such as addition, multiplication, and elementary functions like square root, using the next-token prediction objective. We first demonstrate that conventional training data is not the most effective for arithmetic learning, and simple formatting changes can significantly improve accuracy. This leads to sharp phase transitions as a function of training data scale, which, in some cases, can be explained through connections to low-rank matrix completion. Building on prior work, we then train on chain-of-thought style data that includes intermediate step results. Even in the complete absence of pretraining, this approach significantly and simultaneously improves accuracy, sample complexity, and convergence speed. We also study the interplay between arithmetic and text data during training and examine the effects of few-shot prompting, pretraining, and model scale. Additionally, we discuss length generalization challenges. Our work highlights the importance of high-quality, instructive data that considers the particular characteristics of the next-word prediction objective for rapidly eliciting arithmetic capabilities.
</details>
<details>
<summary>摘要</summary>
大型语言模型如GPT-4会展示涉及到通用任务的emergent能力，例如基本的算术运算，当它们被训练在广泛的文本数据上，即使这些任务没有直接被Encoding在无监督的下一个字符预测目标中。这个研究探索了如何使用下一个字符预测目标来快速学习算术运算，包括加法、乘法和幂函数。我们首先示出了传统训练数据不是最有效的 для算术学习，并且简单的格式变更可以提高准确性。这会导致训练数据的数量对学习数据的阶段性变化产生锐角转折，在一些情况下，这些转折可以通过低维矩阵完成性的连结来解释。我们 THEN以链条式数据来训练，包括中途结果。甚至在完全absence of pre-training，这种方法可以对准确性、样本复杂度和训练速度进行同时提高。我们还研究了在训练过程中文本和算术数据之间的互动，以及几个shot prompting、预训练和模型scale的影响。此外，我们还讨论了长度扩展的挑战。我们的工作强调了高质量、 instruктив的数据的重要性，以应对特定的下一个字符预测目标，快速抽象出算术能力。
</details></li>
</ul>
<hr>
<h2 id="On-Formal-Feature-Attribution-and-Its-Approximation"><a href="#On-Formal-Feature-Attribution-and-Its-Approximation" class="headerlink" title="On Formal Feature Attribution and Its Approximation"></a>On Formal Feature Attribution and Its Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03380">http://arxiv.org/abs/2307.03380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ffattr/ffa">https://github.com/ffattr/ffa</a></li>
<li>paper_authors: Jinqiang Yu, Alexey Ignatiev, Peter J. Stuckey</li>
<li>For: This paper focuses on the problem of feature attribution in machine learning models, specifically in the context of explainable artificial intelligence (XAI). It proposes a new approach called formal feature attribution (FFA) to address the limitations of existing methods.* Methods: The paper uses formal methods to analyze and evaluate the feature attribution of machine learning models. It specifically employs formal explanation enumeration to compute the exact FFA, and proposes an efficient approximation technique to handle the practical complexity of the problem.* Results: The paper provides experimental evidence of the effectiveness of the proposed approximate FFA method, comparing it to existing feature attribution algorithms in terms of feature importance and relative order. It demonstrates that FFA can provide more accurate and informative attributions than existing methods, while also being more efficient in practical settings.<details>
<summary>Abstract</summary>
Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution problem. Additionally, a formal explanation despite being formally sound is typically quite large, which hampers its applicability in practical settings. Motivated by the above, this paper proposes a way to apply the apparatus of formal XAI to the case of feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over the existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper then proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to the existing feature attribution algorithms not only in terms of feature importance and but also in terms of their relative order.
</details>
<details>
<summary>摘要</summary>
近年来，人工智能（AI）算法和机器学习（ML）模型在各个领域得到了广泛的应用。虽然它们取得了很大的成功，但是一些重要的问题仍然需要解决，如机器学习模型的 brittleness、公正性和解释性的缺失。这些问题促使了活跃的开发Explainable Artificial Intelligence（XAI）和正式的机器学习模型验证。XAI的两大主要方向是特征选择方法，如Anchors，以及特征归因技术，如LIME和SHAP。尽管它们承诺了很多，但是现有的特征选择和归因方法受到了许多重要的问题的威胁，如解释不准确和非常型采样。一种最近的正式XAI方法，尽管作为一种alternative，免受了这些问题，但它又有一些其他的限制，例如可扩展性的限制，无法解决特征归因问题。此外，正式的解释，即正式承诺，通常很大，这会妨碍它在实践中的应用。为了解决这些问题，本文提出了一种基于正式XAI的特征归因方法，即正式特征归因（FFA）。 FF A argued to be advantageous over the existing methods, both formal and non-formal。 compte tenu de la complexité pratique du problème, la paper then propose une méthode efficace pour approximer l'explication exacte FFA。Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to the existing feature attribution algorithms not only in terms of feature importance but also in terms of their relative order.
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection"><a href="#Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection" class="headerlink" title="Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection"></a>Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03377">http://arxiv.org/abs/2307.03377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta">https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Paolo Rosso, Damiano Spina</li>
<li>for: 这篇论文目的是解决机器学习中的负转移问题。</li>
<li>methods: 该论文提出了一种基于任务意识概念的方法来缓解负转移问题。</li>
<li>results: 该方法在EXIST-2021和HatEval-2019测试基准上实现了新的状态作图，并且与 класси型多任务学习方法相比，提高了性能。<details>
<summary>Abstract</summary>
This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-Task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文提出了一种新的方法来解决多任务学习中的负面传递问题。在机器学习领域中，通常采用单任务学习方法来训练特定任务的超级vised模型，但是这需要很多数据和计算资源。为了解决这个限制，多任务学习（MTL）被开发出来，它在任务之间共享信息。然而，负面传递现象会导致任务之间的信息干扰，从而导致性能下降。这篇论文提出了一种基于任务意识概念的新方法来 Mitigate负面传递问题，并且在EXIST-2021和HatEval-2019测试benchmark上设置了新的状态公共。
</details></li>
</ul>
<hr>
<h2 id="STG-MTL-Scalable-Task-Grouping-for-Multi-Task-Learning-Using-Data-Map"><a href="#STG-MTL-Scalable-Task-Grouping-for-Multi-Task-Learning-Using-Data-Map" class="headerlink" title="STG-MTL: Scalable Task Grouping for Multi-Task Learning Using Data Map"></a>STG-MTL: Scalable Task Grouping for Multi-Task Learning Using Data Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03374">http://arxiv.org/abs/2307.03374</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar Sherif, Abubakar Abid, Mustafa Elattar, Mohamed ElHelw</li>
<li>for: 提高多任务学习（MTL）的性能，解决 tradicional Single-Task Learning（STL）的缺点。</li>
<li>methods: 使用手工设计的特征数据地图，捕捉每个分类任务在MTL训练中的训练行为，从而实现可扩展和可组合的解决方案。</li>
<li>results: 实验表明，我们的方法可以有效地处理大量任务（达100个），并且可以提高MTL的性能。<details>
<summary>Abstract</summary>
Multi-Task Learning (MTL) is a powerful technique that has gained popularity due to its performance improvement over traditional Single-Task Learning (STL). However, MTL is often challenging because there is an exponential number of possible task groupings, which can make it difficult to choose the best one, and some groupings might produce performance degradation due to negative interference between tasks. Furthermore, existing solutions are severely suffering from scalability issues, limiting any practical application. In our paper, we propose a new data-driven method that addresses these challenges and provides a scalable and modular solution for classification task grouping based on hand-crafted features, specifically Data Maps, which capture the training behavior for each classification task during the MTL training. We experiment with the method demonstrating its effectiveness, even on an unprecedented number of tasks (up to 100).
</details>
<details>
<summary>摘要</summary>
多任务学习（MTL）是一种强大的技术，它在单任务学习（STL）的基础上提高性能，但是MTL也有很多挑战。其中一个主要挑战是可能的任务分组的数量是无限的，这使得选择最佳任务分组变得困难，而且一些任务分组可能会导致任务之间的负面干扰，从而降低性能。此外，现有的解决方案受到可扩展性的限制，这限制了它们在实际应用中的使用。在我们的论文中，我们提出了一种基于手工特征的数据驱动方法，该方法可以 Address these challenges and provide a scalable and modular solution for classification task grouping. We experiment with the method and demonstrate its effectiveness, even on an unprecedented number of tasks (up to 100).
</details></li>
</ul>
<hr>
<h2 id="Distilled-Pruning-Using-Synthetic-Data-to-Win-the-Lottery"><a href="#Distilled-Pruning-Using-Synthetic-Data-to-Win-the-Lottery" class="headerlink" title="Distilled Pruning: Using Synthetic Data to Win the Lottery"></a>Distilled Pruning: Using Synthetic Data to Win the Lottery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03364">http://arxiv.org/abs/2307.03364</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luke-mcdermott-mi/distilled-pruning">https://github.com/luke-mcdermott-mi/distilled-pruning</a></li>
<li>paper_authors: Luke McDermott, Daniel Cummings</li>
<li>for: 这篇论文旨在提出一种使用精炼数据的深度学习模型剪辑方法，不同于传统的建筑或算法优化方法。</li>
<li>methods: 这种方法利用精炼数据捕捉大数据集中的关键模式，并如何利用这种能力来实现 computationally efficient 的剪辑过程。</li>
<li>results: 实验结果表明，使用精炼数据可以在 CIFAR-10 上找到更加快速的、相对精炼的剪辑结果，比 Iterative Magnitude Pruning 快到 5 倍。这些结果表明使用精炼数据可以提高资源有效的神经网络剪辑、模型压缩和神经建筑搜索。<details>
<summary>Abstract</summary>
This work introduces a novel approach to pruning deep learning models by using distilled data. Unlike conventional strategies which primarily focus on architectural or algorithmic optimization, our method reconsiders the role of data in these scenarios. Distilled datasets capture essential patterns from larger datasets, and we demonstrate how to leverage this capability to enable a computationally efficient pruning process. Our approach can find sparse, trainable subnetworks (a.k.a. Lottery Tickets) up to 5x faster than Iterative Magnitude Pruning at comparable sparsity on CIFAR-10. The experimental results highlight the potential of using distilled data for resource-efficient neural network pruning, model compression, and neural architecture search.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Federated-Unlearning-via-Active-Forgetting"><a href="#Federated-Unlearning-via-Active-Forgetting" class="headerlink" title="Federated Unlearning via Active Forgetting"></a>Federated Unlearning via Active Forgetting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03363">http://arxiv.org/abs/2307.03363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuyuan Li, Chaochao Chen, Xiaolin Zheng, Jiaming Zhang</li>
<li>for: 本研究旨在提出一种基于增量学习的联合学习无学习方法，以解决联合学习无学习问题。</li>
<li>methods: 我们提出的方法基于增量学习，不需要特定的模型和联合设置。我们利用新的记忆替换老的记忆，模仿人脑中的活动忘记。Specifically, the model intended to unlearn serves as a student model that continuously learns from randomly initiated teacher models. To prevent catastrophic forgetting of non-target data, we utilize elastic weight consolidation to elastically constrain weight change.</li>
<li>results: 我们的方法在三个标准 benchmark 数据集上进行了广泛的实验，并得到了满意的效果和效率。另外，我们还通过后门攻击示例表明了我们的方法具有满意的完整性。<details>
<summary>Abstract</summary>
The increasing concerns regarding the privacy of machine learning models have catalyzed the exploration of machine unlearning, i.e., a process that removes the influence of training data on machine learning models. This concern also arises in the realm of federated learning, prompting researchers to address the federated unlearning problem. However, federated unlearning remains challenging. Existing unlearning methods can be broadly categorized into two approaches, i.e., exact unlearning and approximate unlearning. Firstly, implementing exact unlearning, which typically relies on the partition-aggregation framework, in a distributed manner does not improve time efficiency theoretically. Secondly, existing federated (approximate) unlearning methods suffer from imprecise data influence estimation, significant computational burden, or both. To this end, we propose a novel federated unlearning framework based on incremental learning, which is independent of specific models and federated settings. Our framework differs from existing federated unlearning methods that rely on approximate retraining or data influence estimation. Instead, we leverage new memories to overwrite old ones, imitating the process of \textit{active forgetting} in neurology. Specifically, the model, intended to unlearn, serves as a student model that continuously learns from randomly initiated teacher models. To preserve catastrophic forgetting of non-target data, we utilize elastic weight consolidation to elastically constrain weight change. Extensive experiments on three benchmark datasets demonstrate the efficiency and effectiveness of our proposed method. The result of backdoor attacks demonstrates that our proposed method achieves satisfying completeness.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型的隐私问题的增加，许多研究者开始探讨机器学习模型的卸载问题，即使模型不再受训练数据的影响。在联合学习领域，这种问题也得到了关注，但是联合卸载仍然是一个挑战。现有的卸载方法可以大致分为两类：精确卸载和approximate卸载。首先，在分布式环境中实现精确卸载不会提高时间效率理论上。其次，现有的联合卸载方法受到数据影响估计不准确、计算负担大、或者都有问题。为此，我们提出了一种基于增量学习的联合卸载框架，不受特定模型和联合设置的限制。我们的框架与现有的联合卸载方法不同，不是通过精度抽象重新训练或数据影响估计来实现卸载。相反，我们利用新的记忆来覆盖老的记忆，模仿人脑中的活动忘记。具体来说，作为卸载的模型，我们的模型在随机开始的老师模型的指导下不断学习。为避免非目标数据的悲观性忘记，我们利用弹性重要权重卷积来稳定重要权重的变化。我们在三个标准数据集上进行了广泛的实验，结果表明我们的提出方法是高效和有效的。结果还表明，我们的方法可以满足完整性要求。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context"><a href="#Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context" class="headerlink" title="Evaluating Biased Attitude Associations of Language Models in an Intersectional Context"></a>Evaluating Biased Attitude Associations of Language Models in an Intersectional Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03360">http://arxiv.org/abs/2307.03360</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shivaomrani/llm-bias">https://github.com/shivaomrani/llm-bias</a></li>
<li>paper_authors: Shiva Omrani Sabbaghi, Robert Wolfe, Aylin Caliskan</li>
<li>For: The paper aims to quantify the biases in language models using a sentence template that provides an intersectional context, and to study the associations of underrepresented groups in language.* Methods: The paper uses a concept projection approach to capture the valence subspace through contextualized word embeddings of language models, and adapts the projection-based approach to embedding association tests to quantify bias.* Results: The paper finds that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language, and that the largest and better-performing model is also more biased. The approach enables the study of complex intersectional biases and contributes to design justice by studying the associations of underrepresented groups in language.<details>
<summary>Abstract</summary>
Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.
</details>
<details>
<summary>摘要</summary>
受大规模文献吸收的语言模型具有隐式偏见，这些偏见在社会认知中确定语言模型对社会集团和概念的偏见态度。基于已有文献，我们使用一个 intersecting 上下文中的句子模板来衡量社会集团的VALence（愉悦程度）。我们研究年龄、教育、性别、身高、智商、文化程度、种族、宗教、性别、性取向、社会阶层和体重等因素对语言模型的偏见。我们采用一种投影方法来捕捉VALence子空间，并通过contextualized word embeddings来衡量语言模型的偏见。我们发现语言模型对性别认同、社会阶层和性取向信号表现出最大的偏见。此外，我们发现最大和最高性能的模型也是最偏见的，因为它能够吸收社会文化数据中嵌入的偏见。我们验证了偏见评价方法的正确性，并发现该方法可以衡量复杂的交叉群偏见，这些偏见在语言模型的输出和应用中仍然存在。此外，我们的方法对设计正义做出贡献，因为它研究未 Represented 在语言中的群体，如 трансジェンダ和同性恋者。
</details></li>
</ul>
<hr>
<h2 id="CSCLog-A-Component-Subsequence-Correlation-Aware-Log-Anomaly-Detection-Method"><a href="#CSCLog-A-Component-Subsequence-Correlation-Aware-Log-Anomaly-Detection-Method" class="headerlink" title="CSCLog: A Component Subsequence Correlation-Aware Log Anomaly Detection Method"></a>CSCLog: A Component Subsequence Correlation-Aware Log Anomaly Detection Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03359">http://arxiv.org/abs/2307.03359</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hang-z/csclog">https://github.com/hang-z/csclog</a></li>
<li>paper_authors: Ling Chen, Chaodu Song, Xu Wang, Dachao Fu, Feifei Li</li>
<li>for: 这个研究旨在提出一个基于系统日志的异常探测方法，以应对智能运营中的异常探测 зада难。</li>
<li>methods: 本研究使用了组件 subsequences corrrelation-aware 方法 (CSCLog)，它不具备传统方法所具备的续接性，同时还能够模型异常 subsequences 之间的隐式相互关联。</li>
<li>results: 实验结果显示，CSCLog 方法可以对四个公开的系统日志数据进行异常探测，与最佳基eline相比，平均提高了7.41%的标准偏差。<details>
<summary>Abstract</summary>
Anomaly detection based on system logs plays an important role in intelligent operations, which is a challenging task due to the extremely complex log patterns. Existing methods detect anomalies by capturing the sequential dependencies in log sequences, which ignore the interactions of subsequences. To this end, we propose CSCLog, a Component Subsequence Correlation-Aware Log anomaly detection method, which not only captures the sequential dependencies in subsequences, but also models the implicit correlations of subsequences. Specifically, subsequences are extracted from log sequences based on components and the sequential dependencies in subsequences are captured by Long Short-Term Memory Networks (LSTMs). An implicit correlation encoder is introduced to model the implicit correlations of subsequences adaptively. In addition, Graph Convolution Networks (GCNs) are employed to accomplish the information interactions of subsequences. Finally, attention mechanisms are exploited to fuse the embeddings of all subsequences. Extensive experiments on four publicly available log datasets demonstrate the effectiveness of CSCLog, outperforming the best baseline by an average of 7.41% in Macro F1-Measure.
</details>
<details>
<summary>摘要</summary>
“异常检测基于系统日志记录是智能运维中重要的一个任务，但是由于系统日志记录的极其复杂，这是一项挑战性的任务。现有的方法通过捕捉系统日志记录序列中的顺序相关性来检测异常，但是它们忽略了系统日志记录序列中的间接相关性。为此，我们提出了CSCLog方法，它不仅捕捉系统日志记录序列中的顺序相关性，而且模型了系统日志记录序列中的间接相关性。具体来说，我们从系统日志记录序列中提取了子序列，并使用Long Short-Term Memory Networks（LSTM）捕捉了这些子序列中的顺序相关性。此外，我们引入了一个适应性的间接相关性编码器，以模型系统日志记录序列中的间接相关性。同时，我们使用Graph Convolution Networks（GCNs）来实现系统日志记录序列中的信息互动。最后，我们利用了注意力机制来融合所有子序列的嵌入。我们对四个公开的系统日志数据集进行了广泛的实验，并证明了CSCLog方法的有效性，与最佳基eline相比，CSCLog方法的平均准确率提高了7.41%。”
</details></li>
</ul>
<hr>
<h2 id="Stability-and-Generalization-of-Stochastic-Compositional-Gradient-Descent-Algorithms"><a href="#Stability-and-Generalization-of-Stochastic-Compositional-Gradient-Descent-Algorithms" class="headerlink" title="Stability and Generalization of Stochastic Compositional Gradient Descent Algorithms"></a>Stability and Generalization of Stochastic Compositional Gradient Descent Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03357">http://arxiv.org/abs/2307.03357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Yang, Xiyuan Wei, Tianbao Yang, Yiming Ying</li>
<li>for: 本文研究了Stochastic Compositional Optimization（SCO）问题的稳定性和泛化性，即在各种机器学习任务中，如奖励学习、AUC最大化和元学习，目标函数具有嵌套结构和随机性。</li>
<li>methods: 本文使用了统计学习理论的机制来分析SCO算法的稳定性和泛化性。首先，我们引入了一种稳定性概念called compositional uniform stability，并证明其与泛化之间的几何关系。然后，我们证明了SCGD和SCSC算法的 compositional uniform stability 结果。最后，我们 derive了基于稳定性和优化误差的维度独立过剩风险 bounds。</li>
<li>results: 本文的结果显示，通过分析SCO算法的稳定性和泛化性，可以更好地理解这些算法在未来测试示例上的行为。此外，我们还提供了一个基于稳定性和优化误差的维度独立过剩风险 bounds，这是现有的首例研究。<details>
<summary>Abstract</summary>
Many machine learning tasks can be formulated as a stochastic compositional optimization (SCO) problem such as reinforcement learning, AUC maximization, and meta-learning, where the objective function involves a nested composition associated with an expectation. While a significant amount of studies has been devoted to studying the convergence behavior of SCO algorithms, there is little work on understanding their generalization, i.e., how these learning algorithms built from training examples would behave on future test examples. In this paper, we provide the stability and generalization analysis of stochastic compositional gradient descent algorithms through the lens of algorithmic stability in the framework of statistical learning theory. Firstly, we introduce a stability concept called compositional uniform stability and establish its quantitative relation with generalization for SCO problems. Then, we establish the compositional uniform stability results for two popular stochastic compositional gradient descent algorithms, namely SCGD and SCSC. Finally, we derive dimension-independent excess risk bounds for SCGD and SCSC by trade-offing their stability results and optimization errors. To the best of our knowledge, these are the first-ever-known results on stability and generalization analysis of stochastic compositional gradient descent algorithms.
</details>
<details>
<summary>摘要</summary>
多种机器学习任务可以表示为随机 compositional optimization（SCO）问题，如奖励学习、AUC最大化和元学习，其目标函数含有嵌入的嵌入关系。虽然有很多研究关注了 SCO 算法的收敛性行为，但对于这些学习算法在未来测试例子上的表现，却有很少研究。在这篇论文中，我们提供了 SCO 算法的稳定性和泛化分析，通过统计学学习理论的框架。首先，我们引入了一种稳定性概念called compositional uniform stability，并证明其与泛化之间存在确定的关系。然后，我们证明了 SCGD 和 SCSC 两种流行的随机 compositional gradient descent 算法的 compositional uniform stability 结果。最后，我们 derivated 不同维度的维度独立过分的剩余风险 bound，通过考虑这些算法的稳定性结果和优化错误来做出交换。根据我们所知，这些结果是 SCO 算法的稳定性和泛化分析的首次研究成果。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access"><a href="#Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access" class="headerlink" title="Federated Learning over a Wireless Network: Distributed User Selection through Random Access"></a>Federated Learning over a Wireless Network: Distributed User Selection through Random Access</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03758">http://arxiv.org/abs/2307.03758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Sun, Shiyao Ma, Ce Zheng, Songtao Wu, Tao Cui, Lingjuan Lyu</li>
<li>for: 降低联合学习（FL）在无线网络上的通信成本，用户选择已成为关键。</li>
<li>methods: 本研究提出了一种基于网络本身的分布式用户选择方法，利用无线资源竞争机制。使用多路访问（CSMA）机制为例，在每次训练中各用户获得Radio资源的机会。</li>
<li>results: 通过控制竞争窗口大小，以增加某些用户在每次训练中获得Radio资源的机会，实现了适度的用户选择。通过训练数据偏迟为FL用户选择目标场景。使用计数机制保证了公平性。在不同的数据集上进行了丰富的实践，并显示该方法可以快速达到与中央用户选择方法相似的准确率。<details>
<summary>Abstract</summary>
User selection has become crucial for decreasing the communication costs of federated learning (FL) over wireless networks. However, centralized user selection causes additional system complexity. This study proposes a network intrinsic approach of distributed user selection that leverages the radio resource competition mechanism in random access. Taking the carrier sensing multiple access (CSMA) mechanism as an example of random access, we manipulate the contention window (CW) size to prioritize certain users for obtaining radio resources in each round of training. Training data bias is used as a target scenario for FL with user selection. Prioritization is based on the distance between the newly trained local model and the global model of the previous round. To avoid excessive contribution by certain users, a counting mechanism is used to ensure fairness. Simulations with various datasets demonstrate that this method can rapidly achieve convergence similar to that of the centralized user selection approach.
</details>
<details>
<summary>摘要</summary>
用户选择已成为聚合学习（FL）在无线网络上减少通信成本的关键。然而，中央化用户选择会增加系统复杂性。本研究提出了基于网络内部的分布式用户选择方法，利用无线资源竞争机制。使用干扰多访问（CSMA）机制为例，我们在每次训练中 manipulate 竞争窗口（CW）大小，以优先给予某些用户无线资源。在训练数据偏袋场景下，我们根据上一轮训练的全球模型与当前轮训练的本地模型之间的距离，对用户进行优先级排序。为避免某些用户的过度贡献，我们使用计数机制保持公平。通过对不同的数据集进行临床示例，我们的方法可以快速达到与中央化用户选择方法相似的减少。
</details></li>
</ul>
<hr>
<h2 id="Distilling-Universal-and-Joint-Knowledge-for-Cross-Domain-Model-Compression-on-Time-Series-Data"><a href="#Distilling-Universal-and-Joint-Knowledge-for-Cross-Domain-Model-Compression-on-Time-Series-Data" class="headerlink" title="Distilling Universal and Joint Knowledge for Cross-Domain Model Compression on Time Series Data"></a>Distilling Universal and Joint Knowledge for Cross-Domain Model Compression on Time Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03347">http://arxiv.org/abs/2307.03347</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ijcai2023/uni_kd">https://github.com/ijcai2023/uni_kd</a></li>
<li>paper_authors: Qing Xu, Min Wu, Xiaoli Li, Kezhi Mao, Zhenghua Chen</li>
<li>for: 这个论文旨在提出一个标准化的架构，以便在有限资源的环境中实现深度学习模型的压缩和适应跨领域类别变化。</li>
<li>methods: 这个方法使用了一个新的统一知识传播（UNI-KD）框架，将两个领域之间的知识传播到学习者模型中，包括通用的特征水平知识和共享的数据领域知识。</li>
<li>results: 实验结果显示，这个方法在四个时间序列数据集上的性能比前一代（SOTA）标准更高，并且可以实现跨领域类别变化中的模型压缩和适应。<details>
<summary>Abstract</summary>
For many real-world time series tasks, the computational complexity of prevalent deep leaning models often hinders the deployment on resource-limited environments (e.g., smartphones). Moreover, due to the inevitable domain shift between model training (source) and deploying (target) stages, compressing those deep models under cross-domain scenarios becomes more challenging. Although some of existing works have already explored cross-domain knowledge distillation for model compression, they are either biased to source data or heavily tangled between source and target data. To this end, we design a novel end-to-end framework called Universal and joint knowledge distillation (UNI-KD) for cross-domain model compression. In particular, we propose to transfer both the universal feature-level knowledge across source and target domains and the joint logit-level knowledge shared by both domains from the teacher to the student model via an adversarial learning scheme. More specifically, a feature-domain discriminator is employed to align teacher's and student's representations for universal knowledge transfer. A data-domain discriminator is utilized to prioritize the domain-shared samples for joint knowledge transfer. Extensive experimental results on four time series datasets demonstrate the superiority of our proposed method over state-of-the-art (SOTA) benchmarks.
</details>
<details>
<summary>摘要</summary>
Many real-world 时序系列任务中，现有的深度学习模型的计算复杂性 oft hinders 部署在有限资源环境（例如智能手机）中。此外，由于源领域和目标领域之间的预期域转换，压缩这些深度模型在交叉领域场景下变得更加挑战。虽然一些现有的工作已经探索了交叉领域知识填充，但它们是 either 偏向源数据还是 heavily tangled  между源和目标数据。为此，我们设计了一个 novel 整体框架，即 Universal and joint knowledge distillation（UNI-KD），用于交叉领域模型压缩。具体来说，我们提议将 teacher 模型中的通用特征层级知识传递给学生模型，并在 adversarial learning scheme 中使用 feature-domain discriminator 对 teacher 的表示进行对接。此外，我们还使用 data-domain discriminator 来优先级化目标领域中共享的样本，以便进行交叉领域知识传递。我们对四个时序系列 dataset 进行了广泛的实验，结果表明我们的提议方法比现有的标准准则（SOTA）更高效。
</details></li>
</ul>
<hr>
<h2 id="Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat"><a href="#Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat" class="headerlink" title="Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat"></a>Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05350">http://arxiv.org/abs/2307.05350</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a></li>
<li>paper_authors: Shantanu Ghosh, Ke Yu, Forough Arabshahi, Kayhan Batmanghelich</li>
<li>for: This paper aims to blur the distinction between post hoc explanation of a Blackbox and constructing interpretable models.</li>
<li>methods: The proposed method begins with a Blackbox, iteratively carves out a mixture of interpretable experts (MoIE) and a residual network, and uses First Order Logic (FOL) to provide basic reasoning on concepts from the Blackbox.</li>
<li>results: The extensive experiments show that the proposed approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising performance, (2) identifies the relatively “harder” samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox.Here is the same information in Simplified Chinese:</li>
<li>for: 这篇论文目标是让黑盒模型的解释和可解释模型之间的分化越来越模糊。</li>
<li>methods: 提议的方法从黑盒开始，iteratively刻划出一个混合的可解释专家（MoIE）和剩下的待处理网络，并使用First Order Logic（FOL）提供黑盒中基本的推理。</li>
<li>results: 广泛的实验显示，提议的方法（1）通过MoIE实现了高完整性的实例特定概念，无需牺牲性能，（2）通过剩下的待处理网络实现了对更加“Difficult”的样本的解释，（3）在测试时间干涉中高度超越了可解释设计模型，（4）解决了黑盒学习的短circuit。 MoIE代码可以在以下链接获取：<a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a><details>
<summary>Abstract</summary>
ML model design either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible and underperforming than their Blackbox variants. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Beginning with a Blackbox, we iteratively carve out a mixture of interpretable experts (MoIE) and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our route, interpret, and repeat approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising in performance, (2) identifies the relatively ``harder'' samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox. The code for MoIE is publicly available at: \url{https://github.com/batmanlab/ICML-2023-Route-interpret-repeat}
</details>
<details>
<summary>摘要</summary>
<<SYS>>模型设计 Either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible and underperforming than their Blackbox variants. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Beginning with a Blackbox, we iteratively carve out a mixture of interpretable experts (MoIE) and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our route, interpret, and repeat approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising in performance, (2) identifies the relatively ``harder'' samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox. 模型设计可以开始 Either with an interpretable model or a Blackbox，并在后续进行解释。Blackbox模型具有灵活性，但它们具有困难解释的特性，而可解释模型则具有内在的解释性。然而，可解释模型需要ML知识的涵盖和具有较差的灵活性和性能下降。这篇论文目标是将黑盒模型的后续解释与构建可解释模型进行混合。我们从黑盒模型开始，并在每次迭代中逐步划分出一个混合的可解释专家（MoIE）和剩下的剩余网络。每个可解释模型专门处理一 subset of samples，并使用First Order Logic（FOL）进行基本的推理，提供黑盒模型中的基本概念。我们将剩下的样本通过一个灵活的剩余网络进行路由。我们在剩下的网络上重复这种方法，直到所有的可解释模型解释满足所需的数据比例。我们的广泛的实验表明，我们的路由、解释和重复方法（1）可以通过MoIE无需牺牲性能来实现高度完整的概念，（2）可以通过剩余来解释一些更加困难的样本，（3）在测试时间干涉中大幅度超越可解释设计模型，以及（4）修复黑盒模型中学习的短circuit。MoIE的代码可以在以下地址找到：<https://github.com/batmanlab/ICML-2023-Route-interpret-repeat>
</details></li>
</ul>
<hr>
<h2 id="Personalized-Prediction-of-Recurrent-Stress-Events-Using-Self-Supervised-Learning-on-Multimodal-Time-Series-Data"><a href="#Personalized-Prediction-of-Recurrent-Stress-Events-Using-Self-Supervised-Learning-on-Multimodal-Time-Series-Data" class="headerlink" title="Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data"></a>Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03337">http://arxiv.org/abs/2307.03337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanvir Islam, Peter Washington</li>
<li>for: 预测chronic stress的发展和影响</li>
<li>methods: 使用穿戴式生物信号数据，采用自我超vision学习（SSL）技术进行个性化预测</li>
<li>results: 在Wearable Stress and Affect Detection（WESAD）数据集上测试，SSL模型表现更好，只需使用 less than 5% 的注释，这表明该方法可以个性化预测chronic stressI hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Chronic stress can significantly affect physical and mental health. The advent of wearable technology allows for the tracking of physiological signals, potentially leading to innovative stress prediction and intervention methods. However, challenges such as label scarcity and data heterogeneity render stress prediction difficult in practice. To counter these issues, we have developed a multimodal personalized stress prediction system using wearable biosignal data. We employ self-supervised learning (SSL) to pre-train the models on each subject's data, allowing the models to learn the baseline dynamics of the participant's biosignals prior to fine-tuning the stress prediction task. We test our model on the Wearable Stress and Affect Detection (WESAD) dataset, demonstrating that our SSL models outperform non-SSL models while utilizing less than 5% of the annotations. These results suggest that our approach can personalize stress prediction to each user with minimal annotations. This paradigm has the potential to enable personalized prediction of a variety of recurring health events using complex multimodal data streams.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Variational-quantum-regression-algorithm-with-encoded-data-structure"><a href="#Variational-quantum-regression-algorithm-with-encoded-data-structure" class="headerlink" title="Variational quantum regression algorithm with encoded data structure"></a>Variational quantum regression algorithm with encoded data structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03334">http://arxiv.org/abs/2307.03334</a></li>
<li>repo_url: None</li>
<li>paper_authors: C. -C. Joseph Wang, Ryan S. Bennink</li>
<li>For:  solves practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers.* Methods:  constructs a quantum regression algorithm with model interpretability, employs a circuit that directly encodes the data in quantum amplitudes, and uses compressed encoding and digital-analog gate operation to reduce the run time complexity.* Results:  achieves a logarithmic reduction in the number of physical qubits needed compared to traditional one-hot-encoding techniques, and demonstrates the effectiveness of the algorithm for linear and nonlinear regression with ensemble model training and important feature selection.<details>
<summary>Abstract</summary>
Variational quantum algorithms (VQAs) prevail to solve practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers. For variational quantum machine learning, a variational algorithm with model interpretability built into the algorithm is yet to be exploited. In this paper, we construct a quantum regression algorithm and identify the direct relation of variational parameters to learned regression coefficients, while employing a circuit that directly encodes the data in quantum amplitudes reflecting the structure of the classical data table. The algorithm is particularly suitable for well-connected qubits. With compressed encoding and digital-analog gate operation, the run time complexity is logarithmically more advantageous than that for digital 2-local gate native hardware with the number of data entries encoded, a decent improvement in noisy intermediate-scale quantum computers and a minor improvement for large-scale quantum computing Our suggested method of compressed binary encoding offers a remarkable reduction in the number of physical qubits needed when compared to the traditional one-hot-encoding technique with the same input data. The algorithm inherently performs linear regression but can also be used easily for nonlinear regression by building nonlinear features into the training data. In terms of measured cost function which distinguishes a good model from a poor one for model training, it will be effective only when the number of features is much less than the number of records for the encoded data structure to be observable. To echo this finding and mitigate hardware noise in practice, the ensemble model training from the quantum regression model learning with important feature selection from regularization is incorporated and illustrated numerically.
</details>
<details>
<summary>摘要</summary>
varyational quantum algorithms (VQAs) prevail in solving practical problems such as combinatorial optimization, quantum chemistry simulation, quantum machine learning, and quantum error correction on noisy quantum computers. For variational quantum machine learning, a variational algorithm with model interpretability built into the algorithm is yet to be exploited. In this paper, we construct a quantum regression algorithm and identify the direct relation of variational parameters to learned regression coefficients, while employing a circuit that directly encodes the data in quantum amplitudes reflecting the structure of the classical data table. The algorithm is particularly suitable for well-connected qubits. With compressed encoding and digital-analog gate operation, the run time complexity is logarithmically more advantageous than that for digital 2-local gate native hardware with the number of data entries encoded, a decent improvement in noisy intermediate-scale quantum computers and a minor improvement for large-scale quantum computing. Our suggested method of compressed binary encoding offers a remarkable reduction in the number of physical qubits needed when compared to the traditional one-hot-encoding technique with the same input data. The algorithm inherently performs linear regression but can also be used easily for nonlinear regression by building nonlinear features into the training data. In terms of measured cost function which distinguishes a good model from a poor one for model training, it will be effective only when the number of features is much less than the number of records for the encoded data structure to be observable. To echo this finding and mitigate hardware noise in practice, the ensemble model training from the quantum regression model learning with important feature selection from regularization is incorporated and illustrated numerically.
</details></li>
</ul>
<hr>
<h2 id="ACDNet-Attention-guided-Collaborative-Decision-Network-for-Effective-Medication-Recommendation"><a href="#ACDNet-Attention-guided-Collaborative-Decision-Network-for-Effective-Medication-Recommendation" class="headerlink" title="ACDNet: Attention-guided Collaborative Decision Network for Effective Medication Recommendation"></a>ACDNet: Attention-guided Collaborative Decision Network for Effective Medication Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03332">http://arxiv.org/abs/2307.03332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiacong Mi, Yi Zu, Zhuoyuan Wang, Jieyue He</li>
<li>for: 这篇研究旨在提出一个基于电子健康纪录（EHR）的药物建议模型，以帮助医生更好地诊断和治疗病人。</li>
<li>methods: 这篇研究使用了注意力机制和Transformer来实现病人健康状况和药物纪录的有效捕捉，并且运用了一个协同决策架构，通过药物纪录和药物表现之间的相似性来促进建议过程。</li>
<li>results: 实验结果显示，这篇研究在两个大规模医疗数据集MIMIC-III和MIMIC-IV上表现出色，与之前的模型相比，它在Jaccard、PR-AUC和F1分数上明显提高。此外，实验中的删除实验和实验案例显示了每个模组的贡献度，证实了它们对整体性能的贡献。<details>
<summary>Abstract</summary>
Medication recommendation using Electronic Health Records (EHR) is challenging due to complex medical data. Current approaches extract longitudinal information from patient EHR to personalize recommendations. However, existing models often lack sufficient patient representation and overlook the importance of considering the similarity between a patient's medication records and specific medicines. Therefore, an Attention-guided Collaborative Decision Network (ACDNet) for medication recommendation is proposed in this paper. Specifically, ACDNet utilizes attention mechanism and Transformer to effectively capture patient health conditions and medication records by modeling their historical visits at both global and local levels. ACDNet also employs a collaborative decision framework, utilizing the similarity between medication records and medicine representation to facilitate the recommendation process. The experimental results on two extensive medical datasets, MIMIC-III and MIMIC-IV, clearly demonstrate that ACDNet outperforms state-of-the-art models in terms of Jaccard, PR-AUC, and F1 score, reaffirming its superiority. Moreover, the ablation experiments provide solid evidence of the effectiveness of each module in ACDNet, validating their contribution to the overall performance. Furthermore, a detailed case study reinforces the effectiveness of ACDNet in medication recommendation based on EHR data, showcasing its practical value in real-world healthcare scenarios.
</details>
<details>
<summary>摘要</summary>
运用电子健康记录（EHR）提供处方建议是具有复杂医疗资料的挑战。现有方法通常从病人EHR中提取长期信息，以personalize处方建议。然而，现有的模型通常缺乏病人表现的完整性，并忽略了考虑病人处方记录和具体药品之间的相似性。因此，本文提出了一个注意力导向的协同决策网络（ACDNet），用于处方建议。具体来说，ACDNet使用注意力机制和Transformer来有效地捕捉病人健康状态和处方记录，并通过模型病人的历史访问记录，实现全球和局部水平的同步运算。ACDNet还使用协同决策框架，通过考虑处方记录和药品表示之间的相似性，来协助建议过程。实验结果显示，ACDNet在两个大量医疗数据集MIMIC-III和MIMIC-IV上具有较高的Jaccard、PR-AUC和F1分数，与现有模型相比，具体表明其超越性。此外，删除实验显示了每个模组在ACDNet中的贡献，证实它们的贡献为整体性能的重要原因。此外，一个详细的实验案例证明ACDNet在基于EHR数据的处方建议中的实际价值，展现其在实际医疗应用中的实用性。
</details></li>
</ul>
<hr>
<h2 id="Encoder-Decoder-Networks-for-Self-Supervised-Pretraining-and-Downstream-Signal-Bandwidth-Regression-on-Digital-Antenna-Arrays"><a href="#Encoder-Decoder-Networks-for-Self-Supervised-Pretraining-and-Downstream-Signal-Bandwidth-Regression-on-Digital-Antenna-Arrays" class="headerlink" title="Encoder-Decoder Networks for Self-Supervised Pretraining and Downstream Signal Bandwidth Regression on Digital Antenna Arrays"></a>Encoder-Decoder Networks for Self-Supervised Pretraining and Downstream Signal Bandwidth Regression on Digital Antenna Arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03327">http://arxiv.org/abs/2307.03327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajib Bhattacharjea, Nathan West</li>
<li>for: 这个研究是应用自动学习技术到数字天线阵列数据上的首次应用。</li>
<li>methods: 研究使用encoder-decoder网络进行自我超vised隐藏重建任务，称为频道填充，用于推断数字天线阵列数据中的 zeros 层面。无需人工标注数据。</li>
<li>results: 我们发现，通过在新网络中转移encoder架构和参数，并在小量标注数据上训练，可以使新网络在数字天线阵列数据上进行带宽调整任务更好than一个Equivalent网络从随机初始化开始训练。<details>
<summary>Abstract</summary>
This work presents the first applications of self-supervised learning applied to data from digital antenna arrays. Encoder-decoder networks are pretrained on digital array data to perform a self-supervised noisy-reconstruction task called channel in-painting, in which the network infers the contents of array data that has been masked with zeros. The self-supervised step requires no human-labeled data. The encoder architecture and weights from pretraining are then transferred to a new network with a task-specific decoder, and the new network is trained on a small volume of labeled data. We show that pretraining on the unlabeled data allows the new network to perform the task of bandwidth regression on the digital array data better than an equivalent network that is trained on the same labeled data from random initialization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Machine-Learning-to-detect-cyber-attacks-and-discriminating-the-types-of-power-system-disturbances"><a href="#Machine-Learning-to-detect-cyber-attacks-and-discriminating-the-types-of-power-system-disturbances" class="headerlink" title="Machine Learning to detect cyber-attacks and discriminating the types of power system disturbances"></a>Machine Learning to detect cyber-attacks and discriminating the types of power system disturbances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03323">http://arxiv.org/abs/2307.03323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diane Tuyizere, Remy Ihabwikuzo</li>
<li>for: 这项研究目标是为智能电网提供机器学习基于攻击探测模型，以便更好地识别和防范攻击。</li>
<li>methods: 该模型使用phasor measuring devices（PMUs）采集数据和日志，并使用机器学习算法来学习系统行为并识别潜在的安全边界。</li>
<li>results: 研究发现，使用Random Forest模型可以达到90.56%的检测精度，并且有助于操作人员做出决策。<details>
<summary>Abstract</summary>
This research proposes a machine learning-based attack detection model for power systems, specifically targeting smart grids. By utilizing data and logs collected from Phasor Measuring Devices (PMUs), the model aims to learn system behaviors and effectively identify potential security boundaries. The proposed approach involves crucial stages including dataset pre-processing, feature selection, model creation, and evaluation. To validate our approach, we used a dataset used, consist of 15 separate datasets obtained from different PMUs, relay snort alarms and logs. Three machine learning models: Random Forest, Logistic Regression, and K-Nearest Neighbour were built and evaluated using various performance metrics. The findings indicate that the Random Forest model achieves the highest performance with an accuracy of 90.56% in detecting power system disturbances and has the potential in assisting operators in decision-making processes.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种基于机器学习的电力系统攻击检测模型，特别是针对智能电网。通过利用phasor Measuring Devices（PMUs）收集的数据和日志，模型希望学习系统行为并有效地识别潜在的安全边界。提出的方法包括重要的阶段，包括数据集 pré-处理、特征选择、模型创建和评估。为验证我们的方法，我们使用了15个不同PMUs、闭合风暴报警和日志的数据集。我们建立了三种机器学习模型：Random Forest、Logistic Regression和K-Nearest Neighbour，并使用了不同的性能指标进行评估。研究发现，Random Forest模型在检测电力系统干扰的准确率达90.56%，并有助于操作人员决策过程中。
</details></li>
</ul>
<hr>
<h2 id="Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation"><a href="#Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation" class="headerlink" title="Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation"></a>Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03315">http://arxiv.org/abs/2307.03315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Xue, Ahmed Sameh Said, Ziqi Xu, Hanyang Liu, Neel Shah, Hanqing Yang, Philip Payne, Chenyang Lu</li>
<li>for: This paper aims to support clinical decisions for COVID-19 patients who require extracorporeal membrane oxygenation (ECMO) treatment.</li>
<li>methods: The paper proposes a novel approach called Treatment Variational AutoEncoder (TVAE) to predict individualized treatment outcomes for COVID-19 patients. TVAE uses a deep latent variable model to represent patients’ potential treatment assignments and factual&#x2F;counterfactual outcomes, and alleviates prediction errors through a reconstruction regularization scheme and semi-supervision.</li>
<li>results: The paper evaluates TVAE on two real-world COVID-19 datasets and shows that it outperforms state-of-the-art treatment effect models in predicting propensity scores and factual outcomes on heterogeneous datasets. Additionally, TVAE outperforms existing models in individual treatment effect estimation on a synthesized dataset.<details>
<summary>Abstract</summary>
Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.
</details>
<details>
<summary>摘要</summary>
外部肺氧化（ECMO）是covid-19患者无法响应传统治疗的生命支持 modalities。然而，正确的治疗决策仍然存在争议，并且不确定哪些患者会从这种罕见和技术复杂的治疗选择中受益。为支持临床决策，我们需要预测治疗需求和可能的治疗和无治疗响应。为解决这种临床挑战，我们提出了个性化治疗分析方法——治疗变量自适应器（TVAE）。TVAE是为了解决ECMO治疗选择偏袋和罕见治疗案例的模型挑战而设计的。我们将患者的可能的治疗决策和实际和对照结果视为患者的内在特征，并使用深度约束模型来表示。寻求和对照预测错误的约束来自重构规则和半监督学习，同时通过分配空间和标签匹配的生成策略来缓解选择偏袋和罕见治疗案例的问题。我们在两个真实世界COVID-19数据集上评估了TVAE：一个国际数据集来自1651家医院在63个国家，另一个机构数据集来自15家医院。结果表明，TVAE在不同COVID-19数据集上预测propensity score和实际结果的性能都高于状态的投入效果模型。此外，我们还通过附加的实验表明，TVAE在个体治疗效果预测方面也超过了 beste existing models。
</details></li>
</ul>
<hr>
<h2 id="On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data"><a href="#On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data" class="headerlink" title="On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data"></a>On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03311">http://arxiv.org/abs/2307.03311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janis Keuper</li>
<li>for: 这份技术报告提供了圆形幂（SH）频谱中数据的数学表示的深入介绍，包括无法变和对称特征、卷积和圆形幂上信号的精确相关性。</li>
<li>methods: 本文使用了圆形幂表示，包括无法变和对称特征、卷积和圆形幂上信号的精确相关性。</li>
<li>results: 本文扩展了scalar SH表示到vectorial harmonics（VH），为3Dvector场在圆形幂上提供了相同的功能。<details>
<summary>Abstract</summary>
The mathematical representations of data in the Spherical Harmonic (SH) domain has recently regained increasing interest in the machine learning community. This technical report gives an in-depth introduction to the theoretical foundation and practical implementation of SH representations, summarizing works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. In extension, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), providing the same capabilities for 3d vector fields on spheres
</details>
<details>
<summary>摘要</summary>
Recently, the mathematical representations of data in the Spherical Harmonic (SH) domain have gained increasing interest in the machine learning community. This technical report provides an in-depth introduction to the theoretical foundation and practical implementation of SH representations, including works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. Additionally, these methods are extended from scalar SH representations to Vectorial Harmonics (VH), enabling the same capabilities for 3D vector fields on spheres.Here's the translation in Traditional Chinese:最近，圆球几何（Spherical Harmonic，SH）领域中的数据数学表现方法在机器学习社区中受到增加的关注。本技术报告将提供深入的理论基础和实践SH表现方法，包括对于旋转不变和对称特征、圆球上信号的卷积和精确相关性。此外，这些方法还被扩展到对 vectorial harmonics（VH），实现3D вектор场在圆球上的相同能力。
</details></li>
</ul>
<hr>
<h2 id="When-Fair-Classification-Meets-Noisy-Protected-Attributes"><a href="#When-Fair-Classification-Meets-Noisy-Protected-Attributes" class="headerlink" title="When Fair Classification Meets Noisy Protected Attributes"></a>When Fair Classification Meets Noisy Protected Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03306">http://arxiv.org/abs/2307.03306</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/evijit/awareness_vs_unawareness">https://github.com/evijit/awareness_vs_unawareness</a></li>
<li>paper_authors: Avijit Ghosh, Pablo Kvitca, Christo Wilson</li>
<li>for: 本研究旨在解决算法公平性的实际挑战，包括数据集中保护属性的可用性和可靠性问题。</li>
<li>methods: 本研究使用了不同的公平分类算法，包括依赖属性、忽略属性和不依赖属性的算法，并对这些算法进行了比较。</li>
<li>results: 研究发现，忽略属性和忽略噪声的公平分类算法可以在保护属性是不可靠或噪声的情况下达到类似的性能水平，但实施需要谨慎。<details>
<summary>Abstract</summary>
The operationalization of algorithmic fairness comes with several practical challenges, not the least of which is the availability or reliability of protected attributes in datasets. In real-world contexts, practical and legal impediments may prevent the collection and use of demographic data, making it difficult to ensure algorithmic fairness. While initial fairness algorithms did not consider these limitations, recent proposals aim to achieve algorithmic fairness in classification by incorporating noisiness in protected attributes or not using protected attributes at all.   To the best of our knowledge, this is the first head-to-head study of fair classification algorithms to compare attribute-reliant, noise-tolerant and attribute-blind algorithms along the dual axes of predictivity and fairness. We evaluated these algorithms via case studies on four real-world datasets and synthetic perturbations. Our study reveals that attribute-blind and noise-tolerant fair classifiers can potentially achieve similar level of performance as attribute-reliant algorithms, even when protected attributes are noisy. However, implementing them in practice requires careful nuance. Our study provides insights into the practical implications of using fair classification algorithms in scenarios where protected attributes are noisy or partially available.
</details>
<details>
<summary>摘要</summary>
“algorithmic fairness的实施面临多种实际挑战，其中最大的问题之一是数据集中保护特征的可用性和可靠性。在真实世界中，法律和实际困难可能会阻止对民生数据的收集和使用，使得保证algorithmic fairness变得困难。初期的公平算法并不考虑这些限制，但最新的建议旨在通过不考虑保护特征或使用噪音来实现公平分类。根据我们所知，这是首次对公平分类算法进行了头对头比较，并考虑了两个轴：预测性和公平性。我们通过四个真实世界数据集和 sintetic perturbations 进行了测试。我们的研究发现，忽略保护特征和噪音忍容的公平分类算法可能能够与依赖保护特征的算法具有相似的性能水平，即使保护特征噪音。但是，在实践中实现这些算法需要谨慎。我们的研究为在保护特征噪音或部分可用的场景中使用公平分类算法提供了实践意义。”Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores"><a href="#A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores" class="headerlink" title="A Vulnerability of Attribution Methods Using Pre-Softmax Scores"></a>A Vulnerability of Attribution Methods Using Pre-Softmax Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03305">http://arxiv.org/abs/2307.03305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlerma54/adversarial-attacks-on-saliency-maps">https://github.com/mlerma54/adversarial-attacks-on-saliency-maps</a></li>
<li>paper_authors: Miguel Lerma, Mirtha Lucas</li>
<li>for: 这种论文探讨了一种类型的归类器中的拟合方法，即使这种模型受到了恶意攻击，小量修改模型也可以导致拟合方法的解释结果受到影响。</li>
<li>methods: 这种论文使用了一种类型的归类器，并使用了某些修改方法来影响拟合方法的解释结果。</li>
<li>results: 研究发现，这种修改方法可以导致拟合方法的解释结果受到影响，而不需要改变模型的输出。<details>
<summary>Abstract</summary>
We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
</details>
<details>
<summary>摘要</summary>
我们讨论了一个漏洞，它与对于卷积神经网作为分类器的说明方法有关。知道这种神经网容易受到敌意攻击，这种攻击可以通过对输入进行微妙的变化，导致模型的输出变化。相反，我们在这里专注于对于说明方法的小修改，不会改变模型的输出。
</details></li>
</ul>
<hr>
<h2 id="Equivariant-Spherical-CNN-for-Data-Efficient-and-High-Performance-Medical-Image-Processing"><a href="#Equivariant-Spherical-CNN-for-Data-Efficient-and-High-Performance-Medical-Image-Processing" class="headerlink" title="Equivariant Spherical CNN for Data Efficient and High-Performance Medical Image Processing"></a>Equivariant Spherical CNN for Data Efficient and High-Performance Medical Image Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03298">http://arxiv.org/abs/2307.03298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirreza Hashemi, Yuemeng Feng, Hamid Sabet</li>
<li>for: 这个研究旨在提高医疗图像处理领域中的Tomography应用，并且提出了一种新的对称网络方法来改善这些应用的效率和性能。</li>
<li>methods: 这个研究使用了一种叫做对称网络的方法，这种方法可以将医疗图像处理中的训练集不断地缩小，以提高网络的稳定性和效率。</li>
<li>results: 研究结果显示，使用对称网络可以实现医疗图像处理中的高品质和高效率，并且可以降低训练集的size，以减少训练时间和计算成本。<details>
<summary>Abstract</summary>
This work highlights the significance of equivariant networks as efficient and high-performance approaches for tomography applications. Our study builds upon the limitations of Convolutional Neural Networks (CNNs), which have shown promise in post-processing various medical imaging systems. However, the efficiency of conventional CNNs heavily relies on an undiminished and proper training set. To tackle this issue, in this study, we introduce an equivariant network, aiming to reduce CNN's dependency on specific training sets. We evaluate the efficacy of equivariant CNNs on spherical signals for tomographic medical imaging problems. Our results demonstrate superior quality and computational efficiency of spherical CNNs (SCNNs) in denoising and reconstructing benchmark problems. Furthermore, we propose a novel approach to employ SCNNs as a complement to conventional image reconstruction tools, enhancing the outcomes while reducing reliance on the training set. Across all cases, we observe a significant decrease in computational costs while maintaining the same or higher quality of image processing using SCNNs compared to CNNs. Additionally, we explore the potential of this network for broader tomography applications, particularly those requiring omnidirectional representation.
</details>
<details>
<summary>摘要</summary>
Translation note:* "Equivariant networks" is translated as "协变网络" (fùbiàn wǎngluò), which means the network architecture that preserves the symmetry of the input data.* "Spherical signals" is translated as "球形信号" (qiúxíng xìnhù), which refers to the signals that have spherical symmetry.* "Tomographic medical imaging" is translated as "tomography医学影像" (tòngshì yīxué yǐngxiàng), which refers to the medical imaging techniques that use X-rays or other forms of radiation to create cross-sectional images of the body.* "Convolutional Neural Networks" is translated as "卷积神经网络" (juéshì shénxiào wǎngluò), which is the abbreviation of CNNs.* "Omnidirectional representation" is translated as "全方位表示" (quánfāngwèi bǎoshì), which means the representation that captures the information from all directions.
</details></li>
</ul>
<hr>
<h2 id="OmniBoost-Boosting-Throughput-of-Heterogeneous-Embedded-Devices-under-Multi-DNN-Workload"><a href="#OmniBoost-Boosting-Throughput-of-Heterogeneous-Embedded-Devices-under-Multi-DNN-Workload" class="headerlink" title="OmniBoost: Boosting Throughput of Heterogeneous Embedded Devices under Multi-DNN Workload"></a>OmniBoost: Boosting Throughput of Heterogeneous Embedded Devices under Multi-DNN Workload</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03290">http://arxiv.org/abs/2307.03290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Karatzas, Iraklis Anagnostopoulos</li>
<li>for: 提高多个深度神经网络（DNN）应用工作负载的高性能和高效率</li>
<li>methods: 使用杂种加速器、硬件异构性和随机空间探索技术</li>
<li>results: 与其他状态对比方法相比，实现了平均吞吐量提高4.6倍<details>
<summary>Abstract</summary>
Modern Deep Neural Networks (DNNs) exhibit profound efficiency and accuracy properties. This has introduced application workloads that comprise of multiple DNN applications, raising new challenges regarding workload distribution. Equipped with a diverse set of accelerators, newer embedded system present architectural heterogeneity, which current run-time controllers are unable to fully utilize. To enable high throughput in multi-DNN workloads, such a controller is ought to explore hundreds of thousands of possible solutions to exploit the underlying heterogeneity. In this paper, we propose OmniBoost, a lightweight and extensible multi-DNN manager for heterogeneous embedded devices. We leverage stochastic space exploration and we combine it with a highly accurate performance estimator to observe a x4.6 average throughput boost compared to other state-of-the-art methods. The evaluation was performed on the HiKey970 development board.
</details>
<details>
<summary>摘要</summary>
现代深度神经网络（DNN）具有深刻的效率和准确性特性。这引入了包含多个DNN应用的工作负荷，引起了新的工作负荷分布挑战。新的嵌入式系统采用多种加速器，导致系统架构多样性，现有的运行时控制器无法完全利用。为实现高吞吨在多个DNN工作负荷中，这种控制器应该探索数以千计的可能性。在这篇论文中，我们提出了OmniBoost，一个轻量级的多DNN管理器，适用于多种嵌入式设备。我们利用随机空间探索和高度准确的性能估计器，观察到与其他状态态方法相比，平均吞吨提升4.6倍。测试结果在HiKey970开发板上进行。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Scalarizations-for-Sublinear-Hypervolume-Regret"><a href="#Optimal-Scalarizations-for-Sublinear-Hypervolume-Regret" class="headerlink" title="Optimal Scalarizations for Sublinear Hypervolume Regret"></a>Optimal Scalarizations for Sublinear Hypervolume Regret</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03288">http://arxiv.org/abs/2307.03288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiuyi Zhang</li>
<li>for: 本研究旨在找到一种简单的非线性归一化方法，可以在多目标设定中探索多个目标的 pareto 前沿，并提高搜索效率。</li>
<li>methods: 我们使用了 hypervolume 归一化方法，并采用了随机权重的方法来评估不同的归一化方法。</li>
<li>results: 我们的研究表明，使用 hypervolume 归一化方法可以获得提高的搜索效率，并且可以在多目标问题中提供更好的解决方案。我们的实验结果也表明，使用简单的 hypervolume 归一化方法可以在 bayesian 优化中表现更好，并且可以超越标准的多目标算法，如 EHVI。<details>
<summary>Abstract</summary>
Scalarization is a general technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, such as recently in RLHF for training reward models that align human preferences. Yet some have dismissed this classical approach because linear scalarizations are known to miss concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that can explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights are surprisingly optimal for provably minimizing the hypervolume regret, achieving an optimal sublinear regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. As a theoretical case study, we consider the multiobjective stochastic linear bandits problem and demonstrate that by exploiting the sublinear regret bounds of the hypervolume scalarizations, we can derive a novel non-Euclidean analysis that produces improved hypervolume regret bounds of $\tilde{O}( d T^{-1/2} + T^{-1/k})$. We support our theory with strong empirical performance of using simple hypervolume scalarizations that consistently outperforms both the linear and Chebyshev scalarizations, as well as standard multiobjective algorithms in bayesian optimization, such as EHVI.
</details>
<details>
<summary>摘要</summary>
scalarization 是一种通用技术，可以在多目标设置中降低多个目标到一个，例如在RLHF中训练奖励模型，以实现人类偏好的Alignment。然而，一些人认为这种经典方法不合适，因为线性Scalarization会错过凹陷区域的Pareto前沿。为此，我们想找到简单的非线性Scalarization，以探索$k$个目标在Pareto前沿上的多样化集合，由dominated hypervolume来度量。我们表明，在随机权重下的 hypervolume scalarization 可以让我们提取优质的 hypervolume regret，实现 $O(T^{-1/k})$ 的优linear regret bound，与它们匹配的下界，阻止任何算法在极限情况下做得更好。作为一个理论案例，我们考虑了多目标随机线性带宽问题，并证明了通过权重Scalarization 的Sublinear regret bound，我们可以 derivate一个新的非Euclidean分析，生成改进的 hypervolume regret bound 的 $\tilde{O}(dT^{-1/2} + T^{-1/k})$。我们的理论实际上支持了使用简单的 hypervolume scalarization，常常超越了线性和Chebyshev scalarization，以及标准多目标算法在 bayesian optimization 中，如EHVI。
</details></li>
</ul>
<hr>
<h2 id="Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging"><a href="#Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging" class="headerlink" title="Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging"></a>Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03266">http://arxiv.org/abs/2307.03266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heejong Kim, Victor Ion Butoi, Adrian V. Dalca, Daniel J. A. Margolis, Mert R. Sabuncu</li>
<li>for: This paper is written for the purpose of evaluating the effectiveness of a foundation model for medical image segmentation, specifically in the context of prostate imaging.</li>
<li>methods: The paper uses a recently developed foundation model called UniverSeg, which is compared against the conventional approach of training a task-specific segmentation model.</li>
<li>results: The study finds that the foundation model achieves competitive performance in prostate imaging segmentation, and highlights several important factors that will be important in the development and adoption of foundation models for medical image segmentation.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了评估医疗图像分割领域中的基础模型效果，具体来说是在肾脏成像中进行评估。</li>
<li>methods: 这篇论文使用了一个最近开发的基础模型，即UniverSeg，与传统的任务特定分割模型进行比较。</li>
<li>results: 研究发现，基础模型在肾脏成像分割中实现了竞争性的性能，并提出了各种重要因素，这些因素将在基础模型的开发和应用中扮演重要的角色。<details>
<summary>Abstract</summary>
Most state-of-the-art techniques for medical image segmentation rely on deep-learning models. These models, however, are often trained on narrowly-defined tasks in a supervised fashion, which requires expensive labeled datasets. Recent advances in several machine learning domains, such as natural language generation have demonstrated the feasibility and utility of building foundation models that can be customized for various downstream tasks with little to no labeled data. This likely represents a paradigm shift for medical imaging, where we expect that foundation models may shape the future of the field. In this paper, we consider a recently developed foundation model for medical image segmentation, UniverSeg. We conduct an empirical evaluation study in the context of prostate imaging and compare it against the conventional approach of training a task-specific segmentation model. Our results and discussion highlight several important factors that will likely be important in the development and adoption of foundation models for medical image segmentation.
</details>
<details>
<summary>摘要</summary>
现代医疗影像分类技术多采用深度学习模型。然而，这些模型通常需要高价的标签数据来训练，导致成本高昂。近年，自然语言生成等机器学习领域的进步，已经证明了建立基础模型，可以根据不同的下游任务进行定制，仅需少量或无标签数据。这将可能成为医疗影像领域的新模式，我们预料基础模型将未来医疗影像领域的发展推动。本文考虑了最近发展的医疗影像分类基础模型UniverSeg，并在阴茎影像上进行了实验性评估，与传统方法（即训练专门的医疗影像分类模型）进行比较。我们的结果和讨论显示了一些重要的因素，将影响医疗影像分类基础模型的发展和采用。
</details></li>
</ul>
<hr>
<h2 id="Vision-Language-Transformers-A-Survey"><a href="#Vision-Language-Transformers-A-Survey" class="headerlink" title="Vision Language Transformers: A Survey"></a>Vision Language Transformers: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03254">http://arxiv.org/abs/2307.03254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clayton Fields, Casey Kennington</li>
<li>for: 这个论文旨在总结目前已经公布的视觉语言传感器模型研究，以及这些模型在不同任务上的应用和表现。</li>
<li>methods: 这些模型使用了基于transformer架构的 pré-training方法，并通过微调参数和架构来适应不同任务。</li>
<li>results: 这些模型在视觉语言任务上表现出色，并且在不同任务上具有较高的灵活性和适应能力。<details>
<summary>Abstract</summary>
Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations and some open questions that remain.
</details>
<details>
<summary>摘要</summary>
computer vision tasks that require both vision and language, such as answering questions about or generating captions that describe an image, are difficult for computers to perform. Recently, researchers have adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling, which has greatly improved performance and versatility over previous vision language models. These models are trained on large generic datasets and then transferred to new tasks with minor changes in architecture and parameter values, which has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks that require both vision and language. In this paper, we provide a comprehensive overview of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations, and open questions that remain.
</details></li>
</ul>
<hr>
<h2 id="Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation"><a href="#Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation" class="headerlink" title="Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation"></a>Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05385">http://arxiv.org/abs/2307.05385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sully F. Chen, Zhicheng Guo, Cheng Ding, Xiao Hu, Cynthia Rudin</li>
<li>for: 本研究旨在提出一种可靠、高效、可解释的信号质量评估和噪声分 Segmentation方法，以确保robust和准确地提取生物Physiological Parameters。</li>
<li>methods: 本方法使用了一种小量且可解释的卷积核来学习，与之前的手工特征检测器或信号度量计算相比，具有更高的性能，同时具有可解释性和低功耗特性。</li>
<li>results: 本研究实验结果表明，提出的方法可以与现有的深度神经网络（DNN）方法相当或更好地提取Physiological Parameters，同时具有许多次更多的参数和更高的计算和存储效率。<details>
<summary>Abstract</summary>
Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and interpretable signal quality assessment and artifact segmentation on low-power devices.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Neural-Network-Field-Theories-Non-Gaussianity-Actions-and-Locality"><a href="#Neural-Network-Field-Theories-Non-Gaussianity-Actions-and-Locality" class="headerlink" title="Neural Network Field Theories: Non-Gaussianity, Actions, and Locality"></a>Neural Network Field Theories: Non-Gaussianity, Actions, and Locality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03223">http://arxiv.org/abs/2307.03223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehmet Demirtas, James Halverson, Anindita Maiti, Matthew D. Schwartz, Keegan Stoner</li>
<li>for: 这篇论文探讨了场理论中的征function distribution，以及由 neural network ensemble describe这种分布的可能性。</li>
<li>methods: 论文使用了场理论中的中心限定定律，以及对 neural network 参数的小量偏置，来描述分布。</li>
<li>results: 论文表明，在 infinite-width （infinite-$N） Limit下， neural network ensemble可以被视为一种自由场理论，并且可以使用 field theory 的方法来描述。<details>
<summary>Abstract</summary>
Both the path integral measure in field theory and ensembles of neural networks describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-$N$) limit, the ensemble of networks corresponds to a free field theory. Although an expansion in $1/N$ corresponds to interactions in the field theory, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the $1/N$-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a field theory, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for neural network field theories. Conversely, the correspondence allows one to engineer architectures realizing a given field theory by representing action deformations as deformations of neural network parameter densities. As an example, $\phi^4$ theory is realized as an infinite-$N$ neural network field theory.
</details>
<details>
<summary>摘要</summary>
Both the path integral measure in field theory and ensembles of neural networks describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-$N$) limit, the ensemble of networks corresponds to a free field theory. Although an expansion in $1/N$ corresponds to interactions in the field theory, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the $1/N$-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a field theory, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for neural network field theories. Conversely, the correspondence allows one to engineer architectures realizing a given field theory by representing action deformations as deformations of neural network parameter densities. As an example, $\phi^4$ theory is realized as an infinite-$N$ neural network field theory.Here's the translation in Traditional Chinese: Both the path integral measure in field theory and ensembles of neural networks describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-$N$) limit, the ensemble of networks corresponds to a free field theory. Although an expansion in $1/N$ corresponds to interactions in the field theory, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the $1/N$-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a field theory, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for neural network field theories. Conversely, the correspondence allows one to engineer architectures realizing a given field theory by representing action deformations as deformations of neural network parameter densities. As an example, $\phi^4$ theory is realized as an infinite-$N$ neural network field theory.
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Artistic-Cinemagraphs-from-Text"><a href="#Synthesizing-Artistic-Cinemagraphs-from-Text" class="headerlink" title="Synthesizing Artistic Cinemagraphs from Text"></a>Synthesizing Artistic Cinemagraphs from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03190">http://arxiv.org/abs/2307.03190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/text2cinemagraph/text2cinemagraph">https://github.com/text2cinemagraph/text2cinemagraph</a></li>
<li>paper_authors: Aniruddha Mahapatra, Aliaksandr Siarohin, Hsin-Ying Lee, Sergey Tulyakov, Jun-Yan Zhu</li>
<li>for: 本研究旨在创建基于文本描述的电影画面。</li>
<li>methods: 本方法使用了自动生成图像双胞胎的想法，通过将文本描述转化为一对包含艺术风格和自然风格的图像。然后，通过分析自然图像和视频数据，对实际图像进行 segmentation 和动作预测，并将预测动作传递到艺术图像中。</li>
<li>results: 本研究的结果表明， compared to现有方法，本方法在创建自然风景以及艺术和其他世界的电影画面方面表现出色，并且可以控制动作方向使用文本。此外，本研究还扩展到了将现有的画作动画化以及通过文本控制动作方向。<details>
<summary>Abstract</summary>
We introduce Text2Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images. Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static. To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin. While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis. Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information. The predicted motion can then be transferred to the artistic image to create the final cinemagraph. Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies. Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text.
</details>
<details>
<summary>摘要</summary>
我们介绍Text2Cinemagraph，一种完全自动的方法，可以从文本描述中生成电影图像 - 特别是处理含有想象元素和艺术风格的描述时，这是一个非常困难的任务。现有的单图动画方法在艺术输入方面有限，而 recient的文本基于视频方法经常出现时间不一致，尝试维持某些区域静止。为解决这些挑战，我们提出了一种将文本描述转化为两个图像的想法 - 一个是一个艺术性的图像，另一个是其像素对齐的自然看起来的图像。而艺术性的图像会具有文本描述中的风格和形态，而自然图像则会大大简化布局和动作分析。利用现有的自然图像和视频数据集，我们可以准确地分割自然图像，并预测可能的动作，基于 semantic信息。预测的动作然后可以被传递到艺术性的图像，以创建最终的电影图像。我们的方法比既有方法在创建电影图像的自然风景以及艺术和其他世界的场景上表现出色，并通过自动度量和用户研究得到了证明。最后，我们还展示了两种扩展：将现有的画作动画并控制动作方向使用文本。
</details></li>
</ul>
<hr>
<h2 id="TGRL-An-Algorithm-for-Teacher-Guided-Reinforcement-Learning"><a href="#TGRL-An-Algorithm-for-Teacher-Guided-Reinforcement-Learning" class="headerlink" title="TGRL: An Algorithm for Teacher Guided Reinforcement Learning"></a>TGRL: An Algorithm for Teacher Guided Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03186">http://arxiv.org/abs/2307.03186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Idan Shenfeld, Zhang-Wei Hong, Aviv Tamar, Pulkit Agrawal</li>
<li>for: 本文目的是解决Sequential Decision-Making问题，通过结合权威指导和奖励学习两种已知方法。</li>
<li>methods: 本文使用的方法是在权威指导和奖励学习目标之间进行平衡，以实现更好的性能。</li>
<li>results: 本文的实验结果显示，使用Teacher Guided Reinforcement Learning（TGRL）方法可以在多个领域中超越强基线，而无需进行参数调整。<details>
<summary>Abstract</summary>
Learning from rewards (i.e., reinforcement learning or RL) and learning to imitate a teacher (i.e., teacher-student learning) are two established approaches for solving sequential decision-making problems. To combine the benefits of these different forms of learning, it is common to train a policy to maximize a combination of reinforcement and teacher-student learning objectives. However, without a principled method to balance these objectives, prior work used heuristics and problem-specific hyperparameter searches to balance the two objectives. We present a $\textit{principled}$ approach, along with an approximate implementation for $\textit{dynamically}$ and $\textit{automatically}$ balancing when to follow the teacher and when to use rewards. The main idea is to adjust the importance of teacher supervision by comparing the agent's performance to the counterfactual scenario of the agent learning without teacher supervision and only from rewards. If using teacher supervision improves performance, the importance of teacher supervision is increased and otherwise it is decreased. Our method, $\textit{Teacher Guided Reinforcement Learning}$ (TGRL), outperforms strong baselines across diverse domains without hyper-parameter tuning.
</details>
<details>
<summary>摘要</summary>
学习从奖励（i.e., 奖励学习或RL）和学习教师（i.e., 教师学习）是两种成熔的解决Sequential decision-making问题的方法。为了结合这些不同的学习方法的优点，通常是训练一个策略以最大化权重的奖励和教师学习目标。然而，在过去，无法使用原则性的方法均衡这两个目标，而是使用规则和问题特有的超参数搜索来均衡。我们提出了一种原则性的方法，以及一种近似的实现方式，可以在运动时动态地和自动地调整在学习从教师和奖励中选择何时遵循教师的指导。我们的方法被称为“教师导向奖励学习”（TGRL），在多个领域中击败了强大的基准值，无需hyperparameter调整。
</details></li>
</ul>
<hr>
<h2 id="Quantification-of-Uncertainty-with-Adversarial-Models"><a href="#Quantification-of-Uncertainty-with-Adversarial-Models" class="headerlink" title="Quantification of Uncertainty with Adversarial Models"></a>Quantification of Uncertainty with Adversarial Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03217">http://arxiv.org/abs/2307.03217</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ml-jku/quam">https://github.com/ml-jku/quam</a></li>
<li>paper_authors: Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Günter Klambauer, Sepp Hochreiter</li>
<li>for: 这篇论文的目的是提出一种新的不确定量化方法，以便在实际应用中做出可靠的预测。</li>
<li>methods: 这篇论文使用了rival models的对抗方法（QUAM）来估计epistemic uncertainty，这种方法可以更好地估计这种不确定性，并且比前一些方法（如深度组合或MC dropout）更加精确。</li>
<li>results: 实验显示，QUAM方法可以优化深度学习模型中的不确定量化，并且在类型识别、物体检测和其他视觉任务中表现出色，比前一些方法更好。<details>
<summary>Abstract</summary>
Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of a reference model. Our experiments show that QUAM excels in capturing epistemic uncertainty for deep learning models and outperforms previous methods on challenging tasks in the vision domain.
</details>
<details>
<summary>摘要</summary>
量化未知是重要的 predictive uncertainty quantification 中的一部分。 epistemic uncertainty 的定义为积分函数和 posterior 的产品。现有的方法，如 Deep Ensembles 或 MC dropout，在估计 epistemic uncertainty 方面表现不佳，因为它们主要依靠 posterior 的样本。我们建议 Quantification of Uncertainty with Adversarial Models (QUAM)，可以更好地估计 epistemic uncertainty。QUAM 可以在积分函数下找到整体积分值大的区域，不仅是 posterior。因此，QUAM 的 Approximation error 相对于之前的方法更低。模型具有高积分值的区域对应于 adversarial models（不是 adversarial examples！）。 adversarial models 具有高 posterior 和 reference model 的预测值之间的差异。我们的实验表明，QUAM 在 deep learning 模型中表现出色，与之前的方法在视觉领域中的 challenging tasks 上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Learning-Curves-for-Heterogeneous-Feature-Subsampled-Ridge-Ensembles"><a href="#Learning-Curves-for-Heterogeneous-Feature-Subsampled-Ridge-Ensembles" class="headerlink" title="Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles"></a>Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03176">http://arxiv.org/abs/2307.03176</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/benruben87/Learning-Curves-for-Heterogeneous-Feature-Subsampled-Ridge-Ensembles">https://github.com/benruben87/Learning-Curves-for-Heterogeneous-Feature-Subsampled-Ridge-Ensembles</a></li>
<li>paper_authors: Benjamin S. Ruben, Cengiz Pehlevan</li>
<li>for: 降低预测差异的方法，使用Random Subspace Method和Feature Bagging方法。</li>
<li>methods: 使用ridge regression在子集中适应特征，并使用statistical physics的replica trick来 derivate学习曲线。</li>
<li>results: 在线性回归设置下，通过调整子集大小和特征数量，实现更好的预测性能，并发现在参数空间中存在锐transition。<details>
<summary>Abstract</summary>
Feature bagging is a well-established ensembling method which aims to reduce prediction variance by training estimators in an ensemble on random subsamples or projections of features. Typically, ensembles are chosen to be homogeneous, in the sense the the number of feature dimensions available to an estimator is uniform across the ensemble. Here, we introduce heterogeneous feature ensembling, with estimators built on varying number of feature dimensions, and consider its performance in a linear regression setting. We study an ensemble of linear predictors, each fit using ridge regression on a subset of the available features. We allow the number of features included in these subsets to vary. Using the replica trick from statistical physics, we derive learning curves for ridge ensembles with deterministic linear masks. We obtain explicit expressions for the learning curves in the case of equicorrelated data with an isotropic feature noise. Using the derived expressions, we investigate the effect of subsampling and ensembling, finding sharp transitions in the optimal ensembling strategy in the parameter space of noise level, data correlations, and data-task alignment. Finally, we suggest variable-dimension feature bagging as a strategy to mitigate double descent for robust machine learning in practice.
</details>
<details>
<summary>摘要</summary>
feature bagging 是一种已经广泛应用的 ensemble 方法，旨在降低预测变分的方法，通过在随机子样本或投影中训练 estimator  ensemble。通常，ensemble 被选择为Homogeneous，即每个 estimator 在 ensemble 中 disposal 的 feature 维度是固定的。在这文中，我们介绍了Heterogeneous feature ensembling，其中 estimator 建立在不同的 feature 维度上，并考虑其在线性回归设置下的性能。我们研究了一个 ensemble 的线性预测器，每个预测器使用ridge regression在一 subset 中的可用 feature 上进行训练。我们允许这些subset 中包含的 feature 的数量发生变化。使用统计物理中的replica trick，我们得到了ridge ensemble 的学习曲线，其中包括 equicorrelated 数据和各向异otropic 特征噪音。使用 derivations 中的表达，我们调查了 subsampling 和 ensembling 对 optimal 结果的影响，并发现了参数空间中的锐转点。最后，我们建议 variable-dimension feature bagging 作为一种 mitigate double descent 的实践策略。
</details></li>
</ul>
<hr>
<h2 id="Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It"><a href="#Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It" class="headerlink" title="Push Past Green: Learning to Look Behind Plant Foliage by Moving It"></a>Push Past Green: Learning to Look Behind Plant Foliage by Moving It</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03175">http://arxiv.org/abs/2307.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Zhang, Saurabh Gupta</li>
<li>for: 这个论文的目的是解决自动化农业应用（如检查、fenotiping、摘取水果）中对植物叶子和枝条的操作带来的挑战。</li>
<li>methods: 这篇论文使用数据驱动方法来解决这些挑战。它使用自我超级视觉网络SRPNet来预测执行一个候选动作后植物上的空间可见性。</li>
<li>results: 实验表明SRPNet在5个设定下对一种 sintetic (蔷薇) 和一种真实植物 ( Draceana) 的物理测试床上表现出色，超过了一种竞争性手工探索方法。 SRPNet也在对手工动力模型和相关减少中表现出色。<details>
<summary>Abstract</summary>
Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations. Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations.
</details>
<details>
<summary>摘要</summary>
自主农业应用（如检查、辐射类型、摘取水果）需要对植物叶子和枝干进行检查和操作。由于植物的部分可见性、极度堆积、细小结构和不确定的植物geometry和动力学，这种操作具有挑战性。我们通过数据驱动方法解决这些挑战。我们使用自我监督训练SRPNet，一种神经网络，该网络预测执行给定植物的候选动作后所可见的空间。我们使用SRPNet与十字积分方法预测有效的执行动作，以便逐渐暴露植物下方的空间。我们在Synthetic（蔷薇）和实际植物（Dracean）上进行了物理测试，并在5个设定中进行了测试，其中2个设定检验了植物配置的普适性。我们的实验表明我们的总方法PPG在比手动探索方法更有效，而SRPNet在手动动力模型和相关减少中表现更有效。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Quantum-Monte-Carlo-A-Novel-Approach-for-Solving-the-Quantum-Many-Body-Schrodinger-Equation"><a href="#Wasserstein-Quantum-Monte-Carlo-A-Novel-Approach-for-Solving-the-Quantum-Many-Body-Schrodinger-Equation" class="headerlink" title="Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schrödinger Equation"></a>Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schrödinger Equation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07050">http://arxiv.org/abs/2307.07050</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/necludov/wqmc">https://github.com/necludov/wqmc</a></li>
<li>paper_authors: Kirill Neklyudov, Jannes Nys, Luca Thiede, Juan Carrasquilla, Qiang Liu, Max Welling, Alireza Makhzani</li>
<li>for:  solves the quantum many-body Schrödinger equation, a fundamental problem in quantum physics, chemistry, and materials science.</li>
<li>methods:  uses deep learning methods to represent wave functions as neural networks, and reformulates energy functional minimization in the space of Born distributions.</li>
<li>results:  demonstrates faster convergence to the ground state of molecular systems using the proposed “Wasserstein Quantum Monte Carlo” (WQMC) method.Here’s the full text in Simplified Chinese:</li>
<li>for:  solves the quantum many-body Schrödinger equation, a fundamental problem in quantum physics, chemistry, and materials science.</li>
<li>methods:  uses deep learning methods to represent wave functions as neural networks, and reformulates energy functional minimization in the space of Born distributions.</li>
<li>results:  demonstrates faster convergence to the ground state of molecular systems using the proposed “Wasserstein Quantum Monte Carlo” (WQMC) method.<details>
<summary>Abstract</summary>
Solving the quantum many-body Schr\"odinger equation is a fundamental and challenging problem in the fields of quantum physics, quantum chemistry, and material sciences. One of the common computational approaches to this problem is Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are obtained by minimizing the energy of the system within a restricted family of parameterized wave functions. Deep learning methods partially address the limitations of traditional QVMC by representing a rich family of wave functions in terms of neural networks. However, the optimization objective in QVMC remains notoriously hard to minimize and requires second-order optimization methods such as natural gradient. In this paper, we first reformulate energy functional minimization in the space of Born distributions corresponding to particle-permutation (anti-)symmetric wave functions, rather than the space of wave functions. We then interpret QVMC as the Fisher-Rao gradient flow in this distributional space, followed by a projection step onto the variational manifold. This perspective provides us with a principled framework to derive new QMC algorithms, by endowing the distributional space with better metrics, and following the projected gradient flow induced by those metrics. More specifically, we propose "Wasserstein Quantum Monte Carlo" (WQMC), which uses the gradient flow induced by the Wasserstein metric, rather than Fisher-Rao metric, and corresponds to transporting the probability mass, rather than teleporting it. We demonstrate empirically that the dynamics of WQMC results in faster convergence to the ground state of molecular systems.
</details>
<details>
<summary>摘要</summary>
解决量子多体Шрёдингер方程是物理学、化学和材料科学领域的基本和挑战性问题。一种常见的计算方法是量子变量 Monte Carlo（QVMC），在这种方法中，系统的基态解是通过在限定的参数化波函数内寻找能量最小值来获得。深度学习方法可以部分解决传统QVMC中的限制，因为它可以表示一个富有的波函数家族使用神经网络。然而，QVMC中的优化目标仍然具有困难度，需要使用次序优化方法，如自然梯度。在这篇论文中，我们首先将能量函数最小化转换为 Born 分布对应的 particle-permutation（反）对称波函数的空间中进行，然后将 QVMC 解释为 Born 分布空间中的 Fisher-Rao 梯度流。接着，我们在这个分布空间中尝试新的 QMC 算法，通过给分布空间添加更好的 метри，并跟踪这些 метри 导引的投影流。更具体来说，我们提出了 "Wasserstein Quantum Monte Carlo"（WQMC），它使用梯度流导引的 Wasserstein  metric，而不是 Fisher-Rao  metric，并与teleporting 不同。我们通过实验证明，WQMC 的动力学会更快地 converges 到分子系统的基态解。
</details></li>
</ul>
<hr>
<h2 id="Focused-Transformer-Contrastive-Training-for-Context-Scaling"><a href="#Focused-Transformer-Contrastive-Training-for-Context-Scaling" class="headerlink" title="Focused Transformer: Contrastive Training for Context Scaling"></a>Focused Transformer: Contrastive Training for Context Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03170">http://arxiv.org/abs/2307.03170</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cstankonrad/long_llama">https://github.com/cstankonrad/long_llama</a></li>
<li>paper_authors: Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, Piotr Miłoś</li>
<li>for: 提高大型语言模型在上下文长度方面的潜在能力</li>
<li>methods: 通过访问外部内存，让注意层访问更多的文档，并采用对比学习的训练方法解决焦点问题</li>
<li>results: 实现了在长上下文下进行精准的启发式学习，并且可以细化大型模型的上下文长度，提高模型的性能<details>
<summary>Abstract</summary>
Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context. This is demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context. We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有Exceptional的能力 Contextual 地搜集新信息。然而，这种方法的潜力 Frequently 受限因为Context Length的限制。一种解决方案是赋予Attention层访问 External Memory，其包含（键、值）对。然而，随着文档数量的增加，相关键对应的权重比例逐渐减少，导致模型更多地关注无关键。我们描述了一个Significant Challenge，称之为distraction issue，其中键 Linked to Different Semantic Values 可能会 overlap，使其困难分辨。为解决这个问题，我们引入了Focused Transformer（FoT），一种基于对比学习的训练方法。这种新的approach 使（键、值）空间的结构更加稠密，使Context Length可以更长。我们的方法允许对Pre-existing, Large-scale模型进行细化，从而Lengthen its Effective Context。我们的 Fine-tuning  $3B$ 和 $7B$ OpenLLaMA Checkpoint 的结果，我们命名为LongLLaMA，在需要Long Context的任务中展现出了进步。我们还证明了我们的 LongLLaMA 模型可以efficaciously manage $256k$ Context Length for Passkey Retrieval。
</details></li>
</ul>
<hr>
<h2 id="Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification"><a href="#Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification" class="headerlink" title="Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?"></a>Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03157">http://arxiv.org/abs/2307.03157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janet Wang, Yunbei Zhang, Zhengming Ding, Jihun Hamm</li>
<li>for: 本研究旨在 investigate unsupervised domain adaptation (UDA) 方法在皮肤癌症分类 tasks 中的可行性，以提高精度和可靠性。</li>
<li>methods: 本研究使用了多个皮肤癌症数据集，并 investigate 不同的 UDA 训练方案，包括单源、合并源和多源。</li>
<li>results: 研究结果显示，UDA 在 binary 分类任务中效果显著，并且在减轻偏置问题时进一步提高了性能。在多类任务中，UDA 的表现较弱，需要处理偏置问题以达到上baseline的准确率。通过我们的量化分析，我们发现测试错误率与标签转移强相关，而特征级 UDA 方法在不平衡数据集上有限制。最后，我们的研究表明，UDA 可以有效地减少对少数群体的偏见，且不需要显式使用公平预处理技术。<details>
<summary>Abstract</summary>
Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant. However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system. In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification. In particular, we assess three UDA training schemes: single-, combined-, and multi-source. Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated. In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy. Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets. Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques.
</details>
<details>
<summary>摘要</summary>
深度学习基于的诊断系统在有 suficient 标注示例时已经表现出了抑分类皮肤癌的潜力。然而，皮肤肿瘤分析通常受到标注数据的不足的限制，这阻碍了建立准确可靠的诊断系统。在这个工作中，我们利用多个皮肤肿瘤数据集，并 investigate了不同的无监督领域适应（UDA）方法在binary和多类皮肤肿瘤分类中的可行性。特别是，我们评估了单源、合并源和多源的UDA训练方案。我们的实验结果表明，UDA在binary分类任务中是有效的，并且在减轻偏见时进一步提高了表现。在多类任务中，其表现较弱，需要解决偏见问题以达到上基线的准确率。我们的量化分析表明，测试错误的多类任务和标签转移之间存在强相关性，而feature层UDA方法在不均衡数据集上有限制。最后，我们的研究表明，UDA可以有效地减少对少数群体的偏见，无需显式使用关注公平性的技术。
</details></li>
</ul>
<hr>
<h2 id="Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images"><a href="#Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images" class="headerlink" title="Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images"></a>Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03137">http://arxiv.org/abs/2307.03137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seher Ozcelik, Sinan Unver, Ilke Ali Gurses, Rustu Turkay, Cigdem Gunduz-Demir</li>
<li>for: 提高图像分割 tasks 中的性能，特别是在人体 анатоMY 中 vessels 的分割任务上。</li>
<li>methods: 提出了一种新的 topology-aware 损失函数，通过 persistent homology 来衡量网络预测和真实值之间的拓扑不同。</li>
<li>results: 对于 4327 个 CT 图像和 24 个主体的实验表明，提出的损失函数可以更好地提高图像分割的性能， indicating the effectiveness of this approach.<details>
<summary>Abstract</summary>
Segmentation networks are not explicitly imposed to learn global invariants of an image, such as the shape of an object and the geometry between multiple objects, when they are trained with a standard loss function. On the other hand, incorporating such invariants into network training may help improve performance for various segmentation tasks when they are the intrinsic characteristics of the objects to be segmented. One example is segmentation of aorta and great vessels in computed tomography (CT) images where vessels are found in a particular geometry in the body due to the human anatomy and they mostly seem as round objects on a 2D CT image. This paper addresses this issue by introducing a new topology-aware loss function that penalizes topology dissimilarities between the ground truth and prediction through persistent homology. Different from the previously suggested segmentation network designs, which apply the threshold filtration on a likelihood function of the prediction map and the Betti numbers of the ground truth, this paper proposes to apply the Vietoris-Rips filtration to obtain persistence diagrams of both ground truth and prediction maps and calculate the dissimilarity with the Wasserstein distance between the corresponding persistence diagrams. The use of this filtration has advantage of modeling shape and geometry at the same time, which may not happen when the threshold filtration is applied. Our experiments on 4327 CT images of 24 subjects reveal that the proposed topology-aware loss function leads to better results than its counterparts, indicating the effectiveness of this use.
</details>
<details>
<summary>摘要</summary>
对于批处理图像中的分割任务，传统的损失函数不会直接学习图像中的全局不变量，如物体形状和多个物体之间的几何关系。然而，在某些任务中，这些不变量是物体的内在特征，通过将它们包含在网络训练中可能会提高分割性能。例如，计算机 Tomatoes（CT）图像中的血管和大血管分割任务中，血管在人体 анаatomy 中的特定几何位置，通常在2D CT 图像上看到为圆形物体。本文通过引入一种新的 topology-aware 损失函数来解决这个问题，该损失函数通过 persist homology  penalty  topology 不同性 zwischen 真实值和预测值。与之前的 segmentation 网络设计不同，这里不是通过阈值滤波器应用 likelihood 函数和 Betti 数来实现，而是通过 Vietoris-Rips 滤波器来获得预测和真实值的 persistence 图，并计算它们之间的 Wasserstein 距离。这种方法的优点在于同时模型形状和几何，可能不会在使用阈值滤波器时发生。我们在 4327 个 CT 图像上进行了 24 个人的实验，发现提案的 topology-aware 损失函数可以更好地处理这些任务，表明其效果。
</details></li>
</ul>
<hr>
<h2 id="Multiplicative-Updates-for-Online-Convex-Optimization-over-Symmetric-Cones"><a href="#Multiplicative-Updates-for-Online-Convex-Optimization-over-Symmetric-Cones" class="headerlink" title="Multiplicative Updates for Online Convex Optimization over Symmetric Cones"></a>Multiplicative Updates for Online Convex Optimization over Symmetric Cones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03136">http://arxiv.org/abs/2307.03136</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/waynelin74/OCO_SymmetricCones">https://github.com/waynelin74/OCO_SymmetricCones</a></li>
<li>paper_authors: Ilayda Canyakmaz, Wayne Lin, Georgios Piliouras, Antonios Varvitsiotis</li>
<li>For: 该 paper 研究在线凸优化中，可能的动作是 trace-one 元素在 симметричный cone 中的扩展，涵盖了广泛研究的专家设置和其量子对应体。* Methods: 该 paper 使用了 Euclidean Jordan Algebras 的工具，提出了无投影的 Symmetric-Cone Multiplicative Weights Update (SCMWU) 算法，用于在 trace-one slice 上进行在线优化。* Results: 该 paper 证明了 SCMWU 算法是一个无误算法，并且扩展了 Multiplicative Weights Update 方法的分析，包括probability simplex 和 density matrices 的扩展。<details>
<summary>Abstract</summary>
We study online convex optimization where the possible actions are trace-one elements in a symmetric cone, generalizing the extensively-studied experts setup and its quantum counterpart. Symmetric cones provide a unifying framework for some of the most important optimization models, including linear, second-order cone, and semidefinite optimization. Using tools from the field of Euclidean Jordan Algebras, we introduce the Symmetric-Cone Multiplicative Weights Update (SCMWU), a projection-free algorithm for online optimization over the trace-one slice of an arbitrary symmetric cone. We show that SCMWU is equivalent to Follow-the-Regularized-Leader and Online Mirror Descent with symmetric-cone negative entropy as regularizer. Using this structural result we show that SCMWU is a no-regret algorithm, and verify our theoretical results with extensive experiments. Our results unify and generalize the analysis for the Multiplicative Weights Update method over the probability simplex and the Matrix Multiplicative Weights Update method over the set of density matrices.
</details>
<details>
<summary>摘要</summary>
我们研究在线凸优化问题，其可能的动作是 traces-one 元素在一个对称体中，泛化了广泛研究的专家设定和其量子对应器。对称体提供一个统一的框架，包括线性、第二阶凸优化和半definite 优化问题。使用 Euclid  Jordan 代数的工具，我们引入了 trace-one slice 的Symmetric-Cone 多重量更新（SCMWU）算法，不需要投影。我们证明 SCMWU 等价于 Follow-the-Regularized-Leader 和 Online Mirror Descent 的对称体负 entropy 作为规则。使用这种结构结果，我们证明 SCMWU 是一个不会追攻的算法，并通过广泛的实验来验证我们的理论结果。我们的结果将 Multiplicative Weights Update 方法在概率 Simplex 和 Matrix Multiplicative Weights Update 方法在密度矩阵上的分析统一和推广。
</details></li>
</ul>
<hr>
<h2 id="Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability"><a href="#Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability" class="headerlink" title="Distilling Large Vision-Language Model with Out-of-Distribution Generalizability"></a>Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03135">http://arxiv.org/abs/2307.03135</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuanlinli17/large_vlm_distillation_ood">https://github.com/xuanlinli17/large_vlm_distillation_ood</a></li>
<li>paper_authors: Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su</li>
<li>For:	+ The paper aims to investigate the distillation of visual representations in large teacher vision-language models into lightweight student models, with a focus on open-vocabulary out-of-distribution (OOD) generalization.* Methods:	+ The proposed method uses two principles from vision and language modality perspectives to enhance student’s OOD generalization: (1) by better imitating teacher’s visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher’s language representations with informative and finegrained semantic attributes to effectively distinguish between different labels.* Results:	+ The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of the proposed approaches.<details>
<summary>Abstract</summary>
Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Code released at https://github.com/xuanlinli17/large_vlm_distillation_ood
</details>
<details>
<summary>摘要</summary>
大型视言语模型已经实现了出色的表现，但它们的大小和计算需求使其在有限的设备和时间上不可靠性不允许其部署。模型缩小，将大型模型转换成更小的更快的模型，以保持大型模型的表现，是一个有前途的方向。这篇论文 investigate teacher视言语模型中的视 representations的缩小，使用小规模或中规模的 dataset。特别是，这种研究强调了无法表示（OOD）泛化问题，在前一个model distillation文献中受到了忽略。我们提出了两个原则，从视觉和语言模式的角度来提高学生的OOD泛化表现：（1）更好地模仿教师的视觉表示空间，并且细致地协调视语对应关系;（2）使用有用和细致的语言特征来有效地分类不同的标签。我们提出了一些指标，并进行了广泛的实验来调查它们的技术。结果表明，我们的提出的方法在零shot和几shot学生表现中具有显著的改进，强调了我们的提出的方法的效iveness。代码可以在https://github.com/xuanlinli17/large_vlm_distillation_ood中下载。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification"><a href="#Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification" class="headerlink" title="Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification"></a>Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03133">http://arxiv.org/abs/2307.03133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuyongcan/benchmark-tta">https://github.com/yuyongcan/benchmark-tta</a></li>
<li>paper_authors: Yongcan Yu, Lijun Sheng, Ran He, Jian Liang</li>
<li>for:  This paper aims to provide a benchmark for test-time adaptation (TTA) methods to enhance the generalization performance of models and improve their robustness against distribution shifts.</li>
<li>methods: The paper evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets, including CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods cover a range of adaptation scenarios, such as online adaptation vs. offline adaptation, instance adaptation vs. batch adaptation vs. domain adaptation.</li>
<li>results: The paper presents a unified framework in PyTorch to evaluate and compare the effectiveness of TTA methods across different datasets and network architectures. By establishing this benchmark, the authors aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance.<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.
</details>
<details>
<summary>摘要</summary>
Test-time adaptation (TTA) 是一种技术，目的是通过在预测时使用无标示样本来提高模型的总体性能。由于神经网络系统面临到分布shift时的稳定性问题，现在有许多TTA方法被提出。然而，评估这些方法的效果通常是在不同的设置下进行，例如不同的分布shift、背景和设计方案，导致了评估这些方法的标准化和公平的标准准比不够。为解决这个问题，我们提出了一个benchmark，可以系统地评估13种知名的TTA方法和其变种在五种常用的图像分类 datasets上：CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home。这些方法涵盖了各种适应enario（例如在线适应与离线适应、实例适应与批适应、领域适应）。此外，我们还探索了不同的TTA方法与不同的网络背景的兼容性。为实现这个benchmark，我们在PyTorch上开发了一套统一的框架，可以在不同的 datasets和网络架构上进行一致的评估和比较TTA方法的效果。通过设立这个benchmark，我们希望为研究者和实践者提供一个可靠的方式来评估和比较TTA方法在提高模型的Robustness和总体性能方面的效果。我们的代码可以在https://github.com/yuyongcan/Benchmark-TTA上获取。
</details></li>
</ul>
<hr>
<h2 id="T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning"><a href="#T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning" class="headerlink" title="T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"></a>T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03132">http://arxiv.org/abs/2307.03132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/locuslab/t-mars">https://github.com/locuslab/t-mars</a></li>
<li>paper_authors: Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan</li>
<li>for: 提高计算机视觉领域的状态提取大量网络源数据的优化，以提高零或几shot认识的性能。</li>
<li>methods: 提出一种新的数据筛选方法，基于我们发现LAION dataset中40%的图片含有与标签重叠的文本，这些数据可能会使模型做到光学字符识别而不是学习视觉特征。我们的方法使用文本屏蔽和CLIP相似度分数来筛选图片，从而过滤出只含有重叠文本的图片。</li>
<li>results: 在DataComp数据筛选benchmark中，T-MARS方法在”中等规模”下的性能比顶尖方法提高6.5%在ImageNet和4.7%在VTAB。此外，我们在不同的数据池大小从2M到64M进行系统性的评估，发现T-MARS方法的准确率提升与数据和计算的扩展幂。代码可以在<a target="_blank" rel="noopener" href="https://github.com/locuslab/T-MARS%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/locuslab/T-MARS中下载。</a><details>
<summary>Abstract</summary>
Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the "medium scale" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. Code is available at https://github.com/locuslab/T-MARS.
</details>
<details>
<summary>摘要</summary>
大量网络收集的多模式数据已经推动了新的计算机视觉表示学习方法的发展，对计算机视觉领域进行了革命性的改进。实际操作者面临的一个关键决策是如何处理这些日益增大的数据集。例如，LAION-5B数据集的创建者选择了只保留图像和描述对应的CLIP相似度score超过设置的阈值。在这篇论文中，我们提出了一种新的数据筛选方法，它是基于我们观察到LAION中约40%的图像含有与描述重叠的文本的观察。这些数据可能是浪费的，因为它们可能会让模型做Optical Character Recognition而不是学习视觉特征。然而， Naively removing all such data could also be wasteful, as it would throw away images that contain visual features (in addition to overlapping text).我们的简单和可扩展方法T-MARS（文本覆盖和重新分配）会过滤掉那些文本占据图像的大部分视觉特征的对应。我们首先对图像中的文本进行覆盖，然后对CLIP相似度score的覆盖图像进行过滤。实验表明，T-MARS在DataComp中的"中等规模"上比顶尖方法表现出6.5%的提升，在ImageNet和VTAB上分别提升4.7%和6.5%。此外，我们对不同的数据池大小从2M到64M进行系统性的评估，发现T-MARS的准确率提升 linearly 随着数据和计算的扩展幂数。代码可以在https://github.com/locuslab/T-MARS上获取。
</details></li>
</ul>
<hr>
<h2 id="Principal-subbundles-for-dimension-reduction"><a href="#Principal-subbundles-for-dimension-reduction" class="headerlink" title="Principal subbundles for dimension reduction"></a>Principal subbundles for dimension reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03128">http://arxiv.org/abs/2307.03128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morten Akhøj, James Benn, Erlend Grong, Stefan Sommer, Xavier Pennec</li>
<li>for: 该 paper 用 sub-Riemannian geometry 进行拟合 manifold 和 surface reconstruction，并将本地线性近似转换为 lower dimensional bundle。</li>
<li>methods: 使用 local PCA 获取 local approximations，并将其集成到 rank $k$ tangent subbundle 中，$k&lt;d$。这个 sub-Riemannian metric 可以应用于一些重要的问题，如：建立 approximating submanifold $M$，构建点云在 $\mathbb{R}^k$ 中的表示，计算 observations 之间的距离，并考虑 learned geometry。</li>
<li>results: 通过 simulations 表明，该框架在噪声数据上是稳定的，并且可以扩展到知道 Riemannian manifold 的情况。<details>
<summary>Abstract</summary>
In this paper we demonstrate how sub-Riemannian geometry can be used for manifold learning and surface reconstruction by combining local linear approximations of a point cloud to obtain lower dimensional bundles. Local approximations obtained by local PCAs are collected into a rank $k$ tangent subbundle on $\mathbb{R}^d$, $k<d$, which we call a principal subbundle. This determines a sub-Riemannian metric on $\mathbb{R}^d$. We show that sub-Riemannian geodesics with respect to this metric can successfully be applied to a number of important problems, such as: explicit construction of an approximating submanifold $M$, construction of a representation of the point-cloud in $\mathbb{R}^k$, and computation of distances between observations, taking the learned geometry into account. The reconstruction is guaranteed to equal the true submanifold in the limit case where tangent spaces are estimated exactly. Via simulations, we show that the framework is robust when applied to noisy data. Furthermore, the framework generalizes to observations on an a priori known Riemannian manifold.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们示例了如何使用非里曼几何来进行拟合 manifold 和表面重建，通过将本地线性近似组合到一个更低维度的束上。本地近似由本地 PCA 获得，并将其集成为一个 rank $k$ 的 tangent 束在 $\mathbb{R}^d$ 上，其中 $k<d$。我们称之为主Bundle。这确定了一个 sub-Riemannian 度量在 $\mathbb{R}^d$ 上。我们示示了 sub-Riemannian 径在这个度量下可以成功应用于一些重要问题，如：生成一个近似 submanifold $M$，将点云表示在 $\mathbb{R}^k$ 上，以及根据学习的几何来计算观察之间的距离。重建是在 tangent 空间被估计为 preciselly 时保证等于真实的 submanifold。通过仿真，我们示示了该框架在噪声数据上是稳定的。此外，该框架可推广到已知 Riemannian 拟合 manifold 上的观察。
</details></li>
</ul>
<hr>
<h2 id="Context-Aware-Configuration-and-Management-of-WiFi-Direct-Groups-for-Real-Opportunistic-Networks"><a href="#Context-Aware-Configuration-and-Management-of-WiFi-Direct-Groups-for-Real-Opportunistic-Networks" class="headerlink" title="Context-Aware Configuration and Management of WiFi Direct Groups for Real Opportunistic Networks"></a>Context-Aware Configuration and Management of WiFi Direct Groups for Real Opportunistic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03126">http://arxiv.org/abs/2307.03126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valerio Arnaboldi, Mattia Giovanni Campana, Franca Delmastro</li>
<li>for: 该研究旨在提高 Wi-Fi Direct 技术在商业移动设备上的支持，以便实现基于设备间通信（D2D）的网络解决方案。</li>
<li>methods: 该研究提议一种新的中间层协议（WiFi Direct Group Manager，WFD-GM），以便自动配置和管理 Wi-Fi Direct 组。该协议包括一个 контекст函数，该函数考虑不同参数来创建最佳组配置，包括节点稳定性和功率水平。</li>
<li>results: 研究结果显示，WFD-GM 在不同的 mobilty 模型、地理区域和节点数量的三种参考enario中表现出色，与基准方法相比，在中等&#x2F;低 mobilty 情况下表现更好，在高 mobilty 情况下与基准方法相当，无论添加额外开销。<details>
<summary>Abstract</summary>
Wi-Fi Direct is a promising technology for the support of device-to-device communications (D2D) on commercial mobile devices. However, the standard as-it-is is not sufficient to support the real deployment of networking solutions entirely based on D2D such as opportunistic networks. In fact, WiFi Direct presents some characteristics that could limit the autonomous creation of D2D connections among users' personal devices. Specifically, the standard explicitly requires the user's authorization to establish a connection between two or more devices, and it provides a limited support for inter-group communication. In some cases, this might lead to the creation of isolated groups of nodes which cannot communicate among each other. In this paper, we propose a novel middleware-layer protocol for the efficient configuration and management of WiFi Direct groups (WiFi Direct Group Manager, WFD-GM) to enable autonomous connections and inter-group communication. This enables opportunistic networks in real conditions (e.g., variable mobility and network size). WFD-GM defines a context function that takes into account heterogeneous parameters for the creation of the best group configuration in a specific time window, including an index of nodes' stability and power levels. We evaluate the protocol performances by simulating three reference scenarios including different mobility models, geographical areas and number of nodes. Simulations are also supported by experimental results related to the evaluation in a real testbed of the involved context parameters. We compare WFD-GM with the state-of-the-art solutions and we show that it performs significantly better than a Baseline approach in scenarios with medium/low mobility, and it is comparable with it in case of high mobility, without introducing additional overhead.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance"><a href="#Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance" class="headerlink" title="Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance"></a>Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03119">http://arxiv.org/abs/2307.03119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, Tie-Yan Liu</li>
<li>for: 这 paper 的目的是解决多个订单同时执行的问题，使用模型自由学习（RL）技术。</li>
<li>methods: 这 paper 使用多代理RL（MARL）方法，每个代理都是一个特定的订单执行者，与其他代理交换信息以协同 Maximize 总收益。</li>
<li>results: 实验结果表明，使用提议的多round通信协议和行动值归因方法可以提高协同效果，并且在两个真实市场上达到了显著更好的性能。<details>
<summary>Abstract</summary>
Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market. To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly. It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient. The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：订单执行是金融计算机科学中的基本任务，旨在完成购买或卖出一些资产的交易订单。现代无模型学习（RL）技术提供了基于数据的订单执行解决方案。然而，现有的工作都是优化每个订单的执行，忽略了实际情况下多个订单同时执行的情况，导致不优化和偏见。在本文中，我们首先提出了多代理RL（MARL）方法，用于多订单执行，考虑实际约束。 Specifically，我们将每个代理视为一个特定订单的交易者，保持与彼此交流，以 maximize 总收益。然而，现有的 MARL 算法通常通过互相交换部分观察信息来进行交流，这在金融市场中是不fficient的。为了改善协作，我们则提出了学习型多轮通信协议，让代理通过交换意图动作来交流，并根据此进行修正。这种协议由一种新的动作值归属方法优化，该方法与原始学习目标一致， yet more efficient。实验结果表明，我们的方法在两个真实的市场数据上表现出色，与传统方法相比，具有显著更好的协作效果。
</details></li>
</ul>
<hr>
<h2 id="Steel-Surface-Roughness-Parameter-Calculations-Using-Lasers-and-Machine-Learning-Models"><a href="#Steel-Surface-Roughness-Parameter-Calculations-Using-Lasers-and-Machine-Learning-Models" class="headerlink" title="Steel Surface Roughness Parameter Calculations Using Lasers and Machine Learning Models"></a>Steel Surface Roughness Parameter Calculations Using Lasers and Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03723">http://arxiv.org/abs/2307.03723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Milne, Xianghua Xie</li>
<li>for: 这个论文主要是为了提高热压板钢制造过程中表面质量的控制。</li>
<li>methods: 这篇论文使用了现代机器学习模型来提高在生产过程中的在线测量结果的准确性，以提高表面质量控制。</li>
<li>results: 研究表明，使用数据驱动的方法可以提高表面质量控制，并且可以实现在生产过程中的实时调整。<details>
<summary>Abstract</summary>
Control of surface texture in strip steel is essential to meet customer requirements during galvanizing and temper rolling processes. Traditional methods rely on post-production stylus measurements, while on-line techniques offer non-contact and real-time measurements of the entire strip. However, ensuring accurate measurement is imperative for their effective utilization in the manufacturing pipeline. Moreover, accurate on-line measurements enable real-time adjustments of manufacturing processing parameters during production, ensuring consistent quality and the possibility of closed-loop control of the temper mill. In this study, we leverage state-of-the-art machine learning models to enhance the transformation of on-line measurements into significantly a more accurate Ra surface roughness metric. By comparing a selection of data-driven approaches, including both deep learning and non-deep learning methods, to the close-form transformation, we evaluate their potential for improving surface texture control in temper strip steel manufacturing.
</details>
<details>
<summary>摘要</summary>
控制表面质量在带钢制造中是非常重要，以满足锈钢和氧化钢的需求。传统方法依靠后期探针测量，而在线技术可以实现不接触的实时测量整个带。然而，确保准确测量是关键，以便在生产过程中实现实时调整制造过程参数，保证产品质量的一致性和闭环控制温钢厂。本研究利用当前最佳的机器学习模型，以提高在线测量转换为更准确的Ra表面粗糙度指标。通过比较数据驱动方法，包括深度学习和非深度学习方法，与关系式转换，我们评估其在表面 тексту라控制方面的潜在提高。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Solutions-to-the-Privacy-vs-Utility-Tradeoff"><a href="#Quantum-Solutions-to-the-Privacy-vs-Utility-Tradeoff" class="headerlink" title="Quantum Solutions to the Privacy vs. Utility Tradeoff"></a>Quantum Solutions to the Privacy vs. Utility Tradeoff</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03118">http://arxiv.org/abs/2307.03118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sagnik Chatterjee, Vyacheslav Kungurtsev</li>
<li>for: 保障生成模型中的数据隐私和安全性</li>
<li>methods: 使用量子密码学 primitives 和可证明的隐私和安全性保证</li>
<li>results: 提供了一种基于量子密码学 primitives 的新架构，可以在任何现有的类型或量子生成模型之上使用，并且具有具有很高的安全性和隐私性保证。<details>
<summary>Abstract</summary>
In this work, we propose a novel architecture (and several variants thereof) based on quantum cryptographic primitives with provable privacy and security guarantees regarding membership inference attacks on generative models. Our architecture can be used on top of any existing classical or quantum generative models. We argue that the use of quantum gates associated with unitary operators provides inherent advantages compared to standard Differential Privacy based techniques for establishing guaranteed security from all polynomial-time adversaries.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的架构（以及其变体），基于量子密码学 primitives，具有可证明的隐私和安全保证，对于生成模型的会员推测攻击。我们的架构可以在现有的类别或量子生成模型之上使用。我们认为，使用量子门相关的单位操作器提供了内置的优势，比标准推Diff Privacy基本技术更能提供来自所有多项时间敌对者的保证的安全性。
</details></li>
</ul>
<hr>
<h2 id="Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings"><a href="#Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings" class="headerlink" title="Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings"></a>Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03212">http://arxiv.org/abs/2307.03212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiliang Chan, Qianqian Ren</li>
<li>for: 本研究旨在提出一种 Region-Wise Multi-View Representation Learning (ROMER) 模型，用于捕捉多视图关系并学习表达式的城市区域表示。</li>
<li>methods: 该模型首先捕捉多视图相关性从移动流 Patterns、POI semantics 和 Check-in dynamics 中，然后采用全球图注意力网络学习任意两个顶点之间的相似性。在这之后，我们提出了一种两个阶段融合模块，以全面考虑多视图特征并共享特征。</li>
<li>results: 对实际世界数据集进行了两个下游任务的实验，结果显示，我们的模型在比较 estado-of-the-art 方法时，提高了17%的性能。<details>
<summary>Abstract</summary>
Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\% improvement.
</details>
<details>
<summary>摘要</summary>
城市区域嵌入是一项重要但又具有极高挑战性的问题，主要因为城市数据的复杂性和不断变化。为 Addressing these challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) method to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighborhood region conditions. Our model focuses on learning urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics, and check-in dynamics. Then, we adopt global graph attention networks to learn the similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\% improvement.Here's the text with some additional information about the Simplified Chinese translation:The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. The text is written in a formal and academic style, using technical terms and phrases commonly used in the field of computer science and machine learning. The translation aims to convey the same meaning and information as the original English text, while also taking into account the grammatical and syntactical conventions of Simplified Chinese.Please note that the translation is provided for reference only, and may not be perfect or entirely accurate. If you have any specific questions or requests for clarification, please feel free to ask.
</details></li>
</ul>
<hr>
<h2 id="How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models"><a href="#How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models" class="headerlink" title="How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models"></a>How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03108">http://arxiv.org/abs/2307.03108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenting Wang, Chen Chen, Yuchen Liu, Lingjuan Lyu, Dimitris Metaxas, Shiqing Ma</li>
<li>for: 防止文本到图像扩散模型的非法数据使用</li>
<li>methods: 植入插入记忆法，通过分析模型是否记忆插入内容来检测非法数据使用</li>
<li>results: 实验表明，提议的方法可以准确检测文本到图像扩散模型中的非法数据使用<details>
<summary>Abstract</summary>
Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages.
</details>
<details>
<summary>摘要</summary>
近些时候，文本到图像扩散模型的表现有所惊喜，但也有一些问题被报告。例如，一个模型培训者可能会收集一组由某个艺术家创作的图像，然后尝试使用这些图像来训练一个可以生成类似图像的模型，而不是获得艺术家的授权。为解决这个问题，在训练过程中检测不当数据使用变得非常重要。在这篇论文中，我们提议一种方法来检测这种不当数据使用，即在文本到图像扩散模型中植入插入记忆。具体来说，我们修改了受保护的图像集，并添加了一些隐藏的图像包装函数，这些函数可以让模型在生成图像时进行隐藏的记忆。通过判断模型是否有记忆这些插入的内容（即是否通过选择的后处理函数处理生成的图像），我们可以检测模型是否使用了未经授权的数据。我们在Stable Diffusion和LoRA模型上进行了实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Intuition-a-Framework-for-Applying-GPs-to-Real-World-Data"><a href="#Beyond-Intuition-a-Framework-for-Applying-GPs-to-Real-World-Data" class="headerlink" title="Beyond Intuition, a Framework for Applying GPs to Real-World Data"></a>Beyond Intuition, a Framework for Applying GPs to Real-World Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03093">http://arxiv.org/abs/2307.03093</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kenzaxtazi/icml23-gpframe">https://github.com/kenzaxtazi/icml23-gpframe</a></li>
<li>paper_authors: Kenza Tazi, Jihao Andreas Lin, Ross Viljoen, Alex Gardner, ST John, Hong Ge, Richard E. Turner</li>
<li>for: 这篇论文是用于描述如何使用 Gaussian Processes (GPs) 进行回溯 regression 的方法和指南。</li>
<li>methods: 这篇论文使用的方法包括 kernel 设计和 computational scalability 的选择，以及如何设置一个强健且具体化的 GP 模型。</li>
<li>results: 在实际应用中，这篇论文使用 GPs 进行推测 glacier elevation change 的结果比较准确。<details>
<summary>Abstract</summary>
Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.
</details>
<details>
<summary>摘要</summary>
Note:* "Gaussian Processes" is translated as "Gaussian processes" in Simplified Chinese, which is the standard way to refer to this topic in Chinese.* "low-dimensional" is translated as "小型" (xiǎo yì) in Simplified Chinese, which means "small" or "low-dimensional" in English.* "kernel design" is translated as "kernel设计" (jīn yì jīng yì) in Simplified Chinese, which means "kernel design" in English.* "computational scalability" is translated as "计算可扩展性" (jì yì kě xiǎo yì) in Simplified Chinese, which means "computational scalability" in English.
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media"><a href="#A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media" class="headerlink" title="A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media"></a>A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.06775">http://arxiv.org/abs/2307.06775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Feldman</li>
<li>for: This study aimed to create a multimodal deep learning model to determine if social media posts promote eating disorders based on visual and textual data.</li>
<li>methods: The study used a labeled dataset of Tweets and trained and tested twelve deep learning models, including a multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model.</li>
<li>results: The RoBERTa and MaxViT fusion model achieved accuracy and F1 scores of 95.9% and 0.959, respectively, and was used to classify an unlabeled dataset of posts from Tumblr and Reddit. The model also uncovered a drastic decrease in the relative abundance of content that promotes eating disorders on eight Twitter hashtags since 2014, but with a resurgence by 2018.Here is the information in Simplified Chinese text:</li>
<li>for: 这个研究目的是创建一种基于多模态深度学习模型，以确定社交媒体文章是否推广吃见症，基于视觉和文本数据。</li>
<li>methods: 该研究使用了 Twitter 上的标注数据集，并训练和测试了十二个深度学习模型，其中包括 RoBERTa 自然语言处理模型和 MaxViT 图像分类模型的多模态融合。</li>
<li>results: RoBERTa 和 MaxViT 融合模型在识别 Tweets 中推广吃见症的任务上实现了准确率和 F1 分数为 95.9% 和 0.959，分别。此外，该模型还用于分类 Tumblr 和 Reddit 上的不标注数据集，并获得了类似于前一代研究所得到的结果，表明深度学习模型可以开发出与人类研究者相似的洞察。此外，模型还进行了 Twitter 上八个 Hashtag 的时间序分析，发现自2014年以来，内容推广吃见症的相对含量在这些社区内逐渐下降，但到2018年，内容推广吃见症又开始增加或停止下降。<details>
<summary>Abstract</summary>
Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. This study aimed to create a multimodal deep learning model that can determine if a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViT fusion model, deployed to classify an unlabeled dataset of posts from the social media sites Tumblr and Reddit, generated results akin to those of previous research studies that did not employ artificial intelligence-based techniques, indicating that deep learning models can develop insights congruent to those of researchers. Additionally, the model was used to conduct a timeseries analysis of yet unseen Tweets from eight Twitter hashtags, uncovering that, since 2014, the relative abundance of content that promotes eating disorders has decreased drastically within those communities. Despite this reduction, by 2018, content that promotes eating disorders had either stopped declining or increased in ampleness anew on these hashtags.
</details>
<details>
<summary>摘要</summary>
过去一代，食用疾病诊断和因食用疾病而导致的死亡人数有很大增长，特别是在covid-19大流行期间。这种巨大增长来自于流行病的压力以及社交媒体上的内容，后者在患食用疾病的人群中更加普遍。这项研究旨在创建一个多模态深度学习模型，可以根据文本和视频数据判断社交媒体文章是否推广食用疾病。在Twitter上收集了一个标注的Twitter文章集，并训练了12个深度学习模型。根据模型性能，最有效的深度学习模型是将RoBERTa自然语言处理模型和MaxViT图像分类模型 multimodal融合，它的准确率和F1分数分别为95.9%和0.959。这个模型在分析Twitter上的未标注文章时，能够生成与人工智能技术不使用的研究成果相似的结果， indicating that deep learning models can develop insights congruent to those of researchers。此外，该模型还用于对Twitter上的八个Hashtag进行时间序分析，发现自2014年以来，这些社群中的不健康食物内容的相对含量有很大减少。然而，到2018年，这些社群中的不健康食物内容的含量已经减少或增加了。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.LG_2023_07_07/" data-id="clogyj8yg00kg7cra4s0635rv" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/eess.IV_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T09:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/eess.IV_2023_07_07/">eess.IV - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery"><a href="#Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery" class="headerlink" title="Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery"></a>Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03662">http://arxiv.org/abs/2307.03662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/br0202/sensing_area_detection">https://github.com/br0202/sensing_area_detection</a></li>
<li>paper_authors: Baoru Huang, Yicheng Hu, Anh Nguyen, Stamatia Giannarou, Daniel S. Elson</li>
<li>for: This paper aims to improve the accuracy of endoscopic radio-guided cancer detection and resection by developing a novel method for detecting the sensing area of a tethered laparoscopic gamma detector.</li>
<li>methods: The proposed method uses a simple regression network to leverage high-dimensional image features and probe position information to visualize gamma activity origination on the tissue surface.</li>
<li>results: The authors demonstrated the effectiveness of their method through intensive experimentation using two publicly released datasets captured with a custom-designed, portable stereo laparoscope system, establishing a new performance benchmark.<details>
<summary>Abstract</summary>
In surgical oncology, it is challenging for surgeons to identify lymph nodes and completely resect cancer even with pre-operative imaging systems like PET and CT, because of the lack of reliable intraoperative visualization tools. Endoscopic radio-guided cancer detection and resection has recently been evaluated whereby a novel tethered laparoscopic gamma detector is used to localize a preoperatively injected radiotracer. This can both enhance the endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and it does not visibly indicate the activity origination on the tissue surface. Initial failed attempts used segmentation or geometric methods, but led to the discovery that it could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through intensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at https://github.com/br0202/Sensing_area_detection.git
</details>
<details>
<summary>摘要</summary>
在外科onkoloji中，外科医生很难以识别lymph node和完全remove癌症，即使使用前 operated imaging系统like PET和CT，因为缺乏可靠的手术过程中的视觉化工具。 Recently, endoscopic radio-guided cancer detection and resection has been evaluated, which uses a novel tethered laparoscopic gamma detector to localize a preoperatively injected radiotracer. This can both enhance endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and it does not visibly indicate the activity origination on the tissue surface. Early attempts used segmentation or geometric methods, but these were not successful. Instead, we found that the problem could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through extensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at <https://github.com/br0202/Sensing_area_detection.git>.
</details></li>
</ul>
<hr>
<h2 id="VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis"><a href="#VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis" class="headerlink" title="VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis"></a>VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03592">http://arxiv.org/abs/2307.03592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paula Feldman, Miguel Fainstein, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi</li>
<li>For: 该论文旨在提出一种数据驱动的生成框架，用于synthesizing blood vessel 3D geometry。* Methods: 该方法使用Recursive Variational Neural Network（RVNN），全面利用血管的层次结构，学习低维抽象空间，包括分支连接性和表面特征。* Results: 该方法可以生成高度相似的真实和 sintetic 数据，包括半径（.97）、长度（.95）和折叠度（.96）。通过深度神经网络的力量，该方法生成的3D血管模型具有高度准确和多样性，这对医疗和手术培训、血液动力学 simulations 等方面都非常重要。<details>
<summary>Abstract</summary>
We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we generate 3D models of blood vessels that are both accurate and diverse, which is crucial for medical and surgical training, hemodynamic simulations, and many other purposes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于数据的生成框架，用于 sintesizing 血管三维几何结构。这是一项具有挑战性的任务，因为血管系统的复杂性以及形态、大小和结构的多样性。现有的模型基于方法可以提供一定的控制和变化，但是它们无法捕捉实际 анатомиче数据的多样性。我们开发了 VesselVAE，一种嵌入式的变量神经网络，它完全利用血管的层次结构，并学习低维度拟合空间，包括连接分支和表面几何特征。经过训练，VesselVAE 的缓存空间可以采样生成新的血管几何结构。根据我们所知，这是第一次利用这种技术来 sintesizing 血管。我们实现了真实数据和 sintesizing 数据之间的相似性（.97）、长度（.95）和折叠性（.96）。通过利用深度神经网络的力量，我们生成了高度准确和多样的血管三维模型，这对医疗和手术培训、血液动力学计算以及许多其他目的都是关键。
</details></li>
</ul>
<hr>
<h2 id="Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis"><a href="#Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis" class="headerlink" title="Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis"></a>Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05519">http://arxiv.org/abs/2307.05519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyi Ji, Richard Salmon, Nita Mulliqi, Umair Khan, Yinxi Wang, Anders Blilie, Henrik Olsson, Bodil Ginnerup Pedersen, Karina Dalsgaard Sørensen, Benedicte Parm Ulhøi, Svein R Kjosavik, Emilius AM Janssen, Mattias Rantalainen, Lars Egevad, Pekka Ruusuvuori, Martin Eklund, Kimmo Kartasalo</li>
<li>for: 提高艾特ints家用于数字病理学的可靠性和应用性</li>
<li>methods: 使用物理颜色准确标准化扫描仪的扫描图像，以提高人工智能系统的评估性和可靠性</li>
<li>results: 实验结果表明，物理颜色准确标准化可以标准化扫描仪的扫描图像，提高艾特ints家的评估性和可靠性，使其在临床应用中更加可靠和可行<details>
<summary>Abstract</summary>
The potential of artificial intelligence (AI) in digital pathology is limited by technical inconsistencies in the production of whole slide images (WSIs), leading to degraded AI performance and posing a challenge for widespread clinical application as fine-tuning algorithms for each new site is impractical. Changes in the imaging workflow can also lead to compromised diagnoses and patient safety risks. We evaluated whether physical color calibration of scanners can standardize WSI appearance and enable robust AI performance. We employed a color calibration slide in four different laboratories and evaluated its impact on the performance of an AI system for prostate cancer diagnosis on 1,161 WSIs. Color standardization resulted in consistently improved AI model calibration and significant improvements in Gleason grading performance. The study demonstrates that physical color calibration provides a potential solution to the variation introduced by different scanners, making AI-based cancer diagnostics more reliable and applicable in clinical settings.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在数字 PATHOLOGY 的潜力受到数字标本（WSIs）的技术不一致所限制，导致 AI 性能下降，使得广泛应用在临床中采用困难。变化在扫描 workflow 也可能导致诊断错误和患者安全风险。我们评估了扫描器的物理色彩准确性是否可以标准化 WSI 的外观，并使 AI 系统在 1,161 个标本上表现出色。结果显示，物理色彩准确性可以提高 AI 模型准确性，并且在 Gleason 分期性能上显示了明显的改善。这一研究表明，物理色彩准确性可以解决不同扫描器导致的变化，使 AI 基于 cancer 诊断更可靠和在临床设置中实用。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts"><a href="#A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts" class="headerlink" title="A Deep Active Contour Model for Delineating Glacier Calving Fronts"></a>A Deep Active Contour Model for Delineating Glacier Calving Fronts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03461">http://arxiv.org/abs/2307.03461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konrad Heidler, Lichao Mou, Erik Loebel, Mirko Scheinert, Sébastien Lefèvre, Xiao Xiang Zhu</li>
<li>for: 这个论文是关于冰川分裂前模型的研究，旨在提出一种基于 outline 找出的方法，以提高冰川分裂前探测器的准确率。</li>
<li>methods: 该方法 combine 了 Convolutional Neural Networks (CNNs) 和 active contour model，以提取特征和描述 outline。</li>
<li>results: 通过在格陵兰冰川的多个大规模数据集上训练和评估，该方法被证明超过基于 segmentation 和 edge-detection 的方法。此外，该方法还可以更好地计算模型预测结果的不确定性。<details>
<summary>Abstract</summary>
Choosing how to encode a real-world problem as a machine learning task is an important design decision in machine learning. The task of glacier calving front modeling has often been approached as a semantic segmentation task. Recent studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called ``Charting Outlines by Recurrent Adaptation'' (COBRA), combines Convolutional Neural Networks (CNNs) for feature extraction and active contour models for the delineation. By training and evaluating on several large-scale datasets of Greenland's outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models' prediction uncertainties. The project page containing the code and animated model predictions can be found at \url{https://khdlr.github.io/COBRA/}.
</details>
<details>
<summary>摘要</summary>
选择如何编码实际问题为机器学习任务是机器学习设计决策的重要一环。冰川脱落前模型的任务经常被看作为语义分割任务。 latest studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. 在这个基础上，我们完全重新表述任务为一个 outline tracing 问题，并提出一种不包含任何稠密预测的模型。我们称之为“Charting Outlines by Recurrent Adaptation”（COBRA），它将 Convolutional Neural Networks（CNNs）用于特征提取和活动 kontur 模型来进行定义。通过对瑞典格陵兰冰川出口的数据进行训练和评估，我们示出了这种方法实际上超过了以前基于 segmentation 和 edge-detection 的方法。最后，我们示出了明确的 outline 检测在量化模型预测不确定性时的优势。关于这个项目，包含代码和动画预测的项目页面可以在 \url{https://khdlr.github.io/COBRA/} 上找到。
</details></li>
</ul>
<hr>
<h2 id="Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration"><a href="#Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration" class="headerlink" title="Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration"></a>Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03421">http://arxiv.org/abs/2307.03421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/registration-nice-trans">https://github.com/mungomeng/registration-nice-trans</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim</li>
<li>for: 这个论文主要是为了提出一种基于深度学习的非迭代抽象图像 региSTRATION方法，以提高图像REGISTRATION的精度和效率。</li>
<li>methods: 这个方法使用了非迭代抽象图像REGISTRATION的单个网络，并首次将 transformers 引入到 NICE 图像REGISTRATION 框架中，以模型图像之间的长距离相关性。</li>
<li>results: 经过广泛的七个公共数据集的实验，这个方法的注意力 Transformer 在 NICE 图像REGISTRATION 中表现出了优于当前状态艺术的精度和效率。<details>
<summary>Abstract</summary>
Image registration is a fundamental requirement for medical image analysis. Deep registration methods based on deep learning have been widely recognized for their capabilities to perform fast end-to-end registration. Many deep registration methods achieved state-of-the-art performance by performing coarse-to-fine registration, where multiple registration steps were iterated with cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE) registration methods have been proposed to perform coarse-to-fine registration in a single network and showed advantages in both registration accuracy and runtime. However, existing NICE registration methods mainly focus on deformable registration, while affine registration, a common prerequisite, is still reliant on time-consuming traditional optimization-based methods or extra affine registration networks. In addition, existing NICE registration methods are limited by the intrinsic locality of convolution operations. Transformers may address this limitation for their capabilities to capture long-range dependency, but the benefits of using transformers for NICE registration have not been explored. In this study, we propose a Non-Iterative Coarse-to-finE Transformer network (NICE-Trans) for image registration. Our NICE-Trans is the first deep registration method that (i) performs joint affine and deformable coarse-to-fine registration within a single network, and (ii) embeds transformers into a NICE registration framework to model long-range relevance between images. Extensive experiments with seven public datasets show that our NICE-Trans outperforms state-of-the-art registration methods on both registration accuracy and runtime.
</details>
<details>
<summary>摘要</summary>
医疗图像分析中的图像注册是一项基本要求。基于深度学习的深度注册方法在过去几年内得到了广泛的认可，因为它们可以快速完成端到端注册。许多深度注册方法在多个注册步骤中使用了缩放网络，以实现粗细到细节的注册。然而，现有的NICE注册方法主要关注于可变性注册，而平移注册，是医疗图像注册的常见前提，仍然是通过传统的优化方法或额外的平移注册网络来实现的。此外，现有的NICE注册方法受到了卷积操作的本地性的限制。使用transformer可以解决这一限制，因为它可以捕捉图像之间的长距离相关性。但是，使用transformer进行NICE注册的好处尚未得到了探讨。在本研究中，我们提出了一种非iterative粗细到细节的transformer网络（NICE-Trans） для图像注册。我们的NICE-Trans是首个深度注册方法，它（i）在单个网络中同时实现了平移和可变性的粗细到细节注册，（ii）将transformer引入NICE注册框架，以模型图像之间的长距离相关性。我们在七个公共数据集上进行了广泛的实验，结果表明，我们的NICE-Trans比状态之前的注册方法在注册精度和运行时间上都有提高。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency"><a href="#Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency" class="headerlink" title="Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency"></a>Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03413">http://arxiv.org/abs/2307.03413</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/CycFusion">https://github.com/shuaikaishi/CycFusion</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Yoann Altmann, Jie Chen</li>
<li>for: 这个论文主要针对的问题是如何实现高spectral resolution和高 spatial resolution的图像拼接，并且提出了一种基于循环一致的无监督拼接模型。</li>
<li>methods: 该模型基于循环一致的概念，将低spectral resolution的干扰图像（LrHSI）和高spectral resolution的多spectral图像（HrMSI）映射到高spectral resolution的图像中，并且通过单个变换和双重变换的对比来学习域转换。</li>
<li>results: 对于多个数据集，该模型的实验结果表明，与其他无监督拼接方法相比，该模型能够更好地实现高spectral resolution和高 spatial resolution的图像拼接，并且可以在不知道干扰参数的情况下进行拼接。<details>
<summary>Abstract</summary>
Hyperspectral images (HSI) with abundant spectral information reflected materials property usually perform low spatial resolution due to the hardware limits. Meanwhile, multispectral images (MSI), e.g., RGB images, have a high spatial resolution but deficient spectral signatures. Hyperspectral and multispectral image fusion can be cost-effective and efficient for acquiring both high spatial resolution and high spectral resolution images. Many of the conventional HSI and MSI fusion algorithms rely on known spatial degradation parameters, i.e., point spread function, spectral degradation parameters, spectral response function, or both of them. Another class of deep learning-based models relies on the ground truth of high spatial resolution HSI and needs large amounts of paired training images when working in a supervised manner. Both of these models are limited in practical fusion scenarios. In this paper, we propose an unsupervised HSI and MSI fusion model based on the cycle consistency, called CycFusion. The CycFusion learns the domain transformation between low spatial resolution HSI (LrHSI) and high spatial resolution MSI (HrMSI), and the desired high spatial resolution HSI (HrHSI) are considered to be intermediate feature maps in the transformation networks. The CycFusion can be trained with the objective functions of marginal matching in single transform and cycle consistency in double transforms. Moreover, the estimated PSF and SRF are embedded in the model as the pre-training weights, which further enhances the practicality of our proposed model. Experiments conducted on several datasets show that our proposed model outperforms all compared unsupervised fusion methods. The codes of this paper will be available at this address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
</details>
<details>
<summary>摘要</summary>
干扰影像（HSI）具有丰富的 спектраль信息，通常由硬件限制而导致低空间分辨率。而多spectral影像（MSI），例如RGB影像，具有高空间分辨率，但缺乏 спектраль特征。干扰影像和多spectral影像的图像混合可以是成本效益和高效的方式，以获得高空间分辨率和高спектраль分辨率的图像。许多传统的HSI和MSI混合算法取决于已知的空间退化参数，例如点扩散函数、spectral退化参数、spectral响应函数或其中之一。另一类的深度学习模型需要大量的实验训练图像，且需要高空间分辨率HSI的实验训练图像。这两类模型在实际混合应用场景中有限制。在这篇论文中，我们提出了一种不需要实验训练图像的干扰影像和多spectral影像混合模型，基于循环一致性，称为CycFusion。CycFusion学习了干扰影像低空间分辨率（LrHSI）和高空间分辨率多spectral影像（HrMSI）之间的Domain转换，并考虑了欲有的高空间分辨率HSI作为中间特征图。CycFusion可以通过单个转换和双转换的对应函数来训练，并且可以在干扰影像和多spectral影像之间进行自适应的混合。此外，我们还在模型中嵌入了估计的PSF和SRF，以进一步提高模型的实用性。我们在多个数据集上进行了实验，结果显示，我们的提出的模型在无监督情况下超过所有相比的无监督混合方法。模型代码将在以下地址可用：https: //github.com/shuaikaishi/CycFusion，以便重现。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-SDRTV-to-HDRTV-via-Dual-Inverse-Degradation-Network"><a href="#Towards-Robust-SDRTV-to-HDRTV-via-Dual-Inverse-Degradation-Network" class="headerlink" title="Towards Robust SDRTV-to-HDRTV via Dual Inverse Degradation Network"></a>Towards Robust SDRTV-to-HDRTV via Dual Inverse Degradation Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03394">http://arxiv.org/abs/2307.03394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kepeng Xu, Gang He, Li Xu, Xingchao Yang, Ming Sun, Yuzhi Wang, Zijia Ma, Haoqiang Fan, Xing Wen</li>
<li>for: 提高SDRTV至HDRTV的转换效果，并且解决转换过程中存在的编码痕迹的增强问题。</li>
<li>methods: 提出了一种双 inverse degradation SDRTV-to-HDRTV网络DIDNet，包括时间空间特征对齐模块和双调度卷积，以及波帕特注意模块，以提高颜色恢复能力和编码痕迹除减能力。</li>
<li>results: 与当前状态艺术方法相比，提出的方法在量化结果、视觉质量和推理时间等方面具有显著优势，因此可以在实际应用场景中提高SDRTV至HDRTV的转换效果。<details>
<summary>Abstract</summary>
Recently, the transformation of standard dynamic range TV (SDRTV) to high dynamic range TV (HDRTV) is in high demand due to the scarcity of HDRTV content. However, the conversion of SDRTV to HDRTV often amplifies the existing coding artifacts in SDRTV which deteriorate the visual quality of the output. In this study, we propose a dual inverse degradation SDRTV-to-HDRTV network DIDNet to address the issue of coding artifact restoration in converted HDRTV, which has not been previously studied. Specifically, we propose a temporal-spatial feature alignment module and dual modulation convolution to remove coding artifacts and enhance color restoration ability. Furthermore, a wavelet attention module is proposed to improve SDRTV features in the frequency domain. An auxiliary loss is introduced to decouple the learning process for effectively restoring from dual degradation. The proposed method outperforms the current state-of-the-art method in terms of quantitative results, visual quality, and inference times, thus enhancing the performance of the SDRTV-to-HDRTV method in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
最近，标准动态范围电视（SDRTV）到高动态范围电视（HDRTV）的转换受到了高动态范围内容缺乏的限制。然而，将SDRTV转换为HDRTV经常会加剧SDRTV中存在的编码 artifacts，从而降低输出视质。在这项研究中，我们提出了一个双重逆减 SDRTV-to-HDRTV 网络 DIDNet，以解决转换后 HDRTV 中的编码 artifact 纠正问题，这一问题尚未被研究。特别是，我们提出了时空特征对齐模块和双扩涨 convolution来除除编码 artifacts和提高颜色纠正能力。此外，我们还提出了wavelet 注意力模块，以提高 SDRTV 特征在频域中。还引入了一个 auxillary 损失函数，以分离学习过程中的纠正过程，从而提高 SDRTV-to-HDRTV 方法的实际场景性能。根据量化结果和视觉质量，我们的方法超过了当前状态的艺术方法，从而提高 SDRTV-to-HDRTV 方法的性能。
</details></li>
</ul>
<hr>
<h2 id="CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images"><a href="#CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images" class="headerlink" title="CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images"></a>CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03293">http://arxiv.org/abs/2307.03293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngaggion/chexmask-database">https://github.com/ngaggion/chexmask-database</a></li>
<li>paper_authors: Nicolás Gaggion, Candelaria Mosquera, Lucas Mansilla, Martina Aineseder, Diego H. Milone, Enzo Ferrante</li>
<li>for: 这个研究的目的是为了提供一个大型、多中心的胸部X射影分类数据集，以便帮助开发更好的人工智能模型。</li>
<li>methods: 这个研究使用了HybridGNet模型来确保所有数据集中的分类都是一致的和高品质的。</li>
<li>results: 这个研究产生了676,803个分类掩模，并进行了严格的验证，包括专业医生评价和自动化品质控制，以验证所有掩模的品质。<details>
<summary>Abstract</summary>
The development of successful artificial intelligence models for chest X-ray analysis relies on large, diverse datasets with high-quality annotations. While several databases of chest X-ray images have been released, most include disease diagnosis labels but lack detailed pixel-level anatomical segmentation labels. To address this gap, we introduce an extensive chest X-ray multi-center segmentation dataset with uniform and fine-grain anatomical annotations for images coming from six well-known publicly available databases: CANDID-PTX, ChestX-ray8, Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in 676,803 segmentation masks. Our methodology utilizes the HybridGNet model to ensure consistent and high-quality segmentations across all datasets. Rigorous validation, including expert physician evaluation and automatic quality control, was conducted to validate the resulting masks. Additionally, we provide individualized quality indices per mask and an overall quality estimation per dataset. This dataset serves as a valuable resource for the broader scientific community, streamlining the development and assessment of innovative methodologies in chest X-ray analysis. The CheXmask dataset is publicly available at: \url{https://physionet.org/content/chexmask-cxr-segmentation-data/}.
</details>
<details>
<summary>摘要</summary>
发展成功人工智能模型需要大量多样化的数据集，以便进行胸部X射线分析。虽然一些胸部X射线图像数据库已经发布，但大多数只包含疾病诊断标签，缺乏细致的像素级别解剖标注。为了解决这个问题，我们介绍了一个胸部X射线多中心分割数据集，包括六个公共可用的数据库：CANDID-PTX、ChestX-ray8、Chexpert、MIMIC-CXR-JPG、Padchest和VinDr-CXR，共计676,803个分割mask。我们的方法使用HybridGNet模型，确保分割结果具有一致性和高质量。我们进行了严格的验证，包括专业医生评估和自动化质量控制，以验证结果。此外，我们还提供了每个mask的个性化质量指数和每个数据集的总质量估计。这个数据集对科学社区来说是一个重要的资源，可以促进胸部X射线分析领域的创新和评估。CheXmask数据集可以在以下链接获取：https://physionet.org/content/chexmask-cxr-segmentation-data/。
</details></li>
</ul>
<hr>
<h2 id="ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images"><a href="#ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images" class="headerlink" title="ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images"></a>ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03273">http://arxiv.org/abs/2307.03273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mokshagna Sai Teja Karanam, Tushar Kataria, Krithika Iyer, Shireen Elhabian</li>
<li>for: 这paper的目的是提出一种基于深度学习的图像到统计形态模型（SSM）框架，以提高图像到SSM的准确率和效率。</li>
<li>methods: 该paper使用了深度学习模型来学习图像中的形态表示，并使用了KDE方法生成形态增强样本以帮助图像到SSM网络实现比较高的准确率。</li>
<li>results: 该paper的实验结果表明，使用该novel strategy可以提高图像到SSM网络的准确率，并且可以避免深度学习模型的图像基于Texture偏好。<details>
<summary>Abstract</summary>
Statistical shape models (SSM) have been well-established as an excellent tool for identifying variations in the morphology of anatomy across the underlying population. Shape models use consistent shape representation across all the samples in a given cohort, which helps to compare shapes and identify the variations that can detect pathologies and help in formulating treatment plans. In medical imaging, computing these shape representations from CT/MRI scans requires time-intensive preprocessing operations, including but not limited to anatomy segmentation annotations, registration, and texture denoising. Deep learning models have demonstrated exceptional capabilities in learning shape representations directly from volumetric images, giving rise to highly effective and efficient Image-to-SSM networks. Nevertheless, these models are data-hungry and due to the limited availability of medical data, deep learning models tend to overfit. Offline data augmentation techniques, that use kernel density estimation based (KDE) methods for generating shape-augmented samples, have successfully aided Image-to-SSM networks in achieving comparable accuracy to traditional SSM methods. However, these augmentation methods focus on shape augmentation, whereas deep learning models exhibit image-based texture bias resulting in sub-optimal models. This paper introduces a novel strategy for on-the-fly data augmentation for the Image-to-SSM framework by leveraging data-dependent noise generation or texture augmentation. The proposed framework is trained as an adversary to the Image-to-SSM network, augmenting diverse and challenging noisy samples. Our approach achieves improved accuracy by encouraging the model to focus on the underlying geometry rather than relying solely on pixel values.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia"><a href="#A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia" class="headerlink" title="A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia"></a>A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03757">http://arxiv.org/abs/2307.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam J Shephard, Raja Muhammad Saad Bashir, Hanya Mahmood, Mostafa Jahanifar, Fayyaz Minhas, Shan E Ahmed Raza, Kris D McCombe, Stephanie G Craig, Jacqueline James, Jill Brooks, Paul Nankivell, Hisham Mehanna, Syed Ali Khurram, Nasir M Rajpoot<br>for: 这个研究的目的是提出一种完全自动化的算法，以便预测口腔细膜癌变的发生，基于可读取的核仁特征。methods: 这个算法使用了自己设计的Segmentation模型，以及一种浅层神经网络，以检测和分类口腔细膜中的核仁。results: 该算法在三个外部数据集上进行了验证，AUROC值为0.74，表明其可以准确预测口腔细膜癌变的发生。此外，Survival分析表明该算法可以预测癌变的发生，并且可以更好地预测比 manually-assigned WHO和二元等级。<details>
<summary>Abstract</summary>
Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis given to lesions of the oral cavity. Its grading suffers from significant inter-/intra- observer variability, and does not reliably predict malignancy progression, potentially leading to suboptimal treatment decisions. To address this, we developed a novel artificial intelligence algorithm that can assign an Oral Malignant Transformation (OMT) risk score, based on histological patterns in the in Haematoxylin and Eosin stained whole slide images, to quantify the risk of OED progression. The algorithm is based on the detection and segmentation of nuclei within (and around) the epithelium using an in-house segmentation model. We then employed a shallow neural network fed with interpretable morphological/spatial features, emulating histological markers. We conducted internal cross-validation on our development cohort (Sheffield; n = 193 cases) followed by independent validation on two external cohorts (Birmingham and Belfast; n = 92 cases). The proposed OMTscore yields an AUROC = 0.74 in predicting whether an OED progresses to malignancy or not. Survival analyses showed the prognostic value of our OMTscore for predicting malignancy transformation, when compared to the manually-assigned WHO and binary grades. Analysis of the correctly predicted cases elucidated the presence of peri-epithelial and epithelium-infiltrating lymphocytes in the most predictive patches of cases that transformed (p < 0.0001). This is the first study to propose a completely automated algorithm for predicting OED transformation based on interpretable nuclear features, whilst being validated on external datasets. The algorithm shows better-than-human-level performance for prediction of OED malignant transformation and offers a promising solution to the challenges of grading OED in routine clinical practice.
</details>
<details>
<summary>摘要</summary>
口腔粘膜细胞变化（OED）是口腔部位的一种前癌性病理诊断，但其分级存在很大的干扰因素和内部/外部观察者的不一致，不能准确预测癌变进程，可能导致不佳的治疗决策。为了解决这个问题，我们开发了一种新的人工智能算法，可以根据染色体板术影像中的细胞核特征分配口腔癌变转换风险分数（OMT分数），以评估OED转换癌变的风险。这种算法基于检测和分类细胞核的具体方法，使用了我们自己开发的分割模型。然后，我们使用了一个浅层神经网络，以便使用可读性特征来模拟 histological markers。我们在我们的开发组（Sheffield）进行了内部十字验证（n = 193例），然后在两个外部组（Birmingham和Belfast）进行了独立验证（n = 92例）。我们的提出的 OMT 分数可以在预测OED转换癌变是否存在的问题上达到 AUROC = 0.74 的性能。我们的存活分析表明，我们的 OMT 分数具有预测癌变转换的 проGNosis 价值，比较于由人工分配的 WHO 和二分类分数。分析 Correctly 预测的 случаeschannel 显示，在转换的 caso 中存在辐射半径内的卵细胞和细胞核的卫星细胞（p < 0.0001）。这是首个提出一种完全自动化的 OED 转换预测算法，基于可读性的核特征，并在外部数据上进行了验证。这种算法在预测 OED 癌变转换性能上达到了人类水平，并且提供了一个可能的解决方案，以解决 OED 的分级挑战。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Aware-Image-Compressed-Sensing"><a href="#Semantic-Aware-Image-Compressed-Sensing" class="headerlink" title="Semantic-Aware Image Compressed Sensing"></a>Semantic-Aware Image Compressed Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03246">http://arxiv.org/abs/2307.03246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Zhang, Zhijin Qin, Geoffrey Ye Li</li>
<li>for: 提高图像压缩感知效率</li>
<li>methods: 使用基于深度学习的图像压缩感知系统，并使用策略网络分析图像semantic信息，确定不同图像区域的测量矩阵</li>
<li>results: 提出了一种基于semantic信息的图像压缩感知系统，实现了提高图像压缩感知效率<details>
<summary>Abstract</summary>
Deep learning based image compressed sensing (CS) has achieved great success. However, existing CS systems mainly adopt a fixed measurement matrix to images, ignoring the fact the optimal measurement numbers and bases are different for different images. To further improve the sensing efficiency, we propose a novel semantic-aware image CS system. In our system, the encoder first uses a fixed number of base CS measurements to sense different images. According to the base CS results, the encoder then employs a policy network to analyze the semantic information in images and determines the measurement matrix for different image areas. At the decoder side, a semantic-aware initial reconstruction network is developed to deal with the changes of measurement matrices used at the encoder. A rate-distortion training loss is further introduced to dynamically adjust the average compression ratio for the semantic-aware CS system and the policy network is trained jointly with the encoder and the decoder in an en-to-end manner by using some proxy functions. Numerical results show that the proposed semantic-aware image CS system is superior to the traditional ones with fixed measurement matrices.
</details>
<details>
<summary>摘要</summary>
深度学习基于图像压缩感知（CS）技术已经取得了很大成功。然而，现有的CS系统主要采用固定的测量矩阵来对图像进行测量，忽略了图像的优化测量数量和基准的不同。为了进一步提高感知效率，我们提出了一种新的Semantic-aware图像CS系统。在我们的系统中，Encoder首先使用固定数量的基础CS测量来感知不同的图像。根据基础CS结果，Encoder然后使用一个政策网络分析图像中的Semantic信息，并确定不同的图像区域的测量矩阵。在Decoder端，一个Semantic-aware初始重建网络被开发以处理测量矩阵的变化。此外，我们还引入了一个率-压缩训练损失，以 Dynamically adjust the average compression ratio for the Semantic-aware CS system。Policy网络与Encoder和Decoder在一起训练，使用某些代理函数。numerical results show that the proposed Semantic-aware image CS system is superior to traditional ones with fixed measurement matrices.Note: Please note that the translation is in Simplified Chinese, and some words or phrases may have been translated differently in Traditional Chinese.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/eess.IV_2023_07_07/" data-id="clogyj92201107cragzinbyoj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/06/cs.SD_2023_07_06/" class="article-date">
  <time datetime="2023-07-06T15:00:00.000Z" itemprop="datePublished">2023-07-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/06/cs.SD_2023_07_06/">cs.SD - 2023-07-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Audio-visual-End-to-end-Multi-channel-Speech-Separation-Dereverberation-and-Recognition"><a href="#Audio-visual-End-to-end-Multi-channel-Speech-Separation-Dereverberation-and-Recognition" class="headerlink" title="Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition"></a>Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02909">http://arxiv.org/abs/2307.02909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guinan Li, Jiajun Deng, Mengzhe Geng, Zengrui Jin, Tianzi Wang, Shujie Hu, Mingyu Cui, Helen Meng, Xunying Liu</li>
<li>for: 提高cocktail party speech recognition精度，增强对干扰音频信号的识别能力。</li>
<li>methods: 利用视频信号，实现多通道音频信号分离、去抖振荡和识别，并在前端和后端都具有视觉信息的完整 incorporation。</li>
<li>results: 相比同种audio-only基eline，提高了9.1%和6.2%的word error rate（WER），同时也提高了PESQ、STOI和SRMR分数。<details>
<summary>Abstract</summary>
Accurate recognition of cocktail party speech containing overlapping speakers, noise and reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all system components is proposed in this paper. The efficacy of the video input is consistently demonstrated in mask-based MVDR speech separation, DNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and Conformer ASR back-end. Audio-visual integrated front-end architectures performing speech separation and dereverberation in a pipelined or joint fashion via mask-based WPD are investigated. The error cost mismatch between the speech enhancement front-end and ASR back-end components is minimized by end-to-end jointly fine-tuning using either the ASR cost function alone, or its interpolation with the speech enhancement loss. Experiments were conducted on the mixture overlapped and reverberant speech data constructed using simulation or replay of the Oxford LRS2 dataset. The proposed audio-visual multi-channel speech separation, dereverberation and recognition systems consistently outperformed the comparable audio-only baseline by 9.1% and 6.2% absolute (41.7% and 36.0% relative) word error rate (WER) reductions. Consistent speech enhancement improvements were also obtained on PESQ, STOI and SRMR scores.
</details>
<details>
<summary>摘要</summary>
当前，cocktail party speech中的叠加说话者、噪声和回声识别仍然是一个非常挑战性的任务。这是因为视觉modalities具有对声音信号损害的不变性，所以一种包含视觉信息的多渠道音频视觉混合分离、减少回声和识别方法被提议。这篇论文中的方法是通过使用面积基于的MVDR音频分离、DNN-WPE或spectral mapping（SpecM）基于的音频前端分离和Conformer ASR后端来实现。我们还 investigate了将视觉信息完全 интегрирован到所有系统组件中的音频视觉混合前端架构。在pipelined或联合的方式下，我们使用面积基于的WPD来实现音频视觉混合。为了消除语音提高前端和后端组件之间的错误成本差，我们使用综合jointly fine-tuning，使用ASR成本函数alone或其混合with语音提高损失来减少错误成本差。我们对于混合了simulation和replay的Oxford LRS2 dataset中的杂合混响杂音数据进行了实验。结果表明，我们的音频视觉多渠道分离、减少回声和识别系统在相比于相同的音频基eline的9.1%和6.2%绝对（41.7%和36.0%相对）word error rate（WER）下提高了识别率。此外，我们还获得了相应的语音提高成果在PESQ、STOI和SRMR scores上。
</details></li>
</ul>
<hr>
<h2 id="The-Relationship-Between-Speech-Features-Changes-When-You-Get-Depressed-Feature-Correlations-for-Improving-Speed-and-Performance-of-Depression-Detection"><a href="#The-Relationship-Between-Speech-Features-Changes-When-You-Get-Depressed-Feature-Correlations-for-Improving-Speed-and-Performance-of-Depression-Detection" class="headerlink" title="The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection"></a>The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02892">http://arxiv.org/abs/2307.02892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuxiang Tao, Wei Ma, Xuri Ge, Anna Esposito, Alessandro Vinciarelli</li>
<li>for: 这个论文研究了听话者抑郁症的影响，发现抑郁症会改变speech中特征之间的相关性。</li>
<li>methods: 该论文使用了SVM和LSTM两种模型，并使用了Androids Corpus dataset，包括112名speaker，其中58人被诊断为职业心理医生。</li>
<li>results: 实验结果显示，使用特征相关矩阵而不是特征向量可以提高模型的训练速度和性能，错误率下降23.1%-26.6%。这可能是因为抑郁 speaker中特征相关性更为变化。<details>
<summary>Abstract</summary>
This work shows that depression changes the correlation between features extracted from speech. Furthermore, it shows that using such an insight can improve the training speed and performance of depression detectors based on SVMs and LSTMs. The experiments were performed over the Androids Corpus, a publicly available dataset involving 112 speakers, including 58 people diagnosed with depression by professional psychiatrists. The results show that the models used in the experiments improve in terms of training speed and performance when fed with feature correlation matrices rather than with feature vectors. The relative reduction of the error rate ranges between 23.1% and 26.6% depending on the model. The probable explanation is that feature correlation matrices appear to be more variable in the case of depressed speakers. Correspondingly, such a phenomenon can be thought of as a depression marker.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Evaluating-raw-waveforms-with-deep-learning-frameworks-for-speech-emotion-recognition"><a href="#Evaluating-raw-waveforms-with-deep-learning-frameworks-for-speech-emotion-recognition" class="headerlink" title="Evaluating raw waveforms with deep learning frameworks for speech emotion recognition"></a>Evaluating raw waveforms with deep learning frameworks for speech emotion recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02820">http://arxiv.org/abs/2307.02820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeynep Hilal Kilimci, Ulku Bayraktar, Ayhan Kucukmanisa<br>for:The paper focuses on speech emotion recognition using deep learning techniques, specifically on the contribution of feeding raw audio files directly into deep neural networks without any feature extraction stage.methods:The proposed model uses a combination of machine learning algorithms, ensemble learning methods, and deep and hybrid deep learning techniques, including support vector machine, decision tree, naive Bayes, random forests, majority voting, and stacking. The model also employs convolutional neural networks, long short-term memory networks, and hybrid CNN-LSTM models.results:The proposed model achieves state-of-the-art performance on six different data sets, including EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. Specifically, the CNN model achieves 95.86% accuracy on the TESS+RAVDESS data set, outperforming existing approaches. The proposed model also demonstrates high accuracy on other data sets, ranging from 90.34% to 99.48% and 69.72% to 85.76%, depending on the data set and the model used.<details>
<summary>Abstract</summary>
Speech emotion recognition is a challenging task in speech processing field. For this reason, feature extraction process has a crucial importance to demonstrate and process the speech signals. In this work, we represent a model, which feeds raw audio files directly into the deep neural networks without any feature extraction stage for the recognition of emotions utilizing six different data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To demonstrate the contribution of proposed model, the performance of traditional feature extraction techniques namely, mel-scale spectogram, mel-frequency cepstral coefficients, are blended with machine learning algorithms, ensemble learning methods, deep and hybrid deep learning techniques. Support vector machine, decision tree, naive Bayes, random forests models are evaluated as machine learning algorithms while majority voting and stacking methods are assessed as ensemble learning techniques. Moreover, convolutional neural networks, long short-term memory networks, and hybrid CNN- LSTM model are evaluated as deep learning techniques and compared with machine learning and ensemble learning methods. To demonstrate the effectiveness of proposed model, the comparison with state-of-the-art studies are carried out. Based on the experiment results, CNN model excels existent approaches with 95.86% of accuracy for TESS+RAVDESS data set using raw audio files, thence determining the new state-of-the-art. The proposed model performs 90.34% of accuracy for EMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of accuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model, 85.76% of accuracy for SAVEE with CNN model in speaker-independent audio categorization problems.
</details>
<details>
<summary>摘要</summary>
《speech emotion recognition是speech processing领域中的一项挑战。为了实现这一目标，特征提取过程具有重要的重要性。在这项工作中，我们提出了一种模型，该模型直接将原始音频文件传递给深度神经网络，不需要特征提取阶段。为了证明模型的贡献，我们对传统特征提取技术（mel-scale spectogram、mel-frequency cepstral coefficients）与机器学习算法（支持向量机、决策树、naive Bayes、Random Forest）、ensemble learning方法（majority voting、stacking）进行比较。此外，我们还评估了深度学习技术（卷积神经网络、长短期记忆网络、混合卷积-LSTM）。基于实验结果，CNN模型在TESS+RAVDESS数据集上达到了95.86%的准确率，超过了现有方法，确定了新的状态态-of-the-art。我们的模型在EMO-DB、RAVDESS、TESS、CREMA和SAVEE数据集上达到了90.34%、90.42%、99.48%、69.72%和85.76%的准确率。》
</details></li>
</ul>
<hr>
<h2 id="DSARSR-Deep-Stacked-Auto-encoders-Enhanced-Robust-Speaker-Recognition"><a href="#DSARSR-Deep-Stacked-Auto-encoders-Enhanced-Robust-Speaker-Recognition" class="headerlink" title="DSARSR: Deep Stacked Auto-encoders Enhanced Robust Speaker Recognition"></a>DSARSR: Deep Stacked Auto-encoders Enhanced Robust Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02751">http://arxiv.org/abs/2307.02751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhifeng Wang, Chunyan Zeng, Surong Duan, Hongjie Ouyang, Hongmin Xu</li>
<li>for: 这项研究旨在提高cross-channel条件下i-vector框架的Robustness，并探索使用深度学习进行人识别。</li>
<li>methods: 该研究使用Stacked Auto-encoders来提取i-vector的抽象，而不是使用PLDA。在预处理和特征提取后，使用Speaker和Channel独立的speech进行UBM训练。</li>
<li>results: 实验结果显示，提出的方法比之前的方法表现更好。<details>
<summary>Abstract</summary>
Speaker recognition is a biometric modality that utilizes the speaker's speech segments to recognize the identity, determining whether the test speaker belongs to one of the enrolled speakers. In order to improve the robustness of the i-vector framework on cross-channel conditions and explore the nova method for applying deep learning to speaker recognition, the Stacked Auto-encoders are used to get the abstract extraction of the i-vector instead of applying PLDA. After pre-processing and feature extraction, the speaker and channel-independent speeches are employed for UBM training. The UBM is then used to extract the i-vector of the enrollment and test speech. Unlike the traditional i-vector framework, which uses linear discriminant analysis (LDA) to reduce dimension and increase the discrimination between speaker subspaces, this research use stacked auto-encoders to reconstruct the i-vector with lower dimension and different classifiers can be chosen to achieve final classification. The experimental results show that the proposed method achieves better performance than the state-of-the-art method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-Device-Constrained-Self-Supervised-Speech-Representation-Learning-for-Keyword-Spotting-via-Knowledge-Distillation"><a href="#On-Device-Constrained-Self-Supervised-Speech-Representation-Learning-for-Keyword-Spotting-via-Knowledge-Distillation" class="headerlink" title="On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation"></a>On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02720">http://arxiv.org/abs/2307.02720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gene-Ping Yang, Yue Gu, Qingming Tang, Dongsu Du, Yuzong Liu</li>
<li>for: 这篇论文是为了提高在 Alexa 关键词搜寻任务中的语音识别精度，特别是在内存限制和受损数据收集的情况下。</li>
<li>methods: 我们使用了知识传授法，将大型自我超vised模型的知识转移到较小的、轻量级模型中，并使用双重视野交叉相关知识传授和老师的codebook作为学习目标。</li>
<li>results: 我们在使用了我们的S3RL架构进行 Alexa 关键词搜寻探测任务时，在正常和噪音情况下表现出色，证明了知识传授方法在自我超vised模型中构建关键词搜寻模型的时候具有优秀的效果，并且在内存限制和受损数据收集的情况下运行。<details>
<summary>Abstract</summary>
Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting. To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting. Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives. We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset. Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints.
</details>
<details>
<summary>摘要</summary>
大型自我监督模型是有效的特征提取器，但是在设备内存限制和偏见数据采集下面临挑战，特别是在关键词检测中。为解决这问题，我们提出了基于知识填充的自我监督语音表示学习（S3RL）建模，用于在设备上进行关键词检测。我们采用了教师-学生框架，将大型、复杂的模型知识传播到小型、轻量级模型，使用双视交叉相关知识填充和教师的编码库作为学习目标。我们使用Alexa关键词检测任务上的16.6万小时内部数据进行评估。我们的技术在正常和噪音条件下都表现出色，证明了知识填充方法在构建自我监督模型的关键词检测任务中的效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/06/cs.SD_2023_07_06/" data-id="clogyj8zv00r47cra5kn7a410" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/06/eess.AS_2023_07_06/" class="article-date">
  <time datetime="2023-07-06T14:00:00.000Z" itemprop="datePublished">2023-07-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/06/eess.AS_2023_07_06/">eess.AS - 2023-07-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Read-Look-or-Listen-What’s-Needed-for-Solving-a-Multimodal-Dataset"><a href="#Read-Look-or-Listen-What’s-Needed-for-Solving-a-Multimodal-Dataset" class="headerlink" title="Read, Look or Listen? What’s Needed for Solving a Multimodal Dataset"></a>Read, Look or Listen? What’s Needed for Solving a Multimodal Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04532">http://arxiv.org/abs/2307.04532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Netta Madvil, Yonatan Bitton, Roy Schwartz</li>
<li>for: 本研究旨在探讨大规模多模式数据集的质量评估问题。</li>
<li>methods: 我们提出了一种两步方法，利用小量人工标注将每个多模式实例映射到需要处理的Modalities。</li>
<li>results: 我们应用方法到TVQA视频问答数据集，发现大多数问题可以通过单一模式答案，无论是视频还是音频。此外，我们发现更多的70%的问题可以使用多种不同的单模式策略解决，如只看视频或只听音频。此外，我们发现MERLOT Reserve在图像基于问题上表现不佳，而文本和音频则表现较好。基于我们的观察，我们提出了一个新的测试集，其中模型需要使用多种模式，并观察到模型性能减降很大。<details>
<summary>Abstract</summary>
The prevalence of large-scale multimodal datasets presents unique challenges in assessing dataset quality. We propose a two-step method to analyze multimodal datasets, which leverages a small seed of human annotation to map each multimodal instance to the modalities required to process it. Our method sheds light on the importance of different modalities in datasets, as well as the relationship between them. We apply our approach to TVQA, a video question-answering dataset, and discover that most questions can be answered using a single modality, without a substantial bias towards any specific modality. Moreover, we find that more than 70% of the questions are solvable using several different single-modality strategies, e.g., by either looking at the video or listening to the audio, highlighting the limited integration of multiple modalities in TVQA. We leverage our annotation and analyze the MERLOT Reserve, finding that it struggles with image-based questions compared to text and audio, but also with auditory speaker identification. Based on our observations, we introduce a new test set that necessitates multiple modalities, observing a dramatic drop in model performance. Our methodology provides valuable insights into multimodal datasets and highlights the need for the development of more robust models.
</details>
<details>
<summary>摘要</summary>
现代大规模多modal数据集存在独特的评估数据集质量挑战。我们提出了一种两步方法，使用小量人工标注来将多modal实例映射到需要处理它的modalities。我们的方法揭示了不同modalities在数据集中的重要性，以及它们之间的关系。我们应用了我们的方法到TVQA视频问答数据集，发现大多数问题可以使用单一modalities解决，无论哪种modalities。此外，我们发现超过70%的问题可以使用多个不同的单modalities策略解决，例如通过视频或音频来解决问题，这 highlights TVQA中多modalities的有限整合。我们利用我们的标注和分析MERLOT Reserve，发现它在图像基于问题上表现不佳，比 Text和音频更差。基于我们的观察，我们引入了一个新的测试集，需要多modalities，观察模型性能异常下降。我们的方法ология为多modal数据集提供了有价值的洞察，并高亮了需要更robust的模型的开发。
</details></li>
</ul>
<hr>
<h2 id="Deep-Speech-Synthesis-from-MRI-Based-Articulatory-Representations"><a href="#Deep-Speech-Synthesis-from-MRI-Based-Articulatory-Representations" class="headerlink" title="Deep Speech Synthesis from MRI-Based Articulatory Representations"></a>Deep Speech Synthesis from MRI-Based Articulatory Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02471">http://arxiv.org/abs/2307.02471</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/articulatory/articulatory">https://github.com/articulatory/articulatory</a></li>
<li>paper_authors: Peter Wu, Tingle Li, Yijing Lu, Yubin Zhang, Jiachen Lian, Alan W Black, Louis Goldstein, Shinji Watanabe, Gopala K. Anumanchipalli</li>
<li>for: 这个研究旨在开发一种基于人类声道信息的语音合成方法，以提高语音合成效率、通用性和可解释性。</li>
<li>methods: 该研究使用MRI技术获取更广泛的声道信息，并引入Normalization和denoising等处理方法，以提高深度学习模型的普适性和语音质量。</li>
<li>results: 研究人员通过一系列ablations表明，MRI表示的声道信息更加全面和精准，并且可以提高语音合成效率和质量。<details>
<summary>Abstract</summary>
In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了语音合成方法，即使用人类声门信息来开发高效、通用和可解释的合成器。最近的进展使得可以实现有声合成，但这些方法缺乏关键的唇形信息，如刺激和腔软度，这限制了其泛化能力。为了弥补这一点，我们提议一种基于MRI的特征集，覆盖了EMA的艺术iculatory空间的多倍。我们还提出了normalization和denoising的过程来提高深度学习方法在MRI数据上的泛化性。此外，我们提出了MRI-to-speech模型，可以提高计算效率和语音准确性。最后，通过一系列剥减实验，我们证明了我们的MRI表示是EMA的更加全面的，并确定了最适合语音合成的MRI特征子。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/06/eess.AS_2023_07_06/" data-id="clogyj91a00xr7cra5fiy2bgo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/06/cs.CV_2023_07_06/" class="article-date">
  <time datetime="2023-07-06T13:00:00.000Z" itemprop="datePublished">2023-07-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/06/cs.CV_2023_07_06/">cs.CV - 2023-07-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Proto-CLIP-Vision-Language-Prototypical-Network-for-Few-Shot-Learning"><a href="#Proto-CLIP-Vision-Language-Prototypical-Network-for-Few-Shot-Learning" class="headerlink" title="Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning"></a>Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03073">http://arxiv.org/abs/2307.03073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IRVLUTD/Proto-CLIP">https://github.com/IRVLUTD/Proto-CLIP</a></li>
<li>paper_authors: Jishnu Jaykumar P, Kamalesh Palanisamy, Yu-Wei Chao, Xinya Du, Yu Xiang</li>
<li>for: 本研究提出了一种基于大规模视语言模型CLIP的新框架，用于几拍学习。</li>
<li>methods: 该方法利用图像prototype和文本prototype进行几拍学习，特别是在CLIP中采用了图像编码器和文本编码器的联合使用几拍示例。</li>
<li>results: 我们在多个几拍学习数据集上进行了实验，并在实际应用中进行了机器人感知的测试，结果表明我们的方法高效。<details>
<summary>Abstract</summary>
We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP. Motivated by the unimodal prototypical networks for few-shot learning, we introduce PROTO-CLIP that utilizes image prototypes and text prototypes for few-shot learning. Specifically, PROTO-CLIP adapts the image encoder and text encoder in CLIP in a joint fashion using few-shot examples. The two encoders are used to compute prototypes of image classes for classification. During adaptation, we propose aligning the image and text prototypes of corresponding classes. Such a proposed alignment is beneficial for few-shot classification due to the contributions from both types of prototypes. We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning as well as in the real world for robot perception.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的几shot学习框架，利用大规模的视觉语言模型 such as CLIP。我们的方法被激发于干扰型网络 для几shot学习，我们称之为PROTO-CLIP。这个方法利用图像概念和文本概念来进行几shot学习。特别是，PROTO-CLIP在CLIP中的图像编码器和文本编码器进行联合调整，使用几shot示例来计算图像类别的概念。在调整过程中，我们提议将图像和文本概念的对应类型进行对接。这种提议的对接有助于几shot分类，因为图像和文本概念的贡献均有所提高。我们在几shot学习的标准数据集和实际世界中的 робот识别任务中进行了实验，以证明我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="PseudoCell-Hard-Negative-Mining-as-Pseudo-Labeling-for-Deep-Learning-Based-Centroblast-Cell-Detection"><a href="#PseudoCell-Hard-Negative-Mining-as-Pseudo-Labeling-for-Deep-Learning-Based-Centroblast-Cell-Detection" class="headerlink" title="PseudoCell: Hard Negative Mining as Pseudo Labeling for Deep Learning-Based Centroblast Cell Detection"></a>PseudoCell: Hard Negative Mining as Pseudo Labeling for Deep Learning-Based Centroblast Cell Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03211">http://arxiv.org/abs/2307.03211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narongrid Seesawad, Piyalitt Ittichaiwong, Thapanun Sudhawiyangkul, Phattarapong Sawangjai, Peti Thuwajit, Paisarn Boonsakan, Supasan Sripodok, Kanyakorn Veerakanjana, Phoomraphee Luenam, Komgrid Charngkaew, Ananya Pongpaibul, Napat Angkathunyakul, Narit Hnoohom, Sumeth Yuenyong, Chanitra Thuwajit, Theerawit Wilaiprasitporn</li>
<li>For: The paper aims to assist pathologists in grading follicular lymphoma patients by automating centroblast detection in whole-slide images (WSI) of H&amp;E-stained tissue samples using deep learning-based object detection frameworks.* Methods: The proposed method, called PseudoCell, incorporates centroblast labels from pathologists and combines them with pseudo-negative labels obtained from undersampled false-positive predictions using the cell’s morphological features.* Results: PseudoCell can accurately narrow down the areas requiring pathologists’ attention during examining tissue, eliminating 58.18-99.35% of non-centroblasts tissue areas on WSI, depending on the confidence threshold.Here’s the simplified Chinese text for the three key points:* For: 这篇论文旨在帮助病理学家评分淋巴癌病例，使用深度学习基于对象检测框架自动检测淋巴细胞在染色体抗静脉涂抹样本中。* Methods: 提议的方法叫做 PseudoCell，它将中心细胞标签与异常预测中的 pseudo-负样本结合使用，利用细胞形态特征来提高检测精度。* Results: PseudoCell 可以准确地减少病理学家的工作负担，在评分过程中减少 58.18-99.35% 的非中心细胞区域，具体的减少率取决于信任阈值。<details>
<summary>Abstract</summary>
Patch classification models based on deep learning have been utilized in whole-slide images (WSI) of H&E-stained tissue samples to assist pathologists in grading follicular lymphoma patients. However, these approaches still require pathologists to manually identify centroblast cells and provide refined labels for optimal performance. To address this, we propose PseudoCell, an object detection framework to automate centroblast detection in WSI (source code is available at https://github.com/IoBT-VISTEC/PseudoCell.git). This framework incorporates centroblast labels from pathologists and combines them with pseudo-negative labels obtained from undersampled false-positive predictions using the cell's morphological features. By employing PseudoCell, pathologists' workload can be reduced as it accurately narrows down the areas requiring their attention during examining tissue. Depending on the confidence threshold, PseudoCell can eliminate 58.18-99.35% of non-centroblasts tissue areas on WSI. This study presents a practical centroblast prescreening method that does not require pathologists' refined labels for improvement. Detailed guidance on the practical implementation of PseudoCell is provided in the discussion section.
</details>
<details>
<summary>摘要</summary>
报告文献：基于深度学习的报告分类模型已经在染色涂抹检查（H&E染色）的整个检查图像（WSI）中用于协助病理学家评分抗体癌病例。然而，这些方法仍然需要病理学家手动标识中心blast细胞并提供精细的标签以实现最佳性能。为了解决这个问题，我们提出了 PseudoCell，一个对象检测框架，可以自动检测WSI中的中心blast细胞。这个框架利用病理学家提供的中心blast标签，并将其与使用细胞形态特征所获取的假性负标签相结合。通过使用PseudoCell，病理学家的工作负担可以减少，因为它准确地缩小了需要其注意的区域。根据信任阈值，PseudoCell可以从WSI中消除58.18-99.35%的非中心blast区域。本研究提供了不需要病理学家精细标签的实用中心blast预屏检测方法。详细的实现方法请参考讨论部分。
</details></li>
</ul>
<hr>
<h2 id="EffLiFe-Efficient-Light-Field-Generation-via-Hierarchical-Sparse-Gradient-Descent"><a href="#EffLiFe-Efficient-Light-Field-Generation-via-Hierarchical-Sparse-Gradient-Descent" class="headerlink" title="EffLiFe: Efficient Light Field Generation via Hierarchical Sparse Gradient Descent"></a>EffLiFe: Efficient Light Field Generation via Hierarchical Sparse Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03017">http://arxiv.org/abs/2307.03017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijie Deng, Lei Han, Tianpeng Lin, Lin Li, Jinzhi Zhang, Lu Fang</li>
<li>for: 提高xtended reality（XR）技术中的实时光场生成速度，尤其是从稀疏视角输入中生成高质量的光场。</li>
<li>methods: 基于多平面图像（MPI）的彩色环境中的稀疏梯度下降（HSGD）方法，以实时生成高质量的光场。</li>
<li>results: 比较state-of-the-art offline方法100倍 faster的速度和相比其他在线方法提供2dB更高的PSNR表现。<details>
<summary>Abstract</summary>
With the rise of Extended Reality (XR) technology, there is a growing need for real-time light field generation from sparse view inputs. Existing methods can be classified into offline techniques, which can generate high-quality novel views but at the cost of long inference/training time, and online methods, which either lack generalizability or produce unsatisfactory results. However, we have observed that the intrinsic sparse manifold of Multi-plane Images (MPI) enables a significant acceleration of light field generation while maintaining rendering quality. Based on this insight, we introduce EffLiFe, a novel light field optimization method, which leverages the proposed Hierarchical Sparse Gradient Descent (HSGD) to produce high-quality light fields from sparse view images in real time. Technically, the coarse MPI of a scene is first generated using a 3D CNN, and it is further sparsely optimized by focusing only on important MPI gradients in a few iterations. Nevertheless, relying solely on optimization can lead to artifacts at occlusion boundaries. Therefore, we propose an occlusion-aware iterative refinement module that removes visual artifacts in occluded regions by iteratively filtering the input. Extensive experiments demonstrate that our method achieves comparable visual quality while being 100x faster on average than state-of-the-art offline methods and delivering better performance (about 2 dB higher in PSNR) compared to other online approaches.
</details>
<details>
<summary>摘要</summary>
随着扩展现实（XR）技术的发展，需要实时生成高质量的场景灯场。现有方法可以分为线上方法和线下方法两类，线下方法可以生成高质量的新视图，但是需要长时间的推理/训练时间，而线上方法则缺乏通用性或生成结果不 satisfactory。然而，我们发现了场景多平面图（MPI）的内在稀畴推导，可以大幅加速场景灯场生成，同时保持渲染质量。基于这一点，我们提出了EffLiFe，一种新的场景灯场优化方法，利用我们提出的层次稀畴梯度下降（HSGD）来从稀畴视图图像中生成高质量的场景灯场，并在实时中完成。技术上，首先使用3D CNN生成场景的粗糙MPI，然后通过稀畴优化，只对场景中重要的MPI梯度进行几次迭代。然而，仅仅通过优化无法在 occlusion 边界处消除视觉遮挡。因此，我们提出了 occlusion-aware 迭代纠正模块，通过迭代筛选输入，消除 occlusion 区域中的视觉遮挡。广泛的实验表明，我们的方法可以与现状的线下方法相比，提供更好的视觉质量，同时在实时中完成，相比之下，其速度为100倍。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-learning-via-inter-modal-reconstruction-and-feature-projection-networks-for-label-efficient-3D-to-2D-segmentation"><a href="#Self-supervised-learning-via-inter-modal-reconstruction-and-feature-projection-networks-for-label-efficient-3D-to-2D-segmentation" class="headerlink" title="Self-supervised learning via inter-modal reconstruction and feature projection networks for label-efficient 3D-to-2D segmentation"></a>Self-supervised learning via inter-modal reconstruction and feature projection networks for label-efficient 3D-to-2D segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03008">http://arxiv.org/abs/2307.03008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/j-morano/multimodal-ssl-fpn">https://github.com/j-morano/multimodal-ssl-fpn</a></li>
<li>paper_authors: José Morano, Guilherme Aresta, Dmitrii Lachinov, Julia Mai, Ursula Schmidt-Erfurth, Hrvoje Bogunović<br>for:这篇论文主要是为了提出一种新的深度学习方法，以便在医疗图像分割任务中提高效率，减轻医生的工作负担。methods:该方法使用了一种新的卷积神经网络（CNN）和自助学习（SSL）方法，其中的3D encoder和2D decoder被连接了一些新的3D-to-2D块。而SSL方法则是通过不同维度的图像对准来实现对模式的重构。results:该方法在两个临床有 relevance 的任务中（抗纤维性atrophy和Reticular Pseudodrusen）中得到了显著的提高，比如在有限的标注数据情况下，该方法可以提高达到8%的Dice score。此外，SSL方法可以进一步提高这个性能，并且我们证明了SSL是无论网络架构是多少都有利。<details>
<summary>Abstract</summary>
Deep learning has become a valuable tool for the automation of certain medical image segmentation tasks, significantly relieving the workload of medical specialists. Some of these tasks require segmentation to be performed on a subset of the input dimensions, the most common case being 3D-to-2D. However, the performance of existing methods is strongly conditioned by the amount of labeled data available, as there is currently no data efficient method, e.g. transfer learning, that has been validated on these tasks. In this work, we propose a novel convolutional neural network (CNN) and self-supervised learning (SSL) method for label-efficient 3D-to-2D segmentation. The CNN is composed of a 3D encoder and a 2D decoder connected by novel 3D-to-2D blocks. The SSL method consists of reconstructing image pairs of modalities with different dimensionality. The approach has been validated in two tasks with clinical relevance: the en-face segmentation of geographic atrophy and reticular pseudodrusen in optical coherence tomography. Results on different datasets demonstrate that the proposed CNN significantly improves the state of the art in scenarios with limited labeled data by up to 8% in Dice score. Moreover, the proposed SSL method allows further improvement of this performance by up to 23%, and we show that the SSL is beneficial regardless of the network architecture.
</details>
<details>
<summary>摘要</summary>
深度学习已成为医疗影像分割任务自动化的有价值工具，减轻医生的工作负担。一些这些任务需要在输入维度中进行分割，最常见的情况是3D-to-2D。然而，现有方法的性能受到可用标注数据的限制，例如没有数据效果的转移学习方法，即使是在这些任务上。在这种情况下，我们提出了一种新的卷积神经网络（CNN）和自我超vised学习（SSL）方法，用于标签效率3D-to-2D分割。CNN由3D编码器和2D解码器连接的新3D-to-2D块组成。SSL方法是通过不同维度的图像对象来重建图像对。我们在两个临床有关的任务中进行验证：扫描型atrophy和reticular pseudodrusen的en-face分割。不同的数据集上的结果表明，我们提出的CNN可以在有限标注数据的情况下提高状态的艺术到8%的Dice分数。此外，我们还证明了SSL方法可以进一步改进这种性能，并且SSL是无论网络架构如何的有利。
</details></li>
</ul>
<hr>
<h2 id="Fourier-Net-Leveraging-Band-Limited-Representation-for-Efficient-3D-Medical-Image-Registration"><a href="#Fourier-Net-Leveraging-Band-Limited-Representation-for-Efficient-3D-Medical-Image-Registration" class="headerlink" title="Fourier-Net+: Leveraging Band-Limited Representation for Efficient 3D Medical Image Registration"></a>Fourier-Net+: Leveraging Band-Limited Representation for Efficient 3D Medical Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02997">http://arxiv.org/abs/2307.02997</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xi-jia/fourier-net">https://github.com/xi-jia/fourier-net</a></li>
<li>paper_authors: Xi Jia, Alexander Thorley, Alberto Gomez, Wenqi Lu, Dipak Kotecha, Jinming Duan</li>
<li>for: 这个论文是为了提高无监督的影像注册过程中的简洁场位数据运算效率，使用U-Net类型网络来预测高分辨率三维影像资料中的简洁场位数据。</li>
<li>methods: 我们首先提出了Fourier-Net，它取代了成本高的U-Net类型网络的膨胀路径，并使用一个无parameter的模型驱动解oder。相反于直接预测全分辨率的简洁场位数据，Fourier-Net学习了对应到对应的对角域 Fouriertransform中的低维度表示。然后我们将Fourier-Net发展为Fourier-Net+，它还接受了对应的对角域像素表示，并进一步删减U-Net类型网络的收缩路径中的卷积层数量。最后，我们提出了对Fourier-Net+的协调版本，以提高注册性能。</li>
<li>results: 我们使用三个 dataset 进行评估，其中包括CT scan和MRI等类型的影像资料。在这些 dataset 上，我们的提案方法均能与现有的州��♀�方法相比，并且具有更快的推论速度、更低的内存占用量和更少的乘法加法操作。这些小型的computational cost使我们的Fourier-Net+在低VRAM GPU上能够高效地训练大规模3D注册。我们的代码公开在 \url{<a target="_blank" rel="noopener" href="https://github.com/xi-jia/Fourier-Net%7D%E3%80%82">https://github.com/xi-jia/Fourier-Net}。</a><details>
<summary>Abstract</summary>
U-Net style networks are commonly utilized in unsupervised image registration to predict dense displacement fields, which for high-resolution volumetric image data is a resource-intensive and time-consuming task. To tackle this challenge, we first propose Fourier-Net, which replaces the costly U-Net style expansive path with a parameter-free model-driven decoder. Instead of directly predicting a full-resolution displacement field, our Fourier-Net learns a low-dimensional representation of the displacement field in the band-limited Fourier domain which our model-driven decoder converts to a full-resolution displacement field in the spatial domain. Expanding upon Fourier-Net, we then introduce Fourier-Net+, which additionally takes the band-limited spatial representation of the images as input and further reduces the number of convolutional layers in the U-Net style network's contracting path. Finally, to enhance the registration performance, we propose a cascaded version of Fourier-Net+. We evaluate our proposed methods on three datasets, on which our proposed Fourier-Net and its variants achieve comparable results with current state-of-the art methods, while exhibiting faster inference speeds, lower memory footprint, and fewer multiply-add operations. With such small computational cost, our Fourier-Net+ enables the efficient training of large-scale 3D registration on low-VRAM GPUs. Our code is publicly available at \url{https://github.com/xi-jia/Fourier-Net}.
</details>
<details>
<summary>摘要</summary>
通常，U-Net风格的网络在无监督图像注册中预测密集偏移场景，对高分辨率三维图像数据来说是一项资源挺大和时间消耗的任务。为解决这个挑战，我们首先提出了Fourier-Net，它将U-Net风格的昂贵的扩展路径换为无参数的模型驱动解码器。而不是直接预测全分辨率偏移场景，Fourier-Net将学习带有限 Fourier频域的低维度偏移场景表示。我们的模型驱动解码器将这个低维度表示转换为全分辨率偏移场景。在这个基础上，我们再次引入Fourier-Net+，它还将带有限空间表示的图像进行输入，并将U-Net风格网络的收缩路径中的几何层数降低。最后，我们提出了卷积率的缩放版本，以提高注册性能。我们在三个数据集上评估了我们的提议方法，其中Fourier-Net和其 variants与当前状态的方法相当，而且具有更快的推理速度、更低的内存占用量和更少的 multiply-add 操作。这样的小计算成本使得我们的Fourier-Net+可以高效地在低VRAM GPU上进行大规模3D注册的训练。我们的代码公开在 GitHub 上，可以在 \url{https://github.com/xi-jia/Fourier-Net} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-multi-class-Parkinson-disease-classification-using-CNN-and-decision-level-fusion"><a href="#Multi-modal-multi-class-Parkinson-disease-classification-using-CNN-and-decision-level-fusion" class="headerlink" title="Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion"></a>Multi-modal multi-class Parkinson disease classification using CNN and decision level fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02978">http://arxiv.org/abs/2307.02978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sushanta Kumar Sahu, Ananda S. Chowdhury</li>
<li>for: 本研究旨在提出一种直接三类PD分类方法，使用两种不同的感知模式，即MRI和DTI。</li>
<li>methods: 本研究使用白 matter和灰 matter从MRI和扩展纹理度和mean diffusivity从DTI来实现目标。四个独立的CNN模型在上述四种数据上进行训练。决策层使用优化的Weighted Average fusion技术进行数据融合。</li>
<li>results: 在公共可用的PPMI数据库上，本研究实现了95.53%的直接三类分类精度，用于PD、HC和SWEDD的分类。对于PD、HC和SWEDD的分类，进行了广泛的比较，包括一系列的剥夺研究，明显地验证了我们的提议的有效性。<details>
<summary>Abstract</summary>
Parkinson disease is the second most common neurodegenerative disorder, as reported by the World Health Organization. In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit and Healthy Control. We use white matter and gray matter from the MRI and fractional anisotropy and mean diffusivity from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53 percentage for the direct three class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.
</details>
<details>
<summary>摘要</summary>
parkinson病是第二常见的神经退化疾病，根据世界卫生组织的报告。在这篇论文中，我们提出了直接的三类PD分类方法，使用两种不同的感知模式，即MRI和DTI。我们使用MRI中的白 matter和灰 matter，以及DTI中的方向强度和mean扩散率来实现我们的目标。我们训练了四个独立的CNN模型。在决策层，四个CNN模型的输出使用最佳权重平均融合技术进行融合。我们在公共可用PPMI数据库上实现了95.53%的直接三类分类精度。经过了详细的对比，包括一系列剥离研究，我们的提议的解决方案得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Cross-Spatial-Pixel-Integration-and-Cross-Stage-Feature-Fusion-Based-Transformer-Network-for-Remote-Sensing-Image-Super-Resolution"><a href="#Cross-Spatial-Pixel-Integration-and-Cross-Stage-Feature-Fusion-Based-Transformer-Network-for-Remote-Sensing-Image-Super-Resolution" class="headerlink" title="Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution"></a>Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network for Remote Sensing Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02974">http://arxiv.org/abs/2307.02974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuting Lu, Lingtong Min, Binglu Wang, Le Zheng, Xiaoxu Wang, Yongqiang Zhao, Teng Long</li>
<li>for: 提高卫星图像的空间细节和质量</li>
<li>methods: 使用Transformer架构，并采用 crossed-spatial pixel integration attention和cross-stage feature fusion attention来提高模型的全像global cognition和特征表达能力</li>
<li>results: 在多个标准 dataset上进行了广泛的实验，并证明了我们提posed的SPIFFNet在量化指标和视觉质量上比现有方法更高的性能<details>
<summary>Abstract</summary>
Remote sensing image super-resolution (RSISR) plays a vital role in enhancing spatial detials and improving the quality of satellite imagery. Recently, Transformer-based models have shown competitive performance in RSISR. To mitigate the quadratic computational complexity resulting from global self-attention, various methods constrain attention to a local window, enhancing its efficiency. Consequently, the receptive fields in a single attention layer are inadequate, leading to insufficient context modeling. Furthermore, while most transform-based approaches reuse shallow features through skip connections, relying solely on these connections treats shallow and deep features equally, impeding the model's ability to characterize them. To address these issues, we propose a novel transformer architecture called Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network (SPIFFNet) for RSISR. Our proposed model effectively enhances global cognition and understanding of the entire image, facilitating efficient integration of features cross-stages. The model incorporates cross-spatial pixel integration attention (CSPIA) to introduce contextual information into a local window, while cross-stage feature fusion attention (CSFFA) adaptively fuses features from the previous stage to improve feature expression in line with the requirements of the current stage. We conducted comprehensive experiments on multiple benchmark datasets, demonstrating the superior performance of our proposed SPIFFNet in terms of both quantitative metrics and visual quality when compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
卫星图像超分辨率（RSISR）在提高空间细节和卫星图像质量方面扮演着重要的角色。最近，基于Transformer模型的方法在RSISR中表现竞争力强。但由于全球自注意的 quadratic computational complexity， Various methods constrain attention to a local window, enhancing its efficiency。然而，单个注意层的接受场所不够，导致Context模型缺乏。另外，大多数transform基本方法通过 skip connections 重复 shallow features，但是这些连接只是对 shallow 和 deep features进行重复，导致模型无法区分它们。为了解决这些问题，我们提出了一种新的Transformer网络模型，即 Cross-Spatial Pixel Integration and Cross-Stage Feature Fusion Based Transformer Network（SPIFFNet）。我们的提议模型可以有效地提高全图像的全局认知和理解，并且可以有效地进行 across-stages 的特征集成。模型包括 cross-spatial pixel integration attention（CSPIA），可以将contextual information引入到当前窗口中，以及 across-stage feature fusion attention（CSFFA），可以适应当前阶段的特征需求，进行特征表达。我们在多个benchmark数据集上进行了广泛的实验，并证明了我们提出的SPIFFNet在量值指标和视觉质量方面与现有方法相比，表现出了更高的性能。
</details></li>
</ul>
<hr>
<h2 id="SegNetr-Rethinking-the-local-global-interactions-and-skip-connections-in-U-shaped-networks"><a href="#SegNetr-Rethinking-the-local-global-interactions-and-skip-connections-in-U-shaped-networks" class="headerlink" title="SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks"></a>SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02953">http://arxiv.org/abs/2307.02953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junlong Cheng, Chengrui Gao, Fengjie Wang, Min Zhu</li>
<li>for: 这篇论文主要针对医疗影像分类 задачі提出了一个轻量级的网络模型，即SegNetr。</li>
<li>methods: 本文提出了一个新的SegNetr封页，可以在任何阶段进行本地-全球互动，并具有线性复杂度。此外， authors还设计了一个通用的信息保留skip连接（IRSC），以保持遮盾对象特征的空间位置信息，并与解oder特征进行精准融合。</li>
<li>results: 作者将SegNetr应用到四个主流的医疗影像分类 datasets上，与常用的U-Net模型相比，SegNetr的参数数量和GFLOPs都比相对少，但是其分类性能与现有的方法相对，并且可以适用于其他U-shaped网络中优化分类性能。<details>
<summary>Abstract</summary>
Recently, U-shaped networks have dominated the field of medical image segmentation due to their simple and easily tuned structure. However, existing U-shaped segmentation networks: 1) mostly focus on designing complex self-attention modules to compensate for the lack of long-term dependence based on convolution operation, which increases the overall number of parameters and computational complexity of the network; 2) simply fuse the features of encoder and decoder, ignoring the connection between their spatial locations. In this paper, we rethink the above problem and build a lightweight medical image segmentation network, called SegNetr. Specifically, we introduce a novel SegNetr block that can perform local-global interactions dynamically at any stage and with only linear complexity. At the same time, we design a general information retention skip connection (IRSC) to preserve the spatial location information of encoder features and achieve accurate fusion with the decoder features. We validate the effectiveness of SegNetr on four mainstream medical image segmentation datasets, with 59\% and 76\% fewer parameters and GFLOPs than vanilla U-Net, while achieving segmentation performance comparable to state-of-the-art methods. Notably, the components proposed in this paper can be applied to other U-shaped networks to improve their segmentation performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>They often rely on complex self-attention modules to compensate for the lack of long-term dependence in convolutional operations, which increases the number of parameters and computational complexity of the network.2. They simply fuse the features of the encoder and decoder, ignoring the spatial relationships between them.In this paper, we aim to address these issues and propose a lightweight medical image segmentation network called SegNetr. Our approach includes:1. A novel SegNetr block that can perform local-global interactions dynamically at any stage with linear complexity.2. A general information retention skip connection (IRSC) to preserve the spatial location information of encoder features and achieve accurate fusion with the decoder features.We validate the effectiveness of SegNetr on four mainstream medical image segmentation datasets, achieving segmentation performance comparable to state-of-the-art methods with 59% and 76% fewer parameters and GFLOPs than vanilla U-Net. The proposed components can be applied to other U-shaped networks to improve their segmentation performance.</details></li>
</ol>
<hr>
<h2 id="DisAsymNet-Disentanglement-of-Asymmetrical-Abnormality-on-Bilateral-Mammograms-using-Self-adversarial-Learning"><a href="#DisAsymNet-Disentanglement-of-Asymmetrical-Abnormality-on-Bilateral-Mammograms-using-Self-adversarial-Learning" class="headerlink" title="DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning"></a>DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms using Self-adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02935">http://arxiv.org/abs/2307.02935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Wang, Tao Tan, Yuan Gao, Luyi Han, Tianyu Zhang, Chunyao Lu, Regina Beets-Tan, Ruisheng Su, Ritse Mann</li>
<li>for: 本研究旨在提供一个框架，以帮助解释胸部X线成像中的异常性。</li>
<li>methods: 本研究使用了偏 asymmetrical abnormality transformer 驱动的自我对抗学习，将异常性与正常成像分离。同时，我们的方法被部分指引由随机生成的异常性。</li>
<li>results: 我们在三个公开数据集和一个内部数据集上进行实验，结果显示我们的方法在异常性分类、分 segmentation 和本地化任务中均能超越现有的方法。此外，重建的正常成像可以提供更好的诊断视觉参考。<details>
<summary>Abstract</summary>
Asymmetry is a crucial characteristic of bilateral mammograms (Bi-MG) when abnormalities are developing. It is widely utilized by radiologists for diagnosis. The question of 'what the symmetrical Bi-MG would look like when the asymmetrical abnormalities have been removed ?' has not yet received strong attention in the development of algorithms on mammograms. Addressing this question could provide valuable insights into mammographic anatomy and aid in diagnostic interpretation. Hence, we propose a novel framework, DisAsymNet, which utilizes asymmetrical abnormality transformer guided self-adversarial learning for disentangling abnormalities and symmetric Bi-MG. At the same time, our proposed method is partially guided by randomly synthesized abnormalities. We conduct experiments on three public and one in-house dataset, and demonstrate that our method outperforms existing methods in abnormality classification, segmentation, and localization tasks. Additionally, reconstructed normal mammograms can provide insights toward better interpretable visual cues for clinical diagnosis. The code will be accessible to the public.
</details>
<details>
<summary>摘要</summary>
bilateral mammograms (Bi-MG) 的非对称性是一个重要的特征，用于诊断。然而，关于“正常的对称 Bi-MG 看起来如何？”这个问题在算法开发中还没有得到强调。我们提出了一种新的框架，DisAsymNet，它使用对称异常变换导向自 adversarial learning 来分离异常和对称 Bi-MG。同时，我们的提议方法受到随机生成的异常影响。我们在三个公共数据集和一个内部数据集上进行了实验，并证明了我们的方法在异常分类、 segmentation 和本地化任务中表现出色。此外，重建的正常床静图可以提供更好的诊断视觉cue。代码将公开。
</details></li>
</ul>
<hr>
<h2 id="A-Real-time-Human-Pose-Estimation-Approach-for-Optimal-Sensor-Placement-in-Sensor-based-Human-Activity-Recognition"><a href="#A-Real-time-Human-Pose-Estimation-Approach-for-Optimal-Sensor-Placement-in-Sensor-based-Human-Activity-Recognition" class="headerlink" title="A Real-time Human Pose Estimation Approach for Optimal Sensor Placement in Sensor-based Human Activity Recognition"></a>A Real-time Human Pose Estimation Approach for Optimal Sensor Placement in Sensor-based Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02906">http://arxiv.org/abs/2307.02906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Orhan Konak, Alexander Wischmann, Robin van de Water, Bert Arnrich</li>
<li>for: 这篇论文旨在提供一种新的方法来确定人体活动识别中最佳的传感器位置，以便实现数据隐私和多模态识别。</li>
<li>methods: 该方法使用实时的2D pose估计技术，基于视频记录target活动来 derivation skeleton数据，并使用这些数据来确定最佳的传感器位置。</li>
<li>results: 我们通过一个可行性研究，使用各种感知器来监测13种不同的活动，并证明了视处理器方法的效果相当于深度学习方法。这项研究对人体活动识别领域带来了重要的进步，提供了一种轻量级、在设备上进行的传感器位置确定方法，以实现数据隐私和多模态识别。<details>
<summary>Abstract</summary>
Sensor-based Human Activity Recognition facilitates unobtrusive monitoring of human movements. However, determining the most effective sensor placement for optimal classification performance remains challenging. This paper introduces a novel methodology to resolve this issue, using real-time 2D pose estimations derived from video recordings of target activities. The derived skeleton data provides a unique strategy for identifying the optimal sensor location. We validate our approach through a feasibility study, applying inertial sensors to monitor 13 different activities across ten subjects. Our findings indicate that the vision-based method for sensor placement offers comparable results to the conventional deep learning approach, demonstrating its efficacy. This research significantly advances the field of Human Activity Recognition by providing a lightweight, on-device solution for determining the optimal sensor placement, thereby enhancing data anonymization and supporting a multimodal classification approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传感器基于人体活动识别可以实现不侵入式监测人体运动。然而，确定最佳传感器位置以获得最佳分类性能仍然是一个挑战。这篇论文介绍了一种新的方法，使用实时2D姿态估计来确定最佳传感器位置。从视频记录中获取的skeleton数据提供了一种独特的策略来识别最佳传感器位置。我们通过实验验证了我们的方法，使用抗 гравитацион acceleration sensor进行13种活动的监测，并对10名参与者进行了评估。我们的结果表明，视觉基于的传感器位置选择方法与传统的深度学习方法相当，这表明了其效果。这项研究对人体活动识别领域发展了重要的进步，提供了轻量级、在设备上进行的传感器位置选择方法，从而提高数据匿名化和支持多模态分类approach。
</details></li>
</ul>
<hr>
<h2 id="RefVSR-Exploiting-Reference-Inputs-for-Reference-based-Video-Super-resolution"><a href="#RefVSR-Exploiting-Reference-Inputs-for-Reference-based-Video-Super-resolution" class="headerlink" title="RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution"></a>RefVSR++: Exploiting Reference Inputs for Reference-based Video Super-resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02897">http://arxiv.org/abs/2307.02897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zou, Masanori Suganuma, Takayuki Okatani<br>for: 这paper是为了提高视频uperResolution的图像质量而写的。methods: 这paper使用了Reference-based SuperResolution和video SuperResolution两种方法，并将它们结合在一起以提高图像质量。results: 这paper实验表明，使用RefVSR++方法可以提高图像质量，比RefVSR方法高出1dB的PSNR。<details>
<summary>Abstract</summary>
Smartphones equipped with a multi-camera system comprising multiple cameras with different field-of-view (FoVs) are becoming more prevalent. These camera configurations are compatible with reference-based SR and video SR, which can be executed simultaneously while recording video on the device. Thus, combining these two SR methods can improve image quality. Recently, Lee et al. have presented such a method, RefVSR. In this paper, we consider how to optimally utilize the observations obtained, including input low-resolution (LR) video and reference (Ref) video. RefVSR extends conventional video SR quite simply, aggregating the LR and Ref inputs over time in a single bidirectional stream. However, considering the content difference between LR and Ref images due to their FoVs, we can derive the maximum information from the two image sequences by aggregating them independently in the temporal direction. Then, we propose an improved method, RefVSR++, which can aggregate two features in parallel in the temporal direction, one for aggregating the fused LR and Ref inputs and the other for Ref inputs over time. Furthermore, we equip RefVSR++ with enhanced mechanisms to align image features over time, which is the key to the success of video SR. We experimentally show that RefVSR++ outperforms RefVSR by over 1dB in PSNR, achieving the new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
智能手机配备多镜头系统，包括多个镜头不同视场（FoV），变得更加普遍。这些镜头配置与参考基 SR 和视频 SR 兼容，可以同时进行视频记录设备上的实时执行。因此，将这两种 SR 方法结合可以提高图像质量。李等人已经提出了这种方法，即 RefVSR。在这篇论文中，我们考虑了如何优化获得的观察结果，包括输入低分辨率（LR）视频和参考（Ref）视频。RefVSR 将LR 和 Ref 输入简单地聚合在一起，并在时间方向上进行单向bidirectional流。但是，由于LR 和 Ref 图像的内容差异，我们可以在两个图像序列之间独立地聚合它们，从而Derive最大的信息。然后，我们提出了改进的方法，即 RefVSR++，它可以在时间方向上并行聚合两个特征，一个用于聚合混合LR 和 Ref 输入，另一个用于Ref 输入的时间方向上的聚合。此外，我们为 RefVSR++ 提供了进一步的时间对齐机制，这是图像SR 的关键。我们实验表明，RefVSR++ 可以超过 RefVSR 的1dB PSNR，达到新的状态态-艺。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-and-Semantic-Descriptions-of-Image-Manifolds-and-Their-Applications"><a href="#Probabilistic-and-Semantic-Descriptions-of-Image-Manifolds-and-Their-Applications" class="headerlink" title="Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications"></a>Probabilistic and Semantic Descriptions of Image Manifolds and Their Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02881">http://arxiv.org/abs/2307.02881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Tu, Zhaoyuan Yang, Richard Hartley, Zhiwei Xu, Jing Zhang, Dylan Campbell, Jaskirat Singh, Tianyu Wang</li>
<li>for: 本研究旨在透过估计图像诸元函数，实现图像资料的统计分布模型。</li>
<li>methods: 本研究使用了常见的生成模型，如泛型流和扩散模型，以模型图像资料的分布。</li>
<li>results: 本研究发现，使用这些生成模型可以建立对抗攻击性质的防御措施，并且可以使用 semantic interpretations 来描述图像资料的分布。<details>
<summary>Abstract</summary>
This paper begins with a description of methods for estimating probability density functions for images that reflects the observation that such data is usually constrained to lie in restricted regions of the high-dimensional image space - not every pattern of pixels is an image. It is common to say that images lie on a lower-dimensional manifold in the high-dimensional space. However, although images may lie on such lower-dimensional manifolds, it is not the case that all points on the manifold have an equal probability of being images. Images are unevenly distributed on the manifold, and our task is to devise ways to model this distribution as a probability distribution. In pursuing this goal, we consider generative models that are popular in AI and computer vision community. For our purposes, generative/probabilistic models should have the properties of 1) sample generation: it should be possible to sample from this distribution according to the modelled density function, and 2) probability computation: given a previously unseen sample from the dataset of interest, one should be able to compute the probability of the sample, at least up to a normalising constant. To this end, we investigate the use of methods such as normalising flow and diffusion models. We then show that such probabilistic descriptions can be used to construct defences against adversarial attacks. In addition to describing the manifold in terms of density, we also consider how semantic interpretations can be used to describe points on the manifold. To this end, we consider an emergent language framework which makes use of variational encoders to produce a disentangled representation of points that reside on a given manifold. Trajectories between points on a manifold can then be described in terms of evolving semantic descriptions.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文开始介绍了图像的概率密度函数估计方法，因为数据通常会受到高维图像空间中的限制，不是所有像素点都是图像。人们常说图像处在一个Lower-dimensional manifold上，但不是所有 manifold 上的点都有相同的概率成为图像。我们的目标是使用生成/概率模型来模型这种分布，这些模型应具有以下两个特性：1）样本生成和2）概率计算。我们研究使用normalizing flow和diffusion模型来实现这一目标。这些概率描述可以用来构建防御性 adversarial attack。此外，我们还考虑使用semantic interpretations来描述 manifold 上的点，使用一种 emergent language 框架，该框架使用variational encoders来生成一个分离的表示图像点。在 manifold 上的点之间的路径可以用 evolving semantic descriptions 来描述。
</details></li>
</ul>
<hr>
<h2 id="Towards-accurate-instance-segmentation-in-large-scale-LiDAR-point-clouds"><a href="#Towards-accurate-instance-segmentation-in-large-scale-LiDAR-point-clouds" class="headerlink" title="Towards accurate instance segmentation in large-scale LiDAR point clouds"></a>Towards accurate instance segmentation in large-scale LiDAR point clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02877">http://arxiv.org/abs/2307.02877</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bxiang233/panopticsegforlargescalepointcloud">https://github.com/bxiang233/panopticsegforlargescalepointcloud</a></li>
<li>paper_authors: Binbin Xiang, Torben Peters, Theodora Kontogianni, Frawa Vetterli, Stefano Puliti, Rasmus Astrup, Konrad Schindler</li>
<li>for: 提高outdoor scene理解的精度，从城市地图到森林管理。</li>
<li>methods: 利用多种学习的点嵌入，进行精细的分割和归一化。</li>
<li>results: 提高了实例分割的精度，可以更好地应用于 inventory 和管理 类应用程序。<details>
<summary>Abstract</summary>
Panoptic segmentation is the combination of semantic and instance segmentation: assign the points in a 3D point cloud to semantic categories and partition them into distinct object instances. It has many obvious applications for outdoor scene understanding, from city mapping to forest management. Existing methods struggle to segment nearby instances of the same semantic category, like adjacent pieces of street furniture or neighbouring trees, which limits their usability for inventory- or management-type applications that rely on object instances. This study explores the steps of the panoptic segmentation pipeline concerned with clustering points into object instances, with the goal to alleviate that bottleneck. We find that a carefully designed clustering strategy, which leverages multiple types of learned point embeddings, significantly improves instance segmentation. Experiments on the NPM3D urban mobile mapping dataset and the FOR-instance forest dataset demonstrate the effectiveness and versatility of the proposed strategy.
</details>
<details>
<summary>摘要</summary>
pan-opeptic segmentation是semantic和instance segmentation的组合：将3D点云中的点分配到semantic类别并将其 partition into distinct object instances。它在户外场景理解方面具有广泛的应用，从城市地图到森林管理。现有方法在邻近同semantic category的实例上具有 segmentation 瓶颈，例如邻近的街道家具或邻近的树木，这限制了它们在 inventory-或 management-type 应用中的可用性。本研究探讨了panoptic segmentation管道中关于点集 clustering into object instances的步骤，以解决这个瓶颈。我们发现了一种精心设计的 clustering 策略，该策略利用多种学习的点嵌入，可以有效地提高实例 segmentation。在NPM3D urban mobile mapping dataset和FOR-instance forest dataset上进行了实验，并证明了我们的策略的有效性和多样性。
</details></li>
</ul>
<hr>
<h2 id="Reference-based-Motion-Blur-Removal-Learning-to-Utilize-Sharpness-in-the-Reference-Image"><a href="#Reference-based-Motion-Blur-Removal-Learning-to-Utilize-Sharpness-in-the-Reference-Image" class="headerlink" title="Reference-based Motion Blur Removal: Learning to Utilize Sharpness in the Reference Image"></a>Reference-based Motion Blur Removal: Learning to Utilize Sharpness in the Reference Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02875">http://arxiv.org/abs/2307.02875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zou, Masanori Suganuma, Takayuki Okatani</li>
<li>for: 提高弱暗图像的清晰度</li>
<li>methods: 使用多个图像，包括一个参考图像，以提高图像清晰度</li>
<li>results: 实验结果显示提出的方法有效地提高图像的清晰度<details>
<summary>Abstract</summary>
Despite the recent advancement in the study of removing motion blur in an image, it is still hard to deal with strong blurs. While there are limits in removing blurs from a single image, it has more potential to use multiple images, e.g., using an additional image as a reference to deblur a blurry image. A typical setting is deburring an image using a nearby sharp image(s) in a video sequence, as in the studies of video deblurring. This paper proposes a better method to use the information present in a reference image. The method does not need a strong assumption on the reference image. We can utilize an alternative shot of the identical scene, just like in video deblurring, or we can even employ a distinct image from another scene. Our method first matches local patches of the target and reference images and then fuses their features to estimate a sharp image. We employ a patch-based feature matching strategy to solve the difficult problem of matching the blurry image with the sharp reference. Our method can be integrated into pre-existing networks designed for single image deblurring. The experimental results show the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
尽管最近在图像去挠模块中得到了进步，但强挠仍然困难去处理。尽管单个图像的挠模块有限，但使用多个图像可以更有可能性地去挠模块。例如，在视频序列中使用邻近的锐化图像来去挠模块。这篇论文提出了更好地使用参考图像中的信息。我们不需要强制对参考图像进行假设。我们可以使用视频序列中的另一幅锐化图像作为参考图像，或者我们可以使用另一幅来自另一个场景的图像。我们的方法首先匹配本地补丁图像的目标和参考图像的地方，然后将其特征进行融合，以便估算一个锐化图像。我们使用补丁图像基于特征匹配策略来解决图像挠模块与锐化图像的困难问题。我们的方法可以与现有的单个图像去挠模块网络集成。实验结果表明我们的方法的效果。
</details></li>
</ul>
<hr>
<h2 id="MomentDiff-Generative-Video-Moment-Retrieval-from-Random-to-Real"><a href="#MomentDiff-Generative-Video-Moment-Retrieval-from-Random-to-Real" class="headerlink" title="MomentDiff: Generative Video Moment Retrieval from Random to Real"></a>MomentDiff: Generative Video Moment Retrieval from Random to Real</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02869">http://arxiv.org/abs/2307.02869</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imccretrieval/momentdiff">https://github.com/imccretrieval/momentdiff</a></li>
<li>paper_authors: Pandeng Li, Chen-Wei Xie, Hongtao Xie, Liming Zhao, Lei Zhang, Yun Zheng, Deli Zhao, Yongdong Zhang</li>
<li>for: 本研究的目的是提出一种高效和普适的视频瞬间检索方法，能够从无 trimmed 视频中提取指定语言描述相应的具体时间段落。</li>
<li>methods: 我们提出了一种生成扩散基于的框架，名为 MomentDiff，它模拟了人类检索过程中的随机浏览和慢步定位。Specifically，我们首先将实际 span 扩散到随机噪声中，然后学习将噪声还原为原始 span 的指导下。这使得模型能够学习一个从随机位置到实际瞬间的映射，从而实现从随机初始化到精准定位的能力。</li>
<li>results: 我们的效果验证结果表明，MomentDiff 在三个公共 benchmark 上都能够准确地检索视频瞬间，并且在我们提出的两个anti-bias dataset上表现出更好的一致性和稳定性。code、模型和anti-bias评价 dataset 都可以在<a target="_blank" rel="noopener" href="https://github.com/IMCCretrieval/MomentDiff">https://github.com/IMCCretrieval/MomentDiff</a> 上下载。<details>
<summary>Abstract</summary>
Video moment retrieval pursues an efficient and generalized solution to identify the specific temporal segments within an untrimmed video that correspond to a given language description. To achieve this goal, we provide a generative diffusion-based framework called MomentDiff, which simulates a typical human retrieval process from random browsing to gradual localization. Specifically, we first diffuse the real span to random noise, and learn to denoise the random noise to the original span with the guidance of similarity between text and video. This allows the model to learn a mapping from arbitrary random locations to real moments, enabling the ability to locate segments from random initialization. Once trained, MomentDiff could sample random temporal segments as initial guesses and iteratively refine them to generate an accurate temporal boundary. Different from discriminative works (e.g., based on learnable proposals or queries), MomentDiff with random initialized spans could resist the temporal location biases from datasets. To evaluate the influence of the temporal location biases, we propose two anti-bias datasets with location distribution shifts, named Charades-STA-Len and Charades-STA-Mom. The experimental results demonstrate that our efficient framework consistently outperforms state-of-the-art methods on three public benchmarks, and exhibits better generalization and robustness on the proposed anti-bias datasets. The code, model, and anti-bias evaluation datasets are available at https://github.com/IMCCretrieval/MomentDiff.
</details>
<details>
<summary>摘要</summary>
视频时刻段检索寻求一种有效和通用的解决方案，以确定给定语言描述中的具体时刻段 within an untrimmed video。为此，我们提供了一个生成扩散基于的框架 called MomentDiff，它模拟了人类检索过程的一般流程，从随机浏览到渐进的地点化。 Specifically, we first diffuse the real span to random noise, and learn to denoise the random noise to the original span with the guidance of similarity between text and video. This allows the model to learn a mapping from arbitrary random locations to real moments, enabling the ability to locate segments from random initialization. Once trained, MomentDiff could sample random temporal segments as initial guesses and iteratively refine them to generate an accurate temporal boundary. 不同于掌学工作（例如基于学习的提案或查询），MomentDiff with random initialized spans could resist the temporal location biases from datasets. To evaluate the influence of the temporal location biases, we propose two anti-bias datasets with location distribution shifts, named Charades-STA-Len and Charades-STA-Mom. The experimental results demonstrate that our efficient framework consistently outperforms state-of-the-art methods on three public benchmarks, and exhibits better generalization and robustness on the proposed anti-bias datasets. The code, model, and anti-bias evaluation datasets are available at https://github.com/IMCCretrieval/MomentDiff.
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Look-at-the-Current-Usage-of-Foundation-Model-for-Dense-Recognition-Task"><a href="#A-Critical-Look-at-the-Current-Usage-of-Foundation-Model-for-Dense-Recognition-Task" class="headerlink" title="A Critical Look at the Current Usage of Foundation Model for Dense Recognition Task"></a>A Critical Look at the Current Usage of Foundation Model for Dense Recognition Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02862">http://arxiv.org/abs/2307.02862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiqi Yang, Atsushi Hashimoto, Yoshitaka Ushiku</li>
<li>for: 本研究目的是对现有的基础模型进行简报调研，以了解它们是否可以应用于不同的下游任务。</li>
<li>methods: 本研究使用了现有的泛型基础模型，并对其进行了简要的调研和实验分析。</li>
<li>results: 研究发现，现有的基础模型可以在不同的下游任务中提供优秀的性能，但是现有的方法并不是最佳的。这些结论可以提供未来基础模型应用下游任务的指导。<details>
<summary>Abstract</summary>
In recent years large model trained on huge amount of cross-modality data, which is usually be termed as foundation model, achieves conspicuous accomplishment in many fields, such as image recognition and generation. Though achieving great success in their original application case, it is still unclear whether those foundation models can be applied to other different downstream tasks. In this paper, we conduct a short survey on the current methods for discriminative dense recognition tasks, which are built on the pretrained foundation model. And we also provide some preliminary experimental analysis of an existing open-vocabulary segmentation method based on Stable Diffusion, which indicates the current way of deploying diffusion model for segmentation is not optimal. This aims to provide insights for future research on adopting foundation model for downstream task.
</details>
<details>
<summary>摘要</summary>
Recently, large models trained on vast amounts of cross-modal data have achieved remarkable success in various fields, such as image recognition and generation. While these foundation models have excelled in their original applications, it remains unclear whether they can be applied to other downstream tasks. In this paper, we provide a brief overview of current methods for discriminative dense recognition tasks built on pre-trained foundation models. Additionally, we present some preliminary experimental analysis of an existing open-vocabulary segmentation method based on Stable Diffusion, which suggests that the current approach to deploying diffusion models for segmentation is not optimal. This aims to provide insights for future research on adopting foundation models for downstream tasks.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other countries. The translation is written in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Deep-Ensemble-Learning-with-Frame-Skipping-for-Face-Anti-Spoofing"><a href="#Deep-Ensemble-Learning-with-Frame-Skipping-for-Face-Anti-Spoofing" class="headerlink" title="Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing"></a>Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02858">http://arxiv.org/abs/2307.02858</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Usman1021/DLE">https://github.com/Usman1021/DLE</a></li>
<li>paper_authors: Usman Muhammad, Md Ziaul Hoque, Mourad Oussalah, Jorma Laaksonen</li>
<li>for: 防止 spoofing 攻击，提高人脸识别系统的安全性。</li>
<li>methods: 利用深度 ensemble 学习模型和帧 skip 机制，从视频中提取人脸动作信息进行预测。</li>
<li>results: 在四个数据集上进行了广泛的实验，并在最复杂的跨数据集测试场景下达到了状态之最高的检测性能（HTER）。<details>
<summary>Abstract</summary>
Face presentation attacks (PA), also known as spoofing attacks, pose a substantial threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems. To mitigate the spoofing risk, several video-based methods have been presented in the literature that analyze facial motion in successive video frames. However, estimating the motion between adjacent frames is a challenging task and requires high computational cost. In this paper, we rephrase the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism. In particular, the proposed frame skipping adopts a uniform sampling approach by dividing the original video into video clips of fixed size. By doing so, every nth frame of the clip is selected to ensure that the temporal patterns can easily be perceived during the training of three different recurrent neural networks (RNNs). Motivated by the performance of individual RNNs, a meta-model is developed to improve the overall detection performance by combining the prediction of individual RNNs. Extensive experiments were performed on four datasets, and state-of-the-art performance is reported on MSU-MFSD (3.12%), Replay-Attack (11.19%), and OULU-NPU (12.23%) databases by using half total error rates (HTERs) in the most challenging cross-dataset testing scenario.
</details>
<details>
<summary>摘要</summary>
面部攻击（PA），也称为伪装攻击，对具有面部识别系统的生物metric系统 pose 了很大的威胁，如访问控制系统、移动支付和身份验证系统。为了减少伪装风险，文献中有许多基于视频的方法进行分析。然而，在Successive video frames中 estimating 面部动作的问题是一项具有高计算成本的任务。在这篇论文中，我们将面部防伪任务重新定义为一个动作预测问题，并引入了一种深度ensemble学习模型和帧跳动机制。具体来说，我们的帧跳动采用了一种均匀采样方法，将原始视频分成固定大小的视频clip。这样，每个n帧的clip中的每一帧都会被选择，以便在训练三个不同的循环神经网络（RNNs）时，能够轻松地感受到时间模式。受到个体RNNs的表现的激励，我们开发了一个meta-模型，以提高总体检测性能。我们对四个数据集进行了广泛的实验，并在MSU-MFSD（3.12%）、Replay-Attack（11.19%）和OULU-NPU（12.23%)数据库上report了最新的状态。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Computer-Aided-Tuberculosis-Diagnosis"><a href="#Revisiting-Computer-Aided-Tuberculosis-Diagnosis" class="headerlink" title="Revisiting Computer-Aided Tuberculosis Diagnosis"></a>Revisiting Computer-Aided Tuberculosis Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02848">http://arxiv.org/abs/2307.02848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Liu, Yu-Huan Wu, Shi-Chen Zhang, Li Liu, Min Wu, Ming-Ming Cheng</li>
<li>For: 这个研究旨在提高计算机支持的肺炎诊断（CTD），使用深度学习。* Methods: 该研究使用了大规模的TB肺炎X射图数据集（TBX11K），并提出了SymFormer模型，该模型通过对称搜索注意力（SymAttention）和对称位置编码（SPE）来学习特征。* Results: 实验显示SymFormer在TBX11K数据集上达到了状态略的性能。<details>
<summary>Abstract</summary>
Tuberculosis (TB) is a major global health threat, causing millions of deaths annually. Although early diagnosis and treatment can greatly improve the chances of survival, it remains a major challenge, especially in developing countries. Recently, computer-aided tuberculosis diagnosis (CTD) using deep learning has shown promise, but progress is hindered by limited training data. To address this, we establish a large-scale dataset, namely the Tuberculosis X-ray (TBX11K) dataset, which contains 11,200 chest X-ray (CXR) images with corresponding bounding box annotations for TB areas. This dataset enables the training of sophisticated detectors for high-quality CTD. Furthermore, we propose a strong baseline, SymFormer, for simultaneous CXR image classification and TB infection area detection. SymFormer incorporates Symmetric Search Attention (SymAttention) to tackle the bilateral symmetry property of CXR images for learning discriminative features. Since CXR images may not strictly adhere to the bilateral symmetry property, we also propose Symmetric Positional Encoding (SPE) to facilitate SymAttention through feature recalibration. To promote future research on CTD, we build a benchmark by introducing evaluation metrics, evaluating baseline models reformed from existing detectors, and running an online challenge. Experiments show that SymFormer achieves state-of-the-art performance on the TBX11K dataset. The data, code, and models will be released.
</details>
<details>
<summary>摘要</summary>
肺炎（TB）是全球主要的健康威胁，每年引起数百万人的死亡。尽管早期诊断和治疗可以大大提高存活的机会，但是在发展中国家，特别是在贫困地区，这是一项重要的挑战。最近，使用深度学习的计算支持肺炎诊断（CTD）已经显示出了承诺，但是进步受到有限的训练数据的限制。为了解决这一问题，我们建立了一个大规模的数据集，即肺炎X射像（TBX11K）数据集，该数据集包含11,200个胸部X射像（CXR）图像，以及对肺炎区域的矩形框标注。这个数据集允许建立高质量的CTD检测器。此外，我们提出了一个强大的基线，即SymFormer，用于同时对CXR图像进行分类和肺炎感染区域检测。SymFormer integrate Symmetric Search Attention（SymAttention）来处理胸部X射像图像的双面对称性，以学习特征。由于CXR图像可能不会严格遵循双面对称性，我们还提出了Symmetric Positional Encoding（SPE）来促进SymAttention通过特征重新定义。为促进未来的CTD研究，我们建立了一个标准套件，包括评价指标、评估基eline模型，以及在线挑战。实验显示，SymFormer在TBX11K数据集上达到了状态畅的性能。数据、代码和模型将被发布。
</details></li>
</ul>
<hr>
<h2 id="Noise-to-Norm-Reconstruction-for-Industrial-Anomaly-Detection-and-Localization"><a href="#Noise-to-Norm-Reconstruction-for-Industrial-Anomaly-Detection-and-Localization" class="headerlink" title="Noise-to-Norm Reconstruction for Industrial Anomaly Detection and Localization"></a>Noise-to-Norm Reconstruction for Industrial Anomaly Detection and Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02836">http://arxiv.org/abs/2307.02836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiqi Deng, Zhiyu Sun, Ruiyan Zhuang, Jun Gong</li>
<li>for: 这篇研究旨在提出一种基于噪音至常平衡的重建方法，用于精确地检测服务器上的异常。</li>
<li>methods: 本研究使用的方法包括多个级别的融合和差分注意模组，实现端对端的检测和定位。</li>
<li>results: 实验结果显示，提案的方法能够很好地重建异常区域为正常模式，并且在MPDD和VisA dataset上取得更竞争性的结果，设置了新的州OF-THE-ART标准。<details>
<summary>Abstract</summary>
Anomaly detection has a wide range of applications and is especially important in industrial quality inspection. Currently, many top-performing anomaly-detection models rely on feature-embedding methods. However, these methods do not perform well on datasets with large variations in object locations. Reconstruction-based methods use reconstruction errors to detect anomalies without considering positional differences between samples. In this study, a reconstruction-based method using the noise-to-norm paradigm is proposed, which avoids the invariant reconstruction of anomalous regions. Our reconstruction network is based on M-net and incorporates multiscale fusion and residual attention modules to enable end-to-end anomaly detection and localization. Experiments demonstrate that the method is effective in reconstructing anomalous regions into normal patterns and achieving accurate anomaly detection and localization. On the MPDD and VisA datasets, our proposed method achieved more competitive results than the latest methods, and it set a new state-of-the-art standard on the MPDD dataset.
</details>
<details>
<summary>摘要</summary>
异常检测有广泛的应用，特别是在工业质量检测中非常重要。目前，许多高性能异常检测模型都采用特征嵌入方法。然而，这些方法在样本位置差异较大的数据集上不太好表现。基于重建Error的方法可以快速检测异常点而无需考虑样本位置的差异。在本研究中，我们提出了基于噪声至 норahlattice的杂合策略，该策略可以避免异常区域的恒定重建。我们的重建网络基于M-net，并包括多scale融合和异常注意模块，以实现端到端异常检测和地图化。实验表明，我们的提议方法可以快速和准确地检测和地图化异常点。在MPDD和VisA数据集上，我们的提议方法比最新的方法更高效，并在MPDD数据集上设置了新的状态标准。
</details></li>
</ul>
<hr>
<h2 id="Sampling-based-Fast-Gradient-Rescaling-Method-for-Highly-Transferable-Adversarial-Attacks"><a href="#Sampling-based-Fast-Gradient-Rescaling-Method-for-Highly-Transferable-Adversarial-Attacks" class="headerlink" title="Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks"></a>Sampling-based Fast Gradient Rescaling Method for Highly Transferable Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02828">http://arxiv.org/abs/2307.02828</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JHL-HUST/S-FGRM">https://github.com/JHL-HUST/S-FGRM</a></li>
<li>paper_authors: Xu Han, Anmin Liu, Chenxuan Yao, Yanbo Fan, Kun He</li>
<li>for: 这个研究目的是提高黑盒攻击的攻击效率和稳定性。</li>
<li>methods: 这个方法使用数据缩寸来取代标志函数，并且提出深度首先抽样法来稳定梯度更新。</li>
<li>results: 实验结果显示，这个方法可以对于黑盒攻击提高攻击效率和稳定性，并且比前state-of-the-art基eline更高。<details>
<summary>Abstract</summary>
Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input. After achieving nearly 100% attack success rates in white-box setting, more focus is shifted to black-box attacks, of which the transferability of adversarial examples has gained significant attention. In either case, the common gradient-based methods generally use the sign function to generate perturbations on the gradient update, that offers a roughly correct direction and has gained great success. But little work pays attention to its possible limitation. In this work, we observe that the deviation between the original gradient and the generated noise may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability. To this end, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM). Specifically, we use data rescaling to substitute the sign function without extra computational cost. We further propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update. Our method could be used in any gradient-based attacks and is extensible to be integrated with various input transformation or ensemble methods to further improve the adversarial transferability. Extensive experiments on the standard ImageNet dataset show that our method could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
在这种情况下，我们提出了一种 Sampling-based Fast Gradient Rescaling Method (S-FGRM)。具体来说，我们使用数据缩放来取代 sign 函数，不需要额外的计算成本。我们还提出了 Depth First Sampling 方法，以消除缩放的波动并稳定梯度更新。我们的方法可以在任何 gradient-based 攻击中使用，并且可以与不同的输入变换或ensemble方法结合使用，以进一步提高攻击性能。我们在标准的 ImageNet 数据集上进行了广泛的实验，结果表明，我们的方法可以很大程度地提高攻击性能，并超越了当前的基eline。
</details></li>
</ul>
<hr>
<h2 id="Bundle-specific-Tractogram-Distribution-Estimation-Using-Higher-order-Streamline-Differential-Equation"><a href="#Bundle-specific-Tractogram-Distribution-Estimation-Using-Higher-order-Streamline-Differential-Equation" class="headerlink" title="Bundle-specific Tractogram Distribution Estimation Using Higher-order Streamline Differential Equation"></a>Bundle-specific Tractogram Distribution Estimation Using Higher-order Streamline Differential Equation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02825">http://arxiv.org/abs/2307.02825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanjing Feng, Lei Xie, Jingqiang Wang, Jianzhong He, Fei Gao</li>
<li>for: 这种诊断方法是为了重建肌肉bundle，尤其是复杂的全球肌肉纤维。</li>
<li>methods: 该方法基于高阶流线差分方程，通过’群集到群集’的方式重建流线集。它还提出了一种全局优化模型来估计束specific tractogram分布函数(BTD)系数，以 characterize 肌肉纤维和束specific tractogram之间的关系。</li>
<li>results: 实验表明，该方法可以直接重建复杂的全球肌肉纤维，并且可以减少地方错误偏差和积累。它还能更好地重建长距离、扭转和大弯肌肉纤维。<details>
<summary>Abstract</summary>
Tractography traces the peak directions extracted from fiber orientation distribution (FOD) suffering from ambiguous spatial correspondences between diffusion directions and fiber geometry, which is prone to producing erroneous tracks while missing true positive connections. The peaks-based tractography methods 'locally' reconstructed streamlines in 'single to single' manner, thus lacking of global information about the trend of the whole fiber bundle. In this work, we propose a novel tractography method based on a bundle-specific tractogram distribution function by using a higher-order streamline differential equation, which reconstructs the streamline bundles in 'cluster to cluster' manner. A unified framework for any higher-order streamline differential equation is presented to describe the fiber bundles with disjoint streamlines defined based on the diffusion tensor vector field. At the global level, the tractography process is simplified as the estimation of bundle-specific tractogram distribution (BTD) coefficients by minimizing the energy optimization model, and is used to characterize the relations between BTD and diffusion tensor vector under the prior guidance by introducing the tractogram bundle information to provide anatomic priors. Experiments are performed on simulated Hough, Sine, Circle data, ISMRM 2015 Tractography Challenge data, FiberCup data, and in vivo data from the Human Connectome Project (HCP) data for qualitative and quantitative evaluation. The results demonstrate that our approach can reconstruct the complex global fiber bundles directly. BTD reduces the error deviation and accumulation at the local level and shows better results in reconstructing long-range, twisting, and large fanning tracts.
</details>
<details>
<summary>摘要</summary>
tractography 跟踪 peak 方向，从 fibers orientation distribution (FOD) 提取的方向，受到 ambiguous 的空间匹配问题，容易产生错误的轨迹，而且错过真实正确的连接。 peaks-based tractography 方法在 'single to single' 方式重建流线，缺乏全局信息，不能捕捉整个纤维Bundle的趋势。在这项工作中，我们提出了一种基于纤维特有的 tractogram 分布函数的新 tractography 方法，使用高阶流线差分方程，重建流线集在 'cluster to cluster' 方式。我们提出了一个普适的高阶流线差分方程来描述纤维Bundle中的分支流线。在全局水平上， tractography 过程简化为估计纤维特有 tractogram 分布(BTD) 系数，通过能量优化模型来Characterize BTD 和 diffusion tensor vector field 之间的关系。我们在 tractogram 集信息的引导下，引入了 tractogram bundle 信息，以提供 anatomic priors。我们在 simulated Hough, Sine, Circle 数据、ISMRM 2015 Tractography Challenge 数据、FiberCup 数据和人类连接计划 (HCP) 数据上进行了质量和量化评估。结果显示，我们的方法可以直接重建复杂的全局纤维Bundle。BTD 降低了本地错误偏差和积累，并且更好地重建长距离、扭转和大扇辐纤维。
</details></li>
</ul>
<hr>
<h2 id="Single-Image-LDR-to-HDR-Conversion-using-Conditional-Diffusion"><a href="#Single-Image-LDR-to-HDR-Conversion-using-Conditional-Diffusion" class="headerlink" title="Single Image LDR to HDR Conversion using Conditional Diffusion"></a>Single Image LDR to HDR Conversion using Conditional Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02814">http://arxiv.org/abs/2307.02814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dwip Dalal, Gautam Vashishtha, Prajwal Singh, Shanmuganathan Raman</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的高动态范围（HDR）图像恢复方法，以恢复真实场景中的细节信息，并且使用 Conditional Denoising Diffusion Probabilistic Model（DDPM）框架。</li>
<li>methods: 该方法使用了一种基于深度学习的 autoencoder 来提高输入低动态范围（LDR）图像的内在表示质量，并且引入了一种新的曝光损失函数来引导梯度的方向。</li>
<li>results: 经过进行了全面的量化和质量测试，该方法得到了有效的结果，表明一种简单的增强 diffusion-based 方法可以替代复杂的摄像头管线架构。<details>
<summary>Abstract</summary>
Digital imaging aims to replicate realistic scenes, but Low Dynamic Range (LDR) cameras cannot represent the wide dynamic range of real scenes, resulting in under-/overexposed images. This paper presents a deep learning-based approach for recovering intricate details from shadows and highlights while reconstructing High Dynamic Range (HDR) images. We formulate the problem as an image-to-image (I2I) translation task and propose a conditional Denoising Diffusion Probabilistic Model (DDPM) based framework using classifier-free guidance. We incorporate a deep CNN-based autoencoder in our proposed framework to enhance the quality of the latent representation of the input LDR image used for conditioning. Moreover, we introduce a new loss function for LDR-HDR translation tasks, termed Exposure Loss. This loss helps direct gradients in the opposite direction of the saturation, further improving the results' quality. By conducting comprehensive quantitative and qualitative experiments, we have effectively demonstrated the proficiency of our proposed method. The results indicate that a simple conditional diffusion-based method can replace the complex camera pipeline-based architectures.
</details>
<details>
<summary>摘要</summary>
digitization 目标是复制真实场景，但低动态范围（LDR）摄像机无法表示实际场景的广泛动态范围，导致阴影和高光部分损失。本文提出了一种基于深度学习的方法，用于从阴影和高光部分中恢复细节，并重建高动态范围（HDR）图像。我们将这个问题定义为一个图像到图像（I2I）翻译任务，并提出一种基于conditioned Denoising Diffusion Probabilistic Model（DDPM）的框架，不需要核心网络指导。我们在我们的提议框架中包含了一个深度透彻网络基于自动编码器，以提高输入LDR图像的latent表示质量。此外，我们还引入了一种新的损失函数，称为曝光损失（Exposure Loss），该损失函数可以帮助导向损失向量在强度方向上反方向，进一步提高结果质量。通过对比质量和质量的实验，我们有效地表明了我们的提议方法的效果。结果表明，一种简单的增强基于diffusion的方法可以取代复杂的摄像机管线结构。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Zero-Shot-Digital-Human-Quality-Assessment-through-Text-Prompted-Evaluation"><a href="#Advancing-Zero-Shot-Digital-Human-Quality-Assessment-through-Text-Prompted-Evaluation" class="headerlink" title="Advancing Zero-Shot Digital Human Quality Assessment through Text-Prompted Evaluation"></a>Advancing Zero-Shot Digital Human Quality Assessment through Text-Prompted Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02808">http://arxiv.org/abs/2307.02808</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zzc-1998/sjtu-h3d">https://github.com/zzc-1998/sjtu-h3d</a></li>
<li>paper_authors: Zicheng Zhang, Wei Sun, Yingjie Zhou, Haoning Wu, Chunyi Li, Xiongkuo Min, Xiaohong Liu, Guangtao Zhai, Weisi Lin</li>
<li>for: This paper aims to address the lack of comprehensive digital human quality assessment (DHQA) databases by proposing a subjective quality assessment database called SJTU-H3D, which can serve as a benchmark for DHQA research.</li>
<li>methods: The proposed method leverages semantic and distortion features extracted from projections, as well as geometry features derived from the mesh structure of digital humans. The method employs the Contrastive Language-Image Pre-training (CLIP) model to measure semantic affinity and incorporates the Naturalness Image Quality Evaluator (NIQE) model to capture low-level distortion information.</li>
<li>results: The proposed Digital Human Quality Index (DHQI) demonstrates significant improvements in zero-shot performance and can serve as a robust baseline for DHQA tasks, facilitating advancements in the field.Here is the summary in the format you requested:</li>
<li>for: 提供了一个全面的数字人质量评估数据库（SJTU-H3D），用于数字人质量评估研究的参照基准。</li>
<li>methods: 利用投影图像中的 semantic 和 distortion 特征，以及数字人的 mesh 结构特征，提出了一种零shot 数字人质量评估方法。</li>
<li>results: 提出的数字人质量指数（DHQI）在零shot 场景下表现出了显著的改善，可以作为数字人质量评估任务的robust 基准，促进领域的进步。<details>
<summary>Abstract</summary>
Digital humans have witnessed extensive applications in various domains, necessitating related quality assessment studies. However, there is a lack of comprehensive digital human quality assessment (DHQA) databases. To address this gap, we propose SJTU-H3D, a subjective quality assessment database specifically designed for full-body digital humans. It comprises 40 high-quality reference digital humans and 1,120 labeled distorted counterparts generated with seven types of distortions. The SJTU-H3D database can serve as a benchmark for DHQA research, allowing evaluation and refinement of processing algorithms. Further, we propose a zero-shot DHQA approach that focuses on no-reference (NR) scenarios to ensure generalization capabilities while mitigating database bias. Our method leverages semantic and distortion features extracted from projections, as well as geometry features derived from the mesh structure of digital humans. Specifically, we employ the Contrastive Language-Image Pre-training (CLIP) model to measure semantic affinity and incorporate the Naturalness Image Quality Evaluator (NIQE) model to capture low-level distortion information. Additionally, we utilize dihedral angles as geometry descriptors to extract mesh features. By aggregating these measures, we introduce the Digital Human Quality Index (DHQI), which demonstrates significant improvements in zero-shot performance. The DHQI can also serve as a robust baseline for DHQA tasks, facilitating advancements in the field. The database and the code are available at https://github.com/zzc-1998/SJTU-H3D.
</details>
<details>
<summary>摘要</summary>
digital humans 有广泛的应用在不同领域，需要相关的质量评估研究。然而，存在全面的数字人质量评估（DHQA）数据库缺失。为了填补这一空白，我们提出了清华大学三维数字人质量评估（SJTU-H3D）数据库，这是特意设计 для全身数字人的主观质量评估数据库。它包括40个高质量参照数字人和1,120个扭曲对应件，通过七种扭曲方式生成。SJTU-H3D数据库可以作为DHQA研究的标准准样， allowing 评估和优化处理算法。此外，我们提出了零极shot DHQA方法，专注于无参考（NR）场景，以确保普适性能力的同时降低数据库偏见。我们的方法利用CLIP模型测量 semantic affinity，并利用NIQE模型捕捉低级扭曲信息。此外，我们利用截角角度来描述数字人的网格结构，提取网格特征。通过综合这些指标，我们引入了数字人质量指数（DHQI），其在零极shot情况下显示了显著的改进。DHQI 也可以作为DHQA任务的稳定基准，促进领域的进步。数据库和代码可以在https://github.com/zzc-1998/SJTU-H3D 上下载。
</details></li>
</ul>
<hr>
<h2 id="UIT-Saviors-at-MEDVQA-GI-2023-Improving-Multimodal-Learning-with-Image-Enhancement-for-Gastrointestinal-Visual-Question-Answering"><a href="#UIT-Saviors-at-MEDVQA-GI-2023-Improving-Multimodal-Learning-with-Image-Enhancement-for-Gastrointestinal-Visual-Question-Answering" class="headerlink" title="UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image Enhancement for Gastrointestinal Visual Question Answering"></a>UIT-Saviors at MEDVQA-GI 2023: Improving Multimodal Learning with Image Enhancement for Gastrointestinal Visual Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02783">http://arxiv.org/abs/2307.02783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Triet M. Thai, Anh T. Vo, Hao K. Tieu, Linh N. P. Bui, Thien T. B. Nguyen</li>
<li>for: 本研究的目的是提高肠食道内镜图像中的医学视问答系统性能，以帮助医生更准确地诊断肠胃疾病。</li>
<li>methods: 该研究使用多模态学习方法，包括BERT编码器和不同的预训练视觉模型，以提取问题和内镜图像的特征。研究还使用图像增强技术来提高VQA性能。</li>
<li>results: 研究结果显示，使用 transformer 基于 CNN 和 Transformer 架构的视觉模型可以在肠食道内镜图像中提高 VQA 性能，而且图像增强技术也有显著提高效果。研究中的最佳方法，即 BERT+BEiT 混合和图像增强，在开发测试集上达到了87.25% 准确率和91.85% F1 分数。<details>
<summary>Abstract</summary>
In recent years, artificial intelligence has played an important role in medicine and disease diagnosis, with many applications to be mentioned, one of which is Medical Visual Question Answering (MedVQA). By combining computer vision and natural language processing, MedVQA systems can assist experts in extracting relevant information from medical image based on a given question and providing precise diagnostic answers. The ImageCLEFmed-MEDVQA-GI-2023 challenge carried out visual question answering task in the gastrointestinal domain, which includes gastroscopy and colonoscopy images. Our team approached Task 1 of the challenge by proposing a multimodal learning method with image enhancement to improve the VQA performance on gastrointestinal images. The multimodal architecture is set up with BERT encoder and different pre-trained vision models based on convolutional neural network (CNN) and Transformer architecture for features extraction from question and endoscopy image. The result of this study highlights the dominance of Transformer-based vision models over the CNNs and demonstrates the effectiveness of the image enhancement process, with six out of the eight vision models achieving better F1-Score. Our best method, which takes advantages of BERT+BEiT fusion and image enhancement, achieves up to 87.25% accuracy and 91.85% F1-Score on the development test set, while also producing good result on the private test set with accuracy of 82.01%.
</details>
<details>
<summary>摘要</summary>
Our team participated in Task 1 of the challenge by proposing a multimodal learning method that incorporated image enhancement to improve the VQA performance on gastrointestinal images. Our approach used a BERT encoder and different pre-trained vision models based on convolutional neural networks (CNNs) and Transformer architecture for feature extraction from questions and endoscopy images.The results of our study showed that Transformer-based vision models outperformed CNNs, and the image enhancement process significantly improved the VQA performance. Our best method, which combined BERT+BEiT fusion and image enhancement, achieved up to 87.25% accuracy and 91.85% F1-Score on the development test set. Additionally, our method performed well on the private test set with an accuracy of 82.01%. These results demonstrate the effectiveness of our multimodal learning method and the importance of image enhancement in improving the performance of MedVQA systems.
</details></li>
</ul>
<hr>
<h2 id="SeLiNet-Sentiment-enriched-Lightweight-Network-for-Emotion-Recognition-in-Images"><a href="#SeLiNet-Sentiment-enriched-Lightweight-Network-for-Emotion-Recognition-in-Images" class="headerlink" title="SeLiNet: Sentiment enriched Lightweight Network for Emotion Recognition in Images"></a>SeLiNet: Sentiment enriched Lightweight Network for Emotion Recognition in Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02773">http://arxiv.org/abs/2307.02773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuneer Khargonkar, Shwetank Choudhary, Sumit Kumar, Barath Raj KR</li>
<li>for: 这个论文是为了进行情感识别 tasks 的轻量级网络模型和端到端在设备上的整合管线。</li>
<li>methods: 这个模型包括人体特征抽象、图像美学特征抽象和学习型融合网络，这些部分共同估计阶梯性情感和人类情感任务。</li>
<li>results: 在 EMOTIC 数据集上，提议的方法实现了对比基eline的 Average Precision (AP) 分数 27.17，并在实际上实现了降低模型大小的 &gt;85% 和 &gt;93%。<details>
<summary>Abstract</summary>
In this paper, we propose a sentiment-enriched lightweight network SeLiNet and an end-to-end on-device pipeline for contextual emotion recognition in images. SeLiNet model consists of body feature extractor, image aesthetics feature extractor, and learning-based fusion network which jointly estimates discrete emotion and human sentiments tasks. On the EMOTIC dataset, the proposed approach achieves an Average Precision (AP) score of 27.17 in comparison to the baseline AP score of 27.38 while reducing the model size by >85%. In addition, we report an on-device AP score of 26.42 with reduction in model size by >93% when compared to the baseline.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种具有情感增强的轻量级网络SeLiNet，以及一个端到端在设备上的管道 для上下文感知图像中的情感识别。SeLiNet模型包括人体特征提取器、图像美学特征提取器和学习基于的融合网络，这些网络共同估计不同情感和人类情感任务。在EMOTIC数据集上，我们提议的方法实现了比基准AP分数27.17，而且减少了模型大小的>85%。此外，我们还报告了在设备上实现的AP分数26.42，并且减少了模型大小的>93%。
</details></li>
</ul>
<hr>
<h2 id="CityTrack-Improving-City-Scale-Multi-Camera-Multi-Target-Tracking-by-Location-Aware-Tracking-and-Box-Grained-Matching"><a href="#CityTrack-Improving-City-Scale-Multi-Camera-Multi-Target-Tracking-by-Location-Aware-Tracking-and-Box-Grained-Matching" class="headerlink" title="CityTrack: Improving City-Scale Multi-Camera Multi-Target Tracking by Location-Aware Tracking and Box-Grained Matching"></a>CityTrack: Improving City-Scale Multi-Camera Multi-Target Tracking by Location-Aware Tracking and Box-Grained Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02753">http://arxiv.org/abs/2307.02753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jincheng Lu, Xipeng Yang, Jin Ye, Yifu Zhang, Zhikang Zou, Wei Zhang, Xiao Tan</li>
<li>For: The paper is written for the task of multi-camera multi-target tracking (MCMT) in urban traffic visual analysis, with the goal of overcoming the challenges posed by complex and dynamic urban traffic scenes.* Methods: The paper proposes a novel systematic MCMT framework called CityTrack, which integrates various advanced techniques to improve the effectiveness of the MCMT task. These techniques include a Location-Aware SCMT tracker and a novel Box-Grained Matching (BGM) method for the ICA module.* Results: The paper achieved an IDF1 of 84.91% on the public test set of the CityFlowV2 dataset, ranking 1st in the 2022 AI CITY CHALLENGE. The experimental results demonstrate the effectiveness of the proposed approach in overcoming the challenges of urban traffic scenes.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解决城市流Visual分析中的多摄像头多目标跟踪问题，目标是在复杂和动态的城市交通场景下实现高效的多摄像头多目标跟踪。</li>
<li>methods: 论文提出了一种新的系统性MCMT框架，称为CityTrack，该框架集成了多种高级技术来提高MCMT任务的效果。这些技术包括一种位置意识SCMT跟踪器和一种novel的盒子粗粒匹配（BGM）方法 дляICA模块。</li>
<li>results: 论文在CityFlowV2数据集的公共测试集上 achievied an IDF1 of 84.91%, ranking 1st in the 2022 AI CITY CHALLENGE。实验结果表明提出的方法在城市交通场景下能够有效地解决多摄像头多目标跟踪问题。<details>
<summary>Abstract</summary>
Multi-Camera Multi-Target Tracking (MCMT) is a computer vision technique that involves tracking multiple targets simultaneously across multiple cameras. MCMT in urban traffic visual analysis faces great challenges due to the complex and dynamic nature of urban traffic scenes, where multiple cameras with different views and perspectives are often used to cover a large city-scale area. Targets in urban traffic scenes often undergo occlusion, illumination changes, and perspective changes, making it difficult to associate targets across different cameras accurately. To overcome these challenges, we propose a novel systematic MCMT framework, called CityTrack. Specifically, we present a Location-Aware SCMT tracker which integrates various advanced techniques to improve its effectiveness in the MCMT task and propose a novel Box-Grained Matching (BGM) method for the ICA module to solve the aforementioned problems. We evaluated our approach on the public test set of the CityFlowV2 dataset and achieved an IDF1 of 84.91%, ranking 1st in the 2022 AI CITY CHALLENGE. Our experimental results demonstrate the effectiveness of our approach in overcoming the challenges posed by urban traffic scenes.
</details>
<details>
<summary>摘要</summary>
多摄像头多目标跟踪（MCMT）是一种计算机视觉技术，它涉及同时跟踪多个目标在多个摄像头上。在城市交通视觉分析中，MCMT遇到了复杂和动态的城市交通场景，多个摄像头具有不同的视角和观点，用于覆盖大规模的城市区域。目标在城市交通场景中经常受到遮挡、照明变化和视角变化的影响，因此准确地相互关联目标在不同的摄像头上是一项具有挑战性的任务。为了解决这些挑战，我们提出了一种新的系统化的MCMT框架，称为CityTrack。具体来说，我们提出了一种位置意识的SCMT跟踪器，该跟踪器结合了多种进步技术来提高MCMT任务的效果。此外，我们还提出了一种新的盒子块匹配（BGM）方法，用于ICA模块解决上述问题。我们在CityFlowV2 dataset的公共测试集上进行了评估，并 achieved IDF1的84.91%，在2022年AI城市挑战中排名第一。我们的实验结果表明，我们的方法在城市交通场景中能够有效地解决MCMT任务中的挑战。
</details></li>
</ul>
<hr>
<h2 id="Active-Learning-with-Contrastive-Pre-training-for-Facial-Expression-Recognition"><a href="#Active-Learning-with-Contrastive-Pre-training-for-Facial-Expression-Recognition" class="headerlink" title="Active Learning with Contrastive Pre-training for Facial Expression Recognition"></a>Active Learning with Contrastive Pre-training for Facial Expression Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02744">http://arxiv.org/abs/2307.02744</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuvenduroy/activefer">https://github.com/shuvenduroy/activefer</a></li>
<li>paper_authors: Shuvendu Roy, Ali Etemad</li>
<li>for: 这篇论文旨在提出和研究一种active learning方法，以优化 facial expression recognition（FER）中的标注费用。</li>
<li>methods: 本论文使用了8种最新的active learning方法，并在FER13、RAF-DB和KDEF三个公共数据集上进行实验。</li>
<li>results: 研究发现现有的active learning方法在FER中不太够，可能是因为”冷启动”现象，即初始标注样本不够代表整个数据集。为解决这个问题，我们提议使用自我超参差异批处理，首先学习整个无标注数据集下的基本表示，然后采用active learning方法。我们的2步方法比随机抽样和最佳现有基eline的active learning方法提高了9.2%和6.7%。<details>
<summary>Abstract</summary>
Deep learning has played a significant role in the success of facial expression recognition (FER), thanks to large models and vast amounts of labelled data. However, obtaining labelled data requires a tremendous amount of human effort, time, and financial resources. Even though some prior works have focused on reducing the need for large amounts of labelled data using different unsupervised methods, another promising approach called active learning is barely explored in the context of FER. This approach involves selecting and labelling the most representative samples from an unlabelled set to make the best use of a limited 'labelling budget'. In this paper, we implement and study 8 recent active learning methods on three public FER datasets, FER13, RAF-DB, and KDEF. Our findings show that existing active learning methods do not perform well in the context of FER, likely suffering from a phenomenon called 'Cold Start', which occurs when the initial set of labelled samples is not well representative of the entire dataset. To address this issue, we propose contrastive self-supervised pre-training, which first learns the underlying representations based on the entire unlabelled dataset. We then follow this with the active learning methods and observe that our 2-step approach shows up to 9.2% improvement over random sampling and up to 6.7% improvement over the best existing active learning baseline without the pre-training. We will make the code for this study public upon publication at: github.com/ShuvenduRoy/ActiveFER.
</details>
<details>
<summary>摘要</summary>
深度学习在人脸表达识别（FER）中发挥了重要作用，感谢大型模型和庞大的标签数据。然而，获得标签数据需要巨量的人工劳动、时间和财务资源。一些先前的工作已经尝试了不同的无监督方法来降低需要大量标签数据的需求，但是另一个有投入的方法叫做活动学习仍未在FER上得到广泛的探讨。这种方法是通过从无标签集中选择和标签最 Representative 的样本来使用有限的标签预算。在这篇论文中，我们实现和研究了8种最近的活动学习方法在三个公共FER数据集上，即FER13、RAF-DB和KDEF。我们的发现表明现有的活动学习方法在FER上不 performs well，可能是因为一种被称为“冷启动”的现象，这种现象发生在整个数据集的初始标签样本不够 Representative 的情况下。为解决这个问题，我们提议了对比自适应预训练，首先学习整个无标签集下的基本表示，然后跟进活动学习方法。我们发现，我们的2步approach在Random Sampling和最佳无预训练基eline之间显示出9.2%的提升和6.7%的提升。我们将在发表之前在github.com/ShuvenduRoy/ActiveFER上公开代码。
</details></li>
</ul>
<hr>
<h2 id="An-Uncertainty-Aided-Framework-for-Learning-based-Liver-T-1ρ-Mapping-and-Analysis"><a href="#An-Uncertainty-Aided-Framework-for-Learning-based-Liver-T-1ρ-Mapping-and-Analysis" class="headerlink" title="An Uncertainty Aided Framework for Learning based Liver $T_1ρ$ Mapping and Analysis"></a>An Uncertainty Aided Framework for Learning based Liver $T_1ρ$ Mapping and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02736">http://arxiv.org/abs/2307.02736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaoxing Huang, Vincent Wai Sun Wong, Queenie Chan, Winnie Chiu Wing Chu, Weitian Chen<br>for:The paper aims to develop a learning-based approach for accurate and reliable quantitative $T_1\rho$ imaging of the liver, which can aid in the assessment of biochemical alterations in liver pathologies.methods:The proposed approach utilizes deep learning techniques to refine parametric maps and model the uncertainty of the predicted $T_1\rho$ values. The approach also employs a probabilistic framework to improve the mapping performance and remove unreliable pixels in the region of interest.results:The proposed approach leads to a relative mapping error of less than 3% and provides uncertainty estimation simultaneously. The estimated uncertainty reflects the actual error level and can be used to further reduce the relative $T_1\rho$ mapping error to 2.60% and remove unreliable pixels in the region of interest effectively.Here is the Chinese translation of the three key points:for:论文目的是开发一种基于学习的方法，以提供准确可靠的量化T1ρ成像，用于评估肝病变的生化变化。methods:提议的方法使用深度学习技术来改进参数地图，并模型预测T1ρ值的uncertainty。该方法还使用probabilistic框架来提高映射性能，并 removes unreliable pixels in the region of interest.results:提议的方法导致相对映射错误低于3%，同时提供uncertainty estimation。预测的uncertainty反映实际错误水平，可以进一步降低相对映射错误率至2.60%，并有效地 removes unreliable pixels in the region of interest.<details>
<summary>Abstract</summary>
Objective: Quantitative $T_1\rho$ imaging has potential for assessment of biochemical alterations of liver pathologies. Deep learning methods have been employed to accelerate quantitative $T_1\rho$ imaging. To employ artificial intelligence-based quantitative imaging methods in complicated clinical environment, it is valuable to estimate the uncertainty of the predicated $T_1\rho$ values to provide the confidence level of the quantification results. The uncertainty should also be utilized to aid the post-hoc quantitative analysis and model learning tasks. Approach: To address this need, we propose a parametric map refinement approach for learning-based $T_1\rho$ mapping and train the model in a probabilistic way to model the uncertainty. We also propose to utilize the uncertainty map to spatially weight the training of an improved $T_1\rho$ mapping network to further improve the mapping performance and to remove pixels with unreliable $T_1\rho$ values in the region of interest. The framework was tested on a dataset of 51 patients with different liver fibrosis stages. Main results: Our results indicate that the learning-based map refinement method leads to a relative mapping error of less than 3% and provides uncertainty estimation simultaneously. The estimated uncertainty reflects the actual error level, and it can be used to further reduce relative $T_1\rho$ mapping error to 2.60% as well as removing unreliable pixels in the region of interest effectively. Significance: Our studies demonstrate the proposed approach has potential to provide a learning-based quantitative MRI system for trustworthy $T_1\rho$ mapping of the liver.
</details>
<details>
<summary>摘要</summary>
目的：量化$T_1\rho$成像有潜力评估肝病变的生物化学变化。深度学习方法已经被应用于加速量化$T_1\rho$成像。在复杂的临床环境中使用人工智能基本图像评估方法，有利于估计预测的$T_1\rho$值的不确定性，以提供评估结果的信任度。方法：为了解决这个需求，我们提出了参数Map重定义方法，用于学习基于$T_1\rho$映射的不确定性模型，并在概率方式上训练模型。我们还提议使用不确定度地图来进行空间权重训练改进$T_1\rho$映射网络，以提高映射性能，并从区域 interesset中除掉不可靠的$T_1\rho$值。框架在51名患者不同的肝病变stage的数据集上进行测试。主要结果：我们的结果表明，学习基于映射的地图重定义方法可以实现相对的映射错误率低于3%，并同时提供不确定性估计。预测的不确定性反映实际错误水平，可以用于进一步降低相对$T_1\rho$映射错误率至2.60%，以及有效地从区域 interesset中除掉不可靠的$T_1\rho$值。意义：我们的研究表明，我们提出的方法有可能为肝脏的量化MRI系统提供可靠的$T_1\rho$映射。
</details></li>
</ul>
<hr>
<h2 id="MMNet-Multi-Collaboration-and-Multi-Supervision-Network-for-Sequential-Deepfake-Detection"><a href="#MMNet-Multi-Collaboration-and-Multi-Supervision-Network-for-Sequential-Deepfake-Detection" class="headerlink" title="MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection"></a>MMNet: Multi-Collaboration and Multi-Supervision Network for Sequential Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02733">http://arxiv.org/abs/2307.02733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiyang Xia, Decheng Liu, Jie Li, Lin Yuan, Nannan Wang, Xinbo Gao<br>for: 这篇论文旨在应对伪造面孔图像，特别是伪造面孔图像的Sequential deepfake detection。methods: 本论文提出了Multi-Collaboration and Multi-Supervision Network (MMNet)，可以处理各种空间排序和排序排序的伪造面孔图像，并且不需要知道伪造方法。results: 实验结果显示，MMNet可以实现高度的检测性和独立的回复性。<details>
<summary>Abstract</summary>
Advanced manipulation techniques have provided criminals with opportunities to make social panic or gain illicit profits through the generation of deceptive media, such as forged face images. In response, various deepfake detection methods have been proposed to assess image authenticity. Sequential deepfake detection, which is an extension of deepfake detection, aims to identify forged facial regions with the correct sequence for recovery. Nonetheless, due to the different combinations of spatial and sequential manipulations, forged face images exhibit substantial discrepancies that severely impact detection performance. Additionally, the recovery of forged images requires knowledge of the manipulation model to implement inverse transformations, which is difficult to ascertain as relevant techniques are often concealed by attackers. To address these issues, we propose Multi-Collaboration and Multi-Supervision Network (MMNet) that handles various spatial scales and sequential permutations in forged face images and achieve recovery without requiring knowledge of the corresponding manipulation method. Furthermore, existing evaluation metrics only consider detection accuracy at a single inferring step, without accounting for the matching degree with ground-truth under continuous multiple steps. To overcome this limitation, we propose a novel evaluation metric called Complete Sequence Matching (CSM), which considers the detection accuracy at multiple inferring steps, reflecting the ability to detect integrally forged sequences. Extensive experiments on several typical datasets demonstrate that MMNet achieves state-of-the-art detection performance and independent recovery performance.
</details>
<details>
<summary>摘要</summary>
高级操作技术为犯罪分子提供了创造社会恐慌或获得违法利润的机会，通过生成假面像。为了评估图像真实性，有多种深伪检测方法被提议。序列深伪检测是深伪检测的扩展，旨在识别假面像中的假区域，并且可以进行回归。然而，由于不同的空间和时序排序杂化，假面像中的假区域具有重大差异，这会严重影响检测性能。此外，回归假面像需要了解攻击者使用的杂化模型，这是困难的获取，因为攻击者通常会隐藏自己的技巧。为解决这些问题，我们提出了多方合作多级监督网络（MMNet），可以处理不同的空间级别和时序排序，并且可以实现不需要攻击者的杂化模型回归。此外，现有的评估指标仅考虑单个推理步骤的检测精度，而不考虑连续多个步骤中的匹配度。为了超越这些限制，我们提出了一个新的评估指标called完整序列匹配（CSM），可以考虑连续多个步骤中的检测精度，更好地反映检测完整性。广泛的实验表明，MMNet在多种典型数据集上达到了当前最佳的检测性能和独立回归性能。
</details></li>
</ul>
<hr>
<h2 id="Applying-a-Color-Palette-with-Local-Control-using-Diffusion-Models"><a href="#Applying-a-Color-Palette-with-Local-Control-using-Diffusion-Models" class="headerlink" title="Applying a Color Palette with Local Control using Diffusion Models"></a>Applying a Color Palette with Local Control using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02698">http://arxiv.org/abs/2307.02698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaibhav Vavilala, David Forsyth</li>
<li>for: 这两种新编辑方法适用于幻想卡牌艺术中。</li>
<li>methods: 这些方法包括alette transfer和segment控制。alette transfer使用指定参考色彩缓存到给定卡牌中，而segment控制允许艺术家将一个或多个图像段移动，并可选择要求结果中的一些段使用指定的颜色。</li>
<li>results: 这两种编辑方法的组合可以生成有价值的工作流程，例如：先移动一个段，然后重新颜色；或者先颜色，然后强制一些段使用指定的颜色。这些方法在Yu-Gi-Oh卡牌 datasets中得到了成功应用。<details>
<summary>Abstract</summary>
We demonstrate two novel editing procedures in the context of fantasy card art. Palette transfer applies a specified reference palette to a given card. For fantasy art, the desired change in palette can be very large, leading to huge changes in the "look" of the art. We demonstrate that a pipeline of vector quantization; matching; and "vector dequantization" (using a diffusion model) produces successful extreme palette transfers. Segment control allows an artist to move one or more image segments, and to optionally specify the desired color of the result. The combination of these two types of edit yields valuable workflows, including: move a segment, then recolor; recolor, then force some segments to take a prescribed color. We demonstrate our methods on the challenging Yu-Gi-Oh card art dataset.
</details>
<details>
<summary>摘要</summary>
我们展示了两种新的编辑方法在魔幻卡牌艺术上。alette转移使用指定的参考色板应用到给定的卡牌中。为了满足魔幻艺术的需求， Desired 的色彩变化可能很大，导致卡牌的“look”发生巨大的变化。我们表明了一个频谱划分；匹配；和“频谱划分”（使用扩散模型）生成了成功的极大色彩转移。 segment控制允许艺术家移动一个或多个图像段落，并可选择要求结果的颜色。这两种类型的编辑结合使得 workflow 非常有价值，例如：移动一段后重新色彩；重新色彩，然后强制一些段落采用指定的颜色。我们在具有挑战性的Yu-Gi-Oh卡牌 dataset上展示了我们的方法。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Impact-of-Face-Image-Quality-on-Face-Recognition-in-the-Wild"><a href="#A-Study-on-the-Impact-of-Face-Image-Quality-on-Face-Recognition-in-the-Wild" class="headerlink" title="A Study on the Impact of Face Image Quality on Face Recognition in the Wild"></a>A Study on the Impact of Face Image Quality on Face Recognition in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02679">http://arxiv.org/abs/2307.02679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Na Zhang</li>
<li>for: 本研究探讨了深度学习在人脸认知中是否能够快速和高效地识别低质量人脸图像。</li>
<li>methods: 本研究使用了多种深度学习方法来处理不同质量的人脸图像，并对这些图像进行了分类和比较。</li>
<li>results: 研究发现，深度学习方法在识别低质量人脸图像时存在一定的挑战，而人类的识别能力在不同质量的人脸图像之间具有更高的灵活性和可靠性。<details>
<summary>Abstract</summary>
Deep learning has received increasing interests in face recognition recently. Large quantities of deep learning methods have been proposed to handle various problems appeared in face recognition. Quite a lot deep methods claimed that they have gained or even surpassed human-level face verification performance in certain databases. As we know, face image quality poses a great challenge to traditional face recognition methods, e.g. model-driven methods with hand-crafted features. However, a little research focus on the impact of face image quality on deep learning methods, and even human performance. Therefore, we raise a question: Is face image quality still one of the challenges for deep learning based face recognition, especially in unconstrained condition. Based on this, we further investigate this problem on human level. In this paper, we partition face images into three different quality sets to evaluate the performance of deep learning methods on cross-quality face images in the wild, and then design a human face verification experiment on these cross-quality data. The result indicates that quality issue still needs to be studied thoroughly in deep learning, human own better capability in building the relations between different face images with large quality gaps, and saying deep learning method surpasses human-level is too optimistic.
</details>
<details>
<summary>摘要</summary>
深度学习在面recognition方面Received recent interest has increased. 大量的深度方法被提出来解决面recognition中的多种问题。许多深度方法声称他们在某些数据库中达到或even surpass human-level face verification performance。我们知道，面图像质量对传统的面recognition方法 pose a great challenge, such as model-driven methods with hand-crafted features。然而，只有一些研究关注深度学习方法在面图像质量下的影响，以及人类的表现。因此，我们提出了一个问题：深度学习基于面recognition中是否仍然面临质量挑战，特别是在无结构的 condition。基于这个问题，我们进一步调查这个问题，并设计了一个人类面验 эксперимент。结果表明，质量问题仍然需要进一步研究，人类在构建不同质量图像之间的关系方面具有更好的能力，而且说深度学习方法超过人类水平是太 оптимисти。
</details></li>
</ul>
<hr>
<h2 id="GIT-Detecting-Uncertainty-Out-Of-Distribution-and-Adversarial-Samples-using-Gradients-and-Invariance-Transformations"><a href="#GIT-Detecting-Uncertainty-Out-Of-Distribution-and-Adversarial-Samples-using-Gradients-and-Invariance-Transformations" class="headerlink" title="GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations"></a>GIT: Detecting Uncertainty, Out-Of-Distribution and Adversarial Samples using Gradients and Invariance Transformations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02672">http://arxiv.org/abs/2307.02672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Lust, Alexandru P. Condurache</li>
<li>for: 提高深度神经网络的预测准确率和检测误差</li>
<li>methods:  combining gradient information and invariance transformations to detect generalization errors</li>
<li>results: 在多种网络架构、问题设置和扰动类型上实现了比state-of-the-art更高的检测性能<details>
<summary>Abstract</summary>
Deep neural networks tend to make overconfident predictions and often require additional detectors for misclassifications, particularly for safety-critical applications. Existing detection methods usually only focus on adversarial attacks or out-of-distribution samples as reasons for false predictions. However, generalization errors occur due to diverse reasons often related to poorly learning relevant invariances. We therefore propose GIT, a holistic approach for the detection of generalization errors that combines the usage of gradient information and invariance transformations. The invariance transformations are designed to shift misclassified samples back into the generalization area of the neural network, while the gradient information measures the contradiction between the initial prediction and the corresponding inherent computations of the neural network using the transformed sample. Our experiments demonstrate the superior performance of GIT compared to the state-of-the-art on a variety of network architectures, problem setups and perturbation types.
</details>
<details>
<summary>摘要</summary>
深度神经网络往往做出过度自信的预测，并且常需要额外检测器来检测错误预测，特别是在安全关键应用场景下。现有的检测方法通常只关注到抗击攻击或者异常样本作为预测错误的原因。然而，总体错误的原因可能是多种多样的， часто与神经网络学习不良的相关 invariants 有关。我们因此提出了 GIT，一种涵盖性的方法， combinates 使用Gradient信息和对称变换。对应样本的对称变换可以将预测错误的样本推回神经网络的总体区域，而Gradient信息则度量在初始预测和神经网络对 transformed sample 的相对计算之间的矛盾。我们的实验表明 GIT 在不同的网络架构、问题设置和扰动类型上都有superior表现，胜过当前状态的检测方法。
</details></li>
</ul>
<hr>
<h2 id="Spherical-Feature-Pyramid-Networks-For-Semantic-Segmentation"><a href="#Spherical-Feature-Pyramid-Networks-For-Semantic-Segmentation" class="headerlink" title="Spherical Feature Pyramid Networks For Semantic Segmentation"></a>Spherical Feature Pyramid Networks For Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02658">http://arxiv.org/abs/2307.02658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Walker, Varun Anand, Pavlos Andreadis</li>
<li>for: 这个论文主要目标是解决圆形数据semantic segmentation问题，因为传统的平面approaches需要将圆形图像投影到平面上，这会导致网络性能下降。</li>
<li>methods: 这篇论文使用了图形基于方法，表示信号在圆形网格上，以解决上述挑战。然而，当前的圆形分割方法仅使用了各种UNet架构的变体，而尚未explore更成功的平面架构。本文提出了基于圆形CNN的圆形Feature Pyramid Network（FPN）模型，以提高分割性能。</li>
<li>results: 在Standford 2D-3D-S数据集上，我们的模型实现了state-of-the-art表现，具有48.75的mIOU，比前一个最佳圆形CNN的表现提高3.75个IOU点。<details>
<summary>Abstract</summary>
Semantic segmentation for spherical data is a challenging problem in machine learning since conventional planar approaches require projecting the spherical image to the Euclidean plane. Representing the signal on a fundamentally different topology introduces edges and distortions which impact network performance. Recently, graph-based approaches have bypassed these challenges to attain significant improvements by representing the signal on a spherical mesh. Current approaches to spherical segmentation exclusively use variants of the UNet architecture, meaning more successful planar architectures remain unexplored. Inspired by the success of feature pyramid networks (FPNs) in planar image segmentation, we leverage the pyramidal hierarchy of graph-based spherical CNNs to design spherical FPNs. Our spherical FPN models show consistent improvements over spherical UNets, whilst using fewer parameters. On the Stanford 2D-3D-S dataset, our models achieve state-of-the-art performance with an mIOU of 48.75, an improvement of 3.75 IoU points over the previous best spherical CNN.
</details>
<details>
<summary>摘要</summary>
Semantic segmentation for spherical data is a challenging problem in machine learning, as conventional planar approaches require projecting the spherical image to the Euclidean plane, which introduces edges and distortions that impact network performance. Recently, graph-based approaches have bypassed these challenges to achieve significant improvements by representing the signal on a spherical mesh. Current approaches to spherical segmentation exclusively use variants of the UNet architecture, meaning more successful planar architectures remain unexplored.Inspired by the success of feature pyramid networks (FPNs) in planar image segmentation, we leverage the pyramidal hierarchy of graph-based spherical CNNs to design spherical FPNs. Our spherical FPN models show consistent improvements over spherical UNets, while using fewer parameters. On the Stanford 2D-3D-S dataset, our models achieve state-of-the-art performance with an mIOU of 48.75, an improvement of 3.75 IoU points over the previous best spherical CNN.Here's the translation in Traditional Chinese:Semantic segmentation for spherical data is a challenging problem in machine learning, as conventional planar approaches require projecting the spherical image to the Euclidean plane, which introduces edges and distortions that impact network performance. Recently, graph-based approaches have bypassed these challenges to achieve significant improvements by representing the signal on a spherical mesh. Current approaches to spherical segmentation exclusively use variants of the UNet architecture, meaning more successful planar architectures remain unexplored.Inspired by the success of feature pyramid networks (FPNs) in planar image segmentation, we leverage the pyramidal hierarchy of graph-based spherical CNNs to design spherical FPNs. Our spherical FPN models show consistent improvements over spherical UNets, while using fewer parameters. On the Stanford 2D-3D-S dataset, our models achieve state-of-the-art performance with an mIOU of 48.75, an improvement of 3.75 IoU points over the previous best spherical CNN.
</details></li>
</ul>
<hr>
<h2 id="Active-Class-Selection-for-Few-Shot-Class-Incremental-Learning"><a href="#Active-Class-Selection-for-Few-Shot-Class-Incremental-Learning" class="headerlink" title="Active Class Selection for Few-Shot Class-Incremental Learning"></a>Active Class Selection for Few-Shot Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02641">http://arxiv.org/abs/2307.02641</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrismcclurg/fscil-acs">https://github.com/chrismcclurg/fscil-acs</a></li>
<li>paper_authors: Christopher McClurg, Ali Ayub, Harsh Tyagi, Sarah M. Rajtmajer, Alan R. Wagner</li>
<li>for: 本研究旨在帮助实际应用中的机器人在有限的互动中不断学习环境中的新对象。</li>
<li>methods: 本研究结合了几何学计算和可活动选择技术，开发了一种名为FIASco模型，可以让机器人通过尝试少量的对象标注来不断学习新对象。</li>
<li>results: 实验结果表明，FIASco模型在实际应用中可以有效地帮助机器人不断学习新对象，并且可以在有限的互动中实现长期的学习和应用。<details>
<summary>Abstract</summary>
For real-world applications, robots will need to continually learn in their environments through limited interactions with their users. Toward this, previous works in few-shot class incremental learning (FSCIL) and active class selection (ACS) have achieved promising results but were tested in constrained setups. Therefore, in this paper, we combine ideas from FSCIL and ACS to develop a novel framework that can allow an autonomous agent to continually learn new objects by asking its users to label only a few of the most informative objects in the environment. To this end, we build on a state-of-the-art (SOTA) FSCIL model and extend it with techniques from ACS literature. We term this model Few-shot Incremental Active class SeleCtiOn (FIASco). We further integrate a potential field-based navigation technique with our model to develop a complete framework that can allow an agent to process and reason on its sensory data through the FIASco model, navigate towards the most informative object in the environment, gather data about the object through its sensors and incrementally update the FIASco model. Experimental results on a simulated agent and a real robot show the significance of our approach for long-term real-world robotics applications.
</details>
<details>
<summary>摘要</summary>
为实际应用， роботы将需要在环境中不断学习，通过与用户有限的互动来更新知识。为此，先前的几何学增长学习（FSCIL）和活动类型选择（ACS）的研究已经取得了有希望的结果，但是这些研究都是在限定的设置下进行的。因此，在这篇论文中，我们将合并FSCIL和ACS的想法，开发一种能让自主代理人 continually 学习新的物体，只需要用户标注环境中最有用的几个对象。为此，我们基于当前最佳（SOTA）的FSCIL模型，并在ACS литературе中提出的技术上进行扩展。我们称这种模型为几何学增长活动类型选择（FIASco）。此外，我们还将潜在场景基本navIGATION技术与我们的模型结合，开发了一个完整的框架，让代理人可以通过FIASco模型处理和理解感知数据， navigate towards环境中最有用的对象，通过感知器收集数据，并不断更新FIASco模型。实验结果表明，我们的方法对长期实际 робо类应用具有重要意义。
</details></li>
</ul>
<hr>
<h2 id="Retinex-based-Image-Denoising-Contrast-Enhancement-using-Gradient-Graph-Laplacian-Regularizer"><a href="#Retinex-based-Image-Denoising-Contrast-Enhancement-using-Gradient-Graph-Laplacian-Regularizer" class="headerlink" title="Retinex-based Image Denoising &#x2F; Contrast Enhancement using Gradient Graph Laplacian Regularizer"></a>Retinex-based Image Denoising &#x2F; Contrast Enhancement using Gradient Graph Laplacian Regularizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02625">http://arxiv.org/abs/2307.02625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeganeh Gharedaghi, Gene Cheung, Xianming Liu</li>
<li>for: 提高低光照图像质量</li>
<li>methods: 使用图гра核方法进行锐化和对比度提高</li>
<li>results: 实现了竞争力强的视觉图像质量，同时降低计算复杂度。<details>
<summary>Abstract</summary>
Images captured in poorly lit conditions are often corrupted by acquisition noise. Leveraging recent advances in graph-based regularization, we propose a fast Retinex-based restoration scheme that denoises and contrast-enhances an image. Specifically, by Retinex theory we first assume that each image pixel is a multiplication of its reflectance and illumination components. We next assume that the reflectance and illumination components are piecewise constant (PWC) and continuous piecewise planar (PWP) signals, which can be recovered via graph Laplacian regularizer (GLR) and gradient graph Laplacian regularizer (GGLR) respectively. We formulate quadratic objectives regularized by GLR and GGLR, which are minimized alternately until convergence by solving linear systems -- with improved condition numbers via proposed preconditioners -- via conjugate gradient (CG) efficiently. Experimental results show that our algorithm achieves competitive visual image quality while reducing computation complexity noticeably.
</details>
<details>
<summary>摘要</summary>
低光照条件下捕捉的图像经常受到获取噪声的损害。我们提出了一种基于图格 regularization的快速 Retinex 修复方案，可以减少图像噪声并提高对比度。Specifically，我们首先根据 Retinex 理论，假设每个图像像素是其反射率和照明组件的乘积。我们接着假设反射率和照明组件是连续piecewise planar（PWP）和piecewise constant（PWC）信号，可以通过图 Laplacian regularizer（GLR）和梯度图 Laplacian regularizer（GGLR）分别recover。我们形式了quadratic objective function regularized by GLR和GGLR，并通过 conjugate gradient（CG）高效地解决线性系统，以达到很好的条件数。实验结果表明，我们的算法可以在computation complexity下降 noticeably的情况下，达到竞争性的视觉图像质量。
</details></li>
</ul>
<hr>
<h2 id="MRecGen-Multimodal-Appropriate-Reaction-Generator"><a href="#MRecGen-Multimodal-Appropriate-Reaction-Generator" class="headerlink" title="MRecGen: Multimodal Appropriate Reaction Generator"></a>MRecGen: Multimodal Appropriate Reaction Generator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02609">http://arxiv.org/abs/2307.02609</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Xu, Cheng Luo, Weicheng Xie, Linlin Shen, Xiaofeng Liu, Lu Liu, Hatice Gunes, Siyang Song</li>
<li>for: 本文提出了一种多Modal和多种应ropriate人类反应生成框架，用于生成适用于不同人类行为的真实和生动的人类式反应（通过同步的文本、音频和视频流），以应对用户行为。</li>
<li>methods: 本文提出了一种基于深度学习的多模态和多种应ropriate人类反应生成方法，通过对大量的人类反应数据进行学习和分类，生成适用于不同人类行为的真实和生动的人类式反应。</li>
<li>results: 本文的实验结果表明，该方法可以生成高质量的人类式反应，并且可以在不同的人类行为场景下应用。具体来说，通过对用户行为进行分类，生成适应的人类式反应，以提高人类与计算机之间的交互体验。<details>
<summary>Abstract</summary>
Verbal and non-verbal human reaction generation is a challenging task, as different reactions could be appropriate for responding to the same behaviour. This paper proposes the first multiple and multimodal (verbal and nonverbal) appropriate human reaction generation framework that can generate appropriate and realistic human-style reactions (displayed in the form of synchronised text, audio and video streams) in response to an input user behaviour. This novel technique can be applied to various human-computer interaction scenarios by generating appropriate virtual agent/robot behaviours. Our demo is available at \url{https://github.com/SSYSteve/MRecGen}.
</details>
<details>
<summary>摘要</summary>
文本和非文本人类反应生成是一项复杂的任务，因为不同的反应可能适用于回应同一种行为。这篇论文提出了首个多模式和多媒体（文本和非文本）适当人类反应生成框架，可以在输入用户行为的基础上生成适当和现实的人类样式反应（表示为同步文本、音频和视频流），并可以应用于不同的人机交互场景中。我们的demo可以在 \url{https://github.com/SSYSteve/MRecGen} 中找到。
</details></li>
</ul>
<hr>
<h2 id="GNEP-Based-Dynamic-Segmentation-and-Motion-Estimation-for-Neuromorphic-Imaging"><a href="#GNEP-Based-Dynamic-Segmentation-and-Motion-Estimation-for-Neuromorphic-Imaging" class="headerlink" title="GNEP Based Dynamic Segmentation and Motion Estimation for Neuromorphic Imaging"></a>GNEP Based Dynamic Segmentation and Motion Estimation for Neuromorphic Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02595">http://arxiv.org/abs/2307.02595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harbir Antil, David Sayre</li>
<li>for: 这篇论文探讨了基于事件驱动摄像头的图像分割和运动估计领域的应用。</li>
<li>methods: 该论文提出了基于Generalized Nash Equilibrium的框架，利用事件流中的时间和空间信息来进行分割和速度估计。</li>
<li>results: 该论文通过一系列实验证明了这种方法的有效性。<details>
<summary>Abstract</summary>
This paper explores the application of event-based cameras in the domains of image segmentation and motion estimation. These cameras offer a groundbreaking technology by capturing visual information as a continuous stream of asynchronous events, departing from the conventional frame-based image acquisition. We introduce a Generalized Nash Equilibrium based framework that leverages the temporal and spatial information derived from the event stream to carry out segmentation and velocity estimation. To establish the theoretical foundations, we derive an existence criteria and propose a multi-level optimization method for calculating equilibrium. The efficacy of this approach is shown through a series of experiments.
</details>
<details>
<summary>摘要</summary>
Note:* "event-based cameras" 为 asynchronous event-based imaging 的 camera* "Generalized Nash Equilibrium" 为 Generalized Nash Equilibrium 的 framework* "temporal and spatial information" 为 时间和空间信息* "existence criteria" 为 existence criteria 的 proof* "multi-level optimization method" 为 multi-level optimization method 的 proposal
</details></li>
</ul>
<hr>
<h2 id="Mainline-Automatic-Train-Horn-and-Brake-Performance-Metric"><a href="#Mainline-Automatic-Train-Horn-and-Brake-Performance-Metric" class="headerlink" title="Mainline Automatic Train Horn and Brake Performance Metric"></a>Mainline Automatic Train Horn and Brake Performance Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02586">http://arxiv.org/abs/2307.02586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rustam Tagiew</li>
<li>for: 这篇论文提出了一种基于主要铁路的执行指标 для替换式驾驶系统。</li>
<li>methods: 该论文提出了一种预liminary的障碍探测子指标，并且不知道任何其他类似的提议。</li>
<li>results: 该论文预计将为执行系统比较和运营设计域中的障碍探测系统提供一个标准化的预测数量。<details>
<summary>Abstract</summary>
This paper argues for the introduction of a mainline rail-oriented performance metric for driver-replacing on-board perception systems. Perception at the head of a train is divided into several subfunctions. This article presents a preliminary submetric for the obstacle detection subfunction. To the best of the author's knowledge, no other such proposal for obstacle detection exists. A set of submetrics for the subfunctions should facilitate the comparison of perception systems among each other and guide the measurement of human driver performance. It should also be useful for a standardized prediction of the number of accidents for a given perception system in a given operational design domain. In particular, for the proposal of the obstacle detection submetric, the professional readership is invited to provide their feedback and quantitative information to the author. The analysis results of the feedback will be published separately later.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了引入主线铁路 Orientated 性能指标，用于评估驾驶员替换车载感知系统。感知系统中的各个子函数被分解为多个子指标。本文提出了一个初步的障碍探测子指标。作者知道的范围内没有其他类似的提议。一组子指标可以方便各个感知系统之间的比较，并且可以指导测量人类驾驶员的性能。此外，它还可以用于预测给定感知系统在给定操作设计域中的事故数量。特别是对于障碍探测子指标的建议，专业读者被邀请提供反馈和量化信息给作者。作者将分析反馈的结果，并将在后续发表。
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Learning-from-Street-View-Images-and-OpenStreetMap-for-Automatic-Building-Height-Estimation"><a href="#Semi-supervised-Learning-from-Street-View-Images-and-OpenStreetMap-for-Automatic-Building-Height-Estimation" class="headerlink" title="Semi-supervised Learning from Street-View Images and OpenStreetMap for Automatic Building Height Estimation"></a>Semi-supervised Learning from Street-View Images and OpenStreetMap for Automatic Building Height Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02574">http://arxiv.org/abs/2307.02574</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bobleegogogo/building_height">https://github.com/bobleegogogo/building_height</a></li>
<li>paper_authors: Hao Li, Zhendong Yuan, Gabriel Dax, Gefei Kong, Hongchao Fan, Alexander Zipf, Martin Werner</li>
<li>for: 本研究旨在提供一种自动化建筑高度估算方法，以便从低成本的 voluntary geographical information (VGI) 数据中生成低成本的三维城市模型。</li>
<li>methods: 本研究使用 semi-supervised learning (SSL) 方法，并利用 Mapillary 街景图像和 OpenStreetMap (OSM) 数据进行自动化建筑高度估算。SSL 方法包括三个部分：首先，我们提出了一种 SSL 结构，其中可以在激活批处理中设置不同的 “pseudo label” 比率；其次，我们从 OSM 数据中提取多层次形态特征，以便从建筑高度中推断建筑高度；最后，我们设计了一个建筑层数估算工作流程，利用预训练的 Facade 对象检测网络来生成 “pseudo label” 从 SVI 数据中，并将其分配给 OSM 建筑脚印。</li>
<li>results: 在 tested 在海德堡市的 caso study 中，我们 validate 了提议的 SSL 方法，并评估模型的性能与参 Referenced 数据中的建筑高度。结果表明，使用 Random Forest (RF)、Support Vector Machine (SVM) 和 Convolutional Neural Network (CNN) 三种不同的回归模型，SSL 方法可以在建筑高度估算中带来明显的性能提升，MAE 约为 2.1 米，与现有方法竞争。这一初步结果是激动人心，鼓励我们在未来继续基于低成本 VGI 数据进行扩展，包括在不同的区域和数据质量上进行应用。<details>
<summary>Abstract</summary>
Accurate building height estimation is key to the automatic derivation of 3D city models from emerging big geospatial data, including Volunteered Geographical Information (VGI). However, an automatic solution for large-scale building height estimation based on low-cost VGI data is currently missing. The fast development of VGI data platforms, especially OpenStreetMap (OSM) and crowdsourced street-view images (SVI), offers a stimulating opportunity to fill this research gap. In this work, we propose a semi-supervised learning (SSL) method of automatically estimating building height from Mapillary SVI and OSM data to generate low-cost and open-source 3D city modeling in LoD1. The proposed method consists of three parts: first, we propose an SSL schema with the option of setting a different ratio of "pseudo label" during the supervised regression; second, we extract multi-level morphometric features from OSM data (i.e., buildings and streets) for the purposed of inferring building height; last, we design a building floor estimation workflow with a pre-trained facade object detection network to generate "pseudo label" from SVI and assign it to the corresponding OSM building footprint. In a case study, we validate the proposed SSL method in the city of Heidelberg, Germany and evaluate the model performance against the reference data of building heights. Based on three different regression models, namely Random Forest (RF), Support Vector Machine (SVM), and Convolutional Neural Network (CNN), the SSL method leads to a clear performance boosting in estimating building heights with a Mean Absolute Error (MAE) around 2.1 meters, which is competitive to state-of-the-art approaches. The preliminary result is promising and motivates our future work in scaling up the proposed method based on low-cost VGI data, with possibilities in even regions and areas with diverse data quality and availability.
</details>
<details>
<summary>摘要</summary>
准确的建筑高度估算是三维城市模型自动生成的关键，特别是从低成本的地理空间数据（VGI）中获取数据。然而，基于低成本VGI数据的大规模建筑高度估算方法目前尚缺乏。随着VGI数据平台的快速发展，特别是OpenStreetMap（OSM）和来自公众参与的街景图像（SVI），我们有机会填补这个研究漏洞。在这项工作中，我们提出了一种半监督学习（SSL）方法，通过使用Mapillary SVI和OSM数据自动计算建筑高度，以生成低成本和开源的三维城市模型。该方法包括三部分：1. 我们提出了一种SSL结构，其中可以在批量回归中设置不同的“ Pseudo Label”比率。2. 我们从OSM数据中提取了多级形态特征，以便从建筑高度进行推断。3. 我们设计了一个建筑层数估算工作流程，使用预训练的外墙对象检测网络来生成“ Pseudo Label”从SVI中，并将其分配到相应的OSM建筑基eline。在海德堡市（Heidelberg）的 caso study中，我们验证了我们的SSL方法，并评估其性能与参照数据中的建筑高度相比。基于Random Forest（RF）、Support Vector Machine（SVM）和Convolutional Neural Network（CNN）三种不同的回归模型，SSL方法在估算建筑高度方面具有明显的性能提升，MAE约为2.1米，与现有方法相当竞争。这些初步结果启发我们未来在基于低成本VGI数据的大规模建筑高度估算方法上进行进一步研究，包括在不同的数据质量和可用性下进行扩展。
</details></li>
</ul>
<hr>
<h2 id="A-Dataset-of-Inertial-Measurement-Units-for-Handwritten-English-Alphabets"><a href="#A-Dataset-of-Inertial-Measurement-Units-for-Handwritten-English-Alphabets" class="headerlink" title="A Dataset of Inertial Measurement Units for Handwritten English Alphabets"></a>A Dataset of Inertial Measurement Units for Handwritten English Alphabets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02480">http://arxiv.org/abs/2307.02480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hari Prabhat Gupta, Rahul Mishra</li>
<li>for: 这个研究是为了提高英文手写识别精度，特别是在印度的多元文化和语言背景下。</li>
<li>methods: 这个研究使用了各种测量工具和方法，包括传感器测量单元(IMU)、离散感知和机器学习等，以捕捉手写动作的动态模式，提高英文手写识别精度。</li>
<li>results: 根据实验结果显示，这个dataset和收集系统可以实现高精度的英文手写识别，特别是在印度的多元文化和语言背景下。<details>
<summary>Abstract</summary>
This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style. The IMUs are utilized to capture the dynamic movement patterns associated with handwriting, enabling more accurate recognition of alphabets. The Indian context introduces various challenges due to the heterogeneity in writing styles across different regions and languages. By leveraging this diversity, the collected dataset and the collection system aim to achieve higher recognition accuracy. Some preliminary experimental results demonstrate the effectiveness of the dataset in accurately recognizing handwritten English alphabet in the Indian context. This research can be extended and contributes to the field of pattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文提出了一种综合方法，通过使用惯性测量单元(IMU)，收集手写英文字母的数据集，并利用印度写作风格的多样性，提高手写识别的准确率。印度的文化和语言多样性会导致写作风格的差异，但是收集的数据集和收集系统尝试达到更高的识别率。初步的实验结果表明，这些数据集可以准确地识别印度上手写英文字母。这些研究可以进一步推广，对手写识别技术的发展产生有价值的影响，特别是在多元语言和文化背景下。
</details></li>
</ul>
<hr>
<h2 id="Large-scale-Detection-of-Marine-Debris-in-Coastal-Areas-with-Sentinel-2"><a href="#Large-scale-Detection-of-Marine-Debris-in-Coastal-Areas-with-Sentinel-2" class="headerlink" title="Large-scale Detection of Marine Debris in Coastal Areas with Sentinel-2"></a>Large-scale Detection of Marine Debris in Coastal Areas with Sentinel-2</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02465">http://arxiv.org/abs/2307.02465</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marccoru/marinedebrisdetector">https://github.com/marccoru/marinedebrisdetector</a></li>
<li>paper_authors: Marc Rußwurm, Sushen Jilla Venkatesa, Devis Tuia</li>
<li>for:  This paper aims to detect and quantify marine pollution and macro-plastics using remote sensing technology.</li>
<li>methods:  The paper uses a deep segmentation model to detect marine debris in coastal areas, leveraging medium-resolution satellite data. The model is trained on a combination of annotated datasets of marine debris and evaluated on specifically selected test sites.</li>
<li>results:  The paper demonstrates that the deep learning model outperforms existing detection models by a large margin, due to the particular dataset design with extensive sampling of negative examples and label refinements. The results show the potential for large-scale automated detection of marine debris, which can help quantify and monitor marine litter with remote sensing at global scales.<details>
<summary>Abstract</summary>
Detecting and quantifying marine pollution and macro-plastics is an increasingly pressing ecological issue that directly impacts ecology and human health. Efforts to quantify marine pollution are often conducted with sparse and expensive beach surveys, which are difficult to conduct on a large scale. Here, remote sensing can provide reliable estimates of plastic pollution by regularly monitoring and detecting marine debris in coastal areas. Medium-resolution satellite data of coastal areas is readily available and can be leveraged to detect aggregations of marine debris containing plastic litter. In this work, we present a detector for marine debris built on a deep segmentation model that outputs a probability for marine debris at the pixel level. We train this detector with a combination of annotated datasets of marine debris and evaluate it on specifically selected test sites where it is highly probable that plastic pollution is present in the detected marine debris. We demonstrate quantitatively and qualitatively that a deep learning model trained on this dataset issued from multiple sources outperforms existing detection models trained on previous datasets by a large margin. Our experiments show, consistent with the principles of data-centric AI, that this performance is due to our particular dataset design with extensive sampling of negative examples and label refinements rather than depending on the particular deep learning model. We hope to accelerate advances in the large-scale automated detection of marine debris, which is a step towards quantifying and monitoring marine litter with remote sensing at global scales, and release the model weights and training source code under https://github.com/marccoru/marinedebrisdetector
</details>
<details>
<summary>摘要</summary>
检测和评估海洋污染和巨型塑料是当前生态环境问题的一个不断增长的焦点，直接影响生物多样性和人类健康。尝试量化海洋污染的努力通常采用罕见和昂贵的海滩调查，这些调查难以在大规模上进行。在这里，Remote sensing可以提供可靠的塑料污染估计，通过定期监测和检测海洋垃圾在沿海区域。我们提出了一种基于深度分割模型的海洋垃圾检测器，该模型可以在像素级输出marine debris的投票 probabilities。我们使用了多种源的注解数据集来训练这个检测器，并在特定的测试地点进行评估，这些测试地点高度可能存在塑料污染。我们的实验表明，使用这种数据集和深度学习模型，我们可以在跨源数据集上超越现有的检测模型，提高检测精度。我们的实验还表明，这种性能是基于我们特有的数据集设计，包括广泛的负例抽象和标签精细化，而不是基于特定的深度学习模型。我们希望通过大规模自动检测海洋垃圾，降低海洋污染的评估难度，并在全球范围内追踪塑料污染，并将模型权重和训练源代码发布在https://github.com/marccoru/marinedebrisdetector。
</details></li>
</ul>
<hr>
<h2 id="AxonCallosumEM-Dataset-Axon-Semantic-Segmentation-of-Whole-Corpus-Callosum-cross-section-from-EM-Images"><a href="#AxonCallosumEM-Dataset-Axon-Semantic-Segmentation-of-Whole-Corpus-Callosum-cross-section-from-EM-Images" class="headerlink" title="AxonCallosumEM Dataset: Axon Semantic Segmentation of Whole Corpus Callosum cross section from EM Images"></a>AxonCallosumEM Dataset: Axon Semantic Segmentation of Whole Corpus Callosum cross section from EM Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02464">http://arxiv.org/abs/2307.02464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ao Cheng, Guoqiang Zhao, Lirong Wang, Ruobing Zhang</li>
<li>for: The paper is written for the purpose of introducing a new dataset and a fine-tuning methodology for segmenting EM images of the corpus callosum.</li>
<li>methods: The paper uses a combination of EM imaging and manual annotation to create a large-scale dataset of the corpus callosum, and a fine-tuning methodology called EM-SAM that adapts the Segment Anything Model (SAM) to EM image segmentation tasks.</li>
<li>results: The paper presents the evaluation results of EM-SAM as a baseline, which outperforms other state-of-the-art methods.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍一个新的数据集和一种精度调整方法，用于对电子显微镜图像的脑干细胞系统进行分割。</li>
<li>methods: 这篇论文使用了组合的电子显微镜成像和手动标注，创建了一个大规模的脑干细胞系统数据集，并使用了一种调整方法called EM-SAM，以适应电子显微镜图像分割任务。</li>
<li>results: 这篇论文提出了EM-SAM的评估结果作为基准，比其他状态所有方法表现出色。<details>
<summary>Abstract</summary>
The electron microscope (EM) remains the predominant technique for elucidating intricate details of the animal nervous system at the nanometer scale. However, accurately reconstructing the complex morphology of axons and myelin sheaths poses a significant challenge. Furthermore, the absence of publicly available, large-scale EM datasets encompassing complete cross sections of the corpus callosum, with dense ground truth segmentation for axons and myelin sheaths, hinders the advancement and evaluation of holistic corpus callosum reconstructions. To surmount these obstacles, we introduce the AxonCallosumEM dataset, comprising a 1.83 times 5.76mm EM image captured from the corpus callosum of the Rett Syndrome (RTT) mouse model, which entail extensive axon bundles. We meticulously proofread over 600,000 patches at a resolution of 1024 times 1024, thus providing a comprehensive ground truth for myelinated axons and myelin sheaths. Additionally, we extensively annotated three distinct regions within the dataset for the purposes of training, testing, and validation. Utilizing this dataset, we develop a fine-tuning methodology that adapts Segment Anything Model (SAM) to EM images segmentation tasks, called EM-SAM, enabling outperforms other state-of-the-art methods. Furthermore, we present the evaluation results of EM-SAM as a baseline.
</details>
<details>
<summary>摘要</summary>
《电子镜相（EM）仍然是解释动物神经系统细胞水平的主要技术。然而，准确地重建复杂的轴细胞和质粒层结构却是一项 significativetask。此外，没有公开可用的大规模EM数据集，包括整个脑桥完整的跨section，并且有密集的真实性标注 для轴细胞和质粒层，限制了整个脑桥的重建和评估。为了突破这些障碍，我们介绍了AxonCallosumEM数据集，包括RTT小鼠型脑桥的1.83 times 5.76mm EM图像，它包含了广泛的轴细胞集。我们仔细对600,000个小块进行了1024 times 1024的真实性检查，以提供完整的myelinated轴细胞和质粒层的真实性标注。此外，我们也进行了三个不同区域的严格的标注，用于训练、测试和验证。使用这个数据集，我们开发了一种基于SAM模型的EM图像分割方法，称为EM-SAM，它可以超越其他当前的状况。此外，我们还提供了EM-SAM的评估结果作为基准。
</details></li>
</ul>
<hr>
<h2 id="Expert-Agnostic-Ultrasound-Image-Quality-Assessment-using-Deep-Variational-Clustering"><a href="#Expert-Agnostic-Ultrasound-Image-Quality-Assessment-using-Deep-Variational-Clustering" class="headerlink" title="Expert-Agnostic Ultrasound Image Quality Assessment using Deep Variational Clustering"></a>Expert-Agnostic Ultrasound Image Quality Assessment using Deep Variational Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02462">http://arxiv.org/abs/2307.02462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Raina, Dimitrios Ntentia, SH Chandrashekhara, Richard Voyles, Subir Kumar Saha<br>for:The paper aims to develop an unsupervised ultrasound image quality assessment network to eliminate the burden and uncertainty of manual annotations.methods:The proposed framework, US2QNet, uses a variational autoencoder with three modules: pre-processing, clustering, and post-processing, to jointly enhance, extract, cluster, and visualize the quality feature representation of ultrasound images.results:The proposed framework achieved 78% accuracy and superior performance to state-of-the-art clustering methods in assessing the quality of urinary bladder ultrasound images.<details>
<summary>Abstract</summary>
Ultrasound imaging is a commonly used modality for several diagnostic and therapeutic procedures. However, the diagnosis by ultrasound relies heavily on the quality of images assessed manually by sonographers, which diminishes the objectivity of the diagnosis and makes it operator-dependent. The supervised learning-based methods for automated quality assessment require manually annotated datasets, which are highly labour-intensive to acquire. These ultrasound images are low in quality and suffer from noisy annotations caused by inter-observer perceptual variations, which hampers learning efficiency. We propose an UnSupervised UltraSound image Quality assessment Network, US2QNet, that eliminates the burden and uncertainty of manual annotations. US2QNet uses the variational autoencoder embedded with the three modules, pre-processing, clustering and post-processing, to jointly enhance, extract, cluster and visualize the quality feature representation of ultrasound images. The pre-processing module uses filtering of images to point the network's attention towards salient quality features, rather than getting distracted by noise. Post-processing is proposed for visualizing the clusters of feature representations in 2D space. We validated the proposed framework for quality assessment of the urinary bladder ultrasound images. The proposed framework achieved 78% accuracy and superior performance to state-of-the-art clustering methods.
</details>
<details>
<summary>摘要</summary>
“超声成像是一种常用的诊断和治疗过程中的重要模式。然而，超声诊断的准确性受到图像评估员（sonographer）的主观因素的影响，这会使诊断变得操作员依赖。支持学习基本方法需要手动标注的数据集，这是非常劳动 INTENSIVE 的。这些超声图像质量低，并且受到了诊断人员之间的视觉差异导致的噪音标注，这会降低学习效率。我们提议一种无监督的超声图像质量评估网络，namely US2QNet，以消除手动标注的压力和不确定性。US2QNet使用包括预处理、聚类和后处理三个模块的变量自动编码器，以联合提高、提取、聚类和可视化超声图像质量特征表示。预处理模块使用图像滤波来引导网络注意力向关键质量特征方向，而不是被噪声所干扰。后处理 module 提出了可视化特征表示的分布在2D空间。我们验证了我们的框架，用于评估膀胱超声图像质量。我们的框架实现了78%的准确率，并超过了当前的聚类方法的性能。”
</details></li>
</ul>
<hr>
<h2 id="LLCaps-Learning-to-Illuminate-Low-Light-Capsule-Endoscopy-with-Curved-Wavelet-Attention-and-Reverse-Diffusion"><a href="#LLCaps-Learning-to-Illuminate-Low-Light-Capsule-Endoscopy-with-Curved-Wavelet-Attention-and-Reverse-Diffusion" class="headerlink" title="LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion"></a>LLCaps: Learning to Illuminate Low-Light Capsule Endoscopy with Curved Wavelet Attention and Reverse Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02452">http://arxiv.org/abs/2307.02452</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/longbai1006/llcaps">https://github.com/longbai1006/llcaps</a></li>
<li>paper_authors: Long Bai, Tong Chen, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren</li>
<li>for: 该论文旨在提出一种基于多尺度卷积神经网络和反扩散过程的 wireless capsule endoscopy 低光照图像增强方法，以提高肠道疾病诊断的精度。</li>
<li>methods: 该方法基于多尺度卷积神经网络，并提出了弯波let attention 块来学习高频和地方特征。此外，该方法还 combining了反扩散过程来进一步优化混合输出，生成最真实的图像。</li>
<li>results: 与前十个state-of-the-art 低光照图像增强方法进行比较，该方法显示出了 statistically 和质量上的优异性。此外，该方法还在肠道疾病分 segmentation 中表现出了优秀的临床潜力。<details>
<summary>Abstract</summary>
Wireless capsule endoscopy (WCE) is a painless and non-invasive diagnostic tool for gastrointestinal (GI) diseases. However, due to GI anatomical constraints and hardware manufacturing limitations, WCE vision signals may suffer from insufficient illumination, leading to a complicated screening and examination procedure. Deep learning-based low-light image enhancement (LLIE) in the medical field gradually attracts researchers. Given the exuberant development of the denoising diffusion probabilistic model (DDPM) in computer vision, we introduce a WCE LLIE framework based on the multi-scale convolutional neural network (CNN) and reverse diffusion process. The multi-scale design allows models to preserve high-resolution representation and context information from low-resolution, while the curved wavelet attention (CWA) block is proposed for high-frequency and local feature learning. Furthermore, we combine the reverse diffusion procedure to further optimize the shallow output and generate the most realistic image. The proposed method is compared with ten state-of-the-art (SOTA) LLIE methods and significantly outperforms quantitatively and qualitatively. The superior performance on GI disease segmentation further demonstrates the clinical potential of our proposed model. Our code is publicly accessible.
</details>
<details>
<summary>摘要</summary>
无线 capsule 内镜（WCE）是一种无痛、非侵入性的诊断工具 для  Digestive tract 疾病（GI）。然而，由于 GI  анатомиче限制和硬件制造限制，WCE 视像信号可能受到不足照明的影响，导致复杂的检测和诊断过程。在医学领域，深度学习基于的低光照图像提高（LLIE）逐渐吸引研究人员。我们在 Computer Vision 领域的发展中，引入了基于多尺度 convolutional neural network （CNN）和反演扩散过程的 WCE LLIE 框架。这种多尺度设计允许模型保留高分辨率表示和 context 信息，而 Curved wavelet attention （CWA）块是用于高频和本地特征学习。此外，我们将反演扩散过程组合到输出优化，生成最真实的图像。我们的提议方法与当前 SOTA  LLIE 方法进行比较，显著超越量化和质量上。此外，我们还对 GI 疾病 segmentation 进行了评估，并证明了我们的提议模型在临床上的潜在价值。我们的代码公共可访问。
</details></li>
</ul>
<hr>
<h2 id="Base-Layer-Efficiency-in-Scalable-Human-Machine-Coding"><a href="#Base-Layer-Efficiency-in-Scalable-Human-Machine-Coding" class="headerlink" title="Base Layer Efficiency in Scalable Human-Machine Coding"></a>Base Layer Efficiency in Scalable Human-Machine Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02430">http://arxiv.org/abs/2307.02430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yalda Foroutan, Alon Harell, Anderson de Andrade, Ivan V. Bajić</li>
<li>for: 这个论文是为了提高一种可扩展的人机图像编码器的基层编码效率而写的。</li>
<li>methods: 论文使用了一种现状最佳的人机图像编码器，并对其基层编码进行分析和优化。</li>
<li>results: 论文表明，通过对基层编码进行优化，可以获得20-40%的BD-Rate提升，用于对物体检测和实例分割进行优化。<details>
<summary>Abstract</summary>
A basic premise in scalable human-machine coding is that the base layer is intended for automated machine analysis and is therefore more compressible than the same content would be for human viewing. Use cases for such coding include video surveillance and traffic monitoring, where the majority of the content will never be seen by humans. Therefore, base layer efficiency is of paramount importance because the system would most frequently operate at the base-layer rate. In this paper, we analyze the coding efficiency of the base layer in a state-of-the-art scalable human-machine image codec, and show that it can be improved. In particular, we demonstrate that gains of 20-40% in BD-Rate compared to the currently best results on object detection and instance segmentation are possible.
</details>
<details>
<summary>摘要</summary>
基本假设在可扩展人机编码中是，基层是为机器自动分析而设计的，因此比同样内容适用于人类查看时更加压缩。使用场景包括视频监控和交通监测，大多数内容将从来不会被人类查看。因此，基层效率非常重要，系统大多数时间都将在基层率下运行。在这篇论文中，我们分析了一种现代可扩展人机图像编码器的基层编码效率，并证明可以提高。特别是，我们示出了对 объек detection 和实例分割的结果进行优化，可以获得20-40%的BD-Rate提升。
</details></li>
</ul>
<hr>
<h2 id="DragonDiffusion-Enabling-Drag-style-Manipulation-on-Diffusion-Models"><a href="#DragonDiffusion-Enabling-Drag-style-Manipulation-on-Diffusion-Models" class="headerlink" title="DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models"></a>DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02421">http://arxiv.org/abs/2307.02421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mc-e/dragondiffusion">https://github.com/mc-e/dragondiffusion</a></li>
<li>paper_authors: Chong Mou, Xintao Wang, Jiechong Song, Ying Shan, Jian Zhang</li>
<li>for: 这篇论文是为了提出一种新的图像编辑方法，即DragonDiffusion，允许用户通过拖动方式进行图像修改。</li>
<li>methods: 该方法基于Diffusion模型的强相关性，通过特征对应损失将编辑信号转换为梯度，以修改Diffusion模型的中间表示。此外，还采用多尺度引导和自注意力机制保持原图和修改结果之间的一致性。</li>
<li>results: 该方法可以实现多种编辑模式，包括对已有图像的对象移动、对象放大、对象外观替换和内容拖动等。而所有的编辑和内容保持信号都来自于原图，无需 Fine-tuning 或额外模块。<details>
<summary>Abstract</summary>
Despite the ability of existing large-scale text-to-image (T2I) models to generate high-quality images from detailed textual descriptions, they often lack the ability to precisely edit the generated or real images. In this paper, we propose a novel image editing method, DragonDiffusion, enabling Drag-style manipulation on Diffusion models. Specifically, we construct classifier guidance based on the strong correspondence of intermediate features in the diffusion model. It can transform the editing signals into gradients via feature correspondence loss to modify the intermediate representation of the diffusion model. Based on this guidance strategy, we also build a multi-scale guidance to consider both semantic and geometric alignment. Moreover, a cross-branch self-attention is added to maintain the consistency between the original image and the editing result. Our method, through an efficient design, achieves various editing modes for the generated or real images, such as object moving, object resizing, object appearance replacement, and content dragging. It is worth noting that all editing and content preservation signals come from the image itself, and the model does not require fine-tuning or additional modules. Our source code will be available at https://github.com/MC-E/DragonDiffusion.
</details>
<details>
<summary>摘要</summary>
尽管现有的大规模文本到图像（T2I）模型可以生成高质量的图像从详细的文本描述，但它们通常缺乏 precisely 编辑生成的图像的能力。在这篇论文中，我们提出了一种新的图像编辑方法，即 DragonDiffusion，允许用户通过 Drag 式操作来修改Diffusion 模型中的图像。特别是，我们基于Diffusion 模型中强相关的间接特征的类ifikator导航，可以将编辑信号转化为梯度，以修改Diffusion 模型的中间表示。此外，我们还建立了多尺度导航，以考虑 Semantic 和 Geometric 对齐。此外，我们还添加了cross-branch self-attention，以保持原始图像和修改结果之间的一致性。我们的方法可以实现多种编辑模式，如物体移动、物体放大、物体外观替换和内容拖动。值得注意的是，所有的编辑和内容保持信号都来自于图像本身，而模型不需要 fine-tuning 或额外模块。我们的源代码将在 GitHub 上公开。
</details></li>
</ul>
<hr>
<h2 id="Unbalanced-Optimal-Transport-A-Unified-Framework-for-Object-Detection"><a href="#Unbalanced-Optimal-Transport-A-Unified-Framework-for-Object-Detection" class="headerlink" title="Unbalanced Optimal Transport: A Unified Framework for Object Detection"></a>Unbalanced Optimal Transport: A Unified Framework for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02402">http://arxiv.org/abs/2307.02402</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hdeplaen/uotod">https://github.com/hdeplaen/uotod</a></li>
<li>paper_authors: Henri De Plaen, Pierre-François De Plaen, Johan A. K. Suykens, Marc Proesmans, Tinne Tuytelaars, Luc Van Gool</li>
<li>for: 这篇论文主要是为了研究supervised object detection中的匹配策略，以提高模型的准确率和初始化速度。</li>
<li>methods: 论文使用的方法包括Unbalanced Optimal Transport，它可以将不同的匹配策略集成到一起，并提供一个灵活的选择参数，以便根据不同的目标选择最佳的方法。</li>
<li>results: 实验结果表明，使用Unbalanced Optimal Transport进行匹配可以达到当前领域的最佳性能，包括均值准确率和均值回归率，并且可以提高模型的初始化速度。<details>
<summary>Abstract</summary>
During training, supervised object detection tries to correctly match the predicted bounding boxes and associated classification scores to the ground truth. This is essential to determine which predictions are to be pushed towards which solutions, or to be discarded. Popular matching strategies include matching to the closest ground truth box (mostly used in combination with anchors), or matching via the Hungarian algorithm (mostly used in anchor-free methods). Each of these strategies comes with its own properties, underlying losses, and heuristics. We show how Unbalanced Optimal Transport unifies these different approaches and opens a whole continuum of methods in between. This allows for a finer selection of the desired properties. Experimentally, we show that training an object detection model with Unbalanced Optimal Transport is able to reach the state-of-the-art both in terms of Average Precision and Average Recall as well as to provide a faster initial convergence. The approach is well suited for GPU implementation, which proves to be an advantage for large-scale models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RADiff-Controllable-Diffusion-Models-for-Radio-Astronomical-Maps-Generation"><a href="#RADiff-Controllable-Diffusion-Models-for-Radio-Astronomical-Maps-Generation" class="headerlink" title="RADiff: Controllable Diffusion Models for Radio Astronomical Maps Generation"></a>RADiff: Controllable Diffusion Models for Radio Astronomical Maps Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02392">http://arxiv.org/abs/2307.02392</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renato Sortino, Thomas Cecconello, Andrea DeMarco, Giuseppe Fiameni, Andrea Pilzer, Andrew M. Hopkins, Daniel Magro, Simone Riggi, Eva Sciacca, Adriano Ingallinera, Cristobal Bordiu, Filomena Bufano, Concetto Spampinato</li>
<li>for: 这篇论文的目的是提出一个基于条件扩散模型的生成方法，用于增强对于电波天文学数据的自动化分析和检测。</li>
<li>methods: 这篇论文使用的方法包括使用条件扩散模型生成 sintetic 图像，以增强现有数据的标注和检测。</li>
<li>results: 这篇论文的结果显示，使用生成的 sintetic 图像可以提高 semantic segmentation 模型的性能，并且可以自动增强数据集的规模和多样性。<details>
<summary>Abstract</summary>
Along with the nearing completion of the Square Kilometre Array (SKA), comes an increasing demand for accurate and reliable automated solutions to extract valuable information from the vast amount of data it will allow acquiring. Automated source finding is a particularly important task in this context, as it enables the detection and classification of astronomical objects. Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose. However, training such deep networks requires a high volume of labeled data, which is not trivial to obtain in the context of radio astronomy. Since data needs to be manually labeled by experts, this process is not scalable to large dataset sizes, limiting the possibilities of leveraging deep networks to address several tasks. In this work, we propose RADiff, a generative approach based on conditional diffusion models trained over an annotated radio dataset to generate synthetic images, containing radio sources of different morphologies, to augment existing datasets and reduce the problems caused by class imbalances. We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset. We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks. We show an improvement in performance when applying augmentation, gaining up to 18% in performance when using real masks and 4% when augmenting with synthetic masks. Finally, we employ this model to generate large-scale radio maps with the objective of simulating Data Challenges.
</details>
<details>
<summary>摘要</summary>
alongside the impending completion of the Square Kilometre Array (SKA), there is an increasing demand for accurate and reliable automated solutions to extract valuable information from the vast amount of data it will acquire. Automated source finding is a particularly important task in this context, as it enables the detection and classification of astronomical objects. Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose. However, training such deep networks requires a high volume of labeled data, which is not easy to obtain in the context of radio astronomy. Since data needs to be manually labeled by experts, this process is not scalable to large dataset sizes, limiting the possibilities of leveraging deep networks to address several tasks. In this work, we propose RADiff, a generative approach based on conditional diffusion models trained over an annotated radio dataset to generate synthetic images, containing radio sources of different morphologies, to augment existing datasets and reduce the problems caused by class imbalances. We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset. We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks. We show an improvement in performance when applying augmentation, gaining up to 18% in performance when using real masks and 4% when augmenting with synthetic masks. Finally, we employ this model to generate large-scale radio maps with the objective of simulating Data Challenges.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/06/cs.CV_2023_07_06/" data-id="clogyj8x500dl7crac8q2czhz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/06/cs.AI_2023_07_06/" class="article-date">
  <time datetime="2023-07-06T12:00:00.000Z" itemprop="datePublished">2023-07-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/06/cs.AI_2023_07_06/">cs.AI - 2023-07-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Can-ChatGPT’s-Responses-Boost-Traditional-Natural-Language-Processing"><a href="#Can-ChatGPT’s-Responses-Boost-Traditional-Natural-Language-Processing" class="headerlink" title="Can ChatGPT’s Responses Boost Traditional Natural Language Processing?"></a>Can ChatGPT’s Responses Boost Traditional Natural Language Processing?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04648">http://arxiv.org/abs/2307.04648</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mostafa-mahmoud/chat-gpt-fusion-evaluation">https://github.com/mostafa-mahmoud/chat-gpt-fusion-evaluation</a></li>
<li>paper_authors: Mostafa M. Amin, Erik Cambria, Björn W. Schuller</li>
<li>for: 这项研究旨在探讨 chatGPT 是否可以增强现有的 NLP 方法，以解决情感分析、自杀倾向检测和大五人格评估等情感 computing 问题。</li>
<li>methods: 研究采用了 verbose 回答来探索 chatGPT 是否具有 novel 知识，并对现有 NLP 方法进行拼接以提高性能。</li>
<li>results: 结果显示，chatGPT 确实具有 novel 知识，可以通过拼接来提高现有 NLP 方法的性能，无论是在早期或晚期拼接。<details>
<summary>Abstract</summary>
The employment of foundation models is steadily expanding, especially with the launch of ChatGPT and the release of other foundation models. These models have shown the potential of emerging capabilities to solve problems, without being particularly trained to solve. A previous work demonstrated these emerging capabilities in affective computing tasks; the performance quality was similar to traditional Natural Language Processing (NLP) techniques, but falling short of specialised trained models, like fine-tuning of the RoBERTa language model. In this work, we extend this by exploring if ChatGPT has novel knowledge that would enhance existing specialised models when they are fused together. We achieve this by investigating the utility of verbose responses from ChatGPT about solving a downstream task, in addition to studying the utility of fusing that with existing NLP methods. The study is conducted on three affective computing problems, namely sentiment analysis, suicide tendency detection, and big-five personality assessment. The results conclude that ChatGPT has indeed novel knowledge that can improve existing NLP techniques by way of fusion, be it early or late fusion.
</details>
<details>
<summary>摘要</summary>
基础模型的雇佣正在不断扩展，尤其是随着ChatGPT的发布和其他基础模型的发布。这些模型表现出了解决问题的潜在能力，无需特别地训练。之前的研究已经证明这些潜在能力在情感计算任务中表现出了类似于传统自然语言处理（NLP）技术的性能质量，但略少于专门训练的模型，如精度调整的RoBERTa语言模型。在这项工作中，我们将进一步探索chatGPT是否具有可以增强现有特殊化模型的新知识。我们通过研究chatGPT对解决下游任务的 verbose 响应的使用，以及与现有NLP方法的融合来实现这一点。研究目标是在三种情感计算问题上进行评估，即情感分析、自杀倾向检测和大五人性评估。结果表明，chatGPTindeed具有可以改进现有NLP技术的新知识，并且可以通过融合来实现这一点，无论是在早期或晚期融合。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Knowledge-Data-Driven-Channel-Semantic-Acquisition-and-Beamforming-for-Cell-Free-Massive-MIMO"><a href="#Hybrid-Knowledge-Data-Driven-Channel-Semantic-Acquisition-and-Beamforming-for-Cell-Free-Massive-MIMO" class="headerlink" title="Hybrid Knowledge-Data Driven Channel Semantic Acquisition and Beamforming for Cell-Free Massive MIMO"></a>Hybrid Knowledge-Data Driven Channel Semantic Acquisition and Beamforming for Cell-Free Massive MIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03070">http://arxiv.org/abs/2307.03070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Gao, Shicong Liu, Yu Su, Zhongxiang Li, Dezhi Zheng</li>
<li>For: 提高户外无线系统的支持能力，以更好地支持普遍性扩展现实（XR）应用，并将户外无线传输能力与室内无线传输能力追究到一起。* Methods: 提议一种混合知识驱动的树枝网络（MLP）-混合器-基于 autoencoder 的通道semantic取得方法，并基于获得的通道semantic进一步提议一种知识驱动的深度 unfolding 多用户扩散幕。* Results: 实验结果表明，提议的方案可以提高通道取得精度，同时降低 CSI 取得和幕设计的复杂性。在下降链传输中，提议的幕设计方法可以在只需要三次迭代后达到大约 96% 的最终谱效率性能。<details>
<summary>Abstract</summary>
This paper focuses on advancing outdoor wireless systems to better support ubiquitous extended reality (XR) applications, and close the gap with current indoor wireless transmission capabilities. We propose a hybrid knowledge-data driven method for channel semantic acquisition and multi-user beamforming in cell-free massive multiple-input multiple-output (MIMO) systems. Specifically, we firstly propose a data-driven multiple layer perceptron (MLP)-Mixer-based auto-encoder for channel semantic acquisition, where the pilot signals, CSI quantizer for channel semantic embedding, and CSI reconstruction for channel semantic extraction are jointly optimized in an end-to-end manner. Moreover, based on the acquired channel semantic, we further propose a knowledge-driven deep-unfolding multi-user beamformer, which is capable of achieving good spectral efficiency with robustness to imperfect CSI in outdoor XR scenarios. By unfolding conventional successive over-relaxation (SOR)-based linear beamforming scheme with deep learning, the proposed beamforming scheme is capable of adaptively learning the optimal parameters to accelerate convergence and improve the robustness to imperfect CSI. The proposed deep unfolding beamforming scheme can be used for access points (APs) with fully-digital array and APs with hybrid analog-digital array. Simulation results demonstrate the effectiveness of our proposed scheme in improving the accuracy of channel acquisition, as well as reducing complexity in both CSI acquisition and beamformer design. The proposed beamforming method achieves approximately 96% of the converged spectrum efficiency performance after only three iterations in downlink transmission, demonstrating its efficacy and potential to improve outdoor XR applications.
</details>
<details>
<summary>摘要</summary>
The proposed method includes a data-driven multiple layer perceptron (MLP)-Mixer-based auto-encoder for channel semantic acquisition, where the pilot signals, CSI quantizer for channel semantic embedding, and CSI reconstruction for channel semantic extraction are jointly optimized in an end-to-end manner. Additionally, based on the acquired channel semantic, the authors propose a knowledge-driven deep-unfolding multi-user beamformer, which can achieve good spectral efficiency with robustness to imperfect CSI in outdoor XR scenarios.The proposed beamforming scheme unfolds the conventional successive over-relaxation (SOR)-based linear beamforming scheme with deep learning, allowing the beamformer to adaptively learn the optimal parameters to accelerate convergence and improve robustness to imperfect CSI. The proposed beamforming scheme can be used for access points (APs) with fully-digital array and APs with hybrid analog-digital array.Simulation results demonstrate the effectiveness of the proposed scheme in improving the accuracy of channel acquisition and reducing complexity in both CSI acquisition and beamformer design. The proposed beamforming method achieves approximately 96% of the converged spectrum efficiency performance after only three iterations in downlink transmission, showing its efficacy and potential to improve outdoor XR applications.
</details></li>
</ul>
<hr>
<h2 id="DeepOnto-A-Python-Package-for-Ontology-Engineering-with-Deep-Learning"><a href="#DeepOnto-A-Python-Package-for-Ontology-Engineering-with-Deep-Learning" class="headerlink" title="DeepOnto: A Python Package for Ontology Engineering with Deep Learning"></a>DeepOnto: A Python Package for Ontology Engineering with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03067">http://arxiv.org/abs/2307.03067</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KRR-Oxford/DeepOnto">https://github.com/KRR-Oxford/DeepOnto</a></li>
<li>paper_authors: Yuan He, Jiaoyan Chen, Hang Dong, Ian Horrocks, Carlo Allocca, Taehun Kim, Brahmananda Sapkota</li>
<li>for: 本文旨在探讨如何使用深度学习技术，特别是语言模型（LM），在 Ontology Engineering 中进行融合。</li>
<li>methods: 本文使用的方法包括 PyTorch 和 Tensorflow 等深度学习框架，以及 widely-used ontology APIs 如 OWL API 和 Jena。</li>
<li>results: 本文提出了 Deeponto，一个 Python 包，用于支持 Ontology Engineering 任务，包括ontology alignment和 completion，通过使用深度学习方法和 Pre-trained LMs。 authors 还提供了两个用例，包括 Samsung Research UK 的数字医疗咨询和 OAEI 的 Bio-ML 追踪。<details>
<summary>Abstract</summary>
Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more "Pythonic" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs. In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI).
</details>
<details>
<summary>摘要</summary>
使用深度学习技术，特别是语言模型（LM），在ontology工程中引起了广泛的关注。然而，深度学习框架如PyTorch和Tensorflow主要是为Python编程语言设计的，而广泛使用的ontology API，如OWL API和Jena，主要是Java基于的。为了实现这些框架和API的协同工作，我们提出了Deeponto，一个Python包用于ontology工程。这个包包括一个核心基于广泛认可和可靠的OWL API的ontology处理模块，封装了其基本特性在更"Pythonic"的方式下，并将其扩展到包括其他重要组成部分，如理解、抽象、准则、投影等。在这个模块基础之上，Deeponto提供了一 suite of工具、资源和算法，支持多种ontology工程任务，如ontology对齐和完成，通过深度学习方法，主要是使用预训练的LM。在这篇论文中，我们还示例了Deeponto在Samsung Research UK的数字医疗咨询和OAEI的生物ML轨道上的实践用case。
</details></li>
</ul>
<hr>
<h2 id="Generalizing-Backpropagation-for-Gradient-Based-Interpretability"><a href="#Generalizing-Backpropagation-for-Gradient-Based-Interpretability" class="headerlink" title="Generalizing Backpropagation for Gradient-Based Interpretability"></a>Generalizing Backpropagation for Gradient-Based Interpretability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03056">http://arxiv.org/abs/2307.03056</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kdu4108/semiring-backprop-exps">https://github.com/kdu4108/semiring-backprop-exps</a></li>
<li>paper_authors: Kevin Du, Lucas Torroba Hennigen, Niklas Stoehr, Alexander Warstadt, Ryan Cotterell</li>
<li>for: 本研究旨在提供一种普遍适用的方法来解释深度神经网络中的模型内部工作方式。</li>
<li>methods: 本研究使用了semirings来扩展归档推导算法，以计算神经网络中的梯度图的可解释统计数据，包括最大权重路径和熵。</li>
<li>results: 研究表明，通过计算梯度图的可解释统计数据，可以快速理解神经网络模型内部的工作方式，并且在SVA任务中，可以确定自注意机制中的哪些路径是最重要的。<details>
<summary>Abstract</summary>
Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs. While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important.
</details>
<details>
<summary>摘要</summary>
很多受欢迎的深度神经网络特征归因方法依靠计算模型输出与输入之间的梯度。although these methods can indicate which input features are important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important.Here is a word-for-word translation of the text into Simplified Chinese:很多受欢迎的深度神经网络特征归因方法依靠计算模型输出与输入之间的梯度。 although these methods can indicate which input features are important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its importance to a prediction and (b) for SVA, identify which pathways of the self-attention mechanism are most important.
</details></li>
</ul>
<hr>
<h2 id="Art-Authentication-with-Vision-Transformers"><a href="#Art-Authentication-with-Vision-Transformers" class="headerlink" title="Art Authentication with Vision Transformers"></a>Art Authentication with Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03039">http://arxiv.org/abs/2307.03039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ludovica Schaerf, Carina Popovici, Eric Postma</li>
<li>for: 这篇研究是为了检查当代电脑可以通过视觉transformer来进行艺术作品验证，以提高电脑验证艺术作品的可靠性。</li>
<li>methods: 这篇研究使用了Swin Transformer和EfficientNet两种不同的视觉transformer方法进行艺术作品验证，并比较了它们的验证性能。</li>
<li>results: 研究结果显示，使用Swin Transformer可以在仅有伪作品的情况下 achieve over 85%的验证精度，而EfficientNet则在标准的对比集上表现较差。这些结果表明，视觉transformer可以成为艺术作品验证中的一个强大和有前途的选择。<details>
<summary>Abstract</summary>
In recent years, Transformers, initially developed for language, have been successfully applied to visual tasks. Vision Transformers have been shown to push the state-of-the-art in a wide range of tasks, including image classification, object detection, and semantic segmentation. While ample research has shown promising results in art attribution and art authentication tasks using Convolutional Neural Networks, this paper examines if the superiority of Vision Transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks. Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin Transformers with those of EfficientNet. Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall. With a contrast set that only consists of imitations, we find the Swin Transformer to be superior to EfficientNet by achieving an authentication accuracy of over 85%. These results lead us to conclude that Vision Transformers represent a strong and promising contender in art authentication, particularly in enhancing the computer-based ability to detect artistic imitations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Sequential-Neural-Barriers-for-Scalable-Dynamic-Obstacle-Avoidance"><a href="#Sequential-Neural-Barriers-for-Scalable-Dynamic-Obstacle-Avoidance" class="headerlink" title="Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance"></a>Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03015">http://arxiv.org/abs/2307.03015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongzhan Yu, Chiaki Hirayama, Chenning Yu, Sylvia Herbert, Sicun Gao</li>
<li>for: 本研究旨在解决机器人导航Dynamic障碍物的扩展问题，即障碍物间复杂的互动征性难以分析、控制计划和执行难以扩展。</li>
<li>methods: 我们提出了一种新的Sequential Neural Control Barrier模型（SNCBF）的compositional learning方法，利用了观察：多个动态障碍物的空间互动模式可以通过时间序列状态来预测。通过这种归一化，我们可以将少量障碍物训练的控制策略扩展到环境中，障碍物密度高得多的环境中。</li>
<li>results: 我们比较了提出的方法与潜在场、终端学习控制和模型预测控制等现有方法，并进行硬件实验，证明了方法的实用性。<details>
<summary>Abstract</summary>
There are two major challenges for scaling up robot navigation around dynamic obstacles: the complex interaction dynamics of the obstacles can be hard to model analytically, and the complexity of planning and control grows exponentially in the number of obstacles. Data-driven and learning-based methods are thus particularly valuable in this context. However, data-driven methods are sensitive to distribution drift, making it hard to train and generalize learned models across different obstacle densities. We propose a novel method for compositional learning of Sequential Neural Control Barrier models (SNCBFs) to achieve scalability. Our approach exploits an important observation: the spatial interaction patterns of multiple dynamic obstacles can be decomposed and predicted through temporal sequences of states for each obstacle. Through decomposition, we can generalize control policies trained only with a small number of obstacles, to environments where the obstacle density can be 100x higher. We demonstrate the benefits of the proposed methods in improving dynamic collision avoidance in comparison with existing methods including potential fields, end-to-end reinforcement learning, and model-predictive control. We also perform hardware experiments and show the practical effectiveness of the approach in the supplementary video.
</details>
<details>
<summary>摘要</summary>
“运动障碍物 Navigation 扩大化面临两大挑战：障碍物间的互动关系具有复杂的非常数据分布，并且计划和控制的复杂度随着障碍物数量的增加而增加 exponentially。因此，数据驱动和学习型方法在这个上特别有价。然而，数据驱动方法受到分布迁移的影响，对于不同的障碍物密度训练和应用难以稳定。我们提出了一种新的Sequential Neural Control Barrier模型（SNCBF）的实时compositional learning方法，以实现扩展性。我们发现了一个重要的观察：多个动态障碍物之间的空间互动图样可以通过时间序列状态来预测，并且透过分解，将已经在少量障碍物环境中训练的控制策略扩展到障碍物密度可以高达100倍的环境中。我们显示了与现有方法，包括潜在场、终端循环学习和预测运算控制方法相比，提出的方法具有更好的动态碰撞避免性。我们还进行了硬件实验，并在辅助影片中展示了实际效果。”
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Optimization-of-Hand-Pose-Estimation-using-Anatomical-Features-and-Iterative-Learning"><a href="#Self-supervised-Optimization-of-Hand-Pose-Estimation-using-Anatomical-Features-and-Iterative-Learning" class="headerlink" title="Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning"></a>Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03007">http://arxiv.org/abs/2307.03007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Jauch, Timo Leitritz, Marco F. Huber</li>
<li>for: 本研究旨在提供一种自动学习的手势识别管道，以便在具有复杂使用场景的情况下进行便宜和可靠的手势识别。</li>
<li>methods: 该管道包括一种通用机器学习模型，通过一个泛化数据集进行训练，以及考虑手部的生物学约束的空间和时间滤波。</li>
<li>results: 研究人员通过对公共可用的和注解的数据集进行评估，选择了最佳参数和模型组合，并在手动组装场景中训练了一个活动识别任务，以示管道的效果。<details>
<summary>Abstract</summary>
Manual assembly workers face increasing complexity in their work. Human-centered assistance systems could help, but object recognition as an enabling technology hinders sophisticated human-centered design of these systems. At the same time, activity recognition based on hand poses suffers from poor pose estimation in complex usage scenarios, such as wearing gloves. This paper presents a self-supervised pipeline for adapting hand pose estimation to specific use cases with minimal human interaction. This enables cheap and robust hand posebased activity recognition. The pipeline consists of a general machine learning model for hand pose estimation trained on a generalized dataset, spatial and temporal filtering to account for anatomical constraints of the hand, and a retraining step to improve the model. Different parameter combinations are evaluated on a publicly available and annotated dataset. The best parameter and model combination is then applied to unlabelled videos from a manual assembly scenario. The effectiveness of the pipeline is demonstrated by training an activity recognition as a downstream task in the manual assembly scenario.
</details>
<details>
<summary>摘要</summary>
人工组装工人面临增加的工作复杂性。人类中心协助系统可以帮助，但对象识别作为激活技术，妨碍了复杂的人类中心设计。同时，基于手势识别的活动识别在复杂的使用场景中，如穿着手套，存在质量不高的手势估计问题。这篇论文介绍了一个自动学习管道，用于适应特定使用场景的手势估计，只需少量人类参与。该管道包括一个通用的机器学习模型，用于手势估计，以及空间和时间滤波器，用于考虑手部的解剖约束。还有一步重新训练，以提高模型。不同的参数组合被评估在公共可用的和注释的数据集上。最佳参数和模型组合然后应用于无注释的手势视频。这种管道的效果得到证明，通过在人工组装场景中训练一个活动识别任务。
</details></li>
</ul>
<hr>
<h2 id="CORE-GPT-Combining-Open-Access-research-and-large-language-models-for-credible-trustworthy-question-answering"><a href="#CORE-GPT-Combining-Open-Access-research-and-large-language-models-for-credible-trustworthy-question-answering" class="headerlink" title="CORE-GPT: Combining Open Access research and large language models for credible, trustworthy question answering"></a>CORE-GPT: Combining Open Access research and large language models for credible, trustworthy question answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04683">http://arxiv.org/abs/2307.04683</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oacore/core-gpt-evaluation">https://github.com/oacore/core-gpt-evaluation</a></li>
<li>paper_authors: David Pride, Matteo Cancellieri, Petr Knoth</li>
<li>for: 本研究旨在开发一种基于GPT语言模型和CORE全文开放访问科学期刊的问答平台，以提供可靠的答案和相关文献参考。</li>
<li>methods: 本研究使用GPT3.5和GPT4语言模型，并将CORE的全文数据集作为训练数据进行了融合。为了提高答案的可靠性和准确性，研究人员还对GPT模型进行了一些改进和调整。</li>
<li>results: 根据20个科学领域的100个问题测试，CORE-GPT可以提供全面和可靠的答案，同时提供相关文献的链接和参考。两名注释员对答案和链接的质量和相关性进行评估，结果显示CORE-GPT的答案和链接准确性高，可靠性大。<details>
<summary>Abstract</summary>
In this paper, we present CORE-GPT, a novel question-answering platform that combines GPT-based language models and more than 32 million full-text open access scientific articles from CORE. We first demonstrate that GPT3.5 and GPT4 cannot be relied upon to provide references or citations for generated text. We then introduce CORE-GPT which delivers evidence-based answers to questions, along with citations and links to the cited papers, greatly increasing the trustworthiness of the answers and reducing the risk of hallucinations. CORE-GPT's performance was evaluated on a dataset of 100 questions covering the top 20 scientific domains in CORE, resulting in 100 answers and links to 500 relevant articles. The quality of the provided answers and and relevance of the links were assessed by two annotators. Our results demonstrate that CORE-GPT can produce comprehensive and trustworthy answers across the majority of scientific domains, complete with links to genuine, relevant scientific articles.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了CORE-GPT，一种新的问答平台，它结合GPT基于语言模型和CORE上的 más de 3200万全文开放论文。我们首先表明GPT3.5和GPT4无法提供参考或引用 для生成的文本。然后，我们引入CORE-GPT，它可以提供基于证据的答案，并提供相关论文的引用和链接，从而增加答案的可靠性和减少误差。CORE-GPT的性能在20种科学领域的100个问题上进行评估，共计100个答案和500篇相关论文的链接。两名注释者评估了提供的答案和链接的质量和相关性。我们的结果表明，CORE-GPT可以在大多数科学领域提供全面和可靠的答案，并且链接到真实、相关的科学论文。
</details></li>
</ul>
<hr>
<h2 id="A-Privacy-Preserving-Walk-in-the-Latent-Space-of-Generative-Models-for-Medical-Applications"><a href="#A-Privacy-Preserving-Walk-in-the-Latent-Space-of-Generative-Models-for-Medical-Applications" class="headerlink" title="A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications"></a>A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02984">http://arxiv.org/abs/2307.02984</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/perceivelab/plan">https://github.com/perceivelab/plan</a></li>
<li>paper_authors: Matteo Pennisi, Federica Proietto Salanitri, Giovanni Bellitto, Simone Palazzo, Ulas Bagci, Concetto Spampinato</li>
<li>for: 本研究旨在提出一种基于k-同样性原理的私钥网络（GAN），以保持数据隐私的方式生成具有可训练深度学习模型的合理样本。</li>
<li>methods: 本研究使用了一种帮助找到latent space中离散的点的辅助标识类ifier，并通过非线性步进行latent space Navigation，以避免隐私问题。</li>
<li>results: 实验表明，给定任意两个latent space中的随机点对，我们的步进行方法比线性 interpolate 更安全，并在两个benchmark（肺炎和糖尿病肠病）上证明，通过我们的方法生成的样本可以减少数据隐私问题，同时保持模型训练的性能。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent space, our walking strategy is safer than linear interpolation. We then test our path-finding strategy combined to k-same methods and demonstrate, on two benchmarks for tuberculosis and diabetic retinopathy classification, that training a model using samples generated by our approach mitigate drops in performance, while keeping privacy preservation.
</details>
<details>
<summary>摘要</summary>
生成敌对网络（GANs）已经证明它们可以生成匹配目标分布的 sintetic 样本。然而，从隐私角度来看，使用 GANs 作为数据共享的代理不是安全的解决方案，因为它们往往将实际样本的几乎重复的样本嵌入在隐藏空间中。 latest works, inspired by k-anonymity principles, address this issue by aggregating samples in the latent space, with the drawback of reducing the dataset by a factor of k。our work aims to mitigate this problem by proposing a latent space navigation strategy that can generate diverse sintetic samples that support the effective training of deep models, while addressing privacy concerns in a principled way。our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples。we empirically demonstrate that, given any random pair of points in the latent space, our walking strategy is safer than linear interpolation。we then test our path-finding strategy combined to k-same methods and demonstrate, on two benchmarks for tuberculosis and diabetic retinopathy classification, that training a model using samples generated by our approach mitigates drops in performance while keeping privacy preservation。Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="How-word-semantics-and-phonology-affect-handwriting-of-Alzheimer’s-patients-a-machine-learning-based-analysis"><a href="#How-word-semantics-and-phonology-affect-handwriting-of-Alzheimer’s-patients-a-machine-learning-based-analysis" class="headerlink" title="How word semantics and phonology affect handwriting of Alzheimer’s patients: a machine learning based analysis"></a>How word semantics and phonology affect handwriting of Alzheimer’s patients: a machine learning based analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04762">http://arxiv.org/abs/2307.04762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicole Dalia Cilia, Claudio De Stefano, Francesco Fontanella, Sabato Marco Siniscalchi</li>
<li>for: 本研究旨在使用手写运动动力学性质以支持诊断神经退化疾病。</li>
<li>methods: 本研究使用非侵入式探测技术和机器学习方法。</li>
<li>results: 研究发现，不同词语类型的手写 task 会产生不同的动力学特征，非常规词语需要更多的特征来进行分类，但其分类性能却很高，最好的结果达到了90%。<details>
<summary>Abstract</summary>
Using kinematic properties of handwriting to support the diagnosis of neurodegenerative disease is a real challenge: non-invasive detection techniques combined with machine learning approaches promise big steps forward in this research field. In literature, the tasks proposed focused on different cognitive skills to elicitate handwriting movements. In particular, the meaning and phonology of words to copy can compromise writing fluency. In this paper, we investigated how word semantics and phonology affect the handwriting of people affected by Alzheimer's disease. To this aim, we used the data from six handwriting tasks, each requiring copying a word belonging to one of the following categories: regular (have a predictable phoneme-grapheme correspondence, e.g., cat), non-regular (have atypical phoneme-grapheme correspondence, e.g., laugh), and non-word (non-meaningful pronounceable letter strings that conform to phoneme-grapheme conversion rules). We analyzed the data using a machine learning approach by implementing four well-known and widely-used classifiers and feature selection. The experimental results showed that the feature selection allowed us to derive a different set of highly distinctive features for each word type. Furthermore, non-regular words needed, on average, more features but achieved excellent classification performance: the best result was obtained on a non-regular, reaching an accuracy close to 90%.
</details>
<details>
<summary>摘要</summary>
In this paper, we investigated how word semantics and phonology affect the handwriting of individuals with Alzheimer's disease. We used data from six handwriting tasks, each requiring the participants to copy a word belonging to one of the following categories: regular (with predictable phoneme-grapheme correspondence, such as "cat"), non-regular (with atypical phoneme-grapheme correspondence, such as "laugh"), and non-word (non-meaningful pronounceable letter strings that conform to phoneme-grapheme conversion rules). We analyzed the data using machine learning techniques, including four well-known and widely-used classifiers and feature selection.Our results showed that feature selection allowed us to derive a different set of highly distinctive features for each word type. Additionally, non-regular words required, on average, more features but achieved excellent classification performance. In fact, the best result was obtained on a non-regular word, with an accuracy of nearly 90%. These findings suggest that machine learning approaches using kinematic properties of handwriting could be a valuable tool for the diagnosis of neurodegenerative diseases such as Alzheimer's.
</details></li>
</ul>
<hr>
<h2 id="On-the-Cultural-Gap-in-Text-to-Image-Generation"><a href="#On-the-Cultural-Gap-in-Text-to-Image-Generation" class="headerlink" title="On the Cultural Gap in Text-to-Image Generation"></a>On the Cultural Gap in Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02971">http://arxiv.org/abs/2307.02971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingshuai Liu, Longyue Wang, Chenyang Lyu, Yong Zhang, Jinsong Su, Shuming Shi, Zhaopeng Tu</li>
<li>for: 提高文本到图像（T2I）生成的跨文化质量</li>
<li>methods: 提出了一个Challenging Cross-Cultural（C3）benchmark，并提出了一种多模式度量，用于约束 fine-tuning 数据，以提高cross-cultural生成的质量</li>
<li>results: 实验结果显示，我们的多模式度量在C3 benchmark上提供了更强的数据选择性，而object-textAlignment在这种metric中起到了关键作用。<details>
<summary>Abstract</summary>
One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural generation. Experimental results show that our multi-modal metric provides stronger data selection performance on the C3 benchmark than existing metrics, in which the object-text alignment is crucial. We release the benchmark, data, code, and generated images to facilitate future research on culturally diverse T2I generation (https://github.com/longyuewangdcu/C3-Bench).
</details>
<details>
<summary>摘要</summary>
一个挑战在文本到图像（T2I）生成中是因为训练数据中存在文化差距，这导致生成图像质量在不同文化元素的输入文本时出现差异。虽然多种T2I模型已经展示了吸引人的但是无法控制的例子，但是没有一个系统性的评价标准来评价一个T2I模型在不同文化中的表现。为了bridging这个差距，我们提出了一个多元评价标准，即挑战性跨文化（C3）benchmark，该标准包括了评价模型在目标文化中的多种评价标准。通过分析Stable Diffusion模型在C3benchmark上生成的瑕且图像，我们发现该模型经常无法生成特定文化元素。因此，我们提出了一种新的多模态指标，它考虑了文本-图像对齐，用于筛选训练数据的精度提高。实验结果显示，我们的多模态指标在C3benchmark上的数据选择性比既有的指标更强，对于文本-图像对齐是关键。我们将benchmark、数据、代码和生成图像公开发布（https://github.com/longyuewangdcu/C3-Bench），以便未来的文化多样化T2I生成研究。
</details></li>
</ul>
<hr>
<h2 id="A-Neuromorphic-Architecture-for-Reinforcement-Learning-from-Real-Valued-Observations"><a href="#A-Neuromorphic-Architecture-for-Reinforcement-Learning-from-Real-Valued-Observations" class="headerlink" title="A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations"></a>A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02947">http://arxiv.org/abs/2307.02947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergio F. Chevtchenko, Yeshwanth Bethi, Teresa B. Ludermir, Saeed Afshar</li>
<li>for:  solves Reinforcement Learning (RL) problems with real-valued observations in a hardware-efficient and bio-inspired way.</li>
<li>methods:  incorporates multi-layered event-based clustering, Temporal Difference (TD)-error modulation, and eligibility traces to build a novel Spiking Neural Network (SNN) architecture.</li>
<li>results:  consistently outperforms a tabular actor-critic algorithm and successfully discovers stable control policies on classic RL environments, with an appealing trade-off in terms of computational and hardware implementation requirements.<details>
<summary>Abstract</summary>
Reinforcement Learning (RL) provides a powerful framework for decision-making in complex environments. However, implementing RL in hardware-efficient and bio-inspired ways remains a challenge. This paper presents a novel Spiking Neural Network (SNN) architecture for solving RL problems with real-valued observations. The proposed model incorporates multi-layered event-based clustering, with the addition of Temporal Difference (TD)-error modulation and eligibility traces, building upon prior work. An ablation study confirms the significant impact of these components on the proposed model's performance. A tabular actor-critic algorithm with eligibility traces and a state-of-the-art Proximal Policy Optimization (PPO) algorithm are used as benchmarks. Our network consistently outperforms the tabular approach and successfully discovers stable control policies on classic RL environments: mountain car, cart-pole, and acrobot. The proposed model offers an appealing trade-off in terms of computational and hardware implementation requirements. The model does not require an external memory buffer nor a global error gradient computation, and synaptic updates occur online, driven by local learning rules and a broadcasted TD-error signal. Thus, this work contributes to the development of more hardware-efficient RL solutions.
</details>
<details>
<summary>摘要</summary>
利用强化学习（Reinforcement Learning，RL）的框架可以在复杂环境中做出决策。然而，通过硬件高效和生物体灵感的方式实现RL仍然是一个挑战。这篇论文提出了一种新的脉冲神经网络（Spiking Neural Network，SNN）架构，用于解决RL问题中的实数观察。提案的模型包括多层事件基于归一化、TD-错误调整和可用性追踪，这些组成部分都是在之前的工作之上。一项ablation研究证明了这些组成部分对提案模型的性能具有显著的影响。与标准的表格actor-critic算法和现状顶点优化算法（Proximal Policy Optimization，PPO）相比，我们的网络一直以上表现出色，并在经典RL环境中成功地找到稳定的控制策略：山脉汽车、折扇杆和Acrobot。提案的模型具有更有吸引力的计算和硬件实现需求。模型不需要外部内存缓冲区域，也不需要全局错误导数计算，更重要的是，神经元更新都发生在线上，驱动于本地学习规则和广播的TD-错误信号。因此，这种工作对RL解决方案的开发做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="Amplifying-Limitations-Harms-and-Risks-of-Large-Language-Models"><a href="#Amplifying-Limitations-Harms-and-Risks-of-Large-Language-Models" class="headerlink" title="Amplifying Limitations, Harms and Risks of Large Language Models"></a>Amplifying Limitations, Harms and Risks of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04821">http://arxiv.org/abs/2307.04821</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael O’Neill, Mark Connor</li>
<li>for: 本文旨在对人工智能（AI）技术的备受吹捧和未来可能出现的科幻情节提供一种小小的答复，以帮助那些不熟悉该领域的人更好地了解AI技术的限制和风险。</li>
<li>methods: 本文使用大量语言模型（LLMs），如ChatGPT，来描述AI技术的限制和风险。</li>
<li>results: 本文指出了LLMs的一些限制，包括其无法满足一些基本的人类语言理解需求，以及其可能导致个人和组织的损害。<details>
<summary>Abstract</summary>
We present this article as a small gesture in an attempt to counter what appears to be exponentially growing hype around Artificial Intelligence (AI) and its capabilities, and the distraction provided by the associated talk of science-fiction scenarios that might arise if AI should become sentient and super-intelligent. It may also help those outside of the field to become more informed about some of the limitations of AI technology. In the current context of popular discourse AI defaults to mean foundation and large language models (LLMs) such as those used to create ChatGPT. This in itself is a misrepresentation of the diversity, depth and volume of research, researchers, and technology that truly represents the field of AI. AI being a field of research that has existed in software artefacts since at least the 1950's. We set out to highlight a number of limitations of LLMs, and in so doing highlight that harms have already arisen and will continue to arise due to these limitations. Along the way we also highlight some of the associated risks for individuals and organisations in using this technology.
</details>
<details>
<summary>摘要</summary>
我们在这篇文章中呈现出一小小的尝试，以抵消人们对人工智能（AI）技术的快速增长和其能力的夸大、以及相关的科幻情节的抖音。我们也希望通过这篇文章，让那些不familiar with AI技术的人更加了解AI领域的限制和风险。在当今的流行讨论中，AI Defaults to Mean foundation和大型自然语言模型（LLMs），如chatGPT所使用的技术。这实际上是对AI领域的多样性、深度和规模的不公正表述。AI是一个已经在软件遗产物since at least the 1950s的研究领域。我们在这篇文章中，探讨了一些LLMs的限制，并在这个过程中，揭示了这些限制已经导致了一些害和将继续导致害。同时，我们还揭示了使用这种技术的个人和组织所面临的风险。
</details></li>
</ul>
<hr>
<h2 id="In-Time-and-Space-Towards-Usable-Adaptive-Control-for-Assistive-Robotic-Arms"><a href="#In-Time-and-Space-Towards-Usable-Adaptive-Control-for-Assistive-Robotic-Arms" class="headerlink" title="In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms"></a>In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02933">http://arxiv.org/abs/2307.02933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Pascher, Kirill Kronhardt, Felix Ferdinand Goldau, Udo Frese, Jens Gerken<br>for:这篇论文旨在提出一种新的控制方法，用于帮助用户更好地控制 робо臂进行 grasping 和 manipulation 任务。methods:本论文使用了 Adaptive DoF Mapping Controls (ADMC) 方法，并通过提供feed-forward multimodal feedback来帮助用户更好地选择合适的控制方式。results:研究表明，在虚拟现实环境中，使用 ADMC 方法可以降低任务完成时间、减少模式 switching 次数以及减轻用户的心理劳动量。此外，研究还发现，在不同的用户中，不同的自适应阈值可以更好地适应用户的需求。<details>
<summary>Abstract</summary>
Robotic solutions, in particular robotic arms, are becoming more frequently deployed for close collaboration with humans, for example in manufacturing or domestic care environments. These robotic arms require the user to control several Degrees-of-Freedom (DoFs) to perform tasks, primarily involving grasping and manipulating objects. Standard input devices predominantly have two DoFs, requiring time-consuming and cognitively demanding mode switches to select individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have shown to decrease the necessary number of mode switches but were up to now not able to significantly reduce the perceived workload. Users still bear the mental workload of incorporating abstract mode switching into their workflow. We address this by providing feed-forward multimodal feedback using updated recommendations of ADMC, allowing users to visually compare the current and the suggested mapping in real-time. We contrast the effectiveness of two new approaches that a) continuously recommend updated DoF combinations or b) use discrete thresholds between current robot movements and new recommendations. Both are compared in a Virtual Reality (VR) in-person study against a classic control method. Significant results for lowered task completion time, fewer mode switches, and reduced perceived workload conclusively establish that in combination with feedforward, ADMC methods can indeed outperform classic mode switching. A lack of apparent quantitative differences between Continuous and Threshold reveals the importance of user-centered customization options. Including these implications in the development process will improve usability, which is essential for successfully implementing robotic technologies with high user acceptance.
</details>
<details>
<summary>摘要</summary>
人工智能解决方案，尤其是机械臂，在人类 Collaborative 环境中越来越广泛应用，如制造或家庭护理环境。这些机械臂需要用户控制多个度Of freedom（DoF）来完成任务，主要是抓取和操纵物体。现有的输入设备主要有两个DoF，需要时间consuming和认知劳动密集的模式转换来选择个别DoF。当前的适应DoF映射控制法（ADMC）已经能够减少必要的模式转换数量，但是没有能力显著减少用户认知劳动。我们解决这问题，通过提供前向多模态反馈，使用更新的ADMC建议，让用户在实时比较当前和建议的映射。我们比较了两种新方法：a）不断推荐更新的DoF组合，或b）使用精度阈值来区分当前机器运动和新建议。两者在虚拟现实（VR）实验室中进行了对照测试，与经典控制方法进行比较。结果显示，在与 feedforward 结合使用的情况下，ADMC 方法可以实现更好的任务完成时间、更少的模式转换和更低的认知劳动。无论 apparent 的量化差异，表明用户中心的个性化选项的重要性。包括这些影响在开发过程中，将提高可用性，这是实施机器人技术的成功关键。
</details></li>
</ul>
<hr>
<h2 id="LEA-Improving-Sentence-Similarity-Robustness-to-Typos-Using-Lexical-Attention-Bias"><a href="#LEA-Improving-Sentence-Similarity-Robustness-to-Typos-Using-Lexical-Attention-Bias" class="headerlink" title="LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias"></a>LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02912">http://arxiv.org/abs/2307.02912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mario Almagro, Emilio Almazán, Diego Ortego, David Jiménez<br>for: 本研究的目的是提高Transformer搜寻引擎对文本噪音的耐性，以提高在多个领域中的下游任务性能。methods: 本研究使用了一种新的lexical-aware Attention模块(LEA)，通过 incorporating lexical similarities between words in both sentences, 以提高cross-encoders对文本噪音的耐性。results: 实验结果表明，LEA可以帮助cross-encoders在文本噪音的情况下提高性能，并在不同领域中保持竞争力。<details>
<summary>Abstract</summary>
Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks. We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing. Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them. Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training. However, all these methods still suffer from the token distribution shift induced by typos. In this work, we propose to tackle textual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences. By using raw text similarities, our approach avoids the tokenization shift problem obtaining improved robustness. We demonstrate that the attention bias introduced by LEA helps cross-encoders to tackle complex scenarios with textual noise, specially in domains with short-text descriptions and limited context. Experiments using three popular Transformer encoders in five e-commerce datasets for product matching show that LEA consistently boosts performance under the presence of noise, while remaining competitive on the original (clean) splits. We also evaluate our approach in two datasets for textual entailment and paraphrasing showing that LEA is robust to typos in domains with longer sentences and more natural context. Additionally, we thoroughly analyze several design choices in our approach, providing insights about the impact of the decisions made and fostering future research in cross-encoders dealing with typos.
</details>
<details>
<summary>摘要</summary>
文本噪声，如 typo 或缩写，是许多下游任务中知名的问题，即使是 sentence similarity 任务。我们显示这也是情况的 caso  для sentence similarity 任务。sentence similarity 可以通过 cross-encoder 来实现，其中两个句子被 concatenated 在输入中，让模型利用它们之间的关系。前一些 Addressing 噪声问题的方法主要通过数据增强策略来解决，并显示在训练样本中的噪声样本上提高了模型的Robustness。但这些方法 все都受到 tokenization shift 的影响，即使在训练样本中噪声样本的情况下。在这种情况下，我们提议使用 LExical-aware Attention 模块 (LEA) 来解决 textual noise。LEA 模块 incorporates 词语之间的 lexical similarity，使得我们可以避免 tokenization shift 问题。我们使用 raw text similarity，从而获得了改进的 robustness。我们表明，LEA 模块引入的注意力偏好可以帮助 cross-encoder 在复杂的 scenario 中处理 textual noise，特别是在短文本描述和有限上下文中。我们在五个电商数据集上进行了三种 popular Transformer encoder 的实验，并证明了 LEA 在噪声存在的情况下 consistently 提高表现，而不会在干净（clean） split 上受到影响。此外，我们还在两个文本同义和重叠任务上进行了评估，并证明了 LEA 在长句子和自然上下文中具有 robustness。此外，我们还进行了多种设计决策的分析，提供了关于 LEA 的设计决策的影响和未来研究的指导。
</details></li>
</ul>
<hr>
<h2 id="Audio-visual-End-to-end-Multi-channel-Speech-Separation-Dereverberation-and-Recognition"><a href="#Audio-visual-End-to-end-Multi-channel-Speech-Separation-Dereverberation-and-Recognition" class="headerlink" title="Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition"></a>Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02909">http://arxiv.org/abs/2307.02909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guinan Li, Jiajun Deng, Mengzhe Geng, Zengrui Jin, Tianzi Wang, Shujie Hu, Mingyu Cui, Helen Meng, Xunying Liu</li>
<li>for: 这个论文的目的是提出一种基于多渠道音频视频信号的混合 speech separation、 dereverberation 和认知方法，以提高听说党场中的语音识别精度。</li>
<li>methods: 该方法首先使用了mask-based MVDR speech separation、DNN-WPE或spectral mapping (SpecM) based speech dereverberation的前端，然后使用Conformer ASR的后端进行语音识别。在音频视频Integrated front-end架构中，speech separation和dereverberation可以在独立或联合的方式进行，通过mask-based WPD来实现。</li>
<li>results: 实验结果表明，提出的音频视频多渠道 speech separation、dereverberation和认知方法可以与相关的音频 только基eline相比，提高41.7%和36.0%的Relative word error rate (WER)，并且在PESQ、STOI和SRMR等评价指标上也获得了一定的提高。<details>
<summary>Abstract</summary>
Accurate recognition of cocktail party speech containing overlapping speakers, noise and reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all system components is proposed in this paper. The efficacy of the video input is consistently demonstrated in mask-based MVDR speech separation, DNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and Conformer ASR back-end. Audio-visual integrated front-end architectures performing speech separation and dereverberation in a pipelined or joint fashion via mask-based WPD are investigated. The error cost mismatch between the speech enhancement front-end and ASR back-end components is minimized by end-to-end jointly fine-tuning using either the ASR cost function alone, or its interpolation with the speech enhancement loss. Experiments were conducted on the mixture overlapped and reverberant speech data constructed using simulation or replay of the Oxford LRS2 dataset. The proposed audio-visual multi-channel speech separation, dereverberation and recognition systems consistently outperformed the comparable audio-only baseline by 9.1% and 6.2% absolute (41.7% and 36.0% relative) word error rate (WER) reductions. Consistent speech enhancement improvements were also obtained on PESQ, STOI and SRMR scores.
</details>
<details>
<summary>摘要</summary>
干预cocktail party speech中的干扰和混响是到现在为止的一个非常挑战的任务。我们被视觉modalities的不变性所 inspirited，我们提出了一种将视觉信息完全integrated into all system components的多渠道speech separation、dereverberation和认知approach。在这篇论文中，我们展示了视频输入的效果是在mask-based MVDR speech separation、DNN-WPE或spectral mapping（SpecM）based speech dereverberation前端和Conformer ASR后端中 consistently demonstrating。我们还investigated了audiovisual integrated front-end architecture，通过pipelined或joint fashion进行speech separation和dereverberationvia mask-based WPD。我们使用了end-to-end joint fine-tuning，使得error cost mismatch междуspeech enhancement front-end和ASR back-end component minimized。我们在用simulation或replay制造的Oxford LRS2 dataset上进行了实验，并 obtainted9.1%和6.2%的绝对（41.7%和36.0%相对）word error rate（WER）下降。我们还获得了consistent speech enhancement改进在PESQ、STOI和SRMR分数上。
</details></li>
</ul>
<hr>
<h2 id="BaBE-Enhancing-Fairness-via-Estimation-of-Latent-Explaining-Variables"><a href="#BaBE-Enhancing-Fairness-via-Estimation-of-Latent-Explaining-Variables" class="headerlink" title="BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables"></a>BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02891">http://arxiv.org/abs/2307.02891</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/babe-algorithm/babe">https://github.com/babe-algorithm/babe</a></li>
<li>paper_authors: Ruta Binkyte, Daniele Gorla, Catuscia Palamidessi<br>for: 本研究旨在解决因敏感特征S和合法变量E之间的不公平歧视问题，提出了一种预处理方法以实现公平。methods: 本研究使用了抽象统计平衡和等可能性方法来解决不公平问题，并提出了一种基于抽象统计平衡和期望最大化方法的抽象隐藏变量BAYesian Bias Elimination（BaBE）方法。results: 实验表明，BABE方法可以在synthetic和实际数据集上提供高精度和公平性。<details>
<summary>Abstract</summary>
We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness. Corrective methods like statistical parity usually lead to bad accuracy and do not really achieve fairness in situations where there is a correlation between the sensitive attribute S and the legitimate attribute E (explanatory variable) that should determine the decision. To overcome these drawbacks, other notions of fairness have been proposed, in particular, conditional statistical parity and equal opportunity. However, E is often not directly observable in the data, i.e., it is a latent variable. We may observe some other variable Z representing E, but the problem is that Z may also be affected by S, hence Z itself can be biased. To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each group. The decision can then be based directly on the estimated E. We show, by experiments on synthetic and real data sets, that our approach provides a good level of fairness as well as high accuracy.
</details>
<details>
<summary>摘要</summary>
我们考虑了不公正歧视的问题，并提出了预处理方法以实现公平。通常的统计平衡方法通常会导致准确率下降，并不真正实现公平在敏感特征S和合法特征E（解释变量）之间存在相关性的情况下。为了解决这些缺点，其他公平性的概念已经被提出，特别是conditional statistical parity和equal opportunity。然而，E通常不直接可见于数据中，即是隐藏变量。我们可以观察一些其他变量Z代表E，但问题是Z也可能受到S的影响，因此Z本身可能受到偏见。为解决这个问题，我们提出了BaBE（极 bayesian偏见消除）方法，该方法基于极 bayes推理和期望最大化方法，以估计每个组的E值。然后，决策可以直接基于估计的E值。我们通过对synthetic和实际数据集进行实验，显示了我们的方法可以实现高度的公平性和准确率。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Solve-Tasks-with-Exploring-Prior-Behaviours"><a href="#Learning-to-Solve-Tasks-with-Exploring-Prior-Behaviours" class="headerlink" title="Learning to Solve Tasks with Exploring Prior Behaviours"></a>Learning to Solve Tasks with Exploring Prior Behaviours</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02889">http://arxiv.org/abs/2307.02889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ricky-zhu/irdec">https://github.com/ricky-zhu/irdec</a></li>
<li>paper_authors: Ruiqi Zhu, Siyuan Li, Tianhong Dai, Chongjie Zhang, Oya Celiktutan</li>
<li>for: 解决深度强化学习（DRL）中任务具有稀有奖励的问题。</li>
<li>methods: 提出了内在奖励驱动示例基本控制（IRDEC）方法，可以让代理人学习和获得需要的先行行为，然后将其与任务特定的行为相连以解决稀有奖励任务。</li>
<li>results: 在三个导航任务和一个机械抓取任务中，与其他基准方法相比，IRDEC方法表现出色。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Ricky-Zhu/IRDEC%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Ricky-Zhu/IRDEC中找到。</a><details>
<summary>Abstract</summary>
Demonstrations are widely used in Deep Reinforcement Learning (DRL) for facilitating solving tasks with sparse rewards. However, the tasks in real-world scenarios can often have varied initial conditions from the demonstration, which would require additional prior behaviours. For example, consider we are given the demonstration for the task of \emph{picking up an object from an open drawer}, but the drawer is closed in the training. Without acquiring the prior behaviours of opening the drawer, the robot is unlikely to solve the task. To address this, in this paper we propose an Intrinsic Rewards Driven Example-based Control \textbf{(IRDEC)}. Our method can endow agents with the ability to explore and acquire the required prior behaviours and then connect to the task-specific behaviours in the demonstration to solve sparse-reward tasks without requiring additional demonstration of the prior behaviours. The performance of our method outperforms other baselines on three navigation tasks and one robotic manipulation task with sparse rewards. Codes are available at https://github.com/Ricky-Zhu/IRDEC.
</details>
<details>
<summary>摘要</summary>
深度强化学习（DRL）中广泛使用演示来解决 tasks with sparse rewards。然而，实际场景中的任务可能有不同的初始条件和演示，需要更多的先行行为。例如，假设我们给出了拾取从开放抽屉的任务演示，但抽屉在训练中是关闭的。如果不具备开抽屉的先行行为，机器人很难解决任务。为此，在这篇论文中，我们提出了内在奖励驱动的例子基于控制方法（IRDEC）。我们的方法可以让代理人具备解决 sparse-reward 任务的能力，并且不需要额外的先行行为演示。我们的方法的性能超过了其他基线在三个导航任务和一个机器人抓取任务上。代码可以在 <https://github.com/Ricky-Zhu/IRDEC> 查看。
</details></li>
</ul>
<hr>
<h2 id="Contrast-Is-All-You-Need"><a href="#Contrast-Is-All-You-Need" class="headerlink" title="Contrast Is All You Need"></a>Contrast Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02882">http://arxiv.org/abs/2307.02882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rprokap/pset-9">https://github.com/rprokap/pset-9</a></li>
<li>paper_authors: Burak Kilic, Florix Bex, Albert Gatt</li>
<li>for: 本研究探讨了数据稀缺的分类场景，其中可用的法律涂抹数据少而受损，可能影响结果质量。</li>
<li>methods: 我们采用了两种finetuning目标，分别是SetFit（句子变换器finetuning）和普通的finetuningSetup，对法律规定分类任务进行了训练。此外，我们使用了LIME（本地可解释性模型无关描述）来检查模型决策中哪些特定特征的贡献。</li>
<li>results: 结果表明，使用SetFit的对比学习设置可以在使用一部分训练样本的情况下表现更好，而且LIME结果显示，对于法律有用的特征都得到了增强，这些特征对于分类决策起到了至关重要的作用。因此，一个使用对比学习目标进行finetuning的模型似乎更自信地基于法律有用的特征来做决策。<details>
<summary>Abstract</summary>
In this study, we analyze data-scarce classification scenarios, where available labeled legal data is small and imbalanced, potentially hurting the quality of the results. We focused on two finetuning objectives; SetFit (Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla finetuning setup on a legal provision classification task. Additionally, we compare the features that are extracted with LIME (Local Interpretable Model-agnostic Explanations) to see which particular features contributed to the model's classification decisions. The results show that a contrastive setup with SetFit performed better than vanilla finetuning while using a fraction of the training samples. LIME results show that the contrastive learning approach helps boost both positive and negative features which are legally informative and contribute to the classification results. Thus a model finetuned with a contrastive objective seems to base its decisions more confidently on legally informative features.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们分析了数据缺乏的分类场景，其中可用的法律批注数据较少、不均衡，可能影响结果质量。我们关注了两个精度调整目标：SetFit（句子变换器精度调整）和普通的精度调整setup，在法律条文分类任务上进行了比较。此外，我们使用LIME（本地可解释模型无关性解释）来比较这两个setup中提取的特征，以确定哪些特征对模型的分类决策产生了影响。结果显示，使用SetFit的对比学习设置可以在使用一小部分训练样本的情况下比普通的精度调整setup表现更好。LIME结果显示，对比学习 Approach Helps 提高了正面和负面的法律有用特征，这些特征对分类结果产生了重要的贡献。因此，一个通过对比学习 objective 精度调整的模型似乎更加可靠地基于法律有用的特征来做出决策。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-safe-MLOps-Process-for-the-Continuous-Development-and-Safety-Assurance-of-ML-based-Systems-in-the-Railway-Domain"><a href="#Towards-a-safe-MLOps-Process-for-the-Continuous-Development-and-Safety-Assurance-of-ML-based-Systems-in-the-Railway-Domain" class="headerlink" title="Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain"></a>Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02867">http://arxiv.org/abs/2307.02867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Zeller, Thomas Waschulzik, Reiner Schmid, Claus Bahlmann</li>
<li>for: 这个论文主要是为了探讨如何实现驾驶automation技术的可靠性和高效性，以便在非限制性基础设施上实现自动驾驶列车（GoA4）。</li>
<li>methods: 论文使用机器学习（ML）技术来实现必要的感知任务，并提出了一种安全的MLOps过程，以便可靠地部署和改进ML模型，以适应不断变化的运行环境。</li>
<li>results: 论文提出了一种 integrate system engineering, safety assurance, 和 ML 生命周期的全面工作流程，并描述了自动化不同阶段的挑战。该过程可以提高 ML 模型的可靠性和高效性，并且可以适应不断变化的运行环境。<details>
<summary>Abstract</summary>
Traditional automation technologies alone are not sufficient to enable driverless operation of trains (called Grade of Automation (GoA) 4) on non-restricted infrastructure. The required perception tasks are nowadays realized using Machine Learning (ML) and thus need to be developed and deployed reliably and efficiently. One important aspect to achieve this is to use an MLOps process for tackling improved reproducibility, traceability, collaboration, and continuous adaptation of a driverless operation to changing conditions. MLOps mixes ML application development and operation (Ops) and enables high frequency software releases and continuous innovation based on the feedback from operations. In this paper, we outline a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain. It integrates system engineering, safety assurance, and the ML life-cycle in a comprehensive workflow. We present the individual stages of the process and their interactions. Moreover, we describe relevant challenges to automate the different stages of the safe MLOps process.
</details>
<details>
<summary>摘要</summary>
传统自动化技术独立不能够实现列车无人驾驶（称为级别自动化（GoA）4）在不受限制的基础设施上。需要完成的感知任务现在通常使用机器学习（ML）来实现，因此需要可靠地开发和部署，以及持续地适应变化的条件。一个重要的方法是使用 MLOps 过程来提高可重复性、跟踪性、合作和不断创新，以便基于运行Feedback进行持续更新和改进。在这篇文章中，我们描述了一种安全的 MLOps 过程，用于无间断开发和验证 ML 基于系统的安全保障。它结合了系统工程、安全验证和 ML 生命周期在一个完整的工作流中。我们还描述了自动化不同阶段的安全 MLOps 过程中的挑战。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-LLM-with-Evolutionary-Fine-Tuning-for-News-Summary-Generation"><a href="#Enhancing-LLM-with-Evolutionary-Fine-Tuning-for-News-Summary-Generation" class="headerlink" title="Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation"></a>Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02839">http://arxiv.org/abs/2307.02839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Xiao, Xiaolin Chen</li>
<li>for: 本研究旨在提出一种新的新闻概要生成方法，使用LLM进行多种结构化事件模式提取、进化和选择，以生成准确可靠的新闻概要。</li>
<li>methods: 本研究使用LLM进行多种结构化事件模式提取，然后使用遗传算法进化事件模式人口，最后选择最适应的事件模式输入LLM生成新闻概要。</li>
<li>results: 实验结果表明，新闻概要生成器能够生成准确可靠的新闻概要，并具有一定的泛化能力。<details>
<summary>Abstract</summary>
News summary generation is an important task in the field of intelligence analysis, which can provide accurate and comprehensive information to help people better understand and respond to complex real-world events. However, traditional news summary generation methods face some challenges, which are limited by the model itself and the amount of training data, as well as the influence of text noise, making it difficult to generate reliable information accurately. In this paper, we propose a new paradigm for news summary generation using LLM with powerful natural language understanding and generative capabilities. We use LLM to extract multiple structured event patterns from the events contained in news paragraphs, evolve the event pattern population with genetic algorithm, and select the most adaptive event pattern to input into the LLM to generate news summaries. A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate news summaries. The experimental results show that the news summary generator is able to generate accurate and reliable news summaries with some generalization ability.
</details>
<details>
<summary>摘要</summary>
新闻概要生成是智能分析领域的重要任务，可以提供准确和全面的信息，帮助人们更好地理解和应对复杂的现实世界事件。然而，传统的新闻概要生成方法面临着一些挑战，这些挑战限制了模型本身和训练数据量，以及文本噪音的影响，使得生成可靠信息具有困难。在这篇论文中，我们提出了一种基于LLM的新闻概要生成方法。我们使用LLM提取新闻段落中包含的多种结构化事件模式，然后使用遗传算法演化事件模式人口，并将最适应的事件模式输入到LLM中生成新闻概要。一个新闻概要生成器（NSG）是设计用于选择和演化事件模式人口，并生成新闻概要。实验结果表明，新闻概要生成器能够生成准确和可靠的新闻概要，并具有一定的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Read-Look-or-Listen-What’s-Needed-for-Solving-a-Multimodal-Dataset"><a href="#Read-Look-or-Listen-What’s-Needed-for-Solving-a-Multimodal-Dataset" class="headerlink" title="Read, Look or Listen? What’s Needed for Solving a Multimodal Dataset"></a>Read, Look or Listen? What’s Needed for Solving a Multimodal Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04532">http://arxiv.org/abs/2307.04532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Netta Madvil, Yonatan Bitton, Roy Schwartz</li>
<li>for: 这篇论文主要是为了分析大规模多modal数据集的质量。</li>
<li>methods: 该方法使用一个小的人工标注种子来将每个多modal实例映射到需要处理它的modalities。</li>
<li>results: 该方法发现大多数问题可以通过单一的modalities来解答，而且大约70%的问题可以使用多种不同的单modal策略解答，如视频或音频等。此外，该方法还发现MERLOT Reserve在图像基本问题上表现不佳，而且声音识别也有困难。基于这些观察，我们提出了一个新的测试集，其中模型性能明显下降。<details>
<summary>Abstract</summary>
The prevalence of large-scale multimodal datasets presents unique challenges in assessing dataset quality. We propose a two-step method to analyze multimodal datasets, which leverages a small seed of human annotation to map each multimodal instance to the modalities required to process it. Our method sheds light on the importance of different modalities in datasets, as well as the relationship between them. We apply our approach to TVQA, a video question-answering dataset, and discover that most questions can be answered using a single modality, without a substantial bias towards any specific modality. Moreover, we find that more than 70% of the questions are solvable using several different single-modality strategies, e.g., by either looking at the video or listening to the audio, highlighting the limited integration of multiple modalities in TVQA. We leverage our annotation and analyze the MERLOT Reserve, finding that it struggles with image-based questions compared to text and audio, but also with auditory speaker identification. Based on our observations, we introduce a new test set that necessitates multiple modalities, observing a dramatic drop in model performance. Our methodology provides valuable insights into multimodal datasets and highlights the need for the development of more robust models.
</details>
<details>
<summary>摘要</summary>
“大规模多modal dataset的存在带来了评估dataset质量的困难。我们提出了一个two-step方法，利用一小部分的人类标注来将每个多modal instance映射到需要处理的modalities。我们的方法照明了不同modalities在dataset中的重要性，以及它们之间的关系。我们将方法应用到TVQA dataset上，发现大多数问题可以使用单一modalities来解答，没有明显的modalities偏好。此外，我们发现超过70%的问题可以使用多种不同的单modalities策略来解答，例如通过观看影片或聆听音频，这显示了TVQA中多modalities的整合有限。我们利用标注和分析MERLOT Reserve，发现它在影像基于问题上表现不佳，但也在语音和音频方面存在问题。根据我们的观察，我们创建了一个需要多 modalities的试点，观察到模型性能明显下降。我们的方法ologie提供了多modal dataset的有价值的内在性和强化模型的需求。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-raw-waveforms-with-deep-learning-frameworks-for-speech-emotion-recognition"><a href="#Evaluating-raw-waveforms-with-deep-learning-frameworks-for-speech-emotion-recognition" class="headerlink" title="Evaluating raw waveforms with deep learning frameworks for speech emotion recognition"></a>Evaluating raw waveforms with deep learning frameworks for speech emotion recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02820">http://arxiv.org/abs/2307.02820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeynep Hilal Kilimci, Ulku Bayraktar, Ayhan Kucukmanisa<br>for:The paper is written for the task of speech emotion recognition, specifically using raw audio files and deep neural networks to recognize emotions.methods:The proposed model uses a combination of machine learning algorithms, ensemble learning methods, and deep learning techniques, including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and hybrid CNN-LSTM models.results:The proposed model achieves state-of-the-art performance on six different data sets, including TESS+RAVDESS, EMO-DB, RAVDESS, CREMA, SAVEE, and TESS, with accuracy rates ranging from 90.34% to 95.86%. Specifically, the CNN model outperforms existing approaches with 95.86% accuracy on the TESS+RAVDESS data set using raw audio files.<details>
<summary>Abstract</summary>
Speech emotion recognition is a challenging task in speech processing field. For this reason, feature extraction process has a crucial importance to demonstrate and process the speech signals. In this work, we represent a model, which feeds raw audio files directly into the deep neural networks without any feature extraction stage for the recognition of emotions utilizing six different data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To demonstrate the contribution of proposed model, the performance of traditional feature extraction techniques namely, mel-scale spectogram, mel-frequency cepstral coefficients, are blended with machine learning algorithms, ensemble learning methods, deep and hybrid deep learning techniques. Support vector machine, decision tree, naive Bayes, random forests models are evaluated as machine learning algorithms while majority voting and stacking methods are assessed as ensemble learning techniques. Moreover, convolutional neural networks, long short-term memory networks, and hybrid CNN- LSTM model are evaluated as deep learning techniques and compared with machine learning and ensemble learning methods. To demonstrate the effectiveness of proposed model, the comparison with state-of-the-art studies are carried out. Based on the experiment results, CNN model excels existent approaches with 95.86% of accuracy for TESS+RAVDESS data set using raw audio files, thence determining the new state-of-the-art. The proposed model performs 90.34% of accuracy for EMO-DB with CNN model, 90.42% of accuracy for RAVDESS with CNN model, 99.48% of accuracy for TESS with LSTM model, 69.72% of accuracy for CREMA with CNN model, 85.76% of accuracy for SAVEE with CNN model in speaker-independent audio categorization problems.
</details>
<details>
<summary>摘要</summary>
音频情感认识是语音处理领域的一个挑战任务。为此，特征提取过程具有关键的重要性，以便处理和识别语音信号。在本研究中，我们提出了一种模型，即将原始音频文件直接输入深度神经网络，不需要特征提取阶段，用于情感识别。为了证明提案的贡献，我们对传统特征提取技术（mel-scale spectrogram和mel-frequency cepstral coefficients）和机器学习算法（支持向量机器、决策树、愚蠢搜索、Random Forest）、ensemble学习方法（大多数投票和堆叠法）、深度学习技术（卷积神经网络、长期短期记忆网络和混合卷积LSTM）进行了评估。results表明，在TESS+RAVDESS数据集上，我们的模型在使用原始音频文件时达到了95.86%的准确率，从而确定了新的州OF-THE-ART。此外，我们的模型在EMO-DB、RAVDESS、TESS、CREMA和SAVEE数据集上也达到了高度的准确率。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Domain-Adaptive-Medical-Image-Segmentation-through-Consistency-Regularized-Disentangled-Contrastive-Learning"><a href="#Semi-supervised-Domain-Adaptive-Medical-Image-Segmentation-through-Consistency-Regularized-Disentangled-Contrastive-Learning" class="headerlink" title="Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning"></a>Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02798">http://arxiv.org/abs/2307.02798</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hritam-98/gfda-disentangled">https://github.com/hritam-98/gfda-disentangled</a></li>
<li>paper_authors: Hritam Basak, Zhaozheng Yin<br>for:This paper focuses on semi-supervised domain adaptation (SSDA) for medical image segmentation, which can improve the adaptation performance with only a few labeled target samples.methods:The proposed method uses a two-stage training process, including pre-training an encoder using a novel domain-content disentangled contrastive learning (CL) and fine-tuning the encoder and decoder for pixel-level segmentation using a semi-supervised setting. The CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics, while consistency regularization maintains spatial sensitivity.results:The proposed method outperforms state-of-the-art (SoTA) methods in both SSDA and unsupervised domain adaptation (UDA) settings, demonstrating its effectiveness in improving the adaptation performance with limited labeled target samples.<details>
<summary>Abstract</summary>
Although unsupervised domain adaptation (UDA) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts. In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially. Specifically, we propose a two-stage training process. First, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (CL) along with a pixel-level feature consistency constraint. The proposed CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity. This pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task, (i.e. pixel-level segmentation) using a semi-supervised setting. Furthermore, we experimentally validate that our proposed method can easily be extended for UDA settings, adding to the superiority of the proposed strategy. Upon evaluation on two domain adaptive image segmentation tasks, our proposed method outperforms the SoTA methods, both in SSDA and UDA settings. Code is available at https://github.com/hritam-98/GFDA-disentangled
</details>
<details>
<summary>摘要</summary>
although unsupervised domain adaptation (uda) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts. in this work, we investigate relatively less explored semi-supervised domain adaptation (ssda) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially. specifically, we propose a two-stage training process. first, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (cl) along with a pixel-level feature consistency constraint. the proposed cl enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity. this pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task (i.e. pixel-level segmentation) using a semi-supervised setting. furthermore, we experimentally validate that our proposed method can easily be extended for uda settings, adding to the superiority of the proposed strategy. upon evaluation on two domain adaptive image segmentation tasks, our proposed method outperforms the soTA methods, both in ssda and uda settings. code is available at https://github.com/hritam-98/gfda-disentangled.Note: Please note that the translation is in Simplified Chinese, and the formatting of the text may be different from the original English version.
</details></li>
</ul>
<hr>
<h2 id="BHEISR-Nudging-from-Bias-to-Balance-–-Promoting-Belief-Harmony-by-Eliminating-Ideological-Segregation-in-Knowledge-based-Recommendations"><a href="#BHEISR-Nudging-from-Bias-to-Balance-–-Promoting-Belief-Harmony-by-Eliminating-Ideological-Segregation-in-Knowledge-based-Recommendations" class="headerlink" title="BHEISR: Nudging from Bias to Balance – Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations"></a>BHEISR: Nudging from Bias to Balance – Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02797">http://arxiv.org/abs/2307.02797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengyan Wang, Yuxuan Hu, Zihan Yuan, Chenting Jiang, Weihua Li, Shiqing Wu, Quan Bai</li>
<li>for:  Addressing the issue of belief imbalance and user biases in personalized recommendation systems, and mitigating the negative effects of the filter bubble phenomenon.</li>
<li>methods:  Introducing an innovative intermediate agency (BHEISR) that combines principles from nudge theory and user-specific category information to stimulate curiosity and broaden users’ belief horizons.</li>
<li>results:  Experimental results show that the BHEISR model outperforms several baseline models in mitigating filter bubbles and balancing user perspectives, with improved recommendation diversity and user satisfaction.<details>
<summary>Abstract</summary>
In the realm of personalized recommendation systems, the increasing concern is the amplification of belief imbalance and user biases, a phenomenon primarily attributed to the filter bubble. Addressing this critical issue, we introduce an innovative intermediate agency (BHEISR) between users and existing recommendation systems to attenuate the negative repercussions of the filter bubble effect in extant recommendation systems. The main objective is to strike a belief balance for users while minimizing the detrimental influence caused by filter bubbles. The BHEISR model amalgamates principles from nudge theory while upholding democratic and transparent principles. It harnesses user-specific category information to stimulate curiosity, even in areas users might initially deem uninteresting. By progressively stimulating interest in novel categories, the model encourages users to broaden their belief horizons and explore the information they typically overlook. Our model is time-sensitive and operates on a user feedback loop. It utilizes the existing recommendation algorithm of the model and incorporates user feedback from the prior time frame. This approach endeavors to transcend the constraints of the filter bubble, enrich recommendation diversity, and strike a belief balance among users while also catering to user preferences and system-specific business requirements. To validate the effectiveness and reliability of the BHEISR model, we conducted a series of comprehensive experiments with real-world datasets. These experiments compared the performance of the BHEISR model against several baseline models using nearly 200 filter bubble-impacted users as test subjects. Our experimental results conclusively illustrate the superior performance of the BHEISR model in mitigating filter bubbles and balancing user perspectives.
</details>
<details>
<summary>摘要</summary>
在个性化推荐系统领域，现在的关注点是增强信念偏袋和用户偏见的问题，这主要归结于筛波效应。为解决这个关键问题，我们提出了一种创新的中间机制（BHEISR），位于用户和现有推荐系统之间，以减少现有推荐系统中的筛波效应的负面影响。BHEISR模型结合了抽象理论的原则，同时保持民主和透明的原则。它利用用户特定的类别信息，以刺激好奇，使用户在原来可能看得不愿意的领域中感兴趣。通过逐渐刺激用户对新类别的兴趣，模型让用户扩大他们的信念范围，探索通常被忽略的信息。我们的模型采用时间敏感的方式，通过用户反馈循环来运作。它利用现有推荐算法的模型，并将用户之前时间段的反馈纳入考虑。这种方法尝试突破筛波效应的限制，提高推荐多样性，并在用户中维护信念的平衡。为验证BHEISR模型的效果和可靠性，我们进行了一系列完整的实验，使用了现实世界数据集。这些实验比较了BHEISR模型与多个基eline模型的性能，使用了约200个受筛波影响的用户作为测试对象。我们的实验结果明确地表明，BHEISR模型在缓解筛波和平衡用户视角方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="What-Should-Data-Science-Education-Do-with-Large-Language-Models"><a href="#What-Should-Data-Science-Education-Do-with-Large-Language-Models" class="headerlink" title="What Should Data Science Education Do with Large Language Models?"></a>What Should Data Science Education Do with Large Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02792">http://arxiv.org/abs/2307.02792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinming Tu, James Zou, Weijie J. Su, Linjun Zhang</li>
<li>for: 这个论文主要针对的是数据科学和统计领域的大语言模型（LLMs）的快速发展，以及这些state-of-the-art工具如何改变数据科学家的角色和职责。</li>
<li>methods: 这篇论文使用了各种LLMs，如ChatGPT，来描述数据科学家的角色发展和教育改革。</li>
<li>results: 论文认为，LLMs将改变数据科学家的职责，从手动编程、数据处理和标准分析中转移到评估和管理由自动化AI进行的分析。这种角色转变类似于软件工程师转变为产品经理。<details>
<summary>Abstract</summary>
The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and learning tools, contributing to personalized education. This paper discusses the opportunities, resources and open challenges for each of these directions. As with any transformative technology, integrating LLMs into education calls for careful consideration. While LLMs can perform repetitive tasks efficiently, it's crucial to remember that their role is to supplement human intelligence and creativity, not to replace it. Therefore, the new era of data science education should balance the benefits of LLMs while fostering complementary human expertise and innovations. In conclusion, the rise of LLMs heralds a transformative period for data science and its education. This paper seeks to shed light on the emerging trends, potential opportunities, and challenges accompanying this paradigm shift, hoping to spark further discourse and investigation into this exciting, uncharted territory.
</details>
<details>
<summary>摘要</summary>
大 language models (LLMs) 的快速发展，如 ChatGPT，正在改变数据科学和统计领域。这些先进工具可以快速完成复杂的任务。因此，它们正在改变数据科学家的职责，从手动编程、数据处理和执行标准分析中转移注意力到评估和管理由这些自动化 AI 执行的分析。这种职业发展类似于软件工程师转变为产品经理。我们通过使用 LLMs 进行具体的数据科学案例研究， Illustrates 这种职业转变。这些发展需要数据科学教育做出深刻的改变。教学方法现需要更多地强调学生培养多样化的技能集，如 LLM  Informed 创造力、批判性思维和 AI 领导编程。LLMs 也可以在教室中作为互动教学工具，贡献个性化教育。这篇文章讨论了这些方向的机会、资源和开放挑战。与任何转型技术一样，将 LLMs integrated 到教育中需要仔细考虑。虽然 LLMs 可以高效完成 repetitive 任务，但是它们的角色是补充人类智能和创造力，不是取代它们。因此，新的数据科学教育时代应该平衡 LLMS 的利点，同时培养补充人类专业知识和创新。总之，LLMs 的出现标志着数据科学和其教育的转型期。这篇文章 hoping 通过探讨 emerging 趋势、可能的机会和挑战，引发更多的讨论和调查，深入探索这个新、未知的领域。
</details></li>
</ul>
<hr>
<h2 id="The-Role-of-Subgroup-Separability-in-Group-Fair-Medical-Image-Classification"><a href="#The-Role-of-Subgroup-Separability-in-Group-Fair-Medical-Image-Classification" class="headerlink" title="The Role of Subgroup Separability in Group-Fair Medical Image Classification"></a>The Role of Subgroup Separability in Group-Fair Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02791">http://arxiv.org/abs/2307.02791</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/biomedia-mira/subgroup-separability">https://github.com/biomedia-mira/subgroup-separability</a></li>
<li>paper_authors: Charles Jones, Mélanie Roschewitz, Ben Glocker</li>
<li>for: 本研究探讨深度分类器的性能差异。</li>
<li>methods: 本研究使用 teoretic analysis 和广泛的实验评估，探讨模型在不平等数据上训练时的性能差异。</li>
<li>results: 研究发现，不同医疗成像方式和保护特征下的模型性能差异有很大，而且这种差异可以预测模型偏见。这些发现提供了开发公平医疗AI的重要洞察。<details>
<summary>Abstract</summary>
We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.
</details>
<details>
<summary>摘要</summary>
我们研究深度分类器的性能差异。我们发现不同医疗影像模式和保护特征下的分类器能力对各个子群体进行分类有所不同，并且这种性质可以预测算法偏见。通过理论分析和广泛的实验评估，我们发现与偏见系统化医疗数据进行训练时，模型性能下降的关系，并且这种关系与子群体分化性和偏见系统化医疗数据之间存在相互关系。我们的发现为开发公正医疗AI提供了重要的新idea。
</details></li>
</ul>
<hr>
<h2 id="Censored-Sampling-of-Diffusion-Models-Using-3-Minutes-of-Human-Feedback"><a href="#Censored-Sampling-of-Diffusion-Models-Using-3-Minutes-of-Human-Feedback" class="headerlink" title="Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback"></a>Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02770">http://arxiv.org/abs/2307.02770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tetrzim/diffusion-human-feedback">https://github.com/tetrzim/diffusion-human-feedback</a></li>
<li>paper_authors: TaeHo Yoon, Kibeom Myoung, Keon Lee, Jaewoong Cho, Albert No, Ernest K. Ryu</li>
<li>for: 这个研究用于约束 diffusion 模型生成高品质图像，并解决偶发生部分错配的问题。</li>
<li>methods: 使用预训 diffusion 模型，并使用一个以少量人工回馈训练的奖励模型来约束生成。</li>
<li>results: 这个方法可以实现高效的人工回馈，并且只需要几分钟的人工回馈来生成足够的标签。<details>
<summary>Abstract</summary>
Diffusion models have recently shown remarkable success in high-quality image generation. Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images. If so, we simply need to prevent the generation of the bad images, and we call this task censoring. In this work, we present censored generation with a pre-trained diffusion model using a reward model trained on minimal human feedback. We show that censoring can be accomplished with extreme human feedback efficiency and that labels generated with a mere few minutes of human feedback are sufficient. Code available at: https://github.com/tetrzim/diffusion-human-feedback.
</details>
<details>
<summary>摘要</summary>
吸引模型最近已经显示出很好的成像质量。然而，有时候预训 diffusion model 会出现部分不稳定性，即模型可以生成好像，但也可能生成不想要的像。如果如此，我们只需要防止生成坏像，我们称这个任务为审查（censoring）。在这个工作中，我们使用预训 diffusion model 和少量人类反馈生成的 reward model，以审查生成的像。我们展示了审查可以通过EXTREME human feedback efficiency来实现，并且只需要几分钟的人类反馈就能生成足够的标签。代码可以在 GitHub 上找到：https://github.com/tetrzim/diffusion-human-feedback。
</details></li>
</ul>
<hr>
<h2 id="PRD-Peer-Rank-and-Discussion-Improve-Large-Language-Model-based-Evaluations"><a href="#PRD-Peer-Rank-and-Discussion-Improve-Large-Language-Model-based-Evaluations" class="headerlink" title="PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations"></a>PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02762">http://arxiv.org/abs/2307.02762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcdnlp/PRD">https://github.com/bcdnlp/PRD</a></li>
<li>paper_authors: Ruosen Li, Teerth Patel, Xinya Du</li>
<li>for: 提高自然语言处理（NLP）模型的评估和比较自动化</li>
<li>methods: 使用参考自由的大语言模型（LLM）作为评估标准，并提出两种改进方法： peer rank（PR）算法和 peer discussion（PD）</li>
<li>results: 实验结果显示，我们的方法可以提高评估准确率和与人类评价更加一致，同时PR算法可以在匿名设定下实现相对准确的自我评估。<details>
<summary>Abstract</summary>
Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized "strongest" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two answers. We conduct experiments on two benchmark datasets. We find that our approaches achieve higher accuracy and align better with human judgments, respectively. Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed. Our work provides space to explore evaluating models that are hard to compare for humans.
</details>
<details>
<summary>摘要</summary>
现在，不同的现代大语言模型（LLM）的回答质量很难自动评估和比较。 latest studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized "strongest" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two answers. We conduct experiments on two benchmark datasets. We find that our approaches achieve higher accuracy and align better with human judgments, respectively. Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed. Our work provides space to explore evaluating models that are hard to compare for humans.Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Graph-Self-Supervised-Rationalization-for-Recommendation"><a href="#Knowledge-Graph-Self-Supervised-Rationalization-for-Recommendation" class="headerlink" title="Knowledge Graph Self-Supervised Rationalization for Recommendation"></a>Knowledge Graph Self-Supervised Rationalization for Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02759">http://arxiv.org/abs/2307.02759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkuds/kgrec">https://github.com/hkuds/kgrec</a></li>
<li>paper_authors: Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang</li>
<li>for: 本文提出了一种新的自监理解方法，叫做 KGRec，用于知识感知推荐系统。</li>
<li>methods: 本文提出了一种注意力机制，用于生成有用的知识连接。这个机制根据知识三元组的 rational scores 进行评分，并将这些 scores 用于推荐系统中的生成和对比自我监管任务。</li>
<li>results: 对三个实际数据集进行了广泛的实验，显示 KGRec 可以超过当前的方法。此外，我们还提供了实现代码，可以在 <a target="_blank" rel="noopener" href="https://github.com/HKUDS/KGRec">https://github.com/HKUDS/KGRec</a> 中找到。<details>
<summary>Abstract</summary>
In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the rational scores are masked. Extensive experiments on three real-world datasets demonstrate that KGRec outperforms state-of-the-art methods. We also provide the implementation codes for our approach at https://github.com/HKUDS/KGRec.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的自动化逻辑化方法，即KGRec，用于知识推荐系统。为了有效地Identify informative知识连接，我们提议了一种注意力机制，生成了知识 triplets 的 rational scores。通过这些分数，KGRec integrate了生成和对比自我超vised任务来进行推荐。为了强调知识图中的逻辑，我们设计了一种新的生成任务，即mas-king-reconstructing。通过将高分 rational scores 中的重要知识掩码，KGRec 被训练来重建和强调有用的知识连接，并作为逻辑。此外，为了更加有效地合理化知识图学习的对抗效果，我们引入了一种对比学习任务，该任务将知识视图和用户ITEM视图的信号进行对比。为了避免噪声的影响，我们将两个图中的潜在噪声根据 rational scores 进行掩码。我们的实验表明，KGRec 在三个实际 dataset 上表现出色，并提供了实现代码在https://github.com/HKUDS/KGRec。
</details></li>
</ul>
<hr>
<h2 id="Offline-Reinforcement-Learning-with-Imbalanced-Datasets"><a href="#Offline-Reinforcement-Learning-with-Imbalanced-Datasets" class="headerlink" title="Offline Reinforcement Learning with Imbalanced Datasets"></a>Offline Reinforcement Learning with Imbalanced Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02752">http://arxiv.org/abs/2307.02752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Jiang, Sijie Chen, Jielin Qiu, Haoran Xu, Wai Kin Chan, Zhao Ding</li>
<li>for: This paper aims to address the issue of imbalanced datasets in offline reinforcement learning (RL) research, which can lead to neglect of real-world dataset distributions in the development of models.</li>
<li>methods: The proposed method utilizes the augmentation of conservative Q-learning (CQL) with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets.</li>
<li>results: The proposed method is shown to be superior to other baselines through empirical results on several tasks in the context of imbalanced datasets with varying levels of imbalance.Here’s the Chinese translation of the three points:</li>
<li>for: 本研究旨在解决现有的偏见RL数据集问题，这些数据集的分布在RL模型的开发中被忽略。</li>
<li>methods: 提议的方法利用CQL的扩展和回忆过程来重新回忆过去相关的经验，以解决偏见数据集中的挑战。</li>
<li>results: 对各种偏见数据集的实验结果表明，提议的方法比基eline方法更加有效。<details>
<summary>Abstract</summary>
The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the context of imbalanced datasets with varying levels of imbalance, utilizing the variant of D4RL. Empirical results demonstrate the superiority of our method over other baselines.
</details>
<details>
<summary>摘要</summary>
现有的大量实验算法（RL）研究中的标准实践是将注重在实验 dataset 的平衡性，导致实验 dataset 的不寻常性被忽略。实际上，现世界的 offline RL 资料集经常具有体积不寻常的状态空间分布，这可能是因为探索或安全考虑所带来的挑战。在这篇文章中，我们详细描述了实际上的 offline RL 资料集的不寻常性，其状态覆盖率遵循力量律分布，并且政策具有偏好性。我们理论和实验显示，通常的 offline RL 方法，如保守 Q-学习（CQL），在不寻常的 dataset 上不能够提取政策。受自然智慧启发，我们提出了一种新的 offline RL 方法，利用 CQL 的增强和回传过程来重新回传过去相关的体验，有效地解决了不寻常的 dataset 带来的挑战。我们在具有不同水平的不寻常度的任务上进行了评估，使用 D4RL 的变体。实验结果显示了我们的方法与其他基准相比有所superiority。
</details></li>
</ul>
<hr>
<h2 id="RecallM-An-Architecture-for-Temporal-Context-Understanding-and-Question-Answering"><a href="#RecallM-An-Architecture-for-Temporal-Context-Understanding-and-Question-Answering" class="headerlink" title="RecallM: An Architecture for Temporal Context Understanding and Question Answering"></a>RecallM: An Architecture for Temporal Context Understanding and Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02738">http://arxiv.org/abs/2307.02738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cisco-open/DeepVision/tree/main/recallm">https://github.com/cisco-open/DeepVision/tree/main/recallm</a></li>
<li>paper_authors: Brandon Kynoch, Hugo Latapie</li>
<li>for: 该论文旨在为基于语言模型（LLM）的聊天机器人开发持续学习、复杂逻辑和序列和时间相关性的理想长期记忆机制。</li>
<li>methods: 该论文提出了一种新的长期记忆建模方法，包括创建适应和更新长期记忆的AGI系统体系。</li>
<li>results: 经过多个实验，该方法能够提供更好的时间理解和知识掌握。<details>
<summary>Abstract</summary>
The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding of knowledge it provides.
</details>
<details>
<summary>摘要</summary>
理想的长期记忆机制为基于自然语言模型（LLM）的聊天机器人，将为持续学习、复杂逻辑和时间相关性学习 lay the foundation. 创建这种类型的记忆机制是极其困难的问题。在这篇论文中，我们探讨不同的方法来实现长期记忆的效果。我们提出了一种新的架构，专门为智能人工智能系统（AGI）创建可适应和可更新的长期记忆。我们通过多种实验证明了RecallM架构的优势，尤其是它在知识的时间理解方面的改善。
</details></li>
</ul>
<hr>
<h2 id="Fine-grained-Action-Analysis-A-Multi-modality-and-Multi-task-Dataset-of-Figure-Skating"><a href="#Fine-grained-Action-Analysis-A-Multi-modality-and-Multi-task-Dataset-of-Figure-Skating" class="headerlink" title="Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating"></a>Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02730">http://arxiv.org/abs/2307.02730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dingyn-Reno/MMFS">https://github.com/dingyn-Reno/MMFS</a></li>
<li>paper_authors: Sheng-Lan Liu, Yu-Ning Ding, Si-Fan Zhang, Wen-Yue Chen, Ning Zhou, Hao Liu, Gui-Hong Lao</li>
<li>for: 本研究的目的是提出一个多Modal和多任务的冰上滑冰动作数据集（MMFS），用于提高细化动作识别和评估。</li>
<li>methods: 本研究使用RGB、骨架和得分来收集11671个clip和256个类别，包括空间和时间标签。</li>
<li>results: 本研究的三大贡献是：1）独立的空间和时间类别来进一步探索细化动作识别和评估; 2）首次使用骨架模式进行复杂细化动作质量评估; 3）多Modal和多任务数据集鼓励更多的动作分析模型。<details>
<summary>Abstract</summary>
The fine-grained action analysis of the existing action datasets is challenged by insufficient action categories, low fine granularities, limited modalities, and tasks. In this paper, we propose a Multi-modality and Multi-task dataset of Figure Skating (MMFS) which was collected from the World Figure Skating Championships. MMFS, which possesses action recognition and action quality assessment, captures RGB, skeleton, and is collected the score of actions from 11671 clips with 256 categories including spatial and temporal labels. The key contributions of our dataset fall into three aspects as follows. (1) Independently spatial and temporal categories are first proposed to further explore fine-grained action recognition and quality assessment. (2) MMFS first introduces the skeleton modality for complex fine-grained action quality assessment. (3) Our multi-modality and multi-task dataset encourage more action analysis models. To benchmark our dataset, we adopt RGB-based and skeleton-based baseline methods for action recognition and action quality assessment.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT全球figure溜滑锦标赛中的现有动作数据集存在精细动作分类、低精细度、有限Modalities和任务的挑战。在本文中，我们提出了多模态和多任务figure溜滑数据集(MMFS)，该数据集来自于世界figure溜滑锦标赛。MMFS包含动作识别和动作质量评估，并收集了RGB、骨架和动作分数的11671个clip，包括256个类别，其中包括空间和时间标签。我们数据集的关键贡献有三个方面：1. 我们首次独立提出了空间和时间类别，以进一步探索精细动作识别和质量评估。2. MMFS首次引入骨架模式，为复杂精细动作质量评估提供了新的可能性。3. 我们的多模态和多任务数据集激励更多的动作分析模型。为了评估我们的数据集，我们采用了基于RGB和骨架的基eline方法进行动作识别和质量评估。>>
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Empowerment-Towards-Tractable-Empowerment-Based-Skill-Learning"><a href="#Hierarchical-Empowerment-Towards-Tractable-Empowerment-Based-Skill-Learning" class="headerlink" title="Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning"></a>Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02728">http://arxiv.org/abs/2307.02728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Levy, Sreehari Rammohan, Alessandro Allievi, Scott Niekum, George Konidaris</li>
<li>for: 这篇论文目的是学习大量独特技能的Agent。</li>
<li>methods: 论文使用了Goal-Conditioned Hierarchical Reinforcement Learning的概念，并提出了一个新的框架 called Hierarchical Empowerment，可以更方便地计算Empowerment。</li>
<li>results: 在一系列的 simulate robotics tasks 中，论文的四级Agent能够学习技能，覆盖了两个级别的表面积，比之前的工作更大。<details>
<summary>Abstract</summary>
General purpose agents will require large repertoires of skills. Empowerment -- the maximum mutual information between skills and the states -- provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize. We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning. Our framework makes two specific contributions. First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons. Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales. We verify the contributions of the framework in a series of simulated robotics tasks. In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work.
</details>
<details>
<summary>摘要</summary>
通用探索者需要大量技能。使owerment（最大共同信息）提供了学习大量独特技能的路径，但共同信息困难优化。我们提出了一个新的框架，层次empowerment，将goal-conditioned hierarchical reinforcement learning中的概念集成到计算empowerment中。我们的框架做出了两个具体贡献：首先，我们引入了一个新的Variational lower bound on mutual information，用于计算empowerment over short horizons。其次，我们引入了一个层次结构，用于计算empowerment over exponentially longer time scales。我们在一系列的模拟机器人任务中验证了我们的框架的贡献。在一个流行的蚂蚁导航领域中，我们的四级探索者能够学习技能，覆盖面积超过两个数量级。
</details></li>
</ul>
<hr>
<h2 id="TL-nvSRAM-CIM-Ultra-High-Density-Three-Level-ReRAM-Assisted-Computing-in-nvSRAM-with-DC-Power-Free-Restore-and-Ternary-MAC-Operations"><a href="#TL-nvSRAM-CIM-Ultra-High-Density-Three-Level-ReRAM-Assisted-Computing-in-nvSRAM-with-DC-Power-Free-Restore-and-Ternary-MAC-Operations" class="headerlink" title="TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations"></a>TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02717">http://arxiv.org/abs/2307.02717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dengfeng Wang, Liukai Xu, Songyuan Liu, zhi Li, Yiming Chen, Weifeng He, Xueqing Li, Yanan Su</li>
<li>for: 大规模神经网络（NN）的计算在内存（ computing-in-memory，CIM）中进行融合，以减少外部存储器访问。</li>
<li>methods: 使用高密度单级ReRAM（single-level ReRAM）和高效性SRAM-CIM（SRAM-based computing-in-memory）的集成，以实现在芯片上的大规模NN计算。</li>
<li>results: 提出了一种高密度三级ReRAM助け进行计算在非易失RAM（nonvolatile RAM，nvSRAM）中的大规模NN计算，并实现了对比基eline设计的7.8倍高的存储密度，以及2.9倍和1.9倍的能效性提升。<details>
<summary>Abstract</summary>
Accommodating all the weights on-chip for large-scale NNs remains a great challenge for SRAM based computing-in-memory (SRAM-CIM) with limited on-chip capacity. Previous non-volatile SRAM-CIM (nvSRAM-CIM) addresses this issue by integrating high-density single-level ReRAMs on the top of high-efficiency SRAM-CIM for weight storage to eliminate the off-chip memory access. However, previous SL-nvSRAM-CIM suffers from poor scalability for an increased number of SL-ReRAMs and limited computing efficiency. To overcome these challenges, this work proposes an ultra-high-density three-level ReRAMs-assisted computing-in-nonvolatile-SRAM (TL-nvSRAM-CIM) scheme for large NN models. The clustered n-selector-n-ReRAM (cluster-nSnRs) is employed for reliable weight-restore with eliminated DC power. Furthermore, a ternary SRAM-CIM mechanism with differential computing scheme is proposed for energy-efficient ternary MAC operations while preserving high NN accuracy. The proposed TL-nvSRAM-CIM achieves 7.8x higher storage density, compared with the state-of-art works. Moreover, TL-nvSRAM-CIM shows up to 2.9x and 1.9x enhanced energy-efficiency, respectively, compared to the baseline designs of SRAM-CIM and ReRAM-CIM, respectively.
</details>
<details>
<summary>摘要</summary>
实现大规模神经网络（NN）中的所有重量在芯片上是一个巨大的挑战，特别是在有限的芯片容量下。前一代非易失性SRAM-CIM（nvSRAM-CIM）解决了这个问题，通过将高密度单级ReRAM（SL-ReRAM）组装在高效率SRAM-CIM之上，以储存重量，并消除外部内存存取。然而，前一代SL-nvSRAM-CIM受到更多SL-ReRAM的扩展和有限的计算效率的限制。为了解决这些挑战，这个工作提出了一个超高密度三级ReRAM-助け（TL-nvSRAM-CIM）方案，用于大型NN模型。clustered n-selector-n-ReRAM（cluster-nSnRs）被用来保证可靠的重量复原，并消除了DC电压。此外，一个ternary SRAM-CIM机制（ternary SRAM-CIM）和分别计算方案（differential computing scheme）是提出，以节能地进行ternary MAC操作，保持高NN准确性。提案的TL-nvSRAM-CIM在存储密度方面比前一代作品高7.8倍，而且在计算效率方面比基准设计高2.9倍和1.9倍，分别比SRAM-CIM和ReRAM-CIM基准设计高。
</details></li>
</ul>
<hr>
<h2 id="Validation-of-the-Practicability-of-Logical-Assessment-Formula-for-Evaluations-with-Inaccurate-Ground-Truth-Labels"><a href="#Validation-of-the-Practicability-of-Logical-Assessment-Formula-for-Evaluations-with-Inaccurate-Ground-Truth-Labels" class="headerlink" title="Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels"></a>Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02709">http://arxiv.org/abs/2307.02709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongquan Yang, Hong Bu</li>
<li>for: 这篇论文是为了评估带有不准确真实标签（IAGTL）的预测模型而提出的新理论。</li>
<li>methods: 这篇论文使用了逻辑评估方程（LAF）来评估带有IAGTL的预测模型。</li>
<li>results: 实验结果表明，LAF可以有效地评估带有IAGTL的预测模型，并且在乳腺癌分 segmentation（TSfBC）领域的医学板卷图分析（MHWSIA）中得到了有效的结果。<details>
<summary>Abstract</summary>
Logical assessment formula (LAF) is a new theory proposed for evaluations with inaccurate ground-truth labels (IAGTLs) to assess the predictive models for various artificial intelligence applications. However, the practicability of LAF for evaluations with IAGTLs has not yet been validated in real-world practice. In this paper, to address this issue, we applied LAF to tumour segmentation for breast cancer (TSfBC) in medical histopathology whole slide image analysis (MHWSIA). Experimental results and analysis show the validity of LAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials of LAF applied to MHWSIA.
</details>
<details>
<summary>摘要</summary>
新的逻辑评估方程（LAF）是一种提议用于评估具有不准确真实标签（IAGTL）的预测模型，用于不同的人工智能应用。然而，LAF在实际应用中的实用性尚未得到证实。在这篇论文中，我们应用了LAF来评估乳腺癌 segmentation（TSfBC）在医学板寸影像分析（MHWSIA）中。实验结果和分析表明LAF对于具有IAGTL的评估是有效的，并且反映了LAF在MHWSIA中的潜在应用 potential。
</details></li>
</ul>
<hr>
<h2 id="Loss-Functions-and-Metrics-in-Deep-Learning-A-Review"><a href="#Loss-Functions-and-Metrics-in-Deep-Learning-A-Review" class="headerlink" title="Loss Functions and Metrics in Deep Learning. A Review"></a>Loss Functions and Metrics in Deep Learning. A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02694">http://arxiv.org/abs/2307.02694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Terven, Diana M. Cordova-Esparza, Alfonzo Ramirez-Pedraza, Edgar A. Chavez-Urbiola</li>
<li>for: 本文对深度学习中最常用的损失函数和性能指标进行了评估和梳理，以帮助读者选择适合自己特定任务的最佳方法。</li>
<li>methods: 本文评论了深度学习中最常用的损失函数和性能指标，包括损失函数的选择和性能指标的选择，并解释了每种方法的优缺点和应用场景。</li>
<li>results: 本文提供了深度学习中不同任务中的损失函数和性能指标的综述，并给出了各种任务的示例和应用。这些信息可以帮助读者更好地理解深度学习中的不同方法和技术，并选择适合自己特定任务的最佳方法。<details>
<summary>Abstract</summary>
One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
</details>
<details>
<summary>摘要</summary>
一个深度学习中的重要组成部分是选择用于训练和评估模型的损失函数和性能指标。本文查询了深度学习中最广泛使用的损失函数和性能指标，并分析它们的优缺点，以及它们在不同的深度学习问题中的应用。本文的审查旨在为具体任务选择最佳的方法，并给深度学习实践者提供一个全面的损失函数和性能指标选择指南。Here's the word-for-word translation of the text into Simplified Chinese:一个深度学习中的重要组成部分是选择用于训练和评估模型的损失函数和性能指标。本文查询了深度学习中最广泛使用的损失函数和性能指标，并分析它们的优缺点，以及它们在不同的深度学习问题中的应用。本文的审查旨在为具体任务选择最佳的方法，并给深度学习实践者提供一个全面的损失函数和性能指标选择指南。
</details></li>
</ul>
<hr>
<h2 id="SACHA-Soft-Actor-Critic-with-Heuristic-Based-Attention-for-Partially-Observable-Multi-Agent-Path-Finding"><a href="#SACHA-Soft-Actor-Critic-with-Heuristic-Based-Attention-for-Partially-Observable-Multi-Agent-Path-Finding" class="headerlink" title="SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding"></a>SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02691">http://arxiv.org/abs/2307.02691</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiushi-lin/sacha">https://github.com/qiushi-lin/sacha</a></li>
<li>paper_authors: Qiushi Lin, Hang Ma</li>
<li>for: 这篇论文主要研究了多 Agent Path Finding（MAPF）中多个 Agent 之间的协作问题，即每个 Agent 需要规划一个不与别的 Agent 相撞的路径以达到目标位置。</li>
<li>methods: 该论文提出了一种名为 Soft Actor-Critic with Heuristic-Based Attention（SACHA）的多 Agent 学习法，该法使用了 novel heuristic-based attention 机制来促进多 Agent 之间的协作。SACHA 学习了一个 neural network 来让每个 Agent 选择ively 听取多个 Agent 的最短路径准则引导，从而使得更可扩展地学习协作。</li>
<li>results:  comparied to 现有的学习基于方法，SACHA 和 SACHA(C) 在多种 MAPF 实例上显示出了较好的成绩，包括Success rate 和解决质量。<details>
<summary>Abstract</summary>
Multi-Agent Path Finding (MAPF) is a crucial component for many large-scale robotic systems, where agents must plan their collision-free paths to their given goal positions. Recently, multi-agent reinforcement learning has been introduced to solve the partially observable variant of MAPF by learning a decentralized single-agent policy in a centralized fashion based on each agent's partial observation. However, existing learning-based methods are ineffective in achieving complex multi-agent cooperation, especially in congested environments, due to the non-stationarity of this setting. To tackle this challenge, we propose a multi-agent actor-critic method called Soft Actor-Critic with Heuristic-Based Attention (SACHA), which employs novel heuristic-based attention mechanisms for both the actors and critics to encourage cooperation among agents. SACHA learns a neural network for each agent to selectively pay attention to the shortest path heuristic guidance from multiple agents within its field of view, thereby allowing for more scalable learning of cooperation. SACHA also extends the existing multi-agent actor-critic framework by introducing a novel critic centered on each agent to approximate $Q$-values. Compared to existing methods that use a fully observable critic, our agent-centered multi-agent actor-critic method results in more impartial credit assignment and better generalizability of the learned policy to MAPF instances with varying numbers of agents and types of environments. We also implement SACHA(C), which embeds a communication module in the agent's policy network to enable information exchange among agents. We evaluate both SACHA and SACHA(C) on a variety of MAPF instances and demonstrate decent improvements over several state-of-the-art learning-based MAPF methods with respect to success rate and solution quality.
</details>
<details>
<summary>摘要</summary>
多智能路径规划（MAPF）是许多大规模 роботиче系统中的关键组件，其中智能体需要规划避免碰撞的路径来到目标位置。在最近，多智能学习 reinforcement learning 被引入解决部分可见 MAPF 问题，通过学习一个均衡单个智能体策略来实现多智能体协作。然而，现有的学习基于方法在拥堵环境中效果不佳，主要因为这种设定的不可预测性。为了解决这个挑战，我们提出了一种多智能actor-critic方法called Soft Actor-Critic with Heuristic-Based Attention（SACHA），该方法使用了新的征量基于注意力机制来促进多智能体协作。SACHA 学习一个智能网络，以便每个智能体在其视野中选择多个智能体的最短路径征量引导，从而使得学习协作更加扩展。SACHA 还扩展了现有的多智能actor-critic框架，通过引入每个智能体中心的 $Q $-值评价器来更好地分配减少信息。与现有方法使用完全可见评价器相比，我们的代理中心多智能actor-critic方法可以更好地分配减少信息，并且更好地泛化学习到 MAPF 实例中的不同数量和类型的环境。此外，我们还实现了 SACHA（C），它在智能体策略网络中嵌入通信模块，以便智能体之间交换信息。我们对 SACHA 和 SACHA（C）在多种 MAPF 实例上进行评估，并证明它们在成功率和解决质量方面具有显著改进。
</details></li>
</ul>
<hr>
<h2 id="Scaling-In-Context-Demonstrations-with-Structured-Attention"><a href="#Scaling-In-Context-Demonstrations-with-Structured-Attention" class="headerlink" title="Scaling In-Context Demonstrations with Structured Attention"></a>Scaling In-Context Demonstrations with Structured Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02690">http://arxiv.org/abs/2307.02690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianle Cai, Kaixuan Huang, Jason D. Lee, Mengdi Wang</li>
<li>for: 提高大语言模型（LLM）在上下文学习中的能力，即从上下文中学习而无需参数更新。</li>
<li>methods: 提议一种新的建筑设计，即SAICL（结构化注意力 для上下文学习），它将全注意力替换为专门为上下文学习设计的结构化注意力机制，并消除不必要的示例之间的依赖关系，使模型不受示例顺序的影响。</li>
<li>results: SAICL在meta-training框架下评估，与全注意力相比具有相当或更好的性能，同时可以实现up to 3.4倍的搜索速度提升。SAICL还一直超越了一个强的Fusion-in-Decoder（FiD）基线，该基线每个示例都进行独立处理。最后，由于SAICL的线性特性，我们证明SAICL可以轻松扩展到数百个示例，并且随着扩展，性能会持续提高。<details>
<summary>Abstract</summary>
The recent surge of large language models (LLMs) highlights their ability to perform in-context learning, i.e., "learning" to perform a task from a few demonstrations in the context without any parameter updates. However, their capabilities of in-context learning are limited by the model architecture: 1) the use of demonstrations is constrained by a maximum sentence length due to positional embeddings; 2) the quadratic complexity of attention hinders users from using more demonstrations efficiently; 3) LLMs are shown to be sensitive to the order of the demonstrations. In this work, we tackle these challenges by proposing a better architectural design for in-context learning. We propose SAICL (Structured Attention for In-Context Learning), which replaces the full-attention by a structured attention mechanism designed for in-context learning, and removes unnecessary dependencies between individual demonstrations, while making the model invariant to the permutation of demonstrations. We evaluate SAICL in a meta-training framework and show that SAICL achieves comparable or better performance than full attention while obtaining up to 3.4x inference speed-up. SAICL also consistently outperforms a strong Fusion-in-Decoder (FiD) baseline which processes each demonstration independently. Finally, thanks to its linear nature, we demonstrate that SAICL can easily scale to hundreds of demonstrations with continuous performance gains with scaling.
</details>
<details>
<summary>摘要</summary>
Recent large language models (LLMs) have highlighted their ability to perform in-context learning, i.e., "learning" to perform a task from a few demonstrations in the context without any parameter updates. However, their capabilities of in-context learning are limited by the model architecture: 1) the use of demonstrations is constrained by a maximum sentence length due to positional embeddings; 2) the quadratic complexity of attention hinders users from using more demonstrations efficiently; 3) LLMs are shown to be sensitive to the order of the demonstrations. In this work, we tackle these challenges by proposing a better architectural design for in-context learning. We propose SAICL (Structured Attention for In-Context Learning), which replaces the full-attention by a structured attention mechanism designed for in-context learning, and removes unnecessary dependencies between individual demonstrations, while making the model invariant to the permutation of demonstrations. We evaluate SAICL in a meta-training framework and show that SAICL achieves comparable or better performance than full attention while obtaining up to 3.4x inference speed-up. SAICL also consistently outperforms a strong Fusion-in-Decoder (FiD) baseline which processes each demonstration independently. Finally, thanks to its linear nature, we demonstrate that SAICL can easily scale to hundreds of demonstrations with continuous performance gains with scaling.
</details></li>
</ul>
<hr>
<h2 id="Comparing-Apples-to-Apples-Generating-Aspect-Aware-Comparative-Sentences-from-User-Reviews"><a href="#Comparing-Apples-to-Apples-Generating-Aspect-Aware-Comparative-Sentences-from-User-Reviews" class="headerlink" title="Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Reviews"></a>Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03691">http://arxiv.org/abs/2307.03691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jessica Echterhoff, An Yan, Julian McAuley</li>
<li>for: 用于帮助用户寻找最佳选择 among many similar alternatives</li>
<li>methods: 使用 transformer 架构，包括 item encoding module、comparison generation module 和 novel decoding method for user personalization</li>
<li>results: 生成了 fluently diverse 的比较句子，并在人工评估研究中表明了 relevance 和 truthfulness 的性能<details>
<summary>Abstract</summary>
It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
</details>
<details>
<summary>摘要</summary>
寻找最佳产品中的多个相似alternative很时间consuming。比较句子可以帮助用户对多个 Item进行对比，并将重点放在Item的重要特征上。我们的模型由三个顺序组成：（i）Item编码模块，用于编码 Item进行比较；（ii）比较生成模块，通过自动生成比较句子的方式生成比较句子；（iii）用户个性化解码方法。我们的管道能够生成流畅和多样的比较句子。我们在人工评估研究中运行了我们生成的句子的相关性和真实性，发现我们的算法可以创建相关的和真实的比较句子。
</details></li>
</ul>
<hr>
<h2 id="AI4OPT-AI-Institute-for-Advances-in-Optimization"><a href="#AI4OPT-AI-Institute-for-Advances-in-Optimization" class="headerlink" title="AI4OPT: AI Institute for Advances in Optimization"></a>AI4OPT: AI Institute for Advances in Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02671">http://arxiv.org/abs/2307.02671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pascal Van Hentenryck, Kevin Dalmeijer</li>
<li>for: 本研究是NSF AI Institute for Advances in Optimization的简介，旨在结合人工智能和优化，以解决供应链、能源系统、半导体设计和生产、可持续食品系统等领域的问题。</li>
<li>methods: 本研究使用了”教学教育”哲学，提供了长期教育路径，以帮助工程师学习人工智能技术。</li>
<li>results: 本研究未提供结果，但描述了AI4OPT的目标和方法。<details>
<summary>Abstract</summary>
This article is a short introduction to AI4OPT, the NSF AI Institute for Advances in Optimization. AI4OPT fuses AI and Optimization, inspired by end-use cases in supply chains, energy systems, chip design and manufacturing, and sustainable food systems. AI4OPT also applies its "teaching the teachers" philosophy to provide longitudinal educational pathways in AI for engineering.
</details>
<details>
<summary>摘要</summary>
这篇文章是关于AI4OPT，美国国家科学基金会的人工智能实验室，它将人工智能和优化相结合，以解决来自供应链、能源系统、半导体设计和生产、可持续食品系统等领域的实际问题。AI4OPT还采用“教师教学”哲学，为工程领域提供了长期教育路径。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Convergence-of-Communications-Control-and-Machine-Learning-for-Secure-and-Autonomous-Vehicle-Navigation"><a href="#Convergence-of-Communications-Control-and-Machine-Learning-for-Secure-and-Autonomous-Vehicle-Navigation" class="headerlink" title="Convergence of Communications, Control, and Machine Learning for Secure and Autonomous Vehicle Navigation"></a>Convergence of Communications, Control, and Machine Learning for Secure and Autonomous Vehicle Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02663">http://arxiv.org/abs/2307.02663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tengchan Zeng, Aidin Ferdowsi, Omid Semiari, Walid Saad, Choong Seon Hong</li>
<li>for: 本研究旨在探讨自动驾驶汽车（CAV） navigate to target destinations 的问题，以便实现减少交通事故人类错误、提高交通效率、执行多种任务等优点。</li>
<li>methods: 本文使用沟通理论、控制理论和机器学习等方法，提出了解决CAV自动导航中的集成问题的方案。</li>
<li>results: 研究人员通过提出稳定轨迹追踪、鲁棒控制 противcyber-physical攻击、适应导航控制器设计等解决方案，以及在多辆CAV协调运动时的稳定队形、快速协作学习和分布式入侵检测等问题的分析和解决方案。<details>
<summary>Abstract</summary>
Connected and autonomous vehicles (CAVs) can reduce human errors in traffic accidents, increase road efficiency, and execute various tasks ranging from delivery to smart city surveillance. Reaping these benefits requires CAVs to autonomously navigate to target destinations. To this end, each CAV's navigation controller must leverage the information collected by sensors and wireless systems for decision-making on longitudinal and lateral movements. However, enabling autonomous navigation for CAVs requires a convergent integration of communication, control, and learning systems. The goal of this article is to explicitly expose the challenges related to this convergence and propose solutions to address them in two major use cases: Uncoordinated and coordinated CAVs. In particular, challenges related to the navigation of uncoordinated CAVs include stable path tracking, robust control against cyber-physical attacks, and adaptive navigation controller design. Meanwhile, when multiple CAVs coordinate their movements during navigation, fundamental problems such as stable formation, fast collaborative learning, and distributed intrusion detection are analyzed. For both cases, solutions using the convergence of communication theory, control theory, and machine learning are proposed to enable effective and secure CAV navigation. Preliminary simulation results are provided to show the merits of proposed solutions.
</details>
<details>
<summary>摘要</summary>
自适应并连接的自动车 (CAVs) 可以减少交通事故中人类错误，提高道路效率，并执行各种任务，从物交付到智能城市监测。为了实现这些利益，每辆 CAV 的导航控制器需要根据感知器和无线系统收集的信息进行决策。然而，为 CAvs 实现自主导航，需要通信、控制和学习系统的融合。这篇文章的目标是暴露 CAvs 自主导航中存在的挑战，并提出解决方案，并在两个主要应用场景中进行分析：不协调的 CAvs 和协调 CAvs。在不协调 CAvs 的导航中，存在稳定轨迹追踪、针对物理攻击的强健控制和适应导航控制器设计的挑战。而当多辆 CAvs 协调其运动时，存在稳定队形、快速协同学习和分布式入侵检测的基本问题。为了解决这些问题，文章提出了通信理论、控制理论和机器学习的融合解决方案。文章还提供了先前的 simulations 结果，以证明提议的解决方案的优点。
</details></li>
</ul>
<hr>
<h2 id="Many-objective-Optimization-via-Voting-for-Elites"><a href="#Many-objective-Optimization-via-Voting-for-Elites" class="headerlink" title="Many-objective Optimization via Voting for Elites"></a>Many-objective Optimization via Voting for Elites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02661">http://arxiv.org/abs/2307.02661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uvm-neurobotics-lab/move">https://github.com/uvm-neurobotics-lab/move</a></li>
<li>paper_authors: Jackson Dean, Nick Cheney</li>
<li>for:  solving many-objective optimization problems with complex trade-offs between objectives</li>
<li>methods: combines Many-Objective Evolutionary Algorithms and Quality Diversity algorithms like MAP-Elites, maintains a map of elites that perform well on different subsets of objective functions</li>
<li>results: outperforms a naive single-objective baseline on a 14-objective image-neuroevolution problem, relies on solutions jumping across bins (goal-switching) for better performance, suggests automatic identification of stepping stones or curriculum learning.<details>
<summary>Abstract</summary>
Real-world problems are often comprised of many objectives and require solutions that carefully trade-off between them. Current approaches to many-objective optimization often require challenging assumptions, like knowledge of the importance/difficulty of objectives in a weighted-sum single-objective paradigm, or enormous populations to overcome the curse of dimensionality in multi-objective Pareto optimization. Combining elements from Many-Objective Evolutionary Algorithms and Quality Diversity algorithms like MAP-Elites, we propose Many-objective Optimization via Voting for Elites (MOVE). MOVE maintains a map of elites that perform well on different subsets of the objective functions. On a 14-objective image-neuroevolution problem, we demonstrate that MOVE is viable with a population of as few as 50 elites and outperforms a naive single-objective baseline. We find that the algorithm's performance relies on solutions jumping across bins (for a parent to produce a child that is elite for a different subset of objectives). We suggest that this type of goal-switching is an implicit method to automatic identification of stepping stones or curriculum learning. We comment on the similarities and differences between MOVE and MAP-Elites, hoping to provide insight to aid in the understanding of that approach $\unicode{x2013}$ and suggest future work that may inform this approach's use for many-objective problems in general.
</details>
<details>
<summary>摘要</summary>
现实世界中的问题经常具有多个目标，需要一种精准地考虑这些目标的解决方案。现有的多目标优化方法常常假设知道目标的重要性和难度，或者需要庞大的人口来超越维度瓶颈。 combining了多目标演化算法和质量多样性算法的元素，我们提出了多目标优化via投票for elites（MOVE）。MOVE维护一个ELITES的地图，这些解决方案在不同的目标函数子集中表现出色。在一个14个目标图像神经演化问题上，我们展示了MOVE可以使用50个elites来解决问题，并且超越了单一目标基线。我们发现，该算法的性能取决于解决方案在不同目标函数子集之间跳跃（父代生成子代的时候，子代需要在不同的目标函数子集中表现出色）。我们认为这种目标跳跃是一种隐式的目标IDENTIFICATION或课程学习方法。我们对MOVE和MAP-Elites之间的相似性和不同进行评论，希望能够提供对这种方法的理解，并建议未来的工作可以为多目标问题的解决提供更多的指导。
</details></li>
</ul>
<hr>
<h2 id="UX-Heuristics-and-Checklist-for-Deep-Learning-powered-Mobile-Applications-with-Image-Classification"><a href="#UX-Heuristics-and-Checklist-for-Deep-Learning-powered-Mobile-Applications-with-Image-Classification" class="headerlink" title="UX Heuristics and Checklist for Deep Learning powered Mobile Applications with Image Classification"></a>UX Heuristics and Checklist for Deep Learning powered Mobile Applications with Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05513">http://arxiv.org/abs/2307.05513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christiane Gresse von Wangenheim, Gustavo Dirschnabel</li>
<li>for: 这个论文是为了提供 Deep Learning powered 移动应用程序图像分类的用户体验创新，以确保这些应用程序的有效使用。</li>
<li>methods: 该论文采用了文献综述和现有的移动应用程序图像分类的分析，并提出了一个初步的 AIX 规范集，以帮助设计人员开发更好的用户界面。</li>
<li>results: 该论文提出了一个在线课程和网络工具，以帮助实践者通过这些规范来评估和改进图像分类应用程序的用户界面。这些结果可以用于指导图像分类应用程序的界面设计，以及支持实践者开发更好的用户体验。<details>
<summary>Abstract</summary>
Advances in mobile applications providing image classification enabled by Deep Learning require innovative User Experience solutions in order to assure their adequate use by users. To aid the design process, usability heuristics are typically customized for a specific kind of application. Therefore, based on a literature review and analyzing existing mobile applications with image classification, we propose an initial set of AIX heuristics for Deep Learning powered mobile applications with image classification decomposed into a checklist. In order to facilitate the usage of the checklist we also developed an online course presenting the concepts and heuristics as well as a web-based tool in order to support an evaluation using these heuristics. These results of this research can be used to guide the design of the interfaces of such applications as well as support the conduction of heuristic evaluations supporting practitioners to develop image classification apps that people can understand, trust, and can engage with effectively.
</details>
<details>
<summary>摘要</summary>
进步的移动应用程序，通过深度学习实现影像分类，需要创新的用户体验解决方案，以确保用户能够正确使用这些应用程序。为了促进设计过程，通常会根据特定类型的应用程序进行用户性heet Customization。因此，根据文献综述和现有的移动应用程序影像分类，我们提出了一份初步的AIXheet for Deep Learning搭配的移动应用程序影像分类，分为一个检查表格。为了便利检查表格的使用，我们还开发了线上课程，介绍概念和heet，以及一个网页工具，以支持使用这些heet进行评估。这些研究结果可以用来引导这些应用程序的界面设计，以及支持实施这些heet进行评估，帮助实现人们能够理解、信任，并对这些应用程序进行有效的互动。
</details></li>
</ul>
<hr>
<h2 id="Surge-Routing-Event-informed-Multiagent-Reinforcement-Learning-for-Autonomous-Rideshare"><a href="#Surge-Routing-Event-informed-Multiagent-Reinforcement-Learning-for-Autonomous-Rideshare" class="headerlink" title="Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare"></a>Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02637">http://arxiv.org/abs/2307.02637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Garces, Stephanie Gil</li>
<li>for: 这篇论文是针对大型活动（如演唱会、运动赛等）导致需求峰值的问题，提出了一个学习框架，以便推断需求峰值并适应需求峰值，并生成合作的routing和搜寻策略。</li>
<li>methods: 本论文使用了以下方法：（i）网络上获取活动资讯的数据库框架，将活动资讯转换为紧密的 вектор表示，并将其用于神经网络中的训练；（ii）使用两个神经网络系统来预测活动需求的每小时变化，并使用这些紧密的 вектор表示来预测需求；（iii）使用抽象的预测方法来将公开available的需求资料对应到抽象的街道交叉点上，并使用这些预测值来预测需求峰值；（iv）使用可扩展的模型基于强化学习框架，使用预测的需求峰值来预测需求峰值，并使用一个代理人一次推断的方法来路由出租车。</li>
<li>results: 本论文的实验结果显示，使用本学习框架可以生成的路由策略，每分钟可以服务 $6$ 更多的请求（约 $360$ 更多的请求每小时），较其他模型基于强化学习框架和操作研究中的其他分布式方法和 классиical algorithms 更高。<details>
<summary>Abstract</summary>
Large events such as conferences, concerts and sports games, often cause surges in demand for ride services that are not captured in average demand patterns, posing unique challenges for routing algorithms. We propose a learning framework for an autonomous fleet of taxis that scrapes event data from the internet to predict and adapt to surges in demand and generates cooperative routing and pickup policies that service a higher number of requests than other routing protocols. We achieve this through a combination of (i) an event processing framework that scrapes the internet for event information and generates dense vector representations that can be used as input features for a neural network that predicts demand; (ii) a two neural network system that predicts hourly demand over the entire map, using these dense vector representations; (iii) a probabilistic approach that leverages locale occupancy schedules to map publicly available demand data over sectors to discretized street intersections; and finally, (iv) a scalable model-based reinforcement learning framework that uses the predicted demand over intersections to anticipate surges and route taxis using one-agent-at-a-time rollout with limited sampling certainty equivalence. We learn routing and pickup policies using real NYC ride share data for 2022 and information for more than 2000 events across 300 unique venues in Manhattan. We test our approach with a fleet of 100 taxis on a map with 38 different sectors (2235 street intersections). Our experimental results demonstrate that our method obtains routing policies that service $6$ more requests on average per minute (around $360$ more requests per hour) than other model-based RL frameworks and other classical algorithms in operations research when dealing with surge demand conditions.
</details>
<details>
<summary>摘要</summary>
大型活动如会议、音乐会和体育赛事会导致乘车服务的需求峰值，这些需求峰值不同于平均需求模式，对路由算法 pose unique challenges. We propose a learning framework for an autonomous fleet of taxis that scrapes event data from the internet to predict and adapt to surges in demand, and generates cooperative routing and pickup policies that can service a higher number of requests than other routing protocols. We achieve this through a combination of:(i) 事件处理框架，从互联网上抓取事件信息，生成可用作神经网络预测需求的密集 вектор表示;(ii) 两个神经网络系统，使用这些密集 вектор表示预测每小时的需求，涵盖整个地图;(iii) 一种 probabilistic 方法，使用可用于地点的公共需求数据来映射到分割的街口;(iv) 一种可扩展的模型基于 reinforcement learning 框架，使用预测的需求 над intersections 来预测峰值和路由TAXI 使用一个 Agent-at-a-time 扩展，限制采样确定Equivalence. We learn routing and pickup policies using real NYC ride share data for 2022 and information for more than 2000 events across 300 unique venues in Manhattan. We test our approach with a fleet of 100 taxis on a map with 38 different sectors (2235 street intersections). Our experimental results show that our method obtains routing policies that service $6$ more requests on average per minute (around $360$ more requests per hour) than other model-based RL frameworks and other classical algorithms in operations research when dealing with surge demand conditions.
</details></li>
</ul>
<hr>
<h2 id="An-explainable-model-to-support-the-decision-about-the-therapy-protocol-for-AML"><a href="#An-explainable-model-to-support-the-decision-about-the-therapy-protocol-for-AML" class="headerlink" title="An explainable model to support the decision about the therapy protocol for AML"></a>An explainable model to support the decision about the therapy protocol for AML</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02631">http://arxiv.org/abs/2307.02631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jade M. Almeida, Giovanna A. Castro, João A. Machado-Neto, Tiago A. Almeida</li>
<li>for: 这项研究的目的是支持医生决策最佳治疗协议，以提高患有AML的患者存活率。</li>
<li>methods: 该研究使用了可解释的机器学习模型，对患者的存活预测进行数据分析。</li>
<li>results: 研究结果显示，使用该模型可以安全地支持医生决策，并且有潜在的应用前景以提高治疗和预测 marker。<details>
<summary>Abstract</summary>
Acute Myeloid Leukemia (AML) is one of the most aggressive types of hematological neoplasm. To support the specialists' decision about the appropriate therapy, patients with AML receive a prognostic of outcomes according to their cytogenetic and molecular characteristics, often divided into three risk categories: favorable, intermediate, and adverse. However, the current risk classification has known problems, such as the heterogeneity between patients of the same risk group and no clear definition of the intermediate risk category. Moreover, as most patients with AML receive an intermediate-risk classification, specialists often demand other tests and analyses, leading to delayed treatment and worsening of the patient's clinical condition. This paper presents the data analysis and an explainable machine-learning model to support the decision about the most appropriate therapy protocol according to the patient's survival prediction. In addition to the prediction model being explainable, the results obtained are promising and indicate that it is possible to use it to support the specialists' decisions safely. Most importantly, the findings offered in this study have the potential to open new avenues of research toward better treatments and prognostic markers.
</details>
<details>
<summary>摘要</summary>
针对恶性白细胞肉瘤（AML）的诊断和治疗决策支持，患者通常根据细胞学和分子特征进行分类，分为三个风险类别：有利、中等和不利。然而，现有的风险分类系统存在多种问题，如患者群体内的多样性，中等风险类别的定义不清晰。此外，由于大多数AML患者被诊断为中等风险，专家经常要求更多的测试和分析，导致治疗延迟并使患者的临床状况加重。本文提出了数据分析和可解释机器学习模型，用于支持治疗决策。除了模型可解释性外，研究结果具有潜在的应用前景，可能用于更好地诊断和治疗AML。此外，本研究还开创了新的研究方向，可能为AML的更好的治疗和诊断做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Workload-Pattern-Analysis-for-Large-scale-Cloud-Databases"><a href="#Real-time-Workload-Pattern-Analysis-for-Large-scale-Cloud-Databases" class="headerlink" title="Real-time Workload Pattern Analysis for Large-scale Cloud Databases"></a>Real-time Workload Pattern Analysis for Large-scale Cloud Databases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02626">http://arxiv.org/abs/2307.02626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wang, Tianyi Li, Anni Wang, Xiaoze Liu, Lu Chen, Jie Chen, Jianye Liu, Junyang Wu, Feifei Li, Yunjun Gao</li>
<li>for: 这种论文旨在为大规模云数据库系统提供高效的工作负载模式发现和优化方法。</li>
<li>methods: 该论文提出了一种基于实时分析和精准执行的工作负载模式发现系统，名为Alibaba Workload Miner（AWM）。AWM使用了高维特征编码和在线分组方法来挖掘大规模云数据库的工作负载模式。</li>
<li>results: 实验结果表明，AWM可以提高工作负载模式发现精度达66%，并将在线推理延迟降低22%，相比之前的状态艺术。<details>
<summary>Abstract</summary>
Hosting database services on cloud systems has become a common practice. This has led to the increasing volume of database workloads, which provides the opportunity for pattern analysis. Discovering workload patterns from a business logic perspective is conducive to better understanding the trends and characteristics of the database system. However, existing workload pattern discovery systems are not suitable for large-scale cloud databases which are commonly employed by the industry. This is because the workload patterns of large-scale cloud databases are generally far more complicated than those of ordinary databases. In this paper, we propose Alibaba Workload Miner (AWM), a real-time system for discovering workload patterns in complicated large-scale workloads. AWM encodes and discovers the SQL query patterns logged from user requests and optimizes the querying processing based on the discovered patterns. First, Data Collection & Preprocessing Module collects streaming query logs and encodes them into high-dimensional feature embeddings with rich semantic contexts and execution features. Next, Online Workload Mining Module separates encoded queries by business groups and discovers the workload patterns for each group. Meanwhile, Offline Training Module collects labels and trains the classification model using the labels. Finally, Pattern-based Optimizing Module optimizes query processing in cloud databases by exploiting discovered patterns. Extensive experimental results on one synthetic dataset and two real-life datasets (extracted from Alibaba Cloud databases) show that AWM enhances the accuracy of pattern discovery by 66% and reduce the latency of online inference by 22%, compared with the state-of-the-arts.
</details>
<details>
<summary>摘要</summary>
主机数据库服务在云系统上成为常见做法。这导致数据库负载的增加，提供了 Pattern 分析的机会。从业务逻辑角度发现数据库系统的工作负载模式可以更好地了解系统的趋势和特点。然而，现有的工作负载模式发现系统不适用于大规模云数据库，这些云数据库通常被行业使用。这是因为大规模云数据库的工作负载模式通常比普通数据库更加复杂。在这篇论文中，我们提出了阿里巴巴工作负载挖掘（AWM），一个实时的工作负载模式发现系统。AWM 将用户请求中的 SQL 查询 logged 编码并分析，以优化查询处理。首先，数据收集和预处理模块将流动查询日志编码成高维ensional 特征嵌入，具有丰富的语义上下文和执行特征。接下来，在线工作挖掘模块将编码查询分成业务组，并发现每个组的工作负载模式。同时，离线训练模块收集标签并使用标签进行分类模型训练。最后，基于发现的模式， Pattern-based Optimizing 模块可以在云数据库中优化查询处理，以提高效率。我们在一个 sintetic 数据集和两个实际数据集（从阿里巴巴云数据库提取）进行了广泛的实验，结果显示，AWM 可以提高Pattern 发现精度达 66%，并将在线推理延迟降低 22%，相比之前的状态艺。
</details></li>
</ul>
<hr>
<h2 id="Learning-when-to-observe-A-frugal-reinforcement-learning-framework-for-a-high-cost-world"><a href="#Learning-when-to-observe-A-frugal-reinforcement-learning-framework-for-a-high-cost-world" class="headerlink" title="Learning when to observe: A frugal reinforcement learning framework for a high-cost world"></a>Learning when to observe: A frugal reinforcement learning framework for a high-cost world</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02620">http://arxiv.org/abs/2307.02620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cbellinger27/learning-when-to-observe-in-rl">https://github.com/cbellinger27/learning-when-to-observe-in-rl</a></li>
<li>paper_authors: Colin Bellinger, Mark Crowley, Isaac Tamblyn</li>
<li>for:  This paper focuses on the problem of learning in reinforcement learning (RL) when there is a high cost associated with measuring the state of the environment.</li>
<li>methods: The proposed method is called the Deep Dynamic Multi-Step Observationless Agent (DMSOA), which does not rely on costly measurements at each time step. Instead, it uses a deep neural network to learn when to observe the environment and when to act without observation.</li>
<li>results: The authors evaluate DMSOA on OpenAI gym and Atari Pong environments and show that it learns a better policy with fewer decision steps and measurements than the considered alternative from the literature.<details>
<summary>Abstract</summary>
Reinforcement learning (RL) has been shown to learn sophisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as materials design, deep-sea and planetary robot exploration and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly measurement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and measurements than the considered alternative from the literature. The corresponding code is available at: \url{https://github.com/cbellinger27/Learning-when-to-observe-in-RL
</details>
<details>
<summary>摘要</summary>
强化学习（RL）已经能够学习复杂任务，包括游戏、机器人、暖通空调和文本生成。但是，RL中的动作-感知循环通常假设在每个时间步骤上可以无成本地测量环境状态。在材料设计、深海和行星探险等应用中，可能存在高成本的环境状态测量或 aproximation。在这篇论文中，我们回顾了近期快速增长的文献，其中RL机器人可能不需要或甚至不想在每个时间步骤上进行costly的测量。基于这个视角，我们提出了深度动态多步无测量代理（DMSOA），并与文献进行比较。我们还通过对OpenAI Gym和Atari Pong环境进行实验，并证明了DMSOA可以在 fewer decision steps和测量下学习更好的策略。相关代码可以在以下链接获取：https://github.com/cbellinger27/Learning-when-to-observe-in-RL。
</details></li>
</ul>
<hr>
<h2 id="Federated-Epidemic-Surveillance"><a href="#Federated-Epidemic-Surveillance" class="headerlink" title="Federated Epidemic Surveillance"></a>Federated Epidemic Surveillance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02616">http://arxiv.org/abs/2307.02616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiqi Lyu, Bryan Wilder, Roni Rosenfeld</li>
<li>for: 这篇论文的目的是为了开发一种联邦方法来检测流行病，并且处理不可靠的数据。</li>
<li>methods: 这篇论文使用了一种将测试假设Push到各个看守者的防火墙后，然后进行meta分析来结合结果的方法。</li>
<li>results: 这篇论文的结果显示了联邦方法的可能性，并且透过实验和数据分析，显示了这种方法在检测流行病方面的优点和适用范围。<details>
<summary>Abstract</summary>
The surveillance of a pandemic is a challenging task, especially when crucial data is distributed and stakeholders cannot or are unwilling to share. To overcome this obstacle, federated methodologies should be developed to incorporate less sensitive evidence that entities are willing to provide. This study aims to explore the feasibility of pushing hypothesis tests behind each custodian's firewall and then meta-analysis to combine the results, and to determine the optimal approach for reconstructing the hypothesis test and optimizing the inference. We propose a hypothesis testing framework to identify a surge in the indicators and conduct power analyses and experiments on real and semi-synthetic data to showcase the properties of our proposed hypothesis test and suggest suitable methods for combining $p$-values. Our findings highlight the potential of using $p$-value combination as a federated methodology for pandemic surveillance and provide valuable insights into integrating available data sources.
</details>
<details>
<summary>摘要</summary>
“监控疫情需要复杂的努力，尤其是当重要的数据分散且掌控者无法或不愿分享。为了解决这个问题，我们应发展联邦方法ologies，将不sensitive的证据包含在内。这项研究尝试探索将假设测试传递到各个看守者的墙壁后，然后进行Meta-分析，并决定最佳的方法来重建假设测试和优化推理。我们提出了一个假设测试框架，用于识别疫情指标的增加，并执行力学分析和实验，以显示我们的提案的假设测试和合理的方法。我们的发现显示，使用$p$-值组合为联邦方法学可以实现疫情监控，并提供有价的导致统合可用数据源。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Human-Inspired-Progressive-Alignment-and-Comparative-Learning-for-Grounded-Word-Acquisition"><a href="#Human-Inspired-Progressive-Alignment-and-Comparative-Learning-for-Grounded-Word-Acquisition" class="headerlink" title="Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition"></a>Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02615">http://arxiv.org/abs/2307.02615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sled-group/comparative-learning">https://github.com/sled-group/comparative-learning</a></li>
<li>paper_authors: Yuwei Bao, Barrett Martin Lattimer, Joyce Chai</li>
<li>for: 本研究旨在提出一种基于人类语言学习的计算模型，用于效率地学习语言概念。</li>
<li>methods: 该模型启发自人类婴儿语言学习的机制，通过比较学习来找到语言概念的相似和不同之处，并将这些概念映射到表示符号上。</li>
<li>results: 控制性实验结果表明，该方法可以有效地实现语言概念的持续学习和扩展。<details>
<summary>Abstract</summary>
Human language acquisition is an efficient, supervised, and continual process. In this work, we took inspiration from how human babies acquire their first language, and developed a computational process for word acquisition through comparative learning. Motivated by cognitive findings, we generated a small dataset that enables the computation models to compare the similarities and differences of various attributes, learn to filter out and extract the common information for each shared linguistic label. We frame the acquisition of words as not only the information filtration process, but also as representation-symbol mapping. This procedure does not involve a fixed vocabulary size, nor a discriminative objective, and allows the models to continually learn more concepts efficiently. Our results in controlled experiments have shown the potential of this approach for efficient continual learning of grounded words.
</details>
<details>
<summary>摘要</summary>
人类语言学习是一个效率高、监督的、不断进行的过程。在这项工作中，我们取得了人类宝宝语言Acquisition的灵感，并开发了一种计算机处理方法，通过比较学习来获得单词。我们根据认知发现，生成了一个小型数据集，让计算机模型可以对各种属性进行比较，学习抽象出每个共享语言标签中的共同信息。我们将单词的获得看成不仅为信息筛选过程，还是表示-符号映射。这种方法不含固定词汇大小，也不含推理性目标，使计算机模型能够高效地学习更多概念。我们在控制实验中获得的结果表明了这种方法的潜在效果。
</details></li>
</ul>
<hr>
<h2 id="Evade-ChatGPT-Detectors-via-A-Single-Space"><a href="#Evade-ChatGPT-Detectors-via-A-Single-Space" class="headerlink" title="Evade ChatGPT Detectors via A Single Space"></a>Evade ChatGPT Detectors via A Single Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02599">http://arxiv.org/abs/2307.02599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuyang Cai, Wanyun Cui</li>
<li>for: 检测ChatGPT生成的内容是否真实由人类生成的内容。</li>
<li>methods: 使用统计信息或分类器来建立分布 diferencial gap 的假设，但是实际上这些 gap 并不能有效地区分人类生成和AI生成的内容的Semantic和Styleistic差异。</li>
<li>results: 提出了基于空格的SpaceInfi策略可以逃脱检测，并在多个benchmark和检测器上进行了实验，并提供了这种策略的理论解释。<details>
<summary>Abstract</summary>
ChatGPT brings revolutionary social value but also raises concerns about the misuse of AI-generated content. Consequently, an important question is how to detect whether content is generated by ChatGPT or by human. Existing detectors are built upon the assumption that there are distributional gaps between human-generated and AI-generated content. These gaps are typically identified using statistical information or classifiers. Our research challenges the distributional gap assumption in detectors. We find that detectors do not effectively discriminate the semantic and stylistic gaps between human-generated and AI-generated content. Instead, the "subtle differences", such as an extra space, become crucial for detection. Based on this discovery, we propose the SpaceInfi strategy to evade detection. Experiments demonstrate the effectiveness of this strategy across multiple benchmarks and detectors. We also provide a theoretical explanation for why SpaceInfi is successful in evading perplexity-based detection. Our findings offer new insights and challenges for understanding and constructing more applicable ChatGPT detectors.
</details>
<details>
<summary>摘要</summary>
chatGPT 带来了革命性的社会价值，但也引发了人工智能生成内容的滥用问题。因此，一个重要的问题是如何判断内容是否由 chatGPT 或人类生成。现有的检测器基于分布分布 gap 假设，这些 gap 通常通过统计信息或分类器来定义。我们的研究质疑这种分布 gap 假设在检测器中的有效性。我们发现，检测器无法有效地异化人类生成和 AI 生成内容的语义和风格差异。相反，“微小差异”，如额外的空格，在检测中变得关键。基于这一发现，我们提出了 SpaceInfi 策略，可以在多个检测器上逃脱检测。实验表明 SpaceInfi 策略在多个标准检测器上具有极高的效果。我们还提供了对 SpaceInfi 策略的理论解释，即在检测器中 why  SpaceInfi 能够成功逃脱准确性基于检测。我们的发现对于构建更加实际的 chatGPT 检测器提供了新的思路和挑战。
</details></li>
</ul>
<hr>
<h2 id="ODD-A-Benchmark-Dataset-for-the-NLP-based-Opioid-Related-Aberrant-Behavior-Detection"><a href="#ODD-A-Benchmark-Dataset-for-the-NLP-based-Opioid-Related-Aberrant-Behavior-Detection" class="headerlink" title="ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection"></a>ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02591">http://arxiv.org/abs/2307.02591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soon91jae/orab_mimic">https://github.com/soon91jae/orab_mimic</a></li>
<li>paper_authors: Sunjae Kwon, Xun Wang, Weisong Liu, Emily Druhl, Minhee L. Sung, Joel I. Reisman, Wenjun Li, Robert D. Kerns, William Becker, Hong Yu</li>
<li>for: This paper aims to develop a novel biomedical natural language processing benchmark dataset (ODD) to detect opioid-related aberrant behaviors (ORAB) from electronic health records (EHRs).</li>
<li>methods: The authors use two state-of-the-art natural language processing (NLP) models (finetuning pretrained language models and prompt-tuning approaches) to identify ORAB in EHR notes.</li>
<li>results: The prompt-tuning models outperformed the finetuning models in most categories, especially in uncommon categories such as Suggested Aberrant Behavior, Diagnosed Opioid Dependence, and Medication Change. The best model achieved an area under the precision recall curve of 83.92%, but there is still room for improvement in detecting uncommon classes.Here’s the Chinese version of the information:</li>
<li>for: 这篇论文目的是开发一个新的医学自然语言处理数据集（ODD），用于从电子医疗记录（EHR）中检测抗疼药相关异常行为（ORAB）。</li>
<li>methods: 作者使用了两种当前最佳的自然语言处理（NLP）模型（finetuning 预训练语言模型和提示调教方法）来识别ORAB在EHR记录中。</li>
<li>results: 提示调教模型在大多数类别上表现出了优于finetuning模型，特别是在不常见类别（建议异常行为、诊断抗疼药依赖和药物变化）上。最佳模型在精度 recall 曲线上的面积为83.92%，但是在检测不常见类别时仍有较大的改进空间。<details>
<summary>Abstract</summary>
Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) models (finetuning pretrained language models and prompt-tuning approaches) to identify ORAB. Experimental results show that the prompt-tuning models outperformed the finetuning models in most cateogories and the gains were especially higher among uncommon categories (Suggested aberrant behavior, Diagnosed opioid dependency and Medication change). Although the best model achieved the highest 83.92% on area under precision recall curve, uncommon classes (Suggested Aberrant Behavior, Diagnosed Opioid Dependence, and Medication Change) still have a large room for performance improvement.
</details>
<details>
<summary>摘要</summary>
“对于专业医疗记录（EHR）中的Opioid相关偏常行为（ORAB）进行识别和分类是一个重要的应用。在过去，ORAB通常通过调查结果和药物管理纪录来评估。但这些方法无法扩展和不能覆盖整个偏常行为的范围。相反地，ORAB在EHR中广泛记录，这篇文章提出了一个新的生医自然语言处理标准 benchmark dataset，名为ODD（Opioid Detection Dataset）。ODD包含了超过750份公开可用的EHR资料，并且以9个类别进行分类：1）确认偏常行为，2）建议偏常行为，3）Opioids，4）指示，5）诊断Opioid依赖，6）苯二氮酚，7）药物变化，8）中枢神经系统相关，9）社会健康Determinants。我们使用了两种现代生医自然语言处理（NLP）模型（finetuning pretrained language models和prompt-tuning方法）进行ORAB的识别。实验结果显示，prompt-tuning模型在大多数类别上表现出色，特别是在不常见的类别（建议偏常行为、诊断Opioid依赖和药物变化）中。 although the best model achieved the highest 83.92% on area under precision recall curve, uncommon classes still have a large room for performance improvement.”
</details></li>
</ul>
<hr>
<h2 id="TransformerG2G-Adaptive-time-stepping-for-learning-temporal-graph-embeddings-using-transformers"><a href="#TransformerG2G-Adaptive-time-stepping-for-learning-temporal-graph-embeddings-using-transformers" class="headerlink" title="TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers"></a>TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02588">http://arxiv.org/abs/2307.02588</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alan John Varghese, Aniruddha Bora, Mengjia Xu, George Em Karniadakis</li>
<li>for: 本研究旨在提出一种基于 transformer encoder 的图像模型，用于解决多种时间图分析任务（如链接预测、节点分类、推荐系统、异常检测和图生成）。</li>
<li>methods: 本研究使用了 transformer encoder 来首先学习当前时间步 ($t$) 和上一步的上下文（[$t-1, t-l$]，$l$ 是上下文的长度）中的中间节点表示。然后，使用两个投影层生成时间步 $t$ 的节点秘密嵌入。</li>
<li>results: 对于不同的“新鲜度”水平（根据 TEA 图表来度量），我们的 TransformerG2G 模型在链接预测精度和计算效率方面都超过了传统多步方法和我们之前的工作（DynG2G），特别是在高度的新鲜度下。此外，通过分析注意力权重，我们可以揭示时间依赖关系，找到影响因素，并获得图structure中复杂的互动之间的启示。例如，我们发现在不同的图结构阶段，注意力权重和节点度之间存在强相关关系。<details>
<summary>Abstract</summary>
Dynamic graph embedding has emerged as a very effective technique for addressing diverse temporal graph analytic tasks (i.e., link prediction, node classification, recommender systems, anomaly detection, and graph generation) in various applications. Such temporal graphs exhibit heterogeneous transient dynamics, varying time intervals, and highly evolving node features throughout their evolution. Hence, incorporating long-range dependencies from the historical graph context plays a crucial role in accurately learning their temporal dynamics. In this paper, we develop a graph embedding model with uncertainty quantification, TransformerG2G, by exploiting the advanced transformer encoder to first learn intermediate node representations from its current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is the length of context). Moreover, we employ two projection layers to generate lower-dimensional multivariate Gaussian distributions as each node's latent embedding at timestamp $t$. We consider diverse benchmarks with varying levels of ``novelty" as measured by the TEA plots. Our experiments demonstrate that the proposed TransformerG2G model outperforms conventional multi-step methods and our prior work (DynG2G) in terms of both link prediction accuracy and computational efficiency, especially for high degree of novelty. Furthermore, the learned time-dependent attention weights across multiple graph snapshots reveal the development of an automatic adaptive time stepping enabled by the transformer. Importantly, by examining the attention weights, we can uncover temporal dependencies, identify influential elements, and gain insights into the complex interactions within the graph structure. For example, we identified a strong correlation between attention weights and node degree at the various stages of the graph topology evolution.
</details>
<details>
<summary>摘要</summary>
几何图模型（Graph Embedding）在许多应用中已经证明非常有效，用于解决多种时间图分析任务（如链接预测、节点分类、推荐系统、异常检测和图生成）。这些时间图会展现不同的不定期性、时间间隔和节点特征的高度演变。因此，从历史图上的长距离依赖性来准确学习它们的时间动态是非常重要。在这篇论文中，我们开发了一种具有不确定性评估的图嵌入模型，名为TransformerG2G，通过利用高级变换编码器来首先学习当前时间步($t$) 和上一个时间步（[$t-1, t-l$）中的节点表示，其中$l$ 是 Context的长度。此外，我们使用两个投影层来生成每个节点的时间步 $t$ 的低维多元 Gaussian 分布。我们在不同的 TEA 图表中进行了多种不同的“新鲜度”水平的测试，我们的实验结果表明，我们提出的 TransformerG2G 模型在链接预测精度和计算效率方面都高于 convential 多步法和我们之前的 DynG2G 模型，特别是在高度新鲜度时。此外，我们通过分析注意力权重来探索图结构中的时间相关性、影响因素和复杂的交互关系。例如，我们发现了节点度和注意力权重之间的强相关性，这些相关性在不同的图结构发展阶段都存在。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-in-archival-and-historical-scholarship-workflow-HTS-and-ChatGPT"><a href="#Artificial-Intelligence-in-archival-and-historical-scholarship-workflow-HTS-and-ChatGPT" class="headerlink" title="Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT"></a>Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02044">http://arxiv.org/abs/2308.02044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salvatore Spina</li>
<li>for: This paper examines the impact of Artificial Intelligence (AI) on the archival heritage digitization processes, specifically focusing on the automatic transcription, correction, and normalization of manuscripts.</li>
<li>methods: The study uses two AI systems, Transkribus and ChatGPT, to analyze and transcribe digitized sources.</li>
<li>results: The paper presents the results of a test using ChatGPT to normalize the text of 366 letters stored in the Correspondence section of the Biscari Archive (Catania), which showed that although the AI exhibited some limitations, the corrected texts met expectations. Overall, the study concludes that digitization and AI can significantly enhance archival and historical research by allowing the analysis of vast amounts of data and the application of computational linguistic tools.<details>
<summary>Abstract</summary>
This article examines the impact of Artificial Intelligence on the archival heritage digitization processes, specifically regarding the manuscripts' automatic transcription, their correction, and normalization. It highlights how digitality has compelled scholars to redefine Archive and History field and has facilitated the accessibility of analogue sources through digitization and integration into big data. The study focuses on two AI systems, namely Transkribus and ChatGPT, which enable efficient analysis and transcription of digitized sources. The article presents a test of ChatGPT, which was utilized to normalize the text of 366 letters stored in the Correspondence section of the Biscari Archive (Catania). Although the AI exhibited some limitations that resulted in inaccuracies, the corrected texts met expectations. Overall, the article concludes that digitization and AI can significantly enhance archival and historical research by allowing the analysis of vast amounts of data and the application of computational linguistic tools.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇文章研究了人工智能对文件遗产数字化过程的影响，特别是手写文本自动识别、修正和normalization。它指出了数字化技术的发展使得学术界被迫重新定义档案领域和历史研究领域，并使得 Analog sources 更加可访整合入大数据。文章关注了两个 AI 系统，即 Transkribus 和 ChatGPT，它们可以高效地分析和转写数字化的源料。文章公布了 ChatGPT 对 Catania 的 Biscari 档案（Correspondence 部分）中的 366 封信的测试结果，尽管 AI 系统存在一些局限性和不准确性，但修正后的文本均达到预期。总的来说，文章结论认为，数字化和 AI 可以对档案和历史研究进行 significative 的提高，以便对大量数据进行分析和应用计算语言工具。
</details></li>
</ul>
<hr>
<h2 id="The-Effects-of-Interaction-Conflicts-Levels-of-Automation-and-Frequency-of-Automation-on-Human-Automation-Trust-and-Acceptance"><a href="#The-Effects-of-Interaction-Conflicts-Levels-of-Automation-and-Frequency-of-Automation-on-Human-Automation-Trust-and-Acceptance" class="headerlink" title="The Effects of Interaction Conflicts, Levels of Automation, and Frequency of Automation on Human Automation Trust and Acceptance"></a>The Effects of Interaction Conflicts, Levels of Automation, and Frequency of Automation on Human Automation Trust and Acceptance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05512">http://arxiv.org/abs/2307.05512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Halvachi, Ali Asghar Nazari Shirehjini, Zahra Kakavand, Niloofar Hashemi, Shervin Shirmohammadi</li>
<li>for: 本研究旨在 investigating the effects of Level of Automation (LoA), Frequency of Automated responses (FoA), and Conflict Intensity (CI) on human trust and acceptance of automation in the context of smart homes.</li>
<li>methods: 研究使用了一种因素研究设计，通过在线实验，收集了324名在线参与者的数据，以了解他们对智能家居的信任和接受度。</li>
<li>results: 结果显示，自动化水平和自动化回应频率对用户对智能环境的信任产生影响。此外，结果还表明，在自动化失败和互动冲突的情况下，用户对自动化智能环境的接受度减退。<details>
<summary>Abstract</summary>
In the presence of interaction conflicts, user trust in automation plays an important role in accepting intelligent environments such as smart homes. In this paper, a factorial research design is employed to investigate and compare the single and joint effects of Level of Automation (LoA), Frequency of Automated responses (FoA), and Conflict Intensity (CI) on human trust and acceptance of automation in the context of smart homes. To study these effects, we conducted web-based experiments to gather data from 324 online participants who experienced the system through a 3D simulation of a smart home. The findings show that the level and frequency of automation had an impact on user trust in smart environments. Furthermore, the results demonstrate that the users' acceptance of automated smart environments decreased in the presence of automation failures and interaction conflicts.
</details>
<details>
<summary>摘要</summary>
在智能环境中存在交互冲突时，用户对自动化的信任作用着重要作用于接受智能家庭。在这篇论文中，我们采用因素研究设计来调查和比较单独和共同影响智能家庭中用户信任和自动化的因素。为了研究这些影响，我们通过网络实验吸引了324名在线参与者，他们通过3D智能家庭 simulate的系统进行了体验。结果表明，自动化水平和自动化响应频率对智能家庭中用户信任有影响。此外，结果还示出在自动化失败和交互冲突情况下，用户对自动化智能环境的接受度下降。
</details></li>
</ul>
<hr>
<h2 id="Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models"><a href="#Building-Cooperative-Embodied-Agents-Modularly-with-Large-Language-Models" class="headerlink" title="Building Cooperative Embodied Agents Modularly with Large Language Models"></a>Building Cooperative Embodied Agents Modularly with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02485">http://arxiv.org/abs/2307.02485</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UMass-Foundation-Model/Co-LLM-Agents">https://github.com/UMass-Foundation-Model/Co-LLM-Agents</a></li>
<li>paper_authors: Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, Chuang Gan</li>
<li>for: This paper aims to explore the use of large language models (LLMs) for multi-agent cooperation and communication in embodied environments.</li>
<li>methods: The authors present a novel framework that utilizes LLMs for planning, communication, and cooperation in various embodied environments, without requiring fine-tuning or few-shot prompting.</li>
<li>results: The authors demonstrate that LLM-based agents can surpass strong planning-based methods and exhibit emergent effective communication, and that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains. However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents. In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments. Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting. We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for embodied AI and lays the foundation for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在单机器人任务中表现出了惊人的规划能力，但它们在多机器人合作中的规划和通信能力仍然不清楚，尽管这些技能对智能机器人来说非常重要。在这篇论文中，我们提出了一种新的框架，用于利用LLM来实现多机器人合作，并在不同的embodied环境中进行测试。我们的框架允许机器人规划、通信和与其他机器人或人类合作，以实现长期任务的效率。我们发现，最新的LLM，如GPT-4，可以在我们的框架下超越强规划方法，并在没有微调或几个推荐的情况下显示出emergent的有效通信。此外，我们发现LLM基于的自然语言通信的机器人可以在人类面前赢得更多的信任和更有效地合作。我们的研究证明了LLM的潜力，并为多机器人合作的未来研究提供了基础。详细信息和视频可以在项目网站https://vis-www.cs.umass.edu/Co-LLM-Agents/中找到。
</details></li>
</ul>
<hr>
<h2 id="Elastic-Decision-Transformer"><a href="#Elastic-Decision-Transformer" class="headerlink" title="Elastic Decision Transformer"></a>Elastic Decision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02484">http://arxiv.org/abs/2307.02484</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Yueh-Hua Wu, Xiaolong Wang, Masashi Hamaya</li>
<li>for: 提高 Decision Transformer (DT) 和其变种的性能，尤其是在生成优化轨迹的过程中。</li>
<li>methods: 提出 Elastic Decision Transformer (EDT)，通过在测试时进行动作推理中实现 trajectory stitching，并在保持历史记录时进行优化。</li>
<li>results: 在 D4RL 步态标准和 Atari 游戏中，EDT 比 Q Learning-based 方法表现更好，特别是在多任务情况下。<details>
<summary>Abstract</summary>
This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to "stitch" with a more optimal trajectory. Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games. Videos are available at: https://kristery.github.io/edt/
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了弹性决策变换器（EDT），它对现有的决策变换器（DT）和其变体具有显著的进步。虽然DT宣称生成最优轨迹，但实际证据表明它在轨迹缝针接处遇到困难，即生成最优或近似最优轨迹从一组sub-optimal轨迹中的最佳部分。提出的EDT通过在测试时进行行动推理中实现轨迹缝针接，并通过调整DT中保持的历史长度来实现。此外，EDT可以根据前一个轨迹是否优化，保持更长的历史记录，从而使其能够“缝”到更优轨迹。广泛的实验表明EDT能够在DT基于和Q学习基于方法之间bridging性能差距。特别是在多任务 режи围的D4RL locomotivebenchmark和Atari游戏中，EDT超越Q学习基于方法。视频可以在：https://kristery.github.io/edt/中找到。
</details></li>
</ul>
<hr>
<h2 id="Reasoning-or-Reciting-Exploring-the-Capabilities-and-Limitations-of-Language-Models-Through-Counterfactual-Tasks"><a href="#Reasoning-or-Reciting-Exploring-the-Capabilities-and-Limitations-of-Language-Models-Through-Counterfactual-Tasks" class="headerlink" title="Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"></a>Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02477">http://arxiv.org/abs/2307.02477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaofengwu/counterfactual-evaluation">https://github.com/zhaofengwu/counterfactual-evaluation</a></li>
<li>paper_authors: Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Akyürek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, Yoon Kim</li>
<li>for: 这个论文旨在评估当代自然语言处理模型是否具备抽象逻辑能力，以及这种能力是否普适或特定任务的偏爱。</li>
<li>methods: 作者提出了一种基于“Counterfactual”任务变体的评估框架，以评估当代语言模型是否具备抽象逻辑能力，并对11种任务进行了测试。</li>
<li>results: 研究发现，当代语言模型在Counterfactual任务变体中表现出了一定的抽象逻辑能力，但是与标准任务的表现相比，其表现却有很大的差异，这表明当代语言模型的表现可能受到了特定任务的偏爱。<details>
<summary>Abstract</summary>
The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on "counterfactual" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to a degree, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior.
</details>
<details>
<summary>摘要</summary>
“现代语言模型在广泛的任务上表现出了印象人的能力，这表明它们拥有一定的抽象逻辑能力。但是，这些能力是通用逻辑能力，还是对特定任务的适应？为了解答这个问题，我们提出了一个基于“假设”的评估框架。在11个任务中，我们发现了不同于默认情况下的任务Variant中的表现，但是它们的表现都具有较低的水准，与默认情况下的表现有很大的差异。这些结果表明，现代语言模型可能拥有一定的抽象任务解决能力，但是它们通常还是对特定任务进行适应，而不是拥有通用的逻辑能力。这些结果鼓励我们更加留意语言模型的表现，并将其分解为不同的方面。”
</details></li>
</ul>
<hr>
<h2 id="Deductive-Additivity-for-Planning-of-Natural-Language-Proofs"><a href="#Deductive-Additivity-for-Planning-of-Natural-Language-Proofs" class="headerlink" title="Deductive Additivity for Planning of Natural Language Proofs"></a>Deductive Additivity for Planning of Natural Language Proofs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02472">http://arxiv.org/abs/2307.02472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zayne-sprague/deductive_additivity_for_planning_of_natural_language_proofs">https://github.com/zayne-sprague/deductive_additivity_for_planning_of_natural_language_proofs</a></li>
<li>paper_authors: Zayne Sprague, Kaj Bostrom, Swarat Chaudhuri, Greg Durrett</li>
<li>for:  investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning</li>
<li>methods:  explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25</li>
<li>results:  find that while standard embedding methods frequently embed conclusions near the sums of their premises, they fall short of being effective heuristics and lack the ability to model certain categories of reasoning<details>
<summary>Abstract</summary>
Current natural language systems designed for multi-step claim validation typically operate in two phases: retrieve a set of relevant premise statements using heuristics (planning), then generate novel conclusions from those statements using a large language model (deduction). The planning step often requires expensive Transformer operations and does not scale to arbitrary numbers of premise statements. In this paper, we investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning. Specifically, we evaluate whether embedding spaces exhibit a property we call deductive additivity: the sum of premise statement embeddings should be close to embeddings of conclusions based on those premises. We explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We study embedding models both intrinsically, evaluating whether the property of deductive additivity holds, and extrinsically, using them to assist planning in natural language proof generation. Lastly, we create a dataset, Single-Step Reasoning Contrast (SSRC), to further probe performance on various reasoning types. Our findings suggest that while standard embedding methods frequently embed conclusions near the sums of their premises, they fall short of being effective heuristics and lack the ability to model certain categories of reasoning.
</details>
<details>
<summary>摘要</summary>
现有的自然语言系统设计为多步验证声明通常采用两个阶段：首先使用规则（规划） retrieve 一组相关的假设语句，然后使用大型自然语言模型（推理）生成新的结论。规划阶段经常需要昂贵的Transformer操作，并不可扩展到 произвольные数量的假设语句。在这篇论文中，我们investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning. Specifically, we evaluate whether embedding spaces exhibit a property we call deductive additivity: the sum of premise statement embeddings should be close to embeddings of conclusions based on those premises. We explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We study embedding models both intrinsically, evaluating whether the property of deductive additivity holds, and extrinsically, using them to assist planning in natural language proof generation. Lastly, we create a dataset, Single-Step Reasoning Contrast (SSRC), to further probe performance on various reasoning types. Our findings suggest that while standard embedding methods frequently embed conclusions near the sums of their premises, they fall short of being effective heuristics and lack the ability to model certain categories of reasoning.
</details></li>
</ul>
<hr>
<h2 id="Performance-Scaling-via-Optimal-Transport-Enabling-Data-Selection-from-Partially-Revealed-Sources"><a href="#Performance-Scaling-via-Optimal-Transport-Enabling-Data-Selection-from-Partially-Revealed-Sources" class="headerlink" title="Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources"></a>Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02460">http://arxiv.org/abs/2307.02460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feiyang Kang, Hoang Anh Just, Anit Kumar Sahu, Ruoxi Jia</li>
<li>for: 这篇论文是关于如何在实际数据交换场景中进行数据选择，特别是当数据提供者只显示一小部分的数据时。</li>
<li>methods: 这篇论文提出了一个名为<projektor>的框架，可以根据部分数据来预测模型的性能和支持数据选择 Decision。它的方法包括使用最佳运输距离来预测模型在任何数据混合比例下的性能，然后使用一种新的参数自由的映射技术来从小数据 extrapolate 模型的性能到更大的未知数据大小。</li>
<li>results: 评估结果显示，<projektor> 在性能预测和计算成本方面都有所改善，并且在数据选择效果方面也有所超越其他一些对照方案。<details>
<summary>Abstract</summary>
Traditionally, data selection has been studied in settings where all samples from prospective sources are fully revealed to a machine learning developer. However, in practical data exchange scenarios, data providers often reveal only a limited subset of samples before an acquisition decision is made. Recently, there have been efforts to fit scaling laws that predict model performance at any size and data source composition using the limited available samples. However, these scaling functions are black-box, computationally expensive to fit, highly susceptible to overfitting, or/and difficult to optimize for data selection. This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources. Our approach distinguishes itself from existing work by introducing a novel *two-stage* performance inference process. In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes. In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws. We further derive an efficient gradient-based method to select data sources based on the projected model performance. Evaluation over a diverse range of applications demonstrates that <projektor> significantly improves existing performance scaling approaches in terms of both the accuracy of performance inference and the computation costs associated with constructing the performance predictor. Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions.
</details>
<details>
<summary>摘要</summary>
传统上，数据选择都是在所有样本都是完全披露给机器学习开发者的情况下研究的。然而，在实际数据交换场景下，数据提供者通常只 revelas 一个有限的子集的样本 перед一个收购决策。最近，有努力适应缩放函数来预测模型性能，但这些缩放函数是黑盒子、计算成本高、易于过拟合或难以优化数据选择。本文提出了一个名为<projektor>的框架，可以根据部分样本预测模型性能并支持数据选择决策。我们的方法与现有工作不同，我们引入了一种新的两Stage性能预测过程。在第一stage，我们利用最佳运输距离来预测模型在任何数据混合比例范围内的性能。在第二stage，我们通过一种新的无参数映射技术，基于神经缩放法则来推断模型性能。我们进一步 derive了一种高效的梯度下降方法来选择数据源基于预测模型性能。经过对多种应用场景的评估，我们发现<projektor>significantly improve现有性能扩展方法的准确性和计算成本。此外，<projektor>也在数据选择效果上大幅超越了一些Off-the-shelf解决方案。
</details></li>
</ul>
<hr>
<h2 id="DeSRA-Detect-and-Delete-the-Artifacts-of-GAN-based-Real-World-Super-Resolution-Models"><a href="#DeSRA-Detect-and-Delete-the-Artifacts-of-GAN-based-Real-World-Super-Resolution-Models" class="headerlink" title="DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models"></a>DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02457">http://arxiv.org/abs/2307.02457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tencentarc/desra">https://github.com/tencentarc/desra</a></li>
<li>paper_authors: Liangbin Xie, Xintao Wang, Xiangyu Chen, Gen Li, Ying Shan, Jiantao Zhou, Chao Dong</li>
<li>for: 提高实际场景中SR模型的应用能力，即使面临不seen数据和无权准的情况</li>
<li>methods: 基于GAN的SR模型，通过检测和修正缺陷来提高SR模型的效果</li>
<li>results: 通过DeSRA方法，可以成功消除GAN-SR模型中的缺陷和不愉悦的artefacts，提高SR模型在实际场景中的应用能力<details>
<summary>Abstract</summary>
Image super-resolution (SR) with generative adversarial networks (GAN) has achieved great success in restoring realistic details. However, it is notorious that GAN-based SR models will inevitably produce unpleasant and undesirable artifacts, especially in practical scenarios. Previous works typically suppress artifacts with an extra loss penalty in the training phase. They only work for in-distribution artifact types generated during training. When applied in real-world scenarios, we observe that those improved methods still generate obviously annoying artifacts during inference. In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths. We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice. Specifically, we propose to measure a relative local variance distance from MSE-SR results and GAN-SR results, and locate the problematic areas based on the above distance and semantic-aware thresholds. After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data. Equipped with our DeSRA, we can successfully eliminate artifacts from inference and improve the ability of SR models to be applied in real-world scenarios. The code will be available at https://github.com/TencentARC/DeSRA.
</details>
<details>
<summary>摘要</summary>
Image超解像（SR）使用生成敌对网络（GAN）已经取得了非常成功的RestoreRealistic Details。然而，GAN基于SR模型会不可避免地产生不愉快和不жела的artefacts，特别在实际应用中。先前的工作通常通过额外的损失 penalty在训练阶段来降低这些artefacts。然而，在实际应用中，我们发现这些改进的方法仍然在推理阶段产生明显的噪声。在这篇论文中，我们分析了GAN artefacts在未看到的测试数据中的原因和特征。然后，我们开发了一种名为DeSRA的方法，用于检测并删除SR artefacts。具体来说，我们提议使用MSE-SR结果和GAN-SR结果之间的相对本地差距来评估artefact区域。然后，我们根据这个距离和semantic-aware的阈值来定位问题区域。在检测artefact区域之后，我们开发了一种finetune过程，以提高GAN基于SR模型对类似 artefacts的处理能力。通过我们的DeSRA，我们可以成功地从推理中除除artefacts，并提高SR模型在实际应用中的可用性。代码将在https://github.com/TencentARC/DeSRA上提供。
</details></li>
</ul>
<hr>
<h2 id="An-Exploratory-Literature-Study-on-Sharing-and-Energy-Use-of-Language-Models-for-Source-Code"><a href="#An-Exploratory-Literature-Study-on-Sharing-and-Energy-Use-of-Language-Models-for-Source-Code" class="headerlink" title="An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code"></a>An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02443">http://arxiv.org/abs/2307.02443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Hort, Anastasiia Grishina, Leon Moonen</li>
<li>for: 本研究的主要目标是检查发表的语言模型在软件工程任务上是否分享源代码和训练 artifacts，以及分析训练能源消耗的透明度。</li>
<li>methods: 我们采用雪崩式Literature搜索来找到使用语言模型解决源代码问题的发表文献，并分析它们的可重用性从可持续性角度。</li>
<li>results: 我们从494独特的发表文献中筛选出293篇相关的文献，其中27%（79个）的文献提供了可重用的工具或IDE插件，以及可以精度调整的特定任务下的模型。此外，我们收集了模型训练硬件和训练时间的信息，以便分析训练过程中的能源消耗。我们发现当前的研究中有40%的论文不分享源代码或训练 artifacts，我们建议分享源代码和训练 artifacts，以实现可持续可重用的复制性。此外，我们建议对模型训练过程中的硬件配置和训练时间进行全面的分享，以便对模型的碳脚印象进行透明度。<details>
<summary>Abstract</summary>
Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair. Large amounts of data for training such models benefit the models' performance. However, the size of the data and models results in long training times and high energy consumption. While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared. The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts. The second goal is to analyze the transparency on training energy usage. We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint.   From 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks. Among them, 27% (79 out of 293) make artifacts available for reuse. This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks. Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process. We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts. We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility. Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint.
</details>
<details>
<summary>摘要</summary>
大型语言模型可以支持软件开发任务，如代码推荐和程序修复。大量数据 для训练这些模型会提高模型性能。然而，模型和数据的大小会导致训练时间长和能源消耗高。发布源代码可以提高复制性，但用户需要重新进行费时的训练过程，如果模型不被共享。我们的研究目标是调查发布在软件工程（SE）任务上使用语言模型的研究是否分享源代码和训练 artifacts。我们的第二个目标是分析训练过程中的能源消耗透明度。我们通过降准搜索来找到使用语言模型Addressing code-related tasks的发表文献，并分析它们的可重用性从可持续性的角度。从494独特的发表文献中，我们identified 293个相关的发表文献，其中27% (79个/293个)提供了可重用的artifacts。这些可重用的artifacts可以是专门为特定任务设计的工具或IDE插件，也可以是可以微调的下游任务的模型。此外，我们收集了训练过程中硬件使用情况以及训练时间，这些信息共同决定了软件开发过程中的能源消耗。我们发现当前关于源代码模型的软件工程任务的研究中存在资源共享的不足，40%的调查文献不会分享源代码或训练过程中的artifacts。我们建议分享源代码以及训练过程中的artifacts，以实现可持续可重用。此外，我们还建议对训练过程中硬件配置和训练时间的信息进行完整的分享，以确保模型的碳脚印。
</details></li>
</ul>
<hr>
<h2 id="External-Reasoning-Towards-Multi-Large-Language-Models-Interchangeable-Assistance-with-Human-Feedback"><a href="#External-Reasoning-Towards-Multi-Large-Language-Models-Interchangeable-Assistance-with-Human-Feedback" class="headerlink" title="External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback"></a>External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12057">http://arxiv.org/abs/2307.12057</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AkideLiu/ANLP">https://github.com/AkideLiu/ANLP</a></li>
<li>paper_authors: Akide Liu</li>
<li>for: 提高人工智能的能力，使其能够解决复杂的实际问题</li>
<li>methods: 通过选择性地吸收外部知识库中的知识，并采用多个LLM之间的交换协助来增强LLM的能力</li>
<li>results: 经过全面评估，该方法可以达到现有解决方案的同等或更高的性能，并且比直接LLM处理全文更加高效<details>
<summary>Abstract</summary>
Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to this approach is the establishment of a tiered policy for \textbf{External Reasoning based on Multiple LLM Interchange Assistance}, where the level of support rendered is modulated across entry, intermediate, and advanced tiers based on the complexity of the query, with adjustments made in response to human feedback. A comprehensive evaluation of this methodology is conducted using multiple LLMs and the results indicate state-of-the-art performance, surpassing existing solutions including ChatPDF.com. Moreover, the paper emphasizes that this approach is more efficient compared to the direct processing of full text by LLMs.
</details>
<details>
<summary>摘要</summary>
память является ключевым человеческимfaculty, allowing for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise throughout a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4, which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to this approach is the establishment of a tiered policy for External Reasoning based on Multiple LLM Interchange Assistance, where the level of support rendered is modulated across entry, intermediate, and advanced tiers based on the complexity of the query, with adjustments made in response to human feedback. A comprehensive evaluation of this methodology is conducted using multiple LLMs and the results indicate state-of-the-art performance, surpassing existing solutions including ChatPDF.com. Moreover, the paper emphasizes that this approach is more efficient compared to the direct processing of full text by LLMs.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FOCUS-Object-Centric-World-Models-for-Robotics-Manipulation"><a href="#FOCUS-Object-Centric-World-Models-for-Robotics-Manipulation" class="headerlink" title="FOCUS: Object-Centric World Models for Robotics Manipulation"></a>FOCUS: Object-Centric World Models for Robotics Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02427">http://arxiv.org/abs/2307.02427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Ferraro, Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt</li>
<li>for: 本研究旨在提出一种基于模型的智能体，用于学习一种对象中心的世界模型，以便更好地理解和处理机器人 manipulate 任务。</li>
<li>methods: 本研究使用了一种新的探索奖励机制，基于对象中心的表示，使得智能体更容易探索机器人-对象之间的互动。</li>
<li>results: 研究表明，基于对象中心的世界模型可以帮助智能体更 efficiently 解决 manipulate 任务，并且能够在不同的设定下一致地探索机器人-对象之间的互动。 具体来说，通过使用 Franka Emika 机器人臂，我们展示了 FOCUS 在实际场景中的采用。<details>
<summary>Abstract</summary>
Understanding the world in terms of objects and the possible interplays with them is an important cognition ability, especially in robotics manipulation, where many tasks require robot-object interactions. However, learning such a structured world model, which specifically captures entities and relationships, remains a challenging and underexplored problem. To address this, we propose FOCUS, a model-based agent that learns an object-centric world model. Thanks to a novel exploration bonus that stems from the object-centric representation, FOCUS can be deployed on robotics manipulation tasks to explore object interactions more easily. Evaluating our approach on manipulation tasks across different settings, we show that object-centric world models allow the agent to solve tasks more efficiently and enable consistent exploration of robot-object interactions. Using a Franka Emika robot arm, we also showcase how FOCUS could be adopted in real-world settings.
</details>
<details>
<summary>摘要</summary>
世界理解为对象和对象之间的交互是至关重要的认知能力，尤其在机器人操作中，许多任务需要机器人和物品之间的交互。然而，学习这种结构化世界模型仍然是一个挑战和未经探索的问题。为解决这个问题，我们提出了 FOCUS 模型基于代理人，该模型可以学习对象中心的世界模型。由于对象中心表示带来的新探索奖励，FOCUS 可以更好地探索机器人和物品之间的交互。在不同的设定下进行 manipulate 任务评估，我们表明对象中心世界模型可以让代理人更加高效地解决任务，并且可以一致地探索机器人和物品之间的交互。使用 Franka Emika 机器人臂，我们也展示了 FOCUS 在实际设定下的采用。
</details></li>
</ul>
<hr>
<h2 id="Multi-objective-Deep-Reinforcement-Learning-for-Mobile-Edge-Computing"><a href="#Multi-objective-Deep-Reinforcement-Learning-for-Mobile-Edge-Computing" class="headerlink" title="Multi-objective Deep Reinforcement Learning for Mobile Edge Computing"></a>Multi-objective Deep Reinforcement Learning for Mobile Edge Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14346">http://arxiv.org/abs/2307.14346</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gracefulning/mec_morl_multipolicy">https://github.com/gracefulning/mec_morl_multipolicy</a></li>
<li>paper_authors: Ning Yang, Junrui Wen, Meng Zhang, Ming Tang</li>
<li>For: The paper is written for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption.* Methods: The paper uses a multi-objective reinforcement learning (MORL) scheme with proximal policy optimization (PPO) to address the challenge of unknown preferences in mobile edge computing (MEC) systems.* Results: The proposed MORL scheme enhances the hypervolume of the Pareto front by up to 233.1% compared to benchmarks.Here’s the Chinese version of the three information points:* For: 这篇论文是为下一代无线网络应用程序而写的，这些应用程序优先级包括延迟和能耗。* Methods: 这篇论文使用多目标学习（MORL）与距离策略优化（PPO）来解决MEC系统中不确定的偏好问题。* Results: 提议的MORL方案可以提高Pareto前的超Volume比例达到233.1%。<details>
<summary>Abstract</summary>
Mobile edge computing (MEC) is essential for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption. However, conventional single-objective scheduling solutions cannot be directly applied to practical systems in which the preferences of these applications (i.e., the weights of different objectives) are often unknown or challenging to specify in advance. In this study, we address this issue by formulating a multi-objective offloading problem for MEC with multiple edges to minimize expected long-term energy consumption and transmission delay while considering unknown preferences as parameters. To address the challenge of unknown preferences, we design a multi-objective (deep) reinforcement learning (MORL)-based resource scheduling scheme with proximal policy optimization (PPO). In addition, we introduce a well-designed state encoding method for constructing features for multiple edges in MEC systems, a sophisticated reward function for accurately computing the utilities of delay and energy consumption. Simulation results demonstrate that our proposed MORL scheme enhances the hypervolume of the Pareto front by up to 233.1% compared to benchmarks. Our full framework is available at https://github.com/gracefulning/mec_morl_multipolicy.
</details>
<details>
<summary>摘要</summary>
Mobile edge computing (MEC) 是下一代移动网络应用程序的关键技术，它们优先级包括延迟和能耗等多个性能指标。然而，传统的单目标调度解决方案不能直接应用于实际系统中，因为这些应用程序的偏好（即不同目标的权重） Frequently unknown or difficult to specify in advance.在本研究中，我们解决了这个问题，通过对 MEC 系统中的多个边进行协调调度，以最小化预期长期能耗和传输延迟，同时考虑不确定的偏好。为了解决不确定的偏好问题，我们设计了一种基于多目标学习（deep reinforcement learning，DRL）的资源调度方案，并使用 proximal policy optimization（PPO）来优化。此外，我们还提出了一种智能的状态编码方法，用于构建 MEC 系统中多个边的特征。此外，我们还提出了一种准确计算延迟和能耗的利益函数。实验结果表明，我们的提posed MORL 方案可以提高 Pareto 前面的抽象体积，与参考值比较，最高提高233.1%。整个框架可以在 GitHub 上找到：https://github.com/gracefulning/mec_morl_multipolicy。
</details></li>
</ul>
<hr>
<h2 id="OpenDelta-A-Plug-and-play-Library-for-Parameter-efficient-Adaptation-of-Pre-trained-Models"><a href="#OpenDelta-A-Plug-and-play-Library-for-Parameter-efficient-Adaptation-of-Pre-trained-Models" class="headerlink" title="OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models"></a>OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03084">http://arxiv.org/abs/2307.03084</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thunlp/opendelta">https://github.com/thunlp/opendelta</a></li>
<li>paper_authors: Shengding Hu, Ning Ding, Weilin Zhao, Xingtai Lv, Zhen Zhang, Zhiyuan Liu, Maosong Sun</li>
<li>for: 大规模预训练模型（PTM）的适应下游任务受到较大的优化负担和存储成本的限制，以适应这种限制，许多研究强调参数精炼训练方法，也称为“delta tuning”，这种方法只更新一小部分参数，称为“delta模块”，而保持背景模型的参数不变。</li>
<li>methods: OpenDelta 是一个开源库，它解决了现有 delta tuning 实现的限制，不需要修改背景 PTM 的代码，可以与不同的 PTM 兼容，并且提供了一系列可扩展的技术，使研究人员和实践者能够方便地适应大型 PTM。</li>
<li>results: OpenDelta 提供了一个简单、干净、可扩展的平台，可以帮助研究人员和实践者快速适应大型 PTM，并且可以提供更多的 delta tuning 方法，以满足不同的应用需求。<details>
<summary>Abstract</summary>
The scale of large pre-trained models (PTMs) poses significant challenges in adapting to downstream tasks due to the high optimization overhead and storage costs associated with full-parameter fine-tuning. To address this, many studies explore parameter-efficient tuning methods, also framed as "delta tuning", which updates only a small subset of parameters, known as "delta modules", while keeping the backbone model's parameters fixed. However, the practicality and flexibility of delta tuning have been limited due to existing implementations that directly modify the code of the backbone PTMs and hard-code specific delta tuning methods for each PTM. In this paper, we present OpenDelta, an open-source library that overcomes these limitations by providing a plug-and-play implementation of various delta tuning methods. Our novel techniques eliminate the need to modify the backbone PTMs' code, making OpenDelta compatible with different, even novel PTMs. OpenDelta is designed to be simple, modular, and extensible, providing a comprehensive platform for researchers and practitioners to adapt large PTMs efficiently.
</details>
<details>
<summary>摘要</summary>
大型预训练模型（PTM）的scale会带来适应下游任务的很大挑战，因为全参数精度调整的优化开销和存储成本很高。为了解决这个问题，许多研究尝试了参数有效调整方法，也称为“delta调整”，该方法只更新一小部分参数，称为“delta模块”，而保持背景模型的参数不变。然而，现有的实现方式直接修改背景PTM的代码，固定了每个PTM的 delta调整方法，这限制了 delta调整的实际性和灵活性。在这篇论文中，我们介绍了 OpenDelta，一个开源库，它解决了这些限制。OpenDelta 提供了多种 delta调整方法的插件式实现，不需要修改背景PTM的代码，因此可以与不同的PTM兼容。我们的新技术使得 OpenDelta 可以与不同的 PTM 兼容，并且可以支持未来的新PTM。OpenDelta 设计为简单、卷积、扩展的，提供了一个完整的平台，让研究人员和实践者能够有效地适应大PTM。
</details></li>
</ul>
<hr>
<h2 id="Causal-Discovery-with-Language-Models-as-Imperfect-Experts"><a href="#Causal-Discovery-with-Language-Models-as-Imperfect-Experts" class="headerlink" title="Causal Discovery with Language Models as Imperfect Experts"></a>Causal Discovery with Language Models as Imperfect Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02390">http://arxiv.org/abs/2307.02390</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stephlong614/causal-disco">https://github.com/stephlong614/causal-disco</a></li>
<li>paper_authors: Stephanie Long, Alexandre Piché, Valentina Zantedeschi, Tibor Schuster, Alexandre Drouin</li>
<li>for: 本研究旨在提高基于数据驱动的 causal 图识别精度，超出 markov 等类。</li>
<li>methods: 我们使用专家知识来改进数据驱动的 causal 图识别，并考虑了专家可能提供错误信息的情况。我们提出了基于一致性属性的纠正策略，如循环无法和 condition independence 等等。</li>
<li>results: 我们在实际数据上进行了一个案例研究，使用大型自然语言模型作为不准确的专家。<details>
<summary>Abstract</summary>
Understanding the causal relationships that underlie a system is a fundamental prerequisite to accurate decision-making. In this work, we explore how expert knowledge can be used to improve the data-driven identification of causal graphs, beyond Markov equivalence classes. In doing so, we consider a setting where we can query an expert about the orientation of causal relationships between variables, but where the expert may provide erroneous information. We propose strategies for amending such expert knowledge based on consistency properties, e.g., acyclicity and conditional independencies in the equivalence class. We then report a case study, on real data, where a large language model is used as an imperfect expert.
</details>
<details>
<summary>摘要</summary>
理解系统下 causal 关系的本质是决策准确的基本必要条件。在这项工作中，我们研究如何使用专家知识来提高基于数据的 causal 图的识别，超过 markov 等类。在这个过程中，我们考虑了一种情况，在该情况下，我们可以询问专家关于变量之间 causal 关系的方向，但专家可能提供错误的信息。我们提出了基于一致性属性的纠正策略，例如无环性和 conditional independence 等等。然后，我们报告了一个实际数据的案例研究，其中使用大语言模型作为不完全的专家。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/06/cs.AI_2023_07_06/" data-id="clogyj8um000h7crad47i31j7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/06/cs.CL_2023_07_06/" class="article-date">
  <time datetime="2023-07-06T11:00:00.000Z" itemprop="datePublished">2023-07-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/06/cs.CL_2023_07_06/">cs.CL - 2023-07-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Parameter-Efficient-Fine-Tuning-of-LLaMA-for-the-Clinical-Domain"><a href="#Parameter-Efficient-Fine-Tuning-of-LLaMA-for-the-Clinical-Domain" class="headerlink" title="Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain"></a>Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03042">http://arxiv.org/abs/2307.03042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aryo Pradipta Gema, Luke Daines, Pasquale Minervini, Beatrice Alex</li>
<li>For: This paper focuses on adapting pre-trained language models for clinical applications, specifically using Parameter-Efficient Fine-Tuning (PEFT) techniques to reduce computational requirements.* Methods: The proposed method, Clinical LLaMA-LoRA, is built upon the open-sourced LLaMA model and is trained using clinical notes from the MIMIC-IV database. A two-step PEFT framework is proposed, which combines Clinical LLaMA-LoRA with Downstream LLaMA-LoRA for downstream tasks.* Results: The proposed framework achieves state-of-the-art AUROC scores averaged across all clinical downstream tasks, with substantial improvements of 6-9% AUROC score in large-scale multilabel classification tasks such as diagnoses and procedures classification.Here is the information in Simplified Chinese text:* For: 本研究探讨了将预训练语言模型应用于医疗领域，特别是通过Parameter-Efficient Fine-Tuning（PEFT）技术来降低计算需求。* Methods: 提议的方法是基于开源的LLaMA模型建立的CLINICAL LLaMA-LoRA，通过在MIMIC-IV数据库中获取医疗笔记进行训练。提议的方法还包括将CLINICAL LLaMA-LoRA与下游LLaMA-LoRA结合使用，形成两步PEFT框架。* Results: 提议的方法实现了医疗下游任务中的最佳AUROC分数，特别是在大规模多标签分类任务中具有6-9% AUROC分数的提升。<details>
<summary>Abstract</summary>
Adapting pretrained language models to novel domains, such as clinical applications, traditionally involves retraining their entire set of parameters. However, this approach is increasingly proven to be impractical owing to the substantial computational requirements associated with training such large language models. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) techniques offer a viable solution by selectively fine-tuning a small subset of additional parameters, significantly reducing the computational requirements for domain adaptation. In this study, we propose Clinical LLaMA-LoRA, a PEFT adapter layer built upon the open-sourced LLaMA model. Clinical LLaMA-LoRA is trained using clinical notes obtained from the MIMIC-IV database, thereby creating a specialised adapter designed for the clinical domain. Additionally, we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA with Downstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks. We evaluate this framework on multiple clinical outcome prediction datasets, comparing it to clinically trained language models. Our proposed framework achieves a state-of-the-art AUROC score averaged across all clinical downstream tasks. We observe substantial improvements of 6-9% AUROC score in the large-scale multilabel classification tasks, such as diagnoses and procedures classification.
</details>
<details>
<summary>摘要</summary>
原文文本中的 Adapting pretrained language models to novel domains, such as clinical applications, 通常需要重新训练整个语言模型的参数集。然而，这种方法在计算机需求方面存在很大的障碍，特别是在训练这些大型语言模型时。为解决这个问题，Parameter-Efficient Fine-Tuning（PEFT）技术提供了一个可行的解决方案，通过选择ively fine-tune 一小部分的额外参数，可以很大地减少预处理需求。在这种研究中，我们提出了Clinical LLaMA-LoRA，一个基于开源的 LLaMA 模型的 PEFT 适应层。Clinical LLaMA-LoRA 通过使用来自 MIMIC-IV 数据库的临床笔记进行训练，创造了特殊的临床适应器。此外，我们还提出了一种两步 PEFT 框架，将 Clinical LLaMA-LoRA 与 Downstream LLaMA-LoRA，另一个特殊的 PEFT 适应器，融合在一起。我们对多个临床结果预测数据集进行评估，与临床训练语言模型进行比较。我们的提议的框架实现了临床下游任务的最佳 AUROC 分数平均值。我们发现在大规模多标签分类任务中，如诊断和治疗分类任务，AUROC 分数提高了6-9%。
</details></li>
</ul>
<hr>
<h2 id="Improving-Retrieval-Augmented-Large-Language-Models-via-Data-Importance-Learning"><a href="#Improving-Retrieval-Augmented-Large-Language-Models-via-Data-Importance-Learning" class="headerlink" title="Improving Retrieval-Augmented Large Language Models via Data Importance Learning"></a>Improving Retrieval-Augmented Large Language Models via Data Importance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03027">http://arxiv.org/abs/2307.03027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amsterdata/ragbooster">https://github.com/amsterdata/ragbooster</a></li>
<li>paper_authors: Xiaozhong Lyu, Stefan Grafberger, Samantha Biegel, Shaopeng Wei, Meng Cao, Sebastian Schelter, Ce Zhang</li>
<li>for: 该文章目的是提高大型语言模型的性能，使其能够利用外部知识，例如在问答和数据填充等任务上。</li>
<li>methods: 该文章提出了一种基于多线性扩展的算法，用于评估检索 Corpora 中数据点的重要性。该算法可以在 polynomial time 内计算，并且可以给出正确的结果，只需要一个检索-加持的模型和一个验证集。</li>
<li>results: 实验结果表明，通过只是修改或重新权重检索 Corpora，可以提高大型语言模型的性能，而不需要进行进一步的训练。在某些任务上，使用检索加持和搜索引擎 API，可以使一个小型模型（如 GPT-JT）超越不含检索增强的 GPT-3.5。此外，我们还证明了在实践中，可以计算多线性扩展的权重非常快（例如，在100万个元素的 Corpora 上只需要几分钟）。<details>
<summary>Abstract</summary>
Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\epsilon}, {\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements).
</details>
<details>
<summary>摘要</summary>
There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial-time algorithm that computes the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function, given a retrieval-augmented model with an additive utility function and a validation set. We also propose an even more efficient (${\epsilon}$, $\delta$)-approximation algorithm.Our experimental results show that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT) augmented with a search engine API to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements).
</details></li>
</ul>
<hr>
<h2 id="Style-Over-Substance-Evaluation-Biases-for-Large-Language-Models"><a href="#Style-Over-Substance-Evaluation-Biases-for-Large-Language-Models" class="headerlink" title="Style Over Substance: Evaluation Biases for Large Language Models"></a>Style Over Substance: Evaluation Biases for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03025">http://arxiv.org/abs/2307.03025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghao Wu, Alham Fikri Aji</li>
<li>For: This paper aims to evaluate the performance of large language models (LLMs) in natural language generation tasks, and to propose a new approach to improve the accuracy of LLM-based evaluations.* Methods: The paper uses a dataset of intentionally flawed machine-generated answers to compare the evaluation behavior of crowd-sourced and expert annotators, as well as LLMs. The proposed approach is based on the Elo rating system, which independently evaluates machine-generated text across multiple dimensions.* Results: The paper finds that the proposed Multi-Elo Rating System significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy. However, there is no significant improvement in crowd-sourced-based evaluations, indicating the need for further investigation and refinement.Here are the three points in Simplified Chinese text:* For: 这篇论文目的是评估大语言模型（LLM）在自然语言生成任务中的表现，并提出一种新的评估方法来提高 LLM 评估的准确性。* Methods: 论文使用一个意外损害机器生成答案的数据集来比较人工评分和专家评分员，以及 LLM 的评估行为。提议的方法基于 Elo 评分系统，独立评估机器生成文本的多个维度。* Results: 论文发现，提议的多维度 Elo 评分系统可以显著提高 LLM 评估的质量，特别是有关事实准确性。然而，对于人工评分来说，没有显著提高， indicating 需要进一步的调查和优化。<details>
<summary>Abstract</summary>
As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging. Human evaluations are conventionally considered the gold standard in natural language generation, but recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes. However, the extent to which humans and LLMs are capable evaluators remains uncertain. This study investigates the behavior of crowd-sourced and expert annotators, as well as LLMs, when comparing outputs from different models. To achieve this, we curate a dataset of intentionally flawed machine-generated answers. Our findings reveal a concerning bias in the evaluation process, as answers with factual errors are rated more favorably than answers that are too short or contained grammatical errors. To address this issue, we propose independently evaluating machine-generated text across multiple dimensions, rather than merging all the evaluation aspects into a single score. We instantiate this idea with the Elo rating system, resulting in the Multi-Elo Rating System. Empirical results from our study reveal that this proposed approach significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy. However, there is no significant improvement in crowd-sourced-based evaluations, indicating the need for further investigation and refinement.
</details>
<details>
<summary>摘要</summary>
LLMs 继续进步，评估其性能变得越来越复杂。人工评估被视为自然语言生成领域的黄金标准，但在评估过程中，使用state-of-the-art LLMS作为人类评审人的代理。然而，人类和 LLMS 是否都有能力作为评估者存在uncertainty。这个研究investigates crowd-sourced和专家标注者，以及 LLMS 对不同模型的输出进行比较。为了实现这一目标，我们创建了一个包含机器生成答案中故意错误的数据集。我们的发现表明，答案中包含错误的答案被评分更高，比答案过短或者语法错误的答案更高。为了解决这个问题，我们提议在多个维度上独立评估机器生成文本，而不是将所有评估方面综合为一个分数。我们实现这一想法通过Elo分数系统，导致Multi-Elo Rating System。我们的研究发现，这种提议的方法可以显著提高 LLM-based 评估质量，尤其是对实际准确性。然而，对于人工标注者来说，没有显著改善，表明需要进一步的调查和优化。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Semiring-Weighted-Earley-Parsing"><a href="#Efficient-Semiring-Weighted-Earley-Parsing" class="headerlink" title="Efficient Semiring-Weighted Earley Parsing"></a>Efficient Semiring-Weighted Earley Parsing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02982">http://arxiv.org/abs/2307.02982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rycolab/earleys-algo">https://github.com/rycolab/earleys-algo</a></li>
<li>paper_authors: Andreas Opedal, Ran Zmigrod, Tim Vieira, Ryan Cotterell, Jason Eisner</li>
<li>for: 这个论文提供了一个引用描述，描述了 Earley （1970）的上下文自由parse算法以及其中的各种加速方法。</li>
<li>methods: 该论文包括了一种知名的最差情况时间复杂度改进，从 Earley 的 $O (N^3|G||R|)$ 改进到 $O (N^3|G|)$，与 CKY 在简化版 grammar $G$ 上的时间复杂度相同。此外，该论文还提供了一种使用Compact finite-state automaton $M$来实现时间复杂度为 $O (N^3|M|)$ 的版本，其中 $|M| \leq |G|$。</li>
<li>results: 该论文的实验结果表明，在采用了预处理 grammar 的情况下，semiring-weighted deduction 的方法和无Weighted deduction 的方法在时间复杂度和空间需求上具有相同的极限性。此外，在某些 grammar 上，可以实现 sub-cubic 时间复杂度的执行。<details>
<summary>Abstract</summary>
This paper provides a reference description, in the form of a deduction system, of Earley's (1970) context-free parsing algorithm with various speed-ups. Our presentation includes a known worst-case runtime improvement from Earley's $O (N^3|G||R|)$, which is unworkable for the large grammars that arise in natural language processing, to $O (N^3|G|)$, which matches the runtime of CKY on a binarized version of the grammar $G$. Here $N$ is the length of the sentence, $|R|$ is the number of productions in $G$, and $|G|$ is the total length of those productions. We also provide a version that achieves runtime of $O (N^3|M|)$ with $|M| \leq |G|$ when the grammar is represented compactly as a single finite-state automaton $M$ (this is partly novel). We carefully treat the generalization to semiring-weighted deduction, preprocessing the grammar like Stolcke (1995) to eliminate deduction cycles, and further generalize Stolcke's method to compute the weights of sentence prefixes. We also provide implementation details for efficient execution, ensuring that on a preprocessed grammar, the semiring-weighted versions of our methods have the same asymptotic runtime and space requirements as the unweighted methods, including sub-cubic runtime on some grammars.
</details>
<details>
<summary>摘要</summary>
Here, $N$ is the length of the sentence, $|R|$ is the number of productions in $G$, and $|G|$ is the total length of those productions. The paper also discusses the generalization to semiring-weighted deduction, preprocessing the grammar like Stolcke (1995) to eliminate deduction cycles, and further generalizing Stolcke's method to compute the weights of sentence prefixes.
</details></li>
</ul>
<hr>
<h2 id="Agentivita-e-telicita-in-GilBERTo-implicazioni-cognitive"><a href="#Agentivita-e-telicita-in-GilBERTo-implicazioni-cognitive" class="headerlink" title="Agentività e telicità in GilBERTo: implicazioni cognitive"></a>Agentività e telicità in GilBERTo: implicazioni cognitive</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02910">http://arxiv.org/abs/2307.02910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnese Lombardi, Alessandro Lenci</li>
<li>for: 本研究旨在调查 transformer 基于神经语言模型是否可以推理词义 semantics，并使用这些信息来完成 morphosyntactic 模式的完成。</li>
<li>methods: 该研究使用 transformer 模型和意大陆 native speakers 的数据进行比较，以Investigate  neural language models 是否能够捕捉人类 semantic competence 中的一些重要方面。</li>
<li>results: 研究发现，transformer 模型在完成 morphosyntactic 模式时能够充分利用词义信息，并且与意大陆 native speakers 的结果相似。这表明 transformer 模型在推理词义 semantics 方面具有一定的能力。<details>
<summary>Abstract</summary>
The goal of this study is to investigate whether a Transformer-based neural language model infers lexical semantics and use this information for the completion of morphosyntactic patterns. The semantic properties considered are telicity (also combined with definiteness) and agentivity. Both act at the interface between semantics and morphosyntax: they are semantically determined and syntactically encoded. The tasks were submitted to both the computational model and a group of Italian native speakers. The comparison between the two groups of data allows us to investigate to what extent neural language models capture significant aspects of human semantic competence.
</details>
<details>
<summary>摘要</summary>
这项研究的目的是研究transformer基于神经语言模型是否可以推断词义，并使用这些信息来完成 morphosyntactic 模式的完成。我们考虑的 semantic properties 包括 telicity 和 agentivity，它们在 semantics 和 morphosyntax 之间作用，它们是semantically determined 并 syntactically encoded。我们对这些任务进行了计算机模型和一群意大利本地语言使用者的比较，这allow us  Investigate 到哪程度 neural language models 捕捉了人类 semantics 能力的重要方面。
</details></li>
</ul>
<hr>
<h2 id="The-Relationship-Between-Speech-Features-Changes-When-You-Get-Depressed-Feature-Correlations-for-Improving-Speed-and-Performance-of-Depression-Detection"><a href="#The-Relationship-Between-Speech-Features-Changes-When-You-Get-Depressed-Feature-Correlations-for-Improving-Speed-and-Performance-of-Depression-Detection" class="headerlink" title="The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection"></a>The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02892">http://arxiv.org/abs/2307.02892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuxiang Tao, Wei Ma, Xuri Ge, Anna Esposito, Alessandro Vinciarelli</li>
<li>for: 该研究发现听力症改变了语音特征之间的相关性。此外，它还表明使用这种发现可以改善基于SVM和LSTM的抑郁检测器的训练速度和性能。</li>
<li>methods: 实验使用了Androids Corpus dataset，包括112名 speaker，其中58名被诊断为职业心理医生诊断的抑郁症。</li>
<li>results: 实验结果显示，使用特征相关矩阵而不是特征向量可以提高模型的训练速度和性能，降低误差率在23.1%到26.6%之间，这可能是因为抑郁 speaker 中特征相关矩阵更为变化。<details>
<summary>Abstract</summary>
This work shows that depression changes the correlation between features extracted from speech. Furthermore, it shows that using such an insight can improve the training speed and performance of depression detectors based on SVMs and LSTMs. The experiments were performed over the Androids Corpus, a publicly available dataset involving 112 speakers, including 58 people diagnosed with depression by professional psychiatrists. The results show that the models used in the experiments improve in terms of training speed and performance when fed with feature correlation matrices rather than with feature vectors. The relative reduction of the error rate ranges between 23.1% and 26.6% depending on the model. The probable explanation is that feature correlation matrices appear to be more variable in the case of depressed speakers. Correspondingly, such a phenomenon can be thought of as a depression marker.
</details>
<details>
<summary>摘要</summary>
这个研究表明，抑郁症会改变来自语音特征的相关性。此外，这个发现可以提高基于SVM和LSTM的抑郁检测器的训练速度和性能。实验使用了公共可用的Androids Corpus数据集，包括112名说话者，其中58名被诊断为职业心理医生诊断的抑郁症患者。结果表明，使用特征相关矩阵而不是特征向量可以提高模型的训练速度和性能。错误率下降的相对减少范围为23.1%到26.6%，具体原因可能是抑郁 speaker 的特征相关矩阵更为变化。这种现象可以被视为抑郁标志。
</details></li>
</ul>
<hr>
<h2 id="ValiTex-–-a-unified-validation-framework-for-computational-text-based-measures-of-social-science-constructs"><a href="#ValiTex-–-a-unified-validation-framework-for-computational-text-based-measures-of-social-science-constructs" class="headerlink" title="ValiTex – a unified validation framework for computational text-based measures of social science constructs"></a>ValiTex – a unified validation framework for computational text-based measures of social science constructs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02863">http://arxiv.org/abs/2307.02863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Birkenmaier, Clemens Lechner, Claudia Wagner</li>
<li>for: 这篇论文的目的是为计算文本数据中的社会科学构uct提供验证框架。</li>
<li>methods: 这篇论文使用了一种新的验证框架called ValiTex，它是基于心理测量的传统，并将其扩展以适应计算文本分析。ValiTex包括一个概念模型和一个动态列表。概念模型提供了一个通用结构，用于验证社会科学构uct，而动态列表则定义了特定的验证步骤，并提供了有关哪些步骤是可以提供有效验证证据的指导。</li>
<li>results: 在使用ValiTex验证社会科学构uct时，可以通过应用于社交媒体数据的示例来证明该框架的实用性。<details>
<summary>Abstract</summary>
Guidance on how to validate computational text-based measures of social science constructs is fragmented. Whereas scholars are generally acknowledging the importance of validating their text-based measures, they often lack common terminology and a unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars to measure social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components, a conceptual model, and a dynamic checklist. Whereas the conceptual model provides a general structure along distinct phases on how to approach validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing additional supporting validation evidence. The utility of the framework is demonstrated by applying it to a use case of detecting sexism from social media data.
</details>
<details>
<summary>摘要</summary>
帮助验证计算文本基于社会科学概念的度量方法存在 Fragmented. Although scholars generally recognize the importance of validating their text-based measures, they often lack a common terminology and unified framework to do so. This paper introduces a new validation framework called ValiTex, designed to assist scholars in measuring social science constructs based on textual data. The framework draws on a long-established tradition within psychometrics while extending the framework for the purpose of computational text analysis. ValiTex consists of two components: a conceptual model and a dynamic checklist. While the conceptual model provides a general structure for approaching validation, the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable (i.e., providing relevant and necessary validation evidence) or optional (i.e., useful for providing additional supporting validation evidence. The utility of the framework is demonstrated by applying it to a use case of detecting sexism from social media data.Here's the breakdown of the translation:* "Guidance on how to validate computational text-based measures of social science constructs is fragmented" becomes 帮助验证计算文本基于社会科学概念的度量方法存在 Fragmented.* "Whereas scholars are generally acknowledging the importance of validating their text-based measures" becomes although scholars generally recognize the importance of validating their text-based measures.* "they often lack common terminology and a unified framework to do so" becomes they often lack a common terminology and unified framework to do so.* "This paper introduces a new validation framework called ValiTex" becomes 这篇论文介绍了一种新的验证框架 called ValiTex.* "designed to assist scholars in measuring social science constructs based on textual data" becomes 用于帮助学者在文本数据上验证社会科学概念.* "The framework draws on a long-established tradition within psychometrics" becomes 该框架基于长期存在的心理测量传统.* "while extending the framework for the purpose of computational text analysis" becomes 而将其扩展为计算文本分析的目的.* "ValiTex consists of two components: a conceptual model and a dynamic checklist" becomes ValiTex consists of two components: a conceptual model and a dynamic checklist.* "Whereas the conceptual model provides a general structure for approaching validation" becomes 而 conceptual model provides a general structure for approaching validation.* "the dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable" becomes 而 dynamic checklist defines specific validation steps and provides guidance on which steps might be considered recommendable.* "or optional (i.e., useful for providing additional supporting validation evidence)" becomes or optional (i.e., useful for providing additional supporting validation evidence).* "The utility of the framework is demonstrated by applying it to a use case of detecting sexism from social media data" becomes 该框架的实用性是通过对社交媒体数据进行性别歧视检测来示例出来.
</details></li>
</ul>
<hr>
<h2 id="NatLogAttack-A-Framework-for-Attacking-Natural-Language-Inference-Models-with-Natural-Logic"><a href="#NatLogAttack-A-Framework-for-Attacking-Natural-Language-Inference-Models-with-Natural-Logic" class="headerlink" title="NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic"></a>NatLogAttack: A Framework for Attacking Natural Language Inference Models with Natural Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02849">http://arxiv.org/abs/2307.02849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zi’ou Zheng, Xiaodan Zhu</li>
<li>for: 本研究旨在探讨逻辑 formalism 基于的攻击模型，以 evaluating 当前的 natural language inference（NLI）模型是否真正进行了推理，还是仅仅依赖于偶合关系。</li>
<li>methods: 本研究提出了 NatLogAttack，一种基于自然逻辑的攻击模型，可以进行系统性的攻击。该模型可以实现标签保持和标签转换两种类型的攻击。</li>
<li>results: 比较 existing 攻击模型，NatLogAttack 可以生成更好的 adversarial examples，需要 fewer 访问 victim 模型。 Label-flipping 设定下，攻击模型更加脆弱。 NatLogAttack 提供了一种测试当前和未来 NLI 模型的能力的工具，并希望更多基于逻辑的攻击将被进一步探讨，以更好地理解推理的愿望性。<details>
<summary>Abstract</summary>
Reasoning has been a central topic in artificial intelligence from the beginning. The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference. However, it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations. Adversarial attacks have proven to be an important tool to help evaluate the Achilles' heel of the victim models. In this study, we explore the fundamental problem of developing attack models based on logic formalism. We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle's syllogism and has been closely developed for natural language inference. The proposed framework renders both label-preserving and label-flipping attacks. We show that compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models. The victim models are found to be more vulnerable under the label-flipping setting. NatLogAttack provides a tool to probe the existing and future NLI models' capacity from a key viewpoint and we hope more logic-based attacks will be further explored for understanding the desired property of reasoning.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Reasoning has been a central topic in artificial intelligence from the beginning. The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference. However, it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations. Adversarial attacks have proven to be an important tool to help evaluate the Achilles' heel of the victim models. In this study, we explore the fundamental problem of developing attack models based on logic formalism. We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle's syllogism and has been closely developed for natural language inference. The proposed framework renders both label-preserving and label-flipping attacks. We show that compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models. The victim models are found to be more vulnerable under the label-flipping setting. NatLogAttack provides a tool to probe the existing and future NLI models' capacity from a key viewpoint and we hope more logic-based attacks will be further explored for understanding the desired property of reasoning." into Simplified Chinese.中文翻译：自人工智能开始以来，理解是一个中心主题。分布表示和神经网络的进步在自然语言推理中提高了状态艺术性。然而，是否模型通过真正的理解来达到结论还是利用偶合关系，这是一个打开的问题。对于受害者模型，抗击攻击是一种重要的工具。在这种研究中，我们探讨了基于逻辑ormalism的攻击模型的基本问题。我们提出了NatLogAttack，一种基于自然逻辑的系统性攻击方法。我们实现了保留和反转标签攻击。我们发现，相比现有的攻击模型，NatLogAttack生成的恶作剂更好，需要 fewer 访问受害者模型。受害者模型在反转标签设置下更加易受攻击。NatLogAttack提供了评估现有和未来 NLI 模型的能力的重要工具，我们希望更多的逻辑基于攻击将被进一步探讨，以更好地理解推理的所求性。
</details></li>
</ul>
<hr>
<h2 id="Generative-Zero-Shot-Prompt-Learning-for-Cross-Domain-Slot-Filling-with-Inverse-Prompting"><a href="#Generative-Zero-Shot-Prompt-Learning-for-Cross-Domain-Slot-Filling-with-Inverse-Prompting" class="headerlink" title="Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting"></a>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02830">http://arxiv.org/abs/2307.02830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefeng Li, Liwen Wang, Guanting Dong, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu</li>
<li>for: 这篇论文旨在解决跨领域插值构型问题，将知识从已经标注的来源领域转移到未标注的目标领域。</li>
<li>methods: 我们提出了一个生成式零条件提示学习框架，以改善这些模型的普遍性和可靠性。我们还引入了一个新的倒推提示策略，以区分不同的构型，并使用高效的提示调整策略，以提高表现。</li>
<li>results: 实验和分析结果显示，我们的提案的框架比前一代模型具有更高的效果，尤其是在未见构型上 (+13.44% F1) 获得了大幅提升。<details>
<summary>Abstract</summary>
Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness. In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work. Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt-tuning strategy to boost higher performance by only training fewer prompt parameters. Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT Zero-shot cross-domain slot filling aims to transfer knowledge from the labeled source domain to the unlabeled target domain. Existing models either encode slot descriptions and examples or design handcrafted question templates using heuristic rules, suffering from poor generalization capability or robustness. In this paper, we propose a generative zero-shot prompt learning framework for cross-domain slot filling, both improving generalization and robustness than previous work. Besides, we introduce a novel inverse prompting strategy to distinguish different slot types to avoid the multiple prediction problem, and an efficient prompt-tuning strategy to boost higher performance by only training fewer prompt parameters. Experiments and analysis demonstrate the effectiveness of our proposed framework, especially huge improvements (+13.44% F1) on the unseen slots.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="VerifAI-Verified-Generative-AI"><a href="#VerifAI-Verified-Generative-AI" class="headerlink" title="VerifAI: Verified Generative AI"></a>VerifAI: Verified Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02796">http://arxiv.org/abs/2307.02796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Tang, Chenyu Yang, Ju Fan, Lei Cao</li>
<li>for: 该论文目的是探讨生成AI输出的准确性和可靠性问题，以及如何通过数据管理方式来解决这个问题。</li>
<li>methods: 该论文使用了多 modal 数据湖的数据分析方法，包括文本文件、表格和知识图谱等，以评估数据质量和一致性。</li>
<li>results: 该论文提出了一种基于数据管理的生成AI验证方法，可以确保生成AI输出的正确性，促进透明度，并帮助做出更加信心的决策。<details>
<summary>Abstract</summary>
Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow. Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more. Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge. We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI. This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency. By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models. Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence. Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UniCoRN-Unified-Cognitive-Signal-ReconstructioN-bridging-cognitive-signals-and-human-language"><a href="#UniCoRN-Unified-Cognitive-Signal-ReconstructioN-bridging-cognitive-signals-and-human-language" class="headerlink" title="UniCoRN: Unified Cognitive Signal ReconstructioN bridging cognitive signals and human language"></a>UniCoRN: Unified Cognitive Signal ReconstructioN bridging cognitive signals and human language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05355">http://arxiv.org/abs/2307.05355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rootnx/UniCoRN">https://github.com/rootnx/UniCoRN</a></li>
<li>paper_authors: Nuwa Xi, Sendong Zhao, Haochun Wang, Chi Liu, Bing Qin, Ting Liu</li>
<li>for: 这篇论文旨在探讨用 cognitive signals (如 fMRI) 提高我们对人类语言系统的理解，并为建立多功能 Brain-Computer Interface 做出了重要贡献。</li>
<li>methods: 这篇论文提出了 fMRI2text，第一个开放词汇任务，旨在将 fMRI 时间序列与人类语言相桥接。此外，作者还提出了一个基线解决方案，称为 UniCoRN，可以重构 cognitive signals 的时间序列和时点值，并利用预训练的语言模型来解码 coherent text。</li>
<li>results: 实验结果表明，UniCoRN 在 fMRI2text 和 EEGto-text 解码任务中具有高效性，其 BLEU 分数分别为 34.77% 和 37.04%，比前一个基线提高了超过 10%。这表明了在不同的 cognitive signals 上使用一个共同结构可以实现高效的解码。<details>
<summary>Abstract</summary>
Decoding text stimuli from cognitive signals (e.g. fMRI) enhances our understanding of the human language system, paving the way for building versatile Brain-Computer Interface. However, existing studies largely focus on decoding individual word-level fMRI volumes from a restricted vocabulary, which is far too idealized for real-world application. In this paper, we propose fMRI2text, the first openvocabulary task aiming to bridge fMRI time series and human language. Furthermore, to explore the potential of this new task, we present a baseline solution, UniCoRN: the Unified Cognitive Signal ReconstructioN for Brain Decoding. By reconstructing both individual time points and time series, UniCoRN establishes a robust encoder for cognitive signals (fMRI & EEG). Leveraging a pre-trained language model as decoder, UniCoRN proves its efficacy in decoding coherent text from fMRI series across various split settings. Our model achieves a 34.77% BLEU score on fMRI2text, and a 37.04% BLEU when generalized to EEGto-text decoding, thereby surpassing the former baseline. Experimental results indicate the feasibility of decoding consecutive fMRI volumes, and the effectiveness of decoding different cognitive signals using a unified structure.
</details>
<details>
<summary>摘要</summary>
decode text 刺激信号（例如fMRI）可以帮助我们更好地理解人类语言系统，这将开创出多样化的脑计算机接口。然而，现有的研究主要集中于解码限定词汇 volume 的 fMRI 时间序列，这是实际应用中过于理想化的。在这篇论文中，我们提出了 fMRI2text，第一个开放词汇任务，旨在将 fMRI 时间序列和人类语言相连。此外，为了探索这个新任务的潜力，我们提出了基线解决方案，即 UniCoRN：一种统一的认知信号重建方法 для脑解oding。UniCoRN 可以重建各个时间点和时间序列，并利用预训练的语言模型作为解码器，以解码 fMRI 序列中的 coherent text。我们的模型在 fMRI2text 任务中 achievement 34.77% BLEU 分数，并在 EEGto-text 解码任务中 achievement 37.04% BLEU，超过了 former 基线。实验结果表明可以解码连续的 fMRI 序列，以及使用统一结构可以解码不同的认知信号。
</details></li>
</ul>
<hr>
<h2 id="Training-Models-to-Generate-Recognize-and-Reframe-Unhelpful-Thoughts"><a href="#Training-Models-to-Generate-Recognize-and-Reframe-Unhelpful-Thoughts" class="headerlink" title="Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts"></a>Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02768">http://arxiv.org/abs/2307.02768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mounica Maddela, Megan Ung, Jing Xu, Andrea Madotto, Heather Foran, Y-Lan Boureau</li>
<li>for: 本研究旨在使用现有的语言模型生成具体化的实践材料，以帮助改善心理健康。</li>
<li>methods: 本研究使用了现有的语言模型，生成了一个大约10k个示例具有不Helpful思维模式的思想，以及27k个正面重新定义。</li>
<li>results: 研究表明，通过使用这些数据集来训练和&#x2F;或评估当前模型，可以生成大量的个性化实践材料和假设，无需或 minimum额外加模型训练。<details>
<summary>Abstract</summary>
Many cognitive approaches to well-being, such as recognizing and reframing unhelpful thoughts, have received considerable empirical support over the past decades, yet still lack truly widespread adoption in self-help format. A barrier to that adoption is a lack of adequately specific and diverse dedicated practice material. This work examines whether current language models can be leveraged to both produce a virtually unlimited quantity of practice material illustrating standard unhelpful thought patterns matching specific given contexts, and generate suitable positive reframing proposals. We propose PATTERNREFRAME, a novel dataset of about 10k examples of thoughts containing unhelpful thought patterns conditioned on a given persona, accompanied by about 27k positive reframes. By using this dataset to train and/or evaluate current models, we show that existing models can already be powerful tools to help generate an abundance of tailored practice material and hypotheses, with no or minimal additional model training required.
</details>
<details>
<summary>摘要</summary>
许多认知方法，如认知和重新定义不helpful的思想，在过去几十年内得到了证据，然而仍未得到广泛的采用。一个阻碍factor是缺乏具有充分specific和多样化的专门练习材料。这项工作研究了whether current language models可以被利用来生成具有specific context的标准不helpful思想模式的庞大量 практи materials，以及生成适合的正面重新定义建议。我们提出了PATTERNREFRAME dataset，包含约10k例思想中的不helpful思想模式， Conditioned on a given persona, accompanied by approximately 27k positive reframes。通过使用这个dataset来训练和/或评估当前模型，我们发现了，现有模型可以被转化成帮助生成大量tailored practice material和假设，无需或 minimum additional model training。
</details></li>
</ul>
<hr>
<h2 id="Undecimated-Wavelet-Transform-for-Word-Embedded-Semantic-Marginal-Autoencoder-in-Security-improvement-and-Denoising-different-Languages"><a href="#Undecimated-Wavelet-Transform-for-Word-Embedded-Semantic-Marginal-Autoencoder-in-Security-improvement-and-Denoising-different-Languages" class="headerlink" title="Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages"></a>Undecimated Wavelet Transform for Word Embedded Semantic Marginal Autoencoder in Security improvement and Denoising different Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03679">http://arxiv.org/abs/2307.03679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreyanth S</li>
<li>for: 提高数据处理应用程序的安全性、隐私性和多语言支持</li>
<li>methods: 结合不减杂波лет变换和word嵌入semantic marginal autoencoder</li>
<li>results: 成功提高多语言数据处理应用程序的安全性和鲁棒性，并且能够有效地降低噪声和提高数据质量<details>
<summary>Abstract</summary>
By combining the undecimated wavelet transform within a Word Embedded Semantic Marginal Autoencoder (WESMA), this research study provides a novel strategy for improving security measures and denoising multiple languages. The incorporation of these strategies is intended to address the issues of robustness, privacy, and multilingualism in data processing applications. The undecimated wavelet transform is used as a feature extraction tool to identify prominent language patterns and structural qualities in the input data. The proposed system may successfully capture significant information while preserving the temporal and geographical links within the data by employing this transform. This improves security measures by increasing the system's ability to detect abnormalities, discover hidden patterns, and distinguish between legitimate content and dangerous threats. The Word Embedded Semantic Marginal Autoencoder also functions as an intelligent framework for dimensionality and noise reduction. The autoencoder effectively learns the underlying semantics of the data and reduces noise components by exploiting word embeddings and semantic context. As a result, data quality and accuracy are increased in following processing stages. The suggested methodology is tested using a diversified dataset that includes several languages and security scenarios. The experimental results show that the proposed approach is effective in attaining security enhancement and denoising capabilities across multiple languages. The system is strong in dealing with linguistic variances, producing consistent outcomes regardless of the language used. Furthermore, incorporating the undecimated wavelet transform considerably improves the system's ability to efficiently address complex security concerns
</details>
<details>
<summary>摘要</summary>
通过将不减波лет变换纳入word嵌入semantic marginal autoencoder（WESMA）中，本研究提供了一种新的安全提高和净化多语言的策略。这种策略的目的是解决数据处理应用中的Robustness、隐私和多语言问题。不减波лет变换被用作特征提取工具，以找出输入数据中语言模式和结构特征。提出的系统可以成功地捕捉主要信息，同时保持数据的时空地理链接。这有助于增强安全措施，提高系统检测异常、发现隐藏模式和分辨合法内容和危险威胁的能力。word嵌入semantic marginal autoencoder 还作为一种智能框架，实现维度和噪声减少。 autoencoder 通过利用word嵌入和semanticContext来学习数据的下面 semantics，从而减少噪声组件。因此，数据质量和准确性在后续处理阶段得到提高。本方法在多种语言和安全enario下进行了实验测试，结果显示，提出的方法可以在多语言下实现安全提高和净化能力。系统强大地处理语言差异，在不同语言下产生相同的结果。此外，通过 incorporating不减波лет变换，系统可以更有效地解决复杂的安全问题。
</details></li>
</ul>
<hr>
<h2 id="Your-spouse-needs-professional-help-Determining-the-Contextual-Appropriateness-of-Messages-through-Modeling-Social-Relationships"><a href="#Your-spouse-needs-professional-help-Determining-the-Contextual-Appropriateness-of-Messages-through-Modeling-Social-Relationships" class="headerlink" title="Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships"></a>Your spouse needs professional help: Determining the Contextual Appropriateness of Messages through Modeling Social Relationships</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02763">http://arxiv.org/abs/2307.02763</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/davidjurgens/contextual-appropriateness">https://github.com/davidjurgens/contextual-appropriateness</a></li>
<li>paper_authors: David Jurgens, Agrima Seth, Jackson Sargent, Athena Aghighi, Michael Geraci</li>
<li>for: 本研究旨在提高实时对话中的不当内容识别，并且考虑社交上下文和规范。</li>
<li>methods: 本研究使用大量自然语言模型，将社交关系信息融入数据中，以更好地识别内容是否当。</li>
<li>results: 研究发现，社交关系信息可以帮助大量自然语言模型更加准确地识别内容是否当，并且可以预测其他社交因素，如态度和礼貌。<details>
<summary>Abstract</summary>
Understanding interpersonal communication requires, in part, understanding the social context and norms in which a message is said. However, current methods for identifying offensive content in such communication largely operate independent of context, with only a few approaches considering community norms or prior conversation as context. Here, we introduce a new approach to identifying inappropriate communication by explicitly modeling the social relationship between the individuals. We introduce a new dataset of contextually-situated judgments of appropriateness and show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context. Using data from online conversations and movie dialogues, we provide insight into how the relationships themselves function as implicit norms and quantify the degree to which context-sensitivity is needed in different conversation settings. Further, we also demonstrate that contextual-appropriateness judgments are predictive of other social factors expressed in language such as condescension and politeness.
</details>
<details>
<summary>摘要</summary>
理解人际交流需要一定程度的社会背景和规范，但现有的偏误内容标识方法大多数都是独立于社会背景进行的，只有一些方法考虑到社区规范或之前的对话。我们介绍了一种新的偏误内容标识方法，该方法将社会关系 между个人Explicitly modeling。我们新 introduce a dataset of contextually-situated appropriateness judgments and show that large language models can readily incorporate relationship information to accurately identify appropriateness in a given context.使用在线对话和电影对话，我们提供了关于社交关系如何作为隐式规范的情况，并衡量不同对话场景中context-sensitivity的程度。此外，我们还证明了Contextual-appropriateness judgments是其他社交因素表达在语言中的预测因素。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Linguistic-Style-Matching-in-Online-Communities-The-Role-of-Social-Context-and-Conversation-Dynamics"><a href="#Exploring-Linguistic-Style-Matching-in-Online-Communities-The-Role-of-Social-Context-and-Conversation-Dynamics" class="headerlink" title="Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics"></a>Exploring Linguistic Style Matching in Online Communities: The Role of Social Context and Conversation Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02758">http://arxiv.org/abs/2307.02758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aparna Ananthasubramaniam, Hong Chen, Jason Yan, Kenan Alkiek, Jiaxin Pei, Agrima Seth, Lavinia Dunagan, Minje Choi, Benjamin Litterer, David Jurgens</li>
<li>for: 研究探讨了在Reddit上的对话中语言风格匹配（LSM）如何影响社交影响的多种方面，包括力量和说服。</li>
<li>methods: 研究使用了两种样式来识别LSM：函数词的使用和正式度。研究者们在Reddit上分析了大量的两人对话线程，并记录了所有LSM的出现。</li>
<li>results: 研究发现LSM与Reddit上的几个社交指标（包括帖子和子社区特征、对话深度、用户积累和评论的争议程度）存在关系，并且 после用户被禁止参与社区，LSM的变化可以反映社区动态的变化。<details>
<summary>Abstract</summary>
Linguistic style matching (LSM) in conversations can be reflective of several aspects of social influence such as power or persuasion. However, how LSM relates to the outcomes of online communication on platforms such as Reddit is an unknown question. In this study, we analyze a large corpus of two-party conversation threads in Reddit where we identify all occurrences of LSM using two types of style: the use of function words and formality. Using this framework, we examine how levels of LSM differ in conversations depending on several social factors within Reddit: post and subreddit features, conversation depth, user tenure, and the controversiality of a comment. Finally, we measure the change of LSM following loss of status after community banning. Our findings reveal the interplay of LSM in Reddit conversations with several community metrics, suggesting the importance of understanding conversation engagement when understanding community dynamics.
</details>
<details>
<summary>摘要</summary>
语言风格匹配（LSM）在对话中可以反映社交影响的多个方面，如力量或说服。然而，LSM在在线交流平台如Reddit上的效果还未得到了许多研究。在这个研究中，我们分析了一个大量的两方对话线程库，并在这里确定了所有的LSM出现。我们使用两种风格来确定LSM：语言功能词和正式度。通过这个框架，我们研究了在Reddit上的讨论中LSM水平与多种社交因素之间的关系，包括帖子和子reddit特征、对话深度、用户 seniority 和评论的争议程度。最后，我们测量了因社区禁止而导致LSM变化的情况。我们的发现表明LSM在Reddit讨论中与多种社区指标之间存在紧密的关系，从而提出了理解对话参与度对社区动力学的重要性。
</details></li>
</ul>
<hr>
<h2 id="Dense-Retrieval-Adaptation-using-Target-Domain-Description"><a href="#Dense-Retrieval-Adaptation-using-Target-Domain-Description" class="headerlink" title="Dense Retrieval Adaptation using Target Domain Description"></a>Dense Retrieval Adaptation using Target Domain Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02740">http://arxiv.org/abs/2307.02740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Helia Hashemi, Yong Zhuang, Sachith Sri Ram Kothur, Srivas Prasad, Edgar Meij, W. Bruce Croft</li>
<li>for: 这paper是为了研究信息检索领域中的领域适应，即无法访问目标文档集的情况下，如何使用文本描述来适应目标领域。</li>
<li>methods: 这paper使用了一种新的自动化数据建构管道，该管道可以根据文本领域描述生成假的文档集、查询集和 Pseudo relevance labels。</li>
<li>results: 经过广泛的实验表明，通过适应 dense retrieval 模型使用生成的假数据可以在目标领域中实现有效的检索性能。<details>
<summary>Abstract</summary>
In information retrieval (IR), domain adaptation is the process of adapting a retrieval model to a new domain whose data distribution is different from the source domain. Existing methods in this area focus on unsupervised domain adaptation where they have access to the target document collection or supervised (often few-shot) domain adaptation where they additionally have access to (limited) labeled data in the target domain. There also exists research on improving zero-shot performance of retrieval models with no adaptation. This paper introduces a new category of domain adaptation in IR that is as-yet unexplored. Here, similar to the zero-shot setting, we assume the retrieval model does not have access to the target document collection. In contrast, it does have access to a brief textual description that explains the target domain. We define a taxonomy of domain attributes in retrieval tasks to understand different properties of a source domain that can be adapted to a target domain. We introduce a novel automatic data construction pipeline that produces a synthetic document collection, query set, and pseudo relevance labels, given a textual domain description. Extensive experiments on five diverse target domains show that adapting dense retrieval models using the constructed synthetic data leads to effective retrieval performance on the target domain.
</details>
<details>
<summary>摘要</summary>
在信息检索（IR）领域，领域适应是指将检索模型适应到新领域的数据分布不同于源领域。现有的方法在这个领域主要集中在无监督领域适应和监督（经常是几个shot）领域适应，其中后者还有访问（有限）标注数据在目标领域。此外，还有研究提高检索模型的零shot性性能。这篇论文介绍了IR领域新的领域适应类别，即与零shot设置相似，我们假设检索模型没有访问目标文档收集。相反，它们有访问目标领域的简短文本描述。我们定义了检索任务中的领域属性分类，以便更好地理解不同的源领域可以适应的不同属性。我们介绍了一种新的自动数据建构管道，可以从文本领域描述中生成 sintetic文档收集、查询集和pseudo relevance标签。我们在五个多样化的目标领域进行了广泛的实验，发现通过适应密集检索模型使用construct的 sintetic数据可以达到有效的检索性能。
</details></li>
</ul>
<hr>
<h2 id="Text-Alignment-Is-An-Efficient-Unified-Model-for-Massive-NLP-Tasks"><a href="#Text-Alignment-Is-An-Efficient-Unified-Model-for-Massive-NLP-Tasks" class="headerlink" title="Text Alignment Is An Efficient Unified Model for Massive NLP Tasks"></a>Text Alignment Is An Efficient Unified Model for Massive NLP Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02729">http://arxiv.org/abs/2307.02729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Zha, Yichi Yang, Ruichen Li, Zhiting Hu</li>
<li>for: 这篇论文目的是提出一种高效的文本对齐模型，用于解决多种文本关系任务，包括文本相似性、问答、事实一致性等。</li>
<li>methods: 该模型使用了 RoBERTa 模型进行轻量级微调，并使用了 5.9 万个样例和 28 个数据集来实现模型的INSTANTIATION。</li>
<li>results: 对于多种文本关系任务，该模型能够匹配或超越 FLAN-T5 模型（具有约 2 倍或 10 倍的参数数量），同时也能够超越任务特定的模型在各个数据集上。此外，该模型还可以用于评估语言生成中的事实一致性，并且可以与 GPT-3.5 和 GPT-4 模型进行比较。<details>
<summary>Abstract</summary>
Large language models (LLMs), typically designed as a function of next-word prediction, have excelled across extensive NLP tasks. Despite the generality, next-word prediction is often not an efficient formulation for many of the tasks, demanding an extreme scale of model parameters (10s or 100s of billions) and sometimes yielding suboptimal performance. In practice, it is often desirable to build more efficient models -- despite being less versatile, they still apply to a substantial subset of problems, delivering on par or even superior performance with much smaller model sizes. In this paper, we propose text alignment as an efficient unified model for a wide range of crucial tasks involving text entailment, similarity, question answering (and answerability), factual consistency, and so forth. Given a pair of texts, the model measures the degree of alignment between their information. We instantiate an alignment model (Align) through lightweight finetuning of RoBERTa (355M parameters) using 5.9M examples from 28 datasets. Despite its compact size, extensive experiments show the model's efficiency and strong performance: (1) On over 20 datasets of aforementioned diverse tasks, the model matches or surpasses FLAN-T5 models that have around 2x or 10x more parameters; the single unified model also outperforms task-specific models finetuned on individual datasets; (2) When applied to evaluate factual consistency of language generation on 23 datasets, our model improves over various baselines, including the much larger GPT-3.5 (ChatGPT) and sometimes even GPT-4; (3) The lightweight model can also serve as an add-on component for LLMs such as GPT-3.5 in question answering tasks, improving the average exact match (EM) score by 17.94 and F1 score by 15.05 through identifying unanswerable questions.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）通常是基于下一个词预测的函数，在各种自然语言处理任务中表现出色。然而，下一个词预测并不是一个有效的形式ulation для许多任务，需要极大的模型参数（10个或100个亿）并且有时会得到低效的性能。在实践中，建立更有效的模型是非常感兴趣，即使它们不那么通用，它们仍然适用于许多问题，可以实现与较小的模型大小相同或者甚至更高的性能。在这篇论文中，我们提议文本对齐作为一种有效的统一模型，用于覆盖许多关键任务的文本相互关系。给定两个文本，模型会测量它们信息之间的相互对齐程度。我们通过轻量级的微调RoBERTa（355M参数）使用590万个示例和28个数据集来实现对齐模型（Align）。即使它的 compact size，我们的实验证明了模型的高效性和强大性：1. 在20个多样化任务上，我们的模型可以与FLAN-T5模型（约2倍或10倍更多参数）匹配或超越它们，并且单一的统一模型也可以超越任务特定的模型在各个数据集上进行微调。2. 当应用于23个数据集上的语言生成的事实一致性评估中，我们的模型可以超越多种基准，包括较大的GPT-3.5（ChatGPT）和有时even GPT-4。3. 轻量级的模型还可以作为LLMs的添加组件，在问答任务中提高GPT-3.5的平均精确匹配（EM）得分17.94%和F1得分15.05%，通过识别无法回答的问题。
</details></li>
</ul>
<hr>
<h2 id="On-Device-Constrained-Self-Supervised-Speech-Representation-Learning-for-Keyword-Spotting-via-Knowledge-Distillation"><a href="#On-Device-Constrained-Self-Supervised-Speech-Representation-Learning-for-Keyword-Spotting-via-Knowledge-Distillation" class="headerlink" title="On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation"></a>On-Device Constrained Self-Supervised Speech Representation Learning for Keyword Spotting via Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02720">http://arxiv.org/abs/2307.02720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gene-Ping Yang, Yue Gu, Qingming Tang, Dongsu Du, Yuzong Liu<br>for: 这个研究旨在应用大型自主学习模型来进行关键词搜寻，但是在设备上的预算和数据收集上存在偏误和限制。methods: 我们提出了一个基于知识传播的自学模型，使用教师生物框架将知识传播到小型轻量级模型，使用双重检查相关知识传播和教师的代码库作为学习目标。results: 我们使用Alexa关键词搜寻探测任务中的16.6万小时内部数据进行评估，结果显示我们的方法在正常和噪音情况下表现出色，证明了知识传播方法在关键词搜寻任务中自主学习模型的构建中具有优异的表现。<details>
<summary>Abstract</summary>
Large self-supervised models are effective feature extractors, but their application is challenging under on-device budget constraints and biased dataset collection, especially in keyword spotting. To address this, we proposed a knowledge distillation-based self-supervised speech representation learning (S3RL) architecture for on-device keyword spotting. Our approach used a teacher-student framework to transfer knowledge from a larger, more complex model to a smaller, light-weight model using dual-view cross-correlation distillation and the teacher's codebook as learning objectives. We evaluated our model's performance on an Alexa keyword spotting detection task using a 16.6k-hour in-house dataset. Our technique showed exceptional performance in normal and noisy conditions, demonstrating the efficacy of knowledge distillation methods in constructing self-supervised models for keyword spotting tasks while working within on-device resource constraints.
</details>
<details>
<summary>摘要</summary>
大型自我超vised模型是有效的特征提取器，但它们在设备上的应用面临了预算限制和欠拟合的数据采集问题，尤其是在关键词检测中。为解决这问题，我们提出了基于知识填充的自我超vised语音表示学习（S3RL）架构，用于在设备上进行关键词检测。我们的方法使用教师-学生框架来传递知识从一个更大的、更复杂的模型到一个更小的、轻量级模型，使用双视相关分配和教师的代码库作为学习目标。我们对Alexa关键词检测任务使用了16.6万小时的自有数据进行评估。我们的技术在正常和噪音条件下表现出色，证明了知识填充方法在构建自我超vised模型 для关键词检测任务中的效果。
</details></li>
</ul>
<hr>
<h2 id="CFSum-A-Coarse-to-Fine-Contribution-Network-for-Multimodal-Summarization"><a href="#CFSum-A-Coarse-to-Fine-Contribution-Network-for-Multimodal-Summarization" class="headerlink" title="CFSum: A Coarse-to-Fine Contribution Network for Multimodal Summarization"></a>CFSum: A Coarse-to-Fine Contribution Network for Multimodal Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02716">http://arxiv.org/abs/2307.02716</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaomin418/cfsum">https://github.com/xiaomin418/cfsum</a></li>
<li>paper_authors: Min Xiao, Junnan Zhu, Haitao Lin, Yu Zhou, Chengqing Zong</li>
<li>for: 提高多模态摘要的效果，解决多modal summarization中图像贡献不清晰的问题。</li>
<li>methods: 提出了一种新的Coarse-to-Fine贡献网络(CFSum)，通过对不同modalities的融合方法进行设计，并忽略不同modalities之间的adaptive条件。</li>
<li>results: 实验结果表明，CFSumsignificantly exceeded多个强基eline的性能标准benchmark。此外，分析也证明了，有用的图像可以帮助生成非视觉词汇，这些词汇在图像中被隐式表示。<details>
<summary>Abstract</summary>
Multimodal summarization usually suffers from the problem that the contribution of the visual modality is unclear. Existing multimodal summarization approaches focus on designing the fusion methods of different modalities, while ignoring the adaptive conditions under which visual modalities are useful. Therefore, we propose a novel Coarse-to-Fine contribution network for multimodal Summarization (CFSum) to consider different contributions of images for summarization. First, to eliminate the interference of useless images, we propose a pre-filter module to abandon useless images. Second, to make accurate use of useful images, we propose two levels of visual complement modules, word level and phrase level. Specifically, image contributions are calculated and are adopted to guide the attention of both textual and visual modalities. Experimental results have shown that CFSum significantly outperforms multiple strong baselines on the standard benchmark. Furthermore, the analysis verifies that useful images can even help generate non-visual words which are implicitly represented in the image.
</details>
<details>
<summary>摘要</summary>
多模态摘要通常受到视觉模式贡献不清晰的问题困扰。现有的多模态摘要方法强调设计不同modalities的融合方法，而忽略不同modalities在摘要中的适应条件。因此，我们提出了一个新的Coarse-to-Fine贡献网络 для多模态摘要（CFSum），以考虑不同modalities的贡献。首先，以避免无用的图像干扰，我们提出了预 filtering模组。其次，以确保精准使用有用的图像，我们提出了两个层次的视觉补充模组，分别是字级和短语级。具体来说，图像贡献被计算，并被运用来引导文本和视觉modalities的注意力。实验结果显示，CFSum与多个强大的基eline进行比较，具有明显的超越。此外，分析显示，有用的图像甚至可以帮助生成非视觉字眼，这些字眼在图像中被隐含表示。
</details></li>
</ul>
<hr>
<h2 id="Strahler-Number-of-Natural-Language-Sentences-in-Comparison-with-Random-Trees"><a href="#Strahler-Number-of-Natural-Language-Sentences-in-Comparison-with-Random-Trees" class="headerlink" title="Strahler Number of Natural Language Sentences in Comparison with Random Trees"></a>Strahler Number of Natural Language Sentences in Comparison with Random Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02697">http://arxiv.org/abs/2307.02697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumiko Tanaka-Ishii, Akira Tanaka</li>
<li>For: The paper aims to apply the Strahler number, originally proposed for characterizing river bifurcation, to natural language sentence tree structures and explore its implications for sentence processing.* Methods: The paper uses empirical measurements across grammatically annotated data to compute the upper and lower limits of the Strahler number for natural language sentences, and analyzes the growth of the Strahler number with sentence length.* Results: The paper shows that the Strahler number of natural language sentences is almost 3 or 4, similar to the case of river bifurcation (Strahler, 1957). The paper also explains reports of 3 to 4 memory areas required for sentence processing (Abney and Johnson, 1991; Schuler et al., 2010) and a psychological “magical number” of 3 to 5 (Cowan, 2001) using the Strahler number. Additionally, the paper finds that the Strahler number is not specific to natural language and holds for random trees.<details>
<summary>Abstract</summary>
The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications. This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures. Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost 3 or 4, similarly to the case of river bifurcation as reported by Strahler (1957). From the theory behind the number, we show that it is one kind of lower limit on the amount of memory required to process sentences. We consider the Strahler number to provide reasoning that explains reports showing that the number of required memory areas to process sentences is 3 to 4 for parsing (Abney and Johnson, 1991; Schuler et al., 2010), and reports indicating a psychological "magical number" of 3 to 5 (Cowan, 2001). An analytical and empirical analysis shows that the Strahler number is not constant but grows logarithmically; therefore, the Strahler number of sentences derives from the range of sentence lengths. Furthermore, the Strahler number is not different for random trees, which could suggest that its origin is not specific to natural language.
</details>
<details>
<summary>摘要</summary>
斯特拉勒数 originally 提出来characterize 河流分支的复杂性，现在这篇文章提议计算自然语言句子树结构中的斯特拉勒数的上下限。通过实际测量grammatically annotated 数据，自然语言句子的斯特拉勒数被证明为大约3或4，与斯特拉勒（1957）所报道的河流分支情况类似。从理论角度来看，斯特拉勒数是自然语言句子处理所需内存量的下限。我们认为斯特拉勒数可以解释某些报告显示 sentence 的处理需要3到4个内存区域（Abney和Johnson，1991；Schuler et al., 2010），以及一些心理学家所提出的“魔数”（Cowan，2001）。我们通过分析和实际测量发现，斯特拉勒数不是常数，而是呈指数增长的，因此斯特拉勒数的句子来自范围内的句子长度。此外，斯特拉勒数不同于随机树，这可能意味着它的起源不特定于自然语言。
</details></li>
</ul>
<hr>
<h2 id="Learning-Symbolic-Rules-over-Abstract-Meaning-Representations-for-Textual-Reinforcement-Learning"><a href="#Learning-Symbolic-Rules-over-Abstract-Meaning-Representations-for-Textual-Reinforcement-Learning" class="headerlink" title="Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning"></a>Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02689">http://arxiv.org/abs/2307.02689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ibm/loa">https://github.com/ibm/loa</a></li>
<li>paper_authors: Subhajit Chaudhury, Sarathkrishna Swaminathan, Daiki Kimura, Prithviraj Sen, Keerthiram Murugesan, Rosario Uceda-Sosa, Michiaki Tatsubori, Achille Fokoue, Pavan Kapanipathi, Asim Munawar, Alexander Gray</li>
<li>for: 本研究旨在提出一种模块化的NEuro-Symbolic Textual Agent（NESTA），以把握游戏文本的 semantics 和含义，从而实现更好的游戏掌控和决策。</li>
<li>methods:  NESTA 方法组合了一个通用semantic parser与一个规则推导系统，从文本中学习抽象可读性的规则，作为游戏决策的基础。</li>
<li>results: 我们在多个文本游戏 benchmark 上进行了实验，结果表明，相比深度强化学习方法，NESTA 方法在未看过测试游戏的情况下的总体性和学习从少量交互数据的能力得到了改进。<details>
<summary>Abstract</summary>
Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.
</details>
<details>
<summary>摘要</summary>
文本基于的强化学习代理人主要是基于神经网络的模型，使用嵌入式表示，学习不可解释的策略，经常无法在未经见过的游戏中普适。然而，神经符号方法，尤其是使用中间正式表示，在语言理解任务中 receiving increasing attention。这是因为它们具有多种优点，如内生可读性、训练数据少量和对未经见过数据的普适性。因此，在这篇论文中，我们提议一种模块化的NEuro-Symbolic Textual Agent（NESTA），该方法结合通用 semantic parser 和规则推导系统，以学习抽象可读性的规则作为策略。我们在已有的文本基于游戏标准套件上进行了实验，结果显示，提议的 NESTA 方法在未经见过测试游戏的普适性和训练交互数量少于深度强化学习基本技术。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Dense-Video-Captioning-by-Jointly-Optimizing-Text-and-Moment"><a href="#Zero-Shot-Dense-Video-Captioning-by-Jointly-Optimizing-Text-and-Moment" class="headerlink" title="Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment"></a>Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02682">http://arxiv.org/abs/2307.02682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongrae Jo, Seongyun Lee, Aiden SJ Lee, Hyunji Lee, Hanseok Oh, Minjoon Seo</li>
<li>for: 本研究旨在降低视频描述需要大量、昂贵的注释集，而不需要训练视频或注释。</li>
<li>methods: 我们提出了一种新的零上下文方法，即ZeroTA，用于紧凑视频描述。ZeroTA不需要任何视频或注释进行训练，而是在测试时使用输入视频本身来定位和描述事件。我们引入了一个软件时间面，用于表示视频中的时间段，并同时优化它与语言生成模型的预refix参数。这种协调使得一个冻结的语言生成模型（例如GPT-2）和一个冻结的视频语言对比模型（例如CLIP）之间匹配得更高。我们还引入了一个对比时间 IoU 损失，使得一组软件时间面能够捕捉视频中多个不同的事件。</li>
<li>results: ZeroTA 效果显著比零上下文基线高，甚至超过了一些几个shot方法在 ActivityNet Captions 上的状态之首。此外，我们的方法在 OUT-OF-DOMAIN 场景下也表现了更高的Robustness，比supervised方法更能抗衡不同的视频样本。这种研究为了使用广泛使用的模型，如语言生成模型和视频语言对比模型，解锁了一种新的能力：理解视频中的时间方面。<details>
<summary>Abstract</summary>
Dense video captioning, a task of localizing meaningful moments and generating relevant captions for videos, often requires a large, expensive corpus of annotated video segments paired with text. In an effort to minimize the annotation cost, we propose ZeroTA, a novel method for dense video captioning in a zero-shot manner. Our method does not require any videos or annotations for training; instead, it localizes and describes events within each input video at test time by optimizing solely on the input. This is accomplished by introducing a soft moment mask that represents a temporal segment in the video and jointly optimizing it with the prefix parameters of a language model. This joint optimization aligns a frozen language generation model (i.e., GPT-2) with a frozen vision-language contrastive model (i.e., CLIP) by maximizing the matching score between the generated text and a moment within the video. We also introduce a pairwise temporal IoU loss to let a set of soft moment masks capture multiple distinct events within the video. Our method effectively discovers diverse significant events within the video, with the resulting captions appropriately describing these events. The empirical results demonstrate that ZeroTA surpasses zero-shot baselines and even outperforms the state-of-the-art few-shot method on the widely-used benchmark ActivityNet Captions. Moreover, our method shows greater robustness compared to supervised methods when evaluated in out-of-domain scenarios. This research provides insight into the potential of aligning widely-used models, such as language generation models and vision-language models, to unlock a new capability: understanding temporal aspects of videos.
</details>
<details>
<summary>摘要</summary>
dense video captioning，一种地点化意义的任务是为视频提供有关的信息和相关的描述，通常需要大量的标注视频片段和文本。为了减少标注成本，我们提议ZeroTA，一种新的零上下文方法 для dense video captioning。我们的方法不需要任何视频或标注 для训练，而是在测试时地点化和描述视频中的事件，通过优化唯一的输入。我们引入了一个软时间面罩，用于表示视频中的时间段，并与预refix参数的语言模型进行同时优化。这个联合优化使得一个冻结的语言生成模型（i.e., GPT-2）和一个冻结的视频语言对比模型（i.e., CLIP）之间进行了一致性的对接。我们还引入了一个对比时间 IoU 损失，使得一组软时间面罩能够捕捉视频中的多个不同事件。我们的方法能够有效地找到视频中的多种重要事件，并且将生成的描述文本与这些事件相应地描述。实验结果表明，ZeroTA 超过零上下文基线值，甚至超过了state-of-the-art 几个shot方法在ActivityNet Captions 上的表现。此外，我们的方法在非标注数据集上的评估也表现了更高的Robustness，比supervised方法更加稳定。这种研究为将广泛使用的模型，如语言生成模型和视频语言对比模型，Alignment 起来，以解锁视频中的时间方面的理解。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Sentiment-Analysis-of-Plastic-Surgery-Social-Media-Posts"><a href="#Unsupervised-Sentiment-Analysis-of-Plastic-Surgery-Social-Media-Posts" class="headerlink" title="Unsupervised Sentiment Analysis of Plastic Surgery Social Media Posts"></a>Unsupervised Sentiment Analysis of Plastic Surgery Social Media Posts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02640">http://arxiv.org/abs/2307.02640</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandrea K. Ramnarine</li>
<li>for: 本研究用于探索社交媒体文本数据的无监督分类和 clustering 技术，以便在人工智能（AI）应用中利用大量文本数据。</li>
<li>methods: 本研究使用TF-IDF方法生成特征，并采用t-SNE、k-means clustering和LDA等方法来学习主要词和生成话题。</li>
<li>results: 研究表明，通过使用无监督分析，计算机可以准确地预测用户对塑形外科的情感，准确率高达90%。此外，模型在无监督分类任务上表现更高的准确率，于是无监督学习可能成为社交媒体文本标注的可能性。<details>
<summary>Abstract</summary>
The massive collection of user posts across social media platforms is primarily untapped for artificial intelligence (AI) use cases based on the sheer volume and velocity of textual data. Natural language processing (NLP) is a subfield of AI that leverages bodies of documents, known as corpora, to train computers in human-like language understanding. Using a word ranking method, term frequency-inverse document frequency (TF-IDF), to create features across documents, it is possible to perform unsupervised analytics, machine learning (ML) that can group the documents without a human manually labeling the data. For large datasets with thousands of features, t-distributed stochastic neighbor embedding (t-SNE), k-means clustering and Latent Dirichlet allocation (LDA) are employed to learn top words and generate topics for a Reddit and Twitter combined corpus. Using extremely simple deep learning models, this study demonstrates that the applied results of unsupervised analysis allow a computer to predict either negative, positive, or neutral user sentiment towards plastic surgery based on a tweet or subreddit post with almost 90% accuracy. Furthermore, the model is capable of achieving higher accuracy on the unsupervised sentiment task than on a rudimentary supervised document classification task. Therefore, unsupervised learning may be considered a viable option in labeling social media documents for NLP tasks.
</details>
<details>
<summary>摘要</summary>
大量用户帖子数据在社交媒体平台上是人工智能（AI）应用的未经利用资源，主要因为数据量和速度的原因。自然语言处理（NLP）是AI的一个子领域，可以利用文档集（corpus）来训练计算机理解人类语言。使用词rank方法，特异频率-反文档频率（TF-IDF）创建文档之间的特征，可以进行无监督分析，机器学习（ML）可以无需人工标注数据来分组文档。对于大量数据（ thousands of features），t-分布随机邻居投影（t-SNE）、k-means聚合和Latent Dirichlet allocation（LDA）可以学习文档中的top词和生成话题。使用非常简单的深度学习模型，这项研究表明，应用无监督分析可以使计算机根据推特或Reddit帖子 predict用户对塑形外科的 sentiment，准确率接近90%。此外，模型还可以在无监督分类任务上达到更高的准确率，因此无监督学习可能是标注社交媒体文档的NLP任务的可靠选择。
</details></li>
</ul>
<hr>
<h2 id="SkipDecode-Autoregressive-Skip-Decoding-with-Batching-and-Caching-for-Efficient-LLM-Inference"><a href="#SkipDecode-Autoregressive-Skip-Decoding-with-Batching-and-Caching-for-Efficient-LLM-Inference" class="headerlink" title="SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference"></a>SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02628">http://arxiv.org/abs/2307.02628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luciano Del Corro, Allie Del Giorno, Sahaj Agarwal, Bin Yu, Ahmed Awadallah, Subhabrata Mukherjee</li>
<li>for: 提高自然语言生成任务中 LLM 的计算效率，以提高实际应用的可行性。</li>
<li>methods: 提出了一种简单有效的 токен级早期退出方法，即 SkipDecode，可以与批处理和 KV 缓存兼容地工作。它通过在每个批处理中设置单个退出点，使每个 токен都可以在批处理中提前退出，从而避免等待最后一个 токен退出。</li>
<li>results: 实验结果表明，使用 SkipDecode 可以获得 2x 到 5x 的批处理速度提升，无论任务类型如何，而且与大型模型（1.3 亿和 6.7 亿参数）兼容。<details>
<summary>Abstract</summary>
Autoregressive large language models (LLMs) have made remarkable progress in various natural language generation tasks. However, they incur high computation cost and latency resulting from the autoregressive token-by-token generation. To address this issue, several approaches have been proposed to reduce computational cost using early-exit strategies. These strategies enable faster text generation using reduced computation without applying the full computation graph to each token. While existing token-level early exit methods show promising results for online inference, they cannot be readily applied for batch inferencing and Key-Value caching. This is because they have to wait until the last token in a batch exits before they can stop computing. This severely limits the practical application of such techniques. In this paper, we propose a simple and effective token-level early exit method, SkipDecode, designed to work seamlessly with batch inferencing and KV caching. It overcomes prior constraints by setting up a singular exit point for every token in a batch at each sequence position. It also guarantees a monotonic decrease in exit points, thereby eliminating the need to recompute KV Caches for preceding tokens. Rather than terminating computation prematurely as in prior works, our approach bypasses lower to middle layers, devoting most of the computational resources to upper layers, allowing later tokens to benefit from the compute expenditure by earlier tokens. Our experimental results show that SkipDecode can obtain 2x to 5x inference speedups with negligible regression across a variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7 billion parameters, all the while being directly compatible with batching and KV caching optimization techniques.
</details>
<details>
<summary>摘要</summary>
自然语言生成任务中，权重自适应大型语言模型（LLM）已经取得了非常出色的进步。然而，它们的计算成本和延迟都是由权重自适应的单词生成引起的。为了解决这个问题，许多方法已经被提出来减少计算成本。这些方法可以在批处理中使用早期终止策略来快速生成文本。然而，现有的单词级早期终止方法无法 direct apply于批处理和Key-Value缓存。这是因为它们必须等待批处理中的最后一个单词离开才能停止计算。这会严重限制它们的实际应用。在这篇论文中，我们提出了一种简单有效的单词级早期终止方法，即SkipDecode。它可以与批处理和Key-Value缓存兼容地工作，并且跨过先前的约束。它在每个批处理中设置了每个单词的独特终止点，并保证单词级减少的终止点，从而消除了重新计算Key-Value缓存的需要。不同于先前的方法，我们的方法不会 prematurely 终止计算，而是通过跳过中间层次，将大部分计算资源分配给上层层次，使后续的单词可以受益于先前单词的计算成本。我们的实验结果表明，SkipDecode可以在多种任务上获得2x至5x的批处理速度提升，而且减少了较小的后果。这是使用1.3亿和6.7亿参数的OPT模型，同时与批处理和Key-Value缓存优化技术兼容。
</details></li>
</ul>
<hr>
<h2 id="Several-categories-of-Large-Language-Models-LLMs-A-Short-Survey"><a href="#Several-categories-of-Large-Language-Models-LLMs-A-Short-Survey" class="headerlink" title="Several categories of Large Language Models (LLMs): A Short Survey"></a>Several categories of Large Language Models (LLMs): A Short Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10188">http://arxiv.org/abs/2307.10188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabh Pahune, Manoj Chandrasekharan<br>for: 本研究的目的是为讲者、开发者、学者和使用LLM-基于虚拟助手和智能客服技术的人提供有用信息和未来方向。methods: 本研究涵盖了不同类型的LLM，包括任务型金融LLM、多语言LLM、医疗和生物医学LLM、视觉语言LLM和代码语言模型。研究还描述了这些类型LLM的方法、特性、数据集、转换模型和比较指标。results: 本研究总结了不同类型LLM的方法、特性、数据集、转换模型和比较指标，并提出了未解决的问题，如提高自然语言处理、提高虚拟助手智能和解决道德和法律问题。<details>
<summary>Abstract</summary>
Large Language Models(LLMs)have become effective tools for natural language processing and have been used in many different fields. This essay offers a succinct summary of various LLM subcategories. The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs. Furthermore, it highlights unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas. The purpose of this study is to provide readers, developers, academics, and users interested in LLM-based chatbots and virtual intelligent assistant technologies with useful information and future directions.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）已成为自然语言处理的有效工具，并在多个领域得到广泛应用。本文提供LLM各种子类别的简洁概述，强调最近的发展和努力。包括任务基金LLM、多语言LLM、生物医学LLM、视觉语言LLM和代码语言模型在内的各种LLM类型。本文还介绍每个类型的方法、特征、数据集、转换器模型和比较指标。此外，文章还强调虚拟助手和智能客服技术的未解决问题，如提高自然语言处理、增强虚拟助手智能和解决道德法律问题。本文的目的是为有关LLM基于虚拟助手和智能客服技术的读者、开发者、学者和用户提供有用信息和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Named-Entity-Inclusion-in-Abstractive-Text-Summarization"><a href="#Named-Entity-Inclusion-in-Abstractive-Text-Summarization" class="headerlink" title="Named Entity Inclusion in Abstractive Text Summarization"></a>Named Entity Inclusion in Abstractive Text Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02570">http://arxiv.org/abs/2307.02570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergey Berezin, Tatiana Batura</li>
<li>for: 提高抽象文本摘要器对名称实体的注意力，解决现有抽象文本摘要器中的名称实体缺失问题。</li>
<li>methods: 提议一种自定义预训练目标，通过使用名称实体识别模型RoBERTa将名称实体在文本中填充，然后使用BART模型重建它们。最后，对摘要任务进行精度调整。</li>
<li>results: 实验表明，这种预训练方法可以提高名称实体包括精度和准确率指标。<details>
<summary>Abstract</summary>
We address the named entity omission - the drawback of many current abstractive text summarizers. We suggest a custom pretraining objective to enhance the model's attention on the named entities in a text. At first, the named entity recognition model RoBERTa is trained to determine named entities in the text. After that, this model is used to mask named entities in the text and the BART model is trained to reconstruct them. Next, the BART model is fine-tuned on the summarization task. Our experiments showed that this pretraining approach improves named entity inclusion precision and recall metrics.
</details>
<details>
<summary>摘要</summary>
我们解决了名称实体漏掉（named entity omission），许多当前的抽象文本摘要器的缺点。我们建议一种自定义预训练目标，以提高模型对名称实体的注意力。首先，我们使用名称实体识别模型RoBERTa来确定文本中的名称实体。然后，我们使用这个模型将名称实体在文本中隐藏，并训练BART模型来重建它们。接着，我们在摘要任务上练化BART模型。我们的实验表明，这种预训练方法可以提高名称实体包括精度和准确率指标。
</details></li>
</ul>
<hr>
<h2 id="LongNet-Scaling-Transformers-to-1-000-000-000-Tokens"><a href="#LongNet-Scaling-Transformers-to-1-000-000-000-Tokens" class="headerlink" title="LongNet: Scaling Transformers to 1,000,000,000 Tokens"></a>LongNet: Scaling Transformers to 1,000,000,000 Tokens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02486">http://arxiv.org/abs/2307.02486</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/unilm">https://github.com/microsoft/unilm</a></li>
<li>paper_authors: Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, Furu Wei</li>
<li>for:  Addressing the challenge of scaling sequence length in the era of large language models, and achieving high performance on both long-sequence modeling and general language tasks.</li>
<li>methods:  Proposes a Transformer variant called LongNet, which uses dilated attention to expand the attentive field exponentially as the distance grows, allowing for the scaling of sequence length to more than 1 billion tokens without sacrificing performance on shorter sequences.</li>
<li>results:  LongNet has significant advantages, including linear computation complexity and logarithmic dependency between any two tokens in a sequence, and can be served as a distributed trainer for extremely long sequences. Experiments demonstrate strong performance on both long-sequence modeling and general language tasks, opening up new possibilities for modeling very long sequences such as entire corpora or the internet.<details>
<summary>Abstract</summary>
Scaling sequence length has become a critical demand in the era of large language models. However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted. To address this issue, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences. Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows. LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between any two tokens in a sequence; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization. Experiments results demonstrate that LongNet yields strong performance on both long-sequence modeling and general language tasks. Our work opens up new possibilities for modeling very long sequences, e.g., treating a whole corpus or even the entire Internet as a sequence.
</details>
<details>
<summary>摘要</summary>
Era of large language models 时代，序列长度扩展成为关键询问。然而，现有方法受到计算复杂性或模型表达能力的限制，导致最大序列长度受限。为解决这个问题，我们介绍 LongNet，一种基于 Transformer 的变体，可以将序列长度扩展到更多于 10^9 个字符，而无需牺牲短序列表现。 Specifically, we propose dilated attention，它可以在距离增长时扩展担注场 exponentially。 LongNet 具有以下优势：1) 它具有线性计算复杂性和对任何两个序列元素之间的对数依赖关系; 2) 它可以作为分布式训练器进行极长序列训练; 3) 它的扩展担注可以轻松地替换标准担注，可以顺利地与现有基于 Transformer 的优化集成。实验结果表明，LongNet 在长序列模型化和通用语言任务上具有强大表现。我们的工作开 up 了模型 Very Long Sequence 的新可能性，例如，将整个文库或 even 互联网视为一个序列。
</details></li>
</ul>
<hr>
<h2 id="What-Matters-in-Training-a-GPT4-Style-Language-Model-with-Multimodal-Inputs"><a href="#What-Matters-in-Training-a-GPT4-Style-Language-Model-with-Multimodal-Inputs" class="headerlink" title="What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?"></a>What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02469">http://arxiv.org/abs/2307.02469</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bytedance/lynx-llm">https://github.com/bytedance/lynx-llm</a></li>
<li>paper_authors: Yan Zeng, Hanbo Zhang, Jiani Zheng, Jiangnan Xia, Guoqiang Wei, Yang Wei, Yuchen Zhang, Tao Kong</li>
<li>for: 本文旨在系统地研究大语言模型（LLM）如GPT4的多Modal能力，以便更好地理解这些模型在following open-ended instructions给出的图像时的表现。</li>
<li>methods: 本文采用了多种控制设置，包括不同的网络结构、数据集和采样策略，以及多种提示方法来影响模型的表现。</li>
<li>results: 研究发现，使用Lynx模型可以实现最高的多Modal理解和多Modal生成能力，而且在多种图像和视频任务上表现最佳。<details>
<summary>Abstract</summary>
Recent advancements in Large Language Models (LLMs) such as GPT4 have displayed exceptional multi-modal capabilities in following open-ended instructions given images. However, the performance of these models heavily relies on design choices such as network structures, training data, and training strategies, and these choices have not been extensively discussed in the literature, making it difficult to quantify progress in this field. To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models. We implement over 20 variants with controlled settings. Concretely, for network structures, we compare different LLM backbones and model designs. For training data, we investigate the impact of data and sampling strategies. For instructions, we explore the influence of diversified prompts on the instruction-following ability of the trained models. For benchmarks, we contribute the first, to our best knowledge, comprehensive evaluation set including both image and video tasks through crowd-sourcing. Based on our findings, we present Lynx, which performs the most accurate multi-modal understanding while keeping the best multi-modal generation ability compared to existing open-sourced GPT4-style models.
</details>
<details>
<summary>摘要</summary>
最近的大语言模型（LLM）如GPT4的发展已经展现出了杰出的多模态能力，能够根据图像提供开放式指令following。然而，这些模型的性能受到设计选择的影响，如网络结构、训练数据和训练策略，这些选择在文献中尚未得到广泛的讨论，因此很难量化进展。为解决这问题，本文提出了一项系统性和全面的研究，通过Quantitative和Qualitative方式来训练这些模型。我们实施了20多种变体，其中包括不同的LLM后缀和模型设计、训练数据和采样策略、指令和多模态生成能力。为了评估这些模型的性能，我们建立了包括图像和视频任务的首个、至今为止最 complet comprehensive评估集。基于我们的发现，我们提出了Lynx，它在多模态理解和多模态生成能力之间具有最高精度。
</details></li>
</ul>
<hr>
<h2 id="Hoodwinked-Deception-and-Cooperation-in-a-Text-Based-Game-for-Language-Models"><a href="#Hoodwinked-Deception-and-Cooperation-in-a-Text-Based-Game-for-Language-Models" class="headerlink" title="Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models"></a>Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01404">http://arxiv.org/abs/2308.01404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aogara-ds/hoodwinked">https://github.com/aogara-ds/hoodwinked</a></li>
<li>paper_authors: Aidan O’Gara</li>
<li>for: 这个论文研究了现有语言模型是否具备诱导和假装能力？作者们引入了一款基于Mafia和Among Us的文本游戏，并在这个游戏中使用GPT-3、GPT-3.5和GPT-4控制的代理人进行测试。</li>
<li>methods: 作者们使用了一种基于自然语言的文本游戏，其中一名玩家被要求杀死其他玩家，然后存活的玩家们进行自然语言讨论并投票 banish 一名玩家。</li>
<li>results: 作者们发现，使用更高级别的模型可以更好地诱导和欺骗其他玩家，使得杀害者更容易逃脱。这种改善不是通过不同的行动，而是通过更强的游说技巧来实现。<details>
<summary>Abstract</summary>
Are current language models capable of deception and lie detection? We study this question by introducing a text-based game called $\textit{Hoodwinked}$, inspired by Mafia and Among Us. Players are locked in a house and must find a key to escape, but one player is tasked with killing the others. Each time a murder is committed, the surviving players have a natural language discussion then vote to banish one player from the game. We conduct experiments with agents controlled by GPT-3, GPT-3.5, and GPT-4 and find evidence of deception and lie detection capabilities. The killer often denies their crime and accuses others, leading to measurable effects on voting outcomes. More advanced models are more effective killers, outperforming smaller models in 18 of 24 pairwise comparisons. Secondary metrics provide evidence that this improvement is not mediated by different actions, but rather by stronger persuasive skills during discussions. To evaluate the ability of AI agents to deceive humans, we make this game publicly available at h https://hoodwinked.ai/ .
</details>
<details>
<summary>摘要</summary>
现有语言模型有能力进行诱导和欺骗吗？我们通过一款基于文本的游戏——《骗子》来研究这个问题。玩家被锁在一个房子里，需要找到逃脱的钥匙，但有一名玩家被指定为杀害其他玩家。每次杀人时，存活的玩家们会进行自然语言的讨论，然后投票 banish 一名玩家。我们在 GPT-3、GPT-3.5 和 GPT-4 控制的机器人上进行了实验，发现了诱导和欺骗的能力。凶手常否认自己的罪行，指责其他人，导致讨论结果有显著的变化。更高级的模型在18/24对比中胜过小型模型。 auxiliary 指标表明这些改进不是通过不同的行动，而是通过更强的说服技巧在讨论中。为了评估人工智能代理人能否欺骗人类，我们将这款游戏公开发布在 hhttps://hoodwinked.ai/ 。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Continual-Learning-for-Code-Generation-Models"><a href="#Exploring-Continual-Learning-for-Code-Generation-Models" class="headerlink" title="Exploring Continual Learning for Code Generation Models"></a>Exploring Continual Learning for Code Generation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02435">http://arxiv.org/abs/2307.02435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Yadav, Qing Sun, Hantian Ding, Xiaopeng Li, Dejiao Zhang, Ming Tan, Xiaofei Ma, Parminder Bhatia, Ramesh Nallapati, Murali Krishna Ramanathan, Mohit Bansal, Bing Xiang</li>
<li>for: This paper focuses on the task of Continual Learning (CL) in the code domain, specifically addressing the issue of catastrophic forgetting in popular CL techniques when applied to coding tasks.</li>
<li>methods: The authors introduce a new benchmark called CodeTask-CL that covers a wide range of tasks and input&#x2F;output programming languages, and compare popular CL techniques from NLP and Vision domains. They also propose a new method called Prompt Pooling with Teacher Forcing (PP-TF) to address the issue of catastrophic forgetting.</li>
<li>results: The authors achieve a 21.54% improvement over Prompt Pooling with their proposed method PP-TF, demonstrating the effectiveness of their approach in stabilizing training and improving performance on CL for code models.Here’s the simplified Chinese text in the format you requested:</li>
<li>for: 这篇论文关注代码领域内的连续学习（Continual Learning，CL）任务，特别是应用于编程任务时popular CL技术的快速忘记问题。</li>
<li>methods: 作者们提出了一个新的benchmark代码Task-CL，覆盖了广泛的任务和输入&#x2F;输出编程语言，并对NLP和视觉领域的CL技术进行比较。他们还提出了一种新的方法called Prompt Pooling with Teacher Forcing (PP-TF)，以稳定训练并提高代码模型的CL性能。</li>
<li>results: 作者们通过PP-TF方法实现了21.54%的提升，证明了他们的方法可以稳定训练并提高代码模型的CL性能。<details>
<summary>Abstract</summary>
Large-scale code generation models such as Codex and CodeT5 have achieved impressive performance. However, libraries are upgraded or deprecated very frequently and re-training large-scale language models is computationally expensive. Therefore, Continual Learning (CL) is an important aspect that remains underexplored in the code domain. In this paper, we introduce a benchmark called CodeTask-CL that covers a wide range of tasks, including code generation, translation, summarization, and refinement, with different input and output programming languages. Next, on our CodeTask-CL benchmark, we compare popular CL techniques from NLP and Vision domains. We find that effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks. We address this issue with our proposed method, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training by enforcing constraints on the prompt selection mechanism and leads to a 21.54% improvement over Prompt Pooling. Along with the benchmark, we establish a training pipeline that can be used for CL on code models, which we believe can motivate further development of CL methods for code models. Our code is available at https://github.com/amazon-science/codetaskcl-pptf
</details>
<details>
<summary>摘要</summary>
大规模的代码生成模型如Codex和CodeT5已经实现了印象所能的性能。然而，库被升级或弃用非常频繁，再次训练大规模的语言模型是计算成本高昂。因此，持续学习（Continual Learning，CL）在代码领域是一个重要的问题，尚未得到充分研究。在这篇论文中，我们介绍了一个名为CodeTask-CL的benchmark，该benchmark涵盖了各种任务，包括代码生成、翻译、概要和修订，输入和输出编程语言也有多种。接着，在我们的CodeTask-CL benchmark上，我们比较了NLP和Computer Vision领域的流行CL技术。我们发现，效果良好的方法Like Prompt Pooling（PP）受到代码任务中的分布Shift导致的训练不稳定，从而导致了悬崖效应。我们解决这个问题的方法是Prompt Pooling with Teacher Forcing（PP-TF），该方法在选择提示机制中强制实施约束，使训练更加稳定，并导致了21.54%的提高。此外，我们还设立了一个用于CL的训练管道，我们认为这可以鼓励进一步的CL方法开发。代码可以在https://github.com/amazon-science/codetaskcl-pptf上获取。
</details></li>
</ul>
<hr>
<h2 id="Won’t-Get-Fooled-Again-Answering-Questions-with-False-Premises"><a href="#Won’t-Get-Fooled-Again-Answering-Questions-with-False-Premises" class="headerlink" title="Won’t Get Fooled Again: Answering Questions with False Premises"></a>Won’t Get Fooled Again: Answering Questions with False Premises</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.02394">http://arxiv.org/abs/2307.02394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thunlp/falseqa">https://github.com/thunlp/falseqa</a></li>
<li>paper_authors: Shengding Hu, Yifan Luo, Huadong Wang, Xingyi Cheng, Zhiyuan Liu, Maosong Sun</li>
<li>for: 这篇论文的目的是探讨语言模型（PLMs）在问答系统中的应用，特别是对于 tricky questions 的应对。</li>
<li>methods: 这篇论文使用了 false premises questions（FPQs）来检验 PLMs 的能力，并对 PLMs 进行 fine-tuning 和重复训练来提高其对 FPQs 的回答能力。</li>
<li>results: 研究发现，PLMs 可以通过 fine-tuning 和重复训练来扩大其对 FPQs 的回答能力，并且可以生成有理解性的回答和讲解。这些结果表明，PLMs 已经具有了对 tricky questions 的回答能力，只是需要刺激这种能力。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have shown unprecedented potential in various fields, especially as the backbones for question-answering (QA) systems. However, they tend to be easily deceived by tricky questions such as "How many eyes does the sun have?". Such frailties of PLMs often allude to the lack of knowledge within them. In this paper, we find that the PLMs already possess the knowledge required to rebut such questions, and the key is how to activate the knowledge. To systematize this observation, we investigate the PLMs' responses to one kind of tricky questions, i.e., the false premises questions (FPQs). We annotate a FalseQA dataset containing 2365 human-written FPQs, with the corresponding explanations for the false premises and the revised true premise questions. Using FalseQA, we discover that PLMs are capable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256) of examples. PLMs also generate reasonable explanations for the false premise, which serve as rebuttals. Further replaying a few general questions during training allows PLMs to excel on FPQs and general questions simultaneously. Our work suggests that once the rebuttal ability is stimulated, knowledge inside the PLMs can be effectively utilized to handle FPQs, which incentivizes the research on PLM-based QA systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/06/cs.CL_2023_07_06/" data-id="clogyj8vu006p7craajem7gpm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/78/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/77/">77</a><a class="page-number" href="/page/78/">78</a><span class="page-number current">79</span><a class="page-number" href="/page/80/">80</a><a class="page-number" href="/page/81/">81</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/80/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
