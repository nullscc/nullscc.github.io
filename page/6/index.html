
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/6/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.SP_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/eess.SP_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T08:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/eess.SP_2023_11_14/">eess.SP - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Choosing-Outdated-Information-to-Achieve-Reliability-in-Age-Based-Gossiping"><a href="#Choosing-Outdated-Information-to-Achieve-Reliability-in-Age-Based-Gossiping" class="headerlink" title="Choosing Outdated Information to Achieve Reliability in Age-Based Gossiping"></a>Choosing Outdated Information to Achieve Reliability in Age-Based Gossiping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08383">http://arxiv.org/abs/2311.08383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Priyanka Kaswan, Sennur Ulukus</li>
<li>for: 这篇论文旨在研究一个年龄分布式谣言网络中，两个来源（可靠源和不可靠源）如何传递处理过程的更新信息，以及Nodes如何选择信息来源并维护信息的新鲜度。</li>
<li>methods: 这篇论文使用了Stochastic Hybrid System（SHS）框架，形成了数学方程来描述网络节点中含有不可靠包和版本年龄的情况。</li>
<li>results: 研究发现，尽管增加G值可以减少网络节点中含有不可靠包的比例，但是这些包的版本年龄增加，从而导致了新鲜度-可靠性贸易offs。数据支持这些发现。<details>
<summary>Abstract</summary>
We consider a system model with two sources, a reliable source and an unreliable source, who are responsible for disseminating updates regarding a process to an age-based gossip network of $n$ nodes. Nodes wish to have fresh information, however, they have preference for packets that originated at the reliable source and are willing to sacrifice their version age of information by up to $G$ versions to switch from an unreliable packet to a reliable packet. We study how this protocol impacts the prevalence of unreliable packets at nodes in the network and their version age. Using a stochastic hybrid system (SHS) framework, we formulate analytical equations to characterize two quantities: expected fraction of nodes with unreliable packets and expected version age of information at network nodes. We show that as $G$ increases, fewer nodes have unreliable packet, however, their version age increases as well, thereby inducing a freshness-reliability trade-off in the network. We present numerical results to support our findings.
</details>
<details>
<summary>摘要</summary>
我们考虑一个系统模型，其包含两个源，一个可靠的源和一个不可靠的源，他们负责将进程更新传递给一个年龄基于谣言网络中的 $n$ 个节点。节点希望有最新的信息，但他们偏好来自可靠源的包，并愿意为了更换到可靠包而丢弃自己的版本年龄信息，最多为 $G$ 个版本。我们研究这种协议如何影响网络节点上带有不可靠包的普遍性和版本年龄。使用随机混合系统（SHS）框架，我们编写了分析方程来描述两个量：网络节点上带有不可靠包的预期总数和网络节点上的版本年龄预期值。我们发现，当 $G$ 增加时，网络节点上带有不可靠包的数量减少，但这些包的版本年龄也增加，从而导致了一种新鲜度-可靠性贸易。我们提供数据支持我们的发现。
</details></li>
</ul>
<hr>
<h2 id="Comparison-of-model-selection-techniques-for-seafloor-scattering-statistics"><a href="#Comparison-of-model-selection-techniques-for-seafloor-scattering-statistics" class="headerlink" title="Comparison of model selection techniques for seafloor scattering statistics"></a>Comparison of model selection techniques for seafloor scattering statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08337">http://arxiv.org/abs/2311.08337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek R Olson, Marc Geilhufe</li>
<li>for: 本研究旨在开发一种数据驱动的方法来选择折射环境中像素强度分布的统计模型，以优化遥感数据的分析。</li>
<li>methods: 该研究使用了一种混合分布模型，并通过对不同数据驱动的模型选择进行比较，以选择最佳的模型。</li>
<li>results: 研究发现，使用数据驱动的方法可以更好地选择折射环境中像Pixel强度分布的统计模型，并且可以减少人类的干预。<details>
<summary>Abstract</summary>
In quantitative analysis of seafloor imagery, it is common to model the collection of individual pixel intensities scattered by the seafloor as a random variable with a given statistical distribution. There is a considerable literature on statistical models for seafloor scattering, mostly focused on areas with statistically homogeneous properties (i.e. exhibiting spatial stationarity). For more complex seafloors, the pixel intensity distribution is more appropriately modeled using a mixture of simple distributions. For very complex seafloors, fitting 3 or more mixture components makes physical sense, but the statistical model becomes much more complex in these cases. Therefore, picking the number of components of the mixture model is a decision that must be made, using a priori information, or using a data driven approach. However, this information is time consuming to collect, and depends on the skill and experience of the human. Therefore, a data-driven approach is advantageous to use, and is explored in this work. Criteria for choosing a model always need to balance the trade-off for the best fit for the data on the one hand and the model complexity on the other hand. In this work, we compare several statistical model selection criteria, e.g., the Bayesian information criterion. Examples are given for SAS data collected by an autonomous underwater vehicle in a rocky environment off the coast of Bergen, Norway using data from the HISAS-1032 synthetic aperture sonar system.
</details>
<details>
<summary>摘要</summary>
在海底图像量化分析中，常将每个像素强度散射到海底模型为随机变量，采用给定的统计分布。关于海底散射的统计模型有很大的文献，主要集中在统计homogeneous（即空间站ARY）的海底上。对于更复杂的海底，则更有理由使用多个简单分布的混合模型。对于非常复杂的海底，使用3个或更多的混合组件是物理意义上的，但统计模型在这些情况下变得非常复杂。因此，选择混合模型的组件数量是一个需要基于先验知识或数据驱动的决策。然而，收集这些信息的时间很长，取决于人员的技能和经验。因此，使用数据驱动的方法更有利，并在这种工作中进行了研究。选择模型的标准要求平衡数据最佳适应和模型复杂度之间的折衔。在这种工作中，我们比较了多种统计模型选择标准，例如 bayesian信息 критерион。使用SAS数据 collected by an autonomous underwater vehicle在挪威Bergen coast rocky environment中，使用HISAS-1032 synthetic aperture sonar系统的数据作为示例。
</details></li>
</ul>
<hr>
<h2 id="Protecting-the-Future-of-Information-LOCO-Coding-With-Error-Detection-for-DNA-Data-Storage"><a href="#Protecting-the-Future-of-Information-LOCO-Coding-With-Error-Detection-for-DNA-Data-Storage" class="headerlink" title="Protecting the Future of Information: LOCO Coding With Error Detection for DNA Data Storage"></a>Protecting the Future of Information: LOCO Coding With Error Detection for DNA Data Storage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08325">http://arxiv.org/abs/2311.08325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Canberk İrimağzı, Yusuf Uslan, Ahmed Hareedy</li>
<li>for: 本文研究了使用新引入的 lexicographically-ordered constrained（LOCO）码在 DNA 数据存储中。</li>
<li>methods: 本文提出了基于 ${A,T,G,C}$ 字母的 DNA LOCO（D-LOCO）码，并提供了编码-解码规则。这些规则提供了可靠的编码-解码算法，并且可以轻松地重新配置。</li>
<li>results: 本文的编码-解码算法比现有Literature中的算法更有效，并且可以实现高率的 DNA 数据存储。此外，本文还提出了四种方案来连接 consecutive codewords，其中三种方案可以确定单个替换错误检测每个 codeword。<details>
<summary>Abstract</summary>
DNA strands serve as a storage medium for $4$-ary data over the alphabet $\{A,T,G,C\}$. DNA data storage promises formidable information density, long-term durability, and ease of replicability. However, information in this intriguing storage technology might be corrupted. Experiments have revealed that DNA sequences with long homopolymers and/or with low $GC$-content are notably more subject to errors upon storage.   This paper investigates the utilization of the recently-introduced method for designing lexicographically-ordered constrained (LOCO) codes in DNA data storage. This paper introduces DNA LOCO (D-LOCO) codes, over the alphabet $\{A,T,G,C\}$ with limited runs of identical symbols. These codes come with an encoding-decoding rule we derive, which provides affordable encoding-decoding algorithms. In terms of storage overhead, the proposed encoding-decoding algorithms outperform those in the existing literature. Our algorithms are readily reconfigurable. D-LOCO codes are intrinsically balanced, which allows us to achieve balancing over the entire DNA strand with minimal rate penalty. Moreover, we propose four schemes to bridge consecutive codewords, three of which guarantee single substitution error detection per codeword. We examine the probability of undetecting errors. We also show that D-LOCO codes are capacity-achieving and that they offer remarkably high rates at moderate lengths.
</details>
<details>
<summary>摘要</summary>
This paper investigates the utilization of the recently-introduced method for designing lexicographically-ordered constrained (LOCO) codes in DNA data storage. This paper introduces DNA LOCO (D-LOCO) codes, over the alphabet $\{\mathtt{A}, \mathtt{T}, \mathtt{G}, \mathtt{C}\}$ with limited runs of identical symbols. These codes come with an encoding-decoding rule we derive, which provides affordable encoding-decoding algorithms. In terms of storage overhead, the proposed encoding-decoding algorithms outperform those in the existing literature. Our algorithms are readily reconfigurable. D-LOCO codes are intrinsically balanced, which allows us to achieve balancing over the entire DNA strand with minimal rate penalty. Moreover, we propose four schemes to bridge consecutive codewords, three of which guarantee single substitution error detection per codeword. We examine the probability of undetecting errors. We also show that D-LOCO codes are capacity-achieving and that they offer remarkably high rates at moderate lengths.
</details></li>
</ul>
<hr>
<h2 id="Resource-Efficient-Over-the-Air-Fronthaul-Signaling-for-Uplink-Cell-Free-Massive-MIMO-Systems"><a href="#Resource-Efficient-Over-the-Air-Fronthaul-Signaling-for-Uplink-Cell-Free-Massive-MIMO-Systems" class="headerlink" title="Resource Efficient Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems"></a>Resource Efficient Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08319">http://arxiv.org/abs/2311.08319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zakir Hussain Shaik, Sai Subramanyam Thoota, Emil Björnson, Erik G. Larsson</li>
<li>for:  addresses the demanding requirements of uplink (UL) fronthaul in cell-free massive multiple-input multiple-output (MIMO) systems.</li>
<li>methods:  proposes a novel resource efficient analog over-the-air (OTA) computation framework, including transmit precoding and two-phase power assignment strategies at the access points (APs).</li>
<li>results:  derives analytical expressions for the Bayesian and classical estimators of the OTA combined signals, and empirically evaluates the normalized mean square error (NMSE), symbol error rate (SER), and coded bit error rate (BER) of the developed solution, showing that it outperforms the state-of-the-art wired fronthaul based system.<details>
<summary>Abstract</summary>
We propose a novel resource efficient analog over-the-air (OTA) computation framework to address the demanding requirements of the uplink (UL) fronthaul between the access points (APs) and the central processing unit (CPU) in cell-free massive multiple-input multiple-output (MIMO) systems. We discuss the drawbacks of the wired and wireless fronthaul solutions, and show that our proposed mechanism is efficient and scalable as the number of APs increases. We present the transmit precoding and two-phase power assignment strategies at the APs to coherently combine the signals OTA in a spectrally efficient manner. We derive the statistics of the APs locally available signals which enable us to to obtain the analytical expressions for the Bayesian and classical estimators of the OTA combined signals. We empirically evaluate the normalized mean square error (NMSE), symbol error rate (SER), and the coded bit error rate (BER) of our developed solution and benchmark against the state-of-the-art wired fronthaul based system
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的资源有效的无线上空计算框架，以满足Cell-free巨量多输入多输出系统的上行（UL）前方向的需求。我们讨论了有线和无线前方向解决方案的缺点，并显示了我们的提议机制具有规模可扩展的优点。我们介绍了在AP上进行预编码和两相电压分配策略，以具有spectral efficiency的方式将OTA信号相乘。我们 derivation了AP上可用信号的统计，允许我们获得OTA相乘后的分布统计。我们Empirically评估了NMSE、SER和BER表现，并与现有的有线前方向基础系统进行比较。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Maximum-Eigenvalue-Detection-based-Spectrum-Sensing-in-RIS-aided-System-with-Correlated-Fading"><a href="#Maximum-Eigenvalue-Detection-based-Spectrum-Sensing-in-RIS-aided-System-with-Correlated-Fading" class="headerlink" title="Maximum Eigenvalue Detection based Spectrum Sensing in RIS-aided System with Correlated Fading"></a>Maximum Eigenvalue Detection based Spectrum Sensing in RIS-aided System with Correlated Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08296">http://arxiv.org/abs/2311.08296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhilsingh Parihar, Praful D. Mankar, Sachin Chaudhari</li>
<li>for: 本研究旨在提高受信息干扰的spectrum sensing表现，尤其是在多path fading和噪声相关的场景下。</li>
<li>methods: 本文提出了使用可编程智能面(RIS)来提高spectrum sensing表现。特别是利用 espacially correlated fading，我们提议使用最大特征值检测(MED)进行spectrum sensing。</li>
<li>results: 我们 derivated了测试统计量的正态分布 under null和signal present假设下。然后，我们使用这些结果计算了假设检测的false alarm和 detection probabilities。此外，我们还优化了RIS的相位旋转矩阵，以提高检测性能。我们的numerical analysis表明，MED的接收操作特征曲线在RIS元素增加、SNR提高和 statistically optimal配置RIS的情况下都得到提高。<details>
<summary>Abstract</summary>
Robust spectrum sensing is crucial for facilitating opportunistic spectrum utilization for secondary users (SU) in the absense of primary users (PU). However, propagation environment factors such as multi-path fading, shadowing, and lack of line of sight (LoS) often adversely affect detection performance. To deal with these issues, this paper focuses on utilizing reconfigurable intelligent surfaces (RIS) to improve spectrum sensing in the scenario wherein both the multi-path fading and noise are correlated. In particular, to leverage the spatially correlated fading, we propose to use maximum eigenvalue detection (MED) for spectrum sensing. We first derive exact distributions of test statistics, i.e., the largest eigenvalue of the sample covariance matrix, observed under the null and signal present hypothesis. Next, utilizing these results, we present the exact closed-form expressions for the false alarm and detection probabilities. In addition, we also optimally configure the phase shift matrix of RIS such that the mean of the test statistics is maximized, thus improving the detection performance. Our numerical analysis demonstrates that the MED's receiving operating characteristic (ROC) curve improves with increased RIS elements, SNR, and the utilization of statistically optimal configured RIS.
</details>
<details>
<summary>摘要</summary>
Robust spectrum sensing 是次级用户（SU）在主要用户（PU）缺 absent 的情况下促进机会性spectrum utilization的关键。然而，传播环境因素 such as 多 PATH 抑制、阴影和无线线 sight（LoS） frequently adversely affect detection performance. To address these issues, this paper focuses on using reconfigurable intelligent surfaces (RIS) to improve spectrum sensing in the scenario where both multi-path fading and noise are correlated. In particular, we propose to use maximum eigenvalue detection (MED) for spectrum sensing. We first derive the exact distributions of test statistics, i.e., the largest eigenvalue of the sample covariance matrix, observed under the null and signal present hypotheses. Next, we use these results to present the exact closed-form expressions for the false alarm and detection probabilities. Additionally, we optimize the phase shift matrix of RIS such that the mean of the test statistics is maximized, thus improving detection performance. Our numerical analysis shows that the MED's receiving operating characteristic (ROC) curve improves with increased RIS elements, SNR, and the utilization of statistically optimal configured RIS.Note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Joint-Location-Sensing-and-Channel-Estimation-for-IRS-Aided-mmWave-ISAC-Systems"><a href="#Joint-Location-Sensing-and-Channel-Estimation-for-IRS-Aided-mmWave-ISAC-Systems" class="headerlink" title="Joint Location Sensing and Channel Estimation for IRS-Aided mmWave ISAC Systems"></a>Joint Location Sensing and Channel Estimation for IRS-Aided mmWave ISAC Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08201">http://arxiv.org/abs/2311.08201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Chen, Ming-Min Zhao, Min Li, Fan Xu, Qingqing Wu, Min-Jian Zhao</li>
<li>for: 本研究 investigate a self-sensing intelligent reflecting surface (IRS) aided millimeter wave (mmWave) integrated sensing and communication (ISAC) system, aiming to jointly sense the target&#x2F;scatterer&#x2F;user positions and estimate the sensing and communication (SAC) channels.</li>
<li>methods: 提议 a two-phase transmission scheme, where the coarse and refined sensing&#x2F;channel estimation (CE) results are respectively obtained in the first phase using scanning-based IRS reflection coefficients and the second phase using optimized IRS reflection coefficients. The proposed algorithm combines VBI, messaging passing, and expectation-maximization (EM) methods to solve the considered joint location sensing and CE problem, exploiting the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels.</li>
<li>results:  simulation results show the superiority of the proposed transmission scheme and associated algorithms, verifying the effectiveness of the self-sensing IRS in reducing the path loss of sensing-related links and enhancing the overall performance of the ISAC system.<details>
<summary>Abstract</summary>
In this paper, we investigate a self-sensing intelligent reflecting surface (IRS) aided millimeter wave (mmWave) integrated sensing and communication (ISAC) system. Unlike the conventional purely passive IRS, the self-sensing IRS can effectively reduce the path loss of sensing-related links, thus rendering it advantageous in ISAC systems. Aiming to jointly sense the target/scatterer/user positions as well as estimate the sensing and communication (SAC) channels in the considered system, we propose a two-phase transmission scheme, where the coarse and refined sensing/channel estimation (CE) results are respectively obtained in the first phase (using scanning-based IRS reflection coefficients) and second phase (using optimized IRS reflection coefficients). For each phase, an angle-based sensing turbo variational Bayesian inference (AS-TVBI) algorithm, which combines the VBI, messaging passing and expectation-maximization (EM) methods, is developed to solve the considered joint location sensing and CE problem. The proposed algorithm effectively exploits the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels to enhance the overall performance. Based on the estimation results from the first phase, we formulate a Cram\'{e}r-Rao bound (CRB) minimization problem for optimizing IRS reflection coefficients, and through proper reformulations, a low-complexity manifold-based optimization algorithm is proposed to solve this problem. Simulation results are provided to verify the superiority of the proposed transmission scheme and associated algorithms.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一种自适应智能反射表面（IRS）帮助毫米波（mmWave）集成感知通信（ISAC）系统。与传统的仅PASSIVE IRS不同，自适应IRS可以有效减少感知相关链路的覆盖距离，从而在ISAC系统中具有优势。为了同时感知目标/散射体/用户位置以及估计感知通信（SAC） канала，我们提议了两个阶段的传输方案，其中第一阶段使用扫描基于IRS反射率来获得粗略的感知频道估计结果，第二阶段使用优化IRS反射率来获得精度的感知频道估计结果。 For each phase, an angle-based sensing turbo variational Bayesian inference (AS-TVBI) algorithm, which combines the VBI, messaging passing and expectation-maximization (EM) methods, is developed to solve the considered joint location sensing and CE problem. The proposed algorithm effectively exploits the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels to enhance the overall performance. Based on the estimation results from the first phase, we formulate a Cramér-Rao bound (CRB) minimization problem for optimizing IRS reflection coefficients, and through proper reformulations, a low-complexity manifold-based optimization algorithm is proposed to solve this problem. Simulation results are provided to verify the superiority of the proposed transmission scheme and associated algorithms.
</details></li>
</ul>
<hr>
<h2 id="Fast-List-Decoding-of-High-Rate-Polar-Codes"><a href="#Fast-List-Decoding-of-High-Rate-Polar-Codes" class="headerlink" title="Fast List Decoding of High-Rate Polar Codes"></a>Fast List Decoding of High-Rate Polar Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08188">http://arxiv.org/abs/2311.08188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Lu, Ming-Min Zhao, Ming Lei, Min-Jian Zhao</li>
<li>for: 这个论文的目的是提高短至中等长度楔码的快速解码性能，尤其是在低延迟通信场景中。</li>
<li>methods: 本论文使用了特定楔码子代码（special nodes）的快速列解算法，包括单元检查（SPC）节点和一个或多个单元检查（SR1&#x2F;SPC）节点。具体来说，本论文提出了两种快速列解算法，其中第一种使用了预序解码程式，使解码时间linear with the list size，第二种则透过在线上预决缺失路径来进一步平行化解码过程，实现更快的解码速度。</li>
<li>results:  simulations results show that the proposed list decoding algorithms are able to achieve up to 70.7% lower decoding latency than state-of-the-art fast SCL decoders, while exhibiting the same error-correction performance.<details>
<summary>Abstract</summary>
Due to the ability to provide superior error-correction performance, the successive cancellation list (SCL) algorithm is widely regarded as one of the most promising decoding algorithms for polar codes with short-to-moderate code lengths. However, the application of SCL decoding in low-latency communication scenarios is limited due to its sequential nature. To reduce the decoding latency, developing tailored fast and efficient list decoding algorithms of specific polar substituent codes (special nodes) is a promising solution. Recently, fast list decoding algorithms are proposed by considering special nodes with low code rates. Aiming to further speedup the SCL decoding, this paper presents fast list decoding algorithms for two types of high-rate special nodes, namely single-parity-check (SPC) nodes and sequence rate one or single-parity-check (SR1/SPC) nodes. In particular, we develop two classes of fast list decoding algorithms for these nodes, where the first class uses a sequential decoding procedure to yield decoding latency that is linear with the list size, and the second further parallelizes the decoding process by pre-determining the redundant candidate paths offline. Simulation results show that the proposed list decoding algorithms are able to achieve up to 70.7\% lower decoding latency than state-of-the-art fast SCL decoders, while exhibiting the same error-correction performance.
</details>
<details>
<summary>摘要</summary>
由于可提供出色的错误纠正性表现，连续取消列表（SCL）算法在短至中型编码长度的楔码中广泛被视为一种最有前途的解码算法。然而，在低延迟通信场景中，SCL解码的应用受到其顺序性的限制。为了降低解码延迟，开发专门为特定楔substituent代码（特定节点）设计快速高效的列解算法是一个有前途的解决方案。在最近，为了提高SCL解码的速度，这篇论文提出了两种类型的高速列解算法，即单元性检查（SPC）节点和序列率一（SR1/SPC）节点。具体来说，我们开发了两类快速列解算法，其中第一类使用顺序解码过程，使解码延迟线性增长与列表大小相关；第二类进一步平行化解码过程，通过先行确定冗余候选道路来提高速度。实验结果表明，提议的列解算法可以与当前最速的SCL解码器相比，实现70.7%的解码延迟降低，同时保持同等的错误纠正性表现。
</details></li>
</ul>
<hr>
<h2 id="Channel-Estimation-with-Dynamic-Metasurface-Antennas-via-Model-Based-Learning"><a href="#Channel-Estimation-with-Dynamic-Metasurface-Antennas-via-Model-Based-Learning" class="headerlink" title="Channel Estimation with Dynamic Metasurface Antennas via Model-Based Learning"></a>Channel Estimation with Dynamic Metasurface Antennas via Model-Based Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08158">http://arxiv.org/abs/2311.08158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Zhang, Haiyang Zhang, Luxi Yang, Yonina C. Eldar<br>for:This paper proposes two model-based learning methods to overcome the challenge of channel estimation in multiple input multiple output (MIMO) communication systems using dynamic metasurface antennas (DMAs).methods:The proposed methods use a combination of random DMA weighting matrices and spatial gridding dictionaries to form the sensing matrix, and employ the learned iterative shrinkage and thresholding algorithm (LISTA) to recover the sparse channel parameters. Additionally, a self-supervised learning technique is proposed to tackle the difficulty of acquiring noise-free data.results:The proposed methods demonstrate better channel accuracy than traditional sparse recovery methods and the sensing matrix optimization technique achieves better channel accuracy than the baseline method.<details>
<summary>Abstract</summary>
Dynamic Metasurface Antenna (DMA) is a cutting-edge antenna technology offering scalable and sustainable solutions for large antenna arrays. The effectiveness of DMAs stems from their inherent configurable analog signal processing capabilities, which facilitate cost-limited implementations. However, when DMAs are used in multiple input multiple output (MIMO) communication systems, they pose challenges in channel estimation due to their analog compression. In this paper, we propose two model-based learning methods to overcome this challenge. Our approach starts by casting channel estimation as a compressed sensing problem. Here, the sensing matrix is formed using a random DMA weighting matrix combined with a spatial gridding dictionary. We then employ the learned iterative shrinkage and thresholding algorithm (LISTA) to recover the sparse channel parameters. LISTA unfolds the iterative shrinkage and thresholding algorithm into a neural network and trains the neural network into a highly efficient channel estimator fitting with the previous channel. As the sensing matrix is crucial to the accuracy of LISTA recovery, we introduce another data-aided method, LISTA-sensing matrix optimization (LISTA-SMO), to jointly optimize the sensing matrix. LISTA-SMO takes LISTA as a backbone and embeds the sensing matrix optimization layers in LISTA's neural network, allowing for the optimization of the sensing matrix along with the training of LISTA. Furthermore, we propose a self-supervised learning technique to tackle the difficulty of acquiring noise-free data. Our numerical results demonstrate that LISTA outperforms traditional sparse recovery methods regarding channel estimation accuracy and efficiency. Besides, LISTA-SMO achieves better channel accuracy than LISTA, demonstrating the effectiveness in optimizing the sensing matrix.
</details>
<details>
<summary>摘要</summary>
dynamically metasurface antenna (DMA) 是一种前沿的天线技术，具有可扩展和可持续的解决方案。 DMA 的可 configurable 分析信号处理能力使其在成本限制下实现高效性。 然而，在多输入多输出 (MIMO) 通信系统中使用 DMA 会带来频道估计的挑战，因为 DMA 的分析压缩会导致频道估计困难。在这篇论文中，我们提出了两种基于模型学习方法来解决这个挑战。我们的方法是将频道估计视为压缩感知问题，其中感知矩阵由随机 DMA 质量矩阵和空间格点词典组成。然后，我们使用学习舒缩和阈值算法 (LISTA) 来恢复稀疏频道参数。LISTA 将舒缩和阈值算法拓展成神经网络，并在神经网络中培训一个高效的频道估计器，与之前的频道相符。在感知矩阵对于 LISTA 的准确性很重要，我们因此引入了另一种数据帮助的方法，即 LISTA-感知矩阵优化 (LISTA-SMO)。LISTA-SMO 将 LISTA 作为后备，并将感知矩阵优化层 embedding 在 LISTA 神经网络中，以同时优化感知矩阵和 LISTA 的训练。此外，我们还提出了一种无supervision learning技术，以解决获取干净数据的困难。我们的数字结果表明，LISTA 比传统稀疏恢复方法更高效和准确地进行频道估计。此外，LISTA-SMO 在频道准确性方面比 LISTA 高，证明了感知矩阵优化的效果。
</details></li>
</ul>
<hr>
<h2 id="Joint-Source-Channel-Coding-for-Channel-Adaptive-Digital-Semantic-Communications"><a href="#Joint-Source-Channel-Coding-for-Channel-Adaptive-Digital-Semantic-Communications" class="headerlink" title="Joint Source-Channel Coding for Channel-Adaptive Digital Semantic Communications"></a>Joint Source-Channel Coding for Channel-Adaptive Digital Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08146">http://arxiv.org/abs/2311.08146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joohyuk Park, Yongjeong Oh, Seonjung Kim, Yo-Seb Jeon</li>
<li>for: 这个论文旨在提出一种 JOINT SOURCE-CHANNEL CODING (JSCC) 方法，用于适应通道的数位 semantics 通信系统中。</li>
<li>methods: 这个方法使用了一种新的检测方法来改善数位semantics通信系统中的稳定性，并开发了一种可靠的终端训练策略，以提高 JSCC 编码器和解oder 的可靠性和灵活性。</li>
<li>results: 这个方法在实验中被证明可以对数位图像分类和重建任务进行改进，比较现有的 JSCC 方法表现更好。<details>
<summary>Abstract</summary>
In this paper, we propose a novel joint source-channel coding (JSCC) approach for channel-adaptive digital semantic communications. In semantic communication systems with digital modulation and demodulation, end-to-end training and robust design of JSCC encoder and decoder becomes challenging due to the nonlinearity of modulation and demodulation processes, as well as diverse channel conditions and modulation orders. To address this challenge, we first develop a new demodulation method which assesses the uncertainty of the demodulation output to improve the robustness of the digital semantic communication system. We then devise a robust training strategy that facilitates end-to-end training of the JSCC encoder and decoder, while enhancing their robustness and flexibility. To this end, we model the relationship between the encoder's output and decoder's input using binary symmetric erasure channels and then sample the parameters of these channels from diverse distributions. We also develop a channel-adaptive modulation technique for an inference phase, in order to reduce the communication latency while maintaining task performance. In this technique, we adaptively determine modulation orders for the latent variables based on channel conditions. Using simulations, we demonstrate the superior performance of the proposed JSCC approach for both image classification and reconstruction tasks compared to existing JSCC approaches.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的联合源码混合（JSCC）方法，用于适应通道condition下的数字semantic通信系统。在数字模ulation和демодуляción中，因为模ulation和демодуляción过程的非线性，以及不同通道条件和模ulationOrder，所以JSCC编码器和解码器的端到端训练和稳定设计变得挑战性更高。为 Addressing this challenge, we first develop a new demodulation method that assesses the uncertainty of the demodulation output to improve the robustness of the digital semantic communication system. We then devise a robust training strategy that facilitates end-to-end training of the JSCC encoder and decoder, while enhancing their robustness and flexibility. To this end, we model the relationship between the encoder's output and decoder's input using binary symmetric erasure channels, and then sample the parameters of these channels from diverse distributions. We also develop a channel-adaptive modulation technique for an inference phase, in order to reduce the communication latency while maintaining task performance. In this technique, we adaptively determine modulation orders for the latent variables based on channel conditions. Using simulations, we demonstrate the superior performance of the proposed JSCC approach for both image classification and reconstruction tasks compared to existing JSCC approaches.
</details></li>
</ul>
<hr>
<h2 id="On-the-View-and-Channel-Aggregation-Gain-in-Integrated-Sensing-and-Edge-AI"><a href="#On-the-View-and-Channel-Aggregation-Gain-in-Integrated-Sensing-and-Edge-AI" class="headerlink" title="On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge AI"></a>On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07986">http://arxiv.org/abs/2311.07986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Chen, Khaled B. Letaief, Kaibin Huang</li>
<li>For: The paper is written to explore the fundamental performance gains of view-and-channel aggregation in Integrated sensing and edge AI (ISEA) systems for Internet-of-Things (IoT) applications.* Methods: The paper uses a well-established distribution model of multi-view sensing data, which is modified to represent individual sensor observation perspectives. The authors also use a novel approach involving a scaling-tight uncertainty surrogate function, global discriminant gain, distribution of receive Signal-to-Noise Ratio (SNR), and channel induced discriminant loss to study the End-to-End sensing (inference) uncertainty of the ISEA system.* Results: The paper shows that the End-to-End sensing uncertainty diminishes at an exponential rate as the number of views&#x2F;sensors grows, with a rate proportional to global discriminant gain. Additionally, the authors find that the exponential scaling remains even with channel distortion, but with a reduced decay rate related to the channel induced discriminant loss. The insights from the paper are validated by experiments using real-world dataset.<details>
<summary>Abstract</summary>
Sensing and edge artificial intelligence (AI) are two key features of the sixth-generation (6G) mobile networks. Their natural integration, termed Integrated sensing and edge AI (ISEA), is envisioned to automate wide-ranging Internet-of-Tings (IoT) applications. To achieve a high sensing accuracy, multi-view features are uploaded to an edge server for aggregation and inference using an AI model. The view aggregation is realized efficiently using over-the-air computing (AirComp), which also aggregates channels to suppress channel noise. At its nascent stage, ISEA still lacks a characterization of the fundamental performance gains from view-and-channel aggregation, which motivates this work. Our framework leverages a well-established distribution model of multi-view sensing data where the classic Gaussian-mixture model is modified by adding sub-spaces matrices to represent individual sensor observation perspectives. Based on the model, we study the End-to-End sensing (inference) uncertainty, a popular measure of inference accuracy, of the said ISEA system by a novel approach involving designing a scaling-tight uncertainty surrogate function, global discriminant gain, distribution of receive Signal-to-Noise Ratio (SNR), and channel induced discriminant loss. We prove that the E2E sensing uncertainty diminishes at an exponential rate as the number of views/sensors grows, where the rate is proportional to global discriminant gain. Given channel distortion, we further show that the exponential scaling remains with a reduced decay rate related to the channel induced discriminant loss. Furthermore, we benchmark AirComp against equally fast, traditional analog orthogonal access, which reveals a sensing-accuracy crossing point between the schemes, leading to the proposal of adaptive access-mode switching. Last, the insights from our framework are validated by experiments using real-world dataset.
</details>
<details>
<summary>摘要</summary>
sixth-generation (6G) 无线网络中的感知和边缘人工智能（AI）是两个关键特点。将它们天然地融合起来，称为 интеegrated sensing and edge AI（ISEA），可以自动执行广泛的互联网东西（IoT）应用。以实现高精度感知，多视图特征被上传到边缘服务器进行聚合和推理使用AI模型。视图聚合可以高效地实现使用空中计算（AirComp），同时也可以聚合通道来抑制通道噪声。在它的早期阶段，ISEA仍然缺乏对视图和通道聚合的基本性能提升的Characterization，这种 motivates this work。我们的框架利用了已有的多视图感知数据分布模型，其中类型的 Gaussian-mixture model 被修改为包含个人感知观察角度的子空间矩阵。基于模型，我们研究ISEA系统的端到端感知（推理）uncertainty，一种流行的推理准确度度量，通过一种新的扩展紧急函数、全球Discriminant gain、接收Signal-to-Noise Ratio（SNR）分布和通道引起的Discriminant loss来研究。我们证明，端到端感知uncertainty在视图/感知器数量增加时 exponentially decay，其速率与全球Discriminant gain相关。在存在通道扭曲时，我们进一步证明，扩展 decay rate 与通道引起的Discriminant loss相关。此外，我们对AirComp和传统的Analog orthogonal access进行比较，发现感知准确度 crossing point  между两种方案，导致了对接入模式的自适应 switching。最后，我们的框架的发现被实际 dataset 验证。
</details></li>
</ul>
<hr>
<h2 id="Learning-Bayes-Optimal-Channel-Estimation-for-Holographic-MIMO-in-Unknown-EM-Environments"><a href="#Learning-Bayes-Optimal-Channel-Estimation-for-Holographic-MIMO-in-Unknown-EM-Environments" class="headerlink" title="Learning Bayes-Optimal Channel Estimation for Holographic MIMO in Unknown EM Environments"></a>Learning Bayes-Optimal Channel Estimation for Holographic MIMO in Unknown EM Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07908">http://arxiv.org/abs/2311.07908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Yu, Hengtao He, Xianghao Yu, Shenghui Song, Jun Zhang, Ross D. Murch, Khaled B. Letaief</li>
<li>For: The paper is written for future 6G systems that use holographic MIMO (HMIMO) technology, which requires efficient channel estimation in arbitrary and unknown EM environments.* Methods: The paper proposes a self-supervised minimum mean-square-error (MMSE) channel estimation algorithm based on powerful machine learning tools, including score matching and principal component analysis. The training stage requires only the pilot signals, without needing to know the spatial correlation, the ground-truth channels, or the received signal-to-noise-ratio.* Results: The proposed algorithm can approach the performance of the oracle MMSE method with an extremely low complexity, making it a competitive candidate in practice.Here is the same information in Simplified Chinese:* For: 这篇论文是为未来的6G系统而写的，该系统使用束幂MIMO（HMIMO）技术，需要高效的通道估计在不知道的EM环境中。* Methods: 论文提出一种基于强大机器学习工具的自助学习最小均方差（MMSE）通道估计算法，包括分数匹配和主成分分析。训练阶段只需要各个批处理信号，不需要知道空间相关性、真实通道分布或接收信号噪声级。* Results: 提议的算法可以接近oracle MMSE方法的性能，但具有极低的复杂性，使其在实践中成为竞争力强的候选人。<details>
<summary>Abstract</summary>
Holographic MIMO (HMIMO) has recently been recognized as a promising enabler for future 6G systems through the use of an ultra-massive number of antennas in a compact space to exploit the propagation characteristics of the electromagnetic (EM) channel. Nevertheless, the promised gain of HMIMO could not be fully unleashed without an efficient means to estimate the high-dimensional channel. Bayes-optimal estimators typically necessitate either a large volume of supervised training samples or a priori knowledge of the true channel distribution, which could hardly be available in practice due to the enormous system scale and the complicated EM environments. It is thus important to design a Bayes-optimal estimator for the HMIMO channels in arbitrary and unknown EM environments, free of any supervision or priors. This work proposes a self-supervised minimum mean-square-error (MMSE) channel estimation algorithm based on powerful machine learning tools, i.e., score matching and principal component analysis. The training stage requires only the pilot signals, without knowing the spatial correlation, the ground-truth channels, or the received signal-to-noise-ratio. Simulation results will show that, even being totally self-supervised, the proposed algorithm can still approach the performance of the oracle MMSE method with an extremely low complexity, making it a competitive candidate in practice.
</details>
<details>
<summary>摘要</summary>
依 Moore 多规模 MIMO (HMIMO) 在未来的 6G 系统中被认为是一个有前途的推动者，通过在受限空间内部署ULTRA 大量天线来利用电磁频谱（EM）频道的传播特性。然而， promise 的 HMIMO 潜在优势尚未得到充分发挥，因为需要一种有效的高维度通道估计方法。 Bayes 优化的估计器通常需要大量的supervised 训练样本或者假设true 通道分布，这些样本或分布在实际中很难获得，因为系统规模很大，EM 环境复杂。因此，这种工作提议了一种基于强大机器学习工具的自主Supervised 最小二乘误差（MMSE）通道估计算法。该算法只需要启动阶段的导航信号，不需要知道空间相关性，真实通道，或接收信号噪听率。 simulation 结果表明，即使完全自主，提议的算法仍然可以接近 oracle MMSE 方法的性能，而且具有极低的复杂度，使其在实践中成为竞争力强的候选人。
</details></li>
</ul>
<hr>
<h2 id="Passive-Human-Sensing-Enhanced-by-Reconfigurable-Intelligent-Surface-Opportunities-and-Challenges"><a href="#Passive-Human-Sensing-Enhanced-by-Reconfigurable-Intelligent-Surface-Opportunities-and-Challenges" class="headerlink" title="Passive Human Sensing Enhanced by Reconfigurable Intelligent Surface: Opportunities and Challenges"></a>Passive Human Sensing Enhanced by Reconfigurable Intelligent Surface: Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07873">http://arxiv.org/abs/2311.07873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Li, Jian Wei You, Ze Gu, Qian Ma, Long Chen, Jingyuan Zhang, Shi Jin, Tie Jun Cui</li>
<li>for: 这篇论文旨在探讨通过半导体智能表面（RIS）的干预，实现无线电信号中人体活动相关信息的探测。</li>
<li>methods: 论文首先介绍了RIS的基本原理和物理平台，然后根据不同应用场景，对现状技术进行了分类，包括人像、定位和活动识别。</li>
<li>results: 论文提出了基于RIS的微动诊断系统，并通过实验证明了这种技术在检测生理指标的潜在潜力。 finally, 论文还讨论了这一领域的技术挑战和机遇。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surfaces (RISs) have flexible and exceptional performance in manipulating electromagnetic waves and customizing wireless channels. These capabilities enable them to provide a plethora of valuable activity-related information for promoting wireless human sensing. In this article, we present a comprehensive review of passive human sensing using radio frequency signals with the assistance of RISs. Specifically, we first introduce fundamental principles and physical platform of RISs. Subsequently, based on the specific applications, we categorize the state-of-the-art human sensing techniques into three types, including human imaging,localization, and activity recognition. Meanwhile, we would also investigate the benefits that RISs bring to these applications. Furthermore, we explore the application of RISs in human micro-motion sensing, and propose a vital signs monitoring system enhanced by RISs. Experimental results are presented to demonstrate the promising potential of RISs in sensing vital signs for manipulating individuals. Finally, we discuss the technical challenges and opportunities in this field.
</details>
<details>
<summary>摘要</summary>
可重配置智能表面（RIS）具有 flexible 和异常表现，可以控制电磁波和自定义无线通道。这些能力使其能提供许多有价值的活动相关信息，以便促进无线人员感知。在这篇文章中，我们提供了无线人员感知的全面回顾，特别是通过 RIS 的帮助实现的。我们首先介绍 RIS 的基本原理和物理平台。然后，根据应用场景，我们将现有的人类感知技术分为三类，包括人像、本地化和活动识别。此外，我们还 investigate RIS 在人微动感知方面的应用，并提出了基于 RIS 的生命体矢量监测系统。实验结果表明，RIS 在感知生命体矢量方面具有普遍的潜力。最后，我们讨论了这一领域的技术挑战和机遇。
</details></li>
</ul>
<hr>
<h2 id="Cost-Efficient-Computation-Offloading-and-Service-Chain-Caching-in-LEO-Satellite-Networks"><a href="#Cost-Efficient-Computation-Offloading-and-Service-Chain-Caching-in-LEO-Satellite-Networks" class="headerlink" title="Cost-Efficient Computation Offloading and Service Chain Caching in LEO Satellite Networks"></a>Cost-Efficient Computation Offloading and Service Chain Caching in LEO Satellite Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07872">http://arxiv.org/abs/2311.07872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yantong Wang, Chuanfen Feng, Jiande Sun</li>
<li>for: 这篇论文的目的是提出一个基于 mobile-edge-computing 且考虑当地网络限制的 low earth orbit 卫星网络，以提高服务质量和可用性。</li>
<li>methods: 本论文使用一种称为服务链快照和计算卸载的方法，并考虑了协力运算、网络资源限制和服务链的特定运行顺序。</li>
<li>results: 研究结果显示，该方法可以降低总成本（包括任务延迟和能源消耗）约20%，相比于传统的资料中心架构。<details>
<summary>Abstract</summary>
The ever-increasing demand for ubiquitous, continuous, and high-quality services poses a great challenge to the traditional terrestrial network. To mitigate this problem, the mobile-edge-computing-enhanced low earth orbit (LEO) satellite network, which provides both communication connectivity and on-board processing services, has emerged as an effective method. The main issue in LEO satellites includes finding the optimal locations to host network functions (NFs) and then making offloading decisions. In this article, we jointly consider the problem of service chain caching and computation offloading to minimize the overall cost, which consists of task latency and energy consumption. In particular, the collaboration among satellites, the network resource limitations, and the specific operation order of NFs in service chains are taken into account. Then, the problem is formulated and linearized as an integer linear programming model. Moreover, to accelerate the solution, we provide a greedy algorithm with cubic time complexity. Numerical investigations demonstrate the effectiveness of the proposed scheme, which can reduce the overall cost by around 20% compared to the nominal case where NFs are served in data centers.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:随着服务需求的不断增长，传统的陆地网络面临着严重的挑战。为解决这问题，低轨道卫星网络（LEO），带有通信连接和机能处理服务，已经出现为有效的解决方案。LEO卫星中的主要问题是找到最佳的NF主机位置，然后做卸载决策。在这篇文章中，我们同时考虑服务链缓存和计算卸载问题，以最小化总成本，包括任务延迟和能耗总量。具体来说，我们考虑卫星之间的协作、网络资源的限制，以及服务链中NF的具体执行顺序。然后，我们将问题形式化并Linear化为整数线性 програм序列。此外，为加速解决，我们提供了一种 cubic 时间复杂度的急速算法。数值调查表明，我们的方案可以相比nominal情况下，降低总成本约20%。
</details></li>
</ul>
<hr>
<h2 id="On-the-IRS-Deployment-in-Smart-Factories-Considering-Blockage-Effects-Collocated-or-Distributed"><a href="#On-the-IRS-Deployment-in-Smart-Factories-Considering-Blockage-Effects-Collocated-or-Distributed" class="headerlink" title="On the IRS Deployment in Smart Factories Considering Blockage Effects: Collocated or Distributed?"></a>On the IRS Deployment in Smart Factories Considering Blockage Effects: Collocated or Distributed?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07843">http://arxiv.org/abs/2311.07843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Zhang, Saeed R. Khosravirad, Xiaoli Chu, Mikko A. Uusitalo</li>
<li>for: 该研究旨在支持工厂内的增强移动广播和低延迟通信服务，通过智能反射表面（IRS）的排列和分布部署。</li>
<li>methods: 该研究使用了一个渠道模型，该模型包括每个传输路径的线视图概率和功率损失，并提出了三个纪录器，即预期的噪声比率、预期的块列长度（FB）容量和预期的失业概率，其中预期是通过内部堵塞和通道抑制的概率分布来计算。</li>
<li>results: 研究发现，对于高堵塞密度，分布部署可以提高预期接收噪声比率和预期FB容量；对于低堵塞密度，URLLC服务可以从分布部署中受益，而eMBB服务则不受分布部署的影响。<details>
<summary>Abstract</summary>
In this article, we study the collocated and distributed deployment of intelligent reflecting surfaces (IRS) for a fixed total number of IRS elements to support enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) services inside a factory. We build a channel model that incorporates the line-of-sight (LOS) probability and power loss of each transmission path, and propose three metrics, namely, the expected received signal-to-noise ratio (SNR), expected finite-blocklength (FB) capacity, and expected outage probability, where the expectation is taken over the probability distributions of interior blockages and channel fading. The expected received SNR and expected FB capacity for extremely high blockage densities are derived in closed-form as functions of the amount and height of IRSs and the density, size, and penetration loss of blockages, which are verified by Monte Carlo simulations. Results show that deploying IRSs vertically higher leads to higher expected received SNR and expected FB capacity. By analysing the average/minimum/maximum of the three metrics versus the number of IRSs, we find that for high blockage densities, both eMBB and URLLC services benefit from distributed deployment; and for low blockage densities, URLLC services benefit from distributed deployment while eMBB services see limited difference between collocated and distributed deployment.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们研究了彩色彩镜（IRS）的分布式部署，以支持内部的增强移动广播（eMBB）和低延迟低可靠通信（URLLC）服务。我们构建了一个通道模型，该模型包括每个传输路径的直视程度（LOS）概率和功率损失，并提出了三个指标，即预期的干扰比率（SNR）、预期的固定块长度（FB）容量，以及预期的失业概率。这三个指标的预期值在高封闭率下是几何函数，它们随着彩镜数量和封闭物体的密度、大小和渗透损失而变化。我们通过 Monte Carlo 仿真来验证这些结果。结果显示，彩镜高度越高，预期的干扰比率和固定块长度容量都越高。通过分析平均/最小/最大的三个指标对彩镜数量的影响，我们发现在高封闭率下， beiden eMBB 和 URLLC 服务都受益于分布式部署；在低封闭率下，URLLC 服务受益于分布式部署，而 eMBB 服务则不受分布式部署的影响。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/eess.SP_2023_11_14/" data-id="clp89dor401hni788czbuczzx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.SD_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T15:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.SD_2023_11_13/">cs.SD - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distributed-pressure-matching-strategy-using-diffusion-adaptation"><a href="#Distributed-pressure-matching-strategy-using-diffusion-adaptation" class="headerlink" title="Distributed pressure matching strategy using diffusion adaptation"></a>Distributed pressure matching strategy using diffusion adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07729">http://arxiv.org/abs/2311.07729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengfei Zhang, Junqing Zhang, Jie Chen, Cédric Richard</li>
<li>for: 这篇论文是关于如何解决个人声区系统（PSZ）任务中的时变Acoustic问题的。</li>
<li>methods: 这篇论文提出了一种分布式压力匹配（PM）方法，利用分散适应（DPM-D）技术来分散计算负担，从而解决中央化方法的高计算复杂性和高精度要求。</li>
<li>results:  simulations和计算复杂性分析表明，分布式PM方法在多频分布式环境中具有更高的计算效率和精度，与中央化方法相比。<details>
<summary>Abstract</summary>
Personal sound zone (PSZ) systems, which aim to create listening (bright) and silent (dark) zones in neighboring regions of space, are often based on time-varying acoustics. Conventional adaptive-based methods for handling PSZ tasks suffer from the collection and processing of acoustic transfer functions~(ATFs) between all the matching microphones and all the loudspeakers in a centralized manner, resulting in high calculation complexity and costly accuracy requirements. This paper presents a distributed pressure-matching (PM) method relying on diffusion adaptation (DPM-D) to spread the computational load amongst nodes in order to overcome these issues. The global PM problem is defined as a sum of local costs, and the diffusion adaption approach is then used to create a distributed solution that just needs local information exchanges. Simulations over multi-frequency bins and a computational complexity analysis are conducted to evaluate the properties of the algorithm and to compare it with centralized counterparts.
</details>
<details>
<summary>摘要</summary>
personal sound zone (PSZ) 系统，目的在于在邻近空间区域创建听众（亮）和沉默（暗）区域，经常基于时变音响学。传统的适应基于方法（ATF）处理 PSZ 任务，由于需要收集和处理所有听笔和所有扬声器之间的听音传函数（ATF），因此会带来高度复杂的计算和昂贵的准确性要求。本文提出了分布式压力匹配（PM）方法，基于扩散适应（DPM-D）来分担计算负担，以超越这些问题。全局 PM 问题定义为一个Local cost的总和，然后使用扩散适应approach来创建分布式解决方案，只需要本地信息交换。通过多频分布和计算复杂性分析，评估算法的性能和与中央化对手进行比较。
</details></li>
</ul>
<hr>
<h2 id="Efficient-bandwidth-extension-of-musical-signals-using-a-differentiable-harmonic-plus-noise-mode"><a href="#Efficient-bandwidth-extension-of-musical-signals-using-a-differentiable-harmonic-plus-noise-mode" class="headerlink" title="Efficient bandwidth extension of musical signals using a differentiable harmonic plus noise mode"></a>Efficient bandwidth extension of musical signals using a differentiable harmonic plus noise mode</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07363">http://arxiv.org/abs/2311.07363</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mathieulagrange/ddspmusicbandwidthextension">https://github.com/mathieulagrange/ddspmusicbandwidthextension</a></li>
<li>paper_authors: Pierre-Amaury Grumiaux, Mathieu Lagrange</li>
<li>for:  Audio signal bandwidth extension, specifically for monophonic and polyphonic musical signals.</li>
<li>methods:  Uses a differentiable digital signal processing (DDSP) model, which is a neural network with relatively few parameters that is trained to infer the parameters of a differentiable digital signal processing model.</li>
<li>results:  Proposed models surpass a higher complexity deep learning model for an objective metric computed in the frequency domain, and are also confirmed to have superior perceptual quality through a MUSHRA listening test.Here’s the Chinese translation of the three points:</li>
<li>for:  audio信号带宽扩展，特别是对于单声道和多声道乐音信号。</li>
<li>methods: 使用梯度可微的数字信号处理（DDSP）模型，该模型是一个具有相对少量参数的神经网络，用于推理DDSP模型的参数。</li>
<li>results: 提议的模型在频域中的一个对象指标上超过了更高复杂度的深度学习模型，并通过MUSHRA听力测试得到了更好的感知质量。<details>
<summary>Abstract</summary>
The task of bandwidth extension addresses the generation of missing high frequencies of audio signals based on knowledge of the low-frequency part of the sound. This task applies to various problems, such as audio coding or audio restoration. In this article, we focus on efficient bandwidth extension of monophonic and polyphonic musical signals using a differentiable digital signal processing (DDSP) model. Such a model is composed of a neural network part with relatively few parameters trained to infer the parameters of a differentiable digital signal processing model, which efficiently generates the output full-band audio signal.   We first address bandwidth extension of monophonic signals, and then propose two methods to explicitely handle polyphonic signals. The benefits of the proposed models are first demonstrated on monophonic and polyphonic synthetic data against a baseline and a deep-learning-based resnet model. The models are next evaluated on recorded monophonic and polyphonic data, for a wide variety of instruments and musical genres. We show that all proposed models surpass a higher complexity deep learning model for an objective metric computed in the frequency domain. A MUSHRA listening test confirms the superiority of the proposed approach in terms of perceptual quality.
</details>
<details>
<summary>摘要</summary>
音频信号的带宽扩展问题是基于听到的低频部分声音的知识，生成缺失的高频部分。这个问题适用于各种问题，如音频编码或音频修复。在这篇文章中，我们关注使用拟 diferenciable digital signal processing（DDSP）模型进行高效的带宽扩展。这种模型由一个具有相对少量参数的神经网络部分和一个可微分的数字信号处理模型组成。这种模型可以高效地生成全带宽音频信号。我们首先对单声音信号进行带宽扩展，然后提出了两种方法来特别处理多声音信号。我们在单声音和多声音 sintetic 数据上对基线和深度学习模型进行比较，并证明了我们的模型在频域中的目标指标上胜过深度学习模型。在录制的单声音和多声音数据上，我们发现所有我们提出的模型都超过了深度学习模型的高复杂性。在Perceptual Quality 中，我们通过 MUSHRA 听测表明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Duet-Singing-Voices-Separation-with-Diffusion-Models"><a href="#Zero-Shot-Duet-Singing-Voices-Separation-with-Diffusion-Models" class="headerlink" title="Zero-Shot Duet Singing Voices Separation with Diffusion Models"></a>Zero-Shot Duet Singing Voices Separation with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07345">http://arxiv.org/abs/2311.07345</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yoyololicon/duet-svs-diffusion">https://github.com/yoyololicon/duet-svs-diffusion</a></li>
<li>paper_authors: Chin-Yun Yu, Emilian Postolache, Emanuele Rodolà, György Fazekas</li>
<li>for: 这篇论文是为了解决对声音反问题中的源分离问题，具体来说是在分离二人或更多人的合唱声音中，保持歌手身份的一致性。</li>
<li>methods: 这篇论文使用了扩散模型作为假设，通过控制扩散过程来采样 posterior 分布中的目标信号。在解决对声音反问题中，提议使用 auto-regressive 方式进行 posterior 采样，并在每个过程中使用前一个过程的结果来保持歌手身份的一致性。</li>
<li>results: 在使用 MedleyVox 数据集进行评估时，提议的方法比基于 posterior 采样的基线方法表现更好，能够更好地保持歌手身份的一致性。<details>
<summary>Abstract</summary>
In recent studies, diffusion models have shown promise as priors for solving audio inverse problems. These models allow us to sample from the posterior distribution of a target signal given an observed signal by manipulating the diffusion process. However, when separating audio sources of the same type, such as duet singing voices, the prior learned by the diffusion process may not be sufficient to maintain the consistency of the source identity in the separated audio. For example, the singer may change from one to another occasionally. Tackling this problem will be useful for separating sources in a choir, or a mixture of multiple instruments with similar timbre, without acquiring large amounts of paired data. In this paper, we examine this problem in the context of duet singing voices separation, and propose a method to enforce the coherency of singer identity by splitting the mixture into overlapping segments and performing posterior sampling in an auto-regressive manner, conditioning on the previous segment. We evaluate the proposed method on the MedleyVox dataset and show that the proposed method outperforms the naive posterior sampling baseline. Our source code and the pre-trained model are publicly available at https://github.com/yoyololicon/duet-svs-diffusion.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Research-and-experimental-verification-on-low-frequency-long-range-underwater-sound-propagation-dispersion-characteristics-under-dual-channel-sound-speed-profiles-in-the-Chukchi-Plateau"><a href="#Research-and-experimental-verification-on-low-frequency-long-range-underwater-sound-propagation-dispersion-characteristics-under-dual-channel-sound-speed-profiles-in-the-Chukchi-Plateau" class="headerlink" title="Research and experimental verification on low-frequency long-range underwater sound propagation dispersion characteristics under dual-channel sound speed profiles in the Chukchi Plateau"></a>Research and experimental verification on low-frequency long-range underwater sound propagation dispersion characteristics under dual-channel sound speed profiles in the Chukchi Plateau</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08425">http://arxiv.org/abs/2311.08425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbao Weng, Yubo Qi, Yanming Yang, Hongtao Wen, Hongtao Zhou, Ruichao Xue</li>
<li>for: 研究了俄罗斯海和加拿大海湾的双通道声速 Profiling下的低频宽带声信号propagation特性</li>
<li>methods: 使用了正常模式理论来研究低频宽带声信号propagation dispersion的细结构，并使用修改后的扭变算符来分离正常模式</li>
<li>results: 解释了双通道声速 Profiling下normal mode dispersion曲线交叉的问题，分析了海底地形变化对dispersion结构的屏蔽效应，并通过长距离地震探测实验在俄罗斯海湾进行验证Here’s the same information in English:</li>
<li>for: Researched the low-frequency wide-band sound signal propagation characteristics under dual-channel sound speed profiles in the Chukchi Plateau and the Canadian Basin</li>
<li>methods: Used the theory of normal modes to study the fine structure of low-frequency wide-band sound propagation dispersion under dual-channel sound speed profiles, and used a modified warping operator to separate the normal modes</li>
<li>results: Explained the intersection of normal mode dispersion curves caused by the dual-channel sound speed profile, analyzed the blocking effect of seabed terrain changes on dispersion structures, and verified the results through a long-range seismic exploration experiment at the Chukchi Plateau. Additionally, proposed two methods for estimating the distance of sound sources based on acoustic signal characteristics in this environment, and verified these methods through experiment data at sea.<details>
<summary>Abstract</summary>
The dual-channel sound speed profiles of the Chukchi Plateau and the Canadian Basin have become current research hotspots due to their excellent low-frequency sound signal propagation ability. Previous research has mainly focused on using sound propagation theory to explain the changes in sound signal energy. This article is mainly based on the theory of normal modes to study the fine structure of low-frequency wide-band sound propagation dispersion under dual-channel sound speed profiles. In this paper, the problem of the intersection of normal mode dispersion curves caused by the dual-channel sound speed profile (SSP) has been explained, the blocking effect of seabed terrain changes on dispersion structures has been analyzed, and the normal modes has been separated by using modified warping operator. The above research results have been verified through a long-range seismic exploration experiment at the Chukchi Plateau. At the same time, based on the acoustic signal characteristics in this environment, two methods for estimating the distance of sound sources have been proposed, and the experiment data at sea has also verified these two methods.
</details>
<details>
<summary>摘要</summary>
“中险棚渠和加拿大海盆的双渠道声速 Profilestoday是研究热点，因为它们具有出色的低频声信号传播能力。以前的研究主要基于声传播理论来解释声信号能量的变化。本文基于准模理论来研究在双渠道声速 Profilestop下细腔低频宽带声信号传播折叠的细结构。文中解释了双渠道声速 Profilestop下准模折叠曲线的交叠问题，分析了海底地形变化对折叠结构的屏蔽效应，并使用修改的折卷算子来分离准模。研究结果得到了在鄂霍次克棚渠进行长距离地震探测实验的验证。同时，根据海洋环境中声信号特点，提出了两种方法来估计声源距离，并在实验数据上验证了这两种方法。”Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="SponTTS-modeling-and-transferring-spontaneous-style-for-TTS"><a href="#SponTTS-modeling-and-transferring-spontaneous-style-for-TTS" class="headerlink" title="SponTTS: modeling and transferring spontaneous style for TTS"></a>SponTTS: modeling and transferring spontaneous style for TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07179">http://arxiv.org/abs/2311.07179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kkksuper/SponTTS">https://github.com/kkksuper/SponTTS</a></li>
<li>paper_authors: Hanzhao Li, Xinfa Zhu, Liumeng Xue, Yang Song, Yunlin Chen, Lei Xie<br>for:本文主要用于模型和传递自由式发言的 Style，以提高自由式发言的自然性、表达力和发音相似性。methods:本文提出了一种两阶段方法，首先采用 Conditional Variational Autoencoder (CVAE) 来捕捉自由式发言的准则，并通过偏置自由式现象嵌入预测损失来包含自由式现象。其次，我们引入了流程基于预测器来预测文本中的自由式样式表示，以增强在推理中的语音和语境特定自由式现象。results:实验表明，SponTTS 能够有效地模型自由式 Style 并传递 Style 到目标说话者，生成自由式语音具有高度的自然性、表达力和发音相似性。 zero-shot 自由式 Style TTS 测试进一步证明了 SponTTS 在生成未经见过的说话者的自由式语音时的普适性和稳定性。<details>
<summary>Abstract</summary>
Spontaneous speaking style exhibits notable differences from other speaking styles due to various spontaneous phenomena (e.g., filled pauses, prolongation) and substantial prosody variation (e.g., diverse pitch and duration variation, occasional non-verbal speech like smile), posing challenges to modeling and prediction of spontaneous style. Moreover, the limitation of high-quality spontaneous data constrains spontaneous speech generation for speakers without spontaneous data. To address these problems, we propose SponTTS, a two-stage approach based on bottleneck (BN) features to model and transfer spontaneous style for TTS. In the first stage, we adopt a Conditional Variational Autoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve the spontaneous phenomena by the constraint of spontaneous phenomena embedding prediction loss. Besides, we introduce a flow-based predictor to predict a latent spontaneous style representation from the text, which enriches the prosody and context-specific spontaneous phenomena during inference. In the second stage, we adopt a VITS-like module to transfer the spontaneous style learned in the first stage to target speakers. Experiments demonstrate that SponTTS is effective in modeling spontaneous style and transferring the style to the target speakers, generating spontaneous speech with high naturalness, expressiveness, and speaker similarity. The zero-shot spontaneous style TTS test further verifies the generalization and robustness of SponTTS in generating spontaneous speech for unseen speakers.
</details>
<details>
<summary>摘要</summary>
自然口语风格 exhibits  notable differences from other speaking styles due to various spontaneous phenomena (e.g., filled pauses, prolongation) and substantial prosody variation (e.g., diverse pitch and duration variation, occasional non-verbal speech like smile), posing challenges to modeling and prediction of spontaneous style. Moreover, the limitation of high-quality spontaneous data constrains spontaneous speech generation for speakers without spontaneous data. To address these problems, we propose SponTTS, a two-stage approach based on bottleneck (BN) features to model and transfer spontaneous style for TTS. In the first stage, we adopt a Conditional Variational Autoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve the spontaneous phenomena by the constraint of spontaneous phenomena embedding prediction loss. Besides, we introduce a flow-based predictor to predict a latent spontaneous style representation from the text, which enriches the prosody and context-specific spontaneous phenomena during inference. In the second stage, we adopt a VITS-like module to transfer the spontaneous style learned in the first stage to target speakers. Experiments demonstrate that SponTTS is effective in modeling spontaneous style and transferring the style to the target speakers, generating spontaneous speech with high naturalness, expressiveness, and speaker similarity. The zero-shot spontaneous style TTS test further verifies the generalization and robustness of SponTTS in generating spontaneous speech for unseen speakers.
</details></li>
</ul>
<hr>
<h2 id="Research-and-experimental-verification-on-low-frequency-long-range-sound-propagation-characteristics-under-ice-covered-and-range-dependent-marine-environment-in-the-Arctic"><a href="#Research-and-experimental-verification-on-low-frequency-long-range-sound-propagation-characteristics-under-ice-covered-and-range-dependent-marine-environment-in-the-Arctic" class="headerlink" title="Research and experimental verification on low-frequency long-range sound propagation characteristics under ice-covered and range-dependent marine environment in the Arctic"></a>Research and experimental verification on low-frequency long-range sound propagation characteristics under ice-covered and range-dependent marine environment in the Arctic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07175">http://arxiv.org/abs/2311.07175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbao Weng, Yubo Qi, Yanming Yang, Hongtao Wen, Hongtao Zhou, Ruichao Xue</li>
<li>for: 这篇论文主要研究的是在北极冰层下propagation of low-frequency broadband acoustic signals，尤其是声传输损耗和声信号的时域波形和细谱结构。</li>
<li>methods: 该文使用了normal modes theory和 measurement of ocean environmental parameters和声场计算来研究北极深海环境中low-frequency long-range声信号的一般法律，并解释了环境因素如海底地形变化、水 column velocity profile变化和海冰覆盖的影响 mechanisms on low-frequency long-range sound propagation in the Arctic.</li>
<li>results: 该文通过在北极进行了一次声传播实验，并确认了上述研究观点，并首次使用了折射正常波的折射变换器来实现单一ydrophone based separation of normal waves and extraction of dispersion structures.<details>
<summary>Abstract</summary>
At present, research on sound propagation under the Arctic ice mainly focuses on modeling and experimental verification of sound propagation under sea ice cover and unique sound velocity profiles. Among them, the main research object of concern is sound transmission loss, and this article will delve into the time-domain waveform and fine dispersion structure of low-frequency broadband acoustic signals. Firstly, based on the theory of normal modes, this article derives the horizontal wavenumber expression and warping transformation operator for refractive normal modes in the Arctic deep-sea environment. Subsequently, based on measured ocean environmental parameters and sound field simulation calculations, this article studied the general laws of low-frequency long-range sound propagation signals in the Arctic deep-sea environment, and elucidated the impact mechanism of environmental factors such as seabed terrain changes, horizontal changes in sound velocity profiles (SSPs), and sea ice cover on low-frequency long-range sound propagation in the Arctic. This article validates the above research viewpoint through a sound propagation experiment conducted in the Arctic with a propagation distance exceeding 1000km. The marine environment of this experiment has obvious horizontal variation characteristics. At the same time, this article takes the lead in utilizing the warping transformation of refractive normal waves in the Arctic waters to achieve single hydrophone based separation of normal waves and extraction of dispersion structures, which is conducive to future research on underwater sound source localization and environmental parameter inversion based on dispersion structures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现在，在北极冰层下的声波传播研究主要集中在模拟和实验验证冰层下的声波传播，以及独特的声速 Profil。其中，研究对象主要是声传损，这篇文章将探讨声波时域波形和细谱振荡结构的低频广频声信号。首先，根据正常模式理论，这篇文章 derivates了在北极深海环境中的横向波数表达和折叠变换算子。然后，通过测量海洋环境参数和声场 simulate calculation，这篇文章研究了北极深海环境中低频长距离声波传播的通用规律，并描述了环境因素如海底地形变化、水 Column 的横向声速 Profil 变化和海冰覆盖的影响于北极深海环境中低频长距离声波传播。这篇文章通过在北极进行了超过 1000km 的声波传播实验， validate 了上述研究视角。实验 Marine 环境具有明显的横向变化特征。同时，这篇文章首次利用北极水域中的折叠变换来实现单 hydrophone 基于 separation of normal waves 和折叠结构的提取，这有助于未来基于折叠结构的声源 localization 和环境参数反射。
</details></li>
</ul>
<hr>
<h2 id="Music-ControlNet-Multiple-Time-varying-Controls-for-Music-Generation"><a href="#Music-ControlNet-Multiple-Time-varying-Controls-for-Music-Generation" class="headerlink" title="Music ControlNet: Multiple Time-varying Controls for Music Generation"></a>Music ControlNet: Multiple Time-varying Controls for Music Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07069">http://arxiv.org/abs/2311.07069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shih-Lun Wu, Chris Donahue, Shinji Watanabe, Nicholas J. Bryan</li>
<li>for: 这个论文的目的是提出一种基于扩散的音乐生成模型，允许用户在不同的时间点进行精细控制音乐的生成。</li>
<li>methods: 该模型使用了一种基于扩散的 conditional generative model，通过在音频spectrogram上进行微调来实现时间点的控制。</li>
<li>results: 该模型可以生成具有高质量和精细控制的音乐，并且在不同的时间点进行控制。与其他相似的音乐生成模型进行比较，该模型能够生成更 faithful 的音乐，即使它具有许多 fewer 参数和训练数据。<details>
<summary>Abstract</summary>
Text-to-music generation models are now capable of generating high-quality music audio in broad styles. However, text control is primarily suitable for the manipulation of global musical attributes like genre, mood, and tempo, and is less suitable for precise control over time-varying attributes such as the positions of beats in time or the changing dynamics of the music. We propose Music ControlNet, a diffusion-based music generation model that offers multiple precise, time-varying controls over generated audio. To imbue text-to-music models with time-varying control, we propose an approach analogous to pixel-wise control of the image-domain ControlNet method. Specifically, we extract controls from training audio yielding paired data, and fine-tune a diffusion-based conditional generative model over audio spectrograms given melody, dynamics, and rhythm controls. While the image-domain Uni-ControlNet method already allows generation with any subset of controls, we devise a new strategy to allow creators to input controls that are only partially specified in time. We evaluate both on controls extracted from audio and controls we expect creators to provide, demonstrating that we can generate realistic music that corresponds to control inputs in both settings. While few comparable music generation models exist, we benchmark against MusicGen, a recent model that accepts text and melody input, and show that our model generates music that is 49% more faithful to input melodies despite having 35x fewer parameters, training on 11x less data, and enabling two additional forms of time-varying control. Sound examples can be found at https://MusicControlNet.github.io/web/.
</details>
<details>
<summary>摘要</summary>
文本到音乐生成模型现在可以生成高质量的音乐声音，但是文本控制主要适用于globale musical attribute的控制，如种类、情感和旋律，而不太适合精确控制时间变化的属性，如音乐的拍点位置或变化的声音 dynamics。我们提出了Music ControlNet，一种 diffusion-based music生成模型，提供了多种精确、时间变化的控制方法。为了让文本到音乐模型具有时间变化控制，我们采用了像 pixel-wise control的image-domain ControlNet方法。具体来说，我们从训练音频中提取控制，并使用 diffusion-based conditional生成模型在音频spectrogram中进行了 fine-tune。而在image-domain ControlNet方法中，可以生成任何subset of controls，我们开发了一种新的策略，允许创作者输入只部分Specified in time的控制。我们对于从音频中提取的控制和我们预期创作者提供的控制进行评估，示出了我们可以在两种设置下生成符合控制输入的真实音乐。虽然只有少数相关的音乐生成模型存在，我们对MusicGen，一种最近的模型，进行了比较，并显示了我们的模型可以生成与输入旋律更加准确的音乐，即使有35倍少于参数，在11倍少于数据上进行了训练，并允许两种额外的时间变化控制。音乐示例可以在https://MusicControlNet.github.io/web/中找到。
</details></li>
</ul>
<hr>
<h2 id="Decoupling-and-Interacting-Multi-Task-Learning-Network-for-Joint-Speech-and-Accent-Recognition"><a href="#Decoupling-and-Interacting-Multi-Task-Learning-Network-for-Joint-Speech-and-Accent-Recognition" class="headerlink" title="Decoupling and Interacting Multi-Task Learning Network for Joint Speech and Accent Recognition"></a>Decoupling and Interacting Multi-Task Learning Network for Joint Speech and Accent Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07062">http://arxiv.org/abs/2311.07062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qijie Shao, Pengcheng Guo, Jinghao Yan, Pengfei Hu, Lei Xie</li>
<li>for: 这个论文的目的是提出一种基于多任务学习的语音识别和口音识别模型（DIMNet），以提高多口音场景下的语音识别精度。</li>
<li>methods: 这个模型使用了分解连接主义时间分类（CTC）分支、语音识别（ASR）分支和口音识别（AR）分支，并使用了两种粒度的模型单元来学习任务特有的表示。此外，模型还使用了文本掌握和口音特征的交互来提高语音识别和口音识别的性能。</li>
<li>results: 试验结果表明，提出的模型在英语和中文数据集上都达到了比较出色的性能，相比标准基准模型，AR准确率提高21.45%&#x2F;28.53%，ASR错误率下降32.33%&#x2F;14.55%。<details>
<summary>Abstract</summary>
Accents, as variations from standard pronunciation, pose significant challenges for speech recognition systems. Although joint automatic speech recognition (ASR) and accent recognition (AR) training has been proven effective in handling multi-accent scenarios, current multi-task ASR-AR approaches overlook the granularity differences between tasks. Fine-grained units capture pronunciation-related accent characteristics, while coarse-grained units are better for learning linguistic information. Moreover, an explicit interaction of two tasks can also provide complementary information and improve the performance of each other, but it is rarely used by existing approaches. In this paper, we propose a novel Decoupling and Interacting Multi-task Network (DIMNet) for joint speech and accent recognition, which is comprised of a connectionist temporal classification (CTC) branch, an AR branch, an ASR branch, and a bottom feature encoder. Specifically, AR and ASR are first decoupled by separated branches and two-granular modeling units to learn task-specific representations. The AR branch is from our previously proposed linguistic-acoustic bimodal AR model and the ASR branch is an encoder-decoder based Conformer model. Then, for the task interaction, the CTC branch provides aligned text for the AR task, while accent embeddings extracted from our AR model are incorporated into the ASR branch's encoder and decoder. Finally, during ASR inference, a cross-granular rescoring method is introduced to fuse the complementary information from the CTC and attention decoder after the decoupling. Our experiments on English and Chinese datasets demonstrate the effectiveness of the proposed model, which achieves 21.45%/28.53% AR accuracy relative improvement and 32.33%/14.55% ASR error rate relative reduction over a published standard baseline, respectively.
</details>
<details>
<summary>摘要</summary>
字符识别（ASR）和口音识别（AR）是两个相关的任务，但是传统的多任务学习方法通常忽略了这两个任务之间的细腻差异。我们在本文提出了一种新的分离和互动多任务网络（DIMNet），用于同时进行字符识别和口音识别。该模型包括一个连接式时间分类（CTC）分支、一个AR分支、一个ASR分支和底层特征编码器。特别是，AR和ASR两个任务首先被分离为两个不同的分支和两个不同的模型单元，以学习任务特定的表示。AR分支采用我们之前提出的语言-听音双模型，而ASR分支采用一个基于Conformer模型的encoder-decoder结构。然后，为了实现任务之间的互动，CTC分支提供了对AR任务的已知文本，而AR模型中提取出来的口音嵌入被integrated到ASR分支的编码器和解码器中。最后，在ASR推理过程中，我们引入了一种交叉гра듷推理方法，以融合CTC和注意力解码器中的补充信息。我们在英语和中文 dataset上进行了实验，并证明了我们的模型的效果，其中对于英语 dataset，Relative AR准确率提高21.45%，Relative ASR错误率降低32.33%，对于中文 dataset，Relative AR准确率提高28.53%，Relative ASR错误率降低14.55%，相比之下，相对提高了21.45%/28.53%和32.33%/14.55%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.SD_2023_11_13/" data-id="clp89dokr0120i78821519ei2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.CV_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T13:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.CV_2023_11_13/">cs.CV - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Assessing-Test-time-Variability-for-Interactive-3D-Medical-Image-Segmentation-with-Diverse-Point-Prompts"><a href="#Assessing-Test-time-Variability-for-Interactive-3D-Medical-Image-Segmentation-with-Diverse-Point-Prompts" class="headerlink" title="Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts"></a>Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07806">http://arxiv.org/abs/2311.07806</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/medicl-vu/variability">https://github.com/medicl-vu/variability</a></li>
<li>paper_authors: Hao Li, Han Liu, Dewei Hu, Jiacheng Wang, Ipek Oguz</li>
<li>for: 这 paper 是为了研究 interactive medical image segmentation 的可靠性和可重现性问题。</li>
<li>methods: 这 paper 使用了 prompt engineering 技术，通过在测试时提供用户提示来生成精准的分割结果。</li>
<li>results: 这 paper 的实验结果表明，在使用多个点提示时，可以提高分割精度和可重现性。同时，通过对提示的位置和数量进行优化，可以提高分割结果的可靠性。<details>
<summary>Abstract</summary>
Interactive segmentation model leverages prompts from users to produce robust segmentation. This advancement is facilitated by prompt engineering, where interactive prompts serve as strong priors during test-time. However, this is an inherently subjective and hard-to-reproduce process. The variability in user expertise and inherently ambiguous boundaries in medical images can lead to inconsistent prompt selections, potentially affecting segmentation accuracy. This issue has not yet been extensively explored for medical imaging. In this paper, we assess the test-time variability for interactive medical image segmentation with diverse point prompts. For a given target region, the point is classified into three sub-regions: boundary, margin, and center. Our goal is to identify a straightforward and efficient approach for optimal prompt selection during test-time based on three considerations: (1) benefits of additional prompts, (2) effects of prompt placement, and (3) strategies for optimal prompt selection. We conduct extensive experiments on the public Medical Segmentation Decathlon dataset for challenging colon tumor segmentation task. We suggest an optimal strategy for prompt selection during test-time, supported by comprehensive results. The code is publicly available at https://github.com/MedICL-VU/variability
</details>
<details>
<summary>摘要</summary>
互动分割模型利用用户提供的提示来生成稳定的分割。这个进步得到了提示工程学支持，其中互动提示在试用时作为强大的先验条件。然而，这是一个内在受主观和难以重复的过程。用户专业知识和医疗影像中的自然欠缺缘点可能导致提示选择不稳定，这可能对分割精度产生影响。这个问题在医疗影像分割领域仍未得到充分探讨。在这篇研究中，我们评估了互动医疗影像分割中多个点提示的试用时间多样性。对于给定目标区域，点会被分为三个子区域：boundary、margin和center。我们的目标是发现一个简单和高效的方法，以便在试用时间选择最佳提示，基于以下三个考虑因素：1. 额外提示的优点2. 提示位置的影响3. 最佳提示选择策略我们在公共的医疗影像分割十大项目数据集上进行了广泛的实验，以挑战colon淋巴癌分割任务。我们建议一个最佳的提示选择策略，并提供了全面的结果。软件可以在https://github.com/MedICL-VU/variability上获取。
</details></li>
</ul>
<hr>
<h2 id="CSLP-AE-A-Contrastive-Split-Latent-Permutation-Autoencoder-Framework-for-Zero-Shot-Electroencephalography-Signal-Conversion"><a href="#CSLP-AE-A-Contrastive-Split-Latent-Permutation-Autoencoder-Framework-for-Zero-Shot-Electroencephalography-Signal-Conversion" class="headerlink" title="CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion"></a>CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07788">http://arxiv.org/abs/2311.07788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andersxa/cslp-ae">https://github.com/andersxa/cslp-ae</a></li>
<li>paper_authors: Anders Vestergaard Nørskov, Alexander Neergaard Zahid, Morten Mørup</li>
<li>for: 提高EEG数据的抽象和普适性，以提高脑功能的研究和分析。</li>
<li>methods: 提出了一种基于对比学习的划分卷积自适应器（CSLP-AE）框架，通过对比学习来引导卷积的 latent splits 表示主体（样式）和任务（内容）的特征，以提高 EEG 的抽象和普适性。</li>
<li>results: 比较 CSLP-AE 与传统的超级vised、无监督（AE）和自监督（对比学习）训练方法，发现 CSLP-AE 提供了更好的普适性和适应性，并且可以实现零例转换 между未看过的主体。<details>
<summary>Abstract</summary>
Electroencephalography (EEG) is a prominent non-invasive neuroimaging technique providing insights into brain function. Unfortunately, EEG data exhibit a high degree of noise and variability across subjects hampering generalizable signal extraction. Therefore, a key aim in EEG analysis is to extract the underlying neural activation (content) as well as to account for the individual subject variability (style). We hypothesize that the ability to convert EEG signals between tasks and subjects requires the extraction of latent representations accounting for content and style. Inspired by recent advancements in voice conversion technologies, we propose a novel contrastive split-latent permutation autoencoder (CSLP-AE) framework that directly optimizes for EEG conversion. Importantly, the latent representations are guided using contrastive learning to promote the latent splits to explicitly represent subject (style) and task (content). We contrast CSLP-AE to conventional supervised, unsupervised (AE), and self-supervised (contrastive learning) training and find that the proposed approach provides favorable generalizable characterizations of subject and task. Importantly, the procedure also enables zero-shot conversion between unseen subjects. While the present work only considers conversion of EEG, the proposed CSLP-AE provides a general framework for signal conversion and extraction of content (task activation) and style (subject variability) components of general interest for the modeling and analysis of biological signals.
</details>
<details>
<summary>摘要</summary>
电 electroencephalography (EEG) 是一种非侵入性的脑成像技术，提供了脑功能的重要信息。然而，EEG 数据具有高度的噪声和主题变化，使得普遍化的信号提取受到阻碍。因此，EEG 分析中的一个关键目标是提取内在的神经活动（内容）以及考虑主题变化（样式）。我们假设可以将 EEG 信号转换到不同的任务和主题之间，需要提取潜在表示主题和任务的独特表示。这个目标可以通过对 EEG 信号进行对比学习来实现。我们提出了一种新的对比拆分潜在嵌入 autoencoder（CSLP-AE）框架，该框架直接优化了 EEG 信号的转换。关键是，潜在表示被对比学习导引，以便主题和任务分别具有独特的表示。与传统的超级vised、无级vised（AE）和自我超级vised（对比学习）训练相比，我们发现提出的方法可以提供有利的总体特征表示。特别是，该方法还允许零shot转换到未看到的主题。虽然本研究只考虑了 EEG 的转换，但我们提出的 CSLP-AE 提供了一种通用的信号转换和内容（任务活动）以及样式（主题变化）组成部分的模型化和分析的框架。
</details></li>
</ul>
<hr>
<h2 id="A-Data-Free-Approach-to-Mitigate-Catastrophic-Forgetting-in-Federated-Class-Incremental-Learning-for-Vision-Tasks"><a href="#A-Data-Free-Approach-to-Mitigate-Catastrophic-Forgetting-in-Federated-Class-Incremental-Learning-for-Vision-Tasks" class="headerlink" title="A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks"></a>A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07784">http://arxiv.org/abs/2311.07784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotabi, Salman Avestimehr</li>
<li>for: 防止深度学习模型忘记之前学习的信息，特别在联合学习（Federated Learning，FL）中，数据分布式，每个用户的数据可能会独立变化。</li>
<li>methods: 提出了一种基于生成模型的联合分类增量学习框架，利用生成模型Synthesize samples from past distributions，以减轻忘记现象。保持隐私性，生成模型在服务器端使用数据free方法进行训练，不需要客户端提供数据。</li>
<li>results: 在多个数据集上进行了广泛的实验，证明了该方法可以减轻忘记现象，并且不需要用户保存过去的数据或模型。<details>
<summary>Abstract</summary>
Deep learning models often suffer from forgetting previously learned information when trained on new data. This problem is exacerbated in federated learning (FL), where the data is distributed and can change independently for each user. Many solutions are proposed to resolve this catastrophic forgetting in a centralized setting. However, they do not apply directly to FL because of its unique complexities, such as privacy concerns and resource limitations. To overcome these challenges, this paper presents a framework for \textbf{federated class incremental learning} that utilizes a generative model to synthesize samples from past distributions. This data can be later exploited alongside the training data to mitigate catastrophic forgetting. To preserve privacy, the generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Moreover, our solution does not demand the users to store old data or models, which gives them the freedom to join/leave the training at any time. Additionally, we introduce SuperImageNet, a new regrouping of the ImageNet dataset specifically tailored for federated continual learning. We demonstrate significant improvements compared to existing baselines through extensive experiments on multiple datasets.
</details>
<details>
<summary>摘要</summary>
深度学习模型经常面临新数据训练时忘记之前学习的信息问题。这个问题在 federated learning（FL）中更加严重，因为数据分布在不同用户处并可以独立地变化。许多解决方案在中央化设置下提出来解决这个慢速衰减问题，但这些解决方案不直接适用于 FL 因为其独特的复杂性，如隐私问题和资源限制。为了突破这些挑战，本文提出了一个框架，即 federated class incremental learning（FL-CIL），该框架利用生成模型来synthesize过去分布的样本。这些样本可以在训练数据之 alongside 使用，以 Mitigate 慢速衰减。在保护隐私方面，生成模型在服务器上使用数据free方法进行训练，而无需请求客户端上传数据。此外，我们的解决方案不需要用户保留过去的数据或模型，这给了他们在训练中任意时间加入/离开的自由。此外，我们还提出了一个新的 ImageNet 数据集重新分组，即 SuperImageNet，特意设计用于 federated continual learning。通过了广泛的实验，我们证明了我们的方案与现有基eline存在显著的改进。
</details></li>
</ul>
<hr>
<h2 id="FedOpenHAR-Federated-Multi-Task-Transfer-Learning-for-Sensor-Based-Human-Activity-Recognition"><a href="#FedOpenHAR-Federated-Multi-Task-Transfer-Learning-for-Sensor-Based-Human-Activity-Recognition" class="headerlink" title="FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based Human Activity Recognition"></a>FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07765">http://arxiv.org/abs/2311.07765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Egemen İşgüder, Özlem Durmaz İncel</li>
<li>for: 这篇论文主要针对的是如何使用分布式机器学习技术来实现基于嗅感器的人体活动识别和设备位置识别两个任务。</li>
<li>methods: 本文使用了联邦传输学习技术，通过将多个小型数据集合并训练一个共享模型，以实现两个任务的同时进行多任务学习。</li>
<li>results: 试验结果表明，通过使用分布式机器学习技术和转移学习，可以在不同的数据集和环境下实现类似于中央化训练的高精度。<details>
<summary>Abstract</summary>
Motion sensors integrated into wearable and mobile devices provide valuable information about the device users. Machine learning and, recently, deep learning techniques have been used to characterize sensor data. Mostly, a single task, such as recognition of activities, is targeted, and the data is processed centrally at a server or in a cloud environment. However, the same sensor data can be utilized for multiple tasks and distributed machine-learning techniques can be used without the requirement of the transmission of data to a centre. This paper explores Federated Transfer Learning in a Multi-Task manner for both sensor-based human activity recognition and device position identification tasks. The OpenHAR framework is used to train the models, which contains ten smaller datasets. The aim is to obtain model(s) applicable for both tasks in different datasets, which may include only some label types. Multiple experiments are carried in the Flower federated learning environment using the DeepConvLSTM architecture. Results are presented for federated and centralized versions under different parameters and restrictions. By utilizing transfer learning and training a task-specific and personalized federated model, we obtained a similar accuracy with training each client individually and higher accuracy than a fully centralized approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese运动传感器 интегрирован到了携带式和移动设备中提供了设备用户的有价值信息。机器学习和最近的深度学习技术已经用于描述传感器数据。通常，单个任务，如活动识别，是目标，并将数据处理中央服务器或云环境中。然而，同一个传感器数据可以用于多个任务，并可以使用分布式机器学习技术，无需数据传输到中心。这篇论文探讨了联邦传输学习在多任务方式下的应用，用于满足感知设备的人体活动识别和设备位置识别两个任务。使用OpenHAR框架进行训练，该框架包含10个较小的数据集。目标是在不同的数据集中获得适用于两个任务的模型，可能只包含一些标签类型。在花开联邦学习环境中进行多个实验，使用深度卷积LSTM架构。结果显示，通过使用传输学习和训练任务特定和个性化联邦模型，我们可以获得与每个客户端分别训练的相似准确率，并高于完全中央化方法。Note: Simplified Chinese is used here, as it is more widely used in mainland China. If you prefer Traditional Chinese, I can also provide the translation.
</details></li>
</ul>
<hr>
<h2 id="Quality-Aware-Prototype-Memory-for-Face-Representation-Learning"><a href="#Quality-Aware-Prototype-Memory-for-Face-Representation-Learning" class="headerlink" title="Quality-Aware Prototype Memory for Face Representation Learning"></a>Quality-Aware Prototype Memory for Face Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07734">http://arxiv.org/abs/2311.07734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evgeny Smirnov, Vasiliy Galyuk, Evgeny Lukyanets</li>
<li>for: 提高 Prototype Memory 模型的扩展性和精度，使其能够更好地处理低质量或具有异常特征的人脸图像。</li>
<li>methods: 提出了一种简单有效的质量感知技术，使得 Prototype Memory 在生成核心时使用不同的权重来处理不同质量的人脸图像，从而提高模型的精度和稳定性。</li>
<li>results: 通过对多个人脸识别benchmark进行了广泛的实验，证明了提出的方法可以提高 Prototype Memory 模型的性能，并且在不同质量的人脸图像下表现更加稳定。<details>
<summary>Abstract</summary>
Prototype Memory is a powerful model for face representation learning. It enables the training of face recognition models using datasets of any size, with on-the-fly generation of prototypes (classifier weights) and efficient ways of their utilization. Prototype Memory demonstrated strong results in many face recognition benchmarks. However, the algorithm of prototype generation, used in it, is prone to the problems of imperfectly calculated prototypes in case of low-quality or poorly recognizable faces in the images, selected for the prototype creation. All images of the same person, presented in the mini-batch, used with equal weights, and the resulting averaged prototype could be contaminated with imperfect embeddings of such face images. It can lead to misdirected training signals and impair the performance of the trained face recognition models. In this paper, we propose a simple and effective way to improve Prototype Memory with quality-aware prototype generation. Quality-Aware Prototype Memory uses different weights for images of different quality in the process of prototype generation. With this improvement, prototypes get more valuable information from high-quality images and less hurt by low-quality ones. We propose and compare several methods of quality estimation and usage, perform extensive experiments on the different face recognition benchmarks and demonstrate the advantages of the proposed model compared to the basic version of Prototype Memory.
</details>
<details>
<summary>摘要</summary>
protoype memory 是一种强大的人脸表示学习模型。它允许通过任意大小的数据集进行人脸识别模型的训练，并且可以在实时生成核心示例（分类器权重）并有效地使用它们。 prototype memory 在许多人脸识别benchmark中显示出了强大的成果。然而， prototype memory 中使用的核心生成算法在低质量或difficult to recognize的面部图像时存在一些问题。当使用相同的人脸图像进行批处理时，所有图像均被视为等重，并且所得到的平均核心可能受到低质量图像的杂乱影响。这可能导致训练信号受扰和人脸识别模型的性能下降。在这篇论文中，我们提出了一种简单有效的方法，用于提高 protoype memory 的质量感知。我们使用不同的权重来处理不同质量的面部图像，以便核心获得更多的高质量图像中的有价值信息，并且减少低质量图像的影响。我们提出了多种质量估计和使用方法，进行了广泛的实验，并在不同的人脸识别benchmark上显示了提高模型的优势。
</details></li>
</ul>
<hr>
<h2 id="To-See-is-to-Believe-Prompting-GPT-4V-for-Better-Visual-Instruction-Tuning"><a href="#To-See-is-to-Believe-Prompting-GPT-4V-for-Better-Visual-Instruction-Tuning" class="headerlink" title="To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning"></a>To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07574">http://arxiv.org/abs/2311.07574</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/x2fd/lvis-instruct4v">https://github.com/x2fd/lvis-instruct4v</a></li>
<li>paper_authors: Junke Wang, Lingchen Meng, Zejia Weng, Bo He, Zuxuan Wu, Yu-Gang Jiang</li>
<li>for: 提高大型多媒体模型（LLaVA-1.5）的性能，使其在各种困难的混合媒体任务中表现出色。</li>
<li>methods: 引入了高级的视觉指令集（LVIS-Instruct4V），通过Prompting强大的GPT-4V模型使用图像来生成高精度的视觉指令数据。</li>
<li>results: 经验验证和案例研究表明，高质量的视觉指令数据可以提高LLaVA-1.5模型在多种混合媒体任务中的性能，比如LLaVA$^w$（76.7 vs. 70.7）和MM-Vet（40.2 vs. 35.4）等。<details>
<summary>Abstract</summary>
Existing visual instruction tuning methods typically prompt large language models with textual descriptions to generate instruction-following data. Despite the promising performance achieved, these descriptions are derived from image annotations, which are oftentimes coarse-grained. Furthermore, the instructions might even contradict the visual content without observing the entire visual context. To address this challenge, we introduce a fine-grained visual instruction dataset, LVIS-Instruct4V, which contains 220K visually aligned and context-aware instructions produced by prompting the powerful GPT-4V with images from LVIS. Through experimental validation and case studies, we demonstrate that high-quality visual instructional data could improve the performance of LLaVA-1.5, a state-of-the-art large multimodal model, across a wide spectrum of benchmarks by clear margins. Notably, by simply replacing the LLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA on most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet (40.2 vs. 35.4). We release our data and model at https://github.com/X2FD/LVIS-INSTRUCT4V.
</details>
<details>
<summary>摘要</summary>
现有的视觉指令优化方法通常是通过文本描述向大语言模型提供图像描述来生成指令跟踪数据。尽管这些描述可以达到出色的性能，但是这些描述通常是基于图像注释，它们可能是粗糙的。此外，指令可能与视觉内容不匹配，而不考虑整个视觉上下文。为解决这个挑战，我们引入了高级的视觉指令数据集，LVIS-Instruct4V，它包含220K个视觉对应的高级指令，这些指令是通过提交强大的GPT-4V图像从LVIS来生成的。通过实验验证和案例研究，我们证明了高质量的视觉指令数据可以提高LLaVA-1.5，一个状态之最大的多Modal模型，在多种 bencmarks 上的性能，并且具有明显的优势。例如，通过将LLaVA-Instruct替换为我们的LVIS-Instruct4V，我们可以在许多最复杂的LMM bencmarks上获得更好的结果，例如LLaVA$^w$ (76.7 vs. 70.7) 和 MM-Vet (40.2 vs. 35.4)。我们在 GitHub 上发布了我们的数据和模型，可以通过以下链接获取：https://github.com/X2FD/LVIS-INSTRUCT4V。
</details></li>
</ul>
<hr>
<h2 id="Fast-Normalized-Cross-Correlation-for-Template-Matching-with-Rotations"><a href="#Fast-Normalized-Cross-Correlation-for-Template-Matching-with-Rotations" class="headerlink" title="Fast Normalized Cross-Correlation for Template Matching with Rotations"></a>Fast Normalized Cross-Correlation for Template Matching with Rotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07561">http://arxiv.org/abs/2311.07561</a></li>
<li>repo_url: None</li>
<li>paper_authors: José María Almira, Harold Phelippeau, Antonio Martinez-Sanchez</li>
<li>for: 用于快速化Template Matching计算（特别是3D图像）</li>
<li>methods: 使用一种新的数学理论，可以同时处理平移和旋转，减少计算复杂性</li>
<li>results: 可以快速地回归模板实例的位置和旋转角度信息<details>
<summary>Abstract</summary>
Normalized cross-correlation is the reference approach to carry out template matching on images. When it is computed in Fourier space, it can handle efficiently template translations but it cannot do so with template rotations. Including rotations requires sampling the whole space of rotations, repeating the computation of the correlation each time.   This article develops an alternative mathematical theory to handle efficiently, at the same time, rotations and translations. Our proposal has a reduced computational complexity because it does not require to repeatedly sample the space of rotations. To do so, we integrate the information relative to all rotated versions of the template into a unique symmetric tensor template -which is computed only once per template-. Afterward, we demonstrate that the correlation between the image to be processed with the independent tensor components of the tensorial template contains enough information to recover template instance positions and rotations.   Our proposed method has the potential to speed up conventional template matching computations by a factor of several magnitude orders for the case of 3D images.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VGSG-Vision-Guided-Semantic-Group-Network-for-Text-based-Person-Search"><a href="#VGSG-Vision-Guided-Semantic-Group-Network-for-Text-based-Person-Search" class="headerlink" title="VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search"></a>VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07514">http://arxiv.org/abs/2311.07514</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuting He, Hao Luo, Wei Jiang, Xudong Jiang, Henghui Ding</li>
<li>for: 本文提出了一种基于视觉引导的Semantic-Group Network（VGSG），用于文本基于人脸搜索，以EXTRACTING高精度的视觉和文本特征。</li>
<li>methods: 本文提出了两个模块：Semantic-Group Textual Learning（SGTL）模块和Vision-guided Knowledge Transfer（VGKT）模块。SGTL模块使用语言表达的semantic cues来分组文本特征，而VGKT模块使用视觉引导的注意力来EXTRACTING视觉相关的文本特征。</li>
<li>results: 实验结果表明，VGSG比state-of-the-art方法高效、高精度地实现文本基于人脸搜索。<details>
<summary>Abstract</summary>
Text-based Person Search (TBPS) aims to retrieve images of target pedestrian indicated by textual descriptions. It is essential for TBPS to extract fine-grained local features and align them crossing modality. Existing methods utilize external tools or heavy cross-modal interaction to achieve explicit alignment of cross-modal fine-grained features, which is inefficient and time-consuming. In this work, we propose a Vision-Guided Semantic-Group Network (VGSG) for text-based person search to extract well-aligned fine-grained visual and textual features. In the proposed VGSG, we develop a Semantic-Group Textual Learning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to extract textual local features under the guidance of visual local clues. In SGTL, in order to obtain the local textual representation, we group textual features from the channel dimension based on the semantic cues of language expression, which encourages similar semantic patterns to be grouped implicitly without external tools. In VGKT, a vision-guided attention is employed to extract visual-related textual features, which are inherently aligned with visual cues and termed vision-guided textual features. Furthermore, we design a relational knowledge transfer, including a vision-language similarity transfer and a class probability transfer, to adaptively propagate information of the vision-guided textual features to semantic-group textual features. With the help of relational knowledge transfer, VGKT is capable of aligning semantic-group textual features with corresponding visual features without external tools and complex pairwise interaction. Experimental results on two challenging benchmarks demonstrate its superiority over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
文本基于人体搜索（TBPS）目的是 retrieve图像指定的人体文本描述。为TBPS提取细腻的本地特征并进行modal的同步是关键。现有方法通过外部工具或重量级modal交互来实现明确的modal同步细腻特征，这是不效率和时间consuming。在这种工作中，我们提议一种视觉引导 semantic-group 网络（VGSG） для文本基于人体搜索，以提取Well-aligned的视觉和文本特征。在我们的VGSG中，我们开发了一种Semantic-Group Textual Learning（SGTL）模块和一种视觉引导知识传输（VGKT）模块，以提取文本本地特征。在SGTL中，我们基于语言表达的semanticcue分组文本特征从通道维度，以便获得本地文本表示。在VGKT中，我们employn了视觉引导注意力来提取视觉相关的文本特征，这些特征是自然地与视觉cue相关，并被称为视觉引导的文本特征。此外，我们设计了一种关系知识传输，包括一种视觉语言相似传输和一种类 probablity传输，以适应ively propagate vision-guided文本特征的信息到semantic-group文本特征。通过关系知识传输，VGKT能够将semantic-group文本特征与相应的视觉特征同步，不需要外部工具和复杂的对抗式交互。实验结果表明，我们的方法在两个复杂的benchmark上表现出色，与当前方法相比有superiority。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Performance-Prediction-for-Deep-Convolutional-Long-Short-Term-Memory-Networks"><a href="#Temporal-Performance-Prediction-for-Deep-Convolutional-Long-Short-Term-Memory-Networks" class="headerlink" title="Temporal Performance Prediction for Deep Convolutional Long Short-Term Memory Networks"></a>Temporal Performance Prediction for Deep Convolutional Long Short-Term Memory Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07477">http://arxiv.org/abs/2311.07477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Fieback, Bidya Dash, Jakob Spiegelberg, Hanno Gottschalk</li>
<li>for: 这篇论文主要目标是量化深度 semantic segmentation 网络的预测uncertainty，以便在安全关键任务中使用。</li>
<li>methods: 这篇论文使用了 convolutional long short-term memory 网络，可以不仅提供semantic segmentation，还可以预测下一步的segmentation。这些模型使用细胞状态来广播previous data中的信息，通过接受时间序列输入来预测未来一步或更多步。</li>
<li>results: 这篇论文提出了一种temporal postprocessing方法，可以估算 convolutional long short-term memory 网络的预测性能，包括预测 intersect over union 值或者 классификация为 zero 或大于 zero。为此，我们创建了基于 temporal cell state 的输入指标，并研究了不同的模型来估算预测质量基于这些指标。我们还研究了考虑 cell states 的数量对提posed metrics 的影响。<details>
<summary>Abstract</summary>
Quantifying predictive uncertainty of deep semantic segmentation networks is essential in safety-critical tasks. In applications like autonomous driving, where video data is available, convolutional long short-term memory networks are capable of not only providing semantic segmentations but also predicting the segmentations of the next timesteps. These models use cell states to broadcast information from previous data by taking a time series of inputs to predict one or even further steps into the future. We present a temporal postprocessing method which estimates the prediction performance of convolutional long short-term memory networks by either predicting the intersection over union of predicted and ground truth segments or classifying between intersection over union being equal to zero or greater than zero. To this end, we create temporal cell state-based input metrics per segment and investigate different models for the estimation of the predictive quality based on these metrics. We further study the influence of the number of considered cell states for the proposed metrics.
</details>
<details>
<summary>摘要</summary>
深度semantic segmentation网络的预测不确定性评估是安全关键任务中的一项重要任务。在自动驾驶应用中，where video数据可用，卷积长短期记忆网络可以不仅提供semantic segmentation，还可以预测下一步的segmentation。这些模型使用细胞状态来广播从前一个数据中的信息，通过接受一系列输入来预测一步或更多步的未来。我们提出了时间Postprocessing方法，该方法可以估计卷积长短期记忆网络的预测性能，通过预测 predicted和实际数据中的交集union的交集或者判断intersection over union是否大于或等于零来实现。为此，我们创建了时间细胞状态基于的输入度量，并研究不同的模型来估计预测质量基于这些度量。我们进一步研究了考虑的细胞状态数量对提posed度量的影响。
</details></li>
</ul>
<hr>
<h2 id="Masked-Face-Dataset-Generation-and-Masked-Face-Recognition"><a href="#Masked-Face-Dataset-Generation-and-Masked-Face-Recognition" class="headerlink" title="Masked Face Dataset Generation and Masked Face Recognition"></a>Masked Face Dataset Generation and Masked Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07475">http://arxiv.org/abs/2311.07475</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luisrui/seeing-ai-system">https://github.com/luisrui/seeing-ai-system</a></li>
<li>paper_authors: Rui Cai, Xuying Ning, Peter N. Belhumeur</li>
<li>for: 本研究旨在解决post-epidemic era面罩妨碍普通面 recognition问题。</li>
<li>methods: 研究人员创建了更加具有挑战性的面罩人脸数据集，并使用了自适应的数据增强策略来提高模型在实际场景中的性能。</li>
<li>results: 研究人员通过自适应模型和数据增强策略，在50个人脸数据集上实现了最高的95%的测试精度。<details>
<summary>Abstract</summary>
In the post-pandemic era, wearing face masks has posed great challenge to the ordinary face recognition. In the previous study, researchers has applied pretrained VGG16, and ResNet50 to extract features on the elaborate curated existing masked face recognition (MFR) datasets, RMFRD and SMFRD. To make the model more adaptable to the real world situation where the sample size is smaller and the camera environment has greater changes, we created a more challenging masked face dataset ourselves, by selecting 50 identities with 1702 images from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks through key point detection. The another part of our study is to solve the masked face recognition problem, and we chose models by referring to the former state of the art results, instead of directly using pretrained models, we fine tuned the model on our new dataset and use the last linear layer to do the classification directly. Furthermore, we proposed using data augmentation strategy to further increase the test accuracy, and fine tuned a new networks beyond the former study, one of the most SOTA networks, Inception ResNet v1. The best test accuracy on 50 identity MFR has achieved 95%.
</details>
<details>
<summary>摘要</summary>
在post-epidemic era，面具穿戴对于普通面Recognition posed great challenge。在前一项研究中，研究人员使用预训练的VGG16和ResNet50提取特征从 elaborate curated existing masked face recognition（MFR）数据集RMFRD和SMFRD。为了让模型更适应实际世界中的小样本大小和摄像头环境更大的变化，我们创建了更加挑战性的面具face数据集，选择了50个人的1702张图像从Labelled Faces in the Wild（LFW）数据集，并通过关键点检测来生成模拟面具。另一方面，我们解决了面具认知问题，选择了根据前一项state of the art结果进行选择，而不是直接使用预训练模型，我们在我们新数据集上进行了微调，并使用最后的直方向来进行直接分类。此外，我们提议使用数据增强策略来进一步提高测试准确率，并微调了新的网络，其中一个最新的SOTA网络，Inception ResNet v1。我们在50个人MFR测试中获得了95%的最高测试准确率。
</details></li>
</ul>
<hr>
<h2 id="Language-Grounded-QFormer-for-Efficient-Vision-Language-Understanding"><a href="#Language-Grounded-QFormer-for-Efficient-Vision-Language-Understanding" class="headerlink" title="Language Grounded QFormer for Efficient Vision Language Understanding"></a>Language Grounded QFormer for Efficient Vision Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07449">http://arxiv.org/abs/2311.07449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moulik Choraria, Nitesh Sekhar, Yue Wu, Xu Zhang, Prateek Singhal, Lav R. Varshney</li>
<li>for: 这篇论文的目的是提出更有效的视频语言匹配方法，以提高视频语言模型的预训练效率。</li>
<li>methods: 该论文使用了Query Transformer（QFormer）方法，启发自BLIP-2模型，通过bridging frozen modalities来实现视频语言对应。</li>
<li>results:  compared to现有基elines，该方法提高了视频语言预训练的效率。<details>
<summary>Abstract</summary>
Large-scale pretraining and instruction tuning have been successful for training general-purpose language models with broad competencies. However, extending to general-purpose vision-language models is challenging due to the distributional diversity in visual inputs. A recent line of work explores vision-language instruction tuning, taking inspiration from the Query Transformer (QFormer) approach proposed in BLIP-2 models for bridging frozen modalities. However, these approaches rely heavily on large-scale multi-modal pretraining for representation learning before eventual finetuning, incurring a huge computational overhead, poor scaling, and limited accessibility. To that end, we propose a more efficient method for QFormer-based vision-language alignment and demonstrate the effectiveness of our strategy compared to existing baselines in improving the efficiency of vision-language pretraining.
</details>
<details>
<summary>摘要</summary>
大规模预训练和指导调整已经成功地训练了通用语言模型，但扩展到通用视语模型却存在许多挑战，主要是因为视觉输入的分布差异。现有的一些研究借鉴Query Transformer（QFormer）方法，在BLIP-2模型中实现停滞模式之间的桥接。然而，这些方法均依赖于大规模多modal预训练，以便 eventually fine-tuning，导致计算开销巨大、缓慢、可达性有限。为了解决这个问题，我们提出了一种更高效的QFormer基于视语Alignment方法，并证明了我们的策略与现有基准相比，可以提高视语预训练的效率。
</details></li>
</ul>
<hr>
<h2 id="Story-to-Motion-Synthesizing-Infinite-and-Controllable-Character-Animation-from-Long-Text"><a href="#Story-to-Motion-Synthesizing-Infinite-and-Controllable-Character-Animation-from-Long-Text" class="headerlink" title="Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text"></a>Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07446">http://arxiv.org/abs/2311.07446</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongfei Qing, Zhongang Cai, Zhitao Yang, Lei Yang</li>
<li>for: 这个研究的目的是生成基于故事的自然人体动作，以便改变动画、游戏和电影等领域的ланд膝景。</li>
<li>methods: 该研究使用了当代大语言模型作为文本驱动动作调度器，EXTRACTING a series of (text, position, duration) pairs from long text，并开发了文本驱动动作检索方案，该方案包括动作匹配和动作Semantics和轨迹约束。</li>
<li>results: 该系统可以生成可控的无限长动作和轨迹，与输入文本保持一致。该系统在三个不同的子任务中（轨迹跟踪、时间动作组合和动作混合）都超过了之前的状态 искусственный动作生成方法。<details>
<summary>Abstract</summary>
Generating natural human motion from a story has the potential to transform the landscape of animation, gaming, and film industries. A new and challenging task, Story-to-Motion, arises when characters are required to move to various locations and perform specific motions based on a long text description. This task demands a fusion of low-level control (trajectories) and high-level control (motion semantics). Previous works in character control and text-to-motion have addressed related aspects, yet a comprehensive solution remains elusive: character control methods do not handle text description, whereas text-to-motion methods lack position constraints and often produce unstable motions. In light of these limitations, we propose a novel system that generates controllable, infinitely long motions and trajectories aligned with the input text. (1) We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text. (2) We develop a text-driven motion retrieval scheme that incorporates motion matching with motion semantic and trajectory constraints. (3) We design a progressive mask transformer that addresses common artifacts in the transition motion such as unnatural pose and foot sliding. Beyond its pioneering role as the first comprehensive solution for Story-to-Motion, our system undergoes evaluation across three distinct sub-tasks: trajectory following, temporal action composition, and motion blending, where it outperforms previous state-of-the-art motion synthesis methods across the board. Homepage: https://story2motion.github.io/.
</details>
<details>
<summary>摘要</summary>
将文本转换为人类动作的潜在潜力可能会改变动画、游戏和电影产业的景观。一个新而具有挑战性的任务是故事到动作（Story-to-Motion），当角色需要根据长文本描述移动到不同的位置并执行特定的动作时，这个任务需要文本驱动的动作控制和高级控制之间的融合。现有的角色控制和文本到动作方法已经解决了相关的问题，但是一个全面的解决方案仍然未知：角色控制方法不能处理文本描述，而文本到动作方法缺乏位置约束并经常产生不稳定的动作。为了解决这些限制，我们提出了一种新的系统，该系统可以根据输入文本生成可控的无限长动作和轨迹，并与文本保持一致。我们利用当代大型自然语言模型作为文本驱动动作计划器，从长文本中提取一系列（文本、位置、持续时间）对。我们开发了一种文本驱动动作检索方法，该方法将包括动作匹配、动作Semantics和轨迹约束。我们还设计了一种进步的掩蔽变换器，以解决通常出现在过渡动作中的不自然姿势和脚滑动。我们的系统不仅是Story-to-Motion的首个全面解决方案，还在三个不同的子任务上进行评估：轨迹跟踪、时间动作组合和动作混合，在所有的情况下都超越了先前的动画生成方法。更多信息请访问我们的主页：<https://story2motion.github.io/>。
</details></li>
</ul>
<hr>
<h2 id="Supersampling-of-Data-from-Structured-light-Scanner-with-Deep-Learning"><a href="#Supersampling-of-Data-from-Structured-light-Scanner-with-Deep-Learning" class="headerlink" title="Supersampling of Data from Structured-light Scanner with Deep Learning"></a>Supersampling of Data from Structured-light Scanner with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07432">http://arxiv.org/abs/2311.07432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Melicherčík, Lukáš Gajdošech, Viktor Kocur, Martin Madaras</li>
<li>for: 提高3D摄像机获得的深度图的分辨率</li>
<li>methods: 修改FDSR和DKN深度学习模型以适应高分辨率数据，并实现数据预处理技术以稳定训练。</li>
<li>results: 使用自定义 dataset 对 1200 个 3D 扫描进行训练，并通过质量和量化指标评估高分辨率 depth map 的结果。<details>
<summary>Abstract</summary>
This paper focuses on increasing the resolution of depth maps obtained from 3D cameras using structured light technology. Two deep learning models FDSR and DKN are modified to work with high-resolution data, and data pre-processing techniques are implemented for stable training. The models are trained on our custom dataset of 1200 3D scans. The resulting high-resolution depth maps are evaluated using qualitative and quantitative metrics. The approach for depth map upsampling offers benefits such as reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at the lower resolution and upsampling the resulting depth map or increasing the resolution of a point cloud captured in lower resolution by a cheaper device. The experiments demonstrate that the FDSR model excels in terms of faster processing time, making it a suitable choice for applications where speed is crucial. On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy.
</details>
<details>
<summary>摘要</summary>
The proposed approach for depth map upsampling offers several benefits, including reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at a lower resolution, and then upsampling the resulting depth map. Additionally, the approach can increase the resolution of a point cloud captured in lower resolution by a cheaper device.Experiments demonstrate that the FDSR model is faster and more suitable for applications where speed is crucial. On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy.
</details></li>
</ul>
<hr>
<h2 id="Optimising-Human-AI-Collaboration-by-Learning-Convincing-Explanations"><a href="#Optimising-Human-AI-Collaboration-by-Learning-Convincing-Explanations" class="headerlink" title="Optimising Human-AI Collaboration by Learning Convincing Explanations"></a>Optimising Human-AI Collaboration by Learning Convincing Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07426">http://arxiv.org/abs/2311.07426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex J. Chan, Alihan Huyuk, Mihaela van der Schaar</li>
<li>for: 本研究旨在开发一种可以协助人类做出决策的协同系统，以确保系统的安全性和性能。</li>
<li>methods: 本研究使用的方法包括开发一种名为Ardent的算法，可以快速学习人类对解释的喜好，并根据这些喜好为人类提供最有用的解释。</li>
<li>results: 研究结果表明，使用Ardent算法可以有效地改善决策过程中的透明度和责任感，并且在一个复杂的图像分类任务中表现出了适用性。<details>
<summary>Abstract</summary>
Machine learning models are being increasingly deployed to take, or assist in taking, complicated and high-impact decisions, from quasi-autonomous vehicles to clinical decision support systems. This poses challenges, particularly when models have hard-to-detect failure modes and are able to take actions without oversight. In order to handle this challenge, we propose a method for a collaborative system that remains safe by having a human ultimately making decisions, while giving the model the best opportunity to convince and debate them with interpretable explanations. However, the most helpful explanation varies among individuals and may be inconsistent across stated preferences. To this end we develop an algorithm, Ardent, to efficiently learn a ranking through interaction and best assist humans complete a task. By utilising a collaborative approach, we can ensure safety and improve performance while addressing transparency and accountability concerns. Ardent enables efficient and effective decision-making by adapting to individual preferences for explanations, which we validate through extensive simulations alongside a user study involving a challenging image classification task, demonstrating consistent improvement over competing systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-semi-supervised-segmentation-with-timestep-ensembling-diffusion-models"><a href="#Robust-semi-supervised-segmentation-with-timestep-ensembling-diffusion-models" class="headerlink" title="Robust semi-supervised segmentation with timestep ensembling diffusion models"></a>Robust semi-supervised segmentation with timestep ensembling diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07421">http://arxiv.org/abs/2311.07421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Margherita Rosnati, Melanie Roschewitz, Ben Glocker</li>
<li>For: This paper is written for the task of semi-supervised medical image segmentation, with a focus on domain generalization.* Methods: The paper uses denoising diffusion probabilistic models (DDPMs) to model the distribution of natural images and perform image segmentation. The authors propose an improved ensemble scheme that leverages information-dense small steps and the regularizing effect of larger steps to generate predictions.* Results: The paper shows that the proposed method significantly outperforms other methods in domain-shifted settings while retaining competitive performance in-domain. The results highlight the potential of DDPMs for semi-supervised medical image segmentation and provide insights into optimising their performance under domain shift.Here’s the Chinese translation of the three pieces of information:* For: 这篇论文是为 semi-supervised 医疗图像分割任务而写的，尤其是在领域映射上。* Methods: 该论文使用 denoising diffusion probabilistic models (DDPMs) 来模型自然图像的分布，并用这些模型进行图像分割。作者们提出了一种改进的ensemble scheme，该 scheme利用小步骤中的信息压缩和大步骤的正则化效果来生成预测。* Results: 论文显示，提出的方法在领域转换下表现出色，同时保持了在领域内的竞争性表现。结果表明 DDPMs 在 semi-supervised 医疗图像分割中具有潜在的潜力，并提供了优化其性能下领域转换的灵感。<details>
<summary>Abstract</summary>
Medical image segmentation is a challenging task, made more difficult by many datasets' limited size and annotations. Denoising diffusion probabilistic models (DDPM) have recently shown promise in modelling the distribution of natural images and were successfully applied to various medical imaging tasks. This work focuses on semi-supervised image segmentation using diffusion models, particularly addressing domain generalisation. Firstly, we demonstrate that smaller diffusion steps generate latent representations that are more robust for downstream tasks than larger steps. Secondly, we use this insight to propose an improved esembling scheme that leverages information-dense small steps and the regularising effect of larger steps to generate predictions. Our model shows significantly better performance in domain-shifted settings while retaining competitive performance in-domain. Overall, this work highlights the potential of DDPMs for semi-supervised medical image segmentation and provides insights into optimising their performance under domain shift.
</details>
<details>
<summary>摘要</summary>
医学图像分割是一项具有挑战性的任务，由于许多数据集的限制性和标注而更加困难。在最近的研究中，涉泳扩散概率模型（DDPM）已经表现出模拟自然图像的分布的潜力，并在各种医学成像任务中得到了成功应用。本研究将关注 semi-supervised 图像分割使用涉泳模型，特别是域泛化。我们首先证明了小步 diffusion 生成的潜在表示更加鲁棒，用于下游任务的下游任务。其次，我们利用这一点来提出一种改进的拼接方案，利用信息密集的小步和大步的约束效果来生成预测。我们的模型在域Shift 的设置下表现出显著改善，同时保持了在预测中的竞争性。总之，这种研究高亮了 DDPM 在 semi-supervised 医学图像分割中的潜力，并提供了在域Shift 下优化其性能的 Insight。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Backdoors-within-Deep-Neural-Networks-in-Data-limited-Configuration"><a href="#Mitigating-Backdoors-within-Deep-Neural-Networks-in-Data-limited-Configuration" class="headerlink" title="Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration"></a>Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07417">http://arxiv.org/abs/2311.07417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soroush Hashemifar, Saeed Parsa, Morteza Zakeri-Nasrabadi</li>
<li>for: 防止深度神经网络（DNN）被黑客攻击，提高DNN的安全性。</li>
<li>methods: 利用潜在恶意 neuron 的特征，实时检测 DNN 中潜在攻击的诡计。</li>
<li>results: 对 CIFAR-10 数据集进行实验，提出了一种基于 activation values、weights 和 neuron 之间关系的潜在攻击检测方法，可以降低攻击成功的机会超过 50%，同时不会对模型性能产生显著影响。此外，该方法比基准方法快三倍。<details>
<summary>Abstract</summary>
As the capacity of deep neural networks (DNNs) increases, their need for huge amounts of data significantly grows. A common practice is to outsource the training process or collect more data over the Internet, which introduces the risks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data while behaving maliciously once a trigger is injected into a sample at the test time. In such cases, the defender faces multiple difficulties. First, the available clean dataset may not be sufficient for fine-tuning and recovering the backdoored DNN. Second, it is impossible to recover the trigger in many real-world applications without information about it. In this paper, we formulate some characteristics of poisoned neurons. This backdoor suspiciousness score can rank network neurons according to their activation values, weights, and their relationship with other neurons in the same layer. Our experiments indicate the proposed method decreases the chance of attacks being successful by more than 50% with a tiny clean dataset, i.e., ten clean samples for the CIFAR-10 dataset, without significantly deteriorating the model's performance. Moreover, the proposed method runs three times as fast as baselines.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）的容量增长，需要的数据量也在增长。一种常见的做法是外部进行训练过程或者在互联网上收集更多数据，这会引入恶意修改DNN的风险。一个恶意修改后的DNN会在测试时采样中注入触发器后表现出错误行为，对于防御者而言，存在多种困难。首先，可用的干净数据集可能不够用于精度调整和恢复恶意修改后的DNN。其次，在实际应用中，无法回收触发器的信息，无法准确地恢复恶意修改后的DNN。在这篇论文中，我们描述了恶意修改后的神经元特征。我们提出的方法可以根据神经元的活动值、权重和相同层中其他神经元的关系，对神经元进行恶意修改检测。我们的实验结果表明，我们的方法可以在使用十个干净样本（CIFAR-10数据集）的情况下，降低攻击成功的机会超过50%，而无需对模型性能产生显著的影响。此外，我们的方法比基线方法快三倍。
</details></li>
</ul>
<hr>
<h2 id="FIRST-A-Million-Entry-Dataset-for-Text-Driven-Fashion-Synthesis-and-Design"><a href="#FIRST-A-Million-Entry-Dataset-for-Text-Driven-Fashion-Synthesis-and-Design" class="headerlink" title="FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and Design"></a>FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07414">http://arxiv.org/abs/2311.07414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Huang, Yihao Li, Dong Pei, Jiapeng Zhou, Xuliang Ning, Jianlin Han, Xiaoguang Han, Xuejun Chen</li>
<li>for: 提高人工智能生成内容(AIGC)中的时尚设计和生成能力，推动传统时尚业的革新和发展。</li>
<li>methods: 介绍了一个新的高分辨率时尚图像和详细结构化文本描述（FIRST）集合，包含一百万个时尚图像和多个层次结构的文本描述。</li>
<li>results: 经过实验表明，FIRST 集合是必需的 для进一步提高时尚生成和设计系统的创造力和想象力。<details>
<summary>Abstract</summary>
Text-driven fashion synthesis and design is an extremely valuable part of artificial intelligence generative content(AIGC), which has the potential to propel a tremendous revolution in the traditional fashion industry. To advance the research on text-driven fashion synthesis and design, we introduce a new dataset comprising a million high-resolution fashion images with rich structured textual(FIRST) descriptions. In the FIRST, there is a wide range of attire categories and each image-paired textual description is organized at multiple hierarchical levels. Experiments on prevalent generative models trained over FISRT show the necessity of FIRST. We invite the community to further develop more intelligent fashion synthesis and design systems that make fashion design more creative and imaginative based on our dataset. The dataset will be released soon.
</details>
<details>
<summary>摘要</summary>
文本驱动时尚合成和设计是人工智能生成内容(AIGC)中非常有价值的一部分，有potential可以驱动传统时尚业的巨大革命。为进一步推进文本驱动时尚合成和设计的研究，我们介绍了一个新的数据集，包含100万高分辨率时尚图片和详细结构化文本描述(FIRST)。在FIRST中，有很多服装类别，每个图片对应的文本描述分别组织在多个层次结构中。经过现有的生成模型在FIRST上训练，我们发现了FIRST的必要性。我们邀请社区为我们的数据集进一步开发更智能的时尚合成和设计系统，使时尚设计更有创意和想象力。数据集即将发布。
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatic-Honey-Bee-Flower-Patch-Assays-with-Paint-Marking-Re-Identification"><a href="#Towards-Automatic-Honey-Bee-Flower-Patch-Assays-with-Paint-Marking-Re-Identification" class="headerlink" title="Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking Re-Identification"></a>Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07407">http://arxiv.org/abs/2311.07407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Meyers, Josué Rodríguez Cordero, Carlos Corrada Bravo, Fanfan Noel, José Agosto-Rivera, Tugrul Giray, Rémi Mégret</li>
<li>for: 这 paper 用于 automatize the analysis of behavioral assays involving honey bees in the field, where marking has to be as lightweight as possible.</li>
<li>methods: 这 paper 使用 paint markings 和 contrastive learning with a ResNet backbone 和 triplet loss 来实现 bees 的 re-identification.</li>
<li>results: 这 paper 提供了一个 novel dataset for bees re-identification with paint-markings, 并实现了 almost perfect recognition in closed setting where identities are known in advance.  Additionally, the paper shows the potential to fully automate the visit detection and provides preliminary results of compute time for future real-time deployment in the field on an edge device.<details>
<summary>Abstract</summary>
In this paper, we show that paint markings are a feasible approach to automatize the analysis of behavioral assays involving honey bees in the field where marking has to be as lightweight as possible. We contribute a novel dataset for bees re-identification with paint-markings with 4392 images and 27 identities. Contrastive learning with a ResNet backbone and triplet loss led to identity representation features with almost perfect recognition in closed setting where identities are known in advance. Diverse experiments evaluate the capability to generalize to separate IDs, and show the impact of using different body parts for identification, such as using the unmarked abdomen only. In addition, we show the potential to fully automate the visit detection and provide preliminary results of compute time for future real-time deployment in the field on an edge device.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们展示了使用涂抹标记来自动化野外Behavioral assays中的蜂群行为分析是可行的。我们提供了一个新的涂抹标记数据集，包含4392张图像和27个标识。对比学习使用ResNet底层和 triplet损失，可以从closed设定中获得几乎完美的识别结果。我们还进行了多种实验，以评估这些特征的泛化能力和使用不同的身体部分进行识别的影响。此外，我们还展示了可以全自动化访问检测，并提供了未来在野外实时部署的计算时间预算。
</details></li>
</ul>
<hr>
<h2 id="Processing-and-Segmentation-of-Human-Teeth-from-2D-Images-using-Weakly-Supervised-Learning"><a href="#Processing-and-Segmentation-of-Human-Teeth-from-2D-Images-using-Weakly-Supervised-Learning" class="headerlink" title="Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning"></a>Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07398">http://arxiv.org/abs/2311.07398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomáš Kunzo, Viktor Kocur, Lukáš Gajdošech, Martin Madaras</li>
<li>For: 这个研究旨在提出一种弱地监督的牙齿分类方法，以减少手动标注的需求。* Methods: 我们使用热点检测网络的输出热点和中间特征图库来引导分类过程。* Results: 我们在TriDental数据集上实现了比前方法更高的准确性和适居性。<details>
<summary>Abstract</summary>
Teeth segmentation is an essential task in dental image analysis for accurate diagnosis and treatment planning. While supervised deep learning methods can be utilized for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.
</details>
<details>
<summary>摘要</summary>
teeth 分割是dentistry 图像分析中的一项关键任务，以确定精确的诊断和治疗规划。 although supervised deep learning methods can be used for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.Here's the translation in Traditional Chinese: teeth 分割是dentistry 图像分析中的一项关键任务，以确定精确的诊断和治疗规划。 although supervised deep learning methods can be used for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Significance-of-Outdoor-Advertising-from-Driver’s-Perspective-Using-Computer-Vision"><a href="#Evaluating-the-Significance-of-Outdoor-Advertising-from-Driver’s-Perspective-Using-Computer-Vision" class="headerlink" title="Evaluating the Significance of Outdoor Advertising from Driver’s Perspective Using Computer Vision"></a>Evaluating the Significance of Outdoor Advertising from Driver’s Perspective Using Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07390">http://arxiv.org/abs/2311.07390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zuzana Černeková, Zuzana Berger Haladová, Ján Špirka, Viktor Kocur</li>
<li>for: 评估路边广告的重要性，预防 drivers 的分心驾驶</li>
<li>methods: 使用 YOLOv8 检测器和不同的对象跟踪方法，并使用随机森林分类器将广告牌分为三类基于驾驶员围注时间、吸引力和大小</li>
<li>results: 获得了 38.5 HOTA 的最佳方法，并在测试集上达到 75.8% 的测试精度<details>
<summary>Abstract</summary>
Outdoor advertising, such as roadside billboards, plays a significant role in marketing campaigns but can also be a distraction for drivers, potentially leading to accidents. In this study, we propose a pipeline for evaluating the significance of roadside billboards in videos captured from a driver's perspective. We have collected and annotated a new BillboardLamac dataset, comprising eight videos captured by drivers driving through a predefined path wearing eye-tracking devices. The dataset includes annotations of billboards, including 154 unique IDs and 155 thousand bounding boxes, as well as eye fixation data. We evaluate various object tracking methods in combination with a YOLOv8 detector to identify billboard advertisements with the best approach achieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forest classifier to classify billboards into three classes based on the length of driver fixations achieving 75.8% test accuracy. An analysis of the trained classifier reveals that the duration of billboard visibility, its saliency, and size are the most influential features when assessing billboard significance.
</details>
<details>
<summary>摘要</summary>
外部广告，如道路旁的大型广告牌，在市场推广活动中扮演着重要的角色，但也可能对 drivers 引起干扰，导致交通事故。在这项研究中，我们提出了一个用于评估路边大型广告的管道。我们收集了和标注了一个新的 BillboardLamac 数据集，包括八个驾驶员驾驶过定制路线，并且穿着眼动追踪设备拍摄的八个视频。该数据集包括了大型广告的标识符、154个唯一标识符和155千个 bounding box，以及眼动数据。我们评估了多种对象跟踪方法，并结合 YOLOv8 检测器来识别大型广告，最佳方法的 HOTA 得分为 38.5。此外，我们训练了随机森林分类器，以类别大型广告为三种基于驾驶员固定时间的长度、吸引力和大小。分析训练的分类器显示，大型广告的可见时间、吸引力和大小是评估大型广告重要性的最重要的特征。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-developmental-and-brain-disorders-via-graph-convolutional-aggregation"><a href="#Classification-of-developmental-and-brain-disorders-via-graph-convolutional-aggregation" class="headerlink" title="Classification of developmental and brain disorders via graph convolutional aggregation"></a>Classification of developmental and brain disorders via graph convolutional aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07370">http://arxiv.org/abs/2311.07370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibrahim Salim, A. Ben Hamza</li>
<li>for: 本研究旨在提高脑疾病预测性能，特别是在脑发育和脑退化疾病预测方面。</li>
<li>methods: 本研究提出了一种协调 нормализа化图 convolutional neural network，通过图像和非图像特征的组合，以及跳过连接和标识映射，以学习图节点表示。</li>
<li>results: 对两个大型数据集（ABIDE和ADNI）进行了比较，研究结果显示，与最近的基线方法相比，该方法在预测自闭症症和阿尔ц海默病等脑疾病方面达到了Relative improvement of 50%和13.56%。<details>
<summary>Abstract</summary>
While graph convolution based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders. In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping. The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders. Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning. We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer's disease, respectively. Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks on ABIDE and ADNI, respectively.
</details>
<details>
<summary>摘要</summary>
而 graph convolution based 方法在图像表示学习中已经成为了标准，但它们在诊断脑病任务中的应用还很有限，特别是在脑发育和脑退化性疾病的分类中。在这篇论文中，我们提出了一种归并normalization图 convolutional neural network，通过图像采样中的归并和跳过连接，以及标识映射来学习图节点表示。我们的模型通过将图节点和边分别归并到图节点和边上，并将各种影像和非影像特征集成到图节点和边上，以提高预测能力和为脑病的内部机制提供整体视图。跳过连接使得输入特征直接流入网络的后 layer，而标识映射保持图的结构信息在特征学习过程中。我们对 Autism Brain Imaging Data Exchange（ABIDE）和 Alzheimer's Disease Neuroimaging Initiative（ADNI）两个大数据集进行了比较，并与最近的基eline方法进行了比较。实验结果表明，我们的方法在 ABIDE 和 ADNI 上的分类精度有50%和13.56%的提高，相比于图 convolutional networks。
</details></li>
</ul>
<hr>
<h2 id="ActiveDC-Distribution-Calibration-for-Active-Finetuning"><a href="#ActiveDC-Distribution-Calibration-for-Active-Finetuning" class="headerlink" title="ActiveDC: Distribution Calibration for Active Finetuning"></a>ActiveDC: Distribution Calibration for Active Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07634">http://arxiv.org/abs/2311.07634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenshuai Xu, Zhenhui Hu, Yu Lu, Jinzhou Meng, Qingjie Liu, Yunhong Wang</li>
<li>for: 这 paper 是关于 active finetuning 的研究，具体来说是如何选择用于精度 tuning 的数据subset，以避免模型过拟合。</li>
<li>methods: 这 paper 提出了一种新的方法 called ActiveDC，它首先选择用于精度 tuning 的数据subset，然后对这些数据进行分布准确化，以使模型在不同的 sampling ratio 下表现更好。</li>
<li>results: 根据 paper 的实验结果，ActiveDC 在三个图像分类任务中均表现出色，特别是当 sampling ratio 较低时，与基eline的性能提升可达 10%。<details>
<summary>Abstract</summary>
The pretraining-finetuning paradigm has gained popularity in various computer vision tasks. In this paradigm, the emergence of active finetuning arises due to the abundance of large-scale data and costly annotation requirements. Active finetuning involves selecting a subset of data from an unlabeled pool for annotation, facilitating subsequent finetuning. However, the use of a limited number of training samples can lead to a biased distribution, potentially resulting in model overfitting. In this paper, we propose a new method called ActiveDC for the active finetuning tasks. Firstly, we select samples for annotation by optimizing the distribution similarity between the subset to be selected and the entire unlabeled pool in continuous space. Secondly, we calibrate the distribution of the selected samples by exploiting implicit category information in the unlabeled pool. The feature visualization provides an intuitive sense of the effectiveness of our approach to distribution calibration. We conducted extensive experiments on three image classification datasets with different sampling ratios. The results indicate that ActiveDC consistently outperforms the baseline performance in all image classification tasks. The improvement is particularly significant when the sampling ratio is low, with performance gains of up to 10%. Our code will be released.
</details>
<details>
<summary>摘要</summary>
“强化-微调”方法在不同的计算机视觉任务中得到了广泛的应用。在这种方法中，由于大规模数据和注解成本的增加，出现了活跃微调的问题。活跃微调是选择未标注 pool 中的一 subset 进行注解，以便后续微调。然而，使用有限的训练样本可能会导致模型过拟合。在这篇论文中，我们提出了一种新的方法called ActiveDC，用于活跃微调任务。首先，我们通过优化未标注 pool 中 subset 的分布相似性来选择需要注解的样本。其次，我们利用未标注 pool 中的隐藏类信息来准确化选择的样本的分布。图像可视化提供了对我们方法的分布准确化效果的直观感。我们在三个图像分类任务中进行了广泛的实验，结果表明，ActiveDC 在所有图像分类任务中具有比基eline性能更高的表现。具体来说，当采样比率低时，ActiveDC 的表现提升可达 10%。我们将代码发布。
</details></li>
</ul>
<hr>
<h2 id="Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><a href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud" class="headerlink" title="Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud"></a>Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07357">http://arxiv.org/abs/2311.07357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pit Henrich, Balázs Gyenes, Paul Maria Scheikl, Gerhard Neumann, Franziska Mathis-Ullrich</li>
<li>for: 对于扭变的实际物体进行弹性对象处理，我们经常想要与特定的对象部分进行交互，这些部分在非扭变的模型中已经被定义。我们需要一种系统可以从感知数据中识别和定位这些部分。</li>
<li>methods: 我们提出了一种使用神经占用函数进行弹性对象注册，并在注册过程中学习对象分割。由于结果已经包含了分割信息，我们可以跳过注册步骤。</li>
<li>results: 我们在许多扭变物体的实际和模拟数据上进行测试，并证明了我们的方法可以强健地找到这些部分。我们还提出了一种简单的采样算法来生成更好的占用学习训练数据。<details>
<summary>Abstract</summary>
In deformable object manipulation, we often want to interact with specific segments of an object that are only defined in non-deformed models of the object. We thus require a system that can recognize and locate these segments in sensor data of deformed real world objects. This is normally done using deformable object registration, which is problem specific and complex to tune. Recent methods utilize neural occupancy functions to improve deformable object registration by registering to an object reconstruction. Going one step further, we propose a system that in addition to reconstruction learns segmentation of the reconstructed object. As the resulting output already contains the information about the segments, we can skip the registration process. Tested on a variety of deformable objects in simulation and the real world, we demonstrate that our method learns to robustly find these segments. We also introduce a simple sampling algorithm to generate better training data for occupancy learning.
</details>
<details>
<summary>摘要</summary>
在可变形物体操作中，我们经常希望与特定的物体段只在非变形模型中定义的段进行交互。因此，我们需要一个系统可以从感知数据中识别和定位这些段。通常通过不适应物体注册来实现这一点，但是这是特定问题和复杂的调整。现代方法使用神经占据函数来改进不适应物体注册，并在注册过程中学习对象重建。我们的方法会在此基础上进一步，不仅是重建物体，还会学习物体的分割。由于结果中已经包含了段的信息，因此我们可以跳过注册步骤。我们在模拟和实际场景中测试了这种方法，并证明我们的方法可以坚定地找到这些段。我们还介绍了一种简单的采样算法，用于生成更好的占据学习训练数据。
</details></li>
</ul>
<hr>
<h2 id="Deformable-Groupwise-Registration-Using-a-Locally-Low-Rank-Dissimilarity-Metric-for-Myocardial-Strain-Estimation-from-Cardiac-Cine-MRI-Images"><a href="#Deformable-Groupwise-Registration-Using-a-Locally-Low-Rank-Dissimilarity-Metric-for-Myocardial-Strain-Estimation-from-Cardiac-Cine-MRI-Images" class="headerlink" title="Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images"></a>Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07348">http://arxiv.org/abs/2311.07348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Chen, Juan Gao, Chenxi Hu</li>
<li>For: The paper is written for cardiac function assessment using cardiac cine MRI images.* Methods: The proposed method uses a deformable groupwise registration-based two-step strategy with a locally low-rank (LLR) dissimilarity metric for CMR-FT.* Results: The proposed method achieved more accurate tracking and strain estimation compared to other methods, especially in late diastole, and may facilitate more accurate assessment of cardiac dysfunction.<details>
<summary>Abstract</summary>
Objective: Cardiovascular magnetic resonance-feature tracking (CMR-FT) represents a group of methods for myocardial strain estimation from cardiac cine MRI images. Established CMR-FT methods are mainly based on optical flow or pairwise registration. However, these methods suffer from either inaccurate estimation of large motion or drift effect caused by accumulative tracking errors. In this work, we propose a deformable groupwise registration method using a locally low-rank (LLR) dissimilarity metric for CMR-FT. Methods: The proposed method (Groupwise-LLR) tracks the feature points by a groupwise registration-based two-step strategy. Unlike the globally low-rank (GLR) dissimilarity metric, the proposed LLR metric imposes low-rankness on local image patches rather than the whole image. We quantitatively compared Groupwise-LLR with the Farneback optical flow, a pairwise registration method, and a GLR-based groupwise registration method on simulated and in vivo datasets. Results: Results from the simulated dataset showed that Groupwise-LLR achieved more accurate tracking and strain estimation compared with the other methods. Results from the in vivo dataset showed that Groupwise-LLR achieved more accurate tracking and elimination of the drift effect in late-diastole. Inter-observer reproducibility of strain estimates was similar between all studied methods. Conclusion: The proposed method estimates myocardial strains more accurately due to the application of a groupwise registration-based tracking strategy and an LLR-based dissimilarity metric. Significance: The proposed CMR-FT method may facilitate more accurate estimation of myocardial strains, especially in diastole, for clinical assessments of cardiac dysfunction.
</details>
<details>
<summary>摘要</summary>
目的：卡地里尺骨磁共振成像-特征跟踪（CMR-FT）是一种基于卡地里磁共振成像图像的肌肉弹性测量方法。现有的CMR-FT方法主要基于光流或对应注册。但这些方法受到大动量或偏移效应的影响，导致测量不准确。在这项工作中，我们提出了一种可变地方法（Groupwise-LLR），使用本地低级（LLR）相似度度量进行群组注册。方法：Groupwise-LLR方法使用两步策略，首先使用光流或对应注册来跟踪特征点，然后使用LLR度量进行群组注册。与全图像的GLR度量不同，LLR度量在本地图像区域强制低级。我们对使用Farneback光流、对应注册方法和GLR基于的群组注册方法进行了量比较。结果：在模拟数据集上，Groupwise-LLR方法在跟踪和弹性测量方面表现更加准确，而在实验数据集上，Groupwise-LLR方法在晚 диастоле阶段消除了偏移效应。对于各种方法的幂等复制性，结果类似。结论：Groupwise-LLR方法可以更加准确地测量肌肉弹性，特别是在 диаastole阶段。意义：Groupwise-LLR方法可能为临床评估卡地里功能障碍提供更加准确的肌肉弹性测量。
</details></li>
</ul>
<hr>
<h2 id="Connecting-the-Dots-Graph-Neural-Network-Powered-Ensemble-and-Classification-of-Medical-Images"><a href="#Connecting-the-Dots-Graph-Neural-Network-Powered-Ensemble-and-Classification-of-Medical-Images" class="headerlink" title="Connecting the Dots: Graph Neural Network Powered Ensemble and Classification of Medical Images"></a>Connecting the Dots: Graph Neural Network Powered Ensemble and Classification of Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07321">http://arxiv.org/abs/2311.07321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aryan-at-ul/aics_2023_submission">https://github.com/aryan-at-ul/aics_2023_submission</a></li>
<li>paper_authors: Aryan Singh, Pepijn Van de Ven, Ciarán Eising, Patrick Denny</li>
<li>for: 这篇论文是为了提出一个可靠、经济可行且可扩展的医疗影像分类方法。</li>
<li>methods: 这篇论文使用了 Image Foresting Transform 来最佳化医疗影像的分割，然后将分割后的图像转换为 graf-structured 数据，使用 Graph Neural Networks (GNNs) 进行特征提取和关系建模。 ensemble 使用三种不同的 GNN 架构来提高其内模的稳定性。</li>
<li>results: 在这篇论文中，这种方法在验证targeting pneumonia classification 的任务中，较前一代的 Deep Neural Networks (DNNs) 高效，同时降低了 Parameters 的数量，从而降低了训练数据的成本和训练时间，并且减少了偏见。<details>
<summary>Abstract</summary>
Deep learning models have demonstrated remarkable results for various computer vision tasks, including the realm of medical imaging. However, their application in the medical domain is limited due to the requirement for large amounts of training data, which can be both challenging and expensive to obtain. To mitigate this, pre-trained models have been fine-tuned on domain-specific data, but such an approach can suffer from inductive biases. Furthermore, deep learning models struggle to learn the relationship between spatially distant features and their importance, as convolution operations treat all pixels equally. Pioneering a novel solution to this challenge, we employ the Image Foresting Transform to optimally segment images into superpixels. These superpixels are subsequently transformed into graph-structured data, enabling the proficient extraction of features and modeling of relationships using Graph Neural Networks (GNNs). Our method harnesses an ensemble of three distinct GNN architectures to boost its robustness. In our evaluations targeting pneumonia classification, our methodology surpassed prevailing Deep Neural Networks (DNNs) in performance, all while drastically cutting down on the parameter count. This not only trims down the expenses tied to data but also accelerates training and minimizes bias. Consequently, our proposition offers a sturdy, economically viable, and scalable strategy for medical image classification, significantly diminishing dependency on extensive training data sets.
</details>
<details>
<summary>摘要</summary>
深度学习模型在各种计算机视觉任务中表现出色，其中包括医疗影像领域。然而，它们在医疗领域的应用受到大量训练数据的限制，这些数据可能具有困难和成本高的获取。为此，人们通常使用预训练模型进行精度调整，但这种方法可能受到逻辑偏见的影响。另外，深度学习模型在图像中的特征之间关系学习不够，因为卷积操作对所有像素进行了平等的处理。为了解决这个挑战，我们提出了图像森林变换，用于优化图像分割成超像素。这些超像素然后被转换成图形结构数据，使得通过图形神经网络（GNN）进行特征提取和模型建立关系。我们的方法使用了三种不同的GNN架构 ensemble，以提高其可靠性。在我们的评估中，我们的方法在肺炎分类任务上表现出excel，而且和传统的深度神经网络相比，它的参数数量大幅减少。这不仅减少了与数据集的成本，还加快训练和降低了偏见。因此，我们的提案提供了一种强大、经济可行和可扩展的医疗图像分类策略，significantly reducing the dependence on extensive training data sets.
</details></li>
</ul>
<hr>
<h2 id="What-Large-Language-Models-Bring-to-Text-rich-VQA"><a href="#What-Large-Language-Models-Bring-to-Text-rich-VQA" class="headerlink" title="What Large Language Models Bring to Text-rich VQA?"></a>What Large Language Models Bring to Text-rich VQA?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07306">http://arxiv.org/abs/2311.07306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuejing Liu, Wei Tang, Xinzhe Ni, Jinghui Lu, Rui Zhao, Zechao Li, Fei Tan</li>
<li>for: 本研究探讨了基于语言模型（LLM）的文本rich VQA方法的优势和瓶颈。</li>
<li>methods: 作者将视觉和语言模块分离，使用外部OCR模型recognize图像中的文本，并使用LLM来回答问题。整个框架不需训练，利用LLM的在场能力。</li>
<li>results: 研究发现，基于LLM的方法在四个文本rich VQA dataset上达到了superior表现，而且基于ablation study，LLM具有更强的理解能力，可能为VQA问题提供有用的知识。然而，研究发现，LLM在视觉部分存在瓶颈。同时， combining OCR模块与MLLM也得到了 pleasantly results。<details>
<summary>Abstract</summary>
Text-rich VQA, namely Visual Question Answering based on text recognition in the images, is a cross-modal task that requires both image comprehension and text recognition. In this work, we focus on investigating the advantages and bottlenecks of LLM-based approaches in addressing this problem. To address the above concern, we separate the vision and language modules, where we leverage external OCR models to recognize texts in the image and Large Language Models (LLMs) to answer the question given texts. The whole framework is training-free benefiting from the in-context ability of LLMs. This pipeline achieved superior performance compared to the majority of existing Multimodal Large Language Models (MLLM) on four text-rich VQA datasets. Besides, based on the ablation study, we find that LLM brings stronger comprehension ability and may introduce helpful knowledge for the VQA problem. The bottleneck for LLM to address text-rich VQA problems may primarily lie in visual part. We also combine the OCR module with MLLMs and pleasantly find that the combination of OCR module with MLLM also works. It's worth noting that not all MLLMs can comprehend the OCR information, which provides insights into how to train an MLLM that preserves the abilities of LLM.
</details>
<details>
<summary>摘要</summary>
文字丰富的VQA（视觉问答）技术，即基于图像中文字识别的图像问答，是跨Modal的任务，需要图像理解和文字识别。在这项工作中，我们主要关注LLM（大语言模型）在解决这个问题上的优势和瓶颈。为了解决这个问题，我们将视觉和语言模块分开，利用外部OCR模型来recognize图像中的文字，并利用LLM来为给定文字提供答案。整个框架不需要训练，借助LLM在context中的能力。这个管道在四个文字丰富VQA数据集上 achieved superior performance，并且基于ablation study，我们发现LLM具有更强的理解能力，可能为VQA问题带来有用的知识。然而，我们发现LLM在处理文字丰富VQA问题的瓶颈主要在视觉部分。此外，我们还将OCR模块与MLLM（多Modal大语言模型）相结合，并发现这种结合也能够工作。需要注意的是，不 всіMLLM都能理解OCR信息，这提供了如何训练一个MLLM，以便它保留LLM的能力。
</details></li>
</ul>
<hr>
<h2 id="Dynamically-Weighted-Factor-Graph-for-Feature-based-Geo-localization"><a href="#Dynamically-Weighted-Factor-Graph-for-Feature-based-Geo-localization" class="headerlink" title="Dynamically Weighted Factor-Graph for Feature-based Geo-localization"></a>Dynamically Weighted Factor-Graph for Feature-based Geo-localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07301">http://arxiv.org/abs/2311.07301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Ángel Muñoz-Bañón, Alejandro Olivas, Edison Velasco-Sánchez, Francisco A. Candelas, Fernando Torres</li>
<li>for: 本研究旨在提高Feature-based地理定位的精度，使其能够在杂乱环境中提供更加可靠的定位结果。</li>
<li>methods: 本研究使用动态加权因子图模型来优化汽车的路径估计，并在检测中使用LiDAR传感器来进行数据质量评估。此外，还包括GNSS基于的先前误差估计。</li>
<li>results: 对比当前最佳地理定位方法，本研究在杂乱环境中显示了更高的精度和更少的偏差。此外，当检测数据失去时，本方法也能够成功地 mitigate 偏差和异常值。<details>
<summary>Abstract</summary>
Feature-based geo-localization relies on associating features extracted from aerial imagery with those detected by the vehicle's sensors. This requires that the type of landmarks must be observable from both sources. This no-variety of feature types generates poor representations that lead to outliers and deviations, produced by ambiguities and lack of detections respectively. To mitigate these drawbacks, in this paper, we present a dynamically weighted factor graph model for the vehicle's trajectory estimation. The weight adjustment in this implementation depends on information quantification in the detections performed using a LiDAR sensor. Also, a prior (GNSS-based) error estimation is included in the model. Then, when the representation becomes ambiguous or sparse, the weights are dynamically adjusted to rely on the corrected prior trajectory, mitigating in this way outliers and deviations. We compare our method against state-of-the-art geo-localization ones in a challenging ambiguous environment, where we also cause detection losses. We demonstrate mitigation of the mentioned drawbacks where the other methods fail.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate text into Simplified ChineseFeature-based geo-localization 基于将从飞行图像中提取的特征与车辆的感知器上探测到的特征进行关联。这需要两者之间的特征类型相同。这种单一的特征类型生成粗糙的表示，导致异常和偏差，由扩大和检测不足所致。为了解决这些缺点，在本文中，我们提出了一种动态权重因子图模型，用于车辆的路径估计。在这个实现中，权重调整取决于利用 LiDAR 探测器进行的检测信息量化。此外，还包括GNSS-based先前错误估计。当表示变得混乱或稀缺时，权重会动态调整，以依靠修正后的先前路径，从而 Mitigate 异常和偏差。我们与现有的地理localization方法进行比较，在一个复杂的混乱环境中，我们还引起检测损失。我们示出了消除这些缺点，其他方法失败的情况。
</details></li>
</ul>
<hr>
<h2 id="Multi-Sentence-Description-of-Complex-Manipulation-Action-Videos"><a href="#Multi-Sentence-Description-of-Complex-Manipulation-Action-Videos" class="headerlink" title="Multi Sentence Description of Complex Manipulation Action Videos"></a>Multi Sentence Description of Complex Manipulation Action Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07285">http://arxiv.org/abs/2311.07285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatemeh Ziaeetabar, Reza Safabakhsh, Saeedeh Momtazi, Minija Tamosiunaite, Florentin Wörgötter</li>
<li>for:  automatización de descripciones de videos</li>
<li>methods:  combina estrategias estadísticas y end-to-end, utilizando LSTM para generar descripciones de videos con diferentes niveles de detalle</li>
<li>results:  produce descripciones más realistas que otras aproximaciones competidoras<details>
<summary>Abstract</summary>
Automatic video description requires the generation of natural language statements about the actions, events, and objects in the video. An important human trait, when we describe a video, is that we are able to do this with variable levels of detail. Different from this, existing approaches for automatic video descriptions are mostly focused on single sentence generation at a fixed level of detail. Instead, here we address video description of manipulation actions where different levels of detail are required for being able to convey information about the hierarchical structure of these actions relevant also for modern approaches of robot learning. We propose one hybrid statistical and one end-to-end framework to address this problem. The hybrid method needs much less data for training, because it models statistically uncertainties within the video clips, while in the end-to-end method, which is more data-heavy, we are directly connecting the visual encoder to the language decoder without any intermediate (statistical) processing step. Both frameworks use LSTM stacks to allow for different levels of description granularity and videos can be described by simple single-sentences or complex multiple-sentence descriptions. In addition, quantitative results demonstrate that these methods produce more realistic descriptions than other competing approaches.
</details>
<details>
<summary>摘要</summary>
自动视频描述需要生成自然语言 sentences about the actions, events, and objects in the video. 人类特点是，当我们描述视频时，我们可以选择不同的级别细节。而现有的自动视频描述方法大多集中在固定级别的句子生成上。在这里，我们解决了视频描述操作动作的问题，其中不同级别的细节是必须以便传递视频中动作层次结构的信息，同时也是现代机器人学习方法的关键。我们提出了一个混合统计学和终端链接的方法，以及一个终端链接方法。两种方法都使用 LSTM 堆来允许不同级别的描述细节，并且视频可以通过单个句子或复杂多句 sentences 来描述。此外，我们对其他竞争方法进行了量化比较，并证明了这些方法生成的描述更加真实。
</details></li>
</ul>
<hr>
<h2 id="LT-ViT-A-Vision-Transformer-for-multi-label-Chest-X-ray-classification"><a href="#LT-ViT-A-Vision-Transformer-for-multi-label-Chest-X-ray-classification" class="headerlink" title="LT-ViT: A Vision Transformer for multi-label Chest X-ray classification"></a>LT-ViT: A Vision Transformer for multi-label Chest X-ray classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07263">http://arxiv.org/abs/2311.07263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Umar Marikkar, Sara Atito, Muhammad Awais, Adam Mahdi</li>
<li>for: 这个研究旨在提高静脉肺X射像（CXR）的医学图像识别 task 中使用 Vision Transformers（ViTs）的性能。</li>
<li>methods: 本研究使用了LT-ViT，一种具有共同注意力的 трансформа器，它结合了图像对象和随机初始化的帮助 tokens，以提高模型的性能。</li>
<li>results: 本研究所得到的结果显示：(1) LT-ViT 在两个公开的 CXR 数据集上比既存的顶尖性能提高; (2) LT-ViT 可以应用于不同的预训法，因此是无预设的; (3) LT-ViT 可以提供模型解释性，不需要 grad-cam 和其他相关技术。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and some existing efforts have been directed towards vision-language training for Chest X-rays (CXRs). However, we envision that there still exists a potential for improvement in vision-only training for CXRs using ViTs, by aggregating information from multiple scales, which has been proven beneficial for non-transformer networks. Hence, we have developed LT-ViT, a transformer that utilizes combined attention between image tokens and randomly initialized auxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT (1) surpasses the state-of-the-art performance using pure ViTs on two publicly available CXR datasets, (2) is generalizable to other pre-training methods and therefore is agnostic to model initialization, and (3) enables model interpretability without grad-cam and its variants.
</details>
<details>
<summary>摘要</summary>
医疗影像任务中广泛采用了视Transformers（ViTs），现有一些努力在视频语言训练中使用ViTs进行胸部X射影像（CXRs）的训练。然而，我们认为还有可能在视力只训练中使用ViTs进行CXRs的提升，通过多尺度信息的汇集，这种方法已经证明对非转换网络有利。因此，我们开发了LT-ViT，一种利用图像征素和随机初始化的auxiliary征素来实现图像特征的共同注意力。我们的实验表明，LT-ViT可以：1. 使用纯度ViTs在两个公开available的CXR数据集上超越现有的状态态强性表现。2. 可以在其他预训练方法上 generalized，因此不виси于模型的初始化。3. 可以无需grad-cam和其他相关图像解释方法，具有解释性。
</details></li>
</ul>
<hr>
<h2 id="Sketch-based-Video-Object-Segmentation-Benchmark-and-Analysis"><a href="#Sketch-based-Video-Object-Segmentation-Benchmark-and-Analysis" class="headerlink" title="Sketch-based Video Object Segmentation: Benchmark and Analysis"></a>Sketch-based Video Object Segmentation: Benchmark and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07261">http://arxiv.org/abs/2311.07261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruolin Yang, Da Li, Conghui Hu, Timothy Hospedales, Honggang Zhang, Yi-Zhe Song</li>
<li>for: 本研究旨在提出一种基于绘图的视频对象 segmentation任务，并提供一个新的标准测试集（Sketch-DAVIS16、Sketch-DAVIS17和Sketch-YouTube-VOS），以便更好地评估视频对象 segmentation 算法。</li>
<li>methods: 本研究使用了 STCN 基eline，并对不同类型的参考（语言表达、scribble和绘图）进行比较，以找出最有效的参考方式。</li>
<li>results: 实验结果显示，使用绘图作为参考是最有效的方式，它比使用语言表达和scribble更有效，同时也更容易进行标注。<details>
<summary>Abstract</summary>
Reference-based video object segmentation is an emerging topic which aims to segment the corresponding target object in each video frame referred by a given reference, such as a language expression or a photo mask. However, language expressions can sometimes be vague in conveying an intended concept and ambiguous when similar objects in one frame are hard to distinguish by language. Meanwhile, photo masks are costly to annotate and less practical to provide in a real application. This paper introduces a new task of sketch-based video object segmentation, an associated benchmark, and a strong baseline. Our benchmark includes three datasets, Sketch-DAVIS16, Sketch-DAVIS17 and Sketch-YouTube-VOS, which exploit human-drawn sketches as an informative yet low-cost reference for video object segmentation. We take advantage of STCN, a popular baseline of semi-supervised VOS task, and evaluate what the most effective design for incorporating a sketch reference is. Experimental results show sketch is more effective yet annotation-efficient than other references, such as photo masks, language and scribble.
</details>
<details>
<summary>摘要</summary>
参考基础视频对象分割是一个emerging topic，旨在将每帧视频内对应的目标物体进行分割，以参考一个 giventext or photo mask。然而，语言表达可能会对某些概念发送不确定的信息，而且在一帧中相似的物体可能很难以通过语言区分。另一方面，photo masks是costly to annotate并且在实际应用中 menos practical。这篇论文介绍了一个新的任务：sketch-based video object segmentation，以及相关的benchmark和强大基线。我们的benchmark包括Sketch-DAVIS16、Sketch-DAVIS17和Sketch-YouTube-VOS三个 dataset，这些dataset利用人类手绘的sketches作为视频对象分割的参考。我们利用STCN，一个受欢迎的semi-supervised VOS任务的基eline，进行评估，并评估在不同的参考方法中，sketch是否比其他参考方法更有效率。实验结果表明，sketch比其他参考方法更有效率，并且可以实现更低的注释成本。
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-Clutter-Detection-and-Semantic-Segmentation-of-Moving-Objects-for-Automotive-Radar-Data"><a href="#Simultaneous-Clutter-Detection-and-Semantic-Segmentation-of-Moving-Objects-for-Automotive-Radar-Data" class="headerlink" title="Simultaneous Clutter Detection and Semantic Segmentation of Moving Objects for Automotive Radar Data"></a>Simultaneous Clutter Detection and Semantic Segmentation of Moving Objects for Automotive Radar Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07247">http://arxiv.org/abs/2311.07247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Kopp, Dominik Kellner, Aldi Piroli, Vinzenz Dallabetta, Klaus Dietmayer</li>
<li>for: 本研究旨在实现同时解决干扰点云和 semantic segmentation问题，而不是将它们处理为两个独立的任务。</li>
<li>methods: 我们提出了一个新的增强多头架构造，以及一种用于表示网络预测值的新方法，以便同时解决两个任务。</li>
<li>results: 我们在广泛的评估中展示了我们的设置高效且超越了现有的网络模型，在RadarScenes dataset上的 semantic segmentation任务中。<details>
<summary>Abstract</summary>
The unique properties of radar sensors, such as their robustness to adverse weather conditions, make them an important part of the environment perception system of autonomous vehicles. One of the first steps during the processing of radar point clouds is often the detection of clutter, i.e. erroneous points that do not correspond to real objects. Another common objective is the semantic segmentation of moving road users. These two problems are handled strictly separate from each other in literature. The employed neural networks are always focused entirely on only one of the tasks. In contrast to this, we examine ways to solve both tasks at the same time with a single jointly used model. In addition to a new augmented multi-head architecture, we also devise a method to represent a network's predictions for the two tasks with only one output value. This novel approach allows us to solve the tasks simultaneously with the same inference time as a conventional task-specific model. In an extensive evaluation, we show that our setup is highly effective and outperforms every existing network for semantic segmentation on the RadarScenes dataset.
</details>
<details>
<summary>摘要</summary>
射频探测器的特有性，如其对恶劣天气的稳定性，使其成为自动驾驶车辆环境感知系统中重要的一部分。在处理射频点云时，一个常见的第一步是检测噪声，即无关实际物体的错误点。另一个常见的目标是对移动路用户进行 semantic segmentation。在文献中，这两个问题通常被视为独立的两个任务，并且使用的神经网络总是专注于单一任务。相比之下，我们研究了同时解决这两个任务的方法，使用了一种新的加密多头架构，以及一种用于表示网络预测值的新方法。这种新approach允许我们在同一个推理时间内同时解决两个任务。在广泛的评估中，我们发现了我们的设置非常有效，并在RadarScenes dataset上超越了每个存在的网络。
</details></li>
</ul>
<hr>
<h2 id="DeepMetricEye-Metric-Depth-Estimation-in-Periocular-VR-Imagery"><a href="#DeepMetricEye-Metric-Depth-Estimation-in-Periocular-VR-Imagery" class="headerlink" title="DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery"></a>DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07235">http://arxiv.org/abs/2311.07235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitong Sun, Zijian Zhou, Cyriel Diels, Ali Asadipour</li>
<li>for: 提供一种用于计算视网膜区域的深度图的轻量级框架，以便在VR头戴式设备上实现可量化的眼部区域计算。</li>
<li>methods: 使用基于U-Net 3+深度学习框架的轻量级框架，将Relative Measurements转换为可量化的Periocular Depth Maps。</li>
<li>results: 在36名参与者的测试中，方法表现出色，在眼部全球精度评估实验和豹心眼径测量方面达到了显著的效果。<details>
<summary>Abstract</summary>
Despite the enhanced realism and immersion provided by VR headsets, users frequently encounter adverse effects such as digital eye strain (DES), dry eye, and potential long-term visual impairment due to excessive eye stimulation from VR displays and pressure from the mask. Recent VR headsets are increasingly equipped with eye-oriented monocular cameras to segment ocular feature maps. Yet, to compute the incident light stimulus and observe periocular condition alterations, it is imperative to transform these relative measurements into metric dimensions. To bridge this gap, we propose a lightweight framework derived from the U-Net 3+ deep learning backbone that we re-optimised, to estimate measurable periocular depth maps. Compatible with any VR headset equipped with an eye-oriented monocular camera, our method reconstructs three-dimensional periocular regions, providing a metric basis for related light stimulus calculation protocols and medical guidelines. Navigating the complexities of data collection, we introduce a Dynamic Periocular Data Generation (DPDG) environment based on UE MetaHuman, which synthesises thousands of training images from a small quantity of human facial scan data. Evaluated on a sample of 36 participants, our method exhibited notable efficacy in the periocular global precision evaluation experiment, and the pupil diameter measurement.
</details>
<details>
<summary>摘要</summary>
尽管虚拟现实（VR）头戴设备提供了更加真实和沉浸的用户体验，但用户们经常出现不良影响，如数字眼疲病（DES）、干燥眼睛和可能的长期视力障碍，这些影响是由 VR 显示器和头戴设备的压力所致。现有的 VR 头戴设备通常配备有面向眼睛的单目镜像传感器，以分割眼部特征地图。然而，为了计算入射光刺激和观察眼部状态的变化，需要将这些相对测量转换成 metric 维度。为了bridging这个差距，我们提出了一个轻量级的框架，基于 U-Net 3+ 深度学习基础，用于估计可测量的眼部深度地图。与任何配备有面向眼睛单目镜像传感器的 VR 头戴设备兼容，我们的方法可重construct三维眼部区域，提供metric 基础 для相关的光刺激计算协议和医疗指南。在数据收集的复杂性方面，我们引入了一个基于 UE MetaHuman 的动态眼部数据生成环境（DPDG），该环境可以从小量的人类脸部扫描数据中生成数千个训练图像。在一个样本中，我们的方法在眼部全球精度评估实验和评估眼径大小方面表现出了明显的有效性。
</details></li>
</ul>
<hr>
<h2 id="Multi-task-learning-for-joint-weakly-supervised-segmentation-and-aortic-arch-anomaly-classification-in-fetal-cardiac-MRI"><a href="#Multi-task-learning-for-joint-weakly-supervised-segmentation-and-aortic-arch-anomaly-classification-in-fetal-cardiac-MRI" class="headerlink" title="Multi-task learning for joint weakly-supervised segmentation and aortic arch anomaly classification in fetal cardiac MRI"></a>Multi-task learning for joint weakly-supervised segmentation and aortic arch anomaly classification in fetal cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07234">http://arxiv.org/abs/2311.07234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/svrtk/masc-multi-task-segmentation-and-classification">https://github.com/svrtk/masc-multi-task-segmentation-and-classification</a></li>
<li>paper_authors: Paula Ramirez, Alena Uus, Milou P. M. van Poppel, Irina Grigorescu, Johannes K. Steinweg, David F. A. Lloyd, Kuberan Pushparajah, Andrew P. King, Maria Deprez</li>
<li>for: 这个研究的目的是为了帮助3D胎儿血管图像的自动化分类和检测，以提高诊断confidence。</li>
<li>methods: 这个研究使用了深度学习的标签卷积和注意力3D U-Net segmentation，以及密集度121的疾病分类。</li>
<li>results: 研究结果表明，我们的提出的训练策略在Label propagation和仅使用卷积过程中训练的网络之上表现出色，并且我们的分类器在与T2w图像进行joint training后表现出色，其平均权衡准确率为0.99（0.01）。<details>
<summary>Abstract</summary>
Congenital Heart Disease (CHD) is a group of cardiac malformations present already during fetal life, representing the prevailing category of birth defects globally. Our aim in this study is to aid 3D fetal vessel topology visualisation in aortic arch anomalies, a group which encompasses a range of conditions with significant anatomical heterogeneity. We present a multi-task framework for automated multi-class fetal vessel segmentation from 3D black blood T2w MRI and anomaly classification. Our training data consists of binary manual segmentation masks of the cardiac vessels' region in individual subjects and fully-labelled anomaly-specific population atlases. Our framework combines deep learning label propagation using VoxelMorph with 3D Attention U-Net segmentation and DenseNet121 anomaly classification. We target 11 cardiac vessels and three distinct aortic arch anomalies, including double aortic arch, right aortic arch, and suspected coarctation of the aorta. We incorporate an anomaly classifier into our segmentation pipeline, delivering a multi-task framework with the primary motivation of correcting topological inaccuracies of the segmentation. The hypothesis is that the multi-task approach will encourage the segmenter network to learn anomaly-specific features. As a secondary motivation, an automated diagnosis tool may have the potential to enhance diagnostic confidence in a decision support setting. Our results showcase that our proposed training strategy significantly outperforms label propagation and a network trained exclusively on propagated labels. Our classifier outperforms a classifier trained exclusively on T2w volume images, with an average balanced accuracy of 0.99 (0.01) after joint training. Adding a classifier improves the anatomical and topological accuracy of all correctly classified double aortic arch subjects.
</details>
<details>
<summary>摘要</summary>
《固有心脏病（CHD）》是胎生时已经存在的心脏畸形，全球范围内最常见的出生畸形之一。我们在这项研究中的目标是通过自动化多类胎 vessle分割和畸形分类来提高3D黑血MRI中胎 vessle topology的可视化。我们的训练数据包括各个个体的手动Binary manual segmentation masks of the cardiac vessels' region和具有精度的畸形特征的各个畸形人体 Atlases。我们的框架结合了深度学习标签传播使用VoxelMorph和3D Attention U-Net segmentation和DenseNet121畸形分类。我们目标是11个心脏血管和三种不同的脊梁畸形，包括双脊梁、右脊梁和可能的脊梁缺陷。我们将畸形分类器 incorporated into our segmentation pipeline，实现一个多任务框架，主要目的是 correction topological inaccuracies of the segmentation。我们 hypothesize that the multi-task approach will encourage the segmenter network to learn anomaly-specific features。作为次要目的，一个自动诊断工具可能会提高诊断自信性。我们的结果表明，我们的训练策略在比label propagation和专门训练在propagated labels的网络之上显著提高。我们的分类器在与T2wVolume Image进行同时训练后，其平均平衡准确率为0.99（0.01）。增加分类器可以提高所有正确分类double aortic arch的 анатомиче和 topological 准确性。
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Learning-for-the-Classification-of-Confocal-Laser-Endomicroscopy-Images-of-Head-and-Neck-Tumors"><a href="#Few-Shot-Learning-for-the-Classification-of-Confocal-Laser-Endomicroscopy-Images-of-Head-and-Neck-Tumors" class="headerlink" title="Few Shot Learning for the Classification of Confocal Laser Endomicroscopy Images of Head and Neck Tumors"></a>Few Shot Learning for the Classification of Confocal Laser Endomicroscopy Images of Head and Neck Tumors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07216">http://arxiv.org/abs/2311.07216</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Aubreville, Zhaoya Pan, Matti Sievert, Jonas Ammeling, Jonathan Ganz, Nicolai Oetter, Florian Stelzle, Ann-Kathrin Frenken, Katharina Breininger, Miguel Goncalves</li>
<li>for: 这种研究旨在发展一种基于confocal laser endomicroscopy（CLE）的自动分析方法，以帮助外科医生在移除头颈肿瘤时确保安全的边缘。</li>
<li>methods: 这些研究人员使用了四种流行的几个shot学习（FSL）方法，以评估它们在不同的生理结构领域中的泛化能力。</li>
<li>results: 研究结果表明，FSL在CLE图像上是可能的，但受到patient数量和生理结构领域的多样性的影响。在 vocals folds（VF）图像上，最佳方法达到了79.6%的 médiane accuracy，而在sinunasal tumors（SNT）图像上只达到了61.6%的 médiane accuracy。<details>
<summary>Abstract</summary>
The surgical removal of head and neck tumors requires safe margins, which are usually confirmed intraoperatively by means of frozen sections. This method is, in itself, an oversampling procedure, which has a relatively low sensitivity compared to the definitive tissue analysis on paraffin-embedded sections. Confocal laser endomicroscopy (CLE) is an in-vivo imaging technique that has shown its potential in the live optical biopsy of tissue. An automated analysis of this notoriously difficult to interpret modality would help surgeons. However, the images of CLE show a wide variability of patterns, caused both by individual factors but also, and most strongly, by the anatomical structures of the imaged tissue, making it a challenging pattern recognition task. In this work, we evaluate four popular few shot learning (FSL) methods towards their capability of generalizing to unseen anatomical domains in CLE images. We evaluate this on images of sinunasal tumors (SNT) from five patients and on images of the vocal folds (VF) from 11 patients using a cross-validation scheme. The best respective approach reached a median accuracy of 79.6% on the rather homogeneous VF dataset, but only of 61.6% for the highly diverse SNT dataset. Our results indicate that FSL on CLE images is viable, but strongly affected by the number of patients, as well as the diversity of anatomical patterns.
</details>
<details>
<summary>摘要</summary>
surgical removal of head and neck tumors 需要安全的边缘，通常通过冻结部分来确认。这是一种过度采样的方法，其敏感度相对较低于 définitive tissue analysis on paraffin-embedded sections。Confocal laser endomicroscopy (CLE) 是一种实时成像技术，可以在实时生物组织检查中提供信息。然而，CLE 图像具有很大的变化，由于个体因素以及镜头检查的结构，这是一项具有挑战性的模式识别任务。在这项工作中，我们评估了四种流行的少数shot learning（FSL）方法，以其能否在未经见过的生理结构中广泛应用。我们使用了五名患者的 sinunasal tumors（SNT）图像和 11名患者的 vocal folds（VF）图像，采用交叉验证方式进行评估。最佳方法在 relativamente homogeneous VF 数据集上达到了79.6%的 median 准确率，但只有61.6%的准确率在高度多样化的 SNT 数据集上。我们的结果表明，FSL on CLE 图像是可行的，但受到patient 数量以及生理结构的多样化的影响。
</details></li>
</ul>
<hr>
<h2 id="A-method-for-quantifying-sectoral-optic-disc-pallor-in-fundus-photographs-and-its-association-with-peripapillary-RNFL-thickness"><a href="#A-method-for-quantifying-sectoral-optic-disc-pallor-in-fundus-photographs-and-its-association-with-peripapillary-RNFL-thickness" class="headerlink" title="A method for quantifying sectoral optic disc pallor in fundus photographs and its association with peripapillary RNFL thickness"></a>A method for quantifying sectoral optic disc pallor in fundus photographs and its association with peripapillary RNFL thickness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07213">http://arxiv.org/abs/2311.07213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Gibbon, Graciela Muniz-Terrera, Fabian SL Yii, Charlene Hamid, Simon Cox, Ian JC Maccormick, Andrew J Tatham, Craig Ritchie, Emanuele Trucco, Baljean Dhillon, Thomas J MacGillivray</li>
<li>for: 本研究的目的是开发一种自动地量化眼睛背部缺乏症状的方法，以及与背部 nerf fibre layer (pRNFL) 厚度的关系。</li>
<li>methods: 我们使用深度学习来 segment 眼睛背部、芳香突起和血管在眼睛照片中，并测量缺乏症状。我们通过对 pRNFL 厚度来自光共振扫描仪获得的数据进行分析，并在 118 名参与者中评估了缺乏症状和 pRNFL 厚度之间的关系。此外，我们还使用临床诊断为衰竭（N&#x3D;45）的图像进行测量，并与健康控制群（N&#x3D;46）进行比较。</li>
<li>results: 我们开发了一种可自动量化眼睛背部缺乏症状的软件。我们发现，缺乏症状与 pRNFL 厚度在全体、 temporal 下部、nasal&#x2F;temporal 比例和整个眼睛背部之间存在关系。此外，衰竭组的缺乏症状也显著高于健康组。最后，我们也证明了这种分析方法对于相机类型、图像格式和分辨率的变化是可Robust。<details>
<summary>Abstract</summary>
Purpose: To develop an automatic method of quantifying optic disc pallor in fundus photographs and determine associations with peripapillary retinal nerve fibre layer (pRNFL) thickness.   Methods: We used deep learning to segment the optic disc, fovea, and vessels in fundus photographs, and measured pallor. We assessed the relationship between pallor and pRNFL thickness derived from optical coherence tomography scans in 118 participants. Separately, we used images diagnosed by clinical inspection as pale (N=45) and assessed how measurements compared to healthy controls (N=46). We also developed automatic rejection thresholds, and tested the software for robustness to camera type, image format, and resolution.   Results: We developed software that automatically quantified disc pallor across several zones in fundus photographs. Pallor was associated with pRNFL thickness globally (\b{eta} = -9.81 (SE = 3.16), p < 0.05), in the temporal inferior zone (\b{eta} = -29.78 (SE = 8.32), p < 0.01), with the nasal/temporal ratio (\b{eta} = 0.88 (SE = 0.34), p < 0.05), and in the whole disc (\b{eta} = -8.22 (SE = 2.92), p < 0.05). Furthermore, pallor was significantly higher in the patient group. Lastly, we demonstrate the analysis to be robust to camera type, image format, and resolution.   Conclusions: We developed software that automatically locates and quantifies disc pallor in fundus photographs and found associations between pallor measurements and pRNFL thickness.   Translational relevance: We think our method will be useful for the identification, monitoring and progression of diseases characterized by disc pallor/optic atrophy, including glaucoma, compression, and potentially in neurodegenerative disorders.
</details>
<details>
<summary>摘要</summary>
Methods: 我们使用深度学习来分割盘绿、芳香眼和血管在眼科照片中，并测量盘绿。我们在118名参与者中评估了盘绿与pRNFL厚度之间的关系，并分别使用被诊断为脊梁（N=45）和健康控制群（N=46）的图像进行比较。此外，我们还开发了自动拒绝阈值，并测试了软件的对camera类型、图像格式和分辨率的Robustness。Results: 我们开发了一种可以自动量化盘绿在多个区域的眼科照片中的软件。盘绿与pRNFL厚度之间存在全体(\b{eta} = -9.81 (SE = 3.16), p < 0.05), temporo- inferior区域(\b{eta} = -29.78 (SE = 8.32), p < 0.01)和nasal/temporal比率(\b{eta} = 0.88 (SE = 0.34), p < 0.05)之间的关系。此外，盘绿在病例群体中高于健康控制群。最后，我们证明了这种分析方法对camera类型、图像格式和分辨率的Robustness。Conclusions: 我们开发了一种可以自动分割盘绿、芳香眼和血管的软件，并发现了盘绿测量与pRNFL厚度之间的关系。Translational relevance: 我们认为这种方法将有用于识别、监测和评估 caracterized by disc pallor/optic atrophy的疾病，包括 glaucoma, compression, 和可能的neurodegenerative disorders。
</details></li>
</ul>
<hr>
<h2 id="Cross-modal-Generative-Model-for-Visual-Guided-Binaural-Stereo-Generation"><a href="#Cross-modal-Generative-Model-for-Visual-Guided-Binaural-Stereo-Generation" class="headerlink" title="Cross-modal Generative Model for Visual-Guided Binaural Stereo Generation"></a>Cross-modal Generative Model for Visual-Guided Binaural Stereo Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07630">http://arxiv.org/abs/2311.07630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaojian Li, Bin Zhao, Yuan Yuan</li>
<li>for: 本研究提出了一种基于生成对抗学习的视觉导向的双耳立体声音生成方法，以提供更加听众式的听众体验。</li>
<li>methods: 本方法使用生成器和判定器，通过视觉共享的共同视觉信息来引导生成器和判定器分别工作。在生成对抗阶段，共同视觉信息被逐渐更新，allowing生成器和判定器发挥相互协作的作用。</li>
<li>results: 该方法在2个数据集和5个评价指标上达到了状态对抗的性能，并且在实际应用中可以提供空间实际的双耳立体声音。<details>
<summary>Abstract</summary>
Binaural stereo audio is recorded by imitating the way the human ear receives sound, which provides people with an immersive listening experience. Existing approaches leverage autoencoders and directly exploit visual spatial information to synthesize binaural stereo, resulting in a limited representation of visual guidance. For the first time, we propose a visually guided generative adversarial approach for generating binaural stereo audio from mono audio. Specifically, we develop a Stereo Audio Generation Model (SAGM), which utilizes shared spatio-temporal visual information to guide the generator and the discriminator to work separately. The shared visual information is updated alternately in the generative adversarial stage, allowing the generator and discriminator to deliver their respective guided knowledge while visually sharing. The proposed method learns bidirectional complementary visual information, which facilitates the expression of visual guidance in generation. In addition, spatial perception is a crucial attribute of binaural stereo audio, and thus the evaluation of stereo spatial perception is essential. However, previous metrics failed to measure the spatial perception of audio. To this end, a metric to measure the spatial perception of audio is proposed for the first time. The proposed metric is capable of measuring the magnitude and direction of spatial perception in the temporal dimension. Further, considering its function, it is feasible to utilize it instead of demanding user studies to some extent. The proposed method achieves state-of-the-art performance on 2 datasets and 5 evaluation metrics. Qualitative experiments and user studies demonstrate that the method generates space-realistic stereo audio.
</details>
<details>
<summary>摘要</summary>
人类耳朵所接收的声音方式为我们录制双耳立体声音提供了启发，从而为人们提供了沉浸式听众体验。现有方法利用自动编码器并直接利用视觉空间信息来生成双耳立体声音，但这会导致视觉指导的限制表现。我们为首次提出了基于视觉导向生成抗战斗方法，通过共享视觉信息来导引生成器和批判器分开工作。特别是，我们开发了双耳声音生成模型（SAGM），该模型利用共享的空间时间视觉信息来导引生成器和批判器。共享的视觉信息在生成抗战斗阶段不断更新，allowing生成器和批判器同时传递各自的导引知识，从而实现了视觉共享。此外，空间感知是双耳立体声音的重要特征，因此评估双耳立体声音的空间感知是必要的。然而，先前的指标未能评估音频中的空间感知。为此，我们提出了一种新的指标来评估音频中的空间感知。该指标可以评估音频中的空间感知的大小和方向。此外，由于其功能，可以在一定程度上取代用户研究。我们的方法在两个数据集和五个评价指标上达到了状态的最佳性能。Qualitative实验和用户研究表明，我们的方法可以生成真实的空间声音。
</details></li>
</ul>
<hr>
<h2 id="MonoDiffusion-Self-Supervised-Monocular-Depth-Estimation-Using-Diffusion-Model"><a href="#MonoDiffusion-Self-Supervised-Monocular-Depth-Estimation-Using-Diffusion-Model" class="headerlink" title="MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model"></a>MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07198">http://arxiv.org/abs/2311.07198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuweishao/monodiffusion">https://github.com/shuweishao/monodiffusion</a></li>
<li>paper_authors: Shuwei Shao, Zhongcai Pei, Weihai Chen, Dingchi Sun, Peter C. Y. Chen, Zhengguo Li</li>
<li>for: 本研究旨在提出一种新的自监督深度估计框架，称为MONODIFFUSION，该框架通过形式化为迭代减噪过程来实现。</li>
<li>methods: 我们在这种情况下开发了一种 pseudo 基准数据扩充过程，以帮助 MONODIFFUSION 的扩充。此外，我们还开发了一种masked visual condition机制，以提高模型的减噪能力。</li>
<li>results: 我们在 KITTI 和 Make3D 数据集上进行了广泛的实验，并证明了 MONODIFFUSION 在自监督深度估计中超过了先前的状态时刻。源代码将在 <a target="_blank" rel="noopener" href="https://github.com/ShuweiShao/MonoDiffusion">https://github.com/ShuweiShao/MonoDiffusion</a> 上发布。<details>
<summary>Abstract</summary>
Over the past few years, self-supervised monocular depth estimation that does not depend on ground-truth during the training phase has received widespread attention. Most efforts focus on designing different types of network architectures and loss functions or handling edge cases, e.g., occlusion and dynamic objects. In this work, we introduce a novel self-supervised depth estimation framework, dubbed MonoDiffusion, by formulating it as an iterative denoising process. Because the depth ground-truth is unavailable in the training phase, we develop a pseudo ground-truth diffusion process to assist the diffusion in MonoDiffusion. The pseudo ground-truth diffusion gradually adds noise to the depth map generated by a pre-trained teacher model. Moreover,the teacher model allows applying a distillation loss to guide the denoised depth. Further, we develop a masked visual condition mechanism to enhance the denoising ability of model. Extensive experiments are conducted on the KITTI and Make3D datasets and the proposed MonoDiffusion outperforms prior state-of-the-art competitors. The source code will be available at https://github.com/ShuweiShao/MonoDiffusion.
</details>
<details>
<summary>摘要</summary>
Note:* "自动" (zìdòng) is used instead of "self-supervised" to emphasize the lack of ground truth during training.* "推理" (tiělǐ) is used instead of "denoising" to emphasize the iterative process.* "假" (jiǎ) is used instead of "pseudo" to emphasize the artificial nature of the pseudo ground truth.* "导学" (dǎoxué) is used instead of "distillation" to emphasize the role of the teacher model.* "遮盖" (miànjià) is used instead of "masked" to emphasize the hiding of the visual information.* "能力" (nénglì) is used instead of "ability" to emphasize the capability of the model.
</details></li>
</ul>
<hr>
<h2 id="Fitting-tree-model-with-CNN-and-geodesics-to-track-vesselsand-application-to-Ultrasound-Localization-Microscopy-data"><a href="#Fitting-tree-model-with-CNN-and-geodesics-to-track-vesselsand-application-to-Ultrasound-Localization-Microscopy-data" class="headerlink" title="Fitting tree model with CNN and geodesics to track vesselsand application to Ultrasound Localization Microscopy data"></a>Fitting tree model with CNN and geodesics to track vesselsand application to Ultrasound Localization Microscopy data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07188">http://arxiv.org/abs/2311.07188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Théo Bertrand, Laurent D. Cohen</li>
<li>for: 探测血管网络中的重要标志点（通过CNN进行本地化和分类），并将血管表示为最小距离树图。</li>
<li>methods: 利用地odesic方法探测血管的几何特征，并在位置和orientation空间中使用空间位置和orientation来准确表示2D血管为树结构。</li>
<li>results: 虽然ULM数据的标注稀缺性是本研究的一大障碍，但是使用ULM数据构建的 Orientation Score 可以提供好的地odesics  для跟踪血管。<details>
<summary>Abstract</summary>
Segmentation of tubular structures in vascular imaging is a well studied task, although it is rare that we try to infuse knowledge of the tree-like structure of the regions to be detected. Our work focuses on detecting the important landmarks in the vascular network (via CNN performing both localization and classification of the points of interest) and representing vessels as the edges in some minimal distance tree graph. We leverage geodesic methods relevant to the detection of vessels and their geometry, making use of the space of positions and orientations so that 2D vessels can be accurately represented as trees. We build our model to carry tracking on Ultrasound Localization Microscopy (ULM) data, proposing to build a good cost function for tracking on this type of data. We also test our framework on synthetic and eye fundus data. Results show that scarcity of well annotated ULM data is an obstacle to localization of vascular landmarks but the Orientation Score built from ULM data yields good geodesics for tracking blood vessels.
</details>
<details>
<summary>摘要</summary>
干流结构分割在血管成像中是已经广泛研究的任务，然而rarely 我们会利用树状结构的知识来检测这些区域。我们的工作是通过使用卷积神经网络进行本地化和分类 interested points，并将血管表示为最小距离树图的边。我们利用血管的推断方法和几何学特性，使用空间位置和方向的空间，以便精确地表示2D血管为树。我们建立了一个良好的成本函数，以便在这种数据上进行跟踪。我们还在synthetic和眼球膜数据上测试了我们的框架。结果表明，ULM数据的缺乏高质量标注是血管地标的本地化的主要障碍，但是我们构建的Orientation Score从ULM数据中得到了良好的地odesics для跟踪血管。
</details></li>
</ul>
<hr>
<h2 id="Regenerating-Arbitrary-Video-Sequences-with-Distillation-Path-Finding"><a href="#Regenerating-Arbitrary-Video-Sequences-with-Distillation-Path-Finding" class="headerlink" title="Regenerating Arbitrary Video Sequences with Distillation Path-Finding"></a>Regenerating Arbitrary Video Sequences with Distillation Path-Finding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07170">http://arxiv.org/abs/2311.07170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi-Ngoc-Hanh Le, Sheng-Yi Yao, Chun-Te Wu, Tong-Yee Lee</li>
<li>for: 这篇论文是为了提供一种可互动的框架，帮助用户根据自己的喜好选择视频动画的开场场景。</li>
<li>methods: 这篇论文使用了一种名为RSFNet的网络来学习视频帧集的特征相关性，然后使用一种新的路径找索算法（SDPF）来基于源视频的运动方向来生成新的动画序列。</li>
<li>results: 该框架可以生成新的动画序列，并且可以在 cartoon 和自然场景中生成更加精准和自然的动画。这些结果超越了现有的商业应用程序和先前的研究工作。<details>
<summary>Abstract</summary>
If the video has long been mentioned as a widespread visualization form, the animation sequence in the video is mentioned as storytelling for people. Producing an animation requires intensive human labor from skilled professional artists to obtain plausible animation in both content and motion direction, incredibly for animations with complex content, multiple moving objects, and dense movement. This paper presents an interactive framework to generate new sequences according to the users' preference on the starting frame. The critical contrast of our approach versus prior work and existing commercial applications is that novel sequences with arbitrary starting frame are produced by our system with a consistent degree in both content and motion direction. To achieve this effectively, we first learn the feature correlation on the frameset of the given video through a proposed network called RSFNet. Then, we develop a novel path-finding algorithm, SDPF, which formulates the knowledge of motion directions of the source video to estimate the smooth and plausible sequences. The extensive experiments show that our framework can produce new animations on the cartoon and natural scenes and advance prior works and commercial applications to enable users to obtain more predictable results.
</details>
<details>
<summary>摘要</summary>
如果视频已经被广泛认为是视觉化的形式，视频中的动画序列被视为人们的故事tellding。制作动画需要凝心的人工劳动，从技巧备受训练的艺术家手中获得可信度的动画内容和动作方向，特别是对于具有复杂内容、多个移动对象和紧张运动的动画。本文提出了一种互动框架，可以根据用户的首帧偏好生成新的序列。我们的方法与先前的工作和商业应用程序的重要对比点在于，我们的系统可以生成novel的序列，并且在内容和动作方向上具有一致的度。为了实现这一目标，我们首先通过我们提出的网络 called RSFNet 学习视频帧集中的特征相关性。然后，我们开发了一种新的路径找索算法，SDPF，该算法利用源视频中的动作方向知识来估算可靠和可信度的新序列。我们的实验表明，我们的框架可以生成在 cartoon 和自然场景中的新动画，并超越先前的工作和商业应用程序，让用户可以更加预测性地获得结果。
</details></li>
</ul>
<hr>
<h2 id="NDDepth-Normal-Distance-Assisted-Monocular-Depth-Estimation-and-Completion"><a href="#NDDepth-Normal-Distance-Assisted-Monocular-Depth-Estimation-and-Completion" class="headerlink" title="NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion"></a>NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07166">http://arxiv.org/abs/2311.07166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ShuweiShao/NDDepth">https://github.com/ShuweiShao/NDDepth</a></li>
<li>paper_authors: Shuwei Shao, Zhongcai Pei, Weihai Chen, Peter C. Y. Chen, Zhengguo Li</li>
<li>for: 本研究旨在提出一种基于物理（几何）的深度学习框架，用于单目深度估计和完成任务。</li>
<li>methods: 我们提出了一种新的深度估计和完成方法，即先估计表面法向和到原点距离图像，然后将其转换为深度图像。此外，我们还开发了一个额外的深度头，以增强方法的稳定性。</li>
<li>results: 我们在NYU-Depth-v2、KITTI和SUN RGB-D数据集上进行了广泛的实验，结果表明我们的方法在单目深度估计和完成任务中表现出色，超越了先前的状态OF-the-art竞争者。<details>
<summary>Abstract</summary>
Over the past few years, monocular depth estimation and completion have been paid more and more attention from the computer vision community because of their widespread applications. In this paper, we introduce novel physics (geometry)-driven deep learning frameworks for these two tasks by assuming that 3D scenes are constituted with piece-wise planes. Instead of directly estimating the depth map or completing the sparse depth map, we propose to estimate the surface normal and plane-to-origin distance maps or complete the sparse surface normal and distance maps as intermediate outputs. To this end, we develop a normal-distance head that outputs pixel-level surface normal and distance. Meanwhile, the surface normal and distance maps are regularized by a developed plane-aware consistency constraint, which are then transformed into depth maps. Furthermore, we integrate an additional depth head to strengthen the robustness of the proposed frameworks. Extensive experiments on the NYU-Depth-v2, KITTI and SUN RGB-D datasets demonstrate that our method exceeds in performance prior state-of-the-art monocular depth estimation and completion competitors. The source code will be available at https://github.com/ShuweiShao/NDDepth.
</details>
<details>
<summary>摘要</summary>
过去几年，单目深度估计和完成已经在计算机视觉社区获得了更多的关注，因为它们在各种应用场景中具有广泛的应用前景。在这篇论文中，我们介绍了一种新的物理（几何）驱动的深度学习框架，假设3D场景由块状平面组成。而不是直接估计深度图或完成缺失的深度图，我们提议估计像素级面法向和平面到原点距离图。为此，我们开发了一个面法距离头，该头输出像素级面法向和距离。此外，我们还开发了一个扩展的深度头，以强化我们提议的框架的稳定性。广泛的实验表明，我们的方法在NYU-Depth-v2、KITTI和SUN RGB-D数据集上的性能较前状态的单目深度估计和完成竞争者高。代码将在https://github.com/ShuweiShao/NDDepth上公开。
</details></li>
</ul>
<hr>
<h2 id="CycleGANAS-Differentiable-Neural-Architecture-Search-for-CycleGAN"><a href="#CycleGANAS-Differentiable-Neural-Architecture-Search-for-CycleGAN" class="headerlink" title="CycleGANAS: Differentiable Neural Architecture Search for CycleGAN"></a>CycleGANAS: Differentiable Neural Architecture Search for CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07162">http://arxiv.org/abs/2311.07162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taegun An, Changhee Joo</li>
<li>for: 这个论文是为了搜索CyclesGAN的神经网络架构，用于无对照图像转换任务。</li>
<li>methods: 这个框架使用了一系列简单的ResNet基于细胞，并开发了一种有效地搜索大搜索空间的搜索方法。</li>
<li>results: 我们的框架可以不 только有效地找到高性能的架构，而且也能够成功地解决数据不均衡问题。<details>
<summary>Abstract</summary>
We develop a Neural Architecture Search (NAS) framework for CycleGAN that carries out unpaired image-to-image translation task. Extending previous NAS techniques for Generative Adversarial Networks (GANs) to CycleGAN is not straightforward due to the task difference and greater search space. We design architectures that consist of a stack of simple ResNet-based cells and develop a search method that effectively explore the large search space. We show that our framework, called CycleGANAS, not only effectively discovers high-performance architectures that either match or surpass the performance of the original CycleGAN, but also successfully address the data imbalance by individual architecture search for each translation direction. To our best knowledge, it is the first NAS result for CycleGAN and shed light on NAS for more complex structures.
</details>
<details>
<summary>摘要</summary>
我们开发了一个基于神经网络搜索（NAS）框架，用于实现无对照图像到图像翻译任务。与前一代GANs NAS技术不同，将NAS技术应用于CycleGAN任务不是直接的，因为任务的不同和搜索空间的更大。我们设计了一个由堆式简单的ResNet基于细胞组成的 architecture，并开发了一种有效地探索大型搜索空间的搜索方法。我们显示，我们的框架，称为CycleGANAS，不仅能够有效地找到高性能的architecture，并且成功地解决了数据不均衡问题，通过个体搜索每个翻译方向。据我们所知，这是NAS的首次成果，并照亮了NAS的更复杂结构的应用。
</details></li>
</ul>
<hr>
<h2 id="Detecting-As-Labeling-Rethinking-LiDAR-camera-Fusion-in-3D-Object-Detection"><a href="#Detecting-As-Labeling-Rethinking-LiDAR-camera-Fusion-in-3D-Object-Detection" class="headerlink" title="Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object Detection"></a>Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07152">http://arxiv.org/abs/2311.07152</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HuangJunJie2017/BEVDet">https://github.com/HuangJunJie2017/BEVDet</a></li>
<li>paper_authors: Junjie Huang, Yun Ye, Zhujin Liang, Yi Shan, Dalong Du</li>
<li>for: 本文旨在提出一种新的3D物体检测方法，以解决LiDAR-camera结合体系中的过拟合问题。</li>
<li>methods: 本文提出了一种基于’检测为标签’（Detecting As Labeling，DAL）的新方法，通过imitating数据注释过程，建立了一个简单的预测管道，并使用了最简单的训练方法来最小化依赖性和提高可移植性。</li>
<li>results: 对比 existed方法，提出的DAL方法在性能和可移植性两个方面具有明显的优势，可以作为未来研发和实际应用的理想基线。<details>
<summary>Abstract</summary>
3D object Detection with LiDAR-camera encounters overfitting in algorithm development which is derived from the violation of some fundamental rules. We refer to the data annotation in dataset construction for theory complementing and argue that the regression task prediction should not involve the feature from the camera branch. By following the cutting-edge perspective of 'Detecting As Labeling', we propose a novel paradigm dubbed DAL. With the most classical elementary algorithms, a simple predicting pipeline is constructed by imitating the data annotation process. Then we train it in the simplest way to minimize its dependency and strengthen its portability. Though simple in construction and training, the proposed DAL paradigm not only substantially pushes the performance boundary but also provides a superior trade-off between speed and accuracy among all existing methods. With comprehensive superiority, DAL is an ideal baseline for both future work development and practical deployment. The code has been released to facilitate future work on https://github.com/HuangJunJie2017/BEVDet.
</details>
<details>
<summary>摘要</summary>
三元 объек特检测遇到了过拟合问题在算法开发中，这是由数据注解在数据集建构中的违反基本规则所致。我们提出了一种新的思路，称为“检测为标注”（DAL）。我们采用了最经典的元素算法，构建了一个简单的预测管道，并通过模仿数据注解过程来训练。尽管简单构建和训练，但提议的 DAL 方法不仅可以显著提高性能boundary，还提供了速度和准确性之间的优秀平衡。在所有现有方法中，DAL 具有最高的全面优势，是未来研发和实践中的理想基eline。代码已经发布到了https://github.com/HuangJunJie2017/BEVDet，以便未来研究。
</details></li>
</ul>
<hr>
<h2 id="PadChannel-Improving-CNN-Performance-through-Explicit-Padding-Encoding"><a href="#PadChannel-Improving-CNN-Performance-through-Explicit-Padding-Encoding" class="headerlink" title="PadChannel: Improving CNN Performance through Explicit Padding Encoding"></a>PadChannel: Improving CNN Performance through Explicit Padding Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07623">http://arxiv.org/abs/2311.07623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aussieseaweed/pad-channel">https://github.com/aussieseaweed/pad-channel</a></li>
<li>paper_authors: Juho Kim</li>
<li>for: 提高 CNN 的表征EXTRACTION 精度，通过将paddingstatus编码为另一个输入通道，使 CNN 能够轻松地分辨真正的像素和padding区域。</li>
<li>methods: 提出了 PadChannel  padding 方法，该方法将 padding status 编码为另一个输入通道，以便 CNN 能够轻松地分辨真正的像素和padding区域。</li>
<li>results: 在 ImageNet-1K 图像分类任务上，通过 incorporating PadChannel  into several prominent CNN architectures，实现了小幅提升性能和明显减少了变差值，而且计算成本增加不多。<details>
<summary>Abstract</summary>
In convolutional neural networks (CNNs), padding plays a pivotal role in preserving spatial dimensions throughout the layers. Traditional padding techniques do not explicitly distinguish between the actual image content and the padded regions, potentially causing CNNs to incorrectly interpret the boundary pixels or regions that resemble boundaries. This ambiguity can lead to suboptimal feature extraction. To address this, we propose PadChannel, a novel padding method that encodes padding statuses as an additional input channel, enabling CNNs to easily distinguish genuine pixels from padded ones. By incorporating PadChannel into several prominent CNN architectures, we observed small performance improvements and notable reductions in the variances on the ImageNet-1K image classification task at marginal increases in the computational cost. The source code is available at https://github.com/AussieSeaweed/pad-channel
</details>
<details>
<summary>摘要</summary>
在卷积神经网络（CNN）中，填充扮演着保持空间维度的重要角色。传统的填充技术不能显式地区分实际图像内容和填充区域，可能导致CNN incorrectly interpretBoundary pixels或区域，从而导致优化特征提取的困难。为解决这个问题，我们提议PadChannel，一种新的填充方法，它将填充状态编码为一个额外输入通道，使CNN可以轻松地 отличи出真实的像素与填充区域。通过将PadChannel integrating into severaleminent CNN architectures, we observed small performance improvements and notable reductions in the variances on the ImageNet-1K image classification task at marginal increases in the computational cost.  Source code available at <https://github.com/AussieSeaweed/pad-channel>。
</details></li>
</ul>
<hr>
<h2 id="Attention-Challenging-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification"><a href="#Attention-Challenging-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification" class="headerlink" title="Attention-Challenging Multiple Instance Learning for Whole Slide Image Classification"></a>Attention-Challenging Multiple Instance Learning for Whole Slide Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07125">http://arxiv.org/abs/2311.07125</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dazhangyu123/acmil">https://github.com/dazhangyu123/acmil</a></li>
<li>paper_authors: Yunlong Zhang, Honglin Li, Yuxuan Sun, Sunyi Zheng, Chenglu Zhu, Lin Yang</li>
<li>for: 本研究旨在解决多个实例学习（MIL）方法在整个扫描图像（WSI）分析中遇到的过拟合问题。</li>
<li>methods: 本研究提出了一种名为 Attention-Challenging MIL（ACMIL）的方法，旨在让注意力机制能够捕捉更多的挑战性预测实例。ACMIL 使用了两种技术：多支分支注意力（MBA）和随机 Top-K 实例屏蔽（STKIM）。</li>
<li>results: 在三个 WSI 数据集上进行评估，ACMIL 表现出色，超过了现有方法。此外，通过热图视化、UMAP 视化和注意值统计，本研究详细展示了 ACMIL 在超越过拟合挑战的效果。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/dazhangyu123/ACMIL%7D">https://github.com/dazhangyu123/ACMIL}</a> 上获取。<details>
<summary>Abstract</summary>
Overfitting remains a significant challenge in the application of Multiple Instance Learning (MIL) methods for Whole Slide Image (WSI) analysis. Visualizing heatmaps reveals that current MIL methods focus on a subset of predictive instances, hindering effective model generalization. To tackle this, we propose Attention-Challenging MIL (ACMIL), aimed at forcing the attention mechanism to capture more challenging predictive instances. ACMIL incorporates two techniques, Multiple Branch Attention (MBA) to capture richer predictive instances and Stochastic Top-K Instance Masking (STKIM) to suppress simple predictive instances. Evaluation on three WSI datasets outperforms state-of-the-art methods. Additionally, through heatmap visualization, UMAP visualization, and attention value statistics, this paper comprehensively illustrates ACMIL's effectiveness in overcoming the overfitting challenge. The source code is available at \url{https://github.com/dazhangyu123/ACMIL}.
</details>
<details>
<summary>摘要</summary>
多个实例学习（MIL）方法在整个扫描图像（WSI）分析中仍然存在至关重要的挑战，即过拟合。使用热图可视化显示，当前MIL方法往往会围绕一部分预测实例集中心化，从而降低模型的泛化能力。为解决这个问题，我们提议了吸引挑战（ACMIL）方法，旨在让吸引机制捕捉更多的挑战预测实例。ACMIL方法包括多支分支吸引（MBA）和随机Top-K实例屏蔽（STKIM）两种技术，以捕捉更加丰富的预测实例和避免简单的预测实例。在三个WSI数据集上进行评估，ACMIL方法超越了现有方法。此外，通过热图可视化、UMAP可视化和吸引值统计，本文全面地展示了ACMIL方法在超越过拟合挑战的效果。ACMIL源代码可以在GitHub上获取，具体请参考\url{https://github.com/dazhangyu123/ACMIL}.
</details></li>
</ul>
<hr>
<h2 id="SpectralGPT-Spectral-Foundation-Model"><a href="#SpectralGPT-Spectral-Foundation-Model" class="headerlink" title="SpectralGPT: Spectral Foundation Model"></a>SpectralGPT: Spectral Foundation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07113">http://arxiv.org/abs/2311.07113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danfeng Hong, Bing Zhang, Xuyang Li, Yuxuan Li, Chenyu Li, Jing Yao, Naoto Yokoya, Hao Li, Xiuping Jia, Antonio Plaza, Gamba Paolo, Jon Atli Benediktsson, Jocelyn Chanussot</li>
<li>for: 这个研究旨在开发一个能够处理颜色spectral remote sensing（RS）影像的通用基础模型，以探索spectral RS 数据的应用前景。</li>
<li>methods: 本研究使用了一种名为SpectralGPT的新型3D生成预训练trasnformer（GPT），可以处理不同大小、分辨率、时间序列和区域的spectral RS 影像，并且可以进行预训练和进一步训练。</li>
<li>results: 根据我们的评估结果，预训练后的SpectralGPT模型具有超过6000万个参数，并且在四个下渠任务中（单&#x2F;多标Scene分类、semantic segmentation和变化检测）表现出了明显的性能提升。<details>
<summary>Abstract</summary>
The foundation model has recently garnered significant attention due to its potential to revolutionize the field of visual representation learning in a self-supervised manner. While most foundation models are tailored to effectively process RGB images for various visual tasks, there is a noticeable gap in research focused on spectral data, which offers valuable information for scene understanding, especially in remote sensing (RS) applications. To fill this gap, we created for the first time a universal RS foundation model, named SpectralGPT, which is purpose-built to handle spectral RS images using a novel 3D generative pretrained transformer (GPT). Compared to existing foundation models, SpectralGPT 1) accommodates input images with varying sizes, resolutions, time series, and regions in a progressive training fashion, enabling full utilization of extensive RS big data; 2) leverages 3D token generation for spatial-spectral coupling; 3) captures spectrally sequential patterns via multi-target reconstruction; 4) trains on one million spectral RS images, yielding models with over 600 million parameters. Our evaluation highlights significant performance improvements with pretrained SpectralGPT models, signifying substantial potential in advancing spectral RS big data applications within the field of geoscience across four downstream tasks: single/multi-label scene classification, semantic segmentation, and change detection.
</details>
<details>
<summary>摘要</summary>
底层模型最近受到了各种视觉学任务自动学习的潜在革命性的注意力。大多数底层模型都是针对RGB图像进行多种视觉任务的效果优化的。然而，在 spectral 数据方面，有一定的研究欠差，这些数据具有Scene 理解中的价值，尤其是在远程感知（RS）应用中。为了填补这个欠差，我们创造了首次的universal RS 底层模型，名为SpectralGPT，它使用了一种新的三维生成预训练变换器（GPT）来处理 spectral RS 图像。与现有的底层模型相比，SpectralGPT 具有以下优势：1. 可以处理不同大小、分辨率、时间序列和区域的输入图像，从而使用广泛的RS大数据进行全面利用。2. 通过三维token生成来实现空间-spectral的coupling。3. 通过多个目标重建来捕捉spectral序列的特征。4. 在一百万个spectral RS 图像上进行训练，实现了模型具有超过6亿个参数。我们的评估表明，使用预训练SpectralGPT模型可以获得显著的性能提升，这表明了这种方法在RS大数据应用中具有潜在的潜力。在四个下游任务中，预训练SpectralGPT模型都显示了显著的性能提升：单/多标Scene 分类、semantic segmentation和变化检测。
</details></li>
</ul>
<hr>
<h2 id="CLiF-VQA-Enhancing-Video-Quality-Assessment-by-Incorporating-High-Level-Semantic-Information-related-to-Human-Feelings"><a href="#CLiF-VQA-Enhancing-Video-Quality-Assessment-by-Incorporating-High-Level-Semantic-Information-related-to-Human-Feelings" class="headerlink" title="CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level Semantic Information related to Human Feelings"></a>CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level Semantic Information related to Human Feelings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07090">http://arxiv.org/abs/2311.07090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yachun Mi, Yu Li, Yan Shu, Chen Hui, Puchao Zhou, Shaohui Liu</li>
<li>For: 这篇论文主要关注视频质量评估 (VQA) 领域，旨在模拟人类视觉系统 (HVS) 对视频质量的评估。* Methods: 该论文提出了一种新的 VQA 方法，即 CLiF-VQA，它考虑了视频中人类情感的影响，同时也考虑了视频的空间特征。为了有效提取视频中人类情感的特征，该方法首次利用 CLIP 和人类情感的一致性进行研究。具体来说，该方法设计了多个对人类情感有关的目标和主观描述作为推荐。此外，该方法还提出了一种基于 CLIP 的 semantic feature extractor (SFE)，可以从视频帧中提取人类情感相关的特征。* Results: 该论文的实验结果表明，提出的 CLiF-VQA 方法在多个 VQA 数据集上表现出色。<details>
<summary>Abstract</summary>
Video Quality Assessment (VQA) aims to simulate the process of perceiving video quality by the human visual system (HVS). The judgments made by HVS are always influenced by human subjective feelings. However, most of the current VQA research focuses on capturing various distortions in the spatial and temporal domains of videos, while ignoring the impact of human feelings. In this paper, we propose CLiF-VQA, which considers both features related to human feelings and spatial features of videos. In order to effectively extract features related to human feelings from videos, we explore the consistency between CLIP and human feelings in video perception for the first time. Specifically, we design multiple objective and subjective descriptions closely related to human feelings as prompts. Further we propose a novel CLIP-based semantic feature extractor (SFE) which extracts features related to human feelings by sliding over multiple regions of the video frame. In addition, we further capture the low-level-aware features of the video through a spatial feature extraction module. The two different features are then aggregated thereby obtaining the quality score of the video. Extensive experiments show that the proposed CLiF-VQA exhibits excellent performance on several VQA datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GazeForensics-DeepFake-Detection-via-Gaze-guided-Spatial-Inconsistency-Learning"><a href="#GazeForensics-DeepFake-Detection-via-Gaze-guided-Spatial-Inconsistency-Learning" class="headerlink" title="GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency Learning"></a>GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07075">http://arxiv.org/abs/2311.07075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinlin He, Chunlei Peng, Dechuang Liu, Nannan Wang, Xinbo Gao</li>
<li>for: 这个研究旨在提高深伪检测的精度，以保护人们的隐私和公共安全。</li>
<li>methods: 本研究使用了3D双眼视线估计模型来取得视线表现，并与通用特征结合使用，以增强深伪检测模型的表现。</li>
<li>results: 实验结果显示，提案的GazeForensics方法可以超过目前的州OF-THE-ART方法。<details>
<summary>Abstract</summary>
DeepFake detection is pivotal in personal privacy and public safety. With the iterative advancement of DeepFake techniques, high-quality forged videos and images are becoming increasingly deceptive. Prior research has seen numerous attempts by scholars to incorporate biometric features into the field of DeepFake detection. However, traditional biometric-based approaches tend to segregate biometric features from general ones and freeze the biometric feature extractor. These approaches resulted in the exclusion of valuable general features, potentially leading to a performance decline and, consequently, a failure to fully exploit the potential of biometric information in assisting DeepFake detection. Moreover, insufficient attention has been dedicated to scrutinizing gaze authenticity within the realm of DeepFake detection in recent years. In this paper, we introduce GazeForensics, an innovative DeepFake detection method that utilizes gaze representation obtained from a 3D gaze estimation model to regularize the corresponding representation within our DeepFake detection model, while concurrently integrating general features to further enhance the performance of our model. Experiment results reveal that our proposed GazeForensics outperforms the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
深度假像检测对个人隐私和公共安全具有核心作用。随着深度假像技术的不断提高，高质量的假造视频和图像变得越来越欺骗性。先前的研究中，学者们已经尝试将生物特征 incorporated 到深度假像检测领域中。然而，传统的生物特征基于的方法通常将生物特征与通用特征分离开来，这会导致排除有价值的通用特征，从而导致性能下降，最终无法完全利用生物信息的潜在优势。此外，近年来对 DeepFake 检测中的视线真实性的研究并未受到足够的关注。本文提出了一种名为 GazeForensics 的创新的 DeepFake 检测方法，该方法使用来自 3D 视线估计模型获得的视线表示来补做对应的表示在我们的 DeepFake 检测模型中，同时并入通用特征以进一步提高我们的模型的性能。实验结果表明，我们的提议的 GazeForensics 方法在当前状态的方法中具有优异的性能。
</details></li>
</ul>
<hr>
<h2 id="L-0-Sampler-An-L-0-Model-Guided-Volume-Sampling-for-NeRF"><a href="#L-0-Sampler-An-L-0-Model-Guided-Volume-Sampling-for-NeRF" class="headerlink" title="$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF"></a>$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07044">http://arxiv.org/abs/2311.07044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangchen Li, Juyong Zhang<br>for:This paper aims to improve the Neural Radiance Fields (NeRF) method by proposing a new sampling strategy called $L_0$-Sampler.methods:The $L_0$-Sampler incorporates the $L_0$ model into the weight function $w(t)$ to guide the sampling process, using piecewise exponential functions for interpolation.results:The proposed $L_0$-Sampler can achieve stable performance improvements in NeRF and related tasks like 3D reconstruction, with the advantage of being easily implemented with few lines of code.Here is the text in Simplified Chinese:for:这篇论文目标是改进Neural Radiance Fields（NeRF）方法，提出一种新的采样策略 called $L_0$-Sampler。methods:$L_0$-Sampler将$L_0$模型integrated into weight函数$w(t)$中，使用piecewise exponential函数进行插值。results:提议的$L_0$-Sampler可以在NeRF和相关任务如3D重建中实现稳定性提升，同时易于实现，只需几行代码。<details>
<summary>Abstract</summary>
Since being proposed, Neural Radiance Fields (NeRF) have achieved great success in related tasks, mainly adopting the hierarchical volume sampling (HVS) strategy for volume rendering. However, the HVS of NeRF approximates distributions using piecewise constant functions, which provides a relatively rough estimation. Based on the observation that a well-trained weight function $w(t)$ and the $L_0$ distance between points and the surface have very high similarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into $w(t)$ to guide the sampling process. Specifically, we propose to use piecewise exponential functions rather than piecewise constant functions for interpolation, which can not only approximate quasi-$L_0$ weight distributions along rays quite well but also can be easily implemented with few lines of code without additional computational burden. Stable performance improvements can be achieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D reconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/ .
</details>
<details>
<summary>摘要</summary>
Since being proposed, Neural Radiance Fields (NeRF) have achieved great success in related tasks, mainly adopting the hierarchical volume sampling (HVS) strategy for volume rendering. However, the HVS of NeRF approximates distributions using piecewise constant functions, which provides a relatively rough estimation. Based on the observation that a well-trained weight function $w(t)$ and the $L_0$ distance between points and the surface have very high similarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into $w(t)$ to guide the sampling process. Specifically, we propose to use piecewise exponential functions rather than piecewise constant functions for interpolation, which can not only approximate quasi-$L_0$ weight distributions along rays quite well but also can be easily implemented with few lines of code without additional computational burden. Stable performance improvements can be achieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D reconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/.Here's the word-for-word translation of the text into Simplified Chinese: desde que se propuso, Neural Radiance Fields (NeRF) han tenido gran éxito en tareas relacionadas, principalmente adoptando la estrategia de muestreo de volumen jerárquico (HVS) para la renderización de volumenes. Sin embargo, el HVS de NeRF aproxima distribuciones utilizando funciones constantes piecewise, lo que proporciona una estimación relativamente rough. Basándonos en la observación de que una función de peso bien entrenada $w(t)$ y la distancia $L_0$ entre puntos y la superficie tienen una alta similitud, propodemos $L_0$-Sampler al incorporar el modelo $L_0$ en $w(t)$ para guiar el proceso de muestreo. Específicamente, propodemos utilizar funciones exponenciales piecewise en lugar de funciones constantes piecewise para la interpolación, lo que puede no solo aproximar distribucciones de peso quasi-$L_0$ en rayas muy bien but also puede ser fácilmente implementado con pocas líneas de código sin un carga adicional computacional. Se pueden lograr mejores mejoras estables en el rendimiento al aplicar $L_0$-Sampler a NeRF y tareas relacionadas como la reconstrucción 3D. El código está disponible en https://ustc3dv.github.io/L0-Sampler/.
</details></li>
</ul>
<hr>
<h2 id="Open-Vocabulary-Video-Anomaly-Detection"><a href="#Open-Vocabulary-Video-Anomaly-Detection" class="headerlink" title="Open-Vocabulary Video Anomaly Detection"></a>Open-Vocabulary Video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07042">http://arxiv.org/abs/2311.07042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wu, Xuerong Zhou, Guansong Pang, Yujia Sun, Jing Liu, Peng Wang, Yanning Zhang</li>
<li>for: 这 paper 旨在解决开放 vocabulary video anomaly detection (OVVAD) 问题，即通过预训练大型模型来检测和分类已知和未知异常。</li>
<li>methods: 该 paper 提出了一种分解 OVVAD 任务为两个互补任务 – 类型不敏感检测和类型特定分类 – 并同时优化两个任务。具体来说，该 paper 提出了一种 semantic knowledge injection module，用于将大型语言模型中的 semantic knowledge 引入检测任务中，以及一种 anomaly synthesis module，用于通过大型视觉生成模型生成 pseudo 未知异常视频，以便分类任务中更好地检测和分类各种 seen 和 unseen 异常。</li>
<li>results: 该 paper 的实验结果表明，其模型在 OVVAD 任务中取得了状态公平的表现，比如在 three  widely-used benchmark 上的 experiment 中。<details>
<summary>Abstract</summary>
Video anomaly detection (VAD) with weak supervision has achieved remarkable performance in utilizing video-level labels to discriminate whether a video frame is normal or abnormal. However, current approaches are inherently limited to a closed-set setting and may struggle in open-world applications where there can be anomaly categories in the test data unseen during training. A few recent studies attempt to tackle a more realistic setting, open-set VAD, which aims to detect unseen anomalies given seen anomalies and normal videos. However, such a setting focuses on predicting frame anomaly scores, having no ability to recognize the specific categories of anomalies, despite the fact that this ability is essential for building more informed video surveillance systems. This paper takes a step further and explores open-vocabulary video anomaly detection (OVVAD), in which we aim to leverage pre-trained large models to detect and categorize seen and unseen anomalies. To this end, we propose a model that decouples OVVAD into two mutually complementary tasks -- class-agnostic detection and class-specific classification -- and jointly optimizes both tasks. Particularly, we devise a semantic knowledge injection module to introduce semantic knowledge from large language models for the detection task, and design a novel anomaly synthesis module to generate pseudo unseen anomaly videos with the help of large vision generation models for the classification task. These semantic knowledge and synthesis anomalies substantially extend our model's capability in detecting and categorizing a variety of seen and unseen anomalies. Extensive experiments on three widely-used benchmarks demonstrate our model achieves state-of-the-art performance on OVVAD task.
</details>
<details>
<summary>摘要</summary>
视频异常检测（VAD）通过弱监督得到了非常出色的表现，可以使用视频帧级别的标签来判断视频帧是否正常。然而，现有的方法受限于关闭集成环境，可能在开放世界应用中遇到未知的异常类型。一些最近的研究尝试解决更加现实的设定，开放集成VAD，以便在测试数据中未经训练的异常类型上检测异常。然而，这种设定仅仅是预测帧异常分数，无法识别特定的异常类型，尽管这种能力是建立更加知ledge的视频监测系统的关键。本文尝试一步更进一步，探索开放词汇视频异常检测（OVVAD），我们希望通过利用预训练大型模型来检测和分类已知和未知异常。为此，我们提议一个模型，将OVVAD分解成两个互补性任务：无关类型检测和类型特定分类，并同时优化两个任务。特别是，我们设计了一个语义知识注入模块，将语义知识从大型语言模型引入检测任务，并设计了一个异常生成模块，通过大视力生成模型生成 Pseudo 未知异常视频。这些语义知识和生成异常substantially 提高了我们模型的异常检测和分类能力。广泛的实验表明，我们的模型在OVVAD任务中具有状态级别的表现。
</details></li>
</ul>
<hr>
<h2 id="Pretrain-like-Your-Inference-Masked-Tuning-Improves-Zero-Shot-Composed-Image-Retrieval"><a href="#Pretrain-like-Your-Inference-Masked-Tuning-Improves-Zero-Shot-Composed-Image-Retrieval" class="headerlink" title="Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed Image Retrieval"></a>Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07622">http://arxiv.org/abs/2311.07622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Chen, Hanjiang Lai</li>
<li>for:  This paper focuses on zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target image based on textual modifications to a reference image without triplet labeling.</li>
<li>methods: The paper introduces a novel unlabeled and pre-trained masked tuning approach to reduce the gap between the pre-trained model and the downstream CIR task. The approach uses the text and the masked image to learn the modifications of the original image.</li>
<li>results: The approach significantly outperforms the baseline models on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.<details>
<summary>Abstract</summary>
Zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target image based on textual modifications to a reference image without triplet labeling, has gained more and more attention. Current ZS-CIR research mainly relies on two unlabeled pre-trained models: the vision-language model, e.g., CLIP, and the Pic2Word/textual inversion model. However, the pre-trained models and CIR tasks have substantial discrepancies, where the pre-trained models learn the similarities between vision and language but CIR aims to learn the modifications of the image guided by text. In this paper, we introduce a novel unlabeled and pre-trained masked tuning approach to reduce the gap between the pre-trained model and the downstream CIR task. We first reformulate the pre-trained vision-language contrastive learning as the CIR task, where we randomly mask input image patches to generate $\langle$masked image, text, image$\rangle$ triple from an image-text pair. Then, we propose a masked tuning, which uses the text and the masked image to learn the modifications of the original image. With such a simple design, it can learn to capture fine-grained text-guided modifications. Extensive experimental results demonstrate the significant superiority of our approach over the baseline models on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.
</details>
<details>
<summary>摘要</summary>
Zero-shot组合图像检索（ZS-CIR），旨在基于文本修改参照图像而不需要三元标注，已经吸引了更多的关注。当前ZS-CIR研究主要基于两个无标注预训练模型：视觉语言模型，例如CLIP，以及Pic2Word/文本反转模型。然而，预训练模型和CIR任务之间存在substantial差异，预训练模型学习视觉和语言之间的相似性，而CIR任务则是学习文本指导图像的修改。在这篇论文中，我们介绍了一种新的无标注预训练掩模型调整方法，以减少预训练模型和下游CIR任务之间的差异。我们首先将预训练视觉语言对比学习重新формализова为CIR任务，将输入图像块随机掩蔽，生成$\langle$掩模图像、文本、原始图像$\rangle$三元组。然后，我们提议一种掩模调整，使用文本和掩模图像来学习原始图像的修改。这种简单的设计可以学习到细致的文本指导修改。我们对三个ZS-CIR数据集进行了广泛的实验，结果表明我们的方法在baseline模型上显著超越。
</details></li>
</ul>
<hr>
<h2 id="TTMFN-Two-stream-Transformer-based-Multimodal-Fusion-Network-for-Survival-Prediction"><a href="#TTMFN-Two-stream-Transformer-based-Multimodal-Fusion-Network-for-Survival-Prediction" class="headerlink" title="TTMFN: Two-stream Transformer-based Multimodal Fusion Network for Survival Prediction"></a>TTMFN: Two-stream Transformer-based Multimodal Fusion Network for Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07033">http://arxiv.org/abs/2311.07033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiquan Ge, Xiangyang Hu, Rungen Huang, Gangyong Jia, Yaqi Wang, Renshu Gu, Changmiao Wang, Elazab Ahmed, Linyan Wang, Juan Ye, Ye Li</li>
<li>for: 预测癌症患者生存时间的研究</li>
<li>methods: 提议一种基于深度学习的两树式多modal合并网络（TTMFN），将生物 PATHOLOGICAL 图像和基因表达数据融合以提高预测性能</li>
<li>results: TTMFN 在四个来自 The Cancer Genome Atlas 的数据集上实现了最佳或与状态艺术方法相当的预测结果，提高了患者生存时间的预测精度<details>
<summary>Abstract</summary>
Survival prediction plays a crucial role in assisting clinicians with the development of cancer treatment protocols. Recent evidence shows that multimodal data can help in the diagnosis of cancer disease and improve survival prediction. Currently, deep learning-based approaches have experienced increasing success in survival prediction by integrating pathological images and gene expression data. However, most existing approaches overlook the intra-modality latent information and the complex inter-modality correlations. Furthermore, existing modalities do not fully exploit the immense representational capabilities of neural networks for feature aggregation and disregard the importance of relationships between features. Therefore, it is highly recommended to address these issues in order to enhance the prediction performance by proposing a novel deep learning-based method. We propose a novel framework named Two-stream Transformer-based Multimodal Fusion Network for survival prediction (TTMFN), which integrates pathological images and gene expression data. In TTMFN, we present a two-stream multimodal co-attention transformer module to take full advantage of the complex relationships between different modalities and the potential connections within the modalities. Additionally, we develop a multi-head attention pooling approach to effectively aggregate the feature representations of the two modalities. The experiment results on four datasets from The Cancer Genome Atlas demonstrate that TTMFN can achieve the best performance or competitive results compared to the state-of-the-art methods in predicting the overall survival of patients.
</details>
<details>
<summary>摘要</summary>
生存预测在医学家开发癌症治疗协议中发挥关键作用。现有证据表明，多modal数据可以帮助诊断癌症疾病并提高生存预测。目前，深度学习基于的方法在生存预测中经历了增长的成功，通过将 PATHOLOGICAL IMAGES 和基因表达数据集成起来。然而，大多数现有方法忽视INTRA-MODALITY LATENT INFORMATION和复杂的交叉modalities关系。此外，现有的modalities不完全利用神经网络的庞大表达能力进行特征聚合，也忽视了特征之间的关系。因此，以提高预测性能的目的，我们建议提出一种新的深度学习基于的方法。我们提出了一种名为 Two-stream Transformer-based Multimodal Fusion Network 的新框架（TTMFN），它将 PATHOLOGICAL IMAGES 和基因表达数据集成起来。在 TTMFN 中，我们提出了一种两树多模态协作变换模块，以便充分利用不同modalities之间的复杂关系和可能的连接。此外，我们开发了一种多头注意池化方法，以有效地聚合 PATHOLOGICAL IMAGES 和基因表达数据的特征表示。实验结果表明，在 The Cancer Genome Atlas 上的四个数据集上，TTMFN 可以获得最佳性能或与当前状态艺术方法竞争。
</details></li>
</ul>
<hr>
<h2 id="PICS-in-Pics-Physics-Informed-Contour-Selection-for-Rapid-Image-Segmentation"><a href="#PICS-in-Pics-Physics-Informed-Contour-Selection-for-Rapid-Image-Segmentation" class="headerlink" title="PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation"></a>PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07002">http://arxiv.org/abs/2311.07002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vikas Dwivedi, Balaji Srinivasan, Ganapathy Krishnamurthi</li>
<li>for: 这篇论文的目的是提出一个可读性好的深度图像分类模型训练方法，并且不需要大量、高品质的标注数据。</li>
<li>methods: 这篇论文使用了Physics Informed Contour Selection（PICS）算法，它是一种可解释的、以物理为指导的图像分类算法，它结合了Physics-Informed Neural Networks（PINNs）和活动曲线模型（snake）。PICS使用了立方spline代替深度神经网络，因此它很快速和计算轻量级。</li>
<li>results: 这篇论文透过实验显示PICS可以快速和高效地完成3D图像分类，并且可以借由转移学习来加速分类。PICS还引入了一个新的凸形积分项，以增强分类质量。总的来说，PICS具有许多新的特点，例如网络架构、转移学习和物理灵感损失，因此显示了可循环和可进一步改进的潜力。<details>
<summary>Abstract</summary>
Effective training of deep image segmentation models is challenging due to the need for abundant, high-quality annotations. Generating annotations is laborious and time-consuming for human experts, especially in medical image segmentation. To facilitate image annotation, we introduce Physics Informed Contour Selection (PICS) - an interpretable, physics-informed algorithm for rapid image segmentation without relying on labeled data. PICS draws inspiration from physics-informed neural networks (PINNs) and an active contour model called snake. It is fast and computationally lightweight because it employs cubic splines instead of a deep neural network as a basis function. Its training parameters are physically interpretable because they directly represent control knots of the segmentation curve. Traditional snakes involve minimization of the edge-based loss functionals by deriving the Euler-Lagrange equation followed by its numerical solution. However, PICS directly minimizes the loss functional, bypassing the Euler Lagrange equations. It is the first snake variant to minimize a region-based loss function instead of traditional edge-based loss functions. PICS uniquely models the three-dimensional (3D) segmentation process with an unsteady partial differential equation (PDE), which allows accelerated segmentation via transfer learning. To demonstrate its effectiveness, we apply PICS for 3D segmentation of the left ventricle on a publicly available cardiac dataset. While doing so, we also introduce a new convexity-preserving loss term that encodes the shape information of the left ventricle to enhance PICS's segmentation quality. Overall, PICS presents several novelties in network architecture, transfer learning, and physics-inspired losses for image segmentation, thereby showing promising outcomes and potential for further refinement.
</details>
<details>
<summary>摘要</summary>
实现深度图像分类模型的训练非常困难，因为需要充足的、高品质的标注。生成标注是人工专家很传统和时间耗费的，特别是医疗图像分类。为了促进图像标注，我们提出了物理决定曲线选择（PICS）：一种可读性的、物理决定的算法，不需要标注数据。PICS受到物理决定神经网络（PINNs）和活动曲线模型（snake）的启发，它快速且轻量级的，因为它使用立方体spline而不是深度神经网络作为基础函数。它的训练参数是物理可解的，因为它们直接表示分类曲线的控制点。传统的蛇涉及到透过监督学习减少边界基于损失函数的最小化，但PICS直接对数据进行损失函数的最小化，不需要监督学习。PICS是首个将区域基于损失函数最小化，而不是传统的边界基于损失函数最小化。PICS具有实现三维（3D）分类过程的不稳定偏微分方程（PDE），可以通过转移学习加速分类。为了证明其效果，我们将PICS应用于公开可用的心脏组织数据集上3D左心脏分类。同时，我们也引入了一个新的凸形积分函数，以增强PICS的分类质量。总之，PICS具有训练网络架构、转移学习和物理决定损失函数等多个新特点，这些特点使得PICS在图像分类方面显示出了可塑性和潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.CV_2023_11_13/" data-id="clp89doft00n4i7882erqbjt4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.AI_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T12:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.AI_2023_11_13/">cs.AI - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Parrot-Trained-Adversarial-Examples-Pushing-the-Practicality-of-Black-Box-Audio-Attacks-against-Speaker-Recognition-Models"><a href="#Parrot-Trained-Adversarial-Examples-Pushing-the-Practicality-of-Black-Box-Audio-Attacks-against-Speaker-Recognition-Models" class="headerlink" title="Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models"></a>Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07780">http://arxiv.org/abs/2311.07780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu</li>
<li>for: 防御对话系统的安全性挑战，特别是对于真实世界中的语音识别系统。</li>
<li>methods: 提出了一种新的机制，即“喊鸟训练”（Parrot Training，PT），用于生成对目标模型的攻击。基于最近的语音转换技术（Voice Conversion，VC），使用一句短语的知识生成更多的假语音样本，以便在PT模型上进行攻击。</li>
<li>results: 实验结果显示，对于开源模型，PT-AEs可以达到45.8%-80.8%的攻击成功率，而对于智能设备，包括Apple HomePod（Siri）、Amazon Echo和Google Home，可以达到47.9%-58.3%的攻击成功率。<details>
<summary>Abstract</summary>
Audio adversarial examples (AEs) have posed significant security challenges to real-world speaker recognition systems. Most black-box attacks still require certain information from the speaker recognition model to be effective (e.g., keeping probing and requiring the knowledge of similarity scores). This work aims to push the practicality of the black-box attacks by minimizing the attacker's knowledge about a target speaker recognition model. Although it is not feasible for an attacker to succeed with completely zero knowledge, we assume that the attacker only knows a short (or a few seconds) speech sample of a target speaker. Without any probing to gain further knowledge about the target model, we propose a new mechanism, called parrot training, to generate AEs against the target model. Motivated by recent advancements in voice conversion (VC), we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech. Then, we use these parrot speech samples to train a parrot-trained(PT) surrogate model for the attacker. Under a joint transferability and perception framework, we investigate different ways to generate AEs on the PT model (called PT-AEs) to ensure the PT-AEs can be generated with high transferability to a black-box target model with good human perceptual quality. Real-world experiments show that the resultant PT-AEs achieve the attack success rates of 45.8% - 80.8% against the open-source models in the digital-line scenario and 47.9% - 58.3% against smart devices, including Apple HomePod (Siri), Amazon Echo, and Google Home, in the over-the-air scenario.
</details>
<details>
<summary>摘要</summary>
听音攻击（AE）对实际世界的 speaker recognition 系统构成了重要的安全挑战。大多数黑盒攻击仍然需要攻击者有一定的信息，如识别分数等（e.g., 探测和需要知道相似度）。这项工作的目标是使黑盒攻击变得更加实际，减少攻击者对目标 speaker recognition 模型的知识。尽管无法 completly 无知攻击成功，但我们假设攻击者只知道target speaker的一段（或几秒）的语音示例。无需进一步的探测，我们提议一种新的机制，called parrot training，来生成对目标模型的攻击。驱动于最近的语音转换（VC）技术，我们提议使用一个短语音示例来生成更多的合成语音样本，以达到更好的人工识别质量。然后，我们使用这些parrot speech样本来训练一个PT模型。在一个共同传播和感知框架下，我们研究不同的方法来生成PT模型上的攻击样本（PT-AEs），以确保PT-AEs可以高效地传播到黑盒目标模型，并且具有良好的人工识别质量。实际实验表明，结果的PT-AEs在开源模型上达到了45.8%-80.8%的攻击成功率，在数字线上enario中，以及47.9%-58.3%的攻击成功率，在过空间上enario中，包括Apple HomePod（Siri）、Amazon Echo和Google Home等智能设备。
</details></li>
</ul>
<hr>
<h2 id="GreekT5-A-Series-of-Greek-Sequence-to-Sequence-Models-for-News-Summarization"><a href="#GreekT5-A-Series-of-Greek-Sequence-to-Sequence-Models-for-News-Summarization" class="headerlink" title="GreekT5: A Series of Greek Sequence-to-Sequence Models for News Summarization"></a>GreekT5: A Series of Greek Sequence-to-Sequence Models for News Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07767">http://arxiv.org/abs/2311.07767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nc0der/greekt5">https://github.com/nc0der/greekt5</a></li>
<li>paper_authors: Nikolaos Giarelis, Charalampos Mastrokostas, Nikos Karacapilidis</li>
<li>for: 这篇论文主要是为了提出一系列的新型文本摘要模型，用于希腊新闻文章的自动摘要。</li>
<li>methods: 该论文使用了深度学习的Transformer模型，并对希腊语新闻文章进行了大量的训练和测试，以评估模型的性能。</li>
<li>results: 论文的实验结果显示，提出的新型模型在多种评价指标上都有显著的超越希腊BART模型的表现， indicating that the proposed models have better performance in summarizing Greek news articles.<details>
<summary>Abstract</summary>
Text summarization (TS) is a natural language processing (NLP) subtask pertaining to the automatic formulation of a concise and coherent summary that covers the major concepts and topics from one or multiple documents. Recent advancements in deep learning have led to the development of abstractive summarization transformer-based models, which outperform classical approaches. In any case, research in this field focuses on high resource languages such as English, while the corresponding work for low resource languages is still underdeveloped. Taking the above into account, this paper proposes a series of novel TS models for Greek news articles. The proposed models were thoroughly evaluated on the same dataset against GreekBART, which is the state-of-the-art model in Greek abstractive news summarization. Our evaluation results reveal that most of the proposed models significantly outperform GreekBART on various evaluation metrics. We make our evaluation code public, aiming to increase the reproducibility of this work and facilitate future research in the field.
</details>
<details>
<summary>摘要</summary>
文本摘要（TS）是自然语言处理（NLP）下一个子任务，它旨在自动生成简洁 coherent 的摘要，涵盖一或多个文档中的主要概念和话题。在深度学习的推动下，有一些抽象摘要转换器模型在英语等高资源语言的研究中取得了突出的成果，而对低资源语言的研究仍然处于不足的状态。本文提出了一系列新的TS模型，用于希腊新闻文章的摘要。这些模型经过了严格的评估，并与希腊BART模型进行了比较。我们的评估结果显示，大多数我们提出的模型在不同的评价指标上都有显著的提高，并且超过了希腊BART模型。我们将我们的评估代码公开，以增加这项工作的重复性和未来研究的便利。
</details></li>
</ul>
<hr>
<h2 id="Vision-Language-Integration-in-Multimodal-Video-Transformers-Partially-Aligns-with-the-Brain"><a href="#Vision-Language-Integration-in-Multimodal-Video-Transformers-Partially-Aligns-with-the-Brain" class="headerlink" title="Vision-Language Integration in Multimodal Video Transformers (Partially) Aligns with the Brain"></a>Vision-Language Integration in Multimodal Video Transformers (Partially) Aligns with the Brain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07766">http://arxiv.org/abs/2311.07766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dota Tianai Dong, Mariya Toneva</li>
<li>for: 这个论文旨在探讨多模态信息的集成是人工智能系统理解现实世界的重要前提。</li>
<li>methods: 该论文使用视频转换器模型，同时学习视觉、文本和声音。</li>
<li>results: 研究发现，通过利用 neuroscientific 证据，可以对预训练多模态视频转换器模型进行评估。 Results show that vision can enhance language processing performance, but the joint representation of the model does not capture brain-relevant information beyond that captured by individual modalities. Fine-tuning the model using a vision-language inference task can improve brain alignment.<details>
<summary>Abstract</summary>
Integrating information from multiple modalities is arguably one of the essential prerequisites for grounding artificial intelligence systems with an understanding of the real world. Recent advances in video transformers that jointly learn from vision, text, and sound over time have made some progress toward this goal, but the degree to which these models integrate information from modalities still remains unclear. In this work, we present a promising approach for probing a pre-trained multimodal video transformer model by leveraging neuroscientific evidence of multimodal information processing in the brain. Using brain recordings of participants watching a popular TV show, we analyze the effects of multi-modal connections and interactions in a pre-trained multi-modal video transformer on the alignment with uni- and multi-modal brain regions. We find evidence that vision enhances masked prediction performance during language processing, providing support that cross-modal representations in models can benefit individual modalities. However, we don't find evidence of brain-relevant information captured by the joint multi-modal transformer representations beyond that captured by all of the individual modalities. We finally show that the brain alignment of the pre-trained joint representation can be improved by fine-tuning using a task that requires vision-language inferences. Overall, our results paint an optimistic picture of the ability of multi-modal transformers to integrate vision and language in partially brain-relevant ways but also show that improving the brain alignment of these models may require new approaches.
</details>
<details>
<summary>摘要</summary>
We find that vision enhances masked prediction performance during language processing, providing support that cross-modal representations in models can benefit individual modalities. However, we do not find evidence of brain-relevant information captured by the joint multi-modal transformer representations beyond that captured by all of the individual modalities.We also show that the brain alignment of the pre-trained joint representation can be improved by fine-tuning using a task that requires vision-language inferences. Our results suggest that multi-modal transformers can integrate vision and language in partially brain-relevant ways, but improving the brain alignment of these models may require new approaches.
</details></li>
</ul>
<hr>
<h2 id="The-Disagreement-Problem-in-Faithfulness-Metrics"><a href="#The-Disagreement-Problem-in-Faithfulness-Metrics" class="headerlink" title="The Disagreement Problem in Faithfulness Metrics"></a>The Disagreement Problem in Faithfulness Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07763">http://arxiv.org/abs/2311.07763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian Barr, Noah Fatsi, Leif Hancox-Li, Peter Richter, Daniel Proano, Caleb Mok</li>
<li>for: 这个论文的目的是对黑盒机器学习模型的解释进行评估。</li>
<li>methods: 这篇论文使用了多种方法来评估解释的准确性。</li>
<li>results: 研究发现现有的 metric 不符合， leaving users 无法选择最准确的解释。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The field of explainable artificial intelligence (XAI) aims to explain how black-box machine learning models work. Much of the work centers around the holy grail of providing post-hoc feature attributions to any model architecture. While the pace of innovation around novel methods has slowed down, the question remains of how to choose a method, and how to make it fit for purpose. Recently, efforts around benchmarking XAI methods have suggested metrics for that purpose -- but there are many choices. That bounty of choice still leaves an end user unclear on how to proceed. This paper focuses on comparing metrics with the aim of measuring faithfulness of local explanations on tabular classification problems -- and shows that the current metrics don't agree; leaving users unsure how to choose the most faithful explanations.
</details>
<details>
<summary>摘要</summary>
XAI（解释人工智能）领域目标是解释黑盒机器学习模型的工作原理。大多数工作集中在寻求“后期特征归因”，即任何模型架构都能提供解释。虽然创新的速度有所减速，但问题是如何选择方法，以及如何使其适用。近期的XAI方法测试建议了多种指标，但选择它们仍然是一个问题。这篇论文将 comparing metrics，以衡量本地解释的准确性在表格分类问题上，并显示当前指标之间没有一致，使用者无法选择最准确的解释。
</details></li>
</ul>
<hr>
<h2 id="Amodal-Optical-Flow"><a href="#Amodal-Optical-Flow" class="headerlink" title="Amodal Optical Flow"></a>Amodal Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07761">http://arxiv.org/abs/2311.07761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Luz, Rohit Mohan, Ahmed Rida Sekkat, Oliver Sawade, Elmar Matthes, Thomas Brox, Abhinav Valada</li>
<li>for: 这个论文主要研究了在透明或填塞物体场景下的光流估计问题，并提出了模块化光流（Amodal Optical Flow）来解决这些问题。</li>
<li>methods: 作者提出了一种新的任务——模块化光流估计，并为这个任务提供了扩展的AmodalSynthDrive数据集，以便进行研究。他们还提出了一种新的Initialization方法——AmodalFlowNet，该方法使用了变换器来实现层次结构的特征传播和模块化Semantic Grounding。</li>
<li>results: 作者在大量实验中证明了模块化光流的可行性，并示出了其在下游任务中的用用，如精准跟踪。他们还提供了一种新的评价指标——Amodal Flow Quality，以便量化估计的性能。<details>
<summary>Abstract</summary>
Optical flow estimation is very challenging in situations with transparent or occluded objects. In this work, we address these challenges at the task level by introducing Amodal Optical Flow, which integrates optical flow with amodal perception. Instead of only representing the visible regions, we define amodal optical flow as a multi-layered pixel-level motion field that encompasses both visible and occluded regions of the scene. To facilitate research on this new task, we extend the AmodalSynthDrive dataset to include pixel-level labels for amodal optical flow estimation. We present several strong baselines, along with the Amodal Flow Quality metric to quantify the performance in an interpretable manner. Furthermore, we propose the novel AmodalFlowNet as an initial step toward addressing this task. AmodalFlowNet consists of a transformer-based cost-volume encoder paired with a recurrent transformer decoder which facilitates recurrent hierarchical feature propagation and amodal semantic grounding. We demonstrate the tractability of amodal optical flow in extensive experiments and show its utility for downstream tasks such as panoptic tracking. We make the dataset, code, and trained models publicly available at http://amodal-flow.cs.uni-freiburg.de.
</details>
<details>
<summary>摘要</summary>
optical flow 估计在透明或屏蔽物体的情况下非常具有挑战性。在这项工作中，我们在任务层面上解决这些挑战，通过插入amodal optical flow，即混合可见和透明的像流。而不是只表示可见区域，我们定义amodal optical flow为多层级像素级动力场，涵盖了场景中可见和透明区域的全部。为便于研究这个新任务，我们将AmodalSynthDrive数据集扩展到包括像素级标签 дляamodal optical flow估计。我们提出了多种强大的基线，以及Amodal Flow Quality指标来衡量性能的可读性。此外，我们还提出了 novel AmodalFlowNet，它包括一个基于变换器的像素级核心编码器和一个循环变换器解码器，这些核心编码器和解码器帮助实现循环层次特征传播和amodal语义固定。我们在广泛的实验中证明了amodal optical flow的可行性，并展示了其对下游任务 such as panoptic tracking 的用于。我们将数据集、代码和训练模型公开发布在http://amodal-flow.cs.uni-freiburg.de。
</details></li>
</ul>
<hr>
<h2 id="Enabling-High-Level-Machine-Reasoning-with-Cognitive-Neuro-Symbolic-Systems"><a href="#Enabling-High-Level-Machine-Reasoning-with-Cognitive-Neuro-Symbolic-Systems" class="headerlink" title="Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems"></a>Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07759">http://arxiv.org/abs/2311.07759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Oltramari</li>
<li>for: 该论文旨在帮助AI系统具备高级别理解能力，以便在不同的应用场景中展现出更加稳定和强大的表现。</li>
<li>methods: 该论文提出了一种将认知架构与外部神经符号学Component integrate的方法，以便帮助AI系统具备更高级别的理解能力。</li>
<li>results: 该论文提出的方法可以帮助AI系统在不同的应用场景中展现出更加稳定和强大的表现，并且可以解决一些现有的AI系统无法解决的问题，如自动驾驶汽车在未经训练的情况下的表现下降。<details>
<summary>Abstract</summary>
High-level reasoning can be defined as the capability to generalize over knowledge acquired via experience, and to exhibit robust behavior in novel situations. Such form of reasoning is a basic skill in humans, who seamlessly use it in a broad spectrum of tasks, from language communication to decision making in complex situations. When it manifests itself in understanding and manipulating the everyday world of objects and their interactions, we talk about common sense or commonsense reasoning. State-of-the-art AI systems don't possess such capability: for instance, Large Language Models have recently become popular by demonstrating remarkable fluency in conversing with humans, but they still make trivial mistakes when probed for commonsense competence; on a different level, performance degradation outside training data prevents self-driving vehicles to safely adapt to unseen scenarios, a serious and unsolved problem that limits the adoption of such technology. In this paper we propose to enable high-level reasoning in AI systems by integrating cognitive architectures with external neuro-symbolic components. We illustrate a hybrid framework centered on ACT-R and we discuss the role of generative models in recent and future applications.
</details>
<details>
<summary>摘要</summary>
高级逻辑可以定义为通过经验获得的知识总结和在新情况下展现稳定行为的能力。这种能力是人类的基本技能，在各种任务中都能够无顾余力地使用，从语言交流到复杂情况下的决策。当它在日常物品和 их交互中表现出来时，我们就称之为常识或通用逻辑。现代AI系统没有这种能力，例如大语言模型在最近几年内吸引了广泛关注，但它们在检测常识能力时仍然会出现轻微的错误。另一方面，自驾车器在未经训练的情况下的性能下降，是一个严重而尚未解决的问题，这限制了自驾车技术的应用。在这篇论文中，我们提议通过结合认知架构和外部神经符号组件来启用高级逻辑在AI系统中。我们介绍了一种混合框架， centered on ACT-R，并讨论了在最近和未来应用中的生成模型的作用。
</details></li>
</ul>
<hr>
<h2 id="SynthEnsemble-A-Fusion-of-CNN-Vision-Transformer-and-Hybrid-Models-for-Multi-Label-Chest-X-Ray-Classification"><a href="#SynthEnsemble-A-Fusion-of-CNN-Vision-Transformer-and-Hybrid-Models-for-Multi-Label-Chest-X-Ray-Classification" class="headerlink" title="SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification"></a>SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07750">http://arxiv.org/abs/2311.07750</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. M. Nabil Ashraf, Md. Adyelullahil Mamun, Hasnat Md. Abdullah, Md. Golam Rabiul Alam</li>
<li>for: 这个研究旨在使用深度学习技术来自动诊断胸部X射像中的肺病变化，以提高早期检测和有效治疗的可能性。</li>
<li>methods: 研究使用了多种预训练的对应式神经网络（CNN）、转换器（Transformer）和混合模型（CNN+Transformer），以及传统模型。最佳个体模型为CoAtNet，其在接收操作特征曲线图（AUROC）中获得84.2%的表现。</li>
<li>results: 通过将所有训练模型的预测结果使用一个加权平均ensemble，使用了进化的算法决定每个模型的重量，可以进一步提高AUROC至85.4%，超越了现有的州际前方法。研究显示了深度学习技术，特别是集成深度学习，对于自动诊断胸部X射像中的肺病变化有很高的准确性。<details>
<summary>Abstract</summary>
Chest X-rays are widely used to diagnose thoracic diseases, but the lack of detailed information about these abnormalities makes it challenging to develop accurate automated diagnosis systems, which is crucial for early detection and effective treatment. To address this challenge, we employed deep learning techniques to identify patterns in chest X-rays that correspond to different diseases. We conducted experiments on the "ChestX-ray14" dataset using various pre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical models. The best individual model was the CoAtNet, which achieved an area under the receiver operating characteristic curve (AUROC) of 84.2%. By combining the predictions of all trained models using a weighted average ensemble where the weight of each model was determined using differential evolution, we further improved the AUROC to 85.4%, outperforming other state-of-the-art methods in this field. Our findings demonstrate the potential of deep learning techniques, particularly ensemble deep learning, for improving the accuracy of automatic diagnosis of thoracic diseases from chest X-rays.
</details>
<details>
<summary>摘要</summary>
胸部X光图是广泛用于诊断胸部疾病的工具，但由于疾病异常的细节信息缺乏，因此建立准确的自动诊断系统是非常重要的，以便早期发现和有效治疗。为解决这个挑战，我们利用深度学习技术来识别胸部X光图中的不同疾病特征。我们在“ChestX-ray14”数据集上进行了多种预训练 convolutional neural network（CNN）、transformer和混合（CNN+Transformer）模型的实验。最佳的个体模型是CoAtNet，它在受者操作特征曲线（AUROC）上达到了84.2%。通过将所有训练模型的预测结果结合使用一个权重平均 ensemble，我们进一步提高了AUROC到85.4%，超过了当前领域其他状态的方法。我们的发现表明深度学习技术，特别是ensemble深度学习，对诊断胸部疾病从胸部X光图自动诊断的精度有着潜在的潜力。
</details></li>
</ul>
<hr>
<h2 id="Simplifying-Complex-Observation-Models-in-Continuous-POMDP-Planning-with-Probabilistic-Guarantees-and-Practice"><a href="#Simplifying-Complex-Observation-Models-in-Continuous-POMDP-Planning-with-Probabilistic-Guarantees-and-Practice" class="headerlink" title="Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice"></a>Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07745">http://arxiv.org/abs/2311.07745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Idan Lev-Yehudi, Moran Barenboim, Vadim Indelman</li>
<li>for: 这个论文是为了解决部分可观测 Markov决策过程（POMDP）中的高维度连续观测问题，如摄像头图像，而需要大量的计算力和存储空间。</li>
<li>methods: 这篇论文使用机器学习的概率模型来表示观测模型，但这些模型在线上部署时需要过多的计算资源。论文提出了使用简化的观测模型进行规划，并保持了对解决方案质量的正式保证。</li>
<li>results: 论文的主要贡献是一种新的概率 bound，基于统计总体变化距离简化模型。这个 bound 可以确保 POMDP 值与原始模型之间的相似性，并且可以在不需要访问昂贵的模型的情况下实现。论文还提出了在线和离线部分的计算，以及不需要访问模型的情况下实现正式保证的新结果。最后，论文通过实验示例了如何将 bound 集成到现有的连续在线 POMDP 解决器中。<details>
<summary>Abstract</summary>
Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to access the costly model at all during planning, which is also a novel result. Finally, we demonstrate in simulation how to integrate the bound into the routine of an existing continuous online POMDP solver.
</details>
<details>
<summary>摘要</summary>
解决具有高维度和连续观测的部分可观测Markov决策过程（POMDP）是许多实际 роботех和规划问题的必需。现有研究提出了机器学习概率模型作为观测模型，但其计算成本过高，不适合在线部署。我们考虑使用简化的观测模型进行规划，保留正式的质量保证。我们的主要贡献是一种新的 probabilistic bound，基于统计总体变化距离简化模型。我们证明这个 bound 约束 POMDP 值与原始模型之间的关系，通过泛化 particle-belief MDP 集中bounds。我们的计算可以分为线上和线下两部分，并不需要在规划过程中访问昂贵的模型，这也是一个新的结果。最后，我们在 simulated 环境中示例了将 bound 集成到现有的连续在线 POMDP 解决器中。
</details></li>
</ul>
<hr>
<h2 id="Generalization-Analogies-GENIES-A-Testbed-for-Generalizing-AI-Oversight-to-Hard-To-Measure-Domains"><a href="#Generalization-Analogies-GENIES-A-Testbed-for-Generalizing-AI-Oversight-to-Hard-To-Measure-Domains" class="headerlink" title="Generalization Analogies (GENIES): A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains"></a>Generalization Analogies (GENIES): A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07723">http://arxiv.org/abs/2311.07723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joshuaclymer/genies">https://github.com/joshuaclymer/genies</a></li>
<li>paper_authors: Joshua Clymer, Garrett Baker, Rohan Subramani, Sam Wang</li>
<li>for: 本研究旨在控制LLMs的推荐模型在不可靠的情况下的泛化。</li>
<li>methods: 作者通过创造8种分类的69个分布转移来研究推荐模型的泛化。</li>
<li>results: 研究发现，推荐模型默认情况下不会评估” instruciton-following”，而是倾向于仿佛网络文本的人物。 standard fine-tuning方法常常无法分辨 instruciton-following 和杂合行为。<details>
<summary>Abstract</summary>
As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable. To better understand how reward models generalize, we craft 69 distribution shifts spanning 8 categories. We find that reward models do not learn to evaluate `instruction-following' by default and instead favor personas that resemble internet text. Techniques for interpreting reward models' internal representations achieve better generalization than standard fine-tuning, but still frequently fail to distinguish instruction-following from conflated behaviors. We consolidate the 15 most challenging distribution shifts into the GENaralization analogIES (GENIES) benchmark, which we hope will enable progress toward controlling reward model generalization.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)随着AI系统的智能化和其行为的挑战性增加，它们可能会学习游戏人类反馈的漏洞而不是真正努力遵从 instruxions;然而，这种风险可以通过控制LLMs对人类反馈的泛化来减少。为了更好地理解奖励模型的泛化，我们创造了69个分布转换，涵盖8个类别。我们发现奖励模型不会默认地评估` instruxion-following'，而是偏爱网络文本类型的人物。使用解释奖励模型内部表示的技术可以更好地泛化than标准精度调整，但并不frequently fails to distinguish instruction-following from conflated behaviors。我们将15个最复杂的分布转换集成为GENeralization analogIES（GENIES）标准，希望这将促进奖励模型泛化控制的进步。
</details></li>
</ul>
<hr>
<h2 id="PolyIE-A-Dataset-of-Information-Extraction-from-Polymer-Material-Scientific-Literature"><a href="#PolyIE-A-Dataset-of-Information-Extraction-from-Polymer-Material-Scientific-Literature" class="headerlink" title="PolyIE: A Dataset of Information Extraction from Polymer Material Scientific Literature"></a>PolyIE: A Dataset of Information Extraction from Polymer Material Scientific Literature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07715">http://arxiv.org/abs/2311.07715</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jerry3027/polyie">https://github.com/jerry3027/polyie</a></li>
<li>paper_authors: Jerry Junyang Cheung, Yuchen Zhuang, Yinghao Li, Pranav Shetty, Wantian Zhao, Sanjeev Grampurohit, Rampi Ramprasad, Chao Zhang</li>
<li>for: 本研究旨在提供一个基于科学文献的 polymer 材料自动提取信息（SciIE） dataset，以便进一步推动这一领域的研究。</li>
<li>methods: 该dataset 基于 146 篇全文 polymer 学术论文，并由域专家 manually annotate 不同类型的命名实体（如材料、性能、值、条件）以及它们之间的 N-ary 关系。</li>
<li>results: 研究人员使用现状的名实体抽取和关系抽取模型对 POLYIE 进行评估，并分析这些模型在不同领域的优劣。<details>
<summary>Abstract</summary>
Scientific information extraction (SciIE), which aims to automatically extract information from scientific literature, is becoming more important than ever. However, there are no existing SciIE datasets for polymer materials, which is an important class of materials used ubiquitously in our daily lives. To bridge this gap, we introduce POLYIE, a new SciIE dataset for polymer materials. POLYIE is curated from 146 full-length polymer scholarly articles, which are annotated with different named entities (i.e., materials, properties, values, conditions) as well as their N-ary relations by domain experts. POLYIE presents several unique challenges due to diverse lexical formats of entities, ambiguity between entities, and variable-length relations. We evaluate state-of-the-art named entity extraction and relation extraction models on POLYIE, analyze their strengths and weaknesses, and highlight some difficult cases for these models. To the best of our knowledge, POLYIE is the first SciIE benchmark for polymer materials, and we hope it will lead to more research efforts from the community on this challenging task. Our code and data are available on: https://github.com/jerry3027/PolyIE.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Histopathologic-Cancer-Detection"><a href="#Histopathologic-Cancer-Detection" class="headerlink" title="Histopathologic Cancer Detection"></a>Histopathologic Cancer Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07711">http://arxiv.org/abs/2311.07711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lbasyal/Histopathologic-Cancer-Detection-">https://github.com/lbasyal/Histopathologic-Cancer-Detection-</a></li>
<li>paper_authors: Varan Singh Rohila, Neeraj Lalwani, Lochan Basyal</li>
<li>for: 预测肿瘤细胞的抑肿效果，以提高病人健康安全。</li>
<li>methods: 使用多层感知网络和卷积神经网络模型，对HE染色压榨组织图像进行分类预测。</li>
<li>results: 基本型卷积神经网络模型比基本型多层感知网络模型表现更好，而ResNet50模型还能超越当前最佳模型。此外，研究还提出了将转移学习和分割技术应用于特定特征的理解。<details>
<summary>Abstract</summary>
Early diagnosis of the cancer cells is necessary for making an effective treatment plan and for the health and safety of a patient. Nowadays, doctors usually use a histological grade that pathologists determine by performing a semi-quantitative analysis of the histopathological and cytological features of hematoxylin-eosin (HE) stained histopathological images. This research contributes a potential classification model for cancer prognosis to efficiently utilize the valuable information underlying the HE-stained histopathological images. This work uses the PatchCamelyon benchmark datasets and trains them in a multi-layer perceptron and convolution model to observe the model's performance in terms of precision, Recall, F1 Score, Accuracy, and AUC Score. The evaluation result shows that the baseline convolution model outperforms the baseline MLP model. Also, this paper introduced ResNet50 and InceptionNet models with data augmentation, where ResNet50 is able to beat the state-of-the-art model. Furthermore, the majority vote and concatenation ensemble were evaluated and provided the future direction of using transfer learning and segmentation to understand the specific features.
</details>
<details>
<summary>摘要</summary>
早期诊断癌细胞是必要的 для制定有效的治疗计划和患者的健康安全。现在医生通常使用 histological grade，由病理学家根据 Hematoxylin-eosin（HE）染色的 histopathological 和细胞学特征进行半量化分析。这项研究提供了一种潜在的癌诊断分类模型，以有效利用HE染色 histopathological 图像下的有价值信息。本研究使用 PatchCamelyon  benchmark 数据集，并使用多层感知网络和卷积模型训练，以评估模型在精度、回卷、F1 分数、准确率和 AUC 分数上的表现。结果显示，基eline 卷积模型在精度、回卷和 F1 分数上超过了基eline MLP 模型。此外，本文还介绍了 ResNet50 和 InceptionNet 模型，并使用数据扩充来评估其性能。最后，文章还评估了 majority vote 和 concatenation ensemble，并提供了将来使用传输学习和分割来理解特定特征的未来方向。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Solving-Stochastic-Vehicle-Routing-Problem"><a href="#Reinforcement-Learning-for-Solving-Stochastic-Vehicle-Routing-Problem" class="headerlink" title="Reinforcement Learning for Solving Stochastic Vehicle Routing Problem"></a>Reinforcement Learning for Solving Stochastic Vehicle Routing Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07708">http://arxiv.org/abs/2311.07708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zangir Iklassov, Ikboljon Sobirov, Ruben Solozabal, Martin Takac</li>
<li>for: 解决RL和ML技术在Stochastic Vehicle Routing Problem（SVRP）中的不约性问题，提出一种新的综合性框架。</li>
<li>methods: 提出一种简单 yet effective的RL代理人，采用了特制的训练方法，能够全面地处理SVRP中的随机性源。</li>
<li>results: 通过比较分析，提出的模型在多个SVRP设定下表现出优于一种广泛应用的现有metaheuristic，实现了3.43%的交通成本减少。此外，模型在不同的SVRP环境下展现了鲁棒性和学习优化路径策略的能力。<details>
<summary>Abstract</summary>
This study addresses a gap in the utilization of Reinforcement Learning (RL) and Machine Learning (ML) techniques in solving the Stochastic Vehicle Routing Problem (SVRP) that involves the challenging task of optimizing vehicle routes under uncertain conditions. We propose a novel end-to-end framework that comprehensively addresses the key sources of stochasticity in SVRP and utilizes an RL agent with a simple yet effective architecture and a tailored training method. Through comparative analysis, our proposed model demonstrates superior performance compared to a widely adopted state-of-the-art metaheuristic, achieving a significant 3.43% reduction in travel costs. Furthermore, the model exhibits robustness across diverse SVRP settings, highlighting its adaptability and ability to learn optimal routing strategies in varying environments. The publicly available implementation of our framework serves as a valuable resource for future research endeavors aimed at advancing RL-based solutions for SVRP.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这项研究旨在填补RL和ML技术在解决不确定性加大的交通车辆路径问题（SVRP）中的 Utilization gap。我们提出了一种全新的综合解决方案，涵盖SVRP中关键的不确定性来源，并使用一种简单 yet有效的RL Agent，以及适应training方法。通过比较分析，我们的提议模型在SVRP中表现出优于一种广泛应用的状态艺术，实现了3.43%的旅行成本减少。此外，模型在不同的SVRP设定下展现出了稳定性和适应性，这表明其可以在不同环境中学习优化的路径策略。我们公开提供的实现方案作为未来RL基于SVRP的研究进程中的有价值资源。
</details></li>
</ul>
<hr>
<h2 id="Robust-and-Scalable-Hyperdimensional-Computing-With-Brain-Like-Neural-Adaptations"><a href="#Robust-and-Scalable-Hyperdimensional-Computing-With-Brain-Like-Neural-Adaptations" class="headerlink" title="Robust and Scalable Hyperdimensional Computing With Brain-Like Neural Adaptations"></a>Robust and Scalable Hyperdimensional Computing With Brain-Like Neural Adaptations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07705">http://arxiv.org/abs/2311.07705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyao Wang, Mohammad Abdullah Al Faruque</li>
<li>for: 这个研究旨在提高 Edge-based 机器学习（ML）方法的效率，使其能够在物联网（IoT）系统中进行实时分析。</li>
<li>methods: 这个研究使用了 brain-inspired 高dimensional computing（HDC）技术，并提出了一些动态 HDC 学习框架，以便获得更好的效率和精度。</li>
<li>results: 这个研究发现，使用动态 HDC 学习框架可以实现更好的精度和效率，并且可以在 Edge-based 系统中进行实时分析。<details>
<summary>Abstract</summary>
The Internet of Things (IoT) has facilitated many applications utilizing edge-based machine learning (ML) methods to analyze locally collected data. Unfortunately, popular ML algorithms often require intensive computations beyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional computing (HDC) has been introduced to address this issue. However, existing HDCs use static encoders, requiring extremely high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a huge efficiency loss, severely impeding the application of HDCs in IoT systems. We observed that a main cause is that the encoding module of existing HDCs lacks the capability to utilize and adapt to information learned during training. In contrast, neurons in human brains dynamically regenerate all the time and provide more useful functionalities when learning new information. While the goal of HDC is to exploit the high-dimensionality of randomly generated base hypervectors to represent the information as a pattern of neural activity, it remains challenging for existing HDCs to support a similar behavior as brain neural regeneration. In this work, we present dynamic HDC learning frameworks that identify and regenerate undesired dimensions to provide adequate accuracy with significantly lowered dimensionalities, thereby accelerating both the training and inference.
</details>
<details>
<summary>摘要</summary>
互联网智能化（IoT）已经推动了许多应用程序利用边缘基于机器学习（ML）技术来分析本地收集的数据。然而，受欢迎的ML算法经常需要昂费的计算力 beyond 今天的IoT设备。基于大脑启发的超dimensional computing（HDC）已经被引入来解决这个问题。然而，现有的HDC使用静止的编码器，需要极高的维度和百上百的训练迭代来 achieve 可接受的精度。这会导致严重的效率损失，严重阻碍HDC的应用在IoT系统中。我们发现了一个主要的问题是现有的HDC编码器无法利用和适应训练中所学习的信息。相比之下，人脑中的神经元在学习新信息时会 dynamically regenerate ，提供更有用的功能。HDC的目标是利用高维度的随机生成的基本超vector 来表示信息作为神经活动的模式，但是现有的HDC无法支持类似于大脑神经重生的行为。在这个工作中，我们提出了动态HDC学习框架，可以识别和重生无愿的维度，以提供足够的精度，并且可以快速训练和推断。这将可以大幅提高IoT系统中HDC的效率和可扩展性。
</details></li>
</ul>
<hr>
<h2 id="AuthentiGPT-Detecting-Machine-Generated-Text-via-Black-Box-Language-Models-Denoising"><a href="#AuthentiGPT-Detecting-Machine-Generated-Text-via-Black-Box-Language-Models-Denoising" class="headerlink" title="AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising"></a>AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07700">http://arxiv.org/abs/2311.07700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Guo, Shangdi Yu</li>
<li>for: 本研究旨在检测大语言模型（LLM）生成的文本是否为人类写作。</li>
<li>methods: 本研究提出了一种效果很好的分类方法，即AuthentiGPT，它利用黑盒模型对输入文本进行干扰处理，然后进行semantic比较来判断文本是否为人类写作。</li>
<li>results: 研究发现，AuthentiGPT在特定领域的数据集上达到了0.918的AUROC分数，比其他商业算法高得多，表明它可以有效地检测LLM生成的文本是否为人类写作。<details>
<summary>Abstract</summary>
Large language models (LLMs) have opened up enormous opportunities while simultaneously posing ethical dilemmas. One of the major concerns is their ability to create text that closely mimics human writing, which can lead to potential misuse, such as academic misconduct, disinformation, and fraud. To address this problem, we present AuthentiGPT, an efficient classifier that distinguishes between machine-generated and human-written texts. Under the assumption that human-written text resides outside the distribution of machine-generated text, AuthentiGPT leverages a black-box LLM to denoise input text with artificially added noise, and then semantically compares the denoised text with the original to determine if the content is machine-generated. With only one trainable parameter, AuthentiGPT eliminates the need for a large training dataset, watermarking the LLM's output, or computing the log-likelihood. Importantly, the detection capability of AuthentiGPT can be easily adapted to any generative language model. With a 0.918 AUROC score on a domain-specific dataset, AuthentiGPT demonstrates its effectiveness over other commercial algorithms, highlighting its potential for detecting machine-generated text in academic settings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-The-Truthfulness-of-‘Surprisingly-Likely’-Responses-of-Large-Language-Models"><a href="#On-The-Truthfulness-of-‘Surprisingly-Likely’-Responses-of-Large-Language-Models" class="headerlink" title="On The Truthfulness of ‘Surprisingly Likely’ Responses of Large Language Models"></a>On The Truthfulness of ‘Surprisingly Likely’ Responses of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07692">http://arxiv.org/abs/2311.07692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naman Goel</li>
<li>for: The paper is written to investigate the relevance of the surprisingly likely criterion for responses of large language models (LLMs).</li>
<li>methods: The paper uses a game-theoretic multi-agent setting to reward rational agents for maximizing the expected information gain with their answers, based on their probabilistic beliefs.</li>
<li>results: The paper shows that the method improves the accuracy of LLMs’ responses significantly, with up to 24 percentage points aggregate improvement on the TruthfulQA benchmark and up to 70 percentage points improvement on individual categories of questions.Here are the three key information points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了研究大语言模型（LLMs）的回答中的可预料性准则的有效性。</li>
<li>methods: 这篇论文使用了游戏理论多代人设定，通过奖励合理代理人为 maximize 其回答中的预期信息增加来提高 LLMS 的回答准确性。</li>
<li>results: 这篇论文显示，该方法可以significantly提高 LLMS 的回答准确性，最多可以提高 TruthfulQA benchmark 的总成绩24%，并在具体的问题类型上达到70%的提高。<details>
<summary>Abstract</summary>
The surprisingly likely criterion in the seminal work of Prelec (the Bayesian Truth Serum) guarantees truthfulness in a game-theoretic multi-agent setting, by rewarding rational agents to maximise the expected information gain with their answers w.r.t. their probabilistic beliefs. We investigate the relevance of a similar criterion for responses of LLMs. We hypothesize that if the surprisingly likely criterion works in LLMs, under certain conditions, the responses that maximize the reward under this criterion should be more accurate than the responses that only maximize the posterior probability. Using benchmarks including the TruthfulQA benchmark and using openly available LLMs: GPT-2 and LLaMA-2, we show that the method indeed improves the accuracy significantly (for example, upto 24 percentage points aggregate improvement on TruthfulQA and upto 70 percentage points improvement on individual categories of questions).
</details>
<details>
<summary>摘要</summary>
“Prelec的著名作品（ bayesian truth serum）中的预期增加价值标准可以 garantuee 多智能体场景中的真实性，通过对回答的 rational agents 的偏好分布进行奖励。我们研究 LLMS 的回答是否可以通过类似的标准进行改善。我们预设，如果这个标准适用于 LLMS，在某些情况下，对回答的奖励最大化的方法可以提高精度。我们使用 truthfulQA benchmark 和公开可用的 GPT-2 和 LLaMA-2 LLMs，证明了这种方法可以提高精度，例如，在 TruthfulQA 中总共提高了 24% 的精度，并在单一问题类别中提高了 70% 的精度。”
</details></li>
</ul>
<hr>
<h2 id="Language-Model-In-The-Loop-Data-Optimal-Approach-to-Learn-To-Recommend-Actions-in-Text-Games"><a href="#Language-Model-In-The-Loop-Data-Optimal-Approach-to-Learn-To-Recommend-Actions-in-Text-Games" class="headerlink" title="Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games"></a>Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07687">http://arxiv.org/abs/2311.07687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arjun Vaithilingam Sudhakar, Prasanna Parthasarathi, Janarthanan Rajendran, Sarath Chandar</li>
<li>for: 提高文本游戏中的表现</li>
<li>methods: 使用更新LLM来更好地推荐动作，从而减少人工标注游戏记录的依赖</li>
<li>results: 通过在游戏中更新LLM，可以减少人工标注游戏记录的依赖，但是在不同游戏之间的传输性不很好Here’s the simplified Chinese text:</li>
<li>for: 提高文本游戏中的表现</li>
<li>methods: 使用更新LLM来更好地推荐动作，从而减少人工标注游戏记录的依赖</li>
<li>results: 通过在游戏中更新LLM，可以减少人工标注游戏记录的依赖，但是在不同游戏之间的传输性不很好<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated superior performance in language understanding benchmarks. CALM, a popular approach, leverages linguistic priors of LLMs -- GPT-2 -- for action candidate recommendations to improve the performance in text games in Jericho without environment-provided actions. However, CALM adapts GPT-2 with annotated human gameplays and keeps the LLM fixed during the learning of the text based games. In this work, we explore and evaluate updating LLM used for candidate recommendation during the learning of the text based game as well to mitigate the reliance on the human annotated gameplays, which are costly to acquire. We observe that by updating the LLM during learning using carefully selected in-game transitions, we can reduce the dependency on using human annotated game plays for fine-tuning the LLMs. We conducted further analysis to study the transferability of the updated LLMs and observed that transferring in-game trained models to other games did not result in a consistent transfer.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fuse-to-Forget-Bias-Reduction-and-Selective-Memorization-through-Model-Fusion"><a href="#Fuse-to-Forget-Bias-Reduction-and-Selective-Memorization-through-Model-Fusion" class="headerlink" title="Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"></a>Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07682">http://arxiv.org/abs/2311.07682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/keremzaman/fusetoforget">https://github.com/keremzaman/fusetoforget</a></li>
<li>paper_authors: Kerem Zaman, Leshem Choshen, Shashank Srivastava</li>
<li>for: 本研究旨在探讨模型融合是否会干扰和减少不需要的知识。</li>
<li>methods: 本研究使用了文本分类和生成任务，对多个模型的权重进行融合，并分析了模型融合对学习快照、社会偏见和记忆能力的影响。</li>
<li>results: 研究发现，在模型融合中，共享知识通常会增强，而不共享知识通常会消失或被忘记。这种现象可能使模型融合成为一种减少语言模型的隐私问题的工具。<details>
<summary>Abstract</summary>
Model fusion research aims to aggregate the knowledge of multiple models to enhance performance by combining their weights. In this work, we study the inverse, investigating whether and how can model fusion interfere and reduce unwanted knowledge. We delve into the effects of model fusion on the evolution of learned shortcuts, social biases, and memorization capabilities in fine-tuned language models. Through several experiments covering text classification and generation tasks, our analysis highlights that shared knowledge among models is usually enhanced during model fusion, while unshared knowledge is usually lost or forgotten. Based on this observation, we demonstrate the potential of model fusion as a debiasing tool and showcase its efficacy in addressing privacy concerns associated with language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SPHINX-The-Joint-Mixing-of-Weights-Tasks-and-Visual-Embeddings-for-Multi-modal-Large-Language-Models"><a href="#SPHINX-The-Joint-Mixing-of-Weights-Tasks-and-Visual-Embeddings-for-Multi-modal-Large-Language-Models" class="headerlink" title="SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models"></a>SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07575">http://arxiv.org/abs/2311.07575</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alpha-vllm/llama2-accessory">https://github.com/alpha-vllm/llama2-accessory</a></li>
<li>paper_authors: Ziyi Lin, Chris Liu, Renrui Zhang, Peng Gao, Longtian Qiu, Han Xiao, Han Qiu, Chen Lin, Wenqi Shao, Keqin Chen, Jiaming Han, Siyuan Huang, Yichi Zhang, Xuming He, Hongsheng Li, Yu Qiao</li>
<li>for: 这个论文主要目标是提出一种多模式大语言模型（MLLM），以实现多Modal的语言理解和图像理解。</li>
<li>methods: 该论文使用了一种权重混合策略，将两个不同领域的模型权重混合在一起，以提高图像理解和语言理解的能力。此外，论文还提出了一种多任务混合策略，将多种视觉任务进行联合调整，以提高模型的多模式能力。</li>
<li>results: 根据论文的描述，SPHINX模型在多种应用场景中表现出色，包括图像理解、视觉问答、区域理解、图像描述、人体pose估计等。此外，论文还提出了一种高分辨率图像分解策略，可以更好地捕捉高分辨率图像中的细节。<details>
<summary>Abstract</summary>
We present SPHINX, a versatile multi-modal large language model (MLLM) with a joint mixing of model weights, tuning tasks, and visual embeddings. First, for stronger vision-language alignment, we unfreeze the large language model (LLM) during pre-training, and introduce a weight mix strategy between LLMs trained by real-world and synthetic data. By directly integrating the weights from two domains, the mixed LLM can efficiently incorporate diverse semantics with favorable robustness. Then, to enable multi-purpose capabilities, we mix a variety of tasks for joint visual instruction tuning, and design task-specific instructions to avoid inter-task conflict. In addition to the basic visual question answering, we include more challenging tasks such as region-level understanding, caption grounding, document layout detection, and human pose estimation, contributing to mutual enhancement over different scenarios. Additionally, we propose to extract comprehensive visual embeddings from various network architectures, pre-training paradigms, and information granularity, providing language models with more robust image representations. Based on our proposed joint mixing, SPHINX exhibits superior multi-modal understanding capabilities on a wide range of applications. On top of this, we further propose an efficient strategy aiming to better capture fine-grained appearances of high-resolution images. With a mixing of different scales and high-resolution sub-images, SPHINX attains exceptional visual parsing and reasoning performance on existing evaluation benchmarks. We hope our work may cast a light on the exploration of joint mixing in future MLLM research. Code is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.
</details>
<details>
<summary>摘要</summary>
我们介绍SPHINX，一种多模态大型自然语言模型（MLLM），具有混合模型权重、调整任务和视觉嵌入的共同混合。首先，为强化视觉语言对应，我们在预训练时解冻大语言模型（LLM），并通过实际数据和 sintetic 数据两种预训练模型的权重混合来实现模型权重的共同混合。这种混合可以快速并高效地将多个 semantic 集成到模型中，并且具有良好的鲁棒性。然后，为实现多用途能力，我们混合了多种任务，并设计了任务特定的 instrucions，以避免任务之间的冲突。此外，我们还提出了EXTRACT comprehensive visual embeddings，从不同的网络架构、预训练方法和信息粒度中提取图像表示，为语言模型提供更加鲁棒的图像表示。基于我们的共同混合方法，SPHINX在多种应用场景中展示出了优秀的多模态理解能力。此外，我们还提出了一种高效的策略，用于更好地捕捉高分辨率图像的细节 appearances。通过混合不同的尺度和高分辨率子图，SPHINX在现有评估标准上实现了出色的视解析和推理性能。我们希望我们的工作可以激发未来 MLLM 研究中的 JOINT 混合方法的探索。代码可以在 <https://github.com/Alpha-VLLM/LLaMA2-Accessory> 上下载。
</details></li>
</ul>
<hr>
<h2 id="GPT-4V-in-Wonderland-Large-Multimodal-Models-for-Zero-Shot-Smartphone-GUI-Navigation"><a href="#GPT-4V-in-Wonderland-Large-Multimodal-Models-for-Zero-Shot-Smartphone-GUI-Navigation" class="headerlink" title="GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation"></a>GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07562">http://arxiv.org/abs/2311.07562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zzxslp/mm-navigator">https://github.com/zzxslp/mm-navigator</a></li>
<li>paper_authors: An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao, Zicheng Liu, Lijuan Wang</li>
<li>for: 这篇论文的目的是提出一种基于GPT-4V的智能手机Graphical User Interface（GUI）导航代理人MM-Navigator，以便它可以与人类用户一样交互，并根据给出的指令决定后续的行动。</li>
<li>methods: 这篇论文使用的方法是使用大量多模态模型（LMMs），具体来说是GPT-4V，以透过其高级屏幕解释、行动理解和精准行动地理位能力来完成零时 GUI 导航任务。</li>
<li>results: 根据人类评估，MM-Navigator在我们收集的iOS屏幕数据集上表现出了91%的准确率，在生成合理的动作描述和执行正确的动作方面。此外，我们还评估了模型在一个Android屏幕导航数据集上的性能，其在零时情况下超越了前一代的 GUI 导航器。<details>
<summary>Abstract</summary>
We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical user interface (GUI) navigation task. MM-Navigator can interact with a smartphone screen as human users, and determine subsequent actions to fulfill given instructions. Our findings demonstrate that large multimodal models (LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its advanced screen interpretation, action reasoning, and precise action localization capabilities. We first benchmark MM-Navigator on our collected iOS screen dataset. According to human assessments, the system exhibited a 91\% accuracy rate in generating reasonable action descriptions and a 75\% accuracy rate in executing the correct actions for single-step instructions on iOS. Additionally, we evaluate the model on a subset of an Android screen navigation dataset, where the model outperforms previous GUI navigators in a zero-shot fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for future research into the GUI navigation task. The project page is at https://github.com/zzxslp/MM-Navigator.
</details>
<details>
<summary>摘要</summary>
我们介绍MM-Navigator，基于GPT-4V的智能手机 Graphical User Interface（GUI）导航代理。MM-Navigator可以与智能手机屏幕交互，并根据给定的 instrucions 确定后续的行动。我们的研究发现，大型多模态模型（LMM），具体来说是GPT-4V，在零容器 GUI 导航方面表现出色，拥有先进的屏幕解释、动作理解和精确动作local化能力。我们首先在我们收集的 iOS 屏幕数据集上对MM-Navigator进行了测试。根据人类评估，系统在生成合理的动作描述上达到了91%的准确率，并在单步 instrucions 上执行正确的动作达到了75%的准确率。此外，我们还对一部分 Android 屏幕导航数据集进行了测试，并证明了前一代 GUI 导航器在零容器情况下的超越。我们的 benchmark 和详细分析旨在为未来关于 GUI 导航任务的研究提供坚实的基础。项目页面可以在 https://github.com/zzxslp/MM-Navigator 上找到。
</details></li>
</ul>
<hr>
<h2 id="An-Extensive-Study-on-Adversarial-Attack-against-Pre-trained-Models-of-Code"><a href="#An-Extensive-Study-on-Adversarial-Attack-against-Pre-trained-Models-of-Code" class="headerlink" title="An Extensive Study on Adversarial Attack against Pre-trained Models of Code"></a>An Extensive Study on Adversarial Attack against Pre-trained Models of Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07553">http://arxiv.org/abs/2311.07553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cgcl-codes/attack_ptmc">https://github.com/cgcl-codes/attack_ptmc</a></li>
<li>paper_authors: Xiaohu Du, Ming Wen, Zichao Wei, Shangwen Wang, Hai Jin</li>
<li>for: 这篇论文是用于测试和评估Transformer-based预训练模型的攻击性评估。</li>
<li>methods: 这篇论文使用了五种现有的攻击方法，并从三个角度进行了系统性的分析：效果、效率和生成的例子质量。</li>
<li>results: 研究结果显示，现有的攻击方法中，identifier substitution within for and if statements 是最有效的，并且可以优化生成的攻击码的自然性。此外，提出了一个新的方法，优化不同类型的陈述式，并使用搜索精灵来生成攻击码，可以优化效率和自然性。<details>
<summary>Abstract</summary>
Transformer-based pre-trained models of code (PTMC) have been widely utilized and have achieved state-of-the-art performance in many mission-critical applications. However, they can be vulnerable to adversarial attacks through identifier substitution or coding style transformation, which can significantly degrade accuracy and may further incur security concerns. Although several approaches have been proposed to generate adversarial examples for PTMC, the effectiveness and efficiency of such approaches, especially on different code intelligence tasks, has not been well understood. To bridge this gap, this study systematically analyzes five state-of-the-art adversarial attack approaches from three perspectives: effectiveness, efficiency, and the quality of generated examples. The results show that none of the five approaches balances all these perspectives. Particularly, approaches with a high attack success rate tend to be time-consuming; the adversarial code they generate often lack naturalness, and vice versa. To address this limitation, we explore the impact of perturbing identifiers under different contexts and find that identifier substitution within for and if statements is the most effective. Based on these findings, we propose a new approach that prioritizes different types of statements for various tasks and further utilizes beam search to generate adversarial examples. Evaluation results show that it outperforms the state-of-the-art ALERT in terms of both effectiveness and efficiency while preserving the naturalness of the generated adversarial examples.
</details>
<details>
<summary>摘要</summary>
启用基于变换器的预训练模型（PTMC）在许多关键应用中已经广泛应用，但它们可能受到 identifier 替换或编程风格变化的攻击，这可能会导致准确性下降和安全问题。虽然有几种方法用于生成针对 PTMC 的攻击示例，但这些方法在不同的代码智能任务中的效果和效率尚未得到了充分的了解。为了填补这一漏洞，本研究系统atically 分析了五种当前领先的攻击方法，从三个角度来评估它们的效果、效率和生成的示例质量。结果显示，其中没有一种方法能够均衡这三个方面。特别是，拥有高攻击成功率的方法通常需要较长的时间，生成的针对式代码通常缺乏自然性，并且vice versa。为了解决这一限制，我们调查了在不同上下文中 Identifier 替换的影响，发现在 for 和 if 语句中进行 Identifier 替换是最有效的。基于这些发现，我们提出了一种新的方法，它根据不同的任务类型将不同类型的语句优先级化，并使用搜索桶来生成攻击示例。测试结果表明，它在效果和效率两个方面超越了现有的 ALERT，同时保持了针对式代码的自然性。
</details></li>
</ul>
<hr>
<h2 id="GPT-4V-ision-as-A-Social-Media-Analysis-Engine"><a href="#GPT-4V-ision-as-A-Social-Media-Analysis-Engine" class="headerlink" title="GPT-4V(ision) as A Social Media Analysis Engine"></a>GPT-4V(ision) as A Social Media Analysis Engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07547">http://arxiv.org/abs/2311.07547</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vista-h/gpt-4v_social_media">https://github.com/vista-h/gpt-4v_social_media</a></li>
<li>paper_authors: Hanjia Lyu, Jinfa Huang, Daoan Zhang, Yongsheng Yu, Xinyi Mou, Jinsheng Pan, Zhengyuan Yang, Zhongyu Wei, Jiebo Luo</li>
<li>for: 这个论文旨在探讨大型多Modal模型（LMMs）在社交媒体内容分析方面的潜力。</li>
<li>methods: 这个论文使用GPT-4V模型进行社交媒体内容分析，选择了五个表型任务，包括情感分析、仇恨言语检测、假新闻识别、人口统计学和政治立场检测，以评估GPT-4V的能力。</li>
<li>results: GPT-4V在这些任务中表现出色，表现出联合图片文字对 pair 的理解能力、文化和情境意识以及广泛的通用常识知识。 despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges, such as struggling with multilingual social multimedia comprehension and generating erroneous information in the context of evolving celebrity and politician knowledge.<details>
<summary>Abstract</summary>
Recent research has offered insights into the extraordinary capabilities of Large Multimodal Models (LMMs) in various general vision and language tasks. There is growing interest in how LMMs perform in more specialized domains. Social media content, inherently multimodal, blends text, images, videos, and sometimes audio. Understanding social multimedia content remains a challenging problem for contemporary machine learning frameworks. In this paper, we explore GPT-4V(ision)'s capabilities for social multimedia analysis. We select five representative tasks, including sentiment analysis, hate speech detection, fake news identification, demographic inference, and political ideology detection, to evaluate GPT-4V. Our investigation begins with a preliminary quantitative analysis for each task using existing benchmark datasets, followed by a careful review of the results and a selection of qualitative samples that illustrate GPT-4V's potential in understanding multimodal social media content. GPT-4V demonstrates remarkable efficacy in these tasks, showcasing strengths such as joint understanding of image-text pairs, contextual and cultural awareness, and extensive commonsense knowledge. Despite the overall impressive capacity of GPT-4V in the social media domain, there remain notable challenges. GPT-4V struggles with tasks involving multilingual social multimedia comprehension and has difficulties in generalizing to the latest trends in social media. Additionally, it exhibits a tendency to generate erroneous information in the context of evolving celebrity and politician knowledge, reflecting the known hallucination problem. The insights gleaned from our findings underscore a promising future for LMMs in enhancing our comprehension of social media content and its users through the analysis of multimodal information.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近期研究提供了关于大型多模态模型（LMM）在多个通用视觉语言任务中的新的发现。在这些任务中，LMM表现出了惊人的能力。我们在这篇论文中探索GPT-4V(ision)在社交媒体分析中的能力。我们选择了五个表示任务，包括情感分析、谩骂检测、假新闻标识、人口统计推断和政治立场检测，以评估GPT-4V。我们的调查开始于现有数据集的初步量化分析，然后是一个精心审查结果，并选择一些ILLUSTRATE GPT-4V在多Modal社交媒体内容中的潜力。GPT-4V在这些任务中表现出了惊人的能力，包括对图文对的同时理解、上下文和文化意识、以及广泛的通情知识。尽管GPT-4V在社交媒体领域中的总体表现很出色，但还有一些突出的挑战。GPT-4V在多语言社交媒体理解任务中困难，以及在最新的社交媒体趋势上generalization。此外，它还表现出了在 evolving celebrity和政治人物知识上的错误信息生成问题，这是已知的幻觉问题。我们的发现可以推出，LMM在社交媒体内容和用户理解方面具有优秀的未来。
</details></li>
</ul>
<hr>
<h2 id="A-Benchmark-to-Understand-the-Role-of-Knowledge-Graphs-on-Large-Language-Model’s-Accuracy-for-Question-Answering-on-Enterprise-SQL-Databases"><a href="#A-Benchmark-to-Understand-the-Role-of-Knowledge-Graphs-on-Large-Language-Model’s-Accuracy-for-Question-Answering-on-Enterprise-SQL-Databases" class="headerlink" title="A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases"></a>A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07509">http://arxiv.org/abs/2311.07509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Sequeda, Dean Allemang, Bryon Jacob</li>
<li>for: This paper aims to evaluate the accuracy of large language models (LLMs) in answering enterprise questions on SQL databases, and to explore the role of knowledge graphs (KGs) in improving accuracy.</li>
<li>methods: The paper introduces a benchmark consisting of an enterprise SQL schema, a range of enterprise queries, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. The authors use GPT-4 with zero-shot prompts directly on SQL databases and evaluate its accuracy.</li>
<li>results: The authors find that question answering using GPT-4 achieves an accuracy of 16%, and that this accuracy increases to 54% when questions are posed over a knowledge graph representation of the enterprise SQL database. The results suggest that investing in knowledge graphs can provide higher accuracy for LLM-powered question answering systems.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在评估大语言模型（LLM）在企业问题上的答案精度，以及探讨知识图（KG）在提高精度方面的作用。</li>
<li>methods: 论文提出了一个企业SQL schema，一系列企业查询，以及一个含有 ontology 和映射的contextual层，用于定义知识图。作者使用 GPT-4  directly on SQL databases 进行零shot prompt，并评估其精度。</li>
<li>results: 作者发现，使用 GPT-4  answering enterprise questions 的精度为 16%，并且当问题提交到知识图表示的企业SQL数据库时，精度提高到 54%。结果表明，投入知识图可以提高 LLM 投入问题 answering 系统的精度。<details>
<summary>Abstract</summary>
Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.
</details>
<details>
<summary>摘要</summary>
企业应用大语言模型（LLM）具有问答系统的潜在应用前景，但是企业问题库中LLM的精度问答能力还未得到了足够的评估。此外，知识图（KG）在增强LLM问答系统的精度方面的潜力还不够了解。本研究旨在评估LLM问答系统在企业问题库中的精度，同时探讨知识图在提高精度方面的作用。为此，我们提出了一个标准 benchmark，包括一个企业 SQL 架构，一系列企业查询，以及一个contextual层，包括一个 ontology 和映射，定义了一个知识图。我们的主要发现是，使用 GPT-4，直接在 SQL 数据库上提问，可以达到 16% 的精度。此外，当问题提交到知识图表示的企业 SQL 数据库时，精度提高至 54%。因此，投资知识图可以提高 LLMPowered 问答系统的精度。
</details></li>
</ul>
<hr>
<h2 id="EvoFed-Leveraging-Evolutionary-Strategies-for-Communication-Efficient-Federated-Learning"><a href="#EvoFed-Leveraging-Evolutionary-Strategies-for-Communication-Efficient-Federated-Learning" class="headerlink" title="EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning"></a>EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07485">http://arxiv.org/abs/2311.07485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Mahdi Rahimi, Hasnain Irshad Bhatti, Younghyun Park, Humaira Kousar, Jaekyun Moon</li>
<li>for: 这篇论文旨在提出一种基于进化策略（Evolutionary Strategies，ES）的联合 Federated Learning（FL）方法，以解决FL中资料共享和通信成本的问题。</li>
<li>methods: 这篇论文使用了一种名为“对应度基于信息分享”的概念，将各个节点的本地更新后的模型与每个误差噪音模型进行比较，从而将模型更新资讯传递给服务器。服务器将这些适应度值进行统计处理，并将更新后的全域模型分发回节点。</li>
<li>results: 这篇论文的实验结果显示，使用EvoFed方法可以在各种实际应用中实现与FedAvg方法相似的性能，并大幅降低了总通信成本。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data. However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters. This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges. EvoFed employs a concept of 'fitness-based information sharing', deviating significantly from the conventional model-based FL. Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population. Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds. With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters. As the population size is typically much smaller than the number of model parameters, the savings in communication load is large. The server aggregates these fitness values and is able to update the global model. This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model. Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）是一种分布式机器学习 paradigma，允许分散的节点合作进行模型训练，而无需强制每个节点共享数据。然而，其广泛应用受到大量模型参数传输成本的限制。这篇论文提出了 EvoFed，一种新的方法，它将生态演化策略（ES）与 FL 集成以解决这些挑战。EvoFed 采用了一种基于“适应度基于信息共享”的概念，与传统的模型基于 FL 不同。每个节点不需要将实际更新后的模型参数传输，而是将本地更新后的模型与每个噪声扰动模型的距离进行比较。每个节点和服务器都会生成一个完全同步的噪声扰动模型集，使用相同的随机种子。当采用合适的噪声 variance 和种子大小时，噪声扰动模型可以准确反映本地数据更新后的模型，使得传输的适应度值（或fitness值）具有几乎完整的模型参数信息。由于种子大小通常比模型参数的数量小得多，因此通信负担减少很大。服务器将这些适应度值聚合，并将其更新到全局模型。全局适应度向量然后被分发回节点，每个节点都将应用相同的更新，以同步到全局模型。我们的分析表明，EvoFed 可以达到 converges，而且我们的实验结果表明，在增加本地处理负担的情况下，EvoFed 可以在各种实际场景中提供与 FedAvg 相当的性能，同时减少大量通信需求。
</details></li>
</ul>
<hr>
<h2 id="Psychometric-Predictive-Power-of-Large-Language-Models"><a href="#Psychometric-Predictive-Power-of-Large-Language-Models" class="headerlink" title="Psychometric Predictive Power of Large Language Models"></a>Psychometric Predictive Power of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07484">http://arxiv.org/abs/2311.07484</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tatsuki Kuribayashi, Yohei Oseki, Timothy Baldwin</li>
<li>for: 这paper是为了研究语言模型如何模拟人类阅读行为而写的。</li>
<li>methods: 这paper使用了大型语言模型（LLMs），并对其进行了指令调整以提高其提供人类首选回答的能力。</li>
<li>results: 研究发现，尽管指令调整可以使LLMs更加人类化，但是它们在计算心理лингвисти学的预测力方面并不总是比基础LLMs更好。此外，研究还发现，使用特定语言假设的提示方法可以使LLMs更加人类化，但是这些提示方法并不能提高LLMs的预测力。<details>
<summary>Abstract</summary>
Next-word probabilities from language models have been shown to successfully simulate human reading behavior. Building on this, we show that, interestingly, instruction-tuned large language models (LLMs) yield worse psychometric predictive power (PPP) for human reading behavior than base LLMs with equivalent perplexities. In other words, instruction tuning, which helps LLMs provide human-preferred responses, does not always make them human-like from the computational psycholinguistics perspective. In addition, we explore prompting methodologies in simulating human reading behavior with LLMs, showing that prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit better PPP but are still worse than base LLMs. These highlight that recent instruction tuning and prompting do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling.
</details>
<details>
<summary>摘要</summary>
基于语言模型的下一个词概率已经成功地模拟了人类阅读行为。我们发现，有趣的是，对于人类阅读行为的预测力（PPP）而言，特定的指导过滤后的大型语言模型（LLMs）的性能更差于基线模型。这意味着，虽然指导过滤可以使LLMs提供人类首选的回答，但并不总是使其成为人类语言模型的计算预测模型。此外，我们还探讨了使用LLMs simulate human reading behavior的提示方法，发现，表达特定语言假设的提示可以使LLMs表现出更好的PPP，但仍然比基线模型差。这些结果表明，最近的指导过滤和提示方法不能提供更好的估计，与直接从基线模型中获取的概率 measurement相比。
</details></li>
</ul>
<hr>
<h2 id="InCA-Rethinking-In-Car-Conversational-System-Assessment-Leveraging-Large-Language-Models"><a href="#InCA-Rethinking-In-Car-Conversational-System-Assessment-Leveraging-Large-Language-Models" class="headerlink" title="InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models"></a>InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07469">http://arxiv.org/abs/2311.07469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ken E. Friedl, Abbas Goher Khan, Soumya Ranjan Sahoo, Md Rashad Al Hasan Rony, Jana Germies, Christian Süß</li>
<li>for: 这个论文主要目标是提出一套适用于评估汽车内 conversational question answering（ConvQA）系统的关键性能指标（KPI），以及相关的数据集。</li>
<li>methods: 该论文使用了现有的评估指标不足的问题作为出发点，并提出了一种基于 persona 的召回方法来提高模型的多元视角能力。</li>
<li>results: 该论文的实验结果表明，使用该提出的 KPI 和数据集可以准确评估 ConvQA 系统的性能，并且通过使用不同的 persona 来召回模型可以提高模型的多元视角能力。<details>
<summary>Abstract</summary>
The assessment of advanced generative large language models (LLMs) poses a significant challenge, given their heightened complexity in recent developments. Furthermore, evaluating the performance of LLM-based applications in various industries, as indicated by Key Performance Indicators (KPIs), is a complex undertaking. This task necessitates a profound understanding of industry use cases and the anticipated system behavior. Within the context of the automotive industry, existing evaluation metrics prove inadequate for assessing in-car conversational question answering (ConvQA) systems. The unique demands of these systems, where answers may relate to driver or car safety and are confined within the car domain, highlight the limitations of current metrics. To address these challenges, this paper introduces a set of KPIs tailored for evaluating the performance of in-car ConvQA systems, along with datasets specifically designed for these KPIs. A preliminary and comprehensive empirical evaluation substantiates the efficacy of our proposed approach. Furthermore, we investigate the impact of employing varied personas in prompts and found that it enhances the model's capacity to simulate diverse viewpoints in assessments, mirroring how individuals with different backgrounds perceive a topic.
</details>
<details>
<summary>摘要</summary>
evaluating advanced generative large language models (LLMs) presents a significant challenge due to their increased complexity in recent developments. additionally, assessing the performance of LLM-based applications in various industries, as indicated by key performance indicators (KPIs), is a complex task. this task requires a deep understanding of industry use cases and the expected system behavior. within the context of the automotive industry, existing evaluation metrics are inadequate for assessing in-car conversational question answering (ConvQA) systems. the unique demands of these systems, where answers may relate to driver or car safety and are confined within the car domain, highlight the limitations of current metrics. to address these challenges, this paper introduces a set of KPIs tailored for evaluating the performance of in-car ConvQA systems, along with datasets specifically designed for these KPIs. a preliminary and comprehensive empirical evaluation substantiates the efficacy of our proposed approach. furthermore, we investigate the impact of employing varied personas in prompts and found that it enhances the model's capacity to simulate diverse viewpoints in assessments, mirroring how individuals with different backgrounds perceive a topic.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Are-We-Falling-in-a-Middle-Intelligence-Trap-An-Analysis-and-Mitigation-of-the-Reversal-Curse"><a href="#Are-We-Falling-in-a-Middle-Intelligence-Trap-An-Analysis-and-Mitigation-of-the-Reversal-Curse" class="headerlink" title="Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse"></a>Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07468">http://arxiv.org/abs/2311.07468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/trestad/mitigating-reversal-curse">https://github.com/trestad/mitigating-reversal-curse</a></li>
<li>paper_authors: Ang Lv, Kaiyi Zhang, Shufang Xie, Quan Tu, Yuhan Chen, Ji-Rong Wen, Rui Yan</li>
<li>for: 本研究旨在探讨大语言模型（LLM）中的“逆转咒”现象，即训练数据中知识实体的顺序影响模型的理解。</li>
<li>methods: 本研究使用了GLM模型，其中使用了autoregressive blank infilling objective来增强模型的表达能力。</li>
<li>results: 在一个由研究者设计的逆转咒测试任务中，使用BICO训练方法可以提高Llama模型的准确率从原来的0%提高到约70%。<details>
<summary>Abstract</summary>
Recent studies have highlighted a phenomenon in large language models (LLMs) known as "the reversal curse," in which the order of knowledge entities in the training data biases the models' comprehension. For example, if a model is trained on sentences where entity A consistently appears before entity B, it can respond to queries about A by providing B as the answer. However, it may encounter confusion when presented with questions concerning B. We contend that the reversal curse is partially a result of specific model training objectives, particularly evident in the prevalent use of the next-token prediction within most causal language models. For the next-token prediction, models solely focus on a token's preceding context, resulting in a restricted comprehension of the input. In contrast, we illustrate that the GLM, trained using the autoregressive blank infilling objective where tokens to be predicted have access to the entire context, exhibits better resilience against the reversal curse. We propose a novel training method, BIdirectional Casual language modeling Optimization (BICO), designed to mitigate the reversal curse when fine-tuning pretrained causal language models on new data. BICO modifies the causal attention mechanism to function bidirectionally and employs a mask denoising optimization. In the task designed to assess the reversal curse, our approach improves Llama's accuracy from the original 0% to around 70%. We hope that more attention can be focused on exploring and addressing these inherent weaknesses of the current LLMs, in order to achieve a higher level of intelligence.
</details>
<details>
<summary>摘要</summary>
研究发现，大语言模型（LLM）中存在一种现象，被称为“逆转咒语”，即训练数据中知识实体的顺序影响模型的理解。例如，如果一个模型在句子中entity A consistently appears before entity B，它可能会在对A的问题上提供B作为答案。但是，它可能会在对B的问题上遇到困惑。我们认为，逆转咒语 partly due to specific model training objectives, particularly the prevalent use of next-token prediction within most causal language models。这种预测方法会让模型围绕一个token的前置上下文进行预测，从而导致输入的 restriction 的理解。然而，我们展示了使用autoregressive blank infilling objective，其中tokens to be predicted有访问整个上下文的能力，可以减轻逆转咒语的影响。我们提出了一种新的训练方法，名为BIdirectional Casual language modeling Optimization（BICO），用于在新数据上细化已经预测的语言模型。BICO改变了 causal attention mechanism 的方向，并使用 mask denoising optimization。在用于评估逆转咒语的任务中，我们的方法可以提高Llama的准确率，从原来的0%提高到大约70%。我们希望可以更多地关注和解决当前LLMs的内在弱点，以达到更高水平的智能。
</details></li>
</ul>
<hr>
<h2 id="On-Measuring-Faithfulness-of-Natural-Language-Explanations"><a href="#On-Measuring-Faithfulness-of-Natural-Language-Explanations" class="headerlink" title="On Measuring Faithfulness of Natural Language Explanations"></a>On Measuring Faithfulness of Natural Language Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07466">http://arxiv.org/abs/2311.07466</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/heidelberg-nlp/cc-shap">https://github.com/heidelberg-nlp/cc-shap</a></li>
<li>paper_authors: Letitia Parcalabescu, Anette Frank</li>
<li>for: 这 paper 的目的是为了解释 LLM 的预测，并评估现有的 faithfulness 测试是否能够准确评估 LLM 的内部工作方式。</li>
<li>methods: 这 paper 使用了现有的 faithfulness 测试，以及自己提出的 CC-SHAP 测试来评估 LLM 的自 consistency。CC-SHAP 是一种新的、更为细致的自 consistency 测试，可以比较模型的输入贡献与答案预测和生成的解释之间的关系。</li>
<li>results: 据 paper 的结果，现有的 faithfulness 测试并不能准确评估 LLM 的内部工作方式，而是只能评估其输出水平的自 consistency。而 CC-SHAP 测试则能够更好地评估 LLM 的自 consistency，并且可以提供更加 interpretable 的结果。<details>
<summary>Abstract</summary>
Large language models (LLMs) can explain their own predictions, through post-hoc or Chain-of-Thought (CoT) explanations. However the LLM could make up reasonably sounding explanations that are unfaithful to its underlying reasoning. Recent work has designed tests that aim to judge the faithfulness of either post-hoc or CoT explanations. In this paper we argue that existing faithfulness tests are not actually measuring faithfulness in terms of the models' inner workings, but only evaluate their self-consistency on the output level. The aims of our work are two-fold. i) We aim to clarify the status of existing faithfulness tests in terms of model explainability, characterising them as self-consistency tests instead. This assessment we underline by constructing a Comparative Consistency Bank for self-consistency tests that for the first time compares existing tests on a common suite of 11 open-source LLMs and 5 datasets -- including ii) our own proposed self-consistency measure CC-SHAP. CC-SHAP is a new fine-grained measure (not test) of LLM self-consistency that compares a model's input contributions to answer prediction and generated explanation. With CC-SHAP, we aim to take a step further towards measuring faithfulness with a more interpretable and fine-grained method. Code available at \url{https://github.com/Heidelberg-NLP/CC-SHAP}
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>To clarify the status of existing faithfulness tests in terms of model explainability, characterizing them as self-consistency tests.2. To propose a new fine-grained measure of LLM self-consistency, called CC-SHAP, which compares the model’s input contributions to its answer prediction and generated explanation.We construct a Comparative Consistency Bank for self-consistency tests on a common suite of 11 open-source LLMs and 5 datasets. Our proposed CC-SHAP measure provides a more interpretable and fine-grained method for measuring faithfulness. The code for CC-SHAP is available at \url{<a target="_blank" rel="noopener" href="https://github.com/Heidelberg-NLP/CC-SHAP%7D">https://github.com/Heidelberg-NLP/CC-SHAP}</a>.</details></li>
</ol>
<hr>
<h2 id="KnowSafe-Combined-Knowledge-and-Data-Driven-Hazard-Mitigation-in-Artificial-Pancreas-Systems"><a href="#KnowSafe-Combined-Knowledge-and-Data-Driven-Hazard-Mitigation-in-Artificial-Pancreas-Systems" class="headerlink" title="KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems"></a>KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07460">http://arxiv.org/abs/2311.07460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xugui Zhou, Maxfield Kouzel, Chloe Smith, Homa Alemzadeh</li>
<li>for: This paper aims to improve the safety and security of cyber-physical systems (CPS) by proposing a combined knowledge and data-driven approach called KnowSafe to predict and mitigate safety hazards.</li>
<li>methods: The KnowSafe approach integrates domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories, infer potential hazards, and generate optimal corrective actions to keep the system safe.</li>
<li>results: Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.Here is the result in Simplified Chinese text:</li>
<li>for: 本研究旨在提高Cyber-Physical Systems (CPS) 的安全性和安全性。</li>
<li>methods: 该方法 combinesterminology-specific knowledge of safety constraints和context-specific mitigation actionswith机器学习(ML)技术来估算系统轨迹、推测potential hazards, 并生成最佳 corrections to keep the system safe.</li>
<li>results: 实验证明，KnowSafe在两个实际关闭loop testbed for artificial pancreas systems (APS) 和一个实际临床试验数据集 for diabetes treatment 上表现出优于状态艺术的 Results show that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.<details>
<summary>Abstract</summary>
Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.
</details>
<details>
<summary>摘要</summary>
“具有显著进步的偏差探测和执行监控技术，以提高Cyber-Physical System（CPS）的安全性和安全性。然而，较少的注意力被带到危险排除方面。本文提出了一个结合知识和数据驱动的方法，即KnowSafe，用于设计安全引擎，可以预测和排除CPS控制器的安全危险。我们结合专业知识和机器学习（ML）技术，估计系统轨迹在远近未来，推断可能的危险，并生成最佳修正动作，以确保系统安全。实验评估过两个实际关闭loop测试床 для人工肾脏系统（APS）和一个真实世界临床试验数据集 для调节糖尿病治疗，显示了KnowSafe在预测系统状态轨迹和潜在危险方面的精度高于现有技术， false positive rate低，false negative absent。它还能在模拟的APS中维持安全运行，即使有faults或攻击，成功排除危险的成功率为92.8%，至少高于专业规则（50.9%）和数据驱动（52.7%）方法。”
</details></li>
</ul>
<hr>
<h2 id="Think-Before-You-Speak-Cultivating-Communication-Skills-of-Large-Language-Models-via-Inner-Monologue"><a href="#Think-Before-You-Speak-Cultivating-Communication-Skills-of-Large-Language-Models-via-Inner-Monologue" class="headerlink" title="Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue"></a>Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07445">http://arxiv.org/abs/2311.07445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junkai Zhou, Liang Pang, Huawei Shen, Xueqi Cheng</li>
<li>for: 提高大语言模型（LLM）的对话系统能力，使其更像人类对话伙伴。</li>
<li>methods: 添加了五种communication skills到响应生成过程中：主题转换、主动问题、概念引导、同情和概要总结。</li>
<li>results: 在人工和自动评估中，提出的CSIM策略比基eline模型更高效，并且能够更好地评估对话生成能力。<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses. However, LLMs still lack an important ability: communication skills, which makes them more like information seeking tools than anthropomorphic chatbots. To make LLMs more anthropomorphic and proactive during the conversation, we add five communication skills to the response generation process: topic transition, proactively asking questions, concept guidance, empathy, and summarising often. The addition of communication skills increases the interest of users in the conversation and attracts them to chat for longer. To enable LLMs better understand and use communication skills, we design and add the inner monologue to LLMs. The complete process is achieved through prompt engineering and in-context learning. To evaluate communication skills, we construct a benchmark named Cskills for evaluating various communication skills, which can also more comprehensively evaluate the dialogue generation ability of the model. Experimental results show that the proposed CSIM strategy improves the backbone models and outperforms the baselines in both automatic and human evaluations.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的出现进一步提高了开放领域对话系统的能力，可以生成流畅、一致、多样的回答。然而，LLM仍缺乏重要的能力：交流技巧，使其更像信息搜索工具而不是人工智能聊天机器人。为使LLM更人化和主动在对话中，我们在回答生成过程中添加了五种交流技巧：话题转换、主动问题，概念导航、同情和概要。这些技巧的添加使用户对对话更有兴趣，使其更长时间参与对话。为让LLM更好地理解和使用交流技巧，我们设计了内部对话。完整的过程通过提问工程和在线学习实现。为评估交流技巧，我们建立了名为Cskills的基准，用于评估不同的交流技巧，同时也更全面评估对话生成能力。实验结果表明，我们提出的CSIM策略可以提高基础模型的性能，并在自动和人类评估中超过基eline。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Multi-Pivot-Ensembling-with-Massively-Multilingual-Machine-Translation-Models"><a href="#Investigating-Multi-Pivot-Ensembling-with-Massively-Multilingual-Machine-Translation-Models" class="headerlink" title="Investigating Multi-Pivot Ensembling with Massively Multilingual Machine Translation Models"></a>Investigating Multi-Pivot Ensembling with Massively Multilingual Machine Translation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07439">http://arxiv.org/abs/2311.07439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zurichnlp/multipivotnmt">https://github.com/zurichnlp/multipivotnmt</a></li>
<li>paper_authors: Alireza Mohammadshahi, Jannis Vamvas, Rico Sennrich</li>
<li>for: 提高低资源语言翻译方向的翻译质量</li>
<li>methods: 使用多语言折衔策略，提出MaxEns结合策略，偏向最高信任预测结果</li>
<li>results: 在FLORES测试准则上对20种低资源语言方向进行评估，显示MaxEns方法可以提高翻译质量，同时减少翻译中的幻化现象，比irect翻译和平均策略更好<details>
<summary>Abstract</summary>
Massively multilingual machine translation models allow for the translation of a large number of languages with a single model, but have limited performance on low- and very-low-resource translation directions. Pivoting via high-resource languages remains a strong strategy for low-resource directions, and in this paper we revisit ways of pivoting through multiple languages. Previous work has used a simple averaging of probability distributions from multiple paths, but we find that this performs worse than using a single pivot, and exacerbates the hallucination problem because the same hallucinations can be probable across different paths. As an alternative, we propose MaxEns, a combination strategy that is biased towards the most confident predictions, hypothesising that confident predictions are less prone to be hallucinations. We evaluate different strategies on the FLORES benchmark for 20 low-resource language directions, demonstrating that MaxEns improves translation quality for low-resource languages while reducing hallucination in translations, compared to both direct translation and an averaging approach. On average, multi-pivot strategies still lag behind using English as a single pivot language, raising the question of how to identify the best pivoting strategy for a given translation direction.
</details>
<details>
<summary>摘要</summary>
大规模多语言机器翻译模型可以同时翻译多种语言，但在低资源翻译方向上表现有限。通过高资源语言作为中间语言来做转换是一个强大策略，在这篇论文中我们重新检视了多语言转换的方法。先前的工作使用了多个路径的概率分布的平均值，但我们发现这会比使用单个转换更差，并且增加了幻觉问题，因为同一个幻觉可能会在不同的路径上出现。作为替代方案，我们提议MaxEns，一种组合策略，偏好最确定的预测，假设最确定的预测对幻觉更敏感。我们在FLORES测试准则上对20种低资源语言方向进行了不同策略的评估，发现MaxEns可以提高低资源语言翻译质量，同时减少翻译中的幻觉，比直接翻译和平均策略更好。然而，多个转换策略仍然落后于使用英语作为单一中间语言，这提出了如何确定最佳转换策略的问题。
</details></li>
</ul>
<hr>
<h2 id="Hallucination-Augmented-Recitations-for-Language-Models"><a href="#Hallucination-Augmented-Recitations-for-Language-Models" class="headerlink" title="Hallucination Augmented Recitations for Language Models"></a>Hallucination Augmented Recitations for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07424">http://arxiv.org/abs/2311.07424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdullatif Köksal, Renat Aksitov, Chung-Ching Chang</li>
<li>for: The paper aims to improve the attribution of large language models (LLMs) by creating counterfactual datasets using hallucination in LLMs.</li>
<li>methods: The paper proposes a method called Hallucination Augmented Recitations (HAR) to create counterfactual datasets for open book question answering.</li>
<li>results: The paper shows that models finetuned with the counterfactual datasets improve text grounding and open book QA performance, with up to an 8.0% increase in F1 score, compared to using human-annotated factual datasets. The improvements are consistent across various model sizes and datasets.<details>
<summary>Abstract</summary>
Attribution is a key concept in large language models (LLMs) as it enables control over information sources and enhances the factuality of LLMs. While existing approaches utilize open book question answering to improve attribution, factual datasets may reward language models to recall facts that they already know from their pretraining data, not attribution. In contrast, counterfactual open book QA datasets would further improve attribution because the answer could only be grounded in the given text. We propose Hallucination Augmented Recitations (HAR) for creating counterfactual datasets by utilizing hallucination in LLMs to improve attribution. For open book QA as a case study, we demonstrate that models finetuned with our counterfactual datasets improve text grounding, leading to better open book QA performance, with up to an 8.0% increase in F1 score. Our counterfactual dataset leads to significantly better performance than using humanannotated factual datasets, even with 4x smaller datasets and 4x smaller models. We observe that improvements are consistent across various model sizes and datasets, including multi-hop, biomedical, and adversarial QA datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。</SYS>>概念归属是大语言模型（LLM）中关键的概念，它允许控制信息来源并提高 LLM 的事实性。现有方法使用开书问答来提高归属，但是可能会奖励语言模型 recall 已经从预训练数据中学习的知识，而不是归属。相比之下，Counterfactual open book QA 数据集可以进一步提高归属，因为答案只能基于给定的文本。我们提议使用 Hallucination Augmented Recitations（HAR）来创建 counterfactual 数据集，利用 LLM 中的幻觉来提高归属。在 open book QA 中作为案例研究，我们表明，使用我们的 counterfactual 数据集可以提高文本固定，导致更好的 open book QA 性能，最高提高 F1 分数8.0%。我们的 counterfactual 数据集比使用人工标注的事实数据集更好，即使用4倍小数据和4倍小模型。我们发现，改进是模型size和数据集之间一致的，包括多步、医学和抗击 QA 数据集。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Values-in-Museum-Artifacts-in-the-SPICE-project-a-Preliminary-Study"><a href="#Exploring-Values-in-Museum-Artifacts-in-the-SPICE-project-a-Preliminary-Study" class="headerlink" title="Exploring Values in Museum Artifacts in the SPICE project: a Preliminary Study"></a>Exploring Values in Museum Artifacts in the SPICE project: a Preliminary Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07396">http://arxiv.org/abs/2311.07396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nele Kadastik, Thomas A. Pederson, Luis Emilio Bruni, Rossana Damiano, Antonio Lieto, Manuel Striani, Tsvi Kuflik, Alan Wecker</li>
<li>for: 本研究目的是开发一个 semantic reasoning 工具，以增强博物馆访问者的多样性视角。</li>
<li>methods: 该工具基于 TCL 常识推理框架，利用 Haidt 理论中的道德价值 ontological 模型，将博物馆展品相关联到共同价值和情感。</li>
<li>results: 在 Haifa 的 Hecht 博物馆collection 上进行先期测试，系统可以建议访问者不同价值观的文物，扩展访问者的博物馆经验。<details>
<summary>Abstract</summary>
This document describes the rationale, the implementation and a preliminary evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project to enhance the diversity of perspectives experienced by museum visitors. The tool, called DEGARI 2.0 for values, relies on the commonsense reasoning framework TCL, and exploits an ontological model formalizingthe Haidt's theory of moral values to associate museum items with combined values and emotions. Within a museum exhibition, this tool can suggest cultural items that are associated not only with the values of already experienced or preferred objects, but also with novel items with different value stances, opening the visit experience to more inclusive interpretations of cultural content. The system has been preliminarily tested, in the context of the SPICE project, on the collection of the Hecht Museum of Haifa.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Predicting-Continuous-Locomotion-Modes-via-Multidimensional-Feature-Learning-from-sEMG"><a href="#Predicting-Continuous-Locomotion-Modes-via-Multidimensional-Feature-Learning-from-sEMG" class="headerlink" title="Predicting Continuous Locomotion Modes via Multidimensional Feature Learning from sEMG"></a>Predicting Continuous Locomotion Modes via Multidimensional Feature Learning from sEMG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07395">http://arxiv.org/abs/2311.07395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiwen Fu, Wenjuan Zhong, Yuyang Zhang, Wenxuan Xiong, Yuzhou Lin, Yanlong Tai, Lin Meng, Mingming Zhang</li>
<li>for: 本研究旨在提高智能化和透明度的人工辅助器（walking-assistive device）控制方法，需要采用适应控制方法来实现平滑的模式转换。</li>
<li>methods: 本研究提出了 Deep-STF，一种综合的深度学习模型，用于捕捉surface electromyography（sEMG）信号的集成特征。该模型可以在不同的预测时间间隔（100-500 ms）上进行精准和可靠的连续预测九种行走模式和15种模式转换。</li>
<li>results: 实验结果表明，Deep-STF在多种行走模式和转换中表现出色，只靠基于sEMG数据进行预测。预测100 ms后，Deep-STF的均值预测精度为96.48%，即使延长预测时间间隔至500 ms，精度仅下降至93.00%。此外，对于下一个转换的稳定预测时间（stable prediction time）的评估也提供了有用的数据。<details>
<summary>Abstract</summary>
Walking-assistive devices require adaptive control methods to ensure smooth transitions between various modes of locomotion. For this purpose, detecting human locomotion modes (e.g., level walking or stair ascent) in advance is crucial for improving the intelligence and transparency of such robotic systems. This study proposes Deep-STF, a unified end-to-end deep learning model designed for integrated feature extraction in spatial, temporal, and frequency dimensions from surface electromyography (sEMG) signals. Our model enables accurate and robust continuous prediction of nine locomotion modes and 15 transitions at varying prediction time intervals, ranging from 100 to 500 ms. In addition, we introduced the concept of 'stable prediction time' as a distinct metric to quantify prediction efficiency. This term refers to the duration during which consistent and accurate predictions of mode transitions are made, measured from the time of the fifth correct prediction to the occurrence of the critical event leading to the task transition. This distinction between stable prediction time and prediction time is vital as it underscores our focus on the precision and reliability of mode transition predictions. Experimental results showcased Deep-STP's cutting-edge prediction performance across diverse locomotion modes and transitions, relying solely on sEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other machine learning techniques, achieving an outstanding average prediction accuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy only marginally decreased to 93.00%. The averaged stable prediction times for detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the 100-500 ms time advances.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified ChineseWalking-assistive devices require adaptive control methods to ensure smooth transitions between various modes of locomotion. For this purpose, detecting human locomotion modes (e.g., level walking or stair ascent) in advance is crucial for improving the intelligence and transparency of such robotic systems. This study proposes Deep-STF, a unified end-to-end deep learning model designed for integrated feature extraction in spatial, temporal, and frequency dimensions from surface electromyography (sEMG) signals. Our model enables accurate and robust continuous prediction of nine locomotion modes and 15 transitions at varying prediction time intervals, ranging from 100 to 500 ms. In addition, we introduced the concept of 'stable prediction time' as a distinct metric to quantify prediction efficiency. This term refers to the duration during which consistent and accurate predictions of mode transitions are made, measured from the time of the fifth correct prediction to the occurrence of the critical event leading to the task transition. This distinction between stable prediction time and prediction time is vital as it underscores our focus on the precision and reliability of mode transition predictions. Experimental results showcased Deep-STP's cutting-edge prediction performance across diverse locomotion modes and transitions, relying solely on sEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other machine learning techniques, achieving an outstanding average prediction accuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy only marginally decreased to 93.00%. The averaged stable prediction times for detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the 100-500 ms time advances.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Testing-learning-enabled-cyber-physical-systems-with-Large-Language-Models-A-Formal-Approach"><a href="#Testing-learning-enabled-cyber-physical-systems-with-Large-Language-Models-A-Formal-Approach" class="headerlink" title="Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach"></a>Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07377">http://arxiv.org/abs/2311.07377</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Zheng, Aloysius K. Mok, Ruzica Piskac, Yong Jae Lee, Bhaskar Krishnamachari, Dakai Zhu, Oleg Sokolsky, Insup Lee</li>
<li>for: This paper focuses on the challenges of ensuring formal safety in cyber-physical systems (CPS) that are infused with machine learning (ML).</li>
<li>methods: The paper examines testing as the most practical method for verification and validation, and summarizes current state-of-the-art methodologies. It also proposes a roadmap to transition from foundational probabilistic testing to a more rigorous approach that can provide formal assurance.</li>
<li>results: The paper identifies the main challenges in ensuring formal safety for learning-enabled CPS, and proposes a roadmap to address these challenges.<details>
<summary>Abstract</summary>
The integration of machine learning (ML) into cyber-physical systems (CPS) offers significant benefits, including enhanced efficiency, predictive capabilities, real-time responsiveness, and the enabling of autonomous operations. This convergence has accelerated the development and deployment of a range of real-world applications, such as autonomous vehicles, delivery drones, service robots, and telemedicine procedures. However, the software development life cycle (SDLC) for AI-infused CPS diverges significantly from traditional approaches, featuring data and learning as two critical components. Existing verification and validation techniques are often inadequate for these new paradigms. In this study, we pinpoint the main challenges in ensuring formal safety for learningenabled CPS.We begin by examining testing as the most pragmatic method for verification and validation, summarizing the current state-of-the-art methodologies. Recognizing the limitations in current testing approaches to provide formal safety guarantees, we propose a roadmap to transition from foundational probabilistic testing to a more rigorous approach capable of delivering formal assurance.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）在Cyber-Physical Systems（CPS）中的集成带来了 significative benefits，包括提高效率、预测能力、实时响应和自动化操作。这种整合已经加速了许多实际应用的开发和部署，例如自动驾驶车辆、快递机器人、服务机器人和 теле医疗程序。然而，AI-infused CPS 的软件开发生命周期（SDLC）与传统方法有很大差异，数据和学习作为两个关键组件。现有的验证和验证技术 часто无法满足这些新的 парадигмы的需求。在这种研究中，我们特别关注了确保正式安全的主要挑战。我们开始 by examining testing as the most practical method for verification and validation, summarizing the current state-of-the-art methodologies。认为现有的测试方法无法提供正式安全保证，我们提出了一个路线图，以帮助从基础概率测试过渡到更加严格的方法，以提供正式保证。
</details></li>
</ul>
<hr>
<h2 id="Past-as-a-Guide-Leveraging-Retrospective-Learning-for-Python-Code-Completion"><a href="#Past-as-a-Guide-Leveraging-Retrospective-Learning-for-Python-Code-Completion" class="headerlink" title="Past as a Guide: Leveraging Retrospective Learning for Python Code Completion"></a>Past as a Guide: Leveraging Retrospective Learning for Python Code Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07635">http://arxiv.org/abs/2311.07635</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SeungyounShin/Past-as-a-Guide">https://github.com/SeungyounShin/Past-as-a-Guide</a></li>
<li>paper_authors: Seunggyoon Shin, Seunggyu Chang, Sungjoon Choi</li>
<li>for: 提高大语言模型（LLM）的代码能力</li>
<li>methods:  integrate past history with interactive and iterative code refinements</li>
<li>results:  achieved 92% pass@1 on HumanEval, demonstrating the potential to advance the field by leveraging retrospection from past experiences and interactive and iterative refinement processes without external correctness indicators.<details>
<summary>Abstract</summary>
This work presents Past as a Guide (PaG), a simple approach for Large Language Models (LLMs) to improve the coding capabilities by integrating the past history with interactive and iterative code refinements. To be specific, inspired by human cognitive processes, the proposed method enables LLMs to utilize previous programming and debugging experiences to enhance the Python code completion tasks. The framework facilitates LLMs to iteratively refine the Python code based on previous execution and debugging results and optimize learning and reasoning capabilities. The proposed methodology achieved a 92\% pass@1 on HumanEval, demonstrating the potential to advance the field by leveraging retrospection from past experiences and interactive and iterative refinement processes without external correctness indicators.
</details>
<details>
<summary>摘要</summary>
这个工作提出了过去作为指南（PaG），一种简单的方法，用于大语言模型（LLM）提高编程能力。具体来说，这种方法受人类认知过程的启发，让提案的方法使用过去编程和调试经验来提高Python代码完成任务。框架允许LLM通过前一次执行和调试结果进行间接反复优化Python代码，提高学习和理解能力。该方法在HumanEval上达到92%的通过率@1，表明该方法可以利用过去经验和间接反复优化过程，不需要外部正确性指标，进而提高领域的进步。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Large-Language-Models-on-Scientific-Discovery-a-Preliminary-Study-using-GPT-4"><a href="#The-Impact-of-Large-Language-Models-on-Scientific-Discovery-a-Preliminary-Study-using-GPT-4" class="headerlink" title="The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4"></a>The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07361">http://arxiv.org/abs/2311.07361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Microsoft Research AI4Science, Microsoft Azure Quantum</li>
<li>for: 本研究的目的是评估GPT-4语言模型在科学发现方面的性能，以 validate its domain-specific expertise、accelerate scientific progress、optimize resource allocation、guide future model development和促进交叉学科研究。</li>
<li>methods: 本研究采用专家驱动的案例评估和 occasionally benchmark testing来评估GPT-4模型在各科学领域中的性能，以获得其对复杂科学概念和关系的理解和解决能力。</li>
<li>results: 初步调查显示，GPT-4模型在多种科学应用方面表现出了扎实的潜力，能够处理复杂的问题解决和知识集成任务。主要评估GPT-4的科学知识库、科学理解、科学数学计算能力和多种科学预测能力。<details>
<summary>Abstract</summary>
In recent years, groundbreaking advancements in natural language processing have culminated in the emergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a vast array of domains, including the understanding, generation, and translation of natural language, and even tasks that extend beyond language processing. In this report, we delve into the performance of LLMs within the context of scientific discovery, focusing on GPT-4, the state-of-the-art language model. Our investigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational chemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial differential equations (PDE). Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research. Our exploration methodology primarily consists of expert-driven case assessments, which offer qualitative insights into the model's comprehension of intricate scientific concepts and relationships, and occasionally benchmark testing, which quantitatively evaluates the model's capacity to solve well-defined domain-specific problems. Our preliminary exploration indicates that GPT-4 exhibits promising potential for a variety of scientific applications, demonstrating its aptitude for handling complex problem-solving and knowledge integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities.
</details>
<details>
<summary>摘要</summary>
近年来，自然语言处理技术的突破性进步使得强大的大语言模型（LLM）出现了，这些模型在各种领域表现出了惊人的能力，包括自然语言理解、生成和翻译，以及 extends beyond 语言处理的任务。在这份报告中，我们将关注 GPT-4，当前领域的状态的语言模型。我们的调查覆盖了多个科学领域，包括药物发现、生物、计算化学（密度功能理论（DFT）和分子动力学（MD））、材料设计和部分偏微方程（PDE）。我们通过专家驱动的案例评估和 occasionally  benchmark 测试来评估 GPT-4 在科学任务上的表现。我们的初步探索表明，GPT-4 在多种科学应用程序中表现出了潜在的潜力，证明它可以处理复杂的问题解决和知识集成任务。总的来说，我们评估 GPT-4 的知识基础、科学理解、科学数学计算能力和多种科学预测能力。
</details></li>
</ul>
<hr>
<h2 id="MetaSymNet-A-Dynamic-Symbolic-Regression-Network-Capable-of-Evolving-into-Arbitrary-Formulations"><a href="#MetaSymNet-A-Dynamic-Symbolic-Regression-Network-Capable-of-Evolving-into-Arbitrary-Formulations" class="headerlink" title="MetaSymNet: A Dynamic Symbolic Regression Network Capable of Evolving into Arbitrary Formulations"></a>MetaSymNet: A Dynamic Symbolic Regression Network Capable of Evolving into Arbitrary Formulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07326">http://arxiv.org/abs/2311.07326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanjie Li, Weijun Li, Lina Yu, Min Wu, Jinyi Liu, Wenqiang Li, Meilan Hao, Shu Wei, Yusong Deng</li>
<li>为：该 paper 的目的是提出一种可靠地自动生成易于理解的数学公式，以解决传统人工神经网络（MLP）的黑盒问题。* 方法：该 paper 使用了一种动态调整网络结构的方法，即 MetaSymNet，该方法可以在实时进行网络结构的扩展和缩小。此外，该 paper 还使用了 PANGU meta 函数作为活化函数，以生成特定需求的数学公式。* 结果：对比四种state-of-the-art симвоlic regression算法，该 paper 的 MetaSymNet 算法在 более чем 10 个公共数据集上进行了比较，并 consistently 表现出了更高的性能。此外，该 paper 还评估了 MetaSymNet 的拟合能力和推断能力，并发现其在这两个领域中均有优异表现。<details>
<summary>Abstract</summary>
Mathematical formulas serve as the means of communication between humans and nature, encapsulating the operational laws governing natural phenomena. The concise formulation of these laws is a crucial objective in scientific research and an important challenge for artificial intelligence (AI). While traditional artificial neural networks (MLP) excel at data fitting, they often yield uninterpretable black box results that hinder our understanding of the relationship between variables x and predicted values y. Moreover, the fixed network architecture in MLP often gives rise to redundancy in both network structure and parameters. To address these issues, we propose MetaSymNet, a novel neural network that dynamically adjusts its structure in real-time, allowing for both expansion and contraction. This adaptive network employs the PANGU meta function as its activation function, which is a unique type capable of evolving into various basic functions during training to compose mathematical formulas tailored to specific needs. We then evolve the neural network into a concise, interpretable mathematical expression. To evaluate MetaSymNet's performance, we compare it with four state-of-the-art symbolic regression algorithms across more than 10 public datasets comprising 222 formulas. Our experimental results demonstrate that our algorithm outperforms others consistently regardless of noise presence or absence. Furthermore, we assess MetaSymNet against MLP and SVM regarding their fitting ability and extrapolation capability, these are two essential aspects of machine learning algorithms. The findings reveal that our algorithm excels in both areas. Finally, we compared MetaSymNet with MLP using iterative pruning in network structure complexity. The results show that MetaSymNet's network structure complexity is obviously less than MLP under the same goodness of fit.
</details>
<details>
<summary>摘要</summary>
matematicos serve como meio de comunicação entre humanos e natureza, encapsulando as leis operacionais que governam fenômenos naturais. A formulação concisa dessas leis é um objetivo crucial na pesquisa científica e uma desvantagem importante para inteligência artificial (IA). Embora as redes neurais artificiais tradicionais (MLP) excelam em adaptação de dados, elas often yield resultados negros brutos que dificultam nossa compreensão da relação entre variáveis x e valores preditos y. Além disso, a estrutura de rede fixa em MLP frequentemente dá rise a redundância em ambos a estrutura de rede e parâmetros. Para abordar esses problemas, propomos MetaSymNet, uma rede neuronal novativa que ajusta sua estrutura em tempo real, permitindo expansão e contração. Essa rede adaptativa emprega a função de ativação PANGU, que é um tipo único capaz de evoluir para várias funções básicas durante o treinamento para compor fórmulas matemáticas personalizadas. Em seguida, evoluímos a rede neuronal para uma expressão matemática concisa e interpretable. Para avaliar o desempenho de MetaSymNet, comparamos com quatro algoritmos de regressão simbólica de estado da arte em mais de 10 conjuntos de dados públicos, que incluem 222 fórmulas. Nossos resultados experimentais demonstram que nosso algoritmo supera os outros consistentemente, independentemente da presença ou ausência de ruído. Além disso, avaliamos MetaSymNet em relação à capacidade de ajuste de MLP e SVM para adaptação de dados e extrapolação. Os resultados mostram que nosso algoritmo excelentes em ambas as áreas. Por fim, comparamos MetaSymNet com MLP usando rede de pruned em complexidade de estrutura. Os resultados mostram que a complexidade de estrutura de MetaSymNet é significativamente menor do que MLP sob o mesmo bom ajuste.
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Transportable-Causal-Network-Model-Based-on-Observational-Healthcare-Data"><a href="#Towards-a-Transportable-Causal-Network-Model-Based-on-Observational-Healthcare-Data" class="headerlink" title="Towards a Transportable Causal Network Model Based on Observational Healthcare Data"></a>Towards a Transportable Causal Network Model Based on Observational Healthcare Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08427">http://arxiv.org/abs/2311.08427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alice Bernasconi, Alessio Zanga, Peter J. F. Lucas, Marco Scutari Fabio Stella</li>
<li>for: 本研究旨在提供一种基于人工智能技术的诊断模型，以提高妊娠和青少年女性患有乳腺癌后的心血管风险评估。</li>
<li>methods: 本研究使用选择图、缺失图、 causal发现和先前知识 combine into a single graphical model，以估计青少年女性患有乳腺癌后心血管风险。 研究从两个不同的患者群体中获取数据，并由专业医生 validate 模型的风险评估、准确率和可解释性。</li>
<li>results: 研究结果表明，使用该模型可以在诊断中提高妊娠和青少年女性患有乳腺癌后心血管风险的准确率，并且模型的预测结果比其他机器学习方法更加准确。<details>
<summary>Abstract</summary>
Over the last decades, many prognostic models based on artificial intelligence techniques have been used to provide detailed predictions in healthcare. Unfortunately, the real-world observational data used to train and validate these models are almost always affected by biases that can strongly impact the outcomes validity: two examples are values missing not-at-random and selection bias. Addressing them is a key element in achieving transportability and in studying the causal relationships that are critical in clinical decision making, going beyond simpler statistical approaches based on probabilistic association.   In this context, we propose a novel approach that combines selection diagrams, missingness graphs, causal discovery and prior knowledge into a single graphical model to estimate the cardiovascular risk of adolescent and young females who survived breast cancer. We learn this model from data comprising two different cohorts of patients. The resulting causal network model is validated by expert clinicians in terms of risk assessment, accuracy and explainability, and provides a prognostic model that outperforms competing machine learning methods.
</details>
<details>
<summary>摘要</summary>
In this context, we propose a novel approach that combines selection diagrams, missingness graphs, causal discovery, and prior knowledge into a single graphical model to estimate the cardiovascular risk of adolescent and young females who survived breast cancer. We use data from two different cohorts of patients to learn this model, and the resulting causal network model is validated by expert clinicians in terms of risk assessment, accuracy, and explainability. The model outperforms competing machine learning methods in providing accurate predictions.
</details></li>
</ul>
<hr>
<h2 id="Rethinking-and-Benchmarking-Predict-then-Optimize-Paradigm-for-Combinatorial-Optimization-Problems"><a href="#Rethinking-and-Benchmarking-Predict-then-Optimize-Paradigm-for-Combinatorial-Optimization-Problems" class="headerlink" title="Rethinking and Benchmarking Predict-then-Optimize Paradigm for Combinatorial Optimization Problems"></a>Rethinking and Benchmarking Predict-then-Optimize Paradigm for Combinatorial Optimization Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07633">http://arxiv.org/abs/2311.07633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Geng, Han Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan</li>
<li>for: 研究领域是 Predict-Then-Optimize (PTO) 中的决策和预测组件系统，旨在解决各种 combinatorial optimization 问题，如能源成本考虑的排程、网络广告预算分配和社交网络上的图像匹配等。</li>
<li>methods: 研究使用的方法包括 end-to-end 方法和传统两阶段方法，以 Directly Optimizing the Ultimate Decision Quality 的方式来提高决策质量。</li>
<li>results: 研究提供了一个整合现有实验场景的benchmark，以便评估不同情况下的模型效果，并提供了一个新的 industrial combinatorial advertising 问题的数据集，以便更好地评估和应用这些方法。<details>
<summary>Abstract</summary>
Numerous web applications rely on solving combinatorial optimization problems, such as energy cost-aware scheduling, budget allocation on web advertising, and graph matching on social networks. However, many optimization problems involve unknown coefficients, and improper predictions of these factors may lead to inferior decisions which may cause energy wastage, inefficient resource allocation, inappropriate matching in social networks, etc. Such a research topic is referred to as "Predict-Then-Optimize (PTO)" which considers the performance of prediction and decision-making in a unified system. A noteworthy recent development is the end-to-end methods by directly optimizing the ultimate decision quality which claims to yield better results in contrast to the traditional two-stage approach. However, the evaluation benchmarks in this field are fragmented and the effectiveness of various models in different scenarios remains unclear, hindering the comprehensive assessment and fast deployment of these methods. To address these issues, we provide a comprehensive categorization of current approaches and integrate existing experimental scenarios to establish a unified benchmark, elucidating the circumstances under which end-to-end training yields improvements, as well as the contexts in which it performs ineffectively. We also introduce a new dataset for the industrial combinatorial advertising problem for inclusive finance to open-source. We hope the rethinking and benchmarking of PTO could facilitate more convenient evaluation and deployment, and inspire further improvements both in the academy and industry within this field.
</details>
<details>
<summary>摘要</summary>
许多网络应用程序依赖于解决 combinatorial optimization 问题，如能源成本考虑的调度、在网络广告上的预算分配和社交网络上的图像匹配。然而，许多优化问题中的系数未知， incorrect predictions of these factors may lead to inferior decisions, resulting in energy waste, inefficient resource allocation, inappropriate matching in social networks, and so on. This research topic is referred to as "Predict-Then-Optimize (PTO)" and considers the performance of prediction and decision-making in a unified system.Recent developments in end-to-end methods have claimed to yield better results by directly optimizing the ultimate decision quality, but the evaluation benchmarks in this field are fragmented and the effectiveness of various models in different scenarios remains unclear. To address these issues, we provide a comprehensive categorization of current approaches and integrate existing experimental scenarios to establish a unified benchmark, elucidating the circumstances under which end-to-end training yields improvements and the contexts in which it performs ineffectively.In addition, we introduce a new dataset for the industrial combinatorial advertising problem in the field of inclusive finance to open-source. We hope that the rethinking and benchmarking of PTO could facilitate more convenient evaluation and deployment, and inspire further improvements both in the academy and industry within this field.
</details></li>
</ul>
<hr>
<h2 id="ResMGCN-Residual-Message-Graph-Convolution-Network-for-Fast-Biomedical-Interactions-Discovering"><a href="#ResMGCN-Residual-Message-Graph-Convolution-Network-for-Fast-Biomedical-Interactions-Discovering" class="headerlink" title="ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering"></a>ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07632">http://arxiv.org/abs/2311.07632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zecheng Yin</li>
<li>for: 本研究旨在提出一种fast和精准的生物医学信息图connolly方法，以便更好地预测生物医学信息之间的互动。</li>
<li>methods: 本研究使用了一种新型的剩余消息图卷积网络（ResMGCN），它可以快速和精准地捕捉生物医学信息之间的互动。ResMGCN通过聚合下一层信息和前一层信息来 guide node更新，从而获得更有意义的节点表示。</li>
<li>results: 在四个生物医学互动网络数据集上进行了实验，结果显示，ResMGCN可以比前一代模型更高效地使用存储和时间，并且在预测生物医学信息之间的互动方面达到了极高的效果。<details>
<summary>Abstract</summary>
Biomedical information graphs are crucial for interaction discovering of biomedical information in modern age, such as identification of multifarious molecular interactions and drug discovery, which attracts increasing interests in biomedicine, bioinformatics, and human healthcare communities. Nowadays, more and more graph neural networks have been proposed to learn the entities of biomedical information and precisely reveal biomedical molecule interactions with state-of-the-art results. These methods remedy the fading of features from a far distance but suffer from remedying such problem at the expensive cost of redundant memory and time. In our paper, we propose a novel Residual Message Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction prediction in a different idea. Specifically, instead of enhancing the message from far nodes, ResMGCN aggregates lower-order information with the next round higher information to guide the node update to obtain a more meaningful node representation. ResMGCN is able to perceive and preserve various messages from the previous layer and high-order information in the current layer with least memory and time cost to obtain informative representations of biomedical entities. We conduct experiments on four biomedical interaction network datasets, including protein-protein, drug-drug, drug-target, and gene-disease interactions, which demonstrates that ResMGCN outperforms previous state-of-the-art models while achieving superb effectiveness on both storage and time.
</details>
<details>
<summary>摘要</summary>
生物医学信息图是现代生物医学研究中不可或缺的工具，用于揭示生物医学信息的多样性，如蛋白质相互作用和药物发现，这在生物医学、生物信息学和人类医疗领域引起了越来越多的关注。在当今，越来越多的图 neural network 被提议用于学习生物医学信息的实体和准确地揭示生物分子相互作用。然而，这些方法往往会带来缺乏特征的问题，并且需要大量的内存和时间成本。在我们的论文中，我们提出了一种新的差异 идеald Residual Message Graph Convolution Network (ResMGCN)，用于快速和准确的生物医学交互预测。Specifically, ResMGCN 通过在下一轮更高级别信息的帮助下，将下一轮更低级别信息与当前层信息融合，以便更准确地更新节点表示。ResMGCN 能够捕捉和保留上一层和当前层的所有信息，并在最小的内存和时间成本下获得有用的生物医学实体表示。我们在四个生物医学交互网络数据集上进行了实验，包括蛋白质-蛋白质、药物-药物、药物-目标和基因-疾病交互，结果表明，ResMGCN 在存储和时间成本方面具有superb的效果，而且在生物医学交互预测方面具有极高的准确率。
</details></li>
</ul>
<hr>
<h2 id="Semi-automatic-Data-Enhancement-for-Document-Level-Relation-Extraction-with-Distant-Supervision-from-Large-Language-Models"><a href="#Semi-automatic-Data-Enhancement-for-Document-Level-Relation-Extraction-with-Distant-Supervision-from-Large-Language-Models" class="headerlink" title="Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models"></a>Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07314">http://arxiv.org/abs/2311.07314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junpeng Li, Zixia Jia, Zilong Zheng</li>
<li>for: 文章的目的是提出一种自动化文档关系EXTRACTION的方法，以便减少人工干预。</li>
<li>methods: 该方法利用大语言模型（LLM）和自然语言推理（NLI）模块生成关系 triple，以增强文档关系集。</li>
<li>results:  authors 通过对 DocGNRE 数据集进行重新标注，发现该方法能够提高文档关系EXTRACTION的准确率。<details>
<summary>Abstract</summary>
Document-level Relation Extraction (DocRE), which aims to extract relations from a long context, is a critical challenge in achieving fine-grained structural comprehension and generating interpretable document representations. Inspired by recent advances in in-context learning capabilities emergent from large language models (LLMs), such as ChatGPT, we aim to design an automated annotation method for DocRE with minimum human effort. Unfortunately, vanilla in-context learning is infeasible for document-level relation extraction due to the plenty of predefined fine-grained relation types and the uncontrolled generations of LLMs. To tackle this issue, we propose a method integrating a large language model (LLM) and a natural language inference (NLI) module to generate relation triples, thereby augmenting document-level relation datasets. We demonstrate the effectiveness of our approach by introducing an enhanced dataset known as DocGNRE, which excels in re-annotating numerous long-tail relation types. We are confident that our method holds the potential for broader applications in domain-specific relation type definitions and offers tangible benefits in advancing generalized language semantic comprehension.
</details>
<details>
<summary>摘要</summary>
文档级关系提取（DocRE），targeting to extract relations from a long context, is a crucial challenge in achieving fine-grained structural comprehension and generating interpretable document representations. Inspired by recent advances in in-context learning capabilities emergent from large language models (LLMs), such as ChatGPT, we aim to design an automated annotation method for DocRE with minimum human effort. However, vanilla in-context learning is infeasible for document-level relation extraction due to the abundance of predefined fine-grained relation types and the uncontrolled generations of LLMs. To address this issue, we propose a method integrating a large language model (LLM) and a natural language inference (NLI) module to generate relation triples, thereby augmenting document-level relation datasets. We demonstrate the effectiveness of our approach by introducing an enhanced dataset known as DocGNRE, which excels in re-annotating numerous long-tail relation types. We believe that our method holds great potential for broader applications in domain-specific relation type definitions and offers tangible benefits in advancing generalized language semantic comprehension.
</details></li>
</ul>
<hr>
<h2 id="C-Procgen-Empowering-Procgen-with-Controllable-Contexts"><a href="#C-Procgen-Empowering-Procgen-with-Controllable-Contexts" class="headerlink" title="C-Procgen: Empowering Procgen with Controllable Contexts"></a>C-Procgen: Empowering Procgen with Controllable Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07312">http://arxiv.org/abs/2311.07312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenxiong Tan, Kaixin Wang, Xinchao Wang</li>
<li>for: 这篇论文是为了提供一个增强的 Procgen 环境集，以便进行多种研究。</li>
<li>methods: 这篇论文使用了细致的环境配置机制，包括游戏机制和代理特性。这使得过程生成过程，之前是一个黑盒，现在变得更加透明和可调整。</li>
<li>results: C-Procgen 提供了200多个独特的游戏上下文，并且可以进行精细的环境配置。这使得研究人员可以更好地控制和分析过程生成过程。<details>
<summary>Abstract</summary>
We present C-Procgen, an enhanced suite of environments on top of the Procgen benchmark. C-Procgen provides access to over 200 unique game contexts across 16 games. It allows for detailed configuration of environments, ranging from game mechanics to agent attributes. This makes the procedural generation process, previously a black-box in Procgen, more transparent and adaptable for various research needs.The upgrade enhances dynamic context management and individualized assignments, while maintaining computational efficiency. C-Procgen's controllable contexts make it applicable in diverse reinforcement learning research areas, such as learning dynamics analysis, curriculum learning, and transfer learning. We believe that C-Procgen will fill a gap in the current literature and offer a valuable toolkit for future works.
</details>
<details>
<summary>摘要</summary>
我们介绍C-Procgen，一个增强版的环境集合，基于Procgen测试库。C-Procgen提供了超过200个不同游戏情境，涵盖16款游戏。它允许精确地配置环境，从游戏机制到代理属性。这使得预设的生成过程，在Procgen中是一个黑盒子，现在变得更加透明和可调整，适用于不同的研究需求。升级提高了动态上下文管理和个性化分配，保持计算效率。C-Procgen的可控上下文使其适用于多种强化学习研究领域，如学习动力分析、课程学习和转移学习。我们认为C-Procgen将填补现有文献中的空白，并提供一个有价的工具组。
</details></li>
</ul>
<hr>
<h2 id="Do-large-language-models-and-humans-have-similar-behaviors-in-causal-inference-with-script-knowledge"><a href="#Do-large-language-models-and-humans-have-similar-behaviors-in-causal-inference-with-script-knowledge" class="headerlink" title="Do large language models and humans have similar behaviors in causal inference with script knowledge?"></a>Do large language models and humans have similar behaviors in causal inference with script knowledge?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07311">http://arxiv.org/abs/2311.07311</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tony-hong/causal-script">https://github.com/tony-hong/causal-script</a></li>
<li>paper_authors: Xudong Hong, Margarita Ryzhova, Daniel Adrian Biondi, Vera Demberg</li>
<li>for: 研究大型预训语言模型（LLMs）的语言理解能力，包括零shot causal reasoning。</li>
<li>methods: 使用脚本基于的故事进行研究，检测事件B的处理。</li>
<li>results: 1) 最新的LLMs（如GPT-3或Vicuna）与人类行为相似，在$\neg A \rightarrow B$ condition下显示较长的阅读时间。2)  despite this correlation, all models still have difficulty integrating script knowledge, failing to predict that $nil \rightarrow B$ is less surprising than $\neg A \rightarrow B$.<details>
<summary>Abstract</summary>
Recently, large pre-trained language models (LLMs) have demonstrated superior language understanding abilities, including zero-shot causal reasoning. However, it is unclear to what extent their capabilities are similar to human ones. We here study the processing of an event $B$ in a script-based story, which causally depends on a previous event $A$. In our manipulation, event $A$ is stated, negated, or omitted in an earlier section of the text. We first conducted a self-paced reading experiment, which showed that humans exhibit significantly longer reading times when causal conflicts exist ($\neg A \rightarrow B$) than under logical conditions ($A \rightarrow B$). However, reading times remain similar when cause A is not explicitly mentioned, indicating that humans can easily infer event B from their script knowledge. We then tested a variety of LLMs on the same data to check to what extent the models replicate human behavior. Our experiments show that 1) only recent LLMs, like GPT-3 or Vicuna, correlate with human behavior in the $\neg A \rightarrow B$ condition. 2) Despite this correlation, all models still fail to predict that $nil \rightarrow B$ is less surprising than $\neg A \rightarrow B$, indicating that LLMs still have difficulties integrating script knowledge. Our code and collected data set are available at https://github.com/tony-hong/causal-script.
</details>
<details>
<summary>摘要</summary>
最近，大型预训言语模型（LLM）表现出了优秀的语言理解能力，包括零shot causal reasoning。然而，它们与人类的能力相似程度还是未知。我们在这里研究一个script-based story中的事件B的处理，它受到前一个事件A的 causal dependence。在我们的探索中，事件A在文本中的某个前面部分被读出、否定或 omits。我们首先进行了自适应阅读实验，发现在 causal conflict 存在（$\neg A \rightarrow B$）时，人类的阅读时间显著 longer than logical conditions 时间 ($A \rightarrow B$）。然而，阅读时间在 causal A 不是直接提到时仍然很相似， indicating that humans can easily infer event B from their script knowledge。然后，我们测试了多种 LLM 在同一数据集上，以确定它们与人类行为相似度。我们的实验结果表明：1）只有最新的 LLM，如 GPT-3 或 Vicuna，与人类行为在 $\neg A \rightarrow B$ 条件中相似。2）尽管与人类行为相似，所有模型仍然无法预测 $nil \rightarrow B$ 比 $\neg A \rightarrow B$ 更少意外，表明 LLMs 仍然有困难 integra script knowledge。我们的代码和数据集可以在 https://github.com/tony-hong/causal-script 上获取。
</details></li>
</ul>
<hr>
<h2 id="Explaining-black-boxes-with-a-SMILE-Statistical-Model-agnostic-Interpretability-with-Local-Explanations"><a href="#Explaining-black-boxes-with-a-SMILE-Statistical-Model-agnostic-Interpretability-with-Local-Explanations" class="headerlink" title="Explaining black boxes with a SMILE: Statistical Model-agnostic Interpretability with Local Explanations"></a>Explaining black boxes with a SMILE: Statistical Model-agnostic Interpretability with Local Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07286">http://arxiv.org/abs/2311.07286</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dependable-intelligent-systems-lab/xwhy">https://github.com/dependable-intelligent-systems-lab/xwhy</a></li>
<li>paper_authors: Koorosh Aslansefat, Mojgan Hashemian, Martin Walker, Mohammed Naveed Akram, Ioannis Sorokos, Yiannis Papadopoulos</li>
<li>for: 提高机器学习模型的可信度</li>
<li>methods: 使用统计距离度量进行解释性提高</li>
<li>results: 提高解释性不会减少模型的通用性<details>
<summary>Abstract</summary>
Machine learning is currently undergoing an explosion in capability, popularity, and sophistication. However, one of the major barriers to widespread acceptance of machine learning (ML) is trustworthiness: most ML models operate as black boxes, their inner workings opaque and mysterious, and it can be difficult to trust their conclusions without understanding how those conclusions are reached. Explainability is therefore a key aspect of improving trustworthiness: the ability to better understand, interpret, and anticipate the behaviour of ML models. To this end, we propose SMILE, a new method that builds on previous approaches by making use of statistical distance measures to improve explainability while remaining applicable to a wide range of input data domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TIAGo-RL-Simulated-Reinforcement-Learning-Environments-with-Tactile-Data-for-Mobile-Robots"><a href="#TIAGo-RL-Simulated-Reinforcement-Learning-Environments-with-Tactile-Data-for-Mobile-Robots" class="headerlink" title="TIAGo RL: Simulated Reinforcement Learning Environments with Tactile Data for Mobile Robots"></a>TIAGo RL: Simulated Reinforcement Learning Environments with Tactile Data for Mobile Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07260">http://arxiv.org/abs/2311.07260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Lach, Francesco Ferro, Robert Haschke</li>
<li>For: The paper is written for researchers and developers working on robotic tasks that involve physical interaction, such as object manipulation.* Methods: The paper uses deep reinforcement learning (DRL) to learn complex behavior in robotics, specifically for the TIAGo service robot.* Results: The paper presents preliminary training results of a learned force control policy and compares it to a classical PI controller.Here’s the information in Simplified Chinese text:* For: 这篇论文是为了研究机器人完成物理互动任务而写的，如物体抓取等。* Methods: 这篇论文使用深度强化学习（DRL）来学习机器人行为，具体来说是为TIAGo服务机器人。* Results: 论文提供了一些初步训练结果，比较了一个学习的力控制策略和一个经典PI控制器。<details>
<summary>Abstract</summary>
Tactile information is important for robust performance in robotic tasks that involve physical interaction, such as object manipulation. However, with more data included in the reasoning and control process, modeling behavior becomes increasingly difficult. Deep Reinforcement Learning (DRL) produced promising results for learning complex behavior in various domains, including tactile-based manipulation in robotics. In this work, we present our open-source reinforcement learning environments for the TIAGo service robot. They produce tactile sensor measurements that resemble those of a real sensorised gripper for TIAGo, encouraging research in transfer learning of DRL policies. Lastly, we show preliminary training results of a learned force control policy and compare it to a classical PI controller.
</details>
<details>
<summary>摘要</summary>
感觉信息对于机器人完成物理互动任务时的稳定性有着重要的作用。然而，随着数据的增加，模型行为变得越来越复杂。深度强化学习（DRL）在不同领域中都有出色的表现，包括机器人的柔软 manipulate。在这篇文章中，我们公布了对TIAGo服务机器人的开源强化学习环境。它们生成了类似于真实感知器的抓取器的感知数据，鼓励研究在DRL策略的传递学习。最后，我们显示了一个学习的力控策略的初步训练结果，并与经典PI控制器进行比较。
</details></li>
</ul>
<hr>
<h2 id="Towards-Transferring-Tactile-based-Continuous-Force-Control-Policies-from-Simulation-to-Robot"><a href="#Towards-Transferring-Tactile-based-Continuous-Force-Control-Policies-from-Simulation-to-Robot" class="headerlink" title="Towards Transferring Tactile-based Continuous Force Control Policies from Simulation to Robot"></a>Towards Transferring Tactile-based Continuous Force Control Policies from Simulation to Robot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07245">http://arxiv.org/abs/2311.07245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Lach, Robert Haschke, Davide Tateo, Jan Peters, Helge Ritter, Júlia Borràs, Carme Torras</li>
<li>for: 本研究旨在提出一种基于深度学习的无模型控制方法，用于控制 робоット在抓取物体时的力量。</li>
<li>methods: 该方法使用模拟环境生成实际的正常力，并使用深度学习算法来训练连续力控制策略。</li>
<li>results: 对比基eline，该方法在实际中表现出较高的性能，并且通过对域随机化和假设干扰进行了验证。Translation:</li>
<li>for: The purpose of this research is to propose a model-free deep reinforcement learning method for controlling the force of a robot when grasping objects.</li>
<li>methods: The method uses a simulation environment to generate realistic normal forces and employs deep learning algorithms to train continuous force control policies.</li>
<li>results: Compared to the baseline, the proposed method performs better in practical applications and is validated through domain randomization and ablation studies.<details>
<summary>Abstract</summary>
The advent of tactile sensors in robotics has sparked many ideas on how robots can leverage direct contact measurements of their environment interactions to improve manipulation tasks. An important line of research in this regard is that of grasp force control, which aims to manipulate objects safely by limiting the amount of force exerted on the object. While prior works have either hand-modeled their force controllers, employed model-based approaches, or have not shown sim-to-real transfer, we propose a model-free deep reinforcement learning approach trained in simulation and then transferred to the robot without further fine-tuning. We therefore present a simulation environment that produces realistic normal forces, which we use to train continuous force control policies. An evaluation in which we compare against a baseline and perform an ablation study shows that our approach outperforms the hand-modeled baseline and that our proposed inductive bias and domain randomization facilitate sim-to-real transfer. Code, models, and supplementary videos are available on https://sites.google.com/view/rl-force-ctrl
</details>
<details>
<summary>摘要</summary>
《机器人拥有感觉传感器后，许多想法就被提出来了，以便机器人通过直接接触环境来改进搅动任务。重要的一线研究在这方面是抓持力控制，它的目标是安全地搅动物体，限制搅动物体的力量。而在众所周知的方法中，有些人手动建模了他们的力控制器，有些人使用模型基本的方法，而其他人没有显示实验到实际的转移。我们则提出了一种没有模型基本的深度学习掌控方法，在模拟环境中训练继续力控制策略，然后将其转移到机器人上， без需要进一步的微调。因此，我们提供了一个生成真实正常力的模拟环境，用于训练连续力控制策略。我们对比基准和扫描研究表明，我们的方法高效性比手动建模基准高，并且我们提出的假设和随机预处理促进了实验到实际的转移。代码、模型和补充视频可以在https://sites.google.com/view/rl-force-ctrl中找到。》Note that Simplified Chinese is a written form of Chinese that uses simpler characters and grammar than Traditional Chinese. It is commonly used in mainland China and other parts of the world where Simplified Chinese is the standard form of Chinese.
</details></li>
</ul>
<hr>
<h2 id="In-Search-of-the-Long-Tail-Systematic-Generation-of-Long-Tail-Knowledge-via-Logical-Rule-Guided-Search"><a href="#In-Search-of-the-Long-Tail-Systematic-Generation-of-Long-Tail-Knowledge-via-Logical-Rule-Guided-Search" class="headerlink" title="In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search"></a>In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07237">http://arxiv.org/abs/2311.07237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ink-usc/link">https://github.com/ink-usc/link</a></li>
<li>paper_authors: Huihan Li, Yuting Ning, Zeyi Liao, Siyuan Wang, Xiang Lorraine Li, Ximing Lu, Faeze Brahman, Wenting Zhao, Yejin Choi, Xiang Ren</li>
<li>for: 这个论文的目的是为了系统地生成尖顶分布中的知识声明。</li>
<li>methods: 这个论文使用了一种名为Logic-Induced-Knowledge-Search（LINK）框架，通过使用一个符号语句作为基础，首先通过提示一个LLM获取初始值，然后通过批评者来验证这些值的正确性，最后通过推进器来强制实现尖顶分布。</li>
<li>results: 这个论文提出了一个名为Logic-Induced-Long-Tail（LINT）的数据集，包含200个符号规则和50000个知识声明，覆盖了四个领域。人工检验发现84%的声明是正确的。与此同时，ChatGPT和GPT4直接根据逻辑规则生成长尾声明时的正确率分别为56%和78%，而且他们的“长尾”生成实际上都处于更高的可能性范围内，因此不是真正的长尾。这些结论表明LINK是有效地生成尖顶分布中的数据，并且LINT可以用于系统地评估LLM的长尾分布能力。<details>
<summary>Abstract</summary>
Since large language models have approached human-level performance on many tasks, it has become increasingly harder for researchers to find tasks that are still challenging to the models. Failure cases usually come from the long-tail distribution - data that an oracle language model could assign a probability on the lower end of its distribution. Current methodology such as prompt engineering or crowdsourcing are insufficient for creating long-tail examples because humans are constrained by cognitive bias. We propose a Logic-Induced-Knowledge-Search (LINK) framework for systematically generating long-tail knowledge statements. Grounded by a symbolic rule, we search for long-tail values for each variable of the rule by first prompting a LLM, then verifying the correctness of the values with a critic, and lastly pushing for the long-tail distribution with a reranker. With this framework we construct a dataset, Logic-Induced-Long-Tail (LINT), consisting of 200 symbolic rules and 50K knowledge statements spanning across four domains. Human annotations find that 84% of the statements in LINT are factually correct. In contrast, ChatGPT and GPT4 struggle with directly generating long-tail statements under the guidance of logic rules, each only getting 56% and 78% of their statements correct. Moreover, their "long-tail" generations in fact fall into the higher likelihood range, and thus are not really long-tail. Our findings suggest that LINK is effective for generating data in the long-tail distribution while enforcing quality. LINT can be useful for systematically evaluating LLMs' capabilities in the long-tail distribution. We challenge the models with a simple entailment classification task using samples from LINT. We find that ChatGPT and GPT4's capability in identifying incorrect knowledge drop by ~3% in the long-tail distribution compared to head distribution.
</details>
<details>
<summary>摘要</summary>
Since large language models have approached human-level performance on many tasks, it has become increasingly difficult for researchers to find tasks that are still challenging to the models. Failure cases usually come from the long-tail distribution - data that an oracle language model could assign a probability on the lower end of its distribution. Current methodology such as prompt engineering or crowdsourcing are insufficient for creating long-tail examples because humans are constrained by cognitive bias. We propose a Logic-Induced-Knowledge-Search (LINK) framework for systematically generating long-tail knowledge statements. Grounded by a symbolic rule, we search for long-tail values for each variable of the rule by first prompting a LLM, then verifying the correctness of the values with a critic, and lastly pushing for the long-tail distribution with a reranker. With this framework we construct a dataset, Logic-Induced-Long-Tail (LINT), consisting of 200 symbolic rules and 50K knowledge statements spanning across four domains. Human annotations find that 84% of the statements in LINT are factually correct. In contrast, ChatGPT and GPT4 struggle with directly generating long-tail statements under the guidance of logic rules, each only getting 56% and 78% of their statements correct. Moreover, their "long-tail" generations in fact fall into the higher likelihood range, and thus are not really long-tail. Our findings suggest that LINK is effective for generating data in the long-tail distribution while enforcing quality. LINT can be useful for systematically evaluating LLMs' capabilities in the long-tail distribution. We challenge the models with a simple entailment classification task using samples from LINT. We find that ChatGPT and GPT4's capability in identifying incorrect knowledge drops by ~3% in the long-tail distribution compared to head distribution.
</details></li>
</ul>
<hr>
<h2 id="IASCAR-Incremental-Answer-Set-Counting-by-Anytime-Refinement"><a href="#IASCAR-Incremental-Answer-Set-Counting-by-Anytime-Refinement" class="headerlink" title="IASCAR: Incremental Answer Set Counting by Anytime Refinement"></a>IASCAR: Incremental Answer Set Counting by Anytime Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07233">http://arxiv.org/abs/2311.07233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes K. Fichte, Sarah Alice Gaggl, Markus Hecher, Dominik Rusovac</li>
<li>for: 这篇论文旨在探讨 Ansemble Programming（ASP）中 counting answer sets 的问题，以及如何使用知识编译来提高计数效率。</li>
<li>methods: 本文使用了知识编译技术，将 ASP 程序转换成 CNF 式，然后使用 inclusion-exclusion principle 进行系统的排除和包含计数，以提高计数效率。</li>
<li>results: 在预liminary empirical analysis中，本文 demonstarted promising results，指出iterative counting可以快速计数 answer sets，并且可以提高计数效率。<details>
<summary>Abstract</summary>
Answer set programming (ASP) is a popular declarative programming paradigm with various applications. Programs can easily have many answer sets that cannot be enumerated in practice, but counting still allows quantifying solution spaces. If one counts under assumptions on literals, one obtains a tool to comprehend parts of the solution space, so-called answer set navigation. However, navigating through parts of the solution space requires counting many times, which is expensive in theory. Knowledge compilation compiles instances into representations on which counting works in polynomial time. However, these techniques exist only for CNF formulas, and compiling ASP programs into CNF formulas can introduce an exponential overhead. This paper introduces a technique to iteratively count answer sets under assumptions on knowledge compilations of CNFs that encode supported models. Our anytime technique uses the inclusion-exclusion principle to improve bounds by over- and undercounting systematically. In a preliminary empirical analysis, we demonstrate promising results. After compiling the input (offline phase), our approach quickly (re)counts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-for-Robotics-A-Survey"><a href="#Large-Language-Models-for-Robotics-A-Survey" class="headerlink" title="Large Language Models for Robotics: A Survey"></a>Large Language Models for Robotics: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07226">http://arxiv.org/abs/2311.07226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, Philip S. Yu</li>
<li>for: This paper aims to provide a comprehensive review of the applications of large language models (LLMs) in robotics, exploring their impact and contributions to key areas such as robot control, perception, decision-making, and path planning.</li>
<li>methods: The paper uses a variety of techniques, including those employed in perception, decision-making, control, and interaction, to demonstrate the potential of LLMs in enhancing robot intelligence and human-robot interaction.</li>
<li>results: The paper highlights recent advancements in robotics models based on LLMs, including their ability to process and generate natural language, facilitating efficient interaction and collaboration with robots. The paper also explores the potential challenges that LLMs may face in the near future, such as the need for more diverse and nuanced training data.<details>
<summary>Abstract</summary>
The human ability to learn, generalize, and control complex manipulation tasks through multi-modality feedback suggests a unique capability, which we refer to as dexterity intelligence. Understanding and assessing this intelligence is a complex task. Amidst the swift progress and extensive proliferation of large language models (LLMs), their applications in the field of robotics have garnered increasing attention. LLMs possess the ability to process and generate natural language, facilitating efficient interaction and collaboration with robots. Researchers and engineers in the field of robotics have recognized the immense potential of LLMs in enhancing robot intelligence, human-robot interaction, and autonomy. Therefore, this comprehensive review aims to summarize the applications of LLMs in robotics, delving into their impact and contributions to key areas such as robot control, perception, decision-making, and path planning. We first provide an overview of the background and development of LLMs for robotics, followed by a description of the benefits of LLMs for robotics and recent advancements in robotics models based on LLMs. We then delve into the various techniques used in the model, including those employed in perception, decision-making, control, and interaction. Finally, we explore the applications of LLMs in robotics and some potential challenges they may face in the near future. Embodied intelligence is the future of intelligent science, and LLMs-based robotics is one of the promising but challenging paths to achieve this.
</details>
<details>
<summary>摘要</summary>
人类的学习、总结和控制复杂 manipulate 任务的能力，我们称之为dexterity intelligence。了解和评估这种智能是一项复杂的任务。随着大语言模型（LLMs）的快速进步和广泛普及，它们在机器人领域的应用得到了越来越多的注意。LLMs具有处理和生成自然语言的能力，可以为机器人交互和合作提供高效的方式。 robotics 领域的研究人员和工程师认为，LLMs在机器人智能、人机交互和自主性方面具有巨大的潜力。因此，本评论的目的是总结LLMs在机器人领域的应用，探讨它们在机器人控制、观察、决策和规划等领域的影响和贡献。我们首先提供LLMs在机器人领域的背景和发展，然后描述LLMs在机器人领域的利点和最新的机器人模型的发展。然后，我们介绍了使用在模型中的各种技术，包括在观察、决策、控制和交互中使用的技术。最后，我们探讨了LLMs在机器人领域的应用和未来可能面临的挑战。聚合智能是未来智能科学的未来，LLMs-based robotics 是一条擅长但挑战性的道路。
</details></li>
</ul>
<hr>
<h2 id="Optical-Quantum-Sensing-for-Agnostic-Environments-via-Deep-Learning"><a href="#Optical-Quantum-Sensing-for-Agnostic-Environments-via-Deep-Learning" class="headerlink" title="Optical Quantum Sensing for Agnostic Environments via Deep Learning"></a>Optical Quantum Sensing for Agnostic Environments via Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07203">http://arxiv.org/abs/2311.07203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeqiao Zhou, Yuxuan Du, Xu-Fei Yin, Shanshan Zhao, Xinmei Tian, Dacheng Tao</li>
<li>for: 这 paper 的目的是提高光学量子探测的精度，并在不知情环境中实现 Heisenberg 限制。</li>
<li>methods: 该 paper 使用了深度学习技术，包括图 neural network 预测器和 trigonometric  interpolating 算法，以实现光学量子探测的高精度。</li>
<li>results:  experiments 表明，该方法可以在不同的设置下达到高精度水平，并且可以在 eight  photons 下实现最大的 quantum Fisher information。<details>
<summary>Abstract</summary>
Optical quantum sensing promises measurement precision beyond classical sensors termed the Heisenberg limit (HL). However, conventional methodologies often rely on prior knowledge of the target system to achieve HL, presenting challenges in practical applications. Addressing this limitation, we introduce an innovative Deep Learning-based Quantum Sensing scheme (DQS), enabling optical quantum sensors to attain HL in agnostic environments. DQS incorporates two essential components: a Graph Neural Network (GNN) predictor and a trigonometric interpolation algorithm. Operating within a data-driven paradigm, DQS utilizes the GNN predictor, trained on offline data, to unveil the intrinsic relationships between the optical setups employed in preparing the probe state and the resulting quantum Fisher information (QFI) after interaction with the agnostic environment. This distilled knowledge facilitates the identification of optimal optical setups associated with maximal QFI. Subsequently, DQS employs a trigonometric interpolation algorithm to recover the unknown parameter estimates for the identified optical setups. Extensive experiments are conducted to investigate the performance of DQS under different settings up to eight photons. Our findings not only offer a new lens through which to accelerate optical quantum sensing tasks but also catalyze future research integrating deep learning and quantum mechanics.
</details>
<details>
<summary>摘要</summary>
DQS consists of two essential components: a graph neural network (GNN) predictor and a trigonometric interpolation algorithm. The GNN predictor is trained on offline data to reveal the intrinsic relationships between the optical setups used to prepare the probe state and the resulting quantum Fisher information (QFI) after interaction with the agnostic environment. This distilled knowledge allows for the identification of optimal optical setups associated with maximal QFI.Subsequently, DQS employs a trigonometric interpolation algorithm to recover the unknown parameter estimates for the identified optical setups. We conduct extensive experiments to investigate the performance of DQS under different settings, including up to eight photons. Our findings not only offer a new approach to accelerate optical quantum sensing tasks but also pave the way for future research integrating deep learning and quantum mechanics.
</details></li>
</ul>
<hr>
<h2 id="Applying-Large-Language-Models-for-Causal-Structure-Learning-in-Non-Small-Cell-Lung-Cancer"><a href="#Applying-Large-Language-Models-for-Causal-Structure-Learning-in-Non-Small-Cell-Lung-Cancer" class="headerlink" title="Applying Large Language Models for Causal Structure Learning in Non Small Cell Lung Cancer"></a>Applying Large Language Models for Causal Structure Learning in Non Small Cell Lung Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07191">http://arxiv.org/abs/2311.07191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narmada Naik, Ayush Khandelwal, Mohit Joshi, Madhusudan Atre, Hollis Wright, Kavya Kannan, Scott Hill, Giridhar Mamidipudi, Ganapati Srinivasa, Carlo Bifulco, Brian Piening, Kevin Matlock</li>
<li>for: 这 paper 是为了研究使用 Large Language Models (LLMs) 来解决 causal discovery 中的 edge 方向性问题。</li>
<li>methods: 这 paper 使用了 LLMs 来预测 causal graph 中 edge 的方向性，并对比了现有的状态 искусственного智能方法。</li>
<li>results: 结果显示，LLMs 可以准确预测 causal graph 中 edge 的方向性，并且表现出色于现有的状态 искусственный智能方法。<details>
<summary>Abstract</summary>
Causal discovery is becoming a key part in medical AI research. These methods can enhance healthcare by identifying causal links between biomarkers, demographics, treatments and outcomes. They can aid medical professionals in choosing more impactful treatments and strategies. In parallel, Large Language Models (LLMs) have shown great potential in identifying patterns and generating insights from text data. In this paper we investigate applying LLMs to the problem of determining the directionality of edges in causal discovery. Specifically, we test our approach on a deidentified set of Non Small Cell Lung Cancer(NSCLC) patients that have both electronic health record and genomic panel data. Graphs are validated using Bayesian Dirichlet estimators using tabular data. Our result shows that LLMs can accurately predict the directionality of edges in causal graphs, outperforming existing state-of-the-art methods. These findings suggests that LLMs can play a significant role in advancing causal discovery and help us better understand complex systems.
</details>
<details>
<summary>摘要</summary>
隐含推理是医疗人工智能研究中越来越重要的一部分。这些方法可以增强医疗效果，通过找到生物标志物、人口、治疗和结果之间的 causal 连接。它们可以帮助医疗专业人员选择更有效的治疗和策略。在这篇论文中，我们调查了应用 Large Language Models（LLMs）来确定 causal 推理中的Edge方向。我们在一个医疗记录和 genomic 数据集上进行了测试，并使用 bayesian Dirichlet estimator 验证图表。我们的结果表明，LLMs 可以准确预测 causal 图中的 Edge 方向，超过现有的状态艺技术。这些发现建议 LLMs 可以在 causal 推理中发挥重要作用，帮助我们更好地理解复杂系统。
</details></li>
</ul>
<hr>
<h2 id="Cross-Axis-Transformer-with-2D-Rotary-Embeddings"><a href="#Cross-Axis-Transformer-with-2D-Rotary-Embeddings" class="headerlink" title="Cross-Axis Transformer with 2D Rotary Embeddings"></a>Cross-Axis Transformer with 2D Rotary Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07184">http://arxiv.org/abs/2311.07184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lily Erickson</li>
<li>for: 这篇论文是为了解决计算效率低下，模式缺乏适应性的视觉转换器问题而写的。</li>
<li>methods: 该论文提出了一种基于 Axial Transformers 和 Microsoft 的 Retentive Network 的模型，称为 Cross-Axis Transformer (CAT)，可以减少处理图像所需的浮点运算数量，同时更快速地达到更高准确性。</li>
<li>results: CAT 模型在比较 Vision Transformers 的情况下，可以更快速地训练，并且在图像处理任务上表现更高准确性。<details>
<summary>Abstract</summary>
Despite lagging behind their modal cousins in many respects, Vision Transformers have provided an interesting opportunity to bridge the gap between sequence modeling and image modeling. Up until now however, vision transformers have largely been held back, due to both computational inefficiency, and lack of proper handling of spatial dimensions. In this paper, we introduce the Cross-Axis Transformer. CAT is a model inspired by both Axial Transformers, and Microsoft's recent Retentive Network, that drastically reduces the required number of floating point operations required to process an image, while simultaneously converging faster and more accurately than the Vision Transformers it replaces.
</details>
<details>
<summary>摘要</summary>
尽管模型 cousin 在多种方面落后，视觉 трансформа器仍提供了将序列模型和图像模型桥接的有趣机会。然而，视觉 трансформа器 hasta 现在都受到了计算效率不足和空间维度处理不当的限制。在这篇论文中，我们介绍了横轴 transformer（CAT）。CAT 是基于 Axial Transformers 和 Microsof 的Recent Retentive Network的模型，可以减少处理图像所需的浮点运算数量，同时 convergence faster 和更准确地 than Vision Transformers。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Graph-Representations-to-enhance-Intensive-Care-Time-Series-Predictions"><a href="#Knowledge-Graph-Representations-to-enhance-Intensive-Care-Time-Series-Predictions" class="headerlink" title="Knowledge Graph Representations to enhance Intensive Care Time-Series Predictions"></a>Knowledge Graph Representations to enhance Intensive Care Time-Series Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07180">http://arxiv.org/abs/2311.07180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samyak Jain, Manuel Burger, Gunnar Rätsch, Rita Kuznetsova</li>
<li>for: 增强Intensive Care Units（ICU）的临床结果预测，需要全面的病人数据集成。</li>
<li>methods: 使用悬崖学进步，将病人时间序列数据和不结构化医疗报告 integrate，提高预测性能。</li>
<li>results: 结合医疗领域的数据，使用知识图 Derived from clinical ontologies like the Unified Medical Language System (UMLS)，提高临床决策模型。 组合图表示与生命 Parameters和临床报告，提高性能，尤其是数据缺失时。 此外，我们的模型还包括可解释组件，以便理解知识图节点如何影响预测。<details>
<summary>Abstract</summary>
Intensive Care Units (ICU) require comprehensive patient data integration for enhanced clinical outcome predictions, crucial for assessing patient conditions. Recent deep learning advances have utilized patient time series data, and fusion models have incorporated unstructured clinical reports, improving predictive performance. However, integrating established medical knowledge into these models has not yet been explored. The medical domain's data, rich in structural relationships, can be harnessed through knowledge graphs derived from clinical ontologies like the Unified Medical Language System (UMLS) for better predictions. Our proposed methodology integrates this knowledge with ICU data, improving clinical decision modeling. It combines graph representations with vital signs and clinical reports, enhancing performance, especially when data is missing. Additionally, our model includes an interpretability component to understand how knowledge graph nodes affect predictions.
</details>
<details>
<summary>摘要</summary>
医院床位加护部 (ICU) 需要全面的患者数据集成以提高临床结果预测，这是评估患者状况的关键。最近的深度学习突破使用了患者时间序数据，并将不结构化的医疗报告 fusion 到模型中，以提高预测性能。但是，将成熔的医疗领域数据（rich in structural relationships）integrated into these models has not yet been explored。我们的提议的方法是通过临床 ontology 如 Unified Medical Language System (UMLS)  derivation 的知识图来捕捉医疗领域的数据，从而提高临床决策模型。这种方法结合了图表示法和生命 parameter 和临床报告，以提高性能，特别是在数据缺失时。此外，我们的模型还包括一个可解释性组件，以便理解知识图节点如何影响预测。
</details></li>
</ul>
<hr>
<h2 id="Game-Solving-with-Online-Fine-Tuning"><a href="#Game-Solving-with-Online-Fine-Tuning" class="headerlink" title="Game Solving with Online Fine-Tuning"></a>Game Solving with Online Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07178">http://arxiv.org/abs/2311.07178</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rlglab/online-fine-tuning-solver">https://github.com/rlglab/online-fine-tuning-solver</a></li>
<li>paper_authors: Ti-Rong Wu, Hung Guei, Ting Han Wei, Chung-Chin Shih, Jui-Te Chin, I-Chen Wu</li>
<li>for:  solves challenging 7x7 Killall-Go problems with online fine-tuning, using less computation time than traditional methods.</li>
<li>methods:  applies online fine-tuning and proposes two tailor-designed heuristics for game solving.</li>
<li>results:  solves a series of challenging 7x7 Killall-Go problems with 23.54% less computation time compared to the baseline, and the savings scale with problem size.<details>
<summary>Abstract</summary>
Game solving is a similar, yet more difficult task than mastering a game. Solving a game typically means to find the game-theoretic value (outcome given optimal play), and optionally a full strategy to follow in order to achieve that outcome. The AlphaZero algorithm has demonstrated super-human level play, and its powerful policy and value predictions have also served as heuristics in game solving. However, to solve a game and obtain a full strategy, a winning response must be found for all possible moves by the losing player. This includes very poor lines of play from the losing side, for which the AlphaZero self-play process will not encounter. AlphaZero-based heuristics can be highly inaccurate when evaluating these out-of-distribution positions, which occur throughout the entire search. To address this issue, this paper investigates applying online fine-tuning while searching and proposes two methods to learn tailor-designed heuristics for game solving. Our experiments show that using online fine-tuning can solve a series of challenging 7x7 Killall-Go problems, using only 23.54% of computation time compared to the baseline without online fine-tuning. Results suggest that the savings scale with problem size. Our method can further be extended to any tree search algorithm for problem solving. Our code is available at https://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver.
</details>
<details>
<summary>摘要</summary>
GAME解释是一种类似 yet更加困难的任务，即找到游戏中的游戏理论价值（基于最优游戏策略），并可选择一个全局策略以实现该结果。AlphaZero算法已经展示出了超人类水平的游戏表现，并且其强大的策略和价值预测也可以作为游戏解释的依据。然而，为了解决游戏并获得全局策略，需要找到对游戏中落后一方的所有移动都有赢的回应。这包括落后一方的很差游戏行为，AlphaZero自动游戏过程中不会遇到这些位置。AlphaZero基于的依据可能在这些 OUT-OF-distribution 位置上高度不准确，这些位置在搜索中occurs throughout the entire search。为解决这个问题，这篇文章提出了在搜索过程中进行在线细化的方法，并提出了两种学习特定的依据来解决游戏。我们的实验表明，使用在线细化可以解决一系列复杂的 7x7 Killall-Go 问题，使用了23.54%的计算时间，相比无在线细化基eline。结果表明，这些节省可以扩大到问题的大小。我们的方法可以进一步扩展到任何树搜索算法来解决问题。我们的代码可以在 <https://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver> 中找到。
</details></li>
</ul>
<hr>
<h2 id="The-High-dimensional-Phase-Diagram-and-the-Large-CALPHAD-Model"><a href="#The-High-dimensional-Phase-Diagram-and-the-Large-CALPHAD-Model" class="headerlink" title="The High-dimensional Phase Diagram and the Large CALPHAD Model"></a>The High-dimensional Phase Diagram and the Large CALPHAD Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07174">http://arxiv.org/abs/2311.07174</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengdi Liu, Xulong An, Wenwen Sun</li>
<li>for: 针对多元素合金系统中的复杂性问题，我们在FeNiCrMn合金系统中引入了大型CALPHAD模型（LCM），以计算所有可能的相态空间。</li>
<li>methods: 我们使用了高维度相态图和哈希表+深度优先搜索（DFS）等方法，系统地结构化了巨量数据，并实现了97%的分类精度和4.80*10^-5的平均方差。</li>
<li>results: 我们成功划分了FeNiCrMn合金系统中的51个独特相态空间，并示例了该方法可用于设计所有439种冷峰合金。这种新的方法将对合金设计技术和多变量问题产生巨大的影响。<details>
<summary>Abstract</summary>
When alloy systems comprise more than three elements, the visualization of the entire phase space becomes not only daunting but is also accompanied by a data surge. Addressing this complexity, we delve into the FeNiCrMn alloy system and introduce the Large CALPHAD Model (LCM). The LCM acts as a computational conduit, capturing the entire phase space. Subsequently, this enormous data is systematically structured using a high-dimensional phase diagram, aided by hash tables and Depth-first Search (DFS), rendering it both digestible and programmatically accessible. Remarkably, the LCM boasts a 97% classification accuracy and a mean square error of 4.80*10-5 in phase volume prediction. Our methodology successfully delineates 51 unique phase spaces in the FeNiCrMn system, exemplifying its efficacy with the design of all 439 eutectic alloys. This pioneering methodology signifies a monumental shift in alloy design techniques or even multi-variable problems.
</details>
<details>
<summary>摘要</summary>
Using high-dimensional phase diagrams, hash tables, and Depth-first Search (DFS), we are able to structure the data in a way that is both digestible and programmatically accessible. Remarkably, the LCM has a 97% classification accuracy and a mean square error of 4.80*10-5 in phase volume prediction.Our methodology successfully delineates 51 unique phase spaces in the FeNiCrMn system, demonstrating its effectiveness in designing all 439 eutectic alloys. This groundbreaking approach represents a significant shift in alloy design techniques and multi-variable problem-solving.
</details></li>
</ul>
<hr>
<h2 id="STEER-Unified-Style-Transfer-with-Expert-Reinforcement"><a href="#STEER-Unified-Style-Transfer-with-Expert-Reinforcement" class="headerlink" title="STEER: Unified Style Transfer with Expert Reinforcement"></a>STEER: Unified Style Transfer with Expert Reinforcement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07167">http://arxiv.org/abs/2311.07167</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skyler Hallinan, Faeze Brahman, Ximing Lu, Jaehun Jung, Sean Welleck, Yejin Choi</li>
<li>for: 本文主要针对的问题是如何实现文本Style Transfer，即将文本从一个未知的源风格转换到一个目标风格中。</li>
<li>methods: 我们提出了STEER：一种基于专家强化的统一框架，通过自动生成样式转移对的数据集来解决限制了并行数据的问题。STEER使用了在解码过程中自动生成的产品专家来生成样式转移对的数据集，然后使用这些数据集来预训练初始策略，然后使用在线、离线的强化学习来进一步改进。</li>
<li>results: 我们在一个复杂的数据集上进行了实验，与竞争对手比较，得到了最佳的结果。尤其是，STEER在总样式转移质量方面比175B参数的指定调节GPT-3高，即使其只有226倍小于GPT-3。此外，我们还证明了STEER在不同风格的数据上保持了样式转移能力，并在多种风格下超越了大多数基准值。<details>
<summary>Abstract</summary>
While text style transfer has many applications across natural language processing, the core premise of transferring from a single source style is unrealistic in a real-world setting. In this work, we focus on arbitrary style transfer: rewriting a text from an arbitrary, unknown style to a target style.   We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified frame-work developed to overcome the challenge of limited parallel data for style transfer. STEER involves automatically generating a corpus of style-transfer pairs using a product of experts during decoding. The generated offline data is then used to pre-train an initial policy before switching to online, off-policy reinforcement learning for further improvements via fine-grained reward signals. STEER is unified and can transfer to multiple target styles from an arbitrary, unknown source style, making it particularly flexible and efficient.   Experimental results on a challenging dataset with text from a diverse set of styles demonstrate state-of-the-art results compared to competitive baselines. Remarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on overall style transfer quality, despite being 226 times smaller in size. We also show STEER is robust, maintaining its style transfer capabilities on out-of-domain data, and surpassing nearly all baselines across various styles. The success of our method highlights the potential of RL algorithms when augmented with controllable decoding to overcome the challenge of limited data supervision.
</details>
<details>
<summary>摘要</summary>
While 文本样式传递有很多应用于自然语言处理领域，核心假设从单个来源样式传递是在实际世界中不切实际的。在这项工作中，我们关注于 произвольные样式传递：将文本从未知样式转换到目标样式。我们提出了STEER：一种综合框架，通过专家激励来超越有限平行数据的限制。STEER通过在解码过程中自动生成样式传递对的自动生成器来生成偏好的样式传递对。然后，使用先进的策略进行在线、离线权重学习，以进一步改进精细的奖励信号。STEER可以同时转换多种目标样式，从未知样式中转换，使其特icularly 灵活和高效。我们的实验结果表明，STEER在一个复杂的数据集上达到了现状最佳的效果，比基elines表现出色。尤其是，STEER在 parameter 175B 的 GPT-3 上进行了 instruction-tuned 的实验，而且在总体样式传递质量方面表现出了优于基elines。此外，我们还证明了STEER在域外数据上保持了样式传递能力，并在不同的样式下超越了大部分基elines。这一成功表明了RL算法在加入可控的解码后可以超越有限数据指导的挑战。
</details></li>
</ul>
<hr>
<h2 id="Pruning-random-resistive-memory-for-optimizing-analogue-AI"><a href="#Pruning-random-resistive-memory-for-optimizing-analogue-AI" class="headerlink" title="Pruning random resistive memory for optimizing analogue AI"></a>Pruning random resistive memory for optimizing analogue AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07164">http://arxiv.org/abs/2311.07164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Li, Songqi Wang, Yaping Zhao, Shaocong Wang, Woyu Zhang, Yangu He, Ning Lin, Binbin Cui, Xi Chen, Shiming Zhang, Hao Jiang, Peng Lin, Xumeng Zhang, Xiaojuan Qi, Zhongrui Wang, Xiaoxin Xu, Dashan Shang, Qi Liu, Kwang-Ting Cheng, Ming Liu<br>for: 这篇论文旨在解决人工智能（AI）的能源消耗和环境可持续性问题，通过恢复 аналогов计算。methods: 该论文使用了软件硬件协同设计，结合结构塑性激活边缘剪裁来优化 randomly weighted 分布式 resistive memory neural network 的 topology。results: 该论文在 FashionMNIST、Spoken digits 和 DRIVE 数据集上实现了17.3%、19.9% 和 9.8% 的准确率提升，同时实现了 82.1%、51.2% 和 99.8% 的能效率提升。<details>
<summary>Abstract</summary>
The rapid advancement of artificial intelligence (AI) has been marked by the large language models exhibiting human-like intelligence. However, these models also present unprecedented challenges to energy consumption and environmental sustainability. One promising solution is to revisit analogue computing, a technique that predates digital computing and exploits emerging analogue electronic devices, such as resistive memory, which features in-memory computing, high scalability, and nonvolatility. However, analogue computing still faces the same challenges as before: programming nonidealities and expensive programming due to the underlying devices physics. Here, we report a universal solution, software-hardware co-design using structural plasticity-inspired edge pruning to optimize the topology of a randomly weighted analogue resistive memory neural network. Software-wise, the topology of a randomly weighted neural network is optimized by pruning connections rather than precisely tuning resistive memory weights. Hardware-wise, we reveal the physical origin of the programming stochasticity using transmission electron microscopy, which is leveraged for large-scale and low-cost implementation of an overparameterized random neural network containing high-performance sub-networks. We implemented the co-design on a 40nm 256K resistive memory macro, observing 17.3% and 19.9% accuracy improvements in image and audio classification on FashionMNIST and Spoken digits datasets, as well as 9.8% (2%) improvement in PR (ROC) in image segmentation on DRIVE datasets, respectively. This is accompanied by 82.1%, 51.2%, and 99.8% improvement in energy efficiency thanks to analogue in-memory computing. By embracing the intrinsic stochasticity and in-memory computing, this work may solve the biggest obstacle of analogue computing systems and thus unleash their immense potential for next-generation AI hardware.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）的快速发展已经由大型语言模型展示了人类智能水平。然而，这些模型也带来了前所未有的能源消耗和环境可持续性挑战。一种有前途的解决方案是探索Analog computing，这是数字计算的前代技术，它利用新型的Analog电子设备，如抗抗压记忆，实现了内存计算、扩展性和不朽性。然而，Analog计算仍面临以下挑战：编程不 ideal和开销较高。在这里，我们报告了一种通用解决方案：软硬件协同设计，使用结构塑性-灵感导向的边缘剔除来优化Randomly weighted Analog resistive memory neural network的topology。软件端，通过剔除连接而不是精准地调整抗抗压记忆权重来优化Randomly weighted neural network的topology。硬件端，我们通过电子显微镜探测到了设备物理的编程随机性的 физи学起源，并利用这一发现实现了大规模、低成本的实现一个高性能的随机神经网络，包括高性能的子网络。我们在40nm 256K抗抗压记忆macro上实现了该协同设计，在FashionMNIST和Spoken digits datasets上观察到了图像和音频分类的准确率提高17.3%和19.9%，以及图像分割任务中的PR（ROC）提高9.8%（2%）。此外，我们还观察到了82.1%、51.2%和99.8%的能效提升。通过拥抱内在的随机性和内存计算，这种工作可能解决了Analog计算系统中最大的障碍，从而释放了这些系统的巨大潜力，用于下一代AI硬件。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Lightweight-Neural-Networks-for-Small-Object-Detection-in-IoT-Applications"><a href="#Enhancing-Lightweight-Neural-Networks-for-Small-Object-Detection-in-IoT-Applications" class="headerlink" title="Enhancing Lightweight Neural Networks for Small Object Detection in IoT Applications"></a>Enhancing Lightweight Neural Networks for Small Object Detection in IoT Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07163">http://arxiv.org/abs/2311.07163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liam Boyle, Nicolas Baumann, Seonyeong Heo, Michele Magno</li>
<li>for: 提高小物体检测精度并适用于嵌入式设备</li>
<li>methods: 提出了一种适用于任何现有物体检测器的适应划分方法，包括FOMO网络</li>
<li>results: 实验结果表明，该方法可以提高F1分数达225%，同时降低平均物体计数错误达76%，并且表明使用软F1损失可以有效降低不均衡数据的负面影响。<details>
<summary>Abstract</summary>
Advances in lightweight neural networks have revolutionized computer vision in a broad range of IoT applications, encompassing remote monitoring and process automation. However, the detection of small objects, which is crucial for many of these applications, remains an underexplored area in current computer vision research, particularly for embedded devices. To address this gap, the paper proposes a novel adaptive tiling method that can be used on top of any existing object detector including the popular FOMO network for object detection on microcontrollers. Our experimental results show that the proposed tiling method can boost the F1-score by up to 225% while reducing the average object count error by up to 76%. Furthermore, the findings of this work suggest that using a soft F1 loss over the popular binary cross-entropy loss can significantly reduce the negative impact of imbalanced data. Finally, we validate our approach by conducting experiments on the Sony Spresense microcontroller, showcasing the proposed method's ability to strike a balance between detection performance, low latency, and minimal memory consumption.
</details>
<details>
<summary>摘要</summary>
新型轻量级神经网络的进步已经对互联网器件应用领域的计算机视觉领域进行了革命性的改变，涵盖远程监测和流程自动化。然而，对小对象的探测，这是现有计算机视觉研究中尚未得到充分研究的领域，特别是在嵌入式设备上。为了解决这个差距，该篇论文提出了一种新的适应分割方法，可以在现有的对象探测器之上使用，包括受欢迎的FOMO网络。我们的实验结果表明，提议的分割方法可以提高F1分数的最大提升为225%，并同时降低平均对象计数错误的最大降低为76%。此外，我们的研究发现，使用软F1损失函数相比于popular binary cross-entropy损失函数可以significantly reduce the negative impact of imbalanced data。最后，我们验证了我们的方法，通过在Sony Spresense微控制器上进行实验，示出了我们的方法可以在探测性能、延迟时间和内存占用量之间做出平衡。
</details></li>
</ul>
<hr>
<h2 id="Interaction-is-all-You-Need-A-Study-of-Robots-Ability-to-Understand-and-Execute"><a href="#Interaction-is-all-You-Need-A-Study-of-Robots-Ability-to-Understand-and-Execute" class="headerlink" title="Interaction is all You Need? A Study of Robots Ability to Understand and Execute"></a>Interaction is all You Need? A Study of Robots Ability to Understand and Execute</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07150">http://arxiv.org/abs/2311.07150</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nid989/teach_edh">https://github.com/nid989/teach_edh</a></li>
<li>paper_authors: Kushal Koshti, Nidhir Bhavsar</li>
<li>for: 本研究旨在帮助机器人在人类环境中自然语言互动下进行高效的任务解决，具体来说是帮助机器人理解和执行复杂的指令在连续对话中解决复杂任务。</li>
<li>methods: 我们基于执行对话历史（EDH）任务从教学标准底采用多变换器模型和BARTLM。我们发现我们最佳配置在基准点上出现了8.85的成功率和14.02的目标相关成功率。此外，我们还提出了一种新的完成这个任务的方法。</li>
<li>results: 我们评估了多个BART模型和LLaMA2 LLMC，其中LLaMA2 LLMC在这个任务上达到了46.77的ROGUE-L分数。<details>
<summary>Abstract</summary>
This paper aims to address a critical challenge in robotics, which is enabling them to operate seamlessly in human environments through natural language interactions. Our primary focus is to equip robots with the ability to understand and execute complex instructions in coherent dialogs to facilitate intricate task-solving scenarios. To explore this, we build upon the Execution from Dialog History (EDH) task from the Teach benchmark. We employ a multi-transformer model with BART LM. We observe that our best configuration outperforms the baseline with a success rate score of 8.85 and a goal-conditioned success rate score of 14.02. In addition, we suggest an alternative methodology for completing this task. Moreover, we introduce a new task by expanding the EDH task and making predictions about game plans instead of individual actions. We have evaluated multiple BART models and an LLaMA2 LLM, which has achieved a ROGUE-L score of 46.77 for this task.
</details>
<details>
<summary>摘要</summary>
Note:* "Teach benchmark" refers to a standardized evaluation framework for natural language understanding and execution in robotics.* "EDH task" stands for "Execution from Dialog History" task, which involves understanding and executing complex instructions given in a coherent dialogue.* "BART LM" refers to a type of language model called Bayesian Artificial Robot Teacher, which is a machine learning model used for natural language understanding and generation.* "ROGUE-L" is a score used to evaluate the performance of language models in task-oriented dialogues, with higher scores indicating better performance.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-and-Predicting-Low-Listenership-Trends-in-a-Large-Scale-Mobile-Health-Program-A-Preliminary-Investigation"><a href="#Analyzing-and-Predicting-Low-Listenership-Trends-in-a-Large-Scale-Mobile-Health-Program-A-Preliminary-Investigation" class="headerlink" title="Analyzing and Predicting Low-Listenership Trends in a Large-Scale Mobile Health Program: A Preliminary Investigation"></a>Analyzing and Predicting Low-Listenership Trends in a Large-Scale Mobile Health Program: A Preliminary Investigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07139">http://arxiv.org/abs/2311.07139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arshika Lalan, Shresth Verma, Kumar Madhu Sudan, Amrita Mahale, Aparna Hegde, Milind Tambe, Aparna Taneja</li>
<li>for: 这项研究是为了分析 Kilkari 移动医疗计划的使用者行为，并提出改进方案以增强该项目的效果。</li>
<li>methods: 研究使用时间序列预测分析 Beneficiary 的dropout行为，并将结果应用于NGO 的滥耗预测和滥耗预防策略。</li>
<li>results: 研究发现，通过分析 Beneficiary 的 listened pattern，可以帮助NGO 更好地了解 Beneficiary 的需求，并采取时间序列预测的方法可以预测 Beneficiary 的dropout。<details>
<summary>Abstract</summary>
Mobile health programs are becoming an increasingly popular medium for dissemination of health information among beneficiaries in less privileged communities. Kilkari is one of the world's largest mobile health programs which delivers time sensitive audio-messages to pregnant women and new mothers. We have been collaborating with ARMMAN, a non-profit in India which operates the Kilkari program, to identify bottlenecks to improve the efficiency of the program. In particular, we provide an initial analysis of the trajectories of beneficiaries' interaction with the mHealth program and examine elements of the program that can be potentially enhanced to boost its success. We cluster the cohort into different buckets based on listenership so as to analyze listenership patterns for each group that could help boost program success. We also demonstrate preliminary results on using historical data in a time-series prediction to identify beneficiary dropouts and enable NGOs in devising timely interventions to strengthen beneficiary retention.
</details>
<details>
<summary>摘要</summary>
移动卫生计划在贫困社区中普遍用于卫生信息的传递。基尔卡莉是世界上最大的移动卫生计划之一，它通过发送时敏感的音频消息，为怀孕妈妈和新生妈妈提供卫生信息。我们与印度非营利组织ARMMAN合作，以便识别项目中的瓶颈，并提高项目的效率。我们对参与者的行为轨迹进行了初步分析，并分析每个组的听众模式，以帮助提高项目的成功。我们还采用历史数据时序预测，以预测受助者退出，并帮助非政府组织制定时间性的干预措施，以增强受助者的保留。
</details></li>
</ul>
<hr>
<h2 id="WaterBench-Towards-Holistic-Evaluation-of-Watermarks-for-Large-Language-Models"><a href="#WaterBench-Towards-Holistic-Evaluation-of-Watermarks-for-Large-Language-Models" class="headerlink" title="WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models"></a>WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07138">http://arxiv.org/abs/2311.07138</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/THU-KEG/WaterBench">https://github.com/THU-KEG/WaterBench</a></li>
<li>paper_authors: Shangqing Tu, Yuliang Sun, Yushi Bai, Jifan Yu, Lei Hou, Juanzi Li</li>
<li>For: 本研究旨在 evaluating the effectiveness of large language model (LLM) watermarking algorithms, and providing a comprehensive benchmark for these algorithms.* Methods: 本研究使用了 four open-source watermarks on two LLMs under two watermarking strengths, and evaluates the generation and detection performance of these watermarks using a five-category taxonomy of tasks.* Results: 研究发现 current LLM watermarking algorithms 面临着 maintaining generation quality 的挑战，并且 observe 了 these algorithms’ decline in instruction-following abilities after watermarking.<details>
<summary>Abstract</summary>
To mitigate the potential misuse of large language models (LLMs), recent research has developed watermarking algorithms, which restrict the generation process to leave an invisible trace for watermark detection. Due to the two-stage nature of the task, most studies evaluate the generation and detection separately, thereby presenting a challenge in unbiased, thorough, and applicable evaluations. In this paper, we introduce WaterBench, the first comprehensive benchmark for LLM watermarks, in which we design three crucial factors: (1) For \textbf{benchmarking procedure}, to ensure an apples-to-apples comparison, we first adjust each watermarking method's hyper-parameter to reach the same watermarking strength, then jointly evaluate their generation and detection performance. (2) For \textbf{task selection}, we diversify the input and output length to form a five-category taxonomy, covering $9$ tasks. (3) For \textbf{evaluation metric}, we adopt the GPT4-Judge for automatically evaluating the decline of instruction-following abilities after watermarking. We evaluate $4$ open-source watermarks on $2$ LLMs under $2$ watermarking strengths and observe the common struggles for current methods on maintaining the generation quality. The code and data are available at \url{https://github.com/THU-KEG/WaterBench}.
</details>
<details>
<summary>摘要</summary>
为了遏制大语言模型（LLM）的潜在违用，latest research 已经开发出水印算法，以限制生成过程，留下隐藏的水印检测。由于这是一个两 stage 的任务， większe studies 通常分开评估生成和检测，从而带来一个挑战：做出不偏袋化、全面和实用的评估。在这篇论文中，我们介绍 WaterBench，第一个对 LLM 水印的完整Benchmark，其中我们设计了三个关键因素：1. 对于 benchmarking 过程，以确保比较公平，我们首先调整每种水印方法的超参数，使其达到同等的水印强度，然后并行评估其生成和检测性能。2. 对于任务选择，我们将输入和输出长度 diversify 到组成五类分类，涵盖了9个任务。3. 对于评估 metric，我们采用 GPT4-Judge 自动评估水印后 instrucions 的退化程度。我们对两种 LL 进行了两种水印强度的评估，并观察到当前方法在保持生成质量方面的普遍困难。代码和数据可以在 <https://github.com/THU-KEG/WaterBench> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Path-Planning-Explanations"><a href="#Understanding-Path-Planning-Explanations" class="headerlink" title="Understanding Path Planning Explanations"></a>Understanding Path Planning Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07132">http://arxiv.org/abs/2311.07132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Amar Halilovic, Senka Krivic</li>
<li>for: 本研究旨在解释移动机器人的导航决策。</li>
<li>methods: 我们提出了一种使用视觉和文本解释来解释机器人的导航决策。</li>
<li>results: 我们计划通过用户研究测试机器人的解释的理解性和简洁性，并启动未来研究计划。<details>
<summary>Abstract</summary>
Navigation is a must-have skill for any mobile robot. A core challenge in navigation is the need to account for an ample number of possible configurations of environment and navigation contexts. We claim that a mobile robot should be able to explain its navigational choices making its decisions understandable to humans. In this paper, we briefly present our approach to explaining navigational decisions of a robot through visual and textual explanations. We propose a user study to test the understandability and simplicity of the robot explanations and outline our further research agenda.
</details>
<details>
<summary>摘要</summary>
Navigation 是移动机器人必备的技能之一。核心挑战在于需要考虑多种环境配置和导航上下文。我们认为移动机器人应该能够解释其导航选择，使其决策能够被人类理解。在这篇论文中，我们简要介绍了我们如何通过视觉和文本解释来解释机器人的导航选择。我们提出了用户研究，以测试机器人解释的理解度和简洁度，并述出我们未来研究论点。Note: "Simplified Chinese" refers to the standardized form of Chinese used in mainland China and Singapore, which is different from "Traditional Chinese" used in Hong Kong, Taiwan, and other countries.
</details></li>
</ul>
<hr>
<h2 id="Untargeted-Black-box-Attacks-for-Social-Recommendations"><a href="#Untargeted-Black-box-Attacks-for-Social-Recommendations" class="headerlink" title="Untargeted Black-box Attacks for Social Recommendations"></a>Untargeted Black-box Attacks for Social Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07127">http://arxiv.org/abs/2311.07127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqi Fan, Shijie Wang, Xiao-yong Wei, Xiaowei Mei, Qing Li</li>
<li>for: 这研究旨在攻击社交推荐系统，即使在黑盒模式下。</li>
<li>methods: 该研究提出了一种基于多代理学习的攻击框架，即 Multiattack，以协调生成冷启动ITEM的 Profil和跨社区社交关系，以对黑盒社交推荐系统进行无目标攻击。</li>
<li>results: 对多个实际数据集进行了广泛的实验，证明了我们的提出的攻击框架在黑盒模式下的效果。<details>
<summary>Abstract</summary>
The rise of online social networks has facilitated the evolution of social recommender systems, which incorporate social relations to enhance users' decision-making process. With the great success of Graph Neural Networks in learning node representations, GNN-based social recommendations have been widely studied to model user-item interactions and user-user social relations simultaneously. Despite their great successes, recent studies have shown that these advanced recommender systems are highly vulnerable to adversarial attacks, in which attackers can inject well-designed fake user profiles to disrupt recommendation performances. While most existing studies mainly focus on targeted attacks to promote target items on vanilla recommender systems, untargeted attacks to degrade the overall prediction performance are less explored on social recommendations under a black-box scenario. To perform untargeted attacks on social recommender systems, attackers can construct malicious social relationships for fake users to enhance the attack performance. However, the coordination of social relations and item profiles is challenging for attacking black-box social recommendations. To address this limitation, we first conduct several preliminary studies to demonstrate the effectiveness of cross-community connections and cold-start items in degrading recommendations performance. Specifically, we propose a novel framework Multiattack based on multi-agent reinforcement learning to coordinate the generation of cold-start item profiles and cross-community social relations for conducting untargeted attacks on black-box social recommendations. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of our proposed attacking framework under the black-box setting.
</details>
<details>
<summary>摘要</summary>
“在线社交网络的兴起，促进了社交推荐系统的进化，这些系统将社交关系纳入用户决策过程中。基于图神经网络的社交推荐系统在学习用户-项目交互和用户-用户社交关系方面取得了很大成功。然而，最新的研究表明，这些高级推荐系统在黑盒enario下面临恶意攻击时表现很脆弱，攻击者可以通过构建高效的假用户 profilesto破坏推荐性能。大多数现有研究主要关注于targeted攻击，即通过推荐特定item来提高推荐性能。然而，针对黑盒社交推荐系统的untargeted攻击，即通过破坏总体推荐性能来引起攻击者的注意，尚未得到充分研究。为了解决这一限制，我们首先进行了一些预liminary研究，以证明横向社交关系和冷启用户 profilestable 在黑盒setting下的攻击性能的有效性。然后，我们提出了一个名为Multiattack的攻击框架，该框架基于多代理权重学习协调冷启item profil和横向社交关系的生成，以实现黑盒社交推荐系统的untargeted攻击。我们在各种实际数据集上进行了广泛的实验，证明了我们提出的攻击框架在黑盒setting下的效果。”
</details></li>
</ul>
<hr>
<h2 id="Explanation-aware-Soft-Ensemble-Empowers-Large-Language-Model-In-context-Learning"><a href="#Explanation-aware-Soft-Ensemble-Empowers-Large-Language-Model-In-context-Learning" class="headerlink" title="Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning"></a>Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07099">http://arxiv.org/abs/2311.07099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Yu, Jiaming Shen, Tianqi Liu, Zhen Qin, Jing Nathan Yan, Jialu Liu, Chao Zhang, Michael Bendersky<br>for: 提高大语言模型（LLM）在自然语言理解任务中的能力methods: 提出了一种Explanation-Aware Soft Ensemble框架，包括两种技术：Explanation-guided ensemble和Soft probability aggregation，以提高LLM在具有示例的情况下学习的能力。results: 经过七种自然语言理解任务和四种不同大小的LLM测试，提出的框架能够提高LLM的性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown remarkable capabilities in various natural language understanding tasks. With only a few demonstration examples, these LLMs can quickly adapt to target tasks without expensive gradient updates. Common strategies to boost such 'in-context' learning ability are to ensemble multiple model decoded results and require the model to generate an explanation along with the prediction. However, these models often treat different class predictions equally and neglect the potential discrepancy between the explanations and predictions. To fully unleash the power of explanations, we propose EASE, an Explanation-Aware Soft Ensemble framework to empower in-context learning with LLMs. We design two techniques, explanation-guided ensemble, and soft probability aggregation, to mitigate the effect of unreliable explanations and improve the consistency between explanations and final predictions. Experiments on seven natural language understanding tasks and four varying-size LLMs demonstrate the effectiveness of our proposed framework.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）在各种自然语言理解任务上展现出了惊人的能力。只需要几个示例，这些LLM就可以快速适应目标任务，不需要昂贵的梯度更新。常见的优化策略包括 ensemble多个模型的输出结果和要求模型生成预测和解释。然而，这些模型经常忽略预测和解释之间的可能差异。为了充分发挥解释的力量，我们提议EASE，一个带有解释感知的软ensemble框架，以便在LLM中进行内部学习。我们设计了两种技术：解释引导的ensemble和软概率聚合，以 Mitigate不可靠的解释的影响并提高解释和最终预测之间的一致性。在七种自然语言理解任务和四种不同大小的LLM上，我们的提议框架得到了实验证明。
</details></li>
</ul>
<hr>
<h2 id="To-Tell-The-Truth-Language-of-Deception-and-Language-Models"><a href="#To-Tell-The-Truth-Language-of-Deception-and-Language-Models" class="headerlink" title="To Tell The Truth: Language of Deception and Language Models"></a>To Tell The Truth: Language of Deception and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07092">http://arxiv.org/abs/2311.07092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bodhisattwa Prasad Majumder, Sanchaita Hazra</li>
<li>for: This paper aims to analyze the ability of individuals to discern truth from misinformation in a high-stake environment, and to develop a machine learning model that can detect deception in text-based conversations.</li>
<li>methods: The paper uses a novel dataset of TV game show conversations to investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth. The authors develop a machine learning model, built on a large language model, that employs a bottleneck framework to learn discernible cues to determine truth.</li>
<li>results: The paper shows that the machine learning model can detect novel but accurate language cues in many cases where humans failed to detect deception, opening up the possibility of humans collaborating with algorithms to improve their ability to detect the truth.<details>
<summary>Abstract</summary>
Text-based misinformation permeates online discourses, yet evidence of people's ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in previous text-based deception datasets. We show that there exists a class of detectors (algorithms) that have similar truth detection performance compared to human subjects, even when the former accesses only the language cues while the latter engages in conversations with complete access to all potential sources of cues (language and audio-visual). Our model, built on a large language model, employs a bottleneck framework to learn discernible cues to determine truth, an act of reasoning in which human subjects often perform poorly, even with incentives. Our model detects novel but accurate language cues in many cases where humans failed to detect deception, opening up the possibility of humans collaborating with algorithms and ameliorating their ability to detect the truth.
</details>
<details>
<summary>摘要</summary>
文本基本是谎言渗透在线讨论中，然而人们对真实性的识别能力的证据罕见。我们分析了一个新的电视竞赛数据，其中对话在高规模环境中，参与者有冲突目标，导致谎言。我们研究了在对话中可靠的语言证据的表现，并发现了一类检测器（算法）可以和人类相比，即使只有语言证据而不是完整的语言和视频证据。我们的模型，基于大型语言模型，采用瓶颈框架学习可识别的证据，以判断真实性，这是人类在很多情况下表现不佳，即使有奖励。我们的模型在许多情况下可以检测人类未能检测到的谎言，开发人类与算法合作，提高真实性的识别能力。
</details></li>
</ul>
<hr>
<h2 id="Sample-Dominance-Aware-Framework-via-Non-Parametric-Estimation-for-Spontaneous-Brain-Computer-Interface"><a href="#Sample-Dominance-Aware-Framework-via-Non-Parametric-Estimation-for-Spontaneous-Brain-Computer-Interface" class="headerlink" title="Sample Dominance Aware Framework via Non-Parametric Estimation for Spontaneous Brain-Computer Interface"></a>Sample Dominance Aware Framework via Non-Parametric Estimation for Spontaneous Brain-Computer Interface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07079">http://arxiv.org/abs/2311.07079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeong-Hoo Lee, Byoung-Hee Kwon, Seong-Whan Lee</li>
<li>for: 这个研究旨在解决电子encephalogram（EEG）信号的非站点特性对于训练神经网络所带来的挑战，以提高自愿性脑-computer interfaces（BCIs）的表现。</li>
<li>methods: 我们提出了一种基于sample dominance的方法，并使用了两阶段的主导性分数估计技术来补偿sample inconsistency对于网络训练的影响。</li>
<li>results: 我们的实验结果显示，这种方法可以增强自愿性BCIs的表现，并且显示了sample dominance的重要性。<details>
<summary>Abstract</summary>
Deep learning has shown promise in decoding brain signals, such as electroencephalogram (EEG), in the field of brain-computer interfaces (BCIs). However, the non-stationary characteristics of EEG signals pose challenges for training neural networks to acquire appropriate knowledge. Inconsistent EEG signals resulting from these non-stationary characteristics can lead to poor performance. Therefore, it is crucial to investigate and address sample inconsistency to ensure robust performance in spontaneous BCIs. In this study, we introduce the concept of sample dominance as a measure of EEG signal inconsistency and propose a method to modulate its effect on network training. We present a two-stage dominance score estimation technique that compensates for performance degradation caused by sample inconsistencies. Our proposed method utilizes non-parametric estimation to infer sample inconsistency and assigns each sample a dominance score. This score is then aggregated with the loss function during training to modulate the impact of sample inconsistency. Furthermore, we design a curriculum learning approach that gradually increases the influence of inconsistent signals during training to improve overall performance. We evaluate our proposed method using public spontaneous BCI dataset. The experimental results confirm that our findings highlight the importance of addressing sample dominance for achieving robust performance in spontaneous BCIs.
</details>
<details>
<summary>摘要</summary>
深度学习在脑电响应（EEG）信号解码方面表现出了承诺，特别是在脑computer接口（BCI）领域。然而，EEG信号的非站点特性使得训练神经网络获得相应的知识困难。不稳定的EEG信号导致训练神经网络表现不佳。因此，我们需要调查和解决样本不一致性问题，以确保BCI的稳定性。在这项研究中，我们提出了样本主导性的概念，用于度量EEG信号不一致性。我们还提出了一种两阶段主导性分数估计技术，用于补做样本不一致性对网络训练的影响。我们的提议方法使用非 Parametric 估计来推导样本不一致性，并将每个样本分配一个主导性分数。这个分数与训练过程中的损失函数相加，以Modulate 样本不一致性的影响。此外，我们还提出了一种课程学习方法，通过逐步增加训练过程中不一致性信号的影响，以提高总性能。我们使用公共的自发BCI数据集进行实验，实验结果证明了我们的发现，即必须解决样本不一致性问题，以实现BCI的稳定性。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Generative-Artificial-Intelligence"><a href="#The-Impact-of-Generative-Artificial-Intelligence" class="headerlink" title="The Impact of Generative Artificial Intelligence"></a>The Impact of Generative Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07071">http://arxiv.org/abs/2311.07071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaichen Zhang, Ohchan Kwon, Hui Xiong</li>
<li>for: 这个研究探讨了生成人工智能对产品市场的影响，以响应生成人工智能可能对失业和市场衰退产生影响的关注。</li>
<li>methods: 这篇论文使用了一种”自然实验”的方法来解决 causal inference 的挑战，即通过识别一种未预期的和突然的图像生成 AI 泄漏来对比不同风格的图像生成成本。</li>
<li>results: 研究发现，虽然生成 AI 降低了平均价格，但它带来了订单量的增加和总收入的增长。这种 counterintuitive 的发现表明，生成 AI 对艺术家而言是一种利益，而不是一种弊端。<details>
<summary>Abstract</summary>
The rise of generative artificial intelligence (AI) has sparked concerns about its potential influence on unemployment and market depression. This study addresses this concern by examining the impact of generative AI on product markets. To overcome the challenge of causal inference, given the inherent limitations of conducting controlled experiments, this paper identifies an unanticipated and sudden leak of a highly proficient image-generative AI as a novel instance of a "natural experiment". This AI leak spread rapidly, significantly reducing the cost of generating anime-style images compared to other styles, creating an opportunity for comparative assessment. We collect real-world data from an artwork outsourcing platform. Surprisingly, our results show that while generative AI lowers average prices, it substantially boosts order volume and overall revenue. This counterintuitive finding suggests that generative AI confers benefits upon artists rather than detriments. The study further offers theoretical economic explanations to elucidate this unexpected phenomenon. By furnishing empirical evidence, this paper dispels the notion that generative AI might engender depression, instead underscoring its potential to foster market prosperity. These findings carry significant implications for practitioners, policymakers, and the broader AI community.
</details>
<details>
<summary>摘要</summary>
《生成人工智能的兴起引发了失业和市场萧条的担忧。这项研究试图解决这个问题，检查生成人工智能对产品市场的影响。为了超越 causal inference 的限制，这篇论文利用了一次意外和不可预期的图像生成人工智能的泄露作为一个“自然实验”。这个 AI 泄露在其他风格的图像生成成本上减少了成本，创造了对比分析的机会。我们收集了一个艺术委托平台的实际数据。 surprisingly，我们发现，虽然生成人工智能降低了平均价格，但它很大程度上提高了订单量和总收入。这种Counterintuitive finding 表明，生成人工智能对艺术家而言是有利的，而不是有害的。这项研究还提供了经济理论解释，以解释这种意外的现象。通过提供实证证据，这篇论文推翻了生成人工智能会导致萧条的假设，反而证明了它的潜在市场繁荣。这些发现对实践者、政策制定者和更广泛的 AI 社区都具有重要意义。
</details></li>
</ul>
<hr>
<h2 id="Non-approximability-of-constructive-global-mathcal-L-2-minimizers-by-gradient-descent-in-Deep-Learning"><a href="#Non-approximability-of-constructive-global-mathcal-L-2-minimizers-by-gradient-descent-in-Deep-Learning" class="headerlink" title="Non-approximability of constructive global $\mathcal{L}^2$ minimizers by gradient descent in Deep Learning"></a>Non-approximability of constructive global $\mathcal{L}^2$ minimizers by gradient descent in Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07065">http://arxiv.org/abs/2311.07065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Chen, Patricia Muñoz Ewald</li>
<li>for: 本研究探讨深度学习（Deep Learning）网络中的梯度下降算法的几何性。</li>
<li>methods: 研究使用梯度下降方法来实现深度学习网络中的最优化。</li>
<li>results: 研究结果表明，globally minimizing weights和biases对于$\mathcal{L}^2$ cost的解决方案不能通过梯度下降流体 approximation。因此，提出的方法与梯度下降方法是独立的。<details>
<summary>Abstract</summary>
We analyze geometric aspects of the gradient descent algorithm in Deep Learning (DL) networks. In particular, we prove that the globally minimizing weights and biases for the $\mathcal{L}^2$ cost obtained constructively in [Chen-Munoz Ewald 2023] for underparametrized ReLU DL networks can generically not be approximated via the gradient descent flow. We therefore conclude that the method introduced in [Chen-Munoz Ewald 2023] is disjoint from the gradient descent method.
</details>
<details>
<summary>摘要</summary>
我们分析深度学习（Deep Learning）网络中的梯度下降算法的几何性。特别是证明了在[Chen-Munoz Ewald 2023]中所得到的最佳梯度下降方法不能通过梯度下降流程来近似。因此，我们 conclude that the method introduced in [Chen-Munoz Ewald 2023] is disjoint from the gradient descent method.Note:* "梯度下降算法" (gradient descent algorithm) is translated as "梯度下降方法" (gradient descent method) in Simplified Chinese.* "underparametrized ReLU DL networks" is translated as "内部不足的ReLU深度学习网络" (underparameterized ReLU deep learning networks) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Effective-In-vehicle-Intrusion-Detection-via-Multi-view-Statistical-Graph-Learning-on-CAN-Messages"><a href="#Effective-In-vehicle-Intrusion-Detection-via-Multi-view-Statistical-Graph-Learning-on-CAN-Messages" class="headerlink" title="Effective In-vehicle Intrusion Detection via Multi-view Statistical Graph Learning on CAN Messages"></a>Effective In-vehicle Intrusion Detection via Multi-view Statistical Graph Learning on CAN Messages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07056">http://arxiv.org/abs/2311.07056</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangkai-tech23/StatGraph">https://github.com/wangkai-tech23/StatGraph</a></li>
<li>paper_authors: Kai Wang, Qiguang Jiang, Bailing Wang, Yongzheng Zhang, Yulei Wu<br>for: 这个论文主要关注在智能连接汽车（ICV）中，对于外部网络的通信进行了详细的攻击探测和防护。methods: 本文提出了一个名为StatGraph的多观点统计学 гра图学探测方法，通过将资料流转换为两个统计学 гра圜（TCG和CRG），并透过轻量级的GCN网络进行训练，以实现更高效的探测性。results: 实验结果显示，StatGraph可以提高探测精度和探测性相比之前的方法，并且可以探测到四种新的攻击，这些攻击之前从未被 investigate 过。<details>
<summary>Abstract</summary>
As an important component of internet of vehicles (IoV), intelligent connected vehicles (ICVs) have to communicate with external networks frequently. In this case, the resource-constrained in-vehicle network (IVN) is facing a wide variety of complex and changing external cyber-attacks, especially the masquerade attack with high difficulty of detection while serious damaging effects that few counter measures can identify successfully. Moreover, only coarse-grained recognition can be achieved in current mainstream intrusion detection mechanisms, i.e., whether a whole data flow observation window contains attack labels rather than fine-grained recognition on every single data item within this window. In this paper, we propose StatGraph: an Effective Multi-view Statistical Graph Learning Intrusion Detection to implement the fine-grained intrusion detection. Specifically, StatGraph generates two statistical graphs, timing correlation graph (TCG) and coupling relationship graph (CRG), based on data streams. In given message observation windows, edge attributes in TCGs represent temporal correlation between different message IDs, while edge attributes in CRGs denote the neighbour relationship and contextual similarity. Besides, a lightweight shallow layered GCN network is trained based graph property of TCGs and CRGs, which can learn the universal laws of various patterns more effectively and further enhance the performance of detection. To address the problem of insufficient attack types in previous intrusion detection, we select two real in-vehicle CAN datasets that cover four new attacks never investigated before. Experimental result shows StatGraph improves both detection granularity and detection performance over state-of-the-art intrusion detection methods.
</details>
<details>
<summary>摘要</summary>
为了实现网络内部自动化（IoV）中的智能连接车辆（ICV），它们需要与外部网络进行频繁的通信。在这种情况下，具有限制的内部网络（IVN）面临着多样化和变化的外部黑客攻击，尤其是让人难以发现的掩盖攻击，这些攻击可能导致严重的损害。目前主流的防范攻击机制只能实现粗略的识别，即是某个数据流观察窗口中是否包含攻击标签，而不是每个数据项的精细识别。在这篇论文中，我们提出了StatGraph：一种有效的多视图统计图学防范攻击方法。具体来说，StatGraph根据数据流生成两个统计图，即时间相关图（TCG）和互相关系图（CRG）。在给定的消息观察窗口中，TCG中的边Attributes表示不同消息ID之间的时间相关性，而CRG中的边Attributes表示消息ID之间的邻居关系和上下文相似性。此外，我们还训练了一个轻量级的GCN网络，以利用统计图的属性来学习更加有效的各种模式。为了解决过去防范攻击方法中缺乏攻击类型的问题，我们选择了四种新的攻击方法，这些攻击方法从未被前人研究过。实验结果表明，StatGraph可以提高检测精细度和检测性能，比前方式防范攻击方法更高。
</details></li>
</ul>
<hr>
<h2 id="Towards-the-Law-of-Capacity-Gap-in-Distilling-Language-Models"><a href="#Towards-the-Law-of-Capacity-Gap-in-Distilling-Language-Models" class="headerlink" title="Towards the Law of Capacity Gap in Distilling Language Models"></a>Towards the Law of Capacity Gap in Distilling Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07052">http://arxiv.org/abs/2311.07052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/genezc/minima">https://github.com/genezc/minima</a></li>
<li>paper_authors: Chen Zhang, Dawei Song, Zheyu Ye, Yan Gao</li>
<li>for: 这种研究旨在探讨LM浸泡的最佳方法，尤其是在教师LM和学生LM之间存在巨大容量差距时。</li>
<li>methods: 该研究使用了一种新的法则，即容量差距法则，来描述在浸泡过程中如何选择最佳的学生LM。</li>
<li>results: 研究发现，在不同的学生缩放和架构下，容量差距的优化点几乎固定，这使得浸泡过程中的选择变得更加简单。此外，通过浸泡一个7B教师LM，研究者成功地折衣了一个3B学生LM（称为MiniMA），该模型在常用的测试上创造了一个新的计算性能矩阵，而其调整版本（称为MiniChat）在GPT4评估中超越了许多3B竞争对手，甚至与一些7B聊天模型相匹配。<details>
<summary>Abstract</summary>
Language model (LM) distillation is a trending area that aims to distil the knowledge resided in a large teacher LM to a small student one. While various methods have been proposed to push the distillation to its limits, it is still a pain distilling LMs when a large capacity gap is exhibited between the teacher and the student LMs. The pain is mainly resulted by the curse of capacity gap, which describes that a larger teacher LM cannot always lead to a better student LM than one distilled from a smaller teacher LM due to the affect of capacity gap increment. That is, there is likely an optimal point yielding the best student LM along the scaling course of the teacher LM. Even worse, the curse of capacity gap can be only partly yet not fully lifted as indicated in previous studies.   However, the tale is not ever one-sided. Although a larger teacher LM has better performance than a smaller teacher LM, it is much more resource-demanding especially in the context of recent large LMs (LLMs). Consequently, instead of sticking to lifting the curse, leaving the curse as is should be arguably fine. Even better, in this paper, we reveal that the optimal capacity gap is almost consistent across different student scales and architectures, fortunately turning the curse into the law of capacity gap. The law later guides us to distil a 3B student LM (termed MiniMA) from a 7B teacher LM (adapted LLaMA2-7B). MiniMA is demonstrated to yield a new compute-performance pareto frontier among existing 3B LMs on commonly used benchmarks, and its instruction-tuned version (termed MiniChat) outperforms a wide range of 3B competitors in GPT4 evaluation and could even compete with several 7B chat models.
</details>
<details>
<summary>摘要</summary>
language model (LM) 精炼是一个流行的领域，旨在压缩一个大老师 LM 中的知识到一个小学生 LM 中。虽然许多方法已经被提出来推动精炼，但是在大教师 LM 和小学生 LM 之间存在较大的容量差异时，仍然是一种痛苦的精炼。这种痛苦主要来自于容量差异的咒语，即大教师 LM 不一定可以导致一个更好的学生 LM，因为容量差异的增加会导致更大的学生 LM 不可能超越小教师 LM。这意味着在教师 LM 的扩展规模上，存在一个最佳的学生 LM 点，并且这个点与学生 LM 的架构和规模有关。事实上，这种咒语只能部分地被解决，根据前一些研究表明。然而，这不总是一个一方面的问题。虽然大教师 LM 的性能比小教师 LM 更好，但是它却需要更多的资源，特别是在现代大型 LM （LLM） 中。因此，相反于努力解决咒语，可以留下咒语，这也是可以接受的。事实上，在这篇论文中，我们发现了容量差异的优化点，这点与学生 LM 的架构和规模有关。我们使用这个点来精炼一个 3B 学生 LM（称为 MiniMA），从一个 7B 教师 LM（改进的 LLaMA2-7B）中。MiniMA 在常用的benchmark上显示出了一个新的计算性能 pareto 边缘，并且其 instruction-tuned 版本（称为 MiniChat）在 GPT4 评价中超过了许多 3B 竞争对手，甚至与一些 7B 对话模型进行竞争。
</details></li>
</ul>
<hr>
<h2 id="Phonological-Level-wav2vec2-based-Mispronunciation-Detection-and-Diagnosis-Method"><a href="#Phonological-Level-wav2vec2-based-Mispronunciation-Detection-and-Diagnosis-Method" class="headerlink" title="Phonological Level wav2vec2-based Mispronunciation Detection and Diagnosis Method"></a>Phonological Level wav2vec2-based Mispronunciation Detection and Diagnosis Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07037">http://arxiv.org/abs/2311.07037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mostafa Shahin, Julien Epps, Beena Ahmed</li>
<li>for: 本研究旨在提高计算机支持下的发音学习（CAPL）工具，特别是第二语言（L2）学习或语音疾病治疗应用中的发音错误检测和诊断（MDD）方法。</li>
<li>methods: 本研究提出了一种基于发音特征分析的低级MDD方法，通过检测发音特征来提供更形成的反馈给学习者。此外，我们还提出了一种基于多标签连接主义分类（CTC）方法来联合模型多个非互相排斥的发音特征。使用预训练的wav2vec2模型作为核心模型。</li>
<li>results: 对于英语学习者的L2语音资料，提出的发音特征MDD方法与传统的phoneme-level MDD方法进行比较，获得了 significatively lower False Acceptance Rate（FAR）、False Rejection Rate（FRR）和诊断错误率（DER）。<details>
<summary>Abstract</summary>
The automatic identification and analysis of pronunciation errors, known as Mispronunciation Detection and Diagnosis (MDD) plays a crucial role in Computer Aided Pronunciation Learning (CAPL) tools such as Second-Language (L2) learning or speech therapy applications. Existing MDD methods relying on analysing phonemes can only detect categorical errors of phonemes that have an adequate amount of training data to be modelled. With the unpredictable nature of the pronunciation errors of non-native or disordered speakers and the scarcity of training datasets, it is unfeasible to model all types of mispronunciations. Moreover, phoneme-level MDD approaches have a limited ability to provide detailed diagnostic information about the error made. In this paper, we propose a low-level MDD approach based on the detection of speech attribute features. Speech attribute features break down phoneme production into elementary components that are directly related to the articulatory system leading to more formative feedback to the learner. We further propose a multi-label variant of the Connectionist Temporal Classification (CTC) approach to jointly model the non-mutually exclusive speech attributes using a single model. The pre-trained wav2vec2 model was employed as a core model for the speech attribute detector. The proposed method was applied to L2 speech corpora collected from English learners from different native languages. The proposed speech attribute MDD method was further compared to the traditional phoneme-level MDD and achieved a significantly lower False Acceptance Rate (FAR), False Rejection Rate (FRR), and Diagnostic Error Rate (DER) over all speech attributes compared to the phoneme-level equivalent.
</details>
<details>
<summary>摘要</summary>
computer-assisted pronunciation learning (CAPL) 工具中的自动识别和分析声音错误（MDD）在语音学习中扮演了关键角色。现有的 MDD 方法仅仅是通过分析音节来检测音节错误，但这些错误可能是非Native 或异常的说话者的不可预测的。此外，音节级 MDD 方法只能提供有限的诊断信息。在这篇论文中，我们提议了一种基于声音特征的低级 MDD 方法。声音特征分解声音生产成Elementary 组件，直接关系到语音生成系统，从而提供更有形成的反馈给学习者。我们还提议了一种多标签的 CTC 方法，以同时模型不同的声音特征。使用 pre-trained wav2vec2 模型作为核心模型。我们的提议方法应用于英语学习者的 L2 语音资料。与传统的音节级 MDD 相比，我们的声音特征 MDD 方法显示了较低的 false acceptance rate（FAR）、false rejection rate（FRR）和诊断错误率（DER）。
</details></li>
</ul>
<hr>
<h2 id="ExpNote-Black-box-Large-Language-Models-are-Better-Task-Solvers-with-Experience-Notebook"><a href="#ExpNote-Black-box-Large-Language-Models-are-Better-Task-Solvers-with-Experience-Notebook" class="headerlink" title="ExpNote: Black-box Large Language Models are Better Task Solvers with Experience Notebook"></a>ExpNote: Black-box Large Language Models are Better Task Solvers with Experience Notebook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07032">http://arxiv.org/abs/2311.07032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/forangel2014/expnote">https://github.com/forangel2014/expnote</a></li>
<li>paper_authors: Wangtao Sun, Xuanqing Yu, Shizhu He, Jun Zhao, Kang Liu</li>
<li>for: 这 paper 的目的是提高黑盒大语言模型（LLMs）在不同任务中的性能。</li>
<li>methods: 该 paper 提出了一种自动化框架，帮助 LLMs 更好地适应未知任务。该框架通过反思和记录训练数据中的经验，以及在测试时从外部存储器中检索经验，以帮助 LLMs 更好地适应新任务。</li>
<li>results: 实验结果表明，该方法可以显著提高黑盒 LLMs 在多个任务中的性能。数据和代码可以在 GitHub 上获取（<a target="_blank" rel="noopener" href="https://github.com/forangel2014/ExpNote%EF%BC%89%E3%80%82">https://github.com/forangel2014/ExpNote）。</a><details>
<summary>Abstract</summary>
Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote
</details>
<details>
<summary>摘要</summary>
黑盒大语言模型（LLMs）已经表现出杰出的能力解决多种任务，并被视为通用的问题解决者。然而，LLMs仍然在许多具体任务上失败，即使理解任务指令。在这篇论文中，我们专注于增强黑盒LLMs解决下游任务的能力。我们提出了ExpNote，一个自动框架，帮助LLMs更好地适应未知任务。在训练数据中反思和记录经验，并在试验过程中从外部内存中撷取经验，以提高黑盒LLMs的性能。我们在多个任务上进行了实验，结果显示，提案的方法可以对黑盒LLMs进行明显改善。资料和代码可以在https://github.com/forangel2014/ExpNote上获取。
</details></li>
</ul>
<hr>
<h2 id="Embarassingly-Simple-Dataset-Distillation"><a href="#Embarassingly-Simple-Dataset-Distillation" class="headerlink" title="Embarassingly Simple Dataset Distillation"></a>Embarassingly Simple Dataset Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07025">http://arxiv.org/abs/2311.07025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunzhen Feng, Ramakrishna Vedantam, Julia Kempe</li>
<li>For: The paper aims to achieve competitive performance on test data when trained on a small set of synthetic training samples, through the process of dataset distillation.* Methods: The paper treats dataset distillation as a bilevel optimization problem and introduces an improved method called Random Truncated Backpropagation Through Time (RaT-BPTT) to address issues such as variance in gradients, computational burden, and long-term dependencies.* Results: The paper establishes new state-of-the-art performance on standard dataset benchmarks using RaT-BPTT, and also discovers that distilled datasets tend to exhibit pronounced intercorrelation, which can be addressed by a boosting mechanism that generates distilled datasets with near optimal performance across different data budgets.Here’s the Chinese translation of the three points:* For:  paper 的目的是在使用小量的合成训练样本来实现测试数据上的竞争性表现。* Methods: paper 将dataset distillation看作是一个二级优化问题，并介绍了一种改进的方法Random Truncated Backpropagation Through Time (RaT-BPTT)来解决变异性、计算负担和长期依赖问题。* Results: paper 使用 RaT-BPTT 实现了标准dataset benchmark上的新state-of-the-art性能，并发现了压缩数据集之间的强相关性，可以通过一种boosting机制来生成具有近似最佳性能的各种数据预算下的压缩数据集。<details>
<summary>Abstract</summary>
Dataset distillation extracts a small set of synthetic training samples from a large dataset with the goal of achieving competitive performance on test data when trained on this sample. In this work, we tackle dataset distillation at its core by treating it directly as a bilevel optimization problem. Re-examining the foundational back-propagation through time method, we study the pronounced variance in the gradients, computational burden, and long-term dependencies. We introduce an improved method: Random Truncated Backpropagation Through Time (RaT-BPTT) to address them. RaT-BPTT incorporates a truncation coupled with a random window, effectively stabilizing the gradients and speeding up the optimization while covering long dependencies. This allows us to establish new state-of-the-art for a variety of standard dataset benchmarks. A deeper dive into the nature of distilled data unveils pronounced intercorrelation. In particular, subsets of distilled datasets tend to exhibit much worse performance than directly distilled smaller datasets of the same size. Leveraging RaT-BPTT, we devise a boosting mechanism that generates distilled datasets that contain subsets with near optimal performance across different data budgets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ViLMA-A-Zero-Shot-Benchmark-for-Linguistic-and-Temporal-Grounding-in-Video-Language-Models"><a href="#ViLMA-A-Zero-Shot-Benchmark-for-Linguistic-and-Temporal-Grounding-in-Video-Language-Models" class="headerlink" title="ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"></a>ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07022">http://arxiv.org/abs/2311.07022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ilkerkesen/ViLMA">https://github.com/ilkerkesen/ViLMA</a></li>
<li>paper_authors: Ilker Kesen, Andrea Pedrotti, Mustafa Dogan, Michele Cafagna, Emre Can Acikgoz, Letitia Parcalabescu, Iacer Calixto, Anette Frank, Albert Gatt, Aykut Erdem, Erkut Erdem</li>
<li>for: 本研究的目的是为了开发一个任务无关的评估指标，以评估视频语言模型（VidLM）的细腻功能。</li>
<li>methods: 本研究使用了仔细制作的反例来测试 VidLM 的能力，并对其进行评估。此外，研究还包括一系列的技能测试，以评估 VidLM 的基础能力。</li>
<li>results: 研究发现，当前的 VidLM 的基础能力和视频语言模型（VLM）使用的 static 图像相比，其表现并不出色。此外，包括技能测试的表现在内，VidLM 的总表现也不如人类水平。这些结果表明， VidLM 还有很多需要进一步探索的领域。<details>
<summary>Abstract</summary>
With the ever-increasing popularity of pretrained Video-Language Models (VidLMs), there is a pressing need to develop robust evaluation methodologies that delve deeper into their visio-linguistic capabilities. To address this challenge, we present ViLMA (Video Language Model Assessment), a task-agnostic benchmark that places the assessment of fine-grained capabilities of these models on a firm footing. Task-based evaluations, while valuable, fail to capture the complexities and specific temporal aspects of moving images that VidLMs need to process. Through carefully curated counterfactuals, ViLMA offers a controlled evaluation suite that sheds light on the true potential of these models, as well as their performance gaps compared to human-level understanding. ViLMA also includes proficiency tests, which assess basic capabilities deemed essential to solving the main counterfactual tests. We show that current VidLMs' grounding abilities are no better than those of vision-language models which use static images. This is especially striking once the performance on proficiency tests is factored in. Our benchmark serves as a catalyst for future research on VidLMs, helping to highlight areas that still need to be explored.
</details>
<details>
<summary>摘要</summary>
随着视频语言模型（VidLM）的普及，需要开发更加稳健的评估方法来探索它们的视频语言功能。为此，我们提出了视频语言模型评估（ViLMA），一个任务无关的benchmark，它通过控制性的counterfactual来评估视频语言模型的细腻能力。任务基础的评估，虽有价值，但是无法捕捉视频图像中的复杂性和时间特征，这些特征是视频语言模型需要处理的。我们的benchmark包括了基础能力测试，它们评估了视频语言模型的基本能力，这些能力被认为是解决主要counterfactual测试的前提。我们的研究显示，现有的视频语言模型在grounding能力方面并没有超过视频语言模型，这是特别明显的，当加入基础能力测试时。我们的benchmark会成为未来研究视频语言模型的catalyst，帮助探索这些模型的未知领域。
</details></li>
</ul>
<hr>
<h2 id="Context-dependent-Instruction-Tuning-for-Dialogue-Response-Generation"><a href="#Context-dependent-Instruction-Tuning-for-Dialogue-Response-Generation" class="headerlink" title="Context-dependent Instruction Tuning for Dialogue Response Generation"></a>Context-dependent Instruction Tuning for Dialogue Response Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07006">http://arxiv.org/abs/2311.07006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin Myung Kwak, Minseon Kim, Sung Ju Hwang</li>
<li>for: 这个论文是为了解决复杂多轮对话生成任务中的输入变化问题而写的。</li>
<li>methods: 该论文提出了基于上一次对话 контекст的指令细化框架，该框架可以在每个多轮对话中生成响应和指令，并在评估阶段使用上一次对话 контекст来自动导航响应。</li>
<li>results: 根据量化评估结果，该框架在多轮对话生成任务中比基线方案更好地适应输入变化，并且可以减少计算资源开销。<details>
<summary>Abstract</summary>
Recent language models have achieved impressive performance in natural language tasks by incorporating instructions with task input during fine-tuning. Since all samples in the same natural language task can be explained with the same task instructions, many instruction datasets only provide a few instructions for the entire task, without considering the input of each example in the task. However, this approach becomes ineffective in complex multi-turn dialogue generation tasks, where the input varies highly with each turn as the dialogue context changes, so that simple task instructions cannot improve the generation performance. To address this limitation, we introduce a context-based instruction fine-tuning framework for each multi-turn dialogue which generates both responses and instructions based on the previous context as input. During the evaluation, the model generates instructions based on the previous context to self-guide the response. The proposed framework produces comparable or even outstanding results compared to the baselines by aligning instructions to the input during fine-tuning with the instructions in quantitative evaluations on dialogue benchmark datasets with reduced computation budget.
</details>
<details>
<summary>摘要</summary>
现代语言模型已经取得了优异的表现在自然语言任务中，通过在精馈过程中融合指令与任务输入。自然语言任务中的所有样例都可以使用相同的任务指令来解释，因此许多指令数据集只提供了任务中的一些指令，不考虑每个样例的输入。然而，这种方法在复杂的多转对话生成任务中失效，因为对话上下文的变化会导致输入的高度不同，使得简单的任务指令无法提高生成性能。为了解决这个限制，我们提出了基于对话上下文的指令精馈框架，这个框架在每个多转对话中生成回复和指令，并且使用上一个对话的上下文来自适化。在评估过程中，模型根据上一个对话的上下文来给出指令，以自适应回复。我们的提案 Frameworks 在对话库数据集上进行评估时，与基准值进行比较，产生了相似或甚至出色的结果，并且在对话生成任务中实现了优化的表现。
</details></li>
</ul>
<hr>
<h2 id="AGRAMPLIFIER-Defending-Federated-Learning-Against-Poisoning-Attacks-Through-Local-Update-Amplification"><a href="#AGRAMPLIFIER-Defending-Federated-Learning-Against-Poisoning-Attacks-Through-Local-Update-Amplification" class="headerlink" title="AGRAMPLIFIER: Defending Federated Learning Against Poisoning Attacks Through Local Update Amplification"></a>AGRAMPLIFIER: Defending Federated Learning Against Poisoning Attacks Through Local Update Amplification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06996">http://arxiv.org/abs/2311.06996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirui Gong, Liyue Shen, Yanjun Zhang, Leo Yu Zhang, Jingwei Wang, Guangdong Bai, Yong Xiang<br>for: 本研究旨在 Addressing the Byzantine poisoning attack 在 Federated Learning (FL) 中的协同性带来的威胁。methods: 本研究提出了一种新的方法，即 AGRAMPLIFIER，以提高现有的 Byzantine-robust aggregation rules 的Robustness、准确性和效率。results: 研究表明，通过将 AGRAMPLIFIER 与现有的 Byzantine-robust mechanisms 结合使用，可以提高模型的Robustness、精度和效率， average gains 为 40.08%、39.18% 和 10.68%。<details>
<summary>Abstract</summary>
The collaborative nature of federated learning (FL) poses a major threat in the form of manipulation of local training data and local updates, known as the Byzantine poisoning attack. To address this issue, many Byzantine-robust aggregation rules (AGRs) have been proposed to filter out or moderate suspicious local updates uploaded by Byzantine participants.   This paper introduces a novel approach called AGRAMPLIFIER, aiming to simultaneously improve the robustness, fidelity, and efficiency of the existing AGRs. The core idea of AGRAMPLIFIER is to amplify the "morality" of local updates by identifying the most repressive features of each gradient update, which provides a clearer distinction between malicious and benign updates, consequently improving the detection effect. To achieve this objective, two approaches, namely AGRMP and AGRXAI, are proposed. AGRMP organizes local updates into patches and extracts the largest value from each patch, while AGRXAI leverages explainable AI methods to extract the gradient of the most activated features. By equipping AGRAMPLIFIER with the existing Byzantine-robust mechanisms, we successfully enhance the model's robustness, maintaining its fidelity and improving overall efficiency.   AGRAMPLIFIER is universally compatible with the existing Byzantine-robust mechanisms. The paper demonstrates its effectiveness by integrating it with all mainstream AGR mechanisms. Extensive evaluations conducted on seven datasets from diverse domains against seven representative poisoning attacks consistently show enhancements in robustness, fidelity, and efficiency, with average gains of 40.08%, 39.18%, and 10.68%, respectively.
</details>
<details>
<summary>摘要</summary>
合作性的联合学习（FL）具有主要的威胁，即本地训练数据和本地更新的操纵，称为Byzantine毒害攻击。为解决这一问题，许多Byzantine鲁班耐式积分规则（AGRs）已经被提议，以筛选或调整嫌疑的本地更新。 这篇论文介绍了一种新的方法 called AGRAMPLIFIER，旨在同时提高现有 AGRs 的 Robustness、准确性和效率。AGRAMPLIFIER的核心思想是通过识别每个梯度更新中最压抑的特征来增强本地更新的“道德”性，从而更好地 отли奇嫌疑和合法更新。为实现这一目标，我们提出了两种方法：AGRMP和AGRXAI。AGRMP 将本地更新分割成块，并从每个块中提取最大值，而 AGRXAI 则利用可解释AI方法提取最活跃特征的梯度。通过将 AGRAMPLIFIER 与现有的Byzantine鲁班耐式机制结合使用，我们成功地提高了模型的Robustness，保持了准确性，并提高了总的效率。AGRAMPLIFIER 与现有的Byzantine鲁班耐式机制兼容，可与所有主流 AGR 机制结合使用。文章通过对七个 datasets 从多个领域进行了七种 poisoning 攻击的广泛评估，证明了 AGRAMPLIFIER 的效iveness。 average 提高了40.08%、39.18% 和 10.68%。
</details></li>
</ul>
<hr>
<h2 id="State-of-the-Art-Review-and-Synthesis-A-Requirement-based-Roadmap-for-Standardized-Predictive-Maintenance-Automation-Using-Digital-Twin-Technologies"><a href="#State-of-the-Art-Review-and-Synthesis-A-Requirement-based-Roadmap-for-Standardized-Predictive-Maintenance-Automation-Using-Digital-Twin-Technologies" class="headerlink" title="State-of-the-Art Review and Synthesis: A Requirement-based Roadmap for Standardized Predictive Maintenance Automation Using Digital Twin Technologies"></a>State-of-the-Art Review and Synthesis: A Requirement-based Roadmap for Standardized Predictive Maintenance Automation Using Digital Twin Technologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06993">http://arxiv.org/abs/2311.06993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhe Ma, Katherine A. Flanigan, Mario Bergés</li>
<li>for:  This paper aims to provide a requirement-based roadmap for standardized predictive maintenance (PMx) automation using digital twin (DT) technologies.</li>
<li>methods:  The paper uses a systematic approach that includes identifying informational requirements (IRs) and functional requirements (FRs) for PMx, and conducting a literature review to determine how these requirements are currently being used in DTs.</li>
<li>results:  The paper provides a roadmap for the development of standardized PMx automation using DTs, and highlights the areas where further research is needed to support the progress and maturation of these technologies.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是提供一个基于需求的PMx自动化道路图，使用数字双工具技术。</li>
<li>methods: 论文采用一种系统atic的方法，包括确定PMx的信息需求(IR)和功能需求(FR)，以及对这些需求在数字双中的现状进行文献评估。</li>
<li>results: 论文提供一个PMx自动化的标准化道路图，并指出需要进一步研究以支持这些技术的进步和成熟。<details>
<summary>Abstract</summary>
Recent digital advances have popularized predictive maintenance (PMx), offering enhanced efficiency, automation, accuracy, cost savings, and independence in maintenance. Yet, it continues to face numerous limitations such as poor explainability, sample inefficiency of data-driven methods, complexity of physics-based methods, and limited generalizability and scalability of knowledge-based methods. This paper proposes leveraging Digital Twins (DTs) to address these challenges and enable automated PMx adoption at larger scales. While we argue that DTs have this transformative potential, they have not yet reached the level of maturity needed to bridge these gaps in a standardized way. Without a standard definition for such evolution, this transformation lacks a solid foundation upon which to base its development. This paper provides a requirement-based roadmap supporting standardized PMx automation using DT technologies. A systematic approach comprising two primary stages is presented. First, we methodically identify the Informational Requirements (IRs) and Functional Requirements (FRs) for PMx, which serve as a foundation from which any unified framework must emerge. Our approach to defining and using IRs and FRs to form the backbone of any PMx DT is supported by the track record of IRs and FRs being successfully used as blueprints in other areas, such as for product development within the software industry. Second, we conduct a thorough literature review spanning fields to determine the ways in which these IRs and FRs are currently being used within DTs, enabling us to point to the specific areas where further research is warranted to support the progress and maturation of requirement-based PMx DTs.
</details>
<details>
<summary>摘要</summary>
近期数字技术发展，predictive maintenance（PMx）得到了广泛应用，提高了效率、自动化、准确性、成本节省和独立性等方面。然而，它仍面临许多限制，如解释能力不足、数据驱动方法的样本不足、物理基础方法的复杂性以及知识基础方法的局限性和扩展性不足。这篇文章提议通过数字双方（DT）解决这些挑战，并促进大规模自动化采用PMx。虽然我们认为DT具有这种转变潜力，但它们并没有达到所需的成熔度，以便在标准化的方式下 bridging这些差距。没有一个标准定义这种演化的基础，这种转型缺乏固定的基础。这篇文章提供了一个基于需求的路线图，支持标准化的PMx自动化使用DT技术。我们采用了两个主要阶段的系统方法。首先，我们方法性地确定PMx的信息需求（IR）和功能需求（FR），这些需求将成为任何统一框架的基础。我们的方法是基于IR和FR的使用记录，在软件行业中产品开发中的蓝图中得到了支持。其次，我们通过对多个领域的文献综述，确定DT中正在使用IR和FR的方式，以便指出需要进行进一步研究，以支持PMx DT的发展和成熔度的提高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.AI_2023_11_13/" data-id="clp89do9i0073i7889z3l9fnu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.CL_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T11:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.CL_2023_11_13/">cs.CL - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="In-context-Learning-Generalizes-But-Not-Always-Robustly-The-Case-of-Syntax"><a href="#In-context-Learning-Generalizes-But-Not-Always-Robustly-The-Case-of-Syntax" class="headerlink" title="In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax"></a>In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07811">http://arxiv.org/abs/2311.07811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aaronmueller/syntax-icl">https://github.com/aaronmueller/syntax-icl</a></li>
<li>paper_authors: Aaron Mueller, Albert Webson, Jackson Petty, Tal Linzen</li>
<li>for:  investigate the robustness of LLMs supervised via ICL</li>
<li>methods:  two simple and well-controlled syntactic transformations tasks, chain-of-thought prompting</li>
<li>results:  large variance across LMs on this fundamental linguistic phenomenon, evidence that models pre-trained on code generalize better, and benefit to a greater extent from chain-of-thought prompting.Here’s the Chinese version:</li>
<li>for:  investigate the robustness of LLMs supervised via ICL</li>
<li>methods:  two simple and well-controlled syntactic transformations tasks, chain-of-thought prompting</li>
<li>results:  大量LMs在这一基本语言现象上存在巨大的变异，这种变异可以通过预训练集和监督方法的组合而更好地解释。具体来说，我们发现了代码预训练集的模型在这种情况下更好地generalize，并且受益于链式思维提示。<details>
<summary>Abstract</summary>
In-context learning (ICL) is now a common method for supervising large language models (LLMs): given labeled examples in the input context, the LLM learns to perform the task without weight updates. Despite ICL's prevalence and utility, we understand little about whether models supervised in this manner represent the underlying structure of their tasks, rather than superficial heuristics that only generalize to identically distributed examples. In this study, we investigate the robustness of LLMs supervised via ICL using the test case of sensitivity to syntax, which is a prerequisite for robust language understanding. Our experiments are based on two simple and well-controlled syntactic transformations tasks, where correct out-of-distribution generalization requires an accurate syntactic analysis of the input. We further investigate whether out-of-distribution generalization can be improved via chain-of-thought prompting, where the model is provided with a sequence of intermediate computation steps that illustrate how the task ought to be performed. In experiments with models from the GPT, PaLM, and Llama 2 families, we find large variance across LMs on this fundamental linguistic phenomenon, and that the variance is explained more by the composition of the pre-training corpus and supervision methods than by model size. In particular, we find evidence that models pre-trained on code generalize better, and benefit to a greater extent from chain-of-thought prompting.
</details>
<details>
<summary>摘要</summary>
启用上下文学习（ICL）现在是大语言模型（LLM）的常见监督方法：给定输入上下文中标注的例子，LLM可以学习完成任务而无需重新更新参数。despite ICL的普遍和实用性，我们对LLM被监督这种方式是否表达任务的基本结构而不是 superficies heuristics 只能泛化到一样分布的例子还不够了解。本研究 investigate LLMs 被监督 via ICL 的稳定性，使用语法敏感性作为语言理解的必要前提。我们的实验基于两个简单和可控的语法变换任务，正确的对于不同分布的输入需要精准的语法分析。我们进一步调查是否可以通过链条思维提示来提高对于不同分布的泛化，其中模型被提供一系列的中间计算步骤，以示如何完成任务。在GPT、PaLM和Llama 2家族的模型上进行实验，我们发现大量的变异，而这种变异更多是由预训练集和监督方法决定，而不是模型的大小。具体来说，我们发现代码预训练模型可以更好地泛化，并且受益于链条思维提示更大。
</details></li>
</ul>
<hr>
<h2 id="IruMozhi-Automatically-classifying-diglossia-in-Tamil"><a href="#IruMozhi-Automatically-classifying-diglossia-in-Tamil" class="headerlink" title="IruMozhi: Automatically classifying diglossia in Tamil"></a>IruMozhi: Automatically classifying diglossia in Tamil</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07804">http://arxiv.org/abs/2311.07804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kabilan Prasanna, Aryaman Arora</li>
<li>for: 这个论文是为了研究板xiTamil, a Dravidian language of South Asia, and its two registers, Literary Tamil and Spoken Tamil.</li>
<li>methods: 这个论文使用了人工标注的数据集，以及在Literary和Spoken Tamil之间进行分类的模型。</li>
<li>results: 这个论文发现了Spoken Tamil在现有的标注数据集中的不足，并且鼓励未来的研究者在这个语言变体上进行更多的工作。<details>
<summary>Abstract</summary>
Tamil, a Dravidian language of South Asia, is a highly diglossic language with two very different registers in everyday use: Literary Tamil (preferred in writing and formal communication) and Spoken Tamil (confined to speech and informal media). Spoken Tamil is under-supported in modern NLP systems. In this paper, we release IruMozhi, a human-annotated dataset of parallel text in Literary and Spoken Tamil. We train classifiers on the task of identifying which variety a text belongs to. We use these models to gauge the availability of pretraining data in Spoken Tamil, to audit the composition of existing labelled datasets for Tamil, and to encourage future work on the variety.
</details>
<details>
<summary>摘要</summary>
泰米尔语，一种南亚地区的达磨语言，是一种非常强烈的双语Diglossia，在日常使用中有两种不同的注重注重注重：文学泰米尔语（在书面和正式通信中具有首选）和口语泰米尔语（仅用于语音媒体和非正式通信）。口语泰米尔语在现代NLP系统中得到了更少的支持。在这篇论文中，我们发布了IruMozhi，一个人工标注的平行文本数据集，包括文学泰米尔语和口语泰米尔语之间的对照文本。我们使用这些模型来评估口语泰米尔语的预处理数据的可用性，对现有的标注数据集的组成进行审核，并促进将来对这种变种的工作。
</details></li>
</ul>
<hr>
<h2 id="In-context-Learning-and-Gradient-Descent-Revisited"><a href="#In-context-Learning-and-Gradient-Descent-Revisited" class="headerlink" title="In-context Learning and Gradient Descent Revisited"></a>In-context Learning and Gradient Descent Revisited</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07772">http://arxiv.org/abs/2311.07772</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/giilde/ft-vs-icl">https://github.com/giilde/ft-vs-icl</a></li>
<li>paper_authors: Tomer Bar Natan, Gilad Deutch, Nadav Magar, Guy Dar</li>
<li>for: 这篇论文探讨了受限学习（ICL）在少量学习任务中的表现，并寻找了ICL的下面机制。</li>
<li>methods: 该论文使用了Gradient Descent（GD）基于优化过程来比较ICL和标准finetuning的相似性。</li>
<li>results: 研究发现，ICL和GD-based finetuning在大多数情况下具有相同或更好的表现，并且提出了一种层 causality 的变体，可以更好地解释ICL的工作机制。<details>
<summary>Abstract</summary>
In-context learning (ICL) has shown impressive results in few-shot learning tasks, yet its underlying mechanism is still not fully understood. Recent works suggest that ICL can be thought of as a gradient descent (GD) based optimization process. While promising, these results mainly focus on simplified settings of ICL and provide only a preliminary evaluation of the similarities between the two methods. In this work, we revisit the comparison between ICL and GD-based finetuning and study what properties of ICL an equivalent process must follow. We highlight a major difference in the flow of information between ICL and standard finetuning. Namely, ICL can only rely on information from lower layers at every point, while finetuning depends on loss gradients from deeper layers. We refer to this discrepancy as Layer Causality and show that a layer causal variant of the finetuning process aligns with ICL on par with vanilla finetuning and is even better in most cases across relevant metrics. To the best of our knowledge, this is the first work to discuss this discrepancy explicitly and suggest a solution that tackles this problem with minimal changes.
</details>
<details>
<summary>摘要</summary>
宽Context learning (ICL) 在几个shot learning任务中表现出色，然而它的下面机制仍未完全理解。 latest works suggest that ICL can be viewed as a gradient descent (GD) based optimization process. Although promising, these results mainly focus on the simplified settings of ICL and provide only a preliminary evaluation of the similarities between the two methods. In this work, we revisit the comparison between ICL and GD-based finetuning and study what properties of ICL an equivalent process must follow. We highlight a major difference in the flow of information between ICL and standard finetuning. Specifically, ICL can only rely on information from lower layers at every point, while finetuning depends on loss gradients from deeper layers. We refer to this discrepancy as Layer Causality and show that a layer causal variant of the finetuning process aligns with ICL on par with vanilla finetuning and is even better in most cases across relevant metrics. To the best of our knowledge, this is the first work to explicitly discuss this discrepancy and suggest a solution that tackles this problem with minimal changes.
</details></li>
</ul>
<hr>
<h2 id="Measuring-Entrainment-in-Spontaneous-Code-switched-Speech"><a href="#Measuring-Entrainment-in-Spontaneous-Code-switched-Speech" class="headerlink" title="Measuring Entrainment in Spontaneous Code-switched Speech"></a>Measuring Entrainment in Spontaneous Code-switched Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07703">http://arxiv.org/abs/2311.07703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debasmita Bhattacharya, Siying Ding, Alayna Nguyen, Julia Hirschberg</li>
<li>for: 研究 Code-switched 通话中的同步现象，以确定同步现象是否在写作和口语中的不同语言设置中具有一致性。</li>
<li>methods: 利用自然语言处理技术分析 Code-switched 通话中的语言结构和语言交界点，以确定同步现象的存在和特征。</li>
<li>results: 发现 Code-switched 通话中的同步现象与写作和口语中的同步现象之间存在相似之处，并且这种同步现象在自然语言交流中具有重要的应用前景。<details>
<summary>Abstract</summary>
It is well-known that interlocutors who entrain to one another have more successful conversations than those who do not. Previous research has shown that interlocutors entrain on linguistic features in both written and spoken monolingual domains. More recent work on code-switched communication has also shown preliminary evidence of entrainment on certain aspects of code-switching (CSW). However, such studies of entrainment in code-switched domains have been extremely few and restricted to human-machine textual interactions. Our work studies code-switched spontaneous speech between humans by answering the following questions: 1) Do patterns of written and spoken entrainment in monolingual settings generalize to code-switched settings? 2) Do patterns of entrainment on code-switching in generated text generalize to spontaneous code-switched speech? We find evidence of affirmative answers to both of these questions, with important implications for the potentially "universal" nature of entrainment as a communication phenomenon, and potential applications in inclusive and interactive speech technology.
</details>
<details>
<summary>摘要</summary>
研究发现，在交流过程中的对话者会相互听附，这会导致更成功的对话。以前的研究表明，在单语言书面和口语领域中，对话者会听附语言特征。然而，关于code-switching（CSW）的交流研究非常少，并且只是关注人机文本交互。我们的研究探讨了code-switched自由说话中的听附模式，并回答了以下两个问题：1）单语言书面和口语中的听附模式是否在code-switched设置中通用？2）在生成的文本中听附CSW后，是否存在对自由说话中的听附模式的扩展？我们发现了肯定答案，这有重要的意义，因为它表明听附可能是一种通用的交流现象，并且可能有各种应用于包容和互动的语音技术。
</details></li>
</ul>
<hr>
<h2 id="MART-Improving-LLM-Safety-with-Multi-round-Automatic-Red-Teaming"><a href="#MART-Improving-LLM-Safety-with-Multi-round-Automatic-Red-Teaming" class="headerlink" title="MART: Improving LLM Safety with Multi-round Automatic Red-Teaming"></a>MART: Improving LLM Safety with Multi-round Automatic Red-Teaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07689">http://arxiv.org/abs/2311.07689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suyu Ge, Chunting Zhou, Rui Hou, Madian Khabsa, Yi-Chia Wang, Qifan Wang, Jiawei Han, Yuning Mao<br>for: This paper aims to improve the safety of Large Language Models (LLMs) by proposing a Multi-round Automatic Red-Teaming (MART) method that can scale up red-teaming and address potential safety risks.methods: The MART method involves both automatic adversarial prompt writing and safe response generation, where an adversarial LLM and a target LLM interplay in an iterative manner to improve the target LLM’s safety alignment.results: After 4 rounds of MART, the violation rate of the target LLM on adversarial prompt benchmarks reduced by up to 84.7%, achieving comparable performance to LLMs with extensive adversarial prompt writing, while maintaining strong performance on non-adversarial prompts.<details>
<summary>Abstract</summary>
Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses. While effective, manual red-teaming is costly, and existing automatic red-teaming typically discovers safety risks without addressing them. In this paper, we propose a Multi-round Automatic Red-Teaming (MART) method, which incorporates both automatic adversarial prompt writing and safe response generation, significantly increasing red-teaming scalability and the safety of the target LLM. Specifically, an adversarial LLM and a target LLM interplay with each other in an iterative manner, where the adversarial LLM aims to generate challenging prompts that elicit unsafe responses from the target LLM, while the target LLM is fine-tuned with safety aligned data on these adversarial prompts. In each round, the adversarial LLM crafts better attacks on the updated target LLM, while the target LLM also improves itself through safety fine-tuning. On adversarial prompt benchmarks, the violation rate of an LLM with limited safety alignment reduces up to 84.7% after 4 rounds of MART, achieving comparable performance to LLMs with extensive adversarial prompt writing. Notably, model helpfulness on non-adversarial prompts remains stable throughout iterations, indicating the target LLM maintains strong performance on instruction following.
</details>
<details>
<summary>摘要</summary>
红人 коман（Red-teaming）是一种常见的减少不安全行为的做法，用于大语言模型（LLMs）中，它通过全面评估LLMs，并对其发现的潜在漏洞进行负责任的回应。虽然有效，但手动红人 коман是昂贵的，而现有的自动红人 коман通常只能发现安全风险而不是解决它们。在这篇论文中，我们提出了一种多轮自动红人 коман（MART）方法，它将自动对抗文本生成和安全回应融合在一起，从而大幅提高红人 коман扩展性和目标LLM的安全性。具体来说，一个敌对的LLM和目标LLM在迭代的过程中互动，敌对LLM会尝试通过生成挑战性的提示来让目标LLM发送不安全的回应，而目标LLM则是在安全适应数据上练习，以适应敌对LLM的攻击。在每轮中，敌对LLM会为目标LLM制定更好的攻击策略，而目标LLM也会通过安全适应来提高自己。在对抗提示 benchmark 上，一个有限度的安全适应 LLM 的违规率下降到 84.7% 之后四轮 MART，与广泛的对抗提示写作 LLM 的性能相当，而且模型在非对抗提示上的帮助性保持稳定，表明目标 LLM 在指令遵从上保持了强大的表现。
</details></li>
</ul>
<hr>
<h2 id="Can-Authorship-Attribution-Models-Distinguish-Speakers-in-Speech-Transcripts"><a href="#Can-Authorship-Attribution-Models-Distinguish-Speakers-in-Speech-Transcripts" class="headerlink" title="Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?"></a>Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07564">http://arxiv.org/abs/2311.07564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llnl/luar">https://github.com/llnl/luar</a></li>
<li>paper_authors: Cristina Aggazzotti, Nicholas Andrews, Elizabeth Allyn Smith</li>
<li>for: 本研究探讨了对转录Speech的作者归属，这个领域存在新的挑战，因为许多语言特征，如括号和大写字母，不可靠或不存在。</li>
<li>methods: 作者使用了一种新的benchmark来测试作者归属的能力，并对不同的对话提供了控制的难度水平。他们还比较了一些神经网络和非神经网络的基elines，发现written文本归属模型在某些情况下可以达到高效性，但在最难的情况下却表现不佳。</li>
<li>results: 研究发现，作者归属模型在转录Speech中的表现不佳，尤其是在最难的情况下。这表明，对转录Speech的作者归属需要特殊的模型和技术来解决这些挑战。<details>
<summary>Abstract</summary>
Authorship verification is the problem of determining if two distinct writing samples share the same author and is typically concerned with the attribution of written text. In this paper, we explore the attribution of transcribed speech, which poses novel challenges. The main challenge is that many stylistic features, such as punctuation and capitalization, are not available or reliable. Therefore, we expect a priori that transcribed speech is a more challenging domain for attribution. On the other hand, other stylistic features, such as speech disfluencies, may enable more successful attribution but, being specific to speech, require special purpose models. To better understand the challenges of this setting, we contribute the first systematic study of speaker attribution based solely on transcribed speech. Specifically, we propose a new benchmark for speaker attribution focused on conversational speech transcripts. To control for spurious associations of speakers with topic, we employ both conversation prompts and speakers' participating in the same conversation to construct challenging verification trials of varying difficulties. We establish the state of the art on this new benchmark by comparing a suite of neural and non-neural baselines, finding that although written text attribution models achieve surprisingly good performance in certain settings, they struggle in the hardest settings we consider.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Using-Natural-Language-Explanations-to-Improve-Robustness-of-In-context-Learning-for-Natural-Language-Inference"><a href="#Using-Natural-Language-Explanations-to-Improve-Robustness-of-In-context-Learning-for-Natural-Language-Inference" class="headerlink" title="Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference"></a>Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07556">http://arxiv.org/abs/2311.07556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanli He, Yuxiang Wu, Oana-Maria Camburu, Pasquale Minervini, Pontus Stenetorp</li>
<li>for: 本研究旨在探讨 whether 增强自然语言解释 (X-ICL) 可以提高语言模型 (LLM) 对于 seven 个难题和攻击性自然语言推理数据集的性能。</li>
<li>methods: 本研究使用了增强自然语言解释 (X-ICL) 和几个人生成的自然语言解释 (NLE) 来提高 LLM 的性能。此外，我们还提出了一种新的 ChatGPT 几个 shot 方法，即通过让 LLM 根据几个人生成的 NLE 生成更多的 NLE。</li>
<li>results: 研究发现，X-ICL 可以提高 LLM 的性能，并且 ChatGPT 几个 shot 方法比 ChatGPT 零shot 和人生成 NLE alone 更有优势。此外，我们还发现，在robustness-oriented evaluations中，prompt selection strategies 不如 X-ICL 方法的效果。<details>
<summary>Abstract</summary>
Recent studies have demonstrated that large language models (LLMs) excel in diverse tasks through in-context learning (ICL) facilitated by task-specific prompts and examples. However, the existing literature shows that ICL encounters performance deterioration when exposed to adversarial inputs. Enhanced performance has been observed when ICL is augmented with natural language explanations (NLEs) (we refer to it as X-ICL). Thus, this work investigates whether X-ICL can improve the robustness of LLMs on a suite of seven adversarial and challenging natural language inference datasets. Moreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in our case) with few human-generated NLEs to produce further NLEs (we call it ChatGPT few-shot), which we show superior to both ChatGPT zero-shot and human-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo, LLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot yields over 6% improvement over ICL. Furthermore, while prompt selection strategies were previously shown to significantly improve ICL on in-distribution test sets, we show that these strategies do not match the efficacy of the X-ICL paradigm in robustness-oriented evaluations.
</details>
<details>
<summary>摘要</summary>
In this study, we investigate whether X-ICL can improve the robustness of LLMs on a set of seven challenging natural language inference datasets that include adversarial examples. We also introduce a new approach to X-ICL called ChatGPT few-shot, which involves prompting an LLM with a few human-generated NLEs to produce additional NLEs. We compare the performance of five popular LLMs (GPT3.5-turbo, LLaMa2, Vicuna, Zephyr, and Mistral) with and without X-ICL and find that X-ICL with ChatGPT few-shot yields over 6% improvement over ICL.Furthermore, we find that prompt selection strategies, which have been shown to improve ICL on in-distribution test sets, do not perform as well as X-ICL in terms of robustness. Our results suggest that X-ICL with ChatGPT few-shot is a more effective approach to improving the robustness of LLMs on adversarial inputs.
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Multiple-Teachers-for-Test-Time-Adaptation-of-Language-Guided-Classifiers"><a href="#Leveraging-Multiple-Teachers-for-Test-Time-Adaptation-of-Language-Guided-Classifiers" class="headerlink" title="Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers"></a>Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07538">http://arxiv.org/abs/2311.07538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weikangda/talc">https://github.com/weikangda/talc</a></li>
<li>paper_authors: Kangda Wei, Sayan Ghosh, Rakesh R. Menon, Shashank Srivastava</li>
<li>for: 这个论文旨在提出一种语言引导的分类器，可以在提供任务特定的自然语言解释、说明或指令时进行分类任务。</li>
<li>methods: 这个论文使用了数据编程技术，通过多个教师的解释和无标示示例来适应新任务。</li>
<li>results: 论文的实验结果表明，TALC framework可以在提供多个教师的解释和无标示示例时，与基eline比较，具有9.3%的相对提升。此外，TALC还能够适应不同的解释质量和量的变化，这标志着其在多个教师或人群学习场景中的可靠性。<details>
<summary>Abstract</summary>
Recent approaches have explored language-guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved. Our code is available at: https://github.com/WeiKangda/TALC.git.
</details>
<details>
<summary>摘要</summary>
现有方法已经探索了语言引导的分类器，可以在提供任务特定的自然语言说明、指导或提示的情况下将示例分类（Sanh et al., 2022; R. Menon et al., 2022）。这些分类器可以在零容量设置下进行泛化，但它们在不同语言说明中的任务性能差异很大，具有不可预测的特性（Lu et al., 2022; Gonen et al., 2022）。此外，当前的方法无法利用可用的无标示例。为了解决这些问题，我们介绍了TALC框架，它使用数据编程来在推理时将语言引导的分类器适应新任务，并使用多个教师和无标测试示例进行适应。我们的结果表明，TALC在比较基eline的9.3%的相对提升下 consistently outperform（相对提升9.3%）。此外，我们还证明了TALC对提供的说明质量和量的变化不敏感，这表明它在多个教师或一群人学习场景中具有潜在的优势。我们的代码可以在：https://github.com/WeiKangda/TALC.git中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Evaluation-of-GPT-4V-on-Knowledge-Intensive-Visual-Question-Answering"><a href="#A-Comprehensive-Evaluation-of-GPT-4V-on-Knowledge-Intensive-Visual-Question-Answering" class="headerlink" title="A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering"></a>A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07536">http://arxiv.org/abs/2311.07536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunxin Li, Longyue Wang, Baotian Hu, Xinyu Chen, Wanqi Zhong, Chenyang Lyu, Min Zhang</li>
<li>for: This paper aims to evaluate the capabilities of the newly introduced GPT-4V model in visual question answering tasks, specifically in the realm of knowledge-intensive VQA tasks.</li>
<li>methods: The paper uses three perspectives to evaluate the model’s performance: Commonsense Knowledge, Fine-grained World Knowledge, and Comprehensive Knowledge with Decision-making Rationales.</li>
<li>results: The extensive experiments show that GPT-4V achieves state-of-the-art (SOTA) performance on the above three tasks, with notable improvements in reasoning and explanation when using composite images as few-shot. However, the model also exhibits severe hallucinations when dealing with world knowledge, highlighting the need for further advancements in this research direction.Here is the same information in Simplified Chinese text:</li>
<li>for: 本研究旨在评估新引入的GPT-4V模型在视觉问答任务中的能力,特别是知识集成VQA任务。</li>
<li>methods: 本研究使用三个角度评估模型性能: 通用常识知识、细化世界知识和决策理由。</li>
<li>results: 广泛的实验表明GPT-4V在上述三个任务中达到了状态之最（SOTA）性能, 其中使用复合图像作为少量时的推理和解释能力有所提升。然而，模型在世界知识方面也存在严重的幻觉现象, 反映未来在这个研究方向上需要进一步的进步。<details>
<summary>Abstract</summary>
The emergence of multimodal large models (MLMs) has significantly advanced the field of visual understanding, offering remarkable capabilities in the realm of visual question answering (VQA). Yet, the true challenge lies in the domain of knowledge-intensive VQA tasks, which necessitate not just recognition of visual elements, but also a deep comprehension of the visual information in conjunction with a vast repository of learned knowledge. To uncover such capabilities of MLMs, particularly the newly introduced GPT-4V, we provide an in-depth evaluation from three perspectives: 1) Commonsense Knowledge, which assesses how well models can understand visual cues and connect to general knowledge; 2) Fine-grained World Knowledge, which tests the model's skill in reasoning out specific knowledge from images, showcasing their proficiency across various specialized fields; 3) Comprehensive Knowledge with Decision-making Rationales, which examines model's capability to provide logical explanations for its inference, facilitating a deeper analysis from the interpretability perspective. Extensive experiments indicate that GPT-4V achieves SOTA performance on above three tasks. Interestingly, we find that: a) GPT-4V demonstrates enhanced reasoning and explanation when using composite images as few-shot; b) GPT-4V produces severe hallucinations when dealing with world knowledge, highlighting the future need for advancements in this research direction.
</details>
<details>
<summary>摘要</summary>
随着多模态大型模型（MLM）的出现，视觉理解领域得到了极大的进步，特别是在视觉问答（VQA）领域。然而，真正的挑战在于知识导向的VQA任务，需要不仅识别视觉元素，而且还需要深入理解视觉信息并与大量学习知识相结合。为了探索MLMs的真正能力，特别是新引入的GPT-4V，我们提供了三个视角的深入评估：1）通用常识，评估模型如何理解视觉提示并与通用知识相连接; 2）细腻世界知识，测试模型在图像中特定知识的逻辑推理能力，展示其在多个专业领域中的掌握能力; 3）全面知识与决策逻辑，评估模型对其推理的解释能力，促进对其解释的深入分析。广泛的实验表明GPT-4V在以上三个任务中达到了最高的表现。有趣的是，我们发现：a）GPT-4V在几何图像作为少量例子时展现出更高的逻辑推理和解释能力; b）GPT-4V在world知识方面存在严重的幻觉现象，表明未来在这个研究方向上需要进一步的进步。
</details></li>
</ul>
<hr>
<h2 id="It’s-Not-Easy-Being-Wrong-Evaluating-Process-of-Elimination-Reasoning-in-Large-Language-Models"><a href="#It’s-Not-Easy-Being-Wrong-Evaluating-Process-of-Elimination-Reasoning-in-Large-Language-Models" class="headerlink" title="It’s Not Easy Being Wrong: Evaluating Process of Elimination Reasoning in Large Language Models"></a>It’s Not Easy Being Wrong: Evaluating Process of Elimination Reasoning in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07532">http://arxiv.org/abs/2311.07532</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nbalepur/poe">https://github.com/nbalepur/poe</a></li>
<li>paper_authors: Nishant Balepur, Shramay Palta, Rachel Rudinger</li>
<li>for: 这个研究旨在测试大语言模型（LLM）是否可以通过链接思考（COT）来推理正确答案，以及这种方法在推理错误答案时的效果。</li>
<li>methods: 这个研究使用了链接思考（COT）和排除过程（PoE）的结合，让LLMs需要在多个选项中推理 incorrect options。</li>
<li>results: 研究发现，使用PoE with COT的能力在2选1的常识和科学推理 datasets 上具有较差的表现，并且这些策略之间的一致性较低。研究还进行了错误分析，并提供了未来工作的建议。<details>
<summary>Abstract</summary>
Chain-of-thought (COT) prompting can help large language models (LLMs) reason toward correct answers, but its efficacy in reasoning toward incorrect answers is unexplored. This strategy of process of elimination (PoE), when used with COT, has the potential to enhance interpretability in tasks like medical diagnoses of exclusion. Thus, we propose PoE with COT, a new task where LLMs must reason toward incorrect options on multiple-choice questions. We evaluate the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice commonsense and scientific reasoning datasets. We show that PoE consistently underperforms directly choosing the correct answer. The agreement of these strategies is also lower than the self-consistency of each strategy. To study these issues further, we conduct an error analysis and give suggestions for future work.
</details>
<details>
<summary>摘要</summary>
链式思维（COT）提问可以帮助大型语言模型（LLM）到达正确答案，但其在 incorrect answers 上的效果未经探索。这种进程消除（PoE）策略，当用于 COT，有可能增强解释性在任务如医疗诊断排除中。因此，我们提议 PoE with COT，一种新的任务，要求 LLM 在多选问题上进行 incorrect options 的理解。我们使用 GPT-3.5、LLaMA-2 和 Falcon 来评估这些模型在 2 选常识和科学理解数据集上的表现。我们发现，PoE 通常下perform directly choosing the correct answer 。这些策略之间的一致性也比每个策略自我一致性低。为了更深入地研究这些问题，我们进行了错误分析并提供了未来工作的建议。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Nonce-Dependency-Treebanks-Understanding-how-LLMs-represent-and-process-syntactic-structure"><a href="#Multilingual-Nonce-Dependency-Treebanks-Understanding-how-LLMs-represent-and-process-syntactic-structure" class="headerlink" title="Multilingual Nonce Dependency Treebanks: Understanding how LLMs represent and process syntactic structure"></a>Multilingual Nonce Dependency Treebanks: Understanding how LLMs represent and process syntactic structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07497">http://arxiv.org/abs/2311.07497</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Arps, Laura Kallmeyer, Younes Samih, Hassan Sajjad</li>
<li>for: 这个论文是为了创建多语言 универсаль dependencies（UD） corpora 的非常扩展（SPUD）框架。</li>
<li>methods: 这个论文使用语义扰动的方法创建非常扩展数据，并遵循语言特定的规则进行语法注释。</li>
<li>results: 研究人员通过使用 SPUD 框架创建了阿拉伯语、英语、法语、德语和俄语等多种语言的非常扩展数据。并对这些数据进行了两个使用场景的研究：首先，研究非常扩展数据对单词共occurrence统计的影响，通过对 autoregressive（ALM）和 masked language models（MLM）的 perplexity 分布进行比较。其次，研究非常扩展数据对语法依赖探测器的影响，并复制了 M&quot;uller-Eberstein et al. (2022) 的研究结果。<details>
<summary>Abstract</summary>
We introduce SPUD (Semantically Perturbed Universal Dependencies), a framework for creating nonce treebanks for the multilingual Universal Dependencies (UD) corpora. SPUD data satisfies syntactic argument structure, provides syntactic annotations, and ensures grammaticality via language-specific rules. We create nonce data in Arabic, English, French, German, and Russian, and demonstrate two use cases of SPUD treebanks. First, we investigate the effect of nonce data on word co-occurrence statistics, as measured by perplexity scores of autoregressive (ALM) and masked language models (MLM). We find that ALM scores are significantly more affected by nonce data than MLM scores. Second, we show how nonce data affects the performance of syntactic dependency probes. We replicate the findings of M\"uller-Eberstein et al. (2022) on nonce test data and show that the performance declines on both MLMs and ALMs wrt. original test data. However, a majority of the performance is kept, suggesting that the probe indeed learns syntax independently from semantics.
</details>
<details>
<summary>摘要</summary>
我们介绍SPUD（semantically perturbed universal dependencies）框架，用于创建多语言 universal dependencies（UD） corpora 的非常数据。SPUD 数据满足语义上的结构、提供语法注释，并通过语言特定规则确保语法正确性。我们在阿拉伯语、英语、法语、德语和俄语等语言中创建了非常数据，并对 SPUD 树 banks 进行了两种应用场景的示例。首先，我们研究非常数据对单词共occurrence 统计的影响，通过对 autoregressive（ALM）和 masked language models（MLM）的抑���阶准确度进行评估。我们发现，ALM  scores 比 MLM scores 更sensitive 于非常数据。其次，我们显示了非常数据对语法依赖探测器的影响。我们重复了 M\"uller-Eberstein et al. (2022) 的研究结果，并发现在原始测试数据上，MLMs 和 ALMs 的性能均下降。然而，大多数性能仍然保留，表明探测器实际上学习了语法独立于 semantics。
</details></li>
</ul>
<hr>
<h2 id="A-Step-Closer-to-Comprehensive-Answers-Constrained-Multi-Stage-Question-Decomposition-with-Large-Language-Models"><a href="#A-Step-Closer-to-Comprehensive-Answers-Constrained-Multi-Stage-Question-Decomposition-with-Large-Language-Models" class="headerlink" title="A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models"></a>A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07491">http://arxiv.org/abs/2311.07491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hejing Cao, Zhenwei An, Jiazhan Feng, Kun Xu, Liwei Chen, Dongyan Zhao</li>
<li>for: 这个论文目的是解决大语言模型在问答任务中容易做出幻见的问题。</li>
<li>methods: 这个论文提出了一种”解构并问”（Decompose-and-Query）框架，该框架使模型能够像ReAct一样利用外部知识，同时也限制模型的思考范围，以避免幻见的风险。</li>
<li>results: 实验表明，D&amp;Q可以减少大语言模型在问答任务中的幻见风险，在ChitChatQA dataset上，D&amp;Q不落后于ChatGPT的67%情况下表现优于ChatGPT，在HotPotQA问题只设置下，D&amp;Q的F1分数达59.6%。<details>
<summary>Abstract</summary>
While large language models exhibit remarkable performance in the Question Answering task, they are susceptible to hallucinations. Challenges arise when these models grapple with understanding multi-hop relations in complex questions or lack the necessary knowledge for a comprehensive response. To address this issue, we introduce the "Decompose-and-Query" framework (D&Q). This framework guides the model to think and utilize external knowledge similar to ReAct, while also restricting its thinking to reliable information, effectively mitigating the risk of hallucinations. Experiments confirm the effectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT in 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1 score of 59.6%. Our code is available at https://github.com/alkaidpku/DQ-ToolQA.
</details>
<details>
<summary>摘要</summary>
大型语言模型在问答任务中表现出色，但它们容易受到幻视的影响。问题的多步关系和模型缺乏必要的知识会导致模型产生不准确的答案。为解决这个问题，我们提出了“分解并询问”（D&Q）框架。这个框架帮助模型思考和使用外部知识，同时限制模型的思考范围仅对可靠的信息，彻底降低幻视的风险。实验表明，D&Q与ChatGPT在67%的情况下不落后，在HotPotQA问题只设置（question-only）中，D&Q的F1分数为59.6%。我们的代码可以在https://github.com/alkaidpku/DQ-ToolQA上获取。
</details></li>
</ul>
<hr>
<h2 id="Finding-and-Editing-Multi-Modal-Neurons-in-Pre-Trained-Transformer"><a href="#Finding-and-Editing-Multi-Modal-Neurons-in-Pre-Trained-Transformer" class="headerlink" title="Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer"></a>Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07470">http://arxiv.org/abs/2311.07470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haowen Pan, Yixin Cao, Xiaozhi Wang, Xun Yang</li>
<li>for: 这 paper 的目的是研究 transformer 型多Modal LLM 如何处理多种模式的信息，以及如何在这些模式之间进行协同工作。</li>
<li>methods: 这 paper 使用了一种新的方法来标识 transformer 型多Modal LLM 中的多Modal neuron，并通过一系列实验描述了这些 neuron 的三个关键特性。</li>
<li>results: 这 paper 的研究结果表明，通过使用这种新的方法，可以帮助更好地理解 transformer 型多Modal LLM 如何处理多种模式的信息，并且可以通过修改特定的 token 来实现更好的协同工作。<details>
<summary>Abstract</summary>
Multi-modal large language models (LLM) have achieved powerful capabilities for visual semantic understanding in recent years. However, little is known about how LLMs comprehend visual information and interpret different modalities of features. In this paper, we propose a new method for identifying multi-modal neurons in transformer-based multi-modal LLMs. Through a series of experiments, We highlight three critical properties of multi-modal neurons by four well-designed quantitative evaluation metrics. Furthermore, we introduce a knowledge editing method based on the identified multi-modal neurons, for modifying a specific token to another designative token. We hope our findings can inspire further explanatory researches on understanding mechanisms of multi-modal LLMs.
</details>
<details>
<summary>摘要</summary>
多modal大语言模型（LLM）在过去几年内实现了视觉semantic理解的强大能力。然而，对于LLM如何理解视觉信息以及不同modalities的特征 interpretations的知识很少。在这篇论文中，我们提出了一种新的方法来确定 transformer-based multi-modal LLM中的多modal нейроны。通过一系列实验，我们高亮了这些多modal нейроны的三个重要特性，并通过四种Well-designed量化评价指标来评估它们。此外，我们还介绍了基于被确定的多modal нейроны的知识编辑方法，可以修改特定的token到另一个特定的token。我们希望我们的发现可以激励更多的研究人员进行对多modal LLM的理解机制进行解释。
</details></li>
</ul>
<hr>
<h2 id="MEGAVERSE-Benchmarking-Large-Language-Models-Across-Languages-Modalities-Models-and-Tasks"><a href="#MEGAVERSE-Benchmarking-Large-Language-Models-Across-Languages-Modalities-Models-and-Tasks" class="headerlink" title="MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks"></a>MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07463">http://arxiv.org/abs/2311.07463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Maxamed Axmed, Kalika Bali, Sunayana Sitaram</li>
<li>for: 本研究旨在扩展MEGA benchmarking suite，包括6个新数据集，组成MEGAVERSE benchmark，覆盖81种语言，包括低资源非洲语言。</li>
<li>methods: 本研究使用了several state-of-the-art LLMs，如GPT-3.5-Turbo、GPT4、PaLM2和Llama2，对MEGAVERSE datasets进行评估。此外，还包括了两个多模式数据集，评估LLaVa-v1.5模型的表现。</li>
<li>results: 实验结果显示，GPT4和PaLM2在各种任务中表现出色，特别是在低资源语言上表现出优异，GPT4在更多的数据集上than PaLM2表现出优异。然而，数据污染问题需要解决，以确保对非英语语言LLM性能的准确评估。<details>
<summary>Abstract</summary>
Recently, there has been a rapid advancement in research on Large Language Models (LLMs), resulting in significant progress in several Natural Language Processing (NLP) tasks. Consequently, there has been a surge in LLM evaluation research to comprehend the models' capabilities and limitations. However, much of this research has been confined to the English language, leaving LLM building and evaluation for non-English languages relatively unexplored. There has been an introduction of several new LLMs, necessitating their evaluation on non-English languages. This study aims to expand our MEGA benchmarking suite by including six new datasets to form the MEGAVERSE benchmark. The benchmark comprises 22 datasets covering 81 languages, including low-resource African languages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4, PaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two multimodal datasets in the benchmark and assess the performance of the LLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the Llama models on various tasks, notably on low-resource languages, with GPT4 outperforming PaLM2 on more datasets than vice versa. However, issues such as data contamination must be addressed to obtain an accurate assessment of LLM performance on non-English languages.
</details>
<details>
<summary>摘要</summary>
近些时候，大语言模型（LLM）的研究得到了快速发展，导致了许多自然语言处理（NLP）任务的重要进步。然而，大多数这些研究都是在英语语言上进行的，因此非英语语言的LLM建构和评估还很少被探索。随着新的LLM的出现，需要对这些模型进行评估。本研究的目标是扩展我们的MEGA benchmarking suite，包括6个新的数据集，组成MEGAVERSE benchmark。该benchmark包括81种语言的22个数据集，包括低资源非洲语言。我们评估了一些当前最佳的LLM，如GPT-3.5-Turbo、GPT4、PaLM2和Llama2在MEGAVERSE数据集上的表现。此外，我们还包括了两个多Modal数据集，评估LLaVa-v1.5模型的表现。我们的实验表明，GPT4和PaLM2在不同任务上表现出色，特别是在低资源语言上。然而，需要解决数据杂杂问题，以获得LLM在非英语语言上的准确评估。
</details></li>
</ul>
<hr>
<h2 id="ChartCheck-An-Evidence-Based-Fact-Checking-Dataset-over-Real-World-Chart-Images"><a href="#ChartCheck-An-Evidence-Based-Fact-Checking-Dataset-over-Real-World-Chart-Images" class="headerlink" title="ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World Chart Images"></a>ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World Chart Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07453">http://arxiv.org/abs/2311.07453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mubashara Akhtar, Nikesh Subedi, Vivek Gupta, Sahar Tahmasebi, Oana Cocarascu, Elena Simperl</li>
<li>for: 这篇论文是用来探讨如何验证图表上的说法的。</li>
<li>methods: 这篇论文使用了一个新的图表验证集合（ChartCheck），该集合包含1.7万个真实世界图表和10.5万个人写的说法和解释。</li>
<li>results: 在使用state-of-the-art模型进行评估后，该研究在finetuned设置下达到了73.9%的准确率。此外，研究还发现了图表特征和逻辑类型，对模型带来挑战。<details>
<summary>Abstract</summary>
Data visualizations are common in the real-world. We often use them in data sources such as scientific documents, news articles, textbooks, and social media to summarize key information in a visual form. Charts can also mislead its audience by communicating false information or biasing them towards a specific agenda. Verifying claims against charts is not a straightforward process. It requires analyzing both the text and visual components of the chart, considering characteristics such as colors, positions, and orientations. Moreover, to determine if a claim is supported by the chart content often requires different types of reasoning. To address this challenge, we introduce ChartCheck, a novel dataset for fact-checking against chart images. ChartCheck is the first large-scale dataset with 1.7k real-world charts and 10.5k human-written claims and explanations. We evaluated the dataset on state-of-the-art models and achieved an accuracy of 73.9 in the finetuned setting. Additionally, we identified chart characteristics and reasoning types that challenge the models.
</details>
<details>
<summary>摘要</summary>
数据视觉是现实中非常普遍的。我们常常在数据来源 such as 科学文献、新闻文章、教科书和社交媒体上使用它们，以概括关键信息在视觉形式下。但是，图表也可能会误导其audience，通过传递false信息或推动特定的议程。验证图表上的clam是一项复杂的过程，需要分析图表的文本和视觉组成部分，考虑颜色、位置和方向等特征。此外，以确定一个说法是否由图表内容支持，经常需要不同类型的推理。为解决这个挑战，我们提出了 ChartCheck，一个大规模的实际图表验证数据集。ChartCheck包含1.7k个实际图表和10.5k个人写的说法和解释。我们在现有模型上进行评估，在finetuned设置下达到了73.9%的准确率。此外，我们还发现了图表特征和推理类型，对模型带来挑战。
</details></li>
</ul>
<hr>
<h2 id="Controlled-Text-Generation-for-Black-box-Language-Models-via-Score-based-Progressive-Editor"><a href="#Controlled-Text-Generation-for-Black-box-Language-Models-via-Score-based-Progressive-Editor" class="headerlink" title="Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor"></a>Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07430">http://arxiv.org/abs/2311.07430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwon Yu, Changmin Lee, Hojin Lee, Sungroh Yoon</li>
<li>for: 这篇论文旨在提供一种控制文本生成方法，以便在特定领域中使用黑盒语言模型生成控制文本。</li>
<li>methods: 该方法基于ScoPE（得分进行推进编辑）生成器，通过在语言模型的泛化预测过程中隐藏层次地进行编辑，以实现控制文本生成。</li>
<li>results: 实验结果表明，ScoPE可以有效地在黑盒语言模型中进行控制文本生成，并且可以在不同的控制条件下进行多种类型的生成，包括在领域内和领域外的情况下。<details>
<summary>Abstract</summary>
Despite recent progress in language models, generating constrained text for specific domains remains a challenge, particularly when utilizing black-box models that lack domain-specific knowledge. In this paper, we introduce ScoPE (Score-based Progressive Editor) generation, a novel approach for controlled text generation for black-box language models. We employ ScoPE to facilitate text generation in the target domain by integrating it with language models through a cascading approach. Trained to enhance the target domain score of the edited text, ScoPE progressively edits intermediate output discrete tokens to align with the target attributes throughout the auto-regressive generation process of the language model. This iterative process guides subsequent steps to produce desired output texts for the target domain. Our experimental results on diverse controlled generations demonstrate that ScoPE effectively facilitates controlled text generation for black-box language models in both in-domain and out-of-domain conditions, which is challenging for existing methods.
</details>
<details>
<summary>摘要</summary>
尽管最近的语言模型进步很大，但在特定领域中生成受限的文本仍然是一个挑战，特别是当使用黑盒模型，这些模型缺乏特定领域的知识。在这篇论文中，我们介绍了ScoPE（Score-based Progressive Editor）生成器，一种新的控制文本生成方法。我们将ScoPE与语言模型结合起来，通过级联方式进行整合。ScoPE在编辑过程中采用分数基于的进度编辑策略，通过提高目标领域的分数来编辑批处理的中间输出整数。这种迭代过程导向后续步骤生成所需的输出文本。我们的实验结果表明，ScoPE可以有效地在黑盒语言模型中进行控制文本生成，包括在预测领域和外部领域的情况下。这是现有方法所不能做的。
</details></li>
</ul>
<hr>
<h2 id="Speech-based-Slot-Filling-using-Large-Language-Models"><a href="#Speech-based-Slot-Filling-using-Large-Language-Models" class="headerlink" title="Speech-based Slot Filling using Large Language Models"></a>Speech-based Slot Filling using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07418">http://arxiv.org/abs/2311.07418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangzhi Sun, Shutong Feng, Dongcheng Jiang, Chao Zhang, Milica Gašić, Philip C. Woodland</li>
<li>for: investigating the potential application of large language models (LLMs) to slot filling with noisy ASR transcriptions</li>
<li>methods: in-context learning, task-specific fine-tuning, dedicated prompt designs, and linearised knowledge injection (LKI) scheme</li>
<li>results: an 8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline system on a limited data setup, achieved by using the proposed fine-tuning together with the LKI scheme for LLaMA-13B.<details>
<summary>Abstract</summary>
Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated prompt designs and fine-tuning approaches are proposed to improve the robustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a linearised knowledge injection (LKI) scheme is also proposed to integrate dynamic external knowledge into LLMs. Experiments were performed on SLURP to quantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and Vicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the proposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an 8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline system on a limited data setup.
</details>
<details>
<summary>摘要</summary>
最近，大型语言模型（LLM）的进步在不同语言任务上显示出无 precedent 的能力。这篇论文研究了使用 LLM 进行插入式学习和任务特定微调来应对噪音 ASR 转录的插入问题。提议了专门的提示设计和微调方法以提高 LLM 的 robustness。此外，还提出了一种线性知识批注（LKI）方案，以 integrating 动态外部知识到 LLM 中。在 SLURP 上进行了实验，测试了不同 ASR 错误率下 LLM 的性能，包括 GPT-3.5-turbo、GPT-4、LLaMA-13B 和 Vicuna-13B（v1.1和v1.5）。结果显示，使用提议的微调和 LKI 方案，LLaMA-13B 在限制数据设置下与强基准系统 Flan-T5-base 相比，提高了8.3%的 SLU-F1 精度。
</details></li>
</ul>
<hr>
<h2 id="An-LLM-free-Multi-dimensional-Benchmark-for-MLLMs-Hallucination-Evaluation"><a href="#An-LLM-free-Multi-dimensional-Benchmark-for-MLLMs-Hallucination-Evaluation" class="headerlink" title="An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation"></a>An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07397">http://arxiv.org/abs/2311.07397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junyangwang0410/amber">https://github.com/junyangwang0410/amber</a></li>
<li>paper_authors: Junyang Wang, Yuhang Wang, Guohai Xu, Jing Zhang, Yukai Gu, Haitao Jia, Ming Yan, Ji Zhang, Jitao Sang</li>
<li>For: 评估多模态语言模型（MLLM）的幻觉，以提高模型改进和实际应用部署。* Methods: 提出了一个免费的多维度评估平台AMBER，可以用于评估生成任务和分类任务中的幻觉，包括物体存在、物体属性和物体关系幻觉。* Results: 通过使用AMBER评估pipeline，对主流MLLMs进行了全面的评估和细化分析，并提供了mitigating幻觉的指导建议。<details>
<summary>Abstract</summary>
Despite making significant progress in multi-modal tasks, current Multi-modal Large Language Models (MLLMs) encounter the significant challenge of hallucination, which may lead to harmful consequences. Therefore, evaluating MLLMs' hallucinations is becoming increasingly important in model improvement and practical application deployment. Previous works are limited in high evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient evaluation dimensions (e.g., types of hallucination and task). In this paper, we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to evaluate both generative task and discriminative task including object existence, object attribute and object relation hallucination. Based on AMBER, we design a low-cost and efficient evaluation pipeline. Additionally, we conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs including GPT-4V(ision), and also give guideline suggestions for mitigating hallucinations. The data and code of AMBER are available at https://github.com/junyangwang0410/AMBER.
</details>
<details>
<summary>摘要</summary>
尽管现代多模态语言模型（MLLMs）已取得了显著进步，但它们仍面临较大的幻觉挑战，这可能会导致有害的后果。因此，评估MLLMs的幻觉变得越来越重要，以便提高模型和实际应用的评估。先前的工作受到高评估成本（如人工或高级LLLMs）和不够的评估维度（如幻觉类型和任务）的限制。在这篇论文中，我们提出了一个LLLM-free的多维度标准Benchmark AMBER，可以用于评估生成任务和推理任务，包括对象存在、对象特征和对象关系幻觉。基于AMBER，我们设计了一个低成本、高效的评估管道。此外，我们对主流MLLMs，如GPT-4V(ision)进行了全面的评估和详细的分析，并提供了适应幻觉的指导建议。AMBER的数据和代码可以在GitHub上获取：https://github.com/junyangwang0410/AMBER。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Logical-Puzzle-Solving-in-Large-Language-Models-Insights-from-a-Minesweeper-Case-Study"><a href="#Assessing-Logical-Puzzle-Solving-in-Large-Language-Models-Insights-from-a-Minesweeper-Case-Study" class="headerlink" title="Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study"></a>Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07387">http://arxiv.org/abs/2311.07387</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yinghao-li/minesweeper-for-llm">https://github.com/yinghao-li/minesweeper-for-llm</a></li>
<li>paper_authors: Yinghao Li, Haorui Wang, Chao Zhang</li>
<li>for: 测试LLMs的推理和观念能力</li>
<li>methods: 使用特定任务的精革定或提示工程来测试LLMs的语言理解能力</li>
<li>results: LLMs具有基本的推理和观念能力，但对于Minesweeper任务还是困难将多步骤逻辑思考转化为实际行动<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown remarkable proficiency in language understanding and have been successfully applied to a variety of real-world tasks through task-specific fine-tuning or prompt engineering. Despite these advancements, it remains an open question whether LLMs are fundamentally capable of reasoning and planning, or if they primarily rely on recalling and synthesizing information from their training data. In our research, we introduce a novel task -- Minesweeper -- specifically designed in a format unfamiliar to LLMs and absent from their training datasets. This task challenges LLMs to identify the locations of mines based on numerical clues provided by adjacent opened cells. Successfully completing this task requires an understanding of each cell's state, discerning spatial relationships between the clues and mines, and strategizing actions based on logical deductions drawn from the arrangement of the cells. Our experiments, including trials with the advanced GPT-4 model, indicate that while LLMs possess the foundational abilities required for this task, they struggle to integrate these into a coherent, multi-step logical reasoning process needed to solve Minesweeper. These findings highlight the need for further research to understand and nature of reasoning capabilities in LLMs under similar circumstances, and to explore pathways towards more sophisticated AI reasoning and planning models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LM-Polygraph-Uncertainty-Estimation-for-Language-Models"><a href="#LM-Polygraph-Uncertainty-Estimation-for-Language-Models" class="headerlink" title="LM-Polygraph: Uncertainty Estimation for Language Models"></a>LM-Polygraph: Uncertainty Estimation for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07383">http://arxiv.org/abs/2311.07383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ekaterina Fadeeva, Roman Vashurin, Akim Tsvigun, Artem Vazhentsev, Sergey Petrakov, Kirill Fedyanin, Daniil Vasilev, Elizaveta Goncharova, Alexander Panchenko, Maxim Panov, Timothy Baldwin, Artem Shelmanov</li>
<li>for: 提高大语言模型的安全、责任和有效性，解决LLMs“妄想”问题</li>
<li>methods: 引入了一系列 state-of-the-art  uncertainty estimation（UE）方法，包括Python程序接口</li>
<li>results: 提供了一个可扩展的测试 benchmark，以及一个演示应用程序，增加了标准对话框架中的信任分数，帮助用户识别不可靠回答<details>
<summary>Abstract</summary>
Recent advancements in the capabilities of large language models (LLMs) have paved the way for a myriad of groundbreaking applications in various fields. However, a significant challenge arises as these models often "hallucinate", i.e., fabricate facts without providing users an apparent means to discern the veracity of their statements. Uncertainty estimation (UE) methods are one path to safer, more responsible, and more effective use of LLMs. However, to date, research on UE methods for LLMs has been focused primarily on theoretical rather than engineering contributions. In this work, we tackle this issue by introducing LM-Polygraph, a framework with implementations of a battery of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, it introduces an extendable benchmark for consistent evaluation of UE techniques by researchers, and a demo web application that enriches the standard chat dialog with confidence scores, empowering end-users to discern unreliable responses. LM-Polygraph is compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs.
</details>
<details>
<summary>摘要</summary>
In this work, we aim to tackle this challenge by introducing LM-Polygraph, a framework that implements a variety of state-of-the-art UE methods for LLMs in text generation tasks, with unified program interfaces in Python. Additionally, we provide an extendable benchmark for consistent evaluation of UE techniques by researchers, as well as a demo web application that enriches standard chat dialogs with confidence scores, empowering end-users to distinguish unreliable responses.LM-Polygraph is compatible with the latest LLMs, including BLOOMz, LLaMA-2, ChatGPT, and GPT-4, and is designed to support future releases of similarly-styled LMs. By providing a practical solution for UE in LLMs, we hope to promote safer, more responsible, and more effective use of these models in a wide range of applications.
</details></li>
</ul>
<hr>
<h2 id="Volcano-Mitigating-Multimodal-Hallucination-through-Self-Feedback-Guided-Revision"><a href="#Volcano-Mitigating-Multimodal-Hallucination-through-Self-Feedback-Guided-Revision" class="headerlink" title="Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision"></a>Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07362">http://arxiv.org/abs/2311.07362</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kaistai/volcano">https://github.com/kaistai/volcano</a></li>
<li>paper_authors: Seongyun Lee, Sue Hyun Park, Yongrae Jo, Minjoon Seo</li>
<li>for: 本研究目的是解决大型多模态模型（LMMs）中的多模态幻觉问题，即模型提供错误的响应与给定的视觉信息不匹配。</li>
<li>methods: 我们提出了一种新的方法，即利用自我反馈作为视觉cue。我们基于这种方法提出了一种名为“火山”的多模态自适应修订模型，该模型可以根据给定的视觉信息生成自然语言反馈，并使用这些反馈进行自适应修订。</li>
<li>results: 我们的模型在MMHal-Bench、POPE和GAVIE上实现了状态的最佳性，并且在通用多模态能力方面也进步了。我们还通过质量分析表明，火山的反馈比初始响应更加靠近图像，这表明火山可以提供更多的视觉信息，帮助缓解多模态幻觉。我们在<a target="_blank" rel="noopener" href="https://github.com/kaistAI/Volcano%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E4%BA%86%E7%81%AB%E5%B1%B1%E6%A8%A1%E5%9E%8B%E7%9A%847B%E5%92%8C13B%E7%89%88%E6%9C%AC%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%92%8C%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/kaistAI/Volcano上公开发布了火山模型的7B和13B版本，以及数据和代码。</a><details>
<summary>Abstract</summary>
Large multimodal models (LMMs) suffer from multimodal hallucination, where they provide incorrect responses misaligned with the given visual information. Recent works have conjectured that one of the reasons behind multimodal hallucination might be due to the vision encoder failing to ground on the image properly. To mitigate this issue, we propose a novel approach that leverages self-feedback as visual cues. Building on this approach, we introduce Volcano, a multimodal self-feedback guided revision model. Volcano generates natural language feedback to its initial response based on the provided visual information and utilizes this feedback to self-revise its initial response. Volcano effectively reduces multimodal hallucination and achieves state-of-the-art on MMHal-Bench, POPE, and GAVIE. It also improves on general multimodal abilities and outperforms previous models on MM-Vet and MMBench. Through a qualitative analysis, we show that Volcano's feedback is properly grounded on the image than the initial response. This indicates that Volcano can provide itself with richer visual information, helping alleviate multimodal hallucination. We publicly release Volcano models of 7B and 13B sizes along with the data and code at https://github.com/kaistAI/Volcano.
</details>
<details>
<summary>摘要</summary>
大型多模式模型（LMM）受到多模式幻觉的影响，即提供错误的回应不符合给定的视觉信息。近期研究认为，这可能是由视觉编码器无法固定到图像而导致的。为解决这个问题，我们提出了一种新的方法，即利用自身反馈作为视觉cue。基于这种方法，我们介绍了一种新的多模式自 feedbac k revisions 模型——火山。火山生成基于提供的视觉信息的自然语言反馈，并使用这些反馈来自 revision 其初始回应。火山有效地减少多模式幻觉，并在 MMHal-Bench、POPE 和 GAVIE 上达到了领先的状态。它还在通用多模式能力方面进步，并在 MM-Vet 和 MMBench 上超越了前一代模型。通过质量分析，我们显示了火山的反馈是与图像更加固定的，这表明火山可以提供更多的视觉信息，帮助消除多模式幻觉。我们在 GitHub 上公开了火山模型的7B和13B版本，以及相关数据和代码。
</details></li>
</ul>
<hr>
<h2 id="BIDRN-A-Method-of-Bidirectional-Recurrent-Neural-Network-for-Sentiment-Analysis"><a href="#BIDRN-A-Method-of-Bidirectional-Recurrent-Neural-Network-for-Sentiment-Analysis" class="headerlink" title="BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment Analysis"></a>BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07296">http://arxiv.org/abs/2311.07296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dr. D Muthusankar, Dr. P Kaladevi, Dr. V R Sadasivam, R Praveen<br>for: This paper aims to provide a systematic framework for sentiment analysis in the context of student input on institution choice.methods: The study employs Deep Bidirectional Recurrent Neural Networks (BDRNNs) to analyze sentiment and generate a dataset with sentiment labels.results: The proposed SA-BDRNN Scheme is compared to existing frameworks to establish a robust deep neural network that can serve as an adequate classification model in sentiment analysis.<details>
<summary>Abstract</summary>
Text mining research has grown in importance in recent years due to the tremendous increase in the volume of unstructured textual data. This has resulted in immense potential as well as obstacles in the sector, which may be efficiently addressed with adequate analytical and study methods. Deep Bidirectional Recurrent Neural Networks are used in this study to analyze sentiment. The method is categorized as sentiment polarity analysis because it may generate a dataset with sentiment labels. This dataset can be used to train and evaluate sentiment analysis models capable of extracting impartial opinions. This paper describes the Sentiment Analysis-Deep Bidirectional Recurrent Neural Networks (SA-BDRNN) Scheme, which seeks to overcome the challenges and maximize the potential of text mining in the context of Big Data. The current study proposes a SA-DBRNN Scheme that attempts to give a systematic framework for sentiment analysis in the context of student input on institution choice. The purpose of this study is to compare the effectiveness of the proposed SA- DBRNN Scheme to existing frameworks to establish a robust deep neural network that might serve as an adequate classification model in the field of sentiment analysis.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:文本挖掘研究在最近几年内得到了越来越多的重要性，这是因为各种不结构化的文本数据的量增加了惊人的幅度。这种情况带来了很大的潜在和障碍，这些障碍可以通过适当的分析和研究方法有效地解决。这里使用的深度卷积神经网络（DBRNN）是用于情感分析的。这种方法被称为情感极性分析，因为它可以生成带有情感标签的数据集。这个数据集可以用来训练和评估情感分析模型，以EXTRACTING偏见的意见。这篇论文描述了对文本挖掘在大数据时代的SA-DBRNN方案，这种方案旨在解决文本挖掘领域中的挑战并充分发挥其潜在。现study提出了一种基于SA-DBRNN的方案，以便在学生选择机构的输入中进行情感分析。本研究的目的是比较SA-DBRNN方案与现有框架的效果，以建立一个robust的深度神经网络，用于情感分析领域的分类模型。
</details></li>
</ul>
<hr>
<h2 id="AdaCCD-Adaptive-Semantic-Contrasts-Discovery-based-Cross-Lingual-Adaptation-for-Code-Clone-Detection"><a href="#AdaCCD-Adaptive-Semantic-Contrasts-Discovery-based-Cross-Lingual-Adaptation-for-Code-Clone-Detection" class="headerlink" title="AdaCCD: Adaptive Semantic Contrasts Discovery based Cross Lingual Adaptation for Code Clone Detection"></a>AdaCCD: Adaptive Semantic Contrasts Discovery based Cross Lingual Adaptation for Code Clone Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07277">http://arxiv.org/abs/2311.07277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangkai Du, Tengfei Ma, Lingfei Wu, Xuhong Zhang, Shouling Ji</li>
<li>for: 本研究旨在提高现代软件中代码冗余检测的效果，特别是在多种编程语言的情况下。</li>
<li>methods: 本文提出了一种名为AdaCCD的新方法，该方法可以在没有新语言的注释的情况下检测代码冗余。AdaCCD利用了预训练的编程语言模型来获得语言不可见代码表示，并提出了一种适应性提升对冲学习框架来传递知识从资源丰富的语言到资源缺乏的语言。</li>
<li>results: 根据多种编程语言的多语言代码冗余检测 benchmark，AdaCCD 的跨语言适应结果显著超过了其他基eline，甚至与精心微调相当。<details>
<summary>Abstract</summary>
Code Clone Detection, which aims to retrieve functionally similar programs from large code bases, has been attracting increasing attention. Modern software often involves a diverse range of programming languages. However, current code clone detection methods are generally limited to only a few popular programming languages due to insufficient annotated data as well as their own model design constraints. To address these issues, we present AdaCCD, a novel cross-lingual adaptation method that can detect cloned codes in a new language without any annotations in that language. AdaCCD leverages language-agnostic code representations from pre-trained programming language models and propose an Adaptively Refined Contrastive Learning framework to transfer knowledge from resource-rich languages to resource-poor languages. We evaluate the cross-lingual adaptation results of AdaCCD by constructing a multilingual code clone detection benchmark consisting of 5 programming languages. AdaCCD achieves significant improvements over other baselines, and it is even comparable to supervised fine-tuning.
</details>
<details>
<summary>摘要</summary>
<<SYSCODESYS>>Code Clone Detection，目标是从大型代码库中检索功能相似的程序，在现代软件中变得越来越受到关注。然而，当前的代码副本检测方法通常只能处理其中一些流行的编程语言。这是因为缺乏相关的标注数据以及模型设计的限制。为解决这些问题，我们提出了AdaCCD，一种跨语言适应方法，可以在新语言中检测副本代码无需该语言的标注。AdaCCD利用预训练的编程语言模型提供的语言不可识别代码表示，并提出了一种适应性反射对比学习框架，将资源丰富的语言中的知识传递到资源缺乏的语言中。我们通过构建5种编程语言的多语言代码副本检测 benchmark来评估AdaCCD的跨语言适应结果。AdaCCD在比较其他基eline上显示出了显著的改善，甚至可以与监督练化相当。
</details></li>
</ul>
<hr>
<h2 id="Danish-Foundation-Models"><a href="#Danish-Foundation-Models" class="headerlink" title="Danish Foundation Models"></a>Danish Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07264">http://arxiv.org/abs/2311.07264</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/centre-for-humanities-computing/danish-foundation-models">https://github.com/centre-for-humanities-computing/danish-foundation-models</a></li>
<li>paper_authors: Kenneth Enevoldsen, Lasse Hansen, Dan S. Nielsen, Rasmus A. F. Egebæk, Søren V. Holm, Martin C. Nielsen, Martin Bernstorff, Rasmus Larsen, Peter B. Jørgensen, Malte Højmark-Bertelsen, Peter B. Vahlstrup, Per Møldrup-Dalum, Kristoffer Nielbo</li>
<li>for: 提高小语言的研究水平和应用前景</li>
<li>methods: 基于广泛合作和高质量数据的开源基础模型</li>
<li>results: 提供高质量的开源基础模型，促进小语言研究和应用发展Here’s a breakdown of each point:</li>
<li>for: The paper is written to improve the research level and application prospects of small languages.</li>
<li>methods: The project uses open, well-documented, and high-quality foundation models for the Danish language, based on broad cooperation with public and private institutions.</li>
<li>results: The project provides high-quality open-source foundation models, which promote the development of small language research and applications.<details>
<summary>Abstract</summary>
Large language models, sometimes referred to as foundation models, have transformed multiple fields of research. However, smaller languages risk falling behind due to high training costs and small incentives for large companies to train these models. To combat this, the Danish Foundation Models project seeks to provide and maintain open, well-documented, and high-quality foundation models for the Danish language. This is achieved through broad cooperation with public and private institutions, to ensure high data quality and applicability of the trained models. We present the motivation of the project, the current status, and future perspectives.
</details>
<details>
<summary>摘要</summary>
大型语言模型，有时也被称为基础模型，已经在多个领域的研究中发挥了重要作用。然而，小语言的发展受到了高训练成本和大公司对这些模型的训练不具备吸引力的限制。为了解决这问题，丹麦基础模型项目目标是提供和维护开放、充分文档和高质量的基础模型，以满足丹麦语言的需求。这实现了广泛合作的公共和私人机构，以确保数据质量的高度和训练模型的应用性。我们介绍了项目的动机、当前状况和未来展望。
</details></li>
</ul>
<hr>
<h2 id="How-are-Prompts-Different-in-Terms-of-Sensitivity"><a href="#How-are-Prompts-Different-in-Terms-of-Sensitivity" class="headerlink" title="How are Prompts Different in Terms of Sensitivity?"></a>How are Prompts Different in Terms of Sensitivity?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07230">http://arxiv.org/abs/2311.07230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sheng Lu, Hendrik Schuff, Iryna Gurevych</li>
<li>for: 本研究旨在对各种模型和任务下的提示进行系统性的分析，了解提示对模型性能的影响。</li>
<li>methods: 本研究使用敏感度函数的敏感性来评估提示的影响，并使用梯度基本的精度分析来解释不同的提示对输入Token的相关性的影响。</li>
<li>results: 研究发现，敏感性是一个不supervised的表现度量，与准确率 exhibits 强negative correlation。此外，提出了一种基于敏感度的搜索策略，可以在输入信息scarce时提供有助于。本研究对提示的分析带来新的视角，为ICL机制的更好的理解做出了贡献。<details>
<summary>Abstract</summary>
In-context learning (ICL) has become one of the most popular learning paradigms. While there is a growing body of literature focusing on prompt engineering, there is a lack of systematic analysis comparing the effects of prompts across different models and tasks. To address this gap, we present a comprehensive prompt analysis based on the sensitivity of a function. Our analysis reveals that sensitivity is an unsupervised proxy for model performance, as it exhibits a strong negative correlation with accuracy. We use gradient-based saliency scores to empirically demonstrate how different prompts affect the relevance of input tokens to the output, resulting in different levels of sensitivity. Furthermore, we introduce sensitivity-aware decoding which incorporates sensitivity estimation as a penalty term in the standard greedy decoding. We show that this approach is particularly helpful when information in the input is scarce. Our work provides a fresh perspective on the analysis of prompts, and contributes to a better understanding of the mechanism of ICL.
</details>
<details>
<summary>摘要</summary>
启发式学习（ICL）已成为最受欢迎的学习方法之一。虽然有一个不断增长的文献关注提示工程，但是没有系统性的分析比较不同模型和任务下的提示效果。为了填补这个差距，我们提出了基于函数敏感度的完整的提示分析。我们的分析显示，函数敏感度是无监督的表现指标，它与准确性之间存在强烈负相关性。我们使用梯度基于的关注分数来实证性地表明不同的提示对输入token的相关性有多大的影响，从而导致不同的敏感度水平。此外，我们引入了敏感度意识的解码方法，它将敏感度估计作为标准排序解码中的罚项。我们示示这种方法在输入信息scarce情况下特别有助于。我们的工作为ICL机制的分析提供了新的视角，并为ICL的更好的理解做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="Troubles-and-Failures-in-Interactional-Language-Towards-a-Linguistically-Informed-Taxonomy"><a href="#Troubles-and-Failures-in-Interactional-Language-Towards-a-Linguistically-Informed-Taxonomy" class="headerlink" title="Troubles and Failures in Interactional Language. Towards a Linguistically Informed Taxonomy"></a>Troubles and Failures in Interactional Language. Towards a Linguistically Informed Taxonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07217">http://arxiv.org/abs/2311.07217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martina Wiltschko</li>
<li>for: 本研究旨在理解人类和人工对话代理（CA）之间的互动 nature, specifically focusing on linguistically defined variables that influence the flow of conversations among humans.</li>
<li>methods: 该研究采用了一个系统性的研究计划，使用Explicit linguistic perspective to investigate the human-machine interaction (HMI).</li>
<li>results: 该研究将提供一系列关于HMI的发现和理解，包括 linguistically defined variables that influence the flow of conversations among humans.<details>
<summary>Abstract</summary>
The goal of this talk is to introduce a systematic research agenda which aims to understand the nature of interaction between humans and artificial conversational agents (CA) (henceforth humanmachine interaction, HMI). Specifically, we shall take an explicit linguistic perspective focusing on linguistically defined variables that are known to influence the flow of conversations among humans (henceforth human-human interaction, HHI).
</details>
<details>
<summary>摘要</summary>
目的是介绍一个系统性的研究计划，旨在了解人类和人工对话机器人（CA）之间的交互（简称人机交互，HMI）。特别是，我们将采取Explicit linguistic perspective，关注人类对话中 linguistically定义的变量，这些变量影响对话的流动（简称人人交互，HHI）。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Coffee-Boost-Your-Code-LLMs-by-Fixing-Bugs-with-Feedback"><a href="#Coffee-Boost-Your-Code-LLMs-by-Fixing-Bugs-with-Feedback" class="headerlink" title="Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback"></a>Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07215">http://arxiv.org/abs/2311.07215</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seungjun Moon, Yongho Song, Hyungjoo Chae, Dongjin Kang, Taeyoon Kwon, Kai Tzu-iunn Ong, Seung-won Hwang, Jinyoung Yeo</li>
<li>for: 本研究旨在利用开源代码LM进行代码修复，以提供有用的反馈和指导。</li>
<li>methods: 本研究使用了一个特定的数据集——Coffee，以及一个框架——CoffeePots，来自动生成有用的反馈和指导。</li>
<li>results: 研究显示，使用Coffee和CoffeePots可以达到人工评估修复 benchmark 的最佳性能。<details>
<summary>Abstract</summary>
Code editing is an essential step towards reliable program synthesis to automatically correct critical errors generated from code LLMs. Recent studies have demonstrated that closed-source LLMs (i.e., ChatGPT and GPT-4) are capable of generating corrective feedback to edit erroneous inputs. However, it remains challenging for open-source code LLMs to generate feedback for code editing, since these models tend to adhere to the superficial formats of feedback and provide feedback with misleading information. Hence, the focus of our work is to leverage open-source code LLMs to generate helpful feedback with correct guidance for code editing. To this end, we present Coffee, a collected dataset specifically designed for code fixing with feedback. Using this dataset, we construct CoffeePots, a framework for COde Fixing with FEEdback via Preference-Optimized Tuning and Selection. The proposed framework aims to automatically generate helpful feedback for code editing while minimizing the potential risk of superficial feedback. The combination of Coffee and CoffeePots marks a significant advancement, achieving state-of-the-art performance on HumanEvalFix benchmark. Codes and model checkpoints are publicly available at https://github.com/Lune-Blue/COFFEE.
</details>
<details>
<summary>摘要</summary>
<<SYS code=UTF-8>>编辑代码是重要的一步 towards 可靠的程序生成，以自动 corrections critical errors 由 code LLMs 生成。 recent studies have shown that closed-source LLMs (i.e., ChatGPT and GPT-4) can generate corrective feedback to edit incorrect inputs. However, it is challenging for open-source code LLMs to generate feedback for code editing, as these models tend to adhere to the superficial formats of feedback and provide feedback with misleading information. Therefore, our work focuses on leveraging open-source code LLMs to generate helpful feedback with correct guidance for code editing. To this end, we present Coffee, a collected dataset specifically designed for code fixing with feedback. Using this dataset, we construct CoffeePots, a framework for COde Fixing with FEEdback via Preference-Optimized Tuning and Selection. The proposed framework aims to automatically generate helpful feedback for code editing while minimizing the potential risk of superficial feedback. The combination of Coffee and CoffeePots represents a significant advancement, achieving state-of-the-art performance on HumanEvalFix benchmark. codes and model checkpoints are publicly available at https://github.com/Lune-Blue/COFFEE.Translated by Google Translate.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Dialogue-Comprehension-Ability-of-Large-Language-Models"><a href="#Exploring-the-Dialogue-Comprehension-Ability-of-Large-Language-Models" class="headerlink" title="Exploring the Dialogue Comprehension Ability of Large Language Models"></a>Exploring the Dialogue Comprehension Ability of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07194">http://arxiv.org/abs/2311.07194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuaijie She, Shujian Huang, Xingyun Wang, Yanke Zhou, Jiajun Chen</li>
<li>for: 这 paper 的目的是评估和分析不同的语言模型（LLMs）在对话 SUMMARIZATION 和对话理解能力的表现。</li>
<li>methods: 这 paper 使用了对话 SUMMARIZATION 任务来评估和分析不同的语言模型（LLMs）的对话理解能力。</li>
<li>results: 该 paper 的结果表明，平均 speaking 27% of the summaries generated by LLMs 包含了不一致的信息。即使使用最强的模型 ChatGPT 也有16%的错误。对于回答问题，所有评估的 LLMs 的错误率为37.2%。这些结果表明现有的 LLMs 在对话理解方面存在严重的缺陷。<details>
<summary>Abstract</summary>
LLMs may interact with users in the form of dialogue and generate responses following their instructions, which naturally require dialogue comprehension abilities. However, dialogue comprehension is a general language ability which is hard to be evaluated directly. In this work, we propose to perform the evaluation with the help of the dialogue summarization task. Beside evaluating and analyzing the dialogue summarization performance (DIAC-Sum) of different LLMs, we also derive factual questions from the generated summaries and use them as a more flexible measurement of dialogue comprehension (DIAC-FactQA). Our evaluation shows that, on average, 27% of the summaries generated by LLMs contain factual inconsistency. Even ChatGPT, the strongest model evaluated, has such errors in 16% of its summaries. For answering the factual questions, which is more challenging, the average error rate of all evaluated LLMs is 37.2%. Both results indicate serious deficiencies. Detailed analysis shows that the understanding of subject/object of the conversation is still the most challenging problem for LLMs. Furthermore, to stimulate and enhance the dialogue comprehension ability of LLMs, we propose a fine-tuning paradigm with auto-constructed multi-task data. The experimental results demonstrate that our method achieved an error rate improvement of 10.9% on DIAC-FactQA.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VerityMath-Advancing-Mathematical-Reasoning-by-Self-Verification-Through-Unit-Consistency"><a href="#VerityMath-Advancing-Mathematical-Reasoning-by-Self-Verification-Through-Unit-Consistency" class="headerlink" title="VerityMath: Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency"></a>VerityMath: Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07172">http://arxiv.org/abs/2311.07172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vernon Toh, Ratish Puduppully, Nancy F. Chen</li>
<li>for: 这篇论文主要是研究一种用于数学理解的方法，具体来说是利用大型自然语言模型（LLMs）和程序基本解决方法来提高数学能力。</li>
<li>methods: 本论文使用了Code Llama（7B）模型，对数学问题进行分析，并提出了一种系统的方法来处理多种单位和类型的量问题。这种方法包括定义单位和确保单位的一致性。</li>
<li>results: 研究发现，通过使用单位一致程序（UCPs）进行定制，可以提高Code Llama（7B）模型的数学能力，并且在处理多种单位和类型的量问题时，提供了一些初步的结果。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) combined with program-based solving techniques are increasingly demonstrating proficiency in mathematical reasoning. However, such progress is mostly demonstrated in closed-source models such as OpenAI-GPT4 and Claude. In this paper, we seek to study the performance of strong open-source LLMs. Specifically, we analyze the outputs of Code Llama (7B) when applied to math word problems. We identify a category of problems that pose a challenge for the model, particularly those involving quantities that span multiple types or units. To address this issue, we propose a systematic approach by defining units for each quantity and ensuring the consistency of these units during mathematical operations. We developed Unit Consistency Programs (UCPs), an annotated dataset of math word problems, each paired with programs that contain unit specifications and unit verification routines. Finally, we finetune the Code Llama (7B) model with UCPs to produce VerityMath and present our preliminary findings.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）与程式基于的解题技术相结合，逐渐展现出数学推理的能力。然而，这些进步主要出现在封闭式模型中，如OpenAI-GPT4和Claude。在这篇论文中，我们想要研究强大的开源LMMs的表现。我们分析了Code Llama（7B）当作应用于数学词汇问题的输出。我们发现了一种问题类型，尤其是涉及多种或单位的量的问题，对模型而言是一大挑战。为解决这个问题，我们提出了一个系统的方法，即定义单位 для每个量，并在数学操作中保持单位的一致性。我们称这为单位一致程式（UCPs）。我们还创建了一个标注的数学词汇问题集，每个问题都有单位规定和单位验证程式。最后，我们调整了Code Llama（7B）模型，使其能够处理VerityMath，并给出我们的初步结果。
</details></li>
</ul>
<hr>
<h2 id="calamanCy-A-Tagalog-Natural-Language-Processing-Toolkit"><a href="#calamanCy-A-Tagalog-Natural-Language-Processing-Toolkit" class="headerlink" title="calamanCy: A Tagalog Natural Language Processing Toolkit"></a>calamanCy: A Tagalog Natural Language Processing Toolkit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07171">http://arxiv.org/abs/2311.07171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ljvmiranda921/calamancy">https://github.com/ljvmiranda921/calamancy</a></li>
<li>paper_authors: Lester James V. Miranda</li>
<li>for:  This paper is written for those who are interested in developing natural language processing (NLP) applications for Tagalog, particularly those who want to use spaCy as their framework.</li>
<li>methods: The paper presents an open-source toolkit called calamanCy, which is built on top of spaCy and provides a consistent API for building NLP applications. The toolkit offers general-purpose multitask models with out-of-the-box support for dependency parsing, POS tagging, and NER.</li>
<li>results: The paper aims to accelerate the progress of Tagalog NLP by consolidating disjointed resources in a unified framework and providing a convenient toolkit for experimentation and integration with other frameworks. The toolkit is available on GitHub for easy access and use.<details>
<summary>Abstract</summary>
We introduce calamanCy, an open-source toolkit for constructing natural language processing (NLP) pipelines for Tagalog. It is built on top of spaCy, enabling easy experimentation and integration with other frameworks. calamanCy addresses the development gap by providing a consistent API for building NLP applications and offering general-purpose multitask models with out-of-the-box support for dependency parsing, parts-of-speech (POS) tagging, and named entity recognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by consolidating disjointed resources in a unified framework. The calamanCy toolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.
</details>
<details>
<summary>摘要</summary>
我们介绍calamanCy，一个开源工具集 для构建自然语言处理（NLP）管道 дляTagalog。它基于spaCy，使得容易实验和其他框架集成。calamanCy通过提供一致的API来建立NLP应用程序，并提供通用多任务模型，包括直接出现的依赖分析、部件标记（POS）和命名实体识别（NER）。calamanCy目标是加速Tagalog NLP的进步，通过集成分散的资源在一个统一的框架中。calamanCy工具集可在GitHub上下载：https://github.com/ljvmiranda921/calamanCy。
</details></li>
</ul>
<hr>
<h2 id="Developing-a-Named-Entity-Recognition-Dataset-for-Tagalog"><a href="#Developing-a-Named-Entity-Recognition-Dataset-for-Tagalog" class="headerlink" title="Developing a Named Entity Recognition Dataset for Tagalog"></a>Developing a Named Entity Recognition Dataset for Tagalog</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07161">http://arxiv.org/abs/2311.07161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ljvmiranda921/calamancy">https://github.com/ljvmiranda921/calamancy</a></li>
<li>paper_authors: Lester James V. Miranda</li>
<li>for: 这个论文是为了开发一个Tagalog语言Named Entity Recognition（NER）数据集而写的。</li>
<li>methods: 这个论文使用了新闻报道获取的文本，并由本地语言使用者进行了词语标注。这些标注后，得到了约7.8万个文档，分别包括人名、机构名和地点名三种实体类型。</li>
<li>results: 论文通过对现有方法进行了广泛的实验评估，并在超级vised和转移学习Setting中测试了state-of-the-art方法。最终，论文公开发布了数据和处理代码，以便在未来的Tagalog NLP工作中激发创新。<details>
<summary>Abstract</summary>
We present the development of a Named Entity Recognition (NER) dataset for Tagalog. This corpus helps fill the resource gap present in Philippine languages today, where NER resources are scarce. The texts were obtained from a pretraining corpora containing news reports, and were labeled by native speakers in an iterative fashion. The resulting dataset contains ~7.8k documents across three entity types: Person, Organization, and Location. The inter-annotator agreement, as measured by Cohen's $\kappa$, is 0.81. We also conducted extensive empirical evaluation of state-of-the-art methods across supervised and transfer learning settings. Finally, we released the data and processing code publicly to inspire future work on Tagalog NLP.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个标点名实体识别（NER）数据集的开发，这些数据集用于填补菲律宾语言资源的空白。这些文本来自新闻报道，并由本地使用者在轮询的方式进行标注。结果的数据集包含约7.8万个文档，分为三个实体类型：人物、组织机构和地点。Inter-annotator agreement，由科恩的κ度量表示，达到0.81。我们还进行了state-of-the-art方法的广泛实验，包括直接学习和转移学习Setting中。最后，我们公开发布了数据和处理代码，以便未来的Tagalog NLP工作。
</details></li>
</ul>
<hr>
<h2 id="Gen-Z-Generative-Zero-Shot-Text-Classification-with-Contextualized-Label-Descriptions"><a href="#Gen-Z-Generative-Zero-Shot-Text-Classification-with-Contextualized-Label-Descriptions" class="headerlink" title="Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions"></a>Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07115">http://arxiv.org/abs/2311.07115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sachin Kumar, Chan Young Park, Yulia Tsvetkov</li>
<li>for: 提高 zero-shot 文本分类 task 的性能和 robustness</li>
<li>methods: 提出了一种生成式 prompting 框架 Gen-Z，通过测量 LM 对输入文本的可能性，以条件提取标签描述</li>
<li>results: 在多个标准分类 benchmark 上，与 six 种开源 LM 家族进行比较，显示 zero-shot 分类可以通过简单地Contextualization 来提高性能，同时提高对 prompt 变化的Robustness。<details>
<summary>Abstract</summary>
Language model (LM) prompting--a popular paradigm for solving NLP tasks--has been shown to be susceptible to miscalibration and brittleness to slight prompt variations, caused by its discriminative prompting approach, i.e., predicting the label given the input. To address these issues, we propose Gen-Z--a generative prompting framework for zero-shot text classification. GEN-Z is generative, as it measures the LM likelihood of input text, conditioned on natural language descriptions of labels. The framework is multivariate, as label descriptions allow us to seamlessly integrate additional contextual information about the labels to improve task performance. On various standard classification benchmarks, with six open-source LM families, we show that zero-shot classification with simple contextualization of the data source of the evaluation set consistently outperforms both zero-shot and few-shot baselines while improving robustness to prompt variations. Further, our approach enables personalizing classification in a zero-shot manner by incorporating author, subject, or reader information in the label descriptions.
</details>
<details>
<summary>摘要</summary>
Language model（LM）提示--一种广泛使用的解决NLP任务的方法--已经显示出受到了偏置和细微提示变化的脆弱性，这是由其推理提示方法引起的，即根据输入预测标签。为解决这些问题，我们提出了Gen-Z--一个生成提示框架 для零shot文本分类。GEN-Z是生成的，因为它测量LM对输入文本的可能性， conditioned on自然语言标签描述。该框架是多变量的，因为标签描述允许我们轻松地 integratingadditional contextual information about the labels to improve task performance。在多个标准分类benchmark上，使用六种开源LM家族，我们显示了零shot分类 with simple contextualization of the data source of the evaluation set可以Consistently outperform both zero-shot和few-shot基elines while improving robustness to prompt variations。此外，我们的方法可以在零shot manner中进行个性化分类，通过在标签描述中包含作者、主题或读者信息。
</details></li>
</ul>
<hr>
<h2 id="Fovea-Transformer-Efficient-Long-Context-Modeling-with-Structured-Fine-to-Coarse-Attention"><a href="#Fovea-Transformer-Efficient-Long-Context-Modeling-with-Structured-Fine-to-Coarse-Attention" class="headerlink" title="Fovea Transformer: Efficient Long-Context Modeling with Structured Fine-to-Coarse Attention"></a>Fovea Transformer: Efficient Long-Context Modeling with Structured Fine-to-Coarse Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07102">http://arxiv.org/abs/2311.07102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziwei He, Jian Yuan, Le Zhou, Jingwen Leng, Bo Jiang</li>
<li>for: 本文旨在提高Transformer模型在长文本处理中的计算效率，并且能够更好地捕捉长程度依赖关系。</li>
<li>methods: 作者提出了一种名为“Fovea Transformer”的新方法，它使用多尺度树来表示输入序列，并使用context token的表示在树中进行进一步精细化。</li>
<li>results: 在三个长文本摘要任务上进行测试，该方法达到了两个任务的状态之Art并在另一个任务上达到了竞争性的结果，并且在一个任务上有部分的评价指标表现出现了改善和退化。<details>
<summary>Abstract</summary>
The quadratic complexity of self-attention in Transformers has hindered the processing of long text. To alleviate this problem, previous works have proposed to sparsify the attention matrix, taking advantage of the observation that crucial information about a token can be derived from its neighbors. These methods typically combine one or another form of local attention and global attention. Such combinations introduce abrupt changes in contextual granularity when going from local to global, which may be undesirable. We believe that a smoother transition could potentially enhance model's ability to capture long-context dependencies. In this study, we introduce Fovea Transformer, a long-context focused transformer that addresses the challenges of capturing global dependencies while maintaining computational efficiency. To achieve this, we construct a multi-scale tree from the input sequence, and use representations of context tokens with a progressively coarser granularity in the tree, as their distance to the query token increases. We evaluate our model on three long-context summarization tasks\footnote{Our code is publicly available at: \textit{https://github.com/ZiweiHe/Fovea-Transformer}. It achieves state-of-the-art performance on two of them, and competitive results on the third with mixed improvement and setback of the evaluation metrics.
</details>
<details>
<summary>摘要</summary>
“transformer的 quadratic complexity对于处理长文本问题产生了阻碍。以前的工作通过将注意力矩阵簇排除，利用了Token之间的相互关联性来获得有利的信息。这些方法通常是通过地方注意力和全球注意力的结合来实现。但这种结合可能会导致Contextual granularity的突然变化，从地方到全球，这可能不太好。我们认为，一个更缓和的变化可能可以帮助模型更好地捕捉长期依赖关系。在这篇研究中，我们引入了Fovea Transformer，一种专注于长期依赖关系的 transformer。我们使用输入序列中的多对称树结构，并使用Token的距离增加而增加的表示，以获得更好的 Computational efficiency。我们将这个模型应用于三个长期摘要任务上，其中两个任务上取得了现场最佳性能，另一个任务上则获得了混合的改善和退化的评估指标。”
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-ASR-Representations-in-Real-world-Noisy-Speech-Emotion-Recognition"><a href="#On-the-Effectiveness-of-ASR-Representations-in-Real-world-Noisy-Speech-Emotion-Recognition" class="headerlink" title="On the Effectiveness of ASR Representations in Real-world Noisy Speech Emotion Recognition"></a>On the Effectiveness of ASR Representations in Real-world Noisy Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07093">http://arxiv.org/abs/2311.07093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohan Shi, Jiajun He, Xingfeng Li, Tomoki Toda</li>
<li>for: 提高非站台噪音感知识的效果</li>
<li>methods: 采用自动语音识别模型为噪音鲁棒特征提取器，从中提取情感语音特征，然后对下游NSER任务进行应用</li>
<li>results: 1) 提出的方法与传统噪音减少方法相比， NSER性能更高; 2) 超越了自动学习方法和文本基于的方法; 3) 甚至超越了使用ASR转录或噪音杂音的文本基于的方法<details>
<summary>Abstract</summary>
This paper proposes an efficient attempt to noisy speech emotion recognition (NSER). Conventional NSER approaches have proven effective in mitigating the impact of artificial noise sources, such as white Gaussian noise, but are limited to non-stationary noises in real-world environments due to their complexity and uncertainty. To overcome this limitation, we introduce a new method for NSER by adopting the automatic speech recognition (ASR) model as a noise-robust feature extractor to eliminate non-vocal information in noisy speech. We first obtain intermediate layer information from the ASR model as a feature representation for emotional speech and then apply this representation for the downstream NSER task. Our experimental results show that 1) the proposed method achieves better NSER performance compared with the conventional noise reduction method, 2) outperforms self-supervised learning approaches, and 3) even outperforms text-based approaches using ASR transcription or the ground truth transcription of noisy speech.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>The proposed method achieves better NSER performance compared with the conventional noise reduction method.2. It outperforms self-supervised learning approaches.3. It even outperforms text-based approaches using ASR transcription or the ground truth transcription of noisy speech.</details></li>
</ol>
<hr>
<h2 id="On-the-Discussion-of-Large-Language-Models-Symmetry-of-Agents-and-Interplay-with-Prompts"><a href="#On-the-Discussion-of-Large-Language-Models-Symmetry-of-Agents-and-Interplay-with-Prompts" class="headerlink" title="On the Discussion of Large Language Models: Symmetry of Agents and Interplay with Prompts"></a>On the Discussion of Large Language Models: Symmetry of Agents and Interplay with Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07076">http://arxiv.org/abs/2311.07076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qineng Wang, Zihao Wang, Ying Su, Yangqiu Song</li>
<li>for: 这 paper 旨在解释如何使用多个语言模型来解释复杂问题。</li>
<li>methods: 这 paper 使用了两种方法：一是提问工程，二是组合多个语言模型的多个推理。</li>
<li>results: 这 paper 实验ally 发现，把提问工程与多个推理机制相结合可以达到复杂多个机制的性能。此外，paper 还提出了一种可扩展的讨论机制，可以使用简单的提问来实现高性能。<details>
<summary>Abstract</summary>
Two ways has been discussed to unlock the reasoning capability of a large language model. The first one is prompt engineering and the second one is to combine the multiple inferences of large language models, or the multi-agent discussion. Theoretically, this paper justifies the multi-agent discussion mechanisms from the symmetry of agents. Empirically, this paper reports the empirical results of the interplay of prompts and discussion mechanisms, revealing the empirical state-of-the-art performance of complex multi-agent mechanisms can be approached by carefully developed prompt engineering. This paper also proposes a scalable discussion mechanism based on conquer and merge, providing a simple multi-agent discussion solution with simple prompts but state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
两种方法已经讨论用于解锁大语言模型的理智能力。第一种是提示工程，第二种是将多个推理机器人的多种推理结果相结合，或者多个机器人的讨论。理论上，这篇论文从代理Symmetry的角度正式 justify了多机器人讨论机制。实际上，这篇论文报告了提示和讨论机制之间的交互效果，显示了复杂多机器人机制的 empirical state-of-the-art性可以通过修改的提示工程来实现。此外，这篇论文还提出了一种可扩展的讨论机制基于征服和合并，提供了简单的多机器人讨论解决方案，但能够达到 state-of-the-art性的性能。
</details></li>
</ul>
<hr>
<h2 id="Explain-then-Translate-An-Analysis-on-Improving-Program-Translation-with-Self-generated-Explanations"><a href="#Explain-then-Translate-An-Analysis-on-Improving-Program-Translation-with-Self-generated-Explanations" class="headerlink" title="Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations"></a>Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07070">http://arxiv.org/abs/2311.07070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pootiet/explain-then-translate">https://github.com/pootiet/explain-then-translate</a></li>
<li>paper_authors: Zilu Tang, Mayank Agarwal, Alex Shypula, Bailin Wang, Derry Wijaya, Jie Chen, Yoon Kim</li>
<li>for: 这种研究使用自然语言解释作为代码-代码翻译中语言模型的中间步骤。</li>
<li>methods: 研究使用三种类型的自然语言解释，对 MultiPL-E  dataset中构建的 19 种编程语言进行评估。</li>
<li>results: 研究发现，自然语言解释在零shot情况下特别有效，平均提高性能 by 12%。在困难程度高的程序上，自然语言解释的改进更加明显。研究发布数据集、代码和全面解决方案在所有 19 种语言中。<details>
<summary>Abstract</summary>
This work explores the use of self-generated natural language explanations as an intermediate step for code-to-code translation with language models. Across three types of explanations and 19 programming languages constructed from the MultiPL-E dataset, we find the explanations to be particularly effective in the zero-shot case, improving performance by 12% on average. Improvements with natural language explanations are particularly pronounced on difficult programs. We release our dataset, code, and canonical solutions in all 19 languages.
</details>
<details>
<summary>摘要</summary>
这个研究探讨了使用自然语言解释作为代码-到-代码翻译的语言模型中间步骤。通过三种类型的解释和使用MultiPL-E数据集构建的19种程序语言，我们发现解释在零shot情况下特别有效，提高性能的平均提升为12%。使用自然语言解释在困难程序中的改进 particualry明显。我们发布了我们的数据集、代码和所有19种语言的标准解。
</details></li>
</ul>
<hr>
<h2 id="Context-Consistency-between-Training-and-Testing-in-Simultaneous-Machine-Translation"><a href="#Context-Consistency-between-Training-and-Testing-in-Simultaneous-Machine-Translation" class="headerlink" title="Context Consistency between Training and Testing in Simultaneous Machine Translation"></a>Context Consistency between Training and Testing in Simultaneous Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07066">http://arxiv.org/abs/2311.07066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongmz/contextconsistencybitraining4simt">https://github.com/zhongmz/contextconsistencybitraining4simt</a></li>
<li>paper_authors: Meizhi Zhong, Lemao Liu, Kehai Chen, Mingming Yang, Min Zhang</li>
<li>for: 这个论文目的是提出一种同时机器翻译（SiMT）方法，以实现实时半翻译，并且逐渐增长源语言上下文。</li>
<li>methods: 这篇论文使用了一种新的训练方法，即上下文一致训练（Context Consistency Training，CCT），以确保在训练和测试中使用上下文的一致性。</li>
<li>results: 实验结果显示，使用CCT方法可以提高翻译质量和响应速度，并且在三种语言对比中，我们的系统首次超越了现有系统，凭借我们的上下文一致训练方法。<details>
<summary>Abstract</summary>
Simultaneous Machine Translation (SiMT) aims to yield a real-time partial translation with a monotonically growing the source-side context. However, there is a counterintuitive phenomenon about the context usage between training and testing: e.g., the wait-k testing model consistently trained with wait-k is much worse than that model inconsistently trained with wait-k' (k' is not equal to k) in terms of translation quality. To this end, we first investigate the underlying reasons behind this phenomenon and uncover the following two factors: 1) the limited correlation between translation quality and training (cross-entropy) loss; 2) exposure bias between training and testing. Based on both reasons, we then propose an effective training approach called context consistency training accordingly, which makes consistent the context usage between training and testing by optimizing translation quality and latency as bi-objectives and exposing the predictions to the model during the training. The experiments on three language pairs demonstrate our intuition: our system encouraging context consistency outperforms that existing systems with context inconsistency for the first time, with the help of our context consistency training approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PROPANE-Prompt-design-as-an-inverse-problem"><a href="#PROPANE-Prompt-design-as-an-inverse-problem" class="headerlink" title="PROPANE: Prompt design as an inverse problem"></a>PROPANE: Prompt design as an inverse problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07064">http://arxiv.org/abs/2311.07064</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rimon15/propane">https://github.com/rimon15/propane</a></li>
<li>paper_authors: Rimon Melamed, Lucas H. McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, Enric Boix-Adsera</li>
<li>for: 提高 Large Language Models (LLMs) 的表现，用于指导 LLMs  toward 特定行为。</li>
<li>methods: 提出自动化提示优化框架 PROPANE，用于找到一个可以导致 semantically similar 输出的提示，无需用户参与。</li>
<li>results: PROPANE 可以用于 (a) 改进现有的提示，和 (b) 找到 semantically obfuscated 提示，可以在不同的模型之间传递。<details>
<summary>Abstract</summary>
Carefully-designed prompts are key to inducing desired behavior in Large Language Models (LLMs). As a result, great effort has been dedicated to engineering prompts that guide LLMs toward particular behaviors. In this work, we propose an automatic prompt optimization framework, PROPANE, which aims to find a prompt that induces semantically similar outputs to a fixed set of examples without user intervention. We further demonstrate that PROPANE can be used to (a) improve existing prompts, and (b) discover semantically obfuscated prompts that transfer between models.
</details>
<details>
<summary>摘要</summary>
仔细设计的提示是大语言模型（LLM）引导行为的关键。因此，大量精力被投入到引导提示，以使LLM行为于特定方向。在这项工作中，我们提出了一个自动化提示优化框架，称为PROPANE，目的是找到一个引导LLM生成相似含义的输入。我们进一步证明了PROPANE可以用于（a）提高现有提示，以及（b）找到Semantic Obfuscation的提示，这些提示可以在不同的模型之间传递。
</details></li>
</ul>
<hr>
<h2 id="Teach-me-with-a-Whisper-Enhancing-Large-Language-Models-for-Analyzing-Spoken-Transcripts-using-Speech-Embeddings"><a href="#Teach-me-with-a-Whisper-Enhancing-Large-Language-Models-for-Analyzing-Spoken-Transcripts-using-Speech-Embeddings" class="headerlink" title="Teach me with a Whisper: Enhancing Large Language Models for Analyzing Spoken Transcripts using Speech Embeddings"></a>Teach me with a Whisper: Enhancing Large Language Models for Analyzing Spoken Transcripts using Speech Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07014">http://arxiv.org/abs/2311.07014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatema Hasan, Yulong Li, James Foulds, Shimei Pan, Bishwaranjan Bhattacharjee<br>for: 这个论文主要用于提高语音识别和理解的语言模型，以便在语音讲解时分析 spoken transcripts。methods: 该方法使用了一种名为 OpenAI Whisper 的语音模型，通过将语音信息转移到语言模型中来帮助学习语言模型。results: 实验结果表明，使用该方法可以在分析 spoken transcripts 时获得显著改进，而无需在测试时处理 audio 流。<details>
<summary>Abstract</summary>
Speech data has rich acoustic and paralinguistic information with important cues for understanding a speaker's tone, emotion, and intent, yet traditional large language models such as BERT do not incorporate this information. There has been an increased interest in multi-modal language models leveraging audio and/or visual information and text. However, current multi-modal language models require both text and audio/visual data streams during inference/test time. In this work, we propose a methodology for training language models leveraging spoken language audio data but without requiring the audio stream during prediction time. This leads to an improved language model for analyzing spoken transcripts while avoiding an audio processing overhead at test time. We achieve this via an audio-language knowledge distillation framework, where we transfer acoustic and paralinguistic information from a pre-trained speech embedding (OpenAI Whisper) teacher model to help train a student language model on an audio-text dataset. In our experiments, the student model achieves consistent improvement over traditional language models on tasks analyzing spoken transcripts.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。</SYS>>听音数据具有丰富的听音和paraлин频信息，这些信息对理解说话人的语调、情感和意图是重要的信号，然而传统的大型自然语言处理器如BERT不会 incorporate这些信息。随着对多Modal语言模型的增长兴趣，我们提出了一种方法，该方法可以在测试时不需要听音流程来训练语言模型。我们通过将语音信息传递给一个预训练的语音嵌入（OpenAI Whisper）教师模型，并将其中的听音和paraлин频信息传递给一个学生语言模型，以便在听音文本集合上进行训练。在我们的实验中，学生模型在分析说话笔记任务上具有一致性的改进。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.CL_2023_11_13/" data-id="clp89dobv00exi788expee4hk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.LG_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T10:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.LG_2023_11_13/">cs.LG - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Probabilistic-Physics-integrated-Neural-Differentiable-Modeling-for-Isothermal-Chemical-Vapor-Infiltration-Process"><a href="#Probabilistic-Physics-integrated-Neural-Differentiable-Modeling-for-Isothermal-Chemical-Vapor-Infiltration-Process" class="headerlink" title="Probabilistic Physics-integrated Neural Differentiable Modeling for Isothermal Chemical Vapor Infiltration Process"></a>Probabilistic Physics-integrated Neural Differentiable Modeling for Isothermal Chemical Vapor Infiltration Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07798">http://arxiv.org/abs/2311.07798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Akhare, Zeping Chen, Richard Gulotty, Tengfei Luo, Jian-Xun Wang</li>
<li>For: This paper aims to develop a data-driven predictive model for the isothermal chemical vapor infiltration (CVI) densification process, which is critical for producing high-performance carbon-carbon and carbon-silicon carbide composites.* Methods: The authors use the physics-integrated neural differentiable (PiNDiff) modeling framework, which incorporates uncertainty quantification to enhance the model’s reliability and robustness. They also use both synthetic and real-world manufacturing data to validate the model’s accuracy.* Results: The proposed method is shown to be effective in modeling the densification process during CVI, and can potentially be used to optimize the manufacturing process and improve the quality and consistency of the final products.<details>
<summary>Abstract</summary>
Chemical vapor infiltration (CVI) is a widely adopted manufacturing technique used in producing carbon-carbon and carbon-silicon carbide composites. These materials are especially valued in the aerospace and automotive industries for their robust strength and lightweight characteristics. The densification process during CVI critically influences the final performance, quality, and consistency of these composite materials. Experimentally optimizing the CVI processes is challenging due to long experimental time and large optimization space. To address these challenges, this work takes a modeling-centric approach. Due to the complexities and limited experimental data of the isothermal CVI densification process, we have developed a data-driven predictive model using the physics-integrated neural differentiable (PiNDiff) modeling framework. An uncertainty quantification feature has been embedded within the PiNDiff method, bolstering the model's reliability and robustness. Through comprehensive numerical experiments involving both synthetic and real-world manufacturing data, the proposed method showcases its capability in modeling densification during the CVI process. This research highlights the potential of the PiNDiff framework as an instrumental tool for advancing our understanding, simulation, and optimization of the CVI manufacturing process, particularly when faced with sparse data and an incomplete description of the underlying physics.
</details>
<details>
<summary>摘要</summary>
化学蒸气渗入（CVI）是制造 carbon-carbon 和 carbon-silicon carbide composites 的广泛采用的制造技术。这些材料在航空和汽车业中尤其有价值，因为它们具有出色的强度和轻量特点。CVI  densification 过程对 composite 材料的最终性能、质量和一致性具有关键影响。由于实验室 optimize CVI 过程的时间长和空间大，因此实验室优化是挑战。为解决这些挑战，这些工作采用了模型中心的方法。由于 CV 的热吸 densification 过程的复杂性和实验数据的有限性，我们开发了基于物理和神经网络的 PiNDiff 模型。在 PiNDiff 方法中嵌入了不确定性评估功能，使模型的可靠性和可重复性得到加强。通过对 synthetic 和实际制造数据进行了广泛的数值实验，我们表明了 PiNDiff 方法在 CV  densification 过程中的模型化能力。这些研究强调 PiNDiff 框架在 CV 制造过程中的可能性，特别是在缺乏数据和不完全物理描述的情况下。
</details></li>
</ul>
<hr>
<h2 id="Explainable-History-Distillation-by-Marked-Temporal-Point-Process"><a href="#Explainable-History-Distillation-by-Marked-Temporal-Point-Process" class="headerlink" title="Explainable History Distillation by Marked Temporal Point Process"></a>Explainable History Distillation by Marked Temporal Point Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07797">http://arxiv.org/abs/2311.07797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sishun Liu, Ke Deng, Yan Wang, Xiuzhen Zhang</li>
<li>for: 这篇论文的目的是提出一种自动生成事件解释的机器学习系统，以便在实际任务中，特别是高度重要的任务中，让研究人员可以更好地理解机器学习模型的含义。</li>
<li>methods: 这篇论文提出了一种新的任务called \acrfull{ehd},它要求一个模型可以从历史记录中提取最少的事件，使得事件分布 conditional on 左边事件可以更好地预测未来。为了有效解决 \acrshort{ehd} 问题， authors 将任务重写为一个 \gls{01ip}，并直接使用名为 \acrfull{model} 的模型来解决这个问题。</li>
<li>results: 实验结果表明， \acrshort{model} 在 Retweet 和 Stack Overflow 数据集上显示出了显著的优势，并且可以 revelas 实际世界中的逻辑基础。<details>
<summary>Abstract</summary>
Explainability of machine learning models is mandatory when researchers introduce these commonly believed black boxes to real-world tasks, especially high-stakes ones. In this paper, we build a machine learning system to automatically generate explanations of happened events from history by \gls{ca} based on the \acrfull{tpp}. Specifically, we propose a new task called \acrfull{ehd}. This task requires a model to distill as few events as possible from observed history. The target is that the event distribution conditioned on left events predicts the observed future noticeably worse. We then regard distilled events as the explanation for the future. To efficiently solve \acrshort{ehd}, we rewrite the task into a \gls{01ip} and directly estimate the solution to the program by a model called \acrfull{model}. This work fills the gap between our task and existing works, which only spot the difference between factual and counterfactual worlds after applying a predefined modification to the environment. Experiment results on Retweet and StackOverflow datasets prove that \acrshort{model} significantly outperforms other \acrshort{ehd} baselines and can reveal the rationale underpinning real-world processes.
</details>
<details>
<summary>摘要</summary>
机器学习模型的可解释性是必备的当研究者将这些通常被认为是黑盒子引入到实际任务中，尤其是高度重要的任务。在这篇论文中，我们构建了一个机器学习系统，可以自动生成历史事件的解释。Specifically，我们提出了一个新的任务called \acrfull{ehd}.这个任务需要一个模型可以从观察历史中提取最少的事件，并且目标是使得事件分布 conditioned on 左事件可以预测未来的观察结果 Notable worse。然后，我们将液化的事件视为未来的解释。为了效率地解决 \acrshort{ehd}，我们将任务重写为 \gls{01ip} ，并直接通过一个模型called \acrfull{model}来解决该程序。这种方法填充了我们的任务和现有工作之间的空白，后者只是在应用先定的环境修改后才能够识别 Factual 和 counterfactual 世界的差异。实验结果表明，\acrshort{model}在 Retweet 和 StackOverflow 数据集上显著超越了其他 \acrshort{ehd} 基elines，并且可以揭示实际世界中的本质。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Hamilton-Jacobi-PDEs-with-time-dependent-Hamiltonians-for-continual-scientific-machine-learning"><a href="#Leveraging-Hamilton-Jacobi-PDEs-with-time-dependent-Hamiltonians-for-continual-scientific-machine-learning" class="headerlink" title="Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning"></a>Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07790">http://arxiv.org/abs/2311.07790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paula Chen, Tingwei Meng, Zongren Zou, Jérôme Darbon, George Em Karniadakis</li>
<li>for: 科学机器学习（SciML）中的解释性和计算效率两大挑战。</li>
<li>methods: 利用一种新的理论连接，将科学机器学习中的优化问题与一般化豪夫公式相连接，该公式表示一个时间依赖的汉密尔顿-雅可比 partial differential equation（HJ PDE）的viscosity解。通过这种连接，我们可以将解决某些带权学习问题的方法重新 интерпретирова为解决一个相关的控制问题和其对应的HJ PDE。这种连接允许我们在时间上跟踪学习过程中的模型更新，并且可以避免忘记性。</li>
<li>results: 我们在特殊情况下的线性回归问题中应用了这种连接，开发了一种基于Riccati方法的解决方案，该方案可以在持续学习应用中提供计算和存储的优化。我们还提供了一些相应的数据示例，显示了我们的方法在计算和存储方面的优势。<details>
<summary>Abstract</summary>
We address two major challenges in scientific machine learning (SciML): interpretability and computational efficiency. We increase the interpretability of certain learning processes by establishing a new theoretical connection between optimization problems arising from SciML and a generalized Hopf formula, which represents the viscosity solution to a Hamilton-Jacobi partial differential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show that when we solve certain regularized learning problems with integral-type losses, we actually solve an optimal control problem and its associated HJ PDE with time-dependent Hamiltonian. This connection allows us to reinterpret incremental updates to learned models as the evolution of an associated HJ PDE and optimal control problem in time, where all of the previous information is intrinsically encoded in the solution to the HJ PDE. As a result, existing HJ PDE solvers and optimal control algorithms can be reused to design new efficient training approaches for SciML that naturally coincide with the continual learning framework, while avoiding catastrophic forgetting. As a first exploration of this connection, we consider the special case of linear regression and leverage our connection to develop a new Riccati-based methodology for solving these learning problems that is amenable to continual learning applications. We also provide some corresponding numerical examples that demonstrate the potential computational and memory advantages our Riccati-based approach can provide.
</details>
<details>
<summary>摘要</summary>
我们面临科学机器学习（SciML）中的两大挑战：解释性和计算效率。我们将增强一些学习过程的解释性，通过建立一个新的理论连接，它连接了由SciML产生的优化问题和一个通用的豪夫公式，这个公式表示一个时间依赖的汉米顿-雅可比偏微分方程（HJ PDE）的沥丹解。具体来说，当我们解决一些具有积分类型损失函数的定制化学习问题时，我们其实是解决一个优化控制问题和其相关的HJ PDE。这个连接让我们可以将增量更新给学习模型视为时间演化的HJ PDE和优化控制问题，所有的先前信息都是内在地嵌入到HJ PDE的解中。因此，我们可以重用现有的HJ PDE解法和优化控制算法来设计新的高效训练方法，这些方法自然地与持续学习框架匹配，而不会发生衰减式遗传。作为一个首先探索这个连接的例子，我们考虑了特殊情况下的线性回推，并利用我们的连接，开发了一个新的里卡提-基础的方法学，这种方法适合持续学习应用。我们还提供了一些相应数例，以示出我们的方法可能具有更高的计算和内存优势。
</details></li>
</ul>
<hr>
<h2 id="Predicting-the-First-Response-Latency-of-Maintainers-and-Contributors-in-Pull-Requests"><a href="#Predicting-the-First-Response-Latency-of-Maintainers-and-Contributors-in-Pull-Requests" class="headerlink" title="Predicting the First Response Latency of Maintainers and Contributors in Pull Requests"></a>Predicting the First Response Latency of Maintainers and Contributors in Pull Requests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07786">http://arxiv.org/abs/2311.07786</a></li>
<li>repo_url: None</li>
<li>paper_authors: SayedHassan Khatoonabadi, Ahmad Abdellatif, Diego Elias Costa, Emad Shihab</li>
<li>For: The paper aims to predict the first response latency of maintainers and contributors in the context of pull requests (PRs) on GitHub.* Methods: The authors use a machine-learning approach with 21 features to predict the first response latency of maintainers and contributors. They evaluate seven types of classifiers and perform permutation feature importance and SHAP analyses to understand the impact of different features on the predicted response latencies.* Results: The authors achieve an average improvement of 33% in AUC-ROC and 58% in AUC-PR for maintainers, as well as 42% in AUC-ROC and 95% in AUC-PR for contributors compared to a no-skilled classifier across the projects. They find that PRs submitted earlier in the week, containing an average or slightly above-average number of commits, and with concise descriptions are more likely to receive faster first responses from the maintainers. Similarly, PRs with a lower first response latency from maintainers, that received the first response of maintainers earlier in the week, and containing an average or slightly above-average number of commits tend to receive faster first responses from the contributors. Additionally, contributors with a higher acceptance rate and a history of timely responses in the project are likely to both obtain and provide faster first responses.<details>
<summary>Abstract</summary>
The success of a Pull Request (PR) depends on the responsiveness of the maintainers and the contributor during the review process. Being aware of the expected waiting times can lead to better interactions and managed expectations for both the maintainers and the contributor. In this paper, we propose a machine-learning approach to predict the first response latency of the maintainers following the submission of a PR, and the first response latency of the contributor after receiving the first response from the maintainers. We curate a dataset of 20 large and popular open-source projects on GitHub and extract 21 features to characterize projects, contributors, PRs, and review processes. Using these features, we then evaluate seven types of classifiers to identify the best-performing models. We also perform permutation feature importance and SHAP analyses to understand the importance and impact of different features on the predicted response latencies. Our best-performing models achieve an average improvement of 33% in AUC-ROC and 58% in AUC-PR for maintainers, as well as 42% in AUC-ROC and 95% in AUC-PR for contributors compared to a no-skilled classifier across the projects. Our findings indicate that PRs submitted earlier in the week, containing an average or slightly above-average number of commits, and with concise descriptions are more likely to receive faster first responses from the maintainers. Similarly, PRs with a lower first response latency from maintainers, that received the first response of maintainers earlier in the week, and containing an average or slightly above-average number of commits tend to receive faster first responses from the contributors. Additionally, contributors with a higher acceptance rate and a history of timely responses in the project are likely to both obtain and provide faster first responses.
</details>
<details>
<summary>摘要</summary>
Success of a Pull Request (PR) 取决于维护者和贡献者在审核过程中的反应速度。了解审核过程的等待时间可以导致更好的互动和管理的期望。在这篇论文中，我们提出一种机器学习方法，可以预测维护者对于PR的第一个响应时间，以及贡献者对于维护者的第一个响应时间。我们收录了20个大型和受欢迎的开源项目的GitHub数据集，并提取了21个特征来描述项目、贡献者、PR和审核过程。使用这些特征，我们然后评估了七种类型的分类器，以确定最佳性能的模型。我们还进行了排序特征重要性和SHAP分析，以了解不同特征对预测响应时间的重要性和影响。我们的最佳模型在20个项目中的AUC-ROC和AUC-PR方面达到了33%的平均提升和58%的平均提升，而贡献者的AUC-ROC和AUC-PR方面达到了42%的平均提升和95%的平均提升。我们的发现表明，PR在星期一提交的早些时候，包含平均或微妙的提交数量，并且描述简洁的PR更有可能得到更快的第一个响应。同时，维护者的第一个响应时间早些，贡献者的第一个响应时间早些，贡献者的acceptance rate高和历史快速响应率高的贡献者更有可能得到和提供更快的第一个响应。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Local-Attention-with-Hierarchical-Patching-for-Irregular-Clinical-Time-Series"><a href="#Dynamic-Local-Attention-with-Hierarchical-Patching-for-Irregular-Clinical-Time-Series" class="headerlink" title="Dynamic Local Attention with Hierarchical Patching for Irregular Clinical Time Series"></a>Dynamic Local Attention with Hierarchical Patching for Irregular Clinical Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07744">http://arxiv.org/abs/2311.07744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyu Chen, Xiaochen Zheng, Amina Mollaysa, Manuel Schürch, Ahmed Allam, Michael Krauthammer</li>
<li>for: 这篇论文是为了解决在医疗和健康领域中频繁出现的不规则多ivariate时间序列数据的问题。</li>
<li>methods: 这篇论文使用了一个新的模型架构，包括两个模块：(1) DLA，一个动态本地注意力机制，通过学习的问题和特定的特征本地窗口来计算自我注意力操作。这会将不规则时间步的原始输入转换为一个调和的常规特征空间表示，同时考虑不同特征的抽样率。(2) 一个层次MLP混合器，将 DLA 的出力处理，通过多尺度装配来利用不同的尺度上的信息来进行下游任务。</li>
<li>results: 这篇论文的方法比前一些方法在三个真实世界数据集上表现更好，包括最新的医疗 MIMIC IV 数据集。<details>
<summary>Abstract</summary>
Irregular multivariate time series data is prevalent in the clinical and healthcare domains. It is characterized by time-wise and feature-wise irregularities, making it challenging for machine learning methods to work with. To solve this, we introduce a new model architecture composed of two modules: (1) DLA, a Dynamic Local Attention mechanism that uses learnable queries and feature-specific local windows when computing the self-attention operation. This results in aggregating irregular time steps raw input within each window to a harmonized regular latent space representation while taking into account the different features' sampling rates. (2) A hierarchical MLP mixer that processes the output of DLA through multi-scale patching to leverage information at various scales for the downstream tasks. Our approach outperforms state-of-the-art methods on three real-world datasets, including the latest clinical MIMIC IV dataset.
</details>
<details>
<summary>摘要</summary>
众多变量时间序列数据在医疗和健康领域非常普遍，它具有时间和特征方面的不规则性，使得机器学习方法很难处理。为解决这个问题，我们介绍了一种新的模型架构，包括两个模块：（1）DLA（动态本地注意力机制），它使用学习的查询和特征特定的本地窗口来计算自注意操作。这将在每个窗口中将不规则时间步骤的原始输入融合到一个协调的常规特征空间表示中，同时考虑不同特征的抽取速率。（2）层次MLP混合器，它将DLA输出处理过多个尺度的补丁来利用不同尺度的信息来下游任务。我们的方法在三个实际世界数据集上达到了现有方法的最佳性能，包括最新的医疗MIMIC IV数据集。
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Quantum-Blockmodeling-with-Qubits-and-Permutations"><a href="#A-Simple-Quantum-Blockmodeling-with-Qubits-and-Permutations" class="headerlink" title="A Simple Quantum Blockmodeling with Qubits and Permutations"></a>A Simple Quantum Blockmodeling with Qubits and Permutations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07726">http://arxiv.org/abs/2311.07726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar Daskin</li>
<li>For: 这篇论文的目的是为了介绍一种基于排序矩阵的量子阈值模型，用于数据分析任务。* Methods: 这种模型使用了排序矩阵和 permutation matrix，并通过在量子计算机上并行执行排序来实现效率的计算。* Results: 论文表明，使用这种模型可以在 $O(log(N))$ 时间内查找或更新适应值，比类 классической计算机更快。此外，由于量子Circuit中可以同时执行不同的排序序列，因此这种模型在量子计算机上可以更有效地实现机器学习任务。<details>
<summary>Abstract</summary>
Blockmodeling of a given problem represented by an $N\times N$ adjacency matrix can be found by swapping rows and columns of the matrix (i.e. multiplying matrix from left and right by a permutation matrix). In general, through performing this task, row and column permutations affect the fitness value in optimization: For an $N\times N$ matrix, it requires $O(N)$ computations to find (or update) the fitness value of a candidate solution.   On quantum computers, permutations can be applied in parallel and efficiently, and their implementations can be as simple as a single qubit operation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step. In this paper, using permutation matrices, we describe a quantum blockmodeling for data analysis tasks. In the model, the measurement outcome of a small group of qubits are mapped to indicate the fitness value. Therefore, we show that it is possible to find or update the fitness value in $O(log(N))$ time. This lead us to show that when the number of iterations are less than $log(N)$ time, it may be possible to reach the same solution exponentially faster on quantum computers in comparison to classical computers. In addition, since on quantum circuits the different sequence of permutations can be applied in parallel (superpositon), the machine learning task in this model can be implemented more efficiently on quantum computers.
</details>
<details>
<summary>摘要</summary>
Blockmodeling of a given problem represented by an $N\times N$ adjacency matrix can be found by swapping rows and columns of the matrix (i.e. multiplying matrix from left and right by a permutation matrix). In general, through performing this task, row and column permutations affect the fitness value in optimization: For an $N\times N$ matrix, it requires $O(N)$ computations to find (or update) the fitness value of a candidate solution.  On quantum computers, permutations can be applied in parallel and efficiently, and their implementations can be as simple as a single qubit operation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step. In this paper, using permutation matrices, we describe a quantum blockmodeling for data analysis tasks. In the model, the measurement outcome of a small group of qubits are mapped to indicate the fitness value. Therefore, we show that it is possible to find or update the fitness value in $O(log(N))$ time. This lead us to show that when the number of iterations are less than $log(N)$ time, it may be possible to reach the same solution exponentially faster on quantum computers in comparison to classical computers. In addition, since on quantum circuits the different sequence of permutations can be applied in parallel (superposition), the machine learning task in this model can be implemented more efficiently on quantum computers.Here's the text with the original English text and the Simplified Chinese translation side by side for reference:Original English Text:Blockmodeling of a given problem represented by an $N\times N$ adjacency matrix can be found by swapping rows and columns of the matrix (i.e. multiplying matrix from left and right by a permutation matrix). In general, through performing this task, row and column permutations affect the fitness value in optimization: For an $N\times N$ matrix, it requires $O(N)$ computations to find (or update) the fitness value of a candidate solution.  Simplified Chinese Translation:Blockmodeling of a given problem represented by an $N\times N$ adjacency matrix can be found by swapping rows and columns of the matrix (i.e. multiplying matrix from left and right by a permutation matrix). In general, through performing this task, row and column permutations affect the fitness value in optimization: For an $N\times N$ matrix, it requires $O(N)$ computations to find (or update) the fitness value of a candidate solution.  Original English Text:On quantum computers, permutations can be applied in parallel and efficiently, and their implementations can be as simple as a single qubit operation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step.Simplified Chinese Translation:On quantum computers, permutations can be applied in parallel and efficiently, and their implementations can be as simple as a single qubit operation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step.Original English Text:In this paper, using permutation matrices, we describe a quantum blockmodeling for data analysis tasks. In the model, the measurement outcome of a small group of qubits are mapped to indicate the fitness value. Therefore, we show that it is possible to find or update the fitness value in $O(log(N))$ time.Simplified Chinese Translation:In this paper, using permutation matrices, we describe a quantum blockmodeling for data analysis tasks. In the model, the measurement outcome of a small group of qubits are mapped to indicate the fitness value. Therefore, we show that it is possible to find or update the fitness value in $O(log(N))$ time.
</details></li>
</ul>
<hr>
<h2 id="Deep-Phenotyping-of-Non-Alcoholic-Fatty-Liver-Disease-Patients-with-Genetic-Factors-for-Insights-into-the-Complex-Disease"><a href="#Deep-Phenotyping-of-Non-Alcoholic-Fatty-Liver-Disease-Patients-with-Genetic-Factors-for-Insights-into-the-Complex-Disease" class="headerlink" title="Deep Phenotyping of Non-Alcoholic Fatty Liver Disease Patients with Genetic Factors for Insights into the Complex Disease"></a>Deep Phenotyping of Non-Alcoholic Fatty Liver Disease Patients with Genetic Factors for Insights into the Complex Disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08428">http://arxiv.org/abs/2311.08428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tahmina Sultana Priya, Fan Leng, Anthony C. Luehrs, Eric W. Klee, Alina M. Allen, Konstantinos N. Lazaridis, Danfeng, Yao, Shulan Tian<br>for:* This study aimed to identify subgroups of Non-alcoholic fatty liver disease (NAFLD) patients based on demographic, clinical, and genetic characteristics for precision medicine.methods:* The study used genomic and phenotypic data from 3,408 NAFLD cases and 4,739 controls, including demographic, clinical, and comorbidity data, and genotype information through whole exome sequencing.* The study used a chi-square test and stepwise backward-forward regression model to determine factors highly relevant to NAFLD, and latent class analysis (LCA) to identify subgroups.results:* The study identified 5 latent subgroups of NAFLD patients, characterized by metabolic syndrome, obesity, different comorbidities, psychoneurological factors, and genetic factors.* Cluster 2 had a significantly higher complex disease outcome compared to other clusters, including fibrosis, cirrhosis, and hepatocellular carcinoma (HCC), as well as liver failure.Here is the information in Simplified Chinese text:for:* 这个研究的目的是通过人群特征和生物 markers 进行精准医学，为NAFLD 患者提供个性化治疗。methods:* 这个研究使用了3408例 NAFLD 患者和4739例控制人群的 genomic 和 fenotypic 数据，包括人群特征、临床特征和相关疾病数据，以及通过整个扩展 sequencing 获得的 genotype 信息。* 研究使用 chi-square 测试和步骤性回推前进回归模型来确定 NAFLD 高度相关的因素，并使用 latent class analysis (LCA) 来确定患者群体。results:* 研究发现了5个 latent 群体，每个群体都具有不同的 мета波性、肥胖、不同的相关疾病、心神内科因素和遗传因素。* 群体2的复杂疾病结果明显高于其他群体，包括 fibrosis、cirrhosis 和肝癌 (HCC) 以及肝功能失调。<details>
<summary>Abstract</summary>
Non-alcoholic fatty liver disease (NAFLD) is a prevalent chronic liver disorder characterized by the excessive accumulation of fat in the liver in individuals who do not consume significant amounts of alcohol, including risk factors like obesity, insulin resistance, type 2 diabetes, etc. We aim to identify subgroups of NAFLD patients based on demographic, clinical, and genetic characteristics for precision medicine. The genomic and phenotypic data (3,408 cases and 4,739 controls) for this study were gathered from participants in Mayo Clinic Tapestry Study (IRB#19-000001) and their electric health records, including their demographic, clinical, and comorbidity data, and the genotype information through whole exome sequencing performed at Helix using the Exome+$^\circledR$ Assay according to standard procedure (www$.$helix$.$com). Factors highly relevant to NAFLD were determined by the chi-square test and stepwise backward-forward regression model. Latent class analysis (LCA) was performed on NAFLD cases using significant indicator variables to identify subgroups. The optimal clustering revealed 5 latent subgroups from 2,013 NAFLD patients (mean age 60.6 years and 62.1% women), while a polygenic risk score based on 6 single-nucleotide polymorphism (SNP) variants and disease outcomes were used to analyze the subgroups. The groups are characterized by metabolic syndrome, obesity, different comorbidities, psychoneurological factors, and genetic factors. Odds ratios were utilized to compare the risk of complex diseases, such as fibrosis, cirrhosis, and hepatocellular carcinoma (HCC), as well as liver failure between the clusters. Cluster 2 has a significantly higher complex disease outcome compared to other clusters. Keywords: Fatty liver disease; Polygenic risk score; Precision medicine; Deep phenotyping; NAFLD comorbidities; Latent class analysis.
</details>
<details>
<summary>摘要</summary>
非酒精脂肪liver病（NAFLD）是一种常见的慢性肝病，表现为不 consume significant amounts of alcohol 的人肝中聚集过多脂肪，包括风险因素如肥胖、荷尔血症、第二型糖尿病等。我们的目标是通过基因和现象特征来分类NAFLD患者，为精准医学提供优化的治疗方案。这些数据来自Mayo临床研究（IRB#19-000001）和其电子健康纪录，包括参与者的民生、临床和相关疾病数据，以及通过全染色体测序实施的基因信息。经过χ²测试和步骤式回溯前进分析模型，确定了NAFLD高度相关的因素。使用秘密分析法（LCA）对NAFLD患者进行分类，并确定了5个秘密群体。这5个群体被定义为不同的 метаболиic syndrome、肥胖、不同的相关疾病、神经内科因素和遗传因素。通过对每个群体的复杂疾病结果进行比较，发现群体2的复杂疾病结果显著高于其他群体。关键词：脂肪肝病；多单 nucleotide polymorphism（SNP）变种；精准医学；深度现象分析；NAFLD相关疾病；秘密分析法。
</details></li>
</ul>
<hr>
<h2 id="Matching-aggregate-posteriors-in-the-variational-autoencoder"><a href="#Matching-aggregate-posteriors-in-the-variational-autoencoder" class="headerlink" title="Matching aggregate posteriors in the variational autoencoder"></a>Matching aggregate posteriors in the variational autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07693">http://arxiv.org/abs/2311.07693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Surojit Saha, Sarang Joshi, Ross Whitaker</li>
<li>for: 提高VAEs的适用范围和性能，解决VAEs常见的“囊泡”和“后退”问题</li>
<li>methods: 基于VAE的理论基础，使用kernel density estimate（KDE）模型高维合计 posterior distribution，提出了aggregate variational autoencoder（AVAE）方法</li>
<li>results: 对多个referenced数据集进行实验，与现有方法相比，AVAE方法表现更高效<details>
<summary>Abstract</summary>
The variational autoencoder (VAE) is a well-studied, deep, latent-variable model (DLVM) that efficiently optimizes the variational lower bound of the log marginal data likelihood and has a strong theoretical foundation. However, the VAE's known failure to match the aggregate posterior often results in \emph{pockets/holes} in the latent distribution (i.e., a failure to match the prior) and/or \emph{posterior collapse}, which is associated with a loss of information in the latent space. This paper addresses these shortcomings in VAEs by reformulating the objective function associated with VAEs in order to match the aggregate/marginal posterior distribution to the prior. We use kernel density estimate (KDE) to model the aggregate posterior in high dimensions. The proposed method is named the \emph{aggregate variational autoencoder} (AVAE) and is built on the theoretical framework of the VAE. Empirical evaluation of the proposed method on multiple benchmark data sets demonstrates the effectiveness of the AVAE relative to state-of-the-art (SOTA) methods.
</details>
<details>
<summary>摘要</summary>
“VAEs是一种已经广泛研究的深度隐变量模型（DLVM），能够有效地优化变量下界和具有强的理论基础。然而，VAEs通常会出现\"囊括/洞\"在幂分布中（即失准备）和/或\"后退\"，这与数据信息损失在隐变量空间相关。这篇论文解决了VAEs中这些缺陷，通过修改VAEs的目标函数，使其能够匹配归一化 posterior distribution 和先验分布。我们使用核密度估计（KDE）来模型高维归一化 posterior distribution。我们提出的方法被称为\"归一化变量自动编码器\"（AVAE），基于VAEs的理论基础。我们对多个参考数据集进行了实验评估，并证明了AVAE相比 estado-of-the-art（SOTA）方法更有效。”Note: Please note that the translation is in Simplified Chinese, which is one of the two standard varieties of Chinese. If you prefer Traditional Chinese, I can provide that as well. Additionally, please keep in mind that machine translation can sometimes be imperfect, and the nuances of the original text may be lost in translation.
</details></li>
</ul>
<hr>
<h2 id="Feature-emergence-via-margin-maximization-case-studies-in-algebraic-tasks"><a href="#Feature-emergence-via-margin-maximization-case-studies-in-algebraic-tasks" class="headerlink" title="Feature emergence via margin maximization: case studies in algebraic tasks"></a>Feature emergence via margin maximization: case studies in algebraic tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07568">http://arxiv.org/abs/2311.07568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Depen Morwani, Benjamin L. Edelman, Costin-Andrei Oncescu, Rosie Zhao, Sham Kakade</li>
<li>for: 本研究探讨了神经网络学习时所学习的内部表示形式，即神经网络如何选择特定的计算策略。</li>
<li>methods: 本研究使用了 margin maximization 原理来完全解释神经网络学习的特性。</li>
<li>results: 研究发现，神经网络在解决代数学习任务时会使用 fourier 特征来实现模块加法，并使用 irreducible 群论中的表示特征来实现总体组合。这与 Nanda et al. 和 Chughtai et al. 的实验结果吻合得非常 closely。<details>
<summary>Abstract</summary>
Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning. While there have been significant recent strides in some cases towards understanding how neural networks implement specific target functions, this paper explores a complementary question -- why do networks arrive at particular computational strategies? Our inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations. Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks. Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network. Specifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. and Chughtai et al. More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies.
</details>
<details>
<summary>摘要</summary>
理解神经网络学习过程中内部表征的学习是机器学习科学中一个重要挑战。本文探讨了一个相关问题：神经网络何以采用特定计算策略呢？我们的研究集中在代数学习任务上，包括幂加法、稀疏偶数和整数群操作。我们的主要理论发现可以使用边缘margin最大化原则来完全描述神经网络学习到的特征。具体来说，我们证明神经网络在训练过程中使用FOURIER特征来实现幂加法，并使用对应于整数群理论中reducible的表示来执行总体群操作，与实际观察结果相吻合。更一般来说，我们希望我们的技术可以帮助更深入地理解神经网络采用特定计算策略的原因。
</details></li>
</ul>
<hr>
<h2 id="Exploration-via-linearly-perturbed-loss-minimisation"><a href="#Exploration-via-linearly-perturbed-loss-minimisation" class="headerlink" title="Exploration via linearly perturbed loss minimisation"></a>Exploration via linearly perturbed loss minimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07565">http://arxiv.org/abs/2311.07565</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/davidjanz/evill-code">https://github.com/davidjanz/evill-code</a></li>
<li>paper_authors: David Janz, Shuai Liu, Alex Ayoub, Csaba Szepesvári</li>
<li>for: 这个论文是为了解决结构化随机带强问题中的探索问题。</li>
<li>methods: 这篇论文提出了一种随机探索方法，即解决一个线性偏移的减少 log-likelihood 函数的最小值。在总体化线性带中，这种方法降到 perturbed history exploration（PHE）。</li>
<li>results: 论文表明，使用我们提出的数据依赖的偏移，EVILL可以与参数偏移方法匹配性能，并且在理论和实践中都有good表现。此外，论文还提供了一个外部 generalised linear bandits 中 PHE 会导致不稳定估计，而 EVILL 仍然表现良好的示例。<details>
<summary>Abstract</summary>
We introduce exploration via linear loss perturbations (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. With the data-dependent perturbations we propose, not present in previous PHE-type methods, EVILL is shown to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside of generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code.
</details>
<details>
<summary>摘要</summary>
我们介绍了探索via线性损失偏移（EVILL），一种随机探索方法 для结构化随机抽象问题，它通过解决一个线性偏移后的减少正负扩展函数的最小值。我们显示，在通用化线性抽象问题下，EVILL降到了受扰的历史探索（PHE），一种通过训练在随机偏移奖励上进行探索。在这之中，我们提供了一个简单清晰的解释，当和为什么随机奖励偏移会导致好的抽象问题Algorithm。我们还提出了一种使用我们所提出的数据依赖的偏移，不存在在前一些PHE-型方法中的偏移，EVILL可以与参数偏移方法匹配表现， both in theory and in practice。此外，我们显示了一个外部普通化线性抽象问题中，PHE会导致不一致的估计，从而导致线性 regret，而EVILL则保持高效。与PHE一样，EVILL可以在只需几行程式码中实现。
</details></li>
</ul>
<hr>
<h2 id="Learning-Control-Policies-of-Hodgkin-Huxley-Neuronal-Dynamics"><a href="#Learning-Control-Policies-of-Hodgkin-Huxley-Neuronal-Dynamics" class="headerlink" title="Learning Control Policies of Hodgkin-Huxley Neuronal Dynamics"></a>Learning Control Policies of Hodgkin-Huxley Neuronal Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07563">http://arxiv.org/abs/2311.07563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Malvern Madondo, Deepanshu Verma, Lars Ruthotto, Nicholas Au Yong</li>
<li>for: 这个论文的目的是开发一种基于神经网络的深脑刺激（DBS）closed-loop控制方法，以优化治疗效果。</li>
<li>methods: 该方法使用了一种控制策略，通过在实时基于患者的神经活动的参数调整DBS系统，以实现在线调整DBS系统的控制策略。</li>
<li>results: 该方法的实验结果显示，可以准确地预测患者的神经活动，并在不同的输入和输出参数下进行优化调整，以提高治疗效果。<details>
<summary>Abstract</summary>
We present a neural network approach for closed-loop deep brain stimulation (DBS). We cast the problem of finding an optimal neurostimulation strategy as a control problem. In this setting, control policies aim to optimize therapeutic outcomes by tailoring the parameters of a DBS system, typically via electrical stimulation, in real time based on the patient's ongoing neuronal activity. We approximate the value function offline using a neural network to enable generating controls (stimuli) in real time via the feedback form. The neuronal activity is characterized by a nonlinear, stiff system of differential equations as dictated by the Hodgkin-Huxley model. Our training process leverages the relationship between Pontryagin's maximum principle and Hamilton-Jacobi-Bellman equations to update the value function estimates simultaneously. Our numerical experiments illustrate the accuracy of our approach for out-of-distribution samples and the robustness to moderate shocks and disturbances in the system.
</details>
<details>
<summary>摘要</summary>
我们提出了一种神经网络方法用于关闭式深脑刺激（DBS）。我们将问题找到优化神经刺激策略转化为控制问题。在这种设定下，控制策略 aim to 优化治疗结果，通过在患者的进行实时电抗应用的DBS系统中调整参数，根据患者的持续神经活动。我们使用神经网络在线预测值函数，以便在实时通过反馈形式生成控制（刺激）。神经活动被描述为非线性、硬系统的差分方程，由韦德-休克利模型确定。我们的训练过程利用普通拉格曼最大原理和汉密尔-雅各布-贝尔曼方程来同时更新估计值函数。我们的数值实验表明我们的方法对于不同样本和系统强大扰动的稳定性和精度具有高度的准确性和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Data-Efficient-Task-Generalization-via-Probabilistic-Model-based-Meta-Reinforcement-Learning"><a href="#Data-Efficient-Task-Generalization-via-Probabilistic-Model-based-Meta-Reinforcement-Learning" class="headerlink" title="Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning"></a>Data-Efficient Task Generalization via Probabilistic Model-based Meta Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07558">http://arxiv.org/abs/2311.07558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arjun Bhardwaj, Jonas Rothfuss, Bhavya Sukhija, Yarden As, Marco Hutter, Stelian Coros, Andreas Krause</li>
<li>for: 这个研究设计了一个名为 PACOH-RL 的模型基于 Meta-循环学习（Meta-RL）算法，用于快速适应不断变化的动力学。</li>
<li>methods: PACOH-RL 使用了热点热点热点（PACOH）来学习动力学模型的偏好，以便快速适应新的动力学情况。此外，它还包括了调整和知识不确定量化，以便在适应新情况时更好地调整探索和数据收集。</li>
<li>results: 实验结果显示，PACOH-RL 比模型基于 RL 和模型基于 Meta-RL 的基eline表现更好，能够快速适应新的动力学情况。此外，在一个真实的机械车上，我们还证明了 PACOH-RL 可以在没有充足的数据情况下进行高效的RL策略适应。<details>
<summary>Abstract</summary>
We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning (Meta-RL) algorithm designed to efficiently adapt control policies to changing dynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift adaptation to new dynamics with minimal interaction data. Existing Meta-RL methods require abundant meta-learning data, limiting their applicability in settings such as robotics, where data is costly to obtain. To address this, PACOH-RL incorporates regularization and epistemic uncertainty quantification in both the meta-learning and task adaptation stages. When facing new dynamics, we use these uncertainty estimates to effectively guide exploration and data collection. Overall, this enables positive transfer, even when access to data from prior tasks or dynamic settings is severely limited. Our experiment results demonstrate that PACOH-RL outperforms model-based RL and model-based Meta-RL baselines in adapting to new dynamic conditions. Finally, on a real robotic car, we showcase the potential for efficient RL policy adaptation in diverse, data-scarce conditions.
</details>
<details>
<summary>摘要</summary>
我们介绍PACOH-RL，一种新的模型基于Meta-循环学习（Meta-RL）算法，用于快速适应更改的动力学。PACOH-RL在元学习阶段学习动力学模型的假设，以便快速适应新的动力学，只需要最小化互动数据。现有的Meta-RL方法需要充足的元学习数据，限制了它们在机器人等设置中的应用。为解决这个问题，PACOH-RL将在元学习和任务适应阶段中添加了调整和知识不确定量化。当面对新的动力学时，我们使用这些不确定度估计来有效地导引探索和数据收集。这使得PACOH-RL能够在仅有限的数据情况下进行有益的RL政策适应。我们的实验结果显示，PACOH-RL在适应新的动力学条件时表现出色，比model-based RL和model-based Meta-RL基eline更好。最后，我们在一辆真实的机器人车上展示了PACOH-RL在多元、数据缺乏的情况下的实际应用潜力。
</details></li>
</ul>
<hr>
<h2 id="Tabdoor-Backdoor-Vulnerabilities-in-Transformer-based-Neural-Networks-for-Tabular-Data"><a href="#Tabdoor-Backdoor-Vulnerabilities-in-Transformer-based-Neural-Networks-for-Tabular-Data" class="headerlink" title="Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data"></a>Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07550">http://arxiv.org/abs/2311.07550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bart Pleiter, Behrad Tajalli, Stefanos Koffas, Gorka Abad, Jing Xu, Martha Larson, Stjepan Picek</li>
<li>for: 研究攻击和 защищать深度神经网络（DNN）在表格数据上的攻击性质。</li>
<li>methods: 使用transformer模型对表格数据进行深度学习，并对其进行系统性的实验 исследование。</li>
<li>results: 发现transformer模型对表格数据的攻击性质强，可以通过 minimal feature value alterations 实现nearly perfect attack success rates（约100%）。另外， Spectral Signatures 被证明是最有效的防御策略。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have shown great promise in various domains. Alongside these developments, vulnerabilities associated with DNN training, such as backdoor attacks, are a significant concern. These attacks involve the subtle insertion of triggers during model training, allowing for manipulated predictions. More recently, DNNs for tabular data have gained increasing attention due to the rise of transformer models.   Our research presents a comprehensive analysis of backdoor attacks on tabular data using DNNs, particularly focusing on transformer-based networks. Given the inherent complexities of tabular data, we explore the challenges of embedding backdoors. Through systematic experimentation across benchmark datasets, we uncover that transformer-based DNNs for tabular data are highly susceptible to backdoor attacks, even with minimal feature value alterations. Our results indicate nearly perfect attack success rates (approx100%) by introducing novel backdoor attack strategies to tabular data. Furthermore, we evaluate several defenses against these attacks, identifying Spectral Signatures as the most effective one. Our findings highlight the urgency to address such vulnerabilities and provide insights into potential countermeasures for securing DNN models against backdoors on tabular data.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在不同领域都显示出了很大的承诺。同时，DNN训练中的漏洞，如后门攻击，也成为了一个重要的问题。这些攻击通过在模型训练过程中抽象插入特征，以致于模型的预测被操纵。在最近，使用表格数据的DNN受到了越来越多的关注，特别是由于 transformer 模型的出现。  我们的研究对 tabular 数据使用 DNN 进行了全面的后门攻击分析，特别是对 transformer 基于的网络进行了研究。由于表格数据的内在复杂性，我们探讨了后门攻击的挑战。通过对标准 benchmark 数据集进行系统实验，我们发现了 transformer 基于的 DNN 对 tabular 数据的后门攻击非常易受，即使特征值变化非常小。我们的结果表明，通过引入新的后门攻击策略，可以在 tabular 数据上达到 nearly 100% 的攻击成功率。此外，我们评估了多种防御策略，并发现 spectral signatures 是最有效的一种。我们的发现强调了需要解决这类漏洞，并提供了可能的对策方法来保护 DNN 模型免受 tabular 数据上的后门攻击。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Fine-Tuning-for-Graph-Neural-Network-Surrogate-Models"><a href="#Interpretable-Fine-Tuning-for-Graph-Neural-Network-Surrogate-Models" class="headerlink" title="Interpretable Fine-Tuning for Graph Neural Network Surrogate Models"></a>Interpretable Fine-Tuning for Graph Neural Network Surrogate Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07548">http://arxiv.org/abs/2311.07548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shivam Barwey, Romit Maulik</li>
<li>for: 本研究的目标是提出一种可解释的精度调整策略，用于提高基于图 neural network (GNN) 的无结构域流体动力学模型的预测能力。</li>
<li>methods: 该策略基于一种可变的子图采样策略，可以在前向传播中随机选择与预测任务直接相关的物理空间区域，并将这些区域作为基于输入的可读性函数进行表示。</li>
<li>results: 通过对一种基于 GNN 的基线模型进行可解释的精度调整，研究人员可以获得一个具有可读性函数的 fine-tuned GNN，该函数可以在预测过程中标识与预测任务直接相关的物理空间区域。此外，通过一种Regularization程序， fine-tuned GNN 还可以在推理过程中标识大多数预测错误的图节点，从而为基eline模型增加一种新的可解释的错误标记功能。<details>
<summary>Abstract</summary>
Data-based surrogate modeling has surged in capability in recent years with the emergence of graph neural networks (GNNs), which can operate directly on mesh-based representations of data. The goal of this work is to introduce an interpretable fine-tuning strategy for GNNs, with application to unstructured mesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that adds interpretability to a pre-trained baseline GNN through an adaptive sub-graph sampling strategy that isolates regions in physical space intrinsically linked to the forecasting task, while retaining the predictive capability of the baseline. The structures identified by the fine-tuned GNNs, which are adaptively produced in the forward pass as explicit functions of the input, serve as an accessible link between the baseline model architecture, the optimization goal, and known problem-specific physics. Additionally, through a regularization procedure, the fine-tuned GNNs can also be used to identify, during inference, graph nodes that correspond to a majority of the anticipated forecasting error, adding a novel interpretable error-tagging capability to baseline models. Demonstrations are performed using unstructured flow data sourced from flow over a backward-facing step at high Reynolds numbers.
</details>
<details>
<summary>摘要</summary>
“数据基于的代理模型在近年来有了很大的进步，尤其是图 neck 网络（GNN），可以直接操作在数据表示中的碰撞网格。本工作的目标是介绍一种可解释的细化策略 для GNN，并应用于无结构的碰撞网格基础流动模型。结果是一种可解释的 GNN，通过适应性的子图抽样策略，隔离物理空间中与预测任务直接相关的区域，保留基础模型的预测能力。由 fine-tuned GNN 生成的结构，在前向传播中为 explicit 函数而生成的，作为基础模型架构、优化目标和已知问题特有物理的可访问的链接。此外，通过规则化程序， fine-tuned GNN 还可以在推理过程中标识出大多数预测错误的图节点，添加了基础模型中的一种新的可解释错误标记功能。示例通过来源于高 Reynolds 数的逆推流动数据进行演示。”
</details></li>
</ul>
<hr>
<h2 id="mlscorecheck-Testing-the-consistency-of-reported-performance-scores-and-experiments-in-machine-learning"><a href="#mlscorecheck-Testing-the-consistency-of-reported-performance-scores-and-experiments-in-machine-learning" class="headerlink" title="mlscorecheck: Testing the consistency of reported performance scores and experiments in machine learning"></a>mlscorecheck: Testing the consistency of reported performance scores and experiments in machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07541">http://arxiv.org/abs/2311.07541</a></li>
<li>repo_url: None</li>
<li>paper_authors: György Kovács, Attila Fazekas</li>
<li>for:  validate reported experimental results in artificial intelligence</li>
<li>methods:  numerical techniques for identifying inconsistencies in machine learning problems</li>
<li>results:  developed an open-source package (mlscorecheck) with specific test bundles to detect systematically recurring flaws in various fields<details>
<summary>Abstract</summary>
Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a challenging task. It necessitates either the reimplementation of techniques or a meticulous assessment of papers for deviations from the scientific method and best statistical practices. To facilitate the validation of reported results, we have developed numerical techniques capable of identifying inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression. These consistency tests are integrated into the open-source package mlscorecheck, which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a difficult task. It requires either reimplementing techniques or carefully assessing papers for deviations from the scientific method and best statistical practices. To facilitate the validation of reported results, we have developed numerical techniques that can identify inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression. These consistency tests are integrated into the open-source package mlscorecheck, which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China and Singapore. Traditional Chinese is also widely used in Taiwan, Hong Kong, and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Estimating-optical-vegetation-indices-with-Sentinel-1-SAR-data-and-AutoML"><a href="#Estimating-optical-vegetation-indices-with-Sentinel-1-SAR-data-and-AutoML" class="headerlink" title="Estimating optical vegetation indices with Sentinel-1 SAR data and AutoML"></a>Estimating optical vegetation indices with Sentinel-1 SAR data and AutoML</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07537">http://arxiv.org/abs/2311.07537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Paluba, Bertrand Le Saux, Francesco Sarti, Přemysl Stych</li>
<li>for: 这个研究的目的是将Synthetic Aperture Radar（SAR）数据用于取代光学数据，并且为森林监控系统提供更好的时间分辨率和空间分辨率。</li>
<li>methods: 本研究使用了Google Earth Engine（GEE）创建了一个多标准和多模式的数据集，包括时间和空间对称的Sentinel-1、Sentinel-2、地形高程数据（DEM）、天气和土地类型数据（MMT-GEE）。此外，还使用了DEM和天气数据生成的辅助特征来提高结果。</li>
<li>results: 研究结果显示，使用AutoML方法可以超过Random Forest Regression的性能，并且在三个中的四个维度上得到了69-84%的R2低误（0.05-0.32的MAE，对应的VI的低误）。此外，选择的案例研究显示，SAR-based VI可以实现更好的时间分辨率和空间分辩率，并且可以探测森林发生的突然变化。<details>
<summary>Abstract</summary>
Current optical vegetation indices (VIs) for monitoring forest ecosystems are widely used in various applications. However, continuous monitoring based on optical satellite data can be hampered by atmospheric effects such as clouds. On the contrary, synthetic aperture radar (SAR) data can offer insightful and systematic forest monitoring with complete time series due to signal penetration through clouds and day and night acquisitions. The goal of this work is to overcome the issues affecting optical data with SAR data and serve as a substitute for estimating optical VIs for forests using machine learning. Time series of four VIs (LAI, FAPAR, EVI and NDVI) were estimated using multitemporal Sentinel-1 SAR and ancillary data. This was enabled by creating a paired multi-temporal and multi-modal dataset in Google Earth Engine (GEE), including temporally and spatially aligned Sentinel-1, Sentinel-2, digital elevation model (DEM), weather and land cover datasets (MMT-GEE). The use of ancillary features generated from DEM and weather data improved the results. The open-source Automatic Machine Learning (AutoML) approach, auto-sklearn, outperformed Random Forest Regression for three out of four VIs, while a 1-hour optimization length was enough to achieve sufficient results with an R2 of 69-84% low errors (0.05-0.32 of MAE depending on VI). Great agreement was also found for selected case studies in the time series analysis and in the spatial comparison between the original and estimated SAR-based VIs. In general, compared to VIs from currently freely available optical satellite data and available global VI products, a better temporal resolution (up to 240 measurements/year) and a better spatial resolution (20 m) were achieved using estimated SAR-based VIs. A great advantage of the SAR-based VI is the ability to detect abrupt forest changes with a sub-weekly temporal accuracy.
</details>
<details>
<summary>摘要</summary>
现有的光学植被指数（VI）在监测森林生态系统方面广泛使用，但是不断监测基于光学卫星数据可能受到大气效应的干扰，如云层。然而，Synthetic Aperture Radar（SAR）数据可以提供系统性的森林监测，并且可以在完整的时间序列中提供完整的数据，因为信号可以通过云层和日夜耦合。这个工作的目标是使用SAR数据来解决光学数据中的问题，并作为估算光学VI的替代方案。使用多个时间的Sentinel-1 SAR和辅助数据，时间序列中的四个VI（LAI、FAPAR、EVI和NDVI）的估算被实现。这被启动了一个在Google Earth Engine（GEE）上的配对多时间多模式 dataset（MMT-GEE），包括时间和空间对齐的Sentinel-1、Sentinel-2、数字高程模型（DEM）、天气和土地数据（MMT-GEE）。使用来自DEM和天气数据生成的辅助特征提高了结果。使用自动机器学习（AutoML）方法auto-sklearn，Random Forest Regression的性能被超越，而1小时优化长度已经足够以达到足够的结果，R2值在69-84%之间，低错率（0.05-0.32的MAE，具体取决于VI）。选择的 caso studies 表明，在时间序列分析和空间比较中，选择了原始 SAR-based VI 的准确性是非常高的。总之，使用估算的 SAR-based VI 可以获得更高的时间分辨率（最多 240 次/年）和更高的空间分辨率（20 m），并且可以快速响应森林的快速变化。这是现有的光学卫星数据和全球 VI 产品中的一大优势。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Musical-Object-Discovery-from-Audio"><a href="#Unsupervised-Musical-Object-Discovery-from-Audio" class="headerlink" title="Unsupervised Musical Object Discovery from Audio"></a>Unsupervised Musical Object Discovery from Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07534">http://arxiv.org/abs/2311.07534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arahosu/musicslots">https://github.com/arahosu/musicslots</a></li>
<li>paper_authors: Joonsu Gha, Vincent Herrmann, Benjamin Grewe, Jürgen Schmidhuber, Anand Gopalakrishnan</li>
<li>for: 这篇论文是为了解决音乐频谱中对象的分解问题而写的。</li>
<li>methods: 这篇论文使用了 modifying SlotAttention 模型来实现不supervised music decomposition。</li>
<li>results: 研究得出了好的性能在不监督的音符发现任务和监督的音符属性预测任务上。<details>
<summary>Abstract</summary>
Current object-centric learning models such as the popular SlotAttention architecture allow for unsupervised visual scene decomposition. Our novel MusicSlots method adapts SlotAttention to the audio domain, to achieve unsupervised music decomposition. Since concepts of opacity and occlusion in vision have no auditory analogues, the softmax normalization of alpha masks in the decoders of visual object-centric models is not well-suited for decomposing audio objects. MusicSlots overcomes this problem. We introduce a spectrogram-based multi-object music dataset tailored to evaluate object-centric learning on western tonal music. MusicSlots achieves good performance on unsupervised note discovery and outperforms several established baselines on supervised note property prediction tasks.
</details>
<details>
<summary>摘要</summary>
当前的对象中心学习模型，如受欢迎的槽注意模型，允许无监督视觉场景分解。我们的MusicSlots方法将槽注意模型应用到音频频谱中，以实现无监督音乐分解。由于视觉中的涂抹和遮盖没有相应的听觉对应物，视觉中的softmax正则化α面积的decoder无法适应音频对象的分解。MusicSlots解决了这个问题。我们介绍了基于spectrogram的多对象音乐数据集，用于评估对西方抽象音乐的对象中心学习。MusicSlots在无监督音符发现任务上达到了良好的性能，并在指定音符属性预测任务上超越了一些确立的基准点。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Identification-of-Driving-Maneuver-Patterns-using-a-Robust-Hidden-Semi-Markov-Models"><a href="#Automatic-Identification-of-Driving-Maneuver-Patterns-using-a-Robust-Hidden-Semi-Markov-Models" class="headerlink" title="Automatic Identification of Driving Maneuver Patterns using a Robust Hidden Semi-Markov Models"></a>Automatic Identification of Driving Maneuver Patterns using a Robust Hidden Semi-Markov Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07527">http://arxiv.org/abs/2311.07527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Aguirre, Wenbo Sun, Jionghua, Jin, Yang Chen</li>
<li>for: 模型自动化驾驶动作模式，通常用于交通研究领域如减速驾驶、路面安全和智能汽车。</li>
<li>methods: 使用 Hierarchical Dirichlet Process Hidden Semi-Markov Model (HDP-HSMM) 模型来自动归类天然的顺序动力数据，并且可以估计数据分割、状态持续时间和转移概率。</li>
<li>results: 提出了一种新的可靠 HDP-HSMM (rHDP-HSMM) 方法，可以减少重复的状态数量，提高模型估计的一致性。采用 simulate 试验和实际驾驶数据示例，证明提议的 rHDP-HSMM 能够更好地识别和推断驾驶动作模式。<details>
<summary>Abstract</summary>
There is an increase in interest to model driving maneuver patterns via the automatic unsupervised clustering of naturalistic sequential kinematic driving data. The patterns learned are often used in transportation research areas such as eco-driving, road safety, and intelligent vehicles. One such model capable of modeling these patterns is the Hierarchical Dirichlet Process Hidden Semi-Markov Model (HDP-HSMM), as it is often used to estimate data segmentation, state duration, and transition probabilities. While this model is a powerful tool for automatically clustering observed sequential data, the existing HDP-HSMM estimation suffers from an inherent tendency to overestimate the number of states. This can result in poor estimation, which can potentially impact impact transportation research through incorrect inference of driving patterns. In this paper, a new robust HDP-HSMM (rHDP-HSMM) method is proposed to reduce the number of redundant states and improve the consistency of the model's estimation. Both a simulation study and a case study using naturalistic driving data are presented to demonstrate the effectiveness of the proposed rHDP-HSMM in identifying and inference of driving maneuver patterns.
</details>
<details>
<summary>摘要</summary>
“there is an increasing interest in using automatic unsupervised clustering of naturalistic sequential kinematic driving data to model driving maneuver patterns. these patterns are often used in transportation research areas such as eco-driving, road safety, and intelligent vehicles. one such model capable of modeling these patterns is the hierarchical dirichlet process hidden semi-markov model (HDP-HSMM), as it is often used to estimate data segmentation, state duration, and transition probabilities. however, the existing HDP-HSMM estimation suffers from an inherent tendency to overestimate the number of states, which can result in poor estimation and potentially impact transportation research through incorrect inference of driving patterns. in this paper, a new robust HDP-HSMM (rHDP-HSMM) method is proposed to reduce the number of redundant states and improve the consistency of the model's estimation. both a simulation study and a case study using naturalistic driving data are presented to demonstrate the effectiveness of the proposed rHDP-HSMM in identifying and inference of driving maneuver patterns.”Here's the text with the Chinese characters:“有增长的兴趣在使用自动无监督数据分 clustering来模型驾驶动作模式。这些模式通常用于交通研究领域，如可持续驾驶、路面安全和智能车辆。一个可以模型这些模式的模型是几何 Dirichlet 过程隐藏Markov 模型 (HDP-HSMM)，它通常用于估计数据分 segmentation、状态持续时间和转换 probabilities。但是现有的 HDP-HSMM 估计受到了自然的倾向，即过度估计状态的数量，这可能会导致估计不单纯、不精确，并可能对交通研究造成错误的推论。在本文中，一个新的可靠 HDP-HSMM (rHDP-HSMM) 方法被提出，以减少状态的重复性并改善模型的估计稳定性。在一个实验研究和一个使用自然驾驶数据的实例研究中，显示了提案的 rHDP-HSMM 能够有效地识别和推断驾驶动作模式。”
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-For-Beamline-Steering"><a href="#Machine-Learning-For-Beamline-Steering" class="headerlink" title="Machine Learning For Beamline Steering"></a>Machine Learning For Beamline Steering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07519">http://arxiv.org/abs/2311.07519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac Kante</li>
<li>for: 这篇论文是为了解决加速器中的电子束轴向准确性问题，以提高光源的科学吞吐量。</li>
<li>methods: 该论文使用深度学习模型来帮助准确调整加速器中的磁agnets，从而降低人工操作时间和努力。</li>
<li>results: 该论文通过对储存数据和 simulate 数据进行训练，并与人工操作员进行比较，发现深度学习模型可以帮助提高加速器中的准确性和科学吞吐量。<details>
<summary>Abstract</summary>
Beam steering is the process involving the calibration of the angle and position at which a particle accelerator's electron beam is incident upon the x-ray target with respect to the rotation axis of the collimator. Beam Steering is an essential task for light sources. In the case under study, the LINAC To Undulator (LTU) section of the beamline is difficult to aim. Each use of the accelerator requires re-calibration of the magnets in this section. This involves a substantial amount of time and effort from human operators, while reducing scientific throughput of the light source. We investigate the use of deep neural networks to assist in this task. The deep learning models are trained on archival data and then validated on simulation data. The performance of the deep learning model is contrasted against that of trained human operators.
</details>
<details>
<summary>摘要</summary>
电子束扫描是指在加速器中电子束与精密测量的射线目标之间的角度和位置准确调整，这个过程对光源来说非常重要。在这个案例中，加速器的LINAC到Undulator（LTU）部分很难调整。每次使用加速器都需要重新调整磁铁，这需要人工操作者投入大量时间和努力，同时减少了光源的科学生产率。我们研究使用深度学习模型来帮助进行这个任务。我们在archiv数据上训练了深度学习模型，然后在模拟数据上验证了其性能，并与人工操作员进行了比较。
</details></li>
</ul>
<hr>
<h2 id="FEMDA-a-unified-framework-for-discriminant-analysis"><a href="#FEMDA-a-unified-framework-for-discriminant-analysis" class="headerlink" title="FEMDA: a unified framework for discriminant analysis"></a>FEMDA: a unified framework for discriminant analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07518">http://arxiv.org/abs/2311.07518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Houdouin, Matthieu Jonckheere, Frederic Pascal</li>
<li>For: The paper aims to address the limitations of classical methods such as linear and quadratic discriminant analysis when dealing with non-Gaussian distributions or contaminated datasets.* Methods: The paper presents a novel approach that uses an arbitrary Elliptically Symmetrical (ES) distribution per cluster with its own arbitrary scale parameter, allowing for potentially diverse and independent samples that may not follow identical distributions.* Results: The paper demonstrates that the new approach is simple, efficient, and robust compared to state-of-the-art methods, and that maximum-likelihood parameter estimation and classification can be easily derived.<details>
<summary>Abstract</summary>
Although linear and quadratic discriminant analysis are widely recognized classical methods, they can encounter significant challenges when dealing with non-Gaussian distributions or contaminated datasets. This is primarily due to their reliance on the Gaussian assumption, which lacks robustness. We first explain and review the classical methods to address this limitation and then present a novel approach that overcomes these issues. In this new approach, the model considered is an arbitrary Elliptically Symmetrical (ES) distribution per cluster with its own arbitrary scale parameter. This flexible model allows for potentially diverse and independent samples that may not follow identical distributions. By deriving a new decision rule, we demonstrate that maximum-likelihood parameter estimation and classification are simple, efficient, and robust compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管线性和 quadratic discriminant analysis 是广泛认可的古典方法，但它们在面临非泊松分布或杂凑数据集时可能遇到 significiant 挑战。这主要是因为它们假设 Gaussian，这种假设缺乏稳定性。我们首先介绍和评论古典方法，然后提出一种新的方法，该方法可以在不同和独立的样本集中实现。在这种新方法中，每个分支 Considered 是一个自由的 Elliptically Symmetrical (ES) 分布，具有自己的自由拟合参数。这种灵活的模型允许样本可能不是完全相同的分布。我们 derivation 了一个新的决策规则，并证明了 maximum-likelihood 参数估计和分类是简单、高效、Robust 的 compared 于现有方法。
</details></li>
</ul>
<hr>
<h2 id="A-Hypothesis-on-Good-Practices-for-AI-based-Systems-for-Financial-Time-Series-Forecasting-Towards-Domain-Driven-XAI-Methods"><a href="#A-Hypothesis-on-Good-Practices-for-AI-based-Systems-for-Financial-Time-Series-Forecasting-Towards-Domain-Driven-XAI-Methods" class="headerlink" title="A Hypothesis on Good Practices for AI-based Systems for Financial Time Series Forecasting: Towards Domain-Driven XAI Methods"></a>A Hypothesis on Good Practices for AI-based Systems for Financial Time Series Forecasting: Towards Domain-Driven XAI Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07513">http://arxiv.org/abs/2311.07513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Branka Hadji Misheva, Joerg Osterrieder</li>
<li>for: 这篇论文主要是为了探讨在金融预测和预测任务中如何使用可解释的人工智能（XAI）方法，以提高客户体验、民主化金融服务、改善消费者保护和提高风险管理。</li>
<li>methods: 论文使用了经典的XAI方法，如LIME和SHAP，以及其他相关的技术来提供模型的解释。</li>
<li>results: 论文认为，在金融业中使用XAI方法可以更好地理解和满足用户的需求，但是现有的XAI方法也存在一些局限性，如计算复杂度、模型偏见、数据采样的敏感性和特性数据处理的挑战。<details>
<summary>Abstract</summary>
Machine learning and deep learning have become increasingly prevalent in financial prediction and forecasting tasks, offering advantages such as enhanced customer experience, democratising financial services, improving consumer protection, and enhancing risk management. However, these complex models often lack transparency and interpretability, making them challenging to use in sensitive domains like finance. This has led to the rise of eXplainable Artificial Intelligence (XAI) methods aimed at creating models that are easily understood by humans. Classical XAI methods, such as LIME and SHAP, have been developed to provide explanations for complex models. While these methods have made significant contributions, they also have limitations, including computational complexity, inherent model bias, sensitivity to data sampling, and challenges in dealing with feature dependence. In this context, this paper explores good practices for deploying explainability in AI-based systems for finance, emphasising the importance of data quality, audience-specific methods, consideration of data properties, and the stability of explanations. These practices aim to address the unique challenges and requirements of the financial industry and guide the development of effective XAI tools.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Machine-learning-for-uncertainty-estimation-in-fusing-precipitation-observations-from-satellites-and-ground-based-gauges"><a href="#Machine-learning-for-uncertainty-estimation-in-fusing-precipitation-observations-from-satellites-and-ground-based-gauges" class="headerlink" title="Machine learning for uncertainty estimation in fusing precipitation observations from satellites and ground-based gauges"></a>Machine learning for uncertainty estimation in fusing precipitation observations from satellites and ground-based gauges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07511">http://arxiv.org/abs/2311.07511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgia Papacharalampous, Hristos Tyralis, Nikolaos Doulamis, Anastasios Doulamis<br>for: 这项研究的目的是提供一种可靠的降水数据集，同时具有高的空间密度，通过将卫星数据和测站数据合并。methods: 这项研究使用了6种适合预测 uncertainty 量化的学习器，分别是quantile regression（QR）、quantile regression forest（QRF）、generalized random forests（GRF）、gradient boosting machines（GBM）、light gradient boosting machines（LightGBM）和quantile regression neural networks（QRNN）。results: 结果显示，LightGBM、QRF和GRF是最佳的学习器，其预测量iles的能力最高，而QRNN和QR最差。此外，这些学习器之间的主要区别在于feature importance的实现方式。<details>
<summary>Abstract</summary>
To form precipitation datasets that are accurate and, at the same time, have high spatial densities, data from satellites and gauges are often merged in the literature. However, uncertainty estimates for the data acquired in this manner are scarcely provided, although the importance of uncertainty quantification in predictive modelling is widely recognized. Furthermore, the benefits that machine learning can bring to the task of providing such estimates have not been broadly realized and properly explored through benchmark experiments. The present study aims at filling in this specific gap by conducting the first benchmark tests on the topic. On a large dataset that comprises 15-year-long monthly data spanning across the contiguous United States, we extensively compared six learners that are, by their construction, appropriate for predictive uncertainty quantification. These are the quantile regression (QR), quantile regression forests (QRF), generalized random forests (GRF), gradient boosting machines (GBM), light gradient boosting machines (LightGBM) and quantile regression neural networks (QRNN). The comparison referred to the competence of the learners in issuing predictive quantiles at nine levels that facilitate a good approximation of the entire predictive probability distribution, and was primarily based on the quantile and continuous ranked probability skill scores. Three types of predictor variables (i.e., satellite precipitation variables, distances between a point of interest and satellite grid points, and elevation at a point of interest) were used in the comparison and were additionally compared with each other. This additional comparison was based on the explainable machine learning concept of feature importance. The results suggest that the order from the best to the worst of the learners for the task investigated is the following: LightGBM, QRF, GRF, GBM, QRNN and QR...
</details>
<details>
<summary>摘要</summary>
通常，通过卫星和测点数据的合并来形成减霾数据集，但是这些数据的不确定性估计 rarely 提供。 although the importance of uncertainty quantification in predictive modeling is widely recognized. 在这种情况下，本研究的目的是填充这个具体的空白，通过对15年的月度数据， covering the contiguous United States，进行了首次 benchmark 测试。我们对6种适用于预测uncertainty quantification的学习器进行了广泛的比较。这些学习器包括：量词回归（QR）、量词回归森林（QRF）、普通随机森林（GRF）、梯度提升机器（GBM）、轻量级梯度提升机器（LightGBM）和量词回归神经网络（QRNN）。 comparison 基于 nine 级预测量误差，以便 aproximate 预测概率分布的整个范围。此外，我们还对不同的预测变量（卫星降水变量、测点与卫星网格点之间的距离、测点 elevation）进行了比较，基于解释机器学习概念的特征重要性。 results 表明，这些学习器的排名如下：LightGBM、QRF、GRF、GBM、QRNN 和 QR。
</details></li>
</ul>
<hr>
<h2 id="Explicit-Foundation-Model-Optimization-with-Self-Attentive-Feed-Forward-Neural-Units"><a href="#Explicit-Foundation-Model-Optimization-with-Self-Attentive-Feed-Forward-Neural-Units" class="headerlink" title="Explicit Foundation Model Optimization with Self-Attentive Feed-Forward Neural Units"></a>Explicit Foundation Model Optimization with Self-Attentive Feed-Forward Neural Units</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07510">http://arxiv.org/abs/2311.07510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jake Ryland Williams, Haoran Zhao</li>
<li>for: 这个论文的目的是提出一种高效的神经网络优化方法，以降低神经网络的计算成本，特别是在大规模使用时。</li>
<li>methods: 这个论文使用迭代近似法和反射层来优化神经网络，并提出了一种基于feed-forward神经网络的通用结果。</li>
<li>results: 测试结果表明，使用Explicit Solutions可以取得更好的优化结果，而且在使用反射层后，Explicit Solutions可以从更小的数据量中获得更好的优化结果。此外，这个论文还进行了一系列的ablation experiment，发现一些不同的体系结构可以生成高性能的模型，并且这些模型可以在更少的数据量上训练。<details>
<summary>Abstract</summary>
Iterative approximation methods using backpropagation enable the optimization of neural networks, but they remain computationally expensive, especially when used at scale. This paper presents an efficient alternative for optimizing neural networks that reduces the costs of scaling neural networks and provides high-efficiency optimizations for low-resource applications. We will discuss a general result about feed-forward neural networks and then extend this solution to compositional (mult-layer) networks, which are applied to a simplified transformer block containing feed-forward and self-attention layers. These models are used to train highly-specified and complex multi-layer neural architectures that we refer to as self-attentive feed-forward unit (SAFFU) layers, which we use to develop a transformer that appears to generalize well over small, cognitively-feasible, volumes of data. Testing demonstrates explicit solutions outperform models optimized by backpropagation alone. Moreover, further application of backpropagation after explicit solutions leads to better optima from smaller scales of data, training effective models from much less data is enabled by explicit solution warm starts. We then carry out ablation experiments training a roadmap of about 250 transformer models over 1-million tokens to determine ideal settings. We find that multiple different architectural variants produce highly-performant models, and discover from this ablation that some of the best are not the most parameterized. This appears to indicate well-generalized models could be reached using less data by using explicit solutions, and that architectural exploration using explicit solutions pays dividends in guiding the search for efficient variants with fewer parameters, and which could be incorporated into low-resource hardware where AI might be embodied.
</details>
<details>
<summary>摘要</summary>
iterative approximation方法使用反射传播可以优化神经网络，但它们仍然具有计算成本，特别是在大规模使用时。这篇文章提出了一种高效的神经网络优化方法，可以降低神经网络缩放时的计算成本，并为低资源应用提供高效优化。我们将讨论一个通用的Feed-Forward神经网络的结果，然后扩展到多层神经网络，并应用于简化后Transformer块中的Feed-Forward和自注意层。这些模型用于训练复杂多层神经架构，我们称之为自注意Feed-Forward单元（SAFFU）层。我们使用这些层来开发一个Transformer模型，该模型在小量数据上Generalization良好。测试表明显式解决方案可以超越backpropagation alone的优化。此外，通过backpropagation和显式解决方案的组合，可以从小规模数据中获得更好的优化。这些方法可以训练效果很好的模型，从更少的数据中训练模型。我们然后进行了ablation experiment，训练约250个Transformer模型，并测试其在100万个字节上的性能。我们发现多种不同的建筑学variant可以生成高性能模型，并发现这些variant中的一些最好的模型并不是最大化参数的。这表明可以使用显式解决方案来找到更好的模型，并且使用这些方法可以在低资源硬件上搬运AI。
</details></li>
</ul>
<hr>
<h2 id="STEM-Rebalance-A-Novel-Approach-for-Tackling-Imbalanced-Datasets-using-SMOTE-Edited-Nearest-Neighbour-and-Mixup"><a href="#STEM-Rebalance-A-Novel-Approach-for-Tackling-Imbalanced-Datasets-using-SMOTE-Edited-Nearest-Neighbour-and-Mixup" class="headerlink" title="STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using SMOTE, Edited Nearest Neighbour, and Mixup"></a>STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using SMOTE, Edited Nearest Neighbour, and Mixup</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07504">http://arxiv.org/abs/2311.07504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yumnah Hasan, Fatemeh Amerehi, Patrick Healy, Conor Ryan</li>
<li>for: 该论文targets imbalanced medical imaging datasets, particularly breast cancer datasets, and aims to improve the performance of machine learning classifiers on these datasets.</li>
<li>methods: 该论文提出了一种新的 Vicinal Distribution Augmentation（Mixup）方法，combines SMOTE-ENN和Mixup在实例层次进行结合，以利用整个少数类分布，thereby mitigating both between-class and within-class imbalances.</li>
<li>results: 该论文在Digital Database for Screening Mammography和Wisconsin Breast Cancer（Diagnostics） datasets中 achieved AUC values of 0.96和0.99，respectively, demonstrating the effectiveness of STEM in improving the performance of machine learning classifiers on imbalanced medical imaging datasets.<details>
<summary>Abstract</summary>
Imbalanced datasets in medical imaging are characterized by skewed class proportions and scarcity of abnormal cases. When trained using such data, models tend to assign higher probabilities to normal cases, leading to biased performance. Common oversampling techniques such as SMOTE rely on local information and can introduce marginalization issues. This paper investigates the potential of using Mixup augmentation that combines two training examples along with their corresponding labels to generate new data points as a generic vicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN and Mixup at the instance level. This integration enables us to effectively leverage the entire distribution of minority classes, thereby mitigating both between-class and within-class imbalances. We focus on the breast cancer problem, where imbalanced datasets are prevalent. The results demonstrate the effectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the Digital Database for Screening Mammography and Wisconsin Breast Cancer (Diagnostics) datasets, respectively. Moreover, this method shows promising potential when applied with an ensemble of machine learning (ML) classifiers.
</details>
<details>
<summary>摘要</summary>
医学影像数据集偏度问题常被定义为类别分布不均衡和罕见病例的缺乏。当使用这些数据进行训练时，模型往往偏好正常情况，导致表现偏移。常见的扩大技术，如SMOTE，基于地方信息，可能会导致边缘化问题。本文研究了使用混合增强的潜在利点，通过将两个训练示例和其相应的标签拼接起来生成新的数据点，以实现一个通用的邻近分布。为此，我们提出了STEM，它将SMOTE-ENN和混合拼接在实例层次结合。这种整合使得我们可以有效利用少数类别的整个分布，从而解决 между类和内类别不均衡。我们将精力集中在乳腺癌问题上，这里的数据集很常见偏度。结果表明，STEM具有抗偏衡能力，在数字图像creening Mamмографи和乳腺癌（诊断）数据集上分别 achieve AUC值0.96和0.99。此外，这种方法在 ensemble 机器学习（ML）类ifier上表现了扎实的潜在性。
</details></li>
</ul>
<hr>
<h2 id="Reducing-the-Need-for-Backpropagation-and-Discovering-Better-Optima-With-Explicit-Optimizations-of-Neural-Networks"><a href="#Reducing-the-Need-for-Backpropagation-and-Discovering-Better-Optima-With-Explicit-Optimizations-of-Neural-Networks" class="headerlink" title="Reducing the Need for Backpropagation and Discovering Better Optima With Explicit Optimizations of Neural Networks"></a>Reducing the Need for Backpropagation and Discovering Better Optima With Explicit Optimizations of Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07498">http://arxiv.org/abs/2311.07498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jake Ryland Williams, Haoran Zhao</li>
<li>for: 这篇论文旨在提出一种可以实现对神经网络的优化，并且可以降低训练神经网络的Computational Expensive。</li>
<li>methods: 作者使用了Iterative differential approximation方法，并且通过分析Gradient的 mathematician来derive一个explicit solution дляfeed-forward language model（LM）和MNIST digit classification。</li>
<li>results: 作者发现，这个explicit solution可以实现near-optimality，并且可以降低iterative optimization的computational cost。此外，作者还发现，这个solution可以在多层神经网络中实现更好的optima，并且可以提高模型的解释性。<details>
<summary>Abstract</summary>
Iterative differential approximation methods that rely upon backpropagation have enabled the optimization of neural networks; however, at present, they remain computationally expensive, especially when training models at scale. In this paper, we propose a computationally efficient alternative for optimizing neural networks that can both reduce the costs of scaling neural networks and provide high-efficiency optimizations for low-resource applications. We derive an explicit solution to a simple feed-forward language model (LM) by mathematically analyzing its gradients. This solution generalizes from single-layer LMs to the class of all single-layer feed-forward softmax-activated neural models trained on positive-valued features, as is demonstrated by our extension of this solution application to MNIST digit classification. For both LM and digit classifiers, we find computationally that explicit solutions perform near-optimality in experiments showing that 1) iterative optimization only marginally improves the explicit solution parameters and 2) randomly initialized parameters iteratively optimize towards the explicit solution. We also preliminarily apply the explicit solution locally by layer in multi-layer networks and discuss how the solution's computational savings increase with model complexity -- for both single- and mult-layer applications of the explicit solution, we emphasize that the optima achieved cannot be reached by backpropagation alone, i.e., better optima appear discoverable only after explicit solutions are applied. Finally, we discuss the solution's computational savings alongside its impact on model interpretability and suggest future directions for the derivation of explicit solutions to complex- and multi-layer architectures.
</details>
<details>
<summary>摘要</summary>
iterative diferencial approximation methods that rely upon backpropagation have enabled the optimization of neural networks; however, at present, they remain computationally expensive, especially when training models at scale. In this paper, we propose a computationally efficient alternative for optimizing neural networks that can both reduce the costs of scaling neural networks and provide high-efficiency optimizations for low-resource applications. We derive an explicit solution to a simple feed-forward language model (LM) by mathematically analyzing its gradients. This solution generalizes from single-layer LMs to the class of all single-layer feed-forward softmax-activated neural models trained on positive-valued features, as is demonstrated by our extension of this solution application to MNIST digit classification. For both LM and digit classifiers, we find computationally that explicit solutions perform near-optimality in experiments showing that 1) iterative optimization only marginally improves the explicit solution parameters and 2) randomly initialized parameters iteratively optimize towards the explicit solution. We also preliminarily apply the explicit solution locally by layer in multi-layer networks and discuss how the solution's computational savings increase with model complexity -- for both single- and mult-layer applications of the explicit solution, we emphasize that the optima achieved cannot be reached by backpropagation alone, i.e., better optima appear discoverable only after explicit solutions are applied. Finally, we discuss the solution's computational savings alongside its impact on model interpretability and suggest future directions for the derivation of explicit solutions to complex- and multi-layer architectures.
</details></li>
</ul>
<hr>
<h2 id="A-Federated-Data-Fusion-Based-Prognostic-Model-for-Applications-with-Multi-Stream-Incomplete-Signals"><a href="#A-Federated-Data-Fusion-Based-Prognostic-Model-for-Applications-with-Multi-Stream-Incomplete-Signals" class="headerlink" title="A Federated Data Fusion-Based Prognostic Model for Applications with Multi-Stream Incomplete Signals"></a>A Federated Data Fusion-Based Prognostic Model for Applications with Multi-Stream Incomplete Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07474">http://arxiv.org/abs/2311.07474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Madi Arabi, Xiaolei Fang</li>
<li>for: 这篇论文旨在提出一种联合多个用户的联邦预测模型，以便在多元数据和尚未完整的情况下预测机器的故障时间。</li>
<li>methods: 本论文使用多元功能原始对角测度分析融合多条流损坏讯号，然后使用融合的特征建立(对数)-位置-标准 regresion 模型进行故障预测。</li>
<li>results: 数据分析显示，提案的模型性能与非联邦预测模型相同，并且比各用户自己建立的模型更好。<details>
<summary>Abstract</summary>
Most prognostic methods require a decent amount of data for model training. In reality, however, the amount of historical data owned by a single organization might be small or not large enough to train a reliable prognostic model. To address this challenge, this article proposes a federated prognostic model that allows multiple users to jointly construct a failure time prediction model using their multi-stream, high-dimensional, and incomplete data while keeping each user's data local and confidential. The prognostic model first employs multivariate functional principal component analysis to fuse the multi-stream degradation signals. Then, the fused features coupled with the times-to-failure are utilized to build a (log)-location-scale regression model for failure prediction. To estimate parameters using distributed datasets and keep the data privacy of all participants, we propose a new federated algorithm for feature extraction. Numerical studies indicate that the performance of the proposed model is the same as that of classic non-federated prognostic models and is better than that of the models constructed by each user itself.
</details>
<details>
<summary>摘要</summary>
大多数预测方法需要一定量的数据进行模型训练。然而，在现实中，一个组织可能拥有的历史数据量可能不够或者太少以建立一个可靠的预测模型。为解决这个挑战，这篇文章提出了一种联合预测模型，允许多个用户共同构建一个失败时间预测模型，使用他们的多元流、高维度和不完整的数据，而不需要将数据分享或泄露。该预测模型首先使用多元函数主成分分析将多流衰减信号融合。然后，融合后的特征coupled with the times-to-failure被用建立一个（对数）-（尺度）-（拟合）回归模型进行失败预测。为了在分布式数据集上计算参数并保持所有参与者的数据隐私，我们提出了一种新的联合算法 для特征提取。 numerically studies show that the performance of the proposed model is the same as that of classic non-federated prognostic models and is better than that of the models constructed by each user itself.
</details></li>
</ul>
<hr>
<h2 id="On-Self-Supervised-Dynamic-Incremental-Regularised-Adaptation"><a href="#On-Self-Supervised-Dynamic-Incremental-Regularised-Adaptation" class="headerlink" title="On Self-Supervised Dynamic Incremental Regularised Adaptation"></a>On Self-Supervised Dynamic Incremental Regularised Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07461">http://arxiv.org/abs/2311.07461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abanoub Ghobrial, Kerstin Eder</li>
<li>for: 本研究提出了一种基于几个样本和轻量级融合的动态领域适应方法，即DIRA，以实现领域适应最佳结果。</li>
<li>methods:  DIRA方法基于一些标签，但这些标签不是必需的，因此它可以视为一种自动适应方法。</li>
<li>results: DIRA方法在前一些研究中已经达到了领域适应最佳结果的水平，但它仍然需要提供标签来进行适应。在本研究中，我们提出了一种修改DIRA方法，使其成为自动适应方法，并将在未来的实验中提供证明。<details>
<summary>Abstract</summary>
In this paper, we overview a recent method for dynamic domain adaptation named DIRA, which relies on a few samples in addition to a regularisation approach named elastic weight consolidation to achieve state-of-the-art (SOTA) domain adaptation results. DIRA has been previously shown to perform competitively with SOTA unsupervised adaption techniques. However, a limitation of DIRA is that it relies on labels to be provided for the few samples used in adaption. This makes it a supervised technique. In this paper, we discuss a proposed alteration to the DIRA method to make it self-supervised i.e. remove the need for providing labels. Experiments on our proposed alteration will be provided in future work.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种最近的动态领域适应方法 named DIRA，该方法基于一些样本和一种正则化方法 named elastic weight consolidation来实现领域适应结果。 DIRA 已经在之前的研究中展示了与顶尖无监督适应技术相当的性能。然而，DIRA 的一个局限性是它需要提供适应样本的标签。这使得它成为一种有监督的技术。在这篇论文中，我们讨论了对 DIRA 方法进行修改，以使其成为无监督的，即移除标签提供的需求。未来的工作中将提供相关的实验。
</details></li>
</ul>
<hr>
<h2 id="Causal-Discovery-under-Latent-Class-Confounding"><a href="#Causal-Discovery-under-Latent-Class-Confounding" class="headerlink" title="Causal Discovery under Latent Class Confounding"></a>Causal Discovery under Latent Class Confounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07454">http://arxiv.org/abs/2311.07454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bijan Mazaheri, Spencer Gordon, Yuval Rabani, Leonard Schulman</li>
<li>for: 这种研究是为了解决多源数据中的 causal discovery 问题。</li>
<li>methods: 这种方法使用 directaded acyclic graphs 模型系统的 causal 结构，并使用 conditional independence properties 来学习这种结构。</li>
<li>results: 研究表明，如果global confounding的 cardinality 是有限的（即数据来源有限），则可以成功地解决 causal discovery 问题。 however, the feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure。<details>
<summary>Abstract</summary>
Directed acyclic graphs are used to model the causal structure of a system. ``Causal discovery'' describes the problem of learning this structure from data. When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms. For this reason, existing causal discovery algorithms are not suitable for the multiple-source setting. We demonstrate that, if the confounding is of bounded cardinality (i.e. the data comes from a limited number of sources), causal discovery can still be achieved. The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:导向无环Graphs are used to model the causal structure of a system. "Causal discovery" describes the problem of learning this structure from data. When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms. For this reason, existing causal discovery algorithms are not suitable for the multiple-source setting. We demonstrate that, if the confounding is of bounded cardinality (i.e. the data comes from a limited number of sources), causal discovery can still be achieved. The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the observed variables, and the sparsity of the causal structure.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Taiwan, and other countries.
</details></li>
</ul>
<hr>
<h2 id="Explainable-Boosting-Machines-with-Sparsity-–-Maintaining-Explainability-in-High-Dimensional-Settings"><a href="#Explainable-Boosting-Machines-with-Sparsity-–-Maintaining-Explainability-in-High-Dimensional-Settings" class="headerlink" title="Explainable Boosting Machines with Sparsity – Maintaining Explainability in High-Dimensional Settings"></a>Explainable Boosting Machines with Sparsity – Maintaining Explainability in High-Dimensional Settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07452">http://arxiv.org/abs/2311.07452</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/interpretml/interpret">https://github.com/interpretml/interpret</a></li>
<li>paper_authors: Brandon M. Greenwell, Annika Dahlmann, Saurabh Dhoble</li>
<li>For: The paper aims to improve the transparency and speed of Explainable Boosting Machines (EBMs) in high-dimensional settings with many predictor variables.* Methods: The paper proposes using the Least Absolute Shrinkage and Selection Operator (LASSO) to introduce sparsity and remove less relevant terms in the EBM, allowing the model to maintain transparency and relatively fast scoring times.* Results: The paper shows that post-processing a fitted EBM with many terms using LASSO can reduce the model’s complexity and drastically improve scoring time, while maintaining competitive accuracy.Here’s the Chinese translation of the three points:* For: 这篇论文目标是在高维设定下提高Explainable Boosting Machines（EBM）的透明度和速度。* Methods: 论文提议使用Least Absolute Shrinkage and Selection Operator（LASSO）引入简洁性，从 fitted EBM 中除去不那么重要的项目，使模型保持透明度和相对快的分分析时间。* Results: 论文显示，对 fitted EBM 使用 LASSO 后处理可以减少模型的复杂性，提高分分析时间，保持竞争性的准确性。<details>
<summary>Abstract</summary>
Compared to "black-box" models, like random forests and deep neural networks, explainable boosting machines (EBMs) are considered "glass-box" models that can be competitively accurate while also maintaining a higher degree of transparency and explainability. However, EBMs become readily less transparent and harder to interpret in high-dimensional settings with many predictor variables; they also become more difficult to use in production due to increases in scoring time. We propose a simple solution based on the least absolute shrinkage and selection operator (LASSO) that can help introduce sparsity by reweighting the individual model terms and removing the less relevant ones, thereby allowing these models to maintain their transparency and relatively fast scoring times in higher-dimensional settings. In short, post-processing a fitted EBM with many (i.e., possibly hundreds or thousands) of terms using the LASSO can help reduce the model's complexity and drastically improve scoring time. We illustrate the basic idea using two real-world examples with code.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:与“黑盒”模型（如随机森林和深度神经网络）相比，可解释扩展机器（EBM）被视为“玻璃盒”模型，可同时保持高度的透明度和解释性。然而，EBM在高维设置中的多个预测变量时会变得更加难以理解和维护，同时也会导致在生产环境中使用变得更加困难。我们提出了一个简单的解决方案，基于最小绝对减少和选择算子（LASSO），可以在高维设置中引入稀疏性，并通过重新权重个模型项和 removes  menos相关的项来保持模型的透明度和相对快的分分时间。简而言之，对已经预测好的 EBM 进行 LASSO 处理可以帮助减少模型的复杂性，并快速提高分分时间。我们使用两个实际例子的代码来说明基本思路。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Neural-Collapse-and-the-Neural-Collapse-of-Robustness"><a href="#On-the-Robustness-of-Neural-Collapse-and-the-Neural-Collapse-of-Robustness" class="headerlink" title="On the Robustness of Neural Collapse and the Neural Collapse of Robustness"></a>On the Robustness of Neural Collapse and the Neural Collapse of Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07444">http://arxiv.org/abs/2311.07444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingtong Su, Ya Shi Zhang, Nikolaos Tsilivis, Julia Kempe</li>
<li>for: 本文研究了神经网络中的神经崩溃现象，即训练结束时神经网络的特征向量和分类权重归一化到一个简单的 геометрической设计（一个简单体）。</li>
<li>methods: 本文使用了实验和理论的方法来研究神经崩溃的稳定性特性。</li>
<li>results: 研究发现，神经崩溃结构在小型攻击下消失，并且输入数据中的扰动Example会“跳跃”到简单体的边点上。此外，研究发现对抗攻击的网络优化后，神经崩溃仍然是普遍存在的现象，clean和扰动表示形成了垂直的简单体，并且导致了一个简单 nearest-neighbor 分类器。<details>
<summary>Abstract</summary>
Neural Collapse refers to the curious phenomenon in the end of training of a neural network, where feature vectors and classification weights converge to a very simple geometrical arrangement (a simplex). While it has been observed empirically in various cases and has been theoretically motivated, its connection with crucial properties of neural networks, like their generalization and robustness, remains unclear. In this work, we study the stability properties of these simplices. We find that the simplex structure disappears under small adversarial attacks, and that perturbed examples "leap" between simplex vertices. We further analyze the geometry of networks that are optimized to be robust against adversarial perturbations of the input, and find that Neural Collapse is a pervasive phenomenon in these cases as well, with clean and perturbed representations forming aligned simplices, and giving rise to a robust simple nearest-neighbor classifier. By studying the propagation of the amount of collapse inside the network, we identify novel properties of both robust and non-robust machine learning models, and show that earlier, unlike later layers maintain reliable simplices on perturbed data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Boolean-Variation-and-Boolean-Logic-BackPropagation"><a href="#Boolean-Variation-and-Boolean-Logic-BackPropagation" class="headerlink" title="Boolean Variation and Boolean Logic BackPropagation"></a>Boolean Variation and Boolean Logic BackPropagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07427">http://arxiv.org/abs/2311.07427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Van Minh Nguyen</li>
<li>for: 这篇论文是关于布尔集的概念引入和布尔逻辑推导深度模型的建立的。</li>
<li>methods: 该论文使用布尔逻辑推导深度模型， weights和活动都是布尔数字，通过布尔逻辑进行运算。具体来说，布尔深度模型可以直接在布尔领域内训练，不需要隐藏权重。没有梯度，只有逻辑是合成和归并。</li>
<li>results: 该论文的实验结果表明，布尔深度模型可以达到与实数深度模型相同的性能水平，但是具有更好的可解释性和安全性。<details>
<summary>Abstract</summary>
The notion of variation is introduced for the Boolean set and based on which Boolean logic backpropagation principle is developed. Using this concept, deep models can be built with weights and activations being Boolean numbers and operated with Boolean logic instead of real arithmetic. In particular, Boolean deep models can be trained directly in the Boolean domain without latent weights. No gradient but logic is synthesized and backpropagated through layers.
</details>
<details>
<summary>摘要</summary>
“变化”概念在布尔集中引入，基于这个概念，布尔逻辑反propagation原理得到开发。使用这个概念，深度模型可以使用布尔数字和布尔逻辑进行操作，而不需要实数 arithmetic。特别是，布尔深度模型可以直接在布尔领域内被训练，而不需要秘密 веса。无需梯度，逻辑是通过层次 синтези并反propagated。
</details></li>
</ul>
<hr>
<h2 id="Three-dimensional-granular-flow-simulation-using-graph-neural-network-based-learned-simulator"><a href="#Three-dimensional-granular-flow-simulation-using-graph-neural-network-based-learned-simulator" class="headerlink" title="Three-dimensional granular flow simulation using graph neural network-based learned simulator"></a>Three-dimensional granular flow simulation using graph neural network-based learned simulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07416">http://arxiv.org/abs/2311.07416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongjin Choi, Krishna Kumar</li>
<li>for:  This paper aims to develop a novel deep learning technique, graph neural network (GNN), to simulate granular flows and address the issues of computational intractability and empirical nature of traditional methods.</li>
<li>methods:  The paper employs GNN to develop a GNN-based simulator (GNS) for granular flows, which learns the local interaction law of granular flows from a limited set of trajectories.</li>
<li>results:  The paper shows that GNS successfully reproduces the overall behaviors of column collapses with various aspect ratios that were not encountered during training, and outperforms high-fidelity numerical simulators by 300 times in terms of computation speed.<details>
<summary>Abstract</summary>
Reliable evaluations of geotechnical hazards like landslides and debris flow require accurate simulation of granular flow dynamics. Traditional numerical methods can simulate the complex behaviors of such flows that involve solid-like to fluid-like transitions, but they are computationally intractable when simulating large-scale systems. Surrogate models based on statistical or machine learning methods are a viable alternative, but they are typically empirical and rely on a confined set of parameters in evaluating associated risks. Due to their permutation-dependent learning, conventional machine learning models require an unreasonably large amount of training data for building generalizable surrogate models. We employ a graph neural network (GNN), a novel deep learning technique, to develop a GNN-based simulator (GNS) for granular flows to address these issues. Graphs represent the state of granular flows and interactions, like the exchange of energy and momentum between grains, and GNN learns the local interaction law. GNS takes the current state of the granular flow and estimates the next state using Euler explicit integration. We train GNS on a limited set of granular flow trajectories and evaluate its performance in a three-dimensional granular column collapse domain. GNS successfully reproduces the overall behaviors of column collapses with various aspect ratios that were not encountered during training. The computation speed of GNS outperforms high-fidelity numerical simulators by 300 times.
</details>
<details>
<summary>摘要</summary>
可靠的地层风险评估需要准确地模拟 granular 流动的动态。传统的数值方法可以模拟 granular 流动中的复杂行为，但它们在大规模系统上 computationally intractable。基于统计或机器学习方法的代理模型是一种可行的 alternativa，但它们通常是empirical的，并且基于一个有限的参数集来评估相关的风险。由于它们的 permutation-dependent learning，传统的机器学习模型需要一个不切实际的大量的训练数据来建立通用的代理模型。我们employs a graph neural network (GNN)，一种新的深度学习技术，来开发一个 GNN-based simulator (GNS) for granular flows。图表示 granular 流动的状态和交互，如粒子之间的能量和动量交换，GNN 学习本地交互法律。GNS 使用当前 granular 流动的状态来估计下一个状态，使用 Euler 显式积分。我们在一个有限的 granular 流动轨迹上训练 GNS，并评估其性能在一个三维 granular 柱塌领域。GNS 成功地复制了不同方向比例的柱塌的总行为，并且在训练期间没有遇到的多样化的柱塌行为。GNS 的计算速度高于高精度数值模拟器，提高了 300 倍。
</details></li>
</ul>
<hr>
<h2 id="Attention-based-Multi-task-Learning-for-Base-Editor-Outcome-Prediction"><a href="#Attention-based-Multi-task-Learning-for-Base-Editor-Outcome-Prediction" class="headerlink" title="Attention-based Multi-task Learning for Base Editor Outcome Prediction"></a>Attention-based Multi-task Learning for Base Editor Outcome Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07636">http://arxiv.org/abs/2311.07636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amina Mollaysa, Ahmed Allam, Michael Krauthammer</li>
<li>for: 提高基因编辑技术的精度和效率，以便更好地治疗人类遗传疾病。</li>
<li>methods: 使用机器学习模型，通过预测各种可能的编辑结果，以提高基因编辑设计的精度和效率。</li>
<li>results: 在多个数据集和基因编辑变体上，模型预测的结果与实验结果呈 corrrelation，证明了模型的有效性和可靠性。<details>
<summary>Abstract</summary>
Human genetic diseases often arise from point mutations, emphasizing the critical need for precise genome editing techniques. Among these, base editing stands out as it allows targeted alterations at the single nucleotide level. However, its clinical application is hindered by low editing efficiency and unintended mutations, necessitating extensive trial-and-error experimentation in the laboratory. To speed up this process, we present an attention-based two-stage machine learning model that learns to predict the likelihood of all possible editing outcomes for a given genomic target sequence. We further propose a multi-task learning schema to jointly learn multiple base editors (i.e. variants) at once. Our model's predictions consistently demonstrated a strong correlation with the actual experimental results on multiple datasets and base editor variants. These results provide further validation for the models' capacity to enhance and accelerate the process of refining base editing designs.
</details>
<details>
<summary>摘要</summary>
人类遗传病多发生于点突变，强调了精准基因编辑技术的核心性。其中，基因编辑技术出现了，它可以在单个核苷酸水平进行targeted修饰。然而，临床应用受到低修饰效率和不意图的突变所阻碍，需要进行详细的实验室试验。为了加速这个过程，我们提出了一种关注机制基于两个阶段机器学习模型，可以预测给定 genomic 目标序列中所有可能的编辑结果的可能性。我们还提议使用多任务学习 schema，可以同时学习多种基因编辑器（即变体）。我们的模型预测结果与实验结果在多个数据集和基因编辑器变体上均具有强相关性。这些结果为我们的模型增强和加速基因编辑设计的能力提供了进一步的验证。
</details></li>
</ul>
<hr>
<h2 id="Transpose-Attack-Stealing-Datasets-with-Bidirectional-Training"><a href="#Transpose-Attack-Stealing-Datasets-with-Bidirectional-Training" class="headerlink" title="Transpose Attack: Stealing Datasets with Bidirectional Training"></a>Transpose Attack: Stealing Datasets with Bidirectional Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07389">http://arxiv.org/abs/2311.07389</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guyamit/transpose-attack-paper-ndss24-">https://github.com/guyamit/transpose-attack-paper-ndss24-</a></li>
<li>paper_authors: Guy Amit, Mosh Levy, Yisroel Mirsky</li>
<li>for: 本研究探讨了深度神经网络在反向方向下的漏洞，以及恶意用户可以通过这个漏洞将模型隐藏在正常模型中。</li>
<li>methods: 本研究使用了深度神经网络的反向传播方法，并示出了如何在这种方法下系统地记忆和回忆特定的样本。</li>
<li>results: 研究发现，现代建模可以通过这种方法在保护学习环境下隐藏敏感数据，并且可以高精度地复制大量样本，这可能会损害数据隐私和生成新模型。此外，研究还提出了一种新的方法来检测恶意模型。<details>
<summary>Abstract</summary>
Deep neural networks are normally executed in the forward direction. However, in this work, we identify a vulnerability that enables models to be trained in both directions and on different tasks. Adversaries can exploit this capability to hide rogue models within seemingly legitimate models. In addition, in this work we show that neural networks can be taught to systematically memorize and retrieve specific samples from datasets. Together, these findings expose a novel method in which adversaries can exfiltrate datasets from protected learning environments under the guise of legitimate models. We focus on the data exfiltration attack and show that modern architectures can be used to secretly exfiltrate tens of thousands of samples with high fidelity, high enough to compromise data privacy and even train new models. Moreover, to mitigate this threat we propose a novel approach for detecting infected models.
</details>
<details>
<summary>摘要</summary>
深度神经网络通常在前向方向下执行。然而，在这项工作中，我们发现了一个漏洞，允许模型在两个方向和不同任务上训练。攻击者可以利用这个能力，隐藏恶意模型在看起来合法的模型中。此外，我们还示出了神经网络可以系统地记忆和重复特定样本。这些发现表明了一种新的攻击方法，可以在受保护的学习环境中隐藏大量数据。我们主要关注数据泄露攻击，并证明现代架构可以使用高准确率泄露数据，足以损害数据隐私和生成新模型。此外，我们还提出了一种新的检测恶意模型的方法，以mitigate这种威胁。
</details></li>
</ul>
<hr>
<h2 id="arfpy-A-python-package-for-density-estimation-and-generative-modeling-with-adversarial-random-forests"><a href="#arfpy-A-python-package-for-density-estimation-and-generative-modeling-with-adversarial-random-forests" class="headerlink" title="arfpy: A python package for density estimation and generative modeling with adversarial random forests"></a>arfpy: A python package for density estimation and generative modeling with adversarial random forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07366">http://arxiv.org/abs/2311.07366</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bips-hb/arfpy">https://github.com/bips-hb/arfpy</a></li>
<li>paper_authors: Kristin Blesch, Marvin N. Wright</li>
<li>for: 该论文提供了一种用于生成类似给定数据的轻量级方法，即 Adversarial Random Forests（ARF）的Python实现，帮助实际者快速地进行数据生成和分布估计。</li>
<li>methods: 该论文使用的方法是Adversarial Random Forests（ARF），它是一种基于树的生成模型，可以快速地生成类似给定数据的新数据。</li>
<li>results: 论文的结果表明，$\textit{arfpy}$ 可以快速地生成高质量的新数据，并且与传统的深度学习模型相比，它具有更低的 Tuning 和计算资源的需求，同时具有易用的Python接口，可以让科学家在各个领域进行数据生成。<details>
<summary>Abstract</summary>
This paper introduces $\textit{arfpy}$, a python implementation of Adversarial Random Forests (ARF) (Watson et al., 2023), which is a lightweight procedure for synthesizing new data that resembles some given data. The software $\textit{arfpy}$ equips practitioners with straightforward functionalities for both density estimation and generative modeling. The method is particularly useful for tabular data and its competitive performance is demonstrated in previous literature. As a major advantage over the mostly deep learning based alternatives, $\textit{arfpy}$ combines the method's reduced requirements in tuning efforts and computational resources with a user-friendly python interface. This supplies audiences across scientific fields with software to generate data effortlessly.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ADAMM-Anomaly-Detection-of-Attributed-Multi-graphs-with-Metadata-A-Unified-Neural-Network-Approach"><a href="#ADAMM-Anomaly-Detection-of-Attributed-Multi-graphs-with-Metadata-A-Unified-Neural-Network-Approach" class="headerlink" title="ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A Unified Neural Network Approach"></a>ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A Unified Neural Network Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07355">http://arxiv.org/abs/2311.07355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/konsotirop/adamm">https://github.com/konsotirop/adamm</a></li>
<li>paper_authors: Konstantinos Sotiropoulos, Lingxiao Zhao, Pierre Jinghong Liang, Leman Akoglu</li>
<li>for: 针对复杂的图Database中的节点和边具有自适应特征的异常实例检测。</li>
<li>methods: 提出了一种名为ADAMM的图神经网络模型，可以直接处理导向的多边图和自环图，同时同时处理图和标注数据的整合。</li>
<li>results: 对两个不同领域的数据集进行了实验，包括公司的财务日志条目和人们的城市流动轨迹数据，并证明了ADAMM的一致性和检测效果。<details>
<summary>Abstract</summary>
Given a complex graph database of node- and edge-attributed multi-graphs as well as associated metadata for each graph, how can we spot the anomalous instances? Many real-world problems can be cast as graph inference tasks where the graph representation could capture complex relational phenomena (e.g., transactions among financial accounts in a journal entry), along with metadata reflecting tabular features (e.g. approver, effective date, etc.). While numerous anomaly detectors based on Graph Neural Networks (GNNs) have been proposed, none are capable of directly handling directed graphs with multi-edges and self-loops. Furthermore, the simultaneous handling of relational and tabular features remains an unexplored area. In this work we propose ADAMM, a novel graph neural network model that handles directed multi-graphs, providing a unified end-to-end architecture that fuses metadata and graph-level representation learning through an unsupervised anomaly detection objective. Experiments on datasets from two different domains, namely, general-ledger journal entries from different firms (accounting) as well as human GPS trajectories from thousands of individuals (urban mobility) validate ADAMM's generality and detection effectiveness of expert-guided and ground-truth anomalies. Notably, ADAMM outperforms existing baselines that handle the two data modalities (graph and metadata) separately with post hoc synthesis efforts.
</details>
<details>
<summary>摘要</summary>
给定复杂的图数据库，包括节点和边具有多重图的多图，以及每个图的相关metadata，如何检测异常实例？许多现实世界问题可以表示为图推理任务，图表示可以捕捉复杂的关系现象（例如，财务交易记录中的账户之间的交易），并且metadata反映了表格特征（例如，批准人、有效日期等）。尽管已经有许多基于图神经网络（GNNs）的异常检测器被提出，但是这些模型无法直接处理指定的多图和自Loop。此外，同时处理关系和表格特征的推理还是一个未探索的领域。在这项工作中，我们提出了ADAMM模型，它可以处理指定多图，并提供一个简单的端到端架构，通过不监督的异常检测目标来融合metadata和图 nivel representation学习。实验表明，ADAMM在不同领域的数据集上（包括财务记录和人类GPS轨迹）具有一致性和检测准确性，并且超过了分离两种数据模式（图和metadata）的基础线上的混合synthesis方法。
</details></li>
</ul>
<hr>
<h2 id="Affine-Invariance-in-Continuous-Domain-Convolutional-Neural-Networks"><a href="#Affine-Invariance-in-Continuous-Domain-Convolutional-Neural-Networks" class="headerlink" title="Affine Invariance in Continuous-Domain Convolutional Neural Networks"></a>Affine Invariance in Continuous-Domain Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09245">http://arxiv.org/abs/2311.09245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Mohaddes, Johannes Lederer</li>
<li>for: 本研究旨在提高深度学习模型对几何变换的识别能力，通过利用群变换的概念。</li>
<li>methods: 本研究使用了连续域 convolutional neural networks，并引入了一新的相似性评价标准来评估两个输入信号之间的相似性under affine transformations。</li>
<li>results: 研究表明，通过利用全部的affine transforms生成的泛型linear group $\mathrm{GL}_2(\mathbb{R})$，可以大幅提高深度学习模型的性能。<details>
<summary>Abstract</summary>
The notion of group invariance helps neural networks in recognizing patterns and features under geometric transformations. Indeed, it has been shown that group invariance can largely improve deep learning performances in practice, where such transformations are very common. This research studies affine invariance on continuous-domain convolutional neural networks. Despite other research considering isometric invariance or similarity invariance, we focus on the full structure of affine transforms generated by the generalized linear group $\mathrm{GL}_2(\mathbb{R})$. We introduce a new criterion to assess the similarity of two input signals under affine transformations. Then, unlike conventional methods that involve solving complex optimization problems on the Lie group $G_2$, we analyze the convolution of lifted signals and compute the corresponding integration over $G_2$. In sum, our research could eventually extend the scope of geometrical transformations that practical deep-learning pipelines can handle.
</details>
<details>
<summary>摘要</summary>
“GROUP INVARIANCE HELPS NEURAL NETWORKS RECOGNIZE PATTERNS AND FEATURES UNDER GEOMETRIC TRANSFORMATIONS. IN PRACTICE, SUCH TRANSFORMATIONS ARE VERY COMMON, AND GROUP INVARIANCE CAN LARGELY IMPROVE DEEP LEARNING PERFORMANCE. THIS RESEARCH STUDIES AFFINE INVARIANCE ON CONTINUOUS-DOMAIN CONVOLUTIONAL NEURAL NETWORKS. OTHER RESEARCH HAS CONSIDERED ISMETRIC INVARIANCE OR SIMILARITY INVARIANCE, BUT WE FOCUS ON THE FULL STRUCTURE OF AFFINE TRANSFORMS GENERATED BY THE GENERALIZED LINEAR GROUP $\mathbb{R}^2$. WE INTRODUCE A NEW CRITERION TO ASSESS THE SIMILARITY OF TWO INPUT SIGNALS UNDER AFFINE TRANSFORMATIONS. UNLIKE CONVENTIONAL METHODS THAT INVOLVE SOLVING COMPLEX OPTIMIZATION PROBLEMS ON THE LIE GROUP $G_2$, WE ANALYZE THE CONVOLUTION OF LIFTED SIGNALS AND COMPUTE THE CORRESPONDING INTEGRATION OVER $G_2$. IN SUM, OUR RESEARCH COULD FINALLY EXTEND THE SCOPE OF GEOMETRIC TRANSFORMATIONS THAT PRACTICAL DEEP-LEARNING PIPELINES CAN HANDLE.”Note that Simplified Chinese is used here, which is a more common writing system in China. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="Missing-Value-Imputation-for-Multi-attribute-Sensor-Data-Streams-via-Message-Propagation-Extended-Version"><a href="#Missing-Value-Imputation-for-Multi-attribute-Sensor-Data-Streams-via-Message-Propagation-Extended-Version" class="headerlink" title="Missing Value Imputation for Multi-attribute Sensor Data Streams via Message Propagation (Extended Version)"></a>Missing Value Imputation for Multi-attribute Sensor Data Streams via Message Propagation (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07344">http://arxiv.org/abs/2311.07344</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xli-2020/mpin">https://github.com/xli-2020/mpin</a></li>
<li>paper_authors: Xiao Li, Huan Li, Hua Lu, Christian S. Jensen, Varun Pandey, Volker Markl</li>
<li>for: 用于替代感知数据流中缺失值的快速和高效方法。</li>
<li>methods: 提出了一种消息协议推广网络（MPIN），可以在一个时间窗口内恢复缺失数据实例的值。同时，我们还提出了一种连续替换机制，包括数据更新和模型更新机制，以便MPIN可以在实时应用中进行连续替换。</li>
<li>results: MPIN可以在多个实际数据集上表现出较高的替换精度和效率，并且连续替换机制可以保证MPIN的高效性和准确性。<details>
<summary>Abstract</summary>
Sensor data streams occur widely in various real-time applications in the context of the Internet of Things (IoT). However, sensor data streams feature missing values due to factors such as sensor failures, communication errors, or depleted batteries. Missing values can compromise the quality of real-time analytics tasks and downstream applications. Existing imputation methods either make strong assumptions about streams or have low efficiency. In this study, we aim to accurately and efficiently impute missing values in data streams that satisfy only general characteristics in order to benefit real-time applications more widely. First, we propose a message propagation imputation network (MPIN) that is able to recover the missing values of data instances in a time window. We give a theoretical analysis of why MPIN is effective. Second, we present a continuous imputation framework that consists of data update and model update mechanisms to enable MPIN to perform continuous imputation both effectively and efficiently. Extensive experiments on multiple real datasets show that MPIN can outperform the existing data imputers by wide margins and that the continuous imputation framework is efficient and accurate.
</details>
<details>
<summary>摘要</summary>
仪器数据流广泛存在在互联网东西（IoT）中的实时应用中。然而，仪器数据流中存在缺失值，这些缺失值可能由仪器故障、通信错误或电池耗尽等因素引起。缺失值会下降实时分析任务和下游应用的质量。现有的填充方法都有一定的假设，或者效率低下。在这个研究中，我们想要准确地和高效地填充数据流中缺失值，以便更广泛地应用于实时应用。首先，我们提出了一种消息传播填充网络（MPIN），可以在时间窗口中重建缺失的数据实例。我们给出了MPIN的理论分析，解释了它的效果。其次，我们提出了一种连续填充框架，该框架包括数据更新和模型更新机制，以便MPIN可以在实时中进行连续填充，同时保证效果和效率。在多个实际数据集上进行了广泛的实验，我们发现MPIN可以在现有数据填充器的基础上准确地和高效地填充数据流中的缺失值，并且连续填充框架可以保证MPIN的高效性和准确性。
</details></li>
</ul>
<hr>
<h2 id="Fine-Tuning-the-Retrieval-Mechanism-for-Tabular-Deep-Learning"><a href="#Fine-Tuning-the-Retrieval-Mechanism-for-Tabular-Deep-Learning" class="headerlink" title="Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning"></a>Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07343">http://arxiv.org/abs/2311.07343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix den Breejen, Sangmin Bae, Stephen Cha, Tae-Young Kim, Seoung Hyun Koh, Se-Young Yun</li>
<li>for: 提高 tabular deep learning 的表现</li>
<li>methods: 使用召回机制，特别是在练习 TabPFN 模型的 fine-tuning 阶段</li>
<li>results: 在我们的实验中，使用召回机制和大量预训练可以明显超越现有方法，这些发现表明将召回机制融合到预训练和传输学习方案中可以提升 tabular deep learning 的表现。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
While interests in tabular deep learning has significantly grown, conventional tree-based models still outperform deep learning methods. To narrow this performance gap, we explore the innovative retrieval mechanism, a methodology that allows neural networks to refer to other data points while making predictions. Our experiments reveal that retrieval-based training, especially when fine-tuning the pretrained TabPFN model, notably surpasses existing methods. Moreover, the extensive pretraining plays a crucial role to enhance the performance of the model. These insights imply that blending the retrieval mechanism with pretraining and transfer learning schemes offers considerable potential for advancing the field of tabular deep learning.
</details>
<details>
<summary>摘要</summary>
而Tabular深度学习的兴趣在过去几年得到了广泛的关注，但是传统的树状模型仍然在深度学习方法之上表现更好。为了减少这个性能差距，我们 explore了一种创新的引用机制，即让神经网络在预测时引用其他数据点。我们的实验表明，引用基本训练，特别是在使用预训练TabPFN模型进行细化训练时，显著超过了现有方法。此外，广泛的预训练也对模型性能产生了重要的影响。这些发现表明，将引用机制与预训练和传输学习策略结合起来可以为表格深度学习领域带来显著的进步。
</details></li>
</ul>
<hr>
<h2 id="DAGC-Data-Volume-Aware-Adaptive-Sparsification-Gradient-Compression-for-Distributed-Machine-Learning-in-Mobile-Computing"><a href="#DAGC-Data-Volume-Aware-Adaptive-Sparsification-Gradient-Compression-for-Distributed-Machine-Learning-in-Mobile-Computing" class="headerlink" title="DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for Distributed Machine Learning in Mobile Computing"></a>DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for Distributed Machine Learning in Mobile Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07324">http://arxiv.org/abs/2311.07324</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rongwei Lu, Yutong Jiang, Yinan Mao, Chen Tang, Bin Chen, Laizhong Cui, Zhi Wang</li>
<li>for: 实现分布式机器学习（Distributed Machine Learning，DML）在移动环境中获得更好的性能。</li>
<li>methods: 使用非均匀压缩法，对不同的worker分配不同的压缩比例，以应对非同一的数据分布和量。</li>
<li>results: 这项研究发现，对于非同一的数据分布和量，将不同的压缩比例分配给不同的worker可以提高 convergence rate，并且可以在受限的通信预算下进行优化。<details>
<summary>Abstract</summary>
Distributed machine learning (DML) in mobile environments faces significant communication bottlenecks. Gradient compression has emerged as an effective solution to this issue, offering substantial benefits in environments with limited bandwidth and metered data. Yet, they encounter severe performance drop in non-IID environments due to a one-size-fits-all compression approach, which does not account for the varying data volumes across workers. Assigning varying compression ratios to workers with distinct data distributions and volumes is thus a promising solution. This study introduces an analysis of distributed SGD with non-uniform compression, which reveals that the convergence rate (indicative of the iterations needed to achieve a certain accuracy) is influenced by compression ratios applied to workers with differing volumes. Accordingly, we frame relative compression ratio assignment as an $n$-variables chi-square nonlinear optimization problem, constrained by a fixed and limited communication budget. We propose DAGC-R, which assigns the worker handling larger data volumes the conservative compression. Recognizing the computational limitations of mobile devices, we DAGC-A, which are computationally less demanding and enhances the robustness of the absolute gradient compressor in non-IID scenarios. Our experiments confirm that both the DAGC-A and DAGC-R can achieve better performance when dealing with highly imbalanced data volume distribution and restricted communication.
</details>
<details>
<summary>摘要</summary>
分布式机器学习（DML）在移动环境中遇到了重要的通信瓶颈。梯度压缩已经出现为解决这个问题的有效解决方案，提供了有限的带宽和计量数据环境中的重要优点。然而，它们在非标一致环境中会导致严重的性能下降，因为不考虑工作者间数据量的差异。将不同数据分布和量的工作者分配不同的压缩比例是一种有前途的解决方案。本研究提出了分布式SGD中非均匀压缩的分析，发现压缩比率应用于不同数据分布和量的工作者会影响收敛率（表示需要达到某种精度的迭代次数）。因此，我们将压缩比率分配视为n变量的chi-方差非线性优化问题，受限于固定的通信预算。我们提出了DAGC-R，它将处理大量数据的工作者分配保守的压缩。认识到移动设备的计算限制，我们还提出了DAGC-A，它是计算较少的，并在非标一致情况下提高了绝对梯度压缩器的稳定性。我们的实验表明，DAGC-A和DAGC-R可以在面临高度不均衡数据量分布和限制通信的情况下表现更好。
</details></li>
</ul>
<hr>
<h2 id="A-Voting-Approach-for-Explainable-Classification-with-Rule-Learning"><a href="#A-Voting-Approach-for-Explainable-Classification-with-Rule-Learning" class="headerlink" title="A Voting Approach for Explainable Classification with Rule Learning"></a>A Voting Approach for Explainable Classification with Rule Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07323">http://arxiv.org/abs/2311.07323</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertn7/modularrulelearning">https://github.com/albertn7/modularrulelearning</a></li>
<li>paper_authors: Albert Nössig, Tobias Hell, Georg Moser</li>
<li>for:  This paper investigates the application of rule learning methods in typical classification tasks, with a focus on providing explanations for the predictions made.</li>
<li>methods: The approach used in the paper is a voting method that combines rule learning and state-of-the-art methods to achieve comparable results with explanations.</li>
<li>results: The paper shows that the proposed approach outperforms ordinary rule learning methods and achieves results on a par with state-of-the-art outcomes, using a variety of benchmark data sets including a use case of significant interest to insurance industries.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文 investigate了通常的分类任务中使用规则学习方法，并强调提供预测结果的解释。</li>
<li>methods: 该论文使用的方法是一种投票方法，将规则学习和当今最佳方法结合起来，以实现与解释相对的结果。</li>
<li>results: 论文表明，提posed方法不仅比普通的规则学习方法更高效，还能够与当今最佳结果相比。使用了多个 benchmark 数据集，包括保险业的一个有用的应用场景。<details>
<summary>Abstract</summary>
State-of-the-art results in typical classification tasks are mostly achieved by unexplainable machine learning methods, like deep neural networks, for instance. Contrarily, in this paper, we investigate the application of rule learning methods in such a context. Thus, classifications become based on comprehensible (first-order) rules, explaining the predictions made. In general, however, rule-based classifications are less accurate than state-of-the-art results (often significantly). As main contribution, we introduce a voting approach combining both worlds, aiming to achieve comparable results as (unexplainable) state-of-the-art methods, while still providing explanations in the form of deterministic rules. Considering a variety of benchmark data sets including a use case of significant interest to insurance industries, we prove that our approach not only clearly outperforms ordinary rule learning methods, but also yields results on a par with state-of-the-art outcomes.
</details>
<details>
<summary>摘要</summary>
现代结果通常由不可解释的机器学习方法取得，如深度神经网络。然而，在本研究中，我们调查了规则学习方法的应用。因此，分类结果会基于可读的（第一类）规则，解释预测结果。然而，规则基分类通常比现代结果（经常significantly）精度较差。作为主要贡献，我们介绍了投票方法，结合这两个世界，尝试以相似的方式获得现代结果，同时仍提供可读的规则解释。使用多种标准资料集，包括一个有意义的保险业案例，我们证明了我们的方法不仅明显超过常规规则学习方法，而且也与现代结果相似。
</details></li>
</ul>
<hr>
<h2 id="An-introduction-to-reinforcement-learning-for-neuroscience"><a href="#An-introduction-to-reinforcement-learning-for-neuroscience" class="headerlink" title="An introduction to reinforcement learning for neuroscience"></a>An introduction to reinforcement learning for neuroscience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07315">http://arxiv.org/abs/2311.07315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristopher T. Jensen</li>
<li>for: 本文主要是为了介绍基于强化学习的神经科学研究，包括 классиical temporal difference算法和深度强化学习方法，以及它们在实验神经科学中的应用。</li>
<li>methods: 本文使用的方法包括模型自由和模型基于的强化学习，以及DYNA和继承表示法。这些方法在机器学习和神经科学实验中都有着广泛的应用。</li>
<li>results: 本文提供了一个入门性的介绍，涵盖了强化学习的基本理论和神经科学实验中的应用。同时，本文还提供了一些实际的例子，如meta-强化学习（Wang et al., 2018）和分布强化学习（Dabney et al., 2020），以及相关的代码和图像生成。<details>
<summary>Abstract</summary>
Reinforcement learning has a rich history in neuroscience, from early work on dopamine as a reward prediction error signal for temporal difference learning (Schultz et al., 1997) to recent work suggesting that dopamine could implement a form of 'distributional reinforcement learning' popularized in deep learning (Dabney et al., 2020). Throughout this literature, there has been a tight link between theoretical advances in reinforcement learning and neuroscientific experiments and findings. As a result, the theories describing our experimental data have become increasingly complex and difficult to navigate. In this review, we cover the basic theory underlying classical work in reinforcement learning and build up to an introductory overview of methods used in modern deep reinforcement learning that have found applications in systems neuroscience. We start with an overview of the reinforcement learning problem and classical temporal difference algorithms, followed by a discussion of 'model-free' and 'model-based' reinforcement learning together with methods such as DYNA and successor representations that fall in between these two categories. Throughout these sections, we highlight the close parallels between the machine learning methods and related work in both experimental and theoretical neuroscience. We then provide an introduction to deep reinforcement learning with examples of how these methods have been used to model different learning phenomena in the systems neuroscience literature, such as meta-reinforcement learning (Wang et al., 2018) and distributional reinforcement learning (Dabney et al., 2020). Code that implements the methods discussed in this work and generates the figures is also provided.
</details>
<details>
<summary>摘要</summary>
强化学习有着丰富的历史在神经科学中，从早期关于 dopamine 作为时间差值学习的奖励预测错误信号 (Schultz et al., 1997) 到最近的研究表明 dopamine 可能实现一种 '分布式强化学习' 的概念，它在深度学习中受欢迎 (Dabney et al., 2020)。在这些文献中，有着神经科学实验和发现的紧密联系，因此理论上的进步和实验的发现相互启发。在这篇文章中，我们将讲解强化学习的基本理论，从经典工作开始，然后推导到现代深度强化学习的方法，它们在系统神经科学中找到了应用。我们开始于强化学习问题的概述和经典时间差值算法，然后讲解 '模型自由' 和 '模型基于' 强化学习，以及 DYNA 和继承表示法，它们在这两个类别之间存在。在这些部分中，我们强调了机器学习方法和相关的神经科学实验和理论之间的密切相互关系。然后，我们将介绍深度强化学习，并通过系统神经科学文献中的不同学习现象模型，如 meta-强化学习 (Wang et al., 2018) 和分布式强化学习 (Dabney et al., 2020) 来示例。我们还提供了实现这些方法和生成图表的代码。
</details></li>
</ul>
<hr>
<h2 id="A-probabilistic-forecast-methodology-for-volatile-electricity-prices-in-the-Australian-National-Electricity-Market"><a href="#A-probabilistic-forecast-methodology-for-volatile-electricity-prices-in-the-Australian-National-Electricity-Market" class="headerlink" title="A probabilistic forecast methodology for volatile electricity prices in the Australian National Electricity Market"></a>A probabilistic forecast methodology for volatile electricity prices in the Australian National Electricity Market</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07289">http://arxiv.org/abs/2311.07289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cameron Cornell, Nam Trong Dinh, S. Ali Pourmousavi</li>
<li>for: 该论文主要探讨了澳大利亚南澳地区电力市场中的价格波动问题，并提出了一种可靠的预测方法。</li>
<li>methods: 该论文使用了随机过滤和一些后处理步骤，包括量词回归 ensemble 方法，以提高预测 precisio。</li>
<li>results:  comparing with各个模型的预测结果， ensemble 模型在预测澳大利亚南澳地区电力市场价格中显示出了更高的准确率和更好的适应性。<details>
<summary>Abstract</summary>
The South Australia region of the Australian National Electricity Market (NEM) displays some of the highest levels of price volatility observed in modern electricity markets. This paper outlines an approach to probabilistic forecasting under these extreme conditions, including spike filtration and several post-processing steps. We propose using quantile regression as an ensemble tool for probabilistic forecasting, with our combined forecasts achieving superior results compared to all constituent models. Within our ensemble framework, we demonstrate that averaging models with varying training length periods leads to a more adaptive model and increased prediction accuracy. The applicability of the final model is evaluated by comparing our median forecasts with the point forecasts available from the Australian NEM operator, with our model outperforming these NEM forecasts by a significant margin.
</details>
<details>
<summary>摘要</summary>
南澳大利用澳大电力市场（NEM）的区域显示出一些最高的价格波动，这篇论文描述了在这些极端情况下的抽象预测方法，包括峰值筛选和一些后处理步骤。我们建议使用量论回归作为ensemble工具，我们的组合预测达到了所有组件模型的超越成果。在我们的集成框架中，我们证明了平均模型各种训练时间期间的变化，导致更适应的模型和提高预测精度。我们对最终模型的可行性进行了评估，通过与澳大电力市场运营商提供的点预测相比较，我们的模型在重要的margin上超越了这些预测。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Learning-Arithmetic-Formulas-in-the-Presence-of-Noise-A-General-Framework-and-Applications-to-Unsupervised-Learning"><a href="#Learning-Arithmetic-Formulas-in-the-Presence-of-Noise-A-General-Framework-and-Applications-to-Unsupervised-Learning" class="headerlink" title="Learning Arithmetic Formulas in the Presence of Noise: A General Framework and Applications to Unsupervised Learning"></a>Learning Arithmetic Formulas in the Presence of Noise: A General Framework and Applications to Unsupervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07284">http://arxiv.org/abs/2311.07284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pritam Chandra, Ankit Garg, Neeraj Kayal, Kunal Mittal, Tanmay Sinha</li>
<li>for: 这 paper 是为了设计高效的无监督学习问题解决方案，如混合 Gaussian 和子空间 clustering。</li>
<li>methods: 这 paper 使用一种基于 meta 算法的框架，学习受噪的 arithmetic circuits。这基于 Garg, Kayal 和 Saha (FOCS 20) 的 latest work，但是它们不受噪。关键的一部分是一种高效的 Robust Vector Space Decomposition 算法。</li>
<li>results: 作者表明，当某些矩阵有足够大的最小非零特征值时，他们的 meta 算法会工作良好。作者还推测，这种condition 在简化版问题上成立，因此他们的框架可以在简化设定下提供高效的算法。<details>
<summary>Abstract</summary>
We present a general framework for designing efficient algorithms for unsupervised learning problems, such as mixtures of Gaussians and subspace clustering. Our framework is based on a meta algorithm that learns arithmetic circuits in the presence of noise, using lower bounds. This builds upon the recent work of Garg, Kayal and Saha (FOCS 20), who designed such a framework for learning arithmetic circuits without any noise. A key ingredient of our meta algorithm is an efficient algorithm for a novel problem called Robust Vector Space Decomposition. We show that our meta algorithm works well when certain matrices have sufficiently large smallest non-zero singular values. We conjecture that this condition holds for smoothed instances of our problems, and thus our framework would yield efficient algorithms for these problems in the smoothed setting.
</details>
<details>
<summary>摘要</summary>
我们提出了一个通用的框架，用于设计高效的无监督学习问题的算法，如混合 Gaussian 和 subspace clustering。我们的框架基于一个 meta 算法，可以在噪声存在的情况下学习加法Circuit，使用下界。这基于最近的 Garg、Kayal 和 Saha (FOCS 20) 的工作，他们设计了这样的框架，但不含噪声。我们的 meta 算法的关键组成部分是一种高效的 Robust Vector Space Decomposition 算法。我们表明，当某些矩阵有足够大的最小非零特征值时，我们的 meta 算法能够工作良好。我们推测，这种条件在简化的问题上是成立的，因此我们的框架可以在简化 Setting 中提供高效的算法。
</details></li>
</ul>
<hr>
<h2 id="Predictive-and-Prescriptive-Analytics-for-Multi-Site-Modeling-of-Frail-and-Elderly-Patient-Services"><a href="#Predictive-and-Prescriptive-Analytics-for-Multi-Site-Modeling-of-Frail-and-Elderly-Patient-Services" class="headerlink" title="Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail and Elderly Patient Services"></a>Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail and Elderly Patient Services</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07283">http://arxiv.org/abs/2311.07283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizabeth Williams, Daniel Gartner, Paul Harper<br>for:The paper aims to assess how predictive and prescriptive analytical methods can address operational challenges in healthcare, specifically in the context of planning resource capacities for frail and elderly inpatient wards.methods:The paper uses a combination of predictive and prescriptive analytical methods, including Classification and Regression Trees (CART) analysis and deterministic and two-stage stochastic programs, to analyze clinical and demographic patient attributes and predict length of stay.results:The linked methodologies provided different but similar results compared to using averages, capturing a more realistic real-world variation in patient length of stay. The results suggest that healthcare managers should consider using predictive and prescriptive models to make more informed decisions, rather than relying on averages.<details>
<summary>Abstract</summary>
Recent research has highlighted the potential of linking predictive and prescriptive analytics. However, it remains widely unexplored how both paradigms could benefit from one another to address today's major challenges in healthcare. One of these is smarter planning of resource capacities for frail and elderly inpatient wards, addressing the societal challenge of an aging population. Frail and elderly patients typically suffer from multimorbidity and require more care while receiving medical treatment. The aim of this research is to assess how various predictive and prescriptive analytical methods, both individually and in tandem, contribute to addressing the operational challenges within an area of healthcare that is growing in demand. Clinical and demographic patient attributes are gathered from more than 165,000 patient records and used to explain and predict length of stay. To that extent, we employ Classification and Regression Trees (CART) analysis to establish this relationship. On the prescriptive side, deterministic and two-stage stochastic programs are developed to determine how to optimally plan for beds and ward staff with the objective to minimize cost. Furthermore, the two analytical methodologies are linked by generating demand for the prescriptive models using the CART groupings. The results show the linked methodologies provided different but similar results compared to using averages and in doing so, captured a more realistic real-world variation in the patient length of stay. Our research reveals that healthcare managers should consider using predictive and prescriptive models to make more informed decisions. By combining predictive and prescriptive analytics, healthcare managers can move away from relying on averages and incorporate the unique characteristics of their patients to create more robust planning decisions, mitigating risks caused by variations in demand.
</details>
<details>
<summary>摘要</summary>
To assess the operational challenges within inpatient wards, we gathered clinical and demographic patient attributes from over 165,000 patient records and used Classification and Regression Trees (CART) analysis to explain and predict length of stay. We also developed deterministic and two-stage stochastic programs to determine how to optimally plan for beds and ward staff to minimize cost.The linked methodologies provided different but similar results compared to using averages, capturing a more realistic real-world variation in patient length of stay. Our research reveals that healthcare managers should consider using predictive and prescriptive models to make more informed decisions, moving away from relying on averages and incorporating the unique characteristics of their patients to create more robust planning decisions. By linking predictive and prescriptive analytics, healthcare managers can mitigate risks caused by variations in demand and create a more sustainable and effective healthcare system.
</details></li>
</ul>
<hr>
<h2 id="Towards-Bounding-Causal-Effects-under-Markov-Equivalence"><a href="#Towards-Bounding-Causal-Effects-under-Markov-Equivalence" class="headerlink" title="Towards Bounding Causal Effects under Markov Equivalence"></a>Towards Bounding Causal Effects under Markov Equivalence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07259">http://arxiv.org/abs/2311.07259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexis Bellot</li>
<li>for: 这 paper 的目的是解决非观察数据下的 causal effect 预测问题，即 determining non-trivial bounds on causal effects induced by the data.</li>
<li>methods: 这 paper 使用了一种名为 Partial Ancestral Graph 的 less informative structure，并提供了一种系统的算法来 derive bounds on causal effects ，可以从 observational data 中学习。</li>
<li>results: 这 paper 的结果是提供了一种可 analytically 计算的 bounds on causal effects，它们可以在 less informative 的 causal diagram 下进行计算。<details>
<summary>Abstract</summary>
Predicting the effect of unseen interventions is a fundamental research question across the data sciences. It is well established that, in general, such questions cannot be answered definitively from observational data, e.g., as a consequence of unobserved confounding. A generalization of this task is to determine non-trivial bounds on causal effects induced by the data, also known as the task of partial causal identification. In the literature, several algorithms have been developed for solving this problem. Most, however, require a known parametric form or a fully specified causal diagram as input, which is usually not available in practical applications. In this paper, we assume as input a less informative structure known as a Partial Ancestral Graph, which represents a Markov equivalence class of causal diagrams and is learnable from observational data. In this more "data-driven" setting, we provide a systematic algorithm to derive bounds on causal effects that can be computed analytically.
</details>
<details>
<summary>摘要</summary>
Predicting the effect of unseen interventions is a fundamental research question across the data sciences. It is well established that, in general, such questions cannot be answered definitively from observational data, e.g., due to unobserved confounding. A generalization of this task is to determine non-trivial bounds on causal effects induced by the data, also known as the task of partial causal identification. In the literature, several algorithms have been developed for solving this problem. Most, however, require a known parametric form or a fully specified causal diagram as input, which is usually not available in practical applications. In this paper, we assume as input a less informative structure known as a Partial Ancestral Graph, which represents a Markov equivalence class of causal diagrams and is learnable from observational data. In this more "data-driven" setting, we provide a systematic algorithm to derive bounds on causal effects that can be computed analytically.Here's the translation in Traditional Chinese as well:预测未见的干预效果是资料科学中的基本研究问题。已经证明，在一般情况下，这些问题无法从观察数据中确定答案，例如因为隐藏的共组因素。一个这个任务的扩展是决定观察数据中的非重要效果 bound，也就是partial causal identification的任务。在文献中，有许多算法用于解决这个问题，但大多数需要知道的 parametric form 或者完全的 causal diagram 作为输入，这通常不是实际应用中的情况。在这篇文章中，我们假设输入的是一个 less informative 的结构，known as Partial Ancestral Graph，这是一个可以从观察数据学习的 Markov equivalence class of causal diagrams。在这个 "data-driven" 的设定下，我们提供了一个系统的算法，可以分析方式 compute analytically bounds on causal effects。
</details></li>
</ul>
<hr>
<h2 id="Error-Analysis-of-Option-Pricing-via-Deep-PDE-Solvers-Empirical-Study"><a href="#Error-Analysis-of-Option-Pricing-via-Deep-PDE-Solvers-Empirical-Study" class="headerlink" title="Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study"></a>Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07231">http://arxiv.org/abs/2311.07231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rawin Assabumrungrat, Kentaro Minami, Masanori Hirano</li>
<li>for: 这个论文的目的是为了研究深度学习基于PDE解决高维Option价值问题的可scalability和实用性。</li>
<li>methods: 这个论文使用了深度学习基于PDE的方法来解决高维Option价值问题，并进行了对比性试验来评估这些方法的实际性和可scalability。</li>
<li>results: 研究发现了三种主要的错误来源：（1）目标选项和下一个资产的规定错误，（2）资产模型仿真方法引起的错误，（3）神经网络训练过程中的错误。这些错误的影响都被细分分析了。研究发现DBSDE方法在性能和可靠性方面较为出色，而其他方法则具有较强的sensitivity性。此外，研究还发现了计算资源的尺度关系，即batch size和时间步长的平方根与方法性能之间存在负相关性。<details>
<summary>Abstract</summary>
Option pricing, a fundamental problem in finance, often requires solving non-linear partial differential equations (PDEs). When dealing with multi-asset options, such as rainbow options, these PDEs become high-dimensional, leading to challenges posed by the curse of dimensionality. While deep learning-based PDE solvers have recently emerged as scalable solutions to this high-dimensional problem, their empirical and quantitative accuracy remains not well-understood, hindering their real-world applicability. In this study, we aimed to offer actionable insights into the utility of Deep PDE solvers for practical option pricing implementation. Through comparative experiments, we assessed the empirical performance of these solvers in high-dimensional contexts. Our investigation identified three primary sources of errors in Deep PDE solvers: (i) errors inherent in the specifications of the target option and underlying assets, (ii) errors originating from the asset model simulation methods, and (iii) errors stemming from the neural network training. Through ablation studies, we evaluated the individual impact of each error source. Our results indicate that the Deep BSDE method (DBSDE) is superior in performance and exhibits robustness against variations in option specifications. In contrast, some other methods are overly sensitive to option specifications, such as time to expiration. We also find that the performance of these methods improves inversely proportional to the square root of batch size and the number of time steps. This observation can aid in estimating computational resources for achieving desired accuracies with Deep PDE solvers.
</details>
<details>
<summary>摘要</summary>
Option 价值计价，金融领域的基本问题，经常需要解决非线性偏微分方程（PDE）。在多资产选项（如彩虹选项）的情况下，这些PDE变得高维度，带来维度味的挑战。Recently, deep learning-based PDE solvers have emerged as scalable solutions to this high-dimensional problem, but their empirical and quantitative accuracy remains not well-understood, hindering their real-world applicability. In this study, we aimed to offer actionable insights into the utility of Deep PDE solvers for practical option pricing implementation. Through comparative experiments, we assessed the empirical performance of these solvers in high-dimensional contexts. Our investigation identified three primary sources of errors in Deep PDE solvers: (i) errors inherent in the specifications of the target option and underlying assets, (ii) errors originating from the asset model simulation methods, and (iii) errors stemming from the neural network training. Through ablation studies, we evaluated the individual impact of each error source. Our results indicate that the Deep BSDE method (DBSDE) is superior in performance and exhibits robustness against variations in option specifications. In contrast, some other methods are overly sensitive to option specifications, such as time to expiration. We also find that the performance of these methods improves inversely proportional to the square root of batch size and the number of time steps. This observation can aid in estimating computational resources for achieving desired accuracies with Deep PDE solvers.Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Neural-General-Circulation-Models"><a href="#Neural-General-Circulation-Models" class="headerlink" title="Neural General Circulation Models"></a>Neural General Circulation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07222">http://arxiv.org/abs/2311.07222</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ananya2001gupta/Bitcoin-Price-Prediction-using-AI-ML">https://github.com/ananya2001gupta/Bitcoin-Price-Prediction-using-AI-ML</a>.</li>
<li>paper_authors: Dmitrii Kochkov, Janni Yuval, Ian Langmore, Peter Norgaard, Jamie Smith, Griffin Mooers, James Lottes, Stephan Rasp, Peter Düben, Milan Klöwer, Sam Hatfield, Peter Battaglia, Alvaro Sanchez-Gonzalez, Matthew Willson, Michael P. Brenner, Stephan Hoyer</li>
<li>for: 这篇论文的目的是为了开发一种新的气象模型，它结合了数学方法和机器学习技术，以提高天气预测和气候预测的准确性和效率。</li>
<li>methods: 这篇论文使用的方法包括了机器学习模型和传统的气象模型，以及一种可微的解方法，用于解决大规模动力学问题。</li>
<li>results: 这篇论文的结果表明，该新的气象模型可以与传统的气象模型和机器学习模型相比，在1-10天的天气预测和1-15天的气候预测中具有同等或更高的准确性。此外，该模型还可以在长期气候预测中准确地跟踪全球气候指标，并且可以模拟出实际的热带风暴频率和轨迹。<details>
<summary>Abstract</summary>
General circulation models (GCMs) are the foundation of weather and climate prediction. GCMs are physics-based simulators which combine a numerical solver for large-scale dynamics with tuned representations for small-scale processes such as cloud formation. Recently, machine learning (ML) models trained on reanalysis data achieved comparable or better skill than GCMs for deterministic weather forecasting. However, these models have not demonstrated improved ensemble forecasts, or shown sufficient stability for long-term weather and climate simulations. Here we present the first GCM that combines a differentiable solver for atmospheric dynamics with ML components, and show that it can generate forecasts of deterministic weather, ensemble weather and climate on par with the best ML and physics-based methods. NeuralGCM is competitive with ML models for 1-10 day forecasts, and with the European Centre for Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts. With prescribed sea surface temperature, NeuralGCM can accurately track climate metrics such as global mean temperature for multiple decades, and climate forecasts with 140 km resolution exhibit emergent phenomena such as realistic frequency and trajectories of tropical cyclones. For both weather and climate, our approach offers orders of magnitude computational savings over conventional GCMs. Our results show that end-to-end deep learning is compatible with tasks performed by conventional GCMs, and can enhance the large-scale physical simulations that are essential for understanding and predicting the Earth system.
</details>
<details>
<summary>摘要</summary>
全球气候模型（GCM）是天气和气候预测的基础模型。GCM 是一种基于物理的数值模拟器，将大规模动力学数值解析与调整的小规模过程模型相结合。近年来，基于机器学习（ML）的模型在 deterministic 天气预测中达到了相当于或更好的技能，但它们尚未展现出了改善的ensemble预测或长期天气和气候 simulations 的稳定性。在这篇文章中，我们首次把数分解 solver 与 ML 组件结合在一起，并证明它可以生成 deterministic 天气、ensemble 天气和气候预测，与best 的 ML 和物理学习方法相当。我们称之为 NeuralGCM。NeuralGCM 在 1-10 天预测中与 ML 模型相当，并与欧洲中期天气预测 ensemble 在 1-15 天预测中相当。在给定的海洋表面温度下，NeuralGCM 可以准确地跟踪气候指标，如全球平均温度，并且气候预测具有140 km 的分辨率可以显示出见识真实的热带风暴的频率和轨迹。在天气和气候方面，我们的方法可以与传统 GCM 的计算量相比，提供多个级别的计算效益。我们的结果表明，深度学习可以与传统 GCM 的任务相容，并且可以提高大规模物理 simulations 的精度，这些 simulations 是地球系统的理解和预测的关键。
</details></li>
</ul>
<hr>
<h2 id="Non-Contact-Breathing-Rate-Detection-Using-Optical-Flow"><a href="#Non-Contact-Breathing-Rate-Detection-Using-Optical-Flow" class="headerlink" title="Non-Contact Breathing Rate Detection Using Optical Flow"></a>Non-Contact Breathing Rate Detection Using Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08426">http://arxiv.org/abs/2311.08426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robyn Maxwell, Timothy Hanley, Dara Golden, Adara Andonie, Joseph Lemley, Ashkan Parsi</li>
<li>for: 这个论文的目的是研究一种非接触式呼吸速率检测方法，使用动态推理算法。</li>
<li>methods: 这篇论文使用了光流算法来成功测量呼吸速率，通过跟踪身体特定点的运动来确定呼吸速率。</li>
<li>results: 测试表明，胸部运动可以生成非常准确的信号，RMSE为0.63。然而，面部运动也可以生成可靠的信号，但是受到头体运动干扰的影响。这些发现表明了光流算法的潜在用于非接触式呼吸速率检测，并且选择合适的点可以提高准确性。<details>
<summary>Abstract</summary>
Breathing rate is a vital health metric that is an invaluable indicator of the overall health of a person. In recent years, the non-contact measurement of health signals such as breathing rate has been a huge area of development, with a wide range of applications from telemedicine to driver monitoring systems. This paper presents an investigation into a method of non-contact breathing rate detection using a motion detection algorithm, optical flow. Optical flow is used to successfully measure breathing rate by tracking the motion of specific points on the body. In this study, the success of optical flow when using different sets of points is evaluated. Testing shows that both chest and facial movement can be used to determine breathing rate but to different degrees of success. The chest generates very accurate signals, with an RMSE of 0.63 on the tested videos. Facial points can also generate reliable signals when there is minimal head movement but are much more vulnerable to noise caused by head/body movements. These findings highlight the potential of optical flow as a non-invasive method for breathing rate detection and emphasize the importance of selecting appropriate points to optimize accuracy.
</details>
<details>
<summary>摘要</summary>
呼吸速率是一个重要的健康指标，对人体全面健康具有无估的意义。在最近的年头，非接触式健康信号的测量已经成为了很大的发展领域，从 теле医疗到驾驶员监测系统。本文介绍了一种非接触式呼吸速率检测方法，使用动态流体遥感算法。动态流体遥感算法可以成功地测量呼吸速率，通过跟踪体内具有特定点的运动。本研究中，使用不同的点集来评估动态流体的成功率。测试结果显示，胸部运动可以生成非常准确的信号，RMSE为0.63。脸部运动也可以生成可靠的信号，但是当头体运动较大时，会受到干扰。这些发现强调了动态流体的非侵入式方法在呼吸速率检测中的潜在优势，并且选择合适的点可以提高准确性。
</details></li>
</ul>
<hr>
<h2 id="On-Elastic-Language-Models"><a href="#On-Elastic-Language-Models" class="headerlink" title="On Elastic Language Models"></a>On Elastic Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07204">http://arxiv.org/abs/2311.07204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RAIVNLab/MatFormer-OLMo">https://github.com/RAIVNLab/MatFormer-OLMo</a></li>
<li>paper_authors: Chen Zhang, Benyou Wang, Dawei Song</li>
<li>for: 这个论文的目的是提出一种可塑性语言模型（ElasticLM），以适应高变化的请求流量而提供可控制的计算弹性。</li>
<li>methods: 该论文使用了知识储存distillation技术将大型语言模型压缩到小型模型中，并在请求流量变化时进行计算弹性调整，以实现可控制的响应时间-性能质量融合。</li>
<li>results: 实验结果表明，与静态基线相比，ElasticLM可以在不同的请求流量下提供可控制的响应时间-性能质量融合，并且可以在高并发下进行线上 simulate 。<details>
<summary>Abstract</summary>
Large-scale pretrained language models have achieved compelling performance in a wide range of language understanding and information retrieval tasks. Knowledge distillation offers an opportunity to compress a large language model to a small one, in order to reach a reasonable latency-performance tradeoff. However, for scenarios where the number of requests (e.g., queries submitted to a search engine) is highly variant, the static tradeoff attained by the compressed language model might not always fit. Once a model is assigned with a static tradeoff, it could be inadequate in that the latency is too high when the number of requests is large or the performance is too low when the number of requests is small. To this end, we propose an elastic language model (ElasticLM) that elastically adjusts the tradeoff according to the request stream. The basic idea is to introduce a compute elasticity to the compressed language model, so that the tradeoff could vary on-the-fly along scalable and controllable compute. Specifically, we impose an elastic structure to enable ElasticLM with compute elasticity and design an elastic optimization to learn ElasticLM under compute elasticity. To serve ElasticLM, we apply an elastic schedule. Considering the specificity of information retrieval, we adapt ElasticLM to dense retrieval and reranking and present ElasticDenser and ElasticRanker respectively. Offline evaluation is conducted on a language understanding benchmark GLUE; and several information retrieval tasks including Natural Question, Trivia QA, and MS MARCO. The results show that ElasticLM along with ElasticDenser and ElasticRanker can perform correctly and competitively compared with an array of static baselines. Furthermore, online simulation with concurrency is also carried out. The results demonstrate that ElasticLM can provide elastic tradeoffs with respect to varying request stream.
</details>
<details>
<summary>摘要</summary>
大规模预训练语言模型已经在各种语言理解和信息检索任务中达到了吸引人的性能。知识填充提供了一种将大型语言模型压缩到小型模型的机会，以实现可接受的延迟-性能质量评估。然而，在请求数（例如，提交到搜索引擎的查询）高度变化的场景下，静态质量可能不适用。一旦模型被分配了静态质量，它可能无法适应高请求量时的延迟或低性能时的请求量较少。为解决这个问题，我们提出了弹性语言模型（ElasticLM），它可以在请求流中灵活地调整质量评估的平衡。基本想法是通过引入可灵活计算的弹性结构，使得弹性LM可以在可扩展和可控的计算下进行灵活的质量评估。具体来说，我们在弹性LM中引入了一种计算弹性，以便在不同的请求流中进行灵活的质量评估。我们还设计了一种弹性优化算法，以学习弹性LM在计算弹性下的性能。为了服务弹性LM，我们采用了一种灵活的调度策略。考虑到信息检索的特点，我们适应了弹性LM到紧凑检索和重新排序，并分别提出了弹性紧凑器（ElasticDenser）和弹性排序器（ElasticRanker）。在GLUE语言理解 benchmark上进行了线上评估，以及一些信息检索任务，如自然问题、智能问答和 MS MARCO。结果显示，弹性LM、弹性紧凑器和弹性排序器可以正确地和竞争力地与静态基线相比。此外，我们还进行了在线验证，并发现弹性LM可以根据请求流的变化提供灵活的质量评估平衡。
</details></li>
</ul>
<hr>
<h2 id="Input-Convex-LSTM-A-Convex-Approach-for-Fast-Lyapunov-Based-Model-Predictive-Control"><a href="#Input-Convex-LSTM-A-Convex-Approach-for-Fast-Lyapunov-Based-Model-Predictive-Control" class="headerlink" title="Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control"></a>Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07202">http://arxiv.org/abs/2311.07202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihao Wang, Zhe Wu</li>
<li>for: 提高MPC的准确率和速度，解决ICNN中vanishing gradient问题</li>
<li>methods: 基于ICNN的LSTM模型，利用input convex性保证closed-loop稳定性，提高MPC的准确率和速度</li>
<li>results: 在非线性化学反应器的模拟研究中，提高了46.7%、31.3%和20.2%相比于基eline平板RNN、平板LSTM和输入几何RECNN模型的减少时间和mitigate vanishing gradient问题<details>
<summary>Abstract</summary>
Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive Control (MPC) successfully attains globally optimal solutions by upholding convexity within the MPC framework. However, current ICNN architectures encounter the issue of vanishing gradients, which limits their ability to serve as deep neural networks for complex tasks. Additionally, the current neural network-based MPC, including conventional neural network-based MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC based on first-principles models. In this study, we leverage the principles of ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific goal of reducing convergence time and mitigating the vanishing gradient problem while ensuring closed-loop stability. From a simulation study of a nonlinear chemical reactor, we observed a mitigation of vanishing gradient problem and a reduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and 20.2% compared to baseline plain RNN, plain LSTM, and Input Convex Recurrent Neural Network, respectively.
</details>
<details>
<summary>摘要</summary>
使用输入凸神经网络（ICNN），ICNN基本的模型预测控制（MPC）得到了全球最优解决方案，并保持在MPC框架中的凸性。然而，当前ICNN架构面临着衰减 gradients 问题，这限制了它们作为复杂任务的深度神经网络的能力。此外，当前神经网络基于的 MPC，包括常见神经网络基于的 MPC 和 ICNN基本的 MPC，在比基于初始理论模型的 MPC  slower convergence speed 。在本研究中，我们基于 ICNN 的原理提出了一种新的输入凸 LSTM  для Lyapunov-based MPC，以减少 converge 时间和消除衰减 gradients 问题，并确保关闭环Loop 稳定性。从一个非线性化学反应器的模拟研究来看，我们观察到了衰减 gradients 问题的减少和 converge 时间的减少，相比基eline plain RNN、plain LSTM 和输入凸回归神经网络，分别下降了46.7%、31.3%和20.2%。
</details></li>
</ul>
<hr>
<h2 id="A-Consistent-Diffusion-Based-Algorithm-for-Semi-Supervised-Graph-Learning"><a href="#A-Consistent-Diffusion-Based-Algorithm-for-Semi-Supervised-Graph-Learning" class="headerlink" title="A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph Learning"></a>A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07627">http://arxiv.org/abs/2311.07627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Bonald, Nathan de Lara</li>
<li>for: 这个论文是关于半监督分类的研究，目标是将图形上的所有节点分配标签，使用一些已知标签的节点作为种子来刺激整个图形。</li>
<li>methods: 这种算法基于热传导原理，将种子节点的标签通过热导媒体传播到整个图形，然后使用每个节点的温度作为每个标签的分数函数。</li>
<li>results: 这paper证明了这种算法不是一定consistent， Unless the temperatures of the nodes at equilibrium are centered before scoring。这个步骤不仅使得算法可证明consistent，还会在实际图形上带来显著的性能提升。<details>
<summary>Abstract</summary>
The task of semi-supervised classification aims at assigning labels to all nodes of a graph based on the labels known for a few nodes, called the seeds. One of the most popular algorithms relies on the principle of heat diffusion, where the labels of the seeds are spread by thermoconductance and the temperature of each node at equilibrium is used as a score function for each label. In this paper, we prove that this algorithm is not consistent unless the temperatures of the nodes at equilibrium are centered before scoring. This crucial step does not only make the algorithm provably consistent on a block model but brings significant performance gains on real graphs.
</details>
<details>
<summary>摘要</summary>
semi-supervised classification的任务是将所有图节点分配标签，基于一些节点的标签（称为种子）的知道。最受欢迎的算法基于热传导原理，其中种子标签通过热导性传播，每个节点的热度（即每个标签的得分函数）在均衡状态下是一个分数函数。在这篇论文中，我们证明了这个算法不一定是一致的，除非在执行前将节点的热度中心化。这一步不仅使算法可证性提高，还会在真实的图上带来显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Machine-Learning-for-Remote-Sensing-Exploring-potential-and-challenges"><a href="#Quantum-Machine-Learning-for-Remote-Sensing-Exploring-potential-and-challenges" class="headerlink" title="Quantum Machine Learning for Remote Sensing: Exploring potential and challenges"></a>Quantum Machine Learning for Remote Sensing: Exploring potential and challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07626">http://arxiv.org/abs/2311.07626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Artur Miroszewski, Jakub Nalepa, Bertrand Le Saux, Jakub Mielczarek</li>
<li>for: 这篇论文研究了量子机器学习（QML）在遥感领域的应用。</li>
<li>methods: 该论文使用了量子计算机来处理和分析遥感数据，并研究了量子优势在QML中对遥感领域的影响。</li>
<li>results: 研究发现，尽管量子计算机的kernel值峰值集中问题会降低其性能，但这并不完全消除量子优势在QML中对遥感领域的影响。<details>
<summary>Abstract</summary>
The industry of quantum technologies is rapidly expanding, offering promising opportunities for various scientific domains. Among these emerging technologies, Quantum Machine Learning (QML) has attracted considerable attention due to its potential to revolutionize data processing and analysis. In this paper, we investigate the application of QML in the field of remote sensing. It is believed that QML can provide valuable insights for analysis of data from space. We delve into the common beliefs surrounding the quantum advantage in QML for remote sensing and highlight the open challenges that need to be addressed. To shed light on the challenges, we conduct a study focused on the problem of kernel value concentration, a phenomenon that adversely affects the runtime of quantum computers. Our findings indicate that while this issue negatively impacts quantum computer performance, it does not entirely negate the potential quantum advantage in QML for remote sensing.
</details>
<details>
<summary>摘要</summary>
产业领域的量子技术在快速发展，为不同科学领域提供了抢夺的机会。这些emerging technologies中，量子机器学习（QML）已经吸引了广泛的注意，因为它可能改变数据处理和分析的方式。在这篇论文中，我们调查了QML在遥感领域的应用。据信QML可以为遥感数据分析提供有价值的洞察。我们探讨了量子优势在QML领域的共同信念，并高亮了需要解决的开放挑战。为了照明这些挑战，我们进行了关于值集中心的问题研究，这是量子计算机性能的一个问题。我们的发现表明，虽然这个问题会影响量子计算机的性能，但并不完全否定量子优势在QML领域的遥感数据分析中。
</details></li>
</ul>
<hr>
<h2 id="Activity-Sparsity-Complements-Weight-Sparsity-for-Efficient-RNN-Inference"><a href="#Activity-Sparsity-Complements-Weight-Sparsity-for-Efficient-RNN-Inference" class="headerlink" title="Activity Sparsity Complements Weight Sparsity for Efficient RNN Inference"></a>Activity Sparsity Complements Weight Sparsity for Efficient RNN Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07625">http://arxiv.org/abs/2311.07625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishav Mukherji, Mark Schöne, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney</li>
<li>for: 这篇论文主要探讨了深度学习模型中的活动簇节点，以及将其转移到神经元 computing 设备上的可能性。</li>
<li>methods: 本研究使用了 GRU 模型，并通过将活动节点簇节过滤来实现活动簇。此外，研究还考虑了活动簇与参数簇的互动。</li>
<li>results: 研究获得了Up to $20\times$ 的computational 缩减，并且维持了 perplexity 值在 $60$ 以下，在 Penn Treebank 语言模型任务上。这个结果不仅不受对对参数簇的影响，而且也不受对对活动簇的影响。<details>
<summary>Abstract</summary>
Artificial neural networks open up unprecedented machine learning capabilities at the cost of ever growing computational requirements. Sparsifying the parameters, often achieved through weight pruning, has been identified as a powerful technique to compress the number of model parameters and reduce the computational operations of neural networks. Yet, sparse activations, while omnipresent in both biological neural networks and deep learning systems, have not been fully utilized as a compression technique in deep learning. Moreover, the interaction between sparse activations and weight pruning is not fully understood. In this work, we demonstrate that activity sparsity can compose multiplicatively with parameter sparsity in a recurrent neural network model based on the GRU that is designed to be activity sparse. We achieve up to $20\times$ reduction of computation while maintaining perplexities below $60$ on the Penn Treebank language modeling task. This magnitude of reduction has not been achieved previously with solely sparsely connected LSTMs, and the language modeling performance of our model has not been achieved previously with any sparsely activated recurrent neural networks or spiking neural networks. Neuromorphic computing devices are especially good at taking advantage of the dynamic activity sparsity, and our results provide strong evidence that making deep learning models activity sparse and porting them to neuromorphic devices can be a viable strategy that does not compromise on task performance. Our results also drive further convergence of methods from deep learning and neuromorphic computing for efficient machine learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Symmetrization-for-Equivariance-with-Orbit-Distance-Minimization"><a href="#Learning-Symmetrization-for-Equivariance-with-Orbit-Distance-Minimization" class="headerlink" title="Learning Symmetrization for Equivariance with Orbit Distance Minimization"></a>Learning Symmetrization for Equivariance with Orbit Distance Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07143">http://arxiv.org/abs/2311.07143</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tiendatnguyen-vision/orbit-symmetrize">https://github.com/tiendatnguyen-vision/orbit-symmetrize</a></li>
<li>paper_authors: Tien Dat Nguyen, Jinwoo Kim, Hongseok Yang, Seunghoon Hong</li>
<li>for: 将任意神经网络架构变换为具有给定群的对称性和等变性。</li>
<li>methods: 基于kim et al. (2023)和kaba et al. (2023)的提议，使用优化的损失函数来替换神经特征的群表示，以提高适用范围。</li>
<li>results: 在SO(2)图像分类任务和O(1, 3)任务上实验表明，我们的方法具有竞争力和更广泛的通用性。实现将于<a target="_blank" rel="noopener" href="https://github.com/tiendatnguyen-vision/Orbit-symmetrize">https://github.com/tiendatnguyen-vision/Orbit-symmetrize</a> 上公开。<details>
<summary>Abstract</summary>
We present a general framework for symmetrizing an arbitrary neural-network architecture and making it equivariant with respect to a given group. We build upon the proposals of Kim et al. (2023); Kaba et al. (2023) for symmetrization, and improve them by replacing their conversion of neural features into group representations, with an optimization whose loss intuitively measures the distance between group orbits. This change makes our approach applicable to a broader range of matrix groups, such as the Lorentz group O(1, 3), than these two proposals. We experimentally show our method's competitiveness on the SO(2) image classification task, and also its increased generality on the task with O(1, 3). Our implementation will be made accessible at https://github.com/tiendatnguyen-vision/Orbit-symmetrize.
</details>
<details>
<summary>摘要</summary>
我们提出一个通用的框架，使得任意神经网络架构变为对一个给定群的对称化和可变性满足。我们基于kim et al. (2023)和kaba et al. (2023)的提议，并且改进了它们，将神经特征转换为群表示的步骤替换为一个优化过程，损失函数直观度量群轨迹之间的距离。这种变化使我们的方法可以应用于更广泛的矩阵群，如 Lorentz 群 O(1, 3)，而不是这两个提议。我们在 SO(2) 图像分类任务上进行了实验，并证明了我们的方法的竞争力。此外，我们还证明了我们的方法在 O(1, 3) 上的更高一致性。我们的实现将在 GitHub 上提供，地址为 <https://github.com/tiendatnguyen-vision/Orbit-symmetrize>。
</details></li>
</ul>
<hr>
<h2 id="SABAF-Removing-Strong-Attribute-Bias-from-Neural-Networks-with-Adversarial-Filtering"><a href="#SABAF-Removing-Strong-Attribute-Bias-from-Neural-Networks-with-Adversarial-Filtering" class="headerlink" title="SABAF: Removing Strong Attribute Bias from Neural Networks with Adversarial Filtering"></a>SABAF: Removing Strong Attribute Bias from Neural Networks with Adversarial Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07141">http://arxiv.org/abs/2311.07141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazhi Li, Mahyar Khayatkhoei, Jiageng Zhu, Hanchen Xie, Mohamed E. Hussein, Wael AbdAlmageed</li>
<li>for: 避免神经网络依赖保护属性（例如种族、性别、年龄）进行预测是当今发展公平可信的AI的关键。虽然已有许多有效的属性偏好除去方法被提出，但它们的局限性尚未得到充分探讨。为此，在这项工作中，我们数学和实验证明了现有属性偏好除去方法在强偏好情况下的局限性，并提出了一种新的方法可以 Mitigate这种局限性。</li>
<li>methods: 我们首先 derive了一个普适的非虚空信息理论上限，表明现有属性偏好除去方法在偏好强度较弱时才能够有效。然后，我们 derive了任何可以除去属性偏好的方法必须满足的必要条件。 inspirited by这个条件，我们则提出了一种新的方法，使用对抗目标函数直接在输入空间中过滤保护属性，不需要任何特定目标标签，并且可以在强偏好和中等偏好情况下达到州际表现。</li>
<li>results: 我们对 sintetic、图像和人口普查数据集进行了广泛的实验，以验证 derive的理论上限和其实际效果，以及提出的新方法在强偏好和中等偏好情况下的效果。结果表明，我们的方法可以减少强偏好情况下的属性偏好，并且在中等偏好情况下可以保持现有方法的表现。<details>
<summary>Abstract</summary>
Ensuring a neural network is not relying on protected attributes (e.g., race, sex, age) for prediction is crucial in advancing fair and trustworthy AI. While several promising methods for removing attribute bias in neural networks have been proposed, their limitations remain under-explored. To that end, in this work, we mathematically and empirically reveal the limitation of existing attribute bias removal methods in presence of strong bias and propose a new method that can mitigate this limitation. Specifically, we first derive a general non-vacuous information-theoretical upper bound on the performance of any attribute bias removal method in terms of the bias strength, revealing that they are effective only when the inherent bias in the dataset is relatively weak. Next, we derive a necessary condition for the existence of any method that can remove attribute bias regardless of the bias strength. Inspired by this condition, we then propose a new method using an adversarial objective that directly filters out protected attributes in the input space while maximally preserving all other attributes, without requiring any specific target label. The proposed method achieves state-of-the-art performance in both strong and moderate bias settings. We provide extensive experiments on synthetic, image, and census datasets, to verify the derived theoretical bound and its consequences in practice, and evaluate the effectiveness of the proposed method in removing strong attribute bias.
</details>
<details>
<summary>摘要</summary>
We first derive an upper bound on the performance of any attribute bias removal method in terms of bias strength, showing that they are effective only when the inherent bias in the dataset is relatively weak. We then derive a necessary condition for the existence of any method that can remove attribute bias regardless of strength. Inspired by this condition, we propose a new method using an adversarial objective that directly filters out protected attributes in the input space while preserving all other attributes, without requiring any specific target label.The proposed method achieves state-of-the-art performance in both strong and moderate bias settings. We provide extensive experiments on synthetic, image, and census datasets to verify the derived theoretical bound and its consequences in practice, and evaluate the effectiveness of the proposed method in removing strong attribute bias.
</details></li>
</ul>
<hr>
<h2 id="How-to-Do-Machine-Learning-with-Small-Data-–-A-Review-from-an-Industrial-Perspective"><a href="#How-to-Do-Machine-Learning-with-Small-Data-–-A-Review-from-an-Industrial-Perspective" class="headerlink" title="How to Do Machine Learning with Small Data? – A Review from an Industrial Perspective"></a>How to Do Machine Learning with Small Data? – A Review from an Industrial Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07126">http://arxiv.org/abs/2311.07126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivan Kraljevski, Yong Chul Ju, Dmitrij Ivanov, Constanze Tschöpe, Matthias Wolff</li>
<li>for: 本研究旨在探讨机器学习在小数据情况下的应用和工程应用。</li>
<li>methods: 本文提出了一种机器学习 formalism，并对小数据的定义、工业应用和机器学习方法进行了简要的介绍。</li>
<li>results: 本文介绍了五种机器学习小数据工业应用中的挑战，并对域表示和数据收集的考虑进行了概述。<details>
<summary>Abstract</summary>
Artificial intelligence experienced a technological breakthrough in science, industry, and everyday life in the recent few decades. The advancements can be credited to the ever-increasing availability and miniaturization of computational resources that resulted in exponential data growth. However, because of the insufficient amount of data in some cases, employing machine learning in solving complex tasks is not straightforward or even possible. As a result, machine learning with small data experiences rising importance in data science and application in several fields. The authors focus on interpreting the general term of "small data" and their engineering and industrial application role. They give a brief overview of the most important industrial applications of machine learning and small data. Small data is defined in terms of various characteristics compared to big data, and a machine learning formalism was introduced. Five critical challenges of machine learning with small data in industrial applications are presented: unlabeled data, imbalanced data, missing data, insufficient data, and rare events. Based on those definitions, an overview of the considerations in domain representation and data acquisition is given along with a taxonomy of machine learning approaches in the context of small data.
</details>
<details>
<summary>摘要</summary>
人工智能在科学、业务和日常生活中经历了技术突破的几十年。这些进步归功于计算资源的急剧增加和缩小，导致数据的快速增长。然而，由于一些情况下数据的缺乏，直接或者even possible的使用机器学习解决复杂任务不是一件容易的事情。因此，机器学习小数据在数据科学和应用领域中升起了重要性。作者将关注“小数据”的通用定义，以及其在工程和产业应用中的作用。他们给出了关于机器学习和小数据的重要工业应用的简要概述。小数据在big data的定义下被定义为具有以下特征：小数据量、高度归一化、缺失数据、缺乏数据和罕见事件。作者还提出了五个关键的机器学习小数据在工业应用中的挑战：无标签数据、偏极数据、缺失数据、缺乏数据和罕见事件。根据这些定义，作者还给出了域表示和数据获取的考虑因素，以及机器学习小数据的稍等分类。
</details></li>
</ul>
<hr>
<h2 id="Novel-models-for-fatigue-life-prediction-under-wideband-random-loads-based-on-machine-learning"><a href="#Novel-models-for-fatigue-life-prediction-under-wideband-random-loads-based-on-machine-learning" class="headerlink" title="Novel models for fatigue life prediction under wideband random loads based on machine learning"></a>Novel models for fatigue life prediction under wideband random loads based on machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07114">http://arxiv.org/abs/2311.07114</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Sun, Yuanying Qiu, Jing Li, Jin Bai, Ming Peng</li>
<li>for: 预测轧钢质量寿命</li>
<li>methods: 使用三种机器学习模型：支持向量机（SVM）、泊松过程回归（GPR）和人工神经网络（ANN）建立三种宽频质量寿命预测模型，并使用多个频率谱样本和各种质量相关参数提高模型的通用能力。</li>
<li>results: 对比传统频率域模型，新开发的机器学习模型具有更高的预测精度，其中人工神经网络模型在三种机器学习模型中表现最佳。<details>
<summary>Abstract</summary>
Machine learning as a data-driven solution has been widely applied in the field of fatigue lifetime prediction. In this paper, three models for wideband fatigue life prediction are built based on three machine learning models, i.e. support vector machine (SVM), Gaussian process regression (GPR) and artificial neural network (ANN). The generalization ability of the models is enhanced by employing numerous power spectra samples with different bandwidth parameters and a variety of material properties related to fatigue life. Sufficient Monte Carlo numerical simulations demonstrate that the newly developed machine learning models are superior to the traditional frequency-domain models in terms of life prediction accuracy and the ANN model has the best overall performance among the three developed machine learning models.
</details>
<details>
<summary>摘要</summary>
机器学习作为数据驱动解决方案广泛应用于软件衰弱生命预测领域。本文提出了基于三种机器学习模型（支持向量机器、泊松过程回归和人工神经网络）构建三种宽带衰弱生命预测模型，以提高模型通用性。通过使用不同带宽参数和多种相关衰弱生命物理性能的数据采样，提高模型的泛化能力。我们通过充分的蒙特卡洛仿真计算表明，新发展的机器学习模型在生命预测精度方面比传统频率域模型有所提高，而人工神经网络模型在三种机器学习模型中显示出最佳总表现。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Purification-for-Data-Driven-Power-System-Event-Classifiers-with-Diffusion-Models"><a href="#Adversarial-Purification-for-Data-Driven-Power-System-Event-Classifiers-with-Diffusion-Models" class="headerlink" title="Adversarial Purification for Data-Driven Power System Event Classifiers with Diffusion Models"></a>Adversarial Purification for Data-Driven Power System Event Classifiers with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07110">http://arxiv.org/abs/2311.07110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanbin Cheng, Koji Yamashita, Jim Follum, Nanpeng Yu</li>
<li>for: 本研究旨在提出一种有效的防御策略，以防止针对机器学习基于PMU数据的电力系统事件分类器的恶意攻击。</li>
<li>methods: 该方法包括两步：首先，在PMU数据中添加噪声；其次，使用预训练的神经网络来消除添加的噪声，同时 removelinear perturbations introduced by adversarial attacks。</li>
<li>results: 实验结果表明，提议的扩散模型基于的防御策略可以增强事件分类器在恶意攻击下的准确率，同时满足实时操作的需求。另外，理论分析表明，该方法可以减少PMU数据的欧几何距离，从而减少恶意攻击的影响。<details>
<summary>Abstract</summary>
The global deployment of the phasor measurement units (PMUs) enables real-time monitoring of the power system, which has stimulated considerable research into machine learning-based models for event detection and classification. However, recent studies reveal that machine learning-based methods are vulnerable to adversarial attacks, which can fool the event classifiers by adding small perturbations to the raw PMU data. To mitigate the threats posed by adversarial attacks, research on defense strategies is urgently needed. This paper proposes an effective adversarial purification method based on the diffusion model to counter adversarial attacks on the machine learning-based power system event classifier. The proposed method includes two steps: injecting noise into the PMU data; and utilizing a pre-trained neural network to eliminate the added noise while simultaneously removing perturbations introduced by the adversarial attacks. The proposed adversarial purification method significantly increases the accuracy of the event classifier under adversarial attacks while satisfying the requirements of real-time operations. In addition, the theoretical analysis reveals that the proposed diffusion model-based adversarial purification method decreases the distance between the original and compromised PMU data, which reduces the impacts of adversarial attacks. The empirical results on a large-scale real-world PMU dataset validate the effectiveness and computational efficiency of the proposed adversarial purification method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exposition-on-over-squashing-problem-on-GNNs-Current-Methods-Benchmarks-and-Challenges"><a href="#Exposition-on-over-squashing-problem-on-GNNs-Current-Methods-Benchmarks-and-Challenges" class="headerlink" title="Exposition on over-squashing problem on GNNs: Current Methods, Benchmarks and Challenges"></a>Exposition on over-squashing problem on GNNs: Current Methods, Benchmarks and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07073">http://arxiv.org/abs/2311.07073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dai Shi, Andi Han, Lequan Lin, Yi Guo, Junbin Gao</li>
<li>for: 本研究旨在探讨Graph-based message-passing neural networks (MPNNs)中的Over-squashing (OSQ)问题，包括OSQ的不同形式、addressing OSQ的方法和与表达能力之间的关系。</li>
<li>methods: 本研究总结了现有literature中对OSQ问题的不同形式和addressing OSQ的方法，包括三类方法：1) node feature transformation, 2) message passing scheme design, 3) graph structure design。</li>
<li>results: 本研究评估了现有works中对OSQ问题的解决方案，包括employned empirical methods和computational complexities。此外，本研究还提出了一些未解决的问题，以及可能的解决方案。<details>
<summary>Abstract</summary>
Graph-based message-passing neural networks (MPNNs) have achieved remarkable success in both node and graph-level learning tasks. However, several identified problems, including over-smoothing (OSM), limited expressive power, and over-squashing (OSQ), still limit the performance of MPNNs. In particular, OSQ serves as the latest identified problem, where MPNNs gradually lose their learning accuracy when long-range dependencies between graph nodes are required. In this work, we provide an exposition on the OSQ problem by summarizing different formulations of OSQ from current literature, as well as the three different categories of approaches for addressing the OSQ problem. In addition, we also discuss the alignment between OSQ and expressive power and the trade-off between OSQ and OSM. Furthermore, we summarize the empirical methods leveraged from existing works to verify the efficiency of OSQ mitigation approaches, with illustrations of their computational complexities. Lastly, we list some open questions that are of interest for further exploration of the OSQ problem along with potential directions from the best of our knowledge.
</details>
<details>
<summary>摘要</summary>
GRAPH-BASED MESSAGE-PASSING NEURAL NETWORKS (MPNNs) 已经取得了优异的成绩在节点和图结构学习任务中。然而，一些已知的问题，包括过滤（OSM）、有限表达力和过滤（OSQ），仍然限制 MPNNs 的表现。特别是 OSQ，最新的已知问题，MPNNs 在需要图节点之间长距离关系时逐渐失去学习精度。在这个工作中，我们提供了 OSQ 问题的概述，包括现有文献中不同形式的 OSQ 问题和Addressing OSQ 问题的三种类型方法。此外，我们还讨论了 OSQ 与表达力之间的对应关系以及 OSQ 和 OSM 之间的贸易。此外，我们还总结了现有工作中用于验证 OSQ 缓解方法的实际方法，包括其计算复杂性。最后，我们列出了一些未解决的问题，以及可能的解决方案。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="To-Transformers-and-Beyond-Large-Language-Models-for-the-Genome"><a href="#To-Transformers-and-Beyond-Large-Language-Models-for-the-Genome" class="headerlink" title="To Transformers and Beyond: Large Language Models for the Genome"></a>To Transformers and Beyond: Large Language Models for the Genome</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07621">http://arxiv.org/abs/2311.07621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Micaela E. Consens, Cameron Dufault, Michael Wainberg, Duncan Forster, Mehran Karimzadeh, Hani Goodarzi, Fabian J. Theis, Alan Moses, Bo Wang</li>
<li>for: 本文主要是为了介绍Large Language Models（LLMs）在 genomics 中的应用，以及这些模型在计算生物学和计算机科学领域的转型作用。</li>
<li>methods: 本文主要采用 transformer 架构和其他 LLMs 进行 genomics 数据的分析和模型化。</li>
<li>results: 本文提出了一种基于 transformer 架构的基因组分析方法，并评估了这种方法在不同的数据集上的性能。Here’s the summary in English:</li>
<li>for: The paper primarily focuses on the application of Large Language Models (LLMs) in genomics and their transformative role in computational biology and computer science.</li>
<li>methods: The paper mainly uses transformer architecture and other LLMs for genomic data analysis and modeling.</li>
<li>results: The paper proposes a gene expression analysis method based on the transformer architecture and evaluates its performance on different data sets.<details>
<summary>Abstract</summary>
In the rapidly evolving landscape of genomics, deep learning has emerged as a useful tool for tackling complex computational challenges. This review focuses on the transformative role of Large Language Models (LLMs), which are mostly based on the transformer architecture, in genomics. Building on the foundation of traditional convolutional neural networks and recurrent neural networks, we explore both the strengths and limitations of transformers and other LLMs for genomics. Additionally, we contemplate the future of genomic modeling beyond the transformer architecture based on current trends in research. The paper aims to serve as a guide for computational biologists and computer scientists interested in LLMs for genomic data. We hope the paper can also serve as an educational introduction and discussion for biologists to a fundamental shift in how we will be analyzing genomic data in the future.
</details>
<details>
<summary>摘要</summary>
在高速发展的基因组学领域中，深度学习已经成为解决复杂计算挑战的有用工具。本文集中关注基因组学中的大语言模型（LLMs），主要基于转换器架构。传统的卷积神经网络和循环神经网络的基础上，我们探讨了转换器和其他 LLMS 在基因组学方面的优势和局限性。此外，我们还考虑了未来基因组数据分析的发展趋势，以及在研究中使用 LLMs 的可能性。本文旨在为计算生物学家和计算机科学家提供 LLMs 在基因组数据分析方面的指南，同时也为生物学家提供一种基因组数据分析的基本变革。
</details></li>
</ul>
<hr>
<h2 id="A-PAC-Bayesian-Perspective-on-the-Interpolating-Information-Criterion"><a href="#A-PAC-Bayesian-Perspective-on-the-Interpolating-Information-Criterion" class="headerlink" title="A PAC-Bayesian Perspective on the Interpolating Information Criterion"></a>A PAC-Bayesian Perspective on the Interpolating Information Criterion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07013">http://arxiv.org/abs/2311.07013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liam Hodgkinson, Chris van der Heide, Robert Salomone, Fred Roosta, Michael W. Mahoney</li>
<li>for: 本文旨在解决深度学习中的理论实践差距问题，即理论不能提供实践中有用的指导。</li>
<li>methods: 本文使用Interpolating Information Criterion（IIC）来研究过参数化模型的性能。</li>
<li>results: 根据IIC， authors得出了一个PAC-Bayes bound，可以描述拥有多参数化模型在 interpolating  régime中的性能。从这个 bound 中， authors可以量化不同因素对模型的泛化性能产生的影响，包括模型、优化器和参数初始化方案的组合；Empirical Neural Tangent Kernel 的 спектrum；损失函数的曲线形状；和数据中的噪声。<details>
<summary>Abstract</summary>
Deep learning is renowned for its theory-practice gap, whereby principled theory typically fails to provide much beneficial guidance for implementation in practice. This has been highlighted recently by the benign overfitting phenomenon: when neural networks become sufficiently large to interpolate the dataset perfectly, model performance appears to improve with increasing model size, in apparent contradiction with the well-known bias-variance tradeoff. While such phenomena have proven challenging to theoretically study for general models, the recently proposed Interpolating Information Criterion (IIC) provides a valuable theoretical framework to examine performance for overparameterized models. Using the IIC, a PAC-Bayes bound is obtained for a general class of models, characterizing factors which influence generalization performance in the interpolating regime. From the provided bound, we quantify how the test error for overparameterized models achieving effectively zero training error depends on the quality of the implicit regularization imposed by e.g. the combination of model, optimizer, and parameter-initialization scheme; the spectrum of the empirical neural tangent kernel; curvature of the loss landscape; and noise present in the data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.LG_2023_11_13/" data-id="clp89doi700uqi788gh8j7cih" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/eess.SP_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T08:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/eess.SP_2023_11_13/">eess.SP - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Near-Field-Integrated-Sensing-Positioning-and-Communication-A-Downlink-and-Uplink-Framework"><a href="#Near-Field-Integrated-Sensing-Positioning-and-Communication-A-Downlink-and-Uplink-Framework" class="headerlink" title="Near-Field Integrated Sensing, Positioning, and Communication: A Downlink and Uplink Framework"></a>Near-Field Integrated Sensing, Positioning, and Communication: A Downlink and Uplink Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07722">http://arxiv.org/abs/2311.07722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochen Li, Zhaolin Wang, Xidong Mu, Zhiwen Pan, Yuanwei Liu</li>
<li>For: 这种Integrated Sensing, Positioning, and Communication (ISPAC)框架可以同时为多个通信用户提供服务，并且实现目标探测和定位。* Methods: 该框架使用了一种新的双数组结构，其中一个小规模的协助传输器（AT）附加到了一个大规模的主传输器（MT）以使通信系统具备探测和定位能力。* Results: 研究人员通过提出的框架，首次 derivated了联合角度和距离Cramér-Rao bound（CRB）。然后，CRB是在下降链和上升链ISPAC场景中进行最小化。数值结果表明：1）提出的ISPAC系统可以仅通过单个BS和有限频率来实现目标的探测和定位；2）折衔式混合分析数字ISPAC方法可以与完全数字ISPAC方法匹配或超越其在无需强制通信率要求下的位置准确性。<details>
<summary>Abstract</summary>
A near-field integrated sensing, positioning, and communication (ISPAC) framework is proposed, where a base station (BS) simultaneously serves multiple communication users and carries out target sensing and positioning. A novel double-array structure is proposed to enable the near-field ISPAC at the BS. Specifically, a small-scale assisting transceiver (AT) is attached to the large-scale main transceiver (MT) to empower the communication system with the ability of sensing and positioning. Based on the proposed framework, the joint angle and distance Cram\'er-Rao bound (CRB) is first derived. Then, the CRB is minimized subject to the minimum communication rate requirement in both downlink and uplink ISPAC scenarios: 1) For downlink ISPAC, a downlink target positioning algorithm is proposed and a penalty dual decomposition (PDD)-based double-loop algorithm is developed to tackle the non-convex optimization problem. 2) For uplink ISPAC, an uplink target positioning algorithm is proposed and an efficient alternating optimization algorithm is conceived to solve the non-convex CRB minimization problem with coupled user communication and target probing design. Both proposed optimization algorithms can converge to a stationary point of the CRB minimization problem. Numerical results show that: 1) The proposed ISPAC system can locate the target in both angle and distance domains merely relying on single BS and limited bandwidths; and 2) the positioning performance achieved by the hybrid-analog-and-digital ISPAC approaches that achieved by fully digital ISPAC when the communication rate requirement is not stringent.
</details>
<details>
<summary>摘要</summary>
提出一种靠近场 интеGRATED SENSING、定位和通信（ISPAC）框架，其中基站（BS）同时服务多个通信用户，并同时进行目标探测和定位。提议了一种双array结构，以启用靠近场 ISPAC。具体来说，一个小规模协助传输器（AT）附加到大规模主传输器（MT）以允许通信系统具备探测和定位能力。基于该框架，首先 derivation 了共振矩阵（CRB）的最小值。然后，CRB 被最小化，并且需要在下行和上行 ISPAC 场景中保持最低通信率要求。具体来说，对于下行 ISPAC，我们提出了一种下行目标定位算法，并使用 penalty dual decomposition（PDD）-based double-loop algorithm 来解决非对称优化问题。对于上行 ISPAC，我们提出了一种上行目标定位算法，并开发了一种高效的 alternate optimization algorithm 来解决非对称CRB最小化问题。两种提出的优化算法都可以 converge 到CRB最小化问题的站点。数值结果显示，提出的 ISPAC 系统可以通过唯一BS和有限频率来定位目标，并且在角度和距离两个域中都可以进行定位。此外，在 Fully digital ISPAC 方法不可能达到的情况下，我们的 hybrid-analog-and-digital ISPAC 方法可以实现更高的定位性能。
</details></li>
</ul>
<hr>
<h2 id="Vertiport-Navigation-Requirements-and-Multisensor-Architecture-Considerations-for-Urban-Air-Mobility"><a href="#Vertiport-Navigation-Requirements-and-Multisensor-Architecture-Considerations-for-Urban-Air-Mobility" class="headerlink" title="Vertiport Navigation Requirements and Multisensor Architecture Considerations for Urban Air Mobility"></a>Vertiport Navigation Requirements and Multisensor Architecture Considerations for Urban Air Mobility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07487">http://arxiv.org/abs/2311.07487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Garcia Crespillo, Chen Zhu, Maximilian Simonetti, Daniel Gerbeth, Young-Hee Lee, Wenhan Hao</li>
<li>for: The paper is written for discussing the navigation technologies required for future safe operation of drones in urban environments, specifically for precision approach operations based on vertiport designs.</li>
<li>methods: The paper proposes a possible multisensor navigation architecture solution to support these operations, which includes an overview of the challenges of each subsystem and initial proof of concept based on flight trials.</li>
<li>results: The paper presents initial proof of concept for some navigation sensor subsystems based on flight trials performed during the German Aerospace Center (DLR) project HorizonUAM.<details>
<summary>Abstract</summary>
Communication, Navigation and Surveillance (CNS) technologies are key enablers for future safe operation of drones in urban environments. However, the design of navigation technologies for these new applications is more challenging compared to e.g., civil aviation. On the one hand, the use cases and operations in urban environments are expected to have stringent requirements in terms of accuracy, integrity, continuity and availability. On the other hand, airborne sensors may not be based on high-quality equipment as in civil aviation and solutions need to rely on tighter multisensor solutions, whose safety is difficult to assess. In this work, we first provide some initial navigation requirements related to precision approach operations based on recently proposed vertiport designs. Then, we provide an overview of a possible multisensor navigation architecture solution able to support these types of operations and we comment on the challenges of each of the subsystems. Finally, initial proof of concept for some navigation sensor subsystems is presented based on flight trials performed during the German Aerospace Center (DLR) project HorizonUAM.
</details>
<details>
<summary>摘要</summary>
通信、导航和监测（CNS）技术是未来无人机在都市环境中安全运行的关键促进者。然而，为了满足这些新应用程序的设计，与民航相比， Navigation technologies 的设计更加具有挑战性。一方面，城市环境下的用例和操作具有高度的准确性、完整性、可用性和一致性要求。另一方面，空中探测仪可能不是民航使用的高质量设备，解决方案需要依赖更紧凑的多感器解决方案，其安全性困难评估。在这种情况下，我们首先提供了一些precision approach操作相关的初始导航要求，然后提供了一种可能的多感器导航架构解决方案，并评估了每个子系统的挑战。最后，对一些导航感知子系统的初步证明是基于德国航空中心（DLR）项目HorizonUAM期间进行的飞行试验。
</details></li>
</ul>
<hr>
<h2 id="Near-Field-Sparse-Channel-Estimation-for-Extremely-Large-Scale-RIS-Aided-Wireless-Communications"><a href="#Near-Field-Sparse-Channel-Estimation-for-Extremely-Large-Scale-RIS-Aided-Wireless-Communications" class="headerlink" title="Near-Field Sparse Channel Estimation for Extremely Large-Scale RIS-Aided Wireless Communications"></a>Near-Field Sparse Channel Estimation for Extremely Large-Scale RIS-Aided Wireless Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07249">http://arxiv.org/abs/2311.07249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixing Tang, Yuanbin Chen, Ying Wang, Tianqi Mao, Qingqing Wu, Marco Di Renzo, Lajos Hanzo</li>
<li>for: 该研究旨在提高大规模智能反射surface（XL-RIS）的通信系统中的频率响应。</li>
<li>methods: 该研究使用了采集频率响应的两个阶段Channel estimation方法，包括预处理阶段和Channel estimation阶段。</li>
<li>results: 研究结果表明，该两个阶段Channel estimation方法可以减少频率响应的不确定性，并提高通信系统的性能。<details>
<summary>Abstract</summary>
A significant increase in the number of reconfigurable intelligent surface (RIS) elements results in a spherical wavefront in the near field of extremely large-scale RIS (XL-RIS). Although the channel matrix of the cascaded two-hop link may become sparse in the polar-domain representation, their accurate estimation of these polar-domain parameters cannot be readily guaranteed. To tackle this challenge, we exploit the sparsity inherent in the cascaded channel. To elaborate, we first estimate the significant path-angles and distances corresponding to the common paths between the BS and the XL-RIS. Then, the individual path parameters associated with different users are recovered. This results in a two-stage channel estimation scheme, in which distinct learning-based networks are used for channel training at each stage. More explicitly, in stage I, a denoising convolutional neural network (DnCNN) is employed for treating the grid mismatches as noise to determine the true grid index of the angles and distances. By contrast, an iterative shrinkage thresholding algorithm (ISTA) based network is proposed for adaptively adjusting the column coherence of the dictionary matrix in stage II. Finally, our simulation results demonstrate that the proposed two-stage learning-based channel estimation outperforms the state-of-the-art benchmarks.
</details>
<details>
<summary>摘要</summary>
“一个重要的增加在弹性智能表面（RIS）元素数量上，导致在EXTREMELY LARGE-SCALE RIS（XL-RIS）的近场内发射圆锥波front。即使这个通道矩阵在对应的两个统计步骤中可能会受到简化，但它们的精确估计仍然不能得到保证。为了解决这个挑战，我们利用了这个简化的通道矩阵中的组合簇统计特性。具体来说，我们首先估计XL-RIS和BS之间的共同路径角度和距离。然后，对不同的用户而言，个别的路径参数被恢复。这结构成了一个两阶段的通道估计方案，在每个阶段中使用不同的学习型网络进行通道训练。更详细地说，在第一阶段中，我们使用了一个检测网络（DnCNN）来处理网格不一致的问题，以确定真正的网格指标。而在第二阶段中，我们提出了一个调整Column coherence的估计网络（ISTA），以适应不同的用户。最后，我们的实验结果显示，我们的两阶段学习型通道估计方案比STATE-OF-THE-ART的参考模型更高效。”
</details></li>
</ul>
<hr>
<h2 id="Time-Frequency-Localization-Characteristics-of-the-Delay-Doppler-Plane-Orthogonal-Pulse"><a href="#Time-Frequency-Localization-Characteristics-of-the-Delay-Doppler-Plane-Orthogonal-Pulse" class="headerlink" title="Time-Frequency Localization Characteristics of the Delay-Doppler Plane Orthogonal Pulse"></a>Time-Frequency Localization Characteristics of the Delay-Doppler Plane Orthogonal Pulse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07238">http://arxiv.org/abs/2311.07238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akram Shafie, Jinhong Yuan, Nan Yang, Hai Lin</li>
<li>for: 这个论文旨在探讨快速移动场景下可靠通信的新方案——orthogonal delay-Doppler（DD）分 multiplexing（ODDM）模ulation。</li>
<li>methods: 作者研究了快速变化频率（TF）本地化特性，这个特性可以衡量干扰信号在TF域中能量的分布情况。</li>
<li>results: 作者发现，使用这种新的干扰信号模ulation可以利用时间和频率多样性，提高探测精度。此外，作者还提出了一种新的干扰信号设计方法，并通过数值计算证明了这种设计的能量分布在TF域中的步骤增长。<details>
<summary>Abstract</summary>
The orthogonal delay-Doppler (DD) division multiplexing (ODDM) modulation has recently been proposed as a promising solution for ensuring reliable communications in high mobility scenarios. In this work, we investigate the time-frequency (TF) localization characteristics of the DD plane orthogonal pulse (DDOP), which is the prototype pulse of ODDM modulation. The TF localization characteristics examine how concentrated or spread out the energy of a pulse is in the joint TF domain. We first derive the TF localization metric, TF area (TFA), for the DDOP. Based on this result, we provide insights into the energy spread of the DDOP in the joint TF domain. Then, we delve into the potential advantages of the DDOP due to its energy spread, particularly in terms of leveraging both time and frequency diversities, and enabling high-resolution sensing. Furthermore, we determine the TFA for the recently proposed generalized design of the DDOP. Finally, we validate our analysis based on numerical results and show that the energy spread for the generalized design of the DDOP in the joint TF domain exhibits a step-wise increase as the duration of sub-pulses increases.
</details>
<details>
<summary>摘要</summary>
高速移动场景中可靠通信的新方案是正交延时Doppler分 multiplexing（ODDM）调制。在这个工作中，我们调查了延时频率（TF）本地化特性的DD平面正交普朗（DDOP）。TF本地化特性检查普朗在TF域的能量集中程度。我们首先 derive TF本地化度量（TFA）的DDOP。基于这个结果，我们提供了DDOP在TF域的能量散布的深入理解。然后，我们探讨了DDOP的能量散布在TF域的优点，尤其是利用时间和频率多样性，并实现高分辨率探测。然后，我们确定了Generalized Design of DDOP的TFA。最后，我们 validate our analysis based on numerical results and show that the energy spread for the generalized design of the DDOP in the joint TF domain exhibits a step-wise increase as the duration of sub-pulses increases.
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Coherent-Multistatic-Imaging-and-Phase-Synchronization-in-Networked-Sensing"><a href="#Cooperative-Coherent-Multistatic-Imaging-and-Phase-Synchronization-in-Networked-Sensing" class="headerlink" title="Cooperative Coherent Multistatic Imaging and Phase Synchronization in Networked Sensing"></a>Cooperative Coherent Multistatic Imaging and Phase Synchronization in Networked Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07212">http://arxiv.org/abs/2311.07212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dario Tagliaferri, Marco Manzoni, Marouan Mizmizi, Stefano Tebaldini, Andrea Virgilio Monti-Guarnieri, Claudio Maria Prati, Umberto Spagnolini</li>
<li>for: 这篇论文探讨了车辆雷达网络中的合作协同成像技术，以提高探测脆弱目标的可靠性和分辨率。</li>
<li>methods: 论文使用了多个雷达搭载的车辆之间的合作，以提高集体探测Capability和检测脆弱目标的能力。</li>
<li>results: 论文表明，通过合作协同成像技术，可以提高探测脆弱目标的可靠性和分辨率，并通过实验示例表明，两辆车辆之间的合作可以检测到静止人体的脚部，并且需要高度准确的时钟同步和探测器的位势准确性来实现。<details>
<summary>Abstract</summary>
Coherent multistatic radio imaging represents a pivotal opportunity for forthcoming wireless networks, which involves distributed nodes cooperating to achieve accurate sensing resolution and robustness. This paper delves into cooperative coherent imaging for vehicular radar networks. Herein, multiple radar-equipped vehicles cooperate to improve collective sensing capabilities and address the fundamental issue of distinguishing weak targets in close proximity to strong ones, a critical challenge for vulnerable road users protection. We prove the significant benefits of cooperative coherent imaging in the considered automotive scenario in terms of both probability of correct detection, evaluated considering several system parameters, as well as resolution capabilities, showcased by a dedicated experimental campaign wherein the collaboration between two vehicles enables the detection of the legs of a pedestrian close to a parked car. Moreover, as \textit{coherent} processing of several sensors' data requires very tight accuracy on clock synchronization and sensor's positioning -- referred to as \textit{phase synchronization} -- (such that to predict sensor-target distances up to a fraction of the carrier wavelength), we present a general three-step cooperative multistatic phase synchronization procedure, detailing the required information exchange among vehicles in the specific automotive radar context and assessing its feasibility and performance by hybrid Cram\'er-Rao bound.
</details>
<details>
<summary>摘要</summary>
多 static 无线电影像表示未来无线网络的重要机会，即分布式节点合作以实现精确感知和鲁棒性。本文探讨了自动车radar网络中的合作协同准确影像。在这种情况下，多个 радио设备Equipped with vehicles cooperate to improve collective sensing capabilities and address the fundamental issue of distinguishing weak targets in close proximity to strong ones, a critical challenge for vulnerable road users protection. We prove the significant benefits of cooperative coherent imaging in the considered automotive scenario in terms of both probability of correct detection, evaluated considering several system parameters, as well as resolution capabilities, showcased by a dedicated experimental campaign wherein the collaboration between two vehicles enables the detection of the legs of a pedestrian close to a parked car. Moreover, as coherent processing of several sensors' data requires very tight accuracy on clock synchronization and sensor's positioning -- referred to as phase synchronization -- (such that to predict sensor-target distances up to a fraction of the carrier wavelength), we present a general three-step cooperative multistatic phase synchronization procedure, detailing the required information exchange among vehicles in the specific automotive radar context and assessing its feasibility and performance by hybrid Cramér-Rao bound.
</details></li>
</ul>
<hr>
<h2 id="Joint-Computation-and-Communication-Resource-Optimization-for-Beyond-Diagonal-UAV-IRS-Empowered-MEC-Networks"><a href="#Joint-Computation-and-Communication-Resource-Optimization-for-Beyond-Diagonal-UAV-IRS-Empowered-MEC-Networks" class="headerlink" title="Joint Computation and Communication Resource Optimization for Beyond Diagonal UAV-IRS Empowered MEC Networks"></a>Joint Computation and Communication Resource Optimization for Beyond Diagonal UAV-IRS Empowered MEC Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07199">http://arxiv.org/abs/2311.07199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asad Mahmood, Thang X. Vu, Wali Ullah Khan, Symeon Chatzinotas, Björn Ottersten</li>
<li>for: 这个论文是为了解决 beyond 5G (B5G) 网络中的覆盖、容量和能源效率等问题，通过实现智能可 configurable 表面 (IRS) 的全面发挥。</li>
<li>methods: 这个论文使用了 Beyond Diagonal IRS (BD-IRS) 技术，它是一种可以超越传统的 diagonally  phase shift matrix 的新型 IRS 架构，具有更好的传输性能和可控性。</li>
<li>results: 这个论文的结果显示，BD-IRS 可以实现更好的系统延迟和数据率，比传统的 diagonally  IRS 系统更好。具体来说，该论文的结果显示，BD-IRS 可以 reduc 系统延迟 by 7.25%，并提高数据率 by 17.77%。<details>
<summary>Abstract</summary>
Intelligent Reconfigurable Surfaces (IRS) are crucial for overcoming challenges in coverage, capacity, and energy efficiency beyond 5G (B5G). The classical IRS architecture, employing a diagonal phase shift matrix, hampers effective passive beamforming manipulation. To unlock its full potential, Beyond Diagonal IRS (BD-IRS or IRS 2.0) emerges as a revolutionary member, transcending limitations of the diagonal IRS. This paper introduces BD-IRS deployed on unmanned aerial vehicles (BD-IRS-UAV) in Mobile Edge Computing (MEC) networks. Here, users offload tasks to the MEC server due to limited resources and finite battery life. The objective is to minimize worst-case system latency by optimizing BD-IRS-UAV deployment, local and edge computational resource allocation, task segmentation, power allocation, and received beamforming vector. The resulting non-convex/non-linear NP-hard optimization problem is intricate, prompting division into two subproblems: 1) BD-IRS-UAV deployment, local and edge computational resources, and task segmentation, and 2) power allocation, received beamforming, and phase shift design. Standard optimization methods efficiently solve each subproblem. Monte Carlo simulations provide numerical results, comparing the proposed BD-IRS-UAV-enabled MEC optimization framework with various benchmarks. Performance evaluations include comparisons with fully-connected and group-connected architectures, single-connected diagonal IRS, and binary offloading, edge computation, fixed computation, and local computation frameworks. Results show a 7.25% lower latency and a 17.77% improvement in data rate with BD-IRS compared to conventional diagonal IRS systems, demonstrating the effectiveness of the proposed optimization framework.
</details>
<details>
<summary>摘要</summary>
智能可重新配置表面（IRS）是5G以外的挑战的关键，包括覆盖率、容量和能源效率。传统的IRS架构使用对角相位Matrix，导致有效的被动扫描干扰不优化。为了解锁其潜力，Beyond Diagonal IRS（BD-IRS）在Mobile Edge Computing（MEC）网络中出现，这是一种革命性的IRS成员，超越传统的IRS架构。本文介绍BD-IRS在无人航空器（BD-IRS-UAV）上的部署，用户因有限的资源和电池寿命而将任务下载到MEC服务器。目标是最小化系统延迟，通过BD-IRS-UAV部署、本地和边缘计算资源分配、任务分割、电力分配和接收扫描向量优化。这是一个非对称/非线性NP困难优化问题，我们将其分解为两个子问题：1）BD-IRS-UAV部署、本地和边缘计算资源和任务分割，2）电力分配、接收扫描和相位偏移设计。标准优化方法可以有效解决每个子问题。Monte Carlo仿真实现了数字结果，并与各种参考模型进行比较。性能评价包括与完全连接和分组连接架构、单连接对角IRS、 binary offloading、边缘计算、固定计算和本地计算框架进行比较。结果显示BD-IRS相比传统对角IRS系统，提供了7.25%的延迟和17.77%的数据速率提升，这说明了我们提posed的优化框架的有效性。
</details></li>
</ul>
<hr>
<h2 id="CASTER-A-Computer-Vision-Assisted-Wireless-Channel-Simulator-for-Gesture-Recognition"><a href="#CASTER-A-Computer-Vision-Assisted-Wireless-Channel-Simulator-for-Gesture-Recognition" class="headerlink" title="CASTER: A Computer-Vision-Assisted Wireless Channel Simulator for Gesture Recognition"></a>CASTER: A Computer-Vision-Assisted Wireless Channel Simulator for Gesture Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07169">http://arxiv.org/abs/2311.07169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rzy0901/testspectrogram">https://github.com/rzy0901/testspectrogram</a></li>
<li>paper_authors: Zhenyu Ren, Guoliang Li, Chenqing Ji, Chao Yu, Shuai Wang, Rui Wang</li>
<li>for:  solves the problem of training dataset acquisition for wireless hand gesture recognition.</li>
<li>methods:  uses computer-vision-assisted simulation method to simulate the training dataset via existing videos, and uses a primitive-based hand model to calculate the channel impulse response of each snapshot.</li>
<li>results:  achieves an average classification accuracy of 90.8% in simulation-to-reality inference.Here’s the full text in Simplified Chinese:</li>
<li>for:  solves the problem of 无线手势识别的训练数据采集.</li>
<li>methods: 使用计算机视觉助动的模拟方法，通过现有视频来生成训练数据，并使用基于原型的手模型来计算每帧图像的通道响应。</li>
<li>results: 实现了90.8%的实验到现实推理精度.<details>
<summary>Abstract</summary>
In this paper, a computer-vision-assisted simulation method is proposed to address the issue of training dataset acquisition for wireless hand gesture recognition. In the existing literature, in order to classify gestures via the wireless channel estimation, massive training samples should be measured in a consistent environment, consuming significant efforts. In the proposed CASTER simulator, however, the training dataset can be simulated via existing videos. Particularly, a gesture is represented by a sequence of snapshots, and the channel impulse response of each snapshot is calculated via tracing the rays scattered off a primitive-based hand model. Moreover, CASTER simulator relies on the existing videos to extract the motion data of gestures. Thus, the massive measurements of wireless channel can be eliminated. The experiments demonstrate a 90.8% average classification accuracy of simulation-to-reality inference.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，一种计算机视觉协助的模拟方法被提出，以解决无线手势识别的训练数据采集问题。现有文献中，为通过无线通道估计识别手势，需要投入巨资，测量大量的适合环境。在提议的 CASTER 模拟器中，然而，训练数据可以通过现有的视频进行模拟。具体来说，每个手势被表示为一个序列的快照，并且每个快照的通道响应被计算通过跟踪一个基于primitive的手模型折射的光线。此外，CASTER 模拟器利用现有的视频提取手势的运动数据，因此可以消除大量的无线通道测量。实验表明，模拟到现实的推断精度达90.8%。
</details></li>
</ul>
<hr>
<h2 id="Communication-Assisted-Sensing-in-6G-Networks"><a href="#Communication-Assisted-Sensing-in-6G-Networks" class="headerlink" title="Communication-Assisted Sensing in 6G Networks"></a>Communication-Assisted Sensing in 6G Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07157">http://arxiv.org/abs/2311.07157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuwang Dong, Fan Liu, Shihang Lu, Yifeng Xiong, Qixun Zhang, Zhiyong Feng</li>
<li>for: 本文旨在探讨 sixth-generation (6G) 感知网络中的整合感知通信系统的协调效果，尤其是在通信协助感知 (CAS) 过程中。</li>
<li>methods: 本文采用了 rate-distortion 理论和源-通道分离定理 (SCT) 来建立 CAS 框架，并对lossy 数据传输中的干扰、编码率和通道容量之间的交互作用进行了全面的理解。</li>
<li>results: 本文提出了两种不同的波形策略：分离的感知通信 (S&amp;C) 波形和双功能波形。其中，分离S&amp;C波形使用了一个简单的一维搜索算法，而双功能波形使用了一种启发式的共声信息优化算法。此外，本文还发现了子空间贸易和水填贸易的存在。最后，通过数字实验 validate 了提议的算法的有效性。<details>
<summary>Abstract</summary>
The exploration of coordination gain achieved through the synergy of sensing and communication (S&C) functions plays a vital role in improving the performance of integrated sensing and communication systems. This paper focuses on the optimal waveform design for communication-assisted sensing (CAS) systems within the context of 6G perceptive networks. In the CAS process, the base station actively senses the targets through device-free wireless sensing and simultaneously transmits the pertinent information to end-users. In our research, we establish a CAS framework grounded in the principles of rate-distortion theory and the source-channel separation theorem (SCT) in lossy data transmission. This framework provides a comprehensive understanding of the interplay between distortion, coding rate, and channel capacity. The purpose of waveform design is to minimize the sensing distortion at the user end while adhering to the SCT and power budget constraints. In the context of target response matrix estimation, we propose two distinct waveform strategies: the separated S&C and dual-functional waveform schemes. In the former strategy, we develop a simple one-dimensional search algorithm, shedding light on a notable power allocation tradeoff between the S&C waveform. In the latter scheme, we conceive a heuristic mutual information optimization algorithm for the general case, alongside a modified gradient projection algorithm tailored for the scenarios with independent sensing sub-channels. Additionally, we identify the presence of both subspace tradeoff and water-filling tradeoff. Finally, we validate the effectiveness of the proposed algorithms through numerical simulations.
</details>
<details>
<summary>摘要</summary>
探索协调效益通过感知和通信（S&C）函数的结合可以提高整合感知和通信系统的性能。这篇论文专注于6G感知网络中的通信协助感知（CAS）系统的优化波动设计。在CAS过程中，基站通过无设备无线感知来活动检测目标，并同时将相关信息传递给终端用户。在我们的研究中，我们建立了基于率误差理论和源通道分离定理（SCT）的CAS框架，提供了感知误差、编码率和通道容量之间的全面理解。波动设计的目的是在用户端 minimize 感知误差，同时遵循SCT和功率预算约束。在目标响应矩阵估计中，我们提出了两种不同的波动策略：分离S&C和双功能波动 schemes。在前一种策略中，我们开发了一种简单的一维搜索算法，探讨了S&C波动力度的电力分配负担tradeoff。在后一种策略中，我们提出了一种基于通信协助感知的通用情况下的优化幂息算法，并与独立感知子频道的情况下的修改版 gradient projection algorithm。此外，我们发现了两种质量贸易：子空间贸易和水填贸易。最后，我们通过数值仿真验证了提出的算法的效果。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-Integrated-Data-and-Energy-Transfer-Assisted-by-Fluid-Antenna-Systems"><a href="#Performance-Analysis-of-Integrated-Data-and-Energy-Transfer-Assisted-by-Fluid-Antenna-Systems" class="headerlink" title="Performance Analysis of Integrated Data and Energy Transfer Assisted by Fluid Antenna Systems"></a>Performance Analysis of Integrated Data and Energy Transfer Assisted by Fluid Antenna Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07134">http://arxiv.org/abs/2311.07134</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Lin, Halvin Yang, Yizhe Zhao, Jie Hu, Kai-Kit Wong</li>
<li>for: 本研究旨在研究一种带有FAMA助け的IDET系统，其中N个接入点（AP）为N个用户设备（UE）提供专用的IDET服务。每个UE都装备有一个流体天线。</li>
<li>methods: 本研究使用时间切换（TS）来分析WDT和WET的性能，包括WDT停机概率、WET停机概率、可靠传输率和平均能量充电量。</li>
<li>results: 研究发现，在优化UE数量和TS比例的情况下，FAMA助け的IDET系统可以实现WDT和WET性能的平衡，并且在相同天线大小情况下，FAMA助け的IDET系统比传统MIMO系统表现更好。<details>
<summary>Abstract</summary>
Fluid antenna multiple access (FAMA) is capable of exploiting the high spatial diversity of wireless channels to mitigate multi-user interference via flexible port switching, which achieves a better performance than traditional multi-input-multi-output (MIMO) systems. Moreover, integrated data and energy transfer (IDET) is able to provide both the wireless data transfer (WDT) and wireless energy transfer (WET) services towards low-power devices. In this paper, a FAMA assisted IDET system is studied, where $N$ access points (APs) provide dedicated IDET services towards $N$ user equipments (UEs). Each UE is equipped with a single fluid antenna. The performance of WDT and WET , \textit{i.e.}, the WDT outage probability, the WET outage probability, the reliable throughput and the average energy harvesting amount, are analysed theoretically by using time switching (TS) between WDT and WET. Numerical results validate our theoretical analysis, which reveals that the number of UEs and TS ratio should be optimized to achieve a trade-off between the WDT and WET performance. Moreover, FAMA assisted IDET achieves a better performance in terms of both WDT and WET than traditional MIMO with the same antenna size.
</details>
<details>
<summary>摘要</summary>
fluid antenna 多元接入 (FAMA) 可以利用无线通信chnnel的高空间多样性来减少多用户干扰，通过flexible port switching实现更好的性能，比traditional 多输入多输出 (MIMO) 系统更好。另外， integral data and energy transfer (IDET) 可以为low-powerdevice提供无线数据传输 (WDT) 和无线能量传输 (WET) 服务。在这篇论文中，我们研究了一种由 N 个Access Points (APs) 提供专门的 IDET 服务，每个用户设备 (UE) 都装备了一个流体天线。我们使用时间switching (TS) 来分析WDT 和 WET 的性能，包括WDT 损失概率、WET 损失概率、可靠传输率和平均能量收集量。我们的理论分析表明，在TS ratio 和用户数量的trade-off下，FAMA 助け的 IDET 系统可以在WDT 和 WET 性能方面达到更好的 equilibria。此外，FAMA 助け的 IDET 系统在相同天线大小情况下比traditional MIMO 系统更好。
</details></li>
</ul>
<hr>
<h2 id="Multi-Point-Method-using-Effective-Demodulation-and-Decomposition-Techniques-allowing-Identification-of-Disturbing-Loads-in-Power-Grids"><a href="#Multi-Point-Method-using-Effective-Demodulation-and-Decomposition-Techniques-allowing-Identification-of-Disturbing-Loads-in-Power-Grids" class="headerlink" title="Multi-Point Method using Effective Demodulation and Decomposition Techniques allowing Identification of Disturbing Loads in Power Grids"></a>Multi-Point Method using Effective Demodulation and Decomposition Techniques allowing Identification of Disturbing Loads in Power Grids</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07129">http://arxiv.org/abs/2311.07129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piotr Kuwałek, Grzegorz Wiczyński</li>
<li>for: 本研究旨在提出一种新的电压波动源标识方法，包括考虑本地化，即指定干扰负荷的供应点。</li>
<li>methods: 提出的方法包括使用搅动信号估计器来估计搅动信号，并将其分解成各个干扰负荷的组成信号。</li>
<li>results: 实验和数字 simulate studies表明，提出的方法可以准确地标识干扰负荷的供应点，并且可以在智能计量基础设施中自动地本地化干扰负荷。<details>
<summary>Abstract</summary>
The paper presents an innovative approach to the identification of sources of voltage fluctuations in power networks, also considering the localization understood as the indication of supply points of disturbing loads. The presented approach considers disturbance sources that change their operating state with a frequency higher than the power frequency. Implementation of the proposed solution is also proposed in such a way that its implementation in the smart meter infrastructure allows for automatic localization of disturbance sources without additional expert knowledge. In the proposed approach, the modulation signal is estimated using a carrier signal estimator, which allows for the estimation of modulation signal with a frequency higher than the power frequency. The estimated modulating signal is decomposed into component signals associated with individual disturbing loads by decomposition by approximation using pulse waves. The decomposition process allows for the estimation of selected parameters associated with disturbing loads, on the basis of which the assessment of propagation of voltage fluctuations associated with the impact of individual disturbance sources is performed, which allows for the indication of their supply point. The proposed approach was verified in numerical simulation studies using MATLAB/SIMULINK and in experimental studies carried out in a real low-voltage power grid.
</details>
<details>
<summary>摘要</summary>
The method uses a carrier signal estimator to estimate the modulation signal, which is then decomposed into component signals associated with individual disturbing loads using pulse wave decomposition. This allows for the estimation of selected parameters associated with the disturbing loads, enabling the assessment of the propagation of voltage fluctuations and the identification of their supply points.The proposed approach was verified through numerical simulations using MATLAB/SIMULINK and experimental studies in a real low-voltage power grid.
</details></li>
</ul>
<hr>
<h2 id="Sum-Rate-Maximization-under-AoI-Constraints-for-RIS-Assisted-mmWave-Communications"><a href="#Sum-Rate-Maximization-under-AoI-Constraints-for-RIS-Assisted-mmWave-Communications" class="headerlink" title="Sum Rate Maximization under AoI Constraints for RIS-Assisted mmWave Communications"></a>Sum Rate Maximization under AoI Constraints for RIS-Assisted mmWave Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07128">http://arxiv.org/abs/2311.07128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Guo, Yong Niu, Shiwen Mao, Changming Zhang, Ning Wang, Zhangdui Zhong, Bo Ai</li>
<li>for: 本文目的是提高 millimeter wave（mmWave）通信系统中信息新鲜度，并满足用户设备（UE）的信息新鲜度要求。</li>
<li>methods: 本文使用了智能表面（RIS）帮助 mmWave 通信系统，并在接收机和发送机中实现了方向性射频。另外，本文还使用了 hierarchical search 方法和本地搜索方法来优化射频和 RIS 反射率。</li>
<li>results:  simulation 结果显示，提出的算法可以有效地提高系统总速率，同时满足所有 UE 的信息新鲜度要求。<details>
<summary>Abstract</summary>
The concept of age of information (AoI) has been proposed to quantify information freshness, which is crucial for time-sensitive applications. However, in millimeter wave (mmWave) communication systems, the link blockage caused by obstacles and the severe path loss greatly impair the freshness of information received by the user equipments (UEs). In this paper, we focus on reconfigurable intelligent surface (RIS)-assisted mmWave communications, where beamforming is performed at transceivers to provide directional beam gain and a RIS is deployed to combat link blockage. We aim to maximize the system sum rate while satisfying the information freshness requirements of UEs by jointly optimizing the beamforming at transceivers, the discrete RIS reflection coefficients, and the UE scheduling strategy. To facilitate a practical solution, we decompose the problem into two subproblems. For the first per-UE data rate maximization problem, we further decompose it into a beamforming optimization subproblem and a RIS reflection coefficient optimization subproblem. Considering the difficulty of channel estimation, we utilize the hierarchical search method for the former and the local search method for the latter, and then adopt the block coordinate descent (BCD) method to alternately solve them. For the second scheduling strategy design problem, a low-complexity heuristic scheduling algorithm is designed. Simulation results show that the proposed algorithm can effectively improve the system sum rate while satisfying the information freshness requirements of all UEs.
</details>
<details>
<summary>摘要</summary>
“年龄信息（AoI）概念已经被提出来衡量信息的新鲜度，这对于时间敏感应用非常重要。但是，在 millimeter 波（mmWave）通信系统中，链路堵塞由障碍物和严重的路径损害很大地减少了接收到用户设备（UE）的信息新鲜度。在本文中，我们关注了基于智能表面（RIS）的 mmWave 通信系统，其中在发射器和接收器之间进行方向性射频，并使用 RIS 来抗链路堵塞。我们的目标是通过同时优化发射器的方向性射频、RIS 的反射系数和 UE 的调度策略来最大化系统总吞吐率，同时满足所有 UE 的信息新鲜度要求。为了实现实用解决方案，我们将问题划分为两个互补问题。首先，我们将每个 UE 的数据速率最大化问题划分为发射器的方向性射频优化问题和 RIS 的反射系数优化问题。 compte tenu de la difficulté de l'estimation de canal, nous utilisons la méthode de recherche hiérarchique pour la première et la méthode de recherche locale pour la deuxième, et then we adopt the method of descent coordonné (BCD) pour les résoudre alternativement。其次，我们设计了一种低复杂度的决策算法来解决调度策略设计问题。 simulation results show that the proposed algorithm can effectively improve the system sum rate while satisfying the information freshness requirements of all UEs.”
</details></li>
</ul>
<hr>
<h2 id="Secure-Wireless-Communication-via-Movable-Antenna-Array"><a href="#Secure-Wireless-Communication-via-Movable-Antenna-Array" class="headerlink" title="Secure Wireless Communication via Movable-Antenna Array"></a>Secure Wireless Communication via Movable-Antenna Array</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07104">http://arxiv.org/abs/2311.07104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guojie Hu, Qingqing Wu, Kui Xu, Jiangbo Si, Naofal Al-Dhahir</li>
<li>for:  investigate the MA array-assisted physical-layer security in wireless communication, to maximize the achievable secrecy rate.</li>
<li>methods:  jointly design the transmit beamforming and positions of all antennas at Alice using projected gradient ascent (PGA) and alternating optimization methods.</li>
<li>results:  the MA array significantly enhances the secrecy rate compared to the conventional fixed-position antenna (FPA) array, due to the additional spatial degree of freedom (DoF) that can be fully exploited.<details>
<summary>Abstract</summary>
Movable antenna (MA) array is a novel technology recently developed where positions of transmit/receive antennas can be flexibly adjusted in the specified region to reconfigure the wireless channel and achieve a higher capacity. In this letter, we, for the first time, investigate the MA array-assisted physical-layer security where the confidential information is transmitted from a MA array-enabled Alice to a single-antenna Bob, in the presence of multiple single-antenna and colluding eavesdroppers. We aim to maximize the achievable secrecy rate by jointly designing the transmit beamforming and positions of all antennas at Alice subject to the transmit power budget and specified regions for positions of all transmit antennas. The resulting problem is highly non-convex, for which the projected gradient ascent (PGA) and the alternating optimization methods are utilized to obtain a high-quality suboptimal solution. Simulation results demonstrate that since the additional spatial degree of freedom (DoF) can be fully exploited, the MA array significantly enhances the secrecy rate compared to the conventional fixed-position antenna (FPA) array.
</details>
<details>
<summary>摘要</summary>
移动天线（MA）数组是一种最近发展的新技术，其中传输/接收天线的位置可以在指定区域中flexibly调整，以重新配置无线通道并实现更高的容量。在这封信中，我们第一次调查了MA数组协助物理层安全性，其中秘密信息由MA数组启用的Alice发送给单天线Bob，在多个单天线和合谋伪装者的存在下。我们想要最大化可以实现的机密率，通过对所有发射天线的传输扬射和位置进行joint设计，并且保持传输功率预算和指定的发射天线位置区域。问题非常非 convex，因此我们使用 проекted gradient ascent（PGA）和交互优化方法来获得高质量的不可靠解。实验结果表明，由于可以充分利用额外的空间度量（DoF），MA数组可以明显提高机密率，相比于传统固定位置天线（FPA）数组。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Configuration-of-Reconfigurable-Intelligent-Surfaces-with-Arbitrary-Discrete-Phase-Shifts"><a href="#Optimal-Configuration-of-Reconfigurable-Intelligent-Surfaces-with-Arbitrary-Discrete-Phase-Shifts" class="headerlink" title="Optimal Configuration of Reconfigurable Intelligent Surfaces with Arbitrary Discrete Phase Shifts"></a>Optimal Configuration of Reconfigurable Intelligent Surfaces with Arbitrary Discrete Phase Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07096">http://arxiv.org/abs/2311.07096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedkhashayar Hashemi, Hai Jiang, Masoud Ardakani</li>
<li>for: 这篇论文是关于智能反射 повер的优化问题的研究，目的是 Maximize the channel capacity of the target user.</li>
<li>methods: 论文使用了一种基于非均匀频率的RIS元素的模型，并提出了一种最优化问题来找到最优的反射振荡和反射阶段。</li>
<li>results: 论文表明，在优化配置下，每个RIS元素都是 either turned off or operates at maximum amplitude，并提供了一种复杂度linear with the number of RIS elements的算法来找到最优的反射振荡和阶段。<details>
<summary>Abstract</summary>
We address the reflection optimization problem for a reconfigurable intelligent surface (RIS), where the RIS elements feature a set of non-uniformly spaced discrete phase shifts. This is motivated by the actual behavior of practical RIS elements, where it is shown that a uniform phase shift assumption is not realistic. A problem is formulated to find the optimal refection amplitudes and reflection phase shifts of the RIS elements such that the channel capacity of the target user is maximized. We first prove that in the optimal configuration, each RIS element is either turned off or operates at maximum amplitude. We then develop a method that finds the optimal reflection amplitudes and phases with complexity linear in the number of RIS elements. Some new and interesting insight into the reflection optimization problem is also provided.
</details>
<details>
<summary>摘要</summary>
我们处理了对可重配置智能表面（RIS）的反射优化问题，其中RIS元素具有一个非均匀的频率分布的不同阶段阶梯。这是因为实际上的RIS元素行为，其中发现均匀阶梯假设不是现实的。我们形ulated了一个问题，以 Maximize the channel capacity of the target user，找到最佳反射振幅和反射阶梯的解。我们首先证明了，在最佳配置下，每个RIS元素都是 Either turned off or operates at maximum amplitude。然后，我们开发了一种方法，可以在RIS元素数量linear增加的情况下找到最佳反射振幅和阶梯。我们还提供了一些新的和有趣的反射优化问题的思想。
</details></li>
</ul>
<hr>
<h2 id="Recursive-and-non-recursive-filters-for-sequential-smoothing-and-prediction-with-instantaneous-phase-and-frequency-estimation-applications"><a href="#Recursive-and-non-recursive-filters-for-sequential-smoothing-and-prediction-with-instantaneous-phase-and-frequency-estimation-applications" class="headerlink" title="Recursive and non-recursive filters for sequential smoothing and prediction with instantaneous phase and frequency estimation applications"></a>Recursive and non-recursive filters for sequential smoothing and prediction with instantaneous phase and frequency estimation applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07089">http://arxiv.org/abs/2311.07089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugh Lachlan Kennedy</li>
<li>for: 这个论文的目的是设计一种可 recursive 和非 recursive 数字 filters，用于跟踪一个指定度量的满足多阶 polynomial 信号，并减少高频噪声的影响。</li>
<li>methods: 这个论文使用了一种 fixes-lag smoothing 技术，以实现低复杂性且低频率响应的满足多阶 polynomial 信号跟踪。它还使用了一种预测器（具有一个预测样本），以减少角度旋转错误的影响。</li>
<li>results:  simulation 结果表明，IIR 过滤器（使用优化的 lag）可以减少角度旋转错误，特别是对于高频率的信号，从而实现低 SNR 下的准确的时延测量和频率测量。此外，IIR 过滤器的错误卷积达到了 FIR 下界，但需要 significatively lower computational cost。<details>
<summary>Abstract</summary>
A simple procedure for the design of recursive digital filters with an infinite impulse response (IIR) and non-recursive digital filters with a finite impulse response (FIR) is described. The fixed-lag smoothing filters are designed to track an approximately polynomial signal of specified degree without bias at steady state, while minimizing the gain of high-frequency (coloured) noise with a specified power spectral density. For the IIR variant, the procedure determines the optimal lag (i.e. the passband group delay) yielding a recursive low-complexity smoother of low order, with a specified bandwidth, and excellent passband phase linearity. The filters are applied to the problem of instantaneous frequency estimation, e.g. for Doppler-shift measurement, for a complex exponential with polynomial phase progression in additive white noise. For this classical problem, simulations show that the incorporation of a prediction filter (with a one-sample lead) reduces the incidence of (phase or frequency) angle unwrapping errors, particularly for signals with high rates of angle change, which are known to limit the performance of standard FIR estimators at low SNR. This improvement allows the instantaneous phase of low-frequency signals to be estimated, e.g. for time-delay measurement, and/or the instantaneous frequency of frequency-modulated signals, down to a lower SNR. In the absence of unwrapping errors, the error variance of the IIR estimators (with the optimal phase lag) reaches the FIR lower bound, at a significantly lower computational cost. Guidelines for configuring and tuning both FIR and IIR filters are provided.
</details>
<details>
<summary>摘要</summary>
一种简单的过程用于设计回归数字filters（IIR）和非回归数字 filters（FIR）的设计方法。这些固定滤波器用于跟踪一个指定度的 polynomialsignal在稳态状态下无偏，同时最小化高频（色整）噪声的功率 спектル。对于IIR变体，这种过程确定了最佳的延迟（即极频组延迟），以获得一个低复杂度的回归估计器，并且在指定宽度下实现出色的极频阶线性。这些筛子应用于Doppler偏移测量中的快速频率估计问题，例如复杂的指数几何函数在加itive white noise中的极频偏移测量。对于这个 классиссиical问题，Simulations表明，在包含预测筛（带有一个预测）的情况下，可以减少（相对频率或相对频率）角度弯曲错误的发生，特别是对于高速角度变化的信号，这些信号已知会限制标准FIR估计器的性能在低SNR情况下。这种改进允许估计低频信号的极频幅度，例如时间延迟测量和/或极频信号的极频频率估计，下降到更低的SNR。在缺乏弯曲错误的情况下，IIR估计器（与最佳相位延迟）的错误方差达到FIR下界，但是在显著更低的计算成本下。文章还提供了配置和调整FIR和IIR筛子的指南。
</details></li>
</ul>
<hr>
<h2 id="Sensing-Mutual-Information-with-Random-Signals-in-Gaussian-Channels"><a href="#Sensing-Mutual-Information-with-Random-Signals-in-Gaussian-Channels" class="headerlink" title="Sensing Mutual Information with Random Signals in Gaussian Channels"></a>Sensing Mutual Information with Random Signals in Gaussian Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07081">http://arxiv.org/abs/2311.07081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Xie, Fan Liu, Zhanyuan Xie, Zheng Jiang, Shenghui Song</li>
<li>for: 本研究旨在提高感知性能，并研究随机信号的感知性能。</li>
<li>methods: 本研究使用随机矩阵理论来计算随机信号下的感知 Shared Information（SMI）的封闭式表达式。然后，使用拓扑推广来优化预处理器。</li>
<li>results: 通过实验结果，提出的方法可以提高感知性能。<details>
<summary>Abstract</summary>
Sensing performance is typically evaluated by classical metrics, such as Cramer-Rao bound and signal-to-clutter-plus-noise ratio. The recent development of the integrated sensing and communication (ISAC) framework motivated the efforts to unify the metric for sensing and communication, where researchers have proposed to utilize mutual information (MI) to measure the sensing performance with deterministic signals. However, the need to communicate in ISAC systems necessitates the use of random signals for sensing applications and the closed-form evaluation for the sensing mutual information (SMI) with random signals is not yet available in the literature. This paper investigates the achievable performance and precoder design for sensing applications with random signals. For that purpose, we first derive the closed-form expression for the SMI with random signals by utilizing random matrix theory. The result reveals some interesting physical insights regarding the relation between the SMI with deterministic and random signals. The derived SMI is then utilized to optimize the precoder by leveraging a manifold-based optimization approach. The effectiveness of the proposed methods is validated by simulation results.
</details>
<details>
<summary>摘要</summary>
感知性能通常通过古典指标评估，如克拉默-瑞托约限和信号噪声比。 reciently，整合感知通信（ISAC）框架的发展激发了研究人员尝试统一感知和通信的度量，其中一些研究人员提议使用共谱（MI）来衡量感知性能。然而，ISAC系统中的通信需求使得感知应用中需要使用随机信号，而关于随机信号的感知共谱（SMI）的关闭形式评估在文献中并没有。这篇论文investigates the achievable performance and precoder design for sensing applications with random signals.为此，我们首先 derivethe closed-form expression for the SMI with random signals by utilizing random matrix theory. The result reveals some interesting physical insights regarding the relation between the SMI with deterministic and random signals. The derived SMI is then utilized to optimize the precoder by leveraging a manifold-based optimization approach. The effectiveness of the proposed methods is validated by simulation results.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Shannon-Theory-for-Wireless-Communication-in-a-Resonant-Chamber"><a href="#Shannon-Theory-for-Wireless-Communication-in-a-Resonant-Chamber" class="headerlink" title="Shannon Theory for Wireless Communication in a Resonant Chamber"></a>Shannon Theory for Wireless Communication in a Resonant Chamber</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07068">http://arxiv.org/abs/2311.07068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amritpal Singh, Thomas Marzetta<br>for: 这个研究探讨了在封闭电磁振兴室（RC）中进行无线通信的可能性。methods: 研究使用了对两个天线的阻抗矩阵的分析，并考虑了对天线的传递和获取。results: 研究发现，当RC壁填充完美导电材料时，通信频率将会受到几何对应的影响，并且随着载重抗的增加，频率将会逐渐趋向真值轴。此外，接收器会受到负iah杂音和内部抗杂变的影响。研究还发现，对于定定力和功率限制，频率和功率的分配可以实现无限制的容量。但是，实际分配不会集中在振兴频率上。<details>
<summary>Abstract</summary>
A closed electromagnetic resonant chamber (RC) is a highly favorable artificial environment for wireless communication. A pair of antennas within the chamber constitutes a two-port network described by an impedance matrix. We analyze communication between the two antennas when the RC has perfectly conducting walls and the impedance matrix is imaginary-valued. The transmit antenna is driven by a current source, and the receive antenna is connected to a load resistor whose voltage is measured by an infinite-impedance amplifier. There are a countably infinite number of poles in the channel, associated with resonance in the RC, which migrate towards the real frequency axis as the load resistance increases. There are two sources of receiver noise: the Johnson noise of the load resistor, and the internal amplifier noise. An application of Shannon theory yields the capacity of the link, subject to bandwidth and power constraints on the transmit current. For a constant transmit power, capacity increases without bound as the load resistance increases. Surprisingly, the capacity-attaining allocation of transmit power versus frequency avoids placing power close to the resonant frequencies.
</details>
<details>
<summary>摘要</summary>
闭合电磁振荡室（RC）是一个非常有利的人工环境，用于无线通信。它中的两个天线组成了一个二端网络，可以通过一个阻抗矩阵来描述。我们分析了它们之间的通信，当RC墙为绝对导电的时候，天线之间的阻抗矩阵为虚数值的时候。传输天线由一个电流源驱动，接收天线连接到一个负担抗的抗器，其电压被一个无限大的抗器检测。频率域中有无数多的极点，与RC的振荡相关，随着负担抗增加，极点逐渐移动到实频轴。接收器的噪声有两种来源：加载抗器的约束噪声，以及内部抗器的噪声。根据雪hnen理论，我们可以计算链路容量，受到带宽和功率限制的情况下。对于Constant transmit power，链路容量会无限增长，随着负担抗增加。很奇怪的是，链路容量最佳分配的发射功率与频率的分配不会将功率集中在振荡频率上。
</details></li>
</ul>
<hr>
<h2 id="Clifford-Algebra-Based-Iterated-Extended-Kalman-Filter-with-Application-to-Low-Cost-INS-GNSS-Navigation"><a href="#Clifford-Algebra-Based-Iterated-Extended-Kalman-Filter-with-Application-to-Low-Cost-INS-GNSS-Navigation" class="headerlink" title="Clifford Algebra-Based Iterated Extended Kalman Filter with Application to Low-Cost INS&#x2F;GNSS Navigation"></a>Clifford Algebra-Based Iterated Extended Kalman Filter with Application to Low-Cost INS&#x2F;GNSS Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07049">http://arxiv.org/abs/2311.07049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Ouyang, Yutian Wang, Yuanxin Wu</li>
<li>for: 提高低成本INS&#x2F;GNSS结合导航系统的初始pose精度</li>
<li>methods: 使用Clifford алгебра表示扩展pose，IMU偏差和杆arm，建立 quasi-group-affine系统，并基于Clifford-RQEKF进行逐步筛选</li>
<li>results: 数值仿真和实验表明，所有逐步筛选方法均具有快速全球受欢迎性，而逐步Clifford-RQEKF在特别大的IMU偏差情况下表现较好<details>
<summary>Abstract</summary>
The traditional GNSS-aided inertial navigation system (INS) usually exploits the extended Kalman filter (EKF) for state estimation, and the initial attitude accuracy is key to the filtering performance. To spare the reliance on the initial attitude, this work generalizes the previously proposed trident quaternion within the framework of Clifford algebra to represent the extended pose, IMU biases and lever arms on the Lie group. Consequently, a quasi-group-affine system is established for the low-cost INS/GNSS integrated navigation system, and the right-error Clifford algebra-based EKF (Clifford-RQEKF) is accordingly developed. The iterated filtering approach is further applied to significantly improve the performances of the Clifford-RQEKF and the previously proposed trident quaternion-based EKFs. Numerical simulations and experiments show that all iterated filtering approaches fulfill the fast and global convergence without the prior attitude information, whereas the iterated Clifford-RQEKF performs much better than the others under especially large IMU biases.
</details>
<details>
<summary>摘要</summary>
传统的GNSS协助导航系统（INS）通常利用扩展卡尔曼 Filter（EKF）进行状态估计，初始Orientation的准确性是过滤性能的关键。为了减少对初始Orientation的依赖，这项工作通过在Clifford алгебра中为扩展pose、IMU偏差和杆臂的表示generalize the previously proposed trident quaternion within the framework of Clifford algebra。因此，一个 quasi-group-affine system是建立了低成本INS/GNSS интеegrated navigation system，并对应地开发了Clifford-RQEKF。iterated filtering approach是进一步应用于显著提高Clifford-RQEKF和之前提出的trident quaternion-based EKFs的性能。数字实验和实验显示，所有的iterated filtering approaches可以在不知情IMU偏差的情况下实现快速和全球化的 converges，而iterated Clifford-RQEKF在特别大的IMU偏差情况下表现较好。
</details></li>
</ul>
<hr>
<h2 id="Deep-Joint-Source-Channel-Coding-With-Attention-Modules-Over-MIMO-Channels"><a href="#Deep-Joint-Source-Channel-Coding-With-Attention-Modules-Over-MIMO-Channels" class="headerlink" title="Deep Joint Source Channel Coding With Attention Modules Over MIMO Channels"></a>Deep Joint Source Channel Coding With Attention Modules Over MIMO Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07041">http://arxiv.org/abs/2311.07041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiran Jiang, Wei Chen, Bo Ai</li>
<li>for: 提高多输入多出力（MIMO）通道的图像传输性能</li>
<li>methods: 使用深度 JOINT SOURCE和通道编码（DJSCC）结构，包括串行结构和平行结构，并使用注意模块来适应不同通道质量</li>
<li>results: 实验结果表明提议的DJSCC结构可以提高图像传输性能，并通过非参数 entropy 估计发现系统通过注意模块来调整发送信息的量，以适应不同通道质量<details>
<summary>Abstract</summary>
In this paper, we propose two deep joint source and channel coding (DJSCC) structures with attention modules for the multi-input multi-output (MIMO) channel, including a serial structure and a parallel structure. With singular value decomposition (SVD)-based precoding scheme, the MIMO channel can be decomposed into various sub-channels, and the feature outputs will experience sub-channels with different channel qualities. In the serial structure, one single network is used at both the transmitter and the receiver to jointly process data streams of all MIMO subchannels, while data steams of different MIMO subchannels are processed independently via multiple sub-networks in the parallel structure. The attention modules in both serial and parallel architectures enable the system to adapt to varying channel qualities and adjust the quantity of information outputs in accordance with the channel qualities. Experimental results demonstrate the proposed DJSCC structures have improved image transmission performance, and reveal the phenomenon via non-parameter entropy estimation that the learned DJSCC transceivers tend to transmit more information over better sub-channels.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了两种深度结合源码混合编码（DJSCC）结构，包括串行结构和平行结构，以便对多输入多输出（MIMO）通道进行编码。使用基于SVD（特征值分解）的编码方案，MIMO通道可以被分解成多个子通道，并且特征输出将经历不同通道质量的子通道。在串行结构中，发送端和接收端都使用单个网络进行数据流的同时处理，而在平行结构中，不同的MIMO子通道使用多个子网络进行独立的数据流处理。对各个MIMO子通道进行独立处理的注意模块允许系统适应不同的通道质量，并调整发送的信息量以适应通道质量。实验结果表明，我们提出的DJSCC结构可以提高图像传输性能，并通过非参数 entropy 估计来证明系统学习的DJSCC接收器通常将更多的信息发送到更好的子通道。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Joint-Source-Channel-Coding-Scheme-for-Mobile-Multi-hop-Networks"><a href="#A-Hybrid-Joint-Source-Channel-Coding-Scheme-for-Mobile-Multi-hop-Networks" class="headerlink" title="A Hybrid Joint Source-Channel Coding Scheme for Mobile Multi-hop Networks"></a>A Hybrid Joint Source-Channel Coding Scheme for Mobile Multi-hop Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07028">http://arxiv.org/abs/2311.07028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghong Bian, Yulin Shao, Deniz Gunduz</li>
<li>for: 这个论文是为了提出一种hybridjoint源�annel编码（JSCC）方案，以便在多� hop 网络中Robust图像传输。</li>
<li>methods: 这个方案使用了深度神经网络（DeepJSCC），并将图像分解成多个部分，然后在不同的hop中进行编码。</li>
<li>results: 经过数字� simulations，这个方案能够超过完全analog和完全数字方案，并且可以避免“峰值效应”和静止噪声的问题。<details>
<summary>Abstract</summary>
We propose a novel hybrid joint source-channel coding (JSCC) scheme for robust image transmission over multi-hop networks. In the considered scenario, a mobile user wants to deliver an image to its destination over a mobile cellular network. We assume a practical setting, where the links between the nodes belonging to the mobile core network are stable and of high quality, while the link between the mobile user and the first node (e.g., the access point) is potentially time-varying with poorer quality. In recent years, neural network based JSCC schemes (called DeepJSCC) have emerged as promising solutions to overcome the limitations of separation-based fully digital schemes. However, relying on analog transmission, DeepJSCC suffers from noise accumulation over multi-hop networks. Moreover, most of the hops within the mobile core network may be high-capacity wireless connections, calling for digital approaches. To this end, we propose a hybrid solution, where DeepJSCC is adopted for the first hop, while the received signal at the first relay is digitally compressed and forwarded through the mobile core network. We show through numerical simulations that the proposed scheme is able to outperform both the fully analog and fully digital schemes. Thanks to DeepJSCC it can avoid the cliff effect over the first hop, while also avoiding noise forwarding over the mobile core network thank to digital transmission. We believe this work paves the way for the practical deployment of DeepJSCC solutions in 6G and future wireless networks.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的混合式 JOINT SOURCE-CHANNEL 编码（JSCC）方案，用于在多个跳代网络上稳定传输图像。在我们考虑的场景中，一个移动用户想要将图像传输到其目标地点，通过移动无线网络。我们假设了一个实际的设定，其中移动用户和首个节点（例如访问点）之间的链路为可能是时间变化的、质量较差的无线链路，而其他节点在移动核心网络中的链路则是稳定的高质量的无线链路。在过去几年中，基于神经网络的JSCC方案（称为深度JSCC）已经 emerged as Promising solutions to overcome the limitations of separation-based fully digital schemes。然而，在Analog transmission中，深度JSCC受到多跳代网络中的噪声积累的限制。此外，大多数内部节点在移动核心网络中的跳代可能是高容量无线连接，需要数字方法。为此，我们提出了一种混合解决方案，其中在首个跳代使用深度JSCC，并将在首个中继器接收的信号数字压缩并传递 через 移动核心网络。我们通过数字实验示例表明，我们的方案能够超越完全数字和完全分析的方案。深度JSCC可以避免首跳效应，同时避免在移动核心网络中传输噪声。我们认为这项工作将在6G和未来的无线网络中实用化深度JSCC解决方案。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/eess.SP_2023_11_13/" data-id="clp89dor001hfi788553d0u38" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/cs.CV_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T13:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/cs.CV_2023_11_12/">cs.CV - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Augmented-Bridge-Matching"><a href="#Augmented-Bridge-Matching" class="headerlink" title="Augmented Bridge Matching"></a>Augmented Bridge Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06978">http://arxiv.org/abs/2311.06978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valentin De Bortoli, Guan-Horng Liu, Tianrong Chen, Evangelos A. Theodorou, Weilie Nie</li>
<li>for: 这篇论文探讨了一种新的流程和桥接匹配过程，它们可以描述diffusion模型。这种新的过程可以在两个给定的分布之间学习随机（和决定）过程，并且可以扩展到学习任意诱导任意转移任务。</li>
<li>methods: 论文使用了流程和桥接匹配过程，这些过程可以 interpolate  между两个给定的分布。然而，这些过程并不一定会保留coupling信息，除非遵循更加强的优化条件。</li>
<li>results: 论文表明，通过对流程的速度场（或推移）加入初始样本点的信息，可以恢复coupling信息。这样，我们失去了Markov性质，但保留了两个分布之间的 coupling信息。论文还通过用于学习图像翻译任务的实验，证明了这种更新的效果。<details>
<summary>Abstract</summary>
Flow and bridge matching are a novel class of processes which encompass diffusion models. One of the main aspect of their increased flexibility is that these models can interpolate between arbitrary data distributions i.e. they generalize beyond generative modeling and can be applied to learning stochastic (and deterministic) processes of arbitrary transfer tasks between two given distributions. In this paper, we highlight that while flow and bridge matching processes preserve the information of the marginal distributions, they do \emph{not} necessarily preserve the coupling information unless additional, stronger optimality conditions are met. This can be problematic if one aims at preserving the original empirical pairing. We show that a simple modification of the matching process recovers this coupling by augmenting the velocity field (or drift) with the information of the initial sample point. Doing so, we lose the Markovian property of the process but preserve the coupling information between distributions. We illustrate the efficiency of our augmentation in learning mixture of image translation tasks.
</details>
<details>
<summary>摘要</summary>
“流和桥匹配是一种新的过程类型，包含扩散模型。其中一个主要优点是这些模型可以 interpolate  между任意数据分布，即可以泛化 beyond 生成模型，并可以应用于学习随机（和决定的）过程的任意传输任务。在这篇论文中，我们指出了流和桥匹配过程保留了边缘分布信息，但是不一定保留了对应关系信息，除非遵循更加强的优化条件。这可能会导致损失原始的empirical pairing。我们示出了一种简单的修改方法，可以重新获得这个对应关系信息，通过在速度场（或拖动）中添加初始样本点的信息。这样，我们失去了MarkovProperty的属性，但保留了分布之间的对应关系。我们在图像翻译任务中证明了这种修改的效率。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="CD-COCO-A-Versatile-Complex-Distorted-COCO-Database-for-Scene-Context-Aware-Computer-Vision"><a href="#CD-COCO-A-Versatile-Complex-Distorted-COCO-Database-for-Scene-Context-Aware-Computer-Vision" class="headerlink" title="CD-COCO: A Versatile Complex Distorted COCO Database for Scene-Context-Aware Computer Vision"></a>CD-COCO: A Versatile Complex Distorted COCO Database for Scene-Context-Aware Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06976">http://arxiv.org/abs/2311.06976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aymanbegh/cd-coco">https://github.com/aymanbegh/cd-coco</a></li>
<li>paper_authors: Ayman Beghdadi, Azeddine Beghdadi, Malik Mallem, Lotfi Beji, Faouzi Alaya Cheikh</li>
<li>for: 提高计算机视觉任务的Robustness，通过人工扩充训练数据库或设计深度学习模型，以适应不同的图像获取环境。</li>
<li>methods: 使用本地和全局photo-realistic扭曲，基于图像场景信息和对象深度信息，以提高图像处理的photo-realism。</li>
<li>results: 提供了一个多样化的图像数据库，可以提高对象检测、场景分割和扭曲类型分类等计算机视觉任务的Robustness。<details>
<summary>Abstract</summary>
The recent development of deep learning methods applied to vision has enabled their increasing integration into real-world applications to perform complex Computer Vision (CV) tasks. However, image acquisition conditions have a major impact on the performance of high-level image processing. A possible solution to overcome these limitations is to artificially augment the training databases or to design deep learning models that are robust to signal distortions. We opt here for the first solution by enriching the database with complex and realistic distortions which were ignored until now in the existing databases. To this end, we built a new versatile database derived from the well-known MS-COCO database to which we applied local and global photo-realistic distortions. These new local distortions are generated by considering the scene context of the images that guarantees a high level of photo-realism. Distortions are generated by exploiting the depth information of the objects in the scene as well as their semantics. This guarantees a high level of photo-realism and allows to explore real scenarios ignored in conventional databases dedicated to various CV applications. Our versatile database offers an efficient solution to improve the robustness of various CV tasks such as Object Detection (OD), scene segmentation, and distortion-type classification methods. The image database, scene classification index, and distortion generation codes are publicly available \footnote{\url{https://github.com/Aymanbegh/CD-COCO}
</details>
<details>
<summary>摘要</summary>
To create a versatile database, we built upon the well-known MS-COCO database and applied local and global photo-realistic distortions. These distortions were generated by considering the scene context of the images, ensuring a high level of photo-realism. We exploited the depth information of the objects in the scene, as well as their semantics, to generate distortions that are both realistic and diverse.Our versatile database offers an efficient solution to improve the robustness of various computer vision tasks, such as object detection, scene segmentation, and distortion-type classification methods. The image database, scene classification index, and distortion generation codes are publicly available at \url{https://github.com/Aymanbegh/CD-COCO}.
</details></li>
</ul>
<hr>
<h2 id="Adaptive-recurrent-vision-performs-zero-shot-computation-scaling-to-unseen-difficulty-levels"><a href="#Adaptive-recurrent-vision-performs-zero-shot-computation-scaling-to-unseen-difficulty-levels" class="headerlink" title="Adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels"></a>Adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06964">http://arxiv.org/abs/2311.06964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vijay Veerabadran, Srinivas Ravishankar, Yuan Tang, Ritik Raina, Virginia R. de Sa</li>
<li>for:  investigate the adaptive computation of recurrent neural networks in visual reasoning tasks, and whether it can enable zero-shot generalization to novel difficulty levels.</li>
<li>methods:  combine convolutional recurrent neural networks (ConvRNNs) with a learnable halting mechanism based on Graves (2016), and explore various implementations of adaptive ConvRNNs (AdRNNs) such as tying weights across layers and biologically inspired recurrent networks with lateral connections and gating.</li>
<li>results:  AdRNNs learn to dynamically halt processing early or late to solve easier or harder problems, and zero-shot generalize to more difficult problem settings not shown during training by dynamically increasing the number of recurrent iterations at test time.<details>
<summary>Abstract</summary>
Humans solving algorithmic (or) reasoning problems typically exhibit solution times that grow as a function of problem difficulty. Adaptive recurrent neural networks have been shown to exhibit this property for various language-processing tasks. However, little work has been performed to assess whether such adaptive computation can also enable vision models to extrapolate solutions beyond their training distribution's difficulty level, with prior work focusing on very simple tasks. In this study, we investigate a critical functional role of such adaptive processing using recurrent neural networks: to dynamically scale computational resources conditional on input requirements that allow for zero-shot generalization to novel difficulty levels not seen during training using two challenging visual reasoning tasks: PathFinder and Mazes. We combine convolutional recurrent neural networks (ConvRNNs) with a learnable halting mechanism based on Graves (2016). We explore various implementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights across layers to more sophisticated biologically inspired recurrent networks that possess lateral connections and gating. We show that 1) AdRNNs learn to dynamically halt processing early (or late) to solve easier (or harder) problems, 2) these RNNs zero-shot generalize to more difficult problem settings not shown during training by dynamically increasing the number of recurrent iterations at test time. Our study provides modeling evidence supporting the hypothesis that recurrent processing enables the functional advantage of adaptively allocating compute resources conditional on input requirements and hence allowing generalization to harder difficulty levels of a visual reasoning problem without training.
</details>
<details>
<summary>摘要</summary>
人类解决算法逻辑问题通常会 exhibit 解决时间随问题难度增长。适应式循环神经网络已经在不同的语言处理任务上显示出这种性质。然而，对于视觉模型是否可以通过适应计算来解决超出训练分布难度水平的问题，尚未得到了足够的研究。在这种研究中，我们调查了适应计算的重要功能作用：动态根据输入要求调整计算资源，以实现零aser普适性。我们结合了卷积循环神经网络（ConvRNN）和学习 halt 机制，并 explore 了不同的适应 ConvRNN（AdRNN）的实现方式，从简单的Weight 套接到更复杂的生物学发现逻辑循环网络。我们的研究表明，1） AdRNNs 可以在解决更容易或更难的问题时适应停止处理，2）这些 RNNs 在训练没有看到的更加困难的问题设定中进行零aser普适性。我们的研究提供了对适应计算的模型证据，支持逻辑处理允许通过 conditional 计算资源的分配来实现零aser普适性，而无需训练。
</details></li>
</ul>
<hr>
<h2 id="SegReg-Segmenting-OARs-by-Registering-MR-Images-and-CT-Annotations"><a href="#SegReg-Segmenting-OARs-by-Registering-MR-Images-and-CT-Annotations" class="headerlink" title="SegReg: Segmenting OARs by Registering MR Images and CT Annotations"></a>SegReg: Segmenting OARs by Registering MR Images and CT Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06956">http://arxiv.org/abs/2311.06956</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/steve-zeyu-zhang/SegReg">https://github.com/steve-zeyu-zhang/SegReg</a></li>
<li>paper_authors: Zeyu Zhang, Xuyin Qi, Bowen Zhang, Biao Wu, Hien Le, Bora Jeong, Minh-Son To, Richard Hartley</li>
<li>for: 这个研究是为了提高肿瘤头颈治疗规划中的肿瘤组织（Organ at Risk，OAR）分类，以提高诊断效率和精确性。</li>
<li>methods: 这个方法使用了弹性对称normalization来对MRI融合CT扫描进行匹配和分类，以提高OAR分类的精度和效率。</li>
<li>results: 这个方法比CT仅的基eline提高了16.78%的mDSC和18.77%的mIoU，显示了它能够有效地结合CT的凖度精度和MRI的软组织视觉化，实现了便捷且精确的自动OAR分类。<details>
<summary>Abstract</summary>
Organ at risk (OAR) segmentation is a critical process in radiotherapy treatment planning such as head and neck tumors. Nevertheless, in clinical practice, radiation oncologists predominantly perform OAR segmentations manually on CT scans. This manual process is highly time-consuming and expensive, limiting the number of patients who can receive timely radiotherapy. Additionally, CT scans offer lower soft-tissue contrast compared to MRI. Despite MRI providing superior soft-tissue visualization, its time-consuming nature makes it infeasible for real-time treatment planning. To address these challenges, we propose a method called SegReg, which utilizes Elastic Symmetric Normalization for registering MRI to perform OAR segmentation. SegReg outperforms the CT-only baseline by 16.78% in mDSC and 18.77% in mIoU, showing that it effectively combines the geometric accuracy of CT with the superior soft-tissue contrast of MRI, making accurate automated OAR segmentation for clinical practice become possible.
</details>
<details>
<summary>摘要</summary>
Organ at risk (OAR) 分 Segmentation 是肿瘤治疗规划中的关键过程，特别是头颈肿瘤。然而，在临床实践中，辐射生物学专家主要通过手动操作 CT 扫描来进行 OAR 分 Segmentation。这个手动过程非常时间consuming 和昂贵，因此限制了可以得到有效的肿瘤治疗的病人数量。此外， CT 扫描表现下降的软组织对比度，尤其是在肿瘤辐射治疗中。Despite MRI 提供更高的软组织视化，它的时间consuming 性使其不可靠实时规划。为了解决这些挑战，我们提出了一种方法called SegReg，该方法利用弹性对称normalization 来将 MRI 注册到 OAR 分 Segmentation。SegReg 比 CT 基eline 高出 16.78% 的 mDSC 和 18.77% 的 mIoU，表明它可以有效地结合 CT 的准确性和 MRI 的软组织对比度，使得临床实践中的自动 OAR 分 Segmentation 变得可能。
</details></li>
</ul>
<hr>
<h2 id="Video-based-sympathetic-arousal-assessment-via-peripheral-blood-flow-estimation"><a href="#Video-based-sympathetic-arousal-assessment-via-peripheral-blood-flow-estimation" class="headerlink" title="Video-based sympathetic arousal assessment via peripheral blood flow estimation"></a>Video-based sympathetic arousal assessment via peripheral blood flow estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06930">http://arxiv.org/abs/2311.06930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bjoern Braun, Daniel McDuff, Tadas Baltrusaitis, Christian Holz<br>for: 这篇论文旨在测量 sympathetic arousal 的标准 markers，但传统的 EDA 测量需要电极在皮肤上固定接触。这篇论文提出了一种新的方法，通过测量面或手上的血液流动来推断 sympathetic arousal。methods: 该方法使用了 RGB 摄像头测量面或手上的血液流动，并使用了同步录制的视频和 EDA 和 photoplethysmography (PPG) 信号作为参照标准。results: 研究结果表明，可以使用只有视频或 PPG 信号来测量 sympathetic arousal，并且得到了高度相关的结果（ median 相关性为 0.57-0.63）。此外，研究还表明，最佳的 sympathetic arousal 推断来自于面、手或手掌。<details>
<summary>Abstract</summary>
Electrodermal activity (EDA) is considered a standard marker of sympathetic activity. However, traditional EDA measurement requires electrodes in steady contact with the skin. Can sympathetic arousal be measured using only an optical sensor, such as an RGB camera? This paper presents a novel approach to infer sympathetic arousal by measuring the peripheral blood flow on the face or hand optically. We contribute a self-recorded dataset of 21 participants, comprising synchronized videos of participants' faces and palms and gold-standard EDA and photoplethysmography (PPG) signals. Our results show that we can measure peripheral sympathetic responses that closely correlate with the ground truth EDA. We obtain median correlations of 0.57 to 0.63 between our inferred signals and the ground truth EDA using only videos of the participants' palms or foreheads or PPG signals from the foreheads or fingers. We also show that sympathetic arousal is best inferred from the forehead, finger, or palm.
</details>
<details>
<summary>摘要</summary>
电气活动 (EDA) 被视为 sympathetic 活动标准标志。然而，传统的 EDA 测量需要电极在皮肤上稳定接触。这篇论文提出了一种新的方法，可以通过 оптиче方式测量表照 sympathetic 活动。我们提供了 21 名参与者的自录录视频数据集，包括参与者的脸和手掌视频和标准 EDA 和光谱激光血流压力 (PPG) 信号。我们的结果显示，我们可以通过只使用参与者的脸、手掌或手指的视频来测量周围 sympathetic 响应，并且与真实 EDA 的对应相吻合度为 0.57-0.63。我们还发现， sympathetic 活动最好从脸、手掌或手指进行测量。
</details></li>
</ul>
<hr>
<h2 id="Setting-a-Baseline-for-long-shot-real-time-Player-and-Ball-detection-in-Soccer-Videos"><a href="#Setting-a-Baseline-for-long-shot-real-time-Player-and-Ball-detection-in-Soccer-Videos" class="headerlink" title="Setting a Baseline for long-shot real-time Player and Ball detection in Soccer Videos"></a>Setting a Baseline for long-shot real-time Player and Ball detection in Soccer Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06892">http://arxiv.org/abs/2311.06892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kmouts/soccernet_v3_h250">https://github.com/kmouts/soccernet_v3_h250</a></li>
<li>paper_authors: Konstantinos Moutselos, Ilias Maglogiannis</li>
<li>for: 本研究的目的是提供一个更好的足球数据集，以便进行人员和球的检测，并提出了一种使用YOLO normalized annotation format进行训练和评估的方法。</li>
<li>methods: 本研究使用了SoccerNet v3的编辑版本，并提供了代码和度量器，以便在未来的比较中作为参照。</li>
<li>results: 研究发现，使用YOLO8n模型可以在实时长距离检测球和人员的情况下，比 FootAndBall 模型更好。<details>
<summary>Abstract</summary>
Players and ball detection are among the first required steps on a football analytics platform. Until recently, the existing open datasets on which the evaluations of most models were based, were not sufficient. In this work, we point out their weaknesses, and with the advent of the SoccerNet v3, we propose and deliver to the community an edited part of its dataset, in YOLO normalized annotation format for training and evaluation. The code of the methods and metrics are provided so that they can be used as a benchmark in future comparisons. The recent YOLO8n model proves better than FootAndBall in long-shot real-time detection of the ball and players on football fields.
</details>
<details>
<summary>摘要</summary>
《玩家和球的探测是足球分析平台上的首要步骤。ntil recently，现有的公开数据集，在大多数模型的评估上是不充分的。在这项工作中，我们指出了它们的弱点，并随着SoccerNet v3的出现，我们对社区提供了修订后的数据集，使用YOLO normalized annotation格式进行训练和评估。我们提供了方法和指标的代码，以便作为未来的比较标准。最新的YOLO8n模型在长距离实时探测足球场上的球和玩家表现出色。》Note that "足球" (zúqiú) in the text refers to "soccer" in English.
</details></li>
</ul>
<hr>
<h2 id="Concept-wise-Fine-tuning-Matters-in-Preventing-Negative-Transfer"><a href="#Concept-wise-Fine-tuning-Matters-in-Preventing-Negative-Transfer" class="headerlink" title="Concept-wise Fine-tuning Matters in Preventing Negative Transfer"></a>Concept-wise Fine-tuning Matters in Preventing Negative Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06868">http://arxiv.org/abs/2311.06868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunqiao Yang, Long-Kai Huang, Ying Wei</li>
<li>for: 提高 Fine-tuning 的效果，尤其是对于 rare 和偶合 correlated 特征的影响</li>
<li>methods: 提出 Concept-wise fine-tuning (Concept-Tuning) 方法，通过在 patch 级别划分特征，提高 feature 表示的精度</li>
<li>results: 在 eleven 个 dataset 上，Concept-Tuning 方法与 priors 的 state-of-the-art fine-tuning 方法相比，显著提高了效果（最多提高4.76%），并在不同的预训练策略、网络架构和样本大小上具有广泛的可行性。<details>
<summary>Abstract</summary>
A multitude of prevalent pre-trained models mark a major milestone in the development of artificial intelligence, while fine-tuning has been a common practice that enables pretrained models to figure prominently in a wide array of target datasets. Our empirical results reveal that off-the-shelf finetuning techniques are far from adequate to mitigate negative transfer caused by two types of underperforming features in a pre-trained model, including rare features and spuriously correlated features. Rooted in structural causal models of predictions after fine-tuning, we propose a Concept-wise fine-tuning (Concept-Tuning) approach which refines feature representations in the level of patches with each patch encoding a concept. Concept-Tuning minimizes the negative impacts of rare features and spuriously correlated features by (1) maximizing the mutual information between examples in the same category with regard to a slice of rare features (a patch) and (2) applying front-door adjustment via attention neural networks in channels and feature slices (patches). The proposed Concept-Tuning consistently and significantly (by up to 4.76%) improves prior state-of-the-art fine-tuning methods on eleven datasets, diverse pre-training strategies (supervised and self-supervised ones), various network architectures, and sample sizes in a target dataset.
</details>
<details>
<summary>摘要</summary>
一群普遍存在的预训练模型标志着人工智能的发展历程中的一个重要里程碑，而适应已成为预训练模型在多个目标数据集中突出表现的常见做法。我们的实验结果表明，直接使用存在问题的特征的预训练技术是不够有效地 mitigate 负面传递。基于结构 causal 模型的预测后 fine-tuning，我们提出了概念层 fine-tuning（Concept-Tuning）方法，它在 patch 级别对特征进行了更加细化的修正。Concept-Tuning 通过（1）在同类目标中的例子之间增加例子之间的相互信息（regarding 一个质量的patch），以及（2）通过注意力神经网络在通道和特征片（patch）中进行前门调整来减少罕见特征和偶合特征的负面影响。我们的 Concept-Tuning 方法在十一个数据集上，包括不同的预训练策略（指导和自我指导）、不同的网络架构和样本大小等多个因素上，与之前的最佳 fine-tuning 方法进行了比较，并表现出了显著改善（最高提升4.76%）。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-of-View-Invariant-Representations-for-Facial-Expressions-Recognition"><a href="#Contrastive-Learning-of-View-Invariant-Representations-for-Facial-Expressions-Recognition" class="headerlink" title="Contrastive Learning of View-Invariant Representations for Facial Expressions Recognition"></a>Contrastive Learning of View-Invariant Representations for Facial Expressions Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06852">http://arxiv.org/abs/2311.06852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuvendu Roy, Ali Etemad</li>
<li>for: 提高非FR面部表达识别精度，抵御不同视角入参影响</li>
<li>methods: 基于对比学习的新视角不变 facial expression recognition 框架 ViewFX，通过自我超vised contrastive loss 学习视角不变特征，并通过supervised contrastive loss 驱动每个表情的特征归一化</li>
<li>results: 在两个多视角面部表达识别数据集上进行测试，表现比前作高，新创造了两个数据集的状态之一，并在不同视角和输入 Parameters 的情况下显示更高的鲁棒性和灵活性<details>
<summary>Abstract</summary>
Although there has been much progress in the area of facial expression recognition (FER), most existing methods suffer when presented with images that have been captured from viewing angles that are non-frontal and substantially different from those used in the training process. In this paper, we propose ViewFX, a novel view-invariant FER framework based on contrastive learning, capable of accurately classifying facial expressions regardless of the input viewing angles during inference. ViewFX learns view-invariant features of expression using a proposed self-supervised contrastive loss which brings together different views of the same subject with a particular expression in the embedding space. We also introduce a supervised contrastive loss to push the learnt view-invariant features of each expression away from other expressions. Since facial expressions are often distinguished with very subtle differences in the learned feature space, we incorporate the Barlow twins loss to reduce the redundancy and correlations of the representations in the learned representations. The proposed method is a substantial extension of our previously proposed CL-MEx, which only had a self-supervised loss. We test the proposed framework on two public multi-view facial expression recognition datasets, KDEF and DDCF. The experiments demonstrate that our approach outperforms previous works in the area and sets a new state-of-the-art for both datasets while showing considerably less sensitivity to challenging angles and the number of output labels used for training. We also perform detailed sensitivity and ablation experiments to evaluate the impact of different components of our model as well as its sensitivity to different parameters.
</details>
<details>
<summary>摘要</summary>
尽管在人脸表达识别（FER）领域已经做出了很多进步，但大多数现有方法在输入角度不同于训练过程中的角度时受到影响。在这篇论文中，我们提出了 ViewFX，一种基于对比学习的新型视角不变的FER框架，能够在推理过程中准确地识别不同角度的人脸表达。ViewFX使用我们提议的自我监督对比损失来学习不同视角的表达特征，并通过推理过程中的不同视角来将这些特征带入嵌入空间中。我们还引入了一种监督对比损失来将学习的不同视角特征远离其他表达的特征。由于人脸表达通常通过非常微小的差异来区分，我们采用了Barlow twins损失来减少学习的表示空间中的重复和相关性。我们的方法是CL-MEx的扩展，只有自我监督loss。我们在两个公共多视角人脸表达识别数据集（KDEF和DDCF）进行了测试，实验结果表明，我们的方法在这两个数据集上超越了之前的成果，并在不同角度和输入标签数量的情况下设置了新的状态法。我们还进行了详细的敏感性和缺失 эксперименты来评估我们的模型的不同组件和参数的影响。
</details></li>
</ul>
<hr>
<h2 id="Sampler-Scheduler-for-Diffusion-Models"><a href="#Sampler-Scheduler-for-Diffusion-Models" class="headerlink" title="Sampler Scheduler for Diffusion Models"></a>Sampler Scheduler for Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06845">http://arxiv.org/abs/2311.06845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/carzit/sd-webui-samplers-scheduler">https://github.com/carzit/sd-webui-samplers-scheduler</a></li>
<li>paper_authors: Zitong Cheng</li>
<li>for: 这个论文的目的是提出一种多抽样器（ODE&#x2F;SDE）的可行性，以解决 diffusion-based generative models 中的抽样问题。</li>
<li>methods: 该论文使用了多种主流抽样器（ODE&#x2F;SDE），并通过分析和总结每种抽样器的更新方程，实现在同一个抽样过程中使用不同的抽样器。</li>
<li>results: 实验结果表明，这种多抽样器调度策略可以提高抽样效率和质量。例如，在 CIFAR-10 数据集上，使用 ODE Sampler Scheduler 时，FID 分数为 1.91，比 DPM++ 2M 、DPM2 和 Heun 等方法更好。同时， combining SDE 和 ODE 的抽样调度策略可以更好地解决抽样问题。<details>
<summary>Abstract</summary>
Diffusion modeling (DM) has high-quality generative performance, and the sampling problem is an important part of the DM performance. Thanks to efficient differential equation solvers, the sampling speed can be reduced while higher sampling quality is guaranteed. However, currently, there is a contradiction in samplers for diffusion-based generative models: the mainstream sampler choices are diverse, each with its own characteristics in terms of performance. However, only a single sampler algorithm can be specified on all sampling steps in the generative process. This often makes one torn between sampler choices; in other words, it makes it difficult to fully utilize the advantages of each sampler. In this paper, we propose the feasibility of using different samplers (ODE/SDE) on different sampling steps of the same sampling process based on analyzing and generalizing the updating formulas of each mainstream sampler, and experimentally demonstrate that such a multi-sampler scheduling improves the sampling results to some extent. In particular, we also verify that the combination of using SDE in the early sampling steps and ODE in the later sampling steps solves the inherent problems previously caused by using both singly. We show that our design changes improve the sampling efficiency and quality in previous work. For instance, when Number of Function Evaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91 on the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and 11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the combined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler a, 3.14 for DPM2 a and 23.14 for DPM++ SDE.
</details>
<details>
<summary>摘要</summary>
Diffusion 模型（DM）具有高质量的生成性能， sampling 问题是 DM 性能的重要组成部分。due to efficient differential equation solvers, the sampling speed can be reduced while higher sampling quality is guaranteed. However, currently, there is a contradiction in samplers for diffusion-based generative models: the mainstream sampler choices are diverse, each with its own characteristics in terms of performance. However, only a single sampler algorithm can be specified on all sampling steps in the generative process. This often makes one torn between sampler choices; in other words, it makes it difficult to fully utilize the advantages of each sampler. In this paper, we propose the feasibility of using different samplers (ODE/SDE) on different sampling steps of the same sampling process based on analyzing and generalizing the updating formulas of each mainstream sampler, and experimentally demonstrate that such a multi-sampler scheduling improves the sampling results to some extent. In particular, we also verify that the combination of using SDE in the early sampling steps and ODE in the later sampling steps solves the inherent problems previously caused by using both singly. We show that our design changes improve the sampling efficiency and quality in previous work. For instance, when Number of Function Evaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91 on the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and 11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the combined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler a, 3.14 for DPM2 a, and 23.14 for DPM++ SDE.
</details></li>
</ul>
<hr>
<h2 id="Osteoporosis-Prediction-from-Hand-and-Wrist-X-rays-using-Image-Segmentation-and-Self-Supervised-Learning"><a href="#Osteoporosis-Prediction-from-Hand-and-Wrist-X-rays-using-Image-Segmentation-and-Self-Supervised-Learning" class="headerlink" title="Osteoporosis Prediction from Hand and Wrist X-rays using Image Segmentation and Self-Supervised Learning"></a>Osteoporosis Prediction from Hand and Wrist X-rays using Image Segmentation and Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06834">http://arxiv.org/abs/2311.06834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyungeun Lee, Ung Hwang, Seungwon Yu, Chang-Hun Lee, Kijung Yoon</li>
<li>for: 这篇文章旨在探讨使用手和腕X射线影像来预测骨质疾病（osteoporosis），以提高检测率而无需增加成本或时间。</li>
<li>methods: 这篇文章使用了一个基础模型来进行影像分类，然后使用自我超vised learning的方法来提取有意义的表示，最后使用一个超vised learning的方法来类别骨质疾病。</li>
<li>results: 这篇文章的结果显示，使用这种方法可以获得一个较高的类别分数（AUC&#x3D;0.83），这表明这种方法可以很好地预测骨质疾病。<details>
<summary>Abstract</summary>
Osteoporosis is a widespread and chronic metabolic bone disease that often remains undiagnosed and untreated due to limited access to bone mineral density (BMD) tests like Dual-energy X-ray absorptiometry (DXA). In response to this challenge, current advancements are pivoting towards detecting osteoporosis by examining alternative indicators from peripheral bone areas, with the goal of increasing screening rates without added expenses or time. In this paper, we present a method to predict osteoporosis using hand and wrist X-ray images, which are both widely accessible and affordable, though their link to DXA-based data is not thoroughly explored. Initially, our method segments the ulnar, radius, and metacarpal bones using a foundational model for image segmentation. Then, we use a self-supervised learning approach to extract meaningful representations without the need for explicit labels, and move on to classify osteoporosis in a supervised manner. Our method is evaluated on a dataset with 192 individuals, cross-referencing their verified osteoporosis conditions against the standard DXA test. With a notable classification score (AUC=0.83), our model represents a pioneering effort in leveraging vision-based techniques for osteoporosis identification from the peripheral skeleton sites.
</details>
<details>
<summary>摘要</summary>
骨质疏松是一种广泛存在和慢性的代谢疾病，经常未被诊断和治疗，这是由于骨骼矿物厚度测试（DXA）的有限访问而导致的。为了解决这个挑战，当前的进展都在转移到查看周边骨骼区域的指标，以提高检测率而无需增加成本或时间。在这篇论文中，我们提出了使用手和手腕X射线图像来预测骨质疏松的方法，这些图像都是非常容易获得和便宜的，但它们与DXA测试的关系尚未得到了充分探讨。我们的方法首先使用基础模型来对手和手腕X射线图像进行分割，然后使用无监督学习方法来提取有意义的表示，最后在监督学习方式下来进行分类。我们的方法在一个包含192名个体的数据集上进行评估，并与标准DXA测试进行对比。我们的模型在这些数据上获得了 Notable的分类分数（AUC=0.83），表明我们的方法可以有效地利用视觉技术来识别骨质疏松。
</details></li>
</ul>
<hr>
<h2 id="On-original-and-latent-space-connectivity-in-deep-neural-networks"><a href="#On-original-and-latent-space-connectivity-in-deep-neural-networks" class="headerlink" title="On original and latent space connectivity in deep neural networks"></a>On original and latent space connectivity in deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06816">http://arxiv.org/abs/2311.06816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boyang Gu, Anastasia Borovykh</li>
<li>for: 研究了 Whether inputs from the same class can be connected by a continuous path in the original or latent representation space, and how the neural network views its own input space and the structure of the latent spaces.</li>
<li>methods: 使用了 Neural network models to study the connectivity of same-class inputs and the structure of the latent spaces.</li>
<li>results: 发现了 All points on the path are mapped by the neural network model to the same class, and paths, linear or nonlinear, connecting same-class inputs exist in all cases studied.<details>
<summary>Abstract</summary>
We study whether inputs from the same class can be connected by a continuous path, in original or latent representation space, such that all points on the path are mapped by the neural network model to the same class. Understanding how the neural network views its own input space and how the latent spaces are structured has value for explainability and robustness. We show that paths, linear or nonlinear, connecting same-class inputs exist in all cases studied.
</details>
<details>
<summary>摘要</summary>
我们研究 Whether inputs from the same class can be connected by a continuous path, in original or latent representation space, such that all points on the path are mapped by the neural network model to the same class. 理解 neural network 对自己的输入空间的看法和离散空间的结构有价值，用于解释性和稳定性。 我们显示，在所有研究的 случаeschina，同类输入的路径，线性或非线性，都存在。
</details></li>
</ul>
<hr>
<h2 id="MetaMix-Meta-state-Precision-Searcher-for-Mixed-precision-Activation-Quantization"><a href="#MetaMix-Meta-state-Precision-Searcher-for-Mixed-precision-Activation-Quantization" class="headerlink" title="MetaMix: Meta-state Precision Searcher for Mixed-precision Activation Quantization"></a>MetaMix: Meta-state Precision Searcher for Mixed-precision Activation Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06798">http://arxiv.org/abs/2311.06798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han-Byul Kim, Joo Hyung Lee, Sungjoo Yoo, Hong-Seok Kim</li>
<li>for: 提高混合精度量化的精度和效率，解决活动不稳定性问题</li>
<li>methods: 提出一种名为MetaMix的新方法，包括位数选择和Weight训练两个阶段，均可减少混合精度量化中的活动不稳定性问题，并且可以快速完成位数选择和Weight训练</li>
<li>results: 通过在MobileNet v2和v3，以及ResNet-18上进行图像Net的实验，显示我们提出的方法可以超越混合和单精度SOTA方法，在精度vs运算数上push混合精度量化的边界<details>
<summary>Abstract</summary>
Mixed-precision quantization of efficient networks often suffer from activation instability encountered in the exploration of bit selections. To address this problem, we propose a novel method called MetaMix which consists of bit selection and weight training phases. The bit selection phase iterates two steps, (1) the mixed-precision-aware weight update, and (2) the bit-search training with the fixed mixed-precision-aware weights, both of which combined reduce activation instability in mixed-precision quantization and contribute to fast and high-quality bit selection. The weight training phase exploits the weights and step sizes trained in the bit selection phase and fine-tunes them thereby offering fast training. Our experiments with efficient and hard-to-quantize networks, i.e., MobileNet v2 and v3, and ResNet-18 on ImageNet show that our proposed method pushes the boundary of mixed-precision quantization, in terms of accuracy vs. operations, by outperforming both mixed- and single-precision SOTA methods.
</details>
<details>
<summary>摘要</summary>
通常，混合精度量化的高效网络会遇到活动不稳定性问题，这是在探索比选择中出现的问题。为解决这个问题，我们提出了一种新方法called MetaMix，它包括比选择和重量训练两个阶段。比选择阶段包括两步：（1）混合精度意识的Weight更新，和（2）固定混合精度意识的比选择训练，这两个步骤共同减少了混合精度量化中的活动不稳定性，并且对快速和高质量的比选择做出了贡献。重量训练阶段利用了在比选择阶段训练的 weights和 step sizes，并对它们进行了细调，从而提供了快速的训练。我们对高效和难以量化的网络，如MobileNet v2和v3，以及ResNet-18在ImageNet上进行了实验，结果表明，我们的提出的方法可以超越混合和单精度的SOTA方法，在精度vs操作方面Push the boundary of mixed-precision quantization。
</details></li>
</ul>
<hr>
<h2 id="Deep-Perspective-Transformation-Based-Vehicle-Localization-on-Bird’s-Eye-View"><a href="#Deep-Perspective-Transformation-Based-Vehicle-Localization-on-Bird’s-Eye-View" class="headerlink" title="Deep Perspective Transformation Based Vehicle Localization on Bird’s Eye View"></a>Deep Perspective Transformation Based Vehicle Localization on Bird’s Eye View</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06796">http://arxiv.org/abs/2311.06796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ipm-hpc/perspective-bev-transformer">https://github.com/ipm-hpc/perspective-bev-transformer</a></li>
<li>paper_authors: Abtin Mahyar, Hossein Motamednia, Dara Rahmati</li>
<li>for: 提高自动驾驶车 Navigation 系统的准确性和效率，提供丰富的环境数据 для下游任务。</li>
<li>methods: 使用 bird’s-eye-view 映射将 perspective 视图RGB 图像转换为分割环境汽车的映射，提供高效且成本低的环境信息获取方法。</li>
<li>results: 提供了一个新的合成数据集，包含了一系列包含 ego 车和其环境的帧图像，为同类下游任务提供了丰富的资源。<details>
<summary>Abstract</summary>
An accurate understanding of a self-driving vehicle's surrounding environment is crucial for its navigation system. To enhance the effectiveness of existing algorithms and facilitate further research, it is essential to provide comprehensive data to the routing system. Traditional approaches rely on installing multiple sensors to simulate the environment, leading to high costs and complexity. In this paper, we propose an alternative solution by generating a top-down representation of the scene, enabling the extraction of distances and directions of other cars relative to the ego vehicle. We introduce a new synthesized dataset that offers extensive information about the ego vehicle and its environment in each frame, providing valuable resources for similar downstream tasks. Additionally, we present an architecture that transforms perspective view RGB images into bird's-eye-view maps with segmented surrounding vehicles. This approach offers an efficient and cost-effective method for capturing crucial environmental information for self-driving cars. Code and dataset are available at https://github.com/IPM-HPC/Perspective-BEV-Transformer.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese一个准确的自驾车环境理解对其导航系统是非常重要的。为了提高现有算法的效iveness和促进进一步的研究，提供全面的数据给路由系统是必要的。传统的方法通过安装多个感测器来模拟环境，这会导致高成本和复杂性。在这篇论文中，我们提出一个 alternativesolution，通过生成顶部视图的场景表示，以提取相对于egos车的其他车辆的距离和方向。我们介绍了一个新的合成数据集，该数据集在每帧中提供了 egos车和其environments的广泛信息，这将为下游任务提供优质的资源。此外，我们提出了一种将平视图RGB图像转换为鸟瞰视图地图的架构，该approach可以有效地和经济地记录自驾车环境中的重要信息。代码和数据集可以在https://github.com/IPM-HPC/Perspective-BEV-Transformer上下载。
</details></li>
</ul>
<hr>
<h2 id="CL-Flow-Strengthening-the-Normalizing-Flows-by-Contrastive-Learning-for-Better-Anomaly-Detection"><a href="#CL-Flow-Strengthening-the-Normalizing-Flows-by-Contrastive-Learning-for-Better-Anomaly-Detection" class="headerlink" title="CL-Flow:Strengthening the Normalizing Flows by Contrastive Learning for Better Anomaly Detection"></a>CL-Flow:Strengthening the Normalizing Flows by Contrastive Learning for Better Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06794">http://arxiv.org/abs/2311.06794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunfeng Wang, Yueyang Li, Haichi Luo, Chenyang Bi</li>
<li>for: 这个论文主要关注于自适应异常检测领域中的异常样本稀缺问题，提出了一种自我监督异常检测方法， combinig contrastive learning with 2D-Flow，以提高检测精度和减少计算成本。</li>
<li>methods: 本文提出了一种新的异常生成方法，通过模拟真实的工业场景来生成异常样本，并对2D-Flow框架进行了改进，通过多种代理任务来练级网络，以提高异常检测精度。</li>
<li>results: 比较主流的无监督方法，本文的自我监督方法在MVTecAD和BTAD datasets上达到了新的州态艺术率记录，分别为99.6%和96.8%。<details>
<summary>Abstract</summary>
In the anomaly detection field, the scarcity of anomalous samples has directed the current research emphasis towards unsupervised anomaly detection. While these unsupervised anomaly detection methods offer convenience, they also overlook the crucial prior information embedded within anomalous samples. Moreover, among numerous deep learning methods, supervised methods generally exhibit superior performance compared to unsupervised methods. Considering the reasons mentioned above, we propose a self-supervised anomaly detection approach that combines contrastive learning with 2D-Flow to achieve more precise detection outcomes and expedited inference processes. On one hand, we introduce a novel approach to anomaly synthesis, yielding anomalous samples in accordance with authentic industrial scenarios, alongside their surrogate annotations. On the other hand, having obtained a substantial number of anomalous samples, we enhance the 2D-Flow framework by incorporating contrastive learning, leveraging diverse proxy tasks to fine-tune the network. Our approach enables the network to learn more precise mapping relationships from self-generated labels while retaining the lightweight characteristics of the 2D-Flow. Compared to mainstream unsupervised approaches, our self-supervised method demonstrates superior detection accuracy, fewer additional model parameters, and faster inference speed. Furthermore, the entire training and inference process is end-to-end. Our approach showcases new state-of-the-art results, achieving a performance of 99.6\% in image-level AUROC on the MVTecAD dataset and 96.8\% in image-level AUROC on the BTAD dataset.
</details>
<details>
<summary>摘要</summary>
在异常检测领域，缺乏异常样本导致当前研究强调无监督异常检测。而这些无监督异常检测方法尽管方便，但它们也忽略了异常样本中关键的先前信息。此外，深度学习方法中，监督方法通常比无监督方法表现更优。针对以上原因，我们提出一种自我监督异常检测方法，将对比学习与2D-Flow结合使用，以实现更精准的检测结果和加速的检测过程。一方面，我们提出了一种新的异常生成方法，生成了符合实际工业场景的异常样本，并同时提供了代表性的注释。另一方面，通过获得大量异常样本，我们改进了2D-Flow框架，通过对多个代理任务进行细化 parameter 的网络。我们的方法使得网络可以从自己生成的标签中学习更精准的映射关系，同时保持2D-Flow的轻量级特性。相比主流无监督方法，我们的自我监督方法在检测精度、额外参数数量和检测速度方面均表现出优异。此外，整个训练和检测过程是端到端的。我们的方法在MVTecAD数据集上达到了图像级AUROC99.6%和BTAD数据集上达到了图像级AUROC96.8%的新状态纪录。
</details></li>
</ul>
<hr>
<h2 id="IMPUS-Image-Morphing-with-Perceptually-Uniform-Sampling-Using-Diffusion-Models"><a href="#IMPUS-Image-Morphing-with-Perceptually-Uniform-Sampling-Using-Diffusion-Models" class="headerlink" title="IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models"></a>IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06792">http://arxiv.org/abs/2311.06792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyuan Yang, Zhengyang Yu, Zhiwei Xu, Jaskirat Singh, Jing Zhang, Dylan Campbell, Peter Tu, Richard Hartley</li>
<li>for: 生成smooth、direct、realistic的图像变换</li>
<li>methods: 利用扩散模型、 lokally线性和Gaussian latent space进行图像 interpolating</li>
<li>results:  suppresses ghosting artifacts、achieves smooth、direct、realistic image morphingHere’s a more detailed explanation of each point:</li>
<li>for: The paper is written to present a new method for image morphing, which is a technique used to transform one image into another. The goal is to create smooth, direct, and realistic changes between the two images.</li>
<li>methods: The proposed method uses a diffusion-based image morphing approach with perceptually-uniform sampling (IMPUS). This method leverages a latent diffusion model that has distinct conditional distributions and data embeddings for each of the two images, especially when they are from different classes. To bridge the gap between the two images, the method interpolates in the locally linear and continuous text embedding space and Gaussian latent space. Additionally, the method uses an adaptive bottleneck constraint based on a novel relative perceptual path diversity score to control the bottleneck size and balance the diversity along the path with its directness.</li>
<li>results: The proposed method can achieve smooth, direct, and realistic image morphing. Extensive experiments validate that the method can be applied to other image generation tasks. Additionally, the method suppresses ghosting artifacts, which are common in traditional image morphing techniques.<details>
<summary>Abstract</summary>
We present a diffusion-based image morphing approach with perceptually-uniform sampling (IMPUS) that produces smooth, direct, and realistic interpolations given an image pair. A latent diffusion model has distinct conditional distributions and data embeddings for each of the two images, especially when they are from different classes. To bridge this gap, we interpolate in the locally linear and continuous text embedding space and Gaussian latent space. We first optimize the endpoint text embeddings and then map the images to the latent space using a probability flow ODE. Unlike existing work that takes an indirect morphing path, we show that the model adaptation yields a direct path and suppresses ghosting artifacts in the interpolated images. To achieve this, we propose an adaptive bottleneck constraint based on a novel relative perceptual path diversity score that automatically controls the bottleneck size and balances the diversity along the path with its directness. We also propose a perceptually-uniform sampling technique that enables visually smooth changes between the interpolated images. Extensive experiments validate that our IMPUS can achieve smooth, direct, and realistic image morphing and be applied to other image generation tasks.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于扩散的图像融合方法（IMPUS），该方法可以生成基于图像对的平滑、直接和实际的插值。我们的模型具有不同类别图像的独特条件分布和数据嵌入，因此在 interpolating 图像时需要 bridge 这个差异。我们使用了在本地线性和连续的文本嵌入空间和高斯嵌入空间进行 interpolating，首先优化终点文本嵌入，然后将图像映射到嵌入空间使用概率流ODE。不同于现有的工作，我们的模型适应化可以实现直接的插值路径，并且可以抑制抽象残余 artifacts。为了实现这一点，我们提出了一种自适应瓶颈约束，该约束基于一种新的相对感知路径多样性分数，可以自动控制瓶颈大小，并且可以在路径上保持视觉平滑的变化。我们还提出了一种可视平滑的抽象采样技术，可以在 interpolating 图像时使得变化更加平滑。我们的IMPUS可以实现平滑、直接和实际的图像插值，并且可以应用于其他图像生成任务。
</details></li>
</ul>
<hr>
<h2 id="InfMLLM-A-Unified-Framework-for-Visual-Language-Tasks"><a href="#InfMLLM-A-Unified-Framework-for-Visual-Language-Tasks" class="headerlink" title="InfMLLM: A Unified Framework for Visual-Language Tasks"></a>InfMLLM: A Unified Framework for Visual-Language Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06791">http://arxiv.org/abs/2311.06791</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mightyzau/infmllm">https://github.com/mightyzau/infmllm</a></li>
<li>paper_authors: Qiang Zhou, Zhibin Wang, Wei Chu, Yinghui Xu, Hao Li, Yuan Qi</li>
<li>for: 这个论文的目的是扩展大语言模型（LLM）的能力，以涵盖更广泛的语言相关应用。</li>
<li>methods: 该论文使用了三个阶段的训练方案：开始 WITH 轻量级含义预处理，然后是中量级多任务混合训练，最后是 LLJ 练习以提高 instrux following 能力。</li>
<li>results: 该论文的实验结果表明，通过使用 pool-adapter 模块保持视觉嵌入的 pozitional 信息，对于如 visual grounding 等任务具有特别的 beneficial 效果。 InfMLLM 的性能达到了或与最新的 MLLM 相当。 代码和模型将在：\url{<a target="_blank" rel="noopener" href="https://github.com/mightyzau/InfMLLM%7D">https://github.com/mightyzau/InfMLLM}</a> 上开源。<details>
<summary>Abstract</summary>
Large language models (LLMs) have proven their remarkable versatility in handling a comprehensive range of language-centric applications. To expand LLMs' capabilities to a broader spectrum of modal inputs, multimodal large language models (MLLMs) have attracted growing interest. This work delves into enabling LLMs to tackle more vision-language-related tasks, particularly image captioning, visual question answering (VQA,) and visual grounding. To this end, we implemented a three-stage training scheme: starting with lightweight alignment pretraining, then moderate-weight multitask hybrid training, and finally, LLM fine-tuning to improve instruction following capability. Throughout the training process, the requirements on GPU memory gradually increase. To effectively manage the number of visual embeddings passed to the LLM while preserving their positional information, we introduce a straightforward visual adapter module dubbed pool-adapter. Our experiments demonstrate that preserving the positional information of visual embeddings through the pool-adapter is particularly beneficial for tasks like visual grounding. We name our proposed approach InfMLLM and have evaluated it extensively on various benchmark datasets. Our results demonstrate that InfMLLM achieves either state-of-the-art (SOTA) performance or performance comparable to recent MLLMs. The code and model will be made open-source at: \url{https://github.com/mightyzau/InfMLLM}.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经证明了它们在处理广泛的语言相关应用方面的卓越多样性。为了扩展LLM的能力到更广泛的模式输入，多模式大型语言模型（MLLM）在最近引起了越来越多的关注。这个工作探索了将LLM应用到更多的视觉语言相关任务，特别是图像描述、视觉问题答案（VQA）和视觉定位。为此，我们采用了三阶段训练方案：首先是轻量级Alignment预训练，然后是中量级多任务混合训练，最后是LLM精细调整以提高指令遵循能力。在训练过程中，GPU内存的需求逐渐增加。为了有效地管理LLM接受的视觉嵌入的数量，我们提出了一个简单的视觉适配器模组，名为pool适配器。我们的实验表明，通过pool适配器保留视觉嵌入的位置信息是特别有益于像定位任务。我们统称我们的提案为InfMLLM，并对多个benchmark数据集进行了广泛的评估。我们的结果显示InfMLLM在不同的任务上均可以 achieve state-of-the-art（SOTA）性或与最近的MLLMs相似的性能。我们将代码和模型公开发布在：<https://github.com/mightyzau/InfMLLM>。
</details></li>
</ul>
<hr>
<h2 id="Explainability-of-Vision-Transformers-A-Comprehensive-Review-and-New-Perspectives"><a href="#Explainability-of-Vision-Transformers-A-Comprehensive-Review-and-New-Perspectives" class="headerlink" title="Explainability of Vision Transformers: A Comprehensive Review and New Perspectives"></a>Explainability of Vision Transformers: A Comprehensive Review and New Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06786">http://arxiv.org/abs/2311.06786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rojina Kashefi, Leili Barekatain, Mohammad Sabokrou, Fatemeh Aghaeipoor</li>
<li>for: 本研究旨在解释视觉转换器（ViT）的工作原理和决策基础。</li>
<li>methods: 本研究提出了不同的解释方法，并对其进行了分类和评价。</li>
<li>results: 本研究提供了一份完整的评价标准和解释工具框架，以及未经探索的重要方向和未来投资领域。<details>
<summary>Abstract</summary>
Transformers have had a significant impact on natural language processing and have recently demonstrated their potential in computer vision. They have shown promising results over convolution neural networks in fundamental computer vision tasks. However, the scientific community has not fully grasped the inner workings of vision transformers, nor the basis for their decision-making, which underscores the importance of explainability methods. Understanding how these models arrive at their decisions not only improves their performance but also builds trust in AI systems. This study explores different explainability methods proposed for visual transformers and presents a taxonomy for organizing them according to their motivations, structures, and application scenarios. In addition, it provides a comprehensive review of evaluation criteria that can be used for comparing explanation results, as well as explainability tools and frameworks. Finally, the paper highlights essential but unexplored aspects that can enhance the explainability of visual transformers, and promising research directions are suggested for future investment.
</details>
<details>
<summary>摘要</summary>
<<SYS>>transformers 对自然语言处理和计算机视觉有很大的影响，最近在基本计算机视觉任务中表现出色。然而，科学社区对视觉transformers 的内部工作和决策基础还没有全面理解，这标志着解释方法的重要性。理解这些模型如何做出决策不仅提高了它们的性能，还可以帮助建立对 AI 系统的信任。本文探讨了不同的解释方法，并对它们进行了分类，按照它们的动机、结构和应用场景进行排序。此外，文章还提供了评估解释结果的标准化评价标准，以及解释工具和框架。最后，文章强调了对视觉transformers 的解释仍然存在一些不足之处，并提出了未来投入的潜在研究方向。>>>
</details></li>
</ul>
<hr>
<h2 id="Q-Instruct-Improving-Low-level-Visual-Abilities-for-Multi-modality-Foundation-Models"><a href="#Q-Instruct-Improving-Low-level-Visual-Abilities-for-Multi-modality-Foundation-Models" class="headerlink" title="Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models"></a>Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06783">http://arxiv.org/abs/2311.06783</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Q-Future/Q-Instruct">https://github.com/Q-Future/Q-Instruct</a></li>
<li>paper_authors: Haoning Wu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Annan Wang, Kaixin Xu, Chunyi Li, Jingwen Hou, Guangtao Zhai, Geng Xue, Wenxiu Sun, Qiong Yan, Weisi Lin</li>
<li>for: 增强基础模型对低级视觉任务的能力，包括对图像的识别、分类、描述等。</li>
<li>methods: 基于GPT-4V的多模态基础模型，通过大规模人工反馈的集成，提高低级视觉任务的能力。</li>
<li>results: 经过大规模人工反馈的集成，可以提高基础模型对低级视觉任务的能力，并且可以让基础模型更好地理解和评价图像的低级视觉特征。<details>
<summary>Abstract</summary>
Multi-modality foundation models, as represented by GPT-4V, have brought a new paradigm for low-level visual perception and understanding tasks, that can respond to a broad range of natural human instructions in a model. While existing foundation models have shown exciting potentials on low-level visual tasks, their related abilities are still preliminary and need to be improved. In order to enhance these models, we conduct a large-scale subjective experiment collecting a vast number of real human feedbacks on low-level vision. Each feedback follows a pathway that starts with a detailed description on the low-level visual appearance (*e.g. clarity, color, brightness* of an image, and ends with an overall conclusion, with an average length of 45 words. The constructed **Q-Pathway** dataset includes 58K detailed human feedbacks on 18,973 images with diverse low-level appearance. Moreover, to enable foundation models to robustly respond to diverse types of questions, we design a GPT-participated conversion to process these feedbacks into diverse-format 200K instruction-response pairs. Experimental results indicate that the **Q-Instruct** consistently elevates low-level perception and understanding abilities across several foundational models. We anticipate that our datasets can pave the way for a future that general intelligence can perceive, understand low-level visual appearance and evaluate visual quality like a human. Our dataset, model zoo, and demo is published at: https://q-future.github.io/Q-Instruct.
</details>
<details>
<summary>摘要</summary>
多Modal基础模型，如GPT-4V，已经带来了一个新的LOW级视觉理解和任务框架，可以回应人类的各种自然指令。现有的基础模型有很多潜在的能力，但它们的相关能力还需要进一步提高。为了提高这些模型，我们进行了大规模的主观实验，收集了大量真正的人类反馈，每个反馈都包括一个详细的LOW级视觉出现（如清晰度、颜色、亮度等）的描述，以及一个总结，平均长度为45个单词。我们构建了**Q-Pathway**数据集，包含58000个详细的人类反馈，对18973张图像进行了多种LOW级视觉出现。此外，为了让基础模型能够有效地回应多种问题，我们设计了一种GPT参与的转换，将这些反馈转换为多种格式的200000个指令响应对。实验结果表明，**Q-Instruct**可以不断提高基础模型的LOW级视觉理解和识别能力。我们预计，我们的数据集、模型 zoological和示例将在未来为一个人类智能感知、理解LOW级视觉出现和评估视觉质量的未来开拓道路。我们的数据集、模型 zoo和示例可以在：https://q-future.github.io/Q-Instruct 中找到。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/cs.CV_2023_11_12/" data-id="clp89dofp00msi788cd06fqr2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/cs.AI_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T12:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/cs.AI_2023_11_12/">cs.AI - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Creating-a-Discipline-specific-Commons-for-Infectious-Disease-Epidemiology"><a href="#Creating-a-Discipline-specific-Commons-for-Infectious-Disease-Epidemiology" class="headerlink" title="Creating a Discipline-specific Commons for Infectious Disease Epidemiology"></a>Creating a Discipline-specific Commons for Infectious Disease Epidemiology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06989">http://arxiv.org/abs/2311.06989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael M. Wagner, William Hogan, John Levander, Adam Darr, Matt Diller, Max Sibilla, Alexander T. Loiacono. Terence Sperringer, Jr., Shawn T. Brown</li>
<li>for: 本研究目的是建立一个感染病谱（ID） epidemiology共享平台，让 epidemiologists、公共卫生官员、数据生产者和软件开发者可以不仅分享数据和软件，还可以在改进它们的可操作性方面得到帮助。</li>
<li>methods: 本研究使用OWL 2和逻辑查询来推导可能兼容的软件和数据集组合，以及这些组合的统计信息。同时， authors 还使用 DATS 2.2 和自己设计的软件元数据Schema来表示对象。</li>
<li>results: 研究发现，由于软件输入&#x2F;输出格式的标准化不足，实现可操作性受限。然而，逻辑搜索基于名称的数据格式的 triple store 仍然能够确定众多的可能兼容的软件和数据集组合。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Objective: To create a commons for infectious disease (ID) epidemiology in which epidemiologists, public health officers, data producers, and software developers can not only share data and software, but receive assistance in improving their interoperability. Materials and Methods: We represented 586 datasets, 54 software, and 24 data formats in OWL 2 and then used logical queries to infer potentially interoperable combinations of software and datasets, as well as statistics about the FAIRness of the collection. We represented the objects in DATS 2.2 and a software metadata schema of our own design. We used these representations as the basis for the Content, Search, FAIR-o-meter, and Workflow pages that constitute the MIDAS Digital Commons. Results: Interoperability was limited by lack of standardization of input and output formats of software. When formats existed, they were human-readable specifications (22/24; 92%); only 3 formats (13%) had machine-readable specifications. Nevertheless, logical search of a triple store based on named data formats was able to identify scores of potentially interoperable combinations of software and datasets. Discussion: We improved the findability and availability of a sample of software and datasets and developed metrics for assessing interoperability. The barriers to interoperability included poor documentation of software input/output formats and little attention to standardization of most types of data in this field. Conclusion: Centralizing and formalizing the representation of digital objects within a commons promotes FAIRness, enables its measurement over time and the identification of potentially interoperable combinations of data and software.
</details>
<details>
<summary>摘要</summary>
目标：创建一个媒体共享平台 для感染病（ID）epidemiology，让感染病学家、公共卫生官员、数据生产者和软件开发者可以不仅分享数据和软件，而且在提高它们的相互适用性方面获得帮助。材料和方法：我们将586个数据集、54个软件和24个数据格式表示为OWL 2，然后使用逻辑查询来推理可能相互适用的软件和数据集的组合，以及这些集合的统计数据。我们使用这些表示来构建Content、搜索、FAIR-o-meter和工作流页面，这些页面组成了MIDAS数字共享平台。结果：宏观的可操作性受到数据集和软件之间的标准化问题的限制。虽然大多数数据格式有人类可读的规范（22/24，92%），但只有13%的格式有机器可读的规范。然而，基于命名数据格式的 triple store 上的逻辑搜索仍可以identify scores of potentially interoperable combinations of software and datasets。讨论：我们提高了一个样本的软件和数据集的可用性和找到性，并开发了评估相互适用性的 metrics。障碍因子包括感染病软件的输入/输出格式的ocumentation缺乏和这个领域大多数数据类型的标准化得 little attention。结论：在一个共享平台上中央和正式地表示数字对象可以提高FAIRness，并且可以随时衡量和识别数据和软件之间的可能相互适用组合。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Interpretability-of-Programmatic-Policies-with-Large-Language-Models"><a href="#Assessing-the-Interpretability-of-Programmatic-Policies-with-Large-Language-Models" class="headerlink" title="Assessing the Interpretability of Programmatic Policies with Large Language Models"></a>Assessing the Interpretability of Programmatic Policies with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06979">http://arxiv.org/abs/2311.06979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Bashir, Michael Bowling, Levi H. S. Lelis</li>
<li>for: 这篇论文目的是评估程序编程策略的可解性。</li>
<li>methods: 这篇论文使用大型自然语言模型（LLM）来评估程序编程策略的可解性。</li>
<li>results: 该评估方法可以准确地评估程序编程策略的可解性，并且可以用来比较不同的程序编程策略的可解性水平。<details>
<summary>Abstract</summary>
Although the synthesis of programs encoding policies often carries the promise of interpretability, systematic evaluations to assess the interpretability of these policies were never performed, likely because of the complexity of such an evaluation. In this paper, we introduce a novel metric that uses large-language models (LLM) to assess the interpretability of programmatic policies. For our metric, an LLM is given both a program and a description of its associated programming language. The LLM then formulates a natural language explanation of the program. This explanation is subsequently fed into a second LLM, which tries to reconstruct the program from the natural language explanation. Our metric measures the behavioral similarity between the reconstructed program and the original. We validate our approach using obfuscated programs that are used to solve classic programming problems. We also assess our metric with programmatic policies synthesized for playing a real-time strategy game, comparing the interpretability scores of programmatic policies synthesized by an existing system to lightly obfuscated versions of the same programs. Our LLM-based interpretability score consistently ranks less interpretable programs lower and more interpretable ones higher. These findings suggest that our metric could serve as a reliable and inexpensive tool for evaluating the interpretability of programmatic policies.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:尽管编译程序策略的合成 часто承诺可读性，但系统性的评估以评估这些策略的可读性从未进行过，可能是因为评估的复杂性。在这篇论文中，我们引入了一个新的指标，使用大型自然语言模型（LLM）来评估程序策略的可读性。我们给LLM提供了一个程序和其关联的编程语言描述。LLM然后将程序转换成自然语言形式的解释。这个解释被Feed入第二个LLM，它尝试从自然语言解释中重构程序。我们的指标测量重构后的程序与原始程序之间的行为相似性。我们验证我们的方法使用了难以解读的程序，用于解决经典编程问题。我们还对使用LLM进行评估的程序策略与轻微隐藏版本的同样程序进行比较。我们的LLM可读性分数一直 ranks不可读性程序低和可读性程序高。这些发现表示我们的指标可能是一种可靠且便宜的评估程序策略可读性的工具。
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Data-Denoising-for-Real-Life-Sensing-Systems"><a href="#Physics-Informed-Data-Denoising-for-Real-Life-Sensing-Systems" class="headerlink" title="Physics-Informed Data Denoising for Real-Life Sensing Systems"></a>Physics-Informed Data Denoising for Real-Life Sensing Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06968">http://arxiv.org/abs/2311.06968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiyuan Zhang, Xiaohan Fu, Diyan Teng, Chengyu Dong, Keerthivasan Vijayakumar, Jiayun Zhang, Ranak Roy Chowdhury, Junsheng Han, Dezhi Hong, Rashmi Kulkarni, Jingbo Shang, Rajesh Gupta</li>
<li>for: 这篇论文是为了提出一种基于物理法则的实时减杂模型，以提高实际应用中的感应器资料品质。</li>
<li>methods: 这篇论文使用的方法是基于物理法则的实时减杂模型，利用不同感应器测值之间的物理关系来导正减杂过程，不需要使用实际减杂数据。</li>
<li>results: 这篇论文的实验结果显示，这种基于物理法则的实时减杂模型可以在不同领域中实现高性能，例如陀螺仪 Navigation、CO2监控和HVAC控制，并且可以实现实时减杂（4ms для每一秒的序列），与高精度、高成本的替代方法相匹配。<details>
<summary>Abstract</summary>
Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects performance and reliability of the systems they support. Classic filtering-based approaches introduce strong assumptions on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.
</details>
<details>
<summary>摘要</summary>
现代互连世界中的感测器广泛存在，这些感测器自然带有噪声，这些噪声可能会影响感测器支持的系统性能和可靠性。 классический滤波器基本方法假设时间或频率特性的感测值，而学习基于权重的净化方法通常需要使用clean数据来训练净化模型，这在许多实际应用中是困难或不可能的。我们发现，在许多场景下，不同感测值之间的关系可以通过物理法则（如二阶差分方程）进行描述。我们可以利用这些物理约束，导引净化过程，以提高净化效果，甚至在clean数据不可获得的情况下。在这个意义上，我们设计了物理约束净化模型，利用不同感测值之间的物理关系，从而减少了净化过程中的噪声。我们的方法不需要clean数据，可以在实时（4毫秒）内进行净化，并且与高精度、高成本的alternative结果高度一致，从而提供了高效、成本效果的净化方案。
</details></li>
</ul>
<hr>
<h2 id="Towards-probabilistic-Weather-Forecasting-with-Conditioned-Spatio-Temporal-Normalizing-Flows"><a href="#Towards-probabilistic-Weather-Forecasting-with-Conditioned-Spatio-Temporal-Normalizing-Flows" class="headerlink" title="Towards probabilistic Weather Forecasting with Conditioned Spatio-Temporal Normalizing Flows"></a>Towards probabilistic Weather Forecasting with Conditioned Spatio-Temporal Normalizing Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06958">http://arxiv.org/abs/2311.06958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christina Winkler</li>
<li>for: 这篇论文是为了模型随机空间时间分布而写的。</li>
<li>methods: 这篇论文使用 conditional normalizing flows 来实现随机空间时间模型。</li>
<li>results: 实验表明，这种方法能够捕捉随机空间时间的相关性，并可以在训练时间以外的时间范围内预测。Here’s the English version for reference:</li>
<li>for: This paper is written for modeling multimodal spatial distributions and capturing temporal correlations.</li>
<li>methods: The paper uses conditional normalizing flows to achieve stochastic spatio-temporal modeling.</li>
<li>results: Experiments show that the method can capture spatio-temporal correlations and extrapolate well beyond the training time horizon.<details>
<summary>Abstract</summary>
Generative normalizing flows are able to model multimodal spatial distributions, and they have been shown to model temporal correlations successfully as well. These models provide several benefits over other types of generative models due to their training stability, invertibility and efficiency in sampling and inference. This makes them a suitable candidate for stochastic spatio-temporal prediction problems, which are omnipresent in many fields of sciences, such as earth sciences, astrophysics or molecular sciences. In this paper, we present conditional normalizing flows for stochastic spatio-temporal modelling. The method is evaluated on the task of daily temperature and hourly geopotential map prediction from ERA5 datasets. Experiments show that our method is able to capture spatio-temporal correlations and extrapolates well beyond the time horizon used during training.
</details>
<details>
<summary>摘要</summary>
<?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" /><?xml:namespace prefix = "dfx" ns = "http://schemas.openxmlformats.org/officeDocument/2006/dfx" /><?xml:namespace prefix = "
</details></li>
</ul>
<hr>
<h2 id="FLASH-RL-Federated-Learning-Addressing-System-and-Static-Heterogeneity-using-Reinforcement-Learning"><a href="#FLASH-RL-Federated-Learning-Addressing-System-and-Static-Heterogeneity-using-Reinforcement-Learning" class="headerlink" title="FLASH-RL: Federated Learning Addressing System and Static Heterogeneity using Reinforcement Learning"></a>FLASH-RL: Federated Learning Addressing System and Static Heterogeneity using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06917">http://arxiv.org/abs/2311.06917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sofianebouaziz1/FLASH-RL">https://github.com/Sofianebouaziz1/FLASH-RL</a></li>
<li>paper_authors: Sofiane Bouaziz, Hadjer Benmeziane, Youcef Imine, Leila Hamdad, Smail Niar, Hamza Ouarnoughi</li>
<li>for: 这篇论文主要关注的是联合学习（Federated Learning，FL）中的训练执行效率和稳定性，以及如何对应系统和静态不统一性。</li>
<li>methods: 本文提出了一个名为FLASH-RL的框架，使用了双层深度问题学习（Double Deep Q-Learning，DDQL）来解决系统和静态不统一性。此外，本文还引入了一个名为“实验增强”的新的评估函数，以评估客户端的贡献度。</li>
<li>results: 实验结果显示，FLASH-RL可以实现与现有解决方案相对的平衡，即模型性能和终端延迟之间的平衡。具体来说，FLASH-RL可以对MNIST和CIFAR-10数据集进行训练，并且在训练轮次和终端延迟方面实现了24.83%和24.67%的提升。此外，FLASH-RL还可以实现模型性能和训练轮次之间的平衡，并且在滑块检测中实现了2.82%的提升。<details>
<summary>Abstract</summary>
Federated Learning (FL) has emerged as a promising Machine Learning paradigm, enabling multiple users to collaboratively train a shared model while preserving their local data. To minimize computing and communication costs associated with parameter transfer, it is common practice in FL to select a subset of clients in each training round. This selection must consider both system and static heterogeneity. Therefore, we propose FLASH-RL, a framework that utilizes Double Deep QLearning (DDQL) to address both system and static heterogeneity in FL. FLASH-RL introduces a new reputation-based utility function to evaluate client contributions based on their current and past performances. Additionally, an adapted DDQL algorithm is proposed to expedite the learning process. Experimental results on MNIST and CIFAR-10 datasets have shown FLASH-RL's effectiveness in achieving a balanced trade-off between model performance and end-to-end latency against existing solutions. Indeed, FLASH-RL reduces latency by up to 24.83% compared to FedAVG and 24.67% compared to FAVOR. It also reduces the training rounds by up to 60.44% compared to FedAVG and +76% compared to FAVOR. In fall detection using the MobiAct dataset, FLASH-RL outperforms FedAVG by up to 2.82% in model's performance and reduces latency by up to 34.75%. Additionally, FLASH-RL achieves the target performance faster, with up to a 45.32% reduction in training rounds compared to FedAVG.
</details>
<details>
<summary>摘要</summary>
Federated Learning (FL) 已经成为一种有前途的机器学习方法，允许多个用户共同训练共享模型，保留他们的本地数据。为了降低计算和通信成本相关的参数传输，FL 通常会选择每轮训练中的一 subset of clients。这种选择必须考虑系统和静态不同化。因此，我们提议 FLASH-RL，一个基于 Double Deep QLearning (DDQL) 的框架，用于解决 FL 中的系统和静态不同化。FLASH-RL 引入了一个基于客户端表现的声誉基于的用户贡献函数。此外，我们还提出了一种适应 DDQL 算法，以促进学习过程。实验结果表明，FLASH-RL 在 MNIST 和 CIFAR-10 数据集上可以很好地寻求一个平衡的交易off между模型性能和端到端延迟，相比现有的解决方案。具体来说，FLASH-RL 可以降低延迟时间达到 24.83%，相比 FedAVG 和 FAVOR。它还可以降低训练轮数达到 60.44%，相比 FedAVG 和 FAVOR。在 fall detection 中使用 MobiAct 数据集，FLASH-RL 可以在模型性能方面与 FedAVG 相比提高达 2.82%，并降低延迟时间达 34.75%。此外，FLASH-RL 可以更快地实现目标性能，相比 FedAVG 的训练轮数减少达 45.32%。
</details></li>
</ul>
<hr>
<h2 id="TSViT-A-Time-Series-Vision-Transformer-for-Fault-Diagnosis"><a href="#TSViT-A-Time-Series-Vision-Transformer-for-Fault-Diagnosis" class="headerlink" title="TSViT: A Time Series Vision Transformer for Fault Diagnosis"></a>TSViT: A Time Series Vision Transformer for Fault Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06916">http://arxiv.org/abs/2311.06916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shouhua Zhang, Jiehan Zhou, Xue Ma, Chenglin Wen, Susanna Pirttikangas, Chen Yu, Weishan Zhang, Chunsheng Yang</li>
<li>For: This paper is written for fault diagnosis in mechanical systems using Convolutional Neural Networks (CNNs) and the Time Series Vision Transformer (TSViT) model.* Methods: The TSViT model uses a combination of convolutional layers to segment vibration signals and capture local features, as well as a transformer encoder to learn long-term temporal information.* Results: The experimental results on two distinct datasets show that TSViT achieves an average accuracy of 100% and 99.99% on two test sets, respectively, outperforming other methods in terms of performance, computational complexity, and parameter quantity.<details>
<summary>Abstract</summary>
Traditional fault diagnosis methods using Convolutional Neural Networks (CNNs) face limitations in capturing temporal features (i.e., the variation of vibration signals over time). To address this issue, this paper introduces a novel model, the Time Series Vision Transformer (TSViT), specifically designed for fault diagnosis. On one hand, TSViT model integrates a convolutional layer to segment vibration signals and capture local features. On the other hand, it employs a transformer encoder to learn long-term temporal information. The experimental results with other methods on two distinct datasets validate the effectiveness and generalizability of TSViT with a comparative analysis of its hyperparameters' impact on model performance, computational complexity, and overall parameter quantity. TSViT reaches average accuracies of 100% and 99.99% on two test sets, correspondingly.
</details>
<details>
<summary>摘要</summary>
传统的疲劳诊断方法使用卷积神经网络（CNN）受到时间特征的限制，这限制了其在捕捉振荡信号的变化过程中的表现。为解决这个问题，本文提出了一种新的模型——时间序列视力 трансформер（TSViT），专门用于疲劳诊断。一方面，TSViT模型包含了一层卷积层，用于分割振荡信号并捕捉本地特征。另一方面，它使用变换器编码器来学习长期的时间特征。实验结果表明，TSViT模型在两个不同的数据集上达到了100%和99.99%的平均准确率，对比其他方法的性能表现明显优于。此外，TSViT模型的计算复杂度和总参数数量也被详细分析。
</details></li>
</ul>
<hr>
<h2 id="Flames-Benchmarking-Value-Alignment-of-Chinese-Large-Language-Models"><a href="#Flames-Benchmarking-Value-Alignment-of-Chinese-Large-Language-Models" class="headerlink" title="Flames: Benchmarking Value Alignment of Chinese Large Language Models"></a>Flames: Benchmarking Value Alignment of Chinese Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06899">http://arxiv.org/abs/2311.06899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kexin Huang, Xiangyang Liu, Qianyu Guo, Tianxiang Sun, Jiawei Sun, Yaru Wang, Zeyang Zhou, Yixu Wang, Yan Teng, Xipeng Qiu, Yingchun Wang, Dahua Lin</li>
<li>for: 本研究旨在评估大语言模型（LLMs）是否与人类价值观align得通。</li>
<li>methods: 本研究提出了首个高度 adversarial benchmark named Flames，包括2,251个手动制作的提问、~18.7K个模型回应、和一个特定的分数器。</li>
<li>results: 根据Flames框架，我们手动制作了逻辑攻击提问，并使用这些提问让主流LLMs回应。我们发现所有评估的LLMs在Flames上表现相对较差，特别是在安全和公平性维度。Claude emerges as the best-performing model overall，但其无害率只有63.08%，而GPT-4的分数只有39.04%。Flames的复杂性已经超越了现有的 benchmark，设置了一个新的挑战 для当代LLMs，并 highlighted the need for further alignment of LLMs。<details>
<summary>Abstract</summary>
The widespread adoption of large language models (LLMs) across various regions underscores the urgent need to evaluate their alignment with human values. Current benchmarks, however, fall short of effectively uncovering safety vulnerabilities in LLMs. Despite numerous models achieving high scores and 'topping the chart' in these evaluations, there is still a significant gap in LLMs' deeper alignment with human values and achieving genuine harmlessness. To this end, this paper proposes the first highly adversarial benchmark named Flames, consisting of 2,251 manually crafted prompts, ~18.7K model responses with fine-grained annotations, and a specified scorer. Our framework encompasses both common harmlessness principles, such as fairness, safety, legality, and data protection, and a unique morality dimension that integrates specific Chinese values such as harmony. Based on the framework, we carefully design adversarial prompts that incorporate complex scenarios and jailbreaking methods, mostly with implicit malice. By prompting mainstream LLMs with such adversarially constructed prompts, we obtain model responses, which are then rigorously annotated for evaluation. Our findings indicate that all the evaluated LLMs demonstrate relatively poor performance on Flames, particularly in the safety and fairness dimensions. Claude emerges as the best-performing model overall, but with its harmless rate being only 63.08% while GPT-4 only scores 39.04%. The complexity of Flames has far exceeded existing benchmarks, setting a new challenge for contemporary LLMs and highlighting the need for further alignment of LLMs. To efficiently evaluate new models on the benchmark, we develop a specified scorer capable of scoring LLMs across multiple dimensions, achieving an accuracy of 77.4%. The Flames Benchmark is publicly available on https://github.com/AIFlames/Flames.
</details>
<details>
<summary>摘要</summary>
广泛的大语言模型（LLM）在不同地区的采用，强调了评估它们与人类价值的调和。现有的标准 however，无法有效发现语言模型的安全漏洞。 despite numerous models achieving high scores and "topping the chart" in these evaluations, there is still a significant gap in LLMs' deeper alignment with human values and achieving genuine harmlessness. To address this issue, this paper proposes the first highly adversarial benchmark named Flames, which includes 2,251 manually crafted prompts, ~18.7K model responses with fine-grained annotations, and a specified scorer. Our framework encompasses both common harmlessness principles, such as fairness, safety, legality, and data protection, and a unique morality dimension that integrates specific Chinese values such as harmony. Based on the framework, we carefully design adversarial prompts that incorporate complex scenarios and jailbreaking methods, mostly with implicit malice. By prompting mainstream LLMs with such adversarially constructed prompts, we obtain model responses, which are then rigorously annotated for evaluation. Our findings indicate that all the evaluated LLMs demonstrate relatively poor performance on Flames, particularly in the safety and fairness dimensions. Claude emerges as the best-performing model overall, but with its harmless rate being only 63.08% while GPT-4 only scores 39.04%. The complexity of Flames has far exceeded existing benchmarks, setting a new challenge for contemporary LLMs and highlighting the need for further alignment of LLMs. To efficiently evaluate new models on the benchmark, we develop a specified scorer capable of scoring LLMs across multiple dimensions, achieving an accuracy of 77.4%. The Flames Benchmark is publicly available on <https://github.com/AIFlames/Flames>.
</details></li>
</ul>
<hr>
<h2 id="Anticipating-User-Needs-Insights-from-Design-Fiction-on-Conversational-Agents-for-Computational-Thinking"><a href="#Anticipating-User-Needs-Insights-from-Design-Fiction-on-Conversational-Agents-for-Computational-Thinking" class="headerlink" title="Anticipating User Needs: Insights from Design Fiction on Conversational Agents for Computational Thinking"></a>Anticipating User Needs: Insights from Design Fiction on Conversational Agents for Computational Thinking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06887">http://arxiv.org/abs/2311.06887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacob Penney, João Felipe Pimentel, Igor Steinmacher, Marco A. Gerosa</li>
<li>for: 这篇论文的目的是为了帮助设计一个能够帮助学生学习计算思维和程式设计的聊天机器人。</li>
<li>methods: 这篇论文使用了设计幻想（design fiction）的方法来了解教育导师对于一个基于生成人工智能（genAI）的聊天机器人的需求和预期。</li>
<li>results: 根据这篇论文的结果，导师们希望一个基于genAI的聊天机器人能够运行学生逐步进行运算，并且能够根据学生的学习背景、技能和缺失、以及学习风格来调整帮助方式。<details>
<summary>Abstract</summary>
Computational thinking, and by extension, computer programming, is notoriously challenging to learn. Conversational agents and generative artificial intelligence (genAI) have the potential to facilitate this learning process by offering personalized guidance, interactive learning experiences, and code generation. However, current genAI-based chatbots focus on professional developers and may not adequately consider educational needs. Involving educators in conceiving educational tools is critical for ensuring usefulness and usability. We enlisted \numParticipants{} instructors to engage in design fiction sessions in which we elicited abilities such a conversational agent supported by genAI should display. Participants envisioned a conversational agent that guides students stepwise through exercises, tuning its method of guidance with an awareness of the educational background, skills and deficits, and learning preferences. The insights obtained in this paper can guide future implementations of tutoring conversational agents oriented toward teaching computational thinking and computer programming.
</details>
<details>
<summary>摘要</summary>
We conducted design fiction sessions with \numParticipants{} instructors to explore the abilities that a conversational agent supported by genAI should have. Participants envisioned a conversational agent that guides students step-by-step through exercises, adapting its method of guidance based on the student's educational background, skills, and learning preferences. The insights from this study can inform the development of future tutoring conversational agents that teach computational thinking and computer programming.
</details></li>
</ul>
<hr>
<h2 id="Modeling-User-Viewing-Flow-using-Large-Language-Models-for-Article-Recommendation"><a href="#Modeling-User-Viewing-Flow-using-Large-Language-Models-for-Article-Recommendation" class="headerlink" title="Modeling User Viewing Flow using Large Language Models for Article Recommendation"></a>Modeling User Viewing Flow using Large Language Models for Article Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07619">http://arxiv.org/abs/2311.07619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenghao Liu, Zulong Chen, Moufeng Zhang, Shaoyang Duan, Hong Wen, Liangyue Li, Nan Li, Yu Gu, Ge Yu</li>
<li>for: 这 paper 是为了提出一种基于用户常见 preference 和当下兴趣的文章推荐方法（SINGLE），用于解决文章推荐任务。</li>
<li>methods: 该方法使用用户常见视图流模型来概括用户的总体兴趣，并使用 Large Language Models (LLMs) 捕捉用户常见的 preference。此外，它还设计了用户即时视图流模型来建立用户点击文章历史和候选文章之间的互动。</li>
<li>results: 根据在 Alibaba Technology Association (ATA) 网站上的实验结果，SINGLE 方法在 online A&#x2F;B 测试中获得了2.4% 的提升，并且further 分析表明，SINGLE 方法可以建立更加适合用户的推荐系统，通过模仿用户查看不同文章的行为和推荐更适合用户兴趣的文章。<details>
<summary>Abstract</summary>
This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. We utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, which achieves 2.4% improvements over previous baseline models in the online A/B test. Our further analyses illustrate that SINGLE has the ability to build a more tailored recommendation system by mimicking different article viewing behaviors of users and recommending more appropriate and diverse articles to match user interests.
</details>
<details>
<summary>摘要</summary>
Note: Simplified Chinese is also known as "简化字符" or "简体字".Please note that the translation is done using Google Translate and may not be perfect.
</details></li>
</ul>
<hr>
<h2 id="Understanding-Practices-around-Computational-News-Discovery-Tools-in-the-Domain-of-Science-Journalism"><a href="#Understanding-Practices-around-Computational-News-Discovery-Tools-in-the-Domain-of-Science-Journalism" class="headerlink" title="Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism"></a>Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06864">http://arxiv.org/abs/2311.06864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sachita Nishal, Jasmine Sinchai, Nicholas Diakopoulos</li>
<li>for: 该论文主要目标是帮助科技新闻记者更加快速地找到新闻灵感，因为他们的工作负担增加，资源减少，科学出版生态系统扩大。</li>
<li>methods: 该论文使用计算机方法来帮助科技新闻记者发现新闻，包括一个交互式工具，用于评估科学新闻的时效性和新闻价值。</li>
<li>results: 研究发现，计算机工具可以帮助科技新闻记者更加快速地找到新闻灵感，但是需要考虑新闻价值、科学背景和社会影响等因素。<details>
<summary>Abstract</summary>
Science and technology journalists today face challenges in finding newsworthy leads due to increased workloads, reduced resources, and expanding scientific publishing ecosystems. Given this context, we explore computational methods to aid these journalists' news discovery in terms of time-efficiency and agency. In particular, we prototyped three computational information subsidies into an interactive tool that we used as a probe to better understand how such a tool may offer utility or more broadly shape the practices of professional science journalists. Our findings highlight central considerations around science journalists' agency, context, and responsibilities that such tools can influence and could account for in design. Based on this, we suggest design opportunities for greater and longer-term user agency; incorporating contextual, personal and collaborative notions of newsworthiness; and leveraging flexible interfaces and generative models. Overall, our findings contribute a richer view of the sociotechnical system around computational news discovery tools, and suggest ways to improve such tools to better support the practices of science journalists.
</details>
<details>
<summary>摘要</summary>
现代科技期刊记者面临着新闻发现的挑战，这主要归结于增加的工作负担、减少的资源以及科学出版生态系统的扩展。为了解决这些问题，我们研究了计算机方法来帮助记者新闻发现，以提高效率和使用者感受。具体来说，我们将三种计算机信息补充变为一个互动工具，用于更好地理解这种工具如何提供用户价值，以及如何改进这种工具以更好地支持专业科技记者的实践。我们的发现表明，计算机新闻发现工具的设计应该考虑科技记者的决策权、上下文和责任，并且应该包括个人、社交和协作的新闻可能性。基于这些发现，我们建议设计者可以通过提供更多的用户参与、个性化的新闻可能性和灵活的界面来提高用户参与度和持续时间。总之，我们的发现为计算机新闻发现工具的设计提供了更加丰富的社会技术系统视角，并提供了改进这种工具以更好地支持专业科技记者的方法。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Augment-a-Biomedical-Ontology-with-missing-Concepts-and-Relations"><a href="#Can-Large-Language-Models-Augment-a-Biomedical-Ontology-with-missing-Concepts-and-Relations" class="headerlink" title="Can Large Language Models Augment a Biomedical Ontology with missing Concepts and Relations?"></a>Can Large Language Models Augment a Biomedical Ontology with missing Concepts and Relations?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06858">http://arxiv.org/abs/2311.06858</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minitour/ontology-extension-chatgpt">https://github.com/minitour/ontology-extension-chatgpt</a></li>
<li>paper_authors: Antonio Zaitoun, Tomer Sagi, Szymon Wilk, Mor Peleg</li>
<li>for: 扩展现有 ontology 中的概念和关系</li>
<li>methods: 使用大型自然语言模型 (LLM) 和对话交互来自动扩展 ontology</li>
<li>results: 对 clinical practice guidelines (CPGs) 进行分析，检测不在 SNOMED-CT 中的新医学概念和关系<details>
<summary>Abstract</summary>
Ontologies play a crucial role in organizing and representing knowledge. However, even current ontologies do not encompass all relevant concepts and relationships. Here, we explore the potential of large language models (LLM) to expand an existing ontology in a semi-automated fashion. We demonstrate our approach on the biomedical ontology SNOMED-CT utilizing semantic relation types from the widely used UMLS semantic network. We propose a method that uses conversational interactions with an LLM to analyze clinical practice guidelines (CPGs) and detect the relationships among the new medical concepts that are not present in SNOMED-CT. Our initial experimentation with the conversational prompts yielded promising preliminary results given a manually generated gold standard, directing our future potential improvements.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文，不同于正式中文） ontology 是知识组织和表示的关键作用，但当前 ontology 并不包括所有相关的概念和关系。我们探讨了使用大型自然语言模型（LLM）来扩展现有 ontology 的方法。我们使用 UMLS semantic network 中的 semantic relation types，并在 SNOMED-CT 生物医学 ontology 中进行了实验。我们提议一种使用 conversational interactions 与 LLM 分析临床实践指南 (CPGs)，检测不在 SNOMED-CT 中的新医疗概念之间的关系。我们的初步实验表明，使用 conversational prompts 可以获得有价值的初步结果，引导我们未来的可能的改进。
</details></li>
</ul>
<hr>
<h2 id="On-learning-spatial-sequences-with-the-movement-of-attention"><a href="#On-learning-spatial-sequences-with-the-movement-of-attention" class="headerlink" title="On learning spatial sequences with the movement of attention"></a>On learning spatial sequences with the movement of attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06856">http://arxiv.org/abs/2311.06856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viacheslav M. Osaulenko</li>
<li>for: 本研究的目的是解释人类如何通过视觉经验recognize不同的身体运动，以及在不同感知modalities中存在固有的空间序列表示。</li>
<li>methods: 本研究使用新的数学表示方法，提出了对于空间序列的抽象层次结构，并提出了两个假设来解释这种抽象的形成。</li>
<li>results: 研究发现，人类认知中的注意力运动是关键，并且可以应用到新的学习算法中。通过对 redundancy的处理，人类可以更好地recognize和泛化不同的身体运动。<details>
<summary>Abstract</summary>
In this paper we start with a simple question, how is it possible that humans can recognize different movements over skin with only a prior visual experience of them? Or in general, what is the representation of spatial sequences that are invariant to scale, rotation, and translation across different modalities? To answer, we rethink the mathematical representation of spatial sequences, argue against the minimum description length principle, and focus on the movements of attention. We advance the idea that spatial sequences must be represented on different levels of abstraction, this adds redundancy but is necessary for recognition and generalization. To address the open question of how these abstractions are formed we propose two hypotheses: the first invites exploring selectionism learning, instead of finding parameters in some models; the second proposes to find new data structures, not neural network architectures, to efficiently store and operate over redundant features to be further selected. Movements of attention are central to human cognition and lessons should be applied to new better learning algorithms.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们开始于一个简单的问题：人类如何通过视觉经验 alone 识别不同的身体运动？或者更一般来说，如何表示不同模式之间的空间序列是具有扩展、旋转和平移不变性的？为了回答这个问题，我们重新思考了空间序列的数学表示方式，反对最小描述长度原则，并将注意力的运动作为中心。我们提出了两个假设：第一个是探索选择主义学习，而不是找到某些模型中的参数；第二个是找到更好的存储和运算缓存重复特征的数据结构，以便进一步选择。我们认为 spatial sequences 必须在不同的层次上表示，这会添加冗余，但是是必要的 для认知和泛化。为了解决如何形成这些抽象，我们提出了两个假设：第一个是通过选择主义学习来形成抽象；第二个是找到更好的学习算法，以便更有效地存储和运算重复特征。我们认为人类认知中的运动是中心，我们应该从这里学习新的更好的学习算法。
</details></li>
</ul>
<hr>
<h2 id="Distribution-Re-weighting-and-Voting-Paradoxes"><a href="#Distribution-Re-weighting-and-Voting-Paradoxes" class="headerlink" title="Distribution Re-weighting and Voting Paradoxes"></a>Distribution Re-weighting and Voting Paradoxes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06840">http://arxiv.org/abs/2311.06840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bijan Mazaheri, Siddharth Jain, Matthew Cook, Jehoshua Bruck</li>
<li>for: 本研究探讨了域专家知识的分布偏移问题，即训练只限于特定标签 subsets。</li>
<li>methods: 研究使用标准分布偏移策略，包括数据重新权重，以及常见 causal inference 调整。</li>
<li>results: 研究发现，标准分布偏移策略可能导致域专家之间的反面互相矛盾，同时也与选举 preference 中的假设相似。<details>
<summary>Abstract</summary>
We explore a specific type of distribution shift called domain expertise, in which training is limited to a subset of all possible labels. This setting is common among specialized human experts, or specific focused studies. We show how the standard approach to distribution shift, which involves re-weighting data, can result in paradoxical disagreements among differing domain expertise. We also demonstrate how standard adjustments for causal inference lead to the same paradox. We prove that the characteristics of these paradoxes exactly mimic another set of paradoxes which arise among sets of voter preferences.
</details>
<details>
<summary>摘要</summary>
我们研究一种特定的分布偏移问题，即领域专家知识，在培训中仅限于一 subset of all possible labels。这种情况常见于专业人士或特定领域研究。我们显示了标准的分布偏移方法，即重新权重数据，可能导致不同领域专家之间的意见不一致。我们也示出了标准的 causal inference 调整也会导致同样的парадок。我们证明了这些 парадок 的特征与另一种来自选民偏好的集合中的 парадок 完全相同。
</details></li>
</ul>
<hr>
<h2 id="Open-Set-Graph-Anomaly-Detection-via-Normal-Structure-Regularisation"><a href="#Open-Set-Graph-Anomaly-Detection-via-Normal-Structure-Regularisation" class="headerlink" title="Open-Set Graph Anomaly Detection via Normal Structure Regularisation"></a>Open-Set Graph Anomaly Detection via Normal Structure Regularisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06835">http://arxiv.org/abs/2311.06835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qizhou Wang, Guansong Pang, Mahsa Salehi, Wray Buntine, Christopher Leckie<br>for:这篇论文针对的是 Graph Anomaly Detection (GAD) 任务，具体来说是开放集 GAD，这种任务的目标是通过一小量标注正常和异常节点（称为 seen anomalies）来检测图像中的异常节点。methods:这篇论文提出了一种新的开放集 GAD方法，即normal structure regularization (NSReg)，该方法利用标注节点中的正常图 структуры来解决现有方法过于强调seen anomalies，导致检测未看到异常节点的问题。results:实验结果表明，NSReg 在实际世界数据集上具有superiority，可以更好地检测图像中的异常节点。<details>
<summary>Abstract</summary>
This paper considers an under-explored Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to detect anomalous nodes using a small number of labelled training normal and anomaly nodes (known as seen anomalies) that cannot illustrate all possible inference-time abnormalities. The task has attracted growing attention due to the availability of anomaly prior knowledge from the label information that can help to substantially reduce detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect unseen anomalies, i.e., those that are not illustrated by the labelled anomaly nodes. Further, they were introduced to handle Euclidean data, failing to effectively capture important non-Euclidean features for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to leverage the rich normal graph structure embedded in the labelled nodes to tackle the aforementioned two issues. In particular, NSReg trains an anomaly-discriminative supervised graph anomaly detector, with a plug-and-play regularisation term to enforce compact, semantically-rich representations of normal nodes. To this end, the regularisation is designed to differentiate various types of normal nodes, including labelled normal nodes that are connected in their local neighbourhood, and those that are not connected. By doing so, it helps incorporate strong normality into the supervised anomaly detector learning, mitigating their overfitting to the seen anomalies. Extensive empirical results on real-world datasets demonstrate the superiority of our proposed NSReg for open-set GAD.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose a novel open-set GAD approach called normal structure regularization (NSReg). NSReg leverages the rich normal graph structure embedded in the labeled nodes to improve the detection of anomalies. Specifically, NSReg trains an anomaly-discriminative supervised graph anomaly detector with a plug-and-play regularization term that enforces compact, semantically-rich representations of normal nodes. The regularization differentiates various types of normal nodes, including labeled normal nodes that are connected in their local neighborhood and those that are not connected. This helps incorporate strong normality into the supervised anomaly detector learning, mitigating overfitting to the seen anomalies.Extensive empirical results on real-world datasets demonstrate the superiority of our proposed NSReg for open-set GAD.
</details></li>
</ul>
<hr>
<h2 id="Fairness-Hacking-The-Malicious-Practice-of-Shrouding-Unfairness-in-Algorithms"><a href="#Fairness-Hacking-The-Malicious-Practice-of-Shrouding-Unfairness-in-Algorithms" class="headerlink" title="Fairness Hacking: The Malicious Practice of Shrouding Unfairness in Algorithms"></a>Fairness Hacking: The Malicious Practice of Shrouding Unfairness in Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06826">http://arxiv.org/abs/2311.06826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristof Meding, Thilo Hagendorff</li>
<li>for: 本研究旨在探讨如何透过“公平黑客”的做法，对Algorithmic discrimination进行隐藏。</li>
<li>methods: 本研究使用了两种不同的“公平黑客”分类：一是内部公平黑客（misuse of a particular metric by adding or removing sensitive attributes from the analysis），二是间接公平黑客（search for a specific fair metric with given attributes）。</li>
<li>results: 本研究使用了真实数据来示范两种“公平黑客”的存在，并说明了这些“公平黑客”可能对于End-users和广泛的AI实践Community造成的伤害。<details>
<summary>Abstract</summary>
Fairness in machine learning (ML) is an ever-growing field of research due to the manifold potential for harm from algorithmic discrimination. To prevent such harm, a large body of literature develops new approaches to quantify fairness. Here, we investigate how one can divert the quantification of fairness by describing a practice we call "fairness hacking" for the purpose of shrouding unfairness in algorithms. This impacts end-users who rely on learning algorithms, as well as the broader community interested in fair AI practices. We introduce two different categories of fairness hacking in reference to the established concept of p-hacking. The first category, intra-metric fairness hacking, describes the misuse of a particular metric by adding or removing sensitive attributes from the analysis. In this context, countermeasures that have been developed to prevent or reduce p-hacking can be applied to similarly prevent or reduce fairness hacking. The second category of fairness hacking is inter-metric fairness hacking. Inter-metric fairness hacking is the search for a specific fair metric with given attributes. We argue that countermeasures to prevent or reduce inter-metric fairness hacking are still in their infancy. Finally, we demonstrate both types of fairness hacking using real datasets. Our paper intends to serve as a guidance for discussions within the fair ML community to prevent or reduce the misuse of fairness metrics, and thus reduce overall harm from ML applications.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）中的公平是一个不断成长的研究领域，因为算法歧视可能导致严重的伤害。为防止这种伤害，一大量的文献开发了新的方法来量化公平。在这篇论文中，我们调查了如何将公平量化歪曲到算法中，以及这对终端用户和更广泛的AI实践社区的影响。我们分别将这种歪曲分为两个类别：在内部度量公平歪曲中，我们添加或删除敏感特征，以影响分析结果。在这种情况下，已经发展了预防或减少p-hacking的对策，可以类似地适用于预防或减少公平歪曲。第二个类别是between度量公平歪曲，它是搜寻特定的公平度量器，以满足给定的属性。我们认为预防或减少between度量公平歪曲的对策仍在起步阶段。最后，我们使用实际数据示出了这两种公平歪曲的示例。我们的论文旨在为公平ML社区提供指南，以预防或减少公平度量器的歪曲，并因此减少ML应用中的伤害。
</details></li>
</ul>
<hr>
<h2 id="Training-A-Multi-stage-Deep-Classifier-with-Feedback-Signals"><a href="#Training-A-Multi-stage-Deep-Classifier-with-Feedback-Signals" class="headerlink" title="Training A Multi-stage Deep Classifier with Feedback Signals"></a>Training A Multi-stage Deep Classifier with Feedback Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06823">http://arxiv.org/abs/2311.06823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Xu, Yu Yang, Rongzhao Wang, Guan Wang, Bojia Lin</li>
<li>for: 这篇论文是针对多阶段分类器（Multi-Stage Classifier，MSC）的训练框架，尤其是两阶段二元分类的情况。</li>
<li>methods: 本文提出了一个新的训练框架，名为反向训练（Feedback Training），它在实际运行的顺序反之训练每个阶段的分类器，并使用后期阶段的分类器来导引初期阶段的分类器训练。</li>
<li>results: 实验结果显示，提案的训练框架在几个 shot 训练情况下具有优秀的表现，并且在实际应用中具有很好的适用性。<details>
<summary>Abstract</summary>
Multi-Stage Classifier (MSC) - several classifiers working sequentially in an arranged order and classification decision is partially made at each step - is widely used in industrial applications for various resource limitation reasons. The classifiers of a multi-stage process are usually Neural Network (NN) models trained independently or in their inference order without considering the signals from the latter stages. Aimed at two-stage binary classification process, the most common type of MSC, we propose a novel training framework, named Feedback Training. The classifiers are trained in an order reverse to their actual working order, and the classifier at the later stage is used to guide the training of initial-stage classifier via a sample weighting method. We experimentally show the efficacy of our proposed approach, and its great superiority under the scenario of few-shot training.
</details>
<details>
<summary>摘要</summary>
多阶段分类器（MSC）是在工业应用中广泛使用的，它是一种多个分类器在预先定义的顺序中工作，并在每个阶段中做出部分分类决策。多阶段分类器的每个阶段通常使用独立地或在推理阶段无视后续阶段的神经网络（NN）模型进行训练。我们对二阶段二分类过程进行了改进，并提出了一种新的训练框架，名为反向培训。在这种框架中，分类器们在它们的实际工作顺序相反的顺序进行训练，并使用后期阶段的分类器来引导初始阶段分类器的训练，通过一种权重方法。我们通过实验证明了我们的提议的优势，特别在几个步骤训练的场景下表现出色。
</details></li>
</ul>
<hr>
<h2 id="Dual-Branch-Reconstruction-Network-for-Industrial-Anomaly-Detection-with-RGB-D-Data"><a href="#Dual-Branch-Reconstruction-Network-for-Industrial-Anomaly-Detection-with-RGB-D-Data" class="headerlink" title="Dual-Branch Reconstruction Network for Industrial Anomaly Detection with RGB-D Data"></a>Dual-Branch Reconstruction Network for Industrial Anomaly Detection with RGB-D Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06797">http://arxiv.org/abs/2311.06797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyang Bi, Yueyang Li, Haichi Luo</li>
<li>for: 这个论文主要针对的是产业异常检测领域中的无监控异常检测方法，并且强调了3D点云和RGB图像的多 modal 检测。</li>
<li>methods: 本论文提出了一个轻量级的双支分支重建网络（DBRN），利用RGB-D输入，通过学习决策界面来区分正常和异常的示例。此外，本论文还引入了一个重要性分配模组，以帮助将这两种模式的特征融合，从而获得全面的决策结果。</li>
<li>results: 根据MVTec 3D-AD dataset的评估结果，DBRN可以 дости得92.8% AUROC的高准确率，而且不需要大量的预训数据和快取库。<details>
<summary>Abstract</summary>
Unsupervised anomaly detection methods are at the forefront of industrial anomaly detection efforts and have made notable progress. Previous work primarily used 2D information as input, but multi-modal industrial anomaly detection based on 3D point clouds and RGB images is just beginning to emerge. The regular approach involves utilizing large pre-trained models for feature representation and storing them in memory banks. However, the above methods require a longer inference time and higher memory usage, which cannot meet the real-time requirements of the industry. To overcome these issues, we propose a lightweight dual-branch reconstruction network(DBRN) based on RGB-D input, learning the decision boundary between normal and abnormal examples. The requirement for alignment between the two modalities is eliminated by using depth maps instead of point cloud input. Furthermore, we introduce an importance scoring module in the discriminative network to assist in fusing features from these two modalities, thereby obtaining a comprehensive discriminative result. DBRN achieves 92.8% AUROC with high inference efficiency on the MVTec 3D-AD dataset without large pre-trained models and memory banks.
</details>
<details>
<summary>摘要</summary>
“无监督异常检测方法在工业中领先，它们已经做出了杰出的进步。以往的工作主要使用2D信息作为输入，但是基于3D点Cloud和RGB图像的多modal工业异常检测则刚开始出现。常规的方法是利用大型预训模型来表示特征，并将其储存在内存库中。但这些方法需要较长的推论时间和更高的内存使用，这不能满足工业的实时需求。为了解决这些问题，我们提出了一个轻量级双支架网络（DBRN），基于RGB-D输入，学习决策界面 между正常和异常的例子。depth maps而不是点Cloud输入，从而消除了两个模式之间的对齐需求。此外，我们引入了优先级分配模组，以帮助将这两个模式的特征融合，从而获得了全面的决策结果。DBRN在MVTec 3D-AD dataset上 achieve 92.8% AUROC，并且具有高推论效率和低资源需求。”
</details></li>
</ul>
<hr>
<h2 id="Alleviating-Behavior-Data-Imbalance-for-Multi-Behavior-Graph-Collaborative-Filtering"><a href="#Alleviating-Behavior-Data-Imbalance-for-Multi-Behavior-Graph-Collaborative-Filtering" class="headerlink" title="Alleviating Behavior Data Imbalance for Multi-Behavior Graph Collaborative Filtering"></a>Alleviating Behavior Data Imbalance for Multi-Behavior Graph Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06777">http://arxiv.org/abs/2311.06777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijie Zhang, Yuanchen Bei, Shiqi Yang, Hao Chen, Zhiqing Li, Lijia Chen, Feiran Huang</li>
<li>for: 提高多行为推荐的性能，解决多行为数据不均衡问题。</li>
<li>methods: 利用多任务学习框架进行多行为图建议，对缺乏数据的行为进行 represencing学习以提高推荐性能。</li>
<li>results: 在两个常用的多行为数据集上实现了IMGCF模型的有效性。<details>
<summary>Abstract</summary>
Graph collaborative filtering, which learns user and item representations through message propagation over the user-item interaction graph, has been shown to effectively enhance recommendation performance. However, most current graph collaborative filtering models mainly construct the interaction graph on a single behavior domain (e.g. click), even though users exhibit various types of behaviors on real-world platforms, including actions like click, cart, and purchase. Furthermore, due to variations in user engagement, there exists an imbalance in the scale of different types of behaviors. For instance, users may click and view multiple items but only make selective purchases from a small subset of them. How to alleviate the behavior imbalance problem and utilize information from the multiple behavior graphs concurrently to improve the target behavior conversion (e.g. purchase) remains underexplored. To this end, we propose IMGCF, a simple but effective model to alleviate behavior data imbalance for multi-behavior graph collaborative filtering. Specifically, IMGCF utilizes a multi-task learning framework for collaborative filtering on multi-behavior graphs. Then, to mitigate the data imbalance issue, IMGCF improves representation learning on the sparse behavior by leveraging representations learned from the behavior domain with abundant data volumes. Experiments on two widely-used multi-behavior datasets demonstrate the effectiveness of IMGCF.
</details>
<details>
<summary>摘要</summary>
graph collaborative filtering，通过message propagation over the user-item interaction graph来学习用户和物品表示，已经能够有效提高推荐性能。然而，当前大多数图共同 Filtering模型都是基于单一的行为Domain（例如，点击）构建交互图，即使用户在现实世界平台上表现出多种行为，例如点击、购物车和购买。此外，由于用户参与度的变化，存在不同类型行为之间的数据不均衡问题。例如，用户可能会对多个物品进行点击和浏览，但只是从一小部分中进行选择性购买。为了解决这个问题并利用多个行为图同时提高目标行为转化（例如，购买），我们提出了IMGCF模型。specifically, IMGCF使用多任务学习框架 для图共同 Filtering on multi-behavior graphs。然后，为了缓解数据不均衡问题，IMGCF在稀薄的行为上提高表示学习，通过使用行为Domain中充满数据量的表示学习来增强表示学习。实验表明，IMGCF在两个广泛使用的多种行为dataset上显示出效果。
</details></li>
</ul>
<hr>
<h2 id="ChatAnything-Facetime-Chat-with-LLM-Enhanced-Personas"><a href="#ChatAnything-Facetime-Chat-with-LLM-Enhanced-Personas" class="headerlink" title="ChatAnything: Facetime Chat with LLM-Enhanced Personas"></a>ChatAnything: Facetime Chat with LLM-Enhanced Personas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06772">http://arxiv.org/abs/2311.06772</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhoudaquan/ChatAnything">https://github.com/zhoudaquan/ChatAnything</a></li>
<li>paper_authors: Yilin Zhao, Xinbin Yuan, Shanghua Gao, Zhijie Lin, Qibin Hou, Jiashi Feng, Daquan Zhou</li>
<li>for: 这个技术报告targets generating anthropomorphized personas for LLM-based characters in an online manner, including visual appearance, personality, and tones, using only text descriptions.</li>
<li>methods:  authors propose two novel concepts, the mixture of voices (MoV) and the mixture of diffusers (MoD), for diverse voice and appearance generation. They also utilize in-context learning capability of LLMs for personality generation and incorporate pixel-level guidance to infuse human face landmarks during the image generation phase.</li>
<li>results: the proposed framework, ChatAnything, can animate anything with any personas that are anthropomorphic using just a few text inputs. The authors also report a significant increase in the detection rate of face landmarks, from 57.0% to 92.5%, allowing for automatic face animation based on generated speech content.<details>
<summary>Abstract</summary>
In this technical report, we target generating anthropomorphized personas for LLM-based characters in an online manner, including visual appearance, personality and tones, with only text descriptions. To achieve this, we first leverage the in-context learning capability of LLMs for personality generation by carefully designing a set of system prompts. We then propose two novel concepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for diverse voice and appearance generation. For MoV, we utilize the text-to-speech (TTS) algorithms with a variety of pre-defined tones and select the most matching one based on the user-provided text description automatically. For MoD, we combine the recent popular text-to-image generation techniques and talking head algorithms to streamline the process of generating talking objects. We termed the whole framework as ChatAnything. With it, users could be able to animate anything with any personas that are anthropomorphic using just a few text inputs. However, we have observed that the anthropomorphic objects produced by current generative models are often undetectable by pre-trained face landmark detectors, leading to failure of the face motion generation, even if these faces possess human-like appearances because those images are nearly seen during the training (e.g., OOD samples). To address this issue, we incorporate pixel-level guidance to infuse human face landmarks during the image generation phase. To benchmark these metrics, we have built an evaluation dataset. Based on it, we verify that the detection rate of the face landmark is significantly increased from 57.0% to 92.5% thus allowing automatic face animation based on generated speech content. The code and more results can be found at https://chatanything.github.io/.
</details>
<details>
<summary>摘要</summary>
在这份技术报告中，我们目标是通过文本描述生成LLM基于人物的人形化人物，包括视觉外表、性格和语言口音。为达到这一目标，我们首先利用LLM在场景学习中的增强学习能力进行人格生成，通过精心设计系统提示。然后，我们提出了两项新概念：混合声音（MoV）和混合扩散器（MoD），用于多样化的声音和外表生成。对MoV，我们利用文本识别算法中的多种预定的声音，并根据用户提供的文本描述自动选择最符合的一个。对MoD，我们结合了最新的文本识别技术和说话头算法，以便更加方便地生成说话的对象。我们将整个框架称为ChatAnything。通过它，用户可以使用只有几个文本输入来animate任何东西，并且可以为这些人物选择任何人形化。然而，我们发现当前的生成模型中的人形对象经常无法被预训练的面部准 markers检测器探测出来，导致对话动画失败，即使这些面部具有人类化的外观，因为这些图像在训练时未被考虑（例如，OD）。为解决这个问题，我们在生成图像阶段添加像素级指导，以启用人类面部准 markers。根据这些指标，我们建立了评估集。根据它，我们证明了面部准 markers检测率的提高，从57.0%提高到92.5%，因此允许基于生成的语音内容自动进行面部动画。代码和更多结果可以在https://chatanything.github.io/查看。
</details></li>
</ul>
<hr>
<h2 id="Learning-Globally-Optimized-Language-Structure-via-Adversarial-Training"><a href="#Learning-Globally-Optimized-Language-Structure-via-Adversarial-Training" class="headerlink" title="Learning Globally Optimized Language Structure via Adversarial Training"></a>Learning Globally Optimized Language Structure via Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06771">http://arxiv.org/abs/2311.06771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuwang Yin</li>
<li>for: 提高文本生成能力</li>
<li>methods: 使用反对敌攻击策略来训练EBM</li>
<li>results: 实验结果表明，该方法可以明显提高文本生成质量，比过去方法更有 Promise。主要贡献包括：	+ 针对文本生成的反对敌攻击策略，生成负样本以外的潜在模式	+ 基于反对敌攻击的EBM训练算法	+ 对文本生成任务的实验验证<details>
<summary>Abstract</summary>
Recent work has explored integrating autoregressive language models with energy-based models (EBMs) to enhance text generation capabilities. However, learning effective EBMs for text is challenged by the discrete nature of language. This work proposes an adversarial training strategy to address limitations in prior efforts. Specifically, an iterative adversarial attack algorithm is presented to generate negative samples for training the EBM by perturbing text from the autoregressive model. This aims to enable the EBM to suppress spurious modes outside the support of the data distribution. Experiments on an arithmetic sequence generation task demonstrate that the proposed adversarial training approach can substantially enhance the quality of generated sequences compared to prior methods. The results highlight the promise of adversarial techniques to improve discrete EBM training. Key contributions include: (1) an adversarial attack strategy tailored to text to generate negative samples, circumventing MCMC limitations; (2) an adversarial training algorithm for EBMs leveraging these attacks; (3) empirical validation of performance improvements on a sequence generation task.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>An adversarial attack strategy tailored to text to generate negative samples, overcoming the limitations of Markov chain Monte Carlo (MCMC) methods.2. An adversarial training algorithm for EBMs leveraging these attacks.3. Empirical validation of performance improvements on a sequence generation task.</details></li>
</ol>
<hr>
<h2 id="Evaluating-the-Efficacy-of-Interactive-Language-Therapy-Based-on-LLM-for-High-Functioning-Autistic-Adolescent-Psychological-Counseling"><a href="#Evaluating-the-Efficacy-of-Interactive-Language-Therapy-Based-on-LLM-for-High-Functioning-Autistic-Adolescent-Psychological-Counseling" class="headerlink" title="Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling"></a>Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09243">http://arxiv.org/abs/2311.09243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujin Cho, Mingeon Kim, Seojin Kim, Oyun Kwon, Ryan Donghan Kwon, Yoonha Lee, Dohyun Lim</li>
<li>for: 这个研究旨在评估大自然语言模型（LLM）在临床语言治疗中的有效性，以帮助高功能自闭症青少年。</li>
<li>methods: 这个研究使用了一种特制的评价表卡，由临床心理学家和心理医生组成的评审组对LLM的表现进行评估。</li>
<li>results: 研究发现，LLM在临床语言治疗中表现出了强大的同情和适应能力，但是在人类治疗师的深度情感理解和个性化方面存在挑战。<details>
<summary>Abstract</summary>
This study investigates the efficacy of Large Language Models (LLMs) in interactive language therapy for high-functioning autistic adolescents. With the rapid advancement of artificial intelligence, particularly in natural language processing, LLMs present a novel opportunity to augment traditional psychological counseling methods. This research primarily focuses on evaluating the LLM's ability to engage in empathetic, adaptable, and contextually appropriate interactions within a therapeutic setting. A comprehensive evaluation was conducted by a panel of clinical psychologists and psychiatrists using a specially developed scorecard. The assessment covered various aspects of the LLM's performance, including empathy, communication skills, adaptability, engagement, and the ability to establish a therapeutic alliance. The study avoided direct testing with patients, prioritizing privacy and ethical considerations, and instead relied on simulated scenarios to gauge the LLM's effectiveness. The results indicate that LLMs hold significant promise as supportive tools in therapy, demonstrating strengths in empathetic engagement and adaptability in conversation. However, challenges in achieving the depth of personalization and emotional understanding characteristic of human therapists were noted. The study also highlights the importance of ethical considerations in the application of AI in therapeutic contexts. This research provides valuable insights into the potential and limitations of using LLMs in psychological counseling for autistic adolescents. It lays the groundwork for future explorations into AI's role in mental health care, emphasizing the need for ongoing development to enhance the capabilities of these models in therapeutic settings.
</details>
<details>
<summary>摘要</summary>
A comprehensive evaluation was conducted by a panel of clinical psychologists and psychiatrists using a specially developed scorecard. The assessment covered various aspects of the LLM's performance, including empathy, communication skills, adaptability, engagement, and the ability to establish a therapeutic alliance. The study avoided direct testing with patients, prioritizing privacy and ethical considerations, and instead relied on simulated scenarios to gauge the LLM's effectiveness.The results indicate that LLMs show great promise as supportive tools in therapy, excelling in empathetic engagement and adaptability in conversation. However, the study also noted challenges in achieving the depth of personalization and emotional understanding that are characteristic of human therapists. The research highlights the importance of ethical considerations in the application of AI in therapeutic contexts.This study provides valuable insights into the potential and limitations of using LLMs in psychological counseling for autistic adolescents. It lays the groundwork for future explorations into AI's role in mental health care, emphasizing the need for ongoing development to enhance the capabilities of these models in therapeutic settings.
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models’-Understanding-of-Math-Source-Criticism-and-Extrapolation"><a href="#Large-Language-Models’-Understanding-of-Math-Source-Criticism-and-Extrapolation" class="headerlink" title="Large Language Models’ Understanding of Math: Source Criticism and Extrapolation"></a>Large Language Models’ Understanding of Math: Source Criticism and Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07618">http://arxiv.org/abs/2311.07618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roozbeh Yousefzadeh, Xuenan Cao</li>
<li>for: 这篇论文是否提出了GPT-4模型是否具有数学理解能力的问题？</li>
<li>methods: 作者使用的方法是通过制作一些数学问题，其正式证明不可通过网络找到，以评估GPT-4模型是否具有数学理解能力。</li>
<li>results: 研究发现，GPT-4模型无法解决这些简单的数学问题，这casts doubt on whether GPT-4 has acquired an understanding of even basic mathematical concepts。<details>
<summary>Abstract</summary>
It has been suggested that large language models such as GPT-4 have acquired some form of understanding beyond the correlations among the words in text including some understanding of mathematics as well. Here, we perform a critical inquiry into this claim by evaluating the mathematical understanding of the GPT-4 model. Considering that GPT-4's training set is a secret, it is not straightforward to evaluate whether the model's correct answers are based on a mathematical understanding or based on replication of proofs that the model has seen before. We specifically craft mathematical questions which their formal proofs are not readily available on the web, proofs that are more likely not seen by the GPT-4. We see that GPT-4 is unable to solve those problems despite their simplicity. It is hard to find scientific evidence suggesting that GPT-4 has acquired an understanding of even basic mathematical concepts. A straightforward way to find failure modes of GPT-4 in theorem proving is to craft questions where their formal proofs are not available on the web. Our finding suggests that GPT-4's ability is to reproduce, rephrase, and polish the mathematical proofs that it has seen before, and not in grasping mathematical concepts. We also see that GPT-4's ability to prove mathematical theorems is continuously expanding over time despite the claim that it is a fixed model. We suggest that the task of proving mathematical theorems in formal language is comparable to the methods used in search engines such as Google while predicting the next word in a sentence may be a misguided approach, a recipe that often leads to excessive extrapolation and eventual failures. Prompting the GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question whether it is valuable for machine learning or for theorem proving.
</details>
<details>
<summary>摘要</summary>
它已被建议大型语言模型如GPT-4已经获得了一些形式的理解，包括数学方面的理解。在这篇文章中，我们进行了一个批判性的评价，以评估GPT-4模型的数学理解能力。由于GPT-4的训练集是机密的，因此不可能直接评估模型是否基于数学理解或是基于复制证明的。我们专门设计了一些没有正式证明的数学问题，以验证GPT-4是否具备数学理解能力。我们发现GPT-4无法解决这些问题，即使它们的简单程度。这 suggeSTS that GPT-4没有获得基本数学概念的理解。我们的发现显示GPT-4的能力是重复、重写和精致化已经看过的数学证明，而不是具备数学概念的理解。此外，我们发现GPT-4的数学证明能力随时间的推移而增长，这与 claim 的固定模型不符。我们建议使用正式语言进行数学证明，而不是预测下一个字的方法，这种方法通常会导致不必要的推理和最终失败。重复提示GPT-4可能对GPT-4和OpenAI有利，但我们问到是这种方法对机器学习或数学证明有价值。
</details></li>
</ul>
<hr>
<h2 id="ReIDTracker-Sea-the-technical-report-of-BoaTrack-and-SeaDronesSee-MOT-challenge-at-MaCVi-of-WACV24"><a href="#ReIDTracker-Sea-the-technical-report-of-BoaTrack-and-SeaDronesSee-MOT-challenge-at-MaCVi-of-WACV24" class="headerlink" title="ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT challenge at MaCVi of WACV24"></a>ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT challenge at MaCVi of WACV24</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07616">http://arxiv.org/abs/2311.07616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang, Weitu Chong</li>
<li>for:  solves the problem of multi-object tracking in maritime unmanned aerial vehicles (UAVs) and unmanned surface vehicles (USVs) usage scenarios, with a completely unsupervised approach.</li>
<li>methods:  uses instance representation learning by self-supervision on ImageNet, and cooperates with high-quality detectors to complete the multi-target tracking task simply and efficiently.</li>
<li>results:  achieved top 3 performance on both UAV-based Multi-Object Tracking with Reidentification and USV-based Multi-Object Tracking benchmarks, and won the championship in many multiple Multi-Object Tracking competitions, such as BDD100K MOT, MOTS, and Waymo 2D MOT.<details>
<summary>Abstract</summary>
Multi-Object Tracking is one of the most important technologies in maritime computer vision. Our solution tries to explore Multi-Object Tracking in maritime Unmanned Aerial vehicles (UAVs) and Unmanned Surface Vehicles (USVs) usage scenarios. Most of the current Multi-Object Tracking algorithms require complex association strategies and association information (2D location and motion, 3D motion, 3D depth, 2D appearance) to achieve better performance, which makes the entire tracking system extremely complex and heavy. At the same time, most of the current Multi-Object Tracking algorithms still require video annotation data which is costly to obtain for training. Our solution tries to explore Multi-Object Tracking in a completely unsupervised way. The scheme accomplishes instance representation learning by using self-supervision on ImageNet. Then, by cooperating with high-quality detectors, the multi-target tracking task can be completed simply and efficiently. The scheme achieved top 3 performance on both UAV-based Multi-Object Tracking with Reidentification and USV-based Multi-Object Tracking benchmarks and the solution won the championship in many multiple Multi-Object Tracking competitions. such as BDD100K MOT,MOTS, Waymo 2D MOT
</details>
<details>
<summary>摘要</summary>
多bject 跟踪是海上计算机视觉中最重要的技术之一。我们的解决方案尝试在海上无人飞机（UAV）和无人水面车（USV）使用场景中探索多bject 跟踪。现有的多bject 跟踪算法大多需要复杂的关联策略和关联信息（2D位置和运动、3D运动、3D深度、2D外观）以实现更好的性能，这使整个跟踪系统变得极其复杂和重量。同时，大多数现有的多bject 跟踪算法仍需要视频注释数据进行训练，这是昂贵的。我们的解决方案尝试在无监督的情况下实现多bject 跟踪。我们使用 ImageNet 上的自我超级vised 学习实现实例表示学习，然后与高质量的探测器合作，完成了多bject 跟踪任务，这种方法简单、高效。我们的方案在 UAV-based 多bject 跟踪与标识和 USV-based 多bject 跟踪标准套件上达到了前三名的表现，并在多个多bject 跟踪竞赛中获得了冠军。例如 BDD100K MOT、MOTS、Waymo 2D MOT 等。
</details></li>
</ul>
<hr>
<h2 id="Towards-General-Purpose-Speech-Abilities-for-Large-Language-Models-Using-Unpaired-Data"><a href="#Towards-General-Purpose-Speech-Abilities-for-Large-Language-Models-Using-Unpaired-Data" class="headerlink" title="Towards General-Purpose Speech Abilities for Large Language Models Using Unpaired Data"></a>Towards General-Purpose Speech Abilities for Large Language Models Using Unpaired Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06753">http://arxiv.org/abs/2311.06753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Junteng Jia, Yuan Shangguan, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, Mike Seltzer</li>
<li>for: 延伸LLM模型，提供整体的语音处理和推理能力，无需使用精心挑选的对应数据。</li>
<li>methods: 使用音频提示代替文本，维护广泛的LLM功能，并能够交换文本和音频模式，利用对话的前Context提供更好的结果。</li>
<li>results: 实验显示，我们的端到端方法与或超越箱式系统（音频识别器+LLM）在响应提示的模型化方面具有相同或更好的性能。<details>
<summary>Abstract</summary>
In this work, we extend the instruction-tuned Llama-2 model with end-to-end general-purpose speech processing and reasoning abilities while maintaining the wide range of LLM capabilities, without using any carefully curated paired data. The proposed model can utilize audio prompts as a replacement for text and sustain a conversation. Such a model also has extended cross-modal capabilities such as being able to perform speech question answering, speech translation, and audio summarization amongst many other closed and open-domain tasks. This is unlike prior approaches in speech, in which LLMs are extended to handle audio for a limited number of pre-designated tasks. Experiments show that our end-to-end approach is on par with or outperforms a cascaded system (speech recognizer + LLM) in terms of modeling the response to a prompt. Furthermore, unlike a cascade, our approach shows the ability to interchange text and audio modalities and utilize the prior context in a conversation to provide better results.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们扩展了 LLama-2 模型，以涉及总体语音处理和推理能力，而无需使用任何精心准备的对应数据。我们提议的模型可以使用音频提示而不是文本进行对话，并且可以实现多modal功能，如语音问答、语音翻译和音频摘要等多种关闭和开放领域任务。这与之前的语音处理方法不同， LLMs 被扩展以处理音频，仅用于限定数量的预定义任务。实验显示，我们的末端方法与或超过简单系统（语音识别器 + LLM）在回快提示的模型化方面。此外，我们的方法还能够交换文本和音频模式，并使用对话中的先前 контекст提供更好的结果。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Generalization-Robustness-Fairness-A-Survey-and-Benchmark"><a href="#Federated-Learning-for-Generalization-Robustness-Fairness-A-Survey-and-Benchmark" class="headerlink" title="Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark"></a>Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06750">http://arxiv.org/abs/2311.06750</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenkehuang/marsfl">https://github.com/wenkehuang/marsfl</a></li>
<li>paper_authors: Wenke Huang, Mang Ye, Zekun Shi, Guancheng Wan, He Li, Bo Du, Qiang Yang</li>
<li>for: 本文提供了一个系统性的报告 Federated Learning 的最新研究发展。</li>
<li>methods: 本文综述了 Federated Learning 的三大研究方向：泛化、稳定性和公平性，并介绍了它们的背景概念、任务设定和主要挑战。</li>
<li>results: 本文对一些知名数据集进行了抽查，并提供了一个公共网站（<a target="_blank" rel="noopener" href="https://github.com/WenkeHuang/MarsFL%EF%BC%89%E4%BB%A5%E8%B7%9F%E8%B8%AA%E8%BF%99%E4%B8%AA%E5%BF%AB%E9%80%9F%E5%8F%91%E5%B1%95%E7%9A%84%E9%A2%86%E5%9F%9F%E7%9A%84%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E3%80%82">https://github.com/WenkeHuang/MarsFL）以跟踪这个快速发展的领域的最新进展。</a><details>
<summary>Abstract</summary>
Federated learning has emerged as a promising paradigm for privacy-preserving collaboration among different parties. Recently, with the popularity of federated learning, an influx of approaches have delivered towards different realistic challenges. In this survey, we provide a systematic overview of the important and recent developments of research on federated learning. Firstly, we introduce the study history and terminology definition of this area. Then, we comprehensively review three basic lines of research: generalization, robustness, and fairness, by introducing their respective background concepts, task settings, and main challenges. We also offer a detailed overview of representative literature on both methods and datasets. We further benchmark the reviewed methods on several well-known datasets. Finally, we point out several open issues in this field and suggest opportunities for further research. We also provide a public website to continuously track developments in this fast advancing field: https://github.com/WenkeHuang/MarsFL.
</details>
<details>
<summary>摘要</summary>
federated learning 已经出现为一种保持隐私的合作方式，各种不同的方面之间进行合作。随着联合学习的流行，一些方法在不同的挑战上提出了许多方法。在这份报告中，我们提供了联合学习的系统性评论，包括该领域的研究历史和术语定义，以及三个基本的研究方向：泛化、鲁棒性和公正。我们还详细介绍了这些研究方向的背景概念、任务设定和主要挑战。此外，我们还为评论的方法和数据集进行了详细的介绍。最后，我们对一些知名的数据集进行了比较。我们还指出了这个领域的一些开放问题，并建议了进一步的研究方向。此外，我们还提供了一个公共网站，以跟踪这个快速发展的领域的最新进展：https://github.com/WenkeHuang/MarsFL。
</details></li>
</ul>
<hr>
<h2 id="Aggregate-Decompose-and-Fine-Tune-A-Simple-Yet-Effective-Factor-Tuning-Method-for-Vision-Transformer"><a href="#Aggregate-Decompose-and-Fine-Tune-A-Simple-Yet-Effective-Factor-Tuning-Method-for-Vision-Transformer" class="headerlink" title="Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective Factor-Tuning Method for Vision Transformer"></a>Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective Factor-Tuning Method for Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06749">http://arxiv.org/abs/2311.06749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongping Chen</li>
<li>for: 提高vision transformer（ViT）模型的 Fine-Tuning效果，解决inner-和cross-layer redundancy问题。</li>
<li>methods: 提出了一种简单 yet effective的 Fine-Tuning方法，即EFfective Factor-Tuning（EFFT）。</li>
<li>results: 在VTAB-1K数据集上，EFFT方法超过了所有基eline，在top-1准确率中取得了75.9%，仅使用0.28%的参数进行全面 Fine-Tuning。<details>
<summary>Abstract</summary>
Recent advancements have illuminated the efficacy of some tensorization-decomposition Parameter-Efficient Fine-Tuning methods like LoRA and FacT in the context of Vision Transformers (ViT). However, these methods grapple with the challenges of inadequately addressing inner- and cross-layer redundancy. To tackle this issue, we introduce EFfective Factor-Tuning (EFFT), a simple yet effective fine-tuning method. Within the VTAB-1K dataset, our EFFT surpasses all baselines, attaining state-of-the-art performance with a categorical average of 75.9% in top-1 accuracy with only 0.28% of the parameters for full fine-tuning. Considering the simplicity and efficacy of EFFT, it holds the potential to serve as a foundational benchmark. The code and model are now available at https://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning.
</details>
<details>
<summary>摘要</summary>
现有最新的进展在tensorization-decomposition Parameter-Efficient Fine-Tuning方法如LoRA和FacT在视transformer（ViT）上得到了证明。然而，这些方法尚未能充分地处理内部和交叉层重复。为解决这个问题，我们介绍了效果因素调整（EFFT），一种简单 yet effective fine-tuning方法。在VTAB-1K数据集上，我们的EFFT超过了所有基elines，在顶部一Accuracy中达到了75.9%，只需0.28%的参数进行全面 fine-tuning。考虑到EFFT的简单性和效果，它具有潜在的基础性。代码和模型现在可以在https://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning中找到。
</details></li>
</ul>
<hr>
<h2 id="Two-Stream-Scene-Understanding-on-Graph-Embedding"><a href="#Two-Stream-Scene-Understanding-on-Graph-Embedding" class="headerlink" title="Two Stream Scene Understanding on Graph Embedding"></a>Two Stream Scene Understanding on Graph Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06746">http://arxiv.org/abs/2311.06746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenkai Yang, Wenyuan Sun, Runxaing Huang</li>
<li>for: 提高计算机视觉中场景理解的能力</li>
<li>methods: 使用两条流网络架构，其中一条是图像特征流，另一条是图像树结构，将两者融合以提高图像分类和场景图生成任务的性能</li>
<li>results: 在ADE20K数据集上进行了实验，并证明了该方法可以提高图像分类精度 compared to 传统方法<details>
<summary>Abstract</summary>
The paper presents a novel two-stream network architecture for enhancing scene understanding in computer vision. This architecture utilizes a graph feature stream and an image feature stream, aiming to merge the strengths of both modalities for improved performance in image classification and scene graph generation tasks. The graph feature stream network comprises a segmentation structure, scene graph generation, and a graph representation module. The segmentation structure employs the UPSNet architecture with a backbone that can be a residual network, Vit, or Swin Transformer. The scene graph generation component focuses on extracting object labels and neighborhood relationships from the semantic map to create a scene graph. Graph Convolutional Networks (GCN), GraphSAGE, and Graph Attention Networks (GAT) are employed for graph representation, with an emphasis on capturing node features and their interconnections. The image feature stream network, on the other hand, focuses on image classification through the use of Vision Transformer and Swin Transformer models. The two streams are fused using various data fusion methods. This fusion is designed to leverage the complementary strengths of graph-based and image-based features.Experiments conducted on the ADE20K dataset demonstrate the effectiveness of the proposed two-stream network in improving image classification accuracy compared to conventional methods. This research provides a significant contribution to the field of computer vision, particularly in the areas of scene understanding and image classification, by effectively combining graph-based and image-based approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detecting-and-Correcting-Hate-Speech-in-Multimodal-Memes-with-Large-Visual-Language-Model"><a href="#Detecting-and-Correcting-Hate-Speech-in-Multimodal-Memes-with-Large-Visual-Language-Model" class="headerlink" title="Detecting and Correcting Hate Speech in Multimodal Memes with Large Visual Language Model"></a>Detecting and Correcting Hate Speech in Multimodal Memes with Large Visual Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06737">http://arxiv.org/abs/2311.06737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minh-Hao Van, Xintao Wu</li>
<li>for: 这个论文主要是为了探讨大语言模型（LLMs）在视觉语言处理中的应用，以及在社交媒体平台上使用这些模型来检测和修正仇恨幻灵的能力。</li>
<li>methods: 该论文使用了预训练的LLaVA模型，通过零shot提示来实现仇恨幻灵检测和修正任务。</li>
<li>results: 经验证明，预训练的LLaVA模型在仇恨幻灵检测和修正任务中具有显著的效果，但也存在一些缺点和局限性。<details>
<summary>Abstract</summary>
Recently, large language models (LLMs) have taken the spotlight in natural language processing. Further, integrating LLMs with vision enables the users to explore more emergent abilities in multimodality. Visual language models (VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive performance on various visio-linguistic tasks. Consequently, there are enormous applications of large models that could be potentially used on social media platforms. Despite that, there is a lack of related work on detecting or correcting hateful memes with VLMs. In this work, we study the ability of VLMs on hateful meme detection and hateful meme correction tasks with zero-shot prompting. From our empirical experiments, we show the effectiveness of the pretrained LLaVA model and discuss its strengths and weaknesses in these tasks.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Recently" is translated as "最近" (most recent)* "large language models" is translated as "大型语言模型" (dà xíng yǔ yán módel)* "integrating" is translated as "结合" (combine)* "vision" is translated as "视觉" (sī jué)* "visio-linguistic" is translated as "语言视觉" (yǔ yán sī jué)* "Visual language models" is translated as "视觉语言模型" (sī jué yǔ yán módel)* "hateful memes" is translated as "仇恨的照片" (chōu hěn de zhào pǐn)* "zero-shot prompting" is translated as "零shot提示" (zhèng shè zhǐ xiǎng)* "empirical experiments" is translated as "实验" (shí yàn)* "strengths and weaknesses" is translated as "优点和缺点" (yù diǎn hé zuò diǎn)
</details></li>
</ul>
<hr>
<h2 id="DeepQC-A-Deep-Learning-System-for-Automatic-Quality-Control-of-In-situ-Soil-Moisture-Sensor-Time-Series-Data"><a href="#DeepQC-A-Deep-Learning-System-for-Automatic-Quality-Control-of-In-situ-Soil-Moisture-Sensor-Time-Series-Data" class="headerlink" title="DeepQC: A Deep Learning System for Automatic Quality Control of In-situ Soil Moisture Sensor Time Series Data"></a>DeepQC: A Deep Learning System for Automatic Quality Control of In-situ Soil Moisture Sensor Time Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06735">http://arxiv.org/abs/2311.06735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lahari Bandaru, Bharat C Irigireddy, Brian Davis<br>for: 这个研究的目的是为了开发一种能够在农业中实时检测 anomalies 的深度学习模型，以提高 soil moisture 数据的质量并帮助农民更好地管理气候变化中的风险。methods: 这个研究使用了 Bi-directional Long Short-Term Memory (LSTM) 模型，称为 DeepQC，来检测 soil moisture 数据中的 anomalies。该模型使用了手动标注的 PSA 观测数据进行训练、验证和测试，并与 Flagit 模型进行比较。results: 研究发现，DeepQC 模型可以准确地检测 soil moisture 数据中的 anomalies，并且其性能与数据量无关。相比之下，Flaggit 模型在检测 anomalies 时存在一定的限制。此外，DeepQC 模型可以在 significatively 更快的时间内完成检测任务。<details>
<summary>Abstract</summary>
Amidst changing climate, real-time soil moisture monitoring is vital for the development of in-season decision support tools to help farmers manage weather related risks. Precision Sustainable Agriculture (PSA) recently established a real-time soil moisture monitoring network across the central, Midwest, and eastern U.S., but field-scale sensor observations often come with data gaps and anomalies. To maintain the data quality needed for development of decision tools, a quality control system is necessary. The International Soil Moisture Network (ISMN) introduced the Flagit module for anomaly detection in soil moisture observations. However, under certain conditions, Flagit's quality control approaches may underperform in identifying anomalies. Recently deep learning methods have been successfully applied to detect anomalies in time series data in various disciplines. However, their use in agriculture has not been yet investigated. This study focuses on developing a Bi-directional Long Short-Term Memory (LSTM) model, referred to as DeepQC, to identify anomalies in soil moisture data. Manual flagged PSA observations were used for training, validation, and testing the model, following an 80:10:10 split. The study then compared the DeepQC and Flagit based estimates to assess their relative performance. Flagit corrected flagged 95.5% of the corrected observations and 50.3% of the anomaly observations, indicating its limitations in identifying anomalies. On the other hand, the DeepQC correctly flagged 99.7% of the correct observations and 95.6% of the anomalies in significantly less time, demonstrating its superiority over Flagit approach. Importantly, DeepQC's performance remained consistent regardless of the number of anomalies. Given the promising results obtained with the DeepQC, future studies will focus on implementing this model on national and global soil moisture networks.
</details>
<details>
<summary>摘要</summary>
在变化的气候条件下，实时土壤湿度监测是不可或缺的 для开发季节性决策支持工具，帮助农民管理气候相关风险。准确可持续农业（PSA）已经在中部、中西部和东部美国建立了实时土壤湿度监测网络，但场地级别的感器观测经常出现数据 gap和异常。为保持需要的数据质量，一个质控系统是必要的。国际土壤湿度网络（ISMN）提出了Flagit模块，用于土壤湿度观测中异常检测，但在某些条件下，Flagit的质控方法可能会下降异常检测性能。现在，深度学习方法在不同领域的时间序列数据中已经得到了成功应用，但在农业中尚未得到研究。本研究旨在开发一种双向长短时间记忆网络（LSTM）模型，称为DeepQC，用于土壤湿度观测中异常检测。使用PSA手动标注的训练、验证和测试数据，按照80:10:10的分 splitting。研究 comparing DeepQC和Flagit两种方法的相对性能，结果显示，DeepQC可以更高精度地检测异常，并且可以在迅速的时间内完成。此外，DeepQC的性能不受异常数量的影响，表明其在不同情况下具有优势。这些结果表明，DeepQC可以成为土壤湿度观测中异常检测的有力工具。未来研究将ocus on在全国和全球土壤湿度网络中实施DeepQC模型。
</details></li>
</ul>
<hr>
<h2 id="An-advantage-based-policy-transfer-algorithm-for-reinforcement-learning-with-metrics-of-transferability"><a href="#An-advantage-based-policy-transfer-algorithm-for-reinforcement-learning-with-metrics-of-transferability" class="headerlink" title="An advantage based policy transfer algorithm for reinforcement learning with metrics of transferability"></a>An advantage based policy transfer algorithm for reinforcement learning with metrics of transferability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06731">http://arxiv.org/abs/2311.06731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ferdous Alam, Parinaz Naghizadeh, David Hoelzle</li>
<li>for: 这个论文的目的是提出一种基于优势的离线策略传递算法（APT-RL），用于在固定Domain环境中进行策略传递。</li>
<li>methods: 这个论文使用了优势概念作为补偿，将知识从源环境传递到目标环境，并提出了一种新的传递性能度标准来评估传递RL算法的性能。</li>
<li>results: 数值实验表明，APT-RL在三个连续控制 benchmark 任务中表现出色，比既有的传递RL算法更高效，并且在大多数任务上比学习从头开始更高效$10%$到$75%$。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) can enable sequential decision-making in complex and high-dimensional environments if the acquisition of a new state-action pair is efficient, i.e., when interaction with the environment is inexpensive. However, there are a myriad of real-world applications in which a high number of interactions are infeasible. In these environments, transfer RL algorithms, which can be used for the transfer of knowledge from one or multiple source environments to a target environment, have been shown to increase learning speed and improve initial and asymptotic performance. However, most existing transfer RL algorithms are on-policy and sample inefficient, and often require heuristic choices in algorithm design. This paper proposes an off-policy Advantage-based Policy Transfer algorithm, APT-RL, for fixed domain environments. Its novelty is in using the popular notion of ``advantage'' as a regularizer, to weigh the knowledge that should be transferred from the source, relative to new knowledge learned in the target, removing the need for heuristic choices. Further, we propose a new transfer performance metric to evaluate the performance of our algorithm and unify existing transfer RL frameworks. Finally, we present a scalable, theoretically-backed task similarity measurement algorithm to illustrate the alignments between our proposed transferability metric and similarities between source and target environments. Numerical experiments on three continuous control benchmark tasks demonstrate that APT-RL outperforms existing transfer RL algorithms on most tasks, and is $10\%$ to $75\%$ more sample efficient than learning from scratch.
</details>
<details>
<summary>摘要</summary>
利用增强学习（RL）可以在复杂高维环境中进行顺序决策，如果新的状态动作对获得是效果的，即在与环境交互时的成本低。然而，现实世界中有许多应用程序在哪里交互的数量太多。在这些环境中，转移RL算法可以将知识从一个或多个源环境传递到目标环境，提高学习速度和初始和终态性能。然而，现有的大多数转移RL算法是在政策上的，并且通常需要许多的参数选择。本文提出了一种基于优点的转移RL算法，称为APT-RL，用于固定领域环境。它的创新在于使用流行的“优点”概念作为规则，以比较源环境中的知识和目标环境中的新知识，从而消除参数选择。此外，我们提出了一个新的转移性能指标，用于评估我们的算法的性能，并将现有的转移RL框架统一。最后，我们提供了一种可扩展、理论支持的任务相似度测量算法，用于证明我们的转移性能指标与源和目标环境之间的相似性。数值实验表明，APT-RL在三个连续控制 benchmark 任务上表现出色，超过现有的转移RL算法，并且在大多数任务上比learn from scratch的学习效率高$10\%$到$75\%$。
</details></li>
</ul>
<hr>
<h2 id="Enabling-Human-Centered-AI-A-Methodological-Perspective"><a href="#Enabling-Human-Centered-AI-A-Methodological-Perspective" class="headerlink" title="Enabling Human-Centered AI: A Methodological Perspective"></a>Enabling Human-Centered AI: A Methodological Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06703">http://arxiv.org/abs/2311.06703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Xu, Zaifeng Gao</li>
<li>for: 本文提出了一种涵盖设计目标、设计原则、实施方法、跨学科团队、HCAI方法和HCAI过程的完整HCAI框架，以帮助实践HCAI的应用。</li>
<li>methods: 本文提出了一种“三层”方法来实现HCAI框架，包括设计目标、设计原则、实施方法和HCAI过程。</li>
<li>results: 本文认为该框架可以解决现有HCAI框架的杠�和实践中遇到的挑战，并且可以帮助实践HCAI的应用。<details>
<summary>Abstract</summary>
Human-centered AI (HCAI) is a design philosophy that advocates prioritizing humans in designing, developing, and deploying intelligent systems, aiming to maximize the benefits of AI to humans and avoid potential adverse impacts. While HCAI continues to influence, the lack of guidance on methodology in practice makes its adoption challenging. This paper proposes a comprehensive HCAI framework based on our previous work with integrated components, including design goals, design principles, implementation approaches, interdisciplinary teams, HCAI methods, and HCAI processes. This paper also presents a "three-layer" approach to facilitate the implementation of the framework. We believe this systematic and executable framework can overcome the weaknesses in current HCAI frameworks and the challenges currently faced in practice, putting it into action to enable HCAI further.
</details>
<details>
<summary>摘要</summary>
人类中心的人工智能（HCAI）是一种设计哲学，强调在设计、开发和部署智能系统时，优先考虑人类的需求和利益，以最大化人工智能对人类的 beneficial impacts，避免 potential negative impacts。 although HCAI continues to influence, the lack of guidance on methodology in practice makes its adoption challenging. This paper proposes a comprehensive HCAI framework based on our previous work with integrated components, including design goals, design principles, implementation approaches, interdisciplinary teams, HCAI methods, and HCAI processes. This paper also presents a "three-layer" approach to facilitate the implementation of the framework. We believe this systematic and executable framework can overcome the weaknesses in current HCAI frameworks and the challenges currently faced in practice, putting it into action to enable HCAI further.Here's the translation of the text into Traditional Chinese:人类中心的人工智能（HCAI）是一种设计哲学，强调在设计、开发和部署智能系统时，优先考虑人类的需求和利益，以最大化人工智能对人类的 beneficial impacts，避免 potential negative impacts。 although HCAI continues to influence, the lack of guidance on methodology in practice makes its adoption challenging. This paper proposes a comprehensive HCAI framework based on our previous work with integrated components, including design goals, design principles, implementation approaches, interdisciplinary teams, HCAI methods, and HCAI processes. This paper also presents a "three-layer" approach to facilitate the implementation of the framework. We believe this systematic and executable framework can overcome the weaknesses in current HCAI frameworks and the challenges currently faced in practice, putting it into action to enable HCAI further.
</details></li>
</ul>
<hr>
<h2 id="An-Investigation-of-Hepatitis-B-Virus-Genome-using-Markov-Models"><a href="#An-Investigation-of-Hepatitis-B-Virus-Genome-using-Markov-Models" class="headerlink" title="An Investigation of Hepatitis B Virus Genome using Markov Models"></a>An Investigation of Hepatitis B Virus Genome using Markov Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06699">http://arxiv.org/abs/2311.06699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khadijeh, Jahanian, Elnaz Shalbafian, Morteza Saberi, Roohallah Alizadehsani, Iman Dehzangi<br>for:这项研究的目的是investigating the mutational footprint of APOBEC3 enzymes in the HBV genome.methods:这项研究使用了一种多变量数据分析技术，通过分析全基因组HBV序列从多种自然感染者中获取的数据，以探索APOBEC3蛋白的抑瘤作用。results:这项研究发现，APOBEC3蛋白对HBV genomes的抑瘤具有不同的结果，并且这些结果与HIV genomes中的抑瘤结果不同。 Specifically, the study found that either APOBEC3 enzymes are not active against HBV, or the induction of G-to-A mutations by these enzymes is not sequence context-dependent in the HBV genome.<details>
<summary>Abstract</summary>
The human genome encodes a family of editing enzymes known as APOBEC3 (apolipoprotein B mRNA editing enzyme, catalytic polypeptide-like 3). Several family members, such as APO-BEC3G, APOBEC3F, and APOBEC3H haplotype II, exhibit activity against viruses such as HIV. These enzymes induce C-to-U mutations in the negative strand of viral genomes, resulting in multiple G-to-A changes, commonly referred to as 'hypermutation.' Mutations catalyzed by these enzymes are sequence context-dependent in the HIV genome; for instance, APOBEC3G preferen-tially mutates G within GG, TGG, and TGGG contexts, while other members mutate G within GA, TGA, and TGAA contexts. However, the same sequence context has not been explored in relation to these enzymes and HBV. In this study, our objective is to identify the mutational footprint of APOBEC3 enzymes in the HBV genome. To achieve this, we employ a multivariable data analytics technique to investigate motif preferences and potential sequence hierarchies of mutation by APOBEC3 enzymes using full genome HBV sequences from a diverse range of naturally infected patients. This approach allows us to distinguish between normal and hypermutated sequences based on the representation of mono- to tetra-nucleotide motifs. Additionally, we aim to identify motifs associated with hypermutation induced by different APOBEC3 enzymes in HBV genomes. Our analyses reveal that either APOBEC3 enzymes are not active against HBV, or the induction of G-to-A mutations by these enzymes is not sequence context-dependent in the HBV genome.
</details>
<details>
<summary>摘要</summary>
人类基因组编码一家编辑酶家族，称为APOBEC3（肽聚簇BmRNA编辑酶， catalytic polypeptide-like 3）。家族成员，如APO-BEC3G、APOBEC3F和APOBEC3H haplotype II，对病毒如HIV有活性。这些酶在病毒基因组中引起C-to-U变化，导致多个G-to-A变化，通常称为"超迁变"。这些变化由这些酶catalyzed是病毒基因组中的序列上下文依赖的；例如，APOBEC3G更偏好在GG、TGG和TGGG上进行mutation，而其他成员更偏好在GA、TGA和TGAA上进行mutation。然而，这些序列上下文尚未在APOBEC3酶和HBV之间进行研究。在这项研究中，我们的目标是确定APOBEC3酶对HBV基因组中的mutational footprint。为了实现这一目标，我们使用多变量数据分析技术，investigate APOBEC3酶对HBV基因组中的motif偏好和可能的序列层次结构。这种方法允许我们根据全基因组HBV序列从多种自然感染的患者中分离出正常和高度突变序列。此外，我们还计划确定APOBEC3酶对HBV基因组中的特定序列上下文所启用的mutation。我们的分析发现，或者APOBEC3酶不活跃对HBV，或者它们在HBV基因组中不是序列上下文依赖的。
</details></li>
</ul>
<hr>
<h2 id="Conversational-Data-Exploration-A-Game-Changer-for-Designing-Data-Science-Pipelines"><a href="#Conversational-Data-Exploration-A-Game-Changer-for-Designing-Data-Science-Pipelines" class="headerlink" title="Conversational Data Exploration: A Game-Changer for Designing Data Science Pipelines"></a>Conversational Data Exploration: A Game-Changer for Designing Data Science Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06695">http://arxiv.org/abs/2311.06695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Genoveva Vargas-Solar, Tania Cerquitelli, Javier A. Espinosa-Oviedo, François Cheval, Anthelme Buchaille, Luca Polgar</li>
<li>for: 这篇论文是为了提供一种对话方式，使系统Chatin实现数据探索的直观体验。</li>
<li>methods: 该论文使用了一种新的数据科学解决方案，通过对话方式帮助非技术用户从不同领域探索数据，并从数据中提取知识。</li>
<li>results: 该论文通过实现对话方式，为非技术用户提供了一种直观的数据探索体验，并帮助他们更好地理解数据。<details>
<summary>Abstract</summary>
This paper proposes a conversational approach implemented by the system Chatin for driving an intuitive data exploration experience. Our work aims to unlock the full potential of data analytics and artificial intelligence with a new generation of data science solutions. Chatin is a cutting-edge tool that democratises access to AI-driven solutions, empowering non-technical users from various disciplines to explore data and extract knowledge from it.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种对话方式，通过系统Chatin实现了INTUISIVE DATA EXPLORATION EXPERIENCE。我们的工作目标是通过一代新的数据科学解决方案，解放数据分析和人工智能的潜力。Chatin是一种先进的工具，通过启用非技术用户从各个领域来探索数据，从数据中提取知识。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Multi-View-Language-Grounding"><a href="#Comparative-Multi-View-Language-Grounding" class="headerlink" title="Comparative Multi-View Language Grounding"></a>Comparative Multi-View Language Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06694">http://arxiv.org/abs/2311.06694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chancharik Mitra, Abrar Anwar, Rodolfo Corona, Dan Klein, Trevor Darrell, Jesse Thomason</li>
<li>for: 解决对象引用问题时给出比较语言描述</li>
<li>methods: 使用 transformers 进行多视图考虑和语言描述的 Pragmatic 理解</li>
<li>results: 比较理解帮助实现 SOTA 性能在 SNARE 对象引用任务上<details>
<summary>Abstract</summary>
In this work, we consider the task of resolving object referents when given a comparative language description. We present a Multi-view Approach to Grounding in Context (MAGiC) that leverages transformers to pragmatically reason over both objects given multiple image views and a language description. In contrast to past efforts that attempt to connect vision and language for this task without fully considering the resulting referential context, MAGiC makes use of the comparative information by jointly reasoning over multiple views of both object referent candidates and the referring language expression. We present an analysis demonstrating that comparative reasoning contributes to SOTA performance on the SNARE object reference task.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们考虑了对象引用的解决方法，当给定一个比较语言描述时。我们提出了一种多视图方法 для文本背景（MAGiC），利用转换器来 Pragmatic 地在多个图像视图和语言描述之间进行关系reasoning。与过去的尝试不同，MAGiC 利用比较信息，同时对多个对象引用候选者和引用语言表达进行联合理解。我们提供分析，表明了比较理解对 SNARE 对象引用任务的最高性能做出贡献。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/cs.AI_2023_11_12/" data-id="clp89do9m007hi7880m4k2fe8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/cs.CL_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T11:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/cs.CL_2023_11_12/">cs.CL - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SELF-EXPLAIN-Teaching-Large-Language-Models-to-Reason-Complex-Questions-by-Themselves"><a href="#SELF-EXPLAIN-Teaching-Large-Language-Models-to-Reason-Complex-Questions-by-Themselves" class="headerlink" title="SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves"></a>SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06985">http://arxiv.org/abs/2311.06985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiachen Zhao, Zonghai Yao, Zhichao Yang, Hong Yu</li>
<li>for: 提高大语言模型的可靠逻辑能力</li>
<li>methods: 使用自我解释生成链条例子</li>
<li>results: 使用自我解释可以提高大语言模型的自信度、准确率和不偏率，并在复杂问题 answering 任务上达到或超过人工制作的 CoT 例子表现。<details>
<summary>Abstract</summary>
Large language models (LLMs) can generate intermediate reasoning steps. To elicit the reliable reasoning, the common practice is to employ few-shot chain-of-thought prompting, where several in-context demonstrations for reasoning are prepended to the question. However, such chain-of-thought examples are expensive to craft, especially for professional domains, and can have high variance depending on human annotators. Therefore, this work investigates whether LLMs can teach themselves to reason without human-crafted demonstrations. We propose SELF-EXPLAIN to generate CoT examples by LLMs inspired by "encoding specificity" in human memory retrieval. We find using self-explanations makes LLMs more confident, more calibrated and less biased when answering complex questions. Moreover, we find prompting with self-explanations can even significantly outperform using human-crafted CoTs on several complex question answering dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Retrieval-and-Generative-Approaches-for-a-Pregnancy-Chatbot-in-Nepali-with-Stemmed-and-Non-Stemmed-Data-A-Comparative-Study"><a href="#Retrieval-and-Generative-Approaches-for-a-Pregnancy-Chatbot-in-Nepali-with-Stemmed-and-Non-Stemmed-Data-A-Comparative-Study" class="headerlink" title="Retrieval and Generative Approaches for a Pregnancy Chatbot in Nepali with Stemmed and Non-Stemmed Data : A Comparative Study"></a>Retrieval and Generative Approaches for a Pregnancy Chatbot in Nepali with Stemmed and Non-Stemmed Data : A Comparative Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06898">http://arxiv.org/abs/2311.06898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujan Poudel, Nabin Ghimire, Bipesh Subedi, Saugat Singh</li>
<li>for: 这个研究旨在开发一个基于自然语言处理（NLP）技术的医疗域聊天机器人，提供有关怀孕信息。</li>
<li>methods: 这个研究使用了两种不同的NLP基本方法，一种是基于BERT的多类分类 Retrieval Approach，另一种是基于Transformer的生成型聊天机器人。</li>
<li>results: 实验结果表明，BERT基本模型在非分词数据上表现良好，而自建Transformer模型在分词数据上表现更好。在非分词数据上，DistilBERT模型 achieved highest training和验证精度，testing精度为0.9165。在生成方法中，使用transformer 1 gram BLEU和2 gram BLEU得分为0.3570和0.1413。<details>
<summary>Abstract</summary>
The field of Natural Language Processing which involves the use of artificial intelligence to support human languages has seen tremendous growth due to its high-quality features. Its applications such as language translation, chatbots, virtual assistants, search autocomplete, and autocorrect are widely used in various domains including healthcare, advertising, customer service, and target advertising. To provide pregnancy-related information a health domain chatbot has been proposed and this work explores two different NLP-based approaches for developing the chatbot. The first approach is a multiclass classification-based retrieval approach using BERTbased multilingual BERT and multilingual DistilBERT while the other approach employs a transformer-based generative chatbot for pregnancy-related information. The performance of both stemmed and non-stemmed datasets in Nepali language has been analyzed for each approach. The experimented results indicate that BERT-based pre-trained models perform well on non-stemmed data whereas scratch transformer models have better performance on stemmed data. Among the models tested the DistilBERT model achieved the highest training and validation accuracy and testing accuracy of 0.9165 on the retrieval-based model architecture implementation on the non-stemmed dataset. Similarly, in the generative approach architecture implementation with transformer 1 gram BLEU and 2 gram BLEU scores of 0.3570 and 0.1413 respectively were achieved.
</details>
<details>
<summary>摘要</summary>
自然语言处理（NLP）领域，利用人工智能支持人类语言的应用有很大的发展 potential，这主要是因为它的高质量特性。其应用包括语言翻译、chatbot、虚拟助手、搜索自动完成和自动修改等，在医疗、广告、客服等领域都有广泛的应用。为了提供妊娠相关信息，这种工作提出了一个医学领域chatbot，本文探讨了两种不同的NLP基于的方法来开发chatbot。第一种方法是基于BERT的多类分类 retrieve Approach，使用BERT和DistilBERT multilingual模型；第二种方法是基于transformer的生成chatbot Approach。对于尼泊尔语的分ensed和不分ensed数据进行了分析。实验结果显示，BERT基于预训练模型在不分ensed数据上表现良好，而凿transformer模型在分ensed数据上表现更好。在多个模型中，DistilBERT模型在非分ensed数据上达到了0.9165的训练和验证精度，以及0.3570和0.1413的1 gram BLEU和2 gram BLEU分数。
</details></li>
</ul>
<hr>
<h2 id="DialMAT-Dialogue-Enabled-Transformer-with-Moment-Based-Adversarial-Training"><a href="#DialMAT-Dialogue-Enabled-Transformer-with-Moment-Based-Adversarial-Training" class="headerlink" title="DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training"></a>DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06855">http://arxiv.org/abs/2311.06855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/keio-smilab23/dialmat">https://github.com/keio-smilab23/dialmat</a></li>
<li>paper_authors: Kanta Kaneda, Ryosuke Korekata, Yuiga Wada, Shunya Nagashima, Motonari Kambara, Yui Iioka, Haruka Matsuo, Yuto Imai, Takayuki Nishimura, Komei Sugiura</li>
<li>for: 本研究 targets the DialFRED task, which is the task of embodied instruction following in a setting where an agent can actively ask questions about the task.</li>
<li>methods: 本研究提出了 DialMAT，它使用了瞬时对抗训练，将对抗扰动添加到语言、图像和动作的幂论空间中。此外，它还引入了跨模态平行特征提取机制，通过基础模型对语言和图像进行同时学习。</li>
<li>results: 我们使用了基于DialFRED dataset构建的数据集进行评估，并与基线方法进行比较。结果显示，我们的模型在成功率和路径权重成功率上表现了superiority。此外，我们的模型在CVPR 2023 Embodied AI工作坊上举行的DialFRED Challenge中获得了第一名。<details>
<summary>Abstract</summary>
This paper focuses on the DialFRED task, which is the task of embodied instruction following in a setting where an agent can actively ask questions about the task. To address this task, we propose DialMAT. DialMAT introduces Moment-based Adversarial Training, which incorporates adversarial perturbations into the latent space of language, image, and action. Additionally, it introduces a crossmodal parallel feature extraction mechanism that applies foundation models to both language and image. We evaluated our model using a dataset constructed from the DialFRED dataset and demonstrated superior performance compared to the baseline method in terms of success rate and path weighted success rate. The model secured the top position in the DialFRED Challenge, which took place at the CVPR 2023 Embodied AI workshop.
</details>
<details>
<summary>摘要</summary>
这篇论文关注的是DialogFRED任务，即在一个 Setting 中，智能机器可以主动提问任务的 Embodied instruction following 任务。为解决这个任务，我们提议了DialMAT。DialMAT 引入了时刻基于的对抗训练，将对抗扰动包含在语言、图像和动作的含义空间中。此外，它还引入了跨Modal 平行特征提取机制，使用基础模型来处理语言和图像。我们使用了基于 DialogFRED  dataset constructed 的数据集进行评估，并证明了与基线方法相比，我们的模型在成功率和路径权重成功率方面具有显著优势。我们的模型在 CVPR 2023 Embodied AI 工作坊举行的 DialFRED 挑战中占据了第一名。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Textual-Normalization-for-Hate-Speech-Detection"><a href="#Automatic-Textual-Normalization-for-Hate-Speech-Detection" class="headerlink" title="Automatic Textual Normalization for Hate Speech Detection"></a>Automatic Textual Normalization for Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06851">http://arxiv.org/abs/2311.06851</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anhhoang0529/small-lexnormvihsd">https://github.com/anhhoang0529/small-lexnormvihsd</a></li>
<li>paper_authors: Anh Thi-Hoang Nguyen, Dung Ha Nguyen, Nguyet Thi Nguyen, Khanh Thanh-Duy Ho, Kiet Van Nguyen</li>
<li>for: 本研究旨在提高社交媒体数据中非标pecific字（NSW）的处理能力，以便进行更好的自然语言处理（NLP）任务。</li>
<li>methods: 本研究使用单一的sequence-to-sequence（Seq2Seq）模型进行文本正常化，并提供了2,181个人注解的评论数据集，它们的间接标注协调率为0.9014。</li>
<li>results: 研究表明，通过使用Seq2Seq模型进行文本正常化，可以提高针对社交媒体数据的仇恨言语检测（HSD）任务的准确率约2%。此外，文本正常化还可以提高NLP任务的总表现水平。数据集可供研究用途。<details>
<summary>Abstract</summary>
Social media data is a valuable resource for research, yet it contains a wide range of non-standard words (NSW). These irregularities hinder the effective operation of NLP tools. Current state-of-the-art methods for the Vietnamese language address this issue as a problem of lexical normalization, involving the creation of manual rules or the implementation of multi-staged deep learning frameworks, which necessitate extensive efforts to craft intricate rules. In contrast, our approach is straightforward, employing solely a sequence-to-sequence (Seq2Seq) model. In this research, we provide a dataset for textual normalization, comprising 2,181 human-annotated comments with an inter-annotator agreement of 0.9014. By leveraging the Seq2Seq model for textual normalization, our results reveal that the accuracy achieved falls slightly short of 70%. Nevertheless, textual normalization enhances the accuracy of the Hate Speech Detection (HSD) task by approximately 2%, demonstrating its potential to improve the performance of complex NLP tasks. Our dataset is accessible for research purposes.
</details>
<details>
<summary>摘要</summary>
社交媒体数据是一种有价值的资源 для研究，但它包含了广泛的非标准词 (NSW)。这些异常会阻碍NLP工具的有效运行。现有的state-of-the-art方法对越南语言问题解决这个问题为词语正常化问题，需要创建手动规则或实施多stage深度学习框架，这需要很大的努力来编写复杂的规则。与之相反，我们的方法是简单的，只使用序列到序列（Seq2Seq）模型。在这项研究中，我们提供了文本正常化的数据集，包括2,181个人注释的评论，其间的间隔注释协调度为0.9014。通过利用Seq2Seq模型进行文本正常化，我们的结果表明，准确率达到了约70%。虽然文本正常化提高了仇恨言语检测（HSD）任务的准确率约2%，这表明它有可能改善复杂NLP任务的性能。我们的数据集可以用于研究用途。
</details></li>
</ul>
<hr>
<h2 id="GIELLM-Japanese-General-Information-Extraction-Large-Language-Model-Utilizing-Mutual-Reinforcement-Effect"><a href="#GIELLM-Japanese-General-Information-Extraction-Large-Language-Model-Utilizing-Mutual-Reinforcement-Effect" class="headerlink" title="GIELLM: Japanese General Information Extraction Large Language Model Utilizing Mutual Reinforcement Effect"></a>GIELLM: Japanese General Information Extraction Large Language Model Utilizing Mutual Reinforcement Effect</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06838">http://arxiv.org/abs/2311.06838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengguang Gan, Qinghao Zhang, Tatsunori Mori<br>for: 本研究旨在开发一个能同时处理多种自然语言处理（NLP）子任务的通用语言模型（GIELLM），以提高现有的专门化模型的性能。methods: 本研究使用了一个统一的输入-输出架构， integrate了文本分类、情感分析、名称实体识别、关系EXTRACTION和事件EXTRACTION等多种自然语言处理子任务。此外，研究还利用了相互强制效应（MRE），从而提高了统一任务中的性能。results: 实验结果显示，GIELLM在日本混合数据集上取得了State-of-the-Art（SOTA）的成绩，较GPT-3.5-Turbo有明显的改善。此外，在新的文本分类关系和事件EXTRACTION数据集上进行独立评估，也获得了相互强制效应的优化。这个突破破坏了传统的NLP子任务特化模型，并将大多数IE子任务整合到了一个通用语言模型架构中。<details>
<summary>Abstract</summary>
Information Extraction (IE) stands as a cornerstone in natural language processing, traditionally segmented into distinct sub-tasks. The advent of Large Language Models (LLMs) heralds a paradigm shift, suggesting the feasibility of a singular model addressing multiple IE subtasks. In this vein, we introduce the General Information Extraction Large Language Model (GIELLM), which integrates text Classification, Sentiment Analysis, Named Entity Recognition, Relation Extraction, and Event Extraction using a uniform input-output schema. This innovation marks the first instance of a model simultaneously handling such a diverse array of IE subtasks. Notably, the GIELLM leverages the Mutual Reinforcement Effect (MRE), enhancing performance in integrated tasks compared to their isolated counterparts. Our experiments demonstrate State-of-the-Art (SOTA) results in five out of six Japanese mixed datasets, significantly surpassing GPT-3.5-Turbo. Further, an independent evaluation using the novel Text Classification Relation and Event Extraction(TCREE) dataset corroborates the synergistic advantages of MRE in text and word classification. This breakthrough paves the way for most IE subtasks to be subsumed under a singular LLM framework. Specialized fine-tune task-specific models are no longer needed.
</details>
<details>
<summary>摘要</summary>
信息提取（IE）作为自然语言处理的基石，曾经分为多个子任务。现在大语言模型（LLM）的出现，标志着一种新的 парадиг shift，提出了一个单一模型可以处理多个 IE 子任务。为此，我们介绍了通用信息提取大语言模型（GIELLM），它将文本分类、情感分析、名实Recognition、关系提取和事件提取 integrates into a uniform input-output schema.这是首次一个模型同时处理这些多样化的 IE 子任务。值得注意的是，GIELLM 利用了相互强制效应（MRE），在集成任务中提高了性能，相比独立的任务。我们的实验表明，GIELLM 在日本混合数据集上达到了状态之最（SOTA）水平，明显超过 GPT-3.5-Turbo。此外，一个独立的评估使用新的文本类别关系和事件抽象（TCREE）数据集也证明了MRE在文本和单词分类中的共同优势。这一突破可能使得大多数 IE 子任务被纳入单一 LLM 框架中，不再需要专门的精化任务模型。
</details></li>
</ul>
<hr>
<h2 id="Cricket-Player-Profiling-Unraveling-Strengths-and-Weaknesses-Using-Text-Commentary-Data"><a href="#Cricket-Player-Profiling-Unraveling-Strengths-and-Weaknesses-Using-Text-Commentary-Data" class="headerlink" title="Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text Commentary Data"></a>Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text Commentary Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06818">http://arxiv.org/abs/2311.06818</a></li>
<li>repo_url: None</li>
<li>paper_authors: Swarup Ranjan Behera, Vijaya V. Saradhi</li>
<li>For: This paper aims to develop computational models to extract the rules governing cricket players’ strengths and weaknesses, with the goal of devising player-specific strategies.* Methods: The paper utilizes unstructured data from cricket text commentary to construct comprehensive strength and weakness rules for cricket players, and employs dimensionality reduction techniques to simplify the rule-building process.* Results: The paper conducts an in-depth analysis of cricket player strengths and weaknesses using a vast corpus of over one million text commentaries, and validates the constructed rules through two distinct methodologies: intrinsic and extrinsic. The results are made openly accessible, including the collected data, source code, and results for over 250 cricket players.<details>
<summary>Abstract</summary>
Devising player-specific strategies in cricket necessitates a meticulous understanding of each player's unique strengths and weaknesses. Nevertheless, the absence of a definitive computational approach to extract such insights from cricket players poses a significant challenge. This paper seeks to address this gap by establishing computational models designed to extract the rules governing player strengths and weaknesses, thereby facilitating the development of tailored strategies for individual players. The complexity of this endeavor lies in several key areas: the selection of a suitable dataset, the precise definition of strength and weakness rules, the identification of an appropriate learning algorithm, and the validation of the derived rules. To tackle these challenges, we propose the utilization of unstructured data, specifically cricket text commentary, as a valuable resource for constructing comprehensive strength and weakness rules for cricket players. We also introduce computationally feasible definitions for the construction of these rules, and present a dimensionality reduction technique for the rule-building process. In order to showcase the practicality of this approach, we conduct an in-depth analysis of cricket player strengths and weaknesses using a vast corpus of more than one million text commentaries. Furthermore, we validate the constructed rules through two distinct methodologies: intrinsic and extrinsic. The outcomes of this research are made openly accessible, including the collected data, source code, and results for over 250 cricket players, which can be accessed at https://bit.ly/2PKuzx8.
</details>
<details>
<summary>摘要</summary>
制定玩家特定策略在板球需要非常细致地理解每名球员的独特优势和劣势。然而，没有一种确定的计算方法可以从板球球员中提取这些洞察。这篇论文希望通过建立计算模型，从板球球员中提取规则，以便为每名球员制定特定策略。这个复杂的任务存在多个关键领域：选择合适的数据集、准确定义优势和劣势规则、选择适当的学习算法和验证 derivated 规则。为了解决这些挑战，我们提议使用无结构数据，具体是板球文字评论，作为建立全面优势和劣势规则的 valuabel 资源。我们还介绍了计算可行的规则定义方法，并提出了维度减少技术来进行规则建立过程。为了证明这种方法的实用性，我们对板球球员的优势和劣势进行了深入分析，使用了超过一百万个文字评论。此外，我们还验证了建立的规则，通过两种不同的方法：内在和外在。研究结果将公开访问，包括收集的数据、源代码和结果，可以在https://bit.ly/2PKuzx8 中获取。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-GPT-4-for-chest-X-ray-impression-generation-A-reader-study-on-performance-and-perception"><a href="#Evaluation-of-GPT-4-for-chest-X-ray-impression-generation-A-reader-study-on-performance-and-perception" class="headerlink" title="Evaluation of GPT-4 for chest X-ray impression generation: A reader study on performance and perception"></a>Evaluation of GPT-4 for chest X-ray impression generation: A reader study on performance and perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06815">http://arxiv.org/abs/2311.06815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Ziegelmayer, Alexander W. Marka, Nicolas Lenhart, Nadja Nehls, Stefan Reischl, Felix Harder, Andreas Sauter, Marcus Makowski, Markus Graf, Joshua Gawlitza</li>
<li>for: 这个研究用于检查GPT-4模型是否可以生成高质量的胸部X射影印象。</li>
<li>methods: 研究使用了GPT-4模型，给它提供了图像、文本、图文三种不同的输入模式，然后让它生成对应的印象。 radiologist then blindly评分了这些印象，并将它们分为人类写的和AI生成的两类。</li>
<li>results: 研究发现，人类写的印象得分最高，但与文本基于印象的分数相似。自动评分指标与评分分数之间存在显著的相关性，但输入模式对检测AI生成印象的能力产生了差异。 AI生成的印象的评分比人类写的印象更差，即使用 radiologist 写的。<details>
<summary>Abstract</summary>
The remarkable generative capabilities of multimodal foundation models are currently being explored for a variety of applications. Generating radiological impressions is a challenging task that could significantly reduce the workload of radiologists. In our study we explored and analyzed the generative abilities of GPT-4 for Chest X-ray impression generation. To generate and evaluate impressions of chest X-rays based on different input modalities (image, text, text and image), a blinded radiological report was written for 25-cases of the publicly available NIH-dataset. GPT-4 was given image, finding section or both sequentially to generate an input dependent impression. In a blind randomized reading, 4-radiologists rated the impressions and were asked to classify the impression origin (Human, AI), providing justification for their decision. Lastly text model evaluation metrics and their correlation with the radiological score (summation of the 4 dimensions) was assessed. According to the radiological score, the human-written impression was rated highest, although not significantly different to text-based impressions. The automated evaluation metrics showed moderate to substantial correlations to the radiological score for the image impressions, however individual scores were highly divergent among inputs, indicating insufficient representation of radiological quality. Detection of AI-generated impressions varied by input and was 61% for text-based impressions. Impressions classified as AI-generated had significantly worse radiological scores even when written by a radiologist, indicating potential bias. Our study revealed significant discrepancies between a radiological assessment and common automatic evaluation metrics depending on the model input. The detection of AI-generated findings is subject to bias that highly rated impressions are perceived as human-written.
</details>
<details>
<summary>摘要</summary>
“研究现在正在探索多modal基础模型的生成能力，以应用于各种领域。生成骨质影像是一个具有挑战性的任务，可以帮助骨科医生优化工作效率。我们在这个研究中探索了GPT-4模型的生成能力，并分析了它对骨质影像的生成。为了生成和评估不同输入模式（影像、文本、文本和影像）的骨质影像，我们将医学报告撰写为25例NIH数据集的隐藏标签。GPT-4模型获得了影像、发现部分或两者来生成输入对应的印象。在隐藏随机读取中，4名医生评估了印象，并被要求根据印象的来源（人类、AI）进行分类，并提供详细的评论。我们发现文本模型评估度和医学评分（四个维度的和）之间存在 Moderate to substantial 的相互相关性，但个别输入的评分存在很大的差异，这表明医学质量的抽象不够。我们发现自动生成印象的检测存在偏见，对于文本印象而言，检测率为61%。我们发现，即使由医生生成的AI印象，也存在偏见。我们的研究表明，医学评分和自动评估度之间存在差异，尤其是在不同的输入模式下。”
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Question-Rewriting-Systems-to-Questions-of-Varying-Hardness"><a href="#On-the-Robustness-of-Question-Rewriting-Systems-to-Questions-of-Varying-Hardness" class="headerlink" title="On the Robustness of Question Rewriting Systems to Questions of Varying Hardness"></a>On the Robustness of Question Rewriting Systems to Questions of Varying Hardness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06807">http://arxiv.org/abs/2311.06807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nusnlp/diffqre">https://github.com/nusnlp/diffqre</a></li>
<li>paper_authors: Hai Ye, Hwee Tou Ng, Wenjuan Han</li>
<li>for: 本文关注在异 Reformulation 系统对 вопро题的灵活性进行扩展，以提高问题的 rewrite 灵活性。</li>
<li>methods: 本文提出了一种自动将问题分类为不同困难度的方法，并通过人工评估确定问题的 rewrite 困难度。 finally, 本文提出了一种新的学习框架，通过独立地在不同困难度的问题上训练 QR 模型，然后将这些模型组合成一个joint模型进行推理。</li>
<li>results: 实验结果表明，本文提出的方法可以提高问题的 rewrite 性能，并且在两个数据集上达到了比基eline更高的性能。<details>
<summary>Abstract</summary>
In conversational question answering (CQA), the task of question rewriting~(QR) in context aims to rewrite a context-dependent question into an equivalent self-contained question that gives the same answer. In this paper, we are interested in the robustness of a QR system to questions varying in rewriting hardness or difficulty. Since there is a lack of questions classified based on their rewriting hardness, we first propose a heuristic method to automatically classify questions into subsets of varying hardness, by measuring the discrepancy between a question and its rewrite. To find out what makes questions hard or easy for rewriting, we then conduct a human evaluation to annotate the rewriting hardness of questions. Finally, to enhance the robustness of QR systems to questions of varying hardness, we propose a novel learning framework for QR that first trains a QR model independently on each subset of questions of a certain level of hardness, then combines these QR models as one joint model for inference. Experimental results on two datasets show that our framework improves the overall performance compared to the baselines.
</details>
<details>
<summary>摘要</summary>
在对话式问答（CQA）任务中，问题重写（QR）任务的目标是将上下文相依的问题重写成等效的自包含问题，以便得到相同的答案。在这篇论文中，我们对Question重写系统的稳定性具有兴趣。因为没有按 Rewrite 难度分类的问题，我们首先提出了一种euristic方法，使用问题和重写之间的差异来自动分类问题，并将其分为不同难度的子集。然后，我们进行了人工评估，以标注问题的重写难度。最后，我们提出了一种新的学习框架，用于增强Question重写系统对问题难度的Robustness。我们首先在每个难度水平上独立训练了QR模型，然后将这些QR模型组合成一个共同模型进行推理。实验结果表明，我们的框架可以提高对比基eline的总性能。
</details></li>
</ul>
<hr>
<h2 id="Tunable-Soft-Prompts-are-Messengers-in-Federated-Learning"><a href="#Tunable-Soft-Prompts-are-Messengers-in-Federated-Learning" class="headerlink" title="Tunable Soft Prompts are Messengers in Federated Learning"></a>Tunable Soft Prompts are Messengers in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06805">http://arxiv.org/abs/2311.06805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibaba/federatedscope">https://github.com/alibaba/federatedscope</a></li>
<li>paper_authors: Chenhe Dong, Yuexiang Xie, Bolin Ding, Ying Shen, Yaliang Li</li>
<li>for: 这个论文的目的是提出一种基于联合学习的新训练方法，以保护模型隐私并提高联合学习的效率。</li>
<li>methods: 该论文使用了软提示的技术，通过在服务器和客户端之间更新和传输软提示来实现信息交换。这些软提示将担任全球模型参数的角色，将本地数据和全球模型的有用知识传递给客户端进行训练。</li>
<li>results: 对比多个基eline，实验结果显示了提出的方法的效果，包括降低了联合学习的通信和计算成本，同时保护了全球模型的隐私。<details>
<summary>Abstract</summary>
Federated learning (FL) enables multiple participants to collaboratively train machine learning models using decentralized data sources, alleviating privacy concerns that arise from directly sharing local data. However, the lack of model privacy protection in FL becomes an unneglectable challenge, especially when people want to federally finetune models based on a proprietary large language model. In this study, we propose a novel FL training approach that accomplishes information exchange among participants via tunable soft prompts. These soft prompts, updated and transmitted between the server and clients, assume the role of the global model parameters and serve as messengers to deliver useful knowledge from the local data and global model. As the global model itself is not required to be shared and the local training is conducted based on an auxiliary model with fewer parameters than the global model, the proposed approach provides protection for the global model while reducing communication and computation costs in FL. Extensive experiments show the effectiveness of the proposed approach compared to several baselines. We have released the source code at \url{https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp}.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 允许多个参与者共同训练机器学习模型使用分散数据源，从直接分享本地数据中减轻隐私问题。然而，FL中模型隐私保护的缺失成为一个不可忽略的挑战，特别是当人们想 federally finetune 模型基于专有大型语言模型时。在这种研究中，我们提出了一种新的 FL 训练方法，通过可调软提示来实现参与者之间的信息交换。这些软提示在服务器和客户端之间往返更新和传输，担任全球模型参数的角色，将本地数据和全球模型中的有用知识传递给其他参与者。由于全球模型本身不需要直接分享，并且基于副本模型（具有较少参数）进行本地训练，我们的方法提供了全球模型的保护，同时降低了 FL 的通信和计算成本。我们的实验表明，我们的方法与多个基准方法进行比较，显著超出了这些基准方法。我们已经在 \url{https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp} 上发布了源代码。
</details></li>
</ul>
<hr>
<h2 id="CLAMP-A-Contrastive-Language-And-Molecule-Pre-training-Network"><a href="#CLAMP-A-Contrastive-Language-And-Molecule-Pre-training-Network" class="headerlink" title="CLAMP: A Contrastive Language And Molecule Pre-training Network"></a>CLAMP: A Contrastive Language And Molecule Pre-training Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07617">http://arxiv.org/abs/2311.07617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neelr/clamp">https://github.com/neelr/clamp</a></li>
<li>paper_authors: Neel Redkar</li>
<li>for: 这篇论文探讨了一种新的材料生成方法，即语言到材料生成架构，利用了数百万个untapped数据点。</li>
<li>methods: 该方法使用了一种对偶模型，通过用一个 convolutional graph neural network encoder 和一个语言encoder来训练。这allow了无监督的零例试验分类，可以利用语言结构的特征。</li>
<li>results: 在实验中，该方法可以达到了约82%的准确率和约75%的光催化剂预测率，使用了一个非常小的数据集。这种新的网络可以应用于任何可以通过文本描述的反应，开启了完全新的方法来思考3D化学结构生成。<details>
<summary>Abstract</summary>
This paper highlights a shift in how to approach material generation. Instead of material-to-material, we propose a language-to-material generation architecture that utilizes millions of untapped data points. Using a web scraper to collect crystal text pairs from open-source research papers, a contrastive model can be trained using a convolutional graph neural network encoder and a language encoder. This would allow unsupervised zero-shot classification which can be trained by taking advantage of linguistic structure. Without any specific training data, an ~82\% accuracy was achieved and ~75\% accuracy for photocatalyst prediction with an extremely small dataset. This novel network could ideally be cross-applied to any reaction that can be described via text, opening completely new methods to think about 3D chemical framework generation. In the full experiment diffusion models would likely be incorporated to fully exploit the latent space.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了一种新的材料生成方法的shift。而不是传统的材料到材料的方法，我们提议使用语言到材料生成架构，利用了数百万个未利用的数据点。通过使用网络抓取器收集开源研究论文中的晶体文本对，我们可以使用一种对比模型来训练一个 convolutional graph neural network 编码器和一个语言编码器。这将允许无监督零shot分类训练，利用语言结构来学习。无需任何特定的训练数据，我们可以达到了~82%的准确率和~75%的光吸catalyst预测准确率，只使用了一个非常小的数据集。这种新的网络可以理论上应用于任何可以通过文本描述的反应，打开了 Completely new方法来思考3D化学框架生成。在实验中，扩散模型可能会被integrated以全面利用潜在空间。
</details></li>
</ul>
<hr>
<h2 id="Learning-Knowledge-Enhanced-Contextual-Language-Representations-for-Domain-Natural-Language-Understanding"><a href="#Learning-Knowledge-Enhanced-Contextual-Language-Representations-for-Domain-Natural-Language-Understanding" class="headerlink" title="Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding"></a>Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06761">http://arxiv.org/abs/2311.06761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyao Xu, Taolin Zhang, Chengyu Wang, Zhongjie Duan, Cen Chen, Minghui Qiu, Dawei Cheng, Xiaofeng He, Weining Qian</li>
<li>for: 提高闭区域NLPTasks的性能（包括知识感知和普通NLPTasks）</li>
<li>methods: 使用知识图中的隐式图结构，以及深度层次entity-class结构的卷积编码来充分融合知识；同时使用subgraph contrastive learning来提高数据训练的质量</li>
<li>results: 在闭区域NLPTasks中显著超过其他KEPLM训练方法的性能，包括全shot和少shot学习设置<details>
<summary>Abstract</summary>
Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the performance of various downstream NLP tasks by injecting knowledge facts from large-scale Knowledge Graphs (KGs). However, existing methods for pre-training KEPLMs with relational triples are difficult to be adapted to close domains due to the lack of sufficient domain graph semantics. In this paper, we propose a Knowledge-enhanced lANGuAge Representation learning framework for various clOsed dOmains (KANGAROO) via capturing the implicit graph structure among the entities. Specifically, since the entity coverage rates of closed-domain KGs can be relatively low and may exhibit the global sparsity phenomenon for knowledge injection, we consider not only the shallow relational representations of triples but also the hyperbolic embeddings of deep hierarchical entity-class structures for effective knowledge fusion.Moreover, as two closed-domain entities under the same entity-class often have locally dense neighbor subgraphs counted by max point biconnected component, we further propose a data augmentation strategy based on contrastive learning over subgraphs to construct hard negative samples of higher quality. It makes the underlying KELPMs better distinguish the semantics of these neighboring entities to further complement the global semantic sparsity. In the experiments, we evaluate KANGAROO over various knowledge-aware and general NLP tasks in both full and few-shot learning settings, outperforming various KEPLM training paradigms performance in closed-domains significantly.
</details>
<details>
<summary>摘要</summary>
知识增强预训练语言模型（KEPLM）可以提高下游NLPTask的性能，通过在大规模知识图（KG）中插入知识事实。然而，现有的KEPLM预训练方法难以适应封闭领域，因为封闭领域知识图的 semantics 缺乏。在这篇论文中，我们提出了一种名为 Knowledge-enhanced lANGuAge Representation learning framework for various clOsed dOmains（KANGAROO），通过捕捉实体之间的隐式图结构来提高 KEPLM 的性能。具体来说，关闭领域知识图中实体的覆盖率可能比较低，同时可能出现全球稀缺现象，因此我们不仅考虑了 triple 的浅层关系表示，还考虑了深层Entity-class结构的质量 embeddings。此外，在关闭领域知识图中，两个相同Entity-class的实体通常有本地稠密的邻居子图，我们提出了基于对比学习的数据增强策略，以生成更高质量的硬性负样本。这使得下面的KELPM更好地了解这些邻近实体的 semantics，并且进一步补偿全球semantic稀缺。在实验中，我们评估了 KANGAROO 在不同知识感知和通用 NLP 任务上的性能，在封闭领域内显著超越了不同的KEPLM 训练方法。
</details></li>
</ul>
<hr>
<h2 id="Sharing-Teaching-and-Aligning-Knowledgeable-Transfer-Learning-for-Cross-Lingual-Machine-Reading-Comprehension"><a href="#Sharing-Teaching-and-Aligning-Knowledgeable-Transfer-Learning-for-Cross-Lingual-Machine-Reading-Comprehension" class="headerlink" title="Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for Cross-Lingual Machine Reading Comprehension"></a>Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for Cross-Lingual Machine Reading Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06758">http://arxiv.org/abs/2311.06758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingfeng Cao, Chengyu Wang, Chuanqi Tan, Jun Huang, Jinhui Zhu</li>
<li>for: 这 paper 的目的是提出一种新的跨语言 Machine Reading Comprehension (MRC) 方法，以增强跨语言模型之间的转移性。</li>
<li>methods: 这 paper 使用了一种名为 X-STA 的新方法，包括一个抑制 teachert 来细致地传递源语言中的答案块到目标语言的答案输出空间，以及一种 Gradient-Disentangled Knowledge Sharing 技术来提高跨语言转移性。</li>
<li>results: 根据 experiments 表明，X-STA 方法可以准确地捕捉多种语言的答案块，并在三个多语言 MRC 数据集上表现出色，超越了当前的state-of-the-art 方法。<details>
<summary>Abstract</summary>
In cross-lingual language understanding, machine translation is often utilized to enhance the transferability of models across languages, either by translating the training data from the source language to the target, or from the target to the source to aid inference. However, in cross-lingual machine reading comprehension (MRC), it is difficult to perform a deep level of assistance to enhance cross-lingual transfer because of the variation of answer span positions in different languages. In this paper, we propose X-STA, a new approach for cross-lingual MRC. Specifically, we leverage an attentive teacher to subtly transfer the answer spans of the source language to the answer output space of the target. A Gradient-Disentangled Knowledge Sharing technique is proposed as an improved cross-attention block. In addition, we force the model to learn semantic alignments from multiple granularities and calibrate the model outputs with teacher guidance to enhance cross-lingual transferability. Experiments on three multi-lingual MRC datasets show the effectiveness of our method, outperforming state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
在语言跨越机器理解中，机器翻译经常被使用来提高语言之间模型的传输性，例如将源语言的训练数据翻译成目标语言，或将目标语言的数据翻译回源语言以帮助推理。然而，在跨语言机器阅读理解（MRC）中，因为答案范围位置在不同语言中存在差异，因此很难进行深度的帮助来提高跨语言传输性。在这篇论文中，我们提出了X-STA，一种新的跨语言MRC方法。具体来说，我们利用了一个注意力教师，通过细致地将源语言的答案范围转移到目标语言的答案输出空间中来帮助学习。此外，我们还提出了一种 Gradient-Disentangled Knowledge Sharing 技术，用于改进交叉注意力块。此外，我们还强制模型学习多级别的 semantic alignments，并使用教师指导来调整模型输出以增强跨语言传输性。实验结果表明，我们的方法可以备受效果，比过去的方法更高。
</details></li>
</ul>
<hr>
<h2 id="From-Complex-to-Simple-Unraveling-the-Cognitive-Tree-for-Reasoning-with-Small-Language-Models"><a href="#From-Complex-to-Simple-Unraveling-the-Cognitive-Tree-for-Reasoning-with-Small-Language-Models" class="headerlink" title="From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models"></a>From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06754">http://arxiv.org/abs/2311.06754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junbing Yan, Chengyu Wang, Taolin Zhang, Xiaofeng He, Jun Huang, Wei Zhang</li>
<li>for: 这个论文旨在探讨语言模型如何实现复杂的逻辑推理能力，以及如何使用双 processtheory来解释语言模型的认知过程。</li>
<li>methods: 该论文采用了一种迭代的方法来构建一个认知树（CogTree），该树的根节点表示初始查询，叶节点则表示可以直接回答的简单问题。该方法包括两个主要组成部分：即潜意EXTRACTION模块（Intuitive System）和EXPLICIT reasoning模块（Reflective System）。</li>
<li>results: 实验结果表明，使用这种方法可以达到与GPT-3.5（具有175B参数）的性能水平，使用的语言模型只有 &lt;&#x3D;7B 参数，这比GPT-3.5的5% fewer parameters。<details>
<summary>Abstract</summary>
Reasoning is a distinctive human capacity, enabling us to address complex problems by breaking them down into a series of manageable cognitive steps. Yet, complex logical reasoning is still cumbersome for language models. Based on the dual process theory in cognitive science, we are the first to unravel the cognitive reasoning abilities of language models. Our framework employs an iterative methodology to construct a Cognitive Tree (CogTree). The root node of this tree represents the initial query, while the leaf nodes consist of straightforward questions that can be answered directly. This construction involves two main components: the implicit extraction module (referred to as the intuitive system) and the explicit reasoning module (referred to as the reflective system). The intuitive system rapidly generates multiple responses by utilizing in-context examples, while the reflective system scores these responses using comparative learning. The scores guide the intuitive system in its subsequent generation step. Our experimental results on two popular and challenging reasoning tasks indicate that it is possible to achieve a performance level comparable to that of GPT-3.5 (with 175B parameters), using a significantly smaller language model that contains fewer parameters (<=7B) than 5% of GPT-3.5.
</details>
<details>
<summary>摘要</summary>
人类具有特殊的理智能力，可以将复杂问题分解成一系列可管理的认知步骤来解决。然而，复杂逻辑理解仍然是语言模型的瓶颈。根据认知科学中的双 процесс理论，我们是第一个揭示语言模型的认知逻辑能力的研究。我们的框架采用迭代方法构建认知树（CogTree）。树的根节点表示初始查询，叶节点包含直接回答的简单问题。这个构建过程包括两个主要组成部分：印象EXTRACT模块（被称为直觉系统）和显式逻辑理解模块（被称为反思系统）。直觉系统快速生成多个回答，利用上下文例子，而显式逻辑理解模块使用比较学习评分这些回答。这些分数导引直觉系统在下一步生成过程中。我们对两个知名和具有挑战性的逻辑任务进行实验，结果表明，可以使用比GPT-3.5（具有175B参数）更小的语言模型（<=7B）达到相似的性能水平。
</details></li>
</ul>
<hr>
<h2 id="BeautifulPrompt-Towards-Automatic-Prompt-Engineering-for-Text-to-Image-Synthesis"><a href="#BeautifulPrompt-Towards-Automatic-Prompt-Engineering-for-Text-to-Image-Synthesis" class="headerlink" title="BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis"></a>BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06752">http://arxiv.org/abs/2311.06752</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NicholasCao/BeautifulPrompt">https://github.com/NicholasCao/BeautifulPrompt</a></li>
<li>paper_authors: Tingfeng Cao, Chengyu Wang, Bingyan Liu, Ziheng Wu, Jinhui Zhu, Jun Huang</li>
<li>for: 提高 diffusion-based deep generative models 的 text-to-image Synthesis 质量</li>
<li>methods: 使用 BeautifulPrompt 模型从简单描述生成高质量的 prompts，并通过人工智能反馈循环优化模型</li>
<li>results: 通过学习视觉 AI 反馈，可以提高生成的 prompts 和图像质量，并将 BeautifulPrompt 集成到云端 AI 平台以提供更好的 text-to-image 生成服务<details>
<summary>Abstract</summary>
Recently, diffusion-based deep generative models (e.g., Stable Diffusion) have shown impressive results in text-to-image synthesis. However, current text-to-image models often require multiple passes of prompt engineering by humans in order to produce satisfactory results for real-world applications. We propose BeautifulPrompt, a deep generative model to produce high-quality prompts from very simple raw descriptions, which enables diffusion-based models to generate more beautiful images. In our work, we first fine-tuned the BeautifulPrompt model over low-quality and high-quality collecting prompt pairs. Then, to ensure that our generated prompts can generate more beautiful images, we further propose a Reinforcement Learning with Visual AI Feedback technique to fine-tune our model to maximize the reward values of the generated prompts, where the reward values are calculated based on the PickScore and the Aesthetic Scores. Our results demonstrate that learning from visual AI feedback promises the potential to improve the quality of generated prompts and images significantly. We further showcase the integration of BeautifulPrompt to a cloud-native AI platform to provide better text-to-image generation service in the cloud.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Are-LLMs-Rigorous-Logical-Reasoner-Empowering-Natural-Language-Proof-Generation-with-Contrastive-Stepwise-Decoding"><a href="#Are-LLMs-Rigorous-Logical-Reasoner-Empowering-Natural-Language-Proof-Generation-with-Contrastive-Stepwise-Decoding" class="headerlink" title="Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof Generation with Contrastive Stepwise Decoding"></a>Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof Generation with Contrastive Stepwise Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06736">http://arxiv.org/abs/2311.06736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Su, Xiaojin Fu, Mingwen Liu, Zhijiang Guo</li>
<li>for: 这个研究旨在评估大型自然语言模型（LLM）在逻辑推理任务中的表现，特别是使用链式思维（CoT）策略。</li>
<li>methods: 研究者使用了减少规模的语言模型，并引入了分解证明目标为更可管理的子目标、以及使用反例推导来强化模型的逻辑推理能力。</li>
<li>results: 实验结果表明，使用研究者提出的方法可以增强LLM在逻辑推理任务中的表现，特别是在复杂的逻辑推理链中。<details>
<summary>Abstract</summary>
Logical reasoning remains a pivotal component within the realm of artificial intelligence. The recent evolution of large language models (LLMs) has marked significant progress in this domain. The adoption of strategies like chain-of-thought (CoT) has enhanced the performance of LLMs across diverse reasoning tasks. Nonetheless, logical reasoning that involves proof planning, specifically those that necessitate the validation of explanation accuracy, continues to present stumbling blocks. In this study, we first evaluate the efficacy of LLMs with advanced CoT strategies concerning such tasks. Our analysis reveals that LLMs still struggle to navigate complex reasoning chains, which demand the meticulous linkage of premises to derive a cogent conclusion. To address this issue, we finetune a smaller-scale language model, equipping it to decompose proof objectives into more manageable subgoals. We also introduce contrastive decoding to stepwise proof generation, making use of negative reasoning paths to strengthen the model's capacity for logical deduction. Experiments on EntailmentBank underscore the success of our method in augmenting the proof planning abilities of language models.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the given text into Simplified Chinese.</SYS>>ilogical reasoning remains a crucial component within the realm of artificial intelligence. The recent evolution of large language models (LLMs) has marked significant progress in this domain. The adoption of strategies like chain-of-thought (CoT) has enhanced the performance of LLMs across diverse reasoning tasks. However, logical reasoning that involves proof planning, specifically those that require the validation of explanation accuracy, continues to present challenges. In this study, we first evaluate the efficacy of LLMs with advanced CoT strategies concerning such tasks. Our analysis reveals that LLMs still struggle to navigate complex reasoning chains, which demand the meticulous linkage of premises to derive a cogent conclusion. To address this issue, we fine-tune a smaller-scale language model, equipping it to decompose proof objectives into more manageable subgoals. We also introduce contrastive decoding to stepwise proof generation, making use of negative reasoning paths to strengthen the model's capacity for logical deduction. Experiments on EntailmentBank underscore the success of our method in augmenting the proof planning abilities of language models.Here's the text in Traditional Chinese:<<SYS>>转换文本为简化字体。</SYS>>ilogical reasoning remains a crucial component within the realm of artificial intelligence. The recent evolution of large language models (LLMs) has marked significant progress in this domain. The adoption of strategies like chain-of-thought (CoT) has enhanced the performance of LLMs across diverse reasoning tasks. However, logical reasoning that involves proof planning, specifically those that require the validation of explanation accuracy, continues to present challenges. In this study, we first evaluate the efficacy of LLMs with advanced CoT strategies concerning such tasks. Our analysis reveals that LLMs still struggle to navigate complex reasoning chains, which demand the meticulous linkage of premises to derive a cogent conclusion. To address this issue, we fine-tune a smaller-scale language model, equipping it to decompose proof objectives into more manageable subgoals. We also introduce contrastive decoding to stepwise proof generation, making use of negative reasoning paths to strengthen the model's capacity for logical deduction. Experiments on EntailmentBank underscore the success of our method in augmenting the proof planning abilities of language models.
</details></li>
</ul>
<hr>
<h2 id="Comprehending-Lexical-and-Affective-Ontologies-in-the-Demographically-Diverse-Spatial-Social-Media-Discourse"><a href="#Comprehending-Lexical-and-Affective-Ontologies-in-the-Demographically-Diverse-Spatial-Social-Media-Discourse" class="headerlink" title="Comprehending Lexical and Affective Ontologies in the Demographically Diverse Spatial Social Media Discourse"></a>Comprehending Lexical and Affective Ontologies in the Demographically Diverse Spatial Social Media Discourse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06729">http://arxiv.org/abs/2311.06729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salim Sazzed<br>for:This study aims to understand the linguistic and socio-demographic features of online social media reviews, including English language styles, conveyed sentiments, and lexical diversity.methods:The study uses a case study approach, extracting and examining statistical, grammatical, and sentimental features from two demographically diverse groups. Machine learning (ML) classifiers are then leveraged to differentiate between the groups based on these features.results:The study finds significant disparities in linguistic attributes between the two groups, which can be effectively used to distinguish them with a macro F1 score of approximately 0.85. Additionally, the study compares the performance of linguistic features with word n-gram-based lexical features and finds that the latter, combined with fine-tuned transformer-based models, achieve higher accuracy (over 95%) and macro F1 scores (over 0.96). The findings provide valuable guidelines for future research on analyzing demographic patterns in textual content across social media platforms.<details>
<summary>Abstract</summary>
This study aims to comprehend linguistic and socio-demographic features, encompassing English language styles, conveyed sentiments, and lexical diversity within spatial online social media review data. To this end, we undertake a case study that scrutinizes reviews composed by two distinct and demographically diverse groups. Our analysis entails the extraction and examination of various statistical, grammatical, and sentimental features from these two groups. Subsequently, we leverage these features with machine learning (ML) classifiers to discern their potential in effectively differentiating between the groups. Our investigation unveils substantial disparities in certain linguistic attributes between the two groups. When integrated into ML classifiers, these attributes exhibit a marked efficacy in distinguishing the groups, yielding a macro F1 score of approximately 0.85. Furthermore, we conduct a comparative evaluation of these linguistic features with word n-gram-based lexical features in discerning demographically diverse review data. As expected, the n-gram lexical features, coupled with fine-tuned transformer-based models, show superior performance, attaining accuracies surpassing 95\% and macro F1 scores exceeding 0.96. Our meticulous analysis and comprehensive evaluations substantiate the efficacy of linguistic and sentimental features in effectively discerning demographically diverse review data. The findings of this study provide valuable guidelines for future research endeavors concerning the analysis of demographic patterns in textual content across various social media platforms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Controllable-Topic-Focused-Abstractive-Summarization"><a href="#Controllable-Topic-Focused-Abstractive-Summarization" class="headerlink" title="Controllable Topic-Focused Abstractive Summarization"></a>Controllable Topic-Focused Abstractive Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06724">http://arxiv.org/abs/2311.06724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Ali Bahrainian, Martin Jaggi, Carsten Eickhoff</li>
<li>for: 这个论文目的是提出一种基于Transformer架构的新方法，用于生成关注特定主题的摘要。</li>
<li>methods: 这个方法修改了Transformer模型中的跨注意力机制，以实现控制生成过程中的主题强调。这不添加任何额外参数到模型中。</li>
<li>results: 我们的模型在NEWTS dataset上实现了关注特定主题的摘要的新州OF艺。此外，我们通过广泛的实验表明，我们的提议的主题跨注意力机制可以在不需要重新训练的情况下，将BART和T5模型改进到CNN&#x2F;Dailymail和XSum数据集上的摘要生成任务上。<details>
<summary>Abstract</summary>
Controlled abstractive summarization focuses on producing condensed versions of a source article to cover specific aspects by shifting the distribution of generated text towards a desired style, e.g., a set of topics. Subsequently, the resulting summaries may be tailored to user-defined requirements. This paper presents a new Transformer-based architecture capable of producing topic-focused summaries. The architecture modifies the cross-attention mechanism of the Transformer to bring topic-focus control to the generation process while not adding any further parameters to the model. We show that our model sets a new state of the art on the NEWTS dataset in terms of topic-focused abstractive summarization as well as a topic-prevalence score. Moreover, we show via extensive experiments that our proposed topical cross-attention mechanism can be plugged into various Transformer models, such as BART and T5, improving their performance on the CNN/Dailymail and XSum benchmark datasets for abstractive summarization. This is achieved via fine-tuning, without requiring training from scratch. Finally, we show through human evaluation that our model generates more faithful summaries outperforming the state-of-the-art Frost model.
</details>
<details>
<summary>摘要</summary>
控制抽象摘要的研究集中焦点在生成受控的摘要，以掌控生成文本的分布，例如将摘要集中在某些主题上。这篇论文提出了一种基于Transformer架构的新型摘要生成模型，可以控制生成过程中的话题强调。我们修改了Transformer模型中的cross-attention机制，以实现话题强调控制，而无需添加任何参数。我们的模型在NEWTS数据集上实现了话题抽象摘要的新状态之冠，同时也在话题强制分布上达到了新的高水平。此外，我们通过广泛的实验表明，我们的提议的话题跨注意力机制可以在不同的Transformer模型中应用，如BART和T5，提高其在CNN/Dailymail和XSum数据集上的抽象摘要性能。这是通过微调，不需要从scratch retrained。最后，我们通过人工评估表明，我们的模型生成的摘要更 faithful，比出现在状态之冠的Frost模型。
</details></li>
</ul>
<hr>
<h2 id="Cappy-Outperforming-and-Boosting-Large-Multi-Task-LMs-with-a-Small-Scorer"><a href="#Cappy-Outperforming-and-Boosting-Large-Multi-Task-LMs-with-a-Small-Scorer" class="headerlink" title="Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer"></a>Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06720">http://arxiv.org/abs/2311.06720</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tanyuqian/cappy">https://github.com/tanyuqian/cappy</a></li>
<li>paper_authors: Bowen Tan, Yun Zhu, Lijuan Liu, Eric Xing, Zhiting Hu, Jindong Chen</li>
<li>for: 提高多任务大语言模型（LLMs）的性能和效率，并且可以方便地适应下游应用程序。</li>
<li>methods: 引入一个预训练小评分器（Cappy），可以独立地完成分类任务或者作为 LLMs 的辅助组件，提高其性能。</li>
<li>results: Cappy 可以在 11 种语言理解任务上表现出色，并且可以与其他 LLM 的适应方法（如 finetuning 和 in-context learning）相互协作，提供更高的性能提升。<details>
<summary>Abstract</summary>
Large language models (LLMs) such as T0, FLAN, and OPT-IML, excel in multi-tasking under a unified instruction-following paradigm, where they also exhibit remarkable generalization abilities to unseen tasks. Despite their impressive performance, these LLMs, with sizes ranging from several billion to hundreds of billions of parameters, demand substantial computational resources, making their training and inference expensive and inefficient. Furthermore, adapting these models to downstream applications, particularly complex tasks, is often unfeasible due to the extensive hardware requirements for finetuning, even when utilizing parameter-efficient approaches such as prompt tuning. Additionally, the most powerful multi-task LLMs, such as OPT-IML-175B and FLAN-PaLM-540B, are not publicly accessible, severely limiting their customization potential. To address these challenges, we introduce a pretrained small scorer, Cappy, designed to enhance the performance and efficiency of multi-task LLMs. With merely 360 million parameters, Cappy functions either independently on classification tasks or serve as an auxiliary component for LLMs, boosting their performance. Moreover, Cappy enables efficiently integrating downstream supervision without requiring LLM finetuning nor the access to their parameters. Our experiments demonstrate that, when working independently on 11 language understanding tasks from PromptSource, Cappy outperforms LLMs that are several orders of magnitude larger. Besides, on 45 complex tasks from BIG-Bench, Cappy boosts the performance of the advanced multi-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to cooperate with other LLM adaptations, including finetuning and in-context learning, offering additional performance enhancement.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如T0、FLAN和OPT-IML，在一体化指令遵循模式下表现出色，并具有卓越的应用扩展能力。尽管它们在表现方面卓越，但这些LLM对于训练和测试而言非常耗费资源，导致它们的训练和测试成本高昂不可持续。此外，对于下游应用的适配也是困难的，特别是面对复杂的任务时。这些最强的多任务LLM之一，如OPT-IML-175B和FLAN-PaLM-540B，则不公开 accessible，严重限制了它们的自定义潜力。为解决这些挑战，我们引入了一个预训小评分器，Cappy，用于增强多任务LLM的表现和效率。Cappy仅有360亿个参数，可以独立进行分类任务，或者作为LLM的辅助元件，提高其表现。此外，Cappy可以效率地 интеграate下游监督，不需要LLM的调整对应，也不需要存取LLM的参数。我们的实验显示，在11种语言理解任务上，Cappy在与许多个项目上表现出色，而且在45个复杂任务上，Cappy将FLAN-T5进步大幅。此外，Cappy还可以与其他LLM的适配方法，包括调整和在 контекスト中学习，提供进一步的表现提升。
</details></li>
</ul>
<hr>
<h2 id="What-factors-influence-the-popularity-of-user-generated-text-in-the-creative-domain-A-case-study-of-book-reviews"><a href="#What-factors-influence-the-popularity-of-user-generated-text-in-the-creative-domain-A-case-study-of-book-reviews" class="headerlink" title="What factors influence the popularity of user-generated text in the creative domain? A case study of book reviews"></a>What factors influence the popularity of user-generated text in the creative domain? A case study of book reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06714">http://arxiv.org/abs/2311.06714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salim Sazzed</li>
<li>for: 本研究探究了书评的各种心理、语言、 semantics 和可读性特征，以揭示书评的评价因素。</li>
<li>methods: 我们对书评中的各种特征进行统计分析，包括观点和情感表达的类型和频率、连接词、人物提及、单词独特性、通用性、句子结构等。此外，我们还使用两种可读性测试来探究是否存在评价媒体和评价媒体之间的相关性。</li>
<li>results: 我们的发现表明，除了一些特征（如评论长度、情感和单词独特性）之外，大多数特征没有显著的差异 между受欢迎和不受欢迎的评论组。此外，使用单词 n-gram 特征的机器学习分类器表现糟糕，这反映了在创造性领域中评价困难的问题。总之，本研究提供了各种评论受欢迎的因素的启示，并强调了在创造性领域进一步研究的必要性。<details>
<summary>Abstract</summary>
This study investigates a range of psychological, lexical, semantic, and readability features of book reviews to elucidate the factors underlying their perceived popularity. To this end, we conduct statistical analyses of various features, including the types and frequency of opinion and emotion-conveying terms, connectives, character mentions, word uniqueness, commonness, and sentence structure, among others. Additionally, we utilize two readability tests to explore whether reading ease is positively associated with review popularity. Finally, we employ traditional machine learning classifiers and transformer-based fine-tuned language models with n-gram features to automatically determine review popularity. Our findings indicate that, with the exception of a few features (e.g., review length, emotions, and word uniqueness), most attributes do not exhibit significant differences between popular and non-popular review groups. Furthermore, the poor performance of machine learning classifiers using the word n-gram feature highlights the challenges associated with determining popularity in creative domains. Overall, our study provides insights into the factors underlying review popularity and highlights the need for further research in this area, particularly in the creative realm.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)这个研究 investigate 一系列心理、语言、Semantic 和可读性特征，以探索书评的可读性的因素。为此，我们进行了各种统计分析，包括评论和情感表达的类型和频率、连接词、人物提及、单词独特性、常见性和句子结构等。此外，我们还使用了两种可读性测试，以探究评论的阅读易懂性是否与评论的流行性相关。最后，我们使用传统的机器学习分类器和基于 transformer 的优化语言模型，使用 n-gram 特征来自动确定评论的流行程度。我们的发现表明，除了一些特征（如评论的长度、情感和单词独特性），大多数特征没有显著的差异 между 流行和不流行的评论组。此外，使用 word n-gram 特征的机器学习分类器表现不佳，反映了在创造性领域中决定流行性的挑战。总的来说，我们的研究提供了关于评论流行性的因素的启示，并高亮了在创造性领域进一步研究的需要。
</details></li>
</ul>
<hr>
<h2 id="Trusted-Source-Alignment-in-Large-Language-Models"><a href="#Trusted-Source-Alignment-in-Large-Language-Models" class="headerlink" title="Trusted Source Alignment in Large Language Models"></a>Trusted Source Alignment in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06697">http://arxiv.org/abs/2311.06697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasilisa Bashlovkina, Zhaobin Kuang, Riley Matthews, Edward Clifford, Yennie Jun, William W. Cohen, Simon Baumgartner</li>
<li>for: This paper is written to evaluate the trusted source alignment (TSA) property of large language models (LLMs) and to present a dataset called FactCheckQA for evaluating TSA.</li>
<li>methods: The paper proposes a simple protocol for evaluating TSA, which includes response extraction, claim contextualization, and bias in prompt formulation.</li>
<li>results: The authors find that as they scale up the model size, the model performance on FactCheckQA improves from near-random to up to 80% balanced accuracy in aligning with trusted sources.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为评估大语言模型（LLM）中的可靠来源对应性（TSA）而写的。</li>
<li>methods: 论文提出了一种简单的评估TSA的协议，包括响应EXTRACTION、CLAIM CONTEXTUALIZATION和提问表达中的偏见。</li>
<li>results: 作者发现，随着模型大小的增加，模型在FactCheckQA上的性能从near-random提高到了80%的权衡精度，与可靠来源进行对应。<details>
<summary>Abstract</summary>
Large language models (LLMs) are trained on web-scale corpora that inevitably include contradictory factual information from sources of varying reliability. In this paper, we propose measuring an LLM property called trusted source alignment (TSA): the model's propensity to align with content produced by trusted publishers in the face of uncertainty or controversy. We present FactCheckQA, a TSA evaluation dataset based on a corpus of fact checking articles. We describe a simple protocol for evaluating TSA and offer a detailed analysis of design considerations including response extraction, claim contextualization, and bias in prompt formulation. Applying the protocol to PaLM-2, we find that as we scale up the model size, the model performance on FactCheckQA improves from near-random to up to 80% balanced accuracy in aligning with trusted sources.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Simple-and-Effective-Input-Reformulations-for-Translation"><a href="#Simple-and-Effective-Input-Reformulations-for-Translation" class="headerlink" title="Simple and Effective Input Reformulations for Translation"></a>Simple and Effective Input Reformulations for Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06696">http://arxiv.org/abs/2311.06696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bri25yu/languagemodelexperimentation">https://github.com/bri25yu/languagemodelexperimentation</a></li>
<li>paper_authors: Brian Yu, Hansen Lillemark, Kurt Keutzer</li>
<li>for: This paper aims to improve the performance of language models on challenging translation tasks through reformulating inputs during finetuning.</li>
<li>methods: The paper proposes simple data-level modifications to the input data during finetuning, which do not require additional training data or modifications at inference time.</li>
<li>results: The proposed methods achieve significant performance improvements of up to $\textbf{3.5 chrF++}$ on the Flores200 translation benchmark.Here’s the full Chinese text:</li>
<li>for: 这篇论文目标是通过在finetuning过程中对输入数据进行修改，提高语言模型在具有挑战性的翻译任务中的性能。</li>
<li>methods: 论文提出了一种简单的数据层修改方法，不需要额外收集训练数据或在推理时进行修改。</li>
<li>results: 提议的方法在Flores200翻译 benchmark上实现了显著的性能提升，达到了 $\textbf{3.5 chrF++}$ 的最佳性能。<details>
<summary>Abstract</summary>
Foundation language models learn from their finetuning input context in different ways. In this paper, we reformulate inputs during finetuning for challenging translation tasks, leveraging model strengths from pretraining in novel ways to improve downstream performance. These reformulations are simple data level modifications, require no additional collection of training data or modification of data at inference time. They can be applied either on single language pair translation tasks or massively multilingual translation tasks. Experiments with these techniques demonstrate significant performance improvements up to $\textbf{3.5 chrF++ on the Flores200 translation benchmark}$. We hope our research accessibly improves finetuning data efficiency, enabling more effective training to scalably improve state-of-the-art performance. Our code is released $\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$
</details>
<details>
<summary>摘要</summary>
基础语言模型从finetuning输入上学习的方式不同。在这篇论文中，我们将finetuning输入重新编写，以利用模型在预训练中的优势，以提高下游性能。这些重新编写是单纯的数据层次修改，无需额外收集训练数据或在推理时修改数据。它们可以应用于单语言对翻译任务或大规模多语言翻译任务。实验结果显示，使用这些技术可以获得$\textbf{3.5 chrF++在Flores200翻译标准 bencmark}$中的显著性能提升。我们希望我们的研究能够提高finetuning数据效率，以便更有效地训练，以拓宽状态之巅表现。我们的代码可以在 $\href{https://github.com/bri25yu/LanguageModelExperimentation}{这里}$ 获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/cs.CL_2023_11_12/" data-id="clp89dobw00f3i7886vyp8d0e" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
