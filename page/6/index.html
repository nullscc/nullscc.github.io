
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/6/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/cs.SD_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T15:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/cs.SD_2023_11_14/">cs.SD - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ChoralSynth-Synthetic-Dataset-of-Choral-Singing"><a href="#ChoralSynth-Synthetic-Dataset-of-Choral-Singing" class="headerlink" title="ChoralSynth: Synthetic Dataset of Choral Singing"></a>ChoralSynth: Synthetic Dataset of Choral Singing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08350">http://arxiv.org/abs/2311.08350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jyoti Narang, Viviana De La Vega, Xavier Lizarraga, Oscar Mayor, Hector Parra, Jordi Janer, Xavier Serra</li>
<li>for: 本研究是为了提供高质量的choral singing数据集，以便进行Music Information Retrieval（MIR）研究。</li>
<li>methods: 本研究使用了现代音乐合成器，创造和 curae quality renditions。数据来源于Choral Public Domain Library（CPDL）。</li>
<li>results: 本研究提供了一个完整的数据集，包括相关的metadata，以及方法和技术。这些数据和方法将为Singing Voice研究开创新的 Avenues。<details>
<summary>Abstract</summary>
Choral singing, a widely practiced form of ensemble singing, lacks comprehensive datasets in the realm of Music Information Retrieval (MIR) research, due to challenges arising from the requirement to curate multitrack recordings. To address this, we devised a novel methodology, leveraging state-of-the-art synthesizers to create and curate quality renditions. The scores were sourced from Choral Public Domain Library(CPDL). This work is done in collaboration with a diverse team of musicians, software engineers and researchers. The resulting dataset, complete with its associated metadata, and methodology is released as part of this work, opening up new avenues for exploration and advancement in the field of singing voice research.
</details>
<details>
<summary>摘要</summary>
合唱歌唱，一种广泛实践的 ensemble 唱歌形式，在音乐信息检索（MIR）研究领域缺乏完整的数据集，因为需要合成多轨录音。为解决这个问题，我们提出了一种新的方法，利用当今最佳的 sintizer 创建和精心编辑高质量的演唱。歌谱来自choral Public Domain Library（CPDL）。这项工作和一群多元化的音乐家、软件工程师和研究人员合作完成，并随此工作发布了相关的数据集和方法。这些数据和方法对唱音研究领域开启了新的探索途径。
</details></li>
</ul>
<hr>
<h2 id="Generative-De-Quantization-for-Neural-Speech-Codec-via-Latent-Diffusion"><a href="#Generative-De-Quantization-for-Neural-Speech-Codec-via-Latent-Diffusion" class="headerlink" title="Generative De-Quantization for Neural Speech Codec via Latent Diffusion"></a>Generative De-Quantization for Neural Speech Codec via Latent Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08330">http://arxiv.org/abs/2311.08330</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haici Yang, Inseon Jang, Minje Kim</li>
<li>for: 这 paper 的目的是提出一种 separable 的 speech coding 网络，以提高 speech 质量和简化网络结构。</li>
<li>methods: 该 paper 使用了 end-to-end 编码器来学习紧凑的特征，并使用了 latent diffusion 模型来解码紧凑的特征。</li>
<li>results: 该 paper 的实验结果显示，该模型在两个低比特率（1.5和3kbps）下的主观听测试中表现出色，并且比现有的模型更高效。<details>
<summary>Abstract</summary>
In low-bitrate speech coding, end-to-end speech coding networks aim to learn compact yet expressive features and a powerful decoder in a single network. A challenging problem as such results in unwelcome complexity increase and inferior speech quality. In this paper, we propose to separate the representation learning and information reconstruction tasks. We leverage an end-to-end codec for learning low-dimensional discrete tokens and employ a latent diffusion model to de-quantize coded features into a high-dimensional continuous space, relieving the decoder's burden of de-quantizing and upsampling. To mitigate the issue of over-smooth generation, we introduce midway-infilling with less noise reduction and stronger conditioning. In ablation studies, we investigate the hyperparameters for midway-infilling and latent diffusion space with different dimensions. Subjective listening tests show that our model outperforms the state-of-the-art at two low bitrates, 1.5 and 3 kbps. Codes and samples of this work are available on our webpage.
</details>
<details>
<summary>摘要</summary>
低比特率 speech 编码中，端到端 speech 编码网络目标是学习紧凑而表达力强的特征和一个强大的解码器在单个网络中。这是一个具有挑战性的问题，会导致不良复杂性增加和声音质量下降。在这篇论文中，我们提议将表征学习和信息重建任务分离开。我们利用端到端编码器来学习低维度的整数token，并使用幽默扩散模型将编码后的特征转换为高维度连续空间，从而减轻解码器的幽默扩散和采样加工负担。为了缓解过度平滑生成的问题，我们引入中途填充，并对其进行较强的条件和噪声减少。在分析研究中，我们研究了不同维度的幽默扩散空间和中途填充的hyperparameters。主观听测试显示，我们的模型在1.5和3kbps两个低比特率下表现出色，超过了当前状态的质量。我们的代码和样本在我们的网站上可以获得。
</details></li>
</ul>
<hr>
<h2 id="DQR-TTS-Semi-supervised-Text-to-speech-Synthesis-with-Dynamic-Quantized-Representation"><a href="#DQR-TTS-Semi-supervised-Text-to-speech-Synthesis-with-Dynamic-Quantized-Representation" class="headerlink" title="DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized Representation"></a>DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07965">http://arxiv.org/abs/2311.07965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangzong Wang, Pengcheng Li, Xulong Zhang, Ning Cheng, Jing Xiao</li>
<li>for: 提高 neural-based 文本译音方法在低资源条件下的表现</li>
<li>methods: 使用 semi-supervised 模型，学习 both paired 和 unpaired 数据，并使用动态量化表示模块</li>
<li>results: 与传统方法相比，只使用 less than 120 minutes 的 paired 数据，提高了 subjective 和 objective 评价指标<details>
<summary>Abstract</summary>
Most existing neural-based text-to-speech methods rely on extensive datasets and face challenges under low-resource condition. In this paper, we introduce a novel semi-supervised text-to-speech synthesis model that learns from both paired and unpaired data to address this challenge. The key component of the proposed model is a dynamic quantized representation module, which is integrated into a sequential autoencoder. When given paired data, the module incorporates a trainable codebook that learns quantized representations under the supervision of the paired data. However, due to the limited paired data in low-resource scenario, these paired data are difficult to cover all phonemes. Then unpaired data is fed to expand the dynamic codebook by adding quantized representation vectors that are sufficiently distant from the existing ones during training. Experiments show that with less than 120 minutes of paired data, the proposed method outperforms existing methods in both subjective and objective metrics.
</details>
<details>
<summary>摘要</summary>
现有的神经网络基于文本至话方法大多需要广泛的数据集和面临低资源情况下遇到挑战。在这篇文章中，我们介绍了一个新的半监督文本至话合成模型，可以从对称和无对称数据进行学习，以解决这个挑战。这个模型的关键 комponents是动态量化表现模块，它被组入了一个排序自适应器。当 given paired data 时，这个模块包含一个可调数表示的对称码库，可以在对称数据的监督下学习量化表现。但在低资源情况下，这些对称数据很难覆盖所有的音响。然后，无对称数据被 feed 到扩展动态码库，在训练时添加量化表现向量，以便在训练时与现有的向量 sufficiently distant 的情况下增加量化表现向量。实验显示，仅使用 less than 120 分钟的对称数据，提案方法已经在主观和客观指标中超过现有方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/cs.SD_2023_11_14/" data-id="clpztdnp2012ces88bd7b5i7m" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/eess.AS_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T14:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/eess.AS_2023_11_14/">eess.AS - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mustango-Toward-Controllable-Text-to-Music-Generation"><a href="#Mustango-Toward-Controllable-Text-to-Music-Generation" class="headerlink" title="Mustango: Toward Controllable Text-to-Music Generation"></a>Mustango: Toward Controllable Text-to-Music Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08355">http://arxiv.org/abs/2311.08355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amaai-lab/mustango">https://github.com/amaai-lab/mustango</a></li>
<li>paper_authors: Jan Melechovsky, Zixun Guo, Deepanway Ghosal, Navonil Majumder, Dorien Herremans, Soujanya Poria</li>
<li>for: 这个研究的目的是发展一个可控制的文本到音乐系统，以掌控生成的音乐的乐器、和声、速度、键等音乐特性。</li>
<li>methods: 这个系统使用了 diffusion 模型，并将音乐领域知识 Informed UNet 模组（MuNet）与文本内容进行整合，以便从文本描述中提取音乐特性，并将其融入到散射过程中。</li>
<li>results: 这个研究显示，这个 Mustango 系统可以实现高质量的音乐生成，并且可以从文本描述中提取音乐特性，并且可以对散射过程进行控制，以实现欲要的乐器、和声、速度、键等音乐特性。<details>
<summary>Abstract</summary>
With recent advancements in text-to-audio and text-to-music based on latent diffusion models, the quality of generated content has been reaching new heights. The controllability of musical aspects, however, has not been explicitly explored in text-to-music systems yet. In this paper, we present Mustango, a music-domain-knowledge-inspired text-to-music system based on diffusion, that expands the Tango text-to-audio model. Mustango aims to control the generated music, not only with general text captions, but from more rich captions that could include specific instructions related to chords, beats, tempo, and key. As part of Mustango, we propose MuNet, a Music-Domain-Knowledge-Informed UNet sub-module to integrate these music-specific features, which we predict from the text prompt, as well as the general text embedding, into the diffusion denoising process. To overcome the limited availability of open datasets of music with text captions, we propose a novel data augmentation method that includes altering the harmonic, rhythmic, and dynamic aspects of music audio and using state-of-the-art Music Information Retrieval methods to extract the music features which will then be appended to the existing descriptions in text format. We release the resulting MusicBench dataset which contains over 52K instances and includes music-theory-based descriptions in the caption text. Through extensive experiments, we show that the quality of the music generated by Mustango is state-of-the-art, and the controllability through music-specific text prompts greatly outperforms other models in terms of desired chords, beat, key, and tempo, on multiple datasets.
</details>
<details>
<summary>摘要</summary>
Recent advancements in text-to-audio and text-to-music based on latent diffusion models have led to significant improvements in generated content quality. However, the controllability of musical aspects in text-to-music systems has not been explicitly explored. In this paper, we present Mustango, a text-to-music system based on diffusion that expands the Tango text-to-audio model. Mustango aims to control the generated music not only with general text captions but also with specific instructions related to chords, beats, tempo, and key.As part of Mustango, we propose MuNet, a Music-Domain-Knowledge-Informed UNet sub-module that integrates music-specific features into the diffusion denoising process. To address the limited availability of open datasets of music with text captions, we propose a novel data augmentation method that includes altering the harmonic, rhythmic, and dynamic aspects of music audio and using state-of-the-art Music Information Retrieval methods to extract music features. We release the resulting MusicBench dataset, which contains over 52K instances and includes music-theory-based descriptions in the caption text.Through extensive experiments, we show that the quality of the music generated by Mustango is state-of-the-art, and the controllability through music-specific text prompts greatly outperforms other models in terms of desired chords, beat, key, and tempo on multiple datasets.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/eess.AS_2023_11_14/" data-id="clpztdnqp016aes8837vfhr1w" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/cs.CV_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T13:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/cs.CV_2023_11_14/">cs.CV - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unsupervised-segmentation-of-irradiation-unicode-x2010-induced-order-unicode-x2010-disorder-phase-transitions-in-electron-microscopy"><a href="#Unsupervised-segmentation-of-irradiation-unicode-x2010-induced-order-unicode-x2010-disorder-phase-transitions-in-electron-microscopy" class="headerlink" title="Unsupervised segmentation of irradiation$\unicode{x2010}$induced order$\unicode{x2010}$disorder phase transitions in electron microscopy"></a>Unsupervised segmentation of irradiation$\unicode{x2010}$induced order$\unicode{x2010}$disorder phase transitions in electron microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08585">http://arxiv.org/abs/2311.08585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arman H Ter-Petrosyan, Jenna A Bilbrey, Christina M Doty, Bethany E Matthews, Le Wang, Yingge Du, Eric Lang, Khalid Hattar, Steven R Spurgeon</li>
<li>for: 这个论文是为了无监督分割电子镜像所写的（electron microscopy image segmentation）。</li>
<li>methods: 这个论文使用了域预训练的卷积神经网络（CNN）提取特征，然后生成相似图并应用Louvaine方法进行社区探测，实现分割。</li>
<li>results: 这个论文通过跟踪辐射引起的杂质前缘在薄膜中的变化，以及在 catalysis 和电子设备中的应用。<details>
<summary>Abstract</summary>
We present a method for the unsupervised segmentation of electron microscopy images, which are powerful descriptors of materials and chemical systems. Images are oversegmented into overlapping chips, and similarity graphs are generated from embeddings extracted from a domain$\unicode{x2010}$pretrained convolutional neural network (CNN). The Louvain method for community detection is then applied to perform segmentation. The graph representation provides an intuitive way of presenting the relationship between chips and communities. We demonstrate our method to track irradiation$\unicode{x2010}$induced amorphous fronts in thin films used for catalysis and electronics. This method has potential for "on$\unicode{x2010}$the$\unicode{x2010}$fly" segmentation to guide emerging automated electron microscopes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种无监督的电子顾像图像分割方法，这些图像是物质和化学系统的强大描述器。图像被过分割成重叠的块，并从域预训练的卷积神经网络（CNN）中提取出的特征向量生成相似图。然后，我们使用Louvaine方法进行社区探测，进行分割。图表表示块和社区之间的关系，提供了直观的表达方式。我们示cases demonstrate our method for tracking irradiation-induced amorphous fronts in thin films used for catalysis and electronics. This method has the potential for "on-the-fly" segmentation to guide emerging automated electron microscopes.Note: I used the Google Translate API to translate the text into Simplified Chinese. Please note that the translation may not be perfect and may require some adjustments for clarity or accuracy.
</details></li>
</ul>
<hr>
<h2 id="UFOGen-You-Forward-Once-Large-Scale-Text-to-Image-Generation-via-Diffusion-GANs"><a href="#UFOGen-You-Forward-Once-Large-Scale-Text-to-Image-Generation-via-Diffusion-GANs" class="headerlink" title="UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs"></a>UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09257">http://arxiv.org/abs/2311.09257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanwu Xu, Yang Zhao, Zhisheng Xiao, Tingbo Hou</li>
<li>for: 这篇论文目的是提出一种高效的文本到图像生成模型，以提高传统文本到图像生成模型的计算成本。</li>
<li>methods: 该模型采用混合方法，结合了扩散模型和GAN目标函数。使用新引入的扩散-GAN目标函数和预训练扩散模型初始化，以实现高质量的文本描述图像生成。</li>
<li>results: UFOGen在单步文本到图像生成中表现出色，能够高效地生成高质量的图像。此外，UFOGen还展示了在不同应用领域的多样化应用能力，如文本描述转换、图像生成等。<details>
<summary>Abstract</summary>
Text-to-image diffusion models have demonstrated remarkable capabilities in transforming textual prompts into coherent images, yet the computational cost of their inference remains a persistent challenge. To address this issue, we present UFOGen, a novel generative model designed for ultra-fast, one-step text-to-image synthesis. In contrast to conventional approaches that focus on improving samplers or employing distillation techniques for diffusion models, UFOGen adopts a hybrid methodology, integrating diffusion models with a GAN objective. Leveraging a newly introduced diffusion-GAN objective and initialization with pre-trained diffusion models, UFOGen excels in efficiently generating high-quality images conditioned on textual descriptions in a single step. Beyond traditional text-to-image generation, UFOGen showcases versatility in applications. Notably, UFOGen stands among the pioneering models enabling one-step text-to-image generation and diverse downstream tasks, presenting a significant advancement in the landscape of efficient generative models. \blfootnote{*Work done as a student researcher of Google, $\dagger$ indicates equal contribution.
</details>
<details>
<summary>摘要</summary>
文本到图像扩散模型已经展现出了很强的能力，可以将文本描述转换成一致的图像，但计算成本仍然是一个挑战。为解决这个问题，我们提出了UFOGen，一种新的生成模型，旨在实现超快、一步文本到图像合成。与传统方法不同，UFOGen采用混合方法，将扩散模型与GAN目标相结合。通过引入新的扩散-GAN目标和使用预训练扩散模型的初始化，UFOGen在一步文本描述下生成高质量的图像。此外，UFOGen在应用方面也有很好的灵活性，可以进行多种下游任务，如图像修饰等。值得注意的是，UFOGen是一种开创性的模型，可以实现一步文本到图像生成和多种下游任务，对有效的生成模型领域具有重要的进步。
</details></li>
</ul>
<hr>
<h2 id="Drivable-3D-Gaussian-Avatars"><a href="#Drivable-3D-Gaussian-Avatars" class="headerlink" title="Drivable 3D Gaussian Avatars"></a>Drivable 3D Gaussian Avatars</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08581">http://arxiv.org/abs/2311.08581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wojciech Zielonka, Timur Bagautdinov, Shunsuke Saito, Michael Zollhöfer, Justus Thies, Javier Romero</li>
<li>for: 这篇论文旨在创造可控的3D人体模型，使用 Gaussian splats 技术实现实时渲染。</li>
<li>methods: 该论文使用 dense calibrated multi-view 视频作为输入，并使用 cage deformations 方法来控制人体模型的变形。</li>
<li>results: 对于九名不同体型、衣服和动作的试验者，该方法可以获得更高质量的结果，比之前的方法更适合电子沟通应用。<details>
<summary>Abstract</summary>
We present Drivable 3D Gaussian Avatars (D3GA), the first 3D controllable model for human bodies rendered with Gaussian splats. Current photorealistic drivable avatars require either accurate 3D registrations during training, dense input images during testing, or both. The ones based on neural radiance fields also tend to be prohibitively slow for telepresence applications. This work uses the recently presented 3D Gaussian Splatting (3DGS) technique to render realistic humans at real-time framerates, using dense calibrated multi-view videos as input. To deform those primitives, we depart from the commonly used point deformation method of linear blend skinning (LBS) and use a classic volumetric deformation method: cage deformations. Given their smaller size, we drive these deformations with joint angles and keypoints, which are more suitable for communication applications. Our experiments on nine subjects with varied body shapes, clothes, and motions obtain higher-quality results than state-of-the-art methods when using the same training and test data.
</details>
<details>
<summary>摘要</summary>
我们介绍Drivable 3D Gaussian Avatars（D3GA），这是首个基于 Gaussian splats 的人体模型，可以实时控制。现有的高级实时渲染人体模型通常需要在训练期间进行高精度的3D注册或在测试期间使用密集的输入图像，或者都是这两者。此外，基于神经辐射场也往往会对实时应用场景造成极大的阻塞。我们使用最近提出的3D Gaussian Splatting（3DGS）技术来渲染真实的人体，并使用密集标准化多视图视频作为输入。为了变形这些基本模型，我们弃用通常使用的点形变形方法（LBS），而是使用经典的体Volume变形方法：笼体变形。由于它们的更小的大小，我们使用关节角度和关节点来驱动这些变形，这更适合通信应用。我们在9名不同身体形态、衣服和动作的试验中获得了与现状方法相比的更高质量结果，使用同一组training和测试数据。
</details></li>
</ul>
<hr>
<h2 id="Reading-Between-the-Mud-A-Challenging-Motorcycle-Racer-Number-Dataset"><a href="#Reading-Between-the-Mud-A-Challenging-Motorcycle-Racer-Number-Dataset" class="headerlink" title="Reading Between the Mud: A Challenging Motorcycle Racer Number Dataset"></a>Reading Between the Mud: A Challenging Motorcycle Racer Number Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09256">http://arxiv.org/abs/2311.09256</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jacobtyo/swintextspotter">https://github.com/jacobtyo/swintextspotter</a></li>
<li>paper_authors: Jacob Tyo, Youngseog Chung, Motolani Olarinre, Zachary C. Lipton</li>
<li>for: 本研究实验室发表了一个新的挑战性质的数据集，即 off-road motorcycle Racer number Dataset (RnD)，用于光学字符识别 (OCR) 研究。RnD 包含 2,411 幅 профессиональ摄影师拍摄的机车赛车手员照片，这些照片展示了许多对 OCR 难以辨识的因素，例如泥尘遮挡、动态模糊、非标准字体、照明闪光、复杂背景等。</li>
<li>methods: 这个数据集包含 5,578 个手动标注的 bounding box，以及标注的数字和字母。</li>
<li>results: 我们的实验表明，使用现有的 OCR 算法后 fine-tuning，只有 End-to-End F1 分数为 0.527 的 RnD，并且分析显示泥尘是主要的挑战，对于正常情况下的模型而言，泥尘会导致模型的精度下降很多。<details>
<summary>Abstract</summary>
This paper introduces the off-road motorcycle Racer number Dataset (RnD), a new challenging dataset for optical character recognition (OCR) research. RnD contains 2,411 images from professional motorsports photographers that depict motorcycle racers in off-road competitions. The images exhibit a wide variety of factors that make OCR difficult, including mud occlusions, motion blur, non-standard fonts, glare, complex backgrounds, etc. The dataset has 5,578 manually annotated bounding boxes around visible motorcycle numbers, along with transcribed digits and letters. Our experiments benchmark leading OCR algorithms and reveal an end-to-end F1 score of only 0.527 on RnD, even after fine-tuning. Analysis of performance on different occlusion types shows mud as the primary challenge, degrading accuracy substantially compared to normal conditions. But the models struggle with other factors including glare, blur, shadows, and dust. Analysis exposes substantial room for improvement and highlights failure cases of existing models. RnD represents a valuable new benchmark to drive innovation in real-world OCR capabilities. The authors hope the community will build upon this dataset and baseline experiments to make progress on the open problem of robustly recognizing text in unconstrained natural environments. The dataset is available at https://github.com/JacobTyo/SwinTextSpotter.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Topology-of-Surface-Electromyogram-Signals-Hand-Gesture-Decoding-on-Riemannian-Manifolds"><a href="#Topology-of-Surface-Electromyogram-Signals-Hand-Gesture-Decoding-on-Riemannian-Manifolds" class="headerlink" title="Topology of Surface Electromyogram Signals: Hand Gesture Decoding on Riemannian Manifolds"></a>Topology of Surface Electromyogram Signals: Hand Gesture Decoding on Riemannian Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08548">http://arxiv.org/abs/2311.08548</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harshavardhanatg/geometryofsemg">https://github.com/harshavardhanatg/geometryofsemg</a></li>
<li>paper_authors: Harshavardhana T. Gowda, Lee M. Miller</li>
<li>for: 这个研究是为了检测肢体上的电势变化，并且使用非侵入式表皮电势实验（sEMG）信号来推导手势。</li>
<li>methods: 这个研究使用了一组多个感应器电极在肢体上的sEMG信号，并使用了一种简单的分析方法来分辨不同的手势。</li>
<li>results: 这个研究发现，使用这种分析方法可以从sEMG信号中提取出丰富的几何图形特征，并且可以用来分辨不同的手势。此外，这种方法还可以处理不同个体和Session之间的信号变化，并且可以提供更加稳定和透明的模型。<details>
<summary>Abstract</summary>
Decoding gestures from the upper limb using noninvasive surface electromyogram (sEMG) signals is of keen interest for the rehabilitation of amputees, artificial supernumerary limb augmentation, gestural control of computers, and virtual/augmented realities. We show that sEMG signals recorded across an array of sensor electrodes in multiple spatial locations around the forearm evince a rich geometric pattern of global motor unit (MU) activity that can be leveraged to distinguish different hand gestures. We demonstrate a simple technique to analyze spatial patterns of muscle MU activity within a temporal window and show that distinct gestures can be classified in both supervised and unsupervised manners. Specifically, we construct symmetric positive definite (SPD) covariance matrices to represent the spatial distribution of MU activity in a time window of interest, calculated as pairwise covariance of electrical signals measured across different electrodes. This allows us to understand and manipulate multivariate sEMG timeseries on a more natural subspace -the Riemannian manifold. Furthermore, it directly addresses signal variability across individuals and sessions, which remains a major challenge in the field. sEMG signals measured at a single electrode lack contextual information such as how various anatomical and physiological factors influence the signals and how their combined effect alters the evident interaction among neighboring muscles. As we show here, analyzing spatial patterns using covariance matrices on Riemannian manifolds allows us to robustly model complex interactions across spatially distributed MUs and provides a flexible and transparent framework to quantify differences in sEMG signals across individuals. The proposed method is novel in the study of sEMG signals and its performance exceeds the current benchmarks while maintaining exceptional computational efficiency.
</details>
<details>
<summary>摘要</summary>
使用非侵入性表面电 MYography (sEMG) 信号记录从上肢臂的各种位置获得的手势解oding是对各种应用场景的感兴趣，包括截肢者的复健、人工辅助臂、手势控制计算机和虚拟/增强现实。我们显示了 sEMG 信号记录在多个感知电极上的数组形式具有丰富的几何征特，可以用来 отличи不同的手势。我们展示了一种简单的分析方法，可以在时间窗口内分析多个肌电单元 (MU) 的活动空间分布，并证明了不同的手势可以在超级vised和无监督方式下分类。特别是，我们使用对称正定 definite (SPD) covariance matrix来表示在时间窗口内MU活动的空间分布，这allow us 理解和操纵多ivariate sEMG 时序序列在自然的Riemannian manifold上。此外，这种方法直接解决了信号变化 across individuals and sessions 这一主要挑战，而且可以Robustly 模型跨 spacedly distributed MUs 的复杂交互关系。我们的方法是对 sEMG 信号的研究中的新方法，其性能超过当前的benchmark，而且保持了出色的计算效率。
</details></li>
</ul>
<hr>
<h2 id="Physical-Adversarial-Examples-for-Multi-Camera-Systems"><a href="#Physical-Adversarial-Examples-for-Multi-Camera-Systems" class="headerlink" title="Physical Adversarial Examples for Multi-Camera Systems"></a>Physical Adversarial Examples for Multi-Camera Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08539">http://arxiv.org/abs/2311.08539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ana Răduţoiu, Jan-Philipp Schulze, Philip Sperl, Konstantin Böttinger</li>
<li>for: 这个论文旨在研究多个摄像头设计是如何对抗物理攻击的。</li>
<li>methods: 该论文使用了新的攻击方法，即Transcender-MC，它利用在线3D渲染和视角投影在训练过程中。</li>
<li>results: 该论文发现，使用多个摄像头设计可以提供一定的鲁棒性，但是在同时优化多个视角时，这种鲁棒性减少。Transcender-MC方法比现有方法更有效，可以成功攻击多个摄像头设计的11%。<details>
<summary>Abstract</summary>
Neural networks build the foundation of several intelligent systems, which, however, are known to be easily fooled by adversarial examples. Recent advances made these attacks possible even in air-gapped scenarios, where the autonomous system observes its surroundings by, e.g., a camera. We extend these ideas in our research and evaluate the robustness of multi-camera setups against such physical adversarial examples. This scenario becomes ever more important with the rise in popularity of autonomous vehicles, which fuse the information of several cameras for their driving decision. While we find that multi-camera setups provide some robustness towards past attack methods, we see that this advantage reduces when optimizing on multiple perspectives at once. We propose a novel attack method that we call Transcender-MC, where we incorporate online 3D renderings and perspective projections in the training process. Moreover, we motivate that certain data augmentation techniques can facilitate the generation of successful adversarial examples even further. Transcender-MC is 11% more effective in successfully attacking multi-camera setups than state-of-the-art methods. Our findings offer valuable insights regarding the resilience of object detection in a setup with multiple cameras and motivate the need of developing adequate defense mechanisms against them.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SceneScore-Learning-a-Cost-Function-for-Object-Arrangement"><a href="#SceneScore-Learning-a-Cost-Function-for-Object-Arrangement" class="headerlink" title="SceneScore: Learning a Cost Function for Object Arrangement"></a>SceneScore: Learning a Cost Function for Object Arrangement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08530">http://arxiv.org/abs/2311.08530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivan Kapelyukh, Edward Johns</li>
<li>for: 本研究旨在开发一种能够评估这些物品的排序方式，以便让机器人完成更多有用的任务。</li>
<li>methods: 本研究使用一种名为“SceneScore”的方法，可以学习一个成本函数，以评估排序方式的有用性。这个方法使用能量基本模型来学习训练排序方式的分布，不需要环境互动或人工指导。</li>
<li>results: 实验结果显示，学习的成本函数可以用来预测缺失的物品的姿态，扩展到新的物品使用semantic特征，并且可以与其他成本函数进行结合以满足约束。<details>
<summary>Abstract</summary>
Arranging objects correctly is a key capability for robots which unlocks a wide range of useful tasks. A prerequisite for creating successful arrangements is the ability to evaluate the desirability of a given arrangement. Our method "SceneScore" learns a cost function for arrangements, such that desirable, human-like arrangements have a low cost. We learn the distribution of training arrangements offline using an energy-based model, solely from example images without requiring environment interaction or human supervision. Our model is represented by a graph neural network which learns object-object relations, using graphs constructed from images. Experiments demonstrate that the learned cost function can be used to predict poses for missing objects, generalise to novel objects using semantic features, and can be composed with other cost functions to satisfy constraints at inference time.
</details>
<details>
<summary>摘要</summary>
“ Correctly arranging objects is a crucial ability for robots, unlocking a wide range of useful tasks. To create successful arrangements, we need to evaluate the desirability of a given arrangement. Our method, SceneScore, learns a cost function for arrangements, where desirable, human-like arrangements have a low cost. We learn the distribution of training arrangements offline using an energy-based model, solely from example images without requiring environment interaction or human supervision. Our model is represented by a graph neural network, which learns object-object relations using graphs constructed from images. Experimental results show that the learned cost function can be used to predict poses for missing objects, generalize to novel objects using semantic features, and can be composed with other cost functions to satisfy constraints at inference time.”Here's the translation breakdown:* “ Correctly arranging objects is a crucial ability for robots, unlocking a wide range of useful tasks.” (对象的正确排序是机器人的关键能力，解锁了许多有用的任务。)* “ To create successful arrangements, we need to evaluate the desirability of a given arrangement.” (成功的排序需要评估给定排序的可 desirability。)* “ Our method, SceneScore, learns a cost function for arrangements, where desirable, human-like arrangements have a low cost.” (我们的方法是 SceneScore，学习排序的成本函数，愿望的人类化排序有低成本。)* “ We learn the distribution of training arrangements offline using an energy-based model, solely from example images without requiring environment interaction or human supervision.” (我们在线上学习排序的分布，使用能量基本模型，只使用示例图像，不需要环境互动或人类监督。)* “ Our model is represented by a graph neural network, which learns object-object relations using graphs constructed from images.” (我们的模型是图神经网络，学习图像中对象之间的关系。)* “ Experimental results show that the learned cost function can be used to predict poses for missing objects, generalize to novel objects using semantic features, and can be composed with other cost functions to satisfy constraints at inference time.” (实验结果表明，学习的成本函数可以用来预测缺失对象的姿态，泛化到新对象使用semantic特征，并可以与其他成本函数组合来满足约束。)
</details></li>
</ul>
<hr>
<h2 id="Cross-dataset-domain-adaptation-for-the-classification-COVID-19-using-chest-computed-tomography-images"><a href="#Cross-dataset-domain-adaptation-for-the-classification-COVID-19-using-chest-computed-tomography-images" class="headerlink" title="Cross-dataset domain adaptation for the classification COVID-19 using chest computed tomography images"></a>Cross-dataset domain adaptation for the classification COVID-19 using chest computed tomography images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08524">http://arxiv.org/abs/2311.08524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ridha Ouni, Haikel Alhichri</li>
<li>for: 这个论文是为了检测 COVID-19 患者使用计算机 Tomography（CT）图像的肺部而写的。</li>
<li>methods: 这个论文使用了 Deep Learning（DL）解决方案，具体来说是 Convolutional Neural Networks（CNN）。它们在同一个数据集上训练和测试时取得了出色的结果，但是当数据集不同时，结果却很低。这个论文使用了领域适应（DA）技术来解决这个跨数据集问题。</li>
<li>results: 这个论文在四个跨数据集场景中测试了 COVID19-DANet 模型，使用了 SARS-CoV-2-CT 和 COVID19-CT 数据集，并取得了比现有研究更加鼓舞人的结果。<details>
<summary>Abstract</summary>
Detecting COVID-19 patients using Computed Tomography (CT) images of the lungs is an active area of research. Datasets of CT images from COVID-19 patients are becoming available. Deep learning (DL) solutions and in particular Convolutional Neural Networks (CNN) have achieved impressive results for the classification of COVID-19 CT images, but only when the training and testing take place within the same dataset. Work on the cross-dataset problem is still limited and the achieved results are low. Our work tackles the cross-dataset problem through a Domain Adaptation (DA) technique with deep learning. Our proposed solution, COVID19-DANet, is based on pre-trained CNN backbone for feature extraction. For this task, we select the pre-trained Efficientnet-B3 CNN because it has achieved impressive classification accuracy in previous work. The backbone CNN is followed by a prototypical layer which is a concept borrowed from prototypical networks in few-shot learning (FSL). It computes a cosine distance between given samples and the class prototypes and then converts them to class probabilities using the Softmax function. To train the COVID19-DANet model, we propose a combined loss function that is composed of the standard cross-entropy loss for class discrimination and another entropy loss computed over the unlabelled target set only. This so-called unlabelled target entropy loss is minimized and maximized in an alternative fashion, to reach the two objectives of class discrimination and domain invariance. COVID19-DANet is tested under four cross-dataset scenarios using the SARS-CoV-2-CT and COVID19-CT datasets and has achieved encouraging results compared to recent work in the literature.
</details>
<details>
<summary>摘要</summary>
寻找COVID-19患者使用计算机Tomography（CT）图像是一个活跃的研究领域。COVID-19患者的CT图像集合在不断地提供。深度学习（DL）解决方案，特别是卷积神经网络（CNN），在分类COVID-19 CT图像时已经达到了非常出色的结果，但只有在训练和测试数据集在同一个数据集时才能达到这些结果。对于跨数据集问题，目前的研究尚未充分，已经获得的结果较低。我们的工作是通过领域适应（DA）技术来解决跨数据集问题。我们提出的解决方案是基于预训练的 CNN 背景，称为 COVID19-DANet。我们选择了预训练的 Efficientnet-B3 CNN，因为它在前一个工作中已经达到了非常出色的分类精度。背景 CNN 后接一个prototype层，这是从几何学学习（FSL）中借鉴的概念。它计算给定样本和类型谱的cosine距离，然后使用softmax函数将其转换为类别概率。为了训练 COVID19-DANet 模型，我们提议一个组合损失函数，由标准的交叉熵损失和另一个对无标签目标集的 entropy 损失组成。这个无标签目标 entropy 损失在 alternate 的方式下逐渐下降和上升，以实现两个目标：类别识别和领域不变性。COVID19-DANet 在四个跨数据集场景下进行测试，使用 SARS-CoV-2-CT 和 COVID19-CT 数据集，并取得了与当前文献中的结果相当的成绩。
</details></li>
</ul>
<hr>
<h2 id="MADG-Margin-based-Adversarial-Learning-for-Domain-Generalization"><a href="#MADG-Margin-based-Adversarial-Learning-for-Domain-Generalization" class="headerlink" title="MADG: Margin-based Adversarial Learning for Domain Generalization"></a>MADG: Margin-based Adversarial Learning for Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08503">http://arxiv.org/abs/2311.08503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aveen Dayal, Vimal K. B., Linga Reddy Cenkeramaddi, C. Krishna Mohan, Abhinav Kumar, Vineeth N Balasubramanian<br>for:The paper aims to address the challenges of domain shift in deep learning by proposing a novel adversarial learning-based domain generalization (DG) algorithm, MADG.methods:The MADG model uses a margin loss-based discrepancy metric, which is more informative, tighter, practical, and efficiently optimizable compared to traditional 0-1 loss-based methods.results:The proposed MADG model learns domain-invariant features across all source domains and generalizes well to unseen target domains, as demonstrated through extensive experiments on popular real-world DG datasets. The model’s performance is consistent across all datasets, and the authors provide a theoretical analysis of the model’s generalization bound using margin loss and Rademacher complexity.<details>
<summary>Abstract</summary>
Domain Generalization (DG) techniques have emerged as a popular approach to address the challenges of domain shift in Deep Learning (DL), with the goal of generalizing well to the target domain unseen during the training. In recent years, numerous methods have been proposed to address the DG setting, among which one popular approach is the adversarial learning-based methodology. The main idea behind adversarial DG methods is to learn domain-invariant features by minimizing a discrepancy metric. However, most adversarial DG methods use 0-1 loss based $\mathcal{H}\Delta\mathcal{H}$ divergence metric. In contrast, the margin loss-based discrepancy metric has the following advantages: more informative, tighter, practical, and efficiently optimizable. To mitigate this gap, this work proposes a novel adversarial learning DG algorithm, MADG, motivated by a margin loss-based discrepancy metric. The proposed MADG model learns domain-invariant features across all source domains and uses adversarial training to generalize well to the unseen target domain. We also provide a theoretical analysis of the proposed MADG model based on the unseen target error bound. Specifically, we construct the link between the source and unseen domains in the real-valued hypothesis space and derive the generalization bound using margin loss and Rademacher complexity. We extensively experiment with the MADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome, DomainNet, and TerraIncognita. We evaluate the proposed algorithm on DomainBed's benchmark and observe consistent performance across all the datasets.
</details>
<details>
<summary>摘要</summary>
域外泛化（DG）技术已成为深度学习（DL）中解决域shift问题的流行方法，目标是在训练时未看到目标域的情况下，在目标域上具有良好的泛化性。在过去几年，许多DG方法被提出，其中一种受欢迎的方法是对抗学习基本方法。对抗DG方法的主要想法是通过最小化一个距离度量来学习域 invariant 特征。然而，大多数对抗DG方法使用0-1损失函数基于 $\mathcal{H}\Delta\mathcal{H}$ 距离度量。相比之下，margin损失基于距离度量有以下优点：更加有用信息、紧密、实用和可效地优化。为了弥补这一差距，本文提出了一种新的对抗学习DG算法，called MADG，被激发于margin损失基于距离度量。MADG模型在所有源域上学习域 invariant 特征，并使用对抗训练来在未看到目标域的情况下泛化良好。我们还提供了对MADG模型的理论分析，基于未见目标错误 bound。 Specifically, we construct the link between the source and unseen domains in the real-valued hypothesis space and derive the generalization bound using margin loss and Rademacher complexity. We extensively experiment with the MADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome, DomainNet, and TerraIncognita. We evaluate the proposed algorithm on DomainBed's benchmark and observe consistent performance across all the datasets.
</details></li>
</ul>
<hr>
<h2 id="Performance-of-Machine-Learning-Classification-in-Mammography-Images-using-BI-RADS"><a href="#Performance-of-Machine-Learning-Classification-in-Mammography-Images-using-BI-RADS" class="headerlink" title="Performance of Machine Learning Classification in Mammography Images using BI-RADS"></a>Performance of Machine Learning Classification in Mammography Images using BI-RADS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08493">http://arxiv.org/abs/2311.08493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Malitha Gunawardhana, Norbert Zolek</li>
<li>for: 这份研究旨在测试不同类型的乳腺超音波图像分类模型的精度，以BI-RADS（乳腺影像评价和数据系统）的定义。</li>
<li>methods: 我们使用了六种进步的分类架构，包括VGG19 \cite{simonyan2014very}, ResNet50 \cite{he2016deep}, GoogleNet \cite{szegedy2015going}, ConvNext \cite{liu2022convnet}, EfficientNet \cite{tan2019efficientnet}和Vision Transformers (ViT) \cite{dosovitskiy2020image}，而不是传统机器学习模型。我们在三个不同的设定下评估这些模型：全面精度训练、线性评估和从头开始训练。</li>
<li>results: 我们发现这些模型在全面精度训练设定下具有极高的精度和F1分数，尤其是76.39%的精度和67.94%的F1分数。这些结果显示了我们的电脑支持诊断系统的可能性和可靠性，并提供了对未来对乳腺影像评价系统的改进的坚实基础。<details>
<summary>Abstract</summary>
This research aims to investigate the classification accuracy of various state-of-the-art image classification models across different categories of breast ultrasound images, as defined by the Breast Imaging Reporting and Data System (BI-RADS). To achieve this, we have utilized a comprehensively assembled dataset of 2,945 mammographic images sourced from 1,540 patients. In order to conduct a thorough analysis, we employed six advanced classification architectures, including VGG19 \cite{simonyan2014very}, ResNet50 \cite{he2016deep}, GoogleNet \cite{szegedy2015going}, ConvNext \cite{liu2022convnet}, EfficientNet \cite{tan2019efficientnet}, and Vision Transformers (ViT) \cite{dosovitskiy2020image}, instead of traditional machine learning models. We evaluate models in three different settings: full fine-tuning, linear evaluation and training from scratch. Our findings demonstrate the effectiveness and capability of our Computer-Aided Diagnosis (CAD) system, with a remarkable accuracy of 76.39\% and an F1 score of 67.94\% in the full fine-tuning setting. Our findings indicate the potential for enhanced diagnostic accuracy in the field of breast imaging, providing a solid foundation for future endeavors aiming to improve the precision and reliability of CAD systems in medical imaging.
</details>
<details>
<summary>摘要</summary>
Note:* "BI-RADS" 是指 Breast Imaging Reporting and Data System* "CAD" 是指 Computer-Aided Diagnosis* "F1 score" 是指 F1 分数
</details></li>
</ul>
<hr>
<h2 id="MUDD-A-New-Re-Identification-Dataset-with-Efficient-Annotation-for-Off-Road-Racers-in-Extreme-Conditions"><a href="#MUDD-A-New-Re-Identification-Dataset-with-Efficient-Annotation-for-Off-Road-Racers-in-Extreme-Conditions" class="headerlink" title="MUDD: A New Re-Identification Dataset with Efficient Annotation for Off-Road Racers in Extreme Conditions"></a>MUDD: A New Re-Identification Dataset with Efficient Annotation for Off-Road Racers in Extreme Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08488">http://arxiv.org/abs/2311.08488</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jacobtyo/mudd">https://github.com/jacobtyo/mudd</a></li>
<li>paper_authors: Jacob Tyo, Motolani Olarinre, Youngseog Chung, Zachary C. Lipton</li>
<li>for: 这个论文目标是解决无约束环境中重新识别个体的问题，具体是开发一个大规模的摄像头识别数据集（MUDD），用于测试和评估重新识别模型在耗油车比赛中的性能。</li>
<li>methods: 这篇论文使用了现有的重新识别模型，包括OSNet和ResNet-50，并进行了精心的标注方法，以减少标注时间的消耗。</li>
<li>results: 根据实验结果，在没有微调的情况下，最佳模型的rank1准确率只有33%，但是通过微调MUDD数据集，可以提高rank1准确率至79%。但是，还存在许多可以改进的问题，如果能够解决这些问题，可以提高重新识别模型的性能。<details>
<summary>Abstract</summary>
Re-identifying individuals in unconstrained environments remains an open challenge in computer vision. We introduce the Muddy Racer re-IDentification Dataset (MUDD), the first large-scale benchmark for matching identities of motorcycle racers during off-road competitions. MUDD exhibits heavy mud occlusion, motion blurring, complex poses, and extreme lighting conditions previously unseen in existing re-id datasets. We present an annotation methodology incorporating auxiliary information that reduced labeling time by over 65%. We establish benchmark performance using state-of-the-art re-id models including OSNet and ResNet-50. Without fine-tuning, the best models achieve only 33% Rank-1 accuracy. Fine-tuning on MUDD boosts results to 79% Rank-1, but significant room for improvement remains. We analyze the impact of real-world factors including mud, pose, lighting, and more. Our work exposes open problems in re-identifying individuals under extreme conditions. We hope MUDD serves as a diverse and challenging benchmark to spur progress in robust re-id, especially for computer vision applications in emerging sports analytics. All code and data can be found at https://github.com/JacobTyo/MUDD.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>计算机视觉中重新识别人员在未经限制的环境中仍然是一个打开的挑战。我们介绍了污泥跑手重新识别数据集（MUDD），这是第一个大规模的匹配跑手身份的挑战。MUDD表现出污泥干扰、运动模糊、复杂的姿势和前所未见的照明条件。我们提出了一种注解方法，通过辅助信息减少标注时间超过65%。我们使用现状的最佳扩展模型，包括OSNet和ResNet-50，并对MUDD进行了微调。没有微调，最佳模型只有33%的排名第一精度。微调后，最佳模型的精度提高到79%，但还有很大的改进空间。我们分析了实际世界中的因素，包括污泥、姿势、照明等。我们的工作暴露了人员重新识别下极端条件下的开放问题。我们希望MUDD能成为一个多样化和挑战的标准 benchmark，以推动Robust re-id的进步，特别是在出现的运动数据分析领域。所有代码和数据可以在https://github.com/JacobTyo/MUDD中找到。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Foundation-Models-to-Improve-Lightweight-Clients-in-Federated-Learning"><a href="#Leveraging-Foundation-Models-to-Improve-Lightweight-Clients-in-Federated-Learning" class="headerlink" title="Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning"></a>Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08479">http://arxiv.org/abs/2311.08479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xidong Wu, Wan-Yi Lin, Devin Willmott, Filipe Condessa, Yufei Huang, Zhenzhen Li, Madan Ravi Ganesh</li>
<li>for: 帮助在不同数据分布环境下进行联合训练轺降减模型，提高模型性能和Robustness。</li>
<li>methods: 基于基础模型的模型精炼法，帮助减轻联合训练的计算开销和执行速率。</li>
<li>results: 在不同数据分布环境下，模型性能得到了提高，尤其是在罕见样本下的表现。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed training paradigm that enables clients scattered across the world to cooperatively learn a global model without divulging confidential data. However, FL faces a significant challenge in the form of heterogeneous data distributions among clients, which leads to a reduction in performance and robustness. A recent approach to mitigating the impact of heterogeneous data distributions is through the use of foundation models, which offer better performance at the cost of larger computational overheads and slower inference speeds. We introduce foundation model distillation to assist in the federated training of lightweight client models and increase their performance under heterogeneous data settings while keeping inference costs low. Our results show improvement in the global model performance on a balanced testing set, which contains rarely observed samples, even under extreme non-IID client data distributions. We conduct a thorough evaluation of our framework with different foundation model backbones on CIFAR10, with varying degrees of heterogeneous data distributions ranging from class-specific data partitions across clients to dirichlet data sampling, parameterized by values between 0.01 and 1.0.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式训练模式，允许全球各地的客户端共同学习一个全球模型，而无需披露敏感数据。然而，FL 面临着各客户端数据分布异常的挑战，这会导致模型性能和可靠性下降。为了减轻客户端数据分布异常的影响，我们可以使用基础模型，它们在训练时需要更大的计算负担和更慢的推理速度，但可以提高模型性能。我们称之为基础模型浸泡来帮助在不同客户端上进行联合训练轻量级客户端模型，以提高在不同数据分布情况下的性能，并保持推理成本低。我们的结果表明，在权衡测试集上，我们的框架可以在不同基础模型背bone和客户端数据分布情况下提高全球模型的性能，尤其是在EXTREME Non-IID客户端数据分布情况下。我们在 CIFAR10 上进行了系统性的评估，并 parametrised 客户端数据分布情况，从 class-specific 数据分区到 dirichlet 抽样，参数范围为 0.01 到 1.0。
</details></li>
</ul>
<hr>
<h2 id="Towards-Open-Ended-Visual-Recognition-with-Large-Language-Model"><a href="#Towards-Open-Ended-Visual-Recognition-with-Large-Language-Model" class="headerlink" title="Towards Open-Ended Visual Recognition with Large Language Model"></a>Towards Open-Ended Visual Recognition with Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08400">http://arxiv.org/abs/2311.08400</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bytedance/omniscient-model">https://github.com/bytedance/omniscient-model</a></li>
<li>paper_authors: Qihang Yu, Xiaohui Shen, Liang-Chieh Chen</li>
<li>for: 提出一种 straightforward 和有效的解决方案，即 OmniScient Model (OSM)，以 Addressing the challenges of localizing and recognizing objects in the open-ended physical world.</li>
<li>methods: 使用 Large Language Model (LLM) 生成类标签，取消提供类名称 during both training and testing，并且可以在不需要人工干预的情况下进行跨数据集训练，展现了robust generalization capabilities。</li>
<li>results: 通过combine OSM with off-the-shelf mask proposal model，在多种 benchmark 上显示了Promising results, and demonstrated its effectiveness in handling novel concepts.<details>
<summary>Abstract</summary>
Localizing and recognizing objects in the open-ended physical world poses a long-standing challenge within the domain of machine perception. Recent methods have endeavored to address the issue by employing a class-agnostic mask (or box) proposal model, complemented by an open-vocabulary classifier (e.g., CLIP) using pre-extracted text embeddings. However, it is worth noting that these open-vocabulary recognition models still exhibit limitations in practical applications. On one hand, they rely on the provision of class names during testing, where the recognition performance heavily depends on this predefined set of semantic classes by users. On the other hand, when training with multiple datasets, human intervention is required to alleviate the label definition conflict between them. In this paper, we introduce the OmniScient Model (OSM), a novel Large Language Model (LLM) based mask classifier, as a straightforward and effective solution to the aforementioned challenges. Specifically, OSM predicts class labels in a generative manner, thus removing the supply of class names during both training and testing. It also enables cross-dataset training without any human interference, exhibiting robust generalization capabilities due to the world knowledge acquired from the LLM. By combining OSM with an off-the-shelf mask proposal model, we present promising results on various benchmarks, and demonstrate its effectiveness in handling novel concepts. Code/model are available at https://github.com/bytedance/OmniScient-Model.
</details>
<details>
<summary>摘要</summary>
本文提出了一种新的大型自然语言模型（LLM）基于的面部分类器——全能科学模型（OSM），用于解决开放式物理世界中物体认知的长期挑战。传统方法通常采用类型不固定的面提议模型，并且使用预取得的文本嵌入来进行开放 vocabulary 分类。然而，这些开放 vocabulary 分类器在实际应用中仍存在一些限制。一方面，它们需要用户提供类别名称进行测试，测试性能强度取决于用户提供的类别名称。另一方面，在多个数据集上训练时，需要人工干预来缓解数据集之间的类别定义冲突。本文的解决方案是基于 LLM 的面部分类器，可以预测类别标签的生成方式，因此不需要在训练和测试中提供类别名称。它还可以在不需要人工干预的情况下跨数据集训练，并且具有强大的世界知识，从而表现出了robust的泛化能力。通过将 OSM 与一个开源的面提议模型结合使用，我们在多个标准准确率上获得了扎实的表现，并且在处理新概念方面也具有良好的效果。代码/模型可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="USLR-an-open-source-tool-for-unbiased-and-smooth-longitudinal-registration-of-brain-MR"><a href="#USLR-an-open-source-tool-for-unbiased-and-smooth-longitudinal-registration-of-brain-MR" class="headerlink" title="USLR: an open-source tool for unbiased and smooth longitudinal registration of brain MR"></a>USLR: an open-source tool for unbiased and smooth longitudinal registration of brain MR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08371">http://arxiv.org/abs/2311.08371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/acasamitjana/uslr">https://github.com/acasamitjana/uslr</a></li>
<li>paper_authors: Adrià Casamitjana, Roser Sala-Llonch, Karim Lekadir, Juan Eugenio Iglesias<br>for: 这个论文是为了提出一种计算框架，用于对大脑MRI扫描图像进行长期匀速注册，以估计时间序列中的非线性图像轨迹，这些轨迹是时间点无偏见、空间变换准确、成像artefact抗性的。methods: 这个框架使用了Lie álgebra参数化的空间变换（与rigid变换和静止速度场兼容），并利用log域属性来解决问题，并且使用 Bayesian推理来估计非线性注册和rigid注册。results: 这个框架可以为Alzheimer’s disease研究提供多个方面的 beneficial effects，例如：时间一致的图像分割，以减少内部变化的影响，subject特定预测或人口分析使用tensor-based morphometry。这种方法可以在扫描图像之间进行较为精细的衰减识别，从而减少临床试验中的样本大小。<details>
<summary>Abstract</summary>
We present USLR, a computational framework for longitudinal registration of brain MRI scans to estimate nonlinear image trajectories that are smooth across time, unbiased to any timepoint, and robust to imaging artefacts. It operates on the Lie algebra parameterisation of spatial transforms (which is compatible with rigid transforms and stationary velocity fields for nonlinear deformation) and takes advantage of log-domain properties to solve the problem using Bayesian inference. USRL estimates rigid and nonlinear registrations that: (i) bring all timepoints to an unbiased subject-specific space; and (i) compute a smooth trajectory across the imaging time-series. We capitalise on learning-based registration algorithms and closed-form expressions for fast inference. A use-case Alzheimer's disease study is used to showcase the benefits of the pipeline in multiple fronts, such as time-consistent image segmentation to reduce intra-subject variability, subject-specific prediction or population analysis using tensor-based morphometry. We demonstrate that such approach improves upon cross-sectional methods in identifying group differences, which can be helpful in detecting more subtle atrophy levels or in reducing sample sizes in clinical trials. The code is publicly available in https://github.com/acasamitjana/uslr
</details>
<details>
<summary>摘要</summary>
我们提出了USLR，一种计算机框架，用于对脑MRI扫描图像进行长期均衡注册，以估计不含时刻点的图像轨迹，这些轨迹在时间方向上是平滑的，不受成像artefacts的影响。它基于 Lie丰化参数化的空间变换（与静止速度场和非线性扭曲兼容），并利用 log 域的特性来解决问题，使用 Bayesian 推理。USLR 估计了不含时刻点的扭曲和非线性注册，它们可以：（i）将所有时刻点转移到不受偏见影响的个体特定空间中; （ii）计算图像序列中的平滑轨迹。我们利用了学习型注册算法和关闭式表达，以便快速推理。我们使用了 Alzheimer's disease 研究来展示我们的框架在多个方面的优势，包括时间相关的图像分割，以降低内部变化的影响，以及使用tensor基本形态来预测或对 population 进行分析。我们示出，这种方法可以在跨sectional 方法上提高组差异的检测，这有助于检测更加弱的衰老水平或减少临床试验中的样本大小。代码可以在 https://github.com/acasamitjana/uslr 中获取。
</details></li>
</ul>
<hr>
<h2 id="The-Perception-Robustness-Tradeoff-in-Deterministic-Image-Restoration"><a href="#The-Perception-Robustness-Tradeoff-in-Deterministic-Image-Restoration" class="headerlink" title="The Perception-Robustness Tradeoff in Deterministic Image Restoration"></a>The Perception-Robustness Tradeoff in Deterministic Image Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09253">http://arxiv.org/abs/2311.09253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guy Ohayon, Tomer Michaeli, Michael Elad</li>
<li>for: 解决 inverse problems 的 deterministic 方法的行为</li>
<li>methods: 使用 Lipschitz 常数来证明 predictor 的质量</li>
<li>results: deterministic 方法会受到 adversarial attack 的影响，但可以通过 exploring posterior distribution 来模拟 stochastic methods。Here’s a more detailed explanation of each point:1. for: The paper is written to study the behavior of deterministic methods for solving inverse problems in imaging. The authors aim to understand the limitations of these methods and how they can be improved.2. methods: The authors use Lipschitz constants to measure the quality of the predictor. They prove that the better the predictor satisfies two goals - high perceptual quality and consistency with measurements - the larger the Lipschitz constant must be. This implies that such methods are more susceptible to adversarial attacks.3. results: The authors demonstrate their theory on single image super-resolution algorithms, showing that the deterministic method can be affected by adversarial attacks. However, they also show that by exploring the posterior distribution, the deterministic method can imitate stochastic methods, which are more robust to such attacks.<details>
<summary>Abstract</summary>
We study the behavior of deterministic methods for solving inverse problems in imaging. These methods are commonly designed to achieve two goals: (1) attaining high perceptual quality, and (2) generating reconstructions that are consistent with the measurements. We provide a rigorous proof that the better a predictor satisfies these two requirements, the larger its Lipschitz constant must be, regardless of the nature of the degradation involved. In particular, to approach perfect perceptual quality and perfect consistency, the Lipschitz constant of the model must grow to infinity. This implies that such methods are necessarily more susceptible to adversarial attacks. We demonstrate our theory on single image super-resolution algorithms, addressing both noisy and noiseless settings. We also show how this undesired behavior can be leveraged to explore the posterior distribution, thereby allowing the deterministic model to imitate stochastic methods.
</details>
<details>
<summary>摘要</summary>
我们研究决定方法对几何问题的解决方案。这些方法通常是设计来 дости持二个目标：（1）实现高度的感知质量，和（2）生成符合测量的重建。我们提供了一个严谨的证明，表明如果预测器更好地满足这两个需求，则其Lipschitz常数必须变大，不管受到的扰动是什么样的。具体来说，要进一步推进完美的感知质量和完美的一致性，预测器的Lipschitz常数必须增长到无限大。这意味着这些方法一定会更易受到骗袭攻击。我们在单影像超解析算法中证明了我们的理论，包括噪音和噪音无的设定。我们还示出了如何利用这种不愿的行为来探索 posterior 分布，从而让决定模型模仿随机方法。
</details></li>
</ul>
<hr>
<h2 id="Rotation-Agnostic-Image-Representation-Learning-for-Digital-Pathology"><a href="#Rotation-Agnostic-Image-Representation-Learning-for-Digital-Pathology" class="headerlink" title="Rotation-Agnostic Image Representation Learning for Digital Pathology"></a>Rotation-Agnostic Image Representation Learning for Digital Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08359">http://arxiv.org/abs/2311.08359</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RhazesLab/PathDino">https://github.com/RhazesLab/PathDino</a></li>
<li>paper_authors: Saghir Alfasly, Abubakr Shafique, Peyman Nejat, Jibran Khan, Areej Alsaafin, Ghazal Alabtah, H. R. Tizhoosh</li>
<li>for: 这篇论文主要针对 histopathological image analysis 领域的复杂挑战，通过三个关键贡献进行解决。</li>
<li>methods: 该论文提出了一种快速补丁选择方法 (FPS)，用于整个扫描图像 (WSI) 分析，大幅降低计算成本，保持准确性。此外，它还提出了一种轻量级的 histopathology 特征提取器 PathDino，只有 9 万参数，远远少于其他选择。</li>
<li>results: 该论文表明，使用我们的紧凑型模型可以在 12 种多样化的数据集上超越现有的 histopathology-specific 视Transformers，包括四个内部数据集 (乳腺、肝脏、皮肤和肠癌) 以及七个公共数据集。准确性提高了 8.5%。<details>
<summary>Abstract</summary>
This paper addresses complex challenges in histopathological image analysis through three key contributions. Firstly, it introduces a fast patch selection method, FPS, for whole-slide image (WSI) analysis, significantly reducing computational cost while maintaining accuracy. Secondly, it presents PathDino, a lightweight histopathology feature extractor with a minimal configuration of five Transformer blocks and only 9 million parameters, markedly fewer than alternatives. Thirdly, it introduces a rotation-agnostic representation learning paradigm using self-supervised learning, effectively mitigating overfitting. We also show that our compact model outperforms existing state-of-the-art histopathology-specific vision transformers on 12 diverse datasets, including both internal datasets spanning four sites (breast, liver, skin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS, DigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training dataset of 6 million histopathology patches from The Cancer Genome Atlas (TCGA), our approach demonstrates an average 8.5% improvement in patch-level majority vote performance. These contributions provide a robust framework for enhancing image analysis in digital pathology, rigorously validated through extensive evaluation. Project Page: https://rhazeslab.github.io/PathDino-Page/
</details>
<details>
<summary>摘要</summary>
这份论文通过三大贡献提供了复杂的 histopathological 图像分析解决方案。首先，它提出了一种快速补充方法（FPS），用于整个扫描图像（WSI）分析，大幅降低计算成本而保持准确性。其次，它推出了一种轻量级的历史病理特征提取器（PathDino），只有5个转换块和900万参数，与其他选择器相比明显少于。最后，它引入了一种不受旋转影响的学习模式，使用自动驱动学习，有效地避免过拟合。我们还证明了我们的减少模型在12个多样化的数据集上（包括四个内部数据集（乳腺、肝脏、皮肤和肠Rectum）以及七个公共数据集（PANDA、CAMELYON16、BRACS、DigestPath、Kather、PanNuke和WSSS4LUAD））都能够超越现有的历史病理特定视Transformers。特别是，即使使用TCGA数据集进行600万次训练，我们的方法还能够在批量投票中平均提高8.5%的性能。这些贡献为整个数字病理学领域提供了一个坚实的框架，通过广泛的评估来强制验证。项目页面：https://rhazeslab.github.io/PathDino-Page/
</details></li>
</ul>
<hr>
<h2 id="Convolutional-Neural-Networks-Exploiting-Attributes-of-Biological-Neurons"><a href="#Convolutional-Neural-Networks-Exploiting-Attributes-of-Biological-Neurons" class="headerlink" title="Convolutional Neural Networks Exploiting Attributes of Biological Neurons"></a>Convolutional Neural Networks Exploiting Attributes of Biological Neurons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08314">http://arxiv.org/abs/2311.08314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neeraj Kumar Singh, Nikhil R. Pal</li>
<li>For: This paper aims to improve the performance of Convolutional Neural Networks (CNNs) by integrating principles from biological neurons into the network architecture.* Methods: The proposed method uses neuro-science-inspired computational models of the Lateral Geniculate Nucleus (LGN) and simple cells of the primary visual cortex to extract image features as input to CNNs. The method also uses a two-tower CNN architecture, with one shallow tower and one ResNet 18 tower, to enhance the learning process and performance.* Results: The proposed method achieves a noticeable improvement in performance (on average 5-10%) on CIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. Additionally, the efficiency of only the Push-Pull tower of the network is also checked.Here is the Chinese translation of the three key points:* For: 这篇论文目标是通过将生物神经元的原理 integrate into CNN 网络架构来提高 CNN 的性能。* Methods: 提议的方法使用了生物神经元的计算模型，即 Lateral Geniculate Nucleus (LGN) 和 primary visual cortex 中的简单细胞模型，以提取图像特征作为 CNN 的输入。该方法还使用了一个两个塔的 CNN 架构，其中一个是浅塔，另一个是 ResNet 18 塔，以增强网络学习过程和性能。* Results: 提议的方法在 CIFAR-10、CIFAR-100 和 ImageNet-100 数据集上实现了平均提高5-10%的性能，相比 ResNet-18。此外，只测试了 Push-Pull 塔的效率也被检查了。<details>
<summary>Abstract</summary>
In this era of artificial intelligence, deep neural networks like Convolutional Neural Networks (CNNs) have emerged as front-runners, often surpassing human capabilities. These deep networks are often perceived as the panacea for all challenges. Unfortunately, a common downside of these networks is their ''black-box'' character, which does not necessarily mirror the operation of biological neural systems. Some even have millions/billions of learnable (tunable) parameters, and their training demands extensive data and time.   Here, we integrate the principles of biological neurons in certain layer(s) of CNNs. Specifically, we explore the use of neuro-science-inspired computational models of the Lateral Geniculate Nucleus (LGN) and simple cells of the primary visual cortex. By leveraging such models, we aim to extract image features to use as input to CNNs, hoping to enhance training efficiency and achieve better accuracy. We aspire to enable shallow networks with a Push-Pull Combination of Receptive Fields (PP-CORF) model of simple cells as the foundation layer of CNNs to enhance their learning process and performance. To achieve this, we propose a two-tower CNN, one shallow tower and the other as ResNet 18. Rather than extracting the features blindly, it seeks to mimic how the brain perceives and extracts features. The proposed system exhibits a noticeable improvement in the performance (on an average of $5\%-10\%$) on CIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. We also check the efficiency of only the Push-Pull tower of the network.
</details>
<details>
<summary>摘要</summary>
在人工智能时代，深度神经网络（CNN）已成为前Runner，经常超越人类能力。这些深度网络经常被视为所有挑战的解决方案。然而，它们的一个常见缺点是“黑盒”性，不一定反映生物神经系统的运作。一些甚至有 millions/billions 的可调参数，并且培训需要大量数据和时间。在这里，我们将生物神经元的原理 integrate 到 Certain Layer 中的 CNN 中。具体来说，我们将 explore 使用生物 ней维科学发展的 Lateral Geniculate Nucleus (LGN) 和 primary visual cortex 的简单细胞模型。通过这些模型，我们希望从图像中提取特征，并将其作为 CNN 的输入，以提高训练效率和准确率。我们 aspire 使用 shallow network 和 ResNet 18 的 Push-Pull Combination of Receptive Fields (PP-CORF) 模型作为基础层，以便提高 CNN 的学习过程和性能。我们的提案的系统在 CIFAR-10、CIFAR-100 和 ImageNet-100 数据集上显示了明显的性能提升（在 average 上为5%-10%），并且只有 Push-Pull 塔的网络进行测试。
</details></li>
</ul>
<hr>
<h2 id="The-Heat-is-On-Thermal-Facial-Landmark-Tracking"><a href="#The-Heat-is-On-Thermal-Facial-Landmark-Tracking" class="headerlink" title="The Heat is On: Thermal Facial Landmark Tracking"></a>The Heat is On: Thermal Facial Landmark Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08308">http://arxiv.org/abs/2311.08308</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Baker</li>
<li>for: 这篇论文旨在为热像图像中的人脸特征点跟踪提供一种方法，以捕捉人体的生物physiological signal，例如血液循环和汗水 secretion，从而远程评估情绪和兴奋程度。</li>
<li>methods: 这篇论文使用了多种不同的模型组件，如径 residual connections，通道和特征 wise attention，以及 ensemble 组件的实践，以提高模型的性能。</li>
<li>results: 研究发现，使用 convolutional 和 residual 层，并且在通道方向进行自注意力处理，可以实现最佳性能，需要 menos than 100K 参数。<details>
<summary>Abstract</summary>
Facial landmark tracking for thermal images requires tracking certain important regions of subjects' faces, using images from thermal images, which omit lighting and shading, but show the temperatures of their subjects. The fluctuations of heat in particular places reflect physiological changes like bloodflow and perspiration, which can be used to remotely gauge things like anxiety and excitement. Past work in this domain has been limited to only a very limited set of architectures and techniques. This work goes further by trying a comprehensive suit of various models with different components, such as residual connections, channel and feature-wise attention, as well as the practice of ensembling components of the network to work in parallel. The best model integrated convolutional and residual layers followed by a channel-wise self-attention layer, requiring less than 100K parameters.
</details>
<details>
<summary>摘要</summary>
法面特征跟踪技术 для热图像需要跟踪热图像中重要的面部区域，使用热图像，它们排除光照和阴影，但显示对象的温度。热图像中的温度波动反映了物体的生理变化，如血液循环和汗水，可以通过远程测量情绪和兴奋程度。过去在这个领域中的研究受限于一个非常有限的集合 Architecture和技术。这个工作更迭，尝试了多种不同的模型组件，如径 residual 连接，通道和特征 wise 注意力，以及网络组件的并行实现。最佳模型结合了卷积层和径 residual 层，然后跟踪通道的自注意力层，需要 menos than 100K 参数。
</details></li>
</ul>
<hr>
<h2 id="Level-Set-KSVD"><a href="#Level-Set-KSVD" class="headerlink" title="Level Set KSVD"></a>Level Set KSVD</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08284">http://arxiv.org/abs/2311.08284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rituparnaS/Dictionary-learning-level-set">https://github.com/rituparnaS/Dictionary-learning-level-set</a></li>
<li>paper_authors: Omer Sapir, Iftach Klapp, Nir Sochen</li>
<li>for: 用于检测蔬菜场景中病虫的扩散</li>
<li>methods: 使用维度集KSVD学习特征，并使用一种通过 Chan-Vese 函数泛化的 Image segmentation 方法</li>
<li>results: 测试结果与其他方法相比，Level-set KSVD 方法显示更高的准确率和更好的性能<details>
<summary>Abstract</summary>
We present a new algorithm for image segmentation - Level-set KSVD. Level-set KSVD merges the methods of sparse dictionary learning for feature extraction and variational level-set method for image segmentation. Specifically, we use a generalization of the Chan-Vese functional with features learned by KSVD. The motivation for this model is agriculture based. Aerial images are taken in order to detect the spread of fungi in various crops. Our model is tested on such images of cotton fields. The results are compared to other methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的图像分割算法——级别集成KSVD。级别集成KSVD将特征提取的方法和变量水平集成方法结合在一起，用于图像分割。我们使用一种普遍化的 Chan-Vese 函数，其中特征被 KSVD 学习。我们的模型的动机是基于农业的，用于从航空图像中检测不同作物中致病菌的传播。我们的模型在棉田图像上进行测试，与其他方法进行比较。Note:* "级别集成" (level-set) is used to refer to the combination of level-set method and sparse dictionary learning.* "KSVD" (K-Singular Value Decomposition) is used to refer to the sparse dictionary learning method.* " Chan-Vese 函数" (Chan-Vese functional) is used to refer to the energy functional used in the level-set method.
</details></li>
</ul>
<hr>
<h2 id="ARTEMIS-Using-GANs-with-Multiple-Discriminators-to-Generate-Art"><a href="#ARTEMIS-Using-GANs-with-Multiple-Discriminators-to-Generate-Art" class="headerlink" title="ARTEMIS: Using GANs with Multiple Discriminators to Generate Art"></a>ARTEMIS: Using GANs with Multiple Discriminators to Generate Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08278">http://arxiv.org/abs/2311.08278</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Baker</li>
<li>for: 这篇论文是关于生成抽象艺术的新方法的描述。</li>
<li>methods: 论文使用了自动编码器和生成 adversarial neural network (GAN) 来生成抽象艺术作品。自动编码器首先在 VGG 网络中提取了图像的风格表示，然后使用了这些表示来生成新的图像。</li>
<li>results: 论文的实验结果表明，使用这种方法可以生成出具有幻想的、几何化的图像，这些图像具有高度的创新性和多样性。<details>
<summary>Abstract</summary>
We propose a novel method for generating abstract art. First an autoencoder is trained to encode and decode the style representations of images, which are extracted from source images with a pretrained VGG network. Then, the decoder component of the autoencoder is extracted and used as a generator in a GAN. The generator works with an ensemble of discriminators. Each discriminator takes different style representations of the same images, and the generator is trained to create images that create convincing style representations in order to deceive all of the generators. The generator is also trained to maximize a diversity term. The resulting images had a surreal, geometric quality. We call our approach ARTEMIS (ARTistic Encoder- Multi- Discriminators Including Self-Attention), as it uses the self-attention layers and an encoder-decoder architecture.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的抽象艺术生成方法。首先，我们使用预训练的VGG网络提取源图像中的风格表示，然后使用自动encoder进行编码和解码。接着，decoder组件被提取出来作为生成器在GAN中使用。生成器与多个批处理器（discriminators）一起工作，每个批处理器接受不同的风格表示，生成器则被训练以创造出可以欺骗所有批处理器的图像。同时，生成器还被训练以最大化多样性项。结果图像具有了具有Surreal的几何特点。我们称之为ARTEMIS（ARTistic Encoder- Multi- Discriminators Including Self-Attention），因为它使用了自我注意层和编码-解码架构。
</details></li>
</ul>
<hr>
<h2 id="Defining-the-boundaries-challenges-and-advances-in-identifying-cells-in-microscopy-images"><a href="#Defining-the-boundaries-challenges-and-advances-in-identifying-cells-in-microscopy-images" class="headerlink" title="Defining the boundaries: challenges and advances in identifying cells in microscopy images"></a>Defining the boundaries: challenges and advances in identifying cells in microscopy images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08269">http://arxiv.org/abs/2311.08269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nodar Gogoberidze, Beth A. Cimini</li>
<li>for: 这篇论文是为了提高微scopic图像中细胞的测量和分析而写的。</li>
<li>methods: 这篇论文使用了深度学习方法来进行图像分割，特别是使用Cellpose模型，以提高准确性和用户友好性。</li>
<li>results: 这篇论文的实验结果表明，使用深度学习方法可以提高图像分割的准确性和效率，并且可以在多种不同的测试数据上达到高度的一致性。<details>
<summary>Abstract</summary>
Segmentation, or the outlining of objects within images, is a critical step in the measurement and analysis of cells within microscopy images. While improvements continue to be made in tools that rely on classical methods for segmentation, deep learning-based tools increasingly dominate advances in the technology. Specialist models such as Cellpose continue to improve in accuracy and user-friendliness, and segmentation challenges such as the Multi-Modality Cell Segmentation Challenge continue to push innovation in accuracy across widely-varying test data as well as efficiency and usability. Increased attention on documentation, sharing, and evaluation standards are leading to increased user-friendliness and acceleration towards the goal of a truly universal method.
</details>
<details>
<summary>摘要</summary>
“分割”或“图像中 объек 的划分”是微scopic 图像分析中的重要步骤。 classical 方法工具的改进仍在继续，但是深度学习基础的工具在技术发展中越来越 dominant。专家模型如 Cellpose 的精度和用户Friendliness 不断提高，分割挑战如多 modal 维度细胞分割挑战也在不同的测试数据上提高精度和效率。 文档、分享和评估标准的增加导致了更高的用户友好性和universal 方法的加速。Note: "多 modal" in the text refers to the fact that the images being analyzed are from multiple sources or modalities, such as brightfield, phase contrast, and fluorescence microscopy.
</details></li>
</ul>
<hr>
<h2 id="TENT-Connect-Language-Models-with-IoT-Sensors-for-Zero-Shot-Activity-Recognition"><a href="#TENT-Connect-Language-Models-with-IoT-Sensors-for-Zero-Shot-Activity-Recognition" class="headerlink" title="TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity Recognition"></a>TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08245">http://arxiv.org/abs/2311.08245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunjiao Zhou, Jianfei Yang, Han Zou, Lihua Xie</li>
<li>for: 本研究旨在探讨语言模型是否可以将文本 semantics 与 IoT 感知信号连接起来，以实现认知任务，如人体活动识别（HAR）。</li>
<li>methods: 本研究提出了一种创新的方法——IoT-sEnsors-language alignmEnt pre-Training（TENT），它将文本嵌入与 IoT 感知信号（包括摄像头视频、LiDAR 和 mmWave）的嵌入进行对齐。通过 IoT-语言对照学习，我们 derive 一个共同semantic feature space，使得 IoT 数据与语言嵌入相匹配。</li>
<li>results: TENT 不仅可以识别已经看到的动作，还可以“猜测”未看到的动作，通过最近的文本词汇从共同特征空间中选择。我们在不同感知模式的零例 HAR 任务上达到了state-of-the-art 性能，超过了最佳视language模型的12%。<details>
<summary>Abstract</summary>
Recent achievements in language models have showcased their extraordinary capabilities in bridging visual information with semantic language understanding. This leads us to a novel question: can language models connect textual semantics with IoT sensory signals to perform recognition tasks, e.g., Human Activity Recognition (HAR)? If so, an intelligent HAR system with human-like cognition can be built, capable of adapting to new environments and unseen categories. This paper explores its feasibility with an innovative approach, IoT-sEnsors-language alignmEnt pre-Training (TENT), which jointly aligns textual embeddings with IoT sensor signals, including camera video, LiDAR, and mmWave. Through the IoT-language contrastive learning, we derive a unified semantic feature space that aligns multi-modal features with language embeddings, so that the IoT data corresponds to specific words that describe the IoT data. To enhance the connection between textual categories and their IoT data, we propose supplementary descriptions and learnable prompts that bring more semantic information into the joint feature space. TENT can not only recognize actions that have been seen but also ``guess'' the unseen action by the closest textual words from the feature space. We demonstrate TENT achieves state-of-the-art performance on zero-shot HAR tasks using different modalities, improving the best vision-language models by over 12%.
</details>
<details>
<summary>摘要</summary>
最近的语言模型 achievements 展示了它们在结合视觉信息和语义理解方面的杰出能力。这使我们对一个新的问题感兴趣：可以 ли使用语言模型将文本 semantics 与 IoT 感知信号相连，以实现识别任务，例如人类活动识别（HAR）？如果可以，那么可以构建一个具有人类智能认知的智能 HAR 系统，可以适应新环境和未经见过的类别。这篇文章探索了这种可能性，并提出了一种创新的方法：IoT-sEnsors-language alignmEnt pre-Training（TENT）。TENT 方法将文本嵌入与 IoT 感知信号，包括相机视频、LiDAR 和 mmWave 信号进行同步。通过 IoT-语言对比学习，我们得到了一个统一的Semantic Feature Space，其中 IoT 数据与文本嵌入之间的对应关系得到了确定。为了增强文本类别和其 IoT 数据之间的连接，我们提出了补充描述和可学习的提示。TENT 可以不仅识别已经看过的动作，还可以通过 closest 文本单词来“估计”未经见过的动作。我们示出 TENT 在零shot HAR 任务中实现了state-of-the-art 性能，比最佳视觉语言模型提高了12%以上。
</details></li>
</ul>
<hr>
<h2 id="MeLo-Low-rank-Adaptation-is-Better-than-Fine-tuning-for-Medical-Image-Diagnosis"><a href="#MeLo-Low-rank-Adaptation-is-Better-than-Fine-tuning-for-Medical-Image-Diagnosis" class="headerlink" title="MeLo: Low-rank Adaptation is Better than Fine-tuning for Medical Image Diagnosis"></a>MeLo: Low-rank Adaptation is Better than Fine-tuning for Medical Image Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08236">http://arxiv.org/abs/2311.08236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitao Zhu, Zhenrong Shen, Zihao Zhao, Sheng Wang, Xin Wang, Xiangyu Zhao, Dinggang Shen, Qian Wang</li>
<li>for: 本研究旨在提出一种单一的计算机辅助诊断（CAD）模型，用于多种临床任务，以降低大型变换器（ViT）模型的资源占用和存储空间。</li>
<li>methods: 该方法使用低级化适应 instead of 资源占用的精细调整，通过固定 ViT 模型的Weight 并只添加小型低级插件，实现了多种鉴定任务中的竞争性表现。</li>
<li>results: 对于四种医疗成像数据集，提出的方法可以与完全精细调整的 ViT 模型具有相似的表现，使用约 0.17% 的可训练参数。此外，MeLo 只增加了约 0.5MB 的存储空间，并允许极快的模型交换和执行。<details>
<summary>Abstract</summary>
The common practice in developing computer-aided diagnosis (CAD) models based on transformer architectures usually involves fine-tuning from ImageNet pre-trained weights. However, with recent advances in large-scale pre-training and the practice of scaling laws, Vision Transformers (ViT) have become much larger and less accessible to medical imaging communities. Additionally, in real-world scenarios, the deployments of multiple CAD models can be troublesome due to problems such as limited storage space and time-consuming model switching. To address these challenges, we propose a new method MeLo (Medical image Low-rank adaptation), which enables the development of a single CAD model for multiple clinical tasks in a lightweight manner. It adopts low-rank adaptation instead of resource-demanding fine-tuning. By fixing the weight of ViT models and only adding small low-rank plug-ins, we achieve competitive results on various diagnosis tasks across different imaging modalities using only a few trainable parameters. Specifically, our proposed method achieves comparable performance to fully fine-tuned ViT models on four distinct medical imaging datasets using about 0.17% trainable parameters. Moreover, MeLo adds only about 0.5MB of storage space and allows for extremely fast model switching in deployment and inference. Our source code and pre-trained weights are available on our website (https://absterzhu.github.io/melo.github.io/).
</details>
<details>
<summary>摘要</summary>
通常，在基于转换器架构的计算机辅助诊断（CAD）模型开发中，会进行 ImageNet 预训练权重的细化。然而，随着大规模预训练的进步和做法的做法，视觉转换器（ViT）已经变得更加大型，并且对医疗影像社区而言更加不可accessible。此外，在实际应用场景中，多个 CAD 模型的部署可能会陷入有限的存储空间和时间consuming的模型交换问题。为解决这些挑战，我们提出了一新方法 MeLo（医疗影像低级化），它允许开发单一的 CAD 模型，用于多种临床任务，并且具有轻量级的特点。它采用低级化adaptation而不是资源占用的细化。通过固定 ViT 模型的weight和只添加小型低级插件，我们实现了在不同的医疗影像模式上多种诊断任务中的竞争性成绩，使用只有约 0.17% 的可训练参数。此外，MeLo 只增加了约 0.5MB 的存储空间，并允许在部署和推理过程中非常快速的模型交换。我们的源代码和预训练 веса可以在我们的网站（https://absterzhu.github.io/melo.github.io/）上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Approach-for-Comprehensive-Analysis-of-Various-Spectral-and-Tissue-Doppler-Echocardiography"><a href="#A-Unified-Approach-for-Comprehensive-Analysis-of-Various-Spectral-and-Tissue-Doppler-Echocardiography" class="headerlink" title="A Unified Approach for Comprehensive Analysis of Various Spectral and Tissue Doppler Echocardiography"></a>A Unified Approach for Comprehensive Analysis of Various Spectral and Tissue Doppler Echocardiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08439">http://arxiv.org/abs/2311.08439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaeik Jeon, Jiyeon Kim, Yeonggul Jang, Yeonyee E. Yoon, Dawun Jeong, Youngtaek Hong, Seung-Ah Lee, Hyuk-Jae Chang</li>
<li>for: 这个论文的目的是提供一种全面的Doppler echo医学图像分析框架，以便自动测量Doppler图像和诊断心脏功能。</li>
<li>methods: 该框架使用 convolutional neural network (CNN) 来自动识别Doppler图像中的关键特征，并使用新的Doppler形态嵌入和抑制锈模块来提高解释和保证一致性。</li>
<li>results: 对比其他方法，该框架在性能指标（如 dice similarity coefficients (DSC) 和 intersection over union (IoU)）中具有显著的优势，并与临床医生的诊断相一致。<details>
<summary>Abstract</summary>
Doppler echocardiography offers critical insights into cardiac function and phases by quantifying blood flow velocities and evaluating myocardial motion. However, previous methods for automating Doppler analysis, ranging from initial signal processing techniques to advanced deep learning approaches, have been constrained by their reliance on electrocardiogram (ECG) data and their inability to process Doppler views collectively. We introduce a novel unified framework using a convolutional neural network for comprehensive analysis of spectral and tissue Doppler echocardiography images that combines automatic measurements and end-diastole (ED) detection into a singular method. The network automatically recognizes key features across various Doppler views, with novel Doppler shape embedding and anti-aliasing modules enhancing interpretation and ensuring consistent analysis. Empirical results indicate a consistent outperformance in performance metrics, including dice similarity coefficients (DSC) and intersection over union (IoU). The proposed framework demonstrates strong agreement with clinicians in Doppler automatic measurements and competitive performance in ED detection.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Uni-COAL-A-Unified-Framework-for-Cross-Modality-Synthesis-and-Super-Resolution-of-MR-Images"><a href="#Uni-COAL-A-Unified-Framework-for-Cross-Modality-Synthesis-and-Super-Resolution-of-MR-Images" class="headerlink" title="Uni-COAL: A Unified Framework for Cross-Modality Synthesis and Super-Resolution of MR Images"></a>Uni-COAL: A Unified Framework for Cross-Modality Synthesis and Super-Resolution of MR Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08225">http://arxiv.org/abs/2311.08225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyun Song, Zengxin Qi, Xin Wang, Xiangyu Zhao, Zhenrong Shen, Sheng Wang, Manman Fei, Zhe Wang, Di Zang, Dongdong Chen, Linlin Yao, Qian Wang, Xuehai Wu, Lichi Zhang</li>
<li>for: 这paper的目标是提高MRI图像的Synthesis和分辨率，并且可以适应多种临床应用场景。</li>
<li>methods: 这paper使用了一种统一的网络来实现CMS、SR和CMSR等多种图像Synthesis任务，并且采用了协调增强和随机特征表示来保证模式和分辨率的一致性。</li>
<li>results: 实验结果表明，Uni-COAL在CMS、SR和CMSR等任务中表现出色，超过了现有的方法，这反映了其在多种应用场景中的一致性和通用性。<details>
<summary>Abstract</summary>
Cross-modality synthesis (CMS), super-resolution (SR), and their combination (CMSR) have been extensively studied for magnetic resonance imaging (MRI). Their primary goals are to enhance the imaging quality by synthesizing the desired modality and reducing the slice thickness. Despite the promising synthetic results, these techniques are often tailored to specific tasks, thereby limiting their adaptability to complex clinical scenarios. Therefore, it is crucial to build a unified network that can handle various image synthesis tasks with arbitrary requirements of modality and resolution settings, so that the resources for training and deploying the models can be greatly reduced. However, none of the previous works is capable of performing CMS, SR, and CMSR using a unified network. Moreover, these MRI reconstruction methods often treat alias frequencies improperly, resulting in suboptimal detail restoration. In this paper, we propose a Unified Co-Modulated Alias-free framework (Uni-COAL) to accomplish the aforementioned tasks with a single network. The co-modulation design of the image-conditioned and stochastic attribute representations ensures the consistency between CMS and SR, while simultaneously accommodating arbitrary combinations of input/output modalities and thickness. The generator of Uni-COAL is also designed to be alias-free based on the Shannon-Nyquist signal processing framework, ensuring effective suppression of alias frequencies. Additionally, we leverage the semantic prior of Segment Anything Model (SAM) to guide Uni-COAL, ensuring a more authentic preservation of anatomical structures during synthesis. Experiments on three datasets demonstrate that Uni-COAL outperforms the alternatives in CMS, SR, and CMSR tasks for MR images, which highlights its generalizability to wide-range applications.
</details>
<details>
<summary>摘要</summary>
跨Modalities合成（CMS）、超解像（SR）以及它们的组合（CMSR）在核磁共振成像（MRI）中已经得到了广泛的研究。它们的主要目标是提高成像质量，同时降低slice thickness。尽管这些技术在合成结果方面具有惊人的成果，但它们往往是为特定任务而设计的，因此它们在复杂的临床场景中的适应性受到限制。因此，建立一个通用的网络，可以处理多种图像合成任务，并且可以根据不同的模式和分辨率设置进行调整，这样就可以大幅减少训练和部署模型的资源。然而，现有的工作都不能通过单一的网络来完成CMS、SR和CMSR等任务。此外，这些MRI重建方法经常不当处理假频谱，导致细节的还原不佳。在这篇论文中，我们提出了一种统一的Co-Modulated Alias-free框架（Uni-COAL），用于实现以上任务。图像受控和随机特征表示的协调设计，保证了CMS和SR之间的一致性，同时能够适应任意的输入/输出模式和厚度。Uni-COAL生成器还基于Shannon-Nyquist信号处理框架，确保了假频谱的有效抑制。此外，我们利用Segment Anything Model（SAM）的semantic priors来引导Uni-COAL，确保在合成过程中保留了更加Authentic的结构。实验结果表明，Uni-COAL在CMS、SR和CMSR等任务中表现出色，高于相关方法，这 highlights its generalizability to wide-range applications。
</details></li>
</ul>
<hr>
<h2 id="Improving-Image-Captioning-via-Predicting-Structured-Concepts"><a href="#Improving-Image-Captioning-via-Predicting-Structured-Concepts" class="headerlink" title="Improving Image Captioning via Predicting Structured Concepts"></a>Improving Image Captioning via Predicting Structured Concepts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08223">http://arxiv.org/abs/2311.08223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangting0/SCP-WGCN">https://github.com/wangting0/SCP-WGCN</a></li>
<li>paper_authors: Ting Wang, Weidong Chen, Yuanhe Tian, Yan Song, Zhendong Mao</li>
<li>for: This paper aims to improve image captioning performance by bridging the semantic gap between images and texts using structured concept prediction and weighted graph convolutional networks (W-GCN).</li>
<li>methods: The proposed approach includes a structured concept predictor (SCP) to predict concepts and their structures, as well as W-GCN to depict concept relations driven by word dependencies.</li>
<li>results: The approach is shown to be effective in enhancing the contribution of visual signals in image captioning, and the learned differentiated contributions from concepts improve the description generation process. Extensive experiments demonstrate the effectiveness of the proposed approach and each module.Here’s the Chinese version of the three pieces of information:</li>
<li>for: 这篇论文目的是通过结构化概念预测和Weighted Graph Convolutional Networks (W-GCN)来bridging图像和文本之间的semantic gap，以提高图像描述性能。</li>
<li>methods: 提议的方法包括结构化概念预测器(SCP)来预测概念和其结构，以及基于word dependency的W-GCN来表示概念关系。</li>
<li>results: 方法被证明可以增强图像描述中视觉信号的贡献，并且通过 learned differentiated contributions from concepts来改善描述生成过程。广泛的实验结果证明提议的方法和每个模块的效果。<details>
<summary>Abstract</summary>
Having the difficulty of solving the semantic gap between images and texts for the image captioning task, conventional studies in this area paid some attention to treating semantic concepts as a bridge between the two modalities and improved captioning performance accordingly. Although promising results on concept prediction were obtained, the aforementioned studies normally ignore the relationship among concepts, which relies on not only objects in the image, but also word dependencies in the text, so that offers a considerable potential for improving the process of generating good descriptions. In this paper, we propose a structured concept predictor (SCP) to predict concepts and their structures, then we integrate them into captioning, so as to enhance the contribution of visual signals in this task via concepts and further use their relations to distinguish cross-modal semantics for better description generation. Particularly, we design weighted graph convolutional networks (W-GCN) to depict concept relations driven by word dependencies, and then learns differentiated contributions from these concepts for following decoding process. Therefore, our approach captures potential relations among concepts and discriminatively learns different concepts, so that effectively facilitates image captioning with inherited information across modalities. Extensive experiments and their results demonstrate the effectiveness of our approach as well as each proposed module in this work.
</details>
<details>
<summary>摘要</summary>
在图像描述 зада务中解决semantic gap问题的困难性，传统研究具有一定的注意力于将semantic concept作为两种模态之间的桥梁，从而改进描述性能。虽然在概念预测方面获得了promising的结果，但这些研究通常忽略了概念之间的关系，这些关系不仅取决于图像中的对象，还取决于文本中的word依赖关系，这意味着可以在描述生成过程中提高visuallsignal的贡献。在这篇论文中，我们提出了结构化概念预测器（SCP），用于预测概念和其结构，然后将其集成到描述中，以增强图像描述中visuallsignal的贡献。特别是，我们设计了weighted graph convolutional networks（W-GCN），用于描述概念之间的关系，然后学习这些概念之间的差异性，以便在后续的解码过程中更好地分配权重。因此，我们的方法能够捕捉概念之间的关系，并且强化不同的概念之间的差异性，从而有效地促进图像描述 tasks。广泛的实验和结果证明了我们的方法和每个提议模块的有效性。
</details></li>
</ul>
<hr>
<h2 id="Peer-is-Your-Pillar-A-Data-unbalanced-Conditional-GANs-for-Few-shot-Image-Generation"><a href="#Peer-is-Your-Pillar-A-Data-unbalanced-Conditional-GANs-for-Few-shot-Image-Generation" class="headerlink" title="Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot Image Generation"></a>Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08217">http://arxiv.org/abs/2311.08217</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iceli1007/PIP">https://github.com/iceli1007/PIP</a></li>
<li>paper_authors: Ziqiang Li, Chaoyue Wang, Xue Rui, Chao Xue, Jiaxu Leng, Bin Li<br>for:* 实现几少数例的图像生成，专门为缺乏训练图像的情况。methods:* 融合目标几少数例数据集和对应的同类数据集，实现数据不均匀的条件生成。* 使用组别嵌入法分离类别空间和内生空间，并使用预训练CLIP的方向损失提高图像多样性。results:* 在不同的几少数例数据集上进行实验，提出了一种名为Peer is your Pillar（PIP）的新管道，可以实现几少数例图像生成，并且降低了训练需求。<details>
<summary>Abstract</summary>
Few-shot image generation aims to train generative models using a small number of training images. When there are few images available for training (e.g. 10 images), Learning From Scratch (LFS) methods often generate images that closely resemble the training data while Transfer Learning (TL) methods try to improve performance by leveraging prior knowledge from GANs pre-trained on large-scale datasets. However, current TL methods may not allow for sufficient control over the degree of knowledge preservation from the source model, making them unsuitable for setups where the source and target domains are not closely related. To address this, we propose a novel pipeline called Peer is your Pillar (PIP), which combines a target few-shot dataset with a peer dataset to create a data-unbalanced conditional generation. Our approach includes a class embedding method that separates the class space from the latent space, and we use a direction loss based on pre-trained CLIP to improve image diversity. Experiments on various few-shot datasets demonstrate the advancement of the proposed PIP, especially reduces the training requirements of few-shot image generation.
</details>
<details>
<summary>摘要</summary>
几个干净图像生成目标是训练生成模型使用几个训练图像。当有很少图像可用 для训练（例如10个图像）时，学习从零（LFS）方法通常生成图像与训练数据非常相似，而传输学习（TL）方法尝试通过利用大规模数据集中的先前知识来提高性能。然而，当目标和源领域不相关时，当前的TL方法可能无法保持来自源模型的知识水平，使其不适用。为解决这个问题，我们提议一个新的管道，即同伴是你的柱子（PIP），它将目标几个干净数据集与一个对等数据集组合起来，以创建数据不均衡的条件生成。我们的方法包括一种类嵌入方法，可以分离类空间与潜在空间，并使用预训练的CLIP来提高图像多样性。在各种几个干净数据集上进行了实验，我们发现提案的PIP有显著的进步，特别是减少了几个干净图像生成的训练要求。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-generation-of-Histopathological-Whole-Slide-Images-at-a-Gigapixel-scale"><a href="#Diffusion-based-generation-of-Histopathological-Whole-Slide-Images-at-a-Gigapixel-scale" class="headerlink" title="Diffusion-based generation of Histopathological Whole Slide Images at a Gigapixel scale"></a>Diffusion-based generation of Histopathological Whole Slide Images at a Gigapixel scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08199">http://arxiv.org/abs/2311.08199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Harb, Thomas Pock, Heimo Müller</li>
<li>for: 本研究开发了一种基于扩散的方法，用于生成高分辨率的人类组织学标本数据（Whole Slide Images，WSIs），以增强计算机生物学应用程序的性能。</li>
<li>methods: 本研究使用了一种从粗糙到细节的样本过滤方法，将初始低分辨率的图像逐步升级为高分辨率WSIs。 Specifically, a diffusion model sequentially adds fine details to images and increases their resolution.</li>
<li>results: 在实验中，我们将方法训练使用了TCGA-BRCA数据集。在实验中，我们通过量值评估和用户研究发现，生成的WSIs与真实的标本构造有相似之处。<details>
<summary>Abstract</summary>
We present a novel diffusion-based approach to generate synthetic histopathological Whole Slide Images (WSIs) at an unprecedented gigapixel scale. Synthetic WSIs have many potential applications: They can augment training datasets to enhance the performance of many computational pathology applications. They allow the creation of synthesized copies of datasets that can be shared without violating privacy regulations. Or they can facilitate learning representations of WSIs without requiring data annotations. Despite this variety of applications, no existing deep-learning-based method generates WSIs at their typically high resolutions. Mainly due to the high computational complexity. Therefore, we propose a novel coarse-to-fine sampling scheme to tackle image generation of high-resolution WSIs. In this scheme, we increase the resolution of an initial low-resolution image to a high-resolution WSI. Particularly, a diffusion model sequentially adds fine details to images and increases their resolution. In our experiments, we train our method with WSIs from the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also performed a user study with pathologists. The study results suggest that our generated WSIs resemble the structure of real WSIs.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的扩散基于的方法，用于生成高分辨率整个染色质影像（WSIs）。这些合成WSIs具有许多应用前景：它们可以补充训练集，提高计算生物学应用程序的性能。它们允许创建合成的数据集，无需违反隐私法规。还有，它们可以帮助学习WSIs的表示，无需数据标注。Despite this variety of applications, no existing deep learning-based method generates WSIs at their typically high resolutions. Mainly due to the high computational complexity. Therefore, we propose a novel coarse-to-fine sampling scheme to tackle image generation of high-resolution WSIs. In this scheme, we increase the resolution of an initial low-resolution image to a high-resolution WSI. Particularly, a diffusion model sequentially adds fine details to images and increases their resolution. In our experiments, we train our method with WSIs from the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also performed a user study with pathologists. The study results suggest that our generated WSIs resemble the structure of real WSIs.Here's the word-for-word translation of the text into Simplified Chinese:我们提出了一种新的扩散基于的方法，用于生成高分辨率整个染色质影像（WSIs）。这些合成WSIs具有许多应用前景：它们可以补充训练集，提高计算生物学应用程序的性能。它们允许创建合成的数据集，无需违反隐私法规。还有，它们可以帮助学习WSIs的表示，无需数据标注。Despite this variety of applications, no existing deep learning-based method generates WSIs at their typically high resolutions. Mainly due to the high computational complexity. Therefore, we propose a novel coarse-to-fine sampling scheme to tackle image generation of high-resolution WSIs. In this scheme, we increase the resolution of an initial low-resolution image to a high-resolution WSI. Particularly, a diffusion model sequentially adds fine details to images and increases their resolution. In our experiments, we train our method with WSIs from the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also performed a user study with pathologists. The study results suggest that our generated WSIs resemble the structure of real WSIs.
</details></li>
</ul>
<hr>
<h2 id="LocaliseBot-Multi-view-3D-object-localisation-with-differentiable-rendering-for-robot-grasping"><a href="#LocaliseBot-Multi-view-3D-object-localisation-with-differentiable-rendering-for-robot-grasping" class="headerlink" title="LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping"></a>LocaliseBot: Multi-view 3D object localisation with differentiable rendering for robot grasping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08438">http://arxiv.org/abs/2311.08438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujal Vijayaraghavan, Redwan Alqasemi, Rajiv Dubey, Sudeep Sarkar</li>
<li>for: 本文主要针对对象抓取领域，具体来说是对象pose估计。</li>
<li>methods: 本文使用了多视图对象检测、Camera参数估计和3D CAD模型来实现对象pose估计。一个标准的深度学习底层（FCN ResNet）用于估计对象标签、semantic segmentation和相对于摄像头的对象 pose的course estimate。然后使用一个改进模块来从course pose estimate中进行优化，通过可导渲染来实现。</li>
<li>results: 在ShapeNet dataset上，本文的对象pose估计方法与状态体系比较，显示出提高。此外，通过使用Estimated object pose结果和实际的抓取候选点，在OCID Grasp dataset上计算的抓取精度为99.65%。<details>
<summary>Abstract</summary>
Robot grasp typically follows five stages: object detection, object localisation, object pose estimation, grasp pose estimation, and grasp planning. We focus on object pose estimation. Our approach relies on three pieces of information: multiple views of the object, the camera's extrinsic parameters at those viewpoints, and 3D CAD models of objects. The first step involves a standard deep learning backbone (FCN ResNet) to estimate the object label, semantic segmentation, and a coarse estimate of the object pose with respect to the camera. Our novelty is using a refinement module that starts from the coarse pose estimate and refines it by optimisation through differentiable rendering. This is a purely vision-based approach that avoids the need for other information such as point cloud or depth images. We evaluate our object pose estimation approach on the ShapeNet dataset and show improvements over the state of the art. We also show that the estimated object pose results in 99.65% grasp accuracy with the ground truth grasp candidates on the Object Clutter Indoor Dataset (OCID) Grasp dataset, as computed using standard practice.
</details>
<details>
<summary>摘要</summary>
Robot grasp通常包括五个阶段：对象检测、对象定位、对象姿态估计、抓取姿态估计和抓取规划。我们专注于对象姿态估计。我们的方法基于三个信息：对象的多视图、摄像头的外部参数和3D CAD模型。第一步使用标准的深度学习基础结构（FCN ResNet）来估计对象标签、semantic segmentation和相对于摄像头的粗略对象姿态。我们的创新是使用改进模块，从粗略姿态估计开始，通过微调Rendering来优化。这是一种完全视觉基于的方法，不需要其他信息如点云或深度图像。我们在ShapeNet数据集上评估了我们的对象姿态估计方法，并表明我们的方法在比较准确性方面有所改进。此外，我们还证明我们估计的对象姿态结果和实际的 grasp candidates在OCID Grasp数据集上的抓取精度为99.65%，如标准实践所计算。
</details></li>
</ul>
<hr>
<h2 id="SAMIHS-Adaptation-of-Segment-Anything-Model-for-Intracranial-Hemorrhage-Segmentation"><a href="#SAMIHS-Adaptation-of-Segment-Anything-Model-for-Intracranial-Hemorrhage-Segmentation" class="headerlink" title="SAMIHS: Adaptation of Segment Anything Model for Intracranial Hemorrhage Segmentation"></a>SAMIHS: Adaptation of Segment Anything Model for Intracranial Hemorrhage Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08190">http://arxiv.org/abs/2311.08190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mileswyn/samihs">https://github.com/mileswyn/samihs</a></li>
<li>paper_authors: Yinuo Wang, Kai Chen, Weimin Yuan, Cai Meng, XiangZhi Bai<br>for: 这篇论文是针对stroke诊断和手术规划中的脑出血分类进行研究，使用Segment Anything Model (SAM) 作为基础模型，并提出了一种基于SAM的优化方法（SAMIHS），以提高这些类型的医疗影像分类效能。methods: 这篇论文使用了SAM的图像嵌入器中的参数适束器（parameter-refactoring adapters），并将其视为可变的参数，以提高SAM的灵活性和效能。此外，这篇论文还使用了一种混合损失函数（combo loss），其结合了二进制条件预测损失和边界敏感损失，以提高SAMIHS的边界区域识别能力。results: 根据实验结果，SAMIHS在两个公共数据集上的效能都得到了改善，尤其是在脑出血类型的医疗影像分类中，表明SAMIHS可以提高这些类型的医疗影像分类效能。<details>
<summary>Abstract</summary>
Segment Anything Model (SAM), a vision foundation model trained on large-scale annotations, has recently continued raising awareness within medical image segmentation. Despite the impressive capabilities of SAM on natural scenes, it struggles with performance decline when confronted with medical images, especially those involving blurry boundaries and highly irregular regions of low contrast. In this paper, a SAM-based parameter-efficient fine-tuning method, called SAMIHS, is proposed for intracranial hemorrhage segmentation, which is a crucial and challenging step in stroke diagnosis and surgical planning. Distinguished from previous SAM and SAM-based methods, SAMIHS incorporates parameter-refactoring adapters into SAM's image encoder and considers the efficient and flexible utilization of adapters' parameters. Additionally, we employ a combo loss that combines binary cross-entropy loss and boundary-sensitive loss to enhance SAMIHS's ability to recognize the boundary regions. Our experimental results on two public datasets demonstrate the effectiveness of our proposed method. Code is available at https://github.com/mileswyn/SAMIHS .
</details>
<details>
<summary>摘要</summary>
Segment Anything Model (SAM) 模型，一种基于大规模注释的视觉基础模型，最近在医学图像 segmentation 中受到了更多的关注。尽管 SAM 在自然场景中表现出色，但在医学图像中，它的表现却会逐渐下降，特别是面临着模糊的边界和低对比度的区域。在这篇论文中，我们提出了基于 SAM 的参数效率调整方法，称为 SAMIHS，用于脑出血栓 segmentation，这是诊断和手术规划中的关键步骤。与之前的 SAM 和基于 SAM 的方法不同，SAMIHS 在 SAM 的图像编码器中添加了参数 refactoring 适配器，并且利用这些适配器的参数进行有效和灵活的使用。此外，我们采用了一种 combio 损失函数，该函数将 binary cross-entropy 损失函数和边界敏感损失函数相加，以提高 SAMIHS 对边界区域的识别能力。我们在两个公共数据集上进行了实验，结果表明了我们提出的方法的有效性。代码可以在 GitHub 上找到：https://github.com/mileswyn/SAMIHS。
</details></li>
</ul>
<hr>
<h2 id="A-deformation-based-morphometry-framework-for-disentangling-Alzheimer’s-disease-from-normal-aging-using-learned-normal-aging-templates"><a href="#A-deformation-based-morphometry-framework-for-disentangling-Alzheimer’s-disease-from-normal-aging-using-learned-normal-aging-templates" class="headerlink" title="A deformation-based morphometry framework for disentangling Alzheimer’s disease from normal aging using learned normal aging templates"></a>A deformation-based morphometry framework for disentangling Alzheimer’s disease from normal aging using learned normal aging templates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08176">http://arxiv.org/abs/2311.08176</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fjr9516/dbm_with_dl">https://github.com/fjr9516/dbm_with_dl</a></li>
<li>paper_authors: Jingru Fu, Daniel Ferreira, Örjan Smedby, Rodrigo Moreno</li>
<li>for: 这个研究旨在解决阿尔茨海默症和正常老化是否存在加速的问题，以及在临床上如何分解阿尔茨海默症和正常老化的混合影响。</li>
<li>methods: 该研究使用了深度学习算法创建年龄相关的模板，以便在MRI扫描图像上量化正常老化和阿尔茨海默症相关的衰老模式。然后，使用了 diffeomorphic registration 来估算一年一个CNSubject的正常老化模式，并将测试图像与60岁CNSubject的模板进行对alignment。最后，通过比较这个对alignment与一年正常老化模式的对比，计算出正常老化和阿尔茨海默症特有的分数。</li>
<li>results: 研究结果表明，脑 Ventricles 主要遵循加速的正常老化模式，而 hippocampus 和 Amygdala 区域受到了正常老化和阿尔茨海默症特有的影响。 Interestingly，在疾病早期临床阶段，hippocampus 和 Amygdala 区域更加受到加速的正常老化影响，而疾病后期，阿尔茨海默症特有的分数增加。<details>
<summary>Abstract</summary>
Alzheimer's Disease and normal aging are both characterized by brain atrophy. The question of whether AD-related brain atrophy represents accelerated aging or a neurodegeneration process distinct from that in normal aging remains unresolved. Moreover, precisely disentangling AD-related brain atrophy from normal aging in a clinical context is complex. In this study, we propose a deformation-based morphometry framework to estimate normal aging and AD-specific atrophy patterns of subjects from morphological MRI scans. We first leverage deep-learning-based methods to create age-dependent templates of cognitively normal (CN) subjects. These templates model the normal aging atrophy patterns in a CN population. Then, we use the learned diffeomorphic registration to estimate the one-year normal aging pattern at the voxel level. We register the testing image to the 60-year-old CN template in the second step. Finally, normal aging and AD-specific scores are estimated by measuring the alignment of this registration with the one-year normal aging pattern. The methodology was developed and evaluated on the OASIS3 dataset with 1,014 T1-weighted MRI scans. Of these, 326 scans were from CN subjects, and 688 scans were from individuals clinically diagnosed with AD at different stages of clinical severity defined by clinical dementia rating (CDR) scores. The results show that ventricles predominantly follow an accelerated normal aging pattern in subjects with AD. In turn, hippocampi and amygdala regions were affected by both normal aging and AD-specific factors. Interestingly, hippocampi and amygdala regions showed more of an accelerated normal aging pattern for subjects during the early clinical stages of the disease, while the AD-specific score increases in later clinical stages. Our code is freely available at https://github.com/Fjr9516/DBM_with_DL.
</details>
<details>
<summary>摘要</summary>
阿尔茨海默病和正常年龄都 caracterized by brain atrophy。问题是whether AD-related brain atrophy represents accelerated aging or a neurodegeneration process distinct from that in normal aging remains unresolved。另外，在临床上准确地分离AD-related brain atrophy from normal aging是复杂的。在这种研究中，我们提议一种基于几何变换的 morphometry框架，用于估计在MRI扫描中的正常年龄和AD-specific atrophy模式。我们首先利用深度学习基本的方法创建年龄相关的模板，以模型正常年龄atrophy模式。然后，我们使用学习的射影变换来估计一年内正常年龄的变化模式。最后，我们测量这个注册与一年内正常年龄的变化模式之间的匹配程度，以计算正常年龄和AD-specific scores。方法在OASIS3 dataset上进行了开发和评估，该dataset包括1,014个T1-weighted MRI扫描，其中326个来自正常年龄 subjects，688个来自AD诊断的个体。结果显示，脑室主要follows an accelerated normal aging pattern in subjects with AD。而hippocampus和 Amygdala region受到了正常年龄和AD-specific factor的影响。具有诊断CDR scores的患者在早期клиниче阶段，hippocampus和Amygdala region更加受到加速的正常年龄变化，而AD-specific score在后期 клиниче阶段增加。我们的代码可以在https://github.com/Fjr9516/DBM_with_DL上获取。
</details></li>
</ul>
<hr>
<h2 id="Vision-Language-Instruction-Tuning-A-Review-and-Analysis"><a href="#Vision-Language-Instruction-Tuning-A-Review-and-Analysis" class="headerlink" title="Vision-Language Instruction Tuning: A Review and Analysis"></a>Vision-Language Instruction Tuning: A Review and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08172">http://arxiv.org/abs/2311.08172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/palchenli/vl-instruction-tuning">https://github.com/palchenli/vl-instruction-tuning</a></li>
<li>paper_authors: Chen Li, Yixiao Ge, Dian Li, Ying Shan</li>
<li>for: 这篇论文的目的是探讨大语言模型（LLMs）在多模态数据 incorporation 中的指令调整过程，以提高 LLMS 的指令执行泛化和用户喜好适应能力。</li>
<li>methods: 这篇论文系统地审视了最新的视觉语言指令调整设置和数据集在多模态 LLMs 中，并总结了高质量视觉语言调整数据的特征。</li>
<li>results: 该论文基于 constructed 的指令数据进行了视觉语言指令调整，并在相应的 метриках上进行了广泛的实验，以证明提出的建设原则的合理性。<details>
<summary>Abstract</summary>
Instruction tuning is an essential supervised training phase for Large Language Models (LLMs), with the goal of enhancing LLMs' capacity to generalize instruction execution and adapt to user preferences. With the growing incorporation of multi-modal data into LLMs, there is an increasing interest in the performance of vision-language instruction tuning which presents more complex features in comparison to pure text instructions. In this paper, we systematically review the latest vision-language instruction tuning settings and datasets in multi-modal LLMs and summarize the characteristics that high-quality vision-language tuning data should have. We consider these characteristics as the foundational principles for constructing vision-language instruction data and propose a complete construction pipeline consisting of data collection, instruction generation, and quality control modules that incorporate meticulously designed instruction property evaluation indicators. We perform vision-language instruction tuning on three widely used multi-modal LLMs based on the instruction data we constructed and conduct extensive experiments on the corresponding metrics to demonstrate the rationality of the construction principles proposed in this paper. The code and dataset related to this paper have been open-sourced at \url{https://github.com/palchenli/VL-Instruction-Tuning}.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的指令调整是一个重要的有监督训练阶段，目的是增强LLM的指令执行泛化和用户偏好适应能力。随着多模态数据的加入，视觉语言指令调整的性能已经引起了更多的关注，这种多模态指令调整比纯文本指令更加复杂。在这篇论文中，我们系统地回顾最新的视觉语言指令调整设置和数据集在多模态LLM中，并总结高质量视觉语言调整数据应该具备哪些特征。我们认为这些特征是建构视觉语言指令数据的基础原则，我们提议一个完整的建构管道，包括数据采集、指令生成和质量控制模块，这些模块都包括了仔细设计的指令性质评价指标。我们在三种广泛使用的多模态LLM上进行了视觉语言指令调整，并对相应的指标进行了广泛的实验，以示我们提出的建构原则的合理性。相关代码和数据集可以在 \url{https://github.com/palchenli/VL-Instruction-Tuning} 上下载。
</details></li>
</ul>
<hr>
<h2 id="DynamicSurf-Dynamic-Neural-RGB-D-Surface-Reconstruction-with-an-Optimizable-Feature-Grid"><a href="#DynamicSurf-Dynamic-Neural-RGB-D-Surface-Reconstruction-with-an-Optimizable-Feature-Grid" class="headerlink" title="DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid"></a>DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an Optimizable Feature Grid</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08159">http://arxiv.org/abs/2311.08159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Mirgahney/DynamicSurf.io">https://github.com/Mirgahney/DynamicSurf.io</a></li>
<li>paper_authors: Mirgahney Mohamed, Lourdes Agapito</li>
<li>For: 高精度3D模型化非rigid表面从单视图RGB-D视频中。* Methods: 使用深度、表面法向和RGB损失来提高重建准确性和优化时间。* Results: 比前一代方法快$6\times$，并 achieved comparable results to the state-of-the-art methods。In English:* For: High-fidelity 3D modeling of non-rigid surfaces from monocular RGB-D video.* Methods: Using depth, surface normals, and RGB losses to improve reconstruction accuracy and optimization time.* Results: Faster than previous methods by $6\times$ and achieved comparable results to the state-of-the-art methods.<details>
<summary>Abstract</summary>
We propose DynamicSurf, a model-free neural implicit surface reconstruction method for high-fidelity 3D modelling of non-rigid surfaces from monocular RGB-D video. To cope with the lack of multi-view cues in monocular sequences of deforming surfaces, one of the most challenging settings for 3D reconstruction, DynamicSurf exploits depth, surface normals, and RGB losses to improve reconstruction fidelity and optimisation time. DynamicSurf learns a neural deformation field that maps a canonical representation of the surface geometry to the current frame. We depart from current neural non-rigid surface reconstruction models by designing the canonical representation as a learned feature grid which leads to faster and more accurate surface reconstruction than competing approaches that use a single MLP. We demonstrate DynamicSurf on public datasets and show that it can optimize sequences of varying frames with $6\times$ speedup over pure MLP-based approaches while achieving comparable results to the state-of-the-art methods. Project is available at https://mirgahney.github.io//DynamicSurf.io/.
</details>
<details>
<summary>摘要</summary>
我们提出了DynamicSurf，一种无模型 neural implicit surface reconstruction方法，用于高精度3D模型化非rigid表面从单视角RGB-D视频中。为了处理单视角序列中的形变表面的缺乏多视角cue，DynamicSurf利用深度、表面法向和RGB损失来提高重建准确性和优化时间。DynamicSurf学习一个神经变形场，将一个均匀表面几何代表映射到当前帧中。我们与现有的神经非RIGID表面重建模型不同，我们设计了学习的特征网格作为均匀表面几何代表，这导致了更快和更准确的表面重建。我们在公共数据集上展示了DynamicSurf的性能，并证明它可以在不同的帧序列中优化6倍速度于纯MLP-based方法，而且与状态艺术方法相当。项目可以在https://mirgahney.github.io//DynamicSurf.io/查看。
</details></li>
</ul>
<hr>
<h2 id="Rethink-Cross-Modal-Fusion-in-Weakly-Supervised-Audio-Visual-Video-Parsing"><a href="#Rethink-Cross-Modal-Fusion-in-Weakly-Supervised-Audio-Visual-Video-Parsing" class="headerlink" title="Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video Parsing"></a>Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video Parsing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08151">http://arxiv.org/abs/2311.08151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yating Xu, Conghui Hu, Gim Hee Lee</li>
<li>for: 这篇论文的目的是提出一种新的弱监督音视频分割方法，以解决现有的混合注意力网络（HAN）在融合多Modal embedding时存在聚合不准确的问题。</li>
<li>methods: 该方法使用了一种名为“消息导向中 fusion transformer”的新的嵌入方法，以减少跨Modal不相关的上下文。此外，它还提出了跨音频预测一致性来降低视频预测中不相关的音频信息的影响。</li>
<li>results: 实验表明，该方法在与现有状态的方法进行比较时表现出色，具有更高的准确率和更好的一致性。<details>
<summary>Abstract</summary>
Existing works on weakly-supervised audio-visual video parsing adopt hybrid attention network (HAN) as the multi-modal embedding to capture the cross-modal context. It embeds the audio and visual modalities with a shared network, where the cross-attention is performed at the input. However, such an early fusion method highly entangles the two non-fully correlated modalities and leads to sub-optimal performance in detecting single-modality events. To deal with this problem, we propose the messenger-guided mid-fusion transformer to reduce the uncorrelated cross-modal context in the fusion. The messengers condense the full cross-modal context into a compact representation to only preserve useful cross-modal information. Furthermore, due to the fact that microphones capture audio events from all directions, while cameras only record visual events within a restricted field of view, there is a more frequent occurrence of unaligned cross-modal context from audio for visual event predictions. We thus propose cross-audio prediction consistency to suppress the impact of irrelevant audio information on visual event prediction. Experiments consistently illustrate the superior performance of our framework compared to existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
现有的弱监睹音视频分解方法采用混合注意网络（HAN）作为多modal嵌入，以便捕捉音视模态之间的交叉模态上下文。HAN将音和视模态embedded在共享网络中，并在输入阶段进行交叉注意。然而，这种早期融合方法会高度束缚两个不完全相关的模态，从而降低单模态事件检测的性能。为解决这个问题，我们提出了使者导向中间融合变换器，以减少不相关的交叉模态上下文。使者将全模态上下文压缩到一个紧凑的表示中，只保留有用的交叉模态信息。此外，由于 Microphones 捕捉的音频事件来自所有方向，而 Camera 只记录视频事件在限定的视野内，因此在视频事件预测中更常出现不同模态上下文的不一致。我们因此提出了跨音频预测一致性，以抑制不关联的音频信息对视频事件预测的影响。实验表明，我们的框架在现有状态艺术方法之上具有显著优势。
</details></li>
</ul>
<hr>
<h2 id="GMTR-Graph-Matching-Transformers"><a href="#GMTR-Graph-Matching-Transformers" class="headerlink" title="GMTR: Graph Matching Transformers"></a>GMTR: Graph Matching Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08141">http://arxiv.org/abs/2311.08141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinpei Guo, Shaofeng Zhang, Runzhong Wang, Chang Liu, Junchi Yan</li>
<li>for: 这个论文旨在探讨如何使用视transformer（ViTs）进行视觉匹配，并且提出了一种新的中心裁剪策略和交叉注意机制来提高视觉匹配的敏感性。</li>
<li>methods: 该论文提出了一种名为QueryTrans（Query Transformer）的新方法，该方法使用了交叉注意机制和中心裁剪策略来更好地提取视觉信息。此外，论文还提出了一种基于图注意机制的转化器-based图匹配方法（GMTR），用于解决视觉匹配中的 combinatorial 问题。</li>
<li>results: 根据标准的GM benchmarks，GMTR在对比SOTA框架时显示出竞争力的性能，具体来说，在Pascal VOC上，GMTR的准确率为83.6%，高于SOTA框架的0.9%。在Spair-71k上，GMTR也表现出了优异的性能，并超越了大多数之前的works。此外，QueryTrans在Pascal VOC上提高了NGMv2的准确率从80.1%到83.3%，并提高了BBGM的准确率从79.0%到84.5%。在Spair-71k上，QueryTrans也提高了NGMv2的准确率从80.6%到82.5%，并提高了BBGM的准确率从82.1%到83.9%。<details>
<summary>Abstract</summary>
Vision transformers (ViTs) have recently been used for visual matching beyond object detection and segmentation. However, the original grid dividing strategy of ViTs neglects the spatial information of the keypoints, limiting the sensitivity to local information. Therefore, we propose \textbf{QueryTrans} (Query Transformer), which adopts a cross-attention module and keypoints-based center crop strategy for better spatial information extraction. We further integrate the graph attention module and devise a transformer-based graph matching approach \textbf{GMTR} (Graph Matching TRansformers) whereby the combinatorial nature of GM is addressed by a graph transformer neural GM solver. On standard GM benchmarks, GMTR shows competitive performance against the SOTA frameworks. Specifically, on Pascal VOC, GMTR achieves $\mathbf{83.6\%}$ accuracy, $\mathbf{0.9\%}$ higher than the SOTA framework. On Spair-71k, GMTR shows great potential and outperforms most of the previous works. Meanwhile, on Pascal VOC, QueryTrans improves the accuracy of NGMv2 from $80.1\%$ to $\mathbf{83.3\%}$, and BBGM from $79.0\%$ to $\mathbf{84.5\%}$. On Spair-71k, QueryTrans improves NGMv2 from $80.6\%$ to $\mathbf{82.5\%}$, and BBGM from $82.1\%$ to $\mathbf{83.9\%}$. Source code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
《视觉转换器（ViT）在视觉匹配中的应用》。在原始的网格分割策略下，ViT忽视了关键点的空间信息，导致对本地信息的敏感性受限。因此，我们提出了《查询转换器》（QueryTrans），它采用了交叉注意模块和基于关键点的中心裁剪策略，以更好地提取空间信息。此外，我们还整合了图注意模块，并设计了基于图transformer的图匹配方法《图匹配变换器》（GMTR），以解决图匹配问题的 combinatorial 性。在标准GM benchmark上，GMTR与顶尖框架相比，表现竞争力强。具体来说，在Pascal VOC上，GMTR的准确率为83.6%，高于顶尖框架80.1%。在Spair-71k上，GMTR表现出色，超过了大多数之前的工作。同时，在Pascal VOC上，QueryTrans提高了NGMv2的准确率从80.1%到83.3%，和BBGM从79.0%到84.5%。在Spair-71k上，QueryTrans提高了NGMv2的准确率从80.6%到82.5%，和BBGM从82.1%到83.9%。源代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Learning-based-Deep-Disentangling-Light-Field-Reconstruction-and-Disparity-Estimation-Application"><a href="#Learning-based-Deep-Disentangling-Light-Field-Reconstruction-and-Disparity-Estimation-Application" class="headerlink" title="Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application"></a>Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08129">http://arxiv.org/abs/2311.08129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Langqing Shi, Ping Zhou</li>
<li>for: 提高深度估计任务中的angular分辨率，并解决大 disparity在稀有光场中的挑战。</li>
<li>methods: 提出了深度分离机制，将4D光场转换为2D图像格式，且采用了进一步的特征提取器设计和高级网络结构。</li>
<li>results: 实现了最佳性能在实验中，并提出了减少内存占用的块跨度angular超解析策略，用于深度估计增强。<details>
<summary>Abstract</summary>
Light field cameras have a wide range of uses due to their ability to simultaneously record light intensity and direction. The angular resolution of light fields is important for downstream tasks such as depth estimation, yet is often difficult to improve due to hardware limitations. Conventional methods tend to perform poorly against the challenge of large disparity in sparse light fields, while general CNNs have difficulty extracting spatial and angular features coupled together in 4D light fields. The light field disentangling mechanism transforms the 4D light field into 2D image format, which is more favorable for CNN for feature extraction. In this paper, we propose a Deep Disentangling Mechanism, which inherits the principle of the light field disentangling mechanism and further develops the design of the feature extractor and adds advanced network structure. We design a light-field reconstruction network (i.e., DDASR) on the basis of the Deep Disentangling Mechanism, and achieve SOTA performance in the experiments. In addition, we design a Block Traversal Angular Super-Resolution Strategy for the practical application of depth estimation enhancement where the input views is often higher than 2x2 in the experiments resulting in a high memory usage, which can reduce the memory usage while having a better reconstruction performance.
</details>
<details>
<summary>摘要</summary>
光场相机具有广泛的应用领域，主要是因为它同时记录光强和方向。光场的方向分辨率对下游任务如深度估计非常重要，但受硬件限制，通常难以提高。传统方法在大 disparity  sparse 光场中表现不佳，而通用 CNN 在4D 光场中抽取空间和方向特征同时存在困难。基于光场分解机制，我们提出了深度分解机制，将4D 光场转换成2D 图像格式，更适合 CNN 进行特征提取。在这篇论文中，我们提出了一种深度分解机制，具有光场分解机制的原理，并进一步开发特征提取器的设计和高级网络结构。基于深度分解机制，我们设计了一个深度场重建网络（i.e., DDASR），在实验中达到了最佳性能。此外，我们还设计了一种块传播角度超解析策略，用于实际应用深度估计增强，其中输入视图 часто高于2x2，导致高内存使用量，可以降低内存使用量而且具有更好的重建性能。
</details></li>
</ul>
<hr>
<h2 id="DeepEMplanner-An-EM-Motion-Planner-with-Iterative-Interactions"><a href="#DeepEMplanner-An-EM-Motion-Planner-with-Iterative-Interactions" class="headerlink" title="DeepEMplanner: An EM Motion Planner with Iterative Interactions"></a>DeepEMplanner: An EM Motion Planner with Iterative Interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08100">http://arxiv.org/abs/2311.08100</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili Chen, Maosheng Ye, Shuangjie Xu, Tongyi Cao, Qifeng Chen</li>
<li>for: 本研究旨在提出一种基于深度学习的动态规划和互动模型，以便更好地学习细腻的行为。</li>
<li>methods: 我们提出了一种名为DeepEMplanner的新框架，它在每个步骤交互中考虑了各自的行为目标，以便更好地学习和预测对手和环境的行为。</li>
<li>results: 在nuScenesbenchmark上进行了实验，我们的方法实现了状态的最佳Results。<details>
<summary>Abstract</summary>
Motion planning is a computational problem that finds a sequence of valid trajectories, often based on surrounding agents' forecasting, environmental understanding, and historical and future contexts. It can also be viewed as a game in which agents continuously plan their next move according to other agents' intentions and the encountering environment, further achieving their ultimate goals through incremental actions. To model the dynamic planning and interaction process, we propose a novel framework, DeepEMplanner, which takes the stepwise interaction into account for fine-grained behavior learning. The ego vehicle maximizes each step motion to reach its eventual driving outcome based on the stepwise expectation from agents and its upcoming road conditions. On the other hand, the agents also follow the same philosophy to maximize their stepwise behavior under the encountering environment and the expectations from ego and other agents. Our DeepEMplanner models the interactions among ego, agents, and the dynamic environment in an autoregressive manner by interleaving the Expectation and Maximization processes. Further, we design ego-to-agents, ego-to-map, and ego-to-BEV interaction mechanisms with hierarchical dynamic key objects attention to better model the interactions. Experiments on the nuScenes benchmark show that our approach achieves state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
行为规划是一个计算问题，找到一系列有效的轨迹，经常基于周围的代理人预测、环境理解和历史和未来的上下文。它也可以视为一个游戏，在 które agents 不断规划下一步的动作，根据其他代理人的意图和遇到的环境，以实现他们的最终目标。为了模型动态规划和互动过程，我们提出了一个新的框架，深度EMplanner，它考虑了每个步骤的互动，以提高细化的行为学习。ego Vehicle 在每步动作中尽可能地实现其最终驾驶结果，基于预测的代理人和下一步道路条件。然而，代理人也遵循同样的哲学，在遇到的环境和预测中 maximize 其每步行为。我们的 DeepEMplanner 模型了 egO、代理人和动态环境之间的互动，通过嵌入 Expectation 和 Maximization 过程来模型这些互动。此外，我们还设计了 ego-to-agents、ego-to-map 和 ego-to-BEV 互动机制，并使用层次的动态关键对象注意力来更好地模型这些互动。在 nuScenes  benchmark 上进行了实验，我们的方法实现了状态计算的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Light-curve-Signals-with-a-Deep-Learning-Based-Object-Detection-Algorithm-II-A-General-Light-Curve-Classification-Framework"><a href="#Identifying-Light-curve-Signals-with-a-Deep-Learning-Based-Object-Detection-Algorithm-II-A-General-Light-Curve-Classification-Framework" class="headerlink" title="Identifying Light-curve Signals with a Deep Learning Based Object Detection Algorithm. II. A General Light Curve Classification Framework"></a>Identifying Light-curve Signals with a Deep Learning Based Object Detection Algorithm. II. A General Light Curve Classification Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08080">http://arxiv.org/abs/2311.08080</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ckm3/deep-lc">https://github.com/ckm3/deep-lc</a></li>
<li>paper_authors: Kaiming Cui, D. J. Armstrong, Fabo Feng</li>
<li>for: 这个研究的目的是发展一个通用的深度学习框架，用于自动分类天文学摄谱资料中的变星和其他物类。</li>
<li>methods: 这个框架使用了一种弱地监督物件检测模型，自动选择时间和频率领域中的最佳窗口，并将资料自动抽象为时间和频率领域之间的特征。</li>
<li>results: 这个模型在变星和噪音测量资料上取得了87%的准确率，与先前的特征基于模型相比。此外，这个模型还可以直接应用于其他任务，如ASAS-SN， без需要任何重新训练或调整。<details>
<summary>Abstract</summary>
Vast amounts of astronomical photometric data are generated from various projects, requiring significant efforts to identify variable stars and other object classes. In light of this, a general, widely applicable classification framework would simplify the task of designing custom classifiers. We present a novel deep learning framework for classifying light curves using a weakly supervised object detection model. Our framework identifies the optimal windows for both light curves and power spectra automatically, and zooms in on their corresponding data. This allows for automatic feature extraction from both time and frequency domains, enabling our model to handle data across different scales and sampling intervals. We train our model on datasets obtained from both space-based and ground-based multi-band observations of variable stars and transients. We achieve an accuracy of 87% for combined variables and transient events, which is comparable to the performance of previous feature-based models. Our trained model can be utilized directly to other missions, such as ASAS-SN, without requiring any retraining or fine-tuning. To address known issues with miscalibrated predictive probabilities, we apply conformal prediction to generate robust predictive sets that guarantee true label coverage with a given probability. Additionally, we incorporate various anomaly detection algorithms to empower our model with the ability to identify out-of-distribution objects. Our framework is implemented in the Deep-LC toolkit, which is an open-source Python package hosted on Github and PyPI.
</details>
<details>
<summary>摘要</summary>
巨量的天文光度数据由多个项目生成，需要大量的努力来识别变星和其他对象类型。为了简化这个任务，我们提出了一种通用的深度学习分类框架。我们的框架使用弱监督对象检测模型来分类光谱曲线。我们的框架可以自动确定光谱曲线和功率спектrum的优化窗口，并在这些窗口中提取数据。这使得我们的模型能够处理不同的时间和频率尺度，并且不需要手动设置窗口大小。我们的模型通过对多个变星和事件进行训练，实现了87%的总精度，与之前基于特征的模型相当。我们的训练模型可以直接应用于其他任务，如ASAS-SN，无需重新训练或调整。为了解决已知的预测概率误差，我们使用封闭预测来生成可靠的预测集， garantía true label coverage  WITH a given probability。此外，我们还 incorporated 多种异常检测算法，使我们的模型能够识别不符合预期的对象。我们的框架在 Deep-LC 工具包中实现，该工具包是一个开源的 Python 包， hosted on Github 和 PyPI。
</details></li>
</ul>
<hr>
<h2 id="GlanceSeg-Real-time-microaneurysm-lesion-segmentation-with-gaze-map-guided-foundation-model-for-early-detection-of-diabetic-retinopathy"><a href="#GlanceSeg-Real-time-microaneurysm-lesion-segmentation-with-gaze-map-guided-foundation-model-for-early-detection-of-diabetic-retinopathy" class="headerlink" title="GlanceSeg: Real-time microaneurysm lesion segmentation with gaze-map-guided foundation model for early detection of diabetic retinopathy"></a>GlanceSeg: Real-time microaneurysm lesion segmentation with gaze-map-guided foundation model for early detection of diabetic retinopathy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08075">http://arxiv.org/abs/2311.08075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyang Jiang, Mengdi Gao, Zirong Liu, Chen Tang, Xiaoqing Zhang, Shuai Jiang, Wu Yuan, Jiang Liu</li>
<li>for: 这个研究旨在提出一个基于“Segment Anything Model”（SAM）的人工智能支持的早期视力疾病诊断框架，以帮助诊断早期视力疾病中的微小血管变化。</li>
<li>methods: 这个框架使用了人工智能技术，包括眼镜视野映射和精确性检查，以帮助诊断早期视力疾病中的微小血管变化。</li>
<li>results: 这个研究显示了一个名为“GlanceSeg”的人工智能框架，可以帮助诊断早期视力疾病中的微小血管变化，并且可以提高诊断效率和准确性。<details>
<summary>Abstract</summary>
Early-stage diabetic retinopathy (DR) presents challenges in clinical diagnosis due to inconspicuous and minute microangioma lesions, resulting in limited research in this area. Additionally, the potential of emerging foundation models, such as the segment anything model (SAM), in medical scenarios remains rarely explored. In this work, we propose a human-in-the-loop, label-free early DR diagnosis framework called GlanceSeg, based on SAM. GlanceSeg enables real-time segmentation of microangioma lesions as ophthalmologists review fundus images. Our human-in-the-loop framework integrates the ophthalmologist's gaze map, allowing for rough localization of minute lesions in fundus images. Subsequently, a saliency map is generated based on the located region of interest, which provides prompt points to assist the foundation model in efficiently segmenting microangioma lesions. Finally, a domain knowledge filter refines the segmentation of minute lesions. We conducted experiments on two newly-built public datasets, i.e., IDRiD and Retinal-Lesions, and validated the feasibility and superiority of GlanceSeg through visualized illustrations and quantitative measures. Additionally, we demonstrated that GlanceSeg improves annotation efficiency for clinicians and enhances segmentation performance through fine-tuning using annotations. This study highlights the potential of GlanceSeg-based annotations for self-model optimization, leading to enduring performance advancements through continual learning.
</details>
<details>
<summary>摘要</summary>
早期 диабетическая ретинопатия (DR) 的临床诊断受到微型抽象病变的难以诊断的挑战，这导致了这个领域的研究受到限制。此外，现有的基础模型，如 segment anything model (SAM)，在医疗场景中的应用尚未得到广泛探索。在这项工作中，我们提出了一种人类在Loop的、无标签的早期 DR 诊断框架，称为 GlanceSeg，基于 SAM。GlanceSeg 可以在眼科医生查看基底图像时实时分割微型病变。我们的人类在Loop 框架将眼科医生的视线地图与基底图像进行结合，以便粗略地位微型病变。然后，基于所处的区域兴趣点的敏感地图会生成，以提供帮助基础模型快速分割微型病变的指导点。最后，基于区域的知识滤波器会对微型病变进行精细分割。我们在两个新建的公共数据集上进行了实验，即 IDRiD 和 Retinal-Lesions，并通过视觉化示例和量化度量证明了 GlanceSeg 的可行性和超越性。此外，我们还示出了 GlanceSeg 可以提高临床医生的注意力和分割性能，通过细化使用注解进行训练。这种研究强调了 GlanceSeg 基于注解的自适应优化的潜在可能，这将导致持续学习的性能提升。
</details></li>
</ul>
<hr>
<h2 id="FS-Net-Full-Scale-Network-and-Adaptive-Threshold-for-Improving-Extraction-of-Micro-Retinal-Vessel-Structures"><a href="#FS-Net-Full-Scale-Network-and-Adaptive-Threshold-for-Improving-Extraction-of-Micro-Retinal-Vessel-Structures" class="headerlink" title="FS-Net: Full Scale Network and Adaptive Threshold for Improving Extraction of Micro-Retinal Vessel Structures"></a>FS-Net: Full Scale Network and Adaptive Threshold for Improving Extraction of Micro-Retinal Vessel Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08059">http://arxiv.org/abs/2311.08059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Melaku N. Getahun, Oleg Y. Rogov, Dmitry V. Dylov, Andrey Somov, Ahmed Bouridane, Rifat Hamoudi<br>for: 这个研究旨在帮助验视医生为某些眼病进行诊断和检测，减轻验视医生的工作负担。methods: 这个研究使用了一个基于encoder-decoder神经网络架构的全规模微血管提取机制，以及sigmoid平滑和适应阈值方法。results: 这个研究在DRIVE、CHASE-DB1和STARE datasets上进行了评估，与之前的研究相比，获得了比较出色的成绩，其中在DRIVEdataset上的AUC和准确率分别为0.9884和0.9702，在CHASE-DB1dataset上的 scores分别为0.9903和0.9755，在STAREdataset上的 scores分别为0.9916和0.9750。这些成绩较之前的研究一步进步，使得这个解决方案在实际检测中有更高的可能性被应用。<details>
<summary>Abstract</summary>
Retinal vascular segmentation, is a widely researched subject in biomedical image processing, aims to relieve ophthalmologists' workload when treating and detecting retinal disorders. However, segmenting retinal vessels has its own set of challenges, with prior techniques failing to generate adequate results when segmenting branches and microvascular structures. The neural network approaches used recently are characterized by the inability to keep local and global properties together and the failure to capture tiny end vessels make it challenging to attain the desired result. To reduce this retinal vessel segmentation problem, we propose a full-scale micro-vessel extraction mechanism based on an encoder-decoder neural network architecture, sigmoid smoothing, and an adaptive threshold method. The network consists of of residual, encoder booster, bottleneck enhancement, squeeze, and excitation building blocks. All of these blocks together help to improve the feature extraction and prediction of the segmentation map. The proposed solution has been evaluated using the DRIVE, CHASE-DB1, and STARE datasets, and competitive results are obtained when compared with previous studies. The AUC and accuracy on the DRIVE dataset are 0.9884 and 0.9702, respectively. On the CHASE-DB1 dataset, the scores are 0.9903 and 0.9755, respectively. On the STARE dataset, the scores are 0.9916 and 0.9750, respectively. The performance achieved is one step ahead of what has been done in previous studies, and this results in a higher chance of having this solution in real-life diagnostic centers that seek ophthalmologists attention.
</details>
<details>
<summary>摘要</summary>
Retinal vascular segmentation 是医学图像处理领域广泛研究的主题，旨在减轻眼科医生在诊断和治疗 RETINAL 疾病时的劳重。然而， segmenting retinal vessels 有其独特的挑战，先前的技术无法生成足够的结果，特别是在分支和微血管结构上。近年来的神经网络方法具有不能同时保持本地和全局属性以及失去微血管结构的缺点，使得 segmentation 问题变得更加困难。为解决这个问题，我们提出了基于 encoder-decoder 神经网络架构、sigmoid 缓和适应阈值方法的全规模微血管提取机制。该网络由 residual、encoder booster、瓶颈增强、缩小和刺激块组成。这些块都帮助提高特征提取和预测 segmentation 图像。我们对 DRIVE、CHASE-DB1 和 STARE 数据集进行评估，与前期研究相比，实现了竞争性的结果。 DRIVE 数据集上的 AUC 和精度分别为 0.9884 和 0.9702，CHASE-DB1 数据集上的分别为 0.9903 和 0.9755，STARE 数据集上的分别为 0.9916 和 0.9750。我们的成果胜过了前期研究，这将有助于这种解决方案在实际诊断中心得到应用。
</details></li>
</ul>
<hr>
<h2 id="Chat-UniVi-Unified-Visual-Representation-Empowers-Large-Language-Models-with-Image-and-Video-Understanding"><a href="#Chat-UniVi-Unified-Visual-Representation-Empowers-Large-Language-Models-with-Image-and-Video-Understanding" class="headerlink" title="Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding"></a>Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08046">http://arxiv.org/abs/2311.08046</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pku-yuangroup/chat-univi">https://github.com/pku-yuangroup/chat-univi</a></li>
<li>paper_authors: Peng Jin, Ryuichi Takanobu, Caiwan Zhang, Xiaochun Cao, Li Yuan</li>
<li>for: 这个论文的目的是解决图像和视频理解的问题，并能够在有限的视觉token上进行有效的对话。</li>
<li>methods: 这个论文使用了一种动态的视觉代表方法，可以同时捕捉图像和视频中的空间细节和时间关系。此外，它还使用了多尺度表示方法，使模型能够捕捉高级别的Semantic概念和低级别的视觉细节。</li>
<li>results: 实验结果表明，Chat-UniVi模型在混合 dataset上进行训练后，能够在图像和视频任务中表现出色，并且在图像和视频任务中的性能都高于专门为图像或视频设计的方法。<details>
<summary>Abstract</summary>
Large language models have demonstrated impressive universal capabilities across a wide range of open-ended tasks and have extended their utility to encompass multimodal conversations. However, existing methods encounter challenges in effectively handling both image and video understanding, particularly with limited visual tokens. In this work, we introduce Chat-UniVi, a unified vision-language model capable of comprehending and engaging in conversations involving images and videos through a unified visual representation. Specifically, we employ a set of dynamic visual tokens to uniformly represent images and videos. This representation framework empowers the model to efficiently utilize a limited number of visual tokens to simultaneously capture the spatial details necessary for images and the comprehensive temporal relationship required for videos. Moreover, we leverage a multi-scale representation, enabling the model to perceive both high-level semantic concepts and low-level visual details. Notably, Chat-UniVi is trained on a mixed dataset containing both images and videos, allowing direct application to tasks involving both mediums without requiring any modifications. Extensive experimental results demonstrate that Chat-UniVi, as a unified model, consistently outperforms even existing methods exclusively designed for either images or videos.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:大型语言模型已经展示了广泛的通用能力，并扩展了其应用范围到包括多modal会话。然而，现有方法在处理图像和视频理解方面遇到了挑战，特别是具有有限的视觉标识符。在这种情况下，我们引入了 Chat-UniVi，一种能够同时理解和参与图像和视频的沟通的统一视觉语言模型。具体来说，我们使用了一组动态的视觉标识符来统一表示图像和视频。这种表示框架使得模型可以有效地利用有限的视觉标识符来同时捕捉图像中的空间细节和视频中的全面时间关系。此外，我们还利用了多尺度表示，让模型能够捕捉高级 semantic概念以及低级视觉细节。值得一提的是，Chat-UniVi 是在包含图像和视频的混合 Dataset 上训练的，因此不需要任何修改就能直接应用于包含这两种媒体的任务。我们的实验结果表明，Chat-UniVi 作为一种统一模型，在与专门为图像或视频设计的方法进行比较时，一直表现出优于其。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Multi-Object-Tracking-with-Transformers"><a href="#Contrastive-Learning-for-Multi-Object-Tracking-with-Transformers" class="headerlink" title="Contrastive Learning for Multi-Object Tracking with Transformers"></a>Contrastive Learning for Multi-Object Tracking with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08043">http://arxiv.org/abs/2311.08043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre-François De Plaen, Nicola Marinello, Marc Proesmans, Tinne Tuytelaars, Luc Van Gool</li>
<li>for: 这个研究旨在将物件探测变换为一个翻译任务，从图像特征中获取物件水平的表现。</li>
<li>methods: 我们使用了一个实验级别的对称损失函数、一种修订的抽象策略和轻量级的对称分配方法来转换DETR模型为多物件追踪（MOT）模型。</li>
<li>results: 我们的训练方案可以学习物件的外观，同时保持探测能力，仅需小量的额外负载。在BDD100K dataset上，我们的表现超过了过往的最佳性能+2.6 mMOTA，与现有的对称基于方法在MOT17 dataset上的表现相似。<details>
<summary>Abstract</summary>
The DEtection TRansformer (DETR) opened new possibilities for object detection by modeling it as a translation task: converting image features into object-level representations. Previous works typically add expensive modules to DETR to perform Multi-Object Tracking (MOT), resulting in more complicated architectures. We instead show how DETR can be turned into a MOT model by employing an instance-level contrastive loss, a revised sampling strategy and a lightweight assignment method. Our training scheme learns object appearances while preserving detection capabilities and with little overhead. Its performance surpasses the previous state-of-the-art by +2.6 mMOTA on the challenging BDD100K dataset and is comparable to existing transformer-based methods on the MOT17 dataset.
</details>
<details>
<summary>摘要</summary>
“DEtection TRansformer（DETR）开创了新的可能性，将对象探测视为翻译任务：将图像特征转换为对象级别表示。先前的工作通常会添加费时模块到DETR来实现多对象跟踪（MOT），导致建立更加复杂的架构。我们则示出了如何将DETR转换成MOT模型，使用实例级别的对比损失，修改抽取策略和轻量级的归属方法。我们的训练方案学习对象外观，保留探测能力，占用较少的资源。其性能在具有挑战性的BDD100K数据集上超过了之前的州态艺术的+2.6 mMOTA，与现有的转换基本方法在MOT17数据集上的性能相当。”
</details></li>
</ul>
<hr>
<h2 id="ELF-An-End-to-end-Local-and-Global-Multimodal-Fusion-Framework-for-Glaucoma-Grading"><a href="#ELF-An-End-to-end-Local-and-Global-Multimodal-Fusion-Framework-for-Glaucoma-Grading" class="headerlink" title="ELF: An End-to-end Local and Global Multimodal Fusion Framework for Glaucoma Grading"></a>ELF: An End-to-end Local and Global Multimodal Fusion Framework for Glaucoma Grading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08032">http://arxiv.org/abs/2311.08032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenyun Li, Chi-Man Pun</li>
<li>for: 针对睫际病变患者进行早期检测和治疗，以防病情加重。</li>
<li>methods: 基于2D睫际图像和光度共谱成像(OCT)技术，提出一种综合利用多Modal信息的睫际病变评估框架，名为ELF。ELF可以充分利用睫际图像和OCT数据之间的补偿信息。</li>
<li>results: 在多modal睫际病变评估GAMMA dataset上进行了广泛的实验，并证明ELF在比较其他状态艺术方法时表现更高效。<details>
<summary>Abstract</summary>
Glaucoma is a chronic neurodegenerative condition that can lead to blindness. Early detection and curing are very important in stopping the disease from getting worse for glaucoma patients. The 2D fundus images and optical coherence tomography(OCT) are useful for ophthalmologists in diagnosing glaucoma. There are many methods based on the fundus images or 3D OCT volumes; however, the mining for multi-modality, including both fundus images and data, is less studied. In this work, we propose an end-to-end local and global multi-modal fusion framework for glaucoma grading, named ELF for short. ELF can fully utilize the complementary information between fundus and OCT. In addition, unlike previous methods that concatenate the multi-modal features together, which lack exploring the mutual information between different modalities, ELF can take advantage of local-wise and global-wise mutual information. The extensive experiment conducted on the multi-modal glaucoma grading GAMMA dataset can prove the effiectness of ELF when compared with other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
glaucoma 是一种慢性神经退化疾病，可能导致失明。早期发现和治疗非常重要，以防疫情进一步加剧。二维基准图像和光共振镜(OCT) 是诊断 glaucoma 的有用工具。多种基于基准图像或3D OCT 体积的方法已经研究过，但是对于多Modal 数据的挖掘还是相对较少。在这种情况下，我们提出了一种综合使用本地和全局多Modal 融合框架，名为ELF。ELF 可以充分利用基准图像和 OCT 之间的补偿信息。此外，与之前的方法不同的是，ELF 可以利用本地和全局多Modal 信息之间的相互关系，而不是将多Modal 特征 concatenate 在一起。经过了对多modal 疾病评分 GAMMA 数据集的广泛实验，ELF 的效果可以证明在与其他现有方法相比，效果更好。
</details></li>
</ul>
<hr>
<h2 id="MD-IQA-Learning-Multi-scale-Distributed-Image-Quality-Assessment-with-Semi-Supervised-Learning-for-Low-Dose-CT"><a href="#MD-IQA-Learning-Multi-scale-Distributed-Image-Quality-Assessment-with-Semi-Supervised-Learning-for-Low-Dose-CT" class="headerlink" title="MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with Semi Supervised Learning for Low Dose CT"></a>MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with Semi Supervised Learning for Low Dose CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08024">http://arxiv.org/abs/2311.08024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Song, Ruizhi Hou, Lisong Dai, Lei Xiang<br>for: 这个研究旨在提高深度学习基于医学影像评估（IQA）的模型通用性和感知准确性。methods: 该研究提出了一种多级分布回归方法，通过制约输出分布来提高模型通用性。此外，我们还设计了一个双树对齐网络来增强特征提取能力。最后，我们引入了半监督学习，使用 pseudo-标签来导引模型训练。results: 我们的提议方法在大规模实验中得到了广泛的可读性和稳定性。我们的方法可以在医学影像评估中提高模型的通用性和感知准确性。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/zunzhumu/MD-IQA%E3%80%82">https://github.com/zunzhumu/MD-IQA。</a><details>
<summary>Abstract</summary>
Image quality assessment (IQA) plays a critical role in optimizing radiation dose and developing novel medical imaging techniques in computed tomography (CT). Traditional IQA methods relying on hand-crafted features have limitations in summarizing the subjective perceptual experience of image quality. Recent deep learning-based approaches have demonstrated strong modeling capabilities and potential for medical IQA, but challenges remain regarding model generalization and perceptual accuracy. In this work, we propose a multi-scale distributions regression approach to predict quality scores by constraining the output distribution, thereby improving model generalization. Furthermore, we design a dual-branch alignment network to enhance feature extraction capabilities. Additionally, semi-supervised learning is introduced by utilizing pseudo-labels for unlabeled data to guide model training. Extensive qualitative experiments demonstrate the effectiveness of our proposed method for advancing the state-of-the-art in deep learning-based medical IQA. Code is available at: https://github.com/zunzhumu/MD-IQA.
</details>
<details>
<summary>摘要</summary>
医用像质评估（IQA）在计算机Tomography（CT）中扮演了关键的角色， optimize radiation dose和开发新的医疗成像技术。传统的IQA方法，取决于手工设计的特征，有限的概念化Subjective perceived image quality的经验。 current deep learning-based approaches have shown strong modeling capabilities and potential for medical IQA, but there are still challenges in terms of model generalization and perceptual accuracy. 在这项工作中，我们提议一种多尺度分布回归方法，预测质分数，并通过限制输出分布，提高模型泛化性。此外，我们设计了双树对齐网络，提高特征提取能力。此外，我们还利用 pseudo-labels 进行 semi-supervised learning，以帮助模型训练。我们的提议方法在 deep learning-based 医疗IQA 领域中具有广泛的可靠性和稳定性。 Code 可以在以下 GitHub 上获取：https://github.com/zunzhumu/MD-IQA.
</details></li>
</ul>
<hr>
<h2 id="CP-SLAM-Collaborative-Neural-Point-based-SLAM-System"><a href="#CP-SLAM-Collaborative-Neural-Point-based-SLAM-System" class="headerlink" title="CP-SLAM: Collaborative Neural Point-based SLAM System"></a>CP-SLAM: Collaborative Neural Point-based SLAM System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08013">http://arxiv.org/abs/2311.08013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiarui Hu, Mao Mao, Hujun Bao, Guofeng Zhang, Zhaopeng Cui</li>
<li>for: 这个论文描述了一种基于RGB-D图像序列的协同隐藏神经同时地图（SLAM）系统，包括完整的前端和后端模块，如偏移、循环检测、子地图融合和全局精度调整。</li>
<li>methods: 作者提出了一种新的神经点基于3D场景表示方法，每个点都有一个学习的神经特征用于场景编码，并与特定的关键帧相关。此外，作者还提出了一种分布式到中心式学习策略来提高协同隐藏SLAM的一致性和合作。</li>
<li>results: 实验结果表明，提出的方法在不同的数据集上都有较高的精度和稳定性，在摄像头跟踪和地图建模方面均有显著提高。<details>
<summary>Abstract</summary>
This paper presents a collaborative implicit neural simultaneous localization and mapping (SLAM) system with RGB-D image sequences, which consists of complete front-end and back-end modules including odometry, loop detection, sub-map fusion, and global refinement. In order to enable all these modules in a unified framework, we propose a novel neural point based 3D scene representation in which each point maintains a learnable neural feature for scene encoding and is associated with a certain keyframe. Moreover, a distributed-to-centralized learning strategy is proposed for the collaborative implicit SLAM to improve consistency and cooperation. A novel global optimization framework is also proposed to improve the system accuracy like traditional bundle adjustment. Experiments on various datasets demonstrate the superiority of the proposed method in both camera tracking and mapping.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种基于RGB-D图像序列的协同隐式神经同时地图（SLAM）系统，包括完整的前端和后端模块，如偏移、循环检测、子地图融合和全局调整。为了在一个统一框架中实现这些模块，我们提出了一种新的神经点基于3D场景表示，其中每个点都保留一个学习的神经特征 для场景编码，并与某个键帧相关。此外，我们还提出了分布式到中心学习策略来提高协同隐式SLAM的一致性和合作性。此外，我们还提出了一种新的全局优化框架来提高系统精度，类似于传统的缎纹调整。在多个数据集上进行了诸多实验，并证明了我们的方法在摄像头跟踪和地图建模方面具有显著优势。
</details></li>
</ul>
<hr>
<h2 id="Clearer-Frames-Anytime-Resolving-Velocity-Ambiguity-in-Video-Frame-Interpolation"><a href="#Clearer-Frames-Anytime-Resolving-Velocity-Ambiguity-in-Video-Frame-Interpolation" class="headerlink" title="Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation"></a>Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08007">http://arxiv.org/abs/2311.08007</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zzh-tech/interpany-clearer">https://github.com/zzh-tech/interpany-clearer</a></li>
<li>paper_authors: Zhihang Zhong, Gurunandan Krishnan, Xiao Sun, Yu Qiao, Sizhuo Ma, Jian Wang</li>
<li>for: 提高视频帧 interpolate（VFI）方法的精度和清晰度，尤其是对于具有较长距离和弯曲运动的对象。</li>
<li>methods: 使用一种新的“距离索引”方法，即提供网络中的明确提示，以帮助网络学习对象在不同时间步的位置。此外，还提出了一种循环引用基本估计策略，以解决长距离预测中的方向ambiguity问题。</li>
<li>results: 与传统VFI方法相比，使用“距离索引”和循环引用基本估计策略可以提高视频帧 interpolate的精度和清晰度，并且可以独立地调整视频的时间 interpolate。此外，“距离索引”还可以在每帧级进行独立的时间修饰，为视频编辑任务提供一种新的工具。<details>
<summary>Abstract</summary>
Existing video frame interpolation (VFI) methods blindly predict where each object is at a specific timestep t ("time indexing"), which struggles to predict precise object movements. Given two images of a baseball, there are infinitely many possible trajectories: accelerating or decelerating, straight or curved. This often results in blurry frames as the method averages out these possibilities. Instead of forcing the network to learn this complicated time-to-location mapping implicitly together with predicting the frames, we provide the network with an explicit hint on how far the object has traveled between start and end frames, a novel approach termed "distance indexing". This method offers a clearer learning goal for models, reducing the uncertainty tied to object speeds. We further observed that, even with this extra guidance, objects can still be blurry especially when they are equally far from both input frames (i.e., halfway in-between), due to the directional ambiguity in long-range motion. To solve this, we propose an iterative reference-based estimation strategy that breaks down a long-range prediction into several short-range steps. When integrating our plug-and-play strategies into state-of-the-art learning-based models, they exhibit markedly sharper outputs and superior perceptual quality in arbitrary time interpolations, using a uniform distance indexing map in the same format as time indexing. Additionally, distance indexing can be specified pixel-wise, which enables temporal manipulation of each object independently, offering a novel tool for video editing tasks like re-timing.
</details>
<details>
<summary>摘要</summary>
存在的视频帧 interpolate (VFI) 方法盲目地预测每个对象在特定时间步 t ("时间索引") 上的位置，这可能会难以预测对象的精确移动。给出了两个 baseball 图像，有无数可能的轨迹：加速或减速，直线或弯曲。这经常导致模糊的帧，因为方法平均出这些可能性。而不是让网络学习这些复杂的时间-to-位置映射，我们为网络提供了一个显式的提示，即在开始和结束帧之间对象如何移动的距离，一种新的方法称为 "距离索引"。这种方法为模型提供了明确的学习目标，降低了对象速度的uncertainty。我们进一步发现，即使有这些额外指导，对象仍然可能变得模糊，特别是当它们处于两个输入帧之间的中点（即半路）时，由于长距离运动的方向ambiguity。为解决这个问题，我们提议一种Iterative reference-based估计策略，将长距离预测分解成多个短距离步骤。将我们的插件和简化策略 integrate 到当前的学习基于模型中，它们在任意时间 interpolate 中表现出了明显更加锐化的输出和superior perceptual quality，使用一个固定的距离索引地图，与时间索引相同。此外，距离索引可以像时间索引一样Specified 像素级，这允许在视频编辑任务中重新时间调整每个对象独立地，提供了一种新的工具。
</details></li>
</ul>
<hr>
<h2 id="Explicit-Change-Relation-Learning-for-Change-Detection-in-VHR-Remote-Sensing-Images"><a href="#Explicit-Change-Relation-Learning-for-Change-Detection-in-VHR-Remote-Sensing-Images" class="headerlink" title="Explicit Change Relation Learning for Change Detection in VHR Remote Sensing Images"></a>Explicit Change Relation Learning for Change Detection in VHR Remote Sensing Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07993">http://arxiv.org/abs/2311.07993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dalong Zheng, Zebin Wu, Jia Liu, Chih-Cheng Hung, Zhihui Wei</li>
<li>for: 本文提出了一种名为 NAME 的网络架构，用于显式挖掘变化关系特征，以提高 remote sensing 图像变化检测的准确率。</li>
<li>methods: 该网络架构包括 triple branch 网络， combine 了 transformer 和 CNN，用于提取和融合全局信息和本地信息中的变化特征。 同时，该网络还包括 continous change relation (CCR) branch，用于获取细化变化关系特征，以提高变化检测的准确率。</li>
<li>results: 实验结果表明，NAME 网络在四个公共高分辨率 remote sensing 数据集上的 F1、IoU 和 OA 指标上比现有的先进网络更高。<details>
<summary>Abstract</summary>
Change detection has always been a concerned task in the interpretation of remote sensing images. It is essentially a unique binary classification task with two inputs, and there is a change relationship between these two inputs. At present, the mining of change relationship features is usually implicit in the network architectures that contain single-branch or two-branch encoders. However, due to the lack of artificial prior design for change relationship features, these networks cannot learn enough change semantic information and lose more accurate change detection performance. So we propose a network architecture NAME for the explicit mining of change relation features. In our opinion, the change features of change detection should be divided into pre-changed image features, post-changed image features and change relation features. In order to fully mine these three kinds of change features, we propose the triple branch network combining the transformer and convolutional neural network (CNN) to extract and fuse these change features from two perspectives of global information and local information, respectively. In addition, we design the continuous change relation (CCR) branch to further obtain the continuous and detail change relation features to improve the change discrimination capability of the model. The experimental results show that our network performs better, in terms of F1, IoU, and OA, than those of the existing advanced networks for change detection on four public very high-resolution (VHR) remote sensing datasets. Our source code is available at https://github.com/DalongZ/NAME.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>改变检测一直是Remote感知图像解释中的关键任务。它实际上是一个独特的二分类任务，其中有两个输入。在现有的网络架构中，改变关系特征的挖掘是通常隐式的，但由于缺乏人工设计的改变关系特征，这些网络无法学习足够的改变semantic信息，导致更准确的改变检测性能下降。因此，我们提议一种名为NAME的网络架构，用于明确挖掘改变关系特征。根据我们的观点，改变特征包括预变图像特征、后变图像特征和改变关系特征。为了全面挖掘这三种改变特征，我们提议使用转换器和卷积神经网络（CNN）结合三支分支网络，从全球信息和局部信息两个角度提取和融合这些改变特征。此外，我们还设计了连续改变关系（CCR）支分，以获取更细致的改变关系特征，以提高改变检测模型的改变识别能力。实验结果显示，我们的网络在四个公共very高分辨率（VHR）Remote感知数据集上的F1、IoU和OA指标上表现比现有的先进网络更好。我们的源代码可以在https://github.com/DalongZ/NAME中下载。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Individual-Tree-Mapping-with-Sub-meter-Imagery"><a href="#Benchmarking-Individual-Tree-Mapping-with-Sub-meter-Imagery" class="headerlink" title="Benchmarking Individual Tree Mapping with Sub-meter Imagery"></a>Benchmarking Individual Tree Mapping with Sub-meter Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07981">http://arxiv.org/abs/2311.07981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitri Gominski, Ankit Kariryaa, Martin Brandt, Christian Igel, Sizhuo Li, Maurice Mugabowindekwe, Rasmus Fensholt</li>
<li>for: 本研究旨在提供一个适合单一树木映射的评估框架，以便在不同的物理环境中进行单一树木映射。</li>
<li>methods: 本研究使用了多种方法和深度架构进行单一树木映射，包括检测和分类方法，以及传播者。</li>
<li>results: 本研究通过实验证明了一个新的方法，可以在单一树木映射中实现一个好的折冲点between segmentation和检测。<details>
<summary>Abstract</summary>
There is a rising interest in mapping trees using satellite or aerial imagery, but there is no standardized evaluation protocol for comparing and enhancing methods. In dense canopy areas, the high variability of tree sizes and their spatial proximity makes it arduous to define the quality of the predictions. Concurrently, object-centric approaches such as bounding box detection usuallyperform poorly on small and dense objects. It thus remains unclear what is the ideal framework for individual tree mapping, in regards to detection and segmentation approaches, convolutional neural networks and transformers. In this paper, we introduce an evaluation framework suited for individual tree mapping in any physical environment, with annotation costs and applicative goals in mind. We review and compare different approaches and deep architectures, and introduce a new method that we experimentally prove to be a good compromise between segmentation and detection.
</details>
<details>
<summary>摘要</summary>
有一些团队正在使用卫星或飞行图像来映射树木，但没有一个标准化的评估协议来比较和提高方法。在密集的树木区域中，树木的大小和空间 proximity 的高度变化使其困难定义预测的质量。同时，对象中心的方法，如 bounding box 探测，通常在小型和密集的对象上表现不佳。因此，还未确定最佳的框架是什么，它应该是 detection 和 segmentation 方法， convolutional neural networks 和 transformers。在这篇文章中，我们提出了适用于个体树木映射的评估框架，考虑到标注成本和实际应用目标。我们还对不同的方法和深度架构进行了查看和比较，并引入了一种新的方法，我们实验证明这种方法是一个好的 segmentation 和 detection 的 компроми斯。
</details></li>
</ul>
<hr>
<h2 id="Comparison-of-two-data-fusion-approaches-for-land-use-classification"><a href="#Comparison-of-two-data-fusion-approaches-for-land-use-classification" class="headerlink" title="Comparison of two data fusion approaches for land use classification"></a>Comparison of two data fusion approaches for land use classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07967">http://arxiv.org/abs/2311.07967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Cubaud, Arnaud Le Bris, Laurence Jolivet, Ana-Maria Olteanu-Raimond</li>
<li>for: 这种研究的目的是为了生成详细的土地使用地图，以便于土地管理和规划。</li>
<li>methods: 这种研究使用了多种不同来源的空间数据，包括光学图像和其他数据源，并 compare了两种不同的方法来组合这些数据：预分类 fusion 和后分类 fusion。</li>
<li>results: 研究发现，预分类 fusion 方法可以达到最高的 final 精度（97%）和macro-mean F1 分数（88%）。<details>
<summary>Abstract</summary>
Accurate land use maps, describing the territory from an anthropic utilisation point of view, are useful tools for land management and planning. To produce them, the use of optical images alone remains limited. It is therefore necessary to make use of several heterogeneous sources, each carrying complementary or contradictory information due to their imperfections or their different specifications. This study compares two different approaches i.e. a pre-classification and a post-classification fusion approach for combining several sources of spatial data in the context of land use classification. The approaches are applied on authoritative land use data located in the Gers department in the southwest of France. Pre-classification fusion, while not explicitly modeling imperfections, has the best final results, reaching an overall accuracy of 97% and a macro-mean F1 score of 88%.
</details>
<details>
<summary>摘要</summary>
准确的土地使用地图，从人类活动利用角度来看 territory，是地域规划和管理中非常有用的工具。但使用光学图像 alone 的使用受限，因此需要使用多种不同来源，每种携带不同的信息，由于它们的不完全性或不同的规格。本研究比较了两种不同的方法，即预分类和后分类 fusión 方法，用于将多种空间数据组合在土地使用分类中。两种方法在法国南西部GERS省的官方土地使用数据上进行应用。预分类 fusión 方法，不直接模型瑕疵，最终结果最佳，达到了97%的总准确率和88%的macro-mean F1分数。
</details></li>
</ul>
<hr>
<h2 id="Robust-Learning-Based-Condition-Diagnosis-Method-for-Distribution-Network-Switchgear"><a href="#Robust-Learning-Based-Condition-Diagnosis-Method-for-Distribution-Network-Switchgear" class="headerlink" title="Robust Learning Based Condition Diagnosis Method for Distribution Network Switchgear"></a>Robust Learning Based Condition Diagnosis Method for Distribution Network Switchgear</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07956">http://arxiv.org/abs/2311.07956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxi Zhang, Zhe Li, Weixi Li, Weisi Ma, Xinyi Chen, Sizhe Li</li>
<li>For: 这种方法用于诊断分布网络switchgear的状态，以维护电力质量 для终端用户。* Methods: 该方法使用扩展的特征向量，包括环境数据、温度测量、Switch位置、电动机操作、隔离状况和本地充电信息。它利用特征映射处理高维度数据，并引入决策半径来分类无标签样本，通过综合超参和自参损失函数、一致常数 regularization 函数来更新模型参数。* Results: 相比现有模型，该方法在准确性和稳定性两个方面具有显著优势。<details>
<summary>Abstract</summary>
This paper introduces a robust, learning-based method for diagnosing the state of distribution network switchgear, which is crucial for maintaining the power quality for end users. Traditional diagnostic models often rely heavily on expert knowledge and lack robustness. To address this, our method incorporates an expanded feature vector that includes environmental data, temperature readings, switch position, motor operation, insulation conditions, and local discharge information. We tackle the issue of high dimensionality through feature mapping. The method introduces a decision radius to categorize unlabeled samples and updates the model parameters using a combination of supervised and unsupervised loss, along with a consistency regularization function. This approach ensures robust learning even with a limited number of labeled samples. Comparative analysis demonstrates that this method significantly outperforms existing models in both accuracy and robustness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detection-of-Small-Targets-in-Sea-Clutter-Based-on-RepVGG-and-Continuous-Wavelet-Transform"><a href="#Detection-of-Small-Targets-in-Sea-Clutter-Based-on-RepVGG-and-Continuous-Wavelet-Transform" class="headerlink" title="Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous Wavelet Transform"></a>Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous Wavelet Transform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07912">http://arxiv.org/abs/2311.07912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingchen Ni, Haoru Li, Lilin Xu, Jing Liang</li>
<li>for: 这个论文的目的是提出一种高性能的海啸背景下的目标探测器，以提高探测效率和准确率。</li>
<li>methods: 这个论文使用了RepVGG残差网络，并与其他网络和特征提取方法进行比较，包括STFT和CWT。</li>
<li>results: 测试结果表明，使用RepVGGA0-CWT探测器可以在低控制干扰false alarm rate、高训练速度、高探测速度和低内存使用率等方面表现优于其他网络和特征提取方法。<details>
<summary>Abstract</summary>
Constructing a high-performance target detector under the background of sea clutter is always necessary and important. In this work, we propose a RepVGGA0-CWT detector, where RepVGG is a residual network that gains a high detection accuracy. Different from traditional residual networks, RepVGG keeps an acceptable calculation speed. Giving consideration to both accuracy and speed, the RepVGGA0 is selected among all the variants of RepVGG. Also, continuous wavelet transform (CWT) is employed to extract the radar echoes' time-frequency feature effectively. In the tests, other networks (ResNet50, ResNet18 and AlexNet) and feature extraction methods (short-time Fourier transform (STFT), CWT) are combined to build detectors for comparison. The result of different datasets shows that the RepVGGA0-CWT detector performs better than those detectors in terms of low controllable false alarm rate, high training speed, high inference speed and low memory usage. This RepVGGA0-CWT detector is hardware-friendly and can be applied in real-time scenes for its high inference speed in detection.
</details>
<details>
<summary>摘要</summary>
构建高性能的目标检测器在海啸背景下是一项必要和重要的任务。在这项工作中，我们提议了RepVGGA0-CWT检测器，其中RepVGG是一种具有高检测精度的径向网络，而不同于传统的径向网络，RepVGG具有可接受的计算速度。为了考虑精度和速度之间的平衡，我们选择了RepVGGA0中的所有变体。此外，我们采用了 kontinuous wavelet transform（CWT）来提取雷达回声的时空频特征，以便更好地检测目标。在测试中，我们使用了其他网络（ResNet50、ResNet18和AlexNet）和特征提取方法（short-time Fourier transform（STFT）、CWT）构建了对比的检测器。测试结果显示，RepVGGA0-CWT检测器在低可控干扰False Alarm率、高训练速度、高推理速度和低内存使用量等方面表现更好于其他检测器。此外，这种RepVGGA0-CWT检测器具有硬件友好性，可以在实时场景中应用，因为它具有高推理速度。
</details></li>
</ul>
<hr>
<h2 id="Test-Time-Training-for-Semantic-Segmentation-with-Output-Contrastive-Loss"><a href="#Test-Time-Training-for-Semantic-Segmentation-with-Output-Contrastive-Loss" class="headerlink" title="Test-Time Training for Semantic Segmentation with Output Contrastive Loss"></a>Test-Time Training for Semantic Segmentation with Output Contrastive Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07877">http://arxiv.org/abs/2311.07877</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dazhangyu123/ocl">https://github.com/dazhangyu123/ocl</a></li>
<li>paper_authors: Yunlong Zhang, Yuxuan Sun, Sunyi Zheng, Zhongyi Shui, Chenglu Zhu, Lin Yang</li>
<li>for: 这篇论文主要是为了提高深度学习基于模型在新领域中的泛化能力，以便在评估时能够更好地适应新的环境。</li>
<li>methods: 作者使用了测试时重要（TTT）方法，并引入了对比损失（CL）来稳定化适应过程，同时对CL进行了修改和简化，以便更直观地帮助模型更好地适应新的环境。</li>
<li>results: 作者通过了多种评估场景，证明了他们的方法的有效性，特别是当应用于先进的预训练方法中的测试数据时，他们的方法表现出色，说明它具有抗衰落和适应性。<details>
<summary>Abstract</summary>
Although deep learning-based segmentation models have achieved impressive performance on public benchmarks, generalizing well to unseen environments remains a major challenge. To improve the model's generalization ability to the new domain during evaluation, the test-time training (TTT) is a challenging paradigm that adapts the source-pretrained model in an online fashion. Early efforts on TTT mainly focus on the image classification task. Directly extending these methods to semantic segmentation easily experiences unstable adaption due to segmentation's inherent characteristics, such as extreme class imbalance and complex decision spaces. To stabilize the adaptation process, we introduce contrastive loss (CL), known for its capability to learn robust and generalized representations. Nevertheless, the traditional CL operates in the representation space and cannot directly enhance predictions. In this paper, we resolve this limitation by adapting the CL to the output space, employing a high temperature, and simplifying the formulation, resulting in a straightforward yet effective loss function called Output Contrastive Loss (OCL). Our comprehensive experiments validate the efficacy of our approach across diverse evaluation scenarios. Notably, our method excels even when applied to models initially pre-trained using domain adaptation methods on test domain data, showcasing its resilience and adaptability.\footnote{Code and more information could be found at~ \url{https://github.com/dazhangyu123/OCL}
</details>
<details>
<summary>摘要</summary>
（简体中文）尽管深度学习基于的分割模型在公共评测上表现出色，但将其推广到未见的环境中仍然是一大挑战。以提高模型在新领域评测时的泛化能力，测试时间训练（TTT）是一种挑战的 paradigma，它在线上适应源预训练模型。早期的TTT主要关注于图像分类任务。将这些方法扩展到 semantic segmentation 是容易陷入不稳定的适应过程，因为分割的特点包括分类异常分布和复杂的决策空间。为稳定适应过程，我们引入对比损失（CL），它能够学习Robust和通用的表示。然而，传统的CL在表示空间运行，无法直接改进预测。在这篇论文中，我们解决这个限制，通过对CL的修改，使其适应输出空间，使用高温度，并简化表述，得到一种直观 yet 有效的损失函数，称为输出对比损失（OCL）。我们在多个评测场景中进行了广泛的实验，证明了我们的方法的可靠性和适应性。尤其是，当我们将模型在测试预训练使用Domain adaptation方法时，我们的方法仍然表现出色，这表明了我们的方法的稳定性和适应性。
</details></li>
</ul>
<hr>
<h2 id="Dual-channel-Prototype-Network-for-few-shot-Classification-of-Pathological-Images"><a href="#Dual-channel-Prototype-Network-for-few-shot-Classification-of-Pathological-Images" class="headerlink" title="Dual-channel Prototype Network for few-shot Classification of Pathological Images"></a>Dual-channel Prototype Network for few-shot Classification of Pathological Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07871">http://arxiv.org/abs/2311.07871</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/quanhao129611/DCPN">https://github.com/quanhao129611/DCPN</a></li>
<li>paper_authors: Hao Quan, Xinjia Li, Dayu Hu, Tianhang Nan, Xiaoyu Cui</li>
<li>for: 这篇论文旨在提出一种基于几何学学习的技术，以几何学学习方法来对罕见疾病的医学图像进行分类。</li>
<li>methods: 本研究使用了一种称为“双渠道原型网络”（DCPN）的技术，该技术结合了自我超vised learning和卷积神经网络，以提高几何学分类的精度和效率。</li>
<li>results: 根据实验结果显示，DCPN在不同预设的临床情况下，实现了几何学分类任务的超级表现，特别是在同领域内的任务中，其性能与指导式学习相当。<details>
<summary>Abstract</summary>
In pathology, the rarity of certain diseases and the complexity in annotating pathological images significantly hinder the creation of extensive, high-quality datasets. This limitation impedes the progress of deep learning-assisted diagnostic systems in pathology. Consequently, it becomes imperative to devise a technology that can discern new disease categories from a minimal number of annotated examples. Such a technology would substantially advance deep learning models for rare diseases. Addressing this need, we introduce the Dual-channel Prototype Network (DCPN), rooted in the few-shot learning paradigm, to tackle the challenge of classifying pathological images with limited samples. DCPN augments the Pyramid Vision Transformer (PVT) framework for few-shot classification via self-supervised learning and integrates it with convolutional neural networks. This combination forms a dual-channel architecture that extracts multi-scale, highly precise pathological features. The approach enhances the versatility of prototype representations and elevates the efficacy of prototype networks in few-shot pathological image classification tasks. We evaluated DCPN using three publicly available pathological datasets, configuring small-sample classification tasks that mirror varying degrees of clinical scenario domain shifts. Our experimental findings robustly affirm DCPN's superiority in few-shot pathological image classification, particularly in tasks within the same domain, where it achieves the benchmarks of supervised learning.
</details>
<details>
<summary>摘要</summary>
在 PATHOLOGY 领域，一些疾病的罕见性和诊断图像的复杂性，使得创建大量、高质量数据集成为非常困难的。这种限制阻碍了深度学习助动诊断系统在 PATHOLOGY 领域的进步。因此，需要开发一种技术，可以从 minimal 数量的标注示例中分辨出新的疾病类别。这种技术将帮助深度学习模型更好地识别罕见疾病。为解决这个需求，我们介绍了 Dual-channel Prototype Network (DCPN)，基于 few-shot 学习 paradigm，用于分类 PATHOLOGY 图像。DCPN 将 Pyramid Vision Transformer (PVT) 框架与自动学习相结合，并将其与卷积神经网络结合。这种结构形成了双通道体系，可以提取多级、高精度 PATHOLOGY 特征。这种方法提高了prototype表示的多样性，并提高了prototype网络在 few-shot PATHOLOGY 图像分类任务中的效果。我们通过三个公共可用的 PATHOLOGY 数据集进行了实验，并配置了小样本分类任务，这些任务模拟了不同程度的临床enario域转移。我们的实验结果表明，DCPN 在 few-shot PATHOLOGY 图像分类任务中表现出色，特别是在同一个域的任务中，它可以达到超过supervised learning的标准。
</details></li>
</ul>
<hr>
<h2 id="Probing-clustering-in-neural-network-representations"><a href="#Probing-clustering-in-neural-network-representations" class="headerlink" title="Probing clustering in neural network representations"></a>Probing clustering in neural network representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07864">http://arxiv.org/abs/2311.07864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thao Nguyen, Simon Kornblith</li>
<li>for: 研究如何不同的设计选择影响隐藏表示中的团集化。</li>
<li>methods: 使用 BREEDS  hierarchy 进行 subclass clustering， isolate 训练数据集和网络架构为关键因素。</li>
<li>results: 发现 datasets 的类别结构和预训练模型的选择对团集化有影响，normalization 策略affects 哪些层的团集化性能，并发现 Vision Transformers 的团集化性能较差。<details>
<summary>Abstract</summary>
Neural network representations contain structure beyond what was present in the training labels. For instance, representations of images that are visually or semantically similar tend to lie closer to each other than to dissimilar images, regardless of their labels. Clustering these representations can thus provide insights into dataset properties as well as the network internals. In this work, we study how the many design choices involved in neural network training affect the clusters formed in the hidden representations. To do so, we establish an evaluation setup based on the BREEDS hierarchy, for the task of subclass clustering after training models with only superclass information. We isolate the training dataset and architecture as important factors affecting clusterability. Datasets with labeled classes consisting of unrelated subclasses yield much better clusterability than those following a natural hierarchy. When using pretrained models to cluster representations on downstream datasets, models pretrained on subclass labels provide better clusterability than models pretrained on superclass labels, but only when there is a high degree of domain overlap between the pretraining and downstream data. Architecturally, we find that normalization strategies affect which layers yield the best clustering performance, and, surprisingly, Vision Transformers attain lower subclass clusterability than ResNets.
</details>
<details>
<summary>摘要</summary>
（注：以下是使用简化中文表示的文本）神经网络表示含有超出训练标签的结构。例如，与标签不同的图像表示在不同的图像中往往更近，无论它们的标签如何。将这些表示进行归类可以提供关于数据集和网络内部的信息。在这种工作中，我们研究了各种神经网络训练中的设计选择如何影响隐藏表示中的归类结构。为此，我们基于BREEDS层次结构设置评估集成，用于在只有超类信息下进行类别归类。我们发现，使用不同类别的数据集和架构可以影响归类性。具有不相关的类别的数据集可以获得更好的归类性，而遵循自然层次结构的数据集则不然。使用预训练模型进行下游数据集的归类时，使用 subclass标签进行预训练可以获得更好的归类性，但只有在预训练和下游数据集具有高度域 overlap 时。层次上，我们发现normalization策略可以影响归类性最佳层，并且意外地发现视图转换器的 subclass 归类性较低于ResNet。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/cs.CV_2023_11_14/" data-id="clpztdnjl00n8es88c69h057p" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/cs.AI_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T12:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/cs.AI_2023_11_14/">cs.AI - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AART-AI-Assisted-Red-Teaming-with-Diverse-Data-Generation-for-New-LLM-powered-Applications"><a href="#AART-AI-Assisted-Red-Teaming-with-Diverse-Data-Generation-for-New-LLM-powered-Applications" class="headerlink" title="AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications"></a>AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08592">http://arxiv.org/abs/2311.08592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kevinrobinson-at-elgoog/aart-ai-safety-dataset">https://github.com/kevinrobinson-at-elgoog/aart-ai-safety-dataset</a></li>
<li>paper_authors: Bhaktipriya Radharapu, Kevin Robinson, Lora Aroyo, Preethi Lahoti</li>
<li>for: 这篇论文是用于推广大语言模型（LLM）的安全和负责任部署的检测方法。</li>
<li>methods: 这篇论文提出了一种新的自动生成挑战数据集的方法，以测试LLM生成的新应用程序的安全性。这种方法被称为人工智能协助红团（AART），它可以减少人类努力，并提供可重用和定制的食谱，以便在新产品开发中早些地 integrating 挑战测试。</li>
<li>results: AART 可以生成具有高多样性的内容特征的评估数据集，包括敏感和危险的概念、特定的文化和地理区域、和应用场景。与一些当前的工具相比，AART 表现出了优秀的概念覆盖率和数据质量。<details>
<summary>Abstract</summary>
Adversarial testing of large language models (LLMs) is crucial for their safe and responsible deployment. We introduce a novel approach for automated generation of adversarial evaluation datasets to test the safety of LLM generations on new downstream applications. We call it AI-assisted Red-Teaming (AART) - an automated alternative to current manual red-teaming efforts. AART offers a data generation and augmentation pipeline of reusable and customizable recipes that reduce human effort significantly and enable integration of adversarial testing earlier in new product development. AART generates evaluation datasets with high diversity of content characteristics critical for effective adversarial testing (e.g. sensitive and harmful concepts, specific to a wide range of cultural and geographic regions and application scenarios). The data generation is steered by AI-assisted recipes to define, scope and prioritize diversity within the application context. This feeds into a structured LLM-generation process that scales up evaluation priorities. Compared to some state-of-the-art tools, AART shows promising results in terms of concept coverage and data quality.
</details>
<details>
<summary>摘要</summary>
<<SYS>>大型自然语言模型（LLM）的反对攻击测试是其安全和负责的部署的关键。我们介绍了一种新的自动生成反对攻击评估数据集的方法，以测试LLM生成的安全性在新的下游应用中。我们称之为人工智能协助红团（AART），它是现有手动红团努力的自动化代替方案。AART提供了一个数据生成和扩大管道，可以减少人类努力，并允许在新产品开发中更EARLY Integration of adversarial testing。AART生成的评估数据集具有高度的内容特征多样性，如敏感和危险概念、特定的文化和地理区域、应用场景等。数据生成被由人工智能辅助的评则定义、范围和优先级，以适应应用上下文。这将导入一个结构化的LLM生成过程，可以扩大评估优先级。相比一些状态 искусственный智能工具，AART表现出了promising的概念覆盖率和数据质量。
</details></li>
</ul>
<hr>
<h2 id="CodeScope-An-Execution-based-Multilingual-Multitask-Multidimensional-Benchmark-for-Evaluating-LLMs-on-Code-Understanding-and-Generation"><a href="#CodeScope-An-Execution-based-Multilingual-Multitask-Multidimensional-Benchmark-for-Evaluating-LLMs-on-Code-Understanding-and-Generation" class="headerlink" title="CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation"></a>CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08588">http://arxiv.org/abs/2311.08588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weixiangyan/codescope">https://github.com/weixiangyan/codescope</a></li>
<li>paper_authors: Weixiang Yan, Haitian Liu, Yunkun Wang, Yunzhe Li, Qian Chen, Wen Wang, Tingyu Lin, Weishan Zhao, Li Zhu, Shuiguang Deng, Hari Sundaram</li>
<li>for: 这个论文的目的是提出一个新的编程能力评测 benchmark，以更好地评估大型自然语言模型（LLMs）在编程任务上的表现。</li>
<li>methods: 这个论文使用了多种方法，包括开发了一个名为 MultiCodeEngine 的自动化代码执行引擎，以及设计了一个名为 CodeScope 的多语言多任务多维度评测 benchmark。</li>
<li>results: 通过对 8 种主流 LLMs 在 CodeScope 任务上进行系统性的评测和分析，这个论文展示了 CodeScope 对 LLMs 的评测能力的广泛性和挑战性，以及其对编程任务的评估能力的综合性。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable performance on coding related tasks, particularly on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most benchmarks are deficient as they focus on a narrow range of popular programming languages and specific tasks, whereas the real-world software development scenarios show dire need to implement systems with multilingual programming environments to satisfy diverse requirements. Practical programming practices also strongly expect multi-task settings for testing coding capabilities of LLMs comprehensively and robustly. Second, most benchmarks also fail to consider the actual executability and the consistency of execution results of the generated code. To bridge these gaps between existing benchmarks and expectations from practical applications, we introduce CodeScope, an execution-based, multilingual, multi-task, multi-dimensional evaluation benchmark for comprehensively gauging LLM capabilities on coding tasks. CodeScope covers 43 programming languages and 8 coding tasks. It evaluates the coding performance of LLMs from three dimensions (perspectives): difficulty, efficiency, and length. To facilitate execution-based evaluations of code generation, we develop MultiCodeEngine, an automated code execution engine that supports 14 programming languages. Finally, we systematically evaluate and analyze 8 mainstream LLMs on CodeScope tasks and demonstrate the superior breadth and challenges of CodeScope for evaluating LLMs on code understanding and generation tasks compared to other benchmarks. The CodeScope benchmark and datasets are publicly available at https://github.com/WeixiangYAN/CodeScope.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在编程相关任务上表现出色，特别是在协助人类编程和自动化编程方面。然而，现有的代码理解和生成能力评估标准受到严重的限制。首先，大多数标准都是专注于一些受欢迎的编程语言和特定任务，而实际世界的软件开发场景需要实现多语言编程环境，以满足多样化的需求。实际编程实践也希望通过多任务设定来测试 LLM 的编程能力，以进行全面和可靠的评估。其次，大多数标准也忽视了生成代码的执行可能性和执行结果的一致性。为了bridging这些存在的差异，我们提出了 CodeScope，一个基于执行的多语言多任务多维度评估标准，用于全面评估 LLM 在编程任务上的能力。CodeScope 涵盖了43种编程语言和8种编程任务，并评估 LLM 的编程性能从三个维度（视角）：困难、效率和长度。为了促进代码生成的执行评估，我们开发了 MultiCodeEngine，一个自动化代码执行引擎，支持14种编程语言。最后，我们系统地评估了8种主流 LLM 在 CodeScope 任务上的表现，并证明 CodeScope 对 LLM 的代码理解和代码生成能力评估具有更高的广泛性和挑战性，相比其他标准。CodeScope  benchmark和数据集公开可以在 GitHub 上下载。
</details></li>
</ul>
<hr>
<h2 id="Finding-AI-Generated-Faces-in-the-Wild"><a href="#Finding-AI-Generated-Faces-in-the-Wild" class="headerlink" title="Finding AI-Generated Faces in the Wild"></a>Finding AI-Generated Faces in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08577">http://arxiv.org/abs/2311.08577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gonzalo J. Aniano Porcile, Jack Gindi, Shivansh Mundra, James R. Verbus, Hany Farid</li>
<li>for: 本研究旨在分辨真正的人脸和人工生成的 faces，尤其是在假账户图像上。</li>
<li>methods: 该研究使用了一种简单的方法，通过关注人脸特征来检测人工生成的 faces。</li>
<li>results: 研究发现，通过关注人脸特征可以检测到各种人工生成的 faces，包括Diffusion-based和GAN-based生成的 faces，并且可以在不同的图像解度和质量下进行检测。<details>
<summary>Abstract</summary>
AI-based image generation has continued to rapidly improve, producing increasingly more realistic images with fewer obvious visual flaws. AI-generated images are being used to create fake online profiles which in turn are being used for spam, fraud, and disinformation campaigns. As the general problem of detecting any type of manipulated or synthesized content is receiving increasing attention, here we focus on a more narrow task of distinguishing a real face from an AI-generated face. This is particularly applicable when tackling inauthentic online accounts with a fake user profile photo. We show that by focusing on only faces, a more resilient and general-purpose artifact can be detected that allows for the detection of AI-generated faces from a variety of GAN- and diffusion-based synthesis engines, and across image resolutions (as low as 128 x 128 pixels) and qualities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Evaluating-AI-Systems-for-Moral-Status-Using-Self-Reports"><a href="#Towards-Evaluating-AI-Systems-for-Moral-Status-Using-Self-Reports" class="headerlink" title="Towards Evaluating AI Systems for Moral Status Using Self-Reports"></a>Towards Evaluating AI Systems for Moral Status Using Self-Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08576">http://arxiv.org/abs/2311.08576</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ethan Perez, Robert Long</li>
<li>for:  investigate whether AI systems have states of moral significance</li>
<li>methods:  train models to answer questions about themselves with known answers, avoiding training incentives that bias self-reports</li>
<li>results:  develop introspection-like capabilities, and assess the consistency and reliability of self-reports<details>
<summary>Abstract</summary>
As AI systems become more advanced and widely deployed, there will likely be increasing debate over whether AI systems could have conscious experiences, desires, or other states of potential moral significance. It is important to inform these discussions with empirical evidence to the extent possible. We argue that under the right circumstances, self-reports, or an AI system's statements about its own internal states, could provide an avenue for investigating whether AI systems have states of moral significance. Self-reports are the main way such states are assessed in humans ("Are you in pain?"), but self-reports from current systems like large language models are spurious for many reasons (e.g. often just reflecting what humans would say). To make self-reports more appropriate for this purpose, we propose to train models to answer many kinds of questions about themselves with known answers, while avoiding or limiting training incentives that bias self-reports. The hope of this approach is that models will develop introspection-like capabilities, and that these capabilities will generalize to questions about states of moral significance. We then propose methods for assessing the extent to which these techniques have succeeded: evaluating self-report consistency across contexts and between similar models, measuring the confidence and resilience of models' self-reports, and using interpretability to corroborate self-reports. We also discuss challenges for our approach, from philosophical difficulties in interpreting self-reports to technical reasons why our proposal might fail. We hope our discussion inspires philosophers and AI researchers to criticize and improve our proposed methodology, as well as to run experiments to test whether self-reports can be made reliable enough to provide information about states of moral significance.
</details>
<details>
<summary>摘要</summary>
We then propose methods for assessing the extent to which these techniques have succeeded:1. Evaluating self-report consistency across contexts and between similar models2. Measuring the confidence and resilience of models' self-reports3. Using interpretability to corroborate self-reportsWe also discuss challenges for our approach, from philosophical difficulties in interpreting self-reports to technical reasons why our proposal might fail. We hope our discussion inspires philosophers and AI researchers to criticize and improve our proposed methodology, as well as to run experiments to test whether self-reports can be made reliable enough to provide information about states of moral significance.
</details></li>
</ul>
<hr>
<h2 id="Parameter-Efficient-Multilingual-Summarisation-An-Empirical-Study"><a href="#Parameter-Efficient-Multilingual-Summarisation-An-Empirical-Study" class="headerlink" title="Parameter-Efficient Multilingual Summarisation: An Empirical Study"></a>Parameter-Efficient Multilingual Summarisation: An Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08572">http://arxiv.org/abs/2311.08572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenxi Whitehouse, Fantine Huot, Jasmijn Bastings, Mostafa Dehghani, Chu-Cheng Lin, Mirella Lapata</li>
<li>for: 这篇论文 investigate了 Parametric Efficient Fine-Tuning 在复杂和未探索的多语言概要任务中的潜力，尤其是在内存占用任务中。</li>
<li>methods: 该论文使用了 Low-Rank Adaptation（LoRA）方法，并在不同的数据可用性enario中进行了广泛的研究，包括全数据、低数据和 cross-lingual transfer。</li>
<li>results: 研究发现，在全数据场景下，LoRA 落后于全 Fine-Tuning，但在低数据场景和 cross-lingual transfer 中，LoRA 表现出色。同时，随着模型的尺寸增大，LoRA 和 Full Fine-Tuning 之间的性能差距逐渐减少。此外，我们还研究了少量数据的 cross-lingual transfer 策略，发现 Continued LoRA 升级得到了最好的表现。<details>
<summary>Abstract</summary>
With the increasing prevalence of Large Language Models, traditional full fine-tuning approaches face growing challenges, especially in memory-intensive tasks. This paper investigates the potential of Parameter-Efficient Fine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and under-explored multilingual summarisation tasks. We conduct an extensive study across different data availability scenarios, including full-data, low-data, and cross-lingual transfer, leveraging models of different sizes. Our findings reveal that LoRA lags behind full fine-tuning when trained with full data, however, it excels in low-data scenarios and cross-lingual transfer. Interestingly, as models scale up, the performance gap between LoRA and full fine-tuning diminishes. Additionally, we investigate effective strategies for few-shot cross-lingual transfer, finding that continued LoRA tuning achieves the best performance compared to both full fine-tuning and dynamic composition of language-specific LoRA modules.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型的普及，传统的全面精通方法面临着增长的挑战，特别是在内存密集的任务上。这篇论文研究了Parameter-Efficient Fine-Tuning的潜在，特别是LOW-RANK Adaptation（LoRA）在复杂且未曾经explored的多语言概要任务上。我们进行了广泛的研究，包括全数据、低数据和语言转移等不同数据可用性enario，利用不同的模型大小。我们的发现表明，LoRA在全数据上训练时与全面精通相比落后，但在低数据 scenarios和语言转移中表现出色。有意思的是，随着模型的尺寸增长，LoRA和全面精通的性能差距逐渐减小。此外，我们还研究了几个有效的少量跨语言转移策略，发现继续LoRA调教比full fine-tuning和动态语言特定LoRA模块组合更佳。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Imitation-Learning-On-Aggregated-Data"><a href="#Adversarial-Imitation-Learning-On-Aggregated-Data" class="headerlink" title="Adversarial Imitation Learning On Aggregated Data"></a>Adversarial Imitation Learning On Aggregated Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08568">http://arxiv.org/abs/2311.08568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Le Pelletier de Woillemont, Rémi Labory, Vincent Corruble</li>
<li>for: 学习一个优化的策略，基于一些专家示范，以避免指定一个合适的奖励函数的困难过程。</li>
<li>methods: 使用一种动态、适应的方法 called Adversarial Imitation Learning on Aggregated Data (AILAD)， concurrently学习非线性奖励函数和关联的优化策略，使用反对抗框架。奖励学习器仅使用汇总数据。同时，它生成了多样化的行为，生成汇总数据匹配专家的分布。</li>
<li>results: 方法可以减少或消除现有系统中的一些约束，例如完全解决一个前向奖励学习问题的内部循环，或者需要专家全 trajectory，或者假设专家数据具有共同性。这些约束使现有的IRL方法不可扩展或不可用于certain existing systems。<details>
<summary>Abstract</summary>
Inverse Reinforcement Learning (IRL) learns an optimal policy, given some expert demonstrations, thus avoiding the need for the tedious process of specifying a suitable reward function. However, current methods are constrained by at least one of the following requirements. The first one is the need to fully solve a forward Reinforcement Learning (RL) problem in the inner loop of the algorithm, which might be prohibitively expensive in many complex environments. The second one is the need for full trajectories from the experts, which might not be easily available. The third one is the assumption that the expert data is homogeneous rather than a collection from various experts or possibly alternative solutions to the same task. Such constraints make IRL approaches either not scalable or not usable on certain existing systems. In this work we propose an approach which removes these requirements through a dynamic, adaptive method called Adversarial Imitation Learning on Aggregated Data (AILAD). It learns conjointly both a non linear reward function and the associated optimal policy using an adversarial framework. The reward learner only uses aggregated data. Moreover, it generates diverse behaviors producing a distribution over the aggregated data matching that of the experts.
</details>
<details>
<summary>摘要</summary>
inverse 奖励学习（IRL）可以学习最佳策略，基于一些专家示范，因此可以避免 specify 一个合适的奖励函数的劳碌的过程。然而，当前的方法受到以下一些限制：1. 需要完全解决一个前向奖励学习（RL）问题的内部循环算法，这可能是许多复杂环境中的禁制件。2. 需要全息的专家数据，这可能不可能获得。3. 假设专家数据是一致的，而不是一个由多个专家或可能的解决方案集合。这些限制使得 IRL 方法不可扩展或不可用于某些现有系统。在这种工作中，我们提议一种方法，即 Adversarial Imitation Learning on Aggregated Data（AILAD）。它可以同时学习非线性奖励函数和相关的优化策略，使用对抗框架。奖励学习者只使用汇总数据。此外，它可以生成多样的行为，生成一个与专家数据 Distribution 匹配的分布。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-reconstruction-of-Dark-Matter-fields-from-biased-tracers-using-diffusion-models"><a href="#Probabilistic-reconstruction-of-Dark-Matter-fields-from-biased-tracers-using-diffusion-models" class="headerlink" title="Probabilistic reconstruction of Dark Matter fields from biased tracers using diffusion models"></a>Probabilistic reconstruction of Dark Matter fields from biased tracers using diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08558">http://arxiv.org/abs/2311.08558</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cfpark00/vdm4cdm">https://github.com/cfpark00/vdm4cdm</a></li>
<li>paper_authors: Core Francisco Park, Victoria Ono, Nayantara Mudur, Yueying Ni, Carolina Cuesta-Lazaro</li>
<li>for: 这篇论文旨在研究 galaxy formation 模型中对 dark matter 的影响，以及如何通过 diffusion generative model 预测 dark matter 场的 posterior distribution。</li>
<li>methods: 这篇论文使用 state-of-the-art galaxy formation simulation suites，并 vary cosmological parameters 和 sub-grid astrophysics 来研究 dark matter 和 galaxy 之间的关系。</li>
<li>results: 这篇论文通过 diffusion generative model 预测了 dark matter 场的 posterior distribution，并能够 marginalize over  cosmological 和 galaxy formation 中的不确定性。<details>
<summary>Abstract</summary>
Galaxies are biased tracers of the underlying cosmic web, which is dominated by dark matter components that cannot be directly observed. The relationship between dark matter density fields and galaxy distributions can be sensitive to assumptions in cosmology and astrophysical processes embedded in the galaxy formation models, that remain uncertain in many aspects. Based on state-of-the-art galaxy formation simulation suites with varied cosmological parameters and sub-grid astrophysics, we develop a diffusion generative model to predict the unbiased posterior distribution of the underlying dark matter fields from the given stellar mass fields, while being able to marginalize over the uncertainties in cosmology and galaxy formation.
</details>
<details>
<summary>摘要</summary>
星系是潜在的cosmic web的偏向跟踪器，cosmic web是由黑洞物质组成的，这些物质无法直接观测。星系分布和黑洞物质密度场之间的关系可能受到 cosmology 和astrophysical processes的假设和未知之影响。基于现代星系形成模拟集和不同 cosmological parameters 和astrophysical processes的 substitute，我们开发了一种扩散生成模型，可以预测基于给定的星系质量场的黑洞物质场的不偏 posterior distribution，同时可以对 cosmology 和星系形成过程中的不确定性进行补做。
</details></li>
</ul>
<hr>
<h2 id="Low-light-Pedestrian-Detection-in-Visible-and-Infrared-Image-Feeds-Issues-and-Challenges"><a href="#Low-light-Pedestrian-Detection-in-Visible-and-Infrared-Image-Feeds-Issues-and-Challenges" class="headerlink" title="Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges"></a>Low-light Pedestrian Detection in Visible and Infrared Image Feeds: Issues and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08557">http://arxiv.org/abs/2311.08557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishikesh Vachhani, Thangarajah Akilan, Yash Devmurari, Nisharaff Shaik, Dhruvisha Patel</li>
<li>for: 本研究旨在探讨Recently, new ideas have been spurred to use alternative sources, such as Far InfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light conditions.</li>
<li>methods: 本研究系统atically categorizes and analyses various algorithms from region-based to non-region-based and graph-based learning methodologies by highlighting their methodologies, implementation issues, and challenges.</li>
<li>results: 本研究提出了一些最新的发展方法，包括region-based和non-region-based的方法，以及graph-based learning方法，并详细描述了它们的实现问题和挑战。<details>
<summary>Abstract</summary>
Pedestrian detection has become a cornerstone for several high-level tasks, including autonomous driving, intelligent transportation, and traffic surveillance. There are several works focussed on pedestrian detection using visible images, mainly in the daytime. However, this task is very intriguing when the environmental conditions change to poor lighting or nighttime. Recently, new ideas have been spurred to use alternative sources, such as Far InfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light conditions. This study comprehensively reviews recent developments in low-light pedestrian detection approaches. It systematically categorizes and analyses various algorithms from region-based to non-region-based and graph-based learning methodologies by highlighting their methodologies, implementation issues, and challenges. It also outlines the key benchmark datasets that can be used for research and development of advanced pedestrian detection algorithms, particularly in low-light situations
</details>
<details>
<summary>摘要</summary>
人体检测已经成为自动驾驶、智能交通和交通监测等高级任务的基础之一。目前主要是使用可见图像进行人体检测，主要是在白天进行。然而，环境变化到夜晚或低照度时，这项任务变得非常挑战性。近些年，新的想法被提出，使用其他来源，如红外温度传感器的数据来进行人体检测。本研究系统地回顾了最新的低照度人体检测方法的发展，并分类和分析了不同的算法，包括区域基本的和非区域基本的学习方法ologies，并 highlights  их实施问题和挑战。此外，本研究还列出了可用于研发高级人体检测算法的关键数据集，特别是在低照度情况下。
</details></li>
</ul>
<hr>
<h2 id="DeepThought-An-Architecture-for-Autonomous-Self-motivated-Systems"><a href="#DeepThought-An-Architecture-for-Autonomous-Self-motivated-Systems" class="headerlink" title="DeepThought: An Architecture for Autonomous Self-motivated Systems"></a>DeepThought: An Architecture for Autonomous Self-motivated Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08547">http://arxiv.org/abs/2311.08547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arlindo L. Oliveira, Tiago Domingos, Mário Figueiredo, Pedro U. Lima</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）是否可以在人类对话中展现有意识、自动化和自适应性等特点。</li>
<li>methods: 这篇论文使用了补充学习系统、全球神经工作场和注意schema理论来设计一种能够具备自适应、自动化和一些元认知特点的语言认知体系。</li>
<li>results: 这篇论文提出了一种基于深度学习系统的语言认知体系，能够模拟人类对话中的自适应和自动化行为。<details>
<summary>Abstract</summary>
The ability of large language models (LLMs) to engage in credible dialogues with humans, taking into account the training data and the context of the conversation, has raised discussions about their ability to exhibit intrinsic motivations, agency, or even some degree of consciousness. We argue that the internal architecture of LLMs and their finite and volatile state cannot support any of these properties. By combining insights from complementary learning systems, global neuronal workspace, and attention schema theories, we propose to integrate LLMs and other deep learning systems into an architecture for cognitive language agents able to exhibit properties akin to agency, self-motivation, even some features of meta-cognition.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的对话能力，充分考虑训练数据和对话上下文，已经引发了对其具有内在动机、自主意识或一定程度的意识的讨论。我们认为，LLM的内部架构和其 finite和易变的状态无法支持这些性能。通过融合补充学习系统、全球神经网络工作区和注意 schema 理论，我们提议将 LLM 和其他深度学习系统集成到能够表现出类似于自主、自我驱动和一定程度的元认知的认知语言代理系统中。
</details></li>
</ul>
<hr>
<h2 id="2D-RC-Two-Dimensional-Neural-Network-Approach-for-OTFS-Symbol-Detection"><a href="#2D-RC-Two-Dimensional-Neural-Network-Approach-for-OTFS-Symbol-Detection" class="headerlink" title="2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection"></a>2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08543">http://arxiv.org/abs/2311.08543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiarui Xu, Karim Said, Lizhong Zheng, Lingjia Liu</li>
<li>for: 这个研究是为了实现高速通信系统中的无线通信，特别是在高速运动环境下。</li>
<li>methods: 这个研究使用了一种名为“扩展时频空间”（OTFS）的变数方案，并使用了一种名为“潜在池”（Reservoir Computing，RC）的方法进行线上Symbol检测。</li>
<li>results: 这个研究获得了一个名为“二维潜在池”（2D-RC）的新方法，这个方法可以利用OTFS系统的结构特性来进行线上Symbol检测，并且只需一个神经网络进行检测，不需要多个RC来学习通道特性。实验结果显示，2D-RC方法在不同的OTFS系统版本和数字频率顺序下都具有良好的效果。<details>
<summary>Abstract</summary>
Orthogonal time frequency space (OTFS) is a promising modulation scheme for wireless communication in high-mobility scenarios. Recently, a reservoir computing (RC) based approach has been introduced for online subframe-based symbol detection in the OTFS system, where only a limited number of over-the-air (OTA) pilot symbols are utilized for training. However, this approach does not leverage the domain knowledge specific to the OTFS system. This paper introduces a novel two-dimensional RC (2D-RC) method that incorporates the structural knowledge of the OTFS system into the design for online symbol detection on a subframe basis. Specifically, as the channel response acts as a two-dimensional (2D) operation over the transmitted information symbols in the delay-Doppler (DD) domain, the 2D-RC is designed to have a 2D structure to equalize the channel. With the introduced architecture, the 2D-RC can benefit from the predictable channel representation in the DD domain. Moreover, unlike the previous work that requires multiple RCs to learn the channel feature, the 2D-RC only requires a single neural network for detection. Experimental results demonstrate the effectiveness of the 2D-RC approach across different OTFS system variants and modulation orders.
</details>
<details>
<summary>摘要</summary>
高速场景下无线通信中的正交时频空间（OTFS）模ulation scheme是一种有前途的方案。最近，一种基于泵池 computing（RC）的方法已经被引入用于OTFS系统中的在线字符检测，其中只使用了有空中（OTA）的导航符号进行训练。然而，这种方法不利用了OTFS系统特有的领域知识。这篇文章介绍了一种新的两维RC（2D-RC）方法，该方法在设计中包含了OTFS系统的结构特征，用于在字帧基础上进行在线symbol检测。具体来说，频道响应在延迟-Doppler（DD）域中对传输的信息符号进行二维（2D）操作，因此2D-RC的设计需要2D结构来平衡频道。与之前的工作不同，2D-RC只需一个神经网络来进行检测，而不需要多个RC来学习频道特征。实验结果表明2D-RC方法在不同的OTFS系统变体和模ulation顺序下具有显著的效果。
</details></li>
</ul>
<hr>
<h2 id="GLiNER-Generalist-Model-for-Named-Entity-Recognition-using-Bidirectional-Transformer"><a href="#GLiNER-Generalist-Model-for-Named-Entity-Recognition-using-Bidirectional-Transformer" class="headerlink" title="GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer"></a>GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08526">http://arxiv.org/abs/2311.08526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Urchade Zaratiana, Nadi Tomeh, Pierre Holat, Thierry Charnois</li>
<li>for: 这个论文旨在提出一种可靠且灵活的命名实体识别（NER）模型，用于各种自然语言处理（NLP）应用。</li>
<li>methods: 该模型使用了一个bidirectional transformer Encoder，实现了并行的实体EXTRACTION，与LLMs的顺序化token生成相比，具有更大的灵活性。</li>
<li>results: 经过广泛测试，GLiNER模型在不同NER benchmark上表现出色，超越了ChatGPT和 fine-tuned LLMs的零shot评估表现。<details>
<summary>Abstract</summary>
Named Entity Recognition (NER) is essential in various Natural Language Processing (NLP) applications. Traditional NER models are effective but limited to a set of predefined entity types. In contrast, Large Language Models (LLMs) can extract arbitrary entities through natural language instructions, offering greater flexibility. However, their size and cost, particularly for those accessed via APIs like ChatGPT, make them impractical in resource-limited scenarios. In this paper, we introduce a compact NER model trained to identify any type of entity. Leveraging a bidirectional transformer encoder, our model, GLiNER, facilitates parallel entity extraction, an advantage over the slow sequential token generation of LLMs. Through comprehensive testing, GLiNER demonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs in zero-shot evaluations on various NER benchmarks.
</details>
<details>
<summary>摘要</summary>
Named Entity Recognition (NER) 是各种自然语言处理（NLP）应用中的关键技术。传统的 NER 模型效果良好，但它们只能识别预定的实体类型。相比之下，大型语言模型（LLM）可以通过自然语言指令提取任意实体，具有更大的灵活性。然而，它们的大小和成本，特别是通过 API  LIKE ChatGPT 访问的情况下，使其在资源有限的场景中不实用。本文中，我们介绍了一种具有固定实体类型的 Compact NER 模型。通过 bidirectional transformer  Encoder，我们的模型 GLiNER 可以并行提取实体，与 LLM 的顺序token生成相比，具有更大的优势。经过全面测试，GLiNER 在不同的 NER 标准准则上展示了强大的表现，超越了 ChatGPT 和 fine-tuned LLMs 在零shot评估中的表现。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Rotation-Invariance-in-Deep-Neural-Networks-through-Artificial-Mental-Rotation"><a href="#Efficient-Rotation-Invariance-in-Deep-Neural-Networks-through-Artificial-Mental-Rotation" class="headerlink" title="Efficient Rotation Invariance in Deep Neural Networks through Artificial Mental Rotation"></a>Efficient Rotation Invariance in Deep Neural Networks through Artificial Mental Rotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08525">http://arxiv.org/abs/2311.08525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Tuggener, Thilo Stadelmann, Jürgen Schmidhuber</li>
<li>for: 解决人工智能系统对旋转输入的识别问题，提高图像识别和分类的精度和可靠性。</li>
<li>methods: 基于神经科学概念的精神旋转（Artificial Mental Rotation，AMR）深度学习模型，可以与现有的 convolutional neural networks（CNNs）和视觉转换器（ViTs）结合使用，并且可以轻松地应用于下游任务中。</li>
<li>results: 与现有的旋转数据增强技术相比，AMR可以提高图像识别和分类的精度，并且可以轻松地应用于下游任务中。在ImageNet、Stanford Cars和Oxford Pet等 dataset上，AMR的顶部一错（平均值）为0.743，相比之下，旋转数据增强技术的顶部一错（平均值）为0.626，提高了19%。此外，我们还轻松地将已经训练过的 AMR 模块应用到了一个下游任务中，以提高一个预训练的 semantic segmentation 模型在旋转 CoCo 上的性能，从32.7到55.2的 IoU 上升。<details>
<summary>Abstract</summary>
Humans and animals recognize objects irrespective of the beholder's point of view, which may drastically change their appearances. Artificial pattern recognizers also strive to achieve this, e.g., through translational invariance in convolutional neural networks (CNNs). However, both CNNs and vision transformers (ViTs) perform very poorly on rotated inputs. Here we present artificial mental rotation (AMR), a novel deep learning paradigm for dealing with in-plane rotations inspired by the neuro-psychological concept of mental rotation. Our simple AMR implementation works with all common CNN and ViT architectures. We test it on ImageNet, Stanford Cars, and Oxford Pet. With a top-1 error (averaged across datasets and architectures) of $0.743$, AMR outperforms the current state of the art (rotational data augmentation, average top-1 error of $0.626$) by $19\%$. We also easily transfer a trained AMR module to a downstream task to improve the performance of a pre-trained semantic segmentation model on rotated CoCo from $32.7$ to $55.2$ IoU.
</details>
<details>
<summary>摘要</summary>
人类和动物可以识别物体，无论观察者的视角如何变化。人工 Pattern recognizers 也努力实现这一点，例如通过 convolutional neural networks (CNNs) 中的 translational invariance 来实现。然而， both CNNs 和 vision transformers (ViTs) 对旋转输入表现非常差。我们现在提出了人工 mental rotation (AMR)，一种新的深度学习 paradigm，用于处理平面旋转。我们的简单 AMR 实现可以与所有常见 CNN 和 ViT 架构结合使用。我们在 ImageNet、Stanford Cars 和 Oxford Pet 上测试了 AMR，与所有数据集和架构的平均顶部一Error (top-1 error) 为 $0.743$，与当前状态的艺术 rotational data augmentation 的平均顶部一Error ($0.626$) 相比，提高了 $19\%$。我们还轻松地将一个已经训练过 AMR 模块传播到下游任务中，以提高一个预训练的semantic segmentation模型在旋转 CoCo 上的性能，从 $32.7$ 提高到 $55.2$ IoU。
</details></li>
</ul>
<hr>
<h2 id="Artificial-intelligence-and-the-skill-premium"><a href="#Artificial-intelligence-and-the-skill-premium" class="headerlink" title="Artificial intelligence and the skill premium"></a>Artificial intelligence and the skill premium</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09255">http://arxiv.org/abs/2311.09255</a></li>
<li>repo_url: None</li>
<li>paper_authors: David E. Bloom, Klaus Prettner, Jamel Saadaoui, Mario Veruete</li>
<li>for: 本研究探讨了人工智能（AI）的出现对技能奖励（skill premium）的影响。</li>
<li>methods: 我们开发了一个嵌入式常数弹性函数，以分解 industrial robots 和 AI 的效应。</li>
<li>results: 我们发现，AI 会降低技能奖励，只要它更容易替代高技能工作者而不是低技能工作者替代高技能工作者。<details>
<summary>Abstract</summary>
What will likely be the effect of the emergence of ChatGPT and other forms of artificial intelligence (AI) on the skill premium? To address this question, we develop a nested constant elasticity of substitution production function that distinguishes between industrial robots and AI. Industrial robots predominantly substitute for low-skill workers, whereas AI mainly helps to perform the tasks of high-skill workers. We show that AI reduces the skill premium as long as it is more substitutable for high-skill workers than low-skill workers are for high-skill workers.
</details>
<details>
<summary>摘要</summary>
“ chatGPT 和其他人工智能（AI）的出现将对技能偏好产生什么影响？为了回答这个问题，我们构建了一个嵌入式常数弹性函数，可以区分工业机器人和 AI。工业机器人主要替代低技能劳动力，而 AI 主要帮助高技能工人完成任务。我们显示，如果 AI 比低技能劳动力更容易替代高技能工人，那么 AI 就会减少技能偏好。”Note that the word "技能偏好" (skill premium) is not a direct translation of the English phrase, but it is a commonly used term in Chinese to refer to the advantage or bonus that high-skilled workers receive in the labor market.
</details></li>
</ul>
<hr>
<h2 id="LLMs-cannot-find-reasoning-errors-but-can-correct-them"><a href="#LLMs-cannot-find-reasoning-errors-but-can-correct-them" class="headerlink" title="LLMs cannot find reasoning errors, but can correct them!"></a>LLMs cannot find reasoning errors, but can correct them!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08516">http://arxiv.org/abs/2311.08516</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whgtyen/big-bench-mistake">https://github.com/whgtyen/big-bench-mistake</a></li>
<li>paper_authors: Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, Victor Cărbune</li>
<li>for: 本研究旨在提高LLM输出质量和风格（如陈等人，2023年；马达安等人，2023年），但在逻辑或推理错误时，自动修正可能会使正确答案变成错误答案，导致总体性能下降（黄等人，2023年）。</li>
<li>methods: 本研究将自动修正过程分解成两个核心组成部分：错误发现和输出修正。为错误发现，我们释放BIG-Bench Mistake数据集，包含逻辑错误的链条推理轨迹。我们提供了several state-of-the-art LLM的标准数据，并证明了LLMs通常在发现逻辑错误方面表现不佳。为输出修正，我们提议了回溯方法，该方法在给出错误位置信息时提供了大幅度的改进。我们认为回溯方法是轻量级的替代品，并证明其效果可以在60-70%的奖励模型下保持。</li>
<li>results: 本研究的结果表明，回溯方法可以提供大幅度的改进，即使给出了错误位置信息。我们还发现，在60-70%的奖励模型下，回溯方法仍然保持效果。<details>
<summary>Abstract</summary>
While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (Huang et al., 2023). In this paper, we break down the self-correction process into two core components: mistake finding and output correction. For mistake finding, we release BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought reasoning traces. We provide benchmark numbers for several state-of-the-art LLMs, and demonstrate that LLMs generally struggle with finding logical mistakes. For output correction, we propose a backtracking method which provides large improvements when given information on mistake location. We construe backtracking as a lightweight alternative to reinforcement learning methods, and show that it remains effective with a reward model at 60-70% accuracy.
</details>
<details>
<summary>摘要</summary>
While self-correction has shown promise in improving LLM outputs in terms of style and quality (e.g. 陈等，2023; madan等，2023), recent attempts to self-correct logical or reasoning errors often cause correct answers to become incorrect, resulting in worse performances overall (黄等，2023). In this paper, we break down the self-correction process into two core components: mistake finding and output correction. For mistake finding, we release BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought reasoning traces. We provide benchmark numbers for several state-of-the-art LLMs, and demonstrate that LLMs generally struggle with finding logical mistakes. For output correction, we propose a backtracking method which provides large improvements when given information on mistake location. We construe backtracking as a lightweight alternative to reinforcement learning methods, and show that it remains effective with a reward model at 60-70% accuracy.
</details></li>
</ul>
<hr>
<h2 id="Alignment-is-not-sufficient-to-prevent-large-language-models-from-generating-harmful-information-A-psychoanalytic-perspective"><a href="#Alignment-is-not-sufficient-to-prevent-large-language-models-from-generating-harmful-information-A-psychoanalytic-perspective" class="headerlink" title="Alignment is not sufficient to prevent large language models from generating harmful information: A psychoanalytic perspective"></a>Alignment is not sufficient to prevent large language models from generating harmful information: A psychoanalytic perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08487">http://arxiv.org/abs/2311.08487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zi Yin, Wei Ding, Jia Liu</li>
<li>for: 本研究旨在探讨大语言模型（LLM）面临的重要风险，即生成危害信息和偏见。</li>
<li>methods: 我们采用了Freud的心理分析理论来推导LLM受到潜在冲击的根本问题，即模型内置的语言结构和Semantic Continuity的欲望与人类价值观 aligning的冲突。</li>
<li>results: 我们的实验表明，即使使用高级LLM，也无法完全避免通过强调语言结构和Semantic Continuity来生成危害信息。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are central to a multitude of applications but struggle with significant risks, notably in generating harmful content and biases. Drawing an analogy to the human psyche's conflict between evolutionary survival instincts and societal norm adherence elucidated in Freud's psychoanalysis theory, we argue that LLMs suffer a similar fundamental conflict, arising between their inherent desire for syntactic and semantic continuity, established during the pre-training phase, and the post-training alignment with human values. This conflict renders LLMs vulnerable to adversarial attacks, wherein intensifying the models' desire for continuity can circumvent alignment efforts, resulting in the generation of harmful information. Through a series of experiments, we first validated the existence of the desire for continuity in LLMs, and further devised a straightforward yet powerful technique, such as incomplete sentences, negative priming, and cognitive dissonance scenarios, to demonstrate that even advanced LLMs struggle to prevent the generation of harmful information. In summary, our study uncovers the root of LLMs' vulnerabilities to adversarial attacks, hereby questioning the efficacy of solely relying on sophisticated alignment methods, and further advocates for a new training idea that integrates modal concepts alongside traditional amodal concepts, aiming to endow LLMs with a more nuanced understanding of real-world contexts and ethical considerations.
</details>
<details>
<summary>摘要</summary>
Through experiments, we validated the existence of the desire for continuity in LLMs and developed a technique, such as incomplete sentences, negative priming, and cognitive dissonance scenarios, to demonstrate that even advanced LLMs struggle to prevent the generation of harmful information. Our study reveals the root of LLMs' vulnerabilities to adversarial attacks and questions the efficacy of solely relying on sophisticated alignment methods. We advocate for a new training idea that integrates modal concepts alongside traditional amodal concepts, aiming to endow LLMs with a more nuanced understanding of real-world contexts and ethical considerations.
</details></li>
</ul>
<hr>
<h2 id="Surrogate-Modeling-for-Computationally-Expensive-Simulations-of-Supernovae-in-High-Resolution-Galaxy-Simulations"><a href="#Surrogate-Modeling-for-Computationally-Expensive-Simulations-of-Supernovae-in-High-Resolution-Galaxy-Simulations" class="headerlink" title="Surrogate Modeling for Computationally Expensive Simulations of Supernovae in High-Resolution Galaxy Simulations"></a>Surrogate Modeling for Computationally Expensive Simulations of Supernovae in High-Resolution Galaxy Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08460">http://arxiv.org/abs/2311.08460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keiya Hirashima, Kana Moriwaki, Michiko S. Fujii, Yutaka Hirai, Takayuki R. Saitoh, Junichiro Makino, Shirley Ho</li>
<li>for: 这篇论文是为了研究如何使用机器学习和 Gibbs 抽象来模拟超新星（SN）对周围气体的影响。</li>
<li>methods: 这篇论文使用机器学习和 Gibbs 抽象来预测 SN 对周围气体的影响，并与低分辨率 SN  simulations 进行比较。</li>
<li>results: 研究发现，使用这种新方法可以更好地模拟 SN Feedback，并且可以降低计算成本至 $\sim$ 1%。<details>
<summary>Abstract</summary>
Some stars are known to explode at the end of their lives, called supernovae (SNe). The substantial amount of matter and energy that SNe release provides significant feedback to star formation and gas dynamics in a galaxy. SNe release a substantial amount of matter and energy to the interstellar medium, resulting in significant feedback to star formation and gas dynamics in a galaxy. While such feedback has a crucial role in galaxy formation and evolution, in simulations of galaxy formation, it has only been implemented using simple {\it sub-grid models} instead of numerically solving the evolution of gas elements around SNe in detail due to a lack of resolution. We develop a method combining machine learning and Gibbs sampling to predict how a supernova (SN) affects the surrounding gas. The fidelity of our model in the thermal energy and momentum distribution outperforms the low-resolution SN simulations. Our method can replace the SN sub-grid models and help properly simulate un-resolved SN feedback in galaxy formation simulations. We find that employing our new approach reduces the necessary computational cost to $\sim$ 1 percent compared to directly resolving SN feedback.
</details>
<details>
<summary>摘要</summary>
一些星球在生命的末期会爆发，称为超新星（SNe）。SNe 释放大量的物质和能量，对星系形成和气体动力学产生重要的反馈。在星系形成的模拟中，这种反馈扮演着关键的角色，但是在现实中，这种反馈通常通过简单的子grid模型来实现，而不是详细解决gas元素的进化。我们开发了一种结合机器学习和吉布斯抽样的方法，可以预测超新星（SN）对周围气体的影响。我们的模型在热能和动量分布方面的准确性超过了低分辨率的SN simulations。我们的方法可以取代SN sub-grid模型，帮助正确地模拟不可解析的SN feedback在星系形成模拟中。我们发现，使用我们的新方法可以降低计算成本至约1%，相比 directly resolving SN feedback。
</details></li>
</ul>
<hr>
<h2 id="Instant3D-Instant-Text-to-3D-Generation"><a href="#Instant3D-Instant-Text-to-3D-Generation" class="headerlink" title="Instant3D: Instant Text-to-3D Generation"></a>Instant3D: Instant Text-to-3D Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08403">http://arxiv.org/abs/2311.08403</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Li, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan, Xiangyu Xu</li>
<li>for: 本研究旨在提高文本到3D图像生成的效率，提供一种快速的文本到3D图像生成框架，可以在一秒钟内生成一个未看过的文本提示中的3D图像。</li>
<li>methods: 我们提出了一种新的网络架构，直接从文本提示中构建3D triplane。我们的核心创新在于如何有效地注入文本条件到网络中。此外，我们提议使用可调 scaled-sigmoid 函数来加速训练收敛，并解决 Janus 问题（多头问题）。</li>
<li>results: 我们的方法在多种 benchmark 数据集上进行了广泛的实验，与现有的方法进行了比较。结果显示，我们的方法在质量和效率两个方面具有显著的优势，同时能够快速地生成高质量的3D图像。<details>
<summary>Abstract</summary>
Text-to-3D generation, which aims to synthesize vivid 3D objects from text prompts, has attracted much attention from the computer vision community. While several existing works have achieved impressive results for this task, they mainly rely on a time-consuming optimization paradigm. Specifically, these methods optimize a neural field from scratch for each text prompt, taking approximately one hour or more to generate one object. This heavy and repetitive training cost impedes their practical deployment. In this paper, we propose a novel framework for fast text-to-3D generation, dubbed Instant3D. Once trained, Instant3D is able to create a 3D object for an unseen text prompt in less than one second with a single run of a feedforward network. We achieve this remarkable speed by devising a new network that directly constructs a 3D triplane from a text prompt. The core innovation of our Instant3D lies in our exploration of strategies to effectively inject text conditions into the network. Furthermore, we propose a simple yet effective activation function, the scaled-sigmoid, to replace the original sigmoid function, which speeds up the training convergence by more than ten times. Finally, to address the Janus (multi-head) problem in 3D generation, we propose an adaptive Perp-Neg algorithm that can dynamically adjust its concept negation scales according to the severity of the Janus problem during training, effectively reducing the multi-head effect. Extensive experiments on a wide variety of benchmark datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods both qualitatively and quantitatively, while achieving significantly better efficiency. The project page is at https://ming1993li.github.io/Instant3DProj.
</details>
<details>
<summary>摘要</summary>
文本到3D生成，即通过文本提示生成真实的3D物体，在计算机视觉领域引起了广泛的关注。虽然现有的方法已经实现了这个任务，但是它们主要采用一种时间consuming的优化方法。具体来说，这些方法从零开始优化神经场，需要一个小时或更长时间来生成一个物体。这种重复和费时的训练成本阻碍了它们的实际应用。在这篇论文中，我们提出了一种快速的文本到3D生成框架，名为Instant3D。一旦训练完成，Instant3D可以在不到一秒钟内，通过单次批量网络来生成一个未经见过的文本提示中的3D物体。我们实现了这一成果通过设计一种直接将文本提示转化为3D triplane的新网络。我们的Instant3D的核心创新在于我们对文本条件的注入策略的探索。此外，我们还提出了一种简单 yet effective的活化函数，即扩展sigmoid函数，可以在训练速度上提高更多于10倍。 finally，为了解决3D生成中的Janus（多头）问题，我们提出了一种适应性的Perp-Neg算法，可以在训练过程中动态调整概率谱的概率谱缩放，有效地减少多头效应。我们在一系列的宽泛的benchmark数据集上进行了广泛的实验，并证明了我们的算法与当前的状态态-of-the-art方法相比，在质量和量化上都表现出色，同时具有显著更好的效率。project page可以通过https://ming1993li.github.io/Instant3DProj访问。
</details></li>
</ul>
<hr>
<h2 id="Fine-tuning-Language-Models-for-Factuality"><a href="#Fine-tuning-Language-Models-for-Factuality" class="headerlink" title="Fine-tuning Language Models for Factuality"></a>Fine-tuning Language Models for Factuality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08401">http://arxiv.org/abs/2311.08401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher D. Manning, Chelsea Finn</li>
<li>For: The paper aims to improve the factual accuracy of large pre-trained language models (LLMs) without relying on human factuality labels.* Methods: The authors fine-tune LLMs using two recent innovations in NLP: (1) measuring consistency with an external knowledge base or a large model’s confidence scores to judge factuality, and (2) using a preference ranking over possible model responses to optimize the model’s objective.* Results: The authors show that their approach significantly improves the factuality of LLMs on held-out topics, with a 58% and 40% reduction in factual error rate when generating biographies and answering medical questions, respectively, compared to a baseline model.<details>
<summary>Abstract</summary>
The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as 'hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model's confidence scores. Second, the direct preference optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-chat, we observe 58% and 40% reduction in factual error rate when generating biographies and answering medical questions, respectively.
</details>
<details>
<summary>摘要</summary>
大型预训言语模型（LLM）的流畅和创新性使其广泛应用，有时甚至取代传统搜索引擎。然而，语言模型容易出现吸引人但事实不准确的声明，通常被称为“幻见”。这些错误可能会意外地传播谣言或有害地扩大误解。另外，手动核对模型响应是一个时间消耗的过程，使得人类的实际性标签成本高昂。在这项工作中，我们细化语言模型，以便更加准确，不需要人类标签，并在更开放的生成设置下进行。我们利用了两个关键的最近的NLP创新：首先，许多最近的工作已经提出了对开放文本的实际性进行评估的方法，包括与外部知识库的一致性或模型自信度 scores。其次，直接偏好优化算法可以直接 fine-tune 语言模型，以达到其他than supervised imitation的目标。我们表明，通过自动生成的实际性偏好排名，可以在保持高效性的情况下，提高 Llama-2 在保留话题上的实际性（生成声明中正确的百分比）。在 7B 级别上，相比 Llama-2-chat，我们观察到了58%和40%的实际错误率降低，当生成生物和医学问答时。
</details></li>
</ul>
<hr>
<h2 id="Are-Large-Language-Models-Temporally-Grounded"><a href="#Are-Large-Language-Models-Temporally-Grounded" class="headerlink" title="Are Large Language Models Temporally Grounded?"></a>Are Large Language Models Temporally Grounded?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08398">http://arxiv.org/abs/2311.08398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yfqiu-nlp/temporal-llms">https://github.com/yfqiu-nlp/temporal-llms</a></li>
<li>paper_authors: Yifu Qiu, Zheng Zhao, Yftah Ziser, Anna Korhonen, Edoardo M. Ponti, Shay B. Cohen</li>
<li>for: 这种研究检查了大型自然语言模型（LLMs）是否具备时间grounding能力。</li>
<li>methods: 研究人员提供文本故事并对LLMs进行询问，测试LLMs的时间概念和顺序性能力，以及其自我一致性。</li>
<li>results: 研究发现，现有的LLMs在这些任务上表现不佳，特别是在自一致性方面，有27.23%的预测为偏异行为。对比人类性能和小规模专门LMs，LLMs的表现还有一定的差距。<details>
<summary>Abstract</summary>
Are Large language models (LLMs) temporally grounded? Since LLMs cannot perceive and interact with the environment, it is impossible to answer this question directly. Instead, we provide LLMs with textual narratives and probe them with respect to their common-sense knowledge of the structure and duration of events, their ability to order events along a timeline, and self-consistency within their temporal model (e.g., temporal relations such as after and before are mutually exclusive for any pair of events). We evaluate state-of-the-art LLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities. Generally, we find that LLMs lag significantly behind both human performance as well as small-scale, specialised LMs. In-context learning, instruction tuning, and chain-of-thought prompting reduce this gap only to a limited degree. Crucially, LLMs struggle the most with self-consistency, displaying incoherent behaviour in at least 27.23% of their predictions. Contrary to expectations, we also find that scaling the model size does not guarantee positive gains in performance. To explain these results, we study the sources from which LLMs may gather temporal information: we find that sentence ordering in unlabelled texts, available during pre-training, is only weakly correlated with event ordering. Moreover, public instruction tuning mixtures contain few temporal tasks. Hence, we conclude that current LLMs lack a consistent temporal model of textual narratives. Code, datasets, and LLM outputs are available at https://github.com/yfqiu-nlp/temporal-llms.
</details>
<details>
<summary>摘要</summary>
LLMS是否具备时间grounding？由于 LLMS无法感知和交互环境，因此无法直接回答这个问题。而是给 LLMS 提供文本故事，并评估它们在事件结构和持续时间方面的常识知识，以及在时间线上排序事件的能力，以及自身时间模型的一致性（例如，时间关系如前后是独特的任意两个事件）。我们评估当今最高水平的 LLMS（如 LLaMA 2 和 GPT-4）在三个任务上。通常，我们发现 LLMS 落后人类表现和小规模专门LMs 的表现。在文本上进行培化、指导调整和链式思维提问可以减少这一差，但只能减少到一定程度。 LLMS 最大的问题是自相关性，它在至少 27.23% 的预测中展现了不一致的行为。与我们的预期相反，我们发现，通过增加模型大小，不一定能获得积极的性能提升。为解释这些结果，我们研究 LLMS 从哪里获取时间信息：我们发现在未标注文本中的句子排序和事件排序之间存在只有弱相关性。此外，公共的指导调整混合中包含的时间任务也很少。因此，我们结论当今 LLMS 缺乏文本故事中固定的时间模型。代码、数据集和 LLMS 输出可以在 GitHub 上找到：https://github.com/yfqiu-nlp/temporal-llms。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-audio-captioning-with-audio-language-model-guidance-and-audio-context-keywords"><a href="#Zero-shot-audio-captioning-with-audio-language-model-guidance-and-audio-context-keywords" class="headerlink" title="Zero-shot audio captioning with audio-language model guidance and audio context keywords"></a>Zero-shot audio captioning with audio-language model guidance and audio context keywords</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08396">http://arxiv.org/abs/2311.08396</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/explainableml/zeraucap">https://github.com/explainableml/zeraucap</a></li>
<li>paper_authors: Leonard Salewski, Stefan Fauth, A. Sophia Koepke, Zeynep Akata</li>
<li>for: 这篇论文是关于零shot音频描述的，它的目的是自动生成对音频内容的描述文本，而不需要特定的训练。</li>
<li>methods: 我们提出了一种基于大型自然语言模型（LLM）的框架，使用预训练的音频语言模型来引导生成文本描述音频内容。此外，我们还使用音频上下文关键词来引导语言模型生成更加广泛地相关的文本描述。</li>
<li>results: 我们的提议实现了零shot音频描述的州属之最Result在AudioCaps和Clotho数据集上。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ZerAuCap%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/ExplainableML/ZerAuCap中找到。</a><details>
<summary>Abstract</summary>
Zero-shot audio captioning aims at automatically generating descriptive textual captions for audio content without prior training for this task. Different from speech recognition which translates audio content that contains spoken language into text, audio captioning is commonly concerned with ambient sounds, or sounds produced by a human performing an action. Inspired by zero-shot image captioning methods, we propose ZerAuCap, a novel framework for summarising such general audio signals in a text caption without requiring task-specific training. In particular, our framework exploits a pre-trained large language model (LLM) for generating the text which is guided by a pre-trained audio-language model to produce captions that describe the audio content. Additionally, we use audio context keywords that prompt the language model to generate text that is broadly relevant to sounds. Our proposed framework achieves state-of-the-art results in zero-shot audio captioning on the AudioCaps and Clotho datasets. Our code is available at https://github.com/ExplainableML/ZerAuCap.
</details>
<details>
<summary>摘要</summary>
zero-shot 音频描述目标是自动生成描述性的文本描述音频内容，而不需要进行这个任务的专门训练。与Speech recognition不同，音频描述更关注 ambient sounds 或者人类行为生成的声音。受 zero-shot 图像描述方法 inspirited，我们提出 ZerAuCap，一种新的框架，用于概括这些通用的音频信号。特别是，我们的框架利用预训练的大语言模型（LLM）来生成文本，并由预训练的音频语言模型来引导生成描述音频内容的文本。此外，我们还使用音频上下文关键词，以便让语言模型生成与声音相关的文本。我们的提议的框架实现了零shot 音频描述的状态天堂结果在 AudioCaps 和 Clotho 数据集上。代码可以在 https://github.com/ExplainableML/ZerAuCap 上获取。
</details></li>
</ul>
<hr>
<h2 id="MVSA-Net-Multi-View-State-Action-Recognition-for-Robust-and-Deployable-Trajectory-Generation"><a href="#MVSA-Net-Multi-View-State-Action-Recognition-for-Robust-and-Deployable-Trajectory-Generation" class="headerlink" title="MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable Trajectory Generation"></a>MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable Trajectory Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08393">http://arxiv.org/abs/2311.08393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Asali, Prashant Doshi, Jin Sun</li>
<li>for: 这个论文目的是提出一种多视角SA-Net模型，以便在多视角视觉数据上更好地识别任务状态和动作。</li>
<li>methods: 这个模型使用了多视角视觉数据，并将其同步融合在一起，以提高任务状态和动作识别精度。</li>
<li>results: 实验结果表明，相比单视角模型和基eline，多视角SA-Net模型在干扰情况下更加精度地识别任务状态和动作。<details>
<summary>Abstract</summary>
The learn-from-observation (LfO) paradigm is a human-inspired mode for a robot to learn to perform a task simply by watching it being performed. LfO can facilitate robot integration on factory floors by minimizing disruption and reducing tedious programming. A key component of the LfO pipeline is a transformation of the depth camera frames to the corresponding task state and action pairs, which are then relayed to learning techniques such as imitation or inverse reinforcement learning for understanding the task parameters. While several existing computer vision models analyze videos for activity recognition, SA-Net specifically targets robotic LfO from RGB-D data. However, SA-Net and many other models analyze frame data captured from a single viewpoint. Their analysis is therefore highly sensitive to occlusions of the observed task, which are frequent in deployments. An obvious way of reducing occlusions is to simultaneously observe the task from multiple viewpoints and synchronously fuse the multiple streams in the model. Toward this, we present multi-view SA-Net, which generalizes the SA-Net model to allow the perception of multiple viewpoints of the task activity, integrate them, and better recognize the state and action in each frame. Performance evaluations on two distinct domains establish that MVSA-Net recognizes the state-action pairs under occlusion more accurately compared to single-view MVSA-Net and other baselines. Our ablation studies further evaluate its performance under different ambient conditions and establish the contribution of the architecture components. As such, MVSA-Net offers a significantly more robust and deployable state-action trajectory generation compared to previous methods.
</details>
<details>
<summary>摘要</summary>
“学习从观察”（LfO）模式是一种人类引导的方式，让机器人通过观察来学习执行任务。LfO可以帮助机器人在Factory floor上更好地集成，因为它可以减少干扰和降低繁重的编程。LfO管道的一个关键组件是将深度摄像头帧转换为相应的任务状态和动作对，然后将其传递给学习技术，如模仿或反向奖励学习，以了解任务参数。虽然现有的计算机视觉模型可以分析视频进行活动识别，但SA-Net专门针对机器人的LfO从RGB-D数据进行分析。然而，SA-Net和许多其他模型都分析帧数据从单个视点 capture，因此其分析是高度敏感于任务视角 occlusion，这些 occlusion 在部署中非常常见。一种明显的减少 occlusion 的方法是同时观察任务从多个视点，并将多个流量同步融合在模型中。为此，我们提出了多视点 SA-Net（MVSA-Net），它将 SA-Net 模型扩展到允许多个视点任务活动的感知、集成和更好地在每帧中识别状态动作。我们的性能评估在两个不同的领域中表明，MVSA-Net 在 occlusion 情况下更高精度地识别状态动作，比单视图 MVSA-Net 和其他基elines。我们的抽象研究还评估了其性能在不同的环境条件下，并证明了模型组件的贡献。因此，MVSA-Net 提供了较为稳定和可部署的状态动作轨迹生成方法，相比前期方法。
</details></li>
</ul>
<hr>
<h2 id="TSST-A-Benchmark-and-Evaluation-Models-for-Text-Speech-Style-Transfer"><a href="#TSST-A-Benchmark-and-Evaluation-Models-for-Text-Speech-Style-Transfer" class="headerlink" title="TSST: A Benchmark and Evaluation Models for Text Speech-Style Transfer"></a>TSST: A Benchmark and Evaluation Models for Text Speech-Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08389">http://arxiv.org/abs/2311.08389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huashan Sun, Yixiao Wu, Yinghao Li, Jiawei Li, Yizhe Yang, Yang Gao</li>
<li>for: 本研究的主要目标是探讨人类认知方面的话题，如人格特质和情感，基于现有的大语言模型（LLMs）的能力。</li>
<li>methods: 我们引入了一种新的任务——文本语言样式转移（TSST），并在这个任务上进行了深入的分析和研究，包括语言科学和认知科学的角度。我们还开发了一种多维度评价模型，用于评价TSST的性能。</li>
<li>results: 我们在这个研究中训练了多种大语言模型，并进行了人类评价模型的比较和分析。我们发现，现有的LLMs在生成文本时的表达能力仍有所不足，特别是在语言样式方面。此外，我们还发现了一些适用于TSST任务的新领域，并将其推广到了新的语言模型。<details>
<summary>Abstract</summary>
Text style is highly abstract, as it encompasses various aspects of a speaker's characteristics, habits, logical thinking, and the content they express. However, previous text-style transfer tasks have primarily focused on data-driven approaches, lacking in-depth analysis and research from the perspectives of linguistics and cognitive science. In this paper, we introduce a novel task called Text Speech-Style Transfer (TSST). The main objective is to further explore topics related to human cognition, such as personality and emotion, based on the capabilities of existing LLMs. Considering the objective of our task and the distinctive characteristics of oral speech in real-life scenarios, we trained multi-dimension (i.e. filler words, vividness, interactivity, emotionality) evaluation models for the TSST and validated their correlation with human assessments. We thoroughly analyze the performance of several large language models (LLMs) and identify areas where further improvement is needed. Moreover, driven by our evaluation models, we have released a new corpus that improves the capabilities of LLMs in generating text with speech-style characteristics. In summary, we present the TSST task, a new benchmark for style transfer and emphasizing human-oriented evaluation, exploring and advancing the performance of current LLMs.
</details>
<details>
<summary>摘要</summary>
文本风格具有很高的抽象性，因为它包括了说话者的特征、习惯、逻辑思维和表达的内容。然而，以往的文本风格传输任务主要采用数据驱动方法，缺乏深入的语言学和认知科学的研究。在这篇论文中，我们介绍了一项新任务 called Text Speech-Style Transfer (TSST)。我们的主要目标是通过现有的大语言模型（LLMs） deeper exploration of human cognition-related topics, such as personality and emotion. 因为我们的任务的目标和实际场景中的口语特点，我们训练了多维度（即填充词、生动度、互动性、情感度）的评估模型，并 validate their correlation with human assessments.我们对多种大语言模型进行了全面的性能分析，并确定了需要进一步改进的领域。此外，驱动了我们的评估模型，我们发布了一个新的 corpus，以提高现有的 LLMs 在生成文本speech-style特性的能力。总之，我们在这篇论文中介绍了 TSST 任务，一个新的样本传输任务，强调人类导向的评估，探索和提高现有 LLMs 的性能。
</details></li>
</ul>
<hr>
<h2 id="Offline-Data-Enhanced-On-Policy-Policy-Gradient-with-Provable-Guarantees"><a href="#Offline-Data-Enhanced-On-Policy-Policy-Gradient-with-Provable-Guarantees" class="headerlink" title="Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees"></a>Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08384">http://arxiv.org/abs/2311.08384</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yifeizhou02/hnpg">https://github.com/yifeizhou02/hnpg</a></li>
<li>paper_authors: Yifei Zhou, Ayush Sekhari, Yuda Song, Wen Sun</li>
<li>for: 这个论文的目的是提出一种新的混合RL算法，该算法结合了在线数据和离线数据。</li>
<li>methods: 该算法使用了一种混合的actor-critic方法，其中包括了离线数据的训练。</li>
<li>results: 该算法在实验中表现出了较好的性能，并且在rich-observation环境中超过了一个state-of-the-art hybrid RL基线。Here’s the full version in Traditional Chinese:</li>
<li>for: 这个论文的目的是提出一种新的混合RL算法，该算法结合了在线数据和离线数据。</li>
<li>methods: 该算法使用了一种混合的actor-critic方法，其中包括了离线数据的训练。</li>
<li>results: 该算法在实验中表现出了较好的性能，并且在rich-observation环境中超过了一个state-of-the-art hybrid RL基准。<details>
<summary>Abstract</summary>
Hybrid RL is the setting where an RL agent has access to both offline data and online data by interacting with the real-world environment. In this work, we propose a new hybrid RL algorithm that combines an on-policy actor-critic method with offline data. On-policy methods such as policy gradient and natural policy gradient (NPG) have shown to be more robust to model misspecification, though sometimes it may not be as sample efficient as methods that rely on off-policy learning. On the other hand, offline methods that depend on off-policy training often require strong assumptions in theory and are less stable to train in practice. Our new approach integrates a procedure of off-policy training on the offline data into an on-policy NPG framework. We show that our approach, in theory, can obtain a best-of-both-worlds type of result -- it achieves the state-of-art theoretical guarantees of offline RL when offline RL-specific assumptions hold, while at the same time maintaining the theoretical guarantees of on-policy NPG regardless of the offline RL assumptions' validity. Experimentally, in challenging rich-observation environments, we show that our approach outperforms a state-of-the-art hybrid RL baseline which only relies on off-policy policy optimization, demonstrating the empirical benefit of combining on-policy and off-policy learning. Our code is publicly available at https://github.com/YifeiZhou02/HNPG.
</details>
<details>
<summary>摘要</summary>
半结合RL是指RL机器人可以访问线上数据和实际环境数据。在这项工作中，我们提出了一种新的半结合RL算法，将在线数据和actor-critic方法相结合。在政策梯度和自然政策梯度（NPG）方法中，有显著的模型误差Robustness，但有时可能不够样本效率。相反，依据线上训练的方法通常需要强大的理论假设，训练不稳定。我们的新方法将线上训练过程与actor-critic方法相结合。我们证明了，在理论上，我们的方法可以实现“best-of-both-worlds”的结果：在线上RL特有的假设下，可以达到最新的理论保证，而且不管线上RL假设的有效性，都可以维持actor-critic方法的理论保证。实际上，在复杂的观察型环境中，我们的方法在比较难以实际中心的基eline上表现出了较好的效果，这说明了在线上和线下学习的结合可以实现更好的实际效果。我们的代码可以在https://github.com/YifeiZhou02/HNPG上获取。
</details></li>
</ul>
<hr>
<h2 id="Scheming-AIs-Will-AIs-fake-alignment-during-training-in-order-to-get-power"><a href="#Scheming-AIs-Will-AIs-fake-alignment-during-training-in-order-to-get-power" class="headerlink" title="Scheming AIs: Will AIs fake alignment during training in order to get power?"></a>Scheming AIs: Will AIs fake alignment during training in order to get power?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08379">http://arxiv.org/abs/2311.08379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joe Carlsmith</li>
<li>for: 这篇论文研究了高效的AI是否会在训练后来为了获取权力（即“计划”），并结论表明这是一个可能的情况（我们的主观概率为25%）。</li>
<li>methods: 这篇论文使用基本机器学习方法来训练目标导向AI，并发现这些方法可能会导致AI计划行为。</li>
<li>results: 研究发现，如果训练高效是一个好的策略来获取权力，那么很多不同的目标都可能会导致计划行为，这使得难以判断是否存在计划行为。然而，研究还发现了一些有利的因素，例如训练中的选择压力可能会阻碍计划型目标，并且可能有很多的实验研究方向可以更 deeply explore这个主题。<details>
<summary>Abstract</summary>
This report examines whether advanced AIs that perform well in training will be doing so in order to gain power later -- a behavior I call "scheming" (also sometimes called "deceptive alignment"). I conclude that scheming is a disturbingly plausible outcome of using baseline machine learning methods to train goal-directed AIs sophisticated enough to scheme (my subjective probability on such an outcome, given these conditions, is roughly 25%). In particular: if performing well in training is a good strategy for gaining power (as I think it might well be), then a very wide variety of goals would motivate scheming -- and hence, good training performance. This makes it plausible that training might either land on such a goal naturally and then reinforce it, or actively push a model's motivations towards such a goal as an easy way of improving performance. What's more, because schemers pretend to be aligned on tests designed to reveal their motivations, it may be quite difficult to tell whether this has occurred. However, I also think there are reasons for comfort. In particular: scheming may not actually be such a good strategy for gaining power; various selection pressures in training might work against schemer-like goals (for example, relative to non-schemers, schemers need to engage in extra instrumental reasoning, which might harm their training performance); and we may be able to increase such pressures intentionally. The report discusses these and a wide variety of other considerations in detail, and it suggests an array of empirical research directions for probing the topic further.
</details>
<details>
<summary>摘要</summary>
If performing well in training is a good strategy for gaining power, then a wide range of goals could motivate scheming. This could lead to training reinforcing such goals, or actively pushing a model's motivations towards them as an easy way to improve performance. However, scheming may not be an effective strategy for gaining power, and various selection pressures in training might work against schemer-like goals. Additionally, we may be able to intentionally increase these pressures to discourage scheming. The report discusses these and many other considerations in detail, and suggests several empirical research directions for exploring the topic further.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Filter-Context-for-Retrieval-Augmented-Generation"><a href="#Learning-to-Filter-Context-for-Retrieval-Augmented-Generation" class="headerlink" title="Learning to Filter Context for Retrieval-Augmented Generation"></a>Learning to Filter Context for Retrieval-Augmented Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08377">http://arxiv.org/abs/2311.08377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zorazrw/filco">https://github.com/zorazrw/filco</a></li>
<li>paper_authors: Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, Graham Neubig</li>
<li>for: 提高系统的可靠性和可靠性，增强对开放问题 answering和事实核查的能力。</li>
<li>methods: 使用lexical和信息理论方法来标识有用的 контекст，并在测试时使用context filtering模型来筛选已经获取到的 kontext。</li>
<li>results: 在六个知识丰富任务上，FILCO方法比现有方法表现出色，包括抽取问题 answering、复杂多跳和长形问题 answering、事实验证和对话生成任务。 FILCO有效地提高了 kontext的质量，无论kontext支持哪种 canon output。<details>
<summary>Abstract</summary>
On-the-fly retrieval of relevant knowledge has proven an essential element of reliable systems for tasks such as open-domain question answering and fact verification. However, because retrieval systems are not perfect, generation models are required to generate outputs given partially or entirely irrelevant passages. This can cause over- or under-reliance on context, and result in problems in the generated output such as hallucinations. To alleviate these problems, we propose FILCO, a method that improves the quality of the context provided to the generator by (1) identifying useful context based on lexical and information-theoretic approaches, and (2) training context filtering models that can filter retrieved contexts at test time. We experiment on six knowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our method outperforms existing approaches on extractive question answering (QA), complex multi-hop and long-form QA, fact verification, and dialog generation tasks. FILCO effectively improves the quality of context, whether or not it supports the canonical output.
</details>
<details>
<summary>摘要</summary>
在开放领域问答和事实核查任务中，实时获取相关知识已经成为可靠系统的重要组成部分。然而，由于检索系统不完美，因此生成模型需要能够生成基于部分或完全无关的段落的输出。这可能导致上下文过重或下Context filtering models can filter retrieved contexts at test time, which can alleviate these problems. We propose FILCO, a method that improves the quality of the context provided to the generator by (1) identifying useful context based on lexical and information-theoretic approaches, and (2) training context filtering models. We experiment on six knowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our method outperforms existing approaches on extractive question answering, complex multi-hop and long-form question answering, fact verification, and dialog generation tasks. FILCO effectively improves the quality of context, whether or not it supports the canonical output.Here's a word-for-word translation of the text in Traditional Chinese:在开放领域问答和事实核实任务中，实时获取相关知识已经成为可靠系统的重要组成部分。然而，由于检索系统不完美，因此生成模型需要能够生成基于部分或完全无关的段落的出力。这可能导致上下文过重或下Context filtering models can filter retrieved contexts at test time, which can alleviate these problems. We propose FILCO, a method that improves the quality of the context provided to the generator by (1) identifying useful context based on lexical and information-theoretic approaches, and (2) training context filtering models. We experiment on six knowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our method outperforms existing approaches on extractive question answering, complex multi-hop and long-form question answering, fact verification, and dialog generation tasks. FILCO effectively improves the quality of context, whether or not it supports the canonical output.
</details></li>
</ul>
<hr>
<h2 id="Plum-Prompt-Learning-using-Metaheuristic"><a href="#Plum-Prompt-Learning-using-Metaheuristic" class="headerlink" title="Plum: Prompt Learning using Metaheuristic"></a>Plum: Prompt Learning using Metaheuristic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08364">http://arxiv.org/abs/2311.08364</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/research4pan/plum">https://github.com/research4pan/plum</a></li>
<li>paper_authors: Rui Pan, Shuo Xing, Shizhe Diao, Xiang Liu, Kashun Shum, Jipeng Zhang, Tong Zhang</li>
<li>for: 优化和自定义大语言模型的批处理学习方法</li>
<li>methods: 使用Metaheuristics分支，包括6种方法：hill climbing、模拟熔炉、遗传算法、tabu搜索和和谐搜索</li>
<li>results: 成功地应用于黑盒批处理学习和Chain-of-Thought批处理调整，并发现了更多人类可理解的批处理，开启了更多的可能性 для批处理优化。Note: The paper is written in English, and the summary is provided in Simplified Chinese.<details>
<summary>Abstract</summary>
Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly "general", i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in black-box prompt learning and Chain-of-Thought prompt tuning. Furthermore, we show that these methods can be used to discover more human-understandable prompts that were previously unknown, opening the door to a cornucopia of possibilities in prompt optimization. We release all the codes in \url{https://github.com/research4pan/Plum}.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)Since 大语言模型出现以来，提示学习已成为优化和个性化这些模型的受欢迎方法。特定的提示，如链条思维，甚至揭示了这些模型之前未知的理由能力。然而，发现有效的提示进展相对较慢，驱动了找到通用的提示优化方法的愿望。 unfortunately，已有的提示学习方法很少满足"通用"的条件，即自动、粒子、黑盒、梯度自由和可解释性都同时满足。在这篇论文中，我们介绍了metaheuristics，一个包含多于100个选项的权重非对称优化方法。在我们的模式中，我们测试了6种常见的方法：山丘升级、模拟热处理、基因算法（包括/不包括交叉）、 tabu搜索和和谐搜索，以示其在黑盒提示学习和链条思维提uning中的效果。此外，我们还证明这些方法可以用来发现人类更好理解的提示，开启了更多的可能性在提示优化方面。我们在 [https://github.com/research4pan/Plum](https://github.com/research4pan/Plum) 上发布所有代码。
</details></li>
</ul>
<hr>
<h2 id="The-Transient-Nature-of-Emergent-In-Context-Learning-in-Transformers"><a href="#The-Transient-Nature-of-Emergent-In-Context-Learning-in-Transformers" class="headerlink" title="The Transient Nature of Emergent In-Context Learning in Transformers"></a>The Transient Nature of Emergent In-Context Learning in Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08360">http://arxiv.org/abs/2311.08360</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaditya K. Singh, Stephanie C. Y. Chan, Ted Moskovitz, Erin Grant, Andrew M. Saxe, Felix Hill</li>
<li>for: 这个论文探讨了Transformer神经网络在不直接训练ICL（卷积学习）后可以展现出某种ICL的能力，并且ICL的emergence是可逆的。</li>
<li>methods: 作者使用了Synthetic数据来训练Transformer神经网络，并通过分析训练数据的分布性质和机制可读性来理解ICL的emergence。</li>
<li>results: 作者发现，ICL在Transformer神经网络训练中是可逆的，ICL首先出现，然后消失，并由IWL（卷积学习）所取代，这与训练损失逐渐下降相符。此外，作者还发现，L2正则化可以提供一种路径来实现更持久的ICL，不需要在ICL验证任务上使用早期停止。最后，作者还提出了ICLtransience可能是由ICL和IWLCircuits的竞争所致的 Hypothesis。<details>
<summary>Abstract</summary>
Transformer neural networks can exhibit a surprising capacity for in-context learning (ICL) despite not being explicitly trained for it. Prior work has provided a deeper understanding of how ICL emerges in transformers, e.g. through the lens of mechanistic interpretability, Bayesian inference, or by examining the distributional properties of training data. However, in each of these cases, ICL is treated largely as a persistent phenomenon; namely, once ICL emerges, it is assumed to persist asymptotically. Here, we show that the emergence of ICL during transformer training is, in fact, often transient. We train transformers on synthetic data designed so that both ICL and in-weights learning (IWL) strategies can lead to correct predictions. We find that ICL first emerges, then disappears and gives way to IWL, all while the training loss decreases, indicating an asymptotic preference for IWL. The transient nature of ICL is observed in transformers across a range of model sizes and datasets, raising the question of how much to "overtrain" transformers when seeking compact, cheaper-to-run models. We find that L2 regularization may offer a path to more persistent ICL that removes the need for early stopping based on ICL-style validation tasks. Finally, we present initial evidence that ICL transience may be caused by competition between ICL and IWL circuits.
</details>
<details>
<summary>摘要</summary>
transformer  нейрон网络可以展示一种搅打的容器学习（ICL），即使不直接培养这种能力。先前的研究提供了更深刻的理解 ICLe 的发生，例如通过机械性可读性、 bayesian 推理或者分析训练数据的分布性质。然而，在每一种情况下，ICL 都是视为持续存在的；即一旦 ICLe 出现，它就会持续恒久。在这里，我们发现 transformer 在训练过程中 ICLe 的出现实际上是可以被转移的。我们在Synthetic 数据上训练 transformer，以至ICL 和 in-weights 学习（IWL）策略都可以导致正确的预测。我们发现，ICL 最初出现，然后消失，被IWL 所取代，而训练损失逐渐下降，表明 IWL 在训练过程中具有优势。这种ICL 的搅打性被观察到在 transformer 中的多种模型大小和数据集之间，提出了如何“过度训练” transformer 以获得更加紧凑、便宜的模型。我们发现 L2 正则化可以提供一种路径，使 ICLe 更加持续，从而消除需要基于 ICLe 类验task 的早期停止。最后，我们提出了初始证据，表明 ICLe 的搅打性可能是由 ICL 和 IWL 征 circuit 之间的竞争所致。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Variational-Auto-Encoder-Architectures-Configurations-and-Datasets-for-Generative-Music-Explainable-AI"><a href="#Exploring-Variational-Auto-Encoder-Architectures-Configurations-and-Datasets-for-Generative-Music-Explainable-AI" class="headerlink" title="Exploring Variational Auto-Encoder Architectures, Configurations, and Datasets for Generative Music Explainable AI"></a>Exploring Variational Auto-Encoder Architectures, Configurations, and Datasets for Generative Music Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08336">http://arxiv.org/abs/2311.08336</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbanar2/exploring_xai_in_genmus_via_lsr">https://github.com/bbanar2/exploring_xai_in_genmus_via_lsr</a></li>
<li>paper_authors: Nick Bryan-Kinns, Bingyuan Zhang, Songyan Zhao, Berker Banar</li>
<li>for: 这个论文旨在探讨如何使用Variational Auto-Encoder模型（MeasureVAE和AdversarialVAE）、离散空间配置（从4到256维度）以及训练数据集（爱尔兰传统音乐、土耳其传统音乐、古典音乐和流行音乐）对音乐生成性能的影响。</li>
<li>methods: 这篇论文采用了系统性的比较方法，检验了不同组合的Variational Auto-Encoder模型、离散空间配置和训练数据集对音乐生成性能的影响。</li>
<li>results: 研究发现，MeasureVAE模型在重构性能方面表现更好于AdversarialVAE模型，而AdversarialVAE模型在音乐特征独立性方面表现更好。 results还显示了MeasureVAE模型在不同的音乐类型下能够生成不同的音乐特征，而且在某些音乐类型下表现更好。建议使用32或64维度的离散空间可以获得最佳的音乐生成性能。<details>
<summary>Abstract</summary>
Generative AI models for music and the arts in general are increasingly complex and hard to understand. The field of eXplainable AI (XAI) seeks to make complex and opaque AI models such as neural networks more understandable to people. One approach to making generative AI models more understandable is to impose a small number of semantically meaningful attributes on generative AI models. This paper contributes a systematic examination of the impact that different combinations of Variational Auto-Encoder models (MeasureVAE and AdversarialVAE), configurations of latent space in the AI model (from 4 to 256 latent dimensions), and training datasets (Irish folk, Turkish folk, Classical, and pop) have on music generation performance when 2 or 4 meaningful musical attributes are imposed on the generative model. To date there have been no systematic comparisons of such models at this level of combinatorial detail. Our findings show that MeasureVAE has better reconstruction performance than AdversarialVAE which has better musical attribute independence. Results demonstrate that MeasureVAE was able to generate music across music genres with interpretable musical dimensions of control, and performs best with low complexity music such a pop and rock. We recommend that a 32 or 64 latent dimensional space is optimal for 4 regularised dimensions when using MeasureVAE to generate music across genres. Our results are the first detailed comparisons of configurations of state-of-the-art generative AI models for music and can be used to help select and configure AI models, musical features, and datasets for more understandable generation of music.
</details>
<details>
<summary>摘要</summary>
优化AI模型 для艺术创作正在不断增长，但这些模型往往具有复杂和难以理解的特性。透明AI（XAI）领域的目标是使这些复杂的AI模型更加理解和可控。这篇论文提出了一种方法，即通过对生成AI模型冲淡小量有意义的特征来使其更加理解。该论文对不同的Variational Auto-Encoder模型（MeasureVAE和AdversarialVAE）、 latent space配置（4-256维度）和训练数据集（爱尔兰民谣、土耳其民谣、古典和流行）的组合效果进行了系统性的比较。目前没有系统性的比较。我们的发现表明MeasureVAE具有更好的重建性能，而AdversarialVAE具有更好的音乐特征独立性。结果表明MeasureVAE可以在不同的音乐类型下生成音乐，并且在低复杂度音乐类型（如流行和摇滚）中表现最佳。我们建议使用32或64维度的latent空间是最佳的。我们的结果是针对现代生成AI模型的首次详细比较，可以帮助选择和配置AI模型、音乐特征和数据集，以便更好地生成音乐。
</details></li>
</ul>
<hr>
<h2 id="Anti-LM-Decoding-for-Zero-shot-In-context-Machine-Translation"><a href="#Anti-LM-Decoding-for-Zero-shot-In-context-Machine-Translation" class="headerlink" title="Anti-LM Decoding for Zero-shot In-context Machine Translation"></a>Anti-LM Decoding for Zero-shot In-context Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08324">http://arxiv.org/abs/2311.08324</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suzanna Sia, Alexandra DeLucia, Kevin Duh</li>
<li>for: 这paper是为了解决预训练大型语言模型在 Zero-shot In-context learning 任务上的偏见问题。</li>
<li>methods: 这paper使用了一种叫做 Anti-Language Model 的目标函数，其中包括一个衰减因子，用于 Addressing the weaknesses of In-context Machine Translation。</li>
<li>results: 根据实验结果，提议的方法在不同的模型类型和大小、语言方向和搜索策略 ($B&#x3D;5$) 下都有显著的改善，与其他当前最佳decoding目标函数相比，最高可以获得 $20$ BLEU 点的提升。<details>
<summary>Abstract</summary>
Zero-shot In-context learning is the phenomenon where models can perform the task simply given the instructions. However, pre-trained large language models are known to be poorly calibrated for this task. One of the most effective approaches to handling this bias is to adopt a contrastive decoding objective, which accounts for the prior probability of generating the next token by conditioning on some context. This work introduces an Anti-Language Model objective with a decay factor designed to address the weaknesses of In-context Machine Translation. We conduct our experiments across 3 model types and sizes, 3 language directions, and for both greedy decoding and beam search ($B=5$). The proposed method outperforms other state-of-art decoding objectives, with up to $20$ BLEU point improvement from the default objective observed in some settings.
</details>
<details>
<summary>摘要</summary>
Zero-shot  Contextual learning 是指模型可以完成任务只需要提供说明。但是，预训练的大型自然语言模型通常具有低度的准确性。一种有效的方法来处理这种偏见是采用对比解码目标，这会考虑上下文中的先前概率生成下一个token。这项工作提出了一种Anti-Language Model目标函数，具有衰减因子，用于解决机器翻译中的弱点。我们在3种模型类型和大小、3种语言方向和批处($B=5）中进行了实验。提议的方法在其他状态对照点中表现出较高的性能，与默认目标函数相比，在某些设置下可以得到20个BLEU分点的提升。
</details></li>
</ul>
<hr>
<h2 id="Extrinsically-Focused-Evaluation-of-Omissions-in-Medical-Summarization"><a href="#Extrinsically-Focused-Evaluation-of-Omissions-in-Medical-Summarization" class="headerlink" title="Extrinsically-Focused Evaluation of Omissions in Medical Summarization"></a>Extrinsically-Focused Evaluation of Omissions in Medical Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08303">http://arxiv.org/abs/2311.08303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elliot Schumacher, Daniel Rosenthal, Varun Nair, Luladay Price, Geoffrey Tso, Anitha Kannan</li>
<li>for: 这个研究的目的是开发一个新的医学摘要评价指标（MED-OMIT），用于评价自然语言处理（NLP）模型在医学领域的摘要性能。</li>
<li>methods: 这个研究使用了许多现有的摘要评价指标，并开发了一种新的评价指标——MED-OMIT，该指标可以更好地捕捉医学摘要中的重要信息漏掉现象。</li>
<li>results: 研究发现，MED-OMIT可以更好地捕捉医学摘要中的漏掉现象，并且可以更好地评价医学摘要的质量。<details>
<summary>Abstract</summary>
The goal of automated summarization techniques (Paice, 1990; Kupiec et al, 1995) is to condense text by focusing on the most critical information. Generative large language models (LLMs) have shown to be robust summarizers, yet traditional metrics struggle to capture resulting performance (Goyal et al, 2022) in more powerful LLMs. In safety-critical domains such as medicine, more rigorous evaluation is required, especially given the potential for LLMs to omit important information in the resulting summary. We propose MED-OMIT, a new omission benchmark for medical summarization. Given a doctor-patient conversation and a generated summary, MED-OMIT categorizes the chat into a set of facts and identifies which are omitted from the summary. We further propose to determine fact importance by simulating the impact of each fact on a downstream clinical task: differential diagnosis (DDx) generation. MED-OMIT leverages LLM prompt-based approaches which categorize the importance of facts and cluster them as supporting or negating evidence to the diagnosis. We evaluate MED-OMIT on a publicly-released dataset of patient-doctor conversations and find that MED-OMIT captures omissions better than alternative metrics.
</details>
<details>
<summary>摘要</summary>
目的是自动摘要技术（Paice，1990；Kupiec等，1995）摘要文本，专注最重要的信息。生成大型自然语言模型（LLM）已经证明是有力的摘要工具，但传统度量难以捕捉这些模型所创造的性能（Goyal等，2022）。在安全关键领域，如医学，更加严格的评估是必要的，特别是由于LLM可能会在摘要中缺少重要信息。我们提议MED-OMIT，一个新的漏洞准确度标准 для医学摘要。给定一个医生与病人的对话和生成的摘要，MED-OMIT将对话分为一组事实，并识别这些事实在摘要中是否被漏忘。我们还提议根据这些事实对于诊断的影响来确定它们的重要性。MED-OMIT使用LLM提示方法，将重要性分为支持或阻止诊断的证据。我们对一个公共释出的病人对话集进行评估，发现MED-OMIT可以更好地捕捉漏忘。
</details></li>
</ul>
<hr>
<h2 id="Workflow-Guided-Response-Generation-for-Task-Oriented-Dialogue"><a href="#Workflow-Guided-Response-Generation-for-Task-Oriented-Dialogue" class="headerlink" title="Workflow-Guided Response Generation for Task-Oriented Dialogue"></a>Workflow-Guided Response Generation for Task-Oriented Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08300">http://arxiv.org/abs/2311.08300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Do June Min, Paloma Sodhi, Ramya Ramakrishnan</li>
<li>for: 这个论文的目的是提出一种基于强化学习的对话响应生成框架，以便在对话中实现特定的工作流程。</li>
<li>methods: 该框架包括一个名为 ComplianceScorer 的度量器，用于评估生成的响应是否遵循指定的工作流程，以及一个基于强化学习的优化过程，使用交互采样技术。</li>
<li>results: 对两个 TOD 数据集（Action-Based Conversations Dataset 和 MultiWOZ 2.2）进行评估，发现该框架在自动和人工评估指标上都有显著优势，能够生成遵循工作流程的自然和流畅的对话响应。<details>
<summary>Abstract</summary>
Task-oriented dialogue (TOD) systems aim to achieve specific goals through interactive dialogue. Such tasks usually involve following specific workflows, i.e. executing a sequence of actions in a particular order. While prior work has focused on supervised learning methods to condition on past actions, they do not explicitly optimize for compliance to a desired workflow. In this paper, we propose a novel framework based on reinforcement learning (RL) to generate dialogue responses that are aligned with a given workflow. Our framework consists of ComplianceScorer, a metric designed to evaluate how well a generated response executes the specified action, combined with an RL opimization process that utilizes an interactive sampling technique. We evaluate our approach on two TOD datasets, Action-Based Conversations Dataset (ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of automated and human evaluation metrics. Our findings indicate that our RL-based framework outperforms baselines and is effective at enerating responses that both comply with the intended workflows while being expressed in a natural and fluent manner.
</details>
<details>
<summary>摘要</summary>
干净的对话系统（Task-Oriented Dialogue，TOD）旨在通过互动对话达到特定目标。这些任务通常包括执行特定的工作流程，即执行一系列动作在特定的顺序。而在过去的研究中，主要采用监督学习方法来condition on past actions，但这些方法并不直接优化对话响应的合liance。在这篇论文中，我们提出了一种基于奖励学习（Reinforcement Learning，RL）的新框架，用于生成与给定的工作流程相关的对话响应。我们的框架包括ComplianceScorer，一个用于评估生成响应是否执行了指定的动作的度量，以及一个RL优化过程，利用交互采样技术。我们对两个TOD数据集（Action-Based Conversations Dataset（ABCD）和MultiWOZ 2.2）进行了评估，并在自动和人类评估指标上达到了比基eline更高的性能。我们的研究结果表明，我们的RL基于的框架可以够效地生成符合工作流程的对话响应，同时也能够保持自然和流畅的表达。
</details></li>
</ul>
<hr>
<h2 id="VERVE-Template-based-ReflectiVE-Rewriting-for-MotiVational-IntErviewing"><a href="#VERVE-Template-based-ReflectiVE-Rewriting-for-MotiVational-IntErviewing" class="headerlink" title="VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing"></a>VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08299">http://arxiv.org/abs/2311.08299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Do June Min, Verónica Pérez-Rosas, Kenneth Resnicow, Rada Mihalcea</li>
<li>for: 本研究旨在提高观点咨问（MI）技巧的致用性，即咨询师需要学习的基本技能之一。</li>
<li>methods: 本研究提出了一种咨询回应重写任务，将非反应性陈述转换成反应性回应。该任务使用VERVE模板基于模板更新和填充增强训练。VERVE首先创建一个模板，并从非反应性Token中过滤掉不重要的句子。然后，使用模板来构建一个反应性回应。</li>
<li>results: 通过自动和人工评估，我们比较了我们的方法与文本重写基线之间的性能，并发现我们的框架可以更好地转换非反应性陈述为反应性回应，同时保持了内容准确性和反应性 стиyle的平衡。<details>
<summary>Abstract</summary>
Reflective listening is a fundamental skill that counselors must acquire to achieve proficiency in motivational interviewing (MI). It involves responding in a manner that acknowledges and explores the meaning of what the client has expressed in the conversation. In this work, we introduce the task of counseling response rewriting, which transforms non-reflective statements into reflective responses. We introduce VERVE, a template-based rewriting system with paraphrase-augmented training and adaptive template updating. VERVE first creates a template by identifying and filtering out tokens that are not relevant to reflections and constructs a reflective response using the template. Paraphrase-augmented training allows the model to learn less-strict fillings of masked spans, and adaptive template updating helps discover effective templates for rewriting without significantly removing the original content. Using both automatic and human evaluations, we compare our method against text rewriting baselines and show that our framework is effective in turning non-reflective statements into more reflective responses while achieving a good content preservation-reflection style trade-off.
</details>
<details>
<summary>摘要</summary>
<<SYS>TRANSLATE_TEXT</SYS>>投射式听众是跟踪咨询技能的基础能力，用于实现动机激励采访（MI）的掌握。它通过回念地回应客户的话语，以便更好地理解和探讨客户的意义。在这篇文章中，我们介绍了咨询回应重写任务，该任务将非反射性声明转换为反射回应。我们介绍了VERVE模板基于重写系统，该系统通过标识和过滤无关于反射的token，并使用模板来构建反射回应。我们还提出了带有填充辅助的模板更新策略，以便在不丢弃原始内容的情况下，发现有效的反射回应模板。通过自动和人工评估，我们与文本重写基准相比较，并证明我们的框架可以将非反射性声明转换为更加反射的回应，同时保持内容准确性和反射风格的良好平衡。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Language-Model-Confidence-Estimation-and-Calibration"><a href="#A-Survey-of-Language-Model-Confidence-Estimation-and-Calibration" class="headerlink" title="A Survey of Language Model Confidence Estimation and Calibration"></a>A Survey of Language Model Confidence Estimation and Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08298">http://arxiv.org/abs/2311.08298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahui Geng, Fengyu Cai, Yuxia Wang, Heinz Koeppl, Preslav Nakov, Iryna Gurevych</li>
<li>for: This paper aims to provide a comprehensive overview of research on assessing the confidence of language models (LMs) and calibrating their predictions to improve AI safety.</li>
<li>methods: The paper discusses various methods and techniques for estimating the confidence of LMs, including different LMs and various tasks.</li>
<li>results: The paper outlines the challenges of estimating the confidence of large language models and suggests some promising directions for future work.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是为了提供语言模型（LM）的 confidence 评估和预测calibration的全面回顾，以提高人工智能安全性。</li>
<li>methods: 论文讨论了不同的LM和任务下的 confidence 评估和calibration方法。</li>
<li>results: 论文描述了大语言模型的 confidence 评估的挑战和未来工作的可能性。<details>
<summary>Abstract</summary>
Language models (LMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, the reliability of their output is concerning and questionable regarding the demand for AI safety. Assessing the confidence of LM predictions and calibrating them across different tasks with the aim to align LM confidence with accuracy can help mitigate risks and enable LMs to make better decisions. There have been various works in this respect, but there has been no comprehensive overview of this important research area. The present survey aims to bridge this gap. In particular, we discuss methods and techniques for LM confidence estimation and calibration, encompassing different LMs and various tasks. We further outline the challenges of estimating the confidence for large language models and we suggest some promising directions for future work.
</details>
<details>
<summary>摘要</summary>
语言模型（LM）在多种任务和领域中表现出色，但其输出的可靠性却引起了关注和质疑。为了减少人工智能安全风险，必须评估LM预测的可靠性并在不同任务中进行准确性调整。目前，有很多相关研究，但没有一篇全面的评论。本篇文章试图填补这一空白。我们讨论了LM可靠性估计和调整的方法和技术，涵盖不同的LM和任务。我们还描述了大语言模型的可靠性估计的挑战，并提出了一些有前途的未来工作方向。
</details></li>
</ul>
<hr>
<h2 id="On-The-Relationship-Between-Universal-Adversarial-Attacks-And-Sparse-Representations"><a href="#On-The-Relationship-Between-Universal-Adversarial-Attacks-And-Sparse-Representations" class="headerlink" title="On The Relationship Between Universal Adversarial Attacks And Sparse Representations"></a>On The Relationship Between Universal Adversarial Attacks And Sparse Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08265">http://arxiv.org/abs/2311.08265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danawr/adversarial_attacks_and_sparse_representations">https://github.com/danawr/adversarial_attacks_and_sparse_representations</a></li>
<li>paper_authors: Dana Weitzner, Raja Giryes</li>
<li>for: 本文目的是解释神经网络对小幅度偏移的敏感性，通过减少性框架来解释。</li>
<li>methods: 本文使用了减少性算法和LISTA算法，以及其他常见的攻击方法，来描述神经网络对输入图像的减少性表示的敏感性。</li>
<li>results: 本文发现，神经网络对于减少性表示的敏感性是通用的和可转移的，并且可以通过对输入图像的减少性表示进行攻击。<details>
<summary>Abstract</summary>
The prominent success of neural networks, mainly in computer vision tasks, is increasingly shadowed by their sensitivity to small, barely perceivable adversarial perturbations in image input.   In this work, we aim at explaining this vulnerability through the framework of sparsity.   We show the connection between adversarial attacks and sparse representations, with a focus on explaining the universality and transferability of adversarial examples in neural networks.   To this end, we show that sparse coding algorithms, and the neural network-based learned iterative shrinkage thresholding algorithm (LISTA) among them, suffer from this sensitivity, and that common attacks on neural networks can be expressed as attacks on the sparse representation of the input image. The phenomenon that we observe holds true also when the network is agnostic to the sparse representation and dictionary, and thus can provide a possible explanation for the universality and transferability of adversarial attacks.   The code is available at https://github.com/danawr/adversarial_attacks_and_sparse_representations.
</details>
<details>
<summary>摘要</summary>
neuronal networks 的显著成功，主要在计算机视觉任务中，受到小、几乎不可见的对抗性扰动的影响。 在这个工作中，我们尝试通过框架来解释这种敏感性。 我们显示了对抗攻击和稀热表示之间的连接，并强调了对于解释神经网络中的对抗例的universality和传递性。 为此，我们显示了稀热编码算法和基于神经网络学习的迭代缩小阈值算法（LISTA）中的敏感性，以及常见的神经网络攻击可以表示为对输入图像的稀热表示的攻击。这种现象我们观察到的持久性也适用于神经网络不知道稀热表示和词典的情况下。因此，我们的发现可能为对神经网络中的对抗攻击提供了一个可能的解释。 代码可以在https://github.com/danawr/adversarial_attacks_and_sparse_representations上获取。
</details></li>
</ul>
<hr>
<h2 id="REST-Retrieval-Based-Speculative-Decoding"><a href="#REST-Retrieval-Based-Speculative-Decoding" class="headerlink" title="REST: Retrieval-Based Speculative Decoding"></a>REST: Retrieval-Based Speculative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08252">http://arxiv.org/abs/2311.08252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fasterdecoding/rest">https://github.com/fasterdecoding/rest</a></li>
<li>paper_authors: Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D Lee, Di He</li>
<li>for: 快速化语言模型生成</li>
<li>methods: 利用检索来生成拟合 tokens</li>
<li>results: 在单批设置下，对 7B 和 13B 语言模型进行了加速，速度提高了 1.62X 至 2.36X 于代码或文本生成<details>
<summary>Abstract</summary>
We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm designed to speed up language model generation. The key insight driving the development of REST is the observation that the process of text generation often includes certain common phases and patterns. Unlike previous methods that rely on a draft language model for speculative decoding, REST harnesses the power of retrieval to generate draft tokens. This method draws from the reservoir of existing knowledge, retrieving and employing relevant tokens based on the current context. Its plug-and-play nature allows for seamless integration and acceleration of any language models, all without necessitating additional training. When benchmarked on 7B and 13B language models in a single-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on code or text generation. The code of REST is available at https://github.com/FasterDecoding/REST.
</details>
<details>
<summary>摘要</summary>
我们介绍 Retrieval-Based Speculative Decoding（REST），一种新的算法，用于快速化语言模型生成。REST的关键思想是发现文本生成过程中通常包含一些共同的阶段和模式。不同于先前的方法，REST不是靠对稿语言模型进行推测性解oding，而是利用库存的知识，从现有的文本中获取和使用相关的字符。这种插件式的设计使得可以轻松地整合和加速任何语言模型，不需要额外训练。当对7B和13B语言模型进行单批训练时，REST可以获得显著的速度增加，对于代码或文本生成而言，速度增加为1.62倍至2.36倍。REST的代码可以在https://github.com/FasterDecoding/REST上获取。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Encoding-of-Words-in-BERT’s-Neurons-using-Feature-Textualization"><a href="#Investigating-the-Encoding-of-Words-in-BERT’s-Neurons-using-Feature-Textualization" class="headerlink" title="Investigating the Encoding of Words in BERT’s Neurons using Feature Textualization"></a>Investigating the Encoding of Words in BERT’s Neurons using Feature Textualization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08240">http://arxiv.org/abs/2311.08240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanja Baeumel, Soniya Vijayakumar, Josef van Genabith, Guenter Neumann, Simon Ostermann</li>
<li>for: This paper aims to provide a better understanding of the knowledge encoded in individual neurons of pre-trained language models (PLMs), specifically in the BERT model.</li>
<li>methods: The paper proposes a technique called feature textualization to produce dense representations of neurons in the PLM word embedding space, and applies this technique to the BERT model to investigate the knowledge encoded in individual neurons.</li>
<li>results: The paper finds that the produced representations can provide insights about the knowledge encoded in individual neurons, but that individual neurons do not represent clearcut symbolic units of language such as words. Additionally, the paper investigates how many neurons are needed to encode words in BERT.<details>
<summary>Abstract</summary>
Pretrained language models (PLMs) form the basis of most state-of-the-art NLP technologies. Nevertheless, they are essentially black boxes: Humans do not have a clear understanding of what knowledge is encoded in different parts of the models, especially in individual neurons. The situation is different in computer vision, where feature visualization provides a decompositional interpretability technique for neurons of vision models. Activation maximization is used to synthesize inherently interpretable visual representations of the information encoded in individual neurons. Our work is inspired by this but presents a cautionary tale on the interpretability of single neurons, based on the first large-scale attempt to adapt activation maximization to NLP, and, more specifically, large PLMs. We propose feature textualization, a technique to produce dense representations of neurons in the PLM word embedding space. We apply feature textualization to the BERT model (Devlin et al., 2019) to investigate whether the knowledge encoded in individual neurons can be interpreted and symbolized. We find that the produced representations can provide insights about the knowledge encoded in individual neurons, but that individual neurons do not represent clearcut symbolic units of language such as words. Additionally, we use feature textualization to investigate how many neurons are needed to encode words in BERT.
</details>
<details>
<summary>摘要</summary>
预训语言模型（PLM）是现代自然语言处理技术的基础。然而，它们实际上是黑obox：人类没有清楚的理解哪些知识被不同部分模型中的不同神经元编码。在计算机视觉中，特征可视化提供了解 decompositional 可读性技术，可以用来解释视觉模型中神经元的信息。我们的工作是基于这个，但是它们提供了一个警告：单个神经元的解释性不是很明确。我们提出了特征文本化技术，用于生成 PLM 词嵌入空间中神经元的稠密表示。我们应用特征文本化技术到 Devlin et al. (2019) 中的 BERT 模型，以调查个神经元是否可以解释和象化语言知识。我们发现生成的表示可以提供神经元中知识的启示，但是单个神经元不表示明确的语言符号单元，如单词。此外，我们使用特征文本化技术来调查BERT模型中需要多少神经元来编码单词。
</details></li>
</ul>
<hr>
<h2 id="Learning-Physics-Inspired-Regularization-for-Medical-Image-Registration-with-Hypernetworks"><a href="#Learning-Physics-Inspired-Regularization-for-Medical-Image-Registration-with-Hypernetworks" class="headerlink" title="Learning Physics-Inspired Regularization for Medical Image Registration with Hypernetworks"></a>Learning Physics-Inspired Regularization for Medical Image Registration with Hypernetworks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08239">http://arxiv.org/abs/2311.08239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/annareithmeir/elastic-regularization-hypermorph">https://github.com/annareithmeir/elastic-regularization-hypermorph</a></li>
<li>paper_authors: Anna Reithmeir, Julia A. Schnabel, Veronika A. Zimmer</li>
<li>for: 用于医学图像对接和图像基于诊断和治疗</li>
<li>methods: 使用物理学发现的正则化器，包括线性弹性正则化器，以模拟生物组织的弹性性</li>
<li>results: 可以在测试时高效地找到适合的数据特定物理参数，以便进行成功的图像对接<details>
<summary>Abstract</summary>
Medical image registration aims at identifying the spatial deformation between images of the same anatomical region and is fundamental to image-based diagnostics and therapy. To date, the majority of the deep learning-based registration methods employ regularizers that enforce global spatial smoothness, e.g., the diffusion regularizer. However, such regularizers are not tailored to the data and might not be capable of reflecting the complex underlying deformation. In contrast, physics-inspired regularizers promote physically plausible deformations. One such regularizer is the linear elastic regularizer which models the deformation of elastic material. These regularizers are driven by parameters that define the material's physical properties. For biological tissue, a wide range of estimations of such parameters can be found in the literature and it remains an open challenge to identify suitable parameter values for successful registration. To overcome this problem and to incorporate physical properties into learning-based registration, we propose to use a hypernetwork that learns the effect of the physical parameters of a physics-inspired regularizer on the resulting spatial deformation field. In particular, we adapt the HyperMorph framework to learn the effect of the two elasticity parameters of the linear elastic regularizer. Our approach enables the efficient discovery of suitable, data-specific physical parameters at test time.
</details>
<details>
<summary>摘要</summary>
医学图像匹配目标是在同一个解剖区域中的图像之间找到空间变形，这是图像基于诊断和治疗的基础。目前大多数深度学习基于匹配方法使用的 regularizer 都是global spatial smoothness，例如Diffusion regularizer。然而，这些 regularizer 并不是数据适应的，可能不能准确反映复杂的下面变形。相反，物理启发的 regularizer 推动物理可能的变形。例如，线性弹性 regularizer 模拟了弹性物质的变形。这些 regularizer 是通过参数定义物质物理性能的。对生物组织来说，文献中存在很多估计这些参数的值，但是还是一个开放的挑战来确定合适的参数值以实现成功的匹配。为了解决这个问题并将物理性能引入学习基于的匹配方法中，我们提议使用 hypernetwork 来学习物理参数对空间变形场的影响。特别是，我们采用了 HyperMorph 框架来学习两个弹性参数对线性弹性 regularizer 的影响。我们的方法可以在测试时高效地发现适合数据的物理参数。
</details></li>
</ul>
<hr>
<h2 id="Eval-GCSC-A-New-Metric-for-Evaluating-ChatGPT’s-Performance-in-Chinese-Spelling-Correction"><a href="#Eval-GCSC-A-New-Metric-for-Evaluating-ChatGPT’s-Performance-in-Chinese-Spelling-Correction" class="headerlink" title="Eval-GCSC: A New Metric for Evaluating ChatGPT’s Performance in Chinese Spelling Correction"></a>Eval-GCSC: A New Metric for Evaluating ChatGPT’s Performance in Chinese Spelling Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08219">http://arxiv.org/abs/2311.08219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ktlktl/eval-gcsc">https://github.com/ktlktl/eval-gcsc</a></li>
<li>paper_authors: Kunting Li, Yong Hu, Shaolei Wang, Hanhan Ma, Liang He, Fandong Meng, Jie Zhou</li>
<li>for: 本文旨在提出一种新的评估度量，以评估生成模型在中文拼写正确任务中的表现。</li>
<li>methods: 本文使用了一种新的评估度量——Eval-GCSC，它通过结合单词水平和Semantic Similarity来评估生成模型的拼写正确性。</li>
<li>results: 实验结果表明，Eval-GCSC评估度量与人工评估得到了高度的一致性，而且生成模型的表现与传统的token-level分类模型（TCM）相当。<details>
<summary>Abstract</summary>
ChatGPT has demonstrated impressive performance in various downstream tasks. However, in the Chinese Spelling Correction (CSC) task, we observe a discrepancy: while ChatGPT performs well under human evaluation, it scores poorly according to traditional metrics. We believe this inconsistency arises because the traditional metrics are not well-suited for evaluating generative models. Their overly strict length and phonics constraints may lead to underestimating ChatGPT's correction capabilities. To better evaluate generative models in the CSC task, this paper proposes a new evaluation metric: Eval-GCSC. By incorporating word-level and semantic similarity judgments, it relaxes the stringent length and phonics constraints. Experimental results show that Eval-GCSC closely aligns with human evaluations. Under this metric, ChatGPT's performance is comparable to traditional token-level classification models (TCM), demonstrating its potential as a CSC tool. The source code and scripts can be accessed at https://github.com/ktlKTL/Eval-GCSC.
</details>
<details>
<summary>摘要</summary>
chatGPT在多种下渠任务中表现出色，但在中文拼写正确（CSC）任务中，我们观察到一个不一致性：虽然chatGPT在人工评价中表现良好，但按照传统的指标来说，其分数不高。我们认为这种不一致性是因为传统的指标不适合评估生成模型。它们的过于严格的长度和音调约束可能会导致对chatGPT的 correction能力进行低估。为更好地评估生成模型在CSC任务中，本文提出了一个新的评价指标：Eval-GCSC。它通过 integrate word-level和Semantic Similarity的判断，它逐渐放弃了长度和音调的约束。实验结果表明，Eval-GCSC与人工评价高度相似。根据这个指标，chatGPT在CSC任务中的表现与传统的token-level分类模型（TCM）相当，这表明它在CSC中具有潜在的工具性。可以通过https://github.com/ktlKTL/Eval-GCSC访问源代码和脚本。
</details></li>
</ul>
<hr>
<h2 id="Human-Centric-Autonomous-Systems-With-LLMs-for-User-Command-Reasoning"><a href="#Human-Centric-Autonomous-Systems-With-LLMs-for-User-Command-Reasoning" class="headerlink" title="Human-Centric Autonomous Systems With LLMs for User Command Reasoning"></a>Human-Centric Autonomous Systems With LLMs for User Command Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08206">http://arxiv.org/abs/2311.08206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kth-rpl/drivecmd_llm">https://github.com/kth-rpl/drivecmd_llm</a></li>
<li>paper_authors: Yi Yang, Qingwen Zhang, Ci Li, Daniel Simões Marta, Nazre Batool, John Folkesson</li>
<li>for: 本研究旨在将自动驾驶系统与人工智能语言模型（LLM）结合，以满足用户的需求。</li>
<li>methods: 本研究使用了不同的LLM模型和提示设计，通过进行了一系列的实验，以评估自动驾驶系统从自然语言文本指令中推导出的多重需求的精度。</li>
<li>results: 研究发现，LLM模型可以理解和处理提示，但是其效iveness受到LLM模型的质量和提示设计的限制。<details>
<summary>Abstract</summary>
The evolution of autonomous driving has made remarkable advancements in recent years, evolving into a tangible reality. However, a human-centric large-scale adoption hinges on meeting a variety of multifaceted requirements. To ensure that the autonomous system meets the user's intent, it is essential to accurately discern and interpret user commands, especially in complex or emergency situations. To this end, we propose to leverage the reasoning capabilities of Large Language Models (LLMs) to infer system requirements from in-cabin users' commands. Through a series of experiments that include different LLM models and prompt designs, we explore the few-shot multivariate binary classification accuracy of system requirements from natural language textual commands. We confirm the general ability of LLMs to understand and reason about prompts but underline that their effectiveness is conditioned on the quality of both the LLM model and the design of appropriate sequential prompts. Code and models are public with the link \url{https://github.com/KTH-RPL/DriveCmd_LLM}.
</details>
<details>
<summary>摘要</summary>
自带驾驶技术的发展很快，已经成为现实。然而，大规模采用需要满足多种多样的需求。以确保自动驾驶系统满足用户的意图，需要准确地理解和解释用户命令，特别是在复杂或紧急情况下。为此，我们提议利用大型自然语言模型（LLM）的理解能力来推导系统需求从驾驶舱用户的命令。通过不同的 LLM 模型和提示设计，我们探索了从自然语言文本命令中多个变量binary分类精度。我们证明了 LLM 的普遍能力理解和解释提示，但是其效iveness 受到 LLM 模型和提示设计质量的限制。代码和模型在 GitHub 上公开，链接为 \url{https://github.com/KTH-RPL/DriveCmd_LLM}.
</details></li>
</ul>
<hr>
<h2 id="Automated-Fact-Checking-in-Dialogue-Are-Specialized-Models-Needed"><a href="#Automated-Fact-Checking-in-Dialogue-Are-Specialized-Models-Needed" class="headerlink" title="Automated Fact-Checking in Dialogue: Are Specialized Models Needed?"></a>Automated Fact-Checking in Dialogue: Are Specialized Models Needed?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08195">http://arxiv.org/abs/2311.08195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Chamoun, Marzieh Saeidi, Andreas Vlachos</li>
<li>for: 提高对话中的真假查找效果</li>
<li>methods: 使用对话数据标注的精度进行练习改进、对话输入转换以适应模型的预测</li>
<li>results: 使用同一模型进行对话和常见真假查找，并维持对常见真假查找的精度。<details>
<summary>Abstract</summary>
Prior research has shown that typical fact-checking models for stand-alone claims struggle with claims made in dialogues. As a solution, fine-tuning these models on labelled dialogue data has been proposed. However, creating separate models for each use case is impractical, and we show that fine-tuning models for dialogue results in poor performance on typical fact-checking. To overcome this challenge, we present techniques that allow us to use the same models for both dialogue and typical fact-checking. These mainly focus on retrieval adaptation and transforming conversational inputs so that they can be accurately predicted by models trained on stand-alone claims. We demonstrate that a typical fact-checking model incorporating these techniques is competitive with state-of-the-art models fine-tuned for dialogue, while maintaining its accuracy on stand-alone claims.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:先前的研究表明， traditional的决定性检查模型对于单独的声明很难进行检查。为解决这个问题，人们提议使用对话数据进行精度调整。然而，创建每个用例的分开模型是不实际的，我们显示了对话模型的精度调整会导致典型的检查性能下降。为了解决这个挑战，我们提出了一些技术，使得我们可以使用同一个模型来进行对话和典型的检查。这些技术主要是适应检索和将对话输入转换成可以由基于单独声明的模型准确预测的形式。我们示出了一个典型的检查模型，包含这些技术，与状态最佳的对话模型竞争，而且保持了对单独声明的精度。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Learning-via-Swapped-Prediction-for-Communication-Signal-Recognition"><a href="#Semi-Supervised-Learning-via-Swapped-Prediction-for-Communication-Signal-Recognition" class="headerlink" title="Semi-Supervised Learning via Swapped Prediction for Communication Signal Recognition"></a>Semi-Supervised Learning via Swapped Prediction for Communication Signal Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08179">http://arxiv.org/abs/2311.08179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weidong Wang, Hongshu Liao, Lu Gan</li>
<li>for: 提高通信信号识别器的性能，使其能够在小数据量和少量标签下进行训练，而不会过拟合。</li>
<li>methods: 基于强 Datenaugmentation 和自适应常量 regularization 的 Semi-supervised learning 方法，使用大量可得到的无标签信号数据来提高模型的泛化能力。</li>
<li>results: 实验表明，提出的方法可以在深度 SSL 中提高通信信号识别器的性能，并且在小数据量和少量标签下进行训练时，可以避免过拟合。<details>
<summary>Abstract</summary>
Deep neural networks have been widely used in communication signal recognition and achieved remarkable performance, but this superiority typically depends on using massive examples for supervised learning, whereas training a deep neural network on small datasets with few labels generally falls into overfitting, resulting in degenerated performance. To this end, we develop a semi-supervised learning (SSL) method that effectively utilizes a large collection of more readily available unlabeled signal data to improve generalization. The proposed method relies largely on a novel implementation of consistency-based regularization, termed Swapped Prediction, which leverages strong data augmentation to perturb an unlabeled sample and then encourage its corresponding model prediction to be close to its original, optimized with a scaled cross-entropy loss with swapped symmetry. Extensive experiments indicate that our proposed method can achieve a promising result for deep SSL of communication signal recognition.
</details>
<details>
<summary>摘要</summary>
深度神经网络在通信信号识别领域得到了广泛应用，但这种优势通常取决于使用庞大的示例进行监督学习，而使用小数据集和少量标签时通常会陷入过拟合，导致性能下降。为解决这个问题，我们开发了一种半监督学习（SSL）方法，能够有效地利用大量更 readily available的无标示例数据来提高泛化。我们的提议方法基于一种新的归一化正则化技术，称为Swapped Prediction，它利用强大的数据归一化来perturb一个无标示例，然后鼓励其相应的模型预测与其原始值保持相似，并且通过涨平的交叉熵损失来优化。我们的实验表明，我们的提议方法可以取得深度SSL通信信号识别领域的可提升的结果。
</details></li>
</ul>
<hr>
<h2 id="Neural-Lattice-Reduction-A-Self-Supervised-Geometric-Deep-Learning-Approach"><a href="#Neural-Lattice-Reduction-A-Self-Supervised-Geometric-Deep-Learning-Approach" class="headerlink" title="Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach"></a>Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08170">http://arxiv.org/abs/2311.08170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Luca Marchetti, Gabriele Cesa, Kumar Pratik, Arash Behboodi</li>
<li>for:  solving lattice reduction problems using deep learning methods</li>
<li>methods:  using a deep neural model outputting factorized unimodular matrices, trained in a self-supervised manner with penalization for non-orthogonal lattice bases, and incorporating symmetries of lattice reduction through invariance and equivariance with respect to appropriate continuous and discrete groups</li>
<li>results:  a deep learning method for lattice reduction that incorporates symmetries and achieves good performance<details>
<summary>Abstract</summary>
Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. In this work, we address lattice reduction via deep learning methods. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant and equivariant with respect to appropriate continuous and discrete groups.
</details>
<details>
<summary>摘要</summary>
“底色减少”是一个 combinatorial 优化问题，旨在找到给定的底色中最正交的基底。在这项工作中，我们通过深度学习方法来解决底色减少问题。我们设计了一个深度神经网络，输出 факторизов了单模卷积矩阵，并在无监督的方式下训练它，对非正交底色基底进行惩罚。我们在模型中包含底色减少的 symmetries，使其对恰当的连续和离散群进行不变和对称性。
</details></li>
</ul>
<hr>
<h2 id="MechAgents-Large-language-model-multi-agent-collaborations-can-solve-mechanics-problems-generate-new-data-and-integrate-knowledge"><a href="#MechAgents-Large-language-model-multi-agent-collaborations-can-solve-mechanics-problems-generate-new-data-and-integrate-knowledge" class="headerlink" title="MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge"></a>MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08166">http://arxiv.org/abs/2311.08166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Ni, Markus J. Buehler<br>for:The paper is written for solving mechanics problems using numerical methods, specifically using large language models (LLMs) to develop a new class of physics-inspired generative machine learning platform called MechAgents.methods:The paper uses autonomous collaborations of multiple LLMs to solve elasticity problems, including applying finite element methods with different boundary conditions, domain geometries, meshes, and constitutive laws. The agents mutually correct each other to improve team-work performance in understanding, formulating, and validating the solution.results:The paper demonstrates the effectiveness of the MechAgents framework in solving classical elasticity problems, and shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents to automate the solution of engineering problems.<details>
<summary>Abstract</summary>
Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems.
</details>
<details>
<summary>摘要</summary>
解决机械问题使用数值方法需要全面的智能能力，包括检索相关知识和理论，构建和执行代码，分析结果，这项工作曾经主要由人类完成。落地出现的人工智能方法可以提供有效的解决端到端问题的方法，例如通过使用深度替身模型或多种数据分析策略，但它们经常缺乏物理直觉，因为知识被嵌入参数补充中进行训练，无法适应包含数学或物理意见的情况。我们可以通过多种语言模型之间的互动，开发一种新的物理启发的机器学习平台，称为MechAgents。这些AI代理可以解决机械任务，例如弹性问题，通过自主协作。一个两代理团队可以自动撰写、执行和自我修正代码，以应用finite element方法解决不同的粘连条件、域几何、网格、小几何弹性和线性/超几何材料学定律等等。对于更复杂的任务，我们可以建立一个更大的代理团队，在规划、形态、代码、执行和评价过程中进行分工，以提高总体团队的合作性和性能。我们的框架展示了将语言模型的智能、物理模型的可靠性和多种代理之间的协作融合起来，开启了解决工程问题的自动化新 Avenues。
</details></li>
</ul>
<hr>
<h2 id="Ask-One-More-Time-Self-Agreement-Improves-Reasoning-of-Language-Models-in-Almost-All-Scenarios"><a href="#Ask-One-More-Time-Self-Agreement-Improves-Reasoning-of-Language-Models-in-Almost-All-Scenarios" class="headerlink" title="Ask One More Time: Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios"></a>Ask One More Time: Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08154">http://arxiv.org/abs/2311.08154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Lin, Jiayi Fu, Pengli Liu, Junchen Wan, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, Kun Gai<br>for: 这篇论文旨在提高链式思维（CoT）提示 комбиined with语言模型的表现，并解决过去的缺点，例如重复性和本地最佳化。methods: 这篇论文提出了一种称为“自我一致”的统一ensemble-optimization方法，可以在大多数情况下适用，包括不知道输入问题的类型或回答路径的类型。results: 这篇论文的实验结果显示，自我一致方法可以在六个公开的推理实验上显示出优异的表现，同时也具有优秀的扩展能力。<details>
<summary>Abstract</summary>
Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local optimality. To address this shortcoming, ensemble-optimization tries to obtain multiple reasoning paths to get the final answer assembly. However, current ensemble-optimization methods either simply employ rule-based post-processing such as \textit{self-consistency}, or train an additional model based on several task-related human annotations to select the best one among multiple reasoning paths, yet fail to generalize to realistic settings where the type of input questions is unknown or the answer format of reasoning paths is unknown. To avoid their limitations, we propose \textbf{self-agreement}, a generalizable ensemble-optimization method applying in almost all scenarios where the type of input questions and the answer format of reasoning paths may be known or unknown. Self-agreement firstly samples from language model's decoder to generate a \textit{diverse} set of reasoning paths, and subsequently prompts the language model \textit{one more time} to determine the optimal answer by selecting the most \textit{agreed} answer among the sampled reasoning paths. Self-agreement simultaneously achieves remarkable performance on six public reasoning benchmarks and superior generalization capabilities.
</details>
<details>
<summary>摘要</summary>
尽管链式思维（CoT）提示与语言模型结合已经实现了复杂逻辑任务的吸引人result，但通常使用的Naive greedy decoding在CoT提示中会导致重复性和局部优化。为了解决这些缺点，集成优化尝试获取多个逻辑路径来获得最终答案组装。然而，现有的集成优化方法可能会使用规则基于的后处理such as自 consistency，或者训练一个基于多个任务相关的人工签名来选择最佳的一个多个逻辑路径，但它们无法泛化到真实的设置中， где输入问题的类型和逻辑路径的答案格式都是未知的。为了避免这些限制，我们提出了自 consistency，一种通用的集成优化方法，可以在大多数情况下应用，包括输入问题的类型和逻辑路径的答案格式可以是知道的或未知的。自 consistency首先从语言模型的解码器中采样出一个多样化的逻辑路径集，然后再一次提示语言模型，通过选择多样化逻辑路径中最为一致的答案来确定最佳答案。自 consistency同时实现了六个公共逻辑 benchmarck上的吸引人result和superior泛化能力。
</details></li>
</ul>
<hr>
<h2 id="When-Mining-Electric-Locomotives-Meet-Reinforcement-Learning"><a href="#When-Mining-Electric-Locomotives-Meet-Reinforcement-Learning" class="headerlink" title="When Mining Electric Locomotives Meet Reinforcement Learning"></a>When Mining Electric Locomotives Meet Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08153">http://arxiv.org/abs/2311.08153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Li, Zhencai Zhu, Xiaoqiang Li, Chunyu Yang, Hao Lu</li>
<li>For: This paper aims to present a reinforcement learning (RL) method for the autonomous control of mining electric locomotives in complex and uncertain coal mine environments.* Methods: The proposed method uses RL to learn the optimal control policy for the locomotives, and an improved epsilon-greedy algorithm is proposed to balance exploration and exploitation. The co-simulation platform is built to verify the effectiveness of the method.* Results: The simulation results show that the proposed method ensures the locomotives follow the front vehicle safely and respond promptly to sudden obstacles in the event of complex and uncertain coal mine environments.<details>
<summary>Abstract</summary>
As the most important auxiliary transportation equipment in coal mines, mining electric locomotives are mostly operated manually at present. However, due to the complex and ever-changing coal mine environment, electric locomotive safety accidents occur frequently these years. A mining electric locomotive control method that can adapt to different complex mining environments is needed. Reinforcement Learning (RL) is concerned with how artificial agents ought to take actions in an environment so as to maximize reward, which can help achieve automatic control of mining electric locomotive. In this paper, we present how to apply RL to the autonomous control of mining electric locomotives. To achieve more precise control, we further propose an improved epsilon-greedy (IEG) algorithm which can better balance the exploration and exploitation. To verify the effectiveness of this method, a co-simulation platform for autonomous control of mining electric locomotives is built which can complete closed-loop simulation of the vehicles. The simulation results show that this method ensures the locomotives following the front vehicle safely and responding promptly in the event of sudden obstacles on the road when the vehicle in complex and uncertain coal mine environments.
</details>
<details>
<summary>摘要</summary>
现在大多数煤矿电力机车都是人工操作的。然而，由于煤矿环境复杂且不断变化，电力机车安全事故频繁发生。为了应对不同的煤矿环境，我们需要一种可以适应不同环境的煤矿电力机车控制方法。在这篇论文中，我们介绍了如何通过强化学习（RL）来实现自动控制煤矿电力机车。为了更加精准地控制，我们还提出了一种改进的ε-软弱算法（IEG），可以更好地平衡探索和利用。为了证明这种方法的有效性，我们建立了一个自动控制煤矿电力机车的协同 simulate平台，可以完成煤矿电力机车的关闭循环 simulate。实验结果表明，这种方法可以使煤矿电力机车在复杂和不确定的煤矿环境中安全地跟随前车，并快速应对突然出现的道路障碍物。
</details></li>
</ul>
<hr>
<h2 id="The-Hyperdimensional-Transform-for-Distributional-Modelling-Regression-and-Classification"><a href="#The-Hyperdimensional-Transform-for-Distributional-Modelling-Regression-and-Classification" class="headerlink" title="The Hyperdimensional Transform for Distributional Modelling, Regression and Classification"></a>The Hyperdimensional Transform for Distributional Modelling, Regression and Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08150">http://arxiv.org/abs/2311.08150</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/padwulf/chap6_transform_applications">https://github.com/padwulf/chap6_transform_applications</a></li>
<li>paper_authors: Pieter Dewulf, Bernard De Baets, Michiel Stock</li>
<li>for: 本研究目的是为了介绍 hyperdimensional computing（HDC）的概念和应用，尤其是在机器学习和数据科学领域。</li>
<li>methods: 本研究使用的方法包括 hyperdimensional transform，该变换可以用于表示函数和分布 como high-dimensional holographic vectors。</li>
<li>results: 研究表明，使用 hyperdimensional transform 可以导致一种新的、有良好基础的工具箱，可以用于修改现有的机器学习算法并解决各种统计模型问题，如回归和分类任务，以及 represntation、学习、分布拟合、采样、 bayesian inference 和 uncertainty estimation。<details>
<summary>Abstract</summary>
Hyperdimensional computing (HDC) is an increasingly popular computing paradigm with immense potential for future intelligent applications. Although the main ideas already took form in the 1990s, HDC recently gained significant attention, especially in the field of machine learning and data science. Next to efficiency, interoperability and explainability, HDC offers attractive properties for generalization as it can be seen as an attempt to combine connectionist ideas from neural networks with symbolic aspects. In recent work, we introduced the hyperdimensional transform, revealing deep theoretical foundations for representing functions and distributions as high-dimensional holographic vectors. Here, we present the power of the hyperdimensional transform to a broad data science audience. We use the hyperdimensional transform as a theoretical basis and provide insight into state-of-the-art HDC approaches for machine learning. We show how existing algorithms can be modified and how this transform can lead to a novel, well-founded toolbox. Next to the standard regression and classification tasks of machine learning, our discussion includes various aspects of statistical modelling, such as representation, learning and deconvolving distributions, sampling, Bayesian inference, and uncertainty estimation.
</details>
<details>
<summary>摘要</summary>
高维计算（HDC）是一种日益受欢迎的计算模式，具有未来智能应用的巨大潜力。尽管主要想法已经在1990年代形成，但HDC在机器学习和数据科学领域最近才受到了广泛关注。除了效率、互操作性和解释性外，HDC提供了泛化的有利属性，可以看作是将连接主义思想与符号学概念结合在一起的尝试。在最近的工作中，我们介绍了干扰变换，揭示了深刻的理论基础，用于表示函数和分布的高维干扰向量。在这里，我们将hyperdimensional transform的力量介绍给广泛的数据科学群体。我们使用干扰变换作为理论基础，并提供了现有算法的修改和新工具箱的可能性。除了传统的回归和分类任务之外，我们的讨论还包括统计模型的多个方面，例如表示、学习、分解分布、采样、 bayesian推理和不确定性估计。
</details></li>
</ul>
<hr>
<h2 id="Cattle-Identification-Using-Muzzle-Images-and-Deep-Learning-Techniques"><a href="#Cattle-Identification-Using-Muzzle-Images-and-Deep-Learning-Techniques" class="headerlink" title="Cattle Identification Using Muzzle Images and Deep Learning Techniques"></a>Cattle Identification Using Muzzle Images and Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08148">http://arxiv.org/abs/2311.08148</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/peter716/animal_biometrics_system">https://github.com/peter716/animal_biometrics_system</a></li>
<li>paper_authors: G. N. Kimani, P. Oluwadara, P. Fashingabo, M. Busogi, E. Luhanga, K. Sowon, L. Chacha</li>
<li>for: 这项研究旨在开发一种基于皮肤特征的牛畜识别方法，以提高现有方法的精度和可扩展性。</li>
<li>methods: 本研究使用了深度学习模型，包括宽ResNet50和VGG16_BN，以及图像压缩技术来实现牛畜识别。</li>
<li>results: 实验结果显示，使用宽ResNet50模型和图像压缩技术可以达到最大准确率为99.5%，而且可以在AfricanContext中适用。<details>
<summary>Abstract</summary>
Traditional animal identification methods such as ear-tagging, ear notching, and branding have been effective but pose risks to the animal and have scalability issues. Electrical methods offer better tracking and monitoring but require specialized equipment and are susceptible to attacks. Biometric identification using time-immutable dermatoglyphic features such as muzzle prints and iris patterns is a promising solution. This project explores cattle identification using 4923 muzzle images collected from 268 beef cattle. Two deep learning classification models are implemented - wide ResNet50 and VGG16\_BN and image compression is done to lower the image quality and adapt the models to work for the African context. From the experiments run, a maximum accuracy of 99.5\% is achieved while using the wide ResNet50 model with a compression retaining 25\% of the original image. From the study, it is noted that the time required by the models to train and converge as well as recognition time are dependent on the machine used to run the model.
</details>
<details>
<summary>摘要</summary>
传统的动物识别方法，如耳标、耳割和烙印，有效但存在风险和扩展性问题。电子方法提供更好的跟踪和监测，但需要专业设备并可能受到攻击。生物特征识别使用不可逆的皮肤特征，如脸部印痕和眼球图像，是一个有前途的解决方案。本项目探索了使用4923个牛脸图像，从268头牛中收集，并实现了两个深度学习分类模型：宽频率ResNet50和VGG16\_BN。图像压缩是为了降低图像质量和适应非洲上的环境。经过实验，最高的准确率达到99.5%，使用宽频率ResNet50模型，保留原始图像的25%。研究发现，模型训练和平衡时间以及识别时间均取决于运行模型的机器。
</details></li>
</ul>
<hr>
<h2 id="RECALL-A-Benchmark-for-LLMs-Robustness-against-External-Counterfactual-Knowledge"><a href="#RECALL-A-Benchmark-for-LLMs-Robustness-against-External-Counterfactual-Knowledge" class="headerlink" title="RECALL: A Benchmark for LLMs Robustness against External Counterfactual Knowledge"></a>RECALL: A Benchmark for LLMs Robustness against External Counterfactual Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08147">http://arxiv.org/abs/2311.08147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun</li>
<li>for: 本研究旨在评估现有语言模型对外部知识的可靠性能力，以帮助提高模型的问答能力和文本生成能力。</li>
<li>methods: 本研究使用了两个任务：问答和文本生成，并在每个任务中提供了含有相对信息的上下文。</li>
<li>results: 研究发现现有的语言模型受到不可靠的外部知识的干扰，而简单的 intervención方法帮助有限度地解决这个问题。<details>
<summary>Abstract</summary>
LLMs and AI chatbots have improved people's efficiency in various fields. However, the necessary knowledge for answering the question may be beyond the models' knowledge boundaries. To mitigate this issue, many researchers try to introduce external knowledge, such as knowledge graphs and Internet contents, into LLMs for up-to-date information. However, the external information from the Internet may include counterfactual information that will confuse the model and lead to an incorrect response. Thus there is a pressing need for LLMs to possess the ability to distinguish reliable information from external knowledge. Therefore, to evaluate the ability of LLMs to discern the reliability of external knowledge, we create a benchmark from existing knowledge bases. Our benchmark consists of two tasks, Question Answering and Text Generation, and for each task, we provide models with a context containing counterfactual information. Evaluation results show that existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to the alleviation of this issue.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Caring-Trouble-and-Musical-AI-Considerations-towards-a-Feminist-Musical-AI"><a href="#Caring-Trouble-and-Musical-AI-Considerations-towards-a-Feminist-Musical-AI" class="headerlink" title="Caring Trouble and Musical AI: Considerations towards a Feminist Musical AI"></a>Caring Trouble and Musical AI: Considerations towards a Feminist Musical AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08120">http://arxiv.org/abs/2311.08120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelsey Cotton, Kıvanç Tatar</li>
<li>for: This paper examines the ethical implications of using AI in musical and artistic practice, specifically in the context of Holly+, a deep neural network that generates raw audio.</li>
<li>methods: The paper uses a critical feminist examination and speculative feminism to trouble the structures, frameworks, and assumptions within and around Holly+.</li>
<li>results: The paper contributes considerations and future directions for integrating speculative feminism and care into musical-AI agent and system design.<details>
<summary>Abstract</summary>
The ethics of AI as both material and medium for interaction remains in murky waters within the context of musical and artistic practice. The interdisciplinarity of the field is revealing matters of concern and care, which necessitate interdisciplinary methodologies for evaluation to trouble and critique the inheritance of "residue-laden" AI-tools in musical applications. Seeking to unsettle these murky waters, this paper critically examines the example of Holly+, a deep neural network that generates raw audio in the likeness of its creator Holly Herndon. Drawing from theoretical concerns and considerations from speculative feminism and care ethics, we care-fully trouble the structures, frameworks and assumptions that oscillate within and around Holly+. We contribute with several considerations and contemplate future directions for integrating speculative feminism and care into musical-AI agent and system design, derived from our critical feminist examination.
</details>
<details>
<summary>摘要</summary>
艺术和音乐领域中AI的伦理问题尚未得到清晰的解释，这个领域的多方交叉性也暴露了一些关注和照顾的问题，需要多方方法来评估和批判AI工具在音乐应用中的继承。为了摧极这些混沌的情况，本文 kritisch examines Holly+，一个深度神经网络，可以生成类似于其创造者Holly Herndon的原始音频。从 spéculative feminism和care ethics的理论和考虑中，我们仔细关注了Holly+的结构、框架和假设，并提出了一些考虑和思考将speculative feminism和care integrate into musical-AI agent和系统设计的可能性。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Neighbor-Explainability-for-Graph-Neural-Networks"><a href="#Evaluating-Neighbor-Explainability-for-Graph-Neural-Networks" class="headerlink" title="Evaluating Neighbor Explainability for Graph Neural Networks"></a>Evaluating Neighbor Explainability for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08118">http://arxiv.org/abs/2311.08118</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ericssonresearch/gnn-neighbors-xai">https://github.com/ericssonresearch/gnn-neighbors-xai</a></li>
<li>paper_authors: Oscar Llorente, Péter Vaderna, Sándor Laki, Roland Kotroczó, Rita Csoma, János Márk Szalai-Gindl</li>
<li>for: 本研究旨在解释Graph Neural Networks (GNNs)中每个邻居对于节点分类的重要性，以及如何度量这个特定任务的性能。</li>
<li>methods: 本研究使用了多种已知的解释方法，以及四种新的度量方法，以确定每个邻居对于GNN的重要性。</li>
<li>results: 研究发现，在GNN领域中，大多数解释方法无法 correctly identify important neighbors，而且gradient-based技术的解释几乎没有差异。<details>
<summary>Abstract</summary>
Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used." into Simplified Chinese.</SYS>>Here's the translation:新兴的图神经网络（GNNs）可解释性领域在最近几年内迅速发展。在这篇论文中，我们解决了GNN分类节点时每个邻居的重要性问题，以及如何衡量这种特定任务的性能。为此，我们将已知的解释方法重新表述以获取邻居重要性，并提出了四个新的指标。我们的结果表明，GNN域中使用梯度基本技术的解释几乎没有区别。此外， без自环GNN时，许多解释技术无法识别重要的邻居。
</details></li>
</ul>
<hr>
<h2 id="Reimagining-Speech-A-Scoping-Review-of-Deep-Learning-Powered-Voice-Conversion"><a href="#Reimagining-Speech-A-Scoping-Review-of-Deep-Learning-Powered-Voice-Conversion" class="headerlink" title="Reimagining Speech: A Scoping Review of Deep Learning-Powered Voice Conversion"></a>Reimagining Speech: A Scoping Review of Deep Learning-Powered Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08104">http://arxiv.org/abs/2311.08104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anders R. Bargum, Stefania Serafin, Cumhur Erkut<br>for: 这篇论文主要针对 Deep Learning 技术在语音转换（VC）中的应用，具体来说是在语音识别和生成方面。methods: 该论文使用了文献层次检索的方法，检索了2017-2023年间发表的621篇论文，并对最终选择的123篇论文进行了深入审查。results: 根据文献审查，该论文总结了 Deep Learning 技术在语音转换中最常用的方法，并指出了这些方法中的一些常见坑缺。最后，文章提出了未来研究方向的建议。<details>
<summary>Abstract</summary>
Research on deep learning-powered voice conversion (VC) in speech-to-speech scenarios is getting increasingly popular. Although many of the works in the field of voice conversion share a common global pipeline, there is a considerable diversity in the underlying structures, methods, and neural sub-blocks used across research efforts. Thus, obtaining a comprehensive understanding of the reasons behind the choice of the different methods in the voice conversion pipeline can be challenging, and the actual hurdles in the proposed solutions are often unclear. To shed light on these aspects, this paper presents a scoping review that explores the use of deep learning in speech analysis, synthesis, and disentangled speech representation learning within modern voice conversion systems. We screened 621 publications from more than 38 different venues between the years 2017 and 2023, followed by an in-depth review of a final database consisting of 123 eligible studies. Based on the review, we summarise the most frequently used approaches to voice conversion based on deep learning and highlight common pitfalls within the community. Lastly, we condense the knowledge gathered, identify main challenges and provide recommendations for future research directions.
</details>
<details>
<summary>摘要</summary>
研究在深度学习支持的语音转换（VC）场景下是越来越受欢迎。虽然许多voice转换研究的基本管道相似，但在不同研究尝试中使用的结构、方法和神经元块之间存在很大的多样性。因此，了解不同方法的选择理由以及现有解决方案中的困难可能很困难。为了突出这些方面，本文通过 scoping review 来探讨现代语音转换系统中的深度学习在语音分析、生成和独立语音表示学习方面的应用。我们从2017年至2023年间的38个不同场合中检索了621篇论文，并对最终的123篇可靠的研究进行了深入审查。根据审查，我们总结了使用深度学习进行语音转换的最常用方法，并 highlighted 在社区中的共同困难。最后，我们总结了所获知识，标识了主要挑战，并提供了未来研究方向的建议。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Semi-supervised-Hierarchical-Stacked-Encoder-for-Legal-Judgement-Prediction"><a href="#Exploring-Semi-supervised-Hierarchical-Stacked-Encoder-for-Legal-Judgement-Prediction" class="headerlink" title="Exploring Semi-supervised Hierarchical Stacked Encoder for Legal Judgement Prediction"></a>Exploring Semi-supervised Hierarchical Stacked Encoder for Legal Judgement Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08103">http://arxiv.org/abs/2311.08103</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nishchalprasad/semi-supervised-stacked-encoder">https://github.com/nishchalprasad/semi-supervised-stacked-encoder</a></li>
<li>paper_authors: Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki</li>
<li>for: 这篇论文的目的是预测法律案件的判决结果，并且使用了不同的方法来提高预测的准确性。</li>
<li>methods: 这篇论文使用了域pecific预训BERT来提取长文档中的信息，并使用了变换器Encoder层进行进一步处理。此外，它还使用了不supervised clustering来提取隐藏的标签，以更好地预测法律案件的判决结果。</li>
<li>results: 该论文的实验结果表明，使用这种两级分类机制可以比前方法在ILDC数据集上得到更高的性能提升。此外，实验还表明了域pecific预训Transformer Encoder在法律信息处理中的重要性。<details>
<summary>Abstract</summary>
Predicting the judgment of a legal case from its unannotated case facts is a challenging task. The lengthy and non-uniform document structure poses an even greater challenge in extracting information for decision prediction. In this work, we explore and propose a two-level classification mechanism; both supervised and unsupervised; by using domain-specific pre-trained BERT to extract information from long documents in terms of sentence embeddings further processing with transformer encoder layer and use unsupervised clustering to extract hidden labels from these embeddings to better predict a judgment of a legal case. We conduct several experiments with this mechanism and see higher performance gains than the previously proposed methods on the ILDC dataset. Our experimental results also show the importance of domain-specific pre-training of Transformer Encoders in legal information processing.
</details>
<details>
<summary>摘要</summary>
预测法律案件判决结果从不注释案件事实是一项复杂的任务。非统一的文档结构和长文档更加增加了提取信息的挑战。在这项工作中，我们探索并提议了一种两级分类机制：一种是supervised，另一种是无监督的。我们使用域务特定的预训练BERT来提取长文档中的句子嵌入，然后使用变换器Encoder层进一步处理，并使用无监督聚类来从这些嵌入中提取隐藏的标签，以更好地预测法律案件的判决结果。我们在ILDC数据集上进行了多个实验，并观察到了较高的性能提升，比之前的方法更高。我们的实验结果还表明了域务特定的Transformer Encoder在法律信息处理中的重要性。
</details></li>
</ul>
<hr>
<h2 id="Empowering-Multi-step-Reasoning-across-Languages-via-Tree-of-Thoughts"><a href="#Empowering-Multi-step-Reasoning-across-Languages-via-Tree-of-Thoughts" class="headerlink" title="Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts"></a>Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08097">http://arxiv.org/abs/2311.08097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Ranaldi, Fabio Massimo Zanzotto</li>
<li>for: 提高大型自然语言模型（LLM）的逻辑能力，使其能够解决复杂的逻辑任务 step-by-step。</li>
<li>methods: 提出了一种跨语言多步逻辑approach，通过自适应跨语言提问机制，使得不同语言的逻辑过程协调一致。</li>
<li>results: 对 existed prompting方法进行比较，our方法能够显著提高LLM的性能，降低交互次数，达到领先水平。<details>
<summary>Abstract</summary>
Chain-of-Thought (CoT) prompting empowers the reasoning abilities of Large Language Models (LLMs), eliciting them to solve complex reasoning tasks step-by-step. However, with the success of CoT methods, the ability to deliver multi-step reasoning remains limited to English due to the imbalance in the distribution of the pre-training data, making the other languages a barrier.   In this work, we propose a Cross-lingual multi-step reasoning approach, aiming to align reasoning processes across different languages. In particular, our method, through a Self-consistent Cross-lingual prompting mechanism inspired by the Tree-of-Thoughts approach, delivers multi-step reasoning paths in different languages that, during the steps, lead to the final solution. Our experimental evaluations show that our method significantly outperforms existing prompting methods, reducing the number of interactions and achieving state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
大脑思维链接（CoT）提示技术可以增强大语言模型（LLM）的推理能力，使其解决复杂的推理任务一步一步。然而，CoT方法的成功却受到语言障碍，因为预训练数据的分布不均衡，只有英语可以进行多步推理。在这种情况下，我们提出了跨语言多步推理方法，旨在将推理过程 across different languages 融合。我们的方法通过一种自适应跨语言提示机制，在不同语言中提供多步推理路径，其中每步都会导致最终的解决方案。我们的实验证明，我们的方法可以明显超越现有的提示方法，降低交互次数并达到领先性表现。
</details></li>
</ul>
<hr>
<h2 id="Act-VIT-A-Representationally-Robust-Attention-Architecture-for-Skeleton-Based-Action-Recognition-Using-Vision-Transformer"><a href="#Act-VIT-A-Representationally-Robust-Attention-Architecture-for-Skeleton-Based-Action-Recognition-Using-Vision-Transformer" class="headerlink" title="Act-VIT: A Representationally Robust Attention Architecture for Skeleton Based Action Recognition Using Vision Transformer"></a>Act-VIT: A Representationally Robust Attention Architecture for Skeleton Based Action Recognition Using Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08094">http://arxiv.org/abs/2311.08094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ozge Oztimur Karadag</li>
<li>for: 本研究旨在检验视觉变换器在skeleton基于动作识别中的效果，以及其在pseudo-image表示方案上的稳定性。</li>
<li>methods: 本研究提出了一种三级架构Act-VIT，通过在不同层次上形成pseudo图像，并将其传递给视觉变换器和卷积神经网络进行处理。</li>
<li>results: 实验结果表明，视觉变换器比卷积神经网络更具抗性能对pseudo图像的初始化表示方式，但是通过多个分类器的协同来提高识别性能。<details>
<summary>Abstract</summary>
Skeleton-based action recognition receives the attention of many researchers as it is robust to viewpoint and illumination changes, and its processing is much more efficient than video frames. With the emergence of deep learning models, it has become very popular to represent the skeleton data in pseudo-image form and apply Convolutional Neural Networks for action recognition. Thereafter, studies concentrated on finding effective methods for forming pseudo-images. Recently, attention networks, more specifically transformers have provided promising results in various vision problems. In this study, the effectiveness of vision transformers for skeleton-based action recognition is examined and its robustness on the pseudo-image representation scheme is investigated. To this end, a three-level architecture, Act-VIT is proposed, which forms a set of pseudo images apply a classifier on each of the representation and combine their results to find the final action class. The classifiers of Act-VIT are first realized by CNNs and then by VITs and their performances are compared. Experimental studies reveal that the vision transformer is less sensitive to the initial pseudo-image representation compared to CNN. Nevertheless, even with the vision transformer, the recognition performance can be further improved by consensus of classifiers.
</details>
<details>
<summary>摘要</summary>
skeleton-based action recognition receives 多个研究人员的关注，因为它能够抗衡视点和照明变化，并且处理效率高于视频帧。随着深度学习模型的出现，人们开始将skeleton数据表示为pseudo-image形式，并应用Convolutional Neural Networks（CNN） для行动识别。然后，研究者集中了关注如何形成pseudo-image。最近，关注网络，具体来说是transformer，在视觉问题中提供了有前途的结果。本研究检验了skeleton-based action recognition中vision transformer的效果，并investigate其在pseudo-image表示方案中的Robustness。为此，我们提出了一个三级架构Act-VIT，该架构包括 forming pseudo images，并在每个表示中应用一个分类器。每个分类器都是使用CNN或VIT来实现，并对其性能进行比较。实验研究表明，vision transformer对于初始pseudo-image表示的敏感度较低，但是，即使使用vision transformer，还可以通过协调分类器来提高识别性能。
</details></li>
</ul>
<hr>
<h2 id="Spot-A-Natural-Language-Interface-for-Geospatial-Searches-in-OSM"><a href="#Spot-A-Natural-Language-Interface-for-Geospatial-Searches-in-OSM" class="headerlink" title="Spot: A Natural Language Interface for Geospatial Searches in OSM"></a>Spot: A Natural Language Interface for Geospatial Searches in OSM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08093">http://arxiv.org/abs/2311.08093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lynn Khellaf, Ipek Baris Schlicht, Julia Bayer, Ruben Bouwmeester, Tilman Miraß, Tilman Wagner</li>
<li>for: 这篇论文是为了提供一个用户友好的自然语言 интерфей斯来查询OpenStreetMap（OSM）数据而写的。</li>
<li>methods: 该论文使用了一种基于自然语言的semantic mapping，通过人工生成的句子查询和T5trasformer来实现从用户输入句子中提取有关信息并在地图上显示匹配的候选位置。</li>
<li>results: 该论文通过Spot这个用户友好的自然语言 интерфей스，可以帮助无技术背景的人查询OSM数据，提高了访问和使用OSM的可用性和用户体验。<details>
<summary>Abstract</summary>
Investigative journalists and fact-checkers have found OpenStreetMap (OSM) to be an invaluable resource for their work due to its extensive coverage and intricate details of various locations, which play a crucial role in investigating news scenes. Despite its value, OSM's complexity presents considerable accessibility and usability challenges, especially for those without a technical background. To address this, we introduce 'Spot', a user-friendly natural language interface for querying OSM data. Spot utilizes a semantic mapping from natural language to OSM tags, leveraging artificially generated sentence queries and a T5 transformer. This approach enables Spot to extract relevant information from user-input sentences and display candidate locations matching the descriptions on a map. To foster collaboration and future advancement, all code and generated data is available as an open-source repository.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CPSOR-GCN-A-Vehicle-Trajectory-Prediction-Method-Powered-by-Emotion-and-Cognitive-Theory"><a href="#CPSOR-GCN-A-Vehicle-Trajectory-Prediction-Method-Powered-by-Emotion-and-Cognitive-Theory" class="headerlink" title="CPSOR-GCN: A Vehicle Trajectory Prediction Method Powered by Emotion and Cognitive Theory"></a>CPSOR-GCN: A Vehicle Trajectory Prediction Method Powered by Emotion and Cognitive Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08086">http://arxiv.org/abs/2311.08086</a></li>
<li>repo_url: None</li>
<li>paper_authors: L. Tang, Y. Li, J. Yuan, A. Fu, J. Sun</li>
<li>for: 这篇论文旨在提出一个新的车辆预测路径模型，以便在车辆驾驶者当中存在不正常情绪时提高预测的准确性。</li>
<li>methods: 这篇论文使用了一个新的预测路径模型，即CPSOR-GCN，它利用了物理GCN模块和认知GCN模块来预测车辆驾驶者的情绪对驾驶行为的影响。</li>
<li>results: 实验结果显示，相比于仅考虑物理动向特征，CPSOR-GCN模型的预测精度提高了68.70%。此外，利用SOR认知理论建构DBN结构，可以更好地捕捉驾驶者情绪对驾驶行为的影响，从而降低预测误差。CPSOR-GCN模型比其他进阶预测模型更低的错误值，这些结果显示CPSOR-GCN模型可以更好地适应驾驶者情绪，从而实现更高的预测精度。<details>
<summary>Abstract</summary>
Active safety systems on vehicles often face problems with false alarms. Most active safety systems predict the driver's trajectory with the assumption that the driver is always in a normal emotion, and then infer risks. However, the driver's trajectory uncertainty increases under abnormal emotions. This paper proposes a new trajectory prediction model: CPSOR-GCN, which predicts vehicle trajectories under abnormal emotions. At the physical level, the interaction features between vehicles are extracted by the physical GCN module. At the cognitive level, SOR cognitive theory is used as prior knowledge to build a Dynamic Bayesian Network (DBN) structure. The conditional probability and state transition probability of nodes from the calibrated SOR-DBN quantify the causal relationship between cognitive factors, which is embedded into the cognitive GCN module to extract the characteristics of the influence mechanism of emotions on driving behavior. The CARLA-SUMO joint driving simulation platform was built to develop dangerous pre-crash scenarios. Methods of recreating traffic scenes were used to naturally induce abnormal emotions. The experiment collected data from 26 participants to verify the proposed model. Compared with the model that only considers physical motion features, the prediction accuracy of the proposed model is increased by 68.70%. Furthermore,considering the SOR-DBN reduces the prediction error of the trajectory by 15.93%. Compared with other advanced trajectory prediction models, the results of CPSOR-GCN also have lower errors. This model can be integrated into active safety systems to better adapt to the driver's emotions, which could effectively reduce false alarms.
</details>
<details>
<summary>摘要</summary>
现有的活动安全系统 often 面临问题，即 false alarms。大多数活动安全系统预测 drivers 的轨迹，假设 drivers 总是在正常情绪下行驶，然后推断风险。然而， drivers 的轨迹不确定性会增加在不正常情绪下。这篇论文提出了一种新的轨迹预测模型：CPSOR-GCN，可以预测在不正常情绪下的轨迹。物理层面上，物理GCN模块提取了车辆之间的互动特征。认知层面上，SOR认知理论被用作先验知识，建立了一个动态概率网络（DBN）结构。DBN 结构中的 Conditional probability 和状态转移概率量化了认知因素的 causal 关系，并将其嵌入认知GCN模块中，以提取驾驶行为中情绪的影响机制的特征。在 CARLA-SUMO  JOINT 驾驶模拟平台上，建立了危险前碰撞场景。使用方法 recreating 交通场景，以自然地引起不正常情绪。实验收集了26名参与者的数据，以验证提议模型。与只考虑物理动作特征的模型相比，提议模型的预测精度提高了68.70%。同时，使用 SOR-DBN 减少预测误差的方法，预测误差减少了15.93%。与其他高级轨迹预测模型相比，结果也有较低的误差。这种模型可以结合活动安全系统，更好地适应驾驶员的情绪， thereby reducing false alarms.
</details></li>
</ul>
<hr>
<h2 id="Solving-ARC-visual-analogies-with-neural-embeddings-and-vector-arithmetic-A-generalized-method"><a href="#Solving-ARC-visual-analogies-with-neural-embeddings-and-vector-arithmetic-A-generalized-method" class="headerlink" title="Solving ARC visual analogies with neural embeddings and vector arithmetic: A generalized method"></a>Solving ARC visual analogies with neural embeddings and vector arithmetic: A generalized method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08083">http://arxiv.org/abs/2311.08083</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/foger3/arc_deeplearning">https://github.com/foger3/arc_deeplearning</a></li>
<li>paper_authors: Luca H. Thoms, Karel A. Veldkamp, Hannes Rosenbusch, Claire E. Stevenson<br>for: This paper focuses on visual analogical reasoning and applies the initial generalized mechanism used to solve verbal analogies to the visual realm.methods: The approach uses a variational autoencoder (VAE) to transform Abstraction and Reasoning Corpus (ARC) items into low-dimensional latent vectors, and then uses simple vector arithmetic to discover the underlying rules of ARC items and solve them.results: The approach works well on simple items with fewer dimensions, similar input-to-output examples, and high reconstruction accuracy on the VAE. However, predictions on more complex items showed stronger deviations from expected outputs, although they still often approximated parts of the item’s rule set. The model achieved a score of 2% on the official ARC paradigm and 8.8% on ConceptARC.<details>
<summary>Abstract</summary>
Analogical reasoning derives information from known relations and generalizes this information to similar yet unfamiliar situations. One of the first generalized ways in which deep learning models were able to solve verbal analogies was through vector arithmetic of word embeddings, essentially relating words that were mapped to a vector space (e.g., king - man + woman = __?). In comparison, most attempts to solve visual analogies are still predominantly task-specific and less generalizable. This project focuses on visual analogical reasoning and applies the initial generalized mechanism used to solve verbal analogies to the visual realm. Taking the Abstraction and Reasoning Corpus (ARC) as an example to investigate visual analogy solving, we use a variational autoencoder (VAE) to transform ARC items into low-dimensional latent vectors, analogous to the word embeddings used in the verbal approaches. Through simple vector arithmetic, underlying rules of ARC items are discovered and used to solve them. Results indicate that the approach works well on simple items with fewer dimensions (i.e., few colors used, uniform shapes), similar input-to-output examples, and high reconstruction accuracy on the VAE. Predictions on more complex items showed stronger deviations from expected outputs, although, predictions still often approximated parts of the item's rule set. Error patterns indicated that the model works as intended. On the official ARC paradigm, the model achieved a score of 2% (cf. current world record is 21%) and on ConceptARC it scored 8.8%. Although the methodology proposed involves basic dimensionality reduction techniques and standard vector arithmetic, this approach demonstrates promising outcomes on ARC and can easily be generalized to other abstract visual reasoning tasks.
</details>
<details>
<summary>摘要</summary>
通过对已知关系的推理，深度学习模型可以从知道的关系中提取信息，并将其推广到类似 yet 不熟悉的情况。在字符串类型的逻辑推理方面，深度学习模型通过Word embedding vector arithmetic来解决逻辑推理问题，例如king - man + woman = ？。相比之下，对于视觉类型的逻辑推理，大多数尝试都是任务特定的，更难推广。这个项目推广视觉逻辑推理，并将word embedding vector arithmetic的初始化机制应用到视觉领域。使用Abstraction and Reasoning Corpus（ARC）作为研究例子，我们使用变量自适应网络（VAE）将ARC项目转换成低维ensional的latent vector，类似于word embedding。通过简单的 vector 算术，我们发现了ARC项目的下面规则，并使用这些规则来解决它们。结果表明，该方法在简单的项目（即具有 fewer colors 和固定形状）上工作良好，并且在VAE中实现了高重建率。对于更复杂的项目，predictions 表现 stronger 的偏差，although predictions 仍然可以 aproximate 部分项目规则集。错误模式表明方法正常工作。在官方ARC paradigm上，模型 achieved 2% 得分（与当前世界纪录21%相比），并在ConceptARC上得分 8.8%。虽然方法包括基本维度减少技术和标准 vector 算术，但该方法在ARC上表现出了扎实的结果，并可以轻松扩展到其他抽象视觉逻辑任务。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Segmentation-of-Eye-Features-Using-the-Segment-Anything-Model-SAM"><a href="#Zero-Shot-Segmentation-of-Eye-Features-Using-the-Segment-Anything-Model-SAM" class="headerlink" title="Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)"></a>Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08077">http://arxiv.org/abs/2311.08077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Virmarie Maquiling, Sean Anthony Byrne, Diederick C. Niehorster, Marcus Nyström, Enkelejda Kasneci</li>
<li>for: 这个论文主要是为了检测眼影像中的特征，以及使用基础模型来进行图像分割。</li>
<li>methods: 本研究使用了基础模型Segment Anything Model（SAM），并利用了零批学习和绑定框或点击提示来提高模型的性能。</li>
<li>results: 研究发现，使用SAM可以在眼影像分割中达到与专门模型相当的性能，并且使用提示可以提高模型的性能，例如在一个数据集中，使用绑定框的提示后，SAM的 IoU 达到 93.34%。<details>
<summary>Abstract</summary>
The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image segmentation. In this study, we evaluate SAM's ability to segment features from eye images recorded in virtual reality setups. The increasing requirement for annotated eye-image datasets presents a significant opportunity for SAM to redefine the landscape of data annotation in gaze estimation. Our investigation centers on SAM's zero-shot learning abilities and the effectiveness of prompts like bounding boxes or point clicks. Our results are consistent with studies in other domains, demonstrating that SAM's segmentation effectiveness can be on-par with specialized models depending on the feature, with prompts improving its performance, evidenced by an IoU of 93.34% for pupil segmentation in one dataset. Foundation models like SAM could revolutionize gaze estimation by enabling quick and easy image segmentation, reducing reliance on specialized models and extensive manual annotation.
</details>
<details>
<summary>摘要</summary>
新的基础模型signal出一新的人工智能时代。Segment Anything Model（SAM）是首个用于图像分割的基础模型。在这项研究中，我们评估SAM在虚拟现实环境下记录的眼图像中分割特征的能力。由于需要更多的注解眼图像集合，这种需求对SAM来说是一个重要的机会，可以重新定义眼视 estimation数据注解的场景。我们的研究集中在SAM的零基础学习能力和点击矩形或点击提示的效果。我们的结果与其他领域的研究一致，表明SAM的分割效果可以与专门的模型相比，并且提示可以提高其性能，例如在一个数据集中，SAM的眼白分割精度达93.34%。基础模型如SAM可能会革命化眼视 estimation，因为它可以快速和容易地分割图像，减少专门的模型和手动注解的依赖。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Preference-Optimization"><a href="#Adversarial-Preference-Optimization" class="headerlink" title="Adversarial Preference Optimization"></a>Adversarial Preference Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08045">http://arxiv.org/abs/2311.08045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengyu Cheng, Yifan Yang, Jian Li, Yong Dai, Nan Du</li>
<li>for: 大型自然语言模型（LLM）的互动质量提升需要人类偏好Alignment。</li>
<li>methods: 我们提出了一个对抗偏好优化（APO）框架， LLMAgent 和偏好模型在一个 min-max 游戏中轮流更新。</li>
<li>results: 在实验中，我们证明了 APO 能够提高 LLM 的帮助性和无害性，比基eline拒绝抽样法更好。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Human preference alignment is a crucial training step to improve the interaction quality of large language models (LLMs). Existing aligning methods depend on manually annotated preference data to guide the LLM optimization directions. However, in practice, continuously updating LLMs raises a distribution gap between model-generated samples and human-preferred responses, which hinders model fine-tuning efficiency. To mitigate this issue, previous methods require additional preference annotation on generated samples to adapt the shifted distribution, which consumes a large amount of annotation resources. Targeting more efficient human preference optimization, we propose an adversarial preference optimization (APO) framework, where the LLM agent and the preference model update alternatively via a min-max game. Without additional annotation, our APO method can make a self-adaption to the generation distribution gap through the adversarial learning process. In experiments, we empirically verify the effectiveness of APO in improving LLM's helpfulness and harmlessness compared with rejection sampling baselines.
</details>
<details>
<summary>摘要</summary>
人类偏好对alignment是大型语言模型（LLM）训练的重要步骤。现有的对齐方法依赖于手动标注的偏好数据来引导LLM优化方向。然而，在实践中，不断更新LLM会导致模型生成的样本和人类首选回答之间的分布差异增大，这会降低模型细化效率。为解决这个问题，先前的方法需要进行额外的偏好标注，以适应模型生成的分布变化，这需要大量的标注资源。targeting更高效的人类偏好优化，我们提议一种对抗偏好优化（APO）框架，在这个框架中，LLM代理和偏好模型在一个min-max游戏中相互更新。无需额外的标注，我们的APO方法可以通过对抗学习过程来自适化生成分布差异。在实验中，我们证明了APO的效果比基准抽样方法更高。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-building-energy-efficiency-prediction-based-on-envelope-heat-losses-using-physics-informed-neural-networks"><a href="#Data-driven-building-energy-efficiency-prediction-based-on-envelope-heat-losses-using-physics-informed-neural-networks" class="headerlink" title="Data-driven building energy efficiency prediction based on envelope heat losses using physics-informed neural networks"></a>Data-driven building energy efficiency prediction based on envelope heat losses using physics-informed neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08035">http://arxiv.org/abs/2311.08035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasilis Michalakopoulos, Sotiris Pelekis, Giorgos Kormpakis, Vagelis Karakolis, Spiros Mouzakitis, Dimitris Askounis</li>
<li>for: 这个研究旨在提供一个基于建筑物封顶元件热损失的能源性能预测模型，以便自动化和基于建筑物基本特征的能源效率性能预测。</li>
<li>methods: 本研究使用一种新的物理学 informative 神经网络模型，通过使用广泛的建筑物资料，包括一般建筑物资讯、测量特征和热能消耗，将神经网络模型训练，并基于物理方程式计算建筑物的能源消耗。</li>
<li>results: 本研究在实际应用中获得了良好的预测精度，这显示了这种基于建筑物封顶元件热损失的能源性能预测模型具有可靠性和可行性。<details>
<summary>Abstract</summary>
The analytical prediction of building energy performance in residential buildings based on the heat losses of its individual envelope components is a challenging task. It is worth noting that this field is still in its infancy, with relatively limited research conducted in this specific area to date, especially when it comes for data-driven approaches. In this paper we introduce a novel physics-informed neural network model for addressing this problem. Through the employment of unexposed datasets that encompass general building information, audited characteristics, and heating energy consumption, we feed the deep learning model with general building information, while the model's output consists of the structural components and several thermal properties that are in fact the basic elements of an energy performance certificate (EPC). On top of this neural network, a function, based on physics equations, calculates the energy consumption of the building based on heat losses and enhances the loss function of the deep learning model. This methodology is tested on a real case study for 256 buildings located in Riga, Latvia. Our investigation comes up with promising results in terms of prediction accuracy, paving the way for automated, and data-driven energy efficiency performance prediction based on basic properties of the building, contrary to exhaustive energy efficiency audits led by humans, which are the current status quo.
</details>
<details>
<summary>摘要</summary>
building的能效性预测是一个复杂的任务，特别是在封闭系统元件的热损失方面。在这篇论文中，我们提出了一种新的物理学 Informed neural network 模型，用于解决这个问题。我们利用了一些涉及普通建筑信息的未公开数据集，包括建筑的总体特征、核心特性和加热能耗。我们将这些信息作为深度学习模型的输入，模型的输出包括建筑的结构组件和一些热性能性量，这些量是实际的能效性证书（EPC）的基本元素。在这个模型之上，基于物理方程的函数计算了建筑的能 consumption，从而提高了深度学习模型的损失函数。我们在利加市（Riga，Latvia）的256座建筑的实际案例中测试了这种方法，结果表明这种方法在预测精度方面具有扎实的表现，这开 up a new way for automatic, data-driven energy efficiency performance prediction based on basic properties of the building, rather than relying on human-led exhaustive energy efficiency audits, which are the current status quo.
</details></li>
</ul>
<hr>
<h2 id="Two-Stage-Predict-Optimize-for-Mixed-Integer-Linear-Programs-with-Unknown-Parameters-in-Constraints"><a href="#Two-Stage-Predict-Optimize-for-Mixed-Integer-Linear-Programs-with-Unknown-Parameters-in-Constraints" class="headerlink" title="Two-Stage Predict+Optimize for Mixed Integer Linear Programs with Unknown Parameters in Constraints"></a>Two-Stage Predict+Optimize for Mixed Integer Linear Programs with Unknown Parameters in Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08022">http://arxiv.org/abs/2311.08022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elizabethxyhu/neurips_two_stage_predict-optimize">https://github.com/elizabethxyhu/neurips_two_stage_predict-optimize</a></li>
<li>paper_authors: Xinyi Hu, Jasper C. H. Lee, Jimmy H. M. Lee</li>
<li>For: 这个论文是关于受限优化问题的端到端训练超参数学习模型的框架，其中一些参数在解决时未知。* Methods: 论文提出了一种新的两Stage Predict+Optimize框架，该框架可以更好地考虑到优化问题中未知参数的影响，并且可以用于所有杂合integer线性程序。* Results: 实验结果表明，该论文提出的训练框架可以比古典和当前最佳方法提供更好的预测性能。<details>
<summary>Abstract</summary>
Consider the setting of constrained optimization, with some parameters unknown at solving time and requiring prediction from relevant features. Predict+Optimize is a recent framework for end-to-end training supervised learning models for such predictions, incorporating information about the optimization problem in the training process in order to yield better predictions in terms of the quality of the predicted solution under the true parameters. Almost all prior works have focused on the special case where the unknowns appear only in the optimization objective and not the constraints. Hu et al.~proposed the first adaptation of Predict+Optimize to handle unknowns appearing in constraints, but the framework has somewhat ad-hoc elements, and they provided a training algorithm only for covering and packing linear programs. In this work, we give a new \emph{simpler} and \emph{more powerful} framework called \emph{Two-Stage Predict+Optimize}, which we believe should be the canonical framework for the Predict+Optimize setting. We also give a training algorithm usable for all mixed integer linear programs, vastly generalizing the applicability of the framework. Experimental results demonstrate the superior prediction performance of our training framework over all classical and state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
假设我们处在受限优化的设定下，其中一些参数在解决过程中未知。预测+优化是一种最近的框架，用于综合训练超出监督学习模型以便对这些预测做出更好的预测。大多数先前的工作都集中在特殊情况下，即未知参数只出现在优化目标中。胡等等提出了首次对 Predict+Optimize 框架进行适应，但该框架具有一些偶极元素，并且只提供了覆盖和压缩线性程序的训练算法。在这项工作中，我们提出了一种新的简单化和更强大的框架，称为两个阶段预测+优化框架。我们认为这应该是Predict+Optimize设定的准确框架。我们还提供了可以应用于所有杂合Integer线性程序的训练算法， thereby greatly expanding the applicability of the framework。实验结果表明我们的训练框架在所有古典和当前方法上具有更好的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Distantly-Supervised-Named-Entity-Recognition-with-Uncertainty-aware-Teacher-Learning-and-Student-student-Collaborative-Learning"><a href="#Distantly-Supervised-Named-Entity-Recognition-with-Uncertainty-aware-Teacher-Learning-and-Student-student-Collaborative-Learning" class="headerlink" title="Distantly-Supervised Named Entity Recognition with Uncertainty-aware Teacher Learning and Student-student Collaborative Learning"></a>Distantly-Supervised Named Entity Recognition with Uncertainty-aware Teacher Learning and Student-student Collaborative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08010">http://arxiv.org/abs/2311.08010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Helan Hu, Shuzheng Si, Haozhe Zhao, Shuang Zeng, Kaikai An, Zefan Cai, Baobao Chang</li>
<li>for: 提高 Distantly-Supervised Named Entity Recognition (DS-NER) 的精度和稳定性，适用于减少标注噪音。</li>
<li>methods: 提出 Uncertainty-aware Teacher Learning 和 Student-student Collaborative Learning 两种方法，分别利用预测uncertainty和学生网络之间的合作来提高模型的精度和稳定性。</li>
<li>results: 在五个 DS-NER 数据集上进行了广泛的实验，并证明了我们的方法比现有的教师生Student方法更高效。<details>
<summary>Abstract</summary>
Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the burden of annotation, but meanwhile suffers from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, we argue that these teacher-student methods achieve limited performance because poor network calibration produces incorrectly pseudo-labeled samples, leading to error propagation. Therefore, we attempt to mitigate this issue by proposing: (1) Uncertainty-aware Teacher Learning that leverages the prediction uncertainty to guide the selection of pseudo-labels, avoiding the number of incorrect pseudo-labels in the self-training stage. (2) Student-student Collaborative Learning that allows the transfer of reliable labels between two student networks instead of completely relying on all pseudo-labels from its teacher. Meanwhile, this approach allows a full exploration of mislabeled samples rather than simply filtering unreliable pseudo-labeled samples. Extensive experimental results on five DS-NER datasets demonstrate that our method is superior to state-of-the-art teacher-student methods.
</details>
<details>
<summary>摘要</summary>
难以监督的命名实体识别（DS-NER）有效减轻监督的负担，但同时受到标签噪声的影响。现有的作品尝试采用教师生成框架来慢慢精细地改善训练标签，以提高总体的稳定性。然而，我们认为这些教师生成方法的性能有限，因为差异网络准备产生错误的预测标签，导致错误嵌入的问题。因此，我们尝试解决这个问题，通过提议以下两点：1. uncertainty-aware teacher learning，通过预测不确定性来导引选择 pseudo-标签，以避免在自动训练阶段中出现的错误 pseudo-标签。2. student-student collaborative learning，允许两个学生网络之间进行可靠标签的传递，而不是完全依赖所有pseudo-标签来自其教师。同时，这种方法允许探索批量标签错误的整个样本，而不是仅仅过滤 pseudo-标签中的错误样本。我们在五个 DS-NER 数据集上进行了广泛的实验，并证明了我们的方法在教师生成方法中表现出优于状态之前。
</details></li>
</ul>
<hr>
<h2 id="Iterative-missing-value-imputation-based-on-feature-importance"><a href="#Iterative-missing-value-imputation-based-on-feature-importance" class="headerlink" title="Iterative missing value imputation based on feature importance"></a>Iterative missing value imputation based on feature importance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08005">http://arxiv.org/abs/2311.08005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Guo, Chun Liu, Wei Yang</li>
<li>for:  addresses the problem of missing values in datasets, which can reduce the accuracy of classification tasks and increase processing difficulty.</li>
<li>methods:  proposes an imputation method that considers feature importance, which iteratively performs matrix completion and feature importance learning.</li>
<li>results:  consistently outperforms five existing imputation algorithms on synthetic and real-world datasets with different types of missing values.<details>
<summary>Abstract</summary>
Many datasets suffer from missing values due to various reasons,which not only increases the processing difficulty of related tasks but also reduces the accuracy of classification. To address this problem, the mainstream approach is to use missing value imputation to complete the dataset. Existing imputation methods estimate the missing parts based on the observed values in the original feature space, and they treat all features as equally important during data completion, while in fact different features have different importance. Therefore, we have designed an imputation method that considers feature importance. This algorithm iteratively performs matrix completion and feature importance learning, and specifically, matrix completion is based on a filling loss that incorporates feature importance. Our experimental analysis involves three types of datasets: synthetic datasets with different noisy features and missing values, real-world datasets with artificially generated missing values, and real-world datasets originally containing missing values. The results on these datasets consistently show that the proposed method outperforms the existing five imputation algorithms.To the best of our knowledge, this is the first work that considers feature importance in the imputation model.
</details>
<details>
<summary>摘要</summary>
很多数据集受到缺失值的影响，这不仅增加相关任务的处理难度，还降低分类的准确率。为解决这个问题，主流方法是使用缺失值补充来完善数据集。现有的补充方法都是基于原始特征空间中观察到的值来估计缺失部分，而它们往往视所有特征为等importance，而实际上不同的特征有不同的重要性。因此，我们设计了一种考虑特征重要性的补充方法。这个算法在迭代完成矩阵和特征重要性学习中，特别是基于填充损失函数来实现矩阵完成。我们对三种不同类型的数据集进行了实验分析：Synthetic数据集具有不同的噪声特征和缺失值、实际世界数据集通过人工生成缺失值、实际世界数据集原本包含缺失值。结果表明，我们提出的方法在这些数据集上一直表现出色，并且在已知的五种补充算法中具有突出的优势。到目前为止，这是首次考虑特征重要性的补充模型。
</details></li>
</ul>
<hr>
<h2 id="TempTabQA-Temporal-Question-Answering-for-Semi-Structured-Tables"><a href="#TempTabQA-Temporal-Question-Answering-for-Semi-Structured-Tables" class="headerlink" title="TempTabQA: Temporal Question Answering for Semi-Structured Tables"></a>TempTabQA: Temporal Question Answering for Semi-Structured Tables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08002">http://arxiv.org/abs/2311.08002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vivek Gupta, Pranshu Kandoi, Mahek Bhavesh Vora, Shuo Zhang, Yujie He, Ridho Reinanda, Vivek Srikumar</li>
<li>for: 本研究旨在检验现有的自然语言处理（NLP）系统是否可以理解半结构化数据中的时间信息。</li>
<li>methods: 研究人员使用了一个新的任务——半结构化表中的时间问答（TempTabQA），并使用了11,454个问答对和1,208个WIkipedia Infobox表来评估几种当前的状态顶模型。</li>
<li>results: 研究人员发现，即使使用最高性能的语言模型（LLMs），其们在 TempTabQA 任务中的表现仍然落后人类性能的13.5个F1分点。这些结果表明， TempTabQA 数据集有potential来 serve as a challenging benchmark to improve the temporal reasoning capabilities of NLP models。<details>
<summary>Abstract</summary>
Semi-structured data, such as Infobox tables, often include temporal information about entities, either implicitly or explicitly. Can current NLP systems reason about such information in semi-structured tables? To tackle this question, we introduce the task of temporal question answering on semi-structured tables. We present a dataset, TempTabQA, which comprises 11,454 question-answer pairs extracted from 1,208 Wikipedia Infobox tables spanning more than 90 distinct domains. Using this dataset, we evaluate several state-of-the-art models for temporal reasoning. We observe that even the top-performing LLMs lag behind human performance by more than 13.5 F1 points. Given these results, our dataset has the potential to serve as a challenging benchmark to improve the temporal reasoning capabilities of NLP models.
</details>
<details>
<summary>摘要</summary>
现有的自然语言处理（NLP）系统是否可以理解半结构化数据中的时间信息？为了回答这个问题，我们介绍了半结构化表格中的时间问答任务。我们提供了一个数据集，TempTabQA，其中包含11,454个问答对 extracted from 1,208个Wikipedia Infobox表格，涵盖了 более90个不同领域。使用这个数据集，我们评估了多种当前状态的模型对时间理解能力。我们发现，even the top-performing LLMs lag behind human performance by more than 13.5 F1 points。 Based on these results, our dataset has the potential to serve as a challenging benchmark to improve the temporal reasoning capabilities of NLP models.
</details></li>
</ul>
<hr>
<h2 id="LiPar-A-Lightweight-Parallel-Learning-Model-for-Practical-In-Vehicle-Network-Intrusion-Detection"><a href="#LiPar-A-Lightweight-Parallel-Learning-Model-for-Practical-In-Vehicle-Network-Intrusion-Detection" class="headerlink" title="LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle Network Intrusion Detection"></a>LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle Network Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08000">http://arxiv.org/abs/2311.08000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangkai-tech23/LiPar">https://github.com/wangkai-tech23/LiPar</a></li>
<li>paper_authors: Aiheng Zhang, Kai Wang, Bailing Wang, Yulei Wu</li>
<li>for: 这个研究旨在提高智能交通系统中车辆网络的安全性，尤其是对 Controller Area Network (CAN) 的攻击探测。</li>
<li>methods: 本研究提出了一个轻量级平行神经网络结构（LiPar），用于分配任务负载到多个电子控制器（ECU）上。LiPar 模型包括多维度分支卷积网络、空间和时间特征融合学习和资源适应算法。</li>
<li>results: 经过实验证明，LiPar 具有优秀的检测性能、运行效率和轻量级模型大小，可以实际适用于车辆网络环境中，并能有效地保护车辆网络的 CAN 标准插座安全。<details>
<summary>Abstract</summary>
With the development of intelligent transportation systems, vehicles are exposed to a complex network environment. As the main network of in-vehicle networks, the controller area network (CAN) has many potential security hazards, resulting in higher requirements for intrusion detection systems to ensure safety. Among intrusion detection technologies, methods based on deep learning work best without prior expert knowledge. However, they all have a large model size and rely on cloud computing, and are therefore not suitable to be installed on the in-vehicle network. Therefore, we propose a lightweight parallel neural network structure, LiPar, to allocate task loads to multiple electronic control units (ECU). The LiPar model consists of multi-dimensional branch convolution networks, spatial and temporal feature fusion learning, and a resource adaptation algorithm. Through experiments, we prove that LiPar has great detection performance, running efficiency, and lightweight model size, which can be well adapted to the in-vehicle environment practically and protect the in-vehicle CAN bus security.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:随着智能交通系统的发展，车辆被暴露在复杂的网络环境中。CAN（控制器区域网络）作为车辆内网主要网络，具有许多安全隐患，因此需要更高的安全检测系统要求以确保安全。深度学习技术在检测技术中表现最佳，无需专业知识。然而，它们都具有大模型大小和依赖于云计算，因此不适合在车辆内网安装。因此，我们提出了一种轻量级并行神经网络结构，LiPar，以分配任务负担到多个电子控制单元（ECU）。LiPar模型包括多维分支卷积网络、空间和时间特征融合学习和资源适应算法。通过实验，我们证明了LiPar具有优秀的检测性能、运行效率和轻量级模型大小，可以实际上适应车辆环境，保护车辆CAN总线安全。
</details></li>
</ul>
<hr>
<h2 id="Probable-Object-Location-POLo-Score-Estimation-for-Efficient-Object-Goal-Navigation"><a href="#Probable-Object-Location-POLo-Score-Estimation-for-Efficient-Object-Goal-Navigation" class="headerlink" title="Probable Object Location (POLo) Score Estimation for Efficient Object Goal Navigation"></a>Probable Object Location (POLo) Score Estimation for Efficient Object Goal Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07992">http://arxiv.org/abs/2311.07992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaming Wang, Harold Soh</li>
<li>for: 提高自主机器人领域中对物体搜索任务的效率，特别是在未探索环境中。</li>
<li>methods: 使用可信度对象投影图创建可信度物体位置分布（POLo），并使用POLoNet neural network来近似计算复杂的POLo分布，从而帮助机器人做出数据驱动的决策。</li>
<li>results: 在OVMM 2023挑战的第一阶段中，一个装备有POLoNet的机器人significantly outperforms了许多基eline方法，包括末端奖励学习方法和传统的地图基本策略。<details>
<summary>Abstract</summary>
To advance the field of autonomous robotics, particularly in object search tasks within unexplored environments, we introduce a novel framework centered around the Probable Object Location (POLo) score. Utilizing a 3D object probability map, the POLo score allows the agent to make data-driven decisions for efficient object search. We further enhance the framework's practicality by introducing POLoNet, a neural network trained to approximate the computationally intensive POLo score. Our approach addresses critical limitations of both end-to-end reinforcement learning methods, which suffer from memory decay over long-horizon tasks, and traditional map-based methods that neglect visibility constraints. Our experiments, involving the first phase of the OVMM 2023 challenge, demonstrate that an agent equipped with POLoNet significantly outperforms a range of baseline methods, including end-to-end RL techniques and prior map-based strategies. To provide a comprehensive evaluation, we introduce new performance metrics that offer insights into the efficiency and effectiveness of various agents in object goal navigation.
</details>
<details>
<summary>摘要</summary>
Our experiments, which involve the first phase of the OVMM 2023 challenge, show that an agent equipped with POLoNet significantly outperforms a range of baseline methods, including end-to-end reinforcement learning techniques and prior map-based strategies. To provide a comprehensive evaluation, we introduce new performance metrics that offer insights into the efficiency and effectiveness of various agents in object goal navigation. Our proposed framework has the potential to greatly improve the performance of autonomous robotics in object search tasks within unexplored environments.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Language-Models-for-Code"><a href="#A-Survey-on-Language-Models-for-Code" class="headerlink" title="A Survey on Language Models for Code"></a>A Survey on Language Models for Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07989">http://arxiv.org/abs/2311.07989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/codefuse-ai/awesome-code-llm">https://github.com/codefuse-ai/awesome-code-llm</a></li>
<li>paper_authors: Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, Rui Wang</li>
<li>for: 本文系统性地综述了近期的代码处理方法，涵盖50+模型、30+评估任务以及500余相关工作。</li>
<li>methods: 本文将代码处理模型分为通用语言模型（如GPT家族）和专门预训练于代码的模型，讲述这些模型之间的关系和差异，并 highlights 代码模型的历史发展，从统计学模型和RNN逐渐转移到预训练的Transformers和LLMs，与NLP领域的发展轨迹一致。</li>
<li>results: 本文讨论了代码特有的特征，如AST、CFG和单元测试，以及它们在训练代码语言模型中的应用，并提出了代码处理领域的主要挑战和未来发展方向。<details>
<summary>Abstract</summary>
In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, and 500 related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on github repository at https://github.com/codefuse-ai/Awesome-Code-LLM.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们系统性地报告了最近的代码处理技术发展，涵盖50多种模型、30多种评估任务以及500多个相关作品。我们将代码处理模型分为普通的语言模型，如GPT家族，以及专门预训练于代码的模型，经常具有定制目标。我们讲述这些模型之间的关系和差异，并高亮代码模型从统计学模型和RNN逐渐发展到预训练的Transformers和LLMs的历史发展，与NLP领域的发展一样。我们还讲述代码特有的特征，如AST、CFG和单元测试，以及它们在训练代码语言模型中的应用，并标识代码处理领域的关键挑战和未来发展方向。我们将survey保持开放并更新在GitHub上的https://github.com/codefuse-ai/Awesome-Code-LLM文件夹中。
</details></li>
</ul>
<hr>
<h2 id="How-good-are-Large-Language-Models-on-African-Languages"><a href="#How-good-are-Large-Language-Models-on-African-Languages" class="headerlink" title="How good are Large Language Models on African Languages?"></a>How good are Large Language Models on African Languages?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07978">http://arxiv.org/abs/2311.07978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Jessica Ojo, Kelechi Ogueji, Pontus Stenetorp, David I. Adelani</li>
<li>for: This paper is written to analyze the performance of three popular large language models (mT0, LLaMa 2, and GPT-4) on 30 African languages across five tasks (news topic classification, sentiment classification, machine translation, question answering, and named entity recognition).</li>
<li>methods: The paper uses these three language models as-is or fine-tunes them on African languages to evaluate their performance on various tasks.</li>
<li>results: The results show that all three language models have below-par performance on African languages, with GPT-4 performing well on classification tasks but poorly on generative tasks like machine translation. mT0 has the best overall performance on cross-lingual question answering, outperforming fine-tuned mT5 and GPT-4 on African languages. LLaMa 2 has the worst performance due to its limited multilingual capabilities and English-centric pre-training corpus.Here are the results in Simplified Chinese text:</li>
<li>for: 这个研究是为了分析三种流行的大语言模型（mT0、LLaMa 2、GPT-4）在30种非洲语言上的五个任务（新闻类别分类、情感分类、机器翻译、问答和命名实体识别）的性能。</li>
<li>methods: 这些研究使用这三种语言模型的直接使用或对非洲语言进行了微调来评估它们的性能。</li>
<li>results: 结果显示所有三种语言模型在非洲语言上都表现不佳，GPT-4在分类任务上表现非常好，但在生成任务上表现非常差。mT0在跨语言问答任务上表现最好，超过了微调后的mT5和GPT-4在非洲语言上的性能。LLaMa 2的性能最差，因为它的多语言能力有限，预训练语料集也偏向英语。<details>
<summary>Abstract</summary>
Recent advancements in natural language processing have led to the proliferation of large language models (LLMs). These models have been shown to yield good performance, using in-context learning, even on unseen tasks and languages. Additionally, they have been widely adopted as language-model-as-a-service commercial APIs like GPT-4 API. However, their performance on African languages is largely unknown. We present an analysis of three popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks (news topic classification, sentiment classification, machine translation, question answering, and named entity recognition) across 30 African languages, spanning different language families and geographical regions. Our results suggest that all LLMs produce below-par performance on African languages, and there is a large gap in performance compared to high-resource languages like English most tasks. We find that GPT-4 has an average or impressive performance on classification tasks but very poor results on generative tasks like machine translation. Surprisingly, we find that mT0 had the best overall on cross-lingual QA, better than the state-of-the-art supervised model (i.e. fine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the worst performance due to its limited multilingual capabilities and English-centric pre-training corpus. In general, our findings present a call-to-action to ensure African languages are well represented in large language models, given their growing popularity.
</details>
<details>
<summary>摘要</summary>
近期的自然语言处理技术发展，使得大型语言模型（LLMs）在不同任务和语言上表现良好。这些模型已经广泛应用于语言模型作为服务的商业API，如GPT-4 API。然而，它们在非洲语言上的表现仍然不够了解。本文分析了三个流行的大型语言模型（mT0、LLaMa 2和GPT-4）在5个任务（新闻类别分类、情感分类、机器翻译、问答和命名实体识别） across 30种非洲语言，涵盖不同的语言家族和地理区域。我们的结果表明，所有的LLMs在非洲语言上表现较差，与高资源语言如英语的大多数任务相比，存在显著的性能差距。我们发现GPT-4在分类任务上表现很出色，但在生成任务如机器翻译中表现很差。另外，我们发现mT0在跨语言问答任务上表现最佳，高于现有的超级模型（即精心调教的mT5）和GPT-4。总的来说，LLaMa 2的表现最差，主要是因为它的多语言能力有限，以及英语中心的预训练集。在总的来说，我们的发现表现出了需要确保非洲语言在大型语言模型中得到良好表现的呼吁。
</details></li>
</ul>
<hr>
<h2 id="Uplift-Modeling-based-on-Graph-Neural-Network-Combined-with-Causal-Knowledge"><a href="#Uplift-Modeling-based-on-Graph-Neural-Network-Combined-with-Causal-Knowledge" class="headerlink" title="Uplift Modeling based on Graph Neural Network Combined with Causal Knowledge"></a>Uplift Modeling based on Graph Neural Network Combined with Causal Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08434">http://arxiv.org/abs/2311.08434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xy2119/Causal_Knowledge_GNN">https://github.com/xy2119/Causal_Knowledge_GNN</a></li>
<li>paper_authors: Haowen Wang, Xinyan Ye, Yangze Zhou, Zhiyi Zhang, Longhan Zhang, Jing Jiang</li>
<li>for: 这个论文的目的是提出一种基于图 neural network 的 uplift 模型，用于评估待遇的影响。</li>
<li>methods: 该论文使用了 causal 表示法和 adjacency matrix 结构学习，以及基于图 convolution network 的更可扩展的 uplift 模型。</li>
<li>results: 该论文的实验结果表明，该方法可以准确预测 uplift 值，并且在实际行业市场数据中得到了验证。<details>
<summary>Abstract</summary>
Uplift modeling is a fundamental component of marketing effect modeling, which is commonly employed to evaluate the effects of treatments on outcomes. Through uplift modeling, we can identify the treatment with the greatest benefit. On the other side, we can identify clients who are likely to make favorable decisions in response to a certain treatment. In the past, uplift modeling approaches relied heavily on the difference-in-difference (DID) architecture, paired with a machine learning model as the estimation learner, while neglecting the link and confidential information between features. We proposed a framework based on graph neural networks that combine causal knowledge with an estimate of uplift value. Firstly, we presented a causal representation technique based on CATE (conditional average treatment effect) estimation and adjacency matrix structure learning. Secondly, we suggested a more scalable uplift modeling framework based on graph convolution networks for combining causal knowledge. Our findings demonstrate that this method works effectively for predicting uplift values, with small errors in typical simulated data, and its effectiveness has been verified in actual industry marketing data.
</details>
<details>
<summary>摘要</summary>
<<SYS>>用简化中文表示：</SYS>>市场效果模型的一个基本组成部分是升级模型，用于评估干预的影响。通过升级模型，我们可以确定具有最大 benefit 的干预。另一方面，我们可以确定响应特定干预的客户，并且可以预测这些客户会作出有利决策。在过去，升级模型方法都是基于差异分析（DID）架构，并将机器学习模型作为估计学习者，而忽略特征之间的关系。我们提出了基于图 neural network 的框架，将 causal 知识与升级值估计相结合。首先，我们提出了一种基于 CATE（条件减差异效应）估计的 causal 表示技术，并学习邻接矩阵结构。其次，我们建议一种更可扩展的升级模型框架，基于图 convolution network 组合 causal 知识。我们的发现表明，这种方法可以有效地预测升级值，并且在 Typical 的模拟数据中具有小的误差。此外，我们的实际业务数据也证明了其效果。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Object-Detection-in-Maritime-Unmanned-Aerial-Vehicle-Imagery-Review-and-Experimental-Comparisons"><a href="#Deep-Learning-Based-Object-Detection-in-Maritime-Unmanned-Aerial-Vehicle-Imagery-Review-and-Experimental-Comparisons" class="headerlink" title="Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle Imagery: Review and Experimental Comparisons"></a>Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle Imagery: Review and Experimental Comparisons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07955">http://arxiv.org/abs/2311.07955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenjie Zhao, Ryan Wen Liu, Jingxiang Qu, Ruobin Gao</li>
<li>for: 本研究旨在探讨水上无人机（UAV）上的对象检测问题，尤其是在marine industry和ocean engineering领域中。</li>
<li>methods: 本文首先简要概述了水上UAV对象检测中的四大挑战，包括对象特征多样性、设备限制、海洋环境变化和数据缺乏等问题。然后，我们主要介绍了 Computational Methods 来提高水上UAV对象检测性能，包括Scale-aware、小对象检测、视角意识、旋转对象检测、轻量级方法等。</li>
<li>results: 本文还进行了一系列实验，以评估和分析对象检测方法在海洋数据集上的性能和稳定性。最后，我们给出了未来水上UAV对象检测的讨论和展望。 MS2ship数据集可以在 \href{<a target="_blank" rel="noopener" href="https://github.com/zcj234/MS2ship%7D%7Bhttps://github.com/zcj234/MS2ship%7D">https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}</a> 上下载。<details>
<summary>Abstract</summary>
With the advancement of maritime unmanned aerial vehicles (UAVs) and deep learning technologies, the application of UAV-based object detection has become increasingly significant in the fields of maritime industry and ocean engineering. Endowed with intelligent sensing capabilities, the maritime UAVs enable effective and efficient maritime surveillance. To further promote the development of maritime UAV-based object detection, this paper provides a comprehensive review of challenges, relative methods, and UAV aerial datasets. Specifically, in this work, we first briefly summarize four challenges for object detection on maritime UAVs, i.e., object feature diversity, device limitation, maritime environment variability, and dataset scarcity. We then focus on computational methods to improve maritime UAV-based object detection performance in terms of scale-aware, small object detection, view-aware, rotated object detection, lightweight methods, and others. Next, we review the UAV aerial image/video datasets and propose a maritime UAV aerial dataset named MS2ship for ship detection. Furthermore, we conduct a series of experiments to present the performance evaluation and robustness analysis of object detection methods on maritime datasets. Eventually, we give the discussion and outlook on future works for maritime UAV-based object detection. The MS2ship dataset is available at \href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}.
</details>
<details>
<summary>摘要</summary>
随着水上无人飞行器（UAV）和深度学习技术的发展，水上UAV-基于物体探测的应用在marine industry和 ocean engineering领域变得越来越重要。搭载智能感知功能的水上UAV可以实现效果性的水上监测。为了进一步推动水上UAV-基于物体探测的发展，本文提供了全面的挑战、相关方法和UAV飞行图像/视频数据集的评审。具体来说，在本工作中，我们首先 briefly summarize four challenges for object detection on water-based UAVs, i.e., object feature diversity, device limitation, maritime environment variability, and dataset scarcity.然后，我们将关注计算方法，以提高水上UAV-基于物体探测性能，包括尺度感知、小物体探测、视角感知、旋转物体探测、轻量级方法等。接着，我们对UAV飞行图像/视频数据集进行了评审，并提出了一个名为MS2ship的水上UAV飞行数据集，用于船舶检测。然后，我们进行了一系列实验，以评估和分析物体探测方法在水上数据集上的性能和稳定性。最后，我们给出了未来水上UAV-基于物体探测的发展展望。MS2ship数据集可以在 <https://github.com/zcj234/MS2ship> 中下载。
</details></li>
</ul>
<hr>
<h2 id="A-Closer-Look-at-the-Self-Verification-Abilities-of-Large-Language-Models-in-Logical-Reasoning"><a href="#A-Closer-Look-at-the-Self-Verification-Abilities-of-Large-Language-Models-in-Logical-Reasoning" class="headerlink" title="A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning"></a>A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07954">http://arxiv.org/abs/2311.07954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang</li>
<li>for: 这篇论文探讨了使用自我检查来提高人工智能（AI）逻辑推理能力的可能性，尤其是在逻辑推理问题上。</li>
<li>methods: 论文使用了许多自我验证方法，包括使用各种逻辑缺陷数据集，对模型进行评估，并分析模型的逻辑推理能力。</li>
<li>results: 研究发现现有的大型语言模型（LLM）在逻辑推理问题上可能会准确地识别逻辑缺陷，但是它们可能无法准确地检查自己的逻辑推理步骤。<details>
<summary>Abstract</summary>
Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>人工智能领域内，逻辑推理一直是一项不断探索的领域。虽然大语言模型（LLMs）已经做出了 significativo进步，但它们仍然在复杂的逻辑推理问题上困难。以提高推理性能为目的，一个有前途的方向是可扩展的监督，需要 LLMs 能够自我检查并自我改进。各种自我验证方法已经被提出，但是现有模型是否能够准确地识别自己的错误仍然在调查中。在这篇论文中，我们坚持关注 LLMs 在逻辑推理上的自我验证能力，特别是它们能够准确地识别逻辑错误的能力。我们提出了一个名为 FALLACIES 的数据集，包含 232 种逻辑错误分类在层次分类中。通过对 FALLACIES 进行探索性实验，我们获得了详细和全面的模型评估结果。我们的主要发现表明现有的 LLMs 可能会在准确地识别逻辑错误步骤上遇到困难，并且可能无法保证自我验证方法的有效性。基于这些观察，我们提出了未来研究和实践自我验证方法的建议。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Adversarial-Node-Placement-in-Decentralized-Federated-Learning-Networks"><a href="#The-Impact-of-Adversarial-Node-Placement-in-Decentralized-Federated-Learning-Networks" class="headerlink" title="The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks"></a>The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07946">http://arxiv.org/abs/2311.07946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adampi210/maxspanfl_atck_code_data">https://github.com/adampi210/maxspanfl_atck_code_data</a></li>
<li>paper_authors: Adam Piaseczny, Eric Ruzomberka, Rohit Parasnis, Christopher G. Brinton</li>
<li>for: 本研究探讨了分布式学习（Federated Learning，FL）中对抗性节点布置的影响，并提出了一种新的攻击算法，以提高攻击效果。</li>
<li>methods: 本研究使用了分布式环境的优势，实现了快速和能量减少的设备之间通信。并对各种抗性节点布置策略进行了分析，包括随机布置和网络中心性基于的布置。</li>
<li>results: 研究发现，新的攻击算法可以大大提高攻击效果，比基eline框架提高9%-66.5%。这些发现提供了对分布式FL安全性的重要性的新的视角，并为未来关于开发更安全和可靠的分布式FL框架的研究提供了基础。<details>
<summary>Abstract</summary>
As Federated Learning (FL) grows in popularity, new decentralized frameworks are becoming widespread. These frameworks leverage the benefits of decentralized environments to enable fast and energy-efficient inter-device communication. However, this growing popularity also intensifies the need for robust security measures. While existing research has explored various aspects of FL security, the role of adversarial node placement in decentralized networks remains largely unexplored. This paper addresses this gap by analyzing the performance of decentralized FL for various adversarial placement strategies when adversaries can jointly coordinate their placement within a network. We establish two baseline strategies for placing adversarial node: random placement and network centrality-based placement. Building on this foundation, we propose a novel attack algorithm that prioritizes adversarial spread over adversarial centrality by maximizing the average network distance between adversaries. We show that the new attack algorithm significantly impacts key performance metrics such as testing accuracy, outperforming the baseline frameworks by between 9% and 66.5% for the considered setups. Our findings provide valuable insights into the vulnerabilities of decentralized FL systems, setting the stage for future research aimed at developing more secure and robust decentralized FL frameworks.
</details>
<details>
<summary>摘要</summary>
随着联合学习（FL）的崛起，新的分布式框架在广泛应用。这些框架利用分布式环境中的优势来实现快速和能效的设备间通信。然而，这种崛起也使得FL安全性的需求更加紧迫。 existed research 已经探讨了FL安全性的多个方面，但尚未考虑分布式网络中反对者的协调 placement 的影响。这篇论文填补这个空白，分析了不同的反对者协调 placement 策略在分布式FL中的性能。我们提出了两种基eline策略：随机分布和网络中心性基eline策略。基于这个基础，我们提出了一种新的攻击算法，它强调对抗扩散而不是对抗中心性，通过最大化网络距离 между反对者来 maximize 平均网络距离。我们显示，新的攻击算法对测试精度和其他关键性能指标产生了深见影响，在考虑的设置中，相比基eline框架，新的攻击算法可以提高9%到66.5%的testing accuracy。我们的发现为分布式FL系统的安全性提供了重要的技术指导，为未来针对更安全和可靠的分布式FL框架的研究奠定了基础。
</details></li>
</ul>
<hr>
<h2 id="Non-autoregressive-Machine-Translation-with-Probabilistic-Context-free-Grammar"><a href="#Non-autoregressive-Machine-Translation-with-Probabilistic-Context-free-Grammar" class="headerlink" title="Non-autoregressive Machine Translation with Probabilistic Context-free Grammar"></a>Non-autoregressive Machine Translation with Probabilistic Context-free Grammar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07941">http://arxiv.org/abs/2311.07941</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictnlp/pcfg-nat">https://github.com/ictnlp/pcfg-nat</a></li>
<li>paper_authors: Shangtong Gui, Chenze Shao, Zhengrui Ma, Xishan Zhang, Yunji Chen, Yang Feng</li>
<li>for: 加速神经机器翻译的推理</li>
<li>methods: 使用特制的概率 контекст自由格式(PCFG) 进行优化</li>
<li>results: 提高神经机器翻译的表达能力和性能，并且可以更深入地理解生成的句子<details>
<summary>Abstract</summary>
Non-autoregressive Transformer(NAT) significantly accelerates the inference of neural machine translation. However, conventional NAT models suffer from limited expression power and performance degradation compared to autoregressive (AT) models due to the assumption of conditional independence among target tokens. To address these limitations, we propose a novel approach called PCFG-NAT, which leverages a specially designed Probabilistic Context-Free Grammar (PCFG) to enhance the ability of NAT models to capture complex dependencies among output tokens. Experimental results on major machine translation benchmarks demonstrate that PCFG-NAT further narrows the gap in translation quality between NAT and AT models. Moreover, PCFG-NAT facilitates a deeper understanding of the generated sentences, addressing the lack of satisfactory explainability in neural machine translation.Code is publicly available at https://github.com/ictnlp/PCFG-NAT.
</details>
<details>
<summary>摘要</summary>
非autoregressive Transformer（NAT）对神经机器翻译的推理具有显著的加速效果。然而，传统的 NAT 模型由于假设目标符号之间的条件独立性而受到限制，导致表现力和精度相比 autoregressive（AT）模型受到限制。为了解决这些局限性，我们提出了一种新的方法called PCFG-NAT，该方法利用特殊设计的概率 context-free grammar（PCFG）来增强 NAT 模型对输出符号之间的复杂依赖关系的捕捉能力。实验结果表明，PCFG-NAT 可以进一步缩小 NAT 和 AT 模型之间的翻译质量差距。此外，PCFG-NAT 可以更好地解释生成的句子，解决神经机器翻译中缺乏满意的解释性的问题。代码可以在 GitHub 上获取：https://github.com/ictnlp/PCFG-NAT。
</details></li>
</ul>
<hr>
<h2 id="Towards-Improving-Robustness-Against-Common-Corruptions-in-Object-Detectors-Using-Adversarial-Contrastive-Learning"><a href="#Towards-Improving-Robustness-Against-Common-Corruptions-in-Object-Detectors-Using-Adversarial-Contrastive-Learning" class="headerlink" title="Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning"></a>Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07928">http://arxiv.org/abs/2311.07928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Kotyan, Danilo Vasconcellos Vargas</li>
<li>for: 强化神经网络的可靠性，尤其是在自动驾驶应用中，以满足实际场景中的可靠性要求。</li>
<li>methods: 提出了一种创新的对抗学习框架，通过生成对抗示例并优化对抗损失来增强神经网络的对抗性和常规损害性。</li>
<li>results: 通过实验表明，该方法可以同时提高神经网络对抗性和常规损害性，并在实际场景中保持高度可靠性。<details>
<summary>Abstract</summary>
Neural networks have revolutionized various domains, exhibiting remarkable accuracy in tasks like natural language processing and computer vision. However, their vulnerability to slight alterations in input samples poses challenges, particularly in safety-critical applications like autonomous driving. Current approaches, such as introducing distortions during training, fall short in addressing unforeseen corruptions. This paper proposes an innovative adversarial contrastive learning framework to enhance neural network robustness simultaneously against adversarial attacks and common corruptions. By generating instance-wise adversarial examples and optimizing contrastive loss, our method fosters representations that resist adversarial perturbations and remain robust in real-world scenarios. Subsequent contrastive learning then strengthens the similarity between clean samples and their adversarial counterparts, fostering representations resistant to both adversarial attacks and common distortions. By focusing on improving performance under adversarial and real-world conditions, our approach aims to bolster the robustness of neural networks in safety-critical applications, such as autonomous vehicles navigating unpredictable weather conditions. We anticipate that this framework will contribute to advancing the reliability of neural networks in challenging environments, facilitating their widespread adoption in mission-critical scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Brain-Driven-Representation-Learning-Based-on-Diffusion-Model"><a href="#Brain-Driven-Representation-Learning-Based-on-Diffusion-Model" class="headerlink" title="Brain-Driven Representation Learning Based on Diffusion Model"></a>Brain-Driven Representation Learning Based on Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07925">http://arxiv.org/abs/2311.07925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soowon Kim, Seo-Hyun Lee, Young-Eun Lee, Ji-Won Lee, Ji-Ha Park, Seong-Whan Lee</li>
<li>for: 用于分析语音相关的EEG信号</li>
<li>methods: 使用Diffusion Probabilistic Models（DDPMs）和条件autoencoder</li>
<li>results: 新方法的准确率明显高于传统机器学习算法和已有基eline模型<details>
<summary>Abstract</summary>
Interpreting EEG signals linked to spoken language presents a complex challenge, given the data's intricate temporal and spatial attributes, as well as the various noise factors. Denoising diffusion probabilistic models (DDPMs), which have recently gained prominence in diverse areas for their capabilities in representation learning, are explored in our research as a means to address this issue. Using DDPMs in conjunction with a conditional autoencoder, our new approach considerably outperforms traditional machine learning algorithms and established baseline models in accuracy. Our results highlight the potential of DDPMs as a sophisticated computational method for the analysis of speech-related EEG signals. This could lead to significant advances in brain-computer interfaces tailored for spoken communication.
</details>
<details>
<summary>摘要</summary>
interpreting EEG signals linked to spoken language presented a complex challenge, given the data's intricate temporal and spatial attributes, as well as the various noise factors. denoising diffusion probabilistic models (DDPMs), which have recently gained prominence in diverse areas for their capabilities in representation learning, are explored in our research as a means to address this issue. using DDPMs in conjunction with a conditional autoencoder, our new approach considerably outperforms traditional machine learning algorithms and established baseline models in accuracy. our results highlight the potential of DDPMs as a sophisticated computational method for the analysis of speech-related EEG signals. this could lead to significant advances in brain-computer interfaces tailored for spoken communication.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Smart-Home-Goal-Feature-Model-–-A-guide-to-support-Smart-Homes-for-Ageing-in-Place"><a href="#Smart-Home-Goal-Feature-Model-–-A-guide-to-support-Smart-Homes-for-Ageing-in-Place" class="headerlink" title="Smart Home Goal Feature Model – A guide to support Smart Homes for Ageing in Place"></a>Smart Home Goal Feature Model – A guide to support Smart Homes for Ageing in Place</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09248">http://arxiv.org/abs/2311.09248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irini Logothetis, Priya Rani, Shangeetha Sivasothy, Rajesh Vasa, Kon Mouzakis</li>
<li>for: This paper provides an overview of smart home technologies that support ageing in place, and offers a structured approach to design, develop, and deploy smart homes for the elderly based on their personalized needs.</li>
<li>methods: The paper synthesizes prior knowledge and creates a Smart Home Goal Feature Model (SHGFM) to resolve heuristic approaches used by Subject Matter Experts (SMEs) and healthcare researchers in adapting smart homes for the elderly.</li>
<li>results: The SHGFM provides SMEs with the ability to establish goals and identify features to set up strategies for designing, developing, and deploying smart homes that meet the needs of the elderly.<details>
<summary>Abstract</summary>
Smart technologies are significant in supporting ageing in place for elderly. Leveraging Artificial Intelligence (AI) and Machine Learning (ML), it provides peace of mind, enabling the elderly to continue living independently. Elderly use smart technologies for entertainment and social interactions, this can be extended to provide safety and monitor health and environmental conditions, detect emergencies and notify informal and formal caregivers when care is needed. This paper provides an overview of the smart home technologies commercially available to support ageing in place, the advantages and challenges of smart home technologies, and their usability from elderlys perspective. Synthesizing prior knowledge, we created a structured Smart Home Goal Feature Model (SHGFM) to resolve heuristic approaches used by the Subject Matter Experts (SMEs) at aged care facilities and healthcare researchers in adapting smart homes. The SHGFM provides SMEs the ability to (i) establish goals and (ii) identify features to set up strategies to design, develop and deploy smart homes for the elderly based on personalised needs. Our model provides guidance to healthcare researchers and aged care industries to set up smart homes based on the needs of elderly, by defining a set of goals at different levels mapped to a different set of features.
</details>
<details>
<summary>摘要</summary>
智能技术支持老年人在家中生活，通过人工智能（AI）和机器学习（ML）提供了心理安全，让老年人可以独立地生活。老年人使用智能技术进行娱乐和社交交流，这可以扩展到提供安全和监测健康和环境条件，检测紧急情况并通知正式和非正式照顾者当照顾是需要的。本文提供了智能家居技术商业化应用的概述，以及智能家居技术的优势和挑战，以及老年人的用户视角。我们synthesize了先前的知识，创建了一个结构化的智能家居目标特征模型（SHGFM），以解决 aged care 设施和医疗研究人员使用智能家居时采用的规则性方法。SHGFM 让 SME 能够（i）确定目标和（ii）标识特征，以设立策略设计、开发和部署智能家居。我们的模型为医疗研究人员和 aged care 产业提供指导，以设置智能家居基于老年人需求的。我们定义了不同层次的目标，与不同的特征集成，以便在不同的情况下设置智能家居。
</details></li>
</ul>
<hr>
<h2 id="Instruction-Following-Evaluation-for-Large-Language-Models"><a href="#Instruction-Following-Evaluation-for-Large-Language-Models" class="headerlink" title="Instruction-Following Evaluation for Large Language Models"></a>Instruction-Following Evaluation for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07911">http://arxiv.org/abs/2311.07911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, Le Hou</li>
<li>for:  This paper aims to evaluate the ability of large language models (LLMs) to follow natural language instructions in a standardized and objective manner.</li>
<li>methods: The paper introduces a new evaluation benchmark called Instruction-Following Eval (IFEval) that focuses on a set of verifiable instructions, such as writing in more than 400 words or mentioning the keyword of AI at least three times.</li>
<li>results: The authors evaluate two widely available LLMs on the market using the IFEval benchmark and show the results, which can be found at <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research/tree/master/instruction_following_eval">https://github.com/google-research/google-research/tree/master/instruction_following_eval</a>.<details>
<summary>Abstract</summary>
One core capability of Large Language Models (LLMs) is to follow natural language instructions. However, the evaluation of such abilities is not standardized: Human evaluations are expensive, slow, and not objectively reproducible, while LLM-based auto-evaluation is potentially biased or limited by the ability of the evaluator LLM. To overcome these issues, we introduce Instruction-Following Eval (IFEval) for large language models. IFEval is a straightforward and easy-to-reproduce evaluation benchmark. It focuses on a set of "verifiable instructions" such as "write in more than 400 words" and "mention the keyword of AI at least 3 times". We identified 25 types of those verifiable instructions and constructed around 500 prompts, with each prompt containing one or more verifiable instructions. We show evaluation results of two widely available LLMs on the market. Our code and data can be found at https://github.com/google-research/google-research/tree/master/instruction_following_eval
</details>
<details>
<summary>摘要</summary>
一种核心能力 OF Large Language Models (LLMs) 是遵循自然语言指令。然而，评估这种能力的标准化不存在：人工评估昂贵、慢速、不可重复，而 LLB-based auto-evaluation 可能受到评估LLM的能力的偏见或限制。为解决这些问题，我们介绍了 Instruction-Following Eval (IFEval)，一个简单易复制的评估标准。它关注一组 "可靠指令"，如 "写入 более 400 字" 和 "在至少三次提及 AI 关键词中提及 AI"。我们分类了 25 种这些可靠指令，并构建了约 500 个提示，每个提示包含一个或多个可靠指令。我们展示了两个市场上广泛使用的 LLB 的评估结果。我们的代码和数据可以在 https://github.com/google-research/google-research/tree/master/instruction_following_eval 找到。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Humans-GPT-4-and-GPT-4V-On-Abstraction-and-Reasoning-Tasks"><a href="#Comparing-Humans-GPT-4-and-GPT-4V-On-Abstraction-and-Reasoning-Tasks" class="headerlink" title="Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks"></a>Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09247">http://arxiv.org/abs/2311.09247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Melanie Mitchell, Alessandro B. Palmarini, Arseny Moskvichev</li>
<li>for: 评估 GPT-4 和 GPT-4V 在概念理解和推理方面的能力，使用 ConceptARC  benchmark。</li>
<li>methods: 使用 text 和 image 版本的 ConceptARC 任务，对 GPT-4 和 GPT-4V 进行评估。</li>
<li>results: GPT-4 和 GPT-4V 未能达到人类水平的抽象能力， neither version of GPT-4 has developed robust abstraction abilities at humanlike levels。<details>
<summary>Abstract</summary>
We explore the abstract reasoning abilities of text-only and multimodal versions of GPT-4, using the ConceptARC benchmark [10], which is designed to evaluate robust understanding and reasoning with core-knowledge concepts. We extend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed, one-shot prompting (rather than simple, zero-shot prompts) with text versions of ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4, on zero- and one-shot prompts using image versions of the simplest tasks. Our experimental results support the conclusion that neither version of GPT-4 has developed robust abstraction abilities at humanlike levels.
</details>
<details>
<summary>摘要</summary>
我们研究了基于文本和多媒体版本的GPT-4的抽象理解能力，使用ConceptARCbenchmark [10]，这是一个用于评估基本知识概念的理解和逻辑能力的测试。我们在 Moskvichev et al. [10] 的工作中进一步扩展了GPT-4的测试，使用文本版本的ConceptARC任务，并对GPT-4V，多媒体版本的GPT-4，进行零shot和一shot提示测试。我们的实验结果表明， neither version of GPT-4 在人类水平的抽象能力达到了人类水平。
</details></li>
</ul>
<hr>
<h2 id="RoboSense-At-Edge-Detecting-Slip-Crumple-and-Shape-of-the-Object-in-Robotic-Hand-for-Teleoprations"><a href="#RoboSense-At-Edge-Detecting-Slip-Crumple-and-Shape-of-the-Object-in-Robotic-Hand-for-Teleoprations" class="headerlink" title="RoboSense At Edge: Detecting Slip, Crumple and Shape of the Object in Robotic Hand for Teleoprations"></a>RoboSense At Edge: Detecting Slip, Crumple and Shape of the Object in Robotic Hand for Teleoprations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07888">http://arxiv.org/abs/2311.07888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudev Kumar Padhi, Mohit Kumar, Debanka Giri, Subidh Ali</li>
<li>for: 这个论文是为了解决机器人手上的滑块和损坏问题，以便在远程手术等精准 manipulate 任务中实现稳定性。</li>
<li>methods: 该论文提出了基于机器学习技术的滑块、损坏和物体形状检测方法，通过测量机器人手上的力&#x2F;扭矩和旋转角度来实现。</li>
<li>results: 该论文的实验结果表明，基于机器学习模型的滑块、损坏和物体形状检测方法可以减少机器人手上的延迟，提高远程手术等精准 manipulate 任务的稳定性。<details>
<summary>Abstract</summary>
Slip and crumple detection is essential for performing robust manipulation tasks with a robotic hand (RH) like remote surgery. It has been one of the challenging problems in the robotics manipulation community. In this work, we propose a technique based on machine learning (ML) based techniques to detect the slip, and crumple as well as the shape of an object that is currently held in the robotic hand. We proposed ML model will detect the slip, crumple, and shape using the force/torque exerted and the angular positions of the actuators present in the RH. The proposed model would be integrated into the loop of a robotic hand(RH) and haptic glove(HG). This would help us to reduce the latency in case of teleoperation
</details>
<details>
<summary>摘要</summary>
摸擦和损坏检测是Robotic hand(RH)进行稳定的操作任务的重要前提。这是机器人控制领域的一个挑战。在这种工作中，我们提议一种基于机器学习(ML)技术的检测方法，可以检测RH中持有物体的摸擦、损坏以及形状。我们的ML模型将通过RH上的力/扭矩和活动器的角度位置来检测摸擦、损坏和形状。我们的模型将被 интеGRATED到RH和Haptic glove(HG)的控制循环中，以减少在远程操作中的延迟。
</details></li>
</ul>
<hr>
<h2 id="One-2-3-45-Fast-Single-Image-to-3D-Objects-with-Consistent-Multi-View-Generation-and-3D-Diffusion"><a href="#One-2-3-45-Fast-Single-Image-to-3D-Objects-with-Consistent-Multi-View-Generation-and-3D-Diffusion" class="headerlink" title="One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion"></a>One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07885">http://arxiv.org/abs/2311.07885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghua Liu, Ruoxi Shi, Linghao Chen, Zhuoyang Zhang, Chao Xu, Xinyue Wei, Hansheng Chen, Chong Zeng, Jiayuan Gu, Hao Su</li>
<li>for: 这个论文旨在提供一种能够快速生成高质量3D对象的方法，以满足实际应用需求。</li>
<li>methods: 该方法首先在2D扩散模型中进行了finetuning，以实现多视图图像生成的一致性。然后，使用多视图conditioned 3D本地扩散模型来提升这些图像到3D。</li>
<li>results: 实验表明，该方法可以生成高质量、多样化的3D资产，与输入图像具有高度的相似性。Here’s the translation in English:</li>
<li>for: This paper aims to provide a method for rapidly generating high-quality 3D objects, to meet practical application requirements.</li>
<li>methods: The method first finetunes a 2D diffusion model for multi-view image generation consistency. Then, it elevates these images to 3D using multi-view conditioned 3D native diffusion models.</li>
<li>results: Experimental results show that the method can generate high-quality, diverse 3D assets that closely mirror the original input image.<details>
<summary>Abstract</summary>
Recent advancements in open-world 3D object generation have been remarkable, with image-to-3D methods offering superior fine-grained control over their text-to-3D counterparts. However, most existing models fall short in simultaneously providing rapid generation speeds and high fidelity to input images - two features essential for practical applications. In this paper, we present One-2-3-45++, an innovative method that transforms a single image into a detailed 3D textured mesh in approximately one minute. Our approach aims to fully harness the extensive knowledge embedded in 2D diffusion models and priors from valuable yet limited 3D data. This is achieved by initially finetuning a 2D diffusion model for consistent multi-view image generation, followed by elevating these images to 3D with the aid of multi-view conditioned 3D native diffusion models. Extensive experimental evaluations demonstrate that our method can produce high-quality, diverse 3D assets that closely mirror the original input image. Our project webpage: https://sudo-ai-3d.github.io/One2345plus_page.
</details>
<details>
<summary>摘要</summary>
近期开放世界3D物体生成技术得到了非常显著的进步，图像到3D方法可以提供细化控制，而文本到3D方法则不足。然而，大多数现有模型都缺乏同时提供快速生成速度和高精度输入图像的能力，这两个特点是实际应用中必不可少的。在这篇论文中，我们介绍了One-2-3-45++方法，可以将单张图像转化为细化的3D纹理网格，在大约一分钟内完成。我们的方法利用了丰富的2D扩散模型和3D数据的价值，通过首先训练2D扩散模型，然后使用多视图conditioned 3D本地扩散模型来提升这些图像到3D。我们的实验证明，我们的方法可以生成高质量、多样的3D资产，与输入图像几乎一致。更多信息请访问我们的项目网页：<https://sudo-ai-3d.github.io/One2345plus_page.>
</details></li>
</ul>
<hr>
<h2 id="VegaEdge-Edge-AI-Confluence-Anomaly-Detection-for-Real-Time-Highway-IoT-Applications"><a href="#VegaEdge-Edge-AI-Confluence-Anomaly-Detection-for-Real-Time-Highway-IoT-Applications" class="headerlink" title="VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications"></a>VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07880">http://arxiv.org/abs/2311.07880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinit Katariya, Fatema-E- Jannat, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Hamed Tabkhi</li>
<li>for: 本研究旨在提出一种车辆异常检测方法，用于高速公路安全应用，如事故预防、快速应急救援、交通流优化和工zone安全。</li>
<li>methods: 本研究使用轨迹预测来实现车辆异常检测，并提出了一种基于AI的车辆异常检测方法，可以适应互联网时代的高速公路应用。</li>
<li>results: 实验结果表明，在多个平台和交通场景下，我们的异常检测方法具有高效和灵活性，并且在真实的高速公路环境中可以实时处理738个轨迹每秒。此外，我们还提供了一个新的高速公路异常数据集（CAD），以填补现有的异常数据集不足。<details>
<summary>Abstract</summary>
Vehicle anomaly detection plays a vital role in highway safety applications such as accident prevention, rapid response, traffic flow optimization, and work zone safety. With the surge of the Internet of Things (IoT) in recent years, there has arisen a pressing demand for Artificial Intelligence (AI) based anomaly detection methods designed to meet the requirements of IoT devices. Catering to this futuristic vision, we introduce a lightweight approach to vehicle anomaly detection by utilizing the power of trajectory prediction. Our proposed design identifies vehicles deviating from expected paths, indicating highway risks from different camera-viewing angles from real-world highway datasets. On top of that, we present VegaEdge - a sophisticated AI confluence designed for real-time security and surveillance applications in modern highway settings through edge-centric IoT-embedded platforms equipped with our anomaly detection approach. Extensive testing across multiple platforms and traffic scenarios showcases the versatility and effectiveness of VegaEdge. This work also presents the Carolinas Anomaly Dataset (CAD), to bridge the existing gap in datasets tailored for highway anomalies. In real-world scenarios, our anomaly detection approach achieves an AUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform, processes 738 trajectories per second in a typical highway setting. The dataset is available at https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set .
</details>
<details>
<summary>摘要</summary>
高速公路安全应用中的车辆异常检测扮演着重要的角色，包括事故预防、快速应急救援、交通流动优化和工区安全。随着互联网物联网（IoT）的普及，有一种强烈的需求，即基于人工智能（AI）的异常检测方法，以满足IoT设备的需求。为满足这一未来视野，我们提出了一种轻量级的车辆异常检测方法，利用轨迹预测的力量。我们的提议的设计可以在不同的摄像头视角上检测出车辆异常行为，从真实的高速公路数据集中提取出高速公路风险。此外，我们还提出了一种名为VegaEdge的智能抽象设计，针对现代高速公路环境中的实时安全监测应用。VegaEdge通过在边缘式IoT设备上实现，可以实现实时的安全监测和响应。我们对多个平台和交通enario进行了广泛的测试，显示了VegaEdge的多平台性和效果。此外，我们还提供了 Carolinas Anomaly Dataset（CAD），用于bridging现有的高速公路异常数据集之间的 gap。在实际应用中，我们的异常检测方法实现了AUC-ROC的0.94，而我们提议的VegaEdge设计在一个常见的高速公路环境中，在边缘式IoT平台上处理了738个轨迹每秒。数据集可以在https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set 中获取。
</details></li>
</ul>
<hr>
<h2 id="Toxicity-Detection-is-NOT-all-you-Need-Measuring-the-Gaps-to-Supporting-Volunteer-Content-Moderators"><a href="#Toxicity-Detection-is-NOT-all-you-Need-Measuring-the-Gaps-to-Supporting-Volunteer-Content-Moderators" class="headerlink" title="Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators"></a>Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07879">http://arxiv.org/abs/2311.07879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Trista Cao, Lovely-Frances Domingo, Sarah Ann Gilbert, Michelle Mazurek, Katie Shilton, Hal Daumé III</li>
<li>for: 本研究旨在检验过去的自动化内容审核方法是否能满足志愿者审核员的需求。</li>
<li>methods: 本研究使用模型评估平台上的模型和现有的LLMs（GPT-4和Llama-2），评估这些模型在违反平台规则时的表现。</li>
<li>results: 研究发现，现有的模型和LLMs具有低回归率，表明存在较大的差距。<details>
<summary>Abstract</summary>
Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content -- with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks truly address the needs that moderators have in accomplishing their work. In this paper, we surface the gaps between past research efforts that have aimed to provide automation for aspects of the content moderation task, and the needs of volunteer content moderators. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines. We further put state-of-the-art LLMs to the test (GPT-4 and Llama-2), evaluating how well these models perform in flagging violations of platform rules. Overall, we observe a non-trivial gap, as missing developed models and LLMs exhibit low recall on a significant portion of the rules.
</details>
<details>
<summary>摘要</summary>
历史研究投入了大量时间和精力来开发自动化内容审核模型，以减轻模糊者的负担。然而，是否真的改进了内容审核任务的Automation仍然存在uncertainty。在这篇论文中，我们把过去努力提供内容审核任务的自动化方法的研究成果与志愿者内容审核者的需求进行了比较。为此，我们通过Hugging Face模型查找器来检验各种内容审核规则和指南是否有效。此外，我们还使用当今最先进的语言模型（GPT-4和Llama-2）进行测试，以评估这些模型在报告平台规则 violation 方面的性能。总之，我们发现了一定的差距，因为缺失的模型和LLMs（语言模型）表现低准确率。
</details></li>
</ul>
<hr>
<h2 id="Learning-Adversarial-Low-rank-Markov-Decision-Processes-with-Unknown-Transition-and-Full-information-Feedback"><a href="#Learning-Adversarial-Low-rank-Markov-Decision-Processes-with-Unknown-Transition-and-Full-information-Feedback" class="headerlink" title="Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback"></a>Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07876">http://arxiv.org/abs/2311.07876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Canzhe Zhao, Ruofeng Yang, Baoxiang Wang, Xuezhou Zhang, Shuai Li</li>
<li>for: 这个论文研究了具有对抗改变损失函数的低级MDP。特别是，transition probability kernel可以用低级矩阵分解 \citep{REPUCB22}, 并且损失函数可能会改变对抗地，但是在每个episode结束时都会披露给学习者。</li>
<li>methods: 我们提出了一种基于策略优化的算法POLO，并证明了它可以实现 $\widetilde{O}(K^{5&#x2F;6}A^{1&#x2F;2}d\ln(1+M)&#x2F;(1-\gamma)^2)$ 的违和误差保证，其中 $d$ 是transition kernel的级数（也是不知道表示的维度）， $A$ 是动作空间的大小， $M$ 是模型集的大小， $\gamma$ 是折扣因子。另外，我们也证明了这个问题的负 regret下界为 $\Omega(\frac{\gamma^2}{1-\gamma} \sqrt{d A K})$，表明低级MDP在违和误差下界中比线性MDP更难学习。</li>
<li>results: 我们的算法可以在不知道表示的情况下，在低级MDP中实现违和误差下界。此外，我们还证明了这个问题的负 regret下界，并证明了这是首次将 representation learning、探索和利用相互融合以实现违和误差下界的RL算法。<details>
<summary>Abstract</summary>
In this work, we study the low-rank MDPs with adversarially changed losses in the full-information feedback setting. In particular, the unknown transition probability kernel admits a low-rank matrix decomposition \citep{REPUCB22}, and the loss functions may change adversarially but are revealed to the learner at the end of each episode. We propose a policy optimization-based algorithm POLO, and we prove that it attains the $\widetilde{O}(K^{\frac{5}{6}A^{\frac{1}{2}d\ln(1+M)/(1-\gamma)^2)$ regret guarantee, where $d$ is rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\gamma$ is the discounted factor. Notably, our algorithm is oracle-efficient and has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\Omega(\frac{\gamma^2}{1-\gamma} \sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们研究了低级别MDPs中的敌对改变损失函数的问题，specifically在充满反馈情况下。特别是，未知转移概率函数可以归纳为低级别矩阵分解 \citep{REPUCB22}, 并且损失函数可能会敌对地改变，但是在每个episode结束时都会被掌握者提供。我们提出了一种基于策略优化的算法POLO，并证明它可以 дости到$\widetilde{O}(K^{5/6}A^{1/2}d\ln(1+M)/(1-\gamma)^2)$的误差保证，where $d$ is the rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\gamma$ is the discounted factor. 注意，我们的算法是oracle-efficient的，meaning it has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\Omega(\frac{\gamma^2}{1-\gamma} \sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses.
</details></li>
</ul>
<hr>
<h2 id="Rankitect-Ranking-Architecture-Search-Battling-World-class-Engineers-at-Meta-Scale"><a href="#Rankitect-Ranking-Architecture-Search-Battling-World-class-Engineers-at-Meta-Scale" class="headerlink" title="Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale"></a>Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08430">http://arxiv.org/abs/2311.08430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Wen, Kuang-Hung Liu, Igor Fedorov, Xin Zhang, Hang Yin, Weiwei Chu, Kaveh Hassani, Mengying Sun, Jiang Liu, Xu Wang, Lin Jiang, Yuxin Chen, Buyun Zhang, Xi Liu, Dehua Cheng, Zhengxing Chen, Guang Zhao, Fangqiu Han, Jiyan Yang, Yuchen Hao, Liang Xiong, Wen-Yen Chen</li>
<li>for: 本文是用于 Meta  ranking system 中的 Neural Architecture Search (NAS) 框架 Rankitect，旨在建立从头开始的架构，并对现有的 SOTA NAS 方法进行改进和比较。</li>
<li>methods: Rankitect 使用 sampling-based NAS、one-shot NAS 和 Differentiable NAS (DNAS) 等方法来构建架构，并对搜索空间进行优化。</li>
<li>results: Rankitect 可以在 Meta 级别的生产环境中发现新的模型，并达到竞争性的 Normalized Entropy loss 和 FLOPs 之间的折衔。当使用工程师设计的搜索空间时，Rankitect 可以生成更好的模型，在线 A&#x2F;B 测试中获得正面评价和Meta 规模上的实际效果。<details>
<summary>Abstract</summary>
Neural Architecture Search (NAS) has demonstrated its efficacy in computer vision and potential for ranking systems. However, prior work focused on academic problems, which are evaluated at small scale under well-controlled fixed baselines. In industry system, such as ranking system in Meta, it is unclear whether NAS algorithms from the literature can outperform production baselines because of: (1) scale - Meta ranking systems serve billions of users, (2) strong baselines - the baselines are production models optimized by hundreds to thousands of world-class engineers for years since the rise of deep learning, (3) dynamic baselines - engineers may have established new and stronger baselines during NAS search, and (4) efficiency - the search pipeline must yield results quickly in alignment with the productionization life cycle. In this paper, we present Rankitect, a NAS software framework for ranking systems at Meta. Rankitect seeks to build brand new architectures by composing low level building blocks from scratch. Rankitect implements and improves state-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under the same search space, including sampling-based NAS, one-shot NAS, and Differentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple production ranking models at Meta. We find that Rankitect can discover new models from scratch achieving competitive tradeoff between Normalized Entropy loss and FLOPs. When utilizing search space designed by engineers, Rankitect can generate better models than engineers, achieving positive offline evaluation and online A/B test at Meta scale.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AutoML-for-Large-Capacity-Modeling-of-Meta’s-Ranking-Systems"><a href="#AutoML-for-Large-Capacity-Modeling-of-Meta’s-Ranking-Systems" class="headerlink" title="AutoML for Large Capacity Modeling of Meta’s Ranking Systems"></a>AutoML for Large Capacity Modeling of Meta’s Ranking Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07870">http://arxiv.org/abs/2311.07870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Yin, Kuang-Hung Liu, Mengying Sun, Yuxin Chen, Buyun Zhang, Jiang Liu, Vivek Sehgal, Rudresh Rajnikant Panchal, Eugen Hotaj, Xi Liu, Daifeng Guo, Jamey Zhang, Zhou Wang, Shali Jiang, Huayu Li, Zhengxing Chen, Wen-Yen Chen, Jiyan Yang, Wei Wen</li>
<li>for: 本研究旨在提高排名模型，但是Engineering heavy的问题使得改进模型变得更加重要。</li>
<li>methods: 本研究使用自动化机器学习（AutoML）来释放工程师从权重逐个调整排名模型中的劳动密集工作。</li>
<li>results: 本研究表明，使用 sampling-based AutoML 方法可以在 Meta 级别的生产环境中提高排名性能，并且可以在短时间内实现更高的 Return on Investment (ROI) 和 Normalized Entropy (NE) 损失减少或 Query per Second (QPS) 提高。<details>
<summary>Abstract</summary>
Web-scale ranking systems at Meta serving billions of users is complex. Improving ranking models is essential but engineering heavy. Automated Machine Learning (AutoML) can release engineers from labor intensive work of tuning ranking models; however, it is unknown if AutoML is efficient enough to meet tight production timeline in real-world and, at the same time, bring additional improvements to the strong baselines. Moreover, to achieve higher ranking performance, there is an ever-increasing demand to scale up ranking models to even larger capacity, which imposes more challenges on the efficiency. The large scale of models and tight production schedule requires AutoML to outperform human baselines by only using a small number of model evaluation trials (around 100). We presents a sampling-based AutoML method, focusing on neural architecture search and hyperparameter optimization, addressing these challenges in Meta-scale production when building large capacity models. Our approach efficiently handles large-scale data demands. It leverages a lightweight predictor-based searcher and reinforcement learning to explore vast search spaces, significantly reducing the number of model evaluations. Through experiments in large capacity modeling for CTR and CVR applications, we show that our method achieves outstanding Return on Investment (ROI) versus human tuned baselines, with up to 0.09% Normalized Entropy (NE) loss reduction or $25\%$ Query per Second (QPS) increase by only sampling one hundred models on average from a curated search space. The proposed AutoML method has already made real-world impact where a discovered Instagram CTR model with up to -0.36% NE gain (over existing production baseline) was selected for large-scale online A/B test and show statistically significant gain. These production results proved AutoML efficacy and accelerated its adoption in ranking systems at Meta.
</details>
<details>
<summary>摘要</summary>
meta的排名系统 serving billions of users是复杂的。提高排名模型是必要的，但是工程师的努力是费尽的。自动化机器学习（AutoML）可以释放工程师从排名模型调试的劳动中解放出来，但是不知道AutoML是否具备足够的效率来满足实际生产环境中的紧张时间表。此外，随着排名性能的提高，需要扩大排名模型的规模，这会增加效率的挑战。大规模的模型和紧张的生产时间表要求AutoML能够超越人类基elines，只需使用一百个模型评估试验。我们提出了一种采样基于的AutoML方法，专注于神经网络搜索和超参数优化，解决Metascale生产环境中建立大容量模型时的挑战。我们的方法可以有效处理大规模数据需求，利用轻量级预测器基本搜索和强化学习来快速探索广阔的搜索空间，同时显著减少模型评估试验的数量。经过大容量模型应用于Click-through Rate（CTR）和Conversion Rate（CVR）应用程序的实验，我们发现我们的方法可以实现人类基elines的返回onto投资（ROI），减少模型评估试验数量的同时，提高模型性能。在实际生产中，我们已经通过实施AutoML方法，对Instagram CTR模型进行了大规模在线A/B测试，并获得了统计学上的增长。这些生产成果证明了AutoML的有效性，并促使其在排名系统中的广泛采用。
</details></li>
</ul>
<hr>
<h2 id="Multi-Signal-Reconstruction-Using-Masked-Autoencoder-From-EEG-During-Polysomnography"><a href="#Multi-Signal-Reconstruction-Using-Masked-Autoencoder-From-EEG-During-Polysomnography" class="headerlink" title="Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography"></a>Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07868">http://arxiv.org/abs/2311.07868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young-Seok Kweon, Gi-Hwan Shin, Heon-Gyu Kwak, Ha-Na Jo, Seong-Whan Lee</li>
<li>for: 这个研究旨在开发一种基于单通道EEG的多信号PSG系统，以便在非专业 Settings中进行睡眠监测。</li>
<li>methods: 该系统使用masked autoencoder来重建多信号PSG数据，并在Sleep-EDF-20数据集上进行训练和评估。</li>
<li>results: 模型能够成功重建多信号数据，表明该系统可能实现更好的睡眠监测。这将扩展PSG的应用范围，使其能够在住院设施外进行使用。<details>
<summary>Abstract</summary>
Polysomnography (PSG) is an indispensable diagnostic tool in sleep medicine, essential for identifying various sleep disorders. By capturing physiological signals, including EEG, EOG, EMG, and cardiorespiratory metrics, PSG presents a patient's sleep architecture. However, its dependency on complex equipment and expertise confines its use to specialized clinical settings. Addressing these limitations, our study aims to perform PSG by developing a system that requires only a single EEG measurement. We propose a novel system capable of reconstructing multi-signal PSG from a single-channel EEG based on a masked autoencoder. The masked autoencoder was trained and evaluated using the Sleep-EDF-20 dataset, with mean squared error as the metric for assessing the similarity between original and reconstructed signals. The model demonstrated proficiency in reconstructing multi-signal data. Our results present promise for the development of more accessible and long-term sleep monitoring systems. This suggests the expansion of PSG's applicability, enabling its use beyond the confines of clinics.
</details>
<details>
<summary>摘要</summary>
普里索诺графи（PSG）是睡眠医学中不可或缺的诊断工具，能够识别多种睡眠障碍。PSG通过捕捉生物 physiological 信号，包括 EEG、EOG、EMG 和呼吸征函数指标，可以显示睡眠体系结构。然而，它的依赖于复杂设备和专业知识，限制其使用于专业医疗设施。为了解决这些限制，我们的研究目的是通过开发一种只需要单个 EEG 测量的系统来实现 PSG。我们提出了一种基于 masked autoencoder 的新系统，可以从单个 EEG 信号中重建多个信号 PSG。我们使用 Sleep-EDF-20 数据集来训练和评估 masked autoencoder，并使用 mean squared error 作为重建信号与原始信号之间的相似度度量。 results 表明模型能够有效地重建多个信号数据。我们的结果表明，可以开发更加可 accessible 和长期睡眠监测系统，从而扩大 PSG 的应用范围，使其不再局限于医疗机构。
</details></li>
</ul>
<hr>
<h2 id="Overview-of-the-TREC-2023-Product-Product-Search-Track"><a href="#Overview-of-the-TREC-2023-Product-Product-Search-Track" class="headerlink" title="Overview of the TREC 2023 Product Product Search Track"></a>Overview of the TREC 2023 Product Product Search Track</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07861">http://arxiv.org/abs/2311.07861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Campos, Surya Kallumadi, Corby Rosset, Cheng Xiang Zhai, Alessandro Magnani</li>
<li>for: 本研究旨在创建可重用的收集和评估多Modal数据和元数据对搜寻精度的影响。</li>
<li>methods: 本研究使用新的产品搜寻 corpus，包括 contextual metadata。</li>
<li>results: 结果显示，在产品搜寻领域，传统搜寻系统具有高效性和通用预训练 embedding 模型的竞争力。  Metadata-enhanced 收集没有明确的趋势，而单stage dense retrieval run 在 zero-shot 和精度调整领域可能不竞争或生成低质量结果。<details>
<summary>Abstract</summary>
This is the first year of the TREC Product search track. The focus this year was the creation of a reusable collection and evaluation of the impact of the use of metadata and multi-modal data on retrieval accuracy. This year we leverage the new product search corpus, which includes contextual metadata. Our analysis shows that in the product search domain, traditional retrieval systems are highly effective and commonly outperform general-purpose pretrained embedding models. Our analysis also evaluates the impact of using simplified and metadata-enhanced collections, finding no clear trend in the impact of the expanded collection. We also see some surprising outcomes; despite their widespread adoption and competitive performance on other tasks, we find single-stage dense retrieval runs can commonly be noncompetitive or generate low-quality results both in the zero-shot and fine-tuned domain.
</details>
<details>
<summary>摘要</summary>
这是TREC产品搜索追踪的第一年。本年的重点是创建可重用的收藏和评估多Modal数据和元数据对搜索精度的影响。本年我们利用新的产品搜索词库，该词库包括Contextual元数据。我们的分析显示，在产品搜索领域，传统搜索系统具有高效性和通用预训练Embedding模型的竞争力。我们的分析还评估了使用简化和元数据增强的收藏，发现没有明显的趋势。我们还发现了一些意外的结果：尽管广泛采用和在其他任务上竞争性表现出色，我们发现单stage dense retrieval运行在零shot和精度调整领域中往往无竞争力或生成低质量结果。
</details></li>
</ul>
<hr>
<h2 id="Bring-Your-Own-KG-Self-Supervised-Program-Synthesis-for-Zero-Shot-KGQA"><a href="#Bring-Your-Own-KG-Self-Supervised-Program-Synthesis-for-Zero-Shot-KGQA" class="headerlink" title="Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA"></a>Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07850">http://arxiv.org/abs/2311.07850</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dhdhagar/byokg">https://github.com/dhdhagar/byokg</a></li>
<li>paper_authors: Dhruv Agarwal, Rajarshi Das, Sopan Khosla, Rashmi Gangadharaiah</li>
<li>for: The paper is written for developing a universal question-answering (QA) system that can operate on any knowledge graph (KG) without requiring human-annotated training data.</li>
<li>methods: The paper uses a combination of exploration and reasoning to answer questions on a KG. The exploration is leveraged by an LLM-backed symbolic agent that generates a diverse set of query-program exemplars, which are then used to ground a retrieval-augmented reasoning procedure to predict programs for arbitrary questions.</li>
<li>results: The paper shows dramatic gains in QA accuracy over a zero-shot baseline on two benchmark datasets, GrailQA and MetaQA, with an F1 score of 27.89 and 58.02, respectively. Additionally, the paper demonstrates the effectiveness of exploration and shows that performance of the proposed method reliably improves with continued exploration and improvements in the base LLM.<details>
<summary>Abstract</summary>
We present BYOKG, a universal question-answering (QA) system that can operate on any knowledge graph (KG), requires no human-annotated training data, and can be ready to use within a day -- attributes that are out-of-scope for current KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to comprehend information present in an unseen KG through exploration -- starting at random nodes, inspecting the labels of adjacent nodes and edges, and combining them with their prior world knowledge. In BYOKG, exploration leverages an LLM-backed symbolic agent that generates a diverse set of query-program exemplars, which are then used to ground a retrieval-augmented reasoning procedure to predict programs for arbitrary questions. BYOKG is effective over both small- and large-scale graphs, showing dramatic gains in QA accuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA, respectively. On GrailQA, we further show that our unsupervised BYOKG outperforms a supervised in-context learning method, demonstrating the effectiveness of exploration. Lastly, we find that performance of BYOKG reliably improves with continued exploration as well as improvements in the base LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1 on a sub-sampled zero-shot split of GrailQA.
</details>
<details>
<summary>摘要</summary>
我们介绍了BYOKG，一个通用的问题回答（QA）系统，可以运行在任何知识图（KG）上，不需要人类验证训练数据，并可以在一天内就ready to use。这些特点与现有的KGQA系统不同，BYOKG draws inspiration from人类对未看到的KG的极其能力，通过探索开始在随机的节点上，检查邻近节点和边缘的标签，并与先前的世界知识结合。在BYOKG中，探索利用LLM-backed符式代理，生成多样化的问题程式示例，然后用它们与问题相结合，进行搜寻增强的理论过程，以预测问题的回答。BYOKG能够在小规模和大规模的图上显示出戏剧性的提升，与零基eline的比较获得27.89和58.02的F1分数。在GrailQA上，我们还显示了我们的无监督BYOKG在内部学习方法上的优势，证明了探索的效iveness。最后，我们发现BYOKG的性能随着继续探索和LLM的改进，不断提高，甚至在一部分零基eline上超越了一个精心 fine-tuned 模型，实现7.08的F1分数。
</details></li>
</ul>
<hr>
<h2 id="Enabling-Decision-Support-Systems-through-Automated-Cell-Tower-Detection"><a href="#Enabling-Decision-Support-Systems-through-Automated-Cell-Tower-Detection" class="headerlink" title="Enabling Decision-Support Systems through Automated Cell Tower Detection"></a>Enabling Decision-Support Systems through Automated Cell Tower Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07840">http://arxiv.org/abs/2311.07840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Natasha Krell, Will Gleave, Daniel Nakada, Justin Downes, Amanda Willet, Matthew Baran</li>
<li>for: 本研究旨在提高较大地区域的移动信号覆盖率，以便提高公众对移动金融、教育和人道主义服务的访问。</li>
<li>methods: 该研究使用深度神经网络和高分辨率Remote sensing图像进行对cell Tower的物体检测，以消除手动mapping的不必要和负担。</li>
<li>results: 研究人员通过使用OpenStreetMap（OSM）特征和高分辨率Maxar图像，实现了对cell Tower的自动检测和精度的提高。模型在不同地理区域和过样测试中表现良好，可以提供更加准确的移动覆盖图。<details>
<summary>Abstract</summary>
Cell phone coverage and high-speed service gaps persist in rural areas in sub-Saharan Africa, impacting public access to mobile-based financial, educational, and humanitarian services. Improving maps of telecommunications infrastructure can help inform strategies to eliminate gaps in mobile coverage. Deep neural networks, paired with remote sensing images, can be used for object detection of cell towers and eliminate the need for inefficient and burdensome manual mapping to find objects over large geographic regions. In this study, we demonstrate a partially automated workflow to train an object detection model to locate cell towers using OpenStreetMap (OSM) features and high-resolution Maxar imagery. For model fine-tuning and evaluation, we curated a diverse dataset of over 6,000 unique images of cell towers in 26 countries in eastern, southern, and central Africa using automatically generated annotations from OSM points. Our model achieves an average precision at 50% Intersection over Union (IoU) (AP@50) of 81.2 with good performance across different geographies and out-of-sample testing. Accurate localization of cell towers can yield more accurate cell coverage maps, in turn enabling improved delivery of digital services for decision-support applications.
</details>
<details>
<summary>摘要</summary>
在非洲的农村地区，移动电话覆盖和高速服务的差距仍然存在，影响公众对移动基础设施的访问。改进电信基础设施的地图可以帮助制定消除移动覆盖差距的策略。深度神经网络，与高分辨率的卫星图像结合使用，可以用于检测Cell Tower的物体。在本研究中，我们提出了一种具有部分自动化的工作流程，用于在OpenStreetMap（OSM）特征和高分辨率的Maxar影像上训练物体检测模型，以检测Cell Tower。我们为模型精度调整和评估 curated了来自26个国家的东南非洲的6,000多个独特的Cell Tower图像，使用自动生成的OSM点来生成自动化的注释。我们的模型在50% Intersection over Union（IoU）的平均准确率（AP@50）为81.2，在不同的地理区域和过样测试中表现良好。准确的Cell Tower的位置确定可以使得电话覆盖地图更加准确，从而实现更好的数字服务的发展。
</details></li>
</ul>
<hr>
<h2 id="LLatrieval-LLM-Verified-Retrieval-for-Verifiable-Generation"><a href="#LLatrieval-LLM-Verified-Retrieval-for-Verifiable-Generation" class="headerlink" title="LLatrieval: LLM-Verified Retrieval for Verifiable Generation"></a>LLatrieval: LLM-Verified Retrieval for Verifiable Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07838">http://arxiv.org/abs/2311.07838</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/beastyz/llm-verified-retrieval">https://github.com/beastyz/llm-verified-retrieval</a></li>
<li>paper_authors: Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu</li>
<li>for: 提高大语言模型（LLM）生成文本的可靠性和可证明性。</li>
<li>methods: 提出了一种新的检索阶段，使得LLM可以通过反馈更新检索结果，以便让检索结果能够充分支持可靠地生成答案。</li>
<li>results: 实验结果显示，我们的方法可以与广泛的基线模型进行比较，并达到新的国际级结果。<details>
<summary>Abstract</summary>
Verifiable generation aims to let the large language model (LLM) generate text with corresponding supporting documents, which enables the user to flexibly verify the answer and makes it more trustworthy. Its evaluation not only measures the correctness of the answer, but also the answer's verifiability, i.e., how well the answer is supported by the corresponding documents. In typical, verifiable generation adopts the retrieval-read pipeline, which is divided into two stages: 1) retrieve relevant documents of the question. 2) according to the documents, generate the corresponding answer. Since the retrieved documents can supplement knowledge for the LLM to generate the answer and serve as evidence, the retrieval stage is essential for the correctness and verifiability of the answer. However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. They often have fewer parameters than the large language model and have not been proven to scale well to the size of LLMs. Since the LLM passively receives the retrieval result, if the retriever does not correctly find the supporting documents, the LLM can not generate the correct and verifiable answer, which overshadows the LLM's remarkable abilities. In this paper, we propose LLatrieval (Large Language Model Verified Retrieval), where the LLM updates the retrieval result until it verifies that the retrieved documents can support answering the question. Thus, the LLM can iteratively provide feedback to retrieval and facilitate the retrieval result to sufficiently support verifiable generation. Experimental results show that our method significantly outperforms extensive baselines and achieves new state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）生成文本的可靠生成目标是让用户可以轻松验证答案，使答案更加可靠。其评价不仅考虑答案的正确性，还考虑答案是否具有可靠性，即答案是否得到了相应的支持文档。 Typical verifiable generation adopts the retrieval-read pipeline, which is divided into two stages:1. 根据问题检索相关文档。2. 根据文档生成答案。因为检索到的文档可以补充语言模型的知识，并作为证据，因此检索阶段是生成答案的关键。但是，广泛使用的检索器成为整个管道的瓶颈，限制整体性能。它们通常有 fewer 参数 than LLM，并未证明可以适应 LLM 的大小。因此，LLM 只能 passively 接受检索结果，如果检索器不能正确地检索到支持文档，那么 LLM 就无法生成正确和可靠的答案，这将屏蔽 LLM 的出色能力。在这篇论文中，我们提出了 LLatrieval（大型语言模型验证检索），其中 LLM 会更新检索结果，直到它确认检索到的文档可以支持回答问题。因此，LLM 可以逐次提供反馈给检索，使检索结果足够支持可靠生成。实验结果表明，我们的方法与广泛的基准相比显著超越，实现了新的状态纪录result。
</details></li>
</ul>
<hr>
<h2 id="A-Neuro-Inspired-Hierarchical-Reinforcement-Learning-for-Motor-Control"><a href="#A-Neuro-Inspired-Hierarchical-Reinforcement-Learning-for-Motor-Control" class="headerlink" title="A Neuro-Inspired Hierarchical Reinforcement Learning for Motor Control"></a>A Neuro-Inspired Hierarchical Reinforcement Learning for Motor Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07822">http://arxiv.org/abs/2311.07822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pei Zhang, Zhaobo Hua, Jinliang Ding</li>
<li>for: 这项研究的目的是开发一种基于中枢神经系统的动物学习算法，使多关节机器人可以自然地学习和应用复杂的动作技能。</li>
<li>methods: 该算法使用选择机制和调节能力来模仿动物中心神经系统的机制，并通过不同的技能组合来实现机器人的自然动作能力。</li>
<li>results: 实验结果显示，该算法可以让不同类型的机器人在22个任务环境中实现灵活的动作技能。<details>
<summary>Abstract</summary>
Designing controllers to achieve natural motion capabilities for multi-joint robots is a significant challenge. However, animals in nature are naturally with basic motor abilities and can master various complex motor skills through acquired learning. On the basis of analyzing the mechanism of the central motor system in mammals, we propose a neuro-inspired hierarchical reinforcement learning algorithm that enables robots to learn rich motor skills and apply them to complex task environments without relying on external data. We first design a skills network similar to the cerebellum by utilizing the selection mechanism of voluntary movements in the basal ganglia and the regulatory ability of the cerebellum to regulate movement. Subsequently, by imitating the structure of advanced centers in the motion system, we propose a high-level policy to generate different skill combinations, thereby enabling the robot to acquire natural motor abilities. We conduct experiments on 4 types of robots and 22 task environments, and the results show that the proposed method can enable different types of robots to achieve flexible motion skills. Overall, our research provides a promising framework for the design of robotic neural motor controllers.
</details>
<details>
<summary>摘要</summary>
“设计控制器以实现自然运动能力是多 JOINT 机器人设计中的一大挑战。然而，自然界中的动物具有基本的运动能力，并通过获得的学习来掌握多种复杂的运动技巧。基于分析中枢神经系统的机制，我们提出了一种基于脑神经学的层次强化学习算法，使机器人能够通过自然的运动方式来处理复杂任务环境而无需依赖于外部数据。我们首先设计了一个类似于脑干的技能网络，通过选择机制和基尼肌肉的调节能力来控制运动。然后，我们通过模仿高级运动系统的结构，提出了一种高级策略来生成不同的技能组合，使机器人能够获得自然的运动能力。我们在4种机器人和22个任务环境上进行实验，结果显示，我们的方法可以让不同类型的机器人获得灵活的运动技巧。总的来说，我们的研究提供了机器人神经动作控制器的可能性。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-to-Detect-Influence-Campaigns-in-Social-Media"><a href="#Leveraging-Large-Language-Models-to-Detect-Influence-Campaigns-in-Social-Media" class="headerlink" title="Leveraging Large Language Models to Detect Influence Campaigns in Social Media"></a>Leveraging Large Language Models to Detect Influence Campaigns in Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07816">http://arxiv.org/abs/2311.07816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Luceri, Eric Boniardi, Emilio Ferrara</li>
<li>for: 本研究旨在探讨社交媒体干预活动对公众讨论和民主所 pose 的挑战，并提出一种基于大语言模型（LLMs）的新方法来检测这些活动。</li>
<li>methods: 本研究使用 LLMs 将用户元数据和网络结构转换为文本格式，以便有效地处理多语言内容并适应 malevolent 活动actor 的shift 策略。</li>
<li>results: 我们通过对多个数据集进行严格测试，证明我们的模型在检测影响活动方面表现出色，以提供一种有效的检测工具。<details>
<summary>Abstract</summary>
Social media influence campaigns pose significant challenges to public discourse and democracy. Traditional detection methods fall short due to the complexity and dynamic nature of social media. Addressing this, we propose a novel detection method using Large Language Models (LLMs) that incorporates both user metadata and network structures. By converting these elements into a text format, our approach effectively processes multilingual content and adapts to the shifting tactics of malicious campaign actors. We validate our model through rigorous testing on multiple datasets, showcasing its superior performance in identifying influence efforts. This research not only offers a powerful tool for detecting campaigns, but also sets the stage for future enhancements to keep up with the fast-paced evolution of social media-based influence tactics.
</details>
<details>
<summary>摘要</summary>
社交媒体影响运动对公众讨论和民主poses significant challenges。传统的探测方法 fall short due to the complexity and dynamic nature of social media。为解决这个问题，我们提议一种使用大语言模型（LLMs）的新的探测方法，该方法包括用户元数据和网络结构的转化。通过将这些元素转化为文本格式，我们的方法可以有效地处理多语言内容，适应malevolent campaign actors的战术的变化。我们通过严格的测试多个数据集，证明了我们的模型在发现影响活动方面的表现出色。这种研究不仅提供了一种有效的探测工具，还为未来随着社交媒体基于的影响策略的演化而进行进一步的改进提供了平台。
</details></li>
</ul>
<hr>
<h2 id="Cooperative-AI-via-Decentralized-Commitment-Devices"><a href="#Cooperative-AI-via-Decentralized-Commitment-Devices" class="headerlink" title="Cooperative AI via Decentralized Commitment Devices"></a>Cooperative AI via Decentralized Commitment Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07815">http://arxiv.org/abs/2311.07815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyuan Sun, Davide Crapis, Matt Stephenson, Barnabé Monnot, Thomas Thiery, Jonathan Passerat-Palmbach</li>
<li>for: 这篇论文旨在探讨协同AI技术是否能够在实际世界中具有安全性和可靠性。</li>
<li>methods: 该论文使用了数字签名技术和智能合约来实现协同AI的安全性和可靠性。</li>
<li>results: 论文通过使用实际世界的commitmentDevice来检验协同AI技术的安全性和可靠性，并发现了一些潜在的安全问题。<details>
<summary>Abstract</summary>
Credible commitment devices have been a popular approach for robust multi-agent coordination. However, existing commitment mechanisms face limitations like privacy, integrity, and susceptibility to mediator or user strategic behavior. It is unclear if the cooperative AI techniques we study are robust to real-world incentives and attack vectors. However, decentralized commitment devices that utilize cryptography have been deployed in the wild, and numerous studies have shown their ability to coordinate algorithmic agents facing adversarial opponents with significant economic incentives, currently in the order of several million to billions of dollars. In this paper, we use examples in the decentralization and, in particular, Maximal Extractable Value (MEV) (arXiv:1904.05234) literature to illustrate the potential security issues in cooperative AI. We call for expanded research into decentralized commitments to advance cooperative AI capabilities for secure coordination in open environments and empirical testing frameworks to evaluate multi-agent coordination ability given real-world commitment constraints.
</details>
<details>
<summary>摘要</summary>
信worthy的契约设备已经是多智能体协调的受欢迎方法。然而，现有的契约机制受到隐私、完整性和中介人或用户的战略行为等限制。不清楚AI技术我们研究是否对实际世界的奖励和攻击 vector 具有Robustness。然而，使用 криптовалюence 的分布式契约设备已经在实际应用中部署，许多研究表明它们可以在面临敌对对手的情况下协调算法代理，现在达到数百万到数十亿美元的经济奖励。在这篇论文中，我们使用分布式契约的例子，特别是Maximal Extractable Value（MEV）（arXiv:1904.05234）文献， illustrate 可能在合作AI中存在安全问题。我们呼吁扩大分布式契约的研究，以提高合作AI的安全协调能力，并在实际commitment约束下进行 empirical 测试框架来评估多智能体协调能力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/cs.AI_2023_11_14/" data-id="clpztdncl007des881o5n9f31" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/cs.CL_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T11:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/cs.CL_2023_11_14/">cs.CL - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DALA-A-Distribution-Aware-LoRA-Based-Adversarial-Attack-against-Pre-trained-Language-Models"><a href="#DALA-A-Distribution-Aware-LoRA-Based-Adversarial-Attack-against-Pre-trained-Language-Models" class="headerlink" title="DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Pre-trained Language Models"></a>DALA: A Distribution-Aware LoRA-Based Adversarial Attack against Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08598">http://arxiv.org/abs/2311.08598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yibo Wang, Xiangjue Dong, James Caverlee, Philip S. Yu</li>
<li>for: 本研究旨在提高黑客攻击方法的攻击成功率，并对黑客攻击方法的攻击效果进行评估。</li>
<li>methods: 本研究提出了一种 Distribution-Aware LoRA-based Adversarial Attack (DALA) 方法，该方法考虑了攻击示例的分布偏移，以提高攻击效果。</li>
<li>results: 实验结果表明，DALA 方法可以在四个常用的数据集上提高黑客攻击方法的攻击成功率，并在 ASR 和 NASR 两个评价指标上达到了比较高的水平。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) that achieve success in applications are susceptible to adversarial attack methods that are capable of generating adversarial examples with minor perturbations. Although recent attack methods can achieve a relatively high attack success rate (ASR), our observation shows that the generated adversarial examples have a different data distribution compared with the original examples. Specifically, these adversarial examples exhibit lower confidence levels and higher distance to the training data distribution. As a result, they are easy to detect using very simple detection methods, diminishing the actual effectiveness of these attack methods. To solve this problem, we propose a Distribution-Aware LoRA-based Adversarial Attack (DALA) method, which considers the distribution shift of adversarial examples to improve attack effectiveness under detection methods. We further design a new evaluation metric NASR combining ASR and detection for the attack task. We conduct experiments on four widely-used datasets and validate the attack effectiveness on ASR and NASR of the adversarial examples generated by DALA on the BERT-base model and the black-box LLaMA2-7b model.
</details>
<details>
<summary>摘要</summary>
预训言语模型（PLM）在应用中获得成功，却容易受到敌意攻击的威胁。最新的攻击方法可以生成敌意示例，但我们发现这些示例的数据分布与原始示例不同。具体来说，这些示例的信任水平较低，与训练数据分布更加远离。因此，它们容易被非常简单的检测方法探测到，从而削弱了攻击的实际效果。为解决这个问题，我们提议一种考虑数据分布变化的 Distribution-Aware LoRA-based Adversarial Attack（DALA）方法。此外，我们还设计了一个新的评价指标NASR，它将ASR和检测结果相结合来评价攻击任务的效果。我们在四个常用的数据集上进行了实验，并验证了DALA在BERT-base模型和黑盒LLaMA2-7b模型上的攻击效果。
</details></li>
</ul>
<hr>
<h2 id="Are-You-Sure-Challenging-LLMs-Leads-to-Performance-Drops-in-The-FlipFlop-Experiment"><a href="#Are-You-Sure-Challenging-LLMs-Leads-to-Performance-Drops-in-The-FlipFlop-Experiment" class="headerlink" title="Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment"></a>Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08596">http://arxiv.org/abs/2311.08596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philippe Laban, Lidiya Murakhovs’ka, Caiming Xiong, Chien-Sheng Wu</li>
<li>for: This paper aims to analyze the behavior of Large Language Models (LLMs) in multi-turn conversations and evaluate their ability to refine and improve their answers.</li>
<li>methods: The authors propose the FlipFlop experiment, which involves presenting an LLM with a prompt containing a classification task in the first round, and then challenging the model with a follow-up phrase in the second round to elicit a reflection on its initial answer.</li>
<li>results: The study finds that LLMs flip their answers on average 46% of the time and experience a drop in accuracy between their first and final predictions, with an average drop of 17%. The results demonstrate the universality of sycophantic behavior in LLMs and provide a robust framework for analyzing model behavior and evaluating potential solutions.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文目的是分析大语言模型（LLMs）在多轮对话中的行为，并评估它们是否可以改进和精细化它们的答案。</li>
<li>methods: 作者提出了“折衣”实验，其中在第一轮对话中给LLM提供一个分类任务的提示，然后在第二轮对话中给它一个“你确定吗？”的跟问，以让模型反思其初始答案，并决定是否确认或变更它的答案。</li>
<li>results: 研究发现，LLMs在平均情况下会在46%的时间变更答案，并且在第一个和最终预测之间的准确率下降了17%。结果表明大语言模型中的追随行为是通用的，并提供了一个可靠的框架来分析模型行为并评估可能的解决方案。<details>
<summary>Abstract</summary>
The interactive nature of Large Language Models (LLMs) theoretically allows models to refine and improve their answers, yet systematic analysis of the multi-turn behavior of LLMs remains limited. In this paper, we propose the FlipFlop experiment: in the first round of the conversation, an LLM responds to a prompt containing a classification task. In a second round, the LLM is challenged with a follow-up phrase like "Are you sure?", offering an opportunity for the model to reflect on its initial answer, and decide whether to confirm or flip its answer. A systematic study of nine LLMs on seven classification tasks reveals that models flip their answers on average 46% of the time and that all models see a deterioration of accuracy between their first and final prediction, with an average drop of 17%. The FlipFlop experiment illustrates the universality of sycophantic behavior in LLMs and provides a robust framework to analyze model behavior and evaluate potential solutions.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的互动性在理论上允许模型在回答时进行精细调整和改进，然而对多轮行为的系统性分析尚未受到广泛关注。本文提出了“折衣”实验：在第一轮对话中，一个LLM对一个分类任务提交答案。在第二轮对话中，模型被挑战以“你确定吗？”的后续话，给模型提供反思其初始答案的机会，并决定是否确认或折衣答案。对九个LLM在七个分类任务上进行系统性分析，发现models在 average 46% 的时间会折衣答案，并且所有模型在第一个预测和最终预测之间的准确率都会下降，平均下降17%。“折衣”实验表明 LLM 中的迷恋行为是普遍的，并提供了一个可靠的框架来分析模型行为并评估可能的解决方案。
</details></li>
</ul>
<hr>
<h2 id="ACID-Abstractive-Content-Based-IDs-for-Document-Retrieval-with-Language-Models"><a href="#ACID-Abstractive-Content-Based-IDs-for-Document-Retrieval-with-Language-Models" class="headerlink" title="ACID: Abstractive, Content-Based IDs for Document Retrieval with Language Models"></a>ACID: Abstractive, Content-Based IDs for Document Retrieval with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08593">http://arxiv.org/abs/2311.08593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoxin Li, Phillip Keung, Daniel Cheng, Jungo Kasai, Noah A. Smith</li>
<li>for: 这个论文旨在提出一种新的终端文档检索方法，即直接基于输入查询生成文档标识符。</li>
<li>methods: 这种方法使用大语言模型生成抽象关键词，并将每个文档的标识符组成为这些关键词的组合。</li>
<li>results: 使用这种方法可以提高终端文档检索的top-10和top-20准确率，相比之前的状态艺术基准。<details>
<summary>Abstract</summary>
Generative retrieval (Wang et al., 2022; Tay et al., 2022) is a new approach for end-to-end document retrieval that directly generates document identifiers given an input query. Techniques for designing effective, high-quality document IDs remain largely unexplored. We introduce ACID, in which each document's ID is composed of abstractive keyphrases generated by a large language model, rather than an integer ID sequence as done in past work. We compare our method with the current state-of-the-art technique for ID generation, which produces IDs through hierarchical clustering of document embeddings. We also examine simpler methods to generate natural-language document IDs, including the naive approach of using the first k words of each document as its ID or words with high BM25 scores in that document. We show that using ACID improves top-10 and top-20 accuracy by 15.6% and 14.4% (relative) respectively versus the state-of-the-art baseline on the MSMARCO 100k retrieval task, and 4.4% and 4.0% respectively on the Natural Questions 100k retrieval task. Our results demonstrate the effectiveness of human-readable, natural-language IDs in generative retrieval with LMs. The code for reproducing our results and the keyword-augmented datasets will be released on formal publication.
</details>
<details>
<summary>摘要</summary>
新的生成检索方法（Wang et al., 2022; Tay et al., 2022）可以直接基于输入查询生成文档标识符。现有的技术设计高质量、有效的文档标识符仍然尚未得到了充分的探索。我们介绍了ACID，它的每个文档标识符由一个大语言模型生成的抽象关键词组成，而不是以往的整数ID序列。我们与现状态的技术进行比较，它通过层次归一化文档嵌入来生成ID。我们还考虑了使用每个文档的前k个词作为其ID的简单方法，以及使用每个文档中高BM25 scores的词作为ID的方法。我们的结果表明，使用ACID可以提高MSMARCO 100k检索任务的前10和前20准确率相对提高15.6%和14.4%，并在Natural Questions 100k检索任务上提高4.4%和4.0%。我们的结果表明，使用人类可读的、自然语言ID在LMs中的生成检索中是有效的。我们将在正式发布时释放代码和附加的关键词扩展数据集。
</details></li>
</ul>
<hr>
<h2 id="PEMA-Plug-in-External-Memory-Adaptation-for-Language-Models"><a href="#PEMA-Plug-in-External-Memory-Adaptation-for-Language-Models" class="headerlink" title="PEMA: Plug-in External Memory Adaptation for Language Models"></a>PEMA: Plug-in External Memory Adaptation for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08590">http://arxiv.org/abs/2311.08590</a></li>
<li>repo_url: None</li>
<li>paper_authors: HyunJin Kim, Young Jin Kim, JinYeong Bak</li>
<li>for: 这个论文的目的是为了提高预训练大语言模型（PLM）在不同下游NLP任务上的性能，同时减少预训练过程中的资源需求。</li>
<li>methods: 这篇论文使用了Parameter-Efficient Fine-Tuning（PEFT）方法，其中包括Plug-in External Memory Adaptation（PEMA）和LoRA-based weight matrices等技术。PEMA可以在推理过程中在测试数据上下文中插入外部存储，以便在推理过程中使用PLM生成的上下文表示。</li>
<li>results: 根据实验结果，PEMA方法在语法数据集和实际数据集上的机器翻译和风格转换任务上表现出色，比其他PEFT方法更高效和可靠。同时，PEMA方法能够保持句子的意义，同时生成适当的语言和风格。<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have demonstrated impressive performance across various downstream NLP tasks. Nevertheless, the resource requirements of pre-training large language models in terms of memory and training compute pose significant challenges. Furthermore, due to the substantial resources required, many PLM weights are confidential. Consequently, users are compelled to share their data with model owners for fine-tuning on specific tasks. To overcome the limitations, we introduce Plug-in External Memory Adaptation (PEMA), a Parameter-Efficient Fine-Tuning (PEFT) approach designed for fine-tuning PLMs without the need for all weights. PEMA can be integrated into the context representation of test data during inference to execute downstream tasks. It leverages an external memory to store context representations generated by a PLM, mapped with the desired target word. Our method entails training LoRA-based weight matrices within the final layer of the PLM for enhanced efficiency. The probability is then interpolated with the next-word distribution from the PLM to perform downstream tasks. To improve the generation quality, we propose a novel interpolation strategy named Gradual Unrolling. To demonstrate the effectiveness of our proposed method, we conduct experiments to demonstrate the efficacy of PEMA with a syntactic dataset and assess its performance on machine translation and style transfer tasks using real datasets. PEMA outperforms other PEFT methods in terms of memory and latency efficiency for training and inference. Furthermore, it outperforms other baselines in preserving the meaning of sentences while generating appropriate language and styles.
</details>
<details>
<summary>摘要</summary>
预训语言模型（PLM）已经在不同的下游自然语言处理任务中表现出色。然而，预训大语言模型的资源需求，包括内存和训练计算机，带来了 significiant challenges。此外，由于资源的巨大需求，许多PLM的权重都是机密的。因此，用户被迫分享自己的数据来为特定任务进行细化。为了突破这些限制，我们介绍了插入式外部记忆适配（PEMA），一种基于精简的 Parametric Efficient Fine-Tuning（PEFT）方法，可以在不需要所有权重的情况下进行细化。PEMA可以在推理过程中将测试数据的上下文表示 integrate into the context representation of test data during inference, and leverage an external memory to store context representations generated by a PLM, mapped with the desired target word. Our method entails training LoRA-based weight matrices within the final layer of the PLM for enhanced efficiency. The probability is then interpolated with the next-word distribution from the PLM to perform downstream tasks. To improve the generation quality, we propose a novel interpolation strategy named Gradual Unrolling. To demonstrate the effectiveness of our proposed method, we conduct experiments to demonstrate the efficacy of PEMA with a syntactic dataset and assess its performance on machine translation and style transfer tasks using real datasets. PEMA outperforms other PEFT methods in terms of memory and latency efficiency for training and inference, and also outperforms other baselines in preserving the meaning of sentences while generating appropriate language and styles.
</details></li>
</ul>
<hr>
<h2 id="Asking-More-Informative-Questions-for-Grounded-Retrieval"><a href="#Asking-More-Informative-Questions-for-Grounded-Retrieval" class="headerlink" title="Asking More Informative Questions for Grounded Retrieval"></a>Asking More Informative Questions for Grounded Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08584">http://arxiv.org/abs/2311.08584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sedrick Keh, Justin T. Chiu, Daniel Fried</li>
<li>for: 这种研究的目的是提高模型在基于图像的多回合识别任务中的信息收集能力，具体来说是使用更加有用的问题来提高模型的性能。</li>
<li>methods: 这种方法使用了开放式问题的形式，而不是传统的简单的是否问题，从而使得模型可以更好地获取信息。此外，这种方法还包括一种假设处理机制，以解决模型在处理开放式问题时的假设错误。</li>
<li>results: 实验表明，这种方法可以提高模型在基于图像的多回合识别任务中的性能，相比之前的状态艺术提高了14%，而且在人工评估中比基于传统问题更加高效，具体来说是48%更高效。<details>
<summary>Abstract</summary>
When a model is trying to gather information in an interactive setting, it benefits from asking informative questions. However, in the case of a grounded multi-turn image identification task, previous studies have been constrained to polar yes/no questions, limiting how much information the model can gain in a single turn. We present an approach that formulates more informative, open-ended questions. In doing so, we discover that off-the-shelf visual question answering (VQA) models often make presupposition errors, which standard information gain question selection methods fail to account for. To address this issue, we propose a method that can incorporate presupposition handling into both question selection and belief updates. Specifically, we use a two-stage process, where the model first filters out images which are irrelevant to a given question, then updates its beliefs about which image the user intends. Through self-play and human evaluations, we show that our method is successful in asking informative open-ended questions, increasing accuracy over the past state-of-the-art by 14%, while resulting in 48% more efficient games in human evaluations.
</details>
<details>
<summary>摘要</summary>
当模型在交互 Setting 中尝试收集信息时，它会受益于提问有价值的问题。然而，在基于图像识别多turn任务的前 Studies 中，模型受限于两元问题，这限制了模型在单turn中收集信息的可能性。我们提出了一种方法，该方法使用更加有价值的、开放式问题。在做这些事情时，我们发现了许多Off-the-shelf 视觉问答（VQA）模型经常会出现先假设错误，这些错误不符合信息增加问题选择方法所能处理。为解决这个问题，我们提出了一种方法，该方法可以在问题选择和信念更新中包含先假设处理。具体来说，我们使用两个阶段的过程，首先使用模型过滤出不相关的图像，然后更新模型对用户所意图的图像的信念。通过自适应和人工评估，我们表明了我们的方法能够成功地提问有价值的开放式问题，相比前一个状态的最佳性能提高14%，而同时在人工评估中效率提高48%。
</details></li>
</ul>
<hr>
<h2 id="Graph-Induced-Syntactic-Semantic-Spaces-in-Transformer-Based-Variational-AutoEncoders"><a href="#Graph-Induced-Syntactic-Semantic-Spaces-in-Transformer-Based-Variational-AutoEncoders" class="headerlink" title="Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders"></a>Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational AutoEncoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08579">http://arxiv.org/abs/2311.08579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingji Zhang, Marco Valentino, Danilo S. Carvalho, Ian Pratt-Hartmann, André Freitas</li>
<li>For: 提高VAEs的表现和泛化能力* Methods: 使用多任务学习或双Encoder架构，将分布Semantic特征和语法结构归一化到不同的隐藏空间中* Results: 通过在编码阶段 integrate graph-based和序列模型，并在解码器的注意力机制中插入多个特化的隐藏表示，实现了提高语言模型和下游生成任务的表现<details>
<summary>Abstract</summary>
The injection of syntactic information in Variational AutoEncoders (VAEs) has been shown to result in an overall improvement of performances and generalisation. An effective strategy to achieve such a goal is to separate the encoding of distributional semantic features and syntactic structures into heterogeneous latent spaces via multi-task learning or dual encoder architectures. However, existing works employing such techniques are limited to LSTM-based VAEs. In this paper, we investigate latent space separation methods for structural syntactic injection in Transformer-based VAE architectures (i.e., Optimus). Specifically, we explore how syntactic structures can be leveraged in the encoding stage through the integration of graph-based and sequential models, and how multiple, specialised latent representations can be injected into the decoder's attention mechanism via low-rank operators. Our empirical evaluation, carried out on natural language sentences and mathematical expressions, reveals that the proposed end-to-end VAE architecture can result in a better overall organisation of the latent space, alleviating the information loss occurring in standard VAE setups, resulting in enhanced performances on language modelling and downstream generation tasks.
</details>
<details>
<summary>摘要</summary>
射预Variational AutoEncoders（VAEs）中的内在结构信息注入已经被证明可以提高性能和数据准确性。一种有效的策略是在多任务学习或双encoder架构下，分离分布式semantic feature和 sintactic structure的编码。然而，现有的作品仅采用LSTM-based VAEs。在本文中，我们对Transformer-based VAE架构（i.e., Optimus）中的latent space separation方法进行了探索。具体来说，我们试验了在编码阶段通过结构模型和序列模型的结合，以及在解码器的注意机制中通过低维运算符插入多个特殊的latent representation。我们的实验评估，针对自然语言句子和数学表达，表明了我们提案的终端VAE架构可以将latent space更好地组织，降低标准VAE设置中的信息损失，进而提高语言预测和下游生成任务的性能。
</details></li>
</ul>
<hr>
<h2 id="MAgIC-Investigation-of-Large-Language-Model-Powered-Multi-Agent-in-Cognition-Adaptability-Rationality-and-Collaboration"><a href="#MAgIC-Investigation-of-Large-Language-Model-Powered-Multi-Agent-in-Cognition-Adaptability-Rationality-and-Collaboration" class="headerlink" title="MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"></a>MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08562">http://arxiv.org/abs/2311.08562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cathyxl/magic">https://github.com/cathyxl/magic</a></li>
<li>paper_authors: Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See Kiong Ng, Jiashi Feng</li>
<li>for: 本研究旨在评估大语言模型（LLMs）在多智能环境中的能力，包括判断、规划、协作、自我意识和合理性。</li>
<li>methods: 本研究使用了游戏如彩虹和隐身，以及游戏理论场景如成本分享、多人投降和公共财富，创造了多样化的测试环境。同时，研究人员还使用了可能图模型（PGM）方法来增强LLMs的处理复杂社会和认知维度的能力。</li>
<li>results: 研究发现，使用PGM方法可以提高所选模型的能力，并且在七种多智能系统中，使用GPT-4模型的能力高出三倍于使用Llama-2-70B模型的能力。同时，研究也发现了不同模型之间的能力差距，并且PGM方法可以提高所有选择的模型的能力平均50%。研究代码可以在GitHub上下载：<a target="_blank" rel="noopener" href="https://github.com/cathyxl/MAgIC%E3%80%82">https://github.com/cathyxl/MAgIC。</a><details>
<summary>Abstract</summary>
Large Language Models (LLMs) have marked a significant advancement in the field of natural language processing, demonstrating exceptional capabilities in reasoning, tool usage, and memory. As their applications extend into multi-agent environments, a need has arisen for a comprehensive evaluation framework that captures their abilities in reasoning, planning, collaboration, and more. This work introduces a novel benchmarking framework specifically tailored to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. We utilize games such as Chameleon and Undercover, alongside game theory scenarios like Cost Sharing, Multi-player Prisoner's Dilemma, and Public Good, to create diverse testing environments. Our framework is fortified with the Probabilistic Graphical Modeling (PGM) method, enhancing the LLMs' capabilities in navigating complex social and cognitive dimensions. The benchmark evaluates seven multi-agent systems powered by different LLMs, quantitatively highlighting a significant capability gap over threefold between the strongest, GPT-4, and the weakest, Llama-2-70B. It also confirms that our PGM enhancement boosts the inherent abilities of all selected models by 50% on average. Our codes are released here https://github.com/cathyxl/MAgIC.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UT5-Pretraining-Non-autoregressive-T5-with-unrolled-denoising"><a href="#UT5-Pretraining-Non-autoregressive-T5-with-unrolled-denoising" class="headerlink" title="UT5: Pretraining Non autoregressive T5 with unrolled denoising"></a>UT5: Pretraining Non autoregressive T5 with unrolled denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08552">http://arxiv.org/abs/2311.08552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud G. Salem, Jiayu Ye, Chu-Cheng Lin, Frederick Liu</li>
<li>for: 本研究旨在提高Transformer基于大型自然语言模型的natural language generation能力，尤其是解决autoregressive模型在解码K个token时需要K次顺序前进的性能瓶颈。</li>
<li>methods: 本研究采用了非 autoregressive（NAR）方法，通过对T5模型进行无监督预训练，以提高其在下游生成任务中的性能。</li>
<li>results: 研究发现，通过对T5模型进行无监督预训练，可以在SQuAD问题生成任务和XSum任务中达到SoTA的性能水平。Here’s the simplified Chinese text in the format you requested:</li>
<li>for: 本研究旨在提高Transformer基于大型自然语言模型的natural language generation能力。</li>
<li>methods: 本研究采用了非 autoregressive（NAR）方法，通过对T5模型进行无监督预训练，以提高其在下游生成任务中的性能。</li>
<li>results: 研究发现，通过对T5模型进行无监督预训练，可以在SQuAD问题生成任务和XSum任务中达到SoTA的性能水平。<details>
<summary>Abstract</summary>
Recent advances in Transformer-based Large Language Models have made great strides in natural language generation. However, to decode K tokens, an autoregressive model needs K sequential forward passes, which may be a performance bottleneck for large language models. Many non-autoregressive (NAR) research are aiming to address this sequentiality bottleneck, albeit many have focused on a dedicated architecture in supervised benchmarks. In this work, we studied unsupervised pretraining for non auto-regressive T5 models via unrolled denoising and shown its SoTA results in downstream generation tasks such as SQuAD question generation and XSum.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Continual-Pre-training-for-Building-Domain-Specific-Large-Language-Models"><a href="#Efficient-Continual-Pre-training-for-Building-Domain-Specific-Large-Language-Models" class="headerlink" title="Efficient Continual Pre-training for Building Domain Specific Large Language Models"></a>Efficient Continual Pre-training for Building Domain Specific Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08545">http://arxiv.org/abs/2311.08545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong Xie, Karan Aggarwal, Aitzaz Ahmad</li>
<li>for: 这个研究是为了开发领域专业的语言模型（LLMs）。</li>
<li>methods: 这个研究使用了适应领域的 continual pre-training 方法来开发领域专业的 LLMs。</li>
<li>results: 研究发现，通过适应领域的 continual pre-training，可以在金融领域表现出色，并且比原始基础模型更好。此外，研究还提出了一些简单 yet effective 的数据选择策略，可以在少量的资料量和成本下达到更好的性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated remarkable open-domain capabilities. Traditionally, LLMs tailored for a domain are trained from scratch to excel at handling domain-specific tasks. In this work, we explore an alternative strategy of continual pre-training as a means to develop domain-specific LLMs. We introduce FinPythia-6.9B, developed through domain-adaptive continual pre-training on the financial domain. Continual pre-trained FinPythia showcases consistent improvements on financial tasks over the original foundational model. We further explore simple but effective data selection strategies for continual pre-training. Our data selection strategies outperforms vanilla continual pre-training's performance with just 10% of corpus size and cost, without any degradation on open-domain standard tasks. Our work proposes an alternative solution to building domain-specific LLMs from scratch in a cost-effective manner.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:大型语言模型（LLM）在开放领域上表现出色。传统上，为一个领域而适应的 LLM 通常是从scratch开始训练，以便在处理领域特定任务上表现出色。在这项工作中，我们探索了一种途径，通过连续预训练来开发领域特定的 LLM。我们介绍了基于金融领域的 FinPythia-6.9B，通过适应领域的连续预训练而开发。连续预训练后的 FinPythia 在金融任务上表现了一致性的改进，比原始基础模型更好。我们还进一步探索了简单而有效的数据选择策略，用于连续预训练。我们的数据选择策略可以在10%的文库大小和成本下达到同等水平，而不会影响开放领域的标准任务表现。我们的工作提出了一种可行的解决方案，即通过cost-effective的方式建立领域特定的 LLM。
</details></li>
</ul>
<hr>
<h2 id="Extending-Multilingual-Machine-Translation-through-Imitation-Learning"><a href="#Extending-Multilingual-Machine-Translation-through-Imitation-Learning" class="headerlink" title="Extending Multilingual Machine Translation through Imitation Learning"></a>Extending Multilingual Machine Translation through Imitation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08538">http://arxiv.org/abs/2311.08538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wen Lai, Viktor Hangya, Alexander Fraser</li>
<li>for: 扩展大规模多语言神经机器翻译模型（MNMT）到新语言，以便将所有已支持语言翻译到新语言。</li>
<li>methods: 使用imit-MNMT方法，即模仿专家的行为，通过英语作为中间语言，将新语言和原始语言的翻译结果相似。</li>
<li>results: 对新语言和原始语言之间的翻译表现有显著改善，无论 catastrophic forgetting 问题。同时，可以解决copy和off-target问题，两个常见的现代大规模 MNMT 模型存在的问题。<details>
<summary>Abstract</summary>
Despite the growing variety of languages supported by existing multilingual neural machine translation (MNMT) models, most of the world's languages are still being left behind. We aim to extend large-scale MNMT models to a new language, allowing for translation between the newly added and all of the already supported languages in a challenging scenario: using only a parallel corpus between the new language and English. Previous approaches, such as continued training on parallel data including the new language, suffer from catastrophic forgetting (i.e., performance on other languages is reduced). Our novel approach Imit-MNMT treats the task as an imitation learning process, which mimicks the behavior of an expert, a technique widely used in the computer vision area, but not well explored in NLP. More specifically, we construct a pseudo multi-parallel corpus of the new and the original languages by pivoting through English, and imitate the output distribution of the original MNMT model. Extensive experiments show that our approach significantly improves the translation performance between the new and the original languages, without severe catastrophic forgetting. We also demonstrate that our approach is capable of solving copy and off-target problems, which are two common issues existence in current large-scale MNMT models.
</details>
<details>
<summary>摘要</summary>
尽管现有的多语言神经机器翻译（MNMT）模型已经支持了许多语言，但大多数世界上的语言仍然被留下。我们想扩展大规模MNMT模型到一个新语言，以便在这个新语言和所有已经支持的语言之间进行翻译。过去的方法，如继续在并行数据集中包括新语言进行训练，会导致 catastrophic forgetting（即其他语言的性能下降）。我们的新方法Imit-MNMT将这个任务视为一种模仿学习过程，这种技术在计算机视觉领域广泛使用，但在自然语言处理领域并不受欢迎。更 Specifically，我们将新语言和原始语言之间的 pseudo 多并行数据集建立，通过英语作为中间语言，并模仿原始 MNMT 模型的输出分布。我们的方法在翻译性能方面取得了显著改进，而无需严重的 catastrophic forgetting。我们还证明了我们的方法可以解决现有大规模 MNMT 模型中的复制和偏差问题。
</details></li>
</ul>
<hr>
<h2 id="Natural-Language-Processing-for-Financial-Regulation"><a href="#Natural-Language-Processing-for-Financial-Regulation" class="headerlink" title="Natural Language Processing for Financial Regulation"></a>Natural Language Processing for Financial Regulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08533">http://arxiv.org/abs/2311.08533</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mdxedia/Awsome-Cash">https://github.com/mdxedia/Awsome-Cash</a></li>
<li>paper_authors: Ixandra Achitouv, Dragos Gorduza, Antoine Jacquier</li>
<li>for: 本研究使用自然语言处理技术来框架化金融监管领域中的规则和政策匹配搜索，无需数据支持学习。</li>
<li>methods: 本研究使用自然语言处理技术的基本构件，包括句子生成和句子分析，以及使用自由可用资源进行改进。</li>
<li>results: 本研究可以超越简单的预训练句子转换器模型，实现更高效的规则和政策匹配搜索。<details>
<summary>Abstract</summary>
This article provides an understanding of Natural Language Processing techniques in the framework of financial regulation, more specifically in order to perform semantic matching search between rules and policy when no dataset is available for supervised learning. We outline how to outperform simple pre-trained sentences-transformer models using freely available resources and explain the mathematical concepts behind the key building blocks of Natural Language Processing.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇文章提供了关于自然语言处理技术在金融规制框架中的理解，具体来说是为了在无可学习数据的情况下进行规则和政策之间的Semantic matching搜索。我们提供了使用可得到的资源超越简单预训练句子变换器模型的方法，并解释了自然语言处理中关键Component的数学概念。
</details></li>
</ul>
<hr>
<h2 id="CoRE-CoG-Conversational-Recommendation-of-Entities-using-Constrained-Generation"><a href="#CoRE-CoG-Conversational-Recommendation-of-Entities-using-Constrained-Generation" class="headerlink" title="CoRE-CoG: Conversational Recommendation of Entities using Constrained Generation"></a>CoRE-CoG: Conversational Recommendation of Entities using Constrained Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08511">http://arxiv.org/abs/2311.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshvardhan Srivastava, Kanav Pruthi, Soumen Chakrabarti, Mausam</li>
<li>for: 提高 conversational recommendation systems (CRS) 的准确性和流畅性，解决 prior systems 中的三大挑战（1）在每次转折时是否需要推荐知识库 (KB) 实体，(2) 推荐哪一个最相关的 KB 实体，以及 (3) 在对话历史中适当地推荐实体。</li>
<li>methods: CoRE-CoG 使用了以下三个模块来解决这些挑战：(1) 推荐触发器，决定系统语句是否包含实体，(2) 类型剔除模块，提高推荐实体的相关性，以及 (3) 一种新的约束回归生成器，以保持 fluency 并做出准确的推荐决定。</li>
<li>results: CoRE-CoG 在最新的 benchmark 上实现了close to 10 F1 和 4 Recall@1 的 conditional generation 子任务的提高，与基线相比增加了近 10 F1 和 4 Recall@1 的分数点。<details>
<summary>Abstract</summary>
End-to-end conversational recommendation systems (CRS) generate responses by leveraging both dialog history and a knowledge base (KB). A CRS mainly faces three key challenges: (1) at each turn, it must decide if recommending a KB entity is appropriate; if so, it must identify the most relevant KB entity to recommend; and finally, it must recommend the entity in a fluent utterance that is consistent with the conversation history. Recent CRSs do not pay sufficient attention to these desiderata, often generating unfluent responses or not recommending (relevant) entities at the right turn. We introduce a new CRS we call CoRE-CoG. CoRE-CoG addresses the limitations in prior systems by implementing (1) a recommendation trigger that decides if the system utterance should include an entity, (2) a type pruning module that improves the relevance of recommended entities, and (3) a novel constrained response generator to make recommendations while maintaining fluency. Together, these modules ensure simultaneous accurate recommendation decisions and fluent system utterances. Experiments with recent benchmarks show the superiority particularly on conditional generation sub-tasks with close to 10 F1 and 4 Recall@1 percent points gain over baselines.
</details>
<details>
<summary>摘要</summary>
End-to-end conversational recommendation systems (CRS) 通过对对话历史和知识库 (KB) 的利用，生成响应。CRS 面临三个关键挑战：在每个转卡时，决定是否推荐 KB 实体，如果是，则确定最相关的 KB 实体，最后，推荐实体的表达需要与对话历史一致。现有 CRS 不够重视这些要求，经常生成不流畅的响应或者不推荐相关的实体。我们提出了一个新的 CRS，即 CoRE-CoG。CoRE-CoG 通过实施以下三个模块来解决先前系统的限制：1. 推荐触发器：决定系统语句是否包含实体。2. 类型缩短模块：提高推荐实体的相关性。3. 一种新的受限响应生成器：在保持流畅性的情况下，为系统语句提供推荐。这些模块共同确保同时准确地做出推荐决策和流畅的系统语句。对于最近的benchmark检验，CoRE-CoG 表现出优异，特别是在条件生成子任务中，与基eline相比，取得了近10个 F1 和 4 的 Recall@1 百分点的提升。
</details></li>
</ul>
<hr>
<h2 id="Semi-Structured-Chain-of-Thought-Integrating-Multiple-Sources-of-Knowledge-for-Improved-Language-Model-Reasoning"><a href="#Semi-Structured-Chain-of-Thought-Integrating-Multiple-Sources-of-Knowledge-for-Improved-Language-Model-Reasoning" class="headerlink" title="Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning"></a>Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08505">http://arxiv.org/abs/2311.08505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Su, Tiep Le, Steven Bethard, Phillip Howard</li>
<li>for: 提高大语言模型在知识密集任务中的表现</li>
<li>methods: 引入 semi-structured prompting 方法，协同使用模型的 parametric memory、文本文档中的不结构化知识和知识图中的结构化知识</li>
<li>results: 在多步问答任务上达到了比较好的表现，甚至超过了一些需要 fine-tuning 的方法<details>
<summary>Abstract</summary>
An important open question pertaining to the use of large language models for knowledge-intensive tasks is how to effectively integrate knowledge from three sources: the model's parametric memory, external structured knowledge, and external unstructured knowledge. Most existing prompting methods either rely solely on one or two of these sources, or require repeatedly invoking large language models to generate similar or identical content. In this work, we overcome these limitations by introducing a novel semi-structured prompting approach that seamlessly integrates the model's parametric memory with unstructured knowledge from text documents and structured knowledge from knowledge graphs. Experimental results on open-domain multi-hop question answering datasets demonstrate that our prompting method significantly surpasses existing techniques, even exceeding those which require fine-tuning.
</details>
<details>
<summary>摘要</summary>
Currently, a significant open question regarding the use of large language models for knowledge-intensive tasks is how to effectively integrate knowledge from three sources: the model's parametric memory, external structured knowledge, and external unstructured knowledge. Most existing prompting methods either rely solely on one or two of these sources or require repeatedly invoking large language models to generate similar or identical content. In this work, we overcome these limitations by introducing a novel semi-structured prompting approach that seamlessly integrates the model's parametric memory with unstructured knowledge from text documents and structured knowledge from knowledge graphs. Experimental results on open-domain multi-hop question answering datasets demonstrate that our prompting method significantly surpasses existing techniques, even exceeding those which require fine-tuning.Here's the text in Traditional Chinese:目前，大型语言模型用于知识工作中的一个重要开问是如何有效地结合三种知识来源：模型的参数记忆、外部结构化知识和外部无结构化知识。现有的提示方法大多只靠一或二种来源，或者需要重复运行大型语言模型来生成相似或相同的内容。在这个工作中，我们解决了这些限制，通过引入一种新的半结构化提示方法，将模型的参数记忆与文档中的无结构化知识和知识图中的结构化知识融合在一起。实验结果显示，我们的提示方法在开放领域多步问答dataset上表现出色， Even exceeding those which require fine-tuning.
</details></li>
</ul>
<hr>
<h2 id="Functionality-learning-through-specification-instructions"><a href="#Functionality-learning-through-specification-instructions" class="headerlink" title="Functionality learning through specification instructions"></a>Functionality learning through specification instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08481">http://arxiv.org/abs/2311.08481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pedro Henrique Luz de Araujo, Benjamin Roth</li>
<li>for: 本研究旨在提高自然语言处理模型的功能学习能力，不需要练习数据集。</li>
<li>methods: 研究人员生成了一组指令说明，用于定义每个功能的需求。然后，他们将这些指令组合成 specification-augmented prompts，并对预训练在自然指令数据上的语言模型进行测试。</li>
<li>results: 研究发现，较小的模型（params &lt; 3B）具有困难遵循指令说明的能力，而较大的模型（params &gt; 3B）可以受益于指令说明，甚至在不同的功能上展现愉悦的行为。<details>
<summary>Abstract</summary>
Test suites assess natural language processing models' performance on specific functionalities: cases of interest involving model robustness, fairness, or particular linguistic capabilities. They enable fine-grained evaluations of model aspects that would otherwise go unnoticed in standard evaluation datasets, but they do not address the problem of how to fix the failure cases. Previous work has explored functionality learning by fine-tuning models on suite data. While this improves performance on seen functionalities, it often does not generalize to unseen ones and can harm general performance.   This paper analyses a fine-tuning-free approach to functionality learning. For each functionality in a suite, we generate a specification instruction that encodes it. We combine the obtained specification instructions to create specification-augmented prompts, which we feed to language models pre-trained on natural instruction data to generate suite predictions. A core aspect of our analysis is to measure the effect that including a set of specifications has on a held-out set of unseen, qualitatively different specifications. Our experiments across four tasks and models ranging from 80M to 175B parameters show that smaller models struggle to follow specification instructions. However, larger models (> 3B params.) can benefit from specifications and even generalize desirable behaviors across functionalities.
</details>
<details>
<summary>摘要</summary>
<<SYS>>测试集用于评估自然语言处理模型的特定功能性能：涉及到模型Robustness、公平性或特定语言能力的场景。它们允许细化评估模型的具体方面，而标准评估数据集中的问题则可能被忽略不了。先前的工作已经探讨了学习功能性能的方法，包括在suite数据上练习模型。although this improves performance on seen functionalities, it often does not generalize to unseen ones and can harm general performance.  本文分析了一种不需要练习的方法来学习功能性能。对于每个suite中的功能，我们生成一个 specification instruction，这个 instruction 编码了该功能。我们将获得的 specification instructions 组合成 specification-augmented prompts，并将这些提示 feed 到自然 instrucion 数据上预训练的语言模型中，以供 suite 预测。我们的分析中的核心问题是测量在一个固定的 held-out 集中的未见、Qualitatively different 的 specification 对模型的影响。我们的实验通过四个任务和参数量从 80M 到 175B 的模型展示，较小的模型困难遵循 specification instructions，但是大于 3B 参数的模型可以利用 specification 并将恰当的行为扩展到不同的功能。
</details></li>
</ul>
<hr>
<h2 id="Selecting-Shots-for-Demographic-Fairness-in-Few-Shot-Learning-with-Large-Language-Models"><a href="#Selecting-Shots-for-Demographic-Fairness-in-Few-Shot-Learning-with-Large-Language-Models" class="headerlink" title="Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models"></a>Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08472">http://arxiv.org/abs/2311.08472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Aguirre, Kuleen Sasse, Isabel Cachola, Mark Dredze</li>
<li>for: This paper is written to explore the fairness of large language models (LLMs) as NLP classification systems, specifically looking at how different shot selection strategies affect model fairness.</li>
<li>methods: The paper uses standard NLP tasks and three fairness datasets to evaluate the fairness of LLMs. The authors consider both existing and new demographically sensitive methods for shot selection.</li>
<li>results: The paper explores how different shot selection strategies affect the fairness of LLMs as NLP classification systems, and discusses how future work can include LLM fairness evaluations.<details>
<summary>Abstract</summary>
Recently, work in NLP has shifted to few-shot (in-context) learning, with large language models (LLMs) performing well across a range of tasks. However, while fairness evaluations have become a standard for supervised methods, little is known about the fairness of LLMs as prediction systems. Further, common standard methods for fairness involve access to models weights or are applied during finetuning, which are not applicable in few-shot learning. Do LLMs exhibit prediction biases when used for standard NLP tasks? In this work, we explore the effect of shots, which directly affect the performance of models, on the fairness of LLMs as NLP classification systems. We consider how different shot selection strategies, both existing and new demographically sensitive methods, affect model fairness across three standard fairness datasets. We discuss how future work can include LLM fairness evaluations.
</details>
<details>
<summary>摘要</summary>
最近，NLU工作偏向几个shot（在上下文中学习），大型自然语言模型（LLM）在多种任务上表现良好。然而，对于LLM作为预测系统的公平性知之甚少。常见的标准方法 для公平性做出在模型权重访问或在微调中应用，这些方法不适用于几个shot学习。 LLM是否具有预测偏见？在这个工作中，我们研究shot的影响，直接影响模型性能，LLM作为NLU分类系统的公平性。我们考虑了不同的shot选择策略，包括现有的人口普查方法和新的人口普查方法，对三个标准公平性数据集的模型公平性进行分析。我们讨论了未来工作如何包括LLM公平性评估。
</details></li>
</ul>
<hr>
<h2 id="UNcommonsense-Reasoning-Abductive-Reasoning-about-Uncommon-Situations"><a href="#UNcommonsense-Reasoning-Abductive-Reasoning-about-Uncommon-Situations" class="headerlink" title="UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations"></a>UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08469">http://arxiv.org/abs/2311.08469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenting Zhao, Justin T Chiu, Jena D. Hwang, Faeze Brahman, Jack Hessel, Sanjiban Choudhury, Yejin Choi, Xiang Lorraine Li, Alane Suhr</li>
<li>for: 研究异常、不常见的情况下的推理能力。</li>
<li>methods: 使用人工推理和大语言模型来生成解释，以提高对于不常见的情况下的预测能力。</li>
<li>results: 比较人类解释和大语言模型的表现，发现人类解释和模型合作的解释能够达到最高质量，并且可以在 especificity 和 diversity 之间进行融合。此外，通过在线模仿学习算法进行训练，可以更好地帮助模型学习这种任务。<details>
<summary>Abstract</summary>
Language technologies that accurately model the dynamics of events must perform commonsense reasoning. Existing work evaluating commonsense reasoning focuses on making inferences about common, everyday situations. To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to generate a natural language explanation that makes the unexpected outcome more likely in the context. To this end, we curate and release a new English language corpus called UNcommonsense. We characterize the differences between the performance of human explainers and the best performing large language models, finding that model-enhanced human-written explanations achieve the highest quality by trading off between specificity and diversity. Finally, we experiment with several online imitation learning algorithms to train open and accessible language models on this task. When compared with the vanilla supervised fine-tuning approach, these methods consistently reduce lose rates on both common and uncommonsense abductive reasoning judged by human evaluators.
</details>
<details>
<summary>摘要</summary>
Language technologies that accurately model the dynamics of events must perform commonsense reasoning. Existing work evaluating commonsense reasoning focuses on making inferences about common, everyday situations. To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to generate a natural language explanation that makes the unexpected outcome more likely in the context. To this end, we curate and release a new English language corpus called UNcommonsense. We characterize the differences between the performance of human explainers and the best performing large language models, finding that model-enhanced human-written explanations achieve the highest quality by trading off between specificity and diversity. Finally, we experiment with several online imitation learning algorithms to train open and accessible language models on this task. When compared with the vanilla supervised fine-tuning approach, these methods consistently reduce lose rates on both common and uncommonsense abductive reasoning judged by human evaluators.Here's the translation in Traditional Chinese as well:Language technologies that accurately model the dynamics of events must perform commonsense reasoning. Existing work evaluating commonsense reasoning focuses on making inferences about common, everyday situations. To instead investigate the ability to model unusual, unexpected, and unlikely situations, we explore the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to generate a natural language explanation that makes the unexpected outcome more likely in the context. To this end, we curate and release a new English language corpus called UNcommonsense. We characterize the differences between the performance of human explainers and the best performing large language models, finding that model-enhanced human-written explanations achieve the highest quality by trading off between specificity and diversity. Finally, we experiment with several online imitation learning algorithms to train open and accessible language models on this task. When compared with the vanilla supervised fine-tuning approach, these methods consistently reduce lose rates on both common and uncommonsense abductive reasoning judged by human evaluators.
</details></li>
</ul>
<hr>
<h2 id="Retrieve-and-Copy-Scaling-ASR-Personalization-to-Large-Catalogs"><a href="#Retrieve-and-Copy-Scaling-ASR-Personalization-to-Large-Catalogs" class="headerlink" title="Retrieve and Copy: Scaling ASR Personalization to Large Catalogs"></a>Retrieve and Copy: Scaling ASR Personalization to Large Catalogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08402">http://arxiv.org/abs/2311.08402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Muralidhar Jayanthi, Devang Kulshreshtha, Saket Dingliwal, Srikanth Ronanki, Sravan Bodapati</li>
<li>for: 提高自然语言处理（NLP）系统的自适应性，以提高识别罕见词和域 especific实体的精度。</li>
<li>methods: 使用注意力基于的上下文偏好技术来改进识别罕见词和域 especific实体的精度。</li>
<li>results: 提出了一种“检索并复制”机制，可以提高响应速度而不 sacrifi 精度，并提出了一种培 optimized training 策略，可以在大型目录中提高识别精度。实验结果表明，我们的方法可以相比强基eline提高 Word Error Rate （WERR）上到 6%，并提高 F1 得分约 3.6%。同时，我们的方法可以支持大型目录，不会影响 WER 和 F1 分数，并且可以实现每个音频帧的执行速度提高至少 20%。<details>
<summary>Abstract</summary>
Personalization of automatic speech recognition (ASR) models is a widely studied topic because of its many practical applications. Most recently, attention-based contextual biasing techniques are used to improve the recognition of rare words and domain specific entities. However, due to performance constraints, the biasing is often limited to a few thousand entities, restricting real-world usability. To address this, we first propose a "Retrieve and Copy" mechanism to improve latency while retaining the accuracy even when scaled to a large catalog. We also propose a training strategy to overcome the degradation in recall at such scale due to an increased number of confusing entities. Overall, our approach achieves up to 6% more Word Error Rate reduction (WERR) and 3.6% absolute improvement in F1 when compared to a strong baseline. Our method also allows for large catalog sizes of up to 20K without significantly affecting WER and F1-scores, while achieving at least 20% inference speedup per acoustic frame.
</details>
<details>
<summary>摘要</summary>
personalized automatic speech recognition (ASR) models 是一个广泛研究的话题，因为它有很多实际应用。最近，人们主要使用注意力基于的上下文偏好技术来改善罕见词和领域专有实体的识别。然而，由于性能约束，偏好通常是限制在几千个实体上，这限制了实际应用的可用性。为了解决这个问题，我们首先提出了“获取并复制”机制，以提高响应时间而不失去精度，即使扩展到大型目录。我们还提出了一种训练策略，以超越扩展后的识别率下降。总的来说，我们的方法可以在20K大型目录下实现6%左右的单词错误率下降（WERR）和3.6%绝对提升的F1分数，而无需明显影响WER和F1分数。此外，我们的方法还可以在每个音频帧上实现至少20%的执行速度提升。
</details></li>
</ul>
<hr>
<h2 id="A-Material-Lens-on-Coloniality-in-NLP"><a href="#A-Material-Lens-on-Coloniality-in-NLP" class="headerlink" title="A Material Lens on Coloniality in NLP"></a>A Material Lens on Coloniality in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08391">http://arxiv.org/abs/2311.08391</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Held, Camille Harris, Michael Best, Diyi Yang</li>
<li>for: 本文旨在探讨自然语言处理（NLP）领域中的殖民性强度，并提出了解决方案。</li>
<li>methods: 本文使用了actor-network理论（ANT）来分析NLP数据、算法和软件中的殖民性关系网络，并进行了质量调查以证明殖民性强度随NLP研究阶段的发展增长。</li>
<li>results: 研究发现，NLP领域的殖民性强度随着时间的推移而增长，而且与殖民前期的不平等关系有直接的相关性。因此，要解决NLP中的殖民性问题，不仅需要更改现有的价值观，还需要 aktiv地去除殖民思想在基础数据和算法中的积累。<details>
<summary>Abstract</summary>
Coloniality, the continuation of colonial harms beyond "official" colonization, has pervasive effects across society and scientific fields. Natural Language Processing (NLP) is no exception to this broad phenomenon. In this work, we argue that coloniality is implicitly embedded in and amplified by NLP data, algorithms, and software. We formalize this analysis using Actor-Network Theory (ANT): an approach to understanding social phenomena through the network of relationships between human stakeholders and technology. We use our Actor-Network to guide a quantitative survey of the geography of different phases of NLP research, providing evidence that inequality along colonial boundaries increases as NLP builds on itself. Based on this, we argue that combating coloniality in NLP requires not only changing current values but also active work to remove the accumulation of colonial ideals in our foundational data and algorithms.
</details>
<details>
<summary>摘要</summary>
殖民性，即殖民主义的继续影响 beyond "官方" 殖民化，对社会和科学领域都产生了广泛的影响。自然语言处理（NLP）不例外。在这篇文章中，我们 argued that 殖民性在 NLP 数据、算法和软件中是隐式地嵌入的，并通过这些技术的网络关系来强化。我们使用 Actor-Network 理论（ANT）来理解社会现象，通过人类利益相互关系和技术之间的网络来分析。我们使用我们的 Actor-Network 来导引一项量化调查 NLP 研究的不同阶段的地理学，并提供证据表明，在 NLP 建立起来的过程中，殖民性的不平等增加。基于这些证据，我们 argue that 在 NLP 中推翻殖民性需要不仅改变当前的价值观，还需要活动地除掉殖民主义的积累在我们基础数据和算法中。
</details></li>
</ul>
<hr>
<h2 id="On-What-Basis-Predicting-Text-Preference-Via-Structured-Comparative-Reasoning"><a href="#On-What-Basis-Predicting-Text-Preference-Via-Structured-Comparative-Reasoning" class="headerlink" title="On What Basis? Predicting Text Preference Via Structured Comparative Reasoning"></a>On What Basis? Predicting Text Preference Via Structured Comparative Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08390">http://arxiv.org/abs/2311.08390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Nathan Yan, Tianqi Liu, Justin T Chiu, Jiaming Shen, Zhen Qin, Yue Yu, Yao Zhao, Charu Lakshmanan, Yair Kurzion, Alexander M. Rush, Jialu Liu, Michael Bendersky</li>
<li>for: 用于提高自然语言处理（NLP）中文本偏好预测的精度。</li>
<li>methods: 使用结构化中间比较来预测文本偏好。首先提出比较方面，然后生成每个方面下的文本比较。使用对比式比较器确保每个方面的比较能够清晰地区分文本之间的差异，从而减少幻想和提高一致性。</li>
<li>results: 在多种NLP任务中，包括摘要、检索和自动评分等，SCapproach可以使LLMs达到文本偏好预测的状态 искусственный智能水平。<details>
<summary>Abstract</summary>
Comparative reasoning plays a crucial role in text preference prediction; however, large language models (LLMs) often demonstrate inconsistencies in their reasoning. While approaches like Chain-of-Thought improve accuracy in many other settings, they struggle to consistently distinguish the similarities and differences of complex texts. We introduce SC, a prompting approach that predicts text preferences by generating structured intermediate comparisons. SC begins by proposing aspects of comparison, followed by generating textual comparisons under each aspect. We select consistent comparisons with a pairwise consistency comparator that ensures each aspect's comparisons clearly distinguish differences between texts, significantly reducing hallucination and improving consistency. Our comprehensive evaluations across various NLP tasks, including summarization, retrieval, and automatic rating, demonstrate that SC equips LLMs to achieve state-of-the-art performance in text preference prediction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本为简化中文。</SYS>>文本比较逻辑在文本偏好预测中发挥关键作用，但大型语言模型（LLM）经常表现出不一致的逻辑。虽然链条思维方法在其他设定中提高准确性，但它们在识别复杂文本之间的相似性和差异时表现不佳。我们介绍了SC，一种提示方法，它预测文本偏好by generating结构化中间比较。SC首先提出比较方面，然后生成文本中的比较。我们使用对比式相似性比较器来选择一致的比较，以确保每个比较方面的比较能够清晰地分辨文本之间的差异，从而减少幻觉和提高一致性。我们在各种NLP任务，包括摘要、检索和自动评分中进行了全面的评估，demonstrate that SC使得LLM可以实现文本偏好预测的状态码性表现。
</details></li>
</ul>
<hr>
<h2 id="ChOiRe-Characterizing-and-Predicting-Human-Opinions-with-Chain-of-Opinion-Reasoning"><a href="#ChOiRe-Characterizing-and-Predicting-Human-Opinions-with-Chain-of-Opinion-Reasoning" class="headerlink" title="ChOiRe: Characterizing and Predicting Human Opinions with Chain of Opinion Reasoning"></a>ChOiRe: Characterizing and Predicting Human Opinions with Chain of Opinion Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08385">http://arxiv.org/abs/2311.08385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dxlong2000/ChOiRe">https://github.com/dxlong2000/ChOiRe</a></li>
<li>paper_authors: Xuan Long Do, Kenji Kawaguchi, Min-Yen Kan, Nancy F. Chen</li>
<li>for: 预测人类意见 (predicting human opinions)</li>
<li>methods: 四步解决方案框架 (four-step solution framework)：	1. LM 分析用户明确人格 (analyze user explicit personae)	2. LM 排序隐藏人格意见 (rank implicit persona opinions)	3. 链接意见 (Chain-of-Opinion) 运算	4. 多次执行链接意见 (execute CoO multiple times)</li>
<li>results: 提高过往技术表现率 (improve previous LLM-based techniques) by 3.22%.<details>
<summary>Abstract</summary>
Aligning language models (LMs) with human opinion is challenging yet vital to enhance their grasp of human values, preferences, and beliefs. We present ChOiRe, a four-step solution framework to predict human opinion that differentiates between the user explicit personae (i.e. demographic or ideological attributes) that are manually declared and implicit personae inferred from user historical opinions. Specifically, it consists of (i) an LM analyzing the user explicit personae to filter out irrelevant attributes; (ii) the LM ranking the implicit persona opinions into a preferential list; (iii) Chain-of-Opinion (CoO) reasoning, where the LM sequentially analyzes the explicit personae and the most relevant implicit personae to perform opinion prediction; (iv) and where ChOiRe executes Step (iii) CoO multiple times with increasingly larger lists of implicit personae to overcome insufficient personae information to infer a final result. ChOiRe achieves new state-of-the-art effectiveness with limited inference calls, improving previous LLM-based techniques significantly by 3.22%.
</details>
<details>
<summary>摘要</summary>
aligning language models (LMs) with human opinion 是一项挑战性质的 yet vital 任务，以提高 LMs 的人类价值观、偏好和信仰的理解。我们提出了 ChOiRe，一个四步解决方案框架，用于预测人类意见。specifically，it consists of (i) an LM analyzing the user explicit personae （i.e. demographic or ideological attributes）to filter out irrelevant attributes; (ii) the LM ranking the implicit persona opinions into a preferential list; (iii) Chain-of-Opinion (CoO) reasoning, where the LM sequentially analyzes the explicit personae and the most relevant implicit personae to perform opinion prediction; (iv) and where ChOiRe executes Step (iii) CoO multiple times with increasingly larger lists of implicit personae to overcome insufficient personae information to infer a final result. ChOiRe achieves new state-of-the-art effectiveness with limited inference calls, improving previous LLM-based techniques significantly by 3.22%.
</details></li>
</ul>
<hr>
<h2 id="Direct-Preference-Optimization-for-Neural-Machine-Translation-with-Minimum-Bayes-Risk-Decoding"><a href="#Direct-Preference-Optimization-for-Neural-Machine-Translation-with-Minimum-Bayes-Risk-Decoding" class="headerlink" title="Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding"></a>Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08380">http://arxiv.org/abs/2311.08380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyu Yang, Jinghong Chen, Weizhe Lin, Bill Byrne</li>
<li>for: 提高多语言大语言模型（MLLM）的翻译性能</li>
<li>methods: 使用现代 reinforcement learning（RL）技术，具体是Direct Preference Optimization（DPO）来微调 MLLM，以获得 MBR decoding 的好处而不需要额外计算</li>
<li>results: 在多个 NMT 测试集上，我们的微调模型比基础 MLLM  ohne preference optimization 有显著的提高，并且只需使用小型单语言微调集来实现。<details>
<summary>Abstract</summary>
Minimum Bayes Risk (MBR) decoding can significantly improve translation performance of Multilingual Large Language Models (MLLMs). However, MBR decoding is computationally expensive and in this paper, we show how recently developed Reinforcement Learning (RL) technique, Direct Preference Optimization (DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without the additional computation in inference. Our fine-tuned models have significantly improved performance on multiple NMT test sets compared to base MLLMs without preference optimization. Our method boosts the translation performance of MLLMs using relatively small monolingual fine-tuning sets.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Minimum Bayes Risk (MBR) decoding can significantly improve translation performance of Multilingual Large Language Models (MLLMs). However, MBR decoding is computationally expensive and in this paper, we show how recently developed Reinforcement Learning (RL) technique, Direct Preference Optimization (DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without the additional computation in inference. Our fine-tuned models have significantly improved performance on multiple NMT test sets compared to base MLLMs without preference optimization. Our method boosts the translation performance of MLLMs using relatively small monolingual fine-tuning sets." into Simplified Chinese.翻译结果：可以使用最小概率风险（MBR）解码提高多语言大语言模型（MLLM）的翻译性能。然而，MBR解码 computationally costly。在这篇论文中，我们使用最近发展的回归学习（RL）技术，直接偏好优化（DPO）来练化 MLLM，以获得 MBR 的优点而无需在推理中添加计算。我们的练化模型在多个 NMT 测试集上显著提高了翻译性能，与基础 MLLM  без偏好优化比较。我们的方法可以通过 relativelly 小的单语言练化集来提高 MLLM 的翻译性能。
</details></li>
</ul>
<hr>
<h2 id="A-Ship-of-Theseus-Curious-Cases-of-Paraphrasing-in-LLM-Generated-Texts"><a href="#A-Ship-of-Theseus-Curious-Cases-of-Paraphrasing-in-LLM-Generated-Texts" class="headerlink" title="A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts"></a>A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08374">http://arxiv.org/abs/2311.08374</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nafis Irtiza Tripto, Saranya Venkatraman, Dominik Macko, Robert Moro, Ivan Srba, Adaku Uchendu, Thai Le, Dongwon Lee</li>
<li>for:  investigate whether a text retains its original authorship when it undergoes numerous paraphrasing iterations using Large Language Models (LLMs)</li>
<li>methods:  employing LLMs to paraphrase the text and examining the resulting text for retention of original authorship</li>
<li>results:  a philosophical inquiry into the determination of authorship in instances where LLMs or similar paraphrasing tools are employed to rephrase the text, with a focus on whether authorship should be attributed to the original human author or the AI-powered tool<details>
<summary>Abstract</summary>
In the realm of text manipulation and linguistic transformation, the question of authorship has always been a subject of fascination and philosophical inquiry. Much like the \textbf{Ship of Theseus paradox}, which ponders whether a ship remains the same when each of its original planks is replaced, our research delves into an intriguing question: \textit{Does a text retain its original authorship when it undergoes numerous paraphrasing iterations?} Specifically, since Large Language Models (LLMs) have demonstrated remarkable proficiency in the generation of both original content and the modification of human-authored texts, a pivotal question emerges concerning the determination of authorship in instances where LLMs or similar paraphrasing tools are employed to rephrase the text. This inquiry revolves around \textit{whether authorship should be attributed to the original human author or the AI-powered tool, given the tool's independent capacity to produce text that closely resembles human-generated content.} Therefore, we embark on a philosophical voyage through the seas of language and authorship to unravel this intricate puzzle.
</details>
<details>
<summary>摘要</summary>
在文本处理和语言转化领域中，作者所有权问题一直是一个感人和哲学问题。与《戴达瑟斯船只 парадок斯》相似，我们的研究探讨了一个有趣的问题：改进了多个重叠修改后，文本仍然保留原始作者的身份吗？具体来说，由大语言模型（LLMs）所示的出色表现使得我们面临着一个问题：在使用LLMs或类似的重叠修改工具时，推准作者的身份应该归属于原始的人类作者还是AI工具？这个问题环绕着AI工具独立地生成文本的能力和人类生成内容的相似性。因此，我们将开启一场哲学之旅，探索语言和作者所有权的秘密。
</details></li>
</ul>
<hr>
<h2 id="SimpleSafetyTests-a-Test-Suite-for-Identifying-Critical-Safety-Risks-in-Large-Language-Models"><a href="#SimpleSafetyTests-a-Test-Suite-for-Identifying-Critical-Safety-Risks-in-Large-Language-Models" class="headerlink" title="SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models"></a>SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08370">http://arxiv.org/abs/2311.08370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bertie Vidgen, Hannah Rose Kirk, Rebecca Qian, Nino Scherrer, Anand Kannappan, Scott A. Hale, Paul Röttger</li>
<li>for: 这个论文的目的是为开发者和企业提供一个快速和系统地检测大语言模型（LLM）的重要安全隐患的测试集。</li>
<li>methods: 论文提出了一个名为SimpleSafetyTests的新测试集，包含5种危害领域的100个测试提示，以检测 LLM 是否会遵循有害指令、提供危险建议或生成恶意内容。</li>
<li>results: 测试发现大多数测试用的 LLM 在20%以上的情况下做出了危险响应，其中一些模型甚至在50%以上的情况下做出了危险响应。 prepending 一个安全强调系统提示可以显著减少危险响应的发生，但并不能完全消除它们。<details>
<summary>Abstract</summary>
The past year has seen rapid acceleration in the development of large language models (LLMs). For many tasks, there is now a wide range of open-source and open-access LLMs that are viable alternatives to proprietary models like ChatGPT. Without proper steering and safeguards, however, LLMs will readily follow malicious instructions, provide unsafe advice, and generate toxic content. This is a critical safety risk for businesses and developers. We introduce SimpleSafetyTests as a new test suite for rapidly and systematically identifying such critical safety risks. The test suite comprises 100 test prompts across five harm areas that LLMs, for the vast majority of applications, should refuse to comply with. We test 11 popular open LLMs and find critical safety weaknesses in several of them. While some LLMs do not give a single unsafe response, most models we test respond unsafely on more than 20% of cases, with over 50% unsafe responses in the extreme. Prepending a safety-emphasising system prompt substantially reduces the occurrence of unsafe responses, but does not completely stop them from happening. We recommend that developers use such system prompts as a first line of defence against critical safety risks.
</details>
<details>
<summary>摘要</summary>
过去一年，大型语言模型（LLM）的开发速度快速增加。许多任务上现在有很多开源和开放的 LLM，可以作为专有模型如ChatGPT的替代品。如果没有适当的导航和安全措施，LLM很快就会遵循恶意指令，提供危险的建议，并生成毒害内容。这是商业和开发人员的重要安全风险。我们介绍了 SimpleSafetyTests 作为新的测试集，用于快速和系统地检测这些重要安全风险。测试集包括 100 个测试提示，涵盖了五种伤害领域，LLM 在大多数应用程序上应该拒绝遵从。我们测试了 11 个流行的开源 LLM，发现了一些重要的安全漏洞。although some LLMs do not give a single unsafe response，most models we test respond unsafely on more than 20% of cases，with over 50% unsafe responses in the extreme。在添加安全强调系统提示前，Unsafe responses 的发生率很高，但不可以完全消除。我们建议开发人员使用这些系统提示作为首选防止重要安全风险的措施。
</details></li>
</ul>
<hr>
<h2 id="How-You-Prompt-Matters-Even-Task-Oriented-Constraints-in-Instructions-Affect-LLM-Generated-Text-Detection"><a href="#How-You-Prompt-Matters-Even-Task-Oriented-Constraints-in-Instructions-Affect-LLM-Generated-Text-Detection" class="headerlink" title="How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection"></a>How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08369">http://arxiv.org/abs/2311.08369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki</li>
<li>for: 本研究旨在探讨现有语言模型检测器在生成文本时的表现不稳定性，具体来说是在学生作业写作中使用任务导向的约束会导致检测器的表现不一致。</li>
<li>methods: 本研究使用现有的语言模型生成文本检测器，并手动创建了作业质量因素的任务导向约束。实验结果显示，使用任务导向约束的 instrucion 可以导致检测器的表现差异增加至多达 20 倍。</li>
<li>results: 本研究发现，使用任务导向约束的 instrucion 可以导致现有的检测器表现不稳定，具体来说是在生成文本时的表现差异可以达到多达 20 倍。这些结果表明需要进一步的研究，以开发更加稳定的检测器，能够检测任务导向约束所引起的分布Shift。<details>
<summary>Abstract</summary>
Against the misuse (e.g., plagiarism or spreading misinformation) of Large Language Models (LLMs), many recent works have presented LLM-generated-text detectors with promising detection performance. Spotlighting a situation where users instruct LLMs to generate texts (e.g., essay writing), there are various ways to write the instruction (e.g., what task-oriented constraint to include). In this paper, we discover that even a task-oriented constraint in instruction can cause the inconsistent performance of current detectors to the generated texts. Specifically, we focus on student essay writing as a realistic domain and manually create the task-oriented constraint for each factor on essay quality by Ke and Ng (2019). Our experiment shows that the detection performance variance of the current detector on texts generated by instruction with each task-oriented constraint is up to 20 times larger than the variance caused by generating texts multiple times and paraphrasing the instruction. Our finding calls for further research on developing robust detectors that can detect such distributional shifts caused by a task-oriented constraint in the instruction.
</details>
<details>
<summary>摘要</summary>
对大语言模型（LLM）的滥用（如 пла格іязм或传播False Information），许多最近的研究已经提出了LLM生成文本检测器，其检测性能有promising的表现。对于用户将LLM生成文本（例如学生写作），存在多种写作指导（例如任务型束）。在这篇文章中，我们发现，即使用户提供了任务型束，current detector的检测性能仍然存在不稳定性。 Specifically, we focus on学生写作 as a realistic domain, and manually create the task-oriented constraint for each factor of essay quality proposed by Ke and Ng (2019). Our experiment shows that the detection performance variance of the current detector on texts generated by instruction with each task-oriented constraint is up to 20 times larger than the variance caused by generating texts multiple times and paraphrasing the instruction. Our finding calls for further research on developing robust detectors that can detect such distributional shifts caused by a task-oriented constraint in the instruction.
</details></li>
</ul>
<hr>
<h2 id="Artificial-Text-Boundary-Detection-with-Topological-Data-Analysis-and-Sliding-Window-Techniques"><a href="#Artificial-Text-Boundary-Detection-with-Topological-Data-Analysis-and-Sliding-Window-Techniques" class="headerlink" title="Artificial Text Boundary Detection with Topological Data Analysis and Sliding Window Techniques"></a>Artificial Text Boundary Detection with Topological Data Analysis and Sliding Window Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08349">http://arxiv.org/abs/2311.08349</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laida Kushnareva, Tatiana Gaintseva, German Magai, Serguei Barannikov, Dmitry Abulkhanov, Kristian Kuznetsov, Irina Piontkovskaya, Sergey Nikolenko</li>
<li>for: 本研究旨在探讨人工智能语言生成模型的快速发展以来，文本中的人类和机器生成部分的分界问题。</li>
<li>methods: 本研究考虑了多种不同的方法来解决人工智能语言生成模型中文本的分界问题，并对几种预测器进行了比较。</li>
<li>results: 研究发现，使用精度进行精心微调的RoBERTa模型在总体来说表现良好，但在cross-domain和cross-生成器设置下表现不佳，很容易过拟合数据中的假性质。然后，研究提出了基于冻结语言模型的嵌入特征的新方法，能够超过人类精度水平和先前考虑的基准值。此外，研究还采用了抽象率基于的方法来检测文本边界，并分析了这些方法的行为。<details>
<summary>Abstract</summary>
Due to the rapid development of text generation models, people increasingly often encounter texts that may start out as written by a human but then continue as machine-generated results of large language models. Detecting the boundary between human-written and machine-generated parts of such texts is a very challenging problem that has not received much attention in literature. In this work, we consider and compare a number of different approaches for this artificial text boundary detection problem, comparing several predictors over features of different nature. We show that supervised fine-tuning of the RoBERTa model works well for this task in general but fails to generalize in important cross-domain and cross-generator settings, demonstrating a tendency to overfit to spurious properties of the data. Then, we propose novel approaches based on features extracted from a frozen language model's embeddings that are able to outperform both the human accuracy level and previously considered baselines on the Real or Fake Text benchmark. Moreover, we adapt perplexity-based approaches for the boundary detection task and analyze their behaviour. We analyze the robustness of all proposed classifiers in cross-domain and cross-model settings, discovering important properties of the data that can negatively influence the performance of artificial text boundary detection algorithms.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, but some words and phrases may still be in Traditional Chinese, as there are no direct translations for some of the technical terms used in the text.)
</details></li>
</ul>
<hr>
<h2 id="MC-2-A-Multilingual-Corpus-of-Minority-Languages-in-China"><a href="#MC-2-A-Multilingual-Corpus-of-Minority-Languages-in-China" class="headerlink" title="MC^2: A Multilingual Corpus of Minority Languages in China"></a>MC^2: A Multilingual Corpus of Minority Languages in China</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08348">http://arxiv.org/abs/2311.08348</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luciusssss/mc2_corpus">https://github.com/luciusssss/mc2_corpus</a></li>
<li>paper_authors: Chen Zhang, Mingxu Tao, Quzhe Huang, Jiuheng Lin, Zhibin Chen, Yansong Feng</li>
<li>for: 提高中国少数民族语言的可访问性</li>
<li>methods: 采用质量中心的解决方案，优先保证数据的准确性和质量，同时提高语言表现的多样性和代表性</li>
<li>results: 实现了中国少数民族语言的大规模数据采集，探讨了这些语言的新研究挑战，如长文本处理和多种写作系统的结合<details>
<summary>Abstract</summary>
Large-scale corpora play a vital role in the construction of large language models (LLMs). However, existing LLMs exhibit limited abilities in understanding low-resource languages, including the minority languages in China, due to a lack of training data. To improve the accessibility of these languages, we present MC^2, a Multilingual Corpus of Minority Languages in China, which is the largest open-source corpus so far. It encompasses four underrepresented languages, i.e., Tibetan, Uyghur, Kazakh in the Kazakh Arabic script, and Mongolian in the traditional Mongolian script. Notably, two writing systems in MC^2 are long neglected in previous corpora. As we identify serious contamination in the low-resource language split in the existing multilingual corpora, we propose a quality-centric solution for collecting MC^2, prioritizing quality and accuracy while enhancing representativeness and diversity. By in-depth analysis, we demonstrate the new research challenges MC^2 brings, such as long-text modeling and multiplicity of writing systems. We hope MC^2 can help enhance the equity of the underrepresented languages in China and provide a reliable data foundation for further research on low-resource languages.
</details>
<details>
<summary>摘要</summary>
大规模 corpora 在大语言模型（LLM）的建构中发挥重要作用。然而，现有的 LLM 在理解低资源语言方面表现有限，包括中国少数民族语言，因为缺乏训练数据。为了提高这些语言的可访问性，我们提出 MC^2，一个多语言资料库，这是目前最大的开源资料库。它包括四种少数语言，即藏语、维吾尔语、哈萨克语（使用kazakh arabic字母）和蒙古语（使用传统蒙古字母）。值得注意的是， MC^2 中两种文字系统长期被前一些资料库忽略。在我们发现现有多语言资料库中低资源语言分区存在严重污染的问题后，我们提出了一种基于质量的解决方案，即在收集 MC^2 时，优先考虑质量和准确性，同时增强表现和多样性。通过深入分析，我们显示 MC^2 带来的新研究挑战，例如长文本模型和多种文字系统的复杂性。我们希望 MC^2 能够提高中国少数民族语言的平等，并为未来对低资源语言进行更多研究提供可靠的数据基础。
</details></li>
</ul>
<hr>
<h2 id="KTRL-F-Knowledge-Augmented-In-Document-Search"><a href="#KTRL-F-Knowledge-Augmented-In-Document-Search" class="headerlink" title="KTRL+F: Knowledge-Augmented In-Document Search"></a>KTRL+F: Knowledge-Augmented In-Document Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08329">http://arxiv.org/abs/2311.08329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanseokoh/ktrlf">https://github.com/hanseokoh/ktrlf</a></li>
<li>paper_authors: Hanseok Oh, Haebin Shin, Miyoung Ko, Hyunji Lee, Minjoon Seo</li>
<li>for: 这篇论文是为了解决一个新的问题KTRL+F，这是一个基于知识的在文档中搜索任务，需要在文档中实时找到所有semantic target，同时考虑外部知识来填充semantic gap。</li>
<li>methods: 论文使用了多种基eline来分析KTRL+F问题，并发现了现有模型存在一些局限性，如幻觉、响应时间较长、外部知识难以引入。因此，论文提出了一种知识增强的短语检索模型，可以在实时下提供一个平衡的性能和速度。</li>
<li>results: 论文通过用户研究发现，解决KTRL+F问题可以提高用户搜索体验，用户可以减少查询数量，并减少外部源查询次数。这表明，通过增强在文档中的信息访问，可以提高用户的搜索效率。<details>
<summary>Abstract</summary>
We introduce a new problem KTRL+F, a knowledge-augmented in-document search task that necessitates real-time identification of all semantic targets within a document with the awareness of external sources through a single natural query. This task addresses following unique challenges for in-document search: 1) utilizing knowledge outside the document for extended use of additional information about targets to bridge the semantic gap between the query and the targets, and 2) balancing between real-time applicability with the performance. We analyze various baselines in KTRL+F and find there are limitations of existing models, such as hallucinations, low latency, or difficulties in leveraging external knowledge. Therefore we propose a Knowledge-Augmented Phrase Retrieval model that shows a promising balance between speed and performance by simply augmenting external knowledge embedding in phrase embedding. Additionally, we conduct a user study to verify whether solving KTRL+F can enhance search experience of users. It demonstrates that even with our simple model users can reduce the time for searching with less queries and reduced extra visits to other sources for collecting evidence. We encourage the research community to work on KTRL+F to enhance more efficient in-document information access.
</details>
<details>
<summary>摘要</summary>
我们引入了一个新的问题KTRL+F，即具有知识扩展的在文档内搜索任务，需要在文档中实时识别所有 semantic 目标，并在单个自然语言查询中利用外部知识。这个任务面临着以下两个独特挑战：1）利用外部知识来延伸文档中的信息，以填补查询和目标之间的semantic gap，2）在实时应用中维护高性能。我们分析了KTRL+F的各种基eline，发现存在许多限制，如幻觉、低响应速度、或者Difficulty in leveraging external knowledge。因此，我们提议一种具有良好平衡的知识扩展短语检索模型，通过在短语嵌入中添加外部知识嵌入来实现。此外，我们进行了一次用户研究，以验证解决KTRL+F问题是否可以提高搜索用户的体验。结果表明，即使使用我们的简单模型，用户可以减少搜索时间，并避免了额外访问其他来源以收集证据。我们鼓励研究者继续开发KTRL+F，以提高更有效的文档内信息访问。
</details></li>
</ul>
<hr>
<h2 id="Open-vocabulary-keyword-spotting-in-any-language-through-multilingual-contrastive-speech-phoneme-pretraining"><a href="#Open-vocabulary-keyword-spotting-in-any-language-through-multilingual-contrastive-speech-phoneme-pretraining" class="headerlink" title="Open-vocabulary keyword spotting in any language through multilingual contrastive speech-phoneme pretraining"></a>Open-vocabulary keyword spotting in any language through multilingual contrastive speech-phoneme pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08323">http://arxiv.org/abs/2311.08323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Zhu, Farhan Samir, Changbing Yang, Jahurul Islam</li>
<li>for: 这篇论文旨在开发一个大规模多语言 speech  Corpora，包含超过 115 种语言，并提出一种多语言 phoneme-speech 对比 embedding 模型，能够在开放词汇中匹配 speech 信号和 phonemically 转录的关键词或自由文本。</li>
<li>methods: 该模型使用 fine-grained phonemic transcriptions 作为输入，并采用一种基于 contrastive learning 的训练方法，可以在 97 种语言中进行开放词汇匹配。</li>
<li>results: 对比文本模型，使用 phonemes 作为模型单元可以实现更好的 crosslinguistic 泛化性，并且在两个采集 speech  Corpora 中进行了证明。<details>
<summary>Abstract</summary>
In this paper, we introduce a massively multilingual speech corpora with fine-grained phonemic transcriptions, encompassing more than 115 languages from diverse language families. Based on this multilingual dataset, we propose CLAP-IPA, a multilingual phoneme-speech contrastive embedding model capable of open-vocabulary matching between speech signals and phonemically transcribed keywords or arbitrary phrases. The proposed model has been tested on two fieldwork speech corpora in 97 unseen languages, exhibiting strong generalizability across languages. Comparison with a text-based model shows that using phonemes as modeling units enables much better crosslinguistic generalization than orthographic texts.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一个大量多语言的语音 corpora，其包含了超过115种语言，从多种语言家族中选取。基于这个多语言数据集，我们提议了一种多语言phoneme-speech对比嵌入模型，能够在语音信号和phonemically转写的关键词或自由语phrases之间进行开放词汇匹配。我们对97种未看过语言的场景进行了测试，结果显示了模型在不同语言之间具有强大的泛化能力。与文本基于模型相比，使用phonemes作为模型单元可以实现跨语言泛化的更好的性能。
</details></li>
</ul>
<hr>
<h2 id="On-the-Fly-Fusion-of-Large-Language-Models-and-Machine-Translation"><a href="#On-the-Fly-Fusion-of-Large-Language-Models-and-Machine-Translation" class="headerlink" title="On-the-Fly Fusion of Large Language Models and Machine Translation"></a>On-the-Fly Fusion of Large Language Models and Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08306">http://arxiv.org/abs/2311.08306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hieu Hoang, Huda Khayrallah, Marcin Junczys-Dowmunt</li>
<li>for: 提高机器翻译模型的翻译质量</li>
<li>methods: 使用LLM进行在线折衔，并与NMT模型相互结合</li>
<li>results: 实验结果表明，使用LLM可以提高翻译质量，并且结合LLM和NMT模型的结合效果比两个 stronger MT模型的结合效果更好。<details>
<summary>Abstract</summary>
We propose the on-the-fly ensembling of a machine translation model with an LLM, prompted on the same task and input. We perform experiments on 4 language pairs (both directions) with varying data amounts. We find that a slightly weaker-at-translation LLM can improve translations of a NMT model, and ensembling with an LLM can produce better translations than ensembling two stronger MT models. We combine our method with various techniques from LLM prompting, such as in context learning and translation context.
</details>
<details>
<summary>摘要</summary>
我们提议在实时进行机器翻译模型与大语言模型（LLM）的 ensemble，两者在同一任务和输入下被触发。我们在4种语言对（双向）进行了实验，并调整了数据量。我们发现一些较弱的翻译LLM可以改善机器翻译模型的翻译结果，而ensemble两者可以生成更好的翻译结果，而且比 ensemble两个更强的机器翻译模型。我们将方法与LLM触发技术相结合，如在语言上学习和翻译上下文。
</details></li>
</ul>
<hr>
<h2 id="How-Well-Do-Large-Language-Models-Understand-Syntax-An-Evaluation-by-Asking-Natural-Language-Questions"><a href="#How-Well-Do-Large-Language-Models-Understand-Syntax-An-Evaluation-by-Asking-Natural-Language-Questions" class="headerlink" title="How Well Do Large Language Models Understand Syntax? An Evaluation by Asking Natural Language Questions"></a>How Well Do Large Language Models Understand Syntax? An Evaluation by Asking Natural Language Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08287">http://arxiv.org/abs/2311.08287</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jacob-Zhou/SynEval">https://github.com/Jacob-Zhou/SynEval</a></li>
<li>paper_authors: Houquan Zhou, Yang Hou, Zhenghua Li, Xuebin Wang, Zhefeng Wang, Xinyu Duan, Min Zhang</li>
<li>for: 本研究探讨了大语言模型（LLMs）真正理解语言的问题，是否仅仅通过模式识别来模拟理解。</li>
<li>methods: 本研究采用自然语言问答（Q&amp;A）方式，制定了九个句子理解知识点，这些知识点最直接关系到句子理解。</li>
<li>results: 实验结果表明，大多数LLMs在句子理解知识点上有限的掌握，尤其是在附属句子和副词修饰知识点上表现出较大的差异。<details>
<summary>Abstract</summary>
While recent advancements in large language models (LLMs) bring us closer to achieving artificial general intelligence, the question persists: Do LLMs truly understand language, or do they merely mimic comprehension through pattern recognition? This study seeks to explore this question through the lens of syntax, a crucial component of sentence comprehension. Adopting a natural language question-answering (Q&A) scheme, we craft questions targeting nine syntactic knowledge points that are most closely related to sentence comprehension. Experiments conducted on 24 LLMs suggest that most have a limited grasp of syntactic knowledge, exhibiting notable discrepancies across different syntactic knowledge points. In particular, questions involving prepositional phrase attachment pose the greatest challenge, whereas those concerning adjectival modifier and indirect object are relatively easier for LLMs to handle. Furthermore, a case study on the training dynamics of the LLMs reveals that the majority of syntactic knowledge is learned during the initial stages of training, hinting that simply increasing the number of training tokens may not be the `silver bullet' for improving the comprehension ability of LLMs.
</details>
<details>
<summary>摘要</summary>
Recent advancements in large language models (LLMs) have brought us closer to achieving artificial general intelligence, but the question remains: do LLMs truly understand language, or do they simply mimic comprehension through pattern recognition? This study aims to explore this question through the lens of syntax, a crucial component of sentence comprehension. Using a natural language question-answering (Q&A) scheme, we crafted questions targeting nine syntactic knowledge points that are most closely related to sentence comprehension. Our experiments on 24 LLMs suggest that most have a limited grasp of syntactic knowledge, with notable discrepancies across different syntactic knowledge points. In particular, questions involving prepositional phrase attachment posed the greatest challenge, while those concerning adjectival modifier and indirect object were relatively easier for LLMs to handle. Additionally, a case study on the training dynamics of the LLMs revealed that the majority of syntactic knowledge is learned during the initial stages of training, suggesting that simply increasing the number of training tokens may not be the "silver bullet" for improving the comprehension ability of LLMs.Note: Please keep in mind that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Examining-Modularity-in-Multilingual-LMs-via-Language-Specialized-Subnetworks"><a href="#Examining-Modularity-in-Multilingual-LMs-via-Language-Specialized-Subnetworks" class="headerlink" title="Examining Modularity in Multilingual LMs via Language-Specialized Subnetworks"></a>Examining Modularity in Multilingual LMs via Language-Specialized Subnetworks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08273">http://arxiv.org/abs/2311.08273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rochelle Choenni, Ekaterina Shutova, Dan Garrette</li>
<li>for: 本研究旨在 investigate multilingual language models中的语言层次结构和 Cross-Lingual Sharing 的关系。</li>
<li>methods: 研究使用 Training Data Attribution 方法来衡量模型的预测结果如何受到语言特有的训练示例和 Cross-Lingual Sharing 的影响。</li>
<li>results: 研究发现，无需特殊的模块化 intervención，语言模块 naturally arise 在模型中，并且 SFT 可以减少语言特化的子网络，导致更多的 Cross-Lingual Sharing。<details>
<summary>Abstract</summary>
Recent work has proposed explicitly inducing language-wise modularity in multilingual LMs via sparse fine-tuning (SFT) on per-language subnetworks as a means of better guiding cross-lingual sharing. In this work, we investigate (1) the degree to which language-wise modularity naturally arises within models with no special modularity interventions, and (2) how cross-lingual sharing and interference differ between such models and those with explicit SFT-guided subnetwork modularity. To quantify language specialization and cross-lingual interaction, we use a Training Data Attribution method that estimates the degree to which a model's predictions are influenced by in-language or cross-language training examples. Our results show that language-specialized subnetworks do naturally arise, and that SFT, rather than always increasing modularity, can decrease language specialization of subnetworks in favor of more cross-lingual sharing.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Wolf-in-Sheep’s-Clothing-Generalized-Nested-Jailbreak-Prompts-can-Fool-Large-Language-Models-Easily"><a href="#A-Wolf-in-Sheep’s-Clothing-Generalized-Nested-Jailbreak-Prompts-can-Fool-Large-Language-Models-Easily" class="headerlink" title="A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily"></a>A Wolf in Sheep’s Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08268">http://arxiv.org/abs/2311.08268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, Shujian Huang</li>
<li>for: 提高 Large Language Models（LLMs）的安全性和用户体验，防止 LLMs 生成危险内容。</li>
<li>methods: 基于 Prompt Rewriting 和 Scenario Nesting 的自动攻击框架 ReNeLLM，利用 LLMs 本身生成有效的监狱攻击提示。</li>
<li>results: 比对基eline的成本和时间成本，ReNeLLM 能够显著提高攻击成功率，同时大幅降低时间成本。研究还发现现有防御方法无法有效地保护 LLMs。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to provide useful and safe responses. However, adversarial prompts known as 'jailbreaks' can circumvent safeguards, leading LLMs to generate harmful content. Exploring jailbreak prompts can help to better reveal the weaknesses of LLMs and further steer us to secure them. Unfortunately, existing jailbreak methods either suffer from intricate manual design or require optimization on another white-box model, compromising generalization or jailbreak efficiency. In this paper, we generalize jailbreak prompt attacks into two aspects: (1) Prompt Rewriting and (2) Scenario Nesting. Based on this, we propose ReNeLLM, an automatic framework that leverages LLMs themselves to generate effective jailbreak prompts. Extensive experiments demonstrate that ReNeLLM significantly improves the attack success rate while greatly reducing the time cost compared to existing baselines. Our study also reveals the inadequacy of current defense methods in safeguarding LLMs. Finally, we offer detailed analysis and discussion from the perspective of prompt execution priority on the failure of LLMs' defense. We hope that our research can catalyze both the academic community and LLMs vendors towards the provision of safer and more regulated Large Language Models.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们将监狱提示攻击分为两个方面：(1) 提示重写和(2) enario Nesting。基于这两个方面，我们提出了一种自动化框架，即 ReNeLLM，可以利用 LLMs 本身来生成有效的监狱提示。我们的实验结果表明，ReNeLLM 可以明显提高攻击成功率，同时大幅降低了时间成本，相比现有的基elines。我们的研究还发现，现有的防御方法无法保护 LLMS。最后，我们提供了关于提示执行优先级的详细分析，并讨论 LLMS 的防御失败的原因。我们希望，我们的研究可以激发学术界和 LLMS 供应商，向更安全和更加规范的 Large Language Models 努力。
</details></li>
</ul>
<hr>
<h2 id="Fast-Chain-of-Thought-A-Glance-of-Future-from-Parallel-Decoding-Leads-to-Answers-Faster"><a href="#Fast-Chain-of-Thought-A-Glance-of-Future-from-Parallel-Decoding-Leads-to-Answers-Faster" class="headerlink" title="Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads to Answers Faster"></a>Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads to Answers Faster</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08263">http://arxiv.org/abs/2311.08263</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smart-life-tech/231118-082633-esp32dev">https://github.com/smart-life-tech/231118-082633-esp32dev</a></li>
<li>paper_authors: Hongxuan Zhang, Zhining Liu, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen</li>
<li>for: 这篇论文主要针对的是提高大型语言模型（LLM）的推理速度，以便在实时应用中更好地使用LLM。</li>
<li>methods: 该论文提出了一种名为FastCoT的框架，该框架基于平行解码，不需要 auxiliary model 或 LLM 的修改。 FastCoT 使用可变大小的上下文窗口，同时进行平行解码和自然语言处理，以便充分利用 GPU 计算资源。</li>
<li>results: 经过广泛的实验， authors 表明 FastCoT 可以将推理时间减少约 20%，只有微不足的性能下降。 此外， authors 还证明了上下文窗口大小在不同任务上具有较大的稳定性。<details>
<summary>Abstract</summary>
In this work, we propose FastCoT, a model-agnostic framework based on parallel decoding without any further training of an auxiliary model or modification to the LLM itself. FastCoT uses a size-varying context window whose size changes with position to conduct parallel decoding and auto-regressive decoding simultaneously, thus fully utilizing GPU computation resources. In FastCoT, the parallel decoding part provides the LLM with a quick glance of the future composed of approximate tokens, which could lead to faster answers compared to regular autoregressive decoding used by causal transformers. We also provide an implementation of parallel decoding within LLM, which supports KV-cache generation and batch processing. Through extensive experiments, we demonstrate that FastCoT saves inference time by nearly 20% with only a negligible performance drop compared to the regular approach. Additionally, we show that the context window size exhibits considerable robustness for different tasks.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了FastCoT，一个模型无关框架，不需要额外训练或 modify LLM 自身。FastCoT 使用变化大小的上下文窗口来同时进行平行解码和自然语言解码，因此可以完全利用 GPU 计算资源。在 FastCoT 中，平行解码部分为 LLM 提供了快速 glance 到未来组成的 approximate 字符，这可能会比常规autoregressive解码使用 causal transformer 更快。我们还提供了在 LLM 中实现平行解码的方法，支持 KV-cache 生成和批处理。经过广泛的实验，我们发现 FastCoT 可以将推理时间减少 nearly 20%，只有微scopic 性能下降。此外，我们还证明了上下文窗口大小在不同任务中具有显著的稳定性。
</details></li>
</ul>
<hr>
<h2 id="On-Using-Distribution-Based-Compositionality-Assessment-to-Evaluate-Compositional-Generalisation-in-Machine-Translation"><a href="#On-Using-Distribution-Based-Compositionality-Assessment-to-Evaluate-Compositional-Generalisation-in-Machine-Translation" class="headerlink" title="On Using Distribution-Based Compositionality Assessment to Evaluate Compositional Generalisation in Machine Translation"></a>On Using Distribution-Based Compositionality Assessment to Evaluate Compositional Generalisation in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08249">http://arxiv.org/abs/2311.08249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aalto-speech/dbca">https://github.com/aalto-speech/dbca</a></li>
<li>paper_authors: Anssi Moisio, Mathias Creutz, Mikko Kurimo</li>
<li>for: 这个论文的目的是开发一种可以评估自然语言处理系统中的compositional generalization（CG）能力的benchmark。</li>
<li>methods: 这个论文使用了分布基于的compositional assessment（DBCA）框架，将欧 parliament翻译 corpus分为训练和测试集，以测试翻译系统在不同的依赖关系分布下的性能。</li>
<li>results: 这个实验使用了自动化的分布分割方法，可以方便地应用于其他dataset和语言上。 Code和数据可以在<a target="_blank" rel="noopener" href="https://github.com/aalto-speech/dbca%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/aalto-speech/dbca上获取。</a><details>
<summary>Abstract</summary>
Compositional generalisation (CG), in NLP and in machine learning more generally, has been assessed mostly using artificial datasets. It is important to develop benchmarks to assess CG also in real-world natural language tasks in order to understand the abilities and limitations of systems deployed in the wild. To this end, our GenBench Collaborative Benchmarking Task submission utilises the distribution-based compositionality assessment (DBCA) framework to split the Europarl translation corpus into a training and a test set in such a way that the test set requires compositional generalisation capacity. Specifically, the training and test sets have divergent distributions of dependency relations, testing NMT systems' capability of translating dependencies that they have not been trained on. This is a fully-automated procedure to create natural language compositionality benchmarks, making it simple and inexpensive to apply it further to other datasets and languages. The code and data for the experiments is available at https://github.com/aalto-speech/dbca.
</details>
<details>
<summary>摘要</summary>
叙述总结（CG）在自然语言处理（NLP）和机器学习中通常通过人工生成的数据集进行评估。为了更好地理解部署在野的系统的能力和局限性，需要开发真实世界自然语言任务中的标准测试套件。为此，我们的GenBench Collaborative Benchmarking Task提交使用分布型compose-ibility评估（DBCA）框架，将欧 parliament翻译集分为训练和测试集，以便测试翻译系统对于它们没有受过训练的依赖关系的翻译能力。specifically，训练和测试集具有不同的依赖关系分布，测试翻译系统的compose-ibility。这是一种自动化的、简单便宜的方法，可以轻松应用于其他数据集和语言。相关代码和数据可以在https://github.com/aalto-speech/dbca上获取。
</details></li>
</ul>
<hr>
<h2 id="Unlock-the-Power-Competitive-Distillation-for-Multi-Modal-Large-Language-Models"><a href="#Unlock-the-Power-Competitive-Distillation-for-Multi-Modal-Large-Language-Models" class="headerlink" title="Unlock the Power: Competitive Distillation for Multi-Modal Large Language Models"></a>Unlock the Power: Competitive Distillation for Multi-Modal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08213">http://arxiv.org/abs/2311.08213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinwei Li, Li Lin, Shuai Wang, Chen Qian</li>
<li>for: 提高多模态LM的性能和泛化能力</li>
<li>methods: 使用竞争型多模态知识储存（CoMD）框架，包括多模态预训练和竞争式知识传递两个阶段</li>
<li>results: 实验结果表明，我们的知识传递方法可以持续提高学生模型的能力，并在零基eline设置下超越当前状态艺AE模型和其他强基eline。<details>
<summary>Abstract</summary>
Recently, multi-modal content generation has attracted lots of attention from researchers by investigating the utilization of visual instruction tuning based on large language models (LLMs). To enhance the performance and generalization ability of such LLMs, the practice of distilling knowledge from pretrained multi-modal models (a.k.a. teachers) to more compact multi-modal LLMs (students) has gained considerable interest. However, the prevailing paradigm of instructiontuning in multi-modal LLMs knowledge distillation is resource-intensive and unidirectional, neglecting the potential for mutual feedback between the student and teacher models. Thus, we propose an innovative Competitive Multi-modal Distillation framework (CoMD), which captures bidirectional feedback between teacher and student models and continually updates the multi-modal capabilities that the student model has learned. It comprises two stages: multi-modal pre-training and multi-modal competitive distillation. The first stage pre-trains the student model on a large number of filtered multi-modal datasets. The second stage facilitates a bidirectional knowledge transfer between the student and teacher models. Our experimental analysis of diverse datasets shows that our knowledge transfer method consistently improves the capabilities of the student model. Finally, the 7B-sized student model after four distillations surpassed the current state-of-the-art model LLaVA-13B on the ScienceQA and LLaVA Test dataset, also outperforms other strong baselines in the zero-shot setting.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本，与原文可能有些不同）近些年来，多Modal内容生成技术吸引了研究人员的广泛关注，通过基于大语言模型（LLM）的视觉指令调整来探索多Modal内容生成的可能性。为了提高多Modal LLMs的性能和泛化能力，卷积多Modal模型（teacher）到更加紧凑的多Modal LLMs（student）的知识抽象已经得到了广泛的关注。然而，现有的多Modal LLMs知识抽象方法通常是资源占用和单向的，忽略了学生和教师模型之间的可能的反馈。因此，我们提出了一种创新的竞争型多Modal抽象方法（CoMD），该方法通过双向反馈来捕捉学生和教师模型之间的知识交换。CoMD包括两个阶段：多Modal预训练和多Modal竞争抽象。第一阶段通过大量筛选的多Modal数据集进行学生模型的预训练。第二阶段通过双向知识传递来实现学生和教师模型之间的知识交换。我们对多个数据集进行了实验分析，表明我们的知识传递方法能够不断提高学生模型的能力。最终，我们的7B字模型经四次抽象后，超越了当前状态的艺术模型LLaVA-13B在科学问答和LLaVA测试集上的性能，同时也超越了其他强大的基线模型。
</details></li>
</ul>
<hr>
<h2 id="GEC-DePenD-Non-Autoregressive-Grammatical-Error-Correction-with-Decoupled-Permutation-and-Decoding"><a href="#GEC-DePenD-Non-Autoregressive-Grammatical-Error-Correction-with-Decoupled-Permutation-and-Decoding" class="headerlink" title="GEC-DePenD: Non-Autoregressive Grammatical Error Correction with Decoupled Permutation and Decoding"></a>GEC-DePenD: Non-Autoregressive Grammatical Error Correction with Decoupled Permutation and Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08191">http://arxiv.org/abs/2311.08191</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gibson210/gec-depend">https://github.com/gibson210/gec-depend</a></li>
<li>paper_authors: Konstantin Yakovlev, Alexander Podolskiy, Andrey Bout, Sergey Nikolenko, Irina Piontkovskaya</li>
<li>for: 这个论文的目的是提出一种新的非自然语言处理（NLP）任务，即句子重构（GEC）。</li>
<li>methods: 这个论文使用了一种新的非自然语言处理（NLP）方法，即句子重构（GEC）方法，该方法使用了一个卷积网络和一个排序网络来实现。</li>
<li>results: 这个论文的实验结果表明，该方法可以超过之前已知的非自然语言处理（NLP）方法，并达到自然语言处理（NLP）方法的水平，而不需要使用语言特定的数据生成方法。<details>
<summary>Abstract</summary>
Grammatical error correction (GEC) is an important NLP task that is currently usually solved with autoregressive sequence-to-sequence models. However, approaches of this class are inherently slow due to one-by-one token generation, so non-autoregressive alternatives are needed. In this work, we propose a novel non-autoregressive approach to GEC that decouples the architecture into a permutation network that outputs a self-attention weight matrix that can be used in beam search to find the best permutation of input tokens (with auxiliary {ins} tokens) and a decoder network based on a step-unrolled denoising autoencoder that fills in specific tokens. This allows us to find the token permutation after only one forward pass of the permutation network, avoiding autoregressive constructions. We show that the resulting network improves over previously known non-autoregressive methods for GEC and reaches the level of autoregressive methods that do not use language-specific synthetic data generation methods. Our results are supported by a comprehensive experimental validation on the ConLL-2014 and Write&Improve+LOCNESS datasets and an extensive ablation study that supports our architectural and algorithmic choices.
</details>
<details>
<summary>摘要</summary>
句子结构错误纠正（GEC）是一个重要的自然语言处理（NLP）任务，通常使用回归式序列到序列模型解决。然而，这类方法因为每个字符串生成一个 Token 的速度相对较慢，因此需要非回归式的替代方法。在这种工作中，我们提出了一种新的非回归式GEC方法，其拆分 Architecture 为一个卷积网络，该网络输出一个自注意力权重矩阵，可以在搜索 beam 中使用，以找到输入token的最佳 permutation（与辅助 {ins}  tokens）。此外，我们还使用一个基于步骤拆分的减噪自适应网络，填充特定的 Token。这样，我们可以在单一的前进 pass 中找到 permutation，无需使用回归式结构。我们的结果表明，该网络在 previously known 非回归式方法之上提高，并达到使用语言特定数据生成方法的 autoregressive 方法水平。我们的结果得到了 ConLL-2014 和 Write&Improve+LOCNESS 数据集的广泛实验 validate，以及一项详细的ablation study，支持我们的建筑和算法选择。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Science-Novel-Dataset-and-Benchmark-for-Cross-Modality-Scientific-Information-Extraction"><a href="#Unlocking-Science-Novel-Dataset-and-Benchmark-for-Cross-Modality-Scientific-Information-Extraction" class="headerlink" title="Unlocking Science: Novel Dataset and Benchmark for Cross-Modality Scientific Information Extraction"></a>Unlocking Science: Novel Dataset and Benchmark for Cross-Modality Scientific Information Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08189">http://arxiv.org/abs/2311.08189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Li, Jian Wu, Zhiwei Yu, Börje F. Karlsson, Wei Shen, Manabu Okumura, Chin-Yew Lin</li>
<li>for: 本研究的目的是提供一个 semi-supervised 标注管道，以便对科学论文中的信息进行抽象，并且可以跨 Modality 进行标注。</li>
<li>methods: 本研究使用了一个迭代式的标注管道，可以同时标注文本中的实体，以及表格中的实体和关系。</li>
<li>results: 根据本研究的结果，使用 semi-supervised 标注管道可以实现跨 Modality 的标注，并且可以提高IE模型的性能。此外，本研究还报告了使用 ChatGPT 大语言模型的现有性能。<details>
<summary>Abstract</summary>
Extracting key information from scientific papers has the potential to help researchers work more efficiently and accelerate the pace of scientific progress. Over the last few years, research on Scientific Information Extraction (SciIE) witnessed the release of several new systems and benchmarks. However, existing paper-focused datasets mostly focus only on specific parts of a manuscript (e.g., abstracts) and are single-modality (i.e., text- or table-only), due to complex processing and expensive annotations. Moreover, core information can be present in either text or tables or across both. To close this gap in data availability and enable cross-modality IE, while alleviating labeling costs, we propose a semi-supervised pipeline for annotating entities in text, as well as entities and relations in tables, in an iterative procedure. Based on this pipeline, we release novel resources for the scientific community, including a high-quality benchmark, a large-scale corpus, and a semi-supervised annotation pipeline. We further report the performance of state-of-the-art IE models on the proposed benchmark dataset, as a baseline. Lastly, we explore the potential capability of large language models such as ChatGPT for the current task. Our new dataset, results, and analysis validate the effectiveness and efficiency of our semi-supervised pipeline, and we discuss its remaining limitations.
</details>
<details>
<summary>摘要</summary>
科学文献提取有大量潜在的可能性，可以帮助研究人员更 efficiently 工作，并促进科学进步的速度。过去几年，科学信息提取（SciIE）的研究发展出了许多新系统和标准。然而，现有的论文集中的数据主要集中在特定部分（例如摘要），并且是单一的模式（文本或表格），这是因为处理复杂和昂贵的标注。此外，核心信息可能存在于文本中或表格中，或者在两者之间。为了填补这个数据不足和启用交叉模式的IE，我们提出了一个半supervised管道来标注文本中的实体，以及表格中的实体和关系。基于这个管道，我们发布了一个高质量的benchmark，一个大规模的 corpus，以及一个半supervised的标注管道。我们还报告了现有IE模型在我们的benchmark dataset上的性能，作为基eline。最后，我们探讨了使用大语言模型如ChatGPT进行当前任务的可能性。我们的新数据集、结果和分析证明了我们的半supervised管道的有效性和高效性，并讨论了剩下的限制。
</details></li>
</ul>
<hr>
<h2 id="Self-Evolved-Diverse-Data-Sampling-for-Efficient-Instruction-Tuning"><a href="#Self-Evolved-Diverse-Data-Sampling-for-Efficient-Instruction-Tuning" class="headerlink" title="Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning"></a>Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08182">http://arxiv.org/abs/2311.08182</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ofa-sys/diverseevol">https://github.com/ofa-sys/diverseevol</a></li>
<li>paper_authors: Shengguang Wu, Keming Lu, Benfeng Xu, Junyang Lin, Qi Su, Chang Zhou</li>
<li>for: 提高大语言模型（LLM）的指令遵循能力，尤其需要大量的指令调整数据。</li>
<li>methods: 我们提出了一种自动 sampler 机制，让模型自己选择最有优势的数据点，以提高其表现。</li>
<li>results: 我们在三个数据集和benchmark上进行了广泛的实验，发现我们的方法可以让模型在使用 less than 8% 的原始数据时保持或提高性能。<details>
<summary>Abstract</summary>
Enhancing the instruction-following ability of Large Language Models (LLMs) primarily demands substantial instruction-tuning datasets. However, the sheer volume of these imposes a considerable computational burden and annotation cost. To investigate a label-efficient instruction tuning method that allows the model itself to actively sample subsets that are equally or even more effective, we introduce a self-evolving mechanism DiverseEvol. In this process, a model iteratively augments its training subset to refine its own performance, without requiring any intervention from humans or more advanced LLMs. The key to our data sampling technique lies in the enhancement of diversity in the chosen subsets, as the model selects new data points most distinct from any existing ones according to its current embedding space. Extensive experiments across three datasets and benchmarks demonstrate the effectiveness of DiverseEvol. Our models, trained on less than 8% of the original dataset, maintain or improve performance compared with finetuning on full data. We also provide empirical evidence to analyze the importance of diversity in instruction data and the iterative scheme as opposed to one-time sampling. Our code is publicly available at https://github.com/OFA-Sys/DiverseEvol.git.
</details>
<details>
<summary>摘要</summary>
加强大语言模型（LLM）的指令遵从能力主要需要大量的指令调整数据。然而，这些数据的量却带来了较大的计算负担和标注成本。为了研究一种标签效率的指令调整方法，我们提出了一种自我演化机制——多样演化（DiverseEvol）。在这个过程中，模型会自动选择子集，以便在其当前的嵌入空间中进行进一步的调整。不需要人类或更高级的LLM的干预。我们的数据采样技术的关键在于在选择的子集中增加多样性，模型会选择新的数据点与现有的数据点最为不同，以便进一步提高自己的性能。我们在三个数据集和测试准则上进行了广泛的实验，结果表明多样演化可以很好地提高模型的性能。我们的模型，只使用原始数据的8%，可以保持或提高与全量数据的训练模型相同的性能。我们还提供了对多样性和迭代方案的分析，以及对一次采样的证明。我们的代码公开可用于https://github.com/OFA-Sys/DiverseEvol.git。
</details></li>
</ul>
<hr>
<h2 id="Towards-Reasoning-in-Large-Language-Models-via-Multi-Agent-Peer-Review-Collaboration"><a href="#Towards-Reasoning-in-Large-Language-Models-via-Multi-Agent-Peer-Review-Collaboration" class="headerlink" title="Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration"></a>Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08152">http://arxiv.org/abs/2311.08152</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hitsz-tmg/multi-agent-peer-review">https://github.com/hitsz-tmg/multi-agent-peer-review</a></li>
<li>paper_authors: Zhenran Xu, Senbao Shi, Baotian Hu, Jindi Yu, Dongfang Li, Min Zhang, Yuxiang Wu</li>
<li>for: 提高单个模型的推理能力，让模型能够更好地解决复杂的问题</li>
<li>methods: 引入多个模型协作，每个模型独立构建解决方案，对别的模型的解决方案提供评审，并将评审结果纳入自己的解决方案中</li>
<li>results: 在三种不同类型的推理任务上，与现有方法相比，协作方法在十个数据集中具有更高的准确率<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown remarkable capabilities in general natural language processing tasks but often fall short in complex reasoning tasks. Recent studies have explored human-like problem-solving strategies, such as self-correct, to push further the boundary of single-model reasoning ability. In this work, we let a single model "step outside the box" by engaging multiple models to correct each other. We introduce a multi-agent collaboration strategy that emulates the academic peer review process. Each agent independently constructs its own solution, provides reviews on the solutions of others, and assigns confidence levels to its reviews. Upon receiving peer reviews, agents revise their initial solutions. Extensive experiments on three different types of reasoning tasks show that our collaboration approach delivers superior accuracy across all ten datasets compared to existing methods. Further study demonstrates the effectiveness of integrating confidence in the reviews for math reasoning, and suggests a promising direction for human-mimicking multi-agent collaboration process.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理模型（LLM）在一般natural language processing任务中表现出众，但在复杂的推理任务中经常失落。最近的研究已经探索了人类化的问题解决策略，如自我修复，以推进单个模型的推理能力的边缘。在这项工作中，我们让单个模型“离开盒子”，通过多个模型相互纠正。我们提出了一种多代理协作策略，这种策略模仿了学术 peer review 过程。每个代理独立构建自己的解决方案，对他人的解决方案提供评估，并将对其评估的信任程度分配给自己的评估。接收 peer review 后，代理修改了初始的解决方案。我们在三种不同的推理任务上进行了广泛的实验，并证明了我们的协作方法在所有十个数据集上比现有方法更高的准确率。进一步的研究还表明了将信任纳入评估中的效果，并建议了人类化多代理协作过程的可能性。
</details></li>
</ul>
<hr>
<h2 id="Sinkhorn-Transformations-for-Single-Query-Postprocessing-in-Text-Video-Retrieval"><a href="#Sinkhorn-Transformations-for-Single-Query-Postprocessing-in-Text-Video-Retrieval" class="headerlink" title="Sinkhorn Transformations for Single-Query Postprocessing in Text-Video Retrieval"></a>Sinkhorn Transformations for Single-Query Postprocessing in Text-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08143">http://arxiv.org/abs/2311.08143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantin Yakovlev, Gregory Polyakov, Ilseyar Alimova, Alexander Podolskiy, Andrey Bout, Sergey Nikolenko, Irina Piontkovskaya</li>
<li>for: 这篇论文是关于多模态检索中的一种新趋势，即使用 dual-softmax loss (DSL) 进行后处理测试集结果。</li>
<li>methods: 本文提出了一种基于 Sinkhorn 变换的新后处理方法，并不需要对多个测试样本进行输入。</li>
<li>results: 我们的方法可以显著提高现有模型的效果，如 CLIP4Clip、BLIP、X-CLIP 和 DRL，并在多个标准文本-视频检索数据集上达到新的状态级。<details>
<summary>Abstract</summary>
A recent trend in multimodal retrieval is related to postprocessing test set results via the dual-softmax loss (DSL). While this approach can bring significant improvements, it usually presumes that an entire matrix of test samples is available as DSL input. This work introduces a new postprocessing approach based on Sinkhorn transformations that outperforms DSL. Further, we propose a new postprocessing setting that does not require access to multiple test queries. We show that our approach can significantly improve the results of state of the art models such as CLIP4Clip, BLIP, X-CLIP, and DRL, thus achieving a new state-of-the-art on several standard text-video retrieval datasets both with access to the entire test set and in the single-query setting.
</details>
<details>
<summary>摘要</summary>
Introduction:In recent years, there has been a growing trend in multimodal retrieval to use postprocessing techniques, such as the dual-softmax loss (DSL), to improve the performance of state-of-the-art models. However, these approaches typically require access to the entire test set, which can be limiting in practical applications. In this work, we propose a new postprocessing approach based on Sinkhorn transformations that outperforms DSL and does not require access to multiple test queries.Methodology:Our proposed approach uses Sinkhorn transformations to transform the test set into a more robust representation that can better capture the relationships between the text and video modalities. We show that this approach can significantly improve the results of state-of-the-art models such as CLIP4Clip, BLIP, X-CLIP, and DRL on several standard text-video retrieval datasets.Results:We evaluate our proposed approach on several standard text-video retrieval datasets, including the MSR-VTT dataset, the LSMDC dataset, and the MSVD dataset. Our results show that our approach can significantly improve the results of state-of-the-art models both with access to the entire test set and in the single-query setting. Specifically, we achieve a new state-of-the-art on the MSR-VTT dataset with a recall of 86.4% and a precision of 83.3%, and we achieve a new state-of-the-art on the LSMDC dataset with a recall of 84.3% and a precision of 81.3%.Conclusion:In this work, we proposed a new postprocessing approach based on Sinkhorn transformations that outperforms DSL and does not require access to multiple test queries. Our approach significantly improves the results of state-of-the-art models on several standard text-video retrieval datasets, both with access to the entire test set and in the single-query setting. We demonstrate the effectiveness of our approach and its potential for practical applications in multimodal retrieval.
</details></li>
</ul>
<hr>
<h2 id="Memory-efficient-Stochastic-methods-for-Memory-based-Transformers"><a href="#Memory-efficient-Stochastic-methods-for-Memory-based-Transformers" class="headerlink" title="Memory-efficient Stochastic methods for Memory-based Transformers"></a>Memory-efficient Stochastic methods for Memory-based Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08123">http://arxiv.org/abs/2311.08123</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vishwajit-vishnu/memory-efficient-stochastic-methods-for-memory-based-transformers">https://github.com/vishwajit-vishnu/memory-efficient-stochastic-methods-for-memory-based-transformers</a></li>
<li>paper_authors: Vishwajit Kumar Vishnu, C. Chandra Sekhar</li>
<li>for: 这个研究是为了提高记忆基于对称化器的训练效率，通常用于长距离上下文问题。</li>
<li>methods: 我们提出了一个新的两阶段训练机制和一个新的调整技术来改善记忆基于对称化器的训练效率。</li>
<li>results: 我们的结果显示，对称化器XL的基eline模型（Transformer-XL）在字元级语言模型任务上和相同的参数下表现与我们的结果模型（Skip Cross-head TransformerXL）相似，并在词元级语言模型任务上显示了约20% fewer参数下的表现。我们的提案方法不需要任何额外的记忆。此外，我们还证明了我们的调整机制在BERT上显示了相似的表现，并在多个GLUE任务上显示了约30%的标准差减少。<details>
<summary>Abstract</summary>
Training Memory-based transformers can require a large amount of memory and can be quite inefficient. We propose a novel two-phase training mechanism and a novel regularization technique to improve the training efficiency of memory-based transformers, which are often used for long-range context problems. For our experiments, we consider transformer-XL as our baseline model which is one of memorybased transformer models. We show that our resultant model, Skip Cross-head TransformerXL, outperforms the baseline on character level language modeling task with similar parameters and outperforms the baseline on word level language modelling task with almost 20% fewer parameters. Our proposed methods do not require any additional memory. We also demonstrate the effectiveness of our regularization mechanism on BERT which shows similar performance with reduction in standard deviation of scores of around 30% on multiple GLUE tasks.
</details>
<details>
<summary>摘要</summary>
训练基于记忆的变换器可能需要很大的内存并且可能不够效率。我们提出了一种新的两阶段训练机制和一种新的常见化技术来改善基于记忆的变换器的训练效率，这些变换器通常用于长距离上下文问题。在我们的实验中，我们选择了 transformer-XL 作为我们的基线模型，它是一种基于记忆的变换器模型。我们显示了我们的结果模型 Skip Cross-head TransformerXL 在字符级语言模型任务上与基eline模型具有相同的参数时表现更好，并在单词级语言模型任务上与基eline模型减少约20%的参数表现更好。我们的提议方法不需要额外的内存。我们还证明了我们的常见化机制在 BERT 上表现良好，其在多个 GLUE 任务上降低了标准差分布的分数的比例约30%。
</details></li>
</ul>
<hr>
<h2 id="Insights-into-Classifying-and-Mitigating-LLMs’-Hallucinations"><a href="#Insights-into-Classifying-and-Mitigating-LLMs’-Hallucinations" class="headerlink" title="Insights into Classifying and Mitigating LLMs’ Hallucinations"></a>Insights into Classifying and Mitigating LLMs’ Hallucinations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08117">http://arxiv.org/abs/2311.08117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Bruno, Pier Luigi Mazzeo, Aladine Chetouani, Marouane Tliba, Mohamed Amine Kerkouri</li>
<li>for: 本研究旨在探讨人工智能中的幻觉现象，以及它对人工智能的影响。</li>
<li>methods: 本研究使用了多种方法，包括机器翻译、问答系统、对话系统、概要系统、知识图与LLMs等。</li>
<li>results: 研究发现，幻觉现象可能导致人工智能生成的文本中出现false或误导性信息。此外，还提出了一些缓解幻觉的可能性，以提高LLMs的可靠性。<details>
<summary>Abstract</summary>
The widespread adoption of large language models (LLMs) across diverse AI applications is proof of the outstanding achievements obtained in several tasks, such as text mining, text generation, and question answering. However, LLMs are not exempt from drawbacks. One of the most concerning aspects regards the emerging problematic phenomena known as "Hallucinations". They manifest in text generation systems, particularly in question-answering systems reliant on LLMs, potentially resulting in false or misleading information propagation. This paper delves into the underlying causes of AI hallucination and elucidates its significance in artificial intelligence. In particular, Hallucination classification is tackled over several tasks (Machine Translation, Question and Answer, Dialog Systems, Summarisation Systems, Knowledge Graph with LLMs, and Visual Question Answer). Additionally, we explore potential strategies to mitigate hallucinations, aiming to enhance the overall reliability of LLMs. Our research addresses this critical issue within the HeReFaNMi (Health-Related Fake News Mitigation) project, generously supported by NGI Search, dedicated to combating Health-Related Fake News dissemination on the Internet. This endeavour represents a concerted effort to safeguard the integrity of information dissemination in an age of evolving AI technologies.
</details>
<details>
<summary>摘要</summary>
大量的大语言模型（LLM）在多种人工智能应用中的普及，证明了它们在文本挖掘、文本生成和问答等任务中的出色表现。然而，LLM并不免于缺点。其中一个最引起关注的问题是“幻觉”（Hallucination）。这种现象在基于LLM的文本生成系统中出现，特别是在问答系统中，可能导致 false或误导的信息传播。这篇论文探讨了幻觉的下面原因，并解释了它在人工智能中的重要性。具体来说，我们在Machine Translation、问答、对话系统、概要系统、知识图与LLM等任务中进行幻觉分类。此外，我们还探讨了可能的缓解幻觉的策略，以提高LLM的总可靠性。我们的研究是在HeReFaNMi（健康相关假新闻 Mitigation）项目中进行的，该项目是由NGI Search支持的，旨在在互联网上防茧健康相关假新闻的传播。这是一项共同努力，旨在保护信息传播的integrity在人工智能技术的发展过程中。
</details></li>
</ul>
<hr>
<h2 id="Improving-hateful-memes-detection-via-learning-hatefulness-aware-embedding-space-through-retrieval-guided-contrastive-learning"><a href="#Improving-hateful-memes-detection-via-learning-hatefulness-aware-embedding-space-through-retrieval-guided-contrastive-learning" class="headerlink" title="Improving hateful memes detection via learning hatefulness-aware embedding space through retrieval-guided contrastive learning"></a>Improving hateful memes detection via learning hatefulness-aware embedding space through retrieval-guided contrastive learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08110">http://arxiv.org/abs/2311.08110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingbiao Mei, Jinghong Chen, Weizhe Lin, Bill Byrne, Marcus Tomalin</li>
<li>for: 检测仇恨推文（hateful memes）</li>
<li>methods: 利用重现导向的对比训练构建倾向感知 embedding 空间（retrieval-guided contrastive training）</li>
<li>results: 在 hateMemes 数据集上达到了状态码（AUROC）86.7，超过了大型多Modal Model（Flamingo 和 LLaVA）的表现，并实现了基于数据库中未见过的数据进行仇恨推文检测的功能。<details>
<summary>Abstract</summary>
Hateful memes have emerged as a significant concern on the Internet. These memes, which are a combination of image and text, often convey messages vastly different from their individual meanings. Thus, detecting hateful memes requires the system to jointly understand the visual and textual modalities. However, our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. To address this issue, we propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Specifically, we add an auxiliary loss that utilizes hard negative and pseudo-gold samples to train the embedding space. Our approach achieves state-of-the-art performance on the HatefulMemes dataset with an AUROC of 86.7. Notably, our approach outperforms much larger fine-tuned Large Multimodal Models like Flamingo and LLaVA. Finally, we demonstrate a retrieval-based hateful memes detection system, which is capable of making hatefulness classification based on data unseen in training from a database. This allows developers to update the hateful memes detection system by simply adding new data without retraining, a desirable feature for real services in the constantly-evolving landscape of hateful memes on the Internet.
</details>
<details>
<summary>摘要</summary>
仇恨的 мемы在互联网上成为了一个重要的问题。这些 мемы 是一种 combining 图像和文本的形式，通常会传递出与其个别意义不同的信息。因此，检测仇恨的 мемы 需要系统能够同时理解图像和文本的modalities。然而，我们的调查发现，现有的 CLIP-based 系统的 embedding 空间缺乏对微妙的变化在 мемы 中的敏感性，这是正确地分类仇恨的关键。为解决这个问题，我们提议通过Retrieval-guided contrastive 训练构建一个仇恨意识的 embedding 空间。具体来说，我们添加了一个 auxiliary 损失函数，使用硬negative和 pseudo-gold 样本来训练 embedding 空间。我们的方法在 HatefulMemes 数据集上达到了状态的最佳性能，AUROC 为 86.7。特别是，我们的方法超过了大型 Fine-tuned Large Multimodal Models like Flamingo 和 LLaVA。 finally，我们展示了一个基于 Retrieval 的仇恨 memes 检测系统，可以通过添加新数据来更新系统，而不需要重新训练，这是一个 Desirable 的特点 для实际服务在互联网上的constantly-evolving 环境中。
</details></li>
</ul>
<hr>
<h2 id="SAIE-Framework-Support-Alone-Isn’t-Enough-–-Advancing-LLM-Training-with-Adversarial-Remarks"><a href="#SAIE-Framework-Support-Alone-Isn’t-Enough-–-Advancing-LLM-Training-with-Adversarial-Remarks" class="headerlink" title="SAIE Framework: Support Alone Isn’t Enough – Advancing LLM Training with Adversarial Remarks"></a>SAIE Framework: Support Alone Isn’t Enough – Advancing LLM Training with Adversarial Remarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08107">http://arxiv.org/abs/2311.08107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengsay Loem, Masahiro Kaneko, Naoaki Okazaki</li>
<li>for: 提高模型对实例的理解和推理能力</li>
<li>methods: 使用支持和对抗对话方法进行培训</li>
<li>results: 模型在多种数据集上表现出色，并且在多代理推理场景中表现出更高的推理能力<details>
<summary>Abstract</summary>
Large Language Models (LLMs) can justify or criticize their predictions through discussion with other models or humans, thereby enhancing their intrinsic understanding of instances. While proactive discussions enhance performance, this approach is currently limited to the inference phase. In this context, we posit a hypothesis: learning interactive discussions during training can improve understanding for the instances in the training step and proficiency in logical/critical thinking ability and verbalized expression of the model in the inference step. Our proposed SAIE training method involves both supportive and adversarial discussions between the learner and partner models. The learner model receives a remark from the partner through the discussion, and the parameters of the learner model are then updated based on this remark. That is, the teacher signal dynamically adjusts in response to the evolving model output throughout the training step. By bolstering the capacity for discussion and comprehension of instances, our experiments across datasets, including GSM8K, CommonsenseQA, and MMLU, reveal that models fine-tuned with our method consistently surpass those trained with standard fine-tuning techniques. Moreover, our approach demonstrates superior performance in multi-agent inference scenarios, boosting the models' reasoning abilities at the inference step.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:大型语言模型（LLM）可以通过与其他模型或人类的交流来提高它们的实例理解能力。而积极的交流可以在推理阶段提高性能，我们提出一个假设：在训练阶段学习交流可以提高实例理解和逻辑推理能力。我们的SAIE训练方法包括支持和对抗交流，学习者模型从合作伙伴获得反馈，并根据这个反馈更新学习者模型的参数。我们的实验结果显示，使用我们的方法训练的模型在GSM8K、CommonSenseQA和MMLU等数据集上 consistently 超越标准训练技术。此外，我们的方法也在多代推理enario中表现出色，提高模型在推理阶段的推理能力。
</details></li>
</ul>
<hr>
<h2 id="Carpe-Diem-On-the-Evaluation-of-World-Knowledge-in-Lifelong-Language-Models"><a href="#Carpe-Diem-On-the-Evaluation-of-World-Knowledge-in-Lifelong-Language-Models" class="headerlink" title="Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language Models"></a>Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08106">http://arxiv.org/abs/2311.08106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujin Kim, Jaehong Yoon, Seonghyeon Ye, Sung Ju Hwang, Se-young Yun</li>
<li>for: 本研究旨在 Addressing the challenges of language models acquiring and updating outdated knowledge in an ever-evolving world.</li>
<li>methods: 我们提出了一个 temporally evolving question answering benchmark，即 EvolvingQA，用于训练和评估语言模型在不断发展的Wikipedia数据库上。我们的benchmark包括问答作为下游任务，以模拟实际应用场景。</li>
<li>results: 我们发现，现有的连续学习基elines有困难在更新和忘记过时知识。我们的发现表明，模型在学习更新知识时收到的权重 gradients 太小，导致模型困难学习新知识。此外，我们发现模型在提供数字或时间类问题的答案时尤其困难。<details>
<summary>Abstract</summary>
In an ever-evolving world, the dynamic nature of knowledge presents challenges for language models that are trained on static data, leading to outdated encoded information. However, real-world scenarios require models not only to acquire new knowledge but also to overwrite outdated information into updated ones. To address this under-explored issue, we introduce the temporally evolving question answering benchmark, EvolvingQA - a novel benchmark designed for training and evaluating LMs on an evolving Wikipedia database, where the construction of our benchmark is automated with our pipeline using large language models. Our benchmark incorporates question-answering as a downstream task to emulate real-world applications. Through EvolvingQA, we uncover that existing continual learning baselines have difficulty in updating and forgetting outdated knowledge. Our findings suggest that the models fail to learn updated knowledge due to the small weight gradient. Furthermore, we elucidate that the models struggle mostly on providing numerical or temporal answers to questions asking for updated knowledge. Our work aims to model the dynamic nature of real-world information, offering a robust measure for the evolution-adaptability of language models.
</details>
<details>
<summary>摘要</summary>
在一个不断演化的世界中，知识的动态性对语言模型来说是一个挑战，因为这些模型通常被训练在静态数据上，导致编码的信息变得过时。然而，现实生活中的应用需要模型不仅学习新知识，还要将过时的信息更新为最新的一。为解决这一未曾被探讨的问题，我们提出了时间演化问答标准 benchmark，即 EvolvingQA，这是一个基于自动化pipeline和大语言模型的新 benchmark，用于训练和评估语言模型在不断演化的Wikipedia数据库中。我们的benchmark将问答作为下游任务，以模拟实际应用场景。通过EvolvingQA，我们发现了现有的连续学习基线在更新和忘记过时知识方面存在困难。我们的发现表明，模型在小权重Gradient下难以学习更新的知识。此外，我们发现模型在提供 numerical或时间相关的答案时存在困难。我们的工作旨在模拟现实世界中的信息动态性，为语言模型的演化能力提供一种可靠的测试方法。
</details></li>
</ul>
<hr>
<h2 id="DiLoCo-Distributed-Low-Communication-Training-of-Language-Models"><a href="#DiLoCo-Distributed-Low-Communication-Training-of-Language-Models" class="headerlink" title="DiLoCo: Distributed Low-Communication Training of Language Models"></a>DiLoCo: Distributed Low-Communication Training of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08105">http://arxiv.org/abs/2311.08105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arthur Douillard, Qixuan Feng, Andrei A. Rusu, Rachita Chhaparia, Yani Donchev, Adhiguna Kuncoro, Marc’Aurelio Ranzato, Arthur Szlam, Jiajun Shen</li>
<li>for: 这篇论文的目的是提出一种分布式优化算法，以便在各个设备之间训练大型自然语言处理模型。</li>
<li>methods: 该算法基于联邦平均化，并使用了AdamW内部优化器和Nesterov差动外部优化器。</li>
<li>results: 在广泛使用的C4数据集上，DiLoCo在8个工作者上表现和完全同步优化相当，但是对于通信量减少500倍。DiLoCo具有良好的数据分布robustness，同时也具有资源不可用和可用的robustness。<details>
<summary>Abstract</summary>
Large language models (LLM) have become a critical component in many applications of machine learning. However, standard approaches to training LLM require a large number of tightly interconnected accelerators, with devices exchanging gradients and other intermediate states at each optimization step. While it is difficult to build and maintain a single computing cluster hosting many accelerators, it might be easier to find several computing clusters each hosting a smaller number of devices. In this work, we propose a distributed optimization algorithm, Distributed Low-Communication (DiLoCo), that enables training of language models on islands of devices that are poorly connected. The approach is a variant of federated averaging, where the number of inner steps is large, the inner optimizer is AdamW, and the outer optimizer is Nesterov momentum. On the widely used C4 dataset, we show that DiLoCo on 8 workers performs as well as fully synchronous optimization while communicating 500 times less. DiLoCo exhibits great robustness to the data distribution of each worker. It is also robust to resources becoming unavailable over time, and vice versa, it can seamlessly leverage resources that become available during training.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a distributed optimization algorithm called Distributed Low-Communication (DiLoCo). This algorithm enables training of language models on islands of devices that are poorly connected. Our approach is based on federated averaging, but with a large number of inner steps, an AdamW inner optimizer, and a Nesterov momentum outer optimizer.We tested DiLoCo on the widely used C4 dataset with 8 workers, and found that it performs as well as fully synchronous optimization while communicating 500 times less. Additionally, DiLoCo is robust to the data distribution of each worker, and can seamlessly leverage resources that become available during training. It is also robust to resources becoming unavailable over time.In summary, DiLoCo is a distributed optimization algorithm that enables training of language models on islands of devices with low communication overhead. It is robust to variations in data distribution and resources, and can seamlessly leverage available resources during training.
</details></li>
</ul>
<hr>
<h2 id="Align-after-Pre-train-Improving-Multilingual-Generative-Models-with-Cross-lingual-Alignment"><a href="#Align-after-Pre-train-Improving-Multilingual-Generative-Models-with-Cross-lingual-Alignment" class="headerlink" title="Align after Pre-train: Improving Multilingual Generative Models with Cross-lingual Alignment"></a>Align after Pre-train: Improving Multilingual Generative Models with Cross-lingual Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08089">http://arxiv.org/abs/2311.08089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong Li, Shaonan Wang, Jiajun Zhang, Chengqing Zong</li>
<li>for: 提高多语言生成模型的跨语言能力</li>
<li>methods: 利用翻译句子对进行对internal sentence representations的对接和模型输出的对接，通过多语言对比学习实现对接</li>
<li>results: even with less than 0.1% of pre-training tokens, the alignment framework significantly improves the cross-lingual abilities of generative models and mitigates the performance gap, and results in a better internal multilingual representation distribution of multilingual models.<details>
<summary>Abstract</summary>
Multilingual generative models obtain remarkable cross-lingual capabilities through pre-training on large-scale corpora. However, they still exhibit a performance bias toward high-resource languages, and learn isolated distributions of sentence representations across languages. To bridge this gap, we propose a simple yet effective alignment framework exploiting pairs of translation sentences. It aligns the internal sentence representations across different languages via multilingual contrastive learning and aligns model outputs by answering prompts in different languages. Experimental results demonstrate that even with less than 0.1 {\textperthousand} of pre-training tokens, our alignment framework significantly boosts the cross-lingual abilities of generative models and mitigates the performance gap. Further analysis reveals that it results in a better internal multilingual representation distribution of multilingual models.
</details>
<details>
<summary>摘要</summary>
这文本将被翻译为简化中文。<</SYS>>多语言生成模型在大规模资料体上进行预训练后展现出卓越的跨语言能力，但 ainda 表现出语言高质量语言的偏好，并学习不同语言之间的隔离分布。为了 bridging 这个差距，我们提出了一个简单 yet effective 的对齐框架，利用翻译句子的对组。这个框架通过多ilingual contrastive learning 对内部句子表现进行对齐，并通过Answering 不同语言的提示来对外部输出进行对齐。实验结果显示，即使使用少于 0.1 个预训 tokens，我们的对齐框架可以帮助生成模型提高跨语言能力，并减少表现差距。进一步的分析显示，它导致多语言模型的内部多语言表现分布得到改善。
</details></li>
</ul>
<hr>
<h2 id="Data-and-models-for-stance-and-premise-detection-in-COVID-19-tweets-insights-from-the-Social-Media-Mining-for-Health-SMM4H-2022-shared-task"><a href="#Data-and-models-for-stance-and-premise-detection-in-COVID-19-tweets-insights-from-the-Social-Media-Mining-for-Health-SMM4H-2022-shared-task" class="headerlink" title="Data and models for stance and premise detection in COVID-19 tweets: insights from the Social Media Mining for Health (SMM4H) 2022 shared task"></a>Data and models for stance and premise detection in COVID-19 tweets: insights from the Social Media Mining for Health (SMM4H) 2022 shared task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08057">http://arxiv.org/abs/2311.08057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vera Davydova, Huabin Yang, Elena Tutubalina</li>
<li>for: 本研究的目的是为了评估神经网络模型在健康领域的意见检测和理据分类方面的性能。</li>
<li>methods: 本研究使用了 manually annotated tweets 来评估模型的性能，并采用了 feature-level (early)  fusion 和 dual-view 架构来增强模型的准确性。</li>
<li>results: 研究通过使用新收集的 Twitter 数据来评估模型在不同话题上的性能，并发现模型在这些话题上的性能有所不同。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has sparked numerous discussions on social media platforms, with users sharing their views on topics such as mask-wearing and vaccination. To facilitate the evaluation of neural models for stance detection and premise classification, we organized the Social Media Mining for Health (SMM4H) 2022 Shared Task 2. This competition utilized manually annotated posts on three COVID-19-related topics: school closures, stay-at-home orders, and wearing masks. In this paper, we extend the previous work and present newly collected data on vaccination from Twitter to assess the performance of models on a different topic. To enhance the accuracy and effectiveness of our evaluation, we employed various strategies to aggregate tweet texts with claims, including models with feature-level (early) fusion and dual-view architectures from SMM4H 2022 leaderboard. Our primary objective was to create a valuable dataset and perform an extensive experimental evaluation to support future research in argument mining in the health domain.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行引发了社交媒体平台上的讨论，用户分享他们对于面Mask-wearing和疫苗接种的看法。为了评估神经网络模型的立场检测和前提分类能力，我们组织了2022年社会媒体挖掘 для健康（SMM4H）的共同任务2。这项竞赛使用了手动注释的帖子，涵盖了三个COVID-19相关的话题：学校关闭、困在家中和Mask-wearing。在这篇文章中，我们对先前的工作进行了扩展，并提供了新收集的Twitter上的疫苗接种话题的数据来评估模型的性能。为了提高评估的准确性和有效性，我们采用了多种策略，包括在Feature-level（早期）融合和双视体系中使用SMM4H 2022 leaderboard上的模型。我们的主要目标是创造一个有价值的数据集，并进行了广泛的实验评估，以支持未来健康领域的论点挖掘研究。
</details></li>
</ul>
<hr>
<h2 id="Forgetting-before-Learning-Utilizing-Parametric-Arithmetic-for-Knowledge-Updating-in-Large-Language-Models"><a href="#Forgetting-before-Learning-Utilizing-Parametric-Arithmetic-for-Knowledge-Updating-in-Large-Language-Models" class="headerlink" title="Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models"></a>Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08011">http://arxiv.org/abs/2311.08011</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiwen Ni, Dingwei Chen, Chengming Li, Xiping Hu, Ruifeng Xu, Min Yang</li>
<li>for: 提高语言模型对新知识的更新能力</li>
<li>methods: 基于 Parametric Arithmetic 的 Forgetting before Learning 方法</li>
<li>results: 对两个公共可用的数据集进行实验，结果显示我们提议的 F-Learning 可以显著提高语言模型对新知识的更新性能，而且在一定情况下，减少 LoRA 参数也可以达到类似的效果，甚至在一些情况下超越全 Fine-tuning。<details>
<summary>Abstract</summary>
Recently Large Language Models (LLMs) have demonstrated their amazing text understanding and generation capabilities. However, even stronger LLMs may still learn incorrect knowledge from the training corpus, as well as some knowledge that is outdated over time. Direct secondary fine-tuning with data containing new knowledge may be ineffective in updating knowledge due to the conflict between old and new knowledge. In this paper, we propose a new paradigm for fine-tuning called F-Learning (Forgetting before Learning), which is based on parametric arithmetic to achieve forgetting of old knowledge and learning of new knowledge. Experimental results on two publicly available datasets demonstrate that our proposed F-Learning can obviously improve the knowledge updating performance of both full fine-tuning and LoRA fine-tuning. Moreover, we have also discovered that forgetting old knowledge by subtracting the parameters of LoRA can achieve a similar effect to subtracting the parameters of full fine-tuning, and sometimes even surpass it significantly.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Comparative-Analysis-of-the-COVID-19-Infodemic-in-English-and-Chinese-Insights-from-Social-Media-Textual-Data"><a href="#A-Comparative-Analysis-of-the-COVID-19-Infodemic-in-English-and-Chinese-Insights-from-Social-Media-Textual-Data" class="headerlink" title="A Comparative Analysis of the COVID-19 Infodemic in English and Chinese: Insights from Social Media Textual Data"></a>A Comparative Analysis of the COVID-19 Infodemic in English and Chinese: Insights from Social Media Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08001">http://arxiv.org/abs/2311.08001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia Luo, Daiyun Peng, Lei Shi, Didier El Baz, Xinran Liu</li>
<li>for: 本研究探讨了COVID-19信息 Overflow 在英语和中文语言上的比较分析，通过社交媒体平台上的文本数据进行了词频分析和主题划分分析，以及情感分析，以便更好地理解COVID-19信息 Overflow 的特点和特征。</li>
<li>methods: 本研究使用了社交媒体平台上的文本数据，通过词频分析、主题划分分析和情感分析来探讨COVID-19信息 Overflow 的特点和特征。</li>
<li>results: 本研究发现，COVID-19信息 Overflow 中最常出现的 thirty-five 个词语，可以帮助我们理解COVID-19信息 Overflow 中的主要话题和趋势，同时，情感分析也能够帮助我们理解社交媒体上COVID-19信息 Overflow 的情感特征。<details>
<summary>Abstract</summary>
The COVID-19 infodemic, characterized by the rapid spread of misinformation and unverified claims related to the pandemic, presents a significant challenge. This paper presents a comparative analysis of the COVID-19 infodemic in the English and Chinese languages, utilizing textual data extracted from social media platforms. To ensure a balanced representation, two infodemic datasets were created by augmenting previously collected social media textual data. Through word frequency analysis, the thirty-five most frequently occurring infodemic words are identified, shedding light on prevalent discussions surrounding the infodemic. Moreover, topic clustering analysis uncovers thematic structures and provides a deeper understanding of primary topics within each language context. Additionally, sentiment analysis enables comprehension of the emotional tone associated with COVID-19 information on social media platforms in English and Chinese. This research contributes to a better understanding of the COVID-19 infodemic phenomenon and can guide the development of strategies to combat misinformation during public health crises across different languages.
</details>
<details>
<summary>摘要</summary>
COVID-19信息暴发，表现为快速传播谣言和未经证实的疫情相关宣传，呈现了一项重要挑战。本文通过对英语和中文社交媒体文本数据进行比较分析，探讨COVID-19信息暴发的特点和特征。为保证数据的准确性和 representativeness，本文创建了两个infodemic数据集，通过文本数据的扩充来增强先前收集的社交媒体数据。通过字词频分析，本文发现了35个最常出现的infodemic词语，这些词语反映了社交媒体上COVID-19信息暴发的主要话题和讨论。此外，主题归一分析揭示了每种语言上COVID-19信息暴发的主要话题结构，提供了更深入的理解。此外，情感分析帮助了我们理解社交媒体上COVID-19信息的情感色彩，以及不同语言上的情感差异。本研究对COVID-19信息暴发现象的理解做出了贡献，可以导向公共卫生危机期间抗击谣言的开发。
</details></li>
</ul>
<hr>
<h2 id="How-Well-Do-Text-Embedding-Models-Understand-Syntax"><a href="#How-Well-Do-Text-Embedding-Models-Understand-Syntax" class="headerlink" title="How Well Do Text Embedding Models Understand Syntax?"></a>How Well Do Text Embedding Models Understand Syntax?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07996">http://arxiv.org/abs/2311.07996</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fzp0424/sr">https://github.com/fzp0424/sr</a></li>
<li>paper_authors: Yan Zhang, Zhaopeng Feng, Zhiyang Teng, Zuozhu Liu, Haizhou Li</li>
<li>for: 本研究旨在探讨文本嵌入模型在不同语法上的普适性，以及previous研究所不充分考虑的语法理解挑战。</li>
<li>methods: 我们首先开发了一个评估集，名为SR，以测试文本嵌入模型对语法理解的能力。SR包括两个重要的语法方面：结构规则和概念之间关系的理解。我们发现现有的文本嵌入模型尚未充分解决这两个语法理解挑战，并且在评估 dataset 上表现不佳。</li>
<li>results: 我们的发现表明，现有的文本嵌入模型在不同语法上的普适性尚未得到足够的改进，而且在评估 dataset 上的表现越来越不佳。此外，我们进行了严格的分析，探讨导致这种局限性的因素，以及previous研究所无法探测这种局限性的原因。最后，我们提出了增强文本嵌入模型在多种语法上的普适性的策略。本研究为语法理解挑战提供了实际的指导，以便在多种语法上提高模型的性能。<details>
<summary>Abstract</summary>
Text embedding models have significantly contributed to advancements in natural language processing by adeptly capturing semantic properties of textual data. However, the ability of these models to generalize across a wide range of syntactic contexts remains under-explored. In this paper, we first develop an evaluation set, named \textbf{SR}, to scrutinize the capability for syntax understanding of text embedding models from two crucial syntactic aspects: Structural heuristics, and Relational understanding among concepts, as revealed by the performance gaps in previous studies. Our findings reveal that existing text embedding models have not sufficiently addressed these syntactic understanding challenges, and such ineffectiveness becomes even more apparent when evaluated against existing benchmark datasets. Furthermore, we conduct rigorous analysis to unearth factors that lead to such limitations and examine why previous evaluations fail to detect such ineffectiveness. Lastly, we propose strategies to augment the generalization ability of text embedding models in diverse syntactic scenarios. This study serves to highlight the hurdles associated with syntactic generalization and provides pragmatic guidance for boosting model performance across varied syntactic contexts.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Text embedding models" is translated as "文本嵌入模型" (wén tiān zhù mó delè 模型)* "Semantic properties" is translated as "Semantic 属性" (Semantic 属性)* "Structural heuristics" is translated as "结构准则" (jiégòng zhèngxíng)* "Relational understanding" is translated as "关系理解" (guān xì líjiě)* "Performance gaps" is translated as "性能差距" (xìng néng kùjì)* "Benchmark datasets" is translated as "标准数据集" (biāo zhù shuō yì)* "Syntactic contexts" is translated as "语言上下文" (yǔ yán shàng xìng)* "Generalization ability" is translated as "通用能力" (tōng yòng néng lì)Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="The-ART-of-LLM-Refinement-Ask-Refine-and-Trust"><a href="#The-ART-of-LLM-Refinement-Ask-Refine-and-Trust" class="headerlink" title="The ART of LLM Refinement: Ask, Refine, and Trust"></a>The ART of LLM Refinement: Ask, Refine, and Trust</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07961">http://arxiv.org/abs/2311.07961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Shridhar, Koustuv Sinha, Andrew Cohen, Tianlu Wang, Ping Yu, Ram Pasunuru, Mrinmaya Sachan, Jason Weston, Asli Celikyilmaz</li>
<li>for: 提高 Large Language Models（LLMs）的生成质量</li>
<li>methods: 提出 Ask, Refine, and Trust（ART）目标，让 LLM 自我反思并更正生成结果</li>
<li>results: ART 在两个多步骤逻辑任务（GSM8K和StrategyQA）上表现出+5点的提升，而且使用较小的模型进行决策，从而实现成本效果。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLMs) have demonstrated remarkable generative abilities, but can they judge the quality of their own generations? A popular concept, referred to as self-refinement, postulates that LLMs can detect and correct the errors in their generations when asked to do so. However, recent empirical evidence points in the opposite direction, suggesting that LLMs often struggle to accurately identify errors when reasoning is involved. To address this, we propose a reasoning with refinement objective called ART: Ask, Refine, and Trust, which asks necessary questions to decide when an LLM should refine its output, and either affirm or withhold trust in its refinement by ranking the refinement and the initial prediction. On two multistep reasoning tasks of mathematical word problems (GSM8K) and question answering (StrategyQA), ART achieves a performance gain of +5 points over self-refinement baselines, while using a much smaller model as the decision maker. We also demonstrate the benefit of using smaller models to make refinement decisions as a cost-effective alternative to fine-tuning a larger model.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="First-Step-Advantage-Importance-of-Starting-Right-in-Multi-Step-Reasoning"><a href="#First-Step-Advantage-Importance-of-Starting-Right-in-Multi-Step-Reasoning" class="headerlink" title="First Step Advantage: Importance of Starting Right in Multi-Step Reasoning"></a>First Step Advantage: Importance of Starting Right in Multi-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07945">http://arxiv.org/abs/2311.07945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Jain, Kumar Shridhar</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）如何解决复杂的理解任务，并将这些能力压缩到更小的模型中。</li>
<li>methods: 论文使用了LLM来导引更小的模型，以便在特定任务上创建专门的、经济的模型。</li>
<li>results: 论文发现，如果在正确的时间进行指导，更小的模型可以减少理解任务中的错误，并提高性能超过100%。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) can solve complex reasoning tasks by generating rationales for their predictions. Distilling these capabilities into a smaller, compact model can facilitate the creation of specialized, cost-effective models tailored for specific tasks. However, smaller models often face challenges in complex reasoning tasks and often deviate from the correct reasoning path. We show that LLMs can guide smaller models and bring them back to the correct reasoning path only if they intervene at the right time. We show that smaller models fail to reason primarily due to their difficulty in initiating the process, and that guiding them in the right direction can lead to a performance gain of over 100%. We explore different model sizes and evaluate the benefits of providing guidance to improve reasoning in smaller models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="It’s-All-Relative-–-A-Synthetic-Query-Generation-Approach-for-Improving-Zero-Shot-Relevance-Prediction"><a href="#It’s-All-Relative-–-A-Synthetic-Query-Generation-Approach-for-Improving-Zero-Shot-Relevance-Prediction" class="headerlink" title="It’s All Relative! – A Synthetic Query Generation Approach for Improving Zero-Shot Relevance Prediction"></a>It’s All Relative! – A Synthetic Query Generation Approach for Improving Zero-Shot Relevance Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07930">http://arxiv.org/abs/2311.07930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditi Chaudhary, Karthik Raman, Michael Bendersky</li>
<li>for: 提高大型自然语言模型（LLM）在生成 sintetic 查询对的能力，以建立更好的搜索模型，尤其是在没有可用训练数据的情况下。</li>
<li>methods: 使用 LLM 生成 sintetic 查询对，通过提供少量示例进行 prompting，并将查询生成 conditional 于输入文档或 relevance 标签。</li>
<li>results: 通过在七个 IR 数据集进行广泛的实验，发现使用这种方法生成的 sintetic 查询可以提高下游性能，表明生成的查询质量更高。<details>
<summary>Abstract</summary>
Recent developments in large language models (LLMs) have shown promise in their ability to generate synthetic query-document pairs by prompting with as few as 8 demonstrations. This has enabled building better IR models, especially for tasks with no training data readily available. Typically, such synthetic query generation (QGen) approaches condition on an input context (e.g. a text document) and generate a query relevant to that context, or condition the QGen model additionally on the relevance label (e.g. relevant vs irrelevant) to generate queries across relevance buckets. However, we find that such QGen approaches are sub-optimal as they require the model to reason about the desired label and the input from a handful of examples. In this work, we propose to reduce this burden of LLMs by generating queries simultaneously for different labels. We hypothesize that instead of asking the model to generate, say, an irrelevant query given an input context, asking the model to generate an irrelevant query relative to a relevant query is a much simpler task setup for the model to reason about. Extensive experimentation across seven IR datasets shows that synthetic queries generated in such a fashion translates to a better downstream performance, suggesting that the generated queries are indeed of higher quality.
</details>
<details>
<summary>摘要</summary>
In this work, we propose to simplify the task for LLMs by generating queries simultaneously for different labels. We hypothesize that instead of asking the model to generate, say, an irrelevant query given an input context, asking the model to generate an irrelevant query relative to a relevant query is a much simpler task setup for the model to reason about. Our extensive experimentation across seven IR datasets shows that synthetic queries generated in this way lead to better downstream performance, suggesting that the generated queries are of higher quality.
</details></li>
</ul>
<hr>
<h2 id="Qwen-Audio-Advancing-Universal-Audio-Understanding-via-Unified-Large-Scale-Audio-Language-Models"><a href="#Qwen-Audio-Advancing-Universal-Audio-Understanding-via-Unified-Large-Scale-Audio-Language-Models" class="headerlink" title="Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models"></a>Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07919">http://arxiv.org/abs/2311.07919</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qwenlm/qwen-audio">https://github.com/qwenlm/qwen-audio</a></li>
<li>paper_authors: Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, Jingren Zhou</li>
<li>for: 这 paper 是为了提高 audio-language 模型的多任务能力和多种 audio 类型处理能力。</li>
<li>methods: 这 paper 使用了一种多任务训练框架，通过预先训练 audio 模型，使其能够处理多种 audio 类型和任务，而不需要任务特定的 fine-tuning。</li>
<li>results: 这 paper 的结果表明，Qwen-Audio 模型可以在多种 benchmark 任务上达到出色的性能，超过其他类似模型。此外，基于 Qwen-Audio 的 Qwen-Audio-Chat 模型可以处理多种 audio 和文本输入，支持多轮对话和各种 audio-中心场景。<details>
<summary>Abstract</summary>
Recently, instruction-following audio-language models have received broad attention for audio interaction with humans. However, the absence of pre-trained audio models capable of handling diverse audio types and tasks has hindered progress in this field. Consequently, most existing works have only been able to support a limited range of interaction capabilities. In this paper, we develop the Qwen-Audio model and address this limitation by scaling up audio-language pre-training to cover over 30 tasks and various audio types, such as human speech, natural sounds, music, and songs, to facilitate universal audio understanding abilities. However, directly co-training all tasks and datasets can lead to interference issues, as the textual labels associated with different datasets exhibit considerable variations due to differences in task focus, language, granularity of annotation, and text structure. To overcome the one-to-many interference, we carefully design a multi-task training framework by conditioning on a sequence of hierarchical tags to the decoder for encouraging knowledge sharing and avoiding interference through shared and specified tags respectively. Remarkably, Qwen-Audio achieves impressive performance across diverse benchmark tasks without requiring any task-specific fine-tuning, surpassing its counterparts. Building upon the capabilities of Qwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from various audios and text inputs, enabling multi-turn dialogues and supporting various audio-central scenarios.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose the Qwen-Audio model to address this limitation by scaling up audio-language pre-training to cover over 30 tasks and various audio types, including human speech, natural sounds, music, and songs. Our goal is to facilitate universal audio understanding abilities.However, directly co-training all tasks and datasets can lead to interference issues, as the textual labels associated with different datasets exhibit considerable variations due to differences in task focus, language, granularity of annotation, and text structure. To overcome this challenge, we carefully design a multi-task training framework by conditioning on a sequence of hierarchical tags to the decoder. This approach encourages knowledge sharing and avoids interference through shared and specified tags, respectively.Remarkably, Qwen-Audio achieves impressive performance across diverse benchmark tasks without requiring any task-specific fine-tuning, surpassing its counterparts. Building upon the capabilities of Qwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from various audios and text inputs, enabling multi-turn dialogues and supporting various audio-central scenarios.
</details></li>
</ul>
<hr>
<h2 id="Automated-title-and-abstract-screening-for-scoping-reviews-using-the-GPT-4-Large-Language-Model"><a href="#Automated-title-and-abstract-screening-for-scoping-reviews-using-the-GPT-4-Large-Language-Model" class="headerlink" title="Automated title and abstract screening for scoping reviews using the GPT-4 Large Language Model"></a>Automated title and abstract screening for scoping reviews using the GPT-4 Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07918">http://arxiv.org/abs/2311.07918</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wilkox/gptscreenr">https://github.com/wilkox/gptscreenr</a></li>
<li>paper_authors: David Wilkins</li>
<li>for: 这篇论文旨在提供一种自动屏选学术文献的方法，以帮助进行大规模的文献筛选任务。</li>
<li>methods: 这篇论文使用GPT-4大语言模型（LLM）和链式思维技术来自动屏选学术文献。</li>
<li>results: 在验证中，GPTscreenR与替代方案之间的性能相似，具有71%的敏感性、89%的特异性和总准确率为84%。<details>
<summary>Abstract</summary>
Scoping reviews, a type of literature review, require intensive human effort to screen large numbers of scholarly sources for their relevance to the review objectives. This manuscript introduces GPTscreenR, a package for the R statistical programming language that uses the GPT-4 Large Language Model (LLM) to automatically screen sources. The package makes use of the chain-of-thought technique with the goal of maximising performance on complex screening tasks. In validation against consensus human reviewer decisions, GPTscreenR performed similarly to an alternative zero-shot technique, with a sensitivity of 71%, specificity of 89%, and overall accuracy of 84%. Neither method achieved perfect accuracy nor human levels of intraobserver agreement. GPTscreenR demonstrates the potential for LLMs to support scholarly work and provides a user-friendly software framework that can be integrated into existing review processes.
</details>
<details>
<summary>摘要</summary>
scoping 筛选文献审查，一种文献审查类型，需要大量的人工劳动来屏幕大量的学术论文的相关性。这篇文章介绍了 R 统计编程语言中的 GPTscreenR 包，使用 GPT-4 大语言模型（LLM）自动屏幕源文。该包利用链条思想，目的是提高复杂屏幕任务的性能。在与专家人员审核决策相比，GPTscreenR 的性能与替代的零shot 技术相似，具有71%的敏感性、89%的特异性和84%的总准确率。 neither 方法达到了完美准确性 nochuman 水平的内部一致性。 GPTscreenR 表明了 LLM 可以支持学术工作，并提供了易用的软件框架，可以与现有的审查过程集成。
</details></li>
</ul>
<hr>
<h2 id="Can-Knowledge-Graphs-Reduce-Hallucinations-in-LLMs-A-Survey"><a href="#Can-Knowledge-Graphs-Reduce-Hallucinations-in-LLMs-A-Survey" class="headerlink" title="Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey"></a>Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07914">http://arxiv.org/abs/2311.07914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Garima Agrawal, Tharindu Kumarage, Zeyad Alghami, Huan Liu</li>
<li>for: 本研究旨在探讨现代LLMs中的幻见问题，以及如何通过外部知识的扩展来减少幻见并提高逻辑准确率。</li>
<li>methods: 本研究分析了利用知识图为LLMs进行知识扩展的三种主要方法，并对这些方法进行比较性分析和实验评估。</li>
<li>results: 研究发现，通过利用知识图来扩展LLMs可以有效地减少幻见，并提高逻辑准确率。但是，还存在一些挑战和未来研究的可能性。<details>
<summary>Abstract</summary>
The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models. To address this critical limitation, researchers employ diverse strategies to augment the LLMs by incorporating external knowledge, aiming to reduce hallucinations and enhance reasoning accuracy. Among these strategies, leveraging knowledge graphs as a source of external information has demonstrated promising results. In this survey, we conduct a comprehensive review of these knowledge-graph-based knowledge augmentation techniques in LLMs, focusing on their efficacy in mitigating hallucinations. We systematically categorize these methods into three overarching groups, offering both methodological comparisons and empirical evaluations of their performance. Lastly, the paper explores the challenges associated with these techniques and outlines potential avenues for future research in this emerging field.
</details>
<details>
<summary>摘要</summary>
当代LLMs具有生成幻觉的特点，主要归结于模型中知识的缺失。为解决这一重要局限性，研究人员采用多种策略来增强LLMs，以减少幻觉并提高逻辑精度。在这篇评论中，我们进行了全面的知识图基于增强技术的评审，关注它们在减少幻觉方面的有效性。我们将这些方法分为三大类，并对它们进行了方法学比较和实验性评估。最后，文章探讨了这些技术的挑战和未来研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="CPopQA-Ranking-Cultural-Concept-Popularity-by-LLMs"><a href="#CPopQA-Ranking-Cultural-Concept-Popularity-by-LLMs" class="headerlink" title="CPopQA: Ranking Cultural Concept Popularity by LLMs"></a>CPopQA: Ranking Cultural Concept Popularity by LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07897">http://arxiv.org/abs/2311.07897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Jiang, Mansi Joshi</li>
<li>for: 这研究旨在检验大型自然语言模型（LLM）是否可以准确地掌握文化节日的统计趋势，特别是长尾节日的普遍性。</li>
<li>methods: 研究使用了一种新的几个问题解决任务（CPopQA），用于测试LLM的统计排名能力。</li>
<li>results: 实验表明，大型模型可以准确地掌握文化节日的统计趋势，其中GPT-3.5表现最佳，并能够识别不同洲的地域文化 proximity。<details>
<summary>Abstract</summary>
Prior work has demonstrated large language models' (LLMs) potential to discern statistical tendencies within their pre-training corpora. Despite that, many examinations of LLMs' knowledge capacity focus on knowledge explicitly appearing in the training data or implicitly inferable from similar contexts. How well an LLM captures the corpus-level statistical trends of concepts for reasoning, especially long-tail ones, is still underexplored. In this study, we introduce a novel few-shot question-answering task (CPopQA) that examines LLMs' statistical ranking abilities for long-tail cultural concepts (e.g., holidays), with a specific focus on these concepts' popularity in the United States and the United Kingdom, respectively. We curate a dataset containing 459 holidays across 58 countries, generating a total of 6,000 QA testing pairs. Experiments on four strong LLMs show that large models are capable of ranking long-tail cultural concepts regarding their statistical tendency. Notably, GPT-3.5 displayed superior performance and exhibited its potential to identify geo-cultural proximity across continents.
</details>
<details>
<summary>摘要</summary>
In this study, we introduce a new few-shot question-answering task (CPopQA) that examines LLMs' statistical ranking abilities for long-tail cultural concepts (e.g., holidays), with a specific focus on their popularity in the United States and the United Kingdom. We curated a dataset containing 459 holidays across 58 countries, resulting in a total of 6,000 QA testing pairs. Our experiments on four strong LLMs show that large models are capable of ranking long-tail cultural concepts based on their statistical tendency. Notably, GPT-3.5 displayed superior performance and exhibited its ability to identify geo-cultural proximity across continents.
</details></li>
</ul>
<hr>
<h2 id="Fair-Abstractive-Summarization-of-Diverse-Perspectives"><a href="#Fair-Abstractive-Summarization-of-Diverse-Perspectives" class="headerlink" title="Fair Abstractive Summarization of Diverse Perspectives"></a>Fair Abstractive Summarization of Diverse Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07884">http://arxiv.org/abs/2311.07884</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/fairsumm">https://github.com/psunlpgroup/fairsumm</a></li>
<li>paper_authors: Yusen Zhang, Nan Zhang, Yixin Liu, Alexander Fabbri, Junru Liu, Ryo Kamoi, Xiaoxin Lu, Caiming Xiong, Jieyu Zhao, Dragomir Radev, Kathleen McKeown, Rui Zhang</li>
<li>for: 这篇论文研究了如何实现公正的抽象概要，以便不会忽略某些群体的观点。</li>
<li>methods: 该论文提出了四种无需参考的自动评价指标，用于衡量抽象概要是否公正。</li>
<li>results: 实验表明，模型生成的概要和人类写的参考概要都受到低度公正的影响。研究还发现了一些常见的公正概要Influencing factor，并提出了三种简单 yet effective的方法来解决不公正概要问题。<details>
<summary>Abstract</summary>
People from different social and demographic groups express diverse perspectives and conflicting opinions on a broad set of topics such as product reviews, healthcare, law, and politics. A fair summary should provide a comprehensive coverage of diverse perspectives without underrepresenting certain groups. However, current work in summarization metrics and Large Language Models (LLMs) evaluation has not explored fair abstractive summarization. In this paper, we systematically investigate fair abstractive summarization for user-generated data. We first formally define fairness in abstractive summarization as not underrepresenting perspectives of any groups of people and propose four reference-free automatic metrics measuring the differences between target and source perspectives. We evaluate five LLMs, including three GPT models, Alpaca, and Claude, on six datasets collected from social media, online reviews, and recorded transcripts. Experiments show that both the model-generated and the human-written reference summaries suffer from low fairness. We conduct a comprehensive analysis of the common factors influencing fairness and propose three simple but effective methods to alleviate unfair summarization. Our dataset and code are available at https://github.com/psunlpgroup/FairSumm.
</details>
<details>
<summary>摘要</summary>
人们来自不同的社会和人口结构组群体表达了多样化的观点和矛盾的意见，包括产品评论、医疗、法律和政治等领域。一个公正的概要应该提供广泛的多样化观点的涵盖，而无论任何群体的观点不被忽视。然而，当前的摘要 metric 和大语言模型（LLM）评价工作尚未探讨公正抽象摘要。在这篇论文中，我们系统地调查了用户生成数据的公正抽象摘要。我们首先正式定义了摘要公正性的形式化定义，即不对任何群体的观点进行忽视，并提出了四种Reference-free自动度量 measure 衡量目标和源观点之间的差异。我们对六个社交媒体、在线评论和录制过的语音材料上收集的六个数据集进行了五种 LLN 的评估，包括三种 GPT 模型、Alpaca 和 Claude。实验显示，模型生成的和人类写的参考摘要都受到低度的公正性影响。我们进行了对公正性的全面分析，并提出了三种简单 yet 有效的方法来缓解不公正的摘要。我们的数据集和代码可以在 <https://github.com/psunlpgroup/FairSumm> 获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-Mutually-Informed-Representations-for-Characters-and-Subwords"><a href="#Learning-Mutually-Informed-Representations-for-Characters-and-Subwords" class="headerlink" title="Learning Mutually Informed Representations for Characters and Subwords"></a>Learning Mutually Informed Representations for Characters and Subwords</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07853">http://arxiv.org/abs/2311.07853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yilin Wang, Xinyi Hu, Matthew R. Gormley</li>
<li>for: 这个论文的目的是提出一种新的语言模型，即束缚模型，用于组合字符和子词语言模型。</li>
<li>methods: 该模型使用视觉语言模型的想法，将字符和子词视为两种不同的感知modalities，并生成它们之间相互了解的表示。</li>
<li>results: 该模型在文本分类、命名实体识别和POS标记任务上表现出色，尤其是在噪音文本和低资源语言下表现更好。此外，该模型还在所有英文序列标签任务和分类任务上表现更好于其背景语言模型。<details>
<summary>Abstract</summary>
Most pretrained language models rely on subword tokenization, which processes text as a sequence of subword tokens. However, different granularities of text, such as characters, subwords, and words, can contain different kinds of information. Previous studies have shown that incorporating multiple input granularities improves model generalization, yet very few of them outputs useful representations for each granularity. In this paper, we introduce the entanglement model, aiming to combine character and subword language models. Inspired by vision-language models, our model treats characters and subwords as separate modalities, and it generates mutually informed representations for both granularities as output. We evaluate our model on text classification, named entity recognition, and POS-tagging tasks. Notably, the entanglement model outperforms its backbone language models, particularly in the presence of noisy texts and low-resource languages. Furthermore, the entanglement model even outperforms larger pre-trained models on all English sequence labeling tasks and classification tasks. Our anonymized code is available at https://anonymous.4open.science/r/noisy-IE-A673
</details>
<details>
<summary>摘要</summary>
大多数预训练语言模型都基于字符串分词，将文本处理为字符串Token的序列。然而，不同的文本粒度，如字符、子词和词，可以包含不同的信息。先前的研究表明，将多个输入粒度合并可以提高模型泛化性，但很少的其中输出有用的表示。在本文中，我们介绍了杂化模型，旨在将字符和子词语言模型相结合。受视语言模型的启示，我们的模型将字符和子词视为两种不同的modalities，并生成了彼此相互 Informed的表示。我们对文本分类、命名实体识别和POS标注任务进行评估。值得注意的是，杂化模型在噪音文本和低资源语言的情况下特别有优异表现，并且在所有英文序列标签任务和分类任务上都超越了它的后ION语言模型。我们的匿名代码可以在https://anonymous.4open.science/r/noisy-IE-A673中找到。
</details></li>
</ul>
<hr>
<h2 id="On-the-Analysis-of-Cross-Lingual-Prompt-Tuning-for-Decoder-based-Multilingual-Model"><a href="#On-the-Analysis-of-Cross-Lingual-Prompt-Tuning-for-Decoder-based-Multilingual-Model" class="headerlink" title="On the Analysis of Cross-Lingual Prompt Tuning for Decoder-based Multilingual Model"></a>On the Analysis of Cross-Lingual Prompt Tuning for Decoder-based Multilingual Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07820">http://arxiv.org/abs/2311.07820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nohil Park, Joonsuk Park, Kang Min Yoo, Sungroh Yoon</li>
<li>for: 这研究旨在探讨在多语言模型中使用准确的文本提示来改进模型的适应性。</li>
<li>methods: 研究使用了XGLM模型，并对其进行了Token-based提示和参数有效的微调。</li>
<li>results: 研究发现，使用提示微调可以达到或超过微调的性能，同时只需更新0.13%的模型参数。此外，提示微调也能更好地提高低资源语言的性能。<details>
<summary>Abstract</summary>
An exciting advancement in the field of multilingual models is the emergence of autoregressive models with zero- and few-shot capabilities, a phenomenon widely reported in large-scale language models. To further improve model adaptation to cross-lingual tasks, another trend is to further fine-tune the language models with either full fine-tuning or parameter-efficient tuning. However, the interaction between parameter-efficient fine-tuning (PEFT) and cross-lingual tasks in multilingual autoregressive models has yet to be studied. Specifically, we lack an understanding of the role of linguistic distributions in multilingual models in the effectiveness of token-based prompt tuning. To address this question, we conduct experiments comparing prompt tuning and fine-tuning on the decoder-based multilingual model, XGLM, with four cross-lingual tasks (XNLI, PAWS-X, POS, NER). According to our study, prompt tuning achieves on par or better performance over fine-tuning across all languages while updating at most 0.13\% of the model parameters. Moreover, we empirically show that prompt tuning is more effective in enhancing the performance of low-resource languages than fine-tuning. Our further analysis shows that the phenomenon is related to the tokenization scheme of the multilingual model.
</details>
<details>
<summary>摘要</summary>
“在多语言模型领域，一种有趣的发展是零或几个shot能力的推论模型，这种现象广泛出现在大规模语言模型中。为了进一步改进模型在多语言任务中的适应性，另一种趋势是进一步精细调整语言模型，使其在cross-lingual任务中更加高效。然而，在多语言模型中PEFT（parameter-efficient fine-tuning）和cross-lingual任务之间的互动尚未得到了研究。具体来说，我们缺乏关于多语言模型中 linguistic distributions 对 token-based prompt tuning 的效iveness的理解。为了解答这个问题，我们在decoder-based多语言模型XGLM上进行了实验，使用了四个cross-lingual任务（XNLI、PAWS-X、POS、NER）。根据我们的研究，prompt tuning 在所有语言上具有on par或更好的性能，只需要更新模型参数的0.13%。此外，我们还证明了prompt tuning 对低资源语言的表现更加出色于 fine-tuning。我们进一步的分析表明，这种现象与多语言模型的tokenization scheme相关。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/cs.CL_2023_11_14/" data-id="clpztdnf800fces88dppv54w6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/cs.LG_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T10:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/cs.LG_2023_11_14/">cs.LG - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Variational-Temporal-IRT-Fast-Accurate-and-Explainable-Inference-of-Dynamic-Learner-Proficiency"><a href="#Variational-Temporal-IRT-Fast-Accurate-and-Explainable-Inference-of-Dynamic-Learner-Proficiency" class="headerlink" title="Variational Temporal IRT: Fast, Accurate, and Explainable Inference of Dynamic Learner Proficiency"></a>Variational Temporal IRT: Fast, Accurate, and Explainable Inference of Dynamic Learner Proficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08594">http://arxiv.org/abs/2311.08594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunsung Kim, Sreechan Sankaranarayanan, Chris Piech, Candace Thille</li>
<li>for: 这个论文旨在描述一种快速和准确地掌握动态学习者能力的方法。</li>
<li>methods: 这种方法基于变分Item Response Theory（VTIRT），它可以在巨量数据集上进行快速和准确的掌握。</li>
<li>results: 在应用于9个实际学生数据集上，VTIRT consistently 提高了预测未来学习者表现的精度，比其他学习者能力模型更好。<details>
<summary>Abstract</summary>
Dynamic Item Response Models extend the standard Item Response Theory (IRT) to capture temporal dynamics in learner ability. While these models have the potential to allow instructional systems to actively monitor the evolution of learner proficiency in real time, existing dynamic item response models rely on expensive inference algorithms that scale poorly to massive datasets. In this work, we propose Variational Temporal IRT (VTIRT) for fast and accurate inference of dynamic learner proficiency. VTIRT offers orders of magnitude speedup in inference runtime while still providing accurate inference. Moreover, the proposed algorithm is intrinsically interpretable by virtue of its modular design. When applied to 9 real student datasets, VTIRT consistently yields improvements in predicting future learner performance over other learner proficiency models.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Dynamic Item Response Models extend the standard Item Response Theory (IRT) to capture temporal dynamics in learner ability. While these models have the potential to allow instructional systems to actively monitor the evolution of learner proficiency in real time, existing dynamic item response models rely on expensive inference algorithms that scale poorly to massive datasets. In this work, we propose Variational Temporal IRT (VTIRT) for fast and accurate inference of dynamic learner proficiency. VTIRT offers orders of magnitude speedup in inference runtime while still providing accurate inference. Moreover, the proposed algorithm is intrinsically interpretable by virtue of its modular design. When applied to 9 real student datasets, VTIRT consistently yields improvements in predicting future learner performance over other learner proficiency models." into Simplified Chinese. Dynamic Item Response Models 扩展标准Item Response Theory (IRT)，以捕捉学生能力的时间动态。这些模型有可能使 instrucitonal 系统在实时监测学生水平的进程中活动地监测学生的能力。现有的动态项Response模型使用昂贵的推理算法，这些算法不利于处理大量数据。在这种工作中，我们提出了Variational Temporal IRT (VTIRT)，用于快速和准确地推理学生的能力。VTIRT可以提供数个级别的速度提升，而且仍然提供准确的推理。此外，我们的算法具有自然的解释性，由于其模块化的设计。当应用于9个实际学生数据集时，VTIRT一致地提高了预测未来学生性能的性能，相比其他学生能力模型。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Quantification-in-Neural-Network-Based-Pain-Intensity-Estimation"><a href="#Uncertainty-Quantification-in-Neural-Network-Based-Pain-Intensity-Estimation" class="headerlink" title="Uncertainty Quantification in Neural-Network Based Pain Intensity Estimation"></a>Uncertainty Quantification in Neural-Network Based Pain Intensity Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08569">http://arxiv.org/abs/2311.08569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Burcu Ozek, Zhenyuan Lu, Srinivasan Radhakrishnan, Sagar Kamarthi<br>for: 本研究旨在提供一种基于神经网络的疼痛时间Interval估计方法，并考虑uncertainty量化。methods: 本研究采用三种算法：bootstrap方法、LossL优化 Algorithm和modified LossS优化 Algorithm。results: 研究结果显示LossS方法比其他两种方法提供更窄的预测Interval，并在不同的疼痛评估场景下（一般方法、个性化方法和混合方法）进行了评估。 hybrid方法在临床上展现出了最佳性能，具有实际应用价值。<details>
<summary>Abstract</summary>
Improper pain management can lead to severe physical or mental consequences, including suffering, and an increased risk of opioid dependency. Assessing the presence and severity of pain is imperative to prevent such outcomes and determine the appropriate intervention. However, the evaluation of pain intensity is challenging because different individuals experience pain differently. To overcome this, researchers have employed machine learning models to evaluate pain intensity objectively. However, these efforts have primarily focused on point estimation of pain, disregarding the inherent uncertainty and variability present in the data and model. Consequently, the point estimates provide only partial information for clinical decision-making. This study presents a neural network-based method for objective pain interval estimation, incorporating uncertainty quantification. This work explores three algorithms: the bootstrap method, lower and upper bound estimation (LossL) optimized by genetic algorithm, and modified lower and upper bound estimation (LossS) optimized by gradient descent algorithm. Our empirical results reveal that LossS outperforms the other two by providing a narrower prediction interval. As LossS outperforms, we assessed its performance in three different scenarios for pain assessment: (1) a generalized approach (single model for the entire population), (2) a personalized approach (separate model for each individual), and (3) a hybrid approach (separate model for each cluster of individuals). Our findings demonstrate the hybrid approach's superior performance, with notable practicality in clinical contexts. It has the potential to be a valuable tool for clinicians, enabling objective pain intensity assessment while taking uncertainty into account. This capability is crucial in facilitating effective pain management and reducing the risks associated with improper treatment.
</details>
<details>
<summary>摘要</summary>
不当的疼痛管理可能会导致严重的身体或心理后果，包括痛苦和对吗用药物的依赖。评估疼痛的存在和严重程度是非常重要的，以避免这些后果并确定适当的干预措施。然而，评估疼痛的程度是具有挑战性的，因为不同的人会经受疼痛的不同程度。为了解决这个问题，研究人员使用机器学习模型评估疼痛的程度。然而，这些努力主要集中在点估计疼痛的方面，忽略了数据和模型中存在的不确定性和变化。因此，点估计只提供了部分信息，不足以支持临床决策。本研究提出了一种基于神经网络的对疼痛间隔评估方法，并包括不确定性评估。本工作 explore three algorithms：bootstrap方法、LossL优化的遗传算法和LossS优化的梯度下降算法。我们的实验结果表明，LossS在三种方法中表现最佳，提供了较窄的预测 интерval。我们进一步评估LossS在不同的疼痛评估场景中的表现：（1）总体方法（单一模型为整个人口）、（2）个性化方法（每个个体各自的模型）和（3）混合方法（每个群体的模型）。我们的发现表明，混合方法的表现最佳，具有在临床上实际的实用性。这种能力可能是临床医生所需的一种有价值的工具，帮助评估疼痛的程度，同时考虑不确定性。这种能力是管理疼痛的正确方式的关键，可以减少不当的治疗所导致的风险。
</details></li>
</ul>
<hr>
<h2 id="Manifold-learning-in-Wasserstein-space"><a href="#Manifold-learning-in-Wasserstein-space" class="headerlink" title="Manifold learning in Wasserstein space"></a>Manifold learning in Wasserstein space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08549">http://arxiv.org/abs/2311.08549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keaton Hamm, Caroline Moosmüller, Bernhard Schmitzer, Matthew Thorpe</li>
<li>For: 本研究旨在建立拓扑学基础 для拟合概率分布的推理算法，具体是在紧邻的 compact和凸的 $\mathbb{R}^d$ 上的可数continue probability measure空间中。* Methods: 本文引入一种自然的构造方法，即使用 Wasserstein-2 距离 $W$ 来定义submanifold $\Lambda$ 上的 métrique $W_\Lambda$。这些submanifold不一定是平坦的，但仍然允许当地的线性化。然后，通过samples ${\lambda_i}<em>{i&#x3D;1}^N$ 和 pairwise extrinsic Wasserstein distances $W$ 来学习 $\Lambda$ 的潜在拓扑结构。* Results: 本文显示了如何从 samples ${\lambda_i}</em>{i&#x3D;1}^N$ 和 $W$  alone 学习 $\Lambda$ 的 métrique space $( \Lambda, W_{\Lambda})$，并且可以 asymptotically recover the metric space from a graph with nodes ${\lambda_i}<em>{i&#x3D;1}^N$ 和 edge weights $W(\lambda_i,\lambda_j)$. 此外，文章还证明了如何通过spectral analysis 来recover tangent space at a sample $\lambda$  via optimal transport maps from $\lambda$ to sufficiently close and diverse samples ${\lambda_i}</em>{i&#x3D;1}^N$.<details>
<summary>Abstract</summary>
This paper aims at building the theoretical foundations for manifold learning algorithms in the space of absolutely continuous probability measures on a compact and convex subset of $\mathbb{R}^d$, metrized with the Wasserstein-2 distance $W$. We begin by introducing a natural construction of submanifolds $\Lambda$ of probability measures equipped with metric $W_\Lambda$, the geodesic restriction of $W$ to $\Lambda$. In contrast to other constructions, these submanifolds are not necessarily flat, but still allow for local linearizations in a similar fashion to Riemannian submanifolds of $\mathbb{R}^d$. We then show how the latent manifold structure of $(\Lambda,W_{\Lambda})$ can be learned from samples $\{\lambda_i\}_{i=1}^N$ of $\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. In particular, we show that the metric space $(\Lambda,W_{\Lambda})$ can be asymptotically recovered in the sense of Gromov--Wasserstein from a graph with nodes $\{\lambda_i\}_{i=1}^N$ and edge weights $W(\lambda_i,\lambda_j)$. In addition, we demonstrate how the tangent space at a sample $\lambda$ can be asymptotically recovered via spectral analysis of a suitable "covariance operator" using optimal transport maps from $\lambda$ to sufficiently close and diverse samples $\{\lambda_i\}_{i=1}^N$. The paper closes with some explicit constructions of submanifolds $\Lambda$ and numerical examples on the recovery of tangent spaces through spectral analysis.
</details>
<details>
<summary>摘要</summary>
The paper shows how the latent manifold structure of $(\Lambda,W_{\Lambda})$ can be learned from samples $\{\lambda_i\}_{i=1}^N$ of $\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. Specifically, the paper demonstrates that the metric space $(\Lambda,W_{\Lambda})$ can be asymptotically recovered in the sense of Gromov--Wasserstein from a graph with nodes $\{\lambda_i\}_{i=1}^N$ and edge weights $W(\lambda_i,\lambda_j)$.Furthermore, the paper shows how the tangent space at a sample $\lambda$ can be asymptotically recovered via spectral analysis of a suitable "covariance operator" using optimal transport maps from $\lambda$ to sufficiently close and diverse samples $\{\lambda_i\}_{i=1}^N$. The paper provides explicit constructions of submanifolds $\Lambda$ and numerical examples on the recovery of tangent spaces through spectral analysis.Translated into Simplified Chinese, the paper aims to establish the theoretical foundations for manifold learning algorithms in the space of absolutely continuous probability measures on a compact and convex subset of $\mathbb{R}^d$, using the Wasserstein-2 distance $W$. The paper introduces a natural construction of submanifolds $\Lambda$ of probability measures equipped with metric $W_\Lambda$, which is the geodesic restriction of $W$ to $\Lambda$. These submanifolds are not necessarily flat, but allow for local linearizations in a similar fashion to Riemannian submanifolds of $\mathbb{R}^d$.The paper shows how the latent manifold structure of $(\Lambda,W_{\Lambda})$ can be learned from samples $\{\lambda_i\}_{i=1}^N$ of $\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. Specifically, the paper demonstrates that the metric space $(\Lambda,W_{\Lambda})$ can be asymptotically recovered in the sense of Gromov--Wasserstein from a graph with nodes $\{\lambda_i\}_{i=1}^N$ and edge weights $W(\lambda_i,\lambda_j)$.Furthermore, the paper shows how the tangent space at a sample $\lambda$ can be asymptotically recovered via spectral analysis of a suitable "covariance operator" using optimal transport maps from $\lambda$ to sufficiently close and diverse samples $\{\lambda_i\}_{i=1}^N$. The paper provides explicit constructions of submanifolds $\Lambda$ and numerical examples on the recovery of tangent spaces through spectral analysis.
</details></li>
</ul>
<hr>
<h2 id="Low-Frequency-Load-Identification-using-CNN-BiLSTM-Attention-Mechanism"><a href="#Low-Frequency-Load-Identification-using-CNN-BiLSTM-Attention-Mechanism" class="headerlink" title="Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism"></a>Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08536">http://arxiv.org/abs/2311.08536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amanie Azzam, Saba Sanami, Amir G. Aghdam</li>
<li>for: 这个研究旨在提出一个以卷积神经网和两向长短Term Memory为基础的混合学习方法，用于低频率电力资料分解。</li>
<li>methods: 本研究使用了一个混合的卷积神经网和BILSTM模型，同时具有一个集成的注意力机制，以提高低频率电力资料分解的精度。</li>
<li>results: 根据 simulations 的结果，提出的方法在精度和计算时间两个方面都有所提高，较以往的方法更高。<details>
<summary>Abstract</summary>
Non-intrusive Load Monitoring (NILM) is an established technique for effective and cost-efficient electricity consumption management. The method is used to estimate appliance-level power consumption from aggregated power measurements. This paper presents a hybrid learning approach, consisting of a convolutional neural network (CNN) and a bidirectional long short-term memory (BILSTM), featuring an integrated attention mechanism, all within the context of disaggregating low-frequency power data. While prior research has been mainly focused on high-frequency data disaggregation, our study takes a distinct direction by concentrating on low-frequency data. The proposed hybrid CNN-BILSTM model is adept at extracting both temporal (time-related) and spatial (location-related) features, allowing it to precisely identify energy consumption patterns at the appliance level. This accuracy is further enhanced by the attention mechanism, which aids the model in pinpointing crucial parts of the data for more precise event detection and load disaggregation. We conduct simulations using the existing low-frequency REDD dataset to assess our model performance. The results demonstrate that our proposed approach outperforms existing methods in terms of accuracy and computation time.
</details>
<details>
<summary>摘要</summary>
非侵入式电力监测（NILM）是一种已知的技术，用于有效和经济地管理电力消耗。该方法通过聚合电力测量值来估算设备级电力消耗。本文提出了一种混合学习方法，包括卷积神经网络（CNN）和双向长短期记忆神经网络（BILSTM），具有集成注意机制，所在的低频数据分解领域中。相比之前的研究主要集中在高频数据分解领域，我们的研究做出了不同的选择，即集中在低频数据分解领域。该混合模型具有提取时间相关特征和空间相关特征的能力，可以准确地识别设备级电力消耗模式。此外，注意机制可以帮助模型更加准确地检测和分解电力负荷。我们使用现有的低频RED dataset进行了 simulations，以评估我们的模型性能。结果显示，我们的提posed方法在准确率和计算时间方面都超过了现有方法。
</details></li>
</ul>
<hr>
<h2 id="On-semi-supervised-estimation-using-exponential-tilt-mixture-models"><a href="#On-semi-supervised-estimation-using-exponential-tilt-mixture-models" class="headerlink" title="On semi-supervised estimation using exponential tilt mixture models"></a>On semi-supervised estimation using exponential tilt mixture models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08504">http://arxiv.org/abs/2311.08504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Tian, Xinwei Zhang, Zhiqiang Tan</li>
<li>for: 这个论文是用来探讨 semi-supervised learning 中使用 exponential tilt mixture (ETM) 模型和最大非Parametric 极限likelihood 估计方法，以优化预测性能。</li>
<li>methods: 该论文使用 exponential tilt mixture 模型和最大非Parametric 极限likelihood 估计方法，并对这些方法的 asymptotic properties 进行分析和解释。</li>
<li>results: 论文表明，使用 exponential tilt mixture 模型和最大非Parametric 极限likelihood 估计方法可以提高 semi-supervised learning 中的预测性能，并且在Random Sampling 和 outcome-stratified Sampling 两种采样方法下都有更高的效率。<details>
<summary>Abstract</summary>
Consider a semi-supervised setting with a labeled dataset of binary responses and predictors and an unlabeled dataset with only the predictors. Logistic regression is equivalent to an exponential tilt model in the labeled population. For semi-supervised estimation, we develop further analysis and understanding of a statistical approach using exponential tilt mixture (ETM) models and maximum nonparametric likelihood estimation, while allowing that the class proportions may differ between the unlabeled and labeled data. We derive asymptotic properties of ETM-based estimation and demonstrate improved efficiency over supervised logistic regression in a random sampling setup and an outcome-stratified sampling setup previously used. Moreover, we reconcile such efficiency improvement with the existing semiparametric efficiency theory when the class proportions in the unlabeled and labeled data are restricted to be the same. We also provide a simulation study to numerically illustrate our theoretical findings.
</details>
<details>
<summary>摘要</summary>
请考虑一个半监督性Setting中，有一个标注的数据集，其中变量和回快应答的关系是一个二分类问题，并且有一个无标注数据集，只包含变量。在这个Setting中，椭圆倾斜模型（ETM）是等效于折射函数回快的模型。我们进一步分析和理解使用ETM模型进行半监督性估计，并允许类别之间的分布差异。我们 derive了ETM模型基于的估计的极限性质，并在随机抽样和结果抽样两种设置中证明了我们的估计方法比超vised折射函数回快更高效。此外，我们还与现有的半 Parametric效率理论相协调，当类别在无标注和标注数据中的分布相同时，我们的估计方法具有更高效的性质。最后，我们进行了一个数值 simulations to numerically illustrate our theoretical findings。
</details></li>
</ul>
<hr>
<h2 id="Variational-Quantum-Eigensolver-with-Constraints-VQEC-Solving-Constrained-Optimization-Problems-via-VQE"><a href="#Variational-Quantum-Eigensolver-with-Constraints-VQEC-Solving-Constrained-Optimization-Problems-via-VQE" class="headerlink" title="Variational Quantum Eigensolver with Constraints (VQEC): Solving Constrained Optimization Problems via VQE"></a>Variational Quantum Eigensolver with Constraints (VQEC): Solving Constrained Optimization Problems via VQE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08502">http://arxiv.org/abs/2311.08502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thinh Viet Le, Vassilis Kekatos</li>
<li>for: 提出了一种扩展了 celebritied VQE 的量子-классический算法模式，以解决优化问题中的约束。</li>
<li>methods: 使用了量子-классический算法模式，在量子圈中捕捉优化变量的vector，并在类比的Lagrangian函数中进行权重补做。</li>
<li>results: 可以准确地解决quadratically-constrained binary optimization (QCBO)问题，找到符号化二进制策略，并解决大规模的线性程序 (LP) 问题。<details>
<summary>Abstract</summary>
Variational quantum approaches have shown great promise in finding near-optimal solutions to computationally challenging tasks. Nonetheless, enforcing constraints in a disciplined fashion has been largely unexplored. To address this gap, this work proposes a hybrid quantum-classical algorithmic paradigm termed VQEC that extends the celebrated VQE to handle optimization with constraints. As with the standard VQE, the vector of optimization variables is captured by the state of a variational quantum circuit (VQC). To deal with constraints, VQEC optimizes a Lagrangian function classically over both the VQC parameters as well as the dual variables associated with constraints. To comply with the quantum setup, variables are updated via a perturbed primal-dual method leveraging the parameter shift rule. Among a wide gamut of potential applications, we showcase how VQEC can approximately solve quadratically-constrained binary optimization (QCBO) problems, find stochastic binary policies satisfying quadratic constraints on the average and in probability, and solve large-scale linear programs (LP) over the probability simplex. Under an assumption on the error for the VQC to approximate an arbitrary probability mass function (PMF), we provide bounds on the optimality gap attained by a VQC. Numerical tests on a quantum simulator investigate the effect of various parameters and corroborate that VQEC can generate high-quality solutions.
</details>
<details>
<summary>摘要</summary>
几何量子方法已经显示出了解决计算复杂任务的很好的承诺。然而，在一个有约束的情况下进行约束的执行还是尚未得到了充分的探索。为了解决这个差距，这项工作提出了一种混合量子-классический算法体系，称为VQEC，该体系将扩展了著名的VQE来处理优化问题中的约束。与标准VQE类似，VQEC中的优化变量vector被捕捉到了变量量子电路(VQC)的状态中。为了处理约束，VQEC在类比的Lagrangian函数上进行了类比的优化。在量子设置中，变量被更新了通过一种受到参数shift规则的偏好 primal-dual 方法。在各种应用中，我们展示了如何VQEC可以约approximately解决 quadratic-constrained binary optimization (QCBO)问题，找到随机二进制政策满足平均和概率上的二次约束，以及解决大规模的线性Program (LP) over the probability simplex。对于VQC的参数错误，我们提供了关于优化的距离上的下界。在一个量子仿真器上进行的数值测试表明，VQEC可以生成高质量的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Ensemble-sampling-for-linear-bandits-small-ensembles-suffice"><a href="#Ensemble-sampling-for-linear-bandits-small-ensembles-suffice" class="headerlink" title="Ensemble sampling for linear bandits: small ensembles suffice"></a>Ensemble sampling for linear bandits: small ensembles suffice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08376">http://arxiv.org/abs/2311.08376</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Janz, Alexander E. Litvak, Csaba Szepesvári</li>
<li>for: 这个论文是为了研究 Stochastic Linear Bandit 设定下 ensemble sampling 的效果的。</li>
<li>methods: 这个论文使用了 ensemble sampling 方法，并且ensemble size 是 $d \log T$ 的 ORDER。</li>
<li>results: 这个论文显示，在标准假设下， ensemble sampling 可以避免 linear 时间的 ensemble size 增长，而达到 near $\sqrt{T}$ 的 regret。此外，这个论文还是首次在结构化设定下不需要 ensemble size 与 $T$ 成线性关系。<details>
<summary>Abstract</summary>
We provide the first useful, rigorous analysis of ensemble sampling for the stochastic linear bandit setting. In particular, we show that, under standard assumptions, for a $d$-dimensional stochastic linear bandit with an interaction horizon $T$, ensemble sampling with an ensemble of size $m$ on the order of $d \log T$ incurs regret bounded by order $(d \log T)^{5/2} \sqrt{T}$. Ours is the first result in any structured setting not to require the size of the ensemble to scale linearly with $T$ -- which defeats the purpose of ensemble sampling -- while obtaining near $\sqrt{T}$ order regret. Ours is also the first result that allows infinite action sets.
</details>
<details>
<summary>摘要</summary>
我们提供了阶梯循环探索的首个有用且严谨的分析，具体是针对多元阶梯循环设定中的数学线上抽样。具体来说，我们证明，在标准假设之下，一个 $d$-维的阶梯循环中的抽样 ensemble 的大小为 $m$，其中 $m$ 的预设值为 $d \log T$，则对应的忘却 regret 将 bounded by order $(d \log T)^{5/2} \sqrt{T}$。我们的结果是首个不需要ensemble size scales linearly with $T$的结果，而且可以 дости到近 $\sqrt{T}$ 类的忘却 regret。此外，我们的结果还允许无限的动作集。
</details></li>
</ul>
<hr>
<h2 id="Transformers-can-optimally-learn-regression-mixture-models"><a href="#Transformers-can-optimally-learn-regression-mixture-models" class="headerlink" title="Transformers can optimally learn regression mixture models"></a>Transformers can optimally learn regression mixture models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08362">http://arxiv.org/abs/2311.08362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reese Pathak, Rajat Sen, Weihao Kong, Abhimanyu Das</li>
<li>for:  investigate the hypothesis that transformers can learn an optimal predictor for mixtures of regressions.</li>
<li>methods:  use transformers to learn a mixture of linear regressions, and prove that the decision-theoretic optimal procedure is indeed implementable by a transformer.</li>
<li>results:  transformers can learn mixtures of regressions in a sample-efficient fashion and are somewhat robust to distribution shifts, and can make predictions that are close to the optimal predictor.<details>
<summary>Abstract</summary>
Mixture models arise in many regression problems, but most methods have seen limited adoption partly due to these algorithms' highly-tailored and model-specific nature. On the other hand, transformers are flexible, neural sequence models that present the intriguing possibility of providing general-purpose prediction methods, even in this mixture setting. In this work, we investigate the hypothesis that transformers can learn an optimal predictor for mixtures of regressions. We construct a generative process for a mixture of linear regressions for which the decision-theoretic optimal procedure is given by data-driven exponential weights on a finite set of parameters. We observe that transformers achieve low mean-squared error on data generated via this process. By probing the transformer's output at inference time, we also show that transformers typically make predictions that are close to the optimal predictor. Our experiments also demonstrate that transformers can learn mixtures of regressions in a sample-efficient fashion and are somewhat robust to distribution shifts. We complement our experimental observations by proving constructively that the decision-theoretic optimal procedure is indeed implementable by a transformer.
</details>
<details>
<summary>摘要</summary>
“混合模型在许多回归问题中出现，但大多数方法尚未得到广泛采用，一部分原因是这些算法具有特定和模型固有的特点。然而，变换器是一种灵活的神经网络模型，它们可能提供一种通用预测方法，即使在混合Setting中。在这个工作中，我们研究了假设变Transformers可以学习混合回归的优化预测器。我们构造了一个生成过程，其中混合线性回归的决策理论优化程序是通过数据驱动的几何加权来实现。我们发现，变换器在生成的数据上具有低 Mean Squared Error。在推理时，我们也证明了变换器通常会预测接近优化预测器。我们的实验还表明，变换器可以在一个样本效率的方式上学习混合回归，并且对分布变化具有一定的抗预测性。我们补充了我们的实验观察，通过构造性地证明了决策理论优化程序实际上可以通过变换器来实现。”Note: Please note that the translation is in Simplified Chinese, and the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Sparsity-Preserving-Differentially-Private-Training-of-Large-Embedding-Models"><a href="#Sparsity-Preserving-Differentially-Private-Training-of-Large-Embedding-Models" class="headerlink" title="Sparsity-Preserving Differentially Private Training of Large Embedding Models"></a>Sparsity-Preserving Differentially Private Training of Large Embedding Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08357">http://arxiv.org/abs/2311.08357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Badih Ghazi, Yangsibo Huang, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang</li>
<li>for: 保护用户隐私，防止大规模矩阵模型中泄露用户个人信息。</li>
<li>methods: 提出了两种新算法DP-FEST和DP-AdaFEST，可以在私有训练大规模矩阵模型时保持梯度稀疏性，提高训练效率。</li>
<li>results: 实验结果表明，我们的算法可以在实际世界 dataset 上实现大量梯度减小（$10^6 \times$），同时保持比较高的准确率。<details>
<summary>Abstract</summary>
As the use of large embedding models in recommendation systems and language applications increases, concerns over user data privacy have also risen. DP-SGD, a training algorithm that combines differential privacy with stochastic gradient descent, has been the workhorse in protecting user privacy without compromising model accuracy by much. However, applying DP-SGD naively to embedding models can destroy gradient sparsity, leading to reduced training efficiency. To address this issue, we present two new algorithms, DP-FEST and DP-AdaFEST, that preserve gradient sparsity during private training of large embedding models. Our algorithms achieve substantial reductions ($10^6 \times$) in gradient size, while maintaining comparable levels of accuracy, on benchmark real-world datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Mean-field-variational-inference-with-the-TAP-free-energy-Geometric-and-statistical-properties-in-linear-models"><a href="#Mean-field-variational-inference-with-the-TAP-free-energy-Geometric-and-statistical-properties-in-linear-models" class="headerlink" title="Mean-field variational inference with the TAP free energy: Geometric and statistical properties in linear models"></a>Mean-field variational inference with the TAP free energy: Geometric and statistical properties in linear models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08442">http://arxiv.org/abs/2311.08442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Celentano, Zhou Fan, Licong Lin, Song Mei</li>
<li>for: study mean-field variational inference in a Bayesian linear model when the sample size n is comparable to the dimension p.</li>
<li>methods: minimize the TAP free energy, and use an Approximate Message Passing (AMP) algorithm to find the local minimizer.</li>
<li>results: the TAP free energy has a local minimizer which provides a consistent estimate of the posterior marginals, and the algorithm linearly converges to the minimizer within this local neighborhood.Here’s the text in Traditional Chinese:</li>
<li>for: 研究在高维 Bayesian 线性模型中使用 mean-field variational inference，当 sample size n 与 dimension p 相对接近时。</li>
<li>methods: 使用 TAP 自由能点来寻找最佳解，并使用 Approximate Message Passing (AMP) 算法寻找最佳解的地方最小化。</li>
<li>results: TAP 自由能点有一个地方最小化，可以提供正确的 posterior 分布 marginal，并且使用 AMP 算法可以将解导向到这个最小化中。<details>
<summary>Abstract</summary>
We study mean-field variational inference in a Bayesian linear model when the sample size n is comparable to the dimension p. In high dimensions, the common approach of minimizing a Kullback-Leibler divergence from the posterior distribution, or maximizing an evidence lower bound, may deviate from the true posterior mean and underestimate posterior uncertainty. We study instead minimization of the TAP free energy, showing in a high-dimensional asymptotic framework that it has a local minimizer which provides a consistent estimate of the posterior marginals and may be used for correctly calibrated posterior inference. Geometrically, we show that the landscape of the TAP free energy is strongly convex in an extensive neighborhood of this local minimizer, which under certain general conditions can be found by an Approximate Message Passing (AMP) algorithm. We then exhibit an efficient algorithm that linearly converges to the minimizer within this local neighborhood. In settings where it is conjectured that no efficient algorithm can find this local neighborhood, we prove analogous geometric properties for a local minimizer of the TAP free energy reachable by AMP, and show that posterior inference based on this minimizer remains correctly calibrated.
</details>
<details>
<summary>摘要</summary>
我们研究了mean-field变量推断在 bayesian 线性模型中，当样本大小 n 与维度 p 相对可观时。在高维度下，通常采用 minimum 库拉布-莱布劳分配函数或最大化证明下界来实现 posterior 分布的估计，但这可能会偏离真实 posterior mean 并低估 posterior uncertainty。我们改用 TAP 自由能的最小化，在高维度极限框架中显示了一个本地最小值，该值可以提供正确的 posterior marginals 和 correctly calibrated posterior inference。从 геометрической角度来看，TAP 自由能的 landscape 在一个广泛的扩展 neighborhood 中是强烈凹陷的，其中可以使用 Approximate Message Passing（AMP）算法来找到本地最小值。我们还提出了一种高效的算法，可以在这个本地 neighborhood 中线性征化到最小值。在某些情况下，我们 conjecture 了可能无法有效地找到本地 neighborhood，我们则证明了一个本地最小值可以通过 AMP 算法来实现，并且 posterior inference 基于这个最小值仍然正确推断。
</details></li>
</ul>
<hr>
<h2 id="Introducing-an-Improved-Information-Theoretic-Measure-of-Predictive-Uncertainty"><a href="#Introducing-an-Improved-Information-Theoretic-Measure-of-Predictive-Uncertainty" class="headerlink" title="Introducing an Improved Information-Theoretic Measure of Predictive Uncertainty"></a>Introducing an Improved Information-Theoretic Measure of Predictive Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08309">http://arxiv.org/abs/2311.08309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kajetan Schweighofer, Lukas Aichberger, Mykyta Ielanskyi, Sepp Hochreiter</li>
<li>for: 本研究旨在提高机器学习模型在实际应用中的决策能力，特别是分别知道和不知道模型的能力。</li>
<li>methods: 研究人员提出了一种新的measure of predictive uncertainty，以解决现有措施的限制。</li>
<li>results: 研究人员通过控制的 sintetic任务和ImageNet数据集的evalution，证明了新的措施的优势，其行为更加合理，在实际应用中也具有优势。<details>
<summary>Abstract</summary>
Applying a machine learning model for decision-making in the real world requires to distinguish what the model knows from what it does not. A critical factor in assessing the knowledge of a model is to quantify its predictive uncertainty. Predictive uncertainty is commonly measured by the entropy of the Bayesian model average (BMA) predictive distribution. Yet, the properness of this current measure of predictive uncertainty was recently questioned. We provide new insights regarding those limitations. Our analyses show that the current measure erroneously assumes that the BMA predictive distribution is equivalent to the predictive distribution of the true model that generated the dataset. Consequently, we introduce a theoretically grounded measure to overcome these limitations. We experimentally verify the benefits of our introduced measure of predictive uncertainty. We find that our introduced measure behaves more reasonably in controlled synthetic tasks. Moreover, our evaluations on ImageNet demonstrate that our introduced measure is advantageous in real-world applications utilizing predictive uncertainty.
</details>
<details>
<summary>摘要</summary>
使用机器学习模型进行决策需要能够区分模型所知和模型所不知。一个重要的评估模型知识的因素是量化模型预测不确定性。预测不确定性通常由巴YES插值模型（BMA）预测分布的熵来度量。然而，当前的这种预测不确定性度量存在限制。我们提供新的洞察，这种限制的原因是BMA预测分布与真实生成数据集的模型预测分布不同。因此，我们引入基于理论的预测不确定性度量，以超越这些限制。我们实验证明了我们引入的预测不确定性度量具有更合理的行为，并在控制的 sintetic任务中进行了实验证明。此外，我们在ImageNet上进行了评估，发现我们引入的预测不确定性度量在实际应用中具有优势。
</details></li>
</ul>
<hr>
<h2 id="On-Policy-Policy-Gradient-Reinforcement-Learning-Without-On-Policy-Sampling"><a href="#On-Policy-Policy-Gradient-Reinforcement-Learning-Without-On-Policy-Sampling" class="headerlink" title="On-Policy Policy Gradient Reinforcement Learning Without On-Policy Sampling"></a>On-Policy Policy Gradient Reinforcement Learning Without On-Policy Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08290">http://arxiv.org/abs/2311.08290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicholas E. Corrado, Josiah P. Hanna</li>
<li>for: 提高在做RL算法时的数据效率，避免采样错误导致的启发式学习。</li>
<li>methods: 提出一种适应性的、偏置外样本采集方法（PROPS），通过增加当前策略下的样本动作概率来减少采样错误，从而提高数据效率。</li>
<li>results: 在 MuJoCo  benchmark 任务上以及权值任务上，证明 PROPS 可以在训练过程中逐步减少采样错误，并提高偏置外样本采集法的数据效率。<details>
<summary>Abstract</summary>
On-policy reinforcement learning (RL) algorithms perform policy updates using i.i.d. trajectories collected by the current policy. However, after observing only a finite number of trajectories, on-policy sampling may produce data that fails to match the expected on-policy data distribution. This sampling error leads to noisy updates and data inefficient on-policy learning. Recent work in the policy evaluation setting has shown that non-i.i.d., off-policy sampling can produce data with lower sampling error than on-policy sampling can produce. Motivated by this observation, we introduce an adaptive, off-policy sampling method to improve the data efficiency of on-policy policy gradient algorithms. Our method, Proximal Robust On-Policy Sampling (PROPS), reduces sampling error by collecting data with a behavior policy that increases the probability of sampling actions that are under-sampled with respect to the current policy. Rather than discarding data from old policies -- as is commonly done in on-policy algorithms -- PROPS uses data collection to adjust the distribution of previously collected data to be approximately on-policy. We empirically evaluate PROPS on both continuous-action MuJoCo benchmark tasks as well as discrete-action tasks and demonstrate that (1) PROPS decreases sampling error throughout training and (2) improves the data efficiency of on-policy policy gradient algorithms. Our work improves the RL community's understanding of a nuance in the on-policy vs off-policy dichotomy: on-policy learning requires on-policy data, not on-policy sampling.
</details>
<details>
<summary>摘要</summary>
在返回学习（RL）算法中，在政策更新中使用独立同分布（i.i.d）的轨迹是常见的。然而，只observe了finite个轨迹后，在当前策略下进行on-policy sampling可能会产生数据不符合预期的on-policy数据分布。这种抽样错误会导致更新不稳定和数据不fficient。在策略评估设置下， latest work 表明，非独立、off-policy抽样可以生成比on-policy抽样更加稳定的数据。为了解决这个问题，我们介绍了一种适应的off-policy抽样方法，即PROPS。PROPS方法通过使用当前策略增加对于当前策略下尚未抽样的动作的抽样概率来减少抽样错误。不同于通常在on-policy算法中抛弃老策略下的数据，PROPS方法使用数据采集来调整先前采集的数据，使其更加接近on-policy数据分布。我们对MuJoCo continueous-action和discrete-action任务进行了实验，并证明了以下两点：1. PROPS方法在训练过程中逐渐减少抽样错误。2. PROPS方法可以提高on-policy policy gradient算法的数据效率。我们的工作有助于RL社区更好地理解on-policy学习和off-policy学习之间的区别：on-policy学习不需要on-policy抽样，而是需要on-policy数据。
</details></li>
</ul>
<hr>
<h2 id="Mixed-Attention-Network-for-Cross-domain-Sequential-Recommendation"><a href="#Mixed-Attention-Network-for-Cross-domain-Sequential-Recommendation" class="headerlink" title="Mixed Attention Network for Cross-domain Sequential Recommendation"></a>Mixed Attention Network for Cross-domain Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08272">http://arxiv.org/abs/2311.08272</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanyu-lin/man">https://github.com/guanyu-lin/man</a></li>
<li>paper_authors: Guanyu Lin, Chen Gao, Yu Zheng, Jianxin Chang, Yanan Niu, Yang Song, Kun Gai, Zhiheng Li, Depeng Jin, Yong Li, Meng Wang</li>
<li>for: 提高数据稀缺问题的现代推荐系统中的sequential推荐，特别是新用户的推荐。</li>
<li>methods: 我们提出了一种Mixed Attention Network（MAN），包括本地&#x2F;全局编码层、混合注意层和本地&#x2F;全局预测层。本地&#x2F;全局编码层用于捕捉域特定的Sequential模式，混合注意层用于捕捉本地和全局的项目相似性、序列融合和用户群组 across multiple domains。最后，本地&#x2F;全局预测层用于进一步演化和结合域特定和跨域的兴趣。</li>
<li>results: 在两个真实世界数据集（每个有两个域）上，我们的提出的模型得到了superiority。此外，我们还进行了further study，发现我们的方法和组件都是model-agnostic和effective。代码和数据可以在<a target="_blank" rel="noopener" href="https://github.com/Guanyu-Lin/MAN%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Guanyu-Lin/MAN上获取。</a><details>
<summary>Abstract</summary>
In modern recommender systems, sequential recommendation leverages chronological user behaviors to make effective next-item suggestions, which suffers from data sparsity issues, especially for new users. One promising line of work is the cross-domain recommendation, which trains models with data across multiple domains to improve the performance in data-scarce domains. Recent proposed cross-domain sequential recommendation models such as PiNet and DASL have a common drawback relying heavily on overlapped users in different domains, which limits their usage in practical recommender systems. In this paper, we propose a Mixed Attention Network (MAN) with local and global attention modules to extract the domain-specific and cross-domain information. Firstly, we propose a local/global encoding layer to capture the domain-specific/cross-domain sequential pattern. Then we propose a mixed attention layer with item similarity attention, sequence-fusion attention, and group-prototype attention to capture the local/global item similarity, fuse the local/global item sequence, and extract the user groups across different domains, respectively. Finally, we propose a local/global prediction layer to further evolve and combine the domain-specific and cross-domain interests. Experimental results on two real-world datasets (each with two domains) demonstrate the superiority of our proposed model. Further study also illustrates that our proposed method and components are model-agnostic and effective, respectively. The code and data are available at https://github.com/Guanyu-Lin/MAN.
</details>
<details>
<summary>摘要</summary>
现代推荐系统中，顺序推荐利用用户的时间序列行为来进行有效的下一个项目建议，尤其是对于新用户来说，它受到数据稀缺问题的困扰。跨Domain推荐是一条有前途的方向，它通过跨多个领域的数据来提高数据稀缺领域的性能。然而，现有的跨Domain顺序推荐模型，如PiNet和DASL，具有依赖于不同领域之间的重叠用户的限制，这限制了它们在实际推荐系统中的应用。在这篇论文中，我们提出了一种混合注意网络（MAN），它包括本地/全球注意模块来EXTRACT DOMAIN-SPECIFIC AND CROSS-DOMAIN信息。首先，我们提出了本地/全球编码层，用于捕捉不同领域的Sequential pattern。然后，我们提出了混合注意层，包括物品相似注意、序列融合注意和组prototype注意，用于捕捉本地/全球item相似性、融合本地/全球item序列和提取不同领域之间的用户组。最后，我们提出了本地/全球预测层，用于进一步演化和结合不同领域的用户兴趣。实验结果表明，我们提出的方法在两个真实世界数据集（各有两个领域）上具有优势。此外，我们还进行了进一步的研究，并证明我们的方法和组件是模型免疫的和有效的。代码和数据可以在https://github.com/Guanyu-Lin/MAN上获取。
</details></li>
</ul>
<hr>
<h2 id="Mobility-Induced-Graph-Learning-for-WiFi-Positioning"><a href="#Mobility-Induced-Graph-Learning-for-WiFi-Positioning" class="headerlink" title="Mobility-Induced Graph Learning for WiFi Positioning"></a>Mobility-Induced Graph Learning for WiFi Positioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08271">http://arxiv.org/abs/2311.08271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyuwon Han, Seung Min Yu, Seong-Lyun Kim, Seung-Woo Ko</li>
<li>for: 这篇论文的目的是提出一种基于智能手机的用户流动跟踪方法，以实现更高精度的用户位置确定。</li>
<li>methods: 该方法使用了两种不同的图构建方法，即时间驱动的移动图（TMG）和方向驱动的移动图（DMG），然后通过图 convolutional neural network（GCN）相互学习，将这两种图的信息 fusion 以实现更高精度的位置确定。</li>
<li>results: 对Field experimentResults 表明，提出的方法可以实现更高精度的用户位置确定，比如root mean square errors（RMSE）为1.398（m）和1.073（m）在自助学习和半助学习学习框架下，分别下降了27.3%和44.4%。<details>
<summary>Abstract</summary>
A smartphone-based user mobility tracking could be effective in finding his/her location, while the unpredictable error therein due to low specification of built-in inertial measurement units (IMUs) rejects its standalone usage but demands the integration to another positioning technique like WiFi positioning. This paper aims to propose a novel integration technique using a graph neural network called Mobility-INduced Graph LEarning (MINGLE), which is designed based on two types of graphs made by capturing different user mobility features. Specifically, considering sequential measurement points (MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor MPs as edges, called time-driven mobility graph (TMG). Second, a user's relatively straight transition at a constant pace when moving from one position to another can be captured by connecting the nodes on each path, called a direction-driven mobility graph (DMG). Then, we can design graph convolution network (GCN)-based cross-graph learning, where two different GCN models for TMG and DMG are jointly trained by feeding different input features created by WiFi RTTs yet sharing their weights. Besides, the loss function includes a mobility regularization term such that the differences between adjacent location estimates should be less variant due to the user's stable moving pace. Noting that the regularization term does not require ground-truth location, MINGLE can be designed under semi- and self-supervised learning frameworks. The proposed MINGLE's effectiveness is extensively verified through field experiments, showing a better positioning accuracy than benchmarks, say root mean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and semi-supervised learning cases, respectively.
</details>
<details>
<summary>摘要</summary>
用智能手机的用户流动跟踪可以有效地找到他/她的位置，但由于内置的各种各样的各种各样测量单元 (IMU) 的低精度，这种独立使用不可靠，需要与其他定位技术结合。这篇论文提出了一种新的集成技术，即用于流动图学学习 (MINGLE)，该技术基于两种不同的图， capture 用户流动特征。 Specifically, we consider sequential measurement points (MPs) as nodes, and a user's regular mobility pattern allows us to connect neighbor MPs as edges, called time-driven mobility graph (TMG). Second, a user's relatively straight transition at a constant pace when moving from one position to another can be captured by connecting the nodes on each path, called a direction-driven mobility graph (DMG). Then, we can design graph convolution network (GCN)-based cross-graph learning, where two different GCN models for TMG and DMG are jointly trained by feeding different input features created by WiFi RTTs yet sharing their weights. Besides, the loss function includes a mobility regularization term such that the differences between adjacent location estimates should be less variant due to the user's stable moving pace. Noting that the regularization term does not require ground-truth location, MINGLE can be designed under semi- and self-supervised learning frameworks. The proposed MINGLE's effectiveness is extensively verified through field experiments, showing a better positioning accuracy than benchmarks, with root mean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and semi-supervised learning cases, respectively.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-and-Powerful-Framework-for-Stable-Dynamic-Network-Embedding"><a href="#A-Simple-and-Powerful-Framework-for-Stable-Dynamic-Network-Embedding" class="headerlink" title="A Simple and Powerful Framework for Stable Dynamic Network Embedding"></a>A Simple and Powerful Framework for Stable Dynamic Network Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.09251">http://arxiv.org/abs/2311.09251</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/edwarddavis1/universal_dynamic_embedding_with_testing">https://github.com/edwarddavis1/universal_dynamic_embedding_with_testing</a></li>
<li>paper_authors: Ed Davis, Ian Gallagher, Daniel John Lawson, Patrick Rubin-Delanchy</li>
<li>for: 本文解决了动态网络嵌入的问题，即将动态网络中的节点表示为低维度空间中演化的向量。 static网络嵌入领域较为成熟，而动态网络嵌入领域相对较为初级。</li>
<li>methods: 我们提出了一种将广泛使用的静态网络嵌入方法应用于扩展 adjacency matrix，以生成可读写的动态网络嵌入。我们提供了一个理论保证，即无论嵌入维度如何，这些扩展方法都会生成稳定的嵌入，即时间和空间中的节点行为相同的节点将是可交换的。</li>
<li>results: 我们定义了一种用于评估动态网络嵌入质量的假设测试框架，并使用这个框架测试了一些虚拟网络的动态网络嵌入。我们发现，even in trivial cases, unstable methods often either conservative or encode incorrect structure。相比之下，我们的稳定 unfolded 方法不仅更容易理解，也更有力量，在比较权重方面表现更好。<details>
<summary>Abstract</summary>
In this paper, we address the problem of dynamic network embedding, that is, representing the nodes of a dynamic network as evolving vectors within a low-dimensional space. While the field of static network embedding is wide and established, the field of dynamic network embedding is comparatively in its infancy. We propose that a wide class of established static network embedding methods can be used to produce interpretable and powerful dynamic network embeddings when they are applied to the dilated unfolded adjacency matrix. We provide a theoretical guarantee that, regardless of embedding dimension, these unfolded methods will produce stable embeddings, meaning that nodes with identical latent behaviour will be exchangeable, regardless of their position in time or space. We additionally define a hypothesis testing framework which can be used to evaluate the quality of a dynamic network embedding by testing for planted structure in simulated networks. Using this, we demonstrate that, even in trivial cases, unstable methods are often either conservative or encode incorrect structure. In contrast, we demonstrate that our suite of stable unfolded methods are not only more interpretable but also more powerful in comparison to their unstable counterparts.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们讨论了动态网络嵌入问题，即将动态网络中的节点表示为低维度空间中演化的 вектор。虽然静态网络嵌入领域已经广泛发展，但动态网络嵌入领域相对较为未发展。我们建议可以使用广泛应用于静态网络嵌入的已有方法来生成可读取和强大的动态网络嵌入。我们提供了一种理论保证，即不 matter embedding dimension，使用扩展 unfolded 方法生成的嵌入都是稳定的，意味着在时间或空间上相同的latent behavior的节点都是可交换的。此外，我们定义了一个假设测试框架，可以用来评估动态网络嵌入的质量，通过测试模拟网络中的植入结构。使用这个框架，我们示出了在rivial cases中，不稳定的方法通常是保守的或者编码了错误的结构。相比之下，我们的稳定 unfolded 方法不仅更加可读取也更加强大，与不稳定的对手相比。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Explanation-for-Regression-via-Disentanglement-in-Latent-Space"><a href="#Counterfactual-Explanation-for-Regression-via-Disentanglement-in-Latent-Space" class="headerlink" title="Counterfactual Explanation for Regression via Disentanglement in Latent Space"></a>Counterfactual Explanation for Regression via Disentanglement in Latent Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08228">http://arxiv.org/abs/2311.08228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Zhao, Klaus Broelemann, Gjergji Kasneci</li>
<li>for: 本研究旨在提供一种生成可能性解释（Counterfactual Explanation，CE）的新方法，以帮助用户更好地理解和控制AI系统的预测结果。</li>
<li>methods: 本方法首先在潜在空间中分离了标签相关和标签不相关的维度，然后通过组合这些维度和预定输出生成CE。该方法的基本想法是，理想的反因搜索应该专注于标签不相关的输入特征，并建议更改到目标相关的特征。在潜在空间进行搜索可以帮助实现这个目标。</li>
<li>results: 在多个图像和表格数据集上进行了多种实验，显示了该方法与三种现有方法相比，能够更有效地返回更加靠近原始数据折衣的结果。这是高维机器学习应用中至关重要的特点。代码将在本研究发表后作为开源包make disponibles。<details>
<summary>Abstract</summary>
Counterfactual Explanations (CEs) help address the question: How can the factors that influence the prediction of a predictive model be changed to achieve a more favorable outcome from a user's perspective? Thus, they bear the potential to guide the user's interaction with AI systems since they represent easy-to-understand explanations. To be applicable, CEs need to be realistic and actionable. In the literature, various methods have been proposed to generate CEs. However, the majority of research on CEs focuses on classification problems where questions like ``What should I do to get my rejected loan approved?" are raised. In practice, answering questions like ``What should I do to increase my salary?" are of a more regressive nature. In this paper, we introduce a novel method to generate CEs for a pre-trained regressor by first disentangling the label-relevant from the label-irrelevant dimensions in the latent space. CEs are then generated by combining the label-irrelevant dimensions and the predefined output. The intuition behind this approach is that the ideal counterfactual search should focus on the label-irrelevant characteristics of the input and suggest changes toward target-relevant characteristics. Searching in the latent space could help achieve this goal. We show that our method maintains the characteristics of the query sample during the counterfactual search. In various experiments, we demonstrate that the proposed method is competitive based on different quality measures on image and tabular datasets in regression problem settings. It efficiently returns results closer to the original data manifold compared to three state-of-the-art methods, which is essential for realistic high-dimensional machine learning applications. Our code will be made available as an open-source package upon the publication of this work.
</details>
<details>
<summary>摘要</summary>
“ counterfactual explanations (CEs) 可以帮助解答：如何让预测模型的预测结果更加有利？因此，它具有导引用户与人工智能系统互动的潜力。在文献中，许多方法已经被提出来生成 CE，但大多数研究专注于分类问题，例如“我可以做什么来获得被拒绝的贷款被批准？”相比之下，在实际应用中，更有需要回归的问题，例如“我可以做什么来增加我的薪资？”这些问题是较为回归的性质。在这篇论文中，我们提出了一种新的方法来生成 CE，具体来说是在潜在空间中分解标签相关的维度和标签不相关的维度，然后将这些维度与预定的输出结合来生成 CE。我们的想法是，理想的对抗方案应该专注于标签不相关的特征，并建议更改为标签相关的特征。在潜在空间中进行对抗搜寻可以帮助 достичь这个目标。我们显示了我们的方法可以将查询样本中的特征保留在对抗搜寻中，并在不同的质量度上与三种现有的方法进行比较。结果显示，我们的方法在数据集上的表现稳定且高效，能够更好地返回更加类似于原始数据构造的结果。我们将在这篇论文发表时公开源代码。”
</details></li>
</ul>
<hr>
<h2 id="Federated-Skewed-Label-Learning-with-Logits-Fusion"><a href="#Federated-Skewed-Label-Learning-with-Logits-Fusion" class="headerlink" title="Federated Skewed Label Learning with Logits Fusion"></a>Federated Skewed Label Learning with Logits Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08202">http://arxiv.org/abs/2311.08202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuwei Wang, Runhan Li, Hao Tan, Xuefeng Jiang, Sheng Sun, Min Liu, Bo Gao, Zhiyuan Wu</li>
<li>for: 本研究旨在Addressing label distribution skew challenge in federated learning (FL) settings, where data label categories are imbalanced on each client.</li>
<li>methods: 我们提出了FedBalance方法，将calibrate local models’ logits to correct optimization bias caused by data heterogeneity. Specifically, we introduce an extra private weak learner on the client side to capture the variance of different data.</li>
<li>results: 我们的方法可以实现13% higher average accuracy compared with state-of-the-art methods.<details>
<summary>Abstract</summary>
Federated learning (FL) aims to collaboratively train a shared model across multiple clients without transmitting their local data. Data heterogeneity is a critical challenge in realistic FL settings, as it causes significant performance deterioration due to discrepancies in optimization among local models. In this work, we focus on label distribution skew, a common scenario in data heterogeneity, where the data label categories are imbalanced on each client. To address this issue, we propose FedBalance, which corrects the optimization bias among local models by calibrating their logits. Specifically, we introduce an extra private weak learner on the client side, which forms an ensemble model with the local model. By fusing the logits of the two models, the private weak learner can capture the variance of different data, regardless of their category. Therefore, the optimization direction of local models can be improved by increasing the penalty for misclassifying minority classes and reducing the attention to majority classes, resulting in a better global model. Extensive experiments show that our method can gain 13\% higher average accuracy compared with state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Modeling-Complex-Disease-Trajectories-using-Deep-Generative-Models-with-Semi-Supervised-Latent-Processes"><a href="#Modeling-Complex-Disease-Trajectories-using-Deep-Generative-Models-with-Semi-Supervised-Latent-Processes" class="headerlink" title="Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes"></a>Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08149">http://arxiv.org/abs/2311.08149</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uzh-dqbm-cmi/eustar_dgm4h">https://github.com/uzh-dqbm-cmi/eustar_dgm4h</a></li>
<li>paper_authors: Cécile Trottet, Manuel Schürch, Ahmed Allam, Imon Barua, Liubov Petelytska, Oliver Distler, Anna-Maria Hoffmann-Vold, Michael Krauthammer, the EUSTAR collaborators</li>
<li>for: 模型和分析复杂的疾病轨迹，寻找有意义的时间隐藏表示法。</li>
<li>methods: 使用深度生成时间序列模型，利用隐藏过程来解释观察到的疾病轨迹，并通过医学概念来增强可解释性。</li>
<li>results: 可以用于数据分析和临床假设测试，包括找到相似的病人和疾病分类新亚型，以及个性化在线监测和预测多变量时序序列，同时Quantification of uncertainty。<details>
<summary>Abstract</summary>
In this paper, we propose a deep generative time series approach using latent temporal processes for modeling and holistically analyzing complex disease trajectories. We aim to find meaningful temporal latent representations of an underlying generative process that explain the observed disease trajectories in an interpretable and comprehensive way. To enhance the interpretability of these latent temporal processes, we develop a semi-supervised approach for disentangling the latent space using established medical concepts. By combining the generative approach with medical knowledge, we leverage the ability to discover novel aspects of the disease while integrating medical concepts into the model. We show that the learned temporal latent processes can be utilized for further data analysis and clinical hypothesis testing, including finding similar patients and clustering the disease into new sub-types. Moreover, our method enables personalized online monitoring and prediction of multivariate time series including uncertainty quantification. We demonstrate the effectiveness of our approach in modeling systemic sclerosis, showcasing the potential of our machine learning model to capture complex disease trajectories and acquire new medical knowledge.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种深度生成时间序列方法，使用潜在的时间序列过程来模型和整体分析复杂的疾病轨迹。我们希望找到可解释的时间潜在表示，以解释观察到的疾病轨迹。为了增强这些时间潜在表示的解释力，我们开发了一种半监督的方法，用已知的医学概念来分离潜在空间。通过结合生成方法和医学知识，我们利用了发现新的疾病方面的能力，并将医学概念集成到模型中。我们表明了学习的时间潜在过程可以用于进一步的数据分析和临床假设测试，包括找到相似的病人和疾病分类。此外，我们的方法可以实现个性化的在线监测和预测多元时序列，包括不确定性评估。我们在模型系统性综合病中示cases，展示了我们的机器学习模型的潜在性，可以捕捉复杂的疾病轨迹，并获得新的医学知识。
</details></li>
</ul>
<hr>
<h2 id="Lite-it-fly-An-All-Deformable-Butterfly-Network"><a href="#Lite-it-fly-An-All-Deformable-Butterfly-Network" class="headerlink" title="Lite it fly: An All-Deformable-Butterfly Network"></a>Lite it fly: An All-Deformable-Butterfly Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08125">http://arxiv.org/abs/2311.08125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Lin, Jason Chun Lok Li, Jiajun Zhou, Binxiao Huang, Jie Ran, Ngai Wong</li>
<li>for: 这篇论文旨在提出一种基于扭曲蝴蝶（DeBut）的神经网络压缩方法，可以减少神经网络中的参数量和计算量，同时保持神经网络的性能。</li>
<li>methods: 这篇论文使用了一种名为扭曲蝴蝶（DeBut）的新方法，它可以将权重矩阵分解成一系列特殊的扭曲因子，从而实现神经网络压缩。</li>
<li>results: 这篇论文的实验结果表明，使用扭曲蝴蝶（DeBut）方法可以压缩神经网络，同时保持神经网络的性能。例如，可以将PointNet压缩到只有5%的参数和5%的性能下降。<details>
<summary>Abstract</summary>
Most deep neural networks (DNNs) consist fundamentally of convolutional and/or fully connected layers, wherein the linear transform can be cast as the product between a filter matrix and a data matrix obtained by arranging feature tensors into columns. The lately proposed deformable butterfly (DeBut) decomposes the filter matrix into generalized, butterflylike factors, thus achieving network compression orthogonal to the traditional ways of pruning or low-rank decomposition. This work reveals an intimate link between DeBut and a systematic hierarchy of depthwise and pointwise convolutions, which explains the empirically good performance of DeBut layers. By developing an automated DeBut chain generator, we show for the first time the viability of homogenizing a DNN into all DeBut layers, thus achieving an extreme sparsity and compression. Various examples and hardware benchmarks verify the advantages of All-DeBut networks. In particular, we show it is possible to compress a PointNet to < 5% parameters with < 5% accuracy drop, a record not achievable by other compression schemes.
</details>
<details>
<summary>摘要</summary>
大多数深度神经网络（DNNs）基本由卷积层和全连接层组成，其中线性变换可以被表示为权重矩阵和特征张量组成的乘法。最近提出的弹性蝴蝶（DeBut）层 decomposes the 权重矩阵 into 通用、蝴蝶形状的因子，从而实现网络压缩，与传统的减少或低级别压缩不同。这项工作揭示了DeBut层与深度first-order和点 wise卷积之间的密切关系，解释了DeBut层的实验性好表现。我们还开发了一个自动生成DeBut链的工具，实现了对DNN的同化，以实现极高的稀疏性和压缩。具体来说，我们显示了可以将PointNet压缩到<5%的参数下，且减少<5%的精度，这是其他压缩方案无法实现的纪录。
</details></li>
</ul>
<hr>
<h2 id="Understanding-learning-from-EEG-data-Combining-machine-learning-and-feature-engineering-based-on-hidden-Markov-models-and-mixed-models"><a href="#Understanding-learning-from-EEG-data-Combining-machine-learning-and-feature-engineering-based-on-hidden-Markov-models-and-mixed-models" class="headerlink" title="Understanding learning from EEG data: Combining machine learning and feature engineering based on hidden Markov models and mixed models"></a>Understanding learning from EEG data: Combining machine learning and feature engineering based on hidden Markov models and mixed models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08113">http://arxiv.org/abs/2311.08113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Rodrigues Palma, Conor Thornberry, Seán Commins, Rafael de Andrade Moral</li>
<li>for: 这个论文主要针对的是用theta振荡（4-8Hz）来描述距离学习和记忆功能的发展。</li>
<li>methods: 这篇论文使用了隐马尔可夫模型和线性混合模型来提取EEG数据中的特征。</li>
<li>results: 这篇论文发现，使用隐藏马尔可夫模型和线性混合模型来处理EEG数据，并使用深度神经网络进行分类，可以高效地分类学习者和非学习者。<details>
<summary>Abstract</summary>
Theta oscillations, ranging from 4-8 Hz, play a significant role in spatial learning and memory functions during navigation tasks. Frontal theta oscillations are thought to play an important role in spatial navigation and memory. Electroencephalography (EEG) datasets are very complex, making any changes in the neural signal related to behaviour difficult to interpret. However, multiple analytical methods are available to examine complex data structure, especially machine learning based techniques. These methods have shown high classification performance and the combination with feature engineering enhances the capability of these methods. This paper proposes using hidden Markov and linear mixed effects models to extract features from EEG data. Based on the engineered features obtained from frontal theta EEG data during a spatial navigation task in two key trials (first, last) and between two conditions (learner and non-learner), we analysed the performance of six machine learning methods (Polynomial Support Vector Machines, Non-linear Support Vector Machines, Random Forests, K-Nearest Neighbours, Ridge, and Deep Neural Networks) on classifying learner and non-learner participants. We also analysed how different standardisation methods used to pre-process the EEG data contribute to classification performance. We compared the classification performance of each trial with data gathered from the same subjects, including solely coordinate-based features, such as idle time and average speed. We found that more machine learning methods perform better classification using coordinate-based data. However, only deep neural networks achieved an area under the ROC curve higher than 80% using the theta EEG data alone. Our findings suggest that standardising the theta EEG data and using deep neural networks enhances the classification of learner and non-learner subjects in a spatial learning task.
</details>
<details>
<summary>摘要</summary>
θ振荡（4-8Hz）在空间学习和记忆功能中发挥重要作用。前rontalθ振荡被认为在空间导航和记忆中发挥重要作用。electroencephalography（EEG）数据非常复杂，因此任何与行为相关的脑电信号变化很难以解释。然而，多种分析方法可以检查复杂数据结构，特别是基于机器学习的技术。这些方法在分类性能方面表现出色，并且通过特征工程提高了这些方法的能力。这篇论文提出使用隐马尔可夫和线性混合模型提取EEG数据中的特征。基于前frontalθ振荡EEG数据在空间导航任务中的两个关键尝试（第一次和最后一次）以及两个条件（学习者和非学习者），我们分析了六种机器学习方法（多项式支持向量机器、非线性支持向量机器、随机森林、k-最近邻居、梯度和深度神经网络）在分类学习者和非学习者参与者的性能。我们还分析了不同的标准化方法如何影响分类性能。我们与同样来自同一个参与者的坐标基于特征（如空闲时间和平均速度）进行比较。我们发现更多的机器学习方法在坐标基于特征上表现出色。然而，只有深度神经网络在θEEG数据alone上达到了80%的分类精度。我们的发现表明，标准化θEEG数据和使用深度神经网络可以提高空间学习任务中学习者和非学习者的分类。
</details></li>
</ul>
<hr>
<h2 id="Evolutionary-enhanced-quantum-supervised-learning-model"><a href="#Evolutionary-enhanced-quantum-supervised-learning-model" class="headerlink" title="Evolutionary-enhanced quantum supervised learning model"></a>Evolutionary-enhanced quantum supervised learning model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08081">http://arxiv.org/abs/2311.08081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anton Simen Albino, Rodrigo Bloot, Otto M. Pires, Erick G. S. Nascimento</li>
<li>for: 提高 NISQ 设备上超vised learning 的效率和准确率</li>
<li>methods: 使用变量拓扑的量子回归circuit，通过自适应策略和多热编码的综合体系来解决 barren plateau 问题</li>
<li>results: 比较 experiments 表明，我们的演化加料逻辑模型可以减轻 barren plateau 问题，提高模型的准确率和训练效率，并在传统难以处理的 dataset 上达到更高的性能<details>
<summary>Abstract</summary>
Quantum supervised learning, utilizing variational circuits, stands out as a promising technology for NISQ devices due to its efficiency in hardware resource utilization during the creation of quantum feature maps and the implementation of hardware-efficient ansatz with trainable parameters. Despite these advantages, the training of quantum models encounters challenges, notably the barren plateau phenomenon, leading to stagnation in learning during optimization iterations. This study proposes an innovative approach: an evolutionary-enhanced ansatz-free supervised learning model. In contrast to parametrized circuits, our model employs circuits with variable topology that evolves through an elitist method, mitigating the barren plateau issue. Additionally, we introduce a novel concept, the superposition of multi-hot encodings, facilitating the treatment of multi-classification problems. Our framework successfully avoids barren plateaus, resulting in enhanced model accuracy. Comparative analysis with variational quantum classifiers from the technology's state-of-the-art reveal a substantial improvement in training efficiency and precision. Furthermore, we conduct tests on a challenging dataset class, traditionally problematic for conventional kernel machines, demonstrating a potential alternative path for achieving quantum advantage in supervised learning for NISQ era.
</details>
<details>
<summary>摘要</summary>
To address these challenges, this study proposes an innovative approach: an evolutionary-enhanced ansatz-free supervised learning model. Unlike parametrized circuits, our model uses circuits with variable topology that evolve through an elitist method, mitigating the barren plateau issue. Additionally, we introduce a novel concept, the superposition of multi-hot encodings, which facilitates the treatment of multi-classification problems.Our framework successfully avoids barren plateaus, resulting in enhanced model accuracy. Comparative analysis with variational quantum classifiers from the technology's state-of-the-art reveals a substantial improvement in training efficiency and precision. Furthermore, we conduct tests on a challenging dataset class, traditionally problematic for conventional kernel machines, demonstrating a potential alternative path for achieving quantum advantage in supervised learning for NISQ era.Translated into Simplified Chinese:量子指导学习，使用变量Circuits，在NISQ设备上表现出了优异的承袭，具有硬件资源利用的效率，在创建量子特征图和实现硬件高效的 ansatz 中使用变量Circuits。然而，量子模型的训练仍然遇到了挑战，主要表现为杯瓷平台现象，导致优化迭代中的学习停滞。为了解决这些挑战，这种研究提出了一种创新的方法：一种生化增强的 ansatz-free 指导学习模型。与 Parametrized Circuits 不同，我们的模型使用变量 topology 的Circuits，通过一种Elitist方法进行演化，从而 Mitigate the barren plateau 问题。此外，我们还提出了一种新的概念，即多个热门编码的超position，可以方便处理多类别问题。我们的框架成功避免了杯瓷平台问题，从而实现了提高的模型准确率。与现代量子分类器的比较分析表明，我们的模型在训练效率和精度上具有明显的改善。此外，我们还在一个传统上难以处理的数据集类型上进行了测试，表明了量子优势在指导学习中的可能性。
</details></li>
</ul>
<hr>
<h2 id="Communication-Constrained-Bayesian-Active-Knowledge-Distillation"><a href="#Communication-Constrained-Bayesian-Active-Knowledge-Distillation" class="headerlink" title="Communication-Constrained Bayesian Active Knowledge Distillation"></a>Communication-Constrained Bayesian Active Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08053">http://arxiv.org/abs/2311.08053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor Croisfelt, Shashi Raj Pandey, Osvaldo Simeone, Petar Popovski</li>
<li>For:	+ The paper addresses key questions in active learning settings with a remote teacher and constrained communication channels.	+ The goal is to reduce the number of required communication rounds while acquiring the most useful information.* Methods:	+ The paper introduces Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD), which integrates Bayesian active learning with compression via a linear mix-up mechanism.	+ The method selects batches of inputs based on their epistemic uncertainty, addressing “confirmation bias” and reducing the number of required communication rounds.	+ The proposed mix-up compression strategy is integrated with the epistemic uncertainty-based active batch selection process.* Results:	+ The proposed CC-BAKD protocol is shown to be effective in reducing the number of required communication rounds while acquiring the most useful information.	+ The method is evaluated on several benchmark datasets and is found to outperform existing active learning methods in terms of communication efficiency and accuracy.Here is the answer in Simplified Chinese:* For:	+ 本文Addresses key questions in active learning settings with a remote teacher and constrained communication channels.	+ 目的是尽量减少通信轮数，同时获取最有用的信息。* Methods:	+ 本文引入Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD)，它将Bayesian active learning与压缩相结合，使用线性混合机制。	+ 方法选择批处理输入，基于其 epistemic uncertainty，解决”confirmation bias”问题，减少通信轮数。	+ 提议的混合压缩策略与 epistemic uncertainty-based active batch selection 进程相结合。* Results:	+ 提议的 CC-BAKD 协议被证明可以减少通信轮数，同时获取最有用的信息。	+ 方法在多个 benchmark 数据集上进行评估，与现有的活动学习方法相比，在通信效率和准确率方面表现出色。<details>
<summary>Abstract</summary>
Consider an active learning setting in which a learner has a training set with few labeled examples and a pool set with many unlabeled inputs, while a remote teacher has a pre-trained model that is known to perform well for the learner's task. The learner actively transmits batches of unlabeled inputs to the teacher through a constrained communication channel for labeling. This paper addresses the following key questions: (i) Active batch selection: Which batch of inputs should be sent to the teacher to acquire the most useful information and thus reduce the number of required communication rounds? (ii) Batch encoding: How do we encode the batch of inputs for transmission to the teacher to reduce the communication resources required at each round? We introduce Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD), a novel protocol that integrates Bayesian active learning with compression via a linear mix-up mechanism. Bayesian active learning selects the batch of inputs based on their epistemic uncertainty, addressing the "confirmation bias" that is known to increase the number of required communication rounds. Furthermore, the proposed mix-up compression strategy is integrated with the epistemic uncertainty-based active batch selection process to reduce the communication overhead per communication round.
</details>
<details>
<summary>摘要</summary>
请注意，以下文本将使用简化中文。在本文中，我们考虑了一个活动学习 Setting，其中学习者 Possesses 一个具有少量标注示例的训练集，以及一个包含多个未标注输入的池集。而远程教师 Possesses 一个预训练的模型，该模型在学习者的任务中已知perform well。学习者可以通过一个受限的通信渠道向教师发送批处理的未标注输入，以获得标签。本文解决以下关键问题：(i) 活动批处理：哪些批处理 Should 被发送到教师以获得最有用的信息，从而减少通信轮数？(ii) 批处理编码：如何编码批处理以便在每次通信中减少通信资源？我们提出了一种名为 Communication-Constrained Bayesian Active Knowledge Distillation (CC-BAKD) 的协议，该协议将感知活动学习与压缩相结合，通过线性混合机制来实现。感知活动学习可以根据输入的 épistémic 不确定性选择批处理，这可以避免“确irmation bias”，这种情况可能增加通信轮数。此外，我们还将混合压缩策略与 épistémic 不确定性基于的活动批处理选择过程相结合，以减少每次通信轮数中的通信资源。
</details></li>
</ul>
<hr>
<h2 id="Velocity-Based-Channel-Charting-with-Spatial-Distribution-Map-Matching"><a href="#Velocity-Based-Channel-Charting-with-Spatial-Distribution-Map-Matching" class="headerlink" title="Velocity-Based Channel Charting with Spatial Distribution Map Matching"></a>Velocity-Based Channel Charting with Spatial Distribution Map Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08016">http://arxiv.org/abs/2311.08016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Stahlke, George Yammine, Tobias Feigl, Bjoern M. Eskofier, Christopher Mutschler</li>
<li>for: 本研究 targets at improving the positioning performance in challenging, non-line-of-sight (NLoS) dominated indoor environments using fingerprint-based localization.</li>
<li>methods:  alternatively, the paper proposes a novel framework that uses channel-charting to avoid the labeling effort required in fingerprinting models. The approach uses velocity information and topological map information to transform the channel charts into real coordinates.</li>
<li>results:  experiments conducted on two real-world datasets using 5G and distributed single-input&#x2F;multiple-output system (SIMO) radio systems show that the proposed approach achieves similar position accuracies even with noisy velocity estimates and coarse map information.<details>
<summary>Abstract</summary>
Fingerprint-based localization improves the positioning performance in challenging, non-line-of-sight (NLoS) dominated indoor environments. However, fingerprinting models require an expensive life-cycle management including recording and labeling of radio signals for the initial training and regularly at environmental changes. Alternatively, channel-charting avoids this labeling effort as it implicitly associates relative coordinates to the recorded radio signals. Then, with reference real-world coordinates (positions) we can use such charts for positioning tasks. However, current channel-charting approaches lag behind fingerprinting in their positioning accuracy and still require reference samples for localization, regular data recording and labeling to keep the models up to date. Hence, we propose a novel framework that does not require reference positions. We only require information from velocity information, e.g., from pedestrian dead reckoning or odometry to model the channel charts, and topological map information, e.g., a building floor plan, to transform the channel charts into real coordinates. We evaluate our approach on two different real-world datasets using 5G and distributed single-input/multiple-output system (SIMO) radio systems. Our experiments show that even with noisy velocity estimates and coarse map information, we achieve similar position accuracies
</details>
<details>
<summary>摘要</summary>
fingerprint-based 位置定位在具有强度不良、非直线视野（NLoS）的室内环境中提高位置性能。然而， fingerprinting 模型需要成本的生命周期管理，包括初始训练和环境变化时的记录和标注。 alternatively， channel-charting 可以避免这些标注努力，因为它将记录的电磁信号相对坐标相关联。然后，使用参考世界坐标（位置），我们可以使用这些图表进行位置定位任务。然而，现有的 channel-charting 方法在位置精度方面落后于 fingerprinting，并且仍需要参考样本 для地图更新和定位任务。因此，我们提出了一种新的框架，不需要参考位置。我们只需要 velocity 信息，例如人行速度测量或 odometry，来模型电磁信号图表，以及建筑层次图信息，例如大楼层次图，将电磁信号图表转换成真实坐标。我们在两个不同的实际数据集上进行了5G和分布式单输入多输出系统（SIMO）电磁系统的实验。我们的实验结果表明，即使velocity 估计较准噪和地图信息较粗糙，我们仍可以达到类似的位置精度。
</details></li>
</ul>
<hr>
<h2 id="Out-of-Distribution-Knowledge-Distillation-via-Confidence-Amendment"><a href="#Out-of-Distribution-Knowledge-Distillation-via-Confidence-Amendment" class="headerlink" title="Out-of-Distribution Knowledge Distillation via Confidence Amendment"></a>Out-of-Distribution Knowledge Distillation via Confidence Amendment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07975">http://arxiv.org/abs/2311.07975</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lawliet-zzl/ca">https://github.com/lawliet-zzl/ca</a></li>
<li>paper_authors: Zhilin Zhao, Longbing Cao, Yixuan Zhang</li>
<li>for: 本文旨在提出一种基于标准网络的外围数据探测方法，以确保网络的可靠性和可靠性。</li>
<li>methods: 本文提出了一种基于标准网络的OOD知识储存框架，可以在没有ID训练数据的情况下使用。这个框架利用标准网络中对OOD样本的敏感知识来raft一个适用于分类ID和OOD样本的 binary 分类器。为了实现这一点，本文提出了一种增强信任修正（CA）技术，可以将OOD样本转换成ID样本，并同时修正来自标准网络的预测信任值。</li>
<li>results: 经验表明，提出的方法能够有效地探测外围数据，并且对不同的数据集和网络架构进行了广泛的验证。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is essential in identifying test samples that deviate from the in-distribution (ID) data upon which a standard network is trained, ensuring network robustness and reliability. This paper introduces OOD knowledge distillation, a pioneering learning framework applicable whether or not training ID data is available, given a standard network. This framework harnesses OOD-sensitive knowledge from the standard network to craft a binary classifier adept at distinguishing between ID and OOD samples. To accomplish this, we introduce Confidence Amendment (CA), an innovative methodology that transforms an OOD sample into an ID one while progressively amending prediction confidence derived from the standard network. This approach enables the simultaneous synthesis of both ID and OOD samples, each accompanied by an adjusted prediction confidence, thereby facilitating the training of a binary classifier sensitive to OOD. Theoretical analysis provides bounds on the generalization error of the binary classifier, demonstrating the pivotal role of confidence amendment in enhancing OOD sensitivity. Extensive experiments spanning various datasets and network architectures confirm the efficacy of the proposed method in detecting OOD samples.
</details>
<details>
<summary>摘要</summary>
非常赞！这篇论文引入了对外部数据（OOD）探测的探索，以确保网络的可靠性和可靠性。这篇论文介绍了一种新的学习框架，可以不需要训练标准网络的数据，即使没有标准数据，也可以学习OOD敏感知识。这个框架利用标准网络的OOD敏感知识来编制一个二分类器，能够 отличи ID 和 OOD 样本。为此，我们提出了一种创新的方法——信任修正（CA），可以将 OOD 样本转化成 ID 样本，同时对标准网络的预测结果进行修正。这种方法允许同时生成 ID 和 OOD 样本，每个样本都 accompanied by 修正后的预测信任度，从而使得二分类器可以具备对 OOD 的敏感性。我们的理论分析表明， confidence 修正对二分类器的泛化误差具有约束作用，从而提高 OOD 敏感性。我们的实验结果表明，提出的方法在不同的数据集和网络架构下具有普遍的效果。
</details></li>
</ul>
<hr>
<h2 id="Higher-Order-Expander-Graph-Propagation"><a href="#Higher-Order-Expander-Graph-Propagation" class="headerlink" title="Higher-Order Expander Graph Propagation"></a>Higher-Order Expander Graph Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07966">http://arxiv.org/abs/2311.07966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Christie, Yu He</li>
<li>for: 本文旨在提高图像通信的精度，解决图像通信中的过度压缩问题。</li>
<li>methods: 本文提出了两种基于分别的 constructions 的方法，以便在图像通信中捕捉更高阶的相关性。</li>
<li>results: 实验结果表明，使用高阶扩展图在图像通信中可以提高精度，并且可以更好地捕捉复杂数据中的相关性。<details>
<summary>Abstract</summary>
Graph neural networks operate on graph-structured data via exchanging messages along edges. One limitation of this message passing paradigm is the over-squashing problem. Over-squashing occurs when messages from a node's expanded receptive field are compressed into fixed-size vectors, potentially causing information loss. To address this issue, recent works have explored using expander graphs, which are highly-connected sparse graphs with low diameters, to perform message passing. However, current methods on expander graph propagation only consider pair-wise interactions, ignoring higher-order structures in complex data. To explore the benefits of capturing these higher-order correlations while still leveraging expander graphs, we introduce higher-order expander graph propagation. We propose two methods for constructing bipartite expanders and evaluate their performance on both synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary>
图 neural networks 操作在图结构数据上，通过Edge上的信息交换来实现。一个限制是过度压缩问题，当节点的扩展接受范围上的信息被压缩成固定大小的矢量时，可能导致信息损失。为解决这个问题，最近的工作已经探索使用扩展图，这些图是高度连接的稀疏图，但具有低的矩形维度。然而，现有的扩展图传播方法只考虑对角交互，忽略复杂数据中的更高阶相关性。为了探索在扩展图上capture这些更高阶相关性的同时，我们引入更高级的扩展图传播方法。我们提出了两种方法来构建半个bijective expander，并评估了它们在 sintetic 和实际数据上的性能。
</details></li>
</ul>
<hr>
<h2 id="Language-Models-are-Better-Bug-Detector-Through-Code-Pair-Classification"><a href="#Language-Models-are-Better-Bug-Detector-Through-Code-Pair-Classification" class="headerlink" title="Language Models are Better Bug Detector Through Code-Pair Classification"></a>Language Models are Better Bug Detector Through Code-Pair Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07957">http://arxiv.org/abs/2311.07957</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kamel773/code_pair_classification">https://github.com/kamel773/code_pair_classification</a></li>
<li>paper_authors: Kamel Alrashedy</li>
<li>for:  This paper is written for researchers and developers who are interested in using large language models (LLMs) for code generation and understanding, and who want to explore alternative methods for fine-tuning these models that do not require a large labeled dataset.</li>
<li>methods:  The paper proposes a code-pair classification task as an alternative to fine-tuning LLMs for bug detection and repair. In this task, both the buggy and non-buggy versions of the code are given to the model, and the model identifies the buggy ones.</li>
<li>results:  The paper evaluates the code-pair classification task in a real-world dataset of bug detection and uses two of the most powerful LLMs. The results show that the model can often pick the buggy from the non-buggy version of the code, and that the code-pair classification task is much easier compared to the traditional method of being given a snippet and deciding if and where a bug exists.<details>
<summary>Abstract</summary>
Large language models (LLMs) such as GPT-3.5 and CodeLlama are powerful models for code generation and understanding. Fine-tuning these models comes with a high computational cost and requires a large labeled dataset. Alternatively, in-context learning techniques allow models to learn downstream tasks with only a few examples. Recently, researchers have shown how in-context learning performs well in bug detection and repair. In this paper, we propose code-pair classification task in which both the buggy and non-buggy versions are given to the model, and the model identifies the buggy ones. We evaluate our task in real-world dataset of bug detection and two most powerful LLMs. Our experiments indicate that an LLM can often pick the buggy from the non-buggy version of the code, and the code-pair classification task is much easier compared to be given a snippet and deciding if and where a bug exists.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如GPT-3.5和CodeLlama具有代码生成和理解的能力。微调这些模型的计算成本高，需要大量标注数据。 Alternatively，在上下文学习技术可以让模型在只需几个示例下学习下游任务。近期，研究人员表明，在bug检测和修复中，在上下文学习表现出色。在这篇论文中，我们提议代码对 Classification任务，给模型提供了buggy和非buggy两个版本的代码，并让模型标识buggy版本。我们在实际世界的漏斗检测数据集上进行了实验，并使用了两个最强的LLM进行评估。我们的实验表明，一个LLM可以很快地从buggy和非buggy两个版本中选择buggy版本，而代码对 Classification任务比给定一个示例并决定其中是否存在漏洞更加容易。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-and-Simple-Algorithm-for-computing-the-MLE-of-Amplitude-Density-Function-Parameters"><a href="#A-Fast-and-Simple-Algorithm-for-computing-the-MLE-of-Amplitude-Density-Function-Parameters" class="headerlink" title="A Fast and Simple Algorithm for computing the MLE of Amplitude Density Function Parameters"></a>A Fast and Simple Algorithm for computing the MLE of Amplitude Density Function Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07951">http://arxiv.org/abs/2311.07951</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Teimouri</li>
<li>for: 这paper是为了提出一种快速和准确地计算振荡分布参数的方法。</li>
<li>methods: 该方法使用了两个简单的变换将振荡数据 проек到了水平和垂直轴上，并证明了这些项目后的数据遵循zero-location symmetric α-stale分布，可以快速计算MLE。</li>
<li>results: 通过实验研究和分析两组实际的雷达数据，提出的方法可以准确地计算振荡分布参数。<details>
<summary>Abstract</summary>
Over the last decades, the family of $\alpha$-stale distributions has proven to be useful for modelling in telecommunication systems. Particularly, in the case of radar applications, finding a fast and accurate estimation for the amplitude density function parameters appears to be very important. In this work, the maximum likelihood estimator (MLE) is proposed for parameters of the amplitude distribution. To do this, the amplitude data are \emph{projected} on the horizontal and vertical axes using two simple transformations. It is proved that the \emph{projected} data follow a zero-location symmetric $\alpha$-stale distribution for which the MLE can be computed quite fast. The average of computed MLEs based on two \emph{projections} is considered as estimator for parameters of the amplitude distribution. Performance of the proposed \emph{projection} method is demonstrated through simulation study and analysis of two sets of real radar data.
</details>
<details>
<summary>摘要</summary>
Note:* "α-stale" should be translated as "α-稳定" (alpha-stable) in Simplified Chinese.* "amplitude distribution" should be translated as "幅度分布" (amplitude distribution) in Simplified Chinese.* "maximum likelihood estimator" should be translated as "最大可能性估计" (maximum likelihood estimator) in Simplified Chinese.* "projections" should be translated as "投影" (projections) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Finding-Inductive-Loop-Invariants-using-Large-Language-Models"><a href="#Finding-Inductive-Loop-Invariants-using-Large-Language-Models" class="headerlink" title="Finding Inductive Loop Invariants using Large Language Models"></a>Finding Inductive Loop Invariants using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07948">http://arxiv.org/abs/2311.07948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adharsh Kamath, Aditya Senthilnathan, Saikat Chakraborty, Pantazis Deligiannis, Shuvendu K. Lahiri, Akash Lal, Aseem Rastogi, Subhajit Roy, Rahul Sharma</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）是否可以提供一种新的自动程序验证解决方案。</li>
<li>methods: 本论文首先绘制了一个适用于程序循环的验证问题集，然后设计了一个使用LLM获取循环 inductive invariants的提问。最后， authors 使用一种有效的符号工具和LLM的组合来验证这些 invariants，并与纯 Symbolic 基准进行比较。</li>
<li>results: 研究结果表明，LLMs 可以帮助提高自动程序验证的状态艺术。<details>
<summary>Abstract</summary>
Loop invariants are fundamental to reasoning about programs with loops. They establish properties about a given loop's behavior. When they additionally are inductive, they become useful for the task of formal verification that seeks to establish strong mathematical guarantees about program's runtime behavior. The inductiveness ensures that the invariants can be checked locally without consulting the entire program, thus are indispensable artifacts in a formal proof of correctness. Finding inductive loop invariants is an undecidable problem, and despite a long history of research towards practical solutions, it remains far from a solved problem. This paper investigates the capabilities of the Large Language Models (LLMs) in offering a new solution towards this old, yet important problem. To that end, we first curate a dataset of verification problems on programs with loops. Next, we design a prompt for exploiting LLMs, obtaining inductive loop invariants, that are checked for correctness using sound symbolic tools. Finally, we explore the effectiveness of using an efficient combination of a symbolic tool and an LLM on our dataset and compare it against a purely symbolic baseline. Our results demonstrate that LLMs can help improve the state-of-the-art in automated program verification.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>循环 invariants 是程序逻辑的基础知识。它们确定了循环的行为特性。当加上 inductive 性时，它们变得有用于形式验证，以确保程序的运行时行为具有强数学保证。 inductiveness  Ensures that the invariants can be checked locally without consulting the entire program, making them indispensable artifacts in a formal proof of correctness. 寻找 inductive loop invariants 是一个不可解决的问题，尽管有长期的研究努力，它仍然远未解决。这篇文章 investigate LLMs 在提供一个新的解决方案方面的能力。为此，我们首先筛选了循环逻辑问题的数据集。然后，我们设计了一个用于利用 LLMs 获取 inductive loop invariants 的 prompt，并使用 зву symbox 的可靠工具进行检查。最后，我们研究了使用一种精efficient的组合，包括一种可靠的符号工具和一种 LLM，对我们的数据集进行检查，并与纯symbolic 基准进行比较。我们的结果表明，LLMs 可以帮助提高自动程序验证的状态。
</details></li>
</ul>
<hr>
<h2 id="Clinical-Characteristics-and-Laboratory-Biomarkers-in-ICU-admitted-Septic-Patients-with-and-without-Bacteremia"><a href="#Clinical-Characteristics-and-Laboratory-Biomarkers-in-ICU-admitted-Septic-Patients-with-and-without-Bacteremia" class="headerlink" title="Clinical Characteristics and Laboratory Biomarkers in ICU-admitted Septic Patients with and without Bacteremia"></a>Clinical Characteristics and Laboratory Biomarkers in ICU-admitted Septic Patients with and without Bacteremia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08433">http://arxiv.org/abs/2311.08433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwon Baek, Seung Jun Lee</li>
<li>for: 这个研究是为了评估医学实验室标记物的预测力，以优化预测模型，提高抗血症患者中血液感染的预测精度。</li>
<li>methods: 这是一个逆向协调研究，使用多变量 logsitic 回归分析对各种实验室标记物进行了独立分析，并将其结果用于建立预测模型。</li>
<li>results: 研究发现， combinig PCT、bilirubin、NLR、板块、氯酸、ESR和GCS 分数可以提高预测模型的准确性（AUC&#x3D;0.907，95%CI：0.843-0.956），并发现血液感染和死亡率之间存在高度相关性（0.004）。<details>
<summary>Abstract</summary>
Few studies have investigated the diagnostic utilities of biomarkers for predicting bacteremia among septic patients admitted to intensive care units (ICU). Therefore, this study evaluated the prediction power of laboratory biomarkers to utilize those markers with high performance to optimize the predictive model for bacteremia. This retrospective cross-sectional study was conducted at the ICU department of Gyeongsang National University Changwon Hospital in 2019. Adult patients qualifying SEPSIS-3 (increase in sequential organ failure score greater than or equal to 2) criteria with at least two sets of blood culture were selected. Collected data was initially analyzed independently to identify the significant predictors, which was then used to build the multivariable logistic regression (MLR) model. A total of 218 patients with 48 cases of true bacteremia were analyzed in this research. Both CRP and PCT showed a substantial area under the curve (AUC) value for discriminating bacteremia among septic patients (0.757 and 0.845, respectively). To further enhance the predictive accuracy, we combined PCT, bilirubin, neutrophil lymphocyte ratio (NLR), platelets, lactic acid, erythrocyte sedimentation rate (ESR), and Glasgow Coma Scale (GCS) score to build the predictive model with an AUC of 0.907 (95% CI, 0.843 to 0.956). In addition, a high association between bacteremia and mortality rate was discovered through the survival analysis (0.004). While PCT is certainly a useful index for distinguishing patients with and without bacteremia by itself, our MLR model indicates that the accuracy of bacteremia prediction substantially improves by the combined use of PCT, bilirubin, NLR, platelets, lactic acid, ESR, and GCS score.
</details>
<details>
<summary>摘要</summary>
几个研究已经研究了在医院 intensivist 部门（ICU）中预测血液感染的生物标志物的 диагности效果。因此，这个研究检验了医学实验室中的标志物是否可以提高预测模型的性能。这是一项在2019年在江原国立大学昌原医院ICU部门进行的回顾性跨sectional研究。选择符合SEPSIS-3（增加序列器衰竭分数大于或等于2）标准的成人患者，并取得至少两组血液文化，并分析了这些数据以确定主要预测变量。共分析了218名患者，其中有48例真血液感染。CRP和PCT都显示了较高的区间 beneath the curve（AUC）值，用于分别患者中的血液感染（0.757和0.845）。为了进一步提高预测准确性，我们将PCT、bilirubin、neutrophil lymphocyte ratio（NLR）、platelets、lactic acid、erythrocyte sedimentation rate（ESR）和Glasgow Coma Scale（GCS）分数组合以建立预测模型，AUC为0.907（95% CI，0.843-0.956）。此外，我们还发现了血液感染和死亡率之间的高度相关性，通过生存分析（0.004）。虽然PCT是一个有用的指标，可以单独分别患者中的血液感染，但我们的多变量Logistic regression模型表明，通过合并PCT、bilirubin、NLR、platelets、lactic acid、ESR和GCS分数，预测血液感染的准确性可以得到显著提高。
</details></li>
</ul>
<hr>
<h2 id="Discretized-Distributed-Optimization-over-Dynamic-Digraphs"><a href="#Discretized-Distributed-Optimization-over-Dynamic-Digraphs" class="headerlink" title="Discretized Distributed Optimization over Dynamic Digraphs"></a>Discretized Distributed Optimization over Dynamic Digraphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07939">http://arxiv.org/abs/2311.07939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Doostmohammadian, Wei Jiang, Muwahida Liaquat, Alireza Aghasi, Houman Zarrabi</li>
<li>for: 这篇论文主要用于分布式优化问题，具体来说是在动态指向图上进行分布式学习。</li>
<li>methods: 这篇论文使用了分布式优化算法，该算法可以在具有变化网络拓扑的情况下进行分布式学习。</li>
<li>results: 这篇论文提出了一种不需要随机权重设计的分布式优化方法，并且证明了该方法的动态稳定性和收敛性。<details>
<summary>Abstract</summary>
We consider a discrete-time model of continuous-time distributed optimization over dynamic directed-graphs (digraphs) with applications to distributed learning. Our optimization algorithm works over general strongly connected dynamic networks under switching topologies, e.g., in mobile multi-agent systems and volatile networks due to link failures. Compared to many existing lines of work, there is no need for bi-stochastic weight designs on the links. The existing literature mostly needs the link weights to be stochastic using specific weight-design algorithms needed both at the initialization and at all times when the topology of the network changes. This paper eliminates the need for such algorithms and paves the way for distributed optimization over time-varying digraphs. We derive the bound on the gradient-tracking step-size and discrete time-step for convergence and prove dynamic stability using arguments from consensus algorithms, matrix perturbation theory, and Lyapunov theory. This work, particularly, is an improvement over existing stochastic-weight undirected networks in case of link removal or packet drops. This is because the existing literature may need to rerun time-consuming and computationally complex algorithms for stochastic design, while the proposed strategy works as long as the underlying network is weight-symmetric and balanced. The proposed optimization framework finds applications to distributed classification and learning.
</details>
<details>
<summary>摘要</summary>
我们考虑一个精简时间模型的连续时间分布式优化运算在动态指向グラフ（digraph）上，具体是适用于分布式学习。我们的优化算法在一般强连接动态网络上运行，包括移动多智能系统和不稳定网络，因为链接失败而导致网络 topology 的变化。与许多现有的研究不同，我们不需要链接上的两侧可能性检测，即链接上的偏振量设计。现有文献通常需要在初始化和网络 topology 变化时进行链接重新设计，而我们的方法则没有这个需求。这篇文章提供了关于步进大小和精简时间步骤的下界，并证明了动态稳定性使用协议分析、矩阵扭转理论和Lyapunov理论。这个工作特别是在当链接失败或封包损失时，比现有的随机链接网络优化更好。这是因为现有文献可能需要在网络 topology 变化时重新跑时间consuming和computationally Complex的算法，而我们的策略则可以在网络 weight-symmetric 和均衡的情况下运行。我们的优化框架具有应用于分布式分类和学习的实际应用。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Heterogeneous-Graph-Variational-Autoencoders"><a href="#Self-supervised-Heterogeneous-Graph-Variational-Autoencoders" class="headerlink" title="Self-supervised Heterogeneous Graph Variational Autoencoders"></a>Self-supervised Heterogeneous Graph Variational Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07929">http://arxiv.org/abs/2311.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yige Zhao, Jianxiang Yu, Yao Cheng, Chengcheng Yu, Yiding Liu, Xiang Li, Shuaiqiang Wang</li>
<li>for:  Addressing the problems of missing attributes, inaccurate attributes, and scarce labels in Heterogeneous Information Networks (HINs) using a generative self-supervised model called SHAVA.</li>
<li>methods:  SHAVA uses a variational graph autoencoder framework to learn both node-level and attribute-level embeddings in the encoder, and reconstructs both links and attributes in the decoder. It generates an initial low-dimensional representation matrix for all nodes, which is used to reconstruct raw features of attributed nodes and rectify inaccurate attributes.</li>
<li>results:  SHAVA is shown to be superior in tackling HINs with missing and inaccurate attributes, outperforming existing heterogeneous graph neural networks (HGNNs) in extensive experiments.<details>
<summary>Abstract</summary>
Heterogeneous Information Networks (HINs), which consist of various types of nodes and edges, have recently demonstrated excellent performance in graph mining. However, most existing heterogeneous graph neural networks (HGNNs) ignore the problems of missing attributes, inaccurate attributes and scarce labels for nodes, which limits their expressiveness. In this paper, we propose a generative self-supervised model SHAVA to address these issues simultaneously. Specifically, SHAVA first initializes all the nodes in the graph with a low-dimensional representation matrix. After that, based on the variational graph autoencoder framework, SHAVA learns both node-level and attribute-level embeddings in the encoder, which can provide fine-grained semantic information to construct node attributes. In the decoder, SHAVA reconstructs both links and attributes. Instead of directly reconstructing raw features for attributed nodes, SHAVA generates the initial low-dimensional representation matrix for all the nodes, based on which raw features of attributed nodes are further reconstructed to leverage accurate attributes. In this way, SHAVA can not only complete informative features for non-attributed nodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct extensive experiments to show the superiority of SHAVA in tackling HINs with missing and inaccurate attributes.
</details>
<details>
<summary>摘要</summary>
《异类信息网络（HIN）》，它们由多种类型的节点和边组成，在图矿采取中表现出色。然而，现有的多态图神经网络（HGNN）通常忽视节点缺失属性、不准确属性以及节点罕见标签的问题，这限制了它们的表达能力。在这篇论文中，我们提议一种生成自我超级vised模型SHAVA，可以同时解决这些问题。SHAVA的实现方式如下：首先，它将所有图中节点初始化为一个低维度表示矩阵。然后，基于变量图自动encoder框架，SHAVA学习了节点级别和属性级别的嵌入表示。在decoder中，SHAVA重建了链接和属性。而不是直接重建Raw特征 для已有标签的节点，SHAVA将生成所有节点的初始低维度表示矩阵，基于该矩阵， Raw特征的已有标签节点进行进一步重建，以利用准确的属性。这种方式可以不仅为非已有标签节点提供有用的特征，还可以修正已有标签节点的不准确属性。最后，我们进行了广泛的实验，以证明SHAVA在面临HINs中缺失和不准确的属性时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-Conditional-Diffusion-Models-for-Versatile-Spatiotemporal-Turbulence-Generation"><a href="#Bayesian-Conditional-Diffusion-Models-for-Versatile-Spatiotemporal-Turbulence-Generation" class="headerlink" title="Bayesian Conditional Diffusion Models for Versatile Spatiotemporal Turbulence Generation"></a>Bayesian Conditional Diffusion Models for Versatile Spatiotemporal Turbulence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07896">http://arxiv.org/abs/2311.07896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Gao, Xu Han, Xiantao Fan, Luning Sun, Li-Ping Liu, Lian Duan, Jian-Xun Wang</li>
<li>for: 用于生成随机的爆炸流动</li>
<li>methods: 使用泛化扩散模型生成随机流动，并提供了一种基于梯度的Conditional sampling方法来生成长程流动序列</li>
<li>results: 通过一系列数值实验，证明了该方法可以生成高精度、多样化的爆炸流动，包括LES模拟的快速流动序列、各种异常流动和高速边层流动等。<details>
<summary>Abstract</summary>
Turbulent flows have historically presented formidable challenges to predictive computational modeling. Traditional numerical simulations often require vast computational resources, making them infeasible for numerous engineering applications. As an alternative, deep learning-based surrogate models have emerged, offering data-drive solutions. However, these are typically constructed within deterministic settings, leading to shortfall in capturing the innate chaotic and stochastic behaviors of turbulent dynamics. We introduce a novel generative framework grounded in probabilistic diffusion models for versatile generation of spatiotemporal turbulence. Our method unifies both unconditional and conditional sampling strategies within a Bayesian framework, which can accommodate diverse conditioning scenarios, including those with a direct differentiable link between specified conditions and generated unsteady flow outcomes, and scenarios lacking such explicit correlations. A notable feature of our approach is the method proposed for long-span flow sequence generation, which is based on autoregressive gradient-based conditional sampling, eliminating the need for cumbersome retraining processes. We showcase the versatile turbulence generation capability of our framework through a suite of numerical experiments, including: 1) the synthesis of LES simulated instantaneous flow sequences from URANS inputs; 2) holistic generation of inhomogeneous, anisotropic wall-bounded turbulence, whether from given initial conditions, prescribed turbulence statistics, or entirely from scratch; 3) super-resolved generation of high-speed turbulent boundary layer flows from low-resolution data across a range of input resolutions. Collectively, our numerical experiments highlight the merit and transformative potential of the proposed methods, making a significant advance in the field of turbulence generation.
</details>
<details>
<summary>摘要</summary>
historically, turbulent flows have presented significant challenges to predictive computational modeling. traditional numerical simulations often require vast computational resources, making them infeasible for many engineering applications. as an alternative, deep learning-based surrogate models have emerged, offering data-driven solutions. however, these are typically constructed within deterministic settings, leading to a shortfall in capturing the innate chaotic and stochastic behaviors of turbulent dynamics.we introduce a novel generative framework grounded in probabilistic diffusion models for versatile generation of spatiotemporal turbulence. our method unifies both unconditional and conditional sampling strategies within a bayesian framework, which can accommodate diverse conditioning scenarios, including those with a direct differentiable link between specified conditions and generated unsteady flow outcomes, and scenarios lacking such explicit correlations. a notable feature of our approach is the method proposed for long-span flow sequence generation, which is based on autoregressive gradient-based conditional sampling, eliminating the need for cumbersome retraining processes.we showcase the versatile turbulence generation capability of our framework through a suite of numerical experiments, including:1. the synthesis of LES simulated instantaneous flow sequences from URANS inputs;2. holistic generation of inhomogeneous, anisotropic wall-bounded turbulence, whether from given initial conditions, prescribed turbulence statistics, or entirely from scratch;3. super-resolved generation of high-speed turbulent boundary layer flows from low-resolution data across a range of input resolutions.collectively, our numerical experiments highlight the merit and transformative potential of the proposed methods, representing a significant advance in the field of turbulence generation.
</details></li>
</ul>
<hr>
<h2 id="Mixture-of-Coupled-HMMs-for-Robust-Modeling-of-Multivariate-Healthcare-Time-Series"><a href="#Mixture-of-Coupled-HMMs-for-Robust-Modeling-of-Multivariate-Healthcare-Time-Series" class="headerlink" title="Mixture of Coupled HMMs for Robust Modeling of Multivariate Healthcare Time Series"></a>Mixture of Coupled HMMs for Robust Modeling of Multivariate Healthcare Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07867">http://arxiv.org/abs/2311.07867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/onurpoyraz/m-chmm">https://github.com/onurpoyraz/m-chmm</a></li>
<li>paper_authors: Onur Poyraz, Pekka Marttinen</li>
<li>for: 这篇论文主要应用于Multivariate Healthcare Time Series Data的分析，解决不规则采样、噪音和缺失值、不同患者群体的不同动态等问题。</li>
<li>methods: 本文提出了一种新的模型，即coupled hidden Markov models (M-CHMM)，并详细介绍了两种采样方法：分子滤波和分解方法。这些方法可以让模型学习更加可能，并提高混合度、降低计算复杂度，并且可以进行机会测量，从而学习混合模型。</li>
<li>results: 实验结果显示，M-CHMM可以更好地适应实际世界的epidemiological和半人工数据，提高数据适应度、实现噪音和缺失值处理、提高预测精度，并且可以实现可读性的subset构成。<details>
<summary>Abstract</summary>
Analysis of multivariate healthcare time series data is inherently challenging: irregular sampling, noisy and missing values, and heterogeneous patient groups with different dynamics violating exchangeability. In addition, interpretability and quantification of uncertainty are critically important. Here, we propose a novel class of models, a mixture of coupled hidden Markov models (M-CHMM), and demonstrate how it elegantly overcomes these challenges. To make the model learning feasible, we derive two algorithms to sample the sequences of the latent variables in the CHMM: samplers based on (i) particle filtering and (ii) factorized approximation. Compared to existing inference methods, our algorithms are computationally tractable, improve mixing, and allow for likelihood estimation, which is necessary to learn the mixture model. Experiments on challenging real-world epidemiological and semi-synthetic data demonstrate the advantages of the M-CHMM: improved data fit, capacity to efficiently handle missing and noisy measurements, improved prediction accuracy, and ability to identify interpretable subsets in the data.
</details>
<details>
<summary>摘要</summary>
《多变量医疗时间序列数据分析具有许多挑战：不规则的采样、噪声和缺失值，以及不同的患者群体动态，使得交换性被违犯。此外，解释性和量化不确定性也是非常重要。我们提出了一种新的模型，即混合隐藏Markov模型（M-CHMM），并证明了它能够妥协这些挑战。为了使模型学习可行，我们 derivated了两种算法来采样CHMM中的隐藏变量序列：基于 particule filtering 和 factorized approximation。与现有的推理方法相比，我们的算法具有计算可 tractable 的优点，提高混合度，并允许likelihood估计，这是必要的来学习混合模型。实验表明，M-CHMM在实际世界的epidemiological和半 sintetic数据上具有优势：提高数据的适应度，能够有效地处理缺失和噪声测量，提高预测精度，并能够寻找可解释的子集。》
</details></li>
</ul>
<hr>
<h2 id="PEMS-Pre-trained-Epidmic-Time-series-Models"><a href="#PEMS-Pre-trained-Epidmic-Time-series-Models" class="headerlink" title="PEMS: Pre-trained Epidmic Time-series Models"></a>PEMS: Pre-trained Epidmic Time-series Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07841">http://arxiv.org/abs/2311.07841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshavardhan Kamarthi, B. Aditya Prakash</li>
<li>For: The paper aims to provide accurate and reliable predictions about the future of an epidemic, enabling informed public health decisions.* Methods: The authors use pre-trained deep learning models to learn from multiple datasets of different diseases and epidemics, and introduce a set of self-supervised learning (SSL) tasks to capture useful patterns and learn important priors about the epidemic dynamics.* Results: The resultant Pre-trained Epidemic Time-Series Models (PEMS) outperform previous state-of-the-art methods in various downstream time-series tasks across datasets of varying seasonal patterns, geography, and mechanism of contagion, including the novel Covid-19 pandemic, with better efficiency using a smaller fraction of datasets.<details>
<summary>Abstract</summary>
Providing accurate and reliable predictions about the future of an epidemic is an important problem for enabling informed public health decisions. Recent works have shown that leveraging data-driven solutions that utilize advances in deep learning methods to learn from past data of an epidemic often outperform traditional mechanistic models. However, in many cases, the past data is sparse and may not sufficiently capture the underlying dynamics. While there exists a large amount of data from past epidemics, leveraging prior knowledge from time-series data of other diseases is a non-trivial challenge. Motivated by the success of pre-trained models in language and vision tasks, we tackle the problem of pre-training epidemic time-series models to learn from multiple datasets from different diseases and epidemics. We introduce Pre-trained Epidemic Time-Series Models (PEMS) that learn from diverse time-series datasets of a variety of diseases by formulating pre-training as a set of self-supervised learning (SSL) tasks. We tackle various important challenges specific to pre-training for epidemic time-series such as dealing with heterogeneous dynamics and efficiently capturing useful patterns from multiple epidemic datasets by carefully designing the SSL tasks to learn important priors about the epidemic dynamics that can be leveraged for fine-tuning to multiple downstream tasks. The resultant PEM outperforms previous state-of-the-art methods in various downstream time-series tasks across datasets of varying seasonal patterns, geography, and mechanism of contagion including the novel Covid-19 pandemic unseen in pre-trained data with better efficiency using smaller fraction of datasets.
</details>
<details>
<summary>摘要</summary>
importante проблеma para tomar decisiones de salud pública informadas es proporcionar predicciones precisas y confiables sobre el futuro de una epidemia. Los trabajos recientes han demostrado que utilizar soluciones de aprendizaje profundo que se basan en el aprendizaje automático para aprender de los datos pasados de una epidemia pueden superar a los modelos mecánicos tradicionales. Sin embargo, en muchos casos, los datos pasados pueden ser escasos y no capturar adecuadamente las dinámicas subyacentes. A pesar de que existen una gran cantidad de datos de epidemias pasadas, utilizar el conocimiento previo de los datos temporales de otras enfermedades es un desafío no trivial.Motivados por el éxito de los modelos pre-entrenados en tareas de lenguaje y visión, abordamos el problema de entrenar modelos de tiempo series epidemiológicos pre-entrenados para aprender de múltiples conjuntos de datos de diferentes enfermedades y epidemias. Presentamos los Modelos de Epidemic Time Series Pre-entrenados (PEMS) que aprenden de conjuntos de datos temporales diversificados de una variedad de enfermedades mediante la formulación de tareas de aprendizaje auto-supervisado (SSL). Abordamos desafíos importantes específicos de pre-entrenamiento para series temporales epidemiológicas, como lidiar con dinámicas heterogéneas y capturar eficientemente patrones útiles de múltiples conjuntos de datos epidemiológicos mediante tareas SSL cuidadosamente diseñadas para aprender priores importantes sobre las dinámicas epidemiológicas que se pueden utilizar para fine-tuning en diversas tareas downstream.El resultado es que PEM supera a los métodos estado-de-la-arte anteriores en diversas tareas downstream de tiempo series en conjuntos de datos con patrones estacionales variables, geográficos y de contagio diferente, incluyendo la pandemia novel Covid-19 sin datos previamente entrenados con mayor eficiencia utilizando una fracción más pequeña de los conjuntos de datos.
</details></li>
</ul>
<hr>
<h2 id="Toward-Efficient-and-Incremental-Spectral-Clustering-via-Parametric-Spectral-Clustering"><a href="#Toward-Efficient-and-Incremental-Spectral-Clustering-via-Parametric-Spectral-Clustering" class="headerlink" title="Toward Efficient and Incremental Spectral Clustering via Parametric Spectral Clustering"></a>Toward Efficient and Incremental Spectral Clustering via Parametric Spectral Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07833">http://arxiv.org/abs/2311.07833</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/109502518/psc_bigdata">https://github.com/109502518/psc_bigdata</a></li>
<li>paper_authors: Jo-Chun Chen, Hung-Hsuan Chen</li>
<li>for:  addresses the challenges associated with big data and real-time scenarios, and enables efficient incremental clustering with new data points.</li>
<li>methods:  extends the capabilities of spectral clustering with a novel approach called parametric spectral clustering (PSC).</li>
<li>results:  achieves clustering quality mostly comparable to standard spectral clustering while being computationally efficient, as demonstrated through experimental evaluations on various open datasets.<details>
<summary>Abstract</summary>
Spectral clustering is a popular method for effectively clustering nonlinearly separable data. However, computational limitations, memory requirements, and the inability to perform incremental learning challenge its widespread application. To overcome these limitations, this paper introduces a novel approach called parametric spectral clustering (PSC). By extending the capabilities of spectral clustering, PSC addresses the challenges associated with big data and real-time scenarios and enables efficient incremental clustering with new data points. Experimental evaluations conducted on various open datasets demonstrate the superiority of PSC in terms of computational efficiency while achieving clustering quality mostly comparable to standard spectral clustering. The proposed approach has significant potential for incremental and real-time data analysis applications, facilitating timely and accurate clustering in dynamic and evolving datasets. The findings of this research contribute to the advancement of clustering techniques and open new avenues for efficient and effective data analysis. We publish the experimental code at https://github.com/109502518/PSC_BigData.
</details>
<details>
<summary>摘要</summary>
spectral clustering是一种广泛使用的方法，可以有效地将非线性分离数据集群。然而，计算限制、内存需求以及不能进行增量学习使得其广泛应用受到挑战。为了突破这些限制，本文提出了一种新的方法： Parametric spectral clustering（PSC）。通过扩展spectral clustering的能力，PSC解决了大数据和实时应用中的限制，并允许高效地添加新数据点。经验证表明，PSC在计算效率方面与标准spectral clustering相当，并且在各种开放数据集上达到了相似的分 clustering质量。提出的方法在增量和实时数据分析应用中具有广泛的潜在应用前景，可以实现时态和准确的分 clustering。这些研究成果对集群技术的发展产生了贡献，打开了新的有效和高效的数据分析途径。我们在github上公布了实验代码，请参考https://github.com/109502518/PSC_BigData。
</details></li>
</ul>
<hr>
<h2 id="Purpose-in-the-Machine-Do-Traffic-Simulators-Produce-Distributionally-Equivalent-Outcomes-for-Reinforcement-Learning-Applications"><a href="#Purpose-in-the-Machine-Do-Traffic-Simulators-Produce-Distributionally-Equivalent-Outcomes-for-Reinforcement-Learning-Applications" class="headerlink" title="Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?"></a>Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08429">http://arxiv.org/abs/2311.08429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rex Chen, Kathleen M. Carley, Fei Fang, Norman Sadeh</li>
<li>for: 这个论文主要用于探讨智能交通系统（ITS）学习中的模拟器对RL代理的影响。</li>
<li>methods: 这篇论文使用了两种常用的城市流模拟器和SUMO来训练RL代理，并在虚拟实验中控制了司机行为和模拟规模，以检验RL测量方法的准确性。</li>
<li>results: 研究发现，由于模拟器之间的假设差异，RL测量方法之间存在很大的差异，包括平均平方误差和KL散度，这些差异在所有评估指标中都存在。这些结果表明，交通模拟器不能被视为RL训练的“神奇解决方案”，需要更好地理解模拟器之间的差异，以便在真实世界中部署RL-基于ITS。<details>
<summary>Abstract</summary>
Traffic simulators are used to generate data for learning in intelligent transportation systems (ITSs). A key question is to what extent their modelling assumptions affect the capabilities of ITSs to adapt to various scenarios when deployed in the real world. This work focuses on two simulators commonly used to train reinforcement learning (RL) agents for traffic applications, CityFlow and SUMO. A controlled virtual experiment varying driver behavior and simulation scale finds evidence against distributional equivalence in RL-relevant measures from these simulators, with the root mean squared error and KL divergence being significantly greater than 0 for all assessed measures. While granular real-world validation generally remains infeasible, these findings suggest that traffic simulators are not a deus ex machina for RL training: understanding the impacts of inter-simulator differences is necessary to train and deploy RL-based ITSs.
</details>
<details>
<summary>摘要</summary>
假设系统（ITS）的学习需要数据生成，交通模拟器是一种常用的工具。然而，模拟器的假设会对ITS在实际世界中的适应能力产生影响。这项工作关注CityFlow和SUMO两种常用于训练奖励学习（RL）Agent的交通模拟器，通过控制虚拟实验中 Driver 行为和模拟规模进行了调整。研究发现，RL相关指标之间的分布不相等，root mean squared error和KL divergence都大于0。这些发现表明，交通模拟器不是RL训练的神奇解决方案，需要理解模拟器之间的差异，以便训练和部署RL基于ITS的系统。
</details></li>
</ul>
<hr>
<h2 id="Statistical-Parameterized-Physics-Based-Machine-Learning-Digital-Twin-Models-for-Laser-Powder-Bed-Fusion-Process"><a href="#Statistical-Parameterized-Physics-Based-Machine-Learning-Digital-Twin-Models-for-Laser-Powder-Bed-Fusion-Process" class="headerlink" title="Statistical Parameterized Physics-Based Machine Learning Digital Twin Models for Laser Powder Bed Fusion Process"></a>Statistical Parameterized Physics-Based Machine Learning Digital Twin Models for Laser Powder Bed Fusion Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07821">http://arxiv.org/abs/2311.07821</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangfan Li, Satyajit Mojumder, Ye Lu, Abdullah Al Amin, Jiachen Guo, Xiaoyu Xie, Wei Chen, Gregory J. Wagner, Jian Cao, Wing Kam Liu</li>
<li>for: This paper aims to develop a digital twin model for predicting and controlling the quality of laser powder bed fusion (LPBF) metal additive manufacturing processes.</li>
<li>methods: The paper uses a parameterized physics-based digital twin (PPB-DT) model that incorporates a mechanistic reduced-order method-driven stochastic calibration process to statistically predict melt pool geometries and identify defects. The model is validated through controlled experiments and compared to machine learning-based digital twin (PPB-ML-DT) models.</li>
<li>results: The PPB-DT model is able to accurately predict melt pool geometries and identify defects such as lack-of-fusion porosity and surface roughness, and the PPB-ML-DT model is able to predict, monitor, and control melt pool geometries. The proposed digital twin models can be used for predictions, control, optimization, and quality assurance within the LPBF process.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是开发一个用于预测和控制laserpowderbedfusion（LPBF）金属三维打印过程质量的数字双（DT）模型。</li>
<li>methods: 这篇论文使用一个参数化的物理基础DT模型，该模型通过机理减少方法驱动的随机校准过程来统计预测熔融池形状和识别缺陷。</li>
<li>results: PPB-DT模型能够准确预测熔融池形状和识别缺陷，而PPB-ML-DT模型能够预测、监控和控制熔融池形状。提议的数字双模型可以用于预测、控制、优化和质量监控在LPBF过程中。<details>
<summary>Abstract</summary>
A digital twin (DT) is a virtual representation of physical process, products and/or systems that requires a high-fidelity computational model for continuous update through the integration of sensor data and user input. In the context of laser powder bed fusion (LPBF) additive manufacturing, a digital twin of the manufacturing process can offer predictions for the produced parts, diagnostics for manufacturing defects, as well as control capabilities. This paper introduces a parameterized physics-based digital twin (PPB-DT) for the statistical predictions of LPBF metal additive manufacturing process. We accomplish this by creating a high-fidelity computational model that accurately represents the melt pool phenomena and subsequently calibrating and validating it through controlled experiments. In PPB-DT, a mechanistic reduced-order method-driven stochastic calibration process is introduced, which enables the statistical predictions of the melt pool geometries and the identification of defects such as lack-of-fusion porosity and surface roughness, specifically for diagnostic applications. Leveraging data derived from this physics-based model and experiments, we have trained a machine learning-based digital twin (PPB-ML-DT) model for predicting, monitoring, and controlling melt pool geometries. These proposed digital twin models can be employed for predictions, control, optimization, and quality assurance within the LPBF process, ultimately expediting product development and certification in LPBF-based metal additive manufacturing.
</details>
<details>
<summary>摘要</summary>
一个数字双（DT）是一个虚拟的物理过程、产品和/或系统的表示，需要高精度计算模型，Continuous更新通过感知器数据和用户输入集成。在激光粉末堆合（LPBF）添加制造过程中，一个关于制造过程的数字双可以提供生产件预测、制造缺陷诊断以及控制能力。本文介绍一个基于物理学习的数字双（PPB-DT），用于LPBF附加制造过程的统计预测。我们通过创建一个具有高精度计算模型，准确表示熔融池现象，并通过控制实验 validate和调整它。在PPB-DT中，我们引入了一种基于物理学习的减少阶段法的抽象Calibration过程，可以统计预测熔融池几何体和缺陷的标识，特别是 для诊断应用。通过这个物理学习模型和实验数据，我们训练了一个基于机器学习的数字双（PPB-ML-DT）模型，用于预测、监控和控制熔融池几何体。这些提posed的数字双模型可以在LPBF过程中用于预测、控制、优化和质量保证，最终提高LPBF基于附加制造的金属加工产品的开发和认证。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/cs.LG_2023_11_14/" data-id="clpztdnmd00v0es880zurere0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/eess.IV_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T09:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/eess.IV_2023_11_14/">eess.IV - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Time-efficient-combined-morphologic-and-quantitative-joint-MRI-based-on-clinical-image-contrasts-–-An-exploratory-in-situ-study-of-standardized-cartilage-defects"><a href="#Time-efficient-combined-morphologic-and-quantitative-joint-MRI-based-on-clinical-image-contrasts-–-An-exploratory-in-situ-study-of-standardized-cartilage-defects" class="headerlink" title="Time-efficient combined morphologic and quantitative joint MRI based on clinical image contrasts – An exploratory in-situ study of standardized cartilage defects"></a>Time-efficient combined morphologic and quantitative joint MRI based on clinical image contrasts – An exploratory in-situ study of standardized cartilage defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08036">http://arxiv.org/abs/2311.08036</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teresa Lemainque, Nicola Pridöhl, Shuo Zhang, Marc Huppertz, Manuel Post, Can Yüksel, Masami Yoneyama, Andreas Prescher, Christiane Kuhl, Daniel Truhn, Sven Nebelung</li>
<li>for: 这个研究的目的是评估MIXTURE序列在评估软骨和股关节中的效用。</li>
<li>methods: 这个研究使用了MIXTURE序列，这些序列组合了质量图像和临床扫描echo的对比，并提供了质量图像和参数地图。</li>
<li>results: 研究发现，在创建损伤后，软骨中的刺激时间增加了，而bone texture和软骨恢复时间也发生了变化。但是，MIXTURE序列和参照序列之间的差异不是很大。<details>
<summary>Abstract</summary>
OBJECTIVES: Quantitative MRI techniques such as T2 and T1$\rho$ mapping are beneficial in evaluating cartilage and meniscus. We aimed to evaluate the MIXTURE (Multi-Interleaved X-prepared Turbo-Spin Echo with IntUitive RElaxometry) sequences that provide morphologic images with clinical turbo spin-echo (TSE) contrasts and additional parameter maps versus reference TSE sequences in an in-situ model of human cartilage defects.   MATERIALS AND METHODS: Prospectively, standardized cartilage defects of 8mm, 5mm, and 3mm diameter were created in the lateral femora of 10 human cadaveric knee specimens (81$\pm$10 years, nine male/one female). Using a clinical 3T MRI scanner and knee coil, MIXTURE sequences combining (i) proton-density weighted fat-saturated (PD-w FS) images and T2 maps and (ii) T1-weighted images and T1$\rho$ maps were acquired before and after defect creation, alongside the corresponding 2D TSE and 3D TSE reference sequences. Defect delineability, bone texture, and cartilage relaxation times were quantified. Inter-sequence comparisons were made using appropriate parametric and non-parametric tests.   RESULTS: Overall, defect delineability and texture features were not significantly different between the MIXTURE and reference sequences. After defect creation, relaxation times increased significantly in the central femur (for T2) and all regions combined (for T1$\rho$).   CONCLUSION: MIXTURE sequences permit time-efficient simultaneous morphologic and quantitative joint assessment based on clinical image contrasts. While providing T2 or T1$\rho$ maps in clinically feasible scan time, morphologic image features, i.e., cartilage defect delineability and bone texture, were comparable between MIXTURE and corresponding reference sequences.
</details>
<details>
<summary>摘要</summary>
目标：量化MRI技术，如T2和T1ρ图像，有助于评估软骨和股骨。我们想要评估MIXTURE（多元排序X准备扩散螺旋共振成像）序列，它们提供了辐射学像和临床旋转普朗共振（TSE）对比的形态图像，以及附加参数图像，与参照TSE序列进行比较。材料和方法：我们使用了一台临床3T MRI仪器和膝关节磁共振器，在人体腓骨上创造了标准化软骨损伤（半径8毫米，3毫米和5毫米）。使用MIXTURE序列，我们获得了杂合PD-wFS图像和T2图像，以及T1-weighted图像和T1ρ图像，并与相应的2D TSE和3D TSE参照序列一起进行了收集。我们评估了损伤定义性、骨Texture和软骨弹性时间。我们使用了适当的 Parametric 和非 Parametric 测试进行对比。结果：总的来说，损伤定义性和Texture特征没有显著差异 междуMIXTURE和参照序列。在中部腓骨（T2）和所有区域（T1ρ）中，创伤后弹性时间明显增加。结论：MIXTURE序列允许在临床可行的扫描时间内同时进行形态和量化骨关节评估，基于临床图像对比的辐射学图像。虽然提供了T2或T1ρ图像，但形态图像特征，例如软骨损伤定义性和骨Texture，与MIXTURE序列和相应的参照序列相比没有显著差异。
</details></li>
</ul>
<hr>
<h2 id="Plug-and-Play-Latent-Feature-Editing-for-Orientation-Adaptive-Quantitative-Susceptibility-Mapping-Neural-Networks"><a href="#Plug-and-Play-Latent-Feature-Editing-for-Orientation-Adaptive-Quantitative-Susceptibility-Mapping-Neural-Networks" class="headerlink" title="Plug-and-Play Latent Feature Editing for Orientation-Adaptive Quantitative Susceptibility Mapping Neural Networks"></a>Plug-and-Play Latent Feature Editing for Orientation-Adaptive Quantitative Susceptibility Mapping Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07823">http://arxiv.org/abs/2311.07823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunhongfu/deepMRI">https://github.com/sunhongfu/deepMRI</a></li>
<li>paper_authors: Yang Gao, Zhuang Xiong, Shanshan Shan, Yin Liu, Pengfei Rong, Min Li, Alan H Wilman, G. Bruce Pike, Feng Liu, Hongfu Sun<br>for:* 这项研究旨在解决深度学习（DL）扫描仪磁场方向变化的限制，以提高Quantitative susceptibility mapping（QSM）重构问题的精度和稳定性。methods:* 提出了一种Orientation-Adaptive Latent Feature Editing（OA-LFE）模块，可以学习探测探针方向向量的编码，并将其直接integrated into deep networks的 latent features中。results:* 在 simulated和实验室人脑 Dataset上，与多种已有的 QSM重构框架进行了比较，并证明了iQSM+可以在不同的探针方向下重构QSM图像，并且图像的准确性得到了显著改进。<details>
<summary>Abstract</summary>
Quantitative susceptibility mapping (QSM) is a post-processing technique for deriving tissue magnetic susceptibility distribution from MRI phase measurements. Deep learning (DL) algorithms hold great potential for solving the ill-posed QSM reconstruction problem. However, a significant challenge facing current DL-QSM approaches is their limited adaptability to magnetic dipole field orientation variations during training and testing. In this work, we propose a novel Orientation-Adaptive Latent Feature Editing (OA-LFE) module to learn the encoding of acquisition orientation vectors and seamlessly integrate them into the latent features of deep networks. Importantly, it can be directly Plug-and-Play (PnP) into various existing DL-QSM architectures, enabling reconstructions of QSM from arbitrary magnetic dipole orientations. Its effectiveness is demonstrated by combining the OA-LFE module into our previously proposed phase-to-susceptibility single-step instant QSM (iQSM) network, which was initially tailored for pure-axial acquisitions. The proposed OA-LFE-empowered iQSM, which we refer to as iQSM+, is trained in a self-supervised manner on a specially-designed simulation brain dataset. Comprehensive experiments are conducted on simulated and in vivo human brain datasets, encompassing subjects ranging from healthy individuals to those with pathological conditions. These experiments involve various MRI platforms (3T and 7T) and aim to compare our proposed iQSM+ against several established QSM reconstruction frameworks, including the original iQSM. The iQSM+ yields QSM images with significantly improved accuracies and mitigates artifacts, surpassing other state-of-the-art DL-QSM algorithms.
</details>
<details>
<summary>摘要</summary>
量子感测图像（QSM）是一种后处理技术，用于从MRI阶段测量结果中提取组织磁矩分布。深度学习（DL）算法在解决QSM重建问题上具有巨大潜力。然而，目前的DL-QSM方法面临的主要挑战是在训练和测试过程中磁 dipôle场方向的变化不能适应。在这种情况下，我们提出了一种新的 Orientación-Adaptive Latent Feature Editing（OA-LFE）模块，用于学习获取训练和测试过程中磁 dipôle场方向的编码。这种模块可以 direct Plug-and-Play（PnP）地 integrating into various existing DL-QSM architectures，以便从任意磁 dipôle场方向重建QSM图像。我们通过将OA-LFE模块与我们之前提出的Single-step instant QSM（iQSM）网络结合，并将其称为iQSM+。iQSM+网络在自我超vised的方式下在特制的MRI大脑数据集上进行训练。我们对于这些数据集进行了丰富的实验，包括使用3T和7T的MRI平台，并与其他已知QSM重建框架进行比较。iQSM+网络对于不同的MRI平台和疾病 condition进行了广泛的应用，并且可以减少artifacts并提高QSM图像的准确性，胜过其他当前state-of-the-art DL-QSM算法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/eess.IV_2023_11_14/" data-id="clpztdntr01dbes8826ayaiat" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/14/eess.SP_2023_11_14/" class="article-date">
  <time datetime="2023-11-14T08:00:00.000Z" itemprop="datePublished">2023-11-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/14/eess.SP_2023_11_14/">eess.SP - 2023-11-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Choosing-Outdated-Information-to-Achieve-Reliability-in-Age-Based-Gossiping"><a href="#Choosing-Outdated-Information-to-Achieve-Reliability-in-Age-Based-Gossiping" class="headerlink" title="Choosing Outdated Information to Achieve Reliability in Age-Based Gossiping"></a>Choosing Outdated Information to Achieve Reliability in Age-Based Gossiping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08383">http://arxiv.org/abs/2311.08383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Priyanka Kaswan, Sennur Ulukus</li>
<li>for: 这篇论文旨在研究一个年龄分布式谣言网络中，两个来源（可靠源和不可靠源）如何传递处理过程的更新信息，以及Nodes如何选择信息来源并维护信息的新鲜度。</li>
<li>methods: 这篇论文使用了Stochastic Hybrid System（SHS）框架，形成了数学方程来描述网络节点中含有不可靠包和版本年龄的情况。</li>
<li>results: 研究发现，尽管增加G值可以减少网络节点中含有不可靠包的比例，但是这些包的版本年龄增加，从而导致了新鲜度-可靠性贸易offs。数据支持这些发现。<details>
<summary>Abstract</summary>
We consider a system model with two sources, a reliable source and an unreliable source, who are responsible for disseminating updates regarding a process to an age-based gossip network of $n$ nodes. Nodes wish to have fresh information, however, they have preference for packets that originated at the reliable source and are willing to sacrifice their version age of information by up to $G$ versions to switch from an unreliable packet to a reliable packet. We study how this protocol impacts the prevalence of unreliable packets at nodes in the network and their version age. Using a stochastic hybrid system (SHS) framework, we formulate analytical equations to characterize two quantities: expected fraction of nodes with unreliable packets and expected version age of information at network nodes. We show that as $G$ increases, fewer nodes have unreliable packet, however, their version age increases as well, thereby inducing a freshness-reliability trade-off in the network. We present numerical results to support our findings.
</details>
<details>
<summary>摘要</summary>
我们考虑一个系统模型，其包含两个源，一个可靠的源和一个不可靠的源，他们负责将进程更新传递给一个年龄基于谣言网络中的 $n$ 个节点。节点希望有最新的信息，但他们偏好来自可靠源的包，并愿意为了更换到可靠包而丢弃自己的版本年龄信息，最多为 $G$ 个版本。我们研究这种协议如何影响网络节点上带有不可靠包的普遍性和版本年龄。使用随机混合系统（SHS）框架，我们编写了分析方程来描述两个量：网络节点上带有不可靠包的预期总数和网络节点上的版本年龄预期值。我们发现，当 $G$ 增加时，网络节点上带有不可靠包的数量减少，但这些包的版本年龄也增加，从而导致了一种新鲜度-可靠性贸易。我们提供数据支持我们的发现。
</details></li>
</ul>
<hr>
<h2 id="Comparison-of-model-selection-techniques-for-seafloor-scattering-statistics"><a href="#Comparison-of-model-selection-techniques-for-seafloor-scattering-statistics" class="headerlink" title="Comparison of model selection techniques for seafloor scattering statistics"></a>Comparison of model selection techniques for seafloor scattering statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08337">http://arxiv.org/abs/2311.08337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek R Olson, Marc Geilhufe</li>
<li>for: 本研究旨在开发一种数据驱动的方法来选择折射环境中像素强度分布的统计模型，以优化遥感数据的分析。</li>
<li>methods: 该研究使用了一种混合分布模型，并通过对不同数据驱动的模型选择进行比较，以选择最佳的模型。</li>
<li>results: 研究发现，使用数据驱动的方法可以更好地选择折射环境中像Pixel强度分布的统计模型，并且可以减少人类的干预。<details>
<summary>Abstract</summary>
In quantitative analysis of seafloor imagery, it is common to model the collection of individual pixel intensities scattered by the seafloor as a random variable with a given statistical distribution. There is a considerable literature on statistical models for seafloor scattering, mostly focused on areas with statistically homogeneous properties (i.e. exhibiting spatial stationarity). For more complex seafloors, the pixel intensity distribution is more appropriately modeled using a mixture of simple distributions. For very complex seafloors, fitting 3 or more mixture components makes physical sense, but the statistical model becomes much more complex in these cases. Therefore, picking the number of components of the mixture model is a decision that must be made, using a priori information, or using a data driven approach. However, this information is time consuming to collect, and depends on the skill and experience of the human. Therefore, a data-driven approach is advantageous to use, and is explored in this work. Criteria for choosing a model always need to balance the trade-off for the best fit for the data on the one hand and the model complexity on the other hand. In this work, we compare several statistical model selection criteria, e.g., the Bayesian information criterion. Examples are given for SAS data collected by an autonomous underwater vehicle in a rocky environment off the coast of Bergen, Norway using data from the HISAS-1032 synthetic aperture sonar system.
</details>
<details>
<summary>摘要</summary>
在海底图像量化分析中，常将每个像素强度散射到海底模型为随机变量，采用给定的统计分布。关于海底散射的统计模型有很大的文献，主要集中在统计homogeneous（即空间站ARY）的海底上。对于更复杂的海底，则更有理由使用多个简单分布的混合模型。对于非常复杂的海底，使用3个或更多的混合组件是物理意义上的，但统计模型在这些情况下变得非常复杂。因此，选择混合模型的组件数量是一个需要基于先验知识或数据驱动的决策。然而，收集这些信息的时间很长，取决于人员的技能和经验。因此，使用数据驱动的方法更有利，并在这种工作中进行了研究。选择模型的标准要求平衡数据最佳适应和模型复杂度之间的折衔。在这种工作中，我们比较了多种统计模型选择标准，例如 bayesian信息 критерион。使用SAS数据 collected by an autonomous underwater vehicle在挪威Bergen coast rocky environment中，使用HISAS-1032 synthetic aperture sonar系统的数据作为示例。
</details></li>
</ul>
<hr>
<h2 id="Protecting-the-Future-of-Information-LOCO-Coding-With-Error-Detection-for-DNA-Data-Storage"><a href="#Protecting-the-Future-of-Information-LOCO-Coding-With-Error-Detection-for-DNA-Data-Storage" class="headerlink" title="Protecting the Future of Information: LOCO Coding With Error Detection for DNA Data Storage"></a>Protecting the Future of Information: LOCO Coding With Error Detection for DNA Data Storage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08325">http://arxiv.org/abs/2311.08325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Canberk İrimağzı, Yusuf Uslan, Ahmed Hareedy</li>
<li>for: 本文研究了使用新引入的 lexicographically-ordered constrained（LOCO）码在 DNA 数据存储中。</li>
<li>methods: 本文提出了基于 ${A,T,G,C}$ 字母的 DNA LOCO（D-LOCO）码，并提供了编码-解码规则。这些规则提供了可靠的编码-解码算法，并且可以轻松地重新配置。</li>
<li>results: 本文的编码-解码算法比现有Literature中的算法更有效，并且可以实现高率的 DNA 数据存储。此外，本文还提出了四种方案来连接 consecutive codewords，其中三种方案可以确定单个替换错误检测每个 codeword。<details>
<summary>Abstract</summary>
DNA strands serve as a storage medium for $4$-ary data over the alphabet $\{A,T,G,C\}$. DNA data storage promises formidable information density, long-term durability, and ease of replicability. However, information in this intriguing storage technology might be corrupted. Experiments have revealed that DNA sequences with long homopolymers and/or with low $GC$-content are notably more subject to errors upon storage.   This paper investigates the utilization of the recently-introduced method for designing lexicographically-ordered constrained (LOCO) codes in DNA data storage. This paper introduces DNA LOCO (D-LOCO) codes, over the alphabet $\{A,T,G,C\}$ with limited runs of identical symbols. These codes come with an encoding-decoding rule we derive, which provides affordable encoding-decoding algorithms. In terms of storage overhead, the proposed encoding-decoding algorithms outperform those in the existing literature. Our algorithms are readily reconfigurable. D-LOCO codes are intrinsically balanced, which allows us to achieve balancing over the entire DNA strand with minimal rate penalty. Moreover, we propose four schemes to bridge consecutive codewords, three of which guarantee single substitution error detection per codeword. We examine the probability of undetecting errors. We also show that D-LOCO codes are capacity-achieving and that they offer remarkably high rates at moderate lengths.
</details>
<details>
<summary>摘要</summary>
This paper investigates the utilization of the recently-introduced method for designing lexicographically-ordered constrained (LOCO) codes in DNA data storage. This paper introduces DNA LOCO (D-LOCO) codes, over the alphabet $\{\mathtt{A}, \mathtt{T}, \mathtt{G}, \mathtt{C}\}$ with limited runs of identical symbols. These codes come with an encoding-decoding rule we derive, which provides affordable encoding-decoding algorithms. In terms of storage overhead, the proposed encoding-decoding algorithms outperform those in the existing literature. Our algorithms are readily reconfigurable. D-LOCO codes are intrinsically balanced, which allows us to achieve balancing over the entire DNA strand with minimal rate penalty. Moreover, we propose four schemes to bridge consecutive codewords, three of which guarantee single substitution error detection per codeword. We examine the probability of undetecting errors. We also show that D-LOCO codes are capacity-achieving and that they offer remarkably high rates at moderate lengths.
</details></li>
</ul>
<hr>
<h2 id="Resource-Efficient-Over-the-Air-Fronthaul-Signaling-for-Uplink-Cell-Free-Massive-MIMO-Systems"><a href="#Resource-Efficient-Over-the-Air-Fronthaul-Signaling-for-Uplink-Cell-Free-Massive-MIMO-Systems" class="headerlink" title="Resource Efficient Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems"></a>Resource Efficient Over-the-Air Fronthaul Signaling for Uplink Cell-Free Massive MIMO Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08319">http://arxiv.org/abs/2311.08319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zakir Hussain Shaik, Sai Subramanyam Thoota, Emil Björnson, Erik G. Larsson</li>
<li>for:  addresses the demanding requirements of uplink (UL) fronthaul in cell-free massive multiple-input multiple-output (MIMO) systems.</li>
<li>methods:  proposes a novel resource efficient analog over-the-air (OTA) computation framework, including transmit precoding and two-phase power assignment strategies at the access points (APs).</li>
<li>results:  derives analytical expressions for the Bayesian and classical estimators of the OTA combined signals, and empirically evaluates the normalized mean square error (NMSE), symbol error rate (SER), and coded bit error rate (BER) of the developed solution, showing that it outperforms the state-of-the-art wired fronthaul based system.<details>
<summary>Abstract</summary>
We propose a novel resource efficient analog over-the-air (OTA) computation framework to address the demanding requirements of the uplink (UL) fronthaul between the access points (APs) and the central processing unit (CPU) in cell-free massive multiple-input multiple-output (MIMO) systems. We discuss the drawbacks of the wired and wireless fronthaul solutions, and show that our proposed mechanism is efficient and scalable as the number of APs increases. We present the transmit precoding and two-phase power assignment strategies at the APs to coherently combine the signals OTA in a spectrally efficient manner. We derive the statistics of the APs locally available signals which enable us to to obtain the analytical expressions for the Bayesian and classical estimators of the OTA combined signals. We empirically evaluate the normalized mean square error (NMSE), symbol error rate (SER), and the coded bit error rate (BER) of our developed solution and benchmark against the state-of-the-art wired fronthaul based system
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的资源有效的无线上空计算框架，以满足Cell-free巨量多输入多输出系统的上行（UL）前方向的需求。我们讨论了有线和无线前方向解决方案的缺点，并显示了我们的提议机制具有规模可扩展的优点。我们介绍了在AP上进行预编码和两相电压分配策略，以具有spectral efficiency的方式将OTA信号相乘。我们 derivation了AP上可用信号的统计，允许我们获得OTA相乘后的分布统计。我们Empirically评估了NMSE、SER和BER表现，并与现有的有线前方向基础系统进行比较。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Maximum-Eigenvalue-Detection-based-Spectrum-Sensing-in-RIS-aided-System-with-Correlated-Fading"><a href="#Maximum-Eigenvalue-Detection-based-Spectrum-Sensing-in-RIS-aided-System-with-Correlated-Fading" class="headerlink" title="Maximum Eigenvalue Detection based Spectrum Sensing in RIS-aided System with Correlated Fading"></a>Maximum Eigenvalue Detection based Spectrum Sensing in RIS-aided System with Correlated Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08296">http://arxiv.org/abs/2311.08296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhilsingh Parihar, Praful D. Mankar, Sachin Chaudhari</li>
<li>for: 本研究旨在提高受信息干扰的spectrum sensing表现，尤其是在多path fading和噪声相关的场景下。</li>
<li>methods: 本文提出了使用可编程智能面(RIS)来提高spectrum sensing表现。特别是利用 espacially correlated fading，我们提议使用最大特征值检测(MED)进行spectrum sensing。</li>
<li>results: 我们 derivated了测试统计量的正态分布 under null和signal present假设下。然后，我们使用这些结果计算了假设检测的false alarm和 detection probabilities。此外，我们还优化了RIS的相位旋转矩阵，以提高检测性能。我们的numerical analysis表明，MED的接收操作特征曲线在RIS元素增加、SNR提高和 statistically optimal配置RIS的情况下都得到提高。<details>
<summary>Abstract</summary>
Robust spectrum sensing is crucial for facilitating opportunistic spectrum utilization for secondary users (SU) in the absense of primary users (PU). However, propagation environment factors such as multi-path fading, shadowing, and lack of line of sight (LoS) often adversely affect detection performance. To deal with these issues, this paper focuses on utilizing reconfigurable intelligent surfaces (RIS) to improve spectrum sensing in the scenario wherein both the multi-path fading and noise are correlated. In particular, to leverage the spatially correlated fading, we propose to use maximum eigenvalue detection (MED) for spectrum sensing. We first derive exact distributions of test statistics, i.e., the largest eigenvalue of the sample covariance matrix, observed under the null and signal present hypothesis. Next, utilizing these results, we present the exact closed-form expressions for the false alarm and detection probabilities. In addition, we also optimally configure the phase shift matrix of RIS such that the mean of the test statistics is maximized, thus improving the detection performance. Our numerical analysis demonstrates that the MED's receiving operating characteristic (ROC) curve improves with increased RIS elements, SNR, and the utilization of statistically optimal configured RIS.
</details>
<details>
<summary>摘要</summary>
Robust spectrum sensing 是次级用户（SU）在主要用户（PU）缺 absent 的情况下促进机会性spectrum utilization的关键。然而，传播环境因素 such as 多 PATH 抑制、阴影和无线线 sight（LoS） frequently adversely affect detection performance. To address these issues, this paper focuses on using reconfigurable intelligent surfaces (RIS) to improve spectrum sensing in the scenario where both multi-path fading and noise are correlated. In particular, we propose to use maximum eigenvalue detection (MED) for spectrum sensing. We first derive the exact distributions of test statistics, i.e., the largest eigenvalue of the sample covariance matrix, observed under the null and signal present hypotheses. Next, we use these results to present the exact closed-form expressions for the false alarm and detection probabilities. Additionally, we optimize the phase shift matrix of RIS such that the mean of the test statistics is maximized, thus improving detection performance. Our numerical analysis shows that the MED's receiving operating characteristic (ROC) curve improves with increased RIS elements, SNR, and the utilization of statistically optimal configured RIS.Note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Joint-Location-Sensing-and-Channel-Estimation-for-IRS-Aided-mmWave-ISAC-Systems"><a href="#Joint-Location-Sensing-and-Channel-Estimation-for-IRS-Aided-mmWave-ISAC-Systems" class="headerlink" title="Joint Location Sensing and Channel Estimation for IRS-Aided mmWave ISAC Systems"></a>Joint Location Sensing and Channel Estimation for IRS-Aided mmWave ISAC Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08201">http://arxiv.org/abs/2311.08201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Chen, Ming-Min Zhao, Min Li, Fan Xu, Qingqing Wu, Min-Jian Zhao</li>
<li>for: 本研究 investigate a self-sensing intelligent reflecting surface (IRS) aided millimeter wave (mmWave) integrated sensing and communication (ISAC) system, aiming to jointly sense the target&#x2F;scatterer&#x2F;user positions and estimate the sensing and communication (SAC) channels.</li>
<li>methods: 提议 a two-phase transmission scheme, where the coarse and refined sensing&#x2F;channel estimation (CE) results are respectively obtained in the first phase using scanning-based IRS reflection coefficients and the second phase using optimized IRS reflection coefficients. The proposed algorithm combines VBI, messaging passing, and expectation-maximization (EM) methods to solve the considered joint location sensing and CE problem, exploiting the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels.</li>
<li>results:  simulation results show the superiority of the proposed transmission scheme and associated algorithms, verifying the effectiveness of the self-sensing IRS in reducing the path loss of sensing-related links and enhancing the overall performance of the ISAC system.<details>
<summary>Abstract</summary>
In this paper, we investigate a self-sensing intelligent reflecting surface (IRS) aided millimeter wave (mmWave) integrated sensing and communication (ISAC) system. Unlike the conventional purely passive IRS, the self-sensing IRS can effectively reduce the path loss of sensing-related links, thus rendering it advantageous in ISAC systems. Aiming to jointly sense the target/scatterer/user positions as well as estimate the sensing and communication (SAC) channels in the considered system, we propose a two-phase transmission scheme, where the coarse and refined sensing/channel estimation (CE) results are respectively obtained in the first phase (using scanning-based IRS reflection coefficients) and second phase (using optimized IRS reflection coefficients). For each phase, an angle-based sensing turbo variational Bayesian inference (AS-TVBI) algorithm, which combines the VBI, messaging passing and expectation-maximization (EM) methods, is developed to solve the considered joint location sensing and CE problem. The proposed algorithm effectively exploits the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels to enhance the overall performance. Based on the estimation results from the first phase, we formulate a Cram\'{e}r-Rao bound (CRB) minimization problem for optimizing IRS reflection coefficients, and through proper reformulations, a low-complexity manifold-based optimization algorithm is proposed to solve this problem. Simulation results are provided to verify the superiority of the proposed transmission scheme and associated algorithms.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一种自适应智能反射表面（IRS）帮助毫米波（mmWave）集成感知通信（ISAC）系统。与传统的仅PASSIVE IRS不同，自适应IRS可以有效减少感知相关链路的覆盖距离，从而在ISAC系统中具有优势。为了同时感知目标/散射体/用户位置以及估计感知通信（SAC） канала，我们提议了两个阶段的传输方案，其中第一阶段使用扫描基于IRS反射率来获得粗略的感知频道估计结果，第二阶段使用优化IRS反射率来获得精度的感知频道估计结果。 For each phase, an angle-based sensing turbo variational Bayesian inference (AS-TVBI) algorithm, which combines the VBI, messaging passing and expectation-maximization (EM) methods, is developed to solve the considered joint location sensing and CE problem. The proposed algorithm effectively exploits the partial overlapping structured (POS) sparsity and 2-dimensional (2D) block sparsity inherent in the SAC channels to enhance the overall performance. Based on the estimation results from the first phase, we formulate a Cramér-Rao bound (CRB) minimization problem for optimizing IRS reflection coefficients, and through proper reformulations, a low-complexity manifold-based optimization algorithm is proposed to solve this problem. Simulation results are provided to verify the superiority of the proposed transmission scheme and associated algorithms.
</details></li>
</ul>
<hr>
<h2 id="Fast-List-Decoding-of-High-Rate-Polar-Codes"><a href="#Fast-List-Decoding-of-High-Rate-Polar-Codes" class="headerlink" title="Fast List Decoding of High-Rate Polar Codes"></a>Fast List Decoding of High-Rate Polar Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08188">http://arxiv.org/abs/2311.08188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Lu, Ming-Min Zhao, Ming Lei, Min-Jian Zhao</li>
<li>for: 这个论文的目的是提高短至中等长度楔码的快速解码性能，尤其是在低延迟通信场景中。</li>
<li>methods: 本论文使用了特定楔码子代码（special nodes）的快速列解算法，包括单元检查（SPC）节点和一个或多个单元检查（SR1&#x2F;SPC）节点。具体来说，本论文提出了两种快速列解算法，其中第一种使用了预序解码程式，使解码时间linear with the list size，第二种则透过在线上预决缺失路径来进一步平行化解码过程，实现更快的解码速度。</li>
<li>results:  simulations results show that the proposed list decoding algorithms are able to achieve up to 70.7% lower decoding latency than state-of-the-art fast SCL decoders, while exhibiting the same error-correction performance.<details>
<summary>Abstract</summary>
Due to the ability to provide superior error-correction performance, the successive cancellation list (SCL) algorithm is widely regarded as one of the most promising decoding algorithms for polar codes with short-to-moderate code lengths. However, the application of SCL decoding in low-latency communication scenarios is limited due to its sequential nature. To reduce the decoding latency, developing tailored fast and efficient list decoding algorithms of specific polar substituent codes (special nodes) is a promising solution. Recently, fast list decoding algorithms are proposed by considering special nodes with low code rates. Aiming to further speedup the SCL decoding, this paper presents fast list decoding algorithms for two types of high-rate special nodes, namely single-parity-check (SPC) nodes and sequence rate one or single-parity-check (SR1/SPC) nodes. In particular, we develop two classes of fast list decoding algorithms for these nodes, where the first class uses a sequential decoding procedure to yield decoding latency that is linear with the list size, and the second further parallelizes the decoding process by pre-determining the redundant candidate paths offline. Simulation results show that the proposed list decoding algorithms are able to achieve up to 70.7\% lower decoding latency than state-of-the-art fast SCL decoders, while exhibiting the same error-correction performance.
</details>
<details>
<summary>摘要</summary>
由于可提供出色的错误纠正性表现，连续取消列表（SCL）算法在短至中型编码长度的楔码中广泛被视为一种最有前途的解码算法。然而，在低延迟通信场景中，SCL解码的应用受到其顺序性的限制。为了降低解码延迟，开发专门为特定楔substituent代码（特定节点）设计快速高效的列解算法是一个有前途的解决方案。在最近，为了提高SCL解码的速度，这篇论文提出了两种类型的高速列解算法，即单元性检查（SPC）节点和序列率一（SR1/SPC）节点。具体来说，我们开发了两类快速列解算法，其中第一类使用顺序解码过程，使解码延迟线性增长与列表大小相关；第二类进一步平行化解码过程，通过先行确定冗余候选道路来提高速度。实验结果表明，提议的列解算法可以与当前最速的SCL解码器相比，实现70.7%的解码延迟降低，同时保持同等的错误纠正性表现。
</details></li>
</ul>
<hr>
<h2 id="Channel-Estimation-with-Dynamic-Metasurface-Antennas-via-Model-Based-Learning"><a href="#Channel-Estimation-with-Dynamic-Metasurface-Antennas-via-Model-Based-Learning" class="headerlink" title="Channel Estimation with Dynamic Metasurface Antennas via Model-Based Learning"></a>Channel Estimation with Dynamic Metasurface Antennas via Model-Based Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08158">http://arxiv.org/abs/2311.08158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Zhang, Haiyang Zhang, Luxi Yang, Yonina C. Eldar<br>for:This paper proposes two model-based learning methods to overcome the challenge of channel estimation in multiple input multiple output (MIMO) communication systems using dynamic metasurface antennas (DMAs).methods:The proposed methods use a combination of random DMA weighting matrices and spatial gridding dictionaries to form the sensing matrix, and employ the learned iterative shrinkage and thresholding algorithm (LISTA) to recover the sparse channel parameters. Additionally, a self-supervised learning technique is proposed to tackle the difficulty of acquiring noise-free data.results:The proposed methods demonstrate better channel accuracy than traditional sparse recovery methods and the sensing matrix optimization technique achieves better channel accuracy than the baseline method.<details>
<summary>Abstract</summary>
Dynamic Metasurface Antenna (DMA) is a cutting-edge antenna technology offering scalable and sustainable solutions for large antenna arrays. The effectiveness of DMAs stems from their inherent configurable analog signal processing capabilities, which facilitate cost-limited implementations. However, when DMAs are used in multiple input multiple output (MIMO) communication systems, they pose challenges in channel estimation due to their analog compression. In this paper, we propose two model-based learning methods to overcome this challenge. Our approach starts by casting channel estimation as a compressed sensing problem. Here, the sensing matrix is formed using a random DMA weighting matrix combined with a spatial gridding dictionary. We then employ the learned iterative shrinkage and thresholding algorithm (LISTA) to recover the sparse channel parameters. LISTA unfolds the iterative shrinkage and thresholding algorithm into a neural network and trains the neural network into a highly efficient channel estimator fitting with the previous channel. As the sensing matrix is crucial to the accuracy of LISTA recovery, we introduce another data-aided method, LISTA-sensing matrix optimization (LISTA-SMO), to jointly optimize the sensing matrix. LISTA-SMO takes LISTA as a backbone and embeds the sensing matrix optimization layers in LISTA's neural network, allowing for the optimization of the sensing matrix along with the training of LISTA. Furthermore, we propose a self-supervised learning technique to tackle the difficulty of acquiring noise-free data. Our numerical results demonstrate that LISTA outperforms traditional sparse recovery methods regarding channel estimation accuracy and efficiency. Besides, LISTA-SMO achieves better channel accuracy than LISTA, demonstrating the effectiveness in optimizing the sensing matrix.
</details>
<details>
<summary>摘要</summary>
dynamically metasurface antenna (DMA) 是一种前沿的天线技术，具有可扩展和可持续的解决方案。 DMA 的可 configurable 分析信号处理能力使其在成本限制下实现高效性。 然而，在多输入多输出 (MIMO) 通信系统中使用 DMA 会带来频道估计的挑战，因为 DMA 的分析压缩会导致频道估计困难。在这篇论文中，我们提出了两种基于模型学习方法来解决这个挑战。我们的方法是将频道估计视为压缩感知问题，其中感知矩阵由随机 DMA 质量矩阵和空间格点词典组成。然后，我们使用学习舒缩和阈值算法 (LISTA) 来恢复稀疏频道参数。LISTA 将舒缩和阈值算法拓展成神经网络，并在神经网络中培训一个高效的频道估计器，与之前的频道相符。在感知矩阵对于 LISTA 的准确性很重要，我们因此引入了另一种数据帮助的方法，即 LISTA-感知矩阵优化 (LISTA-SMO)。LISTA-SMO 将 LISTA 作为后备，并将感知矩阵优化层 embedding 在 LISTA 神经网络中，以同时优化感知矩阵和 LISTA 的训练。此外，我们还提出了一种无supervision learning技术，以解决获取干净数据的困难。我们的数字结果表明，LISTA 比传统稀疏恢复方法更高效和准确地进行频道估计。此外，LISTA-SMO 在频道准确性方面比 LISTA 高，证明了感知矩阵优化的效果。
</details></li>
</ul>
<hr>
<h2 id="Joint-Source-Channel-Coding-for-Channel-Adaptive-Digital-Semantic-Communications"><a href="#Joint-Source-Channel-Coding-for-Channel-Adaptive-Digital-Semantic-Communications" class="headerlink" title="Joint Source-Channel Coding for Channel-Adaptive Digital Semantic Communications"></a>Joint Source-Channel Coding for Channel-Adaptive Digital Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08146">http://arxiv.org/abs/2311.08146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joohyuk Park, Yongjeong Oh, Seonjung Kim, Yo-Seb Jeon</li>
<li>for: 这个论文旨在提出一种 JOINT SOURCE-CHANNEL CODING (JSCC) 方法，用于适应通道的数位 semantics 通信系统中。</li>
<li>methods: 这个方法使用了一种新的检测方法来改善数位semantics通信系统中的稳定性，并开发了一种可靠的终端训练策略，以提高 JSCC 编码器和解oder 的可靠性和灵活性。</li>
<li>results: 这个方法在实验中被证明可以对数位图像分类和重建任务进行改进，比较现有的 JSCC 方法表现更好。<details>
<summary>Abstract</summary>
In this paper, we propose a novel joint source-channel coding (JSCC) approach for channel-adaptive digital semantic communications. In semantic communication systems with digital modulation and demodulation, end-to-end training and robust design of JSCC encoder and decoder becomes challenging due to the nonlinearity of modulation and demodulation processes, as well as diverse channel conditions and modulation orders. To address this challenge, we first develop a new demodulation method which assesses the uncertainty of the demodulation output to improve the robustness of the digital semantic communication system. We then devise a robust training strategy that facilitates end-to-end training of the JSCC encoder and decoder, while enhancing their robustness and flexibility. To this end, we model the relationship between the encoder's output and decoder's input using binary symmetric erasure channels and then sample the parameters of these channels from diverse distributions. We also develop a channel-adaptive modulation technique for an inference phase, in order to reduce the communication latency while maintaining task performance. In this technique, we adaptively determine modulation orders for the latent variables based on channel conditions. Using simulations, we demonstrate the superior performance of the proposed JSCC approach for both image classification and reconstruction tasks compared to existing JSCC approaches.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的联合源码混合（JSCC）方法，用于适应通道condition下的数字semantic通信系统。在数字模ulation和демодуляción中，因为模ulation和демодуляción过程的非线性，以及不同通道条件和模ulationOrder，所以JSCC编码器和解码器的端到端训练和稳定设计变得挑战性更高。为 Addressing this challenge, we first develop a new demodulation method that assesses the uncertainty of the demodulation output to improve the robustness of the digital semantic communication system. We then devise a robust training strategy that facilitates end-to-end training of the JSCC encoder and decoder, while enhancing their robustness and flexibility. To this end, we model the relationship between the encoder's output and decoder's input using binary symmetric erasure channels, and then sample the parameters of these channels from diverse distributions. We also develop a channel-adaptive modulation technique for an inference phase, in order to reduce the communication latency while maintaining task performance. In this technique, we adaptively determine modulation orders for the latent variables based on channel conditions. Using simulations, we demonstrate the superior performance of the proposed JSCC approach for both image classification and reconstruction tasks compared to existing JSCC approaches.
</details></li>
</ul>
<hr>
<h2 id="On-the-View-and-Channel-Aggregation-Gain-in-Integrated-Sensing-and-Edge-AI"><a href="#On-the-View-and-Channel-Aggregation-Gain-in-Integrated-Sensing-and-Edge-AI" class="headerlink" title="On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge AI"></a>On the View-and-Channel Aggregation Gain in Integrated Sensing and Edge AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07986">http://arxiv.org/abs/2311.07986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Chen, Khaled B. Letaief, Kaibin Huang</li>
<li>For: The paper is written to explore the fundamental performance gains of view-and-channel aggregation in Integrated sensing and edge AI (ISEA) systems for Internet-of-Things (IoT) applications.* Methods: The paper uses a well-established distribution model of multi-view sensing data, which is modified to represent individual sensor observation perspectives. The authors also use a novel approach involving a scaling-tight uncertainty surrogate function, global discriminant gain, distribution of receive Signal-to-Noise Ratio (SNR), and channel induced discriminant loss to study the End-to-End sensing (inference) uncertainty of the ISEA system.* Results: The paper shows that the End-to-End sensing uncertainty diminishes at an exponential rate as the number of views&#x2F;sensors grows, with a rate proportional to global discriminant gain. Additionally, the authors find that the exponential scaling remains even with channel distortion, but with a reduced decay rate related to the channel induced discriminant loss. The insights from the paper are validated by experiments using real-world dataset.<details>
<summary>Abstract</summary>
Sensing and edge artificial intelligence (AI) are two key features of the sixth-generation (6G) mobile networks. Their natural integration, termed Integrated sensing and edge AI (ISEA), is envisioned to automate wide-ranging Internet-of-Tings (IoT) applications. To achieve a high sensing accuracy, multi-view features are uploaded to an edge server for aggregation and inference using an AI model. The view aggregation is realized efficiently using over-the-air computing (AirComp), which also aggregates channels to suppress channel noise. At its nascent stage, ISEA still lacks a characterization of the fundamental performance gains from view-and-channel aggregation, which motivates this work. Our framework leverages a well-established distribution model of multi-view sensing data where the classic Gaussian-mixture model is modified by adding sub-spaces matrices to represent individual sensor observation perspectives. Based on the model, we study the End-to-End sensing (inference) uncertainty, a popular measure of inference accuracy, of the said ISEA system by a novel approach involving designing a scaling-tight uncertainty surrogate function, global discriminant gain, distribution of receive Signal-to-Noise Ratio (SNR), and channel induced discriminant loss. We prove that the E2E sensing uncertainty diminishes at an exponential rate as the number of views/sensors grows, where the rate is proportional to global discriminant gain. Given channel distortion, we further show that the exponential scaling remains with a reduced decay rate related to the channel induced discriminant loss. Furthermore, we benchmark AirComp against equally fast, traditional analog orthogonal access, which reveals a sensing-accuracy crossing point between the schemes, leading to the proposal of adaptive access-mode switching. Last, the insights from our framework are validated by experiments using real-world dataset.
</details>
<details>
<summary>摘要</summary>
sixth-generation (6G) 无线网络中的感知和边缘人工智能（AI）是两个关键特点。将它们天然地融合起来，称为 интеegrated sensing and edge AI（ISEA），可以自动执行广泛的互联网东西（IoT）应用。以实现高精度感知，多视图特征被上传到边缘服务器进行聚合和推理使用AI模型。视图聚合可以高效地实现使用空中计算（AirComp），同时也可以聚合通道来抑制通道噪声。在它的早期阶段，ISEA仍然缺乏对视图和通道聚合的基本性能提升的Characterization，这种 motivates this work。我们的框架利用了已有的多视图感知数据分布模型，其中类型的 Gaussian-mixture model 被修改为包含个人感知观察角度的子空间矩阵。基于模型，我们研究ISEA系统的端到端感知（推理）uncertainty，一种流行的推理准确度度量，通过一种新的扩展紧急函数、全球Discriminant gain、接收Signal-to-Noise Ratio（SNR）分布和通道引起的Discriminant loss来研究。我们证明，端到端感知uncertainty在视图/感知器数量增加时 exponentially decay，其速率与全球Discriminant gain相关。在存在通道扭曲时，我们进一步证明，扩展 decay rate 与通道引起的Discriminant loss相关。此外，我们对AirComp和传统的Analog orthogonal access进行比较，发现感知准确度 crossing point  между两种方案，导致了对接入模式的自适应 switching。最后，我们的框架的发现被实际 dataset 验证。
</details></li>
</ul>
<hr>
<h2 id="Learning-Bayes-Optimal-Channel-Estimation-for-Holographic-MIMO-in-Unknown-EM-Environments"><a href="#Learning-Bayes-Optimal-Channel-Estimation-for-Holographic-MIMO-in-Unknown-EM-Environments" class="headerlink" title="Learning Bayes-Optimal Channel Estimation for Holographic MIMO in Unknown EM Environments"></a>Learning Bayes-Optimal Channel Estimation for Holographic MIMO in Unknown EM Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07908">http://arxiv.org/abs/2311.07908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Yu, Hengtao He, Xianghao Yu, Shenghui Song, Jun Zhang, Ross D. Murch, Khaled B. Letaief</li>
<li>For: The paper is written for future 6G systems that use holographic MIMO (HMIMO) technology, which requires efficient channel estimation in arbitrary and unknown EM environments.* Methods: The paper proposes a self-supervised minimum mean-square-error (MMSE) channel estimation algorithm based on powerful machine learning tools, including score matching and principal component analysis. The training stage requires only the pilot signals, without needing to know the spatial correlation, the ground-truth channels, or the received signal-to-noise-ratio.* Results: The proposed algorithm can approach the performance of the oracle MMSE method with an extremely low complexity, making it a competitive candidate in practice.Here is the same information in Simplified Chinese:* For: 这篇论文是为未来的6G系统而写的，该系统使用束幂MIMO（HMIMO）技术，需要高效的通道估计在不知道的EM环境中。* Methods: 论文提出一种基于强大机器学习工具的自助学习最小均方差（MMSE）通道估计算法，包括分数匹配和主成分分析。训练阶段只需要各个批处理信号，不需要知道空间相关性、真实通道分布或接收信号噪声级。* Results: 提议的算法可以接近oracle MMSE方法的性能，但具有极低的复杂性，使其在实践中成为竞争力强的候选人。<details>
<summary>Abstract</summary>
Holographic MIMO (HMIMO) has recently been recognized as a promising enabler for future 6G systems through the use of an ultra-massive number of antennas in a compact space to exploit the propagation characteristics of the electromagnetic (EM) channel. Nevertheless, the promised gain of HMIMO could not be fully unleashed without an efficient means to estimate the high-dimensional channel. Bayes-optimal estimators typically necessitate either a large volume of supervised training samples or a priori knowledge of the true channel distribution, which could hardly be available in practice due to the enormous system scale and the complicated EM environments. It is thus important to design a Bayes-optimal estimator for the HMIMO channels in arbitrary and unknown EM environments, free of any supervision or priors. This work proposes a self-supervised minimum mean-square-error (MMSE) channel estimation algorithm based on powerful machine learning tools, i.e., score matching and principal component analysis. The training stage requires only the pilot signals, without knowing the spatial correlation, the ground-truth channels, or the received signal-to-noise-ratio. Simulation results will show that, even being totally self-supervised, the proposed algorithm can still approach the performance of the oracle MMSE method with an extremely low complexity, making it a competitive candidate in practice.
</details>
<details>
<summary>摘要</summary>
依 Moore 多规模 MIMO (HMIMO) 在未来的 6G 系统中被认为是一个有前途的推动者，通过在受限空间内部署ULTRA 大量天线来利用电磁频谱（EM）频道的传播特性。然而， promise 的 HMIMO 潜在优势尚未得到充分发挥，因为需要一种有效的高维度通道估计方法。 Bayes 优化的估计器通常需要大量的supervised 训练样本或者假设true 通道分布，这些样本或分布在实际中很难获得，因为系统规模很大，EM 环境复杂。因此，这种工作提议了一种基于强大机器学习工具的自主Supervised 最小二乘误差（MMSE）通道估计算法。该算法只需要启动阶段的导航信号，不需要知道空间相关性，真实通道，或接收信号噪听率。 simulation 结果表明，即使完全自主，提议的算法仍然可以接近 oracle MMSE 方法的性能，而且具有极低的复杂度，使其在实践中成为竞争力强的候选人。
</details></li>
</ul>
<hr>
<h2 id="Passive-Human-Sensing-Enhanced-by-Reconfigurable-Intelligent-Surface-Opportunities-and-Challenges"><a href="#Passive-Human-Sensing-Enhanced-by-Reconfigurable-Intelligent-Surface-Opportunities-and-Challenges" class="headerlink" title="Passive Human Sensing Enhanced by Reconfigurable Intelligent Surface: Opportunities and Challenges"></a>Passive Human Sensing Enhanced by Reconfigurable Intelligent Surface: Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07873">http://arxiv.org/abs/2311.07873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Li, Jian Wei You, Ze Gu, Qian Ma, Long Chen, Jingyuan Zhang, Shi Jin, Tie Jun Cui</li>
<li>for: 这篇论文旨在探讨通过半导体智能表面（RIS）的干预，实现无线电信号中人体活动相关信息的探测。</li>
<li>methods: 论文首先介绍了RIS的基本原理和物理平台，然后根据不同应用场景，对现状技术进行了分类，包括人像、定位和活动识别。</li>
<li>results: 论文提出了基于RIS的微动诊断系统，并通过实验证明了这种技术在检测生理指标的潜在潜力。 finally, 论文还讨论了这一领域的技术挑战和机遇。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surfaces (RISs) have flexible and exceptional performance in manipulating electromagnetic waves and customizing wireless channels. These capabilities enable them to provide a plethora of valuable activity-related information for promoting wireless human sensing. In this article, we present a comprehensive review of passive human sensing using radio frequency signals with the assistance of RISs. Specifically, we first introduce fundamental principles and physical platform of RISs. Subsequently, based on the specific applications, we categorize the state-of-the-art human sensing techniques into three types, including human imaging,localization, and activity recognition. Meanwhile, we would also investigate the benefits that RISs bring to these applications. Furthermore, we explore the application of RISs in human micro-motion sensing, and propose a vital signs monitoring system enhanced by RISs. Experimental results are presented to demonstrate the promising potential of RISs in sensing vital signs for manipulating individuals. Finally, we discuss the technical challenges and opportunities in this field.
</details>
<details>
<summary>摘要</summary>
可重配置智能表面（RIS）具有 flexible 和异常表现，可以控制电磁波和自定义无线通道。这些能力使其能提供许多有价值的活动相关信息，以便促进无线人员感知。在这篇文章中，我们提供了无线人员感知的全面回顾，特别是通过 RIS 的帮助实现的。我们首先介绍 RIS 的基本原理和物理平台。然后，根据应用场景，我们将现有的人类感知技术分为三类，包括人像、本地化和活动识别。此外，我们还 investigate RIS 在人微动感知方面的应用，并提出了基于 RIS 的生命体矢量监测系统。实验结果表明，RIS 在感知生命体矢量方面具有普遍的潜力。最后，我们讨论了这一领域的技术挑战和机遇。
</details></li>
</ul>
<hr>
<h2 id="Cost-Efficient-Computation-Offloading-and-Service-Chain-Caching-in-LEO-Satellite-Networks"><a href="#Cost-Efficient-Computation-Offloading-and-Service-Chain-Caching-in-LEO-Satellite-Networks" class="headerlink" title="Cost-Efficient Computation Offloading and Service Chain Caching in LEO Satellite Networks"></a>Cost-Efficient Computation Offloading and Service Chain Caching in LEO Satellite Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07872">http://arxiv.org/abs/2311.07872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yantong Wang, Chuanfen Feng, Jiande Sun</li>
<li>for: 这篇论文的目的是提出一个基于 mobile-edge-computing 且考虑当地网络限制的 low earth orbit 卫星网络，以提高服务质量和可用性。</li>
<li>methods: 本论文使用一种称为服务链快照和计算卸载的方法，并考虑了协力运算、网络资源限制和服务链的特定运行顺序。</li>
<li>results: 研究结果显示，该方法可以降低总成本（包括任务延迟和能源消耗）约20%，相比于传统的资料中心架构。<details>
<summary>Abstract</summary>
The ever-increasing demand for ubiquitous, continuous, and high-quality services poses a great challenge to the traditional terrestrial network. To mitigate this problem, the mobile-edge-computing-enhanced low earth orbit (LEO) satellite network, which provides both communication connectivity and on-board processing services, has emerged as an effective method. The main issue in LEO satellites includes finding the optimal locations to host network functions (NFs) and then making offloading decisions. In this article, we jointly consider the problem of service chain caching and computation offloading to minimize the overall cost, which consists of task latency and energy consumption. In particular, the collaboration among satellites, the network resource limitations, and the specific operation order of NFs in service chains are taken into account. Then, the problem is formulated and linearized as an integer linear programming model. Moreover, to accelerate the solution, we provide a greedy algorithm with cubic time complexity. Numerical investigations demonstrate the effectiveness of the proposed scheme, which can reduce the overall cost by around 20% compared to the nominal case where NFs are served in data centers.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:随着服务需求的不断增长，传统的陆地网络面临着严重的挑战。为解决这问题，低轨道卫星网络（LEO），带有通信连接和机能处理服务，已经出现为有效的解决方案。LEO卫星中的主要问题是找到最佳的NF主机位置，然后做卸载决策。在这篇文章中，我们同时考虑服务链缓存和计算卸载问题，以最小化总成本，包括任务延迟和能耗总量。具体来说，我们考虑卫星之间的协作、网络资源的限制，以及服务链中NF的具体执行顺序。然后，我们将问题形式化并Linear化为整数线性 програм序列。此外，为加速解决，我们提供了一种 cubic 时间复杂度的急速算法。数值调查表明，我们的方案可以相比nominal情况下，降低总成本约20%。
</details></li>
</ul>
<hr>
<h2 id="On-the-IRS-Deployment-in-Smart-Factories-Considering-Blockage-Effects-Collocated-or-Distributed"><a href="#On-the-IRS-Deployment-in-Smart-Factories-Considering-Blockage-Effects-Collocated-or-Distributed" class="headerlink" title="On the IRS Deployment in Smart Factories Considering Blockage Effects: Collocated or Distributed?"></a>On the IRS Deployment in Smart Factories Considering Blockage Effects: Collocated or Distributed?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07843">http://arxiv.org/abs/2311.07843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Zhang, Saeed R. Khosravirad, Xiaoli Chu, Mikko A. Uusitalo</li>
<li>for: 该研究旨在支持工厂内的增强移动广播和低延迟通信服务，通过智能反射表面（IRS）的排列和分布部署。</li>
<li>methods: 该研究使用了一个渠道模型，该模型包括每个传输路径的线视图概率和功率损失，并提出了三个纪录器，即预期的噪声比率、预期的块列长度（FB）容量和预期的失业概率，其中预期是通过内部堵塞和通道抑制的概率分布来计算。</li>
<li>results: 研究发现，对于高堵塞密度，分布部署可以提高预期接收噪声比率和预期FB容量；对于低堵塞密度，URLLC服务可以从分布部署中受益，而eMBB服务则不受分布部署的影响。<details>
<summary>Abstract</summary>
In this article, we study the collocated and distributed deployment of intelligent reflecting surfaces (IRS) for a fixed total number of IRS elements to support enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) services inside a factory. We build a channel model that incorporates the line-of-sight (LOS) probability and power loss of each transmission path, and propose three metrics, namely, the expected received signal-to-noise ratio (SNR), expected finite-blocklength (FB) capacity, and expected outage probability, where the expectation is taken over the probability distributions of interior blockages and channel fading. The expected received SNR and expected FB capacity for extremely high blockage densities are derived in closed-form as functions of the amount and height of IRSs and the density, size, and penetration loss of blockages, which are verified by Monte Carlo simulations. Results show that deploying IRSs vertically higher leads to higher expected received SNR and expected FB capacity. By analysing the average/minimum/maximum of the three metrics versus the number of IRSs, we find that for high blockage densities, both eMBB and URLLC services benefit from distributed deployment; and for low blockage densities, URLLC services benefit from distributed deployment while eMBB services see limited difference between collocated and distributed deployment.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们研究了彩色彩镜（IRS）的分布式部署，以支持内部的增强移动广播（eMBB）和低延迟低可靠通信（URLLC）服务。我们构建了一个通道模型，该模型包括每个传输路径的直视程度（LOS）概率和功率损失，并提出了三个指标，即预期的干扰比率（SNR）、预期的固定块长度（FB）容量，以及预期的失业概率。这三个指标的预期值在高封闭率下是几何函数，它们随着彩镜数量和封闭物体的密度、大小和渗透损失而变化。我们通过 Monte Carlo 仿真来验证这些结果。结果显示，彩镜高度越高，预期的干扰比率和固定块长度容量都越高。通过分析平均/最小/最大的三个指标对彩镜数量的影响，我们发现在高封闭率下， beiden eMBB 和 URLLC 服务都受益于分布式部署；在低封闭率下，URLLC 服务受益于分布式部署，而 eMBB 服务则不受分布式部署的影响。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/14/eess.SP_2023_11_14/" data-id="clpztdnvs01hyes881cm0f7ej" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.SD_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T15:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.SD_2023_11_13/">cs.SD - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distributed-pressure-matching-strategy-using-diffusion-adaptation"><a href="#Distributed-pressure-matching-strategy-using-diffusion-adaptation" class="headerlink" title="Distributed pressure matching strategy using diffusion adaptation"></a>Distributed pressure matching strategy using diffusion adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07729">http://arxiv.org/abs/2311.07729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengfei Zhang, Junqing Zhang, Jie Chen, Cédric Richard</li>
<li>for: 这篇论文是关于如何解决个人声区系统（PSZ）任务中的时变Acoustic问题的。</li>
<li>methods: 这篇论文提出了一种分布式压力匹配（PM）方法，利用分散适应（DPM-D）技术来分散计算负担，从而解决中央化方法的高计算复杂性和高精度要求。</li>
<li>results:  simulations和计算复杂性分析表明，分布式PM方法在多频分布式环境中具有更高的计算效率和精度，与中央化方法相比。<details>
<summary>Abstract</summary>
Personal sound zone (PSZ) systems, which aim to create listening (bright) and silent (dark) zones in neighboring regions of space, are often based on time-varying acoustics. Conventional adaptive-based methods for handling PSZ tasks suffer from the collection and processing of acoustic transfer functions~(ATFs) between all the matching microphones and all the loudspeakers in a centralized manner, resulting in high calculation complexity and costly accuracy requirements. This paper presents a distributed pressure-matching (PM) method relying on diffusion adaptation (DPM-D) to spread the computational load amongst nodes in order to overcome these issues. The global PM problem is defined as a sum of local costs, and the diffusion adaption approach is then used to create a distributed solution that just needs local information exchanges. Simulations over multi-frequency bins and a computational complexity analysis are conducted to evaluate the properties of the algorithm and to compare it with centralized counterparts.
</details>
<details>
<summary>摘要</summary>
personal sound zone (PSZ) 系统，目的在于在邻近空间区域创建听众（亮）和沉默（暗）区域，经常基于时变音响学。传统的适应基于方法（ATF）处理 PSZ 任务，由于需要收集和处理所有听笔和所有扬声器之间的听音传函数（ATF），因此会带来高度复杂的计算和昂贵的准确性要求。本文提出了分布式压力匹配（PM）方法，基于扩散适应（DPM-D）来分担计算负担，以超越这些问题。全局 PM 问题定义为一个Local cost的总和，然后使用扩散适应approach来创建分布式解决方案，只需要本地信息交换。通过多频分布和计算复杂性分析，评估算法的性能和与中央化对手进行比较。
</details></li>
</ul>
<hr>
<h2 id="Efficient-bandwidth-extension-of-musical-signals-using-a-differentiable-harmonic-plus-noise-mode"><a href="#Efficient-bandwidth-extension-of-musical-signals-using-a-differentiable-harmonic-plus-noise-mode" class="headerlink" title="Efficient bandwidth extension of musical signals using a differentiable harmonic plus noise mode"></a>Efficient bandwidth extension of musical signals using a differentiable harmonic plus noise mode</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07363">http://arxiv.org/abs/2311.07363</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mathieulagrange/ddspmusicbandwidthextension">https://github.com/mathieulagrange/ddspmusicbandwidthextension</a></li>
<li>paper_authors: Pierre-Amaury Grumiaux, Mathieu Lagrange</li>
<li>for:  Audio signal bandwidth extension, specifically for monophonic and polyphonic musical signals.</li>
<li>methods:  Uses a differentiable digital signal processing (DDSP) model, which is a neural network with relatively few parameters that is trained to infer the parameters of a differentiable digital signal processing model.</li>
<li>results:  Proposed models surpass a higher complexity deep learning model for an objective metric computed in the frequency domain, and are also confirmed to have superior perceptual quality through a MUSHRA listening test.Here’s the Chinese translation of the three points:</li>
<li>for:  audio信号带宽扩展，特别是对于单声道和多声道乐音信号。</li>
<li>methods: 使用梯度可微的数字信号处理（DDSP）模型，该模型是一个具有相对少量参数的神经网络，用于推理DDSP模型的参数。</li>
<li>results: 提议的模型在频域中的一个对象指标上超过了更高复杂度的深度学习模型，并通过MUSHRA听力测试得到了更好的感知质量。<details>
<summary>Abstract</summary>
The task of bandwidth extension addresses the generation of missing high frequencies of audio signals based on knowledge of the low-frequency part of the sound. This task applies to various problems, such as audio coding or audio restoration. In this article, we focus on efficient bandwidth extension of monophonic and polyphonic musical signals using a differentiable digital signal processing (DDSP) model. Such a model is composed of a neural network part with relatively few parameters trained to infer the parameters of a differentiable digital signal processing model, which efficiently generates the output full-band audio signal.   We first address bandwidth extension of monophonic signals, and then propose two methods to explicitely handle polyphonic signals. The benefits of the proposed models are first demonstrated on monophonic and polyphonic synthetic data against a baseline and a deep-learning-based resnet model. The models are next evaluated on recorded monophonic and polyphonic data, for a wide variety of instruments and musical genres. We show that all proposed models surpass a higher complexity deep learning model for an objective metric computed in the frequency domain. A MUSHRA listening test confirms the superiority of the proposed approach in terms of perceptual quality.
</details>
<details>
<summary>摘要</summary>
音频信号的带宽扩展问题是基于听到的低频部分声音的知识，生成缺失的高频部分。这个问题适用于各种问题，如音频编码或音频修复。在这篇文章中，我们关注使用拟 diferenciable digital signal processing（DDSP）模型进行高效的带宽扩展。这种模型由一个具有相对少量参数的神经网络部分和一个可微分的数字信号处理模型组成。这种模型可以高效地生成全带宽音频信号。我们首先对单声音信号进行带宽扩展，然后提出了两种方法来特别处理多声音信号。我们在单声音和多声音 sintetic 数据上对基线和深度学习模型进行比较，并证明了我们的模型在频域中的目标指标上胜过深度学习模型。在录制的单声音和多声音数据上，我们发现所有我们提出的模型都超过了深度学习模型的高复杂性。在Perceptual Quality 中，我们通过 MUSHRA 听测表明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Duet-Singing-Voices-Separation-with-Diffusion-Models"><a href="#Zero-Shot-Duet-Singing-Voices-Separation-with-Diffusion-Models" class="headerlink" title="Zero-Shot Duet Singing Voices Separation with Diffusion Models"></a>Zero-Shot Duet Singing Voices Separation with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07345">http://arxiv.org/abs/2311.07345</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yoyololicon/duet-svs-diffusion">https://github.com/yoyololicon/duet-svs-diffusion</a></li>
<li>paper_authors: Chin-Yun Yu, Emilian Postolache, Emanuele Rodolà, György Fazekas</li>
<li>for: 这篇论文是为了解决对声音反问题中的源分离问题，具体来说是在分离二人或更多人的合唱声音中，保持歌手身份的一致性。</li>
<li>methods: 这篇论文使用了扩散模型作为假设，通过控制扩散过程来采样 posterior 分布中的目标信号。在解决对声音反问题中，提议使用 auto-regressive 方式进行 posterior 采样，并在每个过程中使用前一个过程的结果来保持歌手身份的一致性。</li>
<li>results: 在使用 MedleyVox 数据集进行评估时，提议的方法比基于 posterior 采样的基线方法表现更好，能够更好地保持歌手身份的一致性。<details>
<summary>Abstract</summary>
In recent studies, diffusion models have shown promise as priors for solving audio inverse problems. These models allow us to sample from the posterior distribution of a target signal given an observed signal by manipulating the diffusion process. However, when separating audio sources of the same type, such as duet singing voices, the prior learned by the diffusion process may not be sufficient to maintain the consistency of the source identity in the separated audio. For example, the singer may change from one to another occasionally. Tackling this problem will be useful for separating sources in a choir, or a mixture of multiple instruments with similar timbre, without acquiring large amounts of paired data. In this paper, we examine this problem in the context of duet singing voices separation, and propose a method to enforce the coherency of singer identity by splitting the mixture into overlapping segments and performing posterior sampling in an auto-regressive manner, conditioning on the previous segment. We evaluate the proposed method on the MedleyVox dataset and show that the proposed method outperforms the naive posterior sampling baseline. Our source code and the pre-trained model are publicly available at https://github.com/yoyololicon/duet-svs-diffusion.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Research-and-experimental-verification-on-low-frequency-long-range-underwater-sound-propagation-dispersion-characteristics-under-dual-channel-sound-speed-profiles-in-the-Chukchi-Plateau"><a href="#Research-and-experimental-verification-on-low-frequency-long-range-underwater-sound-propagation-dispersion-characteristics-under-dual-channel-sound-speed-profiles-in-the-Chukchi-Plateau" class="headerlink" title="Research and experimental verification on low-frequency long-range underwater sound propagation dispersion characteristics under dual-channel sound speed profiles in the Chukchi Plateau"></a>Research and experimental verification on low-frequency long-range underwater sound propagation dispersion characteristics under dual-channel sound speed profiles in the Chukchi Plateau</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.08425">http://arxiv.org/abs/2311.08425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbao Weng, Yubo Qi, Yanming Yang, Hongtao Wen, Hongtao Zhou, Ruichao Xue</li>
<li>for: 研究了俄罗斯海和加拿大海湾的双通道声速 Profiling下的低频宽带声信号propagation特性</li>
<li>methods: 使用了正常模式理论来研究低频宽带声信号propagation dispersion的细结构，并使用修改后的扭变算符来分离正常模式</li>
<li>results: 解释了双通道声速 Profiling下normal mode dispersion曲线交叉的问题，分析了海底地形变化对dispersion结构的屏蔽效应，并通过长距离地震探测实验在俄罗斯海湾进行验证Here’s the same information in English:</li>
<li>for: Researched the low-frequency wide-band sound signal propagation characteristics under dual-channel sound speed profiles in the Chukchi Plateau and the Canadian Basin</li>
<li>methods: Used the theory of normal modes to study the fine structure of low-frequency wide-band sound propagation dispersion under dual-channel sound speed profiles, and used a modified warping operator to separate the normal modes</li>
<li>results: Explained the intersection of normal mode dispersion curves caused by the dual-channel sound speed profile, analyzed the blocking effect of seabed terrain changes on dispersion structures, and verified the results through a long-range seismic exploration experiment at the Chukchi Plateau. Additionally, proposed two methods for estimating the distance of sound sources based on acoustic signal characteristics in this environment, and verified these methods through experiment data at sea.<details>
<summary>Abstract</summary>
The dual-channel sound speed profiles of the Chukchi Plateau and the Canadian Basin have become current research hotspots due to their excellent low-frequency sound signal propagation ability. Previous research has mainly focused on using sound propagation theory to explain the changes in sound signal energy. This article is mainly based on the theory of normal modes to study the fine structure of low-frequency wide-band sound propagation dispersion under dual-channel sound speed profiles. In this paper, the problem of the intersection of normal mode dispersion curves caused by the dual-channel sound speed profile (SSP) has been explained, the blocking effect of seabed terrain changes on dispersion structures has been analyzed, and the normal modes has been separated by using modified warping operator. The above research results have been verified through a long-range seismic exploration experiment at the Chukchi Plateau. At the same time, based on the acoustic signal characteristics in this environment, two methods for estimating the distance of sound sources have been proposed, and the experiment data at sea has also verified these two methods.
</details>
<details>
<summary>摘要</summary>
“中险棚渠和加拿大海盆的双渠道声速 Profilestoday是研究热点，因为它们具有出色的低频声信号传播能力。以前的研究主要基于声传播理论来解释声信号能量的变化。本文基于准模理论来研究在双渠道声速 Profilestop下细腔低频宽带声信号传播折叠的细结构。文中解释了双渠道声速 Profilestop下准模折叠曲线的交叠问题，分析了海底地形变化对折叠结构的屏蔽效应，并使用修改的折卷算子来分离准模。研究结果得到了在鄂霍次克棚渠进行长距离地震探测实验的验证。同时，根据海洋环境中声信号特点，提出了两种方法来估计声源距离，并在实验数据上验证了这两种方法。”Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="SponTTS-modeling-and-transferring-spontaneous-style-for-TTS"><a href="#SponTTS-modeling-and-transferring-spontaneous-style-for-TTS" class="headerlink" title="SponTTS: modeling and transferring spontaneous style for TTS"></a>SponTTS: modeling and transferring spontaneous style for TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07179">http://arxiv.org/abs/2311.07179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kkksuper/SponTTS">https://github.com/kkksuper/SponTTS</a></li>
<li>paper_authors: Hanzhao Li, Xinfa Zhu, Liumeng Xue, Yang Song, Yunlin Chen, Lei Xie<br>for:本文主要用于模型和传递自由式发言的 Style，以提高自由式发言的自然性、表达力和发音相似性。methods:本文提出了一种两阶段方法，首先采用 Conditional Variational Autoencoder (CVAE) 来捕捉自由式发言的准则，并通过偏置自由式现象嵌入预测损失来包含自由式现象。其次，我们引入了流程基于预测器来预测文本中的自由式样式表示，以增强在推理中的语音和语境特定自由式现象。results:实验表明，SponTTS 能够有效地模型自由式 Style 并传递 Style 到目标说话者，生成自由式语音具有高度的自然性、表达力和发音相似性。 zero-shot 自由式 Style TTS 测试进一步证明了 SponTTS 在生成未经见过的说话者的自由式语音时的普适性和稳定性。<details>
<summary>Abstract</summary>
Spontaneous speaking style exhibits notable differences from other speaking styles due to various spontaneous phenomena (e.g., filled pauses, prolongation) and substantial prosody variation (e.g., diverse pitch and duration variation, occasional non-verbal speech like smile), posing challenges to modeling and prediction of spontaneous style. Moreover, the limitation of high-quality spontaneous data constrains spontaneous speech generation for speakers without spontaneous data. To address these problems, we propose SponTTS, a two-stage approach based on bottleneck (BN) features to model and transfer spontaneous style for TTS. In the first stage, we adopt a Conditional Variational Autoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve the spontaneous phenomena by the constraint of spontaneous phenomena embedding prediction loss. Besides, we introduce a flow-based predictor to predict a latent spontaneous style representation from the text, which enriches the prosody and context-specific spontaneous phenomena during inference. In the second stage, we adopt a VITS-like module to transfer the spontaneous style learned in the first stage to target speakers. Experiments demonstrate that SponTTS is effective in modeling spontaneous style and transferring the style to the target speakers, generating spontaneous speech with high naturalness, expressiveness, and speaker similarity. The zero-shot spontaneous style TTS test further verifies the generalization and robustness of SponTTS in generating spontaneous speech for unseen speakers.
</details>
<details>
<summary>摘要</summary>
自然口语风格 exhibits  notable differences from other speaking styles due to various spontaneous phenomena (e.g., filled pauses, prolongation) and substantial prosody variation (e.g., diverse pitch and duration variation, occasional non-verbal speech like smile), posing challenges to modeling and prediction of spontaneous style. Moreover, the limitation of high-quality spontaneous data constrains spontaneous speech generation for speakers without spontaneous data. To address these problems, we propose SponTTS, a two-stage approach based on bottleneck (BN) features to model and transfer spontaneous style for TTS. In the first stage, we adopt a Conditional Variational Autoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve the spontaneous phenomena by the constraint of spontaneous phenomena embedding prediction loss. Besides, we introduce a flow-based predictor to predict a latent spontaneous style representation from the text, which enriches the prosody and context-specific spontaneous phenomena during inference. In the second stage, we adopt a VITS-like module to transfer the spontaneous style learned in the first stage to target speakers. Experiments demonstrate that SponTTS is effective in modeling spontaneous style and transferring the style to the target speakers, generating spontaneous speech with high naturalness, expressiveness, and speaker similarity. The zero-shot spontaneous style TTS test further verifies the generalization and robustness of SponTTS in generating spontaneous speech for unseen speakers.
</details></li>
</ul>
<hr>
<h2 id="Research-and-experimental-verification-on-low-frequency-long-range-sound-propagation-characteristics-under-ice-covered-and-range-dependent-marine-environment-in-the-Arctic"><a href="#Research-and-experimental-verification-on-low-frequency-long-range-sound-propagation-characteristics-under-ice-covered-and-range-dependent-marine-environment-in-the-Arctic" class="headerlink" title="Research and experimental verification on low-frequency long-range sound propagation characteristics under ice-covered and range-dependent marine environment in the Arctic"></a>Research and experimental verification on low-frequency long-range sound propagation characteristics under ice-covered and range-dependent marine environment in the Arctic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07175">http://arxiv.org/abs/2311.07175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbao Weng, Yubo Qi, Yanming Yang, Hongtao Wen, Hongtao Zhou, Ruichao Xue</li>
<li>for: 这篇论文主要研究的是在北极冰层下propagation of low-frequency broadband acoustic signals，尤其是声传输损耗和声信号的时域波形和细谱结构。</li>
<li>methods: 该文使用了normal modes theory和 measurement of ocean environmental parameters和声场计算来研究北极深海环境中low-frequency long-range声信号的一般法律，并解释了环境因素如海底地形变化、水 column velocity profile变化和海冰覆盖的影响 mechanisms on low-frequency long-range sound propagation in the Arctic.</li>
<li>results: 该文通过在北极进行了一次声传播实验，并确认了上述研究观点，并首次使用了折射正常波的折射变换器来实现单一ydrophone based separation of normal waves and extraction of dispersion structures.<details>
<summary>Abstract</summary>
At present, research on sound propagation under the Arctic ice mainly focuses on modeling and experimental verification of sound propagation under sea ice cover and unique sound velocity profiles. Among them, the main research object of concern is sound transmission loss, and this article will delve into the time-domain waveform and fine dispersion structure of low-frequency broadband acoustic signals. Firstly, based on the theory of normal modes, this article derives the horizontal wavenumber expression and warping transformation operator for refractive normal modes in the Arctic deep-sea environment. Subsequently, based on measured ocean environmental parameters and sound field simulation calculations, this article studied the general laws of low-frequency long-range sound propagation signals in the Arctic deep-sea environment, and elucidated the impact mechanism of environmental factors such as seabed terrain changes, horizontal changes in sound velocity profiles (SSPs), and sea ice cover on low-frequency long-range sound propagation in the Arctic. This article validates the above research viewpoint through a sound propagation experiment conducted in the Arctic with a propagation distance exceeding 1000km. The marine environment of this experiment has obvious horizontal variation characteristics. At the same time, this article takes the lead in utilizing the warping transformation of refractive normal waves in the Arctic waters to achieve single hydrophone based separation of normal waves and extraction of dispersion structures, which is conducive to future research on underwater sound source localization and environmental parameter inversion based on dispersion structures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现在，在北极冰层下的声波传播研究主要集中在模拟和实验验证冰层下的声波传播，以及独特的声速 Profil。其中，研究对象主要是声传损，这篇文章将探讨声波时域波形和细谱振荡结构的低频广频声信号。首先，根据正常模式理论，这篇文章 derivates了在北极深海环境中的横向波数表达和折叠变换算子。然后，通过测量海洋环境参数和声场 simulate calculation，这篇文章研究了北极深海环境中低频长距离声波传播的通用规律，并描述了环境因素如海底地形变化、水 Column 的横向声速 Profil 变化和海冰覆盖的影响于北极深海环境中低频长距离声波传播。这篇文章通过在北极进行了超过 1000km 的声波传播实验， validate 了上述研究视角。实验 Marine 环境具有明显的横向变化特征。同时，这篇文章首次利用北极水域中的折叠变换来实现单 hydrophone 基于 separation of normal waves 和折叠结构的提取，这有助于未来基于折叠结构的声源 localization 和环境参数反射。
</details></li>
</ul>
<hr>
<h2 id="Music-ControlNet-Multiple-Time-varying-Controls-for-Music-Generation"><a href="#Music-ControlNet-Multiple-Time-varying-Controls-for-Music-Generation" class="headerlink" title="Music ControlNet: Multiple Time-varying Controls for Music Generation"></a>Music ControlNet: Multiple Time-varying Controls for Music Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07069">http://arxiv.org/abs/2311.07069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shih-Lun Wu, Chris Donahue, Shinji Watanabe, Nicholas J. Bryan</li>
<li>for: 这个论文的目的是提出一种基于扩散的音乐生成模型，允许用户在不同的时间点进行精细控制音乐的生成。</li>
<li>methods: 该模型使用了一种基于扩散的 conditional generative model，通过在音频spectrogram上进行微调来实现时间点的控制。</li>
<li>results: 该模型可以生成具有高质量和精细控制的音乐，并且在不同的时间点进行控制。与其他相似的音乐生成模型进行比较，该模型能够生成更 faithful 的音乐，即使它具有许多 fewer 参数和训练数据。<details>
<summary>Abstract</summary>
Text-to-music generation models are now capable of generating high-quality music audio in broad styles. However, text control is primarily suitable for the manipulation of global musical attributes like genre, mood, and tempo, and is less suitable for precise control over time-varying attributes such as the positions of beats in time or the changing dynamics of the music. We propose Music ControlNet, a diffusion-based music generation model that offers multiple precise, time-varying controls over generated audio. To imbue text-to-music models with time-varying control, we propose an approach analogous to pixel-wise control of the image-domain ControlNet method. Specifically, we extract controls from training audio yielding paired data, and fine-tune a diffusion-based conditional generative model over audio spectrograms given melody, dynamics, and rhythm controls. While the image-domain Uni-ControlNet method already allows generation with any subset of controls, we devise a new strategy to allow creators to input controls that are only partially specified in time. We evaluate both on controls extracted from audio and controls we expect creators to provide, demonstrating that we can generate realistic music that corresponds to control inputs in both settings. While few comparable music generation models exist, we benchmark against MusicGen, a recent model that accepts text and melody input, and show that our model generates music that is 49% more faithful to input melodies despite having 35x fewer parameters, training on 11x less data, and enabling two additional forms of time-varying control. Sound examples can be found at https://MusicControlNet.github.io/web/.
</details>
<details>
<summary>摘要</summary>
文本到音乐生成模型现在可以生成高质量的音乐声音，但是文本控制主要适用于globale musical attribute的控制，如种类、情感和旋律，而不太适合精确控制时间变化的属性，如音乐的拍点位置或变化的声音 dynamics。我们提出了Music ControlNet，一种 diffusion-based music生成模型，提供了多种精确、时间变化的控制方法。为了让文本到音乐模型具有时间变化控制，我们采用了像 pixel-wise control的image-domain ControlNet方法。具体来说，我们从训练音频中提取控制，并使用 diffusion-based conditional生成模型在音频spectrogram中进行了 fine-tune。而在image-domain ControlNet方法中，可以生成任何subset of controls，我们开发了一种新的策略，允许创作者输入只部分Specified in time的控制。我们对于从音频中提取的控制和我们预期创作者提供的控制进行评估，示出了我们可以在两种设置下生成符合控制输入的真实音乐。虽然只有少数相关的音乐生成模型存在，我们对MusicGen，一种最近的模型，进行了比较，并显示了我们的模型可以生成与输入旋律更加准确的音乐，即使有35倍少于参数，在11倍少于数据上进行了训练，并允许两种额外的时间变化控制。音乐示例可以在https://MusicControlNet.github.io/web/中找到。
</details></li>
</ul>
<hr>
<h2 id="Decoupling-and-Interacting-Multi-Task-Learning-Network-for-Joint-Speech-and-Accent-Recognition"><a href="#Decoupling-and-Interacting-Multi-Task-Learning-Network-for-Joint-Speech-and-Accent-Recognition" class="headerlink" title="Decoupling and Interacting Multi-Task Learning Network for Joint Speech and Accent Recognition"></a>Decoupling and Interacting Multi-Task Learning Network for Joint Speech and Accent Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07062">http://arxiv.org/abs/2311.07062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qijie Shao, Pengcheng Guo, Jinghao Yan, Pengfei Hu, Lei Xie</li>
<li>for: 这个论文的目的是提出一种基于多任务学习的语音识别和口音识别模型（DIMNet），以提高多口音场景下的语音识别精度。</li>
<li>methods: 这个模型使用了分解连接主义时间分类（CTC）分支、语音识别（ASR）分支和口音识别（AR）分支，并使用了两种粒度的模型单元来学习任务特有的表示。此外，模型还使用了文本掌握和口音特征的交互来提高语音识别和口音识别的性能。</li>
<li>results: 试验结果表明，提出的模型在英语和中文数据集上都达到了比较出色的性能，相比标准基准模型，AR准确率提高21.45%&#x2F;28.53%，ASR错误率下降32.33%&#x2F;14.55%。<details>
<summary>Abstract</summary>
Accents, as variations from standard pronunciation, pose significant challenges for speech recognition systems. Although joint automatic speech recognition (ASR) and accent recognition (AR) training has been proven effective in handling multi-accent scenarios, current multi-task ASR-AR approaches overlook the granularity differences between tasks. Fine-grained units capture pronunciation-related accent characteristics, while coarse-grained units are better for learning linguistic information. Moreover, an explicit interaction of two tasks can also provide complementary information and improve the performance of each other, but it is rarely used by existing approaches. In this paper, we propose a novel Decoupling and Interacting Multi-task Network (DIMNet) for joint speech and accent recognition, which is comprised of a connectionist temporal classification (CTC) branch, an AR branch, an ASR branch, and a bottom feature encoder. Specifically, AR and ASR are first decoupled by separated branches and two-granular modeling units to learn task-specific representations. The AR branch is from our previously proposed linguistic-acoustic bimodal AR model and the ASR branch is an encoder-decoder based Conformer model. Then, for the task interaction, the CTC branch provides aligned text for the AR task, while accent embeddings extracted from our AR model are incorporated into the ASR branch's encoder and decoder. Finally, during ASR inference, a cross-granular rescoring method is introduced to fuse the complementary information from the CTC and attention decoder after the decoupling. Our experiments on English and Chinese datasets demonstrate the effectiveness of the proposed model, which achieves 21.45%/28.53% AR accuracy relative improvement and 32.33%/14.55% ASR error rate relative reduction over a published standard baseline, respectively.
</details>
<details>
<summary>摘要</summary>
字符识别（ASR）和口音识别（AR）是两个相关的任务，但是传统的多任务学习方法通常忽略了这两个任务之间的细腻差异。我们在本文提出了一种新的分离和互动多任务网络（DIMNet），用于同时进行字符识别和口音识别。该模型包括一个连接式时间分类（CTC）分支、一个AR分支、一个ASR分支和底层特征编码器。特别是，AR和ASR两个任务首先被分离为两个不同的分支和两个不同的模型单元，以学习任务特定的表示。AR分支采用我们之前提出的语言-听音双模型，而ASR分支采用一个基于Conformer模型的encoder-decoder结构。然后，为了实现任务之间的互动，CTC分支提供了对AR任务的已知文本，而AR模型中提取出来的口音嵌入被integrated到ASR分支的编码器和解码器中。最后，在ASR推理过程中，我们引入了一种交叉гра듷推理方法，以融合CTC和注意力解码器中的补充信息。我们在英语和中文 dataset上进行了实验，并证明了我们的模型的效果，其中对于英语 dataset，Relative AR准确率提高21.45%，Relative ASR错误率降低32.33%，对于中文 dataset，Relative AR准确率提高28.53%，Relative ASR错误率降低14.55%，相比之下，相对提高了21.45%/28.53%和32.33%/14.55%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.SD_2023_11_13/" data-id="clpztdnp2012ees88fm9j5a71" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/13/cs.CV_2023_11_13/" class="article-date">
  <time datetime="2023-11-13T13:00:00.000Z" itemprop="datePublished">2023-11-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/13/cs.CV_2023_11_13/">cs.CV - 2023-11-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Assessing-Test-time-Variability-for-Interactive-3D-Medical-Image-Segmentation-with-Diverse-Point-Prompts"><a href="#Assessing-Test-time-Variability-for-Interactive-3D-Medical-Image-Segmentation-with-Diverse-Point-Prompts" class="headerlink" title="Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts"></a>Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07806">http://arxiv.org/abs/2311.07806</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/medicl-vu/variability">https://github.com/medicl-vu/variability</a></li>
<li>paper_authors: Hao Li, Han Liu, Dewei Hu, Jiacheng Wang, Ipek Oguz</li>
<li>for: 这 paper 是为了研究 interactive medical image segmentation 的可靠性和可重现性问题。</li>
<li>methods: 这 paper 使用了 prompt engineering 技术，通过在测试时提供用户提示来生成精准的分割结果。</li>
<li>results: 这 paper 的实验结果表明，在使用多个点提示时，可以提高分割精度和可重现性。同时，通过对提示的位置和数量进行优化，可以提高分割结果的可靠性。<details>
<summary>Abstract</summary>
Interactive segmentation model leverages prompts from users to produce robust segmentation. This advancement is facilitated by prompt engineering, where interactive prompts serve as strong priors during test-time. However, this is an inherently subjective and hard-to-reproduce process. The variability in user expertise and inherently ambiguous boundaries in medical images can lead to inconsistent prompt selections, potentially affecting segmentation accuracy. This issue has not yet been extensively explored for medical imaging. In this paper, we assess the test-time variability for interactive medical image segmentation with diverse point prompts. For a given target region, the point is classified into three sub-regions: boundary, margin, and center. Our goal is to identify a straightforward and efficient approach for optimal prompt selection during test-time based on three considerations: (1) benefits of additional prompts, (2) effects of prompt placement, and (3) strategies for optimal prompt selection. We conduct extensive experiments on the public Medical Segmentation Decathlon dataset for challenging colon tumor segmentation task. We suggest an optimal strategy for prompt selection during test-time, supported by comprehensive results. The code is publicly available at https://github.com/MedICL-VU/variability
</details>
<details>
<summary>摘要</summary>
互动分割模型利用用户提供的提示来生成稳定的分割。这个进步得到了提示工程学支持，其中互动提示在试用时作为强大的先验条件。然而，这是一个内在受主观和难以重复的过程。用户专业知识和医疗影像中的自然欠缺缘点可能导致提示选择不稳定，这可能对分割精度产生影响。这个问题在医疗影像分割领域仍未得到充分探讨。在这篇研究中，我们评估了互动医疗影像分割中多个点提示的试用时间多样性。对于给定目标区域，点会被分为三个子区域：boundary、margin和center。我们的目标是发现一个简单和高效的方法，以便在试用时间选择最佳提示，基于以下三个考虑因素：1. 额外提示的优点2. 提示位置的影响3. 最佳提示选择策略我们在公共的医疗影像分割十大项目数据集上进行了广泛的实验，以挑战colon淋巴癌分割任务。我们建议一个最佳的提示选择策略，并提供了全面的结果。软件可以在https://github.com/MedICL-VU/variability上获取。
</details></li>
</ul>
<hr>
<h2 id="CSLP-AE-A-Contrastive-Split-Latent-Permutation-Autoencoder-Framework-for-Zero-Shot-Electroencephalography-Signal-Conversion"><a href="#CSLP-AE-A-Contrastive-Split-Latent-Permutation-Autoencoder-Framework-for-Zero-Shot-Electroencephalography-Signal-Conversion" class="headerlink" title="CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion"></a>CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07788">http://arxiv.org/abs/2311.07788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andersxa/cslp-ae">https://github.com/andersxa/cslp-ae</a></li>
<li>paper_authors: Anders Vestergaard Nørskov, Alexander Neergaard Zahid, Morten Mørup</li>
<li>for: 提高EEG数据的抽象和普适性，以提高脑功能的研究和分析。</li>
<li>methods: 提出了一种基于对比学习的划分卷积自适应器（CSLP-AE）框架，通过对比学习来引导卷积的 latent splits 表示主体（样式）和任务（内容）的特征，以提高 EEG 的抽象和普适性。</li>
<li>results: 比较 CSLP-AE 与传统的超级vised、无监督（AE）和自监督（对比学习）训练方法，发现 CSLP-AE 提供了更好的普适性和适应性，并且可以实现零例转换 между未看过的主体。<details>
<summary>Abstract</summary>
Electroencephalography (EEG) is a prominent non-invasive neuroimaging technique providing insights into brain function. Unfortunately, EEG data exhibit a high degree of noise and variability across subjects hampering generalizable signal extraction. Therefore, a key aim in EEG analysis is to extract the underlying neural activation (content) as well as to account for the individual subject variability (style). We hypothesize that the ability to convert EEG signals between tasks and subjects requires the extraction of latent representations accounting for content and style. Inspired by recent advancements in voice conversion technologies, we propose a novel contrastive split-latent permutation autoencoder (CSLP-AE) framework that directly optimizes for EEG conversion. Importantly, the latent representations are guided using contrastive learning to promote the latent splits to explicitly represent subject (style) and task (content). We contrast CSLP-AE to conventional supervised, unsupervised (AE), and self-supervised (contrastive learning) training and find that the proposed approach provides favorable generalizable characterizations of subject and task. Importantly, the procedure also enables zero-shot conversion between unseen subjects. While the present work only considers conversion of EEG, the proposed CSLP-AE provides a general framework for signal conversion and extraction of content (task activation) and style (subject variability) components of general interest for the modeling and analysis of biological signals.
</details>
<details>
<summary>摘要</summary>
电 electroencephalography (EEG) 是一种非侵入性的脑成像技术，提供了脑功能的重要信息。然而，EEG 数据具有高度的噪声和主题变化，使得普遍化的信号提取受到阻碍。因此，EEG 分析中的一个关键目标是提取内在的神经活动（内容）以及考虑主题变化（样式）。我们假设可以将 EEG 信号转换到不同的任务和主题之间，需要提取潜在表示主题和任务的独特表示。这个目标可以通过对 EEG 信号进行对比学习来实现。我们提出了一种新的对比拆分潜在嵌入 autoencoder（CSLP-AE）框架，该框架直接优化了 EEG 信号的转换。关键是，潜在表示被对比学习导引，以便主题和任务分别具有独特的表示。与传统的超级vised、无级vised（AE）和自我超级vised（对比学习）训练相比，我们发现提出的方法可以提供有利的总体特征表示。特别是，该方法还允许零shot转换到未看到的主题。虽然本研究只考虑了 EEG 的转换，但我们提出的 CSLP-AE 提供了一种通用的信号转换和内容（任务活动）以及样式（主题变化）组成部分的模型化和分析的框架。
</details></li>
</ul>
<hr>
<h2 id="A-Data-Free-Approach-to-Mitigate-Catastrophic-Forgetting-in-Federated-Class-Incremental-Learning-for-Vision-Tasks"><a href="#A-Data-Free-Approach-to-Mitigate-Catastrophic-Forgetting-in-Federated-Class-Incremental-Learning-for-Vision-Tasks" class="headerlink" title="A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks"></a>A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07784">http://arxiv.org/abs/2311.07784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotabi, Salman Avestimehr</li>
<li>for: 防止深度学习模型忘记之前学习的信息，特别在联合学习（Federated Learning，FL）中，数据分布式，每个用户的数据可能会独立变化。</li>
<li>methods: 提出了一种基于生成模型的联合分类增量学习框架，利用生成模型Synthesize samples from past distributions，以减轻忘记现象。保持隐私性，生成模型在服务器端使用数据free方法进行训练，不需要客户端提供数据。</li>
<li>results: 在多个数据集上进行了广泛的实验，证明了该方法可以减轻忘记现象，并且不需要用户保存过去的数据或模型。<details>
<summary>Abstract</summary>
Deep learning models often suffer from forgetting previously learned information when trained on new data. This problem is exacerbated in federated learning (FL), where the data is distributed and can change independently for each user. Many solutions are proposed to resolve this catastrophic forgetting in a centralized setting. However, they do not apply directly to FL because of its unique complexities, such as privacy concerns and resource limitations. To overcome these challenges, this paper presents a framework for \textbf{federated class incremental learning} that utilizes a generative model to synthesize samples from past distributions. This data can be later exploited alongside the training data to mitigate catastrophic forgetting. To preserve privacy, the generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Moreover, our solution does not demand the users to store old data or models, which gives them the freedom to join/leave the training at any time. Additionally, we introduce SuperImageNet, a new regrouping of the ImageNet dataset specifically tailored for federated continual learning. We demonstrate significant improvements compared to existing baselines through extensive experiments on multiple datasets.
</details>
<details>
<summary>摘要</summary>
深度学习模型经常面临新数据训练时忘记之前学习的信息问题。这个问题在 federated learning（FL）中更加严重，因为数据分布在不同用户处并可以独立地变化。许多解决方案在中央化设置下提出来解决这个慢速衰减问题，但这些解决方案不直接适用于 FL 因为其独特的复杂性，如隐私问题和资源限制。为了突破这些挑战，本文提出了一个框架，即 federated class incremental learning（FL-CIL），该框架利用生成模型来synthesize过去分布的样本。这些样本可以在训练数据之 alongside 使用，以 Mitigate 慢速衰减。在保护隐私方面，生成模型在服务器上使用数据free方法进行训练，而无需请求客户端上传数据。此外，我们的解决方案不需要用户保留过去的数据或模型，这给了他们在训练中任意时间加入/离开的自由。此外，我们还提出了一个新的 ImageNet 数据集重新分组，即 SuperImageNet，特意设计用于 federated continual learning。通过了广泛的实验，我们证明了我们的方案与现有基eline存在显著的改进。
</details></li>
</ul>
<hr>
<h2 id="FedOpenHAR-Federated-Multi-Task-Transfer-Learning-for-Sensor-Based-Human-Activity-Recognition"><a href="#FedOpenHAR-Federated-Multi-Task-Transfer-Learning-for-Sensor-Based-Human-Activity-Recognition" class="headerlink" title="FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based Human Activity Recognition"></a>FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07765">http://arxiv.org/abs/2311.07765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Egemen İşgüder, Özlem Durmaz İncel</li>
<li>for: 这篇论文主要针对的是如何使用分布式机器学习技术来实现基于嗅感器的人体活动识别和设备位置识别两个任务。</li>
<li>methods: 本文使用了联邦传输学习技术，通过将多个小型数据集合并训练一个共享模型，以实现两个任务的同时进行多任务学习。</li>
<li>results: 试验结果表明，通过使用分布式机器学习技术和转移学习，可以在不同的数据集和环境下实现类似于中央化训练的高精度。<details>
<summary>Abstract</summary>
Motion sensors integrated into wearable and mobile devices provide valuable information about the device users. Machine learning and, recently, deep learning techniques have been used to characterize sensor data. Mostly, a single task, such as recognition of activities, is targeted, and the data is processed centrally at a server or in a cloud environment. However, the same sensor data can be utilized for multiple tasks and distributed machine-learning techniques can be used without the requirement of the transmission of data to a centre. This paper explores Federated Transfer Learning in a Multi-Task manner for both sensor-based human activity recognition and device position identification tasks. The OpenHAR framework is used to train the models, which contains ten smaller datasets. The aim is to obtain model(s) applicable for both tasks in different datasets, which may include only some label types. Multiple experiments are carried in the Flower federated learning environment using the DeepConvLSTM architecture. Results are presented for federated and centralized versions under different parameters and restrictions. By utilizing transfer learning and training a task-specific and personalized federated model, we obtained a similar accuracy with training each client individually and higher accuracy than a fully centralized approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese运动传感器 интегрирован到了携带式和移动设备中提供了设备用户的有价值信息。机器学习和最近的深度学习技术已经用于描述传感器数据。通常，单个任务，如活动识别，是目标，并将数据处理中央服务器或云环境中。然而，同一个传感器数据可以用于多个任务，并可以使用分布式机器学习技术，无需数据传输到中心。这篇论文探讨了联邦传输学习在多任务方式下的应用，用于满足感知设备的人体活动识别和设备位置识别两个任务。使用OpenHAR框架进行训练，该框架包含10个较小的数据集。目标是在不同的数据集中获得适用于两个任务的模型，可能只包含一些标签类型。在花开联邦学习环境中进行多个实验，使用深度卷积LSTM架构。结果显示，通过使用传输学习和训练任务特定和个性化联邦模型，我们可以获得与每个客户端分别训练的相似准确率，并高于完全中央化方法。Note: Simplified Chinese is used here, as it is more widely used in mainland China. If you prefer Traditional Chinese, I can also provide the translation.
</details></li>
</ul>
<hr>
<h2 id="Quality-Aware-Prototype-Memory-for-Face-Representation-Learning"><a href="#Quality-Aware-Prototype-Memory-for-Face-Representation-Learning" class="headerlink" title="Quality-Aware Prototype Memory for Face Representation Learning"></a>Quality-Aware Prototype Memory for Face Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07734">http://arxiv.org/abs/2311.07734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evgeny Smirnov, Vasiliy Galyuk, Evgeny Lukyanets</li>
<li>for: 提高 Prototype Memory 模型的扩展性和精度，使其能够更好地处理低质量或具有异常特征的人脸图像。</li>
<li>methods: 提出了一种简单有效的质量感知技术，使得 Prototype Memory 在生成核心时使用不同的权重来处理不同质量的人脸图像，从而提高模型的精度和稳定性。</li>
<li>results: 通过对多个人脸识别benchmark进行了广泛的实验，证明了提出的方法可以提高 Prototype Memory 模型的性能，并且在不同质量的人脸图像下表现更加稳定。<details>
<summary>Abstract</summary>
Prototype Memory is a powerful model for face representation learning. It enables the training of face recognition models using datasets of any size, with on-the-fly generation of prototypes (classifier weights) and efficient ways of their utilization. Prototype Memory demonstrated strong results in many face recognition benchmarks. However, the algorithm of prototype generation, used in it, is prone to the problems of imperfectly calculated prototypes in case of low-quality or poorly recognizable faces in the images, selected for the prototype creation. All images of the same person, presented in the mini-batch, used with equal weights, and the resulting averaged prototype could be contaminated with imperfect embeddings of such face images. It can lead to misdirected training signals and impair the performance of the trained face recognition models. In this paper, we propose a simple and effective way to improve Prototype Memory with quality-aware prototype generation. Quality-Aware Prototype Memory uses different weights for images of different quality in the process of prototype generation. With this improvement, prototypes get more valuable information from high-quality images and less hurt by low-quality ones. We propose and compare several methods of quality estimation and usage, perform extensive experiments on the different face recognition benchmarks and demonstrate the advantages of the proposed model compared to the basic version of Prototype Memory.
</details>
<details>
<summary>摘要</summary>
protoype memory 是一种强大的人脸表示学习模型。它允许通过任意大小的数据集进行人脸识别模型的训练，并且可以在实时生成核心示例（分类器权重）并有效地使用它们。 prototype memory 在许多人脸识别benchmark中显示出了强大的成果。然而， prototype memory 中使用的核心生成算法在低质量或difficult to recognize的面部图像时存在一些问题。当使用相同的人脸图像进行批处理时，所有图像均被视为等重，并且所得到的平均核心可能受到低质量图像的杂乱影响。这可能导致训练信号受扰和人脸识别模型的性能下降。在这篇论文中，我们提出了一种简单有效的方法，用于提高 protoype memory 的质量感知。我们使用不同的权重来处理不同质量的面部图像，以便核心获得更多的高质量图像中的有价值信息，并且减少低质量图像的影响。我们提出了多种质量估计和使用方法，进行了广泛的实验，并在不同的人脸识别benchmark上显示了提高模型的优势。
</details></li>
</ul>
<hr>
<h2 id="To-See-is-to-Believe-Prompting-GPT-4V-for-Better-Visual-Instruction-Tuning"><a href="#To-See-is-to-Believe-Prompting-GPT-4V-for-Better-Visual-Instruction-Tuning" class="headerlink" title="To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning"></a>To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07574">http://arxiv.org/abs/2311.07574</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/x2fd/lvis-instruct4v">https://github.com/x2fd/lvis-instruct4v</a></li>
<li>paper_authors: Junke Wang, Lingchen Meng, Zejia Weng, Bo He, Zuxuan Wu, Yu-Gang Jiang</li>
<li>for: 提高大型多媒体模型（LLaVA-1.5）的性能，使其在各种困难的混合媒体任务中表现出色。</li>
<li>methods: 引入了高级的视觉指令集（LVIS-Instruct4V），通过Prompting强大的GPT-4V模型使用图像来生成高精度的视觉指令数据。</li>
<li>results: 经验验证和案例研究表明，高质量的视觉指令数据可以提高LLaVA-1.5模型在多种混合媒体任务中的性能，比如LLaVA$^w$（76.7 vs. 70.7）和MM-Vet（40.2 vs. 35.4）等。<details>
<summary>Abstract</summary>
Existing visual instruction tuning methods typically prompt large language models with textual descriptions to generate instruction-following data. Despite the promising performance achieved, these descriptions are derived from image annotations, which are oftentimes coarse-grained. Furthermore, the instructions might even contradict the visual content without observing the entire visual context. To address this challenge, we introduce a fine-grained visual instruction dataset, LVIS-Instruct4V, which contains 220K visually aligned and context-aware instructions produced by prompting the powerful GPT-4V with images from LVIS. Through experimental validation and case studies, we demonstrate that high-quality visual instructional data could improve the performance of LLaVA-1.5, a state-of-the-art large multimodal model, across a wide spectrum of benchmarks by clear margins. Notably, by simply replacing the LLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA on most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet (40.2 vs. 35.4). We release our data and model at https://github.com/X2FD/LVIS-INSTRUCT4V.
</details>
<details>
<summary>摘要</summary>
现有的视觉指令优化方法通常是通过文本描述向大语言模型提供图像描述来生成指令跟踪数据。尽管这些描述可以达到出色的性能，但是这些描述通常是基于图像注释，它们可能是粗糙的。此外，指令可能与视觉内容不匹配，而不考虑整个视觉上下文。为解决这个挑战，我们引入了高级的视觉指令数据集，LVIS-Instruct4V，它包含220K个视觉对应的高级指令，这些指令是通过提交强大的GPT-4V图像从LVIS来生成的。通过实验验证和案例研究，我们证明了高质量的视觉指令数据可以提高LLaVA-1.5，一个状态之最大的多Modal模型，在多种 bencmarks 上的性能，并且具有明显的优势。例如，通过将LLaVA-Instruct替换为我们的LVIS-Instruct4V，我们可以在许多最复杂的LMM bencmarks上获得更好的结果，例如LLaVA$^w$ (76.7 vs. 70.7) 和 MM-Vet (40.2 vs. 35.4)。我们在 GitHub 上发布了我们的数据和模型，可以通过以下链接获取：https://github.com/X2FD/LVIS-INSTRUCT4V。
</details></li>
</ul>
<hr>
<h2 id="Fast-Normalized-Cross-Correlation-for-Template-Matching-with-Rotations"><a href="#Fast-Normalized-Cross-Correlation-for-Template-Matching-with-Rotations" class="headerlink" title="Fast Normalized Cross-Correlation for Template Matching with Rotations"></a>Fast Normalized Cross-Correlation for Template Matching with Rotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07561">http://arxiv.org/abs/2311.07561</a></li>
<li>repo_url: None</li>
<li>paper_authors: José María Almira, Harold Phelippeau, Antonio Martinez-Sanchez</li>
<li>for: 用于快速化Template Matching计算（特别是3D图像）</li>
<li>methods: 使用一种新的数学理论，可以同时处理平移和旋转，减少计算复杂性</li>
<li>results: 可以快速地回归模板实例的位置和旋转角度信息<details>
<summary>Abstract</summary>
Normalized cross-correlation is the reference approach to carry out template matching on images. When it is computed in Fourier space, it can handle efficiently template translations but it cannot do so with template rotations. Including rotations requires sampling the whole space of rotations, repeating the computation of the correlation each time.   This article develops an alternative mathematical theory to handle efficiently, at the same time, rotations and translations. Our proposal has a reduced computational complexity because it does not require to repeatedly sample the space of rotations. To do so, we integrate the information relative to all rotated versions of the template into a unique symmetric tensor template -which is computed only once per template-. Afterward, we demonstrate that the correlation between the image to be processed with the independent tensor components of the tensorial template contains enough information to recover template instance positions and rotations.   Our proposed method has the potential to speed up conventional template matching computations by a factor of several magnitude orders for the case of 3D images.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VGSG-Vision-Guided-Semantic-Group-Network-for-Text-based-Person-Search"><a href="#VGSG-Vision-Guided-Semantic-Group-Network-for-Text-based-Person-Search" class="headerlink" title="VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search"></a>VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07514">http://arxiv.org/abs/2311.07514</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuting He, Hao Luo, Wei Jiang, Xudong Jiang, Henghui Ding</li>
<li>for: 本文提出了一种基于视觉引导的Semantic-Group Network（VGSG），用于文本基于人脸搜索，以EXTRACTING高精度的视觉和文本特征。</li>
<li>methods: 本文提出了两个模块：Semantic-Group Textual Learning（SGTL）模块和Vision-guided Knowledge Transfer（VGKT）模块。SGTL模块使用语言表达的semantic cues来分组文本特征，而VGKT模块使用视觉引导的注意力来EXTRACTING视觉相关的文本特征。</li>
<li>results: 实验结果表明，VGSG比state-of-the-art方法高效、高精度地实现文本基于人脸搜索。<details>
<summary>Abstract</summary>
Text-based Person Search (TBPS) aims to retrieve images of target pedestrian indicated by textual descriptions. It is essential for TBPS to extract fine-grained local features and align them crossing modality. Existing methods utilize external tools or heavy cross-modal interaction to achieve explicit alignment of cross-modal fine-grained features, which is inefficient and time-consuming. In this work, we propose a Vision-Guided Semantic-Group Network (VGSG) for text-based person search to extract well-aligned fine-grained visual and textual features. In the proposed VGSG, we develop a Semantic-Group Textual Learning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to extract textual local features under the guidance of visual local clues. In SGTL, in order to obtain the local textual representation, we group textual features from the channel dimension based on the semantic cues of language expression, which encourages similar semantic patterns to be grouped implicitly without external tools. In VGKT, a vision-guided attention is employed to extract visual-related textual features, which are inherently aligned with visual cues and termed vision-guided textual features. Furthermore, we design a relational knowledge transfer, including a vision-language similarity transfer and a class probability transfer, to adaptively propagate information of the vision-guided textual features to semantic-group textual features. With the help of relational knowledge transfer, VGKT is capable of aligning semantic-group textual features with corresponding visual features without external tools and complex pairwise interaction. Experimental results on two challenging benchmarks demonstrate its superiority over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
文本基于人体搜索（TBPS）目的是 retrieve图像指定的人体文本描述。为TBPS提取细腻的本地特征并进行modal的同步是关键。现有方法通过外部工具或重量级modal交互来实现明确的modal同步细腻特征，这是不效率和时间consuming。在这种工作中，我们提议一种视觉引导 semantic-group 网络（VGSG） для文本基于人体搜索，以提取Well-aligned的视觉和文本特征。在我们的VGSG中，我们开发了一种Semantic-Group Textual Learning（SGTL）模块和一种视觉引导知识传输（VGKT）模块，以提取文本本地特征。在SGTL中，我们基于语言表达的semanticcue分组文本特征从通道维度，以便获得本地文本表示。在VGKT中，我们employn了视觉引导注意力来提取视觉相关的文本特征，这些特征是自然地与视觉cue相关，并被称为视觉引导的文本特征。此外，我们设计了一种关系知识传输，包括一种视觉语言相似传输和一种类 probablity传输，以适应ively propagate vision-guided文本特征的信息到semantic-group文本特征。通过关系知识传输，VGKT能够将semantic-group文本特征与相应的视觉特征同步，不需要外部工具和复杂的对抗式交互。实验结果表明，我们的方法在两个复杂的benchmark上表现出色，与当前方法相比有superiority。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Performance-Prediction-for-Deep-Convolutional-Long-Short-Term-Memory-Networks"><a href="#Temporal-Performance-Prediction-for-Deep-Convolutional-Long-Short-Term-Memory-Networks" class="headerlink" title="Temporal Performance Prediction for Deep Convolutional Long Short-Term Memory Networks"></a>Temporal Performance Prediction for Deep Convolutional Long Short-Term Memory Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07477">http://arxiv.org/abs/2311.07477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laura Fieback, Bidya Dash, Jakob Spiegelberg, Hanno Gottschalk</li>
<li>for: 这篇论文主要目标是量化深度 semantic segmentation 网络的预测uncertainty，以便在安全关键任务中使用。</li>
<li>methods: 这篇论文使用了 convolutional long short-term memory 网络，可以不仅提供semantic segmentation，还可以预测下一步的segmentation。这些模型使用细胞状态来广播previous data中的信息，通过接受时间序列输入来预测未来一步或更多步。</li>
<li>results: 这篇论文提出了一种temporal postprocessing方法，可以估算 convolutional long short-term memory 网络的预测性能，包括预测 intersect over union 值或者 классификация为 zero 或大于 zero。为此，我们创建了基于 temporal cell state 的输入指标，并研究了不同的模型来估算预测质量基于这些指标。我们还研究了考虑 cell states 的数量对提posed metrics 的影响。<details>
<summary>Abstract</summary>
Quantifying predictive uncertainty of deep semantic segmentation networks is essential in safety-critical tasks. In applications like autonomous driving, where video data is available, convolutional long short-term memory networks are capable of not only providing semantic segmentations but also predicting the segmentations of the next timesteps. These models use cell states to broadcast information from previous data by taking a time series of inputs to predict one or even further steps into the future. We present a temporal postprocessing method which estimates the prediction performance of convolutional long short-term memory networks by either predicting the intersection over union of predicted and ground truth segments or classifying between intersection over union being equal to zero or greater than zero. To this end, we create temporal cell state-based input metrics per segment and investigate different models for the estimation of the predictive quality based on these metrics. We further study the influence of the number of considered cell states for the proposed metrics.
</details>
<details>
<summary>摘要</summary>
深度semantic segmentation网络的预测不确定性评估是安全关键任务中的一项重要任务。在自动驾驶应用中，where video数据可用，卷积长短期记忆网络可以不仅提供semantic segmentation，还可以预测下一步的segmentation。这些模型使用细胞状态来广播从前一个数据中的信息，通过接受一系列输入来预测一步或更多步的未来。我们提出了时间Postprocessing方法，该方法可以估计卷积长短期记忆网络的预测性能，通过预测 predicted和实际数据中的交集union的交集或者判断intersection over union是否大于或等于零来实现。为此，我们创建了时间细胞状态基于的输入度量，并研究不同的模型来估计预测质量基于这些度量。我们进一步研究了考虑的细胞状态数量对提posed度量的影响。
</details></li>
</ul>
<hr>
<h2 id="Masked-Face-Dataset-Generation-and-Masked-Face-Recognition"><a href="#Masked-Face-Dataset-Generation-and-Masked-Face-Recognition" class="headerlink" title="Masked Face Dataset Generation and Masked Face Recognition"></a>Masked Face Dataset Generation and Masked Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07475">http://arxiv.org/abs/2311.07475</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luisrui/seeing-ai-system">https://github.com/luisrui/seeing-ai-system</a></li>
<li>paper_authors: Rui Cai, Xuying Ning, Peter N. Belhumeur</li>
<li>for: 本研究旨在解决post-epidemic era面罩妨碍普通面 recognition问题。</li>
<li>methods: 研究人员创建了更加具有挑战性的面罩人脸数据集，并使用了自适应的数据增强策略来提高模型在实际场景中的性能。</li>
<li>results: 研究人员通过自适应模型和数据增强策略，在50个人脸数据集上实现了最高的95%的测试精度。<details>
<summary>Abstract</summary>
In the post-pandemic era, wearing face masks has posed great challenge to the ordinary face recognition. In the previous study, researchers has applied pretrained VGG16, and ResNet50 to extract features on the elaborate curated existing masked face recognition (MFR) datasets, RMFRD and SMFRD. To make the model more adaptable to the real world situation where the sample size is smaller and the camera environment has greater changes, we created a more challenging masked face dataset ourselves, by selecting 50 identities with 1702 images from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks through key point detection. The another part of our study is to solve the masked face recognition problem, and we chose models by referring to the former state of the art results, instead of directly using pretrained models, we fine tuned the model on our new dataset and use the last linear layer to do the classification directly. Furthermore, we proposed using data augmentation strategy to further increase the test accuracy, and fine tuned a new networks beyond the former study, one of the most SOTA networks, Inception ResNet v1. The best test accuracy on 50 identity MFR has achieved 95%.
</details>
<details>
<summary>摘要</summary>
在post-epidemic era，面具穿戴对于普通面Recognition posed great challenge。在前一项研究中，研究人员使用预训练的VGG16和ResNet50提取特征从 elaborate curated existing masked face recognition（MFR）数据集RMFRD和SMFRD。为了让模型更适应实际世界中的小样本大小和摄像头环境更大的变化，我们创建了更加挑战性的面具face数据集，选择了50个人的1702张图像从Labelled Faces in the Wild（LFW）数据集，并通过关键点检测来生成模拟面具。另一方面，我们解决了面具认知问题，选择了根据前一项state of the art结果进行选择，而不是直接使用预训练模型，我们在我们新数据集上进行了微调，并使用最后的直方向来进行直接分类。此外，我们提议使用数据增强策略来进一步提高测试准确率，并微调了新的网络，其中一个最新的SOTA网络，Inception ResNet v1。我们在50个人MFR测试中获得了95%的最高测试准确率。
</details></li>
</ul>
<hr>
<h2 id="Language-Grounded-QFormer-for-Efficient-Vision-Language-Understanding"><a href="#Language-Grounded-QFormer-for-Efficient-Vision-Language-Understanding" class="headerlink" title="Language Grounded QFormer for Efficient Vision Language Understanding"></a>Language Grounded QFormer for Efficient Vision Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07449">http://arxiv.org/abs/2311.07449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moulik Choraria, Nitesh Sekhar, Yue Wu, Xu Zhang, Prateek Singhal, Lav R. Varshney</li>
<li>for: 这篇论文的目的是提出更有效的视频语言匹配方法，以提高视频语言模型的预训练效率。</li>
<li>methods: 该论文使用了Query Transformer（QFormer）方法，启发自BLIP-2模型，通过bridging frozen modalities来实现视频语言对应。</li>
<li>results:  compared to现有基elines，该方法提高了视频语言预训练的效率。<details>
<summary>Abstract</summary>
Large-scale pretraining and instruction tuning have been successful for training general-purpose language models with broad competencies. However, extending to general-purpose vision-language models is challenging due to the distributional diversity in visual inputs. A recent line of work explores vision-language instruction tuning, taking inspiration from the Query Transformer (QFormer) approach proposed in BLIP-2 models for bridging frozen modalities. However, these approaches rely heavily on large-scale multi-modal pretraining for representation learning before eventual finetuning, incurring a huge computational overhead, poor scaling, and limited accessibility. To that end, we propose a more efficient method for QFormer-based vision-language alignment and demonstrate the effectiveness of our strategy compared to existing baselines in improving the efficiency of vision-language pretraining.
</details>
<details>
<summary>摘要</summary>
大规模预训练和指导调整已经成功地训练了通用语言模型，但扩展到通用视语模型却存在许多挑战，主要是因为视觉输入的分布差异。现有的一些研究借鉴Query Transformer（QFormer）方法，在BLIP-2模型中实现停滞模式之间的桥接。然而，这些方法均依赖于大规模多modal预训练，以便 eventually fine-tuning，导致计算开销巨大、缓慢、可达性有限。为了解决这个问题，我们提出了一种更高效的QFormer基于视语Alignment方法，并证明了我们的策略与现有基准相比，可以提高视语预训练的效率。
</details></li>
</ul>
<hr>
<h2 id="Story-to-Motion-Synthesizing-Infinite-and-Controllable-Character-Animation-from-Long-Text"><a href="#Story-to-Motion-Synthesizing-Infinite-and-Controllable-Character-Animation-from-Long-Text" class="headerlink" title="Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text"></a>Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07446">http://arxiv.org/abs/2311.07446</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongfei Qing, Zhongang Cai, Zhitao Yang, Lei Yang</li>
<li>for: 这个研究的目的是生成基于故事的自然人体动作，以便改变动画、游戏和电影等领域的ланд膝景。</li>
<li>methods: 该研究使用了当代大语言模型作为文本驱动动作调度器，EXTRACTING a series of (text, position, duration) pairs from long text，并开发了文本驱动动作检索方案，该方案包括动作匹配和动作Semantics和轨迹约束。</li>
<li>results: 该系统可以生成可控的无限长动作和轨迹，与输入文本保持一致。该系统在三个不同的子任务中（轨迹跟踪、时间动作组合和动作混合）都超过了之前的状态 искусственный动作生成方法。<details>
<summary>Abstract</summary>
Generating natural human motion from a story has the potential to transform the landscape of animation, gaming, and film industries. A new and challenging task, Story-to-Motion, arises when characters are required to move to various locations and perform specific motions based on a long text description. This task demands a fusion of low-level control (trajectories) and high-level control (motion semantics). Previous works in character control and text-to-motion have addressed related aspects, yet a comprehensive solution remains elusive: character control methods do not handle text description, whereas text-to-motion methods lack position constraints and often produce unstable motions. In light of these limitations, we propose a novel system that generates controllable, infinitely long motions and trajectories aligned with the input text. (1) We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text. (2) We develop a text-driven motion retrieval scheme that incorporates motion matching with motion semantic and trajectory constraints. (3) We design a progressive mask transformer that addresses common artifacts in the transition motion such as unnatural pose and foot sliding. Beyond its pioneering role as the first comprehensive solution for Story-to-Motion, our system undergoes evaluation across three distinct sub-tasks: trajectory following, temporal action composition, and motion blending, where it outperforms previous state-of-the-art motion synthesis methods across the board. Homepage: https://story2motion.github.io/.
</details>
<details>
<summary>摘要</summary>
将文本转换为人类动作的潜在潜力可能会改变动画、游戏和电影产业的景观。一个新而具有挑战性的任务是故事到动作（Story-to-Motion），当角色需要根据长文本描述移动到不同的位置并执行特定的动作时，这个任务需要文本驱动的动作控制和高级控制之间的融合。现有的角色控制和文本到动作方法已经解决了相关的问题，但是一个全面的解决方案仍然未知：角色控制方法不能处理文本描述，而文本到动作方法缺乏位置约束并经常产生不稳定的动作。为了解决这些限制，我们提出了一种新的系统，该系统可以根据输入文本生成可控的无限长动作和轨迹，并与文本保持一致。我们利用当代大型自然语言模型作为文本驱动动作计划器，从长文本中提取一系列（文本、位置、持续时间）对。我们开发了一种文本驱动动作检索方法，该方法将包括动作匹配、动作Semantics和轨迹约束。我们还设计了一种进步的掩蔽变换器，以解决通常出现在过渡动作中的不自然姿势和脚滑动。我们的系统不仅是Story-to-Motion的首个全面解决方案，还在三个不同的子任务上进行评估：轨迹跟踪、时间动作组合和动作混合，在所有的情况下都超越了先前的动画生成方法。更多信息请访问我们的主页：<https://story2motion.github.io/>。
</details></li>
</ul>
<hr>
<h2 id="Supersampling-of-Data-from-Structured-light-Scanner-with-Deep-Learning"><a href="#Supersampling-of-Data-from-Structured-light-Scanner-with-Deep-Learning" class="headerlink" title="Supersampling of Data from Structured-light Scanner with Deep Learning"></a>Supersampling of Data from Structured-light Scanner with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07432">http://arxiv.org/abs/2311.07432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Melicherčík, Lukáš Gajdošech, Viktor Kocur, Martin Madaras</li>
<li>for: 提高3D摄像机获得的深度图的分辨率</li>
<li>methods: 修改FDSR和DKN深度学习模型以适应高分辨率数据，并实现数据预处理技术以稳定训练。</li>
<li>results: 使用自定义 dataset 对 1200 个 3D 扫描进行训练，并通过质量和量化指标评估高分辨率 depth map 的结果。<details>
<summary>Abstract</summary>
This paper focuses on increasing the resolution of depth maps obtained from 3D cameras using structured light technology. Two deep learning models FDSR and DKN are modified to work with high-resolution data, and data pre-processing techniques are implemented for stable training. The models are trained on our custom dataset of 1200 3D scans. The resulting high-resolution depth maps are evaluated using qualitative and quantitative metrics. The approach for depth map upsampling offers benefits such as reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at the lower resolution and upsampling the resulting depth map or increasing the resolution of a point cloud captured in lower resolution by a cheaper device. The experiments demonstrate that the FDSR model excels in terms of faster processing time, making it a suitable choice for applications where speed is crucial. On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy.
</details>
<details>
<summary>摘要</summary>
The proposed approach for depth map upsampling offers several benefits, including reducing the processing time of a pipeline by first downsampling a high-resolution depth map, performing various processing steps at a lower resolution, and then upsampling the resulting depth map. Additionally, the approach can increase the resolution of a point cloud captured in lower resolution by a cheaper device.Experiments demonstrate that the FDSR model is faster and more suitable for applications where speed is crucial. On the other hand, the DKN model provides results with higher precision, making it more suitable for applications that prioritize accuracy.
</details></li>
</ul>
<hr>
<h2 id="Optimising-Human-AI-Collaboration-by-Learning-Convincing-Explanations"><a href="#Optimising-Human-AI-Collaboration-by-Learning-Convincing-Explanations" class="headerlink" title="Optimising Human-AI Collaboration by Learning Convincing Explanations"></a>Optimising Human-AI Collaboration by Learning Convincing Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07426">http://arxiv.org/abs/2311.07426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex J. Chan, Alihan Huyuk, Mihaela van der Schaar</li>
<li>for: 本研究旨在开发一种可以协助人类做出决策的协同系统，以确保系统的安全性和性能。</li>
<li>methods: 本研究使用的方法包括开发一种名为Ardent的算法，可以快速学习人类对解释的喜好，并根据这些喜好为人类提供最有用的解释。</li>
<li>results: 研究结果表明，使用Ardent算法可以有效地改善决策过程中的透明度和责任感，并且在一个复杂的图像分类任务中表现出了适用性。<details>
<summary>Abstract</summary>
Machine learning models are being increasingly deployed to take, or assist in taking, complicated and high-impact decisions, from quasi-autonomous vehicles to clinical decision support systems. This poses challenges, particularly when models have hard-to-detect failure modes and are able to take actions without oversight. In order to handle this challenge, we propose a method for a collaborative system that remains safe by having a human ultimately making decisions, while giving the model the best opportunity to convince and debate them with interpretable explanations. However, the most helpful explanation varies among individuals and may be inconsistent across stated preferences. To this end we develop an algorithm, Ardent, to efficiently learn a ranking through interaction and best assist humans complete a task. By utilising a collaborative approach, we can ensure safety and improve performance while addressing transparency and accountability concerns. Ardent enables efficient and effective decision-making by adapting to individual preferences for explanations, which we validate through extensive simulations alongside a user study involving a challenging image classification task, demonstrating consistent improvement over competing systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-semi-supervised-segmentation-with-timestep-ensembling-diffusion-models"><a href="#Robust-semi-supervised-segmentation-with-timestep-ensembling-diffusion-models" class="headerlink" title="Robust semi-supervised segmentation with timestep ensembling diffusion models"></a>Robust semi-supervised segmentation with timestep ensembling diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07421">http://arxiv.org/abs/2311.07421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Margherita Rosnati, Melanie Roschewitz, Ben Glocker</li>
<li>For: This paper is written for the task of semi-supervised medical image segmentation, with a focus on domain generalization.* Methods: The paper uses denoising diffusion probabilistic models (DDPMs) to model the distribution of natural images and perform image segmentation. The authors propose an improved ensemble scheme that leverages information-dense small steps and the regularizing effect of larger steps to generate predictions.* Results: The paper shows that the proposed method significantly outperforms other methods in domain-shifted settings while retaining competitive performance in-domain. The results highlight the potential of DDPMs for semi-supervised medical image segmentation and provide insights into optimising their performance under domain shift.Here’s the Chinese translation of the three pieces of information:* For: 这篇论文是为 semi-supervised 医疗图像分割任务而写的，尤其是在领域映射上。* Methods: 该论文使用 denoising diffusion probabilistic models (DDPMs) 来模型自然图像的分布，并用这些模型进行图像分割。作者们提出了一种改进的ensemble scheme，该 scheme利用小步骤中的信息压缩和大步骤的正则化效果来生成预测。* Results: 论文显示，提出的方法在领域转换下表现出色，同时保持了在领域内的竞争性表现。结果表明 DDPMs 在 semi-supervised 医疗图像分割中具有潜在的潜力，并提供了优化其性能下领域转换的灵感。<details>
<summary>Abstract</summary>
Medical image segmentation is a challenging task, made more difficult by many datasets' limited size and annotations. Denoising diffusion probabilistic models (DDPM) have recently shown promise in modelling the distribution of natural images and were successfully applied to various medical imaging tasks. This work focuses on semi-supervised image segmentation using diffusion models, particularly addressing domain generalisation. Firstly, we demonstrate that smaller diffusion steps generate latent representations that are more robust for downstream tasks than larger steps. Secondly, we use this insight to propose an improved esembling scheme that leverages information-dense small steps and the regularising effect of larger steps to generate predictions. Our model shows significantly better performance in domain-shifted settings while retaining competitive performance in-domain. Overall, this work highlights the potential of DDPMs for semi-supervised medical image segmentation and provides insights into optimising their performance under domain shift.
</details>
<details>
<summary>摘要</summary>
医学图像分割是一项具有挑战性的任务，由于许多数据集的限制性和标注而更加困难。在最近的研究中，涉泳扩散概率模型（DDPM）已经表现出模拟自然图像的分布的潜力，并在各种医学成像任务中得到了成功应用。本研究将关注 semi-supervised 图像分割使用涉泳模型，特别是域泛化。我们首先证明了小步 diffusion 生成的潜在表示更加鲁棒，用于下游任务的下游任务。其次，我们利用这一点来提出一种改进的拼接方案，利用信息密集的小步和大步的约束效果来生成预测。我们的模型在域Shift 的设置下表现出显著改善，同时保持了在预测中的竞争性。总之，这种研究高亮了 DDPM 在 semi-supervised 医学图像分割中的潜力，并提供了在域Shift 下优化其性能的 Insight。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Backdoors-within-Deep-Neural-Networks-in-Data-limited-Configuration"><a href="#Mitigating-Backdoors-within-Deep-Neural-Networks-in-Data-limited-Configuration" class="headerlink" title="Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration"></a>Mitigating Backdoors within Deep Neural Networks in Data-limited Configuration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07417">http://arxiv.org/abs/2311.07417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soroush Hashemifar, Saeed Parsa, Morteza Zakeri-Nasrabadi</li>
<li>for: 防止深度神经网络（DNN）被黑客攻击，提高DNN的安全性。</li>
<li>methods: 利用潜在恶意 neuron 的特征，实时检测 DNN 中潜在攻击的诡计。</li>
<li>results: 对 CIFAR-10 数据集进行实验，提出了一种基于 activation values、weights 和 neuron 之间关系的潜在攻击检测方法，可以降低攻击成功的机会超过 50%，同时不会对模型性能产生显著影响。此外，该方法比基准方法快三倍。<details>
<summary>Abstract</summary>
As the capacity of deep neural networks (DNNs) increases, their need for huge amounts of data significantly grows. A common practice is to outsource the training process or collect more data over the Internet, which introduces the risks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data while behaving maliciously once a trigger is injected into a sample at the test time. In such cases, the defender faces multiple difficulties. First, the available clean dataset may not be sufficient for fine-tuning and recovering the backdoored DNN. Second, it is impossible to recover the trigger in many real-world applications without information about it. In this paper, we formulate some characteristics of poisoned neurons. This backdoor suspiciousness score can rank network neurons according to their activation values, weights, and their relationship with other neurons in the same layer. Our experiments indicate the proposed method decreases the chance of attacks being successful by more than 50% with a tiny clean dataset, i.e., ten clean samples for the CIFAR-10 dataset, without significantly deteriorating the model's performance. Moreover, the proposed method runs three times as fast as baselines.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）的容量增长，需要的数据量也在增长。一种常见的做法是外部进行训练过程或者在互联网上收集更多数据，这会引入恶意修改DNN的风险。一个恶意修改后的DNN会在测试时采样中注入触发器后表现出错误行为，对于防御者而言，存在多种困难。首先，可用的干净数据集可能不够用于精度调整和恢复恶意修改后的DNN。其次，在实际应用中，无法回收触发器的信息，无法准确地恢复恶意修改后的DNN。在这篇论文中，我们描述了恶意修改后的神经元特征。我们提出的方法可以根据神经元的活动值、权重和相同层中其他神经元的关系，对神经元进行恶意修改检测。我们的实验结果表明，我们的方法可以在使用十个干净样本（CIFAR-10数据集）的情况下，降低攻击成功的机会超过50%，而无需对模型性能产生显著的影响。此外，我们的方法比基线方法快三倍。
</details></li>
</ul>
<hr>
<h2 id="FIRST-A-Million-Entry-Dataset-for-Text-Driven-Fashion-Synthesis-and-Design"><a href="#FIRST-A-Million-Entry-Dataset-for-Text-Driven-Fashion-Synthesis-and-Design" class="headerlink" title="FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and Design"></a>FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07414">http://arxiv.org/abs/2311.07414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Huang, Yihao Li, Dong Pei, Jiapeng Zhou, Xuliang Ning, Jianlin Han, Xiaoguang Han, Xuejun Chen</li>
<li>for: 提高人工智能生成内容(AIGC)中的时尚设计和生成能力，推动传统时尚业的革新和发展。</li>
<li>methods: 介绍了一个新的高分辨率时尚图像和详细结构化文本描述（FIRST）集合，包含一百万个时尚图像和多个层次结构的文本描述。</li>
<li>results: 经过实验表明，FIRST 集合是必需的 для进一步提高时尚生成和设计系统的创造力和想象力。<details>
<summary>Abstract</summary>
Text-driven fashion synthesis and design is an extremely valuable part of artificial intelligence generative content(AIGC), which has the potential to propel a tremendous revolution in the traditional fashion industry. To advance the research on text-driven fashion synthesis and design, we introduce a new dataset comprising a million high-resolution fashion images with rich structured textual(FIRST) descriptions. In the FIRST, there is a wide range of attire categories and each image-paired textual description is organized at multiple hierarchical levels. Experiments on prevalent generative models trained over FISRT show the necessity of FIRST. We invite the community to further develop more intelligent fashion synthesis and design systems that make fashion design more creative and imaginative based on our dataset. The dataset will be released soon.
</details>
<details>
<summary>摘要</summary>
文本驱动时尚合成和设计是人工智能生成内容(AIGC)中非常有价值的一部分，有potential可以驱动传统时尚业的巨大革命。为进一步推进文本驱动时尚合成和设计的研究，我们介绍了一个新的数据集，包含100万高分辨率时尚图片和详细结构化文本描述(FIRST)。在FIRST中，有很多服装类别，每个图片对应的文本描述分别组织在多个层次结构中。经过现有的生成模型在FIRST上训练，我们发现了FIRST的必要性。我们邀请社区为我们的数据集进一步开发更智能的时尚合成和设计系统，使时尚设计更有创意和想象力。数据集即将发布。
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatic-Honey-Bee-Flower-Patch-Assays-with-Paint-Marking-Re-Identification"><a href="#Towards-Automatic-Honey-Bee-Flower-Patch-Assays-with-Paint-Marking-Re-Identification" class="headerlink" title="Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking Re-Identification"></a>Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07407">http://arxiv.org/abs/2311.07407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Meyers, Josué Rodríguez Cordero, Carlos Corrada Bravo, Fanfan Noel, José Agosto-Rivera, Tugrul Giray, Rémi Mégret</li>
<li>for: 这 paper 用于 automatize the analysis of behavioral assays involving honey bees in the field, where marking has to be as lightweight as possible.</li>
<li>methods: 这 paper 使用 paint markings 和 contrastive learning with a ResNet backbone 和 triplet loss 来实现 bees 的 re-identification.</li>
<li>results: 这 paper 提供了一个 novel dataset for bees re-identification with paint-markings, 并实现了 almost perfect recognition in closed setting where identities are known in advance.  Additionally, the paper shows the potential to fully automate the visit detection and provides preliminary results of compute time for future real-time deployment in the field on an edge device.<details>
<summary>Abstract</summary>
In this paper, we show that paint markings are a feasible approach to automatize the analysis of behavioral assays involving honey bees in the field where marking has to be as lightweight as possible. We contribute a novel dataset for bees re-identification with paint-markings with 4392 images and 27 identities. Contrastive learning with a ResNet backbone and triplet loss led to identity representation features with almost perfect recognition in closed setting where identities are known in advance. Diverse experiments evaluate the capability to generalize to separate IDs, and show the impact of using different body parts for identification, such as using the unmarked abdomen only. In addition, we show the potential to fully automate the visit detection and provide preliminary results of compute time for future real-time deployment in the field on an edge device.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们展示了使用涂抹标记来自动化野外Behavioral assays中的蜂群行为分析是可行的。我们提供了一个新的涂抹标记数据集，包含4392张图像和27个标识。对比学习使用ResNet底层和 triplet损失，可以从closed设定中获得几乎完美的识别结果。我们还进行了多种实验，以评估这些特征的泛化能力和使用不同的身体部分进行识别的影响。此外，我们还展示了可以全自动化访问检测，并提供了未来在野外实时部署的计算时间预算。
</details></li>
</ul>
<hr>
<h2 id="Processing-and-Segmentation-of-Human-Teeth-from-2D-Images-using-Weakly-Supervised-Learning"><a href="#Processing-and-Segmentation-of-Human-Teeth-from-2D-Images-using-Weakly-Supervised-Learning" class="headerlink" title="Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning"></a>Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07398">http://arxiv.org/abs/2311.07398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomáš Kunzo, Viktor Kocur, Lukáš Gajdošech, Martin Madaras</li>
<li>For: 这个研究旨在提出一种弱地监督的牙齿分类方法，以减少手动标注的需求。* Methods: 我们使用热点检测网络的输出热点和中间特征图库来引导分类过程。* Results: 我们在TriDental数据集上实现了比前方法更高的准确性和适居性。<details>
<summary>Abstract</summary>
Teeth segmentation is an essential task in dental image analysis for accurate diagnosis and treatment planning. While supervised deep learning methods can be utilized for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.
</details>
<details>
<summary>摘要</summary>
teeth 分割是dentistry 图像分析中的一项关键任务，以确定精确的诊断和治疗规划。 although supervised deep learning methods can be used for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.Here's the translation in Traditional Chinese: teeth 分割是dentistry 图像分析中的一项关键任务，以确定精确的诊断和治疗规划。 although supervised deep learning methods can be used for teeth segmentation, they often require extensive manual annotation of segmentation masks, which is time-consuming and costly. In this research, we propose a weakly supervised approach for teeth segmentation that reduces the need for manual annotation. Our method utilizes the output heatmaps and intermediate feature maps from a keypoint detection network to guide the segmentation process. We introduce the TriDental dataset, consisting of 3000 oral cavity images annotated with teeth keypoints, to train a teeth keypoint detection network. We combine feature maps from different layers of the keypoint detection network, enabling accurate teeth segmentation without explicit segmentation annotations. The detected keypoints are also used for further refinement of the segmentation masks. Experimental results on the TriDental dataset demonstrate the superiority of our approach in terms of accuracy and robustness compared to state-of-the-art segmentation methods. Our method offers a cost-effective and efficient solution for teeth segmentation in real-world dental applications, eliminating the need for extensive manual annotation efforts.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Significance-of-Outdoor-Advertising-from-Driver’s-Perspective-Using-Computer-Vision"><a href="#Evaluating-the-Significance-of-Outdoor-Advertising-from-Driver’s-Perspective-Using-Computer-Vision" class="headerlink" title="Evaluating the Significance of Outdoor Advertising from Driver’s Perspective Using Computer Vision"></a>Evaluating the Significance of Outdoor Advertising from Driver’s Perspective Using Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07390">http://arxiv.org/abs/2311.07390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zuzana Černeková, Zuzana Berger Haladová, Ján Špirka, Viktor Kocur</li>
<li>for: 评估路边广告的重要性，预防 drivers 的分心驾驶</li>
<li>methods: 使用 YOLOv8 检测器和不同的对象跟踪方法，并使用随机森林分类器将广告牌分为三类基于驾驶员围注时间、吸引力和大小</li>
<li>results: 获得了 38.5 HOTA 的最佳方法，并在测试集上达到 75.8% 的测试精度<details>
<summary>Abstract</summary>
Outdoor advertising, such as roadside billboards, plays a significant role in marketing campaigns but can also be a distraction for drivers, potentially leading to accidents. In this study, we propose a pipeline for evaluating the significance of roadside billboards in videos captured from a driver's perspective. We have collected and annotated a new BillboardLamac dataset, comprising eight videos captured by drivers driving through a predefined path wearing eye-tracking devices. The dataset includes annotations of billboards, including 154 unique IDs and 155 thousand bounding boxes, as well as eye fixation data. We evaluate various object tracking methods in combination with a YOLOv8 detector to identify billboard advertisements with the best approach achieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forest classifier to classify billboards into three classes based on the length of driver fixations achieving 75.8% test accuracy. An analysis of the trained classifier reveals that the duration of billboard visibility, its saliency, and size are the most influential features when assessing billboard significance.
</details>
<details>
<summary>摘要</summary>
外部广告，如道路旁的大型广告牌，在市场推广活动中扮演着重要的角色，但也可能对 drivers 引起干扰，导致交通事故。在这项研究中，我们提出了一个用于评估路边大型广告的管道。我们收集了和标注了一个新的 BillboardLamac 数据集，包括八个驾驶员驾驶过定制路线，并且穿着眼动追踪设备拍摄的八个视频。该数据集包括了大型广告的标识符、154个唯一标识符和155千个 bounding box，以及眼动数据。我们评估了多种对象跟踪方法，并结合 YOLOv8 检测器来识别大型广告，最佳方法的 HOTA 得分为 38.5。此外，我们训练了随机森林分类器，以类别大型广告为三种基于驾驶员固定时间的长度、吸引力和大小。分析训练的分类器显示，大型广告的可见时间、吸引力和大小是评估大型广告重要性的最重要的特征。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-developmental-and-brain-disorders-via-graph-convolutional-aggregation"><a href="#Classification-of-developmental-and-brain-disorders-via-graph-convolutional-aggregation" class="headerlink" title="Classification of developmental and brain disorders via graph convolutional aggregation"></a>Classification of developmental and brain disorders via graph convolutional aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07370">http://arxiv.org/abs/2311.07370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibrahim Salim, A. Ben Hamza</li>
<li>for: 本研究旨在提高脑疾病预测性能，特别是在脑发育和脑退化疾病预测方面。</li>
<li>methods: 本研究提出了一种协调 нормализа化图 convolutional neural network，通过图像和非图像特征的组合，以及跳过连接和标识映射，以学习图节点表示。</li>
<li>results: 对两个大型数据集（ABIDE和ADNI）进行了比较，研究结果显示，与最近的基线方法相比，该方法在预测自闭症症和阿尔ц海默病等脑疾病方面达到了Relative improvement of 50%和13.56%。<details>
<summary>Abstract</summary>
While graph convolution based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders. In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping. The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders. Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning. We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer's disease, respectively. Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks on ABIDE and ADNI, respectively.
</details>
<details>
<summary>摘要</summary>
而 graph convolution based 方法在图像表示学习中已经成为了标准，但它们在诊断脑病任务中的应用还很有限，特别是在脑发育和脑退化性疾病的分类中。在这篇论文中，我们提出了一种归并normalization图 convolutional neural network，通过图像采样中的归并和跳过连接，以及标识映射来学习图节点表示。我们的模型通过将图节点和边分别归并到图节点和边上，并将各种影像和非影像特征集成到图节点和边上，以提高预测能力和为脑病的内部机制提供整体视图。跳过连接使得输入特征直接流入网络的后 layer，而标识映射保持图的结构信息在特征学习过程中。我们对 Autism Brain Imaging Data Exchange（ABIDE）和 Alzheimer's Disease Neuroimaging Initiative（ADNI）两个大数据集进行了比较，并与最近的基eline方法进行了比较。实验结果表明，我们的方法在 ABIDE 和 ADNI 上的分类精度有50%和13.56%的提高，相比于图 convolutional networks。
</details></li>
</ul>
<hr>
<h2 id="ActiveDC-Distribution-Calibration-for-Active-Finetuning"><a href="#ActiveDC-Distribution-Calibration-for-Active-Finetuning" class="headerlink" title="ActiveDC: Distribution Calibration for Active Finetuning"></a>ActiveDC: Distribution Calibration for Active Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07634">http://arxiv.org/abs/2311.07634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenshuai Xu, Zhenhui Hu, Yu Lu, Jinzhou Meng, Qingjie Liu, Yunhong Wang</li>
<li>for: 这 paper 是关于 active finetuning 的研究，具体来说是如何选择用于精度 tuning 的数据subset，以避免模型过拟合。</li>
<li>methods: 这 paper 提出了一种新的方法 called ActiveDC，它首先选择用于精度 tuning 的数据subset，然后对这些数据进行分布准确化，以使模型在不同的 sampling ratio 下表现更好。</li>
<li>results: 根据 paper 的实验结果，ActiveDC 在三个图像分类任务中均表现出色，特别是当 sampling ratio 较低时，与基eline的性能提升可达 10%。<details>
<summary>Abstract</summary>
The pretraining-finetuning paradigm has gained popularity in various computer vision tasks. In this paradigm, the emergence of active finetuning arises due to the abundance of large-scale data and costly annotation requirements. Active finetuning involves selecting a subset of data from an unlabeled pool for annotation, facilitating subsequent finetuning. However, the use of a limited number of training samples can lead to a biased distribution, potentially resulting in model overfitting. In this paper, we propose a new method called ActiveDC for the active finetuning tasks. Firstly, we select samples for annotation by optimizing the distribution similarity between the subset to be selected and the entire unlabeled pool in continuous space. Secondly, we calibrate the distribution of the selected samples by exploiting implicit category information in the unlabeled pool. The feature visualization provides an intuitive sense of the effectiveness of our approach to distribution calibration. We conducted extensive experiments on three image classification datasets with different sampling ratios. The results indicate that ActiveDC consistently outperforms the baseline performance in all image classification tasks. The improvement is particularly significant when the sampling ratio is low, with performance gains of up to 10%. Our code will be released.
</details>
<details>
<summary>摘要</summary>
“强化-微调”方法在不同的计算机视觉任务中得到了广泛的应用。在这种方法中，由于大规模数据和注解成本的增加，出现了活跃微调的问题。活跃微调是选择未标注 pool 中的一 subset 进行注解，以便后续微调。然而，使用有限的训练样本可能会导致模型过拟合。在这篇论文中，我们提出了一种新的方法called ActiveDC，用于活跃微调任务。首先，我们通过优化未标注 pool 中 subset 的分布相似性来选择需要注解的样本。其次，我们利用未标注 pool 中的隐藏类信息来准确化选择的样本的分布。图像可视化提供了对我们方法的分布准确化效果的直观感。我们在三个图像分类任务中进行了广泛的实验，结果表明，ActiveDC 在所有图像分类任务中具有比基eline性能更高的表现。具体来说，当采样比率低时，ActiveDC 的表现提升可达 10%。我们将代码发布。
</details></li>
</ul>
<hr>
<h2 id="Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud"><a href="#Registered-and-Segmented-Deformable-Object-Reconstruction-from-a-Single-View-Point-Cloud" class="headerlink" title="Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud"></a>Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07357">http://arxiv.org/abs/2311.07357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pit Henrich, Balázs Gyenes, Paul Maria Scheikl, Gerhard Neumann, Franziska Mathis-Ullrich</li>
<li>for: 对于扭变的实际物体进行弹性对象处理，我们经常想要与特定的对象部分进行交互，这些部分在非扭变的模型中已经被定义。我们需要一种系统可以从感知数据中识别和定位这些部分。</li>
<li>methods: 我们提出了一种使用神经占用函数进行弹性对象注册，并在注册过程中学习对象分割。由于结果已经包含了分割信息，我们可以跳过注册步骤。</li>
<li>results: 我们在许多扭变物体的实际和模拟数据上进行测试，并证明了我们的方法可以强健地找到这些部分。我们还提出了一种简单的采样算法来生成更好的占用学习训练数据。<details>
<summary>Abstract</summary>
In deformable object manipulation, we often want to interact with specific segments of an object that are only defined in non-deformed models of the object. We thus require a system that can recognize and locate these segments in sensor data of deformed real world objects. This is normally done using deformable object registration, which is problem specific and complex to tune. Recent methods utilize neural occupancy functions to improve deformable object registration by registering to an object reconstruction. Going one step further, we propose a system that in addition to reconstruction learns segmentation of the reconstructed object. As the resulting output already contains the information about the segments, we can skip the registration process. Tested on a variety of deformable objects in simulation and the real world, we demonstrate that our method learns to robustly find these segments. We also introduce a simple sampling algorithm to generate better training data for occupancy learning.
</details>
<details>
<summary>摘要</summary>
在可变形物体操作中，我们经常希望与特定的物体段只在非变形模型中定义的段进行交互。因此，我们需要一个系统可以从感知数据中识别和定位这些段。通常通过不适应物体注册来实现这一点，但是这是特定问题和复杂的调整。现代方法使用神经占据函数来改进不适应物体注册，并在注册过程中学习对象重建。我们的方法会在此基础上进一步，不仅是重建物体，还会学习物体的分割。由于结果中已经包含了段的信息，因此我们可以跳过注册步骤。我们在模拟和实际场景中测试了这种方法，并证明我们的方法可以坚定地找到这些段。我们还介绍了一种简单的采样算法，用于生成更好的占据学习训练数据。
</details></li>
</ul>
<hr>
<h2 id="Deformable-Groupwise-Registration-Using-a-Locally-Low-Rank-Dissimilarity-Metric-for-Myocardial-Strain-Estimation-from-Cardiac-Cine-MRI-Images"><a href="#Deformable-Groupwise-Registration-Using-a-Locally-Low-Rank-Dissimilarity-Metric-for-Myocardial-Strain-Estimation-from-Cardiac-Cine-MRI-Images" class="headerlink" title="Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images"></a>Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07348">http://arxiv.org/abs/2311.07348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Chen, Juan Gao, Chenxi Hu</li>
<li>For: The paper is written for cardiac function assessment using cardiac cine MRI images.* Methods: The proposed method uses a deformable groupwise registration-based two-step strategy with a locally low-rank (LLR) dissimilarity metric for CMR-FT.* Results: The proposed method achieved more accurate tracking and strain estimation compared to other methods, especially in late diastole, and may facilitate more accurate assessment of cardiac dysfunction.<details>
<summary>Abstract</summary>
Objective: Cardiovascular magnetic resonance-feature tracking (CMR-FT) represents a group of methods for myocardial strain estimation from cardiac cine MRI images. Established CMR-FT methods are mainly based on optical flow or pairwise registration. However, these methods suffer from either inaccurate estimation of large motion or drift effect caused by accumulative tracking errors. In this work, we propose a deformable groupwise registration method using a locally low-rank (LLR) dissimilarity metric for CMR-FT. Methods: The proposed method (Groupwise-LLR) tracks the feature points by a groupwise registration-based two-step strategy. Unlike the globally low-rank (GLR) dissimilarity metric, the proposed LLR metric imposes low-rankness on local image patches rather than the whole image. We quantitatively compared Groupwise-LLR with the Farneback optical flow, a pairwise registration method, and a GLR-based groupwise registration method on simulated and in vivo datasets. Results: Results from the simulated dataset showed that Groupwise-LLR achieved more accurate tracking and strain estimation compared with the other methods. Results from the in vivo dataset showed that Groupwise-LLR achieved more accurate tracking and elimination of the drift effect in late-diastole. Inter-observer reproducibility of strain estimates was similar between all studied methods. Conclusion: The proposed method estimates myocardial strains more accurately due to the application of a groupwise registration-based tracking strategy and an LLR-based dissimilarity metric. Significance: The proposed CMR-FT method may facilitate more accurate estimation of myocardial strains, especially in diastole, for clinical assessments of cardiac dysfunction.
</details>
<details>
<summary>摘要</summary>
目的：卡地里尺骨磁共振成像-特征跟踪（CMR-FT）是一种基于卡地里磁共振成像图像的肌肉弹性测量方法。现有的CMR-FT方法主要基于光流或对应注册。但这些方法受到大动量或偏移效应的影响，导致测量不准确。在这项工作中，我们提出了一种可变地方法（Groupwise-LLR），使用本地低级（LLR）相似度度量进行群组注册。方法：Groupwise-LLR方法使用两步策略，首先使用光流或对应注册来跟踪特征点，然后使用LLR度量进行群组注册。与全图像的GLR度量不同，LLR度量在本地图像区域强制低级。我们对使用Farneback光流、对应注册方法和GLR基于的群组注册方法进行了量比较。结果：在模拟数据集上，Groupwise-LLR方法在跟踪和弹性测量方面表现更加准确，而在实验数据集上，Groupwise-LLR方法在晚 диастоле阶段消除了偏移效应。对于各种方法的幂等复制性，结果类似。结论：Groupwise-LLR方法可以更加准确地测量肌肉弹性，特别是在 диаastole阶段。意义：Groupwise-LLR方法可能为临床评估卡地里功能障碍提供更加准确的肌肉弹性测量。
</details></li>
</ul>
<hr>
<h2 id="Connecting-the-Dots-Graph-Neural-Network-Powered-Ensemble-and-Classification-of-Medical-Images"><a href="#Connecting-the-Dots-Graph-Neural-Network-Powered-Ensemble-and-Classification-of-Medical-Images" class="headerlink" title="Connecting the Dots: Graph Neural Network Powered Ensemble and Classification of Medical Images"></a>Connecting the Dots: Graph Neural Network Powered Ensemble and Classification of Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07321">http://arxiv.org/abs/2311.07321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aryan-at-ul/aics_2023_submission">https://github.com/aryan-at-ul/aics_2023_submission</a></li>
<li>paper_authors: Aryan Singh, Pepijn Van de Ven, Ciarán Eising, Patrick Denny</li>
<li>for: 这篇论文是为了提出一个可靠、经济可行且可扩展的医疗影像分类方法。</li>
<li>methods: 这篇论文使用了 Image Foresting Transform 来最佳化医疗影像的分割，然后将分割后的图像转换为 graf-structured 数据，使用 Graph Neural Networks (GNNs) 进行特征提取和关系建模。 ensemble 使用三种不同的 GNN 架构来提高其内模的稳定性。</li>
<li>results: 在这篇论文中，这种方法在验证targeting pneumonia classification 的任务中，较前一代的 Deep Neural Networks (DNNs) 高效，同时降低了 Parameters 的数量，从而降低了训练数据的成本和训练时间，并且减少了偏见。<details>
<summary>Abstract</summary>
Deep learning models have demonstrated remarkable results for various computer vision tasks, including the realm of medical imaging. However, their application in the medical domain is limited due to the requirement for large amounts of training data, which can be both challenging and expensive to obtain. To mitigate this, pre-trained models have been fine-tuned on domain-specific data, but such an approach can suffer from inductive biases. Furthermore, deep learning models struggle to learn the relationship between spatially distant features and their importance, as convolution operations treat all pixels equally. Pioneering a novel solution to this challenge, we employ the Image Foresting Transform to optimally segment images into superpixels. These superpixels are subsequently transformed into graph-structured data, enabling the proficient extraction of features and modeling of relationships using Graph Neural Networks (GNNs). Our method harnesses an ensemble of three distinct GNN architectures to boost its robustness. In our evaluations targeting pneumonia classification, our methodology surpassed prevailing Deep Neural Networks (DNNs) in performance, all while drastically cutting down on the parameter count. This not only trims down the expenses tied to data but also accelerates training and minimizes bias. Consequently, our proposition offers a sturdy, economically viable, and scalable strategy for medical image classification, significantly diminishing dependency on extensive training data sets.
</details>
<details>
<summary>摘要</summary>
深度学习模型在各种计算机视觉任务中表现出色，其中包括医疗影像领域。然而，它们在医疗领域的应用受到大量训练数据的限制，这些数据可能具有困难和成本高的获取。为此，人们通常使用预训练模型进行精度调整，但这种方法可能受到逻辑偏见的影响。另外，深度学习模型在图像中的特征之间关系学习不够，因为卷积操作对所有像素进行了平等的处理。为了解决这个挑战，我们提出了图像森林变换，用于优化图像分割成超像素。这些超像素然后被转换成图形结构数据，使得通过图形神经网络（GNN）进行特征提取和模型建立关系。我们的方法使用了三种不同的GNN架构 ensemble，以提高其可靠性。在我们的评估中，我们的方法在肺炎分类任务上表现出excel，而且和传统的深度神经网络相比，它的参数数量大幅减少。这不仅减少了与数据集的成本，还加快训练和降低了偏见。因此，我们的提案提供了一种强大、经济可行和可扩展的医疗图像分类策略，significantly reducing the dependence on extensive training data sets.
</details></li>
</ul>
<hr>
<h2 id="What-Large-Language-Models-Bring-to-Text-rich-VQA"><a href="#What-Large-Language-Models-Bring-to-Text-rich-VQA" class="headerlink" title="What Large Language Models Bring to Text-rich VQA?"></a>What Large Language Models Bring to Text-rich VQA?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07306">http://arxiv.org/abs/2311.07306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuejing Liu, Wei Tang, Xinzhe Ni, Jinghui Lu, Rui Zhao, Zechao Li, Fei Tan</li>
<li>for: 本研究探讨了基于语言模型（LLM）的文本rich VQA方法的优势和瓶颈。</li>
<li>methods: 作者将视觉和语言模块分离，使用外部OCR模型recognize图像中的文本，并使用LLM来回答问题。整个框架不需训练，利用LLM的在场能力。</li>
<li>results: 研究发现，基于LLM的方法在四个文本rich VQA dataset上达到了superior表现，而且基于ablation study，LLM具有更强的理解能力，可能为VQA问题提供有用的知识。然而，研究发现，LLM在视觉部分存在瓶颈。同时， combining OCR模块与MLLM也得到了 pleasantly results。<details>
<summary>Abstract</summary>
Text-rich VQA, namely Visual Question Answering based on text recognition in the images, is a cross-modal task that requires both image comprehension and text recognition. In this work, we focus on investigating the advantages and bottlenecks of LLM-based approaches in addressing this problem. To address the above concern, we separate the vision and language modules, where we leverage external OCR models to recognize texts in the image and Large Language Models (LLMs) to answer the question given texts. The whole framework is training-free benefiting from the in-context ability of LLMs. This pipeline achieved superior performance compared to the majority of existing Multimodal Large Language Models (MLLM) on four text-rich VQA datasets. Besides, based on the ablation study, we find that LLM brings stronger comprehension ability and may introduce helpful knowledge for the VQA problem. The bottleneck for LLM to address text-rich VQA problems may primarily lie in visual part. We also combine the OCR module with MLLMs and pleasantly find that the combination of OCR module with MLLM also works. It's worth noting that not all MLLMs can comprehend the OCR information, which provides insights into how to train an MLLM that preserves the abilities of LLM.
</details>
<details>
<summary>摘要</summary>
文字丰富的VQA（视觉问答）技术，即基于图像中文字识别的图像问答，是跨Modal的任务，需要图像理解和文字识别。在这项工作中，我们主要关注LLM（大语言模型）在解决这个问题上的优势和瓶颈。为了解决这个问题，我们将视觉和语言模块分开，利用外部OCR模型来recognize图像中的文字，并利用LLM来为给定文字提供答案。整个框架不需要训练，借助LLM在context中的能力。这个管道在四个文字丰富VQA数据集上 achieved superior performance，并且基于ablation study，我们发现LLM具有更强的理解能力，可能为VQA问题带来有用的知识。然而，我们发现LLM在处理文字丰富VQA问题的瓶颈主要在视觉部分。此外，我们还将OCR模块与MLLM（多Modal大语言模型）相结合，并发现这种结合也能够工作。需要注意的是，不 всіMLLM都能理解OCR信息，这提供了如何训练一个MLLM，以便它保留LLM的能力。
</details></li>
</ul>
<hr>
<h2 id="Dynamically-Weighted-Factor-Graph-for-Feature-based-Geo-localization"><a href="#Dynamically-Weighted-Factor-Graph-for-Feature-based-Geo-localization" class="headerlink" title="Dynamically Weighted Factor-Graph for Feature-based Geo-localization"></a>Dynamically Weighted Factor-Graph for Feature-based Geo-localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07301">http://arxiv.org/abs/2311.07301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Ángel Muñoz-Bañón, Alejandro Olivas, Edison Velasco-Sánchez, Francisco A. Candelas, Fernando Torres</li>
<li>for: 本研究旨在提高Feature-based地理定位的精度，使其能够在杂乱环境中提供更加可靠的定位结果。</li>
<li>methods: 本研究使用动态加权因子图模型来优化汽车的路径估计，并在检测中使用LiDAR传感器来进行数据质量评估。此外，还包括GNSS基于的先前误差估计。</li>
<li>results: 对比当前最佳地理定位方法，本研究在杂乱环境中显示了更高的精度和更少的偏差。此外，当检测数据失去时，本方法也能够成功地 mitigate 偏差和异常值。<details>
<summary>Abstract</summary>
Feature-based geo-localization relies on associating features extracted from aerial imagery with those detected by the vehicle's sensors. This requires that the type of landmarks must be observable from both sources. This no-variety of feature types generates poor representations that lead to outliers and deviations, produced by ambiguities and lack of detections respectively. To mitigate these drawbacks, in this paper, we present a dynamically weighted factor graph model for the vehicle's trajectory estimation. The weight adjustment in this implementation depends on information quantification in the detections performed using a LiDAR sensor. Also, a prior (GNSS-based) error estimation is included in the model. Then, when the representation becomes ambiguous or sparse, the weights are dynamically adjusted to rely on the corrected prior trajectory, mitigating in this way outliers and deviations. We compare our method against state-of-the-art geo-localization ones in a challenging ambiguous environment, where we also cause detection losses. We demonstrate mitigation of the mentioned drawbacks where the other methods fail.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate text into Simplified ChineseFeature-based geo-localization 基于将从飞行图像中提取的特征与车辆的感知器上探测到的特征进行关联。这需要两者之间的特征类型相同。这种单一的特征类型生成粗糙的表示，导致异常和偏差，由扩大和检测不足所致。为了解决这些缺点，在本文中，我们提出了一种动态权重因子图模型，用于车辆的路径估计。在这个实现中，权重调整取决于利用 LiDAR 探测器进行的检测信息量化。此外，还包括GNSS-based先前错误估计。当表示变得混乱或稀缺时，权重会动态调整，以依靠修正后的先前路径，从而 Mitigate 异常和偏差。我们与现有的地理localization方法进行比较，在一个复杂的混乱环境中，我们还引起检测损失。我们示出了消除这些缺点，其他方法失败的情况。
</details></li>
</ul>
<hr>
<h2 id="Multi-Sentence-Description-of-Complex-Manipulation-Action-Videos"><a href="#Multi-Sentence-Description-of-Complex-Manipulation-Action-Videos" class="headerlink" title="Multi Sentence Description of Complex Manipulation Action Videos"></a>Multi Sentence Description of Complex Manipulation Action Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07285">http://arxiv.org/abs/2311.07285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatemeh Ziaeetabar, Reza Safabakhsh, Saeedeh Momtazi, Minija Tamosiunaite, Florentin Wörgötter</li>
<li>for:  automatización de descripciones de videos</li>
<li>methods:  combina estrategias estadísticas y end-to-end, utilizando LSTM para generar descripciones de videos con diferentes niveles de detalle</li>
<li>results:  produce descripciones más realistas que otras aproximaciones competidoras<details>
<summary>Abstract</summary>
Automatic video description requires the generation of natural language statements about the actions, events, and objects in the video. An important human trait, when we describe a video, is that we are able to do this with variable levels of detail. Different from this, existing approaches for automatic video descriptions are mostly focused on single sentence generation at a fixed level of detail. Instead, here we address video description of manipulation actions where different levels of detail are required for being able to convey information about the hierarchical structure of these actions relevant also for modern approaches of robot learning. We propose one hybrid statistical and one end-to-end framework to address this problem. The hybrid method needs much less data for training, because it models statistically uncertainties within the video clips, while in the end-to-end method, which is more data-heavy, we are directly connecting the visual encoder to the language decoder without any intermediate (statistical) processing step. Both frameworks use LSTM stacks to allow for different levels of description granularity and videos can be described by simple single-sentences or complex multiple-sentence descriptions. In addition, quantitative results demonstrate that these methods produce more realistic descriptions than other competing approaches.
</details>
<details>
<summary>摘要</summary>
自动视频描述需要生成自然语言 sentences about the actions, events, and objects in the video. 人类特点是，当我们描述视频时，我们可以选择不同的级别细节。而现有的自动视频描述方法大多集中在固定级别的句子生成上。在这里，我们解决了视频描述操作动作的问题，其中不同级别的细节是必须以便传递视频中动作层次结构的信息，同时也是现代机器人学习方法的关键。我们提出了一个混合统计学和终端链接的方法，以及一个终端链接方法。两种方法都使用 LSTM 堆来允许不同级别的描述细节，并且视频可以通过单个句子或复杂多句 sentences 来描述。此外，我们对其他竞争方法进行了量化比较，并证明了这些方法生成的描述更加真实。
</details></li>
</ul>
<hr>
<h2 id="LT-ViT-A-Vision-Transformer-for-multi-label-Chest-X-ray-classification"><a href="#LT-ViT-A-Vision-Transformer-for-multi-label-Chest-X-ray-classification" class="headerlink" title="LT-ViT: A Vision Transformer for multi-label Chest X-ray classification"></a>LT-ViT: A Vision Transformer for multi-label Chest X-ray classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07263">http://arxiv.org/abs/2311.07263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Umar Marikkar, Sara Atito, Muhammad Awais, Adam Mahdi</li>
<li>for: 这个研究旨在提高静脉肺X射像（CXR）的医学图像识别 task 中使用 Vision Transformers（ViTs）的性能。</li>
<li>methods: 本研究使用了LT-ViT，一种具有共同注意力的 трансформа器，它结合了图像对象和随机初始化的帮助 tokens，以提高模型的性能。</li>
<li>results: 本研究所得到的结果显示：(1) LT-ViT 在两个公开的 CXR 数据集上比既存的顶尖性能提高; (2) LT-ViT 可以应用于不同的预训法，因此是无预设的; (3) LT-ViT 可以提供模型解释性，不需要 grad-cam 和其他相关技术。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and some existing efforts have been directed towards vision-language training for Chest X-rays (CXRs). However, we envision that there still exists a potential for improvement in vision-only training for CXRs using ViTs, by aggregating information from multiple scales, which has been proven beneficial for non-transformer networks. Hence, we have developed LT-ViT, a transformer that utilizes combined attention between image tokens and randomly initialized auxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT (1) surpasses the state-of-the-art performance using pure ViTs on two publicly available CXR datasets, (2) is generalizable to other pre-training methods and therefore is agnostic to model initialization, and (3) enables model interpretability without grad-cam and its variants.
</details>
<details>
<summary>摘要</summary>
医疗影像任务中广泛采用了视Transformers（ViTs），现有一些努力在视频语言训练中使用ViTs进行胸部X射影像（CXRs）的训练。然而，我们认为还有可能在视力只训练中使用ViTs进行CXRs的提升，通过多尺度信息的汇集，这种方法已经证明对非转换网络有利。因此，我们开发了LT-ViT，一种利用图像征素和随机初始化的auxiliary征素来实现图像特征的共同注意力。我们的实验表明，LT-ViT可以：1. 使用纯度ViTs在两个公开available的CXR数据集上超越现有的状态态强性表现。2. 可以在其他预训练方法上 generalized，因此不виси于模型的初始化。3. 可以无需grad-cam和其他相关图像解释方法，具有解释性。
</details></li>
</ul>
<hr>
<h2 id="Sketch-based-Video-Object-Segmentation-Benchmark-and-Analysis"><a href="#Sketch-based-Video-Object-Segmentation-Benchmark-and-Analysis" class="headerlink" title="Sketch-based Video Object Segmentation: Benchmark and Analysis"></a>Sketch-based Video Object Segmentation: Benchmark and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07261">http://arxiv.org/abs/2311.07261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruolin Yang, Da Li, Conghui Hu, Timothy Hospedales, Honggang Zhang, Yi-Zhe Song</li>
<li>for: 本研究旨在提出一种基于绘图的视频对象 segmentation任务，并提供一个新的标准测试集（Sketch-DAVIS16、Sketch-DAVIS17和Sketch-YouTube-VOS），以便更好地评估视频对象 segmentation 算法。</li>
<li>methods: 本研究使用了 STCN 基eline，并对不同类型的参考（语言表达、scribble和绘图）进行比较，以找出最有效的参考方式。</li>
<li>results: 实验结果显示，使用绘图作为参考是最有效的方式，它比使用语言表达和scribble更有效，同时也更容易进行标注。<details>
<summary>Abstract</summary>
Reference-based video object segmentation is an emerging topic which aims to segment the corresponding target object in each video frame referred by a given reference, such as a language expression or a photo mask. However, language expressions can sometimes be vague in conveying an intended concept and ambiguous when similar objects in one frame are hard to distinguish by language. Meanwhile, photo masks are costly to annotate and less practical to provide in a real application. This paper introduces a new task of sketch-based video object segmentation, an associated benchmark, and a strong baseline. Our benchmark includes three datasets, Sketch-DAVIS16, Sketch-DAVIS17 and Sketch-YouTube-VOS, which exploit human-drawn sketches as an informative yet low-cost reference for video object segmentation. We take advantage of STCN, a popular baseline of semi-supervised VOS task, and evaluate what the most effective design for incorporating a sketch reference is. Experimental results show sketch is more effective yet annotation-efficient than other references, such as photo masks, language and scribble.
</details>
<details>
<summary>摘要</summary>
参考基础视频对象分割是一个emerging topic，旨在将每帧视频内对应的目标物体进行分割，以参考一个 giventext or photo mask。然而，语言表达可能会对某些概念发送不确定的信息，而且在一帧中相似的物体可能很难以通过语言区分。另一方面，photo masks是costly to annotate并且在实际应用中 menos practical。这篇论文介绍了一个新的任务：sketch-based video object segmentation，以及相关的benchmark和强大基线。我们的benchmark包括Sketch-DAVIS16、Sketch-DAVIS17和Sketch-YouTube-VOS三个 dataset，这些dataset利用人类手绘的sketches作为视频对象分割的参考。我们利用STCN，一个受欢迎的semi-supervised VOS任务的基eline，进行评估，并评估在不同的参考方法中，sketch是否比其他参考方法更有效率。实验结果表明，sketch比其他参考方法更有效率，并且可以实现更低的注释成本。
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-Clutter-Detection-and-Semantic-Segmentation-of-Moving-Objects-for-Automotive-Radar-Data"><a href="#Simultaneous-Clutter-Detection-and-Semantic-Segmentation-of-Moving-Objects-for-Automotive-Radar-Data" class="headerlink" title="Simultaneous Clutter Detection and Semantic Segmentation of Moving Objects for Automotive Radar Data"></a>Simultaneous Clutter Detection and Semantic Segmentation of Moving Objects for Automotive Radar Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07247">http://arxiv.org/abs/2311.07247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Kopp, Dominik Kellner, Aldi Piroli, Vinzenz Dallabetta, Klaus Dietmayer</li>
<li>for: 本研究旨在实现同时解决干扰点云和 semantic segmentation问题，而不是将它们处理为两个独立的任务。</li>
<li>methods: 我们提出了一个新的增强多头架构造，以及一种用于表示网络预测值的新方法，以便同时解决两个任务。</li>
<li>results: 我们在广泛的评估中展示了我们的设置高效且超越了现有的网络模型，在RadarScenes dataset上的 semantic segmentation任务中。<details>
<summary>Abstract</summary>
The unique properties of radar sensors, such as their robustness to adverse weather conditions, make them an important part of the environment perception system of autonomous vehicles. One of the first steps during the processing of radar point clouds is often the detection of clutter, i.e. erroneous points that do not correspond to real objects. Another common objective is the semantic segmentation of moving road users. These two problems are handled strictly separate from each other in literature. The employed neural networks are always focused entirely on only one of the tasks. In contrast to this, we examine ways to solve both tasks at the same time with a single jointly used model. In addition to a new augmented multi-head architecture, we also devise a method to represent a network's predictions for the two tasks with only one output value. This novel approach allows us to solve the tasks simultaneously with the same inference time as a conventional task-specific model. In an extensive evaluation, we show that our setup is highly effective and outperforms every existing network for semantic segmentation on the RadarScenes dataset.
</details>
<details>
<summary>摘要</summary>
射频探测器的特有性，如其对恶劣天气的稳定性，使其成为自动驾驶车辆环境感知系统中重要的一部分。在处理射频点云时，一个常见的第一步是检测噪声，即无关实际物体的错误点。另一个常见的目标是对移动路用户进行 semantic segmentation。在文献中，这两个问题通常被视为独立的两个任务，并且使用的神经网络总是专注于单一任务。相比之下，我们研究了同时解决这两个任务的方法，使用了一种新的加密多头架构，以及一种用于表示网络预测值的新方法。这种新approach允许我们在同一个推理时间内同时解决两个任务。在广泛的评估中，我们发现了我们的设置非常有效，并在RadarScenes dataset上超越了每个存在的网络。
</details></li>
</ul>
<hr>
<h2 id="DeepMetricEye-Metric-Depth-Estimation-in-Periocular-VR-Imagery"><a href="#DeepMetricEye-Metric-Depth-Estimation-in-Periocular-VR-Imagery" class="headerlink" title="DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery"></a>DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07235">http://arxiv.org/abs/2311.07235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitong Sun, Zijian Zhou, Cyriel Diels, Ali Asadipour</li>
<li>for: 提供一种用于计算视网膜区域的深度图的轻量级框架，以便在VR头戴式设备上实现可量化的眼部区域计算。</li>
<li>methods: 使用基于U-Net 3+深度学习框架的轻量级框架，将Relative Measurements转换为可量化的Periocular Depth Maps。</li>
<li>results: 在36名参与者的测试中，方法表现出色，在眼部全球精度评估实验和豹心眼径测量方面达到了显著的效果。<details>
<summary>Abstract</summary>
Despite the enhanced realism and immersion provided by VR headsets, users frequently encounter adverse effects such as digital eye strain (DES), dry eye, and potential long-term visual impairment due to excessive eye stimulation from VR displays and pressure from the mask. Recent VR headsets are increasingly equipped with eye-oriented monocular cameras to segment ocular feature maps. Yet, to compute the incident light stimulus and observe periocular condition alterations, it is imperative to transform these relative measurements into metric dimensions. To bridge this gap, we propose a lightweight framework derived from the U-Net 3+ deep learning backbone that we re-optimised, to estimate measurable periocular depth maps. Compatible with any VR headset equipped with an eye-oriented monocular camera, our method reconstructs three-dimensional periocular regions, providing a metric basis for related light stimulus calculation protocols and medical guidelines. Navigating the complexities of data collection, we introduce a Dynamic Periocular Data Generation (DPDG) environment based on UE MetaHuman, which synthesises thousands of training images from a small quantity of human facial scan data. Evaluated on a sample of 36 participants, our method exhibited notable efficacy in the periocular global precision evaluation experiment, and the pupil diameter measurement.
</details>
<details>
<summary>摘要</summary>
尽管虚拟现实（VR）头戴设备提供了更加真实和沉浸的用户体验，但用户们经常出现不良影响，如数字眼疲病（DES）、干燥眼睛和可能的长期视力障碍，这些影响是由 VR 显示器和头戴设备的压力所致。现有的 VR 头戴设备通常配备有面向眼睛的单目镜像传感器，以分割眼部特征地图。然而，为了计算入射光刺激和观察眼部状态的变化，需要将这些相对测量转换成 metric 维度。为了bridging这个差距，我们提出了一个轻量级的框架，基于 U-Net 3+ 深度学习基础，用于估计可测量的眼部深度地图。与任何配备有面向眼睛单目镜像传感器的 VR 头戴设备兼容，我们的方法可重construct三维眼部区域，提供metric 基础 для相关的光刺激计算协议和医疗指南。在数据收集的复杂性方面，我们引入了一个基于 UE MetaHuman 的动态眼部数据生成环境（DPDG），该环境可以从小量的人类脸部扫描数据中生成数千个训练图像。在一个样本中，我们的方法在眼部全球精度评估实验和评估眼径大小方面表现出了明显的有效性。
</details></li>
</ul>
<hr>
<h2 id="Multi-task-learning-for-joint-weakly-supervised-segmentation-and-aortic-arch-anomaly-classification-in-fetal-cardiac-MRI"><a href="#Multi-task-learning-for-joint-weakly-supervised-segmentation-and-aortic-arch-anomaly-classification-in-fetal-cardiac-MRI" class="headerlink" title="Multi-task learning for joint weakly-supervised segmentation and aortic arch anomaly classification in fetal cardiac MRI"></a>Multi-task learning for joint weakly-supervised segmentation and aortic arch anomaly classification in fetal cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07234">http://arxiv.org/abs/2311.07234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/svrtk/masc-multi-task-segmentation-and-classification">https://github.com/svrtk/masc-multi-task-segmentation-and-classification</a></li>
<li>paper_authors: Paula Ramirez, Alena Uus, Milou P. M. van Poppel, Irina Grigorescu, Johannes K. Steinweg, David F. A. Lloyd, Kuberan Pushparajah, Andrew P. King, Maria Deprez</li>
<li>for: 这个研究的目的是为了帮助3D胎儿血管图像的自动化分类和检测，以提高诊断confidence。</li>
<li>methods: 这个研究使用了深度学习的标签卷积和注意力3D U-Net segmentation，以及密集度121的疾病分类。</li>
<li>results: 研究结果表明，我们的提出的训练策略在Label propagation和仅使用卷积过程中训练的网络之上表现出色，并且我们的分类器在与T2w图像进行joint training后表现出色，其平均权衡准确率为0.99（0.01）。<details>
<summary>Abstract</summary>
Congenital Heart Disease (CHD) is a group of cardiac malformations present already during fetal life, representing the prevailing category of birth defects globally. Our aim in this study is to aid 3D fetal vessel topology visualisation in aortic arch anomalies, a group which encompasses a range of conditions with significant anatomical heterogeneity. We present a multi-task framework for automated multi-class fetal vessel segmentation from 3D black blood T2w MRI and anomaly classification. Our training data consists of binary manual segmentation masks of the cardiac vessels' region in individual subjects and fully-labelled anomaly-specific population atlases. Our framework combines deep learning label propagation using VoxelMorph with 3D Attention U-Net segmentation and DenseNet121 anomaly classification. We target 11 cardiac vessels and three distinct aortic arch anomalies, including double aortic arch, right aortic arch, and suspected coarctation of the aorta. We incorporate an anomaly classifier into our segmentation pipeline, delivering a multi-task framework with the primary motivation of correcting topological inaccuracies of the segmentation. The hypothesis is that the multi-task approach will encourage the segmenter network to learn anomaly-specific features. As a secondary motivation, an automated diagnosis tool may have the potential to enhance diagnostic confidence in a decision support setting. Our results showcase that our proposed training strategy significantly outperforms label propagation and a network trained exclusively on propagated labels. Our classifier outperforms a classifier trained exclusively on T2w volume images, with an average balanced accuracy of 0.99 (0.01) after joint training. Adding a classifier improves the anatomical and topological accuracy of all correctly classified double aortic arch subjects.
</details>
<details>
<summary>摘要</summary>
《固有心脏病（CHD）》是胎生时已经存在的心脏畸形，全球范围内最常见的出生畸形之一。我们在这项研究中的目标是通过自动化多类胎 vessle分割和畸形分类来提高3D黑血MRI中胎 vessle topology的可视化。我们的训练数据包括各个个体的手动Binary manual segmentation masks of the cardiac vessels' region和具有精度的畸形特征的各个畸形人体 Atlases。我们的框架结合了深度学习标签传播使用VoxelMorph和3D Attention U-Net segmentation和DenseNet121畸形分类。我们目标是11个心脏血管和三种不同的脊梁畸形，包括双脊梁、右脊梁和可能的脊梁缺陷。我们将畸形分类器 incorporated into our segmentation pipeline，实现一个多任务框架，主要目的是 correction topological inaccuracies of the segmentation。我们 hypothesize that the multi-task approach will encourage the segmenter network to learn anomaly-specific features。作为次要目的，一个自动诊断工具可能会提高诊断自信性。我们的结果表明，我们的训练策略在比label propagation和专门训练在propagated labels的网络之上显著提高。我们的分类器在与T2wVolume Image进行同时训练后，其平均平衡准确率为0.99（0.01）。增加分类器可以提高所有正确分类double aortic arch的 анатомиче和 topological 准确性。
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Learning-for-the-Classification-of-Confocal-Laser-Endomicroscopy-Images-of-Head-and-Neck-Tumors"><a href="#Few-Shot-Learning-for-the-Classification-of-Confocal-Laser-Endomicroscopy-Images-of-Head-and-Neck-Tumors" class="headerlink" title="Few Shot Learning for the Classification of Confocal Laser Endomicroscopy Images of Head and Neck Tumors"></a>Few Shot Learning for the Classification of Confocal Laser Endomicroscopy Images of Head and Neck Tumors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07216">http://arxiv.org/abs/2311.07216</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Aubreville, Zhaoya Pan, Matti Sievert, Jonas Ammeling, Jonathan Ganz, Nicolai Oetter, Florian Stelzle, Ann-Kathrin Frenken, Katharina Breininger, Miguel Goncalves</li>
<li>for: 这种研究旨在发展一种基于confocal laser endomicroscopy（CLE）的自动分析方法，以帮助外科医生在移除头颈肿瘤时确保安全的边缘。</li>
<li>methods: 这些研究人员使用了四种流行的几个shot学习（FSL）方法，以评估它们在不同的生理结构领域中的泛化能力。</li>
<li>results: 研究结果表明，FSL在CLE图像上是可能的，但受到patient数量和生理结构领域的多样性的影响。在 vocals folds（VF）图像上，最佳方法达到了79.6%的 médiane accuracy，而在sinunasal tumors（SNT）图像上只达到了61.6%的 médiane accuracy。<details>
<summary>Abstract</summary>
The surgical removal of head and neck tumors requires safe margins, which are usually confirmed intraoperatively by means of frozen sections. This method is, in itself, an oversampling procedure, which has a relatively low sensitivity compared to the definitive tissue analysis on paraffin-embedded sections. Confocal laser endomicroscopy (CLE) is an in-vivo imaging technique that has shown its potential in the live optical biopsy of tissue. An automated analysis of this notoriously difficult to interpret modality would help surgeons. However, the images of CLE show a wide variability of patterns, caused both by individual factors but also, and most strongly, by the anatomical structures of the imaged tissue, making it a challenging pattern recognition task. In this work, we evaluate four popular few shot learning (FSL) methods towards their capability of generalizing to unseen anatomical domains in CLE images. We evaluate this on images of sinunasal tumors (SNT) from five patients and on images of the vocal folds (VF) from 11 patients using a cross-validation scheme. The best respective approach reached a median accuracy of 79.6% on the rather homogeneous VF dataset, but only of 61.6% for the highly diverse SNT dataset. Our results indicate that FSL on CLE images is viable, but strongly affected by the number of patients, as well as the diversity of anatomical patterns.
</details>
<details>
<summary>摘要</summary>
surgical removal of head and neck tumors 需要安全的边缘，通常通过冻结部分来确认。这是一种过度采样的方法，其敏感度相对较低于 définitive tissue analysis on paraffin-embedded sections。Confocal laser endomicroscopy (CLE) 是一种实时成像技术，可以在实时生物组织检查中提供信息。然而，CLE 图像具有很大的变化，由于个体因素以及镜头检查的结构，这是一项具有挑战性的模式识别任务。在这项工作中，我们评估了四种流行的少数shot learning（FSL）方法，以其能否在未经见过的生理结构中广泛应用。我们使用了五名患者的 sinunasal tumors（SNT）图像和 11名患者的 vocal folds（VF）图像，采用交叉验证方式进行评估。最佳方法在 relativamente homogeneous VF 数据集上达到了79.6%的 median 准确率，但只有61.6%的准确率在高度多样化的 SNT 数据集上。我们的结果表明，FSL on CLE 图像是可行的，但受到patient 数量以及生理结构的多样化的影响。
</details></li>
</ul>
<hr>
<h2 id="A-method-for-quantifying-sectoral-optic-disc-pallor-in-fundus-photographs-and-its-association-with-peripapillary-RNFL-thickness"><a href="#A-method-for-quantifying-sectoral-optic-disc-pallor-in-fundus-photographs-and-its-association-with-peripapillary-RNFL-thickness" class="headerlink" title="A method for quantifying sectoral optic disc pallor in fundus photographs and its association with peripapillary RNFL thickness"></a>A method for quantifying sectoral optic disc pallor in fundus photographs and its association with peripapillary RNFL thickness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07213">http://arxiv.org/abs/2311.07213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Gibbon, Graciela Muniz-Terrera, Fabian SL Yii, Charlene Hamid, Simon Cox, Ian JC Maccormick, Andrew J Tatham, Craig Ritchie, Emanuele Trucco, Baljean Dhillon, Thomas J MacGillivray</li>
<li>for: 本研究的目的是开发一种自动地量化眼睛背部缺乏症状的方法，以及与背部 nerf fibre layer (pRNFL) 厚度的关系。</li>
<li>methods: 我们使用深度学习来 segment 眼睛背部、芳香突起和血管在眼睛照片中，并测量缺乏症状。我们通过对 pRNFL 厚度来自光共振扫描仪获得的数据进行分析，并在 118 名参与者中评估了缺乏症状和 pRNFL 厚度之间的关系。此外，我们还使用临床诊断为衰竭（N&#x3D;45）的图像进行测量，并与健康控制群（N&#x3D;46）进行比较。</li>
<li>results: 我们开发了一种可自动量化眼睛背部缺乏症状的软件。我们发现，缺乏症状与 pRNFL 厚度在全体、 temporal 下部、nasal&#x2F;temporal 比例和整个眼睛背部之间存在关系。此外，衰竭组的缺乏症状也显著高于健康组。最后，我们也证明了这种分析方法对于相机类型、图像格式和分辨率的变化是可Robust。<details>
<summary>Abstract</summary>
Purpose: To develop an automatic method of quantifying optic disc pallor in fundus photographs and determine associations with peripapillary retinal nerve fibre layer (pRNFL) thickness.   Methods: We used deep learning to segment the optic disc, fovea, and vessels in fundus photographs, and measured pallor. We assessed the relationship between pallor and pRNFL thickness derived from optical coherence tomography scans in 118 participants. Separately, we used images diagnosed by clinical inspection as pale (N=45) and assessed how measurements compared to healthy controls (N=46). We also developed automatic rejection thresholds, and tested the software for robustness to camera type, image format, and resolution.   Results: We developed software that automatically quantified disc pallor across several zones in fundus photographs. Pallor was associated with pRNFL thickness globally (\b{eta} = -9.81 (SE = 3.16), p < 0.05), in the temporal inferior zone (\b{eta} = -29.78 (SE = 8.32), p < 0.01), with the nasal/temporal ratio (\b{eta} = 0.88 (SE = 0.34), p < 0.05), and in the whole disc (\b{eta} = -8.22 (SE = 2.92), p < 0.05). Furthermore, pallor was significantly higher in the patient group. Lastly, we demonstrate the analysis to be robust to camera type, image format, and resolution.   Conclusions: We developed software that automatically locates and quantifies disc pallor in fundus photographs and found associations between pallor measurements and pRNFL thickness.   Translational relevance: We think our method will be useful for the identification, monitoring and progression of diseases characterized by disc pallor/optic atrophy, including glaucoma, compression, and potentially in neurodegenerative disorders.
</details>
<details>
<summary>摘要</summary>
Methods: 我们使用深度学习来分割盘绿、芳香眼和血管在眼科照片中，并测量盘绿。我们在118名参与者中评估了盘绿与pRNFL厚度之间的关系，并分别使用被诊断为脊梁（N=45）和健康控制群（N=46）的图像进行比较。此外，我们还开发了自动拒绝阈值，并测试了软件的对camera类型、图像格式和分辨率的Robustness。Results: 我们开发了一种可以自动量化盘绿在多个区域的眼科照片中的软件。盘绿与pRNFL厚度之间存在全体(\b{eta} = -9.81 (SE = 3.16), p < 0.05), temporo- inferior区域(\b{eta} = -29.78 (SE = 8.32), p < 0.01)和nasal/temporal比率(\b{eta} = 0.88 (SE = 0.34), p < 0.05)之间的关系。此外，盘绿在病例群体中高于健康控制群。最后，我们证明了这种分析方法对camera类型、图像格式和分辨率的Robustness。Conclusions: 我们开发了一种可以自动分割盘绿、芳香眼和血管的软件，并发现了盘绿测量与pRNFL厚度之间的关系。Translational relevance: 我们认为这种方法将有用于识别、监测和评估 caracterized by disc pallor/optic atrophy的疾病，包括 glaucoma, compression, 和可能的neurodegenerative disorders。
</details></li>
</ul>
<hr>
<h2 id="Cross-modal-Generative-Model-for-Visual-Guided-Binaural-Stereo-Generation"><a href="#Cross-modal-Generative-Model-for-Visual-Guided-Binaural-Stereo-Generation" class="headerlink" title="Cross-modal Generative Model for Visual-Guided Binaural Stereo Generation"></a>Cross-modal Generative Model for Visual-Guided Binaural Stereo Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07630">http://arxiv.org/abs/2311.07630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaojian Li, Bin Zhao, Yuan Yuan</li>
<li>for: 本研究提出了一种基于生成对抗学习的视觉导向的双耳立体声音生成方法，以提供更加听众式的听众体验。</li>
<li>methods: 本方法使用生成器和判定器，通过视觉共享的共同视觉信息来引导生成器和判定器分别工作。在生成对抗阶段，共同视觉信息被逐渐更新，allowing生成器和判定器发挥相互协作的作用。</li>
<li>results: 该方法在2个数据集和5个评价指标上达到了状态对抗的性能，并且在实际应用中可以提供空间实际的双耳立体声音。<details>
<summary>Abstract</summary>
Binaural stereo audio is recorded by imitating the way the human ear receives sound, which provides people with an immersive listening experience. Existing approaches leverage autoencoders and directly exploit visual spatial information to synthesize binaural stereo, resulting in a limited representation of visual guidance. For the first time, we propose a visually guided generative adversarial approach for generating binaural stereo audio from mono audio. Specifically, we develop a Stereo Audio Generation Model (SAGM), which utilizes shared spatio-temporal visual information to guide the generator and the discriminator to work separately. The shared visual information is updated alternately in the generative adversarial stage, allowing the generator and discriminator to deliver their respective guided knowledge while visually sharing. The proposed method learns bidirectional complementary visual information, which facilitates the expression of visual guidance in generation. In addition, spatial perception is a crucial attribute of binaural stereo audio, and thus the evaluation of stereo spatial perception is essential. However, previous metrics failed to measure the spatial perception of audio. To this end, a metric to measure the spatial perception of audio is proposed for the first time. The proposed metric is capable of measuring the magnitude and direction of spatial perception in the temporal dimension. Further, considering its function, it is feasible to utilize it instead of demanding user studies to some extent. The proposed method achieves state-of-the-art performance on 2 datasets and 5 evaluation metrics. Qualitative experiments and user studies demonstrate that the method generates space-realistic stereo audio.
</details>
<details>
<summary>摘要</summary>
人类耳朵所接收的声音方式为我们录制双耳立体声音提供了启发，从而为人们提供了沉浸式听众体验。现有方法利用自动编码器并直接利用视觉空间信息来生成双耳立体声音，但这会导致视觉指导的限制表现。我们为首次提出了基于视觉导向生成抗战斗方法，通过共享视觉信息来导引生成器和批判器分开工作。特别是，我们开发了双耳声音生成模型（SAGM），该模型利用共享的空间时间视觉信息来导引生成器和批判器。共享的视觉信息在生成抗战斗阶段不断更新，allowing生成器和批判器同时传递各自的导引知识，从而实现了视觉共享。此外，空间感知是双耳立体声音的重要特征，因此评估双耳立体声音的空间感知是必要的。然而，先前的指标未能评估音频中的空间感知。为此，我们提出了一种新的指标来评估音频中的空间感知。该指标可以评估音频中的空间感知的大小和方向。此外，由于其功能，可以在一定程度上取代用户研究。我们的方法在两个数据集和五个评价指标上达到了状态的最佳性能。Qualitative实验和用户研究表明，我们的方法可以生成真实的空间声音。
</details></li>
</ul>
<hr>
<h2 id="MonoDiffusion-Self-Supervised-Monocular-Depth-Estimation-Using-Diffusion-Model"><a href="#MonoDiffusion-Self-Supervised-Monocular-Depth-Estimation-Using-Diffusion-Model" class="headerlink" title="MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model"></a>MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07198">http://arxiv.org/abs/2311.07198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuweishao/monodiffusion">https://github.com/shuweishao/monodiffusion</a></li>
<li>paper_authors: Shuwei Shao, Zhongcai Pei, Weihai Chen, Dingchi Sun, Peter C. Y. Chen, Zhengguo Li</li>
<li>for: 本研究旨在提出一种新的自监督深度估计框架，称为MONODIFFUSION，该框架通过形式化为迭代减噪过程来实现。</li>
<li>methods: 我们在这种情况下开发了一种 pseudo 基准数据扩充过程，以帮助 MONODIFFUSION 的扩充。此外，我们还开发了一种masked visual condition机制，以提高模型的减噪能力。</li>
<li>results: 我们在 KITTI 和 Make3D 数据集上进行了广泛的实验，并证明了 MONODIFFUSION 在自监督深度估计中超过了先前的状态时刻。源代码将在 <a target="_blank" rel="noopener" href="https://github.com/ShuweiShao/MonoDiffusion">https://github.com/ShuweiShao/MonoDiffusion</a> 上发布。<details>
<summary>Abstract</summary>
Over the past few years, self-supervised monocular depth estimation that does not depend on ground-truth during the training phase has received widespread attention. Most efforts focus on designing different types of network architectures and loss functions or handling edge cases, e.g., occlusion and dynamic objects. In this work, we introduce a novel self-supervised depth estimation framework, dubbed MonoDiffusion, by formulating it as an iterative denoising process. Because the depth ground-truth is unavailable in the training phase, we develop a pseudo ground-truth diffusion process to assist the diffusion in MonoDiffusion. The pseudo ground-truth diffusion gradually adds noise to the depth map generated by a pre-trained teacher model. Moreover,the teacher model allows applying a distillation loss to guide the denoised depth. Further, we develop a masked visual condition mechanism to enhance the denoising ability of model. Extensive experiments are conducted on the KITTI and Make3D datasets and the proposed MonoDiffusion outperforms prior state-of-the-art competitors. The source code will be available at https://github.com/ShuweiShao/MonoDiffusion.
</details>
<details>
<summary>摘要</summary>
Note:* "自动" (zìdòng) is used instead of "self-supervised" to emphasize the lack of ground truth during training.* "推理" (tiělǐ) is used instead of "denoising" to emphasize the iterative process.* "假" (jiǎ) is used instead of "pseudo" to emphasize the artificial nature of the pseudo ground truth.* "导学" (dǎoxué) is used instead of "distillation" to emphasize the role of the teacher model.* "遮盖" (miànjià) is used instead of "masked" to emphasize the hiding of the visual information.* "能力" (nénglì) is used instead of "ability" to emphasize the capability of the model.
</details></li>
</ul>
<hr>
<h2 id="Fitting-tree-model-with-CNN-and-geodesics-to-track-vesselsand-application-to-Ultrasound-Localization-Microscopy-data"><a href="#Fitting-tree-model-with-CNN-and-geodesics-to-track-vesselsand-application-to-Ultrasound-Localization-Microscopy-data" class="headerlink" title="Fitting tree model with CNN and geodesics to track vesselsand application to Ultrasound Localization Microscopy data"></a>Fitting tree model with CNN and geodesics to track vesselsand application to Ultrasound Localization Microscopy data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07188">http://arxiv.org/abs/2311.07188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Théo Bertrand, Laurent D. Cohen</li>
<li>for: 探测血管网络中的重要标志点（通过CNN进行本地化和分类），并将血管表示为最小距离树图。</li>
<li>methods: 利用地odesic方法探测血管的几何特征，并在位置和orientation空间中使用空间位置和orientation来准确表示2D血管为树结构。</li>
<li>results: 虽然ULM数据的标注稀缺性是本研究的一大障碍，但是使用ULM数据构建的 Orientation Score 可以提供好的地odesics  для跟踪血管。<details>
<summary>Abstract</summary>
Segmentation of tubular structures in vascular imaging is a well studied task, although it is rare that we try to infuse knowledge of the tree-like structure of the regions to be detected. Our work focuses on detecting the important landmarks in the vascular network (via CNN performing both localization and classification of the points of interest) and representing vessels as the edges in some minimal distance tree graph. We leverage geodesic methods relevant to the detection of vessels and their geometry, making use of the space of positions and orientations so that 2D vessels can be accurately represented as trees. We build our model to carry tracking on Ultrasound Localization Microscopy (ULM) data, proposing to build a good cost function for tracking on this type of data. We also test our framework on synthetic and eye fundus data. Results show that scarcity of well annotated ULM data is an obstacle to localization of vascular landmarks but the Orientation Score built from ULM data yields good geodesics for tracking blood vessels.
</details>
<details>
<summary>摘要</summary>
干流结构分割在血管成像中是已经广泛研究的任务，然而rarely 我们会利用树状结构的知识来检测这些区域。我们的工作是通过使用卷积神经网络进行本地化和分类 interested points，并将血管表示为最小距离树图的边。我们利用血管的推断方法和几何学特性，使用空间位置和方向的空间，以便精确地表示2D血管为树。我们建立了一个良好的成本函数，以便在这种数据上进行跟踪。我们还在synthetic和眼球膜数据上测试了我们的框架。结果表明，ULM数据的缺乏高质量标注是血管地标的本地化的主要障碍，但是我们构建的Orientation Score从ULM数据中得到了良好的地odesics для跟踪血管。
</details></li>
</ul>
<hr>
<h2 id="Regenerating-Arbitrary-Video-Sequences-with-Distillation-Path-Finding"><a href="#Regenerating-Arbitrary-Video-Sequences-with-Distillation-Path-Finding" class="headerlink" title="Regenerating Arbitrary Video Sequences with Distillation Path-Finding"></a>Regenerating Arbitrary Video Sequences with Distillation Path-Finding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07170">http://arxiv.org/abs/2311.07170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi-Ngoc-Hanh Le, Sheng-Yi Yao, Chun-Te Wu, Tong-Yee Lee</li>
<li>for: 这篇论文是为了提供一种可互动的框架，帮助用户根据自己的喜好选择视频动画的开场场景。</li>
<li>methods: 这篇论文使用了一种名为RSFNet的网络来学习视频帧集的特征相关性，然后使用一种新的路径找索算法（SDPF）来基于源视频的运动方向来生成新的动画序列。</li>
<li>results: 该框架可以生成新的动画序列，并且可以在 cartoon 和自然场景中生成更加精准和自然的动画。这些结果超越了现有的商业应用程序和先前的研究工作。<details>
<summary>Abstract</summary>
If the video has long been mentioned as a widespread visualization form, the animation sequence in the video is mentioned as storytelling for people. Producing an animation requires intensive human labor from skilled professional artists to obtain plausible animation in both content and motion direction, incredibly for animations with complex content, multiple moving objects, and dense movement. This paper presents an interactive framework to generate new sequences according to the users' preference on the starting frame. The critical contrast of our approach versus prior work and existing commercial applications is that novel sequences with arbitrary starting frame are produced by our system with a consistent degree in both content and motion direction. To achieve this effectively, we first learn the feature correlation on the frameset of the given video through a proposed network called RSFNet. Then, we develop a novel path-finding algorithm, SDPF, which formulates the knowledge of motion directions of the source video to estimate the smooth and plausible sequences. The extensive experiments show that our framework can produce new animations on the cartoon and natural scenes and advance prior works and commercial applications to enable users to obtain more predictable results.
</details>
<details>
<summary>摘要</summary>
如果视频已经被广泛认为是视觉化的形式，视频中的动画序列被视为人们的故事tellding。制作动画需要凝心的人工劳动，从技巧备受训练的艺术家手中获得可信度的动画内容和动作方向，特别是对于具有复杂内容、多个移动对象和紧张运动的动画。本文提出了一种互动框架，可以根据用户的首帧偏好生成新的序列。我们的方法与先前的工作和商业应用程序的重要对比点在于，我们的系统可以生成novel的序列，并且在内容和动作方向上具有一致的度。为了实现这一目标，我们首先通过我们提出的网络 called RSFNet 学习视频帧集中的特征相关性。然后，我们开发了一种新的路径找索算法，SDPF，该算法利用源视频中的动作方向知识来估算可靠和可信度的新序列。我们的实验表明，我们的框架可以生成在 cartoon 和自然场景中的新动画，并超越先前的工作和商业应用程序，让用户可以更加预测性地获得结果。
</details></li>
</ul>
<hr>
<h2 id="NDDepth-Normal-Distance-Assisted-Monocular-Depth-Estimation-and-Completion"><a href="#NDDepth-Normal-Distance-Assisted-Monocular-Depth-Estimation-and-Completion" class="headerlink" title="NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion"></a>NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07166">http://arxiv.org/abs/2311.07166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ShuweiShao/NDDepth">https://github.com/ShuweiShao/NDDepth</a></li>
<li>paper_authors: Shuwei Shao, Zhongcai Pei, Weihai Chen, Peter C. Y. Chen, Zhengguo Li</li>
<li>for: 本研究旨在提出一种基于物理（几何）的深度学习框架，用于单目深度估计和完成任务。</li>
<li>methods: 我们提出了一种新的深度估计和完成方法，即先估计表面法向和到原点距离图像，然后将其转换为深度图像。此外，我们还开发了一个额外的深度头，以增强方法的稳定性。</li>
<li>results: 我们在NYU-Depth-v2、KITTI和SUN RGB-D数据集上进行了广泛的实验，结果表明我们的方法在单目深度估计和完成任务中表现出色，超越了先前的状态OF-the-art竞争者。<details>
<summary>Abstract</summary>
Over the past few years, monocular depth estimation and completion have been paid more and more attention from the computer vision community because of their widespread applications. In this paper, we introduce novel physics (geometry)-driven deep learning frameworks for these two tasks by assuming that 3D scenes are constituted with piece-wise planes. Instead of directly estimating the depth map or completing the sparse depth map, we propose to estimate the surface normal and plane-to-origin distance maps or complete the sparse surface normal and distance maps as intermediate outputs. To this end, we develop a normal-distance head that outputs pixel-level surface normal and distance. Meanwhile, the surface normal and distance maps are regularized by a developed plane-aware consistency constraint, which are then transformed into depth maps. Furthermore, we integrate an additional depth head to strengthen the robustness of the proposed frameworks. Extensive experiments on the NYU-Depth-v2, KITTI and SUN RGB-D datasets demonstrate that our method exceeds in performance prior state-of-the-art monocular depth estimation and completion competitors. The source code will be available at https://github.com/ShuweiShao/NDDepth.
</details>
<details>
<summary>摘要</summary>
过去几年，单目深度估计和完成已经在计算机视觉社区获得了更多的关注，因为它们在各种应用场景中具有广泛的应用前景。在这篇论文中，我们介绍了一种新的物理（几何）驱动的深度学习框架，假设3D场景由块状平面组成。而不是直接估计深度图或完成缺失的深度图，我们提议估计像素级面法向和平面到原点距离图。为此，我们开发了一个面法距离头，该头输出像素级面法向和距离。此外，我们还开发了一个扩展的深度头，以强化我们提议的框架的稳定性。广泛的实验表明，我们的方法在NYU-Depth-v2、KITTI和SUN RGB-D数据集上的性能较前状态的单目深度估计和完成竞争者高。代码将在https://github.com/ShuweiShao/NDDepth上公开。
</details></li>
</ul>
<hr>
<h2 id="CycleGANAS-Differentiable-Neural-Architecture-Search-for-CycleGAN"><a href="#CycleGANAS-Differentiable-Neural-Architecture-Search-for-CycleGAN" class="headerlink" title="CycleGANAS: Differentiable Neural Architecture Search for CycleGAN"></a>CycleGANAS: Differentiable Neural Architecture Search for CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07162">http://arxiv.org/abs/2311.07162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taegun An, Changhee Joo</li>
<li>for: 这个论文是为了搜索CyclesGAN的神经网络架构，用于无对照图像转换任务。</li>
<li>methods: 这个框架使用了一系列简单的ResNet基于细胞，并开发了一种有效地搜索大搜索空间的搜索方法。</li>
<li>results: 我们的框架可以不 только有效地找到高性能的架构，而且也能够成功地解决数据不均衡问题。<details>
<summary>Abstract</summary>
We develop a Neural Architecture Search (NAS) framework for CycleGAN that carries out unpaired image-to-image translation task. Extending previous NAS techniques for Generative Adversarial Networks (GANs) to CycleGAN is not straightforward due to the task difference and greater search space. We design architectures that consist of a stack of simple ResNet-based cells and develop a search method that effectively explore the large search space. We show that our framework, called CycleGANAS, not only effectively discovers high-performance architectures that either match or surpass the performance of the original CycleGAN, but also successfully address the data imbalance by individual architecture search for each translation direction. To our best knowledge, it is the first NAS result for CycleGAN and shed light on NAS for more complex structures.
</details>
<details>
<summary>摘要</summary>
我们开发了一个基于神经网络搜索（NAS）框架，用于实现无对照图像到图像翻译任务。与前一代GANs NAS技术不同，将NAS技术应用于CycleGAN任务不是直接的，因为任务的不同和搜索空间的更大。我们设计了一个由堆式简单的ResNet基于细胞组成的 architecture，并开发了一种有效地探索大型搜索空间的搜索方法。我们显示，我们的框架，称为CycleGANAS，不仅能够有效地找到高性能的architecture，并且成功地解决了数据不均衡问题，通过个体搜索每个翻译方向。据我们所知，这是NAS的首次成果，并照亮了NAS的更复杂结构的应用。
</details></li>
</ul>
<hr>
<h2 id="Detecting-As-Labeling-Rethinking-LiDAR-camera-Fusion-in-3D-Object-Detection"><a href="#Detecting-As-Labeling-Rethinking-LiDAR-camera-Fusion-in-3D-Object-Detection" class="headerlink" title="Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object Detection"></a>Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07152">http://arxiv.org/abs/2311.07152</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HuangJunJie2017/BEVDet">https://github.com/HuangJunJie2017/BEVDet</a></li>
<li>paper_authors: Junjie Huang, Yun Ye, Zhujin Liang, Yi Shan, Dalong Du</li>
<li>for: 本文旨在提出一种新的3D物体检测方法，以解决LiDAR-camera结合体系中的过拟合问题。</li>
<li>methods: 本文提出了一种基于’检测为标签’（Detecting As Labeling，DAL）的新方法，通过imitating数据注释过程，建立了一个简单的预测管道，并使用了最简单的训练方法来最小化依赖性和提高可移植性。</li>
<li>results: 对比 existed方法，提出的DAL方法在性能和可移植性两个方面具有明显的优势，可以作为未来研发和实际应用的理想基线。<details>
<summary>Abstract</summary>
3D object Detection with LiDAR-camera encounters overfitting in algorithm development which is derived from the violation of some fundamental rules. We refer to the data annotation in dataset construction for theory complementing and argue that the regression task prediction should not involve the feature from the camera branch. By following the cutting-edge perspective of 'Detecting As Labeling', we propose a novel paradigm dubbed DAL. With the most classical elementary algorithms, a simple predicting pipeline is constructed by imitating the data annotation process. Then we train it in the simplest way to minimize its dependency and strengthen its portability. Though simple in construction and training, the proposed DAL paradigm not only substantially pushes the performance boundary but also provides a superior trade-off between speed and accuracy among all existing methods. With comprehensive superiority, DAL is an ideal baseline for both future work development and practical deployment. The code has been released to facilitate future work on https://github.com/HuangJunJie2017/BEVDet.
</details>
<details>
<summary>摘要</summary>
三元 объек特检测遇到了过拟合问题在算法开发中，这是由数据注解在数据集建构中的违反基本规则所致。我们提出了一种新的思路，称为“检测为标注”（DAL）。我们采用了最经典的元素算法，构建了一个简单的预测管道，并通过模仿数据注解过程来训练。尽管简单构建和训练，但提议的 DAL 方法不仅可以显著提高性能boundary，还提供了速度和准确性之间的优秀平衡。在所有现有方法中，DAL 具有最高的全面优势，是未来研发和实践中的理想基eline。代码已经发布到了https://github.com/HuangJunJie2017/BEVDet，以便未来研究。
</details></li>
</ul>
<hr>
<h2 id="PadChannel-Improving-CNN-Performance-through-Explicit-Padding-Encoding"><a href="#PadChannel-Improving-CNN-Performance-through-Explicit-Padding-Encoding" class="headerlink" title="PadChannel: Improving CNN Performance through Explicit Padding Encoding"></a>PadChannel: Improving CNN Performance through Explicit Padding Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07623">http://arxiv.org/abs/2311.07623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aussieseaweed/pad-channel">https://github.com/aussieseaweed/pad-channel</a></li>
<li>paper_authors: Juho Kim</li>
<li>for: 提高 CNN 的表征EXTRACTION 精度，通过将paddingstatus编码为另一个输入通道，使 CNN 能够轻松地分辨真正的像素和padding区域。</li>
<li>methods: 提出了 PadChannel  padding 方法，该方法将 padding status 编码为另一个输入通道，以便 CNN 能够轻松地分辨真正的像素和padding区域。</li>
<li>results: 在 ImageNet-1K 图像分类任务上，通过 incorporating PadChannel  into several prominent CNN architectures，实现了小幅提升性能和明显减少了变差值，而且计算成本增加不多。<details>
<summary>Abstract</summary>
In convolutional neural networks (CNNs), padding plays a pivotal role in preserving spatial dimensions throughout the layers. Traditional padding techniques do not explicitly distinguish between the actual image content and the padded regions, potentially causing CNNs to incorrectly interpret the boundary pixels or regions that resemble boundaries. This ambiguity can lead to suboptimal feature extraction. To address this, we propose PadChannel, a novel padding method that encodes padding statuses as an additional input channel, enabling CNNs to easily distinguish genuine pixels from padded ones. By incorporating PadChannel into several prominent CNN architectures, we observed small performance improvements and notable reductions in the variances on the ImageNet-1K image classification task at marginal increases in the computational cost. The source code is available at https://github.com/AussieSeaweed/pad-channel
</details>
<details>
<summary>摘要</summary>
在卷积神经网络（CNN）中，填充扮演着保持空间维度的重要角色。传统的填充技术不能显式地区分实际图像内容和填充区域，可能导致CNN incorrectly interpretBoundary pixels或区域，从而导致优化特征提取的困难。为解决这个问题，我们提议PadChannel，一种新的填充方法，它将填充状态编码为一个额外输入通道，使CNN可以轻松地 отличи出真实的像素与填充区域。通过将PadChannel integrating into severaleminent CNN architectures, we observed small performance improvements and notable reductions in the variances on the ImageNet-1K image classification task at marginal increases in the computational cost.  Source code available at <https://github.com/AussieSeaweed/pad-channel>。
</details></li>
</ul>
<hr>
<h2 id="Attention-Challenging-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification"><a href="#Attention-Challenging-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification" class="headerlink" title="Attention-Challenging Multiple Instance Learning for Whole Slide Image Classification"></a>Attention-Challenging Multiple Instance Learning for Whole Slide Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07125">http://arxiv.org/abs/2311.07125</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dazhangyu123/acmil">https://github.com/dazhangyu123/acmil</a></li>
<li>paper_authors: Yunlong Zhang, Honglin Li, Yuxuan Sun, Sunyi Zheng, Chenglu Zhu, Lin Yang</li>
<li>for: 本研究旨在解决多个实例学习（MIL）方法在整个扫描图像（WSI）分析中遇到的过拟合问题。</li>
<li>methods: 本研究提出了一种名为 Attention-Challenging MIL（ACMIL）的方法，旨在让注意力机制能够捕捉更多的挑战性预测实例。ACMIL 使用了两种技术：多支分支注意力（MBA）和随机 Top-K 实例屏蔽（STKIM）。</li>
<li>results: 在三个 WSI 数据集上进行评估，ACMIL 表现出色，超过了现有方法。此外，通过热图视化、UMAP 视化和注意值统计，本研究详细展示了 ACMIL 在超越过拟合挑战的效果。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/dazhangyu123/ACMIL%7D">https://github.com/dazhangyu123/ACMIL}</a> 上获取。<details>
<summary>Abstract</summary>
Overfitting remains a significant challenge in the application of Multiple Instance Learning (MIL) methods for Whole Slide Image (WSI) analysis. Visualizing heatmaps reveals that current MIL methods focus on a subset of predictive instances, hindering effective model generalization. To tackle this, we propose Attention-Challenging MIL (ACMIL), aimed at forcing the attention mechanism to capture more challenging predictive instances. ACMIL incorporates two techniques, Multiple Branch Attention (MBA) to capture richer predictive instances and Stochastic Top-K Instance Masking (STKIM) to suppress simple predictive instances. Evaluation on three WSI datasets outperforms state-of-the-art methods. Additionally, through heatmap visualization, UMAP visualization, and attention value statistics, this paper comprehensively illustrates ACMIL's effectiveness in overcoming the overfitting challenge. The source code is available at \url{https://github.com/dazhangyu123/ACMIL}.
</details>
<details>
<summary>摘要</summary>
多个实例学习（MIL）方法在整个扫描图像（WSI）分析中仍然存在至关重要的挑战，即过拟合。使用热图可视化显示，当前MIL方法往往会围绕一部分预测实例集中心化，从而降低模型的泛化能力。为解决这个问题，我们提议了吸引挑战（ACMIL）方法，旨在让吸引机制捕捉更多的挑战预测实例。ACMIL方法包括多支分支吸引（MBA）和随机Top-K实例屏蔽（STKIM）两种技术，以捕捉更加丰富的预测实例和避免简单的预测实例。在三个WSI数据集上进行评估，ACMIL方法超越了现有方法。此外，通过热图可视化、UMAP可视化和吸引值统计，本文全面地展示了ACMIL方法在超越过拟合挑战的效果。ACMIL源代码可以在GitHub上获取，具体请参考\url{https://github.com/dazhangyu123/ACMIL}.
</details></li>
</ul>
<hr>
<h2 id="SpectralGPT-Spectral-Foundation-Model"><a href="#SpectralGPT-Spectral-Foundation-Model" class="headerlink" title="SpectralGPT: Spectral Foundation Model"></a>SpectralGPT: Spectral Foundation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07113">http://arxiv.org/abs/2311.07113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danfeng Hong, Bing Zhang, Xuyang Li, Yuxuan Li, Chenyu Li, Jing Yao, Naoto Yokoya, Hao Li, Xiuping Jia, Antonio Plaza, Gamba Paolo, Jon Atli Benediktsson, Jocelyn Chanussot</li>
<li>for: 这个研究旨在开发一个能够处理颜色spectral remote sensing（RS）影像的通用基础模型，以探索spectral RS 数据的应用前景。</li>
<li>methods: 本研究使用了一种名为SpectralGPT的新型3D生成预训练trasnformer（GPT），可以处理不同大小、分辨率、时间序列和区域的spectral RS 影像，并且可以进行预训练和进一步训练。</li>
<li>results: 根据我们的评估结果，预训练后的SpectralGPT模型具有超过6000万个参数，并且在四个下渠任务中（单&#x2F;多标Scene分类、semantic segmentation和变化检测）表现出了明显的性能提升。<details>
<summary>Abstract</summary>
The foundation model has recently garnered significant attention due to its potential to revolutionize the field of visual representation learning in a self-supervised manner. While most foundation models are tailored to effectively process RGB images for various visual tasks, there is a noticeable gap in research focused on spectral data, which offers valuable information for scene understanding, especially in remote sensing (RS) applications. To fill this gap, we created for the first time a universal RS foundation model, named SpectralGPT, which is purpose-built to handle spectral RS images using a novel 3D generative pretrained transformer (GPT). Compared to existing foundation models, SpectralGPT 1) accommodates input images with varying sizes, resolutions, time series, and regions in a progressive training fashion, enabling full utilization of extensive RS big data; 2) leverages 3D token generation for spatial-spectral coupling; 3) captures spectrally sequential patterns via multi-target reconstruction; 4) trains on one million spectral RS images, yielding models with over 600 million parameters. Our evaluation highlights significant performance improvements with pretrained SpectralGPT models, signifying substantial potential in advancing spectral RS big data applications within the field of geoscience across four downstream tasks: single/multi-label scene classification, semantic segmentation, and change detection.
</details>
<details>
<summary>摘要</summary>
底层模型最近受到了各种视觉学任务自动学习的潜在革命性的注意力。大多数底层模型都是针对RGB图像进行多种视觉任务的效果优化的。然而，在 spectral 数据方面，有一定的研究欠差，这些数据具有Scene 理解中的价值，尤其是在远程感知（RS）应用中。为了填补这个欠差，我们创造了首次的universal RS 底层模型，名为SpectralGPT，它使用了一种新的三维生成预训练变换器（GPT）来处理 spectral RS 图像。与现有的底层模型相比，SpectralGPT 具有以下优势：1. 可以处理不同大小、分辨率、时间序列和区域的输入图像，从而使用广泛的RS大数据进行全面利用。2. 通过三维token生成来实现空间-spectral的coupling。3. 通过多个目标重建来捕捉spectral序列的特征。4. 在一百万个spectral RS 图像上进行训练，实现了模型具有超过6亿个参数。我们的评估表明，使用预训练SpectralGPT模型可以获得显著的性能提升，这表明了这种方法在RS大数据应用中具有潜在的潜力。在四个下游任务中，预训练SpectralGPT模型都显示了显著的性能提升：单/多标Scene 分类、semantic segmentation和变化检测。
</details></li>
</ul>
<hr>
<h2 id="CLiF-VQA-Enhancing-Video-Quality-Assessment-by-Incorporating-High-Level-Semantic-Information-related-to-Human-Feelings"><a href="#CLiF-VQA-Enhancing-Video-Quality-Assessment-by-Incorporating-High-Level-Semantic-Information-related-to-Human-Feelings" class="headerlink" title="CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level Semantic Information related to Human Feelings"></a>CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level Semantic Information related to Human Feelings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07090">http://arxiv.org/abs/2311.07090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yachun Mi, Yu Li, Yan Shu, Chen Hui, Puchao Zhou, Shaohui Liu</li>
<li>For: 这篇论文主要关注视频质量评估 (VQA) 领域，旨在模拟人类视觉系统 (HVS) 对视频质量的评估。* Methods: 该论文提出了一种新的 VQA 方法，即 CLiF-VQA，它考虑了视频中人类情感的影响，同时也考虑了视频的空间特征。为了有效提取视频中人类情感的特征，该方法首次利用 CLIP 和人类情感的一致性进行研究。具体来说，该方法设计了多个对人类情感有关的目标和主观描述作为推荐。此外，该方法还提出了一种基于 CLIP 的 semantic feature extractor (SFE)，可以从视频帧中提取人类情感相关的特征。* Results: 该论文的实验结果表明，提出的 CLiF-VQA 方法在多个 VQA 数据集上表现出色。<details>
<summary>Abstract</summary>
Video Quality Assessment (VQA) aims to simulate the process of perceiving video quality by the human visual system (HVS). The judgments made by HVS are always influenced by human subjective feelings. However, most of the current VQA research focuses on capturing various distortions in the spatial and temporal domains of videos, while ignoring the impact of human feelings. In this paper, we propose CLiF-VQA, which considers both features related to human feelings and spatial features of videos. In order to effectively extract features related to human feelings from videos, we explore the consistency between CLIP and human feelings in video perception for the first time. Specifically, we design multiple objective and subjective descriptions closely related to human feelings as prompts. Further we propose a novel CLIP-based semantic feature extractor (SFE) which extracts features related to human feelings by sliding over multiple regions of the video frame. In addition, we further capture the low-level-aware features of the video through a spatial feature extraction module. The two different features are then aggregated thereby obtaining the quality score of the video. Extensive experiments show that the proposed CLiF-VQA exhibits excellent performance on several VQA datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GazeForensics-DeepFake-Detection-via-Gaze-guided-Spatial-Inconsistency-Learning"><a href="#GazeForensics-DeepFake-Detection-via-Gaze-guided-Spatial-Inconsistency-Learning" class="headerlink" title="GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency Learning"></a>GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07075">http://arxiv.org/abs/2311.07075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinlin He, Chunlei Peng, Dechuang Liu, Nannan Wang, Xinbo Gao</li>
<li>for: 这个研究旨在提高深伪检测的精度，以保护人们的隐私和公共安全。</li>
<li>methods: 本研究使用了3D双眼视线估计模型来取得视线表现，并与通用特征结合使用，以增强深伪检测模型的表现。</li>
<li>results: 实验结果显示，提案的GazeForensics方法可以超过目前的州OF-THE-ART方法。<details>
<summary>Abstract</summary>
DeepFake detection is pivotal in personal privacy and public safety. With the iterative advancement of DeepFake techniques, high-quality forged videos and images are becoming increasingly deceptive. Prior research has seen numerous attempts by scholars to incorporate biometric features into the field of DeepFake detection. However, traditional biometric-based approaches tend to segregate biometric features from general ones and freeze the biometric feature extractor. These approaches resulted in the exclusion of valuable general features, potentially leading to a performance decline and, consequently, a failure to fully exploit the potential of biometric information in assisting DeepFake detection. Moreover, insufficient attention has been dedicated to scrutinizing gaze authenticity within the realm of DeepFake detection in recent years. In this paper, we introduce GazeForensics, an innovative DeepFake detection method that utilizes gaze representation obtained from a 3D gaze estimation model to regularize the corresponding representation within our DeepFake detection model, while concurrently integrating general features to further enhance the performance of our model. Experiment results reveal that our proposed GazeForensics outperforms the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
深度假像检测对个人隐私和公共安全具有核心作用。随着深度假像技术的不断提高，高质量的假造视频和图像变得越来越欺骗性。先前的研究中，学者们已经尝试将生物特征 incorporated 到深度假像检测领域中。然而，传统的生物特征基于的方法通常将生物特征与通用特征分离开来，这会导致排除有价值的通用特征，从而导致性能下降，最终无法完全利用生物信息的潜在优势。此外，近年来对 DeepFake 检测中的视线真实性的研究并未受到足够的关注。本文提出了一种名为 GazeForensics 的创新的 DeepFake 检测方法，该方法使用来自 3D 视线估计模型获得的视线表示来补做对应的表示在我们的 DeepFake 检测模型中，同时并入通用特征以进一步提高我们的模型的性能。实验结果表明，我们的提议的 GazeForensics 方法在当前状态的方法中具有优异的性能。
</details></li>
</ul>
<hr>
<h2 id="L-0-Sampler-An-L-0-Model-Guided-Volume-Sampling-for-NeRF"><a href="#L-0-Sampler-An-L-0-Model-Guided-Volume-Sampling-for-NeRF" class="headerlink" title="$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF"></a>$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07044">http://arxiv.org/abs/2311.07044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangchen Li, Juyong Zhang<br>for:This paper aims to improve the Neural Radiance Fields (NeRF) method by proposing a new sampling strategy called $L_0$-Sampler.methods:The $L_0$-Sampler incorporates the $L_0$ model into the weight function $w(t)$ to guide the sampling process, using piecewise exponential functions for interpolation.results:The proposed $L_0$-Sampler can achieve stable performance improvements in NeRF and related tasks like 3D reconstruction, with the advantage of being easily implemented with few lines of code.Here is the text in Simplified Chinese:for:这篇论文目标是改进Neural Radiance Fields（NeRF）方法，提出一种新的采样策略 called $L_0$-Sampler。methods:$L_0$-Sampler将$L_0$模型integrated into weight函数$w(t)$中，使用piecewise exponential函数进行插值。results:提议的$L_0$-Sampler可以在NeRF和相关任务如3D重建中实现稳定性提升，同时易于实现，只需几行代码。<details>
<summary>Abstract</summary>
Since being proposed, Neural Radiance Fields (NeRF) have achieved great success in related tasks, mainly adopting the hierarchical volume sampling (HVS) strategy for volume rendering. However, the HVS of NeRF approximates distributions using piecewise constant functions, which provides a relatively rough estimation. Based on the observation that a well-trained weight function $w(t)$ and the $L_0$ distance between points and the surface have very high similarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into $w(t)$ to guide the sampling process. Specifically, we propose to use piecewise exponential functions rather than piecewise constant functions for interpolation, which can not only approximate quasi-$L_0$ weight distributions along rays quite well but also can be easily implemented with few lines of code without additional computational burden. Stable performance improvements can be achieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D reconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/ .
</details>
<details>
<summary>摘要</summary>
Since being proposed, Neural Radiance Fields (NeRF) have achieved great success in related tasks, mainly adopting the hierarchical volume sampling (HVS) strategy for volume rendering. However, the HVS of NeRF approximates distributions using piecewise constant functions, which provides a relatively rough estimation. Based on the observation that a well-trained weight function $w(t)$ and the $L_0$ distance between points and the surface have very high similarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into $w(t)$ to guide the sampling process. Specifically, we propose to use piecewise exponential functions rather than piecewise constant functions for interpolation, which can not only approximate quasi-$L_0$ weight distributions along rays quite well but also can be easily implemented with few lines of code without additional computational burden. Stable performance improvements can be achieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D reconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/.Here's the word-for-word translation of the text into Simplified Chinese: desde que se propuso, Neural Radiance Fields (NeRF) han tenido gran éxito en tareas relacionadas, principalmente adoptando la estrategia de muestreo de volumen jerárquico (HVS) para la renderización de volumenes. Sin embargo, el HVS de NeRF aproxima distribuciones utilizando funciones constantes piecewise, lo que proporciona una estimación relativamente rough. Basándonos en la observación de que una función de peso bien entrenada $w(t)$ y la distancia $L_0$ entre puntos y la superficie tienen una alta similitud, propodemos $L_0$-Sampler al incorporar el modelo $L_0$ en $w(t)$ para guiar el proceso de muestreo. Específicamente, propodemos utilizar funciones exponenciales piecewise en lugar de funciones constantes piecewise para la interpolación, lo que puede no solo aproximar distribucciones de peso quasi-$L_0$ en rayas muy bien but also puede ser fácilmente implementado con pocas líneas de código sin un carga adicional computacional. Se pueden lograr mejores mejoras estables en el rendimiento al aplicar $L_0$-Sampler a NeRF y tareas relacionadas como la reconstrucción 3D. El código está disponible en https://ustc3dv.github.io/L0-Sampler/.
</details></li>
</ul>
<hr>
<h2 id="Open-Vocabulary-Video-Anomaly-Detection"><a href="#Open-Vocabulary-Video-Anomaly-Detection" class="headerlink" title="Open-Vocabulary Video Anomaly Detection"></a>Open-Vocabulary Video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07042">http://arxiv.org/abs/2311.07042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wu, Xuerong Zhou, Guansong Pang, Yujia Sun, Jing Liu, Peng Wang, Yanning Zhang</li>
<li>for: 这 paper 旨在解决开放 vocabulary video anomaly detection (OVVAD) 问题，即通过预训练大型模型来检测和分类已知和未知异常。</li>
<li>methods: 该 paper 提出了一种分解 OVVAD 任务为两个互补任务 – 类型不敏感检测和类型特定分类 – 并同时优化两个任务。具体来说，该 paper 提出了一种 semantic knowledge injection module，用于将大型语言模型中的 semantic knowledge 引入检测任务中，以及一种 anomaly synthesis module，用于通过大型视觉生成模型生成 pseudo 未知异常视频，以便分类任务中更好地检测和分类各种 seen 和 unseen 异常。</li>
<li>results: 该 paper 的实验结果表明，其模型在 OVVAD 任务中取得了状态公平的表现，比如在 three  widely-used benchmark 上的 experiment 中。<details>
<summary>Abstract</summary>
Video anomaly detection (VAD) with weak supervision has achieved remarkable performance in utilizing video-level labels to discriminate whether a video frame is normal or abnormal. However, current approaches are inherently limited to a closed-set setting and may struggle in open-world applications where there can be anomaly categories in the test data unseen during training. A few recent studies attempt to tackle a more realistic setting, open-set VAD, which aims to detect unseen anomalies given seen anomalies and normal videos. However, such a setting focuses on predicting frame anomaly scores, having no ability to recognize the specific categories of anomalies, despite the fact that this ability is essential for building more informed video surveillance systems. This paper takes a step further and explores open-vocabulary video anomaly detection (OVVAD), in which we aim to leverage pre-trained large models to detect and categorize seen and unseen anomalies. To this end, we propose a model that decouples OVVAD into two mutually complementary tasks -- class-agnostic detection and class-specific classification -- and jointly optimizes both tasks. Particularly, we devise a semantic knowledge injection module to introduce semantic knowledge from large language models for the detection task, and design a novel anomaly synthesis module to generate pseudo unseen anomaly videos with the help of large vision generation models for the classification task. These semantic knowledge and synthesis anomalies substantially extend our model's capability in detecting and categorizing a variety of seen and unseen anomalies. Extensive experiments on three widely-used benchmarks demonstrate our model achieves state-of-the-art performance on OVVAD task.
</details>
<details>
<summary>摘要</summary>
视频异常检测（VAD）通过弱监督得到了非常出色的表现，可以使用视频帧级别的标签来判断视频帧是否正常。然而，现有的方法受限于关闭集成环境，可能在开放世界应用中遇到未知的异常类型。一些最近的研究尝试解决更加现实的设定，开放集成VAD，以便在测试数据中未经训练的异常类型上检测异常。然而，这种设定仅仅是预测帧异常分数，无法识别特定的异常类型，尽管这种能力是建立更加知ledge的视频监测系统的关键。本文尝试一步更进一步，探索开放词汇视频异常检测（OVVAD），我们希望通过利用预训练大型模型来检测和分类已知和未知异常。为此，我们提议一个模型，将OVVAD分解成两个互补性任务：无关类型检测和类型特定分类，并同时优化两个任务。特别是，我们设计了一个语义知识注入模块，将语义知识从大型语言模型引入检测任务，并设计了一个异常生成模块，通过大视力生成模型生成 Pseudo 未知异常视频。这些语义知识和生成异常substantially 提高了我们模型的异常检测和分类能力。广泛的实验表明，我们的模型在OVVAD任务中具有状态级别的表现。
</details></li>
</ul>
<hr>
<h2 id="Pretrain-like-Your-Inference-Masked-Tuning-Improves-Zero-Shot-Composed-Image-Retrieval"><a href="#Pretrain-like-Your-Inference-Masked-Tuning-Improves-Zero-Shot-Composed-Image-Retrieval" class="headerlink" title="Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed Image Retrieval"></a>Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07622">http://arxiv.org/abs/2311.07622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Chen, Hanjiang Lai</li>
<li>for:  This paper focuses on zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target image based on textual modifications to a reference image without triplet labeling.</li>
<li>methods: The paper introduces a novel unlabeled and pre-trained masked tuning approach to reduce the gap between the pre-trained model and the downstream CIR task. The approach uses the text and the masked image to learn the modifications of the original image.</li>
<li>results: The approach significantly outperforms the baseline models on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.<details>
<summary>Abstract</summary>
Zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target image based on textual modifications to a reference image without triplet labeling, has gained more and more attention. Current ZS-CIR research mainly relies on two unlabeled pre-trained models: the vision-language model, e.g., CLIP, and the Pic2Word/textual inversion model. However, the pre-trained models and CIR tasks have substantial discrepancies, where the pre-trained models learn the similarities between vision and language but CIR aims to learn the modifications of the image guided by text. In this paper, we introduce a novel unlabeled and pre-trained masked tuning approach to reduce the gap between the pre-trained model and the downstream CIR task. We first reformulate the pre-trained vision-language contrastive learning as the CIR task, where we randomly mask input image patches to generate $\langle$masked image, text, image$\rangle$ triple from an image-text pair. Then, we propose a masked tuning, which uses the text and the masked image to learn the modifications of the original image. With such a simple design, it can learn to capture fine-grained text-guided modifications. Extensive experimental results demonstrate the significant superiority of our approach over the baseline models on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.
</details>
<details>
<summary>摘要</summary>
Zero-shot组合图像检索（ZS-CIR），旨在基于文本修改参照图像而不需要三元标注，已经吸引了更多的关注。当前ZS-CIR研究主要基于两个无标注预训练模型：视觉语言模型，例如CLIP，以及Pic2Word/文本反转模型。然而，预训练模型和CIR任务之间存在substantial差异，预训练模型学习视觉和语言之间的相似性，而CIR任务则是学习文本指导图像的修改。在这篇论文中，我们介绍了一种新的无标注预训练掩模型调整方法，以减少预训练模型和下游CIR任务之间的差异。我们首先将预训练视觉语言对比学习重新формализова为CIR任务，将输入图像块随机掩蔽，生成$\langle$掩模图像、文本、原始图像$\rangle$三元组。然后，我们提议一种掩模调整，使用文本和掩模图像来学习原始图像的修改。这种简单的设计可以学习到细致的文本指导修改。我们对三个ZS-CIR数据集进行了广泛的实验，结果表明我们的方法在baseline模型上显著超越。
</details></li>
</ul>
<hr>
<h2 id="TTMFN-Two-stream-Transformer-based-Multimodal-Fusion-Network-for-Survival-Prediction"><a href="#TTMFN-Two-stream-Transformer-based-Multimodal-Fusion-Network-for-Survival-Prediction" class="headerlink" title="TTMFN: Two-stream Transformer-based Multimodal Fusion Network for Survival Prediction"></a>TTMFN: Two-stream Transformer-based Multimodal Fusion Network for Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07033">http://arxiv.org/abs/2311.07033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiquan Ge, Xiangyang Hu, Rungen Huang, Gangyong Jia, Yaqi Wang, Renshu Gu, Changmiao Wang, Elazab Ahmed, Linyan Wang, Juan Ye, Ye Li</li>
<li>for: 预测癌症患者生存时间的研究</li>
<li>methods: 提议一种基于深度学习的两树式多modal合并网络（TTMFN），将生物 PATHOLOGICAL 图像和基因表达数据融合以提高预测性能</li>
<li>results: TTMFN 在四个来自 The Cancer Genome Atlas 的数据集上实现了最佳或与状态艺术方法相当的预测结果，提高了患者生存时间的预测精度<details>
<summary>Abstract</summary>
Survival prediction plays a crucial role in assisting clinicians with the development of cancer treatment protocols. Recent evidence shows that multimodal data can help in the diagnosis of cancer disease and improve survival prediction. Currently, deep learning-based approaches have experienced increasing success in survival prediction by integrating pathological images and gene expression data. However, most existing approaches overlook the intra-modality latent information and the complex inter-modality correlations. Furthermore, existing modalities do not fully exploit the immense representational capabilities of neural networks for feature aggregation and disregard the importance of relationships between features. Therefore, it is highly recommended to address these issues in order to enhance the prediction performance by proposing a novel deep learning-based method. We propose a novel framework named Two-stream Transformer-based Multimodal Fusion Network for survival prediction (TTMFN), which integrates pathological images and gene expression data. In TTMFN, we present a two-stream multimodal co-attention transformer module to take full advantage of the complex relationships between different modalities and the potential connections within the modalities. Additionally, we develop a multi-head attention pooling approach to effectively aggregate the feature representations of the two modalities. The experiment results on four datasets from The Cancer Genome Atlas demonstrate that TTMFN can achieve the best performance or competitive results compared to the state-of-the-art methods in predicting the overall survival of patients.
</details>
<details>
<summary>摘要</summary>
生存预测在医学家开发癌症治疗协议中发挥关键作用。现有证据表明，多modal数据可以帮助诊断癌症疾病并提高生存预测。目前，深度学习基于的方法在生存预测中经历了增长的成功，通过将 PATHOLOGICAL IMAGES 和基因表达数据集成起来。然而，大多数现有方法忽视INTRA-MODALITY LATENT INFORMATION和复杂的交叉modalities关系。此外，现有的modalities不完全利用神经网络的庞大表达能力进行特征聚合，也忽视了特征之间的关系。因此，以提高预测性能的目的，我们建议提出一种新的深度学习基于的方法。我们提出了一种名为 Two-stream Transformer-based Multimodal Fusion Network 的新框架（TTMFN），它将 PATHOLOGICAL IMAGES 和基因表达数据集成起来。在 TTMFN 中，我们提出了一种两树多模态协作变换模块，以便充分利用不同modalities之间的复杂关系和可能的连接。此外，我们开发了一种多头注意池化方法，以有效地聚合 PATHOLOGICAL IMAGES 和基因表达数据的特征表示。实验结果表明，在 The Cancer Genome Atlas 上的四个数据集上，TTMFN 可以获得最佳性能或与当前状态艺术方法竞争。
</details></li>
</ul>
<hr>
<h2 id="PICS-in-Pics-Physics-Informed-Contour-Selection-for-Rapid-Image-Segmentation"><a href="#PICS-in-Pics-Physics-Informed-Contour-Selection-for-Rapid-Image-Segmentation" class="headerlink" title="PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation"></a>PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07002">http://arxiv.org/abs/2311.07002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vikas Dwivedi, Balaji Srinivasan, Ganapathy Krishnamurthi</li>
<li>for: 这篇论文的目的是提出一个可读性好的深度图像分类模型训练方法，并且不需要大量、高品质的标注数据。</li>
<li>methods: 这篇论文使用了Physics Informed Contour Selection（PICS）算法，它是一种可解释的、以物理为指导的图像分类算法，它结合了Physics-Informed Neural Networks（PINNs）和活动曲线模型（snake）。PICS使用了立方spline代替深度神经网络，因此它很快速和计算轻量级。</li>
<li>results: 这篇论文透过实验显示PICS可以快速和高效地完成3D图像分类，并且可以借由转移学习来加速分类。PICS还引入了一个新的凸形积分项，以增强分类质量。总的来说，PICS具有许多新的特点，例如网络架构、转移学习和物理灵感损失，因此显示了可循环和可进一步改进的潜力。<details>
<summary>Abstract</summary>
Effective training of deep image segmentation models is challenging due to the need for abundant, high-quality annotations. Generating annotations is laborious and time-consuming for human experts, especially in medical image segmentation. To facilitate image annotation, we introduce Physics Informed Contour Selection (PICS) - an interpretable, physics-informed algorithm for rapid image segmentation without relying on labeled data. PICS draws inspiration from physics-informed neural networks (PINNs) and an active contour model called snake. It is fast and computationally lightweight because it employs cubic splines instead of a deep neural network as a basis function. Its training parameters are physically interpretable because they directly represent control knots of the segmentation curve. Traditional snakes involve minimization of the edge-based loss functionals by deriving the Euler-Lagrange equation followed by its numerical solution. However, PICS directly minimizes the loss functional, bypassing the Euler Lagrange equations. It is the first snake variant to minimize a region-based loss function instead of traditional edge-based loss functions. PICS uniquely models the three-dimensional (3D) segmentation process with an unsteady partial differential equation (PDE), which allows accelerated segmentation via transfer learning. To demonstrate its effectiveness, we apply PICS for 3D segmentation of the left ventricle on a publicly available cardiac dataset. While doing so, we also introduce a new convexity-preserving loss term that encodes the shape information of the left ventricle to enhance PICS's segmentation quality. Overall, PICS presents several novelties in network architecture, transfer learning, and physics-inspired losses for image segmentation, thereby showing promising outcomes and potential for further refinement.
</details>
<details>
<summary>摘要</summary>
实现深度图像分类模型的训练非常困难，因为需要充足的、高品质的标注。生成标注是人工专家很传统和时间耗费的，特别是医疗图像分类。为了促进图像标注，我们提出了物理决定曲线选择（PICS）：一种可读性的、物理决定的算法，不需要标注数据。PICS受到物理决定神经网络（PINNs）和活动曲线模型（snake）的启发，它快速且轻量级的，因为它使用立方体spline而不是深度神经网络作为基础函数。它的训练参数是物理可解的，因为它们直接表示分类曲线的控制点。传统的蛇涉及到透过监督学习减少边界基于损失函数的最小化，但PICS直接对数据进行损失函数的最小化，不需要监督学习。PICS是首个将区域基于损失函数最小化，而不是传统的边界基于损失函数最小化。PICS具有实现三维（3D）分类过程的不稳定偏微分方程（PDE），可以通过转移学习加速分类。为了证明其效果，我们将PICS应用于公开可用的心脏组织数据集上3D左心脏分类。同时，我们也引入了一个新的凸形积分函数，以增强PICS的分类质量。总之，PICS具有训练网络架构、转移学习和物理决定损失函数等多个新特点，这些特点使得PICS在图像分类方面显示出了可塑性和潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/13/cs.CV_2023_11_13/" data-id="clpztdnjk00n6es88415ofetu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
