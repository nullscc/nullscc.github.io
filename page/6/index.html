
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/6/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.LG_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.LG_2023_08_17/" class="article-date">
  <time datetime="2023-08-16T16:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.LG_2023_08_17/">cs.LG - 2023-08-17 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization"><a href="#Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization" class="headerlink" title="Enhancing API Documentation through BERTopic Modeling and Summarization"></a>Enhancing API Documentation through BERTopic Modeling and Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09070">http://arxiv.org/abs/2308.09070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scam2023-bert/bertopic">https://github.com/scam2023-bert/bertopic</a></li>
<li>paper_authors: AmirHossein Naghshzan, Sylvie Ratte</li>
<li>for: 本研究旨在提高API文档的可读性和效率，以便开发者更方便地从官方文档中提取有用信息。</li>
<li>methods: 本研究使用BERTopic进行主题分析，并采用自然语言处理（NLP）技术生成API文档的摘要。</li>
<li>results: 研究发现了各种常见主题和问题，并生成了可能的解决方案，从而提高了开发者对复杂API的理解和 Navigation 效率。<details>
<summary>Abstract</summary>
As the amount of textual data in various fields, including software development, continues to grow, there is a pressing demand for efficient and effective extraction and presentation of meaningful insights. This paper presents a unique approach to address this need, focusing on the complexities of interpreting Application Programming Interface (API) documentation. While official API documentation serves as a primary source of information for developers, it can often be extensive and lacks user-friendliness. In light of this, developers frequently resort to unofficial sources like Stack Overflow and GitHub. Our novel approach employs the strengths of BERTopic for topic modeling and Natural Language Processing (NLP) to automatically generate summaries of API documentation, thereby creating a more efficient method for developers to extract the information they need. The produced summaries and topics are evaluated based on their performance, coherence, and interoperability.   The findings of this research contribute to the field of API documentation analysis by providing insights into recurring topics, identifying common issues, and generating potential solutions. By improving the accessibility and efficiency of API documentation comprehension, our work aims to enhance the software development process and empower developers with practical tools for navigating complex APIs.
</details>
<details>
<summary>摘要</summary>
随着不同领域的文本数据量不断增加，包括软件开发，有效和高效地提取和展示有用的洞察结论成为了一项急需。这篇论文提出了一种独特的方法，专注于API文档解释的复杂性。尽管官方API文档作为开发者的主要信息来源，但它们可能是广泛的和不易于使用的。为此，开发者经常查阅Stack Overflow和GitHub等非官方来源。我们的新方法利用BERTopic的话题模型和自然语言处理（NLP）技术，自动生成API文档摘要，从而为开发者提供更高效的信息提取方式。生成的摘要和话题被评估基于其性能、一致性和可操作性。我们的研究成果对API文档分析领域进行了贡献，提供了循环话题、常见问题的指导和解决方案。我们的工作目标是通过改善API文档理解的可 accessed性和效率，推动软件开发过程和开发者在复杂API中导航的实用工具。
</details></li>
</ul>
<hr>
<h2 id="Uplift-Modeling-from-Causal-Inference-to-Personalization"><a href="#Uplift-Modeling-from-Causal-Inference-to-Personalization" class="headerlink" title="Uplift Modeling: from Causal Inference to Personalization"></a>Uplift Modeling: from Causal Inference to Personalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09066">http://arxiv.org/abs/2308.09066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe Moraes, Hugo Manuel Proença, Anastasiia Kornilova, Javier Albert, Dmitri Goldenberg</li>
<li>For: The paper is written for individuals who want to learn about uplift modeling and its applications in personalized promotional campaigns.* Methods: The paper introduces state-of-the-art techniques in uplift modeling, including the advantages and limitations of different approaches. It also covers the unique setup of constrained uplift modeling.* Results: The paper presents real-life applications of uplift modeling and discusses challenges in implementing these models in production.Here’s the same information in Simplified Chinese text:* For: 论文主要是为了探讨个性化促销活动中的营销效果估计和个性化推荐。* Methods: 论文介绍了当前最新的营销效果估计技术，包括不同方法的优点和缺点，以及受限制的营销效果估计。* Results: 论文介绍了实际应用的营销效果估计案例，以及实现这些模型的挑战。<details>
<summary>Abstract</summary>
Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.
</details>
<details>
<summary>摘要</summary>
“ upplift 模型是一种集成机器学习技术，用于估计干预效应的个体或 subgroup 水平。过去几年， causality 和 upplift 模型在在线电商平台上Personalization中变得越来越普遍，以便为每个用户选择最佳治疗，以最大化目标业务指标。upplift 模型在个性化促销活动中 particualrly 有用，因为促销的潜在利益需要与潜在成本进行平衡。在这个教程中，我们将覆盖 causality 的基本概念，并介绍现代 uplift 模型的技术。我们将讨论不同方法的优势和局限性，并深入探讨受限 uplift 模型的特殊设置。最后，我们将介绍实际应用和在生产中实施这些模型的挑战。”
</details></li>
</ul>
<hr>
<h2 id="Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression"><a href="#Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression" class="headerlink" title="Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression"></a>Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09065">http://arxiv.org/abs/2308.09065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanlong Yu, Gianni Franchi, Jindong Gu, Emanuel Aldea</li>
<li>for: 这个论文主要是为了提供更加 Robust uncertainty quantification 方法，以便在实际应用中部署深度神经网络 (DNNs)。</li>
<li>methods: 这个方法使用了一个称为 Auxiliary Uncertainty Estimator (AuxUE) 的方法，并且考虑了不同的分布假设来估计随机误差，最终选择了 Laplace 分布估计预测误差。此外，这个方法还提出了一个名为 Discretization-Induced Dirichlet pOsterior (DIDO) 的新解决方案，用于模型预测误差的 Dirichlet  posterior。</li>
<li>results: 实验结果显示，这个方法可以在噪音输入下提供更加Robust的 uncertainty estimates，并且可以扩展到 both image-level 和 pixel-wise 任务上。<details>
<summary>Abstract</summary>
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks."中文翻译：uncertainty quantification是深度神经网络（DNN）在实际应用中的关键。auxiliary uncertainty estimator（AuxUE）是修改主任务模型的最有效的方法来估计主任务预测结果的uncertainty。为了被视为可靠，AuxUE必须能够保持其性能并在面对Out-of-Distribution（OOD）输入时触发更高的uncertainty。然而，目前的AuxUE设计主要用于aleatoric uncertainty estimate，而AuxUE的Robustness尚未被探索。在这项工作中，我们提出了一种通用的AuxUE方案，用于更加Robust的uncertainty量化。 Specifically，为了实现更加Robust的aleatoric uncertainty estimate，我们考虑了不同的分布假设，并最终选择了Laplace分布来近似预测错误。 For epistemic uncertainty，我们提出了一种新的解决方案，名为Discretization-Induced Dirichlet Posterior（DIDO），它模型了预测错误的Discretized posterior。经验表明，我们的提议方法可以在噪声输入下提供Robust的uncertainty估计，并且可以扩展到像素级和图像级任务。>>
</details></li>
</ul>
<hr>
<h2 id="Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods"><a href="#Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods" class="headerlink" title="Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods"></a>Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09051">http://arxiv.org/abs/2308.09051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paavo Alku, Sudarsana Reddy Kadiri, Dhananjaya Gowda</li>
<li>for: 这个研究是 investigate 形式追踪的，使用现有的数据驱动追踪器DeepFormants的形式被改进，使用LP-based方法来估算形式。</li>
<li>methods: 这个研究使用了LP-COV和QCP-FB两种LP-based方法来估算形式，并将这些估算结果与数据驱动DeepFormants tracker的预测结果进行比较。</li>
<li>results: 研究结果表明，使用QCP-FB方法来改进DeepFormants tracker的表现最佳，并且这种改进的追踪器在受到雑音损害的情况下表现更好。<details>
<summary>Abstract</summary>
In this study, formant tracking is investigated by refining the formants tracked by an existing data-driven tracker, DeepFormants, using the formants estimated in a model-driven manner by linear prediction (LP)-based methods. As LP-based formant estimation methods, conventional covariance analysis (LP-COV) and the recently proposed quasi-closed phase forward-backward (QCP-FB) analysis are used. In the proposed refinement approach, the contours of the three lowest formants are first predicted by the data-driven DeepFormants tracker, and the predicted formants are replaced frame-wise with local spectral peaks shown by the model-driven LP-based methods. The refinement procedure can be plugged into the DeepFormants tracker with no need for any new data learning. Two refined DeepFormants trackers were compared with the original DeepFormants and with five known traditional trackers using the popular vocal tract resonance (VTR) corpus. The results indicated that the data-driven DeepFormants trackers outperformed the conventional trackers and that the best performance was obtained by refining the formants predicted by DeepFormants using QCP-FB analysis. In addition, by tracking formants using VTR speech that was corrupted by additive noise, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers. In general, these results suggest that LP-based model-driven approaches, which have traditionally been used in formant estimation, can be combined with a modern data-driven tracker easily with no further training to improve the tracker's performance.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了形式追踪的可行性，通过改进现有的数据驱动追踪器DeepFormants的形式追踪结果，使用模型驱动的方法来估算形式。作为模型驱动的形式估算方法，我们使用了传统的covariance分析(LP-COV)和最近提出的 quasi-closed phase forward-backward(QCP-FB)分析。在我们提议的改进方法中，首先使用DeepFormants tracker来预测三个最低的形式，然后将预测的形式替换为每帧的本地 спектраль峰点，这些峰点是由模型驱动的LP-based方法估算出来的。这个改进过程可以轻松地插入到DeepFormants tracker中，无需进行任何新的数据学习。我们 compare了两个改进后的DeepFormants tracker与原始DeepFormants tracker和五个已知的传统追踪器，结果表明，数据驱动的DeepFormants tracker比传统追踪器高效，而使用QCP-FB分析进行改进后的追踪器表现最佳。此外，通过使用受损的VTR语音追踪，研究发现，改进后的DeepFormants tracker对噪声抗性更高于参照追踪器。总的来说，这些结果表明，LP-based模型驱动的方法可以轻松地与现有的数据驱动追踪器结合使用，无需进行任何新的数据学习，以提高追踪器的性能。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing"><a href="#Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing" class="headerlink" title="Kernel-Based Tests for Likelihood-Free Hypothesis Testing"></a>Kernel-Based Tests for Likelihood-Free Hypothesis Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09043">http://arxiv.org/abs/2308.09043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrik Róbert Gerber, Tianze Jiang, Yury Polyanskiy, Rui Sun</li>
<li>For: The paper is focused on the problem of labeling additional inputs when only a portion of the data is labeled, specifically in the context of likelihood-free inference.* Methods: The paper introduces a generalization of the problem where unlabeled samples come from a mixture of the two classes, and studies the minimax sample complexity for non-parametric classes of densities under maximum mean discrepancy (MMD) separation.* Results: The paper investigates the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images, and confirms the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.Here’s the Chinese translation of the three points:* For: 这篇论文关注的是只有部分数据标注的情况下，进行likelihood-free推断的标注问题。* Methods: 论文引入了一种扩展，即未标注样本来自两个类的混合，并研究非 Parametric 类型的density下的最小最大值复杂性。* Results: 论文 investigate了使用神经网络参数化的kernel在两个任务上的实际性能：探测希格斯粒子和探测DDPM生成的图像 amidst CIFAR-10图像，并证实了理论上预测的 $m$ vs $n$ 负面trade-off。<details>
<summary>Abstract</summary>
Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax sample complexity for non-parametric classes of densities under \textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.
</details>
<details>
<summary>摘要</summary>
In this work, we:(a) Introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice.(b) Study the minimax sample complexity for non-parametric classes of densities under maximum mean discrepancy (MMD) separation.(c) Investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems, we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.
</details></li>
</ul>
<hr>
<h2 id="LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation"><a href="#LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation" class="headerlink" title="LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation"></a>LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09026">http://arxiv.org/abs/2308.09026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a></li>
<li>paper_authors: Berke Doga Basaran, Weitong Zhang, Mengyun Qiao, Bernhard Kainz, Paul M. Matthews, Wenjia Bai</li>
<li>for: 提高深度学习基于医学影像分割方法的精度和稳定性，通过对医学影像进行数据增强。</li>
<li>methods: LesionMix是一种新的、简单的疾病意识数据增强方法，通过在肿瘤水平进行数据增强，提高了肿瘤形态、位置、强度和负荷分布的多样性，同时允许肿瘤填充和缺失。</li>
<li>results: 在不同的Modalities和不同的肿瘤数据集上，LesionMix实现了优秀的肿瘤图像分割性能，比较新的 Mix-based 数据增强方法更好。代码将于<a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a> 发布。<details>
<summary>Abstract</summary>
Data augmentation has become a de facto component of deep learning-based medical image segmentation methods. Most data augmentation techniques used in medical imaging focus on spatial and intensity transformations to improve the diversity of training images. They are often designed at the image level, augmenting the full image, and do not pay attention to specific abnormalities within the image. Here, we present LesionMix, a novel and simple lesion-aware data augmentation method. It performs augmentation at the lesion level, increasing the diversity of lesion shape, location, intensity and load distribution, and allowing both lesion populating and inpainting. Experiments on different modalities and different lesion datasets, including four brain MR lesion datasets and one liver CT lesion dataset, demonstrate that LesionMix achieves promising performance in lesion image segmentation, outperforming several recent Mix-based data augmentation methods. The code will be released at https://github.com/dogabasaran/lesionmix.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>深度学习基于医学影像分割方法中的数据扩充已成为一种标准组成部分。大多数医学影像扩充技术都是在空间和强度水平进行变换，以提高训练图像的多样性。它们通常是在图像层次上进行设计，对全图像进行扩充，而不是关注特定的病变内部。在这里，我们介绍了LesionMix，一种新的和简单的病变意识数据扩充方法。它在病变层次上进行扩充，提高病变形状、位置、强度和负荷分布，并允许病变填充和抹除。在不同的modalities和不同的病变数据集上，包括四个脑MR病变数据集和一个肝CT病变数据集，LesionMix在病变图像分割中实现了可观的表现，比较出色于一些最近的混合数据扩充方法。代码将在https://github.com/dogabasaran/lesionmix上发布。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming"><a href="#Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming" class="headerlink" title="Reinforcement Learning for Battery Management in Dairy Farming"></a>Reinforcement Learning for Battery Management in Dairy Farming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09023">http://arxiv.org/abs/2308.09023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nawazish Ali, Abdul Wahid, Rachael shaw, Karl Mason</li>
<li>for: 这项研究是为了应对牛奶农业中的能源消耗异常高的问题，通过人工智能技术来优化电池充放和充电管理策略，以提高牛奶农业中的能源效率和可持续性。</li>
<li>methods: 该研究使用Q学习算法来学习一个有效的电池充放和充电策略，并对比与现有的基线算法进行比较。</li>
<li>results: 研究结果表明，使用Q学习算法可以Significantly reduce electricity costs compared to the baseline algorithm，这些发现 highlights the effectiveness of reinforcement learning for battery management within the dairy farming sector。<details>
<summary>Abstract</summary>
Dairy farming is a particularly energy-intensive part of the agriculture sector. Effective battery management is essential for renewable integration within the agriculture sector. However, controlling battery charging/discharging is a difficult task due to electricity demand variability, stochasticity of renewable generation, and energy price fluctuations. Despite the potential benefits of applying Artificial Intelligence (AI) to renewable energy in the context of dairy farming, there has been limited research in this area. This research is a priority for Ireland as it strives to meet its governmental goals in energy and sustainability. This research paper utilizes Q-learning to learn an effective policy for charging and discharging a battery within a dairy farm setting. The results demonstrate that the developed policy significantly reduces electricity costs compared to the established baseline algorithm. These findings highlight the effectiveness of reinforcement learning for battery management within the dairy farming sector.
</details>
<details>
<summary>摘要</summary>
奶业是农业部门中特别能耗能源的一部分。有效的电池管理是重要的，以便在农业部门中 integrating 可再生能源。然而，控制电池充放电是一个困难的任务，因为能源需求的变化、可再生能源的随机性和能源价格的波动。尽管应用人工智能（AI）到奶业中可能有很多的优点，但是这个领域的研究却有限。这项研究是爱尔兰政府的一个优先事项，以实现能源和可持续发展的目标。这篇研究论文使用Q学习算法学习一个有效的电池充放电策略，结果表明，发展的策略可以较基准算法减少电力成本。这些发现表明，强化学习可以在奶业部门中有效地管理电池。
</details></li>
</ul>
<hr>
<h2 id="Multi-field-Visualisation-via-Trait-induced-Merge-Trees"><a href="#Multi-field-Visualisation-via-Trait-induced-Merge-Trees" class="headerlink" title="Multi-field Visualisation via Trait-induced Merge Trees"></a>Multi-field Visualisation via Trait-induced Merge Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09015">http://arxiv.org/abs/2308.09015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jochen Jankowai, Talha Bin Masood, Ingrid Hotz</li>
<li>for: 这paper是为了探讨tensor场或多变量数据的分析，提出 trait-based merge trees，一种特性基于merge trees的总结。</li>
<li>methods: 这paper使用了特性空间中的特性定义，以及Attribute Space中的特性空间定义，将distance field转化为属性空间中的一个整数场，用于 topological data analysis。</li>
<li>results: 这paper提出了一种基于特性的merge tree Hierarchy，可以用于查询最相似和持续存在的特性，并提供了不同的查询方法以便高亮不同的特性方面。三个 caso study在不同的领域中应用了该方法，以证明其跨领域可用性。<details>
<summary>Abstract</summary>
In this work, we propose trait-based merge trees a generalization of merge trees to feature level sets, targeting the analysis of tensor field or general multi-variate data. For this, we employ the notion of traits defined in attribute space as introduced in the feature level sets framework. The resulting distance field in attribute space induces a scalar field in the spatial domain that serves as input for topological data analysis. The leaves in the merge tree represent those areas in the input data that are closest to the defined trait and thus most closely resemble the defined feature. Hence, the merge tree yields a hierarchy of features that allows for querying the most relevant and persistent features. The presented method includes different query methods for the tree which enable the highlighting of different aspects. We demonstrate the cross-application capabilities of this approach with three case studies from different domains.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了 trait-based merge trees，这是 merge trees 的一种普遍化，targeting tensor field 或一般多变量数据的分析。为此，我们利用 attribute space 中定义的特质（trait）。在这个框架中，输入数据的特征空间距离场所引入了一个拓扑数据分析的输入场。merge tree 的叶子节点表示输入数据中最接近定义特质的区域，因此最接近定义的特征。因此，merge tree 提供了一个特征层次结构，可以对输入数据进行特征 queries。我们还提供了不同的查询方法，可以根据不同的需求高亮不同的特征。我们通过三个不同领域的案例，证明了这种方法的跨应用性。
</details></li>
</ul>
<hr>
<h2 id="Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals"><a href="#Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals" class="headerlink" title="Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals"></a>Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09013">http://arxiv.org/abs/2308.09013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Dubois, Carlos Lima Azevedo, Sonja Haustein, Bruno Miranda</li>
<li>for: 这篇论文主要是关于情感认知的研究，旨在提出一种基于物理和心理数据的无监督深度划分方法来实现情感认知。</li>
<li>methods: 该方法使用了深度划分算法，包括深度k-means和深度c-means，并在测试数据集WESAD上实现了87%的总准确率。</li>
<li>results: 该研究表明，通过使用物理和心理数据，并使用无监督深度划分方法，可以实现高度准确的情感认知，并且可以避免需要大量的标签数据。<details>
<summary>Abstract</summary>
Emotions play a significant role in the cognitive processes of the human brain, such as decision making, learning and perception. The use of physiological signals has shown to lead to more objective, reliable and accurate emotion recognition combined with raising machine learning methods. Supervised learning methods have dominated the attention of the research community, but the challenge in collecting needed labels makes emotion recognition difficult in large-scale semi- or uncontrolled experiments. Unsupervised methods are increasingly being explored, however sub-optimal signal feature selection and label identification challenges unsupervised methods' accuracy and applicability. This article proposes an unsupervised deep cluster framework for emotion recognition from physiological and psychological data. Tests on the open benchmark data set WESAD show that deep k-means and deep c-means distinguish the four quadrants of Russell's circumplex model of affect with an overall accuracy of 87%. Seeding the clusters with the subject's subjective assessments helps to circumvent the need for labels.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:情感对人类大脑的认知过程具有重要作用，如决策、学习和感知。通过使用生物学信号，可以实现更加客观、可靠和准确的情感识别，并且与机器学习方法相结合。但是，在大规模的半控制或无控制实验中收集标签是困难的，因此许多研究者对supervised learning方法进行了探索。然而，不同信号特征选择和标签标识问题限制了无监督方法的准确性和可应用性。这篇文章提出了一种无监督深度团 clustering框架，用于从生物学和心理学数据中进行情感识别。在WESAD开放数据集上进行测试，深度k-means和深度c-means能够分解Russell的情感圆框模型中的四个 quadrant，总准确率达87%。通过使用参与者的主观评估来填充团中的标签，可以避免标签收集的困难。
</details></li>
</ul>
<hr>
<h2 id="Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability"><a href="#Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability" class="headerlink" title="Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability"></a>Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09004">http://arxiv.org/abs/2308.09004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renan Souza, Tyler J. Skluzacek, Sean R. Wilkinson, Maxim Ziatdinov, Rafael Ferreira da Silva</li>
<li>for: 科学发现的大规模合作和数据分析</li>
<li>methods: 基于数据可见性、适配器系统设计和证据的轻量级运行多工程数据分析方法</li>
<li>results: 实现了灵活的多工程数据分析，可以在多种并行环境中运行，并且在 Summit 超级计算机上实现了near-zero overhead，可以处理大量任务。<details>
<summary>Abstract</summary>
Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.
</details>
<details>
<summary>摘要</summary>
现代大规模科学发现需要跨学科合作和多种计算机facility的支持，包括高性能计算机（HPC）机器和Edge-to-Cloud kontinuum。集成数据分析在科学发现中扮演着关键的角色，特别是在当前人工智能时代，通过帮助开发负责任AI，FAIR，可重现和用户指导。然而，科学的多元性带来了多种支持工具、跨设施环境和高效HPC执行的挑战。基于数据可见性，适配器系统设计和证明，我们提出MIDA：一种轻量级运行时多工流Integrated Data Analysis的方法。MIDA定义了数据可见性策略和适配方法，用于不同的并行系统和机器学习工具。通过可见性，它在背景中 intercepts 数据流 ohne requiring  инструментирование，并将domain、证明和电信数据在运行时集成到一个统一的数据库中，准备就绪 для用户指导查询。我们进行实验，将多工流分析集成到了材料科学中的分布式深度学习应用程序中，运行在多种环境上，包括最多276个GPU并行。我们显示了near-zero overhead，在1,680个CPU核心上运行Up to 100,000个任务。
</details></li>
</ul>
<hr>
<h2 id="DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering"><a href="#DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering" class="headerlink" title="DealMVC: Dual Contrastive Calibration for Multi-view Clustering"></a>DealMVC: Dual Contrastive Calibration for Multi-view Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09000">http://arxiv.org/abs/2308.09000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/dealmvc">https://github.com/xihongyang1999/dealmvc</a></li>
<li>paper_authors: Xihong Yang, Jiaqi Jin, Siwei Wang, Ke Liang, Yue Liu, Yi Wen, Suyuan Liu, Sihang Zhou, Xinwang Liu, En Zhu</li>
<li>for: 解决多视图 clustering 中同样 pero different samples 的问题，提高 clustering 性能。</li>
<li>methods: 提出了一种 dual contrastive calibration network (DealMVC)，包括 global contrastive calibration loss 和 local contrastive calibration loss，以及 feature structure 的 regularization。</li>
<li>results: 与其他 state-of-the-art 方法进行比较，实验结果表明 DealMVC 的效果和优势较高，可以提高 clustering 性能。<details>
<summary>Abstract</summary>
Benefiting from the strong view-consistent information mining capacity, multi-view contrastive clustering has attracted plenty of attention in recent years. However, we observe the following drawback, which limits the clustering performance from further improvement. The existing multi-view models mainly focus on the consistency of the same samples in different views while ignoring the circumstance of similar but different samples in cross-view scenarios. To solve this problem, we propose a novel Dual contrastive calibration network for Multi-View Clustering (DealMVC). Specifically, we first design a fusion mechanism to obtain a global cross-view feature. Then, a global contrastive calibration loss is proposed by aligning the view feature similarity graph and the high-confidence pseudo-label graph. Moreover, to utilize the diversity of multi-view information, we propose a local contrastive calibration loss to constrain the consistency of pair-wise view features. The feature structure is regularized by reliable class information, thus guaranteeing similar samples have similar features in different views. During the training procedure, the interacted cross-view feature is jointly optimized at both local and global levels. In comparison with other state-of-the-art approaches, the comprehensive experimental results obtained from eight benchmark datasets provide substantial validation of the effectiveness and superiority of our algorithm. We release the code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.
</details>
<details>
<summary>摘要</summary>
利用强大的视图一致信息挖掘能力，多视图对比 clustering 在最近几年内吸引了大量的注意力。然而，我们发现现有的多视图模型主要关注不同视图中的同样样本之间的一致性，而忽略了不同视图中的相似 yet 不同样本之间的关系。为解决这个问题，我们提出了一种新的 dual contrastive calibration network for Multi-View Clustering（DealMVC）。具体来说，我们首先设计了一种 fusions 机制，以获得全局跨视图特征。然后，我们提出了一种全局对比准备损失，通过对视图特征相似图和高置信度假标签图进行对比，使得相似的样本在不同视图中具有相似的特征。此外，为了利用多视图信息的多样性，我们提出了一种本地对比准备损失，以强制不同视图中的对应样本之间的一致性。特征结构被可靠的类信息规范化，以保证不同视图中的相似样本具有相似的特征。在训练过程中，交互的跨视图特征被在本地和全局两级进行优化。与其他状态 искус法比较，我们从八个标准 benchmark 数据集获得了广泛的实验结果，这些结果证明了我们的算法的有效性和优越性。我们在 GitHub 上发布了 DealMVC 的代码，请参考 <https://github.com/xihongyang1999/DealMVC>。
</details></li>
</ul>
<hr>
<h2 id="Reinforced-Self-Training-ReST-for-Language-Modeling"><a href="#Reinforced-Self-Training-ReST-for-Language-Modeling" class="headerlink" title="Reinforced Self-Training (ReST) for Language Modeling"></a>Reinforced Self-Training (ReST) for Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08998">http://arxiv.org/abs/2308.08998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas</li>
<li>for: 提高大语言模型的输出质量（machine translation）</li>
<li>methods: 使用激励自学习（Reinforced Self-Training，ReST）算法，通过在初始语言模型策略基础上生成样本，然后使用离线激励学习算法进行改进</li>
<li>results: substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
</details>
<details>
<summary>摘要</summary>
人工反馈学习（RLHF）可以提高大语言模型（LLM）的输出质量，通过将其与人类喜好进行对齐。我们提出了一种简单的算法，即增强自我训练（ReST），以提高 LLM 政策。给定初始 LLM 策略，ReST 会生成一个样本集，然后使用在线 RL 算法来改善 LLM 策略。相比于 typical online RLHF 方法，ReST 更加高效，因为它可以在线下进行训练，从而实现数据重用。虽然 ReST 是一种通用的措施，但我们在机器翻译中进行了应用。我们的结果显示，ReST 可以在计算和样本效率下提高翻译质量，并且通过人类评估得到证明。
</details></li>
</ul>
<hr>
<h2 id="Learning-representations-by-forward-propagating-errors"><a href="#Learning-representations-by-forward-propagating-errors" class="headerlink" title="Learning representations by forward-propagating errors"></a>Learning representations by forward-propagating errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09728">http://arxiv.org/abs/2308.09728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryoungwoo Jang</li>
<li>for: 这个论文目的是提出一种轻量级、快速的学习算法，用于在中央处理单元（CPU）上优化神经网络。</li>
<li>methods: 这种算法基于前向传播方法，使用了代数几何中的双数概念。</li>
<li>results: 该算法比 tradicional back-propagation（BP）算法更快速，可以在CPU上进行神经网络优化。<details>
<summary>Abstract</summary>
Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry." into Simplified Chinese.翻译文本为Simplified Chinese：Back-propagation（BP）是广泛使用的神经网络优化算法。然而，BP需要巨大的计算成本，并且在中央处理单元（CPU）中训练太慢。因此，当前的神经网络优化通常在图形处理单元（GPU）上使用compute unified device architecture（CUDA）编程进行。在这篇论文中，我们提出了一种轻量级、快速的学习算法，在CPU上实现，与GPU上CUDA加速相同快速。这种算法基于前向传播方法，利用了代数几何中的双数概念。
</details></li>
</ul>
<hr>
<h2 id="Neural-oscillators-for-generalization-of-physics-informed-machine-learning"><a href="#Neural-oscillators-for-generalization-of-physics-informed-machine-learning" class="headerlink" title="Neural oscillators for generalization of physics-informed machine learning"></a>Neural oscillators for generalization of physics-informed machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08989">http://arxiv.org/abs/2308.08989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Kapoor, Abhishek Chandra, Daniel M. Tartakovsky, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</li>
<li>for: 提高物理学 Informed 机器学习（PIML）的泛化能力，特别是在面临复杂物理问题时。</li>
<li>methods: 利用 PDE 解的内在 causality 和时间序列特征，将 PIML 模型与回归神经网络结合，基于系数 ordinary differential equations 的神经抗 oscilators。</li>
<li>results: 通过有效地捕捉长时间依赖和缓解扩散和消失Gradient问题，神经抗 oscilators 提高 PIML 模型的泛化能力，在时间依赖非线性 PDE 和 biharmonic beam 方程上进行了广泛的实验，并证明了该方法的有效性。<details>
<summary>Abstract</summary>
A primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.
</details>
<details>
<summary>摘要</summary>
physics-informed machine learning (PIML) 的主要挑战之一是其泛化性，特别是在处理复杂的物理问题时。这篇论文的目的是增强 PIML 的泛化能力，以便在实际应用中做出准确的预测，特别是在训练数据外的未探索区域。我们利用 PDE 解的内在 causality 和时间序列特征来融合 PIML 模型和回归神经网络，称为神经振荡器。通过有效地捕捉长期依赖关系和 Mitigate 爆炸和消失梯度问题，神经振荡器 提高了 PIML 任务中的泛化能力。经过大量的实验，我们发现在时间不断改变的非线性 PDE 和二次杠杆方程中，包含神经振荡器 的方法可以更高效地解决问题，并且在不同的 метриках上都超过了现有的状态ünstler 方法。因此，我们的方法可以提高 PIML 的泛化能力，为 extrapolation 和预测 beyond 训练数据提供准确的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-biomimicry-gap-in-biohybrid-systems"><a href="#Quantifying-the-biomimicry-gap-in-biohybrid-systems" class="headerlink" title="Quantifying the biomimicry gap in biohybrid systems"></a>Quantifying the biomimicry gap in biohybrid systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08978">http://arxiv.org/abs/2308.08978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaios Papaspyros, Guy Theraulaz, Clément Sire, Francesco Mondada<br>for: 这个论文的目的是用生物hybrid系统来探索和识别动物群体行为的机制。methods: 这篇论文使用了生物寄生的鱼类模型和神经网络模型来生成生物寄生的社交互动。results: 这篇论文通过实验和模拟来证明，使用生物寄生的鱼类模型和神经网络模型可以生成高精度的社交互动，与真实的鱼类群体行为高度相似。<details>
<summary>Abstract</summary>
Biohybrid systems in which robotic lures interact with animals have become compelling tools for probing and identifying the mechanisms underlying collective animal behavior. One key challenge lies in the transfer of social interaction models from simulations to reality, using robotics to validate the modeling hypotheses. This challenge arises in bridging what we term the "biomimicry gap", which is caused by imperfect robotic replicas, communication cues and physics constrains not incorporated in the simulations that may elicit unrealistic behavioral responses in animals. In this work, we used a biomimetic lure of a rummy-nose tetra fish (Hemigrammus rhodostomus) and a neural network (NN) model for generating biomimetic social interactions. Through experiments with a biohybrid pair comprising a fish and the robotic lure, a pair of real fish, and simulations of pairs of fish, we demonstrate that our biohybrid system generates high-fidelity social interactions mirroring those of genuine fish pairs. Our analyses highlight that: 1) the lure and NN maintain minimal deviation in real-world interactions compared to simulations and fish-only experiments, 2) our NN controls the robot efficiently in real-time, and 3) a comprehensive validation is crucial to bridge the biomimicry gap, ensuring realistic biohybrid systems.
</details>
<details>
<summary>摘要</summary>
生物融合系统，在其中机器人饵料与动物互动，已成为诱导和识别集体动物行为的有力工具。一个关键挑战在于将社交互动模型从 simulations 转移到实际情况，使用机器人来验证模型假设。这个挑战 arise 由我们称为 "生物模仿差距"，这是因为机器人的复制不准确、通信提示和物理约束不包括在 simulations 中，可能会诱导动物的不实际行为响应。在这项工作中，我们使用了一个生物模仿的鲤鱼鱼饵（Hemigrammus rhodostomus）和一个神经网络（NN）模型来生成生物模仿社交互动。通过实验中的生物融合对，一个鱼和机器人饵料对，一对真正的鱼对和 simulations 中的鱼对，我们示出了我们的生物融合系统可以生成高准确性的社交互动，与真正的鱼对相似。我们的分析表明：1）饵料和 NN 在实际情况中具有最小偏差，与 simulations 和鱼只实验相比; 2）我们的 NN 在实时控制机器人; 3）全面验证是必要的，以bridging "生物模仿差距"，确保生物融合系统的真实性。
</details></li>
</ul>
<hr>
<h2 id="Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models"><a href="#Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models" class="headerlink" title="Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models"></a>Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08977">http://arxiv.org/abs/2308.08977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizabeth Collins-Woodfin, Courtney Paquette, Elliot Paquette, Inbar Seroussi</li>
<li>for: 这 paper 是研究 streaming stochastic gradient descent (SGD) 在高维限制下的动态特性，具体来说是在通用线性模型和多指量模型（例如Logistic regression、phase retrieval）中应用 SGD，并研究其在大数据量下的性能。</li>
<li>methods: 这 paper 使用了一种系统Ordinary differential equations来描述 SGD 的动态行为，这种方法可以涵盖许多统计量，如风险和优化度量。此外，paper 还引入了一种简化的卷积 coefficient的 SDE（homogenized SGD），以便分析 SGD 迭代器的动态行为。</li>
<li>results: 这 paper 的结果表明，当模型参数个数与数据量成正比时，SGD 可以被视为一种确定性的方法，其可以提供风险和优化度量的确定性 guarantees。此外，paper 还提供了一些标准示例的数据分析，并与理论结果相符。<details>
<summary>Abstract</summary>
We analyze the dynamics of streaming stochastic gradient descent (SGD) in the high-dimensional limit when applied to generalized linear models and multi-index models (e.g. logistic regression, phase retrieval) with general data-covariance. In particular, we demonstrate a deterministic equivalent of SGD in the form of a system of ordinary differential equations that describes a wide class of statistics, such as the risk and other measures of sub-optimality. This equivalence holds with overwhelming probability when the model parameter count grows proportionally to the number of data. This framework allows us to obtain learning rate thresholds for stability of SGD as well as convergence guarantees. In addition to the deterministic equivalent, we introduce an SDE with a simplified diffusion coefficient (homogenized SGD) which allows us to analyze the dynamics of general statistics of SGD iterates. Finally, we illustrate this theory on some standard examples and show numerical simulations which give an excellent match to the theory.
</details>
<details>
<summary>摘要</summary>
我们分析流动式随机Gradient Descent（SGD）在高维限制下的动态行为，尤其是在泛化线性模型和多指标模型（例如逻辑回归、相位恢复）中。我们展示了一个确定的SGD等价项，它描述了一个广泛的统计量，例如风险和其他不足之数据。这个等价项在资料数量增加时，对数据的尺度成长时，具有极高的概率。这个框架允许我们获得SGD的学习率阈值以及稳定性的保证。此外，我们引入了一个简化的扩散系数（殷合SGD），它允许我们分析SGD迭代的一般统计。最后，我们在一些标准的例子中详细介绍了这个理论，并提供了一些实际的实验结果，与理论内容匹配得极佳。
</details></li>
</ul>
<hr>
<h2 id="Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank"><a href="#Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank" class="headerlink" title="Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank"></a>Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09727">http://arxiv.org/abs/2308.09727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhyliu00/tpb">https://github.com/zhyliu00/tpb</a></li>
<li>paper_authors: Zhanyu Liu, Guanjie Zheng, Yanwei Yu</li>
<li>for: 提高智能交通系统中的交通预测精度，尤其是在数据穷市场地区。</li>
<li>methods: 利用交通模式银行（TPB），通过预训练的交通补充编码器将数据丰富城市的交通数据 proyect到高维空间，然后根据协调分区生成交通模式银行。</li>
<li>results: 在实际交通数据集上进行实验，表明TPB在cross-city几个shot交通预测中表现出色，超越现有方法，证明我们的方法在数据穷市场地区的交通预测中具有效果。<details>
<summary>Abstract</summary>
Traffic forecasting is a critical service in Intelligent Transportation Systems (ITS). Utilizing deep models to tackle this task relies heavily on data from traffic sensors or vehicle devices, while some cities might lack device support and thus have few available data. So, it is necessary to learn from data-rich cities and transfer the knowledge to data-scarce cities in order to improve the performance of traffic forecasting. To address this problem, we propose a cross-city few-shot traffic forecasting framework via Traffic Pattern Bank (TPB) due to that the traffic patterns are similar across cities. TPB utilizes a pre-trained traffic patch encoder to project raw traffic data from data-rich cities into high-dimensional space, from which a traffic pattern bank is generated through clustering. Then, the traffic data of the data-scarce city could query the traffic pattern bank and explicit relations between them are constructed. The metaknowledge is aggregated based on these relations and an adjacency matrix is constructed to guide a downstream spatial-temporal model in forecasting future traffic. The frequently used meta-training framework Reptile is adapted to find a better initial parameter for the learnable modules. Experiments on real-world traffic datasets show that TPB outperforms existing methods and demonstrates the effectiveness of our approach in cross-city few-shot traffic forecasting.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统（ITS）中的关键服务。使用深度模型来解决这个任务需要依赖于交通感知器或车辆设备上的数据，而一些城市可能缺乏设备支持，因此有限的数据。因此，我们需要从数据丰富的城市学习并传递知识到数据缺乏的城市，以改善交通预测性能。为解决这个问题，我们提出了跨城市几拟交通预测框架via Traffic Pattern Bank（TPB）。TPB利用预训练的交通补充器来将数据丰富城市的 raw 交通数据 proyect到高维空间中，从而生成交通模式银行。然后，数据缺乏城市的交通数据可以在交通模式银行中查询，并构建了明确的交通模式之间的关系。这些关系的总体知识被聚合，并构建了一个导航下游空间时间模型的优化矩阵。我们采用了现有的meta-training框架Reptile来找到更好的初始参数。实验表明，TPB比现有方法更高效，并证明了我们的方法在跨城市几拟交通预测中的效果。
</details></li>
</ul>
<hr>
<h2 id="CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation"><a href="#CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation" class="headerlink" title="CONVERT:Contrastive Graph Clustering with Reliable Augmentation"></a>CONVERT:Contrastive Graph Clustering with Reliable Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08963">http://arxiv.org/abs/2308.08963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/convert">https://github.com/xihongyang1999/convert</a></li>
<li>paper_authors: Xihong Yang, Cheng Tan, Yue Liu, Ke Liang, Siwei Wang, Sihang Zhou, Jun Xia, Stan Z. Li, Xinwang Liu, En Zhu</li>
<li>for: 提高不监督图像学习中的图像自动生成技术的可靠性和效果。</li>
<li>methods: 提出了一种名为COVERT的新网络模型，该模型通过一种叫做征识扰动恢复网络的方式，对数据生成器进行了可靠性提高和semantic信息捕捉。此外，还提出了一种新的semantic损失函数，用于约束网络的学习。</li>
<li>results: 经过广泛的实验研究，该方法在七个数据集上得到了极高的效果，超过了现有的方法。code和补充文件也在github上公开发布。<details>
<summary>Abstract</summary>
Contrastive graph node clustering via learnable data augmentation is a hot research spot in the field of unsupervised graph learning. The existing methods learn the sampling distribution of a pre-defined augmentation to generate data-driven augmentations automatically. Although promising clustering performance has been achieved, we observe that these strategies still rely on pre-defined augmentations, the semantics of the augmented graph can easily drift. The reliability of the augmented view semantics for contrastive learning can not be guaranteed, thus limiting the model performance. To address these problems, we propose a novel CONtrastiVe Graph ClustEring network with Reliable AugmenTation (COVERT). Specifically, in our method, the data augmentations are processed by the proposed reversible perturb-recover network. It distills reliable semantic information by recovering the perturbed latent embeddings. Moreover, to further guarantee the reliability of semantics, a novel semantic loss is presented to constrain the network via quantifying the perturbation and recovery. Lastly, a label-matching mechanism is designed to guide the model by clustering information through aligning the semantic labels and the selected high-confidence clustering pseudo labels. Extensive experimental results on seven datasets demonstrate the effectiveness of the proposed method. We release the code and appendix of CONVERT at https://github.com/xihongyang1999/CONVERT on GitHub.
</details>
<details>
<summary>摘要</summary>
“对照性图节点聚合via学习数据增强是现场无监督图学中的热点研究领域。现有方法通过自动生成数据驱动增强来学习增强分布。虽然这些策略已经实现了有前途的聚合性能，但我们发现这些策略仍然依赖于预定的增强，即使在增强后，图的 semantics 容易偏移。因此，我们提出了一种名为 CONtrastiVe Graph ClustEring network with Reliable AugmenTation（COVERT）的新方法。具体来说，我们的方法通过我们提出的可逆压抽网络进行数据增强。这个网络可以通过压抽并重建原始 embedding 来提取可靠的semantic信息。此外，为了进一步保证 semantics 的可靠性，我们提出了一种新的semantic损失函数，该函数通过量化压抽和重建来约束网络。最后，我们设计了一种标签匹配机制，通过对semantic标签和选择高置信聚合 Pseudolabels 进行对应，以导引模型。我们的实验结果表明，我们的方法能够有效地进行图聚合。我们在 GitHub 上发布了代码和补充材料，详细的实验结果和方法详细介绍可以参考我们的 GitHub 上的文章。”
</details></li>
</ul>
<hr>
<h2 id="Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health"><a href="#Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health" class="headerlink" title="Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health"></a>Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09726">http://arxiv.org/abs/2308.09726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/socialgood">https://github.com/google-research/socialgood</a></li>
<li>paper_authors: Jackson A. Killian, Manish Jain, Yugang Jia, Jonathan Amar, Erich Huang, Milind Tambe</li>
<li>for: 这篇论文旨在研究多重臂摆（RMAB）的公平目标（ERMAB），以提高决策的公平性和健康等级。</li>
<li>methods: 这篇论文使用了两种公平目标，即最小最大奖励和最大奈雪威夷。它们分别使用了一种灌水算法和一种理论上 inspirited 的落叶算法来实现。</li>
<li>results: 研究在三个模拟领域中，包括一个新的数字医疗模型，发现了其方法可以比现有技术多少 times 更公平，而无需损害效用。这些结果认可了这种研究的urgency，因为RMAB在人类和野生动物的结果中广泛应用。<details>
<summary>Abstract</summary>
Restless multi-armed bandits (RMABs) are a popular framework for algorithmic decision making in sequential settings with limited resources. RMABs are increasingly being used for sensitive decisions such as in public health, treatment scheduling, anti-poaching, and -- the motivation for this work -- digital health. For such high stakes settings, decisions must both improve outcomes and prevent disparities between groups (e.g., ensure health equity). We study equitable objectives for RMABs (ERMABs) for the first time. We consider two equity-aligned objectives from the fairness literature, minimax reward and max Nash welfare. We develop efficient algorithms for solving each -- a water filling algorithm for the former, and a greedy algorithm with theoretically motivated nuance to balance disparate group sizes for the latter. Finally, we demonstrate across three simulation domains, including a new digital health model, that our approaches can be multiple times more equitable than the current state of the art without drastic sacrifices to utility. Our findings underscore our work's urgency as RMABs permeate into systems that impact human and wildlife outcomes. Code is available at https://github.com/google-research/socialgood/tree/equitable-rmab
</details>
<details>
<summary>摘要</summary>
众臂猎手（RMAB）是一种流行的算法决策框架，广泛应用于顺序设置中的有限资源管理。众臂猎手在公共卫生、治疗安排、反贪杀和数字医疗等高规模场景中得到应用，决策必须同时提高结果和避免群体之间的差距（如保障健康公平）。我们研究了众臂猎手的公平目标（ERMAB），并考虑了两种与公平相关的目标，即最小最大奖励和最大 NASH 利益。我们开发了高效的算法来解决每一个目标，包括水填算法和基于理论的柔和策略来平衡不同群体大小的算法。最后，我们在三个 simulations 频道中，包括一个新的数字医疗模型，证明了我们的方法可以在无损Utility 的情况下多达多少倍提高公平性。我们的发现强调了我们的工作的急迫性，因为众臂猎手在影响人类和野生动物的系统中普遍应用。代码可以在 <https://github.com/google-research/socialgood/tree/equitable-rmab> 中获取。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods"><a href="#A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods" class="headerlink" title="A Dual-Perspective Approach to Evaluating Feature Attribution Methods"></a>A Dual-Perspective Approach to Evaluating Feature Attribution Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08949">http://arxiv.org/abs/2308.08949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yawei Li, Yang Zhang, Kenji Kawaguchi, Ashkan Khakzar, Bernd Bischl, Mina Rezaei</li>
<li>for: 本研究旨在提供一个新的评估feature attribution方法的框架，以及两种新的评估视角，即实用性（soundness）和完整性（completeness）。</li>
<li>methods: 本研究使用了现有的feature attribution方法，并提出了两种新的评估方法，即实用性评估和完整性评估。这两种方法都基于固定的数学基础，并可以通过高效的算法来计算。</li>
<li>results: 本研究通过应用这两种新的评估方法，对主流的feature attribution方法进行了评估。结果表明，这两种方法可以提供一个新的视角来分析和比较feature attribution方法的效果。<details>
<summary>Abstract</summary>
Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods."into Simplified Chinese.Feature 归属方法 attempt to explain neural network 预测结果 by identifying relevant features. However, establishing a cohesive framework for assessing feature 归属 remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level"><a href="#Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level" class="headerlink" title="Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level"></a>Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08948">http://arxiv.org/abs/2308.08948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Pathak, Miro Miranda, Francisco Mena, Cristhian Sanchez, Patrick Helber, Benjamin Bischke, Peter Habelitz, Hiba Najjar, Jayanth Siddamsetty, Diego Arenas, Michaela Vollmer, Marcela Charfuelan, Marlon Nuske, Andreas Dengel</li>
<li>for: 这个论文是为了预测农业产量而写的。</li>
<li>methods: 这个论文使用了一种简单 yet effective的早期融合方法，该方法可以处理多种输入模式，并且可以在不同的时间和空间分辨率下工作。</li>
<li>results: 这个论文使用了高分辨率农业产量地图作为真实数据来训练农作物和机器学习模型，并且使用了全球覆盖的卫星图像作为主要输入数据，以及其他补充的模式，如天气、土壤和地形数据。<details>
<summary>Abstract</summary>
We introduce a simple yet effective early fusion method for crop yield prediction that handles multiple input modalities with different temporal and spatial resolutions. We use high-resolution crop yield maps as ground truth data to train crop and machine learning model agnostic methods at the sub-field level. We use Sentinel-2 satellite imagery as the primary modality for input data with other complementary modalities, including weather, soil, and DEM data. The proposed method uses input modalities available with global coverage, making the framework globally scalable. We explicitly highlight the importance of input modalities for crop yield prediction and emphasize that the best-performing combination of input modalities depends on region, crop, and chosen model.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种简单 yet 有效的早期融合方法 для农作物收成预测，该方法可以处理多种输入模式，每种模式具有不同的时空分解能力。我们使用高分辨率农作物收成地图作为真实数据来训练农作物和机器学习模型无关的方法。我们使用卫星影像作为主要输入数据，其他补充数据包括天气、土壤和地形数据。我们的方法使用全球覆盖的输入数据，因此该框架可以在全球范围内扩展。我们显式强调输入数据对农作物收成预测的重要性，并且指出在不同的区域、作物和选择的模型中，最佳的输入数据组合会有所不同。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Graph-Neural-Networks-for-Tabular-Data"><a href="#Interpretable-Graph-Neural-Networks-for-Tabular-Data" class="headerlink" title="Interpretable Graph Neural Networks for Tabular Data"></a>Interpretable Graph Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08945">http://arxiv.org/abs/2308.08945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amr Alkhatib, Sofiane Ennadir, Henrik Boström, Michalis Vazirgiannis</li>
<li>for: 这种论文是为了处理实际应用中频繁出现的表格数据而设计的，使用图 neural network 扩展来捕捉特征间的交互。</li>
<li>methods: 这种方法使用了一种名为 IGNNet 的解释性图 neural network，它通过限制学习算法来生成可解释的模型，从原始输入特征直接计算出预测结果的确切计算方式。</li>
<li>results: 实验表明，IGNNet 与现状的机器学习算法相比，能够在处理表格数据方面达到相同的性能水平，同时可以提供可解释的模型，其预测结果与特征 SHAPley 值相对aligned，而无需额外的计算开销。<details>
<summary>Abstract</summary>
Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true Shapley values of the features without incurring any additional computational overhead.
</details>
<details>
<summary>摘要</summary>
<SYS>将数据表示为表格 Format 是实际应用中的常见现象。Graph Neural Networks (GNNs) 最近已经扩展到可以有效处理这类数据，以捕捉特征之间的交互。然而，这些方法基本上生成黑盒模型，即深度神经网络，使用户无法跟踪模型预测的逻辑。我们提出了一种方法，called IGNNet (Interpretable Graph Neural Network for tabular data), 它强制学习算法生成可解释性模型，其中模型可以从原始输入特征直接计算预测。我们对大规模的实验进行了报告，显示IGNNet 与目标 tabular 数据的状态机器学习算法，包括 XGBoost、Random Forests 和 TabNet 相比，表现准确。同时，结果表明IGNNet 获得的解释与特征的真正 Shapley 值相对应，而无需增加计算开销。</SYS>Note: "Shapley value" refers to a concept in cooperative game theory that assigns a value to each player in a cooperative game, based on their contribution to the grand coalition. In the context of the text, it refers to the contribution of each feature to the prediction made by the model.
</details></li>
</ul>
<hr>
<h2 id="Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces"><a href="#Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces" class="headerlink" title="Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces"></a>Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08938">http://arxiv.org/abs/2308.08938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ehyaei/CAPIFY">https://github.com/Ehyaei/CAPIFY</a></li>
<li>paper_authors: Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, Golnoosh Farnadi</li>
<li>for: 本研究旨在探讨个人公平、鲁棒性和结构 causal 模型在不同数据空间中同时探索和 интегразиOINT 这些性能。</li>
<li>methods: 我们提出了一种新的方法，通过使用 causal 结构模型和敏感特征来创建一个公平度量，并应用它来度量个体之间的 semantic 相似性。我们还引入了一种新的 causal  adversarial 干扰和 adversarial 训练，以创建一个新的 regularizer，这个 regularizer 同时包含了个体公平、鲁棒性和 causal 意识。</li>
<li>results: 我们在实际世界和 sintetic 数据集上评估了我们的方法，并证明了它可以构建一个准确的分类器，同时满足个体公平、鲁棒性和 causal 意识的要求。<details>
<summary>Abstract</summary>
As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.
</details>
<details>
<summary>摘要</summary>
As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.Here's the translation in Traditional Chinese:随着责任AI在机器学习算法中的重要性增加，属于不同类型的特性，如公平、敏感性、因果关系等，在最近的几年中已经获得了很大的关注。然而，这些个别的特性之间仍然存在着重要的欠缺，即同时探索和结合这些特性的方法。在这篇文章中，我们提出了一个新的方法，它探索了个人公平、敏感性和结构因果模型在不同数据空间中的关系，特别是在处理数据中的数据敏感特征时。我们使用因果结构模型和数据敏感特征来建立公平度量，并将其应用到测量个体之间的semantic相似性。通过引入新的因果敌对推差和敌对训练，我们创建了一个新的正规化器，它结合个人公平、因果和敏感性在分类器中的作用。我们的方法在真实世界和 sintetic数据集上进行评估，展示了它在精准分类器同时具备公平、敏感性和因果意识的能力。
</details></li>
</ul>
<hr>
<h2 id="Estimating-fire-Duration-using-regression-methods"><a href="#Estimating-fire-Duration-using-regression-methods" class="headerlink" title="Estimating fire Duration using regression methods"></a>Estimating fire Duration using regression methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08936">http://arxiv.org/abs/2308.08936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hansong Xiao</li>
<li>for: 这篇论文的目的是提出一种基于机器学习的野火预测方法，以解决传统的网格式数学模型所带来的计算成本和时间消耗问题。</li>
<li>methods: 该论文使用了Random Forest、KNN和XGBoost回归模型，以及图像基于的CNN和Encoder模型，来预测已知的野火燃烧时间。模型的输入是通过卫星提供的地形特征地图和相应的历史火灾数据。模型在被训练后，通过处理输入数据以获得最佳结果，能够快速和相对准确地预测未来的野火图像。</li>
<li>results: 论文的实验结果表明，机器学习基于的野火预测方法可以快速和准确地预测野火燃烧时间，并且可以减少计算成本和时间消耗。<details>
<summary>Abstract</summary>
Wildfire forecasting problems usually rely on complex grid-based mathematical models, mostly involving Computational fluid dynamics(CFD) and Celluar Automata, but these methods have always been computationally expensive and difficult to deliver a fast decision pattern. In this paper, we provide machine learning based approaches that solve the problem of high computational effort and time consumption. This paper predicts the burning duration of a known wildfire by RF(random forest), KNN, and XGBoost regression models and also image-based, like CNN and Encoder. Model inputs are based on the map of landscape features provided by satellites and the corresponding historical fire data in this area. This model is trained by happened fire data and landform feature maps and tested with the most recent real value in the same area. By processing the input differently to obtain the optimal outcome, the system is able to make fast and relatively accurate future predictions based on landscape images of known fires.
</details>
<details>
<summary>摘要</summary>
通常情况下，野火预测问题都会采用复杂的网格式数学模型，主要包括计算流体动力学(CFD)和细胞自动机，但这些方法总是 computationally expensive 并且困难呈现快速决策模式。在这篇论文中，我们提供了基于机器学习的方法来解决高计算成本和时间消耗的问题。本文预测已知野火燃烧的时间长度，使用Random Forest、KNN和XGBoost回归模型，以及图像基于的方法，如CNN和Encoder。模型输入基于通过卫星提供的地形特征图和相应的历史火灾数据。这个模型通过已发生火灾数据和地形特征图进行训练，并在同一地区测试最新的实际值。通过不同的处理方式来获得最佳结果，系统可以根据地形图像来快速和相对准确地预测未来的野火。
</details></li>
</ul>
<hr>
<h2 id="On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training"><a href="#On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training" class="headerlink" title="On Data Imbalance in Molecular Property Prediction with Pre-training"></a>On Data Imbalance in Molecular Property Prediction with Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08934">http://arxiv.org/abs/2308.08934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Limin Wang, Masatoshi Hanai, Toyotaro Suzumura, Shun Takashige, Kenjiro Taura</li>
<li>for: 本研究旨在提高分子性质预测模型的准确性，通过修改现有的代表性预训练方法（node masking）的损失函数，以补偿输入数据的不均衡。</li>
<li>methods: 本研究使用了一种组合方法，包括理论计算和机器学习，其中理论计算用于确定分子性质，而机器学习用于构建一个可以应用于剩下的材料的模型。此外，本研究还使用了预训练技术，包括node masking，以提高机器学习模型的准确性。</li>
<li>results: 本研究通过实验和评估使用了benchmark模型，发现修改损失函数可以提高预测结果的准确性，并且可以补偿输入数据的不均衡。<details>
<summary>Abstract</summary>
Revealing and analyzing the various properties of materials is an essential and critical issue in the development of materials, including batteries, semiconductors, catalysts, and pharmaceuticals. Traditionally, these properties have been determined through theoretical calculations and simulations. However, it is not practical to perform such calculations on every single candidate material. Recently, a combination method of the theoretical calculation and machine learning has emerged, that involves training machine learning models on a subset of theoretical calculation results to construct a surrogate model that can be applied to the remaining materials. On the other hand, a technique called pre-training is used to improve the accuracy of machine learning models. Pre-training involves training the model on pretext task, which is different from the target task, before training the model on the target task. This process aims to extract the input data features, stabilizing the learning process and improving its accuracy. However, in the case of molecular property prediction, there is a strong imbalance in the distribution of input data and features, which may lead to biased learning towards frequently occurring data during pre-training. In this study, we propose an effective pre-training method that addresses the imbalance in input data. We aim to improve the final accuracy by modifying the loss function of the existing representative pre-training method, node masking, to compensate the imbalance. We have investigated and assessed the impact of our proposed imbalance compensation on pre-training and the final prediction accuracy through experiments and evaluations using benchmark of molecular property prediction models.
</details>
<details>
<summary>摘要</summary>
描述和分析材料的不同性质是物料发展中的关键和重要问题，包括电池、半导体、催化剂和药物。在过去，这些性质通常通过理论计算和模拟来确定。但是，对每种候选材料进行这些计算是不实际的。最近，一种结合理论计算和机器学习的方法得到了应用，即通过训练机器学习模型在一个子集理论计算结果上构建一个代理模型，以应用于剩下的材料。而在机器学习模型训练中，一种称为预训练的技术得到了应用，即在预测任务上训练模型，然后在目标任务上训练模型。这个过程的目的是提取输入数据特征，稳定学习过程，提高准确性。但在分子性质预测中，输入数据和特征之间存在强烈的不均衡，这可能导致在预训练过程中偏向频繁出现的数据进行偏激学习。在本研究中，我们提出了一种有效地弥合输入数据不均衡的预训练方法。我们希望通过修改现有代表预训练方法的损失函数，以补偿不均衡。我们通过实验和评估使用分子性质预测模型的标准套件进行了研究和评估。
</details></li>
</ul>
<hr>
<h2 id="IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making"><a href="#IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making" class="headerlink" title="IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making"></a>IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08918">http://arxiv.org/abs/2308.08918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Niu, Siyuan Li, Jiahao Zheng, Zhouchi Lin, Jian Li, Jian Guo, Bo An</li>
<li>For: 这篇论文旨在提出一种基于强化学习的多价格水平市场制作者（Imitative Market Maker，IMM）方法，以提高市场流动性和订单处理效率。* Methods: 该方法基于一种新的状态和动作表示方法，可以快速和高效地学习多价格水平市场制作者的策略。它还 integrate了一种表示学习单元，可以捕捉市场趋势的短期和长期变化，从而降低风险。* Results: 实验结果表明，IMM方法在四个实际市场数据集上比现有的RL基于市场制作者策略具有较高的财务效益和处理效率。减少策略的风险也得到了证明。<details>
<summary>Abstract</summary>
Market making (MM) has attracted significant attention in financial trading owing to its essential function in ensuring market liquidity. With strong capabilities in sequential decision-making, Reinforcement Learning (RL) technology has achieved remarkable success in quantitative trading. Nonetheless, most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. Strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level strategies involves a comprehensive trading action space, the challenge of effectively training profitable RL agents for MM persists. Inspired by the efficient workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework start with introducing effective state and action representations adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details>
<details>
<summary>摘要</summary>
市场制作（MM）在金融交易中吸引了广泛的注意力，因为它对市场流动性的稳定性具有关键作用。RL技术在数学交易中取得了显著的成功，但大多数现有RL基于MM方法都是优化单价级别策略，这会导致频繁的订单取消和排队优先权失去。使用多个价格级别的策略更好地适应实际交易场景。然而，由于多个价格级别的策略的复杂性，训练可财富RL代理人是一项挑战。 Drawing inspiration from professional human market makers' efficient workflow, we propose Imitative Market Maker (IMM), a novel RL framework that leverages both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework starts by introducing effective state and action representations that are adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details></li>
</ul>
<hr>
<h2 id="Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection"><a href="#Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection" class="headerlink" title="Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection"></a>Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08915">http://arxiv.org/abs/2308.08915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawnvince/mts_cad">https://github.com/dawnvince/mts_cad</a></li>
<li>paper_authors: Haotian Si, Changhua Pei, Zhihan Li, Yadong Zhao, Jingjing Li, Haiming Zhang, Zulong Diao, Jianhui Li, Gaogang Xie, Dan Pei</li>
<li>for: 本研究旨在提出一种基于多任务学习的多变量时间序列异常检测（MTS AD）算法，以确保软件应用和服务系统的可靠性。</li>
<li>methods: 本研究使用了自适应MTS AD方法，通过优化总体目标&#x2F;损失来捕捉所有指标的回归目标&#x2F;损失。然而，我们的实验发现，这些指标的回归目标之间存在冲突，导致MTS模型面临不同的损失。为解决这问题，我们提出了一种具有冲突 Mitigation的多变量KPI异常检测算法（CAD）。</li>
<li>results: 我们的实验表明，CAD算法在三个公共数据集上的平均F1分数为0.943，明显超过现有方法。此外，我们还发现了MTS形式ulation的输入-输出不一致和扩展任务的问题，并提出了一种简单 yet有效的任务导向指标选择和个性化分配机制，以解决这些挑战。<details>
<summary>Abstract</summary>
Massive key performance indicators (KPIs) are monitored as multivariate time series data (MTS) to ensure the reliability of the software applications and service system. Accurately detecting the abnormality of MTS is very critical for subsequent fault elimination. The scarcity of anomalies and manual labeling has led to the development of various self-supervised MTS anomaly detection (AD) methods, which optimize an overall objective/loss encompassing all metrics' regression objectives/losses. However, our empirical study uncovers the prevalence of conflicts among metrics' regression objectives, causing MTS models to grapple with different losses. This critical aspect significantly impacts detection performance but has been overlooked in existing approaches. To address this problem, by mimicking the design of multi-gate mixture-of-experts (MMoE), we introduce CAD, a Conflict-aware multivariate KPI Anomaly Detection algorithm. CAD offers an exclusive structure for each metric to mitigate potential conflicts while fostering inter-metric promotions. Upon thorough investigation, we find that the poor performance of vanilla MMoE mainly comes from the input-output misalignment settings of MTS formulation and convergence issues arising from expansive tasks. To address these challenges, we propose a straightforward yet effective task-oriented metric selection and p&s (personalized and shared) gating mechanism, which establishes CAD as the first practicable multi-task learning (MTL) based MTS AD model. Evaluations on multiple public datasets reveal that CAD obtains an average F1-score of 0.943 across three public datasets, notably outperforming state-of-the-art methods. Our code is accessible at https://github.com/dawnvince/MTS_CAD.
</details>
<details>
<summary>摘要</summary>
巨大的关键性能指标 (KPI) 被监测为多变量时间序列数据 (MTS)，以确保软件应用程序和服务系统的可靠性。正确地探测 MTS 中的异常是非常关键的，以便后续的故障排除。由于罕见的异常和手动标注的缺乏，已经导致了多种无监督 MTS 异常检测 (AD) 方法的发展，这些方法通过优化总体的目标/损失函数来优化所有指标的回归目标/损失函数。然而，我们的实验发现，在不同指标之间存在冲突的问题，导致 MTS 模型在不同的损失函数之间挣扎。这种问题在现有方法中受到了忽略。为解决这个问题，我们通过模仿多门混合专家 (MMoE) 的设计，引入 CAD，即冲突意识多变量 KPI 异常检测算法。CAD 提供了每个指标 exclusive 结构，以mitigate 可能的冲突，同时推动指标之间的促进。经过全面的调查，我们发现，简单的 MMoE 的 Poor 性能主要来自 MTS 表示形式的输入-输出不一致和扩展任务的准确性问题。为解决这些挑战，我们提议一种简单 yet 有效的任务意向指标选择和人性化分配机制，使 CAD 成为首个实用多任务学习 (MTL) 基于 MTS AD 模型。多个公共数据集的评估显示，CAD 在三个公共数据集上的平均 F1-score 为 0.943，显著超过当前state-of-the-art方法。我们的代码可以在 GitHub 上找到：https://github.com/dawnvince/MTS_CAD。
</details></li>
</ul>
<hr>
<h2 id="MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling"><a href="#MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling" class="headerlink" title="MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling"></a>MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09725">http://arxiv.org/abs/2308.09725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai</li>
<li>for: 这个论文目的是使用多Omics数据来改进肿瘤分型结果，以便更好地了解肿瘤的发展机理。</li>
<li>methods: 该论文使用了一种名为MoCLIM的表示学习框架，通过独立提取不同Omics模式下的有用特征，并使用这些特征进行归一化，以便更好地分类肿瘤。</li>
<li>results: 实验结果表明，使用MoCLIM方法可以提高肿瘤分型结果的数据适应度和分类性能，并且可以在 fewer 高维度肿瘤实例中提供更高的解释性。<details>
<summary>Abstract</summary>
Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances. Moreover, our framework incorporates various medical evaluations as the final component, providing high interpretability in medical analysis.
</details>
<details>
<summary>摘要</summary>
基于精准医学的研究旨在确立肿瘤Subtype与生物化学过程的缺陷关系。ómics技术在肿瘤分类方面发挥了革命性的作用，不同的ómics数据记录了肿瘤的生物化学产物。本文将关注在完全利用多个ómics数据来提高肿瘤分类效果，并因此开发了MoCLIM表示学框架。MoCLIM独立提取不同ómics模式中的有用特征。通过对不同ómics模式的对比学习，我们可以将肿瘤分类到一个较低的 latent space。这种对比可以被解释为生物网络中跨modalities的推理。实验结果表明，我们的方法可以在六个肿瘤数据集中显著提高数据适应度和肿瘤分类性能，并且我们的框架可以 incorporate多种医学评估作为最后一个组件，提供高度可解释的医学分析。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain"><a href="#Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain" class="headerlink" title="Development of a Knowledge Graph Embeddings Model for Pain"></a>Development of a Knowledge Graph Embeddings Model for Pain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08904">http://arxiv.org/abs/2308.08904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaya Chaturvedi, Tao Wang, Sumithra Velupillai, Robert Stewart, Angus Roberts</li>
<li>for: 本研究的目的是构建一个知识图谱模型，用于理解抑郁症患者的痛苦经验。</li>
<li>methods: 本研究使用了知识图谱embedding技术，将痛苦相关的概念与关系从外部医学知识库中提取，并与电子医疗记录中的痛苦实例进行结合。</li>
<li>results: 研究结果显示，使用知识图谱embedding模型可以提高预测痛苦相关的Subject-Object链接任务的性能，比基eline模型更高。<details>
<summary>Abstract</summary>
Pain is a complex concept that can interconnect with other concepts such as a disorder that might cause pain, a medication that might relieve pain, and so on. To fully understand the context of pain experienced by either an individual or across a population, we may need to examine all concepts related to pain and the relationships between them. This is especially useful when modeling pain that has been recorded in electronic health records. Knowledge graphs represent concepts and their relations by an interlinked network, enabling semantic and context-based reasoning in a computationally tractable form. These graphs can, however, be too large for efficient computation. Knowledge graph embeddings help to resolve this by representing the graphs in a low-dimensional vector space. These embeddings can then be used in various downstream tasks such as classification and link prediction. The various relations associated with pain which are required to construct such a knowledge graph can be obtained from external medical knowledge bases such as SNOMED CT, a hierarchical systematic nomenclature of medical terms. A knowledge graph built in this way could be further enriched with real-world examples of pain and its relations extracted from electronic health records. This paper describes the construction of such knowledge graph embedding models of pain concepts, extracted from the unstructured text of mental health electronic health records, combined with external knowledge created from relations described in SNOMED CT, and their evaluation on a subject-object link prediction task. The performance of the models was compared with other baseline models.
</details>
<details>
<summary>摘要</summary>
痛苦是一个复杂的概念，可以与其他概念相互连接，如疾病、药物等，以全面理解个人或人口群体的痛苦经验。为了实现这一目标，我们需要检视所有与痛苦相关的概念和他们之间的关系。这非常有用，特别是在模拟基于电子医疗记录的痛苦记录时。知识图表示概念和其关系为相互连接的网络，允许semantic和上下文基本的推理。但这些图可能太大，不可靠性Compute。知识图嵌入帮助解决这一问题，将知识图 Represented in一个低维度的向量空间。这些嵌入可以在多种下游任务中使用，如分类和链接预测。关于痛苦的各种关系，可以从外部的医疗知识库，如SNOMED CT，获取。SNOMED CT是一个层次的系统性词汇表，用于医学术语。通过将这些知识库与电子医疗记录中的实际痛苦例子相结合，可以构建更加完整的知识图。这篇论文描述了基于痛苦概念的知识图嵌入模型的建构，从精神医疗电子记录中提取的概念和SNOMED CT中的外部知识进行组合，以及这些模型在主题-对象链接预测任务上的评估。与其他基eline模型相比，这些模型的性能如何呢？
</details></li>
</ul>
<hr>
<h2 id="Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning"><a href="#Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning" class="headerlink" title="Optimal Resource Allocation for U-Shaped Parallel Split Learning"></a>Optimal Resource Allocation for U-Shaped Parallel Split Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08896">http://arxiv.org/abs/2308.08896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Lyu, Zheng Lin, Guanqiao Qu, Xianhao Chen, Xiaoxia Huang, Pan Li<br>for: 这paper是为了解决 tradicional的 Split Learning（SL）方法会泄露标签隐私的问题，提出了U-shaped网络的使用来保护标签隐私。methods: 该paper使用了U-shaped网络和Parallel Split Learning（PSL）技术，并提出了一种名为LSCRA的资源分配算法来优化边缘网络的性能。results: 该paper的实验结果表明，LSCRA算法可以有效地分配资源和Split层，并且U-shaped PSL可以与其他SL基线方法具有相似的性能而又保护标签隐私。<details>
<summary>Abstract</summary>
Split learning (SL) has emerged as a promising approach for model training without revealing the raw data samples from the data owners. However, traditional SL inevitably leaks label privacy as the tail model (with the last layers) should be placed on the server. To overcome this limitation, one promising solution is to utilize U-shaped architecture to leave both early layers and last layers on the user side. In this paper, we develop a novel parallel U-shaped split learning and devise the optimal resource optimization scheme to improve the performance of edge networks. In the proposed framework, multiple users communicate with an edge server for SL. We analyze the end-to-end delay of each client during the training process and design an efficient resource allocation algorithm, called LSCRA, which finds the optimal computing resource allocation and split layers. Our experimental results show the effectiveness of LSCRA and that U-shaped PSL can achieve a similar performance with other SL baselines while preserving label privacy. Index Terms: U-shaped network, split learning, label privacy, resource allocation, 5G/6G edge networks.
</details>
<details>
<summary>摘要</summary>
Split learning (SL) 已经出现为训练模型无需披露原始数据样本的有效方法。然而，传统的 SL 必然泄露标签隐私，因为tail模型（最后层）必须放置在服务器上。为解决这个限制，一种有前途的解决方案是使用 U 型架构，留下 Early layers 和 Last layers 在用户端。在本文中，我们开发了一种新的平行 U 型 Split Learning 框架，并设计了最佳资源优化策略，以提高边缘网络的性能。在我们的提案中，多个用户与边缘服务器进行 SL 通信。我们分析每个客户端在训练过程中的末端延迟，并设计了一个高效的资源分配算法，称为 LSCRA，以找到最佳计算资源分配和分割层。我们的实验结果表明 LSCRA 的效果和 U 型 PSL 可以在保持标签隐私的情况下实现相似的性能。关键字： U 型网络、Split learning、标签隐私、资源分配、5G/6G 边缘网络。
</details></li>
</ul>
<hr>
<h2 id="Dual-Gauss-Newton-Directions-for-Deep-Learning"><a href="#Dual-Gauss-Newton-Directions-for-Deep-Learning" class="headerlink" title="Dual Gauss-Newton Directions for Deep Learning"></a>Dual Gauss-Newton Directions for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08886">http://arxiv.org/abs/2308.08886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincent Roulet, Mathieu Blondel</li>
<li>for: 提高深度学习优化算法的精度和效率</li>
<li>methods: 基于半线性化的对象结构，使用对数损失函数和非线性网络的复合，计算更好的方向指标，而不是渐进随机梯度</li>
<li>results: 实验表明，使用对数损失函数和非线性网络的复合，可以获得更好的下降方向指标，并且可以用现有的优化算法中的梯度更新Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to improve the accuracy and efficiency of deep learning optimization algorithms by leveraging the structure of deep learning objectives.</li>
<li>methods: The authors propose to compute better direction oracles using the dual formulation of the objective function, which leads to both computational benefits and new insights.</li>
<li>results: The experimental results show that using the dual formulation of the objective function, combined with the composition of a convex loss function and a nonlinear network, can lead to better descent directions that can be used as a drop-in replacement for stochastic gradients in existing optimization algorithms.<details>
<summary>Abstract</summary>
Inspired by Gauss-Newton-like methods, we study the benefit of leveraging the structure of deep learning objectives, namely, the composition of a convex loss function and of a nonlinear network, in order to derive better direction oracles than stochastic gradients, based on the idea of partial linearization. In a departure from previous works, we propose to compute such direction oracles via their dual formulation, leading to both computational benefits and new insights. We demonstrate that the resulting oracles define descent directions that can be used as a drop-in replacement for stochastic gradients, in existing optimization algorithms. We empirically study the advantage of using the dual formulation as well as the computational trade-offs involved in the computation of such oracles.
</details>
<details>
<summary>摘要</summary>
受加ус-牛顿方法启发，我们研究利用深度学习目标结构的优点，即几何函数和抽象网络的复合，以 derive better direction oracles than stochastic gradients，基于partial linearization的想法。在之前的工作中，我们提议通过对 dual 形式来计算这些方向指南，从而实现计算上的收益和新的理解。我们证明这些方向指南可以作为现有优化算法中的替补，以及计算这些方向指南的计算成本和计算质量的负担。我们进行了实验研究，证明使用 dual 形式的计算具有优势，并且计算成本和计算质量的负担存在trade-off关系。
</details></li>
</ul>
<hr>
<h2 id="Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task"><a href="#Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task" class="headerlink" title="Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task"></a>Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08873">http://arxiv.org/abs/2308.08873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Jahaninasab, Mohamad Ali Bijarchi</li>
<li>for:  This paper is written for solving partial differential equations (PDEs) with a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN).</li>
<li>methods:  The FE-PINN framework uses a sequence of sub-tasks to learn useful features about the underlying physics and then refine the calculations for the target task.</li>
<li>results:  The FE-PINN framework achieves 15x, 2x, and 5x speed up for three benchmarks (flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity) compared to vanilla PINN, and can reach a loss value near 1e-5, which is challenging for vanilla PINN.Here is the simplified Chinese text for the three key information points:</li>
<li>for: 这篇论文是为解决部分 diferencial 方程（PDEs）而编写的，使用一种新的数据自由框架called Feature Enforcing Physics Informed Neural Network (FE-PINN)。</li>
<li>methods:  FE-PINN 框架使用一个序列的子任务来学习有用的物理特征，然后为目标任务进行精细的计算。</li>
<li>results: FE-PINN 框架在三个 benchmark（流过cylinder，2D heat conduction，和反向问题计算入口速度）中实现了15倍，2倍，和5倍的速度提升，并可以达到1e-5的损失值，这是vanilla PINN 困难的。<details>
<summary>Abstract</summary>
In this work, a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN) is introduced. This framework is capable of learning the underlying pattern of any problem with low computational cost before the main training loop. The loss function of vanilla PINN due to the existence of two terms of partial differential residuals and boundary condition mean squared error is imbalanced. FE-PINN solves this challenge with just one minute of training instead of time-consuming hyperparameter tuning for loss function that can take hours. The FE-PINN accomplishes this process by performing a sequence of sub-tasks. The first sub-task learns useful features about the underlying physics. Then, the model trains on the target task to refine the calculations. FE-PINN is applied to three benchmarks, flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity. FE-PINN can solve each case with, 15x, 2x, and 5x speed up accordingly. Another advantage of FE-PINN is that reaching lower order of value for loss function is systematically possible. In this study, it was possible to reach a loss value near 1e-5 which is challenging for vanilla PINN. FE-PINN also has a smooth convergence process which allows for utilizing higher learning rates in comparison to vanilla PINN. This framework can be used as a fast, accurate tool for solving a wide range of Partial Differential Equations (PDEs) across various fields.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了一种新的数据自由框架，即特征强制物理学 Informed Neural Network（FE-PINN）。这个框架可以在低计算成本下学习问题的下面 patrern。这个框架通过一系列子任务来实现。首先，它学习问题的下面特征。然后，模型在目标任务上进行反射计算。FE-PINN应用于三个标准测试函数，即流过圆柱、2D热传导和反向问题计算入口速度。FE-PINN可以在每个情况下提高计算速度15倍、2倍和5倍。此外，FE-PINN可以系统地降低损失函数的值。在这项研究中，我们可以达到一个损失值附近1e-5，这是vanilla PINN很困难的。FE-PINN也有平滑的收敛过程，因此可以在vanilla PINN的比例上使用更高的学习率。这个框架可以作为解决各种 partial Differential Equations（PDEs）的快速、准确的工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels"><a href="#Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels" class="headerlink" title="Towards Semi-supervised Learning with Non-random Missing Labels"></a>Towards Semi-supervised Learning with Non-random Missing Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08872">http://arxiv.org/abs/2308.08872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njuyued/prg4ssl-mnar">https://github.com/njuyued/prg4ssl-mnar</a></li>
<li>paper_authors: Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</li>
<li>for: 本文 targets the problem of label missing not at random (MNAR) in semi-supervised learning (SSL), and proposes a class transition tracking based Pseudo-Rectifying Guidance (PRG) method to improve the performance of SSL models in MNAR scenarios.</li>
<li>methods: 本文使用的方法包括Markov随机游走模型和动态创建的类追踪矩阵，以及基于这些信息的PRG方法，来维护模型的偏好性和类分布的历史信息，从而提高SSL模型在MNAR场景中的性能。</li>
<li>results: 本文的实验结果表明，PRG方法可以在多种MNAR场景中显著超过latest SSL方法组合偏移解决方案的性能，并且在各种极端场景下都能够保持良好的性能。<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data. While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distributions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details>
<details>
<summary>摘要</summary>
semi-supervised learning (SSL)  solves the problem of missing labels by using unlabeled data effectively. However, existing SSL methods mostly focus on the traditional setting and ignore the practical and challenging scenario of label Missing Not At Random (MNAR). In MNAR, the labeled and unlabeled data are in different class distributions, leading to biased label imputation and degrading the performance of SSL models. In this work, we propose class transition tracking based Pseudo-Rectifying Guidance (PRG) for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details></li>
</ul>
<hr>
<h2 id="Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games"><a href="#Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games" class="headerlink" title="Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games"></a>Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08858">http://arxiv.org/abs/2308.08858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songtao Feng, Ming Yin, Yu-Xiang Wang, Jing Yang, Yingbin Liang</li>
<li>for: 这个论文主要研究的是在多智能RL中的两参与 Zero-Sum Markov Game 问题，具体来说是在有限时间循环 Markov Decision Processes 中。</li>
<li>methods: 该论文提出了一种基于Stage-based Q-学习算法的模型自由方法，并证明了该算法可以达到最佳的 $\epsilon $-优 Nash Equilibrium 的样本复杂度为 $O(H^3SAB&#x2F;\epsilon^2) $，这是在 $H $ 和 $S $ 上依赖的最佳。</li>
<li>results: 该论文展示了该算法可以达到模型基于算法的最佳性，并且在 $H $ 上依赖的部分提高了模型自由算法的样本复杂度。此外，该论文还提出了一种新的 referential advantage decomposition 技术，以提高样本效率。<details>
<summary>Abstract</summary>
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by leveraging the popular variance reduction technique based on the reference-advantage decomposition previously used only for single-agent RL. However, such a technique relies on a critical monotonicity property of the value function, which does not hold in Markov games due to the update of the policy via the coarse correlated equilibrium (CCE) oracle. Thus, to extend such a technique to Markov games, our algorithm features a key novel design of updating the reference value functions as the pair of optimistic and pessimistic value functions whose value difference is the smallest in the history in order to achieve the desired improvement in the sample efficiency.
</details>
<details>
<summary>摘要</summary>
“两个玩家零游戏马克夫游戏（Markov game）的问题在多智能抽象学习（multi-agent reinforcement learning，RL）中得到了越来越多的关注。特别是在有限时间剪辑Markov决策过程（MDP）中，已经证明了使用模型基本算法可以在$\epsilon$-优 NashEquilibrium（NE）中找到$O(H^3SAB/\epsilon^2)$的样本复杂度，这是在$H$和$S$上依赖的最优性。然而，现有的模型自由算法无法达到这种优化。在这个工作中，我们提出了一种模型自由阶段Q学习算法，并证明它可以 дости到最优的$H$依赖性。这个主要的改进来自于使用单个智能RL中广泛使用的参考优势分解技术，但这种技术需要Markov游戏中值函数的幂等性，这并不是真实存在的。因此，我们的算法具有一个关键的新特点，即在历史中更新参考值函数为最小值差的对，以实现所需的样本效率提高。”
</details></li>
</ul>
<hr>
<h2 id="Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays"><a href="#Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays" class="headerlink" title="Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays"></a>Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08853">http://arxiv.org/abs/2308.08853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Hong, Tianjie Dai, Jiangchao Yao, Ya Zhang, Yanfeng Wang</li>
<li>for: 这个研究旨在提高胸部X射镜（CXR）诊断的准确性，探讨了许多进步设计，如数据增强、特征提取、分类器设计、损失函数重新配置、外部数据补充等。</li>
<li>methods: 这个研究使用了多种进步设计，包括数据增强、特征提取、分类器设计、损失函数重新配置、外部数据补充等。</li>
<li>results: 这个研究获得了0.349 mAP的成绩，位居评比测试集的前五名。<details>
<summary>Abstract</summary>
Clinical classification of chest radiography is particularly challenging for standard machine learning algorithms due to its inherent long-tailed and multi-label nature. However, few attempts take into account the coupled challenges posed by both the class imbalance and label co-occurrence, which hinders their value to boost the diagnosis on chest X-rays (CXRs) in the real-world scenarios. Besides, with the prevalence of pretraining techniques, how to incorporate these new paradigms into the current framework lacks of the systematical study. This technical report presents a brief description of our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness for CXR diagnosis with the integration of several advanced designs about data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details>
<details>
<summary>摘要</summary>
严重疾病分类在胸部X射影图（CXR）中是特别挑战，主要因为它具有自然长尾和多标签性。然而，少数尝试不足以考虑这两个挑战的结合，从而限制其在实际场景中的价值。此外，随着预训练技术的普及，如何在当前框架中 integrate these new paradigms lacks systematic study.本技术报告 briefly describes our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness of CXR diagnosis with the integration of several advanced designs, including data augmentation, feature extraction, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improved the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details></li>
</ul>
<hr>
<h2 id="Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm"><a href="#Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm" class="headerlink" title="Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm"></a>Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08852">http://arxiv.org/abs/2308.08852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjing Wang, Peipei Tang, Wenling He, Meixia Lin</li>
<li>for:  efficiently estimate graphical models with hub nodes in large datasets</li>
<li>methods:  dual alternating direction method of multipliers (ADMM) and semismooth Newton (SSN) based augmented Lagrangian method (ALM)</li>
<li>results:  significantly outperforms existing state-of-the-art algorithms in terms of execution time and estimation accuracy, with savings of up to 70% in some high-dimensional tasks.<details>
<summary>Abstract</summary>
Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. The sparsity structure of the generalized Jacobian ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still achieves a high-quality estimation.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：</SYS>图形模型在各种任务中表现出色，从生物分析到推荐系统。然而，含有中心节点的图形模型在大量数据时 computationally 难以适应。为了高效地估算中心图形模型，我们提出了两阶段算法。我们的算法首先使用对偶替代方法（ADMM）生成一个良好的初始点，然后使用增强的均值法（SSN）基于扩展拉格朗日方法（ALM）计算一个精度足够高的解决方案。通过各个稀疏结构的总导数，我们的算法可以很快地获得一个高质量的解决方案。实验表明，我们的算法在各种高维任务中可以 saves more than 70% 的执行时间，同时仍然达到高质量的估算。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation"><a href="#Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation" class="headerlink" title="Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation"></a>Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08841">http://arxiv.org/abs/2308.08841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Savage, Nausheen Basha, Jonathan McDonough, Omar K Matar, Ehecatl Antonio del Rio Chanona</li>
<li>for: 这 paper 的目的是设计、优化和制造以下一代化学反应器。</li>
<li>methods: 这 paper 使用了多级 Bayesian 优化法，以优化各种不同的尺度和曲线路径，从而实现高维度、复杂的优化问题。</li>
<li>results: 这 paper 通过 maximizing 填充流性能，提出了两种新的卷积管 geometries，并通过 3D 打印和实验验证了它们的可靠性和性能。<details>
<summary>Abstract</summary>
Additive manufacturing has enabled the production of more advanced reactor geometries, resulting in the potential for significantly larger and more complex design spaces. Identifying and optimising promising configurations within broader design spaces presents a significant challenge for existing human-centric design approaches. As such, existing parameterisations of coiled-tube reactor geometries are low-dimensional with expensive optimisation limiting more complex solutions. Given algorithmic improvements and the onset of additive manufacturing, we propose two novel coiled-tube parameterisations enabling the variation of cross-section and coil path, resulting in a series of high dimensional, complex optimisation problems. To ensure tractable, non-local optimisation where gradients are not available, we apply multi-fidelity Bayesian optimisation. Our approach characterises multiple continuous fidelities and is coupled with parameterised meshing and simulation, enabling lower quality, but faster simulations to be exploited throughout optimisation. Through maximising the plug-flow performance, we identify key characteristics of optimal reactor designs, and extrapolate these to produce two novel geometries that we 3D print and experimentally validate. By demonstrating the design, optimisation, and manufacture of highly parameterised reactors, we seek to establish a framework for the next-generation of reactors, demonstrating that intelligent design coupled with new manufacturing processes can significantly improve the performance and sustainability of future chemical processes.
</details>
<details>
<summary>摘要</summary>
“三维打印技术的出现已经使得反应室的设计空间得以扩大，并且可以实现更复杂的设计。但是，对于现有的人类中心设计方法来说，identifying和优化promising配置在更广泛的设计空间中是一项具有挑战性的任务。因此，现有的环形管径参数化方法都是低维的，并且优化成本较高，不能实现更复杂的解决方案。为了解决这个问题，我们提出了两种新的环形管径参数化方法，允许环形管径的跨section和径路变化，从而导致一系列高维度、复杂的优化问题。为了确保可行的、非本地优化，我们采用多质量抽象 Bayesian 优化方法。我们的方法通过连接多个连续质量的 Bayesian 优化和参数化的笆化和模拟，以便在优化过程中使用较低质量但快速的 simulations。通过最大化插入性性能，我们确定了优化反应室的关键特征，并将其推广到生产两个新的geometry。我们通过3D打印和实验验证这两个geometry，以证明我们的设计、优化和制造方法可以带来未来化学过程的性能和可持续性。”
</details></li>
</ul>
<hr>
<h2 id="ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space"><a href="#ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space" class="headerlink" title="ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space"></a>ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08830">http://arxiv.org/abs/2308.08830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Spieker, Wenqi Huang, Hannah Eichhorn, Jonathan Stelter, Kilian Weiss, Veronika A. Zimmer, Rickmer F. Braren, Dimitrios C. Karampinos, Kerstin Hammernik, Julia A. Schnabel</li>
<li>for: 这份研究旨在提出一种能够生成不受运动噪声影响的高精度腹部MRI重建方法。</li>
<li>methods: 本研究使用神经阶层学习（NIK）来直接在k空间中学习无残差的运动解析，并引入了一个受资料支持的几何调整层（ICo）以正常化NIK的预测。</li>
<li>results: 该方法比标准的运动解析方法表现更好，并且可以获得高精度的腹部MRI重建结果。<details>
<summary>Abstract</summary>
Motion-resolved reconstruction for abdominal magnetic resonance imaging (MRI) remains a challenge due to the trade-off between residual motion blurring caused by discretized motion states and undersampling artefacts. In this work, we propose to generate blurring-free motion-resolved abdominal reconstructions by learning a neural implicit representation directly in k-space (NIK). Using measured sampling points and a data-derived respiratory navigator signal, we train a network to generate continuous signal values. To aid the regularization of sparsely sampled regions, we introduce an additional informed correction layer (ICo), which leverages information from neighboring regions to correct NIK's prediction. Our proposed generative reconstruction methods, NIK and ICoNIK, outperform standard motion-resolved reconstruction techniques and provide a promising solution to address motion artefacts in abdominal MRI.
</details>
<details>
<summary>摘要</summary>
对于腹部磁共振成像（MRI）中的运动解构，仍然是一个挑战，这是因为运动状态的精细化会导致剩下的运动扩散噪声和抽取 artefacts。在这项工作中，我们提议通过直接在 k-空间学习神经网络表示（NIK）来生成无拟合噪声的运动解构。使用测量的抽取点和数据驱动的呼吸导航信号，我们将网络训练出continuous的信号值。为了帮助稀疏抽取区域的正则化，我们引入了一个更正层（ICo），该层利用邻近区域的信息来正则化 NIK 的预测。我们的提出的生成重建方法，NIK 和 ICoNIK，超过了标准的运动解构技术，并提供了Addressing motion artefacts in abdominal MRI 中的一个有前途的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Controlling-Federated-Learning-for-Covertness"><a href="#Controlling-Federated-Learning-for-Covertness" class="headerlink" title="Controlling Federated Learning for Covertness"></a>Controlling Federated Learning for Covertness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08825">http://arxiv.org/abs/2308.08825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adit Jain, Vikram Krishnamurthy</li>
<li>for: 这篇论文目的是探讨一个叫做“covert”或“learner-private”的优化问题，learner要在发生噪音的情况下，通过对应用数据的随机性来隐藏目标函数的最佳值。</li>
<li>methods: 本文使用了Markov decision process来模型问题，并证明了运算的超模统性，这使得找到优化策略的问题可以使用政策条件运算。同时，一个 computationally efficient policy gradient algorithm 是提出来解决问题。</li>
<li>results: 在实际应用中，本文将方法应用在一个联邦学习中的 hate speech 分类任务上，并证明了在使用优化策略时，一个 eavesdropper 只能在没有信息的情况下取得52%的验证率，对比之下，在有10%阳性数据的情况下，eavesdropper 只能取得69%的验证率，而且这些结果较好于使用单纯的 greedy 策略。<details>
<summary>Abstract</summary>
A learner aims to minimize a function $f$ by repeatedly querying a distributed oracle that provides noisy gradient evaluations. At the same time, the learner seeks to hide $\arg\min f$ from a malicious eavesdropper that observes the learner's queries. This paper considers the problem of \textit{covert} or \textit{learner-private} optimization, where the learner has to dynamically choose between learning and obfuscation by exploiting the stochasticity. The problem of controlling the stochastic gradient algorithm for covert optimization is modeled as a Markov decision process, and we show that the dynamic programming operator has a supermodular structure implying that the optimal policy has a monotone threshold structure. A computationally efficient policy gradient algorithm is proposed to search for the optimal querying policy without knowledge of the transition probabilities. As a practical application, our methods are demonstrated on a hate speech classification task in a federated setting where an eavesdropper can use the optimal weights to generate toxic content, which is more easily misclassified. Numerical results show that when the learner uses the optimal policy, an eavesdropper can only achieve a validation accuracy of $52\%$ with no information and $69\%$ when it has a public dataset with 10\% positive samples compared to $83\%$ when the learner employs a greedy policy.
</details>
<details>
<summary>摘要</summary>
学生希望减少函数 $f$ 的值，通过 repeatedly 请求分布式 oracle 提供噪声梯度评估。同时，学生尝试隐藏 $\arg\min f$ 于一个恶意窃听者，该窃听者可以观察学生的查询。这篇论文考虑了“隐蔽”或“学习者私有”优化问题，学生需要在执行权重学习和隐蔽之间 dynamically 选择。在模型中，我们使用 Markov 决策过程来控制权重学习的执行，并证明了优化算法的动态程序拥有超模ular结构，表示优化策略的最优策略具有垂直阈值结构。我们提出了一种 Computational 效率的策略梯度算法，可以无需知情转移概率进行搜索优化策略。在实际应用中，我们将方法应用于一个联合 Setting 中的 hate speech 分类任务，恶意窃听者可以使用最优策略生成毒品，这些毒品更容易被误分类。实际结果表明，当学生使用优化策略时，恶意窃听者只能在没有信息的情况下达到52%的验证精度，并且在拥有10%正样本的情况下达到69%的验证精度，与学生使用响应策略相比，恶意窃听者的验证精度提高了21个百分点。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning"><a href="#Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning" class="headerlink" title="Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning"></a>Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08823">http://arxiv.org/abs/2308.08823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianmeng Yang, Min Zhou, Yujing Wang, Zhengjie Lin, Lujia Pan, Bin Cui, Yunhai Tong<br>for: 本文targets to improve the performance of Graph Neural Networks (GNNs) by addressing the challenge of semantic confusion in graph active learning (GAL).methods: 本文提出了一个Semantic-aware Active learning framework for Graphs (SAG)，包括引入节点相似度和不相似度，jointly evaluate node influence，并设计了一种新的原型基于 criterion和查询策略来保持节点选择的多样性和分类均衡。results: 对于公共 benchmark graphs 和一个实际世界金融数据集，SAGsignificantly improves node classification performance，并常常超过先前的方法。此外，广泛的分析和剥离研究也证明了提案的效果。<details>
<summary>Abstract</summary>
Graph Active Learning (GAL), which aims to find the most informative nodes in graphs for annotation to maximize the Graph Neural Networks (GNNs) performance, has attracted many research efforts but remains non-trivial challenges. One major challenge is that existing GAL strategies may introduce semantic confusion to the selected training set, particularly when graphs are noisy. Specifically, most existing methods assume all aggregating features to be helpful, ignoring the semantically negative effect between inter-class edges under the message-passing mechanism. In this work, we present Semantic-aware Active learning framework for Graphs (SAG) to mitigate the semantic confusion problem. Pairwise similarities and dissimilarities of nodes with semantic features are introduced to jointly evaluate the node influence. A new prototype-based criterion and query policy are also designed to maintain diversity and class balance of the selected nodes, respectively. Extensive experiments on the public benchmark graphs and a real-world financial dataset demonstrate that SAG significantly improves node classification performances and consistently outperforms previous methods. Moreover, comprehensive analysis and ablation study also verify the effectiveness of the proposed framework.
</details>
<details>
<summary>摘要</summary>
格Active学习（GAL），旨在找到图中最有信息的节点进行标注，以最大化图神经网络（GNNs）性能，已经吸引了许多研究努力，但仍存在许多挑战。一个主要挑战是现有的GAL策略可能会在选择训练集时引入semantic confusion，特别是当图像具有噪音时。在这种情况下，大多数现有方法假设所有聚合特征都是有用的，忽略了间类边缘下的semantic负面效果。在这个工作中，我们提出了Semantic-aware Active learning framework for Graphs（SAG），以 Mitigate semantic confusion problem。节点之间的对比性和不同性以及semantic特征被引入，以共同评估节点的影响力。一个新的原型基本 критерион和查询策略也被设计，以保持节点的多样性和分类均衡。经过对公共的benchmark图和一个真实世界的金融 dataset的广泛实验，我们发现SAG可以明显提高节点的分类性能，并常常超过先前的方法。此外，广泛的分析和减少研究也证明了提案的效果。
</details></li>
</ul>
<hr>
<h2 id="A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction"><a href="#A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction" class="headerlink" title="A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction"></a>A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08812">http://arxiv.org/abs/2308.08812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchar Palit, Sandika Biswas</li>
<li>for: 这个论文的目的是提出一种基于 kontinual learning的单图三维重建方法，以便在新类的训练中仍能reasonably重建之前见类。</li>
<li>methods: 该方法使用Variational Priors来表示抽象形态，并使用saliency map来保留物体特征，从而降低存储训练数据的资源成本。</li>
<li>results: 经过进行了严格的实验，该方法与已知方法相比，具有竞争的Result， both quantitatively and qualitatively。<details>
<summary>Abstract</summary>
Single-image 3D reconstruction is a research challenge focused on predicting 3D object shapes from single-view images. This task requires significant data acquisition to predict both visible and occluded portions of the shape. Furthermore, learning-based methods face the difficulty of creating a comprehensive training dataset for all possible classes. To this end, we propose a continual learning-based 3D reconstruction method where our goal is to design a model using Variational Priors that can still reconstruct the previously seen classes reasonably even after training on new classes. Variational Priors represent abstract shapes and combat forgetting, whereas saliency maps preserve object attributes with less memory usage. This is vital due to resource constraints in storing extensive training data. Additionally, we introduce saliency map-based experience replay to capture global and distinct object features. Thorough experiments show competitive results compared to established methods, both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
单图3D重建是一个研究挑战，旨在根据单个图像预测3D物体形状。这项任务需要大量数据收集，以预测可见和遮盖的部分。学习基本方法面临的挑战是创建所有可能的类型的完整训练集。为此，我们提出了一种基于不断学习的3D重建方法，其目标是使用可变假设来设计一个可以在训练新类后仍然理解先前看到的类的模型。可变假设表示抽象形状，并避免忘记，而精灵图保留物体特征，减少存储训练数据的内存占用。此外，我们引入精灵图经验回放，以捕捉全局和特定的物体特征。经验表明，我们的方法与已知方法相比，具有竞争力的result。
</details></li>
</ul>
<hr>
<h2 id="Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts"><a href="#Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts" class="headerlink" title="Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts"></a>Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08810">http://arxiv.org/abs/2308.08810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun</li>
<li>for: 这个论文的目的是要在推断过程中进行测试时适应（Test-time adaptation，TTA），并且能够处理类别分布的不均匀。</li>
<li>methods: 这个论文使用了一种新的类别shift adapter，可以与现有的TTA方法结合，以便在推断过程中处理类别分布的不均匀。</li>
<li>results: 这个论文的实验结果显示， integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation"><a href="#Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation" class="headerlink" title="Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation"></a>Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08799">http://arxiv.org/abs/2308.08799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingxiaoyi/pare">https://github.com/jingxiaoyi/pare</a></li>
<li>paper_authors: Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen</li>
<li>for: The paper aims to address the issue of item popularity in recommendation systems and proposes a novel approach called Popularity-Aware Recommender (PARE) to make non-personalized recommendations.</li>
<li>methods: PARE consists of four modules: popularity history, temporal impact, periodic impact, and side information, which are combined using an attention layer. The approach explicitly models item popularity and does not rely on personalized user preferences.</li>
<li>results: The paper reports that PARE performs on par or even better than state-of-the-art recommendation methods in extensive experiments. Additionally, integrating PARE with existing recommendation methods significantly improves performance, demonstrating its potential as a complementary component.Here’s the Simplified Chinese text version of the three key points:</li>
<li>for: 这篇论文目标是解决推荐系统中的item Popularity问题，并提出了一种新的方法 Popularity-Aware Recommender (PARE)，以非个人化的方式为用户提供推荐。</li>
<li>methods: PARE包括四个模块： popularity history、temporal impact、 periodic impact 和 side information，这些模块通过注意层结合。该方法Explicitly models item popularity，不依赖个人化用户偏好。</li>
<li>results: 论文Reported that PARE在广泛的实验中表现了与当前领先的推荐方法相当或更好的表现。此外，将PARE与现有的推荐方法集成显著提高了性能， демонстрируя其作为补充组件的潜在价值。<details>
<summary>Abstract</summary>
Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.
</details>
<details>
<summary>摘要</summary>
“推荐系统在过去几年中得到了不断的研究注意力。现有大多数推荐方法强调用户个人化偏好，可能会侵犯用户隐私。此外，这些方法经常忽略 Item 的时间影响和周期性，这可能会影响用户的决策。为了填补这个 gap，我们提出了 Popularity-Aware Recommender（PARE），这是一个不个人化的推荐方法，可以预测将在未来具有最高 популярность的 Item。PARE 包括四个模块，每个模块都集中在不同的方面：偏好历史、时间影响、周期影响和副资料。最后，我们使用了注意力层来融合四个模块的出力。我们知道这是第一个明确地模型 Item 的受欢迎程度的推荐系统。我们的实验结果显示，PARE 与现有的先进推荐方法相比，在大多数情况下表现相当或甚至更好。由于 PARE 将受欢迎程度放在用户个人化偏好之前，因此它可以增强现有的推荐方法，成为补充性的一部分。我们的实验显示，将 PARE 与现有的推荐方法结合，可以大幅提高推荐效果，强调 PARE 的潜在价值。此外，PARE 的简单性使其在工业应用中具有实际的实用性，并且成为未来研究的良好基础。”
</details></li>
</ul>
<hr>
<h2 id="Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data"><a href="#Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data" class="headerlink" title="Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data"></a>Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11646">http://arxiv.org/abs/2308.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Chaochao Chen, Weiming Liu, Pengyang Zhou, Huabin Zhu, Shuheng Shen, Weiqiang Wang, Mengling Hu, Yanchao Tan, Xiaolin Zheng</li>
<li>for: 提高 Federated Learning 在非独立 Identical Distribution （non-IID）数据上的效果。</li>
<li>methods: 提出了两个主要模块：本地关系增强（LRA）和全局纳什平衡（GNE），解决了内部和间接客户端不一致的问题。在每个客户端上，LRA 挖掘出不同数据样本之间的相似关系，并通过帮助函数通信来增强少数据样本的表示。在服务器端，GNE 达成了客户端到服务器端的不一致和不同模型偏差的协调，使全局模型在不破坏客户端优化向本地优化的情况下更新。</li>
<li>results: 通过在四个benchmark数据集上进行了广泛的实验，证明了 FedRANE 在非独立 Identical Distribution 数据上提高 Federated Learning 的性能。<details>
<summary>Abstract</summary>
Federated learning (FL) is a distributed machine learning paradigm that needs collaboration between a server and a series of clients with decentralized data. To make FL effective in real-world applications, existing work devotes to improving the modeling of decentralized data with non-independent and identical distributions (non-IID). In non-IID settings, there are intra-client inconsistency that comes from the imbalanced data modeling, and inter-client inconsistency among heterogeneous client distributions, which not only hinders sufficient representation of the minority data, but also brings discrepant model deviations. However, previous work overlooks to tackle the above two coupling inconsistencies together. In this work, we propose FedRANE, which consists of two main modules, i.e., local relational augmentation (LRA) and global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency simultaneously. Specifically, in each client, LRA mines the similarity relations among different data samples and enhances the minority sample representations with their neighbors using attentive message passing. In server, GNE reaches an agreement among inconsistent and discrepant model deviations from clients to server, which encourages the global model to update in the direction of global optimum without breaking down the clients optimization toward their local optimums. We conduct extensive experiments on four benchmark datasets to show the superiority of FedRANE in enhancing the performance of FL with non-IID data.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式机器学习 paradigma，需要服务器和多个客户端之间的合作，以进行分布式数据的机器学习。为了在实际应用中使 FL 更加有效，现有的工作是针对非独立和非同分布 (non-IID) 的数据进行模型化。在 non-IID  Setting 中，存在客户端内的不均匀数据模型，以及客户端间的不一致性，这不仅会阻碍缺乏表征少数据的充分表示，而且会导致模型偏差的不一致。然而，先前的工作忽视了对上述两种结合不一致的解决。在这种工作中，我们提出了 FedRANE，它包括两个主要模块：本地关系增强 (LRA) 和全局纳什均衡 (GNE)。具体来说，在每个客户端中，LRA 挖掘不同数据样本之间的相似关系，并通过帮助式消息传递增强少数据表示。在服务器端，GNE 达成客户端间的不一致和不一致的模型偏差协议，使全局模型更新方向全局优点，而不是让客户端的优化方向各自的局部优点。我们在四个 benchmark 数据集上进行了广泛的实验，以示 FedRANE 在非独立和非同分布数据上的突出表现。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations"><a href="#Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations" class="headerlink" title="Bayesian polynomial neural networks and polynomial neural ordinary differential equations"></a>Bayesian polynomial neural networks and polynomial neural ordinary differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10892">http://arxiv.org/abs/2308.10892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Colby Fronk, Jaewoong Yun, Prashant Singh, Linda Petzold</li>
<li>for: 这 paper 是为了解决科学和工程问题中的方程回归问题。</li>
<li>methods: 这 paper 使用了 polynomial neural networks 和 polynomial neural ODEs 两种现代和强大的方法来回归方程。</li>
<li>results: 这 paper 通过开发和验证 Bayesian 推理方法（包括 Laplace  aproximation、MCMC 采样方法和 variational inference）来解决 noisy 数据问题。<details>
<summary>Abstract</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.
</details>
<details>
<summary>摘要</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) 是两种最近的和有力的方法，用于解决许多科学和工程问题中的方程回归问题。然而，这些方法只能提供点估计模型参数，并且不能处理噪声数据。我们解决这个挑战，通过开发和验证以下抽象推理方法：拉普拉斯近似法、Markov链 Monte Carlo（MCMC）抽样方法和变分推理法。我们发现，拉普拉斯近似法是这类问题中最佳的方法。我们的工作可以轻松扩展到更广泛的符号神经网络中，其中包括 polynomial neural network。
</details></li>
</ul>
<hr>
<h2 id="Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces"><a href="#Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces" class="headerlink" title="Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces"></a>Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08794">http://arxiv.org/abs/2308.08794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Liu-Schiaffini, Clare E. Singer, Nikola Kovachki, Tapio Schneider, Kamyar Azizzadenesheli, Anima Anandkumar</li>
<li>for: 本研究旨在预测非站立异常变化的演化，例如气候变化导致云覆盖减少的 climatological tipping point。</li>
<li>methods: 本研究使用一种新的循环神经网络算法（RNO）来学习函数空间的映射。通过训练 RNO 只使用前段动力学的数据，然后使用不确定性基于预测法来检测未来的至点。</li>
<li>results: 我们在非站立 ordinary 和 partial differential equations 上测试了我们的提议方法，并在气候至点预测中应用了我们的方法。我们的实验结果表明，即使只使用部分或 approximate physics constraints，仍可以准确预测未来的至点。<details>
<summary>Abstract</summary>
Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.
</details>
<details>
<summary>摘要</summary>
“衰点”是指不断、悬崖式、常常不可逆转变的非站点动力系统的演化。例如，增加绿house气体浓度可能导致低云覆盖率减少，这被称为气候学衰点。在这篇论文中，我们使用一种新的循环神经操作（RNO）来学习函数空间之间的映射。我们在只有前期衰点动力学的训练下使用RNO来检测未来衰点。特别是，我们提出了一种准确预测衰点的极限预测框架，通过监测物理约束（如保守量和部分偏微分方程）的偏差来预测这些急剧变化。我们在非站点常微分方程和部分偏微分方程中应用我们的方法，并在气候衰点中预测云层覆盖率的变化。在我们的实验中，我们表明了只需要部分或 aproximate的物理约束可以准确预测未来衰点。
</details></li>
</ul>
<hr>
<h2 id="Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks"><a href="#Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks" class="headerlink" title="Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks"></a>Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08792">http://arxiv.org/abs/2308.08792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junkai Qian, Yuning Jiang, Xin Liu, Qing Wang, Ting Wang, Yuanming Shi, Wei Chen<br>for: This paper aims to address the challenges of power grid stability and driver privacy in electric vehicle (EV) charging control by proposing a novel approach that combines multi-EV charging&#x2F;discharging with a radial distribution network (RDN) operating under optimal power flow (OPF).methods: The proposed approach uses a mathematical model to describe the RDN load and formulates the EV charging control problem as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. A federated deep reinforcement learning algorithm named FedSAC is further proposed to effectively learn the optimal EV charging control strategy.results: The comprehensive simulation results demonstrate the effectiveness and superiority of the proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.<details>
<summary>Abstract</summary>
With the growing popularity of electric vehicles (EVs), maintaining power grid stability has become a significant challenge. To address this issue, EV charging control strategies have been developed to manage the switch between vehicle-to-grid (V2G) and grid-to-vehicle (G2V) modes for EVs. In this context, multi-agent deep reinforcement learning (MADRL) has proven its effectiveness in EV charging control. However, existing MADRL-based approaches fail to consider the natural power flow of EV charging/discharging in the distribution network and ignore driver privacy. To deal with these problems, this paper proposes a novel approach that combines multi-EV charging/discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A mathematical model is developed to describe the RDN load. The EV charging control problem is formulated as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. To effectively learn the optimal EV charging control strategy, a federated deep reinforcement learning algorithm named FedSAC is further proposed. Comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
</details>
<details>
<summary>摘要</summary>
随着电动汽车（EV）的普及，维护电力网络稳定性已成为一个主要挑战。为解决这个问题，EV充电控制策略已被开发来管理电动汽车的充电和充电模式之间的转换。在这个上下文中，多代理深度学习（MADRL）已经证明其在EV充电控制中的效iveness。然而，现有的MADRL基本方法忽略了电动汽车充电/充电的自然流向和驾驶员隐私。为解决这些问题，本文提出了一种新的方法，即将多个电动汽车充电/充电与径向分布网络（RDN）在优化电力流动（OPF）下进行分布式充电控制。一个数学模型被开发来描述RDN负荷。EV充电控制问题被转化为Markov决策过程（MDP），以找到一个优化充电控制策略，折衔V2G利润、RDN负荷和驾驶员焦虑。为有效地学习优化EV充电控制策略，一种名为FedSAC的联邦深度学习算法被进一步提出。 comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
</details></li>
</ul>
<hr>
<h2 id="APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service"><a href="#APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service" class="headerlink" title="APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service"></a>APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08786">http://arxiv.org/abs/2308.08786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilinghan Li, Shilan He, Pranshu Chaturvedi, Trung-Hieu Hoang, Minseok Ryu, E. A. Huerta, Volodymyr Kindratenko, Jordan Fuhrman, Maryellen Giger, Ryan Chard, Kibaek Kim, Ravi Madduri</li>
<li>for: 本研究旨在提供一个 Privacy-Preserving Federated Learning (PPFL) 平台，帮助无需分享敏感数据就可以协同训练 Robust 和 Generalized Machine Learning (ML) 模型。</li>
<li>methods: 本研究使用 Globus 身份验证技术，让用户轻松地邀请可靠的合作者参与 PPFL，并实现了一些同步和异步 Federated Learning (FL) 算法，简化了 FL 实验启动过程，并允许域专家和 ML 实践者轻松地协调和评估 cross-silo FL。</li>
<li>results: 本研究提供了一个名为 APPFLx 的ready-to-use 平台，可以帮助域专家和 ML 实践者轻松地使用 PPFL 技术进行数据 Privacy 保护和模型训练。APPFLx 在线可以在 <a target="_blank" rel="noopener" href="https://appflx.link/">https://appflx.link</a> 上查看。<details>
<summary>Abstract</summary>
Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models without sharing sensitive (e.g., healthcare of financial) local data. To ease and accelerate the adoption of PPFL, we introduce APPFLx, a ready-to-use platform that provides privacy-preserving cross-silo federated learning as a service. APPFLx employs Globus authentication to allow users to easily and securely invite trustworthy collaborators for PPFL, implements several synchronous and asynchronous FL algorithms, streamlines the FL experiment launch process, and enables tracking and visualizing the life cycle of FL experiments, allowing domain experts and ML practitioners to easily orchestrate and evaluate cross-silo FL under one platform. APPFLx is available online at https://appflx.link
</details>
<details>
<summary>摘要</summary>
cross-silo隐私保护联合学习（PPFL）是一种强大的工具，可以无需分享敏感数据（如医疗或金融）来训练robust和通用机器学习（ML）模型。为了使PPFL更加容易采用，我们引入了APPFLx，一个快速启用的平台，提供隐私保护跨存储 Federated Learning（FL）服务。APPFLx使用Globus身份验证，让用户轻松地邀请可靠的合作者参与PPFL，实现了同步和异步FL算法，简化了FL实验启动过程，并允许域专家和机器学习实践者轻松地进行跨存储FL的导航和评估。APPFLx在线可以在https://appflx.link上访问。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer"><a href="#Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer" class="headerlink" title="Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer"></a>Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09724">http://arxiv.org/abs/2308.09724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang</li>
<li>for: 这篇论文是为了提出一个新的专门领域适应方法，以便在不同领域之间进行精确的预测。</li>
<li>methods: 这篇论文使用了一个名为“知识驱动的子领域适应”（KISA）的新方法，它可以在不同领域之间进行精确的预测。</li>
<li>results: 实验结果显示，KISA在骗案探测和交通需求预测等任务上取得了很好的结果。<details>
<summary>Abstract</summary>
Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details>
<details>
<summary>摘要</summary>
Current state-of-the-art deep domain adaptation methods align source and target samples globally, meaning that each source sample should become similar to any target sample after alignment. However, this global alignment may not always be optimal or necessary in practice. For example, in cross-domain fraud detection, there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may lead to better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable fine-grained domain adaptation, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. Specifically, (1) we provide theoretical insight that KISA minimizes the shared expected loss, which is the premise of domain adaptation methods. (2) we propose a knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) we design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments show that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details></li>
</ul>
<hr>
<h2 id="Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning"><a href="#Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning" class="headerlink" title="Environment Diversification with Multi-head Neural Network for Invariant Learning"></a>Environment Diversification with Multi-head Neural Network for Invariant Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08778">http://arxiv.org/abs/2308.08778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joe0123/EDNIL">https://github.com/joe0123/EDNIL</a></li>
<li>paper_authors: Bo-Wei Huang, Keng-Te Liao, Chang-Sheng Kao, Shou-De Lin</li>
<li>for: 提高模型对不同分布的鲁棒性</li>
<li>methods: 提出了一种基于多头神经网络吸收数据偏见的不变学习框架（EDNIL）</li>
<li>results: 实验表明，使用EDNIL框架可以提高模型对不同分布的鲁棒性，而无需先知环境或强ASSUMEptions about预训练模型。<details>
<summary>Abstract</summary>
Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.
</details>
<details>
<summary>摘要</summary>
神经网络经常使用隐式风险最小化进行训练;然而，已经证明了在训练和测试分布之间的偏移会导致性能下降。为解决这一问题，一种研究方向——抗变异学习——已经被提出，以抽取不受分布变化影响的特征。本研究提出了EDNIL框架，包括多头神经网络来吸收数据偏见。我们表明，这种框架不需要先知环境或强制假设先训练模型。我们还揭示了该算法与最近的研究中关于变异和不变特征的性质有许多理论连接。最后，我们实证表明使用EDNIL训练的模型在分布偏移下的表现更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models"><a href="#Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models" class="headerlink" title="Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models"></a>Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08774">http://arxiv.org/abs/2308.08774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phillip Rust, Anders Søgaard</li>
<li>for: 这些研究目的是为了实现多语言通用性和压缩，以便将模型转移到大量（可能未经见）语言中。</li>
<li>methods: 这些模型使用了 differential privacy，以保证隐私。</li>
<li>results: 研究发现，多语言压缩和语言公正性可以同时满足，但是对于训练数据的影响稀缺性和隐私保证之间存在矛盾。<details>
<summary>Abstract</summary>
Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.
</details>
<details>
<summary>摘要</summary>
语模型如mBERT、XLM-R和BLOOM目的是实现多语言通用或压缩，以便转移至大量（可能未看过）语言。但这些模型应该也是私人、语言公平和透明的，通过与训练数据的关联来预测。可以这些需求同时满足吗？我们表明，多语言压缩和语言公平是与数据隐私相容的，但数据隐私与训练数据影响简洁矛盾。我们进一步对两个常见的NLP任务进行了试验，评估多语言压缩和训练数据影响简洁在不同的隐私保证下，进一步探索这些贸易的细节。我们的结果表明，我们需要开发方法来同时优化这些目标，以寻找实际的贸易。
</details></li>
</ul>
<hr>
<h2 id="Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving"><a href="#Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving" class="headerlink" title="Sensor Fusion by Spatial Encoding for Autonomous Driving"></a>Sensor Fusion by Spatial Encoding for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10707">http://arxiv.org/abs/2308.10707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quoc-Vinh Lai-Dang, Jihui Lee, Bumgeun Park, Dongsoo Har</li>
<li>for: 本研究旨在提出一种用于摄像头和激光雷达数据融合的方法，以提高自动驾驶和机器人感知系统的性能。</li>
<li>methods: 该方法使用Transformer模块在多个分辨率进行融合，以确保地面和高空的上下文关系的有效组合。</li>
<li>results: 对于两个难度最高的 benchmark，提出的方法在训练后显示出了明显的改善，与之前的方法相比，在驾驶和违法分数上分别提高8%和19%。<details>
<summary>Abstract</summary>
Sensor fusion is critical to perception systems for task domains such as autonomous driving and robotics. Recently, the Transformer integrated with CNN has demonstrated high performance in sensor fusion for various perception tasks. In this work, we introduce a method for fusing data from camera and LiDAR. By employing Transformer modules at multiple resolutions, proposed method effectively combines local and global contextual relationships. The performance of the proposed method is validated by extensive experiments with two adversarial benchmarks with lengthy routes and high-density traffics. The proposed method outperforms previous approaches with the most challenging benchmarks, achieving significantly higher driving and infraction scores. Compared with TransFuser, it achieves 8% and 19% improvement in driving scores for the Longest6 and Town05 Long benchmarks, respectively.
</details>
<details>
<summary>摘要</summary>
感知系统中的感知融合是自动驾驶和机器人等任务领域的关键技术。最近，由Transformer搭配CNN的方法在不同的感知任务中表现出了高水平的性能。在这篇文章中，我们介绍了一种将摄像头和LiDAR数据进行融合的方法。通过在多个分辨率下使用Transformer模块，我们的方法可以有效地组合本地和全局的contextual关系。我们的方法的性能被证明了通过对两个挑战性 benchmarks进行了广泛的实验。与之前的方法相比，我们的方法在 longest6和town05 Long benchmarks上的驾驶和违法分数都表现出了显著的提高，相比TransFuser，我们的方法在Longest6 benchmark上提高了8%和19%的驾驶分数。
</details></li>
</ul>
<hr>
<h2 id="Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks"><a href="#Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks" class="headerlink" title="Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks"></a>Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11645">http://arxiv.org/abs/2308.11645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobin Shen, Jonathan Elmer, George H. Chen<br>for: 这个研究旨在预测响心止痛后昏迷 patients的神经LOGICAL OUTCOMES，帮助医疗决策。methods: 该研究提出了基于EEG数据的神经LOGICAL PROGNOSIS的动态框架，可以随着更多的EEG数据得到更加准确的预测。该框架使用任何支持竞争风险的动态存存分析模型，并且可以针对不同的训练病人的可用EEG时间序列进行不同的预测。results: 研究发现，使用static特征和最新一小时的EEG数据的Fine和Gray模型在准确度上与使用大量EEG数据的Dynamic-DeepHit模型相当竞争，而且在减少模型简化后，三种竞争风险模型中的模型可以learn更多信息而且准确性至少相当。<details>
<summary>Abstract</summary>
Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (the task of neurological prognostication) could help with treatment decisions. In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients' available EEG time series could vary in length. Predictions are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient's probability of awakening or of dying across multiple time horizons. Our framework uses any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient's static features and summary statistics from the patient's latest hour's worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient's EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks).
</details>
<details>
<summary>摘要</summary>
患者从心肺停止急救后入 coma 的风险很高，预测神经学结果可以帮助医疗决策。在这篇论文中，我们提出了，到目前为止最先进的动态推测框架，使用 EEG 数据预测患者后期神经学结果：我们的框架可以随着更多的 EEG 数据提供预测，不同的训练患者可以有不同的 EEG 时间序列长度。预测是基于时间到事件结果（时间到唤醒或时间到死亡）或患者在多个时间水平上的唤醒或死亡概率。我们的框架使用任何支持竞争风险的动态存生分析模型， estimate 患者级别累积发生函数。我们考虑了三种竞争风险：患者会于何时醒来，被撤销生命维持治疗（然后确定性死亡），或者死亡（由其他原因）。我们在实际数据集上进行了比较三种现有的动态存生分析模型，我们的主要实验结果是：（1）经典的 Fine 和 Gray 模型，只使用患者的静态特征和最近一小时的 EEG 数据，能够与最近开发的 Dynamic-DeepHit 模型匹配精度，而且（2）在剖析研究中，我们发现，我们选择了三种竞争风险的模型，可以提供至少相当精度的预测，同时学习更多的信息。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-tool-wear-prediction-in-turning"><a href="#Explainable-AI-for-tool-wear-prediction-in-turning" class="headerlink" title="Explainable AI for tool wear prediction in turning"></a>Explainable AI for tool wear prediction in turning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08765">http://arxiv.org/abs/2308.08765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleh Valizadeh Sotubadi, Rui Liu, Vinh Neguyen<br>for: 这份研究旨在发展一个可解释人工智能（XAI）框架，以便为切割过程中工具损坏预测提供人类理解的解决方案。methods: 本研究使用了一个随机森林算法作为监督式机器学习（ML）分类器，并使用加速度、声学、温度和螺旋速度等参数进行训练和二分类 classification。results: 经过训练后，使用了Shapley准则来解释训练好的ML分类器预测的结果，并确定工具温度是决定切割工具可用或失效的最重要的输入参数。因此，本研究显示了XAI可以提供磨削操作员诊断和理解复杂的ML分类器预测工具损坏的能力。<details>
<summary>Abstract</summary>
This research aims develop an Explainable Artificial Intelligence (XAI) framework to facilitate human-understandable solutions for tool wear prediction during turning. A random forest algorithm was used as the supervised Machine Learning (ML) classifier for training and binary classification using acceleration, acoustics, temperature, and spindle speed during the orthogonal tube turning process as input features. The ML classifier was used to predict the condition of the tool after the cutting process, which was determined in a binary class form indicating if the cutting tool was available or failed. After the training process, the Shapley criterion was used to explain the predictions of the trained ML classifier. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning of the ML classifier predictions. After implementing the Shapley criterion on all testing datasets, the tool temperature was identified as the most significant feature in determining the classification of available versus failed cutting tools. Hence, this research demonstrates capability of XAI to provide machining operators the ability to diagnose and understand complex ML classifiers in prediction of tool wear.
</details>
<details>
<summary>摘要</summary>
After training the ML classifier, the Shapley criterion was used to explain the predictions. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning behind the ML classifier's predictions. The results showed that tool temperature was the most significant feature in determining the classification of available versus failed cutting tools.This research demonstrates the capability of XAI to provide machining operators with the ability to diagnose and understand complex ML classifiers in predicting tool wear. By using the Shapley criterion to explain the predictions, the research provides a human-understandable explanation of the decision-making process, allowing operators to better understand and trust the ML classifier's predictions.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering"><a href="#Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering" class="headerlink" title="Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering"></a>Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08762">http://arxiv.org/abs/2308.08762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanjie Sun, Zhike Gong, Quan Shi, Lin Chen</li>
<li>for: 本研究主要是为了帮助商业银行控制债务风险，通过使用LightGBM算法建立分类器，判断客户是否有可能 Default on 债务。</li>
<li>methods: 本研究使用了LightGBM算法，并进行了特征工程，如处理缺失值、编码、不均衡样本等，以提高机器学习效果。</li>
<li>results: 本研究构建了新的特征属性，使得分类器的准确率达到0.734，AUC达到0.772，超过了基于同一数据集的许多分类器。这些结果可以为商业银行的债务授予提供参考，也可以为其他相似研究提供特征处理的想法。<details>
<summary>Abstract</summary>
Effective control of credit risk is a key link in the steady operation of commercial banks. This paper is mainly based on the customer information dataset of a foreign commercial bank in Kaggle, and we use LightGBM algorithm to build a classifier to classify customers, to help the bank judge the possibility of customer credit default. This paper mainly deals with characteristic engineering, such as missing value processing, coding, imbalanced samples, etc., which greatly improves the machine learning effect. The main innovation of this paper is to construct new feature attributes on the basis of the original dataset so that the accuracy of the classifier reaches 0.734, and the AUC reaches 0.772, which is more than many classifiers based on the same dataset. The model can provide some reference for commercial banks' credit granting, and also provide some feature processing ideas for other similar studies.
</details>
<details>
<summary>摘要</summary>
效果控制信贷风险是商业银行稳定运营的关键链接。本文主要基于一家外国商业银行的客户信息数据集在Kaggle上，使用LightGBM算法建立分类器，以帮助银行判断客户债务 default 的可能性。本文主要关注特征工程，如排除 missing value、编码、不均衡样本等，这些改进了机器学习效果。本文的主要创新在于在原始数据集基础上构建新的特征属性，使分类器的准确率达0.734，AUC达0.772，超过了同基据集上的许多分类器。该模型可以为商业银行债务赐与提供参考，同时也可以为其他相似研究提供特征处理的想法。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="PMET-Precise-Model-Editing-in-a-Transformer"><a href="#PMET-Precise-Model-Editing-in-a-Transformer" class="headerlink" title="PMET: Precise Model Editing in a Transformer"></a>PMET: Precise Model Editing in a Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08742">http://arxiv.org/abs/2308.08742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xpq-tech/pmet">https://github.com/xpq-tech/pmet</a></li>
<li>paper_authors: Xiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun Ma, Jie Yu</li>
<li>for: 提高模型编辑技术的性能，减少模型更新的成本。</li>
<li>methods: 分析隐藏状态的多头自注意力（MHSA）和循环神经网络（FFN），并同时优化它们的隐藏状态，以便准确地更新FFN的参数。</li>
<li>results: 在COUNTERFACT和zsRE dataset上达到了state-of-the-art的性能。<details>
<summary>Abstract</summary>
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we introduce PMET, which simultaneously optimizes Transformer Component (TC, namely MHSA and FFN) hidden states, while only using the optimized TC hidden states of FFN to precisely update FFN weights. Our experiments demonstrate that PMET exhibits state-of-the-art performance on both the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the effectiveness of our enhancements, further reinforcing the finding that the MHSA encodes certain general knowledge extraction patterns and indicating its storage of a small amount of factual knowledge. Our code is available at https://github.com/xpq-tech/PMET.git.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的修改技术可以轻松地修改一小部分知识，并且已经获得了可观的成功。现有的方法假设transformer层（TL）的隐藏状态是Feed-Forward Network（FFN）中的钥匙值内存。它们通常将TL隐藏状态优化为记忆target知识，并使用这些TL隐藏状态来更新FFN的重量。但是，TL隐藏状态的信息来源来自三个部分：多头自我对话（MHSA）、FFN和复合连接。现有的方法忽略了TL隐藏状态中包含的信息不是FFN特定所需的。因此，模型修改的性能受到影响。为了更精确地进行模型修改，我们进行了隐藏状态分析，发现MHSA对于某些一般知识提取模式具有编码功能。这意味着MHSA的重量不需要更新当新知识引入。基于以上发现，我们提出了PMET，它同时优化transformer ком ponent（TC，即MHSA和FFN）的隐藏状态，仅使用优化TC隐藏状态的FFN来精确地更新FFN的重量。我们的实验显示PMET在COUNTERFACT和zsRE datasets上展示了顶尖的表现。我们的剥离实验证明了我们的改进的有效性，进一步证明MHSA对于一些一般知识提取模式具有编码功能，并且它储存了一小部分的事实知识。我们的代码可以在https://github.com/xpq-tech/PMET.git中找到。
</details></li>
</ul>
<hr>
<h2 id="ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents"><a href="#ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents" class="headerlink" title="ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents"></a>ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08737">http://arxiv.org/abs/2308.08737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejaswini Manjunath, Mozhgan Navardi, Prakhar Dixit, Bharat Prakash, Tinoosh Mohsenin</li>
<li>for: 本研究旨在提出一种能够在实际世界中进行多目标导航的彩虹RL算法，以提高现有RL算法在实际环境中的适用性。</li>
<li>methods: 该方法利用了彩虹RL算法，并在训练过程中使用了对象检测器作为预处理步骤，以学习多目标导航并在实际世界中传递。</li>
<li>results: 实验结果显示，提出的Ready for Production Hierarchical RL（ReProHRL）方法在模拟环境和真实世界环境中都有较好的性能，比基eline方法提高18%和5%。<details>
<summary>Abstract</summary>
Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.
</details>
<details>
<summary>摘要</summary>
роботы已经成功地完成了高精度任务。在实际环境中，受限回报和多个目标是学习的主要挑战，并且使用强化学习（RL）算法学习良好策略仍然是一个挑战。训练在模拟环境中并在实际环境中细化是一个常见的方法。然而，适应实际环境的挑战仍然存在。在这篇论文中，我们提出了一种名为Ready for Production Hierarchical RL（ReProHRL）的方法，该方法将任务分解为层次多目标导航，并使用强化学习来导航。我们还使用对象检测器作为预处理步骤，以学习多目标导航并将其转移到实际世界。我们的实验结果表明，提议的ReProHRL方法在模拟环境和实际世界环境中都能够超越基准值。虽然两个方法在简单环境中完成单目标导航时都达到100%的成功率，但在更复杂的环境和多目标设定下，提议的方法在基准值的18%和5%之上。为了证明实际应用和概念示范，我们在一架名为Crazyflie的奈米飞行器上部署了提议的方法，并使用前置摄像头完成多目标导航实验。
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection"><a href="#On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection" class="headerlink" title="On the Effectiveness of Log Representation for Log-based Anomaly Detection"></a>On the Effectiveness of Log Representation for Log-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08736">http://arxiv.org/abs/2308.08736</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mooselab/suppmaterial-logrepforanomalydetection">https://github.com/mooselab/suppmaterial-logrepforanomalydetection</a></li>
<li>paper_authors: Xingfang Wu, Heng Li, Foutse Khomh</li>
<li>for: 本研究旨在比较常用的日志表示技术，以便选择最适合自动日志分析过程中的日志表示技术。</li>
<li>methods: 本研究使用了六种日志表示技术，并与七种机器学习模型和四个公共日志集（HDFS、BGL、Spirit和Thunderbird）进行了比较。</li>
<li>results: 实验结果显示，不同的日志表示技术对下游模型的性能产生了不同的影响，并提供了一些启示式指南 для未来的研究人员和开发者。<details>
<summary>Abstract</summary>
Logs are an essential source of information for people to understand the running status of a software system. Due to the evolving modern software architecture and maintenance methods, more research efforts have been devoted to automated log analysis. In particular, machine learning (ML) has been widely used in log analysis tasks. In ML-based log analysis tasks, converting textual log data into numerical feature vectors is a critical and indispensable step. However, the impact of using different log representation techniques on the performance of the downstream models is not clear, which limits researchers and practitioners' opportunities of choosing the optimal log representation techniques in their automated log analysis workflows. Therefore, this work investigates and compares the commonly adopted log representation techniques from previous log analysis research. Particularly, we select six log representation techniques and evaluate them with seven ML models and four public log datasets (i.e., HDFS, BGL, Spirit and Thunderbird) in the context of log-based anomaly detection. We also examine the impacts of the log parsing process and the different feature aggregation approaches when they are employed with log representation techniques. From the experiments, we provide some heuristic guidelines for future researchers and developers to follow when designing an automated log analysis workflow. We believe our comprehensive comparison of log representation techniques can help researchers and practitioners better understand the characteristics of different log representation techniques and provide them with guidance for selecting the most suitable ones for their ML-based log analysis workflow.
</details>
<details>
<summary>摘要</summary>
ilog文件是软件系统运行状况的重要来源信息。由于现代软件架构和维护方法不断演化，更多的研究努力被投入到自动化log分析领域。特别是机器学习（ML）在log分析任务中得到了广泛的应用。在ML基于log分析任务中，将文本log数据转化为数字特征向量是一项关键和不可或缺的步骤。然而，使用不同的log表示技术对下游模型的性能的影响并不清晰，这限制了研究人员和实践者在自动化log分析 workflow中选择最佳log表示技术的机会。因此，本工作调查和比较了过去的log分析研究中广泛采用的log表示技术。特别是我们选择了六种log表示技术，并与七种ML模型和四个公共log数据集（即HDFS、BGL、Spirit和Thunderbird）进行了在log基于异常检测中的评估。我们还考虑了在log解析过程和不同的特征聚合方法被采用时的影响。从实验结果来看，我们提供了一些启示性的指南，以帮助未来的研究人员和开发者在设计自动化log分析 workflow时采取更好的决策。我们认为我们的全面的log表示技术比较可以帮助研究人员和实践者更好地了解不同log表示技术的特点，并为他们选择最适合的一种。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing"><a href="#A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing" class="headerlink" title="A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing"></a>A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10869">http://arxiv.org/abs/2308.10869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nibraas Khan, Mahrukh Tauseef, Ritam Ghosh, Nilanjan Sarkar</li>
<li>For: The paper aims to improve the accuracy of emotion detection using deep learning techniques and physiological data.* Methods: The proposed cost function employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data and reduce the impact of subject-dependent noise.* Results: The proposed cost function outperforms a state-of-the-art loss function (Mean Squared Error) across four commonly used datasets, with an average increase of 14.75% and 17.75% in minimum and centroid euclidean distance, respectively.<details>
<summary>Abstract</summary>
Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.
</details>
<details>
<summary>摘要</summary>
人类行为中的情感是一个重要的部分，可以影响思维、决策和communication技能。因此，能够准确识别和评估情感的能力可以在许多人类中心应用中发挥作用，如行为训练、情感健康评估和人机界面开发。通过physiological数据中的模式和情感状态之间的相关性，使用深度学习技术可以准确检测人类情感状态。然而，现有模型的泛化能力 oft limited by subject-dependent noise in physiological data due to variations in a subject's reactions to stimuli。因此，我们提出了一个新的成本函数，利用Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise。我们的模型在四个常用的数据集上进行了评估，并与使用 Mean Squared Error 的基eline模型进行比较。中心和最小距离between different classes在latent space中用来衡量不同类别之间的分离度。在所有数据集上，我们发现了平均增加14.75%和17.75%（从基eline到我们的损失函数）的 minimum和centroid Euclidean distance。
</details></li>
</ul>
<hr>
<h2 id="Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration"><a href="#Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration" class="headerlink" title="Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration"></a>Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11644">http://arxiv.org/abs/2308.11644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Yu, Han Chen</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的Structural Health Monitoring（SHM）方法，以实现基础设施的longevity和安全性。</li>
<li>methods: 这篇论文使用了一种混合了卷积和回归架构的深度学习算法，以捕捉多 modal vibration signals 中的 Complexity。另外，这篇论文还使用了注意力机制，以优化模型的准确性和适应能力。</li>
<li>results: 这篇论文的结果显示了这种方法在多个 SHM enario 中的预测精度和早期损坏探测得到了明显提高，同时也提供了更加透明和可解释的 AI-driven SHM 解决方案。<details>
<summary>Abstract</summary>
Structural Health Monitoring (SHM) plays an indispensable role in ensuring the longevity and safety of infrastructure. With the rapid growth of sensor technology, the volume of data generated from various structures has seen an unprecedented surge, bringing forth challenges in efficient analysis and interpretation. This paper introduces a novel deep learning algorithm tailored for the complexities inherent in multimodal vibration signals prevalent in SHM. By amalgamating convolutional and recurrent architectures, the algorithm adeptly captures both localized and prolonged structural behaviors. The pivotal integration of attention mechanisms further enhances the model's capability, allowing it to discern and prioritize salient structural responses from extraneous noise. Our results showcase significant improvements in predictive accuracy, early damage detection, and adaptability across multiple SHM scenarios. In light of the critical nature of SHM, the proposed approach not only offers a robust analytical tool but also paves the way for more transparent and interpretable AI-driven SHM solutions. Future prospects include real-time processing, integration with external environmental factors, and a deeper emphasis on model interpretability.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)structural health monitoring (SHM) 在保证基础设施的寿命和安全方面发挥不可或缺的作用。随着感知技术的快速发展，来自不同结构的感知数据量有历史上前所未有的增长，这带来了分析和解释数据的挑战。本文介绍了一种适应 multimodal 振荡信号的深度学习算法。通过将卷积和回归架构融合起来，该算法可以fficiently 捕捉结构的本地和持续行为。另外，通过集成注意机制，该算法可以更好地异化和优化结构的响应。我们的结果表明，该算法可以在多个 SHM 场景中提供显著提高的预测精度、早期损害检测和适应性。鉴于 SHM 的重要性，我们的方法不仅提供了一种可靠的分析工具，还开创了更加透明和可解释的 AI-驱动 SHM 解决方案。未来的发展方向包括实时处理、与外部环境因素集成以及更深入的模型解释性。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks"><a href="#Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks" class="headerlink" title="Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks"></a>Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08709">http://arxiv.org/abs/2308.08709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous2015258/Early_Attack">https://github.com/anonymous2015258/Early_Attack</a></li>
<li>paper_authors: Mirazul Haque, Wei Yang</li>
<li>for: 本研究旨在 investigate 动态神经网络（DyNNs）中动态机制的稳定性影响和如何通过设计选择来提高 DyNNs 的稳定性。</li>
<li>methods: 本研究使用三个模型和两个数据集来评估动态机制在 DyNNs 中的影响。我们采用了多种攻击方法来评估动态机制的影响，包括转移攻击和生成攻击。</li>
<li>results: 我们发现，从 DyNNs 到 SDNNs 的攻击传递率高于从 SDNNs 到 DyNNs 的攻击传递率。此外，我们发现 DyNNs 可以更有效地生成攻击样本than SDNNs。最后，我们通过研究来提供设计选择来提高 DyNNs 对攻击的抵抗力。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have been used to solve different day-to-day problems. Recently, DNNs have been deployed in real-time systems, and lowering the energy consumption and response time has become the need of the hour. To address this scenario, researchers have proposed incorporating dynamic mechanism to static DNNs (SDNN) to create Dynamic Neural Networks (DyNNs) performing dynamic amounts of computation based on the input complexity. Although incorporating dynamic mechanism into SDNNs would be preferable in real-time systems, it also becomes important to evaluate how the introduction of dynamic mechanism impacts the robustness of the models. However, there has not been a significant number of works focusing on the robustness trade-off between SDNNs and DyNNs. To address this issue, we propose to investigate the robustness of dynamic mechanism in DyNNs and how dynamic mechanism design impacts the robustness of DyNNs. For that purpose, we evaluate three research questions. These evaluations are performed on three models and two datasets. Through the studies, we find that attack transferability from DyNNs to SDNNs is higher than attack transferability from SDNNs to DyNNs. Also, we find that DyNNs can be used to generate adversarial samples more efficiently than SDNNs. Then, through research studies, we provide insight into the design choices that can increase robustness of DyNNs against the attack generated using static model. Finally, we propose a novel attack to understand the additional attack surface introduced by the dynamic mechanism and provide design choices to improve robustness against the attack.
</details>
<details>
<summary>摘要</summary>
深度神经网络 (DNNs) 已经用于解决不同的日常问题。近些年，DNNs 已经在实时系统中部署，降低能耗和响应时间已成为当务之急。为了解决这种情况，研究人员已经提议将静态神经网络 (SDNNs) 转换成动态神经网络 (DyNNs)，以进行动态量的计算基于输入复杂性。虽然将动态机制添加到 SDNNs 可以在实时系统中提高性能，但也需要评估这种变化对模型的稳定性的影响。然而，有很少的研究集中注意到 SDNNs 和 DyNNs 之间的稳定性质量。为了解决这个问题，我们提出了三个研究问题，并对三种模型和两个数据集进行评估。我们发现，从 DyNNs 到 SDNNs 的攻击传播率高于从 SDNNs 到 DyNNs 的攻击传播率。此外，我们发现 DyNNs 可以更有效地生成黑客样本。然后，通过研究，我们提供了一些设计选择，可以增强 DyNNs 对攻击的抵御力。最后，我们提出了一种新的攻击方法，以评估动态机制引入的额外攻击表面，并提供了一些设计选择，可以提高 DyNNs 对攻击的抵御力。
</details></li>
</ul>
<hr>
<h2 id="Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness"><a href="#Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness" class="headerlink" title="Consciousness in Artificial Intelligence: Insights from the Science of Consciousness"></a>Consciousness in Artificial Intelligence: Insights from the Science of Consciousness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08708">http://arxiv.org/abs/2308.08708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, Liad Mudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, Rufin VanRullen</li>
<li>for: 本文提出了一种rigorous和empirically grounded的方法来评估现代AI系统是否具备意识，并根据我们最好支持的神经科学理论来评估AI系统的意识性。</li>
<li>methods: 本文首先介绍了一些主流的科学理论，包括回卷处理理论、全局工作空间理论、更高级理论、预测处理理论和注意schema理论，然后从这些理论中提取了”指标属性”，这些属性可以用计算机科学的语言来评估AI系统是否满足这些指标。</li>
<li>results: 本文对一些最新的AI系统进行了评估，并发现现在的AI系统没有意识性，但也没有显而出技术障碍建立意识AI系统。<details>
<summary>Abstract</summary>
Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.
</details>
<details>
<summary>摘要</summary>
当前或近期的人工智能系统是科学兴趣和公众关注的话题。本报告强调和证明了一种严谨和基于实验的AI意识方法：通过评估现有AI系统，以及我们最好支持的神经科学理论来评估AI意识。我们对多种知名的科学理论进行了survey，包括回propagation理论、全球工作区理论、更高级理论、预测处理理论和注意schema理论。从这些理论中，我们得出了"指标性质"的 consciousness，并将其转化为计算机科学中的形式，以评估AI系统是否满足这些指标。我们对多个最新的AI系统进行了评估，并讨论了未来系统如何实现这些指标。我们的分析结果表明，目前没有任何AI系统具备意识，但也没有明显的技术障碍建立具备这些指标的AI系统。
</details></li>
</ul>
<hr>
<h2 id="FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs"><a href="#FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs" class="headerlink" title="FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs"></a>FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09723">http://arxiv.org/abs/2308.09723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Jin Kim, Rawn Henry, Raffy Fahim, Hany Hassan Awadalla<br>for: 这个研究是为了提高大型语言模型（LLMs）的实际部署，因为它们需要很大的内存。methods: 我们提出了一种高效的量化方法，可以降低内存consumption和加速LLMs的测试过程。我们还提出了一个简单且有效的规律，可以在无需调整的情况下保持模型质量。results: 我们的方法可以在大规模的开源模型，如 OPT-175B 和内部MoE模型上，实现最小的精度损失，同时获得最多3.65倍的通过率。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights. We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经在不同的语言任务上达到了现场的表现水准，但是它们在实际应用中受到了内存需求的挑战。另外，最新的生成模型受到了自动预测过程中的内存带宽瓶须的高处理成本的影响。为了解决这些问题，我们提出了一种高效的量化方法，可以降低内存消耗和加速 LLM 的测试。我们还提出了一个简单而有效的规则，可以在不需要进一步微调的情况下，将模型精度降至最低。这个方法适用于内部的 Mixture-of-Experts（MoE）和稠密模型。我们还实现了高效的 GPU GEMM，可以在线进行矩阵乘法和量化，支持对 fp16 或 bf16 的激活值进行 int8 或 int4 的重量量化。我们将这个方法应用于 OPT-175B 和内部的 MoE 模型，展示了最小的准确度损失，同时可以在相同的 GPU 上 Achieve 3.65 倍的运算速度。
</details></li>
</ul>
<hr>
<h2 id="Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing"><a href="#Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing" class="headerlink" title="Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing"></a>Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08705">http://arxiv.org/abs/2308.08705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Liu, Kaiqing Zhang</li>
<li>for: This paper focuses on developing a sample- and computation-efficient partially observable multi-agent reinforcement learning (MARL) algorithm in the general framework of partially observable stochastic games (POSGs).</li>
<li>methods: The authors propose leveraging information-sharing among agents and approximating the shared common information to construct an approximate model of the POSG, which enables quasi-efficient planning and solving of the original POSG.</li>
<li>results: The proposed algorithm is both statistically and computationally quasi-efficient, and the authors hope that their study may open up possibilities for leveraging and designing different information structures for developing sample- and computation-efficient partially observable MARL.<details>
<summary>Abstract</summary>
We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.
</details>
<details>
<summary>摘要</summary>
我们研究可证明多智能 reinforcement learning（MARL）的通用框架中的部分可见随机游戏（POSG）。为了绕过已知的困难性和使用计算量卷积的执行器，我们建议利用智能之间的信息共享，这是现实中的多智能控制系统通信的标准模型。我们首先确立了一些计算复杂性结论，以 justify 信息共享的必要性，以及在部分观察下的可见性假设，这使得单机RL可以有效地解决POSG。然后，我们提议使用approximate shared common information来构建一个approximate模型，在该模型中，计划一个近似平衡（在原POSG中解决）可以在可证明的时间内完成，即 quasi-polynomial-time。此外，我们开发了一种部分可见MARL算法，该算法同时具备了统计学和计算学的 quasi-有效性。我们希望我们的研究可以开拓出不同的信息结构，以开发更高效的部分可见MARL算法。
</details></li>
</ul>
<hr>
<h2 id="Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces"><a href="#Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces" class="headerlink" title="Planning in the imagination: High-level planning on learned abstract search spaces"></a>Planning in the imagination: High-level planning on learned abstract search spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08693">http://arxiv.org/abs/2308.08693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Martin, Tuomas Sandholm</li>
<li>for: 该论文旨在提供一种新的规划方法，叫做PiZero，可以让代理人在自己创造的抽象搜索空间中进行规划，完全与实际环境解耦。</li>
<li>methods: 该方法不同于先前的方法，可以在任意时间尺度和基础级微动作数量的情况下进行高级规划，并且可以处理连续动作空间和部分可见性的情况。</li>
<li>results: 在多个领域中进行实验，该方法与相似的先前方法进行比较，达到更高的性能，而不需要访问环境模拟器。<details>
<summary>Abstract</summary>
We propose a new method, called PiZero, that gives an agent the ability to plan in an abstract search space of its own creation that is completely decoupled from the real environment. Unlike prior approaches, this enables the agent to perform high-level planning at arbitrary timescales and reason in terms of compound or temporally-extended actions, which can be useful in environments where large numbers of base-level micro-actions are needed to perform relevant macro-actions. In addition, our method is more general than comparable prior methods because it handles settings with continuous action spaces and partial observability. We evaluate our method on multiple domains, including navigation tasks and Sokoban. Experimentally, it outperforms comparable prior methods without assuming access to an environment simulator.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新方法，叫做PiZero，它让代理人能够在自己创建的抽象搜索空间中进行规划，完全与真实环境分离。与先前的方法不同，这使得代理人可以在任意时间尺度上进行高级规划，并在基础级微动作的批量进行复杂或时间扩展的动作，这可以在环境中需要大量基础级微动作来完成重要的macro动作时是有用的。此外，我们的方法更加通用于先前的方法，因为它处理了连续动作空间和部分可见性的设置。我们在多个领域进行了实验，包括导航任务和Sokoban，并证明了我们的方法在相对先前方法无需访问环境模拟器的情况下表现出色。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Overfitting-Introducing-the-Overfitting-Index"><a href="#Quantifying-Overfitting-Introducing-the-Overfitting-Index" class="headerlink" title="Quantifying Overfitting: Introducing the Overfitting Index"></a>Quantifying Overfitting: Introducing the Overfitting Index</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08682">http://arxiv.org/abs/2308.08682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass</li>
<li>for: 本研究旨在提供一个量化评估模型过拟合情况的度量，以便提高机器学习模型在实际应用中的可靠性。</li>
<li>methods: 本研究使用了一个新的度量方法—Overfitting Index（OI），通过实验显示了OI的有用性和显著性。</li>
<li>results: 研究结果显示，不同架构在不同数据集上的过拟合情况有很大差异，而资料增强对小型特殊数据集的影响特别明显。此外，ViT-32在MNIST数据集上的表现也显示了某些模型和数据集之间的具体关系。<details>
<summary>Abstract</summary>
In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising avenue to advance model optimization and ensure real-world efficacy.
</details>
<details>
<summary>摘要</summary>
在机器学习领域中，确保模型通用性是一项核心挑战。过拟合，其中模型在训练数据上表现出色但在未见数据上表现不佳，是一个常见问题。这篇论文介绍了一种新的度量方法——过拟合指数（OI），用于评估模型过拟合的倾向。通过对Breast Ultrasound Images Dataset（BUS）和MNIST dataset上的多种架构（如MobileNet、U-Net、ResNet、Darknet和ViT-32）进行了广泛的实验，我们示出了OI的实用性和分辨率。我们的结果表明不同的架构之间存在变化的过拟合行为，并且数据扩展尤其是在小型特定数据集上具有缓解作用。ViT-32在MNIST上的表现更加强调了某些模型的稳定性和数据集的全面性。通过提供一个对过拟合进行对象评估的途径，OI提供了一个有前途的方法，以确保模型在实际应用中的有效性。
</details></li>
</ul>
<hr>
<h2 id="SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification"><a href="#SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification" class="headerlink" title="SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification"></a>SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08669">http://arxiv.org/abs/2308.08669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Longman-Stan/SkinDistilVit">https://github.com/Longman-Stan/SkinDistilVit</a></li>
<li>paper_authors: Vlad-Constantin Lungu-Stan, Dumitru-Clementin Cercel, Florin Pop</li>
<li>for: 这个研究旨在提供一个基于 transformer 的 skin cancer 分类方案，可以匹配人工智能的 melanoma 识别精度。</li>
<li>methods: 研究人员使用 knowledge distillation 技术来训练一个基于 transformer 的模型，并在模型中添加多个分类头来提高分类精度。</li>
<li>results: 模型可以匹配教师模型的精度（98.33%），并且在时间和内存方面具有较好的性能（69.25%  faster on GPU、97.96% faster on CPU）。<details>
<summary>Abstract</summary>
Skin cancer is a treatable disease if discovered early. We provide a production-specific solution to the skin cancer classification problem that matches human performance in melanoma identification by training a vision transformer on melanoma medical images annotated by experts. Since inference cost, both time and memory wise is important in practice, we employ knowledge distillation to obtain a model that retains 98.33% of the teacher's balanced multi-class accuracy, at a fraction of the cost. Memory-wise, our model is 49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on GPU and 97.96% faster on CPU. By adding classification heads at each level of the transformer and employing a cascading distillation process, we improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance. We provide the code at https://github.com/Longman-Stan/SkinDistilVit.
</details>
<details>
<summary>摘要</summary>
皮肤癌是一种可治疗的疾病，如果早期发现。我们提供了一种特定于生产的解决方案，用于皮肤癌类型分类问题，与专家标注的医疗图像进行匹配。由于实际应用中的推理成本（时间和内存）非常重要，我们使用知识储存技术来获得一个保留98.33%的教师平衡多类准确率的模型，而且内存占用量为49.60%，时间占用量为69.25%和97.96%。通过在转换器中添加分类头和使用层次分类处理，我们提高了基本模型的平衡多类准确率2.1%，同时创造了不同大小的模型，但具有相同性能。我们提供了代码，可以在 GitHub上找到：https://github.com/Longman-Stan/SkinDistilVit。
</details></li>
</ul>
<hr>
<h2 id="BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration"><a href="#BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration" class="headerlink" title="BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration"></a>BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08666">http://arxiv.org/abs/2308.08666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikhar Tuli, Niraj K. Jha</li>
<li>for: 这个研究的目的是提出一个受限制的多目标优化（MOO）框架，以便在各种科学研究和物理实验中更好地探索和观察新的设计样本。</li>
<li>methods: 这个框架使用了第二项Gradient和异escaled对应模型来实现样本有效的优化。</li>
<li>results: 在单一目标vector优化应用中，BREATHE比下一个基elineRandom Forest Regression高效性64.1%；在图形基数搜索中，BREATHE比下一个基elineGaussian-process-based Bayesian optimization高效性64.9%；在多目标优化任务中，BREATHE可以达到21.9倍的超过MOBOpt的内在量。<details>
<summary>Abstract</summary>
Researchers constantly strive to explore larger and more complex search spaces in various scientific studies and physical experiments. However, such investigations often involve sophisticated simulators or time-consuming experiments that make exploring and observing new design samples challenging. Previous works that target such applications are typically sample-inefficient and restricted to vector search spaces. To address these limitations, this work proposes a constrained multi-objective optimization (MOO) framework, called BREATHE, that searches not only traditional vector-based design spaces but also graph-based design spaces to obtain best-performing graphs. It leverages second-order gradients and actively trains a heteroscedastic surrogate model for sample-efficient optimization. In a single-objective vector optimization application, it leads to 64.1% higher performance than the next-best baseline, random forest regression. In graph-based search, BREATHE outperforms the next-best baseline, i.e., a graphical version of Gaussian-process-based Bayesian optimization, with up to 64.9% higher performance. In a MOO task, it achieves up to 21.9$\times$ higher hypervolume than the state-of-the-art method, multi-objective Bayesian optimization (MOBOpt). BREATHE also outperforms the baseline methods on most standard MOO benchmark applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data"><a href="#Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data" class="headerlink" title="Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data"></a>Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08656">http://arxiv.org/abs/2308.08656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keziah Naggita, Julienne LaChance, Alice Xiang</li>
<li>for:  investigate the limitations of standard Internet data collection methods in low- and middle-income countries</li>
<li>methods: analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa</li>
<li>results: findings for an &#96;&#96;othering’’ phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers, and the need for further work to capture image data representative of African people and their environments to improve the applicability of computer vision models in a global context.Here’s the full text in Simplified Chinese:</li>
<li>for: 这个研究的目的是调查低收入国家和中等收入国家的标准互联网数据采集方法的局限性。</li>
<li>methods: 该研究使用非常大规模的地标批处Flickr图片，对每个非洲国家进行分析，以获取有关人类中心的图像宽泛分布。</li>
<li>results: 研究发现，非洲的图像数据中存在一种“其他化”现象，即非洲的图像由非本地摄影师拍摄的情况很多。这些结果表明，需要进一步的工作，以捕捉更加符合非洲人和他们环境的图像数据，以提高计算机视觉模型在全球上的适用性。<details>
<summary>Abstract</summary>
Biases in large-scale image datasets are known to influence the performance of computer vision models as a function of geographic context. To investigate the limitations of standard Internet data collection methods in low- and middle-income countries, we analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa. We report the quantity and content of available data with comparisons to population-matched nations in Europe as well as the distribution of data according to fine-grained intra-national wealth estimates. Temporal analyses are performed at two-year intervals to expose emerging data trends. Furthermore, we present findings for an ``othering'' phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers. The results of our study suggest that further work is required to capture image data representative of African people and their environments and, ultimately, to improve the applicability of computer vision models in a global context.
</details>
<details>
<summary>摘要</summary>
大规模图像数据集中的偏见会影响计算机视觉模型的表现，具体来说是根据地理背景。为了调查互联网数据采集方法在LOW-和中等收入国家的限制，我们使用Geotagged Flickr图像与每个非洲国家进行大规模人类中心图像地域多样性分析。我们对可用数据量和内容进行比较，并根据细化的内国财富估计进行分布分析。我们还在两年间进行时间分析，以暴露出emerging数据趋势。此外，我们还发现了一种“他者”现象，即非本地摄影师拍摄的非洲图像的巨大数量。我们的研究结果表明，需要进一步的工作，以捕捉非洲人和其环境的图像数据，并最终提高计算机视觉模型在全球上的应用性。
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems"><a href="#Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems" class="headerlink" title="Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems"></a>Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08655">http://arxiv.org/abs/2308.08655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faisal Nissar Malik, James Ricles, Masoud Yari, Malik Arsala Nissar</li>
<li>for: 这个论文旨在测试多度自由系统（MDOF）的类型动态回应，尤其是在地震（earthquake）载荷下的非线性结构性能。</li>
<li>methods: 这个论文使用了物理知识数据驱动的遗传 ней网（Physics-Informed Recurrent Neural Network，PIRNN）来评估多度自由系统的类型动态回应。</li>
<li>results: 该论文预测的回应将与现有方法（如金属元件分析，FEA）进行比较，以评估PIRNN模型的有效性。<details>
<summary>Abstract</summary>
Dynamic response evaluation in structural engineering is the process of determining the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventional methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.
</details>
<details>
<summary>摘要</summary>
dynamically respond evaluation in structural engineering 是指评估结构受到动力荷载（如风、地震、冲击等）时的响应，例如成员力、节点偏移等。这是结构分析中非常重要的一环，因为它可以让工程师在极端荷载情况下评估结构性能，并根据这些结果做出有知识的设计和安全决策。传统的方法 для dynamically respond evaluation 包括数学模拟（FEA），其中结构被模型为finite element，并通过数学方法解决方程。虽然有效，但这种方法可能是计算昂贵的，并且可能不适用于实时应用。为了解决这些限制，最近在机器学习领域，特别是人工神经网络（RNN）中，对 dynamically respond evaluation 进行了应用。这些技术可以利用大量数据集和复杂的算法来学习输入和输出之间的复杂关系，使其成为这种问题的理想解决方案。在本文中，一种新的方法被提出来评估多度关系（MDOF）系统的动力响应。本文的焦点是评估震动（地震）响应。预测的响应将与现有方法（如FEA）进行比较，以评估物理学信息RNN模型的有效性。
</details></li>
</ul>
<hr>
<h2 id="Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction"><a href="#Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction" class="headerlink" title="Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction"></a>Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08653">http://arxiv.org/abs/2308.08653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael G. Rawson, Timothy Doster, Tegan Emerson</li>
<li>for: 本研究旨在开发一种基于希尔伯特空间的减少维度方法，以提高光谱分析的效率和精度。</li>
<li>methods: 该方法使用非负最小二乘估算来构建稀疏表示，并使用最大可能性压缩向量来减少信息损失。</li>
<li>results: 对实验和 sintética数据进行评估，发现希尔伯特空间减少方法可以减少错误率，并且可以与标准减少和最小二乘方法相比，提高压缩率和精度。<details>
<summary>Abstract</summary>
Hyperspectral measurements from long range sensors can give a detailed picture of the items, materials, and chemicals in a scene but analysis can be difficult, slow, and expensive due to high spatial and spectral resolutions of state-of-the-art sensors. As such, sparsity is important to enable the future of spectral compression and analytics. It has been observed that environmental and atmospheric effects, including scattering, can produce nonlinear effects posing challenges for existing source separation and compression methods. We present a novel transformation into Hilbert spaces for pruning and constructing sparse representations via non-negative least squares minimization. Then we introduce max likelihood compression vectors to decrease information loss. Our approach is benchmarked against standard pruning and least squares as well as deep learning methods. Our methods are evaluated in terms of overall spectral reconstruction error and compression rate using real and synthetic data. We find that pruning least squares methods converge quickly unlike matching pursuit methods. We find that Hilbert space pruning can reduce error by as much as 40% of the error of standard pruning and also outperform neural network autoencoders.
</details>
<details>
<summary>摘要</summary>
高spectral度测量从长距离感知器可以提供场景中物品、材料和化学物质的详细图像，但是分析可能困难、慢和昂贵，这主要是因为现有的感知器具有高空间和spectral分辨率。因此，稀疏性具有重要作用，以便未来的spectral压缩和分析。已经观察到环境和大气效应，包括散射，可以导致非线性效应，这会对现有的源分离和压缩方法 pose challenges。我们提出了一种将测量转换到希尔伯特空间的新方法，以便减少稀疏表示的最小二乘问题。然后，我们引入最大可能性压缩向量，以降低信息损失。我们的方法与标准减少和最小二乘以及深度学习方法进行比较。我们的方法在实际和 sintetic数据上进行评估，并发现减少最小二乘方法可以快速 converges，而不同于匹配追求方法。此外，希尔伯特空间减少可以将错误降低到40%以上，并超越神经网络自适应编码器。
</details></li>
</ul>
<hr>
<h2 id="Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly"><a href="#Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly" class="headerlink" title="Towards Personalized Federated Learning via Heterogeneous Model Reassembly"></a>Towards Personalized Federated Learning via Heterogeneous Model Reassembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08643">http://arxiv.org/abs/2308.08643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wang, Xingyi Yang, Suhan Cui, Liwei Che, Lingjuan Lyu, Dongkuan Xu, Fenglong Ma</li>
<li>for: addressing the practical problem of model heterogeneity in federated learning, where clients possess models with different network structures.</li>
<li>methods: leverages heterogeneous model reassembly to achieve personalized federated learning, approaches the problem of heterogeneous model personalization as a model-matching optimization task on the server side, and automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention.</li>
<li>results: outperforms baselines on three datasets under both IID and Non-IID settings, effectively reduces the adverse impact of using different public data, and dynamically generates diverse personalized models in an automated manner.Here’s the full translation in Simplified Chinese:</li>
<li>for: 这篇论文是解决联邦学习中的实际问题， Client 拥有不同网络结构的模型。</li>
<li>methods: 利用多元模型重组来实现个性化联邦学习，在服务器端以模型匹配优化任务方式解决各种模型个性化问题，并自动生成有用且多样化的个性化候选人。</li>
<li>results: 在三个数据集上比基eline 表现出色，在 IID 和 Non-IID 设定下都有出色的表现，可以干扰使用不同的公共数据对模型的影响，同时自动生成多样化的个性化模型。<details>
<summary>Abstract</summary>
This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-monotone-Sequential-Submodular-Maximization"><a href="#Non-monotone-Sequential-Submodular-Maximization" class="headerlink" title="Non-monotone Sequential Submodular Maximization"></a>Non-monotone Sequential Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08641">http://arxiv.org/abs/2308.08641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaojie Tang, Jing Yuan</li>
<li>for: 本研究targets a fundamental problem in submodular optimization, specifically sequential submodular maximization, which is to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \cdots ,f_k$ is maximized.</li>
<li>methods: 该研究提出了一些有效的解决方案，包括针对 flexible 和 fixed 长度约束的方法，以及一个特殊情况下的同Utility函数方法。</li>
<li>results: 实验证明了我们提出的算法在视频推荐领域的有效性。这些结果在推荐系统和搜索优化等领域有着广泛的应用，因为选择项的顺序对总值有着重要的影响。<details>
<summary>Abstract</summary>
In this paper, we study a fundamental problem in submodular optimization, which is called sequential submodular maximization. Specifically, we aim to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+$ is maximized, here each function $f_j$ takes the first $j$ items from this sequence as input. The existing research on sequential submodular maximization has predominantly concentrated on the monotone setting, assuming that the submodular functions are non-decreasing. However, in various real-world scenarios, like diversity-aware recommendation systems, adding items to an existing set might negatively impact the overall utility. In response, this paper pioneers the examination of the aforementioned problem with non-monotone submodular functions and offers effective solutions for both flexible and fixed length constraints, as well as a special case with identical utility functions. The empirical evaluations further validate the effectiveness of our proposed algorithms in the domain of video recommendations. The results of this research have implications in various fields, including recommendation systems and assortment optimization, where the ordering of items significantly impacts the overall value obtained.
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了一个基本问题在 subsequential 优化中，即Sequential Submodular Maximization。特别是，我们想选择和排序一组 $k$ 个元素从基aset $V$，使得权重总和 $k$ (可能非增长) 的可模协变函数 $f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+$ 的最大化，其中每个函数 $f_j$ 取第 $j$ 个元素序列为输入。现有的研究sequential submodular maximization 偏向偏向非增长Setting,假设优化函数是非递减的。然而，在现实生活中的多个enario中，如多样化推荐系统，添加元素到现有的集合可能会下降总用户体验。为此，本文开拓了非增长优化函数的问题，并提供了有效的解决方案，包括灵活和固定长度约束，以及特殊情况下的同用户函数。实验证明了我们提出的算法在视频推荐领域的有效性。本研究的结果在多个领域有着启示性，包括推荐系统和排序优化，其中元素的顺序具有重要的影响。
</details></li>
</ul>
<hr>
<h2 id="Fair-GANs-through-model-rebalancing-with-synthetic-data"><a href="#Fair-GANs-through-model-rebalancing-with-synthetic-data" class="headerlink" title="Fair GANs through model rebalancing with synthetic data"></a>Fair GANs through model rebalancing with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08638">http://arxiv.org/abs/2308.08638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhav Jain, Nasir Memon, Julian Togelius</li>
<li>for: 本研究旨在 mitigate 生成模型中的偏见，以提高模型的公平性。</li>
<li>methods: 本研究使用了 latent space exploration 技术，通过生成 balance 的数据来重新训练一个公平的生成模型。同时，提出了一种偏见纠正损失函数，可以在不平衡数据集上进行训练，并且可以提高公平度标度。</li>
<li>results: 在使用 FFHQ 数据集进行隔离性质测试时，提出的方法可以提高公平度标度，与传统的 Frechet inception distance (FID) 不同，可以更好地评估模型的公平性。此外，在 Cifar-10 数据集上进行了验证，并证明了方法的可行性。<details>
<summary>Abstract</summary>
Deep generative models require large amounts of training data. This often poses a problem as the collection of datasets can be expensive and difficult, in particular datasets that are representative of the appropriate underlying distribution (e.g. demographic). This introduces biases in datasets which are further propagated in the models. We present an approach to mitigate biases in an existing generative adversarial network by rebalancing the model distribution. We do so by generating balanced data from an existing unbalanced deep generative model using latent space exploration and using this data to train a balanced generative model. Further, we propose a bias mitigation loss function that shows improvements in the fairness metric even when trained with unbalanced datasets. We show results for the Stylegan2 models while training on the FFHQ dataset for racial fairness and see that the proposed approach improves on the fairness metric by almost 5 times, whilst maintaining image quality. We further validate our approach by applying it to an imbalanced Cifar-10 dataset. Lastly, we argue that the traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details>
<details>
<summary>摘要</summary>
深度生成模型需要大量的训练数据。这经常会导致问题，因为收集数据集可能是昂贵的和困难的，特别是数据集是合适的下面分布（例如人口）。这会导致数据集中的偏见，并将它们传递给模型。我们提出了一种方法来减少模型中的偏见，通过使用潜在空间探索生成均衡数据，并使用这些数据来训练均衡的生成模型。此外，我们提出了一种偏见缓解损失函数，该函数能够在不均衡的数据集上提高公平度指标，并且可以保持图像质量。我们在使用FFHQ数据集进行遥感匈灵抑制问题中证明了我们的方法的有效性，并且在不均衡的Cifar-10数据集上验证了我们的方法。最后，我们 argue That traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details></li>
</ul>
<hr>
<h2 id="FedPop-Federated-Population-based-Hyperparameter-Tuning"><a href="#FedPop-Federated-Population-based-Hyperparameter-Tuning" class="headerlink" title="FedPop: Federated Population-based Hyperparameter Tuning"></a>FedPop: Federated Population-based Hyperparameter Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08634">http://arxiv.org/abs/2308.08634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 该论文旨在提出一种新的分布式机器学习（Federated Learning，FL）中的参数优化算法，以提高FL的性能。</li>
<li>methods: 该论文提出了一种基于种群进化算法的参数优化算法，称为Federated Population-based Hyperparameter Tuning（FedPop），以优化FL中的参数。</li>
<li>results: 实验结果表明，FedPop比PRIOR的HP优化方法更高效，在常见的FL benchmark和实际世界FL数据集上显著提高了FL的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning (ML) paradigm, in which multiple clients collaboratively train ML models without centralizing their local data. Similar to conventional ML pipelines, the client local optimization and server aggregation procedure in FL are sensitive to the hyperparameter (HP) selection. Despite extensive research on tuning HPs for centralized ML, these methods yield suboptimal results when employed in FL. This is mainly because their "training-after-tuning" framework is unsuitable for FL with limited client computation power. While some approaches have been proposed for HP-Tuning in FL, they are limited to the HPs for client local updates. In this work, we propose a novel HP-tuning algorithm, called Federated Population-based Hyperparameter Tuning (FedPop), to address this vital yet challenging problem. FedPop employs population-based evolutionary algorithms to optimize the HPs, which accommodates various HP types at both client and server sides. Compared with prior tuning methods, FedPop employs an online "tuning-while-training" framework, offering computational efficiency and enabling the exploration of a broader HP search space. Our empirical validation on the common FL benchmarks and complex real-world FL datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the concurrent state-of-the-art HP tuning methods for FL.
</details>
<details>
<summary>摘要</summary>
Federated Learning (FL) 是一种分布式机器学习 (ML) 模式，在多个客户端协同训练 ML 模型时，不需要集中客户端的本地数据。与传统的 ML 管道类似，在 FL 中客户端本地优化和服务器聚合过程中的超参数 (HP) 选择也是敏感的。尽管有大量关于中心化 ML 中HP的优化研究，这些方法在 FL 中具有较差的效果，主要因为它们的 "训练后优化" 框架不适合 FL 中限制的客户端计算能力。一些对 FL 中HP的优化方法已经被提出，但它们只适用于客户端本地更新中的HP。在这项工作中，我们提出了一种新的HP优化算法，called Federated Population-based Hyperparameter Tuning (FedPop)，以解决这一重要但具有挑战性的问题。FedPop 使用人口生物学算法优化 HP，可以满足多种 HP 类型在客户端和服务器端。相比之前的优化方法，FedPop 采用在线 "优化while training" 框架，可以提高计算效率，并允许探索更广泛的 HP 搜索空间。我们对常见 FL benchmark 和复杂的实际 FL 数据进行了实验 validate，结果表明我们提出的方法效果明显超过了当前状态的HP优化方法 для FL。
</details></li>
</ul>
<hr>
<h2 id="LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data"><a href="#LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data" class="headerlink" title="LSTM-Based Forecasting Model for GRACE Accelerometer Data"></a>LSTM-Based Forecasting Model for GRACE Accelerometer Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08621">http://arxiv.org/abs/2308.08621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers">https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers</a></li>
<li>paper_authors: Neda Darbeheshti, Elahe Moradi</li>
<li>for: This paper is written for monitoring variations in Earth’s gravity field and filling data gaps in the GRACE satellite mission.</li>
<li>methods: The paper uses Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.</li>
<li>results: The model demonstrates effectiveness in filling gaps and forecasting GRACE accelerometer data, with accurate predictions for the three axes.<details>
<summary>Abstract</summary>
The Gravity Recovery and Climate Experiment (GRACE) satellite mission, spanning from 2002 to 2017, has provided a valuable dataset for monitoring variations in Earth's gravity field, enabling diverse applications in geophysics and hydrology. The mission was followed by GRACE Follow-On in 2018, continuing data collection efforts. The monthly Earth gravity field, derived from the integration different instruments onboard satellites, has shown inconsistencies due to various factors, including gaps in observations for certain instruments since the beginning of the GRACE mission.   With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details>
<details>
<summary>摘要</summary>
格拉vity Recovery和气候实验(GRACE)卫星任务，从2002年至2017年，提供了对地球重力场变化的珍贵数据集，用于气象和地球物理多种应用。这个任务被GRACE Follow-On在2018年继承，继续数据采集。月度地球重力场，由卫星上不同仪器的集成，具有各种因素引起的不一致，包括GRACE任务开始时的某些仪器观测 gap。  With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details></li>
</ul>
<hr>
<h2 id="Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought"><a href="#Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought" class="headerlink" title="Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought"></a>Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08614">http://arxiv.org/abs/2308.08614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lei, pei-Hung Lin, Chunhua Liao, Caiwen Ding</li>
<li>for: 提高大规模模型对复杂问题的逻辑推理能力</li>
<li>methods: 提出了一种新的引导技术 called Graph of Thoughts (GoT)</li>
<li>results: 在三个增加的挑战任务中，与 GPT-4 和 Tree of Thought (ToT) 相比，我们的方法实现了 $89.7%$, $86%$, $56%$ 的准确率提高，并且与 SOTA 方法的平均准确率提高 $23%$, $24%$, $15%$。<details>
<summary>Abstract</summary>
Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.
</details>
<details>
<summary>摘要</summary>
最近的大规模模型，如GPT-4，已经表现出了解决标准问题的很好的能力。然而，当面临复杂的问题需要多步逻辑推理时，其准确率会减少很多。现有研究在\textit{提示工程}（prompting engineering）领域进行了研究，以增强这些模型的推理能力。我们的论文揭示了一种新的提示技术，名为\textit{思维图（GoT）}。在三个逐渐增加的挑战任务中：24点游戏、高度波动方程的解决和递归序列的公式 derivation 中，我们的方法比GPT-4高效，实现了准确率提高的89.7%、86%和56%。此外，与现有最佳实践（SOTA）提示方法，\textit{树思维（ToT）}，相比，我们的方法在平均上registered一个23%、24%和15%的准确率提高。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach"><a href="#Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach" class="headerlink" title="Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach"></a>Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08611">http://arxiv.org/abs/2308.08611</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Wahid, I faiud, K. Mason</li>
<li>for: 这个研究用于优化农业领域 photovoltaic (PV) 系统的决策。</li>
<li>methods: 这个研究使用深度Q学习网络（DQN）来帮助农业投资者做出有数据支持的决策，包括考虑安装预算、政府激励、能源需求、系统成本以及长期效益。</li>
<li>results: 这个研究提供了一个全面的理解，如何使用DQN来支持农业投资者做出PV安装的决策，以及该技术在农业领域的应用可能性。这些研究结果对推广可持续可靠的农业实践，提高能源效益，降低环境影响，提高利润等方面具有重要意义。<details>
<summary>Abstract</summary>
This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Atom-by-atom-protein-generation-and-beyond-with-language-models"><a href="#Atom-by-atom-protein-generation-and-beyond-with-language-models" class="headerlink" title="Atom-by-atom protein generation and beyond with language models"></a>Atom-by-atom protein generation and beyond with language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09482">http://arxiv.org/abs/2308.09482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Flam-Shepherd, Kevin Zhu, Alán Aspuru-Guzik</li>
<li>for: 这paper是为了探索使用语言模型来生成蛋白质的可能性。</li>
<li>methods: 这paper使用了化学语言模型来学习蛋白质的原子层次表示，并可以生成不受标准遗传码限制的蛋白质。</li>
<li>results: 这paper的结果表明，语言模型可以学习蛋白质的多层次结构，从原始序列到次结构和三维结构，并可以生成不受标准遗传码限制的蛋白质，还可以同时探索蛋白质和化学空间，并生成新的蛋白质-药物 conjugate。<details>
<summary>Abstract</summary>
Protein language models learn powerful representations directly from sequences of amino acids. However, they are constrained to generate proteins with only the set of amino acids represented in their vocabulary. In contrast, chemical language models learn atom-level representations of smaller molecules that include every atom, bond, and ring. In this work, we show that chemical language models can learn atom-level representations of proteins enabling protein generation unconstrained to the standard genetic code and far beyond it. In doing so, we show that language models can generate entire proteins atom by atom -- effectively learning the multiple hierarchical layers of molecular information that define proteins from their primary sequence to their secondary, and tertiary structure. We demonstrate language models are able to explore beyond protein space -- generating proteins with modified sidechains that form unnatural amino acids. Even further, we find that language models can explore chemical space and protein space simultaneously and generate novel examples of protein-drug conjugates. The results demonstrate the potential for biomolecular design at the atom level using language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Proprioceptive-Learning-with-Soft-Polyhedral-Networks"><a href="#Proprioceptive-Learning-with-Soft-Polyhedral-Networks" class="headerlink" title="Proprioceptive Learning with Soft Polyhedral Networks"></a>Proprioceptive Learning with Soft Polyhedral Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08538">http://arxiv.org/abs/2308.08538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobo Liu, Xudong Han, Wei Hong, Fang Wan, Chaoyang Song</li>
<li>for: 这篇论文旨在开发一种能够实现自适应肢体位姿感知的软体网络，以提高现代机器人的敏捷、适应性和感知能力。</li>
<li>methods: 该论文使用了软体网络和内置的视觉系统，通过学习动态力学特征来实现适应性和感知。</li>
<li>results: 实验结果显示，软体网络可以在实时感知6个自由度力和扭矩的同时，精度为0.25&#x2F;0.24&#x2F;0.35 N和0.025&#x2F;0.034&#x2F;0.006 Nm，并在静态适应中包含滑动和塑性修正以提高预测结果。<details>
<summary>Abstract</summary>
Proprioception is the "sixth sense" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low cost with more than 1 million use cycles for tasks such as sensitive and competitive grasping, and touch-based geometry reconstruction. This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction.
</details>
<details>
<summary>摘要</summary>
Proprioception 是Robotics中的"六感"，它通过motor neurons探测 LIMB 姿势。它需要自然的 musculoskeletal 系统和感官器件之间的集成，这是现代Robotics中的挑战，因为它们需要轻量、适应性和敏捷的设计，同时需要低成本。在这篇文章中，我们提出了Soft Polyhedral Network，它具有嵌入式的视觉系统，能够进行适应的运动和弹簧 proprioception，通过学习运动特征来进行预测。这个设计允许机器人在无方向互动中进行自适应，并且可以通过高速动态追踪系统进行 proprioceptive 学习。实验结果显示，软网络可以在实时进行6D 力和扭矩的测量，精度为0.25/0.24/0.35 N 和 0.025/0.034/0.006 Nm。我们还将viscoelasticity 加入 proprioception 中，以更好地精确地预测结果。我们的软网络结合了简单的设计、适应性和 proprioceptive 感知，并且具有高精度和低成本，适合Robotics 中的多种任务，如敏捷和竞争性的抓取、触碰基本重建等。这篇文章将带来新的见解到视基 proprioception 领域，对于软机器人在适应抓取、软操作和人机交互等方面的应用有很大的潜力。
</details></li>
</ul>
<hr>
<h2 id="Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems"><a href="#Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems" class="headerlink" title="Can Transformers Learn Optimal Filtering for Unknown Systems?"></a>Can Transformers Learn Optimal Filtering for Unknown Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08536">http://arxiv.org/abs/2308.08536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haldun Balim, Zhe Du, Samet Oymak, Necmiye Ozay</li>
<li>for: 这个论文的目的是用 transformers 来解决 dynamical systems 中的优化输出估计问题。</li>
<li>methods: 这个论文使用 transformers 来生成输出预测，使用所有过去的输出来生成当前输出预测。论文通过在不同系统上进行训练，以实现在新的系统上快速适应和预测。</li>
<li>results: 这个论文的结果表明，使用 transformers 可以具有很高的预测性能，并且可以在具有非同异idi 噪声、时间变化动力学和非线性动力学等挑战的场景中表现良好。论文还提供了对 MOP 的统计保证和测试时间内的过程中所需的训练量。<details>
<summary>Abstract</summary>
Transformers have demonstrated remarkable success in natural language processing; however, their potential remains mostly unexplored for problems arising in dynamical systems. In this work, we investigate the optimal output estimation problem using transformers, which generate output predictions using all the past ones. We train the transformer using various systems drawn from a prior distribution and then evaluate its performance on previously unseen systems from the same distribution. As a result, the obtained transformer acts like a prediction algorithm that learns in-context and quickly adapts to and predicts well for different systems - thus we call it meta-output-predictor (MOP). MOP matches the performance of the optimal output estimator, based on Kalman filter, for most linear dynamical systems even though it does not have access to a model. We observe via extensive numerical experiments that MOP also performs well in challenging scenarios with non-i.i.d. noise, time-varying dynamics, and nonlinear dynamics like a quadrotor system with unknown parameters. To further support this observation, in the second part of the paper, we provide statistical guarantees on the performance of MOP and quantify the required amount of training to achieve a desired excess risk during test-time. Finally, we point out some limitations of MOP by identifying two classes of problems MOP fails to perform well, highlighting the need for caution when using transformers for control and estimation.
</details>
<details>
<summary>摘要</summary>
transformers 已经展示出了惊人的成功在自然语言处理领域;然而，它们的潜力还未得到了充分的探索，尤其是在动力系统中。在这项工作中，我们使用 transformers 来解决输出预测问题，它们使用所有过去的输出来生成输出预测。我们使用不同的系统从先验分布中随机选择训练数据，然后评估其性能在未经见过的系统上。因此，我们得到的 transformer 被称为元输出预测器 (MOP)。MOP与优化的输出估计器（基于 kalman 滤波器）的性能相当，即使它没有访问模型。我们通过广泛的数值实验发现，MOP 在非相关噪声、时间变化动力学和不确定参数的 quadrotor 系统中也表现良好。在第二部分的论文中，我们提供了对 MOP 性能的统计保证，并估计在测试时需要多少训练时间来达到所需的过量风险。最后，我们指出了 MOP 在某些情况下的限制，并标识了使用 transformers 进行控制和估计时需要小心的两类问题。
</details></li>
</ul>
<hr>
<h2 id="Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches"><a href="#Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches" class="headerlink" title="Painter: Teaching Auto-regressive Language Models to Draw Sketches"></a>Painter: Teaching Auto-regressive Language Models to Draw Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08520">http://arxiv.org/abs/2308.08520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Pourreza, Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Pulkit Madan, Roland Memisevic</li>
<li>for: 这个论文主要针对大语言模型（LLMs）在自然语言理解方面的进步，以及在其他领域如计算机视觉、机器人学习等领域的应用。</li>
<li>methods: 本文使用LLMs直接生成虚拟的毫线笔触来绘制图像。我们提出了Painter，一个基于市场上可购买的LLM，通过对新任务进行细化而不失去语言理解能力来构建Painter。</li>
<li>results: Painter可以从文本描述转换为绘制图像，从图像中移除对象，并检测和分类图像中的对象。虽然这是一项前所未有的使用LLMs进行自动进程图像生成的研究，但结果很鼓励人。<details>
<summary>Abstract</summary>
Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经取得了巨大的进步，并在其他领域如计算机视觉、机器人学、奖励学习等领域中得到成功应用。在这项工作中，我们将LLM应用到图像生成任务中，直接生成虚拟的毫幅笔触来绘制图像。我们提出了“艺术家”（Painter），一种可以根据用户提示转化为笔触的LLM。我们基于市场上可获得的LLM，通过精度调整和保留语言理解能力来构建Painter。我们创建了包含多种物体绘制和任务的多样化笔触集合，并将Painter应用于这些笔触集合中。Painter可以根据文本提示生成笔触，从笔触中移除物体，并探测和分类笔触中的物体。虽然这是使用LLM进行自然语言到自动生成图像的前所未有的做法，但结果非常鼓动人心。
</details></li>
</ul>
<hr>
<h2 id="Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems"><a href="#Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems" class="headerlink" title="Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems"></a>Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08511">http://arxiv.org/abs/2308.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirong Li, Yanyang Wang, Jianjia Zhang, Weiwen Wu, Hengyong Yu</li>
<li>for: 提高CT和MRI图像重建的精度和效率，解决不同的 inverse problem。</li>
<li>methods: 基于Score-based模型，通过在2D空间学习数据分布，然后在3D空间更新数据分布来实现更精度的重建。</li>
<li>results: 在大规模的稀缺视图CT和快速MRI数据集上进行了广泛的实验，比较了现有的方法，并达到了目前最佳的解决3D稀缺 inverse problem 的效果。<details>
<summary>Abstract</summary>
Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial technologies in the field of medical imaging. Score-based models have proven to be effective in addressing different inverse problems encountered in CT and MRI, such as sparse-view CT and fast MRI reconstruction. However, these models face challenges in achieving accurate three dimensional (3D) volumetric reconstruction. The existing score-based models primarily focus on reconstructing two dimensional (2D) data distribution, leading to inconsistencies between adjacent slices in the reconstructed 3D volumetric images. To overcome this limitation, we propose a novel two-and-a-half order score-based model (TOSM). During the training phase, our TOSM learns data distributions in 2D space, which reduces the complexity of training compared to directly working on 3D volumes. However, in the reconstruction phase, the TOSM updates the data distribution in 3D space, utilizing complementary scores along three directions (sagittal, coronal, and transaxial) to achieve a more precise reconstruction. The development of TOSM is built on robust theoretical principles, ensuring its reliability and efficacy. Through extensive experimentation on large-scale sparse-view CT and fast MRI datasets, our method demonstrates remarkable advancements and attains state-of-the-art results in solving 3D ill-posed inverse problems. Notably, the proposed TOSM effectively addresses the inter-slice inconsistency issue, resulting in high-quality 3D volumetric reconstruction.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 和 magnetism resonance imaging (MRI) 是医学影像领域的关键技术。分数模型已经证明可以有效地解决 CT 和 MRI 中的不同的反问题，如稀疏视图 CT 和快速 MRI 重建。然而，这些模型在实现准确的三维（3D）卷积重建方面遇到了挑战。现有的分数模型主要是对二维（2D）数据分布进行重建，从而导致扫描图像中的邻域匹配不准确。为解决这个限制，我们提出了一种新的二阶半分数模型（TOSM）。在训练阶段，我们的 TOSM 学习了数据分布在二维空间，从而降低了训练的复杂性。然而，在重建阶段，TOSM 将数据分布更新到三维空间，利用三个方向（极轴、极圆、和扫描）的补做分数来实现更加精确的重建。TOSM 的开发基于Robust的理论原则，确保其可靠性和效果。通过对大规模稀疏视图 CT 和快速 MRI 数据进行广泛的实验，我们的方法在解决 3D 负定问题中具有显著的进步和达到了当前最佳结果。特别是，我们的 TOSM 能够有效地解决邻域不一致问题，从而实现高质量的 3D 卷积重建。
</details></li>
</ul>
<hr>
<h2 id="Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater"><a href="#Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater" class="headerlink" title="Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater"></a>Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08510">http://arxiv.org/abs/2308.08510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bionicdl-sustech/amphibioussoftfinger">https://github.com/bionicdl-sustech/amphibioussoftfinger</a></li>
<li>paper_authors: Ning Guo, Xudong Han, Xiaobo Liu, Shuqiao Zhong, Zhiyuan Zhou, Jian Lin, Jiansheng Dai, Fang Wan, Chaoyang Song</li>
<li>for: 该研究旨在提高水下机器人的物体抓取稳定性和可靠性，以支持生态环境和海洋研究的基础科学发现。</li>
<li>methods: 该研究使用了视觉基于的软体机器人手指，通过监督VARAE学习6D力和扭矩（FT）。高速摄像机记录了软机器人手指与物体之间的整体塑变，以获得更好的学习效果。</li>
<li>results: 研究结果显示，SVAE模型学习到了从陆地到水中的软机械学的各种秘密代表，在改变环境中具有Superior的适应能力，与商业FT传感器相比，提供了更加稳定和可靠的抓取。这种感觉智能抓取技术将为水下机器人带来更好的可靠性和可重复性，为生态环境和海洋研究带来更多的支持。<details>
<summary>Abstract</summary>
Robots play a critical role as the physical agent of human operators in exploring the ocean. However, it remains challenging to grasp objects reliably while fully submerging under a highly pressurized aquatic environment with little visible light, mainly due to the fluidic interference on the tactile mechanics between the finger and object surfaces. This study investigates the transferability of grasping knowledge from on-land to underwater via a vision-based soft robotic finger that learns 6D forces and torques (FT) using a Supervised Variational Autoencoder (SVAE). A high-framerate camera captures the whole-body deformations while a soft robotic finger interacts with physical objects on-land and underwater. Results show that the trained SVAE model learned a series of latent representations of the soft mechanics transferrable from land to water, presenting a superior adaptation to the changing environments against commercial FT sensors. Soft, delicate, and reactive grasping enabled by tactile intelligence enhances the gripper's underwater interaction with improved reliability and robustness at a much-reduced cost, paving the path for learning-based intelligent grasping to support fundamental scientific discoveries in environmental and ocean research.
</details>
<details>
<summary>摘要</summary>
роботы играют критическую роль как физические агенты человеческих операторов в исследовании океана. Однако, было трудно удерживать объекты надежно, когда полностью погружались в высокопрессURIZрованную акватическую среду с ограниченным видимым светом, главным образом из-за динамической интерференции между поверхностями пальца и объекта. Этот исследование изучает передачу знаний о захвате с наземных в подводные условия с помощью визуальной базированной мягкой роботической пальца, которая обучается 6D силам и моментам (FT) с помощью надсмотренного верификатора автоенкодера (SVAE). Высококачественный камеруCaptures Whole-Body Deformations While Interacting with Physical Objects On-Land and Underwater. Results Show That the Trained SVAE Model Learned a Series of Latent Representations of Soft Mechanics Transferable from Land to Water, Presenting a Superior Adaptation to Changing Environments Against Commercial FT Sensors. Soft, Delicate, and Reactive Grasping Enabled by Tactile Intelligence Enhances the Gripper's Underwater Interaction with Improved Reliability and Robustness at a Much-Reduced Cost, Paving the Path for Learning-Based Intelligent Grasping to Support Fundamental Scientific Discoveries in Environmental and Ocean Research.
</details></li>
</ul>
<hr>
<h2 id="ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures"><a href="#ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures" class="headerlink" title="ResBuilder: Automated Learning of Depth with Residual Structures"></a>ResBuilder: Automated Learning of Depth with Residual Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08504">http://arxiv.org/abs/2308.08504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Burghoff, Matthias Rottmann, Jill von Conta, Sebastian Schoenen, Andreas Witte, Hanno Gottschalk</li>
<li>for: 本文开发了一种基于神经网络搜索算法，即Resbuilder，可以从头开始构建高精度低计算成本的ResNet架构。它还可以修改现有架构，并且可以移除和插入ResNet块，从而在ResNet架构空间进行搜索。</li>
<li>methods: 本文使用了一种基于隐藏状态抽象的搜索算法，并且使用了一种新的强化策略来优化搜索结果。在不同的图像分类任务上进行了实验，Resbuilder能够几乎与状态地标的性能匹配，同时减少了计算成本。</li>
<li>results: 本文在不同的图像分类任务上的实验结果表明，Resbuilder能够减少计算成本，同时保持高精度。此外，通过对一个Proprietary fraud detection dataset进行应用，表明了该方法在实际应用中的一致性。<details>
<summary>Abstract</summary>
In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost. It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures. In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets. We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们开发了一种神经网络搜索算法，即Resbuilder，它可以从头开始开发高精度低计算成本的ResNet架构。它还可以修改现有架构，并且具有将ResNet块添加或删除的能力，从而在ResNet架构空间进行搜索。在我们对不同的图像分类 dataset 进行实验中，Resbuilder 可以达到 state-of-the-art 性能，而且与 commercially 可用的 ResNet 相比，计算成本更低。值得一提的是，我们在 CIFAR10 上调参得到了一个适合所有其他 dataset 的默认选择，并且我们证明这种性能可以普遍应用于工业应用程序，例如在一个 proprietary 销售欺诈数据集上使用 default 参数。
</details></li>
</ul>
<hr>
<h2 id="Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models"><a href="#Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models" class="headerlink" title="Time Travel in LLMs: Tracing Data Contamination in Large Language Models"></a>Time Travel in LLMs: Tracing Data Contamination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08493">http://arxiv.org/abs/2308.08493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahriar Golchin, Mihai Surdeanu</li>
<li>for: 本研究旨在检测大语言模型（LLM）训练数据中是否存在测试数据污染问题。</li>
<li>methods: 本研究提出了一种简单 yet有效的方法来识别LLM中的数据污染。该方法包括对个别实例进行识别污染，然后判断整个数据分区是否受到污染。</li>
<li>results: 研究发现，使用“导向指令”（一个包含数据集名称、分区类型和参考实例的提示）来评估实例是否受到污染，可以准确地检测LLM中的数据污染。此外，研究还发现GPT-4中存在数据污染问题，特别是AG News、WNLI和XSum数据集。<details>
<summary>Abstract</summary>
Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ "guided instruction:" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name. The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.
</details>
<details>
<summary>摘要</summary>
大数据污染，即大语言模型（LLM）训练数据中下游任务的测试数据存在的问题，是 LLM 效果理解的 potential 主要问题。我们提出了一种简单 yet 有效的方法来在 LLM 中 Identify 数据污染。我们的方法的核心是在小样本中随机选择的实例上 Identify 数据污染。使用这些信息，我们的方法然后判断整个数据分区是否污染。为了估计实例上的污染，我们采用 "导向指令"：一个包含数据集名、分区类型和参考实例的开头的提示，请 LLM 完成它。如果 LLM 的输出与参考实例的后半部分匹配，则标记该实例为污染。为了理解整个分区是否污染，我们提出了两个想法。第一个想法是如果使用 ROUGE 或 BLEURT  measure 参考实例与指令之间的 overlap 得分为 statistically  significiantly 高于不包含数据集和分区名的通用指令，那么将标记该分区为污染。第二个想法是如果一个基于 GPT-4 的类ifier 通过受Context learning 提示标记多个实例为污染，那么将标记该数据集为污染。我们的最佳方法在七个数据集（包括训练和测试/验证分区）上达到了92% 到 100% 的准确率，与人工评估 compare 。此外，我们发现 GPT-4 污染 AG News、WNLI 和 XSum 数据集。
</details></li>
</ul>
<hr>
<h2 id="Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals"><a href="#Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals" class="headerlink" title="Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals"></a>Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08480">http://arxiv.org/abs/2308.08480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clara Macabiau, Thanh-Dung Le, Kevin Albert, Philippe Jouvet, Rita Noumeir</li>
<li>for: 这个研究探讨了在受到运动干扰的情况下如何使用标签卷传递技术来标注医疗数据集，特别是在不平衡的类型场景下，清洁的PPG样本被干扰样本所显著多出。</li>
<li>methods: 这种研究使用了标签卷传递技术来传递标签到PPG样本中，并与支持学习模型（包括传统类ifiers和神经网络）进行比较。</li>
<li>results: 研究结果表明，使用标签卷传递技术可以准确地标注PPG样本，尤其是在清洁样本罕见时。与支持学习模型相比，标签卷传递算法在检测干扰物时表现更好。这些结果表明，标签卷传递算法在PPG信号中的干扰物检测中具有潜在的优势。<details>
<summary>Abstract</summary>
Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring vital signs, but they are susceptible to motion artifacts that can lead to inaccurate interpretations. In this study, the use of label propagation techniques to propagate labels among PPG samples is explored, particularly in imbalanced class scenarios where clean PPG samples are significantly outnumbered by artifact-contaminated samples. With a precision of 91%, a recall of 90% and an F1 score of 90% for the class without artifacts, the results demonstrate its effectiveness in labeling a medical dataset, even when clean samples are rare. For the classification of artifacts our study compares supervised classifiers such as conventional classifiers and neural networks (MLP, Transformers, FCN) with the semi-supervised label propagation algorithm. With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN supervised model gives good results, but the semi-supervised algorithm performs better in detecting artifacts. The findings suggest that the semi-supervised algorithm label propagation hold promise for artifact detection in PPG signals, which can enhance the reliability of PPG-based health monitoring systems in real-world applications.
</details>
<details>
<summary>摘要</summary>
对于artifact的分类，我们比较了传统的supervised类ifiers（例如conventional classifiers和神经网络）与 semi-supervised label propagation algorithm。与89%的精度、95%的回归率和92%的F1 Score相比，KNN 超vised模型给出了不错的结果，但semi-supervised algorithm在检测artifacts方面表现更好。研究结果表明，semi-supervised algorithm label propagation在 PPG 信号中检测artifacts 有前途，可以提高 PPG 基于健康监测系统的可靠性在实际应用中。
</details></li>
</ul>
<hr>
<h2 id="LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs"><a href="#LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs" class="headerlink" title="LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs"></a>LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08469">http://arxiv.org/abs/2308.08469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ching Chang, Wen-Chih Peng, Tien-Fu Chen</li>
<li>for: 提高长期时间序列预测精度</li>
<li>methods: 利用预训练的大语言模型（LLM）进行时间序列预测，并采用时间补充和时间编码等技术增强LLM对时间序列数据的处理能力。</li>
<li>results: 通过两stage精度调整和多 Parameter-Efficient Fine-Tuning（PEFT）技术，实现了长期预测的状态艺能，并且能够快速适应新的时间序列数据。<details>
<summary>Abstract</summary>
In this work, we leverage pre-trained Large Language Models (LLMs) to enhance time-series forecasting. Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting. Due to limited large-scale time-series data for building robust foundation models, our approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By combining time-series patching with temporal encoding, we have enhanced the capability of LLMs to handle time-series data effectively. Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art results in long-term forecasting. Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们利用预训练的大语言模型（LLM）来提高时间序列预测。随着自然语言处理和计算机视觉模型的统一的兴趣增长，我们意识到创建相应的模型。由于有限的大规模时间序列数据建立坚实的基础模型，我们的方法LLM4TS将注重利用预训练LLM的优势。通过将时间序列补丁与时间编码结合，我们已经提高了LLM对时间序列数据的处理能力。 Drawing on the supervised fine-tuning experience in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Our model has yielded state-of-the-art results in long-term forecasting, and has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.
</details></li>
</ul>
<hr>
<h2 id="An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks"><a href="#An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks" class="headerlink" title="An Expert’s Guide to Training Physics-informed Neural Networks"></a>An Expert’s Guide to Training Physics-informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08468">http://arxiv.org/abs/2308.08468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/predictiveintelligencelab/jaxpi">https://github.com/predictiveintelligencelab/jaxpi</a></li>
<li>paper_authors: Sifan Wang, Shyam Sankaran, Hanwen Wang, Paris Perdikaris</li>
<li>for: 本研究旨在提高physics-informed neural networks（PINNs）的训练效率和总体准确性，并提供一系列最佳实践和挑战性 benchmark 问题，以便未来研究者可以使用这些方法和指导原则进行比较。</li>
<li>methods: 本研究使用了一系列最佳实践和architecture choices，包括使用 JAX 库进行高效的训练和推理，以及进行了完整的ablation study，以确定不同的训练策略和architecture的影响。</li>
<li>results: 本研究的结果表明，采用本研究提出的方法和指导原则，可以获得state-of-the-art的结果，并提供了strong baselines，可以用于 future studies 的比较。此外，本研究还发布了一个高度优化的 JAX 库，可以用于重现所有结果，以及为新用例场景进行扩展和适应。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints. Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise. In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs. We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models. We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes. To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios.
</details>
<details>
<summary>摘要</summary>
物理学 informed neural networks (PINNs) 已经广泛应用于深度学习框架，可以快速生成观察数据和部分偏微分方程 (PDE) 约束的模型。然而，它们的实际效果可能受到训练问题和用户缺乏深度学习知识所妨碍。在这篇论文中，我们提出了一系列最佳实践，可以大幅提高 PINNs 的训练效率和总准确率。我们还提出了一系列挑战性的 benchmark 问题，描述了 PINNs 训练中的一些最 prominent difficulties，并进行了完整和可重现的剥离研究，以示不同架构选择和训练策略对模型测试准确率的影响。我们显示了我们在这篇论文中提出的方法和指导原则可以获得 estado-of-the-art 结果，并提供了强大的基准值，以便 future studies 可以用于比较。为此，我们还发布了高度优化的库在 JAX 上，可以重现所有报告在这篇论文中的结果，促进未来研究，以及方便将新的应用场景适应到现有的模型。
</details></li>
</ul>
<hr>
<h2 id="On-Neural-Quantum-Support-Vector-Machines"><a href="#On-Neural-Quantum-Support-Vector-Machines" class="headerlink" title="On Neural Quantum Support Vector Machines"></a>On Neural Quantum Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08467">http://arxiv.org/abs/2308.08467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML">https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML</a></li>
<li>paper_authors: Lars Simon, Manuel Radons</li>
<li>for: 本研究旨在探讨神经量子支持向量机（NSVM）的训练方法。</li>
<li>methods: 本文使用四种算法来训练神经支持向量机（NSVM），并证明其可行性。</li>
<li>results: 本文延伸了前一文中的结果，提出神经量子支持向量机（NSVM）和量子核函数的概念，并对其进行扩展。<details>
<summary>Abstract</summary>
In \cite{simon2023algorithms} we introduced four algorithms for the training of neural support vector machines (NSVMs) and demonstrated their feasibility. In this note we introduce neural quantum support vector machines, that is, NSVMs with a quantum kernel, and extend our results to this setting.
</details>
<details>
<summary>摘要</summary>
在《《Algorithms for Training Neural Support Vector Machines》》中（[simon2023algorithms）我们介绍了四种算法用于神经支持向量机（NSVM）的训练，并证明其可行性。在这份note中，我们介绍了神经量子支持向量机（NSVM），即具有量子核函数的NSVM，并扩展我们的结果到这种设定下。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks"><a href="#Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks" class="headerlink" title="Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks"></a>Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08465">http://arxiv.org/abs/2308.08465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Bai, Wenjia Bai</li>
<li>for: 这个论文的目的是建立一个可靠的医学图像分割模型，以及计算模型预测结果的不确定性。</li>
<li>methods: 这个论文使用了一种简单 yet effective的方法，利用 hierarchical image representation 和 skip-connection module 来估计模型预测结果的不确定性。</li>
<li>results: 这个论文的实验结果表明，通过将这种 hierarchical uncertainty estimation module 加入到深度学习图像分割网络中，可以实现高效的图像分割，同时提供了有意义的不确定性地图，可以用于out-of-distribution排除。<details>
<summary>Abstract</summary>
Learning a medical image segmentation model is an inherently ambiguous task, as uncertainties exist in both images (noise) and manual annotations (human errors and bias) used for model training. To build a trustworthy image segmentation model, it is important to not just evaluate its performance but also estimate the uncertainty of the model prediction. Most state-of-the-art image segmentation networks adopt a hierarchical encoder architecture, extracting image features at multiple resolution levels from fine to coarse. In this work, we leverage this hierarchical image representation and propose a simple yet effective method for estimating uncertainties at multiple levels. The multi-level uncertainties are modelled via the skip-connection module and then sampled to generate an uncertainty map for the predicted image segmentation. We demonstrate that a deep learning segmentation network such as U-net, when implemented with such hierarchical uncertainty estimation module, can achieve a high segmentation performance, while at the same time provide meaningful uncertainty maps that can be used for out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
学习医学图像分割模型是一个自然存在各种不确定性的任务，图像中的噪声和人工标注（人类错误和偏见）在模型训练中都存在不确定性。为建立可靠的图像分割模型，不仅需要评估其性能，还需要估计模型预测结果的不确定性。现有大多数状态的艺术图像分割网络采用层次编码结构，从细致到粗略提取图像特征。在这种工作中，我们利用这种层次图像表示，并提议一种简单 yet effective的方法来估计多个水平的不确定性。这些多个不确定性被模拟为跳过连接模块，然后采样以生成预测图像分割结果的不确定性地图。我们示示了一个深度学习分割网络如U-Net，当其与多个水平不确定性估计模块相结合时，可以实现高级别的分割性能，同时也可以提供有意义的不确定性地图，用于非标准分布检测。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.LG_2023_08_17/" data-id="clly4xtdy006zvl885poi96wi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.SD_2023_08_17/" class="article-date">
  <time datetime="2023-08-16T16:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.SD_2023_08_17/">cs.SD - 2023-08-17 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features"><a href="#Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features" class="headerlink" title="Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features"></a>Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09042">http://arxiv.org/abs/2308.09042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarsana Reddy Kadiri, Manila Kodali, Paavo Alku</li>
<li>for: 本研究旨在提出一种新的评估多动性 Parkinson 病（PD）严重程度的对象方法，以提高诊断和治疗的效果。</li>
<li>methods: 该研究使用了单频 filtering（SFF）方法 derive two sets of novel features：（1）SFF cepstral coefficients（SFFCC）和（2）MFCCs from SFF（MFCC-SFF），用于分类PD严重程度。SFF 方法可提供更高的spectro-temporal resolution，而且在多种应用中有着广泛的应用。</li>
<li>results: 实验使用 SVM 分类器，表明提案的特征在三种说话任务（元音、句子、文本读取）中都有出色的表现，与传统的 MFCC 特征相比，提案的 SFFCC 和 MFCC-SFF 特征在元音任务中提高了5.8%和2.3%，在句子任务中提高了7.0%和1.8%，在文本读取任务中提高了2.4%和1.1%。<details>
<summary>Abstract</summary>
Developing objective methods for assessing the severity of Parkinson's disease (PD) is crucial for improving the diagnosis and treatment. This study proposes two sets of novel features derived from the single frequency filtering (SFF) method: (1) SFF cepstral coefficients (SFFCC) and (2) MFCCs from the SFF (MFCC-SFF) for the severity classification of PD. Prior studies have demonstrated that SFF offers greater spectro-temporal resolution compared to the short-time Fourier transform. The study uses the PC-GITA database, which includes speech of PD patients and healthy controls produced in three speaking tasks (vowels, sentences, text reading). Experiments using the SVM classifier revealed that the proposed features outperformed the conventional MFCCs in all three speaking tasks. The proposed SFFCC and MFCC-SFF features gave a relative improvement of 5.8% and 2.3% for the vowel task, 7.0% & 1.8% for the sentence task, and 2.4% and 1.1% for the read text task, in comparison to MFCC features.
</details>
<details>
<summary>摘要</summary>
开发Objective方法评估parkinson病（PD）的严重程度是诊断和治疗的关键。本研究提出了两组新的特征：（1）单频 filtering（SFF）cepstral coefficient（SFFCC）和（2）MFCC from SFF（MFCC-SFF），用于PD严重分类。前研究表明，SFF提供了更高的spectro-temporal分辨率，比short-time Fourier transform。本研究使用PC-GITA数据库，包括PD患者和健康控制者在三种说话任务（vowel、 sentence、 text reading）中的speech。实验表明，提议的特征比普通的MFCC在所有三种说话任务中表现出色，相比MFCC特征，SFFCC和MFCC-SFF特征在vowel任务中提供了5.8%和2.3%的相对改进，在 sentence任务中提供了7.0%和1.8%的相对改进，在read text任务中提供了2.4%和1.1%的相对改进。
</details></li>
</ul>
<hr>
<h2 id="Home-monitoring-for-frailty-detection-through-sound-and-speaker-diarization-analysis"><a href="#Home-monitoring-for-frailty-detection-through-sound-and-speaker-diarization-analysis" class="headerlink" title="Home monitoring for frailty detection through sound and speaker diarization analysis"></a>Home monitoring for frailty detection through sound and speaker diarization analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08985">http://arxiv.org/abs/2308.08985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yannis Tevissen, Dan Istrate, Vincent Zalc, Jérôme Boudy, Gérard Chollet, Frédéric Petitpont, Sami Boutamine</li>
<li>for: 这个研究是为了开发一个可靠、隐私保护的家庭监测系统，以预防衰老 population 中的衰退。</li>
<li>methods: 这个研究使用了最新的声音处理和speaker diarization技术，以提高现有的嵌入式系统的性能。</li>
<li>results: 研究表明，使用深度神经网络（DNN）的方法可以提高性能，比传统方法提高约100%。<details>
<summary>Abstract</summary>
As the French, European and worldwide populations are aging, there is a strong interest for new systems that guarantee a reliable and privacy preserving home monitoring for frailty prevention. This work is a part of a global environmental audio analysis system which aims to help identification of Activities of Daily Life (ADL) through human and everyday life sounds recognition, speech presence and number of speakers detection. The focus is made on the number of speakers detection. In this article, we present how recent advances in sound processing and speaker diarization can improve the existing embedded systems. We study the performances of two new methods and discuss the benefits of DNN based approaches which improve performances by about 100%.
</details>
<details>
<summary>摘要</summary>
“由于法国、欧洲和全球人口年龄增长，有强大的需求对于保证可靠且隐私保护的家居监控系统。这个工作是全球环境音频分析系统的一部分，旨在通过人类日常生活声音识别、语音存在和说话人数检测来帮助活动日常生活（ADL）的识别。我们在这篇文章中介绍了最新的音频处理和Speaker diarization技术的进步，并评估了这两种新方法的表现。我们发现这些方法可以提高现有的嵌入式系统表现，并且这些方法的表现提升约100%。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Explicit-Estimation-of-Magnitude-and-Phase-Spectra-in-Parallel-for-High-Quality-Speech-Enhancement"><a href="#Explicit-Estimation-of-Magnitude-and-Phase-Spectra-in-Parallel-for-High-Quality-Speech-Enhancement" class="headerlink" title="Explicit Estimation of Magnitude and Phase Spectra in Parallel for High-Quality Speech Enhancement"></a>Explicit Estimation of Magnitude and Phase Spectra in Parallel for High-Quality Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08926">http://arxiv.org/abs/2308.08926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye-Xin Lu, Yang Ai, Zhen-Hua Ling</li>
<li>for: 提高Speech perceived质量和可读性</li>
<li>methods: 提出了一种新的Speech Enhancement Network（MP-SENet），通过并行地提高了Magnitude和Phasespectra的表示</li>
<li>results: 实验结果表明，MP-SENet在多个任务中具有高质量的Speech增强，包括Speech denoising、dereverberation和频带扩展，并且成功避免了对Magnitude和Phase的相互赔偿效果，从而实现了更好的harmonic Restoration。特别是在Speech denoising任务上，MP-SENet实现了公共数据集VoiceBank+DEMAND上的最佳性能，PESQ为3.60。<details>
<summary>Abstract</summary>
Phase information has a significant impact on speech perceptual quality and intelligibility. However, existing speech enhancement methods encounter limitations in explicit phase estimation due to the non-structural nature and wrapping characteristics of the phase, leading to a bottleneck in enhanced speech quality. To overcome the above issue, in this paper, we proposed MP-SENet, a novel Speech Enhancement Network which explicitly enhances Magnitude and Phase spectra in parallel. The proposed MP-SENet adopts a codec architecture in which the encoder and decoder are bridged by time-frequency Transformers along both time and frequency dimensions. The encoder aims to encode time-frequency representations derived from the input distorted magnitude and phase spectra. The decoder comprises dual-stream magnitude and phase decoders, directly enhancing magnitude and wrapped phase spectra by incorporating a magnitude estimation architecture and a phase parallel estimation architecture, respectively. To train the MP-SENet model effectively, we define multi-level loss functions, including mean square error and perceptual metric loss of magnitude spectra, anti-wrapping loss of phase spectra, as well as mean square error and consistency loss of short-time complex spectra. Experimental results demonstrate that our proposed MP-SENet excels in high-quality speech enhancement across multiple tasks, including speech denoising, dereverberation, and bandwidth extension. Compared to existing phase-aware speech enhancement methods, it successfully avoids the bidirectional compensation effect between the magnitude and phase, leading to a better harmonic restoration. Notably, for the speech denoising task, the MP-SENet yields a state-of-the-art performance with a PESQ of 3.60 on the public VoiceBank+DEMAND dataset.
</details>
<details>
<summary>摘要</summary>
干扰信息对语音质量和可读性有着重要的影响。然而，现有的语音增强方法在显式阶段的阶段估计中遇到了限制，因为干扰信息的非结构性和包袋特性，导致增强语音质量的瓶颈。为解决上述问题，在这篇论文中，我们提出了MP-SENet，一种新的语音增强网络。MP-SENet在平行地增强了大小和频谱的谱 spectrum。提案的MP-SENet采用了codec架构，编码器和解码器通过时间频率变换器在时间和频率维度上相互连接。编码器的目标是将时间频率表示转化为输入损坏的大小和频谱 spectra。解码器包括两个同步的大小和包袋解码器，直接使用包含大小估计架构和包袋平行估计架构来增强损坏的大小和包袋 spectra。为了训练MP-SENet模型，我们定义了多级损失函数，包括平均平方误差和感知度 metric损失、反包袋损失、平均平方误差和一致性损失。实验结果表明，我们的提案的MP-SENet在多个任务中实现了高质量的语音增强，包括语音干扰、频率抑制和频谱扩展。与现有的阶段意识的语音增强方法相比，MP-SENet成功避免了对大小和频谱的双向赔率效应，从而实现了更好的干扰还原。特别是在语音干扰任务中，MP-SENet的PESQ为3.60，在公共的 VoiceBank+DEMAND 数据集上达到了状态机的性能。
</details></li>
</ul>
<hr>
<h2 id="Long-frame-shift-Neural-Speech-Phase-Prediction-with-Spectral-Continuity-Enhancement-and-Interpolation-Error-Compensation"><a href="#Long-frame-shift-Neural-Speech-Phase-Prediction-with-Spectral-Continuity-Enhancement-and-Interpolation-Error-Compensation" class="headerlink" title="Long-frame-shift Neural Speech Phase Prediction with Spectral Continuity Enhancement and Interpolation Error Compensation"></a>Long-frame-shift Neural Speech Phase Prediction with Spectral Continuity Enhancement and Interpolation Error Compensation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08850">http://arxiv.org/abs/2308.08850</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangai520/lfs-nspp">https://github.com/yangai520/lfs-nspp</a></li>
<li>paper_authors: Yang Ai, Ye-Xin Lu, Zhen-Hua Ling</li>
<li>for: 提高信号处理领域中语音频谱预测的精度，使其能够准确地预测长框框帧偏移的语音频谱。</li>
<li>methods: 提出了一种基于神经网络的长框帧偏移预测方法（LFS-NSPP），包括三个阶段： interpolate、predict和decimate。首先将长框帧频谱spectra interpolated到短框帧频谱spectra的频谱上，然后使用NSPP模型预测短框帧偏移 spectra，最后将长框帧偏移 spectra decimated into short-frame shift phase spectra。</li>
<li>results: 实验结果表明，提出的LFS-NSPP方法可以在预测长框帧偏移 phase spectra方面达到更高的质量，比原始NSPP模型和其他信号处理基于频谱估算法更好。<details>
<summary>Abstract</summary>
Speech phase prediction, which is a significant research focus in the field of signal processing, aims to recover speech phase spectra from amplitude-related features. However, existing speech phase prediction methods are constrained to recovering phase spectra with short frame shifts, which are considerably smaller than the theoretical upper bound required for exact waveform reconstruction of short-time Fourier transform (STFT). To tackle this issue, we present a novel long-frame-shift neural speech phase prediction (LFS-NSPP) method which enables precise prediction of long-frame-shift phase spectra from long-frame-shift log amplitude spectra. The proposed method consists of three stages: interpolation, prediction and decimation. The short-frame-shift log amplitude spectra are first constructed from long-frame-shift ones through frequency-by-frequency interpolation to enhance the spectral continuity, and then employed to predict short-frame-shift phase spectra using an NSPP model, thereby compensating for interpolation errors. Ultimately, the long-frame-shift phase spectra are obtained from short-frame-shift ones through frame-by-frame decimation. Experimental results show that the proposed LFS-NSPP method can yield superior quality in predicting long-frame-shift phase spectra than the original NSPP model and other signal-processing-based phase estimation algorithms.
</details>
<details>
<summary>摘要</summary>
干扰语音阶段预测（Speech phase prediction）是信号处理领域的一个重要研究方向，旨在从振荡功率相关特征中恢复语音阶段спектроgram。然而，现有的语音阶段预测方法都是固定的具有短框架偏移的phaspectra，这些偏移远小于理论最大允许的束缚波形重建短时域 Fourier transform（STFT）。为解决这个问题，我们提出了一种新的长框架偏移神经语音阶段预测（LFS-NSPP）方法，可以准确预测长框架偏移phaspectra从长框架偏移log amplitude spectra。该方法包括三个阶段： interpolate、predict和decimate。首先，从长框架偏移log amplitude spectra中提取出频率维度上的各个频率域的短框架偏移spectra，然后使用NSPP模型预测短框架偏移phaspectra，从而补偿插值错误。最后，通过frame-by-frame decimation，从短框架偏移phaspectra中提取出长框架偏移phaspectra。实验结果表明，提出的LFS-NSPP方法可以在预测长框架偏移phaspectra的质量上提高比原NSPP模型和其他信号处理基于阶段估计算法。
</details></li>
</ul>
<hr>
<h2 id="META-SELD-Meta-Learning-for-Fast-Adaptation-to-the-new-environment-in-Sound-Event-Localization-and-Detection"><a href="#META-SELD-Meta-Learning-for-Fast-Adaptation-to-the-new-environment-in-Sound-Event-Localization-and-Detection" class="headerlink" title="META-SELD: Meta-Learning for Fast Adaptation to the new environment in Sound Event Localization and Detection"></a>META-SELD: Meta-Learning for Fast Adaptation to the new environment in Sound Event Localization and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08847">http://arxiv.org/abs/2308.08847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbo Hu, Yin Cao, Ming Wu, Feiran Yang, Ziying Yu, Wenwu Wang, Mark D. Plumbley, Jun Yang</li>
<li>for: 这个研究是为了解决学习型 зву标定和探测（SELD）方法在不同的Acoustic环境下的性能差异问题。</li>
<li>methods: 这个研究使用了Meta-学习方法来实现快速适应新环境。基于Model Agnostic Meta-Learning（MAML）的Meta-SELD，将寻找适合新环境的初始化参数，并快速适应未见过的环境。</li>
<li>results: 实验结果显示，Meta-SELD在适应新环境方面效果非常好。<details>
<summary>Abstract</summary>
For learning-based sound event localization and detection (SELD) methods, different acoustic environments in the training and test sets may result in large performance differences in the validation and evaluation stages. Different environments, such as different sizes of rooms, different reverberation times, and different background noise, may be reasons for a learning-based system to fail. On the other hand, acquiring annotated spatial sound event samples, which include onset and offset time stamps, class types of sound events, and direction-of-arrival (DOA) of sound sources is very expensive. In addition, deploying a SELD system in a new environment often poses challenges due to time-consuming training and fine-tuning processes. To address these issues, we propose Meta-SELD, which applies meta-learning methods to achieve fast adaptation to new environments. More specifically, based on Model Agnostic Meta-Learning (MAML), the proposed Meta-SELD aims to find good meta-initialized parameters to adapt to new environments with only a small number of samples and parameter updating iterations. We can then quickly adapt the meta-trained SELD model to unseen environments. Our experiments compare fine-tuning methods from pre-trained SELD models with our Meta-SELD on the Sony-TAU Realistic Spatial Soundscapes 2023 (STARSSS23) dataset. The evaluation results demonstrate the effectiveness of Meta-SELD when adapting to new environments.
</details>
<details>
<summary>摘要</summary>
для学习基于声学Event localization and detection（SELD）方法，不同的声学环境在训练和测试集中可能会导致大幅度的性能差异在验证和评估阶段。不同的环境，如不同的房间大小、不同的延迟时间和不同的背景噪音，可能是学习基于系统失败的原因。同时，获取标注的空间声Event样本，包括启动和终止时间戳、声音事件类型和声音源的方向来达（DOA），非常昂贵。此外，在新环境中部署SELD系统经常会出现时间consuming的训练和精度调整问题。为解决这些问题，我们提出Meta-SELD，它应用meta学方法来实现快速适应新环境。更具体地说，基于Model Agnostic Meta-Learning（MAML），我们的Meta-SELD寻找适合新环境的好初始化参数，只需要一小数量的样本和参数更新迭代即可快速适应新环境。我们的实验比较了从预训练SELD模型的细化方法与我们的Meta-SELD在SONY-TAU Realistic Spatial Soundscapes 2023（STARSSS23）数据集上的性能。评估结果表明，Meta-SELD在适应新环境时非常有效。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Network-Backend-for-Speaker-Recognition"><a href="#Graph-Neural-Network-Backend-for-Speaker-Recognition" class="headerlink" title="Graph Neural Network Backend for Speaker Recognition"></a>Graph Neural Network Backend for Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08767">http://arxiv.org/abs/2308.08767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang He, Ruida Li, Mengqi Niu</li>
<li>for: 提高 speaker recognition 精度</li>
<li>methods: 使用图 neural network (GNN)  backend， Mine latent relationships among embeddings for classification</li>
<li>results: 在 NIST SRE14 i-vector challenging、VoxCeleb1-O、VoxCeleb1-E 和 VoxCeleb1-H 数据集上，与主流方法相比，提出的 GNN  backend 显示出了显著的提高。<details>
<summary>Abstract</summary>
Currently, most speaker recognition backends, such as cosine, linear discriminant analysis (LDA), or probabilistic linear discriminant analysis (PLDA), make decisions by calculating similarity or distance between enrollment and test embeddings which are already extracted from neural networks. However, for each embedding, the local structure of itself and its neighbor embeddings in the low-dimensional space is different, which may be helpful for the recognition but is often ignored. In order to take advantage of it, we propose a graph neural network (GNN) backend to mine latent relationships among embeddings for classification. We assume all the embeddings as nodes on a graph, and their edges are computed based on some similarity function, such as cosine, LDA+cosine, or LDA+PLDA. We study different graph settings and explore variants of GNN to find a better message passing and aggregation way to accomplish the recognition task. Experimental results on NIST SRE14 i-vector challenging, VoxCeleb1-O, VoxCeleb1-E, and VoxCeleb1-H datasets demonstrate that our proposed GNN backends significantly outperform current mainstream methods.
</details>
<details>
<summary>摘要</summary>
当前大多数说话识别后端，如cosine、线性混合分析（LDA）或概率线性混合分析（PLDA），做出决策时通常计算测试和托管模型之间的相似性或距离。然而，每个嵌入都有自己本地结构，与邻居嵌入在低维度空间中的结构不同，这可能对识别有帮助，但通常被忽略。为了利用这一点，我们提议使用图ael neural network（GNN）后端，挖掘嵌入之间的隐藏关系，用于分类。我们将所有嵌入视为图ael中的节点，其间的边是根据某种相似函数，如cosine、LDA+cosine或LDA+PLDA计算。我们研究不同的图ael设置和GNN变体，找到更好的消息传递和聚合方式，以完成识别任务。实验结果表明，我们提议的GNN后端在NIST SRE14 i-vector挑战、VoxCeleb1-O、VoxCeleb1-E和VoxCeleb1-H数据集上显著超越了当前主流方法。
</details></li>
</ul>
<hr>
<h2 id="The-DKU-MSXF-Speaker-Verification-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#The-DKU-MSXF-Speaker-Verification-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="The DKU-MSXF Speaker Verification System for the VoxCeleb Speaker Recognition Challenge 2023"></a>The DKU-MSXF Speaker Verification System for the VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08766">http://arxiv.org/abs/2308.08766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Li, Yuke Lin, Xiaoyi Qin, Ning Jiang, Guoqing Zhao, Ming Li</li>
<li>for: 本文是DKU-MSXF系统的track1、track2和track3的VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）系统描述。</li>
<li>methods: 我们使用基于ResNet的网络结构进行训练，并通过构建跨年龄QMF训练集来实现显著提高系统性能。</li>
<li>results: 在track1中，我们通过混合训练方法和VOXBLINK-clean数据集来提高模型性能，相比track1，包含VOXBLINK-clean数据集的模型表现提高了 más de 10%。在track3中，我们采用了一种新的假标签方法，并通过三个阈值和子中心纯化来进行频率附加预测，最终提交得分为task1的mDCF0.1243、track2的mDCF0.1165和track3的EER4.952%。<details>
<summary>Abstract</summary>
This paper is the system description of the DKU-MSXF System for the track1, track2 and track3 of the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23). For Track 1, we utilize a network structure based on ResNet for training. By constructing a cross-age QMF training set, we achieve a substantial improvement in system performance. For Track 2, we inherite the pre-trained model from Track 1 and conducte mixed training by incorporating the VoxBlink-clean dataset. In comparison to Track 1, the models incorporating VoxBlink-clean data exhibit a performance improvement by more than 10% relatively. For Track3, the semi-supervised domain adaptation task, a novel pseudo-labeling method based on triple thresholds and sub-center purification is adopted to make domain adaptation. The final submission achieves mDCF of 0.1243 in task1, mDCF of 0.1165 in Track 2 and EER of 4.952% in Track 3.
</details>
<details>
<summary>摘要</summary>
这篇论文是DKU-MSXF系统的系统描述，用于VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的track1、track2和track3。在track1中，我们采用基于ResNet的网络结构进行训练，通过构建跨年龄QMF训练集，实现了显著提高系统性能。在track2中，我们继承了track1中的预训练模型，并通过将VoxBlink-clean数据集integrated进行混合训练，相比track1，模型包含VoxBlink-clean数据显示了超过10%的性能提高。在track3中，我们采用了一种新的半监督领域适应方法，基于 triple thresholds和sub-center purification，实现了领域适应。最终提交的结果为task1中的mDCF为0.1243，track2中的mDCF为0.1165，以及track3中的EER为4.952%。
</details></li>
</ul>
<hr>
<h2 id="Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition"><a href="#Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition" class="headerlink" title="Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition"></a>Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08713">http://arxiv.org/abs/2308.08713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/95anantsingh/decoding-emotions">https://github.com/95anantsingh/decoding-emotions</a></li>
<li>paper_authors: Anant Singh, Akshat Gupta</li>
<li>for: 这paper主要是为了评估多种语言下的语音情感识别（SER）模型，以及这些模型的内部表示方法。</li>
<li>methods: 这paper使用了八种语音表示模型和六种语言进行比较，并通过 probing 实验来探索这些模型的内部工作方式。</li>
<li>results: 这paper得到了 average 的错误率下降32%，并在德语和波斯语中达到了状态的最佳 результаados。 probing 结果表明，语音模型的中间层 capture 最重要的情感信息。<details>
<summary>Abstract</summary>
Recent advancements in transformer-based speech representation models have greatly transformed speech processing. However, there has been limited research conducted on evaluating these models for speech emotion recognition (SER) across multiple languages and examining their internal representations. This article addresses these gaps by presenting a comprehensive benchmark for SER with eight speech representation models and six different languages. We conducted probing experiments to gain insights into inner workings of these models for SER. We find that using features from a single optimal layer of a speech model reduces the error rate by 32\% on average across seven datasets when compared to systems where features from all layers of speech models are used. We also achieve state-of-the-art results for German and Persian languages. Our probing results indicate that the middle layers of speech models capture the most important emotional information for speech emotion recognition.
</details>
<details>
<summary>摘要</summary>
近期的变换器基本模型在语音处理方面做出了重要进步，但是对于多语言语音情感识别（SER）的评估和内部表示却受到了有限的研究。本文填补这些差距，通过提供八种语音表示模型和六种不同语言的完整性评估。我们进行了探索实验，以了解这些模型内部的工作方式。我们发现，从单一最佳层的语音模型中提取特征可以降低错误率平均为32%，比较于使用所有层语音模型特征系统来说。我们还在德国语和波斯语方面达到了状态的最佳成绩。我们的探索结果表明，语音模型的中间层 capture最重要的情感信息。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.SD_2023_08_17/" data-id="clly4xtes00a4vl88ffowdwm1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/eess.IV_2023_08_17/" class="article-date">
  <time datetime="2023-08-16T16:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/eess.IV_2023_08_17/">eess.IV - 2023-08-17 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation"><a href="#Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation" class="headerlink" title="Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation"></a>Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08974">http://arxiv.org/abs/2308.08974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yilinliu610730/eoe">https://github.com/yilinliu610730/eoe</a></li>
<li>paper_authors: Yilin Liu, Ruining Deng, Juming Xiong, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo</li>
<li>for: 该研究旨在提高食管炎症诊断的精度和效率，并且提供一种自动化的诊断方法。</li>
<li>methods: 该研究使用了圆形表示法和圆形蛇形模型来实现自动化的实例 segmentation。</li>
<li>results: 对比传统的Mask R-CNN模型和DeepSnake模型，圆形蛇形模型在识别和分割嗜好蛋白质方面表现出了superiority，这可能地提高了EoE诊断的精度和效率。<details>
<summary>Abstract</summary>
Eosinophilic esophagitis (EoE) is a chronic and relapsing disease characterized by esophageal inflammation. Symptoms of EoE include difficulty swallowing, food impaction, and chest pain which significantly impact the quality of life, resulting in nutritional impairments, social limitations, and psychological distress. The diagnosis of EoE is typically performed with a threshold (15 to 20) of eosinophils (Eos) per high-power field (HPF). Since the current counting process of Eos is a resource-intensive process for human pathologists, automatic methods are desired. Circle representation has been shown as a more precise, yet less complicated, representation for automatic instance cell segmentation such as CircleSnake approach. However, the CircleSnake was designed as a single-label model, which is not able to deal with multi-label scenarios. In this paper, we propose the multi-label CircleSnake model for instance segmentation on Eos. It extends the original CircleSnake model from a single-label design to a multi-label model, allowing segmentation of multiple object types. Experimental results illustrate the CircleSnake model's superiority over the traditional Mask R-CNN model and DeepSnake model in terms of average precision (AP) in identifying and segmenting eosinophils, thereby enabling enhanced characterization of EoE. This automated approach holds promise for streamlining the assessment process and improving diagnostic accuracy in EoE analysis. The source code has been made publicly available at https://github.com/yilinliu610730/EoE.
</details>
<details>
<summary>摘要</summary>
《营养细胞损伤综合征（EoE）是一种慢性和再次发生的疾病，特征为食管内部的Inflammation。EoE的症状包括困难吞食、食物堵塞和胸痛，对生活质量产生重大影响，导致营养不良、社会限制和心理压力。EoE的诊断通常通过Esophageal高力场（HPF）中Eosinophils（Eos）的数量（15-20）进行。由于当前的Eos数计数过程需要人工Pathologist的劳动，因此自动方法被欢迎。圆形表示已被证明为更精准， yet less complicated的表示方法，但它是单标签模型，无法处理多标签场景。本文提出了基于圆形的多标签CircleSnake模型，用于实例分 segmentation。这个模型从单标签设计扩展到多标签模型，可以进行多种对象类型的分 segmentation。实验结果表明，CircleSnake模型在AP（准确率）方面与传统的Mask R-CNN模型和DeepSnake模型相比，在标识和分 segmentationEosinophils方面表现出了超过其他两个模型的优势。这种自动化方法可以提高EoE分析过程的效率和准确性，并且代码已经在https://github.com/yilinliu610730/EoE上公开发布。
</details></li>
</ul>
<hr>
<h2 id="An-inexact-proximal-majorization-minimization-Algorithm-for-remote-sensing-image-stripe-noise-removal"><a href="#An-inexact-proximal-majorization-minimization-Algorithm-for-remote-sensing-image-stripe-noise-removal" class="headerlink" title="An inexact proximal majorization-minimization Algorithm for remote sensing image stripe noise removal"></a>An inexact proximal majorization-minimization Algorithm for remote sensing image stripe noise removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08866">http://arxiv.org/abs/2308.08866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjing Wang, Xile Zhao, Qingsong Wang, Zepei Ma, Peipei Tang</li>
<li>for: 提高远程感知图像中的视觉质量和数据分析精度，抑制远程感知图像中的梭噪。</li>
<li>methods: 提出非凸模型，使用DC函数结构进行梭噪除除。解决方法利用DC结构和不准确的 proximal 大esten-multipliers 算法，并设计实现的停止条件。</li>
<li>results: 数值实验表明提出的模型和算法在梭噪除除方面具有superiority。<details>
<summary>Abstract</summary>
The stripe noise existing in remote sensing images badly degrades the visual quality and restricts the precision of data analysis. Therefore, many destriping models have been proposed in recent years. In contrast to these existing models, in this paper, we propose a nonconvex model with a DC function (i.e., the difference of convex functions) structure to remove the strip noise. To solve this model, we make use of the DC structure and apply an inexact proximal majorization-minimization algorithm with each inner subproblem solved by the alternating direction method of multipliers. It deserves mentioning that we design an implementable stopping criterion for the inner subproblem, while the convergence can still be guaranteed. Numerical experiments demonstrate the superiority of the proposed model and algorithm.
</details>
<details>
<summary>摘要</summary>
“远程感知图像中的条纹噪音会严重损害视觉质量和数据分析精度。因此，过去几年内，许多条纹除去模型已经被提出。与现有模型不同，在本文中，我们提出了一种非凸模型，其结构是基于差分 convex 函数（DC 函数）。为解决这个模型，我们利用 DC 结构，并采用不准确的 proximal 主要化-最小化算法，其中每个内部子问题通过 alternate direction method of multipliers 解决。值得一提的是，我们设计了可实施的停止条件，而且可以保证 converge。数值实验表明，提出的模型和算法具有优势。”Here's a word-for-word translation of the text into Simplified Chinese:“远程感知图像中的条纹噪音会严重损害视觉质量和数据分析精度。因此，过去几年内，许多条纹除去模型已经被提出。与现有模型不同，在本文中，我们提出了一种非凸模型，其结构是基于差分 convex 函数（DC 函数）。为解决这个模型，我们利用 DC 结构，并采用不准确的 proximal 主要化-最小化算法，其中每个内部子问题通过 alternate direction method of multipliers 解决。值得一提的是，我们设计了可实施的停止条件，而且可以保证 converge。数值实验表明，提出的模型和算法具有优势。”
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution"><a href="#End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution" class="headerlink" title="End-to-end Alternating Optimization for Real-World Blind Super Resolution"></a>End-to-end Alternating Optimization for Real-World Blind Super Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08816">http://arxiv.org/abs/2308.08816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/greatlog/realdan">https://github.com/greatlog/realdan</a></li>
<li>paper_authors: Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan<br>for: 这个论文的目的是提出一种基于 alternate optimization 算法的盲SR方法，以提高盲SR的精度和稳定性。methods: 该方法使用了两个卷积神经网络：Restorer 和 Estimator。 Restorer 用于还原 SR 图像，而 Estimator 用于估计质量损失。这两个模块在 alternate 的形式下进行循环训练，以便互相优化。results: 实验表明，提出的方法可以大幅超越当前state-of-the-art 方法，并生成更加可观的结果。<details>
<summary>Abstract</summary>
Blind Super-Resolution (SR) usually involves two sub-problems: 1) estimating the degradation of the given low-resolution (LR) image; 2) super-resolving the LR image to its high-resolution (HR) counterpart. Both problems are ill-posed due to the information loss in the degrading process. Most previous methods try to solve the two problems independently, but often fall into a dilemma: a good super-resolved HR result requires an accurate degradation estimation, which however, is difficult to be obtained without the help of original HR information. To address this issue, instead of considering these two problems independently, we adopt an alternating optimization algorithm, which can estimate the degradation and restore the SR image in a single model. Specifically, we design two convolutional neural modules, namely \textit{Restorer} and \textit{Estimator}. \textit{Restorer} restores the SR image based on the estimated degradation, and \textit{Estimator} estimates the degradation with the help of the restored SR image. We alternate these two modules repeatedly and unfold this process to form an end-to-end trainable network. In this way, both \textit{Restorer} and \textit{Estimator} could get benefited from the intermediate results of each other, and make each sub-problem easier. Moreover, \textit{Restorer} and \textit{Estimator} are optimized in an end-to-end manner, thus they could get more tolerant of the estimation deviations of each other and cooperate better to achieve more robust and accurate final results. Extensive experiments on both synthetic datasets and real-world images show that the proposed method can largely outperform state-of-the-art methods and produce more visually favorable results. The codes are rleased at \url{https://github.com/greatlog/RealDAN.git}.
</details>
<details>
<summary>摘要</summary>
干Resolution（SR）问题通常包含两个互相关联的互补问题：1）估计LR图像的劣化程度；2）LR图像的超Resolution（HR）图像。两个问题都是不定的，因为升级过程中的信息损失。大多数前一代方法会独立地解决这两个问题，但经常陷入一个困境：一个好的HR图像需要一个准确的劣化估计，但是不可以不使用原始HR图像来获得这个估计。为解决这个问题，我们采用了一种alternating optimization算法，可以同时估计劣化和SR图像。我们设计了两个卷积神经网络模块：Restorer和Estimator。Restorer使用估计的劣化来恢复SR图像，而Estimator使用恢复后的SR图像来估计劣化。我们重复地使用这两个模块，并将其拓展成一个端到端可训练的网络。这样，Restorer和Estimator都可以受益于对方的中间结果，使每个问题变得更加容易。此外，Restorer和Estimator在端到端上进行了结构优化，因此它们可以更快地适应对方的估计偏差，并更好地合作以实现更加稳定和准确的最终结果。我们在 synthetic datasets 和实际图像上进行了广泛的实验，结果显示，我们的方法可以与当前状态计算机技术相比，大幅提高SR图像的质量。代码可以在 \url{https://github.com/greatlog/RealDAN.git} 中下载。
</details></li>
</ul>
<hr>
<h2 id="Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images"><a href="#Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images" class="headerlink" title="Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images"></a>Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08732">http://arxiv.org/abs/2308.08732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aidan S. Wright, Nathaniel P. Youmans, Enrique F. Valderrama Araya</li>
<li>for: 这种 computational framework 的目的是为了精准检测和全面分析 SEM 图像中的粒子。</li>
<li>methods: 这个框架使用了 Python 图像处理库 OpenCV、SciPy 和 Scikit-Image，并结合了阈值处理、膨润和推杂等技术来提高图像处理结果的准确性。</li>
<li>results: 这个框架可以准确地确定粒子坐标，并提取粒子的相关形态特征，包括面积、方向、亮度和长度。 它在五个不同的测试图像中达到 97% 的粒子检测精度。<details>
<summary>Abstract</summary>
In this study, we present a computational framework tailored for the precise detection and comprehensive analysis of nanoparticles within scanning electron microscopy (SEM) images. The primary objective of this framework revolves around the accurate localization of nanoparticle coordinates, accompanied by secondary objectives encompassing the extraction of pertinent morphological attributes including area, orientation, brightness, and length.   Constructed leveraging the robust image processing capabilities of Python, particularly harnessing libraries such as OpenCV, SciPy, and Scikit-Image, the framework employs an amalgamation of techniques, including thresholding, dilating, and eroding, to enhance the fidelity of image processing outcomes.   The ensuing nanoparticle data is seamlessly integrated into the RStudio environment to facilitate meticulous post-processing analysis. This encompasses a comprehensive evaluation of model accuracy, discernment of feature distribution patterns, and the identification of intricate particle arrangements. The finalized framework exhibits high nanoparticle identification within the primary sample image and boasts 97\% accuracy in detecting particles across five distinct test images drawn from a SEM nanoparticle dataset. Furthermore, the framework demonstrates the capability to discern nanoparticles of faint intensity, eluding manual labeling within the control group.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一个计算框架，用于精确检测和全面分析射电镜像（SEM）中的粒子。主要目标是准确地确定粒子坐标，并且包括次要目标，如粒子形态特征的提取，包括面积、方向、亮度和长度。这个框架利用Python的强大图像处理能力，特别是OpenCV、SciPy和Scikit-Image库，结合多种技术，如阈值、扩展和膨润，以提高图像处理结果的准确性。获得的粒子数据可以轻松地 интегрирова到RStudio环境中，进行仔细的后处理分析。这包括完整评估模型准确性，分析特征分布图像，以及识别复杂的粒子排列。实验结果显示，该框架在主要样本图像中具有高精度的粒子检测，并在五个不同的测试图像中达到97%的检测精度。此外，框架还能够识别具有柔弱亮度的粒子，而控制组中的人工标注不能达到。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression"><a href="#Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression" class="headerlink" title="Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression"></a>Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08723">http://arxiv.org/abs/2308.08723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Huairui/DKIC">https://github.com/Huairui/DKIC</a></li>
<li>paper_authors: Huairui Wang, Nianxiang Fu, Zhenzhong Chen, Shan Liu</li>
<li>for: 提高图像压缩率和精度性能</li>
<li>methods: 使用动态核kernel基于转换编码，适应权重分享机制和自适应积集方法</li>
<li>results: 实验结果显示，当前方法在三个标准测试集上比现有学习基于方法具有更高的率压缩率和精度性能<details>
<summary>Abstract</summary>
Learned image compression methods have shown superior rate-distortion performance and remarkable potential compared to traditional compression methods. Most existing learned approaches use stacked convolution or window-based self-attention for transform coding, which aggregate spatial information in a fixed range. In this paper, we focus on extending spatial aggregation capability and propose a dynamic kernel-based transform coding. The proposed adaptive aggregation generates kernel offsets to capture valid information in the content-conditioned range to help transform. With the adaptive aggregation strategy and the sharing weights mechanism, our method can achieve promising transform capability with acceptable model complexity. Besides, according to the recent progress of entropy model, we define a generalized coarse-to-fine entropy model, considering the coarse global context, the channel-wise, and the spatial context. Based on it, we introduce dynamic kernel in hyper-prior to generate more expressive global context. Furthermore, we propose an asymmetric spatial-channel entropy model according to the investigation of the spatial characteristics of the grouped latents. The asymmetric entropy model aims to reduce statistical redundancy while maintaining coding efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance on three benchmarks compared to the state-of-the-art learning-based methods.
</details>
<details>
<summary>摘要</summary>
现有的学习型压缩方法已经显示出了Superior rate-distortion性能和吸引人的潜在性，相比传统压缩方法。大多数现有的学习方法使用堆叠 convolution或窗口基于自注意力 для变换编码，这些方法会汇集Fixed距离内的空间信息。在这篇论文中，我们关注到了扩展空间汇集能力，并提出了动态核心基于变换编码。我们的提案的适应汇集生成核心偏移来捕捉有效信息在内容受限的范围内，以帮助变换。通过适应汇集策略和共享权重机制，我们的方法可以实现可接受的变换能力，同时减少模型复杂度。此外，根据最近的Entropy模型进展，我们定义一个通用Coarse-to-fine Entropy模型，考虑Global上下文、通道级和空间上下文。基于它，我们引入动态核心在超乎 prior中生成更 expresive的全局上下文。另外，我们提出一种不对称的空间通道Entropy模型，根据Latent集的特点进行调整。这种不对称Entropy模型的目的是减少统计重复，保持编码效率。实验结果表明，我们的方法在三个标准底本上比State-of-the-art学习型方法 superior rate-distortion性能。
</details></li>
</ul>
<hr>
<h2 id="Deployment-and-Analysis-of-Instance-Segmentation-Algorithm-for-In-field-Grade-Estimation-of-Sweetpotatoes"><a href="#Deployment-and-Analysis-of-Instance-Segmentation-Algorithm-for-In-field-Grade-Estimation-of-Sweetpotatoes" class="headerlink" title="Deployment and Analysis of Instance Segmentation Algorithm for In-field Grade Estimation of Sweetpotatoes"></a>Deployment and Analysis of Instance Segmentation Algorithm for In-field Grade Estimation of Sweetpotatoes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08534">http://arxiv.org/abs/2308.08534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang M. Nguyen, Sydney Gyurek, Russell Mierop, Kenneth V. Pecota, Kylie LaGamba, Michael Boyette, G. Craig Yencho, Cranos M. Williams, Michael W. Kudenov<br>for:这个论文是为了提出一种直接在场地中进行 Storage roots 的检测和评估，以便更快速地获得 yields 的方法。methods:这个方法使用了 Detectron2 库中的深度学习对象检测算法，实现了 Mask R-CNN 模型，用于实时地在场地中识别 Storage roots。results:模型可以在不同的环境条件下（包括光照和土壤特性的变化）正确地识别 Storage roots，并且与商业化光学排分器的比较表明，模型的 RMSE 值为0.66 cm，1.22 cm，74.73 g 分别，而 root 数量的 RMSE 值为5.27根，r^2 值为0.8。这种phenotyping 策略有 potential 用于实时地在场地中获得 yields，而不需要高科技和昂贵的光学排分器。<details>
<summary>Abstract</summary>
Shape estimation of sweetpotato (SP) storage roots is inherently challenging due to their varied size and shape characteristics. Even measuring "simple" metrics, such as length and width, requires significant time investments either directly in-field or afterward using automated graders. In this paper, we present the results of a model that can perform grading and provide yield estimates directly in the field quicker than manual measurements. Detectron2, a library consisting of deep-learning object detection algorithms, was used to implement Mask R-CNN, an instance segmentation model. This model was deployed for in-field grade estimation of SPs and evaluated against an optical sorter. Storage roots from various clones imaged with a cellphone during trials between 2019 and 2020, were used in the model's training and validation to fine-tune a model to detect SPs. Our results showed that the model could distinguish individual SPs in various environmental conditions including variations in lighting and soil characteristics. RMSE for length, width, and weight, from the model compared to a commercial optical sorter, were 0.66 cm, 1.22 cm, and 74.73 g, respectively, while the RMSE of root counts per plot was 5.27 roots, with r^2 = 0.8. This phenotyping strategy has the potential enable rapid yield estimates in the field without the need for sophisticated and costly optical sorters and may be more readily deployed in environments with limited access to these kinds of resources or facilities.
</details>
<details>
<summary>摘要</summary>
sweetpotato (SP) 存储根的形状评估是一项自然的挑战，因为它们的形状和大小具有很大的变化。 même measuring "simple" metrics, such as length and width, requires a significant investment of time, either directly in the field or using automated graders. In this paper, we present the results of a model that can perform grading and provide yield estimates directly in the field faster than manual measurements. We used Detectron2, a library consisting of deep-learning object detection algorithms, to implement Mask R-CNN, an instance segmentation model. This model was deployed for in-field grade estimation of SPs and evaluated against a commercial optical sorter. Storage roots from various clones imaged with a cellphone during trials between 2019 and 2020 were used to fine-tune the model to detect SPs. Our results showed that the model could distinguish individual SPs in various environmental conditions, including variations in lighting and soil characteristics. The root mean squared error (RMSE) for length, width, and weight, from the model compared to a commercial optical sorter, were 0.66 cm, 1.22 cm, and 74.73 g, respectively, while the RMSE of root counts per plot was 5.27 roots, with r^2 = 0.8. This phenotyping strategy has the potential to enable rapid yield estimates in the field without the need for sophisticated and costly optical sorters, and may be more readily deployed in environments with limited access to these kinds of resources or facilities.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Distill-Global-Representation-for-Sparse-View-CT"><a href="#Learning-to-Distill-Global-Representation-for-Sparse-View-CT" class="headerlink" title="Learning to Distill Global Representation for Sparse-View CT"></a>Learning to Distill Global Representation for Sparse-View CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08463">http://arxiv.org/abs/2308.08463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilong Li, Chenglong Ma, Jie Chen, Junping Zhang, Hongming Shan</li>
<li>for: 这篇论文的目的是提出一种新的图像后处理方法，以提高稀疏视角计算Tomography（CT）图像的质量。</li>
<li>methods: 该方法使用了 globale representation（GloRe）核对应法，并通过对GloRe进行方向填充和频率特征填充来提高图像质量。</li>
<li>results: 对比于现有方法，该方法的 globale representation（GloRe）核对应法可以更好地提高稀疏视角CT图像的质量，并且可以更好地捕捉临床重要的诊断信息。<details>
<summary>Abstract</summary>
Sparse-view computed tomography (CT) -- using a small number of projections for tomographic reconstruction -- enables much lower radiation dose to patients and accelerated data acquisition. The reconstructed images, however, suffer from strong artifacts, greatly limiting their diagnostic value. Current trends for sparse-view CT turn to the raw data for better information recovery. The resultant dual-domain methods, nonetheless, suffer from secondary artifacts, especially in ultra-sparse view scenarios, and their generalization to other scanners/protocols is greatly limited. A crucial question arises: have the image post-processing methods reached the limit? Our answer is not yet. In this paper, we stick to image post-processing methods due to great flexibility and propose global representation (GloRe) distillation framework for sparse-view CT, termed GloReDi. First, we propose to learn GloRe with Fourier convolution, so each element in GloRe has an image-wide receptive field. Second, unlike methods that only use the full-view images for supervision, we propose to distill GloRe from intermediate-view reconstructed images that are readily available but not explored in previous literature. The success of GloRe distillation is attributed to two key components: representation directional distillation to align the GloRe directions, and band-pass-specific contrastive distillation to gain clinically important details. Extensive experiments demonstrate the superiority of the proposed GloReDi over the state-of-the-art methods, including dual-domain ones. The source code is available at https://github.com/longzilicart/GloReDi.
</details>
<details>
<summary>摘要</summary>
《简洁 computed tomography（CT）》——使用少量投射进行tomographic重建——可以大幅降低对病人的辐射剂量和数据获取的时间。然而，重建的图像却受到强烈的artefacts的限制，从而大大降低其诊断价值。当前的 sparse-view CT 趋势是转向原始数据，以便更好地回收信息。然而，结果性的 dual-domain 方法在 ultra-sparse 视图场景下受到次要artefact的影响，而且其在其他扫描器/协议上的普遍性受限。问题是：图像后处理方法是否已经达到了限制？我们的答案是不是。在这篇论文中，我们坚持使用图像后处理方法，因为它具有很大的灵活性。我们提出了 GloRe 整合框架（GloReDi），用于 sparse-view CT。首先，我们提出了学习 GloRe 使用 Fourier 杂化，使每个 GloRe 元素具有整个图像的广泛响应场。其次，不同于以前的方法，我们提出了使用 intermediate-view 重建图像进行监督，这些图像ready available，但在前期 литературе未被探讨。 GloRe 整合框架的成功归因于两个关键组成部分： representation directional distillation 用于对 GloRe 方向进行对齐，以及 band-pass-specific contrastive distillation 用于获取临床重要的细节。我们对 GloReDi 进行了广泛的实验，并证明其在state-of-the-art方法之上。源代码可以在 https://github.com/longzilicart/GloReDi 上获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/eess.IV_2023_08_17/" data-id="clly4xtgb00f7vl889abngu69" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/cs.LG_2023_08_16/" class="article-date">
  <time datetime="2023-08-15T16:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/cs.LG_2023_08_16/">cs.LG - 2023-08-16 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Accurate-synthesis-of-Dysarthric-Speech-for-ASR-data-augmentation"><a href="#Accurate-synthesis-of-Dysarthric-Speech-for-ASR-data-augmentation" class="headerlink" title="Accurate synthesis of Dysarthric Speech for ASR data augmentation"></a>Accurate synthesis of Dysarthric Speech for ASR data augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08438">http://arxiv.org/abs/2308.08438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Soleymanpour, Michael T. Johnson, Rahim Soleymanpour, Jeffrey Berry</li>
<li>for: 这篇论文的目的是为了提高自动语音识别（ASR）系统的性能，通过增加疾病某些特征来提供更多的疾病样本。</li>
<li>methods: 这篇论文使用了一种基于神经网络的多话者Text-to-Speech（TTS）系统，并在其中添加了疾病严重程度 coefficient和停顿插入模型，以生成不同疾病严重程度的语音。</li>
<li>results: 这篇论文使用了这种模型来生成训练数据，并通过对其进行语音识别测试来评估其效果。结果显示，在使用这种模型和数据 augmentation 技术后，ASR系统的识别精度得到了显著改善。此外，对比基eline模型，添加疾病严重程度和停顿控制可以降低WRR值6.5%。<details>
<summary>Abstract</summary>
Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech recognition (ASR) systems can help dysarthric talkers communicate more effectively. However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers. This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation. Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation. For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels. To evaluate the effectiveness for synthesis of training data for ASR, dysarthria-specific speech recognition was used. Results show that a DNN-HMM model trained on additional synthetic dysarthric speech achieves WER improvement of 12.2% compared to the baseline, and that the addition of the severity level and pause insertion controls decrease WER by 6.5%, showing the effectiveness of adding these parameters. Overall results on the TORGO database demonstrate that using dysarthric synthetic speech to increase the amount of dysarthric-patterned speech for training has significant impact on the dysarthric ASR systems. In addition, we have conducted a subjective evaluation to evaluate the dysarthric-ness and similarity of synthesized speech. Our subjective evaluation shows that the perceived dysartrhic-ness of synthesized speech is similar to that of true dysarthric speech, especially for higher levels of dysarthria
</details>
<details>
<summary>摘要</summary>
<<SYS>>这是一种 дви力问题，常见于语言生成功能不足的话者。自动语音识别系统（ASR）可以帮助这些话者更有效地沟通。然而，为了建立坚固的动力症特定ASR系统，需要大量的训练语音，但这些语音仅存在于少数话者身上。这篇文章提出了一新的动力症特定语音合成方法，用于ASR训练语音资料增强。在不同的严重程度下，动力症特定语音的语音和态度特征是合成语音模型的重要组成部分。为了合成动力症语音，我们将 modificated neural multi-talker TTS加入了动力症严重程度 coefficient和暂停插入模型，以合成不同严重程度的动力症语音。为了评估这种合成语音的有效性，我们使用了动力症特定语音识别系统。结果显示，将额外的合成动力症语音训练到DNN-HMM模型可以提高WRR值12.2%，并且将严重程度和暂停插入控制添加到合成语音模型可以降低WRR值6.5%，这说明了将这些参数添加的有效性。总结来说，使用动力症合成语音增加训练语音量有重要的影响力在动力症ASR系统。此外，我们还进行了主观评估，以评估合成语音的动力症程度和真实性。我们的主观评估显示，合成语音的动力症程度与真实动力症语音相似，尤其是在更高的严重程度下。这篇文章的结论是，使用动力症合成语音增加训练语音量可以提高动力症ASR系统的性能。这种方法可以帮助建立更加坚固的动力症ASR系统，并且可以增加训练语音量。
</details></li>
</ul>
<hr>
<h2 id="Eliciting-Risk-Aversion-with-Inverse-Reinforcement-Learning-via-Interactive-Questioning"><a href="#Eliciting-Risk-Aversion-with-Inverse-Reinforcement-Learning-via-Interactive-Questioning" class="headerlink" title="Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning"></a>Eliciting Risk Aversion with Inverse Reinforcement Learning via Interactive Questioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08427">http://arxiv.org/abs/2308.08427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziteng Cheng, Anthony Coache, Sebastian Jaimungal</li>
<li>for: 本研究提出了一种新的框架，用于通过交互问答来识别代理人的风险偏好。我们的研究在两种场景下进行了测试：一个一期情况和一个无穷远景情况。在一期情况下，我们假设代理人的风险偏好是一个状态的成本函数和一种扭曲风险度量。在无穷远景情况下，我们模型了代理人的风险偏好，添加了一个优先级因子。假设我们有访问一组候选人，其中包含代理人的真实风险偏好，我们示出了问候者可以通过在不同环境中展示其最佳策略来识别代理人的风险偏好。我们证明，问候者可以通过问答来识别代理人的风险偏好，问题数量增加，问题随机设计。我们还开发了一个算法来设计优化的问题，并在 simulations 中提供了实证证明，我们的方法可以更快地识别代理人的风险偏好，比Randomly designed questions 更快。</li>
<li>methods: 我们的方法包括两个部分：一个是模型代理人的风险偏好，另一个是通过问答来识别代理人的风险偏好。在一期情况下，我们使用了一个成本函数和一种扭曲风险度量来模型代理人的风险偏好。在无穷远景情况下，我们添加了一个优先级因子来模型代理人的风险偏好。我们使用了一种随机设计的问题来识别代理人的风险偏好，并开发了一个算法来设计优化的问题。</li>
<li>results: 我们的实验结果表明，我们的方法可以快速地识别代理人的风险偏好。在 simulations 中，我们发现，我们的方法可以更快地识别代理人的风险偏好，比Randomly designed questions 更快。此外，我们还发现，我们的方法可以更好地适应不同的风险偏好。<details>
<summary>Abstract</summary>
This paper proposes a novel framework for identifying an agent's risk aversion using interactive questioning. Our study is conducted in two scenarios: a one-period case and an infinite horizon case. In the one-period case, we assume that the agent's risk aversion is characterized by a cost function of the state and a distortion risk measure. In the infinite horizon case, we model risk aversion with an additional component, a discount factor. Assuming the access to a finite set of candidates containing the agent's true risk aversion, we show that asking the agent to demonstrate her optimal policies in various environment, which may depend on their previous answers, is an effective means of identifying the agent's risk aversion. Specifically, we prove that the agent's risk aversion can be identified as the number of questions tends to infinity, and the questions are randomly designed. We also develop an algorithm for designing optimal questions and provide empirical evidence that our method learns risk aversion significantly faster than randomly designed questions in simulations. Our framework has important applications in robo-advising and provides a new approach for identifying an agent's risk preferences.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文提出了一种新的方法，用于透过交互问答来确定代理人的风险偏好。我们的研究分为两个场景：一个一期 случа和一个无限远景 случа。在一期 случа中，我们假设代理人的风险偏好是通过状态的成本函数和扭曲风险度量来描述的。在无限远景 случа中，我们模型风险偏好有一个附加组成部分：折扣因子。假设我们有对代理人真实风险偏好的访问权，我们显示出问答可以作为一种有效的风险偏好标识方法。特别是，我们证明代理人的风险偏好可以通过问答的数量增长而被确定，并且问答可以随机设计。我们还开发了一个算法来设计优化的问答，并在实验中证明我们的方法可以在 simulations 中学习风险偏好得到更好的效果。我们的框架在 robo-advising 中有重要应用，并提供了一种新的风险偏好标识方法。
</details></li>
</ul>
<hr>
<h2 id="Digital-twinning-of-cardiac-electrophysiology-models-from-the-surface-ECG-a-geodesic-backpropagation-approach"><a href="#Digital-twinning-of-cardiac-electrophysiology-models-from-the-surface-ECG-a-geodesic-backpropagation-approach" class="headerlink" title="Digital twinning of cardiac electrophysiology models from the surface ECG: a geodesic backpropagation approach"></a>Digital twinning of cardiac electrophysiology models from the surface ECG: a geodesic backpropagation approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08410">http://arxiv.org/abs/2308.08410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Grandits, Jan Verhülsdonk, Gundolf Haase, Alexander Effland, Simone Pezzuto</li>
<li>For: The paper is written for researchers and clinicians interested in cardiac electrophysiology and the development of personalized models of cardiac activation.* Methods: The paper introduces a novel method called Geodesic-BP, which uses the eikonal equation to solve the inverse problem of cardiac electrophysiology and reconstruct a given electrocardiogram (ECG). The method is well-suited for GPU-accelerated machine learning frameworks and can be used to optimize the parameters of the eikonal equation to reproduce a given ECG.* Results: The paper shows that Geodesic-BP can reconstruct a simulated cardiac activation with high accuracy in a synthetic test case, even in the presence of modeling inaccuracies. The method is also applied to a publicly available dataset of a rabbit model, with very positive results.<details>
<summary>Abstract</summary>
The eikonal equation has become an indispensable tool for modeling cardiac electrical activation accurately and efficiently. In principle, by matching clinically recorded and eikonal-based electrocardiograms (ECGs), it is possible to build patient-specific models of cardiac electrophysiology in a purely non-invasive manner. Nonetheless, the fitting procedure remains a challenging task. The present study introduces a novel method, Geodesic-BP, to solve the inverse eikonal problem. Geodesic-BP is well-suited for GPU-accelerated machine learning frameworks, allowing us to optimize the parameters of the eikonal equation to reproduce a given ECG. We show that Geodesic-BP can reconstruct a simulated cardiac activation with high accuracy in a synthetic test case, even in the presence of modeling inaccuracies. Furthermore, we apply our algorithm to a publicly available dataset of a rabbit model, with very positive results. Given the future shift towards personalized medicine, Geodesic-BP has the potential to help in future functionalizations of cardiac models meeting clinical time constraints while maintaining the physiological accuracy of state-of-the-art cardiac models.
</details>
<details>
<summary>摘要</summary>
《射线方程》已成为心脏电动力学模型精准计算的不可或缺工具。在原理上，通过对临床记录的电子干扰gram（ECG）和射线方程进行匹配，可以建立个性化的心脏电physiology模型，无需侵入性的干扰。然而，匹配过程仍然是一项具有挑战性的任务。本研究提出了一种新的方法，即Geodesic-BP，以解决反射射线问题。Geodesic-BP适用于加速机器学习框架的GPU，可以优化射线方程中的参数，以实现与给定ECG的匹配。我们在一个人工测试案例中展示了Geodesic-BP可以高精度地重建模拟的心脏活动，包括模型精度不足时的情况。此外，我们将我们的算法应用于一个公共可用的兔子模型数据集，得到了非常正面的结果。鉴于未来的个性化医疗的发展，Geodesic-BP有望帮助未来的心脏模型功能化，满足临床时间限制，同时维持现有的心脏模型的生物学精度。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-clinical-risk-prediction-a-survey-of-concepts-methods-and-modalities"><a href="#Explainable-AI-for-clinical-risk-prediction-a-survey-of-concepts-methods-and-modalities" class="headerlink" title="Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities"></a>Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08407">http://arxiv.org/abs/2308.08407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Munib Mesinovic, Peter Watkinson, Tingting Zhu</li>
<li>for: 这篇论文的目的是探讨 ai 应用于医疗领域中的解释性能力，以确保 ai 系统的可靠性和可信worthiness。</li>
<li>methods: 这篇论文使用了多种解释性模型，包括 LIME、 SHAP 和 TreeExplainer，以及其他一些新的解释性方法。</li>
<li>results: 这篇论文的结果表明，使用解释性模型可以提高 ai 系统的可靠性和可信worthiness，同时也可以增加模型的透明度和可读性。<details>
<summary>Abstract</summary>
Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis. With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability. To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial. Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders. In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability. In this review, we address the relationship between these concepts as they are often used together or interchangeably. This review also discusses recent progress in developing explainable models for clinical risk prediction, highlighting the importance of quantitative and clinical evaluation and validation across multiple common modalities in clinical practice. It emphasizes the need for external validation and the combination of diverse interpretability methods to enhance trust and fairness. Adopting rigorous testing, such as using synthetic datasets with known generative factors, can further improve the reliability of explainability methods. Open access and code-sharing resources are essential for transparency and reproducibility, enabling the growth and trustworthiness of explainable research. While challenges exist, an end-to-end approach to explainability in clinical risk prediction, incorporating stakeholders from clinicians to developers, is essential for success.
</details>
<details>
<summary>摘要</summary>
最近的人工智能应用于医疗领域的进步已经显示出了人性化的 диагности和疾病预测的能力。然而，随着人工智能模型的复杂度的增加，关于它们的不透明度、潜在偏见和解释性的问题也引起了关注。以确保人工智能系统的可信worth和可靠性，特别是在临床风险预测模型中，解释性变得非常重要。解释性通常指的是人工智能系统能够提供人类权益者可靠的决策逻辑或决策结果的解释。在临床风险预测中，其他方面的解释性如公平、偏见、信任和透明度也是重要的概念，这些概念frequently被用于一起或相互替换使用。本文评论了这些概念之间的关系，并讨论了最近在临床风险预测中发展的解释模型，强调了在多种常见模式下的量化和临床评估和验证的重要性。它也强调了外部验证和多种解释方法的结合，以提高可信worth和公平性。采用严格的测试，如使用已知生成因素的 sintetic数据集，可以进一步提高解释性方法的可靠性。开放访问和代码分享资源是必要的，以确保透明度和可重现性。而且，在实施解释性时，需要结合临床医生到开发者的多种潜在偏见，以确保成功。
</details></li>
</ul>
<hr>
<h2 id="Content-based-Recommendation-Engine-for-Video-Streaming-Platform"><a href="#Content-based-Recommendation-Engine-for-Video-Streaming-Platform" class="headerlink" title="Content-based Recommendation Engine for Video Streaming Platform"></a>Content-based Recommendation Engine for Video Streaming Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08406">http://arxiv.org/abs/2308.08406</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Puskal Khadka, Prabhav Lamichhane</li>
<li>for: 这个论文是为了提供一种基于内容的推荐引擎，用于为用户提供视频建议，以满足他们的先前兴趣和选择。</li>
<li>methods: 该论文使用了TF-IDF文本分Vector化方法来确定文档中的相关性，然后计算每个内容之间的cosine相似性来确定它们之间的相似性。</li>
<li>results: 该论文得到了一个基于TF-IDF和cosine相似性的推荐引擎，可以帮助用户找到符合他们兴趣的视频内容。同时，论文还测试了该引擎的性能，并计算了精度、报告率和F1核心等指标，以评估其性能。<details>
<summary>Abstract</summary>
Recommendation engine suggest content, product or services to the user by using machine learning algorithm. This paper proposed a content-based recommendation engine for providing video suggestion to the user based on their previous interests and choices. We will use TF-IDF text vectorization method to determine the relevance of words in a document. Then we will find out the similarity between each content by calculating cosine similarity between them. Finally, engine will recommend videos to the users based on the obtained similarity score value. In addition, we will measure the engine's performance by computing precision, recall, and F1 core of the proposed system.
</details>
<details>
<summary>摘要</summary>
<<SYS>>机器学习算法可以为用户提供内容、产品或服务的建议。这篇论文提出了基于用户之前的兴趣和选择的内容基于推荐引擎，用于为用户提供视频建议。我们将使用TF-IDF文本矢量化方法来确定文档中的相关性。然后，我们将计算每个内容之间的相似性，并根据所得到的相似性分值来推荐视频给用户。此外，我们还将测量引擎的性能，计算推荐系统的准确率、恰当率和F1分值。Note: "TF-IDF" stands for "Term Frequency-Inverse Document Frequency", which is a text vectorization method used to determine the relevance of words in a document.
</details></li>
</ul>
<hr>
<h2 id="Fast-Uncertainty-Quantification-of-Spent-Nuclear-Fuel-with-Neural-Networks"><a href="#Fast-Uncertainty-Quantification-of-Spent-Nuclear-Fuel-with-Neural-Networks" class="headerlink" title="Fast Uncertainty Quantification of Spent Nuclear Fuel with Neural Networks"></a>Fast Uncertainty Quantification of Spent Nuclear Fuel with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08391">http://arxiv.org/abs/2308.08391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arnau Albà, Andreas Adelmann, Lucas Münster, Dimitri Rochman, Romana Boiger<br>for: 这个论文的目的是为了简化核电厂燃料的特性calculation和不确定性评估，以提高核能生产、废料处理和核安全预防的安全、效率和可持续性。methods: 本论文使用神经网络（NN）来建立一个快速的模拟模型，以便预测核电厂燃料的一些特性，例如衰变热和核lide的含量，并且可以对这些特性进行不确定性评估。results: 本论文的结果显示，使用NN模型可以实现这些特性的精确预测，并且可以对这些特性进行不确定性评估，并且可以大大降低physics-based模型的计算成本。<details>
<summary>Abstract</summary>
The accurate calculation and uncertainty quantification of the characteristics of spent nuclear fuel (SNF) play a crucial role in ensuring the safety, efficiency, and sustainability of nuclear energy production, waste management, and nuclear safeguards. State of the art physics-based models, while reliable, are computationally intensive and time-consuming. This paper presents a surrogate modeling approach using neural networks (NN) to predict a number of SNF characteristics with reduced computational costs compared to physics-based models. An NN is trained using data generated from CASMO5 lattice calculations. The trained NN accurately predicts decay heat and nuclide concentrations of SNF, as a function of key input parameters, such as enrichment, burnup, cooling time between cycles, mean boron concentration and fuel temperature. The model is validated against physics-based decay heat simulations and measurements of different uranium oxide fuel assemblies from two different pressurized water reactors. In addition, the NN is used to perform sensitivity analysis and uncertainty quantification. The results are in very good alignment to CASMO5, while the computational costs (taking into account the costs of generating training samples) are reduced by a factor of 10 or more. Our findings demonstrate the feasibility of using NNs as surrogate models for fast characterization of SNF, providing a promising avenue for improving computational efficiency in assessing nuclear fuel behavior and associated risks.
</details>
<details>
<summary>摘要</summary>
使用神经网络（NN）模型来快速计算核电燃料（SNF）的特性，可以提高核能生产、废料处理和核保障的安全、效率和可持续性。当前的物理基于模型，尽管可靠，但计算成本高。这篇文章介绍了使用NN模型来预测SNF特性，包括衰变热和核lide的分布，作为输入参数的核燃料燃烧度、燃烧时间、冷却时间、燃料浓度和燃料温度等。NN模型通过对CASMO5网络计算数据进行训练。模型可以准确地预测核燃料的衰变热和核lide的分布，并且可以对不同的氧化铀燃料聚合体进行预测。此外，NN模型还可以进行敏感分析和不确定性评估。结果与CASMO5模型相符，而计算成本（包括生成训练样本的成本）则被减少了一倍或更多。我们的发现表明使用NN模型可以快速地计算SNF特性，提供了一个有前途的方法来提高核燃料行为和相关风险的计算效率。
</details></li>
</ul>
<hr>
<h2 id="Continuous-Sweep-an-improved-binary-quantifier"><a href="#Continuous-Sweep-an-improved-binary-quantifier" class="headerlink" title="Continuous Sweep: an improved, binary quantifier"></a>Continuous Sweep: an improved, binary quantifier</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08387">http://arxiv.org/abs/2308.08387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kevin Kloos, Julian D. Karch, Quinten A. Meertens, Mark de Rooij</li>
<li>for: 这篇论文主要关注的是量化学习任务中的binary quantifier，即估计资料集中类别的分布。</li>
<li>methods: 作者们提出了一个新的 parametric binary quantifier，叫做Continuous Sweep，这个方法受到Median Sweep的影响，但是有三个主要的改进：1) 使用Parametric class distributions instead of empirical distributions，2) 优化决策boundaries instead of 应用类别规则，3) 计算mean instead of median。</li>
<li>results: 作者们通过分析表现，证明了Continuous Sweep在广泛的情况下比Median Sweep表现更好，并且提供了一些 theoretically optimal decision boundaries。<details>
<summary>Abstract</summary>
Quantification is a supervised machine learning task, focused on estimating the class prevalence of a dataset rather than labeling its individual observations. We introduce Continuous Sweep, a new parametric binary quantifier inspired by the well-performing Median Sweep. Median Sweep is currently one of the best binary quantifiers, but we have changed this quantifier on three points, namely 1) using parametric class distributions instead of empirical distributions, 2) optimizing decision boundaries instead of applying discrete decision rules, and 3) calculating the mean instead of the median. We derive analytic expressions for the bias and variance of Continuous Sweep under general model assumptions. This is one of the first theoretical contributions in the field of quantification learning. Moreover, these derivations enable us to find the optimal decision boundaries. Finally, our simulation study shows that Continuous Sweep outperforms Median Sweep in a wide range of situations.
</details>
<details>
<summary>摘要</summary>
<<SYS>>quantification是一种指导学习任务，关注数据集中类别的出现频率而不是具体的观察值。我们介绍了连续探索，一种基于 median sweep 的新参数化二分量器。Median sweep 目前是二分量器中的一个非常好的选择，但我们在其上改变了三点：1）使用参数化类别分布而不是实际分布，2）优化决策界而不是应用简单的决策规则，3）计算平均值而不是中值。我们 derive 了一系列的analytic表达式，用于描述 Continuous Sweep 的偏差和方差。这是量化学习领域的一个非常rare的理论贡献。此外，这些 derivations 允许我们找到最佳决策界。最后，我们的 simulations 研究表明，Continuous Sweep 在各种情况下都能够超越 Median Sweep。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Precision-and-Recall-Reject-Curves-for-Classification"><a href="#Precision-and-Recall-Reject-Curves-for-Classification" class="headerlink" title="Precision and Recall Reject Curves for Classification"></a>Precision and Recall Reject Curves for Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08381">http://arxiv.org/abs/2308.08381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lydia Fischer, Patricia Wollstadt</li>
<li>for: 这个论文主要是为了提出一种新的评估分类器性能的方法，以及一种基于这种方法的分类器。</li>
<li>methods: 这个论文使用了一种基于学习 вектор量化的prototype-based分类器，并使用了一些不同的certainty measure来评估分类器的性能。</li>
<li>results: 论文通过对人工测试数据和实际医疗数据进行测试，发现在面临着类别不对称的情况下，使用precision和recall reject curve可以更好地评估分类器的性能，而不是使用准确率 reject curve。<details>
<summary>Abstract</summary>
For some classification scenarios, it is desirable to use only those classification instances that a trained model associates with a high certainty. To obtain such high-certainty instances, previous work has proposed accuracy-reject curves. Reject curves allow to evaluate and compare the performance of different certainty measures over a range of thresholds for accepting or rejecting classifications. However, the accuracy may not be the most suited evaluation metric for all applications, and instead precision or recall may be preferable. This is the case, for example, for data with imbalanced class distributions. We therefore propose reject curves that evaluate precision and recall, the recall-reject curve and the precision-reject curve. Using prototype-based classifiers from learning vector quantization, we first validate the proposed curves on artificial benchmark data against the accuracy reject curve as a baseline. We then show on imbalanced benchmarks and medical, real-world data that for these scenarios, the proposed precision- and recall-curves yield more accurate insights into classifier performance than accuracy reject curves.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将给定文本翻译成简化中文。</SYS>>对于一些分类场景，您可以使用已经训练的模型中的高确定度分类实例。以前的工作已经提出了准确度拒绝曲线，这些曲线可以评估和比较不同的确定度测试的性能。但是，准确度可能不是所有应用场景中最适合的评价指标，特别是数据具有不均衡的类别分布。我们因此提议使用 recall-reject 曲线和 precision-reject 曲线来评估分类器性能。使用学习 вектор量化的prototype-based分类器，我们首先在人工测试数据上验证我们提议的曲线，并作为基准点使用准确度拒绝曲线。然后，我们在具有不均衡的测试数据和医疗实际数据上展示了，在这些场景下，我们的precision-和 recall-曲线可以更加准确地评估分类器性能，比较准确度拒绝曲线。
</details></li>
</ul>
<hr>
<h2 id="A-distributed-neural-network-architecture-for-dynamic-sensor-selection-with-application-to-bandwidth-constrained-body-sensor-networks"><a href="#A-distributed-neural-network-architecture-for-dynamic-sensor-selection-with-application-to-bandwidth-constrained-body-sensor-networks" class="headerlink" title="A distributed neural network architecture for dynamic sensor selection with application to bandwidth-constrained body-sensor networks"></a>A distributed neural network architecture for dynamic sensor selection with application to bandwidth-constrained body-sensor networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08379">http://arxiv.org/abs/2308.08379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Strypsteen, Alexander Bertrand</li>
<li>for: 这个研究旨在提出一个动态侦测器选择方法，用于深度神经网络（DNNs），以便从每个具体的输入样本中选择最佳侦测器子集，而不是整个数据集中的固定选择。</li>
<li>methods: 这个动态选择是与任务模型一起学习的，使用Gumbel-Softmax的技巧，以让决策获得数据验证。</li>
<li>results: 我们显示了如何使用这个动态选择来增加无线传感网络（WSN）的寿命，并且透过对每个节点的传输次数实施限制。我们还提高了性能的方法，包括一个动态空间范本，让任务-DNN更加对多个可能的节点子集具有抗衰变的能力。最后，我们说明了如何选择最佳通道。我们验证了这个方法，使用实际的电普瑞度测量数据，模拟一个EEG感应网络。我们分析了对输送负载和任务精度的交换。<details>
<summary>Abstract</summary>
We propose a dynamic sensor selection approach for deep neural networks (DNNs), which is able to derive an optimal sensor subset selection for each specific input sample instead of a fixed selection for the entire dataset. This dynamic selection is jointly learned with the task model in an end-to-end way, using the Gumbel-Softmax trick to allow the discrete decisions to be learned through standard backpropagation. We then show how we can use this dynamic selection to increase the lifetime of a wireless sensor network (WSN) by imposing constraints on how often each node is allowed to transmit. We further improve performance by including a dynamic spatial filter that makes the task-DNN more robust against the fact that it now needs to be able to handle a multitude of possible node subsets. Finally, we explain how the selection of the optimal channels can be distributed across the different nodes in a WSN. We validate this method on a use case in the context of body-sensor networks, where we use real electroencephalography (EEG) sensor data to emulate an EEG sensor network. We analyze the resulting trade-offs between transmission load and task accuracy.
</details>
<details>
<summary>摘要</summary>
我们提出了一种动态感测器选择方法，用于深度神经网络（DNN），可以为每个特定输入样本选择最佳感测器子集而不是整个数据集的固定选择。这种动态选择与任务模型一起学习，使用Gumbel-Softmax技巧，以便通过标准反馈来学习不同的决策。我们然后解释了如何使用这种动态选择来增加无线传感器网络（WSN）的寿命，并在不同的节点上强制执行特定的传输限制。此外，我们还提高了任务-DNN的可靠性，使其能够处理多个可能的节点子集。最后，我们解释了如何在WSN中选择优化的通道。我们验证了这种方法在身体感测网络上的使用情况，使用实际的电encephalography（EEG）感测器数据来模拟EEG感测器网络。我们分析了因 переда信荷和任务准确率之间的负面效应。
</details></li>
</ul>
<hr>
<h2 id="PDPK-A-Framework-to-Synthesise-Process-Data-and-Corresponding-Procedural-Knowledge-for-Manufacturing"><a href="#PDPK-A-Framework-to-Synthesise-Process-Data-and-Corresponding-Procedural-Knowledge-for-Manufacturing" class="headerlink" title="PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing"></a>PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08371">http://arxiv.org/abs/2308.08371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/0x14d/embedding-operator-knowledge">https://github.com/0x14d/embedding-operator-knowledge</a></li>
<li>paper_authors: Richard Nordsieck, André Schweizer, Michael Heider, Jörg Hähner</li>
<li>For: The paper aims to provide a framework for generating synthetic datasets that can be used to represent procedural knowledge in different domains.* Methods: The framework uses a combination of knowledge graphs and parametric processes to simulate real-world data and generate synthetic datasets. The authors evaluate the effectiveness of several existing embedding methods on the synthetic datasets.* Results: The authors compare the results of the embedding methods on the synthetic datasets with those achievable on a real-world dataset, and find that the synthetic datasets can accurately represent the procedural knowledge in the real-world data. They also provide a baseline for future work by demonstrating the potential of the synthetic datasets to represent procedural knowledge.Here’s the information in Simplified Chinese text:* For: 本文提供了一个框架，用于生成不同领域的 sintetic 数据集，以表现程序知识。* Methods: 框架使用知识 graphs 和参数化过程来实现实际数据的生成，并评估了多个现有的嵌入方法在 sintetic 数据集上的效果。* Results: 作者比较了嵌入方法在 sintetic 数据集和实际数据集上的结果，发现 sintetic 数据集能够准确表现实际数据中的程序知识。他们还提供了未来工作的基eline，显示 sintetic 数据集的可能性。<details>
<summary>Abstract</summary>
Procedural knowledge describes how to accomplish tasks and mitigate problems. Such knowledge is commonly held by domain experts, e.g. operators in manufacturing who adjust parameters to achieve quality targets. To the best of our knowledge, no real-world datasets containing process data and corresponding procedural knowledge are publicly available, possibly due to corporate apprehensions regarding the loss of knowledge advances. Therefore, we provide a framework to generate synthetic datasets that can be adapted to different domains. The design choices are inspired by two real-world datasets of procedural knowledge we have access to. Apart from containing representations of procedural knowledge in Resource Description Framework (RDF)-compliant knowledge graphs, the framework simulates parametrisation processes and provides consistent process data. We compare established embedding methods on the resulting knowledge graphs, detailing which out-of-the-box methods have the potential to represent procedural knowledge. This provides a baseline which can be used to increase the comparability of future work. Furthermore, we validate the overall characteristics of a synthesised dataset by comparing the results to those achievable on a real-world dataset. The framework and evaluation code, as well as the dataset used in the evaluation, are available open source.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>专业知识描述如何完成任务和解决问题。这种知识通常由领域专家所拥有，例如制造业中的操作员，他们根据参数进行调整以达到质量目标。根据我们所知，现实世界中没有公开可用的实际数据和相应的专业知识集。因此，我们提供了一个框架，可以生成可靠的合成数据集，可以适应不同领域。该框架的设计启发自我们有access的两个实际数据集，它们包含了专业知识的RDF相容知识图表示，同时还模拟了参数化过程，提供了一致的过程数据。我们使用现有的嵌入方法对于生成的知识图进行评估，详细介绍了这些方法在表示专业知识方面的潜力。此外，我们还验证了合成数据集的总特征，并与真实世界数据集进行比较，以验证合成数据集的可靠性。框架和评估代码以及使用于评估的数据集都是开源的。
</details></li>
</ul>
<hr>
<h2 id="Dual-Branch-Temperature-Scaling-Calibration-for-Long-Tailed-Recognition"><a href="#Dual-Branch-Temperature-Scaling-Calibration-for-Long-Tailed-Recognition" class="headerlink" title="Dual-Branch Temperature Scaling Calibration for Long-Tailed Recognition"></a>Dual-Branch Temperature Scaling Calibration for Long-Tailed Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08366">http://arxiv.org/abs/2308.08366</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialin Guo, Zhenyu Wu, Zhiqiang Zhan, Yang Ji</li>
<li>for: 本研究旨在解决深度神经网络中的误差补做问题，尤其是在长板分布的数据下存在较大的误差问题。</li>
<li>methods: 本研究使用了温度扩展（TS）方法，并设计了多支分支温度扩展模型（Dual-TS），以考虑不同类别的温度参数的多样性和罕见样本的非一致性。</li>
<li>results: 经过实验，本研究表明，我们的模型在传统ECE和Esbin-ECE评价指标下均达到了顶尖性能。<details>
<summary>Abstract</summary>
The calibration for deep neural networks is currently receiving widespread attention and research. Miscalibration usually leads to overconfidence of the model. While, under the condition of long-tailed distribution of data, the problem of miscalibration is more prominent due to the different confidence levels of samples in minority and majority categories, and it will result in more serious overconfidence. To address this problem, some current research have designed diverse temperature coefficients for different categories based on temperature scaling (TS) method. However, in the case of rare samples in minority classes, the temperature coefficient is not generalizable, and there is a large difference between the temperature coefficients of the training set and the validation set. To solve this challenge, this paper proposes a dual-branch temperature scaling calibration model (Dual-TS), which considers the diversities in temperature parameters of different categories and the non-generalizability of temperature parameters for rare samples in minority classes simultaneously. Moreover, we noticed that the traditional calibration evaluation metric, Excepted Calibration Error (ECE), gives a higher weight to low-confidence samples in the minority classes, which leads to inaccurate evaluation of model calibration. Therefore, we also propose Equal Sample Bin Excepted Calibration Error (Esbin-ECE) as a new calibration evaluation metric. Through experiments, we demonstrate that our model yields state-of-the-art in both traditional ECE and Esbin-ECE metrics.
</details>
<details>
<summary>摘要</summary>
Currently, the calibration of deep neural networks is receiving extensive attention and research. If the model is miscalibrated, it can lead to overconfidence. In particular, when dealing with long-tailed distribution of data, the problem of miscalibration is more pronounced due to the differences in confidence levels of samples in minority and majority categories, which can result in more serious overconfidence. To address this issue, some current research has proposed using diverse temperature coefficients for different categories based on the temperature scaling (TS) method. However, for rare samples in minority classes, the temperature coefficient is not generalizable, and there is a large difference between the temperature coefficients of the training set and the validation set.To solve this challenge, this paper proposes a dual-branch temperature scaling calibration model (Dual-TS), which takes into account the diversity of temperature parameters for different categories and the non-generalizability of temperature parameters for rare samples in minority classes simultaneously. Furthermore, we noticed that the traditional calibration evaluation metric, Expected Calibration Error (ECE), gives a higher weight to low-confidence samples in minority classes, which leads to inaccurate evaluation of model calibration. Therefore, we also propose Equal Sample Bin Expected Calibration Error (Esbin-ECE) as a new calibration evaluation metric. Through experiments, we demonstrate that our model achieves state-of-the-art performance in both traditional ECE and Esbin-ECE metrics.
</details></li>
</ul>
<hr>
<h2 id="KernelWarehouse-Towards-Parameter-Efficient-Dynamic-Convolution"><a href="#KernelWarehouse-Towards-Parameter-Efficient-Dynamic-Convolution" class="headerlink" title="KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution"></a>KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08361">http://arxiv.org/abs/2308.08361</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osvai/kernelwarehouse">https://github.com/osvai/kernelwarehouse</a></li>
<li>paper_authors: Chao Li, Anbang Yao</li>
<li>for: 这 paper 是为了提出一种更高效的动态核函数，以提高图像识别模型的表现。</li>
<li>methods: 这 paper 使用了一种新的核函数设计方法，即 KernelWarehouse，它可以减少核函数的维度和增加核函数的数量，从而提高图像识别模型的表现。</li>
<li>results: 这 paper 的实验结果表明，使用 KernelWarehouse 可以达到图像识别领域的州际最佳性，并且可以降低模型的参数数量，从而提高模型的可扩展性和灵活性。<details>
<summary>Abstract</summary>
Dynamic convolution learns a linear mixture of $n$ static kernels weighted with their sample-dependent attentions, demonstrating superior performance compared to normal convolution. However, existing designs are parameter-inefficient: they increase the number of convolutional parameters by $n$ times. This and the optimization difficulty lead to no research progress in dynamic convolution that can allow us to use a significant large value of $n$ (e.g., $n>100$ instead of typical setting $n<10$) to push forward the performance boundary. In this paper, we propose $KernelWarehouse$, a more general form of dynamic convolution, which can strike a favorable trade-off between parameter efficiency and representation power. Its key idea is to redefine the basic concepts of "$kernels$" and "$assembling$ $kernels$" in dynamic convolution from the perspective of reducing kernel dimension and increasing kernel number significantly. In principle, KernelWarehouse enhances convolutional parameter dependencies within the same layer and across successive layers via tactful kernel partition and warehouse sharing, yielding a high degree of freedom to fit a desired parameter budget. We validate our method on ImageNet and MS-COCO datasets with different ConvNet architectures, and show that it attains state-of-the-art results. For instance, the ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny model trained with KernelWarehouse on ImageNet reaches 76.05%|81.05%|75.52%|82.51% top-1 accuracy. Thanks to its flexible design, KernelWarehouse can even reduce the model size of a ConvNet while improving the accuracy, e.g., our ResNet18 model with 36.45%|65.10% parameter reduction to the baseline shows 2.89%|2.29% absolute improvement to top-1 accuracy.
</details>
<details>
<summary>摘要</summary>
“动态核函数学习一种线性权重混合的$n$ static核函数，达到比正常核函数更高的性能，但现有设计存在参数不效率问题：它将参数数量增加$n$倍。这导致了对动态核函数的研究停滞不前进，无法使用较大的$n$值（例如$n>100$）来推动性能边界。本文提出了«KernelWarehouse”，一种更通用的动态核函数设计，可以实现参数效率和表示能力之间的平衡。它的关键思想是在动态核函数中重新定义«核函数”和«核函数组合»的概念，从减少核函数维度和增加核函数数量的角度来看。在实践中，KernelWarehouse通过精巧的核函数分割和库共享，提高了层内参数之间的依赖关系和层次关系，从而实现了高度的自由度来适应感兴趣的参数预算。我们在ImageNet和MS-COCO datasets上验证了KernelWarehouse，并证明其可以达到状态略的最佳结果。例如，在ImageNet上，使用KernelWarehouse训练ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny模型，可以达到76.05%|81.05%|75.52%|82.51%的顶部一个精度。此外，由于KernelWarehouse的灵活设计，可以在ConvNet模型中减少参数大小，同时提高准确率，例如我们的ResNet18模型在参数减少36.45%|65.10%后，可以提高2.89%|2.29%的精度。”
</details></li>
</ul>
<hr>
<h2 id="Independent-Distribution-Regularization-for-Private-Graph-Embedding"><a href="#Independent-Distribution-Regularization-for-Private-Graph-Embedding" class="headerlink" title="Independent Distribution Regularization for Private Graph Embedding"></a>Independent Distribution Regularization for Private Graph Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08360">http://arxiv.org/abs/2308.08360</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkust-knowcomp/privategraphencoder">https://github.com/hkust-knowcomp/privategraphencoder</a></li>
<li>paper_authors: Qi Hu, Yangqiu Song</li>
<li>for: 本研究旨在提出一种名为Private Variational Graph AutoEncoders（PVGAE）的新方法，以保护个人隐私信息的同时实现图像学任务的优秀表现。</li>
<li>methods: PVGAE使用了独立分布罚项作为正则项，并将原始的变量图自动编码器（VGAE）分解成学习敏感和非敏感特征的两个集。</li>
<li>results: 对三个实际数据集进行实验，PVGAE在保护个人隐私信息的同时实现了优秀的表现，舒服于其他基eline。<details>
<summary>Abstract</summary>
Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues. In this paper, we propose a novel approach called Private Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.
</details>
<details>
<summary>摘要</summary>
学习图embedding是 graf矿 tasks 中的一项重要任务。一个有效的图embedding模型可以从图结构数据中学习低维度表示，为数据发布带来多种下游应用程序的利益，如节点分类、链接预测等。然而， latest studies have shown that graph embeddings are vulnerable to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues.In this paper, we propose a novel approach called Private Variational Graph Autoencoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.
</details></li>
</ul>
<hr>
<h2 id="Convergence-of-Two-Layer-Regression-with-Nonlinear-Units"><a href="#Convergence-of-Two-Layer-Regression-with-Nonlinear-Units" class="headerlink" title="Convergence of Two-Layer Regression with Nonlinear Units"></a>Convergence of Two-Layer Regression with Nonlinear Units</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08358">http://arxiv.org/abs/2308.08358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichuan Deng, Zhao Song, Shenghao Xie</li>
<li>for: 本研究旨在提出一种快速收敛的精度恰当的软MAX-ReLU回归问题解决方案，以便更好地训练大型自然语言模型（LLMs）。</li>
<li>methods: 本文提出了一种基于approx Newton方法的软MAX-ReLU回归算法，该算法在certain assumptions下可以 guarantees the convergence of the solution in the sense of the distance to the optimal solution。</li>
<li>results: 本研究通过计算closed form表示形式的梯度Matrix，并在certain assumptions下证明梯度的 lipschitz continuity和半正定性，从而实现了软MAX-ReLU回归问题的解决。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as ChatGPT and GPT4, have shown outstanding performance in many human life task. Attention computation plays an important role in training LLMs. Softmax unit and ReLU unit are the key structure in attention computation. Inspired by them, we put forward a softmax ReLU regression problem. Generally speaking, our goal is to find an optimal solution to the regression problem involving the ReLU unit. In this work, we calculate a close form representation for the Hessian of the loss function. Under certain assumptions, we prove the Lipschitz continuous and the PSDness of the Hessian. Then, we introduce an greedy algorithm based on approximate Newton method, which converges in the sense of the distance to optimal solution. Last, We relax the Lipschitz condition and prove the convergence in the sense of loss value.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如ChatGPT和GPT4，在许多人类任务中表现出色。计算注意力对于训练LLM非常重要。软饱和ReLU单元是计算注意力的关键结构。受其启发，我们提出了软饱ReLU回归问题。总的来说，我们的目标是找到一个优化的回归解决方案，其中包括ReLU单元。在这种情况下，我们计算了一个快速的表示形式，用于捕捉损失函数的迷你。在某些假设下，我们证明了梯度的 lipschitz 连续和归一化性。然后，我们介绍了一种基于approximate Newton方法的满足搜索算法，该算法在某种意义上 converge。最后，我们松解了 lipschitz 条件，并证明了在损失值上的convergence。
</details></li>
</ul>
<hr>
<h2 id="Is-Meta-Learning-the-Right-Approach-for-the-Cold-Start-Problem-in-Recommender-Systems"><a href="#Is-Meta-Learning-the-Right-Approach-for-the-Cold-Start-Problem-in-Recommender-Systems" class="headerlink" title="Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?"></a>Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08354">http://arxiv.org/abs/2308.08354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Buffelli, Ashish Gupta, Agnieszka Strzalka, Vassilis Plachouras</li>
<li>for:  solve the cold-start problem in deep learning models for recommender systems</li>
<li>methods:  standard and widely adopted deep learning models, common representation learning techniques</li>
<li>results:  comparable performance to meta-learning techniques specifically designed for the cold-start setting, with much easier deployment in real-world applications<details>
<summary>Abstract</summary>
Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience. In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems. Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved. Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems. However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements. In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchmarks for the cold-start problem without using meta-learning techniques. In more detail, we show that, when tuned correctly, standard and widely adopted deep learning models perform just as well as newer meta-learning models. We further show that an extremely simple modular approach using common representation learning techniques, can perform comparably to meta-learning techniques specifically designed for the cold-start setting while being much more easily deployable in real-world applications.
</details>
<details>
<summary>摘要</summary>
现代在线产品和服务中，推荐系统已成为基本结构的重要组件，对用户体验产生了深远的影响。过去几年，深度学习方法在研究中吸引了很多注意力，现在在现实世界中广泛应用于现代推荐系统中。然而，在冷开始设定下（例如，用户在系统中有限的交互），仍然是一个未解决的问题。学术研究文献中最受欢迎的方法是使用meta-学习技术来解决这个问题。然而，现有的meta-学习方法在实际应用中并不实用，因为它们需要训练大量数据和计算资源，并且具有严格的延迟要求。在这篇论文中，我们展示了可以在通用的深度学习模型中获得类似或更高的性能，而不需要使用meta-学习技术。具体来说，当正确地调整时，标准的深度学习模型可以与 newer meta-学习模型性能相似。此外，我们还展示了一种非常简单的模块化方法，使用常见的表示学习技术，可以在现实世界应用中与meta-学习技术特化于冷开始设定相比而表现类似，同时更易于部署。</sys>Here's the translation in Simplified Chinese:现代在线产品和服务中，推荐系统已成为基本结构的重要组件，对用户体验产生了深远的影响。过去几年，深度学习方法在研究中吸引了很多注意力，现在在现实世界中广泛应用于现代推荐系统中。然而，在冷开始设定下（例如，用户在系统中有限的交互），仍然是一个未解决的问题。学术研究文献中最受欢迎的方法是使用meta-学习技术来解决这个问题。然而，现有的meta-学习方法在实际应用中并不实用，因为它们需要训练大量数据和计算资源，并且具有严格的延迟要求。在这篇论文中，我们展示了可以在通用的深度学习模型中获得类似或更高的性能，而不需要使用meta-学习技术。具体来说，当正确地调整时，标准的深度学习模型可以与 newer meta-学习模型性能相似。此外，我们还展示了一种非常简单的模块化方法，使用常见的表示学习技术，可以在现实世界应用中与meta-学习技术特化于冷开始设定相比而表现类似，同时更易于部署。
</details></li>
</ul>
<hr>
<h2 id="Graph-Out-of-Distribution-Generalization-with-Controllable-Data-Augmentation"><a href="#Graph-Out-of-Distribution-Generalization-with-Controllable-Data-Augmentation" class="headerlink" title="Graph Out-of-Distribution Generalization with Controllable Data Augmentation"></a>Graph Out-of-Distribution Generalization with Controllable Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08344">http://arxiv.org/abs/2308.08344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lu, Xiaoying Gan, Ze Zhao, Shiyu Liang, Luoyi Fu, Xinbing Wang, Chenghu Zhou</li>
<li>for: 这篇论文旨在解决图像分类中的选择偏见问题，尤其是在训练和测试数据之间的分布偏移。</li>
<li>methods: 本文提出了一个名为\texttt{OOD-GMixup}的方法，它通过控制训练分布，以解决图像分类中的分布偏移问题。</li>
<li>results: extensive studies on several real-world datasets demonstrate the superiority of 本文提出的方法，比过现有的基eline方法更好。<details>
<summary>Abstract</summary>
Graph Neural Network (GNN) has demonstrated extraordinary performance in classifying graph properties. However, due to the selection bias of training and testing data (e.g., training on small graphs and testing on large graphs, or training on dense graphs and testing on sparse graphs), distribution deviation is widespread. More importantly, we often observe \emph{hybrid structure distribution shift} of both scale and density, despite of one-sided biased data partition. The spurious correlations over hybrid distribution deviation degrade the performance of previous GNN methods and show large instability among different datasets. To alleviate this problem, we propose \texttt{OOD-GMixup} to jointly manipulate the training distribution with \emph{controllable data augmentation} in metric space. Specifically, we first extract the graph rationales to eliminate the spurious correlations due to irrelevant information. Secondly, we generate virtual samples with perturbation on graph rationale representation domain to obtain potential OOD training samples. Finally, we propose OOD calibration to measure the distribution deviation of virtual samples by leveraging Extreme Value Theory, and further actively control the training distribution by emphasizing the impact of virtual OOD samples. Extensive studies on several real-world datasets on graph classification demonstrate the superiority of our proposed method over state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 在分类图属性方面表现出了惊人的表现。然而，由于训练和测试数据的选择偏袋（例如，训练小图并测试大图，或训练紧凑图并测试稀疏图），分布偏移广泛存在。更重要的是，我们经常观察到图结构分布偏移的“半混合结构”，即同时存在一个稀疏图和一个紧凑图的偏移。这些偏移会导致前一代GNN方法的性能下降，并且在不同的数据集上显示出大的不稳定性。为了解决这个问题，我们提出了\texttt{OOD-GMixup}，一种通过控制数据增强的方法，用于同时控制训练分布和数据 augmentation。具体来说，我们首先提取图理据，以消除由不相关信息引起的假正相关性。然后，我们使用图理据表示域中的扰动生成虚拟样本。最后，我们提出了OOD核验，通过极值理论来测量虚拟样本的分布偏移，并且通过控制训练分布来活动地控制训练过程。我们在一些真实世界的图分类任务上进行了广泛的实验，并证明了我们提出的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Logic-Programs-by-Discovering-Higher-Order-Abstractions"><a href="#Learning-Logic-Programs-by-Discovering-Higher-Order-Abstractions" class="headerlink" title="Learning Logic Programs by Discovering Higher-Order Abstractions"></a>Learning Logic Programs by Discovering Higher-Order Abstractions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08334">http://arxiv.org/abs/2308.08334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Céline Hocquette, Sebastijan Dumančić, Andrew Cropper</li>
<li>for: 本研究旨在找到人类水平的AI需要的新抽象，即高阶抽象。</li>
<li>methods: 本研究使用了逻辑编程，从示例和背景知识中生成逻辑程序。</li>
<li>results: 我们的实验结果表明，与不 refactoring 相比，STEVIE 可以提高预测精度27%，降低学习时间47%。此外，STEVIE 还可以找到可以跨领域传递的抽象。<details>
<summary>Abstract</summary>
Discovering novel abstractions is important for human-level AI. We introduce an approach to discover higher-order abstractions, such as map, filter, and fold. We focus on inductive logic programming, which induces logic programs from examples and background knowledge. We introduce the higher-order refactoring problem, where the goal is to compress a logic program by introducing higher-order abstractions. We implement our approach in STEVIE, which formulates the higher-order refactoring problem as a constraint optimisation problem. Our experimental results on multiple domains, including program synthesis and visual reasoning, show that, compared to no refactoring, STEVIE can improve predictive accuracies by 27% and reduce learning times by 47%. We also show that STEVIE can discover abstractions that transfer to different domains
</details>
<details>
<summary>摘要</summary>
人类水平AI的发现新抽象是重要的。我们提出了一种方法，用于发现更高级别的抽象，如地图、筛选和折叠。我们将焦点放在逻辑编程中，它从示例和背景知识中逻辑程序的induction。我们介绍了更高级别的重构问题，目标是通过引入更高级别的抽象来压缩逻辑程序。我们在STEVIE中实现了我们的方法，它将更高级别的重构问题形式化为约束优化问题。我们的实验结果在多个领域，包括程序生成和视觉理解，表明，相比没有重构，STEVIE可以提高预测精度27%，降低学习时间47%。我们还表明STEVIE可以找到可以在不同领域传递的抽象。
</details></li>
</ul>
<hr>
<h2 id="Warped-geometric-information-on-the-optimisation-of-Euclidean-functions"><a href="#Warped-geometric-information-on-the-optimisation-of-Euclidean-functions" class="headerlink" title="Warped geometric information on the optimisation of Euclidean functions"></a>Warped geometric information on the optimisation of Euclidean functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08305">http://arxiv.org/abs/2308.08305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcelo Hartmann, Bernardo Williams, Hanlin Yu, Mark Girolami, Alessandro Barp, Arto Klami</li>
<li>for: 优化一个具有高维 Euclidian 空间中的实数函数，如机器学习任务中的损失函数或统计推断中的 probaility 分布 logarithm。</li>
<li>methods: 使用折叠 Riemean 几何 notion 重新定义了函数在 Euclidean 空间上的优化问题为一个 Riemean 拓扑上的函数，然后在这个拓扑上寻找函数的最优点。选择的折叠 metric 使得优化问题变成了一个计算友好的 metric-tensor，可以轻松地计算优化方向。</li>
<li>results: 使用 third-order  Taylor 约化来 aproximate geodesic curve，并使用 retraction map 将其拔回到拓扑上。这种方法可以有效地优化 geodesic curve。与标准 Euclidean gradient-based 对抗方法相比，提出的算法在迭代次数到达 converges 和 Hessian-based 优化 Routine 中表现更好。<details>
<summary>Abstract</summary>
We consider the fundamental task of optimizing a real-valued function defined in a potentially high-dimensional Euclidean space, such as the loss function in many machine-learning tasks or the logarithm of the probability distribution in statistical inference. We use the warped Riemannian geometry notions to redefine the optimisation problem of a function on Euclidean space to a Riemannian manifold with a warped metric, and then find the function's optimum along this manifold. The warped metric chosen for the search domain induces a computational friendly metric-tensor for which optimal search directions associate with geodesic curves on the manifold becomes easier to compute. Performing optimization along geodesics is known to be generally infeasible, yet we show that in this specific manifold we can analytically derive Taylor approximations up to third-order. In general these approximations to the geodesic curve will not lie on the manifold, however we construct suitable retraction maps to pull them back onto the manifold. Therefore, we can efficiently optimize along the approximate geodesic curves. We cover the related theory, describe a practical optimization algorithm and empirically evaluate it on a collection of challenging optimisation benchmarks. Our proposed algorithm, using third-order approximation of geodesics, outperforms standard Euclidean gradient-based counterparts in term of number of iterations until convergence and an alternative method for Hessian-based optimisation routines.
</details>
<details>
<summary>摘要</summary>
我们考虑一个基本任务，即优化一个定义在可能高维欧几学空间中的实数函数，例如机器学习任务中的损函数或统计推断中的Logarithm的分布函数。我们使用扭曲的里曼纹理观念来重新定义欧几学空间上的函数优化问题为一个里曼拓扑上的函数优化问题，然后在这个拓扑上找到函数的最优点。选择的扭曲纹理在搜索空间上引入了一个计算友好的矩阵对应，其中优化搜索方向与拓扑上的地odesic曲线相关的计算变得更加容易。尽管在拓扑上的搜索通常是不可能的，但我们表明在这种特殊拓扑上，我们可以 analytically derivate Taylor approximations up to third-order。这些近似曲线不会在拓扑上，但我们可以构造适当的 retraction map 将其拟合回拓扑上。因此，我们可以高效地优化这些近似曲线。我们还详细介绍了相关理论、实践的优化算法以及对一系列困难优化问题的实验评估。我们的提议的算法，使用第三阶 Taylor 近似，在迭代次数 until convergence 和一种基于Hessian的优化方法之间占据了优势。
</details></li>
</ul>
<hr>
<h2 id="Robust-Bayesian-Satisficing"><a href="#Robust-Bayesian-Satisficing" class="headerlink" title="Robust Bayesian Satisficing"></a>Robust Bayesian Satisficing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08291">http://arxiv.org/abs/2308.08291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Artun Saday, Yaşar Cahit Yıldırım, Cem Tekin</li>
<li>for: 本研究旨在掌握robust satisficing（RS）在contextual Bayesian optimization中的问题，以及在存在 Context 的假设分布与真实分布之间的差异。</li>
<li>methods: 我们提出了一种新的robust Bayesian satisficing算法（RoBOS），用于启发黑盒优化。我们的算法在某些假设下保证了下凹的 regret。此外，我们还定义了一种弱化的 regret 度量，称为 robust satisficing regret，我们的算法在这种情况下实现了下凹的上界独立于分布差异。</li>
<li>results: 我们在各种学习问题中应用了我们的方法，并与其他方法，如分布ally robust optimization，进行比较。我们的结果显示，RoBOS 能够在不同的学习问题中提供更好的性能，并且可以适应不同的分布差异。<details>
<summary>Abstract</summary>
Distributional shifts pose a significant challenge to achieving robustness in contemporary machine learning. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTDistributional shifts pose a significant challenge to achieving robustness in contemporary machine learning. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization.TRANSLATE_TEXT以下是文章的中文翻译：Distributional shifts pose a significant challenge to achieving robustness in contemporary machine learning. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. 本文关注在Contextual Bayesian optimization中的RS问题，当真实分布与参考分布之间存在差异时。我们提出了一种名为RoBOS的robust Bayesian satisficing算法，用于黑盒优化。我们的算法在certain assumptions中 guarantee sublinear lenient regret。此外，我们定义了一种弱的 regret called robust satisficing regret，在这种情况下，我们的算法 achieves sublinear upper bound，不受分布shift的影响。为证明我们的方法的效果，我们将其应用于various learning problems，并与其他方法进行比较，如distributionally robust optimization。
</details></li>
</ul>
<hr>
<h2 id="DFedADMM-Dual-Constraints-Controlled-Model-Inconsistency-for-Decentralized-Federated-Learning"><a href="#DFedADMM-Dual-Constraints-Controlled-Model-Inconsistency-for-Decentralized-Federated-Learning" class="headerlink" title="DFedADMM: Dual Constraints Controlled Model Inconsistency for Decentralized Federated Learning"></a>DFedADMM: Dual Constraints Controlled Model Inconsistency for Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08290">http://arxiv.org/abs/2308.08290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinglun Li, Li Shen, Guanghao Li, Quanjun Yin, Dacheng Tao</li>
<li>for: 这个论文的目的是提出一种基于分布式学习的训练方法，以解决联合学习中的通信负担问题。</li>
<li>methods: 这个论文使用的方法是基于ADMM的分布式优化算法，并在这个基础上提出了两种改进版本：DFedADMM和DFedADMM-SAM。</li>
<li>results: 实验表明，这些算法在MNIST、CIFAR10和CIFAR100数据集上具有较高的泛化性和更快的收敛速度，比既有的状态态峰值优化器（SOTA）在分布式学习中表现更好。<details>
<summary>Abstract</summary>
To address the communication burden issues associated with federated learning (FL), decentralized federated learning (DFL) discards the central server and establishes a decentralized communication network, where each client communicates only with neighboring clients. However, existing DFL methods still suffer from two major challenges: local inconsistency and local heterogeneous overfitting, which have not been fundamentally addressed by existing DFL methods. To tackle these issues, we propose novel DFL algorithms, DFedADMM and its enhanced version DFedADMM-SAM, to enhance the performance of DFL. The DFedADMM algorithm employs primal-dual optimization (ADMM) by utilizing dual variables to control the model inconsistency raised from the decentralized heterogeneous data distributions. The DFedADMM-SAM algorithm further improves on DFedADMM by employing a Sharpness-Aware Minimization (SAM) optimizer, which uses gradient perturbations to generate locally flat models and searches for models with uniformly low loss values to mitigate local heterogeneous overfitting. Theoretically, we derive convergence rates of $\small \mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}\Big)$ and $\small \mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}+ \frac{1}{T^{3/2}K^{1/2}}\Big)$ in the non-convex setting for DFedADMM and DFedADMM-SAM, respectively, where $1 - \psi$ represents the spectral gap of the gossip matrix. Empirically, extensive experiments on MNIST, CIFAR10 and CIFAR100 datesets demonstrate that our algorithms exhibit superior performance in terms of both generalization and convergence speed compared to existing state-of-the-art (SOTA) optimizers in DFL.
</details>
<details>
<summary>摘要</summary>
为了解决联合学习（FL）中的通信负担问题，分布式联合学习（DFL）抛弃中央服务器，建立了分布式通信网络，每个客户端只与周围的客户端进行通信。然而，现有的DFL方法仍面临两个主要挑战：本地不一致和本地特异适应，这些问题尚未由现有的DFL方法得到基本解决。为此，我们提出了新的DFL算法，即DFedADMM和其加强版DFedADMM-SAM，以提高DFL的性能。DFedADMM算法使用了 primal-dual 优化（ADMM），通过使用 dual 变量控制分布式不同数据分布引起的模型不一致。DFedADMM-SAM算法进一步改进了 DFedADMM，通过使用 Sharpness-Aware Minimization（SAM）优化器，通过斜坡值误差来生成本地平滑模型，并在搜索本地特异适应模型时使用 Gradient Perturbations。理论上，我们得出了 $\small \mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}\Big)$ 和 $\small \mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}+\frac{1}{T^{3/2}K^{1/2}}\Big)$ 的收敛速率在非对称设定下，其中 $1 - \psi$ 表示热度矩阵的spectral gap。实验结果表明，我们的算法在 MNIST、CIFAR10 和 CIFAR100 数据集上展现出了与现有最佳优化器相比的优秀表现，包括总体化和收敛速度。
</details></li>
</ul>
<hr>
<h2 id="CARE-A-Large-Scale-CT-Image-Dataset-and-Clinical-Applicable-Benchmark-Model-for-Rectal-Cancer-Segmentation"><a href="#CARE-A-Large-Scale-CT-Image-Dataset-and-Clinical-Applicable-Benchmark-Model-for-Rectal-Cancer-Segmentation" class="headerlink" title="CARE: A Large Scale CT Image Dataset and Clinical Applicable Benchmark Model for Rectal Cancer Segmentation"></a>CARE: A Large Scale CT Image Dataset and Clinical Applicable Benchmark Model for Rectal Cancer Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08283">http://arxiv.org/abs/2308.08283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hantao Zhang, Weidong Guo, Chenyang Qiu, Shouhong Wan, Bingbing Zou, Wanqin Wang, Peiquan Jin</li>
<li>for: 这个论文的目的是提出一种新的大规模RECTAL CANCER CT图像数据集CARE，以及一种特有的医疗器官癌症分割模型U-SAM，以解决RECTAL CANCER CT图像分割precision的问题。</li>
<li>methods: 这个论文使用了一种新的大规模RECTAL CANCER CT图像数据集CARE，并提出了一种特有的医疗器官癌症分割模型U-SAM，该模型包括三个关键组件：提示信息（例如，点）， convolution模块，和 skip-connection，以解决肠道器官的复杂结构。</li>
<li>results: 该论文的实验结果表明，提出的U-SAM模型在CARE数据集和WORD数据集上都能够达到state-of-the-art的性能水平，并且可以serve as the baseline for future research和临床应用开发。<details>
<summary>Abstract</summary>
Rectal cancer segmentation of CT image plays a crucial role in timely clinical diagnosis, radiotherapy treatment, and follow-up. Although current segmentation methods have shown promise in delineating cancerous tissues, they still encounter challenges in achieving high segmentation precision. These obstacles arise from the intricate anatomical structures of the rectum and the difficulties in performing differential diagnosis of rectal cancer. Additionally, a major obstacle is the lack of a large-scale, finely annotated CT image dataset for rectal cancer segmentation. To address these issues, this work introduces a novel large scale rectal cancer CT image dataset CARE with pixel-level annotations for both normal and cancerous rectum, which serves as a valuable resource for algorithm research and clinical application development. Moreover, we propose a novel medical cancer lesion segmentation benchmark model named U-SAM. The model is specifically designed to tackle the challenges posed by the intricate anatomical structures of abdominal organs by incorporating prompt information. U-SAM contains three key components: promptable information (e.g., points) to aid in target area localization, a convolution module for capturing low-level lesion details, and skip-connections to preserve and recover spatial information during the encoding-decoding process. To evaluate the effectiveness of U-SAM, we systematically compare its performance with several popular segmentation methods on the CARE dataset. The generalization of the model is further verified on the WORD dataset. Extensive experiments demonstrate that the proposed U-SAM outperforms state-of-the-art methods on these two datasets. These experiments can serve as the baseline for future research and clinical application development.
</details>
<details>
<summary>摘要</summary>
癌症肛部分 segmentation CT 图像在至关重要的诊断、放疗治疗和跟踪中扮演着关键角色。尽管当前的分 segmentation 方法已经展示了潜在的精度，但它们仍然遇到了在准确地分 segmentation 癌症组织的挑战。这些障碍来自肛部的复杂 анатомиче 结构以及Difficulties in performing differential diagnosis of rectal cancer。此外，lack of a large-scale, finely annotated CT image dataset for rectal cancer segmentation。 To address these issues, this work introduces a novel large-scale rectal cancer CT image dataset CARE with pixel-level annotations for both normal and cancerous rectum, which serves as a valuable resource for algorithm research and clinical application development. Moreover, we propose a novel medical cancer lesion segmentation benchmark model named U-SAM. The model is specifically designed to tackle the challenges posed by the intricate anatomical structures of abdominal organs by incorporating prompt information. U-SAM contains three key components: promptable information (e.g., points) to aid in target area localization, a convolution module for capturing low-level lesion details, and skip-connections to preserve and recover spatial information during the encoding-decoding process. To evaluate the effectiveness of U-SAM, we systematically compare its performance with several popular segmentation methods on the CARE dataset. The generalization of the model is further verified on the WORD dataset. Extensive experiments demonstrate that the proposed U-SAM outperforms state-of-the-art methods on these two datasets. These experiments can serve as the baseline for future research and clinical application development.
</details></li>
</ul>
<hr>
<h2 id="It-Ain’t-That-Bad-Understanding-the-Mysterious-Performance-Drop-in-OOD-Generalization-for-Generative-Transformer-Models"><a href="#It-Ain’t-That-Bad-Understanding-the-Mysterious-Performance-Drop-in-OOD-Generalization-for-Generative-Transformer-Models" class="headerlink" title="It Ain’t That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models"></a>It Ain’t That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08268">http://arxiv.org/abs/2308.08268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingcheng Xu, Zihao Pan, Haipeng Zhang, Yanqing Yang</li>
<li>for:  investigate the generalization behaviors of Generative Transformer-based models</li>
<li>methods:  using n-digit addition and multiplication tasks to study the models’ generalization abilities</li>
<li>results:  discovered that the models have structured representations and learned algebraic structures, but struggle with out-of-distribution inputs<details>
<summary>Abstract</summary>
Generative Transformer-based models have achieved remarkable proficiency on solving diverse problems. However, their generalization ability is not fully understood and not always satisfying. Researchers take basic mathematical tasks like n-digit addition or multiplication as important perspectives for investigating their generalization behaviors. Curiously, it is observed that when training on n-digit operations (e.g., additions) in which both input operands are n-digit in length, models generalize successfully on unseen n-digit inputs (in-distribution (ID) generalization), but fail miserably and mysteriously on longer, unseen cases (out-of-distribution (OOD) generalization). Studies try to bridge this gap with workarounds such as modifying position embedding, fine-tuning, and priming with more extensive or instructive data. However, without addressing the essential mechanism, there is hardly any guarantee regarding the robustness of these solutions. We bring this unexplained performance drop into attention and ask whether it is purely from random errors. Here we turn to the mechanistic line of research which has notable successes in model interpretability. We discover that the strong ID generalization stems from structured representations, while behind the unsatisfying OOD performance, the models still exhibit clear learned algebraic structures. Specifically, these models map unseen OOD inputs to outputs with equivalence relations in the ID domain. These highlight the potential of the models to carry useful information for improved generalization.
</details>
<details>
<summary>摘要</summary>
We bring attention to this unexplained performance drop and question whether it is due to random errors. To address this, we turn to the mechanistic line of research, which has been successful in model interpretability. We find that the strong ID generalization is due to structured representations, while the unsatisfying OOD performance is caused by the models still exhibiting clear learned algebraic structures. Specifically, these models map unseen OOD inputs to outputs with equivalence relations in the ID domain, highlighting the potential for improved generalization.
</details></li>
</ul>
<hr>
<h2 id="Graph-Relation-Aware-Continual-Learning"><a href="#Graph-Relation-Aware-Continual-Learning" class="headerlink" title="Graph Relation Aware Continual Learning"></a>Graph Relation Aware Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08259">http://arxiv.org/abs/2308.08259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinghua Shen, Weijieying Ren, Wei Qin</li>
<li>for: 本研究探讨了从无穷数据流中学习图像，卷积历史知识，并将其推广到未来任务。在这个任务中，只有当前图像数据可用。</li>
<li>methods: 本研究使用了一种叫做 relation-aware adaptive model（RAM-CG），它包括一个用于发现 latent relations 的模块和一个用于考虑时间推移的掩模。</li>
<li>results: 实验结果显示，RAM-CG 相比于当前状态的最佳结果，在 CitationNet、OGBN-arxiv 和 TWITCH 数据集上提供了显著的 2.2%、6.9% 和 6.6% 的改进。<details>
<summary>Abstract</summary>
Continual graph learning (CGL) studies the problem of learning from an infinite stream of graph data, consolidating historical knowledge, and generalizing it to the future task. At once, only current graph data are available. Although some recent attempts have been made to handle this task, we still face two potential challenges: 1) most of existing works only manipulate on the intermediate graph embedding and ignore intrinsic properties of graphs. It is non-trivial to differentiate the transferred information across graphs. 2) recent attempts take a parameter-sharing policy to transfer knowledge across time steps or progressively expand new architecture given shifted graph distribution. Learning a single model could loss discriminative information for each graph task while the model expansion scheme suffers from high model complexity. In this paper, we point out that latent relations behind graph edges can be attributed as an invariant factor for the evolving graphs and the statistical information of latent relations evolves. Motivated by this, we design a relation-aware adaptive model, dubbed as RAM-CG, that consists of a relation-discovery modular to explore latent relations behind edges and a task-awareness masking classifier to accounts for the shifted. Extensive experiments show that RAM-CG provides significant 2.2%, 6.9% and 6.6% accuracy improvements over the state-of-the-art results on CitationNet, OGBN-arxiv and TWITCH dataset, respective.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Two-Phases-of-Scaling-Laws-for-Nearest-Neighbor-Classifiers"><a href="#Two-Phases-of-Scaling-Laws-for-Nearest-Neighbor-Classifiers" class="headerlink" title="Two Phases of Scaling Laws for Nearest Neighbor Classifiers"></a>Two Phases of Scaling Laws for Nearest Neighbor Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08247">http://arxiv.org/abs/2308.08247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengkun Yang, Jingzhao Zhang</li>
<li>for: 本文研究近邻类ifiers的扩展法律。</li>
<li>methods: 作者使用了数据分布的复杂性来解释模型的通用错误。</li>
<li>results: 作者发现了两个阶段的扩展法律：在第一阶段，通用错误与数据维度之间存在直接的 polynomial 关系，而在第二阶段，错误与数据维度之间存在 exponential 关系。这种分布复杂性对模型的通用性产生了重要的影响。当数据分布宽泛时，近邻类ifiers 可以实现 polynomial 类型的通用错误，而不是 exponential 类型。<details>
<summary>Abstract</summary>
A scaling law refers to the observation that the test performance of a model improves as the number of training data increases. A fast scaling law implies that one can solve machine learning problems by simply boosting the data and the model sizes. Yet, in many cases, the benefit of adding more data can be negligible. In this work, we study the rate of scaling laws of nearest neighbor classifiers. We show that a scaling law can have two phases: in the first phase, the generalization error depends polynomially on the data dimension and decreases fast; whereas in the second phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the generalization error. When the data distributes benignly, our result suggests that nearest neighbor classifier can achieve a generalization error that depends polynomially, instead of exponentially, on the data dimension.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本）一个减小法（scaling law）指的是模型在训练数据量增加后测试性能的改善。快速减小法则意味着只需增加数据和模型大小就可以解决机器学习问题。然而，在许多情况下，增加更多数据的效果可能是微乎其微。在这项工作中，我们研究近似 neighboor 类型的减小法。我们发现一个减小法可以分为两个阶段：在第一阶段，总体错误取决于数据维度的度量函数，随着数据维度增加而快速下降;而在第二阶段，错误取决于数据维度的指数函数，随着数据维度增加而慢速下降。我们的分析表明数据分布的复杂性对总体错误的确定产生了重要影响。当数据分布良好时，我们的结果表明，近似 neighboor 类型的模型可以实现数据维度取决于指数函数而不是指数函数的总体错误。
</details></li>
</ul>
<hr>
<h2 id="The-Expressive-Power-of-Graph-Neural-Networks-A-Survey"><a href="#The-Expressive-Power-of-Graph-Neural-Networks-A-Survey" class="headerlink" title="The Expressive Power of Graph Neural Networks: A Survey"></a>The Expressive Power of Graph Neural Networks: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08235">http://arxiv.org/abs/2308.08235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxu Zhang, Changjun Fan, Shixuan Liu, Kuihua Huang, Xiang Zhao, Jincai Huang, Zhong Liu</li>
<li>for: 本研究旨在探讨图 neural network (GNN) 的表达能力问题，即 GNN 能够学习什么样的图结构和特征。</li>
<li>methods: 本研究使用了多种方法来探讨 GNN 的表达能力，包括图特征增强、图结构增强和 GNN 架构增强等方法。</li>
<li>results: 本研究结果显示，通过不同的定义和方法，GNN 可以具有不同的表达能力，并且可以用于解决多种图学和机器学习问题。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) are effective machine learning models for many graph-related applications. Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., Graph feature enhancement, Graph topology enhancement, and GNNs architecture enhancement.
</details>
<details>
<summary>摘要</summary>
格Nodes neural networks (GNNs) 是多种图像应用中的有效机器学习模型。 Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., 图像特征增强, 图像结构增强, and GNNs 架构增强.
</details></li>
</ul>
<hr>
<h2 id="Challenges-and-Opportunities-of-Using-Transformer-Based-Multi-Task-Learning-in-NLP-Through-ML-Lifecycle-A-Survey"><a href="#Challenges-and-Opportunities-of-Using-Transformer-Based-Multi-Task-Learning-in-NLP-Through-ML-Lifecycle-A-Survey" class="headerlink" title="Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey"></a>Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08234">http://arxiv.org/abs/2308.08234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lovre Torbarina, Tin Ferkovic, Lukasz Roguski, Velimir Mihelcic, Bruno Sarlija, Zeljko Kraljevic</li>
<li>for: 本研究旨在提高自然语言处理（NLP）模型的效率和性能，通过 JOINT 训练多个模型，而不是单独训练每个模型。</li>
<li>methods: 本文提出了一种基于 transformer 的多任务学习（MTL）方法，并系统地分析了在 NLP 领域中这种方法如何应用于各个机器学习生命周期阶段。</li>
<li>results: 本文提出了一种基于 transformer 的 MTL 方法，并对这种方法的应用进行了系统的分析，包括数据工程、模型开发、部署和监测等阶段。此外，本文还提出了一种将 MTL 与 continual learning（CL）相连的想法，以便在模型 Periodically 重新训练、更新和添加新功能等方面具有更高的灵活性和可扩展性。<details>
<summary>Abstract</summary>
The increasing adoption of natural language processing (NLP) models across industries has led to practitioners' need for machine learning systems to handle these models efficiently, from training to serving them in production. However, training, deploying, and updating multiple models can be complex, costly, and time-consuming, mainly when using transformer-based pre-trained language models. Multi-Task Learning (MTL) has emerged as a promising approach to improve efficiency and performance through joint training, rather than training separate models. Motivated by this, we first provide an overview of transformer-based MTL approaches in NLP. Then, we discuss the challenges and opportunities of using MTL approaches throughout typical ML lifecycle phases, specifically focusing on the challenges related to data engineering, model development, deployment, and monitoring phases. This survey focuses on transformer-based MTL architectures and, to the best of our knowledge, is novel in that it systematically analyses how transformer-based MTL in NLP fits into ML lifecycle phases. Furthermore, we motivate research on the connection between MTL and continual learning (CL), as this area remains unexplored. We believe it would be practical to have a model that can handle both MTL and CL, as this would make it easier to periodically re-train the model, update it due to distribution shifts, and add new capabilities to meet real-world requirements.
</details>
<details>
<summary>摘要</summary>
随着自然语言处理（NLP）模型在不同领域的推广，机器学习（ML）实践者需要能够高效地训练、部署和更新多个模型，从训练到生产环境中的部署。然而，训练、部署和更新多个模型可能会复杂、成本高和时间consuming，特别是使用基于转换器的预训练语言模型。多任务学习（MTL）已经出现为提高效率和性能的可能性，我们将提供一个概述 transformer-based MTL 在 NLP 中的方法。然后，我们将讨论在 ML 生命周期阶段中使用 MTL approaches 的挑战和机遇，特别是关注数据工程、模型开发、部署和监控阶段的挑战。本文将重点关注基于 transformer 的 MTL 架构，并且，到我们所知道的 extend，这是一篇系统性的分析文章，探讨了 transformer-based MTL 在 NLP 中如何适应 ML 生命周期阶段。此外，我们还motivates 研究将 MTL 和 continual learning（CL）相连接，因为这个领域还没有得到过足的研究。我们认为，一个能够同时处理 MTL 和 CL 的模型会更加实用，这样可以更加方便地在 periodic 训练、因 distribution shift 更新模型以及添加新功能来满足实际需求。
</details></li>
</ul>
<hr>
<h2 id="SCQPTH-an-efficient-differentiable-splitting-method-for-convex-quadratic-programming"><a href="#SCQPTH-an-efficient-differentiable-splitting-method-for-convex-quadratic-programming" class="headerlink" title="SCQPTH: an efficient differentiable splitting method for convex quadratic programming"></a>SCQPTH: an efficient differentiable splitting method for convex quadratic programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08232">http://arxiv.org/abs/2308.08232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Butler</li>
<li>for: 这篇论文主要是为了提出一种可微分的第一阶分裂法（SCQPTH），用于解 convex quadratic programs（QPs）。</li>
<li>methods: 这种方法基于 alternating direction method of multipliers（ADMM），并且受到现有的 state-of-the-art solver OSQP：一种操作分裂解决方案的启发。</li>
<li>results: 实验表明，对于大规模的 QPs，SCQPTH 可以提供 $1\times - 10\times$ 的计算效率提升，相比现有的可微分 QP 解决方案。<details>
<summary>Abstract</summary>
We present SCQPTH: a differentiable first-order splitting method for convex quadratic programs. The SCQPTH framework is based on the alternating direction method of multipliers (ADMM) and the software implementation is motivated by the state-of-the art solver OSQP: an operating splitting solver for convex quadratic programs (QPs). The SCQPTH software is made available as an open-source python package and contains many similar features including efficient reuse of matrix factorizations, infeasibility detection, automatic scaling and parameter selection. The forward pass algorithm performs operator splitting in the dimension of the original problem space and is therefore suitable for large scale QPs with $100-1000$ decision variables and thousands of constraints. Backpropagation is performed by implicit differentiation of the ADMM fixed-point mapping. Experiments demonstrate that for large scale QPs, SCQPTH can provide a $1\times - 10\times$ improvement in computational efficiency in comparison to existing differentiable QP solvers.
</details>
<details>
<summary>摘要</summary>
我们介绍了 SCQPTH：一种可微分的首选分解方法 для凸quadratic programs。 SCQPTH框架基于alternating direction method of multipliers（ADMM），并且由state-of-the-art solver OSQP：一种操作分裂解决方法 для凸quadratic programs（QPs）所 inspirited。 SCQPTH软件作为开源python包，具有许多相似特点，包括高效的矩阵因子重用、不可行检测、自动缩放和参数选择。 forward pass算法在原始问题空间的维度进行operator splitting，适用于大规模QPs，具有100-1000个决策变量和千个约束。 backpropagation通过ADMM固定点映射的隐式导数计算。实验表明，对于大规模QPs，SCQPTH可以提供1\*-10\*的计算效率提升，相比现有的可微分QP解决方法。
</details></li>
</ul>
<hr>
<h2 id="Self-Deception-Reverse-Penetrating-the-Semantic-Firewall-of-Large-Language-Models"><a href="#Self-Deception-Reverse-Penetrating-the-Semantic-Firewall-of-Large-Language-Models" class="headerlink" title="Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models"></a>Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11521">http://arxiv.org/abs/2308.11521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhua Wang, Wei Xie, Kai Chen, Baosheng Wang, Zhiwen Gui, Enze Wang<br>for:* The paper investigates the “LLM jailbreak” problem and proposes an automatic jailbreak method for the first time.methods:* The paper introduces the concept of a “semantic firewall” and provides three technical implementation approaches.* The paper introduces a “self-deception” attack that can bypass the semantic firewall by inducing LLM to generate prompts that facilitate jailbreak.results:* The paper reports a success rate of 86.2% and 67% on two models (GPT-3.5-Turbo and GPT-4) in generating attack payloads that can bypass the semantic firewall.* The paper also reports a failure rate of 4.7% and 2.2% on the two models, respectively.<details>
<summary>Abstract</summary>
Large language models (LLMs), such as ChatGPT, have emerged with astonishing capabilities approaching artificial general intelligence. While providing convenience for various societal needs, LLMs have also lowered the cost of generating harmful content. Consequently, LLM developers have deployed semantic-level defenses to recognize and reject prompts that may lead to inappropriate content. Unfortunately, these defenses are not foolproof, and some attackers have crafted "jailbreak" prompts that temporarily hypnotize the LLM into forgetting content defense rules and answering any improper questions. To date, there is no clear explanation of the principles behind these semantic-level attacks and defenses in both industry and academia.   This paper investigates the LLM jailbreak problem and proposes an automatic jailbreak method for the first time. We propose the concept of a semantic firewall and provide three technical implementation approaches. Inspired by the attack that penetrates traditional firewalls through reverse tunnels, we introduce a "self-deception" attack that can bypass the semantic firewall by inducing LLM to generate prompts that facilitate jailbreak. We generated a total of 2,520 attack payloads in six languages (English, Russian, French, Spanish, Chinese, and Arabic) across seven virtual scenarios, targeting the three most common types of violations: violence, hate, and pornography. The experiment was conducted on two models, namely the GPT-3.5-Turbo and GPT-4. The success rates on the two models were 86.2% and 67%, while the failure rates were 4.7% and 2.2%, respectively. This highlighted the effectiveness of the proposed attack method. All experimental code and raw data will be released as open-source to inspire future research. We believe that manipulating AI behavior through carefully crafted prompts will become an important research direction in the future.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如ChatGPT，已经出现了不可思议的能力，接近人工智能。它们为社会各种需求提供了便利，但也降低了生成危险内容的成本。因此，LLM开发者已经部署了semantic-level防御，以识别和拒绝可能导致不当内容的提示。然而，这些防御不是不可攻击的，一些攻击者已经制作了“监狱折衣”提示，使LLM忘记内容防御规则，回答任何不当问题。迄今为止，在业界和学术界都没有明确的semantic-level攻击和防御原理的解释。本文 investigate LLM监狱问题，并提出了自动监狱方法的第一次实现。我们提出了semantic firewall的概念，并提供了三种技术实现方式。受到传统防火墙被穿越反터 tunneled攻击的启发，我们引入了“自我欺骗”攻击，可以绕过semantic firewall，使LLM生成提示，促使监狱。我们总共生成了2,520个攻击 payload，分别在英语、俄语、法语、西班牙语、中文和阿拉伯语七种语言中，targeting三种最常见的违规行为：暴力、仇恨和色情。实验在GPT-3.5-Turbo和GPT-4两个模型上进行，成功率分别为86.2%和67%，失败率分别为4.7%和2.2%。这表明了我们提出的攻击方法的效iveness。我们将所有实验代码和原始数据发布为开源，以便未来的研究。我们认为，通过精心制作的提示，控制AI行为将成为未来的重要研究方向。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Winograd-Convolution-for-Cost-effective-Neural-Network-Fault-Tolerance"><a href="#Exploring-Winograd-Convolution-for-Cost-effective-Neural-Network-Fault-Tolerance" class="headerlink" title="Exploring Winograd Convolution for Cost-effective Neural Network Fault Tolerance"></a>Exploring Winograd Convolution for Cost-effective Neural Network Fault Tolerance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08230">http://arxiv.org/abs/2308.08230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinghua Xue, Cheng Liu, Bo Liu, Haitong Huang, Ying Wang, Tao Luo, Lei Zhang, Huawei Li, Xiaowei Li</li>
<li>for: 本文研究了Winograd核函数在神经网络中的稳定性，以提高神经网络的硬件缺陷忍容性。</li>
<li>methods: 本文从不同的粒度（模型、层、操作类型）进行了全面的Winograd核函数缺陷忍容性评估。然后，本文探讨了在Winograd核函数基础上实现成本效果的NN保护策略。</li>
<li>results: 实验结果表明，Winograd核函数可以在不减少精度的情况下减少硬件缺陷忍容性设计负担，并且可以在具有不同硬件缺陷的情况下提高NN的精度。<details>
<summary>Abstract</summary>
Winograd is generally utilized to optimize convolution performance and computational efficiency because of the reduced multiplication operations, but the reliability issues brought by winograd are usually overlooked. In this work, we observe the great potential of winograd convolution in improving neural network (NN) fault tolerance. Based on the observation, we evaluate winograd convolution fault tolerance comprehensively from different granularities ranging from models, layers, and operation types for the first time. Then, we explore the use of inherent fault tolerance of winograd convolution for cost-effective NN protection against soft errors. Specifically, we mainly investigate how winograd convolution can be effectively incorporated with classical fault-tolerant design approaches including triple modular redundancy (TMR), fault-aware retraining, and constrained activation functions. According to our experiments, winograd convolution can reduce the fault-tolerant design overhead by 55.77\% on average without any accuracy loss compared to standard convolution, and further reduce the computing overhead by 17.24\% when the inherent fault tolerance of winograd convolution is considered. When it is applied on fault-tolerant neural networks enhanced with fault-aware retraining and constrained activation functions, the resulting model accuracy generally shows significant improvement in presence of various faults.
</details>
<details>
<summary>摘要</summary>
Winograd通常用于优化卷积性能和计算效率，因为它减少了乘法操作数量，但Winograd的可靠性问题通常被忽略。在这种工作中，我们发现Winograd卷积可以提高神经网络（NN）fault tolerance的潜力。基于这一观察，我们系统地评估Winograd卷积 fault tolerance从不同的粒度（models、layers、operation types）开始。然后，我们探索使用Winograd卷积的内在fault tolerance来实现cost-effective NN保护 against soft errors。具体来说，我们主要研究如何有效地将Winograd卷积与经典的 fault-tolerant设计方法（如TMR、 fault-aware retraining和受限 activation functions）结合使用。根据我们的实验，Winograd卷积可以在标准卷积的基础上减少fault-tolerant设计开销55.77%，而且在考虑Winograd卷积的内在fault tolerance时，可以减少计算开销17.24%。当应用于强化了 fault-tolerant神经网络的Winograd卷积、 fault-aware retraining和受限 activation functions后，模型的准确率在不同类型的缺陷情况下都显示了显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Inherent-Redundancy-in-Spiking-Neural-Networks"><a href="#Inherent-Redundancy-in-Spiking-Neural-Networks" class="headerlink" title="Inherent Redundancy in Spiking Neural Networks"></a>Inherent Redundancy in Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08227">http://arxiv.org/abs/2308.08227</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/biclab/asa-snn">https://github.com/biclab/asa-snn</a></li>
<li>paper_authors: Man Yao, Jiakui Hu, Guangshe Zhao, Yaoyuan Wang, Ziyang Zhang, Bo Xu, Guoqi Li</li>
<li>for: 本研究旨在探讨隐藏在神经网络中的内在重复性，以提高神经网络的准确率和能效性。</li>
<li>methods: 本研究使用了隐藏状态激活（HSA）模块，以适应神经网络中的内在重复性，并对神经网络的各个元素进行了优化。</li>
<li>results: 实验结果表明，提案的方法可以显著减少神经网络中的冲击脉冲，并在比较于现有神经网络基eline上显示更好的性能。<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) are well known as a promising energy-efficient alternative to conventional artificial neural networks. Subject to the preconceived impression that SNNs are sparse firing, the analysis and optimization of inherent redundancy in SNNs have been largely overlooked, thus the potential advantages of spike-based neuromorphic computing in accuracy and energy efficiency are interfered. In this work, we pose and focus on three key questions regarding the inherent redundancy in SNNs. We argue that the redundancy is induced by the spatio-temporal invariance of SNNs, which enhances the efficiency of parameter utilization but also invites lots of noise spikes. Further, we analyze the effect of spatio-temporal invariance on the spatio-temporal dynamics and spike firing of SNNs. Then, motivated by these analyses, we propose an Advance Spatial Attention (ASA) module to harness SNNs' redundancy, which can adaptively optimize their membrane potential distribution by a pair of individual spatial attention sub-modules. In this way, noise spike features are accurately regulated. Experimental results demonstrate that the proposed method can significantly drop the spike firing with better performance than state-of-the-art SNN baselines. Our code is available in \url{https://github.com/BICLab/ASA-SNN}.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）已经广泛认可为一种能效的人工神经网络 alternatives。然而，由于人们对 SNN 的偏见，即 SNN 是稀疏的发射，因此对 SNN 内部缺乏 redundancy 的分析和优化，从而阻碍了 SNN 在准确性和能效性方面的潜在优势。在这个工作中，我们提出了三个关键问题，关于 SNN 中的内部缺乏 redundancy。我们认为，这种缺乏 redundancy 是由 SNN 的空间-时间不变性引起的，这种不变性可以提高参数的使用效率，但也会引入很多噪声脉冲。然后，我们分析了 SNN 的空间-时间动力学和脉冲发生的影响。根据这些分析结果，我们提出了一种 Advance Spatial Attention（ASA）模块，可以利用 SNN 的缺乏 redundancy，并可以自适应调整 SNN 的膜电压分布。这样，可以准确地控制噪声脉冲特征。实验结果表明，我们的方法可以显著降低 SNN 的脉冲发生，并且比现有的 SNN 基eline 性能更好。我们的代码可以在 \url{https://github.com/BICLab/ASA-SNN} 上找到。
</details></li>
</ul>
<hr>
<h2 id="How-To-Overcome-Confirmation-Bias-in-Semi-Supervised-Image-Classification-By-Active-Learning"><a href="#How-To-Overcome-Confirmation-Bias-in-Semi-Supervised-Image-Classification-By-Active-Learning" class="headerlink" title="How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning"></a>How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08224">http://arxiv.org/abs/2308.08224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra Gilhuber, Rasmus Hvingelby, Mang Ling Ada Fok, Thomas Seidl</li>
<li>for: 本研究是为了检验是否需要活动学习，因为强大的深度半supervised方法的出现使得有限的标注数据设置中的活动学习可能失效。</li>
<li>methods: 本研究使用了semi-supervised learning（SSL）方法和活动学习（AL）方法，并 comparing their performance in realistic data scenarios。</li>
<li>results: 研究发现，在实际数据场景中，SSL方法可能会受到between-class imbalance、within-class imbalance和between-class similarity等挑战，这些挑战可能会导致SSL性能下降。然而，通过使用AL方法，可以超越confirmation bias，并在这些实际数据场景中提高SSL性能。<details>
<summary>Abstract</summary>
Do we need active learning? The rise of strong deep semi-supervised methods raises doubt about the usability of active learning in limited labeled data settings. This is caused by results showing that combining semi-supervised learning (SSL) methods with a random selection for labeling can outperform existing active learning (AL) techniques. However, these results are obtained from experiments on well-established benchmark datasets that can overestimate the external validity. However, the literature lacks sufficient research on the performance of active semi-supervised learning methods in realistic data scenarios, leaving a notable gap in our understanding. Therefore we present three data challenges common in real-world applications: between-class imbalance, within-class imbalance, and between-class similarity. These challenges can hurt SSL performance due to confirmation bias. We conduct experiments with SSL and AL on simulated data challenges and find that random sampling does not mitigate confirmation bias and, in some cases, leads to worse performance than supervised learning. In contrast, we demonstrate that AL can overcome confirmation bias in SSL in these realistic settings. Our results provide insights into the potential of combining active and semi-supervised learning in the presence of common real-world challenges, which is a promising direction for robust methods when learning with limited labeled data in real-world applications.
</details>
<details>
<summary>摘要</summary>
active learning是必要吗？ semi-supervised learning的强大方法的出现使得有限的标注数据设置中使用active learning的可用性存在各种 вопро题。这是因为结果表明将 semi-supervised learning（SSL）方法与随机选择标注结合可以超越现有的active learning（AL）技术。然而，这些结果是基于可靠的标准 benchmark dataset上进行的实验，这可能会过分估计外部适用性。然而，文献缺乏对实际数据场景中active semi-supervised learning方法的性能研究，这种知识漏洞存在。因此，我们提出了三种常见的实际数据挑战： между类异常、 Within-class异常和 между类相似。这些挑战可能会对 SSL性能产生负面影响，因为确认偏见。我们在模拟数据挑战中进行了SSL和AL实验，发现随机抽样不能消除确认偏见，有时even worse than supervised learning。然而，我们发现AL可以在这些实际设置中超越确认偏见。我们的结果为将活动和 semi-supervised learning结合使用在实际应用中的可能性提供了新的思路，这是一种robust方法在有限标注数据中学习的承诺。
</details></li>
</ul>
<hr>
<h2 id="HyperSNN-A-new-efficient-and-robust-deep-learning-model-for-resource-constrained-control-applications"><a href="#HyperSNN-A-new-efficient-and-robust-deep-learning-model-for-resource-constrained-control-applications" class="headerlink" title="HyperSNN: A new efficient and robust deep learning model for resource constrained control applications"></a>HyperSNN: A new efficient and robust deep learning model for resource constrained control applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08222">http://arxiv.org/abs/2308.08222</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanglu Yan, Shida Wang, Kaiwen Tang, Weng-Fai Wong</li>
<li>for: 这篇论文旨在探讨智能家居、机器人和智能家具等领域中的边缘计算技术，尤其是使用脉冲神经网络（SNN）和超dimensional computing来进行控制任务。</li>
<li>methods: 这篇论文提出了一种名为HyperSNN的新方法，它使用8位数字加法来替代昂贵的32位浮点数 Multiplications，从而降低能源消耗，提高了韧性和可能提高精度。</li>
<li>results: 我们在AI Gym评 bench上测试了HyperSNN，结果显示HyperSNN可以与传统机器学习方法相比，仅 consume 1.36%到9.96%的能源，且在韧性方面也有提高。我们认为HyperSNN适用于互动、移动和穿戴式设备，实现能效的系统设计，并且开拓了实际应用中的实时预测控制（MPC）等复杂算法的可能性。<details>
<summary>Abstract</summary>
In light of the increasing adoption of edge computing in areas such as intelligent furniture, robotics, and smart homes, this paper introduces HyperSNN, an innovative method for control tasks that uses spiking neural networks (SNNs) in combination with hyperdimensional computing. HyperSNN substitutes expensive 32-bit floating point multiplications with 8-bit integer additions, resulting in reduced energy consumption while enhancing robustness and potentially improving accuracy. Our model was tested on AI Gym benchmarks, including Cartpole, Acrobot, MountainCar, and Lunar Lander. HyperSNN achieves control accuracies that are on par with conventional machine learning methods but with only 1.36% to 9.96% of the energy expenditure. Furthermore, our experiments showed increased robustness when using HyperSNN. We believe that HyperSNN is especially suitable for interactive, mobile, and wearable devices, promoting energy-efficient and robust system design. Furthermore, it paves the way for the practical implementation of complex algorithms like model predictive control (MPC) in real-world industrial scenarios.
</details>
<details>
<summary>摘要</summary>
在智能家居、机器人和智能家具等领域的edge computing应用日益普及，这篇论文提出了HyperSNN方法，这是一种结合神经网络和高维计算的新型控制方法。HyperSNN通过将昂贵的32位浮点 multiply替换为8位整数加法，从而降低能耗，同时提高了鲁棒性和可能提高了准确性。我们的模型在AI Gym测试启用上，包括Cartpole、Acrobot、MountainCar和Lunar Lander等标准测试集，HyperSNN实现了与传统机器学习方法相当的控制精度，但能耗只有1.36%到9.96%。此外，我们的实验还表明了HyperSNN具有更高的鲁棒性。我们认为HyperSNN特别适合交互式、移动和穿戴设备，推动能效的系统设计，同时为实际应用中的复杂算法如模型预测控制（MPC）铺平了道路。
</details></li>
</ul>
<hr>
<h2 id="In-situ-Fault-Diagnosis-of-Indium-Tin-Oxide-Electrodes-by-Processing-S-Parameter-Patterns"><a href="#In-situ-Fault-Diagnosis-of-Indium-Tin-Oxide-Electrodes-by-Processing-S-Parameter-Patterns" class="headerlink" title="In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns"></a>In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11639">http://arxiv.org/abs/2308.11639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tae Yeob Kang, Haebom Lee, Sungho Suh</li>
<li>for: 该研究旨在为光电子器件中的铝镉酸盐电极进行不 destruktive 的故障检测和诊断，以确保设备的性能和可靠性。</li>
<li>methods: 该研究使用了干扰参数（S-parameter）信号处理方法，可以早期检测、具有高精度、鲁棒性和根本原因分析。</li>
<li>results: 研究表明，可以通过将不同通道的S-parameters作为输入，使用深度学习（DL）方法同时分析报头和严重程度。此外，在增加了添加性噪声水平时， combining 不同通道的S-parameters可以明显提高诊断性能。<details>
<summary>Abstract</summary>
In the field of optoelectronics, indium tin oxide (ITO) electrodes play a crucial role in various applications, such as displays, sensors, and solar cells. Effective fault detection and diagnosis of the ITO electrodes are essential to ensure the performance and reliability of the devices. However, traditional visual inspection is challenging with transparent ITO electrodes, and existing fault detection methods have limitations in determining the root causes of the defects, often requiring destructive evaluations. In this study, an in situ fault diagnosis method is proposed using scattering parameter (S-parameter) signal processing, offering early detection, high diagnostic accuracy, noise robustness, and root cause analysis. A comprehensive S-parameter pattern database is obtained according to defect states. Deep learning (DL) approaches, including multilayer perceptron (MLP), convolutional neural network (CNN), and transformer, are then used to simultaneously analyze the cause and severity of defects. Notably, it is demonstrated that the diagnostic performance under additive noise levels can be significantly enhanced by combining different channels of the S-parameters as input to the learning algorithms, as confirmed through the t-distributed stochastic neighbor embedding (t-SNE) dimension reduction visualization.
</details>
<details>
<summary>摘要</summary>
在光电子学领域中，镍铁矿（ITO）电极扮演着重要的角色，包括显示器、感测器和太阳能电池等应用。有效检测和诊断ITO电极的缺陷是保证设备性能和可靠性的关键。然而，传统的视觉检查受到透明ITO电极的限制，现有的缺陷检测方法往往无法决定缺陷的根本原因，需要破坏性评估。本研究提出了一种实时缺陷诊断方法，使用散射参数（S-parameter）信号处理，可以早期检测、具有高精度、鲁棒性和根本原因分析。通过对缺陷状态下的S-parameter模式库的获取，使用深度学习（DL）方法，包括多层感知神经网络（MLP）、卷积神经网络（CNN）和变换器，同时分析缺陷的原因和严重程度。另外，研究表明，将不同通道的S-parameter作为输入，可以使用不同的混合方法提高诊断性能下附加噪声水平的表现。这一结论得到了通过t-分布随机邻居embedding（t-SNE）维度减少视觉化的确认。
</details></li>
</ul>
<hr>
<h2 id="Epicure-Distilling-Sequence-Model-Predictions-into-Patterns"><a href="#Epicure-Distilling-Sequence-Model-Predictions-into-Patterns" class="headerlink" title="Epicure: Distilling Sequence Model Predictions into Patterns"></a>Epicure: Distilling Sequence Model Predictions into Patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08203">http://arxiv.org/abs/2308.08203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miltiadis Allamanis, Earl T. Barr</li>
<li>for: 用于生成高精度的函数名称和侦测异常函数名称</li>
<li>methods: 使用 Epicure 方法将模型预测结果转换为简单的几何模式</li>
<li>results: Epicure 方法可以对于预测函数名称和侦测异常函数名称 task 取得更高精度的结果，比起最佳模型预测结果高出 61% 以上。<details>
<summary>Abstract</summary>
Most machine learning models predict a probability distribution over concrete outputs and struggle to accurately predict names over high entropy sequence distributions. Here, we explore finding abstract, high-precision patterns intrinsic to these predictions in order to make abstract predictions that usefully capture rare sequences. In this short paper, we present Epicure, a method that distils the predictions of a sequence model, such as the output of beam search, into simple patterns. Epicure maps a model's predictions into a lattice that represents increasingly more general patterns that subsume the concrete model predictions.   On the tasks of predicting a descriptive name of a function given the source code of its body and detecting anomalous names given a function, we show that Epicure yields accurate naming patterns that match the ground truth more often compared to just the highest probability model prediction. For a false alarm rate of 10%, Epicure predicts patterns that match 61% more ground-truth names compared to the best model prediction, making Epicure well-suited for scenarios that require high precision.
</details>
<details>
<summary>摘要</summary>
大多数机器学习模型预测结果是一个概率分布，尤其是在高 entropy 序列分布时，它们很难准确预测名称。在这里，我们探索了找到Abstract高精度模式，以便使用这些模式来预测罕见序列。本文介绍了 Epicure 方法，它将序列模型预测结果映射到一个表示增加更一般模式的笛卡尔矩阵中。在函数的描述名称预测和异常名称检测任务上，我们显示了 Epicure 可以更准确地预测名称，相比于最佳模型预测。为了 false alarm rate 为 10%，Epicure 预测的模式与真实ground truth中的名称相匹配的情况比最佳模型预测多出了 61%。因此，Epicure 适用于需要高精度的场景。
</details></li>
</ul>
<hr>
<h2 id="DeSCo-Towards-Generalizable-and-Scalable-Deep-Subgraph-Counting"><a href="#DeSCo-Towards-Generalizable-and-Scalable-Deep-Subgraph-Counting" class="headerlink" title="DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting"></a>DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08198">http://arxiv.org/abs/2308.08198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyu Fu, Chiyue Wei, Yu Wang, Rex Ying<br>for: 这个研究是为了提出一个可扩展的神经网络架构，以便精确地预测查询 граф中的元素出现次数和位置。methods: 这个研究使用了一个新的专门分partition的技术，将大量目标 Graf divide 为小型邻接 Graph，以减少查询 граф中元素的 Count 的变化。然后，使用一个具有表现力的SUBGRAPH-based  hetereogeneous graph neural network 进行 Counting calculation。最后，使用learnable gates 进行 gossip propagation 以充分利用查询 Graf 中的 inductive biases。results: 这个研究在 eight 个真实世界数据集上进行了评估，与现有的神经网络方法相比，实现了137倍的mean squared error 的改善，同时保持了多项式时间复杂度。<details>
<summary>Abstract</summary>
Subgraph counting is the problem of counting the occurrences of a given query graph in a large target graph. Large-scale subgraph counting is useful in various domains, such as motif counting for social network analysis and loop counting for money laundering detection on transaction networks. Recently, to address the exponential runtime complexity of scalable subgraph counting, neural methods are proposed. However, existing neural counting approaches fall short in three aspects. Firstly, the counts of the same query can vary from zero to millions on different target graphs, posing a much larger challenge than most graph regression tasks. Secondly, current scalable graph neural networks have limited expressive power and fail to efficiently distinguish graphs in count prediction. Furthermore, existing neural approaches cannot predict the occurrence position of queries in the target graph.   Here we design DeSCo, a scalable neural deep subgraph counting pipeline, which aims to accurately predict the query count and occurrence position on any target graph after one-time training. Firstly, DeSCo uses a novel canonical partition and divides the large target graph into small neighborhood graphs. The technique greatly reduces the count variation while guaranteeing no missing or double-counting. Secondly, neighborhood counting uses an expressive subgraph-based heterogeneous graph neural network to accurately perform counting in each neighborhood. Finally, gossip propagation propagates neighborhood counts with learnable gates to harness the inductive biases of motif counts. DeSCo is evaluated on eight real-world datasets from various domains. It outperforms state-of-the-art neural methods with 137x improvement in the mean squared error of count prediction, while maintaining the polynomial runtime complexity.
</details>
<details>
<summary>摘要</summary>
大量子グラフ数えは、目标グラフ中の Given クエリー グラフの出现回数を数える问题です。大规模な子グラフ数えは、社会ネットワーク分析のモチーフ数えや、取引ネットワーク上の资金洗浄検出など、いくつかの领域で有用です。ただし、スケーラブルな子グラフ数えでは、问题の复雑さに対応するために、ニューラルな方法が提案されています。しかし、既存のニューラル カウンティング アプローチは、以下の3点で不足しています。1. 同じクエリーでは、ターゲット グラフによってカウントが0から数百万まで変化するため、大きな挑戦を提示します。2. 现在のスケーラブルなグラフニューラルネットワークは、クエリー カウントの效率的な予测をできません。3. 既存のニューラル アプローチは、ターゲット グラフ上のクエリーの出现位置を予测することができません。これらの问题を解决するために、我々はデスコ（DeSCo）というスケーラブルなニューラル ディープ サブグラフ カウンティング パイプラインを设计しました。デスコは、一度のトレーニングで任意のターゲット グラフ上のクエリー カウントと出现位置を正确に予测することができます。1. デスコでは、ターゲット グラフを小さな neighboorhood グラフに分割し、カウントのバラツキを大幅に削减します。2.  neighborhood カウンティングでは、heterogeneous graph neural network を使用して、各 neighboorhood でのカウントを正确に予测します。3. gossip propagation では、学习ゲートを使用して、适切なモチーフ カウントを导入します。デスコは、8つの実世界データセットから评価されました。その结果、状况 のあるニューラル メソッドに対して、137倍のmean squared error の改善を达成しました。また、既存のニューラル アプローチと同じように、ポリノミアルな时间コンプレックスを维持しています。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Explainable-AI-to-Analyze-Researchers’-Aspect-Based-Sentiment-about-ChatGPT"><a href="#Leveraging-Explainable-AI-to-Analyze-Researchers’-Aspect-Based-Sentiment-about-ChatGPT" class="headerlink" title="Leveraging Explainable AI to Analyze Researchers’ Aspect-Based Sentiment about ChatGPT"></a>Leveraging Explainable AI to Analyze Researchers’ Aspect-Based Sentiment about ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11001">http://arxiv.org/abs/2308.11001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shilpa Lakhanpal, Ajay Gupta, Rajeev Agrawal</li>
<li>for: 这篇论文的目的是分析研究者对ChatGPT的看法，以便更好地理解它的使用和发展。</li>
<li>methods: 该论文提出了一种使用可解释AI来进行方面基于情感分析的方法，以便在更新的 datasets 上进行分析。</li>
<li>results: 该论文通过实践示出了这种方法可以帮助扩展现有的状态艺术，并且在 longer text data 上进行有效的方面基于情感分析。<details>
<summary>Abstract</summary>
The groundbreaking invention of ChatGPT has triggered enormous discussion among users across all fields and domains. Among celebration around its various advantages, questions have been raised with regards to its correctness and ethics of its use. Efforts are already underway towards capturing user sentiments around it. But it begs the question as to how the research community is analyzing ChatGPT with regards to various aspects of its usage. It is this sentiment of the researchers that we analyze in our work. Since Aspect-Based Sentiment Analysis has usually only been applied on a few datasets, it gives limited success and that too only on short text data. We propose a methodology that uses Explainable AI to facilitate such analysis on research data. Our technique presents valuable insights into extending the state of the art of Aspect-Based Sentiment Analysis on newer datasets, where such analysis is not hampered by the length of the text data.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "The groundbreaking invention of ChatGPT has triggered enormous discussion among users across all fields and domains. Among celebration around its various advantages, questions have been raised with regards to its correctness and ethics of its use. Efforts are already underway towards capturing user sentiments around it. But it begs the question as to how the research community is analyzing ChatGPT with regards to various aspects of its usage. It is this sentiment of the researchers that we analyze in our work. Since Aspect-Based Sentiment Analysis has usually only been applied on a few datasets, it gives limited success and that too only on short text data. We propose a methodology that uses Explainable AI to facilitate such analysis on research data. Our technique presents valuable insights into extending the state of the art of Aspect-Based Sentiment Analysis on newer datasets, where such analysis is not hampered by the length of the text data." into Simplified Chinese.干货发明ChatGPT已经引发了各个领域和领导人的广泛的讨论。虽然欢快 celebrate its多种优点，但也提出了关于其正确性和使用道德问题的问题。尝试已经进行了捕捉用户情感的努力。但是，研究者如何分析ChatGPT在不同方面的使用仍然是一个问题。我们的工作是分析研究者对ChatGPT的感受。由于Aspect-Based Sentiment Analysis通常只能在一些数据集上进行，因此它具有有限的成功，只能处理短文本数据。我们提出了一种方法，使用可解释AI来实现这种分析在研究数据上。我们的技术可以提供对 newer datasets 的扩展state of the art的Aspect-Based Sentiment Analysis，不受文本数据的长度所限制。
</details></li>
</ul>
<hr>
<h2 id="Endogenous-Macrodynamics-in-Algorithmic-Recourse"><a href="#Endogenous-Macrodynamics-in-Algorithmic-Recourse" class="headerlink" title="Endogenous Macrodynamics in Algorithmic Recourse"></a>Endogenous Macrodynamics in Algorithmic Recourse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08187">http://arxiv.org/abs/2308.08187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pat-alt/endogenous-macrodynamics-in-algorithmic-recourse">https://github.com/pat-alt/endogenous-macrodynamics-in-algorithmic-recourse</a></li>
<li>paper_authors: Patrick Altmeyer, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, Cynthia C. S. Liem</li>
<li>for: 本文主要研究Counterfactual Explanations（CE）和Algorithmic Recourse（AR）在动态环境下的应用，以及这些技术在实际应用中对其他个体的影响。</li>
<li>methods: 本文使用了一种普遍的框架来描述现有的方法ologies，并证明了这些方法ologies忽略了一种隐藏的外部成本，只有在研究团队级别的幂等 dynamics 时才会表现出来。</li>
<li>results: 通过使用各种现有的counterfactual生成器和多种标准数据集，我们在实验中生成了大量的counterfactuals，并研究了这些counterfactuals对模型和领域的影响。我们发现，由于recourse的实现，可能会导致模型和领域的变化，这些变化可能会妨碍Algorithmic Recourse的应用。然而，我们提出了一些缓解这些问题的策略。我们的实验框架快速、开源，可以帮助研究人员更好地理解recourse的应用。<details>
<summary>Abstract</summary>
Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and opensourced.
</details>
<details>
<summary>摘要</summary>
现有的Counterfactual Explanations（CE）和Algorithmic Recourse（AR）研究主要关注单个个体在静止环境下：给定一个估计模型，目标是找到满足多种要求的有效counterfactuals。然而，这些counterfactuals对数据和模型演变的能力尚未得到了充分的研究。此外，很少有关于个体实施救济后他们对其他个体的影响的研究。我们通过这项工作，希望能够填补这一差。我们首先示出了现有的方法ologies可以总结为一个通用框架。然后，我们 argue that现有的框架不会考虑到救济实施过程中隐藏的外部成本，只有在研究救济过程的群体水平时才会发现。通过使用当今顶尖counterfactual生成器和多个标准数据集，我们生成了大量的counterfactuals，并研究其所导致的领域和模型变化。我们发现，引入的变化是足够大，可能会阻碍救济的应用。幸运的是，我们发现了多种缓解这些问题的策略。我们的救济动力学研究框架快速，开源。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Generic-Graph-Neural-Networks-via-Architecture-Compiler-Partition-Method-Co-Design"><a href="#Accelerating-Generic-Graph-Neural-Networks-via-Architecture-Compiler-Partition-Method-Co-Design" class="headerlink" title="Accelerating Generic Graph Neural Networks via Architecture, Compiler, Partition Method Co-Design"></a>Accelerating Generic Graph Neural Networks via Architecture, Compiler, Partition Method Co-Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08174">http://arxiv.org/abs/2308.08174</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwen Lu, Zhihui Zhang, Cong Guo, Jingwen Leng, Yangjie Zhou, Minyi Guo</li>
<li>for: 这个研究旨在开发高效和高性能的图形神经网络（GNNs）硬件加速器，以实现图形学习领域中的精确性提升。</li>
<li>methods: 这个研究使用了一些新的技术来解决GNN模型的两个基本挑战：一是GNN模型的带宽需求很高，二是GNN模型的多样性。这个研究使用了一种新的分区阶段Operator整合，以减少GNN模型的带宽需求；同时，这个研究也引入分区阶段多执行绪，以便同时处理图形分 partitions，并将不同的硬件资源分配给不同的执行绪。为了降低额外的On-chip memory，这个研究还提出了细化的图形分割。</li>
<li>results: 这个研究使用了 SwitchBlade 框架，包括编译器、图形分割器和硬件加速器，实现了对 NVIDIA V100 GPU 的平均速度提升为 1.85倍，和能源减少为 19.03倍。此外，SwitchBlade 还能够与现有的特殊适配器相比。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have shown significant accuracy improvements in a variety of graph learning domains, sparking considerable research interest. To translate these accuracy improvements into practical applications, it is essential to develop high-performance and efficient hardware acceleration for GNN models. However, designing GNN accelerators faces two fundamental challenges: the high bandwidth requirement of GNN models and the diversity of GNN models. Previous works have addressed the first challenge by using more expensive memory interfaces to achieve higher bandwidth. For the second challenge, existing works either support specific GNN models or have generic designs with poor hardware utilization.   In this work, we tackle both challenges simultaneously. First, we identify a new type of partition-level operator fusion, which we utilize to internally reduce the high bandwidth requirement of GNNs. Next, we introduce partition-level multi-threading to schedule the concurrent processing of graph partitions, utilizing different hardware resources. To further reduce the extra on-chip memory required by multi-threading, we propose fine-grained graph partitioning to generate denser graph partitions. Importantly, these three methods make no assumptions about the targeted GNN models, addressing the challenge of model variety. We implement these methods in a framework called SwitchBlade, consisting of a compiler, a graph partitioner, and a hardware accelerator. Our evaluation demonstrates that SwitchBlade achieves an average speedup of $1.85\times$ and energy savings of $19.03\times$ compared to the NVIDIA V100 GPU. Additionally, SwitchBlade delivers performance comparable to state-of-the-art specialized accelerators.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 在多种图学学问题上显示了重要的准确性改进，引起了广泛的研究兴趣。为将这些准确性改进应用于实际场景，必须开发高性能和高效的硬件加速器 для GNN 模型。然而，设计 GNN 加速器面临两个根本挑战：GNN 模型的带宽需求很高，以及 GNN 模型的多样性。previous works 通过使用更昂贵的内存接口来实现更高的带宽来解决第一个挑战。对于第二个挑战，现有的工作ether 支持特定 GNN 模型或者有通用的设计，但它们的硬件利用率很低。在这种情况下，我们同时解决了这两个挑战。首先，我们发现了一种新的分区级别的Operator融合方法，我们通过这种方法来减少 GNN 模型的带宽需求。然后，我们引入分区级别的多线程处理，以便同时处理不同的图分区，并使用不同的硬件资源。为了避免多线程处理所增加的额外的内存，我们提议使用细化的图分区来生成更密集的图分区。这三种方法不仅不假设目标 GNN 模型，而且可以同时解决多种 GNN 模型的问题。我们在 SwitchBlade 框架中实现了这三种方法， SwitchBlade 包括一个编译器、一个图分区器和一个硬件加速器。我们的评估表明，SwitchBlade 可以在 NVIDIA V100 GPU 上实现平均的速度提升为 1.85 倍，并且能够降低能耗量达 19.03 倍。此外，SwitchBlade 可以与现有的专门加速器相比，实现相似的性能。
</details></li>
</ul>
<hr>
<h2 id="Expressivity-of-Graph-Neural-Networks-Through-the-Lens-of-Adversarial-Robustness"><a href="#Expressivity-of-Graph-Neural-Networks-Through-the-Lens-of-Adversarial-Robustness" class="headerlink" title="Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness"></a>Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08173">http://arxiv.org/abs/2308.08173</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/francesco-campi/rob-subgraphs">https://github.com/francesco-campi/rob-subgraphs</a></li>
<li>paper_authors: Francesco Campi, Lukas Gosch, Tom Wollschläger, Yan Scholten, Stephan Günnemann</li>
<li>for: 这个论文探讨了图神经网络（GNNs）的对抗 robustness，并证明GNNs比传统的消息传递神经网络（MPNNs）更有力。</li>
<li>methods: 作者使用对抗 robustness作为一种工具，探讨GNNs的表达能力的限制。他们使用对抗攻击来测试GNNs的能力 counting specific subgraph patterns，并发展了高效的对抗攻击策略。</li>
<li>results: 研究发现，更强大的GNNs在小结构变化的情况下失去泛化能力，并且无法在非标准图上计数子结构。<details>
<summary>Abstract</summary>
We perform the first adversarial robustness study into Graph Neural Networks (GNNs) that are provably more powerful than traditional Message Passing Neural Networks (MPNNs). In particular, we use adversarial robustness as a tool to uncover a significant gap between their theoretically possible and empirically achieved expressive power. To do so, we focus on the ability of GNNs to count specific subgraph patterns, which is an established measure of expressivity, and extend the concept of adversarial robustness to this task. Based on this, we develop efficient adversarial attacks for subgraph counting and show that more powerful GNNs fail to generalize even to small perturbations to the graph's structure. Expanding on this, we show that such architectures also fail to count substructures on out-of-distribution graphs.
</details>
<details>
<summary>摘要</summary>
我们进行了首个对图 neural network (GNNs) 的敏感性研究，该研究表明 GNNs 比传统的讯息传递神经网络 (MPNNs) 更具潜力。具体来说，我们使用敏感性作为一个工具，对 GNNs 的表现进行探索，并发现了它们在实际上可以表达的表现和理论上可以表达的表现之间存在很大的差距。我们针对 GNNs 的子图计数能力进行了扩展，并发现了更强大的 GNNs 对小的结构变化进行了攻击，并且还无法处理非常力分布的图。
</details></li>
</ul>
<hr>
<h2 id="AATCT-IDS-A-Benchmark-Abdominal-Adipose-Tissue-CT-Image-Dataset-for-Image-Denoising-Semantic-Segmentation-and-Radiomics-Evaluation"><a href="#AATCT-IDS-A-Benchmark-Abdominal-Adipose-Tissue-CT-Image-Dataset-for-Image-Denoising-Semantic-Segmentation-and-Radiomics-Evaluation" class="headerlink" title="AATCT-IDS: A Benchmark Abdominal Adipose Tissue CT Image Dataset for Image Denoising, Semantic Segmentation, and Radiomics Evaluation"></a>AATCT-IDS: A Benchmark Abdominal Adipose Tissue CT Image Dataset for Image Denoising, Semantic Segmentation, and Radiomics Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08172">http://arxiv.org/abs/2308.08172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyu Ma, Chen Li, Tianming Du, Le Zhang, Dechao Tang, Deguo Ma, Shanchuan Huang, Yan Liu, Yihao Sun, Zhihao Chen, Jin Yuan, Qianqing Nie, Marcin Grzegorzek, Hongzan Sun</li>
<li>For: This paper is written to introduce and validate a new benchmark dataset for abdominal adipose tissue CT images, and to explore the potential of the dataset for different tasks such as image denoising, semantic segmentation, and radiomics.* Methods: The paper uses a benchmark dataset called AATTCT-IDS, which contains 13,732 raw CT slices and has been individually annotated for subcutaneous and visceral adipose tissue regions. The authors compare and analyze the performance of various methods on the dataset for different tasks.* Results: The results show that algorithms using a smoothing strategy perform better for image denoising, while methods like BM3D preserve the original image structure better. The segmentation results of adipose tissue by different models show different structural characteristics, and BiSeNet obtains segmentation results that are only slightly inferior to U-Net with the shortest training time. The radiomics study based on AATTCT-IDS reveals three adipose distributions in the subject population.Here’s the information in Simplified Chinese text:* For: 这篇论文是为了介绍和验证一个新的 Referenced dataset for abdominal adipose tissue CT images，并 explore这个dataset的多维特征以及其在不同任务中的潜在性。* Methods: 这篇论文使用一个名为AATTCT-IDS的 Referenced dataset，该dataset包含13,732个Raw CT slice，并且每个slice都被手动标注了脂肪组织区域。作者们对不同任务使用不同方法进行比较和分析。* Results: 结果表明使用平滑策略的算法在图像压缩中表现更好，而BM3D等方法能够更好地保持原始图像结构。不同模型的 segmentation 结果表明不同的结构特征，而BiSeNet等模型能够在最短训练时间内获得与U-Net的 segmentation 结果相似的结果。基于AATTCT-IDS的 radiomics 研究发现了脂肪分布的三种类型。<details>
<summary>Abstract</summary>
Methods: In this study, a benchmark \emph{Abdominal Adipose Tissue CT Image Dataset} (AATTCT-IDS) containing 300 subjects is prepared and published. AATTCT-IDS publics 13,732 raw CT slices, and the researchers individually annotate the subcutaneous and visceral adipose tissue regions of 3,213 of those slices that have the same slice distance to validate denoising methods, train semantic segmentation models, and study radiomics. For different tasks, this paper compares and analyzes the performance of various methods on AATTCT-IDS by combining the visualization results and evaluation data. Thus, verify the research potential of this data set in the above three types of tasks.   Results: In the comparative study of image denoising, algorithms using a smoothing strategy suppress mixed noise at the expense of image details and obtain better evaluation data. Methods such as BM3D preserve the original image structure better, although the evaluation data are slightly lower. The results show significant differences among them. In the comparative study of semantic segmentation of abdominal adipose tissue, the segmentation results of adipose tissue by each model show different structural characteristics. Among them, BiSeNet obtains segmentation results only slightly inferior to U-Net with the shortest training time and effectively separates small and isolated adipose tissue. In addition, the radiomics study based on AATTCT-IDS reveals three adipose distributions in the subject population.   Conclusion: AATTCT-IDS contains the ground truth of adipose tissue regions in abdominal CT slices. This open-source dataset can attract researchers to explore the multi-dimensional characteristics of abdominal adipose tissue and thus help physicians and patients in clinical practice. AATCT-IDS is freely published for non-commercial purpose at: \url{https://figshare.com/articles/dataset/AATTCT-IDS/23807256}.
</details>
<details>
<summary>摘要</summary>
方法：本研究使用了一个名为“腹部脂肪组织CT影像数据集”（AATTCT-IDS）的标准数据集，该数据集包含300名参与者，并公布了13,732个RAW CT slice的原始图像。研究人员ividually annotated 3,213个slice的脂肪组织区域，以验证去噪方法、训练semantic segmentation模型和研究 радиологи学。通过对不同任务的组合可视化结果和评估数据进行比较和分析，这个数据集的研究潜力得到了验证。结果：在图像去噪比较研究中，使用滤波策略的算法可以更好地降低杂噪，但是同时也会导致图像细节的产生。比如BM3D算法可以更好地保持原始图像结构，但评估数据略有下降。结果表明不同算法之间存在显著的差异。在脂肪组织分 segmentation研究中，BiSeNet模型可以在短时间内 obtian segmentation结果，并且可以有效地分离小型和隔离的脂肪组织。此外，基于AATTCT-IDS的 радиологи学研究发现了腹部脂肪组织中主要存在三种分布。结论：AATTCT-IDS包含了腹部CT影像中脂肪组织区域的真实图像。这个开源数据集可以吸引研究人员来探索腹部脂肪组织的多维特征，并帮助临床医生和病人。AATCT-IDS采用非商业用途发布，可以免费获取：https://figshare.com/articles/dataset/AATTCT-IDS/23807256。
</details></li>
</ul>
<hr>
<h2 id="A-Quantum-Approximation-Scheme-for-k-Means"><a href="#A-Quantum-Approximation-Scheme-for-k-Means" class="headerlink" title="A Quantum Approximation Scheme for k-Means"></a>A Quantum Approximation Scheme for k-Means</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08167">http://arxiv.org/abs/2308.08167</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ragesh Jaiswal</li>
<li>for: 这个论文的目的是解决经典k-means clustering问题，提供一种量子近似方案，可以在QRAM模型中实现，并且running time只具有 polynomial 幂级度的依赖关系。</li>
<li>methods: 这个量子算法使用了一种$(1+\varepsilon)$-近似方法，对于每个$\varepsilon&gt;0$，可以在QRAM数据结构上进行实现，并且running time为$\tilde{O}\left(2^{\tilde{O}\left(\frac{k}{\varepsilon}\right)} \eta^2 d\right)$。</li>
<li>results: 这个量子算法可以在高probability下输出一组$k$个中心点，使得$cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$，其中$C_{OPT}$是最优的$k$-中心点，$cost(.)$是标准的$k$-means成本函数（即点到最近中心点的平方距离之和），$\eta$是几何比（即最大距离到最小距离的比）。这是第一个具有polylogarithmic running time的量子算法，可以提供$(1+\varepsilon)$的证明近似保证。<details>
<summary>Abstract</summary>
We give a quantum approximation scheme (i.e., $(1 + \varepsilon)$-approximation for every $\varepsilon > 0$) for the classical $k$-means clustering problem in the QRAM model with a running time that has only polylogarithmic dependence on the number of data points. More specifically, given a dataset $V$ with $N$ points in $\mathbb{R}^d$ stored in QRAM data structure, our quantum algorithm runs in time $\tilde{O} \left( 2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ and with high probability outputs a set $C$ of $k$ centers such that $cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$. Here $C_{OPT}$ denotes the optimal $k$-centers, $cost(.)$ denotes the standard $k$-means cost function (i.e., the sum of the squared distance of points to the closest center), and $\eta$ is the aspect ratio (i.e., the ratio of maximum distance to minimum distance). This is the first quantum algorithm with a polylogarithmic running time that gives a provable approximation guarantee of $(1+\varepsilon)$ for the $k$-means problem. Also, unlike previous works on unsupervised learning, our quantum algorithm does not require quantum linear algebra subroutines and has a running time independent of parameters (e.g., condition number) that appear in such procedures.
</details>
<details>
<summary>摘要</summary>
我们提供了一种量子近似方案（即$(1 + \varepsilon)$-近似方案）来解决 классиical $k$-means归一化问题在QRAM模型中，并且running时间具有只带有多项式幂ilogarithmic（polylogarithmic）依赖于数据点的数量。更具体地说，给定一个数据集$V$包含$N$个点在$\mathbb{R}^d$中，我们的量子算法在时间 $\tilde{O} \left( 2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ 内运行，并且 WITH HIGH PROBABILITY输出一组 $C$ 的 $k$ 中心，使得 $cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$，其中 $C_{OPT}$ 表示最优的 $k$-中心，$cost(.)$ 表示标准 $k$-means 成本函数（即点到最近中心的平方距离的总和），而 $\eta$ 是最大距离到最小距离的比率（即 aspect ratio）。这是第一个具有 polylogarithmic 运行时间的量子算法，并且不需要量子线性代数子routines，运行时间与参数（例如 condition number）无关。Note:* "QRAM" stands for "Quantum Random Access Memory", which is a quantum analogue of classical random access memory.* "polylogarithmic" means the running time has a polynomial logarithmic dependence on the number of data points.* "condition number" refers to the ratio of the maximum distance to the minimum distance in the dataset.
</details></li>
</ul>
<hr>
<h2 id="PEvoLM-Protein-Sequence-Evolutionary-Information-Language-Model"><a href="#PEvoLM-Protein-Sequence-Evolutionary-Information-Language-Model" class="headerlink" title="PEvoLM: Protein Sequence Evolutionary Information Language Model"></a>PEvoLM: Protein Sequence Evolutionary Information Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08578">http://arxiv.org/abs/2308.08578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/issararab/pevolm">https://github.com/issararab/pevolm</a></li>
<li>paper_authors: Issar Arab</li>
<li>for: 本研究旨在提高protein序列数据库的搜索效率和质量，以及提高计算生物学和生物信息学中ML模型的性能。</li>
<li>methods: 本研究使用了一种基于自然语言处理的语言模型（ELMo），将蛋白质序列转换为数字Vector表示。研究还使用了PSSM的概念和传输学习，开发了一种新的双向语言模型（bi-LM），其中一个路径用于前向传输，另一个路径用于反向传输。</li>
<li>results: 研究发现，使用bi-LM可以在预测下一个氨基酸时同时学习蛋白质序列的演化信息，并且bi-LM的参数数量比原始ELMo少了四倍。同时，bi-LM在预测下一个氨基酸和PSSM中的概率分布方面也达到了比较高的性能。<details>
<summary>Abstract</summary>
With the exponential increase of the protein sequence databases over time, multiple-sequence alignment (MSA) methods, like PSI-BLAST, perform exhaustive and time-consuming database search to retrieve evolutionary information. The resulting position-specific scoring matrices (PSSMs) of such search engines represent a crucial input to many machine learning (ML) models in the field of bioinformatics and computational biology. A protein sequence is a collection of contiguous tokens or characters called amino acids (AAs). The analogy to natural language allowed us to exploit the recent advancements in the field of Natural Language Processing (NLP) and therefore transfer NLP state-of-the-art algorithms to bioinformatics. This research presents an Embedding Language Model (ELMo), converting a protein sequence to a numerical vector representation. While the original ELMo trained a 2-layer bidirectional Long Short-Term Memory (LSTMs) network following a two-path architecture, one for the forward and the second for the backward pass, by merging the idea of PSSMs with the concept of transfer-learning, this work introduces a novel bidirectional language model (bi-LM) with four times less free parameters and using rather a single path for both passes. The model was trained not only on predicting the next AA but also on the probability distribution of the next AA derived from similar, yet different sequences as summarized in a PSSM, simultaneously for multi-task learning, hence learning evolutionary information of protein sequences as well. The network architecture and the pre-trained model are made available as open source under the permissive MIT license on GitHub at https://github.com/issararab/PEvoLM.
</details>
<details>
<summary>摘要</summary>
随着蛋白序列数据库的不断增长，多重序列对 align (MSA) 方法，如 PSI-BLAST，在时间上进行极其耗时的数据库搜索，以获取演化信息。 resulting position-specific scoring matrices (PSSMs) 的搜索引擎表示了生物信息学和计算生物学领域中机器学习 (ML) 模型的关键输入。一个蛋白序列是一个连续的 tokens 或字符串，叫做氨基酸 (AA)。由于蛋白序列与自然语言之间的相似性，我们可以利用自然语言处理领域的最新进展，并将其转移到生物信息学中。本研究提出了 Embedding Language Model (ELMo)，将蛋白序列转换为数字向量表示。而原始 ELMo 使用了两层拟合长短时间记忆 (LSTMs) 网络，一个是向前的一个，另一个是向后的一个，通过将 PSSMs 的想法与传输学习的概念结合起来，这个工作提出了一种新的双向语言模型 (bi-LM)，具有四倍少的自由参数，使用单一路径来进行两个方向的传输。这个模型不仅在预测下一个 AA 上，还在 PSSM 中的概率分布上进行学习，同时进行多任务学习，因此学习蛋白序列的演化信息。模型的网络架构和预训练模型都在 GitHub 上公开，可以在 <https://github.com/issararab/PEvoLM> 获取。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-Controlled-Averaging-for-Federated-Learning-with-Communication-Compression"><a href="#Stochastic-Controlled-Averaging-for-Federated-Learning-with-Communication-Compression" class="headerlink" title="Stochastic Controlled Averaging for Federated Learning with Communication Compression"></a>Stochastic Controlled Averaging for Federated Learning with Communication Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08165">http://arxiv.org/abs/2308.08165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinmeng Huang, Ping Li, Xiaoyun Li</li>
<li>for: 降低 Federated Learning（FL）的通信负担，提高FL的效率和可扩展性。</li>
<li>methods: 提议一种更有效率和简化的Stochastic Controlled Averaging方法，并基于该方法提出两种压缩FL算法：SCALLION和SCAFCOM。这两种算法可以支持不偏向和偏向压缩，并且可以适应任意数据不同性和不偏向压缩。</li>
<li>results: 对比 existed 压缩FL算法，SCALLION和SCAFCOM可以减少通信和计算复杂度，并且可以与相应的全精度FL方法匹配或超越其性能。实验结果表明，SCALLION和SCAFCOM可以在相同的通信预算下提高FL的性能。<details>
<summary>Abstract</summary>
Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.   In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to support unbiased and biased compression, respectively. Both the proposed methods outperform the existing compressed FL methods in terms of communication and computation complexities. Moreover, SCALLION and SCAFCOM accommodates arbitrary data heterogeneity and do not make any additional assumptions on compression errors. Experiments show that SCALLION and SCAFCOM can match the performance of corresponding full-precision FL approaches with substantially reduced uplink communication, and outperform recent compressed FL methods under the same communication budget.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用压缩通信技术可以减少在空中传输的信息量，这已经在联合学习（Federated Learning，FL）中受到了广泛关注，因为它可以减轻FL的通信开销。然而，压缩通信会在FL中带来新的挑战，这是因为压缩通信会导致信息损害，并且FL的特点，如部分参与和数据不同化，会导致压缩通信的效果不可预测。虽然最近有些研究已经进行了，但是现有的方法并不能充分发挥性能。在这篇论文中，我们重新评估了一种基于渐进控制的概率平均法，并提出了一种更高效/简单的表述方式，可以减少上行通信成本的一半。基于这种实现方式，我们提出了两种压缩FL算法，即SCALLION和SCAFCOM，可以支持不偏和偏压缩。两种算法都能够超过现有的压缩FL方法，并且可以适应任意的数据不同化，不需要任何额外的压缩错误假设。实验表明，SCALLION和SCAFCOM可以与相应的全精度FL方法匹配性能，并且在同样的通信预算下表现更好。Note: Simplified Chinese is a simplified version of Chinese that is used in mainland China and Singapore. It is different from Traditional Chinese, which is used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="Characteristics-of-networks-generated-by-kernel-growing-neural-gas"><a href="#Characteristics-of-networks-generated-by-kernel-growing-neural-gas" class="headerlink" title="Characteristics of networks generated by kernel growing neural gas"></a>Characteristics of networks generated by kernel growing neural gas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08163">http://arxiv.org/abs/2308.08163</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kazuhisafujita/kernelgng">https://github.com/kazuhisafujita/kernelgng</a></li>
<li>paper_authors: Kazuhisa Fujita</li>
<li>for: 本研究旨在开发 kernel GNG，即基kernels的生长神经网络算法，并investigate kernel GNG生成的网络特性。</li>
<li>methods: 本研究使用了五种kernel，包括 Gaussian、Laplacian、Cauchy、 inverse multiquadric 和 log kernels，以mappingdataset到特征空间。</li>
<li>results: 研究发现，kernel GNG可以生成具有高度稠密度和高度连接度的网络，并且可以准确地捕捉dataset中的特征。<details>
<summary>Abstract</summary>
This research aims to develop kernel GNG, a kernelized version of the growing neural gas (GNG) algorithm, and to investigate the features of the networks generated by the kernel GNG. The GNG is an unsupervised artificial neural network that can transform a dataset into an undirected graph, thereby extracting the features of the dataset as a graph. The GNG is widely used in vector quantization, clustering, and 3D graphics. Kernel methods are often used to map a dataset to feature space, with support vector machines being the most prominent application. This paper introduces the kernel GNG approach and explores the characteristics of the networks generated by kernel GNG. Five kernels, including Gaussian, Laplacian, Cauchy, inverse multiquadric, and log kernels, are used in this study.
</details>
<details>
<summary>摘要</summary>
这个研究的目标是开发kernel GNG，即kernelized版本的增长神经气体（GNG）算法，并研究由kernel GNG生成的网络特征。GNG是一种无监督的人工神经网络，可以将数据集转换成无向图，从而提取数据集中的特征作为图。GNG广泛应用于 вектор化Quantization、归一化和3D图形。 kernel方法通常用于将数据集映射到特征空间，支持向量机器学习是最广泛应用的例子。这篇文章介绍了kernel GNG方法，并探索由kernel GNG生成的网络特征。本研究使用的五种kernels包括Gaussian、Laplacian、Cauchy、 inverse multiquadric和log kernel。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-Benchmark-for-Evaluating-Spatial-Misalignment-of-Prototypical-Parts-Explanations"><a href="#Interpretability-Benchmark-for-Evaluating-Spatial-Misalignment-of-Prototypical-Parts-Explanations" class="headerlink" title="Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations"></a>Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08162">http://arxiv.org/abs/2308.08162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikołaj Sacha, Bartosz Jura, Dawid Rymarczyk, Łukasz Struski, Jacek Tabor, Bartosz Zieliński</li>
<li>for: 提高parts-based网络的自我解释性</li>
<li>methods: 引入一个特有的解释性指标集和修复方法来纠正偏移</li>
<li>results: 通过实验研究，表明提出的指标集和修复方法能够有效纠正偏移，提高parts-based网络的解释性<details>
<summary>Abstract</summary>
Prototypical parts-based networks are becoming increasingly popular due to their faithful self-explanations. However, their similarity maps are calculated in the penultimate network layer. Therefore, the receptive field of the prototype activation region often depends on parts of the image outside this region, which can lead to misleading interpretations. We name this undesired behavior a spatial explanation misalignment and introduce an interpretability benchmark with a set of dedicated metrics for quantifying this phenomenon. In addition, we propose a method for misalignment compensation and apply it to existing state-of-the-art models. We show the expressiveness of our benchmark and the effectiveness of the proposed compensation methodology through extensive empirical studies.
</details>
<details>
<summary>摘要</summary>
弹性部件网络在现代计算机视觉识别领域中日益受欢迎，主要是因为它们的自我解释能力很强。然而，它们的相似度图在次末层网络层中计算，因此prototype activation区域的接收场景经常受到外部像区域的影响，这可能会导致误leading interpretations。我们称这为 espacial explanation misalignment，并提出了一个dedicated metrics集以量化这种现象。此外，我们也提出了一种修正方法，并将其应用到现有的state-of-the-art模型中。我们透过广泛的实验研究表明了我们的benchmark的表达能力和我们的修正方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Adversarial-Robustness-of-Compressed-Deep-Learning-Models"><a href="#Benchmarking-Adversarial-Robustness-of-Compressed-Deep-Learning-Models" class="headerlink" title="Benchmarking Adversarial Robustness of Compressed Deep Learning Models"></a>Benchmarking Adversarial Robustness of Compressed Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08160">http://arxiv.org/abs/2308.08160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brijesh Vora, Kartik Patwari, Syed Mahbub Hafiz, Zubair Shafiq, Chen-Nee Chuah</li>
<li>for: 本研究旨在探讨基础模型对各种攻击Input的抗性，以便更好地理解压缩模型对抗性的影响。</li>
<li>methods: 我们开发了一个多样化的攻击 benchmark，用于测试不同的攻击方法和常见深度神经网络模型。我们采用了优化的压缩策略，以保持准确性和性能。</li>
<li>results: 我们发现，压缩后的模型仍然保持了对攻击的抗性，而且拥有更好的泛化性、更高的性能和更快的执行速度。这表明，压缩模型不会对抗性造成负面影响。<details>
<summary>Abstract</summary>
The increasing size of Deep Neural Networks (DNNs) poses a pressing need for model compression, particularly when employed on resource constrained devices. Concurrently, the susceptibility of DNNs to adversarial attacks presents another significant hurdle. Despite substantial research on both model compression and adversarial robustness, their joint examination remains underexplored. Our study bridges this gap, seeking to understand the effect of adversarial inputs crafted for base models on their pruned versions. To examine this relationship, we have developed a comprehensive benchmark across diverse adversarial attacks and popular DNN models. We uniquely focus on models not previously exposed to adversarial training and apply pruning schemes optimized for accuracy and performance. Our findings reveal that while the benefits of pruning enhanced generalizability, compression, and faster inference times are preserved, adversarial robustness remains comparable to the base model. This suggests that model compression while offering its unique advantages, does not undermine adversarial robustness.
</details>
<details>
<summary>摘要</summary>
随着深度神经网络（DNN）的尺度不断增大，需要进行模型压缩，特别是在资源有限的设备上使用。同时，DNN受到攻击者的攻击也成为一个重要的障碍。虽然关于模型压缩和攻击鲁棒性的研究已经进行了大量的工作，但是它们之间的联系还没有得到充分探讨。我们的研究尝试填补这个空白，探索攻击基本模型的输入对其压缩版本的影响。为此，我们开发了一个包括多种攻击和各种流行的DNN模型的完整的benchmark。我们独特地将注意力集中在没有接受过攻击训练的模型上，并应用优化的减少方案以保持准确性和性能。我们的发现表明，即使使用压缩，模型的总体鲁棒性仍然保持不变，这表明模型压缩不会对鲁棒性产生负面影响。这表明，模型压缩可以提供独特的优势，而不会对鲁棒性产生负面影响。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Imputation-Model-for-Missing-Not-At-Random-Data"><a href="#Deep-Generative-Imputation-Model-for-Missing-Not-At-Random-Data" class="headerlink" title="Deep Generative Imputation Model for Missing Not At Random Data"></a>Deep Generative Imputation Model for Missing Not At Random Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08158">http://arxiv.org/abs/2308.08158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialei Chen, Yuanbo Xu, Pengyang Wang, Yongjian Yang</li>
<li>for: 强调处理真实世界中存在缺失的数据，而不是模拟MCAR的缺失机制。</li>
<li>methods: 提出了一种基于joint probability decomposition的generative模型特有的方法，并在latent空间中处理真实世界中的缺失机制。</li>
<li>results: 对比state-of-the-art基elines，GNR模型在RMSE指标上平均提高9.9%至18.8%，并且总是在mask重建精度方面得到更好的结果。<details>
<summary>Abstract</summary>
Data analysis usually suffers from the Missing Not At Random (MNAR) problem, where the cause of the value missing is not fully observed. Compared to the naive Missing Completely At Random (MCAR) problem, it is more in line with the realistic scenario whereas more complex and challenging. Existing statistical methods model the MNAR mechanism by different decomposition of the joint distribution of the complete data and the missing mask. But we empirically find that directly incorporating these statistical methods into deep generative models is sub-optimal. Specifically, it would neglect the confidence of the reconstructed mask during the MNAR imputation process, which leads to insufficient information extraction and less-guaranteed imputation quality. In this paper, we revisit the MNAR problem from a novel perspective that the complete data and missing mask are two modalities of incomplete data on an equal footing. Along with this line, we put forward a generative-model-specific joint probability decomposition method, conjunction model, to represent the distributions of two modalities in parallel and extract sufficient information from both complete data and missing mask. Taking a step further, we exploit a deep generative imputation model, namely GNR, to process the real-world missing mechanism in the latent space and concurrently impute the incomplete data and reconstruct the missing mask. The experimental results show that our GNR surpasses state-of-the-art MNAR baselines with significant margins (averagely improved from 9.9% to 18.8% in RMSE) and always gives a better mask reconstruction accuracy which makes the imputation more principle.
</details>
<details>
<summary>摘要</summary>
通常情况下，数据分析会面临缺失不够权（MNAR）问题，其中数据缺失的原因不能全面观察。与完全随机缺失（MCAR）问题相比，MNAR问题更加真实和复杂。现有的统计方法模型了MNAR机制的各种分解方法，但我们发现直接将这些统计方法 integrate into深度生成模型是不优化的。具体来说，这会忽略恢复 маска的信任度 during MNAR 恢复过程，导致信息抽取不充分和缺失补做质量不够保障。在这篇论文中，我们从一种新的视角重新审视了MNAR问题，即完整数据和缺失数据是两种不同的杂态数据模式。遵循这种思路，我们提出了一种生成模型特有的联合概率分解方法，即并联模型，用于同时表征两种模式的分布。这种方法可以从两种模式中提取足够的信息，并且可以在缺失数据和恢复 маска之间进行共同补做。进一步地，我们利用深度生成补做模型，即GNR，来处理实际世界中的缺失机制，并同时补做缺失数据和恢复 маска。实验结果显示，我们的GNR在MNAR基线上显著提高了性能（平均提高9.9%到18.8%），并且总是提供更好的恢复率，这使得补做更符合原理。
</details></li>
</ul>
<hr>
<h2 id="Sarcasm-Detection-in-a-Disaster-Context"><a href="#Sarcasm-Detection-in-a-Disaster-Context" class="headerlink" title="Sarcasm Detection in a Disaster Context"></a>Sarcasm Detection in a Disaster Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08156">http://arxiv.org/abs/2308.08156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiberiu Sosea, Junyi Jessy Li, Cornelia Caragea</li>
<li>for: 这个论文是为了研究自然灾害发生时人们在社交媒体平台上使用的讲话方式，以及如何使用先进的自然语言处理技术来理解这种讲话方式。</li>
<li>methods: 该论文使用了一个名为HurricaneSARC的数据集，该数据集包含15,000条涉及讲话的报道，并使用了预训练的语言模型进行讲话检测。</li>
<li>results: 该论文的最佳模型在HurricaneSARC数据集上取得了0.70的F1分，并且通过中间任务转移学习可以提高模型的性能。<details>
<summary>Abstract</summary>
During natural disasters, people often use social media platforms such as Twitter to ask for help, to provide information about the disaster situation, or to express contempt about the unfolding event or public policies and guidelines. This contempt is in some cases expressed as sarcasm or irony. Understanding this form of speech in a disaster-centric context is essential to improving natural language understanding of disaster-related tweets. In this paper, we introduce HurricaneSARC, a dataset of 15,000 tweets annotated for intended sarcasm, and provide a comprehensive investigation of sarcasm detection using pre-trained language models. Our best model is able to obtain as much as 0.70 F1 on our dataset. We also demonstrate that the performance on HurricaneSARC can be improved by leveraging intermediate task transfer learning. We release our data and code at https://github.com/tsosea2/HurricaneSarc.
</details>
<details>
<summary>摘要</summary>
在自然灾害事件中，人们常利用社交媒体平台如推特，请求帮助、提供灾害情况信息或表达对事件或公共政策的负面 sentiment。这种语言形式在灾害Context中是非常重要的，以提高自然语言理解灾害相关的推文。在这篇论文中，我们介绍了风暴SARC数据集，包含15000条推文，并进行了 pré-trained语言模型的全面研究。我们的最佳模型在我们的数据集上可以获得0.70的F1分。我们还证明了在HurricaneSARC上进行中间任务传承学习可以提高性能。我们将数据和代码发布在https://github.com/tsosea2/HurricaneSarc上。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Topological-Ordering-with-Conditional-Independence-Test-for-Limited-Time-Series"><a href="#Hierarchical-Topological-Ordering-with-Conditional-Independence-Test-for-Limited-Time-Series" class="headerlink" title="Hierarchical Topological Ordering with Conditional Independence Test for Limited Time Series"></a>Hierarchical Topological Ordering with Conditional Independence Test for Limited Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08148">http://arxiv.org/abs/2308.08148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anpeng Wu, Haoxuan Li, Kun Kuang, Keli Zhang, Fei Wu</li>
<li>For: This paper aims to improve the process of learning directed acyclic graphs (DAGs) to identify causal relations in observational data.* Methods: The proposed method, called HT-CIT, incorporates limited time series data and conditional instrumental variables to identify descendant nodes for each variable. The algorithm uses a hierarchical topological ordering approach with a conditional independence test to efficiently learn sparse DAGs with a smaller search space.* Results: The proposed HT-CIT algorithm is shown to be superior to other popular approaches through empirical results from synthetic and real-world datasets, with a significant reduction in the number of edges that need to be pruned.<details>
<summary>Abstract</summary>
Learning directed acyclic graphs (DAGs) to identify causal relations underlying observational data is crucial but also poses significant challenges. Recently, topology-based methods have emerged as a two-step approach to discovering DAGs by first learning the topological ordering of variables and then eliminating redundant edges, while ensuring that the graph remains acyclic. However, one limitation is that these methods would generate numerous spurious edges that require subsequent pruning. To overcome this limitation, in this paper, we propose an improvement to topology-based methods by introducing limited time series data, consisting of only two cross-sectional records that need not be adjacent in time and are subject to flexible timing. By incorporating conditional instrumental variables as exogenous interventions, we aim to identify descendant nodes for each variable. Following this line, we propose a hierarchical topological ordering algorithm with conditional independence test (HT-CIT), which enables the efficient learning of sparse DAGs with a smaller search space compared to other popular approaches. The HT-CIT algorithm greatly reduces the number of edges that need to be pruned. Empirical results from synthetic and real-world datasets demonstrate the superiority of the proposed HT-CIT algorithm.
</details>
<details>
<summary>摘要</summary>
To overcome this limitation, this paper proposes an improvement to topology-based methods by incorporating limited time series data, consisting of only two cross-sectional records that do not need to be adjacent in time and are subject to flexible timing. By using conditional instrumental variables as exogenous interventions, we aim to identify descendant nodes for each variable.We propose a hierarchical topological ordering algorithm with conditional independence tests (HT-CIT), which enables the efficient learning of sparse DAGs with a smaller search space compared to other popular approaches. The HT-CIT algorithm greatly reduces the number of edges that need to be pruned. Empirical results from synthetic and real-world datasets demonstrate the superiority of the proposed HT-CIT algorithm.
</details></li>
</ul>
<hr>
<h2 id="Online-Control-for-Linear-Dynamics-A-Data-Driven-Approach"><a href="#Online-Control-for-Linear-Dynamics-A-Data-Driven-Approach" class="headerlink" title="Online Control for Linear Dynamics: A Data-Driven Approach"></a>Online Control for Linear Dynamics: A Data-Driven Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08138">http://arxiv.org/abs/2308.08138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zishun Liu, Yongxin Chen</li>
<li>for: 本文考虑了一个在线控制问题，其中系统动态不知道，干扰 bounded，并且存在敌对成本。</li>
<li>methods: 我们提出了一种数据驱动策略，以减少控制器的违和。与模型基于方法不同，我们的算法不需要identify系统模型，而是使用一个干净的轨迹来计算干扰的积累，并使用我们设计的积累干扰控制器来做决策，其参数通过在线梯度下降更新。</li>
<li>results: 我们证明了我们的算法的违和是$\mathcal{O}(\sqrt{T})$，这意味着其性能与模型基于方法相当。<details>
<summary>Abstract</summary>
This paper considers an online control problem over a linear time-invariant system with unknown dynamics, bounded disturbance, and adversarial cost. We propose a data-driven strategy to reduce the regret of the controller. Unlike model-based methods, our algorithm does not identify the system model, instead, it leverages a single noise-free trajectory to calculate the accumulation of disturbance and makes decisions using the accumulated disturbance action controller we design, whose parameters are updated by online gradient descent. We prove that the regret of our algorithm is $\mathcal{O}(\sqrt{T})$ under mild assumptions, suggesting that its performance is on par with model-based methods.
</details>
<details>
<summary>摘要</summary>
这篇论文研究了一个在线控制问题，其中系统为线性时间不变的系统，动力不确定、干扰bounded和敌意成本存在。我们提出了一种数据驱动策略，以减少控制器的后悔。不同于模型基于方法，我们的算法不需要确定系统模型，而是利用干扰自由的一个轨迹来计算干扰的积累，并使用我们设计的积累干扰控制器来做决策，该控制器的参数通过在线梯度下降更新。我们证明了我们的算法的后悔是 $\mathcal{O}(\sqrt{T})$ 的，这表明它的性能与模型基于方法相当。
</details></li>
</ul>
<hr>
<h2 id="Microstructure-Empowered-Stock-Factor-Extraction-and-Utilization"><a href="#Microstructure-Empowered-Stock-Factor-Extraction-and-Utilization" class="headerlink" title="Microstructure-Empowered Stock Factor Extraction and Utilization"></a>Microstructure-Empowered Stock Factor Extraction and Utilization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08135">http://arxiv.org/abs/2308.08135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xianfeng Jiao, Zizhong Li, Chang Xu, Yang Liu, Weiqing Liu, Jiang Bian</li>
<li>for: 高频量股票投资是股票投资中的一个关键方面，order flow数据在这方面具有关键性，因为它提供了最详细的信息，包括全部的订单书和交易记录。</li>
<li>methods: 我们提出了一种新的框架，用于从order flow数据中提取有用的因素，并且可以在不同的粒度和enario下进行多种下游任务。我们的方法包括Context Encoder和Factor Extractor。Context Encoder使得当前订单流数据段的上下文得到嵌入，包括预期和实际市场状态。Factor Extractor使用不supervised学习方法，从订单流数据中选择最重要的信号，这些信号与大多数信号进行分割。</li>
<li>results: 我们的提出的框架可以高效处理一年的股票订单流数据，并且可以在不同的enario下应用。我们的方法可以提取更好的因素，从而提高股票趋势预测和订单执行任务的精度。<details>
<summary>Abstract</summary>
High-frequency quantitative investment is a crucial aspect of stock investment. Notably, order flow data plays a critical role as it provides the most detailed level of information among high-frequency trading data, including comprehensive data from the order book and transaction records at the tick level. The order flow data is extremely valuable for market analysis as it equips traders with essential insights for making informed decisions. However, extracting and effectively utilizing order flow data present challenges due to the large volume of data involved and the limitations of traditional factor mining techniques, which are primarily designed for coarser-level stock data. To address these challenges, we propose a novel framework that aims to effectively extract essential factors from order flow data for diverse downstream tasks across different granularities and scenarios. Our method consists of a Context Encoder and an Factor Extractor. The Context Encoder learns an embedding for the current order flow data segment's context by considering both the expected and actual market state. In addition, the Factor Extractor uses unsupervised learning methods to select such important signals that are most distinct from the majority within the given context. The extracted factors are then utilized for downstream tasks. In empirical studies, our proposed framework efficiently handles an entire year of stock order flow data across diverse scenarios, offering a broader range of applications compared to existing tick-level approaches that are limited to only a few days of stock data. We demonstrate that our method extracts superior factors from order flow data, enabling significant improvement for stock trend prediction and order execution tasks at the second and minute level.
</details>
<details>
<summary>摘要</summary>
高频量质投资是股票投资中一个关键方面。突出重要的是，订单流数据在高频投资中扮演了关键角色，因为它提供了最详细的信息，包括订单书和交易记录的细节。订单流数据对市场分析非常有价值，因为它为投资者提供了关键的信息，帮助他们做出了 Informed Decisions。然而，提取并有效利用订单流数据具有挑战，因为涉及的数据量很大，而且传统的因子挖掘技术主要针对粗细级股票数据。为解决这些挑战，我们提出了一种新的框架，旨在有效地从订单流数据中提取关键因子，用于不同的下游任务和不同的场景。我们的方法包括上下文编码器和因子挖掘器。上下文编码器通过考虑当前订单流数据段的预期和实际市场状况，学习订单流数据段的上下文嵌入。此外，因子挖掘器使用无监督学习方法，选择订单流数据中最为特异的信号，以便在给定的上下文中提取关键因子。提取的因子后续用于下游任务。我们的方法可以有效处理一年的股票订单流数据，在多种场景下提供更广泛的应用场景，与现有的tick级 approached有限制，只能处理几天的股票数据。我们的方法提取了订单流数据中的优秀因子，使得股票趋势预测和订单执行任务在秒和分级别得到了显著改进。
</details></li>
</ul>
<hr>
<h2 id="Is-Self-Supervised-Pretraining-Good-for-Extrapolation-in-Molecular-Property-Prediction"><a href="#Is-Self-Supervised-Pretraining-Good-for-Extrapolation-in-Molecular-Property-Prediction" class="headerlink" title="Is Self-Supervised Pretraining Good for Extrapolation in Molecular Property Prediction?"></a>Is Self-Supervised Pretraining Good for Extrapolation in Molecular Property Prediction?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08129">http://arxiv.org/abs/2308.08129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shun Takashige, Masatoshi Hanai, Toyotaro Suzumura, Limin Wang, Kenjiro Taura</li>
<li>for: 本研究旨在探讨如何使用自动学习技术提高材料性能预测的准确性，特别是在材料性能预测中的推断问题上。</li>
<li>methods: 本研究使用了自动学习模型，首先通过自然语言处理方法对无标签数据进行自我预训练，然后对标签数据进行目标任务训练。</li>
<li>results: 研究发现，通过自我预训练，模型可以更好地捕捉材料的相对性质趋势，从而提高推断性能。<details>
<summary>Abstract</summary>
The prediction of material properties plays a crucial role in the development and discovery of materials in diverse applications, such as batteries, semiconductors, catalysts, and pharmaceuticals. Recently, there has been a growing interest in employing data-driven approaches by using machine learning technologies, in combination with conventional theoretical calculations. In material science, the prediction of unobserved values, commonly referred to as extrapolation, is particularly critical for property prediction as it enables researchers to gain insight into materials beyond the limits of available data. However, even with the recent advancements in powerful machine learning models, accurate extrapolation is still widely recognized as a significantly challenging problem. On the other hand, self-supervised pretraining is a machine learning technique where a model is first trained on unlabeled data using relatively simple pretext tasks before being trained on labeled data for target tasks. As self-supervised pretraining can effectively utilize material data without observed property values, it has the potential to improve the model's extrapolation ability. In this paper, we clarify how such self-supervised pretraining can enhance extrapolation performance.We propose an experimental framework for the demonstration and empirically reveal that while models were unable to accurately extrapolate absolute property values, self-supervised pretraining enables them to learn relative tendencies of unobserved property values and improve extrapolation performance.
</details>
<details>
<summary>摘要</summary>
Material 属性预测在材料发展和发现中扮演了关键角色，如电池、半导体、催化剂和药物等应用中。最近，有一个增长的兴趣是通过使用机器学习技术，与传统的理论计算相结合来使用数据驱动方法。在材料科学中，预测未观测值（extrapolation）是特别重要的，因为它允许研究人员对材料进行深入的研究，超出可用数据的限制。然而，即使最近的高能机器学习模型，准确的� extrapolation 仍被广泛认为是一个非常困难的问题。自我超vised pretraining 是一种机器学习技术，其中一个模型首先在无标签数据上使用相对简单的预文任务进行训练，然后在标签数据上进行目标任务的训练。由于自我超vised pretraining 可以充分利用材料数据不包含观测值，因此它有可能提高模型的� extrapolation 能力。在这篇文章中，我们解释了如何使用自我超vised pretraining 提高� extrapolation 性能。我们提出了一种实验框架，并经验表明，虽然模型无法准确地 extrapolate 绝对属性值，但自我超vised pretraining 使得它们学习了未观测值的相对趋势，并提高了� extrapolation 性能。
</details></li>
</ul>
<hr>
<h2 id="How-to-Mask-in-Error-Correction-Code-Transformer-Systematic-and-Double-Masking"><a href="#How-to-Mask-in-Error-Correction-Code-Transformer-Systematic-and-Double-Masking" class="headerlink" title="How to Mask in Error Correction Code Transformer: Systematic and Double Masking"></a>How to Mask in Error Correction Code Transformer: Systematic and Double Masking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08128">http://arxiv.org/abs/2308.08128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seong-Joon Park, Hee-Youl Kwak, Sang-Hyo Kim, Sunghwan Kim, Yongjune Kim, Jong-Seon No</li>
<li>for: 这个论文主要是研究一种基于神经网络的编码器，以提高错误修复码（ECC）的性能。</li>
<li>methods: 这个论文提出了两种新的方法来提高错误修复码编码器（ECCT）的性能。其中一种是基于系统编码技术的新的面Masking矩阵，它可以提高性能并降低计算复杂度。另一种是一种新的双面Masked ECCT架构，它使用两个不同的面矩阵在并行方式中学习码word比特之间的关系。</li>
<li>results: 对于ECCT，提出的两种方法都得到了较好的效果。特别是，使用新的面Masking矩阵可以提高性能，而使用双面Masked ECCT架构可以学习更多的码word比特之间的关系，从而提高decoding性能。<details>
<summary>Abstract</summary>
In communication and storage systems, error correction codes (ECCs) are pivotal in ensuring data reliability. As deep learning's applicability has broadened across diverse domains, there is a growing research focus on neural network-based decoders that outperform traditional decoding algorithms. Among these neural decoders, Error Correction Code Transformer (ECCT) has achieved the state-of-the-art performance, outperforming other methods by large margins. To further enhance the performance of ECCT, we propose two novel methods. First, leveraging the systematic encoding technique of ECCs, we introduce a new masking matrix for ECCT, aiming to improve the performance and reduce the computational complexity. Second, we propose a novel transformer architecture of ECCT called a double-masked ECCT. This architecture employs two different mask matrices in a parallel manner to learn more diverse features of the relationship between codeword bits in the masked self-attention blocks. Extensive simulation results show that the proposed double-masked ECCT outperforms the conventional ECCT, achieving the state-of-the-art decoding performance with significant margins.
</details>
<details>
<summary>摘要</summary>
在通信和存储系统中，错误修复码（ECC）是确保数据可靠性的关键。随着深度学习在不同领域的应用积极扩大，关注 neural network 基于的解码算法在 ECC 中的研究也在不断增长。其中，Error Correction Code Transformer（ECCT）已经实现了最佳性能，比其他方法的性能优势较大。为了进一步提高 ECCT 的性能，我们提出了两种新的方法。首先，利用 ECC 的系统编码技术，我们引入了一个新的遮盲矩阵，以提高性能并降低计算复杂度。其次，我们提出了一种新的 ECCT 架构，即双遮盲 ECCT，该架构在并行方式中使用两个不同的遮盲矩阵来学习码word 位 bits 之间的更多多样性的关系。我们对 ECCT 进行了广泛的实验，结果显示，提出的双遮盲 ECCT 能够超越传统 ECCT，实现最佳解码性能，并且具有显著的性能优势。
</details></li>
</ul>
<hr>
<h2 id="S-Mixup-Structural-Mixup-for-Graph-Neural-Networks"><a href="#S-Mixup-Structural-Mixup-for-Graph-Neural-Networks" class="headerlink" title="S-Mixup: Structural Mixup for Graph Neural Networks"></a>S-Mixup: Structural Mixup for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08097">http://arxiv.org/abs/2308.08097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sukwonyun/s-mixup">https://github.com/sukwonyun/s-mixup</a></li>
<li>paper_authors: Junghurn Kim, Sukwon Yun, Chanyoung Park</li>
<li>for: 本研究探讨了应用mixup技术在图像上的扩展，尤其是在节点分类任务上。</li>
<li>methods: 本文提出了一种新的结构mixup（S-Mixup），具体来说是根据图像中的结构信息来混合节点。S-Mixup使用图像神经网络（GNN）分类器来获取 pseudo-标签 для没有标签的节点，并使用这些标签作为混合池的组合标准。此外，我们还提出了基于GNN训练的边梯度选择策略，用于选择与混合节点相连的边。</li>
<li>results: 经过广泛的实验表明，S-Mixup可以提高GNN的Robustness和泛化性，尤其是在不同类型的图像中。<details>
<summary>Abstract</summary>
Existing studies for applying the mixup technique on graphs mainly focus on graph classification tasks, while the research in node classification is still under-explored. In this paper, we propose a novel mixup augmentation for node classification called Structural Mixup (S-Mixup). The core idea is to take into account the structural information while mixing nodes. Specifically, S-Mixup obtains pseudo-labels for unlabeled nodes in a graph along with their prediction confidence via a Graph Neural Network (GNN) classifier. These serve as the criteria for the composition of the mixup pool for both inter and intra-class mixups. Furthermore, we utilize the edge gradient obtained from the GNN training and propose a gradient-based edge selection strategy for selecting edges to be attached to the nodes generated by the mixup. Through extensive experiments on real-world benchmark datasets, we demonstrate the effectiveness of S-Mixup evaluated on the node classification task. We observe that S-Mixup enhances the robustness and generalization performance of GNNs, especially in heterophilous situations. The source code of S-Mixup can be found at \url{https://github.com/SukwonYun/S-Mixup}
</details>
<details>
<summary>摘要</summary>
先前的研究主要集中在图像分类任务上应用mixup技术，而节点分类任务的研究仍然尚未得到充分的探索。在这篇论文中，我们提出了一种新的结构强化mixup修饰（S-Mixup）。其核心思想是在混合节点时考虑结构信息。具体来说，S-Mixup通过一个图 neural network（GNN）分类器获得未标注节点的 pseudo-标签和其预测信心。这些服务为混合池的组合的标准。此外，我们利用GNN训练中的边梯度并提出了一种基于边梯度的边选择策略，用于选择混合 Pool 中连接到生成的节点的边。经过了实际的实验，我们证明了S-Mixup可以提高GNN的可靠性和泛化性，特别是在不同类型的情况下。S-Mixup的源代码可以在 GitHub上找到：https://github.com/SukwonYun/S-Mixup。
</details></li>
</ul>
<hr>
<h2 id="Safety-Filter-Design-for-Neural-Network-Systems-via-Convex-Optimization"><a href="#Safety-Filter-Design-for-Neural-Network-Systems-via-Convex-Optimization" class="headerlink" title="Safety Filter Design for Neural Network Systems via Convex Optimization"></a>Safety Filter Design for Neural Network Systems via Convex Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08086">http://arxiv.org/abs/2308.08086</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shaoruchen/nn-system-psf">https://github.com/shaoruchen/nn-system-psf</a></li>
<li>paper_authors: Shaoru Chen, Kong Yao Chee, Nikolai Matni, M. Ani Hsieh, George J. Pappas</li>
<li>for: 这篇论文旨在提出一种基于凸优化的安全筛选方法，以确保神经网络系统在面对扰动时能够保持安全。</li>
<li>methods: 该方法首先使用神经网络验证工具来过度估算神经网络动态，然后通过稳定LPV搜索法找到一个能够保证约束满足的控制器。</li>
<li>results: 数值实验表明，该方法可以有效地确保神经网络系统在面对扰动时的安全性。<details>
<summary>Abstract</summary>
With the increase in data availability, it has been widely demonstrated that neural networks (NN) can capture complex system dynamics precisely in a data-driven manner. However, the architectural complexity and nonlinearity of the NNs make it challenging to synthesize a provably safe controller. In this work, we propose a novel safety filter that relies on convex optimization to ensure safety for a NN system, subject to additive disturbances that are capable of capturing modeling errors. Our approach leverages tools from NN verification to over-approximate NN dynamics with a set of linear bounds, followed by an application of robust linear MPC to search for controllers that can guarantee robust constraint satisfaction. We demonstrate the efficacy of the proposed framework numerically on a nonlinear pendulum system.
</details>
<details>
<summary>摘要</summary>
随着数据的增加，已经广泛证明了神经网络（NN）可以在数据驱动方式下准确捕捉复杂系统动态。然而，神经网络的建筑复杂性和非线性使得Synthesizing a provably safe controller是一项挑战。在这种情况下，我们提出了一种新的安全筛选器，该筛选器基于凸优化来确保神经网络系统的安全性，对于带有添加干扰的系统。我们的方法利用了神经网络验证工具来过度估算神经网络动态，然后通过Robust linear MPC来搜索能够保证约束满足的控制器。我们通过数值方法示出了我们的框架的有效性，并且在非线性挠杆系统上进行了实验。
</details></li>
</ul>
<hr>
<h2 id="Rigid-Transformations-for-Stabilized-Lower-Dimensional-Space-to-Support-Subsurface-Uncertainty-Quantification-and-Interpretation"><a href="#Rigid-Transformations-for-Stabilized-Lower-Dimensional-Space-to-Support-Subsurface-Uncertainty-Quantification-and-Interpretation" class="headerlink" title="Rigid Transformations for Stabilized Lower Dimensional Space to Support Subsurface Uncertainty Quantification and Interpretation"></a>Rigid Transformations for Stabilized Lower Dimensional Space to Support Subsurface Uncertainty Quantification and Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08079">http://arxiv.org/abs/2308.08079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ademide O. Mabadeje, Michael J. Pyrcz<br>for:这篇论文主要是为了解决隐藏层数据的维度减少问题，以提高地球科学和能源资源工程中的数据分析和机器学习过程中的重复性和比较性。methods:这篇论文使用了非线性维度减少（NDR）方法，尤其是多元维度减少（MDS）方法，以处理隐藏层数据的维度减少问题。它们的缺点是存在不稳定的唯一解，而且无法扩展到外样点（OOSP）。为了解决这些问题，该论文提出了一种稳定的、包含OOSP的隐藏层数据表示方法。results:该论文通过使用固定变换、计算MDS输入不同性矩阵和应用多个实现来保证变换不变性，并将OOSP纳入到数据表示中。该方法使用了 convex hull 算法和loss函数和 норamlized stress 来衡量扭曲。与Synthetic数据、不同距离度量和实际的DUVERNAY formación 井井相比，结果证明了该方法的有效性。此外，提出的“压缩率”（SR）指标，可以提供有关不确定性的信息，对于数据分析和推理分析是有利的。因此，该工作流程提出了在NDR中提高重复性和比较性的可能性。<details>
<summary>Abstract</summary>
Subsurface datasets inherently possess big data characteristics such as vast volume, diverse features, and high sampling speeds, further compounded by the curse of dimensionality from various physical, engineering, and geological inputs. Among the existing dimensionality reduction (DR) methods, nonlinear dimensionality reduction (NDR) methods, especially Metric-multidimensional scaling (MDS), are preferred for subsurface datasets due to their inherent complexity. While MDS retains intrinsic data structure and quantifies uncertainty, its limitations include unstabilized unique solutions invariant to Euclidean transformations and an absence of out-of-sample points (OOSP) extension. To enhance subsurface inferential and machine learning workflows, datasets must be transformed into stable, reduced-dimension representations that accommodate OOSP.   Our solution employs rigid transformations for a stabilized Euclidean invariant representation for LDS. By computing an MDS input dissimilarity matrix, and applying rigid transformations on multiple realizations, we ensure transformation invariance and integrate OOSP. This process leverages a convex hull algorithm and incorporates loss function and normalized stress for distortion quantification. We validate our approach with synthetic data, varying distance metrics, and real-world wells from the Duvernay Formation. Results confirm our method's efficacy in achieving consistent LDS representations. Furthermore, our proposed "stress ratio" (SR) metric provides insight into uncertainty, beneficial for model adjustments and inferential analysis. Consequently, our workflow promises enhanced repeatability and comparability in NDR for subsurface energy resource engineering and associated big data workflows.
</details>
<details>
<summary>摘要</summary>
底层数据自然而有大数据特点，如庞大量、多样特征和高采样速率，这些特点更加受到物理、工程和地质输入的带来的诸多维度的咒语。现有的维度减少（DR）方法中，非线性维度减少（NDR）方法，尤其是多元维度减少（MDS），对底层数据进行处理是更为首选的，因为它们可以更好地处理底层数据的复杂性。然而，MDS存在两个缺点：一是无法保证唯一解，二是缺乏对外样点（OOSP）的扩展。为了提高底层数据的推断和机器学习工作流程，数据需要被转换成稳定、减少维度的表示，并且包含OOSP。我们的解决方案是使用固定变换来实现稳定的几何减少，并且在多个实现中计算MDS输入不同性矩阵，以确保变换不变性和包含OOSP。这个过程利用了 convex hull 算法和 incorporate 损失函数和正规化压力，以量化扭曲。我们通过使用synthetic data、不同的距离度量和实际的DUVERNAY  formación 井井来验证我们的方法，结果证明了我们的方法的有效性。此外，我们还提出了一个"stress ratio"（SR）指标，可以提供很好的 uncertainty 的视角，这有助于进行模型调整和推断分析。因此，我们的工作流程 promise 提高了NDR 的重复性和相对性，为底层数据的能源资源工程和相关的大数据工作流程提供了更好的支持。
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Graph-Neural-Network-for-Privacy-Preserving-Recommendation"><a href="#Decentralized-Graph-Neural-Network-for-Privacy-Preserving-Recommendation" class="headerlink" title="Decentralized Graph Neural Network for Privacy-Preserving Recommendation"></a>Decentralized Graph Neural Network for Privacy-Preserving Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08072">http://arxiv.org/abs/2308.08072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Jiashu Qian, Yao Yang</li>
<li>for: This paper aims to build a privacy-preserving graph neural network (GNN) based recommender system without violating user privacy.</li>
<li>methods: The proposed method, called DGREC, includes three stages: graph construction, local gradient calculation, and global gradient passing. It uses a local differential privacy mechanism called secure gradient-sharing to protect users’ private data.</li>
<li>results: The authors conduct extensive experiments on three public datasets and show that DGREC achieves consistent superiority over existing methods in terms of accuracy and privacy protection.Here’s the simplified Chinese version:</li>
<li>for: 这篇论文目标是构建一个遵循用户隐私的图内存神经网络（GNN）基于推荐系统，不会违反用户的隐私。</li>
<li>methods: 该提议的方法包括三个阶段：图构建、本地梯度计算和全局梯度传递。它使用一种名为安全梯度分享的本地异质隐私机制来保护用户的私人数据。</li>
<li>results: 作者们对三个公共数据集进行了广泛的实验，并证明了 DGREC 在精度和隐私保护方面与现有方法具有一致的优越性。<details>
<summary>Abstract</summary>
Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framework.
</details>
<details>
<summary>摘要</summary>
建立一个基于图神经网络（GNN）的推荐系统，保持用户隐私具有挑战性。现有方法可以分为联邦GNN和分散GNN两种。但两种方法都带有不 DESirable Effects，即通信效率低和隐私泄露。这篇论文提出了DGREC，一种新的分散GNN，用户可以选择公开自己的互动记录。它包括三个阶段：图建构、本地梯度计算和全球梯度传递。第一阶段建立了每个用户的本地内部项目图和全球用户图。第二阶段模型用户偏好并在每个本地设备上计算梯度。第三阶段实现了一种安全梯度分享机制，以保障用户隐私数据的强大隐私。我们在三个公共数据集上进行了广泛的实验，以验证我们的框架的一致性和优越性。
</details></li>
</ul>
<hr>
<h2 id="Freshness-or-Accuracy-Why-Not-Both-Addressing-Delayed-Feedback-via-Dynamic-Graph-Neural-Networks"><a href="#Freshness-or-Accuracy-Why-Not-Both-Addressing-Delayed-Feedback-via-Dynamic-Graph-Neural-Networks" class="headerlink" title="Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via Dynamic Graph Neural Networks"></a>Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via Dynamic Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08071">http://arxiv.org/abs/2308.08071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Feng Zhu, Jiashu Qian</li>
<li>for: 预测在线购物系统中用户的购买率，解决延迟反馈问题。</li>
<li>methods: 使用动态图 neural network 模型，包括数据预处理、建立动态图和训练 CVR 预测模型。在模型训练中，我们提出了一种新的图 convolutional 方法 named HLGCN，可以处理 conversion 和 non-conversion 关系。</li>
<li>results: 在三个行业数据集上进行了广泛的实验 validate 了我们的方法的一致优势。<details>
<summary>Abstract</summary>
The delayed feedback problem is one of the most pressing challenges in predicting the conversion rate since users' conversions are always delayed in online commercial systems. Although new data are beneficial for continuous training, without complete feedback information, i.e., conversion labels, training algorithms may suffer from overwhelming fake negatives. Existing methods tend to use multitask learning or design data pipelines to solve the delayed feedback problem. However, these methods have a trade-off between data freshness and label accuracy. In this paper, we propose Delayed Feedback Modeling by Dynamic Graph Neural Network (DGDFEM). It includes three stages, i.e., preparing a data pipeline, building a dynamic graph, and training a CVR prediction model. In the model training, we propose a novel graph convolutional method named HLGCN, which leverages both high-pass and low-pass filters to deal with conversion and non-conversion relationships. The proposed method achieves both data freshness and label accuracy. We conduct extensive experiments on three industry datasets, which validate the consistent superiority of our method.
</details>
<details>
<summary>摘要</summary>
延迟反馈问题是在线商业系统中预测转化率的最大挑战之一，因为用户的转化都会延迟。新的数据对于连续训练是有利，但是无完整的转化标签，训练算法可能会受到干扰性的假负样本的影响。现有方法通常使用多任务学习或设计数据管道来解决延迟反馈问题，但这些方法存在数据新鲜度和标签准确性之间的负担。本文提出了延迟反馈模型化方法（DGDFEM），包括三个阶段：准备数据管道、建立动态图和训练CVR预测模型。在模型训练中，我们提出了一种新的图解决方法 named HLGCN，它利用高频和低频滤波器来处理转化和非转化关系。提出的方法同时保证数据新鲜度和标签准确性。我们对三个行业数据集进行了广泛的实验， validate了我们的方法的一致性优势。
</details></li>
</ul>
<hr>
<h2 id="Max-affine-regression-via-first-order-methods"><a href="#Max-affine-regression-via-first-order-methods" class="headerlink" title="Max-affine regression via first-order methods"></a>Max-affine regression via first-order methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08070">http://arxiv.org/abs/2308.08070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seonho Kim, Kiryung Lee</li>
<li>for: 这篇论文主要关注于 max-affine 模型的回归分析，尤其是在测量变量随机分布和反对对应下进行 gradient descent 和 mini-batch stochastic gradient descent 的非对称渐近分析。</li>
<li>methods: 论文使用了 gradient descent 和 mini-batch stochastic gradient descent，并进行了非对称渐近分析。</li>
<li>results: 论文发现，在随机分布和反对对应下，适当初始化的 gradient descent 和 mini-batch stochastic gradient descent 会在适当的错误范围内线性收摄到解。此外，在噪音存在的低样本案例中，SGD 不仅快速执行时间，还超过了对称降低和 gradient descent 的性能。<details>
<summary>Abstract</summary>
We consider regression of a max-affine model that produces a piecewise linear model by combining affine models via the max function. The max-affine model ubiquitously arises in applications in signal processing and statistics including multiclass classification, auction problems, and convex regression. It also generalizes phase retrieval and learning rectifier linear unit activation functions. We present a non-asymptotic convergence analysis of gradient descent (GD) and mini-batch stochastic gradient descent (SGD) for max-affine regression when the model is observed at random locations following the sub-Gaussianity and an anti-concentration with additive sub-Gaussian noise. Under these assumptions, a suitably initialized GD and SGD converge linearly to a neighborhood of the ground truth specified by the corresponding error bound. We provide numerical results that corroborate the theoretical finding. Importantly, SGD not only converges faster in run time with fewer observations than alternating minimization and GD in the noiseless scenario but also outperforms them in low-sample scenarios with noise.
</details>
<details>
<summary>摘要</summary>
我们考虑一个最大拟合模型，它生成一个分割线性模型，通过最大函数将多个拟合模型相加。这种最大拟合模型在信号处理和统计应用中广泛存在，包括多类分类、拍卖问题和凸回归。它还泛化了phas Retrieval和学习矩阵减法。我们提供了非 asymptotic 的收敛分析，证明了梯度下降（GD）和批处理随机梯度下降（SGD）在最大拟合 regression 中的收敛性。在这些假设下，一个适当的初始化GD和SGD会 linearly收敛到一个包含真实值的邻域，以至于这个邻域的错误 bound。我们提供了数字结果，证明了理论发现。此外，SGD不仅在干擦无噪scenario下更快地收敛，也在低样本 scenarios 中超越了交互式最优化和GD。
</details></li>
</ul>
<hr>
<h2 id="A-Reinforcement-Learning-Approach-for-Performance-aware-Reduction-in-Power-Consumption-of-Data-Center-Compute-Nodes"><a href="#A-Reinforcement-Learning-Approach-for-Performance-aware-Reduction-in-Power-Consumption-of-Data-Center-Compute-Nodes" class="headerlink" title="A Reinforcement Learning Approach for Performance-aware Reduction in Power Consumption of Data Center Compute Nodes"></a>A Reinforcement Learning Approach for Performance-aware Reduction in Power Consumption of Data Center Compute Nodes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08069">http://arxiv.org/abs/2308.08069</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhileshraj91/generalized_rl_anl">https://github.com/akhileshraj91/generalized_rl_anl</a></li>
<li>paper_authors: Akhilesh Raj, Swann Perarnau, Aniruddha Gokhale</li>
<li>for: 这个论文的目的是设计一种基于Reinforcement Learning（RL）的云计算节点资源控制策略，以减少计算节点的能源消耗。</li>
<li>methods: 该论文使用了Reinforcement Learning（RL）技术，使用当前电力消耗和协调器性能（heartbeats）的观察值，设计了一种可以在实际硬件上运行的最佳策略。</li>
<li>results: 该论文通过使用Argo Node Resource Management（NRM）软件栈和Intel Running Average Power Limit（RAPL）硬件控制机制，设计了一种可以控制计算节点的最大供应电力，不会妨碍应用程序性能。通过使用STREAM benchmark进行评估，表明训练了一个RL代理可以在实际硬件上进行动作，均衡电力消耗和应用程序性能。<details>
<summary>Abstract</summary>
As Exascale computing becomes a reality, the energy needs of compute nodes in cloud data centers will continue to grow. A common approach to reducing this energy demand is to limit the power consumption of hardware components when workloads are experiencing bottlenecks elsewhere in the system. However, designing a resource controller capable of detecting and limiting power consumption on-the-fly is a complex issue and can also adversely impact application performance. In this paper, we explore the use of Reinforcement Learning (RL) to design a power capping policy on cloud compute nodes using observations on current power consumption and instantaneous application performance (heartbeats). By leveraging the Argo Node Resource Management (NRM) software stack in conjunction with the Intel Running Average Power Limit (RAPL) hardware control mechanism, we design an agent to control the maximum supplied power to processors without compromising on application performance. Employing a Proximal Policy Optimization (PPO) agent to learn an optimal policy on a mathematical model of the compute nodes, we demonstrate and evaluate using the STREAM benchmark how a trained agent running on actual hardware can take actions by balancing power consumption and application performance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:随着存储计算 becoming a reality, 云数据中心的计算节点的能源需求将继续增长。一种常见的方法是在工作负荷经历瓶颈时限制硬件组件的能源消耗。然而，在实时 detection 和限制能源消耗的设计是一个复杂的问题，可能会影响应用程序性能。在这篇论文中，我们explore使用强化学习（RL）设计云计算节点的能源帽策略，使用当前的电力消耗和应用程序性能（心跳） Observations。通过利用 Argo 节点资源管理（NRM）软件栈和Intel 运行平均电力限制（RAPL）硬件控制机制，我们设计了一个控制器来限制计算节点的最大供应电力，而不会影响应用程序性能。我们使用 PPO 代理来学习一个最佳策略，并在实际硬件上运行。使用 STREAM benchmark，我们 demonstate 和评估一个训练过的代理可以通过平衡电力消耗和应用程序性能来取得行动。
</details></li>
</ul>
<hr>
<h2 id="The-Costly-Dilemma-Generalization-Evaluation-and-Cost-Optimal-Deployment-of-Large-Language-Models"><a href="#The-Costly-Dilemma-Generalization-Evaluation-and-Cost-Optimal-Deployment-of-Large-Language-Models" class="headerlink" title="The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models"></a>The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08061">http://arxiv.org/abs/2308.08061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abi Aryan, Aakash Kumar Nain, Andrew McMahon, Lucas Augusto Meyer, Harpreet Singh Sahota</li>
<li>for: 这篇论文是为了探讨大自然语言模型在生产环境中的应用和管理。</li>
<li>methods: 论文提出了一个横跨三个目标（即通用性、评估和成本优化）的框架，用于评估和优化大自然语言模型在生产环境中的性能和成本。</li>
<li>results: 论文表明，这个框架可以帮助企业对大自然语言模型进行评估和优化，以减少投资的成本和增加效率。<details>
<summary>Abstract</summary>
When deploying machine learning models in production for any product/application, there are three properties that are commonly desired. First, the models should be generalizable, in that we can extend it to further use cases as our knowledge of the domain area develops. Second they should be evaluable, so that there are clear metrics for performance and the calculation of those metrics in production settings are feasible. Finally, the deployment should be cost-optimal as far as possible. In this paper we propose that these three objectives (i.e. generalization, evaluation and cost-optimality) can often be relatively orthogonal and that for large language models, despite their performance over conventional NLP models, enterprises need to carefully assess all the three factors before making substantial investments in this technology. We propose a framework for generalization, evaluation and cost-modeling specifically tailored to large language models, offering insights into the intricacies of development, deployment and management for these large language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>模型应该是可扩展的，以便在我们对领域知识的发展中可以进一步应用。2. 模型应该可评估，以便有明确的表现指标和在生产环境中可行的计算表现指标。3. 部署应该是最优化的，尽可能保持成本低。在这篇论文中，我们提出这三个目标（即泛化、评估和成本优化）通常是相互独立的，并且对大语言模型来说，企业需要仔细评估这三个因素才能够做出大投资。我们提出了特制的泛化、评估和成本模型，以便更好地发展、部署和管理这些大语言模型。</details></li>
</ol>
<hr>
<h2 id="Robust-Bayesian-Tensor-Factorization-with-Zero-Inflated-Poisson-Model-and-Consensus-Aggregation"><a href="#Robust-Bayesian-Tensor-Factorization-with-Zero-Inflated-Poisson-Model-and-Consensus-Aggregation" class="headerlink" title="Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation"></a>Robust Bayesian Tensor Factorization with Zero-Inflated Poisson Model and Consensus Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08060">http://arxiv.org/abs/2308.08060</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/klarman-cell-observatory/scbtf_experiments">https://github.com/klarman-cell-observatory/scbtf_experiments</a></li>
<li>paper_authors: Daniel Chafamo, Vignesh Shanmugam, Neriman Tokcan</li>
<li>for: 这篇论文是为了解决高维度计数数据中异常值带来的挑战，提出了一种基于 zero-inflated Poisson tensor factorization（ZIPTF）的新方法。</li>
<li>methods: 这篇论文使用了一种基于 maximum likelihood estimation的经典TF方法，但是这些方法在应用于单元RNA-seq数据时表现不佳。在解决随机性问题方面，这篇论文提出了一种基于consensus的zero-inflated Poisson tensor factorization（C-ZIPTF）方法。</li>
<li>results: 对于 sintetic zero-inflated count data和real single-cell RNA-seq数据，ZIPTF和C-ZIPTF都能够高效地重建知识图和生物 significative的表达程序。ZIPTF在probability of excess zeros高时能够达到2.4倍的准确率提高。此外，C-ZIPTF可以大幅提高重建精度和一致性。<details>
<summary>Abstract</summary>
Tensor factorizations (TF) are powerful tools for the efficient representation and analysis of multidimensional data. However, classic TF methods based on maximum likelihood estimation underperform when applied to zero-inflated count data, such as single-cell RNA sequencing (scRNA-seq) data. Additionally, the stochasticity inherent in TFs results in factors that vary across repeated runs, making interpretation and reproducibility of the results challenging. In this paper, we introduce Zero Inflated Poisson Tensor Factorization (ZIPTF), a novel approach for the factorization of high-dimensional count data with excess zeros. To address the challenge of stochasticity, we introduce Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF), which combines ZIPTF with a consensus-based meta-analysis. We evaluate our proposed ZIPTF and C-ZIPTF on synthetic zero-inflated count data and synthetic and real scRNA-seq data. ZIPTF consistently outperforms baseline matrix and tensor factorization methods in terms of reconstruction accuracy for zero-inflated data. When the probability of excess zeros is high, ZIPTF achieves up to $2.4\times$ better accuracy. Additionally, C-ZIPTF significantly improves the consistency and accuracy of the factorization. When tested on both synthetic and real scRNA-seq data, ZIPTF and C-ZIPTF consistently recover known and biologically meaningful gene expression programs.
</details>
<details>
<summary>摘要</summary>
tensor化工具 (TF) 是一种强大的数据表示和分析工具，但 классические TF 方法基于最大化可能性估计在应用于零含量计数数据时表现不佳，如单个细胞 RNA 测序 (scRNA-seq) 数据。此外，TF 中的随机性使得因素在重复运行中变化，从而使得结果的解释和重现困难。在这篇论文中，我们介绍了 Zero Inflated Poisson Tensor Factorization (ZIPTF)，一种用于高维计数数据中的零含量的因素化方法。为了解决随机性的挑战，我们引入了 Consensus Zero Inflated Poisson Tensor Factorization (C-ZIPTF)，它将 ZIPTF 与 consensus-based 元分析结合。我们对 ZIPTF 和 C-ZIPTF 在 sintetic zero-inflated count data 和 sintetic 和实际 scRNA-seq data 上进行评估。ZIPTF 在零含量数据上的重建精度与基线矩阵和矩阵因素化方法相比，表现出了明显的优势。当零含量的概率高时，ZIPTF 的精度可以达到 2.4 倍。此外，C-ZIPTF 可以有效地提高因素化的一致性和精度。当测试在 sintetic 和实际 scRNA-seq data 上时，ZIPTF 和 C-ZIPTF 一致地回归了知道的和生物学意义的基因表达程序。
</details></li>
</ul>
<hr>
<h2 id="Simple-online-learning-with-consistency-oracle"><a href="#Simple-online-learning-with-consistency-oracle" class="headerlink" title="Simple online learning with consistency oracle"></a>Simple online learning with consistency oracle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08055">http://arxiv.org/abs/2308.08055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Kozachinskiy, Tomasz Steifer</li>
<li>for: 这个论文是关于在具有一个一致性 oracle 的模型下进行在线学习的。这个模型是由 Assos et al. (COLT’23) 最近提出的，它是由于标准的在线学习方法 rely on 计算 Littlestone 维度的问题，这是计算 tractable 的。</li>
<li>methods: 这个论文提出了一种新的在线学习算法，该算法可以在类的 Littlestone 维度为 $d$ 时最多出错 $O(256^d)$ 次。我们的证明比 Assos et al. 的证明更简单，只需要使用了一些基本的 Littlestone 维度的性质。</li>
<li>results: 这个论文的结果包括两点：首先，我们提供了一种可计算的在线学习算法，该算法可以解决一个开放的问题，即是每个有限 Littlestone 维度的类都存在可计算的在线学习算法。其次，我们证明了存在一个不可 counts 的类，即是任何类的 Littlestone 维度不小于 $2^{d+1}-2$ 时，不可能有一个可计算的在线学习算法。<details>
<summary>Abstract</summary>
We consider online learning in the model where a learning algorithm can access the class only via the consistency oracle -- an oracle, that, at any moment, can give a function from the class that agrees with all examples seen so far. This model was recently considered by Assos et al. (COLT'23). It is motivated by the fact that standard methods of online learning rely on computing the Littlestone dimension of subclasses, a problem that is computationally intractable. Assos et al. gave an online learning algorithm in this model that makes at most $C^d$ mistakes on classes of Littlestone dimension $d$, for some absolute unspecified constant $C > 0$. We give a novel algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly simpler and uses only very basic properties of the Littlestone dimension. We also observe that there exists no algorithm in this model that makes at most $2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the algorithm of Assos et al.) solves an open problem by Hasrati and Ben-David (ALT'23). Namely, it demonstrates that every class of finite Littlestone dimension with recursively enumerable representation admits a computable online learner (that may be undefined on unrealizable samples).
</details>
<details>
<summary>摘要</summary>
我们考虑在模型中使用线上学习，其中学习算法可以通过一个具有一致性 oracle 访问 клаス。这个模型最近在 Assos 等人（COLT'23）中被考虑过。这个模型的动机是由于标准的线上学习方法需要计算 Littlestone 次数，这是 computationally intractable 的问题。Assos 等人提供了一个线上学习算法，它在类的 Littlestone 次数为 d 时会 maken at most C^d 的错误，其中 C 是一个未知的绝对常数。我们提供了一个新的算法，它在类的 Littlestone 次数为 d 时会 maken at most O(256^d) 的错误。我们的证明比较简单，只需要使用类的 Littlestone 次数的非常基本的性质。我们还观察到，不存在任何算法可以在类的 Littlestone 次数为 d 时 maken at most 2^(d+1)-2 的错误。此外，我们的算法（以及 Assos 等人的算法）解决了 Hasrati 和 Ben-David（ALT'23）的开问题。具体而言，它证明了每个有质量的类都存在可计算的线上学习器（可能是未定义的在不可能的测试样本上）。
</details></li>
</ul>
<hr>
<h2 id="Natural-Evolution-Strategies-as-a-Black-Box-Estimator-for-Stochastic-Variational-Inference"><a href="#Natural-Evolution-Strategies-as-a-Black-Box-Estimator-for-Stochastic-Variational-Inference" class="headerlink" title="Natural Evolution Strategies as a Black Box Estimator for Stochastic Variational Inference"></a>Natural Evolution Strategies as a Black Box Estimator for Stochastic Variational Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08053">http://arxiv.org/abs/2308.08053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Ayaz Amin</li>
<li>for: 用于替代Variational Autoencoders（VAE）中的梯度估计，以解决VAE中的一种设计选择（即重parameterization trick）限制了模型的类型。</li>
<li>methods: 使用自然演化策略来提供一种不假设 distribuition 类型的 estimator，allowing for the creation of models that would otherwise not have been possible under the VAE framework。</li>
<li>results: 提出了一种不受 VAE 设计选择限制的模型创建方法，allowing for the creation of more diverse and complex models.<details>
<summary>Abstract</summary>
Stochastic variational inference and its derivatives in the form of variational autoencoders enjoy the ability to perform Bayesian inference on large datasets in an efficient manner. However, performing inference with a VAE requires a certain design choice (i.e. reparameterization trick) to allow unbiased and low variance gradient estimation, restricting the types of models that can be created. To overcome this challenge, an alternative estimator based on natural evolution strategies is proposed. This estimator does not make assumptions about the kind of distributions used, allowing for the creation of models that would otherwise not have been possible under the VAE framework.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:Stochastic variational inference和其 derivatives的形式为variational autoencoders (VAE)可以高效地进行 bayesian inference on large datasets。然而，使用 VAE 进行 inference 需要特定的设计选择（即 reparameterization trick）以确保无偏度和低差异的梯度估计，这限制了可以创建的模型类型。为了解决这个挑战，一种基于自然进化策略的替代估计器被提议。这种估计器不会假设分布的类型，因此可以创建 VAE 框架下不可能创建的模型。
</details></li>
</ul>
<hr>
<h2 id="Unbiased-Decisions-Reduce-Regret-Adversarial-Domain-Adaptation-for-the-Bank-Loan-Problem"><a href="#Unbiased-Decisions-Reduce-Regret-Adversarial-Domain-Adaptation-for-the-Bank-Loan-Problem" class="headerlink" title="Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem"></a>Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08051">http://arxiv.org/abs/2308.08051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Gal, Shaun Singh, Aldo Pacchiano, Ben Walker, Terry Lyons, Jakob Foerster</li>
<li>for: 本研究旨在 Addressing bias in binary classification decisions based on limited data in near real-time, particularly in scenarios where the true label is only observed when a data point is assigned a positive label.</li>
<li>methods: 该研究提出了一种新的方法 called adversarial optimism (AdOpt), which uses adversarial domain adaptation to directly address bias in the training set and learn an unbiased but informative representation of past data.</li>
<li>results: 对一组Difficult benchmark problems, AdOpt 能够显著超过州Of-the-art表现，并且初步证明了该方法在这种设定中改善公平性。<details>
<summary>Abstract</summary>
In many real world settings binary classification decisions are made based on limited data in near real-time, e.g. when assessing a loan application. We focus on a class of these problems that share a common feature: the true label is only observed when a data point is assigned a positive label by the principal, e.g. we only find out whether an applicant defaults if we accepted their loan application. As a consequence, the false rejections become self-reinforcing and cause the labelled training set, that is being continuously updated by the model decisions, to accumulate bias. Prior work mitigates this effect by injecting optimism into the model, however this comes at the cost of increased false acceptance rate. We introduce adversarial optimism (AdOpt) to directly address bias in the training set using adversarial domain adaptation. The goal of AdOpt is to learn an unbiased but informative representation of past data, by reducing the distributional shift between the set of accepted data points and all data points seen thus far. AdOpt significantly exceeds state-of-the-art performance on a set of challenging benchmark problems. Our experiments also provide initial evidence that the introduction of adversarial domain adaptation improves fairness in this setting.
</details>
<details>
<summary>摘要</summary>
在许多实际场景中，二进制分类决策基于有限数据进行实时进行，例如审批贷款申请。我们关注一类这些问题，它们共同特点是：真正的标签只有当数据点被主体分配正确标签时才可以见到，例如只有当我们接受了贷款申请后才能确定应用者是否 defaults。这导致假拒绝被自我强化，从而使标记训练集，由模型决策而不断更新的集合，受到偏见。先前的工作通过在模型中注入乐观性来 mitigate这种效应，但这会导致准确批准率上升。我们引入对抗优化（AdOpt），直接通过对抗领域适应来减少标记训练集中的偏见。AdOpt的目标是学习不偏的， yet informative 的过去数据表示，通过减少接受数据点和所有见过的数据点之间的分布差异。AdOpt在一组具有挑战性的benchmark问题上表现出色，我们的实验也提供了初步证据，表明在这种设置中，对抗领域适应可以提高公平性。
</details></li>
</ul>
<hr>
<h2 id="Regret-Lower-Bounds-in-Multi-agent-Multi-armed-Bandit"><a href="#Regret-Lower-Bounds-in-Multi-agent-Multi-armed-Bandit" class="headerlink" title="Regret Lower Bounds in Multi-agent Multi-armed Bandit"></a>Regret Lower Bounds in Multi-agent Multi-armed Bandit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08046">http://arxiv.org/abs/2308.08046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengfan Xu, Diego Klabjan</li>
<li>for: 本文研究了多客户端多臂抽筋问题，即每个客户端面临着一个分布式抽筋问题，总体系统性能被评估为尝验 regret。</li>
<li>methods: 本文使用了多种方法，包括贪婪启发、决策规则、搜索等，以实现高效的启发和减少 regret。</li>
<li>results: 本文提供了多种情况下的 regret 下界，包括对各种设定下的 Connectivity 和奖励分布的研究。Specifically, 当图表现good connectivity properties和奖励是随机分布时，我们证明了下界为O（log T）的instance-dependent bounds和$\sqrt{T}$的mean-gap independent bounds，并证明了其紧张性。在对抗奖励下，我们建立了下界为O(T^{2&#x2F;3})的连接图下界，这与之前的上界相匹配。此外，当图是离散的时，我们证明了线性的下界。相比之前的研究，本文提供了严格的下界研究。<details>
<summary>Abstract</summary>
Multi-armed Bandit motivates methods with provable upper bounds on regret and also the counterpart lower bounds have been extensively studied in this context. Recently, Multi-agent Multi-armed Bandit has gained significant traction in various domains, where individual clients face bandit problems in a distributed manner and the objective is the overall system performance, typically measured by regret. While efficient algorithms with regret upper bounds have emerged, limited attention has been given to the corresponding regret lower bounds, except for a recent lower bound for adversarial settings, which, however, has a gap with let known upper bounds. To this end, we herein provide the first comprehensive study on regret lower bounds across different settings and establish their tightness. Specifically, when the graphs exhibit good connectivity properties and the rewards are stochastically distributed, we demonstrate a lower bound of order $O(\log T)$ for instance-dependent bounds and $\sqrt{T}$ for mean-gap independent bounds which are tight. Assuming adversarial rewards, we establish a lower bound $O(T^{\frac{2}{3}})$ for connected graphs, thereby bridging the gap between the lower and upper bound in the prior work. We also show a linear regret lower bound when the graph is disconnected. While previous works have explored these settings with upper bounds, we provide a thorough study on tight lower bounds.
</details>
<details>
<summary>摘要</summary>
多臂弓箭刺激方法的研究已有证明的最高 regret 上界和对应的下界也得到了广泛的研究。在这个上下文中，最近的多智能体多臂弓箭问题已经在不同领域得到了广泛的应用，其中每个客户面临着分布式的弓箭问题，并且目标是总系统性能，通常由 regret 来度量。虽然有效的算法得到了提出，但对应的 regret 下界却受到了有限的关注，除了最近的对抗性下界，其中 however 有一定的差距。为了解决这个问题，我们在这里提供了首次的全面的下界研究，并证明其紧耦合。具体来说，当图表现出良好的连接性和奖励是随机分布的时候，我们示出了一个下界为 $O(\log T)$ 的实例依赖下界和 $ \sqrt{T} $ 的无关下界，这些下界都是紧耦合的。在对抗性奖励下，我们确立了一个下界为 $O(T^{2/3})$ 的连接图下界，因此bridging了之前的下界和上界之间的差距。此外，当图为离散图时，我们还证明了一个线性的下界。相比之前的研究，我们在这里提供了一个全面的下界研究。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Analysis-of-the-Capabilities-of-Nature-inspired-Feature-Selection-Algorithms-in-Predicting-Student-Performance"><a href="#A-Comparative-Analysis-of-the-Capabilities-of-Nature-inspired-Feature-Selection-Algorithms-in-Predicting-Student-Performance" class="headerlink" title="A Comparative Analysis of the Capabilities of Nature-inspired Feature Selection Algorithms in Predicting Student Performance"></a>A Comparative Analysis of the Capabilities of Nature-inspired Feature Selection Algorithms in Predicting Student Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08574">http://arxiv.org/abs/2308.08574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Trask</li>
<li>for: 预测学生表现，以便采取有效的预warning措施对于受风险学生。</li>
<li>methods: 使用12种自然引导的算法来预测学生表现，并对3个数据集进行分析，包括单个课程表现、多门课程表现和点播数据。</li>
<li>results: 结果显示，无论是哪个数据集，都可以通过结合NIAs进行特征选择和传统机器学习算法进行分类，提高预测精度，同时减少特征集大小by 2&#x2F;3。<details>
<summary>Abstract</summary>
Predicting student performance is key in leveraging effective pre-failure interventions for at-risk students. In this paper, I have analyzed the relative performance of a suite of 12 nature-inspired algorithms when used to predict student performance across 3 datasets consisting of instance-based clickstream data, intra-course single-course performance, and performance when taking multiple courses simultaneously. I found that, for all datasets, leveraging an ensemble approach using NIAs for feature selection and traditional ML algorithms for classification increased predictive accuracy while also reducing feature set size by 2/3.
</details>
<details>
<summary>摘要</summary>
预测学生表现是键在实施有效预测失败学生之前的干预措施中。在这篇论文中，我分析了12种自然指导算法的相对性，当用于预测学生表现 across 3个数据集，包括单个实例流量数据、单个课程表现和同时攻击多门课程表现。我发现，对于所有数据集，使用NIAs进行特征选择和传统机器学习算法进行分类可以提高预测精度，同时减少特征集的大小 by 2/3。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-Data-Generated-by-Gaussian-Mixture-Models-Using-Deep-ReLU-Networks"><a href="#Classification-of-Data-Generated-by-Gaussian-Mixture-Models-Using-Deep-ReLU-Networks" class="headerlink" title="Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks"></a>Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08030">http://arxiv.org/abs/2308.08030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tian-Yi Zhou, Xiaoming Huo</li>
<li>for: 这个论文研究了使用深度ReLU神经网络进行二分类问题中的数据从 ${\mathbb R}^d$ 生成的 Gaussian Mixture Models (GMMs) 的极限风险误差。</li>
<li>methods: 我们提供了非对易Bounds和抽象率的极限风险误差的非准确上界，这些上界不依赖于维度 $d$，表明深度ReLU网络可以缓解维度约束的味道。</li>
<li>results: 我们的结果表明，使用深度ReLU网络进行二分类问题中的数据从 ${\mathbb R}^d$ 生成的 Gaussian Mixture Models (GMMs) 可以减少误差，并且不受维度 $d$ 的影响。<details>
<summary>Abstract</summary>
This paper studies the binary classification of unbounded data from ${\mathbb R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural networks. We obtain $\unicode{x2013}$ for the first time $\unicode{x2013}$ non-asymptotic upper bounds and convergence rates of the excess risk (excess misclassification error) for the classification without restrictions on model parameters. The convergence rates we derive do not depend on dimension $d$, demonstrating that deep ReLU networks can overcome the curse of dimensionality in classification. While the majority of existing generalization analysis of classification algorithms relies on a bounded domain, we consider an unbounded domain by leveraging the analyticity and fast decay of Gaussian distributions. To facilitate our analysis, we give a novel approximation error bound for general analytic functions using ReLU networks, which may be of independent interest. Gaussian distributions can be adopted nicely to model data arising in applications, e.g., speeches, images, and texts; our results provide a theoretical verification of the observed efficiency of deep neural networks in practical classification problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Planning-to-Learn-A-Novel-Algorithm-for-Active-Learning-during-Model-Based-Planning"><a href="#Planning-to-Learn-A-Novel-Algorithm-for-Active-Learning-during-Model-Based-Planning" class="headerlink" title="Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning"></a>Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08029">http://arxiv.org/abs/2308.08029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rowanlibr/sophisticated-learning">https://github.com/rowanlibr/sophisticated-learning</a></li>
<li>paper_authors: Rowan Hodson, Bruce Bassett, Charel van Hoof, Benjamin Rosman, Mark Solms, Jonathan P. Shock, Ryan Smith</li>
<li>For: 本研究的目的是比较Active Inference和 bayesian reinforcement learning（RL） schemes在解决相似问题时的表现，以及扩展Active Inference以包括活动学习。* Methods: 本研究使用了一种新的、生物学上启发的环境，用于强调解决问题的问题结构，并使用了推理搜索和对假推理来解决问题。* Results: 研究结果显示，使用了扩展的Active Inference（SL）算法可以在这种生物学上适用的环境中高效地解决问题，并且在比较 bayes-adaptive RL和Upper confidence bound算法时表现更好。这些结果为Active Inference在解决这类生物学上适用的问题提供了更多的支持，并为测试人类认知理论提供了新的工具。<details>
<summary>Abstract</summary>
Active Inference is a recent framework for modeling planning under uncertainty. Empirical and theoretical work have now begun to evaluate the strengths and weaknesses of this approach and how it might be improved. A recent extension - the sophisticated inference (SI) algorithm - improves performance on multi-step planning problems through recursive decision tree search. However, little work to date has been done to compare SI to other established planning algorithms. SI was also developed with a focus on inference as opposed to learning. The present paper has two aims. First, we compare performance of SI to Bayesian reinforcement learning (RL) schemes designed to solve similar problems. Second, we present an extension of SI - sophisticated learning (SL) - that more fully incorporates active learning during planning. SL maintains beliefs about how model parameters would change under the future observations expected under each policy. This allows a form of counterfactual retrospective inference in which the agent considers what could be learned from current or past observations given different future observations. To accomplish these aims, we make use of a novel, biologically inspired environment designed to highlight the problem structure for which SL offers a unique solution. Here, an agent must continually search for available (but changing) resources in the presence of competing affordances for information gain. Our simulations show that SL outperforms all other algorithms in this context - most notably, Bayes-adaptive RL and upper confidence bound algorithms, which aim to solve multi-step planning problems using similar principles (i.e., directed exploration and counterfactual reasoning). These results provide added support for the utility of Active Inference in solving this class of biologically-relevant problems and offer added tools for testing hypotheses about human cognition.
</details>
<details>
<summary>摘要</summary>
active inference是一种最近的规划下不确定性框架。实验和理论工作现在开始评估这种方法的优缺点和如何改进它。一种最新的扩展——复杂的推理（SI）算法——在多步规划问题上提高性能通过重层决策树搜索。然而，到目前为止，尚未对SI与其他已知规划算法进行比较。SI在推理而非学习方面得到了开发。本文的两个目标是：首先，比较SI与 bayesian reinforcement learning（RL）算法，解决类似问题。其次，我们提出了一种扩展SI的方法——复杂学习（SL），它更全面地包括活动学习在规划中。SL保留了对未来观测所期望的模型参数变化的信念。这allowsthe agent to consider what could be learned from current or past observations given different future observations。为了实现这些目标，我们使用了一个新的、生物学发现环境，这种环境可以强调规划问题中的问题结构，对于SL提供了特殊的解决方案。在这个环境中，agent需要不断搜索可用（但是变化的）资源，同时面临着竞争的信息收获可能性。我们的 simulations表明，SL在这种情况下表现出色，比bayes-adaptive RL和Upper confidence bound算法（这些算法目标解决类似的多步规划问题，使用相同的原则，即导航探索和对假推理）。这些结果为活动推断在这类生物学相关问题中的 utility提供了进一步的支持，并为测试人类认知假设提供了更多的工具。
</details></li>
</ul>
<hr>
<h2 id="Potential-Energy-Advantage-of-Quantum-Economy"><a href="#Potential-Energy-Advantage-of-Quantum-Economy" class="headerlink" title="Potential Energy Advantage of Quantum Economy"></a>Potential Energy Advantage of Quantum Economy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08025">http://arxiv.org/abs/2308.08025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Liu, Hansheng Jiang, Zuo-Jun Max Shen</li>
<li>for: 本研究旨在探讨量子计算在能效性方面的优势，并证明量子计算可以在能效性和盈利性两个方面超过类别计算。</li>
<li>methods: 本研究使用了 Cournot 竞争模型，并在能效性限制下研究了量子计算和类别计算的比较。</li>
<li>results: 研究发现，量子计算在大规模计算情况下可以实现更高的盈利性和能效性，并且这种优势是基于实际物理参数。<details>
<summary>Abstract</summary>
Energy cost is increasingly crucial in the modern computing industry with the wide deployment of large-scale machine learning models and language models. For the firms that provide computing services, low energy consumption is important both from the perspective of their own market growth and the government's regulations. In this paper, we study the energy benefits of quantum computing vis-a-vis classical computing. Deviating from the conventional notion of quantum advantage based solely on computational complexity, we redefine advantage in an energy efficiency context. Through a Cournot competition model constrained by energy usage, we demonstrate quantum computing firms can outperform classical counterparts in both profitability and energy efficiency at Nash equilibrium. Therefore quantum computing may represent a more sustainable pathway for the computing industry. Moreover, we discover that the energy benefits of quantum computing economies are contingent on large-scale computation. Based on real physical parameters, we further illustrate the scale of operation necessary for realizing this energy efficiency advantage.
</details>
<details>
<summary>摘要</summary>
现代计算业中能源成本日益重要，由于大规模机器学习模型和语言模型的广泛部署。为提供计算服务的公司来说，低能耗是重要的，不仅从市场增长的角度来看，还从政府的法规来看。在这篇论文中，我们研究了量子计算对于纳什平衡下的能源利好。相比传统的计算复杂性基础上的优势，我们重新定义了优势在能效环境下的意义。通过一个固定能源使用的 Cournot竞争模型，我们示出了量子计算公司可以在纳什平衡下超过 классиical对手在利润和能效环境方面表现优势。因此，量子计算可能代表计算业更可持续的发展途径。此外，我们发现了量子计算经济的能源利好取决于大规模计算。基于实际物理参数，我们进一步说明了实现这种能效优势所需的规模。
</details></li>
</ul>
<hr>
<h2 id="Active-Inverse-Learning-in-Stackelberg-Trajectory-Games"><a href="#Active-Inverse-Learning-in-Stackelberg-Trajectory-Games" class="headerlink" title="Active Inverse Learning in Stackelberg Trajectory Games"></a>Active Inverse Learning in Stackelberg Trajectory Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08017">http://arxiv.org/abs/2308.08017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Yu, Jacob Levy, Negar Mehr, David Fridovich-Keil, Ufuk Topcu</li>
<li>for: 这篇论文主要写于哪个问题上？	+ 回答：Game-theoretic inverse learning问题，即从行为中推断玩家目标函数。</li>
<li>methods: 这篇论文使用了哪些方法？	+ 回答：提议了一种活动 inverse learning方法，通过帮助领导者尝试不同假设中的玩家目标函数，以加速领导者对玩家目标函数的推断。</li>
<li>results: 这篇论文得到了什么结果？	+ 回答：比对uniformly random inputs的情况，提议的输入可以加速玩家目标函数的推断，conditioned on the follower’s trajectory的概率加速了orders of magnitude。<details>
<summary>Abstract</summary>
Game-theoretic inverse learning is the problem of inferring the players' objectives from their actions. We formulate an inverse learning problem in a Stackelberg game between a leader and a follower, where each player's action is the trajectory of a dynamical system. We propose an active inverse learning method for the leader to infer which hypothesis among a finite set of candidates describes the follower's objective function. Instead of using passively observed trajectories like existing methods, the proposed method actively maximizes the differences in the follower's trajectories under different hypotheses to accelerate the leader's inference. We demonstrate the proposed method in a receding-horizon repeated trajectory game. Compared with uniformly random inputs, the leader inputs provided by the proposed method accelerate the convergence of the probability of different hypotheses conditioned on the follower's trajectory by orders of magnitude.
</details>
<details>
<summary>摘要</summary>
<<SYS>>游戏理论反学习是推理玩家的目标函数的问题。我们将游戏形式为 Stackelberg 游戏的领袖和追随者之间的反学习问题进行形式化。我们提议一种活动的反学习方法，使领袖可以根据追随者的动力系统轨迹中的差异来推断追随者的目标函数中的哪一个假设。不同于现有方法，我们的方法不使用被动地观察到的轨迹，而是活动地增加不同假设下追随者的轨迹之间的差异，以加速领袖的推断。我们在回归 horizon 重复轨迹游戏中示cases。相比于随机输入，由我们提议的领袖输入可以提高conditioned on the follower's trajectory的各个假设的概率的减少速度，这些减少速度可以达到orders of magnitude。Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="GRINN-A-Physics-Informed-Neural-Network-for-solving-hydrodynamic-systems-in-the-presence-of-self-gravity"><a href="#GRINN-A-Physics-Informed-Neural-Network-for-solving-hydrodynamic-systems-in-the-presence-of-self-gravity" class="headerlink" title="GRINN: A Physics-Informed Neural Network for solving hydrodynamic systems in the presence of self-gravity"></a>GRINN: A Physics-Informed Neural Network for solving hydrodynamic systems in the presence of self-gravity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08010">http://arxiv.org/abs/2308.08010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayantan Auddy, Ramit Dey, Neal J. Turner, Shantanu Basu<br>for: 这篇论文旨在模拟三维自引力液体系统，以解决astrophysics中许多基础问题，如星系形成、星系核心形成、大规模结构的发展等。methods: 该论文使用物理学 informed neural network（PINN）技术，在无网格框架下实现3D自引力液体系统的模拟。results: 该论文的结果表明，GRINN在一个iso thermic气体中的引力不稳定和波传播问题上具有高准确性和高效率。与传统网格代码相比，GRINN的计算时间不随维度的增加而增长，而是随着计算量的增加而增长。这些结果表明，PINN技术在astrophysical flows中可能带来 significative advances。<details>
<summary>Abstract</summary>
Modeling self-gravitating gas flows is essential to answering many fundamental questions in astrophysics. This spans many topics including planet-forming disks, star-forming clouds, galaxy formation, and the development of large-scale structures in the Universe. However, the nonlinear interaction between gravity and fluid dynamics offers a formidable challenge to solving the resulting time-dependent partial differential equations (PDEs) in three dimensions (3D). By leveraging the universal approximation capabilities of a neural network within a mesh-free framework, physics informed neural networks (PINNs) offer a new way of addressing this challenge. We introduce the gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D self-gravitating hydrodynamic systems. Here, we specifically study gravitational instability and wave propagation in an isothermal gas. Our results match a linear analytic solution to within 1\% in the linear regime and a conventional grid code solution to within 5\% as the disturbance grows into the nonlinear regime. We find that the computation time of the GRINN does not scale with the number of dimensions. This is in contrast to the scaling of the grid-based code for the hydrodynamic and self-gravity calculations as the number of dimensions is increased. Our results show that the GRINN computation time is longer than the grid code in one- and two- dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy. Physics-informed neural networks like GRINN thus show promise for advancing our ability to model 3D astrophysical flows.
</details>
<details>
<summary>摘要</summary>
模拟自引力液体流动是astrophysics中答您许多基本问题的关键。这些问题包括 planet-forming 盘、star-forming 云、galaxy 形成和 universe 大规模结构的发展。然而，在三维空间中非线性的引力和流体动力学交互，对解决时间依赖的 partial differential equations (PDEs) 提出了挑战。通过利用神经网络的通用近似能力，physics informed neural networks (PINNs) 提供了一种新的解决方案。我们介绍了引力 informed neural network (GRINN)，一种基于 PINN 的代码，用于模拟三维自引力液体系统。在这里，我们专门研究引力不稳定和波传播在固定温度气体中。我们的结果与线性分析解匹配在线性 régime中的1%，并与基于网格的代码解匹配在非线性 régime中的5%。我们发现GRINN 的计算时间与维度无关，与基于网格的代码计算时间成正比。这与维度增加后网格代码的计算时间增长相比，GRINN 的计算时间更短。 physics-informed neural networks 如 GRINN 因此显示了在模拟三维astrophysical flows中的承诺。
</details></li>
</ul>
<hr>
<h2 id="BI-LAVA-Biocuration-with-Hierarchical-Image-Labeling-through-Active-Learning-and-Visual-Analysis"><a href="#BI-LAVA-Biocuration-with-Hierarchical-Image-Labeling-through-Active-Learning-and-Visual-Analysis" class="headerlink" title="BI-LAVA: Biocuration with Hierarchical Image Labeling through Active Learning and Visual Analysis"></a>BI-LAVA: Biocuration with Hierarchical Image Labeling through Active Learning and Visual Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08003">http://arxiv.org/abs/2308.08003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Trelles, Andrew Wentzel, William Berrios, G. Elisabeta Marai</li>
<li>For: 本研究用于 Addressing the challenges of creating useful datasets for biocuration in the biomedical domain, particularly the hierarchical nature of image labels, the overhead of processing images, the absence or incompleteness of labeled data, and the expertise required to label this type of data.* Methods: 本研究使用了一种 Iterative visual analytics and active learning strategy, 包括 a small set of image labels, a hierarchical set of image classifiers, and active learning to help model builders deal with incomplete ground-truth labels, target a hierarchical taxonomy of image modalities, and classify a large pool of unlabeled images.* Results: 研究表明，BI-LAVA 系统可以帮助域专家更好地理解类别内的特征，以及验证和改进数据质量在标注和未标注集合中。<details>
<summary>Abstract</summary>
In the biomedical domain, taxonomies organize the acquisition modalities of scientific images in hierarchical structures. Such taxonomies leverage large sets of correct image labels and provide essential information about the importance of a scientific publication, which could then be used in biocuration tasks. However, the hierarchical nature of the labels, the overhead of processing images, the absence or incompleteness of labeled data, and the expertise required to label this type of data impede the creation of useful datasets for biocuration. From a multi-year collaboration with biocurators and text-mining researchers, we derive an iterative visual analytics and active learning strategy to address these challenges. We implement this strategy in a system called BI-LAVA Biocuration with Hierarchical Image Labeling through Active Learning and Visual Analysis. BI-LAVA leverages a small set of image labels, a hierarchical set of image classifiers, and active learning to help model builders deal with incomplete ground-truth labels, target a hierarchical taxonomy of image modalities, and classify a large pool of unlabeled images. BI-LAVA's front end uses custom encodings to represent data distributions, taxonomies, image projections, and neighborhoods of image thumbnails, which help model builders explore an unfamiliar image dataset and taxonomy and correct and generate labels. An evaluation with machine learning practitioners shows that our mixed human-machine approach successfully supports domain experts in understanding the characteristics of classes within the taxonomy, as well as validating and improving data quality in labeled and unlabeled collections.
</details>
<details>
<summary>摘要</summary>
在生物医学领域，taxonomy 组织科学图像的获取方式在层次结构中。这些taxonomy 利用大量正确的图像标签，提供了科学公版的重要信息，可以用于生物团采工作。然而，层次性标签、处理图像的开销、标签数据的缺失或不完整、以及标签这类数据的专业知识卷积着创建有用的数据集。从多年的biocurator和文本挖掘研究人员的合作，我们 derivate了一种迭代式视觉分析和活动学习策略。我们在BI-LAVA 系统中实现了这种策略，BI-LAVA 是一个通过活动学习和迭代式视觉分析来帮助模型建立者处理部分标签、针对层次的图像模式和大量未标记图像进行分类的系统。BI-LAVA 的前端使用自定编码来表示数据分布、税onomy、图像投影和图像缩略图的邻域，这些编码帮助模型建立者探索未familiar的图像集和税onomy，并且 correction和生成标签。我们与机器学习实践者进行评估，发现我们的人机共同approach 成功地支持领域专家理解税onomy中类别的特点，以及验证和改进标签数据的质量。
</details></li>
</ul>
<hr>
<h2 id="A-physics-informed-machine-learning-model-for-reconstruction-of-dynamic-loads"><a href="#A-physics-informed-machine-learning-model-for-reconstruction-of-dynamic-loads" class="headerlink" title="A physics-informed machine learning model for reconstruction of dynamic loads"></a>A physics-informed machine learning model for reconstruction of dynamic loads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08571">http://arxiv.org/abs/2308.08571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gledson Rodrigo Tondo, Igor Kavrakov, Guido Morgenthal</li>
<li>for: 这篇论文是为了评估长 Span bridges 在不同动态刺激下的响应，以及考虑这些刺激对结构系统的影响。</li>
<li>methods: 这篇论文使用了概率Physics-informed机器学习框架，基于 Gaussian process regression 重构动力。该模型可以处理受限和杂质数据，并提供自然的衰减方法来补做测量系统中的噪声。</li>
<li>results: 这篇论文通过应用于大坝东桥的 aerodynamic 分析，计算了不同动态刺激下的响应，并使用了稀缺和噪声的测量数据来重构动力。结果显示，模型和实际应用的动力之间存在良好的一致性，并可以扩展到计算全局响应和结构内力。<details>
<summary>Abstract</summary>
Long-span bridges are subjected to a multitude of dynamic excitations during their lifespan. To account for their effects on the structural system, several load models are used during design to simulate the conditions the structure is likely to experience. These models are based on different simplifying assumptions and are generally guided by parameters that are stochastically identified from measurement data, making their outputs inherently uncertain. This paper presents a probabilistic physics-informed machine-learning framework based on Gaussian process regression for reconstructing dynamic forces based on measured deflections, velocities, or accelerations. The model can work with incomplete and contaminated data and offers a natural regularization approach to account for noise in the measurement system. An application of the developed framework is given by an aerodynamic analysis of the Great Belt East Bridge. The aerodynamic response is calculated numerically based on the quasi-steady model, and the underlying forces are reconstructed using sparse and noisy measurements. Results indicate a good agreement between the applied and the predicted dynamic load and can be extended to calculate global responses and the resulting internal forces. Uses of the developed framework include validation of design models and assumptions, as well as prognosis of responses to assist in damage detection and structural health monitoring.
</details>
<details>
<summary>摘要</summary>
长链桥受到多种动态冲击 durante 其服役寿命。为了考虑这些冲击对结构系统的影响，设计时使用多种荷载模型来模拟结构会经历的情况。这些模型基于不同的简化假设，通常受到测量数据中的参数随机 identificado 的指导。这篇文章介绍了一种基于 Gaussian process regression 的概率物理学 informed machine-learning 框架，可以根据测量到的弯曲、速度或加速度来重建动态力。该模型可以处理部分 incomplete 和污染的数据，并提供一种自然的常化方法来补做测量系统中的噪声。应用该开发的框架是大套东大桥的 aerodynamic 分析。通过 numerically 计算 quasi-steady 模型，并使用稀疏和噪声干扰的测量数据来重建动态荷载。结果表明与应用的动态荷载相比，预测的动态荷载具有良好的一致性。此外，该框架可以扩展到计算全局响应和结构内部力。用于 validate 设计模型和假设，以及诊断和结构健康监测。
</details></li>
</ul>
<hr>
<h2 id="Monte-Carlo-guided-Diffusion-for-Bayesian-linear-inverse-problems"><a href="#Monte-Carlo-guided-Diffusion-for-Bayesian-linear-inverse-problems" class="headerlink" title="Monte Carlo guided Diffusion for Bayesian linear inverse problems"></a>Monte Carlo guided Diffusion for Bayesian linear inverse problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07983">http://arxiv.org/abs/2308.07983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Cardoso, Yazid Janati El Idrissi, Sylvain Le Corff, Eric Moulines</li>
<li>for: 解决具有前向模型知识的不整合线性逆问题，从计算摄影到医学成像等多个应用领域。</li>
<li>methods: 使用得分生成模型（SGMs）生成有感知可能性的图像，尤其是填充问题。</li>
<li>results: 提出使用Sequential Monte Carlo方法解决Feynman–Kac模型的问题，并在实验中超越竞争对比方案。<details>
<summary>Abstract</summary>
Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>计算摄影和医学成像等应用中频繁出现的不整合线性逆问题，现在通过使用分数基生成模型（SGM）解决这些问题，特别是填充问题。在这种研究中，我们利用SGM中的特殊结构来设置 bayesian 框架，并将其转化为凯克-菲涅曼模型，从而解决这个凯克-菲涅曼问题。为解决这个问题，我们提议使用顺序蒙те Carlo 方法。我们称之为 MCGdiff。我们证明了这种算法的理论基础，并通过数值实验表明，它在解决不整合逆问题时表现更好于竞争对手。
</details></li>
</ul>
<hr>
<h2 id="An-Adaptive-Approach-for-Probabilistic-Wind-Power-Forecasting-Based-on-Meta-Learning"><a href="#An-Adaptive-Approach-for-Probabilistic-Wind-Power-Forecasting-Based-on-Meta-Learning" class="headerlink" title="An Adaptive Approach for Probabilistic Wind Power Forecasting Based on Meta-Learning"></a>An Adaptive Approach for Probabilistic Wind Power Forecasting Based on Meta-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07980">http://arxiv.org/abs/2308.07980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zichao Meng, Ye Guo, Hongbin Sun</li>
<li>for: This paper proposes an adaptive approach for probabilistic wind power forecasting (WPF) that includes offline and online learning procedures.</li>
<li>methods: The proposed approach uses inner and outer loop updates of meta-learning to train a base forecast model, which is then applied to online forecasting combined with incremental learning techniques.</li>
<li>results: The proposed approach is validated through numerical tests on real-world wind power data sets, and the results show that it has advantages in adaptivity compared with existing alternatives.Here is the same information in Traditional Chinese:</li>
<li>for: 这个研究提出了一个适应方法 для probabilistic wind power forecasting (WPF)，包括了线上和线下学习过程。</li>
<li>methods: 这个方法使用了内部和外部循环更新的meta-learning来训练基础预测模型，然后将基础预测模型应用到线上预测，并与增量学习技术相结合。</li>
<li>results: 研究结果透过使用实际风力资料集进行数据分析，发现这个方法在适应性方面比现有的方法有优势。<details>
<summary>Abstract</summary>
This paper studies an adaptive approach for probabilistic wind power forecasting (WPF) including offline and online learning procedures. In the offline learning stage, a base forecast model is trained via inner and outer loop updates of meta-learning, which endows the base forecast model with excellent adaptability to different forecast tasks, i.e., probabilistic WPF with different lead times or locations. In the online learning stage, the base forecast model is applied to online forecasting combined with incremental learning techniques. On this basis, the online forecast takes full advantage of recent information and the adaptability of the base forecast model. Two applications are developed based on our proposed approach concerning forecasting with different lead times (temporal adaptation) and forecasting for newly established wind farms (spatial adaptation), respectively. Numerical tests were conducted on real-world wind power data sets. Simulation results validate the advantages in adaptivity of the proposed methods compared with existing alternatives.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MultiSChuBERT-Effective-Multimodal-Fusion-for-Scholarly-Document-Quality-Prediction"><a href="#MultiSChuBERT-Effective-Multimodal-Fusion-for-Scholarly-Document-Quality-Prediction" class="headerlink" title="MultiSChuBERT: Effective Multimodal Fusion for Scholarly Document Quality Prediction"></a>MultiSChuBERT: Effective Multimodal Fusion for Scholarly Document Quality Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07971">http://arxiv.org/abs/2308.07971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gideon Maillette de Buy Wenniger, Thomas van Dongen, Lambert Schomaker</li>
<li>for: 本文旨在提高学术文献质量预测 task 的性能，特别是通过添加视觉信息来提高模型的准确率。</li>
<li>methods: 本文提出了一种多modal预测模型 MultiSChuBERT，它结合了基于块化全文文本的文本模型 SChuBERT，以及基于 Inception V3 的视觉模型。</li>
<li>results: 本文证明了以下三点：首先，将视觉和文本嵌入结合可以显著改善结果。其次，逐渐冻结视觉子模型的权重可以降低过拟合现象，提高结果。最后，使用不同的文本嵌入模型可以进一步提高结果。使用 BERT$_{\textrm{BASE}}$ 嵌入，在 ACL-BiblioMetry 数据集上的（对数）引用数预测任务中，MultiSChuBERT 模型的 $R^{2}$ 分数为 0.454，比 SChuBERT 模型（只使用文本）的 0.432 高。类似的改进也在 PeerRead 接受&#x2F;拒绝预测任务中获得。在使用 SciBERT、scincl、SPECTER 和 SPECTER2.0 嵌入时，我们发现每个这些适应嵌入都可以进一步提高模型的性能，SPECTER2.0 嵌入得最好。<details>
<summary>Abstract</summary>
Automatic assessment of the quality of scholarly documents is a difficult task with high potential impact. Multimodality, in particular the addition of visual information next to text, has been shown to improve the performance on scholarly document quality prediction (SDQP) tasks. We propose the multimodal predictive model MultiSChuBERT. It combines a textual model based on chunking full paper text and aggregating computed BERT chunk-encodings (SChuBERT), with a visual model based on Inception V3.Our work contributes to the current state-of-the-art in SDQP in three ways. First, we show that the method of combining visual and textual embeddings can substantially influence the results. Second, we demonstrate that gradual-unfreezing of the weights of the visual sub-model, reduces its tendency to ovefit the data, improving results. Third, we show the retained benefit of multimodality when replacing standard BERT$_{\textrm{BASE}}$ embeddings with more recent state-of-the-art text embedding models.   Using BERT$_{\textrm{BASE}}$ embeddings, on the (log) number of citations prediction task with the ACL-BiblioMetry dataset, our MultiSChuBERT (text+visual) model obtains an $R^{2}$ score of 0.454 compared to 0.432 for the SChuBERT (text only) model. Similar improvements are obtained on the PeerRead accept/reject prediction task. In our experiments using SciBERT, scincl, SPECTER and SPECTER2.0 embeddings, we show that each of these tailored embeddings adds further improvements over the standard BERT$_{\textrm{BASE}}$ embeddings, with the SPECTER2.0 embeddings performing best.
</details>
<details>
<summary>摘要</summary>
自动评估学术文献质量是一项具有高潜在影响力的任务。在特定的情况下，通过添加视觉信息与文本信息一起进行评估，可以提高学术文献质量预测（SDQP）任务的性能。我们提出了多模态预测模型MultiSChuBERT，它将文本模型基于分割全文本并聚合计算的BERT块编码（SChuBERT）与视觉模型基于Inception V3.0结合。我们的工作对现有状态的SDQP进行了贡献。首先，我们发现将视觉和文本嵌入结合的方法可以对结果产生显著影响。其次，我们示出了逐渐冰结视觉子模型的重量的方法可以降低它们的预测倾向，提高结果。最后，我们发现在使用更新的文本嵌入模型而不是标准BERT$_{\textrm{BASE}}$嵌入时，多模态性仍然保留着其优势。使用BERT$_{\textrm{BASE}}$嵌入，我们的MultiSChuBERT（文本+视觉）模型在ACL-BiblioMetry数据集上的（对数）引用数预测任务中，obtained an $R^{2}$ score of 0.454，比SChuBERT（文本只）模型的0.432高。类似的改进也在PeerRead Accept/Reject预测任务中被获得。在我们使用SciBERT、scincl、SPECTER和SPECTER2.0嵌入时，我们发现每个这些适应嵌入都可以进一步提高标准BERT$_{\textrm{BASE}}$嵌入的性能，SPECTER2.0嵌入表现最佳。
</details></li>
</ul>
<hr>
<h2 id="RAVEN-In-Context-Learning-with-Retrieval-Augmented-Encoder-Decoder-Language-Models"><a href="#RAVEN-In-Context-Learning-with-Retrieval-Augmented-Encoder-Decoder-Language-Models" class="headerlink" title="RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models"></a>RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07922">http://arxiv.org/abs/2308.07922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Huang, Wei Ping, Peng Xu, Mohammad Shoeybi, Kevin Chen-Chuan Chang, Bryan Catanzaro</li>
<li>for:  investigate the in-context learning ability of retrieval-augmented encoder-decoder language models</li>
<li>methods:  combines retrieval-augmented masked language modeling and prefix language modeling, and introduces Fusion-in-Context Learning to enhance the few-shot performance</li>
<li>results:  significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters<details>
<summary>Abstract</summary>
In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of the state-of-the-art ATLAS model and identify its limitations in in-context learning, primarily due to a mismatch between pretraining and testing, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training or model modifications. Through extensive experiments, we demonstrate that RAVEN significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder language models for in-context learning and encourages further research in this direction.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们 investigate retrieval-augmented encoder-decoder语言模型的在语言上下文中学习能力。我们首先对现有的ATLAS模型进行了全面的分析，并发现其在语言上下文中学习时存在一些限制，主要是因为预训练和测试集的匹配度不高，以及上下文长度的限制。为了解决这些问题，我们提议了RAVEN模型，该模型结合了检索支持的隐藏语言模型和前缀语言模型。我们还提出了Context-Aware Fusion Learning，以便通过在语言上下文中充分利用更多的示例来提高几个步骤性能，无需进行额外训练或模型修改。通过广泛的实验，我们证明了RAVEN模型可以在某些情况下明显超越ATLAS模型，并达到与最先进的语言模型相当的性能，即使RAVEN模型具有许多更少的参数。我们的工作论证了 retrieval-augmented encoder-decoder语言模型在语言上下文中学习的潜力，并鼓励进一步的研究在这个方向上。
</details></li>
</ul>
<hr>
<h2 id="The-Regular-Expression-Inference-Challenge"><a href="#The-Regular-Expression-Inference-Challenge" class="headerlink" title="The Regular Expression Inference Challenge"></a>The Regular Expression Inference Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07899">http://arxiv.org/abs/2308.07899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojtaba Valizadeh, Philip John Gorinski, Ignacio Iacobacci, Martin Berger</li>
<li>for: 这paper是为了挑战code&#x2F;语言模型领域中的一个挑战任务，即常见表达式推理（REI）问题。</li>
<li>methods: 这paper使用了Program Synthesis技术和GPU来实现REI问题的解决方案。</li>
<li>results: 这paper首次生成了复杂REI实例的最小表达式，并发布了大规模的REI数据集。此外，paper还提出了一些初步的机器学习基线和优化策略。<details>
<summary>Abstract</summary>
We propose \emph{regular expression inference (REI)} as a challenge for code/language modelling, and the wider machine learning community. REI is a supervised machine learning (ML) and program synthesis task, and poses the problem of finding minimal regular expressions from examples: Given two finite sets of strings $P$ and $N$ and a cost function $\text{cost}(\cdot)$, the task is to generate an expression $r$ that accepts all strings in $P$ and rejects all strings in $N$, while no other such expression $r'$ exists with $\text{cost}(r')<\text{cost}(r)$.   REI has advantages as a challenge problem: (i) regular expressions are well-known, widely used, and a natural idealisation of code; (ii) REI's asymptotic worst-case complexity is well understood; (iii) REI has a small number of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string lengths of examples, or the cost function); this lets us easily finetune REI-hardness; (iv) REI is an unsolved problem for deep learning based ML.   Recently, an REI solver was implemented on GPUs, using program synthesis techniques. This enabled, for the first time, fast generation of minimal expressions for complex REI instances. Building on this advance, we generate and publish the first large-scale datasets for REI, and devise and evaluate several initial heuristic and machine learning baselines.   We invite the community to participate and explore ML methods that learn to solve REI problems. We believe that progress in REI directly translates to code/language modelling.
</details>
<details>
<summary>摘要</summary>
我们提议“常量表示法（REI）”作为代码/语言模型领域的挑战，并且广泛的机器学习社群。 REI 是一个监督式机器学习（ML）和程式生成任务，需要寻找最小的常量表示法，以满足以下需求： giventwo个有限集合 $P$ 和 $N$，以及一个成本函数 $\text{cost}(\cdot)$，任务是生成一个表示法 $r$，使得 $r$ 接受所有 $P$ 中的字串，并且拒绝所有 $N$ 中的字串，而不是其他任何表示法 $r'$，使得 $\text{cost}(r') < \text{cost}(r)$。REI 有以下优点作为挑战问题：1. 常量表示法是广泛使用的、具有自然化的代码理想化；2. REI 的极限最坏情况复杂度很好地理解；3. REI 只有很少的容易理解的参数（例如 $P$ 或 $N$ 的卡дина特数、字串示例的长度、或成本函数），这让我们可以轻松地调整 REI 的困难度；4. REI 是深度学习基于 ML 的未解决问题。最近，一个 REI 解决方案在 GPU 上被实现，使用程式生成技术。这使得， для 首次可以快速生成复杂的 REI 问题中的最小表示法。基于这个进步，我们组建了第一个大规模的 REI 数据集，并设计了一些初步的变数和机器学习基线。我们邀请社区参与，探索 ML 方法，以解决 REI 问题。我们相信，REI 的进步将直接对代码/语言模型领域产生影响。
</details></li>
</ul>
<hr>
<h2 id="SciRE-Solver-Efficient-Sampling-of-Diffusion-Probabilistic-Models-by-Score-integrand-Solver-with-Recursive-Derivative-Estimation"><a href="#SciRE-Solver-Efficient-Sampling-of-Diffusion-Probabilistic-Models-by-Score-integrand-Solver-with-Recursive-Derivative-Estimation" class="headerlink" title="SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation"></a>SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07896">http://arxiv.org/abs/2308.07896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shigui Li, Wei Chen, Delu Zeng</li>
<li>for: 这篇论文是为了提出一种高效的推 diffusion probabilistic models（DPMs）采样算法。</li>
<li>methods: 该论文使用了一种新的score-based exact solution paradigm，以及一种 recursive derivative estimation（RDE）方法，以提高采样速度。</li>
<li>results: 该论文通过使用score-integrand solver with convergence order guarantee（SciRE-Solver），实现了高效的采样性能，并在CIFAR10和CelebA 64×64上达到了state-of-the-art（SOTA）水平。 Specifically, it achieved $3.48$ FID with $12$ NFE and $2.42$ FID with $20$ NFE for continuous-time DPMs on CIFAR10, and $2.17$ ($2.02$) FID with $18$ ($50$) NFE for discrete-time DPM on CelebA 64×64.<details>
<summary>Abstract</summary>
Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs in comparison to existing training-free sampling algorithms. Such as, we achieve $3.48$ FID with $12$ NFE and $2.42$ FID with $20$ NFE for continuous-time DPMs on CIFAR10, respectively. Different from other samplers, SciRE-Solver has the promising potential to surpass the FIDs achieved in the original papers of some pre-trained models with a small NFEs. For example, we reach SOTA value of $2.40$ FID with $100$ NFE for continuous-time DPM and of $3.15$ FID with $84$ NFE for discrete-time DPM on CIFAR-10, as well as of $2.17$ ($2.02$) FID with $18$ ($50$) NFE for discrete-time DPM on CelebA 64$\times$64.
</details>
<details>
<summary>摘要</summary>
Diffusion probabilistic models (DPMs) 是一种强大的生成模型，能够生成高质量的图像样本。然而，在实现DPMs时，一个主要挑战是慢的采样过程。在这种情况下，我们提出了一种高效的采样方法。具体来说，我们提出了基于分布解决方法的高效采样方法，该方法可以减少采样过程中的估计误差。为了实现高效采样，我们提出了一种可重复的 derive 估计方法（RDE），该方法可以减少估计误差。通过我们的提出的解法和RDE方法，我们提出了一种高效的分布解决方法（SciRE-Solver），该方法可以高效地解决Diffusion ODEs。SciRE-Solver 可以在不同的时间分辨率下实现高效的采样，并且可以在有限的分布解决方法中实现高质量的采样。例如，我们在 CIFAR10 上实现了 $3.48$ FID 的值，只需要 $12$ NFE，并且在 continuous-time DPMs 上实现了 $2.42$ FID 的值，只需要 $20$ NFE。与其他采样器不同，SciRE-Solver 具有可能超越原始模型中的 FID 的潜在能力。例如，我们在 continuous-time DPMs 上实现了 $2.40$ FID 的值，只需要 $100$ NFE，并在 discrete-time DPMs 上实现了 $3.15$ FID 的值，只需要 $84$ NFE。此外，我们还在 CelebA 64$\times$64 上实现了 $2.17$ ($2.02$) FID 的值，只需要 $18$ ($50$) NFE。
</details></li>
</ul>
<hr>
<h2 id="On-regularized-Radon-Nikodym-differentiation"><a href="#On-regularized-Radon-Nikodym-differentiation" class="headerlink" title="On regularized Radon-Nikodym differentiation"></a>On regularized Radon-Nikodym differentiation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07887">http://arxiv.org/abs/2308.07887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duc Hoan Nguyen, Werner Zellinger, Sergei V. Pereverzyev</li>
<li>for: 解决Radon-NikodymDerivatives估计问题，这个问题在各种应用中出现，如covariate shift适应、likelihood-ratio测试、mutual information估计和conditional probability估计中。</li>
<li>methods: 使用通用正则化方案在 reproduce kernel Hilbert space中进行估计。</li>
<li>results:  estabilish了估计Derivatives的收敛率，并且可以在特定点进行高精度的重建。<details>
<summary>Abstract</summary>
We discuss the problem of estimating Radon-Nikodym derivatives. This problem appears in various applications, such as covariate shift adaptation, likelihood-ratio testing, mutual information estimation, and conditional probability estimation. To address the above problem, we employ the general regularization scheme in reproducing kernel Hilbert spaces. The convergence rate of the corresponding regularized algorithm is established by taking into account both the smoothness of the derivative and the capacity of the space in which it is estimated. This is done in terms of general source conditions and the regularized Christoffel functions. We also find that the reconstruction of Radon-Nikodym derivatives at any particular point can be done with high order of accuracy. Our theoretical results are illustrated by numerical simulations.
</details>
<details>
<summary>摘要</summary>
我们讨论类 Radon-Nikodym Derivative 的估计问题。这个问题在不同的应用中出现，例如对应拓扑变化、对应拓扑测试、共轨信息估计以及 conditional probability 估计。为了解决上述问题，我们使用通用的常数化方案在 reproduce kernel 空间中实现。我们证明了这个常数化算法的数据速度，通过考虑 derivative 的平滑性和估计空间的容量。此外，我们还发现了在特定点进行 Radon-Nikodym Derivative 的重建可以实现高精度。我们的理论成果通过数学模拟来描述。
</details></li>
</ul>
<hr>
<h2 id="Back-to-Basics-A-Sanity-Check-on-Modern-Time-Series-Classification-Algorithms"><a href="#Back-to-Basics-A-Sanity-Check-on-Modern-Time-Series-Classification-Algorithms" class="headerlink" title="Back to Basics: A Sanity Check on Modern Time Series Classification Algorithms"></a>Back to Basics: A Sanity Check on Modern Time Series Classification Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07886">http://arxiv.org/abs/2308.07886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlgig/tabularmodelsfortsc">https://github.com/mlgig/tabularmodelsfortsc</a></li>
<li>paper_authors: Bhaskar Dhariyal, Thach Le Nguyen, Georgiana Ifrim</li>
<li>for: 本研究旨在评估时序分类领域的基本参照模型，以及与现代时序分类算法相比较。</li>
<li>methods: 本研究使用了简单的表格模型（如ridge、LDA、RandomForest）和ROCKET家族的时序分类算法（如Rocket、MiniRocket、MultiRocket）进行比较。</li>
<li>results: 结果表明，表格模型在大约19%的单变量 dataset和28%的多变量 dataset上表现较为出色，并在大约50%的 dataset 上达到了准确率的10个百分点。这些结果表明，在开发时序分类算法时，需要考虑基本的表格模型作为参照。这些模型快速、简单、可能更容易理解和部署。<details>
<summary>Abstract</summary>
The state-of-the-art in time series classification has come a long way, from the 1NN-DTW algorithm to the ROCKET family of classifiers. However, in the current fast-paced development of new classifiers, taking a step back and performing simple baseline checks is essential. These checks are often overlooked, as researchers are focused on establishing new state-of-the-art results, developing scalable algorithms, and making models explainable. Nevertheless, there are many datasets that look like time series at first glance, but classic algorithms such as tabular methods with no time ordering may perform better on such problems. For example, for spectroscopy datasets, tabular methods tend to significantly outperform recent time series methods. In this study, we compare the performance of tabular models using classic machine learning approaches (e.g., Ridge, LDA, RandomForest) with the ROCKET family of classifiers (e.g., Rocket, MiniRocket, MultiRocket). Tabular models are simple and very efficient, while the ROCKET family of classifiers are more complex and have state-of-the-art accuracy and efficiency among recent time series classifiers. We find that tabular models outperform the ROCKET family of classifiers on approximately 19% of univariate and 28% of multivariate datasets in the UCR/UEA benchmark and achieve accuracy within 10 percentage points on about 50% of datasets. Our results suggest that it is important to consider simple tabular models as baselines when developing time series classifiers. These models are very fast, can be as effective as more complex methods and may be easier to understand and deploy.
</details>
<details>
<summary>摘要</summary>
现代时序分类技术已经发展到了非常高水平，从1NN-DTW算法到ROCKET家族的分类器。然而，在当前的快速发展新的分类器，回退并执行简单的基准检查是必要的。这些检查经常被忽略，因为研究人员正在寻求新的state-of-the-art结果，开发可扩展的算法，并使模型更加可解释。然而，有很多数据集看起来像时序数据，但经典算法如表格方法无时间顺序可能在这些问题上表现更好。例如，对于光谱数据集，表格方法通常在近期时间系列方法之上表现出色。在这种研究中，我们比较了使用经典机器学习方法（例如ridge、LDA、RandomForest）的表格模型与ROCKET家族的分类器（例如Rocket、MiniRocket、MultiRocket）的性能。表格模型简单而高效，而ROCKET家族的分类器更加复杂，在最近的时序分类器中具有state-of-the-art的准确率和效率。我们发现，在UCRLUEA标准测试集上，表格模型比ROCKET家族的分类器在约19%的单variate数据集和28%的多variate数据集上表现出色，并在约50%的数据集上达到了准确率在10个百分点之间。我们的结果表明，在开发时序分类器时，应该考虑使用简单的表格模型作为基准。这些模型很快速，可以与更复杂的方法相比，并且可能更易于理解和部署。
</details></li>
</ul>
<hr>
<h2 id="The-Challenge-of-Fetal-Cardiac-MRI-Reconstruction-Using-Deep-Learning"><a href="#The-Challenge-of-Fetal-Cardiac-MRI-Reconstruction-Using-Deep-Learning" class="headerlink" title="The Challenge of Fetal Cardiac MRI Reconstruction Using Deep Learning"></a>The Challenge of Fetal Cardiac MRI Reconstruction Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07885">http://arxiv.org/abs/2308.07885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Prokopenko, Kerstin Hammernik, Thomas Roberts, David F A Lloyd, Daniel Rueckert, Joseph V Hajnal<br>for:* The paper aims to improve the quality of non-gated kt-SENSE reconstruction for dynamic free-breathing fetal cardiac MRI using deep learning methods.methods:* The authors use supervised deep learning networks to recover fully-sampled data from undersampled data, and explore various model architectures and training strategies.results:* The best-performing models recover a detailed depiction of the maternal anatomy but underestimate the dynamic properties of the fetal heart, suggesting the need for more targeted training and evaluation methods.<details>
<summary>Abstract</summary>
Dynamic free-breathing fetal cardiac MRI is one of the most challenging modalities, which requires high temporal and spatial resolution to depict rapid changes in a small fetal heart. The ability of deep learning methods to recover undersampled data could help to optimise the kt-SENSE acquisition strategy and improve non-gated kt-SENSE reconstruction quality. In this work, we explore supervised deep learning networks for reconstruction of kt-SENSE style acquired data using an extensive in vivo dataset. Having access to fully-sampled low-resolution multi-coil fetal cardiac MRI, we study the performance of the networks to recover fully-sampled data from undersampled data. We consider model architectures together with training strategies taking into account their application in the real clinical setup used to collect the dataset to enable networks to recover prospectively undersampled data. We explore a set of modifications to form a baseline performance evaluation for dynamic fetal cardiac MRI on real data. We systematically evaluate the models on coil-combined data to reveal the effect of the suggested changes to the architecture in the context of fetal heart properties. We show that the best-performers recover a detailed depiction of the maternal anatomy on a large scale, but the dynamic properties of the fetal heart are under-represented. Training directly on multi-coil data improves the performance of the models, allows their prospective application to undersampled data and makes them outperform CTFNet introduced for adult cardiac cine MRI. However, these models deliver similar qualitative performances recovering the maternal body very well but underestimating the dynamic properties of fetal heart. This dynamic feature of fast change of fetal heart that is highly localised suggests both more targeted training and evaluation methods might be needed for fetal heart application.
</details>
<details>
<summary>摘要</summary>
“动态自由呼吸幼儿心脏MRI是最复杂的modalities，需要高度的时间和空间分辨率来描述幼儿心脏的快速变化。深度学习方法可以回归不完全探测的数据，可以帮助优化kt-SENSE数据获取策略，提高非阻塞kt-SENSE重建质量。在这种工作中，我们使用了supervised深度学习网络来重建kt-SENSE风格获取的数据，使用了大量的生物实验室数据。由于我们拥有完整的低分辨率多极心脏MRI数据，我们研究了网络可以从不完整的数据中恢复完整的数据的性能。我们考虑了模型架构和训练策略，以便在实际临床设置中收集数据时使用。我们系统地评估了模型在实际数据上的性能，并对幼儿心脏属性进行了修改。我们发现最佳performer可以呈现出详细的 maternal anatomy，但是幼儿心脏的动态特性受到了下降。通过直接训练多极数据，我们可以使模型预测不完整的数据，并且其性能高于CTFNet。但是，这些模型在恢复 maternal body 方面表现良好，而幼儿心脏的动态特性方面表现较差。这种快速变化的幼儿心脏特性表示需要更加targeted的训练和评估方法。”
</details></li>
</ul>
<hr>
<h2 id="A-Trustable-LSTM-Autoencoder-Network-for-Cyberbullying-Detection-on-Social-Media-Using-Synthetic-Data"><a href="#A-Trustable-LSTM-Autoencoder-Network-for-Cyberbullying-Detection-on-Social-Media-Using-Synthetic-Data" class="headerlink" title="A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data"></a>A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on Social Media Using Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09722">http://arxiv.org/abs/2308.09722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mst Shapna Akter, Hossain Shahriar, Alfredo Cuzzocrea<br>for: This paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection on social media using synthetic data.methods: The proposed model uses a combination of Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models.results: The proposed model outperformed all the models on all datasets, achieving the highest accuracy of 95%.<details>
<summary>Abstract</summary>
Social media cyberbullying has a detrimental effect on human life. As online social networking grows daily, the amount of hate speech also increases. Such terrible content can cause depression and actions related to suicide. This paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection on social media using synthetic data. We have demonstrated a cutting-edge method to address data availability difficulties by producing machine-translated data. However, several languages such as Hindi and Bangla still lack adequate investigations due to a lack of datasets. We carried out experimental identification of aggressive comments on Hindi, Bangla, and English datasets using the proposed model and traditional models, including Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models. We employed evaluation metrics such as f1-score, accuracy, precision, and recall to assess the models performance. Our proposed model outperformed all the models on all datasets, achieving the highest accuracy of 95%. Our model achieves state-of-the-art results among all the previous works on the dataset we used in this paper.
</details>
<details>
<summary>摘要</summary>
社交媒体恐吓行为对人类生活产生负面影响。随着在线社交网络日益增长，讨厌言语也在不断增加。这种厉害的内容可能导致抑郁和自杀行为。本文提议一种可靠的LSTM-Autoencoder网络，用于社交媒体上的恐吓行为检测。我们通过生成机器翻译数据来解决数据可用性问题。然而，一些语言，如希ن第和孟加拉语，仍然缺乏足够的调查，因为数据不足。我们使用提议模型和传统模型，包括LSTM、BiLSTM、LSTM-Autoencoder、Word2vec、BERT和GPT-2模型，进行实验 indentification of aggressive comments。我们使用f1-score、准确率、精度和回归来评估模型的表现。我们的提议模型在所有数据集上都表现出优于所有其他模型，具有最高准确率95%。我们的模型在所有前一个工作中达到了状态 искусственный智能的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Towards-Temporal-Edge-Regression-A-Case-Study-on-Agriculture-Trade-Between-Nations"><a href="#Towards-Temporal-Edge-Regression-A-Case-Study-on-Agriculture-Trade-Between-Nations" class="headerlink" title="Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations"></a>Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07883">http://arxiv.org/abs/2308.07883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scylj1/gnn_edge_regression">https://github.com/scylj1/gnn_edge_regression</a></li>
<li>paper_authors: Lekang Jiang, Caiqi Zhang, Farimah Poursafaei, Shenyang Huang</li>
<li>for: 预测国际贸易数据中的边值（edge regression）任务，特别是在静态和动态图中。</li>
<li>methods: 使用图神经网络（Graph Neural Networks，GNNs）模型进行预测，并 introduce three simple yet strong baselines。</li>
<li>results: 实验结果显示baselines在不同设置下表现极其出色，而TGN模型在edge regression任务中表现更好，并且发现训练样本中负边的比例对测试性能产生了重要的影响。<details>
<summary>Abstract</summary>
Recently, Graph Neural Networks (GNNs) have shown promising performance in tasks on dynamic graphs such as node classification, link prediction and graph regression. However, few work has studied the temporal edge regression task which has important real-world applications. In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations. We introduce three simple yet strong baselines and comprehensively evaluate one static and three dynamic GNN models using the UN Trade dataset. Our experimental results reveal that the baselines exhibit remarkably strong performance across various settings, highlighting the inadequacy of existing GNNs. We also find that TGN outperforms other GNN models, suggesting TGN is a more appropriate choice for edge regression tasks. Moreover, we note that the proportion of negative edges in the training samples significantly affects the test performance. The companion source code can be found at: https://github.com/scylj1/GNN_Edge_Regression.
</details>
<details>
<summary>摘要</summary>
最近，图 neck Networks (GNNs) 在动态图上的任务中表现出色，包括节点分类、链接预测和图回归。然而，对于时间Edge regression任务，有很少的研究。在这篇论文中，我们探索了 GNNs 在静态和动态设置下的边 regression 任务，特点是预测国家之间的食品和农业贸易值。我们提出了三种简单又强大的基线，并对一个静态和三个动态 GNN 模型进行了广泛的测试，使用 UN Trade 数据集。我们的实验结果表明，基elines 在不同设置下具有极强表现，这 highlights 现有 GNNs 的不足。此外，我们发现 TGN 在边 regression 任务中表现出色， suggesting TGN 是更适合的选择。同时，我们注意到训练样本中负边的比例对测试性能产生了显著影响。相关的源代码可以在 GitHub 上找到：https://github.com/scylj1/GNN_Edge_Regression。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Political-Zero-Shot-Relation-Classification-via-Codebook-Knowledge-NLI-and-ChatGPT"><a href="#Synthesizing-Political-Zero-Shot-Relation-Classification-via-Codebook-Knowledge-NLI-and-ChatGPT" class="headerlink" title="Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT"></a>Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07876">http://arxiv.org/abs/2308.07876</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snowood1/zero-shot-plover">https://github.com/snowood1/zero-shot-plover</a></li>
<li>paper_authors: Yibo Hu, Erick Skorupa Parolin, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito J. D’Orazio</li>
<li>for: 这 paper 的目的是提高政治事件代码分类的精度和效率，并利用现有的专家数据库中的知识来避免新的注释创建。</li>
<li>methods: 这 paper 使用了 Zero-shot 方法和自然语言推理（NLI）方法，其中 ZSP 方法采用了树查询框架来解决分类任务中的上下文、模式和类别划分等问题。</li>
<li>results: 经过广泛的实验研究，ZSP 方法在我们新建的数据集上达到了40%的 F1 分数提升，与超级vised BERT 模型的性能相当。这表明 ZSP 方法可以作为政治事件记录验证和 ontology 发展的有价值工具。<details>
<summary>Abstract</summary>
Recent supervised models for event coding vastly outperform pattern-matching methods. However, their reliance solely on new annotations disregards the vast knowledge within expert databases, hindering their applicability to fine-grained classification. To address these limitations, we explore zero-shot approaches for political event ontology relation classification, by leveraging knowledge from established annotation codebooks. Our study encompasses both ChatGPT and a novel natural language inference (NLI) based approach named ZSP. ZSP adopts a tree-query framework that deconstructs the task into context, modality, and class disambiguation levels. This framework improves interpretability, efficiency, and adaptability to schema changes. By conducting extensive experiments on our newly curated datasets, we pinpoint the instability issues within ChatGPT and highlight the superior performance of ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained Rootcode classification. ZSP demonstrates competitive performance compared to supervised BERT models, positioning it as a valuable tool for event record validation and ontology development. Our work underscores the potential of leveraging transfer learning and existing expertise to enhance the efficiency and scalability of research in the field.
</details>
<details>
<summary>摘要</summary>
最近的监督模型对事件编码表现出色，但它们完全依赖于新的注释，忽略了专家数据库中的庞大知识，这限制了它们的应用范围。为了解决这些局限性，我们explore零批处理方法 для政治事件 ontology 关系分类，利用专家注释代码库中的知识。我们的研究包括ChatGPT和一种基于自然语言推理（NLI）的新方法 named ZSP。ZSP采用树查询框架，将任务分解成上下文、模式和分类层次。这种框架提高了可读性、效率和 schema 变化的适应能力。通过对我们新划分的数据集进行广泛的实验，我们揭示了 ChatGPT 中的不稳定性问题，并 highlight了 ZSP 的显著性能优势。ZSP 在细化的 Rootcode 分类任务中实现了40%的提升。ZSP 与超级vised BERT模型的性能相当，这positioned它作为事件记录验证和 ontology 发展的有价值工具。我们的工作强调了利用传输学习和现有专业知识来提高研究领域的效率和扩展性。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Embeddings-unicode-x2014-Learning-Stable-and-Homogeneous-Abstractions-from-Heterogeneous-Affective-Datasets"><a href="#Emotion-Embeddings-unicode-x2014-Learning-Stable-and-Homogeneous-Abstractions-from-Heterogeneous-Affective-Datasets" class="headerlink" title="Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets"></a>Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07871">http://arxiv.org/abs/2308.07871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Buechel, Udo Hahn<br>for:这篇论文的目的是提出一种可以独立地学习和拟合不同自然语言、交流Modalities、媒体和表示标签格式的计算模型，以实现情感分析领域的共享表示和可重用性。methods:该论文使用了一种训练程序，通过学习共享的 latent 表示来捕捉情感的多样性，无论是在不同的自然语言、交流Modalities、媒体或表示标签格式中。results:实验表明，该方法可以在各种不同的情感数据集上实现预测质量的稳定和可重用性，而无需拘束到特定的语言、Modalities、媒体或表示标签格式。Code和数据都已经被存储在 <a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.7405327">https://doi.org/10.5281/zenodo.7405327</a> 上。<details>
<summary>Abstract</summary>
Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label formats, and even disparate model architectures. Experiments on a wide range of heterogeneous affective datasets indicate that this approach yields the desired interoperability for the sake of reusability, interpretability and flexibility, without penalizing prediction quality. Code and data are archived under https://doi.org/10.5281/zenodo.7405327 .
</details>
<details>
<summary>摘要</summary>
人类情感表达在多种通信modalities和媒体格式中表现出来，因此计算研究也是多样化的，包括自然语言处理、音频信号分析、计算机视觉等。在过去的研究中，用于描述情感的多种格式（如偏好级别、基本情绪类别、维度方法、评估理论等）导致了对情感分析的数据和预测模型的总体化，以至于现在的数据和标签类型在不断演化。为了解决这两种不同的多样性，我们提出一种统一的计算模型。我们提议一种培训过程，通过学习情感的共享幂等 représentation来独立于不同的自然语言、通信modalities、媒体或表达标签格式，甚至不同的模型架构。实验表明，这种方法可以实现数据和标签类型之间的可 reuse、可读性和灵活性，无需增加预测质量的减少。代码和数据可以在https://doi.org/10.5281/zenodo.7405327中找到。
</details></li>
</ul>
<hr>
<h2 id="Brain-Inspired-Computational-Intelligence-via-Predictive-Coding"><a href="#Brain-Inspired-Computational-Intelligence-via-Predictive-Coding" class="headerlink" title="Brain-Inspired Computational Intelligence via Predictive Coding"></a>Brain-Inspired Computational Intelligence via Predictive Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07870">http://arxiv.org/abs/2308.07870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Salvatori, Ankur Mali, Christopher L. Buckley, Thomas Lukasiewicz, Rajesh P. N. Rao, Karl Friston, Alexander Ororbia</li>
<li>for: 这篇论文旨在探讨使用Predictive Coding（PC）理论来解决深度神经网络的限制，以提高机器学习的效果。</li>
<li>methods: 本论文使用Literature survey方法，浏览了 relate to PC 的文献，并 highlighted its potential applications in machine learning and computational intelligence。</li>
<li>results: 论文表明，PC 可以用于模型脑内信息处理，可以应用于认知控制和机器人学习，并具有强大的数学基础，可以用于特定类型的连续状态生成模型的倒逼算法。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a powerful inversion scheme for a specific class of continuous-state generative models. With the hope of foregrounding research in this direction, we survey the literature that has contributed to this perspective, highlighting the many ways that PC might play a role in the future of machine learning and computational intelligence at large.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在这个世纪快速成为一个关键技术。目前大多数AI成果都是使用深度神经网络和错误反射学习算法获得的。然而，这种广泛采用的方法存在一些重要的限制，如计算成本很高、难以量化不确定性、缺乏可靠性和生物可能性。可能需要采用基于神经科学理论的方案来解决这些限制。一种如此理论是预测编码（PC），它在机器智能任务中表现出了惊喜性，并且具有可能为机器学习社区提供价值的特性：PC可以模型不同脑区的信息处理方式，可以应用于认知控制和机器人学习，并且具有强制VARIATIONAL推理的数学基础，可以为某些连续状态生成模型提供强大的逆转计划。希望通过这篇文章，推动研究人员对这个视角的研究，并强调PC在未来机器学习和计算智能中的潜在作用。
</details></li>
</ul>
<hr>
<h2 id="Graph-Structured-Kernel-Design-for-Power-Flow-Learning-using-Gaussian-Processes"><a href="#Graph-Structured-Kernel-Design-for-Power-Flow-Learning-using-Gaussian-Processes" class="headerlink" title="Graph-Structured Kernel Design for Power Flow Learning using Gaussian Processes"></a>Graph-Structured Kernel Design for Power Flow Learning using Gaussian Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07867">http://arxiv.org/abs/2308.07867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parikshit Pareek, Deepjyoti Deka, Sidhant Misra</li>
<li>for: 这种physics-inspired graph-structured kernel是用于电流流行学习的Gaussian Process（GP）中的一种kernel，旨在利用网络图或结构来抽象Voltage-injection关系的latent decomposition。</li>
<li>methods: 这种kernel被称为 vertex-degree kernel（VDK），它不需要解决优化问题来搜索kernel。此外，我们还提出了一种图缩 Representation with fewer terms，以提高效率。</li>
<li>results: 对于500-Bus和1354-Bus电力系统，我们的VDK-GP方法可以在样本复杂性方面减少超过两倍，相比于全GP。此外，我们的网络滑块活动学习算法可以在测试预测中超过mean Performance of 500 Random Trials by two fold for medium-sized 500-Bus systems and best performance of 25 random trials for large-scale 1354-Bus systems by 10%.<details>
<summary>Abstract</summary>
This paper presents a physics-inspired graph-structured kernel designed for power flow learning using Gaussian Process (GP). The kernel, named the vertex-degree kernel (VDK), relies on latent decomposition of voltage-injection relationship based on the network graph or topology. Notably, VDK design avoids the need to solve optimization problems for kernel search. To enhance efficiency, we also explore a graph-reduction approach to obtain a VDK representation with lesser terms. Additionally, we propose a novel network-swipe active learning scheme, which intelligently selects sequential training inputs to accelerate the learning of VDK. Leveraging the additive structure of VDK, the active learning algorithm performs a block-descent type procedure on GP's predictive variance, serving as a proxy for information gain. Simulations demonstrate that the proposed VDK-GP achieves more than two fold sample complexity reduction, compared to full GP on medium scale 500-Bus and large scale 1354-Bus power systems. The network-swipe algorithm outperforms mean performance of 500 random trials on test predictions by two fold for medium-sized 500-Bus systems and best performance of 25 random trials for large-scale 1354-Bus systems by 10%. Moreover, we demonstrate that the proposed method's performance for uncertainty quantification applications with distributionally shifted testing data sets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Impression-Aware-Recommender-Systems"><a href="#Impression-Aware-Recommender-Systems" class="headerlink" title="Impression-Aware Recommender Systems"></a>Impression-Aware Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07857">http://arxiv.org/abs/2308.07857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando B. Pérez Maurera, Maurizio Ferrari Dacrema, Pablo Castells, Paolo Cremonesi</li>
<li>for: 本研究旨在探讨基于印象（过去推荐的项目）的 recommender system 的开发和应用，以提高推荐系统的质量。</li>
<li>methods: 本文使用系统性文献综述方法，对各种推荐系统使用印象的研究进行分类和详细介绍，同时还总结了不同的数据集和评价方法。</li>
<li>results: 本文通过对各种推荐系统使用印象的研究进行分类和详细介绍，掌握了各种研究的方法和结论，并发现了一些未在文献中提到的问题和未来研究方向。<details>
<summary>Abstract</summary>
Novel data sources bring new opportunities to improve the quality of recommender systems. Impressions are a novel data source containing past recommendations (shown items) and traditional interactions. Researchers may use impressions to refine user preferences and overcome the current limitations in recommender systems research. The relevance and interest of impressions have increased over the years; hence, the need for a review of relevant work on this type of recommenders. We present a systematic literature review on recommender systems using impressions, focusing on three fundamental angles in research: recommenders, datasets, and evaluation methodologies. We provide three categorizations of papers describing recommenders using impressions, present each reviewed paper in detail, describe datasets with impressions, and analyze the existing evaluation methodologies. Lastly, we present open questions and future directions of interest, highlighting aspects missing in the literature that can be addressed in future works.
</details>
<details>
<summary>摘要</summary>
新的数据源带来了改善推荐系统质量的新机会。印象是一种新的数据源，包含过去的推荐（显示的项目）和传统的交互。研究人员可以使用印象来细化用户的偏好，超越当前推荐系统研究的限制。随着年代的推移，印象的相关性和兴趣度也在增长，因此需要对这类推荐系统的研究进行系统atic literature review。本文对推荐系统使用印象进行系统atic literature review，将研究分为三个基本的视角：推荐器、数据集和评估方法ологи。我们对每篇评论细节描述、介绍数据集，并分析现有的评估方法ологи。最后，我们提出了未解决的问题和未来方向，强调文献中缺失的方面，可以在未来的研究中解决。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/cs.LG_2023_08_16/" data-id="clly4xtdx006vvl8890e9aez8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/cs.SD_2023_08_16/" class="article-date">
  <time datetime="2023-08-15T16:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/cs.SD_2023_08_16/">cs.SD - 2023-08-16 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mitigating-the-Exposure-Bias-in-Sentence-Level-Grapheme-to-Phoneme-G2P-Transduction"><a href="#Mitigating-the-Exposure-Bias-in-Sentence-Level-Grapheme-to-Phoneme-G2P-Transduction" class="headerlink" title="Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction"></a>Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08442">http://arxiv.org/abs/2308.08442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eunseop Yoon, Hee Suk Yoon, Dhananjaya Gowda, SooHwan Eom, Daehyeok Kim, John Harvill, Heting Gao, Mark Hasegawa-Johnson, Chanwoo Kim, Chang D. Yoo</li>
<li>for: 这个论文是为了提高文本中字符串到音节转换（G2P）的性能而写的。</li>
<li>methods: 这个论文使用了Tokenizer-free byte-level模型（ByT5），通过表示每个输入字符的UTF-8编码来实现字符串到音节转换。</li>
<li>results: 这个论文发现，使用ByT5进行句子级或段落级G2P可以提高实际应用中的用户体验，但是需要避免曝光偏见常见在自动生成模型中。<details>
<summary>Abstract</summary>
Text-to-Text Transfer Transformer (T5) has recently been considered for the Grapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free byte-level model based on T5 referred to as ByT5, recently gave promising results on word-level G2P conversion by representing each input character with its corresponding UTF-8 encoding. Although it is generally understood that sentence-level or paragraph-level G2P can improve usability in real-world applications as it is better suited to perform on heteronyms and linking sounds between words, we find that using ByT5 for these scenarios is nontrivial. Since ByT5 operates on the character level, it requires longer decoding steps, which deteriorates the performance due to the exposure bias commonly observed in auto-regressive generation models. This paper shows that the performance of sentence-level and paragraph-level G2P can be improved by mitigating such exposure bias using our proposed loss-based sampling method.
</details>
<details>
<summary>摘要</summary>
文本-to-文本传输变换器（T5）最近被考虑用于文本-to-phoneme（G2P）转换。作为继续，一个不需要tokenizer的字节级模型基于T5，称之为ByT5，最近在word-level G2P转换中表现出了扎实的结果。虽然普遍认为 sentence-level或paragraph-level G2P可以提高实际应用中的可用性，因为更适合处理Homonyms和 слова间的连接音，但我们发现使用ByT5进行这些场景是非常困难。因为ByT5操作在字符水平，需要更长的解码步骤，这会导致性能下降，这是因为自动生成模型通常会出现露示偏见。本文显示，使用我们提议的损失采样方法可以提高 sentence-level和paragraph-level G2P的性能。
</details></li>
</ul>
<hr>
<h2 id="Classifying-Dementia-in-the-Presence-of-Depression-A-Cross-Corpus-Study"><a href="#Classifying-Dementia-in-the-Presence-of-Depression-A-Cross-Corpus-Study" class="headerlink" title="Classifying Dementia in the Presence of Depression: A Cross-Corpus Study"></a>Classifying Dementia in the Presence of Depression: A Cross-Corpus Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08306">http://arxiv.org/abs/2308.08306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Franziska Braun, Sebastian P. Bayerl, Paula A. Pérez-Toro, Florian Hönig, Hartmut Lehfeld, Thomas Hillemacher, Elmar Nöth, Tobias Bocklet, Korbinian Riedhammer</li>
<li>for: 这个论文的目的是提出一种自动诊断老年痴呆症的方法，以提高医疗系统的效率和患者的生活质量。</li>
<li>methods: 这个论文使用了语音、文本和情感嵌入来分类诊断老年痴呆症，并在三个类别中进行了比较（健康人 VS 轻度智能障碍 VS 老年痴呆症）。</li>
<li>results: 研究人员通过对两个独立录制的德国数据集进行交叉验证和混合验证，发现了这种方法的普适性和可重复性。<details>
<summary>Abstract</summary>
Automated dementia screening enables early detection and intervention, reducing costs to healthcare systems and increasing quality of life for those affected. Depression has shared symptoms with dementia, adding complexity to diagnoses. The research focus so far has been on binary classification of dementia (DEM) and healthy controls (HC) using speech from picture description tests from a single dataset. In this work, we apply established baseline systems to discriminate cognitive impairment in speech from the semantic Verbal Fluency Test and the Boston Naming Test using text, audio and emotion embeddings in a 3-class classification problem (HC vs. MCI vs. DEM). We perform cross-corpus and mixed-corpus experiments on two independently recorded German datasets to investigate generalization to larger populations and different recording conditions. In a detailed error analysis, we look at depression as a secondary diagnosis to understand what our classifiers actually learn.
</details>
<details>
<summary>摘要</summary>
自动化认知评估可以早期检测和 intervene，降低医疗系统的成本和提高认知症患者的生活质量。与认知症有共同症状的抑郁症可以增加诊断的复杂性。过去的研究主要集中在使用单一数据集的语音描述测验进行二分类认知症和健康控制（HC）的分类。在这个工作中，我们使用已经建立的基eline系统来分辨语音中的认知障碍，使用 semantic Verbal Fluency Test 和 Boston Naming Test 的文本、音频和情感嵌入，进行三类分类问题（HC vs. MCI vs. DEM）。我们在两个独立录取的德国数据集上进行交叉数据和混合数据实验，以调查更大的人口和不同的录音条件下的一致性。在详细的错误分析中，我们将抑郁症作为次要诊断来了解我们的分类器是否真的学习了什么。
</details></li>
</ul>
<hr>
<h2 id="ChinaTelecom-System-Description-to-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#ChinaTelecom-System-Description-to-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="ChinaTelecom System Description to VoxCeleb Speaker Recognition Challenge 2023"></a>ChinaTelecom System Description to VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08181">http://arxiv.org/abs/2308.08181</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengjie Du, Xiang Fang, Jie Li</li>
<li>for: This paper is written for the VoxCeleb2023 Speaker Recognition Challenge (VoxSRC 2023) and describes the ChinaTelecom system for Track 1 (closed).</li>
<li>methods: The system consists of several ResNet variants trained only on VoxCeleb2, which were fused for better performance later. Score calibration was also applied for each variant and the fused system.</li>
<li>results: The final submission achieved minDCF of 0.1066 and EER of 1.980%.Here are the three key points in Simplified Chinese:</li>
<li>for: 这篇论文是为了VOXCELEB2023发音识别挑战（VOXSRC2023）的Track 1（关闭）而写的。</li>
<li>methods: 该系统包括几种基于VOXCELEB2的ResNet变体，这些变体被后续进行了融合以提高表现。此外，每个变体和融合系统还进行了分数调整。</li>
<li>results: 最终提交的结果为minDCF为0.1066和EER为1.980%。<details>
<summary>Abstract</summary>
This technical report describes ChinaTelecom system for Track 1 (closed) of the VoxCeleb2023 Speaker Recognition Challenge (VoxSRC 2023). Our system consists of several ResNet variants trained only on VoxCeleb2, which were fused for better performance later. Score calibration was also applied for each variant and the fused system. The final submission achieved minDCF of 0.1066 and EER of 1.980%.
</details>
<details>
<summary>摘要</summary>
这份技术报告介绍了我们在VoxCeleb2023 Speaker Recognition Challenge（VoxSRC 2023）的Track 1（关闭）系统。我们的系统包括了多种ResNet变体，只在VoxCeleb2上进行训练。这些变体后来进行了融合，以提高性能。此外，我们还应用了分数均衡calibration对每个变体和融合系统。最终的提交达到了0.1066的minDCF和1.980%的EER。
</details></li>
</ul>
<hr>
<h2 id="AffectEcho-Speaker-Independent-and-Language-Agnostic-Emotion-and-Affect-Transfer-for-Speech-Synthesis"><a href="#AffectEcho-Speaker-Independent-and-Language-Agnostic-Emotion-and-Affect-Transfer-for-Speech-Synthesis" class="headerlink" title="AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis"></a>AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08577">http://arxiv.org/abs/2308.08577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishikesh Viswanath, Aneesh Bhattacharya, Pascal Jutras-Dubé, Prerit Gupta, Mridu Prashanth, Yashvardhan Khaitan, Aniket Bera</li>
<li>for: The paper is written for discussing a new approach to emotional translation in text-to-speech and speech-to-speech systems, with the goal of capturing complex nuances and subtle differences in emotions.</li>
<li>methods: The proposed approach, called AffectEcho, uses a Vector Quantized codebook to model emotions within a quantized space featuring five levels of affect intensity. The quantized emotional embeddings are implicitly derived from spoken speech samples, eliminating the need for one-hot vectors or explicit strength embeddings.</li>
<li>results: The experimental results demonstrate the effectiveness of the proposed approach in controlling the emotions of generated speech while preserving identity, style, and emotional cadence unique to each speaker. The language-independent emotion modeling capability of the quantized emotional embeddings learned from a bilingual (English and Chinese) speech corpus is also shown, with an emotion transfer task from a reference speech to a target speech achieving state-of-art results on both qualitative and quantitative metrics.Here are the three points in Simplified Chinese text:</li>
<li>for: 本文是为了介绍一种新的情感翻译方法，用于文本到语音和语音到语音系统中，以便捕捉复杂的情感细微差异。</li>
<li>methods: 提议的方法是使用Vector Quantized codebook来模型情感，在一个5级情感强度的量化空间中进行模型。这些量化情感嵌入不需要一个热度 вектор或者显式强度嵌入。</li>
<li>results: 实验结果表明，提议的方法能够控制生成的语音中的情感，同时保持每个 speaker 的个性、风格和情感节奏。此外，通过一种语言无关的情感模型，在一个英文和中文双语Speech corpus中学习的情感嵌入可以在另一种语言中进行情感传递任务，并达到了当前最佳的质量和量化指标。<details>
<summary>Abstract</summary>
Affect is an emotional characteristic encompassing valence, arousal, and intensity, and is a crucial attribute for enabling authentic conversations. While existing text-to-speech (TTS) and speech-to-speech systems rely on strength embedding vectors and global style tokens to capture emotions, these models represent emotions as a component of style or represent them in discrete categories. We propose AffectEcho, an emotion translation model, that uses a Vector Quantized codebook to model emotions within a quantized space featuring five levels of affect intensity to capture complex nuances and subtle differences in the same emotion. The quantized emotional embeddings are implicitly derived from spoken speech samples, eliminating the need for one-hot vectors or explicit strength embeddings. Experimental results demonstrate the effectiveness of our approach in controlling the emotions of generated speech while preserving identity, style, and emotional cadence unique to each speaker. We showcase the language-independent emotion modeling capability of the quantized emotional embeddings learned from a bilingual (English and Chinese) speech corpus with an emotion transfer task from a reference speech to a target speech. We achieve state-of-art results on both qualitative and quantitative metrics.
</details>
<details>
<summary>摘要</summary>
“情感”是一种情感特征，包括价值观、情感刺激和强度，这种特征对实际对话的进行是关键。现有的文本到语音（TTS）和语音到语音系统通常使用强度嵌入向量和全局风格token来捕捉情感，但这些模型表示情感为样式的一部分或以分类的方式表示。我们提议的情感回声模型（AffectEcho）使用量化编码 кни簿来模型情感在量化空间中的五级强度，以捕捉复杂的细节和同一种情感中的微妙差异。这些量化情感嵌入不需要一个一热 вектор或显式强度嵌入。我们的方法可以控制生成的语音中的情感，保留每个说话者的个性、风格和情感节奏。我们在一个英文和中文语音词汇库中学习的语言独立情感模型能够完成参照语音到目标语音的情感传递任务，并在质量和量度指标上达到了当前最佳效果。
</details></li>
</ul>
<hr>
<h2 id="SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation"><a href="#SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation" class="headerlink" title="SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation"></a>SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08143">http://arxiv.org/abs/2308.08143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Li, Runxuan Yang, Xiaolin Hu</li>
<li>for: 这篇论文主要用于探讨一种新的多模态协同分离方法，即自适应和交叉关注网络（SCANet），该方法可以有效地融合音频和视频特征，以提高对话人的识别率。</li>
<li>methods: SCANet 使用了两种听取块：自适应（SA）块和交叉关注（CA）块，其中 CA 块分布在网络的顶部（TCA）、中部（MCA）和底部（BCA）。这些块可以学习不同的模式特征，并提取不同的 semantics 从音频和视频特征。</li>
<li>results: 根据三个标准的音频视频分离 benchmark（LRS2、LRS3 和 VoxCeleb2）的实验结果，SCANet 比现有的状态对比方法（SOTA）高效，同时保持相对的执行时间。<details>
<summary>Abstract</summary>
The integration of different modalities, such as audio and visual information, plays a crucial role in human perception of the surrounding environment. Recent research has made significant progress in designing fusion modules for audio-visual speech separation. However, they predominantly focus on multi-modal fusion architectures situated either at the top or bottom positions, rather than comprehensively considering multi-modal fusion at various hierarchical positions within the network. In this paper, we propose a novel model called self- and cross-attention network (SCANet), which leverages the attention mechanism for efficient audio-visual feature fusion. SCANet consists of two types of attention blocks: self-attention (SA) and cross-attention (CA) blocks, where the CA blocks are distributed at the top (TCA), middle (MCA) and bottom (BCA) of SCANet. These blocks maintain the ability to learn modality-specific features and enable the extraction of different semantics from audio-visual features. Comprehensive experiments on three standard audio-visual separation benchmarks (LRS2, LRS3, and VoxCeleb2) demonstrate the effectiveness of SCANet, outperforming existing state-of-the-art (SOTA) methods while maintaining comparable inference time.
</details>
<details>
<summary>摘要</summary>
人类在识别环境中利用不同模式的感知信息，如音频和视觉信息，进行集成很重要。现代研究已经在设计多模态融合模块方面做出了重要进步，但是这些模型大多集中于网络的顶层或底层位置，而不是全面考虑多模态融合在网络各个层次位置。本文提出了一种新的模型，即自身和交叉注意网络（SCANet），它利用注意机制来有效地融合音频和视觉特征。SCANet包括两种注意块：自身注意（SA）和交叉注意（CA）块，其中CA块分布在网络顶层（TCA）、中层（MCA）和底层（BCA）。这些块可以学习不同模式的特征，并允许从音频和视觉特征中提取不同的 semantics。我们对三个标准音频视频分离 benchmark（LRS2、LRS3和VoxCeleb2）进行了广泛的实验， demonstarted SCANet的效果，而且与现有的最佳方法（SOTA）保持相对的推理时间。
</details></li>
</ul>
<hr>
<h2 id="Radio2Text-Streaming-Speech-Recognition-Using-mmWave-Radio-Signals"><a href="#Radio2Text-Streaming-Speech-Recognition-Using-mmWave-Radio-Signals" class="headerlink" title="Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals"></a>Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08125">http://arxiv.org/abs/2308.08125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Running Zhao, Jiangtao Yu, Hang Zhao, Edith C. H. Ngai</li>
<li>for: 这篇论文旨在提供一种基于 millimeter wave (mmWave) 技术的语音识别系统，以便在会议听录和窃听等场景中实现高精度语音识别。</li>
<li>methods: 该系统基于一种适配 streams 的 transformer 模型，通过特定的束缚和知识储存技术来实现大词汇量语音识别。</li>
<li>results: 实验结果显示，Radio2Text 可以在 recognizing 一个包含超过 13,000 个词的词汇库时达到 character error rate 5.7% 和 word error rate 9.4%。<details>
<summary>Abstract</summary>
Millimeter wave (mmWave) based speech recognition provides more possibility for audio-related applications, such as conference speech transcription and eavesdropping. However, considering the practicality in real scenarios, latency and recognizable vocabulary size are two critical factors that cannot be overlooked. In this paper, we propose Radio2Text, the first mmWave-based system for streaming automatic speech recognition (ASR) with a vocabulary size exceeding 13,000 words. Radio2Text is based on a tailored streaming Transformer that is capable of effectively learning representations of speech-related features, paving the way for streaming ASR with a large vocabulary. To alleviate the deficiency of streaming networks unable to access entire future inputs, we propose the Guidance Initialization that facilitates the transfer of feature knowledge related to the global context from the non-streaming Transformer to the tailored streaming Transformer through weight inheritance. Further, we propose a cross-modal structure based on knowledge distillation (KD), named cross-modal KD, to mitigate the negative effect of low quality mmWave signals on recognition performance. In the cross-modal KD, the audio streaming Transformer provides feature and response guidance that inherit fruitful and accurate speech information to supervise the training of the tailored radio streaming Transformer. The experimental results show that our Radio2Text can achieve a character error rate of 5.7% and a word error rate of 9.4% for the recognition of a vocabulary consisting of over 13,000 words.
</details>
<details>
<summary>摘要</summary>
微米波（mmWave）基于语音识别提供更多的音频相关应用，如会议语音转文和窃听。然而，在实际场景中，延迟和可识别词汇数是两个关键因素，不能被忽略。在这篇论文中，我们提出Radio2Text，首个基于微米波的流处理自动语音识别（ASR）系统，可以识别超过13,000个词的词汇。Radio2Text基于适应流处理变换器，可以有效地学习语音相关特征的表示，为流处理ASR带来新的可能性。为了解决流处理网络无法访问整个未来输入的缺陷，我们提出引导初始化，通过重量继承来传递非流处理变换器中的特征知识相关全局 контекст到适应流处理变换器。此外，我们提出了基于知识传授（KD）的交叉模态结构，称为交叉模态KD，以mitigate低质量微米波信号对识别性的负面效应。在交叉模态KD中，音频流处理变换器提供特征和回应导航，将有用和准确的语音信息继承给适应广播流处理变换器进行超vision训练。实验结果显示，我们的Radio2Text可以达到Character Error Rate（CER）5.7%和Word Error Rate（WER）9.4%，用于识别超过13,000个词的词汇。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Open-Vocabulary-Keyword-Search-With-Multilingual-Neural-Representations"><a href="#End-to-End-Open-Vocabulary-Keyword-Search-With-Multilingual-Neural-Representations" class="headerlink" title="End-to-End Open Vocabulary Keyword Search With Multilingual Neural Representations"></a>End-to-End Open Vocabulary Keyword Search With Multilingual Neural Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08027">http://arxiv.org/abs/2308.08027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bolaji Yusuf, Jan Cernocky, Murat Saraclar</li>
<li>for: 提高 keyword search 系统的效率和简化搜索过程，不需要自动语音识别（ASR）输出。</li>
<li>methods: 使用神经网络encoder对查询和文档进行编码，并将编码结果进行点积 multiplication 组合。</li>
<li>results: 在长查询和没有在训练数据中出现的查询中，提高了模型的性能，并且对于短查询和包含在 vocabulary 中的查询，虽然不能与强大的 ASR-based 传统搜索系统匹配，但是仍然超过了 ASR-based 系统。<details>
<summary>Abstract</summary>
Conventional keyword search systems operate on automatic speech recognition (ASR) outputs, which causes them to have a complex indexing and search pipeline. This has led to interest in ASR-free approaches to simplify the search procedure. We recently proposed a neural ASR-free keyword search model which achieves competitive performance while maintaining an efficient and simplified pipeline, where queries and documents are encoded with a pair of recurrent neural network encoders and the encodings are combined with a dot-product. In this article, we extend this work with multilingual pretraining and detailed analysis of the model. Our experiments show that the proposed multilingual training significantly improves the model performance and that despite not matching a strong ASR-based conventional keyword search system for short queries and queries comprising in-vocabulary words, the proposed model outperforms the ASR-based system for long queries and queries that do not appear in the training data.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:传统的关键词搜索系统采用自动语音识别（ASR）输出，这导致搜索管道变得复杂。这引起了关注ASR-free方法，以简化搜索过程。我们最近提出了一种基于神经网络的ASR-free关键词搜索模型，该模型在竞争性和效率方面具有优异表现，而无需复杂的搜索管道。在这篇文章中，我们延续这种工作，并通过多语言预训练和详细分析，进一步提高模型性能。我们的实验表明，提档多语言训练显著提高模型性能，并且对于长 queries和不在训练数据中出现的 queries，模型的性能胜过ASR-based系统。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/cs.SD_2023_08_16/" data-id="clly4xtet00aavl88h5m71132" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/eess.AS_2023_08_16/" class="article-date">
  <time datetime="2023-08-15T16:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/eess.AS_2023_08_16/">eess.AS - 2023-08-16 22:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-ID-R-D-VoxCeleb-Speaker-Recognition-Challenge-2023-System-Description"><a href="#The-ID-R-D-VoxCeleb-Speaker-Recognition-Challenge-2023-System-Description" class="headerlink" title="The ID R&amp;D VoxCeleb Speaker Recognition Challenge 2023 System Description"></a>The ID R&amp;D VoxCeleb Speaker Recognition Challenge 2023 System Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08294">http://arxiv.org/abs/2308.08294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Torgashov, Rostislav Makarov, Ivan Yakovlev, Pavel Malov, Andrei Balykin, Anton Okhotnikov</li>
<li>for: 这个研究是为了参加2023年VoxCeleb Speaker Recognition Challenge（VoxSRC-23）的Track 2（开放赛）而撰写的。</li>
<li>methods: 该解决方案基于深度ResNet和自动标注学习（SSL）基于模型，在一个组合的VoxCeleb2数据集和大量的VoxTube数据集上进行训练。</li>
<li>results: 最终在Track 2上提交的解决方案在VoxSRC-23公共排名板上达到了第一名， minDCF(0.05) 为0.0762， EER 为1.30%。<details>
<summary>Abstract</summary>
This report describes ID R&D team submissions for Track 2 (open) to the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23). Our solution is based on the fusion of deep ResNets and self-supervised learning (SSL) based models trained on a mixture of a VoxCeleb2 dataset and a large version of a VoxTube dataset. The final submission to the Track 2 achieved the first place on the VoxSRC-23 public leaderboard with a minDCF(0.05) of 0.0762 and EER of 1.30%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/eess.AS_2023_08_16/" data-id="clly4xtfb00c6vl885ooafxc9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/eess.IV_2023_08_16/" class="article-date">
  <time datetime="2023-08-15T16:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/eess.IV_2023_08_16/">eess.IV - 2023-08-16 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Prediction-of-post-radiotherapy-recurrence-volumes-in-head-and-neck-squamous-cell-carcinoma-using-3D-U-Net-segmentation"><a href="#Prediction-of-post-radiotherapy-recurrence-volumes-in-head-and-neck-squamous-cell-carcinoma-using-3D-U-Net-segmentation" class="headerlink" title="Prediction of post-radiotherapy recurrence volumes in head and neck squamous cell carcinoma using 3D U-Net segmentation"></a>Prediction of post-radiotherapy recurrence volumes in head and neck squamous cell carcinoma using 3D U-Net segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08396">http://arxiv.org/abs/2308.08396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Kutnár, Ivan R Vogelius, Katrin Elisabet Håkansson, Jens Petersen, Jeppe Friborg, Lena Specht, Mogens Bernsdorf, Anita Gothelf, Claus Kristensen, Abraham George Smith</li>
<li>for: 这研究旨在使用 convolutional neural network (CNN) 预测头颈癌细胞癌 (HNSCC) 患者的 lokoregional recurrences (LRR) 体积，以便通过生物标记化辐射疗法来提高治疗效果。</li>
<li>methods: 研究使用了 18F-fluorodeoxyglucose positron emission tomography (FDG-PET)&#x2F;computed tomography (CT) 扫描图像来训练 CNN，并对患者的前 treated 患区进行了预测。</li>
<li>results: 研究发现，使用 CNN 可以准确预测 HNSCC 患者的 LRR 体积，并且比使用 SUVmax 阈值方法或 GTV 直接使用更有效。 however, 需要进一步的数据集开发以实现临床有用的预测精度。<details>
<summary>Abstract</summary>
Locoregional recurrences (LRR) are still a frequent site of treatment failure for head and neck squamous cell carcinoma (HNSCC) patients.   Identification of high risk subvolumes based on pretreatment imaging is key to biologically targeted radiation therapy. We investigated the extent to which a Convolutional neural network (CNN) is able to predict LRR volumes based on pre-treatment 18F-fluorodeoxyglucose positron emission tomography (FDG-PET)/computed tomography (CT) scans in HNSCC patients and thus the potential to identify biological high risk volumes using CNNs.   For 37 patients who had undergone primary radiotherapy for oropharyngeal squamous cell carcinoma, five oncologists contoured the relapse volumes on recurrence CT scans. Datasets of pre-treatment FDG-PET/CT, gross tumour volume (GTV) and contoured relapse for each of the patients were randomly divided into training (n=23), validation (n=7) and test (n=7) datasets. We compared a CNN trained from scratch, a pre-trained CNN, a SUVmax threshold approach, and using the GTV directly.   The SUVmax threshold method included 5 out of the 7 relapse origin points within a volume of median 4.6 cubic centimetres (cc). Both the GTV contour and best CNN segmentations included the relapse origin 6 out of 7 times with median volumes of 28 and 18 cc respectively.   The CNN included the same or greater number of relapse volume POs, with significantly smaller relapse volumes. Our novel findings indicate that CNNs may predict LRR, yet further work on dataset development is required to attain clinically useful prediction accuracy.
</details>
<details>
<summary>摘要</summary>
Head and neck squamous cell carcinoma (HNSCC) 患者中的局部再现 (LRR) 仍然是治疗失败的常见现象。 为了预测LRR的卷积批处，我们使用了卷积神经网络 (CNN)。我们研究了在前治疗18F-fluorodeoxyglucose пози트рон辐射tomography (FDG-PET)/计算机 Tomography (CT) 图像上预测LRR объем的可能性。为了进行这项研究，我们收集了37名有主治疗的口腔癌患者的数据。这些患者都已经接受了主治疗。我们让5名医生标注了再现图像上的再现 объем。我们将这些数据分为训练集（n=23）、验证集（n=7）和测试集（n=7）。我们比较了从头文字开始训练的CNN、预训练的CNN、SUVmax阈值方法和直接使用GTV的方法。SUVmax阈值方法中包含了7名再现起点的5个点在 median 4.6立方厘米（cc）内。GTV框和最佳CNN分割都包含了再现起点6个名次， median volume 28和18 cc。 CN中包含了相同或更多的再现量PO，并且再现 объем更小。我们的新发现表明，CNN可能预测LRR，但是我们需要进一步增加数据来提高临床可用性的预测精度。
</details></li>
</ul>
<hr>
<h2 id="DeepContrast-Deep-Tissue-Contrast-Enhancement-using-Synthetic-Data-Degradations-and-OOD-Model-Predictions"><a href="#DeepContrast-Deep-Tissue-Contrast-Enhancement-using-Synthetic-Data-Degradations-and-OOD-Model-Predictions" class="headerlink" title="DeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data Degradations and OOD Model Predictions"></a>DeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data Degradations and OOD Model Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08365">http://arxiv.org/abs/2308.08365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nuno Pimpão Martins, Yannis Kalaidzidis, Marino Zerial, Florian Jug</li>
<li>for: 该论文主要针对 Microscopy 图像质量下降的问题，即图像噪音、模糊和其他问题，以及这些问题对图像含义的影响。</li>
<li>methods: 该论文使用 Deep Learning 方法来提高 Microscopy 图像质量，但是这些方法通常需要有clean的ground truth（GT）数据进行训练。然而，在深入到样本中图像时，因为各种降低效应，获得clean GT数据变得困难。因此，该论文提出了一种新的方法，可以缺省GT数据进行训练。</li>
<li>results: 该论文使用了一种模拟前向模型来模拟深入到样本中图像的降低效应，然后使用 neural network 学习这个降低效应的逆过程。结果表明，使用这种方法可以提高 Microscopy 图像质量，并且可以在不需要clean GT数据的情况下进行训练。此外，该论文还发现，在不同的下游分析中，需要找到一个平衡点，以保留图像细节和提高图像含义的抽象。<details>
<summary>Abstract</summary>
Microscopy images are crucial for life science research, allowing detailed inspection and characterization of cellular and tissue-level structures and functions. However, microscopy data are unavoidably affected by image degradations, such as noise, blur, or others. Many such degradations also contribute to a loss of image contrast, which becomes especially pronounced in deeper regions of thick samples. Today, best performing methods to increase the quality of images are based on Deep Learning approaches, which typically require ground truth (GT) data during training. Our inability to counteract blurring and contrast loss when imaging deep into samples prevents the acquisition of such clean GT data. The fact that the forward process of blurring and contrast loss deep into tissue can be modeled, allowed us to propose a new method that can circumvent the problem of unobtainable GT data. To this end, we first synthetically degraded the quality of microscopy images even further by using an approximate forward model for deep tissue image degradations. Then we trained a neural network that learned the inverse of this degradation function from our generated pairs of raw and degraded images. We demonstrated that networks trained in this way can be used out-of-distribution (OOD) to improve the quality of less severely degraded images, e.g. the raw data imaged in a microscope. Since the absolute level of degradation in such microscopy images can be stronger than the additional degradation introduced by our forward model, we also explored the effect of iterative predictions. Here, we observed that in each iteration the measured image contrast kept improving while detailed structures in the images got increasingly removed. Therefore, dependent on the desired downstream analysis, a balance between contrast improvement and retention of image details has to be found.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:微scopic 图像是生命科学研究中不可或缺的，允许详细检查和Cellular 和组织水平结构和功能的 characterization。然而，微scopic 图像数据不可避免地受到图像质量下降的影响，如噪声、模糊或其他。这些质量下降也会导致图像对比下降，特别是在厚度样本深处。今天，使用深度学习方法来提高图像质量的最佳实践是基于GT数据的训练。然而，我们无法对深度样本中的厚度进行对比下降，因此无法获得净化GT数据。我们发现，可以使用深度图像模型来模拟深度样本中的对比下降过程，从而提出一种新的方法，可以绕过无法获得GT数据的问题。我们首先使用深度图像模型来进一步降低微scopic 图像的质量，然后使用这些生成的对比下降对的图像对比下降进行学习。我们证明了这种方法可以在OOD（out-of-distribution）下使用，以提高less severely degraded 的图像质量。由于微scopic 图像中的绝对质量可能比我们的深度图像模型引入的质量更强，我们还 investigate了反复预测的效果。我们发现，在每次预测中，测量图像对比度会不断提高，而图像中的细节会逐渐消失。因此，根据下游分析的需求，需要找到保持图像细节的平衡。
</details></li>
</ul>
<hr>
<h2 id="GAEI-UNet-Global-Attention-and-Elastic-Interaction-U-Net-for-Vessel-Image-Segmentation"><a href="#GAEI-UNet-Global-Attention-and-Elastic-Interaction-U-Net-for-Vessel-Image-Segmentation" class="headerlink" title="GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel Image Segmentation"></a>GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08345">http://arxiv.org/abs/2308.08345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiqiang Xiao, Zhuoyue Wan</li>
<li>for: 静脉图像分割是医学诊断中非常重要的一环，能够帮助早期发现和治疗血管疾病。</li>
<li>methods: 我们提出了一种新的模型，即GAEI-UNet，它将全局注意力和弹性互动技术相结合。GAEI-UNet 利用全局空间和通道信息来增强 U-Net 架构中的高级 semantics 理解，以提高小血管的精确分割。此外，我们采用了弹性互动基于的损失函数，以提高小血管网络中的连接性。</li>
<li>results: 我们在 DRIVE 血管图像集上进行了评估，结果表明 GAEI-UNet 在精确分割小血管方面表现出色，而无需增加计算复杂度。此外，GAEI-UNet 还能够保持血管网络的正确 topology。<details>
<summary>Abstract</summary>
Vessel image segmentation plays a pivotal role in medical diagnostics, aiding in the early detection and treatment of vascular diseases. While segmentation based on deep learning has shown promising results, effectively segmenting small structures and maintaining connectivity between them remains challenging. To address these limitations, we propose GAEI-UNet, a novel model that combines global attention and elastic interaction-based techniques. GAEI-UNet leverages global spatial and channel context information to enhance high-level semantic understanding within the U-Net architecture, enabling precise segmentation of small vessels. Additionally, we adopt an elastic interaction-based loss function to improve connectivity among these fine structures. By capturing the forces generated by misalignment between target and predicted shapes, our model effectively learns to preserve the correct topology of vessel networks. Evaluation on retinal vessel dataset -- DRIVE demonstrates the superior performance of GAEI-UNet in terms of SE and connectivity of small structures, without significantly increasing computational complexity. This research aims to advance the field of vessel image segmentation, providing more accurate and reliable diagnostic tools for the medical community. The implementation code is available on Code.
</details>
<details>
<summary>摘要</summary>
船体图像分割在医学诊断中扮演着关键角色，帮助早期发现和治疗血管疾病。although deep learning-based segmentation has shown promising results, effectively segmenting small structures and maintaining connectivity between them remains challenging. To address these limitations, we propose GAEI-UNet, a novel model that combines global attention and elastic interaction-based techniques. GAEI-UNet leverages global spatial and channel context information to enhance high-level semantic understanding within the U-Net architecture, enabling precise segmentation of small vessels. Additionally, we adopt an elastic interaction-based loss function to improve connectivity among these fine structures. By capturing the forces generated by misalignment between target and predicted shapes, our model effectively learns to preserve the correct topology of vessel networks. Evaluation on retinal vessel dataset -- DRIVE demonstrates the superior performance of GAEI-UNet in terms of SE and connectivity of small structures, without significantly increasing computational complexity. This research aims to advance the field of vessel image segmentation, providing more accurate and reliable diagnostic tools for the medical community. The implementation code is available on Code.Here's the text with some notes on the translation:1. "船体图像分割" (zhōng tǐ tú zhǐ bīng) - This phrase is used to refer to the process of segmenting images of vessels, such as blood vessels in the retina.2. "在医学诊断中扮演着关键角色" (zhī xué shòu yì zhòng zhì yǐng) - This phrase emphasizes the importance of vessel image segmentation in medical diagnosis.3. "although deep learning-based segmentation has shown promising results" (although deep learning-based segmentation has shown promising results) - This phrase is used to acknowledge the progress that has been made in vessel image segmentation using deep learning techniques.4. "effectively segmenting small structures and maintaining connectivity between them remains challenging" (effectively segmenting small structures and maintaining connectivity between them remains challenging) - This phrase highlights the limitations of current vessel image segmentation methods, specifically the difficulty in accurately segmenting small vessels and maintaining the connectivity between them.5. "To address these limitations, we propose GAEI-UNet" (To address these limitations, we propose GAEI-UNet) - This phrase introduces the novel model proposed in the research, which aims to overcome the limitations of current methods.6. "a novel model that combines global attention and elastic interaction-based techniques" (a novel model that combines global attention and elastic interaction-based techniques) - This phrase describes the key innovation of the proposed model, which combines global attention and elastic interaction-based techniques to improve the accuracy and reliability of vessel image segmentation.7. "leverages global spatial and channel context information to enhance high-level semantic understanding" (leverages global spatial and channel context information to enhance high-level semantic understanding) - This phrase explains how the proposed model uses global spatial and channel context information to improve the understanding of the vessel networks and enhance the accuracy of segmentation.8. "enabling precise segmentation of small vessels" (enabling precise segmentation of small vessels) - This phrase highlights the main advantage of the proposed model, which is its ability to accurately segment small vessels.9. "without significantly increasing computational complexity" (without significantly increasing computational complexity) - This phrase emphasizes that the proposed model does not require a significant increase in computational resources, making it more practical and efficient for real-world applications.10. "This research aims to advance the field of vessel image segmentation" (This research aims to advance the field of vessel image segmentation) - This phrase highlights the overall goal of the research, which is to improve the accuracy and reliability of vessel image segmentation and provide more accurate and reliable diagnostic tools for the medical community.I hope this helps! Let me know if you have any further questions or if there's anything else I can help with.
</details></li>
</ul>
<hr>
<h2 id="Denoising-Diffusion-Probabilistic-Model-for-Retinal-Image-Generation-and-Segmentation"><a href="#Denoising-Diffusion-Probabilistic-Model-for-Retinal-Image-Generation-and-Segmentation" class="headerlink" title="Denoising Diffusion Probabilistic Model for Retinal Image Generation and Segmentation"></a>Denoising Diffusion Probabilistic Model for Retinal Image Generation and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08339">http://arxiv.org/abs/2308.08339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aaleka/retree">https://github.com/aaleka/retree</a></li>
<li>paper_authors: Alnur Alimanov, Md Baharul Islam<br>for:这个研究旨在提供一个高品质的retinal image dataset，并运用Generative Adversarial Networks (GAN)和Denosing Diffusion Probabilistic Model (DDPM)来生成具有多样性的retinal images。methods:本研究使用了GAN和DDPM来生成retinal images，并开发了一个名为Retinal Trees (ReTree)的dataset，包括retinal images、相应的血管树和一个基于DDPM的分类网络。results:研究发现，DDPM可以对于retinal images的生成比GAN更高品质，并且可以生成多样性较高的retinal images。ReTree dataset也被评估了其量化和质量上的表现，并且显示了其可以用于血管树分类和retinal image分类任务。<details>
<summary>Abstract</summary>
Experts use retinal images and vessel trees to detect and diagnose various eye, blood circulation, and brain-related diseases. However, manual segmentation of retinal images is a time-consuming process that requires high expertise and is difficult due to privacy issues. Many methods have been proposed to segment images, but the need for large retinal image datasets limits the performance of these methods. Several methods synthesize deep learning models based on Generative Adversarial Networks (GAN) to generate limited sample varieties. This paper proposes a novel Denoising Diffusion Probabilistic Model (DDPM) that outperformed GANs in image synthesis. We developed a Retinal Trees (ReTree) dataset consisting of retinal images, corresponding vessel trees, and a segmentation network based on DDPM trained with images from the ReTree dataset. In the first stage, we develop a two-stage DDPM that generates vessel trees from random numbers belonging to a standard normal distribution. Later, the model is guided to generate fundus images from given vessel trees and random distribution. The proposed dataset has been evaluated quantitatively and qualitatively. Quantitative evaluation metrics include Frechet Inception Distance (FID) score, Jaccard similarity coefficient, Cohen's kappa, Matthew's Correlation Coefficient (MCC), precision, recall, F1-score, and accuracy. We trained the vessel segmentation model with synthetic data to validate our dataset's efficiency and tested it on authentic data. Our developed dataset and source code is available at https://github.com/AAleka/retree.
</details>
<details>
<summary>摘要</summary>
专家利用血液图像和血管树来检测和诊断各种眼、血液和脑部疾病。然而，手动分割血液图像是一项时间consuming和需要高度专业知识的过程，另外，隐私问题也使得这项工作困难。许多方法已经被提出来分割图像，但是因为数据的限制，这些方法的性能受到限制。本文提出了一种新的涂抹扩散 probabilistic model（DDPM），其在图像生成方面超过了GAN的表现。我们还制作了一个名为“Retinal Trees”（ReTree）的 dataset，该 dataset包括血液图像、对应的血管树和基于 DDPM 的分割网络。在首个阶段，我们开发了一种两 stage DDPM，该模型从标准正态分布中的随机数生成血管树。后来，模型被引导使用给定的血管树和随机分布来生成血液图像。我们对该 dataset 进行了量化和质量上的评估。量化评估指标包括Frechet Inception Distance（FID）分数、Jaccard 相似度系数、Cohen's kappa、Matthew's Correlation Coefficient（MCC）、精度、 recall、F1-score 和准确率。我们使用合成数据来训练分割模型，以验证我们的 dataset 的效率，然后在真实数据上进行测试。我们开发的 dataset 和源代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="ECPC-IDS-A-benchmark-endometrail-cancer-PET-CT-image-dataset-for-evaluation-of-semantic-segmentation-and-detection-of-hypermetabolic-regions"><a href="#ECPC-IDS-A-benchmark-endometrail-cancer-PET-CT-image-dataset-for-evaluation-of-semantic-segmentation-and-detection-of-hypermetabolic-regions" class="headerlink" title="ECPC-IDS:A benchmark endometrail cancer PET&#x2F;CT image dataset for evaluation of semantic segmentation and detection of hypermetabolic regions"></a>ECPC-IDS:A benchmark endometrail cancer PET&#x2F;CT image dataset for evaluation of semantic segmentation and detection of hypermetabolic regions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08313">http://arxiv.org/abs/2308.08313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dechao Tang, Xuanyi Li, Tianming Du, Deguo Ma, Zhiyu Ma, Hongzan Sun, Marcin Grzegorzek, Huiyan Jiang, Chen Li</li>
<li>for: 这个论文主要目的是提供一个大量多图像的 ENDOMETRIAL CANCER PET&#x2F;CT图像数据集，以便研究人员可以通过计算机助理诊断技术来提高诊断的准确性和 объектив性，同时减轻医生的工作负担。</li>
<li>methods: 这个论文使用了五种经典的深度学习 semantic segmentation 方法和六种深度学习对象检测方法进行测试，以证明不同方法在 ECPC-IDS 上的差异。</li>
<li>results: 这个论文通过 extensively 的实验，demonstrate 了不同方法在 ECPC-IDS 上的性能差异，并证明了这个数据集可以帮助研究人员开发新的算法，以提高计算机助理诊断技术的性能，从而为临床医生和患者带来很大的 benefit.<details>
<summary>Abstract</summary>
Endometrial cancer is one of the most common tumors in the female reproductive system and is the third most common gynecological malignancy that causes death after ovarian and cervical cancer. Early diagnosis can significantly improve the 5-year survival rate of patients. With the development of artificial intelligence, computer-assisted diagnosis plays an increasingly important role in improving the accuracy and objectivity of diagnosis, as well as reducing the workload of doctors. However, the absence of publicly available endometrial cancer image datasets restricts the application of computer-assisted diagnostic techniques.In this paper, a publicly available Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation and Detection of Hypermetabolic Regions (ECPC-IDS) are published. Specifically, the segmentation section includes PET and CT images, with a total of 7159 images in multiple formats. In order to prove the effectiveness of segmentation methods on ECPC-IDS, five classical deep learning semantic segmentation methods are selected to test the image segmentation task. The object detection section also includes PET and CT images, with a total of 3579 images and XML files with annotation information. Six deep learning methods are selected for experiments on the detection task.This study conduct extensive experiments using deep learning-based semantic segmentation and object detection methods to demonstrate the differences between various methods on ECPC-IDS. As far as we know, this is the first publicly available dataset of endometrial cancer with a large number of multiple images, including a large amount of information required for image and target detection. ECPC-IDS can aid researchers in exploring new algorithms to enhance computer-assisted technology, benefiting both clinical doctors and patients greatly.
</details>
<details>
<summary>摘要</summary>
《Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation and Detection of Hypermetabolic Regions (ECPC-IDS)》Endometrial cancer是女性生殖系统中最常见的肿瘤，也是最常见的女性生殖系统癌症之一，仅次于卵巢和子宫癌。早期诊断可以显著提高病人5年生存率。随着人工智能的发展，计算机协助诊断在提高诊断精度和公正性方面发挥了越来越重要的作用，同时也减轻医生的工作负担。然而， absence of publicly available endometrial cancer image datasets restricts the application of computer-assisted diagnostic techniques。为了解决这个问题，我们在这篇论文中发布了一个公共可用的Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation and Detection of Hypermetabolic Regions (ECPC-IDS)。具体来说，分别包括PET和CT图像，共7159张图像，多种格式。为证明ECPC-IDS上 segmentation 方法的效果，我们选择了5种经典的深度学习 semantic segmentation 方法进行测试图像 segmentation 任务。另外， objet detection 部分也包括PET和CT图像，共3579张图像和XML文件中的注释信息。我们选择了6种深度学习方法进行 эксперимент detection 任务。本研究通过使用深度学习基于的semantic segmentation和object detection方法，进行了对ECPC-IDS的广泛实验，以示出不同方法之间的差异。据我们所知，ECPC-IDS是首个公共可用的 endometrial cancer 数据集，包含大量多种图像信息，包括图像和目标检测需要的大量信息。ECPC-IDS 可以帮助研究人员探索新的算法，以提高计算机协助技术，对临床医生和病人都是非常有利。
</details></li>
</ul>
<hr>
<h2 id="OnUVS-Online-Feature-Decoupling-Framework-for-High-Fidelity-Ultrasound-Video-Synthesis"><a href="#OnUVS-Online-Feature-Decoupling-Framework-for-High-Fidelity-Ultrasound-Video-Synthesis" class="headerlink" title="OnUVS: Online Feature Decoupling Framework for High-Fidelity Ultrasound Video Synthesis"></a>OnUVS: Online Feature Decoupling Framework for High-Fidelity Ultrasound Video Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08269">http://arxiv.org/abs/2308.08269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zhou, Dong Ni, Ao Chang, Xinrui Zhou, Rusi Chen, Yanlin Chen, Lian Liu, Jiamin Liang, Yuhao Huang, Tong Han, Zhe Liu, Deng-Ping Fan, Xin Yang</li>
<li>for:  This paper aims to address the challenges of synthesizing high-fidelity ultrasound (US) videos for clinical diagnosis, particularly the limited availability of specific US video cases, by presenting a novel online feature-decoupling framework called OnUVS.</li>
<li>methods:  The OnUVS framework uses a weakly-supervised training strategy to introduce anatomic information into keypoint learning, a dual-decoder to decouple content and textural features, and a multiple-feature discriminator to enhance the sharpness and fine details of the generated videos. Additionally, the framework constrains the motion trajectories of keypoints during online learning to enhance the fluidity of the generated videos.</li>
<li>results:  The paper demonstrates the effectiveness of OnUVS in synthesizing US videos with high fidelity through validation and user studies on in-house echocardiographic and pelvic floor US videos.<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is indispensable in clinical practice. To diagnose certain diseases, sonographers must observe corresponding dynamic anatomic structures to gather comprehensive information. However, the limited availability of specific US video cases causes teaching difficulties in identifying corresponding diseases, which potentially impacts the detection rate of such cases. The synthesis of US videos may represent a promising solution to this issue. Nevertheless, it is challenging to accurately animate the intricate motion of dynamic anatomic structures while preserving image fidelity. To address this, we present a novel online feature-decoupling framework called OnUVS for high-fidelity US video synthesis. Our highlights can be summarized by four aspects. First, we introduced anatomic information into keypoint learning through a weakly-supervised training strategy, resulting in improved preservation of anatomical integrity and motion while minimizing the labeling burden. Second, to better preserve the integrity and textural information of US images, we implemented a dual-decoder that decouples the content and textural features in the generator. Third, we adopted a multiple-feature discriminator to extract a comprehensive range of visual cues, thereby enhancing the sharpness and fine details of the generated videos. Fourth, we constrained the motion trajectories of keypoints during online learning to enhance the fluidity of generated videos. Our validation and user studies on in-house echocardiographic and pelvic floor US videos showed that OnUVS synthesizes US videos with high fidelity.
</details>
<details>
<summary>摘要</summary>
超声影像（US）是诊断疾病的不可或缺的工具。sonographers需要观察相应的动态生理结构，以获取全面的信息。然而，有限的特定US视频案例的有效性，使得教学和诊断这些疾病具有挑战性。为解决这个问题，我们提出了一种新的在线特征分离框架 called OnUVS，用于高精度US视频生成。我们的特点包括：1. 通过弱有监督训练策略，将解剖信息引入关键点学习中，以提高动态生理结构的保留和动作，同时减少标注卷积。2. 为了更好地保持US图像的完整性和текстуral信息，我们实现了内容和текстуral特征的解码器。3. 采用多个特征识别器，挖掘更广泛的视觉cue，提高生成视频的锐度和细节。4. 在在线学习中，限制关键点的运动轨迹，以提高生成视频的流畅性。我们的验证和用户研究表明，OnUVS可以生成高精度的US视频。
</details></li>
</ul>
<hr>
<h2 id="Neural-Spherical-Harmonics-for-structurally-coherent-continuous-representation-of-diffusion-MRI-signal"><a href="#Neural-Spherical-Harmonics-for-structurally-coherent-continuous-representation-of-diffusion-MRI-signal" class="headerlink" title="Neural Spherical Harmonics for structurally coherent continuous representation of diffusion MRI signal"></a>Neural Spherical Harmonics for structurally coherent continuous representation of diffusion MRI signal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08210">http://arxiv.org/abs/2308.08210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Hendriks, Anna Vilanova, Maxime Chamberland</li>
<li>for: This paper presents a novel method for modeling diffusion magnetic resonance imaging (dMRI) datasets, which leverages the structural coherence of the human brain to improve the accuracy and efficiency of the reconstruction process.</li>
<li>methods: The proposed method uses a neural network to parameterize a spherical harmonics series (NeSH) to represent the dMRI signal of a single subject, continuous in both the angular and spatial domain. The method also utilizes upsampling in both the angular and spatial domain to improve the reconstruction results.</li>
<li>results: The reconstructed dMRI signal using the proposed method shows a more structurally coherent representation of the data, with reduced noise in gradient images and smoother fiber orientation distribution functions. The method also enables the calculation of mean diffusivity, fractional anisotropy, and total apparent fiber density with a single model architecture and minimal hyperparameter tuning.<details>
<summary>Abstract</summary>
We present a novel way to model diffusion magnetic resonance imaging (dMRI) datasets, that benefits from the structural coherence of the human brain while only using data from a single subject. Current methods model the dMRI signal in individual voxels, disregarding the intervoxel coherence that is present. We use a neural network to parameterize a spherical harmonics series (NeSH) to represent the dMRI signal of a single subject from the Human Connectome Project dataset, continuous in both the angular and spatial domain. The reconstructed dMRI signal using this method shows a more structurally coherent representation of the data. Noise in gradient images is removed and the fiber orientation distribution functions show a smooth change in direction along a fiber tract. We showcase how the reconstruction can be used to calculate mean diffusivity, fractional anisotropy, and total apparent fiber density. These results can be achieved with a single model architecture, tuning only one hyperparameter. In this paper we also demonstrate how upsampling in both the angular and spatial domain yields reconstructions that are on par or better than existing methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于模型Diffusion Magnetic Resonance Imaging（dMRI）数据集，该方法利用人脑的结构减噪。现有方法通常在个体粒子上模型dMRI信号，忽略了各个粒子之间的协调性。我们使用神经网络来参数化球面幂数列（NeSH）来表示单个参与者的dMRI信号，这种表示方式是连续的在角度和空间领域。重建的dMRI信号表现出了更好的结构减噪，排除了梯度图像中的噪声，并且纤维方向分布函数（fOD）示出了细胞轴的平滑变化。我们还示出了如何使用这种重建方法来计算平均扩散率、有效扩散率和总显示纤维 densidad。这些结果可以通过单个模型架构和一个超参数来实现。此外，我们还证明了在角度和空间领域进行upsampling可以实现重建的结果与现有方法相当或更好。
</details></li>
</ul>
<hr>
<h2 id="Self-Reference-Deep-Adaptive-Curve-Estimation-for-Low-Light-Image-Enhancement"><a href="#Self-Reference-Deep-Adaptive-Curve-Estimation-for-Low-Light-Image-Enhancement" class="headerlink" title="Self-Reference Deep Adaptive Curve Estimation for Low-Light Image Enhancement"></a>Self-Reference Deep Adaptive Curve Estimation for Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08197">http://arxiv.org/abs/2308.08197</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/john-venti/self-dace">https://github.com/john-venti/self-dace</a></li>
<li>paper_authors: Jianyu Wen, Chenhao Wu, Tong Zhang, Yixuan Yu, Piotr Swierczynski</li>
<li>for: 提高低光照图像的显示质量</li>
<li>methods: 使用自适应曲线估计和降噪网络对低光照图像进行两个阶段进行优化</li>
<li>results: 与现有状态艺图像处理算法进行比较，该方法在多个实际数据集上表现出优于其他方法的性能<details>
<summary>Abstract</summary>
In this paper, we propose a 2-stage low-light image enhancement method called Self-Reference Deep Adaptive Curve Estimation (Self-DACE). In the first stage, we present an intuitive, lightweight, fast, and unsupervised luminance enhancement algorithm. The algorithm is based on a novel low-light enhancement curve that can be used to locally boost image brightness. We also propose a new loss function with a simplified physical model designed to preserve natural images' color, structure, and fidelity. We use a vanilla CNN to map each pixel through deep Adaptive Adjustment Curves (AAC) while preserving the local image structure. Secondly, we introduce the corresponding denoising scheme to remove the latent noise in the darkness. We approximately model the noise in the dark and deploy a Denoising-Net to estimate and remove the noise after the first stage. Exhaustive qualitative and quantitative analysis shows that our method outperforms existing state-of-the-art algorithms on multiple real-world datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种两stage的低光照图像增强方法，称为Self-Reference Deep Adaptive Curve Estimation（Self-DACE）。在第一个阶段，我们提供了一种直观、轻量级、快速和无监督的亮度增强算法。该算法基于一个新的低光照增强曲线，可以地方性地提高图像亮度。我们还提出了一个新的损失函数，用于保持自然图像的颜色、结构和准确性。我们使用了一个普通的 convolutional neural network（CNN）来将每个像素通过深度适应曲线（AAC）进行映射，同时保持图像的本地结构。在第二个阶段，我们引入了相应的干扰除方法，以除除在黑暗中存在的隐藏噪声。我们简化了噪声的模型，并使用了一个Denoising-Net来估计和除去噪声。我们对多个实际世界数据集进行了详细的 качеitative和量化分析，结果表明，我们的方法在与现有状态的艺术算法进行比较时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Conditional-Perceptual-Quality-Preserving-Image-Compression"><a href="#Conditional-Perceptual-Quality-Preserving-Image-Compression" class="headerlink" title="Conditional Perceptual Quality Preserving Image Compression"></a>Conditional Perceptual Quality Preserving Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08154">http://arxiv.org/abs/2308.08154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongda Xu, Qian Zhang, Yanghao Li, Dailan He, Zhe Wang, Yuanyuan Wang, Hongwei Qin, Yan Wang, Jingjing Liu, Ya-Qin Zhang</li>
<li>for: 本文提出了基于用户定义信息的可conditioned感知质量（CPQ），用于保持高质量和semantic质量在各比特率下。</li>
<li>methods: 本文基于用户定义信息conditioning的感知质量，通过对比原始图像和重建图像的 divergence 来定义CPQ。</li>
<li>results: 实验结果表明，我们的代码可以成功保持高质量和semantic质量，并且提供了对共同随机性的下界，解决了过去关于是否应该在生成器中包含随机性以提高（conditional）感知质量压缩的辩论。<details>
<summary>Abstract</summary>
We propose conditional perceptual quality, an extension of the perceptual quality defined in \citet{blau2018perception}, by conditioning it on user defined information. Specifically, we extend the original perceptual quality $d(p_{X},p_{\hat{X}})$ to the conditional perceptual quality $d(p_{X|Y},p_{\hat{X}|Y})$, where $X$ is the original image, $\hat{X}$ is the reconstructed, $Y$ is side information defined by user and $d(.,.)$ is divergence. We show that conditional perceptual quality has similar theoretical properties as rate-distortion-perception trade-off \citep{blau2019rethinking}. Based on these theoretical results, we propose an optimal framework for conditional perceptual quality preserving compression. Experimental results show that our codec successfully maintains high perceptual quality and semantic quality at all bitrate. Besides, by providing a lowerbound of common randomness required, we settle the previous arguments on whether randomness should be incorporated into generator for (conditional) perceptual quality compression. The source code is provided in supplementary material.
</details>
<details>
<summary>摘要</summary>
我们提出了基于用户定义信息的conditional perceptual quality，具体来说是将原始的perceptual quality $d(p_{X},p_{\hat{X}})$扩展为 $d(p_{X|Y},p_{\hat{X}|Y})$,其中$X$是原始图像， $\hat{X}$是重建图像，$Y$是用户定义的侧信息。我们证明了conditional perceptual quality具有类似的理论性质，与rate-distortion-perception trade-off的交互作用。基于这些理论结论，我们提出了一个优化的conditional perceptual quality保持压缩框架。实验结果表明，我们的编码器能够保持高度的感知质量和semantic质量，并且提供了对公共随机性的下界，从而解决了过去的争议是否应该在生成器中添加随机性以实现（conditional）perceptual quality压缩。代码在补充材料中提供。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Overview-of-Computational-Nuclei-Segmentation-Methods-in-Digital-Pathology"><a href="#A-Comprehensive-Overview-of-Computational-Nuclei-Segmentation-Methods-in-Digital-Pathology" class="headerlink" title="A Comprehensive Overview of Computational Nuclei Segmentation Methods in Digital Pathology"></a>A Comprehensive Overview of Computational Nuclei Segmentation Methods in Digital Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08112">http://arxiv.org/abs/2308.08112</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasileios Magoulianitis, Catherine A. Alexander, C. -C. Jay Kuo</li>
<li>for: 本文主要用于概述肿瘤诊断领域中数字patology在诊断、分期和分级等方面的应用。</li>
<li>methods: 本文使用了现代人工智能（AI）模型来自动实现核体分 segmentation，从传统图像处理技术到深度学习（DL） paradigm。</li>
<li>results: 本文提供了一个广泛的回顾，从早期使用传统图像处理技术到现代approaches，并讨论了弱监督问题的优势、不同模型的优劣点以及未来研究方向。<details>
<summary>Abstract</summary>
In the cancer diagnosis pipeline, digital pathology plays an instrumental role in the identification, staging, and grading of malignant areas on biopsy tissue specimens. High resolution histology images are subject to high variance in appearance, sourcing either from the acquisition devices or the H\&E staining process. Nuclei segmentation is an important task, as it detects the nuclei cells over background tissue and gives rise to the topology, size, and count of nuclei which are determinant factors for cancer detection. Yet, it is a fairly time consuming task for pathologists, with reportedly high subjectivity. Computer Aided Diagnosis (CAD) tools empowered by modern Artificial Intelligence (AI) models enable the automation of nuclei segmentation. This can reduce the subjectivity in analysis and reading time. This paper provides an extensive review, beginning from earlier works use traditional image processing techniques and reaching up to modern approaches following the Deep Learning (DL) paradigm. Our review also focuses on the weak supervision aspect of the problem, motivated by the fact that annotated data is scarce. At the end, the advantages of different models and types of supervision are thoroughly discussed. Furthermore, we try to extrapolate and envision how future research lines will potentially be, so as to minimize the need for labeled data while maintaining high performance. Future methods should emphasize efficient and explainable models with a transparent underlying process so that physicians can trust their output.
</details>
<details>
<summary>摘要</summary>
在肿瘤诊断管线中，数字patology扮演了重要的角色，用于识别、分期和评分肿瘤区域的各种生物标本样本。高分辨率历史图像具有高变异性，可能来自获取设备或H\&E染色过程。核仁分 segmentation是一项重要任务，因为它可以在背景组织背景下检测核仁细胞，并且对肿瘤检测有决定性作用。然而，这是一项较为时间consuming的任务， pathologists 报告了高度主观性。使用现代人工智能（AI）模型的计算支持工具（CAD）可以自动实现核仁分 segmentation，从而减少分析和阅读时间的主观性。本文提供了广泛的综述，从传统图像处理技术开始，沿着深度学习（DL） paradigm 进行到现代方法。我们的综述还专注于弱级指导问题，因为标注数据scarce。文章结束时，我们详细讨论了不同模型和类型的supervision的优势。此外，我们尝试预测未来研究的发展趋势，以减少标注数据的需求，同时保持高性能。未来的方法应该强调高效可解释的模型，并且具有透明的下面过程，以便physicians可以信任其输出。
</details></li>
</ul>
<hr>
<h2 id="Snapshot-High-Dynamic-Range-Imaging-with-a-Polarization-Camera"><a href="#Snapshot-High-Dynamic-Range-Imaging-with-a-Polarization-Camera" class="headerlink" title="Snapshot High Dynamic Range Imaging with a Polarization Camera"></a>Snapshot High Dynamic Range Imaging with a Polarization Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08094">http://arxiv.org/abs/2308.08094</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Intelligent-Sensing/polarization-hdr">https://github.com/Intelligent-Sensing/polarization-hdr</a></li>
<li>paper_authors: Mingyang Xie, Matthew Chan, Christopher Metzler</li>
<li>for: 这篇论文的目的是把一个常见的 polarization 相机转化为高性能的 HDR 相机。</li>
<li>methods: 这篇论文使用了一种简单 yet 高效的方法，通过在 polarization 相机前置一个线性激光 polarizer，同时捕捉四个不同曝光的图像，并使用一种 robust 和自适应的算法来重建 HDR 图像（具有单一的极性）。</li>
<li>results: 论文的实验结果表明，这种方法可以有效地提高 HDR 图像的质量，并且可以在实际世界中进行广泛的应用。<details>
<summary>Abstract</summary>
High dynamic range (HDR) images are important for a range of tasks, from navigation to consumer photography. Accordingly, a host of specialized HDR sensors have been developed, the most successful of which are based on capturing variable per-pixel exposures. In essence, these methods capture an entire exposure bracket sequence at once in a single shot. This paper presents a straightforward but highly effective approach for turning an off-the-shelf polarization camera into a high-performance HDR camera. By placing a linear polarizer in front of the polarization camera, we are able to simultaneously capture four images with varied exposures, which are determined by the orientation of the polarizer. We develop an outlier-robust and self-calibrating algorithm to reconstruct an HDR image (at a single polarity) from these measurements. Finally, we demonstrate the efficacy of our approach with extensive real-world experiments.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）图像在多种任务中具有重要作用，从导航到消费类摄影。因此，一系列专门设计 дляHDR感知器被开发出来，最成功的是基于变量每像素曝光的方法。在本文中，我们提出了将普通的偏振相机转化为高性能HDR摄影机的简单 yet highly effectiveapproach。通过在偏振相机前置一个直线偏振器，我们能够同时捕捉四个不同曝光的图像，这些图像的曝光是偏振器的 orientations 所决定的。我们开发了一种耐异常和自适应算法，用于从这些测量中重建HDR图像（在单一的偏振 polarity 下）。最后，我们通过广泛的实验证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Framework-for-Spleen-Volume-Estimation-from-2D-Cross-sectional-Views"><a href="#Deep-Learning-Framework-for-Spleen-Volume-Estimation-from-2D-Cross-sectional-Views" class="headerlink" title="Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views"></a>Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08038">http://arxiv.org/abs/2308.08038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Yuan, Esther Puyol-Anton, Haran Jogeesvaran, Baba Inusa, Andrew P. King</li>
<li>for: This paper aims to develop a method for automated spleen volume measurement from 2D cross-sectional segmentations obtained from ultrasound imaging, which can be used to assess splenomegaly and related clinical conditions.</li>
<li>methods: The proposed method uses a variational autoencoder-based framework to measure spleen volume from single- or dual-view 2D spleen segmentations. Three volume estimation methods are proposed and evaluated within this framework.</li>
<li>results: The best model achieved mean relative volume accuracies of 86.62% and 92.58% for single- and dual-view segmentations, respectively, surpassing the performance of the clinical standard approach of linear regression using manual measurements and a comparative deep learning-based 2D-3D reconstruction-based approach. The proposed method can be integrated into standard clinical workflows which currently use 2D ultrasound images to measure spleen length.<details>
<summary>Abstract</summary>
Abnormal spleen enlargement (splenomegaly) is regarded as a clinical indicator for a range of conditions, including liver disease, cancer and blood diseases. While spleen length measured from ultrasound images is a commonly used surrogate for spleen size, spleen volume remains the gold standard metric for assessing splenomegaly and the severity of related clinical conditions. Computed tomography is the main imaging modality for measuring spleen volume, but it is less accessible in areas where there is a high prevalence of splenomegaly (e.g., the Global South). Our objective was to enable automated spleen volume measurement from 2D cross-sectional segmentations, which can be obtained from ultrasound imaging. In this study, we describe a variational autoencoder-based framework to measure spleen volume from single- or dual-view 2D spleen segmentations. We propose and evaluate three volume estimation methods within this framework. We also demonstrate how 95% confidence intervals of volume estimates can be produced to make our method more clinically useful. Our best model achieved mean relative volume accuracies of 86.62% and 92.58% for single- and dual-view segmentations, respectively, surpassing the performance of the clinical standard approach of linear regression using manual measurements and a comparative deep learning-based 2D-3D reconstruction-based approach. The proposed spleen volume estimation framework can be integrated into standard clinical workflows which currently use 2D ultrasound images to measure spleen length. To the best of our knowledge, this is the first work to achieve direct 3D spleen volume estimation from 2D spleen segmentations.
</details>
<details>
<summary>摘要</summary>
非常常见的脾膜肥大（splenomegaly）被视为临床指标，用于诊断多种疾病，如肝病、癌症和血液疾病。而脾膜长度从ultrasound图像中得到的是通常用于脾膜大小的临床标准，但脾膜体积仍是评估splenomegaly和相关临床病情的金标准指标。计算机断层成像是评估脾膜体积的主要成像方法，但在有高发率的脾膜肥大（如全球南部）的地区，计算机断层成像更加不可accessible。我们的目标是启用自动化脾膜体积量计算，从2D横截图像中获得的分割。我们描述了基于variational autoencoder的框架，用于从单个或双视2D脾膜分割中计算脾膜体积。我们提出了三种体积估计方法，并评估了这些方法的性能。我们还示出了在95%信度范围内生成体积估计的方法，以使我们的方法更加临床有用。我们的最佳模型在单视和双视分割中达到了86.62%和92.58%的相对体积准确率，超过了临床标准方法的线性回归使用手动测量和相比之下的深度学习基于2D-3D重建的方法。我们的提议的脾膜体积估计框架可以与现有的仅使用2D ultrasound图像来测量脾膜长度的临床工作流程集成。到目前为止，这是首次直接从2D脾膜分割中 estimate 3D脾膜体积的方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/eess.IV_2023_08_16/" data-id="clly4xtgb00f9vl88fw3hfi14" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/15/cs.SD_2023_08_15/" class="article-date">
  <time datetime="2023-08-15T15:00:00.000Z" itemprop="datePublished">2023-08-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/15/cs.SD_2023_08_15/">cs.SD - 2023-08-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Preliminary-investigation-of-the-short-term-in-situ-performance-of-an-automatic-masker-selection-system"><a href="#Preliminary-investigation-of-the-short-term-in-situ-performance-of-an-automatic-masker-selection-system" class="headerlink" title="Preliminary investigation of the short-term in situ performance of an automatic masker selection system"></a>Preliminary investigation of the short-term in situ performance of an automatic masker selection system</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07767">http://arxiv.org/abs/2308.07767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bhan Lam, Zhen-Ting Ong, Kenneth Ooi, Wen-Hui Ong, Trevor Wong, Karn N. Watcharasupat, Woon-Seng Gan</li>
<li>for: 这篇论文主要是为了提高室内声学环境的听觉舒适性而写的。</li>
<li>methods: 该论文使用了一种深度学习模型，该模型是根据大规模的主观反馈数据来选择最佳的干扰音频，以提高ISO听觉舒适性（ISO 12913-2）的。</li>
<li>results: 研究发现，使用AMSS系统可以提高室内声学环境的听觉舒适性，而且可以更好地根据听觉反馈来选择最佳的干扰音频。<details>
<summary>Abstract</summary>
Soundscape augmentation or "masking" introduces wanted sounds into the acoustic environment to improve acoustic comfort. Usually, the masker selection and playback strategies are either arbitrary or based on simple rules (e.g. -3 dBA), which may lead to sub-optimal increment or even reduction in acoustic comfort for dynamic acoustic environments. To reduce ambiguity in the selection of maskers, an automatic masker selection system (AMSS) was recently developed. The AMSS uses a deep-learning model trained on a large-scale dataset of subjective responses to maximize the derived ISO pleasantness (ISO 12913-2). Hence, this study investigates the short-term in situ performance of the AMSS implemented in a gazebo in an urban park. Firstly, the predicted ISO pleasantness from the AMSS is evaluated in comparison to the in situ subjective evaluation scores. Secondly, the effect of various masker selection schemes on the perceived affective quality and appropriateness would be evaluated. In total, each participant evaluated 6 conditions: (1) ambient environment with no maskers; (2) AMSS; (3) bird and (4) water masker from prior art; (5) random selection from same pool of maskers used to train the AMSS; and (6) selection of best-performing maskers based on the analysis of the dataset used to train the AMSS.
</details>
<details>
<summary>摘要</summary>
增强声响环境或"遮盾"技术可以提高声响舒适度。通常，遮盾选择和播放策略是随意的或基于简单的规则（例如 -3 dBA），可能会导致声响舒适度的下降或不足。为了减少遮盾选择的 ambiguity，一个自动遮盾选择系统（AMSS）已经被开发出来。AMSS使用基于大规模数据集的主观反应进行训练，以最大化 derivated ISO 舒适度（ISO 12913-2）。因此，本研究探讨了在城市公园中的废墟中进行的 AMSS 实际性表现。首先，AMSS 预测的 ISO 舒适度与现场评估分数进行比较。其次，通过不同遮盾选择方案对人们对声响质量和适应性的感知做出评估。总的来说，每名参与者评估了6个条件：（1）无遮盾的 ambient 环境；（2）AMSS；（3）鸟声和水声遮盾来自优等艺术作品；（4）随机从同一个训练数据集中选择的遮盾；（5）基于训练数据集分析选择最佳遮盾；以及（6）由参与者自己选择的最佳遮盾。
</details></li>
</ul>
<hr>
<h2 id="Improving-CTC-AED-model-with-integrated-CTC-and-auxiliary-loss-regularization"><a href="#Improving-CTC-AED-model-with-integrated-CTC-and-auxiliary-loss-regularization" class="headerlink" title="Improving CTC-AED model with integrated-CTC and auxiliary loss regularization"></a>Improving CTC-AED model with integrated-CTC and auxiliary loss regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08449">http://arxiv.org/abs/2308.08449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daobin Zhu, Xiangdong Su, Hongbin Zhang</li>
<li>for:  automatic speech recognition (ASR)</li>
<li>methods:  connectionist temporal classification (CTC) 和 attention-based encoder decoder (AED) 的 JOINT 训练</li>
<li>results:  DAL 方法在注意力重新评分中表现更好，而 PMP 方法在 CTC 预refix 搜索和扩散搜索中表现更好<details>
<summary>Abstract</summary>
Connectionist temporal classification (CTC) and attention-based encoder decoder (AED) joint training has been widely applied in automatic speech recognition (ASR). Unlike most hybrid models that separately calculate the CTC and AED losses, our proposed integrated-CTC utilizes the attention mechanism of AED to guide the output of CTC. In this paper, we employ two fusion methods, namely direct addition of logits (DAL) and preserving the maximum probability (PMP). We achieve dimensional consistency by adaptively affine transforming the attention results to match the dimensions of CTC. To accelerate model convergence and improve accuracy, we introduce auxiliary loss regularization for accelerated convergence. Experimental results demonstrate that the DAL method performs better in attention rescoring, while the PMP method excels in CTC prefix beam search and greedy search.
</details>
<details>
<summary>摘要</summary>
卷积时间分类（CTC）和注意力基于编码器解码器（AED）的共同训练在自动语音识别（ASR）中广泛应用。与大多数混合模型不同，我们提议的综合CTC使用AED的注意力机制来导引CTC输出。在这篇论文中，我们采用了两种融合方法，即直接加法的峰值（DAL）和保持最大概率（PMP）。为确保维度一致，我们采用了适应权重变换来调整注意力结果的维度与CTC匹配。为加速模型 converges 和提高准确性，我们引入了辅助损失regularization。实验结果表明，DAL方法在注意力重新评分中表现更好，而PMP方法在CTC预фикс搜索和扫描搜索中表现更好。
</details></li>
</ul>
<hr>
<h2 id="Using-Text-Injection-to-Improve-Recognition-of-Personal-Identifiers-in-Speech"><a href="#Using-Text-Injection-to-Improve-Recognition-of-Personal-Identifiers-in-Speech" class="headerlink" title="Using Text Injection to Improve Recognition of Personal Identifiers in Speech"></a>Using Text Injection to Improve Recognition of Personal Identifiers in Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07393">http://arxiv.org/abs/2308.07393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yochai Blau, Rohan Agrawal, Lior Madmony, Gary Wang, Andrew Rosenberg, Zhehuai Chen, Zorik Gekhman, Genady Beryozkin, Parisa Haghani, Bhuvana Ramabhadran</li>
<li>for: 提高自动语音识别（ASR）系统中 especific category 的识别精度，例如人名、日期等个人信息。</li>
<li>methods: 使用 text-injection 方法，在训练数据中包含假文本替换Personally Identifiable Information（PII）类别，以提高 ASR 模型对这些类别的识别精度。</li>
<li>results: 在医疗笔记中，可以提高名称和日期的回忆率，并提高总的words error rate（WER）。对于字符串数字序列，可以提高字符错误率和句子准确率。<details>
<summary>Abstract</summary>
Accurate recognition of specific categories, such as persons' names, dates or other identifiers is critical in many Automatic Speech Recognition (ASR) applications. As these categories represent personal information, ethical use of this data including collection, transcription, training and evaluation demands special care. One way of ensuring the security and privacy of individuals is to redact or eliminate Personally Identifiable Information (PII) from collection altogether. However, this results in ASR models that tend to have lower recognition accuracy of these categories. We use text-injection to improve the recognition of PII categories by including fake textual substitutes of PII categories in the training data using a text injection method. We demonstrate substantial improvement to Recall of Names and Dates in medical notes while improving overall WER. For alphanumeric digit sequences we show improvements to Character Error Rate and Sentence Accuracy.
</details>
<details>
<summary>摘要</summary>
“准确识别特定类别，如人名、日期等标识信息，在自动语音识别（ASR）应用中是关键。这些类别代表个人信息，因此使用这些数据需要特殊的注意和保护。一种方法是不收集或消除个人可识别信息（PII），但这会导致ASR模型对这些类别的识别精度下降。我们使用文本插入法来提高PII类别的识别精度，通过在训练数据中包含假文本substitute来提高名称和日期的回忆率。我们在医疗笔记中展示了明显的提高，同时提高总的word error rate。对于字符串数字序列，我们显示了字符错误率和句子准确率的改善。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Localization-of-DOA-trajectories-–-Beyond-the-grid"><a href="#Localization-of-DOA-trajectories-–-Beyond-the-grid" class="headerlink" title="Localization of DOA trajectories – Beyond the grid"></a>Localization of DOA trajectories – Beyond the grid</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07265">http://arxiv.org/abs/2308.07265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruchi Pandey, Santosh Nannuru</li>
<li>for: 本研究旨在提出两种轨迹模型，以捕捉DOA动态。</li>
<li>methods: 用Sliding Frank-Wolfe（SFW）和Newtonized Orthogonal Matching Pursuit（NOMP）两种网格less算法来估计轨迹参数。</li>
<li>results: 对比传统网格方法，提议的轨迹localization算法在噪音抗干扰和计算效率方面具有改善的性能。<details>
<summary>Abstract</summary>
The direction of arrival (DOA) estimation algorithms are crucial in localizing acoustic sources. Traditional localization methods rely on block-level processing to extract the directional information from multiple measurements processed together. However, these methods assume that DOA remains constant throughout the block, which may not be true in practical scenarios. Also, the performance of localization methods is limited when the true parameters do not lie on the parameter search grid. In this paper we propose two trajectory models, namely the polynomial and bandlimited trajectory models, to capture the DOA dynamics. To estimate trajectory parameters, we adopt two gridless algorithms: i) Sliding Frank-Wolfe (SFW), which solves the Beurling LASSO problem and ii) Newtonized Orthogonal Matching Pursuit (NOMP), which improves over OMP using cyclic refinement. Furthermore, we extend our analysis to include wideband processing. The simulation results indicate that the proposed trajectory localization algorithms exhibit improved performance compared to grid-based methods in terms of resolution, robustness to noise, and computational efficiency.
</details>
<details>
<summary>摘要</summary>
Direction of arrival (DOA) 估计算法是音频源本地化的关键。传统的本地化方法依赖块级处理来提取方向信息，但这些方法假设DOA在块内保持相同，这可能不符合实际场景。此外，本地化方法的性能受限于真实参数不在搜索网格上。在本文中，我们提出了两种轨迹模型：多项式轨迹模型和带有限轨迹模型，以捕捉DOA的动态。为估计轨迹参数，我们采用了两种不含网格的算法：i）滑动法沃尔夫（SFW），解决了Beurling LASSO问题，ii）增强的正交匹配追踪（NOMP），通过循环纠正提高OMP的性能。此外，我们扩展了分析至宽频处理。实验结果表明，提议的轨迹本地化算法在比grid-based方法更高的分解能力、鲁棒性和计算效率方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Compositional-nonlinear-audio-signal-processing-with-Volterra-series"><a href="#Compositional-nonlinear-audio-signal-processing-with-Volterra-series" class="headerlink" title="Compositional nonlinear audio signal processing with Volterra series"></a>Compositional nonlinear audio signal processing with Volterra series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07229">http://arxiv.org/abs/2308.07229</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jake Araujo-Simon</li>
<li>for: 这篇论文是为了构建一种基于Volterra系列的非线性音频信号处理理论，以便更好地理解和预测非线性音频系统的行为。</li>
<li>methods: 论文使用了一种基于函数器的方法，通过对Volterra系列进行Category化，以描述非线性变换的输出如何受到输入信号的线性处理的影响。它还引入了一种抽象的折射映射，用于模型非线性音频系统的变化。</li>
<li>results: 论文得出了一些关于非线性音频系统的结论，包括：非线性音频系统的变化可以通过模型为折射映射来描述； Volterra系列和其 morphisms 组织成一个Category，可以用来模型非线性音频系统的时间变化； series composition of Volterra series 是 associative。<details>
<summary>Abstract</summary>
We develop a compositional theory of nonlinear audio signal processing based on a categorification of the Volterra series. We begin by considering what it would mean for the Volterra series to be functorial with respect to a base category whose objects are temperate distributions and whose morphisms are certain linear transformations. This leads to formulae describing how the outcomes of nonlinear transformations are affected if their input signals are first linearly processed. We then consider how nonlinear audio systems change, and introduce as a model thereof a notion of morphism of Volterra series, which we exhibit as a kind of lens map. We show how morphisms can be parameterized and used to generate indexed families of Volterra series, which are well-suited to model nonstationary or time-varying nonlinear phenomena. We then describe how Volterra series and their morphisms organize into a category, which we call Volt. We exhibit the operations of sum, product, and series composition of Volterra series as monoidal products on Volt and identify, for each in turn, its corresponding universal property. We show, in particular, that the series composition of Volterra series is associative. We then bridge between our framework and a subject at the heart of audio signal processing: time-frequency analysis. Specifically, we show that an equivalence between a certain class of second-order Volterra series and the bilinear time-frequency distributions (TFDs) can be extended to one between certain higher-order Volterra series and the so-called polynomial TFDs. We end with prospects for future work, including the incorporation of nonlinear system identification techniques and the extension of our theory to the settings of compositional graph and topological audio signal processing.
</details>
<details>
<summary>摘要</summary>
我们开发了一种基于幂阶系列的非线性音频信号处理理论，该理论是基于幂阶系列的 categorification。我们首先考虑了幂阶系列是如何作为一种函手，对底Category的对象（温度分布）和态射（certain linear transformation）进行函手性的定义。这导致了输入非线性变换后的结果如何受到输入信号的线性处理影响的公式。然后，我们考虑了非线性音频系统如何改变，并引入了一种模型，即幂阶系列的态射。我们显示了这种态射可以被视为一种类型的镜像。我们还介绍了如何使用态射来生成索引 family of Volterra series，这些家族适合模拟非站ARY或时间变化的非线性现象。最后，我们描述了幂阶系列和其态射组织成一个category，我们称之为Volt。我们展示了幂阶系列和其态射之间的操作，包括加法、乘法和序列 compose，它们都是Volt中的对应的幂阶乘法。我们还证明了序列 compose 是相关的。最后，我们将我们的框架与音频信号处理中关键的主题进行桥接，即时域分析。我们证明了一种等价关系，即某种次序 Volterra series与bilinear time-frequency distributions（TFDs）之间的等价关系，可以扩展到高阶 Volterra series和叫做多项式 TFDs。我们结束于未来工作的展望，包括非线性系统识别技术的 incorporation 和我们理论的扩展到compositional graph 和 topological audio signal processing 的设置。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/15/cs.SD_2023_08_15/" data-id="clly4xteq009yvl885m9qh6ub" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/15/eess.AS_2023_08_15/" class="article-date">
  <time datetime="2023-08-15T14:00:00.000Z" itemprop="datePublished">2023-08-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/15/eess.AS_2023_08_15/">eess.AS - 2023-08-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="GIST-AiTeR-Speaker-Diarization-System-for-VoxCeleb-Speaker-Recognition-Challenge-VoxSRC-2023"><a href="#GIST-AiTeR-Speaker-Diarization-System-for-VoxCeleb-Speaker-Recognition-Challenge-VoxSRC-2023" class="headerlink" title="GIST-AiTeR Speaker Diarization System for VoxCeleb Speaker Recognition Challenge (VoxSRC) 2023"></a>GIST-AiTeR Speaker Diarization System for VoxCeleb Speaker Recognition Challenge (VoxSRC) 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07788">http://arxiv.org/abs/2308.07788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongkeon Park, Ji Won Kim, Kang Ryeol Kim, Do Hyun Lee, Hong Kook Kim</li>
<li>for: 本文描述了GIST-AiTeR团队在VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）Track 4的提交系统。</li>
<li>methods: 该提交系统集成了多种说话分类（SD）技术，包括ResNet293和MFA-Conformer，以及不同的段和跳长组合。</li>
<li>results: ResNet293和MFA-Conformer模型在VAL46上表现出了3.65%和3.83%的分类错误率（DER），分布 ensemble模型在VAL46上表现出了3.50%的DER，并在VoxSRC-23测试集上达到4.88%的DER。<details>
<summary>Abstract</summary>
This report describes the submission system by the GIST-AiTeR team for the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23) Track 4. Our submission system focuses on implementing diverse speaker diarization (SD) techniques, including ResNet293 and MFA-Conformer with different combinations of segment and hop length. Then, those models are combined into an ensemble model. The ResNet293 and MFA-Conformer models exhibited the diarization error rates (DERs) of 3.65% and 3.83% on VAL46, respectively. The submitted ensemble model provided a DER of 3.50% on VAL46, and consequently, it achieved a DER of 4.88% on the VoxSRC-23 test set.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-DKU-MSXF-Diarization-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#The-DKU-MSXF-Diarization-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="The DKU-MSXF Diarization System for the VoxCeleb Speaker Recognition Challenge 2023"></a>The DKU-MSXF Diarization System for the VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07595">http://arxiv.org/abs/2308.07595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Cheng, Weiqing Wang, Xiaoyi Qin, Yuke Lin, Ning Jiang, Guoqing Zhao, Ming Li</li>
<li>for: 这篇论文是为了描述DKU-MSXF在VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的识别系统提交。</li>
<li>methods: 该系统管道包括声动活跃检测、分组分割、重叠演讲检测和目标说话人活跃检测，每个过程都有3个子模型的拟合输出。</li>
<li>results: 最终通过DOVER-Lap进行拟合不同的分组和TSVAD系统，实现4.30%的识别错误率（DER），在track 4的挑战排行榜上名列第一。<details>
<summary>Abstract</summary>
This paper describes the DKU-MSXF submission to track 4 of the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23). Our system pipeline contains voice activity detection, clustering-based diarization, overlapped speech detection, and target-speaker voice activity detection, where each procedure has a fused output from 3 sub-models. Finally, we fuse different clustering-based and TSVAD-based diarization systems using DOVER-Lap and achieve the 4.30% diarization error rate (DER), which ranks first place on track 4 of the challenge leaderboard.
</details>
<details>
<summary>摘要</summary>
这篇论文描述DKU-MSXF在VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的订阅提交，我们的系统管道包括声音活动检测、集群化基于分类的分类、重叠说话检测和目标说话人声音活动检测，每个过程有3个子模型的融合输出。最后，我们将不同的集群化和TSVAD基于的分类系统融合使用DOVER-Lap，实现4.30%的分类错误率（DER），在赛事排名榜上名列第一。
</details></li>
</ul>
<hr>
<h2 id="AKVSR-Audio-Knowledge-Empowered-Visual-Speech-Recognition-by-Compressing-Audio-Knowledge-of-a-Pretrained-Model"><a href="#AKVSR-Audio-Knowledge-Empowered-Visual-Speech-Recognition-by-Compressing-Audio-Knowledge-of-a-Pretrained-Model" class="headerlink" title="AKVSR: Audio Knowledge Empowered Visual Speech Recognition by Compressing Audio Knowledge of a Pretrained Model"></a>AKVSR: Audio Knowledge Empowered Visual Speech Recognition by Compressing Audio Knowledge of a Pretrained Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07593">http://arxiv.org/abs/2308.07593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeong Hun Yeo, Minsu Kim, Jeongsoo Choi, Dae Hoe Kim, Yong Man Ro</li>
<li>for: 这个论文的目的是提出一个 Audio Knowledge empowered Visual Speech Recognition 框架 (AKVSR)，以使用音频模式补充视觉模式中的不足信息。</li>
<li>methods: 提案的 AKVSR 使用大规模预训Audio模型所编码的丰富音频知识，将音频信息储存在单簇音频内存中，并通过音频桥接模组寻找最佳对应的音频特征。</li>
<li>results: 经过广泛的实验 validate the effectiveness of the proposed method，在 widely-used datasets LRS2 和 LRS3 上 achievement new state-of-the-art performances。<details>
<summary>Abstract</summary>
Visual Speech Recognition (VSR) is the task of predicting spoken words from silent lip movements. VSR is regarded as a challenging task because of the insufficient information on lip movements. In this paper, we propose an Audio Knowledge empowered Visual Speech Recognition framework (AKVSR) to complement the insufficient speech information of visual modality by using audio modality. Different from the previous methods, the proposed AKVSR 1) utilizes rich audio knowledge encoded by a large-scale pretrained audio model, 2) saves the linguistic information of audio knowledge in compact audio memory by discarding the non-linguistic information from the audio through quantization, and 3) includes Audio Bridging Module which can find the best-matched audio features from the compact audio memory, which makes our training possible without audio inputs, once after the compact audio memory is composed. We validate the effectiveness of the proposed method through extensive experiments, and achieve new state-of-the-art performances on the widely-used datasets, LRS2 and LRS3.
</details>
<details>
<summary>摘要</summary>
Visual Speech Recognition (VSR) 是指从舌部运动中预测说话的任务。由于舌部运动的信息不充分，VSR 被视为一项具有挑战性的任务。在这篇论文中，我们提出了一个 Audio Knowledge empowered Visual Speech Recognition 框架 (AKVSR)，通过使用音频模式来补充视觉模式中的不充分信息。与前一些方法不同，我们的 AKVSR 具有以下特点：1. 使用大规模预训练的音频模型来编码丰富的音频知识。2. 通过归约来抛弃非语言信息，将音频知识储存在紧凑的音频内存中。3. 包括音频桥接模块，可以在训练时找到最佳匹配的音频特征，从而使我们的训练不需要音频输入，只需要一次性将紧凑音频内存构建。我们通过广泛的实验 validate 了我们的方法的效果，并在广泛使用的 dataset 上达到了新的状态码性表现。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/15/eess.AS_2023_08_15/" data-id="clly4xtf900bwvl882jks41fc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/15/cs.CV_2023_08_15/" class="article-date">
  <time datetime="2023-08-15T13:00:00.000Z" itemprop="datePublished">2023-08-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/15/cs.CV_2023_08_15/">cs.CV - 2023-08-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CCD-3DR-Consistent-Conditioning-in-Diffusion-for-Single-Image-3D-Reconstruction"><a href="#CCD-3DR-Consistent-Conditioning-in-Diffusion-for-Single-Image-3D-Reconstruction" class="headerlink" title="CCD-3DR: Consistent Conditioning in Diffusion for Single-Image 3D Reconstruction"></a>CCD-3DR: Consistent Conditioning in Diffusion for Single-Image 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07837">http://arxiv.org/abs/2308.07837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Di, Chenyangguang Zhang, Pengyuan Wang, Guangyao Zhai, Ruida Zhang, Fabian Manhardt, Benjamin Busam, Xiangyang Ji, Federico Tombari</li>
<li>for: 该文章描述了一种基于扩散模型的三维稀畴点云重建方法，用于基于单一RGB图像捕捉的对象重建。</li>
<li>methods: 该方法使用了一种新的中心扩散probabilistic模型来约束本地特征来 condtioning。在反 diffusion 过程中，抑制点云和样本点云被限制在一个子空间中，以确保点云中心保持不变。</li>
<li>results: 对于Synthetic ShapeNet-R2N2测试集，CCD-3DR超过了所有竞争者，增加了 más de 40%的性能提升。同时， authors还提供了实际应用中的Result on Pix3D数据集，以证明CCD-3DR在实际应用中的潜在性。<details>
<summary>Abstract</summary>
In this paper, we present a novel shape reconstruction method leveraging diffusion model to generate 3D sparse point cloud for the object captured in a single RGB image. Recent methods typically leverage global embedding or local projection-based features as the condition to guide the diffusion model. However, such strategies fail to consistently align the denoised point cloud with the given image, leading to unstable conditioning and inferior performance. In this paper, we present CCD-3DR, which exploits a novel centered diffusion probabilistic model for consistent local feature conditioning. We constrain the noise and sampled point cloud from the diffusion model into a subspace where the point cloud center remains unchanged during the forward diffusion process and reverse process. The stable point cloud center further serves as an anchor to align each point with its corresponding local projection-based features. Extensive experiments on synthetic benchmark ShapeNet-R2N2 demonstrate that CCD-3DR outperforms all competitors by a large margin, with over 40% improvement. We also provide results on real-world dataset Pix3D to thoroughly demonstrate the potential of CCD-3DR in real-world applications. Codes will be released soon
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于扩散模型的新型形态重建方法，用于从单个RGB图像中恢复3D稀畴点云。现有方法通常使用全局嵌入或本地投影基于特征作为扩散模型的指导条件，但这些策略无法一致地将净化后的点云与给定图像相对应，导致稳定性差和性能下降。在这篇论文中，我们提出了CCD-3DR，它利用一种新型的中心扩散概率模型来实现一致的本地特征控制。我们在扩散和归还过程中将噪声和采样点云压缩到一个子空间，使得点云中心保持不变。稳定的点云中心更serve as一个锚点，使每个点与其相应的本地投影基于特征进行对应。我们在Synthetic benchmark ShapeNet-R2N2上进行了广泛的实验，结果表明CCD-3DR与其他竞争对手相比，提高了40%以上。我们还对实际应用中的Pix3D数据集进行了详细的研究，以展示CCD-3DR在实际应用中的潜在能力。代码将很快发布。
</details></li>
</ul>
<hr>
<h2 id="Learning-Better-Keypoints-for-Multi-Object-6DoF-Pose-Estimation"><a href="#Learning-Better-Keypoints-for-Multi-Object-6DoF-Pose-Estimation" class="headerlink" title="Learning Better Keypoints for Multi-Object 6DoF Pose Estimation"></a>Learning Better Keypoints for Multi-Object 6DoF Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07827">http://arxiv.org/abs/2308.07827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangzheng Wu, Michael Greenspan</li>
<li>for: 本研究探讨了预定义关键点对pose estimation的影响，并发现可以通过训练一个图 Orientated Graph Network（KeyGNet）来选择一组分散的关键点，以提高准确率和效率。</li>
<li>methods: KeyGNet使用一种组合损失函数，包括 Wassserstein 距离和分散，来监督学习颜色和几何特征来估算关键点位置。</li>
<li>results: 实验表明，使用KeyGNet选择的关键点可以提高所有评价指标的准确率，包括所有七个测试集。特别是在Occlusion LINEMOD数据集上，KeyGNet选择的关键点可以提高ADD(S)的值 by +16.4% on PVN3D。<details>
<summary>Abstract</summary>
We investigate the impact of pre-defined keypoints for pose estimation, and found that accuracy and efficiency can be improved by training a graph network to select a set of disperse keypoints with similarly distributed votes. These votes, learned by a regression network to accumulate evidence for the keypoint locations, can be regressed more accurately compared to previous heuristic keypoint algorithms. The proposed KeyGNet, supervised by a combined loss measuring both Wassserstein distance and dispersion, learns the color and geometry features of the target objects to estimate optimal keypoint locations. Experiments demonstrate the keypoints selected by KeyGNet improved the accuracy for all evaluation metrics of all seven datasets tested, for three keypoint voting methods. The challenging Occlusion LINEMOD dataset notably improved ADD(S) by +16.4% on PVN3D, and all core BOP datasets showed an AR improvement for all objects, of between +1% and +21.5%. There was also a notable increase in performance when transitioning from single object to multiple object training using KeyGNet keypoints, essentially eliminating the SISO-MIMO gap for Occlusion LINEMOD.
</details>
<details>
<summary>摘要</summary>
我们研究了预定的关键点对pose estimation的影响，并发现了通过训练一个图гра夫网络选择一组广泛分布的票点，以提高准确性和效率。这些票点由一个回归网络学习归一化证据以提高精度，相比之前的习惯性关键点算法。我们提出的KeyGNet，以combined损失函数 measuring Wasserstein distance和分布为优化目标，学习目标对象的颜色和几何特征以估算优化关键点位置。实验表明，KeyGNet选择的关键点提高了所有评价指标的准确性，包括所有七个数据集的所有三种关键点投票方法。特别是在Occlusion LINEMOD数据集上，KeyGNet选择的关键点提高了ADD(S)的准确性 by +16.4% on PVN3D，并且所有核心BOP数据集上的所有对象都显示了AR提升，分别为+1%到+21.5%。此外，使用KeyGNet关键点进行多对象训练时，可以基本消除SISO-MIMO障碍，为Occlusion LINEMOD数据集表现出了明显的提升。
</details></li>
</ul>
<hr>
<h2 id="ImbSAM-A-Closer-Look-at-Sharpness-Aware-Minimization-in-Class-Imbalanced-Recognition"><a href="#ImbSAM-A-Closer-Look-at-Sharpness-Aware-Minimization-in-Class-Imbalanced-Recognition" class="headerlink" title="ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition"></a>ImbSAM: A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07815">http://arxiv.org/abs/2308.07815</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cool-xuan/imbalanced_sam">https://github.com/cool-xuan/imbalanced_sam</a></li>
<li>paper_authors: Yixuan Zhou, Yi Qu, Xing Xu, Hengtao Shen</li>
<li>for:  Addressing the challenge of class imbalance in recognition tasks, specifically the generalization issues that arise when tail classes have limited training data.</li>
<li>methods:  Proposes a class-aware smoothness optimization algorithm called Imbalanced-SAM (ImbSAM) that leverages class priors to restrict the generalization scope of the class-agnostic SAM, improving generalization targeting tail classes.</li>
<li>results:  Demonstrates remarkable performance improvements for tail classes and anomaly detection in two prototypical applications of class-imbalanced recognition: long-tailed classification and semi-supervised anomaly detection.<details>
<summary>Abstract</summary>
Class imbalance is a common challenge in real-world recognition tasks, where the majority of classes have few samples, also known as tail classes. We address this challenge with the perspective of generalization and empirically find that the promising Sharpness-Aware Minimization (SAM) fails to address generalization issues under the class-imbalanced setting. Through investigating this specific type of task, we identify that its generalization bottleneck primarily lies in the severe overfitting for tail classes with limited training data. To overcome this bottleneck, we leverage class priors to restrict the generalization scope of the class-agnostic SAM and propose a class-aware smoothness optimization algorithm named Imbalanced-SAM (ImbSAM). With the guidance of class priors, our ImbSAM specifically improves generalization targeting tail classes. We also verify the efficacy of ImbSAM on two prototypical applications of class-imbalanced recognition: long-tailed classification and semi-supervised anomaly detection, where our ImbSAM demonstrates remarkable performance improvements for tail classes and anomaly. Our code implementation is available at https://github.com/cool-xuan/Imbalanced_SAM.
</details>
<details>
<summary>摘要</summary>
“类别不匹配是现实世界识别任务中的常见挑战，主要是因为大多数类别具有少量样本，也称为尾类。我们通过总化和实验发现，promising Sharpness-Aware Minimization (SAM) 在类别不匹配的设定下存在总化问题。通过研究这种特定任务，我们发现其总化瓶颈主要在tail classes中严重过拟合。为了缓解这个瓶颈，我们利用类别优先顺序来限制类型不感知 SAM 的总化范围，并提出一种类别意识细化优化算法名为 Imbalanced-SAM（ImbSAM）。通过类别优先顺序的引导，我们的 ImbSAM specifically 提高了tail classes的总化表现。我们还证明 ImbSAM 在long-tailed classification和 semi-supervised anomaly detection 中表现出色，尤其是在tail classes和异常处理方面。我们的代码实现可以在 GitHub 上找到：https://github.com/cool-xuan/Imbalanced_SAM。”
</details></li>
</ul>
<hr>
<h2 id="Grasp-Transfer-based-on-Self-Aligning-Implicit-Representations-of-Local-Surfaces"><a href="#Grasp-Transfer-based-on-Self-Aligning-Implicit-Representations-of-Local-Surfaces" class="headerlink" title="Grasp Transfer based on Self-Aligning Implicit Representations of Local Surfaces"></a>Grasp Transfer based on Self-Aligning Implicit Representations of Local Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07807">http://arxiv.org/abs/2308.07807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet Tekden, Marc Peter Deisenroth, Yasemin Bekiroglu</li>
<li>for: 本文解决了将抓取经验或示例转移到新对象的问题，该对象与先前遇到的对象共享形状特征。</li>
<li>methods: 本文使用单一专家抓取示例学习了一个基于本地表面的印象模型，并在推理时使用这个模型将抓取转移到新对象的相似表面上。</li>
<li>results: 该方法在实验中可以成功将抓取转移到未看过的对象类别，并在实验和实际场景中表现出较好的空间精度和抓取精度。<details>
<summary>Abstract</summary>
Objects we interact with and manipulate often share similar parts, such as handles, that allow us to transfer our actions flexibly due to their shared functionality. This work addresses the problem of transferring a grasp experience or a demonstration to a novel object that shares shape similarities with objects the robot has previously encountered. Existing approaches for solving this problem are typically restricted to a specific object category or a parametric shape. Our approach, however, can transfer grasps associated with implicit models of local surfaces shared across object categories. Specifically, we employ a single expert grasp demonstration to learn an implicit local surface representation model from a small dataset of object meshes. At inference time, this model is used to transfer grasps to novel objects by identifying the most geometrically similar surfaces to the one on which the expert grasp is demonstrated. Our model is trained entirely in simulation and is evaluated on simulated and real-world objects that are not seen during training. Evaluations indicate that grasp transfer to unseen object categories using this approach can be successfully performed both in simulation and real-world experiments. The simulation results also show that the proposed approach leads to better spatial precision and grasp accuracy compared to a baseline approach.
</details>
<details>
<summary>摘要</summary>
Objects we interact with and manipulate often share similar parts, such as handles, that allow us to transfer our actions flexibly due to their shared functionality. This work addresses the problem of transferring a grasp experience or a demonstration to a novel object that shares shape similarities with objects the robot has previously encountered. Existing approaches for solving this problem are typically restricted to a specific object category or a parametric shape. Our approach, however, can transfer grasps associated with implicit models of local surfaces shared across object categories. Specifically, we employ a single expert grasp demonstration to learn an implicit local surface representation model from a small dataset of object meshes. At inference time, this model is used to transfer grasps to novel objects by identifying the most geometrically similar surfaces to the one on which the expert grasp is demonstrated. Our model is trained entirely in simulation and is evaluated on simulated and real-world objects that are not seen during training. Evaluations indicate that grasp transfer to unseen object categories using this approach can be successfully performed both in simulation and real-world experiments. The simulation results also show that the proposed approach leads to better spatial precision and grasp accuracy compared to a baseline approach.Here's the text in Traditional Chinese:objects we interact with and manipulate often share similar parts, such as handles, that allow us to transfer our actions flexibly due to their shared functionality. This work addresses the problem of transferring a grasp experience or a demonstration to a novel object that shares shape similarities with objects the robot has previously encountered. Existing approaches for solving this problem are typically restricted to a specific object category or a parametric shape. Our approach, however, can transfer grasps associated with implicit models of local surfaces shared across object categories. Specifically, we employ a single expert grasp demonstration to learn an implicit local surface representation model from a small dataset of object meshes. At inference time, this model is used to transfer grasps to novel objects by identifying the most geometrically similar surfaces to the one on which the expert grasp is demonstrated. Our model is trained entirely in simulation and is evaluated on simulated and real-world objects that are not seen during training. Evaluations indicate that grasp transfer to unseen object categories using this approach can be successfully performed both in simulation and real-world experiments. The simulation results also show that the proposed approach leads to better spatial precision and grasp accuracy compared to a baseline approach.
</details></li>
</ul>
<hr>
<h2 id="Neuromorphic-Seatbelt-State-Detection-for-In-Cabin-Monitoring-with-Event-Cameras"><a href="#Neuromorphic-Seatbelt-State-Detection-for-In-Cabin-Monitoring-with-Event-Cameras" class="headerlink" title="Neuromorphic Seatbelt State Detection for In-Cabin Monitoring with Event Cameras"></a>Neuromorphic Seatbelt State Detection for In-Cabin Monitoring with Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07802">http://arxiv.org/abs/2308.07802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Kielty, Cian Ryan, Mehdi Sefidgar Dilmaghani, Waseem Shariff, Joe Lemley, Peter Corcoran</li>
<li>for: 这个论文主要是为了研究如何使用事件摄像机在座位安全系统中检测安全带状态。</li>
<li>methods: 这篇论文使用了事件生成器生成的Synthetic neuromorphic frames，以及基于循环卷积神经网络的检测算法。</li>
<li>results: 论文的实验结果显示，在 binary 分类任务中，fastened&#x2F;unfastened 帧的识别精度为 0.989 和 0.944 分别在 simulated 和 real test sets 上。当问题扩展到包括快速安全带的扭矩时，分别达到了 0.964 和 0.846 的 F1 分数。<details>
<summary>Abstract</summary>
Neuromorphic vision sensors, or event cameras, differ from conventional cameras in that they do not capture images at a specified rate. Instead, they asynchronously log local brightness changes at each pixel. As a result, event cameras only record changes in a given scene, and do so with very high temporal resolution, high dynamic range, and low power requirements. Recent research has demonstrated how these characteristics make event cameras extremely practical sensors in driver monitoring systems (DMS), enabling the tracking of high-speed eye motion and blinks. This research provides a proof of concept to expand event-based DMS techniques to include seatbelt state detection. Using an event simulator, a dataset of 108,691 synthetic neuromorphic frames of car occupants was generated from a near-infrared (NIR) dataset, and split into training, validation, and test sets for a seatbelt state detection algorithm based on a recurrent convolutional neural network (CNN). In addition, a smaller set of real event data was collected and reserved for testing. In a binary classification task, the fastened/unfastened frames were identified with an F1 score of 0.989 and 0.944 on the simulated and real test sets respectively. When the problem extended to also classify the action of fastening/unfastening the seatbelt, respective F1 scores of 0.964 and 0.846 were achieved.
</details>
<details>
<summary>摘要</summary>
neuromorphic vision sensors 或事件摄像头，与传统摄像头不同，不是预先定义的帧率来捕捉图像。相反，它们在每个像素上逐渐记录当地明亮变化。这意味着事件摄像头只记录场景中的变化，并且具有非常高的时间分辨率、高动态范围和低功耗要求。最新的研究表明，这些特点使得事件摄像头成为了非常实用的护身伞系统（DMS）感知器，可以跟踪高速眼动和耶飞。这些研究提供了扩展事件基于DMS技术的证明，包括座席安全带状态检测。使用事件模拟器，一个由近红外（NIR）数据集生成的108,691个神经元模拟帧的车Occupants dataset被生成，并被分配到训练、验证和测试集中。此外，一个更小的真实事件数据集也被收集并保留用于测试。在一个二分类任务中，带fastened/unfastened帧被识别出来，F1分数分别为0.989和0.944。当问题扩展到还包括快速安装/解除座席安全带的动作时，分别获得了0.964和0.846的F1分数。
</details></li>
</ul>
<hr>
<h2 id="Handwritten-Stenography-Recognition-and-the-LION-Dataset"><a href="#Handwritten-Stenography-Recognition-and-the-LION-Dataset" class="headerlink" title="Handwritten Stenography Recognition and the LION Dataset"></a>Handwritten Stenography Recognition and the LION Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07799">http://arxiv.org/abs/2308.07799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://zenodo.org/record/8249818">https://zenodo.org/record/8249818</a></li>
<li>paper_authors: Raphaela Heil, Malin Nauwerck</li>
<li>for: 这篇论文的目的是建立一个基准模型，用于识别手写stenography。</li>
<li>methods: 这篇论文使用了现有的文本识别模型，并应用了四种不同的编码方法，将目标序列转换成表示selected aspects of the writing system。此外，还使用了预训练方案，基于合成数据。</li>
<li>results: 基准模型在测试集上的平均字符错误率（CER）为29.81%，word error rate（WER）为55.14%。通过结合stenography-specific target sequence encodings、预训练和细化，可以大幅降低测试错误率，CER在24.5% - 26%之间，WER在44.8% - 48.2%之间。<details>
<summary>Abstract</summary>
Purpose: In this paper, we establish a baseline for handwritten stenography recognition, using the novel LION dataset, and investigate the impact of including selected aspects of stenographic theory into the recognition process. We make the LION dataset publicly available with the aim of encouraging future research in handwritten stenography recognition.   Methods: A state-of-the-art text recognition model is trained to establish a baseline. Stenographic domain knowledge is integrated by applying four different encoding methods that transform the target sequence into representations, which approximate selected aspects of the writing system. Results are further improved by integrating a pre-training scheme, based on synthetic data.   Results: The baseline model achieves an average test character error rate (CER) of 29.81% and a word error rate (WER) of 55.14%. Test error rates are reduced significantly by combining stenography-specific target sequence encodings with pre-training and fine-tuning, yielding CERs in the range of 24.5% - 26% and WERs of 44.8% - 48.2%.   Conclusion: The obtained results demonstrate the challenging nature of stenography recognition. Integrating stenography-specific knowledge, in conjunction with pre-training and fine-tuning on synthetic data, yields considerable improvements. Together with our precursor study on the subject, this is the first work to apply modern handwritten text recognition to stenography. The dataset and our code are publicly available via Zenodo.
</details>
<details>
<summary>摘要</summary>
目的：在这篇论文中，我们建立了手写stenography认识基线，使用新的LION数据集，并研究包括选择的stenographic理论方面的影响。我们将LION数据集公开提供，以促进未来的手写stenography认识研究。方法：我们使用现代文本认识模型进行基线建立。stenographic领域知识被集成，通过将目标序列转换为表示形式，以估计选择的stenographic特征。此外，我们还使用基于Synthetic数据的预训练方案，进一步改进结果。结果：基线模型在测试集上的平均字符错误率（CER）为29.81%，单词错误率（WER）为55.14%。通过将stenography特有的target序列编码与预训练和细化结合使用，可以将测试错误率显著降低到24.5% - 26%之间的CER，以及44.8% - 48.2%之间的WER。结论：我们的结果表明stenography认识是一项非常具有挑战性的任务。通过结合stenography特有的知识和预训练和细化，可以获得显著的改进。这是现代手写文本认识在stenography领域的第一篇研究，同时我们的数据集和代码也公开提供了via Zenodo。
</details></li>
</ul>
<hr>
<h2 id="DiffV2S-Diffusion-based-Video-to-Speech-Synthesis-with-Vision-guided-Speaker-Embedding"><a href="#DiffV2S-Diffusion-based-Video-to-Speech-Synthesis-with-Vision-guided-Speaker-Embedding" class="headerlink" title="DiffV2S: Diffusion-based Video-to-Speech Synthesis with Vision-guided Speaker Embedding"></a>DiffV2S: Diffusion-based Video-to-Speech Synthesis with Vision-guided Speaker Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07787">http://arxiv.org/abs/2308.07787</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joannahong/diffv2s">https://github.com/joannahong/diffv2s</a></li>
<li>paper_authors: Jeongsoo Choi, Joanna Hong, Yong Man Ro</li>
<li>for: 这个论文的目的是提出一种基于自我超vised学习模型和提示调整技术的视觉导航 speaker embedding抽取器，以便在推理时不需要外部音频信息。</li>
<li>methods: 该论文使用了一种基于自我超vised学习模型和提示调整技术的视觉导航 speaker embedding抽取器，以及一种基于这些 speaker embedding 和视觉表示的扩散基于视频到语音Synthesis模型。</li>
<li>results: 该论文的实验结果显示，使用该视觉导航 speaker embedding抽取器和扩散基于视频到语音Synthesis模型可以保持输入视频帧中的音频细节，同时还可以在推理时不需要外部音频信息。这些方法在比较之前的视频到语音Synthesis技术中达到了state-of-the-art的性能。<details>
<summary>Abstract</summary>
Recent research has demonstrated impressive results in video-to-speech synthesis which involves reconstructing speech solely from visual input. However, previous works have struggled to accurately synthesize speech due to a lack of sufficient guidance for the model to infer the correct content with the appropriate sound. To resolve the issue, they have adopted an extra speaker embedding as a speaking style guidance from a reference auditory information. Nevertheless, it is not always possible to obtain the audio information from the corresponding video input, especially during the inference time. In this paper, we present a novel vision-guided speaker embedding extractor using a self-supervised pre-trained model and prompt tuning technique. In doing so, the rich speaker embedding information can be produced solely from input visual information, and the extra audio information is not necessary during the inference time. Using the extracted vision-guided speaker embedding representations, we further develop a diffusion-based video-to-speech synthesis model, so called DiffV2S, conditioned on those speaker embeddings and the visual representation extracted from the input video. The proposed DiffV2S not only maintains phoneme details contained in the input video frames, but also creates a highly intelligible mel-spectrogram in which the speaker identities of the multiple speakers are all preserved. Our experimental results show that DiffV2S achieves the state-of-the-art performance compared to the previous video-to-speech synthesis technique.
</details>
<details>
<summary>摘要</summary>
最新的研究表明，视频到语音合成技术已经取得了很好的结果，即从视觉输入重建说话。然而，之前的工作很难准确地合成说话，因为缺乏足够的指导，使模型很难准确地推断出正确的内容和相应的声音。为解决这个问题，他们采用了Extra speaker embedding作为引导，从参考音频信息中获得。然而，在推断时不一定可以获得相应的音频信息，特别是在推断时。在这篇论文中，我们提出了一种新的视觉引导的Speaker embedding抽取器，使用自我超visumodel和提示调整技术。在这种情况下，可以从输入视频信息中提取出富有的Speaker embedding信息，不需要外部音频信息。使用提取的视觉引导Speaker embedding表示，我们进一步发展了一种扩散基于的视频到语音合成模型，称为DiffV2S。DiffV2S Conditioned on these speaker embeddings and the visual representation extracted from the input video, the proposed DiffV2S not only maintains the phoneme details contained in the input video frames, but also creates a highly intelligible mel-spectrogram in which the speaker identities of the multiple speakers are all preserved. Our experimental results show that DiffV2S achieves the state-of-the-art performance compared to the previous video-to-speech synthesis technique.
</details></li>
</ul>
<hr>
<h2 id="Future-Video-Prediction-from-a-Single-Frame-for-Video-Anomaly-Detection"><a href="#Future-Video-Prediction-from-a-Single-Frame-for-Video-Anomaly-Detection" class="headerlink" title="Future Video Prediction from a Single Frame for Video Anomaly Detection"></a>Future Video Prediction from a Single Frame for Video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07783">http://arxiv.org/abs/2308.07783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Baradaran, Robert Bergevin</li>
<li>for: 这篇论文的目的是提出一个新的代理任务，即从单一帧画面中预测未来的影片，以便实现影片异常检测（VAD）中的长期运动模型。</li>
<li>methods: 这篇论文使用了一种新的semi-supervised anomaly detection方法，具体来说是使用未来帧画面预测作为代理任务，并将初始和未来的原始帧替换为它们的Semantic segmentation map，以增强模型的敏感度和精度。</li>
<li>results: 实验结果显示，这篇论文的方法能够实现长期运动模型的学习，并且与现有的预测基于VAD方法相比，具有更高的效果和精度。<details>
<summary>Abstract</summary>
Video anomaly detection (VAD) is an important but challenging task in computer vision. The main challenge rises due to the rarity of training samples to model all anomaly cases. Hence, semi-supervised anomaly detection methods have gotten more attention, since they focus on modeling normals and they detect anomalies by measuring the deviations from normal patterns. Despite impressive advances of these methods in modeling normal motion and appearance, long-term motion modeling has not been effectively explored so far. Inspired by the abilities of the future frame prediction proxy-task, we introduce the task of future video prediction from a single frame, as a novel proxy-task for video anomaly detection. This proxy-task alleviates the challenges of previous methods in learning longer motion patterns. Moreover, we replace the initial and future raw frames with their corresponding semantic segmentation map, which not only makes the method aware of object class but also makes the prediction task less complex for the model. Extensive experiments on the benchmark datasets (ShanghaiTech, UCSD-Ped1, and UCSD-Ped2) show the effectiveness of the method and the superiority of its performance compared to SOTA prediction-based VAD methods.
</details>
<details>
<summary>摘要</summary>
视频异常检测（VAD）是计算机视觉中的一项重要而困难的任务。主要挑战在于缺乏异常情况下训练样本，因此半监督异常检测方法在过去几年中得到了更多的关注，这些方法通过模型常规动作和出现异常的方式进行检测。 despite impressive advances of these methods in modeling normal motion and appearance, long-term motion modeling has not been effectively explored so far. 鼓励了未来帧预测代理任务的能力，我们引入了从单一帧预测未来视频的任务，作为一种新的代理任务，以解决先前方法学习更长的动作模式的挑战。此外，我们将初始和未来的原始帧替换为它们对应的 semantic segmentation map，这不仅使得方法能够识别物体类型，还使得预测任务对模型更加简单。我们在 ShanghaiTech、UCSD-Ped1 和 UCSD-Ped2  benchmark datasets 进行了广泛的实验，并证明了方法的有效性和与State-of-the-art（SOTA）预测基于 VAD 方法的性能的superiority。
</details></li>
</ul>
<hr>
<h2 id="Learning-Image-Deraining-Transformer-Network-with-Dynamic-Dual-Self-Attention"><a href="#Learning-Image-Deraining-Transformer-Network-with-Dynamic-Dual-Self-Attention" class="headerlink" title="Learning Image Deraining Transformer Network with Dynamic Dual Self-Attention"></a>Learning Image Deraining Transformer Network with Dynamic Dual Self-Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07781">http://arxiv.org/abs/2308.07781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhentao Fan, Hongming Chen, Yufeng Li</li>
<li>for: 本研究旨在提出一种高效的单张图像雨水去除方法，使用Transformer架构和动态双层自注意（DDSA）精确地捕捉图像中的雨水信息。</li>
<li>methods: 本方法使用了动态双层自注意（DDSA）精确地选择图像中的相似性值，并结合了一种新的空间增强Feedforward网络（SEFN）来提高图像的重建质量。</li>
<li>results: 经验表明，本方法在标准数据集上达到了高质量的雨水去除效果，并且在不同的雨水环境下都能够保持高度的稳定性。<details>
<summary>Abstract</summary>
Recently, Transformer-based architecture has been introduced into single image deraining task due to its advantage in modeling non-local information. However, existing approaches tend to integrate global features based on a dense self-attention strategy since it tend to uses all similarities of the tokens between the queries and keys. In fact, this strategy leads to ignoring the most relevant information and inducing blurry effect by the irrelevant representations during the feature aggregation. To this end, this paper proposes an effective image deraining Transformer with dynamic dual self-attention (DDSA), which combines both dense and sparse attention strategies to better facilitate clear image reconstruction. Specifically, we only select the most useful similarity values based on top-k approximate calculation to achieve sparse attention. In addition, we also develop a novel spatial-enhanced feed-forward network (SEFN) to further obtain a more accurate representation for achieving high-quality derained results. Extensive experiments on benchmark datasets demonstrate the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
最近，基于Transformer架构的单图雨水减除技术在单图雨水减除任务中得到应用。这是因为Transformer架构可以更好地模型非本地信息。然而，现有的方法通常会将全球特征集成到一个笔 dense self-attention策略中，这会导致忽略最重要的信息并通过不相关的表示导致图像重建的模糊效果。为了解决这个问题，本文提出了一种高效的图像雨水减除Transformer（DDSA），它结合了密集和疏缺注意策略来更好地促进清晰图像重建。具体来说，我们只选择最有用的相似性值，并通过top-k相似计算来实现疏缺注意。此外，我们还开发了一种新的空间增强Feed-Forward网络（SEFN），以更好地获得更高质量的雨水减除结果。我们在标准数据集上进行了广泛的实验，并证明了我们的提议的效果。
</details></li>
</ul>
<hr>
<h2 id="An-Interpretable-Machine-Learning-Model-with-Deep-Learning-based-Imaging-Biomarkers-for-Diagnosis-of-Alzheimer’s-Disease"><a href="#An-Interpretable-Machine-Learning-Model-with-Deep-Learning-based-Imaging-Biomarkers-for-Diagnosis-of-Alzheimer’s-Disease" class="headerlink" title="An Interpretable Machine Learning Model with Deep Learning-based Imaging Biomarkers for Diagnosis of Alzheimer’s Disease"></a>An Interpretable Machine Learning Model with Deep Learning-based Imaging Biomarkers for Diagnosis of Alzheimer’s Disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07778">http://arxiv.org/abs/2308.07778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Kang, Bo Li, Janne M. Papma, Lize C. Jiskoot, Peter Paul De Deyn, Geert Jan Biessels, Jurgen A. H. R. Claassen, Huub A. M. Middelkoop, Wiesje M. van der Flier, Inez H. G. B. Ramakers, Stefan Klein, Esther E. Bron</li>
<li>for: 本研究旨在提出一种可解释的机器学习框架，用于自动早期诊断阿尔茨heimer病（AD）。</li>
<li>methods: 本研究使用了可解释的机器学习模型（EBM），并使用深度学习来提取特征。</li>
<li>results: 研究在Alzheimer’s Disease Neuroimaging Initiative（ADNI）数据集上 achieved accuracy of 0.883和area-under-the-curve（AUC）of 0.970在AD和控制分类中。在一个外部测试集上也达到了accuracy of 0.778和AUC of 0.887在AD和主观认知下降（SCD）分类中。 compared to使用体量生物标志代替深度学习特征的EBM模型，以及一个优化的 convolutional neural network（CNN）模型。<details>
<summary>Abstract</summary>
Machine learning methods have shown large potential for the automatic early diagnosis of Alzheimer's Disease (AD). However, some machine learning methods based on imaging data have poor interpretability because it is usually unclear how they make their decisions. Explainable Boosting Machines (EBMs) are interpretable machine learning models based on the statistical framework of generalized additive modeling, but have so far only been used for tabular data. Therefore, we propose a framework that combines the strength of EBM with high-dimensional imaging data using deep learning-based feature extraction. The proposed framework is interpretable because it provides the importance of each feature. We validated the proposed framework on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, achieving accuracy of 0.883 and area-under-the-curve (AUC) of 0.970 on AD and control classification. Furthermore, we validated the proposed framework on an external testing set, achieving accuracy of 0.778 and AUC of 0.887 on AD and subjective cognitive decline (SCD) classification. The proposed framework significantly outperformed an EBM model using volume biomarkers instead of deep learning-based features, as well as an end-to-end convolutional neural network (CNN) with optimized architecture.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Dual-path-TokenLearner-for-Remote-Photoplethysmography-based-Physiological-Measurement-with-Facial-Videos"><a href="#Dual-path-TokenLearner-for-Remote-Photoplethysmography-based-Physiological-Measurement-with-Facial-Videos" class="headerlink" title="Dual-path TokenLearner for Remote Photoplethysmography-based Physiological Measurement with Facial Videos"></a>Dual-path TokenLearner for Remote Photoplethysmography-based Physiological Measurement with Facial Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07771">http://arxiv.org/abs/2308.07771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Qian, Dan Guo, Kun Li, Xilan Tian, Meng Wang</li>
<li>for: 这个论文旨在提出一种基于 Transformer 框架的远程光谱 Plethysmography (rPPG) 测量方法，以减少干扰因素的影响，提高测量精度。</li>
<li>methods: 该方法使用了两种 TokenLearner（S-TL 和 T-TL）来捕捉不同的 facial ROI 之间的关系，以及 quasi- periodic  patrern 的推断，以减少干扰因素的影响。</li>
<li>results: 在四个 physiological measurement  benchmark 数据集上进行了广泛的实验，结果表明 Dual-TL 可以在 intra- 和 cross-dataset 测试中达到 state-of-the-art 性能，表明其在 rPPG 测量中的潜在应用前景。<details>
<summary>Abstract</summary>
Remote photoplethysmography (rPPG) based physiological measurement is an emerging yet crucial vision task, whose challenge lies in exploring accurate rPPG prediction from facial videos accompanied by noises of illumination variations, facial occlusions, head movements, \etc, in a non-contact manner. Existing mainstream CNN-based models make efforts to detect physiological signals by capturing subtle color changes in facial regions of interest (ROI) caused by heartbeats. However, such models are constrained by the limited local spatial or temporal receptive fields in the neural units. Unlike them, a native Transformer-based framework called Dual-path TokenLearner (Dual-TL) is proposed in this paper, which utilizes the concept of learnable tokens to integrate both spatial and temporal informative contexts from the global perspective of the video. Specifically, the proposed Dual-TL uses a Spatial TokenLearner (S-TL) to explore associations in different facial ROIs, which promises the rPPG prediction far away from noisy ROI disturbances. Complementarily, a Temporal TokenLearner (T-TL) is designed to infer the quasi-periodic pattern of heartbeats, which eliminates temporal disturbances such as head movements. The two TokenLearners, S-TL and T-TL, are executed in a dual-path mode. This enables the model to reduce noise disturbances for final rPPG signal prediction. Extensive experiments on four physiological measurement benchmark datasets are conducted. The Dual-TL achieves state-of-the-art performances in both intra- and cross-dataset testings, demonstrating its immense potential as a basic backbone for rPPG measurement. The source code is available at \href{https://github.com/VUT-HFUT/Dual-TL}{https://github.com/VUT-HFUT/Dual-TL}
</details>
<details>
<summary>摘要</summary>
distant photoplethysmography (rPPG) 基于视频的生物指标测量是一个emerging yet crucial vision task， whose challenge lies in accurately predicting rPPG from facial videos accompanied by illumination variations, facial occlusions, head movements, etc. in a non-contact manner. Existing mainstream CNN-based models make efforts to detect physiological signals by capturing subtle color changes in facial regions of interest (ROI) caused by heartbeats. However, such models are constrained by the limited local spatial or temporal receptive fields in the neural units. Unlike them, a native Transformer-based framework called Dual-path TokenLearner (Dual-TL) is proposed in this paper, which utilizes the concept of learnable tokens to integrate both spatial and temporal informative contexts from the global perspective of the video. Specifically, the proposed Dual-TL uses a Spatial TokenLearner (S-TL) to explore associations in different facial ROIs, which promises the rPPG prediction far away from noisy ROI disturbances. Complementarily, a Temporal TokenLearner (T-TL) is designed to infer the quasi-periodic pattern of heartbeats, which eliminates temporal disturbances such as head movements. The two TokenLearners, S-TL and T-TL, are executed in a dual-path mode. This enables the model to reduce noise disturbances for final rPPG signal prediction. Extensive experiments on four physiological measurement benchmark datasets are conducted. The Dual-TL achieves state-of-the-art performances in both intra- and cross-dataset testings, demonstrating its immense potential as a basic backbone for rPPG measurement. The source code is available at \href{https://github.com/VUT-HFUT/Dual-TL}{https://github.com/VUT-HFUT/Dual-TL}.
</details></li>
</ul>
<hr>
<h2 id="Multi-scale-Promoted-Self-adjusting-Correlation-Learning-for-Facial-Action-Unit-Detection"><a href="#Multi-scale-Promoted-Self-adjusting-Correlation-Learning-for-Facial-Action-Unit-Detection" class="headerlink" title="Multi-scale Promoted Self-adjusting Correlation Learning for Facial Action Unit Detection"></a>Multi-scale Promoted Self-adjusting Correlation Learning for Facial Action Unit Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07770">http://arxiv.org/abs/2308.07770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuankaishen2001/Self-adjusting-AU">https://github.com/yuankaishen2001/Self-adjusting-AU</a></li>
<li>paper_authors: Xin Liu, Kaishen Yuan, Xuesong Niu, Jingang Shi, Zitong Yu, Huanjing Yue, Jingyu Yang</li>
<li>for: 这个论文旨在提出一种新的自适应AU相关学习方法（SACL），以提高人类表情识别task中AU相关性的准确性和效率。</li>
<li>methods: 本文使用了一种自适应AU相关学习方法，通过约束AU相关性的学习和更新，以及一种多层学习（MSFL）方法，将多个尺度的特征学习到一个统一的表征中。</li>
<li>results: 实验结果显示，提案的方法在广泛使用的AU识别benchmark datasets上表现出色，与现有的方法相比，只需28.7%和12.0%的parameters和FLOPs，并且具有较高的准确性和稳定性。<details>
<summary>Abstract</summary>
Facial Action Unit (AU) detection is a crucial task in affective computing and social robotics as it helps to identify emotions expressed through facial expressions. Anatomically, there are innumerable correlations between AUs, which contain rich information and are vital for AU detection. Previous methods used fixed AU correlations based on expert experience or statistical rules on specific benchmarks, but it is challenging to comprehensively reflect complex correlations between AUs via hand-crafted settings. There are alternative methods that employ a fully connected graph to learn these dependencies exhaustively. However, these approaches can result in a computational explosion and high dependency with a large dataset. To address these challenges, this paper proposes a novel self-adjusting AU-correlation learning (SACL) method with less computation for AU detection. This method adaptively learns and updates AU correlation graphs by efficiently leveraging the characteristics of different levels of AU motion and emotion representation information extracted in different stages of the network. Moreover, this paper explores the role of multi-scale learning in correlation information extraction, and design a simple yet effective multi-scale feature learning (MSFL) method to promote better performance in AU detection. By integrating AU correlation information with multi-scale features, the proposed method obtains a more robust feature representation for the final AU detection. Extensive experiments show that the proposed method outperforms the state-of-the-art methods on widely used AU detection benchmark datasets, with only 28.7\% and 12.0\% of the parameters and FLOPs of the best method, respectively. The code for this method is available at \url{https://github.com/linuxsino/Self-adjusting-AU}.
</details>
<details>
<summary>摘要</summary>
Facial Action Unit (AU) 检测是影响情感计算和社会机器人的关键任务，因为它帮助确定人脸表达中的情感。生物学上来说，AU 之间存在无数关系，这些关系含有丰富的信息，对 AU 检测至关重要。以前的方法通过专家经验或统计规则在特定基准上预先定义 AU 关系，但这些方法无法全面反映复杂的 AU 关系。其他方法使用完全连接图来学习这些依赖关系，但这些方法可能会导致计算暴涨和大量数据依赖。为解决这些挑战，本文提出了一种新的自适应AU correlation学习方法（SACL），它具有较少的计算量，但能够提高 AU 检测的性能。SACL 方法通过有效地利用不同层次AU动作特征和情感表示信息来学习和更新 AU 关系图。此外，本文还探讨了多尺度学习在相关信息提取中的作用，并设计了一种简单 yet 有效的多尺度特征学习（MSFL）方法，以提高 AU 检测的性能。通过将 AU 关系信息与多尺度特征结合，提出的方法可以获得更加稳定的特征表示，进而提高 AU 检测的准确率。广泛的实验表明，提出的方法在多个常用 AU 检测基准数据集上的性能较之前的状态艺法高，仅使用 28.7% 和 12.0% 的参数和 FLOPs。代码可以在 <https://github.com/linuxsino/Self-adjusting-AU> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Whale-Detection-Enhancement-through-Synthetic-Satellite-Images"><a href="#Whale-Detection-Enhancement-through-Synthetic-Satellite-Images" class="headerlink" title="Whale Detection Enhancement through Synthetic Satellite Images"></a>Whale Detection Enhancement through Synthetic Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07766">http://arxiv.org/abs/2308.07766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prgumd/seadronesim2">https://github.com/prgumd/seadronesim2</a></li>
<li>paper_authors: Akshaj Gaur, Cheng Liu, Xiaomin Lin, Nare Karapetyan, Yiannis Aloimonos</li>
<li>for: 该研究目的是开发一个名为SeaDroneSim2的测试环境和数据集，以提高鲸鱼检测和减少训练数据收集的努力。</li>
<li>methods: 该研究使用现代计算机视觉算法和人工智能技术来生成synthetic图像数据集，以便用于训练机器学习算法。</li>
<li>results: 研究发现，通过将synthetic数据集与实际数据集相结合训练，可以提高鲸鱼检测性能15%，而不需要额外的数据收集努力。<details>
<summary>Abstract</summary>
With a number of marine populations in rapid decline, collecting and analyzing data about marine populations has become increasingly important to develop effective conservation policies for a wide range of marine animals, including whales. Modern computer vision algorithms allow us to detect whales in images in a wide range of domains, further speeding up and enhancing the monitoring process. However, these algorithms heavily rely on large training datasets, which are challenging and time-consuming to collect particularly in marine or aquatic environments. Recent advances in AI however have made it possible to synthetically create datasets for training machine learning algorithms, thus enabling new solutions that were not possible before. In this work, we present a solution - SeaDroneSim2 benchmark suite, which addresses this challenge by generating aerial, and satellite synthetic image datasets to improve the detection of whales and reduce the effort required for training data collection. We show that we can achieve a 15% performance boost on whale detection compared to using the real data alone for training, by augmenting a 10% real data. We open source both the code of the simulation platform SeaDroneSim2 and the dataset generated through it.
</details>
<details>
<summary>摘要</summary>
“由于海洋生物种群在快速减少，收集和分析海洋生物数据已成为保护各种海洋动物，包括鲸鱼的重要策略。现代计算机视觉算法可以在各种领域中检测鲸鱼的图像，从而加速和提高监测过程。然而，这些算法具有大量训练数据的需求，特别是在海洋或水生环境中收集这些数据是困难和耗时的。最近的人工智能技术 however 使得可以 sintetically create datasets for training machine learning algorithms，从而开启了以前不可能的解决方案。在这项工作中，我们提出一个解决方案 - SeaDroneSim2  benchmark suite，它解决了这个挑战，通过生成航空和卫星synthetic图像数据，以提高鲸鱼检测的准确率。我们证明，通过将10%的实际数据与15%的synthetic数据混合，可以在训练中提高鲸鱼检测的性能，相比使用实际数据 alone。我们开源了 SeaDroneSim2 的代码和生成的数据集。”Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="CASPNet-Joint-Multi-Agent-Motion-Prediction"><a href="#CASPNet-Joint-Multi-Agent-Motion-Prediction" class="headerlink" title="CASPNet++: Joint Multi-Agent Motion Prediction"></a>CASPNet++: Joint Multi-Agent Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07751">http://arxiv.org/abs/2308.07751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Schäfer, Kun Zhao, Anton Kummert</li>
<li>for: 本研究旨在提高自动驾驶技术的支持，具体来说是预测道路用户未来的运动。</li>
<li>methods: 本研究使用Context-Aware Scene Prediction Network (CASPNet)的改进版本CASPNet++，通过改进景象理解和交互模型，支持场景中所有道路用户的联合预测。此外，还引入了基于实例的输出头，以提供多模态的轨迹。</li>
<li>results: 在EXTENSIVE量化和质量分析中，我们展示了CASPNet++在使用和融合多种环境输入源（如HD地图、雷达探测和激光分 segmentation）的能力。在 nuScenes 城市预测数据集上测试，CASPNet++达到了现状之最的性能。模型已经在测试车辆中部署，并在实时下运行，具有moderate的计算资源。<details>
<summary>Abstract</summary>
The prediction of road users' future motion is a critical task in supporting advanced driver-assistance systems (ADAS). It plays an even more crucial role for autonomous driving (AD) in enabling the planning and execution of safe driving maneuvers. Based on our previous work, Context-Aware Scene Prediction Network (CASPNet), an improved system, CASPNet++, is proposed. In this work, we focus on further enhancing the interaction modeling and scene understanding to support the joint prediction of all road users in a scene using spatiotemporal grids to model future occupancy. Moreover, an instance-based output head is introduced to provide multi-modal trajectories for agents of interest. In extensive quantitative and qualitative analysis, we demonstrate the scalability of CASPNet++ in utilizing and fusing diverse environmental input sources such as HD maps, Radar detection, and Lidar segmentation. Tested on the urban-focused prediction dataset nuScenes, CASPNet++ reaches state-of-the-art performance. The model has been deployed in a testing vehicle, running in real-time with moderate computational resources.
</details>
<details>
<summary>摘要</summary>
预测路用户未来运动是智能驾驶技术支持的关键任务之一，尤其是自动驾驶（AD）。在这种情况下，预测安全驾驶动作的能力变得非常重要。基于我们之前的工作，Context-Aware Scene Prediction Network（CASPNet），我们提出了改进的系统CASPNet++。在这个工作中，我们将更进一步地提高交互模型和场景理解，以支持场景中所有道路用户的未来运动预测。此外，我们还引入了基于实例的输出头，以提供多模态轨迹 для关注点。在详细的量化和质量分析中，我们示出了CASPNet++在使用和融合多种环境输入源，如高分辨环境地图、雷达探测和激光分 segmentation 的可扩展性。在 nuScenes 城市预测数据集上，CASPNet++ 达到了状态agh 的性能。模型已经在测试车辆上部署，在实时运行中具有中等计算资源。
</details></li>
</ul>
<hr>
<h2 id="ChartDETR-A-Multi-shape-Detection-Network-for-Visual-Chart-Recognition"><a href="#ChartDETR-A-Multi-shape-Detection-Network-for-Visual-Chart-Recognition" class="headerlink" title="ChartDETR: A Multi-shape Detection Network for Visual Chart Recognition"></a>ChartDETR: A Multi-shape Detection Network for Visual Chart Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07743">http://arxiv.org/abs/2308.07743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenyuan Xue, Dapeng Chen, Baosheng Yu, Yifei Chen, Sai Zhou, Wei Peng<br>for: 这篇论文的目的是提出一种基于变换器的多形态检测器，以便自动从图表图像中识别表头和数据元素。methods: 该方法使用变换器来地址现有方法中的分组错误，通过引入查询组来预测所有数据元素形状，从而消除后期处理步骤。results: 该方法在三个 dataset 上达到了竞争性的 результа，包括在 Adobe Synthetic 上达到了 0.98 的 F1 分数，与之前最佳模型的 0.71  F1 分数相比显著提高。此外，我们也实现了一个新的状态对标结果，达到了 ExcelChart400k 上的 0.97。<details>
<summary>Abstract</summary>
Visual chart recognition systems are gaining increasing attention due to the growing demand for automatically identifying table headers and values from chart images. Current methods rely on keypoint detection to estimate data element shapes in charts but suffer from grouping errors in post-processing. To address this issue, we propose ChartDETR, a transformer-based multi-shape detector that localizes keypoints at the corners of regular shapes to reconstruct multiple data elements in a single chart image. Our method predicts all data element shapes at once by introducing query groups in set prediction, eliminating the need for further postprocessing. This property allows ChartDETR to serve as a unified framework capable of representing various chart types without altering the network architecture, effectively detecting data elements of diverse shapes. We evaluated ChartDETR on three datasets, achieving competitive results across all chart types without any additional enhancements. For example, ChartDETR achieved an F1 score of 0.98 on Adobe Synthetic, significantly outperforming the previous best model with a 0.71 F1 score. Additionally, we obtained a new state-of-the-art result of 0.97 on ExcelChart400k. The code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
“图表识别系统在当前receiving increasing attention，主要是因为需要自动从图表图像中识别表头和数据值。现有方法通过关键点检测来估算图表元素的形状，但是会在后处理中出现分组错误。为解决这个问题，我们提出了 ChartDETR，一种基于transformer的多形态检测器，可以在单个图表图像中寻找多个数据元素的角点。我们的方法通过设置查询组来预测所有数据元素的形状，从而消除后处理步骤。这个特性使得 ChartDETR 可以作为一个通用的框架，无需修改网络结构，可以有效地检测各种图表类型中的数据元素。我们对 ChartDETR 进行了三个数据集的评估，实现了所有图表类型中的竞争性结果，不需要任何额外增强。例如，在 Adobe Synthetic 数据集上，ChartDETR  achieved an F1 score of 0.98，与之前的最佳模型（F1 score 0.71）有所显著超越。此外，我们在 ExcelChart400k 数据集上获得了新的州际最佳结果（F1 score 0.97）。代码将会公开发布。”
</details></li>
</ul>
<hr>
<h2 id="Identity-Consistent-Aggregation-for-Video-Object-Detection"><a href="#Identity-Consistent-Aggregation-for-Video-Object-Detection" class="headerlink" title="Identity-Consistent Aggregation for Video Object Detection"></a>Identity-Consistent Aggregation for Video Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07737">http://arxiv.org/abs/2308.07737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bladewaltz1/clipvid">https://github.com/bladewaltz1/clipvid</a></li>
<li>paper_authors: Chaorui Deng, Da Chen, Qi Wu</li>
<li>for: 在视频对象检测（VID）中，通常利用视频中的丰富时间上下文来提高每帧中的对象表示。现有方法往往对不同对象的时间上下文进行一个汇总，而忽略其不同身份。而intuitively, 将不同对象的本地视图在不同帧中汇总可能为对象的理解提供更好的帮助。因此，在这篇论文中，我们目的是使模型能够专注于每个对象的一致性时间上下文，从而获得更全面的对象表示，并处理快速的对象出现变化，如遮挡、运动模糊等。</li>
<li>methods: 我们提出了一种名为ClipVID的VID模型，它具有特定于个体的汇总（ICA）层，可以为每个对象提取更细致的一致性时间上下文。通过设计非重复的集 Prediction 策略，我们减少了模型的重复性，使ICA层非常高效。此外，我们还设计了一个并行的剪辑clip-wise预测方案，使得整个视频clip的预测都可以在一个时间内完成。</li>
<li>results: 我们的方法在ImageNet VID数据集上实现了state-of-the-art（SOTA）性能（84.7% mAP），而且在7倍的运行速度（39.3 fps）上达到了前一代SOTA的速度。<details>
<summary>Abstract</summary>
In Video Object Detection (VID), a common practice is to leverage the rich temporal contexts from the video to enhance the object representations in each frame. Existing methods treat the temporal contexts obtained from different objects indiscriminately and ignore their different identities. While intuitively, aggregating local views of the same object in different frames may facilitate a better understanding of the object. Thus, in this paper, we aim to enable the model to focus on the identity-consistent temporal contexts of each object to obtain more comprehensive object representations and handle the rapid object appearance variations such as occlusion, motion blur, etc. However, realizing this goal on top of existing VID models faces low-efficiency problems due to their redundant region proposals and nonparallel frame-wise prediction manner. To aid this, we propose ClipVID, a VID model equipped with Identity-Consistent Aggregation (ICA) layers specifically designed for mining fine-grained and identity-consistent temporal contexts. It effectively reduces the redundancies through the set prediction strategy, making the ICA layers very efficient and further allowing us to design an architecture that makes parallel clip-wise predictions for the whole video clip. Extensive experimental results demonstrate the superiority of our method: a state-of-the-art (SOTA) performance (84.7% mAP) on the ImageNet VID dataset while running at a speed about 7x faster (39.3 fps) than previous SOTAs.
</details>
<details>
<summary>摘要</summary>
在视频对象检测（VID）中，一种常见的做法是利用视频中的丰富时间上下文来强化每帧中的对象表示。现有的方法对不同对象的时间上下文待遇一样，而忽略了它们的不同标识。而 intuitively，将不同对象的本地视图在不同帧中聚合可能会更好地理解这些对象。因此，在这篇论文中，我们目标是让模型能够关注每个对象的一致性时间上下文，以获得更全面的对象表示，并处理快速的对象出现变化，如遮挡、动态模糊等。然而，在现有的 VID 模型之上实现这个目标存在低效率的问题，主要是因为它们的重复的区域提案和非平行的帧次预测方式。为了解决这个问题，我们提议 ClipVID，一种具有一致性聚合（ICA）层的 VID 模型，专门用于挖掘细致的时间上下文。它通过设置预测策略，有效减少了重复性，使 ICA 层非常高效，并让我们能够设计一个可以并行预测整个视频剪辑的架构。我们的实验结果表明，我们的方法可以达到最新的状态（SOTA）的性能（84.7% mAP）在 ImageNet VID 数据集上，而且在运行速度方面比前一代 SOTA 快约 7 倍（39.3 fps）。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Low-Rank-Instance-Adaptation-for-Universal-Neural-Image-Compression"><a href="#Dynamic-Low-Rank-Instance-Adaptation-for-Universal-Neural-Image-Compression" class="headerlink" title="Dynamic Low-Rank Instance Adaptation for Universal Neural Image Compression"></a>Dynamic Low-Rank Instance Adaptation for Universal Neural Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07733">http://arxiv.org/abs/2308.07733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llvy21/duic">https://github.com/llvy21/duic</a></li>
<li>paper_authors: Yue Lv, Jinxi Xiang, Jun Zhang, Wenming Yang, Xiao Han, Wei Yang</li>
<li>For: The paper aims to address the domain gap between training and inference datasets in neural image compression, and to improve the rate-distortion performance of out-of-domain images.* Methods: The proposed method uses low-rank adaptation and a dynamic gating network to update the adaptation parameters of the client’s decoder. The low-rank constraint reduces the bit rate overhead, and the dynamic gating network decides which decoder layers should employ adaptation.* Results: The proposed method significantly mitigates the domain gap and outperforms non-adaptive and instance adaptive methods with an average BD-rate improvement of approximately $19%$ and $5%$, respectively. Ablation studies confirm the method’s universality across various image compression architectures.Here is the information in Simplified Chinese text:* 用途：纸上提出了解决神经图像压缩领域中域外图像的问题，并且提高域外图像的率-损失性能。* 方法：提议使用低级别适应和动态阀网络来更新客户端解码器的适应参数。低级别约束 redues the bit rate overhead，而动态阀网络决定了哪些解码层应用适应。* 结果：提议方法能够有效地减少域外图像的域 gap，并且超越非适应方法和实例适应方法，具体是BD-rate上下降约19%和5%。杂合研究证明了方法的通用性。<details>
<summary>Abstract</summary>
The latest advancements in neural image compression show great potential in surpassing the rate-distortion performance of conventional standard codecs. Nevertheless, there exists an indelible domain gap between the datasets utilized for training (i.e., natural images) and those utilized for inference (e.g., artistic images). Our proposal involves a low-rank adaptation approach aimed at addressing the rate-distortion drop observed in out-of-domain datasets. Specifically, we perform low-rank matrix decomposition to update certain adaptation parameters of the client's decoder. These updated parameters, along with image latents, are encoded into a bitstream and transmitted to the decoder in practical scenarios. Due to the low-rank constraint imposed on the adaptation parameters, the resulting bit rate overhead is small. Furthermore, the bit rate allocation of low-rank adaptation is \emph{non-trivial}, considering the diverse inputs require varying adaptation bitstreams. We thus introduce a dynamic gating network on top of the low-rank adaptation method, in order to decide which decoder layer should employ adaptation. The dynamic adaptation network is optimized end-to-end using rate-distortion loss. Our proposed method exhibits universality across diverse image datasets. Extensive results demonstrate that this paradigm significantly mitigates the domain gap, surpassing non-adaptive methods with an average BD-rate improvement of approximately $19\%$ across out-of-domain images. Furthermore, it outperforms the most advanced instance adaptive methods by roughly $5\%$ BD-rate. Ablation studies confirm our method's ability to universally enhance various image compression architectures.
</details>
<details>
<summary>摘要</summary>
最新的神经网络图像压缩技术显示出了超越传统标准编码器的可能性。然而，存在一个不可缓和的领域差距 между训练集（即自然图像）和推理集（例如艺术图像）。我们的提议是通过对客户端解码器的certain adaptation参数进行低级精度约束来解决Rate-Distortion Drop在异领域数据集上。特别是，我们使用低级精度约束来更新客户端解码器的adaptation参数，然后将这些参数、 along with image latents，编码到bitstream中并在实际应用场景中传输。由于低级精度约束的存在，所得到的bit rate overhead很小。此外，低级精度 adaptation的bit rate分配是非易的，需要根据异类输入的需求进行调整。我们因此引入了一个动态闭合网络，以确定哪些解码层应该使用适应。这个动态闭合网络通过练习率-损失函数来优化。我们的提议显示了对各种图像压缩架构的通用性。广泛的结果表明，我们的方法可以减少异领域图像压缩中的领域差距，相比非适应方法的平均BD-rate提高约19%。此外，它还超过了最先进的实例适应方法的BD-rate提高约5%。ablation研究证明了我们的方法可以通过不同的图像压缩架构进行加强。
</details></li>
</ul>
<hr>
<h2 id="UniTR-A-Unified-and-Efficient-Multi-Modal-Transformer-for-Bird’s-Eye-View-Representation"><a href="#UniTR-A-Unified-and-Efficient-Multi-Modal-Transformer-for-Bird’s-Eye-View-Representation" class="headerlink" title="UniTR: A Unified and Efficient Multi-Modal Transformer for Bird’s-Eye-View Representation"></a>UniTR: A Unified and Efficient Multi-Modal Transformer for Bird’s-Eye-View Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07732">http://arxiv.org/abs/2308.07732</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haiyang-w/unitr">https://github.com/haiyang-w/unitr</a></li>
<li>paper_authors: Haiyang Wang, Hao Tang, Shaoshuai Shi, Aoxue Li, Zhenguo Li, Bernt Schiele, Liwei Wang</li>
<li>For: The paper is written for developing an efficient multi-modal backbone for outdoor 3D perception, which can handle a variety of modalities with unified modeling and shared parameters.* Methods: The paper uses a modality-agnostic transformer encoder to handle view-discrepant sensor data for parallel modal-wise representation learning and automatic cross-modal interaction without additional fusion steps. It also presents a novel multi-modal integration strategy that considers semantic-abundant 2D perspective and geometry-aware 3D sparse neighborhood relations.* Results: The paper achieves a new state-of-the-art performance on the nuScenes benchmark, with +1.1 NDS higher for 3D object detection and +12.0 higher mIoU for BEV map segmentation, and lower inference latency.<details>
<summary>Abstract</summary>
Jointly processing information from multiple sensors is crucial to achieving accurate and robust perception for reliable autonomous driving systems. However, current 3D perception research follows a modality-specific paradigm, leading to additional computation overheads and inefficient collaboration between different sensor data. In this paper, we present an efficient multi-modal backbone for outdoor 3D perception named UniTR, which processes a variety of modalities with unified modeling and shared parameters. Unlike previous works, UniTR introduces a modality-agnostic transformer encoder to handle these view-discrepant sensor data for parallel modal-wise representation learning and automatic cross-modal interaction without additional fusion steps. More importantly, to make full use of these complementary sensor types, we present a novel multi-modal integration strategy by both considering semantic-abundant 2D perspective and geometry-aware 3D sparse neighborhood relations. UniTR is also a fundamentally task-agnostic backbone that naturally supports different 3D perception tasks. It sets a new state-of-the-art performance on the nuScenes benchmark, achieving +1.1 NDS higher for 3D object detection and +12.0 higher mIoU for BEV map segmentation with lower inference latency. Code will be available at https://github.com/Haiyang-W/UniTR .
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Context-Aware-Pseudo-Label-Refinement-for-Source-Free-Domain-Adaptive-Fundus-Image-Segmentation"><a href="#Context-Aware-Pseudo-Label-Refinement-for-Source-Free-Domain-Adaptive-Fundus-Image-Segmentation" class="headerlink" title="Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation"></a>Context-Aware Pseudo-Label Refinement for Source-Free Domain Adaptive Fundus Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07731">http://arxiv.org/abs/2308.07731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/cpr">https://github.com/xmed-lab/cpr</a></li>
<li>paper_authors: Zheang Huai, Xinpeng Ding, Yi Li, Xiaomeng Li</li>
<li>for: 这个论文是针对源数不可用的目标端做domain adaptation问题，即将源端模型训练到目标端，但源数没有可用，因此使用源模型生成的 Pseudo-label 进行更新。</li>
<li>methods: 本论文提出了一个基于上下文关系的 Pseudo-label 精度更新方法，包括将上下文相似度学习到 Pseudo-label 更新、适用于不同类别的Pixel-level和Class-level降噪方法，以及适度调整 Pseudo-label 以补偿错误更新。</li>
<li>results: 在跨领域眼部像素数据上进行实验，结果显示本方法可以实现顶尖的结果。<details>
<summary>Abstract</summary>
In the domain adaptation problem, source data may be unavailable to the target client side due to privacy or intellectual property issues. Source-free unsupervised domain adaptation (SF-UDA) aims at adapting a model trained on the source side to align the target distribution with only the source model and unlabeled target data. The source model usually produces noisy and context-inconsistent pseudo-labels on the target domain, i.e., neighbouring regions that have a similar visual appearance are annotated with different pseudo-labels. This observation motivates us to refine pseudo-labels with context relations. Another observation is that features of the same class tend to form a cluster despite the domain gap, which implies context relations can be readily calculated from feature distances. To this end, we propose a context-aware pseudo-label refinement method for SF-UDA. Specifically, a context-similarity learning module is developed to learn context relations. Next, pseudo-label revision is designed utilizing the learned context relations. Further, we propose calibrating the revised pseudo-labels to compensate for wrong revision caused by inaccurate context relations. Additionally, we adopt a pixel-level and class-level denoising scheme to select reliable pseudo-labels for domain adaptation. Experiments on cross-domain fundus images indicate that our approach yields the state-of-the-art results. Code is available at https://github.com/xmed-lab/CPR.
</details>
<details>
<summary>摘要</summary>
在领域适应问题中，源数据可能无法提供到目标客边，因为隐私或知识产权问题。源无supervised领域适应（SF-UDA）target的目标分布，仅使用源模型和目标无标签数据进行对领域的适应。源模型通常对目标领域生成噪音和无法适应的文本标签，即邻近区域可能会被不同的文本标签。这个观察动机我们更新 pseudo-label。另外，我们发现在领域差距下，同一类型的特征通常会形成一个对应的分布，这implies context relations可以从特征距离中Calculate。为此，我们提出一个context-aware pseudo-label revision方法。具体来说，我们开发了一个context-similarity learning module，用于学习context relations。接下来，我们设计了使用学习的context relations来修订 pseudo-label。此外，我们提出了calibrate revisions的方法，以补偿因为不准确的context relations而导致的错误修订。此外，我们还采用了像素级和类别级的噪音除掉方法，以选择可靠的 pseudo-label для领域适应。实验结果显示，我们的方法在跨领域基因摄像头上获得了state-of-the-art的结果。代码可以在https://github.com/xmed-lab/CPR上获取。
</details></li>
</ul>
<hr>
<h2 id="Domain-Aware-Fine-Tuning-Enhancing-Neural-Network-Adaptability"><a href="#Domain-Aware-Fine-Tuning-Enhancing-Neural-Network-Adaptability" class="headerlink" title="Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability"></a>Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07728">http://arxiv.org/abs/2308.07728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seokhyeon Ha, Sunbeom Jung, Jungwoo Lee<br>for: 本研究旨在提高 fine-tuning 过程中的模型性能，特别是在新目标领域中。methods: 本研究提出了一种名为 Domain-Aware Fine-Tuning (DAFT) 的新方法，它包括批量准则转换和细致调整。results: 对于多个基线方法，DAFT 方法能够明显提高模型的性能，并且在各种不同的数据集上都有显著的优势。<details>
<summary>Abstract</summary>
Fine-tuning pre-trained neural network models has become a widely adopted approach across various domains. However, it can lead to the distortion of pre-trained feature extractors that already possess strong generalization capabilities. Mitigating feature distortion during adaptation to new target domains is crucial. Recent studies have shown promising results in handling feature distortion by aligning the head layer on in-distribution datasets before performing fine-tuning. Nonetheless, a significant limitation arises from the treatment of batch normalization layers during fine-tuning, leading to suboptimal performance. In this paper, we propose Domain-Aware Fine-Tuning (DAFT), a novel approach that incorporates batch normalization conversion and the integration of linear probing and fine-tuning. Our batch normalization conversion method effectively mitigates feature distortion by reducing modifications to the neural network during fine-tuning. Additionally, we introduce the integration of linear probing and fine-tuning to optimize the head layer with gradual adaptation of the feature extractor. By leveraging batch normalization layers and integrating linear probing and fine-tuning, our DAFT significantly mitigates feature distortion and achieves improved model performance on both in-distribution and out-of-distribution datasets. Extensive experiments demonstrate that our method outperforms other baseline methods, demonstrating its effectiveness in not only improving performance but also mitigating feature distortion.
</details>
<details>
<summary>摘要</summary>
“现代化的预训练神经网络模型已成为各个领域的广泛采用方法。然而，这可能导致预训练的特征提取器受到扭曲，这会影响模型的泛化能力。避免特征扭曲在新目标领域中进行适应是非常重要。近期的研究表明，在进行适应时对头层进行对齐可以有效地避免特征扭曲。然而，在细化过程中对批处理归一化层的处理会导致表现下降。在本文中，我们提出了适应领域域特征 fine-tuning（DAFT）方法，该方法包括批处理归一化转换和细化过程中的线性探测与细化。我们的批处理归一化转换方法可以减少在细化过程中对神经网络的修改，从而避免特征扭曲。此外，我们引入了线性探测与细化的集成，以便逐渐适应头层和特征提取器。通过利用批处理归一化层和集成线性探测与细化，我们的DAFT可以有效地避免特征扭曲，并在各种预测和非预测 datasets 上显著提高模型的性能。我们的实验结果表明，我们的方法可以超越其他基准方法，说明了它的效果不仅在提高性能，还在避免特征扭曲。”
</details></li>
</ul>
<hr>
<h2 id="Real-time-Automatic-M-mode-Echocardiography-Measurement-with-Panel-Attention-from-Local-to-Global-Pixels"><a href="#Real-time-Automatic-M-mode-Echocardiography-Measurement-with-Panel-Attention-from-Local-to-Global-Pixels" class="headerlink" title="Real-time Automatic M-mode Echocardiography Measurement with Panel Attention from Local-to-Global Pixels"></a>Real-time Automatic M-mode Echocardiography Measurement with Panel Attention from Local-to-Global Pixels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07717">http://arxiv.org/abs/2308.07717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanktseng131415go/ramem">https://github.com/hanktseng131415go/ramem</a></li>
<li>paper_authors: Ching-Hsun Tseng, Shao-Ju Chien, Po-Shen Wang, Shin-Jye Lee, Wei-Huan Hu, Bin Pu, Xiao-jun Zeng</li>
<li>For: 这个论文的目的是提出一种实时自动echocardiography测量方法，以解决现有的三个主要阻碍：无法建立一个自动化方案、手动标注M-mode echocardiogram是时间consuming、现有的卷积层（如ResNet）在处理大对象时效率低下。* Methods: 该论文使用了MEIS数据集（M-mode echocardiogram的实例分割数据集），提出了面掌注意力（local-to-global efficient attention）和更新后的UPANets V2，以实现大对象检测和全局接受场。* Results: 实验结果表明，RAMEM比现有的RIS脊梁（带有非本地注意力）在PASCAL 2012 SBD和人类性能测试中表现更好，并且可以在实时中进行自动化echocardiography测量。<details>
<summary>Abstract</summary>
Motion mode (M-mode) recording is an essential part of echocardiography to measure cardiac dimension and function. However, the current diagnosis cannot build an automatic scheme, as there are three fundamental obstructs: Firstly, there is no open dataset available to build the automation for ensuring constant results and bridging M-mode echocardiography with real-time instance segmentation (RIS); Secondly, the examination is involving the time-consuming manual labelling upon M-mode echocardiograms; Thirdly, as objects in echocardiograms occupy a significant portion of pixels, the limited receptive field in existing backbones (e.g., ResNet) composed from multiple convolution layers are inefficient to cover the period of a valve movement. Existing non-local attentions (NL) compromise being unable real-time with a high computation overhead or losing information from a simplified version of the non-local block. Therefore, we proposed RAMEM, a real-time automatic M-mode echocardiography measurement scheme, contributes three aspects to answer the problems: 1) provide MEIS, a dataset of M-mode echocardiograms for instance segmentation, to enable consistent results and support the development of an automatic scheme; 2) propose panel attention, local-to-global efficient attention by pixel-unshuffling, embedding with updated UPANets V2 in a RIS scheme toward big object detection with global receptive field; 3) develop and implement AMEM, an efficient algorithm of automatic M-mode echocardiography measurement enabling fast and accurate automatic labelling among diagnosis. The experimental results show that RAMEM surpasses existing RIS backbones (with non-local attention) in PASCAL 2012 SBD and human performances in real-time MEIS tested. The code of MEIS and dataset are available at https://github.com/hanktseng131415go/RAME.
</details>
<details>
<summary>摘要</summary>
幻象模式（M-mode）记录是听觉心动图像测量的重要组成部分，但现有的诊断方案无法建立自动化机制，因为存在以下三个基本障碍：首先，没有开放的数据集可用于建立自动化，以确保定制化结果并将M-mode听觉心动图像与实时实例 segmentation（RIS）相连接；其次，检查需要手动标注M-mode听觉心动图像，时间consuming；第三，因为听觉心动图像中的对象占用了大量像素，现有的卷积层（例如ResNet）的有限感知范围不能覆盖心动期间oval movement。现有的非本地注意力（NL）不能实现实时，或者 computation overhead过高，或者 lost information from a simplified version of the non-local block。因此，我们提出了RAMEM，一种实时自动M-mode听觉心动图像测量方案，它在以下三个方面做出贡献：1. 提供MEIS数据集，用于实例 segmentation，以确保定制化结果和支持自动化方案的发展。2. 提出面attenion，具有local-to-global高效注意力，通过像素排序和更新UPANets V2在RIS方案中，以实现大对象检测与全局感知范围。3. 开发和实现AMEM算法，一种高效的自动M-mode听觉心动图像测量算法，可以快速和准确地自动标注诊断过程中。实验结果表明，RAMEM在PASCAL 2012 SBD和人类性能上都超过了现有的RIS卷积层（带有非本地注意力）。MEIS数据集和代码可以在https://github.com/hanktseng131415go/RAME中获取。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Network-Initialization-for-Medical-AI-Models-Using-Large-Scale-Unlabeled-Natural-Images"><a href="#Enhancing-Network-Initialization-for-Medical-AI-Models-Using-Large-Scale-Unlabeled-Natural-Images" class="headerlink" title="Enhancing Network Initialization for Medical AI Models Using Large-Scale, Unlabeled Natural Images"></a>Enhancing Network Initialization for Medical AI Models Using Large-Scale, Unlabeled Natural Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07688">http://arxiv.org/abs/2308.07688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soroosh Tayebi Arasteh, Leo Misera, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung</li>
<li>for: 这个研究旨在测试SSL在非医学影像领域进行预训练，以及与对非医学影像和医学影像进行预训练进行比较。</li>
<li>methods: 我们使用了视觉 трансформер，并将其预设的参数基于以下三种预训练方法：(i) SSL预训练自然影像（DINOv2），(ii) ImageNet dataset上的SL预训练，以及(iii) MIMIC-CXR dataset上的SL预训练。</li>
<li>results: 我们发现，使用这些预训练方法可以在800,000多帧颈部X-光像中诊断更多于20种不同的内部发现。SSL预训练在预训练自然影像时不仅超过ImageNet-based预训练（P&lt;0.001 for all datasets），甚至在某些情况下也超过了预训练MIMIC-CXR dataset。<details>
<summary>Abstract</summary>
Pre-training datasets, like ImageNet, have become the gold standard in medical image analysis. However, the emergence of self-supervised learning (SSL), which leverages unlabeled data to learn robust features, presents an opportunity to bypass the intensive labeling process. In this study, we explored if SSL for pre-training on non-medical images can be applied to chest radiographs and how it compares to supervised pre-training on non-medical images and on medical images. We utilized a vision transformer and initialized its weights based on (i) SSL pre-training on natural images (DINOv2), (ii) SL pre-training on natural images (ImageNet dataset), and (iii) SL pre-training on chest radiographs from the MIMIC-CXR database. We tested our approach on over 800,000 chest radiographs from six large global datasets, diagnosing more than 20 different imaging findings. Our SSL pre-training on curated images not only outperformed ImageNet-based pre-training (P<0.001 for all datasets) but, in certain cases, also exceeded SL on the MIMIC-CXR dataset. Our findings suggest that selecting the right pre-training strategy, especially with SSL, can be pivotal for improving artificial intelligence (AI)'s diagnostic accuracy in medical imaging. By demonstrating the promise of SSL in chest radiograph analysis, we underline a transformative shift towards more efficient and accurate AI models in medical imaging.
</details>
<details>
<summary>摘要</summary>
医疗图像分析领域的预训练数据集，如ImageNet，已成为黄金标准。然而，自动学习（SSL）技术，利用无标签数据来学习强健特征，现在提供了一种可能的代替方案。在本研究中，我们研究了将SSL预训练在非医学图像上应用于胸部X射线图像，以及与超参数预训练在非医学图像和医学图像上的比较。我们使用了视觉 трансформа器，并将其参数初始化为（i）SSL预训练natural images（DINOv2），（ii）SL预训练natural images（ImageNet数据集），和（iii）SL预训练在MIMIC-CXR数据库上的胸部X射线图像。我们对6个大型全球数据集中的超过800,000个胸部X射线图像进行测试，并识别了20种不同的成像发现。我们的SSL预训练在精心选择的图像上不仅超过了ImageNet基础预训练（P<0.001 for all datasets），而且在某些情况下还超过了SL在MIMIC-CXR数据库上的预训练。我们的发现表明，选择合适的预训练策略，特别是使用SSL，可以对医疗图像识别精度进行重要改进。我们的研究证明了SSL在胸部X射线图像分析中的承诺，并标识了医疗图像识别领域的一种转型变革，从而实现更高效和准确的人工智能模型。
</details></li>
</ul>
<hr>
<h2 id="A-Review-of-Adversarial-Attacks-in-Computer-Vision"><a href="#A-Review-of-Adversarial-Attacks-in-Computer-Vision" class="headerlink" title="A Review of Adversarial Attacks in Computer Vision"></a>A Review of Adversarial Attacks in Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07673">http://arxiv.org/abs/2308.07673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yutong Zhang, Yao Li, Yin Li, Zhichang Guo</li>
<li>for: 本研究旨在解决深度神经网络受到敌意样本攻击的问题，尤其是在自动驾驶等安全关键场景中。</li>
<li>methods: 本研究使用了黑盒设定，即攻击者只能获得模型的输入和输出，而不知道模型的参数和梯度。</li>
<li>results: 研究发现，黑盒攻击可以 Transferability 到不同的深度学习和机器学习模型，并且可以 Achievability 在实际场景中。<details>
<summary>Abstract</summary>
Deep neural networks have been widely used in various downstream tasks, especially those safety-critical scenario such as autonomous driving, but deep networks are often threatened by adversarial samples. Such adversarial attacks can be invisible to human eyes, but can lead to DNN misclassification, and often exhibits transferability between deep learning and machine learning models and real-world achievability. Adversarial attacks can be divided into white-box attacks, for which the attacker knows the parameters and gradient of the model, and black-box attacks, for the latter, the attacker can only obtain the input and output of the model. In terms of the attacker's purpose, it can be divided into targeted attacks and non-targeted attacks, which means that the attacker wants the model to misclassify the original sample into the specified class, which is more practical, while the non-targeted attack just needs to make the model misclassify the sample. The black box setting is a scenario we will encounter in practice.
</details>
<details>
<summary>摘要</summary>
深度神经网络在各种下游任务中广泛应用，特别是安全关键的情况下，如自动驾驶等，但深度网络受到反对攻击的威胁。这些反对攻击可能会在人类眼中不可见，但可能导致神经网络误分类，并且常常具有神经网络和机器学习模型之间的传播性和实际应用性。反对攻击可以分为白盒攻击和黑盒攻击两类，其中白盒攻击者知道模型的参数和梯度，黑盒攻击者只能获得输入和输出。根据攻击者的目的，反对攻击可以分为targeted攻击和非targeted攻击。targeted攻击需要模型误分类原始样本为指定的类别，更加实际；非targeted攻击只需要模型误分类样本。黑盒设定是我们在实践中会遇到的情况。
</details></li>
</ul>
<hr>
<h2 id="Inversion-by-Inversion-Exemplar-based-Sketch-to-Photo-Synthesis-via-Stochastic-Differential-Equations-without-Training"><a href="#Inversion-by-Inversion-Exemplar-based-Sketch-to-Photo-Synthesis-via-Stochastic-Differential-Equations-without-Training" class="headerlink" title="Inversion-by-Inversion: Exemplar-based Sketch-to-Photo Synthesis via Stochastic Differential Equations without Training"></a>Inversion-by-Inversion: Exemplar-based Sketch-to-Photo Synthesis via Stochastic Differential Equations without Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07665">http://arxiv.org/abs/2308.07665</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ximinng/inversion-by-inversion">https://github.com/ximinng/inversion-by-inversion</a></li>
<li>paper_authors: Ximing Xing, Chuang Wang, Haitao Zhou, Zhihao Hu, Chongxuan Li, Dong Xu, Qian Yu</li>
<li>for: 将简图转换为真实图像</li>
<li>methods: 使用“倒反”两Stage方法，包括形态倒反和全控倒反两个阶段，通过形态能函数和外观能函数来控制图像的形态和外观特征。</li>
<li>results: 实验结果表明，提议的“倒反”方法能够生成高质量的真实图像，并且可以根据不同的示例图来控制图像的颜色和 текстура特征。<details>
<summary>Abstract</summary>
Exemplar-based sketch-to-photo synthesis allows users to generate photo-realistic images based on sketches. Recently, diffusion-based methods have achieved impressive performance on image generation tasks, enabling highly-flexible control through text-driven generation or energy functions. However, generating photo-realistic images with color and texture from sketch images remains challenging for diffusion models. Sketches typically consist of only a few strokes, with most regions left blank, making it difficult for diffusion-based methods to produce photo-realistic images. In this work, we propose a two-stage method named ``Inversion-by-Inversion" for exemplar-based sketch-to-photo synthesis. This approach includes shape-enhancing inversion and full-control inversion. During the shape-enhancing inversion process, an uncolored photo is generated with the guidance of a shape-energy function. This step is essential to ensure control over the shape of the generated photo. In the full-control inversion process, we propose an appearance-energy function to control the color and texture of the final generated photo.Importantly, our Inversion-by-Inversion pipeline is training-free and can accept different types of exemplars for color and texture control. We conducted extensive experiments to evaluate our proposed method, and the results demonstrate its effectiveness.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CN<<SYS>> exemplar-based sketch-to-photo synthesis 可以让用户生成基于绘图的 photo-realistic 图像。最近，Diffusion-based 方法在图像生成任务上 achieved 出色的表现，允许通过文本驱动生成或能量函数进行高度灵活的控制。然而，通过Diffusion 模型生成具有颜色和 texture 的 photo-realistic 图像仍然是一个挑战。绘图通常只有几个笔画，大多数区域都是质感，使得Diffusion 模型很难生成 photo-realistic 图像。在这项工作中，我们提出了一种 Two-stage 方法，名为“Inversion-by-Inversion”，用于 exemplar-based sketch-to-photo synthesis。这种方法包括 shape-enhancing inversion 和 full-control inversion。在 shape-enhancing inversion 过程中，通过一个 shape-energy 函数的引导，生成一个没有颜色的照片。这一步很重要，以确保对生成的照片的形状进行控制。在 full-control inversion 过程中，我们提出了一种 appearance-energy 函数，用于控制照片的颜色和 texture。重要的是，我们的 Inversion-by-Inversion 管道是无需训练的，可以接受不同类型的 exemplar 进行颜色和 texture 控制。我们进行了广泛的实验来评估我们的提议方法，结果显示其效果。
</details></li>
</ul>
<hr>
<h2 id="Gradient-Based-Post-Training-Quantization-Challenging-the-Status-Quo"><a href="#Gradient-Based-Post-Training-Quantization-Challenging-the-Status-Quo" class="headerlink" title="Gradient-Based Post-Training Quantization: Challenging the Status Quo"></a>Gradient-Based Post-Training Quantization: Challenging the Status Quo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07662">http://arxiv.org/abs/2308.07662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edouard Yvinec, Arnaud Dapogny, Kevin Bailly</li>
<li>For: The paper focuses on gradient-based post-training quantization (GPTQ) methods for efficient deployment of deep neural networks.* Methods: The paper challenges common choices in GPTQ methods and derives best practices for designing more efficient and scalable GPTQ methods, including the problem formulation and optimization process.* Results: The paper proposes a novel importance-based mixed-precision technique and shows significant performance improvements on all tested state-of-the-art GPTQ methods and networks, achieving +6.819 points on ViT for 4-bit quantization.Here’s the simplified Chinese version:</li>
<li>for: 这篇论文关注的是在训练后进行权重调整的混合精度方法，以实现深度神经网络的高效部署。</li>
<li>methods: 论文挑战了常见的GPTQ方法选择，并提出了更有效和可扩展的GPTQ方法设计方法，包括问题定义和优化过程。</li>
<li>results: 论文提出了一种新的重要性基于混合精度技术，并在所有测试的当前GPTQ方法和网络上实现了显著的性能提升，例如在ViT网络上的4位量化得到了+6.819点的提升。<details>
<summary>Abstract</summary>
Quantization has become a crucial step for the efficient deployment of deep neural networks, where floating point operations are converted to simpler fixed point operations. In its most naive form, it simply consists in a combination of scaling and rounding transformations, leading to either a limited compression rate or a significant accuracy drop. Recently, Gradient-based post-training quantization (GPTQ) methods appears to be constitute a suitable trade-off between such simple methods and more powerful, yet expensive Quantization-Aware Training (QAT) approaches, particularly when attempting to quantize LLMs, where scalability of the quantization process is of paramount importance. GPTQ essentially consists in learning the rounding operation using a small calibration set. In this work, we challenge common choices in GPTQ methods. In particular, we show that the process is, to a certain extent, robust to a number of variables (weight selection, feature augmentation, choice of calibration set). More importantly, we derive a number of best practices for designing more efficient and scalable GPTQ methods, regarding the problem formulation (loss, degrees of freedom, use of non-uniform quantization schemes) or optimization process (choice of variable and optimizer). Lastly, we propose a novel importance-based mixed-precision technique. Those guidelines lead to significant performance improvements on all the tested state-of-the-art GPTQ methods and networks (e.g. +6.819 points on ViT for 4-bit quantization), paving the way for the design of scalable, yet effective quantization methods.
</details>
<details>
<summary>摘要</summary>
量化已成为深度神经网络的有效部署步骤，将浮点运算转换为简单的固定点运算。最简单的方式是通过缩放和四舍五入变换，但这将导致压缩率有限或准确率下降。现在，使用梯度based后期量化（GPTQ）方法可以实现一个适当的平衡，特别是在尝试量化LLMs（大型语言模型）时，因为量化过程的扩展性是非常重要。GPTQ通过学习缩放操作使用小量训练集来实现。在这个工作中，我们挑战了GPTQ方法的常见选择。具体来说，我们发现这个过程在一定程度上是Robust，即选择特征、增强特征和calibration集的变量的影响相对较小。此外，我们还提出了一些设计更高效和可扩展的GPTQ方法的最佳实践，包括问题定义（损失、自由度、非对称量化方案）和优化过程（变量和优化器）中的一些变量。最后，我们提出了一种新的重要性基于混合精度技术。这些指南导致所有测试的State-of-the-art GPTQ方法和网络（如+6.819点的ViT для4位量化）获得显著性能提高，为设计可扩展、有效的量化方法铺平道路。
</details></li>
</ul>
<hr>
<h2 id="Geometry-of-the-Visual-Cortex-with-Applications-to-Image-Inpainting-and-Enhancement"><a href="#Geometry-of-the-Visual-Cortex-with-Applications-to-Image-Inpainting-and-Enhancement" class="headerlink" title="Geometry of the Visual Cortex with Applications to Image Inpainting and Enhancement"></a>Geometry of the Visual Cortex with Applications to Image Inpainting and Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07652">http://arxiv.org/abs/2308.07652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ballerin/v1diffusion">https://github.com/ballerin/v1diffusion</a></li>
<li>paper_authors: Francesco Ballerin, Erlend Grong</li>
<li>for: 这篇论文是为了提出基于视觉核心V1的扩展矩阵群$SE(2)$的图像填充和改善算法。</li>
<li>methods: 这篇论文使用了浸泡-推拿（WaxOn-WaxOff）方法，并利用了子 riemannian 结构来定义一种新的不锈滤波器，用于图像提高。</li>
<li>results: 研究人员通过应用这种方法于血管扩大扫描中的血管增强，得到了更加锐利的结果。<details>
<summary>Abstract</summary>
Equipping the rototranslation group $SE(2)$ with a sub-Riemannian structure inspired by the visual cortex V1, we propose algorithms for image inpainting and enhancement based on hypoelliptic diffusion. We innovate on previous implementations of the methods by Citti, Sarti and Boscain et al., by proposing an alternative that prevents fading and capable of producing sharper results in a procedure that we call WaxOn-WaxOff. We also exploit the sub-Riemannian structure to define a completely new unsharp using $SE(2)$, analogous of the classical unsharp filter for 2D image processing, with applications to image enhancement. We demonstrate our method on blood vessels enhancement in retinal scans.
</details>
<details>
<summary>摘要</summary>
将$SE(2)$拓扑群受到视觉核V1的启发下的半里曼尼拓扑结构，我们提出了基于液体扩散的图像填充和改善算法。我们在之前的实现方法（Citti、Sarti和Boscain等人的方法）的基础上做出了修改，以避免模糊和生成更加锐利的结果，我们称之为“WaxOn-WaxOff”过程。我们还利用了子拓扑结构来定义一种全新的不锐化器，类似于传统的2D图像处理中的不锐化过滤器，并应用于图像增强。我们在血管扩大retinal扫描中进行了示例。
</details></li>
</ul>
<hr>
<h2 id="Prompt-Switch-Efficient-CLIP-Adaptation-for-Text-Video-Retrieval"><a href="#Prompt-Switch-Efficient-CLIP-Adaptation-for-Text-Video-Retrieval" class="headerlink" title="Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval"></a>Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07648">http://arxiv.org/abs/2308.07648</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bladewaltz1/promptswitch">https://github.com/bladewaltz1/promptswitch</a></li>
<li>paper_authors: Chaorui Deng, Qi Chen, Pengda Qin, Da Chen, Qi Wu</li>
<li>for: 本文主要研究text-video retrieval领域中的问题，即如何使用预训练的文本-图像基础模型（如CLIP）在视频领域中进行有效的学习。</li>
<li>methods: 本文提出了一种新的方法，即在CLIP图像Encoder中引入空间-时间”Prompt Cube”，以快速包含全视频 semantics在帧表示中。此外，本文还提出了一种auxiliary video captioning目标函数，以帮助学习详细的视频 semantics。</li>
<li>results: 通过使用本文提出的方法，可以在三个标准 benchmark dataset上取得状态机器的性能（MSR-VTT、MSVD、LSMDC），而且只需要使用一个简单的时间融合策略（即mean-pooling）。<details>
<summary>Abstract</summary>
In text-video retrieval, recent works have benefited from the powerful learning capabilities of pre-trained text-image foundation models (e.g., CLIP) by adapting them to the video domain. A critical problem for them is how to effectively capture the rich semantics inside the video using the image encoder of CLIP. To tackle this, state-of-the-art methods adopt complex cross-modal modeling techniques to fuse the text information into video frame representations, which, however, incurs severe efficiency issues in large-scale retrieval systems as the video representations must be recomputed online for every text query. In this paper, we discard this problematic cross-modal fusion process and aim to learn semantically-enhanced representations purely from the video, so that the video representations can be computed offline and reused for different texts. Concretely, we first introduce a spatial-temporal "Prompt Cube" into the CLIP image encoder and iteratively switch it within the encoder layers to efficiently incorporate the global video semantics into frame representations. We then propose to apply an auxiliary video captioning objective to train the frame representations, which facilitates the learning of detailed video semantics by providing fine-grained guidance in the semantic space. With a naive temporal fusion strategy (i.e., mean-pooling) on the enhanced frame representations, we obtain state-of-the-art performances on three benchmark datasets, i.e., MSR-VTT, MSVD, and LSMDC.
</details>
<details>
<summary>摘要</summary>
在文本视频检索中， latest works 受益于预训练的文本图像基础模型（如 CLIP）的强大学习能力，通过适应它们到视频频谱中来进行改进。然而，一个 kritical problem 是如何有效地在图像Encoder中捕捉视频中的丰富 semantics。 To tackle this, state-of-the-art methods 采用复杂的跨模态模型化技术来融合文本信息到视频帧表示中，这 however, incurs severe efficiency issues in large-scale retrieval systems as the video representations must be recomputed online for every text query. In this paper, we discard this problematic cross-modal fusion process and aim to learn semantically-enhanced representations purely from the video, so that the video representations can be computed offline and reused for different texts.Concretely, we first introduce a spatial-temporal "Prompt Cube" into the CLIP image encoder and iteratively switch it within the encoder layers to efficiently incorporate the global video semantics into frame representations. We then propose to apply an auxiliary video captioning objective to train the frame representations, which facilitates the learning of detailed video semantics by providing fine-grained guidance in the semantic space. With a naive temporal fusion strategy (i.e., mean-pooling) on the enhanced frame representations, we obtain state-of-the-art performances on three benchmark datasets, i.e., MSR-VTT, MSVD, and LSMDC.
</details></li>
</ul>
<hr>
<h2 id="Backpropagation-Path-Search-On-Adversarial-Transferability"><a href="#Backpropagation-Path-Search-On-Adversarial-Transferability" class="headerlink" title="Backpropagation Path Search On Adversarial Transferability"></a>Backpropagation Path Search On Adversarial Transferability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07625">http://arxiv.org/abs/2308.07625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuoer Xu, Zhangxuan Gu, Jianping Zhang, Shiwen Cui, Changhua Meng, Weiqiang Wang</li>
<li>for: 防御深度神经网络受到攻击的隐晦攻击，需要在部署之前测试模型的可靠性。</li>
<li>methods: 使用Transfer-based攻击者制作攻击示例，并将其传递给黑盒中部署的受害者模型。为提高攻击性能，结构基本攻击者调整反propagation路径，但现有的结构基本攻击者未能探索 convolution 模块在 CNN 中的作用，并且修改反propagation 图表时使用了优化的方法。</li>
<li>results: 在各种传输设置下，我们的 backPropagation pAth Search (PAS) 可以大幅提高攻击成功率，包括正常训练和防御模型。<details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to adversarial examples, dictating the imperativeness to test the model's robustness before deployment. Transfer-based attackers craft adversarial examples against surrogate models and transfer them to victim models deployed in the black-box situation. To enhance the adversarial transferability, structure-based attackers adjust the backpropagation path to avoid the attack from overfitting the surrogate model. However, existing structure-based attackers fail to explore the convolution module in CNNs and modify the backpropagation graph heuristically, leading to limited effectiveness. In this paper, we propose backPropagation pAth Search (PAS), solving the aforementioned two problems. We first propose SkipConv to adjust the backpropagation path of convolution by structural reparameterization. To overcome the drawback of heuristically designed backpropagation paths, we further construct a DAG-based search space, utilize one-step approximation for path evaluation and employ Bayesian Optimization to search for the optimal path. We conduct comprehensive experiments in a wide range of transfer settings, showing that PAS improves the attack success rate by a huge margin for both normally trained and defense models.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到反例攻击，需要在部署之前测试模型的可靠性。转移基于攻击者通过对代理模型创建反例，并将其传递到黑盒环境中部署的受害者模型。为增强反例传递性，结构基于攻击者可以修改反例传递的背景干扰路径，以避免攻击过拟合代理模型。然而，现有的结构基于攻击者未能探索 convolution 模块在 CNN 中，并修改背景干扰路径的方法，导致有限的效果。在这篇论文中，我们提出了 backPropagation pAth Search (PAS)，解决以下两个问题。我们首先提出 SkipConv，用于调整 convolution 模块的背景干扰路径。为了超越轮循的设计方法，我们进一步建立了 DAG 型搜索空间，利用一步逼近方法来评估路径，并使用 Bayesian 优化来搜索最佳路径。我们在各种转移设置下进行了广泛的实验，结果显示，PAS 可以在各种转移设置下提高攻击成功率，并且在防御模型上也有显著改善。
</details></li>
</ul>
<hr>
<h2 id="Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation"><a href="#Self-Prompting-Large-Vision-Models-for-Few-Shot-Medical-Image-Segmentation" class="headerlink" title="Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation"></a>Self-Prompting Large Vision Models for Few-Shot Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07624">http://arxiv.org/abs/2308.07624</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/peteryyzhang/few-shot-self-prompt-sam">https://github.com/peteryyzhang/few-shot-self-prompt-sam</a></li>
<li>paper_authors: Qi Wu, Yuyao Zhang, Marawan Elbatel</li>
<li>for: 这篇论文主要应用于医疗领域的大基础模型（Segment Anything Model，SAM），以提高医疗影像分类的性能。</li>
<li>methods: 这篇论文提出了一种新的自我推问法，利用SAM的嵌入空间来推问自己，通过简单 yet有效的直线像素层级分类器。</li>
<li>results: 这篇论文在多个数据集上（比如几几个医疗影像分类 зада问）取得了竞争性的结果，较以少数影像进行微调的方法提高约15%。<details>
<summary>Abstract</summary>
Recent advancements in large foundation models have shown promising potential in the medical industry due to their flexible prompting capability. One such model, the Segment Anything Model (SAM), a prompt-driven segmentation model, has shown remarkable performance improvements, surpassing state-of-the-art approaches in medical image segmentation. However, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. In this paper, we propose a novel perspective on self-prompting in medical vision applications. Specifically, we harness the embedding space of SAM to prompt itself through a simple yet effective linear pixel-wise classifier. By preserving the encoding capabilities of the large model, the contextual information from its decoder, and leveraging its interactive promptability, we achieve competitive results on multiple datasets (i.e. improvement of more than 15% compared to fine-tuning the mask decoder using a few images).
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的大基础模型在医疗领域的应用显示了扎实的投资潜力，特别是其 flexible 的提示能力。一种名为 Segment Anything Model（SAM）的提示驱动 segmentation 模型，在医疗图像 segmentation 方面显示了非凡的表现，超越了当前的状态艺术方法。然而，现有的方法主要依赖于调整策略，需要大量的数据或特定任务的先前提示，这使得只有有限数量的数据样本时 особенelly 挑战。在这篇论文中，我们提出了一种新的自我提示视角，具体来说是利用 SAM 的 embedding 空间来自我提示，通过一种简单 yet effective 的线性像素级分类器。通过保留大型模型的编码能力，保留解码器的上下文信息，以及利用其交互提示能力，我们在多个 dataset 上达到了竞争力的结果（比如 Fine-tuning mask decoder 使用几个图像时的提高 более 15%）。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Hypergraphs-for-Learning-Multiple-World-Interpretations"><a href="#Self-supervised-Hypergraphs-for-Learning-Multiple-World-Interpretations" class="headerlink" title="Self-supervised Hypergraphs for Learning Multiple World Interpretations"></a>Self-supervised Hypergraphs for Learning Multiple World Interpretations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07615">http://arxiv.org/abs/2308.07615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alina Marcu, Mihai Pirvu, Dragos Costea, Emanuela Haller, Emil Slusanschi, Ahmed Nabil Belbachir, Rahul Sukthankar, Marius Leordeanu</li>
<li>for: 学习多个场景表示，使用小量标注集。</li>
<li>methods: 利用场景表示之间的关系，建立多任务超гра�。使用超гра�提高VisTransformer模型，无需额外标注数据。</li>
<li>results: 比其他多任务图模型表现出色，在不同类型的超гра�和ensemble模型下进行自我超vision学习。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We present a method for learning multiple scene representations given a small labeled set, by exploiting the relationships between such representations in the form of a multi-task hypergraph. We also show how we can use the hypergraph to improve a powerful pretrained VisTransformer model without any additional labeled data. In our hypergraph, each node is an interpretation layer (e.g., depth or segmentation) of the scene. Within each hyperedge, one or several input nodes predict the layer at the output node. Thus, each node could be an input node in some hyperedges and an output node in others. In this way, multiple paths can reach the same node, to form ensembles from which we obtain robust pseudolabels, which allow self-supervised learning in the hypergraph. We test different ensemble models and different types of hyperedges and show superior performance to other multi-task graph models in the field. We also introduce Dronescapes, a large video dataset captured with UAVs in different complex real-world scenes, with multiple representations, suitable for multi-task learning.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，通过利用场景表示的关系形式为多任务 гиперграフ来学习多个场景表示。我们还示出了如何使用 гиперграフ来提高一种强大预训练 VisTransformer 模型，无需任何额外的标注数据。在我们的 гиперграフ中，每个节点是一个解释层（例如深度或分割）的场景表示。在每个 гипер边上，一个或多个输入节点预测输出节点的层。因此，每个节点可以是输入节点在某些 гипер边上，并且是输出节点在其他 гипер边上。这样，多个路径可以达到同一个节点，从而形成ensemble，并使用这些ensemble来获得Robustpseudolabel，以实现自动标注学习在 гиперграフ中。我们测试了不同的ensemble模型和不同类型的 гипер边，并显示了与其他多任务图模型在领域中的超越性。我们还介绍了 Dronescapes，一个大量视频数据集，captured with UAVs在不同的复杂实际场景中，具有多种表示，适合多任务学习。
</details></li>
</ul>
<hr>
<h2 id="GAMER-MRIL-identifies-Disability-Related-Brain-Changes-in-Multiple-Sclerosis"><a href="#GAMER-MRIL-identifies-Disability-Related-Brain-Changes-in-Multiple-Sclerosis" class="headerlink" title="GAMER-MRIL identifies Disability-Related Brain Changes in Multiple Sclerosis"></a>GAMER-MRIL identifies Disability-Related Brain Changes in Multiple Sclerosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07611">http://arxiv.org/abs/2308.07611</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Jui Lu, Benjamin Odry, Muhamed Barakovic, Matthias Weigel, Robin Sandkühler, Reza Rahmanzadeh, Xinjie Chen, Mario Ocampo-Pineda, Jens Kuhle, Ludwig Kappos, Philippe Cattin, Cristina Granziera</li>
<li>For: The paper aims to identify disability-related brain changes in multiple sclerosis (MS) patients using whole-brain quantitative MRI (qMRI) and a novel comprehensive approach called GAMER-MRIL.* Methods: The approach uses a gated-attention-based convolutional neural network (CNN) to select patch-based qMRI images that are important for a given task&#x2F;question, and incorporates a structure-aware interpretability method called Layer-wise Relevance Propagation (LRP) to identify disability-related brain regions.* Results: The approach achieved an AUC of 0.885, and the most sensitive measures related to disability were qT1 and NDI. The proposed LRP approach obtained more specifically relevant regions than other interpretability methods, including the saliency map, the integrated gradients, and the original LRP. The relevant regions included the corticospinal tract, where average qT1 and NDI significantly correlated with patients’ disability scores.Here’s the Chinese version of the three key points:* 用途：本研究旨在通过整体approach GAMER-MRIL，利用整个脑quantitative MRI (qMRI) 数据，为多发性静脉炎 (MS) 患者识别缺乏功能相关的脑区域。* 方法：该方法使用 gated-attention-based convolutional neural network (CNN) 选择 qMRI 图像中重要的 patch，并 incorporates 结构意识的 interpretability method Layer-wise Relevance Propagation (LRP) 来发现缺乏功能相关的脑区域。* 结果：该方法实现了 AUC 0.885，qT1 和 NDI 是缺乏功能相关的最敏感度量。提议的 LRP 方法在其他 interpretability methods 中获得了更加特定的相关区域，包括 corticospinal tract，其中 qT1 和 NDI 与患者缺乏功能分数相关性 ($ \rho $ &#x3D; -0.37 和 0.44)。<details>
<summary>Abstract</summary>
Objective: Identifying disability-related brain changes is important for multiple sclerosis (MS) patients. Currently, there is no clear understanding about which pathological features drive disability in single MS patients. In this work, we propose a novel comprehensive approach, GAMER-MRIL, leveraging whole-brain quantitative MRI (qMRI), convolutional neural network (CNN), and an interpretability method from classifying MS patients with severe disability to investigating relevant pathological brain changes. Methods: One-hundred-sixty-six MS patients underwent 3T MRI acquisitions. qMRI informative of microstructural brain properties was reconstructed, including quantitative T1 (qT1), myelin water fraction (MWF), and neurite density index (NDI). To fully utilize the qMRI, GAMER-MRIL extended a gated-attention-based CNN (GAMER-MRI), which was developed to select patch-based qMRI important for a given task/question, to the whole-brain image. To find out disability-related brain regions, GAMER-MRIL modified a structure-aware interpretability method, Layer-wise Relevance Propagation (LRP), to incorporate qMRI. Results: The test performance was AUC=0.885. qT1 was the most sensitive measure related to disability, followed by NDI. The proposed LRP approach obtained more specifically relevant regions than other interpretability methods, including the saliency map, the integrated gradients, and the original LRP. The relevant regions included the corticospinal tract, where average qT1 and NDI significantly correlated with patients' disability scores ($\rho$=-0.37 and 0.44). Conclusion: These results demonstrated that GAMER-MRIL can classify patients with severe disability using qMRI and subsequently identify brain regions potentially important to the integrity of the mobile function. Significance: GAMER-MRIL holds promise for developing biomarkers and increasing clinicians' trust in NN.
</details>
<details>
<summary>摘要</summary>
目标：identifying multiple sclerosis (MS) 患者中 relate to disability 的 brain changes是非常重要的。目前，没有明确的认知关于单个 MS 患者中哪些病理特征驱动残疾。在这种工作中，我们提出了一种全新的 comprehensive 方法，GAMER-MRIL，通过整个大脑量化MRI (qMRI)、卷积神经网络 (CNN) 和可解释方法来从MS患者中分类患者严重残疾。方法：一百六十六名 MS 患者通过3T MRI成像。qMRI 中提供了微结构脑 Properties 的信息，包括量化T1 (qT1)、myelin water fraction (MWF) 和 neurite density index (NDI)。为了完全利用 qMRI，GAMER-MRIL 扩展了一种闭合注意力基于CNN (GAMER-MRI)，将其应用到整个大脑图像。为了找出残疾相关的脑区，GAMER-MRIL 修改了结构意识 interpretability 方法，卷积层感知 propagation (LRP)，以包含 qMRI。结果：测试性能为 AUC=0.885。qT1 是残疾相关度最高的度量，其次是 NDI。提出的 LRP 方法在特定的脑区中获得了更多的相关区域，比其他可解释方法更加具有特点。这些相关区域包括 corticospinal tract，其中 qT1 和 NDI 与患者残疾分数相关性 (-0.37 和 0.44)。结论：这些结果表明GAMER-MRIL 可以使用 qMRI 分类患者严重残疾，并在脑区中寻找可能与 mobil 功能完整性相关的区域。意义：GAMER-MRIL 具有发展生物标志物和提高临床医生对NN的信任的潜在价值。
</details></li>
</ul>
<hr>
<h2 id="AKVSR-Audio-Knowledge-Empowered-Visual-Speech-Recognition-by-Compressing-Audio-Knowledge-of-a-Pretrained-Model"><a href="#AKVSR-Audio-Knowledge-Empowered-Visual-Speech-Recognition-by-Compressing-Audio-Knowledge-of-a-Pretrained-Model" class="headerlink" title="AKVSR: Audio Knowledge Empowered Visual Speech Recognition by Compressing Audio Knowledge of a Pretrained Model"></a>AKVSR: Audio Knowledge Empowered Visual Speech Recognition by Compressing Audio Knowledge of a Pretrained Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07593">http://arxiv.org/abs/2308.07593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeong Hun Yeo, Minsu Kim, Jeongsoo Choi, Dae Hoe Kim, Yong Man Ro</li>
<li>for: 这篇论文主要应用在无音识别中，将声音资讯与视觉资讯结合，以提高无音识别的精度。</li>
<li>methods: 提案的 Audio Knowledge empowered Visual Speech Recognition 框架（AKVSR）使用大规模预训Audio模型对声音资讯进行了丰富的编码，并将非语言信息从声音资料中排除，将语言信息储存在高精度的Audio内存中，最后通过Audio Bridging Module与视觉资讯进行匹配，以实现无需声音输入的训练。</li>
<li>results: 这篇论文透过广泛的实验证明了提案的方法的有效性，在两个广泛使用的数据集LRS2和LRS3上实现了新的顶峰性能。<details>
<summary>Abstract</summary>
Visual Speech Recognition (VSR) is the task of predicting spoken words from silent lip movements. VSR is regarded as a challenging task because of the insufficient information on lip movements. In this paper, we propose an Audio Knowledge empowered Visual Speech Recognition framework (AKVSR) to complement the insufficient speech information of visual modality by using audio modality. Different from the previous methods, the proposed AKVSR 1) utilizes rich audio knowledge encoded by a large-scale pretrained audio model, 2) saves the linguistic information of audio knowledge in compact audio memory by discarding the non-linguistic information from the audio through quantization, and 3) includes Audio Bridging Module which can find the best-matched audio features from the compact audio memory, which makes our training possible without audio inputs, once after the compact audio memory is composed. We validate the effectiveness of the proposed method through extensive experiments, and achieve new state-of-the-art performances on the widely-used datasets, LRS2 and LRS3.
</details>
<details>
<summary>摘要</summary>
visual speech recognition (VSR) 是指从舌头运动中预测说话的任务。 VSR 被视为一个具有挑战性的任务，因为舌头运动的信息不够。 在这篇论文中，我们提议了一个听音知识强化的视频语音识别框架（AKVSR），用于补充视觉模式中的不够的语音信息。 与前一些方法不同，我们的 AKVSR 具有以下特点：1. 利用大规模预训练的音频模型编码的丰富听音知识。2. 通过归约非语言信息，将音频信息储存在高效的音频内存中，以便在训练时不需要音频输入。3. 包括听音桥接模块，可以在训练时找到最佳匹配的音频特征，从而实现无需音频输入的训练。我们通过广泛的实验 validate 了我们的提议，并在常用的 datasets 上达到了新的state-of-the-art 性能。
</details></li>
</ul>
<hr>
<h2 id="Graph-Segmenter-Graph-Transformer-with-Boundary-aware-Attention-for-Semantic-Segmentation"><a href="#Graph-Segmenter-Graph-Transformer-with-Boundary-aware-Attention-for-Semantic-Segmentation" class="headerlink" title="Graph-Segmenter: Graph Transformer with Boundary-aware Attention for Semantic Segmentation"></a>Graph-Segmenter: Graph Transformer with Boundary-aware Attention for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07592">http://arxiv.org/abs/2308.07592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizhang Wu, Yuanzhu Gan, Tianhao Xu, Fan Wang</li>
<li>for: 提高 semantic segmentation 的性能</li>
<li>methods: 使用 Graph Transformer 和 Boundary-aware Attention 模块</li>
<li>results: 在三个 widely used semantic segmentation  dataset 上达到 state-of-the-art 性能<details>
<summary>Abstract</summary>
The transformer-based semantic segmentation approaches, which divide the image into different regions by sliding windows and model the relation inside each window, have achieved outstanding success. However, since the relation modeling between windows was not the primary emphasis of previous work, it was not fully utilized. To address this issue, we propose a Graph-Segmenter, including a Graph Transformer and a Boundary-aware Attention module, which is an effective network for simultaneously modeling the more profound relation between windows in a global view and various pixels inside each window as a local one, and for substantial low-cost boundary adjustment. Specifically, we treat every window and pixel inside the window as nodes to construct graphs for both views and devise the Graph Transformer. The introduced boundary-aware attention module optimizes the edge information of the target objects by modeling the relationship between the pixel on the object's edge. Extensive experiments on three widely used semantic segmentation datasets (Cityscapes, ADE-20k and PASCAL Context) demonstrate that our proposed network, a Graph Transformer with Boundary-aware Attention, can achieve state-of-the-art segmentation performance.
</details>
<details>
<summary>摘要</summary>
“ transformer-based semantic segmentation 方法，通过将图像分成不同区域，使用滑块窗口来建立关系，已经取得了出色的成果。然而，由于在这些方法中模型窗口之间的关系不是主要的强调点，因此未能充分利用。为了解决这个问题，我们提出了一个名为 Graph-Segmenter 的网络，包括 Graph Transformer 和Boundary-aware Attention 模组。这个网络可以同时在全球视图中模型窗口之间的深层关系，以及每个窗口和内部每个像素之间的本地关系，并且实现了低成本的边界调整。具体来说，我们将每个窗口和内部每个像素视为节点，以建立这两个视图的图形。我们还引入了边界意识注意力模组，以便优化目标物边界上的像素关系。我们在 Cityscapes、ADE-20k 和 PASCAL Context 三个通用 semantic segmentation 数据集上进行了广泛的实验，结果显示，我们的提案的网络，Graph Transformer with Boundary-aware Attention，可以 дости得 estado-of-the-art 的 segmentation 性能。”
</details></li>
</ul>
<hr>
<h2 id="ADD-An-Automatic-Desensitization-Fisheye-Dataset-for-Autonomous-Driving"><a href="#ADD-An-Automatic-Desensitization-Fisheye-Dataset-for-Autonomous-Driving" class="headerlink" title="ADD: An Automatic Desensitization Fisheye Dataset for Autonomous Driving"></a>ADD: An Automatic Desensitization Fisheye Dataset for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07590">http://arxiv.org/abs/2308.07590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizhang Wu, Chenxin Yuan, Hongyang Wei, Fan Song, Tianhao Xu</li>
<li>for: 提供一个大 FoV 鱼眼相机拍摄的自动驾驶环境中数据保护的解决方案，以满足法规要求。</li>
<li>methods: 基于大 FoV 鱼眼相机的自动驾驶拍摄数据，构建了首个 Autopilot Desensitization Dataset (ADD)，并提出了一种深度学习基于图像感知的图像隐藏框架。</li>
<li>results: 在 ADD 数据集上，提出了一种高效的多任务感知网络（DesCenterNet），可以同时实现人脸和车牌检测和隐藏任务。对于图像隐藏任务，我们提出了一种新的评价标准，并进行了广泛的比较实验，证明了我们的方法的有效性和超越性。<details>
<summary>Abstract</summary>
Autonomous driving systems require many images for analyzing the surrounding environment. However, there is fewer data protection for private information among these captured images, such as pedestrian faces or vehicle license plates, which has become a significant issue. In this paper, in response to the call for data security laws and regulations and based on the advantages of large Field of View(FoV) of the fisheye camera, we build the first Autopilot Desensitization Dataset, called ADD, and formulate the first deep-learning-based image desensitization framework, to promote the study of image desensitization in autonomous driving scenarios. The compiled dataset consists of 650K images, including different face and vehicle license plate information captured by the surround-view fisheye camera. It covers various autonomous driving scenarios, including diverse facial characteristics and license plate colors. Then, we propose an efficient multitask desensitization network called DesCenterNet as a benchmark on the ADD dataset, which can perform face and vehicle license plate detection and desensitization tasks. Based on ADD, we further provide an evaluation criterion for desensitization performance, and extensive comparison experiments have verified the effectiveness and superiority of our method on image desensitization.
</details>
<details>
<summary>摘要</summary>
自动驾驶系统需要大量图像来分析周围环境。然而， captured 图像中的private信息，如行人脸或车辆识别号，却受到较少的数据保护，这成为了一个重要的问题。在这篇论文中，我们根据宽视场(FoV)大的鱼眼镜头的优点，建立了首个Autopilot Desensitization Dataset（ADD），并提出了首个深度学习基于图像抑制框架。通过ADD集成了650000张图像，包括不同的脸和车辆识别号信息， captured by surround-view fisheye camera。它覆盖了各种自动驾驶场景，包括多样化的脸容特征和车辆识别号颜色。然后，我们提出了一种高效的多任务抑制网络， called DesCenterNet，作为ADD集成的benchmark，可以同时完成脸和车辆识别号检测和抑制任务。基于ADD，我们还提供了图像抑制性评价标准，并进行了广泛的比较实验，证明了我们的方法在图像抑制方面的效果和优势。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-data-generation-method-for-hybrid-image-tabular-data-using-two-generative-adversarial-networks"><a href="#Synthetic-data-generation-method-for-hybrid-image-tabular-data-using-two-generative-adversarial-networks" class="headerlink" title="Synthetic data generation method for hybrid image-tabular data using two generative adversarial networks"></a>Synthetic data generation method for hybrid image-tabular data using two generative adversarial networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07573">http://arxiv.org/abs/2308.07573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomohiro Kikuchi, Shouhei Hanaoka, Takahiro Nakao, Tomomi Takenaga, Yukihiro Nomura, Harushi Mori, Takeharu Yoshikawa</li>
<li>for: 这篇论文旨在提出一种生成医疗资料的方法，以便解决医疗领域中隐私问题和促进数据共享。</li>
<li>methods: 这篇论文使用了一种称为 auto-encoding GAN（αGAN）和一种称为 conditional tabular GAN（CTGAN）的生成opponent neural network（GAN）方法，以生成医疗领域中的合成医疗资料。</li>
<li>results: 这篇论文成功地实现了生成多样化的合成医疗资料，包括颈部X射像（CXR）和结构化的数据（包括人体尺寸数据和实验室测试数据），并且保持了这些数据之间的对应关系。<details>
<summary>Abstract</summary>
The generation of synthetic medical records using generative adversarial networks (GANs) has become increasingly important for addressing privacy concerns and promoting data sharing in the medical field. In this paper, we propose a novel method for generating synthetic hybrid medical records consisting of chest X-ray images (CXRs) and structured tabular data (including anthropometric data and laboratory tests) using an auto-encoding GAN ({\alpha}GAN) and a conditional tabular GAN (CTGAN). Our approach involves training a {\alpha}GAN model on a large public database (pDB) to reduce the dimensionality of CXRs. We then applied the trained encoder of the GAN model to the images in original database (oDB) to obtain the latent vectors. These latent vectors were combined with tabular data in oDB, and these joint data were used to train the CTGAN model. We successfully generated diverse synthetic records of hybrid CXR and tabular data, maintaining correspondence between them. We evaluated this synthetic database (sDB) through visual assessment, distribution of interrecord distances, and classification tasks. Our evaluation results showed that the sDB captured the features of the oDB while maintaining the correspondence between the images and tabular data. Although our approach relies on the availability of a large-scale pDB containing a substantial number of images with the same modality and imaging region as those in the oDB, this method has the potential for the public release of synthetic datasets without compromising the secondary use of data.
</details>
<details>
<summary>摘要</summary>
现代生成技术在医疗领域中得到了广泛应用，尤其是通过生成对抗网络（GAN）来解决隐私问题和促进数据共享。本文提出了一种新的方法，使用自动编码GAN（αGAN）和条件表格GAN（CTGAN）生成混合类医疗记录，包括胸部X射线图像（CXR）和结构化表格数据（包括人体测量数据和实验室测试结果）。我们的方法是使用大规模公共数据库（pDB）来减少CXR的维度，然后使用训练过的GAN模型的编码器对oDB中的图像进行编码，得到了潜在 вектор。这些潜在 вектор与表格数据进行结合，并将这些联合数据用于CTGAN模型的训练。我们成功地生成了多样化的医疗记录，保持了图像和表格数据之间的协调。我们对这个synthetic数据库（sDB）进行了视觉评估、记录间距离分布和分类任务的评估。我们的评估结果表明，sDB捕捉了oDB中的特征，同时保持了图像和表格数据之间的协调。虽然我们的方法需要一个大规模的pDB，但这种方法具有公开 синтетиче数据库的潜在优势，不需要牺牲第二次使用数据的隐私。
</details></li>
</ul>
<hr>
<h2 id="Ske2Grid-Skeleton-to-Grid-Representation-Learning-for-Action-Recognition"><a href="#Ske2Grid-Skeleton-to-Grid-Representation-Learning-for-Action-Recognition" class="headerlink" title="Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition"></a>Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07571">http://arxiv.org/abs/2308.07571</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osvai/ske2grid">https://github.com/osvai/ske2grid</a></li>
<li>paper_authors: Dongqi Cai, Yangyuxuan Kang, Anbang Yao, Yurong Chen</li>
<li>for: 本文提出了一种新的 Representation Learning 框架，用于改进人体skeleton基于动作识别。</li>
<li>methods: 本文使用了三种新的设计方法：Graph-node index transform (GIT)、Up-sampling transform (UPT) 和 Progressive learning strategy (PLS)，用于构建一个具有更高表示能力的人体skeleton网格表示。</li>
<li>results:  experiments 表明，使用本文提出的Ske2Grid方法可以在六个主流的人体skeleton基于动作识别 dataset 上达到更高的性能，而不需要额外的设计。<details>
<summary>Abstract</summary>
This paper presents Ske2Grid, a new representation learning framework for improved skeleton-based action recognition. In Ske2Grid, we define a regular convolution operation upon a novel grid representation of human skeleton, which is a compact image-like grid patch constructed and learned through three novel designs. Specifically, we propose a graph-node index transform (GIT) to construct a regular grid patch through assigning the nodes in the skeleton graph one by one to the desired grid cells. To ensure that GIT is a bijection and enrich the expressiveness of the grid representation, an up-sampling transform (UPT) is learned to interpolate the skeleton graph nodes for filling the grid patch to the full. To resolve the problem when the one-step UPT is aggressive and further exploit the representation capability of the grid patch with increasing spatial size, a progressive learning strategy (PLS) is proposed which decouples the UPT into multiple steps and aligns them to multiple paired GITs through a compact cascaded design learned progressively. We construct networks upon prevailing graph convolution networks and conduct experiments on six mainstream skeleton-based action recognition datasets. Experiments show that our Ske2Grid significantly outperforms existing GCN-based solutions under different benchmark settings, without bells and whistles. Code and models are available at https://github.com/OSVAI/Ske2Grid
</details>
<details>
<summary>摘要</summary>
First, we propose a graph-node index transform (GIT) to assign nodes in the skeleton graph to desired grid cells. This ensures that GIT is a bijection and enriches the expressiveness of the grid representation.Second, we learn an up-sampling transform (UPT) to interpolate the skeleton graph nodes for filling the grid patch to the full. This ensures that the grid representation is dense and detailed.Third, we propose a progressive learning strategy (PLS) to decouple the UPT into multiple steps and align them with multiple paired GITs through a compact cascaded design learned progressively. This further exploits the representation capability of the grid patch with increasing spatial size.We construct networks upon prevailing graph convolution networks and conduct experiments on six mainstream skeleton-based action recognition datasets. The results show that our Ske2Grid significantly outperforms existing GCN-based solutions under different benchmark settings, without bells and whistles. The code and models are available at https://github.com/OSVAI/Ske2Grid.
</details></li>
</ul>
<hr>
<h2 id="Improved-mirror-ball-projection-for-more-accurate-merging-of-multiple-camera-outputs-and-process-monitoring"><a href="#Improved-mirror-ball-projection-for-more-accurate-merging-of-multiple-camera-outputs-and-process-monitoring" class="headerlink" title="Improved mirror ball projection for more accurate merging of multiple camera outputs and process monitoring"></a>Improved mirror ball projection for more accurate merging of multiple camera outputs and process monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10991">http://arxiv.org/abs/2308.10991</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FrostKiwi/Mirrorball">https://github.com/FrostKiwi/Mirrorball</a></li>
<li>paper_authors: Wladislav Artsimovich, Yoko Hirono</li>
<li>for: 用圆镜代替宽角摄像机，实现低成本的生产过程监测在危险环境中，包括高温、真空和强电磁场环境。</li>
<li>methods: 使用圆镜反射将多种摄像机类型（如彩色图像、近红外、长波长红外、 ultraviolet）集成到单一宽角输出中，并考虑不同摄像机位置和镜头使用。</li>
<li>results: 研究表明，使用圆镜反射可以减少不同摄像机位置引入的视角偏移，具体取决于镜子大小和监测目标距离。此外，本文还介绍了一种受限于投影镜球的扭曲问题的变种，并评估了过程监测via圆镜球的效果。<details>
<summary>Abstract</summary>
Using spherical mirrors in place of wide-angle cameras allows for cost-effective monitoring of manufacturing processes in hazardous environment, where a camera would normally not operate. This includes environments of high heat, vacuum and strong electromagnetic fields. Moreover, it allows the layering of multiple camera types (e.g., color image, near-infrared, long-wavelength infrared, ultraviolet) into a single wide-angle output, whilst accounting for the different camera placements and lenses used. Normally, the different camera positions introduce a parallax shift between the images, but with a spherical projection as produced by a spherical mirror, this parallax shift is reduced, depending on mirror size and distance to the monitoring target.   This paper introduces a variation of the 'mirror ball projection', that accounts for distortion produced by a perspective camera at the pole of the projection. Finally, the efficacy of process monitoring via a mirror ball is evaluated.
</details>
<details>
<summary>摘要</summary>
Note: Simplified Chinese is also known as "简化字" or "简化字".Translation Notes:* "wide-angle camera" is translated as "广角镜头" (guǎng jiàng jīng tóu), which is a more common term in Simplified Chinese.* "spherical mirror" is translated as "球形镜" (qiu xíng jìng), which is a more precise term in Simplified Chinese.* "parallax shift" is translated as "偏移" (piān yì), which is a more common term in Simplified Chinese.* "perspective camera" is translated as "投影镜头" (pù yǐng jīng tóu), which is a more precise term in Simplified Chinese.* "mirror ball projection" is translated as "镜球投影" (jìng qiu pù yǐng), which is a more common term in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="SST-A-Simplified-Swin-Transformer-based-Model-for-Taxi-Destination-Prediction-based-on-Existing-Trajectory"><a href="#SST-A-Simplified-Swin-Transformer-based-Model-for-Taxi-Destination-Prediction-based-on-Existing-Trajectory" class="headerlink" title="SST: A Simplified Swin Transformer-based Model for Taxi Destination Prediction based on Existing Trajectory"></a>SST: A Simplified Swin Transformer-based Model for Taxi Destination Prediction based on Existing Trajectory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07555">http://arxiv.org/abs/2308.07555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zepu Wang, Yifei Sun, Zhiyu Lei, Xincheng Zhu, Peng Sun</li>
<li>for: 预测AXI trajectory的目的地有很多减值，可以帮助智能位置基础服务。</li>
<li>methods: 将AXI trajectory转换为二维网格，使用计算机视觉技术进行预测。</li>
<li>results: 我们的实验结果表明，使用简化的Swin Transformer（SST）结构可以在实际 trajectory数据上达到更高的准确率，比state-of-the-art方法更高。<details>
<summary>Abstract</summary>
Accurately predicting the destination of taxi trajectories can have various benefits for intelligent location-based services. One potential method to accomplish this prediction is by converting the taxi trajectory into a two-dimensional grid and using computer vision techniques. While the Swin Transformer is an innovative computer vision architecture with demonstrated success in vision downstream tasks, it is not commonly used to solve real-world trajectory problems. In this paper, we propose a simplified Swin Transformer (SST) structure that does not use the shifted window idea in the traditional Swin Transformer, as trajectory data is consecutive in nature. Our comprehensive experiments, based on real trajectory data, demonstrate that SST can achieve higher accuracy compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本为简化中文。</SYS>>预测出AXI Taxi trajectory的目的地可以有各种 beneficial effects for intelligent location-based services. one potential method to achieve this prediction is by converting the taxi trajectory into a two-dimensional grid and using computer vision techniques. Although the Swin Transformer is an innovative computer vision architecture with demonstrated success in vision downstream tasks, it is not commonly used to solve real-world trajectory problems. In this paper, we propose a simplified Swin Transformer (SST) structure that does not use the shifted window idea in the traditional Swin Transformer, as trajectory data is consecutive in nature. Our comprehensive experiments, based on real trajectory data, demonstrate that SST can achieve higher accuracy compared to state-of-the-art methods.Here's the word-for-word translation of the text into Simplified Chinese:<<SYS>>将给定文本转换为简化中文。</SYS>>预测AXI taxi trajectory的目的地可以有各种有益的效果 для智能位置基于服务。一个 potential method to achieve this prediction is by converting the taxi trajectory into a two-dimensional grid and using computer vision techniques. Although the Swin Transformer is an innovative computer vision architecture with demonstrated success in vision downstream tasks, it is not commonly used to solve real-world trajectory problems. In this paper, we propose a simplified Swin Transformer (SST) structure that does not use the shifted window idea in the traditional Swin Transformer, as trajectory data is consecutive in nature. Our comprehensive experiments, based on real trajectory data, demonstrate that SST can achieve higher accuracy compared to state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Multi-view-3D-Face-Reconstruction-Based-on-Flame"><a href="#Multi-view-3D-Face-Reconstruction-Based-on-Flame" class="headerlink" title="Multi-view 3D Face Reconstruction Based on Flame"></a>Multi-view 3D Face Reconstruction Based on Flame</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07551">http://arxiv.org/abs/2308.07551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhuo Zheng, Junhao Zhao, Xiaohong Liu, Yongyang Pan, Zhenghao Gan, Haozhe Han, Ning Liu</li>
<li>for: 本研究旨在提高面部3D重建质量，通过结合多视图训练框架和面 Parametric模型Flame，提出多视图训练和测试模型MFNet。</li>
<li>methods: 我们建立了一个无监督训练框架，并实施了多视图光流损失函数和面点损失约束，最后获得了完整的MFNet。我们还提出了多视图光流损失和可见面罩的创新实现。</li>
<li>results: 我们在AFLW和facescape数据集上测试了我们的模型，并在实际场景中拍摄了我们的脸部图像，并实现了3D面部重建的好 Result。我们的工作主要解决了将面 Parametric模型与多视图face 3D重建结合的问题，并探讨了基于Flame的多视图训练和测试框架在面部3D重建领域的贡献。<details>
<summary>Abstract</summary>
At present, face 3D reconstruction has broad application prospects in various fields, but the research on it is still in the development stage. In this paper, we hope to achieve better face 3D reconstruction quality by combining multi-view training framework with face parametric model Flame, propose a multi-view training and testing model MFNet (Multi-view Flame Network). We build a self-supervised training framework and implement constraints such as multi-view optical flow loss function and face landmark loss, and finally obtain a complete MFNet. We propose innovative implementations of multi-view optical flow loss and the covisible mask. We test our model on AFLW and facescape datasets and also take pictures of our faces to reconstruct 3D faces while simulating actual scenarios as much as possible, which achieves good results. Our work mainly addresses the problem of combining parametric models of faces with multi-view face 3D reconstruction and explores the implementation of a Flame based multi-view training and testing framework for contributing to the field of face 3D reconstruction.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:当前，人脸3D重建具有广泛应用前景，但相关研究还处于发展阶段。在这篇论文中，我们希望通过结合多视图培训框架和人脸参数模型Flame，提出一种多视图培训和测试模型MFNet（多视图Flame网络）。我们建立了一个无监督培训框架，并实施约束 Multi-view optical flow loss function和面部标记损失等，最后获得了完整的MFNet。我们提出了面部 parametric 模型和多视图 face 3D 重建的innovative实现，包括多视图 optical flow 损失和可见面罩。我们在 AFLW 和 facescape 数据集上测试了我们的模型，并在实际场景中拍摄了我们的脸部图像，并实现了三维人脸重建。我们的工作主要解决了人脸参数模型与多视图 face 3D 重建的组合问题，并探讨了基于 Flame 的多视图培训和测试框架在人脸3D重建领域的应用。
</details></li>
</ul>
<hr>
<h2 id="3DHacker-Spectrum-based-Decision-Boundary-Generation-for-Hard-label-3D-Point-Cloud-Attack"><a href="#3DHacker-Spectrum-based-Decision-Boundary-Generation-for-Hard-label-3D-Point-Cloud-Attack" class="headerlink" title="3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack"></a>3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07546">http://arxiv.org/abs/2308.07546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunbo Tao, Daizong Liu, Pan Zhou, Yulai Xie, Wei Du, Wei Hu</li>
<li>for: 攻击3D点云模型的安全性在自动驾驶和机器人导航等应用中 receiving increasing attention。</li>
<li>methods: 我们提出了一种新的3D攻击方法，称为3D Hard-label Attacker（3DHacker），基于分类标签知识生成敏感amples。</li>
<li>results: 我们的3DHacker方法在具有黑盒环境的情况下，可以凭借高效率和小型做出比较出色的攻击性能，并且对攻击者的质量也有较好的控制。<details>
<summary>Abstract</summary>
With the maturity of depth sensors, the vulnerability of 3D point cloud models has received increasing attention in various applications such as autonomous driving and robot navigation. Previous 3D adversarial attackers either follow the white-box setting to iteratively update the coordinate perturbations based on gradients, or utilize the output model logits to estimate noisy gradients in the black-box setting. However, these attack methods are hard to be deployed in real-world scenarios since realistic 3D applications will not share any model details to users. Therefore, we explore a more challenging yet practical 3D attack setting, \textit{i.e.}, attacking point clouds with black-box hard labels, in which the attacker can only have access to the prediction label of the input. To tackle this setting, we propose a novel 3D attack method, termed \textbf{3D} \textbf{H}ard-label att\textbf{acker} (\textbf{3DHacker}), based on the developed decision boundary algorithm to generate adversarial samples solely with the knowledge of class labels. Specifically, to construct the class-aware model decision boundary, 3DHacker first randomly fuses two point clouds of different classes in the spectral domain to craft their intermediate sample with high imperceptibility, then projects it onto the decision boundary via binary search. To restrict the final perturbation size, 3DHacker further introduces an iterative optimization strategy to move the intermediate sample along the decision boundary for generating adversarial point clouds with smallest trivial perturbations. Extensive evaluations show that, even in the challenging hard-label setting, 3DHacker still competitively outperforms existing 3D attacks regarding the attack performance as well as adversary quality.
</details>
<details>
<summary>摘要</summary>
随着深度感知器的成熟，3D点云模型的漏洞受到了各种应用程序中的关注，如自动驾驶和机器人导航。先前的3D反击器都是采用白盒设定来逐渐更新坐标偏移量基于梯度，或者使用输出模型的логи值来估计噪声梯度在黑盒设定下。然而，这些攻击方法在实际应用场景中很难实施，因为实际的3D应用程序不会分享任何模型细节给用户。因此，我们研究一种更加具有挑战性且实用的3D攻击设定，即在黑盒硬标记下攻击点云，在这个设定下，攻击者只有访问输入的预测标签。为解决这个设定，我们提出了一种新的3D攻击方法，即3D硬标记攻击者（3DHacker），基于已发展的决策边界算法来生成反击样本，只需通过知道类别标签来生成对抗样本。具体来说，为构建类别意识模型的决策边界，3DHacker首先随机将两个不同类型的点云在spectral domain中混合为中间样本，然后将其投射到决策边界 via binary search。为限制最终的偏移量，3DHacker进一步引入了一种迭代优化策略，将中间样本在决策边界上移动，以生成最小的极小偏移量。广泛的评估表明，即使在挑战性的硬标记设定下，3DHacker仍然可以与现有3D攻击相比，在攻击性和对手质量方面具有竞争力。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Dataset-Distillation-for-Image-Text-Retrieval"><a href="#Multimodal-Dataset-Distillation-for-Image-Text-Retrieval" class="headerlink" title="Multimodal Dataset Distillation for Image-Text Retrieval"></a>Multimodal Dataset Distillation for Image-Text Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07545">http://arxiv.org/abs/2308.07545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xindi Wu, Zhiwei Deng, Olga Russakovsky</li>
<li>for: 这篇论文的目的是扩展 dataset distillation 方法到vision-language模型的训练中，以实现从零开始训练新模型的可能性。</li>
<li>methods: 本文提出了一个基于对应汇总的多Modal dataset distillation 方法，将影像和其相应的语言描述汇总在一个对应的形式中。</li>
<li>results: 本文比较了三种核心集选择方法 (strategic subsampling of the training dataset)，并证明了对于具有挑战性的 Flickr30K 和 COCO 检索准确度测试 benchmark 的改进，将最好的核心集选择方法选择 1000 个影像-文本组合用于训练，仅能实现 5.6% 的影像-文本搜寻精度 (recall@1)，而对于我们的 dataset distillation 方法仅需要 100 个训练组合 (一个次元的数量更少)，则可以实现类似的精度。<details>
<summary>Abstract</summary>
Dataset distillation methods offer the promise of reducing a large-scale dataset down to a significantly smaller set of (potentially synthetic) training examples, which preserve sufficient information for training a new model from scratch. So far dataset distillation methods have been developed for image classification. However, with the rise in capabilities of vision-language models, and especially given the scale of datasets necessary to train these models, the time is ripe to expand dataset distillation methods beyond image classification. In this work, we take the first steps towards this goal by expanding on the idea of trajectory matching to create a distillation method for vision-language datasets. The key challenge is that vision-language datasets do not have a set of discrete classes. To overcome this, our proposed multimodal dataset distillation method jointly distill the images and their corresponding language descriptions in a contrastive formulation. Since there are no existing baselines, we compare our approach to three coreset selection methods (strategic subsampling of the training dataset), which we adapt to the vision-language setting. We demonstrate significant improvements on the challenging Flickr30K and COCO retrieval benchmark: the best coreset selection method which selects 1000 image-text pairs for training is able to achieve only 5.6% image-to-text retrieval accuracy (recall@1); in contrast, our dataset distillation approach almost doubles that with just 100 (an order of magnitude fewer) training pairs.
</details>
<details>
<summary>摘要</summary>
dataset 简化方法可以将大规模 dataset 缩小到一个较小的（可能是人工生成的）训练示例集，保留足够的信息来训练一个新模型从头开始。目前，dataset 简化方法已经被开发出来用于图像分类。然而，随着视觉语言模型的能力的提高，特别是对于训练这些模型所需的数据集的规模的增长，现在是时候扩展 dataset 简化方法到更多领域。在这项工作中，我们做出了首先的尝试，扩展了路径匹配的想法，以创建一种用于视觉语言 dataset 的简化方法。主要挑战在于视觉语言 dataset 没有固定的分类集。为了解决这个问题，我们提出了一种多Modal 的 dataset 简化方法，通过对图像和其相应的语言描述进行joint降维来实现。由于没有现有的基准，我们对这种方法进行比较，并将其与三种核心选择方法（策略性抽样）进行比较。我们在复杂的 Flickr30K 和 COCO 检索benchmark上显示出了显著的改善：最佳核心选择方法，选择 1000 个图像-文本对作为训练集，只能达到 5.6% 的图像-文本检索精度（recall@1）；相比之下，我们的 dataset 简化方法可以在 100 个训练对（一个小数量）下达到同样的精度。
</details></li>
</ul>
<hr>
<h2 id="Visual-and-Textual-Prior-Guided-Mask-Assemble-for-Few-Shot-Segmentation-and-Beyond"><a href="#Visual-and-Textual-Prior-Guided-Mask-Assemble-for-Few-Shot-Segmentation-and-Beyond" class="headerlink" title="Visual and Textual Prior Guided Mask Assemble for Few-Shot Segmentation and Beyond"></a>Visual and Textual Prior Guided Mask Assemble for Few-Shot Segmentation and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07539">http://arxiv.org/abs/2308.07539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Shuai, Meng Fanman, Zhang Runtong, Qiu Heqian, Li Hongliang, Wu Qingbo, Xu Linfeng<br>for:* The paper is written for few-shot segmentation (FSS) tasks, specifically to enhance the generalization ability of FSS models using CLIP.methods:* The proposed method, PGMA-Net, employs a class-agnostic mask assembly process to alleviate bias towards base classes, and formulates diverse tasks into a unified manner by assembling prior through affinity.* The method includes a Prior-Guided Mask Assemble Module (PGMAM) with multiple General Assemble Units (GAUs) that consider diverse and plug-and-play interactions, and a Hierarchical Decoder with Channel-Drop Mechanism (HDCDM) to flexibly exploit assembled masks and low-level features.results:* The proposed PGMA-Net achieves new state-of-the-art results in the FSS task, with mIoU of $77.6$ on $\text{PASCAL-}5^i$ and $59.4$ on $\text{COCO-}20^i$ in 1-shot scenario.* The method can also solve bbox-level and cross-domain FSS, co-segmentation, zero-shot segmentation (ZSS) tasks, leading to an any-shot segmentation framework without extra re-training.<details>
<summary>Abstract</summary>
Few-shot segmentation (FSS) aims to segment the novel classes with a few annotated images. Due to CLIP's advantages of aligning visual and textual information, the integration of CLIP can enhance the generalization ability of FSS model. However, even with the CLIP model, the existing CLIP-based FSS methods are still subject to the biased prediction towards base classes, which is caused by the class-specific feature level interactions. To solve this issue, we propose a visual and textual Prior Guided Mask Assemble Network (PGMA-Net). It employs a class-agnostic mask assembly process to alleviate the bias, and formulates diverse tasks into a unified manner by assembling the prior through affinity. Specifically, the class-relevant textual and visual features are first transformed to class-agnostic prior in the form of probability map. Then, a Prior-Guided Mask Assemble Module (PGMAM) including multiple General Assemble Units (GAUs) is introduced. It considers diverse and plug-and-play interactions, such as visual-textual, inter- and intra-image, training-free, and high-order ones. Lastly, to ensure the class-agnostic ability, a Hierarchical Decoder with Channel-Drop Mechanism (HDCDM) is proposed to flexibly exploit the assembled masks and low-level features, without relying on any class-specific information. It achieves new state-of-the-art results in the FSS task, with mIoU of $77.6$ on $\text{PASCAL-}5^i$ and $59.4$ on $\text{COCO-}20^i$ in 1-shot scenario. Beyond this, we show that without extra re-training, the proposed PGMA-Net can solve bbox-level and cross-domain FSS, co-segmentation, zero-shot segmentation (ZSS) tasks, leading an any-shot segmentation framework.
</details>
<details>
<summary>摘要</summary>
“几shot分类（FSS）的目标是使用几个标注图像来分类新的类别。由于CLIP的优点，将CLIP与FSS模型结合可以提高模型的扩展能力。然而，即使使用CLIP模型，现有的CLIP-based FSS方法仍然受到基本类别的预测偏好，这是由于类别特定的层次交互所致。为解决这个问题，我们提出了一个可视和文本对照的 Prior Guided Mask Assemble Network (PGMA-Net)。它使用一个类别不偏的掩模过程来减少偏好，并将多种任务转换为一个统一的形式。具体来说，首先将类别相关的文本和可见特征转换为类别不偏的机会地图。然后，我们引入一个 Prior-Guided Mask Assemble Module (PGMAM)，包括多个通用组合单元 (GAUs)。它考虑了多种不同和可插入的交互，例如可见文本、间隔和内部图像、训练无须、高阶的交互。最后，为保持类别不偏的能力，我们提出了一个弹性调节的高级解码器 (HDCDM)，以灵活地利用掩模和低层特征，不需要靠类别特定的信息。它实现了新的顶尖成绩在FSS任务中，具体为PASCAL-$5^i$中的$77.6$和COCO-$20^i$中的$59.4$在1架构enario中。此外，我们显示了在无需额外重训的情况下，提案的PGMA-Net可以解决矩形范围内的FSS、共 segmentation、零shot segmentation (ZSS)任务，实现一个任何shot segmentation框架。”
</details></li>
</ul>
<hr>
<h2 id="AttMOT-Improving-Multiple-Object-Tracking-by-Introducing-Auxiliary-Pedestrian-Attributes"><a href="#AttMOT-Improving-Multiple-Object-Tracking-by-Introducing-Auxiliary-Pedestrian-Attributes" class="headerlink" title="AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary Pedestrian Attributes"></a>AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary Pedestrian Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07537">http://arxiv.org/abs/2308.07537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunhao Li, Zhen Xiao, Lin Yang, Dan Meng, Xin Zhou, Heng Fan, Libo Zhang<br>for:* The paper aims to address the gap in exploring pedestrian attributes in multi-object tracking (MOT) and propose a method to predict pedestrian attributes to support general Re-ID embedding.methods:* The proposed method AAM explores different approaches to fuse Re-ID embedding and pedestrian attributes, including attention mechanisms, to improve the performance of MOT.results:* The proposed method AAM achieves consistent improvements in MOTA, HOTA, AssA, IDs, and IDF1 scores on several representative pedestrian multi-object tracking benchmarks, including MOT17 and MOT20, when applied to state-of-the-art trackers.<details>
<summary>Abstract</summary>
Multi-object tracking (MOT) is a fundamental problem in computer vision with numerous applications, such as intelligent surveillance and automated driving. Despite the significant progress made in MOT, pedestrian attributes, such as gender, hairstyle, body shape, and clothing features, which contain rich and high-level information, have been less explored. To address this gap, we propose a simple, effective, and generic method to predict pedestrian attributes to support general Re-ID embedding. We first introduce AttMOT, a large, highly enriched synthetic dataset for pedestrian tracking, containing over 80k frames and 6 million pedestrian IDs with different time, weather conditions, and scenarios. To the best of our knowledge, AttMOT is the first MOT dataset with semantic attributes. Subsequently, we explore different approaches to fuse Re-ID embedding and pedestrian attributes, including attention mechanisms, which we hope will stimulate the development of attribute-assisted MOT. The proposed method AAM demonstrates its effectiveness and generality on several representative pedestrian multi-object tracking benchmarks, including MOT17 and MOT20, through experiments on the AttMOT dataset. When applied to state-of-the-art trackers, AAM achieves consistent improvements in MOTA, HOTA, AssA, IDs, and IDF1 scores. For instance, on MOT17, the proposed method yields a +1.1 MOTA, +1.7 HOTA, and +1.8 IDF1 improvement when used with FairMOT. To encourage further research on attribute-assisted MOT, we will release the AttMOT dataset.
</details>
<details>
<summary>摘要</summary>
多bject tracking (MOT) 是计算机视觉中的基本问题，具有许多应用，如智能监控和自动驾驶。 DESPITE 在 MOT 中做出了 significan progress， pedestrian 特征，如性别、发型、身体形态和服装特征，具有丰富和高级信息，却得到了更少的关注。为了解决这一漏洞，我们提出了一种简单、有效和通用的方法，可以预测 pedestrian 特征，以支持通用 Re-ID 嵌入。我们首先介绍 AttMOT，一个大型、高度充实的人工synthetic dataset for pedestrian tracking，包含了80k帧和6000万个 pedestrian ID，具有不同的时间、天气和场景。我们知道 AttMOT 是首个具有semantic attribute的 MOT dataset。然后，我们探索了不同的方法来融合 Re-ID 嵌入和 pedestrian 特征，包括注意力机制。我们希望这种方法能够激发attribute-assisted MOT的发展。我们提出的方法 AAM 在多个表现 pedestrian multi-object tracking benchmarks，包括 MOT17 和 MOT20，通过在 AttMOT  dataset上进行实验，实现了显著的改进。例如，在 MOT17 上，我们的方法可以提高 +1.1 MOTA、+1.7 HOTA 和 +1.8 IDF1 分数。为了鼓励 attribute-assisted MOT 的进一步研究，我们将在 AttMOT dataset上发布 AttMOT。
</details></li>
</ul>
<hr>
<h2 id="Improved-Region-Proposal-Network-for-Enhanced-Few-Shot-Object-Detection"><a href="#Improved-Region-Proposal-Network-for-Enhanced-Few-Shot-Object-Detection" class="headerlink" title="Improved Region Proposal Network for Enhanced Few-Shot Object Detection"></a>Improved Region Proposal Network for Enhanced Few-Shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07535">http://arxiv.org/abs/2308.07535</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zshanggu/htrpn">https://github.com/zshanggu/htrpn</a></li>
<li>paper_authors: Zeyu Shangguan, Mohammad Rostami</li>
<li>For: 这种研究是为了解决深度学习基本监督学习方法的限制，提高对象检测任务的性能。* Methods: 该研究提出了一种半监督法，通过使用无标注数据进行训练，提高几招物检测性能。具体来说，他们开发了一种层次三元分类区提案网络（HTRPN），以便检测并分类未标注的新类实例。* Results: 对COCO和PASCAL VOC基准数据集进行测试，研究结果表明，该方法可以提高几招物检测性能，并超越现有的状态平台FSOD方法。<details>
<summary>Abstract</summary>
Despite significant success of deep learning in object detection tasks, the standard training of deep neural networks requires access to a substantial quantity of annotated images across all classes. Data annotation is an arduous and time-consuming endeavor, particularly when dealing with infrequent objects. Few-shot object detection (FSOD) methods have emerged as a solution to the limitations of classic object detection approaches based on deep learning. FSOD methods demonstrate remarkable performance by achieving robust object detection using a significantly smaller amount of training data. A challenge for FSOD is that instances from novel classes that do not belong to the fixed set of training classes appear in the background and the base model may pick them up as potential objects. These objects behave similarly to label noise because they are classified as one of the training dataset classes, leading to FSOD performance degradation. We develop a semi-supervised algorithm to detect and then utilize these unlabeled novel objects as positive samples during the FSOD training stage to improve FSOD performance. Specifically, we develop a hierarchical ternary classification region proposal network (HTRPN) to localize the potential unlabeled novel objects and assign them new objectness labels to distinguish these objects from the base training dataset classes. Our improved hierarchical sampling strategy for the region proposal network (RPN) also boosts the perception ability of the object detection model for large objects. We test our approach and COCO and PASCAL VOC baselines that are commonly used in FSOD literature. Our experimental results indicate that our method is effective and outperforms the existing state-of-the-art (SOTA) FSOD methods. Our implementation is provided as a supplement to support reproducibility of the results.
</details>
<details>
<summary>摘要</summary>
尽管深度学习在对象检测任务中具有显著的成功，但标准的深度神经网络训练需要大量的标注图像，特别是处理不常见的对象。几拟对象检测（FSOD）方法已经出现，以解决深度学习对象检测方法的限制。FSOD方法可以达到使用较少的训练数据来实现稳定的对象检测性能。然而，FSOD中的一个挑战是，训练集中不存在的新类型对象可能会出现在背景中，并被基础模型认为是可能的对象。这些对象会被视为标注噪声，导致FSOD性能下降。我们提出了一种半supervised算法，用于检测并利用训练集外的未标注新对象作为Positive样本，以改进FSOD性能。具体来说，我们开发了一种嵌入式三元分类区域提案网络（HTRPN），用于定位潜在的未标注新对象，并将其分配新的对象性标签，以分开这些对象与基础训练集类别。我们还改进了RPN的层次采样策略，以提高对象检测模型对大对象的感知能力。我们测试了我们的方法，并与COCO和PASCAL VOC基线相比较。我们的实验结果表明，我们的方法是有效的，并超越了现有的状态的最佳方法（SOTA）。我们的实现提供了补充，以支持result的重复性。
</details></li>
</ul>
<hr>
<h2 id="Inverse-Lithography-Physics-informed-Deep-Neural-Level-Set-for-Mask-Optimization"><a href="#Inverse-Lithography-Physics-informed-Deep-Neural-Level-Set-for-Mask-Optimization" class="headerlink" title="Inverse Lithography Physics-informed Deep Neural Level Set for Mask Optimization"></a>Inverse Lithography Physics-informed Deep Neural Level Set for Mask Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12299">http://arxiv.org/abs/2308.12299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing-Yu Ma, Shaogang Hao</li>
<li>for: 提高磁版印刷过程中的分辨率，提高磁版印刷过程中的印刷可靠性</li>
<li>methods: 利用深度学习（DL）方法和层设法（ILT），实现磁版优化</li>
<li>results: 相比于各种纯DL和ILT方法，ILDLS方法可以减少计算时间，提高印刷可靠性和过程窗口（PW）等效果<details>
<summary>Abstract</summary>
As the feature size of integrated circuits continues to decrease, optical proximity correction (OPC) has emerged as a crucial resolution enhancement technology for ensuring high printability in the lithography process. Recently, level set-based inverse lithography technology (ILT) has drawn considerable attention as a promising OPC solution, showcasing its powerful pattern fidelity, especially in advanced process. However, massive computational time consumption of ILT limits its applicability to mainly correcting partial layers and hotspot regions. Deep learning (DL) methods have shown great potential in accelerating ILT. However, lack of domain knowledge of inverse lithography limits the ability of DL-based algorithms in process window (PW) enhancement and etc. In this paper, we propose an inverse lithography physics-informed deep neural level set (ILDLS) approach for mask optimization. This approach utilizes level set based-ILT as a layer within the DL framework and iteratively conducts mask prediction and correction to significantly enhance printability and PW in comparison with results from pure DL and ILT. With this approach, computation time is reduced by a few orders of magnitude versus ILT. By gearing up DL with knowledge of inverse lithography physics, ILDLS provides a new and efficient mask optimization solution.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The translation may vary depending on the region and dialect.)
</details></li>
</ul>
<hr>
<h2 id="Confidence-Contours-Uncertainty-Aware-Annotation-for-Medical-Semantic-Segmentation"><a href="#Confidence-Contours-Uncertainty-Aware-Annotation-for-Medical-Semantic-Segmentation" class="headerlink" title="Confidence Contours: Uncertainty-Aware Annotation for Medical Semantic Segmentation"></a>Confidence Contours: Uncertainty-Aware Annotation for Medical Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07528">http://arxiv.org/abs/2308.07528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andre Ye, Quan Ze Chen, Amy Zhang</li>
<li>for: 本研究旨在提出一种新的验证图像分割模型的方法，以增强模型对不确定性的理解，从而更好地处理视觉抽象。</li>
<li>methods: 本研究提出了一种新的分割表示方法，称为信度轮廓（Confidence Contours），该方法通过高信度和低信度的轮廓来捕捉不确定性。同时，研究人员还开发了一种新的标注系统，用于收集轮廓数据。</li>
<li>results: 研究人员在Lung Image Dataset Consortium（LIDC）和一个 sintetic dataset上进行了评估，结果表明，Confidence Contours可以准确地捕捉不确定性，而且与标准的单个精度标注相比， annotator的努力不会增加太多。此外，研究人员还发现，通用的分割模型可以很好地学习Confidence Contours。最后，在5名医学专家的采访中，研究人员发现，Confidence Contour map比bayesian map更易于理解，因为它能够反映结构不确定性。<details>
<summary>Abstract</summary>
Medical image segmentation modeling is a high-stakes task where understanding of uncertainty is crucial for addressing visual ambiguity. Prior work has developed segmentation models utilizing probabilistic or generative mechanisms to infer uncertainty from labels where annotators draw a singular boundary. However, as these annotations cannot represent an individual annotator's uncertainty, models trained on them produce uncertainty maps that are difficult to interpret. We propose a novel segmentation representation, Confidence Contours, which uses high- and low-confidence ``contours'' to capture uncertainty directly, and develop a novel annotation system for collecting contours. We conduct an evaluation on the Lung Image Dataset Consortium (LIDC) and a synthetic dataset. From an annotation study with 30 participants, results show that Confidence Contours provide high representative capacity without considerably higher annotator effort. We also find that general-purpose segmentation models can learn Confidence Contours at the same performance level as standard singular annotations. Finally, from interviews with 5 medical experts, we find that Confidence Contour maps are more interpretable than Bayesian maps due to representation of structural uncertainty.
</details>
<details>
<summary>摘要</summary>
医学图像分割模型化是一项高风险任务，理解不确定性是关键来解决视觉 ambiguity。先前的工作已经开发出了使用概率或生成机制来推导不确定性从标签中的分割模型，但这些标签不能表示个体注意者的不确定性，因此模型从这些标签学习的不确定性地图很难解释。我们提出了一种新的分割表示方式，即信心轮廓，可以直接捕捉不确定性，并开发了一种新的注意者系统来收集轮廓。我们在Lung Image Dataset Consortium（LIDC）和一个 sintetic  dataset上进行了评估。从30名参与者的注意者研究中，结果表明，信心轮廓可以提供高度表示能力，而无需较大的注意者努力。此外，我们发现，通用分割模型可以学习信心轮廓，并且与标准单个标签学习模型的性能相当。最后，经验了5名医学专家的采访，发现，信心轮廓地图比bayesian地图更易于理解，因为它表示了结构不确定性。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Scalable-Epistemic-Uncertainty-Quantification-in-Organ-Segmentation"><a href="#Benchmarking-Scalable-Epistemic-Uncertainty-Quantification-in-Organ-Segmentation" class="headerlink" title="Benchmarking Scalable Epistemic Uncertainty Quantification in Organ Segmentation"></a>Benchmarking Scalable Epistemic Uncertainty Quantification in Organ Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07506">http://arxiv.org/abs/2308.07506</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jadie1/medseguq">https://github.com/jadie1/medseguq</a></li>
<li>paper_authors: Jadie Adams, Shireen Y. Elhabian</li>
<li>for: 这个论文的目的是评估多种基于深度学习的自动组织器gmentation方法中的epistemicuncertainty量化方法，以便在临床应用中提供可靠和可Robust的模型。</li>
<li>methods: 本文使用了多种epistemic uncertainty量化方法，包括Bayesian neural networks, Monte Carlo dropout, and Deep Ensembles，并进行了比较性 benchmarking 测试。</li>
<li>results: 研究发现，Deep Ensembles方法在accuracy和uncertainty calibration方面表现最佳，而Bayesian neural networks方法在out-of-distribution detection方面表现最好。本文还提供了每种方法的优缺点和未来改进的建议。<details>
<summary>Abstract</summary>
Deep learning based methods for automatic organ segmentation have shown promise in aiding diagnosis and treatment planning. However, quantifying and understanding the uncertainty associated with model predictions is crucial in critical clinical applications. While many techniques have been proposed for epistemic or model-based uncertainty estimation, it is unclear which method is preferred in the medical image analysis setting. This paper presents a comprehensive benchmarking study that evaluates epistemic uncertainty quantification methods in organ segmentation in terms of accuracy, uncertainty calibration, and scalability. We provide a comprehensive discussion of the strengths, weaknesses, and out-of-distribution detection capabilities of each method as well as recommendations for future improvements. These findings contribute to the development of reliable and robust models that yield accurate segmentations while effectively quantifying epistemic uncertainty.
</details>
<details>
<summary>摘要</summary>
深度学习基于方法可能在自动器官分割方面展示了较好的表现，但是量化和理解模型预测结果中的不确定性是重要的。虽然许多技术已经被提出用于知识型或模型基的不确定性估计，但是尚未清楚哪种方法在医学图像分析场景中更有优势。这篇论文提供了一项完整的比较研究，评估了器官分割中 epistemic 不确定性估计方法的准确性、不确定性归一化和可扩展性。我们提供了每种方法的优缺点、缺失和离群检测能力，以及未来改进的建议。这些发现有助于开发可靠和可靠的模型，以便实现准确的分割和有效地量化 epistemic 不确定性。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="ICAFusion-Iterative-Cross-Attention-Guided-Feature-Fusion-for-Multispectral-Object-Detection"><a href="#ICAFusion-Iterative-Cross-Attention-Guided-Feature-Fusion-for-Multispectral-Object-Detection" class="headerlink" title="ICAFusion: Iterative Cross-Attention Guided Feature Fusion for Multispectral Object Detection"></a>ICAFusion: Iterative Cross-Attention Guided Feature Fusion for Multispectral Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07504">http://arxiv.org/abs/2308.07504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chanchanchan97/icafusion">https://github.com/chanchanchan97/icafusion</a></li>
<li>paper_authors: Jifeng Shen, Yifei Chen, Yue Liu, Xin Zuo, Heng Fan, Wankou Yang</li>
<li>for: 本研究旨在提高多spectral图像的特征融合，以提高多spectral对象检测的精度。</li>
<li>methods: 提出了一种基于双cross-attention transformer的新特征融合框架，通过全球特征交互模型，捕捉多modalitat中的补偿信息，提高对象特征的抑制性。</li>
<li>results: 实验结果表明，提出的方法可以在KAIST、FLIR和VEDAI数据集上实现superior表现，同时具有更快的推理速度，适用于各种实际应用场景。<details>
<summary>Abstract</summary>
Effective feature fusion of multispectral images plays a crucial role in multi-spectral object detection. Previous studies have demonstrated the effectiveness of feature fusion using convolutional neural networks, but these methods are sensitive to image misalignment due to the inherent deffciency in local-range feature interaction resulting in the performance degradation. To address this issue, a novel feature fusion framework of dual cross-attention transformers is proposed to model global feature interaction and capture complementary information across modalities simultaneously. This framework enhances the discriminability of object features through the query-guided cross-attention mechanism, leading to improved performance. However, stacking multiple transformer blocks for feature enhancement incurs a large number of parameters and high spatial complexity. To handle this, inspired by the human process of reviewing knowledge, an iterative interaction mechanism is proposed to share parameters among block-wise multimodal transformers, reducing model complexity and computation cost. The proposed method is general and effective to be integrated into different detection frameworks and used with different backbones. Experimental results on KAIST, FLIR, and VEDAI datasets show that the proposed method achieves superior performance and faster inference, making it suitable for various practical scenarios. Code will be available at https://github.com/chanchanchan97/ICAFusion.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translates into 多spectral图像的有效特征融合在多spectral对象检测中发挥关键作用。先前的研究已经证明了使用卷积神经网络进行特征融合的效iveness，但这些方法容易受到图像不对齐的影响，导致性能下降。为解决这问题，一种新的特征融合框架基于双重交叉注意力变换器是提出来，可以模型全局特征交互和同时捕捉不同模式之间的补做信息。这个框架通过尝试引导的交叉注意力机制来增强对象特征的抗混淆性，从而提高性能。然而，堆叠多个变换器块以提高特征的增强，会增加模型的参数量和空间复杂度。为解决这问题，根据人类审查知识的过程，一种循环互动机制是提出来，可以在不同模式之间共享参数，从而降低模型的参数量和计算量。提出的方法可以与不同的检测框架集成，并且可以与不同的后处器结合使用。实验结果表明，提出的方法在KAIST、FLIR和VEDAI datasets上 achieve superior performance和快速的检测，适用于各种实际应用场景。代码将在https://github.com/chanchanchan97/ICAFusion中公开。
</details></li>
</ul>
<hr>
<h2 id="SpecTracle-Wearable-Facial-Motion-Tracking-from-Unobtrusive-Peripheral-Cameras"><a href="#SpecTracle-Wearable-Facial-Motion-Tracking-from-Unobtrusive-Peripheral-Cameras" class="headerlink" title="SpecTracle: Wearable Facial Motion Tracking from Unobtrusive Peripheral Cameras"></a>SpecTracle: Wearable Facial Motion Tracking from Unobtrusive Peripheral Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07502">http://arxiv.org/abs/2308.07502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinan Xuan, Varun Viswanath, Sunny Chu, Owen Bartolf, Jessica Echterhoff, Edward Wang</li>
<li>for: 这个论文旨在实现无障碍的虚拟现实环境中的”面对面”互动。</li>
<li>methods: 该系统使用两个宽角相机，位于幕面上，以实现面部动作跟踪。</li>
<li>results: 该系统可以在实时24帧&#x2F;秒的� mobil GPU上运行，并且可以精准地跟踪用户面部的不同部分运动。个性化协调可以提高跟踪性能42.3%。<details>
<summary>Abstract</summary>
Facial motion tracking in head-mounted displays (HMD) has the potential to enable immersive "face-to-face" interaction in a virtual environment. However, current works on facial tracking are not suitable for unobtrusive augmented reality (AR) glasses or do not have the ability to track arbitrary facial movements. In this work, we demonstrate a novel system called SpecTracle that tracks a user's facial motions using two wide-angle cameras mounted right next to the visor of a Hololens. Avoiding the usage of cameras extended in front of the face, our system greatly improves the feasibility to integrate full-face tracking into a low-profile form factor. We also demonstrate that a neural network-based model processing the wide-angle cameras can run in real-time at 24 frames per second (fps) on a mobile GPU and track independent facial movement for different parts of the face with a user-independent model. Using a short personalized calibration, the system improves its tracking performance by 42.3% compared to the user-independent model.
</details>
<details>
<summary>摘要</summary>
“头戴式显示器（HMD）中的面部运动跟踪可能启用虚拟环境中的互动。然而，当前的面部跟踪方法不适用于不干扰的增强现实（AR）镜或无法跟踪自由的面部运动。在这项工作中，我们介绍了一种名为SpecTracle的系统，它使用两个宽角相机安装在Hololens镜的两侧，以跟踪用户的面部运动。避免使用扩展到面前的相机，我们的系统可以大幅提高将全面跟踪集成到低 профиль形态中的可能性。我们还示出了一种基于神经网络的模型，通过处理宽角相机可以在实时24帧/秒（fps）的移动硬件上运行，并可以独立地跟踪不同部分的面部运动。通过短时间的个性化准备，系统可以提高跟踪性能42.3%比用户无关模型。”
</details></li>
</ul>
<hr>
<h2 id="BSED-Baseline-Shapley-Based-Explainable-Detector"><a href="#BSED-Baseline-Shapley-Based-Explainable-Detector" class="headerlink" title="BSED: Baseline Shapley-Based Explainable Detector"></a>BSED: Baseline Shapley-Based Explainable Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07490">http://arxiv.org/abs/2308.07490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michihiro Kuroki, Toshihiko Yamasaki</li>
<li>for: 这个论文的目的是提高Explainable Artificial Intelligence（XAI）在图像识别领域的可解释性，并提供一种基于基线特征的可解释的检测器（BSED），以满足可解释性axioms。</li>
<li>methods: 这个论文使用了Shapley值来扩展对象检测，并将其应用到各种检测器中，以实现可解释性。它还可以在不需要细致参数调整的情况下，对各种检测目标进行解释。</li>
<li>results: 论文的结果表明，BSED可以提供更有效的解释，并且可以在各种应用中 correction based on explanations from our method。此外，BSED的处理成本在理解的范围内，而原始的Shapley值则是计算成本过高的。<details>
<summary>Abstract</summary>
Explainable artificial intelligence (XAI) has witnessed significant advances in the field of object recognition, with saliency maps being used to highlight image features relevant to the predictions of learned models. Although these advances have made AI-based technology more interpretable to humans, several issues have come to light. Some approaches present explanations irrelevant to predictions, and cannot guarantee the validity of XAI (axioms). In this study, we propose the Baseline Shapley-based Explainable Detector (BSED), which extends the Shapley value to object detection, thereby enhancing the validity of interpretation. The Shapley value can attribute the prediction of a learned model to a baseline feature while satisfying the explainability axioms. The processing cost for the BSED is within the reasonable range, while the original Shapley value is prohibitively computationally expensive. Furthermore, BSED is a generalizable method that can be applied to various detectors in a model-agnostic manner, and interpret various detection targets without fine-grained parameter tuning. These strengths can enable the practical applicability of XAI. We present quantitative and qualitative comparisons with existing methods to demonstrate the superior performance of our method in terms of explanation validity. Moreover, we present some applications, such as correcting detection based on explanations from our method.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）的解释性（XAI）在图像识别领域已经取得了重要进步，使用焦点图来高亮图像特征，有助于人类更好地理解AI模型的预测。然而，这些进步并不能解决所有问题。一些方法提供不相关的解释，无法保证XAI的AXIoms的正确性。在本研究中，我们提出了基线Shapley值基于的解释探测器（BSED），该方法扩展了Shapley值到对象检测，从而提高了解释的正确性。Shapley值可以归因预测的learned模型到基线特征，同时满足解释AXIoms。BSED的处理成本在合理范围内，而原始Shapley值计算成本过高。此外，BSED是一种通用的方法，可以适用于不同的检测器，并且可以对各种检测目标进行不必做细致参数调整的解释。这些优点使得XAI在实际应用中得到了加强。我们对现有方法进行了量化和质量比较，以示我们的方法在解释正确性方面的超越。此外，我们还展示了一些应用，如通过我们的方法提供的解释来修正检测结果。
</details></li>
</ul>
<hr>
<h2 id="Space-Object-Identification-and-Classification-from-Hyperspectral-Material-Analysis"><a href="#Space-Object-Identification-and-Classification-from-Hyperspectral-Material-Analysis" class="headerlink" title="Space Object Identification and Classification from Hyperspectral Material Analysis"></a>Space Object Identification and Classification from Hyperspectral Material Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07481">http://arxiv.org/abs/2308.07481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Massimiliano Vasile, Lewis Walker, Andrew Campbell, Simao Marto, Paul Murray, Stephen Marshall, Vasili Savitski</li>
<li>for: 这个论文是为了提取未知宇宙对象的谱spectrum信息而设计的数据处理管道。</li>
<li>methods: 该论文使用了两种物质标识和分类技术：一种是基于机器学习，另一种是基于最小二乘匹配已知谱spectrum库。</li>
<li>results: 论文将展示一些初步的物体识别和分类结果。<details>
<summary>Abstract</summary>
This paper presents a data processing pipeline designed to extract information from the hyperspectral signature of unknown space objects. The methodology proposed in this paper determines the material composition of space objects from single pixel images. Two techniques are used for material identification and classification: one based on machine learning and the other based on a least square match with a library of known spectra. From this information, a supervised machine learning algorithm is used to classify the object into one of several categories based on the detection of materials on the object. The behaviour of the material classification methods is investigated under non-ideal circumstances, to determine the effect of weathered materials, and the behaviour when the training library is missing a material that is present in the object being observed. Finally the paper will present some preliminary results on the identification and classification of space objects.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "hyperspectral signature" is translated as "多spectral特征" (duō spectrum de tiào xiàng)* "material composition" is translated as "物质组成" (wù zhì zhōng jī)* "machine learning" is translated as "机器学习" (jī shì xué xí)* "least square match" is translated as "最小二乘匹配" (zuì xiǎo èr chuī pīng pái)* "library of known spectra" is translated as "已知spectra库" (yǐ zhī spectrum kù)* "supervised machine learning algorithm" is translated as "指导式机器学习算法" (dì dǎo xìng jī shì xué xí algoritmos)* "classify the object" is translated as "对象分类" (duì yì fāng lèi)* "weathered materials" is translated as "天然风化物" (tiān zhēn fēng huà wù)Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-MIMO-U-Net-Efficient-and-Accurate-Uncertainty-Estimation-for-Pixel-wise-Regression"><a href="#Probabilistic-MIMO-U-Net-Efficient-and-Accurate-Uncertainty-Estimation-for-Pixel-wise-Regression" class="headerlink" title="Probabilistic MIMO U-Net: Efficient and Accurate Uncertainty Estimation for Pixel-wise Regression"></a>Probabilistic MIMO U-Net: Efficient and Accurate Uncertainty Estimation for Pixel-wise Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07477">http://arxiv.org/abs/2308.07477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antonbaumann/mimo-unet">https://github.com/antonbaumann/mimo-unet</a></li>
<li>paper_authors: Anton Baumann, Thomas Roßberg, Michael Schmitt</li>
<li>For: 提高机器学习模型的可靠性和可读性，特别在高度重要的实际应用场景中。* Methods: 基于多输入多输出（MIMO）框架，利用深度神经网络的过参数化来实现像素级回归任务。采用U-Net架构，在单个模型中培养多个互相约束的子网络。还提出了一种同步子网络性能的新程序。* Results: 对两个正交的数据集进行了全面的评估，与现有模型相比，具有相似的准确率，更好的准确率Calibration，robust的out-of-distribution检测能力，并且具有较小的参数大小和执行时间。代码可以在github.com&#x2F;antonbaumann&#x2F;MIMO-Unet中下载。<details>
<summary>Abstract</summary>
Uncertainty estimation in machine learning is paramount for enhancing the reliability and interpretability of predictive models, especially in high-stakes real-world scenarios. Despite the availability of numerous methods, they often pose a trade-off between the quality of uncertainty estimation and computational efficiency. Addressing this challenge, we present an adaptation of the Multiple-Input Multiple-Output (MIMO) framework -- an approach exploiting the overparameterization of deep neural networks -- for pixel-wise regression tasks. Our MIMO variant expands the applicability of the approach from simple image classification to broader computer vision domains. For that purpose, we adapted the U-Net architecture to train multiple subnetworks within a single model, harnessing the overparameterization in deep neural networks. Additionally, we introduce a novel procedure for synchronizing subnetwork performance within the MIMO framework. Our comprehensive evaluations of the resulting MIMO U-Net on two orthogonal datasets demonstrate comparable accuracy to existing models, superior calibration on in-distribution data, robust out-of-distribution detection capabilities, and considerable improvements in parameter size and inference time. Code available at github.com/antonbaumann/MIMO-Unet
</details>
<details>
<summary>摘要</summary>
“机器学习中的不确定性估计是对预测模型的可靠性和解释性提高的重要因素，特别是在高度重要的实际应用中。 despite the availability of numerous methods, they often pose a trade-off between the quality of uncertainty estimation and computational efficiency.  Addressing this challenge, we present an adaptation of the Multiple-Input Multiple-Output（MIMO）framework—an approach exploiting the overparameterization of deep neural networks—for pixel-wise regression tasks. Our MIMO variant expands the applicability of the approach from simple image classification to broader computer vision domains. For that purpose, we adapted the U-Net architecture to train multiple subnetworks within a single model, harnessing the overparameterization in deep neural networks. Additionally, we introduce a novel procedure for synchronizing subnetwork performance within the MIMO framework. Our comprehensive evaluations of the resulting MIMO U-Net on two orthogonal datasets demonstrate comparable accuracy to existing models, superior calibration on in-distribution data, robust out-of-distribution detection capabilities, and considerable improvements in parameter size and inference time. Code available at github.com/antonbaumann/MIMO-Unet”Here's the breakdown of the translation:1. 机器学习 (machine learning) -> 机器学习 (machine learning)2. 不确定性估计 (uncertainty estimation) -> 不确定性估计 (uncertainty estimation)3. MIMO (Multiple-Input Multiple-Output) -> MIMO (多输入多输出)4. overparameterization -> 过参数化5. deep neural networks -> 深度神经网络6. pixel-wise regression -> 像素级别回归7. U-Net -> U-Net8. subnetworks -> 子网络9. in-distribution data -> 在分布中的数据10. out-of-distribution detection -> 外分布检测11. parameter size -> 参数大小12. inference time -> 推理时间Note that Simplified Chinese is used in the translation, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Reducing-Training-Demands-for-3D-Gait-Recognition-with-Deep-Koopman-Operator-Constraints"><a href="#Reducing-Training-Demands-for-3D-Gait-Recognition-with-Deep-Koopman-Operator-Constraints" class="headerlink" title="Reducing Training Demands for 3D Gait Recognition with Deep Koopman Operator Constraints"></a>Reducing Training Demands for 3D Gait Recognition with Deep Koopman Operator Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07468">http://arxiv.org/abs/2308.07468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cole Hill, Mauricio Pamplona Segundo, Sudeep Sarkar</li>
<li>for: 本研究的目的是提出一种使用深度学习技术实现人体步态识别，并使用Linear Dynamical Systems（LDS）模块和损失函数来保证时间相关性和动态可靠性。</li>
<li>methods: 本研究使用了深度神经网络来适应3D人体步态数据，并引入了LDS模块和基于Koopman算子理论的损失函数来保证模型的动态可靠性和时间相关性。</li>
<li>results: 根据USF HumanID和CASIA-B dataset的比较，本研究的LDS方法可以在训练数据的限制下实现更高的准确率，而且3D模型方法在不同的视角变化和包袋等情况下也表现更好。<details>
<summary>Abstract</summary>
Deep learning research has made many biometric recognition solution viable, but it requires vast training data to achieve real-world generalization. Unlike other biometric traits, such as face and ear, gait samples cannot be easily crawled from the web to form massive unconstrained datasets. As the human body has been extensively studied for different digital applications, one can rely on prior shape knowledge to overcome data scarcity. This work follows the recent trend of fitting a 3D deformable body model into gait videos using deep neural networks to obtain disentangled shape and pose representations for each frame. To enforce temporal consistency in the network, we introduce a new Linear Dynamical Systems (LDS) module and loss based on Koopman operator theory, which provides an unsupervised motion regularization for the periodic nature of gait, as well as a predictive capacity for extending gait sequences. We compare LDS to the traditional adversarial training approach and use the USF HumanID and CASIA-B datasets to show that LDS can obtain better accuracy with less training data. Finally, we also show that our 3D modeling approach is much better than other 3D gait approaches in overcoming viewpoint variation under normal, bag-carrying and clothing change conditions.
</details>
<details>
<summary>摘要</summary>
This study uses deep neural networks to fit a 3D deformable body model to gait videos and get separate shape and pose representations for each frame. To make sure the movements in the videos are consistent, we use a new Linear Dynamical Systems (LDS) module and loss based on Koopman operator theory. This approach provides an unsupervised motion regularization for the periodic nature of gait, as well as a way to predict how gait sequences will continue. We compare LDS to traditional adversarial training and use the USF HumanID and CASIA-B datasets to show that LDS can get better accuracy with less training data.Finally, we show that our 3D modeling approach is much better than other 3D gait approaches at handling changes in viewpoint, bag-carrying, and clothing under normal conditions.
</details></li>
</ul>
<hr>
<h2 id="There-Is-a-Digital-Art-History"><a href="#There-Is-a-Digital-Art-History" class="headerlink" title="There Is a Digital Art History"></a>There Is a Digital Art History</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07464">http://arxiv.org/abs/2308.07464</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Gracetyty/art-gallery">https://github.com/Gracetyty/art-gallery</a></li>
<li>paper_authors: Leonardo Impett, Fabian Offert</li>
<li>for: 本研究探讨了 Johanna Drucker 十年前提出的问题：“是否有数字艺术历史？”，以及在大规模变换器基础上的视觉模型的出现对数字艺术历史的影响。</li>
<li>methods: 本研究使用了两种主要方法：一是对大规模视觉模型中新编码的视艺抄影重要性进行分析，二是通过使用当代大规模视觉模型investigate基本问题从艺术史和城市规划等领域来进行技术 caso study。</li>
<li>results: 研究结果表明，大规模视觉模型在数字艺术历史方面可能会导致一个新的парадигShift，因为它们可以自动批处和抽象不同形式的视觉逻辑，并且在数字生活中已经广泛应用。同时，这些系统需要一种新的批判方法，该方法需要考虑模型和其应用之间的知识共生。<details>
<summary>Abstract</summary>
In this paper, we revisit Johanna Drucker's question, "Is there a digital art history?" -- posed exactly a decade ago -- in the light of the emergence of large-scale, transformer-based vision models. While more traditional types of neural networks have long been part of digital art history, and digital humanities projects have recently begun to use transformer models, their epistemic implications and methodological affordances have not yet been systematically analyzed. We focus our analysis on two main aspects that, together, seem to suggest a coming paradigm shift towards a "digital" art history in Drucker's sense. On the one hand, the visual-cultural repertoire newly encoded in large-scale vision models has an outsized effect on digital art history. The inclusion of significant numbers of non-photographic images allows for the extraction and automation of different forms of visual logics. Large-scale vision models have "seen" large parts of the Western visual canon mediated by Net visual culture, and they continuously solidify and concretize this canon through their already widespread application in all aspects of digital life. On the other hand, based on two technical case studies of utilizing a contemporary large-scale visual model to investigate basic questions from the fields of art history and urbanism, we suggest that such systems require a new critical methodology that takes into account the epistemic entanglement of a model and its applications. This new methodology reads its corpora through a neural model's training data, and vice versa: the visual ideologies of research datasets and training datasets become entangled.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们重新回归到 Johanna Drucker 提出的十年前的问题：“是否有数字艺术历史？”——传统神经网络已经长期出现在数字艺术史上，而最近的数字人文科学项目则开始使用转换器模型。然而，这些模型的认知途径和方法论上的影响尚未系统地分析。我们将分析两个主要方面，这两个方面共同表明一种可能的未来方向：数字艺术史。一方面，大规模感知模型中新编码的视觉文化财富对数字艺术史产生了巨大的影响。由于大量非摄影图像的包容，可以自动提取和抽象不同类型的视觉逻辑。大规模感知模型已经“看到”了西方视觉Canvas的大部分，并且不断巩固和固化这个Canvas，通过在所有数字生活中广泛应用。另一方面，基于两个实践案例，我们建议需要一种新的批判方法，该方法考虑模型和其应用之间的认知纠缠。这种新方法可以通过神经网络的训练数据和研究数据来读取 corpora，并且反之，研究数据和训练数据的视觉意识都会紧密相互纠缠。
</details></li>
</ul>
<hr>
<h2 id="U-Turn-Diffusion"><a href="#U-Turn-Diffusion" class="headerlink" title="U-Turn Diffusion"></a>U-Turn Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07421">http://arxiv.org/abs/2308.07421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamidreza Behjoo, Michael Chertkov</li>
<li>for: 这个论文探讨了基于人工智能的 diffusion 模型，用于生成合成图像。这些模型利用动态辅助时间机制，通过随机差分方程来获得分数函数。</li>
<li>methods: 该论文提出了一个效果评价标准：生成过程中快速谱 correlation 的破坏能力直接关系到生成图像质量。此外， authors 还提出了一种“U-Turn Diffusion”技术，通过将标准前向 diffusion 过程缩短，然后执行标准反向动力，最终生成一个与 i.i.d. 样本 Distribution 相似的合成图像。</li>
<li>results: 该论文通过使用不同的分析工具，如自相关分析、分数函数质量分析和高斯分布预测测试，来分析相关的时间尺度。结果表明，在优化 U-turn 时间后，生成的合成图像与实际数据样本之间的干扰距离最小化。<details>
<summary>Abstract</summary>
We present a comprehensive examination of score-based diffusion models of AI for generating synthetic images. These models hinge upon a dynamic auxiliary time mechanism driven by stochastic differential equations, wherein the score function is acquired from input images. Our investigation unveils a criterion for evaluating efficiency of the score-based diffusion models: the power of the generative process depends on the ability to de-construct fast correlations during the reverse/de-noising phase. To improve the quality of the produced synthetic images, we introduce an approach coined "U-Turn Diffusion". The U-Turn Diffusion technique starts with the standard forward diffusion process, albeit with a condensed duration compared to conventional settings. Subsequently, we execute the standard reverse dynamics, initialized with the concluding configuration from the forward process. This U-Turn Diffusion procedure, combining forward, U-turn, and reverse processes, creates a synthetic image approximating an independent and identically distributed (i.i.d.) sample from the probability distribution implicitly described via input samples. To analyze relevant time scales we employ various analytical tools, including auto-correlation analysis, weighted norm of the score-function analysis, and Kolmogorov-Smirnov Gaussianity test. The tools guide us to establishing that the Kernel Intersection Distance, a metric comparing the quality of synthetic samples with real data samples, is minimized at the optimal U-turn time.
</details>
<details>
<summary>摘要</summary>
我们提出了一项全面的检查Score-based扩散模型，用于生成 sintetic 图像。这些模型基于动态辅助时间机制驱动的随机差分方程，其中Score函数从输入图像中获得。我们的调查发现一个用于评估扩散模型效率的标准：扩散过程中快速相关性的破坏能力直接关系到生成过程的能效性。为了提高生成的 sintetic 图像质量，我们提出了“U-Turn扩散”技术。U-Turn扩散过程从标准前进Diffusion过程开始，但是压缩了传统设置中的时间。然后，我们执行标准的反动动态，初始化使用前进过程的结束配置。这种U-Turn扩散过程，包括前进、U-turn和反向过程，可以生成一个约束相同分布的 sintetic 图像，与输入样本的随机分布相对独立。为了分析相关的时间尺度，我们使用了多种分析工具，包括自相关分析、加重函数分析和高斯假设测试。这些工具引导我们确定了最佳U-turn时间，以使得扩散模型可以生成高质量的 sintetic 图像。
</details></li>
</ul>
<hr>
<h2 id="Semantify-Simplifying-the-Control-of-3D-Morphable-Models-using-CLIP"><a href="#Semantify-Simplifying-the-Control-of-3D-Morphable-Models-using-CLIP" class="headerlink" title="Semantify: Simplifying the Control of 3D Morphable Models using CLIP"></a>Semantify: Simplifying the Control of 3D Morphable Models using CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07415">http://arxiv.org/abs/2308.07415</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Omergral/Semantify">https://github.com/Omergral/Semantify</a></li>
<li>paper_authors: Omer Gralnik, Guy Gafni, Ariel Shamir</li>
<li>for: 用于自动控制3D形态模型</li>
<li>methods: 使用CLIP语言视觉基础模型的 semantic 力进行自我超vised 训练</li>
<li>results: 实现了定制3D形态模型的简单 slider  интерфей스，并可以快速地适应各种3D模型的定制。Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written for the purpose of simplifying the control of 3D morphable models, specifically using self-supervised learning and the semantic power of CLIP language-vision foundation models.</li>
<li>methods: The paper proposes a method called Semantify, which utilizes the semantic power of CLIP to learn a non-linear mapping from scores across a small set of semantically meaningful and disentangled descriptors to the parametric coefficients of a given 3D morphable model. This is done without a human-in-the-loop and using training data created by randomly sampling the model’s parameters, creating various shapes, and rendering them.</li>
<li>results: The paper presents results on numerous 3D morphable models, including body shape models, face shape and expression models, and animal shapes. The results show that the proposed method defines a simple slider interface for intuitive modeling and can be used to instantly fit a 3D parametric body shape to in-the-wild images.<details>
<summary>Abstract</summary>
We present Semantify: a self-supervised method that utilizes the semantic power of CLIP language-vision foundation model to simplify the control of 3D morphable models. Given a parametric model, training data is created by randomly sampling the model's parameters, creating various shapes and rendering them. The similarity between the output images and a set of word descriptors is calculated in CLIP's latent space. Our key idea is first to choose a small set of semantically meaningful and disentangled descriptors that characterize the 3DMM, and then learn a non-linear mapping from scores across this set to the parametric coefficients of the given 3DMM. The non-linear mapping is defined by training a neural network without a human-in-the-loop. We present results on numerous 3DMMs: body shape models, face shape and expression models, as well as animal shapes. We demonstrate how our method defines a simple slider interface for intuitive modeling, and show how the mapping can be used to instantly fit a 3D parametric body shape to in-the-wild images.
</details>
<details>
<summary>摘要</summary>
我们介绍Semantify：一种自动超级方法，利用CLIP语言视觉基础模型的 semantic 力来简化3D可变模型的控制。将 parametric 模型作为input，通过随机抽样模型参数，创建不同形状并rendering 它们。然后，使用CLIP的内存空间计算模型的出力图像和一组字幕描述的相似度。我们的关键想法是首先选择一小集 semantically meaningful 和分离的描述符，描述3DMM的特征，然后学习一个非线性的 mapping 将 scores across 这个集合转换为input 模型的参数。这个 mapping 是通过人工不在从事的方式定义的，我们提出了一个 neural network 的解释。我们在 numerous 3DMM 上进行了实验，包括人体形状模型、脸形和表情模型以及动物形状。我们显示了我们的方法可以定义一个简单的滑块界面，并说明了如何将 mapping 用于快速适应实验中的内部显示。最后，我们显示了我们的方法可以将3D parametric 体形快速适应到野外图像中。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Query-based-Paradigm-for-Camouflaged-Instance-Segmentation"><a href="#A-Unified-Query-based-Paradigm-for-Camouflaged-Instance-Segmentation" class="headerlink" title="A Unified Query-based Paradigm for Camouflaged Instance Segmentation"></a>A Unified Query-based Paradigm for Camouflaged Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07392">http://arxiv.org/abs/2308.07392</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dongbo811/uqformer">https://github.com/dongbo811/uqformer</a></li>
<li>paper_authors: Do Dong, Jialun Pei, Rongrong Gao, Tian-Zhu Xiang, Shuo Wang, Huan Xiong</li>
<li>for: 提高隐藏的实例分割精度</li>
<li>methods: 使用 query-based 多任务学习框架，包括设计多scales的 unified learning transformer decoder 和 composed query learning paradigm，以 capture 隐藏的对象区域和边界特征</li>
<li>results: 与 14 状态级方法进行比较，实现了隐藏实例分割的显著提高<details>
<summary>Abstract</summary>
Due to the high similarity between camouflaged instances and the background, the recently proposed camouflaged instance segmentation (CIS) faces challenges in accurate localization and instance segmentation. To this end, inspired by query-based transformers, we propose a unified query-based multi-task learning framework for camouflaged instance segmentation, termed UQFormer, which builds a set of mask queries and a set of boundary queries to learn a shared composed query representation and efficiently integrates global camouflaged object region and boundary cues, for simultaneous instance segmentation and instance boundary detection in camouflaged scenarios. Specifically, we design a composed query learning paradigm that learns a shared representation to capture object region and boundary features by the cross-attention interaction of mask queries and boundary queries in the designed multi-scale unified learning transformer decoder. Then, we present a transformer-based multi-task learning framework for simultaneous camouflaged instance segmentation and camouflaged instance boundary detection based on the learned composed query representation, which also forces the model to learn a strong instance-level query representation. Notably, our model views the instance segmentation as a query-based direct set prediction problem, without other post-processing such as non-maximal suppression. Compared with 14 state-of-the-art approaches, our UQFormer significantly improves the performance of camouflaged instance segmentation. Our code will be available at https://github.com/dongbo811/UQFormer.
</details>
<details>
<summary>摘要</summary>
due to the high similarity between camouflaged instances and the background, the recently proposed camouflaged instance segmentation (CIS) faces challenges in accurate localization and instance segmentation. to this end, inspired by query-based transformers, we propose a unified query-based multi-task learning framework for camouflaged instance segmentation, termed UQFormer, which builds a set of mask queries and a set of boundary queries to learn a shared composed query representation and efficiently integrates global camouflaged object region and boundary cues, for simultaneous instance segmentation and instance boundary detection in camouflaged scenarios. specifically, we design a composed query learning paradigm that learns a shared representation to capture object region and boundary features by the cross-attention interaction of mask queries and boundary queries in the designed multi-scale unified learning transformer decoder. then, we present a transformer-based multi-task learning framework for simultaneous camouflaged instance segmentation and camouflaged instance boundary detection based on the learned composed query representation, which also forces the model to learn a strong instance-level query representation. notably, our model views the instance segmentation as a query-based direct set prediction problem, without other post-processing such as non-maximal suppression. compared with 14 state-of-the-art approaches, our UQFormer significantly improves the performance of camouflaged instance segmentation. our code will be available at https://github.com/dongbo811/UQFormer.Here's the word-for-word translation of the text into Simplified Chinese:由于隐形实例和背景的高相似性，最近提出的隐形实例分割（CIS）面临精度地位和实例分割挑战。为此，我们取得了 query-based transformers 的灵感，并提出了一种统一的 query-based 多任务学习框架，称为 UQFormer，该框架在隐形场景中同时进行实例分割和实例边界检测。specifically，我们设计了一种组合查询学习方案，通过 маска查询和边界查询的交互跨度束对象区域和边界特征进行学习共享的查询表示。然后，我们提出了一种基于 transformer 的多任务学习框架，通过学习共享的查询表示来同时进行隐形实例分割和隐形实例边界检测。此外，我们的模型视实例分割为直接查询集prediction问题，不需要其他后处理如非最大suppression。与14种状态级方法进行比较，我们的 UQFormer 显著提高了隐形实例分割的性能。我们的代码将在 https://github.com/dongbo811/UQFormer 上发布。
</details></li>
</ul>
<hr>
<h2 id="DISBELIEVE-Distance-Between-Client-Models-is-Very-Essential-for-Effective-Local-Model-Poisoning-Attacks"><a href="#DISBELIEVE-Distance-Between-Client-Models-is-Very-Essential-for-Effective-Local-Model-Poisoning-Attacks" class="headerlink" title="DISBELIEVE: Distance Between Client Models is Very Essential for Effective Local Model Poisoning Attacks"></a>DISBELIEVE: Distance Between Client Models is Very Essential for Effective Local Model Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07387">http://arxiv.org/abs/2308.07387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indu Joshi, Priyank Upadhya, Gaurav Kumar Nayak, Peter Schüffler, Nassir Navab</li>
<li>for: This paper focuses on the privacy issues in federated learning, specifically in the medical image analysis domain, and proposes a local model poisoning attack called DISBELIEVE to defend against robust aggregation methods.</li>
<li>methods: The proposed DISBELIEVE attack creates malicious parameters or gradients that are close to benign clients’ parameters or gradients but have a high adverse effect on the global model’s performance.</li>
<li>results: The proposed attack significantly lowers the performance of state-of-the-art robust aggregation methods for medical image analysis on three publicly available datasets, and is also effective on natural images for multi-class classification on the benchmark dataset CIFAR-10.Here’s the full Chinese translation of the paper’s abstract:for: 这篇论文关注联合学习中的隐私问题，具体是医疗图像分析领域，并提出了一种本地模型毒品攻击方法called DISBELIEVE，以防止robust集成方法。methods: DISBELIEVE攻击方法创造了假的参数或梯度，使其与正常客户端的参数或梯度很近，但是对全局模型的性能产生高度的负面影响。results: 提议的攻击方法对state-of-the-art robust集成方法在三个公开的医疗图像数据集上显示出了显著的下降性能，并且在自然图像的多类分类任务上也有严重的下降性能。<details>
<summary>Abstract</summary>
Federated learning is a promising direction to tackle the privacy issues related to sharing patients' sensitive data. Often, federated systems in the medical image analysis domain assume that the participating local clients are \textit{honest}. Several studies report mechanisms through which a set of malicious clients can be introduced that can poison the federated setup, hampering the performance of the global model. To overcome this, robust aggregation methods have been proposed that defend against those attacks. We observe that most of the state-of-the-art robust aggregation methods are heavily dependent on the distance between the parameters or gradients of malicious clients and benign clients, which makes them prone to local model poisoning attacks when the parameters or gradients of malicious and benign clients are close. Leveraging this, we introduce DISBELIEVE, a local model poisoning attack that creates malicious parameters or gradients such that their distance to benign clients' parameters or gradients is low respectively but at the same time their adverse effect on the global model's performance is high. Experiments on three publicly available medical image datasets demonstrate the efficacy of the proposed DISBELIEVE attack as it significantly lowers the performance of the state-of-the-art \textit{robust aggregation} methods for medical image analysis. Furthermore, compared to state-of-the-art local model poisoning attacks, DISBELIEVE attack is also effective on natural images where we observe a severe drop in classification performance of the global model for multi-class classification on benchmark dataset CIFAR-10.
</details>
<details>
<summary>摘要</summary>
“联邦学习”是一种解决医疗资料共享时隐私问题的可能性。在医疗影像分析领域中，联邦系统通常假设地方客户端是“正直”的。然而，一些研究发现，可以将一组黑客户端引入联邦系统，导致全球模型的性能下降。为了解决这个问题，一些防护整合方法被提出，但大多数这些方法对于黑客户端的攻击 remain vulnerable。我们引入了一种名为“DISBELIEVE”的本地模型欺骗攻击，它可以创造出黑客户端的参数或梯度，使其与正常客户端的参数或梯度之间的距离很近，但同时对全球模型的性能产生严重的影响。我们在三个公开可用的医疗影像数据集上进行实验，结果显示 DISBELIEVE 攻击可以对现有的robust aggregation方法进行严重攻击，并且与其他本地模型欺骗攻击相比，DISBELIEVE 攻击在自然图像中也有很好的效果。
</details></li>
</ul>
<hr>
<h2 id="The-Devil-in-the-Details-Simple-and-Effective-Optical-Flow-Synthetic-Data-Generation"><a href="#The-Devil-in-the-Details-Simple-and-Effective-Optical-Flow-Synthetic-Data-Generation" class="headerlink" title="The Devil in the Details: Simple and Effective Optical Flow Synthetic Data Generation"></a>The Devil in the Details: Simple and Effective Optical Flow Synthetic Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07378">http://arxiv.org/abs/2308.07378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kwon Byung-Ki, Kim Sung-Bin, Tae-Hyun Oh</li>
<li>for: 这 paper 是为了研究 dense optical flow 的进展而写的，特别是使用 supervised learning 方法，需要大量标注数据。</li>
<li>methods: 这 paper 使用了一种 simpler synthetic data generation method，通过组合基本操作来实现一定的真实感。 authors 还提出了一种使用 occlusion masks 的新方法，以帮助 RAFT 网络在 supervised 方法中进行更好的初始化。</li>
<li>results: 据 authors 的实验结果，使用这种新方法可以让 RAFT 网络在 MPI Sintel 和 KITTI 2015 上表现出色，超过原始 RAFT 的表现。<details>
<summary>Abstract</summary>
Recent work on dense optical flow has shown significant progress, primarily in a supervised learning manner requiring a large amount of labeled data. Due to the expensiveness of obtaining large scale real-world data, computer graphics are typically leveraged for constructing datasets. However, there is a common belief that synthetic-to-real domain gaps limit generalization to real scenes. In this paper, we show that the required characteristics in an optical flow dataset are rather simple and present a simpler synthetic data generation method that achieves a certain level of realism with compositions of elementary operations. With 2D motion-based datasets, we systematically analyze the simplest yet critical factors for generating synthetic datasets. Furthermore, we propose a novel method of utilizing occlusion masks in a supervised method and observe that suppressing gradients on occluded regions serves as a powerful initial state in the curriculum learning sense. The RAFT network initially trained on our dataset outperforms the original RAFT on the two most challenging online benchmarks, MPI Sintel and KITTI 2015.
</details>
<details>
<summary>摘要</summary>
最近的紧密光流研究已经取得了重要进步，主要是以监督学习方式进行，需要大量标注数据。由于真实世界数据的获得成本较高，因此通常会利用计算机图形进行数据构造。然而，有一种常见的信念是， sintetic-to-real 领域差限制了对真实场景的泛化。在这篇论文中，我们表明了光流数据集中所需的特征很简单，并提出了一种简单的 sintetic 数据生成方法，该方法可以在元素操作的组合下实现一定的真实感。对于 2D 运动基于的数据集，我们系统地分析了生成 sintetic 数据的最简 yet critical 因素。此外，我们提议了在监督学习方法中使用遮盲mask，并观察到在遮盲区域上抑制梯度 serve as a powerful initial state in the curriculum learning sense。RAFT 网络首先在我们的数据集上进行了训练，然后在两个最为挑战的在线抽象上出色表现，即 MPI Sintel 和 KITTI 2015。
</details></li>
</ul>
<hr>
<h2 id="Jurassic-World-Remake-Bringing-Ancient-Fossils-Back-to-Life-via-Zero-Shot-Long-Image-to-Image-Translation"><a href="#Jurassic-World-Remake-Bringing-Ancient-Fossils-Back-to-Life-via-Zero-Shot-Long-Image-to-Image-Translation" class="headerlink" title="Jurassic World Remake: Bringing Ancient Fossils Back to Life via Zero-Shot Long Image-to-Image Translation"></a>Jurassic World Remake: Bringing Ancient Fossils Back to Life via Zero-Shot Long Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07316">http://arxiv.org/abs/2308.07316</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexmartin1722/Revive-2I">https://github.com/alexmartin1722/Revive-2I</a></li>
<li>paper_authors: Alexander Martin, Haitian Zheng, Jie An, Jiebo Luo</li>
<li>for: 这个论文的目的是提出一种可以在大领域差距下进行零shot图像到图像翻译（I2I）的方法，并且能够在不同领域中进行应用。</li>
<li>methods: 这个论文使用了文本引导的潜在扩散模型来实现零shot I2I，并且提出了一个新的任务——Skull2Animal，用于翻译骨骼和生物体之间。</li>
<li>results: 研究发现，传统的I2I方法无法跨大领域差距进行翻译，而文本引导的扩散和图像编辑模型则能够准确地完成零shot I2I。此外，研究还发现，提示是跨大领域差距翻译的关键因素，因为需要将目标领域的优先知识传递给模型。<details>
<summary>Abstract</summary>
With a strong understanding of the target domain from natural language, we produce promising results in translating across large domain gaps and bringing skeletons back to life. In this work, we use text-guided latent diffusion models for zero-shot image-to-image translation (I2I) across large domain gaps (longI2I), where large amounts of new visual features and new geometry need to be generated to enter the target domain. Being able to perform translations across large domain gaps has a wide variety of real-world applications in criminology, astrology, environmental conservation, and paleontology. In this work, we introduce a new task Skull2Animal for translating between skulls and living animals. On this task, we find that unguided Generative Adversarial Networks (GANs) are not capable of translating across large domain gaps. Instead of these traditional I2I methods, we explore the use of guided diffusion and image editing models and provide a new benchmark model, Revive-2I, capable of performing zero-shot I2I via text-prompting latent diffusion models. We find that guidance is necessary for longI2I because, to bridge the large domain gap, prior knowledge about the target domain is needed. In addition, we find that prompting provides the best and most scalable information about the target domain as classifier-guided diffusion models require retraining for specific use cases and lack stronger constraints on the target domain because of the wide variety of images they are trained on.
</details>
<details>
<summary>摘要</summary>
With a strong understanding of the target domain from natural language, we produce promising results in translating across large domain gaps and bringing skeletons back to life. In this work, we use text-guided latent diffusion models for zero-shot image-to-image translation (I2I) across large domain gaps (longI2I), where large amounts of new visual features and new geometry need to be generated to enter the target domain. Being able to perform translations across large domain gaps has a wide variety of real-world applications in criminology, astrology, environmental conservation, and paleontology. In this work, we introduce a new task Skull2Animal for translating between skulls and living animals. On this task, we find that unguided Generative Adversarial Networks (GANs) are not capable of translating across large domain gaps. Instead of these traditional I2I methods, we explore the use of guided diffusion and image editing models and provide a new benchmark model, Revive-2I, capable of performing zero-shot I2I via text-prompting latent diffusion models. We find that guidance is necessary for longI2I because, to bridge the large domain gap, prior knowledge about the target domain is needed. In addition, we find that prompting provides the best and most scalable information about the target domain as classifier-guided diffusion models require retraining for specific use cases and lack stronger constraints on the target domain because of the wide variety of images they are trained on.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Hong Kong, Macau, and Taiwan. The translation is written in Simplified Chinese, but the original text is in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Dual-Associated-Encoder-for-Face-Restoration"><a href="#Dual-Associated-Encoder-for-Face-Restoration" class="headerlink" title="Dual Associated Encoder for Face Restoration"></a>Dual Associated Encoder for Face Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07314">http://arxiv.org/abs/2308.07314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Ju Tsai, Yu-Lun Liu, Lu Qi, Kelvin C. K. Chan, Ming-Hsuan Yang</li>
<li>for: 提高低质量图像中的人脸细节 restored</li>
<li>methods: 使用双支持分支框架DAEFR，其中一支支持高质量图像（HQ）特征提取，另一支支持低质量图像（LQ）特征提取，并通过相互协同训练来促进代码预测和输出质量提高</li>
<li>results: 在 synthetic 和 real-world 数据集上，DAEFR 表现出色，可以更好地恢复人脸细节<details>
<summary>Abstract</summary>
Restoring facial details from low-quality (LQ) images has remained a challenging problem due to its ill-posedness induced by various degradations in the wild. The existing codebook prior mitigates the ill-posedness by leveraging an autoencoder and learned codebook of high-quality (HQ) features, achieving remarkable quality. However, existing approaches in this paradigm frequently depend on a single encoder pre-trained on HQ data for restoring HQ images, disregarding the domain gap between LQ and HQ images. As a result, the encoding of LQ inputs may be insufficient, resulting in suboptimal performance. To tackle this problem, we propose a novel dual-branch framework named DAEFR. Our method introduces an auxiliary LQ branch that extracts crucial information from the LQ inputs. Additionally, we incorporate association training to promote effective synergy between the two branches, enhancing code prediction and output quality. We evaluate the effectiveness of DAEFR on both synthetic and real-world datasets, demonstrating its superior performance in restoring facial details.
</details>
<details>
<summary>摘要</summary>
优化 facial details 从低质量（LQ）图像的恢复问题一直是一个挑战，因为这个问题受到野外环境中各种破坏的影响，导致非固定的问题。现有的代码库先验 Mitigates 这个问题，通过使用 autoencoder 和学习的高质量（HQ）特征 codebook，实现了 Remarkable 的质量。然而，现有的这些方法 часто依赖于单个 encoder 预训练在 HQ 数据上，忽视 LQ 和 HQ 图像之间的领域差异。这导致 LQ 输入的编码可能不够，从而导致优化性不足。为解决这个问题，我们提出了一种新的 dual-branch 框架，名为 DAEFR。我们的方法在 auxiliary LQ 分支中提取了关键信息，并将这些信息与主要 HQ 分支相关联，以便在编码和输出质量之间产生有利的共同作用。我们在 synthetic 和实际世界的数据集上评估了 DAEFR 的效果，并证明其在恢复 facial details 方面具有 Superior 的性能。
</details></li>
</ul>
<hr>
<h2 id="Group-Pose-A-Simple-Baseline-for-End-to-End-Multi-person-Pose-Estimation"><a href="#Group-Pose-A-Simple-Baseline-for-End-to-End-Multi-person-Pose-Estimation" class="headerlink" title="Group Pose: A Simple Baseline for End-to-End Multi-person Pose Estimation"></a>Group Pose: A Simple Baseline for End-to-End Multi-person Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07313">http://arxiv.org/abs/2308.07313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/michel-liu/grouppose-paddle">https://github.com/michel-liu/grouppose-paddle</a></li>
<li>paper_authors: Huan Liu, Qiang Chen, Zichang Tan, Jiang-Jiang Liu, Jian Wang, Xiangbo Su, Xiaolong Li, Kun Yao, Junyu Han, Errui Ding, Yao Zhao, Jingdong Wang</li>
<li>For: 这种论文的目的是研究终端多人姿态估计问题，以DETR-like框架为基础，并主要发展复杂的解码器。* Methods: 这种方法使用了简单 yet effective transformerapproach，名为Group Pose。它将 $K$-keypoint pose estimation视为预测 $N\times K$ 关键点位置，每个关键点从一个关键点查询中预测，同时每个姿态被表示为一个实例查询用于得分 $N$ 姿态预测。* Results: 这种方法无需人工框架监督，在 MS COCO 和 CrowdPose 上实验表明，其表现比前一些使用复杂解码器的方法更好，甚至与使用人工框架监督的 ED-Pose 相当。可以在 $\href{<a target="_blank" rel="noopener" href="https://github.com/Michel-liu/GroupPose-Paddle%7D%7B/rm">https://github.com/Michel-liu/GroupPose-Paddle}{\rm</a> Paddle}$ 和 $\href{<a target="_blank" rel="noopener" href="https://github.com/Michel-liu/GroupPose%7D%7B/rm">https://github.com/Michel-liu/GroupPose}{\rm</a> PyTorch}$ 中找到代码。<details>
<summary>Abstract</summary>
In this paper, we study the problem of end-to-end multi-person pose estimation. State-of-the-art solutions adopt the DETR-like framework, and mainly develop the complex decoder, e.g., regarding pose estimation as keypoint box detection and combining with human detection in ED-Pose, hierarchically predicting with pose decoder and joint (keypoint) decoder in PETR. We present a simple yet effective transformer approach, named Group Pose. We simply regard $K$-keypoint pose estimation as predicting a set of $N\times K$ keypoint positions, each from a keypoint query, as well as representing each pose with an instance query for scoring $N$ pose predictions. Motivated by the intuition that the interaction, among across-instance queries of different types, is not directly helpful, we make a simple modification to decoder self-attention. We replace single self-attention over all the $N\times(K+1)$ queries with two subsequent group self-attentions: (i) $N$ within-instance self-attention, with each over $K$ keypoint queries and one instance query, and (ii) $(K+1)$ same-type across-instance self-attention, each over $N$ queries of the same type. The resulting decoder removes the interaction among across-instance type-different queries, easing the optimization and thus improving the performance. Experimental results on MS COCO and CrowdPose show that our approach without human box supervision is superior to previous methods with complex decoders, and even is slightly better than ED-Pose that uses human box supervision. $\href{https://github.com/Michel-liu/GroupPose-Paddle}{\rm Paddle}$ and $\href{https://github.com/Michel-liu/GroupPose}{\rm PyTorch}$ code are available.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了端到端多人姿态估计问题。现有的解决方案大多采用DETR-like框架，主要是开发复杂的解码器，例如将姿态估计视为关键点框检测并与人体检测结合在ED-Pose中，或者在PETR中 hierarchically 预测姿态和关键点。我们提出了一种简单 yet 有效的 transformer 方法，名为 Group Pose。我们简单地认为 $K$-关键点姿态估计是预测 $N\times K$ 关键点位置，每个从关键点查询中预测，同时每个姿态被 Represented 为一个实例查询用于得分 $N$ 姿态预测。我们受到了关键点查询之间相互交互不直接有助于的想法，因此我们对解码器自注意的进行了简单修改。我们将单个自注意所有 $N\times(K+1)$ 查询被替换为两个顺序的组自注意：（i） $N$ 内部实例自注意，每个在 $K$ 关键点查询和一个实例查询之间进行自注意，和（ii） $(K+1)$ 同类 across-instance 自注意，每个在 $N$ 查询之间进行自注意。这些修改后的解码器可以减少不同类型的关键点查询之间的交互，从而简化优化，并提高性能。我们在 COCO 和 CrowdPose 上进行了实验，发现我们的方法无需人工盒子超级视觉是与前一代方法相比提高性能，甚至与使用人工盒子超级视觉的 ED-Pose 相比略有提高。我们在 $\href{https://github.com/Michel-liu/GroupPose-Paddle}{\rm Paddle}$ 和 $\href{https://github.com/Michel-liu/GroupPose}{\rm PyTorch}$ 上提供了代码。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Masked-Autoencoder-with-Patchified-Skeletons-for-Motion-Synthesis"><a href="#A-Unified-Masked-Autoencoder-with-Patchified-Skeletons-for-Motion-Synthesis" class="headerlink" title="A Unified Masked Autoencoder with Patchified Skeletons for Motion Synthesis"></a>A Unified Masked Autoencoder with Patchified Skeletons for Motion Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07301">http://arxiv.org/abs/2308.07301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Esteve Valls Mascaro, Hyemin Ahn, Dongheui Lee</li>
<li>for: 这个论文的目的是提出一种新的任务无关的人体动作生成模型，即UNIMASK-M，可以有效地解决人体动作预测和填充中间姿势等问题。</li>
<li>methods: 这个模型使用了着重体部关系的架构，以及基于ViTs的人体姿势分解方法，以利用人体动作中的空间时间关系。此外，该模型还通过不同的面罩设计来进行姿势conditioned的动作生成。</li>
<li>results: 实验结果表明，UNIMASK-M模型在Human3.6M数据集上成功预测人体动作，并在LaFAN1数据集上实现了状态之最的动作填充结果，特别是在长距离转换期。更多信息可以查看项目官方网站：<a target="_blank" rel="noopener" href="https://sites.google.com/view/estevevallsmascaro/publications/unimask-m%E3%80%82">https://sites.google.com/view/estevevallsmascaro/publications/unimask-m。</a><details>
<summary>Abstract</summary>
The synthesis of human motion has traditionally been addressed through task-dependent models that focus on specific challenges, such as predicting future motions or filling in intermediate poses conditioned on known key-poses. In this paper, we present a novel task-independent model called UNIMASK-M, which can effectively address these challenges using a unified architecture. Our model obtains comparable or better performance than the state-of-the-art in each field. Inspired by Vision Transformers (ViTs), our UNIMASK-M model decomposes a human pose into body parts to leverage the spatio-temporal relationships existing in human motion. Moreover, we reformulate various pose-conditioned motion synthesis tasks as a reconstruction problem with different masking patterns given as input. By explicitly informing our model about the masked joints, our UNIMASK-M becomes more robust to occlusions. Experimental results show that our model successfully forecasts human motion on the Human3.6M dataset. Moreover, it achieves state-of-the-art results in motion inbetweening on the LaFAN1 dataset, particularly in long transition periods. More information can be found on the project website https://sites.google.com/view/estevevallsmascaro/publications/unimask-m.
</details>
<details>
<summary>摘要</summary>
历史上人体运动的合成总是通过任务 dependent 模型来解决，这些模型通常会专注于特定的挑战，例如预测未来运动或者使用知道的关键姿势来填充中间姿势。在这篇论文中，我们提出了一种新的任务独立的模型，即 UNIMASK-M，它可以有效地解决这些挑战。我们的模型在每个领域中都可以达到或更好的性能。我们的 UNIMASK-M 模型从人体 pose 中提取了身体部分，以利用人体运动中的空间时间关系。此外，我们将各种姿势conditioned 的运动合成任务重新表述为一个重建问题，输入不同的面纱模式。通过直接告诉我们模型关于遮盖的关节的信息，我们的 UNIMASK-M 模型变得更加鲁棒，更能够抵御遮挡。实验结果表明，我们的模型在 Human3.6M 数据集上预测人体运动成功。此外，它在 LaFAN1 数据集上的动作填充任务中达到了领先的成绩，特别是在长期跨过渡期内。更多信息可以在项目网站（https://sites.google.com/view/estevevallsmascaro/publications/unimask-m）上找到。
</details></li>
</ul>
<hr>
<h2 id="Accurate-Eye-Tracking-from-Dense-3D-Surface-Reconstructions-using-Single-Shot-Deflectometry"><a href="#Accurate-Eye-Tracking-from-Dense-3D-Surface-Reconstructions-using-Single-Shot-Deflectometry" class="headerlink" title="Accurate Eye Tracking from Dense 3D Surface Reconstructions using Single-Shot Deflectometry"></a>Accurate Eye Tracking from Dense 3D Surface Reconstructions using Single-Shot Deflectometry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07298">http://arxiv.org/abs/2308.07298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazhang Wang, Tianfu Wang, Bingjie Xu, Oliver Cossairt, Florian Willomitzer</li>
<li>for: 提高虚拟现实设备、神经科学研究和心理学中的眼动跟踪精度和速度。</li>
<li>methods: 基于单shotphasemeasuring-deflectometry（PMD）的新方法，通过获取肤色镜面上的密集3D表面信息来提高眼动跟踪精度和速度。</li>
<li>results: 实验表明，该方法可以实现眼动跟踪精度低于0.25度，至少比现有技术高出了$&gt;3300\times$。<details>
<summary>Abstract</summary>
Eye-tracking plays a crucial role in the development of virtual reality devices, neuroscience research, and psychology. Despite its significance in numerous applications, achieving an accurate, robust, and fast eye-tracking solution remains a considerable challenge for current state-of-the-art methods. While existing reflection-based techniques (e.g., "glint tracking") are considered the most accurate, their performance is limited by their reliance on sparse 3D surface data acquired solely from the cornea surface. In this paper, we rethink the way how specular reflections can be used for eye tracking: We propose a novel method for accurate and fast evaluation of the gaze direction that exploits teachings from single-shot phase-measuring-deflectometry (PMD). In contrast to state-of-the-art reflection-based methods, our method acquires dense 3D surface information of both cornea and sclera within only one single camera frame (single-shot). Improvements in acquired reflection surface points("glints") of factors $>3300 \times$ are easily achievable. We show the feasibility of our approach with experimentally evaluated gaze errors of only $\leq 0.25^\circ$ demonstrating a significant improvement over the current state-of-the-art.
</details>
<details>
<summary>摘要</summary>
眼动跟踪在虚拟现实设备的开发、 neuroscience 研究和心理学中扮演着关键性的角色。尽管它在多个应用程序中具有重要的作用，但是实现高度准确、可靠和快速的眼动跟踪解决方案仍然是当前技术的主要挑战。现有的反射基本技术（如“光泽跟踪”）被认为是最准确的，但它们的性能受到仅仅凭借硬件表面的辐射数据的限制。在这篇论文中，我们重新思考了如何使用折射来跟踪眼动：我们提出了一种新的方法，可以准确地和快速地评估眼动方向，这种方法利用了单 shot 相位测量折射（PMD）的教程。与现有的反射基本技术不同，我们的方法可以在单个摄像头帧中获得硬件表面的密集3D数据，包括辐射表面点的增加。我们实验证明，我们的方法可以在辐射表面点的增加比例上提高了$>3300\times$，并且我们实验证明了我们的方法的可行性，误差仅为$\leq 0.25^\circ$，这表明了我们的方法与当前技术的显著提高。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Approach-Towards-Distinguishing-Natural-and-Computer-Generated-Images-using-Multi-Colorspace-fused-and-Enriched-Vision-Transformer"><a href="#A-Robust-Approach-Towards-Distinguishing-Natural-and-Computer-Generated-Images-using-Multi-Colorspace-fused-and-Enriched-Vision-Transformer" class="headerlink" title="A Robust Approach Towards Distinguishing Natural and Computer Generated Images using Multi-Colorspace fused and Enriched Vision Transformer"></a>A Robust Approach Towards Distinguishing Natural and Computer Generated Images using Multi-Colorspace fused and Enriched Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07279">http://arxiv.org/abs/2308.07279</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manjaryp/mce-vit">https://github.com/manjaryp/mce-vit</a></li>
<li>paper_authors: Manjary P Gangan, Anoop Kadan, Lajish V L</li>
<li>for: 能够分辨 natura 和计算机生成的图像</li>
<li>methods: 使用两个视Transformers进行拟合，一个在 RGB 色域，另一个在 YCbCr 色域，并将两个拟合结果进行拟合</li>
<li>results: 提高了对计算机生成图像和 GAN 生成图像的分辨率，以及提高了对压缩、噪音等后处理图像的Robustness和普适性<details>
<summary>Abstract</summary>
The works in literature classifying natural and computer generated images are mostly designed as binary tasks either considering natural images versus computer graphics images only or natural images versus GAN generated images only, but not natural images versus both classes of the generated images. Also, even though this forensic classification task of distinguishing natural and computer generated images gets the support of the new convolutional neural networks and transformer based architectures that can give remarkable classification accuracies, they are seen to fail over the images that have undergone some post-processing operations usually performed to deceive the forensic algorithms, such as JPEG compression, gaussian noise, etc. This work proposes a robust approach towards distinguishing natural and computer generated images including both, computer graphics and GAN generated images using a fusion of two vision transformers where each of the transformer networks operates in different color spaces, one in RGB and the other in YCbCr color space. The proposed approach achieves high performance gain when compared to a set of baselines, and also achieves higher robustness and generalizability than the baselines. The features of the proposed model when visualized are seen to obtain higher separability for the classes than the input image features and the baseline features. This work also studies the attention map visualizations of the networks of the fused model and observes that the proposed methodology can capture more image information relevant to the forensic task of classifying natural and generated images.
</details>
<details>
<summary>摘要</summary>
文学类别自然和计算机生成的图像工作大都设计为二分类任务， Either considering natural images versus computer graphics images only or natural images versus GAN generated images only，但不是natural images versus both classes of generated images。 尽管这种审查类别任务可以通过新的 convolutional neural networks 和 transformer 基础架构得到惊人的分类精度，但它们在图像经过一些预处理操作后，如 JPEG 压缩、 Gaussian noise 等，会失败。 这个工作提议一种可靠的方法，用于分类自然和计算机生成的图像，包括计算机图形和 GAN 生成的图像，使用两个视transformer 网络，其中一个在 RGB 色空间中运行，另一个在 YCbCr 色空间中运行。 提议的方法在比较基eline 的情况下， achieve 高性能增加，同时也 achieve 更高的可靠性和普遍性。 图像特征视觉化时，可以看到提议的模型对类别之间的分离性更高，than the input image features 和基eline 的特征。 此外，研究提议的模型网络的注意力地图时，发现该方法可以更好地捕捉与审查任务相关的图像信息。
</details></li>
</ul>
<hr>
<h2 id="Diving-with-Penguins-Detecting-Penguins-and-their-Prey-in-Animal-borne-Underwater-Videos-via-Deep-Learning"><a href="#Diving-with-Penguins-Detecting-Penguins-and-their-Prey-in-Animal-borne-Underwater-Videos-via-Deep-Learning" class="headerlink" title="Diving with Penguins: Detecting Penguins and their Prey in Animal-borne Underwater Videos via Deep Learning"></a>Diving with Penguins: Detecting Penguins and their Prey in Animal-borne Underwater Videos via Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07267">http://arxiv.org/abs/2308.07267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kejia Zhang, Mingyu Yang, Stephen D. J. Lang, Alistair M. McInnes, Richard B. Sherley, Tilo Burghardt</li>
<li>for: 这个论文的目的是提供一个可靠的海水下enguin检测器，以及一个鱼类检测器，并对enguin的捕食行为进行自动识别。</li>
<li>methods: 这个论文使用了现代生物学logging技术，并使用了深度学习系统来检测enguin和鱼类。</li>
<li>results: 这个论文提供了一个高度可靠的海水下enguin检测器，并对enguin的捕食行为进行了自动识别。但是，进一步的工作是必要的以使这种技术在实际场景中有用。<details>
<summary>Abstract</summary>
African penguins (Spheniscus demersus) are an endangered species. Little is known regarding their underwater hunting strategies and associated predation success rates, yet this is essential for guiding conservation. Modern bio-logging technology has the potential to provide valuable insights, but manually analysing large amounts of data from animal-borne video recorders (AVRs) is time-consuming. In this paper, we publish an animal-borne underwater video dataset of penguins and introduce a ready-to-deploy deep learning system capable of robustly detecting penguins (mAP50@98.0%) and also instances of fish (mAP50@73.3%). We note that the detectors benefit explicitly from air-bubble learning to improve accuracy. Extending this detector towards a dual-stream behaviour recognition network, we also provide the first results for identifying predation behaviour in penguin underwater videos. Whilst results are promising, further work is required for useful applicability of predation behaviour detection in field scenarios. In summary, we provide a highly reliable underwater penguin detector, a fish detector, and a valuable first attempt towards an automated visual detection of complex behaviours in a marine predator. We publish the networks, the DivingWithPenguins video dataset, annotations, splits, and weights for full reproducibility and immediate usability by practitioners.
</details>
<details>
<summary>摘要</summary>
非洲伯劳鸟（Spheniscus demersus）是一种濒临灭绝的物种。关于它们在水下猎食策略和相关的捕食成功率的知识很少，但这些信息对保护非常重要。现代生物 logging技术有potential提供有价值的洞察，但是手动分析动物携带视频记录器（AVR）上的大量数据非常时间consuming。在这篇论文中，我们发布了一个动物携带的水下视频数据集和一个准备就绪的深度学习系统，能够准确地检测伯劳鸟（mAP50@98.0%）和鱼雷（mAP50@73.3%）。我们发现检测器受到空气泡学习的帮助，以提高准确性。通过扩展这个检测器，我们还提供了第一次在水下伯劳鸟视频中自动识别捕食行为的结果。虽然结果有前途，但更多的工作是需要在实际场景中使用捕食行为检测。总之，我们提供了一个非常可靠的水下伯劳鸟检测器、鱼雷检测器和水下伯劳鸟视频中自动识别复杂行为的第一次尝试。我们发布了网络、DivingWithPenguins视频数据集、注释、分割和 weights，以便实现全 reproduceability和 immediate usability by practitioners。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Real-time-Smoke-Filtration-with-3D-LiDAR-for-Search-and-Rescue-with-Autonomous-Heterogeneous-Robotic-Systems"><a href="#Efficient-Real-time-Smoke-Filtration-with-3D-LiDAR-for-Search-and-Rescue-with-Autonomous-Heterogeneous-Robotic-Systems" class="headerlink" title="Efficient Real-time Smoke Filtration with 3D LiDAR for Search and Rescue with Autonomous Heterogeneous Robotic Systems"></a>Efficient Real-time Smoke Filtration with 3D LiDAR for Search and Rescue with Autonomous Heterogeneous Robotic Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07264">http://arxiv.org/abs/2308.07264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Kyuroson, Anton Koval, George Nikolakopoulos</li>
<li>for: 提高机器人在具有烟尘的潜地环境中的自主导航和定位精度。</li>
<li>methods: 提出了一种模块化agnostic滤除管道，利用照度和空间信息进行烟尘排除，以提高点云检测的精度。</li>
<li>results: 对多个前沿探索任务进行了实验研究，并提供了对比其他方法的计算影响和安全自主导航的价值观。<details>
<summary>Abstract</summary>
Search and Rescue (SAR) missions in harsh and unstructured Sub-Terranean (Sub-T) environments in the presence of aerosol particles have recently become the main focus in the field of robotics. Aerosol particles such as smoke and dust directly affect the performance of any mobile robotic platform due to their reliance on their onboard perception systems for autonomous navigation and localization in Global Navigation Satellite System (GNSS)-denied environments. Although obstacle avoidance and object detection algorithms are robust to the presence of noise to some degree, their performance directly relies on the quality of captured data by onboard sensors such as Light Detection And Ranging (LiDAR) and camera. Thus, this paper proposes a novel modular agnostic filtration pipeline based on intensity and spatial information such as local point density for removal of detected smoke particles from Point Cloud (PCL) prior to its utilization for collision detection. Furthermore, the efficacy of the proposed framework in the presence of smoke during multiple frontier exploration missions is investigated while the experimental results are presented to facilitate comparison with other methodologies and their computational impact. This provides valuable insight to the research community for better utilization of filtration schemes based on available computation resources while considering the safe autonomous navigation of mobile robots.
</details>
<details>
<summary>摘要</summary>
寻找和救援（SAR）任务在恶劣和无结构的地壳环境中变得越来越重要，特别是在Global Navigation Satellite System（GNSS）被排除的环境中。由于移动 робот平台的自主导航和地点化依赖于其 бордов的感知系统，因此尘埃和烟雾直接影响移动 робот的性能。虽然障碍物避免和物体探测算法有一定的鲁棒性，但它们的性能直接取决于捕获到的数据质量，例如雷达和摄像头的数据。因此，这篇论文提出了一种新的模块不可识别的筛选管道，基于照度和空间信息，如地点密度，以去除从点云（PCL）中探测到的烟雾。此外，这篇论文还 investigate了在多个前沿探索任务中，提议的框架在烟雾存在下的效果，并对结果进行实验，以便与其他方法ologies和计算影响进行比较。这为研究者提供了有价值的反馈，以便更好地利用筛选方案，同时考虑移动 robot的自主导航安全性。
</details></li>
</ul>
<hr>
<h2 id="Large-kernel-Attention-for-Efficient-and-Robust-Brain-Lesion-Segmentation"><a href="#Large-kernel-Attention-for-Efficient-and-Robust-Brain-Lesion-Segmentation" class="headerlink" title="Large-kernel Attention for Efficient and Robust Brain Lesion Segmentation"></a>Large-kernel Attention for Efficient and Robust Brain Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07251">http://arxiv.org/abs/2308.07251</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liamchalcroft/mdunet">https://github.com/liamchalcroft/mdunet</a></li>
<li>paper_authors: Liam Chalcroft, Ruben Lourenço Pereira, Mikael Brudfors, Andrew S. Kayser, Mark D’Esposito, Cathy J. Price, Ioannis Pappas, John Ashburner</li>
<li>for: 这个论文主要用于提出一种基于 transformer 块的 U-Net 架构，用于三维脑损块分割。</li>
<li>methods: 该模型使用了一种混合 convolutional 和 transformer 块的 variant，用于模elling 长距离交互。</li>
<li>results: 研究表明，该模型在三维脑损块分割任务中提供了最佳的折衔点，即性能与当前状态体系相当，且参数效率与 CNN 相当，同时具有转化不变性的良好假设。<details>
<summary>Abstract</summary>
Vision transformers are effective deep learning models for vision tasks, including medical image segmentation. However, they lack efficiency and translational invariance, unlike convolutional neural networks (CNNs). To model long-range interactions in 3D brain lesion segmentation, we propose an all-convolutional transformer block variant of the U-Net architecture. We demonstrate that our model provides the greatest compromise in three factors: performance competitive with the state-of-the-art; parameter efficiency of a CNN; and the favourable inductive biases of a transformer. Our public implementation is available at https://github.com/liamchalcroft/MDUNet .
</details>
<details>
<summary>摘要</summary>
视transformer是深度学习模型，用于视觉任务，包括医学影像分割。然而，它缺乏效率和翻译不变性，与卷积神经网络（CNN）不同。为了模型3D脑损害分割中的长距离交互，我们提议一种alleviation transformer块变体的U-Net架构。我们示示了我们的模型提供了三个因素的最佳妥协：与状态之artefact的性能竞争; 参数效率与CNN相同; 以及转移器的有利 inductive bias。我们的公共实现可以在https://github.com/liamchalcroft/MDUNet上找到。
</details></li>
</ul>
<hr>
<h2 id="AAFACE-Attribute-aware-Attentional-Network-for-Face-Recognition"><a href="#AAFACE-Attribute-aware-Attentional-Network-for-Face-Recognition" class="headerlink" title="AAFACE: Attribute-aware Attentional Network for Face Recognition"></a>AAFACE: Attribute-aware Attentional Network for Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07243">http://arxiv.org/abs/2308.07243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niloufar Alipour Talemi, Hossein Kashiani, Sahar Rahimi Malakshan, Mohammad Saeed Ebrahimi Saadabadi, Nima Najafzadeh, Mohammad Akyash, Nasser M. Nasrabadi</li>
<li>for: 这个论文是为了提出一种新的多分支神经网络，该网络同时进行软生物ometrics（SB）预测和人脸识别（FR）两个任务。</li>
<li>methods: 该网络使用SB特征来增强FR表示的推断能力。具体来说，我们提出了一个属性意识的集成（AAI）模块，该模块通过对FR与SB特征图进行Weighted集成来实现。AAI模块不仅具有完全上下文意识，还可以学习输入特征之间复杂的关系。</li>
<li>results: 我们的提出的网络在比较于现状的SB预测和FR方法上表现出了superiority。<details>
<summary>Abstract</summary>
In this paper, we present a new multi-branch neural network that simultaneously performs soft biometric (SB) prediction as an auxiliary modality and face recognition (FR) as the main task. Our proposed network named AAFace utilizes SB attributes to enhance the discriminative ability of FR representation. To achieve this goal, we propose an attribute-aware attentional integration (AAI) module to perform weighted integration of FR with SB feature maps. Our proposed AAI module is not only fully context-aware but also capable of learning complex relationships between input features by means of the sequential multi-scale channel and spatial sub-modules. Experimental results verify the superiority of our proposed network compared with the state-of-the-art (SoTA) SB prediction and FR methods.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种新的多分支神经网络，该网络同时进行软生物特征（SB）预测作为辅助特征和人脸识别（FR）作为主要任务。我们提出的AAFace网络利用SB特征来增强FR表示的分类能力。为此，我们提出了一种属性意识权重整合（AAI）模块，以进行FR与SB特征地图的Weighted整合。我们的AAI模块不仅具有完整的上下文意识，还能够学习输入特征之间的复杂关系，通过纵向多尺度通道和空间子模块。实验结果证明了我们提出的网络的优越性，与当前最佳状态（SoTA）SB预测和FR方法相比。
</details></li>
</ul>
<hr>
<h2 id="UniWorld-Autonomous-Driving-Pre-training-via-World-Models"><a href="#UniWorld-Autonomous-Driving-Pre-training-via-World-Models" class="headerlink" title="UniWorld: Autonomous Driving Pre-training via World Models"></a>UniWorld: Autonomous Driving Pre-training via World Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07234">http://arxiv.org/abs/2308.07234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaytonmin/uniworld">https://github.com/chaytonmin/uniworld</a></li>
<li>paper_authors: Chen Min, Dawei Zhao, Liang Xiao, Yiming Nie, Bin Dai</li>
<li>for: This paper is written for those interested in developing world models for robots, specifically for autonomous driving.</li>
<li>methods: The paper proposes a unified pre-training framework called UniWorld, which uses a spatial-temporal world model to perceive the surroundings and predict the future behavior of other participants. The framework is based on Alberto Elfes’ pioneering work in 1989 and uses a label-free pre-training process to build a foundational model.</li>
<li>results: The proposed method demonstrates promising results in key tasks such as motion prediction, multi-camera 3D object detection, and surrounding semantic scene completion. Compared to monocular pre-training methods on the nuScenes dataset, UniWorld shows a significant improvement of about 1.5% in IoU for motion prediction, 2.0% in mAP and 2.0% in NDS for multi-camera 3D object detection, as well as a 3% increase in mIoU for surrounding semantic scene completion. Additionally, the method achieves a 25% reduction in 3D training annotation costs, offering significant practical value for real-world autonomous driving.<details>
<summary>Abstract</summary>
In this paper, we draw inspiration from Alberto Elfes' pioneering work in 1989, where he introduced the concept of the occupancy grid as World Models for robots. We imbue the robot with a spatial-temporal world model, termed UniWorld, to perceive its surroundings and predict the future behavior of other participants. UniWorld involves initially predicting 4D geometric occupancy as the World Models for foundational stage and subsequently fine-tuning on downstream tasks. UniWorld can estimate missing information concerning the world state and predict plausible future states of the world. Besides, UniWorld's pre-training process is label-free, enabling the utilization of massive amounts of image-LiDAR pairs to build a Foundational Model.The proposed unified pre-training framework demonstrates promising results in key tasks such as motion prediction, multi-camera 3D object detection, and surrounding semantic scene completion. When compared to monocular pre-training methods on the nuScenes dataset, UniWorld shows a significant improvement of about 1.5% in IoU for motion prediction, 2.0% in mAP and 2.0% in NDS for multi-camera 3D object detection, as well as a 3% increase in mIoU for surrounding semantic scene completion. By adopting our unified pre-training method, a 25% reduction in 3D training annotation costs can be achieved, offering significant practical value for the implementation of real-world autonomous driving. Codes are publicly available at https://github.com/chaytonmin/UniWorld.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们启发自阿尔伯托·艾尔法斯在1989年的开创性工作，其中提出了机器人世界模型的概念。我们为机器人提供了一个空间-时间世界模型，称之为UniWorld，以便理解它所处的环境和预测其他参与者的未来行为。UniWorld包括先预测4D几何占据的世界模型为基础阶段，然后细化到下游任务。UniWorld可以 estimte missing world state information和预测可能的未来世界状态。此外，UniWorld的预训练过程无需标签，可以使用巨量的图像-LiDAR对组建基础模型。提出的统一预训练框架在关键任务中表现出了可观的成果，比如运动预测、多摄像头3D物体检测和周围 semanticscene完成。与单摄像头预训练方法在nuScenes dataset上进行比较，UniWorld在运动预测、3D物体检测和semanticscene完成任务中显示出了约1.5%的 IoU提升、2.0%的 mAP提升和2.0%的 NDS提升。通过采用我们的统一预训练方法，可以降低3D训练注释成本的25%，提供了实际应用自动驾驶的重要实践价值。代码可以在https://github.com/chaytonmin/UniWorld中找到。
</details></li>
</ul>
<hr>
<h2 id="RestoreFormer-Towards-Real-World-Blind-Face-Restoration-from-Undegraded-Key-Value-Pairs"><a href="#RestoreFormer-Towards-Real-World-Blind-Face-Restoration-from-Undegraded-Key-Value-Pairs" class="headerlink" title="RestoreFormer++: Towards Real-World Blind Face Restoration from Undegraded Key-Value Pairs"></a>RestoreFormer++: Towards Real-World Blind Face Restoration from Undegraded Key-Value Pairs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07228">http://arxiv.org/abs/2308.07228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhouxia Wang, Jiawei Zhang, Tianshui Chen, Wenping Wang, Ping Luo</li>
<li>for: 这个论文的目标是提高高质量的人脸图像从不知道的干扰中进行恢复。</li>
<li>methods: 该论文提出了RestoreFormer++,一种新的人脸图像恢复算法，它在一个手动注意力机制上模型了人脸图像的上下文信息，并在另一个扩展降低模型上帮助生成更加真实的降低图像，以增强对真实场景的适应性。</li>
<li>results: 对比当前算法，RestoreFormer++有多个优势，包括更高的真实性和质量，以及更好的适应性和泛化能力。<details>
<summary>Abstract</summary>
Blind face restoration aims at recovering high-quality face images from those with unknown degradations. Current algorithms mainly introduce priors to complement high-quality details and achieve impressive progress. However, most of these algorithms ignore abundant contextual information in the face and its interplay with the priors, leading to sub-optimal performance. Moreover, they pay less attention to the gap between the synthetic and real-world scenarios, limiting the robustness and generalization to real-world applications. In this work, we propose RestoreFormer++, which on the one hand introduces fully-spatial attention mechanisms to model the contextual information and the interplay with the priors, and on the other hand, explores an extending degrading model to help generate more realistic degraded face images to alleviate the synthetic-to-real-world gap. Compared with current algorithms, RestoreFormer++ has several crucial benefits. First, instead of using a multi-head self-attention mechanism like the traditional visual transformer, we introduce multi-head cross-attention over multi-scale features to fully explore spatial interactions between corrupted information and high-quality priors. In this way, it can facilitate RestoreFormer++ to restore face images with higher realness and fidelity. Second, in contrast to the recognition-oriented dictionary, we learn a reconstruction-oriented dictionary as priors, which contains more diverse high-quality facial details and better accords with the restoration target. Third, we introduce an extending degrading model that contains more realistic degraded scenarios for training data synthesizing, and thus helps to enhance the robustness and generalization of our RestoreFormer++ model. Extensive experiments show that RestoreFormer++ outperforms state-of-the-art algorithms on both synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary>
目标是从不知名的降低中恢复高质量的面孔图像。现有算法主要通过引入约束来补充高质量的细节，实现了很好的进步。然而，大多数这些算法忽略面孔中的丰富上下文信息和它们之间的互动，导致优化性不佳。另外，它们对实际世界应用场景的差异不够关注，限制了其robustness和泛化性。在这种情况下，我们提出了RestoreFormer++，它在一个方面引入了完全的空间注意力机制，以模型面孔中的上下文信息和约束之间的互动；另一方面，它探索了一种扩展降低模型，以帮助生成更真实的降低面孔图像，从而缓解实际世界和synthetic世界之间的差异。与现有算法相比，RestoreFormer++有几个重要优点。首先，不同于传统的视觉转换器，我们引入了多头跨度的cross-attention机制，以全面探索降低信息和高质量约束之间的空间互动，从而使RestoreFormer++能够更好地恢复面孔图像。第二，我们不是通过认知 oriented的字典来学习约束，而是通过恢复 oriented的字典来学习约束，这种字典包含更多的多样化的高质量 facial detail，更好地符合恢复目标。第三，我们引入了一种扩展降低模型，该模型包含更真实的降低场景，从而帮助提高RestoreFormer++模型的Robustness和泛化性。广泛的实验表明，RestoreFormer++在synthetic和实际世界数据上都能够超越现有的算法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/15/cs.CV_2023_08_15/" data-id="clly4xtcw003vvl88d6kpaggq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">108</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
