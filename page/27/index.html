
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/27/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.AS_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/eess.AS_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T14:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/eess.AS_2023_09_26/">eess.AS - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Privacy-preserving-and-Privacy-attacking-Approaches-for-Speech-and-Audio-–-A-Survey"><a href="#Privacy-preserving-and-Privacy-attacking-Approaches-for-Speech-and-Audio-–-A-Survey" class="headerlink" title="Privacy-preserving and Privacy-attacking Approaches for Speech and Audio – A Survey"></a>Privacy-preserving and Privacy-attacking Approaches for Speech and Audio – A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15087">http://arxiv.org/abs/2309.15087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchen Liu, Apu Kapadia, Donald Williamson</li>
<li>For: This paper aims to examine existing approaches for privacy-preserving and privacy-attacking strategies for audio and speech, and to provide a comprehensive analysis of their limitations.* Methods: The paper classifies attack and defense scenarios into several categories and provides detailed analysis of each approach, highlighting their contributions and limitations.* Results: The investigation reveals that voice-controlled devices based on neural networks are inherently susceptible to specific types of attacks, and more sophisticated approaches are required to comprehensively safeguard user privacy.Here is the same information in Simplified Chinese text:* For: 这篇论文目的是对现有的声音和语音隐私保护和隐私攻击策略进行分类和详细分析，以及对其限制的调查。* Methods: 论文将攻击和防御场景分类为多个类别，并对每种方法进行详细的分析，并且高亮它们的贡献和局限性。* Results: 调查发现，基于神经网络的声控设备容易受到特定类型的攻击，以及更加复杂的方法是必须保护用户隐私的。<details>
<summary>Abstract</summary>
In contemporary society, voice-controlled devices, such as smartphones and home assistants, have become pervasive due to their advanced capabilities and functionality. The always-on nature of their microphones offers users the convenience of readily accessing these devices. However, recent research and events have revealed that such voice-controlled devices are prone to various forms of malicious attacks, hence making it a growing concern for both users and researchers to safeguard against such attacks. Despite the numerous studies that have investigated adversarial attacks and privacy preservation for images, a conclusive study of this nature has not been conducted for the audio domain. Therefore, this paper aims to examine existing approaches for privacy-preserving and privacy-attacking strategies for audio and speech. To achieve this goal, we classify the attack and defense scenarios into several categories and provide detailed analysis of each approach. We also interpret the dissimilarities between the various approaches, highlight their contributions, and examine their limitations. Our investigation reveals that voice-controlled devices based on neural networks are inherently susceptible to specific types of attacks. Although it is possible to enhance the robustness of such models to certain forms of attack, more sophisticated approaches are required to comprehensively safeguard user privacy.
</details>
<details>
<summary>摘要</summary>
现代社会中，声控设备，如智能手机和智能助手，因其高级功能和可用性而广泛使用。这些设备的总是开机的麦克风使用者可以轻松地访问这些设备。然而，最近的研究和事件表明，这些声控设备受到多种恶意攻击的威胁，因此使用者和研究人员需要采取保护措施。 DESPITE  numerous studies investigating adversarial attacks and privacy preservation for images, a conclusive study of this nature has not been conducted for the audio domain. Therefore, this paper aims to examine existing approaches for privacy-preserving and privacy-attacking strategies for audio and speech. To achieve this goal, we classify the attack and defense scenarios into several categories and provide detailed analysis of each approach. We also interpret the dissimilarities between the various approaches, highlight their contributions, and examine their limitations. Our investigation reveals that voice-controlled devices based on neural networks are inherently susceptible to specific types of attacks. Although it is possible to enhance the robustness of such models to certain forms of attack, more sophisticated approaches are required to comprehensively safeguard user privacy.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/eess.AS_2023_09_26/" data-id="clogyj91q00zg7cra1sew8ajo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/cs.CV_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T13:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/cs.CV_2023_09_26/">cs.CV - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Cross-City-Matters-A-Multimodal-Remote-Sensing-Benchmark-Dataset-for-Cross-City-Semantic-Segmentation-using-High-Resolution-Domain-Adaptation-Networks"><a href="#Cross-City-Matters-A-Multimodal-Remote-Sensing-Benchmark-Dataset-for-Cross-City-Semantic-Segmentation-using-High-Resolution-Domain-Adaptation-Networks" class="headerlink" title="Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks"></a>Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.16499">http://arxiv.org/abs/2309.16499</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danfeng Hong, Bing Zhang, Hao Li, Yuxuan Li, Jing Yao, Chenyu Li, Martin Werner, Jocelyn Chanussot, Alexander Zipf, Xiao Xiang Zhu</li>
<li>for: 这个论文的目的是提出一种高分解能力的城市范围内 semantic segmentation 任务的解决方案，以提高人工智能（AI）模型在多modal remote sensing（RS）应用中的表现。</li>
<li>methods: 这个论文使用了一种高分解能力的域 adaptation network（HighDAN），可以在多城市环境中提高AI模型的泛化能力。HighDAN 使用了平行高到低分辨率的混合方式，并通过对抗学习来覆盖不同城市中RS图像表示的巨大差异。此外，该论文还考虑了 Dice 损失来缓解因城市因素而导致的类别不均匀问题。</li>
<li>results: 实验表明，高分解能力的 HighDAN 在 C2Seg 数据集上表现出色，与现有的竞争对手相比，具有更高的分 segmentation 性能和泛化能力。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) approaches nowadays have gained remarkable success in single-modality-dominated remote sensing (RS) applications, especially with an emphasis on individual urban environments (e.g., single cities or regions). Yet these AI models tend to meet the performance bottleneck in the case studies across cities or regions, due to the lack of diverse RS information and cutting-edge solutions with high generalization ability. To this end, we build a new set of multimodal remote sensing benchmark datasets (including hyperspectral, multispectral, SAR) for the study purpose of the cross-city semantic segmentation task (called C2Seg dataset), which consists of two cross-city scenes, i.e., Berlin-Augsburg (in Germany) and Beijing-Wuhan (in China). Beyond the single city, we propose a high-resolution domain adaptation network, HighDAN for short, to promote the AI model's generalization ability from the multi-city environments. HighDAN is capable of retaining the spatially topological structure of the studied urban scene well in a parallel high-to-low resolution fusion fashion but also closing the gap derived from enormous differences of RS image representations between different cities by means of adversarial learning. In addition, the Dice loss is considered in HighDAN to alleviate the class imbalance issue caused by factors across cities. Extensive experiments conducted on the C2Seg dataset show the superiority of our HighDAN in terms of segmentation performance and generalization ability, compared to state-of-the-art competitors. The C2Seg dataset and the semantic segmentation toolbox (involving the proposed HighDAN) will be available publicly at https://github.com/danfenghong.
</details>
<details>
<summary>摘要</summary>
现代人工智能（AI）方法在单一感知（RS）应用中已经取得了非常出色的成功，特别是在强调个别城市环境（例如单个城市或区域）。然而，这些AI模型在各个城市或区域的案例研究中会遇到性能瓶颈，因为缺乏多元RS信息和 cutting-edge 解决方案。为此，我们建立了一个新的多模态RS benchmark数据集（包括偏振、多спектраль、Synthetic Aperture Radar），称为C2Seg数据集，用于跨城市semantic segmentation任务。C2Seg数据集包括两个跨城市场景： Berlin-Augsburg（德国）和Beijing-Wuhan（中国）。我们提议一种高分辨率领域适应网络（HighDAN），用于提高AI模型在多城市环境中的泛化能力。HighDAN可以保持 изучение城市景象的空间 topological结构在高到低分辨率的并行混合方式中，同时通过对RS图像表示之间的巨大差异进行反对学习来填充这些差异。此外，我们还考虑了Dice损失函数，以解决由不同城市因素引起的分类不均匀问题。我们在C2Seg数据集上进行了广泛的实验，并证明了我们的HighDAN在segmentation性能和泛化能力方面与现有竞争者相比较出色。C2Seg数据集和semantic segmentation工具箱（包括我们提议的HighDAN）将在https://github.com/danfenghong公共地址上公开。
</details></li>
</ul>
<hr>
<h2 id="Conversion-of-single-energy-computed-tomography-to-parametric-maps-of-dual-energy-computed-tomography-using-convolutional-neural-network"><a href="#Conversion-of-single-energy-computed-tomography-to-parametric-maps-of-dual-energy-computed-tomography-using-convolutional-neural-network" class="headerlink" title="Conversion of single-energy computed tomography to parametric maps of dual-energy computed tomography using convolutional neural network"></a>Conversion of single-energy computed tomography to parametric maps of dual-energy computed tomography using convolutional neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15314">http://arxiv.org/abs/2309.15314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwook Kim, Jimin Lee, Jungye Kim, Bitbyeol Kim, Chang Heon Choi, Seongmoon Jung</li>
<li>for: 这个研究的目的是将单能CT图像（SECT）直接转换为三种 Parametric 地幅图像（DECT）中的虚拟独束图像（VMI）、有效原子数（EAN）和相对电子浓度（RED）。</li>
<li>methods: 我们提出了一个深度学习（DL）多任务学习框架，使用 convolutional neural network（CNN）直接将 SECT 图像转换为 DECT 中的三种 Parametric 地幅图像。我们提出了 VMI-Net、EAN-Net 和 RED-Net 三种不同的网络，用于将 SECT 图像转换为不同的 Parametric 地幅图像。我们在 67 名患者的数据集（2019-2020 年采集）上训练和验证了我们的模型。</li>
<li>results: 我们的模型可以将 120 kVp SECT 图像转换为高质量的 VMI、EAN 和 RED 图像。转换后的 AD 为 9.02 Hounsfield Unit，RD 为 0.41% 相对于真实的 VMIs。转换后的 EAN 和 RED 的 AD 分别为 0.29 和 0.96，RD 分别为 1.99% 和 0.50%。<details>
<summary>Abstract</summary>
Objectives: We propose a deep learning (DL) multi-task learning framework using convolutional neural network (CNN) for a direct conversion of single-energy CT (SECT) to three different parametric maps of dual-energy CT (DECT): Virtual-monochromatic image (VMI), effective atomic number (EAN), and relative electron density (RED).   Methods: We propose VMI-Net for conversion of SECT to 70, 120, and 200 keV VMIs. In addition, EAN-Net and RED-Net were also developed to convert SECT to EAN and RED. We trained and validated our model using 67 patients collected between 2019 and 2020. SECT images with 120 kVp acquired by the DECT (IQon spectral CT, Philips) were used as input, while the VMIs, EAN, and RED acquired by the same device were used as target. The performance of the DL framework was evaluated by absolute difference (AD) and relative difference (RD).   Results: The VMI-Net converted 120 kVp SECT to the VMIs with AD of 9.02 Hounsfield Unit, and RD of 0.41% compared to the ground truth VMIs. The ADs of the converted EAN and RED were 0.29 and 0.96, respectively, while the RDs were 1.99% and 0.50% for the converted EAN and RED, respectively.   Conclusions: SECT images were directly converted to the three parametric maps of DECT (i.e., VMIs, EAN, and RED). By using this model, one can generate the parametric information from SECT images without DECT device. Our model can help investigate the parametric information from SECT retrospectively.   Advances in knowledge: Deep learning framework enables converting SECT to various high-quality parametric maps of DECT.
</details>
<details>
<summary>摘要</summary>
目标：我们提出了一种深度学习（DL）多任务学习框架，使用卷积神经网络（CNN）将单能CT（SECT）直接转换为三个不同的参数图像：虚拟单能图像（VMI）、有效原子数（EAN）和相对电子密度（RED）。方法：我们提出了VMI-Net来将SECT转换为70、120和200 keV的VMIs。此外，我们还开发了EAN-Net和RED-Net，用于将SECT转换为EAN和RED。我们使用2019-2020年采集的67例病人数据进行训练和验证。SECT图像使用120 kVp的DECT（IQon spectral CT， Philips）获取，而VMIs、EAN和RED则是使用同一设备获取的目标。我们评估了DL框架的性能，使用绝对差（AD）和相对差（RD）进行评估。结果：VMI-Net将120 kVp SECT转换为VMIs的AD为9.02 Hounsfield Unit，RD为0.41%，相比于参照值VMIs。转换后的EAN和RED的AD分别为0.29和0.96，RD分别为1.99%和0.50%。结论：我们提出了一种将SECT图像直接转换为DECT三个参数图像的DL框架。通过这种模型，可以从SECT图像中提取 Parametric 信息，无需使用DECT设备。我们的模型可以帮助回溯SECT图像中的 Parametric 信息。知识前进：DL框架可以将SECT图像转换为多种高质量的DECT参数图像。
</details></li>
</ul>
<hr>
<h2 id="M-3-3D-Learning-3D-priors-using-Multi-Modal-Masked-Autoencoders-for-2D-image-and-video-understanding"><a href="#M-3-3D-Learning-3D-priors-using-Multi-Modal-Masked-Autoencoders-for-2D-image-and-video-understanding" class="headerlink" title="M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for 2D image and video understanding"></a>M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for 2D image and video understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15313">http://arxiv.org/abs/2309.15313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Abdullah Jamal, Omid Mohareri</li>
<li>for: 本研究旨在提出一种新的预训练策略，即M$^{3}$3D（多ModalMasked3D），可以利用RGB-D数据中的3D先验知识和学习的跨模态特征，并通过自我监督学习框架的组合来提升modal之间的匹配程度。</li>
<li>methods: 本研究使用了两种主要的自我监督学习框架：Masked Image Modeling（MIM）和对比学习，以便嵌入屏幕3D先验知识和相关的特征，提高modal之间的匹配程度。</li>
<li>results: 实验表明，M$^{3}$3D在ScanNet、NYUv2、UCF-101和OR-AR等数据集上都表现出优于现有的状态艺术方法，尤其是在ScanNet semantic segmentation任务上提高了+1.3% mIoU  противMask3D。此外，我们还证明了我们的方法在数据缺乏情况下的数据效率superiority。<details>
<summary>Abstract</summary>
We present a new pre-training strategy called M$^{3}$3D ($\underline{M}$ulti-$\underline{M}$odal $\underline{M}$asked $\underline{3D}$) built based on Multi-modal masked autoencoders that can leverage 3D priors and learned cross-modal representations in RGB-D data. We integrate two major self-supervised learning frameworks; Masked Image Modeling (MIM) and contrastive learning; aiming to effectively embed masked 3D priors and modality complementary features to enhance the correspondence between modalities. In contrast to recent approaches which are either focusing on specific downstream tasks or require multi-view correspondence, we show that our pre-training strategy is ubiquitous, enabling improved representation learning that can transfer into improved performance on various downstream tasks such as video action recognition, video action detection, 2D semantic segmentation and depth estimation. Experiments show that M$^{3}$3D outperforms the existing state-of-the-art approaches on ScanNet, NYUv2, UCF-101 and OR-AR, particularly with an improvement of +1.3\% mIoU against Mask3D on ScanNet semantic segmentation. We further evaluate our method on low-data regime and demonstrate its superior data efficiency compared to current state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的预训练策略，称为M$^{3}$3D（多Modal多样性掩码3D），基于多Modal掩码自动encoder，可以利用3D先验和学习的过程来抽象RGB-D数据中的多Modal特征。我们将两种主要的自我超vised学习框架，Masked Image Modeling（MIM）和对比学习，结合在一起，以便具有更好的映射性和多Modal特征的嵌入。与现有的方法不同，我们的预训练策略不仅关注特定的下游任务，也不需要多视角对应。我们展示了M$^{3}$3D在不同的下游任务上的改进表现，包括视频动作识别、视频动作检测、2D semantics标注和深度估计。实验结果表明，M$^{3}$3D在ScanNet、NYUv2、UCF-101和OR-AR等数据集上具有较高的表现，特别是在ScanNet semantic segmentation任务上与Mask3D的+1.3\% mIoU提升。此外，我们还对M$^{3}$3D在低数据量情况下的数据效率进行了评估，并证明了它在当前状态的最佳方法中具有超过其他方法的优势。
</details></li>
</ul>
<hr>
<h2 id="SEPT-Towards-Efficient-Scene-Representation-Learning-for-Motion-Prediction"><a href="#SEPT-Towards-Efficient-Scene-Representation-Learning-for-Motion-Prediction" class="headerlink" title="SEPT: Towards Efficient Scene Representation Learning for Motion Prediction"></a>SEPT: Towards Efficient Scene Representation Learning for Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15289">http://arxiv.org/abs/2309.15289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqian Lan, Yuxuan Jiang, Yao Mu, Chen Chen, Shengbo Eben Li, Hang Zhao, Keqiang Li</li>
<li>for: 这篇论文旨在提高自动驾驶车辆在复杂交通环境中安全运行，通过提取有效的空间时间关系来准确预测行进。</li>
<li>methods: 该论文提出了一种基于自我指导学习的模型框架，利用Scene Encoder来捕捉行车轨迹和路网的空间结构，以及路网和 Agent 之间的交互。</li>
<li>results: 经过广泛的实验，SEPT 模型在 Argoverse 1 和 Argoverse 2 运动预测测试 bencmark 上达到了状态机器人性能，与前一代方法在所有主要指标上大幅超越。<details>
<summary>Abstract</summary>
Motion prediction is crucial for autonomous vehicles to operate safely in complex traffic environments. Extracting effective spatiotemporal relationships among traffic elements is key to accurate forecasting. Inspired by the successful practice of pretrained large language models, this paper presents SEPT, a modeling framework that leverages self-supervised learning to develop powerful spatiotemporal understanding for complex traffic scenes. Specifically, our approach involves three masking-reconstruction modeling tasks on scene inputs including agents' trajectories and road network, pretraining the scene encoder to capture kinematics within trajectory, spatial structure of road network, and interactions among roads and agents. The pretrained encoder is then finetuned on the downstream forecasting task. Extensive experiments demonstrate that SEPT, without elaborate architectural design or manual feature engineering, achieves state-of-the-art performance on the Argoverse 1 and Argoverse 2 motion forecasting benchmarks, outperforming previous methods on all main metrics by a large margin.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNMotion prediction is crucial for autonomous vehicles to operate safely in complex traffic environments. Extracting effective spatiotemporal relationships among traffic elements is key to accurate forecasting. Inspired by the successful practice of pretrained large language models, this paper presents SEPT, a modeling framework that leverages self-supervised learning to develop powerful spatiotemporal understanding for complex traffic scenes. Specifically, our approach involves three masking-reconstruction modeling tasks on scene inputs including agents' trajectories and road network, pretraining the scene encoder to capture kinematics within trajectory, spatial structure of road network, and interactions among roads and agents. The pretrained encoder is then finetuned on the downstream forecasting task. Extensive experiments demonstrate that SEPT, without elaborate architectural design or manual feature engineering, achieves state-of-the-art performance on the Argoverse 1 and Argoverse 2 motion forecasting benchmarks, outperforming previous methods on all main metrics by a large margin.<</SYS>>Here's the translation in Traditional Chinese as well:<<SYS>>translate_language: zh-TWMotion prediction is crucial for autonomous vehicles to operate safely in complex traffic environments. Extracting effective spatiotemporal relationships among traffic elements is key to accurate forecasting. Inspired by the successful practice of pretrained large language models, this paper presents SEPT, a modeling framework that leverages self-supervised learning to develop powerful spatiotemporal understanding for complex traffic scenes. Specifically, our approach involves three masking-reconstruction modeling tasks on scene inputs including agents' trajectories and road network, pretraining the scene encoder to capture kinematics within trajectory, spatial structure of road network, and interactions among roads and agents. The pretrained encoder is then finetuned on the downstream forecasting task. Extensive experiments demonstrate that SEPT, without elaborate architectural design or manual feature engineering, achieves state-of-the-art performance on the Argoverse 1 and Argoverse 2 motion forecasting benchmarks, outperforming previous methods on all main metrics by a large margin.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Boosting-High-Resolution-Image-Classification-with-Scaling-up-Transformers"><a href="#Boosting-High-Resolution-Image-Classification-with-Scaling-up-Transformers" class="headerlink" title="Boosting High Resolution Image Classification with Scaling-up Transformers"></a>Boosting High Resolution Image Classification with Scaling-up Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15277">http://arxiv.org/abs/2309.15277</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyi111/cvppa2023-dnd-challenge">https://github.com/wangyi111/cvppa2023-dnd-challenge</a></li>
<li>paper_authors: Yi Wang</li>
<li>for: 这个论文是为了提出一个整体方法来进行高分辨率图像分类，并在ICCV&#x2F;CVPPA2023 Deep Nutrient Deficiency Challenge中获得第二名。</li>
<li>methods: 这个方法包括了以下六个步骤：1）数据分布分析以检查潜在的领域转移，2）选择强大基eline模型，3）将已 publiushed pretrained模型进行转移学习，4）进行不断 fine-tuning 小子集，5）实现训练数据的多样性和避免过滤，6）在试验时使用 “data soups” 进行跨折衣平均预测，以获得更稳定的最终试验结果。</li>
<li>results: 这个方法在ICCV&#x2F;CVPPA2023 Deep Nutrient Deficiency Challenge中获得第二名，并且在高分辨率图像分类任务中表现出色。<details>
<summary>Abstract</summary>
We present a holistic approach for high resolution image classification that won second place in the ICCV/CVPPA2023 Deep Nutrient Deficiency Challenge. The approach consists of a full pipeline of: 1) data distribution analysis to check potential domain shift, 2) backbone selection for a strong baseline model that scales up for high resolution input, 3) transfer learning that utilizes published pretrained models and continuous fine-tuning on small sub-datasets, 4) data augmentation for the diversity of training data and to prevent overfitting, 5) test-time augmentation to improve the prediction's robustness, and 6) "data soups" that conducts cross-fold model prediction average for smoothened final test results.
</details>
<details>
<summary>摘要</summary>
我们提出了一种整体方法 для高分辨率图像分类，在ICCV/CVPPA2023年度深度营养不足挑战赛中获得第二名。该方法包括以下整体管道：1. 数据分布分析，检查可能存在域shift问题。2. 选择一个强大基线模型，可扩展到高分辨率输入。3. 基于已发布的预训练模型进行传播学习，并进行不断微调小sub-dataset。4. 对训练数据进行数据扩展，以避免过拟合和提高预测的稳定性。5. 在测试时使用数据扩展，以提高预测的Robustness。6. "数据汤"，对各个折衣进行平均预测，以平滑最终测试结果。
</details></li>
</ul>
<hr>
<h2 id="A-Topological-Machine-Learning-Pipeline-for-Classification"><a href="#A-Topological-Machine-Learning-Pipeline-for-Classification" class="headerlink" title="A Topological Machine Learning Pipeline for Classification"></a>A Topological Machine Learning Pipeline for Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15276">http://arxiv.org/abs/2309.15276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Conti, Davide Moroni, Maria Antonietta Pascali</li>
<li>for: 这个研究旨在发展一个可以将抗持续图 associate 到数据中的数位数据处理管道。</li>
<li>methods: 这个管道使用了一个格子搜索方法来 determin 最佳的表示方法和参数。</li>
<li>results: 这个研究获得了一个可以将抗持续图转换为适合机器学习数据的表示方法，并且可以评估这个管道的性能，并且与其他表示方法进行比较。<details>
<summary>Abstract</summary>
In this work, we develop a pipeline that associates Persistence Diagrams to digital data via the most appropriate filtration for the type of data considered. Using a grid search approach, this pipeline determines optimal representation methods and parameters. The development of such a topological pipeline for Machine Learning involves two crucial steps that strongly affect its performance: firstly, digital data must be represented as an algebraic object with a proper associated filtration in order to compute its topological summary, the Persistence Diagram. Secondly, the persistence diagram must be transformed with suitable representation methods in order to be introduced in a Machine Learning algorithm. We assess the performance of our pipeline, and in parallel, we compare the different representation methods on popular benchmark datasets. This work is a first step toward both an easy and ready-to-use pipeline for data classification using persistent homology and Machine Learning, and to understand the theoretical reasons why, given a dataset and a task to be performed, a pair (filtration, topological representation) is better than another.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们开发了一个管道，将持续征迹相关联到数字数据上，通过最佳筛选方法来确定最佳表示方法和参数。我们使用格子搜索方法来确定最佳表示方法和参数。这个管道的开发对机器学习领域具有重要意义，因为它可以帮助我们快速地将数据分类器与持续征迹相结合，从而提高数据分类的精度。在我们的管道中，我们首先将数字数据转换为一个 алгебраического对象，并将其关联到适当的筛选方法来计算其拓扑概要，即持续征迹。然后，我们将持续征迹转换为适当的表示方法，以便在机器学习算法中使用。我们评估管道的性能，并同时比较不同的表示方法在popular benchmark datasets上的性能。这项工作是机器学习领域的一个重要突破，因为它可以帮助我们快速地选择最佳的表示方法和参数，以便在数据分类 task 中实现更高的精度。此外，我们还可以通过对不同的表示方法进行比较，更好地理解在给定的数据集和任务中，哪种表示方法是更好的。
</details></li>
</ul>
<hr>
<h2 id="DECO-Dense-Estimation-of-3D-Human-Scene-Contact-In-The-Wild"><a href="#DECO-Dense-Estimation-of-3D-Human-Scene-Contact-In-The-Wild" class="headerlink" title="DECO: Dense Estimation of 3D Human-Scene Contact In The Wild"></a>DECO: Dense Estimation of 3D Human-Scene Contact In The Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15273">http://arxiv.org/abs/2309.15273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Tripathi, Agniv Chatterjee, Jean-Claude Passy, Hongwei Yi, Dimitrios Tzionas, Michael J. Black</li>
<li>for: 本研究旨在开发一种可以在真实生活中捕捉人类与物体之间的接触的人工智能模型。</li>
<li>methods: 该方法使用了新收集的 DAMON 数据集，该数据集包含人体Vertex-level的接触标注和RGB图像。然后，我们使用了一种新的 body-part-driven 和 scene-context-driven 注意力机制来estrain一种名为 DECO 的3D接触探测器。</li>
<li>results: 我们对 DAMON 数据集进行了广泛的评估，以及 RICH 和 BEHAVE 数据集。我们的方法与现有的 SOTA 方法进行了比较，并显示了在多种Benchmark上的显著性能提升。此外，我们还证明了 DECO 在真实生活中的人类互动图像中能够具有良好的普适性。<details>
<summary>Abstract</summary>
Understanding how humans use physical contact to interact with the world is key to enabling human-centric artificial intelligence. While inferring 3D contact is crucial for modeling realistic and physically-plausible human-object interactions, existing methods either focus on 2D, consider body joints rather than the surface, use coarse 3D body regions, or do not generalize to in-the-wild images. In contrast, we focus on inferring dense, 3D contact between the full body surface and objects in arbitrary images. To achieve this, we first collect DAMON, a new dataset containing dense vertex-level contact annotations paired with RGB images containing complex human-object and human-scene contact. Second, we train DECO, a novel 3D contact detector that uses both body-part-driven and scene-context-driven attention to estimate vertex-level contact on the SMPL body. DECO builds on the insight that human observers recognize contact by reasoning about the contacting body parts, their proximity to scene objects, and the surrounding scene context. We perform extensive evaluations of our detector on DAMON as well as on the RICH and BEHAVE datasets. We significantly outperform existing SOTA methods across all benchmarks. We also show qualitatively that DECO generalizes well to diverse and challenging real-world human interactions in natural images. The code, data, and models are available at https://deco.is.tue.mpg.de.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:理解人类如何通过物理接触与世界交互是人类中心智能的关键。现有方法 Either focus on 2D or 3D body joints rather than the surface, use coarse 3D body regions, or do not generalize to in-the-wild images. In contrast, we focus on inferring dense, 3D contact between the full body surface and objects in arbitrary images. To achieve this, we first collect DAMON, a new dataset containing dense vertex-level contact annotations paired with RGB images containing complex human-object and human-scene contact. Second, we train DECO, a novel 3D contact detector that uses both body-part-driven and scene-context-driven attention to estimate vertex-level contact on the SMPL body. DECO builds on the insight that human observers recognize contact by reasoning about the contacting body parts, their proximity to scene objects, and the surrounding scene context. We perform extensive evaluations of our detector on DAMON as well as on the RICH and BEHAVE datasets. We significantly outperform existing SOTA methods across all benchmarks. We also show qualitatively that DECO generalizes well to diverse and challenging real-world human interactions in natural images. The code, data, and models are available at https://deco.is.tue.mpg.de.
</details></li>
</ul>
<hr>
<h2 id="ObVi-SLAM-Long-Term-Object-Visual-SLAM"><a href="#ObVi-SLAM-Long-Term-Object-Visual-SLAM" class="headerlink" title="ObVi-SLAM: Long-Term Object-Visual SLAM"></a>ObVi-SLAM: Long-Term Object-Visual SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15268">http://arxiv.org/abs/2309.15268</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ut-amrl/obvi-slam">https://github.com/ut-amrl/obvi-slam</a></li>
<li>paper_authors: Amanda Adkins, Taijing Chen, Joydeep Biswas</li>
<li>for: 这篇论文是为了解决长时间执行任务中机器人的定位问题，即在不同的环境变化下保持定位的稳定性和扩展性。</li>
<li>methods: 本论文使用了低级别的视觉特征点，以及不确定性感知的长期地图建模技术来解决这个问题。</li>
<li>results: 经验证明，使用ObVi-SLAM可以在不同的天气和照明条件下实现高精度的定位估计，并且能够在长时间内保持定位的一致性。<details>
<summary>Abstract</summary>
Robots responsible for tasks over long time scales must be able to localize consistently and scalably amid geometric, viewpoint, and appearance changes. Existing visual SLAM approaches rely on low-level feature descriptors that are not robust to such environmental changes and result in large map sizes that scale poorly over long-term deployments. In contrast, object detections are robust to environmental variations and lead to more compact representations, but most object-based SLAM systems target short-term indoor deployments with close objects. In this paper, we introduce ObVi-SLAM to overcome these challenges by leveraging the best of both approaches. ObVi-SLAM uses low-level visual features for high-quality short-term visual odometry; and to ensure global, long-term consistency, ObVi-SLAM builds an uncertainty-aware long-term map of persistent objects and updates it after every deployment. By evaluating ObVi-SLAM on data from 16 deployment sessions spanning different weather and lighting conditions, we empirically show that ObVi-SLAM generates accurate localization estimates consistent over long-time scales in spite of varying appearance conditions.
</details>
<details>
<summary>摘要</summary>
роботы, ответственные за задачи на долгосрочных временных масштабах, должны быть в состоянии локализоваться надежным образом и масштабируемо amid геометрических, точек зрения и изменений внешнего вида. существующие подходы к визуальному SLAM основаны на низкоуровневых описаниях особенностей, которые не устойчивы к изменениям окружающей среды и приводят к большим картам, которые масштабируются плохо на долгосрочных деплоиментах. в отличие от этого, детектирование объектов является robust to изменения окружающей среды и приводит к более компактным представлениям, но большинство систем SLAM на основе объектов ориентированы на короткие термины наружных деплоиментов с близкими объектами. в этой статье мы вводим ObVi-SLAM, чтобы преодолеть эти проблемы, используя лучшие свойства обоих подходов. ObVi-SLAM использует низкоуровневые визуальные особенности для высококачественной краткосрочной визуальной одометрии; и для обеспечения глобальной, долгосрочной一порядковости, ObVi-SLAM строит карту неопределенности-осознанного долгосрочного мапа persistent objects и обновляет ее после каждого деплоимента. путем empirical evaluation ObVi-SLAM на данных из 16 сеансов деплоимента, разных погодных и осветительных условий, мы показываем, что ObVi-SLAM генерирует точные оценки локализации, согласующиеся на долгосрочных временных масштабах, несмотря на изменяющиеся условия внешнего вида.
</details></li>
</ul>
<hr>
<h2 id="SLIQ-Quantum-Image-Similarity-Networks-on-Noisy-Quantum-Computers"><a href="#SLIQ-Quantum-Image-Similarity-Networks-on-Noisy-Quantum-Computers" class="headerlink" title="SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers"></a>SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15259">http://arxiv.org/abs/2309.15259</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/silverengineered/sliq">https://github.com/silverengineered/sliq</a></li>
<li>paper_authors: Daniel Silver, Tirthak Patel, Aditya Ranjan, Harshitta Gandhi, William Cutler, Devesh Tiwari</li>
<li>for: 这项研究旨在解决量子计算机上进行无监督相似检测任务的挑战，提出了首个开源的量子相似检测网络SLIQ，使用实用和有效的量子学习和减少方差算法。</li>
<li>methods: SLIQ使用了实用和有效的量子学习和减少方差算法，包括量子径弧优化和量子均值优化等。</li>
<li>results: SLIQ可以在资源有限的情况下实现高效的无监督相似检测任务，并且比传统的量子算法有更好的性能。<details>
<summary>Abstract</summary>
Exploration into quantum machine learning has grown tremendously in recent years due to the ability of quantum computers to speed up classical programs. However, these efforts have yet to solve unsupervised similarity detection tasks due to the challenge of porting them to run on quantum computers. To overcome this challenge, we propose SLIQ, the first open-sourced work for resource-efficient quantum similarity detection networks, built with practical and effective quantum learning and variance-reducing algorithms.
</details>
<details>
<summary>摘要</summary>
对量子机器学习的探索在最近几年内有很大的发展，这主要是因为量子计算机可以快速化古典程式。然而，这些努力仍然无法解决无监督相似探测任务，因为将它们转换到量子计算机上是一个挑战。为了解决这个挑战，我们提出了SLIQ，首个开源的量子相似探测网络，使用了实用和有效的量子学习和减少方差算法。
</details></li>
</ul>
<hr>
<h2 id="APIS-A-paired-CT-MRI-dataset-for-ischemic-stroke-segmentation-challenge"><a href="#APIS-A-paired-CT-MRI-dataset-for-ischemic-stroke-segmentation-challenge" class="headerlink" title="APIS: A paired CT-MRI dataset for ischemic stroke segmentation challenge"></a>APIS: A paired CT-MRI dataset for ischemic stroke segmentation challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15243">http://arxiv.org/abs/2309.15243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Santiago Gómez, Daniel Mantilla, Gustavo Garzón, Edgar Rangel, Andrés Ortiz, Franklin Sierra-Jerez, Fabio Martínez</li>
<li>for: 本研究旨在提供一个公共数据集，以便研究人员可以使用配对的NCCT和ADC图像来描述stroke患者的脑损伤。</li>
<li>methods: 本研究使用了APIS数据集，该数据集包括20名 stroke患者的NCCT和ADC图像。研究人员可以使用这些数据来提出新的计算方法，以便更好地处理 stroke 患者的脑损伤。</li>
<li>results: 研究人员使用了专门的深度学习工具来解决 stroke 患者的脑损伤分 segmentation 问题。然而，结果表明，从 NCCT 序列中分 segmentation stroke 患者的脑损伤仍然是一个挑战。不withstanding, the annotated dataset remains accessible to the public upon registration, inviting the scientific community to deal with stroke characterization from NCCT but guided with paired DWI information.<details>
<summary>Abstract</summary>
Stroke is the second leading cause of mortality worldwide. Immediate attention and diagnosis play a crucial role regarding patient prognosis. The key to diagnosis consists in localizing and delineating brain lesions. Standard stroke examination protocols include the initial evaluation from a non-contrast CT scan to discriminate between hemorrhage and ischemia. However, non-contrast CTs may lack sensitivity in detecting subtle ischemic changes in the acute phase. As a result, complementary diffusion-weighted MRI studies are captured to provide valuable insights, allowing to recover and quantify stroke lesions. This work introduced APIS, the first paired public dataset with NCCT and ADC studies of acute ischemic stroke patients. APIS was presented as a challenge at the 20th IEEE International Symposium on Biomedical Imaging 2023, where researchers were invited to propose new computational strategies that leverage paired data and deal with lesion segmentation over CT sequences. Despite all the teams employing specialized deep learning tools, the results suggest that the ischemic stroke segmentation task from NCCT remains challenging. The annotated dataset remains accessible to the public upon registration, inviting the scientific community to deal with stroke characterization from NCCT but guided with paired DWI information.
</details>
<details>
<summary>摘要</summary>
世界上第二大死因之一是中风，即时注意和诊断对患者结果产生关键作用。诊断的关键在于确定脑损害的位置和范围。标准中风诊断协议包括非contrast CT扫描，以确定是否有出血或压缩。然而，非contrast CT可能无法察觉急性阶段的微scopic ischemic变化。因此，补充的扩散束环境MRI研究可以提供有价值的信息，帮助回复和量化中风损害。本文介绍了APIS，第一个对应公共数据集，包括NCCT和ADC研究数据。APIS在2023年IEEE国际生物医学图像学会上展示为挑战，邀请研究人员提出新的计算机科学策略，利用对应数据来解决中风损害部署。尽管所有团队使用特殊的深度学习工具，结果表明NCCT中风损害部署仍然是一个挑战。注释数据集仍然公开访问，邀请科学社区利用NCCT数据，但是受到对应DWI信息的指导。
</details></li>
</ul>
<hr>
<h2 id="CLRmatchNet-Enhancing-Curved-Lane-Detection-with-Deep-Matching-Process"><a href="#CLRmatchNet-Enhancing-Curved-Lane-Detection-with-Deep-Matching-Process" class="headerlink" title="CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process"></a>CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15204">http://arxiv.org/abs/2309.15204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sapir Kontente, Roy Orfaig, Ben-Zion Bobrovsky<br>for: 提高排版检测精度，增加安全导航数据methods: 使用深度学习子模块网络（MatchNet）取代传统的标签分配过程，提高排版检测精度results: 在抛物线路段中显著提高排版检测精度，对所有背景进行改进，并维持或提高相对精度在其他部分。<details>
<summary>Abstract</summary>
Lane detection plays a crucial role in autonomous driving by providing vital data to ensure safe navigation. Modern algorithms rely on anchor-based detectors, which are then followed by a label assignment process to categorize training detections as positive or negative instances based on learned geometric attributes. The current methods, however, have limitations and might not be optimal since they rely on predefined classical cost functions that are based on a low-dimensional model. Our research introduces MatchNet, a deep learning sub-module-based approach aimed at enhancing the label assignment process. Integrated into a state-of-the-art lane detection network like the Cross Layer Refinement Network for Lane Detection (CLRNet), MatchNet replaces the conventional label assignment process with a sub-module network. This integration results in significant improvements in scenarios involving curved lanes, with remarkable improvement across all backbones of +2.8% for ResNet34, +2.3% for ResNet101, and +2.96% for DLA34. In addition, it maintains or even improves comparable results in other sections. Our method boosts the confidence level in lane detection, allowing an increase in the confidence threshold. The code will be available soon: https://github.com/sapirkontente/CLRmatchNet.git
</details>
<details>
<summary>摘要</summary>
Lane detection plays a crucial role in autonomous driving by providing vital data to ensure safe navigation. Modern algorithms rely on anchor-based detectors, which are then followed by a label assignment process to categorize training detections as positive or negative instances based on learned geometric attributes. The current methods, however, have limitations and might not be optimal since they rely on predefined classical cost functions that are based on a low-dimensional model. Our research introduces MatchNet, a deep learning sub-module-based approach aimed at enhancing the label assignment process. Integrated into a state-of-the-art lane detection network like the Cross Layer Refinement Network for Lane Detection (CLRNet), MatchNet replaces the conventional label assignment process with a sub-module network. This integration results in significant improvements in scenarios involving curved lanes, with remarkable improvement across all backbones of +2.8% for ResNet34, +2.3% for ResNet101, and +2.96% for DLA34. In addition, it maintains or even improves comparable results in other sections. Our method boosts the confidence level in lane detection, allowing an increase in the confidence threshold. The code will be available soon: <https://github.com/sapirkontente/CLRmatchNet.git>
</details></li>
</ul>
<hr>
<h2 id="GasMono-Geometry-Aided-Self-Supervised-Monocular-Depth-Estimation-for-Indoor-Scenes"><a href="#GasMono-Geometry-Aided-Self-Supervised-Monocular-Depth-Estimation-for-Indoor-Scenes" class="headerlink" title="GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes"></a>GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.16019">http://arxiv.org/abs/2309.16019</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zxcqlf/gasmono">https://github.com/zxcqlf/gasmono</a></li>
<li>paper_authors: Chaoqiang Zhao, Matteo Poggi, Fabio Tosi, Lei Zhou, Qiyu Sun, Yang Tang, Stefano Mattoccia</li>
<li>for: This paper aims to improve self-supervised monocular depth estimation in indoor scenes, addressing challenges such as large rotation and low texture.</li>
<li>methods: The proposed method uses multi-view geometry to obtain coarse camera poses, and refines them through rotation and translation&#x2F;scale optimization. It also combines global reasoning with an overfitting-aware, iterative self-distillation mechanism to improve depth estimation.</li>
<li>results: The proposed method achieves state-of-the-art performance on four datasets (NYUv2, ScanNet, 7scenes, and KITTI), with outstanding generalization ability. Code and models are available at <a target="_blank" rel="noopener" href="https://github.com/zxcqlf/GasMono.Here's">https://github.com/zxcqlf/GasMono.Here&#39;s</a> the full text in Simplified Chinese:</li>
<li>for: 这篇论文目标是提高自动监督单视深度估计在室内场景中的性能，解决大角度转换和低 тексту化等挑战。</li>
<li>methods: 提议方法使用多视图几何来获取估计摄像头位置，并通过旋转和平移&#x2F;缩放优化来提高准确性。它还结合全球推理和迭代自适应自我混合优化机制来提高深度估计。</li>
<li>results: 提议方法在四个数据集（NYUv2、ScanNet、7scenes、KITTI）上实现了新的州度-of-the-art性能，同时也有出色的泛化能力。代码和模型可以在<a target="_blank" rel="noopener" href="https://github.com/zxcqlf/GasMono%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/zxcqlf/GasMono上下载。</a><details>
<summary>Abstract</summary>
This paper tackles the challenges of self-supervised monocular depth estimation in indoor scenes caused by large rotation between frames and low texture. We ease the learning process by obtaining coarse camera poses from monocular sequences through multi-view geometry to deal with the former. However, we found that limited by the scale ambiguity across different scenes in the training dataset, a na\"ive introduction of geometric coarse poses cannot play a positive role in performance improvement, which is counter-intuitive. To address this problem, we propose to refine those poses during training through rotation and translation/scale optimization. To soften the effect of the low texture, we combine the global reasoning of vision transformers with an overfitting-aware, iterative self-distillation mechanism, providing more accurate depth guidance coming from the network itself. Experiments on NYUv2, ScanNet, 7scenes, and KITTI datasets support the effectiveness of each component in our framework, which sets a new state-of-the-art for indoor self-supervised monocular depth estimation, as well as outstanding generalization ability. Code and models are available at https://github.com/zxcqlf/GasMono
</details>
<details>
<summary>摘要</summary>
这个论文解决了室内场景自指导的单视深度估计中的旋转和纹理问题。我们通过多视图几何获取估算摄像头位置，以处理前一些旋转。然而，我们发现由于不同场景集中的尺度抽象ambiguity，直接从场景集中获取的几何估算不能提高性能，这是预期的。为解决这个问题，我们提议在训练中对这些估算进行旋转和缩放优化。此外，为了减轻纹理的影响，我们将全球理解与迭代自适应自逼化机制相结合，提供更准确的深度指导。实验表明，我们的框架在NYUv2、ScanNet、7scenes和KITTI数据集上达到了室内自指导单视深度估计的新州chart，以及出色的泛化能力。代码和模型可以在https://github.com/zxcqlf/GasMono中下载。
</details></li>
</ul>
<hr>
<h2 id="Generating-Visual-Scenes-from-Touch"><a href="#Generating-Visual-Scenes-from-Touch" class="headerlink" title="Generating Visual Scenes from Touch"></a>Generating Visual Scenes from Touch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15117">http://arxiv.org/abs/2309.15117</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/roopeshukla/Drishti-For_Blind">https://github.com/roopeshukla/Drishti-For_Blind</a></li>
<li>paper_authors: Fengyu Yang, Jiacheng Zhang, Andrew Owens</li>
<li>for: 这篇论文旨在生成可能的图像从触感中。</li>
<li>methods: 该论文使用最近的扩散进步来创建图像从感触信号中的模型，并应用于多个视触合成任务。</li>
<li>results: 该模型在 manipulate 图像以符合触感信号的问题上表现出色，并且是首次成功地生成图像从触感信号中不需要其他场景信息。  additionally, the model is also used to solve two novel synthesis problems: generating images without the touch sensor or the hand holding it, and estimating an image’s shading from its reflectance and touch.<details>
<summary>Abstract</summary>
An emerging line of work has sought to generate plausible imagery from touch. Existing approaches, however, tackle only narrow aspects of the visuo-tactile synthesis problem, and lag significantly behind the quality of cross-modal synthesis methods in other domains. We draw on recent advances in latent diffusion to create a model for synthesizing images from tactile signals (and vice versa) and apply it to a number of visuo-tactile synthesis tasks. Using this model, we significantly outperform prior work on the tactile-driven stylization problem, i.e., manipulating an image to match a touch signal, and we are the first to successfully generate images from touch without additional sources of information about the scene. We also successfully use our model to address two novel synthesis problems: generating images that do not contain the touch sensor or the hand holding it, and estimating an image's shading from its reflectance and touch.
</details>
<details>
<summary>摘要</summary>
一种新兴的工作努力在触感中生成可信的图像。现有的方法只是处理触感领域的窄化方面，与其他领域的交叉模式同步生成方法相比，质量有很大差距。我们利用latest advances in latent diffusion创建一个图像从触感信号（以及vice versa）的模型，并应用于多个视触同步生成任务。使用这个模型，我们在触感驱动的风格化问题上表现出色，即通过触感信号修改图像，并且是首次无需其他场景信息就能从触感中生成图像。我们还成功地使用我们的模型解决了两个新的同步生成问题：生成不包含触感传感器或手持之物的图像，以及根据反射和触感来估算图像的阴影。
</details></li>
</ul>
<hr>
<h2 id="InternLM-XComposer-A-Vision-Language-Large-Model-for-Advanced-Text-image-Comprehension-and-Composition"><a href="#InternLM-XComposer-A-Vision-Language-Large-Model-for-Advanced-Text-image-Comprehension-and-Composition" class="headerlink" title="InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition"></a>InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15112">http://arxiv.org/abs/2309.15112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/internlm/internlm-xcomposer">https://github.com/internlm/internlm-xcomposer</a></li>
<li>paper_authors: Pan Zhang, Xiaoyi Dong, Bin Wang, Yuhang Cao, Chao Xu, Linke Ouyang, Zhiyuan Zhao, Shuangrui Ding, Songyang Zhang, Haodong Duan, Wenwei Zhang, Hang Yan, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, Jiaqi Wang</li>
<li>for:  This paper proposes a vision-language large model called InternLM-XComposer, which enables advanced image-text comprehension and composition.</li>
<li>methods:  The model uses interleaved text-image composition, comprehension with rich multilingual knowledge, and state-of-the-art performance.</li>
<li>results:  The model consistently achieves state-of-the-art results across various mainstream benchmarks for vision-language foundational models.Here’s the text in Simplified Chinese:</li>
<li>for: InternLM-XComposer是一个用于进行高级图文理解和组合的视觉语言大型模型。</li>
<li>methods: 该模型采用了互动的文本图像组合，以及训练在广泛的多Modal多语言概念上，以实现深刻的视觉内容理解。</li>
<li>results: 该模型在主流的视觉语言基础模型benchmark上一直保持了状态之Art的 Result。<details>
<summary>Abstract</summary>
We propose InternLM-XComposer, a vision-language large model that enables advanced image-text comprehension and composition. The innovative nature of our model is highlighted by three appealing properties: 1) Interleaved Text-Image Composition: InternLM-XComposer can effortlessly generate coherent and contextual articles that seamlessly integrate images, providing a more engaging and immersive reading experience. Simply provide a title, and our system will generate the corresponding manuscript. It can intelligently identify the areas in the text where images would enhance the content and automatically insert the most appropriate visual candidates. 2) Comprehension with Rich Multilingual Knowledge: The text-image comprehension is empowered by training on extensive multi-modal multilingual concepts with carefully crafted strategies, resulting in a deep understanding of visual content. 3) State-of-the-art Performance: Our model consistently achieves state-of-the-art results across various mainstream benchmarks for vision-language foundational models, including MME Benchmark, MMBench, MMBench-CN, Seed-Bench, and CCBench (Chinese Cultural Benchmark). Collectively, InternLM-XComposer seamlessly blends advanced text-image comprehension and composition, revolutionizing vision-language interaction and offering new insights and opportunities. The InternLM-XComposer model series with 7B parameters are publicly available at https://github.com/InternLM/InternLM-XComposer.
</details>
<details>
<summary>摘要</summary>
我们提出了InternLM-XComposer，一种视觉语言大型模型，具有先进的图文涉及和组合能力。我们的模型具有三个吸引人的特性：1. 交叉文本图像组合：InternLM-XComposer可以轻松地生成协调的和上下文相关的文章，并将图片与文本结合在一起，提供更加有趣和沉浸的阅读体验。只需提供一个标题，我们的系统将生成相应的报道。它可以智能地确定文本中需要图片的地方，并自动提供最合适的视觉候选者。2. 多语言多Modal概念的理解：图文理解受到了训练多Modal多语言概念的广泛和精心制定的策略的激进提高，从而实现了深刻的视觉内容理解。3. 状态之Art的表现：我们的模型在主流的视觉语言基础模型 benchmark 上 consistently  achieve state-of-the-art 的Results，包括 MME Benchmark、MMBench、MMBench-CN、Seed-Bench 和 CCBench（中文文化benchmark）。总之，InternLM-XComposer 具有高级的文本图像组合和理解能力，对视觉语言交互带来革命性的变革，提供新的视角和机遇。InternLM-XComposer 模型系列，包含 7B 参数，公开 disponibles 于 GitHub 上：<https://github.com/InternLM/InternLM-XComposer>。
</details></li>
</ul>
<hr>
<h2 id="DistillBEV-Boosting-Multi-Camera-3D-Object-Detection-with-Cross-Modal-Knowledge-Distillation"><a href="#DistillBEV-Boosting-Multi-Camera-3D-Object-Detection-with-Cross-Modal-Knowledge-Distillation" class="headerlink" title="DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation"></a>DistillBEV: Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15109">http://arxiv.org/abs/2309.15109</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qcraftai/distill-bev">https://github.com/qcraftai/distill-bev</a></li>
<li>paper_authors: Zeyu Wang, Dingwen Li, Chenxu Luo, Cihang Xie, Xiaodong Yang</li>
<li>for: 提高多摄像头 bird’s-eye-view（BEV）基于3D感知的性能，以便在自动驾驶行业中大量生产相机。</li>
<li>methods: 提议使用多摄像头BEV学习的学生探测器模型，通过与一个Well-trained LiDAR基于的教师探测器模型进行协同学习，以提高学生模型的表征学习能力。</li>
<li>results: 在多个表征模型上进行了广泛的测试，结果显示，我们的方法可以在nuScenes中实现state-of-the-art的性能。<details>
<summary>Abstract</summary>
3D perception based on the representations learned from multi-camera bird's-eye-view (BEV) is trending as cameras are cost-effective for mass production in autonomous driving industry. However, there exists a distinct performance gap between multi-camera BEV and LiDAR based 3D object detection. One key reason is that LiDAR captures accurate depth and other geometry measurements, while it is notoriously challenging to infer such 3D information from merely image input. In this work, we propose to boost the representation learning of a multi-camera BEV based student detector by training it to imitate the features of a well-trained LiDAR based teacher detector. We propose effective balancing strategy to enforce the student to focus on learning the crucial features from the teacher, and generalize knowledge transfer to multi-scale layers with temporal fusion. We conduct extensive evaluations on multiple representative models of multi-camera BEV. Experiments reveal that our approach renders significant improvement over the student models, leading to the state-of-the-art performance on the popular benchmark nuScenes.
</details>
<details>
<summary>摘要</summary>
三元射频（BEV）多摄像头基于的3D识别是现在自动驾驶行业中趋势，因为摄像头具有低成本的大规模生产。然而，现有的多摄像头BEV和激光激光（LiDAR）基于的3D对象检测存在显著性能差距。主要的原因在于LiDAR可以准确地测量深度和其他几何量，而从仅图像输入中抽取3D信息是极其困难的。在这种情况下，我们提议通过让学生检测器模型学习教师检测器的特征来增强多摄像头BEV的表征学习。我们提出了有效的均衡策略，使学生模型专注于学习教师模型的关键特征，并在多尺度层次进行时间融合。我们对多个代表性模型进行了广泛的实验，实验结果表明，我们的方法可以提供显著改善，使学生模型达到nuScenes上的 estado del arte性能。
</details></li>
</ul>
<hr>
<h2 id="LAVIE-High-Quality-Video-Generation-with-Cascaded-Latent-Diffusion-Models"><a href="#LAVIE-High-Quality-Video-Generation-with-Cascaded-Latent-Diffusion-Models" class="headerlink" title="LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models"></a>LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15103">http://arxiv.org/abs/2309.15103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, Yuwei Guo, Tianxing Wu, Chenyang Si, Yuming Jiang, Cunjian Chen, Chen Change Loy, Bo Dai, Dahua Lin, Yu Qiao, Ziwei Liu</li>
<li>for: 本研究旨在基于预训练的文本到图像（T2I）模型，开发高质量的文本到视频（T2V）生成模型。</li>
<li>methods: 该研究提出了LaVie框架，包括基础T2V模型、时间 interpolate模型和视频超分辨模型。具有简单的时间自注意力和扭转位坐标编码，LaVie能够有效捕捉视频数据中的时间相关性。</li>
<li>results: 对LaVie进行了广泛的实验，证明其在量和质上都达到了领先水平。此外，LaVie还能够在不同的长视频生成和个性化视频合成应用中表现出优秀的 versatility。<details>
<summary>Abstract</summary>
This work aims to learn a high-quality text-to-video (T2V) generative model by leveraging a pre-trained text-to-image (T2I) model as a basis. It is a highly desirable yet challenging task to simultaneously a) accomplish the synthesis of visually realistic and temporally coherent videos while b) preserving the strong creative generation nature of the pre-trained T2I model. To this end, we propose LaVie, an integrated video generation framework that operates on cascaded video latent diffusion models, comprising a base T2V model, a temporal interpolation model, and a video super-resolution model. Our key insights are two-fold: 1) We reveal that the incorporation of simple temporal self-attentions, coupled with rotary positional encoding, adequately captures the temporal correlations inherent in video data. 2) Additionally, we validate that the process of joint image-video fine-tuning plays a pivotal role in producing high-quality and creative outcomes. To enhance the performance of LaVie, we contribute a comprehensive and diverse video dataset named Vimeo25M, consisting of 25 million text-video pairs that prioritize quality, diversity, and aesthetic appeal. Extensive experiments demonstrate that LaVie achieves state-of-the-art performance both quantitatively and qualitatively. Furthermore, we showcase the versatility of pre-trained LaVie models in various long video generation and personalized video synthesis applications.
</details>
<details>
<summary>摘要</summary>
Our key insights are:1. Incorporating simple temporal self-attentions and rotary positional encoding effectively captures the temporal correlations in video data.2. Joint image-video fine-tuning is crucial for producing high-quality and creative outcomes.To enhance the performance of LaVie, we contribute a comprehensive and diverse video dataset named Vimeo25M, consisting of 25 million text-video pairs that prioritize quality, diversity, and aesthetic appeal. Extensive experiments demonstrate that LaVie achieves state-of-the-art performance both quantitatively and qualitatively. Additionally, we showcase the versatility of pre-trained LaVie models in various long video generation and personalized video synthesis applications.
</details></li>
</ul>
<hr>
<h2 id="Case-Study-Ensemble-Decision-Based-Annotation-of-Unconstrained-Real-Estate-Images"><a href="#Case-Study-Ensemble-Decision-Based-Annotation-of-Unconstrained-Real-Estate-Images" class="headerlink" title="Case Study: Ensemble Decision-Based Annotation of Unconstrained Real Estate Images"></a>Case Study: Ensemble Decision-Based Annotation of Unconstrained Real Estate Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15097">http://arxiv.org/abs/2309.15097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miroslav Despotovic, Zedong Zhang, Eric Stumpe, Matthias Zeppelzauer</li>
<li>for: 这个研究是为了实现房产照片标注的证明方案。</li>
<li>methods: 这个研究使用了简单迭代规律基于 semi-supervised learning 方法来标注房产照片。</li>
<li>results: 这个研究获得了实际应用中对房产照片标注的重要关键特征和单一性，以及实现 praktical 实现的重要需求。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We describe a proof-of-concept for annotating real estate images using simple iterative rule-based semi-supervised learning. In this study, we have gained important insights into the content characteristics and uniqueness of individual image classes as well as essential requirements for a practical implementation.
</details>
<details>
<summary>摘要</summary>
我们描述了一个 Proof of Concept，用于使用简单迭代规则基于 semi-supervised learning 来标注房产图片。在这项研究中，我们获得了图像类别特征和个体图像的重要理解，以及实际应用中必需的基本要求。Here's the breakdown of the translation:* 我们 (wǒmen) - we* 描述了 (pīnxiē le) - describe* 一个 (yī ge) - one* Proof of Concept (Proof of Concept)* 用于 (yòngyòu) - for* 使用 (shǐyòu) - using* 简单迭代 (jìndān diēyuè) - simple iterative* 规则基于 (guīyù jīdào) - rule-based* semi-supervised learning (semi-supervised learning)* 来 (lái) - to* 标注 (biāozhù) - annotate* 房产 (fángchǎng) - real estate* 图片 (túpǐn) - imagesNote that Simplified Chinese uses  "图片" (túpǐn) instead of "图像" (túxiàng) to refer to images. Also, "简单迭代" (jìndān diēyuè) is a more common way to say "iterative" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Video-adverb-retrieval-with-compositional-adverb-action-embeddings"><a href="#Video-adverb-retrieval-with-compositional-adverb-action-embeddings" class="headerlink" title="Video-adverb retrieval with compositional adverb-action embeddings"></a>Video-adverb retrieval with compositional adverb-action embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15086">http://arxiv.org/abs/2309.15086</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ReGaDa">https://github.com/ExplainableML/ReGaDa</a></li>
<li>paper_authors: Thomas Hummel, Otniel-Bogdan Mercea, A. Sophia Koepke, Zeynep Akata</li>
<li>for: 本研究提出了一种视频至动词概念映射（以下简称 video-to-adverb）的框架，用于实现细致的视频理解。</li>
<li>methods: 该框架使用了一种共同嵌入空间中的异常网格机制，以及一种新的训练目标，包括 triplet 损失和一个回归目标。</li>
<li>results: 该方法在最新的五个视频-动词检索 benchmark 上达到了状态的前学者性能。此外，我们还提出了一些新的数据集分裂，用于测试视频-动词检索的通用性。<details>
<summary>Abstract</summary>
Retrieving adverbs that describe an action in a video poses a crucial step towards fine-grained video understanding. We propose a framework for video-to-adverb retrieval (and vice versa) that aligns video embeddings with their matching compositional adverb-action text embedding in a joint embedding space. The compositional adverb-action text embedding is learned using a residual gating mechanism, along with a novel training objective consisting of triplet losses and a regression target. Our method achieves state-of-the-art performance on five recent benchmarks for video-adverb retrieval. Furthermore, we introduce dataset splits to benchmark video-adverb retrieval for unseen adverb-action compositions on subsets of the MSR-VTT Adverbs and ActivityNet Adverbs datasets. Our proposed framework outperforms all prior works for the generalisation task of retrieving adverbs from videos for unseen adverb-action compositions. Code and dataset splits are available at https://hummelth.github.io/ReGaDa/.
</details>
<details>
<summary>摘要</summary>
Retrieving adverbs that describe an action in a video is a crucial step towards fine-grained video understanding. We propose a framework for video-to-adverb retrieval (and vice versa) that aligns video embeddings with their matching compositional adverb-action text embeddings in a joint embedding space. The compositional adverb-action text embedding is learned using a residual gating mechanism, along with a novel training objective consisting of triplet losses and a regression target. Our method achieves state-of-the-art performance on five recent benchmarks for video-adverb retrieval. Furthermore, we introduce dataset splits to benchmark video-adverb retrieval for unseen adverb-action compositions on subsets of the MSR-VTT Adverbs and ActivityNet Adverbs datasets. Our proposed framework outperforms all prior works for the generalization task of retrieving adverbs from videos for unseen adverb-action compositions. Code and dataset splits are available at https://hummelth.github.io/ReGaDa/.Here's the translation in Traditional Chinese:取得运动动作中的动词形容词是精确的运动理解的重要步骤。我们提出了一个影像与动词形容词的对应框架，将影像嵌入与其对应的动词形容词文本嵌入在共同的嵌入空间中进行对应。我们使用了一个复零阀 mechanism来学习动词形容词文本的对应，同时使用了一个新的训练目标，包括 triplet loss 和一个回溯目标。我们的方法在五个最近的benchmark上取得了最佳性能。此外，我们还引入了一些新的数据分割，以便在未见过的动词形容词-动作compositions上进行测试。我们的提出的框架在这个测试任务中表现出色，并且超过了所有之前的工作。代码和数据分割可以在https://hummelth.github.io/ReGaDa/上取得。
</details></li>
</ul>
<hr>
<h2 id="The-Surveillance-AI-Pipeline"><a href="#The-Surveillance-AI-Pipeline" class="headerlink" title="The Surveillance AI Pipeline"></a>The Surveillance AI Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15084">http://arxiv.org/abs/2309.15084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratyusha Ria Kalluri, William Agnew, Myra Cheng, Kentrell Owens, Luca Soldaini, Abeba Birhane</li>
<li>for: 这篇论文主要写作的目的是揭露计算机视觉研究如何推动跟踪surveillance。</li>
<li>methods: 这篇论文使用了三十年的计算机视觉研究论文和下游具有专利的文献，共计超过40,000份文献进行分析，以揭露计算机视觉研究如何转化为跟踪surveillance。</li>
<li>results: 研究发现，大多数计算机视觉论文和专利都报道其技术可以提取人类数据，而且主要是提取人体和身体部位的数据。此外，研究发现了一些机构、国家和领域在计算机视觉研究中拥有较高的涉及度，这些机构、国家和领域的研究往往被用于跟踪专利。总的来说，计算机视觉研究在过去三十年内，对跟踪surveillance的应用增长了五倍以上，现已经用于超过11,000个跟踪专利。此外，研究还发现了大量的文献使用掩饰语言，以隐藏跟踪的程度。<details>
<summary>Abstract</summary>
A rapidly growing number of voices argue that AI research, and computer vision in particular, is powering mass surveillance. Yet the direct path from computer vision research to surveillance has remained obscured and difficult to assess. Here, we reveal the Surveillance AI pipeline by analyzing three decades of computer vision research papers and downstream patents, more than 40,000 documents. We find the large majority of annotated computer vision papers and patents self-report their technology enables extracting data about humans. Moreover, the majority of these technologies specifically enable extracting data about human bodies and body parts. We present both quantitative and rich qualitative analysis illuminating these practices of human data extraction. Studying the roots of this pipeline, we find that institutions that prolifically produce computer vision research, namely elite universities and "big tech" corporations, are subsequently cited in thousands of surveillance patents. Further, we find consistent evidence against the narrative that only these few rogue entities are contributing to surveillance. Rather, we expose the fieldwide norm that when an institution, nation, or subfield authors computer vision papers with downstream patents, the majority of these papers are used in surveillance patents. In total, we find the number of papers with downstream surveillance patents increased more than five-fold between the 1990s and the 2010s, with computer vision research now having been used in more than 11,000 surveillance patents. Finally, in addition to the high levels of surveillance we find documented in computer vision papers and patents, we unearth pervasive patterns of documents using language that obfuscates the extent of surveillance. Our analysis reveals the pipeline by which computer vision research has powered the ongoing expansion of surveillance.
</details>
<details>
<summary>摘要</summary>
快速增长的声音表示，人工智能研究，特别是计算机视觉，在跟踪surveillance中扮演着关键角色。然而，从计算机视觉研究直接到跟踪的路径一直保持混乱和难以评估。在这里，我们揭露了跟踪AI管道，通过分析过去三十年的计算机视觉研究文献和下游套件，涵盖了超过40,000份文档。我们发现大多数标注的计算机视觉文献和套件都自report其技术可以提取人类数据。此外，大多数这些技术都可以提取人体和身体部分数据。我们提供了丰富的质量分析，描绘这些实践。研究这些管道的源头，我们发现了著名大学和“big tech”公司在计算机视觉研究方面的强大势力，后来被引用在数千个跟踪套件中。此外，我们发现了证据，证明这些机构、国家或领域作出计算机视觉研究后，大多数文献都被用于跟踪套件。总的来说，我们发现在20世纪90年代和2010年代之间，计算机视觉研究在跟踪领域的数量增长了五倍以上，现已被用于超过11,000个跟踪套件。此外，我们发现了计算机视觉文献和套件中的高水平跟踪记录，以及文档使用掩饰跟踪的语言。我们的分析揭示了计算机视觉研究如何为跟踪提供了持续增长的能量。
</details></li>
</ul>
<hr>
<h2 id="RPEFlow-Multimodal-Fusion-of-RGB-PointCloud-Event-for-Joint-Optical-Flow-and-Scene-Flow-Estimation"><a href="#RPEFlow-Multimodal-Fusion-of-RGB-PointCloud-Event-for-Joint-Optical-Flow-and-Scene-Flow-Estimation" class="headerlink" title="RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation"></a>RPEFlow: Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15082">http://arxiv.org/abs/2309.15082</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danqu130/RPEFlow">https://github.com/danqu130/RPEFlow</a></li>
<li>paper_authors: Zhexiong Wan, Yuxin Mao, Jing Zhang, Yuchao Dai</li>
<li>for: 本研究旨在jointly estimating 2D optical flow和3D scene flow，使用RGB图像、点云和事件的多Modal Fusion。</li>
<li>methods: 我们提出了一种多Stage multimodal fusion模型，称为RPEFlow，它使用了跨模态关注拟合模块和多模态信息匹配regularization项。</li>
<li>results: 我们的模型在实验中与现有状态的 искусurz以一定的优势进行比较，并提供了一个新的synthetic dataset，以便进一步探索多模态感知的研究。<details>
<summary>Abstract</summary>
Recently, the RGB images and point clouds fusion methods have been proposed to jointly estimate 2D optical flow and 3D scene flow. However, as both conventional RGB cameras and LiDAR sensors adopt a frame-based data acquisition mechanism, their performance is limited by the fixed low sampling rates, especially in highly-dynamic scenes. By contrast, the event camera can asynchronously capture the intensity changes with a very high temporal resolution, providing complementary dynamic information of the observed scenes. In this paper, we incorporate RGB images, Point clouds and Events for joint optical flow and scene flow estimation with our proposed multi-stage multimodal fusion model, RPEFlow. First, we present an attention fusion module with a cross-attention mechanism to implicitly explore the internal cross-modal correlation for 2D and 3D branches, respectively. Second, we introduce a mutual information regularization term to explicitly model the complementary information of three modalities for effective multimodal feature learning. We also contribute a new synthetic dataset to advocate further research. Experiments on both synthetic and real datasets show that our model outperforms the existing state-of-the-art by a wide margin. Code and dataset is available at https://npucvr.github.io/RPEFlow.
</details>
<details>
<summary>摘要</summary>
最近，RGB图像和点云 fusión方法已经被提议用于同时估算2D光流和3D场景流。然而，由于传统的RGB相机和LiDAR感知器都采用帧基数据采集机制，因此其性能受到固定的低采样率的限制，特别是在高动态场景下。相反，事件摄像头可以不同步地捕捉强度变化，提供了高时间分辨率下的动态信息。在这篇论文中，我们将RGB图像、点云和事件 fusion在我们提出的多阶段多模式融合模型RPEFlow中。首先，我们提出了一种注意力融合模块，使用交叉注意力机制来隐式地探索2D和3D分支之间的内部交叉模式关系。其次，我们引入了互信息规则项来显式地模型三个感知器之间的补充信息，以便有效地学习多模式特征。我们还提供了一个新的 sintetic数据集，以促进进一步的研究。实验表明，我们的模型在实验室和真实数据集上都超过了现有状态的较好。代码和数据集可以在https://npucvr.github.io/RPEFlow上下载。
</details></li>
</ul>
<hr>
<h2 id="Language-EXtended-Indoor-SLAM-LEXIS-A-Versatile-System-for-Real-time-Visual-Scene-Understanding"><a href="#Language-EXtended-Indoor-SLAM-LEXIS-A-Versatile-System-for-Real-time-Visual-Scene-Understanding" class="headerlink" title="Language-EXtended Indoor SLAM (LEXIS): A Versatile System for Real-time Visual Scene Understanding"></a>Language-EXtended Indoor SLAM (LEXIS): A Versatile System for Real-time Visual Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15065">http://arxiv.org/abs/2309.15065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christina Kassab, Matias Mattamala, Lintong Zhang, Maurice Fallon</li>
<li>For: This paper introduces a real-time indoor Simultaneous Localization and Mapping (SLAM) system that can understand and interact with its surroundings.* Methods: The system uses Large Language Models (LLMs) to create a unified approach to scene understanding and place recognition, including visual-inertial odometry and Contrastive Language-Image Pretraining (CLIP) features.* Results: The system successfully categorizes rooms with varying layouts and dimensions and outperforms the state-of-the-art (SOTA) for place recognition and trajectory estimation tasks. Additionally, it demonstrates the potential for planning.Here is the same information in Simplified Chinese:* For: 这篇论文介绍了一个实时indoor Simultaneous Localization and Mapping（SLAM）系统，它可以理解和与周围环境交互。* Methods: 该系统使用大型自然语言模型（LLMs）创建一种统一的场景理解和地点识别方法，包括视觉感知和语言图像预训练（CLIP）特征。* Results: 该系统成功分类具有不同布局和尺寸的房间，并超越了当前最佳（SOTA）的地点识别和轨迹估计任务。它还 demonstrably potential for planning。<details>
<summary>Abstract</summary>
Versatile and adaptive semantic understanding would enable autonomous systems to comprehend and interact with their surroundings. Existing fixed-class models limit the adaptability of indoor mobile and assistive autonomous systems. In this work, we introduce LEXIS, a real-time indoor Simultaneous Localization and Mapping (SLAM) system that harnesses the open-vocabulary nature of Large Language Models (LLMs) to create a unified approach to scene understanding and place recognition. The approach first builds a topological SLAM graph of the environment (using visual-inertial odometry) and embeds Contrastive Language-Image Pretraining (CLIP) features in the graph nodes. We use this representation for flexible room classification and segmentation, serving as a basis for room-centric place recognition. This allows loop closure searches to be directed towards semantically relevant places. Our proposed system is evaluated using both public, simulated data and real-world data, covering office and home environments. It successfully categorizes rooms with varying layouts and dimensions and outperforms the state-of-the-art (SOTA). For place recognition and trajectory estimation tasks we achieve equivalent performance to the SOTA, all also utilizing the same pre-trained model. Lastly, we demonstrate the system's potential for planning.
</details>
<details>
<summary>摘要</summary>
自适应和多元的语义理解能使自动化系统更好地理解和与周围环境交互。现有的固定类型模型限制了室内移动和助手自动化系统的适应性。在这项工作中，我们介绍了LEXIS，一种实时室内同时地图和定位（SLAM）系统，利用大型语言模型（LLMs）的开放词汇性来创建一种综合的场景理解和地点识别方法。该方法首先建立了环境中的Topological SLAM图（使用视觉-陀螺偏移），并将语音-图像预训练（CLIP）特征embed在图节点中。我们使用这种表示来进行flexible房间分类和分割，作为基础 для房间中心的地点识别。这使得循环关闭搜索可以 dirigir towards semantically relevant places。我们提posed系统被评估使用公共、 simulate数据和实际数据，覆盖办公室和家庭环境。它成功地分类了不同的布局和维度的房间，并超过了当前最佳（SOTA）。 для地点识别和轨迹估计任务，我们 achieveequivalent performance to SOTA，alls utilizing the same pre-trained model。最后，我们示出了系统的规划潜力。
</details></li>
</ul>
<hr>
<h2 id="HPCR-Holistic-Proxy-based-Contrastive-Replay-for-Online-Continual-Learning"><a href="#HPCR-Holistic-Proxy-based-Contrastive-Replay-for-Online-Continual-Learning" class="headerlink" title="HPCR: Holistic Proxy-based Contrastive Replay for Online Continual Learning"></a>HPCR: Holistic Proxy-based Contrastive Replay for Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15038">http://arxiv.org/abs/2309.15038</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/felixhuiweilin/pcr">https://github.com/felixhuiweilin/pcr</a></li>
<li>paper_authors: Huiwei Lin, Shanshan Feng, Baoquan Zhang, Xutao Li, Yew-soon Ong, Yunming Ye<br>for: This paper aims to address the catastrophic forgetting issue in online continual learning (OCL) by proposing a novel replay-based method called proxy-based contrastive replay (PCR) and a more advanced method named holistic proxy-based contrastive replay (HPCR).methods: The proposed methods use a contrastive-based loss with anchor-to-proxy pairs instead of anchor-to-sample pairs to alleviate the forgetting issue. The HPCR method consists of three components: a contrastive component, a temperature component, and a distillation component.results: The proposed methods are evaluated on four datasets and consistently demonstrate superior performance over various state-of-the-art methods.<details>
<summary>Abstract</summary>
Online continual learning (OCL) aims to continuously learn new data from a single pass over the online data stream. It generally suffers from the catastrophic forgetting issue. Existing replay-based methods effectively alleviate this issue by replaying part of old data in a proxy-based or contrastive-based replay manner. In this paper, we conduct a comprehensive analysis of these two replay manners and find they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR), which replaces anchor-to-sample pairs with anchor-to-proxy pairs in the contrastive-based loss to alleviate the phenomenon of forgetting. Based on PCR, we further develop a more advanced method named holistic proxy-based contrastive replay (HPCR), which consists of three components. The contrastive component conditionally incorporates anchor-to-sample pairs to PCR, learning more fine-grained semantic information with a large training batch. The second is a temperature component that decouples the temperature coefficient into two parts based on their impacts on the gradient and sets different values for them to learn more novel knowledge. The third is a distillation component that constrains the learning process to keep more historical knowledge. Experiments on four datasets consistently demonstrate the superiority of HPCR over various state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
在线持续学习（OCL）目标是在单次在线数据流中不断学习新数据。它通常受到忘却问题的困扰。现有的重播基本方法有效地解决这个问题，其中包括在代理基于的重播方式和对比基于的重播方式。在这篇论文中，我们进行了这两种重播方法的全面分析，发现它们可以补做。 inspirited by this finding，我们提出了一种新的重播基本方法，即代理基于对比重播（PCR），它将 anchor-to-sample 对替换为 anchor-to-proxy 对在对比基于的损失函数中，以解决忘却现象。基于 PCR，我们进一步开发了一种更高级的方法，即整体代理基于对比重播（HPCR），它包括三个 ком成分。第一是对比成分，它在大训练批处理中 conditionally 包含 anchor-to-sample 对，以学习更细致的semantic信息。第二是温度成分，它将温度系数分解为两个部分，根据它们对梯度的影响，并将其设置为不同的值，以学习更多的新知识。第三是馈送成分，它使得学习过程中保留更多的历史知识。实验结果表明，HPCR 在四个数据集上相比多种当前的方法表现出色。
</details></li>
</ul>
<hr>
<h2 id="Nuclear-Morphometry-using-a-Deep-Learning-based-Algorithm-has-Prognostic-Relevance-for-Canine-Cutaneous-Mast-Cell-Tumors"><a href="#Nuclear-Morphometry-using-a-Deep-Learning-based-Algorithm-has-Prognostic-Relevance-for-Canine-Cutaneous-Mast-Cell-Tumors" class="headerlink" title="Nuclear Morphometry using a Deep Learning-based Algorithm has Prognostic Relevance for Canine Cutaneous Mast Cell Tumors"></a>Nuclear Morphometry using a Deep Learning-based Algorithm has Prognostic Relevance for Canine Cutaneous Mast Cell Tumors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15031">http://arxiv.org/abs/2309.15031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Haghofer, Eda Parlak, Alexander Bartel, Taryn A. Donovan, Charles-Antoine Assenmacher, Pompei Bolfa, Michael J. Dark, Andrea Fuchs-Baumgartinger, Andrea Klang, Kathrin Jäger, Robert Klopfleisch, Sophie Merz, Barbara Richter, F. Yvonne Schulman, Jonathan Ganz, Josef Scharinger, Marc Aubreville, Stephan M. Winkler, Matti Kiupel, Christof A. Bertram</li>
<li>for: 这个研究是为了评估自动化形态学在犬肉瘤细胞肿瘤中的预后价值。</li>
<li>methods: 这个研究使用了深度学习算法来自动地测量细胞核的大小和形状，并与人工测量和Pathologist估计的核大小进行比较。</li>
<li>results: 研究发现，自动化形态学的报告值与人工测量和Pathologist估计的核大小有高度相关性，且其预后价值也较高。在ROC曲线中，自动化形态学的AUC值为0.943（95% CI：0.889-0.996），高于人工测量和mitotic count。此外，自动化形态学还可以提供较高的特异性和低的内涵相关性。<details>
<summary>Abstract</summary>
Variation in nuclear size and shape is an important criterion of malignancy for many tumor types; however, categorical estimates by pathologists have poor reproducibility. Measurements of nuclear characteristics (morphometry) can improve reproducibility, but manual methods are time consuming. In this study, we evaluated fully automated morphometry using a deep learning-based algorithm in 96 canine cutaneous mast cell tumors with information on patient survival. Algorithmic morphometry was compared with karyomegaly estimates by 11 pathologists, manual nuclear morphometry of 12 cells by 9 pathologists, and the mitotic count as a benchmark. The prognostic value of automated morphometry was high with an area under the ROC curve regarding the tumor-specific survival of 0.943 (95% CI: 0.889 - 0.996) for the standard deviation (SD) of nuclear area, which was higher than manual morphometry of all pathologists combined (0.868, 95% CI: 0.737 - 0.991) and the mitotic count (0.885, 95% CI: 0.765 - 1.00). At the proposed thresholds, the hazard ratio for algorithmic morphometry (SD of nuclear area $\geq 9.0 \mu m^2$) was 18.3 (95% CI: 5.0 - 67.1), for manual morphometry (SD of nuclear area $\geq 10.9 \mu m^2$) 9.0 (95% CI: 6.0 - 13.4), for karyomegaly estimates 7.6 (95% CI: 5.7 - 10.1), and for the mitotic count 30.5 (95% CI: 7.8 - 118.0). Inter-rater reproducibility for karyomegaly estimates was fair ($\kappa$ = 0.226) with highly variable sensitivity/specificity values for the individual pathologists. Reproducibility for manual morphometry (SD of nuclear area) was good (ICC = 0.654). This study supports the use of algorithmic morphometry as a prognostic test to overcome the limitations of estimates and manual measurements.
</details>
<details>
<summary>摘要</summary>
干细胞癌的核体大小和形状的变化是许多肿瘤类型的恶性性的重要依据，但是专业人员的 categorical 估计具有低的重建性。使用measurements of nuclear characteristics（ morphometry）可以提高重建性，但是手动方法需要很多时间。在这个研究中，我们对96只犬尖锐皮癌细胞的自动化 morphometry 使用了深度学习基于的算法，并与11名医生的 karyomegaly 估计、12名医生手动的核体形态和 Mitotic count 作为参照进行比较。自动化 morphometry 的预测价值很高，ROC 曲线的面积为0.943（95% CI：0.889-0.996），而手动 morphometry 的所有医生合计的预测价值为0.868（95% CI：0.737-0.991）， Mitotic count 的预测价值为0.885（95% CI：0.765-1.00）。在提出的阈值下，自动化 morphometry（核体面积SD≥9.0μm²）的 Hazard ratio 为18.3（95% CI：5.0-67.1），手动 morphometry（核体面积SD≥10.9μm²）的 Hazard ratio 为9.0（95% CI：6.0-13.4）， karyomegaly 估计的 Hazard ratio 为7.6（95% CI：5.7-10.1）， Mitotic count 的 Hazard ratio 为30.5（95% CI：7.8-118.0）。医生之间的 karyomegaly 估计的重建性只有 fair（κ=0.226），而手动 morphometry（核体面积SD）的重建性为good（ICC=0.654）。这种研究支持使用自动化 morphometry 作为诊断的方法，以超越估计和手动测量的限制。
</details></li>
</ul>
<hr>
<h2 id="IFT-Image-Fusion-Transformer-for-Ghost-free-High-Dynamic-Range-Imaging"><a href="#IFT-Image-Fusion-Transformer-for-Ghost-free-High-Dynamic-Range-Imaging" class="headerlink" title="IFT: Image Fusion Transformer for Ghost-free High Dynamic Range Imaging"></a>IFT: Image Fusion Transformer for Ghost-free High Dynamic Range Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15019">http://arxiv.org/abs/2309.15019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hailing Wang, Wei Li, Yuanyuan Xi, Jie Hu, Hanting Chen, Longyu Li, Yunhe Wang</li>
<li>for: 高动态范围多帧图像重建无幽霾图像，以提供具有 фото真实细节的内容相似但空间不一致的低动态范围图像。</li>
<li>methods: 提议一种图像融合变换器（IFT），包括快速全球补做搜索（FGPS）模块和自我交叠融合模块（SCF），用于生成无幽霾的HDR图像。 FGPS模块在参照帧中搜索与参照帧中的每个patch相似的patch，以模型长距离依赖关系；SCF模块在patch上进行了内部Feature融合和交叠Feature融合，以降低输入分辨率的线性复杂度。</li>
<li>results: 对多个标准 benchmark进行了广泛的实验，并达到了现有方法的状态空间性能。<details>
<summary>Abstract</summary>
Multi-frame high dynamic range (HDR) imaging aims to reconstruct ghost-free images with photo-realistic details from content-complementary but spatially misaligned low dynamic range (LDR) images. Existing HDR algorithms are prone to producing ghosting artifacts as their methods fail to capture long-range dependencies between LDR frames with large motion in dynamic scenes. To address this issue, we propose a novel image fusion transformer, referred to as IFT, which presents a fast global patch searching (FGPS) module followed by a self-cross fusion module (SCF) for ghost-free HDR imaging. The FGPS searches the patches from supporting frames that have the closest dependency to each patch of the reference frame for long-range dependency modeling, while the SCF conducts intra-frame and inter-frame feature fusion on the patches obtained by the FGPS with linear complexity to input resolution. By matching similar patches between frames, objects with large motion ranges in dynamic scenes can be aligned, which can effectively alleviate the generation of artifacts. In addition, the proposed FGPS and SCF can be integrated into various deep HDR methods as efficient plug-in modules. Extensive experiments on multiple benchmarks show that our method achieves state-of-the-art performance both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
多帧高动态范围（HDR）捕捉目标是从内容相似仍然空间不一致的低动态范围（LDR）图像中重建无幻象 artifacts 图像，而现有的HDR算法容易产生幻象痕迹，因为它们的方法无法捕捉动态场景中大动量的长距离依赖关系。为解决这个问题，我们提议一种新的图像融合变换器，称为IFT，它包括一个快速全局小块搜索（FGPS）模块和一个自我交叉融合模块（SCF），用于无幻象HDR捕捉。FGPS模块在支持图像中搜索与参照图像中每个小块相似的小块，以模拟长距离依赖关系，而SCF模块在获得FGPS模块中的小块后，通过线性复杂度来进行内部Feature fusion和间接Feature fusion，使得对象在动态场景中的大动量可以得到准确的对齐，从而有效地避免生成artefacts。此外，我们的FGPS和SCF模块可以与多种深度HDR方法集成为高效插件模块。我们在多个标准底图上进行了广泛的实验，结果表明，我们的方法在量和质量两个方面均达到了领先的性能。
</details></li>
</ul>
<hr>
<h2 id="Object-Centric-Open-Vocabulary-Image-Retrieval-with-Aggregated-Features"><a href="#Object-Centric-Open-Vocabulary-Image-Retrieval-with-Aggregated-Features" class="headerlink" title="Object-Centric Open-Vocabulary Image-Retrieval with Aggregated Features"></a>Object-Centric Open-Vocabulary Image-Retrieval with Aggregated Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14999">http://arxiv.org/abs/2309.14999</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeniSoida/pl1">https://github.com/zeniSoida/pl1</a></li>
<li>paper_authors: Hila Levi, Guy Heller, Dan Levi, Ethan Fetaya</li>
<li>for: 这个研究的目的是提高开放词汇图像搜寻的效率，以便更好地搜寻具有特定物品的图像。</li>
<li>methods: 这个研究使用了 dense embedding 技术，将 CLIP 中的对象标注为 dense embedding，并将这些对象 embedding 聚合为一个简洁的表示。</li>
<li>results: 这个研究比较 global feature 方法，在三个 dataset 上 achieved 15 mAP 点更高的准确率。它还证明了其可扩展性和可解释性。<details>
<summary>Abstract</summary>
The task of open-vocabulary object-centric image retrieval involves the retrieval of images containing a specified object of interest, delineated by an open-set text query. As working on large image datasets becomes standard, solving this task efficiently has gained significant practical importance. Applications include targeted performance analysis of retrieved images using ad-hoc queries and hard example mining during training. Recent advancements in contrastive-based open vocabulary systems have yielded remarkable breakthroughs, facilitating large-scale open vocabulary image retrieval. However, these approaches use a single global embedding per image, thereby constraining the system's ability to retrieve images containing relatively small object instances. Alternatively, incorporating local embeddings from detection pipelines faces scalability challenges, making it unsuitable for retrieval from large databases.   In this work, we present a simple yet effective approach to object-centric open-vocabulary image retrieval. Our approach aggregates dense embeddings extracted from CLIP into a compact representation, essentially combining the scalability of image retrieval pipelines with the object identification capabilities of dense detection methods. We show the effectiveness of our scheme to the task by achieving significantly better results than global feature approaches on three datasets, increasing accuracy by up to 15 mAP points. We further integrate our scheme into a large scale retrieval framework and demonstrate our method's advantages in terms of scalability and interpretability.
</details>
<details>
<summary>摘要</summary>
开放词汇物体固定图像检索任务是将图像包含指定的目标物体，通过开放集文本查询来定义。随着图像数据集的大小增长，解决这个任务得到了实际上的重要性。应用包括基于自定义查询和训练中的困难例挖掘。近期，基于对比学习的开放词汇系统取得了很大的突破，使得大规模的开放词汇图像检索成为可能。然而，这些方法使用单个全局嵌入，因此无法检索包含相对较小的物体实例的图像。另一方面，从检测管道中提取本地嵌入也面临着扩展性挑战，使其不适用于大规模的图像检索。在这项工作中，我们提出了一种简单又有效的物体固定图像检索方法。我们的方法将CLIP中提取的密集嵌入聚合到一个紧凑的表示中，实际上将图像检索管道的扩展性与密集检测方法的物体识别能力相结合。我们证明了我们的方法在三个数据集上比全球特征方法提高了15个mAP点。此外，我们还将我们的方法integrirated into a large-scale retrieval framework，并证明了我们的方法在扩展性和可读性方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="An-Ensemble-Model-for-Distorted-Images-in-Real-Scenarios"><a href="#An-Ensemble-Model-for-Distorted-Images-in-Real-Scenarios" class="headerlink" title="An Ensemble Model for Distorted Images in Real Scenarios"></a>An Ensemble Model for Distorted Images in Real Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14998">http://arxiv.org/abs/2309.14998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boyuan Ji, Jianchang Huang, Wenzhuo Huang, Shuke He</li>
<li>for: 实现高级Computer Vision任务中的影像捕捉条件和环境的影响，并且训练在不具有扭曲的数据集上的大多数Computer Vision算法将会受到限制。即使对硬件进行更新，如感应器和深度学习方法，在实际应用中仍然无法应对变化的环境和条件。</li>
<li>methods: 我们运用了物件探测器YOLOv7来探测CDCOCO数据集上的扭曲图像。我们运用了精心设计的优化，包括数据增强、检测盒 ensemble、降噪模型、超解析模型和转移学习，使我们的模型在CDCOCO测试集上表现出色。我们的降噪检测模型可以对扭曲图像进行降噪和修复，使得模型在实际应用中有很多实际应用场景和环境。</li>
<li>results: 我们的模型在CDCOCO测试集上表现出色，实现了高级Computer Vision任务中的影像捕捉和识别。我们的降噪检测模型可以对扭曲图像进行降噪和修复，使得模型在实际应用中有很多实际应用场景和环境。<details>
<summary>Abstract</summary>
Image acquisition conditions and environments can significantly affect high-level tasks in computer vision, and the performance of most computer vision algorithms will be limited when trained on distortion-free datasets. Even with updates in hardware such as sensors and deep learning methods, it will still not work in the face of variable conditions in real-world applications. In this paper, we apply the object detector YOLOv7 to detect distorted images from the dataset CDCOCO. Through carefully designed optimizations including data enhancement, detection box ensemble, denoiser ensemble, super-resolution models, and transfer learning, our model achieves excellent performance on the CDCOCO test set. Our denoising detection model can denoise and repair distorted images, making the model useful in a variety of real-world scenarios and environments.
</details>
<details>
<summary>摘要</summary>
computer vision 高级任务的图像获取条件和环境可能会有显著影响，而大多数计算机视觉算法在不受扭曲影响的数据集上训练时会表现有限。即使升级硬件如感知器和深度学习方法，在实际应用中仍然无法满足变化的条件。在这篇论文中，我们将对 CDCOCO 数据集中的扭曲图像进行探测，使用了优化的数据增强、检测盒集合、除噪集合、超分解模型和传输学习等技术，我们的模型在 CDCOCO 测试集上表现出色。我们的噪声检测模型可以将扭曲图像去噪和修复，使得模型在多种实际应用环境中变得有用。
</details></li>
</ul>
<hr>
<h2 id="IAIFNet-An-Illumination-Aware-Infrared-and-Visible-Image-Fusion-Network"><a href="#IAIFNet-An-Illumination-Aware-Infrared-and-Visible-Image-Fusion-Network" class="headerlink" title="IAIFNet: An Illumination-Aware Infrared and Visible Image Fusion Network"></a>IAIFNet: An Illumination-Aware Infrared and Visible Image Fusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14997">http://arxiv.org/abs/2309.14997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Yang, Yu Zhang, Jian Zhang, Zijing Zhao, Shunli Zhang, Jinqiao Wang, Junzhe Chen</li>
<li>for: 提高低光照环境下图像融合的质量</li>
<li>methods: 使用抗阴影增强网络和自适应差分融合模块以及焦点意识模块</li>
<li>results: 比较五种现有方法，实验结果表明该方法可以提高低光照环境下图像融合的质量<details>
<summary>Abstract</summary>
Infrared and visible image fusion (IVIF) is used to generate fusion images with comprehensive features of both images, which is beneficial for downstream vision tasks. However, current methods rarely consider the illumination condition in low-light environments, and the targets in the fused images are often not prominent. To address the above issues, we propose an Illumination-Aware Infrared and Visible Image Fusion Network, named as IAIFNet. In our framework, an illumination enhancement network first estimates the incident illumination maps of input images. Afterwards, with the help of proposed adaptive differential fusion module (ADFM) and salient target aware module (STAM), an image fusion network effectively integrates the salient features of the illumination-enhanced infrared and visible images into a fusion image of high visual quality. Extensive experimental results verify that our method outperforms five state-of-the-art methods of fusing infrared and visible images.
</details>
<details>
<summary>摘要</summary>
射频和可见像融合（IVIF）是用来生成具有两个图像完整特征的融合图像，对下游视觉任务有利。然而，目前的方法几乎不考虑低光环境中的照明条件，目标在融合图像中也很难发掘。为了解决这些问题，我们提出了对照明意识的射频和可见像融合网络，名为IAIFNet。在我们的框架中，照明增强网first estimates input图像的进入照明地图。然后，透过我们提出的适应式差分融合模组（ADFM）和焦点意识模组（STAM），图像融合网络将融合两个照明增强的射频和可见像的焦点特征，生成高质量的融合图像。实验结果显示，我们的方法比五种现有的融合方法性能更高。
</details></li>
</ul>
<hr>
<h2 id="Robust-Sequential-DeepFake-Detection"><a href="#Robust-Sequential-DeepFake-Detection" class="headerlink" title="Robust Sequential DeepFake Detection"></a>Robust Sequential DeepFake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14991">http://arxiv.org/abs/2309.14991</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rshaojimmy/seqdeepfake">https://github.com/rshaojimmy/seqdeepfake</a></li>
<li>paper_authors: Rui Shao, Tianxing Wu, Ziwei Liu<br>for: 这篇论文目的是为了探讨深伪攻击（DeepFake）的新型威胁，即多步骤脸部修改（Sequential DeepFake），并提出了一个新的研究问题——检测sequential DeepFake manipulation（Seq-DeepFake）。methods: 这篇论文使用了一个新的dataset——Seq-DeepFake dataset，并提出了一个专门针对Seq-DeepFake manipulation的问题，casting it as an image-to-sequence task。furthermore, the authors proposed a concise yet effective Seq-DeepFake Transformer (SeqFakeFormer) and a dedicated Seq-DeepFake Transformer with Image-Sequence Reasoning (SeqFakeFormer++) to better detect Seq-DeepFake manipulation.results: 根据实验结果，SeqFakeFormer和SeqFakeFormer++ Both show strong performance on the Seq-DeepFake dataset and the more challenging Sequential DeepFake dataset with perturbations (Seq-DeepFake-P)，demonstrating their effectiveness in detecting Seq-DeepFake manipulation.<details>
<summary>Abstract</summary>
Since photorealistic faces can be readily generated by facial manipulation technologies nowadays, potential malicious abuse of these technologies has drawn great concerns. Numerous deepfake detection methods are thus proposed. However, existing methods only focus on detecting one-step facial manipulation. As the emergence of easy-accessible facial editing applications, people can easily manipulate facial components using multi-step operations in a sequential manner. This new threat requires us to detect a sequence of facial manipulations, which is vital for both detecting deepfake media and recovering original faces afterwards. Motivated by this observation, we emphasize the need and propose a novel research problem called Detecting Sequential DeepFake Manipulation (Seq-DeepFake). Unlike the existing deepfake detection task only demanding a binary label prediction, detecting Seq-DeepFake manipulation requires correctly predicting a sequential vector of facial manipulation operations. To support a large-scale investigation, we construct the first Seq-DeepFake dataset, where face images are manipulated sequentially with corresponding annotations of sequential facial manipulation vectors. Based on this new dataset, we cast detecting Seq-DeepFake manipulation as a specific image-to-sequence task and propose a concise yet effective Seq-DeepFake Transformer (SeqFakeFormer). To better reflect real-world deepfake data distributions, we further apply various perturbations on the original Seq-DeepFake dataset and construct the more challenging Sequential DeepFake dataset with perturbations (Seq-DeepFake-P). To exploit deeper correlation between images and sequences when facing Seq-DeepFake-P, a dedicated Seq-DeepFake Transformer with Image-Sequence Reasoning (SeqFakeFormer++) is devised, which builds stronger correspondence between image-sequence pairs for more robust Seq-DeepFake detection.
</details>
<details>
<summary>摘要</summary>
因为现在可以轻松地通过图像修改技术生成真实的人脸，这已经引起了严重的风险。许多深伪检测方法已经被提出，但是这些方法只关注一步图像修改。然而，随着易 accessible 的人脸编辑应用程序的出现，人们可以通过多步操作Sequentially manipulate facial components。这种新的威胁需要我们检测一个序列的图像修改，这是检测深伪媒体以及恢复原始人脸的关键。我们根据这一观察，提出了一个新的研究问题：检测串行深伪修改（Seq-DeepFake）。与传统的深伪检测任务只需要对图像进行二分类预测而言，检测 Seq-DeepFake 修改需要正确地预测一个序列的facial manipulation vector。为支持大规模的调查，我们构建了第一个 Seq-DeepFake 数据集，其中每个人脸图像都被Sequentially manipulate，并且对应的涉及到Sequential facial manipulation vector的注释。基于这个新数据集，我们将检测 Seq-DeepFake 修改定义为图像到序列任务，并提出了一种简洁 yet effective 的 Seq-DeepFake Transformer（SeqFakeFormer）。为更好地反映实际深伪数据分布，我们还对原始 Seq-DeepFake 数据集进行了多种杂化，并构建了更加具有挑战性的 Sequential DeepFake 数据集（Seq-DeepFake-P）。面临 Seq-DeepFake-P 数据集时，我们提出了一种专门为image-sequence pairs建立更强的相关性的Seq-DeepFake Transformer with Image-Sequence Reasoning（SeqFakeFormer++），以更好地利用图像和序列之间的深刻相关性，从而提高 Seq-DeepFake 检测的Robustness。
</details></li>
</ul>
<hr>
<h2 id="MoCaE-Mixture-of-Calibrated-Experts-Significantly-Improves-Object-Detection"><a href="#MoCaE-Mixture-of-Calibrated-Experts-Significantly-Improves-Object-Detection" class="headerlink" title="MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection"></a>MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14976">http://arxiv.org/abs/2309.14976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kemal Oksuz, Selim Kuzucu, Tom Joy, Puneet K. Dokania</li>
<li>for: 提高对象检测的精度和稳定性</li>
<li>methods: 使用混合尝试（MoE）和准确混合（Calibration）技术，对不同的对象检测器进行匹配和筛选，以提高总的检测精度</li>
<li>results: 在COCO测试数据集上提高了对象检测的AP值$2.4$，在 LVIS数据集上提高了实例分割的AP值$2.3$，在DOTA数据集上提高了旋转对象检测的AP值$82.62$，全部实现了新的最佳状态（SOTA）<details>
<summary>Abstract</summary>
We propose an extremely simple and highly effective approach to faithfully combine different object detectors to obtain a Mixture of Experts (MoE) that has a superior accuracy to the individual experts in the mixture. We find that naively combining these experts in a similar way to the well-known Deep Ensembles (DEs), does not result in an effective MoE. We identify the incompatibility between the confidence score distribution of different detectors to be the primary reason for such failure cases. Therefore, to construct the MoE, our proposal is to first calibrate each individual detector against a target calibration function. Then, filter and refine all the predictions from different detectors in the mixture. We term this approach as MoCaE and demonstrate its effectiveness through extensive experiments on object detection, instance segmentation and rotated object detection tasks. Specifically, MoCaE improves (i) three strong object detectors on COCO test-dev by $2.4$ $\mathrm{AP}$ by reaching $59.0$ $\mathrm{AP}$; (ii) instance segmentation methods on the challenging long-tailed LVIS dataset by $2.3$ $\mathrm{AP}$; and (iii) all existing rotated object detectors by reaching $82.62$ $\mathrm{AP_{50}$ on DOTA dataset, establishing a new state-of-the-art (SOTA). Code will be made public.
</details>
<details>
<summary>摘要</summary>
我们提出一种非常简单且高效的方法，以混合不同的对象探测器来建立一个混合experts（MoE），以提高各个专家的精度。我们发现，将这些专家集成在类似于知名的深度ensemble（DE）中，并不能达到有效的混合。我们认为，不同探测器的信任分布不兼容是主要的原因。因此，为建立MoE，我们的建议是首先对每个个体探测器进行对目标准化函数的调整。然后，对不同探测器的所有预测进行筛选和精度调整。我们称这种方法为MoCaE，并通过了详细的实验，证明其效果。具体来说，MoCaE可以提高COCO测试开发集的三个强对象探测器的AP分数by 2.4，达到59.0AP；在挑战性的长尾LVIS数据集上提高实例分割方法的AP分数by 2.3；以及在DOTA数据集上所有旋转对象探测器的AP50分数by 82.62，创造了新的状态之状态（SOTA）。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="A-novel-approach-for-holographic-3D-content-generation-without-depth-map"><a href="#A-novel-approach-for-holographic-3D-content-generation-without-depth-map" class="headerlink" title="A novel approach for holographic 3D content generation without depth map"></a>A novel approach for holographic 3D content generation without depth map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14967">http://arxiv.org/abs/2309.14967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hakdong Kim, Minkyu Jee, Yurim Lee, Kyudam Choi, MinSung Yoon, Cheongwon Kim</li>
<li>for: 用于生成计算机生成镜像（CGH），使用FFT算法。</li>
<li>methods: 使用深度学习方法，只使用输入RGB图像来估计图像的深度图，然后生成CGH。</li>
<li>results: 对比与其他模型，提出的方法可以更加准确地生成镜像，只使用RGB色度数据。<details>
<summary>Abstract</summary>
In preparation for observing holographic 3D content, acquiring a set of RGB color and depth map images per scene is necessary to generate computer-generated holograms (CGHs) when using the fast Fourier transform (FFT) algorithm. However, in real-world situations, these paired formats of RGB color and depth map images are not always fully available. We propose a deep learning-based method to synthesize the volumetric digital holograms using only the given RGB image, so that we can overcome environments where RGB color and depth map images are partially provided. The proposed method uses only the input of RGB image to estimate its depth map and then generate its CGH sequentially. Through experiments, we demonstrate that the volumetric hologram generated through our proposed model is more accurate than that of competitive models, under the situation that only RGB color data can be provided.
</details>
<details>
<summary>摘要</summary>
要观看幻象三维内容，需要获取每个场景的RGB颜色和深度地图图像集。使用快速傅立勋变换算法时，这对计算机生成镜像（CGH）的生成是必要的。然而，在实际情况下，这对RGB颜色和深度地图图像的对应形式不总是可用。我们提出了一种基于深度学习的方法，可以使用只提供RGB图像来生成三维数字镜像，以便在RGB颜色和深度地图图像不完整提供的情况下进行覆盖。该方法只需要输入RGB图像，并且可以逐步生成其CGH。经过实验，我们证明了我们提出的模型可以在RGB颜色数据仅提供的情况下生成更加准确的幻象镜像，比与竞争模型更好。
</details></li>
</ul>
<hr>
<h2 id="GridFormer-Towards-Accurate-Table-Structure-Recognition-via-Grid-Prediction"><a href="#GridFormer-Towards-Accurate-Table-Structure-Recognition-via-Grid-Prediction" class="headerlink" title="GridFormer: Towards Accurate Table Structure Recognition via Grid Prediction"></a>GridFormer: Towards Accurate Table Structure Recognition via Grid Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14962">http://arxiv.org/abs/2309.14962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengyuan Lyu, Weihong Ma, Hongyi Wang, Yuechen Yu, Chengquan Zhang, Kun Yao, Yang Xue, Jingdong Wang</li>
<li>for: 理解无约束表格结构</li>
<li>methods: 提出了一种新的GridFormer方法，通过预测Grid中的顶点和边来解释无约束表格结构</li>
<li>results: 在五个具有困难性的benchmark上实现了与其他方法相比竞争性的表现<details>
<summary>Abstract</summary>
All tables can be represented as grids. Based on this observation, we propose GridFormer, a novel approach for interpreting unconstrained table structures by predicting the vertex and edge of a grid. First, we propose a flexible table representation in the form of an MXN grid. In this representation, the vertexes and edges of the grid store the localization and adjacency information of the table. Then, we introduce a DETR-style table structure recognizer to efficiently predict this multi-objective information of the grid in a single shot. Specifically, given a set of learned row and column queries, the recognizer directly outputs the vertexes and edges information of the corresponding rows and columns. Extensive experiments on five challenging benchmarks which include wired, wireless, multi-merge-cell, oriented, and distorted tables demonstrate the competitive performance of our model over other methods.
</details>
<details>
<summary>摘要</summary>
所有表格都可以表示为格子。基于这一观察，我们提出了GridFormer，一种新的方法，用于解释不受限制的表格结构，通过预测格子的顶点和边。首先，我们提出了一种灵活的表格表示方式，即MXN格子。在这种表示方式中，格子的顶点和边存储了表格的本地化和相邻信息。然后，我们引入了DETR风格的表结构识别器，以高效地预测这些多对象信息。specifically，给定一组学习的行和列查询，识别器直接输出了相应的行和列的顶点和边信息。我们在五个具有挑战性的标准化表格 benchmark上进行了广泛的实验，并证明了我们的模型在其他方法之上具有竞争性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-World-Test-Time-Adaptation-Tri-Net-Self-Training-with-Balanced-Normalization"><a href="#Towards-Real-World-Test-Time-Adaptation-Tri-Net-Self-Training-with-Balanced-Normalization" class="headerlink" title="Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization"></a>Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14949">http://arxiv.org/abs/2309.14949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gorilla-lab-scut/tribe">https://github.com/gorilla-lab-scut/tribe</a></li>
<li>paper_authors: Yongyi Su, Xun Xu, Kui Jia</li>
<li>for: 这个研究的目的是对于实际世界的测试过程进行时间适应，以适应未见过的损坏。</li>
<li>methods: 这个研究使用了globally class imbalanced testing set来补充现有的实际世界时间适应协议，并示出了现有方法在不同的测试设定下的缺陷。它们还提出了一个叫做平衡batchnorm层的新方法，可以在测试过程中适应而不偏向多数类别。此外，它们还参考了自适应（ST）的成功，并将其应用于时间适应。但是，ST独立使用可能会导致过度适应，因此它们提出了一个称为anchored loss的调整方法，以避免过度适应。</li>
<li>results: 这个研究建立了一个名为TRIBE的统一架构，其中包括平衡batchnorm层。TRIBE在四个实际世界时间适应设定中进行评估，并在多个评估协议下表现出了州际的最佳成绩。<details>
<summary>Abstract</summary>
Test-Time Adaptation aims to adapt source domain model to testing data at inference stage with success demonstrated in adapting to unseen corruptions. However, these attempts may fail under more challenging real-world scenarios. Existing works mainly consider real-world test-time adaptation under non-i.i.d. data stream and continual domain shift. In this work, we first complement the existing real-world TTA protocol with a globally class imbalanced testing set. We demonstrate that combining all settings together poses new challenges to existing methods. We argue the failure of state-of-the-art methods is first caused by indiscriminately adapting normalization layers to imbalanced testing data. To remedy this shortcoming, we propose a balanced batchnorm layer to swap out the regular batchnorm at inference stage. The new batchnorm layer is capable of adapting without biasing towards majority classes. We are further inspired by the success of self-training~(ST) in learning from unlabeled data and adapt ST for test-time adaptation. However, ST alone is prone to over adaption which is responsible for the poor performance under continual domain shift. Hence, we propose to improve self-training under continual domain shift by regularizing model updates with an anchored loss. The final TTA model, termed as TRIBE, is built upon a tri-net architecture with balanced batchnorm layers. We evaluate TRIBE on four datasets representing real-world TTA settings. TRIBE consistently achieves the state-of-the-art performance across multiple evaluation protocols. The code is available at \url{https://github.com/Gorilla-Lab-SCUT/TRIBE}.
</details>
<details>
<summary>摘要</summary>
Test-Time Adaptation的目标是在推理阶段将源频道模型适应测试数据，并在不同的挑战性实际场景中成功减少。然而，现有的工作主要关注于非非独立的数据流和持续频道转移。在这种工作中，我们首先补充了现有的实际世界TTA协议，并添加了全球级别的类别不均衡测试集。我们示示，将所有设置结合起来会带来新的挑战，并让现有方法失败。我们认为现有方法的失败的原因是不经过分类地应用normalization层到不均衡的测试数据。为了解决这个缺陷，我们提议使用平衡batchnorm层在推理阶段交换常规batchnorm层。新的batchnorm层可以在不偏向多个类别的情况下适应。此外，我们受到了自适应学习（ST）的成功，并将ST应用于测试阶段适应。然而，ST独立进行适应可能会导致过度适应，这会导致在持续频道转移中的 poor performance。因此，我们提议在持续频道转移中补充模型更新的 anchored loss。最终的TTA模型，称为TRIBE，基于了三元网络架构和平衡batchnorm层。我们在四个实际世界TTA设置上评估TRIBE，并在多种评价协议中获得了状态的艺术性表现。代码可以在 \url{https://github.com/Gorilla-Lab-SCUT/TRIBE} 中获取。
</details></li>
</ul>
<hr>
<h2 id="FEC-Three-Finetuning-free-Methods-to-Enhance-Consistency-for-Real-Image-Editing"><a href="#FEC-Three-Finetuning-free-Methods-to-Enhance-Consistency-for-Real-Image-Editing" class="headerlink" title="FEC: Three Finetuning-free Methods to Enhance Consistency for Real Image Editing"></a>FEC: Three Finetuning-free Methods to Enhance Consistency for Real Image Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14934">http://arxiv.org/abs/2309.14934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songyan Chen, Jiancheng Huang</li>
<li>for: 实现精准的图像编辑任务，解决现有方法重建图像失败的问题。</li>
<li>methods: 提出了三种抽样方法，每种适用于不同的编辑类型和设置，可以确保成功的重建和提高编辑效果。</li>
<li>results: 方法可以减少计算机 память和计算量的使用，同时保持图像的纹理和特征，实现精准的图像编辑任务。<details>
<summary>Abstract</summary>
Text-conditional image editing is a very useful task that has recently emerged with immeasurable potential. Most current real image editing methods first need to complete the reconstruction of the image, and then editing is carried out by various methods based on the reconstruction. Most methods use DDIM Inversion for reconstruction, however, DDIM Inversion often fails to guarantee reconstruction performance, i.e., it fails to produce results that preserve the original image content. To address the problem of reconstruction failure, we propose FEC, which consists of three sampling methods, each designed for different editing types and settings. Our three methods of FEC achieve two important goals in image editing task: 1) ensuring successful reconstruction, i.e., sampling to get a generated result that preserves the texture and features of the original real image. 2) these sampling methods can be paired with many editing methods and greatly improve the performance of these editing methods to accomplish various editing tasks. In addition, none of our sampling methods require fine-tuning of the diffusion model or time-consuming training on large-scale datasets. Hence the cost of time as well as the use of computer memory and computation can be significantly reduced.
</details>
<details>
<summary>摘要</summary>
文本编辑是一项非常有前途的任务，它最近受到了无法估量的潜力。大多数当前实际图像编辑方法都需要先完成图像重建，然后使用不同的方法进行基于重建的编辑。大多数方法使用DDIM反向扩散来进行重建，但DDIM反向扩散经常无法保证重建性能，即无法生成保持原始图像内容的结果。为解决重建失败的问题，我们提出了FEC，它包括三种采样方法，每种采样方法适用于不同的编辑类型和设置。我们的三种采样方法可以实现两个重要的编辑任务目标：1）确保成功重建，即采样到生成结果，保持原始实际图像的纹理和特征。2）这些采样方法可以与多种编辑方法结合使用，大幅提高这些编辑方法的性能，完成多种编辑任务。此外，我们的采样方法不需要扩散模型的细调或大规模数据集的时间consuming Training，因此可以减少计算机 память和计算成本。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Data-Misalignment-in-Image-LiDAR-Fusion-on-Point-Cloud-Segmentation"><a href="#Addressing-Data-Misalignment-in-Image-LiDAR-Fusion-on-Point-Cloud-Segmentation" class="headerlink" title="Addressing Data Misalignment in Image-LiDAR Fusion on Point Cloud Segmentation"></a>Addressing Data Misalignment in Image-LiDAR Fusion on Point Cloud Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14932">http://arxiv.org/abs/2309.14932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jong Yang, Guan Cheng Lee</li>
<li>for: 提高自动驾驶 task 的性能，尤其是Camera和LiDAR感知器的数据融合。</li>
<li>methods: 使用先进的多感器融合模型，但是面临着数据不匹配的问题，需要更好地对准LiDAR点与图像之间的对应关系。</li>
<li>results: 提出了一种解决方案，通过对nuScenes数据集和SOTA的融合模型2DPASS进行仔细分析，并提供可能的解决方案或改进方向。<details>
<summary>Abstract</summary>
With the advent of advanced multi-sensor fusion models, there has been a notable enhancement in the performance of perception tasks within in terms of autonomous driving. Despite these advancements, the challenges persist, particularly in the fusion of data from cameras and LiDAR sensors. A critial concern is the accurate alignment of data from these disparate sensors. Our observations indicate that the projected positions of LiDAR points often misalign on the corresponding image. Furthermore, fusion models appear to struggle in accurately segmenting these misaligned points. In this paper, we would like to address this problem carefully, with a specific focus on the nuScenes dataset and the SOTA of fusion models 2DPASS, and providing the possible solutions or potential improvements.
</details>
<details>
<summary>摘要</summary>
“随着进步的多感应用模型的出现，自动驾驶感知任务中的性能有了明显提升。然而，问题仍然存在，尤其是把激光感知和摄像头感知融合的问题。我们的观察显示，LiDAR点的投影位置常常与相应的图像不一致。此外，融合模型似乎对这些不一致的点进行正确分类具有困难。在本文中，我们将仔细处理这个问题，专注于nuscenes数据集和2DPASS的SOTA融合模型，并提供可能的解决方案或改进方向。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Noise-Tolerant-Unsupervised-Adapter-for-Vision-Language-Models"><a href="#Noise-Tolerant-Unsupervised-Adapter-for-Vision-Language-Models" class="headerlink" title="Noise-Tolerant Unsupervised Adapter for Vision-Language Models"></a>Noise-Tolerant Unsupervised Adapter for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14928">http://arxiv.org/abs/2309.14928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eman Ali, Dayan Guan, Shijian Lu, Abdulmotaleb Elsaddik</li>
<li>for: 这篇论文旨在开发一个不需要目标标签的类型辨识模型，以提高类型辨识任务的扩展性和可扩展性。</li>
<li>methods: 本研究使用了一个名为NtUA的随机适应器，它可以从几个随机标本中学习出更好的目标模型。NtUA包括两个补充设计：一是适应缓存的形成，它根据预测信心重新排序缓存中的鉴定项目和预测值；另一个是预测整合，它利用大量数据语言模型的知识传授来修正缓存中的预测值和缓存权重。</li>
<li>results: 实验结果显示，NtUA在多个通用的测试集上具有优秀的性能，并且可以在不需要目标标签的情况下进行类型辨识任务。<details>
<summary>Abstract</summary>
Recent advances in large-scale vision-language models have achieved very impressive performance in various zero-shot image classification tasks. While prior studies have demonstrated significant improvements by introducing few-shot labelled target samples, they still require labelling of target samples, which greatly degrades their scalability while handling various visual recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that allows learning superior target models with few-shot unlabelled target samples. NtUA works as a key-value cache that formulates visual features and predicted pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It consists of two complementary designs. The first is adaptive cache formation that combats pseudo-label noises by weighting the key-value pairs according to their prediction confidence. The second is pseudo-label rectification, which corrects both pair values (i.e., pseudo-labels) and cache weights by leveraging knowledge distillation from large-scale vision language models. Extensive experiments show that NtUA achieves superior performance consistently across multiple widely adopted benchmarks.
</details>
<details>
<summary>摘要</summary>
latest advances in large-scale vision-language models have achieved very impressive performance in various zero-shot image classification tasks. While prior studies have demonstrated significant improvements by introducing few-shot labelled target samples, they still require labelling of target samples, which greatly degrades their scalability while handling various visual recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that allows learning superior target models with few-shot unlabelled target samples. NtUA works as a key-value cache that formulates visual features and predicted pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It consists of two complementary designs. The first is adaptive cache formation that combats pseudo-label noises by weighting the key-value pairs according to their prediction confidence. The second is pseudo-label rectification, which corrects both pair values (i.e., pseudo-labels) and cache weights by leveraging knowledge distillation from large-scale vision language models. Extensive experiments show that NtUA achieves superior performance consistently across multiple widely adopted benchmarks.
</details></li>
</ul>
<hr>
<h2 id="PHRIT-Parametric-Hand-Representation-with-Implicit-Template"><a href="#PHRIT-Parametric-Hand-Representation-with-Implicit-Template" class="headerlink" title="PHRIT: Parametric Hand Representation with Implicit Template"></a>PHRIT: Parametric Hand Representation with Implicit Template</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14916">http://arxiv.org/abs/2309.14916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhisheng Huang, Yujin Chen, Di Kang, Jinlu Zhang, Zhigang Tu</li>
<li>for: Parametric hand mesh modeling with an implicit template.</li>
<li>methods: 使用 signed distance fields (SDFs) with part-based shape priors, deforming the canonical template using a deformation field.</li>
<li>results: Realistic and immersive hand modeling with state-of-the-art performance, demonstrated through multiple downstream tasks such as skeleton-driven hand reconstruction, shapes from point clouds, and single-view 3D reconstruction.<details>
<summary>Abstract</summary>
We propose PHRIT, a novel approach for parametric hand mesh modeling with an implicit template that combines the advantages of both parametric meshes and implicit representations. Our method represents deformable hand shapes using signed distance fields (SDFs) with part-based shape priors, utilizing a deformation field to execute the deformation. The model offers efficient high-fidelity hand reconstruction by deforming the canonical template at infinite resolution. Additionally, it is fully differentiable and can be easily used in hand modeling since it can be driven by the skeleton and shape latent codes. We evaluate PHRIT on multiple downstream tasks, including skeleton-driven hand reconstruction, shapes from point clouds, and single-view 3D reconstruction, demonstrating that our approach achieves realistic and immersive hand modeling with state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
我们提出PHRIT，一种新的方法 Parametric Hand Mesh Modeling，结合 parametric meshes 和 implicit representations 的优点。我们的方法使用 signed distance fields (SDFs) 表示可变手型，通过部分基于 shape priors 的扭曲场来执行扭曲。该模型可以高效地执行高精度手形重建，通过扭曲权重的权重场来执行扭曲。此外，该模型是可导数的，可以由骨架和形状幂代码驱动。我们在多个下游任务中评估PHRIT，包括骨架驱动手形重建、点云形状重建和单视图三维重建， demonstarted that our approach achieves realistic and immersive hand modeling with state-of-the-art performance.Here's the translation in Traditional Chinese:我们提出PHRIT，一种新的方法 Parametric Hand Mesh Modeling，结合 parametric meshes 和 implicit representations 的优点。我们的方法使用 signed distance fields (SDFs) 表示可变手型，通过部分基于 shape priors 的扭曲场来执行扭曲。该模型可以高效地执行高精度手形重建，通过扭曲权重的权重场来执行扭曲。此外，该模型是可导数的，可以由骨架和形状幂代码驱动。我们在多个下游任务中评估PHRIT，包括骨架驱动手形重建、点云形状重建和单视野三维重建， demonstarted that our approach achieves realistic and immersive hand modeling with state-of-the-art performance.
</details></li>
</ul>
<hr>
<h2 id="Face-Cartoonisation-For-Various-Poses-Using-StyleGAN"><a href="#Face-Cartoonisation-For-Various-Poses-Using-StyleGAN" class="headerlink" title="Face Cartoonisation For Various Poses Using StyleGAN"></a>Face Cartoonisation For Various Poses Using StyleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14908">http://arxiv.org/abs/2309.14908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Jain, Ankith Varun J, Anoop Namboodiri</li>
<li>for: 本文提出了一种新的方法，以保持原始Identität和支持多种姿势来实现面卡通化。 unlike previous methods, which relied on conditional-GANs, our approach leverages the expressive latent space of StyleGAN.</li>
<li>methods: 我们的方法通过引入一个捕捉图像中的姿势和Identität信息的编码器，并将其转换为 StyleGAN的表达空间中的嵌入。 we then pass this embedding through a pre-trained generator to obtain the desired cartoonised output.</li>
<li>results: 我们通过广泛的实验表明，我们的编码器可以使StyleGAN输出更好地保持Identität，并且可以在不同的姿势下进行 cartoonisation. our method stands out from other approaches based on StyleGAN by not requiring a dedicated and fine-tuned StyleGAN model.<details>
<summary>Abstract</summary>
This paper presents an innovative approach to achieve face cartoonisation while preserving the original identity and accommodating various poses. Unlike previous methods in this field that relied on conditional-GANs, which posed challenges related to dataset requirements and pose training, our approach leverages the expressive latent space of StyleGAN. We achieve this by introducing an encoder that captures both pose and identity information from images and generates a corresponding embedding within the StyleGAN latent space. By subsequently passing this embedding through a pre-trained generator, we obtain the desired cartoonised output. While many other approaches based on StyleGAN necessitate a dedicated and fine-tuned StyleGAN model, our method stands out by utilizing an already-trained StyleGAN designed to produce realistic facial images. We show by extensive experimentation how our encoder adapts the StyleGAN output to better preserve identity when the objective is cartoonisation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Pre-training-free-Image-Manipulation-Localization-through-Non-Mutually-Exclusive-Contrastive-Learning"><a href="#Pre-training-free-Image-Manipulation-Localization-through-Non-Mutually-Exclusive-Contrastive-Learning" class="headerlink" title="Pre-training-free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning"></a>Pre-training-free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14900">http://arxiv.org/abs/2309.14900</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knightzjz/ncl-iml">https://github.com/knightzjz/ncl-iml</a></li>
<li>paper_authors: Jizhe Zhou, Xiaochen Ma, Xia Du, Ahmed Y. Alhammadi, Wentao Feng<br>for:* The paper aims to address the data insufficiency problem in Deep Image Manipulation Localization (IML) models by proposing a Non-mutually exclusive Contrastive Learning (NCL) framework.methods:* The NCL framework uses a pivot structure with dual branches to constantly switch the role of contour patches between positives and negatives during training, and a pivot-consistent loss to avoid spatial corruption.results:* The proposed NCL framework achieves state-of-the-art performance on all five benchmarks without any pre-training, and is more robust on unseen real-life samples.Here is the simplified Chinese text for the three key points:for:* 论文目标是解决 Deep Image Manipulation Localization (IML) 模型所处的数据缺乏问题，提出 Non-mutually exclusive Contrastive Learning (NCL) 框架。methods:* NCL 框架使用一个 pivot 结构，其中 dual branches 在训练中不断交换抽象范围和实际范围的角色，并使用 pivot-consistent 损失函数来避免空间损害。results:* 提议的 NCL 框架在所有五个 benchmark 上达到了无预训练的状态之冠，并在未看过的实际样本上更加稳定。<details>
<summary>Abstract</summary>
Deep Image Manipulation Localization (IML) models suffer from training data insufficiency and thus heavily rely on pre-training. We argue that contrastive learning is more suitable to tackle the data insufficiency problem for IML. Crafting mutually exclusive positives and negatives is the prerequisite for contrastive learning. However, when adopting contrastive learning in IML, we encounter three categories of image patches: tampered, authentic, and contour patches. Tampered and authentic patches are naturally mutually exclusive, but contour patches containing both tampered and authentic pixels are non-mutually exclusive to them. Simply abnegating these contour patches results in a drastic performance loss since contour patches are decisive to the learning outcomes. Hence, we propose the Non-mutually exclusive Contrastive Learning (NCL) framework to rescue conventional contrastive learning from the above dilemma. In NCL, to cope with the non-mutually exclusivity, we first establish a pivot structure with dual branches to constantly switch the role of contour patches between positives and negatives while training. Then, we devise a pivot-consistent loss to avoid spatial corruption caused by the role-switching process. In this manner, NCL both inherits the self-supervised merits to address the data insufficiency and retains a high manipulation localization accuracy. Extensive experiments verify that our NCL achieves state-of-the-art performance on all five benchmarks without any pre-training and is more robust on unseen real-life samples. The code is available at: https://github.com/Knightzjz/NCL-IML.
</details>
<details>
<summary>摘要</summary>
深度图像修饰本地化（IML）模型受训练数据不足的影响，因此强调预训练。我们认为对IML而言，对比学习更适合解决数据不足问题。创造独特的负和正样本是对比学习的前提。然而，在IML中采用对比学习时，我们遇到了三类图像 patch：妥协、原始和边界 patch。妥协和原始 patch 是自然的独特的，但边界 patch 包含了妥协和原始像素，因此不是独特的。简单地抛弃这些边界 patch 会导致性能下降，因为边界 patch 对学习结果有决定性的作用。因此，我们提出了非独特对比学习（NCL）框架，以解决上述困境。在 NCL 中，我们首先建立了一个平衡结构，其中包含了两个分支，以在训练过程中不断地将边界 patch 的角色 switching。然后，我们设计了一个平衡结构相关的损失函数，以避免由角色 switching 过程引起的空间损害。通过这种方式，NCL 同时继承了自动学习的自我超vised 优点，并保留高效的修饰本地化精度。广泛的实验证明了我们的 NCL 在五个标准测试集上均达到了领先的性能水平，而且在未经预训练的情况下达到了最高的修饰本地化精度。代码可以在 GitHub 上获取：<https://github.com/Knightzjz/NCL-IML>。
</details></li>
</ul>
<hr>
<h2 id="FDLS-A-Deep-Learning-Approach-to-Production-Quality-Controllable-and-Retargetable-Facial-Performances"><a href="#FDLS-A-Deep-Learning-Approach-to-Production-Quality-Controllable-and-Retargetable-Facial-Performances" class="headerlink" title="FDLS: A Deep Learning Approach to Production Quality, Controllable, and Retargetable Facial Performances"></a>FDLS: A Deep Learning Approach to Production Quality, Controllable, and Retargetable Facial Performances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14897">http://arxiv.org/abs/2309.14897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wan-Duo Kurt Ma, Muhammad Ghifary, J. P. Lewis, Byungkuk Choi, Haekwang Eom</li>
<li>for: 这 paper 是为了解决电影特效中的人工智能表演问题，包括创建真实的人工智能人类和将演员表演 transferred 到人形角色。</li>
<li>methods: 该 paper 使用了 Facial Deep Learning Solver (FDLS) 解决方案，它采用了粗略到细节的人工智能策略，让解决过程中的表演可以被验证和修改。</li>
<li>results: FDLS 可以帮助制作人员在生产中实现高质量的动画表演，而不需要大量的人工干预。该系统已经在多部电影中使用，并且可以处理小于一天的日常变化。<details>
<summary>Abstract</summary>
Visual effects commonly requires both the creation of realistic synthetic humans as well as retargeting actors' performances to humanoid characters such as aliens and monsters. Achieving the expressive performances demanded in entertainment requires manipulating complex models with hundreds of parameters. Full creative control requires the freedom to make edits at any stage of the production, which prohibits the use of a fully automatic ``black box'' solution with uninterpretable parameters. On the other hand, producing realistic animation with these sophisticated models is difficult and laborious. This paper describes FDLS (Facial Deep Learning Solver), which is Weta Digital's solution to these challenges. FDLS adopts a coarse-to-fine and human-in-the-loop strategy, allowing a solved performance to be verified and edited at several stages in the solving process. To train FDLS, we first transform the raw motion-captured data into robust graph features. Secondly, based on the observation that the artists typically finalize the jaw pass animation before proceeding to finer detail, we solve for the jaw motion first and predict fine expressions with region-based networks conditioned on the jaw position. Finally, artists can optionally invoke a non-linear finetuning process on top of the FDLS solution to follow the motion-captured virtual markers as closely as possible. FDLS supports editing if needed to improve the results of the deep learning solution and it can handle small daily changes in the actor's face shape. FDLS permits reliable and production-quality performance solving with minimal training and little or no manual effort in many cases, while also allowing the solve to be guided and edited in unusual and difficult cases. The system has been under development for several years and has been used in major movies.
</details>
<details>
<summary>摘要</summary>
通常，特效需要创建真实的人工人类和将演员的表演转移到人oid角色，如外星人和怪物。为了实现娱乐中的表演效果，需要 manipulate复杂的模型，包括数百个参数。为了获得完全的创作控制，需要在生产过程中有自由地进行编辑，因此不能使用完全自动的“黑obox”解决方案。然而，使用这些复杂的模型生成真实的动画是困难和耗时的。本文描述了WDLS（Facial Deep Learning Solver），是威塔数字的解决方案。WDLS采用了粗略到细节的人类在循环策略，allowing solved performance可以在多个阶段的解决过程中进行验证和编辑。为了训练WDLS，我们首先将原始的动作捕获数据转化为Robust Graph特征。然后，根据艺术家们通常在完成短脊动画之前进行精细表情的修饰，我们解决了下嘴部动作，并使用区域网络根据嘴部位置预测细表情。最后，艺术家可以选择atively辅助非线性调整过程，以便在动作捕获虚拟标记上最接近可能。WDLS支持编辑，以便根据需要改进深度学习解决方案的结果，并可以处理小于日常变化的actor面部形态。WDLS允许可靠且生产质量高的表现解决方案，同时允许解决方案被指导和编辑在不常见和困难的情况下。这个系统已经在数年内开发，并在主要电影中使用。
</details></li>
</ul>
<hr>
<h2 id="Nearest-Neighbor-Guidance-for-Out-of-Distribution-Detection"><a href="#Nearest-Neighbor-Guidance-for-Out-of-Distribution-Detection" class="headerlink" title="Nearest Neighbor Guidance for Out-of-Distribution Detection"></a>Nearest Neighbor Guidance for Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14888">http://arxiv.org/abs/2309.14888</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingkang50/openood">https://github.com/jingkang50/openood</a></li>
<li>paper_authors: Jaewoo Park, Yoon Gyo Jung, Andrew Beng Jin Teoh</li>
<li>for: 这篇论文的目的是提出一种基于类ifier的外部样本探测方法，以提高机器学习模型在开放世界环境中的检测精度。</li>
<li>methods: 该方法使用 Nearest Neighbor Guidance (NNGuide) 方法，将类ifier-based 分数引导到数据拟合的边界 geometries 中，以减少 OOD 样本的过度自信问题。</li>
<li>results: 经过广泛的实验测试，NNGuide 方法可以减少 OOD 样本的过度自信问题，同时保持类ifier-based 分数的细腻度，在 ImageNet OOD 检测测试准则下达到了状态的艺术指标 AUROC、FPR95 和 AUPR 的最佳 результа们。<details>
<summary>Abstract</summary>
Detecting out-of-distribution (OOD) samples are crucial for machine learning models deployed in open-world environments. Classifier-based scores are a standard approach for OOD detection due to their fine-grained detection capability. However, these scores often suffer from overconfidence issues, misclassifying OOD samples distant from the in-distribution region. To address this challenge, we propose a method called Nearest Neighbor Guidance (NNGuide) that guides the classifier-based score to respect the boundary geometry of the data manifold. NNGuide reduces the overconfidence of OOD samples while preserving the fine-grained capability of the classifier-based score. We conduct extensive experiments on ImageNet OOD detection benchmarks under diverse settings, including a scenario where the ID data undergoes natural distribution shift. Our results demonstrate that NNGuide provides a significant performance improvement on the base detection scores, achieving state-of-the-art results on both AUROC, FPR95, and AUPR metrics. The code is given at \url{https://github.com/roomo7time/nnguide}.
</details>
<details>
<summary>摘要</summary>
检测open-world环境中的非标准样本（out-of-distribution，OOD）是机器学习模型的关键问题。基于分类器的分数是标准的OOD检测方法，它具有细致的检测能力。然而，这些分数常常受到过自信问题的困扰，错误地分类OOD样本远离标准区域。为解决这个挑战，我们提出了一种方法called Nearest Neighbor Guidance（NNGuide），它使得分类器基于的分数尊重数据拟合的 geometrical 结构。NNGuide降低了OOD样本的过自信问题，同时保持了分类器的细致能力。我们在ImageNet OOD检测 benchmark中进行了广泛的实验，包括一个情况下ID数据经受自然分布变化。我们的结果表明，NNGuide可以带来显著的性能提升，在AUROC、FPR95和AUPR metrics中均达到了领先的结果。代码可以在 GitHub上找到：https://github.com/roomo7time/nnguide。
</details></li>
</ul>
<hr>
<h2 id="Locality-preserving-Directions-for-Interpreting-the-Latent-Space-of-Satellite-Image-GANs"><a href="#Locality-preserving-Directions-for-Interpreting-the-Latent-Space-of-Satellite-Image-GANs" class="headerlink" title="Locality-preserving Directions for Interpreting the Latent Space of Satellite Image GANs"></a>Locality-preserving Directions for Interpreting the Latent Space of Satellite Image GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14883">http://arxiv.org/abs/2309.14883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgia Kourmouli, Nikos Kostagiolas, Yannis Panagakis, Mihalis A. Nicolaou</li>
<li>for: 这 paper 是为了解释wavelet-based Generative Adversarial Networks (GANs) 的隐藏空间，以便 capture 卫星图像中的大空间和频谱特征。</li>
<li>methods: 这 paper 使用了保持本地性的方法，可以 decomposed 预训练 GANs 的权重空间，并回归可解释的方向，与高级 semantics 概念（如城市化、结构密度、植被存在）相关。</li>
<li>results: 作者比较了本地性方法和传统的 PCA 方法，发现本地性方法可以更好地 preserve 类信息，并且在卫星图像数据synthesis中表现出色。<details>
<summary>Abstract</summary>
We present a locality-aware method for interpreting the latent space of wavelet-based Generative Adversarial Networks (GANs), that can well capture the large spatial and spectral variability that is characteristic to satellite imagery. By focusing on preserving locality, the proposed method is able to decompose the weight-space of pre-trained GANs and recover interpretable directions that correspond to high-level semantic concepts (such as urbanization, structure density, flora presence) - that can subsequently be used for guided synthesis of satellite imagery. In contrast to typically used approaches that focus on capturing the variability of the weight-space in a reduced dimensionality space (i.e., based on Principal Component Analysis, PCA), we show that preserving locality leads to vectors with different angles, that are more robust to artifacts and can better preserve class information. Via a set of quantitative and qualitative examples, we further show that the proposed approach can outperform both baseline geometric augmentations, as well as global, PCA-based approaches for data synthesis in the context of data augmentation for satellite scene classification.
</details>
<details>
<summary>摘要</summary>
我们提出了一种地域意识的方法，用于解释基于wavelet的生成对抗网络（GANs）的latent空间，可以很好地捕捉卫星图像中的大空间和频谱多样性。通过强调地域性，我们的方法可以对预训练的GANs的权重空间进行分解，并回归可解释的方向，这些方向与高级 semantics（如城市化、结构密度、植被存在）相关，可以用于导引卫星图像的生成。与通常使用的方法相比，我们显示了保持地域性可以生成更加robust的方向，这些方向具有不同的角度，可以更好地抵御artifacts并保持类别信息。通过一系列量化和质量化的例子，我们进一步显示了我们的方法可以在卫星场景分类数据synthesis中超过基eline的几何增强和全局、基于PCA的方法。
</details></li>
</ul>
<hr>
<h2 id="ITEM3D-Illumination-Aware-Directional-Texture-Editing-for-3D-Models"><a href="#ITEM3D-Illumination-Aware-Directional-Texture-Editing-for-3D-Models" class="headerlink" title="ITEM3D: Illumination-Aware Directional Texture Editing for 3D Models"></a>ITEM3D: Illumination-Aware Directional Texture Editing for 3D Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14872">http://arxiv.org/abs/2309.14872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengqi Liu, Zhuo Chen, Jingnan Gao, Yichao Yan, Wenhan Zhu, Xiaobo Li, Ke Gao, Jiangjing Lyu, Xiaokang Yang</li>
<li>for:  automatic 3D object editing according to text prompts</li>
<li>methods:  diffusion models, differentiable rendering, noise difference optimization objective</li>
<li>results:  outperforms state-of-the-art methods, explicit control over lighting<details>
<summary>Abstract</summary>
Texture editing is a crucial task in 3D modeling that allows users to automatically manipulate the surface materials of 3D models. However, the inherent complexity of 3D models and the ambiguous text description lead to the challenge in this task. To address this challenge, we propose ITEM3D, an illumination-aware model for automatic 3D object editing according to the text prompts. Leveraging the diffusion models and the differentiable rendering, ITEM3D takes the rendered images as the bridge of text and 3D representation, and further optimizes the disentangled texture and environment map. Previous methods adopt the absolute editing direction namely score distillation sampling (SDS) as the optimization objective, which unfortunately results in the noisy appearance and text inconsistency. To solve the problem caused by the ambiguous text, we introduce a relative editing direction, an optimization objective defined by the noise difference between the source and target texts, to release the semantic ambiguity between the texts and images. Additionally, we gradually adjust the direction during optimization to further address the unexpected deviation in the texture domain. Qualitative and quantitative experiments show that our ITEM3D outperforms the state-of-the-art methods on various 3D objects. We also perform text-guided relighting to show explicit control over lighting.
</details>
<details>
<summary>摘要</summary>
《Texture Editing in 3D Modeling: A Challenge and a Proposed Solution》Texture editing是3D模型创建中的一项重要任务，它允许用户自动修改3D模型的表面材料。然而，3D模型的内在复杂性和文本描述的模糊性使得这项任务具有挑战。为解决这个挑战，我们提出了ITEM3D，一种基于扩散模型和可导渲染的自适应3D物体编辑方法。ITEM3D通过将渲染图像作为文本和3D表示之间的桥梁，并且进一步优化分离的 текстур和环境图像。前一些方法使用绝对编辑方向，即分配混合样本（SDS）的分数浓缩为优化目标，却导致图像的噪音和文本不一致。为解决文本的模糊性，我们引入了相对编辑方向，即源和目标文本之间的差异噪音作为优化目标，以释放文本和图像之间的 semantics 的模糊性。此外，我们在优化过程中逐步调整方向，以进一步解决图像领域中的意外偏差。我们对ITEM3D进行了质量和量化的实验，结果显示，ITEM3D在多种3D对象上超过了现有方法的性能。此外，我们还进行了文本指导的照明控制，以示Explicit Control over Lighting。
</details></li>
</ul>
<hr>
<h2 id="Cross-Dataset-Robust-Method-for-Blind-Real-World-Image-Quality-Assessment"><a href="#Cross-Dataset-Robust-Method-for-Blind-Real-World-Image-Quality-Assessment" class="headerlink" title="Cross-Dataset-Robust Method for Blind Real-World Image Quality Assessment"></a>Cross-Dataset-Robust Method for Blind Real-World Image Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14868">http://arxiv.org/abs/2309.14868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Chen, Zhiliang Ma, Yang Zhao</li>
<li>for: 本研究旨在提出一种可靠、 robust 的盲图质量评估（BIQA）方法，以便在实际世界中评估图像质量。</li>
<li>methods: 本研究使用了三个方面的技术，包括：1）多种人工智能模型的训练策略，2）大规模的实际世界图像数据集，3）强大的基础模型。</li>
<li>results: 实验结果表明，提出的方法在跨数据集测试中表现更好，甚至超越了直接在这些数据集上训练的一些状态对照方法，这证明了我们的方法的可靠性和泛化能力。<details>
<summary>Abstract</summary>
Although many effective models and real-world datasets have been presented for blind image quality assessment (BIQA), recent BIQA models usually tend to fit specific training set. Hence, it is still difficult to accurately and robustly measure the visual quality of an arbitrary real-world image. In this paper, a robust BIQA method, is designed based on three aspects, i.e., robust training strategy, large-scale real-world dataset, and powerful backbone. First, many individual models based on popular and state-of-the-art (SOTA) Swin-Transformer (SwinT) are trained on different real-world BIQA datasets respectively. Then, these biased SwinT-based models are jointly used to generate pseudo-labels, which adopts the probability of relative quality of two random images instead of fixed quality score. A large-scale real-world image dataset with 1,000,000 image pairs and pseudo-labels is then proposed for training the final cross-dataset-robust model. Experimental results on cross-dataset tests show that the performance of the proposed method is even better than some SOTA methods that are directly trained on these datasets, thus verifying the robustness and generalization of our method.
</details>
<details>
<summary>摘要</summary>
尽管现有许多有效的模型和实际数据集已经为盲图质量评估（BIQA）提供了许多有用的方法，但是现在的BIQA模型通常会适应特定的训练集。因此，仍然很难准确和可靠地测量真实世界图像的视觉质量。本文提出了一种robustBIQA方法，基于以下三个方面：一、robust训练策略；二、大规模的实际世界图像集；三、强大的后向。首先，多个基于流行和state-of-the-art（SOTA）Swin-Transformer（SwinT）的个体模型在不同的盲图BIQA数据集上进行了分别训练。然后，这些偏向的SwinT-based模型被用来生成 pseudo-labels，使用了两个随机图像之间的相对质量概率而不是固定的质量分数。然后，一个大规模的实际世界图像集，包含1000000个图像对和pseudo-labels，被用于训练最终的cross-dataset-robust模型。实验结果表明，提议的方法在cross-dataset测试中的性能甚至高于直接在这些数据集上训练的一些SOTA方法，从而证明了我们的方法的Robustness和普适性。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Reconstruction-of-3D-Human-Pose-Interactions-From-2D-Poses-Alone"><a href="#Unsupervised-Reconstruction-of-3D-Human-Pose-Interactions-From-2D-Poses-Alone" class="headerlink" title="Unsupervised Reconstruction of 3D Human Pose Interactions From 2D Poses Alone"></a>Unsupervised Reconstruction of 3D Human Pose Interactions From 2D Poses Alone</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14865">http://arxiv.org/abs/2309.14865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Hardy, Hansung Kim<br>for: 这种研究旨在解决多人场景下无监督2D-3D人姿估算方法中的投影歧义问题，通过预测人体眼镜中的高度角度来解决问题。methods: 该方法基于先前的工作，独立地提取每个人物的2D姿势，然后将其拼接在共享的3D坐标系中。然后，使用预测的高度角度来旋转和偏移每个人物的姿势，以便得到精确的3D重建。results: 在CHI3D dataset上进行测试，该方法能够实现精确的3D重建，并且介绍了三种新的量化指标来评估该方法的性能。这些指标为：1) 2D-3D姿势重建精度（2D-3D Pose Reconstruction Accuracy），2) 3D人姿精度（3D Human Pose Accuracy），3) 多人姿势重建精度（Multi-Person Pose Reconstruction Accuracy）。这些指标为未来研究的标准。<details>
<summary>Abstract</summary>
Current unsupervised 2D-3D human pose estimation (HPE) methods do not work in multi-person scenarios due to perspective ambiguity in monocular images. Therefore, we present one of the first studies investigating the feasibility of unsupervised multi-person 2D-3D HPE from just 2D poses alone, focusing on reconstructing human interactions. To address the issue of perspective ambiguity, we expand upon prior work by predicting the cameras' elevation angle relative to the subjects' pelvis. This allows us to rotate the predicted poses to be level with the ground plane, while obtaining an estimate for the vertical offset in 3D between individuals. Our method involves independently lifting each subject's 2D pose to 3D, before combining them in a shared 3D coordinate system. The poses are then rotated and offset by the predicted elevation angle before being scaled. This by itself enables us to retrieve an accurate 3D reconstruction of their poses. We present our results on the CHI3D dataset, introducing its use for unsupervised 2D-3D pose estimation with three new quantitative metrics, and establishing a benchmark for future research.
</details>
<details>
<summary>摘要</summary>
Current unsupervised 2D-3D人姿估算（HPE）方法在多人场景下不起作用，因为单目图像中的视角含义不明确。因此，我们发表了一项研究，探讨未经监督的多人2D-3DHPE从仅2D姿势中进行可行性研究，关注人类互动的重建。为解决视角不确定性问题，我们在先前的工作之上预测了相机的抬高角度 relative to the subjects' pelvis。这使得我们可以将预测的姿势旋转到地平面和水平面之间的垂直偏移来进行校准，并获得了每个人的3D姿势的估算。我们的方法是独立地提升每个人的2D姿势到3D，然后将它们在共享的3D坐标系中组合。然后，我们将 pose 旋转和偏移到预测的抬高角度，并将其缩放。这样就可以得到一个准确的3D重建。我们在 CHI3D 数据集上进行了实验，引入了三种新的量化指标，并建立了一个标准 для未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-pixel-wise-phase-estimation-by-CNN-and-improvement-of-phase-unwrapping-by-MRF-optimization-for-one-shot-3D-scan"><a href="#Generalization-of-pixel-wise-phase-estimation-by-CNN-and-improvement-of-phase-unwrapping-by-MRF-optimization-for-one-shot-3D-scan" class="headerlink" title="Generalization of pixel-wise phase estimation by CNN and improvement of phase-unwrapping by MRF optimization for one-shot 3D scan"></a>Generalization of pixel-wise phase estimation by CNN and improvement of phase-unwrapping by MRF optimization for one-shot 3D scan</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14824">http://arxiv.org/abs/2309.14824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hiroto Harada, Michihiro Mikamo, Ryo Furukawa, Ryushuke Sagawa, Hiroshi Kawasaki<br>for: 提高一遍3D扫描的精度和稳定性，特别适用于医疗、工业等领域。methods: 提议使用像素间插值技术，通过U-Net预训练CG数据进行高效数据增强，并提出robust对匹配找索引算法基于Markov随机场优化。results: 实验结果表明，提议方法可以有效地提高一遍3D扫描的精度和稳定性，并能够处理具有强频率和文本特征的实际数据。<details>
<summary>Abstract</summary>
Active stereo technique using single pattern projection, a.k.a. one-shot 3D scan, have drawn a wide attention from industry, medical purposes, etc. One severe drawback of one-shot 3D scan is sparse reconstruction. In addition, since spatial pattern becomes complicated for the purpose of efficient embedding, it is easily affected by noise, which results in unstable decoding. To solve the problems, we propose a pixel-wise interpolation technique for one-shot scan, which is applicable to any types of static pattern if the pattern is regular and periodic. This is achieved by U-net which is pre-trained by CG with efficient data augmentation algorithm. In the paper, to further overcome the decoding instability, we propose a robust correspondence finding algorithm based on Markov random field (MRF) optimization. We also propose a shape refinement algorithm based on b-spline and Gaussian kernel interpolation using explicitly detected laser curves. Experiments are conducted to show the effectiveness of the proposed method using real data with strong noises and textures.
</details>
<details>
<summary>摘要</summary>
aktive stereo技术使用单一模式投影，即一枚3D扫描，在业界、医疗领域等方面引起了广泛的关注。一个一枚3D扫描的严重缺点是稀疏重建。此外，由于空间模式变得复杂，以便高效嵌入，因此易受到噪声的影响，导致解码不稳定。为解决这些问题，我们提议了一种像素级 interpolate技术，适用于任何类型的静止模式，只要模式是正则和周期的。这是通过CG预训练的U-网进行实现的。在论文中，为进一步减轻解码不稳定性，我们提议了基于Markov随机场（MRF）优化的稳定匹配算法。我们还提议了基于b-spline和Gaussian核函数 interpolate的形态纠正算法，使用显式探测的激光曲线。我们对实际数据进行了实验，以证明我们提议的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Three-dimensional-Tracking-of-a-Large-Number-of-High-Dynamic-Objects-from-Multiple-Views-using-Current-Statistical-Model"><a href="#Three-dimensional-Tracking-of-a-Large-Number-of-High-Dynamic-Objects-from-Multiple-Views-using-Current-Statistical-Model" class="headerlink" title="Three-dimensional Tracking of a Large Number of High Dynamic Objects from Multiple Views using Current Statistical Model"></a>Three-dimensional Tracking of a Large Number of High Dynamic Objects from Multiple Views using Current Statistical Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14820">http://arxiv.org/abs/2309.14820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nianhao Xie</li>
<li>for: 该论文主要针对多视图多物体三维跟踪问题，尤其是生物群体行为研究中需要精确的轨迹数据。</li>
<li>methods: 该方法基于 bayesian tracking-while-reconstruction 框架，使用现有的统计模型来预测物体状态和估计状态协方差，并通过 kalman 筛选减少测量噪声。</li>
<li>results:  simulations 实验和实际蜡烛实验表明，该方法可以提高跟踪完整性、续度和精度，相比常见的常速度基于 particule filter 方法。<details>
<summary>Abstract</summary>
Three-dimensional tracking of multiple objects from multiple views has a wide range of applications, especially in the study of bio-cluster behavior which requires precise trajectories of research objects. However, there are significant temporal-spatial association uncertainties when the objects are similar to each other, frequently maneuver, and cluster in large numbers. Aiming at such a multi-view multi-object 3D tracking scenario, a current statistical model based Kalman particle filter (CSKPF) method is proposed following the Bayesian tracking-while-reconstruction framework. The CSKPF algorithm predicts the objects' states and estimates the objects' state covariance by the current statistical model to importance particle sampling efficiency, and suppresses the measurement noise by the Kalman filter. The simulation experiments prove that the CSKPF method can improve the tracking integrity, continuity, and precision compared with the existing constant velocity based particle filter (CVPF) method. The real experiment on fruitfly clusters also confirms the effectiveness of the CSKPF method.
</details>
<details>
<summary>摘要</summary>
三维跟踪多个物体从多个视图有广泛的应用，特别是生物群集行为研究需要精确的轨迹数据。然而，在物体相似、频繁拐弯和大量聚集时，存在较大的时空协同不确定性。为解决这类多视图多物体三维跟踪问题，提出了一种现有统计模型基于Kalman滤波器（CSKPF）方法。CSKPF算法预测物体状态和估计物体状态协方差，通过当前统计模型提高实际效率，并通过Kalman滤波器减少测量噪声。实验表明，CSKPF方法可以提高跟踪完整性、续写性和精度，比CVPF方法更为有效。实际实验也证实了CSKPF方法的效果。
</details></li>
</ul>
<hr>
<h2 id="Discrepancy-Matters-Learning-from-Inconsistent-Decoder-Features-for-Consistent-Semi-supervised-Medical-Image-Segmentation"><a href="#Discrepancy-Matters-Learning-from-Inconsistent-Decoder-Features-for-Consistent-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="Discrepancy Matters: Learning from Inconsistent Decoder Features for Consistent Semi-supervised Medical Image Segmentation"></a>Discrepancy Matters: Learning from Inconsistent Decoder Features for Consistent Semi-supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14819">http://arxiv.org/abs/2309.14819</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maxwell0027/lefed">https://github.com/maxwell0027/lefed</a></li>
<li>paper_authors: Qingjie Zeng, Yutong Xie, Zilin Lu, Mengkang Lu, Yong Xia</li>
<li>for: 这篇论文主要应用在扩展有限标签数据的领域，尤其是医疗影像分类 задачі上。</li>
<li>methods: 本文提出了一种新的半超级学习方法（LeFeD），通过将两个解oder的不一致信息作为反馈信号传递到encoder中，从而学习feature水平的不一致。</li>
<li>results: 实验结果显示，LeFeD可以比前 eight 个SOTA方法在三个公开 dataset上进行排名，而且不需要添加额外的不确定性估计和强制性约束。此外，LeFeD也在医疗影像分类任务上设置了新的SOTA记录。<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) has been proven beneficial for mitigating the issue of limited labeled data especially on the task of volumetric medical image segmentation. Unlike previous SSL methods which focus on exploring highly confident pseudo-labels or developing consistency regularization schemes, our empirical findings suggest that inconsistent decoder features emerge naturally when two decoders strive to generate consistent predictions. Based on the observation, we first analyze the treasure of discrepancy in learning towards consistency, under both pseudo-labeling and consistency regularization settings, and subsequently propose a novel SSL method called LeFeD, which learns the feature-level discrepancy obtained from two decoders, by feeding the discrepancy as a feedback signal to the encoder. The core design of LeFeD is to enlarge the difference by training differentiated decoders, and then learn from the inconsistent information iteratively. We evaluate LeFeD against eight state-of-the-art (SOTA) methods on three public datasets. Experiments show LeFeD surpasses competitors without any bells and whistles such as uncertainty estimation and strong constraints, as well as setting a new state-of-the-art for semi-supervised medical image segmentation. Code is available at \textcolor{cyan}{https://github.com/maxwell0027/LeFeD}
</details>
<details>
<summary>摘要</summary>
半经过监督学习（SSL）已经证明对受限标注数据的问题具有有利的影响，特别是在医疗影像分割任务上。 unlike previous SSL methods，我们的实证发现，当两个解码器努力生成一致的预测时，自然而然地出现了不一致的解码器特征。基于这一观察，我们首先分析了在学习向一致的过程中，缺失的储量，以及在pseudo-标签和一致化正则化设置下的情况。然后，我们提出了一种新的SSL方法，called LeFeD，它通过在两个解码器之间学习层次不一致的特征，以Feedback信号来驱动编码器。LeFeD的核心设计是通过培养不同的解码器来扩大差异，然后在不一致信息上学习。我们对八种现有的SOTA方法进行比较，实验结果表明，LeFeD可以在三个公共数据集上超越竞争对手，而无需添加额外的征识度量和强制约束。代码可以在 \textcolor{cyan}{https://github.com/maxwell0027/LeFeD} 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Population-Graph-Construction-Methods-and-Graph-Neural-Networks-for-Brain-Age-Regression"><a href="#A-Comparative-Study-of-Population-Graph-Construction-Methods-and-Graph-Neural-Networks-for-Brain-Age-Regression" class="headerlink" title="A Comparative Study of Population-Graph Construction Methods and Graph Neural Networks for Brain Age Regression"></a>A Comparative Study of Population-Graph Construction Methods and Graph Neural Networks for Brain Age Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14816">http://arxiv.org/abs/2309.14816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bintsi/brain-age-population-graphs">https://github.com/bintsi/brain-age-population-graphs</a></li>
<li>paper_authors: Kyriaki-Margarita Bintsi, Tamara T. Mueller, Sophie Starck, Vasileios Baltatzis, Alexander Hammers, Daniel Rueckert</li>
<li>for: 这个研究的目的是为了提高脑 возраст估计的精度，以便在临床设置中作为诊断工具。</li>
<li>methods: 这个研究使用了人口图，将多种成像数据 combinated 并捕捉了人口中个体之间的关系。</li>
<li>results: 研究发现，使用 homophily 约束可以提高 GNN 的性能，而其他建立方法可能是更加稳定的。<details>
<summary>Abstract</summary>
The difference between the chronological and biological brain age of a subject can be an important biomarker for neurodegenerative diseases, thus brain age estimation can be crucial in clinical settings. One way to incorporate multimodal information into this estimation is through population graphs, which combine various types of imaging data and capture the associations among individuals within a population. In medical imaging, population graphs have demonstrated promising results, mostly for classification tasks. In most cases, the graph structure is pre-defined and remains static during training. However, extracting population graphs is a non-trivial task and can significantly impact the performance of Graph Neural Networks (GNNs), which are sensitive to the graph structure. In this work, we highlight the importance of a meaningful graph construction and experiment with different population-graph construction methods and their effect on GNN performance on brain age estimation. We use the homophily metric and graph visualizations to gain valuable quantitative and qualitative insights on the extracted graph structures. For the experimental evaluation, we leverage the UK Biobank dataset, which offers many imaging and non-imaging phenotypes. Our results indicate that architectures highly sensitive to the graph structure, such as Graph Convolutional Network (GCN) and Graph Attention Network (GAT), struggle with low homophily graphs, while other architectures, such as GraphSage and Chebyshev, are more robust across different homophily ratios. We conclude that static graph construction approaches are potentially insufficient for the task of brain age estimation and make recommendations for alternative research directions.
</details>
<details>
<summary>摘要</summary>
人类脑发育年龄与生物年龄之间的差异可能是脑性变化疾病的重要生物标记器，因此脑发育年龄估计可能是临床设置中非常重要。一种方法是通过人口图，融合不同类型的内部数据，以capture个体之间的相互关联。在医疗影像中，人口图已经显示出了非常有前途的结果，主要是用于分类任务。然而，提取人口图是一个非常困难的任务，可能会对Graph Neural Networks（GNNs）的性能产生很大的影响，GNNs是对图结构非常敏感。在这个研究中，我们强调了具有意义的图建构的重要性，并尝试了不同的人口图建构方法，以及它们对GNN性能的影响。我们使用了同化度量和图可视化来获得有用的量化和质量的问题。我们利用了UK Biobank数据集，这个数据集提供了许多影像和非影像特征。我们的结果显示，高敏感度的图结构，如几何网络（GCN）和几何注意力网络（GAT），对低同化度图进行训练时表现不佳，而其他架构，如几何泛化网络（GraphSage）和Chebychev网络，则在不同的同化度比率下表现更加稳定。我们结论，静态图建构方法可能不够具体，我们建议进行更多的研究，以找到更好的方法。
</details></li>
</ul>
<hr>
<h2 id="ENIGMA-51-Towards-a-Fine-Grained-Understanding-of-Human-Object-Interactions-in-Industrial-Scenarios"><a href="#ENIGMA-51-Towards-a-Fine-Grained-Understanding-of-Human-Object-Interactions-in-Industrial-Scenarios" class="headerlink" title="ENIGMA-51: Towards a Fine-Grained Understanding of Human-Object Interactions in Industrial Scenarios"></a>ENIGMA-51: Towards a Fine-Grained Understanding of Human-Object Interactions in Industrial Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14809">http://arxiv.org/abs/2309.14809</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/syscv/sam-hq">https://github.com/syscv/sam-hq</a></li>
<li>paper_authors: Francesco Ragusa, Rosario Leonardi, Michele Mazzamuto, Claudia Bonanno, Rosario Scavo, Antonino Furnari, Giovanni Maria Farinella</li>
<li>for: The paper is written for studying human-object interactions in industrial scenarios.</li>
<li>methods: The paper uses a new dataset called ENIGMA-51, which is densely annotated with labels to enable the systematic study of human-object interactions.</li>
<li>results: The baseline results show that the ENIGMA-51 dataset poses a challenging benchmark for studying human-object interactions in industrial scenarios.Here’s the text in Simplified Chinese:</li>
<li>for: 这篇论文是为了研究工业场景中人与物之间的互动而写的。</li>
<li>methods: 这篇论文使用了一个新的数据集 called ENIGMA-51，这个数据集是 densely annotated 的，具有许多标签，可以系统地研究人与物之间的互动。</li>
<li>results: 基本结果表明，ENIGMA-51 数据集在工业场景中的人与物互动研究提供了一个具有挑战性的标准。<details>
<summary>Abstract</summary>
ENIGMA-51 is a new egocentric dataset acquired in a real industrial domain by 19 subjects who followed instructions to complete the repair of electrical boards using industrial tools (e.g., electric screwdriver) and electronic instruments (e.g., oscilloscope). The 51 sequences are densely annotated with a rich set of labels that enable the systematic study of human-object interactions in the industrial domain. We provide benchmarks on four tasks related to human-object interactions: 1) untrimmed action detection, 2) egocentric human-object interaction detection, 3) short-term object interaction anticipation and 4) natural language understanding of intents and entities. Baseline results show that the ENIGMA-51 dataset poses a challenging benchmark to study human-object interactions in industrial scenarios. We publicly release the dataset at: https://iplab.dmi.unict.it/ENIGMA-51/.
</details>
<details>
<summary>摘要</summary>
ENIGMA-51 是一个新的自我中心数据集，在真实的工业领域中由 19 名参与者收集到，他们按照 instrucions 完成了电气板的维修使用工业工具（例如电动钻）和电子 instrumente（例如振荡器）。这 51 个序列都有密集的注解，包括一个丰富的标签集，允许系统性的人机交互研究。我们在四个关于人机交互任务上提供了标准测试：1）不加工作行为检测，2） egocentric 人机交互检测，3）短期对象交互预测和4）自然语言理解意图和实体。基准结果显示，ENIGMA-51 数据集对于研究工业场景中的人机交互具有挑战性。我们在以下链接公开发布了数据集：https://iplab.dmi.unict.it/ENIGMA-51/。
</details></li>
</ul>
<hr>
<h2 id="3D-printed-realistic-finger-vein-phantoms"><a href="#3D-printed-realistic-finger-vein-phantoms" class="headerlink" title="3D printed realistic finger vein phantoms"></a>3D printed realistic finger vein phantoms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14806">http://arxiv.org/abs/2309.14806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luuk Spreeuwers, Rasmus van der Grift, Pesigrihastamadya Normakristagaluh</li>
<li>for: 该论文旨在提出一种创新的手别脉干模拟方法，以实现获得真实的手别脉干图像和精确知道脉干 patrern。</li>
<li>methods: 该方法使用3D打印技术，通过不同的打印材料和参数，模拟手别脉干中不同组织的光学性能，如骨、血管和软组织。</li>
<li>results: 该方法可以创造出真实的手别脉干图像和精确知道脉干 patrern，并且可以用于开发和评估手别脉干EXTRACTION和识别方法。此外，该方法还可以用于骗取手别脉干识别系统。<details>
<summary>Abstract</summary>
Finger vein pattern recognition is an emerging biometric with a good resistance to presentation attacks and low error rates. One problem is that it is hard to obtain ground truth finger vein patterns from live fingers. In this paper we propose an advanced method to create finger vein phantoms using 3D printing where we mimic the optical properties of the various tissues inside the fingers, like bone, veins and soft tissues using different printing materials and parameters. We demonstrate that we are able to create finger phantoms that result in realistic finger vein images and precisely known vein patterns. These phantoms can be used to develop and evaluate finger vein extraction and recognition methods. In addition, we show that the finger vein phantoms can be used to spoof a finger vein recognition system. This paper is based on the Master's thesis of Rasmus van der Grift.
</details>
<details>
<summary>摘要</summary>
finger vein pattern recognition 是一种emerging biometric，具有良好的抵御呈现攻击和低错误率。然而，一个问题是寻得真实的 finger vein pattern 的实验室数据很Difficult。在这篇论文中，我们提出了一种高级的方法，使用 3D printing 技术创建 finger vein phantom，模拟手指内部不同组织的光学性质，如骨、血管和软组织，使用不同的印刷材料和参数。我们示示了我们可以创建真实的手指形态和精确知道的血管图像。这些 phantom 可以用来开发和评估手指血管提取和识别方法。此外，我们还表明了 finger vein phantom 可以用来骗取手指血管识别系统。这篇论文基于 Rasmus van der Grift 的硕士论文。
</details></li>
</ul>
<hr>
<h2 id="3D-Density-Gradient-based-Edge-Detection-on-Neural-Radiance-Fields-NeRFs-for-Geometric-Reconstruction"><a href="#3D-Density-Gradient-based-Edge-Detection-on-Neural-Radiance-Fields-NeRFs-for-Geometric-Reconstruction" class="headerlink" title="3D Density-Gradient based Edge Detection on Neural Radiance Fields (NeRFs) for Geometric Reconstruction"></a>3D Density-Gradient based Edge Detection on Neural Radiance Fields (NeRFs) for Geometric Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14800">http://arxiv.org/abs/2309.14800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miriam Jäger, Boris Jutzi</li>
<li>for: 可以从Neural Radiance Fields（NeRF）中生成高质量的3D几何重建。</li>
<li>methods: 使用density gradient的方法，具体是使用Sobel、Canny和Laplacian of Gaussian的3D边条探测器，从相邻的维度进行探测。</li>
<li>results: 能够实现高地形精度的3D几何重建，并且可以实现物体表面上的物体完整性。Canny探测器能够干涯缺口，并且实现uniform的点密度。<details>
<summary>Abstract</summary>
Generating geometric 3D reconstructions from Neural Radiance Fields (NeRFs) is of great interest. However, accurate and complete reconstructions based on the density values are challenging. The network output depends on input data, NeRF network configuration and hyperparameter. As a result, the direct usage of density values, e.g. via filtering with global density thresholds, usually requires empirical investigations. Under the assumption that the density increases from non-object to object area, the utilization of density gradients from relative values is evident. As the density represents a position-dependent parameter it can be handled anisotropically, therefore processing of the voxelized 3D density field is justified. In this regard, we address geometric 3D reconstructions based on density gradients, whereas the gradients result from 3D edge detection filters of the first and second derivatives, namely Sobel, Canny and Laplacian of Gaussian. The gradients rely on relative neighboring density values in all directions, thus are independent from absolute magnitudes. Consequently, gradient filters are able to extract edges along a wide density range, almost independent from assumptions and empirical investigations. Our approach demonstrates the capability to achieve geometric 3D reconstructions with high geometric accuracy on object surfaces and remarkable object completeness. Notably, Canny filter effectively eliminates gaps, delivers a uniform point density, and strikes a favorable balance between correctness and completeness across the scenes.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Generating geometric 3D reconstructions from Neural Radiance Fields (NeRFs) is of great interest. However, accurate and complete reconstructions based on the density values are challenging. The network output depends on input data, NeRF network configuration and hyperparameter. As a result, the direct usage of density values, e.g. via filtering with global density thresholds, usually requires empirical investigations. Under the assumption that the density increases from non-object to object area, the utilization of density gradients from relative values is evident. As the density represents a position-dependent parameter it can be handled anisotropically, therefore processing of the voxelized 3D density field is justified. In this regard, we address geometric 3D reconstructions based on density gradients, whereas the gradients result from 3D edge detection filters of the first and second derivatives, namely Sobel, Canny and Laplacian of Gaussian. The gradients rely on relative neighboring density values in all directions, thus are independent from absolute magnitudes. Consequently, gradient filters are able to extract edges along a wide density range, almost independent from assumptions and empirical investigations. Our approach demonstrates the capability to achieve geometric 3D reconstructions with high geometric accuracy on object surfaces and remarkable object completeness. Notably, Canny filter effectively eliminates gaps, delivers a uniform point density, and strikes a favorable balance between correctness and completeness across the scenes."into Simplified Chinese.Here's the translation:<<SYS>>生成基于神经辐射场（NeRF）的三维几何重建是非常有趣的。然而，基于密度值的准确和完整的重建很困难。神经网络输出取决于输入数据、NeRF网络配置和超参数。因此，直接使用密度值，例如通过全局密度阈值滤波，通常需要实际调查。在密度增加从非对象区域到对象区域的假设下，使用密度梯度的Relative值是明显的。由于密度是位置依赖的参数，因此可以在三维浓度场中进行处理。在这种情况下，我们关注基于密度梯度的三维几何重建，其中梯度来自三维边检测器的第一和第二导数，即索贝尔、坎尼和洛普拉几何。这些梯度依赖于所有方向的相邻密度值，因此不受绝对值的影响。因此，梯度滤波可以在广泛的密度范围内提取边缘，大致独立于假设和实际调查。我们的方法可以实现高度准确的三维几何重建，并且可以在对象表面上达到很高的物理精度和对象完整性。尤其是坎尼滤波可以有效地消除峰值，提供一致的点密度，并在场景中占据有利的平衡。
</details></li>
</ul>
<hr>
<h2 id="Treating-Motion-as-Option-with-Output-Selection-for-Unsupervised-Video-Object-Segmentation"><a href="#Treating-Motion-as-Option-with-Output-Selection-for-Unsupervised-Video-Object-Segmentation" class="headerlink" title="Treating Motion as Option with Output Selection for Unsupervised Video Object Segmentation"></a>Treating Motion as Option with Output Selection for Unsupervised Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14786">http://arxiv.org/abs/2309.14786</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suhwan-cho/tmo">https://github.com/suhwan-cho/tmo</a></li>
<li>paper_authors: Suhwan Cho, Minhyeok Lee, Jungho Lee, MyeongAh Cho, Sangyoun Lee</li>
<li>for: 提高视频对象分割（VOS）任务中对象检测的稳定性和可靠性，不受外部指导或干扰。</li>
<li>methods: 使用动态图像和流动图像的共同特征来适应对象的动态特征，并通过对动态图像的隐藏学习来减少对运动指示的依赖性。</li>
<li>results: 在所有公共测试数据集上达到了最佳性能水平，并在实时推理速度下保持稳定性。<details>
<summary>Abstract</summary>
Unsupervised video object segmentation (VOS) is a task that aims to detect the most salient object in a video without external guidance about the object. To leverage the property that salient objects usually have distinctive movements compared to the background, recent methods collaboratively use motion cues extracted from optical flow maps with appearance cues extracted from RGB images. However, as optical flow maps are usually very relevant to segmentation masks, the network is easy to be learned overly dependent on the motion cues during network training. As a result, such two-stream approaches are vulnerable to confusing motion cues, making their prediction unstable. To relieve this issue, we design a novel motion-as-option network by treating motion cues as optional. During network training, RGB images are randomly provided to the motion encoder instead of optical flow maps, to implicitly reduce motion dependency of the network. As the learned motion encoder can deal with both RGB images and optical flow maps, two different predictions can be generated depending on which source information is used as motion input. In order to fully exploit this property, we also propose an adaptive output selection algorithm to adopt optimal prediction result at test time. Our proposed approach affords state-of-the-art performance on all public benchmark datasets, even maintaining real-time inference speed.
</details>
<details>
<summary>摘要</summary>
自助视频对象分割（VOS）是一项任务，旨在在视频中检测最引人注目的对象，不受外部指导。为了利用聚集对象的特征运动，现代方法通常结合运动图表中的运动规划和RGB图像中的外观规划。然而，由于运动图表通常很相关于分割掩蔽，因此网络在训练时容易被学习过度依赖于运动规划。这会导致这些两派方法在预测时容易被混淆运动规划，使其预测不稳定。为解决这问题，我们设计了一种新的运动作为选项网络，在网络训练时对RGB图像进行隐式减少运动依赖。由于学习的运动编码器可以处理RGB图像和运动图表两种不同的输入，因此在测试时可以生成两个不同的预测结果，具体取决于哪种源信息作为运动输入。为了充分利用这性能，我们还提出了一种适应输出选择算法，以选择最佳预测结果。我们的提出的方法可以在所有公共benchmark数据集上达到状态革命性的性能，同时保持实时推理速度。
</details></li>
</ul>
<hr>
<h2 id="Frugal-Satellite-Image-Change-Detection-with-Deep-Net-Inversion"><a href="#Frugal-Satellite-Image-Change-Detection-with-Deep-Net-Inversion" class="headerlink" title="Frugal Satellite Image Change Detection with Deep-Net Inversion"></a>Frugal Satellite Image Change Detection with Deep-Net Inversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14781">http://arxiv.org/abs/2309.14781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hichem Sahbi, Sebastien Deschamps</li>
<li>For: 这个论文的目的是提出一种基于活动学习的变化检测算法，用于检测卫星图像中的目标变化。* Methods: 该算法基于问答模型，通过询问用户（即oracle）关于图像中的变化相关性，更新深度神经网络（DNN）分类器。该算法还使用了一种新的对抗模型，以学习最有代表性、多样性和不确定性的虚拟 exemplars，从而提高了活动学习的效果。* Results: 实验表明，提出的深度网络反向推理方法在相关工作中表现出色，超过了相关的前工作。<details>
<summary>Abstract</summary>
Change detection in satellite imagery seeks to find occurrences of targeted changes in a given scene taken at different instants. This task has several applications ranging from land-cover mapping, to anthropogenic activity monitory as well as climate change and natural hazard damage assessment. However, change detection is highly challenging due to the acquisition conditions and also to the subjectivity of changes. In this paper, we devise a novel algorithm for change detection based on active learning. The proposed method is based on a question and answer model that probes an oracle (user) about the relevance of changes only on a small set of critical images (referred to as virtual exemplars), and according to oracle's responses updates deep neural network (DNN) classifiers. The main contribution resides in a novel adversarial model that allows learning the most representative, diverse and uncertain virtual exemplars (as inverted preimages of the trained DNNs) that challenge (the most) the trained DNNs, and this leads to a better re-estimate of these networks in the subsequent iterations of active learning. Experiments show the out-performance of our proposed deep-net inversion against the related work.
</details>
<details>
<summary>摘要</summary>
Change detection in satellite imagery aims to identify targeted changes in a scene captured at different times. This task has numerous applications, including land-cover mapping, monitoring anthropogenic activities, and assessing climate change and natural hazard damage. However, change detection is highly challenging due to acquisition conditions and the subjectivity of changes. In this paper, we propose a novel algorithm for change detection based on active learning. Our method uses a question-and-answer model to probe an oracle (user) about the relevance of changes on a small set of critical images (referred to as virtual exemplars), and updates deep neural network (DNN) classifiers according to the oracle's responses. The main contribution is a novel adversarial model that learns the most representative, diverse, and uncertain virtual exemplars (as inverted preimages of the trained DNNs) that challenge the trained DNNs, leading to a better re-estimate of these networks in subsequent active learning iterations. Experimental results show the outperformance of our proposed deep-net inversion compared to related work.
</details></li>
</ul>
<hr>
<h2 id="Multi-Label-Feature-Selection-Using-Adaptive-and-Transformed-Relevance"><a href="#Multi-Label-Feature-Selection-Using-Adaptive-and-Transformed-Relevance" class="headerlink" title="Multi-Label Feature Selection Using Adaptive and Transformed Relevance"></a>Multi-Label Feature Selection Using Adaptive and Transformed Relevance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14768">http://arxiv.org/abs/2309.14768</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadegh28/atr">https://github.com/sadegh28/atr</a></li>
<li>paper_authors: Sadegh Eskandari, Sahar Ghassabi</li>
<li>for: 本研究旨在提出一种基于信息理论的多标签特征选择方法，以便在多标签数据中提取有用的特征。</li>
<li>methods: 本方法基于一种新的启发函数，结合了算法适应和问题转换方法。它考虑每个标签的个别powers和抽象标签空间的权重，以选择最佳的特征。</li>
<li>results: 我们在12个benchmark上进行了实验，与10种现有的信息理论筛选方法进行比较。结果显示，我们的方法在6个评价指标中均显示出优异性，并且在特征和标签空间相对较大的benchmark中保持稳定性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Sadegh28/ATR%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Sadegh28/ATR上获取。</a><details>
<summary>Abstract</summary>
Multi-label learning has emerged as a crucial paradigm in data analysis, addressing scenarios where instances are associated with multiple class labels simultaneously. With the growing prevalence of multi-label data across diverse applications, such as text and image classification, the significance of multi-label feature selection has become increasingly evident. This paper presents a novel information-theoretical filter-based multi-label feature selection, called ATR, with a new heuristic function. Incorporating a combinations of algorithm adaptation and problem transformation approaches, ATR ranks features considering individual labels as well as abstract label space discriminative powers. Our experimental studies encompass twelve benchmarks spanning various domains, demonstrating the superiority of our approach over ten state-of-the-art information-theoretical filter-based multi-label feature selection methods across six evaluation metrics. Furthermore, our experiments affirm the scalability of ATR for benchmarks characterized by extensive feature and label spaces. The codes are available at https://github.com/Sadegh28/ATR
</details>
<details>
<summary>摘要</summary>
多标签学习已成为数据分析中的重要方法，用于处理同时具有多个分类标签的实例。随着多标签数据在不同应用领域的普及，如文本和图像分类等，多标签特征选择的重要性得到了更加明显的证明。本文提出了一种基于信息理论滤波器的新型多标签特征选择方法，即ATR，它通过结合算法适应和问题转换技术来评估特征的个别标签和抽象标签空间的探索力。我们的实验包括12个标准 benchmark，覆盖多个领域，表明我们的方法在6个评价指标中超过了10种现有的信息理论滤波器基于多标签特征选择方法。此外，我们的实验还证明了ATR在特征和标签空间较大的 benchmark 上的扩展性。代码可以在https://github.com/Sadegh28/ATR 中获取。
</details></li>
</ul>
<hr>
<h2 id="InvKA-Gait-Recognition-via-Invertible-Koopman-Autoencoder"><a href="#InvKA-Gait-Recognition-via-Invertible-Koopman-Autoencoder" class="headerlink" title="InvKA: Gait Recognition via Invertible Koopman Autoencoder"></a>InvKA: Gait Recognition via Invertible Koopman Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14764">http://arxiv.org/abs/2309.14764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Li, Dong Liang, Jing Lian, Qidong Liu, Hegui Zhu, Jizhao Liu</li>
<li>for: 提高步态识别方法的可解性和计算效率</li>
<li>methods: 基于koopman算子理论提取步态特征，使用可逆 autoencoder 减少模型大小并减少计算深度，从而降低计算成本</li>
<li>results: 在多个数据集上实现了计算成本减少至1%，同时保持步态识别精度高达98%（非遮挡数据集）<details>
<summary>Abstract</summary>
Most current gait recognition methods suffer from poor interpretability and high computational cost. To improve interpretability, we investigate gait features in the embedding space based on Koopman operator theory. The transition matrix in this space captures complex kinematic features of gait cycles, namely the Koopman operator. The diagonal elements of the operator matrix can represent the overall motion trend, providing a physically meaningful descriptor. To reduce the computational cost of our algorithm, we use a reversible autoencoder to reduce the model size and eliminate convolutional layers to compress its depth, resulting in fewer floating-point operations. Experimental results on multiple datasets show that our method reduces computational cost to 1% compared to state-of-the-art methods while achieving competitive recognition accuracy 98% on non-occlusion datasets.
</details>
<details>
<summary>摘要</summary>
现有的步幅识别方法受到低解释性和高计算成本的影响。为改善解释性，我们在库曼操作理论基础上探索步幅特征在嵌入空间中。这个转换矩阵在这个空间中捕捉了复杂的步幅周期特征，即库曼操作。转换矩阵的主要元素可以表示步幅运动趋势，提供物理意义的描述。对于我们的算法，我们使用可逆 autoencoder 将模型大小缩小，并删除卷积层以压缩其深度，从而减少浮点运算次数。实验结果显示，我们的方法可以与现有的方法相比，在非遮掩 dataset 上 achieves 98% 的识别率，而且计算成本仅占现有方法的 1%。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-Holistic-Texture-Rectification-and-Synthesis"><a href="#Diffusion-based-Holistic-Texture-Rectification-and-Synthesis" class="headerlink" title="Diffusion-based Holistic Texture Rectification and Synthesis"></a>Diffusion-based Holistic Texture Rectification and Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14759">http://arxiv.org/abs/2309.14759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Dominoer/siggraph_asia_2023_holistic_texture">https://github.com/Dominoer/siggraph_asia_2023_holistic_texture</a></li>
<li>paper_authors: Guoqing Hao, Satoshi Iizuka, Kensho Hara, Edgar Simo-Serra, Hirokatsu Kataoka, Kazuhiro Fukui</li>
<li>for: 本文提出了一种新的框架，用于修正自然图像中的遮挡和扭曲。</li>
<li>methods: 该框架使用一种条件的潜在扩散模型（LDM），并使用一种新的遮挡意识的潜在变换器来编码图像特征。</li>
<li>results: 实验结果表明，该框架在评价量和质量上都有显著的优势，并且通过了全面的拟合研究。<details>
<summary>Abstract</summary>
We present a novel framework for rectifying occlusions and distortions in degraded texture samples from natural images. Traditional texture synthesis approaches focus on generating textures from pristine samples, which necessitate meticulous preparation by humans and are often unattainable in most natural images. These challenges stem from the frequent occlusions and distortions of texture samples in natural images due to obstructions and variations in object surface geometry. To address these issues, we propose a framework that synthesizes holistic textures from degraded samples in natural images, extending the applicability of exemplar-based texture synthesis techniques. Our framework utilizes a conditional Latent Diffusion Model (LDM) with a novel occlusion-aware latent transformer. This latent transformer not only effectively encodes texture features from partially-observed samples necessary for the generation process of the LDM, but also explicitly captures long-range dependencies in samples with large occlusions. To train our model, we introduce a method for generating synthetic data by applying geometric transformations and free-form mask generation to clean textures. Experimental results demonstrate that our framework significantly outperforms existing methods both quantitatively and quantitatively. Furthermore, we conduct comprehensive ablation studies to validate the different components of our proposed framework. Results are corroborated by a perceptual user study which highlights the efficiency of our proposed approach.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的框架，用于纠正自然图像中的遮挡和扭曲。传统的文本生成方法强调从无损样本中生成文本，但这些样本往往需要人工准备，而且很难在自然图像中获得。这些问题源于自然图像中文本样本的频繁遮挡和变化，导致文本样本的缺失和扭曲。为解决这些问题，我们提出了一个框架，可以从自然图像中纠正的文本样本，扩展了示例基于文本生成技术的应用范围。我们的框架使用一种conditional Latent Diffusion Model（LDM），并使用一种新的遮挡意识的缓冲变换器。这个缓冲变换器不仅能够有效地编码自然图像中的文本特征，还能够显著地捕捉大遮挡样本中的长距离依赖关系。为训练我们的模型，我们引入了一种生成合成数据的方法，通过几何变换和自由形mask生成来生成干净的文本样本。实验结果表明，我们的框架在量化和质量上都有显著提高，并且进行了完整的ablation研究来验证不同的模型组件。结果得到了人类感知测试的证明，表明我们的提出的方法更加高效。
</details></li>
</ul>
<hr>
<h2 id="On-quantifying-and-improving-realism-of-images-generated-with-diffusion"><a href="#On-quantifying-and-improving-realism-of-images-generated-with-diffusion" class="headerlink" title="On quantifying and improving realism of images generated with diffusion"></a>On quantifying and improving realism of images generated with diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14756">http://arxiv.org/abs/2309.14756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunzhuo Chen, Naveed Akhtar, Nur Al Hasan Haldar, Ajmal Mian<br>for:* 这个论文主要是为了解决生成模型中的图像真实性评估问题。methods:* 该论文提出了一种基于统计方法的图像真实性评估指标，即图像真实性分数（IRS），并通过实验表明其可以有效地评估生成模型中的图像真实性。results:* 该论文的实验结果表明，图像真实性分数可以准确地分辨真实图像和假图像，并且可以用于评估生成模型的性能。此外，通过修改生成损失函数以采用图像真实性分数，可以提高生成模型中的图像质量。<details>
<summary>Abstract</summary>
Recent advances in diffusion models have led to a quantum leap in the quality of generative visual content. However, quantification of realism of the content is still challenging. Existing evaluation metrics, such as Inception Score and Fr\'echet inception distance, fall short on benchmarking diffusion models due to the versatility of the generated images. Moreover, they are not designed to quantify realism of an individual image. This restricts their application in forensic image analysis, which is becoming increasingly important in the emerging era of generative models. To address that, we first propose a metric, called Image Realism Score (IRS), computed from five statistical measures of a given image. This non-learning based metric not only efficiently quantifies realism of the generated images, it is readily usable as a measure to classify a given image as real or fake. We experimentally establish the model- and data-agnostic nature of the proposed IRS by successfully detecting fake images generated by Stable Diffusion Model (SDM), Dalle2, Midjourney and BigGAN.   We further leverage this attribute of our metric to minimize an IRS-augmented generative loss of SDM, and demonstrate a convenient yet considerable quality improvement of the SDM-generated content with our modification. Our efforts have also led to Gen-100 dataset, which provides 1,000 samples for 100 classes generated by four high-quality models. We will release the dataset and code.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Image-Denoising-via-Style-Disentanglement"><a href="#Image-Denoising-via-Style-Disentanglement" class="headerlink" title="Image Denoising via Style Disentanglement"></a>Image Denoising via Style Disentanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14755">http://arxiv.org/abs/2309.14755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingwei Niu, Jun Cheng, Shan Tan</li>
<li>for: 提出了一种新的图像去噪方法，可以同时提供清晰的去噪机制和好的性能。</li>
<li>methods: 视噪为图像的一种风格，通过提取噪音样本和噪音自由样本来除噪。设计了新的损失函数和网络模块，在特征空间中分离噪音和内容特征。</li>
<li>results: 通过Synthetic Noise Removal和Real-world Image Denoising dataset（SIDD和DND）的广泛实验，证明了方法的效果，PSNR和SSIM指标均有显著提高。此外，方法也具有良好的解释性。<details>
<summary>Abstract</summary>
Image denoising is a fundamental task in low-level computer vision. While recent deep learning-based image denoising methods have achieved impressive performance, they are black-box models and the underlying denoising principle remains unclear. In this paper, we propose a novel approach to image denoising that offers both clear denoising mechanism and good performance. We view noise as a type of image style and remove it by incorporating noise-free styles derived from clean images. To achieve this, we design novel losses and network modules to extract noisy styles from noisy images and noise-free styles from clean images. The noise-free style induces low-response activations for noise features and high-response activations for content features in the feature space. This leads to the separation of clean contents from noise, effectively denoising the image. Unlike disentanglement-based image editing tasks that edit semantic-level attributes using styles, our main contribution lies in editing pixel-level attributes through global noise-free styles. We conduct extensive experiments on synthetic noise removal and real-world image denoising datasets (SIDD and DND), demonstrating the effectiveness of our method in terms of both PSNR and SSIM metrics. Moreover, we experimentally validate that our method offers good interpretability.
</details>
<details>
<summary>摘要</summary>
图像噪声除除是计算机视觉领域的基础任务。Recent deep learning基于图像噪声除方法具有印象深刻的表现，但是它们是黑盒模型，即使用的原理不明确。在这篇论文中，我们提出了一种新的图像噪声除方法，具有明确的噪声除机制并且表现良好。我们视噪声为图像风格的一种，通过将噪声样本从噪声图像中提取出来，并将噪声样本与清晰图像中的风格相结合，从而将噪声分离出来。为此，我们设计了新的损失函数和网络模块，以提取噪声样本和清晰图像中的风格。噪声样本在特征空间中产生低响应活动，而内容特征产生高响应活动，这导致了噪声和内容的分离，从而有效地除噪图像。不同于基于分离Semantic-level特征的图像修改任务，我们的主要贡献在于通过全局噪声无响应风格来修改像素级别的特征。我们在合成噪声除和实际图像噪声除数据集（SIDD和DND）进行了广泛的实验，并证明了我们的方法在PSNR和SSIM指标上表现出色。此外，我们还进行了实验来证明我们的方法具有良好的可读性。
</details></li>
</ul>
<hr>
<h2 id="Advanced-Volleyball-Stats-for-All-Levels-Automatic-Setting-Tactic-Detection-and-Classification-with-a-Single-Camera"><a href="#Advanced-Volleyball-Stats-for-All-Levels-Automatic-Setting-Tactic-Detection-and-Classification-with-a-Single-Camera" class="headerlink" title="Advanced Volleyball Stats for All Levels: Automatic Setting Tactic Detection and Classification with a Single Camera"></a>Advanced Volleyball Stats for All Levels: Automatic Setting Tactic Detection and Classification with a Single Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14753">http://arxiv.org/abs/2309.14753</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/volleyIEEE/VolleyStats">https://github.com/volleyIEEE/VolleyStats</a></li>
<li>paper_authors: Haotian Xia, Rhys Tracy, Yun Zhao, Yuqing Wang, Yuan-Fang Wang, Weining Shen</li>
<li>for: 提供高级战术分类方法的单视图计算机视觉框架</li>
<li>methods: 使用设球轨迹认识和novel设轨类ifier生成全面和高级统计数据</li>
<li>results: 超越现有方法的性能，在不同游戏情况下进行复杂游戏情况和不同摄像头角度处理Here’s the same information in Simplified Chinese:</li>
<li>for: 为高级战术分类提供单视图计算机视觉框架</li>
<li>methods:  combining setting ball trajectory recognition with novel set trajectory classifier生成全面和高级统计数据</li>
<li>results: 超越现有方法的性能，在不同游戏情况下进行复杂游戏情况和不同摄像头角度处理<details>
<summary>Abstract</summary>
This paper presents PathFinder and PathFinderPlus, two novel end-to-end computer vision frameworks designed specifically for advanced setting strategy classification in volleyball matches from a single camera view. Our frameworks combine setting ball trajectory recognition with a novel set trajectory classifier to generate comprehensive and advanced statistical data. This approach offers a fresh perspective for in-game analysis and surpasses the current level of granularity in volleyball statistics. In comparison to existing methods used in our baseline PathFinder framework, our proposed ball trajectory detection methodology in PathFinderPlus exhibits superior performance for classifying setting tactics under various game conditions. This robustness is particularly advantageous in handling complex game situations and accommodating different camera angles. Additionally, our study introduces an innovative algorithm for automatic identification of the opposing team's right-side (opposite) hitter's current row (front or back) during gameplay, providing critical insights for tactical analysis. The successful demonstration of our single-camera system's feasibility and benefits makes high-level technical analysis accessible to volleyball enthusiasts of all skill levels and resource availability. Furthermore, the computational efficiency of our system allows for real-time deployment, enabling in-game strategy analysis and on-the-spot gameplan adjustments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Text-image-guided-Diffusion-Model-for-generating-Deepfake-celebrity-interactions"><a href="#Text-image-guided-Diffusion-Model-for-generating-Deepfake-celebrity-interactions" class="headerlink" title="Text-image guided Diffusion Model for generating Deepfake celebrity interactions"></a>Text-image guided Diffusion Model for generating Deepfake celebrity interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14751">http://arxiv.org/abs/2309.14751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunzhuo Chen, Nur Al Hasan Haldar, Naveed Akhtar, Ajmal Mian</li>
<li>for: The paper aims to explore the use of diffusion models for generating realistic and controllable Deepfake images, with a focus on creating forged content for celebrity interactions.</li>
<li>methods: The paper modifies a popular stable diffusion model to generate high-quality Deepfake images with text and image prompts, and adds the input anchor image’s latent at the beginning of inferencing to improve the generation of images with multiple persons. Additionally, the paper uses Dreambooth to enhance the realism of the fake images.</li>
<li>results: The paper demonstrates that the devised scheme can create fake visual content with alarming realism, such as images of meetings between powerful political figures, which could be used to spread rumors or misinformation.<details>
<summary>Abstract</summary>
Deepfake images are fast becoming a serious concern due to their realism. Diffusion models have recently demonstrated highly realistic visual content generation, which makes them an excellent potential tool for Deepfake generation. To curb their exploitation for Deepfakes, it is imperative to first explore the extent to which diffusion models can be used to generate realistic content that is controllable with convenient prompts. This paper devises and explores a novel method in that regard. Our technique alters the popular stable diffusion model to generate a controllable high-quality Deepfake image with text and image prompts. In addition, the original stable model lacks severely in generating quality images that contain multiple persons. The modified diffusion model is able to address this problem, it add input anchor image's latent at the beginning of inferencing rather than Gaussian random latent as input. Hence, we focus on generating forged content for celebrity interactions, which may be used to spread rumors. We also apply Dreambooth to enhance the realism of our fake images. Dreambooth trains the pairing of center words and specific features to produce more refined and personalized output images. Our results show that with the devised scheme, it is possible to create fake visual content with alarming realism, such that the content can serve as believable evidence of meetings between powerful political figures.
</details>
<details>
<summary>摘要</summary>
深圳图像是现在日益成为严重问题，因为它们的真实性。扩散模型在最近几年内表现出了高度真实的视觉内容生成能力，这使得它们成为深圳图像生成的极佳潜在工具。为了防止深圳图像的滥用，我们需要首先探索扩散模型可以生成高质量、控制性良好的深圳图像的可能性。这篇论文提出了一种新的方法。我们的技术改变了流行的稳定扩散模型，以生成高质量、控制性良好的深圳图像，使用文本和图像提示。此外，原始的稳定模型在生成高质量图像时缺乏严重的问题，我们修改了模型，将输入的anchor图像的秘密添加到推理过程的开始，而不是 Gaussian 随机秘密输入。因此，我们专注于生成假内容，如著名人之间的互动，这可能用于散布谣言。我们还使用 Dreambooth 来提高假图像的真实感。Dreambooth 训练了对中心词和特定特征的对应，以生成更加细致和个性化的输出图像。我们的结果显示，通过我们的方案，可以创建真实性惊人的假视觉内容，例如，著名人之间的互动，这些内容可能用作具有证据性的证据。
</details></li>
</ul>
<hr>
<h2 id="SSPFusion-A-Semantic-Structure-Preserving-Approach-for-Infrared-and-Visible-Image-Fusion"><a href="#SSPFusion-A-Semantic-Structure-Preserving-Approach-for-Infrared-and-Visible-Image-Fusion" class="headerlink" title="SSPFusion: A Semantic Structure-Preserving Approach for Infrared and Visible Image Fusion"></a>SSPFusion: A Semantic Structure-Preserving Approach for Infrared and Visible Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14745">http://arxiv.org/abs/2309.14745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Yang, Yu Zhang, Jian Zhang, Zijing Zhao, Shunli Zhang, Jinqiao Wang, Junzhe Chen</li>
<li>for: 提高计算机视觉任务的性能，即提高图像融合后的对象检测和识别等任务的性能。</li>
<li>methods: 提出了一种 semantic structure-preserving 方法，即 SSPFusion，该方法包括 Structural Feature Extractor (SFE) 和 multi-scale Structure-Preserving Fusion (SPF) 两个模块。</li>
<li>results: 对三个标准数据集进行了实验，证明了 SSPFusion 方法可以生成高质量的融合图像，并且在对象检测和识别等计算机视觉任务中提高了性能。<details>
<summary>Abstract</summary>
Most existing learning-based infrared and visible image fusion (IVIF) methods exhibit massive redundant information in the fusion images, i.e., yielding edge-blurring effect or unrecognizable for object detectors. To alleviate these issues, we propose a semantic structure-preserving approach for IVIF, namely SSPFusion. At first, we design a Structural Feature Extractor (SFE) to extract the structural features of infrared and visible images. Then, we introduce a multi-scale Structure-Preserving Fusion (SPF) module to fuse the structural features of infrared and visible images, while maintaining the consistency of semantic structures between the fusion and source images. Owing to these two effective modules, our method is able to generate high-quality fusion images from pairs of infrared and visible images, which can boost the performance of downstream computer-vision tasks. Experimental results on three benchmarks demonstrate that our method outperforms eight state-of-the-art image fusion methods in terms of both qualitative and quantitative evaluations. The code for our method, along with additional comparison results, will be made available at: https://github.com/QiaoYang-CV/SSPFUSION.
</details>
<details>
<summary>摘要</summary>
大多数现有的学习基于的红外和可见图像 fusión（IVIF）方法会带来巨大的重复信息在合并图像中，例如导致边缘模糊效应或对物体检测器无法识别。为了解决这些问题，我们提出了一种semantic structure-preserving的方法，即SSPFusion。在这个方法中，我们首先设计了一个结构特征提取器（SFE），用于提取红外和可见图像的结构特征。然后，我们引入了一个多尺度结构保持合并（SPF）模块，用于将红外和可见图像的结构特征进行合并，同时保持了这些特征在合并图像和原始图像之间的一致性。由于这两个有效的模块，我们的方法能够生成高质量的合并图像，从红外和可见图像的对应组合中获得提高。实验结果表明，我们的方法在三个标准测试集上与八种现有的图像 fusión方法进行比较，在质量和量化评价方面都表现出优于其他方法。我们的代码、以及更多的比较结果，将在GitHub上公开：https://github.com/QiaoYang-CV/SSPFUSION。
</details></li>
</ul>
<hr>
<h2 id="ADU-Depth-Attention-based-Distillation-with-Uncertainty-Modeling-for-Depth-Estimation"><a href="#ADU-Depth-Attention-based-Distillation-with-Uncertainty-Modeling-for-Depth-Estimation" class="headerlink" title="ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation"></a>ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14744">http://arxiv.org/abs/2309.14744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizhang Wu, Zhuozheng Li, Zhi-Gang Fan, Yunzhe Wu, Xiaoquan Wang, Rui Tang, Jian Pu</li>
<li>for: 提高单目深度估计精度，使用左右图像对Alignment和学习帮助提高单目深度估计精度。</li>
<li>methods: 提出了一种名为ADU-Depth的知识填充框架，通过将Well-trained教师网络传递知识到单目学生网络，以提高单目深度估计精度。在训练阶段，应用了注意力适应特征填充和关注深度适应响应填充，以便在不同预测难度下进行有效的知识传递。同时，Explicitly model the uncertainty of depth estimation to guide distillation in both feature space and result space。</li>
<li>results: 在实际的深度估计 dataset KITTI 和 DrivingStereo 上进行了广泛的实验，并达到了在挑战性较高的 KITTI 在线Benchmark 上的第一名。<details>
<summary>Abstract</summary>
Monocular depth estimation is challenging due to its inherent ambiguity and ill-posed nature, yet it is quite important to many applications. While recent works achieve limited accuracy by designing increasingly complicated networks to extract features with limited spatial geometric cues from a single RGB image, we intend to introduce spatial cues by training a teacher network that leverages left-right image pairs as inputs and transferring the learned 3D geometry-aware knowledge to the monocular student network. Specifically, we present a novel knowledge distillation framework, named ADU-Depth, with the goal of leveraging the well-trained teacher network to guide the learning of the student network, thus boosting the precise depth estimation with the help of extra spatial scene information. To enable domain adaptation and ensure effective and smooth knowledge transfer from teacher to student, we apply both attention-adapted feature distillation and focal-depth-adapted response distillation in the training stage. In addition, we explicitly model the uncertainty of depth estimation to guide distillation in both feature space and result space to better produce 3D-aware knowledge from monocular observations and thus enhance the learning for hard-to-predict image regions. Our extensive experiments on the real depth estimation datasets KITTI and DrivingStereo demonstrate the effectiveness of the proposed method, which ranked 1st on the challenging KITTI online benchmark.
</details>
<details>
<summary>摘要</summary>
单眼深度估计是一个挑战性的任务，因为它具有自然的歧义和不确定性，但它对许多应用程序非常重要。Recent works 通过设计越来越复杂的网络来提取具有有限空间几何指标的单眼照片，实现有限的精度。我们则是通过将左右两个照片作为输入，训练一个教师网络，以便传递到单眼学生网络中的3D几何意识。我们称之为ADU-Depth的知识传授框架。我们希望通过将教师网络的学习知识转移到学生网络中，以提高单眼深度估计的精度。为了实现领域适应和确保专业转移，我们在训练阶段使用了注意力适应的特征传授和聚焦深度适应的回应传授。此外，我们Explicitly 模型深度估计的不确定性，以导引传授在特征空间和结果空间中。我们的实验结果显示，我们的提案可以在真实的深度估计数据集KITTI和DrivingStereo上得到高效的性能，并在挑战性的KITTI online排名中排名第一。
</details></li>
</ul>
<hr>
<h2 id="Volumetric-Semantically-Consistent-3D-Panoptic-Mapping"><a href="#Volumetric-Semantically-Consistent-3D-Panoptic-Mapping" class="headerlink" title="Volumetric Semantically Consistent 3D Panoptic Mapping"></a>Volumetric Semantically Consistent 3D Panoptic Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14737">http://arxiv.org/abs/2309.14737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/y9miao/consistentpanopticslam">https://github.com/y9miao/consistentpanopticslam</a></li>
<li>paper_authors: Yang Miao, Iro Armeni, Marc Pollefeys, Daniel Barath</li>
<li>for: 生成自适应、准确、高效的semantic 3D地图，用于无结构环境中的自主机器人。</li>
<li>methods: 基于Voxel-TSDF表示法，具有semantic prediction confidence的集成、semantic和实例一致的3D区域生成、基于图像优化的semantic标签和实例精度提升等新方法。</li>
<li>results: 在公共大规模数据集上达到了state-of-the-art精度水平，提高了许多常用的指标，并且指出了现有研究评价中的一个缺陷：使用真实轨迹而不是SLAM估计的轨迹作为输入，会导致评价结果与实际数据之间存在很大差距。<details>
<summary>Abstract</summary>
We introduce an online 2D-to-3D semantic instance mapping algorithm aimed at generating comprehensive, accurate, and efficient semantic 3D maps suitable for autonomous agents in unstructured environments. The proposed approach is based on a Voxel-TSDF representation used in recent algorithms. It introduces novel ways of integrating semantic prediction confidence during mapping, producing semantic and instance-consistent 3D regions. Further improvements are achieved by graph optimization-based semantic labeling and instance refinement. The proposed method achieves accuracy superior to the state of the art on public large-scale datasets, improving on a number of widely used metrics. We also highlight a downfall in the evaluation of recent studies: using the ground truth trajectory as input instead of a SLAM-estimated one substantially affects the accuracy, creating a large gap between the reported results and the actual performance on real-world data.
</details>
<details>
<summary>摘要</summary>
我们介绍一种在线2D-to-3D语义实例映射算法，旨在生成全面、准确和高效的语义3D地图，适用于无结构环境中的自主机器人。该方法基于最近的Voxel-TSDF表示方式，并提出了新的语义预测信任级别的集成方法，生成语义和实例一致的3D区域。此外，我们还提出了基于图优化的语义标签和实例细化方法，进一步提高方法的准确性。我们的方法在大规模公共数据集上实现了比STATE-OF-THE-ART更高的准确度，提高了一些广泛使用的指标。此外，我们还指出了评估最近研究的缺点：使用真实的轨迹作为输入而不是SLAM估计的轨迹，会导致评估结果与实际数据中的性能存在大差异。
</details></li>
</ul>
<hr>
<h2 id="Explaining-Deep-Face-Algorithms-through-Visualization-A-Survey"><a href="#Explaining-Deep-Face-Algorithms-through-Visualization-A-Survey" class="headerlink" title="Explaining Deep Face Algorithms through Visualization: A Survey"></a>Explaining Deep Face Algorithms through Visualization: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14715">http://arxiv.org/abs/2309.14715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thrupthi Ann John, Vineeth N Balasubramanian, C. V. Jawahar</li>
<li>for: 本研究旨在 bridging the gap between deep face models 和 human understanding, by conducting a meta-analysis of explainability algorithms in the face domain.</li>
<li>methods: 本研究使用了一系列的普适可视化算法，并对各种面部模型进行计算可视化。</li>
<li>results: 研究发现了面部网络结构和层次结构的细节，以及可视化算法的设计考虑事项。此外，通过用户研究，确定了实用的可视化算法，以便对 AI 专业人员提供可读性的可视化工具。<details>
<summary>Abstract</summary>
Although current deep models for face tasks surpass human performance on some benchmarks, we do not understand how they work. Thus, we cannot predict how it will react to novel inputs, resulting in catastrophic failures and unwanted biases in the algorithms. Explainable AI helps bridge the gap, but currently, there are very few visualization algorithms designed for faces. This work undertakes a first-of-its-kind meta-analysis of explainability algorithms in the face domain. We explore the nuances and caveats of adapting general-purpose visualization algorithms to the face domain, illustrated by computing visualizations on popular face models. We review existing face explainability works and reveal valuable insights into the structure and hierarchy of face networks. We also determine the design considerations for practical face visualizations accessible to AI practitioners by conducting a user study on the utility of various explainability algorithms.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管当前的深度模型在面任务上已经超越了人类表现，但我们并不理解它们如何工作。这意味着我们无法预测它们如何对新输入react，导致 catastrophic failures 和不想要的偏见在算法中。可见 AI 可以帮助bridging the gap，但目前有很少的视觉化算法适用于面。这个工作是一次首次的 meta-analysis of explainability algorithms in the face domain。我们探索了适应面模型的通用视觉化算法的妙处和缺点，通过计算面模型上的视觉化来 Ilustrated。我们还回顾了现有的面可见工作，并发现了面网络的结构和层次结构的 valuable insights。最后，我们确定了实用的面视觉化设计考虑因素，通过对各种可见算法的用户研究来确定。
</details></li>
</ul>
<hr>
<h2 id="Bootstrap-Diffusion-Model-Curve-Estimation-for-High-Resolution-Low-Light-Image-Enhancement"><a href="#Bootstrap-Diffusion-Model-Curve-Estimation-for-High-Resolution-Low-Light-Image-Enhancement" class="headerlink" title="Bootstrap Diffusion Model Curve Estimation for High Resolution Low-Light Image Enhancement"></a>Bootstrap Diffusion Model Curve Estimation for High Resolution Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14709">http://arxiv.org/abs/2309.14709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiancheng Huang, Yifan Liu, Shifeng Chen</li>
<li>For: 本研究目的是提出一种基于学习的弱光照图像提升方法，以解决现有方法的两大问题：高分辨率图像的计算成本高和同时增强和净化不够。* Methods: 本方法使用了拟合分布模型，通过学习分布参数的分布来代替传统的 нормаль光照图像本身。具体来说，我们采用了抛物线估计方法来处理高分辨率图像，其中抛物线参数由我们的拟合分布模型来估计。此外，我们还在每次抛物线调整中应用了净化模块，以净化每次调整后的提升结果。* Results: 我们在常用的 benchmark 数据集上进行了广泛的实验，并证明了 BDCE 在质量和量化上达到了领先水平。<details>
<summary>Abstract</summary>
Learning-based methods have attracted a lot of research attention and led to significant improvements in low-light image enhancement. However, most of them still suffer from two main problems: expensive computational cost in high resolution images and unsatisfactory performance in simultaneous enhancement and denoising. To address these problems, we propose BDCE, a bootstrap diffusion model that exploits the learning of the distribution of the curve parameters instead of the normal-light image itself. Specifically, we adopt the curve estimation method to handle the high-resolution images, where the curve parameters are estimated by our bootstrap diffusion model. In addition, a denoise module is applied in each iteration of curve adjustment to denoise the intermediate enhanced result of each iteration. We evaluate BDCE on commonly used benchmark datasets, and extensive experiments show that it achieves state-of-the-art qualitative and quantitative performance.
</details>
<details>
<summary>摘要</summary>
学习基于方法在低光照图像提升中吸引了很多研究人员的关注，并导致了显著的改善。然而，大多数方法仍然受到两个主要问题的困扰：高分辨率图像的计算成本高昂，同时同时提升和净化的性能不足。为解决这些问题，我们提议BDCE，一种使用分布的演化模型，利用学习分布参数的Curve estimation方法来处理高分辨率图像。另外，在每次曲线调整中，我们采用了一个净化模块，以净化每次调整后的图像结果。我们在常用的 referencia dataset上进行了广泛的实验，结果表明BDCE可以达到领先的质量和量化性能。
</details></li>
</ul>
<hr>
<h2 id="Tile-Classification-Based-Viewport-Prediction-with-Multi-modal-Fusion-Transformer"><a href="#Tile-Classification-Based-Viewport-Prediction-with-Multi-modal-Fusion-Transformer" class="headerlink" title="Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer"></a>Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14704">http://arxiv.org/abs/2309.14704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihao Zhang, Yiwei Chen, Weizhan Zhang, Caixia Yan, Qinghua Zheng, Qi Wang, Wangdu Chen</li>
<li>for: 这种论文主要是为了提出一种基于多模态融合 трансформа器的视窗预测方法，以解决现有的轨迹基本方法存在缺乏稳定性和信息拼接问题。</li>
<li>methods: 该方法使用变换器网络EXTRACTER来抽取每种模态中的长距离依赖关系，然后 Mine intra-和inter-模态关系以捕捉视频内容和用户历史输入的共同影响。此外，该方法还将未来的块分为两类：用户有兴趣或无兴趣，并选择未来的视窗为包含最多用户有兴趣的块。</li>
<li>results: 对于两个广泛使用的PVS-HM和Xu-Gaze数据集，MFTR表现出优于状态艺术方法的平均预测精度和重叠率，同时具有竞争的计算效率。<details>
<summary>Abstract</summary>
Viewport prediction is a crucial aspect of tile-based 360 video streaming system. However, existing trajectory based methods lack of robustness, also oversimplify the process of information construction and fusion between different modality inputs, leading to the error accumulation problem. In this paper, we propose a tile classification based viewport prediction method with Multi-modal Fusion Transformer, namely MFTR. Specifically, MFTR utilizes transformer-based networks to extract the long-range dependencies within each modality, then mine intra- and inter-modality relations to capture the combined impact of user historical inputs and video contents on future viewport selection. In addition, MFTR categorizes future tiles into two categories: user interested or not, and selects future viewport as the region that contains most user interested tiles. Comparing with predicting head trajectories, choosing future viewport based on tile's binary classification results exhibits better robustness and interpretability. To evaluate our proposed MFTR, we conduct extensive experiments on two widely used PVS-HM and Xu-Gaze dataset. MFTR shows superior performance over state-of-the-art methods in terms of average prediction accuracy and overlap ratio, also presents competitive computation efficiency.
</details>
<details>
<summary>摘要</summary>
视窗预测是360度视频流式系统中的关键方面，但现有的轨迹基于方法缺乏Robustness，同时过分解信息构建和多Modal输入之间的融合过程，导致错误积累问题。在本文中，我们提出了基于多模态融合变换器的瓦片分类视窗预测方法，称之为MFTR。具体来说，MFTR利用变换器网络EXTRACT每个模式中的长距离依赖关系，然后挖掘INTRA-和INTER-模式关系，以捕捉用户历史输入和视频内容的共同影响 future viewport选择。此外，MFTR将未来瓦片分为两类：用户有趣或不，并选择未来视窗为包含最多用户有趣瓦片的区域。与predicting head trajectories不同，基于瓦片的二分类结果选择未来视窗显示更高的Robustness和可读性。为评估我们提出的MFTR，我们在两个广泛使用的PVS-HM和Xu-Gaze数据集上进行了广泛的实验。MFTR在状态前方法的平均预测精度和重叠率方面显示出superior性，同时具有竞争力的计算效率。
</details></li>
</ul>
<hr>
<h2 id="Structure-Invariant-Transformation-for-better-Adversarial-Transferability"><a href="#Structure-Invariant-Transformation-for-better-Adversarial-Transferability" class="headerlink" title="Structure Invariant Transformation for better Adversarial Transferability"></a>Structure Invariant Transformation for better Adversarial Transferability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14700">http://arxiv.org/abs/2309.14700</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaosen-wang/sit">https://github.com/xiaosen-wang/sit</a></li>
<li>paper_authors: Xiaosen Wang, Zeliang Zhang, Jianping Zhang</li>
<li>for: This paper aims to improve the effectiveness of black-box adversarial attacks on deep neural networks (DNNs) by proposing a novel input transformation-based attack called Structure Invariant Attack (SIA).</li>
<li>methods: The SIA attack applies random image transformations to each image block to create a diverse set of images for gradient calculation, improving the transferability of the attack compared to existing methods.</li>
<li>results: The proposed SIA attack exhibits better transferability than existing state-of-the-art (SOTA) input transformation-based attacks on both CNN-based and transformer-based models, as demonstrated through extensive experiments on the ImageNet dataset.<details>
<summary>Abstract</summary>
Given the severe vulnerability of Deep Neural Networks (DNNs) against adversarial examples, there is an urgent need for an effective adversarial attack to identify the deficiencies of DNNs in security-sensitive applications. As one of the prevalent black-box adversarial attacks, the existing transfer-based attacks still cannot achieve comparable performance with the white-box attacks. Among these, input transformation based attacks have shown remarkable effectiveness in boosting transferability. In this work, we find that the existing input transformation based attacks transform the input image globally, resulting in limited diversity of the transformed images. We postulate that the more diverse transformed images result in better transferability. Thus, we investigate how to locally apply various transformations onto the input image to improve such diversity while preserving the structure of image. To this end, we propose a novel input transformation based attack, called Structure Invariant Attack (SIA), which applies a random image transformation onto each image block to craft a set of diverse images for gradient calculation. Extensive experiments on the standard ImageNet dataset demonstrate that SIA exhibits much better transferability than the existing SOTA input transformation based attacks on CNN-based and transformer-based models, showing its generality and superiority in boosting transferability. Code is available at https://github.com/xiaosen-wang/SIT.
</details>
<details>
<summary>摘要</summary>
由于深度神经网络（DNNs）对攻击性示例的漏洞性，有一项紧迫需要有效的攻击方法来识别DNNs在安全敏感应用中的缺陷。现有的黑盒攻击中的传输基于攻击仍然无法达到相对比白盒攻击的性能。其中，输入变换基于的攻击表现出了remarkable的效果，但是现有的输入变换基于的攻击仍然只能对输入图像进行全局性的变换，导致变换图像的多样性受限。我们认为，更多的多样性变换图像可以提高传输性。因此，我们开展了一种新的输入变换基于的攻击方法，即结构不变攻击（SIA），它在每个图像块上随机应用图像变换来生成一组多样的图像，以便在梯度计算中更好地保持图像的结构。我们对标准的ImageNet数据集进行了广泛的实验，结果显示，SIA比现有的SOTA输入变换基于的攻击更有效，可以在CNN-based和transformer-based模型上提高传输性，这表明了它的通用性和超越性。代码可以在https://github.com/xiaosen-wang/SIT上获取。
</details></li>
</ul>
<hr>
<h2 id="DriveSceneGen-Generating-Diverse-and-Realistic-Driving-Scenarios-from-Scratch"><a href="#DriveSceneGen-Generating-Diverse-and-Realistic-Driving-Scenarios-from-Scratch" class="headerlink" title="DriveSceneGen: Generating Diverse and Realistic Driving Scenarios from Scratch"></a>DriveSceneGen: Generating Diverse and Realistic Driving Scenarios from Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14685">http://arxiv.org/abs/2309.14685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SS47816/DriveSceneGen">https://github.com/SS47816/DriveSceneGen</a></li>
<li>paper_authors: Shuo Sun, Zekai Gu, Tianchen Sun, Jiawei Sun, Chengran Yuan, Yuhang Han, Dongen Li, Marcelo H. Ang Jr</li>
<li>for: This paper is written for the development and validation of autonomous driving systems, specifically to address the lack of diverse and realistic traffic scenarios in large quantities.</li>
<li>methods: The paper introduces DriveSceneGen, a data-driven driving scenario generation method that learns from real-world driving datasets and generates entire dynamic driving scenarios from scratch.</li>
<li>results: The experimental results on 5,000 generated scenarios show that DriveSceneGen can generate novel driving scenarios with high fidelity and diversity, and is able to generate scenarios that align with real-world data distributions.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了开发和验证自动驾驶系统而写的，特别是解决现实世界中缺乏具有多样性和真实性的交通场景的问题。</li>
<li>methods: 论文引入了 DriveSceneGen，一种基于实际驾驶数据的驾驶场景生成方法，可以从零开始生成整个动态驾驶场景。</li>
<li>results: 对5000个生成的场景进行了实验，结果显示，DriveSceneGen可以生成高准确性和多样性的驾驶场景，并且能够生成与现实世界数据分布相似的场景。<details>
<summary>Abstract</summary>
Realistic and diverse traffic scenarios in large quantities are crucial for the development and validation of autonomous driving systems. However, owing to numerous difficulties in the data collection process and the reliance on intensive annotations, real-world datasets lack sufficient quantity and diversity to support the increasing demand for data. This work introduces DriveSceneGen, a data-driven driving scenario generation method that learns from the real-world driving dataset and generates entire dynamic driving scenarios from scratch. DriveSceneGen is able to generate novel driving scenarios that align with real-world data distributions with high fidelity and diversity. Experimental results on 5k generated scenarios highlight the generation quality, diversity, and scalability compared to real-world datasets. To the best of our knowledge, DriveSceneGen is the first method that generates novel driving scenarios involving both static map elements and dynamic traffic participants from scratch.
</details>
<details>
<summary>摘要</summary>
现实生活中的交通情况具有广泛的多样性和复杂性，这些情况是自动驾驶系统的开发和验证中非常重要的。然而，由于数据收集过程中的多个问题和对于数据的依赖，现实世界的数据缺乏量和多样性，无法满足增长中的数据需求。本研究提出了 DriveSceneGen，一种基于数据的驾驶情况生成方法，从真实世界的驾驶数据中学习，并从零生成完整的动态驾驶情况。DriveSceneGen 能够生成高匹配度和多样性的驾驶情况，并且可以与实际世界数据的分布相互适应。实验结果显示，DriveSceneGen 能够生成5000个高品质和多样性的驾驶情况，并且可以与实际世界数据的分布相互适应。根据我们所知，DriveSceneGen 是首个从零生成包含静止地图元素和动态交通参与者的驾驶情况的方法。
</details></li>
</ul>
<hr>
<h2 id="DONNAv2-–-Lightweight-Neural-Architecture-Search-for-Vision-tasks"><a href="#DONNAv2-–-Lightweight-Neural-Architecture-Search-for-Vision-tasks" class="headerlink" title="DONNAv2 – Lightweight Neural Architecture Search for Vision tasks"></a>DONNAv2 – Lightweight Neural Architecture Search for Vision tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14670">http://arxiv.org/abs/2309.14670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sweta Priyadarshi, Tianyu Jiang, Hsin-Pai Cheng, Sendil Krishna, Viswanath Ganapathy, Chirag Patel</li>
<li>for: 这个研究旨在开发一个具有 Computationally Efficient Neural Architecture Distillation（DONNA）的下一代神经网络架构，以便在装置在边缘设备上进行视觉应用的部署。</li>
<li>methods: 这个研究使用了一种名为DONNAv2的神经网络架构，并使用了一个简单的方法来减少 computationally extensive stage，这个方法是使用对各个块的损失函数作为对样本模型的表现度量。</li>
<li>results: 这个研究的结果显示，DONNAv2可以实现10倍的计算成本减少，并且可以在装置在Samsung Galaxy S10 mobile平台上进行硬件在轮试验。此外，DONNAv2还使用了封页知识传播范本来移除高测试成本的块。<details>
<summary>Abstract</summary>
With the growing demand for vision applications and deployment across edge devices, the development of hardware-friendly architectures that maintain performance during device deployment becomes crucial. Neural architecture search (NAS) techniques explore various approaches to discover efficient architectures for diverse learning tasks in a computationally efficient manner. In this paper, we present the next-generation neural architecture design for computationally efficient neural architecture distillation - DONNAv2 . Conventional NAS algorithms rely on a computationally extensive stage where an accuracy predictor is learned to estimate model performance within search space. This building of accuracy predictors helps them predict the performance of models that are not being finetuned. Here, we have developed an elegant approach to eliminate building the accuracy predictor and extend DONNA to a computationally efficient setting. The loss metric of individual blocks forming the network serves as the surrogate performance measure for the sampled models in the NAS search stage. To validate the performance of DONNAv2 we have performed extensive experiments involving a range of diverse vision tasks including classification, object detection, image denoising, super-resolution, and panoptic perception network (YOLOP). The hardware-in-the-loop experiments were carried out using the Samsung Galaxy S10 mobile platform. Notably, DONNAv2 reduces the computational cost of DONNA by 10x for the larger datasets. Furthermore, to improve the quality of NAS search space, DONNAv2 leverages a block knowledge distillation filter to remove blocks with high inference costs.
</details>
<details>
<summary>摘要</summary>
随着视觉应用的扩展和边缘设备的普及，发展具有高性能和可扩展性的硬件友好架构成为了不可或缺的。神经网络搜索（NAS）技术探索了许多方法，以便在计算效率高的情况下找到适合多种学习任务的高效架构。在这篇论文中，我们介绍了下一代神经网络设计方法，即DONNAv2，用于计算效率高的神经网络采样。传统的NAS算法需要一个计算昂贵的阶段，用于学习一个准确性预测器，以便在搜索空间中估计模型的性能。我们在这篇论文中提出了一种简洁的方法，即使用网络块的损失度作为采样模型的表现度量。为验证DONNAv2的性能，我们进行了对多种多样化视觉任务的广泛实验，包括分类、物体检测、图像噪声纠正、超分辨率和拼接性见网络（YOLOP）。实验使用了Samsung Galaxy S10移动 платформой。值得注意的是，DONNAv2将DONNA的计算成本减少了10倍，并且通过使用块知识继承筛选来移除高计算成本的块。
</details></li>
</ul>
<hr>
<h2 id="ZiCo-BC-A-Bias-Corrected-Zero-Shot-NAS-for-Vision-Tasks"><a href="#ZiCo-BC-A-Bias-Corrected-Zero-Shot-NAS-for-Vision-Tasks" class="headerlink" title="ZiCo-BC: A Bias Corrected Zero-Shot NAS for Vision Tasks"></a>ZiCo-BC: A Bias Corrected Zero-Shot NAS for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14666">http://arxiv.org/abs/2309.14666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kartikeya Bhardwaj, Hsin-Pai Cheng, Sweta Priyadarshi, Zhuojin Li</li>
<li>for: 这个论文主要是为了研究零shot neural architecture search（NAS）方法的可靠性和广泛应用性。</li>
<li>methods: 该论文使用了现有的零shot proxy ZiCo，并对其进行了修正以解决偏见问题。</li>
<li>results: 该论文通过对多种视觉任务（图像分类、物体检测和 semantic segmentation）进行了广泛的实验，并证明了our approach可以在Samsung Galaxy S10设备上实现更高的准确率和更低的延迟时间。<details>
<summary>Abstract</summary>
Zero-Shot Neural Architecture Search (NAS) approaches propose novel training-free metrics called zero-shot proxies to substantially reduce the search time compared to the traditional training-based NAS. Despite the success on image classification, the effectiveness of zero-shot proxies is rarely evaluated on complex vision tasks such as semantic segmentation and object detection. Moreover, existing zero-shot proxies are shown to be biased towards certain model characteristics which restricts their broad applicability. In this paper, we empirically study the bias of state-of-the-art (SOTA) zero-shot proxy ZiCo across multiple vision tasks and observe that ZiCo is biased towards thinner and deeper networks, leading to sub-optimal architectures. To solve the problem, we propose a novel bias correction on ZiCo, called ZiCo-BC. Our extensive experiments across various vision tasks (image classification, object detection and semantic segmentation) show that our approach can successfully search for architectures with higher accuracy and significantly lower latency on Samsung Galaxy S10 devices.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Zero-Shot neural architecture search (NAS) approaches propose novel training-free metrics called zero-shot proxies to significantly reduce the search time compared to traditional training-based NAS. Despite the success on image classification, the effectiveness of zero-shot proxies is rarely evaluated on complex vision tasks such as semantic segmentation and object detection. Moreover, existing zero-shot proxies are shown to be biased towards certain model characteristics which restricts their broad applicability. In this paper, we empirically study the bias of state-of-the-art (SOTA) zero-shot proxy ZiCo across multiple vision tasks and observe that ZiCo is biased towards thinner and deeper networks, leading to sub-optimal architectures. To solve the problem, we propose a novel bias correction on ZiCo, called ZiCo-BC. Our extensive experiments across various vision tasks (image classification, object detection and semantic segmentation) show that our approach can successfully search for architectures with higher accuracy and significantly lower latency on Samsung Galaxy S10 devices.中文简体版： zero-shot neural architecture search (NAS) 方法提出了新的训练不需要的度量，以减少传统的训练基于 NAS 的搜索时间。 despite 图像分类 tasks 的成功，zero-shot proxies 在复杂的视觉任务，如 semantic segmentation 和 object detection 中的效果 rarely 评估。 In addition, 现有的 zero-shot proxies 具有一定的特征偏好，限制了它们的普遍性。 在这篇 paper 中，我们对 state-of-the-art (SOTA) zero-shot proxy ZiCo 的 bias 进行了 empirical study，并发现 ZiCo 偏好于较为细长和深的网络，导致非优化的 architecture。 To solve the problem, we propose a novel bias correction on ZiCo, called ZiCo-BC. Our extensive experiments across various vision tasks (image classification, object detection and semantic segmentation) show that our approach can successfully search for architectures with higher accuracy and significantly lower latency on Samsung Galaxy S10 devices.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-3D-Multi-Object-Cooperative-Tracking-for-Autonomous-Driving-via-Differentiable-Multi-Sensor-Kalman-Filter"><a href="#Probabilistic-3D-Multi-Object-Cooperative-Tracking-for-Autonomous-Driving-via-Differentiable-Multi-Sensor-Kalman-Filter" class="headerlink" title="Probabilistic 3D Multi-Object Cooperative Tracking for Autonomous Driving via Differentiable Multi-Sensor Kalman Filter"></a>Probabilistic 3D Multi-Object Cooperative Tracking for Autonomous Driving via Differentiable Multi-Sensor Kalman Filter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14655">http://arxiv.org/abs/2309.14655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hsu-kuang Chiu, Chien-Yi Wang, Min-Hung Chen, Stephen F. Smith</li>
<li>for: This paper aims to improve the reliability and accuracy of multi-object cooperative tracking in autonomous driving by leveraging vehicle-to-vehicle (V2V) communication and a differentiable multi-sensor Kalman Filter.</li>
<li>methods: The proposed method uses a differentiable multi-sensor Kalman Filter to estimate the measurement uncertainty of each detection from different connected autonomous vehicles (CAVs), which enables better utilization of the theoretical optimality property of Kalman Filter-based tracking algorithms.</li>
<li>results: The experimental results show that the proposed algorithm improves the tracking accuracy by 17% with only 0.037x communication costs compared to the state-of-the-art method in V2V4Real.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目的是通过追踪多个目标的多感器协同追踪方法来提高自动驾驶车辆的可靠性和准确性。</li>
<li>methods: 该提议的方法使用可微多感器卡尔曼滤波器来估算各个探测机器人的测量不确定性，从而更好地利用卡尔曼滤波器基于追踪算法的理论优化性。</li>
<li>results: 实验结果显示，该提议的算法可以提高追踪精度 by 17%，并且只需0.037x的通信成本相比于现有方法在V2V4Real中。<details>
<summary>Abstract</summary>
Current state-of-the-art autonomous driving vehicles mainly rely on each individual sensor system to perform perception tasks. Such a framework's reliability could be limited by occlusion or sensor failure. To address this issue, more recent research proposes using vehicle-to-vehicle (V2V) communication to share perception information with others. However, most relevant works focus only on cooperative detection and leave cooperative tracking an underexplored research field. A few recent datasets, such as V2V4Real, provide 3D multi-object cooperative tracking benchmarks. However, their proposed methods mainly use cooperative detection results as input to a standard single-sensor Kalman Filter-based tracking algorithm. In their approach, the measurement uncertainty of different sensors from different connected autonomous vehicles (CAVs) may not be properly estimated to utilize the theoretical optimality property of Kalman Filter-based tracking algorithms. In this paper, we propose a novel 3D multi-object cooperative tracking algorithm for autonomous driving via a differentiable multi-sensor Kalman Filter. Our algorithm learns to estimate measurement uncertainty for each detection that can better utilize the theoretical property of Kalman Filter-based tracking methods. The experiment results show that our algorithm improves the tracking accuracy by 17% with only 0.037x communication costs compared with the state-of-the-art method in V2V4Real.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a novel 3D multi-object cooperative tracking algorithm for autonomous driving via a differentiable multi-sensor Kalman Filter. Our algorithm learns to estimate measurement uncertainty for each detection, which can better utilize the theoretical property of Kalman Filter-based tracking methods. The experiment results show that our algorithm improves the tracking accuracy by 17% with only 0.037x communication costs compared with the state-of-the-art method in V2V4Real.
</details></li>
</ul>
<hr>
<h2 id="Free-Discontinuity-Design-With-an-Application-to-the-Economic-Effects-of-Internet-Shutdowns"><a href="#Free-Discontinuity-Design-With-an-Application-to-the-Economic-Effects-of-Internet-Shutdowns" class="headerlink" title="Free Discontinuity Design: With an Application to the Economic Effects of Internet Shutdowns"></a>Free Discontinuity Design: With an Application to the Economic Effects of Internet Shutdowns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14630">http://arxiv.org/abs/2309.14630</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/davidvandijcke/fdd">https://github.com/davidvandijcke/fdd</a></li>
<li>paper_authors: Florian Gunsilius, David Van Dijcke</li>
<li>for: 这篇论文是为了研究干扰 assigning 的影响而写的。</li>
<li>methods: 这篇论文使用了一种非 Parametric 方法来估计干扰 assigning 导致的不连续性。这种方法基于 Mumford-Shah 函数的卷积relaxation，并且我们证明了它的标识和收敛。</li>
<li>results: 使用这种方法，作者发现印度的互联网停机导致经济活动减少了超过 50%，这大大超过了之前的估计，并为全球数字经济带来新的灯光。<details>
<summary>Abstract</summary>
Thresholds in treatment assignments can produce discontinuities in outcomes, revealing causal insights. In many contexts, like geographic settings, these thresholds are unknown and multivariate. We propose a non-parametric method to estimate the resulting discontinuities by segmenting the regression surface into smooth and discontinuous parts. This estimator uses a convex relaxation of the Mumford-Shah functional, for which we establish identification and convergence. Using our method, we estimate that an internet shutdown in India resulted in a reduction of economic activity by over 50%, greatly surpassing previous estimates and shedding new light on the true cost of such shutdowns for digital economies globally.
</details>
<details>
<summary>摘要</summary>
干预分配的阈值可能会产生输出的破碎，揭示了 causal 的增长。在许多情况下，如地理设置，这些阈值未知并且多变量。我们提议一种非 Parametric 方法来估计这些破碎的结果，segments 回归表面为平滑和破碎部分。这个估计器使用 Mumford-Shah 函数的凸relaxation，我们证明其标识和收敛。使用我们的方法，我们估计印度的互联网停机导致经济活动减少了超过 50%，大大超过了之前的估计，为全球数字经济带来新的见解。
</details></li>
</ul>
<hr>
<h2 id="Text-to-Image-Generation-for-Abstract-Concepts"><a href="#Text-to-Image-Generation-for-Abstract-Concepts" class="headerlink" title="Text-to-Image Generation for Abstract Concepts"></a>Text-to-Image Generation for Abstract Concepts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14623">http://arxiv.org/abs/2309.14623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayi Liao, Xu Chen, Qiang Fu, Lun Du, Xiangnan He, Xiang Wang, Shi Han, Dongmei Zhang<br>for: 这种研究旨在提高大规模模型在各个领域中表达抽象概念的能力，例如自然语言处理和计算机视觉。methods: 该研究基于三层艺术作品理论，将抽象概念 clarify为明确的意图，然后通过语言模型转换为具有相关含义的物理对象，最后使用概念依赖的形式从LM中提取形态模式集来集成信息。results: 该研究的评估结果表明，该框架可以帮助创建具有充分表达抽象概念的图像，并且与人类评估和新定义的概念分数指标表现良好。<details>
<summary>Abstract</summary>
Recent years have witnessed the substantial progress of large-scale models across various domains, such as natural language processing and computer vision, facilitating the expression of concrete concepts. Unlike concrete concepts that are usually directly associated with physical objects, expressing abstract concepts through natural language requires considerable effort, which results from their intricate semantics and connotations. An alternative approach is to leverage images to convey rich visual information as a supplement. Nevertheless, existing Text-to-Image (T2I) models are primarily trained on concrete physical objects and tend to fail to visualize abstract concepts. Inspired by the three-layer artwork theory that identifies critical factors, intent, object and form during artistic creation, we propose a framework of Text-to-Image generation for Abstract Concepts (TIAC). The abstract concept is clarified into a clear intent with a detailed definition to avoid ambiguity. LLMs then transform it into semantic-related physical objects, and the concept-dependent form is retrieved from an LLM-extracted form pattern set. Information from these three aspects will be integrated to generate prompts for T2I models via LLM. Evaluation results from human assessments and our newly designed metric concept score demonstrate the effectiveness of our framework in creating images that can sufficiently express abstract concepts.
</details>
<details>
<summary>摘要</summary>
recent years have witnessed significant progress in large-scale models across various domains, such as natural language processing and computer vision, which has facilitated the expression of concrete concepts. However, expressing abstract concepts through natural language is much more challenging due to their complex semantics and connotations. To address this issue, we can leverage images to convey rich visual information as a supplement. However, existing Text-to-Image (T2I) models are primarily trained on concrete physical objects and tend to fail to visualize abstract concepts.Inspired by the three-layer artwork theory that identifies critical factors, intent, object, and form during artistic creation, we propose a framework for Text-to-Image generation for Abstract Concepts (TIAC). The abstract concept is first clarified into a clear intent with a detailed definition to avoid ambiguity. Then, LLMs (Large Language Models) transform it into semantic-related physical objects, and the concept-dependent form is retrieved from an LLM-extracted form pattern set. Finally, information from these three aspects is integrated to generate prompts for T2I models via LLM.Our evaluation results from human assessments and our newly designed metric, concept score, demonstrate the effectiveness of our framework in creating images that can sufficiently express abstract concepts.
</details></li>
</ul>
<hr>
<h2 id="NDC-Scene-Boost-Monocular-3D-Semantic-Scene-Completion-in-Normalized-Device-Coordinates-Space"><a href="#NDC-Scene-Boost-Monocular-3D-Semantic-Scene-Completion-in-Normalized-Device-Coordinates-Space" class="headerlink" title="NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space"></a>NDC-Scene: Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14616">http://arxiv.org/abs/2309.14616</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jiawei-Yao0812/NDCScene">https://github.com/Jiawei-Yao0812/NDCScene</a></li>
<li>paper_authors: Jiawei Yao, Chuming Li, Keqiang Sun, Yingjie Cai, Hao Li, Wanli Ouyang, Hongsheng Li</li>
<li>For: 提高单目3D semantic scene completion（SSC）的精度和效率，解决当前状态OF-THE-ART方法存在的特征抽象、姿态异常和计算不均衡等问题。* Methods: 提出了一种 Normalized Device Coordinates scene completion network（NDC-Scene），通过进行逐步修复depth维度的归一化设备坐标（NDC）空间，而不是直接将2D特征图卷积到世界空间中，以解决当前状态OF-THE-ART方法的特征抽象和姿态异常问题。同时，设计了一个适应深度的双 decode器，以同时进行2D和3D特征图的混合和提升。* Results: 经验证明，提出的方法在SemanticKITTI和NYUv2 dataset上比现状态OF-THE-ART方法表现更高，并且可以更好地处理各种复杂的场景和姿态。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Jiawei-Yao0812/NDCScene%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Jiawei-Yao0812/NDCScene中下载。</a><details>
<summary>Abstract</summary>
Monocular 3D Semantic Scene Completion (SSC) has garnered significant attention in recent years due to its potential to predict complex semantics and geometry shapes from a single image, requiring no 3D inputs. In this paper, we identify several critical issues in current state-of-the-art methods, including the Feature Ambiguity of projected 2D features in the ray to the 3D space, the Pose Ambiguity of the 3D convolution, and the Computation Imbalance in the 3D convolution across different depth levels. To address these problems, we devise a novel Normalized Device Coordinates scene completion network (NDC-Scene) that directly extends the 2D feature map to a Normalized Device Coordinates (NDC) space, rather than to the world space directly, through progressive restoration of the dimension of depth with deconvolution operations. Experiment results demonstrate that transferring the majority of computation from the target 3D space to the proposed normalized device coordinates space benefits monocular SSC tasks. Additionally, we design a Depth-Adaptive Dual Decoder to simultaneously upsample and fuse the 2D and 3D feature maps, further improving overall performance. Our extensive experiments confirm that the proposed method consistently outperforms state-of-the-art methods on both outdoor SemanticKITTI and indoor NYUv2 datasets. Our code are available at https://github.com/Jiawei-Yao0812/NDCScene.
</details>
<details>
<summary>摘要</summary>
《单目3D semantics场景完成（SSC）》在最近几年内引起了广泛的关注，因为它可以从单一图像中预测复杂的 semantics和geometry形状，无需3D输入。在这篇论文中，我们确定了当前状态艺术方法中的一些关键问题，包括 проекed 2D特征在射线空间中的特征歧义、3D卷积中的姿态歧义和3D卷积在不同深度水平上的计算不均衡。为解决这些问题，我们提出了一种新的Normalized Device Coordinates场景完成网络（NDC-Scene），通过逐渐恢复depth维度的卷积操作来直接将2D特征图射到Normalized Device Coordinates（NDC）空间中，而不是直接射到世界空间中。实验结果表明，将大多数计算从目标3D空间传播到我们提议的 Normalized Device Coordinates空间中得到了monocular SSC任务的改进。此外，我们还设计了一种适应深度的双解码器，以同时提高2D和3D特征图的 upsampling 和融合，进一步提高总性能。我们的广泛实验表明，我们的方法在SemanticKITTI和NYUv2 dataset上的表现都高于当前状态艺术方法。我们的代码可以在https://github.com/Jiawei-Yao0812/NDCScene中下载。
</details></li>
</ul>
<hr>
<h2 id="Event-Stream-based-Visual-Object-Tracking-A-High-Resolution-Benchmark-Dataset-and-A-Novel-Baseline"><a href="#Event-Stream-based-Visual-Object-Tracking-A-High-Resolution-Benchmark-Dataset-and-A-Novel-Baseline" class="headerlink" title="Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline"></a>Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14611">http://arxiv.org/abs/2309.14611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangxiao5791509/VisEvent_SOT_Benchmark">https://github.com/wangxiao5791509/VisEvent_SOT_Benchmark</a></li>
<li>paper_authors: Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang</li>
<li>for: 这 paper 的目的是提出一种基于 bio-inspired 事件摄像头的高速低延迟视觉跟踪方法，使用多模态&#x2F;多视图信息进行知识传递，以实现使用事件信号进行测试的高性能低延迟跟踪。</li>
<li>methods: 该 paper 使用一个教师 Transformer 网络和一个学生 Transformer 网络，通过对 RGB 帧和事件流同时进行训练，实现高速低延迟的视觉跟踪。此外，该 paper 还提出了一种层次知识填充策略，包括对比相似性、特征表示和响应图填充知识，以引导学生网络的学习。</li>
<li>results: 该 paper 在两个低分辨率的 dataset（FE240hz、VisEvent、COESOT）上进行了广泛的实验，以及提出了一个大规模高分辨率的 dataset（EventVOT），包含 1141 个视频，覆盖了人行、车辆、无人机等多种类别。结果表明，该方法可以在高速低延迟的情况下实现高性能的视觉跟踪。<details>
<summary>Abstract</summary>
Tracking using bio-inspired event cameras has drawn more and more attention in recent years. Existing works either utilize aligned RGB and event data for accurate tracking or directly learn an event-based tracker. The first category needs more cost for inference and the second one may be easily influenced by noisy events or sparse spatial resolution. In this paper, we propose a novel hierarchical knowledge distillation framework that can fully utilize multi-modal / multi-view information during training to facilitate knowledge transfer, enabling us to achieve high-speed and low-latency visual tracking during testing by using only event signals. Specifically, a teacher Transformer-based multi-modal tracking framework is first trained by feeding the RGB frame and event stream simultaneously. Then, we design a new hierarchical knowledge distillation strategy which includes pairwise similarity, feature representation, and response maps-based knowledge distillation to guide the learning of the student Transformer network. Moreover, since existing event-based tracking datasets are all low-resolution ($346 \times 260$), we propose the first large-scale high-resolution ($1280 \times 720$) dataset named EventVOT. It contains 1141 videos and covers a wide range of categories such as pedestrians, vehicles, UAVs, ping pongs, etc. Extensive experiments on both low-resolution (FE240hz, VisEvent, COESOT), and our newly proposed high-resolution EventVOT dataset fully validated the effectiveness of our proposed method. The dataset, evaluation toolkit, and source code are available on \url{https://github.com/Event-AHU/EventVOT_Benchmark}
</details>
<details>
<summary>摘要</summary>
很多研究者在最近几年内对使用生物体感知的事件摄像机进行跟踪吸引了越来越多的注意力。现有的方法可以通过同时使用RGB图像和事件数据进行准确的跟踪，或者直接学习事件基于的跟踪器。前一种方法需要更多的计算成本，而后一种可能会受到噪音事件或者稀疏的空间分辨率的影响。在这篇论文中，我们提出了一种新的层次知识填充框架，可以在训练时将多模态/多视图信息完全利用，以便知识传递，从而在测试时通过使用事件信号来实现高速低延迟的视觉跟踪。具体来说，我们首先使用Transformer基本多模态跟踪框架进行训练，并在其基础之上设计了一种新的层次知识填充策略，包括对比相似性、特征表示和响应地图基于的知识填充。此外，由于现有的事件基本跟踪数据库都是低分辨率（$346 \times 260），我们提出了首个大规模高分辨率（$1280 \times 720）数据库，名为EventVOT。它包括1141个视频，覆盖了人行、车辆、无人机、乒乓球等多种类别。我们在低分辨率（FE240hz、VisEvent、COESOT）和我们新提出的高分辨率EventVOT数据库上进行了广泛的实验，并证明了我们提出的方法的有效性。数据库、评价工具箱和源代码可以在https://github.com/Event-AHU/EventVOT_Benchmark上获取。
</details></li>
</ul>
<hr>
<h2 id="Progressive-Text-to-3D-Generation-for-Automatic-3D-Prototyping"><a href="#Progressive-Text-to-3D-Generation-for-Automatic-3D-Prototyping" class="headerlink" title="Progressive Text-to-3D Generation for Automatic 3D Prototyping"></a>Progressive Text-to-3D Generation for Automatic 3D Prototyping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14600">http://arxiv.org/abs/2309.14600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Texaser/MTN">https://github.com/Texaser/MTN</a></li>
<li>paper_authors: Han Yi, Zhedong Zheng, Xiangyu Xu, Tat-seng Chua</li>
<li>for: 本研究旨在提出一种基于自然语言描述的文本-三维生成方法，以减少手动设计三维模型的工作量，并提供一种更自然的用户交互方式。</li>
<li>methods: 我们提出了一种多尺度三平面网络（MTN）和一种新的进度学习策略，以解决文本-三维生成问题中精度的重要问题。MTN网络由四个三平面组成，从低分辨率向高分辨率进行过渡，以便优化大型输出。此外，我们还引入进度学习策略，使网络专注于困难的细腻特征。</li>
<li>results: 我们的实验表明，提出的方法在各种描述中具有优异表现，包括一些最为困难的描述，现有方法难以生成可行的形状。我们的方法能够成功地生成高质量的三维模型，并且能够减少用户需要提供的描述细节。<details>
<summary>Abstract</summary>
Text-to-3D generation is to craft a 3D object according to a natural language description. This can significantly reduce the workload for manually designing 3D models and provide a more natural way of interaction for users. However, this problem remains challenging in recovering the fine-grained details effectively and optimizing a large-size 3D output efficiently. Inspired by the success of progressive learning, we propose a Multi-Scale Triplane Network (MTN) and a new progressive learning strategy. As the name implies, the Multi-Scale Triplane Network consists of four triplanes transitioning from low to high resolution. The low-resolution triplane could serve as an initial shape for the high-resolution ones, easing the optimization difficulty. To further enable the fine-grained details, we also introduce the progressive learning strategy, which explicitly demands the network to shift its focus of attention from simple coarse-grained patterns to difficult fine-grained patterns. Our experiment verifies that the proposed method performs favorably against existing methods. For even the most challenging descriptions, where most existing methods struggle to produce a viable shape, our proposed method consistently delivers. We aspire for our work to pave the way for automatic 3D prototyping via natural language descriptions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Applications-of-Sequential-Learning-for-Medical-Image-Classification"><a href="#Applications-of-Sequential-Learning-for-Medical-Image-Classification" class="headerlink" title="Applications of Sequential Learning for Medical Image Classification"></a>Applications of Sequential Learning for Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14591">http://arxiv.org/abs/2309.14591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sohaib Naim, Brian Caffo, Haris I Sair, Craig K Jones</li>
<li>for: 这个研究的目的是为了开发一个适合小量医疗影像资料的神经网络训练框架，并为无阶级验证或测试集的训练提供依据。</li>
<li>methods: 我们提出了一种逐步学习方法，将和时间相关的小批量医疗影像资料用PyTorch convolutional neural networks (CNN)进行训练和逐步更新。我们解决了逐步学习中的遗传扩散、恰遇遗传和概念变化问题，并使用公开ailable的医疗MNIST和NIH胸部X射像数据集。我们开始比较两种方法：将神经网络先进行短时间的预训练，然后进行逐步学习，以及不进行预训练，直接进行逐步学习。我们还考虑了两种独特的训练和验证数据recruitment的方法，以确保获得完整的信息抽象。</li>
<li>results: 在第一个实验中，两种方法都成功地 дости了~95%的准确度门槛， although the short pre-training step enables sequential accuracy to plateau in fewer steps. 在第二个实验中，两种方法中的第二种方法（crosses the ~90% accuracy threshold much sooner）表现更好。在第三个实验中，这个方法在 Without pre-training 的情况下表现较差，但在具有预训练步骤的情况下，神经网络可以较快地超过 ~60% 的准确度门槛。<details>
<summary>Abstract</summary>
Purpose: The aim of this work is to develop a neural network training framework for continual training of small amounts of medical imaging data and create heuristics to assess training in the absence of a hold-out validation or test set.   Materials and Methods: We formulated a retrospective sequential learning approach that would train and consistently update a model on mini-batches of medical images over time. We address problems that impede sequential learning such as overfitting, catastrophic forgetting, and concept drift through PyTorch convolutional neural networks (CNN) and publicly available Medical MNIST and NIH Chest X-Ray imaging datasets. We begin by comparing two methods for a sequentially trained CNN with and without base pre-training. We then transition to two methods of unique training and validation data recruitment to estimate full information extraction without overfitting. Lastly, we consider an example of real-life data that shows how our approach would see mainstream research implementation.   Results: For the first experiment, both approaches successfully reach a ~95% accuracy threshold, although the short pre-training step enables sequential accuracy to plateau in fewer steps. The second experiment comparing two methods showed better performance with the second method which crosses the ~90% accuracy threshold much sooner. The final experiment showed a slight advantage with a pre-training step that allows the CNN to cross ~60% threshold much sooner than without pre-training.   Conclusion: We have displayed sequential learning as a serviceable multi-classification technique statistically comparable to traditional CNNs that can acquire data in small increments feasible for clinically realistic scenarios.
</details>
<details>
<summary>摘要</summary>
目的：本工作的目的是开发一个神经网络训练框架，用于逐步训练小量医学成像数据，并创造一些启发法来评估在缺乏预约验证或测试集时的训练。材料和方法：我们提出了一种回顾性顺序学习方法，可以在医学成像数据中逐步训练和更新模型。我们使用PyTorch神经网络（CNN）和公开available的医学MNIST和NIH胸部X射影数据集来解决顺序学习中的过拟合、恶化学习和概念漂移问题。我们首先比较了两种方法：一种是在顺序学习过程中不进行基础预训练，另一种是在顺序学习过程中进行基础预训练。然后，我们转移到了两种唯一的训练和验证数据招募方法来估计无损信息抽取。最后，我们考虑了一个实际的数据示例，显示了我们的方法在现实生活中的应用。结果：在第一个实验中，两种方法都能达到大约95%的准确率阈值，但短期预训练步骤使Sequential learning的准确率快速落在阈值。在第二个实验中， Comparing two methods showed better performance with the second method, which crossed the ~90% accuracy threshold much sooner. Finally, the third experiment showed a slight advantage with a pre-training step that allows the CNN to cross the ~60% threshold much sooner than without pre-training.结论：我们已经Displayed sequential learning as a serviceable multi-classification technique that is statistically comparable to traditional CNNs, and can acquire data in small increments feasible for clinically realistic scenarios.
</details></li>
</ul>
<hr>
<h2 id="DifAttack-Query-Efficient-Black-Box-Attack-via-Disentangled-Feature-Space"><a href="#DifAttack-Query-Efficient-Black-Box-Attack-via-Disentangled-Feature-Space" class="headerlink" title="DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space"></a>DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14585">http://arxiv.org/abs/2309.14585</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csjunjun/difattack">https://github.com/csjunjun/difattack</a></li>
<li>paper_authors: Liu Jun, Zhou Jiantao, Zeng Jiandian, Jinyu Tian</li>
<li>for:  This paper aims to propose an efficient score-based black-box adversarial attack method with a high Attack Success Rate (ASR) and good generalizability.</li>
<li>methods:  The proposed method, called DifAttack, uses a disentangled feature space to differentiate an image’s latent feature into an adversarial feature and a visual feature. The method trains an autoencoder for the disentanglement using pairs of clean images and their Adversarial Examples (AEs) generated from available surrogate models via white-box attack methods.</li>
<li>results:  The proposed method achieves significant improvements in ASR and query efficiency simultaneously, especially in the targeted attack and open-set scenarios. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/csjunjun/DifAttack.git">https://github.com/csjunjun/DifAttack.git</a> soon.Here’s the same information in Simplified Chinese:</li>
<li>for:  This paper aims to propose an efficient score-based black-box adversarial attack method with a high Attack Success Rate (ASR) and good generalizability.</li>
<li>methods:  The proposed method, called DifAttack, uses a disentangled feature space to differentiate an image’s latent feature into an adversarial feature and a visual feature. The method trains an autoencoder for the disentanglement using pairs of clean images and their Adversarial Examples (AEs) generated from available surrogate models via white-box attack methods.</li>
<li>results:  The proposed method achieves significant improvements in ASR and query efficiency simultaneously, especially in the targeted attack and open-set scenarios. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/csjunjun/DifAttack.git">https://github.com/csjunjun/DifAttack.git</a> soon.<details>
<summary>Abstract</summary>
This work investigates efficient score-based black-box adversarial attacks with a high Attack Success Rate (ASR) and good generalizability. We design a novel attack method based on a Disentangled Feature space, called DifAttack, which differs significantly from the existing ones operating over the entire feature space. Specifically, DifAttack firstly disentangles an image's latent feature into an adversarial feature and a visual feature, where the former dominates the adversarial capability of an image, while the latter largely determines its visual appearance. We train an autoencoder for the disentanglement by using pairs of clean images and their Adversarial Examples (AEs) generated from available surrogate models via white-box attack methods. Eventually, DifAttack iteratively optimizes the adversarial feature according to the query feedback from the victim model until a successful AE is generated, while keeping the visual feature unaltered. In addition, due to the avoidance of using surrogate models' gradient information when optimizing AEs for black-box models, our proposed DifAttack inherently possesses better attack capability in the open-set scenario, where the training dataset of the victim model is unknown. Extensive experimental results demonstrate that our method achieves significant improvements in ASR and query efficiency simultaneously, especially in the targeted attack and open-set scenarios. The code will be available at https://github.com/csjunjun/DifAttack.git soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/cs.CV_2023_09_26/" data-id="clogyj8y000i47cra9o7o6q27" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/cs.AI_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T12:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/cs.AI_2023_09_26/">cs.AI - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Prediction-and-Denoising-for-Large-scale-Multilingual-Self-supervised-Learning"><a href="#Joint-Prediction-and-Denoising-for-Large-scale-Multilingual-Self-supervised-Learning" class="headerlink" title="Joint Prediction and Denoising for Large-scale Multilingual Self-supervised Learning"></a>Joint Prediction and Denoising for Large-scale Multilingual Self-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15317">http://arxiv.org/abs/2309.15317</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Chen, Jiatong Shi, Brian Yan, Dan Berrebbi, Wangyou Zhang, Yifan Peng, Xuankai Chang, Soumi Maiti, Shinji Watanabe</li>
<li>for: 本文旨在提出一种多语言自监学习（SSL）方法，以减少训练数据量并提高可重复性。</li>
<li>methods: 本文提出了一种新的多Stage预训练方法，以Address语言偏好问题，并使用WavLM的共同预测和干扰预测。</li>
<li>results: 本文实现了与XLS-R相当的性能（ML-SUPERB），仅使用了少于10%的训练数据，并且可以使用academic compute进行实现。此外，还提出了一种使用vanilla HuBERT基础模型，可以维持94%的XLS-R性能，仅使用3%的数据、4个GPU和有限的试验。<details>
<summary>Abstract</summary>
Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM's joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than 10% of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain 94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.
</details>
<details>
<summary>摘要</summary>
多语言自监学习（SSL）经常落后于当前最佳方法（SOTA），这主要是因为处理多种语言的成本和复杂性。这会增加SSL的复制性问题，现在只有一些研究小组可以进行SSL的研究，因为它的资源使用。我们表明更强大的技术可以实际导致更有效的预训练，从而使SSL更加开放。我们提出了WavLabLM，它将在40000小时数据上扩展WavLM的联合预测和干扰。为建立WavLabLM，我们开发了一种新的多stage预训练方法，用于解决多语言数据的语言偏好问题。WavLabLM在ML-SUPERB上与XLS-R的性能相似，但使用了 fewer than 10% of the training data，使SSL在学术计算机中变得可行。我们还证明了可以通过使用vanilla HuBERT Base模型，以维持94%的XLS-R性能，只需3%的数据，4个GPU和有限的尝试。我们将所有代码和模型开源在ESPnet上。
</details></li>
</ul>
<hr>
<h2 id="MAPTree-Beating-“Optimal”-Decision-Trees-with-Bayesian-Decision-Trees"><a href="#MAPTree-Beating-“Optimal”-Decision-Trees-with-Bayesian-Decision-Trees" class="headerlink" title="MAPTree: Beating “Optimal” Decision Trees with Bayesian Decision Trees"></a>MAPTree: Beating “Optimal” Decision Trees with Bayesian Decision Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15312">http://arxiv.org/abs/2309.15312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thrungroup/maptree">https://github.com/thrungroup/maptree</a></li>
<li>paper_authors: Colin Sullivan, Mo Tiwari, Sebastian Thrun</li>
<li>for: 这个论文的目的是提出一种 bayesian 方法来推导决策树，通过 maximum a posteriori 推理来找到最优树。</li>
<li>methods: 这个论文使用的方法是通过和&#x2F;或搜索来找到最大 posteriori 树，并且提出了一种名为 MAPTree 的算法来实现这一点。</li>
<li>results: 在 16 个实际数据集上，MAPTree  Either outperforms baselines 或者和比较好的性能，但是它的树会更小。在一个 sintetic 数据集上，MAPTree  also demonstrates greater robustness to noise and better generalization than existing approaches。此外，MAPTree 还可以更快地找到最大 posteriori 树，并且可以提供一个 оптимальность 证明。<details>
<summary>Abstract</summary>
Decision trees remain one of the most popular machine learning models today, largely due to their out-of-the-box performance and interpretability. In this work, we present a Bayesian approach to decision tree induction via maximum a posteriori inference of a posterior distribution over trees. We first demonstrate a connection between maximum a posteriori inference of decision trees and AND/OR search. Using this connection, we propose an AND/OR search algorithm, dubbed MAPTree, which is able to recover the maximum a posteriori tree. Lastly, we demonstrate the empirical performance of the maximum a posteriori tree both on synthetic data and in real world settings. On 16 real world datasets, MAPTree either outperforms baselines or demonstrates comparable performance but with much smaller trees. On a synthetic dataset, MAPTree also demonstrates greater robustness to noise and better generalization than existing approaches. Finally, MAPTree recovers the maxiumum a posteriori tree faster than existing sampling approaches and, in contrast with those algorithms, is able to provide a certificate of optimality. The code for our experiments is available at https://github.com/ThrunGroup/maptree.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Importance-of-Multimodal-Emotion-Conditioning-and-Affect-Consistency-for-Embodied-Conversational-Agents"><a href="#The-Importance-of-Multimodal-Emotion-Conditioning-and-Affect-Consistency-for-Embodied-Conversational-Agents" class="headerlink" title="The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents"></a>The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15311">http://arxiv.org/abs/2309.15311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Che-Jui Chang, Samuel S. Sohn, Sen Zhang, Rajath Jayashankar, Muhammad Usman, Mubbasir Kapadia</li>
<li>for: 这个论文的目的是提高虚拟人工智能对人类的情感传递。</li>
<li>methods: 这个论文使用的方法是基于多Modal的行为生成框架，以实现情感的共同传递。</li>
<li>results: 研究发现，当多Modal的行为与主要情感保持一致时，人类对虚拟人工智能的情感传递得到了最高评分。同时，当某一Modal的行为与主要情感不一致时，人类对虚拟人工智能的情感传递明显减弱。<details>
<summary>Abstract</summary>
Previous studies regarding the perception of emotions for embodied virtual agents have shown the effectiveness of using virtual characters in conveying emotions through interactions with humans. However, creating an autonomous embodied conversational agent with expressive behaviors presents two major challenges. The first challenge is the difficulty of synthesizing the conversational behaviors for each modality that are as expressive as real human behaviors. The second challenge is that the affects are modeled independently, which makes it difficult to generate multimodal responses with consistent emotions across all modalities. In this work, we propose a conceptual framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We have conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimodal behaviors that are consistent and inconsistent with respect to a driving affect. The result shows that among all model conditions, our affect-consistent framework receives the highest Likert scores for the perception of driving affects. Our statistical analysis suggests that making a modality affect-inconsistent significantly decreases the perception of driving affects. We also observe that multimodal behaviors conditioned on consistent affects are more expressive compared to behaviors with inconsistent affects. Therefore, we conclude that multimodal emotion conditioning and affect consistency are vital to enhancing the perception of affects for embodied conversational agents.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Synthesizing conversational behaviors for each modality that are as expressive as real human behaviors is difficult.2. Affects are modeled independently, making it hard to generate multimodal responses with consistent emotions across all modalities.To address these challenges, we propose the ACTOR (Affect-Consistent mulTimodal behaviOR generation) framework, which aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimodal behaviors that are consistent and inconsistent with respect to a driving affect. The results show that our affect-consistent framework received the highest Likert scores for the perception of driving affects. Additionally, we found that making a modality affect-inconsistent significantly decreases the perception of driving affects, and that multimodal behaviors conditioned on consistent affects are more expressive compared to behaviors with inconsistent affects.Therefore, we conclude that multimodal emotion conditioning and affect consistency are crucial to enhancing the perception of affects for embodied conversational agents.</details></li>
</ol>
<hr>
<h2 id="Ruffle-Riley-Towards-the-Automated-Induction-of-Conversational-Tutoring-Systems"><a href="#Ruffle-Riley-Towards-the-Automated-Induction-of-Conversational-Tutoring-Systems" class="headerlink" title="Ruffle&amp;Riley: Towards the Automated Induction of Conversational Tutoring Systems"></a>Ruffle&amp;Riley: Towards the Automated Induction of Conversational Tutoring Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.01420">http://arxiv.org/abs/2310.01420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin Schmucker, Meng Xia, Amos Azaria, Tom Mitchell</li>
<li>for: 该论文旨在提出一种基于大语言模型的便捷教学系统，以提高学习效果和减少内容创作成本。</li>
<li>methods: 该系统利用大语言模型自动生成教学脚本，并通过两个基于LLM的代理（Ruffle&amp;Riley）实现自动化脚本排序和学习-教学模式。</li>
<li>results: 在一项在线用户研究中，与简单的问答聊天机器人和阅读活动相比，Ruffle&amp;Riley Users表现出更高的理解和记忆，并认为提供的支持更有用和对话更 coherent。<details>
<summary>Abstract</summary>
Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interaction. They are known to promote high levels of cognitive engagement and benefit learning outcomes, particularly in reasoning tasks. Nonetheless, the time and cost required to author CTS content is a major obstacle to widespread adoption. In this paper, we introduce a novel type of CTS that leverages the recent advances in large language models (LLMs) in two ways: First, the system induces a tutoring script automatically from a lesson text. Second, the system automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical outer-/inner-loop structure. In an initial between-subject online user study (N = 100) comparing Ruffle&Riley to simpler QA chatbots and reading activity, we found no significant differences in post-test scores. Nonetheless, in the learning experience survey, Ruffle&Riley users expressed higher ratings of understanding and remembering and further perceived the offered support as more helpful and the conversation as coherent. Our study provides insights for a new generation of scalable CTS technologies.
</details>
<details>
<summary>摘要</summary>
对话教育系统（CTS）提供了由自然语言互动驱动的学习体验。它们知名于提高高度的认知投入和学习结果，特别是在推理任务中。然而，创建CTS内容所需的时间和成本是普遍采用的主要障碍。在这篇论文中，我们介绍了一种新型的CTS，它利用最近的大语言模型（LLM）的进步，自动从课程文本中推导导师课程。其次，这个系统通过两个LLM-基于的代理人（Ruffle&Riley），将学生和教授的角色分别扮演为学习-教学格式。系统允许自由的对话，并且遵循ITS-典型的外部/内部回路结构。在我们的初步在网上用户研究（N = 100）中，比较Ruffle&Riley与简单的问答聊天机器人和阅读活动，我们未发现任何显著的差异在 poste-test  scores。然而，Ruffle&Riley 用户对系统的理解和记忆得分高于其他两种方法，并且觉得提供的支持更有帮助，以及对话更加流畅。我们的研究给出了一代新的可扩展的CTS技术的洞察。
</details></li>
</ul>
<hr>
<h2 id="STERLING-Self-Supervised-Terrain-Representation-Learning-from-Unconstrained-Robot-Experience"><a href="#STERLING-Self-Supervised-Terrain-Representation-Learning-from-Unconstrained-Robot-Experience" class="headerlink" title="STERLING: Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience"></a>STERLING: Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15302">http://arxiv.org/abs/2309.15302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haresh Karnan, Elvin Yang, Daniel Farkash, Garrett Warnell, Joydeep Biswas, Peter Stone</li>
<li>for: 本研究旨在帮助自主跟踪器提高地形认知能力，以便在无人值 navigation 中更好地进行自主驾驶。</li>
<li>methods: 本研究提出了一种新的自我超vised Terrain Representation LearnING（STERLING）方法，通过不需要专业人员标注数据，从易于收集的、无约束的机器人经验中学习地形表示。STERLING 使用了一种多modal自我超vised Representation Learning 目标函数，通过非对比性学习来学习有关地形的重要表示。</li>
<li>results: 通过物理机器人实验，研究人员发现 STERLING 的特征在 preference-aligned visual navigation 任务上与完全超vised方法相当，而且与其他现有的方法相比，具有更好的对称性。此外，研究人员在一个3英里长的自然走道上完成了自主旅行，只需要两次人工干预，这表明 STERLING 在实际的 off-road 环境中具有较好的Robustness。<details>
<summary>Abstract</summary>
Terrain awareness, i.e., the ability to identify and distinguish different types of terrain, is a critical ability that robots must have to succeed at autonomous off-road navigation. Current approaches that provide robots with this awareness either rely on labeled data which is expensive to collect, engineered features and cost functions that may not generalize, or expert human demonstrations which may not be available. Towards endowing robots with terrain awareness without these limitations, we introduce Self-supervised TErrain Representation LearnING (STERLING), a novel approach for learning terrain representations that relies solely on easy-to-collect, unconstrained (e.g., non-expert), and unlabelled robot experience, with no additional constraints on data collection. STERLING employs a novel multi-modal self-supervision objective through non-contrastive representation learning to learn relevant terrain representations for terrain-aware navigation. Through physical robot experiments in off-road environments, we evaluate STERLING features on the task of preference-aligned visual navigation and find that STERLING features perform on par with fully supervised approaches and outperform other state-of-the-art methods with respect to preference alignment. Additionally, we perform a large-scale experiment of autonomously hiking a 3-mile long trail which STERLING completes successfully with only two manual interventions, demonstrating its robustness to real-world off-road conditions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TERRAIN 认知，即机器人能够识别和区别不同类型的地形，是自主off-road导航中机器人必备的重要能力。现有的方法提供机器人 terrain 认知都有一些限制，包括需要收集和标注的数据成本高昂、可能不会总结的工程特征和成本函数，以及可能不可获得的专家人类示范。为了让机器人具备 terrain 认知无需这些限制，我们介绍了一种新的方法：Self-supervised TErrain Representation LearnING（STERLING）。STERLING 方法基于非对照 represencing 学习，通过不同模式的自我监督目标来学习地形表示。通过物理机器人在off-road环境中的实验，我们评估了 STERLING 的特征在视觉导航中的性能，发现 STERLING 特征与完全监督方法相当，并且在对齐性方面超过了现有的状态艺术方法。此外，我们进行了一项大规模的自主步行一个3英里长的徒步道，STERLING 成功完成了这项任务，只需两次人类干预，这表明它在实际的off-road条件下具有了可靠性。>>>
</details></li>
</ul>
<hr>
<h2 id="Maximum-Diffusion-Reinforcement-Learning"><a href="#Maximum-Diffusion-Reinforcement-Learning" class="headerlink" title="Maximum Diffusion Reinforcement Learning"></a>Maximum Diffusion Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15293">http://arxiv.org/abs/2309.15293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/murpheylab/maxdiffrl">https://github.com/murpheylab/maxdiffrl</a></li>
<li>paper_authors: Thomas A. Berrueta, Allison Pinosky, Todd D. Murphey</li>
<li>for: 提高机器学习agent的适应能力和可靠性，使其能够在单射部署中不断学习并在不同初始化情况下达到优秀性能。</li>
<li>methods: 基于统计物理学的ergodic过程，提出了最大扩散强化学习方法，可以减少机器学习agent的经验相关性，并且可以在单射部署中提高agent的学习效率。</li>
<li>results: 证明了该方法可以超越已知最大Entropy技术，并在多种各种标准准备列表上实现了较好的性能。<details>
<summary>Abstract</summary>
The assumption that data are independent and identically distributed underpins all machine learning. When data are collected sequentially from agent experiences this assumption does not generally hold, as in reinforcement learning. Here, we derive a method that overcomes these limitations by exploiting the statistical mechanics of ergodic processes, which we term maximum diffusion reinforcement learning. By decorrelating agent experiences, our approach provably enables agents to learn continually in single-shot deployments regardless of how they are initialized. Moreover, we prove our approach generalizes well-known maximum entropy techniques, and show that it robustly exceeds state-of-the-art performance across popular benchmarks. Our results at the nexus of physics, learning, and control pave the way towards more transparent and reliable decision-making in reinforcement learning agents, such as locomoting robots and self-driving cars.
</details>
<details>
<summary>摘要</summary>
<<sys.translation.activate("zh-CN")把数据视为独立并相同分布是机器学习的基本假设。但在经验收集是连续的情况下，这个假设通常不成立，如在奖励学习中。我们 derive一种方法，利用随机过程的统计物理学来超越这些限制，我们称之为最大扩散奖励学习。通过decorrelate代理体验，我们的方法可以让代理人在单射部署中不断学习，无论它们如何初始化。此外，我们证明我们的方法可以准确地扩展知识最大化技术，并在各种流行的标准测试集上表现出色。我们的结果在物理学、学习和控制之间的交叉点上，为机器学习代理人带来更加透明和可靠的决策。例如，行走机器人和自动驾驶车等。>>Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Out-of-Sight-Still-in-Mind-Reasoning-and-Planning-about-Unobserved-Objects-with-Video-Tracking-Enabled-Memory-Models"><a href="#Out-of-Sight-Still-in-Mind-Reasoning-and-Planning-about-Unobserved-Objects-with-Video-Tracking-Enabled-Memory-Models" class="headerlink" title="Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models"></a>Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15278">http://arxiv.org/abs/2309.15278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixuan Huang, Jialin Yuan, Chanho Kim, Pupul Pradhan, Bryan Chen, Li Fuxin, Tucker Hermans</li>
<li>for: 本研究旨在帮助机器人在真实环境中可靠地工作，需要对已经观察过但现在受到遮盲的物体进行记忆。</li>
<li>methods: 我们提出了DOOM和LOOM方法，利用转换器关系动力学来编码物体轨迹历史，并且具有对半视图点云进行物体发现和跟踪的功能。</li>
<li>results: 我们在广泛的模拟和实际实验中发现，我们的方法在不同数量的物体和干扰动作下表现出色，并且超越了隐式记忆基准。<details>
<summary>Abstract</summary>
Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.
</details>
<details>
<summary>摘要</summary>
瑜珐机器人需要保持过去观察到但现在受阻物体的记忆，以在真实环境中正常工作。我们研究对象 ориентирован的记忆编码到多对象抓取和规划框架中。我们提出了DOOM和LOOM，它们利用变换器关系动力学来编码部分视图点云中的历史轨迹，并且具有发现和跟踪物体的引擎。我们的方法可以完成许多具有挑战性的任务，包括处理遮盲物体、新出现的物体和物体重新出现。在我们的广泛的模拟和实际实验中，我们发现我们的方法在不同数量的物体和不同数量的干扰动作下表现良好。此外，我们还证明我们的方法比基eline抑制器表现更好。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Low-rank-Backpropagation-for-Vision-Transformer-Adaptation"><a href="#Efficient-Low-rank-Backpropagation-for-Vision-Transformer-Adaptation" class="headerlink" title="Efficient Low-rank Backpropagation for Vision Transformer Adaptation"></a>Efficient Low-rank Backpropagation for Vision Transformer Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15275">http://arxiv.org/abs/2309.15275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuedong Yang, Hung-Yueh Chiang, Guihong Li, Diana Marculescu, Radu Marculescu</li>
<li>for: 提高大型视transformer（ViT）的效率微调，解决在各种应用中大型模型的高效微调成为了一个主要挑战。</li>
<li>methods: 我们提出了一种新的低级别背沟传播方法（LBP-WHT），该方法将梯度投影到低级别空间中进行背沟传播，从而大幅减少了对ViT的适应需要的计算量。</li>
<li>results: 我们在不同的模型（ViT、混合 convolution-ViT模型）和多个数据集上进行了广泛的实验，证明了我们的LBP-WHT方法的效果。例如，当适应一个EfficientFormer-L1模型在CIFAR100上时，我们的LBP-WHT方法可以提高对比预测的准确率10.4%，同时需要9亿次FLOPs的计算量少。<details>
<summary>Abstract</summary>
The increasing scale of vision transformers (ViT) has made the efficient fine-tuning of these large models for specific needs a significant challenge in various applications. This issue originates from the computationally demanding matrix multiplications required during the backpropagation process through linear layers in ViT. In this paper, we tackle this problem by proposing a new Low-rank BackPropagation via Walsh-Hadamard Transformation (LBP-WHT) method. Intuitively, LBP-WHT projects the gradient into a low-rank space and carries out backpropagation. This approach substantially reduces the computation needed for adapting ViT, as matrix multiplication in the low-rank space is far less resource-intensive. We conduct extensive experiments with different models (ViT, hybrid convolution-ViT model) on multiple datasets to demonstrate the effectiveness of our method. For instance, when adapting an EfficientFormer-L1 model on CIFAR100, our LBP-WHT achieves 10.4% higher accuracy than the state-of-the-art baseline, while requiring 9 MFLOPs less computation. As the first work to accelerate ViT adaptation with low-rank backpropagation, our LBP-WHT method is complementary to many prior efforts and can be combined with them for better performance.
</details>
<details>
<summary>摘要</summary>
随着视transformer（ViT）的扩大规模，为特定需求进行高效调整这些大型模型已成为各种应用中的主要挑战。这个问题的起源在于ViT中linear层中的计算复杂度较高，即在backpropagation过程中的矩阵乘法。在这篇论文中，我们解决这个问题，提出了一种新的Low-rank BackPropagation via Walsh-Hadamard Transformation（LBP-WHT）方法。INTUITIVELY，LBP-WHT方法将梯度投影到低级空间中，并进行backpropagation。这种方法可以减少适应ViT的计算量，因为矩阵乘法在低级空间中是非常资源占用的。我们在不同的模型（ViT、混合卷积-ViT模型）和多个数据集上进行了广泛的实验，以证明我们的方法的有效性。例如，当适应EfficientFormer-L1模型在CIFAR100上的时候，我们的LBP-WHT方法可以与状态之前的基线方法相比，提高10.4%的准确率，同时需要9 MFLOPs fewer computation。作为第一个加速ViT适应的低级后向传播方法，我们的LBP-WHT方法是与许多先前的尝试相结合的，可以提高性能。
</details></li>
</ul>
<hr>
<h2 id="Memory-Efficient-Continual-Learning-Object-Segmentation-for-Long-Video"><a href="#Memory-Efficient-Continual-Learning-Object-Segmentation-for-Long-Video" class="headerlink" title="Memory-Efficient Continual Learning Object Segmentation for Long Video"></a>Memory-Efficient Continual Learning Object Segmentation for Long Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15274">http://arxiv.org/abs/2309.15274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Nazemi, Mohammad Javad Shafiee, Zahra Gharaee, Paul Fieguth</li>
<li>for: 提高在视频中的对象分割精度</li>
<li>methods: 提出了两种新的技术来减少在线对象分割方法中的内存需求，以提高模型的精度和通用性在长视频中</li>
<li>results: 实验结果表明，提出的方法可以提高在线对象分割模型的性能，在长视频 dataset 上提高精度达到10%，同时在短视频 dataset 上保持相对稳定的性能。<details>
<summary>Abstract</summary>
Recent state-of-the-art semi-supervised Video Object Segmentation (VOS) methods have shown significant improvements in target object segmentation accuracy when information from preceding frames is used in undertaking segmentation on the current frame. In particular, such memory-based approaches can help a model to more effectively handle appearance changes (representation drift) or occlusions. Ideally, for maximum performance, online VOS methods would need all or most of the preceding frames (or their extracted information) to be stored in memory and be used for online learning in consecutive frames. Such a solution is not feasible for long videos, as the required memory size would grow without bound. On the other hand, these methods can fail when memory is limited and a target object experiences repeated representation drifts throughout a video.   We propose two novel techniques to reduce the memory requirement of online VOS methods while improving modeling accuracy and generalization on long videos. Motivated by the success of continual learning techniques in preserving previously-learned knowledge, here we propose Gated-Regularizer Continual Learning (GRCL), which improves the performance of any online VOS subject to limited memory, and a Reconstruction-based Memory Selection Continual Learning (RMSCL) which empowers online VOS methods to efficiently benefit from stored information in memory.   Experimental results show that the proposed methods improve the performance of online VOS models up to 10 %, and boosts their robustness on long-video datasets while maintaining comparable performance on short-video datasets DAVIS16 and DAVIS17.
</details>
<details>
<summary>摘要</summary>
现代 semi-supervised Video Object Segmentation（VOS）方法在使用前一帧信息进行当前帧分 segmentation 时已经显示了显著改善 target 对象分 segmentation 精度。尤其是这些记忆型方法可以帮助模型更好地处理出现变化（表达漂移）或遮挡。理想情况下，为了 дости到最高性能，在线 VOS 方法需要所有或大多数的前一帧（或其提取的信息）被存储在内存中，并在连续帧中进行在线学习。然而，这种解决方案并不可行于长视频，因为所需的内存大小会无限增长。另一方面，这些方法可能会失败当内存有限制，target 对象在视频中经历重复的表达漂移。我们提出了两种新的技术来降低在线 VOS 方法的内存需求，同时提高模型的准确性和泛化能力在长视频上。我们的方法包括：1. 闭包 regularizer continual learning（GRCL），可以提高在线 VOS 模型的性能，并且可以在有限内存下进行学习。2. 重建基于内存选择 continual learning（RMSCL），可以让在线 VOS 方法有效地利用存储在内存中的信息，以提高模型的性能和泛化能力。实验结果表明，我们的方法可以提高在线 VOS 模型的性能，并且可以增强其在长视频上的稳定性，而不会影响短视频上的性能。
</details></li>
</ul>
<hr>
<h2 id="STARC-A-General-Framework-For-Quantifying-Differences-Between-Reward-Functions"><a href="#STARC-A-General-Framework-For-Quantifying-Differences-Between-Reward-Functions" class="headerlink" title="STARC: A General Framework For Quantifying Differences Between Reward Functions"></a>STARC: A General Framework For Quantifying Differences Between Reward Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15257">http://arxiv.org/abs/2309.15257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joar Skalse, Lucy Farnik, Sumeet Ramesh Motwani, Erik Jenner, Adam Gleave, Alessandro Abate</li>
<li>For: The paper aims to provide a solution to the problem of deriving theoretical guarantees for reward learning algorithms, which is difficult due to the lack of good methods for quantifying the difference between reward functions.* Methods: The paper proposes a class of pseudometrics called STARC (STAndardised Reward Comparison) metrics, which can be used to quantify the difference between reward functions and provide both upper and lower bounds on worst-case regret.* Results: The paper shows that STARC metrics are tight and bilipschitz equivalent, and identifies issues with reward metrics proposed by earlier works. The paper also demonstrates the empirical efficacy of STARC metrics through practical evaluation.<details>
<summary>Abstract</summary>
In order to solve a task using reinforcement learning, it is necessary to first formalise the goal of that task as a reward function. However, for many real-world tasks, it is very difficult to manually specify a reward function that never incentivises undesirable behaviour. As a result, it is increasingly popular to use reward learning algorithms, which attempt to learn a reward function from data. However, the theoretical foundations of reward learning are not yet well-developed. In particular, it is typically not known when a given reward learning algorithm with high probability will learn a reward function that is safe to optimise. This means that reward learning algorithms generally must be evaluated empirically, which is expensive, and that their failure modes are difficult to predict in advance. One of the roadblocks to deriving better theoretical guarantees is the lack of good methods for quantifying the difference between reward functions. In this paper we provide a solution to this problem, in the form of a class of pseudometrics on the space of all reward functions that we call STARC (STAndardised Reward Comparison) metrics. We show that STARC metrics induce both an upper and a lower bound on worst-case regret, which implies that our metrics are tight, and that any metric with the same properties must be bilipschitz equivalent to ours. Moreover, we also identify a number of issues with reward metrics proposed by earlier works. Finally, we evaluate our metrics empirically, to demonstrate their practical efficacy. STARC metrics can be used to make both theoretical and empirical analysis of reward learning algorithms both easier and more principled.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:为解决一个任务使用奖励学习，首先需要正式化该任务的目标为奖励函数。然而，在许多实际任务中，很难手动指定一个不奖励不良行为的奖励函数。因此，奖励学习算法在很多情况下变得越来越受欢迎。然而，奖励学习的理论基础还不够发展。特别是，通常不知道一个给定的奖励学习算法是否会在高probability上学习一个安全优化的奖励函数。这意味着奖励学习算法通常需要通过实际评估，这会很昂贵，并且其失败模式难以预测。一个障碍得到更好的理论保证的原因是量化奖励函数之间的差别的缺乏好的方法。在这篇论文中，我们提供一个解决方案，即 STARC（STAndardised Reward Comparison）度量。我们证明STARC度量induces both upper and lower bound on worst-case regret,这意味着我们的度量是紧张的，任何与我们度量相同的度量都必须是bilipSchitz相同的。此外，我们还标识了早期的奖励度量的一些问题。最后，我们employmSTARC度量进行实证评估，以证明其实践效果。STARC度量可以使得奖励学习算法的理论和实证分析变得更加容易和更加原则性。
</details></li>
</ul>
<hr>
<h2 id="VPA-Fully-Test-Time-Visual-Prompt-Adaptation"><a href="#VPA-Fully-Test-Time-Visual-Prompt-Adaptation" class="headerlink" title="VPA: Fully Test-Time Visual Prompt Adaptation"></a>VPA: Fully Test-Time Visual Prompt Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15251">http://arxiv.org/abs/2309.15251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiachen Sun, Mark Ibrahim, Melissa Hall, Ivan Evtimov, Z. Morley Mao, Cristian Canton Ferrer, Caner Hazirbas</li>
<li>for: 这个论文的目的是提出一种可以在测试时进行适应的视觉提示框架，以提高模型的对异常输入、损害输入和领域转换的能力。</li>
<li>methods: 该论文使用了一种名为Visual Prompt Adaptation（VPA）的方法，该方法通过增加一些可学习的符号，使得模型在测试时可以进行适应。</li>
<li>results: 实验结果显示，VPA可以提高对异常输入的泛化能力 by 3.3%，超过了之前的测试方法。此外，VPA还可以提高损害鲁棒性 by 6.5%，并且可以提高领域转换性能 by 5.2%。<details>
<summary>Abstract</summary>
Textual prompt tuning has demonstrated significant performance improvements in adapting natural language processing models to a variety of downstream tasks by treating hand-engineered prompts as trainable parameters. Inspired by the success of textual prompting, several studies have investigated the efficacy of visual prompt tuning. In this work, we present Visual Prompt Adaptation (VPA), the first framework that generalizes visual prompting with test-time adaptation. VPA introduces a small number of learnable tokens, enabling fully test-time and storage-efficient adaptation without necessitating source-domain information. We examine our VPA design under diverse adaptation settings, encompassing single-image, batched-image, and pseudo-label adaptation. We evaluate VPA on multiple tasks, including out-of-distribution (OOD) generalization, corruption robustness, and domain adaptation. Experimental results reveal that VPA effectively enhances OOD generalization by 3.3% across various models, surpassing previous test-time approaches. Furthermore, we show that VPA improves corruption robustness by 6.5% compared to strong baselines. Finally, we demonstrate that VPA also boosts domain adaptation performance by relatively 5.2%. Our VPA also exhibits marked effectiveness in improving the robustness of zero-shot recognition for vision-language models.
</details>
<details>
<summary>摘要</summary>
文本提示调整已经显示出对多种下游任务的模型适应性提高了显著性。 draw inspiration from textual prompting success， several studies have explored visual prompting efficacy. In this work, we present Visual Prompt Adaptation (VPA), the first framework that generalizes visual prompting with test-time adaptation. VPA introduces a small number of learnable tokens, enabling fully test-time and storage-efficient adaptation without requiring source-domain information. We examine our VPA design under diverse adaptation settings, including single-image, batched-image, and pseudo-label adaptation. We evaluate VPA on multiple tasks, including out-of-distribution (OOD) generalization, corruption robustness, and domain adaptation. Experimental results show that VPA effectively enhances OOD generalization by 3.3% across various models, surpassing previous test-time approaches. Furthermore, we show that VPA improves corruption robustness by 6.5% compared to strong baselines. Finally, we demonstrate that VPA also boosts domain adaptation performance by relatively 5.2%. Our VPA also exhibits marked effectiveness in improving the robustness of zero-shot recognition for vision-language models.
</details></li>
</ul>
<hr>
<h2 id="SeMAnD-Self-Supervised-Anomaly-Detection-in-Multimodal-Geospatial-Datasets"><a href="#SeMAnD-Self-Supervised-Anomaly-Detection-in-Multimodal-Geospatial-Datasets" class="headerlink" title="SeMAnD: Self-Supervised Anomaly Detection in Multimodal Geospatial Datasets"></a>SeMAnD: Self-Supervised Anomaly Detection in Multimodal Geospatial Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15245">http://arxiv.org/abs/2309.15245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daria Reshetova, Swetava Ganguli, C. V. Krishnakumar Iyer, Vipul Pandey<br>for:* 这个论文旨在检测多modal geospatial数据中的 геометрические异常（如道路、建筑、地形等）。methods:* 该论文提出了一种无监督异常检测技术，即 SeMAnD，使用 RandPolyAugment 数据增强策略和自我超vised 训练目标来学习多modal数据的表示，并具有异常检测能力。results:* 该论文的实验表明，SeMAnD 能够有效地检测实际世界中的异常，并与域外异常检测策略相比，提高了4.8-19.7%的异常分类 AUC。此外，模型性能随输入模式数量和数据增强策略的多样性和强度增长。<details>
<summary>Abstract</summary>
We propose a Self-supervised Anomaly Detection technique, called SeMAnD, to detect geometric anomalies in Multimodal geospatial datasets. Geospatial data comprises of acquired and derived heterogeneous data modalities that we transform to semantically meaningful, image-like tensors to address the challenges of representation, alignment, and fusion of multimodal data. SeMAnD is comprised of (i) a simple data augmentation strategy, called RandPolyAugment, capable of generating diverse augmentations of vector geometries, and (ii) a self-supervised training objective with three components that incentivize learning representations of multimodal data that are discriminative to local changes in one modality which are not corroborated by the other modalities. Detecting local defects is crucial for geospatial anomaly detection where even small anomalies (e.g., shifted, incorrectly connected, malformed, or missing polygonal vector geometries like roads, buildings, landcover, etc.) are detrimental to the experience and safety of users of geospatial applications like mapping, routing, search, and recommendation systems. Our empirical study on test sets of different types of real-world geometric geospatial anomalies across 3 diverse geographical regions demonstrates that SeMAnD is able to detect real-world defects and outperforms domain-agnostic anomaly detection strategies by 4.8-19.7% as measured using anomaly classification AUC. We also show that model performance increases (i) up to 20.4% as the number of input modalities increase and (ii) up to 22.9% as the diversity and strength of training data augmentations increase.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自动异常检测技术，称为SeMAnD，用于检测多Modal geospatial数据中的几何异常。 geospatial数据包括获取和 derivated 多种数据类型，我们将其转换为semantically meaningful的 image-like 张量，以解决多Modal数据的表示、对接和融合问题。 SeMAnD 包括（i）一种简单的数据增强策略，称为 RandPolyAugment，可以生成多种几何异常的扩展，以及（ii）一种自动异常检测目标函数，包括三个组件，这些组件鼓励学习多Modal数据的表示，对一个模式中的局部变化不被其他模式支持。 检测局部异常是关键的，因为even small 异常（例如，偏移、错过连接、腐坏、缺失多边形vector geometry like roads, buildings, landcover, etc.）对 geospatial应用程序（如地图、路径规划、搜索、推荐系统）的用户体验和安全产生重要影响。我们的实验表明，SeMAnD 可以检测实际的异常并在预测异常分类 AUC 方面高于域无关异常检测策略 by 4.8-19.7%。我们还发现，模型性能随输入模式数量和数据增强策略的多样性和强度而增长，最高可以达到 20.4% 和 22.9%。
</details></li>
</ul>
<hr>
<h2 id="PlotMap-Automated-Layout-Design-for-Building-Game-Worlds"><a href="#PlotMap-Automated-Layout-Design-for-Building-Game-Worlds" class="headerlink" title="PlotMap: Automated Layout Design for Building Game Worlds"></a>PlotMap: Automated Layout Design for Building Game Worlds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15242">http://arxiv.org/abs/2309.15242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Wang, Jieliang Luo, Adam Gaier, Evan Atherton, Hilmar Koch<br>for:The paper aims to address the challenge of designing game maps that support a desired narrative, by introducing an extra layer of plot facility layout design that is independent of the underlying map generation method.methods:The paper proposes using Reinforcement Learning (RL) to automatically assign concrete locations on a game map to abstract locations mentioned in a given story (plot facilities), following spatial constraints derived from the story.results:The paper presents a system that considers input from multiple modalities, including map images, facility locations, and story constraints expressed in natural language, to train and evaluate RL models for plot facility layout design. The system is evaluated through a group of comprehensive experiments and ablation studies, providing insights for RL-based plot facility layout design.<details>
<summary>Abstract</summary>
World-building, the process of developing both the narrative and physical world of a game, plays a vital role in the game's experience. Critically acclaimed independent and AAA video games are praised for strong world building, with game maps that masterfully intertwine with and elevate the narrative, captivating players and leaving a lasting impression. However, designing game maps that support a desired narrative is challenging, as it requires satisfying complex constraints from various considerations. Most existing map generation methods focus on considerations about gameplay mechanics or map topography, while the need to support the story is typically neglected. As a result, extensive manual adjustment is still required to design a game world that facilitates particular stories. In this work, we approach this problem by introducing an extra layer of plot facility layout design that is independent of the underlying map generation method in a world-building pipeline. Concretely, we present a system that leverages Reinforcement Learning (RL) to automatically assign concrete locations on a game map to abstract locations mentioned in a given story (plot facilities), following spatial constraints derived from the story. A decision-making agent moves the plot facilities around, considering their relationship to the map and each other, to locations on the map that best satisfy the constraints of the story. Our system considers input from multiple modalities: map images as pixels, facility locations as real values, and story constraints expressed in natural language. We develop a method of generating datasets of facility layout tasks, create an RL environment to train and evaluate RL models, and further analyze the behaviors of the agents through a group of comprehensive experiments and ablation studies, aiming to provide insights for RL-based plot facility layout design.
</details>
<details>
<summary>摘要</summary>
世界建设，游戏的叙述和物理世界的开发过程，对游戏的体验非常重要。独立游戏和AAA游戏都得到了广泛的赞誉，即使游戏地图与叙述相互呼应， captivating 玩家并留下深刻的印象。然而，设计游戏地图以支持特定的叙述是具有复杂的约束的问题，而现有的地图生成方法通常会忽略这些约束。因此，手动调整仍然是必要的，以设计游戏世界，以便支持特定的叙述。在这种情况下，我们采用了一种独特的叙述设计方法，通过强化学习（RL）自动将叙述中提到的抽象位置（叙述设施）转换为游戏地图上的具体位置。一个决策者会将叙述设施移动到地图上，考虑它们之间的关系和地图上的约束，以满足叙述的约束。我们的系统将来自多种模式的输入进行处理：地图图像作为像素、设施位置作为真实值，以及叙述约束表示在自然语言中。我们开发了一种生成叙述设施任务的方法，创建了RL环境来训练和评估RL模型，并通过一系列完整的实验和剥离研究，以提供RL-基于叙述设施布局的深入理解。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-Mechanical-Engineering-Examining-performance-on-the-FE-Mechanical-Engineering-and-Undergraduate-Exams"><a href="#ChatGPT-Mechanical-Engineering-Examining-performance-on-the-FE-Mechanical-Engineering-and-Undergraduate-Exams" class="headerlink" title="ChatGPT &amp; Mechanical Engineering: Examining performance on the FE Mechanical Engineering and Undergraduate Exams"></a>ChatGPT &amp; Mechanical Engineering: Examining performance on the FE Mechanical Engineering and Undergraduate Exams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15866">http://arxiv.org/abs/2309.15866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Frenkel, Hebah Emara</li>
<li>For: This paper is written for exploring the capabilities of ChatGPT in the discipline of mechanical engineering, specifically in the classroom and professional settings.* Methods: The paper uses two ChatGPT models, one free and one paid subscription, to examine their performance on junior and senior level mechanical engineering exams and practice questions for the Fundamentals of Engineering Exam (FE) in Mechanical Engineering.* Results: The paid subscription model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76% correct vs 51% correct, but the limitation of text only input on both models makes neither likely to pass the FE exam. The results confirm findings in the literature with regards to types of errors and pitfalls made by ChatGPT.<details>
<summary>Abstract</summary>
The launch of ChatGPT at the end of 2022 generated large interest into possible applications of artificial intelligence in STEM education and among STEM professions. As a result many questions surrounding the capabilities of generative AI tools inside and outside of the classroom have been raised and are starting to be explored. This study examines the capabilities of ChatGPT within the discipline of mechanical engineering. It aims to examine use cases and pitfalls of such a technology in the classroom and professional settings. ChatGPT was presented with a set of questions from junior and senior level mechanical engineering exams provided at a large private university, as well as a set of practice questions for the Fundamentals of Engineering Exam (FE) in Mechanical Engineering. The responses of two ChatGPT models, one free to use and one paid subscription, were analyzed. The paper found that the subscription model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76% correct vs 51% correct, but the limitation of text only input on both models makes neither likely to pass the FE exam. The results confirm findings in the literature with regards to types of errors and pitfalls made by ChatGPT. It was found that due to its inconsistency and a tendency to confidently produce incorrect answers the tool is best suited for users with expert knowledge.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese于2022年底发布ChatGPT引发了大量关于人工智能在科学技术教育和相关领oprofessions的兴趣。因此，许多关于生成AI工具在课堂和职业场景中的能力和局限性的问题被提出并开始被探讨。本研究探讨了ChatGPT在机械工程领域的能力。它的目的是检查ChatGPT在课堂和职业场景中的应用案例和陷阱。为了完成这项研究，ChatGPT被给予了一组 junior和senior机械工程考试中的问题，以及一组机械工程基础知识考试（FE）的练习题。两个ChatGPT模型（一个免费版本GPT-3.5和一个付费版本GPT-4）的回答被分析。研究发现，付费版本GPT-4在正确率方面大幅过之GPT-3.5（76%对51%），但两个模型均限于文本输入，使得 neither是可以通过FE考试。研究结果证明了文献中关于ChatGPT的错误和陷阱的发现。它发现了ChatGPT的不一致和自信地生成错误的倾向，因此建议用户应具备专家知识使用该工具。本研究的结果表明，ChatGPT在机械工程领域的应用需要进一步的研究和开发，以便更好地利用其能力。此外，研究还发现了一些可能的应用场景，例如用于提供学生们学习资源、帮助教师们设计课程和评估学生们的知识水平等。
</details></li>
</ul>
<hr>
<h2 id="Learning-Using-Generated-Privileged-Information-by-Text-to-Image-Diffusion-Models"><a href="#Learning-Using-Generated-Privileged-Information-by-Text-to-Image-Diffusion-Models" class="headerlink" title="Learning Using Generated Privileged Information by Text-to-Image Diffusion Models"></a>Learning Using Generated Privileged Information by Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15238">http://arxiv.org/abs/2309.15238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael-Edy Menadil, Mariana-Iuliana Georgescu, Radu Tudor Ionescu</li>
<li>for: 提高文本分类表现，不需要额外成本在推理阶段</li>
<li>methods: 使用文本到图像扩散模型生成人工特权信息，并使用多模态教师模型（基于state-of-the-art transformer-based architectures）来储存知识。最后，通过多模态教师模型的知识整合，提高文本分类表现。</li>
<li>results: 在四个文本分类数据集上，LUGPI方法实现了明显的性能提升，示出其在文本分类中的潜力。<details>
<summary>Abstract</summary>
Learning Using Privileged Information is a particular type of knowledge distillation where the teacher model benefits from an additional data representation during training, called privileged information, improving the student model, which does not see the extra representation. However, privileged information is rarely available in practice. To this end, we propose a text classification framework that harnesses text-to-image diffusion models to generate artificial privileged information. The generated images and the original text samples are further used to train multimodal teacher models based on state-of-the-art transformer-based architectures. Finally, the knowledge from multimodal teachers is distilled into a text-based (unimodal) student. Hence, by employing a generative model to produce synthetic data as privileged information, we guide the training of the student model. Our framework, called Learning Using Generated Privileged Information (LUGPI), yields noticeable performance gains on four text classification data sets, demonstrating its potential in text classification without any additional cost during inference.
</details>
<details>
<summary>摘要</summary>
学习使用特权信息是一种特定的知识填充，其中教师模型在训练时得到额外数据表示，称为特权信息，以改进学生模型，该模型不能看到额外表示。然而，特权信息在实践中很少可用。为此，我们提议一种文本分类框架，利用文本到图像扩散模型生成人工特权信息。生成的图像和原始文本样本被用来训练基于state-of-the-art transformer-based architecture的多Modal教师模型。最后，多Modal教师模型中的知识被透传到文本基本（单Modal）学生模型中。因此，通过使用生成模型生成Synthetic数据作为特权信息，我们可以导引学生模型的训练。我们的框架，称为学习使用生成的特权信息（LUGPI），在四个文本分类数据集上显示了明显的性能提升，这表明它在文本分类中具有潜在的应用前提。
</details></li>
</ul>
<hr>
<h2 id="User-Experience-Design-Professionals’-Perceptions-of-Generative-Artificial-Intelligence"><a href="#User-Experience-Design-Professionals’-Perceptions-of-Generative-Artificial-Intelligence" class="headerlink" title="User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence"></a>User Experience Design Professionals’ Perceptions of Generative Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15237">http://arxiv.org/abs/2309.15237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Li, Hancheng Cao, Laura Lin, Youyang Hou, Ruihao Zhu, Abdallah El Ali</li>
<li>for: 这个论文探讨了生成人工智能（GenAI）如何影响用户体验设计（UXD）实践，以及是否有不必要的担忧。</li>
<li>methods: 作者通过对20名UX设计师进行采访，了解他们的实践和态度，以及他们对GenAI的担忧和期望。</li>
<li>results: 研究发现经验丰富的设计师对GenAI的辅助作用表示自信，但新手设计师可能会受到技能减退、工作替换和创造力疲劳的影响。<details>
<summary>Abstract</summary>
Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI's role as assistive. They emphasized the unique human factors of "enjoyment" and "agency", where humans remain the arbiters of "AI alignment". However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.
</details>
<details>
<summary>摘要</summary>
amongst creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI's role as assistive. They emphasized the unique human factors of "enjoyment" and "agency", where humans remain the arbiters of "AI alignment". However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens of responsible and participatory AI, we contribute a deeper understanding of GenAI fears and opportunities for UXD.Here's the word-for-word translation in Simplified Chinese: amongst 创新专业人士, 生成人工智能（GenAI）已引起了能力和不确定后果的兴趣。GenAI如何影响用户体验设计（UXD）实践，而担忧是否合理？我们采访了20名UX设计师，他们在不同的公司（从创新公司到大型企业）中有各种经验。我们询问他们描述他们的做法，并抽样他们的态度、担忧和期望。我们发现经验丰富的设计师对他们的原创性、创造力和Empathy技能充满自信，并认为GenAI的角色是助手。他们强调了人类的特有因素，如“娱乐”和“权力”，人类仍然是AI的“调节者”。然而，技能衰退、工作替换和创造力疲劳可能会对初级设计师产生负面影响。我们讨论了人类-GenAI合作的影响，包括版权和所有权、人类创造力和权力，以及AI文化和访问权。通过负责和参与式AI的镜头，我们为UXD提供了更深刻的GenAI担忧和机遇。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Watermarking-for-Adversarial-Speech-Synthesis"><a href="#Collaborative-Watermarking-for-Adversarial-Speech-Synthesis" class="headerlink" title="Collaborative Watermarking for Adversarial Speech Synthesis"></a>Collaborative Watermarking for Adversarial Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15224">http://arxiv.org/abs/2309.15224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lauri Juvela, Xin Wang</li>
<li>for: 本研究旨在提出一种活动 watermarking 方法，以帮助检测生成的语音，同时保持人工 listener 的 transparent。</li>
<li>methods: 本研究使用了一种协作训练方法，将 HiFi-GAN 神经 vocoder 与 ASVspoof 2021 基准防御模型相结合，以提高检测性能。</li>
<li>results: 研究表明，协作训练可以增加对噪音和时间压缩的Robustness，而且 listening 测试表明，协作训练对语音质量没有负面影响。<details>
<summary>Abstract</summary>
Advances in neural speech synthesis have brought us technology that is not only close to human naturalness, but is also capable of instant voice cloning with little data, and is highly accessible with pre-trained models available. Naturally, the potential flood of generated content raises the need for synthetic speech detection and watermarking. Recently, considerable research effort in synthetic speech detection has been related to the Automatic Speaker Verification and Spoofing Countermeasure Challenge (ASVspoof), which focuses on passive countermeasures. This paper takes a complementary view to generated speech detection: a synthesis system should make an active effort to watermark the generated speech in a way that aids detection by another machine, but remains transparent to a human listener. We propose a collaborative training scheme for synthetic speech watermarking and show that a HiFi-GAN neural vocoder collaborating with the ASVspoof 2021 baseline countermeasure models consistently improves detection performance over conventional classifier training. Furthermore, we demonstrate how collaborative training can be paired with augmentation strategies for added robustness against noise and time-stretching. Finally, listening tests demonstrate that collaborative training has little adverse effect on perceptual quality of vocoded speech.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation) neural speech synthesis技术的进步使得我们可以快速创建自然语音，并且可以使用预训练模型进行访问。然而，这些生成的内容的潮流使得人工语音检测和水印成为必要。在这些研究中，我们采用了一种与生成语音检测相关的方法：一个合成系统应该为另一个机器提供一种可以帮助检测的 watermark，但是对人类听众来说是透明的。我们提议一种合作训练方法，使得HiFi-GAN神经 vocoder与ASVspoof 2021基准防范模型之间进行了可 collaborative 的训练。我们表明，这种方法可以提高检测性能，并且可以结合增强策略来抵御噪音和时间延迟。最后，我们通过听力测试表明，这种合作训练对语音质量的影响是微乎其微的。
</details></li>
</ul>
<hr>
<h2 id="Low-rank-Adaptation-of-Large-Language-Model-Rescoring-for-Parameter-Efficient-Speech-Recognition"><a href="#Low-rank-Adaptation-of-Large-Language-Model-Rescoring-for-Parameter-Efficient-Speech-Recognition" class="headerlink" title="Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition"></a>Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15223">http://arxiv.org/abs/2309.15223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Yu, Chao-Han Huck Yang, Jari Kolehmainen, Prashanth G. Shivakumar, Yile Gu, Sungho Ryu, Roger Ren, Qi Luo, Aditya Gourav, I-Fan Chen, Yi-Chieh Liu, Tuan Dinh, Ankur Gandhe, Denis Filimonov, Shalini Ghosh, Andreas Stolcke, Ariya Rastow, Ivan Bulyko</li>
<li>for: 这个论文是为了提出一种基于低级别适应（LoRA）的神经语言模型，用于提高语音识别输出重新分配。</li>
<li>methods: 这个论文使用了一种基于低级别适应的训练方法，通过低级别适应来训练一个重新分配BERT模型，并通过一种探索性的训练目标和相关性损失来优化这些插入的矩阵。</li>
<li>results: 这个论文的实验结果表明，使用LoRB架构可以在LibriSpeech和内部数据集上实现减少训练时间，减少5.4倍到3.6倍不等。<details>
<summary>Abstract</summary>
We propose a neural language modeling system based on low-rank adaptation (LoRA) for speech recognition output rescoring. Although pretrained language models (LMs) like BERT have shown superior performance in second-pass rescoring, the high computational cost of scaling up the pretraining stage and adapting the pretrained models to specific domains limit their practical use in rescoring. Here we present a method based on low-rank decomposition to train a rescoring BERT model and adapt it to new domains using only a fraction (0.08%) of the pretrained parameters. These inserted matrices are optimized through a discriminative training objective along with a correlation-based regularization loss. The proposed low-rank adaptation Rescore-BERT (LoRB) architecture is evaluated on LibriSpeech and internal datasets with decreased training times by factors between 5.4 and 3.6.
</details>
<details>
<summary>摘要</summary>
我们提出一种基于低级别适应（LoRA）的神经语言模型系统，用于语音识别输出重新分配。尽管先前训练的语言模型（LM）如BERT已经在第二次重新分配中显示出优秀表现，但是扩大预训练阶段和适应特定领域的预训练模型的计算成本限制了它们的实际使用。我们提出一种基于低级别分解的方法，通过只使用0.08%的预训练参数来训练重新分配BERT模型并适应新领域。这些插入矩阵通过一种推理目标和相关性基于的规则损失进行优化。我们提出的低级别适应重新分配BERT（LoRB）架构在LibriSpeech和内部数据集上进行评估，与训练时间相应减少了5.4到3.6倍。
</details></li>
</ul>
<hr>
<h2 id="Conservative-World-Models"><a href="#Conservative-World-Models" class="headerlink" title="Conservative World Models"></a>Conservative World Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15178">http://arxiv.org/abs/2309.15178</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/enjeeneer/conservative-world-models">https://github.com/enjeeneer/conservative-world-models</a></li>
<li>paper_authors: Scott Jeen, Tom Bewley, Jonathan M. Cullen</li>
<li>for: 描述了一种零shot学习环境中的agent，通过在线预训练phase后在任务环境中表现出任务性能的85%。</li>
<li>methods: 使用了forward-backward表示法，并通过加入保守性来减少在小数据集上的性能下降。</li>
<li>results: 在多个数据集、领域和任务上评估了family of方法，其中conservative FB算法在总体来说达到了150%的vanilla FB性能。同时，保守的FB算法也超越了具有奖励标签的任务特定基线，即使没有访问奖励标签。<details>
<summary>Abstract</summary>
Zero-shot reinforcement learning (RL) promises to provide agents that can perform any task in an environment after an offline pre-training phase. Forward-backward (FB) representations represent remarkable progress towards this ideal, achieving 85% of the performance of task-specific agents in this setting. However, such performance is contingent on access to large and diverse datasets for pre-training, which cannot be expected for most real problems. Here, we explore how FB performance degrades when trained on small datasets that lack diversity, and mitigate it with conservatism, a well-established feature of performant offline RL algorithms. We evaluate our family of methods across various datasets, domains and tasks, reaching 150% of vanilla FB performance in aggregate. Somewhat surprisingly, conservative FB algorithms also outperform the task-specific baseline, despite lacking access to reward labels and being required to maintain policies for all tasks. Conservative FB algorithms perform no worse than FB on full datasets, and so present little downside over their predecessor. Our code is available open-source via https://enjeeneer.io/projects/conservative-world-models/.
</details>
<details>
<summary>摘要</summary>
zero-shot reinforcement learning（RL）承诺提供能够在环境中完成任何任务的代理人，具体来说是通过在线上进行准备 phase 来实现。forward-backward（FB）表示达了非常 significiant progress towards this ideal，达到了85%的任务特定代理人的性能。然而，这种性能受到了大量和多样化数据集的预training的限制，这些数据集在实际问题中不可能被期望。在这里，我们研究了FB表示性能如何随着小数据集的不同而下降，并采用保守性作为缓解方法，这是一种在offline RL算法中广泛存在的特征。我们在不同的数据集、领域和任务上评估了我们的家族方法，共 дости得150%的vanilla FB性能。尚未料算起来，保守FB算法还能超过任务特定基线，即使没有访问奖励标签和维护所有任务的策略。保守FB算法与FB在全数据集上表现相同，因此它们没有下降的缺点。我们的代码可以在https://enjeeneer.io/projects/conservative-world-models/上获取。
</details></li>
</ul>
<hr>
<h2 id="Revealing-the-Power-of-Spatial-Temporal-Masked-Autoencoders-in-Multivariate-Time-Series-Forecasting"><a href="#Revealing-the-Power-of-Spatial-Temporal-Masked-Autoencoders-in-Multivariate-Time-Series-Forecasting" class="headerlink" title="Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting"></a>Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15169">http://arxiv.org/abs/2309.15169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiarui Sun, Yujie Fan, Chin-Chia Michael Yeh, Wei Zhang, Girish Chowdhary</li>
<li>for: 这个研究旨在提高多重时间序列（MTS）预测的性能，以及将它应用于实际应用中。</li>
<li>methods: 这篇研究提出了一个名为“空间时间对应者”（STMAE）的预测框架，利用对应器来强化已有的空间时间基本模型。</li>
<li>results: 实验结果显示，通过与 existed 的空间时间模型混合 STMAE，可以大幅提高 MTS 预测的能力。<details>
<summary>Abstract</summary>
Multivariate time series (MTS) forecasting involves predicting future time series data based on historical observations. Existing research primarily emphasizes the development of complex spatial-temporal models that capture spatial dependencies and temporal correlations among time series variables explicitly. However, recent advances have been impeded by challenges relating to data scarcity and model robustness. To address these issues, we propose Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that leverages masked autoencoders to enhance the performance of spatial-temporal baseline models. STMAE consists of two learning stages. In the pretraining stage, an encoder-decoder architecture is employed. The encoder processes the partially visible MTS data produced by a novel dual-masking strategy, including biased random walk-based spatial masking and patch-based temporal masking. Subsequently, the decoders aim to reconstruct the masked counterparts from both spatial and temporal perspectives. The pretraining stage establishes a challenging pretext task, compelling the encoder to learn robust spatial-temporal patterns. In the fine-tuning stage, the pretrained encoder is retained, and the original decoder from existing spatial-temporal models is appended for forecasting. Extensive experiments are conducted on multiple MTS benchmarks. The promising results demonstrate that integrating STMAE into various spatial-temporal models can largely enhance their MTS forecasting capability.
</details>
<details>
<summary>摘要</summary>
多变量时间序列（MTS）预测 involve forecasting future time series data based on historical observations. Existing research primarily focuses on developing complex spatial-temporal models that explicitly capture spatial dependencies and temporal correlations among time series variables. However, recent advances have been hindered by challenges related to data scarcity and model robustness. To address these issues, we propose Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that leverages masked autoencoders to enhance the performance of spatial-temporal baseline models.STMAE consists of two learning stages. In the pretraining stage, an encoder-decoder architecture is employed. The encoder processes the partially visible MTS data produced by a novel dual-masking strategy, including biased random walk-based spatial masking and patch-based temporal masking. Subsequently, the decoders aim to reconstruct the masked counterparts from both spatial and temporal perspectives. The pretraining stage establishes a challenging pretext task, compelling the encoder to learn robust spatial-temporal patterns. In the fine-tuning stage, the pretrained encoder is retained, and the original decoder from existing spatial-temporal models is appended for forecasting.Extensive experiments are conducted on multiple MTS benchmarks. The promising results demonstrate that integrating STMAE into various spatial-temporal models can significantly enhance their MTS forecasting capability.
</details></li>
</ul>
<hr>
<h2 id="3D-Reconstruction-with-Generalizable-Neural-Fields-using-Scene-Priors"><a href="#3D-Reconstruction-with-Generalizable-Neural-Fields-using-Scene-Priors" class="headerlink" title="3D Reconstruction with Generalizable Neural Fields using Scene Priors"></a>3D Reconstruction with Generalizable Neural Fields using Scene Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15164">http://arxiv.org/abs/2309.15164</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/USTCPCS/CVPR2018_attention">https://github.com/USTCPCS/CVPR2018_attention</a></li>
<li>paper_authors: Yang Fu, Shalini De Mello, Xueting Li, Amey Kulkarni, Jan Kautz, Xiaolong Wang, Sifei Liu</li>
<li>For: The paper is written for high-fidelity 3D scene reconstruction using neural fields, with a focus on scalability and flexibility.* Methods: The paper introduces training generalizable Neural Fields incorporating scene Priors (NFPs), which map single-view RGB-D images into signed distance and radiance values. The NFP network does not require a fusion module, allowing for faster adaptation to new scenes with fewer views.* Results: The paper demonstrates state-of-the-art (SOTA) scene reconstruction performance and efficiency, as well as support for single-image novel-view synthesis, which is underexplored in neural fields.<details>
<summary>Abstract</summary>
High-fidelity 3D scene reconstruction has been substantially advanced by recent progress in neural fields. However, most existing methods train a separate network from scratch for each individual scene. This is not scalable, inefficient, and unable to yield good results given limited views. While learning-based multi-view stereo methods alleviate this issue to some extent, their multi-view setting makes it less flexible to scale up and to broad applications. Instead, we introduce training generalizable Neural Fields incorporating scene Priors (NFPs). The NFP network maps any single-view RGB-D image into signed distance and radiance values. A complete scene can be reconstructed by merging individual frames in the volumetric space WITHOUT a fusion module, which provides better flexibility. The scene priors can be trained on large-scale datasets, allowing for fast adaptation to the reconstruction of a new scene with fewer views. NFP not only demonstrates SOTA scene reconstruction performance and efficiency, but it also supports single-image novel-view synthesis, which is underexplored in neural fields. More qualitative results are available at: https://oasisyang.github.io/neural-prior
</details>
<details>
<summary>摘要</summary>
高级准确3D场景重建得到了近期神经场的进步。然而，大多数现有方法都是从零开始训练单个场景的分开网络。这不可持续、不够高效，并且难以在有限视角下获得好结果。而学习基于多视图零点法则可以减轻这些问题的影响，但它们的多视图设置使其更难扩展和应用于广泛的场景。相反，我们引入了基于场景假设（NFP）的培训普通神经场。NFP网络将单个视角RGB-D图像映射到了签名距离和颜色值上。通过在Volume空间合并个体帧，可以无需拟合模块重建完整的场景。场景假设可以在大规模数据集上培训，以便快速适应重建新场景的更少视角。NFP不仅达到了最佳场景重建性能和效率，还支持单个图像新视角synthesis，这是神经场中尚未得到充分发挥的。更详细的结果可以在：https://oasisyang.github.io/neural-prior 查看。
</details></li>
</ul>
<hr>
<h2 id="Doduo-Learning-Dense-Visual-Correspondence-from-Unsupervised-Semantic-Aware-Flow"><a href="#Doduo-Learning-Dense-Visual-Correspondence-from-Unsupervised-Semantic-Aware-Flow" class="headerlink" title="Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow"></a>Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15110">http://arxiv.org/abs/2309.15110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyu Jiang, Hanwen Jiang, Yuke Zhu</li>
<li>for: 这个论文旨在建立在动态场景下进行大规模变换的图像对应关系。</li>
<li>methods: 这个论文提出了一种无需基于真实数据的超参数监督的方法，通过流程基于截割来获得监督信号，并结合 semantic 预期来进行自动调节。</li>
<li>results: 在使用实际视频数据进行训练后，这种方法能够准确地对应图像中每个像素的位置，并在不同场景下保持高精度。 代码和更多视觉化数据可以在 <a target="_blank" rel="noopener" href="https://ut-austin-rpl.github.io/Doduo">https://ut-austin-rpl.github.io/Doduo</a> 上找到。<details>
<summary>Abstract</summary>
Dense visual correspondence plays a vital role in robotic perception. This work focuses on establishing the dense correspondence between a pair of images that captures dynamic scenes undergoing substantial transformations. We introduce Doduo to learn general dense visual correspondence from in-the-wild images and videos without ground truth supervision. Given a pair of images, it estimates the dense flow field encoding the displacement of each pixel in one image to its corresponding pixel in the other image. Doduo uses flow-based warping to acquire supervisory signals for the training. Incorporating semantic priors with self-supervised flow training, Doduo produces accurate dense correspondence robust to the dynamic changes of the scenes. Trained on an in-the-wild video dataset, Doduo illustrates superior performance on point-level correspondence estimation over existing self-supervised correspondence learning baselines. We also apply Doduo to articulation estimation and zero-shot goal-conditioned manipulation, underlining its practical applications in robotics. Code and additional visualizations are available at https://ut-austin-rpl.github.io/Doduo
</details>
<details>
<summary>摘要</summary>
紧密的视觉对应在机器人感知中发挥关键作用。这项工作专注于在两个图像中建立紧密的对应关系，以捕捉在进行重大变化的动态场景中。我们提出了Doduo，一种不需要基于真实数据的学习批处理的普适 dense visual correspondence 算法。给定两个图像，它估算每个像素在一个图像中的满意流场，并将其映射到另一个图像中的对应像素。Doduo 使用流程基于折射来获得超级visery 信号，用于训练。将semantic prior 与自我supervised flow 训练结合，Doduo 可以生成高度准确的紧密对应，抗性能够抵御场景的动态变化。在一个野外视频数据集上训练，Doduo 在点级对应估算方面表现出色，超过现有的自我supervised correspondence 学习基线。我们还应用Doduo 到人工智能和机器人的艺术骨骼估算和零基础目标conditined manipulation 中，展示了其实际应用的可行性。代码和补充的视觉化可以在https://ut-austin-rpl.github.io/Doduo 中找到。
</details></li>
</ul>
<hr>
<h2 id="Attention-Satisfies-A-Constraint-Satisfaction-Lens-on-Factual-Errors-of-Language-Models"><a href="#Attention-Satisfies-A-Constraint-Satisfaction-Lens-on-Factual-Errors-of-Language-Models" class="headerlink" title="Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models"></a>Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15098">http://arxiv.org/abs/2309.15098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mert Yuksekgonul, Varun Chandrasekaran, Erik Jones, Suriya Gunasekar, Ranjita Naik, Hamid Palangi, Ece Kamar, Besmira Nushi</li>
<li>for: 本研究探究 transformer 基于大语言模型（LLM）在生成错误文本时的内部行为。</li>
<li>methods: 本研究使用约束满足问题的框架来调查模型如何与事实约束交互。特别是，我们发现模型强调约束Token的注意力和事实准确性之间存在强正相关。</li>
<li>results: 我们在11个 dataset中进行了大规模的探索，包括7B、13B和70B的Llama-2家族模型。我们提出了SAT Probe方法，可以预测约束满足和事实错误，并允许早期错误识别。这种方法和结论表明如何在LLMs中利用事实准确性的机制来提高可靠性。<details>
<summary>Abstract</summary>
We investigate the internal behavior of Transformer-based Large Language Models (LLMs) when they generate factually incorrect text. We propose modeling factual queries as Constraint Satisfaction Problems and use this framework to investigate how the model interacts internally with factual constraints. Specifically, we discover a strong positive relation between the model's attention to constraint tokens and the factual accuracy of its responses. In our curated suite of 11 datasets with over 40,000 prompts, we study the task of predicting factual errors with the Llama-2 family across all scales (7B, 13B, 70B). We propose SAT Probe, a method probing self-attention patterns, that can predict constraint satisfaction and factual errors, and allows early error identification. The approach and findings demonstrate how using the mechanistic understanding of factuality in LLMs can enhance reliability.
</details>
<details>
<summary>摘要</summary>
我们研究 transformer 基于大语言模型（LLM）在生成错误文本时的内部行为。我们提议将 factual 查询作为约束满足问题来调查模型如何与约束进行交互。我们发现模型对约束符号的注意力强相关于它们的事实准确率。在我们精心制作的 11 个数据集中，包括超过 40,000 个提示，我们使用 Llama-2 家族在不同级别（7B、13B、70B）中预测错误。我们提出了 SAT Probe，一种探测自注意力模式的方法，可以预测约束满足和事实错误，并允许早期错误识别。这种方法和发现表明如何通过理解 LLM 中的事实性机制来提高可靠性。
</details></li>
</ul>
<hr>
<h2 id="VideoDirectorGPT-Consistent-Multi-scene-Video-Generation-via-LLM-Guided-Planning"><a href="#VideoDirectorGPT-Consistent-Multi-scene-Video-Generation-via-LLM-Guided-Planning" class="headerlink" title="VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning"></a>VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15091">http://arxiv.org/abs/2309.15091</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HL-hanlin/VideoDirectorGPT">https://github.com/HL-hanlin/VideoDirectorGPT</a></li>
<li>paper_authors: Han Lin, Abhay Zala, Jaemin Cho, Mohit Bansal</li>
<li>For: The paper aims to explore the use of large language models (LLMs) for temporally consistent long video generation, and to develop a novel framework called VideoDirectorGPT that can leverage the knowledge of LLMs for video content planning and grounded video generation.* Methods: The proposed VideoDirectorGPT framework consists of a video planner LLM (GPT-4) and a video generator (Layout2Vid), which work together to generate multi-scene videos with visual consistency across scenes. The video planner generates a “video plan” that includes scene descriptions, entity layouts, and background information, and the video generator uses this plan to generate the video content.* Results: The proposed framework substantially improves layout and movement control in both single- and multi-scene video generation, and can generate multi-scene videos with visual consistency across scenes while achieving competitive performance with state-of-the-art (SOTA) methods in open-domain single-scene text-to-video generation. Additionally, the framework can dynamically control the strength of layout guidance and can generate videos with user-provided images.<details>
<summary>Abstract</summary>
Although recent text-to-video (T2V) generation methods have seen significant advancements, most of these works focus on producing short video clips of a single event with a single background (i.e., single-scene videos). Meanwhile, recent large language models (LLMs) have demonstrated their capability in generating layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency groupings of the entities and backgrounds. Next, guided by this output from the video planner, our video generator, Layout2Vid, has explicit control over spatial layouts and can maintain temporal consistency of entities/backgrounds across scenes, while only trained with image-level annotations. Our experiments demonstrate that VideoDirectorGPT framework substantially improves layout and movement control in both single- and multi-scene video generation and can generate multi-scene videos with visual consistency across scenes, while achieving competitive performance with SOTAs in open-domain single-scene T2V generation. We also demonstrate that our framework can dynamically control the strength for layout guidance and can also generate videos with user-provided images. We hope our framework can inspire future work on better integrating the planning ability of LLMs into consistent long video generation.
</details>
<details>
<summary>摘要</summary>
Although recent text-to-video (T2V) generation methods have made significant progress, most of these works focus on producing short video clips with a single background (i.e., single-scene videos). However, recent large language models (LLMs) have demonstrated their ability to generate layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency groupings of the entities and backgrounds. Next, guided by this output from the video planner, our video generator, Layout2Vid, has explicit control over spatial layouts and can maintain temporal consistency of entities/backgrounds across scenes, while only trained with image-level annotations. Our experiments demonstrate that VideoDirectorGPT framework substantially improves layout and movement control in both single- and multi-scene video generation and can generate multi-scene videos with visual consistency across scenes, while achieving competitive performance with SOTAs in open-domain single-scene T2V generation. We also demonstrate that our framework can dynamically control the strength for layout guidance and can also generate videos with user-provided images. We hope our framework can inspire future work on better integrating the planning ability of LLMs into consistent long video generation.
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-AI-Algorithms-for-Energy-Management-in-E-Mobility-Services"><a href="#A-Review-on-AI-Algorithms-for-Energy-Management-in-E-Mobility-Services" class="headerlink" title="A Review on AI Algorithms for Energy Management in E-Mobility Services"></a>A Review on AI Algorithms for Energy Management in E-Mobility Services</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15140">http://arxiv.org/abs/2309.15140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sen Yan, Maqsood Hussain Shah, Ji Li, Noel O’Connor, Mingming Liu</li>
<li>for: 本研究旨在探讨人工智能（AI）在电动交通系统（EMS）中的应用潜力，以Address various challenges related to efficient energy management, including range anxiety, charge rate optimization, and energy storage longevity.</li>
<li>methods: 本研究通过分析现有文献，探讨AI在EMS中的应用，并提出未来研究的有效方向。</li>
<li>results: 本研究的目标是提供EMS中AI应用的现状报告，并提出未来研究的有效方向，以为可持续和高效的电动交通系统提供贡献，并为交通领域带来更绿色和可持续的未来。<details>
<summary>Abstract</summary>
E-mobility, or electric mobility, has emerged as a pivotal solution to address pressing environmental and sustainability concerns in the transportation sector. The depletion of fossil fuels, escalating greenhouse gas emissions, and the imperative to combat climate change underscore the significance of transitioning to electric vehicles (EVs). This paper seeks to explore the potential of artificial intelligence (AI) in addressing various challenges related to effective energy management in e-mobility systems (EMS). These challenges encompass critical factors such as range anxiety, charge rate optimization, and the longevity of energy storage in EVs. By analyzing existing literature, we delve into the role that AI can play in tackling these challenges and enabling efficient energy management in EMS. Our objectives are twofold: to provide an overview of the current state-of-the-art in this research domain and propose effective avenues for future investigations. Through this analysis, we aim to contribute to the advancement of sustainable and efficient e-mobility solutions, shaping a greener and more sustainable future for transportation.
</details>
<details>
<summary>摘要</summary>
电动 mobilité (e-mobility) 已经出现为解决交通领域的环境和可持续性问题的重要解决方案。 fossil fuels 的枯竭、增加的气候变化排放和战 against 气候变化 都高亮了转换到电动汽车 (EV) 的必要性。 本文想要探讨人工智能 (AI) 在电动交通系统 (EMS) 中有效能源管理的挑战。这些挑战包括范围焦虑、加速率优化和电动汽车中能量存储的寿命。通过分析现有的文献，我们探讨了 AI 在这些挑战中的作用，并提出了有效的未来研究方向。我们的目标是为可持续可靠的电动交通解决方案做出贡献，创造一个更绿色、更可持续的交通未来。
</details></li>
</ul>
<hr>
<h2 id="When-Prolog-meets-generative-models-a-new-approach-for-managing-knowledge-and-planning-in-robotic-applications"><a href="#When-Prolog-meets-generative-models-a-new-approach-for-managing-knowledge-and-planning-in-robotic-applications" class="headerlink" title="When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications"></a>When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15049">http://arxiv.org/abs/2309.15049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enrico Saccon, Ahmet Tikna, Davide De Martini, Edoardo Lamon, Marco Roveri, Luigi Palopoli</li>
<li>for: 本文提出了一种基于Prolog语言的机器人知识管理系统，用于解决多机器人系统的计划生成和执行问题。</li>
<li>methods: 该系统采用了特殊的知识库组织方式，可以快速从自然语言文本中自动填充知识库，并通过一系列转换生成时间平行计划 для多机器人系统。</li>
<li>results: 该系统通过一个实际应用示例，实现了自动化计划生成和执行，提高了机器人系统的效率和可靠性。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In this paper, we propose a robot oriented knowledge management system based on the use of the Prolog language. Our framework hinges on a special organisation of knowledge base that enables: 1. its efficient population from natural language texts using semi-automated procedures based on Large Language Models, 2. the bumpless generation of temporal parallel plans for multi-robot systems through a sequence of transformations, 3. the automated translation of the plan into an executable formalism (the behaviour trees). The framework is supported by a set of open source tools and is shown on a realistic application.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于Prolog语言的机器人知识管理系统。我们的框架利用特殊的知识库组织方式，以实现：1. 自然语言文本自动或半自动填充知识库，使用大语言模型；2. 生成多机器人系统的时间平行计划，通过序列转换；3. 自动将计划转换为执行语言（行为树）。该框架得到了一组开源工具的支持，并在实际应用中展示了其可行性。
</details></li>
</ul>
<hr>
<h2 id="Class-Incremental-Learning-via-Likelihood-Ratio-Based-Task-Prediction"><a href="#Class-Incremental-Learning-via-Likelihood-Ratio-Based-Task-Prediction" class="headerlink" title="Class Incremental Learning via Likelihood Ratio Based Task Prediction"></a>Class Incremental Learning via Likelihood Ratio Based Task Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15048">http://arxiv.org/abs/2309.15048</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linhaowei1/tplr">https://github.com/linhaowei1/tplr</a></li>
<li>paper_authors: Haowei Lin, Yijia Shao, Weinan Qian, Ningxin Pan, Yiduo Guo, Bing Liu</li>
<li>for: 这篇论文targets continual learning setting of class incremental learning (CIL), where tasks are learned sequentially and no task identifier is provided at test time.</li>
<li>methods: 该论文提出了一种基于任务增量学习 (TIL) 方法的方法，即在一个共享网络中训练每个任务的专门模型，并使用这些模型作为OOD探测器进行内容检测和OOD检测。</li>
<li>results: 该论文表明，使用传统的OOD探测器进行任务标识预测是低效的，因为可以利用CIL中的额外信息（如回退数据和已学会任务）来设计更好和原理性的任务标识预测方法。该论文提出了TPLR（任务标识预测基于likelihood ratio）方法，该方法在CIL中表现出了明显的优异。<details>
<summary>Abstract</summary>
Class incremental learning (CIL) is a challenging setting of continual learning, which learns a series of tasks sequentially. Each task consists of a set of unique classes. The key feature of CIL is that no task identifier (or task-id) is provided at test time for each test sample. Predicting the task-id for each test sample is a challenging problem. An emerging theoretically justified and effective approach is to train a task-specific model for each task in a shared network for all tasks based on a task-incremental learning (TIL) method to deal with forgetting. The model for each task in this approach is an out-of-distribution (OOD) detector rather than a conventional classifier. The OOD detector can perform both within-task (in-distribution (IND)) class prediction and OOD detection. The OOD detection capability is the key for task-id prediction during inference for each test sample. However, this paper argues that using a traditional OOD detector for task-id prediction is sub-optimal because additional information (e.g., the replay data and the learned tasks) available in CIL can be exploited to design a better and principled method for task-id prediction. We call the new method TPLR (Task-id Prediction based on Likelihood Ratio}). TPLR markedly outperforms strong CIL baselines.
</details>
<details>
<summary>摘要</summary>
增量学习（CIL）是一种挑战性的持续学习设定，它通过一系列任务进行顺序学习。每个任务包含一组唯一的类。CIL的关键特征是在测试时没有提供任务标识符（或任务ID）。预测任务标识符 для每个测试样本是一个挑战性的问题。一种迅速成熔和有理据 justify的方法是在一个共享网络中基于任务增量学习（TIL）方法来处理忘记。在这种方法中，每个任务的模型是一个out-of-distribution（OOD）探测器，而不是一个传统的分类器。OOD探测器可以同时进行内任务（IN-distribution (IND)）类预测和OOD检测。OOD检测能力是键 для任务标识符预测 durante la inferencia para cada muestra de prueba. Sin embargo, este artículo argumenta que utilizar un detector OOD tradicional para la predicción de la tarea es subóptima, ya que la información adicional (por ejemplo, los datos de replay y las tareas aprendidas) disponible en CIL puede ser explotada para diseñar un método más efectivo y principios para la predicción de la tarea. Llamamos al nuevo método TPLR (Predicción de Tarea basada en el Ratiode Likelihood). TPLR notablemente supera los baselines fuertes de CIL.
</details></li>
</ul>
<hr>
<h2 id="Combining-Survival-Analysis-and-Machine-Learning-for-Mass-Cancer-Risk-Prediction-using-EHR-data"><a href="#Combining-Survival-Analysis-and-Machine-Learning-for-Mass-Cancer-Risk-Prediction-using-EHR-data" class="headerlink" title="Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data"></a>Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15039">http://arxiv.org/abs/2309.15039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Petr Philonenko, Vladimir Kokh, Pavel Blinov</li>
<li>for: 这个论文是为了提出一种基于电子医疗记录（EHR）数据的大规模个性化肿瘤风险评估方法。</li>
<li>methods: 这个方法使用了机器学习和生存分析，并将其组合成一个ensemble（生存ensemble），以降低计算量和可重现性。</li>
<li>results: 对比基线方法，提出的方法在ROC AUC、F1和年龄基线方法上均显示出显著的优势（22.8% vs 15.1%、83.7% vs 84.9%、17.8% vs 21.4%）。在盲测随机回归测试中，提出的方法还能够正确地检测肿瘤病人（9 out of 100）。<details>
<summary>Abstract</summary>
Purely medical cancer screening methods are often costly, time-consuming, and weakly applicable on a large scale. Advanced Artificial Intelligence (AI) methods greatly help cancer detection but require specific or deep medical data. These aspects affect the mass implementation of cancer screening methods. For these reasons, it is a disruptive change for healthcare to apply AI methods for mass personalized assessment of the cancer risk among patients based on the existing Electronic Health Records (EHR) volume.   This paper presents a novel method for mass cancer risk prediction using EHR data. Among other methods, our one stands out by the minimum data greedy policy, requiring only a history of medical service codes and diagnoses from EHR. We formulate the problem as a binary classification. This dataset contains 175 441 de-identified patients (2 861 diagnosed with cancer). As a baseline, we implement a solution based on a recurrent neural network (RNN). We propose a method that combines machine learning and survival analysis since these approaches are less computationally heavy, can be combined into an ensemble (the Survival Ensemble), and can be reproduced in most medical institutions.   We test the Survival Ensemble in some studies. Firstly, we obtain a significant difference between values of the primary metric (Average Precision) with 22.8% (ROC AUC 83.7%, F1 17.8%) for the Survival Ensemble versus 15.1% (ROC AUC 84.9%, F1 21.4%) for the Baseline. Secondly, the performance of the Survival Ensemble is also confirmed during the ablation study. Thirdly, our method exceeds age baselines by a significant margin. Fourthly, in the blind retrospective out-of-time experiment, the proposed method is reliable in cancer patient detection (9 out of 100 selected). Such results exceed the estimates of medical screenings, e.g., the best Number Needed to Screen (9 out of 1000 screenings).
</details>
<details>
<summary>摘要</summary>
医疗保健领域的纯医学抵抗癌症检测方法通常是非常昂贵的、耗时的、并且适用范围不够广泛。高级人工智能（AI）方法可以帮助癌症检测，但它们需要特定或深入的医疗数据。这些因素对普遍实施癌症检测方法产生影响。为了缓解这些问题，我们提出了基于电子医疗记录（EHR）量的大规模个性化癌症风险评估的干预性变革。这篇论文提出了一种新的癌症风险预测方法，使用EHR数据。与其他方法不同的是，我们的方法只需要医疗服务代码和诊断记录，并将问题定义为二分类问题。我们的数据集包含175441名医疗记录（2861名患有癌症）。作为基线，我们实施了一种基于循环神经网络（RNN）的解决方案。我们提出了一种结合机器学习和生存分析的方法，因为这些方法较为轻量级，可以结合成ensemble（生存ensemble），并且可以在大多数医疗机构中实现。我们在一些研究中测试了生存ensemble。首先，我们发现Survival Ensemble的主要指标（均值精度）的值为22.8%（ROC AUC 83.7%, F1 17.8%），与基线相比，表示Survival Ensemble的性能有所提升。其次，我们在减少研究中证明了Survival Ensemble的性能。第三，我们的方法超过了年龄基线的 margin。最后，在盲测退化试验中，我们的方法可靠地检测癌症患者（9 out of 100）。这些结果超越了医疗检测的估计，例如最佳数量检测（9 out of 1000）。
</details></li>
</ul>
<hr>
<h2 id="How-to-Catch-an-AI-Liar-Lie-Detection-in-Black-Box-LLMs-by-Asking-Unrelated-Questions"><a href="#How-to-Catch-an-AI-Liar-Lie-Detection-in-Black-Box-LLMs-by-Asking-Unrelated-Questions" class="headerlink" title="How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"></a>How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15840">http://arxiv.org/abs/2309.15840</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lorypack/llm-liedetector">https://github.com/lorypack/llm-liedetector</a></li>
<li>paper_authors: Lorenzo Pacchiardi, Alex J. Chan, Sören Mindermann, Ilan Moscovitz, Alexa Y. Pan, Yarin Gal, Owain Evans, Jan Brauner</li>
<li>for: The paper aims to develop a simple lie detector for large language models (LLMs) that does not require access to the LLM’s activations or ground-truth knowledge of the fact in question.</li>
<li>methods: The lie detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM’s yes&#x2F;no answers into a logistic regression classifier.</li>
<li>results: The detector is highly accurate and generalizes well to different LLM architectures, fine-tuned lies, sycophantic lies, and real-life scenarios such as sales, indicating that LLMs have distinctive lie-related behavioral patterns that could enable general-purpose lie detection.Here’s the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文想要开发一个简单的大语言模型（LLM）假说检测器，不需要访问LLM的活动或真实知识。</li>
<li>methods: 这个检测器使用一组预先定义的无关问题来检测嫌疑性假话，然后将LLM的是&#x2F;否答案传递给一个线性回归分类器。</li>
<li>results: 检测器具有高准确率和可扩展性，可以在不同的LLM架构、精心预期假话、卖场假话和实际生活场景中工作，表明LLM在假说方面具有一定的共同行为特征，可能实现普适的假说检测。<details>
<summary>Abstract</summary>
Large language models (LLMs) can "lie", which we define as outputting false statements despite "knowing" the truth in a demonstrable sense. LLMs might "lie", for example, when instructed to output misinformation. Here, we develop a simple lie detector that requires neither access to the LLM's activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM's yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. When trained on examples from a single setting -- prompting GPT-3.5 to lie about factual questions -- the detector generalises out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie, (3) sycophantic lies, and (4) lies emerging in real-life scenarios such as sales. These results indicate that LLMs have distinctive lie-related behavioural patterns, consistent across architectures and contexts, which could enable general-purpose lie detection.
</details>
<details>
<summary>摘要</summary>
翻译结果：大型语言模型（LLM）可以“谎”，我们定义为输出 false 语句，即使其“知道”真实情况可见。LLM 可能“谎”，例如，当它被 instruced 输出谎言。我们开发了一种简单的谎言检测器，不需要访问 LLM 的激活（黑盒），也不需要对事实知识进行证明。检测器通过在可疑谎言后提出一组预先定义的无关 follow-up 问题，并将 LLM 的是/否答案传入 logistic regression 分类器。尽管其简单，但这种检测器具有高度准确和意外的通用性。当在单个设定下（提问 GPT-3.5 谎言关于事实 вопросы）进行训练后，检测器可以通过（1）其他 LLM 架构、（2） LLM 精通谎言、（3）偏袋谎言和（4）实际生活场景中的谎言来进行泛化。这些结果表明，LLM 在不同架构和上下文中具有一致的谎言相关行为模式，可能实现通用的谎言检测。
</details></li>
</ul>
<hr>
<h2 id="Don’t-throw-away-your-value-model-Making-PPO-even-better-via-Value-Guided-Monte-Carlo-Tree-Search-decoding"><a href="#Don’t-throw-away-your-value-model-Making-PPO-even-better-via-Value-Guided-Monte-Carlo-Tree-Search-decoding" class="headerlink" title="Don’t throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding"></a>Don’t throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15028">http://arxiv.org/abs/2309.15028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiacheng Liu, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, Asli Celikyilmaz</li>
<li>for: 提高生成文本的可读性和吸引力</li>
<li>methods: 结合Monte-Carlo Tree Search（MCTS）和Proximal Policy Optimization（PPO）</li>
<li>results: 比标准实践提高生成文本的偏好性和可读性<details>
<summary>Abstract</summary>
Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS greatly improves the preferability of generated text compared to the standard practice of using only the PPO policy. Our results demonstrate the promise of search algorithms even on top of the aligned language models from PPO, and the under-explored benefit of the value network.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT假设用 Monte-Carlo Tree Search（MCTS）进行推理时，可能会认为无需使用 reinforcement learning 的 state-of-the-art 方法，例如 Proximal Policy Optimization（PPO）。在这篇论文中，我们表明可以通过将 MCTS 与 PPO 集成起来，从而获得更多的优势。关键思想是不要抛弃 PPO 的值网络，即在 PPO 训练过程中生成的 partial output sequences 的评估结果，而是在推理时使用这些值网络来导引policy网络进行文本生成。我们提出了一种新的值导向的推理算法，称为 PPO-MCTS，它可以将 PPO 的值网络与 policy 网络在推理时进行紧密的合作。与之前基于 MCTS 的文本生成方法相比，我们的方法的关键优势在于减少了在训练和测试之间的基本匹配问题，从而提高生成的文本的偏好性。我们的实验结果表明，PPO-MCTS 可以在四个文本生成任务上大幅提高生成的文本的偏好性，比标准实践使用只有 PPO 政策更好。我们的结果表明，搜索算法可以在 PPO 的对齐语言模型上获得优势，而且值网络的可用性还未得到充分利用。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Model-Alignment-A-Survey"><a href="#Large-Language-Model-Alignment-A-Survey" class="headerlink" title="Large Language Model Alignment: A Survey"></a>Large Language Model Alignment: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15025">http://arxiv.org/abs/2309.15025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Magnetic2014/llm-alignment-survey">https://github.com/Magnetic2014/llm-alignment-survey</a></li>
<li>paper_authors: Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, Deyi Xiong</li>
<li>for: 本文旨在探讨大语言模型（LLM）的对Alignment技术的应用，以确保这些模型的行为与人类价值观念相一致。</li>
<li>methods: 本文分析了现有的外部和内部Alignment方法，以及新见的提议，并评估了这些方法的效果。</li>
<li>results: 本文提供了评估大语言模型对Alignment技术的多种benchmark和评估方法，并对这些方法的可靠性和安全性进行了分析。<details>
<summary>Abstract</summary>
Recent years have witnessed remarkable progress made in large language models (LLMs). Such advancements, while garnering significant attention, have concurrently elicited various concerns. The potential of these models is undeniably vast; however, they may yield texts that are imprecise, misleading, or even detrimental. Consequently, it becomes paramount to employ alignment techniques to ensure these models to exhibit behaviors consistent with human values.   This survey endeavors to furnish an extensive exploration of alignment methodologies designed for LLMs, in conjunction with the extant capability research in this domain. Adopting the lens of AI alignment, we categorize the prevailing methods and emergent proposals for the alignment of LLMs into outer and inner alignment. We also probe into salient issues including the models' interpretability, and potential vulnerabilities to adversarial attacks. To assess LLM alignment, we present a wide variety of benchmarks and evaluation methodologies. After discussing the state of alignment research for LLMs, we finally cast a vision toward the future, contemplating the promising avenues of research that lie ahead.   Our aspiration for this survey extends beyond merely spurring research interests in this realm. We also envision bridging the gap between the AI alignment research community and the researchers engrossed in the capability exploration of LLMs for both capable and safe LLMs.
</details>
<details>
<summary>摘要</summary>
近年来，大语言模型（LLM）的进步很快，吸引了广泛的注意。然而，这些进步同时也引发了各种担忧。 LLM 的潜在力量无疑，但它们可能生成不准确、误导或甚至有害的文本。因此，使得这些模型与人类价值观 align 成为 Paramount 问题。本文尝试为大语言模型alignment的方法和新提议进行全面的探索，同时涉及到现有的 capacitor 研究。采用 AI alignment 的视野，我们分类了现有的方法和新提议为外部Alignment和内部Alignment。我们还考虑了模型的可读性和对 adversarial attack 的抵御能力。为评估 LLM 的 alignmen，我们提供了多种benchmark和评价方法。在讨论大语言模型alignment的现状后，我们将对未来的研究方向进行探讨，探讨这个领域可能会出现的有前途的研究方向。我们的 aspiration 不仅是激发关于这个领域的研究兴趣，还是在 AI Alignment 研究社区和探索大语言模型capability的研究人员之间建立桥梁，以实现 capable 和安全的 LLM。
</details></li>
</ul>
<hr>
<h2 id="PINF-Continuous-Normalizing-Flows-for-Physics-Constrained-Deep-Learning"><a href="#PINF-Continuous-Normalizing-Flows-for-Physics-Constrained-Deep-Learning" class="headerlink" title="PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning"></a>PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15139">http://arxiv.org/abs/2309.15139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Liu, Faguo Wu, Xiao Zhang</li>
<li>for: 解决 Фоккер-朋杰尔方程的归一化问题</li>
<li>methods: 利用变换方程保持概率密度的准正流模型</li>
<li>results: 可以效率地解决高维时间依赖和稳态 Фоккер-朋杰尔方程<details>
<summary>Abstract</summary>
The normalization constraint on probability density poses a significant challenge for solving the Fokker-Planck equation. Normalizing Flow, an invertible generative model leverages the change of variables formula to ensure probability density conservation and enable the learning of complex data distributions. In this paper, we introduce Physics-Informed Normalizing Flows (PINF), a novel extension of continuous normalizing flows, incorporating diffusion through the method of characteristics. Our method, which is mesh-free and causality-free, can efficiently solve high dimensional time-dependent and steady-state Fokker-Planck equations.
</details>
<details>
<summary>摘要</summary>
“常规化约束对概率密度进行解决是一个 significiant 挑战。正则化流，一种可逆生成模型，利用变量变换公式来保证概率密度的保守和复杂数据分布的学习。本文提出了物理学 informed 正则化流（PINF），一种新的连续正则化流扩展，通过方法Characteristics 来实现增材和 causality-free 的高维时间依赖和稳态方程解决。”Note: Simplified Chinese is also known as "简化字" or "简体字" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Unidirectional-brain-computer-interface-Artificial-neural-network-encoding-natural-images-to-fMRI-response-in-the-visual-cortex"><a href="#Unidirectional-brain-computer-interface-Artificial-neural-network-encoding-natural-images-to-fMRI-response-in-the-visual-cortex" class="headerlink" title="Unidirectional brain-computer interface: Artificial neural network encoding natural images to fMRI response in the visual cortex"></a>Unidirectional brain-computer interface: Artificial neural network encoding natural images to fMRI response in the visual cortex</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15018">http://arxiv.org/abs/2309.15018</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rxliang/vision">https://github.com/rxliang/vision</a></li>
<li>paper_authors: Ruixing Liang, Xiangyu Zhang, Qiong Li, Lai Wei, Hexin Liu, Avisha Kumar, Kelley M. Kempski Leadingham, Joshua Punnoose, Leibny Paola Garcia, Amir Manbachi</li>
<li>for: 这 paper 的目的是为了利用人工智能来理解视觉过程，并且可以用于研究大脑的功能和结构。</li>
<li>methods: 这 paper 使用了人工神经网络模型，名为 VISION，来模拟大脑的视觉过程。该模型使用视觉和语义输入，可以预测大脑的功能磁共振成像（fMRI） scan 响应。</li>
<li>results: 这 paper 的结果表明，VISION 模型可以准确预测人类血液响应的 fMRI 磁共振成像，比现有技术的性能高出 45%。此外，这 paper 还探讨了训练的神经网络中的表征偏见，生成了可验证的实验假设，并提出了一个可解释的度量来关联这些假设与 cortical 功能。<details>
<summary>Abstract</summary>
While significant advancements in artificial intelligence (AI) have catalyzed progress across various domains, its full potential in understanding visual perception remains underexplored. We propose an artificial neural network dubbed VISION, an acronym for "Visual Interface System for Imaging Output of Neural activity," to mimic the human brain and show how it can foster neuroscientific inquiries. Using visual and contextual inputs, this multimodal model predicts the brain's functional magnetic resonance imaging (fMRI) scan response to natural images. VISION successfully predicts human hemodynamic responses as fMRI voxel values to visual inputs with an accuracy exceeding state-of-the-art performance by 45%. We further probe the trained networks to reveal representational biases in different visual areas, generate experimentally testable hypotheses, and formulate an interpretable metric to associate these hypotheses with cortical functions. With both a model and evaluation metric, the cost and time burdens associated with designing and implementing functional analysis on the visual cortex could be reduced. Our work suggests that the evolution of computational models may shed light on our fundamental understanding of the visual cortex and provide a viable approach toward reliable brain-machine interfaces.
</details>
<details>
<summary>摘要</summary>
尽管人工智能（AI）在不同领域得到了重大进步，但它在理解视觉理解仍然处于未利用状态。我们提议一种人工神经网络名为“视觉接口系统”（VISION），以模拟人类大脑并证明它可以推动神经科学研究。使用视觉和语言输入，这种多模态模型预测大脑的功能磁共振成像（fMRI）扫描响应自然图像。VISION成功预测人类血液动力学响应视觉输入，与现有技术的性能相比，提高了45%。我们进一步探究训练的网络，揭示视觉区域的表达偏好，生成可验证的假设，并构建可解释的度量，将这些假设相关于 cortical 功能。通过这种模型和评价度量，设计和实施功能分析可以减少成本和时间开销。我们的工作表明，计算机模型的演化可能为我们的基本理解提供灯光，并提供可靠的脑机器接口。
</details></li>
</ul>
<hr>
<h2 id="Automating-question-generation-from-educational-text"><a href="#Automating-question-generation-from-educational-text" class="headerlink" title="Automating question generation from educational text"></a>Automating question generation from educational text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15004">http://arxiv.org/abs/2309.15004</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Ayan Kumar Bhowmick, Ashish Jagmohan, Aditya Vempaty, Prasenjit Dey, Leigh Hall, Jeremy Hartman, Ravi Kokku, Hema Maheshwari<br>for:本研究设计了一个自动生成问题工具，用于学校的学习和评估过程中的形ative和总结评估。methods:我们使用了最近的生成AI技术，设计了一个模块化框架，将transformer型语言模型用于自动生成多项选择问题（MCQ）。results:我们进行了广泛的量化和质感评估，展示了不同技术和模型之间的贸易。<details>
<summary>Abstract</summary>
The use of question-based activities (QBAs) is wide-spread in education, traditionally forming an integral part of the learning and assessment process. In this paper, we design and evaluate an automated question generation tool for formative and summative assessment in schools. We present an expert survey of one hundred and four teachers, demonstrating the need for automated generation of QBAs, as a tool that can significantly reduce the workload of teachers and facilitate personalized learning experiences. Leveraging the recent advancements in generative AI, we then present a modular framework employing transformer based language models for automatic generation of multiple-choice questions (MCQs) from textual content. The presented solution, with distinct modules for question generation, correct answer prediction, and distractor formulation, enables us to evaluate different language models and generation techniques. Finally, we perform an extensive quantitative and qualitative evaluation, demonstrating trade-offs in the use of different techniques and models.
</details>
<details>
<summary>摘要</summary>
使用问题基本活动（QBA）是教育中广泛的应用，传统上作为学习和评估过程的重要组成部分。在这篇论文中，我们设计并评估了一种自动生成问题工具，用于形ative和summative评估。我们发布了一百四名教师专家调查，表明自动生成QBA的需求，作为可以大幅减轻教师的工作负担，并且为个性化学习经验提供便利。利用最新的生成AI技术，我们然后提出了一种模块化框架，利用转换器基于语言模型生成多项选择问题（MCQ）。该解决方案具有问题生成、正确答案预测和幌Launchx的三个模块，允许我们评估不同的语言模型和生成技术。最后，我们进行了详细的量化和质量评估，描述了不同技术和模型的负担。
</details></li>
</ul>
<hr>
<h2 id="Measurement-Models-For-Sailboats-Price-vs-Features-And-Regional-Areas"><a href="#Measurement-Models-For-Sailboats-Price-vs-Features-And-Regional-Areas" class="headerlink" title="Measurement Models For Sailboats Price vs. Features And Regional Areas"></a>Measurement Models For Sailboats Price vs. Features And Regional Areas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14994">http://arxiv.org/abs/2309.14994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Weng, Chunlin Feng, Yihan Shao</li>
<li>for: 本研究探讨了帆船技术参数与价格之间的关系，以及各地售价的影响。</li>
<li>methods: 本研究使用了多种机器学习模型来预测帆船价格，其中梯度下降模型表现最佳，具有最低MSE和MAE。</li>
<li>results: 分析发现，单桅船通常比双桅船更便宜，并且一些参数，如长、宽、排水量和帆面积直接影响价格。另外，较低的吃水也与更高的列价有直接关系。研究还发现，不同国家的GDP没有直接影响帆船价格。使用50%交叉验证方法，我们的模型在测试组中具有一致的结果。本研究通过机器学习技术提供了更加精准的帆船价格预测，为潜在购买者提供了有用的指导。<details>
<summary>Abstract</summary>
In this study, we investigated the relationship between sailboat technical specifications and their prices, as well as regional pricing influences. Utilizing a dataset encompassing characteristics like length, beam, draft, displacement, sail area, and waterline, we applied multiple machine learning models to predict sailboat prices. The gradient descent model demonstrated superior performance, producing the lowest MSE and MAE. Our analysis revealed that monohulled boats are generally more affordable than catamarans, and that certain specifications such as length, beam, displacement, and sail area directly correlate with higher prices. Interestingly, lower draft was associated with higher listing prices. We also explored regional price determinants and found that the United States tops the list in average sailboat prices, followed by Europe, Hong Kong, and the Caribbean. Contrary to our initial hypothesis, a country's GDP showed no direct correlation with sailboat prices. Utilizing a 50% cross-validation method, our models yielded consistent results across test groups. Our research offers a machine learning-enhanced perspective on sailboat pricing, aiding prospective buyers in making informed decisions.
</details>
<details>
<summary>摘要</summary>
本研究 investigate sailboat技术参数和价格之间的关系，以及地域性的影响。使用一个包括特征如长、宽、吃水、排水量、 sail 面积和水线的数据集，我们应用多种机器学习模型来预测 sailboat 价格。梯度下降模型表现出色，生成最低的MSE和MAE。我们的分析发现，单桅船通常比多桅船便宜，并且一些特征，如长、宽、排水量和 sail 面积直接与更高的价格相关。另外，较低的吃水也与更高的列价有关。我们还探究了不同地区的价格决定因素，发现美国的平均 sailboat 价格最高，其次是欧洲、香港和加勒比海。与我们的初始假设不同，一个国家的GDP直接与 sailboat 价格无关。使用50%的交叉验证方法，我们的模型在测试组中提供了一致的结果。本研究提供了机器学习增强的 sailboat 价格Perspective，帮助潜在买家做出了 Informed 决定。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Deep-Neural-Network-Architecture-and-Feature-Extraction-Designs-for-Sensor-based-Human-Activity-Recognition"><a href="#Investigating-Deep-Neural-Network-Architecture-and-Feature-Extraction-Designs-for-Sensor-based-Human-Activity-Recognition" class="headerlink" title="Investigating Deep Neural Network Architecture and Feature Extraction Designs for Sensor-based Human Activity Recognition"></a>Investigating Deep Neural Network Architecture and Feature Extraction Designs for Sensor-based Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03760">http://arxiv.org/abs/2310.03760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danial Ahangarani, Mohammad Shirazi, Navid Ashraf</li>
<li>for: 本研究旨在 Investigate the performance of common deep learning and machine learning approaches, as well as different training mechanisms and feature representations, for human activity recognition.</li>
<li>methods: 本研究使用的方法包括deep learning和传统机器学习方法，以及不同的训练机制和特征表示方法。</li>
<li>results: 实验研究表明，deep learning方法可以在人类活动识别任务中表现出优于传统的信号处理和机器学习方法，而不同的特征表示方法和训练机制也对任务的性能有着不同的影响。<details>
<summary>Abstract</summary>
The extensive ubiquitous availability of sensors in smart devices and the Internet of Things (IoT) has opened up the possibilities for implementing sensor-based activity recognition. As opposed to traditional sensor time-series processing and hand-engineered feature extraction, in light of deep learning's proven effectiveness across various domains, numerous deep methods have been explored to tackle the challenges in activity recognition, outperforming the traditional signal processing and traditional machine learning approaches. In this work, by performing extensive experimental studies on two human activity recognition datasets, we investigate the performance of common deep learning and machine learning approaches as well as different training mechanisms (such as contrastive learning), and various feature representations extracted from the sensor time-series data and measure their effectiveness for the human activity recognition task.
</details>
<details>
<summary>摘要</summary>
“智能设备和互联网物联网（IoT）中的广泛 ubique 感知器的可用性，已经开启了基于感知器的活动识别的可能性。相比传统的感知器时间序列处理和手工设计特征提取，随着深度学习在不同领域的证明效果，许多深度方法在人类活动识别中被探索，超越传统的信号处理和机器学习方法。在这种工作中，我们通过对两个人活动识别数据集进行广泛的实验研究， investigate 不同的深度学习和机器学习方法，以及不同的训练机制（如对照学习）和不同的特征表示方法，并测试它们在人类活动识别任务中的效果。”Note: "ubique" is not a word in Simplified Chinese, so I translated it as "广泛" (practical) to convey the same meaning.
</details></li>
</ul>
<hr>
<h2 id="Improving-Unsupervised-Visual-Program-Inference-with-Code-Rewriting-Families"><a href="#Improving-Unsupervised-Visual-Program-Inference-with-Code-Rewriting-Families" class="headerlink" title="Improving Unsupervised Visual Program Inference with Code Rewriting Families"></a>Improving Unsupervised Visual Program Inference with Code Rewriting Families</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14972">http://arxiv.org/abs/2309.14972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Ganeshan, R. Kenny Jones, Daniel Ritchie</li>
<li>for: 这 paper 的目的是提高从视觉数据中推导程序的系统。</li>
<li>methods: 这 paper 使用的方法包括 sparse intermittent rewrite injection (SIRI) 框架，以及一家Parameter optimization, code pruning, 和 code grafting 的 rewrite family。</li>
<li>results: 使用 SIRI 和 rewrite family，对 2D 和 3D CSG shape programming languages 进行了改进，包括更好的重建和更快的收敛率，并且在测试时可以更好地提高 SIRI 预测结果的重建性能。<details>
<summary>Abstract</summary>
Programs offer compactness and structure that makes them an attractive representation for visual data. We explore how code rewriting can be used to improve systems for inferring programs from visual data. We first propose Sparse Intermittent Rewrite Injection (SIRI), a framework for unsupervised bootstrapped learning. SIRI sparsely applies code rewrite operations over a dataset of training programs, injecting the improved programs back into the training set. We design a family of rewriters for visual programming domains: parameter optimization, code pruning, and code grafting. For three shape programming languages in 2D and 3D, we show that using SIRI with our family of rewriters improves performance: better reconstructions and faster convergence rates, compared with bootstrapped learning methods that do not use rewriters or use them naively. Finally, we demonstrate that our family of rewriters can be effectively used at test time to improve the output of SIRI predictions. For 2D and 3D CSG, we outperform or match the reconstruction performance of recent domain-specific neural architectures, while producing more parsimonious programs that use significantly fewer primitives.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)程序具有紧凑性和结构，使其成为视觉数据的有效表示。我们探索如何使用代码重写来改善从视觉数据中推理程序的系统。我们首先提出了零噪抽象 rewrite injection（SIRI）框架，该框架通过对训练程序集进行零噪抽象 rewrite 操作，将改进后的程序重新插入到训练集中。我们设计了一家函数 rewrite 的家族，用于视觉编程领域：参数优化、代码剪辑和代码rafting。对于2D和3D CSGshape编程语言，我们显示了使用 SIRI 和我们家族的 rewrite 可以提高性能：更好的重建和更快的收敛率，相比于不使用 rewrite 或使用它们的随机方法。最后，我们示出了我们家族的 rewrite 可以在测试时有效地提高 SIRI 预测的输出。对2D和3D CSG，我们的方法可以与最新的域特定神经网络架构相比，并且生成更简洁的程序，使用更少的基本元素。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Methods-for-Producing-Forecast-Trajectories-in-Power-Systems"><a href="#Deep-Generative-Methods-for-Producing-Forecast-Trajectories-in-Power-Systems" class="headerlink" title="Deep Generative Methods for Producing Forecast Trajectories in Power Systems"></a>Deep Generative Methods for Producing Forecast Trajectories in Power Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15137">http://arxiv.org/abs/2309.15137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Weill, Jonathan Dumas</li>
<li>for: 随着绿色能源在电力混合体系中的扩展，电力系统的变化性会增加，因此需要强化系统以保证其安全性。因此，交通系统运营商（TSO）需要进行分析，模拟未来电力系统的运行。这些分析结果将被用于决策过程中。</li>
<li>methods: 我们使用深度学习模型生成能源生产和负荷预测轨迹。为了捕捉多变量时间序列的空间时间相关性，我们采用自适应网络和标准化流体，并证明它们对当前的统计方法（copula）更加有效。</li>
<li>results: 我们在法国TSO RTE风力预测数据上进行了广泛的实验，并与特定的时间序列生成metric进行比较。结果表明，我们的深度学习模型可以更好地预测风力资源的变化，并且可以减少预测错误的概率。<details>
<summary>Abstract</summary>
With the expansion of renewables in the electricity mix, power grid variability will increase, hence a need to robustify the system to guarantee its security. Therefore, Transport System Operators (TSOs) must conduct analyses to simulate the future functioning of power systems. Then, these simulations are used as inputs in decision-making processes. In this context, we investigate using deep learning models to generate energy production and load forecast trajectories. To capture the spatiotemporal correlations in these multivariate time series, we adapt autoregressive networks and normalizing flows, demonstrating their effectiveness against the current copula-based statistical approach. We conduct extensive experiments on the French TSO RTE wind forecast data and compare the different models with \textit{ad hoc} evaluation metrics for time series generation.
</details>
<details>
<summary>摘要</summary>
随着可再生能源在电力混合体中的扩展，电力网络的变化程度将增加，因此需要强化电力系统以确保其安全性。因此，交通系统运营商（TSOs）必须进行分析来模拟未来电力系统的运行。然后，这些分析结果将用于决策过程中。在这个上下文中，我们调查使用深度学习模型生成能源生产和负荷预测曲线。为了捕捉多变量时间序列的空间时间相关性，我们适应 autoregressive 网络和 норmalizing 流，并证明其效果性比现有的 copula 统计方法更高。我们在法国TSO RTE 风力预测数据上进行了广泛的实验，并与不同模型进行比较，使用特制时间序列生成评价指标。
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Hypernetworks-are-Surprisingly-Strong-in-Meta-RL"><a href="#Recurrent-Hypernetworks-are-Surprisingly-Strong-in-Meta-RL" class="headerlink" title="Recurrent Hypernetworks are Surprisingly Strong in Meta-RL"></a>Recurrent Hypernetworks are Surprisingly Strong in Meta-RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14970">http://arxiv.org/abs/2309.14970</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jacooba/hyper">https://github.com/jacooba/hyper</a></li>
<li>paper_authors: Jacob Beck, Risto Vuorio, Zheng Xiong, Shimon Whiteson</li>
<li>for: 这篇论文是关于深度强化学习（RL）的实现问题。</li>
<li>methods: 这篇论文使用了元RL，通过在相关任务的分布上进行meta-训练来直接解决样本不fficient问题。</li>
<li>results: 研究发现，结合批量学习和一般化模型（如回归网络）可以实现强大的性能，但是使用超网络是关键来激活这种潜在的性能。 surprisingly，这些简单的基本方法实际上在所有评估方法中表现最优。<details>
<summary>Abstract</summary>
Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually achieve the strongest performance of all methods evaluated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Interactively-Learning-Social-Media-Representations-Improves-News-Source-Factuality-Detection"><a href="#Interactively-Learning-Social-Media-Representations-Improves-News-Source-Factuality-Detection" class="headerlink" title="Interactively Learning Social Media Representations Improves News Source Factuality Detection"></a>Interactively Learning Social Media Representations Improves News Source Factuality Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14966">http://arxiv.org/abs/2309.14966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hockeybro12/fake_news_interactive_detection">https://github.com/hockeybro12/fake_news_interactive_detection</a></li>
<li>paper_authors: Nikhil Mehta, Dan Goldwasser</li>
<li>for: 这篇论文旨在探讨如何快速检测假新闻，特别是在新事件发生时。</li>
<li>methods: 本文提出了一个互动式的方法，让人类和机器学习系统共同帮助增强社交媒体表征质量。</li>
<li>results: 在实际世界事件上，我们的实验结果显示了对新闻来源的实际性检测表现的改善，甚至只需要几次人类互动即可。<details>
<summary>Abstract</summary>
The rise of social media has enabled the widespread propagation of fake news, text that is published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake news, especially as new events arise, is important to prevent misinformation.   While prior works have tackled this problem using supervised learning systems, automatedly modeling the complexities of the social media landscape that enables the spread of fake news is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where humans can interact to help an automated system learn a better social media representation quality. On real world events, our experiments show performance improvements in detecting factuality of news sources, even after few human interactions.
</details>
<details>
<summary>摘要</summary>
“社交媒体的崛起导致假新闻的广泛传播，这是为了散播误信和影响人们的信念。快速检测假新闻，特别是在新事件发生时，是非常重要的，以预防误信。而以往的工作已经使用监督学习系统来解决这个问题，但模拟社交媒体的复杂景象，却是一个挑战。而且，让人类检查所有新闻也不是可扩展的。因此，在这篇论文中，我们提出了一个互动式的方法，让人类和机器系统共同帮助对社交媒体的表现质量进行学习。在实际的世界事件上，我们的实验结果显示，对新闻来源的实际性进行检查，甚至只需几次人类互动，就可以 obtain 性能提升。”
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Continual-Multi-view-Clustering-with-Filtered-Structural-Fusion"><a href="#Contrastive-Continual-Multi-view-Clustering-with-Filtered-Structural-Fusion" class="headerlink" title="Contrastive Continual Multi-view Clustering with Filtered Structural Fusion"></a>Contrastive Continual Multi-view Clustering with Filtered Structural Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15135">http://arxiv.org/abs/2309.15135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhang Wan, Jiyuan Liu, Ao Li, Xinwang Liu, En Zhu</li>
<li>for: 该 paper 针对于实时数据 clustering 问题提出了一种新的方法，即 Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF)，以解决现有方法在面临新视图时的灾难性忘记问题。</li>
<li>methods: 该 paper 使用了一种数据缓存机制，通过筛选结构信息来减少数据的干扰效应，并通过对比学习来生成一个robust的分区矩阵。此外，该 paper 还结合了 semi-supervised learning 和知识储存技术。</li>
<li>results: EXTENSIVE experiments 表明，该 paper 提出的方法可以减少灾难性忘记问题，并且在不同的实际场景中具有优秀的性能。<details>
<summary>Abstract</summary>
Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we develop a data buffer with fixed size to store filtered structural information and utilize it to guide the generation of a robust partition matrix via contrastive learning. Furthermore, we theoretically connect CCMVC-FSF with semi-supervised learning and knowledge distillation. Extensive experiments exhibit the excellence of the proposed method.
</details>
<details>
<summary>摘要</summary>
多视图聚类在数据视图预先采集了一致和补充的信息中得到最佳效果。然而，它忽略了实时数据的情况，即数据视图随时间的采集。由于隐私问题或内存压力等原因，先前的视图不可能在时间上提供。一些方法已经提出来解决这个问题，但它们受到稳定性和软化之间的负担。具体来说，这些方法在获得新视图时会导致严重的忘记先前知识的问题（CFP），从而使得一致和补充的信息困难以获得，并影响聚类性能。为解决这个问题，我们提出了一种新方法，即对比学习 filtered 结构融合（CCMVC-FSF）。具体来说，我们认为数据相关性在聚类过程中扮演着关键角色，因此我们开发了一个固定大小的数据缓存，用于存储 filtered 结构信息，并使用其引导生成一个强健的分区矩阵。此外，我们 theoretically 连接 CCMVC-FSF 与半导导学习和知识储存。广泛的实验表明我们提出的方法的优势。
</details></li>
</ul>
<hr>
<h2 id="Addressing-preferred-orientation-in-single-particle-cryo-EM-through-AI-generated-auxiliary-particles"><a href="#Addressing-preferred-orientation-in-single-particle-cryo-EM-through-AI-generated-auxiliary-particles" class="headerlink" title="Addressing preferred orientation in single-particle cryo-EM through AI-generated auxiliary particles"></a>Addressing preferred orientation in single-particle cryo-EM through AI-generated auxiliary particles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14954">http://arxiv.org/abs/2309.14954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Dihan Zheng, Qiurong Wu, Nieng Yan, Zuoqiang Shi, Mingxu Hu, Chenglong Bao</li>
<li>for: 解决单 particle cryo-EM领域中的偏好方向问题，提供一种基于AI的方法。</li>
<li>methods: 使用 Conditional deep generative model 生成辅助粒子，解决观察到的粒子方向估计中的内在偏好。</li>
<li>results: 在凝固粒子电子顺向分析中 Hemagglutinin 聚合体的near-atomic resolution结构重建，以及在不倾斜数据中使用 cryoPROS-MP 版本进行膜蛋白 NaX 的结构重建。<details>
<summary>Abstract</summary>
The single-particle cryo-EM field faces the persistent challenge of preferred orientation, lacking general computational solutions. We introduce cryoPROS, an AI-based approach designed to address the above issue. By generating the auxiliary particles with a conditional deep generative model, cryoPROS addresses the intrinsic bias in orientation estimation for the observed particles. We effectively employed cryoPROS in the cryo-EM single particle analysis of the hemagglutinin trimer, showing the ability to restore the near-atomic resolution structure on non-tilt data. Moreover, the enhanced version named cryoPROS-MP significantly improves the resolution of the membrane protein NaX using the no-tilted data that contains the effects of micelles. Compared to the classical approaches, cryoPROS does not need special experimental or image acquisition techniques, providing a purely computational yet effective solution for the preferred orientation problem. Finally, we conduct extensive experiments that establish the low risk of model bias and the high robustness of cryoPROS.
</details>
<details>
<summary>摘要</summary>
单粒子普遍困难：对于单粒子普遍困难，我们提出了一个基于人工智能的方法---cryoPROS。这个方法使用深度生成模型来生成辅助粒子，以解决实验资料中的自然偏见问题。我们在血液蛋白聚矩体中使用了cryoPROS，并取得了非tilt数据中的精确结构。此外，我们还开发了一个优化版本名为cryoPROS-MP，它在没有偏向数据中实现了蛋白质NaX的高分辨率结构。相比于传统方法，cryoPROS不需要特殊的实验或摄像频率技术，提供了一个纯 computationally 的解决方案。最后，我们进行了广泛的实验，证明了cryoPROS并不存在偏见问题，并且具有高价的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Domain-Adaptation-for-Object-Detection-with-Prototype-based-Mean-teacher"><a href="#Multi-Source-Domain-Adaptation-for-Object-Detection-with-Prototype-based-Mean-teacher" class="headerlink" title="Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher"></a>Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14950">http://arxiv.org/abs/2309.14950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imatif17/Prototype-Mean-Teacher">https://github.com/imatif17/Prototype-Mean-Teacher</a></li>
<li>paper_authors: Atif Belal, Akhil Meethal, Francisco Perdigon Romero, Marco Pedersoli, Eric Granger<br>for:This paper is written for adapting visual object detectors to operational target domains using unsupervised domain adaptation (UDA) methods, specifically for multi-source domain adaptation (MSDA) scenarios.methods:The proposed method, Prototype-based Mean-Teacher (PMT), uses class prototypes learned using a contrastive loss to preserve domain-specific information and align categories across domains.results:The proposed PMT method outperforms state-of-the-art MSDA methods on several challenging object detection datasets, demonstrating its effectiveness in adapting visual object detectors to operational target domains.Here’s the information in Simplified Chinese text:for:这篇论文是为了使用无监督领域适应（UDA）方法来适应视觉对象检测器到运维目标领域中，特别是在多源领域适应（MSDA）场景下所写的。methods:该提议的方法是使用类prototype来保持领域特定信息，这些prototype是通过对应性损失来学习的。results:该提议的PMT方法在一些复杂的对象检测数据集上比州先进的MSDA方法表现出色，证明了它在适应视觉对象检测器到运维目标领域中的效果。<details>
<summary>Abstract</summary>
Adapting visual object detectors to operational target domains is a challenging task, commonly achieved using unsupervised domain adaptation (UDA) methods. When the labeled dataset is coming from multiple source domains, treating them as separate domains and performing a multi-source domain adaptation (MSDA) improves the accuracy and robustness over mixing these source domains and performing a UDA, as observed by recent studies in MSDA. Existing MSDA methods learn domain invariant and domain-specific parameters (for each source domain) for the adaptation. However, unlike single-source UDA methods, learning domain-specific parameters makes them grow significantly proportional to the number of source domains used. This paper proposes a novel MSDA method called Prototype-based Mean-Teacher (PMT), which uses class prototypes instead of domain-specific subnets to preserve domain-specific information. These prototypes are learned using a contrastive loss, aligning the same categories across domains and separating different categories far apart. Because of the use of prototypes, the parameter size of our method does not increase significantly with the number of source domains, thus reducing memory issues and possible overfitting. Empirical studies show PMT outperforms state-of-the-art MSDA methods on several challenging object detection datasets.
</details>
<details>
<summary>摘要</summary>
通常通过不监督领域适应（UDA）方法来实现对操作目标领域的视觉对象检测器的适应。当来自多个源领域的标注数据集被视为独立的多个源领域时，使用多源领域适应（MSDA）方法可以提高准确性和稳定性，根据最近的研究表明。现有的 MSDA 方法learns领域不变和领域特定参数（对每个源领域） для适应。然而，与单个 UDA 方法不同，学习领域特定参数会使其增长得 proportional to the number of source domains used。这篇文章提出了一种新的 MSDA 方法，即 Prototype-based Mean-Teacher（PMT），它使用类prototype来保留领域特定信息。这些 prototypes 是通过对应类型的损失函数来学习的，以实现类型之间的对齐和不同类型之间的分离。由于使用 prototypes，我们的方法中的参数大小不会随着 source domains 的数量增加，从而避免内存问题和可能的过拟合。实验表明，PMT 在多个挑战性的对象检测数据集上表现出色，超越了当前state-of-the-art MSDA 方法。
</details></li>
</ul>
<hr>
<h2 id="A-Democratic-Platform-for-Engaging-with-Disabled-Community-in-Generative-AI-Development"><a href="#A-Democratic-Platform-for-Engaging-with-Disabled-Community-in-Generative-AI-Development" class="headerlink" title="A Democratic Platform for Engaging with Disabled Community in Generative AI Development"></a>A Democratic Platform for Engaging with Disabled Community in Generative AI Development</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14921">http://arxiv.org/abs/2309.14921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Giri, Erin Brady</li>
<li>for: The paper aims to involve the disabled community in the design and development of generative AI systems to address bias and incorrectness in the outputs generated by these systems when used by the disabled community.</li>
<li>methods: The proposed platform calls for asynchronous and remote collaboration between disabled and non-disabled individuals from diverse backgrounds, using a democratic approach to decision-making.</li>
<li>results: The paper hopes to gain insight into the factors that contribute to bias in generative AI systems when used by the disabled community, and to identify the main algorithmic factors responsible for incorrect or irrelevant outputs.<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) systems, especially generative AI technologies are becoming more relevant in our society. Tools like ChatGPT are being used by members of the disabled community e.g., Autistic people may use it to help compose emails. The growing impact and popularity of generative AI tools have prompted us to examine their relevance within the disabled community. The design and development phases often neglect this marginalized group, leading to inaccurate predictions and unfair discrimination directed towards them. This could result from bias in data sets, algorithms, and systems at various phases of creation and implementation. This workshop paper proposes a platform to involve the disabled community while building generative AI systems. With this platform, our aim is to gain insight into the factors that contribute to bias in the outputs generated by generative AI when used by the disabled community. Furthermore, we expect to comprehend which algorithmic factors are the main contributors to the output's incorrectness or irrelevancy. The proposed platform calls on both disabled and non-disabled people from various geographical and cultural backgrounds to collaborate asynchronously and remotely in a democratic approach to decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）系统，尤其是生成AI技术在我们社会中变得越来越重要。如ChatGPT这种工具，被disabled社区的成员使用，例如自闭症人士可以使用其帮助compose电子邮件。随着生成AI工具的增长影响和流行度，我们被迫检查这些工具在disabled社区中的 relevance。然而，设计和开发阶段 часто忽视这个受欢迎的社群，导致错误预测和不公正对待。这可能由数据集、算法和系统在不同阶段的创建和实施中的偏见引起。本工作shop paper提出了一个平台，以便在生成AI系统的建设中包括disabled社区。通过这个平台，我们的目标是了解生成AI在disabled社区中输出的偏见的因素。此外，我们还希望了解算法因素是输出的错误或不相关的主要 contribuens。 proposed platform召集了不同地理和文化背景的 disable和非 disable人士共同参与协作，以征集 asynchronous和 remote的民主决策方式。
</details></li>
</ul>
<hr>
<h2 id="Label-Deconvolution-for-Node-Representation-Learning-on-Large-scale-Attributed-Graphs-against-Learning-Bias"><a href="#Label-Deconvolution-for-Node-Representation-Learning-on-Large-scale-Attributed-Graphs-against-Learning-Bias" class="headerlink" title="Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias"></a>Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14907">http://arxiv.org/abs/2309.14907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihao Shi, Jie Wang, Fanghua Lu, Hanzhu Chen, Defu Lian, Zheng Wang, Jieping Ye, Feng Wu</li>
<li>for: 本研究旨在提高 attributed graph 上的 node representation learning 性能，以便在多个下游任务中进行准确预测。</li>
<li>methods: 本研究使用 pre-trained model 和 graph neural network (GNN) 结合，将 attribute 和 graph structure 同时编码。然而，由于joint training large-scale graphs 会导致性能下降，therefore, many methods propose to train NEs 和 GNNs 分开。然而，这会导致 feature convolution 在 GNNs 中被忽略，从而导致学习偏好。本研究提出了一种高效的标签减少技术，即 Label Deconvolution (LD)，以解决这个问题。</li>
<li>results: 实验结果表明，LD 可以准确地预测 Open Graph Benchmark 数据集中的结果，并且与 state-of-the-art 方法相比，具有显著的性能优势。<details>
<summary>Abstract</summary>
Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias from that by the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping leads to an objective function that is equivalent to that by the joint training, while it can effectively incorporate GNNs in the training phase of NEs against the learning bias. More importantly, we show that LD converges to the optimal objective function values by thejoint training under mild assumptions. Experiments demonstrate LD significantly outperforms state-of-the-art methods on Open Graph Benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Node representation learning on attributed graphs---whose nodes are associated with rich attributes (e.g., texts and protein sequences)---plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias from that by the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping leads to an objective function that is equivalent to that by the joint training, while it can effectively incorporate GNNs in the training phase of NEs against the learning bias. More importantly, we show that LD converges to the optimal objective function values by the joint training under mild assumptions. Experiments demonstrate LD significantly outperforms state-of-the-art methods on Open Graph Benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Explainable-Sustainability-for-AI-in-the-Arts"><a href="#Explainable-Sustainability-for-AI-in-the-Arts" class="headerlink" title="Explainable Sustainability for AI in the Arts"></a>Explainable Sustainability for AI in the Arts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14877">http://arxiv.org/abs/2309.14877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Petra Jääskeläinen</li>
<li>for: 这两项研究旨在为AI艺术领域的艺术家和创作者提供环境可持续性反应系统，以便他们更好地理解AI的可持续性影响。</li>
<li>methods: 这两项研究使用了观察者参与的设计研究方法，以获取艺术家和创作者对AI的可持续性影响的认知和感知。</li>
<li>results: 研究发现，AI艺术领域的艺术家和创作者需要更多的信息和工具来理解AI的可持续性影响，并且需要一种可解释的可持续性模型来帮助他们更好地理解AI的可持续性影响。<details>
<summary>Abstract</summary>
AI is becoming increasingly popular in artistic practices, but the tools for informing practitioners about the environmental impact (and other sustainability implications) of AI are adapted for other contexts than creative practices -- making the tools and sustainability implications of AI not accessible for artists and creative practitioners. In this position paper, I describe two empirical studies that aim to develop environmental sustainability reflection systems for AI Arts, and discuss and introduce Explainable Sustainability in for AI Arts.
</details>
<details>
<summary>摘要</summary>
AI在艺术实践中日益受欢迎，但现有的环境影响（以及其他可持续发展因素）AI工具主要针对其他领域，因此艺术家和创作者无法访问这些工具和可持续发展因素。在本 Position paper 中，我描述了两项验证研究，旨在为 AI 艺术创造可持续发展反射系统，并讨论了Explainable Sustainability in AI Arts。Here's a breakdown of the translation:* AI在艺术实践中日益受欢迎 (AI is becoming increasingly popular in artistic practices)* 但现有的环境影响（以及其他可持续发展因素）AI工具主要针对其他领域 (but the tools for informing practitioners about the environmental impact and other sustainability implications of AI are mainly adapted for other contexts)* 因此艺术家和创作者无法访问这些工具和可持续发展因素 (therefore, artists and creative practitioners cannot access these tools and sustainability implications)* 在本 Position paper 中 (in this position paper)* 我描述了两项验证研究 (I describe two empirical studies)* 旨在为 AI 艺术创造可持续发展反射系统 (aiming to develop environmental sustainability reflection systems for AI Arts)* 并讨论了Explainable Sustainability in AI Arts (and discuss and introduce Explainable Sustainability in AI Arts)
</details></li>
</ul>
<hr>
<h2 id="Navigating-Text-To-Image-Customization-From-LyCORIS-Fine-Tuning-to-Model-Evaluation"><a href="#Navigating-Text-To-Image-Customization-From-LyCORIS-Fine-Tuning-to-Model-Evaluation" class="headerlink" title="Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation"></a>Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14859">http://arxiv.org/abs/2309.14859</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kohakublueleaf/lycoris">https://github.com/kohakublueleaf/lycoris</a></li>
<li>paper_authors: Shin-Ying Yeh, Yu-Guan Hsieh, Zhidong Gao, Bernard B W Yang, Giyeong Oh, Yanmin Gong</li>
<li>for: 本研究旨在提供一个开源库（LyCORIS），用于稳定扩散模型的多种调整方法，并提供一个系统性的评估框架，以探索不同调整技术对稳定扩散模型的影响。</li>
<li>methods: 本研究使用了多种调整方法，包括调整条件、条件调整和批评调整等，以测试它们在不同的概念类别和提示类型下的表现。</li>
<li>results: 本研究的结果显示，不同的调整方法对稳定扩散模型的表现有不同的影响，并且提供了一个系统性的评估框架，可以帮助研究人员更好地理解这些影响，并将其应用于实际应用中。<details>
<summary>Abstract</summary>
Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts. Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field. However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation. Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion) [https://github.com/KohakuBlueleaf/LyCORIS], an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion. Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categories. Through this comprehensive approach, our work provides essential insights into the nuanced effects of fine-tuning parameters, bridging the gap between state-of-the-art research and practical application.
</details>
<details>
<summary>摘要</summary>
Note: "Simplified Chinese" is a romanization of Chinese characters, which is used to represent the language in a simpler form, especially for non-native speakers. The text above is written in Simplified Chinese, and it may not be exactly the same as the traditional Chinese version.
</details></li>
</ul>
<hr>
<h2 id="Supersonic-Learning-to-Generate-Source-Code-Optimizations-in-C-C"><a href="#Supersonic-Learning-to-Generate-Source-Code-Optimizations-in-C-C" class="headerlink" title="Supersonic: Learning to Generate Source Code Optimizations in C&#x2F;C++"></a>Supersonic: Learning to Generate Source Code Optimizations in C&#x2F;C++</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14846">http://arxiv.org/abs/2309.14846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zimin Chen, Sen Fang, Martin Monperrus</li>
<li>for: 这个论文targets minor source code modifications for optimization.</li>
<li>methods: The paper presents a neural approach called Supersonic, which uses a seq2seq model to optimize C&#x2F;C++ programs.</li>
<li>results: The experiments show that Supersonic outperforms OpenAI’s GPT-3.5-Turbo and GPT-4 on competitive programming tasks, while also minimizing the extent of the change with a model that is more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.<details>
<summary>Abstract</summary>
Software optimization refines programs for resource efficiency while preserving functionality. Traditionally, it is a process done by developers and compilers. This paper introduces a third option, automated optimization at the source code level. We present Supersonic, a neural approach targeting minor source code modifications for optimization. Using a seq2seq model, Supersonic is trained on C/C++ program pairs ($x_{t}$, $x_{t+1}$), where $x_{t+1}$ is an optimized version of $x_{t}$, and outputs a diff. Supersonic's performance is benchmarked against OpenAI's GPT-3.5-Turbo and GPT-4 on competitive programming tasks. The experiments show that Supersonic not only outperforms both models on the code optimization task but also minimizes the extent of the change with a model more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Revisiting-Softmax-Masking-for-Stability-in-Continual-Learning"><a href="#Revisiting-Softmax-Masking-for-Stability-in-Continual-Learning" class="headerlink" title="Revisiting Softmax Masking for Stability in Continual Learning"></a>Revisiting Softmax Masking for Stability in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14808">http://arxiv.org/abs/2309.14808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoyong Kim, Minchan Kwon, Kangil Kim</li>
<li>for: 本文旨在解决 continual learning 中 softmax 函数不能准确捕捉 epistemic uncertainty 的问题。</li>
<li>methods: 本文提出一种基于 masking softmax 函数的方法，以 preserve confidence distribution during continual learning。</li>
<li>results:  Comparing with state-of-the-art methods, 本文的方法在 class-和 task-incremental learning benchmarks 中显示了更高的稳定性和足够的пластично性。特别是在使用 zero 或小 memory 时，本文的方法表现更好。<details>
<summary>Abstract</summary>
In continual learning, many classifiers use softmax function to learn confidence. However, numerous studies have pointed out its inability to accurately determine confidence distributions for outliers, often referred to as epistemic uncertainty. This inherent limitation also curtails the accurate decisions for selecting what to forget and keep in previously trained confidence distributions over continual learning process. To address the issue, we revisit the effects of masking softmax function. While this method is both simple and prevalent in literature, its implication for retaining confidence distribution during continual learning, also known as stability, has been under-investigated. In this paper, we revisit the impact of softmax masking, and introduce a methodology to utilize its confidence preservation effects. In class- and task-incremental learning benchmarks with and without memory replay, our approach significantly increases stability while maintaining sufficiently large plasticity. In the end, our methodology shows better overall performance than state-of-the-art methods, particularly in the use with zero or small memory. This lays a simple and effective foundation of strongly stable replay-based continual learning.
</details>
<details>
<summary>摘要</summary>
在连续学习中，许多分类器使用softmax函数来学习 confidence。然而，许多研究表明softmax函数无法准确地确定outsider的epistemic uncertainty。这种内置的限制也限制了精确地决定在前期训练 confidence distributions 中保留和忘记的决策。为解决这个问题，我们重新评估softmax函数的masking效果。虽然这种方法是简单而普遍存在在文献中，但它在连续学习过程中保持confidence分布的稳定性具有未得到足够的研究。在这篇论文中，我们重新评估softmax masking的影响，并介绍了一种使用它的confidence保存效果的方法。在不同的类和任务增量学习benchmark中，我们的方法显著提高了稳定性，同时保持了足够的пластичность。最后，我们的方法在与零或小的内存使用时表现更好，这建立了一个简单而有效的强有力的连续学习基础。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Soccer-Match-Prediction-Models-A-Deep-Learning-Approach-and-Feature-Optimization-for-Gradient-Boosted-Trees"><a href="#Evaluating-Soccer-Match-Prediction-Models-A-Deep-Learning-Approach-and-Feature-Optimization-for-Gradient-Boosted-Trees" class="headerlink" title="Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees"></a>Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14807">http://arxiv.org/abs/2309.14807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Calvin Yeung, Rory Bunker, Rikuhei Umemoto, Keisuke Fujii</li>
<li>for: 本研究旨在评估深度学习模型在足球赛事预测中的表现，以及确定最佳特征集合。</li>
<li>methods: 本研究使用了深度学习模型，使用最近五年的数据进行训练，并使用三个训练和验证集进行参数Grid搜索。</li>
<li>results: 根据验证集的结果表示，我们的模型在win&#x2F;draw&#x2F;loss预测中表现出了强大的稳定性，比前一次在2017年足球预测比赛中发表的模型更佳。<details>
<summary>Abstract</summary>
Machine learning models have become increasingly popular for predicting the results of soccer matches, however, the lack of publicly-available benchmark datasets has made model evaluation challenging. The 2023 Soccer Prediction Challenge required the prediction of match results first in terms of the exact goals scored by each team, and second, in terms of the probabilities for a win, draw, and loss. The original training set of matches and features, which was provided for the competition, was augmented with additional matches that were played between 4 April and 13 April 2023, representing the period after which the training set ended, but prior to the first matches that were to be predicted (upon which the performance was evaluated). A CatBoost model was employed using pi-ratings as the features, which were initially identified as the optimal choice for calculating the win/draw/loss probabilities. Notably, deep learning models have frequently been disregarded in this particular task. Therefore, in this study, we aimed to assess the performance of a deep learning model and determine the optimal feature set for a gradient-boosted tree model. The model was trained using the most recent five years of data, and three training and validation sets were used in a hyperparameter grid search. The results from the validation sets show that our model had strong performance and stability compared to previously published models from the 2017 Soccer Prediction Challenge for win/draw/loss prediction.
</details>
<details>
<summary>摘要</summary>
机器学习模型在足球赛事预测中变得越来越受欢迎，然而公共可用的标准数据集的缺乏使得模型评估变得困难。2023年足球预测挑战要求预测每个队伍所得的进球数量，以及每个队伍赢得、平局、负败的概率。提供的原始训练集和特征，在竞赛中提供，被补充了在4月4日至4月13日期间进行的其他比赛，表示训练集结束后的时间段，但是在预测的第一场比赛之前（在评估性能时使用）。使用Pi-评分来使用CatBoost模型，这些特征最初被认为是计算赢负平比数据的优选。值得注意的是，深度学习模型在这个特定任务中经常被忽视。因此，在这项研究中，我们想要评估深度学习模型的性能，并确定最佳特征集 для梯度树模型。模型使用过去五年的数据进行训练，并使用三个训练和验证集在搜索扫描中进行了超参数的搜索。验证集的结果表明，我们的模型在win/draw/loss预测方面具有强大的性能和稳定性，与2017年足球预测挑战中发表的模型相比。
</details></li>
</ul>
<hr>
<h2 id="Fine-tuning-and-aligning-question-answering-models-for-complex-information-extraction-tasks"><a href="#Fine-tuning-and-aligning-question-answering-models-for-complex-information-extraction-tasks" class="headerlink" title="Fine-tuning and aligning question answering models for complex information extraction tasks"></a>Fine-tuning and aligning question answering models for complex information extraction tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14805">http://arxiv.org/abs/2309.14805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthias Engelbach, Dennis Klau, Felix Scheerer, Jens Drawehn, Maximilien Kintz</li>
<li>For: This paper proposes an approach for improving the feature extraction of German business documents, such as insurance reports or medical leaflets, using extractive question answering (QA) models.* Methods: The paper uses and integrates existing German QA models, and fine-tunes them for tailored extraction tasks of complex linguistic features.* Results: The paper shows that fine-tuning the QA models boosts performance for these tasks, even with a small set of annotated data. Additionally, the paper discusses the relevance of scoring metrics for evaluating information extraction tasks and proposes a combined metric that mimics the assessment criteria from human experts.Here is the information in Simplified Chinese text:* For: 这篇论文提出了一种基于抽取问答模型的德国企业文档特征提取方法，以提高德国企业文档的特征提取精度。* Methods: 论文使用和集成了现有的德国问答模型，并对其进行了定制化的特征提取任务。* Results: 论文显示，通过定制化问答模型可以提高特征提取精度，即使只使用一小部分标注数据。此外，论文还讨论了特征提取任务的评价指标，并提出了一种组合指标，以模拟人类专家的评价标准。<details>
<summary>Abstract</summary>
The emergence of Large Language Models (LLMs) has boosted performance and possibilities in various NLP tasks. While the usage of generative AI models like ChatGPT opens up new opportunities for several business use cases, their current tendency to hallucinate fake content strongly limits their applicability to document analysis, such as information retrieval from documents. In contrast, extractive language models like question answering (QA) or passage retrieval models guarantee query results to be found within the boundaries of an according context document, which makes them candidates for more reliable information extraction in productive environments of companies. In this work we propose an approach that uses and integrates extractive QA models for improved feature extraction of German business documents such as insurance reports or medical leaflets into a document analysis solution. We further show that fine-tuning existing German QA models boosts performance for tailored extraction tasks of complex linguistic features like damage cause explanations or descriptions of medication appearance, even with using only a small set of annotated data. Finally, we discuss the relevance of scoring metrics for evaluating information extraction tasks and deduce a combined metric from Levenshtein distance, F1-Score, Exact Match and ROUGE-L to mimic the assessment criteria from human experts.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的出现对各种自然语言处理任务的性能和可能性带来了提升。然而，使用生成AI模型如ChatGPT时，它们很容易生成假内容，这限制了它们在文档分析中的应用。相比之下，抽取语言模型如问答（QA）或段落检索模型可以保证查询结果在指定的文档范围内，这使得它们在公司生产环境中更适合用于可靠的信息抽取。在这项工作中，我们提议一种使用和结合抽取QA模型来改进德国商业文档的特征提取解决方案。我们还证明了使用现有的德语QA模型进行精细调整可以提高适应性特征提取任务的表现，即使只使用一小部分标注数据。最后，我们讨论了评价信息提取任务的分数指标，并 deduced一个combined metric，包括Levenshtein距离、F1分数、精确匹配和ROUGE-L，以模拟人类专家的评价标准。
</details></li>
</ul>
<hr>
<h2 id="Forgetting-aware-Linear-Bias-for-Attentive-Knowledge-Tracing"><a href="#Forgetting-aware-Linear-Bias-for-Attentive-Knowledge-Tracing" class="headerlink" title="Forgetting-aware Linear Bias for Attentive Knowledge Tracing"></a>Forgetting-aware Linear Bias for Attentive Knowledge Tracing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14796">http://arxiv.org/abs/2309.14796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skewondr/FoLiBi">https://github.com/skewondr/FoLiBi</a></li>
<li>paper_authors: Yoonjin Im, Eunseong Choi, Heejin Kook, Jongwuk Lee</li>
<li>for: 这篇论文目的是提出一种忘记遗弃的知识追踪（KT）模型，以便更好地评估学生的知识水平。</li>
<li>methods: 该论文使用了注意力机制，将问题与学生的回答特征相结合，以捕捉问题之间的相关性。但是，我们的实验发现，现有的注意力基рованKT模型忽略了学生的忘记行为，特别是在交互历史较长时。</li>
<li>results: 该论文提出了一种简单 yet effective的解决方案，即忘记遗弃linear偏好（FoLiBi），用于反映学生的忘记行为。尽管简单，FoLiBi可以轻松地与现有的注意力基рованKT模型结合使用，并且在四个 benchmark数据集上实现了state-of-the-art KT模型的2.58%的AUC提升。<details>
<summary>Abstract</summary>
Knowledge Tracing (KT) aims to track proficiency based on a question-solving history, allowing us to offer a streamlined curriculum. Recent studies actively utilize attention-based mechanisms to capture the correlation between questions and combine it with the learner's characteristics for responses. However, our empirical study shows that existing attention-based KT models neglect the learner's forgetting behavior, especially as the interaction history becomes longer. This problem arises from the bias that overprioritizes the correlation of questions while inadvertently ignoring the impact of forgetting behavior. This paper proposes a simple-yet-effective solution, namely Forgetting-aware Linear Bias (FoLiBi), to reflect forgetting behavior as a linear bias. Despite its simplicity, FoLiBi is readily equipped with existing attentive KT models by effectively decomposing question correlations with forgetting behavior. FoLiBi plugged with several KT models yields a consistent improvement of up to 2.58% in AUC over state-of-the-art KT models on four benchmark datasets.
</details>
<details>
<summary>摘要</summary>
知识跟踪（KT）目标是根据问题解决历史评估学习者的掌握程度，以便提供更加流畅的课程设计。现今的研究者通常使用注意力机制来捕捉问题之间的相关性，并结合学习者的特点进行响应。然而，我们的实验研究发现，现有的注意力based KT 模型忽略学习者的忘记行为，特别是在互动历史越长时。这个问题来源于关注问题相关性的偏见，不经意识地忽略了忘记行为的影响。本文提出了一种简单 yet effective的解决方案，即忘记行为权重linear bias（FoLiBi），用于反映学习者的忘记行为。尽管简单，FoLiBi可以轻松地与现有的注意力based KT 模型结合使用，并且可以有效地 decomposition question相关性和忘记行为。在四个benchmark dataset上，FoLiBi与其他KT模型相结合得到了2.58%的AUC提升。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Map-Learning-of-Traffic-Light-to-Lane-Assignment-based-on-Motion-Data"><a href="#Semantic-Map-Learning-of-Traffic-Light-to-Lane-Assignment-based-on-Motion-Data" class="headerlink" title="Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data"></a>Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14793">http://arxiv.org/abs/2309.14793</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/map-learning/tl2la">https://github.com/map-learning/tl2la</a></li>
<li>paper_authors: Thomas Monninger, Andreas Weber, Steffen Staab</li>
<li>for: 这篇论文的目的是提供一种自动从交通灯状态和车辆交通动向中提取交通灯控制哪个车道的方法，以解决现有的手动配置和成本高、不可扩展的问题。</li>
<li>methods: 该方法使用基本统计方法来实现，包括模式基本贡献方法和安全考虑。</li>
<li>results: 研究人员通过实现和评估这种方法，并对可用的运动预测数据集进行转换，提供了一个公共的 API，以便研究人员开发和评估自己的方法。<details>
<summary>Abstract</summary>
Understanding which traffic light controls which lane is crucial to navigate intersections safely. Autonomous vehicles commonly rely on High Definition (HD) maps that contain information about the assignment of traffic lights to lanes. The manual provisioning of this information is tedious, expensive, and not scalable. To remedy these issues, our novel approach derives the assignments from traffic light states and the corresponding motion patterns of vehicle traffic. This works in an automated way and independently of the geometric arrangement. We show the effectiveness of basic statistical approaches for this task by implementing and evaluating a pattern-based contribution method. In addition, our novel rejection method includes accompanying safety considerations by leveraging statistical hypothesis testing. Finally, we propose a dataset transformation to re-purpose available motion prediction datasets for semantic map learning. Our publicly available API for the Lyft Level 5 dataset enables researchers to develop and evaluate their own approaches.
</details>
<details>
<summary>摘要</summary>
理解交通灯的控制哪一个车道是安全通行口的关键。自动驾驶车辆通常依赖高清晰度地图，这些地图包含交通灯分配给车道的信息。手动提供这些信息是费时、昂贵，并且不可扩展。为解决这些问题，我们提出了一种新的方法，即从交通灯状态和相应的车辆交通模式中提取分配信息。这种方法自动化了进行，不受地理布局的影响。我们还实现了一种基本的统计方法，以确定分配信息的有效性。此外，我们还提出了一种安全考虑的拒绝方法，通过利用统计假设测试来确保安全性。最后，我们建议将可用的动作预测数据集转换为semantic地图学习用的数据集，并提供了一个公共可用API，以便研究人员可以开发和评估自己的方法。
</details></li>
</ul>
<hr>
<h2 id="Transferring-climate-change-knowledge"><a href="#Transferring-climate-change-knowledge" class="headerlink" title="Transferring climate change knowledge"></a>Transferring climate change knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14780">http://arxiv.org/abs/2309.14780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suleymanabdureman65/Suleymen-Abdureman-Omer-">https://github.com/suleymanabdureman65/Suleymen-Abdureman-Omer-</a></li>
<li>paper_authors: Francesco Immorlano, Veronika Eyring, Thomas le Monnier de Gouville, Gabriele Accarino, Donatello Elia, Giovanni Aloisio, Pierre Gentine</li>
<li>for: 这种研究是为了提供更加准确的气候预测，以便于气候适应和气候控制。</li>
<li>methods: 这种研究使用了机器学习技术，具体来说是深度神经网络，以便利用和融合地球系统模型 simulate的知识和历史观测记录，以更准确地预测21世纪初的全球表面温度场。</li>
<li>results: 研究结果显示，使用这种方法可以更 precisely project global surface temperature fields in the 21st century，并且可以提供更加准确的气候预测，以便于气候适应和气候控制。 Specifically, the study found that the 1.5°C threshold of the Paris Agreement will be crossed in 2031 (2028-2034) for SSP2-4.5, in 2029 (2027-2031) for SSP3-7.0, and in 2028 (2025-2031) for SSP5-8.5. Similarly, the 2°C threshold will be exceeded in 2051 (2045-2059), 2044 (2040-2047), and 2042 (2038-2047) respectively.<details>
<summary>Abstract</summary>
Accurate climate projections are required for climate adaptation and mitigation. Earth system model simulations, used to project climate change, inherently make approximations in their representation of small-scale physical processes, such as clouds, that are at the root of the uncertainties in global mean temperature's response to increased greenhouse gas concentrations. Several approaches have been developed to use historical observations to constrain future projections and reduce uncertainties in climate projections and climate feedbacks. Yet those methods cannot capture the non-linear complexity inherent in the climate system. Using a Transfer Learning approach, we show that Machine Learning, in particular Deep Neural Networks, can be used to optimally leverage and merge the knowledge gained from Earth system model simulations and historical observations to more accurately project global surface temperature fields in the 21st century. For the Shared Socioeconomic Pathways (SSPs) 2-4.5, 3-7.0 and 5-8.5, we refine regional estimates and the global projection of the average global temperature in 2081-2098 (with respect to the period 1850-1900) to 2.73{\deg}C (2.44-3.11{\deg}C), 3.92{\deg}C (3.5-4.47{\deg}C) and 4.53{\deg}C (3.69-5.5{\deg}C), respectively, compared to the unconstrained 2.7{\deg}C (1.65-3.8{\deg}C), 3.71{\deg}C (2.56-4.97{\deg}C) and 4.47{\deg}C (2.95-6.02{\deg}C). Our findings show that the 1.5{\deg}C threshold of the Paris' agreement will be crossed in 2031 (2028-2034) for SSP2-4.5, in 2029 (2027-2031) for SSP3-7.0 and in 2028 (2025-2031) for SSP5-8.5. Similarly, the 2{\deg}C threshold will be exceeded in 2051 (2045-2059), 2044 (2040-2047) and 2042 (2038-2047) respectively. Our new method provides more accurate climate projections urgently required for climate adaptation.
</details>
<details>
<summary>摘要</summary>
准确的气候预测是为气候适应和抑制需要的。地球系统模型的 simulate climate change 中含有一些简化了小规模物理过程，如云，这些过程的不确定性导致全球平均温度响应增加绿house gas concentration的不确定性。多种方法已经开发来使用历史观察来约束未来预测并减少气候预测和反馈的不确定性。然而，这些方法无法捕捉气候系统的非线性复杂性。我们使用传输学习方法，具体来说是深度神经网络，可以最优地利用和融合地球系统模型和历史观察所获得的知识，以更准确地预测21世纪初期的全球表面温度场。对于 Shared Socioeconomic Pathways (SSPs) 2-4.5、3-7.0和5-8.5，我们精细地估算了地域估计和全球预测的平均全球温度差异，分别为2.73°C（2.44-3.11°C）、3.92°C（3.5-4.47°C）和4.53°C（3.69-5.5°C），与未控制的2.7°C（1.65-3.8°C）、3.71°C（2.56-4.97°C）和4.47°C（2.95-6.02°C）相比。我们的发现表明，在2031年（2028-2034年）、2029年（2027-2031年）和2028年（2025-2031年），分别为SSP2-4.5、SSP3-7.0和SSP5-8.5的情况下， Париж协议中的1.5°C阈值将会超过。同时，2°C阈值将在2051年（2045-2059年）、2044年（2040-2047年）和2042年（2038-2047年）内相继超过。我们的新方法提供了更准确的气候预测，为气候适应提供了至关重要的信息。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Small-Language-Models-with-Prompt-Learning-Paradigm-for-Efficient-Domain-Specific-Text-Classification"><a href="#Exploring-Small-Language-Models-with-Prompt-Learning-Paradigm-for-Efficient-Domain-Specific-Text-Classification" class="headerlink" title="Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification"></a>Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14779">http://arxiv.org/abs/2309.14779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengyu Luo, Peng Liu, Stefan Esping</li>
<li>for: 这个研究旨在探讨小型语言模型（SLMs）与提示学习方法（prompt-learning）在专门领域文本分类中的潜力。</li>
<li>methods: 本研究使用T5-base和GPT-3.5-turbo作为SLMs，并将其与提示学习方法结合，以测试它们在几个数据点（few-shot）和零数据点（zero-shot）下的表现。</li>
<li>results: 研究结果显示，在几个数据点下，使用提示学习方法可以实现T5-base模型的精确率高于75%，仅需要限制的标注数据。此外，研究还发现，这些提示可以在零数据点下实现模型的改进，并且可以实现模型之间的ensemble效果。<details>
<summary>Abstract</summary>
Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this, We further validate the effectiveness of active few-shot sampling and the ensemble strategy in the prompt-learning pipeline that contribute to a remarkable performance gain. Besides, in zero-shot settings with a fixed model, we underscore a pivotal observation that, although the GPT-3.5-turbo equipped with around 154B parameters garners an accuracy of 55.16%, the power of well designed prompts becomes evident when the FLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achieves an accuracy exceeding 31% with the optimized prompt, a leap from its sub-18% performance with an unoptimized one. Our findings underscore the promise of prompt-learning in classification tasks with SLMs, emphasizing the benefits of active few-shot sampling, and ensemble strategies in few-shot settings, and the importance of prompt engineering in zero-shot settings.
</details>
<details>
<summary>摘要</summary>
域域特定文本分类面临着匮乏标注数据的挑战，由于人工标注的高成本。提问学习，在少数shot场景中著名的效率，被提议为传统精度调整方法的替代。此外，虽然大语言模型（LLMs）在获得了前列，但小语言模型（SLMs，参数在1B以下）在域特定任务中提供了显著的可定制化、适应性和成本效益，遵循产业限制。本研究通过对SLMs与提问学习训练模型的组合来研究域特定文本分类的潜力。我们的评估表明，在少数shot设置下，当提问基本模型精度调整是可能的时候，T5-base，一个典型的SLM，可以在有限标注数据（占总数据的15%）下达到约75%的准确率。此外，我们还验证了在提问学习管道中的活动几个shot采样和 ensemble策略的效果，它们在提高性能方面发挥了重要作用。此外，在零shot设置下，我们注意到，虽然GPT-3.5-turbo搭载约154B参数，它在55.16%的准确率，但提问设计的优势在适用于FLAN-T5-large，一个具有0.5%的GPT-3.5-turbo参数，在优化提问下达到了31.10%的准确率，与未优化提问时的Sub-18%的性能有了大幅提升。我们的发现强调了提问学习在分类任务中的承诺，特别是在少数shot设置下的活动几个shot采样和ensemble策略的重要性，以及零shot设置下的提问工程学的重要性。
</details></li>
</ul>
<hr>
<h2 id="Boosting-In-Context-Learning-with-Factual-Knowledge"><a href="#Boosting-In-Context-Learning-with-Factual-Knowledge" class="headerlink" title="Boosting In-Context Learning with Factual Knowledge"></a>Boosting In-Context Learning with Factual Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14771">http://arxiv.org/abs/2309.14771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianing Wang, Chengyu Wang, Chuanqi Tan, Jun Huang, Ming Gao</li>
<li>for: 这 paper 的目的是解释如何使用 Large language models (LLMs) 进行 In-Context Learning (ICL)，以实现在未经见过的任务上达到竞争性表现。</li>
<li>methods: 这 paper 使用了一种新的 Knowledgeable In-Context Tuning (KICT) 框架，包括在连续自我超vised pre-training 过程中注入知识，选择高知识相关性的例子，以及根据先前知识进行结果调整。</li>
<li>results: 实验结果表明，KICT 相比强基eline，可以提高 auto-regressive LLMs 在多种文本分类和问答任务上的表现，提高了更多于 13% 和 7% 的准确率。<details>
<summary>Abstract</summary>
In-Context Learning (ICL) over Large language models (LLMs) aims at solving previously unseen tasks by conditioning on a few training examples, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge biases in LLMs for output generation. To unleash the power of LLMs in few-shot learning scenarios, we introduce a novel Knowledgeable In-Context Tuning (KICT) framework to further improve the performance of ICL: 1) injecting factual knowledge to LLMs during continual self-supervised pre-training, 2) judiciously selecting the examples with high knowledge relevance, and 3) calibrating the prediction results based on prior knowledge. We evaluate the proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over multiple text classification and question answering tasks. Experimental results demonstrate that KICT substantially outperforms strong baselines, and improves by more than 13% and 7% of accuracy on text classification and question answering tasks, respectively.
</details>
<details>
<summary>摘要</summary>
听说大语言模型（LLM）在受限语言学习（ICL）中表现突出，可以通过几个训练示例来解决未看过的任务，不需要参数更新，并且达到竞争性的性能。在这篇论文中，我们表明了知识的重要性，即LLM中的内在知识、选择的在上下文中的示例知识和LLM的输出生成知识偏好。为了解放LLM在几个步骤学习场景中的力量，我们提出了一种新的知识感知适应（KICT）框架：1）在不断的自我监督预训练中注入知识，2）精准地选择高知识相关的示例，3）根据先前知识进行预测结果的准确性补偿。我们对 auto-regressive LLM（如 GPT 型模型）进行了多种文本分类和问答任务的实验，结果表明，KICT substantially 超越了强基elines，并在文本分类和问答任务中提高了13% 和 7% 的准确率。
</details></li>
</ul>
<hr>
<h2 id="Program-Repair-with-Minimal-Edits-Using-CodeT5"><a href="#Program-Repair-with-Minimal-Edits-Using-CodeT5" class="headerlink" title="Program Repair with Minimal Edits Using CodeT5"></a>Program Repair with Minimal Edits Using CodeT5</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14760">http://arxiv.org/abs/2309.14760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Md. Mostafizer Rahman, Md Faizul Ibne Amin, Yutaka Watanobe</li>
<li>for:  This paper aims to suggest a correct program with minimal repair edits for solving introductory programming problems.</li>
<li>methods: The authors use a pre-trained CodeT5 model and fine-tune it on code pairs of wrong and correct programs to suggest a correct program.</li>
<li>results: The fine-tuned CodeT5 achieves a pass@100 of 91.95% and an average edit distance of 6.84, indicating that at least one correct program can be suggested by generating 100 candidate programs.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是为 introductory programming problems 提供一个尽可能少的修复编辑数量的正确程序建议。</li>
<li>methods: 作者使用 pre-trained CodeT5 模型，并在错误和正确程序的代码对中进行了微调，以建议正确的程序。</li>
<li>results: 微调后的 CodeT5 实现了 pass@100 的 91.95% 和平均修改距离 6.84，表明可以通过生成 100 个候选程序来建议至少一个正确程序。<details>
<summary>Abstract</summary>
Programmers often struggle to identify and fix bugs in their programs. In recent years, many language models (LMs) have been proposed to fix erroneous programs and support error recovery. However, the LMs tend to generate solutions that differ from the original input programs. This leads to potential comprehension difficulties for users. In this paper, we propose an approach to suggest a correct program with minimal repair edits using CodeT5. We fine-tune a pre-trained CodeT5 on code pairs of wrong and correct programs and evaluate its performance with several baseline models. The experimental results show that the fine-tuned CodeT5 achieves a pass@100 of 91.95% and an average edit distance of the most similar correct program of 6.84, which indicates that at least one correct program can be suggested by generating 100 candidate programs. We demonstrate the effectiveness of LMs in suggesting program repair with minimal edits for solving introductory programming problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Age-Minimization-in-Massive-IoT-via-UAV-Swarm-A-Multi-agent-Reinforcement-Learning-Approach"><a href="#Age-Minimization-in-Massive-IoT-via-UAV-Swarm-A-Multi-agent-Reinforcement-Learning-Approach" class="headerlink" title="Age Minimization in Massive IoT via UAV Swarm: A Multi-agent Reinforcement Learning Approach"></a>Age Minimization in Massive IoT via UAV Swarm: A Multi-agent Reinforcement Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14757">http://arxiv.org/abs/2309.14757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eslam Eldeeb, Mohammad Shehab, Hirley Alves</li>
<li>for: 这篇论文的目的是要Addressing the high-dimensional problem of deploying a swarm of UAVs to collect fresh information from IoT devices, and minimizing the overall age of information in the IoT network.</li>
<li>methods: 这篇论文使用了多代理深度学习来解决高维度的问题，包括cooperative和partially cooperative multi-agent deep reinforcement learning approaches.</li>
<li>results: 研究结果显示，cooperative和partially cooperative multi-agent deep reinforcement learning approaches可以比中央化深度学习方法表现更好，尤其在大规模网络中。<details>
<summary>Abstract</summary>
In many massive IoT communication scenarios, the IoT devices require coverage from dynamic units that can move close to the IoT devices and reduce the uplink energy consumption. A robust solution is to deploy a large number of UAVs (UAV swarm) to provide coverage and a better line of sight (LoS) for the IoT network. However, the study of these massive IoT scenarios with a massive number of serving units leads to high dimensional problems with high complexity. In this paper, we apply multi-agent deep reinforcement learning to address the high-dimensional problem that results from deploying a swarm of UAVs to collect fresh information from IoT devices. The target is to minimize the overall age of information in the IoT network. The results reveal that both cooperative and partially cooperative multi-agent deep reinforcement learning approaches are able to outperform the high-complexity centralized deep reinforcement learning approach, which stands helpless in large-scale networks.
</details>
<details>
<summary>摘要</summary>
在许多大规模IoT通信场景中，IoT设备需要由动态单元提供覆盖，以降低上行能 consumption。一种可靠的解决方案是通过大量的无人机（UAV群）来提供覆盖和IoT网络的更好的直线视野。然而，这些大规模IoT场景中服务单元的研究会导致高维度问题，高复杂性。在这篇论文中，我们运用多代理深度学习来解决由UAV群提供的高维度问题，目标是最小化IoT网络中信息的总龄。结果显示，协作和半协作多代理深度学习方法在大规模网络中表现出色，能够超越中央化深度学习方法，后者在大规模网络中无法作用。
</details></li>
</ul>
<hr>
<h2 id="Ego-perspective-enhanced-fitness-training-experience-of-AR-Try-to-Move-game"><a href="#Ego-perspective-enhanced-fitness-training-experience-of-AR-Try-to-Move-game" class="headerlink" title="Ego-perspective enhanced fitness training experience of AR Try to Move game"></a>Ego-perspective enhanced fitness training experience of AR Try to Move game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.13698">http://arxiv.org/abs/2310.13698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chongyu Zhang</li>
<li>for: 提高肢体重建训练的参与度和效果，并提供一种可乐思的训练方式</li>
<li>methods: 使用AR技术和 convolutional neural network (CNN) 识别和分类用户手势，并实现一种基于ego-视角的多交互手势数据集</li>
<li>results: 提供了一款AR Try to Move 游戏和一种可以快速和准确识别用户手势的 CNN 模型，帮助用户通过远程训练提高上肢部 muscle system 的效果和方便性<details>
<summary>Abstract</summary>
AR, a recent emerging technology, has been widely used in entertainment to provide users with immersive, interactive, and, sometimes, engaging experiences. The process of rehabilitation treatment and motor training process is often boring, and it is well known that users' exercise efficiency is often not as efficient as in a rehabilitation institution. Thus far, there is no effective upper limb sports rehabilitation training game based on the ego-perspective. Hence, with the objective of enhancing the enjoyment experience in rehabilitation and more effective remote rehabilitation training, this work aims to provide an AR Try to Move game and a convolutional neural network (CNN) for identifying and classifying user gestures from a self-collected AR multiple interactive gestures dataset. Utilizing an AR game scoring system, users are incentivized to enhance their upper limb muscle system through remote training with greater effectiveness and convenience.
</details>
<details>
<summary>摘要</summary>
新出现的技术AR在娱乐领域广泛应用，为用户提供 immerse、互动和有趣的经验。然而，rehabilitation treatment和motor training过程经常枯燥，用户的锻炼效率通常不如医疗机构的。目前没有有效的上肢体征复健康训练游戏，因此这项工作的目标是提供一款基于EGO视角的AR Try to Move游戏和一个 convolutional neural network（CNN），用于识别和分类用户自采集的AR多交互姿势数据集。通过使用AR游戏分数系统，用户有更多的动机来提高上肢体肌系，通过远程培训，提高效率和便捷性。
</details></li>
</ul>
<hr>
<h2 id="ANNCRIPS-Artificial-Neural-Networks-for-Cancer-Research-In-Prediction-Survival"><a href="#ANNCRIPS-Artificial-Neural-Networks-for-Cancer-Research-In-Prediction-Survival" class="headerlink" title="ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction &amp; Survival"></a>ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction &amp; Survival</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15803">http://arxiv.org/abs/2309.15803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amit Mathapati<br>for:  This research paper aims to develop and validate an intelligent mathematical model using Artificial Neural Networks (ANNs) to enhance the early detection of prostate cancer.methods:  The model utilizes ANNs to analyze various clinical and laboratory data, such as PSA and DRE results, to improve the accuracy of prostate cancer detection and reduce false positives.results:  The model demonstrates promising potential in reducing false positives and improving patient outcomes, with the potential to become a robust and marketable solution for prostate cancer detection in the future.Here’s the text in Simplified Chinese:for: 这个研究报告的目的是开发和验证一种基于人工神经网络（ANNs）的智能数学模型，以提高肾癌早期检测的准确率。methods: 该模型利用ANNs分析各种临床和实验室数据，如PSA和DRE结果，以提高肾癌检测的准确率并减少假阳性结果。results: 该模型在减少假阳性结果和提高病人结果的前提下显示了扎实的潜在价值，未来可能成为肾癌检测的可靠和市场化解决方案。<details>
<summary>Abstract</summary>
Prostate cancer is a prevalent malignancy among men aged 50 and older. Current diagnostic methods primarily rely on blood tests, PSA:Prostate-Specific Antigen levels, and Digital Rectal Examinations (DRE). However, these methods suffer from a significant rate of false positive results. This study focuses on the development and validation of an intelligent mathematical model utilizing Artificial Neural Networks (ANNs) to enhance the early detection of prostate cancer. The primary objective of this research paper is to present a novel mathematical model designed to aid in the early detection of prostate cancer, facilitating prompt intervention by healthcare professionals. The model's implementation demonstrates promising potential in reducing the incidence of false positives, thereby improving patient outcomes. Furthermore, we envision that, with further refinement, extensive testing, and validation, this model can evolve into a robust, marketable solution for prostate cancer detection. The long-term goal is to make this solution readily available for deployment in various screening centers, hospitals, and research institutions, ultimately contributing to more effective cancer screening and patient care.
</details>
<details>
<summary>摘要</summary>
probstate cancer 是男性年龄在50岁及以上的常见肿瘤之一。当前的诊断方法主要基于血液测试和PSA：肾脏特异抗体水平（Digital Rectal Examinations，DRE）。但这些方法具有较高的假阳性率。本研究旨在开发和验证一种智能的数学模型，使用人工神经网络（ANNs），以提高肾脏癌早期检测。本研究的主要目标是提供一种能够帮助检测肾脏癌的新型数学模型，以便医疗专业人员早期发现和治疗。该模型的实施表现了有前途的潜力，可以减少假阳性的发生，从而提高病人的 outcome。此外，我们期望通过进一步的优化、广泛的测试和验证，这种模型可以变得更加坚固，并最终变得可商业化，以便更好地检测和治疗肾脏癌。长期目标是将这种解决方案在各个检查中心、医院和研究机构中广泛应用，以便更有效地检测和治疗癌症，并 ultimately contribute to better patient outcomes.
</details></li>
</ul>
<hr>
<h2 id="Legal-Question-Answering-in-the-Indian-Context-Efficacy-Challenges-and-Potential-of-Modern-AI-Models"><a href="#Legal-Question-Answering-in-the-Indian-Context-Efficacy-Challenges-and-Potential-of-Modern-AI-Models" class="headerlink" title="Legal Question-Answering in the Indian Context: Efficacy, Challenges, and Potential of Modern AI Models"></a>Legal Question-Answering in the Indian Context: Efficacy, Challenges, and Potential of Modern AI Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14735">http://arxiv.org/abs/2309.14735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubham Kumar Nigam, Shubham Kumar Mishra, Ayush Kumar Mishra, Noel Shallum, Arnab Bhattacharya</li>
<li>for: 本文旨在探讨AI在印度法律问答中的应用，尤其是在印度刑事法律领域。</li>
<li>methods: 本文使用了一系列的检索和问答机制，其中包括OpenAI GPT模型。</li>
<li>results: 研究发现现有的AILQA方法在理解自然语言提示并生成精确回答方面具有强大的能力。<details>
<summary>Abstract</summary>
Legal QA platforms bear the promise to metamorphose the manner in which legal experts engage with jurisprudential documents. In this exposition, we embark on a comparative exploration of contemporary AI frameworks, gauging their adeptness in catering to the unique demands of the Indian legal milieu, with a keen emphasis on Indian Legal Question Answering (AILQA). Our discourse zeroes in on an array of retrieval and QA mechanisms, positioning the OpenAI GPT model as a reference point. The findings underscore the proficiency of prevailing AILQA paradigms in decoding natural language prompts and churning out precise responses. The ambit of this study is tethered to the Indian criminal legal landscape, distinguished by its intricate nature and associated logistical constraints. To ensure a holistic evaluation, we juxtapose empirical metrics with insights garnered from seasoned legal practitioners, thereby painting a comprehensive picture of AI's potential and challenges within the realm of Indian legal QA.
</details>
<details>
<summary>摘要</summary>
法律QA平台承诺能够改变法律专家与法律文档之间的交互方式。在这篇论文中，我们进行了对当代AI框架的比较研究，以评估它们在印度法律环境中的适应度，尤其是在印度法律问答（AILQA）领域。我们的讨论涵盖了一系列的检索和问答机制，使用OpenAI GPT模型作为参考点。研究结果表明现有AILQA方法在处理自然语言提示和生成准确回答方面具有强大的能力。本研究的范围围绕着印度刑事法律景观，这个景观具有复杂的特点和相关的设备限制。为了进行全面的评估，我们对实际指标和从经验法律专业人员处获得的信息进行了结合，从而为AI在印度法律QA领域的潜力和挑战提供了全面的图景。
</details></li>
</ul>
<hr>
<h2 id="Effective-Multi-Agent-Deep-Reinforcement-Learning-Control-with-Relative-Entropy-Regularization"><a href="#Effective-Multi-Agent-Deep-Reinforcement-Learning-Control-with-Relative-Entropy-Regularization" class="headerlink" title="Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization"></a>Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14727">http://arxiv.org/abs/2309.14727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AdrienLin1/MACDPP">https://github.com/AdrienLin1/MACDPP</a></li>
<li>paper_authors: Chenyang Miao, Yunduan Cui, Huiyun Li, Xinyu Wu</li>
<li>for: 多任务多代理人学习控制问题（Multi-agent Reinforcement Learning，MARL）</li>
<li>methods: 提出了一种新的多任务多代理人学习控制方法（Multi-Agent Continuous Dynamic Policy Gradient，MACDPP），用于解决多任务多代理人控制场景中的限制性和样本效率问题。</li>
<li>results: MACDPP在多任务多代理人合作和竞争任务中，以及传统控制任务中，如OpenAI Benchmarks和机器臂运动控制等，表现出了明显的优势，包括学习能力和样本效率。<details>
<summary>Abstract</summary>
In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，一种新的多智能体学习（MARL）方法，即多智能体连续动态政策差分（MACDPP），用于解决多智能体控制场景中的局限性和样本效率问题。它通过在中央训练与分布式执行（CTDE）框架中引入相对 entropy 约束，使多智能体的政策更新更加一致。在多智能体合作和竞争任务中，以及传统的控制任务，包括OpenAI benchmarks和机械臂 manipulate任务，MACDPP表现出了明显的学习能力和样本效率优势，与相关的多智能体和广泛实施的信号代理基elines相比。因此，MACDPP扩大了MARL在学习复杂控制场景中的潜在能力。
</details></li>
</ul>
<hr>
<h2 id="PLMM-Personal-Large-Models-on-Mobile-Devices"><a href="#PLMM-Personal-Large-Models-on-Mobile-Devices" class="headerlink" title="PLMM: Personal Large Models on Mobile Devices"></a>PLMM: Personal Large Models on Mobile Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14726">http://arxiv.org/abs/2309.14726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 这篇论文的目的是提出一种基于 Federated Learning的个人化大型语言模型，专门适应地区用户的个人资讯，例如教育背景和兴趣。</li>
<li>methods: 本文使用了三种不同的大型语言模型，分别是个人化模型、专门知识模型和传统模型。个人化模型适应用户的个人资讯，并将用户的输入加密以保护隐私。专门知识模型专注于结合特定领域的知识，例如金融、IT和艺术。传统模型则专注于发现通用知识并升级专门知识模型。</li>
<li>results: 本文发现，个人化大型语言模型可以在广泛的应用领域中提供高品质的结果，例如语言和视觉任务。此外，这些模型还能在实时的情况下执行，并且可以在个人电脑或移动设备上运行。<details>
<summary>Abstract</summary>
Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user experience and produce high quality results. The proposed personal large models can be applied in a wide range of applications such as language and vision tasks.
</details>
<details>
<summary>摘要</summary>
受 Federated Learning 启发，在这篇论文中，我们提议个性化大型模型，从传统大型语言模型中提取出更适应本地用户个人信息，如教育背景和兴趣爱好。我们将大语言模型分为三级：个性化级、专家级和传统级。个性化级模型适应用户个人信息，对用户输入进行加密，保护用户隐私。专家级模型将特定知识，如金融、IT和艺术等融合。传统级模型则专注于普遍知识发现和提升专家模型。在这些分类中，个性化模型直接与用户进行交互，用户的（加密）个人信息被模型所拥有。此外，这些模型还需要具备在个人计算机或移动设备上进行执行，并在实时响应用户需求，生成高质量结果。我们提议的个性化大型模型可以应用于语言和视觉任务等广泛领域。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-delegation-between-human-and-AI-collaborative-agents"><a href="#Optimizing-delegation-between-human-and-AI-collaborative-agents" class="headerlink" title="Optimizing delegation between human and AI collaborative agents"></a>Optimizing delegation between human and AI collaborative agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14718">http://arxiv.org/abs/2309.14718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Fuchs, Andrea Passarella, Marco Conti</li>
<li>for: 本研究旨在帮助人类与自动化代理人组成混合团队，并准确地授权团队成员执行动作。</li>
<li>methods: 本研究使用观察团队表现来学习一个管理模型，不Restricting agents to matching dynamics。</li>
<li>results: 研究结果表明，我们的管理模型在不同 Representation of the environment下可以有效地做出授权决策，并且与替代方法相比，表现出色。<details>
<summary>Abstract</summary>
In the context of humans operating with artificial or autonomous agents in a hybrid team, it is essential to accurately identify when to authorize those team members to perform actions. Given past examples where humans and autonomous systems can either succeed or fail at tasks, we seek to train a delegating manager agent to make delegation decisions with respect to these potential performance deficiencies. Additionally, we cannot always expect the various agents to operate within the same underlying model of the environment. It is possible to encounter cases where the actions and transitions would vary between agents. Therefore, our framework provides a manager model which learns through observations of team performance without restricting agents to matching dynamics. Our results show our manager learns to perform delegation decisions with teams of agents operating under differing representations of the environment, significantly outperforming alternative methods to manage the team.
</details>
<details>
<summary>摘要</summary>
在人类与自动或自适应智能代理人合作的团队中，正确地授权团队成员执行操作是非常重要的。根据过去的例子，人类和自动系统在任务上可以成功或失败。我们希望通过训练一个委托管理者代理人来做委托决策，尊重团队成员的可能性。同时，我们不能一直预期不同代理人在同一个下式环境中操作。可能会出现情况，代理人的行动和转移会不同。因此，我们的框架提供一个管理模型，通过团队表现观察学习，不Restricting代理人遵循环境的同一个模型。我们的结果显示，我们的管理器在不同代理人操作下的环境表现下适应性明显高于其他管理方法。
</details></li>
</ul>
<hr>
<h2 id="From-Asset-Flow-to-Status-Action-and-Intention-Discovery-Early-Malice-Detection-in-Cryptocurrency"><a href="#From-Asset-Flow-to-Status-Action-and-Intention-Discovery-Early-Malice-Detection-in-Cryptocurrency" class="headerlink" title="From Asset Flow to Status, Action and Intention Discovery: Early Malice Detection in Cryptocurrency"></a>From Asset Flow to Status, Action and Intention Discovery: Early Malice Detection in Cryptocurrency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15133">http://arxiv.org/abs/2309.15133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ling Cheng, Feida Zhu, Yong Wang, Ruicheng Liang, Huiwen Liu</li>
<li>For: 这个研究旨在开发一个早期侦测黑客活动的模型，以解决现有的黑客侦测模型具有深度学习无解释性、只能进行过去黑客活动类型的特定预测等问题。* Methods: 本研究使用了决策树基本特征选择和补充（DT-SC）来定义资产转账路径，然后使用了状态&#x2F;行为提议模组（S&#x2F;A-PM）和意图VAE模组来生成状态、行为、意图抽象和隐藏意图抽象。* Results: 实验结果显示，提出的算法在三个真实世界数据集上表现出色，较进行过去的方法更高的侦测速度和解释性。此外，适当的损失函数设计进一步增强预测速度和模型的解释性。<details>
<summary>Abstract</summary>
Cryptocurrency has been subject to illicit activities probably more often than traditional financial assets due to the pseudo-anonymous nature of its transacting entities. An ideal detection model is expected to achieve all three critical properties of (I) early detection, (II) good interpretability, and (III) versatility for various illicit activities. However, existing solutions cannot meet all these requirements, as most of them heavily rely on deep learning without interpretability and are only available for retrospective analysis of a specific illicit type. To tackle all these challenges, we propose Intention-Monitor for early malice detection in Bitcoin (BTC), where the on-chain record data for a certain address are much scarcer than other cryptocurrency platforms. We first define asset transfer paths with the Decision-Tree based feature Selection and Complement (DT-SC) to build different feature sets for different malice types. Then, the Status/Action Proposal Module (S/A-PM) and the Intention-VAE module generate the status, action, intent-snippet, and hidden intent-snippet embedding. With all these modules, our model is highly interpretable and can detect various illegal activities. Moreover, well-designed loss functions further enhance the prediction speed and model's interpretability. Extensive experiments on three real-world datasets demonstrate that our proposed algorithm outperforms the state-of-the-art methods. Furthermore, additional case studies justify our model can not only explain existing illicit patterns but can also find new suspicious characters.
</details>
<details>
<summary>摘要</summary>
криптовалюта часто becomes subject to illegal activities due to its pseudonymous nature, making it difficult to detect illicit activities. To address this challenge, we propose an ideal detection model that should have three critical properties: early detection, good interpretability, and versatility for various illegal activities. However, existing solutions are limited by their reliance on deep learning without interpretability and their inability to detect multiple types of illegal activities.To overcome these challenges, we propose Intention-Monitor, a model that uses decision trees to select features and complement the data, followed by a status/action proposal module and an intention-VAE module to generate embeddings for status, action, intent, and hidden intent. Our model is highly interpretable and can detect various illegal activities, and well-designed loss functions further enhance its prediction speed and interpretability.Extensive experiments on three real-world datasets show that our proposed algorithm outperforms state-of-the-art methods, and additional case studies demonstrate that our model can not only explain existing illicit patterns but can also find new suspicious characters.
</details></li>
</ul>
<hr>
<h2 id="Are-Human-generated-Demonstrations-Necessary-for-In-context-Learning"><a href="#Are-Human-generated-Demonstrations-Necessary-for-In-context-Learning" class="headerlink" title="Are Human-generated Demonstrations Necessary for In-context Learning?"></a>Are Human-generated Demonstrations Necessary for In-context Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14681">http://arxiv.org/abs/2309.14681</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ruili33/sec">https://github.com/ruili33/sec</a></li>
<li>paper_authors: Rui Li, Guoyin Wang, Jiwei Li</li>
<li>for: 是否可以废除人工制作的示例，以便更好地进行 In-context Learning (ICL)？</li>
<li>methods: 提议使用自我反思提示策略 (SEC)，它不需要人工制作的示例，而是让大语言模型自己 generates 示例，基于这些示例进行最终输出生成。</li>
<li>results: 在四个数学逻辑、常识逻辑、多任务语言理解和代码生成测试 benchmarks 中，SEC 表现出色，并且不需要人工制作的示例，与使用手工制作的示例相比，效果相似。这表明，当今的大语言模型在许多任务上具备独立做出决策的能力，可以废除外部训练数据。<details>
<summary>Abstract</summary>
Despite the promising few-shot ability of large language models (LLMs), the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations. In this paper, we raise the fundamental question that whether human-generated demonstrations are necessary for ICL. To answer this question, we propose self-contemplation prompting strategy (SEC), a paradigm free from human-crafted demonstrations. The key point of SEC is that, instead of using hand-crafted examples as demonstrations in ICL, SEC asks LLMs to first create demonstrations on their own, based on which the final output is generated. SEC is a flexible framework and can be adapted to both the vanilla ICL and the chain-of-thought (CoT), but with greater ease: as the manual-generation process of both examples and rationale can be saved. Extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understanding, and code generation benchmarks, show that SEC, which does not require hand-crafted demonstrations, significantly outperforms the zero-shot learning strategy, and achieves comparable results to ICL with hand-crafted demonstrations. This demonstrates that, for many tasks, contemporary LLMs possess a sufficient level of competence to exclusively depend on their own capacity for decision making, removing the need for external training data. Code is available at https://github.com/ruili33/SEC.
</details>
<details>
<summary>摘要</summary>
尽管大语言模型（LLM）具有批处少量能力，标准的尽Context学习（ICL） paradigm 受到选择性示范和生成示范的缺点。在这篇论文中，我们提出了基本问题：人类生成的示范是ICL必需的？为回答这个问题，我们提议了自我思考提示策略（SEC），一种不需要人类制定示范的 paradigm。SEC的关键点是，而不是使用手工制定的示范，LLMs可以通过自己生成示范来生成最终输出。SEC是一个灵活的框架，可以适应标准ICL和链条思考（CoT），但更容易：手动生成示范和理由的手动处理可以快速地保存。我们在数学逻辑、通用常识逻辑、多任务语言理解和代码生成benchmark中进行了广泛的实验，结果显示，不需要手动生成示范的SEC，在零shot学习策略下表现出色，与手动生成示范的ICL相当。这表明，许多任务上，当代LLMs具有独立决策的能力，可以完全依靠自己的能力，无需外部培训数据。代码可以在https://github.com/ruili33/SEC中找到。
</details></li>
</ul>
<hr>
<h2 id="XGV-BERT-Leveraging-Contextualized-Language-Model-and-Graph-Neural-Network-for-Efficient-Software-Vulnerability-Detection"><a href="#XGV-BERT-Leveraging-Contextualized-Language-Model-and-Graph-Neural-Network-for-Efficient-Software-Vulnerability-Detection" class="headerlink" title="XGV-BERT: Leveraging Contextualized Language Model and Graph Neural Network for Efficient Software Vulnerability Detection"></a>XGV-BERT: Leveraging Contextualized Language Model and Graph Neural Network for Efficient Software Vulnerability Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14677">http://arxiv.org/abs/2309.14677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vu Le Anh Quan, Chau Thuan Phat, Kiet Van Nguyen, Phan The Duy, Van-Hau Pham</li>
<li>for: 本研究旨在提出一种基于深度学习的软件漏洞检测方法，以提高软件安全性。</li>
<li>methods: 本方法基于预训练的CodeBERT模型和图神经网络（GCN），结合了这两种模块，以便更好地捕捉代码特征的非顺序性和上下文关系。</li>
<li>results: 研究结果表明，XGV-BERT方法比现有的两种方法（VulDeePecker和SySeVR）更高的检测精度，特别是在VulDeePecker数据集上，XGV-BERT方法达到了97.5%的F1分数，而VulDeePecker方法只达到了78.3%的F1分数。在SySeVR数据集上，XGV-BERT方法也达到了95.5%的F1分数，超过了SySeVR方法的83.5%的F1分数。<details>
<summary>Abstract</summary>
With the advancement of deep learning (DL) in various fields, there are many attempts to reveal software vulnerabilities by data-driven approach. Nonetheless, such existing works lack the effective representation that can retain the non-sequential semantic characteristics and contextual relationship of source code attributes. Hence, in this work, we propose XGV-BERT, a framework that combines the pre-trained CodeBERT model and Graph Neural Network (GCN) to detect software vulnerabilities. By jointly training the CodeBERT and GCN modules within XGV-BERT, the proposed model leverages the advantages of large-scale pre-training, harnessing vast raw data, and transfer learning by learning representations for training data through graph convolution. The research results demonstrate that the XGV-BERT method significantly improves vulnerability detection accuracy compared to two existing methods such as VulDeePecker and SySeVR. For the VulDeePecker dataset, XGV-BERT achieves an impressive F1-score of 97.5%, significantly outperforming VulDeePecker, which achieved an F1-score of 78.3%. Again, with the SySeVR dataset, XGV-BERT achieves an F1-score of 95.5%, surpassing the results of SySeVR with an F1-score of 83.5%.
</details>
<details>
<summary>摘要</summary>
随着深度学习（DL）在不同领域的应用，有许多尝试通过数据驱动方法揭示软件漏洞。然而，现有的方法缺乏有效的表示方式，能够保留代码特征的非序列性和Contextual关系。因此，在这项工作中，我们提出了XGV-BERT框架，它将CodeBERT模型和图神经网络（GCN）结合以检测软件漏洞。通过在XGV-BERT中同时训练CodeBERT和GCN模块，我们的方法可以利用大规模预训练、继承大量原始数据和转移学习，以学习表示训练数据的图 convolution。研究结果表明，XGV-BERT方法在VulDeePecker和SySeVR dataset上显著提高了漏洞检测精度，比如VulDeePecker和SySeVR方法的F1分数分别为78.3%和83.5%，而XGV-BERT方法在VulDeePecker dataset上达到了97.5%的F1分数，在SySeVR dataset上达到了95.5%的F1分数。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Herpangina-Data-to-Enhance-Hospital-level-Prediction-of-Hand-Foot-and-Mouth-Disease-Admissions-Using-UPTST"><a href="#Leveraging-Herpangina-Data-to-Enhance-Hospital-level-Prediction-of-Hand-Foot-and-Mouth-Disease-Admissions-Using-UPTST" class="headerlink" title="Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST"></a>Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14674">http://arxiv.org/abs/2309.14674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Levi-Ackman/UPTST">https://github.com/Levi-Ackman/UPTST</a></li>
<li>paper_authors: Guoqi Yu, Hailun Yao, Huan Zheng, Ximing Xu</li>
<li>for: 预测儿童手足口炎日患者入院数，以便医院准备可能的爆发和避免医院内传播。</li>
<li>methods: 提出了一种基于 transformer 的 U-net 模型，使用负采样策略和联合预测策略，并具有表达学学习的特性。</li>
<li>results: 模型在医院级别的长臂和短臂预测精度方面具有显著优势，并且在探索性扩展实验中表现出了更广泛的应用前景。<details>
<summary>Abstract</summary>
Outbreaks of hand-foot-and-mouth disease(HFMD) have been associated with significant morbidity and, in severe cases, mortality. Accurate forecasting of daily admissions of pediatric HFMD patients is therefore crucial for aiding the hospital in preparing for potential outbreaks and mitigating nosocomial transmissions. To address this pressing need, we propose a novel transformer-based model with a U-net shape, utilizing the patching strategy and the joint prediction strategy that capitalizes on insights from herpangina, a disease closely correlated with HFMD. This model also integrates representation learning by introducing reconstruction loss as an auxiliary loss. The results show that our U-net Patching Time Series Transformer (UPTST) model outperforms existing approaches in both long- and short-arm prediction accuracy of HFMD at hospital-level. Furthermore, the exploratory extension experiments show that the model's capabilities extend beyond prediction of infectious disease, suggesting broader applicability in various domains.
</details>
<details>
<summary>摘要</summary>
OUTBREAKS OF HAND-FOOT-AND-MOUTH DISEASE (HFMD) HAVE BEEN ASSOCIATED WITH SIGNIFICANT MORBIDITY AND, IN SEVERE CASES, MORTALITY. ACCURATE FORECASTING OF DAILY ADMISSIONS OF PEDIATRIC HFMD PATIENTS IS THEREFORE CRUCIAL FOR AIDING THE HOSPITAL IN PREPARING FOR POTENTIAL OUTBREAKS AND MITIGATING NOSOCOMIAL TRANSMISSIONS. TO ADDRESS THIS PRESSING NEED, WE PROPOSE A NOVEL TRANSFORMER-BASED MODEL WITH A U-NET SHAPE, UTILIZING THE PATCHING STRATEGY AND THE JOINT PREDICTION STRATEGY THAT CAPITALIZES ON INSIGHTS FROM HERPANGINA, A DISEASE CLOSELY CORRELATED WITH HFMD. THIS MODEL ALSO INTEGRATES REPRESENTATION LEARNING BY INTRODUCING RECONSTRUCTION LOSS AS AN AUXILIARY LOSS. THE RESULTS SHOW THAT OUR U-NET PATCHING TIME SERIES TRANSFORMER (UPTST) MODEL OUTPERFORMS EXISTING APPROACHES IN BOTH LONG- AND SHORT-ARM PREDICTION ACCURACY OF HFMD AT HOSPITAL-LEVEL. FURTHERMORE, THE EXPLORATORY EXTENSION EXPERIMENTS SHOW THAT THE MODEL'S CAPABILITIES EXTEND BEYOND PREDICTION OF INFECTIOUS DISEASE, SUGGESTING BROADER APPLICABILITY IN VARIOUS DOMEAINS.
</details></li>
</ul>
<hr>
<h2 id="ALEX-Towards-Effective-Graph-Transfer-Learning-with-Noisy-Labels"><a href="#ALEX-Towards-Effective-Graph-Transfer-Learning-with-Noisy-Labels" class="headerlink" title="ALEX: Towards Effective Graph Transfer Learning with Noisy Labels"></a>ALEX: Towards Effective Graph Transfer Learning with Noisy Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14673">http://arxiv.org/abs/2309.14673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyang Yuan, Xiao Luo, Yifang Qin, Zhengyang Mao, Wei Ju, Ming Zhang</li>
<li>for: 本研究旨在解决图像降维中存在杂乱标签的问题，通过将知识从含杂标签源图传播到无标记目标图。</li>
<li>methods: 本研究提出了一种新的技术 Balance Alignment and Information-aware Examination (ALEX)，包括对矩阵进行特征分解，通过图像对比学习提供稳定的节点表示，并通过估算假设分布来建立均衡的子图分布。</li>
<li>results: 对多个基准数据集进行了广泛的实验，证明了 ALEX 在不同设定下具有突出的优势。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have garnered considerable interest due to their exceptional performance in a wide range of graph machine learning tasks. Nevertheless, the majority of GNN-based approaches have been examined using well-annotated benchmark datasets, leading to suboptimal performance in real-world graph learning scenarios. To bridge this gap, the present paper investigates the problem of graph transfer learning in the presence of label noise, which transfers knowledge from a noisy source graph to an unlabeled target graph. We introduce a novel technique termed Balance Alignment and Information-aware Examination (ALEX) to address this challenge. ALEX first employs singular value decomposition to generate different views with crucial structural semantics, which help provide robust node representations using graph contrastive learning. To mitigate both label shift and domain shift, we estimate a prior distribution to build subgraphs with balanced label distributions. Building on this foundation, an adversarial domain discriminator is incorporated for the implicit domain alignment of complex multi-modal distributions. Furthermore, we project node representations into a different space, optimizing the mutual information between the projected features and labels. Subsequently, the inconsistency of similarity structures is evaluated to identify noisy samples with potential overfitting. Comprehensive experiments on various benchmark datasets substantiate the outstanding superiority of the proposed ALEX in different settings.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) have received extensive attention due to their remarkable performance in a wide range of graph machine learning tasks. However, most GNN-based approaches have been evaluated using well-annotated benchmark datasets, leading to suboptimal performance in real-world graph learning scenarios. To bridge this gap, the present paper investigates the problem of graph transfer learning in the presence of label noise, which transfers knowledge from a noisy source graph to an unlabeled target graph. We propose a novel technique termed Balance Alignment and Information-aware Examination (ALEX) to address this challenge.ALEX first employs singular value decomposition to generate different views with crucial structural semantics, which help provide robust node representations using graph contrastive learning. To mitigate both label shift and domain shift, we estimate a prior distribution to build subgraphs with balanced label distributions. Building on this foundation, an adversarial domain discriminator is incorporated for the implicit domain alignment of complex multi-modal distributions. Furthermore, we project node representations into a different space, optimizing the mutual information between the projected features and labels. Subsequently, the inconsistency of similarity structures is evaluated to identify noisy samples with potential overfitting.Comprehensive experiments on various benchmark datasets substantiate the outstanding superiority of the proposed ALEX in different settings.
</details></li>
</ul>
<hr>
<h2 id="Learning-Emergent-Behavior-in-Robot-Swarms-with-NEAT"><a href="#Learning-Emergent-Behavior-in-Robot-Swarms-with-NEAT" class="headerlink" title="Learning Emergent Behavior in Robot Swarms with NEAT"></a>Learning Emergent Behavior in Robot Swarms with NEAT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14663">http://arxiv.org/abs/2309.14663</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pranavraj575/swarm_coppeliasim">https://github.com/pranavraj575/swarm_coppeliasim</a></li>
<li>paper_authors: Pranav Rajbhandari, Donald Sofge</li>
<li>for: 本研究旨在解决 robot swarm 中个体代理的简单本地行为如何产生复杂的群体行为的问题。</li>
<li>methods: 我们使用进化算法来训练分布式 роботизирован群体算法，以产生愿望的群体行为。我们受到生物进化中的群体行为的启发，使用进化算法来训练一个 ‘人口’ 的个体行为来近似愿望的群体行为。</li>
<li>results: 我们在 Georgia Tech Miniature Autonomous Blimps (GT-MABs) 飞行 платформы上进行了 simulations，并在 Anki Vector 机器人上进行了测试。我们在不同的任务中评估了我们的算法，包括 Area Coverage 任务、Surround Target 任务和 Wall Climb 任务。我们比较了我们的算法生成的行为和 ‘设计政策’ 的行为，并发现我们的算法可以更好地实现愿望的群体行为。<details>
<summary>Abstract</summary>
When researching robot swarms, many studies observe complex group behavior emerging from the individual agents' simple local actions. However, the task of learning an individual policy to produce a desired emergent behavior remains a challenging and largely unsolved problem. We present a method of training distributed robotic swarm algorithms to produce emergent behavior. Inspired by the biological evolution of emergent behavior in animals, we use an evolutionary algorithm to train a 'population' of individual behaviors to approximate a desired group behavior. We perform experiments using simulations of the Georgia Tech Miniature Autonomous Blimps (GT-MABs) aerial robotics platforms conducted in the CoppeliaSim simulator. Additionally, we test on simulations of Anki Vector robots to display our algorithm's effectiveness on various modes of actuation. We evaluate our algorithm on various tasks where a somewhat complex group behavior is required for success. These tasks include an Area Coverage task, a Surround Target task, and a Wall Climb task. We compare behaviors evolved using our algorithm against 'designed policies', which we create in order to exhibit the emergent behaviors we desire.
</details>
<details>
<summary>摘要</summary>
We conduct experiments using simulations of the Georgia Tech Miniature Autonomous Blimps (GT-MABs) aerial robotics platforms in the CoppeliaSim simulator, and also test our algorithm on simulations of Anki Vector robots to demonstrate its effectiveness on various modes of actuation. We evaluate our algorithm on tasks where a somewhat complex group behavior is required for success, such as Area Coverage, Surround Target, and Wall Climb. We compare the behaviors evolved using our algorithm with 'designed policies' that we create to exhibit the desired emergent behaviors.
</details></li>
</ul>
<hr>
<h2 id="CoFiI2P-Coarse-to-Fine-Correspondences-for-Image-to-Point-Cloud-Registration"><a href="#CoFiI2P-Coarse-to-Fine-Correspondences-for-Image-to-Point-Cloud-Registration" class="headerlink" title="CoFiI2P: Coarse-to-Fine Correspondences for Image-to-Point Cloud Registration"></a>CoFiI2P: Coarse-to-Fine Correspondences for Image-to-Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14660">http://arxiv.org/abs/2309.14660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuhao Kang, Youqi Liao, Jianping Li, Fuxun Liang, Yuhao Li, Fangning Li, Zhen Dong, Bisheng Yang</li>
<li>for: 这篇论文主要针对图像与点云数据融合的问题进行了研究，具体来说是实现图像到点云（I2P）匹配。</li>
<li>methods: 该论文提出了一种新的I2P匹配网络，即CoFiI2P，它通过 Hierarchical feature extraction 和粗细匹配模块来实现全球优化的匹配。</li>
<li>results: 根据实验结果，CoFiI2P在KITTI数据集上取得了优秀的结果，相对偏动 Error 为1.14度，相对偏移 Error 为0.29米，与当前最佳方法相比提高了84%和89%。<details>
<summary>Abstract</summary>
Image-to-point cloud (I2P) registration is a fundamental task in the field of autonomous vehicles and transportation systems for cross-modality data fusion and localization. Existing I2P registration methods estimate correspondences at the point/pixel level, often overlooking global alignment. However, I2P matching can easily converge to a local optimum when performed without high-level guidance from global constraints. To address this issue, this paper introduces CoFiI2P, a novel I2P registration network that extracts correspondences in a coarse-to-fine manner to achieve the globally optimal solution. First, the image and point cloud data are processed through a Siamese encoder-decoder network for hierarchical feature extraction. Second, a coarse-to-fine matching module is designed to leverage these features and establish robust feature correspondences. Specifically, In the coarse matching phase, a novel I2P transformer module is employed to capture both homogeneous and heterogeneous global information from the image and point cloud data. This enables the estimation of coarse super-point/super-pixel matching pairs with discriminative descriptors. In the fine matching module, point/pixel pairs are established with the guidance of super-point/super-pixel correspondences. Finally, based on matching pairs, the transform matrix is estimated with the EPnP-RANSAC algorithm. Extensive experiments conducted on the KITTI dataset demonstrate that CoFiI2P achieves impressive results, with a relative rotation error (RRE) of 1.14 degrees and a relative translation error (RTE) of 0.29 meters. These results represent a significant improvement of 84\% in RRE and 89\% in RTE compared to the current state-of-the-art (SOTA) method. Qualitative results are available at https://youtu.be/ovbedasXuZE. The source code will be publicly released at https://github.com/kang-1-2-3/CoFiI2P.
</details>
<details>
<summary>摘要</summary>
Image-to-point cloud（I2P）匹配是汽车自主领域和交通系统中的基本任务，用于跨模态数据融合和地理位置。现有I2P匹配方法通常在点/像素级别进行匹配，经常忽略全局约束。然而，I2P匹配容易 converges to 局部最优解而不是全局最优解。为解决这个问题，这篇文章提出了CoFiI2P，一种新的I2P匹配网络，该网络可以在层次结构下提取特征，以实现全球最优解。首先，图像和点云数据经过一个SIAMESE编码器-解码器网络进行特征提取。其次，我们设计了一个coarse-to-fine匹配模块，以利用这些特征并建立稳定的特征对应。Specifically，在粗略匹配阶段，我们采用了一个新的I2P变换模块，以捕捉图像和点云数据中的同质和不同质全局信息。这使得可以估计粗略超点/超像素匹配对，并生成特征描述器。在细密匹配阶段，点/像素对被指导super-point/super-pixel对的建立。最后，基于匹配对，我们使用EPnP-RANSAC算法估计变换矩阵。广泛在KITTI数据集上进行了实验，CoFiI2P实现了出色的结果，其相对旋转误差（RRE）为1.14度，相对平移误差（RTE）为0.29米。这些结果与当前SOTA方法相比，提高了84%的RRE和89%的RTE。详细结果可以在https://youtu.be/ovbedasXuZE中查看。代码将在https://github.com/kang-1-2-3/CoFiI2P上公开发布。
</details></li>
</ul>
<hr>
<h2 id="Divide-and-Conquer-in-Video-Anomaly-Detection-A-Comprehensive-Review-and-New-Approach"><a href="#Divide-and-Conquer-in-Video-Anomaly-Detection-A-Comprehensive-Review-and-New-Approach" class="headerlink" title="Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach"></a>Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14622">http://arxiv.org/abs/2309.14622</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XiaoJian923/Divide-and-Conquer">https://github.com/XiaoJian923/Divide-and-Conquer</a></li>
<li>paper_authors: Jian Xiao, Tianyuan Liu, Genlin Ji</li>
<li>for: 本研究旨在系统性地review了最新的视频异常检测方法，以提高使用”divide and conquer”策略在视频异常检测中的应用。</li>
<li>methods: 本研究使用了六个维度来review最新的视频异常检测方法，包括人工骨架与视频数据分析技术的综合应用。</li>
<li>results: 根据本研究所获得的发现，提出了一种新的方法， integrate human skeletal frameworks with video data analysis techniques，可以在ShanghaiTech dataset上达到最高的性能，超过所有已有的先进方法。<details>
<summary>Abstract</summary>
Video anomaly detection is a complex task, and the principle of "divide and conquer" is often regarded as an effective approach to tackling intricate issues. It's noteworthy that recent methods in video anomaly detection have revealed the application of the divide and conquer philosophy (albeit with distinct perspectives from traditional usage), yielding impressive outcomes. This paper systematically reviews these literatures from six dimensions, aiming to enhance the use of the divide and conquer strategy in video anomaly detection. Furthermore, based on the insights gained from this review, a novel approach is presented, which integrates human skeletal frameworks with video data analysis techniques. This method achieves state-of-the-art performance on the ShanghaiTech dataset, surpassing all existing advanced methods.
</details>
<details>
<summary>摘要</summary>
视频异常检测是一项复杂的任务，“分而治之”的原则经常被视为解决复杂问题的有效方法。值得注意的是，近年来的视频异常检测方法中，已经应用了分而治之的哲学（尽管从传统使用角度有所不同），并且得到了出色的结果。本文系统地回顾这些文献从六个维度，旨在提高视频异常检测中使用分而治之策略的使用。此外，基于本文的检查，我们提出了一种新的方法，即将人体骨架与视频数据分析技术结合起来，该方法在上海理工大学数据集上达到了当前最佳性能，超过了所有先进方法。
</details></li>
</ul>
<hr>
<h2 id="Towards-A-Unified-Utilitarian-Ethics-Framework-for-Healthcare-Artificial-Intelligence"><a href="#Towards-A-Unified-Utilitarian-Ethics-Framework-for-Healthcare-Artificial-Intelligence" class="headerlink" title="Towards A Unified Utilitarian Ethics Framework for Healthcare Artificial Intelligence"></a>Towards A Unified Utilitarian Ethics Framework for Healthcare Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14617">http://arxiv.org/abs/2309.14617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Forhan Bin Emdad, Shuyuan Mary Ho, Benhur Ravuri, Shezin Hussain<br>for: This study aims to identify the major ethical principles influencing the utility performance of AI in healthcare settings and to propose a new utilitarian ethics-based theoretical framework for designing ethical AI.methods: The study uses a thematic analysis of secondary survey data from 36 AI experts to identify the top ethical principles of AI design, and a meta-analysis to categorize the ethical issues in AI design.results: The study found that justice, privacy, bias, lack of regulations, risks, and interpretability are the most important ethical principles to consider for ethical AI in healthcare settings. The proposed theoretical framework is based on utilitarian ethics and aims to resolve the ethical issues identified by the meta-analysis and domain experts.<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) aims to elevate healthcare to a pinnacle by aiding clinical decision support. Overcoming the challenges related to the design of ethical AI will enable clinicians, physicians, healthcare professionals, and other stakeholders to use and trust AI in healthcare settings. This study attempts to identify the major ethical principles influencing the utility performance of AI at different technological levels such as data access, algorithms, and systems through a thematic analysis. We observed that justice, privacy, bias, lack of regulations, risks, and interpretability are the most important principles to consider for ethical AI. This data-driven study has analyzed secondary survey data from the Pew Research Center (2020) of 36 AI experts to categorize the top ethical principles of AI design. To resolve the ethical issues identified by the meta-analysis and domain experts, we propose a new utilitarian ethics-based theoretical framework for designing ethical AI for the healthcare domain.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）目标是提升医疗健康到最高点，通过支持临床决策。通过解决 relate to the design of ethical AI 的挑战，可以使临床医生、physicians、医疗专业人员和其他关注者可以使用和信任 AI 在医疗设置中。本研究尝试通过主题分析来识别不同技术水平（如数据访问、算法和系统）中 ethical principles 的影响。我们发现，正义、隐私、偏见、缺乏法规、风险和可解释性是 ethical AI 中最重要的原则。本数据驱动的研究分析了 Pew Research Center （2020）36名 AI 专家的次要调查数据，以分类 AI 设计中的最重要道德原则。为解决由 meta-analysis 和领域专家所提出的道德问题，我们提出了一种基于利用主义道德学的新理论框架，用于设计医疗领域的 ethical AI。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Graph-Deep-Learning-Reveals-Emergent-Flood-Risk-Profile-of-Urban-Areas"><a href="#Unsupervised-Graph-Deep-Learning-Reveals-Emergent-Flood-Risk-Profile-of-Urban-Areas" class="headerlink" title="Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas"></a>Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14610">http://arxiv.org/abs/2309.14610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Yin, Ali Mostafavi</li>
<li>for: 本研究目的是为了开发一种可以捕捉城市洪水风险的复杂和非线性相互作用的城市洪水风险评估模型。</li>
<li>methods: 该模型基于一种新的无监督图深度学习模型（称为 FloodRisk-Net），可以捕捉城市区域之间的空间依赖关系和洪水风险的复杂和非线性相互作用。</li>
<li>results: 使用美国多个都会统计区（MSA）的数据，该模型可以为每个都会区分类出六个不同的洪水风险水平，并且可以对每个水平中的区域进行特征分析，从而识别出每个都会区的三种极性类型。研究发现洪水风险在每个都会区内存在层次结构，核心城市占洪水风险的主要部分。<details>
<summary>Abstract</summary>
Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into six distinct city-specific levels. The model is interpretable and enables feature analysis of areas within each flood-risk level, allowing for the identification of the three archetypes shaping the highest flood risk within each MSA. Flood risk is found to be spatially distributed in a hierarchical structure within each MSA, where the core city disproportionately bears the highest flood risk. Multiple cities are found to have high overall flood-risk levels and low spatial inequality, indicating limited options for balancing urban development and flood-risk reduction. Relevant flood-risk reduction strategies are discussed considering ways that the highest flood risk and uneven spatial distribution of flood risk are formed.
</details>
<details>
<summary>摘要</summary>
城市洪水风险由多个因素相互作用而生成，包括洪水威胁、洪水暴露、社会和物理敏感性等多个方面。然而，现有的城市洪水风险评估方法主要基于洪水平原地图，强调一些特定的特征，主要是洪水威胁和暴露特征，而不考虑特征之间的依赖关系或城市区域之间的复杂关系。为了解决这一漏洞，本研究提出了一种基于深度学习模型（称为洪水风险网络）的城市洪水风险评估模型。洪水风险网络能够捕捉城市区域之间的空间依赖关系以及洪水威胁和城市特征之间的复杂非线性互动。使用美国多个都会区统计数据，模型将城市洪水风险分为六个不同的城市特定水平。模型可解释性强，允许对每个城市区域进行特征分析，并将每个都会区内的三种架构类型划分为最高洪水风险。洪水风险发现在每个都会区中具有层次结构，核心城市占据最高洪水风险。许多城市具有高总洪水风险水平和低空间不平等，表明城市发展和洪水风险减少之间有限的选择空间。研究提出了适应城市发展和洪水风险减少的措施，并考虑了洪水风险最高和空间分布不均的形成原因。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Post-training-Quantization-with-FP8-Formats"><a href="#Efficient-Post-training-Quantization-with-FP8-Formats" class="headerlink" title="Efficient Post-training Quantization with FP8 Formats"></a>Efficient Post-training Quantization with FP8 Formats</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14592">http://arxiv.org/abs/2309.14592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intel/neural-compressor">https://github.com/intel/neural-compressor</a></li>
<li>paper_authors: Haihao Shen, Naveen Mellempudi, Xin He, Qun Gao, Chang Wang, Mengni Wang</li>
<li>for: The paper is written to study the advantages of FP8 data formats for post-training quantization of deep learning models, and to develop a quantization workflow that generalizes across different network architectures.</li>
<li>methods: The paper examines three different FP8 representations (E5M2, E4M3, and E3M4) and compares their effects on model accuracy, and also uses Intel Neural Compressor for quantization.</li>
<li>results: The paper finds that FP8 formats outperform INT8 in multiple aspects, including workload coverage, model accuracy, and suitability for a broader range of operations. Additionally, the paper finds that E4M3 is better suited for NLP models, whereas E3M4 performs marginally better than E4M3 on computer vision tasks.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了研究FP8数据格式在深度学习模型的后期量化中的优势，并开发一个可以普适应用于不同网络架构的量化工作流。</li>
<li>methods: 论文通过对三种FP8表示（E5M2、E4M3和E3M4）进行比较，研究这些表示对模型准确性的影响，并使用Intel Neural Compressor进行量化。</li>
<li>results: 论文发现FP8格式在多种方面比INT8高效，包括工作负载覆盖率（92.64% vs. 65.87%）、模型准确性和更广泛的操作范围。此外，论文还发现E4M3适合语言模型，而E3M4在计算机视觉任务上表现marginally更好。<details>
<summary>Abstract</summary>
Recent advances in deep learning methods such as LLMs and Diffusion models have created a need for improved quantization methods that can meet the computational demands of these modern architectures while maintaining accuracy. Towards this goal, we study the advantages of FP8 data formats for post-training quantization across 75 unique network architectures covering a wide range of tasks, including machine translation, language modeling, text generation, image classification, generation, and segmentation. We examine three different FP8 representations (E5M2, E4M3, and E3M4) to study the effects of varying degrees of trade-off between dynamic range and precision on model accuracy. Based on our extensive study, we developed a quantization workflow that generalizes across different network architectures. Our empirical results show that FP8 formats outperform INT8 in multiple aspects, including workload coverage (92.64% vs. 65.87%), model accuracy and suitability for a broader range of operations. Furthermore, our findings suggest that E4M3 is better suited for NLP models, whereas E3M4 performs marginally better than E4M3 on computer vision tasks. The code is publicly available on Intel Neural Compressor: https://github.com/intel/neural-compressor.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Joint-Communication-and-Computation-Framework-for-Goal-Oriented-Semantic-Communication-with-Distortion-Rate-Resilience"><a href="#Joint-Communication-and-Computation-Framework-for-Goal-Oriented-Semantic-Communication-with-Distortion-Rate-Resilience" class="headerlink" title="Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience"></a>Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14587">http://arxiv.org/abs/2309.14587</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skyd-semantic/drgo-semcom">https://github.com/skyd-semantic/drgo-semcom</a></li>
<li>paper_authors: Minh-Duong Nguyen, Quang-Vinh Do, Zhaohui Yang, Quoc-Viet Pham, Won-Joo Hwang</li>
<li>for: 本研究旨在提高goal-oriented semantic communication系统的准确性。</li>
<li>methods: 本研究使用 rate-distortion theory 分析语音和semantic压缩induced的扰动，以估计人工智能任务的实际性能。</li>
<li>results: 实验结果表明，提出的方法可以保持人工智能任务的准确性，同时遵循网络限制。这成为goal-oriented semantic communication领域的一个有价值贡献。此外，本研究也提出了数据驱动的方法在优化智能系统性能方面的积极作用。<details>
<summary>Abstract</summary>
Recent research efforts on semantic communication have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of artificial intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate-distortion theory to analyze distortions induced by communication and semantic compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented semantic communication problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and experiments that demonstrate its effectiveness. The experimental results indicate that our proposed method enables accurate AI task performance while adhering to network constraints, establishing it as a valuable contribution to the field of signal processing. Furthermore, this work advances research in goal-oriented semantic communication and highlights the significance of data-driven approaches in optimizing the performance of intelligent systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Speech-Audio-Synthesis-from-Tagged-MRI-and-Non-Negative-Matrix-Factorization-via-Plastic-Transformer"><a href="#Speech-Audio-Synthesis-from-Tagged-MRI-and-Non-Negative-Matrix-Factorization-via-Plastic-Transformer" class="headerlink" title="Speech Audio Synthesis from Tagged MRI and Non-Negative Matrix Factorization via Plastic Transformer"></a>Speech Audio Synthesis from Tagged MRI and Non-Negative Matrix Factorization via Plastic Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14586">http://arxiv.org/abs/2309.14586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaofeng Liu, Fangxu Xing, Maureen Stone, Jiachen Zhuo, Sidney Fels, Jerry L. Prince, Georges El Fakhri, Jonghye Woo<br>for:* 这个论文旨在研究语音生成的方法，具体来说是将weighting map翻译成对应的声音波形。methods:* 该论文使用了非负矩阵分解方法来估算函数单元的运动特征，并使用了深度学习框架来翻译weighting map到对应的声音波形。results:* 该论文的实验结果表明，使用该方法可以Synthesize speech audio waveforms from weighting maps，并且超过了传统的 convolution 和 transformer 模型。<details>
<summary>Abstract</summary>
The tongue's intricate 3D structure, comprising localized functional units, plays a crucial role in the production of speech. When measured using tagged MRI, these functional units exhibit cohesive displacements and derived quantities that facilitate the complex process of speech production. Non-negative matrix factorization-based approaches have been shown to estimate the functional units through motion features, yielding a set of building blocks and a corresponding weighting map. Investigating the link between weighting maps and speech acoustics can offer significant insights into the intricate process of speech production. To this end, in this work, we utilize two-dimensional spectrograms as a proxy representation, and develop an end-to-end deep learning framework for translating weighting maps to their corresponding audio waveforms. Our proposed plastic light transformer (PLT) framework is based on directional product relative position bias and single-level spatial pyramid pooling, thus enabling flexible processing of weighting maps with variable size to fixed-size spectrograms, without input information loss or dimension expansion. Additionally, our PLT framework efficiently models the global correlation of wide matrix input. To improve the realism of our generated spectrograms with relatively limited training samples, we apply pair-wise utterance consistency with Maximum Mean Discrepancy constraint and adversarial training. Experimental results on a dataset of 29 subjects speaking two utterances demonstrated that our framework is able to synthesize speech audio waveforms from weighting maps, outperforming conventional convolution and transformer models.
</details>
<details>
<summary>摘要</summary>
tongue's intricate 3D structure, comprising localized functional units, plays a crucial role in the production of speech. When measured using tagged MRI, these functional units exhibit cohesive displacements and derived quantities that facilitate the complex process of speech production. Non-negative matrix factorization-based approaches have been shown to estimate the functional units through motion features, yielding a set of building blocks and a corresponding weighting map. Investigating the link between weighting maps and speech acoustics can offer significant insights into the intricate process of speech production. To this end, in this work, we utilize two-dimensional spectrograms as a proxy representation, and develop an end-to-end deep learning framework for translating weighting maps to their corresponding audio waveforms. Our proposed plastic light transformer (PLT) framework is based on directional product relative position bias and single-level spatial pyramid pooling, thus enabling flexible processing of weighting maps with variable size to fixed-size spectrograms, without input information loss or dimension expansion. Additionally, our PLT framework efficiently models the global correlation of wide matrix input. To improve the realism of our generated spectrograms with relatively limited training samples, we apply pair-wise utterance consistency with Maximum Mean Discrepancy constraint and adversarial training. Experimental results on a dataset of 29 subjects speaking two utterances demonstrated that our framework is able to synthesize speech audio waveforms from weighting maps, outperforming conventional convolution and transformer models.Here's the text with some notes on the translation:1. "tongue's intricate 3D structure" is translated as "舌头的精确三维结构" (shí yì zhèng qié sān wéi jié gòng)2. "comprising localized functional units" is translated as "包括本地功能单位" (bā jīn běn dì gōng chéng dān yì)3. "plays a crucial role in the production of speech" is translated as "对话调制中发挥重要的作用" (duì huì tiáng zhèng zhōng yì de zuò yì)4. "Non-negative matrix factorization-based approaches" is translated as "基于非负矩阵分解的方法" (jī yú fēi shū jí zhèng fāng yì)5. "yielding a set of building blocks and a corresponding weighting map" is translated as "生成一个集合和对应的权重图" (shēng jìn yī gè jí hù yì de quán zhòng tú)6. "Investigating the link between weighting maps and speech acoustics" is translated as "研究权重图和话语音响之间的关联" (yán jí quán zhòng tú yǔ huì yǔ yīn jiān zhì)7. "two-dimensional spectrograms as a proxy representation" is translated as "作为代表的二维спектロграм" (zuò weǐ de dì yì xiàng yì zhèng)8. "and develop an end-to-end deep learning framework for translating weighting maps to their corresponding audio waveforms" is translated as "并开发一套从权重图到对应的音频波形的深度学习框架" (qǐng dào yī yī jī zhèng xué xí guī fám)9. "Our proposed plastic light transformer (PLT) framework" is translated as "我们提出的塑料光Transformer（PLT）框架" (wǒ men tím chuī de zhāng liào guāng tīng zhèng jì)10. "efficiently models the global correlation of wide matrix input" is translated as "能够有效地模型宽度矩阵输入的全球相互关系" (néng kě yǐ jì dì módeli xiàng dào jí zhèng zhì yì)11. "To improve the realism of our generated spectrograms with relatively limited training samples" is translated as "以增强我们生成的спектロграм中的实际感受，使用有限的训练样本" (yǐ jìn cháng wèi de xiàng yì zhèng zhì yì, shǐ yòng yǒu xiàng de xiàng yì zhèng zhì)12. "we apply pair-wise utterance consistency with Maximum Mean Discrepancy constraint and adversarial training" is translated as "我们运用对应的说话遗传性和最大差异约束，以及反对攻击训练" (wǒ men yù yòng duì bìng de jiàn chuī zhèng zhì yì, yǐ jìn cháng wèi de zhèng zhì yì)Note that the translation is not word-for-word, but rather a more natural and idiomatic translation that captures the meaning and nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="CWCL-Cross-Modal-Transfer-with-Continuously-Weighted-Contrastive-Loss"><a href="#CWCL-Cross-Modal-Transfer-with-Continuously-Weighted-Contrastive-Loss" class="headerlink" title="CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss"></a>CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14580">http://arxiv.org/abs/2309.14580</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rakshith Sharma Srinivasa, Jaejin Cho, Chouchang Yang, Yashas Malur Saidutta, Ching-Hua Lee, Yilin Shen, Hongxia Jin</li>
<li>for: 本研究探讨了对多modalities之间的零shot传输问题，即使用预训练模型在一个模式下进行表示学习，然后在另一个模式下使用得到的模型来完成多种任务。</li>
<li>methods: 本研究提出了一种新的损失函数called Continuously Weighted Contrastive Loss (CWCL)，该损失函数使用连续的相似度测量来对一个模式的表示空间与另一个模式的表示空间进行对齐。</li>
<li>results: 对多种模型、数据集和模式进行实验，本研究发现CWCL可以在零shot传输中超过现有方法的性能，尤其是在图像分类和语音分类中。 Specifically, the models achieve 5-8% (absolute) improvement over previous state-of-the-art methods in 0-shot image classification and 20-30% (absolute) improvement in 0-shot speech-to-intent classification and keyword classification.<details>
<summary>Abstract</summary>
This paper considers contrastive training for cross-modal 0-shot transfer wherein a pre-trained model in one modality is used for representation learning in another domain using pairwise data. The learnt models in the latter domain can then be used for a diverse set of tasks in a zero-shot way, similar to ``Contrastive Language-Image Pre-training (CLIP)'' and ``Locked-image Tuning (LiT)'' that have recently gained considerable attention. Most existing works for cross-modal representation alignment (including CLIP and LiT) use the standard contrastive training objective, which employs sets of positive and negative examples to align similar and repel dissimilar training data samples. However, similarity amongst training examples has a more continuous nature, thus calling for a more `non-binary' treatment. To address this, we propose a novel loss function called Continuously Weighted Contrastive Loss (CWCL) that employs a continuous measure of similarity. With CWCL, we seek to align the embedding space of one modality with another. Owing to the continuous nature of similarity in the proposed loss function, these models outperform existing methods for 0-shot transfer across multiple models, datasets and modalities. Particularly, we consider the modality pairs of image-text and speech-text and our models achieve 5-8% (absolute) improvement over previous state-of-the-art methods in 0-shot image classification and 20-30% (absolute) improvement in 0-shot speech-to-intent classification and keyword classification.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/cs.AI_2023_09_26/" data-id="clogyj8vh004l7crac7teazlc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/cs.CL_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T11:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/cs.CL_2023_09_26/">cs.CL - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unsupervised-Pre-Training-for-Vietnamese-Automatic-Speech-Recognition-in-the-HYKIST-Project"><a href="#Unsupervised-Pre-Training-for-Vietnamese-Automatic-Speech-Recognition-in-the-HYKIST-Project" class="headerlink" title="Unsupervised Pre-Training for Vietnamese Automatic Speech Recognition in the HYKIST Project"></a>Unsupervised Pre-Training for Vietnamese Automatic Speech Recognition in the HYKIST Project</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15869">http://arxiv.org/abs/2309.15869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khai Le-Duc</li>
<li>for: 这个研究的目的是开发一个敬礼语言翻译系统，以支持患者和医生之间的沟通。</li>
<li>methods: 该研究使用了ASR和MT技术，并 investigate了不同的训练计划和数据结合策略，以提高系统的性能。</li>
<li>results: 研究发现，使用公共可用的模型如XLSR-53可以达到比较高的识别精度，而自定义预训练模型也可以提高系统的性能。同时，该研究还 compare了不同的训练方法，包括supervised和Unsupervised方法，并使用wav2vec 2.0作为架构。<details>
<summary>Abstract</summary>
In today's interconnected globe, moving abroad is more and more prevalent, whether it's for employment, refugee resettlement, or other causes. Language difficulties between natives and immigrants present a common issue on a daily basis, especially in medical domain. This can make it difficult for patients and doctors to communicate during anamnesis or in the emergency room, which compromises patient care. The goal of the HYKIST Project is to develop a speech translation system to support patient-doctor communication with ASR and MT.   ASR systems have recently displayed astounding performance on particular tasks for which enough quantities of training data are available, such as LibriSpeech. Building a good model is still difficult due to a variety of speaking styles, acoustic and recording settings, and a lack of in-domain training data. In this thesis, we describe our efforts to construct ASR systems for a conversational telephone speech recognition task in the medical domain for Vietnamese language to assist emergency room contact between doctors and patients across linguistic barriers. In order to enhance the system's performance, we investigate various training schedules and data combining strategies. We also examine how best to make use of the little data that is available. The use of publicly accessible models like XLSR-53 is compared to the use of customized pre-trained models, and both supervised and unsupervised approaches are utilized using wav2vec 2.0 as architecture.
</details>
<details>
<summary>摘要</summary>
今天的全球化社会中，越来越多的人选择移民 abroad，无论是为了工作、难民重新安置或其他原因。在医疗领域，语言障碍问题是每天都存在的问题，特别是在医生和患者之间的交流中。这会使患者和医生在医学询问或紧急室中的交流受到干扰，从而影响病人的护理。 Project HYKIST 的目标是开发一个语音翻译系统，以支持患者和医生之间的交流。 ASR 系统在特定任务上已经表现出了惊人的表现，如 LibriSpeech。但建立好模型仍然困难，因为有很多说话风格、音频和录音设置，以及缺乏相关领域的训练数据。在这个论文中，我们描述了我们在医疗领域的语音识别任务中使用 ASR 系统的努力。我们 investigate 了不同的训练计划和数据组合策略，以提高系统的表现。我们还研究了如何利用有限的数据来提高系统的性能。我们 compare 了使用公共可用模型如 XLSR-53 和自定义预训练模型，以及使用 supervised 和 unsupervised 方法，使用 wav2vec 2.0 架构。
</details></li>
</ul>
<hr>
<h2 id="RAGAS-Automated-Evaluation-of-Retrieval-Augmented-Generation"><a href="#RAGAS-Automated-Evaluation-of-Retrieval-Augmented-Generation" class="headerlink" title="RAGAS: Automated Evaluation of Retrieval Augmented Generation"></a>RAGAS: Automated Evaluation of Retrieval Augmented Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15217">http://arxiv.org/abs/2309.15217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert</li>
<li>for: 评估 Retrieval Augmented Generation (RAG) 框架，不需要参考文本数据库。</li>
<li>methods: 使用 Retrieval 和 LLM 模块，将知识从参考文本数据库传递给 LLM，以减少用户与文本数据库之间的风险。</li>
<li>results: 提出了一组无需人工标注的评估指标，可以评估不同维度的 RAGB 架构，包括 retrieve 模块是否能够准确地标识有关焦点文本段落，LLM 模块是否能够准确地利用这些段落，以及生成结果的质量。<details>
<summary>Abstract</summary>
We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With RAGAs, we put forward a suite of metrics which can be used to evaluate these different dimensions \textit{without having to rely on ground truth human annotations}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.
</details>
<details>
<summary>摘要</summary>
我们介绍了RAGAs（引用自由评估Retrieval Augmented Generation）框架，用于评估基于引用文本库的 Retrieval Augmented Generation（RAG）pipeline。RAG系统由一个检索和一个基于LLM的生成模块组成，通过将知识从参考文本库传递给LLM，使LLM能够作为自然语言层次，减少用户和文本库之间的风险假设。评估RAG体系却存在多个维度：检索系统能够寻找相关和焦点的文本段落，LLM能够充分利用这些文本段落，或生成的质量自身。我们提出了一组无需基于真实人类标注的指标，用于评估这些不同维度。我们认为这种框架可以在评估RAG体系中帮助降低评估周期的时间，特别是 LLM 的广泛采用。
</details></li>
</ul>
<hr>
<h2 id="STANCE-C3-Domain-adaptive-Cross-target-Stance-Detection-via-Contrastive-Learning-and-Counterfactual-Generation"><a href="#STANCE-C3-Domain-adaptive-Cross-target-Stance-Detection-via-Contrastive-Learning-and-Counterfactual-Generation" class="headerlink" title="STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation"></a>STANCE-C3: Domain-adaptive Cross-target Stance Detection via Contrastive Learning and Counterfactual Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15176">http://arxiv.org/abs/2309.15176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nayoung Kim, David Mosallanezhad, Lu Cheng, Michelle V. Mancenido, Huan Liu</li>
<li>for: 这个研究的目的是提出一种适用于多个领域的立场推断模型，以便在不同领域和目标话题上进行高效的立场推断。</li>
<li>methods: 该模型使用了对比学习和对比生成来强化领域适应性的训练，以及修改的自然语言约束来防止过拟合和提高对多个领域的泛化能力。</li>
<li>results: 经过实验表明，该模型在多个 dataset 上表现出了性能提升，并且在不同领域和目标话题上具有较高的泛化能力。<details>
<summary>Abstract</summary>
Stance detection is the process of inferring a person's position or standpoint on a specific issue to deduce prevailing perceptions toward topics of general or controversial interest, such as health policies during the COVID-19 pandemic. Existing models for stance detection are trained to perform well for a single domain (e.g., COVID-19) and a specific target topic (e.g., masking protocols), but are generally ineffectual in other domains or targets due to distributional shifts in the data. However, constructing high-performing, domain-specific stance detection models requires an extensive corpus of labeled data relevant to the targeted domain, yet such datasets are not readily available. This poses a challenge as the process of annotating data is costly and time-consuming. To address these challenges, we introduce a novel stance detection model coined domain-adaptive Cross-target STANCE detection via Contrastive learning and Counterfactual generation (STANCE-C3) that uses counterfactual data augmentation to enhance domain-adaptive training by enriching the target domain dataset during the training process and requiring significantly less information from the new domain. We also propose a modified self-supervised contrastive learning as a component of STANCE-C3 to prevent overfitting for the existing domain and target and enable cross-target stance detection. Through experiments on various datasets, we show that STANCE-C3 shows performance improvement over existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CN<</SYS>>Stance detection是推断人的立场或看法在特定问题上，以便推断人们对一些广泛或争议性的话题（如COVID-19大流行期间的健康政策）的看法。现有的姿态检测模型通常只能在单一领域（如COVID-19）和特定目标话题（如面具协议）上表现出色，但在其他领域或话题上通常无法达到相同的水平，这是因为数据的分布shift。然而，建立高性能的领域专门的姿态检测模型需要大量的相关领域数据，但这些数据并不易 disponibles。这种情况提出了一个挑战，因为标注数据的过程是贵重的和时间consuming。为解决这些挑战，我们介绍了一种新的姿态检测模型，名为域 adapted Cross-target STANCE detection via Contrastive learning and Counterfactual generation（STANCE-C3）。STANCE-C3使用了对立数据增强，以便在训练过程中增强目标领域数据，并且需要较少的新领域信息。我们还提出了一种修改后的自我超视的对比学习，以避免过拟合现有领域和目标，并启用跨目标姿态检测。通过对多个数据集进行实验，我们表明STANCE-C3表现出了与现有状态艺技的性能提升。
</details></li>
</ul>
<hr>
<h2 id="RankVicuna-Zero-Shot-Listwise-Document-Reranking-with-Open-Source-Large-Language-Models"><a href="#RankVicuna-Zero-Shot-Listwise-Document-Reranking-with-Open-Source-Large-Language-Models" class="headerlink" title="RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models"></a>RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15088">http://arxiv.org/abs/2309.15088</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/castorini/rank_llm">https://github.com/castorini/rank_llm</a></li>
<li>paper_authors: Ronak Pradeep, Sahel Sharifymoghaddam, Jimmy Lin</li>
<li>for: 提高信息检索中列表重新排序的质量，并使用现代大语言模型（LLM）进行列表重新排序。</li>
<li>methods: 使用开源的7B参数模型，基于GPT-3.5和GPT-4的列表重新排序方法，并进行了分布式训练和排序。</li>
<li>results: 实验结果表明，我们可以在零批训练情况下达到与GPT-3.5的列表重新排序效果相似，但效果略为落后于GPT-4。我们希望我们的工作可以为未来关于列表重新排序的研究提供基础。<details>
<summary>Abstract</summary>
Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. To address this significant shortcoming, we present RankVicuna, the first fully open-source LLM capable of performing high-quality listwise reranking in a zero-shot setting. Experimental results on the TREC 2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter model, although our effectiveness remains slightly behind reranking with GPT-4. We hope our work provides the foundation for future research on reranking with modern LLMs. All the code necessary to reproduce our results is available at https://github.com/castorini/rank_llm.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Question-Answering-Approach-to-Evaluate-Legal-Summaries"><a href="#Question-Answering-Approach-to-Evaluate-Legal-Summaries" class="headerlink" title="Question-Answering Approach to Evaluate Legal Summaries"></a>Question-Answering Approach to Evaluate Legal Summaries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15016">http://arxiv.org/abs/2309.15016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huihui Xu, Kevin Ashley</li>
<li>for: 法律摘要评价框架</li>
<li>methods: GPT-4生成问答对集和答案评价</li>
<li>results: GPT-4评价与人类评价之间的相关性可以用于评估摘要质量<details>
<summary>Abstract</summary>
Traditional evaluation metrics like ROUGE compare lexical overlap between the reference and generated summaries without taking argumentative structure into account, which is important for legal summaries. In this paper, we propose a novel legal summarization evaluation framework that utilizes GPT-4 to generate a set of question-answer pairs that cover main points and information in the reference summary. GPT-4 is then used to generate answers based on the generated summary for the questions from the reference summary. Finally, GPT-4 grades the answers from the reference summary and the generated summary. We examined the correlation between GPT-4 grading with human grading. The results suggest that this question-answering approach with GPT-4 can be a useful tool for gauging the quality of the summary.
</details>
<details>
<summary>摘要</summary>
传统的评估指标如ROUGE对 lexical  overlap  между参考和生成摘要没有考虑情节结构，这是法律摘要中重要的一点。在这篇论文中，我们提出了一种新的法律摘要评估框架，利用 GPT-4 生成一组对应于参考摘要中主要点和信息的问题集。然后，GPT-4 使用生成的摘要回答这些问题。最后，GPT-4 评分来自参考摘要和生成摘要的答案。我们对 GPT-4 评分与人工评分之间的相关性进行了检验。结果表明，这种问题回答方法与 GPT-4 可以作为评估摘要质量的有用工具。
</details></li>
</ul>
<hr>
<h2 id="Updated-Corpora-and-Benchmarks-for-Long-Form-Speech-Recognition"><a href="#Updated-Corpora-and-Benchmarks-for-Long-Form-Speech-Recognition" class="headerlink" title="Updated Corpora and Benchmarks for Long-Form Speech Recognition"></a>Updated Corpora and Benchmarks for Long-Form Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15013">http://arxiv.org/abs/2309.15013</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/revdotcom/speech-datasets">https://github.com/revdotcom/speech-datasets</a></li>
<li>paper_authors: Jennifer Drexler Fox, Desh Raj, Natalie Delworth, Quinn McNamara, Corey Miller, Migüel Jetté</li>
<li>for: 这个论文主要用于研究长形语音识别（ASR）领域中的域名匹配问题。</li>
<li>methods: 该论文使用了三个标准的ASR corpora（TED-LIUM 3、Gigapeech和VoxPopuli-en），对其进行了更新的转录和对应，以便用于长形ASR研究。它们还研究了在训练和测试数据不同的情况下，逻辑架构和注意力基本encoder-decoder（AED）模型的Robustness问题。</li>
<li>results: 研究发现，AED模型更容易受到域名匹配问题的影响，而长形训练可以提高这些模型的Robustness。<details>
<summary>Abstract</summary>
The vast majority of ASR research uses corpora in which both the training and test data have been pre-segmented into utterances. In most real-word ASR use-cases, however, test audio is not segmented, leading to a mismatch between inference-time conditions and models trained on segmented utterances. In this paper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and VoxPopuli-en - with updated transcription and alignments to enable their use for long-form ASR research. We use these reconstituted corpora to study the train-test mismatch problem for transducers and attention-based encoder-decoders (AEDs), confirming that AEDs are more susceptible to this issue. Finally, we benchmark a simple long-form training for these models, showing its efficacy for model robustness under this domain shift.
</details>
<details>
<summary>摘要</summary>
大多数ASR研究使用已经 pré-分 segmented的数据集进行训练和测试。然而，在实际应用中，测试音频通常没有 segmented，导致模型训练用的 condition和测试 condition 之间存在匹配问题。在这篇论文中，我们重新发布了三个标准 ASR 数据集 - TED-LIUM 3、Gigapeech 和 VoxPopuli-en - 的更新的转录和对应，以便用于长形 ASR 研究。我们使用这些重新拟合的数据集来研究训练和测试之间的匹配问题，发现 AEDs 更容易受到这种问题的影响。最后，我们测试了一种简单的长形训练方法，并证明其在这种领域移植中的效果。
</details></li>
</ul>
<hr>
<h2 id="Robustness-of-the-Random-Language-Model"><a href="#Robustness-of-the-Random-Language-Model" class="headerlink" title="Robustness of the Random Language Model"></a>Robustness of the Random Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14913">http://arxiv.org/abs/2309.14913</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Fatemeh Lalegani, Eric De Giuli</li>
<li>for: 本研究探讨了人类和计算机语言之间的语法匹配。</li>
<li>methods: 该研究使用了随机语言模型（De Giuli 2019），这是一种 ensemble of stochastic context-free grammars，用于量化人类和计算机语言的 syntax。</li>
<li>results: 研究表明，在考虑到显式对称破坏的情况下，模型的enario是Robust的。与人类语言数据中的 syntax 网络划分系数相比， Observation 与24岁的儿童 обычно经历的转变相当。<details>
<summary>Abstract</summary>
The Random Language Model (De Giuli 2019) is an ensemble of stochastic context-free grammars, quantifying the syntax of human and computer languages. The model suggests a simple picture of first language learning as a type of annealing in the vast space of potential languages. In its simplest formulation, it implies a single continuous transition to grammatical syntax, at which the symmetry among potential words and categories is spontaneously broken. Here this picture is scrutinized by considering its robustness against explicit symmetry breaking, an inevitable component of learning in the real world. It is shown that the scenario is robust to such symmetry breaking. Comparison with human data on the clustering coefficient of syntax networks suggests that the observed transition is equivalent to that normally experienced by children at age 24 months.
</details>
<details>
<summary>摘要</summary>
随机语言模型（De Giuli 2019）是一个集合的随机上下文自由格式语言，量化人类和计算机语言的语法。该模型提出了一个简单的语言学习图景，认为人类语言学习是一种热化在可能语言空间中的过程。在最简式表述中，它表明了一种单一的连续变换，在潜在词汇和分类之间各自破坏 симметрии。在这种情况下，我们考虑了对显式对称破坏的Robustness，这是学习世界中不可避免的一部分。结果表明，这种情况具有Robustness。与人类语言结构网络的凝集系数相比，显示出这种过渡与24个月大的儿童常见的过渡相等。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Flawed-Data-Weakly-Supervised-Automatic-Speech-Recognition"><a href="#Learning-from-Flawed-Data-Weakly-Supervised-Automatic-Speech-Recognition" class="headerlink" title="Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition"></a>Learning from Flawed Data: Weakly Supervised Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15796">http://arxiv.org/abs/2309.15796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k2-fsa/icefall">https://github.com/k2-fsa/icefall</a></li>
<li>paper_authors: Dongji Gao, Hainan Xu, Desh Raj, Leibny Paola Garcia Perera, Daniel Povey, Sanjeev Khudanpur</li>
<li>For: 提高自动语音识别（ASR）系统的训练效果，适用于大量的高质量对应数据。* Methods: 提出了 Omni-temporal Classification（OTC）训练标准，通过考虑标签不确定性，使模型能够有效地学习语音-文本对应。OTC基于不确定的Weighted Finite State Transducers（WFST）扩展了传统的 CTC 目标函数。* Results: 通过在 LibriSpeech 和 LibriVox 数据集上进行实验，表明使用 OTC 训练 ASR 模型，甚至在对应文本中含有70%错误的情况下，模型的性能不会下降。<details>
<summary>Abstract</summary>
Training automatic speech recognition (ASR) systems requires large amounts of well-curated paired data. However, human annotators usually perform "non-verbatim" transcription, which can result in poorly trained models. In this paper, we propose Omni-temporal Classification (OTC), a novel training criterion that explicitly incorporates label uncertainties originating from such weak supervision. This allows the model to effectively learn speech-text alignments while accommodating errors present in the training transcripts. OTC extends the conventional CTC objective for imperfect transcripts by leveraging weighted finite state transducers. Through experiments conducted on the LibriSpeech and LibriVox datasets, we demonstrate that training ASR models with OTC avoids performance degradation even with transcripts containing up to 70% errors, a scenario where CTC models fail completely. Our implementation is available at https://github.com/k2-fsa/icefall.
</details>
<details>
<summary>摘要</summary>
培训自动语音识别（ASR）系统需要大量的高质量对应数据。然而，人工标注员通常会进行“非文字”抄写，这可能导致模型训练不佳。在这篇论文中，我们提出了一种新的训练标准《全时分类》（OTC），该标准直接表达标注不确定性的影响。这使得模型能够有效地学习语音-文本对应，同时满足训练脚本中存在错误的情况。OTC基于权重finite state transducers扩展了传统的CTC目标，并通过实验表明，即使训练脚本中有70%的错误，ASR模型也能够保持高效性。我们的实现可以在https://github.com/k2-fsa/icefall中找到。
</details></li>
</ul>
<hr>
<h2 id="Segmentation-Free-Streaming-Machine-Translation"><a href="#Segmentation-Free-Streaming-Machine-Translation" class="headerlink" title="Segmentation-Free Streaming Machine Translation"></a>Segmentation-Free Streaming Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14823">http://arxiv.org/abs/2309.14823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier Iranzo-Sánchez, Jorge Iranzo-Sánchez, Adrià Giménez, Jorge Civera, Alfons Juan</li>
<li>for: 提出了一种无需分 segmentation 的概率机器翻译（MT）框架，以实现在实时翻译中不需要预先分 segmentation。</li>
<li>methods: 提出了一种延迟 segmentation 决策ntil 翻译结果生成完毕的方法，使得模型可以在不需要硬件 segmentation 的情况下进行翻译。</li>
<li>results: 对比其他竞争方法，提出的 Segmentation-Free 框架在质量-延迟Trade-off中具有更好的性能。<details>
<summary>Abstract</summary>
Streaming Machine Translation (MT) is the task of translating an unbounded input text stream in real-time. The traditional cascade approach, which combines an Automatic Speech Recognition (ASR) and an MT system, relies on an intermediate segmentation step which splits the transcription stream into sentence-like units. However, the incorporation of a hard segmentation constrains the MT system and is a source of errors. This paper proposes a Segmentation-Free framework that enables the model to translate an unsegmented source stream by delaying the segmentation decision until the translation has been generated. Extensive experiments show how the proposed Segmentation-Free framework has better quality-latency trade-off than competing approaches that use an independent segmentation model. Software, data and models will be released upon paper acceptance.
</details>
<details>
<summary>摘要</summary>
流动机器翻译（MT）是将输入文本流转换成实时翻译的任务。传统的堆叠方法，将自动语音识别（ASR）和MT系统结合在一起，需要一个中间分 segmentation 步骤，将转录流分成句子样式的单元。然而，在 incorporating 硬件分 segmentation 会限制MT系统的性能，并且是错误的来源。这篇论文提出了无需分 segmentation 的框架，允许模型在翻译过程中延迟分 segmentation 决策，直到翻译结果被生成。广泛的实验表明，提议的无需分 segmentation 框架在质量-延迟质量之间有更好的质量-延迟平衡，与独立的分 segmentation 模型相比。软件、数据和模型会在论文接受后释出。
</details></li>
</ul>
<hr>
<h2 id="BLIP-Adapter-Parameter-Efficient-Transfer-Learning-for-Mobile-Screenshot-Captioning"><a href="#BLIP-Adapter-Parameter-Efficient-Transfer-Learning-for-Mobile-Screenshot-Captioning" class="headerlink" title="BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning"></a>BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile Screenshot Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14774">http://arxiv.org/abs/2309.14774</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rainyugg/blip-adapter">https://github.com/rainyugg/blip-adapter</a></li>
<li>paper_authors: Ching-Yu Chiang, I-Hua Chang, Shih-Wei Liao</li>
<li>for: 这项研究旨在探索屏幕截图captioning任务的有效调参方法。</li>
<li>methods: 本研究提议使用适应器方法，只需调参模型中的附加模块，以提高性能。</li>
<li>results: 研究表明，通过将批处理大型预训练模型的参数冻结，并仅调参适应器方法中的参数，可以实现与完全调参模型的性能相似，同时减少了大量参数的数量。<details>
<summary>Abstract</summary>
This study aims to explore efficient tuning methods for the screenshot captioning task. Recently, image captioning has seen significant advancements, but research in captioning tasks for mobile screens remains relatively scarce. Current datasets and use cases describing user behaviors within product screenshots are notably limited. Consequently, we sought to fine-tune pre-existing models for the screenshot captioning task. However, fine-tuning large pre-trained models can be resource-intensive, requiring considerable time, computational power, and storage due to the vast number of parameters in image captioning models. To tackle this challenge, this study proposes a combination of adapter methods, which necessitates tuning only the additional modules on the model. These methods are originally designed for vision or language tasks, and our intention is to apply them to address similar challenges in screenshot captioning. By freezing the parameters of the image caption models and training only the weights associated with the methods, performance comparable to fine-tuning the entire model can be achieved, while significantly reducing the number of parameters. This study represents the first comprehensive investigation into the effectiveness of combining adapters within the context of the screenshot captioning task. Through our experiments and analyses, this study aims to provide valuable insights into the application of adapters in vision-language models and contribute to the development of efficient tuning techniques for the screenshot captioning task. Our study is available at https://github.com/RainYuGG/BLIP-Adapter
</details>
<details>
<summary>摘要</summary>
这个研究的目标是探索屏幕截图标题预测任务中有效的调参方法。在图像描述领域，近年来有了 significative 的进步，但是对手机屏幕上的用户行为描述 task 的研究尚处于相对缺乏的状态。当前的数据集和用户行为描述 case 都很有限，因此我们决定使用先前训练的模型进行调参。然而，对大型预训练模型的调参可能会占用大量的时间、计算资源和存储空间，这是因为图像描述模型中有很多参数。为了解决这个挑战，本研究提出了一种将适配器方法与图像描述模型结合使用的方法。这种方法原本是设计用于视觉或语言任务的，我们想用它们来解决屏幕截图标题预测任务中的类似挑战。通过冻结图像描述模型的参数，并仅对适配器方法进行训练，可以实现与完全调参模型的性能相似，同时减少了大量参数的数量。本研究是首次对适配器在屏幕截图标题预测任务中的应用进行全面的研究。通过我们的实验和分析，本研究旨在为应用适配器在视觉语言模型中的应用提供有价值的发现，并为屏幕截图标题预测任务中的效率调参技术做出贡献。研究的数据集和代码可以在 GitHub 上找到：https://github.com/RainYuGG/BLIP-Adapter
</details></li>
</ul>
<hr>
<h2 id="KERMIT-Knowledge-Graph-Completion-of-Enhanced-Relation-Modeling-with-Inverse-Transformation"><a href="#KERMIT-Knowledge-Graph-Completion-of-Enhanced-Relation-Modeling-with-Inverse-Transformation" class="headerlink" title="KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation"></a>KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14770">http://arxiv.org/abs/2309.14770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Li, Lingzhi Wang, Yuliang Wei, Richard Yi Da Xu, Bailing Wang</li>
<li>for: 填充知识图中缺失的三元组（triple），以提高知识图完成任务的准确性。</li>
<li>methods: 利用文本描述来完成知识图 completion 任务，但可能会遇到限制，因为描述可能不准确地表达意图。为了解决这些挑战，我们提议通过两种附加机制来增强数据。首先，我们使用 ChatGPT 作为外部知识库，生成具有准确性和 coherence 的描述，以bridging semantic gap между查询和答案。其次，我们利用 inverse relations 创建对称图，生成额外标签和提供补充信息，以便链接预测。这种方法可以提供更多的关系between entities。</li>
<li>results: 通过这两种机制，我们观察到了知识图 completion 的显著改善，这些机制可以增强数据的 ricahness 和多样性，导致更准确的结果。<details>
<summary>Abstract</summary>
Knowledge graph completion is a task that revolves around filling in missing triples based on the information available in a knowledge graph. Among the current studies, text-based methods complete the task by utilizing textual descriptions of triples. However, this modeling approach may encounter limitations, particularly when the description fails to accurately and adequately express the intended meaning. To overcome these challenges, we propose the augmentation of data through two additional mechanisms. Firstly, we employ ChatGPT as an external knowledge base to generate coherent descriptions to bridge the semantic gap between the queries and answers. Secondly, we leverage inverse relations to create a symmetric graph, thereby creating extra labeling and providing supplementary information for link prediction. This approach offers additional insights into the relationships between entities. Through these efforts, we have observed significant improvements in knowledge graph completion, as these mechanisms enhance the richness and diversity of the available data, leading to more accurate results.
</details>
<details>
<summary>摘要</summary>
知识图完成任务是基于现有的知识图信息完善缺失的 triple。目前的研究主要采用文本方法来完成这项任务，但这种模型化方法可能会遇到限制，特别是当描述不准确、不完整时。为了解决这些挑战，我们提议在数据上进行两种附加机制。首先，我们使用 ChatGPT 作为外部知识库，生成具有协调性的描述， bridging 知识图中缺失的semantic gap。其次，我们利用反向关系，创建对称图，从而创建Extra labeling和提供补充信息 для链接预测。这种方法提供了更多的关系 между实体的意义，通过这些努力，我们观察到了知识图完成任务中显著的改善，这些机制增加了可用数据的丰富性和多样性，导致更加准确的结果。
</details></li>
</ul>
<hr>
<h2 id="ConPET-Continual-Parameter-Efficient-Tuning-for-Large-Language-Models"><a href="#ConPET-Continual-Parameter-Efficient-Tuning-for-Large-Language-Models" class="headerlink" title="ConPET: Continual Parameter-Efficient Tuning for Large Language Models"></a>ConPET: Continual Parameter-Efficient Tuning for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14763">http://arxiv.org/abs/2309.14763</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/raincleared-song/conpet">https://github.com/raincleared-song/conpet</a></li>
<li>paper_authors: Chenyang Song, Xu Han, Zheni Zeng, Kuai Li, Chen Chen, Zhiyuan Liu, Maosong Sun, Tao Yang</li>
<li>for: 这个研究旨在提出一种应用于大型语言模型（LLM）的持续学习方法，以减少 computation costs、内存耗尽和遗传问题。</li>
<li>methods: 这个方法基于优化parameter-efficient tuning（PET），包括两个版本：静态ConPET和动态ConPET。静态ConPET可以让former continual learning方法在LMM中进行适应，并将适应成本大大减少。动态ConPET则透过分类PET模组和PET模组选择器实现动态选择最佳PET模组。</li>
<li>results: 实验结果显示，静态ConPET可以帮助多个former方法将可调参数的数量增加至3,000多倍，并在五个较小的benchmark上超过PET-只基eline以少于5分点。动态ConPET则在最大的dataset上获得了优化。codes和数据可以在<a target="_blank" rel="noopener" href="https://github.com/Raincleared-Song/ConPET%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Raincleared-Song/ConPET上获取。</a><details>
<summary>Abstract</summary>
Continual learning necessitates the continual adaptation of models to newly emerging tasks while minimizing the catastrophic forgetting of old ones. This is extremely challenging for large language models (LLMs) with vanilla full-parameter tuning due to high computation costs, memory consumption, and forgetting issue. Inspired by the success of parameter-efficient tuning (PET), we propose Continual Parameter-Efficient Tuning (ConPET), a generalizable paradigm for continual task adaptation of LLMs with task-number-independent training complexity. ConPET includes two versions with different application scenarios. First, Static ConPET can adapt former continual learning methods originally designed for relatively smaller models to LLMs through PET and a dynamic replay strategy, which largely reduces the tuning costs and alleviates the over-fitting and forgetting issue. Furthermore, to maintain scalability, Dynamic ConPET adopts separate PET modules for different tasks and a PET module selector for dynamic optimal selection. In our extensive experiments, the adaptation of Static ConPET helps multiple former methods reduce the scale of tunable parameters by over 3,000 times and surpass the PET-only baseline by at least 5 points on five smaller benchmarks, while Dynamic ConPET gains its advantage on the largest dataset. The codes and datasets are available at https://github.com/Raincleared-Song/ConPET.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>> kontinuel lerning需要 kontinuel adapting模型到新出现的任务，并最大限度减少老任务的忘记。这对大语言模型（LLM）来说是极其困难的，因为它们的计算成本高、内存占用大，以及忘记问题。 Drawing inspiration from the success of parameter-efficient tuning（PET）, we propose Continual Parameter-Efficient Tuning（ConPET）， a generalizable paradigm for continual task adaptation of LLMs with task-number-independent training complexity. ConPET includes two versions with different application scenarios. First, Static ConPET can adapt former continual learning methods originally designed for relatively smaller models to LLMs through PET and a dynamic replay strategy, which largely reduces the tuning costs and alleviates the over-fitting and forgetting issue. Furthermore, to maintain scalability, Dynamic ConPET adopts separate PET modules for different tasks and a PET module selector for dynamic optimal selection. In our extensive experiments, the adaptation of Static ConPET helps multiple former methods reduce the scale of tunable parameters by over 3,000 times and surpass the PET-only baseline by at least 5 points on five smaller benchmarks, while Dynamic ConPET gains its advantage on the largest dataset. The codes and datasets are available at https://github.com/Raincleared-Song/ConPET。
</details></li>
</ul>
<hr>
<h2 id="QA-LoRA-Quantization-Aware-Low-Rank-Adaptation-of-Large-Language-Models"><a href="#QA-LoRA-Quantization-Aware-Low-Rank-Adaptation-of-Large-Language-Models" class="headerlink" title="QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"></a>QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14717">http://arxiv.org/abs/2309.14717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eltociear/qa-lora">https://github.com/eltociear/qa-lora</a></li>
<li>paper_authors: Yuhui Xu, Lingxi Xie, Xiaotao Gu, Xin Chen, Heng Chang, Hengheng Zhang, Zhengsu Chen, Xiaopeng Zhang, Qi Tian</li>
<li>for: 这个论文的目的是提出一个量化意识掌握算法（QA-LoRA），以实现大型自然语言模型（LLM）在边缘设备上的部署。</li>
<li>methods: 这个论文使用的方法是使用群体化算子，增加量化的自由度，同时减少适应的自由度。这个方法可以轻松地实现，只需要几行代码。</li>
<li>results: 这个论文的结果显示，使用QA-LoRA可以实现量化LLM的时间和内存使用率的减少，并且不会对精度造成损害。这个方法可以在不同的精度档案和下游应用中进行适用。<details>
<summary>Abstract</summary>
Recently years have witnessed a rapid development of large language models (LLMs). Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices. In this paper, we propose a quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation. QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model families and validate its effectiveness in different fine-tuning datasets and downstream scenarios. Code will be made available at https://github.com/yuhuixu1993/qa-lora.
</details>
<details>
<summary>摘要</summary>
最近几年内，大型语言模型（LLM）的快速发展已经引起了广泛的关注。尽管LLM具有许多语言理解任务的强大能力，但是计算负担很大，特别是在部署到边缘设备时。在这篇论文中，我们提出了一种量化意识扩展低级化算法（QA-LoRA）。我们的动机在于量化和适应的自由度不均衡，我们的解决方案是使用群组操作符，以增加量化的自由度，同时减少适应的自由度。QA-LoRA易于实现，只需几行代码即可，它使得原始LoRA具有两种能力：（i）在练习中，LLM的参数被量化（例如INT4），以降低时间和存储使用；（ii）在练习后，LLM和辅助参数自然地被 integrate到量化模型中，无损失准确性。我们在LLaMA和LLaMA2模型家族上应用QA-LoRA，并在不同的练习数据集和下游enario中验证其效果。代码将在https://github.com/yuhuixu1993/qa-lora中提供。
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Text-to-Video-Model-via-Transformer"><a href="#A-Simple-Text-to-Video-Model-via-Transformer" class="headerlink" title="A Simple Text to Video Model via Transformer"></a>A Simple Text to Video Model via Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14683">http://arxiv.org/abs/2309.14683</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vividitytech/text2videogpt">https://github.com/vividitytech/text2videogpt</a></li>
<li>paper_authors: Gang Chen</li>
<li>for: 本研究旨在提出一种通用且简单的文本到视频模型，基于Transformer结构。</li>
<li>methods: 本模型使用了Transformer结构来捕捉文本和图像的时间相关性，并使用GPT2进行语言模型。</li>
<li>results: 经测试在UCF101 dataset上，本方法可以生成出promising的视频。Here’s a more detailed explanation of each point:1. For: The paper aims to propose a general and simple text-to-video model based on the Transformer architecture.2. Methods: The model uses the Transformer architecture to capture the temporal consistency between text and image sequences, and employs GPT2 as the language model.3. Results: The proposed method is tested on the UCF101 dataset and shows promising results in generating videos.<details>
<summary>Abstract</summary>
We present a general and simple text to video model based on Transformer. Since both text and video are sequential data, we encode both texts and images into the same hidden space, which are further fed into Transformer to capture the temporal consistency and then decoder to generate either text or images. Considering the image signal may become weak in the long sequence, we introduce the U-Net to reconstruct image from its noised version. Specifically, we increase the noise level to the original image in the long sequence, then use the $down$ module from U-Net to encode noised images, which are further input to transformer to predict next clear images. We also add a constraint to promote motion between any generated image pair in the video. We use GPT2 and test our approach on UCF101 dataset and show it can generate promising videos.
</details>
<details>
<summary>摘要</summary>
我们提出了一种通用、简单的文本到视频模型，基于Transformer。由于文本和视频都是序列数据，我们将文本和图像编码到同一个隐藏空间中，然后将其传递给Transformer来捕捉时间一致性。为了处理长序列中的图像信号弱化，我们引入了U-Net来重建图像。 Specifically，我们将原始图像的噪声水平提高，然后使用U-Net的$down$模块编码噪声图像，并将其输入到Transformer来预测下一帧清晰图像。此外，我们添加了一个约束来促进视频中任意生成图像对的运动。我们使用GPT2进行测试，并在UCF101 dataset上实现了可靠的视频生成。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/cs.CL_2023_09_26/" data-id="clogyj8wn00b77crafpbf7o3m" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/cs.LG_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T10:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/cs.LG_2023_09_26/">cs.LG - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DeepROCK-Error-controlled-interaction-detection-in-deep-neural-networks"><a href="#DeepROCK-Error-controlled-interaction-detection-in-deep-neural-networks" class="headerlink" title="DeepROCK: Error-controlled interaction detection in deep neural networks"></a>DeepROCK: Error-controlled interaction detection in deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15319">http://arxiv.org/abs/2309.15319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Winston Chen, William Stafford Noble, Yang Young Lu</li>
<li>for: 这 paper 的目的是提高深度神经网络 (DNN) 的解释性，使其在抗错准备领域中更加可靠。</li>
<li>methods: 这 paper 使用了“knockoffs”，即假变量，来模拟特定功能集之间的依赖关系，并使用了一种新的 DNN 架构，以控制 false discovery rate (FDR) 和最大化统计能力。</li>
<li>results:  experiments 表明，DeepROCK 可以有效地控制 FDR，并在 simulate 和实际数据上进行了广泛的验证。<details>
<summary>Abstract</summary>
The complexity of deep neural networks (DNNs) makes them powerful but also makes them challenging to interpret, hindering their applicability in error-intolerant domains. Existing methods attempt to reason about the internal mechanism of DNNs by identifying feature interactions that influence prediction outcomes. However, such methods typically lack a systematic strategy to prioritize interactions while controlling confidence levels, making them difficult to apply in practice for scientific discovery and hypothesis validation. In this paper, we introduce a method, called DeepROCK, to address this limitation by using knockoffs, which are dummy variables that are designed to mimic the dependence structure of a given set of features while being conditionally independent of the response. Together with a novel DNN architecture involving a pairwise-coupling layer, DeepROCK jointly controls the false discovery rate (FDR) and maximizes statistical power. In addition, we identify a challenge in correctly controlling FDR using off-the-shelf feature interaction importance measures. DeepROCK overcomes this challenge by proposing a calibration procedure applied to existing interaction importance measures to make the FDR under control at a target level. Finally, we validate the effectiveness of DeepROCK through extensive experiments on simulated and real datasets.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）的复杂性使其具有强大的计算能力，但同时也使其难以解释，这限制了其在容错领域的应用。现有的方法通过找出特征相互作用来推理DNN的内部机制，但这些方法通常缺乏系统的策略来优先级化交互，使其在实践中困难应用于科学发现和假设验证。在本文中，我们介绍了一种方法，称为DeepROCK，以解决这一限制。DeepROCK使用“假变量”（knockoffs），这些变量模拟给定特征集的依赖结构，同时保持conditionally independent于响应变量。与一种新的DNN架构相结合，DeepROCK同时控制了false discovery rate（FDR）和最大化统计能力。此外，我们发现了控制FDR使用现有特征相互作用重要性度量的挑战。DeepROCK解决了这个挑战，通过对现有的特征相互作用重要性度量进行滤波来使FDR进行控制。最后，我们通过对模拟和实际数据进行广泛的实验验证了DeepROCK的效果。
</details></li>
</ul>
<hr>
<h2 id="Telescope-An-Automated-Hybrid-Forecasting-Approach-on-a-Level-Playing-Field"><a href="#Telescope-An-Automated-Hybrid-Forecasting-Approach-on-a-Level-Playing-Field" class="headerlink" title="Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field"></a>Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15871">http://arxiv.org/abs/2309.15871</a></li>
<li>repo_url: None</li>
<li>paper_authors: André Bauer, Mark Leznik, Michael Stenger, Robert Leppich, Nikolas Herbst, Samuel Kounev, Ian Foster</li>
<li>for: 预测（forecasting）</li>
<li>methods: 使用机器学习方法自动从给定时间序列中提取有关信息，并将其分解成多个部分进行处理。</li>
<li>results: 比较其他最新方法的准确和可靠预测，而无需进行参数化或训练多个参数。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In many areas of decision-making, forecasting is an essential pillar. Consequently, many different forecasting methods have been proposed. From our experience, recently presented forecasting methods are computationally intensive, poorly automated, tailored to a particular data set, or they lack a predictable time-to-result. To this end, we introduce Telescope, a novel machine learning-based forecasting approach that automatically retrieves relevant information from a given time series and splits it into parts, handling each of them separately. In contrast to deep learning methods, our approach doesn't require parameterization or the need to train and fit a multitude of parameters. It operates with just one time series and provides forecasts within seconds without any additional setup. Our experiments show that Telescope outperforms recent methods by providing accurate and reliable forecasts while making no assumptions about the analyzed time series.
</details>
<details>
<summary>摘要</summary>
在很多决策领域中，预测是一个重要的柱子。因此，有很多不同的预测方法被提出。从我们的经验来看，最近提出的预测方法都具有计算昂贵、自动化不够、特定数据集适应性或时间到结果难以预测等缺点。为了解决这些问题，我们介绍了天镜，一种新的机器学习基于的预测方法。与深度学习方法不同，我们的方法不需要参数化或训练多个参数。它只需要一个时间序列，并在秒钟内提供准确和可靠的预测，无需任何额外设置。我们的实验表明，天镜比最近的方法提供更准确和可靠的预测，而且不会对分析的时间序列做任何假设。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Log-Concavity-Theory-and-Algorithm-for-Sum-Log-Concave-Optimization"><a href="#Beyond-Log-Concavity-Theory-and-Algorithm-for-Sum-Log-Concave-Optimization" class="headerlink" title="Beyond Log-Concavity: Theory and Algorithm for Sum-Log-Concave Optimization"></a>Beyond Log-Concavity: Theory and Algorithm for Sum-Log-Concave Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15298">http://arxiv.org/abs/2309.15298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mastane Achab</li>
<li>for: 该文章扩展了经典的凸优化理论，应用于函数的最小化，其等于减法各个凸抽象函数的逻辑和。</li>
<li>methods: 该文章提出了一种新的梯度下降算法（cross gradient descent，XGD），该算法在梯度和副向量之间进行交互调整，以实现更高效的优化。</li>
<li>results: 该文章通过应用该框架，引入了一种新的分类方法（检查ered regression），该方法可以在非线性分离问题中进行分类，并且可以通过使用任意数量的准则平面，创造一种棋盘状的决策区域。<details>
<summary>Abstract</summary>
This paper extends the classic theory of convex optimization to the minimization of functions that are equal to the negated logarithm of what we term as a sum-log-concave function, i.e., a sum of log-concave functions. In particular, we show that such functions are in general not convex but still satisfy generalized convexity inequalities. These inequalities unveil the key importance of a certain vector that we call the cross-gradient and that is, in general, distinct from the usual gradient. Thus, we propose the Cross Gradient Descent (XGD) algorithm moving in the opposite direction of the cross-gradient and derive a convergence analysis. As an application of our sum-log-concave framework, we introduce the so-called checkered regression method relying on a sum-log-concave function. This classifier extends (multiclass) logistic regression to non-linearly separable problems since it is capable of tessellating the feature space by using any given number of hyperplanes, creating a checkerboard-like pattern of decision regions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multiple-Case-Physics-Informed-Neural-Network-for-Biomedical-Tube-Flows"><a href="#Multiple-Case-Physics-Informed-Neural-Network-for-Biomedical-Tube-Flows" class="headerlink" title="Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows"></a>Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15294">http://arxiv.org/abs/2309.15294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Shen Wong, Wei Xuan Chan, Bing Huan Li, Choon Hwai Yap</li>
<li>for: 计算血液和空气流动在管状 geometries 的生物医学评估</li>
<li>methods: 使用Physics-Informed Neural Networks (PINNs) 代替传统的计算流体力学 (CFD) 方法</li>
<li>results: 可以在实时内获得未看到的geometry cases的结果，并且可以优化网络架构、管状特有的和正则化策略以提高性能<details>
<summary>Abstract</summary>
Fluid dynamics computations for tube-like geometries are important for biomedical evaluation of vascular and airway fluid dynamics. Physics-Informed Neural Networks (PINNs) have recently emerged as a good alternative to traditional computational fluid dynamics (CFD) methods. The vanilla PINN, however, requires much longer training time than the traditional CFD methods for each specific flow scenario and thus does not justify its mainstream use. Here, we explore the use of the multi-case PINN approach for calculating biomedical tube flows, where varied geometry cases are parameterized and pre-trained on the PINN, such that results for unseen geometries can be obtained in real time. Our objective is to identify network architecture, tube-specific, and regularization strategies that can optimize this, via experiments on a series of idealized 2D stenotic tube flows.
</details>
<details>
<summary>摘要</summary>
fluid 动力计算 для管状结构是生物医学评估血液和空气流动的重要方面。物理学 Informed Neural Networks (PINNs) 最近emerge 为传统计算流体力学 (CFD) 方法的好alternative。然而，vanilla PINN 需要每个特定流场训练时间更长，因此无法 justify 其主流使用。在这里，我们探讨使用多个案例 PINN 方法计算生物管流动，其中 varied geometry cases 被参数化并在 PINN 中预训练，以便在实时内获得未经见过的geometry结果。我们的目标是通过实验 serie 的idealized 2D 狭窄管流动来优化这种方法。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Representation-Learning-from-Ubiquitous-ECG-with-State-Space-Models"><a href="#Scaling-Representation-Learning-from-Ubiquitous-ECG-with-State-Space-Models" class="headerlink" title="Scaling Representation Learning from Ubiquitous ECG with State-Space Models"></a>Scaling Representation Learning from Ubiquitous ECG with State-Space Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15292">http://arxiv.org/abs/2309.15292</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/klean2050/tiles_ecg_model">https://github.com/klean2050/tiles_ecg_model</a></li>
<li>paper_authors: Kleanthis Avramidis, Dominika Kunc, Bartosz Perz, Kranti Adsul, Tiantian Feng, Przemysław Kazienko, Stanisław Saganowski, Shrikanth Narayanan</li>
<li>For: The paper is written for enhancing human well-being through ubiquitous sensing from wearable devices in the wild, with a focus on electrocardiogram (ECG) signals.* Methods: The paper introduces a pre-trained state-space model for representation learning from ECG signals, which is trained in a self-supervised manner using a large dataset of 275,000 10s ECG recordings collected in the wild.* Results: The proposed model demonstrates competitive performance on a range of downstream tasks, including health monitoring, stress and affect estimation, and provides efficacy in low-resource regimes.Here’s the information in Simplified Chinese text format, as requested:</li>
<li>for: 帮助人类健康提升，通过抽象敏感设备在野外收集数据，包括诊断临床病种和衡量压力和情绪等。</li>
<li>methods: 提出一种基于状态空间模型的 Representation Learning 方法，通过自我超vised 方式使用大量的野外收集到的 275,000 个 10s ECG 记录。</li>
<li>results: 提出的模型在多个下游任务上显示竞争性的表现，包括健康监测、压力和情绪估计等，并在资源有限的情况下显示有效性。<details>
<summary>Abstract</summary>
Ubiquitous sensing from wearable devices in the wild holds promise for enhancing human well-being, from diagnosing clinical conditions and measuring stress to building adaptive health promoting scaffolds. But the large volumes of data therein across heterogeneous contexts pose challenges for conventional supervised learning approaches. Representation Learning from biological signals is an emerging realm catalyzed by the recent advances in computational modeling and the abundance of publicly shared databases. The electrocardiogram (ECG) is the primary researched modality in this context, with applications in health monitoring, stress and affect estimation. Yet, most studies are limited by small-scale controlled data collection and over-parameterized architecture choices. We introduce \textbf{WildECG}, a pre-trained state-space model for representation learning from ECG signals. We train this model in a self-supervised manner with 275,000 10s ECG recordings collected in the wild and evaluate it on a range of downstream tasks. The proposed model is a robust backbone for ECG analysis, providing competitive performance on most of the tasks considered, while demonstrating efficacy in low-resource regimes. The code and pre-trained weights are shared publicly at https://github.com/klean2050/tiles_ecg_model.
</details>
<details>
<summary>摘要</summary>
通过 ubique 感知设备在野外的应用，可以提高人类的健康水平，从诊断临床病种和测量压力到构建适应性健康促进架构。但是，由于这些数据在不同的CONTEXT中存在差异，因此使用传统的指导学习方法会面临挑战。生物信号的 Representation Learning 是一个出现在的领域，它受到了计算机模型的最新进步和大量公共分享数据库的推动。电cardiogram (ECG) 是这个上下文中最常研究的Modalitas，它在健康监测、压力和情绪估计等方面有着应用。然而，大多数研究都受限于小规模的控制数据收集和过参数化的建筑选择。我们介绍了 \textbf{WildECG}，一个预训练的状态空间模型，用于 Representation Learning 从 ECG 信号中获取特征。我们通过在野外收集了 275,000 个 10s ECG 记录的自助监测方式进行训练，并对其进行评估。该模型是一个强健的 ECG 分析的基础模型，在大多数任务上提供了竞争性的性能，同时在低资源 режи下也表现出了效果。代码和预训练 веса公共分享在 https://github.com/klean2050/tiles_ecg_model 上。
</details></li>
</ul>
<hr>
<h2 id="Composable-Coresets-for-Determinant-Maximization-Greedy-is-Almost-Optimal"><a href="#Composable-Coresets-for-Determinant-Maximization-Greedy-is-Almost-Optimal" class="headerlink" title="Composable Coresets for Determinant Maximization: Greedy is Almost Optimal"></a>Composable Coresets for Determinant Maximization: Greedy is Almost Optimal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15286">http://arxiv.org/abs/2309.15286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddharth Gollapudi, Sepideh Mahabadi, Varun Sivashankar</li>
<li>For: 本研究的目标是解决一个维度为 $d$ 的集合中选择 $k$ 个向量，以最大化向量的体积。* Methods: 本研究使用了 Determinantal point processes (DPP) 的 MAP-inference 任务，并在大量数据下进行研究。* Results: 我们提出了一种基于 Greedy 算法的可 compose 核心集合，可以在 $O(k)^{3k}$ 的准确因子下解决这个问题。此外，我们还证明了 Greedy 算法的本地优化性，可以在实际数据集上实现更高的准确性。<details>
<summary>Abstract</summary>
Given a set of $n$ vectors in $\mathbb{R}^d$, the goal of the \emph{determinant maximization} problem is to pick $k$ vectors with the maximum volume. Determinant maximization is the MAP-inference task for determinantal point processes (DPP) and has recently received considerable attention for modeling diversity. As most applications for the problem use large amounts of data, this problem has been studied in the relevant \textit{composable coreset} setting. In particular, [Indyk-Mahabadi-OveisGharan-Rezaei--SODA'20, ICML'19] showed that one can get composable coresets with optimal approximation factor of $\tilde O(k)^k$ for the problem, and that a local search algorithm achieves an almost optimal approximation guarantee of $O(k)^{2k}$. In this work, we show that the widely-used Greedy algorithm also provides composable coresets with an almost optimal approximation factor of $O(k)^{3k}$, which improves over the previously known guarantee of $C^{k^2}$, and supports the prior experimental results showing the practicality of the greedy algorithm as a coreset. Our main result follows by showing a local optimality property for Greedy: swapping a single point from the greedy solution with a vector that was not picked by the greedy algorithm can increase the volume by a factor of at most $(1+\sqrt{k})$. This is tight up to the additive constant $1$. Finally, our experiments show that the local optimality of the greedy algorithm is even lower than the theoretical bound on real data sets.
</details>
<details>
<summary>摘要</summary>
给定一组 $n$ 向量在 $\mathbb{R}^d$ 中，目标是选择 $k$ 个向量以最大化体积。这个问题被称为 determinant maximization 问题，是 determinantal point processes (DPP) 的MAP-推理任务，最近受到了各种应用的关注，以模型多样性。由于大多数应用都使用大量数据，因此这个问题在相关的可composable coreset 设定下进行研究。特别是，Indyk-Mahabadi-OveisGharan-Rezaei 在 SODA'20 和 ICML'19 上显示了可composable coreset 的优化因子为 $\tilde O(k)^k$，并且一个本地搜索算法可以达到 $O(k)^{2k}$ 的相对误差 guarantee。在这个工作中，我们表明了广泛使用的 Greedy 算法也可以提供可composable coreset 的近似因子 $O(k)^{3k}$，超过之前知道的 $C^{k^2}$  guarantee，并且支持先前的实验结果，证明 Greedy 算法在实际数据集上的实用性。我们的主要结论来自于 showing Greedy 算法的本地优化性ERT：将一个点从 Greedy 解决中拿换一个未被 Greedy 选择的向量可以提高体积的因子为最多 $(1+\sqrt{k})$，这是准确到 $1$ 的上限。最后，我们的实验结果表明 Greedy 算法的本地优化性实际比 теоретиче上的 bound 低。
</details></li>
</ul>
<hr>
<h2 id="A-Physics-Enhanced-Residual-Learning-PERL-Framework-for-Traffic-State-Prediction"><a href="#A-Physics-Enhanced-Residual-Learning-PERL-Framework-for-Traffic-State-Prediction" class="headerlink" title="A Physics Enhanced Residual Learning (PERL) Framework for Traffic State Prediction"></a>A Physics Enhanced Residual Learning (PERL) Framework for Traffic State Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15284">http://arxiv.org/abs/2309.15284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keke Long, Haotian Shi, Zihao Sheng, Xiaopeng Li, Sikai Chen</li>
<li>for: 本文提出了一种新的框架，即物理增强剩余学习（PERL）模型，用于解决物理模型和数据驱动模型的矛盾。</li>
<li>methods: 本文使用了物理模型和剩余学习模型，并将其 integrate into a single model。该模型的预测结果为物理模型的结果加上一个预测的偏差。</li>
<li>results: 实验结果表明，PERL模型在小数据集上比物理模型、数据驱动模型和PINN模型更好地预测行驶轨迹。此外，PERL模型在训练过程中更快地 converges，需要 fewer training samples than data-driven model和PINN模型。<details>
<summary>Abstract</summary>
In vehicle trajectory prediction, physics models and data-driven models are two predominant methodologies. However, each approach presents its own set of challenges: physics models fall short in predictability, while data-driven models lack interpretability. Addressing these identified shortcomings, this paper proposes a novel framework, the Physics-Enhanced Residual Learning (PERL) model. PERL integrates the strengths of physics-based and data-driven methods for traffic state prediction. PERL contains a physics model and a residual learning model. Its prediction is the sum of the physics model result and a predicted residual as a correction to it. It preserves the interpretability inherent to physics-based models and has reduced data requirements compared to data-driven methods. Experiments were conducted using a real-world vehicle trajectory dataset. We proposed a PERL model, with the Intelligent Driver Model (IDM) as its physics car-following model and Long Short-Term Memory (LSTM) as its residual learning model. We compare this PERL model with the physics car-following model, data-driven model, and other physics-informed neural network (PINN) models. The result reveals that PERL achieves better prediction with a small dataset, compared to the physics model, data-driven model, and PINN model. Second, the PERL model showed faster convergence during training, offering comparable performance with fewer training samples than the data-driven model and PINN model. Sensitivity analysis also proves comparable performance of PERL using another residual learning model and a physics car-following model.
</details>
<details>
<summary>摘要</summary>
在车辆轨迹预测中，物理模型和数据驱动模型是两种主要的方法。然而，每个方法都有自己的缺点：物理模型对预测不够可靠，而数据驱动模型则缺乏解释性。为了解决这些缺点，这篇论文提出了一个新的框架，即物理增强遗传学习（PERL）模型。PERL结合了物理基础和数据驱动方法的优点，并提供了更好的车辆轨迹预测。PERL模型包括物理模型和遗传学习模型。其预测结果为物理模型的结果加上一个预测的差异。这样可以保留物理模型中的解释性，并且需要更少的数据。我们在实际的车辆轨迹数据集上进行了实验，比较了PERL模型与物理汽车追随模型、数据驱动模型和物理启发阶层神经网络（PINN）模型。结果显示，PERL模型在小数据集情况下表现更好，比物理模型、数据驱动模型和PINN模型更好。其次，PERL模型在训练过程中更快地趋向于平衡，需要更少的训练数据，与数据驱动模型和PINN模型相比。另外，对PERL模型使用不同的遗传学习模型和物理汽车追随模型进行了敏感性分析，结果显示PERL模型在不同的模型和物理模型下仍然具有良好的预测性。
</details></li>
</ul>
<hr>
<h2 id="Identifying-factors-associated-with-fast-visual-field-progression-in-patients-with-ocular-hypertension-based-on-unsupervised-machine-learning"><a href="#Identifying-factors-associated-with-fast-visual-field-progression-in-patients-with-ocular-hypertension-based-on-unsupervised-machine-learning" class="headerlink" title="Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning"></a>Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15867">http://arxiv.org/abs/2309.15867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoqin Huang, Asma Poursoroush, Jian Sun, Michael V. Boland, Chris Johnson, Siamak Yousefi</li>
<li>for: 本研究旨在透过不监督学习机器学习技术，确定 ocular hypertension (OHT) 的不同趋势型域视场 (VF) 进程，以及发现导致快速 VF 进程的因素。</li>
<li>methods: 研究使用了潜在类混合模型 (LCMM)，通过标准自动报测 (SAP) 的 mean deviation (MD) 轨迹，确定 OHT 个体的不同类型。基于基线测试中的人口、临床、视觉和VF 因素，我们characterized 每个类型。然后，我们使用一般估计方程 (GEE) 确定导致快速 VF 进程的因素，并对结果进行质量和量化的解释。</li>
<li>results: LCMM 模型发现了四个眼睛类型，每个类型的 MD 衰减趋势不同。794 个眼睛（25%）、1675 个眼睛（54%）、531 个眼睛（17%）和 133 个眼睛（4%）分别被分为 Improvers、Stables、Slow progressors 和 Fast progressors。这些类型的 MD 衰减平均值分别为 0.08、-0.06、-0.21 和 -0.45 dB&#x2F;年。快速 VF 进程相关的因素包括基线年龄、内分泌压力 (IOP)、 Pattern standard deviation (PSD) 和 refractive error (RE)，但是低于中央肋壁厚度 (CCT)。fast progression 与 calcium channel blockers、男性、心血管疾病历史、糖尿病历史、非洲裔美国人、心脏病历史、 migraine headaches 有关。<details>
<summary>Abstract</summary>
Purpose: To identify ocular hypertension (OHT) subtypes with different trends of visual field (VF) progression based on unsupervised machine learning and to discover factors associated with fast VF progression. Participants: A total of 3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with at least five follow-up VF tests were included in the study. Methods: We used a latent class mixed model (LCMM) to identify OHT subtypes using standard automated perimetry (SAP) mean deviation (MD) trajectories. We characterized the subtypes based on demographic, clinical, ocular, and VF factors at the baseline. We then identified factors driving fast VF progression using generalized estimating equation (GEE) and justified findings qualitatively and quantitatively. Results: The LCMM model discovered four clusters (subtypes) of eyes with different trajectories of MD worsening. The number of eyes in clusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the clusters as Improvers, Stables, Slow progressors, and Fast progressors based on their mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year, respectively. Eyes with fast VF progression had higher baseline age, intraocular pressure (IOP), pattern standard deviation (PSD) and refractive error (RE), but lower central corneal thickness (CCT). Fast progression was associated with calcium channel blockers, being male, heart disease history, diabetes history, African American race, stroke history, and migraine headaches.
</details>
<details>
<summary>摘要</summary>
目的：通过无监督机器学习发现 ocular hypertension (OHT) 的不同趋势视场（VF）进程 под型，并找到加速 VF 进程的因素。参与者：全部有 3133 个眼和 1568 名 ocular hypertension treatment study（OHTS）参与者，每个参与者至少有五次视场测试。方法：我们使用潜在类混合模型（LCMM）来发现 OHT 的不同 под型，使用标准自动测测（SAP）的 Mean Deviation（MD）轨迹。我们根据基线测试时的 демографи、临床、眼科和视场因素进行分类。然后，我们使用通用估计方法（GEE）来确定加速 VF 进程的因素，并证明发现的结论。结果：LCMM 模型发现了四种眼睛的不同趋势 MD 下降。这些群体的眼睛数量分别为 794（25%）、1675（54%）、531（17%）和 133（4%）。我们将这些群体分别命名为 Improvers、Stables、Slow progressors 和 Fast progressors，根据每个群体的 MD 下降的平均值。加速 VF 进程的眼睛具有更高的基线年龄、血压（IOP）、模式标准差（PSD）和视力错觉（RE），但更低的中央肾脏厚度（CCT）。加速 VF 进程与 calcium channel blockers、男性、心血管疾病历史、糖尿病历史、非洲裔美国人种、心血管疾病历史、 migraine 和头痛历史有关。
</details></li>
</ul>
<hr>
<h2 id="Method-and-Validation-for-Optimal-Lineup-Creation-for-Daily-Fantasy-Football-Using-Machine-Learning-and-Linear-Programming"><a href="#Method-and-Validation-for-Optimal-Lineup-Creation-for-Daily-Fantasy-Football-Using-Machine-Learning-and-Linear-Programming" class="headerlink" title="Method and Validation for Optimal Lineup Creation for Daily Fantasy Football Using Machine Learning and Linear Programming"></a>Method and Validation for Optimal Lineup Creation for Daily Fantasy Football Using Machine Learning and Linear Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15253">http://arxiv.org/abs/2309.15253</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph M. Mahoney, Tomasz B. Paniak</li>
<li>for: This paper aims to develop a method to forecast NFL player performance under uncertainty and determine an optimal lineup to maximize FPTS under a set salary limit.</li>
<li>methods: The paper uses a supervised learning neural network to project FPTS based on past player performance, and a mixed integer linear program to find the optimal lineup.</li>
<li>results: The optimal lineups outperformed randomly-created lineups on average, and fell in approximately the 31st percentile (median) compared to real-world lineups from users on DraftKings.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文的目的是开发一种能够在不确定性下预测NFL球员表现的方法，以及一种可以在一定的薪资上限下最大化FPTS的优化阵容。</li>
<li>methods: 这篇论文使用一种监督学习神经网络来预测FPTS，并使用杂合Integer Linear Programming来找到最优阵容。</li>
<li>results: 优化的阵容在 randomly-created 阵容的平均上赢得了比赛，并且与DraftKings上用户的真实阵容相比，通常在 Approximately 31st percentile (medians) 之间。<details>
<summary>Abstract</summary>
Daily fantasy sports (DFS) are weekly or daily online contests where real-game performances of individual players are converted to fantasy points (FPTS). Users select players for their lineup to maximize their FPTS within a set player salary cap. This paper focuses on (1) the development of a method to forecast NFL player performance under uncertainty and (2) determining an optimal lineup to maximize FPTS under a set salary limit. A supervised learning neural network was created and used to project FPTS based on past player performance (2018 NFL regular season for this work) prior to the upcoming week. These projected FPTS were used in a mixed integer linear program to find the optimal lineup. The performance of resultant lineups was compared to randomly-created lineups. On average, the optimal lineups outperformed the random lineups. The generated lineups were then compared to real-world lineups from users on DraftKings. The generated lineups generally fell in approximately the 31st percentile (median). The FPTS methods and predictions presented here can be further improved using this study as a baseline comparison.
</details>
<details>
<summary>摘要</summary>
每周或每天的在线日常体育竞技 (DFS) 是一种在线竞技平台， Users可以选择球员来增加他们的极限积分 (FPTS)，而不超过球员薪资限额。这篇论文将 concentrate on (1) 预测 NFL 球员表现的方法的开发和 (2) 根据薪资限额最大化 FPTS 的优补策略。一种以过去 NFL 赛季 (2018 赛季) 的球员表现数据进行预测的超vised 学习神经网络被创建并使用，以预测下一周的 FPTS。这些预测的 FPTS 然后被用在杂integer linear program中找到最佳阵容。结果的阵容与Randomly创建的阵容进行比较，并发现了最佳阵容的性能较高。然后，这些阵容与 DraftKings 上用户实际创建的阵容进行比较，并发现了这些阵容在approximately 31% 的位置 (中位数)。这种 FPTS 预测和方法可以在这个基准比较中进行进一步改进。
</details></li>
</ul>
<hr>
<h2 id="V2X-Lead-LiDAR-based-End-to-End-Autonomous-Driving-with-Vehicle-to-Everything-Communication-Integration"><a href="#V2X-Lead-LiDAR-based-End-to-End-Autonomous-Driving-with-Vehicle-to-Everything-Communication-Integration" class="headerlink" title="V2X-Lead: LiDAR-based End-to-End Autonomous Driving with Vehicle-to-Everything Communication Integration"></a>V2X-Lead: LiDAR-based End-to-End Autonomous Driving with Vehicle-to-Everything Communication Integration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15252">http://arxiv.org/abs/2309.15252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyun Deng, Yanjun Shi, Weiming Shen</li>
<li>for: 本研究提出了一种基于LiDAR的端到端自动驾驶方法，通过与所有东西（V2X）通信集成，解决城市化环境下杂化交通条件下的自动驾驶挑战。</li>
<li>methods: 提议方法利用了车辆上的LiDAR感知器和V2X通信数据进行融合处理，采用了无模型和离线学习（DRL）算法来训练驾驶代理人，并采用了精心设计的奖励函数和多任务学习技术来提高驾驶代理人的泛化性。</li>
<li>results: 实验结果表明，提议方法可以在杂化交通条件下 traverse不监控交叉路口时提高安全性和效率，并在不同的驾驶任务和场景中进行泛化。V2X通信的集成提供了让AV更好地感知周围环境的重要数据源，从而提高了驾驶行为的准确性和完整性。<details>
<summary>Abstract</summary>
This paper presents a LiDAR-based end-to-end autonomous driving method with Vehicle-to-Everything (V2X) communication integration, termed V2X-Lead, to address the challenges of navigating unregulated urban scenarios under mixed-autonomy traffic conditions. The proposed method aims to handle imperfect partial observations by fusing the onboard LiDAR sensor and V2X communication data. A model-free and off-policy deep reinforcement learning (DRL) algorithm is employed to train the driving agent, which incorporates a carefully designed reward function and multi-task learning technique to enhance generalization across diverse driving tasks and scenarios. Experimental results demonstrate the effectiveness of the proposed approach in improving safety and efficiency in the task of traversing unsignalized intersections in mixed-autonomy traffic, and its generalizability to previously unseen scenarios, such as roundabouts. The integration of V2X communication offers a significant data source for autonomous vehicles (AVs) to perceive their surroundings beyond onboard sensors, resulting in a more accurate and comprehensive perception of the driving environment and more safe and robust driving behavior.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Homotopy-Relaxation-Training-Algorithms-for-Infinite-Width-Two-Layer-ReLU-Neural-Networks"><a href="#Homotopy-Relaxation-Training-Algorithms-for-Infinite-Width-Two-Layer-ReLU-Neural-Networks" class="headerlink" title="Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks"></a>Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15244">http://arxiv.org/abs/2309.15244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yahong Yang, Qipin Chen, Wenrui Hao</li>
<li>for: 加速神经网络训练过程</li>
<li>methods: 提出了一种新的训练方法—Homotopy Relaxation Training Algorithm (HRTA)，通过连接线性活动函数和ReLU活动函数的homotopy活动函数，以及对训练精度进行放松来加速训练过程。</li>
<li>results: 经过对NTK上的深度神经网络的深入分析，显示HRTA可以提高训练速度的 convergence rates，特别是在宽度更大的神经网络中。实验结果也验证了理论结论。这种提出的HRTA具有在其他活动函数和深度神经网络中的潜在应用前景。<details>
<summary>Abstract</summary>
In this paper, we present a novel training approach called the Homotopy Relaxation Training Algorithm (HRTA), aimed at accelerating the training process in contrast to traditional methods. Our algorithm incorporates two key mechanisms: one involves building a homotopy activation function that seamlessly connects the linear activation function with the ReLU activation function; the other technique entails relaxing the homotopy parameter to enhance the training refinement process. We have conducted an in-depth analysis of this novel method within the context of the neural tangent kernel (NTK), revealing significantly improved convergence rates. Our experimental results, especially when considering networks with larger widths, validate the theoretical conclusions. This proposed HRTA exhibits the potential for other activation functions and deep neural networks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的训练方法，称为Homotopy Relaxation Training Algorithm（HRTA），目的是加速训练过程，而不是使用传统方法。我们的算法包含两个关键机制：一是建立一个连续函数 activation function，将线性 activation function 与 ReLU activation function 连续连接起来；另一个技术是通过放松 homotopy 参数来提高训练精度过程。我们在NTK 的背景下进行了深入的分析，发现该新方法可以提高训练速度。我们的实验结果，特别是考虑到大width 网络，证明了我们的理论结论。这种提出的 HRTA 具有潜在的应用前提，并不仅限于 activation functions 和深度神经网络。
</details></li>
</ul>
<hr>
<h2 id="Cross-Validation-for-Training-and-Testing-Co-occurrence-Network-Inference-Algorithms"><a href="#Cross-Validation-for-Training-and-Testing-Co-occurrence-Network-Inference-Algorithms" class="headerlink" title="Cross-Validation for Training and Testing Co-occurrence Network Inference Algorithms"></a>Cross-Validation for Training and Testing Co-occurrence Network Inference Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15225">http://arxiv.org/abs/2309.15225</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/EngineerDanny/CS685-Microbe-Network-Research-Code">https://github.com/EngineerDanny/CS685-Microbe-Network-Research-Code</a></li>
<li>paper_authors: Daniel Agyapong, Jeffrey Ryan Propster, Jane Marks, Toby Dylan Hocking</li>
<li>for: 本研究旨在提出一种新的评估维度网络推断算法的方法，以及应用现有算法预测测试数据。</li>
<li>methods: 本研究使用了现有的网络推断算法，并提出了一种新的评估方法来评估网络推断算法的质量。</li>
<li>results: 研究发现，提出的评估方法可以帮助选择最佳的网络推断算法和评估网络推断算法的质量。<details>
<summary>Abstract</summary>
Microorganisms are found in almost every environment, including the soil, water, air, and inside other organisms, like animals and plants. While some microorganisms cause diseases, most of them help in biological processes such as decomposition, fermentation and nutrient cycling. A lot of research has gone into studying microbial communities in various environments and how their interactions and relationships can provide insights into various diseases. Co-occurrence network inference algorithms help us understand the complex associations of micro-organisms, especially bacteria. Existing network inference algorithms employ techniques such as correlation, regularized linear regression, and conditional dependence, which have different hyper-parameters that determine the sparsity of the network. Previous methods for evaluating the quality of the inferred network include using external data, and network consistency across sub-samples, both which have several drawbacks that limit their applicability in real microbiome composition data sets. We propose a novel cross-validation method to evaluate co-occurrence network inference algorithms, and new methods for applying existing algorithms to predict on test data. Our empirical study shows that the proposed method is useful for hyper-parameter selection (training) and comparing the quality of the inferred networks between different algorithms (testing).
</details>
<details>
<summary>摘要</summary>
微生物可以在各种环境中找到，包括土壤、水、空气以及其他生物体内。虽然一些微生物会引起疾病，但大多数微生物帮助进行生物过程，如腐败、发酵和营养循环。研究微生物社区在不同环境中的相互作用和关系可以提供疾病研究的意义。存在的网络推理算法可以帮助我们理解微生物之间的复杂关系，特别是细菌。现有的网络推理算法使用技术如相关性、规则化线性回归和conditional dependence，它们的各种超参数会影响网络的稀畴程度。以前的评估推理网络质量的方法包括使用外部数据和网络在不同抽样下的一致性，但这些方法有一些缺点，限制它们在实际微生物组成数据集中的应用。我们提议一种新的验证方法来评估推理网络推理算法，以及新的方法来应用现有算法预测测试数据。我们的实验显示，我们的方法有用于权重选择（训练）和对不同算法预测测试数据的质量进行比较。
</details></li>
</ul>
<hr>
<h2 id="Auto-grading-C-programming-assignments-with-CodeBERT-and-Random-Forest-Regressor"><a href="#Auto-grading-C-programming-assignments-with-CodeBERT-and-Random-Forest-Regressor" class="headerlink" title="Auto-grading C programming assignments with CodeBERT and Random Forest Regressor"></a>Auto-grading C programming assignments with CodeBERT and Random Forest Regressor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15216">http://arxiv.org/abs/2309.15216</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roshan Vasu Muddaluru, Sharvaani Ravikumar Thoguluva, Shruti Prabha, Dr. Peeta Basa Pati, Ms. Roshni M Balakrishnan</li>
<li>for: 这个论文主要是为了描述如何使用深度学习自动评分编程作业，以减轻教师的评分负担，同时确保公正和有效的评分。</li>
<li>methods: 该论文使用了多种机器学习和深度学习方法，包括回归、卷积神经网络（CNN）和长短期记忆（LSTM），以及一种名为CodeBERT的代码基于转换器词嵌入模型。</li>
<li>results: 测试结果表明，使用该方法可以准确地评分C编程作业， Root Mean Squared Error（RMSE）为1.89。 这些结果表明，使用深度学习自动评分编程作业的方法比使用统计方法更有效。<details>
<summary>Abstract</summary>
Grading coding assignments manually is challenging due to complexity and subjectivity. However, auto-grading with deep learning simplifies the task. It objectively assesses code quality, detects errors, and assigns marks accurately, reducing the burden on instructors while ensuring efficient and fair assessment. This study provides an analysis of auto-grading of the C programming assignments using machine learning and deep learning approaches like regression, convolutional neural networks (CNN) and long short-term memory (LSTM). Using a code-based transformer word embedding model called CodeBERT, the textual code inputs were transformed into vectors, and the vectors were then fed into several models. The testing findings demonstrated the efficacy of the suggested strategy with a root mean squared error (RMSE) of 1.89. The contrast between statistical methods and deep learning techniques is discussed in the study.
</details>
<details>
<summary>摘要</summary>
“手动评分程式作业是具有复杂性和主观性的，但使用深度学习可以简化这个任务。它 объектив地评估程式的质量，检测错误，并将分数划分给学生，从而减轻教师的负担，同时确保了公正和有效的评估。本研究通过机器学习和深度学习方法（如回归、单调数网络和长期缓存）进行自动评分C语言作业的分析。使用一个称为CodeBERT的程式码基于词汇嵌入模型，将文字式程式码转换为向量，然后将向量输入到不同模型中进行评分。测试结果显示了建议的策略的有效性，RMSE为1.89。研究中也讨论了统计方法和深度学习技术之间的比较。”Note: "Simplified Chinese" refers to the standardized form of Chinese used in mainland China and Singapore, which is different from "Traditional Chinese" used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="Balancing-Computational-Efficiency-and-Forecast-Error-in-Machine-Learning-based-Time-Series-Forecasting-Insights-from-Live-Experiments-on-Meteorological-Nowcasting"><a href="#Balancing-Computational-Efficiency-and-Forecast-Error-in-Machine-Learning-based-Time-Series-Forecasting-Insights-from-Live-Experiments-on-Meteorological-Nowcasting" class="headerlink" title="Balancing Computational Efficiency and Forecast Error in Machine Learning-based Time-Series Forecasting: Insights from Live Experiments on Meteorological Nowcasting"></a>Balancing Computational Efficiency and Forecast Error in Machine Learning-based Time-Series Forecasting: Insights from Live Experiments on Meteorological Nowcasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15207">http://arxiv.org/abs/2309.15207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elin Törnquist, Wagner Costa Santos, Timothy Pogue, Nicholas Wingle, Robert A. Caulk<br>for:This paper aims to explore the relationship between computational cost and forecast error in machine learning-based time-series forecasting, using meteorological nowcasting as an example.methods:The paper employs various popular regression techniques, including XGBoost, FC-MLP, Transformer, and LSTM, for multi-horizon, short-term forecasting of temperature, wind speed, and cloud cover at multiple locations. The authors also propose two computational cost minimization methods: a novel auto-adaptive data reduction technique called Variance Horizon and a performance-based concept drift-detection mechanism.results:The results show that using the Variance Horizon technique can reduce computational usage by more than 50%, while increasing forecast error by up to 15%. Meanwhile, performance-based retraining can reduce computational usage by up to 90%, while improving forecast error by up to 10%. The combination of both techniques outperformed other model configurations by up to 99.7% when considering error normalized to computational usage.<details>
<summary>Abstract</summary>
Machine learning for time-series forecasting remains a key area of research. Despite successful application of many machine learning techniques, relating computational efficiency to forecast error remains an under-explored domain. This paper addresses this topic through a series of real-time experiments to quantify the relationship between computational cost and forecast error using meteorological nowcasting as an example use-case. We employ a variety of popular regression techniques (XGBoost, FC-MLP, Transformer, and LSTM) for multi-horizon, short-term forecasting of three variables (temperature, wind speed, and cloud cover) for multiple locations. During a 5-day live experiment, 4000 data sources were streamed for training and inferencing 144 models per hour. These models were parameterized to explore forecast error for two computational cost minimization methods: a novel auto-adaptive data reduction technique (Variance Horizon) and a performance-based concept drift-detection mechanism. Forecast error of all model variations were benchmarked in real-time against a state-of-the-art numerical weather prediction model. Performance was assessed using classical and novel evaluation metrics. Results indicate that using the Variance Horizon reduced computational usage by more than 50\%, while increasing between 0-15\% in error. Meanwhile, performance-based retraining reduced computational usage by up to 90\% while \emph{also} improving forecast error by up to 10\%. Finally, the combination of both the Variance Horizon and performance-based retraining outperformed other model configurations by up to 99.7\% when considering error normalized to computational usage.
</details>
<details>
<summary>摘要</summary>
“机器学习 для时间序列预测仍然是研究领域的关键领域。尽管许多机器学习技术已经得到成功应用，但将计算效率与预测误差之间的关系进行研究仍然是一个未探索的领域。这篇论文通过一系列实时实验来评估这个问题，使用天气预报为例子应用场景。我们使用了多种流行的回归技术（XGBoost、FC-MLP、Transformer和LSTM）进行多个地点的多时间档期预测温度、风速和云覆盖率。在5天的实验中，我们流动了4000个数据源，每小时训练和推断144个模型。这些模型被参数化以探索预测误差的两种计算成本减少方法：一种新的自适应数据减少技术（Variance Horizon）和一种基于性能的概念漂移检测机制。所有模型变化的预测误差都在实时比较之前的状态艺术天气预报模型。我们使用了传统和新的评价指标来评估性能。结果表明，使用Variance Horizon可以降低计算使用率超过50%，而预测误差也在0-15%之间增加。同时，基于性能的重新训练可以降低计算使用率达到90%，而同时也提高预测误差达到10%。最后，将Variance Horizon和基于性能的重新训练结合使用的模型在计算使用率normalized预测误差方面表现出色，高达99.7%。”
</details></li>
</ul>
<hr>
<h2 id="ICML-2023-Topological-Deep-Learning-Challenge-Design-and-Results"><a href="#ICML-2023-Topological-Deep-Learning-Challenge-Design-and-Results" class="headerlink" title="ICML 2023 Topological Deep Learning Challenge : Design and Results"></a>ICML 2023 Topological Deep Learning Challenge : Design and Results</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15188">http://arxiv.org/abs/2309.15188</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pyt-team/topomodelx">https://github.com/pyt-team/topomodelx</a></li>
<li>paper_authors: Mathilde Papillon, Mustafa Hajij, Florian Frantzen, Josef Hoppe, Helen Jenne, Johan Mathe, Audun Myers, Theodore Papamarkou, Michael T. Schaub, Ghada Zamzmi, Tolga Birdal, Tamal Dey, Tim Doster, Tegan Emerson, Gurusankar Gopalakrishnan, Devendra Govil, Vincent Grande, Aldo Guzmán-Sáenz, Henry Kvinge, Neal Livesay, Jan Meisner, Soham Mukherjee, Shreyas N. Samaga, Karthikeyan Natesan Ramamurthy, Maneel Reddy Karri, Paul Rosen, Sophia Sanborn, Michael Scholkemper, Robin Walters, Jens Agerberg, Georg Bökman, Sadrodin Barikbin, Claudio Battiloro, Gleb Bazhenov, Guillermo Bernardez, Aiden Brent, Sergio Escalera, Simone Fiorellino, Dmitrii Gavrilev, Mohammed Hassanin, Paul Häusner, Odin Hoff Gardaa, Abdelwahed Khamis, Manuel Lecha, German Magai, Tatiana Malygina, Pavlo Melnyk, Rubén Ballester, Kalyan Nadimpalli, Alexander Nikitin, Abraham Rabinowitz, Alessandro Salatiello, Simone Scardapane, Luca Scofano, Suraj Singh, Jens Sjölund, Pavel Snopov, Indro Spinelli, Lev Telyatnikov, Lucia Testa, Maosheng Yang, Yixiao Yue, Olga Zaghen, Ali Zia, Nina Miolane</li>
<li>for: 本研究是一项计算挑战，探讨了拓扑深度学习的计算问题。</li>
<li>methods: 本研究使用了开源的Python包TopoNetX和TopoModelX进行数据处理和深度学习。</li>
<li>results: 研究得到了28个合格的提交，并summarizes了挑战的主要发现。<details>
<summary>Abstract</summary>
This paper presents the computational challenge on topological deep learning that was hosted within the ICML 2023 Workshop on Topology and Geometry in Machine Learning. The competition asked participants to provide open-source implementations of topological neural networks from the literature by contributing to the python packages TopoNetX (data processing) and TopoModelX (deep learning). The challenge attracted twenty-eight qualifying submissions in its two-month duration. This paper describes the design of the challenge and summarizes its main findings.
</details>
<details>
<summary>摘要</summary>
Note:*  topological neural networks 改为  topological deep learning*  data processing 改为 数据处理*  deep learning 改为 深度学习
</details></li>
</ul>
<hr>
<h2 id="Monitoring-Machine-Learning-Models-Online-Detection-of-Relevant-Deviations"><a href="#Monitoring-Machine-Learning-Models-Online-Detection-of-Relevant-Deviations" class="headerlink" title="Monitoring Machine Learning Models: Online Detection of Relevant Deviations"></a>Monitoring Machine Learning Models: Online Detection of Relevant Deviations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15187">http://arxiv.org/abs/2309.15187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian Heinrichs</li>
<li>for: 本研究旨在提供一种可靠地检测机器学习模型性能下降的方法，以维护模型的可靠性。</li>
<li>methods: 本研究提议一种顺序监测方案，通过考虑时间依赖性来减少不必要的警报和多测试问题。</li>
<li>results: 实验结果表明，本方法可以更好地检测机器学习模型性能下降，比 benchmark 方法更有效。<details>
<summary>Abstract</summary>
Machine learning models are essential tools in various domains, but their performance can degrade over time due to changes in data distribution or other factors. On one hand, detecting and addressing such degradations is crucial for maintaining the models' reliability. On the other hand, given enough data, any arbitrary small change of quality can be detected. As interventions, such as model re-training or replacement, can be expensive, we argue that they should only be carried out when changes exceed a given threshold. We propose a sequential monitoring scheme to detect these relevant changes. The proposed method reduces unnecessary alerts and overcomes the multiple testing problem by accounting for temporal dependence of the measured model quality. Conditions for consistency and specified asymptotic levels are provided. Empirical validation using simulated and real data demonstrates the superiority of our approach in detecting relevant changes in model quality compared to benchmark methods. Our research contributes a practical solution for distinguishing between minor fluctuations and meaningful degradations in machine learning model performance, ensuring their reliability in dynamic environments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SGD-Finds-then-Tunes-Features-in-Two-Layer-Neural-Networks-with-near-Optimal-Sample-Complexity-A-Case-Study-in-the-XOR-problem"><a href="#SGD-Finds-then-Tunes-Features-in-Two-Layer-Neural-Networks-with-near-Optimal-Sample-Complexity-A-Case-Study-in-the-XOR-problem" class="headerlink" title="SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem"></a>SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15111">http://arxiv.org/abs/2309.15111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Margalit Glasgow</li>
<li>for: 这个论文研究了使用小批量随机梯度下降（SGD）来有效地学习二层神经网络。</li>
<li>methods: 论文使用了标准的SGD算法和Logistic损失函数来训练神经网络。同时，论文同时训练了两层神经网络的两个层。</li>
<li>results: 论文证明了，当数据来自$d$维布尔体系，使用$d$个polylog($d$)样本来训练二层神经网络，可以达到 populaion error $o(1)$。这是首次有人提供了$\tilde{O}(d)$的样本复杂度来有效地学习XOR函数在标准神经网络上。<details>
<summary>Abstract</summary>
In this work, we consider the optimization process of minibatch stochastic gradient descent (SGD) on a 2-layer neural network with data separated by a quadratic ground truth function. We prove that with data drawn from the $d$-dimensional Boolean hypercube labeled by the quadratic ``XOR'' function $y = -x_ix_j$, it is possible to train to a population error $o(1)$ with $d \:\text{polylog}(d)$ samples. Our result considers simultaneously training both layers of the two-layer-neural network with ReLU activations via standard minibatch SGD on the logistic loss. To our knowledge, this work is the first to give a sample complexity of $\tilde{O}(d)$ for efficiently learning the XOR function on isotropic data on a standard neural network with standard training. Our main technique is showing that the network evolves in two phases: a $\textit{signal-finding}$ phase where the network is small and many of the neurons evolve independently to find features, and a $\textit{signal-heavy}$ phase, where SGD maintains and balances the features. We leverage the simultaneous training of the layers to show that it is sufficient for only a small fraction of the neurons to learn features, since those neurons will be amplified by the simultaneous growth of their second layer weights.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们考虑了批处理式随机梯度下降（SGD）在二层神经网络上的优化过程。我们证明了，当数据来自 $d$ 维布尔多面体，并且标注为 quadratic “XOR” 函数 $y = -x_ix_j$，然后可以在 $d$ 个polylog（d）样本上培养到 population error $o(1)$。我们的结果同时考虑了两层神经网络中的两个层的标准批处理SGD的训练。根据我们所知，这是首次为效率地学习 XOR 函数在各向同性数据上的标准神经网络进行 $\tilde{O}(d)$ 样本的证明。我们的主要技巧是显示网络在两个阶段中进行发展：一个 $\textit{signal-finding}$ 阶段，在这个阶段，网络很小，许多神经元独立地找到特征；另一个 $\textit{signal-heavy}$ 阶段，SGD在维护和平衡特征。我们利用同时训练层的技巧，显示只需要一小部分神经元学习特征，因为这些神经元将在同时增长其第二层权重时被扩大。
</details></li>
</ul>
<hr>
<h2 id="Fixing-the-NTK-From-Neural-Network-Linearizations-to-Exact-Convex-Programs"><a href="#Fixing-the-NTK-From-Neural-Network-Linearizations-to-Exact-Convex-Programs" class="headerlink" title="Fixing the NTK: From Neural Network Linearizations to Exact Convex Programs"></a>Fixing the NTK: From Neural Network Linearizations to Exact Convex Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15096">http://arxiv.org/abs/2309.15096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajat Vadiraj Dwaraknath, Tolga Ergen, Mert Pilanci</li>
<li>for: 本研究探讨了深度神经网络的理论分析，具体来说是对SGD训练的推理和ReLU网络的正则化训练目标的全面优化。</li>
<li>methods: 本研究使用了多kernel学习（MKL）模型和迭代重量调整来解决深度神经网络的训练问题。</li>
<li>results: 研究发现，对于某些特定的掩码量，NTK不能在训练集上达到最佳性能，而MKL kernel则可以达到最佳性能。通过iterative reweighting，我们可以从NTK中获得最佳MKLkernel，并且提供了一些数值实验来证明我们的理论。<details>
<summary>Abstract</summary>
Recently, theoretical analyses of deep neural networks have broadly focused on two directions: 1) Providing insight into neural network training by SGD in the limit of infinite hidden-layer width and infinitesimally small learning rate (also known as gradient flow) via the Neural Tangent Kernel (NTK), and 2) Globally optimizing the regularized training objective via cone-constrained convex reformulations of ReLU networks. The latter research direction also yielded an alternative formulation of the ReLU network, called a gated ReLU network, that is globally optimizable via efficient unconstrained convex programs. In this work, we interpret the convex program for this gated ReLU network as a Multiple Kernel Learning (MKL) model with a weighted data masking feature map and establish a connection to the NTK. Specifically, we show that for a particular choice of mask weights that do not depend on the learning targets, this kernel is equivalent to the NTK of the gated ReLU network on the training data. A consequence of this lack of dependence on the targets is that the NTK cannot perform better than the optimal MKL kernel on the training set. By using iterative reweighting, we improve the weights induced by the NTK to obtain the optimal MKL kernel which is equivalent to the solution of the exact convex reformulation of the gated ReLU network. We also provide several numerical simulations corroborating our theory. Additionally, we provide an analysis of the prediction error of the resulting optimal kernel via consistency results for the group lasso.
</details>
<details>
<summary>摘要</summary>
近来，深度神经网络的理论分析主要集中在两个方向上：1）通过SGD训练在无穷层宽和学习率为零的极限下提供神经网络训练的洞察，使用神经 Tangent Kernel (NTK)；2）globally optimizing the regularized training objective via cone-constrained convex reformulations of ReLU networks。后者的研究方向还产生了一种称为闭合ReLU网络的代表形式，可以通过高效的无约束凸 програм序global optimiztion。在这个工作中，我们将这个凸程序解释为一种多重kernel学习（MKL）模型，并与NTK建立连接。具体来说，我们证明在某些掩码权重不виси于学习目标时，这个kernel与NTK相同，这个kernel是gated ReLU网络的NTK在训练数据上。由于这些掩码权重不виси于学习目标，NTK无法在训练集上做出更好的性能。通过迭代重新权重，我们可以改进由NTK引入的权重，以获得最佳的MKL kernel，这个kernel与gated ReLU网络的凸形式的正确解相同。我们还提供了一些数值实验证明我们的理论。此外，我们还提供了预测误差的分析，使用群集lasso的一致性结果。
</details></li>
</ul>
<hr>
<h2 id="Automated-Detection-of-Persistent-Inflammatory-Biomarkers-in-Post-COVID-19-Patients-Using-Machine-Learning-Techniques"><a href="#Automated-Detection-of-Persistent-Inflammatory-Biomarkers-in-Post-COVID-19-Patients-Using-Machine-Learning-Techniques" class="headerlink" title="Automated Detection of Persistent Inflammatory Biomarkers in Post-COVID-19 Patients Using Machine Learning Techniques"></a>Automated Detection of Persistent Inflammatory Biomarkers in Post-COVID-19 Patients Using Machine Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15838">http://arxiv.org/abs/2309.15838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ghizal Fatima, Fadhil G. Al-Amran, Maitham G. Yousif<br>for: 这份研究的目的是探索机器学习技术可以自动识别潜在的急性炎症生物 markers在 COVID-19 后期病人中，以提高医疗对病人的早期诊断和个性化治疗策略。methods: 这份研究使用了多种机器学习算法，包括逻辑回传、随机森林、支持向量机器和渐进提升，将资料进行了严格的数据预processing和特征选择，以便优化资料集供机器学习分析。results: 这份研究发现，使用机器学习技术可以实现高精度和确定性地自动识别 COVID-19 后期病人中的急性炎症生物 markers，并且这些模型可以作为医疗 provider 的有用工具，帮助早期诊断和个性化治疗策略，最终对 COVID-19 后期病人的康康和生活质量有所提高。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has left a lasting impact on individuals, with many experiencing persistent symptoms, including inflammation, in the post-acute phase of the disease. Detecting and monitoring these inflammatory biomarkers is critical for timely intervention and improved patient outcomes. This study employs machine learning techniques to automate the identification of persistent inflammatory biomarkers in 290 post-COVID-19 patients, based on medical data collected from hospitals in Iraq. The data encompassed a wide array of clinical parameters, such as C-reactive protein and interleukin-6 levels, patient demographics, comorbidities, and treatment histories. Rigorous data preprocessing and feature selection processes were implemented to optimize the dataset for machine learning analysis. Various machine learning algorithms, including logistic regression, random forests, support vector machines, and gradient boosting, were deployed to construct predictive models. These models exhibited promising results, showcasing high accuracy and precision in the identification of patients with persistent inflammation. The findings of this study underscore the potential of machine learning in automating the detection of persistent inflammatory biomarkers in post-COVID-19 patients. These models can serve as valuable tools for healthcare providers, facilitating early diagnosis and personalized treatment strategies for individuals at risk of persistent inflammation, ultimately contributing to improved post-acute COVID-19 care and patient well-being. Keywords: COVID-19, post-COVID-19, inflammation, biomarkers, machine learning, early detection.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行对个人有持续影响，许多人在后途期患有持续的发炎症状。检测和监测这些发炎生物标志是关键，以确定患者的病情和提高患者的结果。这项研究使用机器学习技术自动识别290名患上 COVID-19 后期的患者中的持续发炎生物标志，基于伊拉克医院收集的医疗数据。数据包括丰富的临床参数，如 C-反抗蛋白和Interleukin-6 水平、患者人口、相关疾病和治疗历史。经过严格的数据预处理和特征选择过程，以便优化数据集 для机器学习分析。不同的机器学习算法，包括逻辑回归、Random Forest、支持向量机和梯度提升，被部署来构建预测模型。这些模型表现出色，展现了高精度和准确性在识别持续发炎患者方面。这些发现反映了机器学习在自动识别持续发炎生物标志方面的潜在潜力。这些模型可以作为医疗提供者的有价值工具，帮助早期诊断和个性化治疗策略，以提高后途期 COVID-19 患者的健康状况。关键词：COVID-19, 后途期 COVID-19, 发炎, 生物标志, 机器学习, 早期诊断.
</details></li>
</ul>
<hr>
<h2 id="Identifying-Simulation-Model-Through-Alternative-Techniques-for-a-Medical-Device-Assembly-Process"><a href="#Identifying-Simulation-Model-Through-Alternative-Techniques-for-a-Medical-Device-Assembly-Process" class="headerlink" title="Identifying Simulation Model Through Alternative Techniques for a Medical Device Assembly Process"></a>Identifying Simulation Model Through Alternative Techniques for a Medical Device Assembly Process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15094">http://arxiv.org/abs/2309.15094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatemeh Kakavandi</li>
<li>for: 这篇论文探讨了两种不同的方法来识别和估算生产过程模型，尤其是在医疗器械组装中关键的快照过程。</li>
<li>methods: 这两种方法分别使用spline函数和机器学习（ML）模型来识别模型。</li>
<li>results: 这些方法可以创建适应性强的模型，准确地表示快照过程，并且可以满足不同的enario。这些模型有助于进一步了解生产过程，帮助决策，特别当数据有限时。<details>
<summary>Abstract</summary>
This scientific paper explores two distinct approaches for identifying and approximating the simulation model, particularly in the context of the snap process crucial to medical device assembly. Simulation models play a pivotal role in providing engineers with insights into industrial processes, enabling experimentation and troubleshooting before physical assembly. However, their complexity often results in time-consuming computations.   To mitigate this complexity, we present two distinct methods for identifying simulation models: one utilizing Spline functions and the other harnessing Machine Learning (ML) models. Our goal is to create adaptable models that accurately represent the snap process and can accommodate diverse scenarios. Such models hold promise for enhancing process understanding and aiding in decision-making, especially when data availability is limited.
</details>
<details>
<summary>摘要</summary>
这篇科学论文探讨了两种不同的方法来识别和估算模拟模型，尤其是在医疗器械组装过程中的快照过程中。模拟模型在工程师获得工业过程的洞察力方面发挥着关键作用，允许他们在实际组装之前进行实验和排查。然而，它们的复杂性常常导致计算时间很长。为了缓解这种复杂性，我们提出了使用spline函数和机器学习（ML）模型来识别模拟模型的两种方法。我们的目标是创造一些适应性强的模型，能够准确地表示快照过程并适应多种情况。这些模型在数据有限情况下能够提供进程理解和决策支持。
</details></li>
</ul>
<hr>
<h2 id="Single-Biological-Neurons-as-Temporally-Precise-Spatio-Temporal-Pattern-Recognizers"><a href="#Single-Biological-Neurons-as-Temporally-Precise-Spatio-Temporal-Pattern-Recognizers" class="headerlink" title="Single Biological Neurons as Temporally Precise Spatio-Temporal Pattern Recognizers"></a>Single Biological Neurons as Temporally Precise Spatio-Temporal Pattern Recognizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15090">http://arxiv.org/abs/2309.15090</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Beniaguev</li>
<li>for: 本论文主要研究的中心思想是认为单个神经元在大脑应该被视为高精度的时间特征和空间特征 Pattern recognizer。</li>
<li>methods: 本论文使用了单个神经元的计算性质和生物学性质来探讨大脑中神经元之间的各种循环和信息编码方式。</li>
<li>results: 研究表明，单个神经元的计算特征有较大的系统级别影响，并且可以用简单可靠的学习规则来模拟大脑中的非线性XOR操作。<details>
<summary>Abstract</summary>
This PhD thesis is focused on the central idea that single neurons in the brain should be regarded as temporally precise and highly complex spatio-temporal pattern recognizers. This is opposed to the prevalent view of biological neurons as simple and mainly spatial pattern recognizers by most neuroscientists today. In this thesis, I will attempt to demonstrate that this is an important distinction, predominantly because the above-mentioned computational properties of single neurons have far-reaching implications with respect to the various brain circuits that neurons compose, and on how information is encoded by neuronal activity in the brain. Namely, that these particular "low-level" details at the single neuron level have substantial system-wide ramifications. In the introduction we will highlight the main components that comprise a neural microcircuit that can perform useful computations and illustrate the inter-dependence of these components from a system perspective. In chapter 1 we discuss the great complexity of the spatio-temporal input-output relationship of cortical neurons that are the result of morphological structure and biophysical properties of the neuron. In chapter 2 we demonstrate that single neurons can generate temporally precise output patterns in response to specific spatio-temporal input patterns with a very simple biologically plausible learning rule. In chapter 3, we use the differentiable deep network analog of a realistic cortical neuron as a tool to approximate the gradient of the output of the neuron with respect to its input and use this capability in an attempt to teach the neuron to perform nonlinear XOR operation. In chapter 4 we expand chapter 3 to describe extension of our ideas to neuronal networks composed of many realistic biological spiking neurons that represent either small microcircuits or entire brain regions.
</details>
<details>
<summary>摘要</summary>
这个博士论文主要关注的中心思想是：单个神经元在脑中应该被视为高精度的空间-时间模式识别器，而不是现在大多数神经科学家视为简单的空间模式识别器。在这个论文中，我会尝试证明这是一个重要的分别，因为单个神经元的计算属性在脑内部的各种神经细胞圈和信息编码方面具有广泛的系统性影响。在引言中，我们将高亮显示神经元微circuit中的主要组件，并 illustrate它们之间的互dependent关系从系统角度。在第一章中，我们讨论了触发区域中神经元的复杂的空间-时间输入-输出关系，这些关系是由神经元的形态结构和生物物理特性所导致。在第二章中，我们展示了单个神经元可以在特定的空间-时间输入模式下生成高精度的输出模式，使用了一种简单的生物可能的学习规则。在第三章中，我们使用一个可微分的深度网络模型来估算神经元输出的梯度，并使用这种能力来教育神经元执行非线性XOR操作。在第四章中，我们扩展了上述想法，描述了使用多个真实生物快速射精神神经元组成的神经网络，代表了小微circuit或整个脑区域。
</details></li>
</ul>
<hr>
<h2 id="On-Excess-Risk-Convergence-Rates-of-Neural-Network-Classifiers"><a href="#On-Excess-Risk-Convergence-Rates-of-Neural-Network-Classifiers" class="headerlink" title="On Excess Risk Convergence Rates of Neural Network Classifiers"></a>On Excess Risk Convergence Rates of Neural Network Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15075">http://arxiv.org/abs/2309.15075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunouk Ko, Namjoon Suh, Xiaoming Huo</li>
<li>for: This paper studies the performance of plug-in classifiers based on neural networks in a binary classification setting, with a focus on their excess risks.</li>
<li>methods: The paper uses a more general scenario that resembles actual practice, with the function class including the Barron functions as a proper subset, and the neural network classifier is constructed as the minimizer of a surrogate loss.</li>
<li>results: The paper obtains a dimension-free, uniform rate of convergence for the excess risk, and shows that the rate is minimax optimal up to a logarithmic factor. The paper also demonstrates the effect of the margin assumption in this regime.<details>
<summary>Abstract</summary>
The recent success of neural networks in pattern recognition and classification problems suggests that neural networks possess qualities distinct from other more classical classifiers such as SVMs or boosting classifiers. This paper studies the performance of plug-in classifiers based on neural networks in a binary classification setting as measured by their excess risks. Compared to the typical settings imposed in the literature, we consider a more general scenario that resembles actual practice in two respects: first, the function class to be approximated includes the Barron functions as a proper subset, and second, the neural network classifier constructed is the minimizer of a surrogate loss instead of the $0$-$1$ loss so that gradient descent-based numerical optimizations can be easily applied. While the class of functions we consider is quite large that optimal rates cannot be faster than $n^{-\frac{1}{3}$, it is a regime in which dimension-free rates are possible and approximation power of neural networks can be taken advantage of. In particular, we analyze the estimation and approximation properties of neural networks to obtain a dimension-free, uniform rate of convergence for the excess risk. Finally, we show that the rate obtained is in fact minimax optimal up to a logarithmic factor, and the minimax lower bound shows the effect of the margin assumption in this regime.
</details>
<details>
<summary>摘要</summary>
近期，神经网络在图像识别和分类问题中的成功表明了神经网络具有与传统分类器不同的特点。这篇论文研究基于神经网络的插入分类器在二分类 Setting 中的性能，并且使用过程损失来衡量其剩余风险。与文献中常见的设定相比，我们在两个方面进行了更加实际的设定：首先，函数类型包括Barron函数作为一个 Correct 子集，其次，使用surrogate损失函数来构建神经网络分类器，以便使用梯度下降的数值优化。尽管我们考虑的函数集是非常大，但是我们可以在这个 regime 中获得约度独立的速度，并且利用神经网络的近似能力。特别是，我们分析神经网络的估计和抽象性特性，以获得约度独立的异常速度。最后，我们证明了获得的速度实际上是最优的，并且显示了margin假设在这个regime中的效果。
</details></li>
</ul>
<hr>
<h2 id="Targeting-Relative-Risk-Heterogeneity-with-Causal-Forests"><a href="#Targeting-Relative-Risk-Heterogeneity-with-Causal-Forests" class="headerlink" title="Targeting Relative Risk Heterogeneity with Causal Forests"></a>Targeting Relative Risk Heterogeneity with Causal Forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15793">http://arxiv.org/abs/2309.15793</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vshirvaikar/rrcf">https://github.com/vshirvaikar/rrcf</a></li>
<li>paper_authors: Vik Shirvaikar, Chris Holmes</li>
<li>for:  This paper focuses on the problem of treatment effect heterogeneity (TEH) in clinical trial analysis, and proposes a method for modifying causal forests to target relative risk using a novel node-splitting procedure based on generalized linear model (GLM) comparison.</li>
<li>methods: The proposed method uses a modified version of causal forests, which is a highly popular method for detecting TEH, but with a focus on relative risk instead of absolute risk. The method uses a novel node-splitting procedure based on GLM comparison to capture nuance in the relative risk.</li>
<li>results: The results of the paper show that the proposed relative risk causal forests method can capture otherwise unobserved sources of heterogeneity, as demonstrated on simulated and real-world data.<details>
<summary>Abstract</summary>
Treatment effect heterogeneity (TEH), or variability in treatment effect for different subgroups within a population, is of significant interest in clinical trial analysis. Causal forests (Wager and Athey, 2018) is a highly popular method for this problem, but like many other methods for detecting TEH, its criterion for separating subgroups focuses on differences in absolute risk. This can dilute statistical power by masking nuance in the relative risk, which is often a more appropriate quantity of clinical interest. In this work, we propose and implement a methodology for modifying causal forests to target relative risk using a novel node-splitting procedure based on generalized linear model (GLM) comparison. We present results on simulated and real-world data that suggest relative risk causal forests can capture otherwise unobserved sources of heterogeneity.
</details>
<details>
<summary>摘要</summary>
клиниче观察数据分析中，受试者群体内部效果差异（TEH）的研究具有重要意义。 causal forests（Wager和Athey，2018）是这种问题的高度流行方法，但与其他TEH检测方法一样，它的分组标准是基于绝对风险的差异。这可能会削弱统计能力，因为它会隐藏对积分风险的细节，这通常是临床兴趣的量。在这种工作中，我们提议和实现了一种修改 causal forests 以target相对风险的方法，使用一种基于泛化线性模型（GLM）的新的节点拆分方法。我们在模拟和实际数据上的结果表明，相对风险 causal forests 可以捕捉到其他不可见的差异源。
</details></li>
</ul>
<hr>
<h2 id="QUILT-Effective-Multi-Class-Classification-on-Quantum-Computers-Using-an-Ensemble-of-Diverse-Quantum-Classifiers"><a href="#QUILT-Effective-Multi-Class-Classification-on-Quantum-Computers-Using-an-Ensemble-of-Diverse-Quantum-Classifiers" class="headerlink" title="QUILT: Effective Multi-Class Classification on Quantum Computers Using an Ensemble of Diverse Quantum Classifiers"></a>QUILT: Effective Multi-Class Classification on Quantum Computers Using an Ensemble of Diverse Quantum Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15056">http://arxiv.org/abs/2309.15056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Silver, Tirthak Patel, Devesh Tiwari</li>
<li>for: 这篇论文是用于描述一个名为 Quilt 的框架，用于进行多类别分类任务，并且能够在现有的误差多的量子计算机上进行有效运行。</li>
<li>methods: 这篇论文使用了量子计算机上的误差多的状况，并且使用了一些特别的算法来实现多类别分类任务。</li>
<li>results: 根据论文的报告，使用 Quilt 框架进行多类别分类任务，可以在现有的五边系统上达到85%的准确率，使用 MNIST 数据集。<details>
<summary>Abstract</summary>
Quantum computers can theoretically have significant acceleration over classical computers; but, the near-future era of quantum computing is limited due to small number of qubits that are also error prone. Quilt is a framework for performing multi-class classification task designed to work effectively on current error-prone quantum computers. Quilt is evaluated with real quantum machines as well as with projected noise levels as quantum machines become more noise-free. Quilt demonstrates up to 85% multi-class classification accuracy with the MNIST dataset on a five-qubit system.
</details>
<details>
<summary>摘要</summary>
量子计算机在理论上可能具有显著的加速效果比经典计算机更快;但是，近期量子计算机的时代受到有限的量子比特数和错误率的限制。Quilt是一个用于实现多类分类任务的框架，针对当前的错误率量子计算机进行设计。Quilt在真正的量子机器上以及预计的噪声水平下进行评估。Quilt在MNIST数据集上的五个量子比特系统上达到85%多类分类精度。
</details></li>
</ul>
<hr>
<h2 id="Synthia’s-Melody-A-Benchmark-Framework-for-Unsupervised-Domain-Adaptation-in-Audio"><a href="#Synthia’s-Melody-A-Benchmark-Framework-for-Unsupervised-Domain-Adaptation-in-Audio" class="headerlink" title="Synthia’s Melody: A Benchmark Framework for Unsupervised Domain Adaptation in Audio"></a>Synthia’s Melody: A Benchmark Framework for Unsupervised Domain Adaptation in Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15024">http://arxiv.org/abs/2309.15024</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cynthpie/synthia_melody">https://github.com/cynthpie/synthia_melody</a></li>
<li>paper_authors: Chia-Hsin Lin, Charles Jones, Björn W. Schuller, Harry Coppock</li>
<li>for: 本研究的目的是提供一个不受观察 bias 的音频数据生成框架，用于测试音频深度学习模型对不同水平的分布偏移的抵抗力。</li>
<li>methods: 该研究使用了一种新的数据生成框架 called Synthia’s melody，可以生成具有用户指定的障碍结构的无数种4秒钢琴 melody。</li>
<li>results: 经测试表明，Synthia’s melody 可以提供一个不受 observation bias 的测试环境，用于评估音频深度学习模型对分布偏移的抵抗力。<details>
<summary>Abstract</summary>
Despite significant advancements in deep learning for vision and natural language, unsupervised domain adaptation in audio remains relatively unexplored. We, in part, attribute this to the lack of an appropriate benchmark dataset. To address this gap, we present Synthia's melody, a novel audio data generation framework capable of simulating an infinite variety of 4-second melodies with user-specified confounding structures characterised by musical keys, timbre, and loudness. Unlike existing datasets collected under observational settings, Synthia's melody is free of unobserved biases, ensuring the reproducibility and comparability of experiments. To showcase its utility, we generate two types of distribution shifts-domain shift and sample selection bias-and evaluate the performance of acoustic deep learning models under these shifts. Our evaluations reveal that Synthia's melody provides a robust testbed for examining the susceptibility of these models to varying levels of distribution shift.
</details>
<details>
<summary>摘要</summary>
尽管深度学习在视觉和自然语言领域取得了 significative 进步，但无监督频谱适应仍然相对未explored。我们认为这是因为缺乏适当的标准 benchmark 数据集。为了填补这个遗漏，我们提出了 Synthia 的旋律，一种新的音频数据生成框架，可以生成无数个 4 秒旋律，并且可以根据用户指定的隐藏结构（音频键、 timbre 和响度）进行定制。不同于现有的观察型数据集，Synthia 的旋律不受不观察到的偏见影响，因此可以保证实验的重复性和比较性。为了展示其 utility，我们生成了两种类型的分布转移-频谱转移和样本选择偏见-并评估了这些模型在这些转移下的性能。我们的评估结果表明，Synthia 的旋律提供了一个可靠的测试床 для检验这些模型对不同水平的分布转移的抗性。
</details></li>
</ul>
<hr>
<h2 id="Tempo-Adaptation-in-Non-stationary-Reinforcement-Learning"><a href="#Tempo-Adaptation-in-Non-stationary-Reinforcement-Learning" class="headerlink" title="Tempo Adaptation in Non-stationary Reinforcement Learning"></a>Tempo Adaptation in Non-stationary Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14989">http://arxiv.org/abs/2309.14989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunin Lee, Yuhao Ding, Jongmin Lee, Ming Jin, Javad Lavaei, Somayeh Sojoudi</li>
<li>for: 解决非站点RL中时间同步问题，提高RL在实际应用中的可行性。</li>
<li>methods: 提出了一种名为Proactively Synchronizing Tempo（$\texttt{ProST}$）框架，通过计算一个子优化的时间序列({$t_{1:K}$})来最小化动态 regret。</li>
<li>results: 实验证明，$\texttt{ProST}$框架在多维非站点环境中实现了较高的在线返点，并且比既有方法更具有可行性。<details>
<summary>Abstract</summary>
We first raise and tackle a ``time synchronization'' issue between the agent and the environment in non-stationary reinforcement learning (RL), a crucial factor hindering its real-world applications. In reality, environmental changes occur over wall-clock time ($t$) rather than episode progress ($k$), where wall-clock time signifies the actual elapsed time within the fixed duration $t \in [0, T]$. In existing works, at episode $k$, the agent rolls a trajectory and trains a policy before transitioning to episode $k+1$. In the context of the time-desynchronized environment, however, the agent at time $t_{k}$ allocates $\Delta t$ for trajectory generation and training, subsequently moves to the next episode at $t_{k+1}=t_{k}+\Delta t$. Despite a fixed total number of episodes ($K$), the agent accumulates different trajectories influenced by the choice of interaction times ($t_1,t_2,...,t_K$), significantly impacting the suboptimality gap of the policy. We propose a Proactively Synchronizing Tempo ($\texttt{ProST}$) framework that computes a suboptimal sequence {$t_1,t_2,...,t_K$} (= { $t_{1:K}$}) by minimizing an upper bound on its performance measure, i.e., the dynamic regret. Our main contribution is that we show that a suboptimal {$t_{1:K}$} trades-off between the policy training time (agent tempo) and how fast the environment changes (environment tempo). Theoretically, this work develops a suboptimal {$t_{1:K}$} as a function of the degree of the environment's non-stationarity while also achieving a sublinear dynamic regret. Our experimental evaluation on various high-dimensional non-stationary environments shows that the $\texttt{ProST}$ framework achieves a higher online return at suboptimal {$t_{1:K}$} than the existing methods.
</details>
<details>
<summary>摘要</summary>
我们首先面临到非站点学习（RL）中的时间同步问题，这是实际应用中的一个关键因素。在实际情况下，环境变化发生在墙上时间（$t$)而不是 episodenumber（$k$)，即墙上时间表示实际过去的时间在固定时间段[$0,T$]中。现有的方法在每个 episodenumber $k$ 中，Agent在 $k$  episodenumber 中生成 trajectory 并训练策略，然后在 $k+1$  episodenumber 中继续。但在时间不同步的环境中，Agent 在 $t_k$  allocate $\Delta t$  для trajectory 生成和策略训练，然后在 $t_{k+1} = t_k + \Delta t$ 中移动到下一个 episodenumber。尽管有固定的总集数 ($K$)，但 Agent 在不同的交互时间 ($t_1, t_2, ..., t_K$) 中收集了不同的 trajectory，这会对策略的优化差值产生显著的影响。我们提出了一个名为 Proactively Synchronizing Tempo（ $\texttt{ProST}$）框架，该框架计算一个不优的序列 {$t_1, t_2, ..., t_K$} (= { $t_{1:K}$})，以降低动态 regret的上限。我们的主要贡献在于我们显示了一个不优的 {$t_{1:K}$} 与策略训练时间（Agent 的拍弹）和环境变化速度（环境的拍弹）之间存在交易关系。理论上，这种工作在环境的非站点性程度的度量下计算出一个不优的 {$t_{1:K}$}，并实现了对动态 regret的下降。我们在高维非站点环境中进行了多个实验，结果表明，$\texttt{ProST}$ 框架在不优的 {$t_{1:K}$} 下实现了更高的在线返回。
</details></li>
</ul>
<hr>
<h2 id="Statistical-Analysis-of-Quantum-State-Learning-Process-in-Quantum-Neural-Networks"><a href="#Statistical-Analysis-of-Quantum-State-Learning-Process-in-Quantum-Neural-Networks" class="headerlink" title="Statistical Analysis of Quantum State Learning Process in Quantum Neural Networks"></a>Statistical Analysis of Quantum State Learning Process in Quantum Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14980">http://arxiv.org/abs/2309.14980</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenghongz/lim_learning_state">https://github.com/chenghongz/lim_learning_state</a></li>
<li>paper_authors: Hao-kai Zhang, Chenghong Zhu, Mingrui Jing, Xin Wang</li>
<li>for: 这篇论文旨在研究量子神经网络（QNNs）是否可以学习未知的量子状态，并证明在某些情况下，QNNs无法学习这种状态，即使从高精度的初始状态开始。</li>
<li>methods: 这篇论文使用了无果定理来证明，当损失值低于一定阈值时，QNNs 中的搜索空间内的概率会下降 exponentially  WITH  qubit 的数量，而只有 polynomial 增长 WITH  circuit 的深度。</li>
<li>results: 研究结果表明，QNNs 无法学习未知的量子状态，即使从高精度的初始状态开始，并且这种不可学习性与 circuit 的结构、初始化策略和 ansatz 无关。 数据 simulations  validate 了我们的理论结果。这些结果对 QNNs 的可学习性和扩展性带来了限制，同时深入了量子神经网络中备忘的优先知识的作用。<details>
<summary>Abstract</summary>
Quantum neural networks (QNNs) have been a promising framework in pursuing near-term quantum advantage in various fields, where many applications can be viewed as learning a quantum state that encodes useful data. As a quantum analog of probability distribution learning, quantum state learning is theoretically and practically essential in quantum machine learning. In this paper, we develop a no-go theorem for learning an unknown quantum state with QNNs even starting from a high-fidelity initial state. We prove that when the loss value is lower than a critical threshold, the probability of avoiding local minima vanishes exponentially with the qubit count, while only grows polynomially with the circuit depth. The curvature of local minima is concentrated to the quantum Fisher information times a loss-dependent constant, which characterizes the sensibility of the output state with respect to parameters in QNNs. These results hold for any circuit structures, initialization strategies, and work for both fixed ansatzes and adaptive methods. Extensive numerical simulations are performed to validate our theoretical results. Our findings place generic limits on good initial guesses and adaptive methods for improving the learnability and scalability of QNNs, and deepen the understanding of prior information's role in QNNs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Context-Aware-Generative-Models-for-Prediction-of-Aircraft-Ground-Tracks"><a href="#Context-Aware-Generative-Models-for-Prediction-of-Aircraft-Ground-Tracks" class="headerlink" title="Context-Aware Generative Models for Prediction of Aircraft Ground Tracks"></a>Context-Aware Generative Models for Prediction of Aircraft Ground Tracks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14957">http://arxiv.org/abs/2309.14957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nick Pepper, George De Ath, Marc Thomas, Richard Everson, Tim Dodwell</li>
<li>for: 支持航空交通管理者（ATCO）决策的 trajectory prediction（TP）扮演着重要的角色。</li>
<li>methods: 这项工作提出了一种生成方法，使用机器学习的概率模型来考虑飞机飞行轨迹中的epistemicuncertainty，即пилот行为和ATCO意图的不确定性。</li>
<li>results: 使用一周的英国上空航空Surveillance数据进行训练和测试，研究发现，使用bayesian neural network和Laplaceapproximation的模型可以生成最有可能性的轨迹，以便模拟航空交通的流动。<details>
<summary>Abstract</summary>
Trajectory prediction (TP) plays an important role in supporting the decision-making of Air Traffic Controllers (ATCOs). Traditional TP methods are deterministic and physics-based, with parameters that are calibrated using aircraft surveillance data harvested across the world. These models are, therefore, agnostic to the intentions of the pilots and ATCOs, which can have a significant effect on the observed trajectory, particularly in the lateral plane. This work proposes a generative method for lateral TP, using probabilistic machine learning to model the effect of the epistemic uncertainty arising from the unknown effect of pilot behaviour and ATCO intentions. The models are trained to be specific to a particular sector, allowing local procedures such as coordinated entry and exit points to be modelled. A dataset comprising a week's worth of aircraft surveillance data, passing through a busy sector of the United Kingdom's upper airspace, was used to train and test the models. Specifically, a piecewise linear model was used as a functional, low-dimensional representation of the ground tracks, with its control points determined by a generative model conditioned on partial context. It was found that, of the investigated models, a Bayesian Neural Network using the Laplace approximation was able to generate the most plausible trajectories in order to emulate the flow of traffic through the sector.
</details>
<details>
<summary>摘要</summary>
准确预测航空器轨迹（TP）在支持空交管理员（ATCO）决策中扮演着重要角色。传统的TP方法是决定性的，基于物理学术，参数通过全球采集的飞机抽象数据进行准确。这些模型因此具有不考虑飞行员和ATCO的意图的缺陷，特别在水平面上。这项工作提出了一种生成方法，使用概率机器学习来模拟飞机轨迹中不确定因素的影响，包括飞行员和ATCO的意图。模型通过特定到某个区域的方式进行训练，以便模型当地的过程，如协调入口和出口点。使用一周内英国Upper空间的繁忙区域的飞机抽象数据进行训练和测试。Specifically, a piecewise linear model was used as a functional, low-dimensional representation of the ground tracks, with its control points determined by a generative model conditioned on partial context. It was found that, of the investigated models, a Bayesian Neural Network using the Laplace approximation was able to generate the most plausible trajectories in order to emulate the flow of traffic through the sector.Note: Simplified Chinese is a romanization of Chinese that uses simpler characters and grammar to facilitate communication. It is not a formal standard of Chinese, but it is commonly used in informal writing and online communication.
</details></li>
</ul>
<hr>
<h2 id="Learning-Generative-Models-for-Climbing-Aircraft-from-Radar-Data"><a href="#Learning-Generative-Models-for-Climbing-Aircraft-from-Radar-Data" class="headerlink" title="Learning Generative Models for Climbing Aircraft from Radar Data"></a>Learning Generative Models for Climbing Aircraft from Radar Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14941">http://arxiv.org/abs/2309.14941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nick Pepper, Marc Thomas</li>
<li>for: 这篇论文的目的是提出一个可靠的飞行器预测方法，以减少飞行器运行时的不确定性对预测结果的影响。</li>
<li>methods: 这篇论文使用了一个基于数据的生成模型，将标准的飞机数据库（BADA）模型与推进力的函数修正学习自数据。</li>
<li>results: 这篇论文的结果显示，使用这个方法可以预测飞行器的到达时间比BADA模型更加精确，并且生成的轨迹对测试数据的实际情况有着更高的吻合度。<details>
<summary>Abstract</summary>
Accurate trajectory prediction (TP) for climbing aircraft is hampered by the presence of epistemic uncertainties concerning aircraft operation, which can lead to significant misspecification between predicted and observed trajectories. This paper proposes a generative model for climbing aircraft in which the standard Base of Aircraft Data (BADA) model is enriched by a functional correction to the thrust that is learned from data. The method offers three features: predictions of the arrival time with 66.3% less error when compared to BADA; generated trajectories that are realistic when compared to test data; and a means of computing confidence bounds for minimal computational cost.
</details>
<details>
<summary>摘要</summary>
减少飞机轨迹预测错误的精准方法（TP），受飞机运行不确定性的影响，导致预测和观测轨迹之间的差异较大。这篇论文提出了一种基于飞机数据（BADA）模型的生成模型，通过学习数据来修正驱进力。该方法具有以下三个特点：1）预测到达时间的错误率比BADA低于66.3%；2）生成的轨迹与测试数据实际上具有准确性；3）可以计算出轨迹 confidence bound，而且计算成本较低。
</details></li>
</ul>
<hr>
<h2 id="Parallel-Multi-Objective-Hyperparameter-Optimization-with-Uniform-Normalization-and-Bounded-Objectives"><a href="#Parallel-Multi-Objective-Hyperparameter-Optimization-with-Uniform-Normalization-and-Bounded-Objectives" class="headerlink" title="Parallel Multi-Objective Hyperparameter Optimization with Uniform Normalization and Bounded Objectives"></a>Parallel Multi-Objective Hyperparameter Optimization with Uniform Normalization and Bounded Objectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14936">http://arxiv.org/abs/2309.14936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Romain Egele, Tyler Chang, Yixuan Sun, Venkatram Vishwanath, Prasanna Balaprakash</li>
<li>for: 提高机器学习模型的多个目标性能</li>
<li>methods: 使用多目标搜索优化机器学习模型的超参数，并采用均衡约束和随机权重缩放法提高效率</li>
<li>results: 提高了多目标性能优化的效率，并且可以快速并平铺地运行多个任务。<details>
<summary>Abstract</summary>
Machine learning (ML) methods offer a wide range of configurable hyperparameters that have a significant influence on their performance. While accuracy is a commonly used performance objective, in many settings, it is not sufficient. Optimizing the ML models with respect to multiple objectives such as accuracy, confidence, fairness, calibration, privacy, latency, and memory consumption is becoming crucial. To that end, hyperparameter optimization, the approach to systematically optimize the hyperparameters, which is already challenging for a single objective, is even more challenging for multiple objectives. In addition, the differences in objective scales, the failures, and the presence of outlier values in objectives make the problem even harder. We propose a multi-objective Bayesian optimization (MoBO) algorithm that addresses these problems through uniform objective normalization and randomized weights in scalarization. We increase the efficiency of our approach by imposing constraints on the objective to avoid exploring unnecessary configurations (e.g., insufficient accuracy). Finally, we leverage an approach to parallelize the MoBO which results in a 5x speed-up when using 16x more workers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Verifiable-Learned-Behaviors-via-Motion-Primitive-Composition-Applications-to-Scooping-of-Granular-Media"><a href="#Verifiable-Learned-Behaviors-via-Motion-Primitive-Composition-Applications-to-Scooping-of-Granular-Media" class="headerlink" title="Verifiable Learned Behaviors via Motion Primitive Composition: Applications to Scooping of Granular Media"></a>Verifiable Learned Behaviors via Motion Primitive Composition: Applications to Scooping of Granular Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14894">http://arxiv.org/abs/2309.14894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Benton, Eugen Solowjow, Prithvi Akella</li>
<li>for: 提高工业机器人采用率，通过实时生成自然语言输入的机器人行为模型。</li>
<li>methods: 基于语言抽象器学习的行为抽象器，通过生成指定的运动 primitives  Synthesize  directed graph，以实现行为的可靠验证。</li>
<li>results: 在simulation中进行探索任务和硬件上使用机器人挖掘固体媒体中的示范。<details>
<summary>Abstract</summary>
A robotic behavior model that can reliably generate behaviors from natural language inputs in real time would substantially expedite the adoption of industrial robots due to enhanced system flexibility. To facilitate these efforts, we construct a framework in which learned behaviors, created by a natural language abstractor, are verifiable by construction. Leveraging recent advancements in motion primitives and probabilistic verification, we construct a natural-language behavior abstractor that generates behaviors by synthesizing a directed graph over the provided motion primitives. If these component motion primitives are constructed according to the criteria we specify, the resulting behaviors are probabilistically verifiable. We demonstrate this verifiable behavior generation capacity in both simulation on an exploration task and on hardware with a robot scooping granular media.
</details>
<details>
<summary>摘要</summary>
一种可靠生成行为的机器人行为模型，可以在实时语言输入下生成行为，将加速工业机器人的采用，因为增加系统的灵活性。为了支持这些努力，我们构建了一个框架，在该框架中，通过自然语言抽象器学习的行为被可靠地验证。利用最新的动作基本 primitives和概率验证技术，我们构建了一个基于自然语言的行为抽象器，通过将提供的动作基本 primitives синтези为导向图来生成行为。如果这些组件动作基本 primitives按照我们的要求构建，则生成的行为是可靠地验证的。我们在实验中使用一个探索任务和硬件机器人夹取粒子物质进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Credit-Card-Fraud-Detection-with-Subspace-Learning-based-One-Class-Classification"><a href="#Credit-Card-Fraud-Detection-with-Subspace-Learning-based-One-Class-Classification" class="headerlink" title="Credit Card Fraud Detection with Subspace Learning-based One-Class Classification"></a>Credit Card Fraud Detection with Subspace Learning-based One-Class Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14880">http://arxiv.org/abs/2309.14880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zaffar Zaffar, Fahad Sohrab, Juho Kanniainen, Moncef Gabbouj</li>
<li>For: 这种论文旨在提出一种基于一类分类算法的自动信用卡fraud检测方法，以解决因commerce digitization而导致的信用卡fraud问题，以及随着fraud技术的不断发展，已有的检测方法的局限性。* Methods: 本文使用subspace learning-based One-Class Classification（OCC）算法，可以处理偏极分布的数据，同时具有预测未来fraud技术的能力。这种算法将数据描述于一个lower-dimensional的子空间中，从而提高了OCC的性能。* Results: 经过严格的实验和分析，本文证明了提出的方法可以有效地 mitigate credit card fraud detection中的curse of dimensionality和偏极分布问题，提高了自动检测的精度和效率。<details>
<summary>Abstract</summary>
In an increasingly digitalized commerce landscape, the proliferation of credit card fraud and the evolution of sophisticated fraudulent techniques have led to substantial financial losses. Automating credit card fraud detection is a viable way to accelerate detection, reducing response times and minimizing potential financial losses. However, addressing this challenge is complicated by the highly imbalanced nature of the datasets, where genuine transactions vastly outnumber fraudulent ones. Furthermore, the high number of dimensions within the feature set gives rise to the ``curse of dimensionality". In this paper, we investigate subspace learning-based approaches centered on One-Class Classification (OCC) algorithms, which excel in handling imbalanced data distributions and possess the capability to anticipate and counter the transactions carried out by yet-to-be-invented fraud techniques. The study highlights the potential of subspace learning-based OCC algorithms by investigating the limitations of current fraud detection strategies and the specific challenges of credit card fraud detection. These algorithms integrate subspace learning into the data description; hence, the models transform the data into a lower-dimensional subspace optimized for OCC. Through rigorous experimentation and analysis, the study validated that the proposed approach helps tackle the curse of dimensionality and the imbalanced nature of credit card data for automatic fraud detection to mitigate financial losses caused by fraudulent activities.
</details>
<details>
<summary>摘要</summary>
在数字化贸易景观中，信用卡诈骗的扩散和黑科技的不断演化，导致了严重的金融损失。自动化信用卡诈骗检测是一种可行的方法，可以加速检测，降低响应时间，最小化可能的金融损失。然而，解决这个挑战是因为数据集的高度偏好性和维度瓶颈的缘故复杂。在这篇论文中，我们调查了基于一个空间学习的一类分类算法，这些算法在处理偏好数据分布时表现出色，并具有预测和防范尚未发明的诈骗技术的能力。我们的研究探讨了现有的诈骗检测策略的局限性和信用卡诈骗检测的特定挑战。这些算法将数据描述中的subspace学习 integrate into the data description, so the models transform the data into a lower-dimensional subspace optimized for one-class classification.经过严格的实验和分析，我们的研究证明了我们提出的方法可以抗衡维度瓶颈和信用卡数据的偏好性，以便自动检测诈骗，从而减少由诈骗活动导致的金融损失。
</details></li>
</ul>
<hr>
<h2 id="Cluster-Exploration-using-Informative-Manifold-Projections"><a href="#Cluster-Exploration-using-Informative-Manifold-Projections" class="headerlink" title="Cluster Exploration using Informative Manifold Projections"></a>Cluster Exploration using Informative Manifold Projections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14857">http://arxiv.org/abs/2309.14857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asem010/legend-pice">https://github.com/asem010/legend-pice</a></li>
<li>paper_authors: Stavros Gerolymatos, Xenophon Evangelopoulos, Vladimir Gusev, John Y. Goulermas</li>
<li>for: 本研究旨在提出一种基于层次结构的维度减少方法，以便利用先前知识来探索高维数据的视觉结构。</li>
<li>methods: 本方法使用了一种线性组合的目标函数，包括对偏好信息的杜尔减去和含义层次分析。</li>
<li>results: 实验表明，本方法可以效果地揭示高维数据中的层次结构，并且可以根据不同的先前知识进行自动化的视觉探索。<details>
<summary>Abstract</summary>
Dimensionality reduction (DR) is one of the key tools for the visual exploration of high-dimensional data and uncovering its cluster structure in two- or three-dimensional spaces. The vast majority of DR methods in the literature do not take into account any prior knowledge a practitioner may have regarding the dataset under consideration. We propose a novel method to generate informative embeddings which not only factor out the structure associated with different kinds of prior knowledge but also aim to reveal any remaining underlying structure. To achieve this, we employ a linear combination of two objectives: firstly, contrastive PCA that discounts the structure associated with the prior information, and secondly, kurtosis projection pursuit which ensures meaningful data separation in the obtained embeddings. We formulate this task as a manifold optimization problem and validate it empirically across a variety of datasets considering three distinct types of prior knowledge. Lastly, we provide an automated framework to perform iterative visual exploration of high-dimensional data.
</details>
<details>
<summary>摘要</summary>
维度减少（DR）是数据可见化中一种关键工具，可以在两到三维空间中揭示高维数据的层次结构。大多数DR方法在文献中忽略了具体数据的先验知识。我们提出了一种新的方法，可以生成有用的嵌入，不仅抑制了不同类型的先验知识结构，还尝试揭示剩下的下面结构。我们使用了一种线性组合的两个目标：首先，对比PCA，抑制先验知识结构；其次，峰度投影约束，确保获得的嵌入是有意义的。我们将这个任务视为一个拟合优化问题，并在多个数据集上进行了验证。最后，我们提供了一个自动化的框架，可以对高维数据进行迭代可见化。
</details></li>
</ul>
<hr>
<h2 id="Investigation-of-factors-regarding-the-effects-of-COVID-19-pandemic-on-college-students’-depression-by-quantum-annealer"><a href="#Investigation-of-factors-regarding-the-effects-of-COVID-19-pandemic-on-college-students’-depression-by-quantum-annealer" class="headerlink" title="Investigation of factors regarding the effects of COVID-19 pandemic on college students’ depression by quantum annealer"></a>Investigation of factors regarding the effects of COVID-19 pandemic on college students’ depression by quantum annealer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.00018">http://arxiv.org/abs/2310.00018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junggu Choi, Kion Kim, Soohyun Park, Juyoen Hur, Hyunjung Yang, Younghoon Kim, Hakbae Lee, Sanghoon Han</li>
<li>for: 本研究旨在探讨COVID-19疫情对大学生们的心理健康产生的影响，以及这些影响因素的复杂关系。</li>
<li>methods: 本研究使用量子落差（QA）特征选择算法，通过商业D-Wave量子计算机执行，确定疫情前后不同因素之间的关系变化。同时还使用多变量线性回归（MLR）和XGBoost模型来验证QA算法的可行性。</li>
<li>results: 研究结果表明，QA算法在因素分析研究中具有与MLR模型广泛使用的相同能力。此外，QA算法的重要因素结果也被验证了。疫情相关因素（如社会系统信任度）和心理因素（如不确定情况下的决策）在后疫情条件下更加重要。我们认为，本研究将为研究类似主题的研究人员提供参考。<details>
<summary>Abstract</summary>
Diverse cases regarding the impact, with its related factors, of the COVID-19 pandemic on mental health have been reported in previous studies. College student groups have been frequently selected as the target population in previous studies because they are easily affected by pandemics. In this study, multivariable datasets were collected from 751 college students based on the complex relationships between various mental health factors. We utilized quantum annealing (QA)-based feature selection algorithms that were executed by commercial D-Wave quantum computers to determine the changes in the relative importance of the associated factors before and after the pandemic. Multivariable linear regression (MLR) and XGBoost models were also applied to validate the QA-based algorithms. Based on the experimental results, we confirm that QA-based algorithms have comparable capabilities in factor analysis research to the MLR models that have been widely used in previous studies. Furthermore, the performance of the QA-based algorithms was validated through the important factor results from the algorithms. Pandemic-related factors (e.g., confidence in the social system) and psychological factors (e.g., decision-making in uncertain situations) were more important in post-pandemic conditions. We believe that our study will serve as a reference for researchers studying similar topics.
</details>
<details>
<summary>摘要</summary>
Previous studies have reported diverse cases of the impact of the COVID-19 pandemic on mental health, with various related factors. College student groups have been frequently selected as the target population due to their vulnerability to pandemics. In this study, we collected multivariable datasets from 751 college students to examine the complex relationships between mental health factors using quantum annealing (QA)-based feature selection algorithms executed by commercial D-Wave quantum computers. We also applied multivariable linear regression (MLR) and XGBoost models for validation. Our results confirm that QA-based algorithms have comparable capabilities in factor analysis research to the widely used MLR models in previous studies. Additionally, the performance of the QA-based algorithms was validated through the important factor results from the algorithms. In post-pandemic conditions, pandemic-related factors (such as confidence in the social system) and psychological factors (such as decision-making in uncertain situations) were found to be more important. We believe that our study will serve as a reference for researchers studying similar topics.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Realtime-Motion-Generation-with-Active-Perception-Using-Attention-Mechanism-for-Cooking-Robot"><a href="#Realtime-Motion-Generation-with-Active-Perception-Using-Attention-Mechanism-for-Cooking-Robot" class="headerlink" title="Realtime Motion Generation with Active Perception Using Attention Mechanism for Cooking Robot"></a>Realtime Motion Generation with Active Perception Using Attention Mechanism for Cooking Robot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14837">http://arxiv.org/abs/2309.14837</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CraftXinkali/Dungeon-Quest-HUBS">https://github.com/CraftXinkali/Dungeon-Quest-HUBS</a></li>
<li>paper_authors: Namiko Saito, Mayu Hiramoto, Ayuna Kubo, Kanata Suzuki, Hiroshi Ito, Shigeki Sugano, Tetsuya Ogata</li>
<li>for: 本研究旨在帮助机器人在日常生活中自动学习、适应物体和环境，并实现相应的动作。</li>
<li>methods: 本研究使用predictive recurrent neural network（PRNN）和注意力机制，可以快速和高效地识别感知信息中的重要信息和可靠信息，并基于这些信息进行动作生成。</li>
<li>results: 经过训练和验证，机器人通过学习人类技能，可以成功地烹饪不同的鸡蛋。机器人可以根据鸡蛋的状态进行不同的搅拌和扭转动作，例如在开始热煮鸡蛋时，机器人会搅拌整个锅，然后随着鸡蛋的热度提高，机器人会改变搅拌方式和target area，例如进行扭转和分割动作，即使没有直接指定。<details>
<summary>Abstract</summary>
To support humans in their daily lives, robots are required to autonomously learn, adapt to objects and environments, and perform the appropriate actions. We tackled on the task of cooking scrambled eggs using real ingredients, in which the robot needs to perceive the states of the egg and adjust stirring movement in real time, while the egg is heated and the state changes continuously. In previous works, handling changing objects was found to be challenging because sensory information includes dynamical, both important or noisy information, and the modality which should be focused on changes every time, making it difficult to realize both perception and motion generation in real time. We propose a predictive recurrent neural network with an attention mechanism that can weigh the sensor input, distinguishing how important and reliable each modality is, that realize quick and efficient perception and motion generation. The model is trained with learning from the demonstration, and allows the robot to acquire human-like skills. We validated the proposed technique using the robot, Dry-AIREC, and with our learning model, it could perform cooking eggs with unknown ingredients. The robot could change the method of stirring and direction depending on the status of the egg, as in the beginning it stirs in the whole pot, then subsequently, after the egg started being heated, it starts flipping and splitting motion targeting specific areas, although we did not explicitly indicate them.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we proposed a predictive recurrent neural network with an attention mechanism that can weigh the sensor input, distinguishing how important and reliable each modality is. This allows the robot to quickly and efficiently perceive and generate motion. The model is trained using learning from demonstration, allowing the robot to acquire human-like skills.We validated our proposed technique using the robot Dry-AIREC, and our learning model allowed the robot to cook eggs with unknown ingredients. The robot was able to change its method of stirring and direction depending on the status of the egg, starting with whole-pot stirring and then switching to flipping and splitting motions targeting specific areas as the egg heated up. This demonstrates the effectiveness of our proposed technique in enabling robots to adapt to changing objects and environments in real time.
</details></li>
</ul>
<hr>
<h2 id="OS-net-Orbitally-Stable-Neural-Networks"><a href="#OS-net-Orbitally-Stable-Neural-Networks" class="headerlink" title="OS-net: Orbitally Stable Neural Networks"></a>OS-net: Orbitally Stable Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14822">http://arxiv.org/abs/2309.14822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marieme Ngom, Carlo Graziani</li>
<li>for: 这篇论文是 для研究 периоди动力系统中的神经网络架构，尤其是使用运动方程式来描述动力系统的动作。</li>
<li>methods: 本论文使用了Neural Ordinary Differential Equations（NODEs）和运动方程式来建立神经网络架构，并利用ODE理论来确定网络参数的稳定性。</li>
<li>results: 本论文透过应用OS-net于罗斯勒和斯洛特的系统中，发现了 périod doubling attractors 和 chaotic 行为的动力学。<details>
<summary>Abstract</summary>
We introduce OS-net (Orbitally Stable neural NETworks), a new family of neural network architectures specifically designed for periodic dynamical data. OS-net is a special case of Neural Ordinary Differential Equations (NODEs) and takes full advantage of the adjoint method based backpropagation method. Utilizing ODE theory, we derive conditions on the network weights to ensure stability of the resulting dynamics. We demonstrate the efficacy of our approach by applying OS-net to discover the dynamics underlying the R\"{o}ssler and Sprott's systems, two dynamical systems known for their period doubling attractors and chaotic behavior.
</details>
<details>
<summary>摘要</summary>
我们介绍OS-net（Orbitally Stable neural NETworks），一新的神经网络架构，特别针对周期动力系统的资料。OS-net是NODEs（神经普通微分方程）的特殊情况，利用微分方程理论，我们得出了网络 Parameters的稳定性条件。我们透过实践OS-net，发现了R\"{o}ssler和Sprott的两个动力系统中的时间倍增吸引器和混沌行为。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Markov-Chain-Mirror-Descent-On-Data-Federation"><a href="#Markov-Chain-Mirror-Descent-On-Data-Federation" class="headerlink" title="Markov Chain Mirror Descent On Data Federation"></a>Markov Chain Mirror Descent On Data Federation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14775">http://arxiv.org/abs/2309.14775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yawei Zhao</li>
<li>for: 这个论文探讨了在联合学习中使用随机抽样 descent的方法，并提出了一个新的版本名为 MarchOn。</li>
<li>methods: 这个方法使用了随机从节点到其邻居的选择，并提出了一个新的分析框架，可以实现最好的速度传播。</li>
<li>results: 这个研究获得了实验 validate theoretical results，并证明了 MarchOn 的传播速度是最佳的。<details>
<summary>Abstract</summary>
Stochastic optimization methods such as mirror descent have wide applications due to low computational cost. Those methods have been well studied under assumption of the independent and identical distribution, and usually achieve sublinear rate of convergence. However, this assumption may be too strong and unpractical in real application scenarios. Recent researches investigate stochastic gradient descent when instances are sampled from a Markov chain. Unfortunately, few results are known for stochastic mirror descent. In the paper, we propose a new version of stochastic mirror descent termed by MarchOn in the scenario of the federated learning. Given a distributed network, the model iteratively travels from a node to one of its neighbours randomly. Furthermore, we propose a new framework to analyze MarchOn, which yields best rates of convergence for convex, strongly convex, and non-convex loss. Finally, we conduct empirical studies to evaluate the convergence of MarchOn, and validate theoretical results.
</details>
<details>
<summary>摘要</summary>
Stochastic 优化方法，如镜像下降法，具有低计算成本，因此在各种应用场景中具有广泛的应用前景。然而，这些方法通常假设数据是独立和相同分布的，这可能是一个偏要假设。现在的研究则探讨在Markov链上采样实例时，镜像下降法的性能。尽管有些结果已经得到了关注，但是对于镜像下降法，还知之不够多。在本文中，我们提出了一种新的镜像下降法，称之为MarchOn，并在联合学习场景中应用。在分布网络上，模型会随机从一个节点跳转到其近邻节点。此外，我们还提出了一种新的分析框架，可以在 convex、强Converter、非凸损函数下达到最佳的速度。最后，我们进行了实验研究，证明了MarchOn的收敛性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Computational-Complexity-and-Formal-Hierarchy-of-Second-Order-Recurrent-Neural-Networks"><a href="#On-the-Computational-Complexity-and-Formal-Hierarchy-of-Second-Order-Recurrent-Neural-Networks" class="headerlink" title="On the Computational Complexity and Formal Hierarchy of Second Order Recurrent Neural Networks"></a>On the Computational Complexity and Formal Hierarchy of Second Order Recurrent Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14691">http://arxiv.org/abs/2309.14691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ankur Mali, Alexander Ororbia, Daniel Kifer, Lee Giles</li>
<li>for: 这个论文旨在探讨基于人工神经网络（ANNs）的二阶Recurrent Neural Networks（RNNs）是否能够实现图灵完备性（TC）。</li>
<li>methods: 作者们使用了二阶RNNs的概率性和自注意力来实现TC。他们还提出了一种可解释的设计方法，可以在受限制的精度和时间下实现TC。</li>
<li>results: 作者们证明了二阶RNNs可以在受限制的精度和时间下recognize任何规则语言，并且在recognize regular grammars时表现更好于现代化RNNs和Gated Recurrent Units。他们还提供了一个Upper bound和稳定分析，证明二阶RNNs只需要一定的最大 neuron数来recognize任何规则语言。<details>
<summary>Abstract</summary>
Artificial neural networks (ANNs) with recurrence and self-attention have been shown to be Turing-complete (TC). However, existing work has shown that these ANNs require multiple turns or unbounded computation time, even with unbounded precision in weights, in order to recognize TC grammars. However, under constraints such as fixed or bounded precision neurons and time, ANNs without memory are shown to struggle to recognize even context-free languages. In this work, we extend the theoretical foundation for the $2^{nd}$-order recurrent network ($2^{nd}$ RNN) and prove there exists a class of a $2^{nd}$ RNN that is Turing-complete with bounded time. This model is capable of directly encoding a transition table into its recurrent weights, enabling bounded time computation and is interpretable by design. We also demonstrate that $2$nd order RNNs, without memory, under bounded weights and time constraints, outperform modern-day models such as vanilla RNNs and gated recurrent units in recognizing regular grammars. We provide an upper bound and a stability analysis on the maximum number of neurons required by $2$nd order RNNs to recognize any class of regular grammar. Extensive experiments on the Tomita grammars support our findings, demonstrating the importance of tensor connections in crafting computationally efficient RNNs. Finally, we show $2^{nd}$ order RNNs are also interpretable by extraction and can extract state machines with higher success rates as compared to first-order RNNs. Our results extend the theoretical foundations of RNNs and offer promising avenues for future explainable AI research.
</details>
<details>
<summary>摘要</summary>
人工神经网络（ANNs）带有回归和自注意力已被证明是图灵完备（TC）。然而，现有的工作表明，这些ANNs需要多个轮次或无限的计算时间，即使在无限精度的权重下，以recognize TC语法。然而，在受限于固定或受限的精度神经和时间的情况下，没有记忆的ANNs很难recognizeeven context-free语言。在这种工作中，我们扩展了第二阶段回归网络（2nd RNN）的理论基础，并证明存在一类的2nd RNN可以在受限时间内recognize TC语法。这种模型可以直接将转移表编码到其回归权重中，使得计算时间受限，并且可以通过设计来解释。我们还证明了没有记忆的2nd RNN，在固定权重和时间约束下，可以在较低的精度下recognize常见语法，并且在Tomita语法上进行了广泛的实验支持。最后，我们表明2nd RNN可以通过提取来解释，并且可以在比first-order RNN更高的成功率下提取状态机。我们的结果扩展了RNN的理论基础，并提供了未来可解释AI研究的有优点的方向。
</details></li>
</ul>
<hr>
<h2 id="FedCompass-Efficient-Cross-Silo-Federated-Learning-on-Heterogeneous-Client-Devices-using-a-Computing-Power-Aware-Scheduler"><a href="#FedCompass-Efficient-Cross-Silo-Federated-Learning-on-Heterogeneous-Client-Devices-using-a-Computing-Power-Aware-Scheduler" class="headerlink" title="FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices using a Computing Power Aware Scheduler"></a>FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices using a Computing Power Aware Scheduler</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14675">http://arxiv.org/abs/2309.14675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilinghan Li, Pranshu Chaturvedi, Shilan He, Han Chen, Gagandeep Singh, Volodymyr Kindratenko, E. A. Huerta, Kibaek Kim, Ravi Madduri</li>
<li>for: 这篇论文旨在解决跨节点联合学习中的客户端异相性和数据异相性问题，以实现无中央数据设施的情况下，实现强大且通用的人工智能模型训练。</li>
<li>methods: 本论文提出了一个名为FedCompass的创新的半同步联合学习算法，其在服务器端使用了资源知识来分配不同客户端的训练任务，以适应不同客户端的计算能力。这使得多个客户端的本地模型可以被收到并处理，以减少本地模型的落后性。</li>
<li>results: 使用了多种异步的非同相数据分布式集合，研究发现FedCompass可以比其他半同步算法更快地训练到准确性，并且在不同客户端的计算能力不同情况下保持高效率。<details>
<summary>Abstract</summary>
Cross-silo federated learning offers a promising solution to collaboratively train robust and generalized AI models without compromising the privacy of local datasets, e.g., healthcare, financial, as well as scientific projects that lack a centralized data facility. Nonetheless, because of the disparity of computing resources among different clients (i.e., device heterogeneity), synchronous federated learning algorithms suffer from degraded efficiency when waiting for straggler clients. Similarly, asynchronous federated learning algorithms experience degradation in the convergence rate and final model accuracy on non-identically and independently distributed (non-IID) heterogeneous datasets due to stale local models and client drift. To address these limitations in cross-silo federated learning with heterogeneous clients and data, we propose FedCompass, an innovative semi-asynchronous federated learning algorithm with a computing power aware scheduler on the server side, which adaptively assigns varying amounts of training tasks to different clients using the knowledge of the computing power of individual clients. FedCompass ensures that multiple locally trained models from clients are received almost simultaneously as a group for aggregation, effectively reducing the staleness of local models. At the same time, the overall training process remains asynchronous, eliminating prolonged waiting periods from straggler clients. Using diverse non-IID heterogeneous distributed datasets, we demonstrate that FedCompass achieves faster convergence and higher accuracy than other asynchronous algorithms while remaining more efficient than synchronous algorithms when performing federated learning on heterogeneous clients.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:跨存储 silo 联合学习提供了一个优秀的解决方案，以协同训练 robust 和泛化 AI 模型，无需妥协本地数据隐私，例如医疗、金融、以及科学项目，这些项目缺乏中央数据设施。然而，由于客户端（设备）的资源差异（device heterogeneity），同步联合学习算法受到客户端延迟的影响，而异步联合学习算法则因为客户端模型偏移和数据不均匀（non-IID）而导致衰落。为了解决这些限制，我们提出了 FedCompass，一种具有服务器端计算能力感知调度器的半同步联合学习算法。FedCompass 能够适应客户端的计算能力，并在服务器端分配不同的训练任务，以避免客户端延迟。这种方法使得多个客户端上的本地模型被接收并聚合，从而减少本地模型的衰落。同时，整个训练过程保持异步，从而消除客户端延迟。使用多种非同Kind 的非同一样 distributed datasets，我们证明了 FedCompass 在异步联合学习中实现了更快的整合速度和更高的准确率，同时保持和同步联合学习更高的效率。
</details></li>
</ul>
<hr>
<h2 id="Transformer-based-classification-of-user-queries-for-medical-consultancy-with-respect-to-expert-specialization"><a href="#Transformer-based-classification-of-user-queries-for-medical-consultancy-with-respect-to-expert-specialization" class="headerlink" title="Transformer-based classification of user queries for medical consultancy with respect to expert specialization"></a>Transformer-based classification of user queries for medical consultancy with respect to expert specialization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14662">http://arxiv.org/abs/2309.14662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dmitry Lyutkin, Andrey Soloviev, Dmitry Zhukov, Denis Pozdnyakov, Muhammad Shahid Iqbal Malik, Dmitry I. Ignatov</li>
<li>for: 这个研究旨在提供一个创新的数位健康照顾方法，通过利用 RuBERT 模型进行患者查询分类，并且强调专业专长。</li>
<li>methods: 我们使用 RuBERT 模型进行微调，利用不同的数据集进行 fine-tuning，以实现具体的医疗专业与查询之间的精确对应。</li>
<li>results: 我们透过实验证明了我们的方法在不同医疗领域（如心脏科、神经科和皮肤科）中的高效性，F1 分数超过 92%。<details>
<summary>Abstract</summary>
The need for skilled medical support is growing in the era of digital healthcare. This research presents an innovative strategy, utilizing the RuBERT model, for categorizing user inquiries in the field of medical consultation with a focus on expert specialization. By harnessing the capabilities of transformers, we fine-tuned the pre-trained RuBERT model on a varied dataset, which facilitates precise correspondence between queries and particular medical specialisms. Using a comprehensive dataset, we have demonstrated our approach's superior performance with an F1-score of over 92%, calculated through both cross-validation and the traditional split of test and train datasets. Our approach has shown excellent generalization across medical domains such as cardiology, neurology and dermatology. This methodology provides practical benefits by directing users to appropriate specialists for prompt and targeted medical advice. It also enhances healthcare system efficiency, reduces practitioner burden, and improves patient care quality. In summary, our suggested strategy facilitates the attainment of specific medical knowledge, offering prompt and precise advice within the digital healthcare field.
</details>
<details>
<summary>摘要</summary>
在数字医疗时代，需求专业医疗支持的增长日益明显。本研究提出了一种创新的策略，利用 RuBERT 模型，对医疗咨询用户问题进行分类，以提高专业化水平。通过利用 transformers 的能力，我们对预训练 RuBERT 模型进行了精细调整，使得问题和医疗专业之间达到精准匹配。通过使用完整的数据集，我们已经证明了我们的方法的超过 92% 的 F1 分数，通过跨Validation和传统的测试集和训练集分割。我们的方法在医学领域such as cardiology、neurology和dermatology中展现出了优秀的泛化性。这种方法ология在数字医疗领域提供了实用的好处，可以引导用户到相应的专家获得timely和精准的医疗建议，从而提高医疗系统的效率、减轻医生的负担、提高患者的健康质量。总之，我们建议的策略可以帮助在数字医疗领域获得特定的医学知识，提供时效和精准的医疗建议。
</details></li>
</ul>
<hr>
<h2 id="Genetic-InfoMax-Exploring-Mutual-Information-Maximization-in-High-Dimensional-Imaging-Genetics-Studies"><a href="#Genetic-InfoMax-Exploring-Mutual-Information-Maximization-in-High-Dimensional-Imaging-Genetics-Studies" class="headerlink" title="Genetic InfoMax: Exploring Mutual Information Maximization in High-Dimensional Imaging Genetics Studies"></a>Genetic InfoMax: Exploring Mutual Information Maximization in High-Dimensional Imaging Genetics Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15132">http://arxiv.org/abs/2309.15132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaochen Xie, Ziqian Xie, Sheikh Muhammad Saiful Islam, Degui Zhi, Shuiwang Ji</li>
<li>for: This paper is written for the purpose of addressing the challenges of representation learning in genome-wide association studies (GWAS) for high-dimensional medical imaging data, specifically using mutual information (MI) to identify informative representations of the data.</li>
<li>methods: The paper introduces a trans-modal learning framework called Genetic InfoMax (GIM), which includes a regularized MI estimator and a novel genetics-informed transformer to address the specific challenges of GWAS.</li>
<li>results: The paper demonstrates the effectiveness of GIM and a significantly improved performance on GWAS, as evaluated on human brain 3D MRI data using standardized evaluation protocols.<details>
<summary>Abstract</summary>
Genome-wide association studies (GWAS) are used to identify relationships between genetic variations and specific traits. When applied to high-dimensional medical imaging data, a key step is to extract lower-dimensional, yet informative representations of the data as traits. Representation learning for imaging genetics is largely under-explored due to the unique challenges posed by GWAS in comparison to typical visual representation learning. In this study, we tackle this problem from the mutual information (MI) perspective by identifying key limitations of existing methods. We introduce a trans-modal learning framework Genetic InfoMax (GIM), including a regularized MI estimator and a novel genetics-informed transformer to address the specific challenges of GWAS. We evaluate GIM on human brain 3D MRI data and establish standardized evaluation protocols to compare it to existing approaches. Our results demonstrate the effectiveness of GIM and a significantly improved performance on GWAS.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-the-Uncertainty-Sets-for-Control-Dynamics-via-Set-Membership-A-Non-Asymptotic-Analysis"><a href="#Learning-the-Uncertainty-Sets-for-Control-Dynamics-via-Set-Membership-A-Non-Asymptotic-Analysis" class="headerlink" title="Learning the Uncertainty Sets for Control Dynamics via Set Membership: A Non-Asymptotic Analysis"></a>Learning the Uncertainty Sets for Control Dynamics via Set Membership: A Non-Asymptotic Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14648">http://arxiv.org/abs/2309.14648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingying Li, Jing Yu, Lauren Conger, Adam Wierman</li>
<li>for:  Linear dynamical systems under bounded, i.i.d. disturbances</li>
<li>methods: Set membership estimation, non-asymptotic bound on the diameter of the uncertainty sets</li>
<li>results: Robust adaptive model predictive control with performance approaching offline optimal model predictive control<details>
<summary>Abstract</summary>
Set-membership estimation is commonly used in adaptive/learning-based control algorithms that require robustness over the model uncertainty sets, e.g., online robustly stabilizing control and robust adaptive model predictive control. Despite having broad applications, non-asymptotic estimation error bounds in the stochastic setting are limited. This paper provides such a non-asymptotic bound on the diameter of the uncertainty sets generated by set membership estimation on linear dynamical systems under bounded, i.i.d. disturbances. Further, this result is applied to robust adaptive model predictive control with uncertainty sets updated by set membership. We numerically demonstrate the performance of the robust adaptive controller, which rapidly approaches the performance of the offline optimal model predictive controller, in comparison with the control design based on least square estimation's confidence regions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>设 membership 估计是通用的控制算法中的一个重要组成部分，例如在线 robustly 稳定控制和robust 适应模型预测控制中。 despite 广泛应用，非偏 asymptotic 估计误差 bound 在sto 价设置下有限。这篇文章提供了这样一个 non-asymptotic bound 在线 linear 动力系统上的 uncertainty 集 generated by set membership 估计的 diameter。此外，这个结果被应用于 robust 适应模型预测控制中，where uncertainty sets 是通过 set membership 估计更新的。我们通过数值示例表明了这种 robust 适应控制器的性能，它快速地 approached 线上最优化的模型预测控制器的性能，与 based on least square estimation 的 confidence regions 的控制设计相比。Note: "set membership" in the text refers to the estimation of the uncertainty sets of the system's parameters, and "non-asymptotic" means that the bound is valid for all time and does not rely on any assumptions about the convergence of the estimation process.
</details></li>
</ul>
<hr>
<h2 id="Gray-box-Adversarial-Attack-of-Deep-Reinforcement-Learning-based-Trading-Agents"><a href="#Gray-box-Adversarial-Attack-of-Deep-Reinforcement-Learning-based-Trading-Agents" class="headerlink" title="Gray-box Adversarial Attack of Deep Reinforcement Learning-based Trading Agents"></a>Gray-box Adversarial Attack of Deep Reinforcement Learning-based Trading Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14615">http://arxiv.org/abs/2309.14615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Foozhan Ataiefard, Hadi Hemmati</li>
<li>For: The paper is written to demonstrate the robustness of a Deep Reinforcement Learning (Deep RL) based trading agent against adversarial attacks.* Methods: The paper uses a “gray-box” approach for attacking the Deep RL-based trading agent, which involves trading in the same stock market with no extra access to the trading agent. The adversary agent uses a hybrid Deep Neural Network as its policy, consisting of Convolutional layers and fully-connected layers.* Results: The paper shows that the adversary policy proposed in the research is able to reduce the reward values by 214.17%, which results in reducing the potential profits of the baseline by 139.4%, ensemble method by 93.7%, and an automated trading software developed by the industrial partner by 85.5%, while consuming significantly less budget than the victims.Here are the three points in Simplified Chinese text:* 为：本研究用于证明深度强化学习（Deep RL）基于的交易代理程序对抗性的可行性。* 方法：本研究使用“灰色框架”的方法进行攻击深度强化学习基于的交易代理程序，即在同一股票市场中进行交易，无需额外访问交易代理程序。敌对代理程序使用了一个混合深度神经网络作为其政策，该政策包括卷积层和全连接层。* 结果：研究显示，敌对政策提出的本研究可以将奖励值降低214.17%，这导致基准值下降139.4%，协同方法下降93.7%，并且由industrial partner开发的自动交易软件下降85.5%，同时消耗了许多更少的预算。<details>
<summary>Abstract</summary>
In recent years, deep reinforcement learning (Deep RL) has been successfully implemented as a smart agent in many systems such as complex games, self-driving cars, and chat-bots. One of the interesting use cases of Deep RL is its application as an automated stock trading agent. In general, any automated trading agent is prone to manipulations by adversaries in the trading environment. Thus studying their robustness is vital for their success in practice. However, typical mechanism to study RL robustness, which is based on white-box gradient-based adversarial sample generation techniques (like FGSM), is obsolete for this use case, since the models are protected behind secure international exchange APIs, such as NASDAQ. In this research, we demonstrate that a "gray-box" approach for attacking a Deep RL-based trading agent is possible by trading in the same stock market, with no extra access to the trading agent. In our proposed approach, an adversary agent uses a hybrid Deep Neural Network as its policy consisting of Convolutional layers and fully-connected layers. On average, over three simulated trading market configurations, the adversary policy proposed in this research is able to reduce the reward values by 214.17%, which results in reducing the potential profits of the baseline by 139.4%, ensemble method by 93.7%, and an automated trading software developed by our industrial partner by 85.5%, while consuming significantly less budget than the victims (427.77%, 187.16%, and 66.97%, respectively).
</details>
<details>
<summary>摘要</summary>
在最近几年，深度强化学习（Deep RL）在复杂的游戏、自动驾驶车和chatbot等系统中被成功应用。其中一个有趣的应用场景是作为自动交易代理。然而，通常的机制来研究RL的可靠性是基于白盒子Gradient-based adversarial sample生成技术（like FGSM），这种方法在实际应用中是无效的，因为模型被保护在安全的国际交易API中，如NASDAQ。在这个研究中，我们展示了一种“灰色盒”的攻击方法，可以在同一个股票市场上进行交易，没有额外访问交易代理。我们的提议的敌方策略使用了混合深度神经网络，其中包括卷积层和全连接层。在三个 simulate 的股票市场配置中，我们的敌方策略可以将奖励值降低214.17%，这将导致基eline的可能收益降低139.4%，集成方法降低93.7%，以及由我们的伙伴公司开发的自动交易软件降低85.5%，而消耗的预算比 víctims（427.77%, 187.16%, 66.97%）还要少。
</details></li>
</ul>
<hr>
<h2 id="Reparameterized-Variational-Rejection-Sampling"><a href="#Reparameterized-Variational-Rejection-Sampling" class="headerlink" title="Reparameterized Variational Rejection Sampling"></a>Reparameterized Variational Rejection Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14612">http://arxiv.org/abs/2309.14612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Jankowiak, Du Phan</li>
<li>for: 这篇论文的目的是扩展现有的变量推断方法，以提高变量推断的准确性和效率。</li>
<li>methods: 这篇论文使用了变量拒绝采样（VRS）技术，其将参数化提案分布与拒绝采样结合，定义了一种非参数的、高级别的变量家族。这种技术还引入了低差值重arameter化gradient估计器，以便在实际应用中更好地优化参数。</li>
<li>results: 该论文通过理论分析和实验 validate 了这种新的变量推断方法（RVRS）的效果，并证明了它在模型中存在某些特定的本地变量时表现特别好。<details>
<summary>Abstract</summary>
Traditional approaches to variational inference rely on parametric families of variational distributions, with the choice of family playing a critical role in determining the accuracy of the resulting posterior approximation. Simple mean-field families often lead to poor approximations, while rich families of distributions like normalizing flows can be difficult to optimize and usually do not incorporate the known structure of the target distribution due to their black-box nature. To expand the space of flexible variational families, we revisit Variational Rejection Sampling (VRS) [Grover et al., 2018], which combines a parametric proposal distribution with rejection sampling to define a rich non-parametric family of distributions that explicitly utilizes the known target distribution. By introducing a low-variance reparameterized gradient estimator for the parameters of the proposal distribution, we make VRS an attractive inference strategy for models with continuous latent variables. We argue theoretically and demonstrate empirically that the resulting method--Reparameterized Variational Rejection Sampling (RVRS)--offers an attractive trade-off between computational cost and inference fidelity. In experiments we show that our method performs well in practice and that it is well-suited for black-box inference, especially for models with local latent variables.
</details>
<details>
<summary>摘要</summary>
传统的变量推断方法通常基于参数化的变量分布家族，选择家族的选择对 posterior approximation 的准确性起到关键作用。简单的mean-field家族经常导致低精度的approximation，而Rich的分布家族如normalizing flows往往难以优化并不会利用target distribution的知识因为其黑盒性质。为扩展灵活的变量推断家族，我们回归到Variational Rejection Sampling（VRS）[Grover et al., 2018]，它将 parametric proposal distribution 与拒绝抽样相结合，定义一种非 Parametric 的 rich family of distributions，并且直接利用target distribution的知识。通过引入低差variance reparameterized gradient estimator 的参数，我们使VRS成为latent variables 是 kontinuous的模型中的吸引力 inference 策略。我们 theoretically 和 empirically 论证，RVRS 提供了一个吸引人的trade-off between computational cost 和推断准确性。在实验中，我们发现我们的方法在实践中表现良好，特别是适用于black-box inference，尤其是local latent variables。
</details></li>
</ul>
<hr>
<h2 id="Neuro-Visualizer-An-Auto-encoder-based-Loss-Landscape-Visualization-Method"><a href="#Neuro-Visualizer-An-Auto-encoder-based-Loss-Landscape-Visualization-Method" class="headerlink" title="Neuro-Visualizer: An Auto-encoder-based Loss Landscape Visualization Method"></a>Neuro-Visualizer: An Auto-encoder-based Loss Landscape Visualization Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14601">http://arxiv.org/abs/2309.14601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohannad Elhamod, Anuj Karpatne</li>
<li>For: This paper aims to provide a novel auto-encoder-based non-linear landscape visualization method for neural networks, called Neuro-Visualizer, to help researchers study the loss landscape of neural networks and their training process.* Methods: The proposed Neuro-Visualizer method uses an auto-encoder to learn a lower-dimensional representation of the loss landscape, and then visualizes the landscape using a 2D plot. The method is evaluated on a variety of problems in two applications of knowledge-guided machine learning (KGML).* Results: The results show that Neuro-Visualizer outperforms other linear and non-linear baselines and provides useful insights about the loss landscape of neural networks. The method is able to corroborate and sometimes challenge claims proposed by the machine learning community.Here’s the summary in Simplified Chinese:* 为: 这篇论文目标是提供一种基于自编码器的非线性损失地形可见化方法，名为Neuro-Visualizer，以帮助研究人员研究神经网络的损失地形和训练过程。* 方法: 提议的Neuro-Visualizer方法使用自编码器学习损失地形的下降维度表示，然后使用2D图表可见化地形。方法在两个知识导向机器学习（KGML）应用中进行了多种问题的实验评估。* 结果: 结果表明Neuro-Visualizer比其他线性和非线性基准方法表现更好，并为神经网络损失地形提供了有用的洞察。方法能够证实和机器学习社区提出的一些laims。所有实验代码和数据在<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/NeuroVisualizer-FDD6%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://anonymous.4open.science/r/NeuroVisualizer-FDD6上公开发布。</a><details>
<summary>Abstract</summary>
In recent years, there has been a growing interest in visualizing the loss landscape of neural networks. Linear landscape visualization methods, such as principal component analysis, have become widely used as they intuitively help researchers study neural networks and their training process. However, these linear methods suffer from limitations and drawbacks due to their lack of flexibility and low fidelity at representing the high dimensional landscape. In this paper, we present a novel auto-encoder-based non-linear landscape visualization method called Neuro-Visualizer that addresses these shortcoming and provides useful insights about neural network loss landscapes. To demonstrate its potential, we run experiments on a variety of problems in two separate applications of knowledge-guided machine learning (KGML). Our findings show that Neuro-Visualizer outperforms other linear and non-linear baselines and helps corroborate, and sometime challenge, claims proposed by machine learning community. All code and data used in the experiments of this paper are available at an anonymous link https://anonymous.4open.science/r/NeuroVisualizer-FDD6
</details>
<details>
<summary>摘要</summary>
近年来，有越来越多的研究者关注神经网络训练过程中的损失地图的可视化。使用原理Components分析等线性可视化方法已成为广泛使用的做法，因为它们可以直观地帮助研究者研究神经网络和它的训练过程。然而，这些线性方法受到一些限制和缺陷，因为它们无法准确表达高维度的地图。在这篇论文中，我们提出了一种基于自适应Encoder的非线性地图可视化方法，称之为Neuro-Visualizer。我们运行了多个问题在两个不同的知识导向机器学习（KGML）应用中，并证明Neuro-Visualizer可以超过其他线性和非线性基准，并提供有用的意见关于神经网络损失地图。所有实验代码和数据都可以在https://anonymous.4open.science/r/NeuroVisualizer-FDD6上获取。
</details></li>
</ul>
<hr>
<h2 id="Policy-Optimization-in-a-Noisy-Neighborhood-On-Return-Landscapes-in-Continuous-Control"><a href="#Policy-Optimization-in-a-Noisy-Neighborhood-On-Return-Landscapes-in-Continuous-Control" class="headerlink" title="Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control"></a>Policy Optimization in a Noisy Neighborhood: On Return Landscapes in Continuous Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14597">http://arxiv.org/abs/2309.14597</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nathanrahn/return-landscapes">https://github.com/nathanrahn/return-landscapes</a></li>
<li>paper_authors: Nate Rahn, Pierluca D’Oro, Harley Wiltzer, Pierre-Luc Bacon, Marc G. Bellemare</li>
<li>for: 这个论文的目的是研究深度强化学习代理的稳定性问题。</li>
<li>methods: 该论文使用返回地图来研究政策和返回之间的映射，并发现流行的算法在这个地图上徘徊于噪声 neighbohood，这导致政策 Parameters 更新后返回具有广泛的变化范围。</li>
<li>results: 研究发现，返回地图具有意外的结构，存在简单的路径，可以通过 navigating 这些路径来改善政策的稳定性。该论文还提出了一种分布式视角来评估政策质量，并开发了一种分布式方法来找到这些路径。<details>
<summary>Abstract</summary>
Deep reinforcement learning agents for continuous control are known to exhibit significant instability in their performance over time. In this work, we provide a fresh perspective on these behaviors by studying the return landscape: the mapping between a policy and a return. We find that popular algorithms traverse noisy neighborhoods of this landscape, in which a single update to the policy parameters leads to a wide range of returns. By taking a distributional view of these returns, we map the landscape, characterizing failure-prone regions of policy space and revealing a hidden dimension of policy quality. We show that the landscape exhibits surprising structure by finding simple paths in parameter space which improve the stability of a policy. To conclude, we develop a distribution-aware procedure which finds such paths, navigating away from noisy neighborhoods in order to improve the robustness of a policy. Taken together, our results provide new insight into the optimization, evaluation, and design of agents.
</details>
<details>
<summary>摘要</summary>
深度强化学会控制器的表现会随时间而呈现显著的不稳定性。在这个工作中，我们提供了一种新的视角，研究返回地图：策略和返回之间的映射。我们发现受欢迎的算法在策略参数空间中穿梭着噪声的 neighborhood，一次更新策略参数可以导致返回值的各种各样变化。通过对这些返回值采取分布视角，我们映射了这个地图，描述了策略空间中失败的区域，并发现了一个隐藏的策略质量维度。我们发现返回地图具有意外的结构，找到了简单的参数空间路径，可以提高策略的稳定性。最后，我们开发了一种分布意识的过程，找到这些路径，在策略参数空间中缓解噪声，以提高策略的可靠性。总之，我们的结果为代理人的优化、评估和设计提供了新的视角。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/cs.LG_2023_09_26/" data-id="clogyj8zf00ou7cra96x4d4b6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/eess.IV_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T09:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/eess.IV_2023_09_26/">eess.IV - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Challenges-of-building-medical-image-datasets-for-development-of-deep-learning-software-in-stroke"><a href="#Challenges-of-building-medical-image-datasets-for-development-of-deep-learning-software-in-stroke" class="headerlink" title="Challenges of building medical image datasets for development of deep learning software in stroke"></a>Challenges of building medical image datasets for development of deep learning software in stroke</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15081">http://arxiv.org/abs/2309.15081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Fontanella, Wenwen Li, Grant Mair, Antreas Antoniou, Eleanor Platt, Chloe Martin, Paul Armitage, Emanuele Trucco, Joanna Wardlaw, Amos Storkey<br>for: This paper aims to address the challenge of preparing clinical brain CT datasets for deep learning (DL) analysis.methods: The authors propose a complete semi-automatic pipeline to standardize the heterogeneous dataset, which includes handling image sets with different orientations, image types, and dimensions, and removing redundant background.results: The final pipeline was able to process 5,868&#x2F;10,659 (45%) CT image datasets, with the majority of axial scans being accepted after adjustments such as image cropping, resizing, and scaling. However, 465 scans failed the registration process.<details>
<summary>Abstract</summary>
Despite the large amount of brain CT data generated in clinical practice, the availability of CT datasets for deep learning (DL) research is currently limited. Furthermore, the data can be insufficiently or improperly prepared for machine learning and thus lead to spurious and irreproducible analyses. This lack of access to comprehensive and diverse datasets poses a significant challenge for the development of DL algorithms. In this work, we propose a complete semi-automatic pipeline to address the challenges of preparing a clinical brain CT dataset for DL analysis and describe the process of standardising this heterogeneous dataset. Challenges include handling image sets with different orientations (axial, sagittal, coronal), different image types (to view soft tissues or bones) and dimensions, and removing redundant background. The final pipeline was able to process 5,868/10,659 (45%) CT image datasets. Reasons for rejection include non-axial data (n=1,920), bone reformats (n=687), separated skull base/vault images (n=1,226), and registration failures (n=465). Further format adjustments, including image cropping, resizing and scaling are also needed for DL processing. Of the axial scans that were not localisers, bone reformats or split brains, 5,868/6,333 (93%) were accepted, while the remaining 465 failed the registration process. Appropriate preparation of medical imaging datasets for DL is a costly and time-intensive process.
</details>
<details>
<summary>摘要</summary>
尽管在临床实践中生成了大量的脑CT数据，但现在对深度学习（DL）研究的CT数据仍然受到限制。此外，数据可能未经正确准备，导致机器学习分析出现假象和不可重复的问题。这种数据的限制对DL算法的发展带来了重大挑战。在这项工作中，我们提出了一个完整的半自动化管道，以解决在临床脑CT数据上进行DL分析前的挑战。我们描述了处理不同方向（AXIAL、SAGGITAL、CORONAL）、不同图像类型（观察软组织或骨骼）和维度等多种挑战。我们的最终管道可以处理5,868/10,659（45%）的CT图像集。拒绝原因包括非AXIAL数据（n=1,920）、骨 Reformats（n=687）、分割的颅骨基/顶层图像（n=1,226）以及注册失败（n=465）。进一步的格式调整，包括图像剪辑、缩放和缩放，还是需要DL处理。AXIAL扫描中未经本地化的、骨 Reformats或分割的脑，5,868/6,333（93%）被接受，剩下465个失败了注册过程。适当地准备医学成像数据 дляDL是一项成本高和时间投入巨大的过程。
</details></li>
</ul>
<hr>
<h2 id="Thalamic-nuclei-segmentation-from-T-1-weighted-MRI-unifying-and-benchmarking-state-of-the-art-methods-with-young-and-old-cohorts"><a href="#Thalamic-nuclei-segmentation-from-T-1-weighted-MRI-unifying-and-benchmarking-state-of-the-art-methods-with-young-and-old-cohorts" class="headerlink" title="Thalamic nuclei segmentation from T$_1$-weighted MRI: unifying and benchmarking state-of-the-art methods with young and old cohorts"></a>Thalamic nuclei segmentation from T$_1$-weighted MRI: unifying and benchmarking state-of-the-art methods with young and old cohorts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15053">http://arxiv.org/abs/2309.15053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brendan Williams, Dan Nguyen, Julie Vidal, Alzheimer’s Disease Neuroimaging Initiative, Manojkumar Saranathan</li>
<li>for: 这个研究是为了比较不同State of the art的腋带神经分 segmentation方法的效果，以及这些方法在识别健康人群和阿尔ц海默病人群之间的分化能力。</li>
<li>methods: 这个研究使用了四种State of the art的腋带神经分 segmentation方法，包括FreeSurfer、HIPS-THOMAS、SCS-CNN和T1-THOMAS。这些方法都被应用在T1 MRI图像上，并被比较使用 overlap和异同度量来评估其精度。</li>
<li>results: 研究发现，HIPS-THOMAS方法能够最好地分解各个腋带神经元的尺度，并且能够最 accurately地识别健康人群和阿尔ц海默病人群之间的分化。此外，研究还发现，这些方法的识别健康人群和阿尔ц海默病人群的精度随着疾病的进程而变化。<details>
<summary>Abstract</summary>
The thalamus and its constituent nuclei are critical for a broad range of cognitive and sensorimotor processes, and implicated in many neurological and neurodegenerative conditions. However, the functional involvement and specificity of thalamic nuclei in human neuroimaging is underappreciated and not well studied due, in part, to technical challenges of accurately identifying and segmenting nuclei. This challenge is further exacerbated by a lack of common nomenclature for comparing segmentation methods. Here, we use data from healthy young (Human Connectome Project, 100 subjects) and older healthy adults, plus those with minor cognitive impairment and Alzheimer$'$s disease (Alzheimer$'$s Disease Neuroimaging Initiative, 540 subjects), to benchmark four state of the art thalamic segmentation methods for T1 MRI (FreeSurfer, HIPS-THOMAS, SCS-CNN, and T1-THOMAS) under a single segmentation framework. Segmentations were compared using overlap and dissimilarity metrics to the Morel stereotaxic atlas. We also quantified each method$'$s estimation of thalamic nuclear degeneration across Alzheimer$'$s disease progression, and how accurately early and late mild cognitive impairment, and Alzheimers disease could be distinguished from healthy controls. We show that HIPS-THOMAS produced the most effective segmentations of individual thalamic nuclei and was also most accurate in discriminating healthy controls from those with mild cognitive impairment and Alzheimer$'$s disease using individual nucleus volumes. This work is the first to systematically compare the efficacy of anatomical thalamic segmentation approaches under a unified nomenclature. We also provide recommendations of which segmentation method to use for studying the functional relevance of specific thalamic nuclei, based on their overlap and dissimilarity with the Morel atlas.
</details>
<details>
<summary>摘要</summary>
腔室和其组成部分 nuclei 对认知和感觉过程具有关键作用，并且与许多神经病理和神经退化病种相关。然而，人类腔室 nuclei 的功能参与度和特定性在人像成像中尚未得到充分认可和研究，这主要是因为识别和分割腔室 nuclei 技术上的挑战。此外，不同的识别方法之间没有共同的命名标准，进一步增加了研究难度。本文使用100名健康年轻人（人类连接计划）和older健康成人（540名），以及急性认知障碍和阿尔茨海默病（阿尔茨海默病成像计划）的Subjects，对4种state-of-the-art腔室分割方法（FreeSurfer、HIPS-THOMAS、SCS-CNN和T1-THOMAS）进行比较，并使用单一分割框架。分割结果与Moreel颈部 Atlases 进行比较，并计算每种方法对腔室 nuclear degeneration 的估计，以及在阿尔茨海默病进程中，健康控制组和急性认知障碍、阿尔茨海默病之间的区别如何准确。结果表明HIPS-THOMAS方法生成了最有效的各个腔室 nuclei 分割，并且在健康控制组和急性认知障碍、阿尔茨海默病之间的分割结果最为准确。本研究是首次系统地比较了不同的腔室分割方法，并提供了选择具体腔室 nuclei 研究功能相关性的建议，基于它们与Moreel Atlases 的重叠和不同程度。
</details></li>
</ul>
<hr>
<h2 id="Multiplex-ultrasound-imaging-of-perfluorocarbon-nanodroplets-enabled-by-decomposition-of-post-vaporization-dynamics"><a href="#Multiplex-ultrasound-imaging-of-perfluorocarbon-nanodroplets-enabled-by-decomposition-of-post-vaporization-dynamics" class="headerlink" title="Multiplex ultrasound imaging of perfluorocarbon nanodroplets enabled by decomposition of post-vaporization dynamics"></a>Multiplex ultrasound imaging of perfluorocarbon nanodroplets enabled by decomposition of post-vaporization dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.00019">http://arxiv.org/abs/2310.00019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Austin Van Namen, Sidhartha Jandhyala, Catalina-Paula Spatarelu, Kenneth M. Tichauer, Kimberley S. Samkoe, Geoffrey P. Luke</li>
<li>for:  This paper aims to develop a new approach to multiplex ultrasound imaging using perfluorocarbon (PFC) nanodroplets as activatable contrast agents.</li>
<li>methods:  The paper uses two populations of PFC nanodroplets with different core boiling points, and leverages their unique temporal responses to an acoustic trigger to differentiate their unique contributions to the overall ultrasound signal.</li>
<li>results:  The paper demonstrates the potential of this approach for multiplex ultrasound imaging, showing that the relative concentrations of the two populations of PFC nanodroplets can be accurately measured in the same imaging volume within an average error of 1.1%.<details>
<summary>Abstract</summary>
Among the various molecular imaging modalities, ultrasound imaging benefits from its real-time, nonionizing, and cost-effective nature. Despite its benefits, there is a dearth of methods to visualize two or more populations of contrast agents simultaneously, a technique known as multiplex imaging. In this paper, we present a new approach to multiplex ultrasound imaging using perfluorocarbon (PFC) nanodroplets. The nanodroplets, which undergo a liquid-to-gas phase transition in response to an acoustic trigger, act as activatable contrast agents. By using two populations of PFC nanodroplets, each with a different core boiling point, their unique temporal responses to an acoustic trigger were leveraged to differentiate their unique contributions to the overall ultrasound signal. This work characterized the dynamic responses of two PFC nanodroplets with boiling points of 28 and 56 {\deg}C. These characteristic responses were then used to demonstrate that the relative concentrations of the two populations of PFC nanodroplets could be accurately measured in the same imaging volume within an average error of 1.1%. Overall, the findings indicate the potential of this approach for multiplex ultrasound imaging, allowing for the visualization of multiple molecular targets simultaneously.
</details>
<details>
<summary>摘要</summary>
在多种分子成像方法中，超声成像具有实时、非离子和cost-effective的特点，但 simultanously visualizing two or more populations of contrast agents still remains a challenge, a technique known as multiplex imaging. In this paper, we present a new approach to multiplex ultrasound imaging using perfluorocarbon (PFC) nanodroplets. The nanodroplets, which undergo a liquid-to-gas phase transition in response to an acoustic trigger, act as activatable contrast agents. By using two populations of PFC nanodroplets, each with a different core boiling point, their unique temporal responses to an acoustic trigger were leveraged to differentiate their unique contributions to the overall ultrasound signal. This work characterized the dynamic responses of two PFC nanodroplets with boiling points of 28 and 56 ℃. These characteristic responses were then used to demonstrate that the relative concentrations of the two populations of PFC nanodroplets could be accurately measured in the same imaging volume within an average error of 1.1%. Overall, the findings indicate the potential of this approach for multiplex ultrasound imaging, allowing for the visualization of multiple molecular targets simultaneously.
</details></li>
</ul>
<hr>
<h2 id="Depolarized-Holography-with-Polarization-multiplexing-Metasurface"><a href="#Depolarized-Holography-with-Polarization-multiplexing-Metasurface" class="headerlink" title="Depolarized Holography with Polarization-multiplexing Metasurface"></a>Depolarized Holography with Polarization-multiplexing Metasurface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14668">http://arxiv.org/abs/2309.14668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seung-Woo Nam, Youngjin Kim, Dongyeon Kim, Yoonchan Jeong</li>
<li>for: 提高投射幕技术的表现，超越物理限制</li>
<li>methods: 利用受体表面，充分利用偏振度的多样性，实现无关性的投射幕显示</li>
<li>results: 实验和 simulations 表明，通过偏振度多样性，可以减少雾点噪声，提高图像质量<details>
<summary>Abstract</summary>
The evolution of computer-generated holography (CGH) algorithms has prompted significant improvements in the performances of holographic displays. Nonetheless, they start to encounter a limited degree of freedom in CGH optimization and physical constraints stemming from the coherent nature of holograms. To surpass the physical limitations, we consider polarization as a new degree of freedom by utilizing a novel optical platform called metasurface. Polarization-multiplexing metasurfaces enable incoherent-like behavior in holographic displays due to the mutual incoherence of orthogonal polarization states. We leverage this unique characteristic of a metasurface by integrating it into a holographic display and exploiting polarization diversity to bring an additional degree of freedom for CGH algorithms. To minimize the speckle noise while maximizing the image quality, we devise a fully differentiable optimization pipeline by taking into account the metasurface proxy model, thereby jointly optimizing spatial light modulator phase patterns and geometric parameters of metasurface nanostructures. We evaluate the metasurface-enabled depolarized holography through simulations and experiments, demonstrating its ability to reduce speckle noise and enhance image quality.
</details>
<details>
<summary>摘要</summary>
计算机生成投射法（CGH）的进化已经提高了投射显示器的性能。然而，它们开始遇到物理限制，即投射的干扰性。为超越物理限制，我们利用一种新的自由度，即极化。我们使用一种新的光学平台，即元件表面（metasurface），以实现无关的行为。元件表面的多极化能力使得投射显示器的行为更加不干扰。我们利用这一特点，并通过在投射显示器中集成元件表面，以及利用极化多样性来带来一个额外的自由度，以便CGH算法进行优化。为最小化干扰噪和最大化图像质量，我们设计了一个完全可导优化管道，包括元件表面代理模型，以联合投射显示器的灵敏度模ulator相位模式和元件表面 nanostructure 的几何参数。我们通过实验和仿真来评估元件表面启用的投射极化投射，并证明其能够减少干扰噪并提高图像质量。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/eess.IV_2023_09_26/" data-id="clogyj93901547cra8538en3d" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/26/eess.SP_2023_09_26/" class="article-date">
  <time datetime="2023-09-26T08:00:00.000Z" itemprop="datePublished">2023-09-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/26/eess.SP_2023_09_26/">eess.SP - 2023-09-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Fully-Adaptive-Time-Varying-Wave-Shape-Model-Applications-in-Biomedical-Signal-Processing"><a href="#Fully-Adaptive-Time-Varying-Wave-Shape-Model-Applications-in-Biomedical-Signal-Processing" class="headerlink" title="Fully Adaptive Time-Varying Wave-Shape Model: Applications in Biomedical Signal Processing"></a>Fully Adaptive Time-Varying Wave-Shape Model: Applications in Biomedical Signal Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15211">http://arxiv.org/abs/2309.15211</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joaquinr-uner/tvwse">https://github.com/joaquinr-uner/tvwse</a></li>
<li>paper_authors: Joaquin Ruiz, Gastón Schlotthauer, Leandro Vignolo, Marcelo A. Colominas</li>
<li>for: 这篇论文的目的是提出一个时间 varying wave-shape 抽取算法，用于处理非站点信号。</li>
<li>methods: 这篇论文使用了一个修改后的适应非干扰模型，来捕捉非站点信号的时间 varying wave-shape 信息。</li>
<li>results: 这篇论文的算法可以高效地从非站点信号中提取时间 varying wave-shape 信息，并且在含高水平的噪音情况下表现更好，比较 existing wave-shape 估计算法和基于短时间傅立卷变数的检测方法。实际上，这篇论文还用于电普雷agraph 信号的静态� States 分析和静态� States 构成 waveform 的分析。<details>
<summary>Abstract</summary>
In this work, we propose a time-varying wave-shape extraction algorithm based on a modified version of the adaptive non-harmonic model for non-stationary signals. The model codifies the time-varying wave-shape information in the relative amplitude and phase of the harmonic components of the wave-shape. The algorithm was validated on both real and synthetic signals for the tasks of denoising, decomposition and adaptive segmentation. For the denoising task, both monocomponent and multicomponent synthetic signals were considered. In both cases, the proposed algorithm can accurately recover the time-varying wave-shape of non-stationary signals, even in the presence of high levels of noise, outperforming existing wave-shape estimation algorithms and denoising methods based on short-time Fourier transform thresholding. The denoising of an electroencephalograph signal was also performed, giving similar results. For decomposition, our proposal was able to recover the composing waveforms more accurately by considering the time variations from the harmonic amplitude functions when compared to existing methods. Finally, the algorithm was used for the adaptive segmentation of synthetic signals and an electrocardiograph of a patient undergoing ventricular fibrillation.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种基于修改后的适应非固定模型的时变波形抽取算法，用于处理非站ARY信号。该模型在相对幅度和相位中codifies时变波形信息。我们验证了该算法在实际和 sintetic 信号上进行了denoising、decomposition和 adaptive segmentation 任务中的性能。对于denoising任务，我们考虑了单组件和多组件的synthetic信号。在两种情况下，我们的提案可以准确地回归非站ARY信号中的时变波形，即使在高噪声水平下，超过了基于短时域快推变换的杜邦滤波法和杜邦滤波法。此外，我们还应用了该算法于电enzephalograph信号的denoising任务，获得类似的结果。对于decomposition任务，我们的提案可以更加准确地回归组成波形，因为考虑了时变幅度函数中的时变信息。与现有方法相比，我们的方法可以更好地回归非站ARY信号的组成部分。最后，我们使用了该算法进行了adaptive segmentation Synthetic信号和一个患有心脏缺陷的病人的electrocardiograph信号。
</details></li>
</ul>
<hr>
<h2 id="Wave-shape-Function-Model-Order-Estimation-by-Trigonometric-Regression"><a href="#Wave-shape-Function-Model-Order-Estimation-by-Trigonometric-Regression" class="headerlink" title="Wave-shape Function Model Order Estimation by Trigonometric Regression"></a>Wave-shape Function Model Order Estimation by Trigonometric Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15210">http://arxiv.org/abs/2309.15210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joaquin Ruiz, Marcelo A. Colominas</li>
<li>for: 这个论文旨在研究非固定幅度和相位的抽象 oscilating signal 的表示方法，并提出一种基于adaptive trigonometric regression的方法来估计波形函数（WSF）中的幂数。</li>
<li>methods: 该论文使用了适应 trigonometric regression 模型选择 criterion 来解决 estimating the number of harmonic components of WSF 问题，并将其应用到非站立波形信号中。</li>
<li>results: 实验结果表明，该方法可以有效地重construct non-stationary signals with non-sinusoidal oscillatory patterns，即使在噪声存在的情况下。  furthermore, the proposed method can denoise simulated pulse wave signals and take into account the interpatient waveform variability of ECG and respiratory signals.<details>
<summary>Abstract</summary>
The adaptive non-harmonic (ANH) model is a powerful tool to compactly represent oscillating signals with time-varying amplitude and phase, and non-sinusoidal oscillating morphology. Given good estimators of instantaneous amplitude and phase we can construct an adaptive model, where the morphology of the oscillation is described by the wave-shape function (WSF), a 2{\pi}-periodic more general periodic function. In this paper, we address the problem of estimating the number of harmonic components of the WSF, a problem that remains underresearched, by adapting trigonometric regression model selection criteria into this context. We study the application of these criteria, originally developed in the context of stationary signals, to the case of signals with time-varying amplitudes and phases. We then incorporate the order estimation to the ANH model reconstruction procedure and analyze its performance for noisy AM-FM signals. Experimental results on synthethic signals indicate that these criteria enable the adaptive estimation of the waveform of non-stationary signals with non-sinusoidal oscillatory patterns, even in the presence of considerable amount of noise. We also apply our reconstruction procedure to the task of denoising simulated pulse wave signals and determine that the proposed technique performs competitively to other denoising schemes. We conclude this work by showing that our adaptive order estimation algorithm takes into account the interpatient waveform variability of the electrocardiogram (ECG) and respiratory signals by analyzing recordings from the Fantasia Database.
</details>
<details>
<summary>摘要</summary>
“非传统的非伤害（ANH）模型是一个强大的工具，可以简洁地表示时间变化的振荡信号，包括时间变化的振幅和相位。我们可以透过适当的估计几何和相位，创建一个适应型模型，其中振荡模式由波形函数（WSF）描述，这是一个2π periodic的更一般的周期函数。在这篇文章中，我们研究了对WSF的数量估计问题，这个问题在这个 контексті仍未得到充分研究。我们运用了这些标准的 trigonometric regression 模型选择 criterion 到这个 контексті中，并研究了这些 criterion 的应用。我们然后将这些数量估计 integrate 到 ANH 模型重建程序中，并分析了它们在噪音 AM-FM 信号上的性能。实验结果表明，这些 criterion 可以在非站ARY信号上实现适应性的数量估计，即使在充斥噪音的情况下。我们还将我们的重建程序应用到实验数据中，并发现它们与其他数据去噪程序相比，表现相当竞争。最后，我们显示了我们的适应数量估计算法能够考虑各种胸部电压ogram 和呼吸信号之间的波形Variability。”
</details></li>
</ul>
<hr>
<h2 id="Eve-Said-Yes-AirBone-Authentication-for-Head-Wearable-Smart-Voice-Assistant"><a href="#Eve-Said-Yes-AirBone-Authentication-for-Head-Wearable-Smart-Voice-Assistant" class="headerlink" title="Eve Said Yes: AirBone Authentication for Head-Wearable Smart Voice Assistant"></a>Eve Said Yes: AirBone Authentication for Head-Wearable Smart Voice Assistant</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15203">http://arxiv.org/abs/2309.15203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenpei Huang, Hui Zhong, Jie Lian, Pavana Prakash, Dian Shi, Yuan Xu, Miao Pan</li>
<li>for: 本研究旨在解决智能声助手上的声音攻击问题，通过采用头环设备（如耳buds和虚拟现实头sets）进行连续监测，并利用骨射频域的声音特征进行多因素身份验证（MFA）。</li>
<li>methods: 本研究使用了两个阶段的 AirBone 验证方法，首先确定 whether air and bone conduction utterances 是时域一致（TC），然后通过骨射频域的声音特征进行骨射频speaker recognition（BC-SR）。</li>
<li>results: 实验结果表明，提posed AirBone 验证方法具有可用性和安全性，可以轻松地通过商业市场上的头环设备进行实现，并且可以提供更高的安全水平，因为它可以抗御Current acoustic attacks 和高级 cross-domain attacks。<details>
<summary>Abstract</summary>
Recent advances in machine learning and natural language processing have fostered the enormous prosperity of smart voice assistants and their services, e.g., Alexa, Google Home, Siri, etc. However, voice spoofing attacks are deemed to be one of the major challenges of voice control security, and never stop evolving such as deep-learning-based voice conversion and speech synthesis techniques. To solve this problem outside the acoustic domain, we focus on head-wearable devices, such as earbuds and virtual reality (VR) headsets, which are feasible to continuously monitor the bone-conducted voice in the vibration domain. Specifically, we identify that air and bone conduction (AC/BC) from the same vocalization are coupled (or concurrent) and user-level unique, which makes them suitable behavior and biometric factors for multi-factor authentication (MFA). The legitimate user can defeat acoustic domain and even cross-domain spoofing samples with the proposed two-stage AirBone authentication. The first stage answers \textit{whether air and bone conduction utterances are time domain consistent (TC)} and the second stage runs \textit{bone conduction speaker recognition (BC-SR)}. The security level is hence increased for two reasons: (1) current acoustic attacks on smart voice assistants cannot affect bone conduction, which is in the vibration domain; (2) even for advanced cross-domain attacks, the unique bone conduction features can detect adversary's impersonation and machine-induced vibration. Finally, AirBone authentication has good usability (the same level as voice authentication) compared with traditional MFA and those specially designed to enhance smart voice security. Our experimental results show that the proposed AirBone authentication is usable and secure, and can be easily equipped by commercial off-the-shelf head wearables with good user experience.
</details>
<details>
<summary>摘要</summary>
Our approach is based on the observation that air and bone conduction (AC/BC) from the same vocalization are coupled and unique to each user, making them suitable for use as behavior and biometric factors in multi-factor authentication (MFA). In the first stage of our proposed method, we check whether the air and bone conduction utterances are time domain consistent (TC). If the utterances are consistent, we proceed to the second stage, which involves bone conduction speaker recognition (BC-SR).The use of AirBone authentication offers several advantages over traditional MFA methods. First, current acoustic attacks on smart voice assistants cannot affect bone conduction, which is in the vibration domain. Second, even for advanced cross-domain attacks, the unique bone conduction features can detect the adversary's impersonation and machine-induced vibration. Finally, AirBone authentication has good usability compared with traditional MFA and specialized methods designed to enhance smart voice security.Our experimental results show that the proposed AirBone authentication is both usable and secure, and can be easily equipped by commercial off-the-shelf head wearables with good user experience.
</details></li>
</ul>
<hr>
<h2 id="Application-of-reciprocity-for-facilitation-of-wave-field-visualization-and-defect-detection"><a href="#Application-of-reciprocity-for-facilitation-of-wave-field-visualization-and-defect-detection" class="headerlink" title="Application of reciprocity for facilitation of wave field visualization and defect detection"></a>Application of reciprocity for facilitation of wave field visualization and defect detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15198">http://arxiv.org/abs/2309.15198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bernd Köhler, Kanta Takahashi, Kazuyuki Nakahata</li>
<li>for: 研究了STRUCTURAL ком成分中的运动可视化 для缺陷检测</li>
<li>methods: 使用了hammer impacts at multiple points to excite elastic motions, and received by an accelerometer at a fixed point</li>
<li>results: 通过reciprocity in elastodynamics theorem, obtained the dynamic motion of the structural component for fixed-point excitation from measurements performed using multipoint excitations, and observed significant additional deformation at the wall thinning inserted as an artificial defect using maximum intensity projection method.<details>
<summary>Abstract</summary>
The motion visualization in a structural component was studied for defect detection. Elastic motions were excited by hammer impacts at multiple points and received by an accelerometer at a fixed point. Reciprocity in elastodynamics is only valid under certain conditions. Its validity under given experimental conditions was derived from the elastodynamic reciprocity theorem. Based on this, the dynamic motion of the structural component was obtained for fixed-point excitation from measurements performed using multipoint excitations. In the visualized eigenmodes, significant additional deformation was observed at the wall thinning inserted as an artificial defect. To prevent the dependence of defect detection on its position within the mode shape, another approach was proposed based on the extraction of guided wave modes immediately after impact excitation. It is shown that this maximum intensity projection method works well in detecting defects.
</details>
<details>
<summary>摘要</summary>
在结构组件中的运动可视化被研究用于缺陷检测。使用锤子影响的弹性运动被测量到固定点上的加速计上，并且根据刚Dynamic motion of the structural component was obtained from measurements performed using multipoint excitation. In the visualized eigenmodes, significant additional deformation was observed at the wall thinning inserted as an artificial defect. To prevent the dependence of defect detection on its position within the mode shape, another approach was proposed based on the extraction of guided wave modes immediately after impact excitation. It is shown that this maximum intensity projection method works well in detecting defects.Here's the translation in Traditional Chinese:在结构组件中的运动可见化被研究用于缺陷检测。使用锤子影响的弹性运动被量测到固定点上的加速计上，并且根据刚Dynamic motion of the structural component was obtained from measurements performed using multipoint excitation. In the visualized eigenmodes, significant additional deformation was observed at the wall thinning inserted as an artificial defect. To prevent the dependence of defect detection on its position within the mode shape, another approach was proposed based on the extraction of guided wave modes immediately after impact excitation. It is shown that this maximum intensity projection method works well in detecting defects.
</details></li>
</ul>
<hr>
<h2 id="Reliable-Majority-Vote-Computation-with-Complementary-Sequences-for-UAV-Waypoint-Flight-Control"><a href="#Reliable-Majority-Vote-Computation-with-Complementary-Sequences-for-UAV-Waypoint-Flight-Control" class="headerlink" title="Reliable Majority Vote Computation with Complementary Sequences for UAV Waypoint Flight Control"></a>Reliable Majority Vote Computation with Complementary Sequences for UAV Waypoint Flight Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15193">http://arxiv.org/abs/2309.15193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alphan Sahin, Xiaofeng Wang</li>
<li>for: 本研究提出了一种不协调的Over-the-air computation（OAC）方案，用于可靠地计算多个参数的多数投票（MV）在滑动频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频<details>
<summary>Abstract</summary>
In this study, we propose a non-coherent over-the-air computation (OAC) scheme to calculate the majority vote (MV) reliably in fading channels. The proposed approach relies on modulating the amplitude of the elements of complementary sequences (CSs) based on the sign of the parameters to be aggregated. Since it does not use channel state information at the nodes, it is compatible with time-varying channels. To demonstrate the efficacy of our method, we employ it in a scenario where an unmanned aerial vehicle (UAV) is guided by distributed sensors, relying on the MV computed using our proposed scheme. We show that the proposed scheme reduces the computation error rate notably with a longer sequence length in fading channels while maintaining the peak-to-mean-envelope power ratio of the transmitted orthogonal frequency division multiplexing signals to be less than or equal to 3 dB.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种非协调的天空计算（OAC）方案，以可靠地计算多数投票（MV）在淡化通道中。我们的方法基于对填充序列元素的振幅进行模拟，根据参数的符号来决定。由于不使用节点的通道状态信息，这种方法与时变通道相容。为证明我们的方法的有效性，我们在一个由分布式感知器引导的无人飞行器（UAV）上使用了我们的方法。我们显示，我们的方法可以在淡化通道中减少计算错误率，而且可以保持发射的多射频分多路复用信号的峰峰至平均功率比不超过3 dB。
</details></li>
</ul>
<hr>
<h2 id="AsQM-Audio-streaming-Quality-Metric-based-on-Network-Impairments-and-User-Preferences"><a href="#AsQM-Audio-streaming-Quality-Metric-based-on-Network-Impairments-and-User-Preferences" class="headerlink" title="AsQM: Audio streaming Quality Metric based on Network Impairments and User Preferences"></a>AsQM: Audio streaming Quality Metric based on Network Impairments and User Preferences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15186">http://arxiv.org/abs/2309.15186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcelo Rodrigo dos Santos, Andreza Patrícia Batista, Renata Lopes Rosa, Muhammad Saadi, Dick Carrillo Melgarejo, Demóstenes Zegarra Rodríguez</li>
<li>for: 这篇论文主要研究了音乐流式服务中的时间中断对用户体验质量（QoE）的影响，以及用户对音乐内容的喜好如何影响 QoE。</li>
<li>methods: 研究人员采用了主观测试方法，测试了不同的应用参数对用户 QoE 的影响，并发现用户对音乐内容的喜好对 QoE 具有重要作用。</li>
<li>results: 实验结果表明，用户对音乐内容的喜好对 QoE 具有重要作用，并且提出了一种基于用户喜好的 Audio streaming Quality Metric（AsQM）来衡量音乐流式服务质量。此外，实验还表明，在用户设备中实现 AsQM 对功耗、处理和内存占用产生了较低的影响。<details>
<summary>Abstract</summary>
There are many users of audio streaming services because of the proliferation of cloud-based audio streaming services for different content. The complex networks that support these services do not always guarantee an acceptable quality on the end-user side. In this paper, the impact of temporal interruptions on the reproduction of audio streaming and the users preference in relation to audio contents are studied. In order to determine the key parameters in the audio streaming service, subjective tests were conducted, and their results show that users Quality-of-Experience (QoE) is highly correlated with the following application parameters, the number of temporal interruptions or stalls, its frequency and length, and the temporal location in which they occur. However, most important, experimental results demonstrated that users preference for audio content plays an important role in users QoE. Thus, a Preference Factor (PF) function is defined and considered in the formulation of the proposed metric named Audio streaming Quality Metric (AsQM). Considering that multimedia service providers are based on web servers, a framework to obtain user information is proposed. Furthermore, results show that the AsQM implemented in the audio player of an end users device presents a low impact on energy, processing and memory consumption.
</details>
<details>
<summary>摘要</summary>
“现有许多音乐流媒体服务的用户，因为云端音乐流媒体服务的普及，导致不同内容的音乐流媒体服务。但是，这些服务支持的复杂网络不一定能提供用户端的可接受度。本文研究了音乐流媒体服务中的时间中断对于音乐重播的影响，以及用户对于音乐内容的偏好。通过调查，发现用户的品质体验（QoE）高度与以下应用程序参数相关：时间中断或停止的次数、时间长度和时间位置。但是，最重要的是，实验结果显示用户对音乐内容的偏好对于QoE有着重要的影响。因此，我们定义了偏好因子（PF）函数，并将其包含在提案的音乐流媒体质量指标（AsQM）中。考虑到多媒体服务提供商基于网页服务器，我们提出了一个框架来获取用户信息。结果显示，在用户设备上实现的AsQM具有低影响力、处理和内存占用。”
</details></li>
</ul>
<hr>
<h2 id="STAR-RIS-Assisted-Full-Duplex-Communication-Networks"><a href="#STAR-RIS-Assisted-Full-Duplex-Communication-Networks" class="headerlink" title="STAR-RIS Assisted Full-Duplex Communication Networks"></a>STAR-RIS Assisted Full-Duplex Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15037">http://arxiv.org/abs/2309.15037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelhamid Salem, Kai-Kit Wong, Chan-Byoung Chae, Yangyang Zhang</li>
<li>for: 本研究探讨了一种具有完全360度覆盖能力的同时传输和反射智能表面（STAR-RIS）助力的全双工通信系统的性能。</li>
<li>methods: 本研究使用了非对称多access（NOMA）对口 schemes和考虑了系统缺陷，如基站自身干扰和不完美的成功接续干扰（SIC）。</li>
<li>results: 我们 derivatedclosed-form表达式来描述上下行通信的质量因子，并对bidirectional通信进行了扩展分析。此外，我们还提出了一个最大化 Erdos均速率的优化问题，该问题包括调整STAR-RIS元素的振荡和相位偏移，以及有效分配总传输功率。<details>
<summary>Abstract</summary>
Different from conventional reconfigurable intelligent surfaces (RIS), a recent innovation called simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) has emerged, aimed at achieving complete 360-degree coverage in communication networks. Additionally, fullduplex (FD) technology is recognized as a potent approach for enhancing spectral efficiency by enabling simultaneous transmission and reception within the same time and frequency resources. In this study, we investigate the performance of a STAR-RIS-assisted FD communication system. The STAR-RIS is strategically placed at the cell-edge to facilitate communication for users located in this challenging region, while cell-center users can communicate directly with the FD base station (BS). We employ a non-orthogonal multiple access (NOMA) pairing scheme and account for system impairments, such as self-interference at the BS and imperfect successive interference cancellation (SIC). We derive closed-form expressions for the ergodic rates in both the up-link and down-link communications and extend our analysis to bidirectional communication between cell-center and cell-edge users. Furthermore, we formulate an optimization problem aimed at maximizing the ergodic sum-rate. This optimization involves adjusting the amplitudes and phase-shifts of the STAR-RIS elements and allocating total transmit power efficiently. To gain deeper insights into the achievable rates of STAR-RIS-aided FD systems, we explore the impact of various system parameters through numerical results.
</details>
<details>
<summary>摘要</summary>
不同于传统的可重新配置智能表面（RIS），最近的创新是同时传输和反射可重新配置智能表面（STAR-RIS），旨在实现全天猫360度的覆盖率在通信网络中。此外，全双工（FD）技术被认为是提高频率效率的强大方法，可以在同一时间和频率资源上同时进行传输和接收。在这项研究中，我们研究了STAR-RIS帮助FD通信系统的性能。STAR-RIS位于终端处，以便为位于这个困难区域的用户提供通信，而中心用户可以直接与FD基站（BS）进行通信。我们采用了不对称多接入（NOMA）对pairing schemes，并考虑了系统障碍物，如BS自身的自适应干扰和不完全的Successive Interference Cancellation（SIC）。我们 derivatedclosed-form表达式来描述在上行和下行通信中的质量因子，并将分析扩展到双向通信 между中心用户和边缘用户。此外，我们形ulated一个优化问题，旨在最大化服务器的质量因子。这个优化问题包括调整STAR-RIS元素的振荡和相位偏移，以及有效地分配总传输功率。通过numerical results，我们深入探讨STAR-RIS帮助FD系统实现的可能的速率。
</details></li>
</ul>
<hr>
<h2 id="Quadratic-Detection-in-Noncoherent-Massive-SIMO-Systems-over-Correlated-Channels"><a href="#Quadratic-Detection-in-Noncoherent-Massive-SIMO-Systems-over-Correlated-Channels" class="headerlink" title="Quadratic Detection in Noncoherent Massive SIMO Systems over Correlated Channels"></a>Quadratic Detection in Noncoherent Massive SIMO Systems over Correlated Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15030">http://arxiv.org/abs/2309.15030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Vilà-Insa, Aniol Martí, Jaume Riba, Meritxell Lamarca</li>
<li>for: 帮助实现低延迟和高可靠性无线通信 для工业互联网关键物联网（IIoT）。</li>
<li>methods: 使用能量基本模ulation在非共振性大量单输入多输出（SIMO）系统中进行研究。</li>
<li>results: 提出了一种基于最大可能性探测的非正负抽象极限的证明，并提供了一种基于统计知识的通信器抗干扰性能更好的设计框架。这种设计框架可以在中等和高SNR水平下提供更低的错误率。<details>
<summary>Abstract</summary>
With the goal of enabling ultrareliable and low-latency wireless communications for industrial internet of things (IIoT), this paper studies the use of energy-based modulations in noncoherent massive single input multiple output (SIMO) systems. We consider a one-shot communication over a channel with correlated Rayleigh fading and colored Gaussian noise. We first provide a theoretical analysis on the limitations of non-negative pulse-amplitude modulation (PAM) in systems of this kind, based on maximum likelihood detection. The existence of a fundamental error floor at high signal-to-noise ratio (SNR) regimes is proved for constellations with more than two energy levels, when no (statistical) channel state information is available at the transmitter. In the main body of the paper, we present a design framework for quadratic detectors that generalizes the widely-used energy detector, to better exploit the statistical knowledge of the channel. This allows us to design receivers optimized according to information-theoretic criteria that exhibit lower error rates at moderate and high SNR. We subsequently derive an analytic approximation for the error probability of a general class of quadratic detectors in the large array regime. Finally, we introduce an improved reception scheme based on the combination of quadratic detectors and assess its capabilities numerically.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传输goal是实现低延迟和无障碍无线通信，这篇论文研究了基于能量模式的非共振性大量单输入多输出（SIMO）系统。我们考虑了一次性通信在具有相关的徐杰尼谱折射和频率噪声的通道上。我们首先提供了非共振性PAM在这种系统中的限制分析，基于最大likelihood检测。在高信号噪声比例（SNR） regime中存在基本错误地板，当无 statistically channel state information available at the transmitter。在主要文章中，我们提供了一种泛化 quadratic detector的设计框架，以更好地利用通道的统计知识。这使得我们可以根据信息学定义的标准设计接收器，并且在中等和高SNR regime exhibit lower error rates。我们随后 derive了一个 Analytic approximation for the error probability of a general class of quadratic detectors in the large array regime。最后，我们介绍了一种基于quadratic detector和 assess its capabilities numerically。Note: Simplified Chinese is a romanization of Mandarin Chinese, which is the official language of China. The translation is written in the Simplified Chinese format, which is used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Minimizing-Energy-Consumption-for-5G-NR-Beam-Management-for-RedCap-Devices"><a href="#Minimizing-Energy-Consumption-for-5G-NR-Beam-Management-for-RedCap-Devices" class="headerlink" title="Minimizing Energy Consumption for 5G NR Beam Management for RedCap Devices"></a>Minimizing Energy Consumption for 5G NR Beam Management for RedCap Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14971">http://arxiv.org/abs/2309.14971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manishika Rawat, Matteo Pagin, Marco Giordani, Louis-Adrien Dufrene, Quentin Lampin, Michele Zorzi</li>
<li>for: 降低5G New Radio（NR）中的照射管理中的能量消耗，以满足低成本、低复杂度和电池限制的设备，如RedCap设备，支持中等市场互联网器件（IoT）应用场景。</li>
<li>methods: 我们将该问题形式化为一个优化问题，在室内工厂（InF）场景中选择最佳照射管理参数，包括照射更新频率和照射宽度，以最小化能量消耗，基于用户分布和速度。</li>
<li>results: 分析得到了可行范围，即RedCap设备的照射管理参数的Upper limit，我们可以根据这些指导方针进行设计。<details>
<summary>Abstract</summary>
In 5G New Radio (NR), beam management entails periodic and continuous transmission and reception of control signals in the form of synchronization signal blocks (SSBs), used to perform initial access and/or channel estimation. However, this procedure demands continuous energy consumption, which is particularly challenging to handle for low-cost, low-complexity, and battery-constrained devices, such as RedCap devices to support mid-market Internet of Things (IoT) use cases. In this context, this work aims at reducing the energy consumption during beam management for RedCap devices, while ensuring that the desired Quality of Service (QoS) requirements are met. To do so, we formalize an optimization problem in an Indoor Factory (InF) scenario to select the best beam management parameters, including the beam update periodicity and the beamwidth, to minimize energy consumption based on users' distribution and their speed. The analysis yields the regions of feasibility, i.e., the upper limit(s) on the beam management parameters for RedCap devices, that we use to provide design guidelines accordingly.
</details>
<details>
<summary>摘要</summary>
在5G新 Radio（NR）中，磁力管理包括 periodic和连续的控制信号传输和接收，用于初始访问和/或通道估计。但这些过程需要不断的能量消耗，尤其是 для低成本、低复杂度和电池受限的设备，如RedCap设备，以支持中高级Internet of Things（IoT）应用场景。在这个上下文中，本工作的目标是在磁力管理中降低RedCap设备的能量消耗，以确保达到所需的质量服务（QoS）要求。为此，我们将在室内工厂（InF）场景中形式化优化问题，选择最佳的磁力管理参数，包括磁力更新频率和磁力宽度，以最小化RedCap设备的能量消耗，基于用户的分布和速度。分析得到了可行范围，即RedCap设备的磁力管理参数的Upper limit，我们可以根据这些设计指南来提供相应的设计建议。
</details></li>
</ul>
<hr>
<h2 id="ML-based-PBCH-symbol-detection-and-equalization-for-5G-Non-Terrestrial-Networks"><a href="#ML-based-PBCH-symbol-detection-and-equalization-for-5G-Non-Terrestrial-Networks" class="headerlink" title="ML-based PBCH symbol detection and equalization for 5G Non-Terrestrial Networks"></a>ML-based PBCH symbol detection and equalization for 5G Non-Terrestrial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14923">http://arxiv.org/abs/2309.14923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inés Larráyoz-Arrigote, Marcele O. K. Mendonca, Alejandro Gonzalez-Garrido, Jevgenij Krivochiza, Sumit Kumar, Jorge Querol, Joel Grotz, Stefano Andrenacci, Symeon Chatzinotas</li>
<li>for: 本研究探讨了在5G无 terrestrial网络（5G-NTN）中应用机器学习（ML）技术的可能性，特别是对物理广播频道（PBCH）的符号检测和平衡。</li>
<li>methods: 本研究使用了 synthetic 和实际数据，从实际的5G通过卫星测试环境中收集到的数据进行训练。我们的分析包括在不同的信号噪听比（SNR）情况下对这些模型的性能进行评估，以及对符号增强和通道平衡任务进行评估。</li>
<li>results: 结果显示了在控制的环境中ML的性能，以及其适应实际挑战的能力。这些结果 shed light on the potential benefits of applying ML in 5G-NTN, and provide a basis for further research in this area.<details>
<summary>Abstract</summary>
This paper delves into the application of Machine Learning (ML) techniques in the realm of 5G Non-Terrestrial Networks (5G-NTN), particularly focusing on symbol detection and equalization for the Physical Broadcast Channel (PBCH). As 5G-NTN gains prominence within the 3GPP ecosystem, ML offers significant potential to enhance wireless communication performance. To investigate these possibilities, we present ML-based models trained with both synthetic and real data from a real 5G over-the-satellite testbed. Our analysis includes examining the performance of these models under various Signal-to-Noise Ratio (SNR) scenarios and evaluating their effectiveness in symbol enhancement and channel equalization tasks. The results highlight the ML performance in controlled settings and their adaptability to real-world challenges, shedding light on the potential benefits of the application of ML in 5G-NTN.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文探讨了在5G无 terrestrial 网络 (5G-NTN) 中应用机器学习 (ML) 技术，尤其是对物理广播频道 (PBCH) 的符号检测和平衡。随着5G-NTN在3GPP生态系统中的崛起，ML有可能在无线通信性能方面提供显著的提升。为了探索这些可能性，我们提出了基于 ML 的模型，使用了真实数据和验证数据从一个真实的5G过球测试平台进行训练。我们的分析包括在不同的信号噪听比 (SNR) 场景下评估这些模型的性能，以及对符号增强和频道平衡任务的评估。结果表明 ML 在控制场景下的性能和其适应实际挑战的能力，这 shedding light on the potential benefits of applying ML in 5G-NTN.
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Channel-Estimation-in-mm-Wave-MIMO-Systems-Leveraging-Integrated-Communication-and-Sensing"><a href="#Enhanced-Channel-Estimation-in-mm-Wave-MIMO-Systems-Leveraging-Integrated-Communication-and-Sensing" class="headerlink" title="Enhanced Channel Estimation in mm-Wave MIMO Systems Leveraging Integrated Communication and Sensing"></a>Enhanced Channel Estimation in mm-Wave MIMO Systems Leveraging Integrated Communication and Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14875">http://arxiv.org/abs/2309.14875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silvia Mura, Marouan Mizmizi, Umberto Spagnolini, Athina Petropulu</li>
<li>for: 这篇论文解决了indoor millimeter-wave场景中宽带MIMO通道估算的挑战。</li>
<li>methods: 该方法利用了 integrate sensing and communication paradigm，使估算信道所需的训练导航数量减少了4倍。</li>
<li>results: 实验表明，该方法可以减少4倍的训练导航数量，并且能够正确地修复感知和通信模式之间的匹配问题。<details>
<summary>Abstract</summary>
This paper tackles the challenge of wideband MIMO channel estimation within indoor millimeter-wave scenarios. Our proposed approach exploits the integrated sensing and communication paradigm, where sensing information aids in channel estimation. The key innovation consists of employing both spatial and temporal sensing modes to significantly reduce the number of required training pilots. Moreover, our algorithm addresses and corrects potential mismatches between sensing and communication modes, which can arise from differing sensing and communication propagation paths. Extensive simulations demonstrate that the proposed method requires 4x less pilots compared to the current state-of-the-art, marking a substantial advancement in channel estimation efficiency.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:这篇论文研究了indoor millimeter-wave场景中广带MIMO通道估算的挑战。我们提出的方法利用了整合感知和通信的思想，通过感知信息帮助通道估算。我们的算法利用了空间和时间感知模式，可以减少需要的训练导航器数量。此外，我们的算法还解决了感知和通信传播路径之间的差异，可以提高通道估算精度。广泛的 simulations 表明，我们的方法可以比现有技术减少4倍的导航器数量，标志着通道估算效率的显著提升。
</details></li>
</ul>
<hr>
<h2 id="Multi-static-Parameter-Estimation-in-the-Near-Far-Field-Beam-Space-for-Integrated-Sensing-and-Communication-Applications"><a href="#Multi-static-Parameter-Estimation-in-the-Near-Far-Field-Beam-Space-for-Integrated-Sensing-and-Communication-Applications" class="headerlink" title="Multi-static Parameter Estimation in the Near&#x2F;Far Field Beam Space for Integrated Sensing and Communication Applications"></a>Multi-static Parameter Estimation in the Near&#x2F;Far Field Beam Space for Integrated Sensing and Communication Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14778">http://arxiv.org/abs/2309.14778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeid K. Dehkordi, Lorenzo Pucci, Peter Jung, Andrea Giorgetti, Enrico Paolini, Giuseppe Caire</li>
<li>for: 提出一种基于最大可能性（ML）估计框架，用于 millimeter 波（mmWave）集成感知通信（ISAC）系统中的多Static配置。</li>
<li>methods: 使用能效的混合数字分析阵列来实现hybrid digital-analog arrays，并在近场 режиме下使用两stage估计过程来估计目标参数。</li>
<li>results: 通过数字实验来评估提出的框架效果，并表明使用自定义的扁平增益编码字符串可以提高系统的通信性能。<details>
<summary>Abstract</summary>
This work proposes a maximum likelihood (ML)-based parameter estimation framework for a millimeter wave (mmWave) integrated sensing and communication (ISAC) system in a multi-static configuration using energy-efficient hybrid digital-analog arrays. Due to the typically large arrays deployed in the higher frequency bands to mitigate isotropic path loss, such arrays may operate in the near-field regime. The proposed parameter estimation in this work consists of a two-stage estimation process, where the first stage is based on far-field assumptions, and is used to obtain a first estimate of the target parameters. In cases where the target is determined to be in the near-field of the arrays, a second estimation based on near-field assumptions is carried out to obtain more accurate estimates. In particular, we select beamfocusing array weights designed to achieve a constant gain over an extended spatial region and re-estimate the target parameters at the receivers. We evaluate the effectiveness of the proposed framework in numerous scenarios through numerical simulations and demonstrate the impact of the custom-designed flat-gain beamfocusing codewords in increasing the communication performance of the system.
</details>
<details>
<summary>摘要</summary>
这个工作提出了基于最大可能性（ML）的参数估算框架，用于毫米波（mmWave）集成感知通信（ISAC）系统的多Static配置中。由于高频段的大型阵列在减轻各向异性视场损失，这些阵列可能会在近场区间运行。本文中的参数估算包括两个阶段的估算过程，其中第一阶段基于远场假设，用于获得初步目标参数估算。在目标确定在阵列近场区间时，进行第二阶段基于近场假设的估算，以获得更加准确的估算结果。特别是，我们选择了用于实现恒定增益的扩散焦点阵列重量，并在接收器上重新估算目标参数。我们通过数字 simulations 证明了该框架在各种场景中的效果，并示出了自定义的扁平增益扩散编码字符串在系统的通信性能中的影响。
</details></li>
</ul>
<hr>
<h2 id="Toward-Energy-Efficient-Multiuser-IRS-Assisted-URLLC-Systems-A-Novel-Rank-Relaxation-Method"><a href="#Toward-Energy-Efficient-Multiuser-IRS-Assisted-URLLC-Systems-A-Novel-Rank-Relaxation-Method" class="headerlink" title="Toward Energy Efficient Multiuser IRS-Assisted URLLC Systems: A Novel Rank Relaxation Method"></a>Toward Energy Efficient Multiuser IRS-Assisted URLLC Systems: A Novel Rank Relaxation Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14606">http://arxiv.org/abs/2309.14606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jalal Jalali, Filip Lemic, Hina Tabassum, Rafael Berkvens, Jeroen Famaey</li>
<li>for: 该论文提出了一种智能反射 повер面（IRS）助け的下降ULTRA-可靠低延迟通信（URLLC）网络的能源效率资源配置设计算法。该设置包括一个多antenna基站（BS）发送数据流量到一组URLLC用户，具有短包长。我们通过BS的活动扫描器和IRS的pasive扫描器（即相位Shift）的优化，提高整个网络的能源效率（EE）。</li>
<li>methods: 该论文使用了一种分割优化方法（AO）来解决主要的非杂 convex 问题。通过成功ive convex approximation（SCA）和一种新的迭代rank relaxation方法，我们构建了一个凹降-convex 目标函数。首先，我们解决了第一个子问题，即一个分数程序，使用Dinkelbach方法和罚金方法。然后，我们解决了第二个子问题，即基于 semi-definite programming（SDP）和罚金方法。</li>
<li>results: 我们的结果表明，提案的解决方案比现有的参考解决方案更有效。<details>
<summary>Abstract</summary>
This paper proposes an energy efficient resource allocation design algorithm for an intelligent reflecting surface (IRS)-assisted downlink ultra-reliable low-latency communication (URLLC) network. This setup features a multi-antenna base station (BS) transmitting data traffic to a group of URLLC users with short packet lengths. We maximize the total network's energy efficiency (EE) through the optimization of active beamformers at the BS and passive beamformers (a.k.a. phase shifts) at the IRS. The main non-convex problem is divided into two sub-problems. An alternating optimization (AO) approach is then used to solve the problem. Through the use of the successive convex approximation (SCA) with a novel iterative rank relaxation method, we construct a concave-convex objective function for each sub-problem. The first sub-problem is a fractional program that is solved using the Dinkelbach method and a penalty-based approach. The second sub-problem is then solved based on semi-definite programming (SDP) and the penalty-based approach. The iterative solution gradually approaches the rank-one for both the active beamforming and unit modulus IRS phase-shift sub-problems. Our results demonstrate the efficacy of the proposed solution compared to existing benchmarks.
</details>
<details>
<summary>摘要</summary>
The main non-convex problem is divided into two sub-problems, and an alternating optimization (AO) approach is used to solve the problem. The first sub-problem is a fractional program that is solved using the Dinkelbach method and a penalty-based approach. The second sub-problem is then solved based on semi-definite programming (SDP) and the penalty-based approach. The iterative solution gradually approaches the rank-one for both the active beamforming and unit modulus IRS phase-shift sub-problems.The proposed solution is compared to existing benchmarks, and the results demonstrate the efficacy of the proposed solution. The key contribution of this paper is the development of an energy-efficient resource allocation design algorithm for IRS-assisted URLLC networks, which can significantly reduce the energy consumption of the network while maintaining the required reliability and latency.Here is the text in Simplified Chinese:这篇论文提出了一种智能反射Surface（IRS）助手的下行ultra-可靠低延迟通信（URLLC）网络的能源效率资源分配算法。在这种设置中，一个多antenna基站（BS）将数据流传输到一个URLLC用户群体，用户 packets的长度很短。我们通过对BS的活动扬声器和IRS的pasive扬声器（即相位Shift）进行优化，以最大化总网络的能源效率（EE）。主要非凸问题被分解成两个互相关联的优化问题。我们使用alternating optimization（AO）方法来解决问题。通过successive convex approximation（SCA）和一种新的迭代rank relaxation方法，我们构建了一个凹陷-凸函数对象函数。第一个优化问题是一个分数程序，通过Dinkelbach方法和一种罚金方法来解决。第二个优化问题是基于 semi-definite programming（SDP）和罚金方法来解决。迭代解决方案逐渐逼近rank-one для活动扬声器和IRS phase-shift优化问题。我们的结果表明，提出的解决方案比现有的标准做法更有效。这篇论文的关键贡献在于开发了一种智能反射Surface（IRS）助手的下行URLLC网络中的能源效率资源分配算法，可以减少网络的能 consumption，保持必要的可靠性和延迟。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/26/eess.SP_2023_09_26/" data-id="clogyj945018c7cra414dbmt8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/25/cs.SD_2023_09_25/" class="article-date">
  <time datetime="2023-09-25T15:00:00.000Z" itemprop="datePublished">2023-09-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/25/cs.SD_2023_09_25/">cs.SD - 2023-09-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NoLACE-Improving-Low-Complexity-Speech-Codec-Enhancement-Through-Adaptive-Temporal-Shaping"><a href="#NoLACE-Improving-Low-Complexity-Speech-Codec-Enhancement-Through-Adaptive-Temporal-Shaping" class="headerlink" title="NoLACE: Improving Low-Complexity Speech Codec Enhancement Through Adaptive Temporal Shaping"></a>NoLACE: Improving Low-Complexity Speech Codec Enhancement Through Adaptive Temporal Shaping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14521">http://arxiv.org/abs/2309.14521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Büthe, Ahmed Mustafa, Jean-Marc Valin, Karim Helwani, Michael M. Goodwin</li>
<li>for: 提高 speech codec 的质量，对于 Opus 编码器进行增强。</li>
<li>methods: 使用 Linear Adaptive Coding Enhancer (LACE) 模型，combines DNNs with classical long-term&#x2F;short-term postfiltering，具有低复杂性和零延迟。</li>
<li>results: 比较 Opus 基线和扩大 LACE 模型，NoLACE 实现了较高的质量表现，并且与 ASR 系统良好的合作。<details>
<summary>Abstract</summary>
Speech codec enhancement methods are designed to remove distortions added by speech codecs. While classical methods are very low in complexity and add zero delay, their effectiveness is rather limited. Compared to that, DNN-based methods deliver higher quality but they are typically high in complexity and/or require delay. The recently proposed Linear Adaptive Coding Enhancer (LACE) addresses this problem by combining DNNs with classical long-term/short-term postfiltering resulting in a causal low-complexity model. A short-coming of the LACE model is, however, that quality quickly saturates when the model size is scaled up. To mitigate this problem, we propose a novel adatpive temporal shaping module that adds high temporal resolution to the LACE model resulting in the Non-Linear Adaptive Coding Enhancer (NoLACE). We adapt NoLACE to enhance the Opus codec and show that NoLACE significantly outperforms both the Opus baseline and an enlarged LACE model at 6, 9 and 12 kb/s. We also show that LACE and NoLACE are well-behaved when used with an ASR system.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通用 speech codec 优化方法是为了移除 speech codec 添加的扭曲。古典方法具有非常低的复杂性和零延迟，但是其效果很有限。相比之下，基于 DNN 的方法可以提供更高的质量，但是它们通常具有较高的复杂性和/或延迟。随后提出的 Linear Adaptive Coding Enhancer (LACE) 模型解决了这个问题，它将 DNN 与古典长期/短期 POSTfiltering 结合在一起，实现了 causal 低复杂度模型。然而，LACE 模型的缺点是，当模型大小增加时，质量快速增加。为了解决这个问题，我们提出了一种新的适应性时间形态模块，这种模块将高时间分辨率添加到 LACE 模型中，实现了 Non-Linear Adaptive Coding Enhancer (NoLACE)。我们适应 NoLACE 模型来提高 Opus 码ц，并证明 NoLACE 在 6、9 和 12 kb/s 的比特率下显著超过 Opus 基eline 和扩大 LACE 模型。我们还证明 LACE 和 NoLACE 在 ASR 系统中是合理的。
</details></li>
</ul>
<hr>
<h2 id="Noise-Robust-DSP-Assisted-Neural-Pitch-Estimation-with-Very-Low-Complexity"><a href="#Noise-Robust-DSP-Assisted-Neural-Pitch-Estimation-with-Very-Low-Complexity" class="headerlink" title="Noise-Robust DSP-Assisted Neural Pitch Estimation with Very Low Complexity"></a>Noise-Robust DSP-Assisted Neural Pitch Estimation with Very Low Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14507">http://arxiv.org/abs/2309.14507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krishna Subramani, Jean-Marc Valin, Jan Buethe, Paris Smaragdis, Mike Goodwin</li>
<li>for: 这篇论文旨在提出一种hybrid抽取器，使得深度神经网络（DNN）和传统的信号处理（DSP）技术之间的优点得到平衡，以提高抽取器的性能和可实现性。</li>
<li>methods: 该论文使用了一种小型的DNN和传统的DSP特征来实现抽取器，并结合了这两种方法来提高抽取器的性能。</li>
<li>results: 论文表明，这种混合方法可以与纯DNN方法匹配或超越其性能，同时具有与传统DSP方法相同的复杂性和算法延迟。此外，该方法还可以提供一些优势 для神经语音编码任务。<details>
<summary>Abstract</summary>
Pitch estimation is an essential step of many speech processing algorithms, including speech coding, synthesis, and enhancement. Recently, pitch estimators based on deep neural networks (DNNs) have have been outperforming well-established DSP-based techniques. Unfortunately, these new estimators can be impractical to deploy in real-time systems, both because of their relatively high complexity, and the fact that some require significant lookahead. We show that a hybrid estimator using a small deep neural network (DNN) with traditional DSP-based features can match or exceed the performance of pure DNN-based models, with a complexity and algorithmic delay comparable to traditional DSP-based algorithms. We further demonstrate that this hybrid approach can provide benefits for a neural vocoding task.
</details>
<details>
<summary>摘要</summary>
“抽象估值是许多语音处理算法的关键步骤，包括语音编码、合成和提高。最近，基于深度神经网络（DNN）的抽象估值器已经超越了传统的数字信号处理（DSP）技术。然而，这些新的估值器在实时系统中部署可能是不实际的，因为它们的相对较高复杂度和一些需要明显的往回预测。我们表明，一种混合使用小型深度神经网络（DNN）和传统的DSP基于特征的抽象估值器可以与纯DNN基本模型匹配或超越其性能，并且与传统DSP基本算法相同的复杂性和算法延迟。我们还证明了这种混合方法可以为神经编码任务提供优势。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-Impact-of-Quantization-and-Pruning-of-Self-Supervised-Speech-Models-for-Downstream-Speech-Recognition-Tasks-“In-the-Wild’’"><a href="#On-the-Impact-of-Quantization-and-Pruning-of-Self-Supervised-Speech-Models-for-Downstream-Speech-Recognition-Tasks-“In-the-Wild’’" class="headerlink" title="On the Impact of Quantization and Pruning of Self-Supervised Speech Models for Downstream Speech Recognition Tasks “In-the-Wild’’"></a>On the Impact of Quantization and Pruning of Self-Supervised Speech Models for Downstream Speech Recognition Tasks “In-the-Wild’’</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14462">http://arxiv.org/abs/2309.14462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arthur Pimentel, Heitor Guimarães, Anderson R. Avila, Mehdi Rezagholizadeh, Tiago H. Falk</li>
<li>for: 本研究旨在探讨基于自动编程学习的语音识别系统在不同条件下的准确率，特别是在训练和测试条件不同时的情况下。</li>
<li>methods: 本研究使用了Parameter Quantization和Model Pruning两种模型压缩方法，以及robust wav2vec 2.0模型，对语音识别精度进行了分析。</li>
<li>results: 研究发现，在噪音、抑扬和噪音+抑扬等不同条件下，Parameter Quantization和Model Pruning两种方法都能够有效地提高语音识别精度。<details>
<summary>Abstract</summary>
Recent advances with self-supervised learning have allowed speech recognition systems to achieve state-of-the-art (SOTA) word error rates (WER) while requiring only a fraction of the labeled training data needed by its predecessors. Notwithstanding, while such models achieve SOTA performance in matched train/test conditions, their performance degrades substantially when tested in unseen conditions. To overcome this problem, strategies such as data augmentation and/or domain shift training have been explored. Available models, however, are still too large to be considered for edge speech applications on resource-constrained devices, thus model compression tools are needed. In this paper, we explore the effects that train/test mismatch conditions have on speech recognition accuracy based on compressed self-supervised speech models. In particular, we report on the effects that parameter quantization and model pruning have on speech recognition accuracy based on the so-called robust wav2vec 2.0 model under noisy, reverberant, and noise-plus-reverberation conditions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Investigation-of-Distribution-Alignment-in-Multi-Genre-Speaker-Recognition"><a href="#An-Investigation-of-Distribution-Alignment-in-Multi-Genre-Speaker-Recognition" class="headerlink" title="An Investigation of Distribution Alignment in Multi-Genre Speaker Recognition"></a>An Investigation of Distribution Alignment in Multi-Genre Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14158">http://arxiv.org/abs/2309.14158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyu Zhou, Junhui Chen, Namin Wang, Lantian Li, Dong Wang</li>
<li>for: 本研究旨在 investigate the performance of mainstream distribution alignment methods on multi-genre data, 以便更好地 Addressing the challenges of multi-genre speaker recognition.</li>
<li>methods: 本研究使用了多种主流分布Alignment方法，包括 Within-between distribution alignment (WBDA) 等。</li>
<li>results: 实验结果表明，WBDA方法在 CN-Celeb  dataset 中表现较好，但是 None of the investigated methods consistently improved performance in all test cases. 这表明尚未发展出一种全面的解决方案。<details>
<summary>Abstract</summary>
Multi-genre speaker recognition is becoming increasingly popular due to its ability to better represent the complexities of real-world applications. However, a major challenge is the significant shift in the distribution of speaker vectors across different genres. While distribution alignment is a common approach to address this challenge, previous studies have mainly focused on aligning a source domain with a target domain, and the performance of multi-genre data is unknown.   This paper presents a comprehensive study of mainstream distribution alignment methods on multi-genre data, where multiple distributions need to be aligned. We analyze various methods both qualitatively and quantitatively. Our experiments on the CN-Celeb dataset show that within-between distribution alignment (WBDA) performs relatively better. However, we also found that none of the investigated methods consistently improved performance in all test cases. This suggests that solely aligning the distributions of speaker vectors may not fully address the challenges posed by multi-genre speaker recognition. Further investigation is necessary to develop a more comprehensive solution.
</details>
<details>
<summary>摘要</summary>
多样化 Speaker 认知正在不断受欢迎，主要是因为它能更好地反映实际应用中的复杂性。然而，一个主要挑战是多个频率域之间的分布变化。过往的研究主要集中在将源频率域与目标频率域进行分布对接，并未探讨多个频率域数据的性能。本文对多个频率域数据进行了全面的分布对接方法研究。我们分析了各种方法，包括内在between分布对接（WBDA）等。我们的实验结果表明，WBDA在CN-Celeb 数据集上表现较好。然而，我们还发现，不同的测试情况下，不同的方法的性能表现不一致。这表明，仅仅通过对 speaker  vector 的分布进行对接，并不能彻底解决多个频率域 Speaker 认知中的挑战。需要进一步的研究，以开发更加全面的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Multi-Domain-Adaptation-by-Self-Supervised-Learning-for-Speaker-Verification"><a href="#Multi-Domain-Adaptation-by-Self-Supervised-Learning-for-Speaker-Verification" class="headerlink" title="Multi-Domain Adaptation by Self-Supervised Learning for Speaker Verification"></a>Multi-Domain Adaptation by Self-Supervised Learning for Speaker Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14149">http://arxiv.org/abs/2309.14149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wan Lin, Lantian Li, Dong Wang</li>
<li>for: addressing the domain-mismatch challenge in speaker recognition models</li>
<li>methods: self-supervised learning method with three strategies (in-domain negative sampling, MoCo-like memory bank scheme, and CORAL-like distribution alignment)</li>
<li>results: outperforms the basic self-supervised adaptation method in nearly all in-domain tests and cross-domain tests, demonstrating the effectiveness of the proposed method.<details>
<summary>Abstract</summary>
In real-world applications, speaker recognition models often face various domain-mismatch challenges, leading to a significant drop in performance. Although numerous domain adaptation techniques have been developed to address this issue, almost all present methods focus on a simple configuration where the model is trained in one domain and deployed in another. However, real-world environments are often complex and may contain multiple domains, making the methods designed for one-to-one adaptation suboptimal. In our paper, we propose a self-supervised learning method to tackle this multi-domain adaptation problem. Building upon the basic self-supervised adaptation algorithm, we designed three strategies to make it suitable for multi-domain adaptation: an in-domain negative sampling strategy, a MoCo-like memory bank scheme, and a CORAL-like distribution alignment. We conducted experiments using VoxCeleb2 as the source domain dataset and CN-Celeb1 as the target multi-domain dataset. Our results demonstrate that our method clearly outperforms the basic self-supervised adaptation method, which simply treats the data of CN-Celeb1 as a single domain. Importantly, the improvement is consistent in nearly all in-domain tests and cross-domain tests, demonstrating the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
在实际应用中，语音识别模型经常面临不同领域的挑战，导致其性能下降。虽然已有许多领域适应技术的研发，但大多数方法都是基于单个领域的训练和部署。然而，实际环境往往复杂，可能包含多个领域，这些方法在一对一适应下表现不佳。在我们的论文中，我们提出了一种基于自助学习的多领域适应方法。我们在基本的自助适应算法之上设计了三种策略，使其适应多领域适应：在领域内的负样本采样策略、MoCo-like储存银行方案以及CORAL-like分布对齐。我们使用VoxCeleb2作为源领域数据集，CN-Celeb1作为目标多领域数据集，并进行了实验。我们的结果表明，我们的方法在比较多个领域的测试中均有显著提高，而且这种改进是在几乎所有的领域测试和跨领域测试中均有，这说明了我们提出的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Speaker-anonymization-using-neural-audio-codec-language-models"><a href="#Speaker-anonymization-using-neural-audio-codec-language-models" class="headerlink" title="Speaker anonymization using neural audio codec language models"></a>Speaker anonymization using neural audio codec language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14129">http://arxiv.org/abs/2309.14129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michele Panariello, Francesco Nespoli, Massimiliano Todisco, Nicholas Evans</li>
<li>for: 隐藏发音者的匿名（Speaker Anonymization）</li>
<li>methods: 使用神经网络编码器（NAC）和语言模型来生成高质量的匿名语音（Synthetic Speech），并使用量化码来瓶颈发音者相关的信息</li>
<li>results: 通过应用voice Privacy Challenge 2022的评价框架，示出NAC语言模型可以实现高质量的匿名语音生成，并且能够有效瓶颈发音者相关的信息<details>
<summary>Abstract</summary>
The vast majority of approaches to speaker anonymization involve the extraction of fundamental frequency estimates, linguistic features and a speaker embedding which is perturbed to obfuscate the speaker identity before an anonymized speech waveform is resynthesized using a vocoder. Recent work has shown that x-vector transformations are difficult to control consistently: other sources of speaker information contained within fundamental frequency and linguistic features are re-entangled upon vocoding, meaning that anonymized speech signals still contain speaker information. We propose an approach based upon neural audio codecs (NACs), which are known to generate high-quality synthetic speech when combined with language models. NACs use quantized codes, which are known to effectively bottleneck speaker-related information: we demonstrate the potential of speaker anonymization systems based on NAC language modeling by applying the evaluation framework of the Voice Privacy Challenge 2022.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose an approach based on neural audio codecs (NACs), which are known to generate high-quality synthetic speech when combined with language models. NACs use quantized codes that effectively bottleneck speaker-related information. We demonstrate the potential of speaker anonymization systems based on NAC language modeling by applying the evaluation framework of the Voice Privacy Challenge 2022.Here's the text in Simplified Chinese:大多数speaker anonymization方法都包括提取基本频率估计、语言特征和一个扰乱后的speaker嵌入，然后使用vocoder重新synthesize一个匿名的语音波形。然而，最近的研究表明，x-vector变换很难控制一致地：在vocoding后，其他speaker信息包含在基本频率和语言特征中被重新杂化，导致匿名的语音信号仍然含有speaker信息。在这篇论文中，我们提出一种基于Neural Audio Codecs（NAC）的方法，NACs是在语言模型 комбиined with高质量的Synthetic Speech生成。NACs使用归一化的编码，这些编码可以有效地瓶颈speaker相关的信息。我们通过应用Voice Privacy Challenge 2022的评估框架，示出了基于NAC语言模型的speaker匿名系统的潜在能力。
</details></li>
</ul>
<hr>
<h2 id="Haha-Pod-An-Attempt-for-Laughter-based-Non-Verbal-Speaker-Verification"><a href="#Haha-Pod-An-Attempt-for-Laughter-based-Non-Verbal-Speaker-Verification" class="headerlink" title="Haha-Pod: An Attempt for Laughter-based Non-Verbal Speaker Verification"></a>Haha-Pod: An Attempt for Laughter-based Non-Verbal Speaker Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14109">http://arxiv.org/abs/2309.14109</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nevermorelin/hahapod">https://github.com/nevermorelin/hahapod</a></li>
<li>paper_authors: Yuke Lin, Xiaoyi Qin, Ning Jiang, Guoqing Zhao, Ming Li</li>
<li>for:  explore speaker verification based on non-verbal vocalization, specifically laughter</li>
<li>methods:  Two-Stage Teacher-Student (2S-TS) framework to minimize the within-speaker embedding distance between verbal and non-verbal signals</li>
<li>results:  significant improvement in S2L-Eval test set performance with only minor degradation on VoxCeleb1 test set.Here’s the full summary in Simplified Chinese:</li>
<li>for: 这个研究探讨了基于非言语 vocalization 的 speaker verification，具体是 laughter。</li>
<li>methods: 这个研究提出了 Two-Stage Teacher-Student (2S-TS) 框架，以实现非言语 vocalization 和言语信号之间的内部距离最小化。</li>
<li>results: 实验结果显示，这个方法可以对 S2L-Eval 试验集的表现有所提高，仅受 VoxCeleb1 试验集的轻微下降影响。I hope that helps!<details>
<summary>Abstract</summary>
It is widely acknowledged that discriminative representation for speaker verification can be extracted from verbal speech. However, how much speaker information that non-verbal vocalization carries is still a puzzle. This paper explores speaker verification based on the most ubiquitous form of non-verbal voice, laughter. First, we use a semi-automatic pipeline to collect a new Haha-Pod dataset from open-source podcast media. The dataset contains over 240 speakers' laughter clips with corresponding high-quality verbal speech. Second, we propose a Two-Stage Teacher-Student (2S-TS) framework to minimize the within-speaker embedding distance between verbal and non-verbal (laughter) signals. Considering Haha-Pod as a test set, two trials (S2L-Eval) are designed to verify the speaker's identity through laugh sounds. Experimental results demonstrate that our method can significantly improve the performance of the S2L-Eval test set with only a minor degradation on the VoxCeleb1 test set. The resources for the Haha-Pod dataset can be found at https://github.com/nevermoreLin/HahaPod.
</details>
<details>
<summary>摘要</summary>
广泛认可的观点是，演说中的特征表达可以提取到说话中的声音中。然而，非语言声音中带有多少说话者信息仍然是一个谜。这篇论文探讨基于最普遍的非语言声音——笑声的说话者验证。我们首先使用半自动化管道收集了一个新的 Haha-Pod 数据集，该数据集包含了240个说话者的笑声clip，其中每个clip都有高质量的语音。然后，我们提出了一个 Two-Stage Teacher-Student (2S-TS) 框架，以减少语音和笑声信号之间的在说话者 embedding 距离。对于 Haha-Pod 数据集，我们设计了两次（S2L-Eval）测试来验证说话者的身份。实验结果表明，我们的方法可以显著提高 S2L-Eval 测试集的性能，只有微量地降低 VoxCeleb1 测试集的性能。Haha-Pod 数据集的资源可以在 GitHub 上找到：https://github.com/nevermoreLin/HahaPod。
</details></li>
</ul>
<hr>
<h2 id="VoiceLens-Controllable-Speaker-Generation-and-Editing-with-Flow"><a href="#VoiceLens-Controllable-Speaker-Generation-and-Editing-with-Flow" class="headerlink" title="VoiceLens: Controllable Speaker Generation and Editing with Flow"></a>VoiceLens: Controllable Speaker Generation and Editing with Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14094">http://arxiv.org/abs/2309.14094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shi, Ming Li</li>
<li>for: 这篇论文目的是为多个说话人的语音合成和voice转换系统提供一种 semi-supervised flow-based 方法，以模型说话人的嵌入vector distribution，并在不同的条件下进行多个说话人的生成和编辑。</li>
<li>methods: 该论文提出了一种名为 VoiceLens 的方法，它将说话人嵌入vector 映射到独立的特征和差异信息中。该方法允许在已有的 TTS 模型基础上生成新的说话人voice，并可以meaningfully 编辑已知的说话人的特征。</li>
<li>results: 该论文表明，VoiceLens 在不同的条件下 display 了类似于 Tacospawn 的无条件生成能力，同时具有更高的控制性和灵活性。此外，使用 VoiceLens 模型可以在不需要重新训练 TTS 模型的情况下，将已知的噪音说话人的嵌入vector 编辑，并生成 cleaner 的语音。<details>
<summary>Abstract</summary>
Currently, many multi-speaker speech synthesis and voice conversion systems address speaker variations with an embedding vector. Modeling it directly allows new voices outside of training data to be synthesized. GMM based approaches such as Tacospawn are favored in literature for this generation task, but there are still some limitations when difficult conditionings are involved. In this paper, we propose VoiceLens, a semi-supervised flow-based approach, to model speaker embedding distributions for multi-conditional speaker generation. VoiceLens maps speaker embeddings into a combination of independent attributes and residual information. It allows new voices associated with certain attributes to be \textit{generated} for existing TTS models, and attributes of known voices to be meaningfully \textit{edited}. We show in this paper, VoiceLens displays an unconditional generation capacity that is similar to Tacospawn while obtaining higher controllability and flexibility when used in a conditional manner. In addition, we show synthesizing less noisy speech from known noisy speakers without re-training the TTS model is possible via solely editing their embeddings with a SNR conditioned VoiceLens model. Demos are available at sos1sos2sixteen.github.io/voicelens.
</details>
<details>
<summary>摘要</summary>
当前，许多多 speaker speech synthesis 和voice conversion系统使用 embedding vector来处理 speaker variations。直接模型它们允许在训练数据外部生成新的voice。文献中，GMM基于的approaches such as Tacospawn 是常见的 Generation Task 方法，但是在具有困难的conditioning时还存在一些限制。在这篇论文中，我们提出了 VoiceLens，一种半supervised flow-based方法，用于模型 speaker embedding Distributions  для多 conditional speaker Generation。VoiceLens将 speaker embeddings映射到独立的特征和差异信息中。它允许基于已有 TTS 模型的新音频 associates with certain attributes 被生成，并且可以 meaningfully edit 已知音频的特征。我们在这篇论文中表明，VoiceLens 在不conditional 的情况下 display 类似于 Tacospawn 的无条件生成能力，同时在具有条件的情况下具有更高的控制性和灵活性。此外，我们还证明可以通过只编辑 embedding 来从已知噪音speakers中生成更清晰的speech，无需重新训练 TTS 模型。示例可以在 sos1sos2sixteen.github.io/voicelens 上找到。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Accent-Adaptation-Through-Masked-Language-Model-Correction-Of-Discrete-Self-Supervised-Speech-Units"><a href="#Unsupervised-Accent-Adaptation-Through-Masked-Language-Model-Correction-Of-Discrete-Self-Supervised-Speech-Units" class="headerlink" title="Unsupervised Accent Adaptation Through Masked Language Model Correction Of Discrete Self-Supervised Speech Units"></a>Unsupervised Accent Adaptation Through Masked Language Model Correction Of Discrete Self-Supervised Speech Units</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13994">http://arxiv.org/abs/2309.13994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakob Poncelet, Hugo Van hamme</li>
<li>for: 改善预训练语音模型对不同口音和异常语音的敏感性</li>
<li>methods: 使用遮盖语言模型和小口音适应器块进行不supervised调整</li>
<li>results: 提高 HuBERT Large 模型在下游口音识别任务中的性能，无需监督<details>
<summary>Abstract</summary>
Self-supervised pre-trained speech models have strongly improved speech recognition, yet they are still sensitive to domain shifts and accented or atypical speech. Many of these models rely on quantisation or clustering to learn discrete acoustic units. We propose to correct the discovered discrete units for accented speech back to a standard pronunciation in an unsupervised manner. A masked language model is trained on discrete units from a standard accent and iteratively corrects an accented token sequence by masking unexpected cluster sequences and predicting their common variant. Small accent adapter blocks are inserted in the pre-trained model and fine-tuned by predicting the corrected clusters, which leads to an increased robustness of the pre-trained model towards a target accent, and this without supervision. We are able to improve a state-of-the-art HuBERT Large model on a downstream accented speech recognition task by altering the training regime with the proposed method.
</details>
<details>
<summary>摘要</summary>
自适应预训练音频模型已经强化了语音识别，但它们仍然敏感于频谱转移和不同口音或特殊语音。许多这些模型利用量化或归一化学习独立的声学单元。我们提议将捕捉到的特殊单元 Corrected 到标准发音的方式，以便在无监督的情况下进行改进。我们使用遮盖语言模型，并在预训练模型中插入小口音适应块，进行无监督的改进，以提高预训练模型对目标口音的抗频谱性能。我们通过修改训练方法，使用我们的方法来改进一个state-of-the-art HuBERT Large模型，并在下游受损 speech recognition 任务中获得了改进。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Emergency-Vehicle-Detection-using-Mel-Spectrograms-and-Regular-Expressions"><a href="#Real-Time-Emergency-Vehicle-Detection-using-Mel-Spectrograms-and-Regular-Expressions" class="headerlink" title="Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular Expressions"></a>Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular Expressions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13920">http://arxiv.org/abs/2309.13920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Pacheco-Gonzalez, Raymundo Torres, Raul Chacon, Isidro Robledo</li>
<li>for:  detecting emergency vehicle sirens in real time</li>
<li>methods:  digital signal processing techniques and signal symbolization, compared to a deep neural network audio classifier</li>
<li>results:  the developed DSP algorithm presented a greater ability to discriminate between signal and noise, compared to the CNN model.Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这个论文旨在实时探测紧急车辆 siren 声音。</li>
<li>methods: 该论文使用的方法包括数字信号处理技术和信号符号化，并与深度神经网络音频分类器进行比较。</li>
<li>results: 发展的 DSP 算法在听到信号和噪声之间的分辨率比 CNN 模型更高。<details>
<summary>Abstract</summary>
In emergency situations, the movement of vehicles through city streets can be problematic due to vehicular traffic. This paper presents a method for detecting emergency vehicle sirens in real time. To derive a siren Hi-Lo audio fingerprint it was necessary to apply digital signal processing techniques and signal symbolization, contrasting against a deep neural network audio classifier feeding 280 environmental sounds and 38 Hi-Lo sirens. In both methods, their precision was evaluated based on a confusion matrix and various metrics. The precision of the developed DSP algorithm presented a greater ability to discriminate between signal and noise, compared to the CNN model.
</details>
<details>
<summary>摘要</summary>
在紧急情况下，城市街道上的车辆运动可能会受到交通堵塞的影响。本文提出了一种实时探测紧急车辆 siren 的方法。为 derivation 紧急 siren Hi-Lo 音响指纹，需要应用数字信号处理技术和音标化，并与深度神经网络音频分类器相比较，该分类器接受了 280 个环境声和 38 个 Hi-Lo  siren。在两种方法中，它们的准确率被评估基于冲激矩阵和多种指标。发展的 DSP 算法表现出更高的能力来 отли奇 Between signal 和噪声，相比 CNN 模型。
</details></li>
</ul>
<hr>
<h2 id="Frame-wise-streaming-end-to-end-speaker-diarization-with-non-autoregressive-self-attention-based-attractors"><a href="#Frame-wise-streaming-end-to-end-speaker-diarization-with-non-autoregressive-self-attention-based-attractors" class="headerlink" title="Frame-wise streaming end-to-end speaker diarization with non-autoregressive self-attention-based attractors"></a>Frame-wise streaming end-to-end speaker diarization with non-autoregressive self-attention-based attractors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13916">http://arxiv.org/abs/2309.13916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-westlakeu/fs-eend">https://github.com/audio-westlakeu/fs-eend</a></li>
<li>paper_authors: Di Liang, Nian Shao, Xiaofei Li</li>
<li>for: 这种方法用于实时语音分类和说话者识别</li>
<li>methods: 使用 causal speaker embedding encoder 和 online non-autoregressive self-attention-based attractor decoder，采用 look-ahead 机制以实时检测新的说话者并自适应更新说话者吸引器</li>
<li>results: 与最近提出的块 wise online方法相比，本方法实现了状态机器的分类和说话者识别结果，并且具有低的推理延迟和计算成本<details>
<summary>Abstract</summary>
This work proposes a frame-wise online/streaming end-to-end neural diarization (FS-EEND) method in a frame-in-frame-out fashion. To frame-wisely detect a flexible number of speakers and extract/update their corresponding attractors, we propose to leverage a causal speaker embedding encoder and an online non-autoregressive self-attention-based attractor decoder. A look-ahead mechanism is adopted to allow leveraging some future frames for effectively detecting new speakers in real time and adaptively updating speaker attractors. The proposed method processes the audio stream frame by frame, and has a low inference latency caused by the look-ahead frames. Experiments show that, compared with the recently proposed block-wise online methods, our method FS-EEND achieves state-of-the-art diarization results, with a low inference latency and computational cost.
</details>
<details>
<summary>摘要</summary>
这个工作提出了一种帧级在线/流动端到端神经 диари化（FS-EEND）方法，采用帧内帧外的方式进行检测。为了在帧级检测灵活数量的说话人并提取/更新其相应的吸引器，我们提议利用 causal 说话人嵌入编码器和在线非autoregressive自注意力基本吸引器解码器。采用了 looked-ahead 机制，以便利用未来帧来有效地检测新的说话人并动态更新说话人吸引器。提posed 方法按帧处理音频流，并且具有低的推理延迟和计算成本。实验表明，相比最近提出的块级在线方法，我们的方法FS-EEND可以 achieve state-of-the-art  диари化结果，同时具有低的推理延迟和计算成本。
</details></li>
</ul>
<hr>
<h2 id="HiGNN-TTS-Hierarchical-Prosody-Modeling-with-Graph-Neural-Networks-for-Expressive-Long-form-TTS"><a href="#HiGNN-TTS-Hierarchical-Prosody-Modeling-with-Graph-Neural-Networks-for-Expressive-Long-form-TTS" class="headerlink" title="HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for Expressive Long-form TTS"></a>HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for Expressive Long-form TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13907">http://arxiv.org/abs/2309.13907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dake Guo, Xinfa Zhu, Liumeng Xue, Tao Li, Yuanjun Lv, Yuepeng Jiang, Lei Xie</li>
<li>for: 提高短 фор式文本译 Speech 表现力</li>
<li>methods: 使用嵌入式Global Node和上下文注意力机制，以及层次supervision来增强GNNs的表达能力</li>
<li>results: 对象和主观评估都表明，HiGNN-TTS可以显著提高长形文本译Speech的自然性和表达力<details>
<summary>Abstract</summary>
Recent advances in text-to-speech, particularly those based on Graph Neural Networks (GNNs), have significantly improved the expressiveness of short-form synthetic speech. However, generating human-parity long-form speech with high dynamic prosodic variations is still challenging. To address this problem, we expand the capabilities of GNNs with a hierarchical prosody modeling approach, named HiGNN-TTS. Specifically, we add a virtual global node in the graph to strengthen the interconnection of word nodes and introduce a contextual attention mechanism to broaden the prosody modeling scope of GNNs from intra-sentence to inter-sentence. Additionally, we perform hierarchical supervision from acoustic prosody on each node of the graph to capture the prosodic variations with a high dynamic range. Ablation studies show the effectiveness of HiGNN-TTS in learning hierarchical prosody. Both objective and subjective evaluations demonstrate that HiGNN-TTS significantly improves the naturalness and expressiveness of long-form synthetic speech.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近期文本到语音技术的进步，特别是基于图像神经网络（GNNs），有效提高了短形文本合成语音的表达力。然而，生成人工合理的长形语音，尚存在高Dynamic Prosody变化的挑战。为解决这个问题，我们扩展了GNNs的能力，通过层次听音模型策略（HiGNN-TTS）。具体来说，我们在图像中添加虚拟全球节点，强化单词节点之间的连接，并引入Contextual Attention机制，以扩展GNNs的听音模型范围从内句到间句。此外，我们在每个图像节点上进行层次监督，从听音PROSODY级别进行多层次监督，以捕捉高Dynamic Prosody变化。ablation study表明HiGNN-TTS有效学习层次听音。对象和主观评价表明，HiGNN-TTS可以显著提高长形文本合成语音的自然性和表达力。
</details></li>
</ul>
<hr>
<h2 id="AutoPrep-An-Automatic-Preprocessing-Framework-for-In-the-Wild-Speech-Data"><a href="#AutoPrep-An-Automatic-Preprocessing-Framework-for-In-the-Wild-Speech-Data" class="headerlink" title="AutoPrep: An Automatic Preprocessing Framework for In-the-Wild Speech Data"></a>AutoPrep: An Automatic Preprocessing Framework for In-the-Wild Speech Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13905">http://arxiv.org/abs/2309.13905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tomasJwYU/AutoPrepDemo">https://github.com/tomasJwYU/AutoPrepDemo</a></li>
<li>paper_authors: Jianwei Yu, Hangting Chen, Yanyao Bian, Xiang Li, Yi Luo, Jinchuan Tian, Mengyang Liu, Jiayi Jiang, Shuai Wang</li>
<li>for: 提高听说技术领域中各种大规模语音数据的使用效率</li>
<li>methods: 提出了一种自动化听说数据预处理框架AutoPrep，包括声音提升、听说段化、speaker clustering、目标听说提取、质量筛选和自动听说识别</li>
<li>results: 实验表明，提出的AutoPrep框架可以生成与多个开源TTS数据集相似的DNMS和PDNMS分数，并且可以实现0.68的在域内 speaker相似性<details>
<summary>Abstract</summary>
Recently, the utilization of extensive open-sourced text data has significantly advanced the performance of text-based large language models (LLMs). However, the use of in-the-wild large-scale speech data in the speech technology community remains constrained. One reason for this limitation is that a considerable amount of the publicly available speech data is compromised by background noise, speech overlapping, lack of speech segmentation information, missing speaker labels, and incomplete transcriptions, which can largely hinder their usefulness. On the other hand, human annotation of speech data is both time-consuming and costly. To address this issue, we introduce an automatic in-the-wild speech data preprocessing framework (AutoPrep) in this paper, which is designed to enhance speech quality, generate speaker labels, and produce transcriptions automatically. The proposed AutoPrep framework comprises six components: speech enhancement, speech segmentation, speaker clustering, target speech extraction, quality filtering and automatic speech recognition. Experiments conducted on the open-sourced WenetSpeech and our self-collected AutoPrepWild corpora demonstrate that the proposed AutoPrep framework can generate preprocessed data with similar DNSMOS and PDNSMOS scores compared to several open-sourced TTS datasets. The corresponding TTS system can achieve up to 0.68 in-domain speaker similarity.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近，通过大量开源的文本数据的使用，文本基本语言模型（LLM）的性能得到了显著提高。然而，对于语音技术社区中的大规模语音数据来说，使用尚未得到有效利用。一个原因是公共可用的语音数据中很多受到背景噪音、语音重叠、语音分割信息缺失、缺失说话人标签和不完整的转录等限制，这些限制可以很大地阻碍其使用。而人工标注语音数据则是时间consuming和costly。为解决这个问题，我们在这篇论文中介绍了一种自动化对话语音数据预处理框架（AutoPrep），用于提高语音质量、生成说话人标签和生成转录。AutoPrep框架包括6个组件：语音增强、语音分割、说话人团 clustering、目标语音提取、质量筛选和自动语音识别。在open-sourced WenetSpeech和我们自己收集的AutoPrepWild corpora上进行的实验表明，提posed AutoPrep框架可以生成与开源 TTS 数据集相似的 DNSMOS 和 PDNSMOS 分数，并且可以达到0.68 的域内说话人相似性。
</details></li>
</ul>
<hr>
<h2 id="A-Two-Step-Approach-for-Narrowband-Source-Localization-in-Reverberant-Rooms"><a href="#A-Two-Step-Approach-for-Narrowband-Source-Localization-in-Reverberant-Rooms" class="headerlink" title="A Two-Step Approach for Narrowband Source Localization in Reverberant Rooms"></a>A Two-Step Approach for Narrowband Source Localization in Reverberant Rooms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13819">http://arxiv.org/abs/2309.13819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei-Ting Lai, Lachlan Birnie, Thushara Abhayapala, Amy Bastine, Shaoheng Xu, Prasanga Samarasinghe</li>
<li>for: 本研究旨在提出一种基于两步方法的窄带源localization算法，用于听觉环境中的音源定位。</li>
<li>methods: 该方法首先使用Iteratively Reweighted Least Squares（IRLS）模型干扰音场的同质分量，然后使用Orthogonal Matching Pursuit（OMP）模型干扰分量为点源分布的稀疏表示。</li>
<li>results: 实验结果表明，该方法可以减少测量量而提高定位精度，特别是在听觉环境中。此外，该方法可以不需要先知道房间边界条件和室内geometry，因此可以适用于不同的室内环境。<details>
<summary>Abstract</summary>
This paper presents a two-step approach for narrowband source localization within reverberant rooms. The first step involves dereverberation by modeling the homogeneous component of the sound field by an equivalent decomposition of planewaves using Iteratively Reweighted Least Squares (IRLS), while the second step focuses on source localization by modeling the dereverberated component as a sparse representation of point-source distribution using Orthogonal Matching Pursuit (OMP). The proposed method enhances localization accuracy with fewer measurements, particularly in environments with strong reverberation. A numerical simulation in a conference room scenario, using a uniform microphone array affixed to the wall, demonstrates real-world feasibility. Notably, the proposed method and microphone placement effectively localize sound sources within the 2D-horizontal plane without requiring prior knowledge of boundary conditions and room geometry, making it versatile for application in different room types.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/25/cs.SD_2023_09_25/" data-id="clogyj90r00vd7craa5owb7ya" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/25/cs.CV_2023_09_25/" class="article-date">
  <time datetime="2023-09-25T13:00:00.000Z" itemprop="datePublished">2023-09-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/25/cs.CV_2023_09_25/">cs.CV - 2023-09-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MEMO-Dataset-and-Methods-for-Robust-Multimodal-Retinal-Image-Registration-with-Large-or-Small-Vessel-Density-Differences"><a href="#MEMO-Dataset-and-Methods-for-Robust-Multimodal-Retinal-Image-Registration-with-Large-or-Small-Vessel-Density-Differences" class="headerlink" title="MEMO: Dataset and Methods for Robust Multimodal Retinal Image Registration with Large or Small Vessel Density Differences"></a>MEMO: Dataset and Methods for Robust Multimodal Retinal Image Registration with Large or Small Vessel Density Differences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14550">http://arxiv.org/abs/2309.14550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chiao-Yi Wang, Faranguisse Kakhi Sadrieh, Yi-Ting Shen, Shih-En Chen, Sarah Kim, Victoria Chen, Achyut Raghavendra, Dongyi Wang, Osamah Saeedi, Yang Tao</li>
<li>for: 这个论文的目的是提出一种基于多Modalities的血液流量测量方法，以便早期诊断和治疗 ocular 疾病。</li>
<li>methods: 这个方法使用了 EMA 和 OCTA 两种多Modalities，并提出了一种基于 segmentation 的深度学习框架 (VDD-Reg) 和一种新的评价指标 (MSD)，以Address 多Modalities 中血液管道的不同而导致的注射挑战。</li>
<li>results: 在 CF-FA 数据集和 MEMO 数据集上，VDD-Reg 表现出了较好的性能，并且只需要三个注解的血液管道分割图来维持其精度。<details>
<summary>Abstract</summary>
The measurement of retinal blood flow (RBF) in capillaries can provide a powerful biomarker for the early diagnosis and treatment of ocular diseases. However, no single modality can determine capillary flowrates with high precision. Combining erythrocyte-mediated angiography (EMA) with optical coherence tomography angiography (OCTA) has the potential to achieve this goal, as EMA can measure the absolute 2D RBF of retinal microvasculature and OCTA can provide the 3D structural images of capillaries. However, multimodal retinal image registration between these two modalities remains largely unexplored. To fill this gap, we establish MEMO, the first public multimodal EMA and OCTA retinal image dataset. A unique challenge in multimodal retinal image registration between these modalities is the relatively large difference in vessel density (VD). To address this challenge, we propose a segmentation-based deep-learning framework (VDD-Reg) and a new evaluation metric (MSD), which provide robust results despite differences in vessel density. VDD-Reg consists of a vessel segmentation module and a registration module. To train the vessel segmentation module, we further designed a two-stage semi-supervised learning framework (LVD-Seg) combining supervised and unsupervised losses. We demonstrate that VDD-Reg outperforms baseline methods quantitatively and qualitatively for cases of both small VD differences (using the CF-FA dataset) and large VD differences (using our MEMO dataset). Moreover, VDD-Reg requires as few as three annotated vessel segmentation masks to maintain its accuracy, demonstrating its feasibility.
</details>
<details>
<summary>摘要</summary>
retinal blood flow (RBF) 的测量可以提供一个强大的生物标志物，用于早期诊断和治疗 ocular diseases。然而，没有一种单一的模式可以准确地确定 capillary flowrates。 combing erythrocyte-mediated angiography (EMA) 与 optical coherence tomography angiography (OCTA) 可以实现这个目标，因为 EMA 可以测量 retinal microvasculature 的绝对 2D RBF，而 OCTA 可以提供 capillaries 的 3D 结构图像。然而，多modal retinal image registration between these two modalities 仍然存在很大的知识 gap。 To fill this gap, we establish MEMO, the first public multimodal EMA and OCTA retinal image dataset.一个Unique challenge in multimodal retinal image registration between these modalities 是 vessel density (VD) 的相对较大的差异。 To address this challenge, we propose a segmentation-based deep-learning framework (VDD-Reg) 和 a new evaluation metric (MSD), which provide robust results despite differences in vessel density. VDD-Reg consists of a vessel segmentation module and a registration module. To train the vessel segmentation module, we further designed a two-stage semi-supervised learning framework (LVD-Seg) combining supervised and unsupervised losses. We demonstrate that VDD-Reg outperforms baseline methods quantitatively and qualitatively for cases of both small VD differences (using the CF-FA dataset) and large VD differences (using our MEMO dataset). Moreover, VDD-Reg requires as few as three annotated vessel segmentation masks to maintain its accuracy, demonstrating its feasibility.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Scene-Graph-Representation-for-Surgical-Video"><a href="#Dynamic-Scene-Graph-Representation-for-Surgical-Video" class="headerlink" title="Dynamic Scene Graph Representation for Surgical Video"></a>Dynamic Scene Graph Representation for Surgical Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14538">http://arxiv.org/abs/2309.14538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix Holm, Ghazal Ghazaei, Tobias Czempiel, Ege Özsoy, Stefan Saur, Nassir Navab</li>
<li>for:  This paper aims to improve the automated understanding of surgical workflows in videos captured from microscopic or endoscopic imaging devices.</li>
<li>methods: The paper proposes using scene graphs as a more holistic and semantically meaningful way to represent surgical videos, and leverages graph convolutional networks (GCNs) to tackle surgical downstream tasks such as workflow recognition.</li>
<li>results: The paper demonstrates the benefits of surgical scene graphs in terms of explainability and robustness of model decisions, and shows competitive performance in surgical workflow recognition tasks.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文目的是提高微scopic或endoscopic imaging设备上捕捉的手术视频自动理解的方法。</li>
<li>methods: 论文提出使用场景图表示手术视频，并利用图 convolutional neural networks (GCNs) 解决手术下沟通任务，如手术 workflow 认知。</li>
<li>results: 论文表明场景图在解释和模型决策的Robustness方面具有优势，并在手术 workflow 认知任务中显示竞争性表现。<details>
<summary>Abstract</summary>
Surgical videos captured from microscopic or endoscopic imaging devices are rich but complex sources of information, depicting different tools and anatomical structures utilized during an extended amount of time. Despite containing crucial workflow information and being commonly recorded in many procedures, usage of surgical videos for automated surgical workflow understanding is still limited.   In this work, we exploit scene graphs as a more holistic, semantically meaningful and human-readable way to represent surgical videos while encoding all anatomical structures, tools, and their interactions. To properly evaluate the impact of our solutions, we create a scene graph dataset from semantic segmentations from the CaDIS and CATARACTS datasets. We demonstrate that scene graphs can be leveraged through the use of graph convolutional networks (GCNs) to tackle surgical downstream tasks such as surgical workflow recognition with competitive performance. Moreover, we demonstrate the benefits of surgical scene graphs regarding the explainability and robustness of model decisions, which are crucial in the clinical setting.
</details>
<details>
<summary>摘要</summary>
手术录影幕 capture from microscopic or endoscopic imaging devices 是丰富且复杂的信息源，显示了不同的工具和生物结构在延时间进行了多种程度的交互。尽管这些录影幕在许多程序中很常见，但是用于自动推理手术 workflow 的使用仍然受限。在这个工作中，我们利用Scene graph来表示手术录影幕，并将所有生物结构和工具都编码在内。为了评估我们的解决方案的影响，我们创建了Scene graph dataset，并使用Graph Convolutional Networks (GCNs)来利用Scene graphs来解决手术下游任务，例如手术 workflow 识别，获得了竞争性的表现。此外，我们还证明了Scene graphs 在解释和Robustness 方面的利陵，这些是在临床设定中非常重要的。
</details></li>
</ul>
<hr>
<h2 id="Pixel-Grounded-Prototypical-Part-Networks"><a href="#Pixel-Grounded-Prototypical-Part-Networks" class="headerlink" title="Pixel-Grounded Prototypical Part Networks"></a>Pixel-Grounded Prototypical Part Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14531">http://arxiv.org/abs/2309.14531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zachariah Carmichael, Suhas Lohit, Anoop Cherian, Michael Jones, Walter Scheirer</li>
<li>for: 这个论文的目的是提高protoPartNN的解释性，并解决过去的localization问题。</li>
<li>methods: 这篇论文使用了新的�ceptive field-based architectural constraint和principled pixel space mapping来实现meaningful localization，并提出了一种简化的分类头来提高解释性。</li>
<li>results: 作者们的方法PIXPNET可以 Quantifiably improve interpretability without sacrificing accuracy，并且是唯一一个真正地学习和localize到权重部分的protoPartNN。<details>
<summary>Abstract</summary>
Prototypical part neural networks (ProtoPartNNs), namely PROTOPNET and its derivatives, are an intrinsically interpretable approach to machine learning. Their prototype learning scheme enables intuitive explanations of the form, this (prototype) looks like that (testing image patch). But, does this actually look like that? In this work, we delve into why object part localization and associated heat maps in past work are misleading. Rather than localizing to object parts, existing ProtoPartNNs localize to the entire image, contrary to generated explanatory visualizations. We argue that detraction from these underlying issues is due to the alluring nature of visualizations and an over-reliance on intuition. To alleviate these issues, we devise new receptive field-based architectural constraints for meaningful localization and a principled pixel space mapping for ProtoPartNNs. To improve interpretability, we propose additional architectural improvements, including a simplified classification head. We also make additional corrections to PROTOPNET and its derivatives, such as the use of a validation set, rather than a test set, to evaluate generalization during training. Our approach, PIXPNET (Pixel-grounded Prototypical part Network), is the only ProtoPartNN that truly learns and localizes to prototypical object parts. We demonstrate that PIXPNET achieves quantifiably improved interpretability without sacrificing accuracy.
</details>
<details>
<summary>摘要</summary>
归纳部神经网络（ProtoPartNNs）是一种内在可解释的机器学习方法。它的原型学习方案允许直观的解释，例如：这个原型看起来像那个测试图像的 patch。然而，这实际上是否看起来像那个？在这项工作中，我们探究过去的对象部分Localization和相关的热图是误导的。现有的ProtoPartNNs并不是localize到对象部分，而是localize到整个图像，与生成的解释性视觉化不符。我们认为这些问题的抽象是由于视觉化的吸引力和过于依赖于直观的INTUITION。为了解决这些问题，我们设计了新的接受场景基于的建筑限制，以及一个原则正确的像素空间映射。此外，我们还提出了更多的建筑改进，包括简化的分类头。我们还对PROTOPNET和其 Derivatives进行了修正，例如使用验证集而不是测试集来评估在训练过程中的普适性。我们的方法PIXPNET（像素基于的原型部分网络）是唯一一个真正地学习和localize到prototype object part。我们示出PIXPNET可以提供量化提高的可解释性而不损失准确性。
</details></li>
</ul>
<hr>
<h2 id="UniBEV-Multi-modal-3D-Object-Detection-with-Uniform-BEV-Encoders-for-Robustness-against-Missing-Sensor-Modalities"><a href="#UniBEV-Multi-modal-3D-Object-Detection-with-Uniform-BEV-Encoders-for-Robustness-against-Missing-Sensor-Modalities" class="headerlink" title="UniBEV: Multi-modal 3D Object Detection with Uniform BEV Encoders for Robustness against Missing Sensor Modalities"></a>UniBEV: Multi-modal 3D Object Detection with Uniform BEV Encoders for Robustness against Missing Sensor Modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14516">http://arxiv.org/abs/2309.14516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiming Wang, Holger Caesar, Liangliang Nan, Julian F. P. Kooij<br>for:这个论文的目的是提高自动驾驶中多感器对象检测模型的稳定性，特别是在感器输入缺失（modalities missing）的情况下。methods:这个论文提出了一种名为UniBEV的端到端多模态3D对象检测框架，可以在LiDAR和摄像头输入下运行，而无需 retraining。UniBEV使用了 Bird’s Eye View（BEV）特征地图来确保检测器的输入组合能够处理不同的输入。这种方法与之前的BEV多模态检测方法不同，所有的感器模式都采用了一种统一的方法来从原始感器坐标系统中采样特征到BEV特征。results:在nuScenes上对所有感器输入组合进行比较，UniBEV得到了52.5%的mAP平均值，与基线值（43.5%的mAP平均值）和MetaBEV（48.7%的mAP平均值）相比有显著提高。一个ablation研究表明，通过权重平均 fusioneather than regular concatenation，以及在每个模式的BEV编码器之间共享查询，可以提高对稳定性的依赖。<details>
<summary>Abstract</summary>
Multi-sensor object detection is an active research topic in automated driving, but the robustness of such detection models against missing sensor input (modality missing), e.g., due to a sudden sensor failure, is a critical problem which remains under-studied. In this work, we propose UniBEV, an end-to-end multi-modal 3D object detection framework designed for robustness against missing modalities: UniBEV can operate on LiDAR plus camera input, but also on LiDAR-only or camera-only input without retraining. To facilitate its detector head to handle different input combinations, UniBEV aims to create well-aligned Bird's Eye View (BEV) feature maps from each available modality. Unlike prior BEV-based multi-modal detection methods, all sensor modalities follow a uniform approach to resample features from the native sensor coordinate systems to the BEV features. We furthermore investigate the robustness of various fusion strategies w.r.t. missing modalities: the commonly used feature concatenation, but also channel-wise averaging, and a generalization to weighted averaging termed Channel Normalized Weights. To validate its effectiveness, we compare UniBEV to state-of-the-art BEVFusion and MetaBEV on nuScenes over all sensor input combinations. In this setting, UniBEV achieves $52.5 \%$ mAP on average over all input combinations, significantly improving over the baselines ($43.5 \%$ mAP on average for BEVFusion, $48.7 \%$ mAP on average for MetaBEV). An ablation study shows the robustness benefits of fusing by weighted averaging over regular concatenation, and of sharing queries between the BEV encoders of each modality. Our code will be released upon paper acceptance.
</details>
<details>
<summary>摘要</summary>
多感器对象检测是自动驾驶领域的活跃研究话题，但对感器输入缺失（例如突然的感器故障）的Robustness仍然是一个尚未得到充分研究的问题。在这种情况下，我们提出了UniBEV，一个综合多Modal 3D对象检测框架，旨在提高对感器输入缺失的Robustness。UniBEV可以使用LiDAR和摄像头输入，同时也可以使用LiDAR-only或摄像头只输入，无需重新训练。为使其检测头处理不同的输入组合，UniBEV стре望在每个可用感器模式下创建匹配的Bird's Eye View（BEV）特征地图。与先前的BEV基于多Modal detection方法不同，所有感器模式都采用了一致的方式，将native感器坐标系统中的特征atures映射到BEV特征地图。我们还进行了不同模式之间的混合策略的研究，包括常见的特征 concatenation、梯度平均值和通过 Channel Normalized Weights 扩展。为证明其效果，我们与状态体系的BEVFusion和MetaBEV进行比较，在nuScenes上对所有感器输入组合进行评估。在这种设定下，UniBEV achieved $52.5\%$ mAP的平均值，significantly improving over the baselines ($43.5\%$ mAP on average for BEVFusion, $48.7\%$ mAP on average for MetaBEV).一个ablation study表明，通过权重平均混合而不是常见的特征 concatenation，以及在每个模式的BEVEncoder中共享查询，具有Robustness的优点。我们将在纸Acceptance时发布代码。
</details></li>
</ul>
<hr>
<h2 id="Accurate-and-Interactive-Visual-Inertial-Sensor-Calibration-with-Next-Best-View-and-Next-Best-Trajectory-Suggestion"><a href="#Accurate-and-Interactive-Visual-Inertial-Sensor-Calibration-with-Next-Best-View-and-Next-Best-Trajectory-Suggestion" class="headerlink" title="Accurate and Interactive Visual-Inertial Sensor Calibration with Next-Best-View and Next-Best-Trajectory Suggestion"></a>Accurate and Interactive Visual-Inertial Sensor Calibration with Next-Best-View and Next-Best-Trajectory Suggestion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14514">http://arxiv.org/abs/2309.14514</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chutsu/yac">https://github.com/chutsu/yac</a></li>
<li>paper_authors: Christopher L. Choi, Binbin Xu, Stefan Leutenegger</li>
<li>for: 本研究旨在帮助非专家用户更好地使用视觉遥感（VI）传感器进行计算机视觉或状态估计任务，通过提供图形用户界面和信息理论来收集有用的准备数据，并提供下一个最佳视图和下一个最佳轨迹的建议。</li>
<li>methods: 本研究提出了一种新的VI准备管线，使用图形用户界面和信息理论来导引非专家用户收集有用的准备数据，并提供下一个最佳视图和下一个最佳轨迹的建议，以准备VI传感器的内参、外参和时间偏差。</li>
<li>results: 经过实验表明，我们的方法比现有技术更快、更准、更一致，并且可以与现有VI odometry和VI-SLAM方法结合使用，以获得更高精度的估计结果。<details>
<summary>Abstract</summary>
Visual-Inertial (VI) sensors are popular in robotics, self-driving vehicles, and augmented and virtual reality applications. In order to use them for any computer vision or state-estimation task, a good calibration is essential. However, collecting informative calibration data in order to render the calibration parameters observable is not trivial for a non-expert. In this work, we introduce a novel VI calibration pipeline that guides a non-expert with the use of a graphical user interface and information theory in collecting informative calibration data with Next-Best-View and Next-Best-Trajectory suggestions to calibrate the intrinsics, extrinsics, and temporal misalignment of a VI sensor. We show through experiments that our method is faster, more accurate, and more consistent than state-of-the-art alternatives. Specifically, we show how calibrations with our proposed method achieve higher accuracy estimation results when used by state-of-the-art VI Odometry as well as VI-SLAM approaches. The source code of our software can be found on: https://github.com/chutsu/yac.
</details>
<details>
<summary>摘要</summary>
Visual-Inertial（VI）传感器在 роботику、自动驾驶车和增强和虚拟现实应用中广泛使用。为了在计算机视觉或状态估计任务中使用它们，一个好的准备是必要的。然而，收集有用的准备数据以便计算准备参数的可见性并不是非专家的 trivial事。在这个工作中，我们介绍了一个新的 VI 准备管线，通过使用图形用户界面和信息理论来引导非专家收集有用的准备数据，并且提供 Next-Best-View 和 Next-Best-Trajectory 建议来准备 VI 传感器的内参、外参和时间偏移。我们通过实验表明，我们的方法比现有的状态之 искусственный风格更快、更准、更一致。 Specifically，我们表明使用我们提议的方法来准备准确性估计结果，与现有的 VI Odometry 以及 VI-SLAM 方法相比，具有更高的准确性。我们的软件源代码可以在：https://github.com/chutsu/yac 找到。
</details></li>
</ul>
<hr>
<h2 id="Assessment-of-a-new-GeoAI-foundation-model-for-flood-inundation-mapping"><a href="#Assessment-of-a-new-GeoAI-foundation-model-for-flood-inundation-mapping" class="headerlink" title="Assessment of a new GeoAI foundation model for flood inundation mapping"></a>Assessment of a new GeoAI foundation model for flood inundation mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14500">http://arxiv.org/abs/2309.14500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenwen Li, Hyunho Lee, Sizhe Wang, Chia-Yu Hsu, Samantha T. Arundel</li>
<li>for: 这个研究旨在评估IBM-NASA的Prithvi模型在洪水淹没地图分析领域中的表现，以支持关键的地ospatial分析任务。</li>
<li>methods: 这篇论文使用了IBM-NASA的Prithvi模型，并与卷积神经网络和感知器transformer-based架构进行比较，以测试这些模型在洪水淹没地图分析任务中的对策精度。</li>
<li>results: 研究结果显示Prithvi模型在未见过的区域中进行洪水淹没地图分析任务时表现良好，并且在验证数据集和没有被模型视觉化的数据集上显示了良好的预测性和可读性。<details>
<summary>Abstract</summary>
Vision foundation models are a new frontier in Geospatial Artificial Intelligence (GeoAI), an interdisciplinary research area that applies and extends AI for geospatial problem solving and geographic knowledge discovery, because of their potential to enable powerful image analysis by learning and extracting important image features from vast amounts of geospatial data. This paper evaluates the performance of the first-of-its-kind geospatial foundation model, IBM-NASA's Prithvi, to support a crucial geospatial analysis task: flood inundation mapping. This model is compared with convolutional neural network and vision transformer-based architectures in terms of mapping accuracy for flooded areas. A benchmark dataset, Sen1Floods11, is used in the experiments, and the models' predictability, generalizability, and transferability are evaluated based on both a test dataset and a dataset that is completely unseen by the model. Results show the good transferability of the Prithvi model, highlighting its performance advantages in segmenting flooded areas in previously unseen regions. The findings also indicate areas for improvement for the Prithvi model in terms of adopting multi-scale representation learning, developing more end-to-end pipelines for high-level image analysis tasks, and offering more flexibility in terms of input data bands.
</details>
<details>
<summary>摘要</summary>
地球空间人工智能（GeoAI）是一个交叉学科研究领域，它应用和扩展人工智能来解决地球空间问题和地理知识发现。视频基础模型是GeoAI新领域，它们可以通过学习和提取重要的图像特征来实现强大的图像分析。本文评估了首次实现的地球空间基础模型——IBM-NASA的Prithvi，以支持重要的地球空间分析任务：洪水泛滥地图。这个模型与 convolutional neural network 和 vision transformer 基础结构相比，在泛滥区域的地图准确率方面进行了比较。使用 Sen1Floods11  benchmark 数据集进行实验，并根据测试数据集和完全新的数据集来评估模型的预测性、普适性和可转移性。结果显示 Prithvi 模型在未经见过的区域中 segments 泛滥区域的表现良好，表明其在新区域中的表现优异。发现也表明了 Prithvi 模型在采用多尺度表示学习、开发更多的端到端管道和提供更多的输入数据频谱等方面存在改进的空间。
</details></li>
</ul>
<hr>
<h2 id="Free-Bloom-Zero-Shot-Text-to-Video-Generator-with-LLM-Director-and-LDM-Animator"><a href="#Free-Bloom-Zero-Shot-Text-to-Video-Generator-with-LLM-Director-and-LDM-Animator" class="headerlink" title="Free-Bloom: Zero-Shot Text-to-Video Generator with LLM Director and LDM Animator"></a>Free-Bloom: Zero-Shot Text-to-Video Generator with LLM Director and LDM Animator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14494">http://arxiv.org/abs/2309.14494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soolab/free-bloom">https://github.com/soolab/free-bloom</a></li>
<li>paper_authors: Hanzhuo Huang, Yufan Feng, Cheng Shi, Lan Xu, Jingyi Yu, Sibei Yang</li>
<li>for: 本研究旨在实现无需视频数据和训练的情况下，生成具有Semantic coherence的高质量视频。</li>
<li>methods: 提议一种名为Free-Bloom的管道，利用大型自然语言模型（LLM）作为导演，生成Semantic coherence的提示序列，并使用预训练的潜在扩散模型（LDM）为动画师生成高效率帧。为保证时间和 identical coherence，提出了一些修改，包括共同噪声抽取、步态意识转移和双路 interpolate。</li>
<li>results: 无需任何视频数据和训练，Free-Bloom可以生成具有丰富semantic meaningful frame sequence的高质量视频，能够描绘复杂的场景。此外，Free-Bloom自然兼容LDMs-based extensions。<details>
<summary>Abstract</summary>
Text-to-video is a rapidly growing research area that aims to generate a semantic, identical, and temporal coherence sequence of frames that accurately align with the input text prompt. This study focuses on zero-shot text-to-video generation considering the data- and cost-efficient. To generate a semantic-coherent video, exhibiting a rich portrayal of temporal semantics such as the whole process of flower blooming rather than a set of "moving images", we propose a novel Free-Bloom pipeline that harnesses large language models (LLMs) as the director to generate a semantic-coherence prompt sequence, while pre-trained latent diffusion models (LDMs) as the animator to generate the high fidelity frames. Furthermore, to ensure temporal and identical coherence while maintaining semantic coherence, we propose a series of annotative modifications to adapting LDMs in the reverse process, including joint noise sampling, step-aware attention shift, and dual-path interpolation. Without any video data and training requirements, Free-Bloom generates vivid and high-quality videos, awe-inspiring in generating complex scenes with semantic meaningful frame sequences. In addition, Free-Bloom is naturally compatible with LDMs-based extensions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AiAReSeg-Catheter-Detection-and-Segmentation-in-Interventional-Ultrasound-using-Transformers"><a href="#AiAReSeg-Catheter-Detection-and-Segmentation-in-Interventional-Ultrasound-using-Transformers" class="headerlink" title="AiAReSeg: Catheter Detection and Segmentation in Interventional Ultrasound using Transformers"></a>AiAReSeg: Catheter Detection and Segmentation in Interventional Ultrasound using Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14492">http://arxiv.org/abs/2309.14492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Ranne, Yordanka Velikova, Nassir Navab, Ferdinando Rodriguez y Baena<br>for: 这篇论文是为了提出一种基于深度学习的扫描器网络，以便在 intervencion Ultrasound 图像序列中探测和分割导管。methods: 该方法使用了一种基于 Attention 机制的 transformer 架构，并引入了一种新的 3D 分割头，以实现在时间上的扫描。results: 该方法在一个验证数据集上进行了验证，并在用physics-based导管插入 simulations 生成的synthetic Ultrasound 图像上进行了测试，得到了良好的效果。<details>
<summary>Abstract</summary>
To date, endovascular surgeries are performed using the golden standard of Fluoroscopy, which uses ionising radiation to visualise catheters and vasculature. Prolonged Fluoroscopic exposure is harmful for the patient and the clinician, and may lead to severe post-operative sequlae such as the development of cancer. Meanwhile, the use of interventional Ultrasound has gained popularity, due to its well-known benefits of small spatial footprint, fast data acquisition, and higher tissue contrast images. However, ultrasound images are hard to interpret, and it is difficult to localise vessels, catheters, and guidewires within them. This work proposes a solution using an adaptation of a state-of-the-art machine learning transformer architecture to detect and segment catheters in axial interventional Ultrasound image sequences. The network architecture was inspired by the Attention in Attention mechanism, temporal tracking networks, and introduced a novel 3D segmentation head that performs 3D deconvolution across time. In order to facilitate training of such deep learning networks, we introduce a new data synthesis pipeline that used physics-based catheter insertion simulations, along with a convolutional ray-casting ultrasound simulator to produce synthetic ultrasound images of endovascular interventions. The proposed method is validated on a hold-out validation dataset, thus demonstrated robustness to ultrasound noise and a wide range of scanning angles. It was also tested on data collected from silicon-based aorta phantoms, thus demonstrated its potential for translation from sim-to-real. This work represents a significant step towards safer and more efficient endovascular surgery using interventional ultrasound.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:到目前为止，endovascular手术使用金标准fluoroscopy，利用 ionizing radiation Visualize catheters 和vasculature。 prolonged fluoroscopic exposure 对 patient 和 clinician 有害，可能导致 postoperative sequelae 的发展，如 cancer。 Meanwhile，使用 interventional ultrasound 已经得到了广泛的应用，因为它的小型空间占用、快速的数据收集和高对比度图像等优点。然而，ultrasound 图像具有困难的解释和localize vessels、catheters 和 guidewires 在它们中的问题。这个工作提出了一种解决方案，利用一种基于 state-of-the-art 机器学习 transformer 架构来检测和分割 axial interventional ultrasound 图像序列中的 catheters。该网络架构 inspirited 了 Attention in Attention 机制、时间跟踪网络和引入了一个新的3D分割头，通过在时间方向上进行3D deconvolution。为了促进这些深度学习网络的训练，我们引入了一个新的数据生成管线，利用基于物理学习 catheter 插入 simulations 和一个 convolutional ray-casting ultrasound simulator 生成 synthetic ultrasound 图像。该提案在 hold-out 验证集上验证了Robustness 于 ultrasound noise 和多个扫描角度。它还在基于 silicon-based 的 aorta 模型上测试， thereby demonstrating its potential for translation from sim-to-real。这个工作表示了更安全和高效的 endovascular surgery 使用 interventional ultrasound 的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-3D-Perception-with-2D-Vision-Language-Distillation-for-Autonomous-Driving"><a href="#Unsupervised-3D-Perception-with-2D-Vision-Language-Distillation-for-Autonomous-Driving" class="headerlink" title="Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving"></a>Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14491">http://arxiv.org/abs/2309.14491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Najibi, Jingwei Ji, Yin Zhou, Charles R. Qi, Xinchen Yan, Scott Ettinger, Dragomir Anguelov</li>
<li>for: 这篇论文是为了解决关键控制自动驾驶中关键的开放集类型的3D感知问题而写的。</li>
<li>methods: 该论文提出了一种多模态自动标注管道，可以在没有3D人类标签的情况下，使用点云序列中的运动迹象和公共可用的2D图像文本对，识别和跟踪所有交通参与者。</li>
<li>results: 对于 Waymo 开放数据集的实验，该方法与先前的研究相比，在各种无监督3D感知任务上表现出了显著的优异。<details>
<summary>Abstract</summary>
Closed-set 3D perception models trained on only a pre-defined set of object categories can be inadequate for safety critical applications such as autonomous driving where new object types can be encountered after deployment. In this paper, we present a multi-modal auto labeling pipeline capable of generating amodal 3D bounding boxes and tracklets for training models on open-set categories without 3D human labels. Our pipeline exploits motion cues inherent in point cloud sequences in combination with the freely available 2D image-text pairs to identify and track all traffic participants. Compared to the recent studies in this domain, which can only provide class-agnostic auto labels limited to moving objects, our method can handle both static and moving objects in the unsupervised manner and is able to output open-vocabulary semantic labels thanks to the proposed vision-language knowledge distillation. Experiments on the Waymo Open Dataset show that our approach outperforms the prior work by significant margins on various unsupervised 3D perception tasks.
</details>
<details>
<summary>摘要</summary>
闭sets 3D 识别模型只训练在预定的对象类型上可能不够用于安全关键应用程序，如自动驾驶，因为在部署后可能会遇到新的对象类型。在这篇论文中，我们提出了一个多Modal auto Labeling 管道，可以在无人标注的情况下为训练模型提供开放集成类别的培训数据。我们的管道利用点云序列中的运动特征，并与可以得到的免费的2D图像文本对照来识别和跟踪所有交通参与者。与当前领域的研究相比，我们的方法可以不需要人工标注，并且可以自动为移动和静止对象分配开放 vocabulary 语义标签。我们的方法在 Waymo 开放数据集上进行了实验，并与之前的工作相比，在各种无监督3D识别任务上表现出了显著的优异。
</details></li>
</ul>
<hr>
<h2 id="Gastro-Intestinal-Tract-Segmentation-Using-an-Explainable-3D-Unet"><a href="#Gastro-Intestinal-Tract-Segmentation-Using-an-Explainable-3D-Unet" class="headerlink" title="Gastro-Intestinal Tract Segmentation Using an Explainable 3D Unet"></a>Gastro-Intestinal Tract Segmentation Using an Explainable 3D Unet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14474">http://arxiv.org/abs/2309.14474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Li, Jonathan Chan</li>
<li>for: 这篇论文旨在探讨对胃肠癌使用放射治疗时，辐射科医师的角色是如何实现高剂量辐射的同时避免胃肠的影响。</li>
<li>methods: 这篇论文提出了一个基于深度学习（DL）的治疗管线，并将可读性学习（XAI） integrate into the pipeline 以提高模型的透明度和可信度。</li>
<li>results: 这篇论文获得了一个可靠且高精度的辐射治疗管线，可以帮助辐射科医师更快速地处理病人。<details>
<summary>Abstract</summary>
In treating gastrointestinal cancer using radiotherapy, the role of the radiation oncologist is to administer high doses of radiation, through x-ray beams, toward the tumor while avoiding the stomach and intestines. With the advent of precise radiation treatment technology such as the MR-Linac, oncologists can visualize the daily positions of the tumors and intestines, which may vary day to day. Before delivering radiation, radio oncologists must manually outline the position of the gastrointestinal organs in order to determine position and direction of the x-ray beam. This is a time consuming and labor intensive process that may substantially prolong a patient's treatment. A deep learning (DL) method can automate and expedite the process. However, many deep neural networks approaches currently in use are black-boxes which lack interpretability which render them untrustworthy and impractical in a healthcare setting. To address this, an emergent field of AI known as Explainable AI (XAI) may be incorporated to improve the transparency and viability of a model. This paper proposes a deep learning pipeline that incorporates XAI to address the challenges of organ segmentation.
</details>
<details>
<summary>摘要</summary>
在治疗肝肠癌用电疗时，辐射生物学家的角色是通过X射线束射高剂量辐射于肿瘤，同时避免肠和肠肝。随着精细辐射治疗技术的发展，如MR-Linac，生物学家可以每天Visualize肿瘤和肠肝的位置，这些位置可能每天不同。在发射辐射之前， radio生物学家必须手动标识肠肝的位置，以确定辐射的方向和强度。这是一项时间consuming和劳动密集的过程，可能会导致患者的治疗持续时间增加。在这种情况下，一种深度学习（DL）方法可以自动和加速这个过程。然而，许多深度神经网络方法现在在使用的是黑obox，缺乏可读性，这使得它们在医疗设置中不可靠和不实用。为了解决这个问题，一个emergent的人工智能领域，称为可解释AI（XAI），可以被包含到深度学习管道中，以提高模型的透明度和实用性。本文提出了一个深度学习管道，其中包含XAI，以解决肠肿瘤分割的挑战。
</details></li>
</ul>
<hr>
<h2 id="FARSEC-A-Reproducible-Framework-for-Automatic-Real-Time-Vehicle-Speed-Estimation-Using-Traffic-Cameras"><a href="#FARSEC-A-Reproducible-Framework-for-Automatic-Real-Time-Vehicle-Speed-Estimation-Using-Traffic-Cameras" class="headerlink" title="FARSEC: A Reproducible Framework for Automatic Real-Time Vehicle Speed Estimation Using Traffic Cameras"></a>FARSEC: A Reproducible Framework for Automatic Real-Time Vehicle Speed Estimation Using Traffic Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14468">http://arxiv.org/abs/2309.14468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/porscheofficial/speed-estimation-traffic-monitoring">https://github.com/porscheofficial/speed-estimation-traffic-monitoring</a></li>
<li>paper_authors: Lucas Liebe, Franz Sauerwald, Sylwester Sawicki, Matthias Schneider, Leo Schuhmann, Tolga Buz, Paul Boes, Ahmad Ahmadov, Gerard de Melo</li>
<li>for: 该研究旨在提供一种自动实时计算车辆速度的框架，以提高交通监测和管理的精度和效果。</li>
<li>methods: 该模型使用了新的技术来预测深度地图，从而估算道路段长度，并可以自动处理实际情况如摄像头运动和不同视频流输入。</li>
<li>results: 与三种已知模型进行比较后，该模型在实际的CCTV视频上达到了竞争性的结果，同时具有更好的可重复性和可更新性。<details>
<summary>Abstract</summary>
Estimating the speed of vehicles using traffic cameras is a crucial task for traffic surveillance and management, enabling more optimal traffic flow, improved road safety, and lower environmental impact. Transportation-dependent systems, such as for navigation and logistics, have great potential to benefit from reliable speed estimation. While there is prior research in this area reporting competitive accuracy levels, their solutions lack reproducibility and robustness across different datasets. To address this, we provide a novel framework for automatic real-time vehicle speed calculation, which copes with more diverse data from publicly available traffic cameras to achieve greater robustness. Our model employs novel techniques to estimate the length of road segments via depth map prediction. Additionally, our framework is capable of handling realistic conditions such as camera movements and different video stream inputs automatically. We compare our model to three well-known models in the field using their benchmark datasets. While our model does not set a new state of the art regarding prediction performance, the results are competitive on realistic CCTV videos. At the same time, our end-to-end pipeline offers more consistent results, an easier implementation, and better compatibility. Its modular structure facilitates reproducibility and future improvements.
</details>
<details>
<summary>摘要</summary>
Our model employs novel techniques to estimate the length of road segments via depth map prediction. Additionally, our framework can automatically handle realistic conditions such as camera movements and different video stream inputs. We compare our model with three well-known models in the field using their benchmark datasets. While our model does not set a new state of the art regarding prediction performance, the results are competitive on realistic CCTV videos. Our end-to-end pipeline offers more consistent results, easier implementation, and better compatibility. Its modular structure facilitates reproducibility and future improvements.
</details></li>
</ul>
<hr>
<h2 id="Chop-Learn-Recognizing-and-Generating-Object-State-Compositions"><a href="#Chop-Learn-Recognizing-and-Generating-Object-State-Compositions" class="headerlink" title="Chop &amp; Learn: Recognizing and Generating Object-State Compositions"></a>Chop &amp; Learn: Recognizing and Generating Object-State Compositions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14339">http://arxiv.org/abs/2309.14339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirat Saini, Hanyu Wang, Archana Swaminathan, Vinoj Jayasundara, Bo He, Kamal Gupta, Abhinav Shrivastava</li>
<li>for: 这篇论文主要研究了不同风格下对物体进行割辑和对象状态的变化。</li>
<li>methods: 该论文提出了一个新的benchmark集合Chop &amp; Learn，用于学习不同风格下的割辑和多视点下的对象状态。同时，它还提出了一个新任务：compositional image generation，可以将学习的割辑风格转移到不同的对象上，生成新的对象状态图像。</li>
<li>results: 该论文使用视频进行compositional action recognition，并证明了这些数据的多种应用。项目官网：<a target="_blank" rel="noopener" href="https://chopnlearn.github.io./">https://chopnlearn.github.io。</a><details>
<summary>Abstract</summary>
Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions. In this paper, we study the task of cutting objects in different styles and the resulting object state changes. We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints. We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images. Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks. Project website: https://chopnlearn.github.io.
</details>
<details>
<summary>摘要</summary>
Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions. In this paper, we study the task of cutting objects in different styles and the resulting object state changes. We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints. We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images. Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks. Project website: https://chopnlearn.github.io.Translation:recognizing和生成对象状态组合是一个挑战性任务，特别是对于未看过的组合。在这篇论文中，我们研究对象在不同风格下被剪辑的任务，以及它们所导致的对象状态变化。我们提出了一个新的benchmark集Chop & Learn，以便学习对象和不同剪辑风格的多视点学习。我们还提出了一个新的任务：compositional Image Generation，可以将学习的剪辑风格应用到不同的对象上，通过生成新的对象状态图像。此外，我们还使用视频进行compositional Action Recognition，并显示了这个数据集的多种视频任务的用途。项目网站：https://chopnlearn.github.io。
</details></li>
</ul>
<hr>
<h2 id="3D-Indoor-Instance-Segmentation-in-an-Open-World"><a href="#3D-Indoor-Instance-Segmentation-in-an-Open-World" class="headerlink" title="3D Indoor Instance Segmentation in an Open-World"></a>3D Indoor Instance Segmentation in an Open-World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14338">http://arxiv.org/abs/2309.14338</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aminebdj/3d-owis">https://github.com/aminebdj/3d-owis</a></li>
<li>paper_authors: Mohamed El Amine Boudjoghra, Salwa K. Al Khatib, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Fahad Khan</li>
<li>for: 3D indoor instance segmentation in an open-world setting, where the model can distinguish known classes and identify unknown objects</li>
<li>methods: use an auto-labeling scheme to produce pseudo-labels during training, and adjust the unknown class probability based on objectness score distribution</li>
<li>results: promising open-world 3D instance segmentation performance with carefully curated open-world splits<details>
<summary>Abstract</summary>
Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference. We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available. To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels. We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution. We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes. Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance.
</details>
<details>
<summary>摘要</summary>
现有的3D实例分割方法通常假设所有需要分割的semantic类都会在训练时 disponible，只有seen类会在推理时分割。我们认为这种closed-world假设是限制性的，我们开发了第一个在开放世界设定下进行3Dindoor实例分割的方法，其中模型允许分辨知道的类别以及未知对象的类别，并在可以获得对应类别标签时逐渐学习未知类别的semanticcategory。为此，我们提出了一种开放世界3Dindoor实例分割方法，其中使用自动标签机制生成pseudo-标签 durante entrenamiento，并在推理时调整未知类别概率根据对象性分布。此外，我们还提出了仔细制定的开放世界分割，利用实际场景、indoorScene区域探索和Randomaspect of open-world类来生成准确的pseudo-标签。广泛的实验表明我们的提案具有优秀的开放世界3D实例分割性能。
</details></li>
</ul>
<hr>
<h2 id="Noise-in-Bias-out-Balanced-and-Real-time-MoCap-Solving"><a href="#Noise-in-Bias-out-Balanced-and-Real-time-MoCap-Solving" class="headerlink" title="Noise-in, Bias-out: Balanced and Real-time MoCap Solving"></a>Noise-in, Bias-out: Balanced and Real-time MoCap Solving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14330">http://arxiv.org/abs/2309.14330</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Albanis, Nikolaos Zioulis, Spyridon Thermos, Anargyros Chatzitofis, Kostas Kolomvatsos</li>
<li>for: 这篇论文旨在提高现场摄像头采集系统的准确性和可靠性，使用机器学习算法来解决 marker 估计中的噪声和不规则性。</li>
<li>methods: 该论文使用机器学习技术，包括表示学习和不平衡回归，来解决 marker 估计中的问题。它还利用了 marker-less MoCap 技术来获取数据。</li>
<li>results: 该论文的实验结果表明，使用该方法可以在实时 MoCap 中提高 marker 估计的准确性和稳定性，并在具有极端和特殊 pose 的情况下表现出优异性。项目页面：<a target="_blank" rel="noopener" href="https://moverseai.github.io/noise-tail">https://moverseai.github.io/noise-tail</a><details>
<summary>Abstract</summary>
Real-time optical Motion Capture (MoCap) systems have not benefited from the advances in modern data-driven modeling. In this work we apply machine learning to solve noisy unstructured marker estimates in real-time and deliver robust marker-based MoCap even when using sparse affordable sensors. To achieve this we focus on a number of challenges related to model training, namely the sourcing of training data and their long-tailed distribution. Leveraging representation learning we design a technique for imbalanced regression that requires no additional data or labels and improves the performance of our model in rare and challenging poses. By relying on a unified representation, we show that training such a model is not bound to high-end MoCap training data acquisition, and exploit the advances in marker-less MoCap to acquire the necessary data. Finally, we take a step towards richer and affordable MoCap by adapting a body model-based inverse kinematics solution to account for measurement and inference uncertainty, further improving performance and robustness. Project page: https://moverseai.github.io/noise-tail
</details>
<details>
<summary>摘要</summary>
现实时光学动作捕捉（MoCap）系统没有受到现代数据驱动模型的改进。在这项工作中，我们通过机器学习解决实时噪声不结构 marker 估计中的噪声问题，并提供了可靠的 marker-based MoCap，即使使用便宜的感知器。为达到这一目标，我们关注了许多相关的挑战，包括训练数据的获取和其长尾分布。通过表示学习，我们设计了一种无需额外数据或标签的偏好回归技术，以提高我们模型在罕见和具有挑战性的姿势中的性能。由于我们的模型不依赖高级 MoCap 训练数据获取，我们可以利用 marker-less MoCap 技术获取必要的数据。最后，我们通过对体部模型基于 inverse kinematics 解决方案进行修改，以考虑测量和推理不确定性，进一步提高性能和可靠性。项目页面：https://moverseai.github.io/noise-tail
</details></li>
</ul>
<hr>
<h2 id="DeepMesh-Mesh-based-Cardiac-Motion-Tracking-using-Deep-Learning"><a href="#DeepMesh-Mesh-based-Cardiac-Motion-Tracking-using-Deep-Learning" class="headerlink" title="DeepMesh: Mesh-based Cardiac Motion Tracking using Deep Learning"></a>DeepMesh: Mesh-based Cardiac Motion Tracking using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14306">http://arxiv.org/abs/2309.14306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingjie Meng, Wenjia Bai, Declan P O’Regan, and Daniel Rueckert</li>
<li>for: 这个论文是用于评估冠动脉疾病和诊断冠动脉疾病的评估工具。</li>
<li>methods: 这个论文使用的方法是基于深度学习的DeepMesh模型，该模型可以从冠动脉CMR图像中提取冠动脉的3D运动信息。</li>
<li>results: 实验结果表明，DeepMesh方法可以高效地和量化地评估冠动脉左心室的3D运动信息，并且比其他图像基于和网格基于的冠动脉运动跟踪方法更高效。<details>
<summary>Abstract</summary>
3D motion estimation from cine cardiac magnetic resonance (CMR) images is important for the assessment of cardiac function and the diagnosis of cardiovascular diseases. Current state-of-the art methods focus on estimating dense pixel-/voxel-wise motion fields in image space, which ignores the fact that motion estimation is only relevant and useful within the anatomical objects of interest, e.g., the heart. In this work, we model the heart as a 3D mesh consisting of epi- and endocardial surfaces. We propose a novel learning framework, DeepMesh, which propagates a template heart mesh to a subject space and estimates the 3D motion of the heart mesh from CMR images for individual subjects. In DeepMesh, the heart mesh of the end-diastolic frame of an individual subject is first reconstructed from the template mesh. Mesh-based 3D motion fields with respect to the end-diastolic frame are then estimated from 2D short- and long-axis CMR images. By developing a differentiable mesh-to-image rasterizer, DeepMesh is able to leverage 2D shape information from multiple anatomical views for 3D mesh reconstruction and mesh motion estimation. The proposed method estimates vertex-wise displacement and thus maintains vertex correspondences between time frames, which is important for the quantitative assessment of cardiac function across different subjects and populations. We evaluate DeepMesh on CMR images acquired from the UK Biobank. We focus on 3D motion estimation of the left ventricle in this work. Experimental results show that the proposed method quantitatively and qualitatively outperforms other image-based and mesh-based cardiac motion tracking methods.
</details>
<details>
<summary>摘要</summary>
3D动态计算从cinéCardiac Magnetic Resonance（CMR）图像是评估心脏功能和诊断循环疾病的重要方法。当前状态艺术方法都是在图像空间进行密集像素/体积化动态场的估计，忽略了动态场只在心脏的解剖对象上是有用的事实。在这种工作中，我们模型了心脏为3D网格，包括血管和内血管表面。我们提出了一种新的学习框架，深度网格（DeepMesh），它将投影模板心脏网格到个体空间，并估计从CMR图像中心脏的3D动态。在DeepMesh中，个体心脏的结构图像的结束 диасто利Frame中的心脏网格被首先从模板网格中重construct。然后，从2D短轴和长轴CMR图像中获取心脏网格的3D动态场，并通过开发可导的网格到图像照片的映射器，以便利用多视图解剖信息来进行3D网格重建和动态场估计。提出的方法可以计算 vertex-wise 偏移量，并维护 vertex 之间的匹配关系，这是评估不同个体和人口中心脏功能的量化评估的关键。我们在UK Biobank中获取的CMR图像进行了实验，我们专注于左心室的3D动态跟踪。实验结果表明，提出的方法在图像基于和网格基于的心脏动态跟踪方法中量化和质量上有显著优势。
</details></li>
</ul>
<hr>
<h2 id="Regress-Before-Construct-Regress-Autoencoder-for-Point-Cloud-Self-supervised-Learning"><a href="#Regress-Before-Construct-Regress-Autoencoder-for-Point-Cloud-Self-supervised-Learning" class="headerlink" title="Regress Before Construct: Regress Autoencoder for Point Cloud Self-supervised Learning"></a>Regress Before Construct: Regress Autoencoder for Point Cloud Self-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03670">http://arxiv.org/abs/2310.03670</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyyy111/point-rae">https://github.com/liuyyy111/point-rae</a></li>
<li>paper_authors: Yang Liu, Chen Chen, Can Wang, Xulin King, Mengyuan Liu</li>
<li>for: 这篇论文的目的是提出一种新的自适应神经网络模型，即Point Regress AutoEncoder（Point-RAE），用于无监督学习三维点云数据。</li>
<li>methods: 该模型使用了一个mask regressor来预测masked patch representation，并使用了一个alignment constraint来确保预测的masked patch representation与实际的masked patch表示相一致。</li>
<li>results: 该模型在多个下游任务中表现出色，包括ScanObjectNN和ModelNet40等。Specifically, our pre-trained models achieve a high accuracy of 90.28% on the ScanObjectNN hardest split and 94.1% accuracy on ModelNet40, surpassing all the other self-supervised learning methods.<details>
<summary>Abstract</summary>
Masked Autoencoders (MAE) have demonstrated promising performance in self-supervised learning for both 2D and 3D computer vision. Nevertheless, existing MAE-based methods still have certain drawbacks. Firstly, the functional decoupling between the encoder and decoder is incomplete, which limits the encoder's representation learning ability. Secondly, downstream tasks solely utilize the encoder, failing to fully leverage the knowledge acquired through the encoder-decoder architecture in the pre-text task. In this paper, we propose Point Regress AutoEncoder (Point-RAE), a new scheme for regressive autoencoders for point cloud self-supervised learning. The proposed method decouples functions between the decoder and the encoder by introducing a mask regressor, which predicts the masked patch representation from the visible patch representation encoded by the encoder and the decoder reconstructs the target from the predicted masked patch representation. By doing so, we minimize the impact of decoder updates on the representation space of the encoder. Moreover, we introduce an alignment constraint to ensure that the representations for masked patches, predicted from the encoded representations of visible patches, are aligned with the masked patch presentations computed from the encoder. To make full use of the knowledge learned in the pre-training stage, we design a new finetune mode for the proposed Point-RAE. Extensive experiments demonstrate that our approach is efficient during pre-training and generalizes well on various downstream tasks. Specifically, our pre-trained models achieve a high accuracy of \textbf{90.28\%} on the ScanObjectNN hardest split and \textbf{94.1\%} accuracy on ModelNet40, surpassing all the other self-supervised learning methods. Our code and pretrained model are public available at: \url{https://github.com/liuyyy111/Point-RAE}.
</details>
<details>
<summary>摘要</summary>
masked autoencoders (MAE) 在自助学习中表现出色，特别是在2D和3D计算机视觉领域。然而，现有的MAE基本方法仍有一些缺点。首先，Encoder和Decoder之间的函数分离不够完善，这限制了Encoder的表征学习能力。其次，下游任务只使用Encoder，而不全面利用通过Encoder-Decoder架构在 предtext任务中获得的知识。在这篇论文中，我们提出了Point Regress AutoEncoder（Point-RAE），一种新的抽象方法 для点云自助学习。我们在Point-RAE中引入了一个mask推 regression器，该推 regression器预测从可见patch表示中编码的masked patch表示，而Decoder则使用这些预测的masked patch表示重建目标。通过这种方式，我们减少了Encoder的表征空间中Decoder的影响。此外，我们引入了一个alignment constraint，确保encoded表示中的masked patch表示与Encoder计算的masked patch表示相align。为了充分利用在预训练阶段学习的知识，我们设计了一种新的finetune模式 дляPoint-RAE。我们的实验表明，我们的方法是在预训练阶段高效，并且在多个下游任务上具有良好的泛化性。具体来说，我们的预训练模型在ScanObjectNN最难的分区上达到了90.28%的高精度，并在ModelNet40上达到了94.1%的精度，超过了所有其他自助学习方法。我们的代码和预训练模型可以在以下链接中下载：\url{https://github.com/liuyyy111/Point-RAE}.
</details></li>
</ul>
<hr>
<h2 id="Dataset-Diffusion-Diffusion-based-Synthetic-Dataset-Generation-for-Pixel-Level-Semantic-Segmentation"><a href="#Dataset-Diffusion-Diffusion-based-Synthetic-Dataset-Generation-for-Pixel-Level-Semantic-Segmentation" class="headerlink" title="Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for Pixel-Level Semantic Segmentation"></a>Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for Pixel-Level Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14303">http://arxiv.org/abs/2309.14303</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vinairesearch/dataset-diffusion">https://github.com/vinairesearch/dataset-diffusion</a></li>
<li>paper_authors: Quang Nguyen, Truong Vu, Anh Tran, Khoi Nguyen<br>for:This paper aims to address the labor-intensive task of preparing training data for deep vision models by proposing a novel method for generating pixel-level semantic segmentation labels using a text-to-image generative model.methods:The proposed method utilizes the text prompts, cross-attention, and self-attention of the Stable Diffusion (SD) model to generate segmentation maps corresponding to synthetic images. The method introduces three new techniques: class-prompt appending, class-prompt cross-attention, and self-attention exponentiation.results:The proposed approach significantly outperforms concurrent work on two datasets, PASCAL VOC and MSCOCO, and provides a reliable way to generate pixel-level semantic segmentation labels without the need for labor-intensive pixel-wise annotation.<details>
<summary>Abstract</summary>
Preparing training data for deep vision models is a labor-intensive task. To address this, generative models have emerged as an effective solution for generating synthetic data. While current generative models produce image-level category labels, we propose a novel method for generating pixel-level semantic segmentation labels using the text-to-image generative model Stable Diffusion (SD). By utilizing the text prompts, cross-attention, and self-attention of SD, we introduce three new techniques: class-prompt appending, class-prompt cross-attention, and self-attention exponentiation. These techniques enable us to generate segmentation maps corresponding to synthetic images. These maps serve as pseudo-labels for training semantic segmenters, eliminating the need for labor-intensive pixel-wise annotation. To account for the imperfections in our pseudo-labels, we incorporate uncertainty regions into the segmentation, allowing us to disregard loss from those regions. We conduct evaluations on two datasets, PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent work. Our benchmarks and code will be released at https://github.com/VinAIResearch/Dataset-Diffusion
</details>
<details>
<summary>摘要</summary>
准备深度视觉模型的训练数据是一项劳动密集的任务。为了解决这个问题，生成模型在深度学习领域得到了广泛的应用。现有的生成模型可以生成图像级别的类别标签，但我们提出了一种新的方法，即使用文本生成器Stable Diffusion（SD）来生成像素级别的semantic segmentation标签。我们利用文本提示、跨处理和自处理的SD特性，提出了三种新技术：类提示附加、类提示跨处理和自处理指数。这些技术使得我们可以生成对应于合成图像的segmentation图。这些图像serve为训练semantic segmenter的pseudo标签，从而消除了对每个像素的手动标注的劳动密集任务。为了考虑我们的 pseudo标签中的不准确部分，我们将uncertainty区域纳入segmentation中，因此可以忽略这些区域中的损失。我们在PASCAL VOC和MSCOCO两个 dataset上进行了评估，并得到了与当前同类工作的显著超越。我们的标准 benchmarks和代码将在https://github.com/VinAIResearch/Dataset-Diffusion中发布。
</details></li>
</ul>
<hr>
<h2 id="Tiled-Multiplane-Images-for-Practical-3D-Photography"><a href="#Tiled-Multiplane-Images-for-Practical-3D-Photography" class="headerlink" title="Tiled Multiplane Images for Practical 3D Photography"></a>Tiled Multiplane Images for Practical 3D Photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14291">http://arxiv.org/abs/2309.14291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Numair Khan, Douglas Lanman, Lei Xiao</li>
<li>for: 该研究旨在解决单视图图像中的三维摄影问题，有用的应用包括虚拟现实和移动计算。</li>
<li>methods: 该研究使用了多平面图像（MPI）来Estimate scene，可以模型复杂的外观效果、抗抖阈深度错误和软边缘Synthesize better than使用 текстури化的雷达或层次深度图像。</li>
<li>results: 该研究提出了一种使用分割多平面图像（TMPI）来生成单视图三维图像的方法，其中每个小区域只有几个深度层，可以提高计算效率。与state-of-the-art单视图MPI方法相比，该方法的生成结果相似，计算 overhead 比较低。<details>
<summary>Abstract</summary>
The task of synthesizing novel views from a single image has useful applications in virtual reality and mobile computing, and a number of approaches to the problem have been proposed in recent years. A Multiplane Image (MPI) estimates the scene as a stack of RGBA layers, and can model complex appearance effects, anti-alias depth errors and synthesize soft edges better than methods that use textured meshes or layered depth images. And unlike neural radiance fields, an MPI can be efficiently rendered on graphics hardware. However, MPIs are highly redundant and require a large number of depth layers to achieve plausible results. Based on the observation that the depth complexity in local image regions is lower than that over the entire image, we split an MPI into many small, tiled regions, each with only a few depth planes. We call this representation a Tiled Multiplane Image (TMPI). We propose a method for generating a TMPI with adaptive depth planes for single-view 3D photography in the wild. Our synthesized results are comparable to state-of-the-art single-view MPI methods while having lower computational overhead.
</details>
<details>
<summary>摘要</summary>
“ synthesizing novel views from a single image ”有很多实际应用，如虚拟现实和移动设备等，Recent years 有很多解决方案提出来。 Multiplane Image (MPI) 估算场景为堆叠的 RGBA 层，可以更好地模拟复杂的外观效果、抑制遮蔽depth 误差和软边缘。 不同于 neural radiance fields， MPI 可以高效地在图形硬件上运算。然而， MPI 很受重复性的限制，需要许多深度层以 дости得可靠的结果。 根据本地图像区域的深度复杂性观察，我们将 MPI 拆分为多个小、瓷砾的区域，每个区域只有几个深度平面。 我们称这个表示法为 Tiled Multiplane Image (TMPI)。 我们提出一种方法，用于从单一影像中生成 TMPI  WITH adaptive depth planes 的单眼 3D 摄影。我们的合成结果与现有的单眼 MPI 方法相似，但计算负载较低。
</details></li>
</ul>
<hr>
<h2 id="CLIP-DIY-CLIP-Dense-Inference-Yields-Open-Vocabulary-Semantic-Segmentation-For-Free"><a href="#CLIP-DIY-CLIP-Dense-Inference-Yields-Open-Vocabulary-Semantic-Segmentation-For-Free" class="headerlink" title="CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic Segmentation For-Free"></a>CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic Segmentation For-Free</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14289">http://arxiv.org/abs/2309.14289</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wysoczanska/clip-diy">https://github.com/wysoczanska/clip-diy</a></li>
<li>paper_authors: Monika Wysoczańska, Michaël Ramamonjisoa, Tomasz Trzciński, Oriane Siméoni</li>
<li>for: 这个论文旨在开发一种基于 CLIP 的开放世界图像识别方法，以达到零shot  semantic segmentation 的目标。</li>
<li>methods: 该方法不需要任何额外训练或标注，而是基于现有的无监督物体定位方法，Directly 利用 CLIP 的分类能力进行多 scales 的 patch 处理，并将决策综合到一个地图中。</li>
<li>results: 在 PASCAL VOC 和 COCO 上，该方法可以达到零shot  semantic segmentation 的State-of-the-art 结果，与最佳方法在 COCO 上表现相当。<details>
<summary>Abstract</summary>
The emergence of CLIP has opened the way for open-world image perception. The zero-shot classification capabilities of the model are impressive but are harder to use for dense tasks such as image segmentation. Several methods have proposed different modifications and learning schemes to produce dense output. Instead, we propose in this work an open-vocabulary semantic segmentation method, dubbed CLIP-DIY, which does not require any additional training or annotations, but instead leverages existing unsupervised object localization approaches. In particular, CLIP-DIY is a multi-scale approach that directly exploits CLIP classification abilities on patches of different sizes and aggregates the decision in a single map. We further guide the segmentation using foreground/background scores obtained using unsupervised object localization methods. With our method, we obtain state-of-the-art zero-shot semantic segmentation results on PASCAL VOC and perform on par with the best methods on COCO.
</details>
<details>
<summary>摘要</summary>
CLIP的出现开启了开放世界图像识别的新时代。CLIP的零shot分类能力吸引了很多人，但是在密集任务如图像 segmentation 中更加困难使用。许多方法已经提出了不同的修改和学习方案来生成密集输出。而我们在这里提出了一种开放词汇 semantic segmentation 方法，称为 CLIP-DIY，不需要任何额外的训练或标注，而是利用现有的无监督物体定位方法来进行推导。具体来说，CLIP-DIY 是一种多尺度方法，直接利用 CLIP 分类器在不同大小的 patches 上进行分类，并将决定聚合到一个地图上。我们还使用无监督物体定位方法来引导分 segmentation。我们的方法可以在 PASCAL VOC 和 COCO 上达到领先的 zero-shot semantic segmentation 结果，并与最佳方法在 COCO 上表现相当。
</details></li>
</ul>
<hr>
<h2 id="Calibration-based-Dual-Prototypical-Contrastive-Learning-Approach-for-Domain-Generalization-Semantic-Segmentation"><a href="#Calibration-based-Dual-Prototypical-Contrastive-Learning-Approach-for-Domain-Generalization-Semantic-Segmentation" class="headerlink" title="Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation"></a>Calibration-based Dual Prototypical Contrastive Learning Approach for Domain Generalization Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14282">http://arxiv.org/abs/2309.14282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muxin Liao, Shishun Tian, Yuhang Zhang, Guoguang Hua, Wenbin Zou, Xia Li<br>for: 这个研究是为了解决域缩推理中的域对预设问题，并提出了一个基于对照对比学习的方法来获得域标准的特征。methods: 这个方法使用了一个对照对比学习的核心思想，即使用不同域的中心价值作为域标准，并将这些中心价值与不同域的标准对照。results: 这个方法在域扩展Semantic segmentation任务中得到了superior的性能，并且可以对不同域的标准进行对照对比，以获得更好的域标准。<details>
<summary>Abstract</summary>
Prototypical contrastive learning (PCL) has been widely used to learn class-wise domain-invariant features recently. These methods are based on the assumption that the prototypes, which are represented as the central value of the same class in a certain domain, are domain-invariant. Since the prototypes of different domains have discrepancies as well, the class-wise domain-invariant features learned from the source domain by PCL need to be aligned with the prototypes of other domains simultaneously. However, the prototypes of the same class in different domains may be different while the prototypes of different classes may be similar, which may affect the learning of class-wise domain-invariant features. Based on these observations, a calibration-based dual prototypical contrastive learning (CDPCL) approach is proposed to reduce the domain discrepancy between the learned class-wise features and the prototypes of different domains for domain generalization semantic segmentation. It contains an uncertainty-guided PCL (UPCL) and a hard-weighted PCL (HPCL). Since the domain discrepancies of the prototypes of different classes may be different, we propose an uncertainty probability matrix to represent the domain discrepancies of the prototypes of all the classes. The UPCL estimates the uncertainty probability matrix to calibrate the weights of the prototypes during the PCL. Moreover, considering that the prototypes of different classes may be similar in some circumstances, which means these prototypes are hard-aligned, the HPCL is proposed to generate a hard-weighted matrix to calibrate the weights of the hard-aligned prototypes during the PCL. Extensive experiments demonstrate that our approach achieves superior performance over current approaches on domain generalization semantic segmentation tasks.
</details>
<details>
<summary>摘要</summary>
它们（Prototypical contrastive learning，PCL）在最近得到了广泛的应用，用于学习域外兼顾的特征。这些方法基于假设，各个类域的中值（prototype）是域外兼顾的。然而，不同域的中值之间可能存在差异，因此通过PCL学习的域外兼顾特征需要同时与其他域的中值进行对alignment。然而，不同类域的中值可能存在差异，而不同类域的中值可能相似，这可能影响学习域外兼顾特征的过程。基于这些观察，我们提出了一种calibration-based dual prototypical contrastive learning（CDPCL）方法，用于降低不同域的中值与学习的域外兼顾特征之间的域不一致。CDPCL包括了一种uncertainty-guided PCL（UPCL）和一种hard-weighted PCL（HPCL）。由于不同类域的中值之间可能存在不同的差异，我们提出了一个不确定性概率矩阵，用于表示不同类域中值之间的差异。UPCL用于估算这个不确定性概率矩阵，以calibrate PCL中的权重。此外，considering that prototypes of different classes may be similar in some circumstances, which means these prototypes are hard-aligned, we propose a hard-weighted matrix to calibrate the weights of the hard-aligned prototypes during the PCL.经过广泛的实验，我们发现我们的方法在域通用 semantic segmentation 任务上达到了现有方法的最高性能。
</details></li>
</ul>
<hr>
<h2 id="SINCERE-Supervised-Information-Noise-Contrastive-Estimation-REvisited"><a href="#SINCERE-Supervised-Information-Noise-Contrastive-Estimation-REvisited" class="headerlink" title="SINCERE: Supervised Information Noise-Contrastive Estimation REvisited"></a>SINCERE: Supervised Information Noise-Contrastive Estimation REvisited</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14277">http://arxiv.org/abs/2309.14277</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tufts-ml/supcontrast">https://github.com/tufts-ml/supcontrast</a></li>
<li>paper_authors: Patrick Feeney, Michael C. Hughes</li>
<li>for: 提供一种正确的扩展自动学习方法，使得自动学习模型可以从可用的类别标签中学习。</li>
<li>methods: 使用InfoNCE损失函数作为基础，并通过修改SupCon损失函数来提供一种正确的扩展方法。</li>
<li>results: 比较SINCERE和SupCon损失函数的学习轨迹和终端Linear分类器性能，发现SINCERE损失函数可以更好地分离不同类别的嵌入空间，并且与SupCon损失函数相比，SINCERE损失函数可以提供更高的终端分类器性能。<details>
<summary>Abstract</summary>
The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation. Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels. This SupCon loss has been widely-used due to reports of good empirical performance. However, in this work we suggest that the specific SupCon loss formulated by prior work has questionable theoretic justification, because it can encourage images from the same class to repel one another in the learned embedding space. This problematic behavior gets worse as the number of inputs sharing one class label increases. We propose the Supervised InfoNCE REvisited (SINCERE) loss as a remedy. SINCERE is a theoretically justified solution for a supervised extension of InfoNCE that never causes images from the same class to repel one another. We further show that minimizing our new loss is equivalent to maximizing a bound on the KL divergence between class conditional embedding distributions. We compare SINCERE and SupCon losses in terms of learning trajectories during pretraining and in ultimate linear classifier performance after finetuning. Our proposed SINCERE loss better separates embeddings from different classes during pretraining while delivering competitive accuracy.
</details>
<details>
<summary>摘要</summary>
《信息干扰对照估计（InfoNCE）损失函数提供了许多自动学习深度学习方法的基础，因为它在实际上表现良好并具有理论基础。之前的工作提出了一种名为超级vised contrastive（SupCon）损失函数，用于从可用的类标签学习。这种SupCon损失函数广泛使用，但是我们认为其具体的形式不具有理论基础，因为它可能会使图像同一个类型的图像在学习的嵌入空间中抵抗对方。这种问题的严重程度随着输入图像同一个类型的数量增加。我们提议一种名为Supervised InfoNCE REvisited（SINCERE）损失函数，它是一种理论上正确的自upervised扩展，不会使图像同一个类型的图像在学习的嵌入空间中抵抗对方。我们还证明了将我们的新损失函数最小化等价于将类型 conditional嵌入分布的KL散度上升 bounds。我们比较了SINCERE和SupCon损失函数在预训练和精化后的线性分类器性能。我们的提议的SINCERE损失函数在预训练时更好地分离不同类型的嵌入，而且在精化后具有竞争力的准确率。》Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Identity-preserving-Editing-of-Multiple-Facial-Attributes-by-Learning-Global-Edit-Directions-and-Local-Adjustments"><a href="#Identity-preserving-Editing-of-Multiple-Facial-Attributes-by-Learning-Global-Edit-Directions-and-Local-Adjustments" class="headerlink" title="Identity-preserving Editing of Multiple Facial Attributes by Learning Global Edit Directions and Local Adjustments"></a>Identity-preserving Editing of Multiple Facial Attributes by Learning Global Edit Directions and Local Adjustments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14267">http://arxiv.org/abs/2309.14267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Najmeh Mohammadbagheri, Fardin Ayar, Ahmad Nickabadi, Reza Safabakhsh</li>
<li>for: 这个研究旨在解决人脸特征编辑中的identiy损失问题，提出了一个新的架构ID-Style，并在训练过程中使用两种损失函数来保持实例特征的独特性。</li>
<li>methods: 这个架构包括学习全球方向(LGD)和实例化对应强度预测器(IAIP)网络，LGD找到每个属性的共享和半独特的方向，IAIP网络在输入实例上调整全球方向。训练时使用两种损失函数，一种是来避免LGD找到过度独特的方向，另一种是来保持实例特征的独特性。</li>
<li>results: 试验结果显示，ID-Style比基于相似的state-of-the-art工作更好地保持实例特征，具体而言，与基于工作相比，ID-Style在人脸特征编辑中的Identity preserving metric(FRS)和均值修改率(mACC)分别提高了10%和7%。此外，ID-Style的网络结构比基于工作小了约95%，但是它仍然能够保持与基于工作相似的修改效果。<details>
<summary>Abstract</summary>
Semantic facial attribute editing using pre-trained Generative Adversarial Networks (GANs) has attracted a great deal of attention and effort from researchers in recent years. Due to the high quality of face images generated by StyleGANs, much work has focused on the StyleGANs' latent space and the proposed methods for facial image editing. Although these methods have achieved satisfying results for manipulating user-intended attributes, they have not fulfilled the goal of preserving the identity, which is an important challenge. We present ID-Style, a new architecture capable of addressing the problem of identity loss during attribute manipulation. The key components of ID-Style include Learnable Global Direction (LGD), which finds a shared and semi-sparse direction for each attribute, and an Instance-Aware Intensity Predictor (IAIP) network, which finetunes the global direction according to the input instance. Furthermore, we introduce two losses during training to enforce the LGD to find semi-sparse semantic directions, which along with the IAIP, preserve the identity of the input instance. Despite reducing the size of the network by roughly 95% as compared to similar state-of-the-art works, it outperforms baselines by 10% and 7% in Identity preserving metric (FRS) and average accuracy of manipulation (mACC), respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>Recent years have seen a great deal of attention and effort from researchers in the field of semantic facial attribute editing using pre-trained Generative Adversarial Networks (GANs). This is due to the high quality of face images generated by StyleGANs, which has led to a focus on the latent space of StyleGANs and proposed methods for facial image editing. However, these methods have not been able to preserve the identity of the input instance, which is an important challenge. To address this challenge, we present ID-Style, a new architecture that includes Learnable Global Direction (LGD) and an Instance-Aware Intensity Predictor (IAIP) network. The LGD finds a shared and semi-sparse direction for each attribute, while the IAIP finetunes the global direction according to the input instance. Additionally, we introduce two losses during training to enforce the LGD to find semi-sparse semantic directions, which, along with the IAIP, preserve the identity of the input instance. Despite reducing the size of the network by roughly 95% compared to similar state-of-the-art works, ID-Style outperforms baselines by 10% and 7% in Identity Preserving Metric (FRS) and Average Accuracy of Manipulation (mACC), respectively.
</details></li>
</ul>
<hr>
<h2 id="Industrial-Application-of-6D-Pose-Estimation-for-Robotic-Manipulation-in-Automotive-Internal-Logistics"><a href="#Industrial-Application-of-6D-Pose-Estimation-for-Robotic-Manipulation-in-Automotive-Internal-Logistics" class="headerlink" title="Industrial Application of 6D Pose Estimation for Robotic Manipulation in Automotive Internal Logistics"></a>Industrial Application of 6D Pose Estimation for Robotic Manipulation in Automotive Internal Logistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14265">http://arxiv.org/abs/2309.14265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Quentin, Dino Knoll, Daniel Goehring</li>
<li>for: This paper aims to evaluate the current status quo of 6D pose estimation in the context of automotive parts handling tasks, and to identify the challenges and limitations of existing approaches.</li>
<li>methods: The authors built a representative 6D pose estimation pipeline using state-of-the-art components, including data generation methods and pose estimators, and evaluated its performance on automotive parts.</li>
<li>results: The authors found that the performance of the trained 6D pose estimators was promising, but did not meet industry requirements. They also revealed that the main challenge was the inability of the estimators to provide reliable uncertainties for their poses, rather than the accuracy of the poses themselves. Additionally, the authors compared RGB- and RGB-D-based approaches and showed that they are differently vulnerable to the domain gap induced by synthetic data.<details>
<summary>Abstract</summary>
Despite the advances in robotics a large proportion of the of parts handling tasks in the automotive industry's internal logistics are not automated but still performed by humans. A key component to competitively automate these processes is a 6D pose estimation that can handle a large number of different parts, is adaptable to new parts with little manual effort, and is sufficiently accurate and robust with respect to industry requirements. In this context, the question arises as to the current status quo with respect to these measures. To address this we built a representative 6D pose estimation pipeline with state-of-the-art components from economically scalable real to synthetic data generation to pose estimators and evaluated it on automotive parts with regards to a realistic sequencing process. We found that using the data generation approaches, the performance of the trained 6D pose estimators are promising, but do not meet industry requirements. We reveal that the reason for this is the inability of the estimators to provide reliable uncertainties for their poses, rather than the ability of to provide sufficiently accurate poses. In this context we further analyzed how RGB- and RGB-D-based approaches compare against this background and show that they are differently vulnerable to the domain gap induced by synthetic data.
</details>
<details>
<summary>摘要</summary>
Our results show that while the trained 6D pose estimators perform well, they do not meet industry requirements. We found that the reason for this is the inability of the estimators to provide reliable uncertainties for their poses, rather than the accuracy of the poses themselves. Additionally, we compared RGB- and RGB-D-based approaches and found that they are differently vulnerable to the domain gap induced by synthetic data.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Healthcare-with-EOG-A-Novel-Approach-to-Sleep-Stage-Classification"><a href="#Enhancing-Healthcare-with-EOG-A-Novel-Approach-to-Sleep-Stage-Classification" class="headerlink" title="Enhancing Healthcare with EOG: A Novel Approach to Sleep Stage Classification"></a>Enhancing Healthcare with EOG: A Novel Approach to Sleep Stage Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03757">http://arxiv.org/abs/2310.03757</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suvadeepmaiti/EOG_Sleep_Stage_classification">https://github.com/suvadeepmaiti/EOG_Sleep_Stage_classification</a></li>
<li>paper_authors: Suvadeep Maiti, Shivam Kumar Sharma, Raju S. Bapi</li>
<li>for:  automated sleep stage classification using EOG signals</li>
<li>methods:  proposed SE-Resnet-Transformer model, 1D-GradCAM, t-SNE plots</li>
<li>results:  accurate classification of five distinct sleep stages, noteworthy performance with macro-F1 scores of 74.72, 70.63, and 69.26, respectively, excelling in identifying REM sleep.<details>
<summary>Abstract</summary>
We introduce an innovative approach to automated sleep stage classification using EOG signals, addressing the discomfort and impracticality associated with EEG data acquisition. In addition, it is important to note that this approach is untapped in the field, highlighting its potential for novel insights and contributions. Our proposed SE-Resnet-Transformer model provides an accurate classification of five distinct sleep stages from raw EOG signal. Extensive validation on publically available databases (SleepEDF-20, SleepEDF-78, and SHHS) reveals noteworthy performance, with macro-F1 scores of 74.72, 70.63, and 69.26, respectively. Our model excels in identifying REM sleep, a crucial aspect of sleep disorder investigations. We also provide insight into the internal mechanisms of our model using techniques such as 1D-GradCAM and t-SNE plots. Our method improves the accessibility of sleep stage classification while decreasing the need for EEG modalities. This development will have promising implications for healthcare and the incorporation of wearable technology into sleep studies, thereby advancing the field's potential for enhanced diagnostics and patient comfort.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种创新的自动睡眠阶段分类方法使用 EOG 信号，解决了使用 EEG 数据采集所带来的不适和实用性问题。此外，这种方法在领域中尚未被探索，因此它的潜在性和贡献很大。我们的提议的 SE-Resnet-Transformer 模型可以准确地从原始 EOG 信号中分类五个不同的睡眠阶段。我们对公共可用的数据库（SleepEDF-20、SleepEDF-78 和 SHHS）进行了广泛的验证，并发现了关键的表现，其中 macro-F1 分数分别为 74.72、70.63 和 69.26。我们的模型在识别 REM 睡眠方面表现出色，这是许多睡眠疾病研究中的关键方面。我们还使用了一些技术，如 1D-GradCAM 和 t-SNE 图表，来探索我们的模型的内部机制。我们的方法可以提高睡眠阶段分类的可accessibility，同时减少 EEG 模态的需求。这种发展将对医疗保健和睡眠研究中的睡眠疾病诊断和患者舒适具有普ROMising的影响。
</details></li>
</ul>
<hr>
<h2 id="Informative-Data-Mining-for-One-Shot-Cross-Domain-Semantic-Segmentation"><a href="#Informative-Data-Mining-for-One-Shot-Cross-Domain-Semantic-Segmentation" class="headerlink" title="Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation"></a>Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14241">http://arxiv.org/abs/2309.14241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Wang, Jian Liang, Jun Xiao, Shuqi Mei, Yuran Yang, Zhaoxiang Zhang<br>for: 这个研究旨在提供一个有效的一击适应方法，实现从标注源数据到无标注目数据的语意分类转换。methods: 这个方法使用了一个新的选择项目，将标注源数据中的最有用样本选择出来，以便快速适应和减少过滤训练。然后，这些选择的样本会被用来更新模型，包括裁剪和原型基于的信息增强。results: 我们的方法在实验中表现出色，比较 existing 方法高效和精度。 Specifically, our approach achieves a new state-of-the-art one-shot performance of 56.7%&#x2F;55.4% on the GTA5&#x2F;SYNTHIA to Cityscapes adaptation tasks, respectively.<details>
<summary>Abstract</summary>
Contemporary domain adaptation offers a practical solution for achieving cross-domain transfer of semantic segmentation between labeled source data and unlabeled target data. These solutions have gained significant popularity; however, they require the model to be retrained when the test environment changes. This can result in unbearable costs in certain applications due to the time-consuming training process and concerns regarding data privacy. One-shot domain adaptation methods attempt to overcome these challenges by transferring the pre-trained source model to the target domain using only one target data. Despite this, the referring style transfer module still faces issues with computation cost and over-fitting problems. To address this problem, we propose a novel framework called Informative Data Mining (IDM) that enables efficient one-shot domain adaptation for semantic segmentation. Specifically, IDM provides an uncertainty-based selection criterion to identify the most informative samples, which facilitates quick adaptation and reduces redundant training. We then perform a model adaptation method using these selected samples, which includes patch-wise mixing and prototype-based information maximization to update the model. This approach effectively enhances adaptation and mitigates the overfitting problem. In general, we provide empirical evidence of the effectiveness and efficiency of IDM. Our approach outperforms existing methods and achieves a new state-of-the-art one-shot performance of 56.7\%/55.4\% on the GTA5/SYNTHIA to Cityscapes adaptation tasks, respectively. The code will be released at \url{https://github.com/yxiwang/IDM}.
</details>
<details>
<summary>摘要</summary>
当前领域的适应采用实现了semantic segmentation中的交叉频道传输，即使在不同的测试环境下，可以将源数据标注得到目标数据上的semantic segmentation。这些解决方案在应用中得到了广泛的应用，但是它们需要模型在测试环境发生变化时重新训练，这可能会导致不可持额外高的成本，特别是在时间consuming的训练过程和数据隐私问题上。one-shot适应方法试图解决这些挑战，通过将源模型转移到目标频道上，只需要一个目标数据。然而，这些方法仍然面临计算成本和过拟合问题。为了解决这个问题，我们提出了一种新的框架，即信息挖掘（Informative Data Mining，IDM）。IDM提供了一种不确定性基于的选择 criterion，可以帮助快速适应和减少重复训练。然后，我们使用这些选择的样本进行模型适应方法，包括patch-wise混合和prototype-based信息最大化，以更新模型。这种方法有效地提高适应和减少过拟合问题。总之，我们提供了empirical evidence表明IDM的效果和效率。我们的方法比现有方法更高效，在GTA5/SYNTHIA到Cityscapes适应任务上达到了56.7%/55.4%的一射性能。我们的代码将在\url{https://github.com/yxiwang/IDM}上发布。
</details></li>
</ul>
<hr>
<h2 id="QuadricsNet-Learning-Concise-Representation-for-Geometric-Primitives-in-Point-Clouds"><a href="#QuadricsNet-Learning-Concise-Representation-for-Geometric-Primitives-in-Point-Clouds" class="headerlink" title="QuadricsNet: Learning Concise Representation for Geometric Primitives in Point Clouds"></a>QuadricsNet: Learning Concise Representation for Geometric Primitives in Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14211">http://arxiv.org/abs/2309.14211</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/michaelwu99-lab/quadricsnet">https://github.com/michaelwu99-lab/quadricsnet</a></li>
<li>paper_authors: Ji Wu, Huai Yu, Wen Yang, Gui-Song Xia</li>
<li>for: 本研究目的是提出一种 novel 的抽象框架，用于学习 3D 点云中的减少精简 geometric primitive representation。</li>
<li>methods: 我们使用 quadrics 来表示多种 primitives，并提出了首个 end-to-end 学习基于 quadrics 的框架，即 QuadricsNet，用于解析 quadrics 在点云中。我们还提出了一种新的 pattern-comprehensive 数据集，用于训练和评估。</li>
<li>results: 我们的研究表明，我们的精简表示方法和 QuadricsNet 框架具有高效性和稳定性。我们的代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/MichaelWu99-lab/QuadricsNet%7D">https://github.com/MichaelWu99-lab/QuadricsNet}</a> 上获取。<details>
<summary>Abstract</summary>
This paper presents a novel framework to learn a concise geometric primitive representation for 3D point clouds. Different from representing each type of primitive individually, we focus on the challenging problem of how to achieve a concise and uniform representation robustly. We employ quadrics to represent diverse primitives with only 10 parameters and propose the first end-to-end learning-based framework, namely QuadricsNet, to parse quadrics in point clouds. The relationships between quadrics mathematical formulation and geometric attributes, including the type, scale and pose, are insightfully integrated for effective supervision of QuaidricsNet. Besides, a novel pattern-comprehensive dataset with quadrics segments and objects is collected for training and evaluation. Experiments demonstrate the effectiveness of our concise representation and the robustness of QuadricsNet. Our code is available at \url{https://github.com/MichaelWu99-lab/QuadricsNet}
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的框架，用于学习3D点云中简洁的 геометри� primitives表示。与之前每种 primitives 都被 individually 表示不同，我们在挑战性的问题上关注了如何实现一种简洁而均衡的表示。我们使用 quadrics 来表示多样化的 primitives，只需要10个参数。我们提出了第一个终端学习基于架构，即 QuadricsNet，用于解析 quadrics 在点云中。我们妥善地 интеGRATE了 quadrics 的数学表述和 geometric attribute，包括类型、比例和 Orient，以便对 QuadricsNet 进行有效的监督。此外，我们还收集了包含 quadrics 段和物体的novel pattern-comprehensive dataset，用于训练和评估。实验表明我们的简洁表示和 QuadricsNet 的稳定性。我们的代码可以在 GitHub 上找到：https://github.com/MichaelWu99-lab/QuadricsNet。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Animation-of-Hair-Blowing-in-Still-Portrait-Photos"><a href="#Automatic-Animation-of-Hair-Blowing-in-Still-Portrait-Photos" class="headerlink" title="Automatic Animation of Hair Blowing in Still Portrait Photos"></a>Automatic Animation of Hair Blowing in Still Portrait Photos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14207">http://arxiv.org/abs/2309.14207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenpeng Xiao, Wentao Liu, Yitong Wang, Bernard Ghanem, Bing Li</li>
<li>for: 这个论文是为了自动animate人类发样图片中的人发。</li>
<li>methods: 该论文使用了先进的实例分割网络，将发分解为多个实例，并提出了一种基于实例分割的发动模块，以生成自然和愉悦的发动效果。</li>
<li>results: 对比其他state-of-the-art方法，该论文的方法在量化评价中占优，并在质量测试中提供了最愉悦和最吸引人的视觉效果。<details>
<summary>Abstract</summary>
We propose a novel approach to animate human hair in a still portrait photo. Existing work has largely studied the animation of fluid elements such as water and fire. However, hair animation for a real image remains underexplored, which is a challenging problem, due to the high complexity of hair structure and dynamics. Considering the complexity of hair structure, we innovatively treat hair wisp extraction as an instance segmentation problem, where a hair wisp is referred to as an instance. With advanced instance segmentation networks, our method extracts meaningful and natural hair wisps. Furthermore, we propose a wisp-aware animation module that animates hair wisps with pleasing motions without noticeable artifacts. The extensive experiments show the superiority of our method. Our method provides the most pleasing and compelling viewing experience in the qualitative experiments and outperforms state-of-the-art still-image animation methods by a large margin in the quantitative evaluation. Project url: \url{https://nevergiveu.github.io/AutomaticHairBlowing/}
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于在静止画像中动画人类发型。现有的工作主要研究了流体元素的动画，如水和火。然而，对真实图像中的发型动画还具有挑战性，这是因为发型结构的复杂性和动态性。为了解决这个问题，我们创新地将发型抽取视为实例分割问题，其中每个发型被称为一个实例。使用高级实例分割网络，我们的方法可以EXTRACT meaningful和自然的发型。此外，我们还提议了一种发型感知动画模块，可以使发型动画具有愉悦的运动而不会出现显著的瑕疵。我们的实验结果表明，我们的方法可以提供最有趣和最有吸引力的视觉体验，并在量化评价中大幅超越了现有的静止图像动画方法。项目链接：<https://nevergiveu.github.io/AutomaticHairBlowing/>
</details></li>
</ul>
<hr>
<h2 id="Detecting-and-Grounding-Multi-Modal-Media-Manipulation-and-Beyond"><a href="#Detecting-and-Grounding-Multi-Modal-Media-Manipulation-and-Beyond" class="headerlink" title="Detecting and Grounding Multi-Modal Media Manipulation and Beyond"></a>Detecting and Grounding Multi-Modal Media Manipulation and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14203">http://arxiv.org/abs/2309.14203</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rshaojimmy/multimodal-deepfake">https://github.com/rshaojimmy/multimodal-deepfake</a></li>
<li>paper_authors: Rui Shao, Tianxing Wu, Jianlong Wu, Liqiang Nie, Ziwei Liu</li>
<li>for: 本研究探讨了一新的多Modal媒体伪造问题，即Detecting and Grounding Multi-Modal Media Manipulation (DGM^4)，旨在不仅检测多Modal媒体的 authenticty，还是根据多Modal媒体的不同modalities进行深入的媒体伪造推理。</li>
<li>methods: 本研究提出了一种名为 HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) 的新方法，该方法包括两个主要部分：1) 多Modal媒体杂化学习和深度媒体推理两个部分，以及2) 多Modal媒体聚合器。</li>
<li>results: 实验结果表明，HAMMER和HAMMER++ 两种模型具有superiority，能够准确地检测和理解多Modal媒体中的伪造 traces。<details>
<summary>Abstract</summary>
Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various deepfake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely Detecting and Grounding Multi-Modal Media Manipulation (DGM^4). DGM^4 aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content, which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER performs 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model HAMMER++. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of HAMMER and HAMMER++.
</details>
<details>
<summary>摘要</summary>
伪信息已成为一种紧迫的问题。在图像和文本之间的多modal forgery广泛存在于互联网上。虽然多种深度迷假检测和文本假新闻检测方法已经提出，但它们只是为单模态迷假进行二分类 binary classification，而不是检测和理解多modal media forgery的细节。在这篇论文中，我们提出了一个新的研究问题：多Modal Media Manipulation Detection and Grounding（DGM^4）。DGM^4的目标不仅是检测多modal media的authenticity，而且需要理解和检测受到 modificaiton的内容，这需要更深入的理解多modal media forgery。为了支持大规模的研究，我们构建了第一个DGM^4数据集，其中图像和文本组合被多种方法修改，并且有丰富的修改注释。此外，我们提出了一种 HierArchical Multi-modal Manipulation rEasoning tRansformer（HAMMER），它可以全面捕捉多modal media forgery的细节交互。HAMMER包括两种推理方法：1）在图像和文本之间进行修改意识的对比学习，以及2）在多modal信息之间进行模块相关的交互。通过将这两种推理方法集成到深度和浅度层次上，我们可以实现更细致的修改检测和修改理解。为了更好地利用跨modal semantic alignment的推理，我们还提出了Manipulation-Aware Contrastive Loss with Local View，并构建了更先进的模型HAMMER++。最后，我们建立了一个完整的 bencmarks，并设置了严格的评价指标。广泛的实验表明HAMMER和HAMMER++的优越性。
</details></li>
</ul>
<hr>
<h2 id="Predictable-Performance-Bias-in-Unsupervised-Anomaly-Detection"><a href="#Predictable-Performance-Bias-in-Unsupervised-Anomaly-Detection" class="headerlink" title="(Predictable) Performance Bias in Unsupervised Anomaly Detection"></a>(Predictable) Performance Bias in Unsupervised Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14198">http://arxiv.org/abs/2309.14198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix Meissen, Svenja Breuer, Moritz Knolle, Alena Buyx, Ruth Müller, Georgios Kaissis, Benedikt Wiestler, Daniel Rückert</li>
<li>for: 本研究旨在探讨Unsupervised Anomaly Detection（UAD）模型在医疗领域中的公平性问题。</li>
<li>methods: 我们使用三个大规模公共available的胸部X射线图像 dataset进行了实验，并使用了两种 state-of-the-art UAD模型 для医疗图像。我们还引入了一个新的 subgroup-AUROC（sAUROC）指标，用于衡量机器学习的公平性。</li>
<li>results: 我们的实验发现了“公平法律”（类似于 Transformers 中的“扩大法律”），即训练集中 subgroup 的表达与该 subgroup 内 anomaly detection性能之间存在直线关系。我们的研究还发现了Balanced training data 仍然存在性能差距，并且这些差距可以叠加，使得具有多个不利影响组的主体性能更加低下。<details>
<summary>Abstract</summary>
Background: With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified. Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection. While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored.   Methods: In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets. Our experiments were validated using two state-of-the-art UAD models for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning.   Findings: Our experiments revealed empirical "fairness laws" (similar to "scaling laws" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data. Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups.   Interpretation: Our study quantified the disparate performance of UAD models against certain demographic subgroups. Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone. Instead, the representation of some subgroups seems harder to learn by UAD models than that of others. The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition.
</details>
<details>
<summary>摘要</summary>
Background: With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified. Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection. While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored.Methods: In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets. Our experiments were validated using two state-of-the-art UAD models for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning.Findings: Our experiments revealed empirical "fairness laws" (similar to "scaling laws" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data. Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups.Interpretation: Our study quantified the disparate performance of UAD models against certain demographic subgroups. Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone. Instead, the representation of some subgroups seems harder to learn by UAD models than that of others. The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition.Here's the translation in Traditional Chinese:背景：随着医疗影像数据的不断增加，诊断助手需求增加。不监督型异常检测（UAD）模型能帮助在疾病检测的首步中发掘疾病。过去的研究已经对医疗保健领域中监督模型的公平性进行了广泛的探讨，但是对UAD模型仍然是未知的。方法：这次研究中，我们评估了不同子群体的参数影响UAD模型在多个数据库中的表现差异。我们使用了三个公共可用的胸部X射影数据库，并验证了两个现有的UAD模型。最后，我们引入了一个新的子群体AUROC（sAUROC）指标，以便量测机器学习中的公平性。发现：我们的实验发现了关于训练集合的公平性法则（similar to Transformers的推广法则），这些法则表示在一个子population中的异常检测性能和训练集合中的表现之间的直线关系。我们的研究还发现了充分平衡的训练数据中的表现差异，以及两个或多个负面影响的子群体之间的互动效应。解释：我们的研究量化了UAD模型对特定民族子群体的不公平表现。我们发现了，不公平性不能通过充分平衡 alone 来减轻。相反，一些子群体的表现似乎更难由UAD模型学习，而其他子群体的表现则更容易学习。我们在这研究中发现的公平法则使得UAD模型的不公平表现更易估计，并帮助决定最佳的训练集合。
</details></li>
</ul>
<hr>
<h2 id="LAPP-Layer-Adaptive-Progressive-Pruning-for-Compressing-CNNs-from-Scratch"><a href="#LAPP-Layer-Adaptive-Progressive-Pruning-for-Compressing-CNNs-from-Scratch" class="headerlink" title="LAPP: Layer Adaptive Progressive Pruning for Compressing CNNs from Scratch"></a>LAPP: Layer Adaptive Progressive Pruning for Compressing CNNs from Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14157">http://arxiv.org/abs/2309.14157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pucheng Zhai, Kailing Guo, Fang Liu, Xiaofen Xing, Xiangmin Xu<br>for:这个论文的目的是提出一种名为层 adaptive progressive pruning（LAPP）的框架，用于快速适应性地减小 convolutional Neural Network（CNN）的计算量。methods:LAPP 框架使用了一种learnable threshold和 FLOPs 约束来控制减小率，并在训练过程中动态更新这些约束，以便适应不同层的重要性分数变化。此外，在减小每层之前，我们还引入了一种轻量级的跳过来提高减小后的表达能力。results:与先前的压缩方法相比，LAPP 框架在多个数据集和后ION 背景上达到了更高的性能提升。例如，在 CIFAR-10 上，我们可以压缩 ResNet-20 到 40.3% 而无需减少精度。 ImageNet 上，我们可以减少 ResNet-18 的 FLOPs 55.6%，同时保持顶部 1 准确率和顶部 5 准确率不变。<details>
<summary>Abstract</summary>
Structured pruning is a commonly used convolutional neural network (CNN) compression approach. Pruning rate setting is a fundamental problem in structured pruning. Most existing works introduce too many additional learnable parameters to assign different pruning rates across different layers in CNN or cannot control the compression rate explicitly. Since too narrow network blocks information flow for training, automatic pruning rate setting cannot explore a high pruning rate for a specific layer. To overcome these limitations, we propose a novel framework named Layer Adaptive Progressive Pruning (LAPP), which gradually compresses the network during initial training of a few epochs from scratch. In particular, LAPP designs an effective and efficient pruning strategy that introduces a learnable threshold for each layer and FLOPs constraints for network. Guided by both task loss and FLOPs constraints, the learnable thresholds are dynamically and gradually updated to accommodate changes of importance scores during training. Therefore the pruning strategy can gradually prune the network and automatically determine the appropriate pruning rates for each layer. What's more, in order to maintain the expressive power of the pruned layer, before training starts, we introduce an additional lightweight bypass for each convolutional layer to be pruned, which only adds relatively few additional burdens. Our method demonstrates superior performance gains over previous compression methods on various datasets and backbone architectures. For example, on CIFAR-10, our method compresses ResNet-20 to 40.3% without accuracy drop. 55.6% of FLOPs of ResNet-18 are reduced with 0.21% top-1 accuracy increase and 0.40% top-5 accuracy increase on ImageNet.
</details>
<details>
<summary>摘要</summary>
“构成式剔除”是一种常用的卷积神经网络（CNN）压缩方法。剔除率设定是 convolutional neural network （CNN）压缩的基本问题。现有大多数的工作将额外的可学习参数引入到不同层的 CNN 中，以便对不同层设置不同的剔除率。另外，一些方法无法明确控制压缩率，或者对于特定层设置过高的剔除率。这些限制使得自动剔除率设定无法充分发挥其效果。为了解决这些问题，我们提出了一个名为层别进行式进行剔除（Layer Adaptive Progressive Pruning，LAPP）的新框架。LAPP 采用了一个可学习的阈值，以及 FLOPs 约束，以便在训练的初期几十轮中逐步压缩网络。具体来说，LAPP 设计了一个高效且可靠的剔除策略，通过在训练过程中逐步更新可学习的阈值，以便适应变化的重要性分数。因此，LAPP 可以逐步剔除网络，并自动决定每个层的适当剔除率。此外，为维护剔除后的表达能力，我们将每个剔除的卷积层加上一个轻量级的辅助路径，这仅增加了一些轻微的负担。我们的方法在多个数据集和背景 arquitectures 上示出了优秀的性能提升。例如，在 CIFAR-10 上，我们将 ResNet-20 压缩到 40.3% without accuracy drop。 ImageNet 上，我们将 ResNet-18 的 FLOPs 压缩到 55.6%，并且跟踪到 0.21% 顶部 1 accuracy increase 和 0.40% top-5 accuracy increase。
</details></li>
</ul>
<hr>
<h2 id="IEBins-Iterative-Elastic-Bins-for-Monocular-Depth-Estimation"><a href="#IEBins-Iterative-Elastic-Bins-for-Monocular-Depth-Estimation" class="headerlink" title="IEBins: Iterative Elastic Bins for Monocular Depth Estimation"></a>IEBins: Iterative Elastic Bins for Monocular Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14137">http://arxiv.org/abs/2309.14137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuweishao/iebins">https://github.com/shuweishao/iebins</a></li>
<li>paper_authors: Shuwei Shao, Zhongcai Pei, Xingming Wu, Zhong Liu, Weihai Chen, Zhengguo Li<br>for:* 本研究旨在提出一种基于分类回归的独眼深度估计方法（MDE），用于解决独眼深度估计中的问题。methods:* 提出了一种新的迭代弹性桶（IEBins）技术，用于在多个阶段中进行高质量深度搜索。* 利用了一种 нов的弹性目标桶技术，以适应不同的深度不确定性。results:* 对于KITTI、NYU-Depth-v2和SUN RGB-D数据集进行了广泛的实验，并证明了提出的方法可以超越先前的状态之 искусственный智能。* 源代码可以在<a target="_blank" rel="noopener" href="https://github.com/ShuweiShao/IEBins%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ShuweiShao/IEBins上获取。</a><details>
<summary>Abstract</summary>
Monocular depth estimation (MDE) is a fundamental topic of geometric computer vision and a core technique for many downstream applications. Recently, several methods reframe the MDE as a classification-regression problem where a linear combination of probabilistic distribution and bin centers is used to predict depth. In this paper, we propose a novel concept of iterative elastic bins (IEBins) for the classification-regression-based MDE. The proposed IEBins aims to search for high-quality depth by progressively optimizing the search range, which involves multiple stages and each stage performs a finer-grained depth search in the target bin on top of its previous stage. To alleviate the possible error accumulation during the iterative process, we utilize a novel elastic target bin to replace the original target bin, the width of which is adjusted elastically based on the depth uncertainty. Furthermore, we develop a dedicated framework composed of a feature extractor and an iterative optimizer that has powerful temporal context modeling capabilities benefiting from the GRU-based architecture. Extensive experiments on the KITTI, NYU-Depth-v2 and SUN RGB-D datasets demonstrate that the proposed method surpasses prior state-of-the-art competitors. The source code is publicly available at https://github.com/ShuweiShao/IEBins.
</details>
<details>
<summary>摘要</summary>
《单眼深度估计（MDE）是计算机视觉的基本领域和许多下渠应用的核心技术。近期，一些方法将MDE视为一个分类预测和回传问题，使用线性结合的概率分布和数组中心来预测深度。本文提出一个新的迭代弹性桶（IEBins）概念，用于分类预测和回传问题的MDE。提案的IEBins通过不断地优化搜寻范围，以进行多阶段的精确深度搜寻。为了避免可能的错误累累在迭代过程中，我们使用了一个新的弹性目标桶，其宽度根据深度不确定而调整。此外，我们开发了一个特别的架构，包括一个特征提取器和一个迭代优化器，具有强大的时间统计模型能力，从GRU架构中受益。广泛的实验表明，提案的方法在KITTI、NYU-Depth-v2和SUN RGB-D数据集上具有较高的性能，超过了先前的州际之径。原始代码可以在https://github.com/ShuweiShao/IEBins上取得。
</details></li>
</ul>
<hr>
<h2 id="Masked-Image-Residual-Learning-for-Scaling-Deeper-Vision-Transformers"><a href="#Masked-Image-Residual-Learning-for-Scaling-Deeper-Vision-Transformers" class="headerlink" title="Masked Image Residual Learning for Scaling Deeper Vision Transformers"></a>Masked Image Residual Learning for Scaling Deeper Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14136">http://arxiv.org/abs/2309.14136</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/russellllaputa/MIRL">https://github.com/russellllaputa/MIRL</a></li>
<li>paper_authors: Guoxi Huang, Hongtao Fu, Adrian G. Bors</li>
<li>for: 这篇研究旨在提高深度向 ViT 的训练过程，并解决深度层中的降低问题。</li>
<li>methods:  authors propose a self-supervised learning framework called Masked Image Residual Learning (MIRL), which significantly alleviates the degradation problem, making it possible to scale ViT along depth for performance upgrade.</li>
<li>results:  authors show that deeper ViTs can be effectively optimized using MIRL, and easily gain accuracy from increased depth. With the same level of computational complexity as ViT-Base and ViT-Large, they instantiate 4.5 times and 2 times deeper ViTs, dubbed ViT-S-54 and ViT-B-48. The deeper ViT-S-54 achieves performance on par with ViT-Large, while ViT-B-48 achieves 86.2% top-1 accuracy on ImageNet.<details>
<summary>Abstract</summary>
Deeper Vision Transformers (ViTs) are more challenging to train. We expose a degradation problem in deeper layers of ViT when using masked image modeling (MIM) for pre-training. To ease the training of deeper ViTs, we introduce a self-supervised learning framework called Masked Image Residual Learning (MIRL), which significantly alleviates the degradation problem, making scaling ViT along depth a promising direction for performance upgrade. We reformulate the pre-training objective for deeper layers of ViT as learning to recover the residual of the masked image. We provide extensive empirical evidence showing that deeper ViTs can be effectively optimized using MIRL and easily gain accuracy from increased depth. With the same level of computational complexity as ViT-Base and ViT-Large, we instantiate 4.5$\times$ and 2$\times$ deeper ViTs, dubbed ViT-S-54 and ViT-B-48. The deeper ViT-S-54, costing 3$\times$ less than ViT-Large, achieves performance on par with ViT-Large. ViT-B-48 achieves 86.2% top-1 accuracy on ImageNet. On one hand, deeper ViTs pre-trained with MIRL exhibit excellent generalization capabilities on downstream tasks, such as object detection and semantic segmentation. On the other hand, MIRL demonstrates high pre-training efficiency. With less pre-training time, MIRL yields competitive performance compared to other approaches.
</details>
<details>
<summary>摘要</summary>
deeper 视图变换器（ViTs）更加具有挑战性，我们揭示了深层 ViT 的降低问题，当使用掩码图像模型（MIM）进行预训练时。为了减轻深层 ViT 的训练困难，我们提出了一种自动学习框架，称为掩码图像差分学习（MIRL），它可以明显减轻降低问题，使深层 ViT 的缩放成为性能升级的可能性。我们重新表述了深层 ViT 的预训练目标，即学习恢复掩码图像中的差异。我们提供了丰富的实验证据，表明深层 ViT 可以通过 MIRL 有效地优化，并且可以轻松地从增加深度中获得性能提升。与 ViT-Base 和 ViT-Large 相同的计算复杂度下，我们实例化了 4.5 $\times$ 和 2 $\times$ 深度更深的 ViTs，称为 ViT-S-54 和 ViT-B-48。深度更深的 ViT-S-54，耗资相当于 ViT-Large 的三倍，却可以与 ViT-Large 的性能一致。ViT-B-48 在 ImageNet 上达到 86.2% 的顶部一 Accuracy。一方面，深度更深的 ViTs 预训练后在下游任务中表现出色，如物体检测和semantic segmentation。另一方面， MIRL 表现出高效的预训练能力，需要更少的预训练时间，却可以与其他方法相比肩并胜。
</details></li>
</ul>
<hr>
<h2 id="SurrogatePrompt-Bypassing-the-Safety-Filter-of-Text-To-Image-Models-via-Substitution"><a href="#SurrogatePrompt-Bypassing-the-Safety-Filter-of-Text-To-Image-Models-via-Substitution" class="headerlink" title="SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution"></a>SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14122">http://arxiv.org/abs/2309.14122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zjm1900/surrogateprompt">https://github.com/zjm1900/surrogateprompt</a></li>
<li>paper_authors: Zhongjie Ba, Jieming Zhong, Jiachen Lei, Peng Cheng, Qinglong Wang, Zhan Qin, Zhibo Wang, Kui Ren</li>
<li>for: The paper is written to address the issue of advanced text-to-image models generating unsafe content, specifically photorealistic NSFW images of political figures.</li>
<li>methods: The paper uses a novel framework called SurrogatePrompt, which utilizes large language models, image-to-text, and image-to-image modules to automate the creation of attack prompts that can bypass the safety filters of closed-source models like Midjourney.</li>
<li>results: The paper demonstrates the success of SurrogatePrompt in generating abundant photorealistic NSFW images of political figures by exploiting vulnerabilities in Midjourney’s proprietary safety filter, with an 88% success rate in bypassing the filter. The generated images are found to present significant safety hazards, both subjectively and objectively.<details>
<summary>Abstract</summary>
Advanced text-to-image models such as DALL-E 2 and Midjourney possess the capacity to generate highly realistic images, raising significant concerns regarding the potential proliferation of unsafe content. This includes adult, violent, or deceptive imagery of political figures. Despite claims of rigorous safety mechanisms implemented in these models to restrict the generation of not-safe-for-work (NSFW) content, we successfully devise and exhibit the first prompt attacks on Midjourney, resulting in the production of abundant photorealistic NSFW images. We reveal the fundamental principles of such prompt attacks and suggest strategically substituting high-risk sections within a suspect prompt to evade closed-source safety measures. Our novel framework, SurrogatePrompt, systematically generates attack prompts, utilizing large language models, image-to-text, and image-to-image modules to automate attack prompt creation at scale. Evaluation results disclose an 88% success rate in bypassing Midjourney's proprietary safety filter with our attack prompts, leading to the generation of counterfeit images depicting political figures in violent scenarios. Both subjective and objective assessments validate that the images generated from our attack prompts present considerable safety hazards.
</details>
<details>
<summary>摘要</summary>
高级文本到图像模型如DALL-E 2和Midjourney具有生成高度真实的图像能力，这引发了严重的安全问题。这包括政治人物的成人、暴力或误导性图像。尽管这些模型的生成不安全内容的安全机制已经实施了严格的安全措施，但我们成功地开发了第一个攻击示例，使得Midjourney生成了大量高度真实的不安全图像。我们揭示了攻击示例的基本原理，并建议在涉及高风险的提示中进行部分替换，以避免关闭源代码安全措施。我们的新框架SurrogatePrompt可以在大规模的攻击提示创建中自动化攻击提示的生成。我们的评估结果表明，使用我们的攻击提示可以在Midjourney的专有安全筛选器中成功绕过88%的攻击，并生成政治人物在暴力场景中的假图像。subjective和objective评估表明，生成的图像具有严重的安全风险。
</details></li>
</ul>
<hr>
<h2 id="Convolutional-autoencoder-based-multimodal-one-class-classification"><a href="#Convolutional-autoencoder-based-multimodal-one-class-classification" class="headerlink" title="Convolutional autoencoder-based multimodal one-class classification"></a>Convolutional autoencoder-based multimodal one-class classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14090">http://arxiv.org/abs/2309.14090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Firas Laakom, Fahad Sohrab, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj</li>
<li>for: 这种论文是为了提出一种适用于多Modal数据的深度学习一类分类方法，以便在异常检测中使用。</li>
<li>methods: 该方法使用了两个卷积autoencoder并在它们之间进行了 JOINT 训练，以使得输入数据在幂等空间中得到最紧凑的表示。</li>
<li>results: 对于一个多Modal图像分类数据集，该方法的实验结果表明，与单模式方法相比，该方法的多模式方法得到了更好的结果。此外，研究不同的输入图像大小和最新的特征多样性规则izers的影响，并证明这些规则izers可以提高性能。<details>
<summary>Abstract</summary>
One-class classification refers to approaches of learning using data from a single class only. In this paper, we propose a deep learning one-class classification method suitable for multimodal data, which relies on two convolutional autoencoders jointly trained to reconstruct the positive input data while obtaining the data representations in the latent space as compact as possible. During inference, the distance of the latent representation of an input to the origin can be used as an anomaly score. Experimental results using a multimodal macroinvertebrate image classification dataset show that the proposed multimodal method yields better results as compared to the unimodal approach. Furthermore, study the effect of different input image sizes, and we investigate how recently proposed feature diversity regularizers affect the performance of our approach. We show that such regularizers improve performance.
</details>
<details>
<summary>摘要</summary>
一类分类指的是使用单一类型的数据进行学习。在这篇论文中，我们提出了一种适用于多modal数据的深度学习一类分类方法，该方法基于两个卷积 autoencoder 同时进行卷积重构正确的输入数据，并在幂空间中获得数据表示的最短距离。在推理阶段，输入数据的幂空间表示距离原点的距离可以作为异常分数。我们使用多modalmacro生物图像分类 dataset 进行实验，并证明了我们的方法在多modal数据中获得更好的结果，而且比单modal方法更好。此外，我们还研究了不同的输入图像大小的效果，以及最近提出的特征多样化规范化的影响。我们发现这些规范化可以提高性能。
</details></li>
</ul>
<hr>
<h2 id="BoIR-Box-Supervised-Instance-Representation-for-Multi-Person-Pose-Estimation"><a href="#BoIR-Box-Supervised-Instance-Representation-for-Multi-Person-Pose-Estimation" class="headerlink" title="BoIR: Box-Supervised Instance Representation for Multi-Person Pose Estimation"></a>BoIR: Box-Supervised Instance Representation for Multi-Person Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14072">http://arxiv.org/abs/2309.14072</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uyoung-jeong/BoIR">https://github.com/uyoung-jeong/BoIR</a></li>
<li>paper_authors: Uyoung Jeong, Seungryul Baek, Hyung Jin Chang, Kwang In Kim</li>
<li>for: 这篇论文是为了提出一种解决多人 pose estimation 下 instances 分解问题的方法，提高了scene中人体pose estimation的性能。</li>
<li>methods: 该方法使用了 bounding box-level instance representation learning，同时解决了人体实例检测、实例分解和实例关键点匹配问题。它还使用了多任务学习，包括底层关键点估计、 bounding box 回归和对比式实例嵌入学习，无需在推理过程中添加额外计算成本。</li>
<li>results: 该方法在 CrowdPose 和 OCHuman 等数据集上达到了领先的性能水平，比如 COCO val (0.8 AP)、COCO test-dev (0.5 AP) 和 CrowdPose (4.9 AP) 等。<details>
<summary>Abstract</summary>
Single-stage multi-person human pose estimation (MPPE) methods have shown great performance improvements, but existing methods fail to disentangle features by individual instances under crowded scenes. In this paper, we propose a bounding box-level instance representation learning called BoIR, which simultaneously solves instance detection, instance disentanglement, and instance-keypoint association problems. Our new instance embedding loss provides a learning signal on the entire area of the image with bounding box annotations, achieving globally consistent and disentangled instance representation. Our method exploits multi-task learning of bottom-up keypoint estimation, bounding box regression, and contrastive instance embedding learning, without additional computational cost during inference. BoIR is effective for crowded scenes, outperforming state-of-the-art on COCO val (0.8 AP), COCO test-dev (0.5 AP), CrowdPose (4.9 AP), and OCHuman (3.5 AP). Code will be available at https://github.com/uyoung-jeong/BoIR
</details>
<details>
<summary>摘要</summary>
单stage多人人体 pose 估计（MPPE）方法已经达到了非常高的性能水平，但现有方法在拥挤场景下无法分离特征。在这篇论文中，我们提出了一种名为BoIR的 bounding box 级别实体表示学习方法，该方法同时解决实体检测、实体分离和实体关键点匹配问题。我们的新的实体嵌入损失提供了图像整体的学习信号，实现了全局一致的和分离的实体表示。我们的方法通过 bottom-up 关键点估计、 bounding box 回归和对比实体嵌入学习 Multi-task learning，不需要额外计算成本在推理过程中。BoIR 在拥挤场景下表现出色，与状态流行的 COCO val (0.8 AP)、COCO test-dev (0.5 AP)、CrowdPose (4.9 AP) 和 OCHuman (3.5 AP) 等测试集上表现出色。代码将在 GitHub 上提供，请参考 https://github.com/uyoung-jeong/BoIR。
</details></li>
</ul>
<hr>
<h2 id="Soft-Mixture-Denoising-Beyond-the-Expressive-Bottleneck-of-Diffusion-Models"><a href="#Soft-Mixture-Denoising-Beyond-the-Expressive-Bottleneck-of-Diffusion-Models" class="headerlink" title="Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models"></a>Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14068">http://arxiv.org/abs/2309.14068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li, Boris van Breugel, Mihaela van der Schaar</li>
<li>for: 这 paper 是 investigate  diffusion models 的表现和假设的，特别是在 backward denoising 方面。</li>
<li>methods: 这 paper 使用 current diffusion models 和 soft mixture denoising (SMD) 方法进行研究。</li>
<li>results: 这 paper 发现 current diffusion models 在 backward denoising 方面存在 expressive bottleneck 和 unbounded errors，而 SMD 方法可以有效地解决这些问题，并在实际应用中表现出优于 diffusion models。<details>
<summary>Abstract</summary>
Because diffusion models have shown impressive performances in a number of tasks, such as image synthesis, there is a trend in recent works to prove (with certain assumptions) that these models have strong approximation capabilities. In this paper, we show that current diffusion models actually have an expressive bottleneck in backward denoising and some assumption made by existing theoretical guarantees is too strong. Based on this finding, we prove that diffusion models have unbounded errors in both local and global denoising. In light of our theoretical studies, we introduce soft mixture denoising (SMD), an expressive and efficient model for backward denoising. SMD not only permits diffusion models to well approximate any Gaussian mixture distributions in theory, but also is simple and efficient for implementation. Our experiments on multiple image datasets show that SMD significantly improves different types of diffusion models (e.g., DDPM), espeically in the situation of few backward iterations.
</details>
<details>
<summary>摘要</summary>
因为扩散模型在多种任务中表现出色，如图像生成等，所以有一些研究者在最近的工作中尝试证明（假设一些）这些模型具有强的近似能力。在这篇论文中，我们发现现有的扩散模型实际上在回卷降噪中存在表达力瓶颈，而现有的理论保证假设太强。基于这个发现，我们证明了扩散模型在本地和全局降噪中有无限大的错误。视我们的理论研究，我们引入了软组合降噪（SMD）模型，这是一种表达力强大且实用的回卷降噪模型。SMD不仅允许扩散模型在理论上能够很好地近似任何高斯混合分布，而且是实用的并简单的实现。我们在多个图像 dataset 上进行了实验，发现SMD可以大幅提高不同类型的扩散模型（如 DDPM），特别是在几个后向迭代中。
</details></li>
</ul>
<hr>
<h2 id="AsymFormer-Asymmetrical-Cross-Modal-Representation-Learning-for-Mobile-Platform-Real-Time-RGB-D-Semantic-Segmentation"><a href="#AsymFormer-Asymmetrical-Cross-Modal-Representation-Learning-for-Mobile-Platform-Real-Time-RGB-D-Semantic-Segmentation" class="headerlink" title="AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile Platform Real-Time RGB-D Semantic Segmentation"></a>AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile Platform Real-Time RGB-D Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14065">http://arxiv.org/abs/2309.14065</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Fourier7754/AsymFormer">https://github.com/Fourier7754/AsymFormer</a></li>
<li>paper_authors: Siqi Du, Weixi Wang, Renzhong Guo, Shengjun Tang</li>
<li>for: 实现RGB-D semantic segmentation的高效精准算法，以提高 робо类智能系统的可靠性和效率。</li>
<li>methods: 提出了一种新的非对称网络AsymFormer，通过优化计算资源分布和非对称背bone来实现多模态特征的有效融合。还利用了特征选择和多模态自相似特征EXTRACTION来提高网络精度，而无需增加参数数量，保证实时执行于机器人平台。</li>
<li>results: 在NYUv2和SUNRGBD datasets上进行了测试，AsymFormer与52.0% mIoU在NYUv2和49.1% mIoU在SUNRGBD达到了竞争性的结果。此外，AsymFormer在RTX3090上实现了79 FPS的推理速度，在混合精度量化后达到了65 FPS的推理速度。这些结果表明AsymFormer可以在RGB-D semantic segmentation中寻求高精度和高效率的平衡。<details>
<summary>Abstract</summary>
In the realm of robotic intelligence, achieving efficient and precise RGB-D semantic segmentation is a key cornerstone. State-of-the-art multimodal semantic segmentation methods, primarily rooted in symmetrical skeleton networks, find it challenging to harmonize computational efficiency and precision. In this work, we propose AsymFormer, a novel network for real-time RGB-D semantic segmentation, which targets the minimization of superfluous parameters by optimizing the distribution of computational resources and introduces an asymmetrical backbone to allow for the effective fusion of multimodal features. Furthermore, we explore techniques to bolster network accuracy by redefining feature selection and extracting multi-modal self-similarity features without a substantial increase in the parameter count, thereby ensuring real-time execution on robotic platforms. Additionally, a Local Attention-Guided Feature Selection (LAFS) module is used to selectively fuse features from different modalities by leveraging their dependencies. Subsequently, a Cross-Modal Attention-Guided Feature Correlation Embedding (CMA) module is introduced to further extract cross-modal representations. This method is evaluated on NYUv2 and SUNRGBD datasets, with AsymFormer demonstrating competitive results with 52.0% mIoU on NYUv2 and 49.1% mIoU on SUNRGBD. Notably, AsymFormer achieves an inference speed of 65 FPS and after implementing mixed precision quantization, it attains an impressive inference speed of 79 FPS on RTX3090. This significantly outperforms existing multi-modal methods, thereby demonstrating that AsymFormer can strike a balance between high accuracy and efficiency for RGB-D semantic segmentation.
</details>
<details>
<summary>摘要</summary>
在机器人智能领域，实现高效精准的 RGB-D semantic segmentation 是一个关键的核心。现有的多Modal semantic segmentation 方法，主要基于对称骨网络，很难实现计算效率和准确之间的平衡。在这个工作中，我们提出了 AsymFormer，一种新的网络，旨在最小化无用参数，通过分布计算资源的优化，并引入非对称脊梁，以有效地融合多Modal 特征。此外，我们还 explore 了提高网络准确性的技术，包括重新定义特征选择和提取多Modal 自相似特征，而无需增加参数数量，以确保实时执行于机器人平台。另外，我们还使用 Local Attention-Guided Feature Selection (LAFS) 模块， selecing 不同模式的特征，并使用 Cross-Modal Attention-Guided Feature Correlation Embedding (CMA) 模块，进一步提取交Modal 表示。这种方法在 NYUv2 和 SUNRGBD 数据集上进行评估，AsymFormer Displaying competitive results with 52.0% mIoU on NYUv2 and 49.1% mIoU on SUNRGBD。含义的是，AsymFormer 在实时执行中能够平衡高准确率和高效率，为 RGB-D semantic segmentation 提供了一个可靠的解决方案。
</details></li>
</ul>
<hr>
<h2 id="FeCAM-Exploiting-the-Heterogeneity-of-Class-Distributions-in-Exemplar-Free-Continual-Learning"><a href="#FeCAM-Exploiting-the-Heterogeneity-of-Class-Distributions-in-Exemplar-Free-Continual-Learning" class="headerlink" title="FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning"></a>FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14062">http://arxiv.org/abs/2309.14062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dipamgoswami/fecam">https://github.com/dipamgoswami/fecam</a></li>
<li>paper_authors: Dipam Goswami, Yuyang Liu, Bartłomiej Twardowski, Joost van de Weijer</li>
<li>for: 这篇研究探讨了类别增执行（Continual Learning）中的概念增执行（Class-Incremental Learning），尤其是在没有回溯的情况下，因为这会受到严重的遗传问题的影响。</li>
<li>methods: 这篇研究使用了 prototype 网络，它们生成了新的类别标本，并使用封锁的特征提取器来分类特征基于 Euclidian 距离。</li>
<li>results: 研究发现，在统计学上分布的分类是成功的，但是在学习非站势数据时，Euclidian 距离是不理想的，并且特征分布是多样的。因此，这篇研究提出了使用不规律 Mahalanobis 距离来解决这个挑战。此外，这篇研究还证明了模型特征相关性比之前的对应样本从正常分布中采样和训练线性分类器的方法更好。相比于现有的方法，这篇研究的方法可以在多个shot CIL 设定下进行普遍化，并且在领域增执行设定下也能够取得顶尖的结果。<details>
<summary>Abstract</summary>
Exemplar-free class-incremental learning (CIL) poses several challenges since it prohibits the rehearsal of data from previous tasks and thus suffers from catastrophic forgetting. Recent approaches to incrementally learning the classifier by freezing the feature extractor after the first task have gained much attention. In this paper, we explore prototypical networks for CIL, which generate new class prototypes using the frozen feature extractor and classify the features based on the Euclidean distance to the prototypes. In an analysis of the feature distributions of classes, we show that classification based on Euclidean metrics is successful for jointly trained features. However, when learning from non-stationary data, we observe that the Euclidean metric is suboptimal and that feature distributions are heterogeneous. To address this challenge, we revisit the anisotropic Mahalanobis distance for CIL. In addition, we empirically show that modeling the feature covariance relations is better than previous attempts at sampling features from normal distributions and training a linear classifier. Unlike existing methods, our approach generalizes to both many- and few-shot CIL settings, as well as to domain-incremental settings. Interestingly, without updating the backbone network, our method obtains state-of-the-art results on several standard continual learning benchmarks. Code is available at https://github.com/dipamgoswami/FeCAM.
</details>
<details>
<summary>摘要</summary>
例子空间自适应学习（CIL）具有一些挑战，因为它禁止在前一个任务中重新训练数据，从而导致忘记现象。最近的途径是通过冻结特征提取器来逐步学习类别器，这些途径在这篇论文中得到了广泛的关注。我们在这篇论文中探讨了示例网络，它们通过冻结特征提取器生成新的类 prototype，并基于Euclidean距离来类别特征。我们在类别分布分析中表明，基于Euclidean距离的分类是适用于共同训练的特征。然而，当学习非站点数据时，我们发现Euclidean距离是不优的，特征分布是不均匀的。为了解决这个挑战，我们再次考虑了不规则的Mahalanobis距离。此外，我们验证了模型特征 covariance 关系的模型化是比前一些尝试在normal分布上随机抽取特征并训练线性分类器更好。与现有方法不同的是，我们的方法可以在多少shot CIL设定下和领域增量学习设定下普遍适用，并且不需要更新后台网络，我们的方法在多个标准的不断学习标准benchmark上获得了状态机器人的结果。代码可以在https://github.com/dipamgoswami/FeCAM中找到。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Semantic-Segmentation-by-Knowledge-Graph-Inference"><a href="#Weakly-Supervised-Semantic-Segmentation-by-Knowledge-Graph-Inference" class="headerlink" title="Weakly Supervised Semantic Segmentation by Knowledge Graph Inference"></a>Weakly Supervised Semantic Segmentation by Knowledge Graph Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14057">http://arxiv.org/abs/2309.14057</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jia-zhang666/grm_layer">https://github.com/jia-zhang666/grm_layer</a></li>
<li>paper_authors: Jia Zhang, Bo Peng, Xi Wu</li>
<li>for: 提高弱监督semantic segmentation（WSSS）的性能，特别是在Convolutional Neural Networks（CNNs）上。</li>
<li>methods: 提出了一种基于图reasoning的方法，通过同时提高多类划分网络和 segmentation network的两个阶段，提高WSSS的整体性能。在多类划分网络阶段，外部知识被 интеGRATED，并与GCNs结合，以全局理解图像中的inter-class依赖关系。在 segmentation network阶段，提出了一种Graph Reasoning Mapping（GRM）模块，使用文本数据库来挖掘图像区域中的semantic coherence，以提高特征表示。</li>
<li>results: 使用图像级别的supervision，在PASCAL VOC 2012和MS-COCO datasets上实现了WSSS的状态oa-level性能。经验表明，提出的图reasoning方法有效地提高了WSSS的性能。<details>
<summary>Abstract</summary>
Currently, existing efforts in Weakly Supervised Semantic Segmentation (WSSS) based on Convolutional Neural Networks (CNNs) have predominantly focused on enhancing the multi-label classification network stage, with limited attention given to the equally important downstream segmentation network. Furthermore, CNN-based local convolutions lack the ability to model the extensive inter-category dependencies. Therefore, this paper introduces a graph reasoning-based approach to enhance WSSS. The aim is to improve WSSS holistically by simultaneously enhancing both the multi-label classification and segmentation network stages. In the multi-label classification network segment, external knowledge is integrated, coupled with GCNs, to globally reason about inter-class dependencies. This encourages the network to uncover features in non-salient regions of images, thereby refining the completeness of generated pseudo-labels. In the segmentation network segment, the proposed Graph Reasoning Mapping (GRM) module is employed to leverage knowledge obtained from textual databases, facilitating contextual reasoning for class representation within image regions. This GRM module enhances feature representation in high-level semantics of the segmentation network's local convolutions, while dynamically learning semantic coherence for individual samples. Using solely image-level supervision, we have achieved state-of-the-art performance in WSSS on the PASCAL VOC 2012 and MS-COCO datasets. Extensive experimentation on both the multi-label classification and segmentation network stages underscores the effectiveness of the proposed graph reasoning approach for advancing WSSS.
</details>
<details>
<summary>摘要</summary>
现有的弱监督Semantic Segmentation（WSSS）基于Convolutional Neural Networks（CNNs）的努力主要集中在增强多标签分类网络阶段，忽略了下游分类网络的 equally important 部分。此外，CNN-based 本地卷积缺乏模型图像中的广泛交互类关系。因此，本文提出了基于图 reasoning的方法，以提高 WSSS。目标是通过同时提高多标签分类和分类网络两个阶段来改进 WSSS。在多标签分类网络段，外部知识被集成，与GCNs相结合，以全局理解图像中的交互类关系。这使得网络可以在非关键区域找到特征，从而提高生成的 Pseudo-labels 的完整性。在分类网络段，我们提出的 Graph Reasoning Mapping（GRM）模块，使用文本数据库中的知识，以便在图像区域内进行 Contextual Reasoning 。这个 GRM 模块可以增强分类网络的高级 semantics 表示，同时动态学习个体样本的 semantic coherence。通过仅使用图像水平监督，我们在 PASCAL VOC 2012 和 MS-COCO 数据集上实现了 WSSS 的最新状态。广泛的实验表明，提出的图 reasoning 方法有效地提高 WSSS。
</details></li>
</ul>
<hr>
<h2 id="Single-Image-Test-Time-Adaptation-for-Segmentation"><a href="#Single-Image-Test-Time-Adaptation-for-Segmentation" class="headerlink" title="Single Image Test-Time Adaptation for Segmentation"></a>Single Image Test-Time Adaptation for Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14052">http://arxiv.org/abs/2309.14052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/klarajanouskova/SITTA-Segmentation">https://github.com/klarajanouskova/SITTA-Segmentation</a></li>
<li>paper_authors: Klara Janouskova, Tamir Shor, Chaim Baskin, Jiri Matas</li>
<li>for: 这项研究旨在提高深度神经网络对领域变化的Robustness，并在图像分类或分割任务上实现这一目标。</li>
<li>methods: 这项研究使用Test-Time Adaptation（TTA）方法，并且特点在于使用自动生成的mask来进行验证。</li>
<li>results: 研究发现，通过在测试时间使用自动生成的mask来优化自我超vised损失，可以提高图像分割模型的Robustness。在不同的条件下，这些改进可以提高模型的性能，相比之下，不使用这些改进，提高的性能仅为1.7%和2.16%。<details>
<summary>Abstract</summary>
Test-Time Adaptation (TTA) methods improve the robustness of deep neural networks to domain shift on a variety of tasks such as image classification or segmentation. This work explores adapting segmentation models to a single unlabelled image with no other data available at test-time. In particular, this work focuses on adaptation by optimizing self-supervised losses at test-time. Multiple baselines based on different principles are evaluated under diverse conditions and a novel adversarial training is introduced for adaptation with mask refinement. Our additions to the baselines result in a 3.51 and 3.28 % increase over non-adapted baselines, without these improvements, the increase would be 1.7 and 2.16 % only.
</details>
<details>
<summary>摘要</summary>
测试时适应（TTA）方法可以提高深度神经网络对频率差shift的Robustness在各种任务上，如图像分类或分割。这项工作探讨在没有其他数据可用的情况下，使用单个无标注图像进行适应。具体来说，这项工作关注在测试时优化自我指导损失来进行适应。我们评估了基于不同原则的多个基准，并引入了一种新的对适应进行干扰训练。我们的改进对基准而言，导致了3.51%和3.28%的提高，如果没有这些改进，则只有1.7%和2.16%的提高。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Fairness-Biases-in-Deep-Learning-Based-Brain-MRI-Reconstruction"><a href="#Unveiling-Fairness-Biases-in-Deep-Learning-Based-Brain-MRI-Reconstruction" class="headerlink" title="Unveiling Fairness Biases in Deep Learning-Based Brain MRI Reconstruction"></a>Unveiling Fairness Biases in Deep Learning-Based Brain MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14392">http://arxiv.org/abs/2309.14392</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ydu0117/reconfairness">https://github.com/ydu0117/reconfairness</a></li>
<li>paper_authors: Yuning Du, Yuyang Xue, Rohan Dharmakumar, Sotirios A. Tsaftaris</li>
<li>for: 这个研究旨在检查深度学习（DL）重建的脑磁共振成像中是否存在不公正性问题，以及如何通过不同的方法来解决这个问题。</li>
<li>methods: 这个研究使用的方法包括U-Net架构来重建图像，并对基eline Empirical Risk Minimisation（ERM）和重新均衡策略进行实现，以检测和解决不公正性问题。</li>
<li>results: 研究发现，DL重建模型存在男女和年龄 subgroup的性别偏见，但不是由数据不均衡和训练歧视引起的。这些发现可以帮助我们更好地理解深度学习图像重建中的不公正性问题，并为医疗AI应用中的公平性提供更多的参考。<details>
<summary>Abstract</summary>
Deep learning (DL) reconstruction particularly of MRI has led to improvements in image fidelity and reduction of acquisition time. In neuroimaging, DL methods can reconstruct high-quality images from undersampled data. However, it is essential to consider fairness in DL algorithms, particularly in terms of demographic characteristics. This study presents the first fairness analysis in a DL-based brain MRI reconstruction model. The model utilises the U-Net architecture for image reconstruction and explores the presence and sources of unfairness by implementing baseline Empirical Risk Minimisation (ERM) and rebalancing strategies. Model performance is evaluated using image reconstruction metrics. Our findings reveal statistically significant performance biases between the gender and age subgroups. Surprisingly, data imbalance and training discrimination are not the main sources of bias. This analysis provides insights of fairness in DL-based image reconstruction and aims to improve equity in medical AI applications.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）重建特别是MRI的场景下，已经导致图像准确性的提高和数据采样时间的减少。在神经成像中，DL方法可以从不充分的数据中重建高质量图像。然而，是必须考虑公平性在DL算法中，特别是在人口特征方面。本研究提供了首次DL基于脑MRI重建模型的公平分析。该模型采用U-Net架构 для图像重建，并实施基eline Empirical Risk Minimization（ERM）和重新填充策略来探讨不公正的存在和来源。模型的性能被评估使用图像重建指标。我们的发现表明男女和年龄子集之间存在 statistically significant的性能偏好。意外地，数据不均衡和训练歧视并不是主要的偏好来源。这种分析提供了DL基于图像重建中的公平性的视角，并旨在提高医疗AI应用中的公平性。
</details></li>
</ul>
<hr>
<h2 id="Hashing-Neural-Video-Decomposition-with-Multiplicative-Residuals-in-Space-Time"><a href="#Hashing-Neural-Video-Decomposition-with-Multiplicative-Residuals-in-Space-Time" class="headerlink" title="Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time"></a>Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14022">http://arxiv.org/abs/2309.14022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Hung Chan, Cheng-Yang Yuan, Cheng Sun, Hwann-Tzong Chen</li>
<li>for: 这个研究旨在提供一种基于层次编辑的视频分解方法，以便在视频中进行快速、高质量的编辑。</li>
<li>methods: 该方法使用神经网络模型将输入视频分解成多个层次表示，每个层包括一个2D текстура地图、原始视频的遮盾、和表示视频中的空间时间变化的乘法差异。该方法可以快速地在单个GPU上学习神经表示，并在实时渲染编辑结果。</li>
<li>results: 该方法可以在不同视频中生成高质量的编辑效果，并且可以在实时进行编辑。同时，该方法还提出了一种基于特征跟踪的评价指标，以对视频编辑效果进行 объектив评估。<details>
<summary>Abstract</summary>
We present a video decomposition method that facilitates layer-based editing of videos with spatiotemporally varying lighting and motion effects. Our neural model decomposes an input video into multiple layered representations, each comprising a 2D texture map, a mask for the original video, and a multiplicative residual characterizing the spatiotemporal variations in lighting conditions. A single edit on the texture maps can be propagated to the corresponding locations in the entire video frames while preserving other contents' consistencies. Our method efficiently learns the layer-based neural representations of a 1080p video in 25s per frame via coordinate hashing and allows real-time rendering of the edited result at 71 fps on a single GPU. Qualitatively, we run our method on various videos to show its effectiveness in generating high-quality editing effects. Quantitatively, we propose to adopt feature-tracking evaluation metrics for objectively assessing the consistency of video editing. Project page: https://lightbulb12294.github.io/hashing-nvd/
</details>
<details>
<summary>摘要</summary>
我们提出了一种视频分解方法，该方法使得可以对视频进行层次编辑，包括空间时间变化的灯光效果。我们的神经网络模型将输入视频分解成多个层次表示，每个层包括一个2D текстура地图、原始视频的遮盾和表示空间时间变化的乘法差异。通过修改Texture Maps可以在整个视频帧中快速传播修改，而保持其他内容的一致性。我们的方法可以快速学习视频层次神经表示，并在单个GPU上实现实时渲染修改后的结果，每帧25s。我们对多个视频进行了质量评估，并提出了一种基于特征跟踪的评价指标来客观评估视频编辑的一致性。项目页面：https://lightbulb12294.github.io/hashing-nvd/Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Variational-Inference-for-Scalable-3D-Object-centric-Learning"><a href="#Variational-Inference-for-Scalable-3D-Object-centric-Learning" class="headerlink" title="Variational Inference for Scalable 3D Object-centric Learning"></a>Variational Inference for Scalable 3D Object-centric Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14010">http://arxiv.org/abs/2309.14010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyu Wang, Kee Siong Ng, Miaomiao Liu</li>
<li>for: 学习3D场景中对象-центric的无监督表示学习，以适应更大的场景。</li>
<li>methods: 分别学习对象姿态和外观表示，并将对象表示升级到视图不变的形式，以保持对象身份。使用渐进变型推断过程可以处理顺序输入和在线更新对象热度分布。</li>
<li>results: 实验表明，我们提出的方法可以在synthetic和实际数据集上INFER和维护3D场景中对象-центric的表示，并比前一代模型表现更好。<details>
<summary>Abstract</summary>
We tackle the task of scalable unsupervised object-centric representation learning on 3D scenes. Existing approaches to object-centric representation learning show limitations in generalizing to larger scenes as their learning processes rely on a fixed global coordinate system. In contrast, we propose to learn view-invariant 3D object representations in localized object coordinate systems. To this end, we estimate the object pose and appearance representation separately and explicitly map object representations across views while maintaining object identities. We adopt an amortized variational inference pipeline that can process sequential input and scalably update object latent distributions online. To handle large-scale scenes with a varying number of objects, we further introduce a Cognitive Map that allows the registration and query of objects on a per-scene global map to achieve scalable representation learning. We explore the object-centric neural radiance field (NeRF) as our 3D scene representation, which is jointly modeled within our unsupervised object-centric learning framework. Experimental results on synthetic and real datasets show that our proposed method can infer and maintain object-centric representations of 3D scenes and outperforms previous models.
</details>
<details>
<summary>摘要</summary>
我们面临三维场景上可扩展无监督物体中心表示学习的挑战。现有的物体中心表示学习方法在扩大到更大的场景时存在限制，因为它们的学习过程基于固定的全球坐标系。与此相反，我们提议通过分离出视图不变的3D物体表示和维护物体标识来学习视图不变的3D物体表示。我们采用了一个缓存梯度推导管道，可以处理顺序输入并在线更新物体热度分布。为了处理大规模场景中的变化数量物体，我们还引入了认知地图，允许在每个场景全球地图上注册和查询物体，以实现可扩展的表示学习。我们采用物体中心场景灯光场（NeRF）作为我们的三维场景表示，并将其与我们的无监督物体中心学习框架集成。实验结果表明，我们的提议方法可以推断和维护三维场景中的物体中心表示，并在现实数据集上超越先前的模型。
</details></li>
</ul>
<hr>
<h2 id="Better-Generalization-of-White-Matter-Tract-Segmentation-to-Arbitrary-Datasets-with-Scaled-Residual-Bootstrap"><a href="#Better-Generalization-of-White-Matter-Tract-Segmentation-to-Arbitrary-Datasets-with-Scaled-Residual-Bootstrap" class="headerlink" title="Better Generalization of White Matter Tract Segmentation to Arbitrary Datasets with Scaled Residual Bootstrap"></a>Better Generalization of White Matter Tract Segmentation to Arbitrary Datasets with Scaled Residual Bootstrap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13980">http://arxiv.org/abs/2309.13980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wan Liu, Chuyang Ye</li>
<li>for: 提高 diffusion magnetic resonance imaging（dMRI）white matter（WM）轨迹分割的泛化性能。</li>
<li>methods: 使用降噪 bootstrap 缩放策略对培oki数据进行增强，以适应不同测试数据集的分布误差。</li>
<li>results: 对两个 dMRI 数据集进行实验，结果表明，提出的方法可以在不同的设置下提高 WM 轨迹分割的泛化性能。<details>
<summary>Abstract</summary>
White matter (WM) tract segmentation is a crucial step for brain connectivity studies. It is performed on diffusion magnetic resonance imaging (dMRI), and deep neural networks (DNNs) have achieved promising segmentation accuracy. Existing DNN-based methods use an annotated dataset for model training. However, the performance of the trained model on a different test dataset may not be optimal due to distribution shift, and it is desirable to design WM tract segmentation approaches that allow better generalization of the segmentation model to arbitrary test datasets. In this work, we propose a WM tract segmentation approach that improves the generalization with scaled residual bootstrap. The difference between dMRI scans in training and test datasets is most noticeably caused by the different numbers of diffusion gradients and noise levels. Since both of them lead to different signal-to-noise ratios (SNRs) between the training and test data, we propose to augment the training scans by adjusting the noise magnitude and develop an adapted residual bootstrap strategy for the augmentation. To validate the proposed approach, two dMRI datasets were used, and the experimental results show that our method consistently improved the generalization of WM tract segmentation under various settings.
</details>
<details>
<summary>摘要</summary>
白 matter（WM）轨迹分 segmentation 是脑连接研究的关键步骤。它通过 diffusion magnetic resonance imaging（dMRI）进行，并使用深度神经网络（DNNs）获得了有前途的分 segmentation 精度。现有的 DNN-based 方法通常使用标注数据集进行模型训练。然而，训练模型在不同的测试数据集上的性能可能不是最佳，因为分布转移，而且您想要设计 WM tract segmentation 方法，可以更好地将分 segmentation 模型应用于任何测试数据集。在这项工作中，我们提出了一种 WM tract segmentation 方法，可以提高分 segmentation 模型的泛化性。我们通过扩大 residual bootstrap 来实现这一点。测试和训练数据集之间的主要差异在于增强和噪声水平的不同，这两个因素都会导致测试和训练数据集之间的信号噪声比（SNR）的不同。因此，我们提议在训练数据集上进行噪声调整，并开发了适应的 residual bootstrap 策略。为验证我们的方法，我们使用了两个 dMRI 数据集，并实验结果表明，我们的方法可以在不同的设置下提高 WM tract segmentation 的泛化性。
</details></li>
</ul>
<hr>
<h2 id="Diverse-Semantic-Image-Editing-with-Style-Codes"><a href="#Diverse-Semantic-Image-Editing-with-Style-Codes" class="headerlink" title="Diverse Semantic Image Editing with Style Codes"></a>Diverse Semantic Image Editing with Style Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13975">http://arxiv.org/abs/2309.13975</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hakansivuk/divsem">https://github.com/hakansivuk/divsem</a></li>
<li>paper_authors: Hakan Sivuk, Aysegul Dundar<br>for: 这个论文的目的是提出一种基于semantic map的Semantic Image Editing方法，可以填充杀死图像中的 pixels，同时保持图像的内在逻辑和外在逻辑的一致性。methods: 该方法使用了一种新的Style Encoding机制，可以区分可见和部分可见对象的风格编码，从而提高了图像的一致性和多样性。results: 对比之前的条件图像生成和Semantic Image Editing算法，该方法在评价指标上具有显著的改进，并且可以提供更多的多样化结果。<details>
<summary>Abstract</summary>
Semantic image editing requires inpainting pixels following a semantic map. It is a challenging task since this inpainting requires both harmony with the context and strict compliance with the semantic maps. The majority of the previous methods proposed for this task try to encode the whole information from erased images. However, when an object is added to a scene such as a car, its style cannot be encoded from the context alone. On the other hand, the models that can output diverse generations struggle to output images that have seamless boundaries between the generated and unerased parts. Additionally, previous methods do not have a mechanism to encode the styles of visible and partially visible objects differently for better performance. In this work, we propose a framework that can encode visible and partially visible objects with a novel mechanism to achieve consistency in the style encoding and final generations. We extensively compare with previous conditional image generation and semantic image editing algorithms. Our extensive experiments show that our method significantly improves over the state-of-the-art. Our method not only achieves better quantitative results but also provides diverse results. Please refer to the project web page for the released code and demo: https://github.com/hakansivuk/DivSem.
</details>
<details>
<summary>摘要</summary>
semantic image editing 需要根据semantic map进行像素填充。这是一项复杂的任务，因为这种填充需要与上下文相协调，并且必须严格遵循semantic map。大多数之前的方法都尝试从抹除图像中提取整个信息。然而，当一个 objet 如车加入场景时，其样式不能从上下文中提取。相反，模型们可以输出多个生成物，但是这些生成物往往与不抹除部分之间没有滑块。此外，之前的方法没有机制来对可见和部分可见对象的样式进行不同的编码，以提高性能。在这种情况下，我们提出了一个框架，可以对可见和部分可见对象进行novel机制来实现样式编码的一致性和最终生成的一致性。我们与前期的条件图像生成和semantic image editing算法进行了广泛的比较。我们的广泛实验表明，我们的方法在状态前的性能上显著提高。我们不仅获得了更好的量化结果，还提供了更多的多样性。请参考项目网页获取代码和示例：https://github.com/hakansivuk/DivSem。
</details></li>
</ul>
<hr>
<h2 id="Egocentric-RGB-Depth-Action-Recognition-in-Industry-Like-Settings"><a href="#Egocentric-RGB-Depth-Action-Recognition-in-Industry-Like-Settings" class="headerlink" title="Egocentric RGB+Depth Action Recognition in Industry-Like Settings"></a>Egocentric RGB+Depth Action Recognition in Industry-Like Settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13962">http://arxiv.org/abs/2309.13962</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jkini/Meccano">https://github.com/jkini/Meccano</a></li>
<li>paper_authors: Jyoti Kini, Sarah Fleischer, Ishan Dave, Mubarak Shah</li>
<li>for: 本研究旨在提高 egocentric 视角下的人机交互行为识别率，通过利用RGB和深度模式。</li>
<li>methods: 我们采用3D Video SWIN Transformer来有效地编码RGB和深度模式，并提出了一种基于exponentially decaying variant of the focal loss modulating factor的训练策略，以及late fusion来结合两种模式的预测结果。</li>
<li>results: 我们在MECCANO dataset上进行了广泛的评估，并在多模式人体动作识别挑战中获得了优秀成绩，其中包括在ICIAP 2023 多模式人体动作识别比赛中获得第一名。<details>
<summary>Abstract</summary>
Action recognition from an egocentric viewpoint is a crucial perception task in robotics and enables a wide range of human-robot interactions. While most computer vision approaches prioritize the RGB camera, the Depth modality - which can further amplify the subtleties of actions from an egocentric perspective - remains underexplored. Our work focuses on recognizing actions from egocentric RGB and Depth modalities in an industry-like environment. To study this problem, we consider the recent MECCANO dataset, which provides a wide range of assembling actions. Our framework is based on the 3D Video SWIN Transformer to encode both RGB and Depth modalities effectively. To address the inherent skewness in real-world multimodal action occurrences, we propose a training strategy using an exponentially decaying variant of the focal loss modulating factor. Additionally, to leverage the information in both RGB and Depth modalities, we opt for late fusion to combine the predictions from each modality. We thoroughly evaluate our method on the action recognition task of the MECCANO dataset, and it significantly outperforms the prior work. Notably, our method also secured first place at the multimodal action recognition challenge at ICIAP 2023.
</details>
<details>
<summary>摘要</summary>
egocentric 视角下的行为识别是机器人学中的一项重要感知任务，它允许机器人与人类进行广泛的互动。而大多数计算机视觉方法强调RGB摄像头，但深度modalidad - 可以进一步强调 egocentric 视角下的动作细节 - 仍然未得到充分的利用。我们的工作是 Egocentric RGB 和深度modalities 上的动作识别在行业环境中进行研究。为了研究这个问题，我们使用了最近的MECCANO dataset，该集合提供了许多精心搭建的动作。我们的框架基于3D Video SWIN Transformer来有效地编码RGB和深度modalities。为了解决实际世界中多Modal 动作的自然偏见，我们提出了一种使用加速式衰减的焦点损失模块化因子来进行训练策略。此外，我们选择了将RGB和深度modalities 的预测结果进行融合，以利用每个模式中的信息。我们对MECCANO dataset上的动作识别任务进行了严格的评估，并证明了我们的方法在此任务上明显超越了先前的工作。值得注意的是，我们的方法还在ICIAP 2023 多模态动作识别挑战中获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="In-Domain-GAN-Inversion-for-Faithful-Reconstruction-and-Editability"><a href="#In-Domain-GAN-Inversion-for-Faithful-Reconstruction-and-Editability" class="headerlink" title="In-Domain GAN Inversion for Faithful Reconstruction and Editability"></a>In-Domain GAN Inversion for Faithful Reconstruction and Editability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13956">http://arxiv.org/abs/2309.13956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiapeng Zhu, Yujun Shen, Yinghao Xu, Deli Zhao, Qifeng Chen, Bolei Zhou</li>
<li>for: 这篇论文的目的是提出一种内部类型对应（In-Domain GAN Inversion），将已经预训的GAN模型中的内存空间对应到原始影像，以便实现各种影像修改应用程序，无需重新训练。</li>
<li>methods: 这篇论文使用了域导向encoder和域调整优化器，将内存空间对应到原始影像，并进行了广泛的分析，包括预测器结构、起始对应点和对应参数空间的影响，以探索修改性和重建质量之间的贡献。</li>
<li>results: 这篇论文发现，内部类型对应可以将GAN模型中学习的知识应用到实际的影像修改上，并且可以让GAN模型在不需要重新训练的情况下，实现各种影像修改应用程序。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) have significantly advanced image synthesis through mapping randomly sampled latent codes to high-fidelity synthesized images. However, applying well-trained GANs to real image editing remains challenging. A common solution is to find an approximate latent code that can adequately recover the input image to edit, which is also known as GAN inversion. To invert a GAN model, prior works typically focus on reconstructing the target image at the pixel level, yet few studies are conducted on whether the inverted result can well support manipulation at the semantic level. This work fills in this gap by proposing in-domain GAN inversion, which consists of a domain-guided encoder and a domain-regularized optimizer, to regularize the inverted code in the native latent space of the pre-trained GAN model. In this way, we manage to sufficiently reuse the knowledge learned by GANs for image reconstruction, facilitating a wide range of editing applications without any retraining. We further make comprehensive analyses on the effects of the encoder structure, the starting inversion point, as well as the inversion parameter space, and observe the trade-off between the reconstruction quality and the editing property. Such a trade-off sheds light on how a GAN model represents an image with various semantics encoded in the learned latent distribution. Code, models, and demo are available at the project page: https://genforce.github.io/idinvert/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Speed-Co-Augmentation-for-Unsupervised-Audio-Visual-Pre-training"><a href="#Speed-Co-Augmentation-for-Unsupervised-Audio-Visual-Pre-training" class="headerlink" title="Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training"></a>Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13942">http://arxiv.org/abs/2309.13942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangliu Wang, Jianbo Jiao, Yibing Song, Stephen James, Zhan Tong, Chongjian Ge, Pieter Abbeel, Yun-hui Liu</li>
<li>for: 本研究旨在提高无监督音视频预训练。</li>
<li>methods: 我们提议一种新的速度协调增强方法，该方法随机改变音频和视频数据的播放速率。</li>
<li>results: 实验结果表明，我们提议的方法可以明显提高学习的表示。<details>
<summary>Abstract</summary>
This work aims to improve unsupervised audio-visual pre-training. Inspired by the efficacy of data augmentation in visual contrastive learning, we propose a novel speed co-augmentation method that randomly changes the playback speeds of both audio and video data. Despite its simplicity, the speed co-augmentation method possesses two compelling attributes: (1) it increases the diversity of audio-visual pairs and doubles the size of negative pairs, resulting in a significant enhancement in the learned representations, and (2) it changes the strict correlation between audio-visual pairs but introduces a partial relationship between the augmented pairs, which is modeled by our proposed SoftInfoNCE loss to further boost the performance. Experimental results show that the proposed method significantly improves the learned representations when compared to vanilla audio-visual contrastive learning.
</details>
<details>
<summary>摘要</summary>
这项工作目的是提高无监督音视频预训练。受到视觉对冲学习的数据扩充效果启发，我们提议一种新的速度合并方法，该方法随机改变音频和视频数据的播放速度。尽管简单，这种速度合并方法具有两个吸引人的特点：（1）它增加了音视频对的多样性，同时将负对的数据量增加一倍，从而对学习的表示进行了显著提升，和（2）它改变了音视频对的紧密相关性，但是引入了增强对的关系，这种关系由我们提议的SoftInfoNCE损失函数来模型，以进一步提高表示的性能。实验结果表明，我们的方法在无监督音视频对比学习中显著提高了学习的表示。
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Recurrent-Grouping-Attention-Network-for-Video-Super-Resolution"><a href="#A-Lightweight-Recurrent-Grouping-Attention-Network-for-Video-Super-Resolution" class="headerlink" title="A Lightweight Recurrent Grouping Attention Network for Video Super-Resolution"></a>A Lightweight Recurrent Grouping Attention Network for Video Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13940">http://arxiv.org/abs/2309.13940</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karlygzhu/rgan">https://github.com/karlygzhu/rgan</a></li>
<li>paper_authors: Yonggui Zhu, Guofang Li</li>
<li>for: 提高视频超分解（VSR）模型的效率和可扩展性。</li>
<li>methods: 提出了一种轻量级循环分组注意力网络，利用前向特征提取模块和后向特征提取模块从两个方向收集时间信息，并提出了一种新的分组机制以高效地收集参照帧和其邻域帧的空间时间信息。</li>
<li>results: 实验表明，我们的模型在多个数据集上达到了当今主流模型的最佳性能。<details>
<summary>Abstract</summary>
Effective aggregation of temporal information of consecutive frames is the core of achieving video super-resolution. Many scholars have utilized structures such as sliding windows and recurrent to gather spatio-temporal information of frames. However, although the performance of the constructed VSR models is improving, the size of the models is also increasing, exacerbating the demand on the equipment. Thus, to reduce the stress on the device, we propose a novel lightweight recurrent grouping attention network. The parameters of this model are only 0.878M, which is much lower than the current mainstream model for studying video super-resolution. We design forward feature extraction module and backward feature extraction module to collect temporal information between consecutive frames from two directions. Moreover, a new grouping mechanism is proposed to efficiently collect spatio-temporal information of the reference frame and its neighboring frames. The attention supplementation module is presented to further enhance the information gathering range of the model. The feature reconstruction module aims to aggregate information from different directions to reconstruct high-resolution features. Experiments demonstrate that our model achieves state-of-the-art performance on multiple datasets.
</details>
<details>
<summary>摘要</summary>
“有效地聚合 consecutiverame 的时间信息是视频超分辨的核心。许多学者们使用 slide window 和 recurrent 结构收集 frame 的空间时间信息。although the constructed VSR models are improving, the size of the models is also increasing, exacerbating the demand on the equipment. Therefore, to reduce the stress on the device, we propose a novel lightweight recurrent grouping attention network. The parameters of this model are only 0.878M, which is much lower than the current mainstream model for studying video super-resolution.我们设计了 forward feature extraction module 和 backward feature extraction module，用于从两个方向收集 consecutive frames 的时间信息。此外，我们还提出了一种新的 grouping mechanism，用于高效地收集 reference frame 和其邻近 frame 的空间时间信息。另外，我们还提出了一种 attention supplementation module，用于进一步增强模型的信息收集范围。最后，我们设计了一个 feature reconstruction module，用于将信息从不同的方向聚合到高分辨特征上。实验表明，我们的模型在多个 dataset 上达到了状态监测性能。”
</details></li>
</ul>
<hr>
<h2 id="Recursive-Counterfactual-Deconfounding-for-Object-Recognition"><a href="#Recursive-Counterfactual-Deconfounding-for-Object-Recognition" class="headerlink" title="Recursive Counterfactual Deconfounding for Object Recognition"></a>Recursive Counterfactual Deconfounding for Object Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13924">http://arxiv.org/abs/2309.13924</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayin Sun, Hong Wang, Qiulei Dong</li>
<li>for: 提高图像识别 tasks 的准确率和泛化能力，特别是对于闭SET和开SET scenario。</li>
<li>methods: 基于counterfactual分析的Recursive Counterfactual Deconfounding（RCD）模型，包括对图像特征、模型预测和干扰因素之间的关系建立和更新。</li>
<li>results: 在closed-set和open-set scenario的识别任务中，提出的RCD模型与11个基eline模型相比，在大多数情况下表现出色，并且可以进一步提高图像识别的准确率和泛化能力。<details>
<summary>Abstract</summary>
Image recognition is a classic and common task in the computer vision field, which has been widely applied in the past decade. Most existing methods in literature aim to learn discriminative features from labeled images for classification, however, they generally neglect confounders that infiltrate into the learned features, resulting in low performances for discriminating test images. To address this problem, we propose a Recursive Counterfactual Deconfounding model for object recognition in both closed-set and open-set scenarios based on counterfactual analysis, called RCD. The proposed model consists of a factual graph and a counterfactual graph, where the relationships among image features, model predictions, and confounders are built and updated recursively for learning more discriminative features. It performs in a recursive manner so that subtler counterfactual features could be learned and eliminated progressively, and both the discriminability and generalization of the proposed model could be improved accordingly. In addition, a negative correlation constraint is designed for alleviating the negative effects of the counterfactual features further at the model training stage. Extensive experimental results on both closed-set recognition task and open-set recognition task demonstrate that the proposed RCD model performs better than 11 state-of-the-art baselines significantly in most cases.
</details>
<details>
<summary>摘要</summary>
RCD 模型包括一个事实图和一个对事实图的对照图，其中包含了图像特征、模型预测和干扰因素之间的关系，通过 recursively 更新和学习更加细致的特征，以提高模型的抗混淆性和泛化能力。此外，为了进一步缓解对对照特征的负面影响，我们在模型训练阶段设计了一种负 correlated 约束。在 closed-set 识别任务和 open-set 识别任务中，我们进行了广泛的实验，结果显示，相比于 11 个基eline，RCD 模型在大多数情况下能够显著提高对象识别的性能。
</details></li>
</ul>
<hr>
<h2 id="Subspace-Aware-Feature-Reconstruction-for-Unsupervised-Anomaly-Localization"><a href="#Subspace-Aware-Feature-Reconstruction-for-Unsupervised-Anomaly-Localization" class="headerlink" title="Subspace-Aware Feature Reconstruction for Unsupervised Anomaly Localization"></a>Subspace-Aware Feature Reconstruction for Unsupervised Anomaly Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13904">http://arxiv.org/abs/2309.13904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katsuya Hotta, Chao Zhang, Yoshihiro Hagihara, Takuya Akashi</li>
<li>for: 这篇论文旨在提出一个新的 anomaly localization 方法，实现适应 feature approximation。</li>
<li>methods: 方法基于 self-expressive model，learn low-dimensional subspaces，并通过这些 subspaces 重建 feature representation。</li>
<li>results: 实验结果显示，这篇论文的方法可以与现有的 state-of-the-art 方法相比，实现适应 feature approximation，并且只需要少量的 samples。<details>
<summary>Abstract</summary>
Unsupervised anomaly localization, which plays a critical role in industrial manufacturing, is to identify anomalous regions that deviate from patterns established exclusively from nominal samples. Recent mainstream methods focus on approximating the target feature distribution by leveraging embeddings from ImageNet models. However, a common issue in many anomaly localization methods is the lack of adaptability of the feature approximations to specific targets. Consequently, their ability to effectively identify anomalous regions relies significantly on the data coverage provided by the finite resources in a memory bank. In this paper, we propose a novel subspace-aware feature reconstruction framework for anomaly localization. To achieve adaptive feature approximation, our proposed method involves the reconstruction of the feature representation through the self-expressive model designed to learn low-dimensional subspaces. Importantly, the sparsity of the subspace representation contributes to covering feature patterns from the same subspace with fewer resources, leading to a reduction in the memory bank. Extensive experiments across three industrial benchmark datasets demonstrate that our approach achieves competitive anomaly localization performance compared to state-of-the-art methods by adaptively reconstructing target features with a small number of samples.
</details>
<details>
<summary>摘要</summary>
不监督异常定位，在工业生产中扮演关键的角色，是要将异常区域与基于nominal样本所建立的模式进行比较。现今主流方法通常是通过利用ImageNet模型生成的嵌入来近似目标特征分布。然而，许多异常定位方法中的共同问题是特征近似的灵活性不够，这使得它们在特定目标上效果地识别异常区域的能力受到数据库中的finite资源的限制。在本文中，我们提出了一种新的子空间意识激发特征重建框架，用于异常定位。我们的提议方法包括通过自我表达模型学习低维度子空间，以达到适应性的特征近似。重要的是，子空间表示的稀疏性使得从同一个子空间中覆盖特征模式需要 fewer 资源，从而降低数据库。我们在三个工业标准 datasets上进行了广泛的实验，结果表明，我们的方法可以与当前状态OF-the-art方法竞争地实现异常定位，只需要一小数量的样本。
</details></li>
</ul>
<hr>
<h2 id="Bitstream-Corrupted-Video-Recovery-A-Novel-Benchmark-Dataset-and-Method"><a href="#Bitstream-Corrupted-Video-Recovery-A-Novel-Benchmark-Dataset-and-Method" class="headerlink" title="Bitstream-Corrupted Video Recovery: A Novel Benchmark Dataset and Method"></a>Bitstream-Corrupted Video Recovery: A Novel Benchmark Dataset and Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13890">http://arxiv.org/abs/2309.13890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liutighe/bscv-dataset">https://github.com/liutighe/bscv-dataset</a></li>
<li>paper_authors: Tianyi Liu, Kejun Wu, Yi Wang, Wenyang Liu, Kim-Hui Yap, Lap-Pui Chau</li>
<li>for: 提供了一个大规模的bitstream-corrupted video（BSCV）benchmark，用于解决实世界中的视频损坏问题。</li>
<li>methods: 使用了一个三个参数的视频损坏模型，并提供了一个可替换的video recovery框架，用于评估现有的视频填写方法。</li>
<li>results: 透过评估现有的视频填写方法，发现了这些方法在解决实世界中的视频损坏问题上的限制，并证明了我们的框架在解决这个问题上的优势。<details>
<summary>Abstract</summary>
The past decade has witnessed great strides in video recovery by specialist technologies, like video inpainting, completion, and error concealment. However, they typically simulate the missing content by manual-designed error masks, thus failing to fill in the realistic video loss in video communication (e.g., telepresence, live streaming, and internet video) and multimedia forensics. To address this, we introduce the bitstream-corrupted video (BSCV) benchmark, the first benchmark dataset with more than 28,000 video clips, which can be used for bitstream-corrupted video recovery in the real world. The BSCV is a collection of 1) a proposed three-parameter corruption model for video bitstream, 2) a large-scale dataset containing rich error patterns, multiple corruption levels, and flexible dataset branches, and 3) a plug-and-play module in video recovery framework that serves as a benchmark. We evaluate state-of-the-art video inpainting methods on the BSCV dataset, demonstrating existing approaches' limitations and our framework's advantages in solving the bitstream-corrupted video recovery problem. The benchmark and dataset are released at https://github.com/LIUTIGHE/BSCV-Dataset.
</details>
<details>
<summary>摘要</summary>
过去一代，视频恢复技术得到了大幅度的进步，如视频填充、完善和错误隐藏。然而，这些技术通常通过手动设计的错误面积来模拟缺失内容，因此无法填充实际的视频损害在视频通信（如电子投票、直播和互联网视频）和多媒体证明中。为解决这一问题，我们介绍了 bitstream-corrupted video（BSCV） benchmark，这是世界上第一个以上28,000个视频剪辑为基础的损害视频恢复 benchmark。BSCV包括以下三个组成部分：1）一种提议的三参数损害模型 для视频比特流；2）一个大规模的数据集，包含丰富的错误特征、多个损害水平和灵活的数据支线；3）一个在视频恢复框架中的插件模块，作为 benchmark。我们对现有视频填充方法进行了BSCV dataset上的评估，并证明了我们的框架在解决损害视频恢复问题中的优势。BSCV dataset和 benchmark将于https://github.com/LIUTIGHE/BSCV-Dataset上发布。
</details></li>
</ul>
<hr>
<h2 id="Skip-Connected-Neural-Networks-with-Layout-Graphs-for-Floor-Plan-Auto-Generation"><a href="#Skip-Connected-Neural-Networks-with-Layout-Graphs-for-Floor-Plan-Auto-Generation" class="headerlink" title="Skip-Connected Neural Networks with Layout Graphs for Floor Plan Auto-Generation"></a>Skip-Connected Neural Networks with Layout Graphs for Floor Plan Auto-Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13881">http://arxiv.org/abs/2309.13881</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuntaeJ/SkipNet-FloorPlanGen">https://github.com/yuntaeJ/SkipNet-FloorPlanGen</a></li>
<li>paper_authors: Yuntae Jeon, Dai Quoc Tran, Seunghee Park</li>
<li>for: automated and efficient floor plan designs</li>
<li>methods: skip-connected neural networks integrated with layout graphs</li>
<li>results: 93.9 mIoU score in the 1st CVAAD workshop challenge<details>
<summary>Abstract</summary>
With the advent of AI and computer vision techniques, the quest for automated and efficient floor plan designs has gained momentum. This paper presents a novel approach using skip-connected neural networks integrated with layout graphs. The skip-connected layers capture multi-scale floor plan information, and the encoder-decoder networks with GNN facilitate pixel-level probability-based generation. Validated on the MSD dataset, our approach achieved a 93.9 mIoU score in the 1st CVAAD workshop challenge. Code and pre-trained models are publicly available at https://github.com/yuntaeJ/SkipNet-FloorPlanGe.
</details>
<details>
<summary>摘要</summary>
With the advent of AI and computer vision techniques, the quest for automated and efficient floor plan designs has gained momentum. This paper presents a novel approach using skip-connected neural networks integrated with layout graphs. The skip-connected layers capture multi-scale floor plan information, and the encoder-decoder networks with GNN facilitate pixel-level probability-based generation. Validated on the MSD dataset, our approach achieved a 93.9 mIoU score in the 1st CVAAD workshop challenge. Code and pre-trained models are publicly available at https://github.com/yuntaeJ/SkipNet-FloorPlanGe.Here's the translation in Traditional Chinese:随着人工智能和计算机见识技术的发展，自动化和高效的地图设计问题得到了很多关注。这篇论文提出了一种使用跳接连接神经网络与格局图Integrated的新方法。跳接层 capture多値标高图信息，并且与对应的encoder-decoder网络和GNN结合，实现像素级概率基于生成。在MSD dataset上验证，我们的方法实现了93.9 mIoU分数在1st CVAAD工作坊挑战中。代码和预训模型公开可以在https://github.com/yuntaeJ/SkipNet-FloorPlanGe中找到。
</details></li>
</ul>
<hr>
<h2 id="Attention-and-Pooling-based-Sigmoid-Colon-Segmentation-in-3D-CT-images"><a href="#Attention-and-Pooling-based-Sigmoid-Colon-Segmentation-in-3D-CT-images" class="headerlink" title="Attention and Pooling based Sigmoid Colon Segmentation in 3D CT images"></a>Attention and Pooling based Sigmoid Colon Segmentation in 3D CT images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13872">http://arxiv.org/abs/2309.13872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Akizur Rahman, Sonit Singh, Kuruparan Shanmugalingam, Sankaran Iyer, Alan Blair, Praveen Ravindran, Arcot Sowmya</li>
<li>for: 该研究旨在开发一种基于修改的3D U-Net体系结构的深度学习模型，用于从计算机 Tomography（CT）图像中 segments the sigmoid colon。</li>
<li>methods: 该研究使用了Pyramid pooling（PyP）和通道空间压缩和刺激（csSE）等技术来改进模型性能。</li>
<li>results: 结果表明，使用PyP和csSE技术可以提高分割精度，并且 ensemble方法可以提高分割精度。最终，该研究结果表明，基于修改的3D U-Net体系结构是有效的用于 segments the sigmoid colon在CT图像中。<details>
<summary>Abstract</summary>
Segmentation of the sigmoid colon is a crucial aspect of treating diverticulitis. It enables accurate identification and localisation of inflammation, which in turn helps healthcare professionals make informed decisions about the most appropriate treatment options. This research presents a novel deep learning architecture for segmenting the sigmoid colon from Computed Tomography (CT) images using a modified 3D U-Net architecture. Several variations of the 3D U-Net model with modified hyper-parameters were examined in this study. Pyramid pooling (PyP) and channel-spatial Squeeze and Excitation (csSE) were also used to improve the model performance. The networks were trained using manually annotated sigmoid colon. A five-fold cross-validation procedure was used on a test dataset to evaluate the network's performance. As indicated by the maximum Dice similarity coefficient (DSC) of 56.92+/-1.42%, the application of PyP and csSE techniques improves segmentation precision. We explored ensemble methods including averaging, weighted averaging, majority voting, and max ensemble. The results show that average and majority voting approaches with a threshold value of 0.5 and consistent weight distribution among the top three models produced comparable and optimal results with DSC of 88.11+/-3.52%. The results indicate that the application of a modified 3D U-Net architecture is effective for segmenting the sigmoid colon in Computed Tomography (CT) images. In addition, the study highlights the potential benefits of integrating ensemble methods to improve segmentation precision.
</details>
<details>
<summary>摘要</summary>
Segmentation of the sigmoid colon is a crucial aspect of treating diverticulitis. It enables accurate identification and localization of inflammation, which in turn helps healthcare professionals make informed decisions about the most appropriate treatment options. This research presents a novel deep learning architecture for segmenting the sigmoid colon from Computed Tomography (CT) images using a modified 3D U-Net architecture. Several variations of the 3D U-Net model with modified hyper-parameters were examined in this study. Pyramid pooling (PyP) and channel-spatial Squeeze and Excitation (csSE) were also used to improve the model performance. The networks were trained using manually annotated sigmoid colon. A five-fold cross-validation procedure was used on a test dataset to evaluate the network's performance. As indicated by the maximum Dice similarity coefficient (DSC) of 56.92+/-1.42%, the application of PyP and csSE techniques improves segmentation precision. We explored ensemble methods including averaging, weighted averaging, majority voting, and max ensemble. The results show that average and majority voting approaches with a threshold value of 0.5 and consistent weight distribution among the top three models produced comparable and optimal results with DSC of 88.11+/-3.52%. The results indicate that the application of a modified 3D U-Net architecture is effective for segmenting the sigmoid colon in Computed Tomography (CT) images. In addition, the study highlights the potential benefits of integrating ensemble methods to improve segmentation precision.Here's the text in Traditional Chinese:分 segmentation of the sigmoid colon 是 diverticulitis 的一个重要方面，可以精确地识别和localization of inflammation，从而帮助医疗专业人员做出最适当的治疗选择。本研究提出了一个基于 modified 3D U-Net 架构的深度学习模型，用于 Computed Tomography (CT) 影像中的sigmoid colon 分 segmentation。本研究中评估了多种 modified 3D U-Net 模型的不同参数，并使用 Pyramid pooling (PyP) 和 channel-spatial Squeeze and Excitation (csSE) 技术来改善模型性能。模型被训练使用手动标注的sigmoid colon。使用五fold cross-validation 方法进行评估，结果显示，使用 PyP 和 csSE 技术可以提高分 segmentation 精度。我们explored ensemble methods，包括 averaging、weighted averaging、majority voting 和 max ensemble，并发现，使用average 和 majority voting 方法，并设置阈值为 0.5，可以获得最佳结果，DSC 为 88.11+/-3.52%。结果显示，使用 modified 3D U-Net 架构可以有效地分 segmentation sigmoid colon 在 Computed Tomography (CT) 影像中。此外，研究也显示了 ensemble methods 的潜在优化效果。
</details></li>
</ul>
<hr>
<h2 id="On-Calibration-of-Modern-Quantized-Efficient-Neural-Networks"><a href="#On-Calibration-of-Modern-Quantized-Efficient-Neural-Networks" class="headerlink" title="On Calibration of Modern Quantized Efficient Neural Networks"></a>On Calibration of Modern Quantized Efficient Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13866">http://arxiv.org/abs/2309.13866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joey Kuang, Alexander Wong</li>
<li>for: 这个论文探讨了几种 Architecture 和两个 Dataset 上的 Calibration 性能，以及这些 Calibration 性能与精度之间的关系。</li>
<li>methods: 该论文使用了 ShuffleNetv2、GhostNet-VGG 和 MobileOne 三种 Architecture，以及 CIFAR-100 和 PathMNIST 两个 Dataset。它们使用了不同的精度来评估 Calibration 性能。</li>
<li>results: 研究发现，Calibration 性能与精度之间存在相互关系，尤其是在 4 位 activation  режиmé下。GhostNet-VGG 被发现为最为鲁减的 Architecture，能够在低精度下保持比较好的 Calibration 性能。另外，温度 scaling 可以改善 Calibration 错误，但也有一些限制。<details>
<summary>Abstract</summary>
We explore calibration properties at various precisions for three architectures: ShuffleNetv2, GhostNet-VGG, and MobileOne; and two datasets: CIFAR-100 and PathMNIST. The quality of calibration is observed to track the quantization quality; it is well-documented that performance worsens with lower precision, and we observe a similar correlation with poorer calibration. This becomes especially egregious at 4-bit activation regime. GhostNet-VGG is shown to be the most robust to overall performance drop at lower precision. We find that temperature scaling can improve calibration error for quantized networks, with some caveats. We hope that these preliminary insights can lead to more opportunities for explainable and reliable EdgeML.
</details>
<details>
<summary>摘要</summary>
我们研究了不同精度下的准确性质量，对三种架构：ShuffleNetv2、GhostNet-VGG和MobileOne，以及两个 dataset：CIFAR-100和PathMNIST。我们发现，准确性质量与量化质量之间存在直接的相关性，即性能随着精度下降而变差，我们在4比特活动 режиimen中发现了类似的关系。 GhostNet-VGG 显示为低精度下的最高抗性。我们发现了温度Scaling可以改善量化网络的准确性错误，但有一些限制。我们希望这些初步发现可以带来更多的可靠和可解释的EdgeML。
</details></li>
</ul>
<hr>
<h2 id="SuPerPM-A-Large-Deformation-Robust-Surgical-Perception-Framework-Based-on-Deep-Point-Matching-Learned-from-Physical-Constrained-Simulation-Data"><a href="#SuPerPM-A-Large-Deformation-Robust-Surgical-Perception-Framework-Based-on-Deep-Point-Matching-Learned-from-Physical-Constrained-Simulation-Data" class="headerlink" title="SuPerPM: A Large Deformation-Robust Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data"></a>SuPerPM: A Large Deformation-Robust Surgical Perception Framework Based on Deep Point Matching Learned from Physical Constrained Simulation Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13863">http://arxiv.org/abs/2309.13863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shan Lin, Albert J. Miao, Ali Alabiad, Fei Liu, Kaiyuan Wang, Jingpei Lu, Florian Richter, Michael C. Yip</li>
<li>for: 实现更好的骨盘识别和重建，减少对大幅弯曲的肿瘤进行追踪和重建的误差。</li>
<li>methods: 使用学习型非静态点云匹配来进行数据汇合，以应对大幅弯曲。</li>
<li>results: 在复杂的骨盘运动中，得到了superior的表现，比前一代医疗场景追踪算法更好。<details>
<summary>Abstract</summary>
Manipulation of tissue with surgical tools often results in large deformations that current methods in tracking and reconstructing algorithms have not effectively addressed. A major source of tracking errors during large deformations stems from wrong data association between observed sensor measurements with previously tracked scene. To mitigate this issue, we present a surgical perception framework, SuPerPM, that leverages learning-based non-rigid point cloud matching for data association, thus accommodating larger deformations. The learning models typically require training data with ground truth point cloud correspondences, which is challenging or even impractical to collect in surgical environments. Thus, for tuning the learning model, we gather endoscopic data of soft tissue being manipulated by a surgical robot and then establish correspondences between point clouds at different time points to serve as ground truth. This was achieved by employing a position-based dynamics (PBD) simulation to ensure that the correspondences adhered to physical constraints. The proposed framework is demonstrated on several challenging surgical datasets that are characterized by large deformations, achieving superior performance over state-of-the-art surgical scene tracking algorithms.
</details>
<details>
<summary>摘要</summary>
人体组织的 manipulate 使用手术工具经常会导致大幅变形，现有的跟踪和重建算法并未有效地处理这些变形。主要的跟踪错误源于 incorrect data association between observed sensor measurements with previously tracked scene。为解决这个问题，我们提出了一个手术认知框架，SuPerPM，该框架利用学习基于非RIGID点云匹配来实现数据关联，因此可以满足更大的变形。学习模型通常需要训练数据包含真实的点云对应关系，但在手术环境中收集这些数据是困难或者实际上不可能的。因此，我们为训练学习模型，收集了endoscopic数据 soft tissue being manipulated by a surgical robot，并在不同时间点之间建立了点云对应关系，以供真实的参照。我们使用了位置基于动力学（PBD）模拟来确保这些对应关系遵循物理约束。我们提出的框架在一些具有大幅变形的手术数据集上进行了评测，实现了与当前最佳手术场景跟踪算法相比的更高性能。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Attacks-on-Video-Object-Segmentation-with-Hard-Region-Discovery"><a href="#Adversarial-Attacks-on-Video-Object-Segmentation-with-Hard-Region-Discovery" class="headerlink" title="Adversarial Attacks on Video Object Segmentation with Hard Region Discovery"></a>Adversarial Attacks on Video Object Segmentation with Hard Region Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13857">http://arxiv.org/abs/2309.13857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Li, Yu Zhang, Li Yuan, Jian Zhao, Xianghua Xu, Xiaoqin Zhang</li>
<li>for: 本研究旨在提高视频对象 segmentation 模型的安全性，对抗 adversarial examples 的攻击。</li>
<li>methods: 本研究提出了一种基于 first-frame attack 的对象agnostic adversary，通过探索 easily confused region 来生成具有更强的攻击力的干扰。</li>
<li>results: 实验结果表明，我们的攻击器可以很大程度下降了多种 state-of-the-art video object segmentation 模型的性能。<details>
<summary>Abstract</summary>
Video object segmentation has been applied to various computer vision tasks, such as video editing, autonomous driving, and human-robot interaction. However, the methods based on deep neural networks are vulnerable to adversarial examples, which are the inputs attacked by almost human-imperceptible perturbations, and the adversary (i.e., attacker) will fool the segmentation model to make incorrect pixel-level predictions. This will rise the security issues in highly-demanding tasks because small perturbations to the input video will result in potential attack risks. Though adversarial examples have been extensively used for classification, it is rarely studied in video object segmentation. Existing related methods in computer vision either require prior knowledge of categories or cannot be directly applied due to the special design for certain tasks, failing to consider the pixel-wise region attack. Hence, this work develops an object-agnostic adversary that has adversarial impacts on VOS by first-frame attacking via hard region discovery. Particularly, the gradients from the segmentation model are exploited to discover the easily confused region, in which it is difficult to identify the pixel-wise objects from the background in a frame. This provides a hardness map that helps to generate perturbations with a stronger adversarial power for attacking the first frame. Empirical studies on three benchmarks indicate that our attacker significantly degrades the performance of several state-of-the-art video object segmentation models.
</details>
<details>
<summary>摘要</summary>
“视频对象分割（VOS）在计算机视觉任务中得到应用，如视频编辑、自动驾驶和人机交互。然而，基于深度神经网络的方法容易受到恶意示例（adversarial examples）的攻击，这些攻击者（i.e., 攻击者）会使用 almost human-imperceptible 的干扰，让 VOS 模型进行错误的像素级预测。这会导致高度需求任务中的安全问题。虽然恶意示例在分类领域已经广泛研究，但在 VOS 领域 rarely 被研究。现有的计算机视觉相关方法 Either require prior knowledge of categories 或者不可直接应用，因为它们特定的设计不适用于 VOS。因此，这项工作开发了一种对 VOS 具有恶意影响的对象agnostic adversary。具体来说，从 VOS 模型的梯度来发现容易困惑的区域，这个区域中的像素Difficult to identify from the background in a frame.这提供了一个 hardness map，帮助生成具有更强的恶意力的攻击。实验表明，我们的攻击者可以 Significantly degrade 多种 state-of-the-art VOS 模型的性能。”
</details></li>
</ul>
<hr>
<h2 id="DISeR-Designing-Imaging-Systems-with-Reinforcement-Learning"><a href="#DISeR-Designing-Imaging-Systems-with-Reinforcement-Learning" class="headerlink" title="DISeR: Designing Imaging Systems with Reinforcement Learning"></a>DISeR: Designing Imaging Systems with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13851">http://arxiv.org/abs/2309.13851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tzofi Klinghoffer, Kushagra Tiwary, Nikhil Behari, Bhavya Agrawalla, Ramesh Raskar</li>
<li>for: 本研究旨在自动化图像系统设计，提高图像系统的性能和可靠性。</li>
<li>methods: 本研究使用语言学模型和强化学习来自动搜索图像系统的组件，包括摄像头、光源、光学元件和感知模型。</li>
<li>results: 研究示出，通过自动搜索图像系统的组件，可以实现更高的任务性能和更好的可靠性。实验结果表明，与业界标准相比，我们的方法可以提供更高的深度估计和更好的摄像头配置。<details>
<summary>Abstract</summary>
Imaging systems consist of cameras to encode visual information about the world and perception models to interpret this encoding. Cameras contain (1) illumination sources, (2) optical elements, and (3) sensors, while perception models use (4) algorithms. Directly searching over all combinations of these four building blocks to design an imaging system is challenging due to the size of the search space. Moreover, cameras and perception models are often designed independently, leading to sub-optimal task performance. In this paper, we formulate these four building blocks of imaging systems as a context-free grammar (CFG), which can be automatically searched over with a learned camera designer to jointly optimize the imaging system with task-specific perception models. By transforming the CFG to a state-action space, we then show how the camera designer can be implemented with reinforcement learning to intelligently search over the combinatorial space of possible imaging system configurations. We demonstrate our approach on two tasks, depth estimation and camera rig design for autonomous vehicles, showing that our method yields rigs that outperform industry-wide standards. We believe that our proposed approach is an important step towards automating imaging system design.
</details>
<details>
<summary>摘要</summary>
In this paper, we use a context-free grammar (CFG) to formulate these four building blocks of imaging systems. The CFG can be automatically searched over with a learned camera designer to jointly optimize the imaging system with task-specific perception models. By transforming the CFG to a state-action space, we can implement the camera designer with reinforcement learning to intelligently search over the combinatorial space of possible imaging system configurations.We demonstrate our approach on two tasks, depth estimation and camera rig design for autonomous vehicles. Our method yields rigs that outperform industry-wide standards. We believe that our proposed approach is an important step towards automating imaging system design.
</details></li>
</ul>
<hr>
<h2 id="Tuning-Multi-mode-Token-level-Prompt-Alignment-across-Modalities"><a href="#Tuning-Multi-mode-Token-level-Prompt-Alignment-across-Modalities" class="headerlink" title="Tuning Multi-mode Token-level Prompt Alignment across Modalities"></a>Tuning Multi-mode Token-level Prompt Alignment across Modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13847">http://arxiv.org/abs/2309.13847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wds2014/ALIGN">https://github.com/wds2014/ALIGN</a></li>
<li>paper_authors: Dongsheng Wang, Miaoge Li, Xinyang Liu, MingSheng Xu, Bo Chen, Hanwang Zhang</li>
<li>for: 提高视觉概念理解的开放世界视觉模型表现。</li>
<li>methods: 使用多模式Token级别调整框架，利用最优运输来学习和协调多模式modalities的Prompt tokens。</li>
<li>results: 在各种图像识别benchmark上显示出优于常见方法的总体化和几个shot能力，并且Qualitative分析表明学习的Prompt tokens能够捕捉多种视觉概念。<details>
<summary>Abstract</summary>
Advancements in prompt tuning of vision-language models have underscored their potential in enhancing open-world visual concept comprehension. However, prior works only primarily focus on single-mode (only one prompt for each modality) and holistic level (image or sentence) semantic alignment, which fails to capture the sample diversity, leading to sub-optimal prompt discovery. To address the limitation, we propose a multi-mode token-level tuning framework that leverages the optimal transportation to learn and align a set of prompt tokens across modalities. Specifically, we rely on two essential factors: 1) multi-mode prompts discovery, which guarantees diverse semantic representations, and 2) token-level alignment, which helps explore fine-grained similarity. Consequently, the similarity can be calculated as a hierarchical transportation problem between the modality-specific sets. Extensive experiments on popular image recognition benchmarks show the superior generalization and few-shot abilities of our approach. The qualitative analysis demonstrates that the learned prompt tokens have the ability to capture diverse visual concepts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Multi-mode prompts discovery, which guarantees diverse semantic representations.2. Token-level alignment, which helps explore fine-grained similarity.Consequently, the similarity can be calculated as a hierarchical transportation problem between the modality-specific sets. Extensive experiments on popular image recognition benchmarks show the superior generalization and few-shot abilities of our approach. The qualitative analysis demonstrates that the learned prompt tokens have the ability to capture diverse visual concepts.Note: “vision-language models” should be translated as “视觉语言模型” in Simplified Chinese.</details></li>
</ol>
<hr>
<h2 id="Traj-LO-In-Defense-of-LiDAR-Only-Odometry-Using-an-Effective-Continuous-Time-Trajectory"><a href="#Traj-LO-In-Defense-of-LiDAR-Only-Odometry-Using-an-Effective-Continuous-Time-Trajectory" class="headerlink" title="Traj-LO: In Defense of LiDAR-Only Odometry Using an Effective Continuous-Time Trajectory"></a>Traj-LO: In Defense of LiDAR-Only Odometry Using an Effective Continuous-Time Trajectory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13842">http://arxiv.org/abs/2309.13842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kevin2431/traj-lo">https://github.com/kevin2431/traj-lo</a></li>
<li>paper_authors: Xin Zheng, Jianke Zhu</li>
<li>for: 这个论文旨在探讨LiDAR仅凭借LiDAR点云数据实现的ODometry问题，而不是通过附加惯性仪器来提高精度。</li>
<li>methods: 该方法首先将LiDAR测量点视为流动的流点，然后将LiDAR运动 parameterized为简单 yet effective的连续时间曲线。最后，我们的Traj-LO方法尝试通过紧密结合LiDAR点云的 геометри信息和运动约束来重建 LiDAR的空间时间准确的运动。</li>
<li>results: 对于不同类型的LiDAR和多个LiDAR系统，我们的方法表现出了可靠和有效的性能，甚至在kinematic状态超过IMU测量范围的情况下也能够取得良好的结果。我们的实现已经在GitHub上公开。<details>
<summary>Abstract</summary>
LiDAR Odometry is an essential component in many robotic applications. Unlike the mainstreamed approaches that focus on improving the accuracy by the additional inertial sensors, this letter explores the capability of LiDAR-only odometry through a continuous-time perspective. Firstly, the measurements of LiDAR are regarded as streaming points continuously captured at high frequency. Secondly, the LiDAR movement is parameterized by a simple yet effective continuous-time trajectory. Therefore, our proposed Traj-LO approach tries to recover the spatial-temporal consistent movement of LiDAR by tightly coupling the geometric information from LiDAR points and kinematic constraints from trajectory smoothness. This framework is generalized for different kinds of LiDAR as well as multi-LiDAR systems. Extensive experiments on the public datasets demonstrate the robustness and effectiveness of our proposed LiDAR-only approach, even in scenarios where the kinematic state exceeds the IMU's measuring range. Our implementation is open-sourced on GitHub.
</details>
<details>
<summary>摘要</summary>
雷达探测器（LiDAR）是许多 робо械应用中的一个关键组件。与主流方法不同，这封信函数通过不断增强附加的惯性传感器来提高精度。而我们的方法则是通过持续时间的视角来探讨LiDAR只的定位。首先，我们视为LiDAR测量点是高频Capture的流动点。其次，我们将LiDAR的移动参数化为简单 yet effective的持续时间曲线。因此，我们提出的Traj-LO方法尝试通过与LiDAR点的几何信息和运动稳定性的束缚来恢复LiDAR的空间时间准确的运动。这种框架适用于不同类型的LiDAR以及多个LiDAR系统。我们的实现在GitHub上公开。Extensive experiments on public datasets have demonstrated the robustness and effectiveness of our proposed LiDAR-only approach, even in scenarios where the kinematic state exceeds the IMU's measuring range.
</details></li>
</ul>
<hr>
<h2 id="Fill-the-K-Space-and-Refine-the-Image-Prompting-for-Dynamic-and-Multi-Contrast-MRI-Reconstruction"><a href="#Fill-the-K-Space-and-Refine-the-Image-Prompting-for-Dynamic-and-Multi-Contrast-MRI-Reconstruction" class="headerlink" title="Fill the K-Space and Refine the Image: Prompting for Dynamic and Multi-Contrast MRI Reconstruction"></a>Fill the K-Space and Refine the Image: Prompting for Dynamic and Multi-Contrast MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13839">http://arxiv.org/abs/2309.13839</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hellopipu/promptmr">https://github.com/hellopipu/promptmr</a></li>
<li>paper_authors: Bingyu Xin, Meng Ye, Leon Axel, Dimitris N. Metaxas</li>
<li>for: 提高动态或多contrast MRI重建的精度和效率，以及扩展现有的MRI重建模型到不同的输入类型和参数 Conditioning.</li>
<li>methods: 提出了一种两 stage重建管道，首先利用物理学基础重建缺失的k-空间数据，然后通过一种基于提示的学习方法（PromptMR）来进行多视图、多对比度、邻近类型和加速因子的all-in-one重建。</li>
<li>results: 对比 précédente estado del arte的加速MRI重建方法，提出的方法得到了显著的提高，并且可以更好地适应不同的输入类型和参数 Conditioning.<details>
<summary>Abstract</summary>
The key to dynamic or multi-contrast magnetic resonance imaging (MRI) reconstruction lies in exploring inter-frame or inter-contrast information. Currently, the unrolled model, an approach combining iterative MRI reconstruction steps with learnable neural network layers, stands as the best-performing method for MRI reconstruction. However, there are two main limitations to overcome: firstly, the unrolled model structure and GPU memory constraints restrict the capacity of each denoising block in the network, impeding the effective extraction of detailed features for reconstruction; secondly, the existing model lacks the flexibility to adapt to variations in the input, such as different contrasts, resolutions or views, necessitating the training of separate models for each input type, which is inefficient and may lead to insufficient reconstruction. In this paper, we propose a two-stage MRI reconstruction pipeline to address these limitations. The first stage involves filling the missing k-space data, which we approach as a physics-based reconstruction problem. We first propose a simple yet efficient baseline model, which utilizes adjacent frames/contrasts and channel attention to capture the inherent inter-frame/-contrast correlation. Then, we extend the baseline model to a prompt-based learning approach, PromptMR, for all-in-one MRI reconstruction from different views, contrasts, adjacent types, and acceleration factors. The second stage is to refine the reconstruction from the first stage, which we treat as a general video restoration problem to further fuse features from neighboring frames/contrasts in the image domain. Extensive experiments show that our proposed method significantly outperforms previous state-of-the-art accelerated MRI reconstruction methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>针对动态或多比特磁共振成像（MRI）重建，关键在于挖掘 между帧或比特信息。目前，最佳性能的方法是折叠模型，它将iterative MRI重建步骤与可学习神经网络层组合起来。然而，需要突破两个主要限制：首先，折叠模型的结构和GPU内存限制限制每个除噪块在网络中的容量，阻碍细节特征的有效提取;其次，现有模型缺乏适应输入的灵活性，需要对不同的输入，如不同的比特、分辨率、视野或视角，进行分别训练，这是不fficient和可能导致重建不足。在这篇论文中，我们提出了一个两个阶段的MRI重建管道，用于解决这些限制。第一阶段是填充缺失的k空间数据，我们对此采用物理基础的重建方法。我们首先提出了一个简单 yet efficient的基准模型，该模型利用邻近帧/比特和通道注意力 capture the inherent inter-frame/-contrast correlation。然后，我们将基准模型扩展到PromptMR，用于从不同的视角、比特、邻近类型和加速因子中进行一起的MRI重建。第二阶段是对第一阶段的重建进行进一步的纠正，我们将其视为一个通用视频恢复问题，以更好地融合邻近帧/比特中的特征。经过广泛的实验，我们发现我们的提议方法在前一个状态的加速MRI重建方法上显著超越。
</details></li>
</ul>
<hr>
<h2 id="IBVC-Interpolation-driven-B-frame-Video-Compression"><a href="#IBVC-Interpolation-driven-B-frame-Video-Compression" class="headerlink" title="IBVC: Interpolation-driven B-frame Video Compression"></a>IBVC: Interpolation-driven B-frame Video Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13835">http://arxiv.org/abs/2309.13835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meiqin Liu, Chenming Xu, Chao Yao, Weisi Lin, Yao Zhao</li>
<li>For: The paper aims to improve B-frame video compression by addressing inaccurate quantized motions and inefficient motion compensation in previous learned approaches.* Methods: The proposed method, Interpolation-driven B-frame Video Compression (IBVC), involves two major operations: video frame interpolation and artifact reduction compression. It uses a bit-rate free MEMC based on interpolation and a residual guided masking encoder to adaptively select meaningful contexts with interpolated multi-scale dependencies.* Results: The experimental results on B-frame coding demonstrate that IBVC has significant improvements compared to relevant state-of-the-art methods, and can save bit rates compared with the random access (RA) configuration of H.266 (VTM).Here are the three points in Simplified Chinese:* For: 提高B帧视频压缩，解决前一些学习方法中的不准确量化运动和不fficient的运动补做。* Methods: 提议的方法是Interpolation-driven B-frame Video Compression (IBVC)，它包括两个主要操作：视频 interpolating和artefact reduction compression。它使用免费的MEMC based on interpolation，并使用 residual guided masking encoder来选择有用的上下文。* Results: 实验结果表明，IBVC在B帧编码方面有显著的改进，并可以比Random Access（RA）配置的H.266（VTM）节省比特率。<details>
<summary>Abstract</summary>
Learned B-frame video compression aims to adopt bi-directional motion estimation and motion compensation (MEMC) coding for middle frame reconstruction. However, previous learned approaches often directly extend neural P-frame codecs to B-frame relying on bi-directional optical-flow estimation or video frame interpolation. They suffer from inaccurate quantized motions and inefficient motion compensation. To address these issues, we propose a simple yet effective structure called Interpolation-driven B-frame Video Compression (IBVC). Our approach only involves two major operations: video frame interpolation and artifact reduction compression. IBVC introduces a bit-rate free MEMC based on interpolation, which avoids optical-flow quantization and additional compression distortions. Later, to reduce duplicate bit-rate consumption and focus on unaligned artifacts, a residual guided masking encoder is deployed to adaptively select the meaningful contexts with interpolated multi-scale dependencies. In addition, a conditional spatio-temporal decoder is proposed to eliminate location errors and artifacts instead of using MEMC coding in other methods. The experimental results on B-frame coding demonstrate that IBVC has significant improvements compared to the relevant state-of-the-art methods. Meanwhile, our approach can save bit rates compared with the random access (RA) configuration of H.266 (VTM). The code will be available at https://github.com/ruhig6/IBVC.
</details>
<details>
<summary>摘要</summary>
学习B帧视频压缩targets采用双向运动估计和运动补做(MEMC)编码来重建中间帧。然而，以前的学习方法通常直接将神经网络P帧编码器扩展到B帧，基于双向光流估计或视频帧 interpolación。它们受到不准确的量化运动和不fficient的运动补做的影响。为了解决这些问题，我们提出了一种简单 yet effective的结构，即 interpolación-driven B帧视频压缩(IBVC)。我们的方法只有两个主要操作：视频帧 interpolación和噪声压缩。IBVC引入了一种免费的MEMC基于 interpolación，这可以避免光流量化和额外压缩损害。后来，为了减少重复的比特率消耗和重点关注不同依赖度的噪声，我们提出了一种适应性的masking编码器，以便选择 interpolated多尺度依赖关系中的有意义上下文。此外，我们还提出了一种conditional spatio-temporal解码器，以消除Location errors和噪声而不是使用MEMC编码。实验结果表明，IBVC与相关的状态 искусternal methods相比有显著改善。同时，我们的方法可以与H.266（VTM）中的随机访问（RA）配置相比节省比特率。代码将在https://github.com/ruhig6/IBVC上提供。
</details></li>
</ul>
<hr>
<h2 id="PARTICLE-Part-Discovery-and-Contrastive-Learning-for-Fine-grained-Recognition"><a href="#PARTICLE-Part-Discovery-and-Contrastive-Learning-for-Fine-grained-Recognition" class="headerlink" title="PARTICLE: Part Discovery and Contrastive Learning for Fine-grained Recognition"></a>PARTICLE: Part Discovery and Contrastive Learning for Fine-grained Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13822">http://arxiv.org/abs/2309.13822</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cvl-umass/PARTICLE">https://github.com/cvl-umass/PARTICLE</a></li>
<li>paper_authors: Oindrila Saha, Subhransu Maji</li>
<li>for: 这些方法是用于提高细化分类和分割任务的自助学习方法。</li>
<li>methods: 这些方法包括instance-discriminative contrastive学习和part-centric equivariance和不变性目标。</li>
<li>results: 这些方法可以提高图像分类和分割任务的性能，例如在Linear-evaluation scheme中，使用DetCon自助学习方法训练ResNet50在ImageNet上的分类精度从35.4%提高到42.0%在Caltech-UCSD Birds上，从35.5%提高到44.1%在FGVC Aircraft上，从29.7%提高到37.4%在Stanford Cars上。<details>
<summary>Abstract</summary>
We develop techniques for refining representations for fine-grained classification and segmentation tasks in a self-supervised manner. We find that fine-tuning methods based on instance-discriminative contrastive learning are not as effective, and posit that recognizing part-specific variations is crucial for fine-grained categorization. We present an iterative learning approach that incorporates part-centric equivariance and invariance objectives. First, pixel representations are clustered to discover parts. We analyze the representations from convolutional and vision transformer networks that are best suited for this task. Then, a part-centric learning step aggregates and contrasts representations of parts within an image. We show that this improves the performance on image classification and part segmentation tasks across datasets. For example, under a linear-evaluation scheme, the classification accuracy of a ResNet50 trained on ImageNet using DetCon, a self-supervised learning approach, improves from 35.4% to 42.0% on the Caltech-UCSD Birds, from 35.5% to 44.1% on the FGVC Aircraft, and from 29.7% to 37.4% on the Stanford Cars. We also observe significant gains in few-shot part segmentation tasks using the proposed technique, while instance-discriminative learning was not as effective. Smaller, yet consistent, improvements are also observed for stronger networks based on transformers.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)我们开发了一种基于自我指导的方法，用于精细分类和分割任务中的表示更新。我们发现，基于实例异同学习的精化方法并不那么有效，而recognizing特定部分的变化是精度分类的关键。我们提出了一种循环学习方法，其中包括部分准确性和不变性目标。首先，我们使用图像中的像素表示进行聚合，以便发现特定部分。然后，我们分析了图像中的卷积和视力转换网络，以确定最适合这种任务的表示。接着，我们在图像中聚合和对比部分表示，以提高图像分类和分割任务的性能。我们发现，这种方法在多个数据集上都有显著提高，而instance-discriminative学习方法不太有效。此外，我们还发现，对于更强大的网络，基于转换器的方法也会得到更小 yet consistent的改进。
</details></li>
</ul>
<hr>
<h2 id="MMA-Net-Multiple-Morphology-Aware-Network-for-Automated-Cobb-Angle-Measurement"><a href="#MMA-Net-Multiple-Morphology-Aware-Network-for-Automated-Cobb-Angle-Measurement" class="headerlink" title="MMA-Net: Multiple Morphology-Aware Network for Automated Cobb Angle Measurement"></a>MMA-Net: Multiple Morphology-Aware Network for Automated Cobb Angle Measurement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13817">http://arxiv.org/abs/2309.13817</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengxuan Qiu, Jie Yang, Jiankun Wang</li>
<li>for: 提高骨盘畸形诊断和评估中的自动定角度测量精度。</li>
<li>methods: 利用多种骨盘 morphology 作为注意力信息，并将 segmentation 结果与原始 X-ray 图像 concatenate 作为 regression 模块进行精度的定角度测量。</li>
<li>results: 在 AASCE 挑战数据集上测试，SMAPE 为 7.28%，MAE 为 3.18{\deg}, 与其他竞争方法相比表现出色。<details>
<summary>Abstract</summary>
Scoliosis diagnosis and assessment depend largely on the measurement of the Cobb angle in spine X-ray images. With the emergence of deep learning techniques that employ landmark detection, tilt prediction, and spine segmentation, automated Cobb angle measurement has become increasingly popular. However, these methods encounter difficulties such as high noise sensitivity, intricate computational procedures, and exclusive reliance on a single type of morphological information. In this paper, we introduce the Multiple Morphology-Aware Network (MMA-Net), a novel framework that improves Cobb angle measurement accuracy by integrating multiple spine morphology as attention information. In the MMA-Net, we first feed spine X-ray images into the segmentation network to produce multiple morphological information (spine region, centerline, and boundary) and then concatenate the original X-ray image with the resulting segmentation maps as input for the regression module to perform precise Cobb angle measurement. Furthermore, we devise joint loss functions for our segmentation and regression network training, respectively. We evaluate our method on the AASCE challenge dataset and achieve superior performance with the SMAPE of 7.28% and the MAE of 3.18{\deg}, indicating a strong competitiveness compared to other outstanding methods. Consequently, we can offer clinicians automated, efficient, and reliable Cobb angle measurement.
</details>
<details>
<summary>摘要</summary>
诊断和评估斯科利病（Scoliosis）几乎完全依赖在脊梁X射线图像中测量Cobb角度。随着深度学习技术的出现，使用landmark检测、倾斜预测和脊梁分 segmentation的自动化Cobb角度测量方法在现场上变得越来越受欢迎。然而，这些方法受到高噪音敏感、复杂计算过程和单一类型形态信息的限制。在这篇论文中，我们介绍了多种形态意识网络（MMA-Net），一种新的框架，可以提高Cobb角度测量精度。在MMA-Net中，我们首先将脊梁X射线图像传递给分 segmentation网络，以生成多种形态信息（脊梁区域、中心线和边界），然后将原始X射线图像和生成的分 segmentation图像作为输入传递给 regression模块进行精确Cobb角度测量。此外，我们定义了joint损失函数用于我们的分 segmentation和回归网络训练。我们在AASCE挑战数据集上评估了我们的方法，并实现了优于其他突出的方法的性能，SMAPE值为7.28%和MAE值为3.18°，这表明我们的方法具有强大的竞争力。因此，我们可以为临床医生提供自动化、高效和可靠的Cobb角度测量。
</details></li>
</ul>
<hr>
<h2 id="DVI-SLAM-A-Dual-Visual-Inertial-SLAM-Network"><a href="#DVI-SLAM-A-Dual-Visual-Inertial-SLAM-Network" class="headerlink" title="DVI-SLAM: A Dual Visual Inertial SLAM Network"></a>DVI-SLAM: A Dual Visual Inertial SLAM Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13814">http://arxiv.org/abs/2309.13814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiongfeng Peng, Zhihua Liu, Weiming Li, Ping Tan, SoonYong Cho, Qiang Wang</li>
<li>for: This paper aims to improve visual simultaneous localization and mapping (SLAM) methods by better integrating visual information and inertial measurement unit (IMU) data.</li>
<li>methods: The proposed method uses a novel deep SLAM network with dual visual factors, which integrates both photometric and re-projection factors into an end-to-end differentiable structure through a multi-factor data association module.</li>
<li>results: The proposed method significantly outperforms state-of-the-art methods on several public datasets, including TartanAir, EuRoC, and ETH3D-SLAM. Specifically, the absolute trajectory error was reduced by 45.3% and 36.2% for monocular and stereo configurations on the EuRoC dataset, respectively.<details>
<summary>Abstract</summary>
Recent deep learning based visual simultaneous localization and mapping (SLAM) methods have made significant progress. However, how to make full use of visual information as well as better integrate with inertial measurement unit (IMU) in visual SLAM has potential research value. This paper proposes a novel deep SLAM network with dual visual factors. The basic idea is to integrate both photometric factor and re-projection factor into the end-to-end differentiable structure through multi-factor data association module. We show that the proposed network dynamically learns and adjusts the confidence maps of both visual factors and it can be further extended to include the IMU factors as well. Extensive experiments validate that our proposed method significantly outperforms the state-of-the-art methods on several public datasets, including TartanAir, EuRoC and ETH3D-SLAM. Specifically, when dynamically fusing the three factors together, the absolute trajectory error for both monocular and stereo configurations on EuRoC dataset has reduced by 45.3% and 36.2% respectively.
</details>
<details>
<summary>摘要</summary>
现代深度学习基于视觉同时定位地图（SLAM）方法在最近几年中已经做出了很大的进步。然而，如何更好地利用视觉信息并更好地与惯性测量单元（IMU）在视觉SLAM中进行集成，这是有研究价值的。本文提出了一种新的深度SLAM网络，具有双视觉因素。基本思想是通过多因素数据匹配模块将 photometric 因素和重投影因素集成到端到端可微结构中。我们显示了我们提出的网络可以在运动中学习和调整两个视觉因素的信任地图，并且可以进一步包括 IMU 因素。广泛的实验证明了我们的提出方法在多个公共数据集上具有显著的优势，包括 TartanAir、EuRoC 和 ETH3D-SLAM。具体来说，在动态混合三个因素时，EuRoC 数据集上的绝对轨迹错误量降低了45.3%和36.2%分别 для 单镜和 стерео 配置。
</details></li>
</ul>
<hr>
<h2 id="Boundary-Aware-Proposal-Generation-Method-for-Temporal-Action-Localization"><a href="#Boundary-Aware-Proposal-Generation-Method-for-Temporal-Action-Localization" class="headerlink" title="Boundary-Aware Proposal Generation Method for Temporal Action Localization"></a>Boundary-Aware Proposal Generation Method for Temporal Action Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13810">http://arxiv.org/abs/2309.13810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Chunyan Feng, Jiahui Yang, Zheng Li, Caili Guo<br>for: 本文旨在提出一种基于界限感知的暂时动作地理化（TAL）方法，以便在未处理视频中找到动作类别和时间边界。methods: 本文提出的Boundary-Aware Proposal Generation（BAPG）方法，通过强调界限感知来改善TAL的准确性。BAPG不依赖现有的TAL网络架构，可以与主流TAL模型进行插件式应用。results: 对于THUMOS14和ActivityNet-1.3 dataset的广泛实验表明，BAPG可以显著提高TAL的性能。<details>
<summary>Abstract</summary>
The goal of Temporal Action Localization (TAL) is to find the categories and temporal boundaries of actions in an untrimmed video. Most TAL methods rely heavily on action recognition models that are sensitive to action labels rather than temporal boundaries. More importantly, few works consider the background frames that are similar to action frames in pixels but dissimilar in semantics, which also leads to inaccurate temporal boundaries. To address the challenge above, we propose a Boundary-Aware Proposal Generation (BAPG) method with contrastive learning. Specifically, we define the above background frames as hard negative samples. Contrastive learning with hard negative mining is introduced to improve the discrimination of BAPG. BAPG is independent of the existing TAL network architecture, so it can be applied plug-and-play to mainstream TAL models. Extensive experimental results on THUMOS14 and ActivityNet-1.3 demonstrate that BAPG can significantly improve the performance of TAL.
</details>
<details>
<summary>摘要</summary>
文本内容：目的是Temporal Action Localization（TAL）找到视频中的分类和时间边界。大多数TAL方法都依赖于动作识别模型，而这些模型更关注动作标签而非时间边界。更重要的是，有些工作不考虑视频中的背景帧，这些帧与动作帧相似在像素级别，但是在semantics方面不同，这也导致了不准确的时间边界。为解决这个挑战，我们提出了Boundary-Aware Proposal Generation（BAPG）方法，该方法使用了对比学习。我们定义了上述背景帧为hard negative samples。对比学习可以提高BAPG的推iscrimination。BAPG与主流TAL网络架构独立，因此可以直接应用于主流TAL模型。我们在THUMOS14和ActivityNet-1.3上进行了广泛的实验，结果表明BAPG可以显著提高TAL的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/25/cs.CV_2023_09_25/" data-id="clogyj8xz00i27craamzma68b" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/25/cs.AI_2023_09_25/" class="article-date">
  <time datetime="2023-09-25T12:00:00.000Z" itemprop="datePublished">2023-09-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/25/cs.AI_2023_09_25/">cs.AI - 2023-09-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Integrating-Higher-Order-Dynamics-and-Roadway-Compliance-into-Constrained-ILQR-based-Trajectory-Planning-for-Autonomous-Vehicles"><a href="#Integrating-Higher-Order-Dynamics-and-Roadway-Compliance-into-Constrained-ILQR-based-Trajectory-Planning-for-Autonomous-Vehicles" class="headerlink" title="Integrating Higher-Order Dynamics and Roadway-Compliance into Constrained ILQR-based Trajectory Planning for Autonomous Vehicles"></a>Integrating Higher-Order Dynamics and Roadway-Compliance into Constrained ILQR-based Trajectory Planning for Autonomous Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14566">http://arxiv.org/abs/2309.14566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanxiang Li, Jiaqiao Zhang, Sheng Zhu, Dongjian Tang, Donghao Xu</li>
<li>for: 本研究旨在提出一种基于CILQR优化算法的在道路上的自动驾驶汽车路径规划方法，以提高安全性和舒适性。</li>
<li>methods: 本研究使用了CILQR优化算法，并增加了更高阶的约束和成本，以确保路径规划是可控的。此外，本研究还考虑了道路规则遵从性，以确保车辆遵循路径规划的约束。</li>
<li>results:  simulation和实际驾驶场景 validate了本研究的方法，显示了改进的安全性和舒适性。<details>
<summary>Abstract</summary>
This paper addresses the advancements in on-road trajectory planning for Autonomous Passenger Vehicles (APV). Trajectory planning aims to produce a globally optimal route for APVs, considering various factors such as vehicle dynamics, constraints, and detected obstacles. Traditional techniques involve a combination of sampling methods followed by optimization algorithms, where the former ensures global awareness and the latter refines for local optima. Notably, the Constrained Iterative Linear Quadratic Regulator (CILQR) optimization algorithm has recently emerged, adapted for APV systems, emphasizing improved safety and comfort. However, existing implementations utilizing the vehicle bicycle kinematic model may not guarantee controllable trajectories. We augment this model by incorporating higher-order terms, including the first and second-order derivatives of curvature and longitudinal jerk. This inclusion facilitates a richer representation in our cost and constraint design. We also address roadway compliance, emphasizing adherence to lane boundaries and directions, which past work often overlooked. Lastly, we adopt a relaxed logarithmic barrier function to address the CILQR's dependency on feasible initial trajectories. The proposed methodology is then validated through simulation and real-world experiment driving scenes in real time.
</details>
<details>
<summary>摘要</summary>
To address this limitation, we augment the model by incorporating higher-order terms, including the first and second-order derivatives of curvature and longitudinal jerk. This allows for a more detailed representation in our cost and constraint design. Additionally, we emphasize adherence to lane boundaries and directions, which past work often overlooked. To address the CILQR's dependency on feasible initial trajectories, we adopt a relaxed logarithmic barrier function.The proposed methodology is then validated through simulation and real-world experiment driving scenes in real time. This paper's contributions include a more accurate and comprehensive vehicle model, improved roadway compliance, and a relaxed logarithmic barrier function to address the CILQR's dependency on feasible initial trajectories. These advancements lead to more controllable and safe trajectories for APVs.
</details></li>
</ul>
<hr>
<h2 id="Generative-Escher-Meshes"><a href="#Generative-Escher-Meshes" class="headerlink" title="Generative Escher Meshes"></a>Generative Escher Meshes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14564">http://arxiv.org/abs/2309.14564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noam Aigerman, Thibault Groueix</li>
<li>For:  This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher.* Methods: The method uses an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group, and modifies the laplacian used in a 2D mesh-mapping technique - Orbifold Tutte Embedding - to achieve all possible tiling configurations for a chosen planar symmetry group. The method also leverages a trained image diffusion model to define a loss on the resulting image, thereby updating the mesh’s parameters based on its appearance matching the text prompt.* Results: The paper shows that the method is able to produce plausible, appealing results, with non-trivial tiles, for a variety of different periodic tiling patterns.<details>
<summary>Abstract</summary>
This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher. In contrast to the standard concept of a seamless texture, i.e., square images that are seamless when tiled, our method generates non-square tilings which comprise solely of repeating copies of the same object. It achieves this by optimizing both geometry and color of a 2D mesh, in order to generate a non-square tile in the shape and appearance of the desired object, with close to no additional background details. We enable geometric optimization of tilings by our key technical contribution: an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. Namely, we prove that modifying the laplacian used in a 2D mesh-mapping technique - Orbifold Tutte Embedding - can achieve all possible tiling configurations for a chosen planar symmetry group. We thus consider both the mesh's tile-shape and its texture as optimizable parameters, rendering the textured mesh via a differentiable renderer. We leverage a trained image diffusion model to define a loss on the resulting image, thereby updating the mesh's parameters based on its appearance matching the text prompt. We show our method is able to produce plausible, appealing results, with non-trivial tiles, for a variety of different periodic tiling patterns.
</details>
<details>
<summary>摘要</summary>
Our key technical contribution is an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. We modify the laplacian used in a 2D mesh-mapping technique called Orbifold Tutte Embedding to achieve all possible tiling configurations for a chosen planar symmetry group. This allows us to optimize both the mesh's tile shape and its texture as parameters, which are then rendered using a differentiable renderer.We use a trained image diffusion model to define a loss on the resulting image, which is used to update the mesh's parameters based on its appearance matching the text prompt. Our method is able to produce plausible and appealing results with non-trivial tiles for a variety of different periodic tiling patterns.
</details></li>
</ul>
<hr>
<h2 id="Training-free-Linear-Image-Inversion-via-Flows"><a href="#Training-free-Linear-Image-Inversion-via-Flows" class="headerlink" title="Training-free Linear Image Inversion via Flows"></a>Training-free Linear Image Inversion via Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04432">http://arxiv.org/abs/2310.04432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashwini Pokle, Matthew J. Muckley, Ricky T. Q. Chen, Brian Karrer</li>
<li>for:  Linear image inversion without training</li>
<li>methods: 使用预训练的生成模型，采用流程匹配模型，使用理论支持的质量补做方法，大幅减少手动参数调整。</li>
<li>results: 在高维数据集上（ImageNet-64&#x2F;128和AFHQ-256），无需特定问题调整，我们的流程基于匹配方法对图像反向问题进行了有效的解决。<details>
<summary>Abstract</summary>
Training-free linear inversion involves the use of a pretrained generative model and -- through appropriate modifications to the generation process -- solving inverse problems without any finetuning of the generative model. While recent prior methods have explored the use of diffusion models, they still require the manual tuning of many hyperparameters for different inverse problems. In this work, we propose a training-free method for image inversion using pretrained flow models, leveraging the simplicity and efficiency of Flow Matching models, using theoretically-justified weighting schemes and thereby significantly reducing the amount of manual tuning. In particular, we draw inspiration from two main sources: adopting prior gradient correction methods to the flow regime, and a solver scheme based on conditional Optimal Transport paths. As pretrained diffusion models are widely accessible, we also show how to practically adapt diffusion models for our method. Empirically, our approach requires no problem-specific tuning across an extensive suite of noisy linear image inversion problems on high-dimensional datasets, ImageNet-64/128 and AFHQ-256, and we observe that our flow-based method for image inversion significantly improves upon closely-related diffusion-based linear inversion methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用预训练的生成模型进行无需训练的线性逆转，通过对生成过程进行相应的修改，可以解决逆转问题无需生成模型的负载。Recent prior方法已经探索了使用扩散模型，但仍然需要手动调整许多超参数 для不同的逆转问题。在这种工作中，我们提出了一种无需训练的图像逆转方法使用预训练的流模型，利用流模型的简单性和高效性，并使用理论上正确的权重分配方案，以降低手动调整的数量。特别是，我们从两个主要的来源中突破想法：在流程中采用先前的梯度修正方法，以及基于条件最优运输路径的解决方案。由于预训练的扩散模型广泛可用，我们还展示了如何实际地适应 diffusion 模型。在实验中，我们发现我们的流基于方法可以在高维度的数据集上进行无需具体问题调整的图像逆转，并且与相似的扩散基于线性逆转方法相比，我们的流基于方法可以获得显著的改进。>>
</details></li>
</ul>
<hr>
<h2 id="Disinformation-Detection-An-Evolving-Challenge-in-the-Age-of-LLMs"><a href="#Disinformation-Detection-An-Evolving-Challenge-in-the-Age-of-LLMs" class="headerlink" title="Disinformation Detection: An Evolving Challenge in the Age of LLMs"></a>Disinformation Detection: An Evolving Challenge in the Age of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15847">http://arxiv.org/abs/2309.15847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohan Jiang, Zhen Tan, Ayushi Nirmal, Huan Liu</li>
<li>for: 本研究旨在探讨利用大型语言模型（LLMs）生成的假信息攻击性的威胁，以及如何通过利用LLMs自身来建立可靠的防御机制。</li>
<li>methods: 本研究采用了现有的假信息检测技术，以及利用LLMs自身来生成检测假信息的模型。</li>
<li>results: 研究发现，现有的假信息检测技术对LLMs生成的假信息有限的检测能力，而利用LLMs自身来生成检测假信息的模型则表现更高效。<details>
<summary>Abstract</summary>
The advent of generative Large Language Models (LLMs) such as ChatGPT has catalyzed transformative advancements across multiple domains. However, alongside these advancements, they have also introduced potential threats. One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system. This work aims to address this issue by answering three research questions: (1) To what extent can the current disinformation detection technique reliably detect LLM-generated disinformation? (2) If traditional techniques prove less effective, can LLMs themself be exploited to serve as a robust defense against advanced disinformation? and, (3) Should both these strategies falter, what novel approaches can be proposed to counter this burgeoning threat effectively? A holistic exploration for the formation and detection of disinformation is conducted to foster this line of research.
</details>
<details>
<summary>摘要</summary>
LLMs的出现已经导致多个领域的进步，但同时也引入了潜在的威胁。一个重要的问题是利用LLMs散布假信息，使用这些模型生成高度感染的假信息，这会挑战假信息检测系统。本研究的目的是回答以下三个研究问题：（1）现有的假信息检测技术能够有效地检测LLM生成的假信息吗？（2）如果传统技术不够有效，可以利用LLM们自己作为防止高级假信息的强大防御手段吗？以及（3）如果这两种策略失败，可以提出新的方法来有效地对抗这种快速发展的威胁。通过探讨假信息的形成和检测，本研究旨在推动这一领域的研究。
</details></li>
</ul>
<hr>
<h2 id="Art-or-Artifice-Large-Language-Models-and-the-False-Promise-of-Creativity"><a href="#Art-or-Artifice-Large-Language-Models-and-the-False-Promise-of-Creativity" class="headerlink" title="Art or Artifice? Large Language Models and the False Promise of Creativity"></a>Art or Artifice? Large Language Models and the False Promise of Creativity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14556">http://arxiv.org/abs/2309.14556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuhin Chakrabarty, Philippe Laban, Divyansh Agarwal, Smaranda Muresan, Chien-Sheng Wu</li>
<li>for: 评估大语言模型（LLM）的创作能力</li>
<li>methods: 使用Consensual Assessment Technique和Torrance Test of Creative Writing评估创作性</li>
<li>results: LLM生成的故事通过TTCW测试失败率较高，并且使用LLM作为评估器时与专业作者的评估结果没有正面相关性。<details>
<summary>Abstract</summary>
Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose the Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:研究人员认为大语言模型（LLM）具有高质量的写作能力，从博客到故事。然而，评估创作文章的创新性是具有挑战性的。受某种创新思维测试（TTCT）的启发，我们使用了共识评估技术 [3]，并提出了杜鲁门创作写作测试（TTCW），以评估创作作品的质量。TTCW包括14个二进制测试，涵盖了原始维度的流畅、灵活性、原创性和发展。我们邀请了10名创作作家，并对由专业作家或 LLM 写作的48篇故事进行人类评估使用 TTCW。我们的分析显示，LLM 生成的故事通过 TTCW 测试的数量比专业作家的故事少得多，3-10 倍。此外，我们还探讨了使用 LLM 作为评估者，以自动化 TTCW 评估，结果显示，没有任何 LLM 与专业评估相关。
</details></li>
</ul>
<hr>
<h2 id="Tactile-Estimation-of-Extrinsic-Contact-Patch-for-Stable-Placement"><a href="#Tactile-Estimation-of-Extrinsic-Contact-Patch-for-Stable-Placement" class="headerlink" title="Tactile Estimation of Extrinsic Contact Patch for Stable Placement"></a>Tactile Estimation of Extrinsic Contact Patch for Stable Placement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14552">http://arxiv.org/abs/2309.14552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kei Ota, Devesh K. Jha, Krishna Murthy Jatavallabhula, Asako Kanezaki, Joshua B. Tenenbaum</li>
<li>for: 这个论文是为了研究机器人如何具备细化的操作技能，特别是在堆叠复杂形状物体时。</li>
<li>methods: 该论文使用了反馈技能来帮助机器人学习堆叠复杂形状物体。机器人通过感受到物体与环境之间的轻微接触来理解物体的稳定性。</li>
<li>results: 研究结果表明，通过对物体与环境之间的轻微接触来估算物体的稳定性是可能的。此外，该方法还可以估算物体在释放 grasp 时的稳定性。实验结果表明，该方法可以在不同的物体对象中实现精准的堆叠。<details>
<summary>Abstract</summary>
Precise perception of contact interactions is essential for the fine-grained manipulation skills for robots. In this paper, we present the design of feedback skills for robots that must learn to stack complex-shaped objects on top of each other. To design such a system, a robot should be able to reason about the stability of placement from very gentle contact interactions. Our results demonstrate that it is possible to infer the stability of object placement based on tactile readings during contact formation between the object and its environment. In particular, we estimate the contact patch between a grasped object and its environment using force and tactile observations to estimate the stability of the object during a contact formation. The contact patch could be used to estimate the stability of the object upon the release of the grasp. The proposed method is demonstrated on various pairs of objects that are used in a very popular board game.
</details>
<details>
<summary>摘要</summary>
<<sys: language="zh-Hans">精准感受接触互动是机器人细致 manipulate 技能的关键。在这篇论文中，我们提出了机器人学习排序复杂形状物体的方法。为了设计这种系统，机器人需要能够根据非常轻微的接触互动理解物体的稳定性。我们的结果表明，可以通过触感读数在物体和其环境之间的接触形成时计算物体的稳定性。特别是，我们可以通过力和感觉观察来估计握持物体和环境之间的接触面积，以估计物体在释放时的稳定性。我们的方法在各种普遍的板球游戏中使用了不同的对象。</sys>>Note that Simplified Chinese is used in the translation, as it is the more widely used standard for Chinese writing in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Algorithmic-Collusion-or-Competition-the-Role-of-Platforms’-Recommender-Systems"><a href="#Algorithmic-Collusion-or-Competition-the-Role-of-Platforms’-Recommender-Systems" class="headerlink" title="Algorithmic Collusion or Competition: the Role of Platforms’ Recommender Systems"></a>Algorithmic Collusion or Competition: the Role of Platforms’ Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14548">http://arxiv.org/abs/2309.14548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingchen Xu, Stephanie Lee, Yong Tan</li>
<li>For: This paper examines how recommendation algorithms used by e-commerce platforms can impact the competitive dynamics of AI-based pricing algorithms.* Methods: The paper uses a repeated game framework to model the interactions between sellers and the platform’s recommender system, and conducts experiments to observe price dynamics and determine the final equilibrium.* Results: The paper finds that a profit-based recommender system can intensify algorithmic collusion among sellers, while a demand-based recommender system can foster price competition and result in lower prices. The results are robust in various market scenarios.<details>
<summary>Abstract</summary>
Recent academic research has extensively examined algorithmic collusion resulting from the utilization of artificial intelligence (AI)-based dynamic pricing algorithms. Nevertheless, e-commerce platforms employ recommendation algorithms to allocate exposure to various products, and this important aspect has been largely overlooked in previous studies on algorithmic collusion. Our study bridges this important gap in the literature and examines how recommendation algorithms can determine the competitive or collusive dynamics of AI-based pricing algorithms. Specifically, two commonly deployed recommendation algorithms are examined: (i) a recommender system that aims to maximize the sellers' total profit (profit-based recommender system) and (ii) a recommender system that aims to maximize the demand for products sold on the platform (demand-based recommender system). We construct a repeated game framework that incorporates both pricing algorithms adopted by sellers and the platform's recommender system. Subsequently, we conduct experiments to observe price dynamics and ascertain the final equilibrium. Experimental results reveal that a profit-based recommender system intensifies algorithmic collusion among sellers due to its congruence with sellers' profit-maximizing objectives. Conversely, a demand-based recommender system fosters price competition among sellers and results in a lower price, owing to its misalignment with sellers' goals. Extended analyses suggest the robustness of our findings in various market scenarios. Overall, we highlight the importance of platforms' recommender systems in delineating the competitive structure of the digital marketplace, providing important insights for market participants and corresponding policymakers.
</details>
<details>
<summary>摘要</summary>
现代学术研究已经广泛研究了基于人工智能（AI）的动态价格算法的算法协作。然而，电商平台使用推荐算法来分配产品的曝光，这一重要方面在过去的研究中受到了广泛的忽略。我们的研究填补了这一重要的研究漏洞，并研究了推荐算法如何影响AI基于价格算法的竞争或协作动态。 Specifically,我们研究了两种通常部署的推荐算法：（i）一个目标 Maximize sellers' total profit的推荐系统（profit-based recommender system），和（ii）一个目标 Maximize the demand for products sold on the platform的推荐系统（demand-based recommender system）。我们建立了一个重复游戏框架，该框架包括采用的价格算法和平台的推荐系统。然后，我们进行实验，观察价格动态并确定最终平衡。实验结果表明，一个基于利润的推荐系统会使算法协作增强，因为它与卖家的利润最大化目标相匹配。相反，一个基于需求的推荐系统会促进价格竞争，导致价格下降，因为它与卖家的目标不一致。 extended 分析表明我们的结论在不同的市场情况下具有坚实性。总的来说，我们强调了平台的推荐系统在数字市场的竞争结构中发挥重要作用，为市场参与者和相关政策制定者提供重要的洞察。
</details></li>
</ul>
<hr>
<h2 id="Effect-of-roundabout-design-on-the-behavior-of-road-users-A-case-study-of-roundabouts-with-application-of-Unsupervised-Machine-Learning"><a href="#Effect-of-roundabout-design-on-the-behavior-of-road-users-A-case-study-of-roundabouts-with-application-of-Unsupervised-Machine-Learning" class="headerlink" title="Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning"></a>Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14540">http://arxiv.org/abs/2309.14540</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tasnim M. Dwekat, Ayda A. Almsre, Huthaifa I. Ashqar<br>for: 这个研究的目的是评估缓冲器的性能并研究人行道用户在互动缓冲器时的行为。methods: 该研究使用了观察和分类 drivers的行为，以及预测道路用户在缓冲器交叉点的行为。results: 研究发现，缓冲器可以减少拐弯口口的速度，入口速度和相应的影响速度取决于道路用户的评级。此外，车辆的速度在过缓冲器时更适合于汽车和卡车的速度。此外，缓冲器具有两种内在特点，首先，由于汽车的小尺寸和缓冲器所有部分都可见，因此从所有方向进入缓冲器时，所有 drivers 都需要减速，从而增加了他们在穿过缓冲器时的反应时间，降低了事故的风险。其次，由于缓冲器内部的流速更少， drivers 只需要左看（在右侧交通），从而更容易过缓冲器。<details>
<summary>Abstract</summary>
This research aims to evaluate the performance of the rotors and study the behavior of the human driver in interacting with the rotors. In recent years, rotors have been increasingly used between countries due to their safety, capacity, and environmental advantages, and because they provide safe and fluid flows of vehicles for transit and integration. It turns out that roundabouts can significantly reduce speed at twisting intersections, entry speed and the resulting effect on speed depends on the rating of road users. In our research, (bus, car, truck) drivers were given special attention and their behavior was categorized into (conservative, normal, aggressive). Anticipating and recognizing driver behavior is an important challenge. Therefore, the aim of this research is to study the effect of roundabouts on these classifiers and to develop a method for predicting the behavior of road users at roundabout intersections. Safety is primarily due to two inherent features of the rotor. First, by comparing the data collected and processed in order to classify and evaluate drivers' behavior, and comparing the speeds of the drivers (bus, car and truck), the speed of motorists at crossing the roundabout was more fit than that of buses and trucks. We looked because the car is smaller and all parts of the rotor are visible to it. So drivers coming from all directions have to slow down, giving them more time to react and mitigating the consequences in the event of an accident. Second, with fewer conflicting flows (and points of conflict), drivers only need to look to their left (in right-hand traffic) for other vehicles, making their job of crossing the roundabout easier as there is less need to split attention between different directions.
</details>
<details>
<summary>摘要</summary>
Safety is a primary concern, and rotors have two inherent features that contribute to safety. First, the speed of motorists crossing the roundabout is more controlled compared to buses and trucks, as the smaller car size allows for better visibility of all parts of the rotor. This requires drivers to slow down, giving them more time to react and reducing the risk of accidents. Second, with fewer conflicting flows and points of conflict, drivers only need to look to their left (in right-hand traffic) for other vehicles, making it easier to cross the roundabout and reducing the need to split attention between different directions.In our research, we collected and processed data to classify and evaluate driver behavior, and compared the speeds of buses, cars, and trucks. We found that the speed of motorists crossing the roundabout was more controlled than that of buses and trucks, as the car's smaller size allows for better visibility of all parts of the rotor. Overall, the design of rotors provides a safer and more efficient way to manage traffic flow, and our research aims to further understand and improve the performance of these intersections.
</details></li>
</ul>
<hr>
<h2 id="Watch-Your-Language-Large-Language-Models-and-Content-Moderation"><a href="#Watch-Your-Language-Large-Language-Models-and-Content-Moderation" class="headerlink" title="Watch Your Language: Large Language Models and Content Moderation"></a>Watch Your Language: Large Language Models and Content Moderation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14517">http://arxiv.org/abs/2309.14517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Kumar, Yousef AbuHashem, Zakir Durumeric</li>
<li>for: 这个论文旨在研究大型自然语言模型（LLM）在内容审核任务中的表现。</li>
<li>methods: 论文使用了现代商业化的GPT-3、GPT-3.5和GPT-4大型自然语言模型，对两种常见的内容审核任务进行评估：规则基础的社区审核和价值评估。</li>
<li>results: 论文发现，LLMs可以有效地进行许多社区的规则基础审核， median accuracy 达到 64%， median precision 达到 83%。而对恶意内容检测，LLMs 表现明显 луч于现有的商业化恶意类别化器。但是，论文发现，在恶意检测任务上，Recent 附加的模型大小增加只有微scopic 的提升，表明 LLMs 在这种任务上可能已经达到性能杯顶。<details>
<summary>Abstract</summary>
Large language models (LLMs) have exploded in popularity due to their ability to perform a wide array of natural language tasks. Text-based content moderation is one LLM use case that has received recent enthusiasm, however, there is little research investigating how LLMs perform in content moderation settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3, GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community moderation and toxic content detection. For rule-based community moderation, we construct 95 LLM moderation-engines prompted with rules from 95 Reddit subcommunities and find that LLMs can be effective at rule-based moderation for many communities, achieving a median accuracy of 64% and a median precision of 83%. For toxicity detection, we find that LLMs significantly outperform existing commercially available toxicity classifiers. However, we also find that recent increases in model size add only marginal benefit to toxicity detection, suggesting a potential performance plateau for LLMs on toxicity detection tasks. We conclude by outlining avenues for future work in studying LLMs and content moderation.
</details>
<details>
<summary>摘要</summary>
For rule-based community moderation, we created 95 LLM moderation engines using rules from 95 Reddit subcommunities. We found that LLMs can effectively moderate content for many communities, achieving a median accuracy of 64% and a median precision of 83%.For toxicity detection, we found that LLMs significantly outperformed existing commercial toxicity classifiers. However, we also found that increasing the size of the model only provided marginal benefits for toxicity detection, suggesting a potential performance plateau for LLMs on this task.Based on our findings, we outline potential avenues for future research on LLMs and content moderation.
</details></li>
</ul>
<hr>
<h2 id="Interaction-Aware-Decision-Making-for-Autonomous-Vehicles-in-Forced-Merging-Scenario-Leveraging-Social-Psychology-Factors"><a href="#Interaction-Aware-Decision-Making-for-Autonomous-Vehicles-in-Forced-Merging-Scenario-Leveraging-Social-Psychology-Factors" class="headerlink" title="Interaction-Aware Decision-Making for Autonomous Vehicles in Forced Merging Scenario Leveraging Social Psychology Factors"></a>Interaction-Aware Decision-Making for Autonomous Vehicles in Forced Merging Scenario Leveraging Social Psychology Factors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14497">http://arxiv.org/abs/2309.14497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Li, Kaiwen Liu, H. Eric Tseng, Anouck Girard, Ilya Kolmanovsky</li>
<li>for: 本研究旨在帮助自动驾驶车辆在复杂的交通场景中成功完成其驾驶任务，特别是在高速公路强制汇聚场景中。</li>
<li>methods: 本研究使用了社会行为模型，该模型考虑了交互的 drivers 的社会行为和个人目标。基于这个模型，我们开发了一种退火策略控制的决策策略，可以在线估计其他司机的意图，并在不确定的意图下预测附近车辆的行为。</li>
<li>results: 我们通过对比game理论控制器和实际交通数据进行了对比，证明了我们的决策策略的有效性。<details>
<summary>Abstract</summary>
Understanding the intention of vehicles in the surrounding traffic is crucial for an autonomous vehicle to successfully accomplish its driving tasks in complex traffic scenarios such as highway forced merging. In this paper, we consider a behavioral model that incorporates both social behaviors and personal objectives of the interacting drivers. Leveraging this model, we develop a receding-horizon control-based decision-making strategy, that estimates online the other drivers' intentions using Bayesian filtering and incorporates predictions of nearby vehicles' behaviors under uncertain intentions. The effectiveness of the proposed decision-making strategy is demonstrated and evaluated based on simulation studies in comparison with a game theoretic controller and a real-world traffic dataset.
</details>
<details>
<summary>摘要</summary>
理解周围交通中车辆的意图是自动驾驶车辆在复杂交通场景中成功完成驾驶任务的关键。在这篇论文中，我们考虑了一种行为模型，该模型包括交互驾驶员的社会行为和个人目标。利用这种模型，我们开发了一种往复控制基于决策策略，该策略在线上估计其他驾驶员的意图使用 bayesian 筛选，并在不确定意图下预测附近车辆的行为。我们通过模拟研究和与游戏理论控制器进行比较，证明了提议的决策策略的有效性。
</details></li>
</ul>
<hr>
<h2 id="Era-Splitting-–-Invariant-Learning-for-Decision-Trees"><a href="#Era-Splitting-–-Invariant-Learning-for-Decision-Trees" class="headerlink" title="Era Splitting – Invariant Learning for Decision Trees"></a>Era Splitting – Invariant Learning for Decision Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14496">http://arxiv.org/abs/2309.14496</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jefferythewind/era-splitting-notebook-examples">https://github.com/jefferythewind/era-splitting-notebook-examples</a></li>
<li>paper_authors: Timothy DeLise</li>
<li>For: The paper is written to address the issue of out-of-distribution (OOD) generalization in decision tree models, specifically random forest and gradient-boosting decision trees.* Methods: The paper proposes two new splitting criteria for decision trees that incorporate era-wise information into the splitting process, allowing the models to find split points that are optimal across all disjoint eras in the data.* Results: The paper describes unique experiments to showcase the benefits of the new splitting criteria, which improve metrics in the authors’ experiments out-of-sample. The new criteria are incorporated into a state-of-the-art gradient boosted decision tree model in the Scikit-Learn code base, which is made freely available.Here are the three key points in Simplified Chinese text:* For: 本研究是为了解决决策树模型中的外部数据泛化问题，特别是随机森林和梯度拟合决策树模型。* Methods: 本研究提出了两种新的分割 criterion，用于决策树模型中的分割过程中，以便在不同的时间和地点上进行数据分割。* Results: 本研究通过一系列唯一的实验，展示了新分割 criterion 的优势，可以在尝试样本中提高 metric 的表现。新 criterion 被 integrate 到 Scikit-Learn 代码库中的一个状态最佳的梯度拟合决策树模型中，并且免费释出。<details>
<summary>Abstract</summary>
Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optimal over the entire data set pooled together, which is the default setting. We describe the new splitting criteria in detail and develop unique experiments to showcase the benefits of these new criteria, which improve metrics in our experiments out-of-sample. The new criteria are incorporated into the a state-of-the-art gradient boosted decision tree model in the Scikit-Learn code base, which is made freely available.
</details>
<details>
<summary>摘要</summary>
The new splitting criteria use era-wise information associated with each data point to find split points that are optimal across all disjoint eras in the data, rather than optimal over the entire data set pooled together. We describe the new splitting criteria in detail and conduct unique experiments to demonstrate their benefits, which improve metrics out-of-sample.We have incorporated the new splitting criteria into a state-of-the-art gradient boosted decision tree model in the Scikit-Learn code base and made it freely available. This research provides a new approach to addressing distributional shifts in machine learning and improving the generalization of tree-based models.
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Deep-Learning-Technique-for-Morphology-Preserved-Fetal-ECG-Extraction-from-Mother-ECG-using-1D-CycleGAN"><a href="#A-Novel-Deep-Learning-Technique-for-Morphology-Preserved-Fetal-ECG-Extraction-from-Mother-ECG-using-1D-CycleGAN" class="headerlink" title="A Novel Deep Learning Technique for Morphology Preserved Fetal ECG Extraction from Mother ECG using 1D-CycleGAN"></a>A Novel Deep Learning Technique for Morphology Preserved Fetal ECG Extraction from Mother ECG using 1D-CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03759">http://arxiv.org/abs/2310.03759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Promit Basak, A. H. M Nazmus Sakib, Muhammad E. H. Chowdhury, Nasser Al-Emadi, Huseyin Cagatay Yalcin, Shona Pedersen, Sakib Mahmud, Serkan Kiranyaz, Somaya Al-Maadeed<br>for: 这个研究的目的是监测胎儿心脏的电压信号，以实现胎儿心脏疾病的早期诊断和后续照护。methods: 这个研究使用了1D CycleGAN来重建胎儿心脏电压信号，并且进行了广泛的预处理和适当的框架，以维持信号的结构。results: 这个研究的结果显示，使用1D CycleGAN重建胎儿心脏电压信号的方法可以获得高精度的胎儿心脏疾病诊断和胎儿心脏功能监测。这个方法可以实现胎儿心脏疾病的早期诊断和后续照护，并且与现有的相关技术相比，具有较高的精度和可靠性。<details>
<summary>Abstract</summary>
Monitoring the electrical pulse of fetal heart through a non-invasive fetal electrocardiogram (fECG) can easily detect abnormalities in the developing heart to significantly reduce the infant mortality rate and post-natal complications. Due to the overlapping of maternal and fetal R-peaks, the low amplitude of the fECG, systematic and ambient noises, typical signal extraction methods, such as adaptive filters, independent component analysis, empirical mode decomposition, etc., are unable to produce satisfactory fECG. While some techniques can produce accurate QRS waves, they often ignore other important aspects of the ECG. Our approach, which is based on 1D CycleGAN, can reconstruct the fECG signal from the mECG signal while maintaining the morphology due to extensive preprocessing and appropriate framework. The performance of our solution was evaluated by combining two available datasets from Physionet, "Abdominal and Direct Fetal ECG Database" and "Fetal electrocardiograms, direct and abdominal with reference heartbeat annotations", where it achieved an average PCC and Spectral-Correlation score of 88.4% and 89.4%, respectively. It detects the fQRS of the signal with accuracy, precision, recall and F1 score of 92.6%, 97.6%, 94.8% and 96.4%, respectively. It can also accurately produce the estimation of fetal heart rate and R-R interval with an error of 0.25% and 0.27%, respectively. The main contribution of our work is that, unlike similar studies, it can retain the morphology of the ECG signal with high fidelity. The accuracy of our solution for fetal heart rate and R-R interval length is comparable to existing state-of-the-art techniques. This makes it a highly effective tool for early diagnosis of fetal heart diseases and regular health checkups of the fetus.
</details>
<details>
<summary>摘要</summary>
监测胎儿心脏电压通过非侵入式胎儿电cardiogram (fECG) 可以轻松地检测胎儿心脏发育异常，从而减少新生儿死亡率和哺乳期后的合并症状。由于胎母和胎儿的R峰重叠，低强度fECG，系统性和 ambient 噪声，传统的信号提取方法，如适应过滤、独立 componenets 分析、empirical mode decomposition 等，通常无法生成满意的fECG。虽然一些技术可以生成准确的QRS波，但它们通常忽略了其他重要的ECG方面。我们的方法基于1D CycleGAN，可以从mECG信号中重建fECG信号，同时保持信号的形态，因为我们进行了广泛的预处理和适当的框架。我们的解决方案的性能得到了两个可用的Physionet数据集("Abdominal and Direct Fetal ECG Database"和"Fetal electrocardiograms, direct and abdominal with reference heartbeat annotations")的评估，其中获得了88.4%和89.4%的PCC和spectral-correlation分数。它可以准确地检测信号中的fQRS，并具有92.6%、97.6%、94.8%和96.4%的准确率、精度、回归率和F1分数。它还可以准确地计算胎儿心率和R-R间隔的误差，分别为0.25%和0.27%。我们的工作的主要贡献在于，与其他相似的研究不同，可以保持ECG信号的形态高度准确。我们的解决方案的准确率和R-R间隔长度与现有的状态 искусственный智能技术相当。这使得它成为了诊断胎心疾病的高效工具，以及哺乳期后胎心健康检查的重要工具。
</details></li>
</ul>
<hr>
<h2 id="When-Automated-Assessment-Meets-Automated-Content-Generation-Examining-Text-Quality-in-the-Era-of-GPTs"><a href="#When-Automated-Assessment-Meets-Automated-Content-Generation-Examining-Text-Quality-in-the-Era-of-GPTs" class="headerlink" title="When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs"></a>When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14488">http://arxiv.org/abs/2309.14488</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nd-hal/automated-ml-scoring-versus-generation">https://github.com/nd-hal/automated-ml-scoring-versus-generation</a></li>
<li>paper_authors: Marialena Bevilacqua, Kezia Oketch, Ruiyang Qin, Will Stamey, Xinyuan Zhang, Yi Gan, Kai Yang, Ahmed Abbasi</li>
<li>for: 这个论文主要研究了机器学习（ML）模型在文本数据评分中的应用和发展。</li>
<li>methods: 该论文使用了多种机器学习模型，包括文本生成大语言模型（GPTs）和卷积神经网络（CNN&#x2F;RNN），对人类生成的文本和GPT生成的文本进行评分和评估。</li>
<li>results: 研究发现，使用 transformer 预训练语言模型（PLMs）可以更准确地评分人类生成的文本质量，而 traditional deep learning 和特征基于的 ML 模型则更倾向于评分人类文本较高。此外，研究还发现，transformer PLMs 具有更强的泛化能力，可以更好地处理 GPT 生成的文本。<details>
<summary>Abstract</summary>
The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML-models, human and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that transformer pretrained language models (PLMs) more accurately score human essay quality as compared to CNN/RNN and feature-based ML methods. Interestingly, we find that the transformer PLMs tend to score GPT-generated text 10-15\% higher on average, relative to human-authored documents. Conversely, traditional deep learning and feature-based ML models score human text considerably higher. Further analysis reveals that although the transformer PLMs are exclusively fine-tuned on human text, they more prominently attend to certain tokens appearing only in GPT-generated text, possibly due to familiarity/overlap in pre-training. Our framework and results have implications for text classification settings where automated scoring of text is likely to be disrupted by generative AI.
</details>
<details>
<summary>摘要</summary>
使用机器学习（ML）模型评分文本数据已经在多种场景中广泛应用，包括自然语言处理、信息检索、搜索和推荐、以及在线内容可靠性评分。一种 significante 的干预在机器学习和文本之间的交叉处是文本生成大语言模型（GPTs）。我们employs一种分析框架，覆盖了文本评分ML模型、人类和GPTs生成的文本，以及一个简单的统计模型，考虑了评分模型的类型、提示类型和评分模型的影响。我们使用了一个丰富的测试环境，包括18,460个人类生成和GPTs生成的文本。我们的基准分析结果显示，transformer预训练语言模型（PLMs）在评分人类文本质量方面更为准确，比起CNN/RNN和特征基于ML方法。另外，我们发现transformer PLMs对GPTs生成的文本进行评分，相对于人类写作的文本，提高了10-15%的平均分。然而，传统的深度学习和特征基于ML方法对人类文本进行评分，显著高于。进一步的分析表明，although transformer PLMs是仅仅特征基于人类文本进行finetune，它们更加强调在GPTs生成的文本中出现的某些字符，可能是因为预训练中的熟悉/重叠。我们的框架和结果对于文本分类设置，其中自动评分文本可能受到生成AI的干扰有重要意义。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Ensemble-and-Transfer-Learning-For-An-End-To-End-Auto-Colorized-Image-Detection-Model"><a href="#Incorporating-Ensemble-and-Transfer-Learning-For-An-End-To-End-Auto-Colorized-Image-Detection-Model" class="headerlink" title="Incorporating Ensemble and Transfer Learning For An End-To-End Auto-Colorized Image Detection Model"></a>Incorporating Ensemble and Transfer Learning For An End-To-End Auto-Colorized Image Detection Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14478">http://arxiv.org/abs/2309.14478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Samir Ragab, Shereen Aly Taie, Howida Youssry Abdelnaby</li>
<li>for: 这个论文旨在提出一种新的图像色调检测方法，用于分辨天然颜色图像和计算机色调图像。</li>
<li>methods: 该方法结合了传输学习和集成学习的优点，并使用预训练的VGG16和Resnet50树脊，以及Mobile Net v2或Efficientnet特征向量。</li>
<li>results: 该模型在分类性能和泛化能力方面表现出色，准确率在94.55%到99.13%之间，偏差总错误率很低。与现有状态的先进模型相比，该模型表现出了更高的分类性能和泛化能力。<details>
<summary>Abstract</summary>
Image colorization is the process of colorizing grayscale images or recoloring an already-color image. This image manipulation can be used for grayscale satellite, medical and historical images making them more expressive. With the help of the increasing computation power of deep learning techniques, the colorization algorithms results are becoming more realistic in such a way that human eyes cannot differentiate between natural and colorized images. However, this poses a potential security concern, as forged or illegally manipulated images can be used illegally. There is a growing need for effective detection methods to distinguish between natural color and computer-colorized images. This paper presents a novel approach that combines the advantages of transfer and ensemble learning approaches to help reduce training time and resource requirements while proposing a model to classify natural color and computer-colorized images. The proposed model uses pre-trained branches VGG16 and Resnet50, along with Mobile Net v2 or Efficientnet feature vectors. The proposed model showed promising results, with accuracy ranging from 94.55% to 99.13% and very low Half Total Error Rate values. The proposed model outperformed existing state-of-the-art models regarding classification performance and generalization capabilities.
</details>
<details>
<summary>摘要</summary>
Image colorization是将灰度图像或已经颜色化的图像中的颜色更改的过程。这种图像修改可以用于灰度卫星图像、医疗图像和历史图像等，使其更加表达力。随着深度学习技术的计算能力的提高，图像色化算法的结果变得越来越真实，以至于人眼无法分辨天然颜色和计算机颜色化图像之间的差异。然而，这也带来了安全性问题，因为假或非法修改的图像可以用于违法活动。随着需求的增长，有效地检测天然颜色和计算机颜色化图像的方法变得越来越重要。本文提出了一种新的方法，该方法结合了传输学习和集成学习的优点，以减少训练时间和资源需求，并提出了一种用于分类天然颜色和计算机颜色化图像的模型。该模型使用预训练分支VGG16和Resnet50，以及Mobile Net v2或Efficientnet特征向量。该模型的实验结果表现出色，准确率在94.55%至99.13%之间，并且半总错误率很低。该模型超越了现有的状态对模型，以 regards to classification performance和总体能力。
</details></li>
</ul>
<hr>
<h2 id="Adapting-Double-Q-Learning-for-Continuous-Reinforcement-Learning"><a href="#Adapting-Double-Q-Learning-for-Continuous-Reinforcement-Learning" class="headerlink" title="Adapting Double Q-Learning for Continuous Reinforcement Learning"></a>Adapting Double Q-Learning for Continuous Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14471">http://arxiv.org/abs/2309.14471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arsenii Kuznetsov</li>
<li>for: 这个论文主要针对off-policy reinforcement learning中的偏高偏估问题，提出了一种新的偏估控制方法。</li>
<li>methods: 该方法基于一个混合策略，每个策略组件由两个分立的网络评估，从而消除了基于偏估的假设。</li>
<li>results: 该方法在一些MuJoCo环境中达到了near-SOTA的result，显示了其可行性和有效性。<details>
<summary>Abstract</summary>
Majority of off-policy reinforcement learning algorithms use overestimation bias control techniques. Most of these techniques rooted in heuristics, primarily addressing the consequences of overestimation rather than its fundamental origins. In this work we present a novel approach to the bias correction, similar in spirit to Double Q-Learning. We propose using a policy in form of a mixture with two components. Each policy component is maximized and assessed by separate networks, which removes any basis for the overestimation bias. Our approach shows promising near-SOTA results on a small set of MuJoCo environments.
</details>
<details>
<summary>摘要</summary>
大多数Off-policy reinforcement learning算法使用过估偏调技术。这些技术基于规则，主要是解决过估的后果而不是其基本原因。在这项工作中，我们提出了一种新的偏调修正方法，类似于Double Q-Learning。我们提议使用一个策略组合，其中每个策略组件是由两个分开的网络评估和最大化。这种方法可以消除任何基于过估偏调的基础。我们的方法在一些MuJoCo环境上显示了有优的近SOTA结果。
</details></li>
</ul>
<hr>
<h2 id="DefGoalNet-Contextual-Goal-Learning-from-Demonstrations-For-Deformable-Object-Manipulation"><a href="#DefGoalNet-Contextual-Goal-Learning-from-Demonstrations-For-Deformable-Object-Manipulation" class="headerlink" title="DefGoalNet: Contextual Goal Learning from Demonstrations For Deformable Object Manipulation"></a>DefGoalNet: Contextual Goal Learning from Demonstrations For Deformable Object Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14463">http://arxiv.org/abs/2309.14463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bao Thach, Tanner Watts, Shing-Hei Ho, Tucker Hermans, Alan Kuntz</li>
<li>for: 解决控制柔体物体到目标形状的问题，即shape servoing问题。</li>
<li>methods: 开发了一种基于神经网络的 DefGoalNet，可以直接从人类示范中学习柔体物体目标形状。</li>
<li>results: 在 simulate 和physical robot 上进行了多种任务测试，包括手术压缩任务，并达到了高达90%的成功率，表明该方法可以有效地解决shape servoing问题， bringing deformable object manipulation closer to practical, real-world applications.<details>
<summary>Abstract</summary>
Shape servoing, a robotic task dedicated to controlling objects to desired goal shapes, is a promising approach to deformable object manipulation. An issue arises, however, with the reliance on the specification of a goal shape. This goal has been obtained either by a laborious domain knowledge engineering process or by manually manipulating the object into the desired shape and capturing the goal shape at that specific moment, both of which are impractical in various robotic applications. In this paper, we solve this problem by developing a novel neural network DefGoalNet, which learns deformable object goal shapes directly from a small number of human demonstrations. We demonstrate our method's effectiveness on various robotic tasks, both in simulation and on a physical robot. Notably, in the surgical retraction task, even when trained with as few as 10 demonstrations, our method achieves a median success percentage of nearly 90%. These results mark a substantial advancement in enabling shape servoing methods to bring deformable object manipulation closer to practical, real-world applications.
</details>
<details>
<summary>摘要</summary>
shape servoing, a robotic task focused on controlling objects to desired goal shapes, is a promising approach to deformable object manipulation. however, a challenge arises with the reliance on the specification of a goal shape. this goal has been obtained either through a laborious domain knowledge engineering process or by manually manipulating the object into the desired shape and capturing the goal shape at that specific moment, both of which are impractical in various robotic applications. in this paper, we solve this problem by developing a novel neural network DefGoalNet, which learns deformable object goal shapes directly from a small number of human demonstrations. we demonstrate our method's effectiveness on various robotic tasks, both in simulation and on a physical robot. notably, in the surgical retraction task, even when trained with as few as 10 demonstrations, our method achieves a median success percentage of nearly 90%. these results mark a substantial advancement in enabling shape servoing methods to bring deformable object manipulation closer to practical, real-world applications.
</details></li>
</ul>
<hr>
<h2 id="Online-Active-Learning-For-Sound-Event-Detection"><a href="#Online-Active-Learning-For-Sound-Event-Detection" class="headerlink" title="Online Active Learning For Sound Event Detection"></a>Online Active Learning For Sound Event Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14460">http://arxiv.org/abs/2309.14460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Lindsey, Ankit Shah, Francis Kubala, Richard M. Stern</li>
<li>for: 这篇论文是为了提高Sound Event Detection（SED）中的监督学习效率而写的。</li>
<li>methods: 这篇论文使用了线上活动学习（OAL）来减少监督学习需要的时间和努力。它还使用了新的损失函数来解决现有OAL方法中的问题，例如气流分布的变化和数据漂移。</li>
<li>results: 实验结果显示，使用OAL可以将SED监督学习的时间和努力缩减到SONYC dataset中的一半，并且新的方法可以成功地解决现有OAL方法中的问题。<details>
<summary>Abstract</summary>
Data collection and annotation is a laborious, time-consuming prerequisite for supervised machine learning tasks. Online Active Learning (OAL) is a paradigm that addresses this issue by simultaneously minimizing the amount of annotation required to train a classifier and adapting to changes in the data over the duration of the data collection process. Prior work has indicated that fluctuating class distributions and data drift are still common problems for OAL. This work presents new loss functions that address these challenges when OAL is applied to Sound Event Detection (SED). Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.
</details>
<details>
<summary>摘要</summary>
数据收集和注释是超级vised机器学习任务的必要前置条件，但它们是时间consuming和劳动密集的。在线活动学习（OAL）是一种方法，它同时减少了训练分类器所需的注释量和适应数据的变化过程中的数据风险。前一个研究表示，在OAL中仍然存在涨落分布和数据漂移的问题。这个工作提出了新的损失函数，以解决这些问题在音频事件检测（SED）领域中。实验结果来自SONYC数据集和两个语音类型识别（VTD） corpora，表明OAL可以将SED分类器训练所需的时间和劳动量减少到SONYC数据集的5倍，并且新的方法在现有OAL方法中成功解决了问题。
</details></li>
</ul>
<hr>
<h2 id="Self-Recovery-Prompting-Promptable-General-Purpose-Service-Robot-System-with-Foundation-Models-and-Self-Recovery"><a href="#Self-Recovery-Prompting-Promptable-General-Purpose-Service-Robot-System-with-Foundation-Models-and-Self-Recovery" class="headerlink" title="Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery"></a>Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14425">http://arxiv.org/abs/2309.14425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mimo Shirasaka, Tatsuya Matsushima, Soshi Tsunashima, Yuya Ikeda, Aoi Horo, So Ikoma, Chikaha Tsuji, Hikaru Wada, Tsunekazu Omija, Dai Komukai, Yutaka Matsuo Yusuke Iwasawa</li>
<li>for: 本研究旨在开发一个可以执行多种任务的通用服务机器人（GPSR），需要一个高度普适和适应任务和环境的系统。</li>
<li>methods: 我们首先基于多个基础模型开发了一个高级GPSR系统，并通过让每个模型提示来使其普适和适应。</li>
<li>results: 我们发现在更实际的GPSR应用场景中存在三种类型的失败情况：缺乏信息、错误的规划生成和执行失败。我们则提出了自适应提示管道，以探索必要的信息并修改提示来恢复失败。我们的实验证明，具有自适应机制的系统可以完成任务并解决多种失败情况。<details>
<summary>Abstract</summary>
A general-purpose service robot (GPSR), which can execute diverse tasks in various environments, requires a system with high generalizability and adaptability to tasks and environments. In this paper, we first developed a top-level GPSR system for worldwide competition (RoboCup@Home 2023) based on multiple foundation models. This system is both generalizable to variations and adaptive by prompting each model. Then, by analyzing the performance of the developed system, we found three types of failure in more realistic GPSR application settings: insufficient information, incorrect plan generation, and plan execution failure. We then propose the self-recovery prompting pipeline, which explores the necessary information and modifies its prompts to recover from failure. We experimentally confirm that the system with the self-recovery mechanism can accomplish tasks by resolving various failure cases. Supplementary videos are available at https://sites.google.com/view/srgpsr .
</details>
<details>
<summary>摘要</summary>
一种通用服务机器人（GPSR），能够执行多种任务在多种环境中，需要一个高度通用和适应性的系统。在这篇论文中，我们首先基于多个基础模型开发了一个全面的GPSR系统，并通过提示每个模型来使其通用和适应性更高。然后，通过分析系统的性能，我们发现在更实际的GPSR应用场景中存在三种失败类型：不充分的信息、错误的计划生成和计划执行失败。我们提出了自动恢复提示管道，以探索所需的信息并修改提示来解决失败。我们通过实验证明，具有自动恢复机制的系统可以成功完成任务，并解决多种失败情况。补充视频可以在https://sites.google.com/view/srgpsr 中找到。
</details></li>
</ul>
<hr>
<h2 id="Extreme-Parkour-with-Legged-Robots"><a href="#Extreme-Parkour-with-Legged-Robots" class="headerlink" title="Extreme Parkour with Legged Robots"></a>Extreme Parkour with Legged Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14341">http://arxiv.org/abs/2309.14341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuxin Cheng, Kexin Shi, Ananye Agarwal, Deepak Pathak</li>
<li>for: 本研究旨在开发一种小型低成本机器人，以便它可以通过困难的满足某些难以控制的环境。</li>
<li>methods: 该研究使用一种单一的前视频摄像头和深度学习算法，以便从摄像头图像直接生成高精度控制行为。</li>
<li>results: 研究结果显示，该机器人可以通过跳高障碍物、跨越差距、悬停和跑过倾斜的坡道等动作，并可以在新的障碍物环境中进行普适化。<details>
<summary>Abstract</summary>
Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eye-muscle coordination and movement. Getting robots to do the same task requires overcoming similar challenges. Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances. This restricts them to tightly controlled settings such as a predetermined obstacle course in labs. In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology. In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts. We show how a single neural net policy operating directly from a camera image, trained in simulation with large-scale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end. We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties. Parkour videos at https://extreme-parkour.github.io/
</details>
<details>
<summary>摘要</summary>
人类可以通过穿梭障碍物来完成公园OUR，需要精准的眼睛肌肉协调和运动。为了让机器人做同样的任务，需要超越类似的挑战。传统上，这是通过独立地工程感知、行动和控制系统来实现的，这会限制它们只能在严格控制的室内预先设定的赛跑课程中运行。与此相反，人类可以通过练习而不是改变基本生物结构来学习公园OUR。在这篇论文中，我们采用类似的方法，使用一个小型低成本机器人，具有不精准的运动和单个前方深度摄像头来感知，它的摄像头图像是低频、颤动和噪声易产生的。我们证明了一个单一神经网络策略，直接从摄像头图像中获取控制行为，通过大规模RL在模拟中训练，可以超越不精准的感知和运动，并输出高精度的控制行为。我们的机器人可以跳高障碍物2倍其高度，跳跃差2倍其长度，执行手stand和跑在倾斜的滚动道上，并可以通过不同物理特性的新障碍课程进行扩展。有关公园OUR视频，请参考https://extreme-parkour.github.io/
</details></li>
</ul>
<hr>
<h2 id="Joint-Audio-and-Speech-Understanding"><a href="#Joint-Audio-and-Speech-Understanding" class="headerlink" title="Joint Audio and Speech Understanding"></a>Joint Audio and Speech Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14405">http://arxiv.org/abs/2309.14405</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YuanGongND/ltu">https://github.com/YuanGongND/ltu</a></li>
<li>paper_authors: Yuan Gong, Alexander H. Liu, Hongyin Luo, Leonid Karlinsky, James Glass</li>
<li>for: 这篇论文旨在构建一个基于机器学习的听说识别和理解模型，以便更好地理解人类听说信号中的语音和非语音声音。</li>
<li>methods: 该模型基于 integrate Whisper 和 LLaMA 两个模块，分别用于听说识别和理解语音和非语音声音。</li>
<li>results: 模型可以同时识别和理解语音和非语音声音，包括语音和非语音声音的识别、语音特征提取、语音识别和语音理解等任务。<details>
<summary>Abstract</summary>
Humans are surrounded by audio signals that include both speech and non-speech sounds. The recognition and understanding of speech and non-speech audio events, along with a profound comprehension of the relationship between them, constitute fundamental cognitive capabilities. For the first time, we build a machine learning model, called LTU-AS, that has a conceptually similar universal audio perception and advanced reasoning ability. Specifically, by integrating Whisper as a perception module and LLaMA as a reasoning module, LTU-AS can simultaneously recognize and jointly understand spoken text, speech paralinguistics, and non-speech audio events - almost everything perceivable from audio signals.
</details>
<details>
<summary>摘要</summary>
人类在听到各种各样的声音信号周围，包括语音和非语音声音。认识和理解语音和非语音声音事件，以及对它们之间的关系的深入理解，是人类的基本认知能力。我们现在第一次建立了一个机器学习模型，即LTU-AS，它具有类似于人类听觉的概念性和高级逻辑能力。具体来说，通过将Whisper作为感知模块和LLaMA作为逻辑模块相结合，LTU-AS可以同时认识和共同理解说话文本、语音非语言特征和非语音声音事件——大致上来说，听到 audio 信号中的一切可见事物。
</details></li>
</ul>
<hr>
<h2 id="UnitedHuman-Harnessing-Multi-Source-Data-for-High-Resolution-Human-Generation"><a href="#UnitedHuman-Harnessing-Multi-Source-Data-for-High-Resolution-Human-Generation" class="headerlink" title="UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation"></a>UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14335">http://arxiv.org/abs/2309.14335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/unitedhuman/unitedhuman">https://github.com/unitedhuman/unitedhuman</a></li>
<li>paper_authors: Jianglin Fu, Shikai Li, Yuming Jiang, Kwan-Yee Lin, Wayne Wu, Ziwei Liu</li>
<li>for: 提高人像生成质量</li>
<li>methods: 多源数据集合并学习高分辨率人像生成模型</li>
<li>results: 与单一数据集学习的模型相比，通过jointly learning from multi-source data achieve superior quality in human image generation.<details>
<summary>Abstract</summary>
Human generation has achieved significant progress. Nonetheless, existing methods still struggle to synthesize specific regions such as faces and hands. We argue that the main reason is rooted in the training data. A holistic human dataset inevitably has insufficient and low-resolution information on local parts. Therefore, we propose to use multi-source datasets with various resolution images to jointly learn a high-resolution human generative model. However, multi-source data inherently a) contains different parts that do not spatially align into a coherent human, and b) comes with different scales. To tackle these challenges, we propose an end-to-end framework, UnitedHuman, that empowers continuous GAN with the ability to effectively utilize multi-source data for high-resolution human generation. Specifically, 1) we design a Multi-Source Spatial Transformer that spatially aligns multi-source images to full-body space with a human parametric model. 2) Next, a continuous GAN is proposed with global-structural guidance and CutMix consistency. Patches from different datasets are then sampled and transformed to supervise the training of this scale-invariant generative model. Extensive experiments demonstrate that our model jointly learned from multi-source data achieves superior quality than those learned from a holistic dataset.
</details>
<details>
<summary>摘要</summary>
人类生成技术已经取得了 significiant 的进步，然而现有的方法仍然困难将特定的区域如面部和手臂等生成出来。我们认为这主要的原因在于训练数据。总体的人类数据集缺乏和低分辨率的地方部分信息，因此我们提议使用多源数据集，包括不同分辨率的图像，并将其集成到一个高分辨率的人类生成模型中。然而，多源数据集具有以下两个挑战：一是不同的部分不能够在一个准确的人类空间中匹配，二是不同的数据集来源的图像尺寸不同。为了解决这些挑战，我们提出了一个综合框架，名为 UnitedHuman，它使得 kontinuous GAN 能够有效地利用多源数据来生成高分辨率的人类图像。具体来说，我们设计了一个 Multi-Source Spatial Transformer，它将多源图像转换到全身人类空间中，并使用人类参数模型来进行匹配。然后，我们提出了一个 kontinuous GAN，它具有全STRUCTURE 导向和 CutMix 一致性。不同的数据集中的小块被随机选择并转换，以supervise  kontinuous GAN 的训练。我们的实验表明，我们从多源数据集中 JOINTLY 学习的模型可以超过来自整体数据集的模型。
</details></li>
</ul>
<hr>
<h2 id="LinGCN-Structural-Linearized-Graph-Convolutional-Network-for-Homomorphically-Encrypted-Inference"><a href="#LinGCN-Structural-Linearized-Graph-Convolutional-Network-for-Homomorphically-Encrypted-Inference" class="headerlink" title="LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference"></a>LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14331">http://arxiv.org/abs/2309.14331</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harveyp123/lingcn-neurips23">https://github.com/harveyp123/lingcn-neurips23</a></li>
<li>paper_authors: Hongwu Peng, Ran Ran, Yukui Luo, Jiahui Zhao, Shaoyi Huang, Kiran Thorat, Tong Geng, Chenghong Wang, Xiaolin Xu, Wujie Wen, Caiwen Ding</li>
<li>for: 这个论文是为了提高Graph Convolution Network (GCN)模型的安全性和可扩展性而写的。</li>
<li>methods: 这个论文使用了Homomorphic Encryption (HE)技术来保护客户端数据，并且提出了一个名为LinGCN的框架，用于实现GCN模型的加密运算。LinGCN使用了分别为node-wise non-linear location selection和compact node-wise polynomial replacement policy两个关键元素，以提高GCN模型的性能和可扩展性。</li>
<li>results: 这个论文的实验结果显示，LinGCN在NTU-XVIEW skeleton joint dataset上具有较高的延迟速度、准确率和可扩展性，相比CryptoGCN等其他解决方案。具体来说，LinGCN在GCN模型的加密运算中实现了14.2倍的延迟速度提升，保持了75%的准确率，并且降低了 multiplication depth。<details>
<summary>Abstract</summary>
The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems. The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data. To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data. However, it introduces substantial computational overhead in practical applications. To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference. LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal. This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth. (2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model. (3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN. Remarkably, LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving an inference accuracy of 75% and notably reducing multiplication depth.
</details>
<details>
<summary>摘要</summary>
Graph Convolutional Network (GCN) 模型的发展已经革命化了许多应用程序，超过了人类表现在个人健康监测和金融系统等领域。但是在云端部署GCNs时，隐私问题引起了关注，因为可能会发生对客户数据的敌意攻击。为解决安全问题，使用了同源加密（HE）来保护敏感客户数据。然而，HE引入了实际应用中的重要计算开销。为了解决这些挑战，我们提出了LinGCN框架，用于降低 multiplication depth并优化HE基于GCN的推理性能。LinGCN框架包括三个关键元素：1. 可微分结构线性化算法，并且通过一个参数化的整数指示函数，与模型参数进行共训练，以达到优化目标。这种策略可以实现精细化节点级非线性位置选择，从而降低 multiplication depth。2. 一种减少 multiplication depth的紧凑型节点值替换策略，通过一个二次可训练的活化函数，由一个两级液态灵感法推导，从一个所有ReLU基于教师模型中学习。3. 一种可以进一步减少HE基于节点活化函数的 multiplication level 的加强HE解决方案。我们的实验表明，LinGCN在NTU-XVIEW骨架联合数据集上表现出了较高的延迟、准确率和扩展性，与CRYPTOGCN相比，LinGCN可以实现14.2倍的延迟速度提升，保持75%的推理精度，同时减少 multiplication depth。
</details></li>
</ul>
<hr>
<h2 id="Innovative-Digital-Storytelling-with-AIGC-Exploration-and-Discussion-of-Recent-Advances"><a href="#Innovative-Digital-Storytelling-with-AIGC-Exploration-and-Discussion-of-Recent-Advances" class="headerlink" title="Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances"></a>Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14329">http://arxiv.org/abs/2309.14329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rongzhang Gu, Hui Li, Changyue Su, Wayne Wu</li>
<li>for: 这个研究的目的是提高人们对将AI生成内容（AIGC）与数字故事创作的结合现状、局限性和挑战的认识。</li>
<li>methods: 这篇论文使用了现有的AIGC技术和数字故事创作工具，并通过实验和专家采访来研究AIGC与数字故事创作的整体效果和挑战。</li>
<li>results: 研究发现，虽然AIGC可以快速生成图片、音频和音效，但是在复杂的人物动画、表情和声音效果方面，人类仍然无法被代表。此外，AIGC与数字故事创作的结合还存在许多挑战和限制，如人工创作的灵活性和艺术感受的缺失。<details>
<summary>Abstract</summary>
Digital storytelling, as an art form, has struggled with cost-quality balance. The emergence of AI-generated Content (AIGC) is considered as a potential solution for efficient digital storytelling production. However, the specific form, effects, and impacts of this fusion remain unclear, leaving the boundaries of AIGC combined with storytelling undefined. This work explores the current integration state of AIGC and digital storytelling, investigates the artistic value of their fusion in a sample project, and addresses common issues through interviews. Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects. The research objective is to increase public awareness of the current state, limitations, and challenges arising from combining AIGC and digital storytelling.
</details>
<details>
<summary>摘要</summary>
“数字storytelling”作为艺术形式，困惑于成本质量平衡。人工智能生成内容（AIGC）的出现被视为可能解决高效数字storytelling生产的问题。然而，这两者的结合的具体形式、效果和影响仍然不清楚，“数字storytelling”与AIGC的界限未定。本研究探讨了AIGC与数字storytelling的当前整合状况，研究了这两者艺术价值的融合效果，并通过采访 Addressing common issues. Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects. The research objective is to increase public awareness of the current state, limitations, and challenges arising from combining AIGC and digital storytelling.
</details></li>
</ul>
<hr>
<h2 id="Physics-of-Language-Models-Part-3-2-Knowledge-Manipulation"><a href="#Physics-of-Language-Models-Part-3-2-Knowledge-Manipulation" class="headerlink" title="Physics of Language Models: Part 3.2, Knowledge Manipulation"></a>Physics of Language Models: Part 3.2, Knowledge Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14402">http://arxiv.org/abs/2309.14402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyuan Allen-Zhu, Yuanzhi Li<br>for:This paper explores the ability of language models to manipulate stored knowledge during inference, specifically focusing on four manipulation types: retrieval, classification, comparison, and inverse search.methods:The authors use pre-trained language models like GPT2&#x2F;3&#x2F;4 and employ Chain of Thoughts (CoTs) during both training and inference to improve performance on simple classification and comparison tasks.results:The paper finds that language models struggle with simple classification and comparison tasks unless CoTs are employed, and they perform poorly in inverse knowledge search, even with adequate instruct fine-tuning. The primary contribution of the paper is a synthetic dataset for a controlled experiment that confirms these inherent weaknesses in language models.Here is the text in Simplified Chinese:for:这篇论文探讨了语言模型在推理过程中是否可以有效地把已经存储的知识 manipulate。methods:作者使用了预训练的语言模型如GPT2&#x2F;3&#x2F;4，并在推理过程中使用链条思维（CoTs）来提高简单的分类和比较任务的性能。results:论文发现，语言模型在简单的分类和比较任务上需要使用CoTs才能够有效地完成，而且它们在反向知识搜索任务中表现不佳，即使有足够的指导 fine-tuning。Primary contribution是一个控制实验的synthetic数据集，以confirm这些语言模型内在的劣势。<details>
<summary>Abstract</summary>
Language models can store vast amounts of factual knowledge, but their ability to use this knowledge for logical reasoning remains questionable. This paper explores a language model's ability to manipulate its stored knowledge during inference. We focus on four manipulation types: retrieval (e.g., "What is person A's attribute X"), classification (e.g., "Is A's attribute X even or odd?"), comparison (e.g., "Is A greater than B in attribute X?") and inverse search (e.g., "Which person's attribute X equals T?")   We observe that pre-trained language models like GPT2/3/4 excel in knowledge retrieval but struggle with simple classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. They also perform poorly in inverse knowledge search, irrespective of the prompts. Our primary contribution is a synthetic dataset for a controlled experiment that confirms these inherent weaknesses: a language model cannot efficiently manipulate knowledge from pre-training data, even when such knowledge is perfectly stored and fully extractable in the models, and despite adequate instruct fine-tuning.
</details>
<details>
<summary>摘要</summary>
语言模型可以存储庞大的 фактические知识，但它们在逻辑推理方面的能力仍然存在问题。这篇论文探讨了语言模型在推理过程中如何 manipulate 存储的知识。我们关注了四种推理方法：提取（例如，"人A的特征X是什么？）、分类（例如，"A的特征X是偶数或奇数？）、比较（例如，"A是B在特征X方面大吗？）以及反向搜索（例如，"谁的特征X等于T？）。我们发现，预训练的语言模型如GPT2/3/4在知识提取方面表现出色，但在简单的分类或比较任务中，除非使用链接思维（CoTs），否则表现不佳。它们还在反向知识搜索方面表现不佳，不管提示是什么。我们的主要贡献是一个控制性的 synthetic 数据集，用于确认这些内在的弱点：语言模型不能效率地从预训练数据中提取知识，即使这些知识完全可以在模型中提取并且受到了充分的训练精化。
</details></li>
</ul>
<hr>
<h2 id="Physics-of-Language-Models-Part-3-1-Knowledge-Storage-and-Extraction"><a href="#Physics-of-Language-Models-Part-3-1-Knowledge-Storage-and-Extraction" class="headerlink" title="Physics of Language Models: Part 3.1, Knowledge Storage and Extraction"></a>Physics of Language Models: Part 3.1, Knowledge Storage and Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14316">http://arxiv.org/abs/2309.14316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyuan Allen Zhu, Yuanzhi Li</li>
<li>for: 本研究探讨了大语言模型是否真正从知识源中提取信息，或者只是通过在训练中遇到类似的问题来回答问题。</li>
<li>methods: 本研究使用控制的半人工生物графи信息来进行深入研究这个问题。</li>
<li>results: 研究发现，模型的知识提取能力与不同多样性度指标的训练数据相关。通过近似线性探测，发现模型在隐藏嵌入名词的位置或者在训练文本中的其他符号的嵌入位置上线性编码知识属性强相关。<details>
<summary>Abstract</summary>
Large language models can store extensive world knowledge, often extractable through question-answering (e.g., "What is Abraham Lincoln's birthday?"). However, it's unclear whether the model answers questions based on exposure to exact/similar questions during training, or if it genuinely extracts knowledge from the source (e.g., Wikipedia biographies).   In this paper, we conduct an in-depth study of this problem using a controlled set of semi-synthetic biography data. We uncover a relationship between the model's knowledge extraction ability and different diversity measures of the training data. We conduct (nearly) linear probing, revealing a strong correlation between this relationship and whether the model (nearly) linearly encodes the knowledge attributes at the hidden embedding of the entity names, or across the embeddings of other tokens in the training text.
</details>
<details>
<summary>摘要</summary>
大型语言模型可以储存广泛的世界知识，通常通过问答（例如，“亚伯拉罕林肯的生日是什么？）来抽出知识。然而，是否 modelo 回答问题基于训练时期所曝露的具体/相似问题，或是它实际提取知识从源（例如，Wikipedia 传记），这是一个未知的问题。在这篇论文中，我们透过一个控制的半人工生物agraph 数据集进行了深入的研究。我们发现了知识提取能力和不同多样性度量的训练数据之间的关系。我们进行了（近乎）直线探索，发现这个关系和模型（近乎）直线将知识属性嵌入到实体名称的隐藏嵌入中，或者在训练文本中的其他 tokens 的嵌入中。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Different-Explanations-for-Image-Classifiers"><a href="#Multiple-Different-Explanations-for-Image-Classifiers" class="headerlink" title="Multiple Different Explanations for Image Classifiers"></a>Multiple Different Explanations for Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14309">http://arxiv.org/abs/2309.14309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hana Chockler, David A. Kelly, Daniel Kroening</li>
<li>for: 提供多个预测结果的算法和工具，以帮助理解黑盒图像分类器的行为。</li>
<li>methods: 基于 causal 理论，使用原理导向的方法计算多个预测结果。</li>
<li>results: 在 ImageNet-mini benchmark 上，REX 算法可以对 7 倍更多的图像进行多个预测结果计算，与之前的工作具有显著的提升。<details>
<summary>Abstract</summary>
Existing explanation tools for image classifiers usually give only one single explanation for an image. For many images, however, both humans and image classifiers accept more than one explanation for the image label. Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier. In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image. Our algorithm uses a principled approach based on causal theory. We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark.
</details>
<details>
<summary>摘要</summary>
现有的图像分类器解释工具通常只给出一个图像的解释。然而，许多图像都可以由人类和图像分类器接受多个解释。因此，只给出一个解释将限制我们对分类器的行为的理解。在这篇论文中，我们描述了一种算法和工具，即REX，用于计算一个黑板图像分类器的输出对某图像的多个解释。我们的算法基于 causal theory，我们分析了其理论复杂性，并提供了实验结果，显示REX在ImageNet-mini benchmark上可以对7个图像计算多个解释。
</details></li>
</ul>
<hr>
<h2 id="Overview-of-Class-Activation-Maps-for-Visualization-Explainability"><a href="#Overview-of-Class-Activation-Maps-for-Visualization-Explainability" class="headerlink" title="Overview of Class Activation Maps for Visualization Explainability"></a>Overview of Class Activation Maps for Visualization Explainability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14304">http://arxiv.org/abs/2309.14304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anh Pham Thi Minh</li>
<li>for: 本研究旨在概述过去几年内Class Activation Map（CAM）方法的演进，以及评价CAM的精度和可读性。</li>
<li>methods: 本研究使用了多种方法来评价CAM的精度和可读性，包括使用不同的评价指标和附加技术来提高CAM的精度和可读性。</li>
<li>results: 本研究发现了一些CAM方法的缺点和限制，并提出了未来研究的可能性，以提高CAM的可读性和精度。<details>
<summary>Abstract</summary>
Recent research in deep learning methodology has led to a variety of complex modelling techniques in computer vision (CV) that reach or even outperform human performance. Although these black-box deep learning models have obtained astounding results, they are limited in their interpretability and transparency which are critical to take learning machines to the next step to include them in sensitive decision-support systems involving human supervision. Hence, the development of explainable techniques for computer vision (XCV) has recently attracted increasing attention. In the realm of XCV, Class Activation Maps (CAMs) have become widely recognized and utilized for enhancing interpretability and insights into the decision-making process of deep learning models. This work presents a comprehensive overview of the evolution of Class Activation Map methods over time. It also explores the metrics used for evaluating CAMs and introduces auxiliary techniques to improve the saliency of these methods. The overview concludes by proposing potential avenues for future research in this evolving field.
</details>
<details>
<summary>摘要</summary>
Within the realm of XCV, Class Activation Maps (CAMs) have become widely recognized and utilized for enhancing interpretability and insights into the decision-making process of deep learning models. This overview provides a comprehensive review of the evolution of CAM methods over time, explores the metrics used for evaluating CAMs, and introduces auxiliary techniques to improve the saliency of these methods. The overview concludes by proposing potential avenues for future research in this rapidly evolving field.Translation notes:* "black-box" refers to the lack of transparency and interpretability of deep learning models.* "sensitive decision-support systems" refers to systems that require human supervision and involve critical decision-making.* "XCV" stands for "explainable computer vision".* "CAMs" stands for "Class Activation Maps".
</details></li>
</ul>
<hr>
<h2 id="Identifying-the-Risks-of-LM-Agents-with-an-LM-Emulated-Sandbox"><a href="#Identifying-the-Risks-of-LM-Agents-with-an-LM-Emulated-Sandbox" class="headerlink" title="Identifying the Risks of LM Agents with an LM-Emulated Sandbox"></a>Identifying the Risks of LM Agents with an LM-Emulated Sandbox</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15817">http://arxiv.org/abs/2309.15817</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ryoungj/toolemu">https://github.com/ryoungj/toolemu</a></li>
<li>paper_authors: Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao Zhou, Jimmy Ba, Yann Dubois, Chris J. Maddison, Tatsunori Hashimoto<br>for:The paper aims to address the challenges of identifying risks in Language Model (LM) agents and tools, such as leaking private data or causing financial losses, by introducing a framework called ToolEmu and an automatic safety evaluator.methods:The ToolEmu framework uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios without manual instantiation. The evaluator examines agent failures and quantifies associated risks.results:The tool emulator and evaluator were tested through human evaluation, and the results showed that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. The paper also provides a quantitative risk analysis of current LM agents and identifies numerous failures with potentially severe outcomes, highlighting the need to develop safer LM agents for real-world deployment.Here’s the simplified Chinese text:for: 这篇论文目标是解决语言模型（LM）代理和工具中的风险识别问题，如泄露private数据或者导致金融损失，通过引入工具模拟器（ToolEmu）和自动安全评估器。methods: 工具模拟器使用LM来模拟工具执行，无需手动实例化，可以测试LM代理在多种工具和enario下。自动安全评估器对代理失败进行评估并评估相关风险。results: 通过人工评估，工具模拟器和自动安全评估器的测试结果显示，68.8%的失败是真实的世界代理失败。论文还提供了当前LM代理的量化风险分析，并发现了许多可能导致严重后果的失败，高亮了需要开发更安全的LM代理 для实际应用。<details>
<summary>Abstract</summary>
Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes tools and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment.
</details>
<details>
<summary>摘要</summary>
近期语言模型（LM）代理和工具的应用，如ChatGPT插件，提供了一个富有可能性的功能集，但也扩大了潜在风险的范围 - 如泄露私人数据或导致财务损失。识别这些风险是劳动密集的，需要实施工具，手动设置测试enario的环境，并找到危险的场景。随着工具和代理的复杂度的增加，测试这些代理的成本将在不断增加，使得找到高度投资、长尾风险变得越来越困难。为解决这些挑战，我们引入 ToolEmu：一个基于LM的工具抽象框架，可以在多种工具和enario下测试LM代理，无需手动实例化。同时，我们开发了基于LM的自动安全评估工具，可以对代理失败进行评估，并评估相关风险。我们通过人工评估测试了ToolEmu和评估工具，发现68.8%的失败是真实世界中的代理失败。使用我们精心准备的初始准 benchmark，包括36个高度投资工具和144个测试场景，我们提供了一个量化风险分析，并发现当前LM代理中存在许多失败，其中23.9%的时间，最安全的LM代理也会出现这些失败。这表明需要为实际部署开发更安全的LM代理。
</details></li>
</ul>
<hr>
<h2 id="NAS-NeRF-Generative-Neural-Architecture-Search-for-Neural-Radiance-Fields"><a href="#NAS-NeRF-Generative-Neural-Architecture-Search-for-Neural-Radiance-Fields" class="headerlink" title="NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields"></a>NAS-NeRF: Generative Neural Architecture Search for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14293">http://arxiv.org/abs/2309.14293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeejith Nair, Yuhao Chen, Mohammad Javad Shafiee, Alexander Wong</li>
<li>for: 该文章的目的是提出一种基于神经网络搜索的NeRF架构优化策略，以实现在不同场景下达到高品质synthesis的同时控制计算复杂性。</li>
<li>methods: 该方法使用神经网络搜索策略来生成适应不同场景的NeRF架构，并通过约束目标synthesis质量指标和预算来引导搜索。</li>
<li>results: 实验结果表明，提议的NAS-NeRF可以生成比基eline NeRF更加小巧、快速和低耗的NeRF架构，而且在不同场景下都可以保持高品质synthesis。<details>
<summary>Abstract</summary>
Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but their high computational complexity limits deployability. While existing neural-based solutions strive for efficiency, they use one-size-fits-all architectures regardless of scene complexity. The same architecture may be unnecessarily large for simple scenes but insufficient for complex ones. Thus, there is a need to dynamically optimize the neural network component of NeRFs to achieve a balance between computational complexity and specific targets for synthesis quality. We introduce NAS-NeRF, a generative neural architecture search strategy that generates compact, scene-specialized NeRF architectures by balancing architecture complexity and target synthesis quality metrics. Our method incorporates constraints on target metrics and budgets to guide the search towards architectures tailored for each scene. Experiments on the Blender synthetic dataset show the proposed NAS-NeRF can generate architectures up to 5.74$\times$ smaller, with 4.19$\times$ fewer FLOPs, and 1.93$\times$ faster on a GPU than baseline NeRFs, without suffering a drop in SSIM. Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to 23$\times$ smaller, with 22$\times$ fewer FLOPs, and 4.7$\times$ faster than baseline NeRFs with only a 5.3% average SSIM drop. Our source code is also made publicly available at https://saeejithnair.github.io/NAS-NeRF.
</details>
<details>
<summary>摘要</summary>
神经震荡场（NeRF）可以实现高质量的新视图合成，但是它们的计算复杂性限制了它们的部署。现有的神经网络解决方案尽量减少计算复杂性，但是它们使用一个适用于所有场景的 Architecture，无论场景的复杂性如何。这种 Architecture 可能是对简单场景来说过大，对复杂场景来说则不够。因此，有一个需要 dynamically optimize NeRF 的神经网络组件，以达到计算复杂性和特定目标的平衡。我们介绍了 NAS-NeRF，一种生成神经架构搜索策略，可以生成适合场景的 Compact 和 Scene-Specialized NeRF 架构，并且可以根据目标合成质量指标和预算来导引搜索。我们的方法可以在 Blender synthetic 数据集上实现，并且可以生成与基eline NeRF 相比，5.74倍小、4.19倍 fewer FLOPs、1.93倍快于 GPU 上的 NeRF 架构，而无需做出 SSIM 下降。此外，我们还证明了 NAS-NeRF 可以生成与基eline NeRF 相比，23倍小、22倍 fewer FLOPs、4.7倍快于 GPU 上的 NeRF 架构，只有5.3%的 average SSIM 下降。我们的源代码也公开发布在 <https://saeejithnair.github.io/NAS-NeRF>。
</details></li>
</ul>
<hr>
<h2 id="Perception-and-Energy-aware-Motion-Planning-for-UAV-using-Learning-based-Model-under-Heteroscedastic-Uncertainty"><a href="#Perception-and-Energy-aware-Motion-Planning-for-UAV-using-Learning-based-Model-under-Heteroscedastic-Uncertainty" class="headerlink" title="Perception-and-Energy-aware Motion Planning for UAV using Learning-based Model under Heteroscedastic Uncertainty"></a>Perception-and-Energy-aware Motion Planning for UAV using Learning-based Model under Heteroscedastic Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14272">http://arxiv.org/abs/2309.14272</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/rei08/perception-energy-planner">https://gitlab.com/rei08/perception-energy-planner</a></li>
<li>paper_authors: Reiya Takemura, Genya Ishigami</li>
<li>for: 本研究旨在帮助无人航空器（UAV）在Global Navigation Satellite Systems（GNSS） denied环境中能够能量高效、可靠地飞行。</li>
<li>methods: 该研究提出了一种基于感知和能源的动作规划算法，用于解决UAV在GNSS denied环境中的轨迹规划问题。该算法优化了一个权重因子，包括UAV的总能量消耗和LiDAR探测器 mounted on UAV 的感知质量。在线导航之前，高精度模拟器从实际飞行数据中学习了UAV的能量消耗和LiDAR测量的不确定性，以便在线导航时能够更好地估算这些参数。</li>
<li>results: 对比实际环境中的 fotorealistic 环境，实验结果表明，提出的算法可以在不确定性下进行权衡，以提高UAV的能效性和感知质量。开源代码可以在 <a target="_blank" rel="noopener" href="https://gitlab.com/ReI08/perception-energy-planner">https://gitlab.com/ReI08/perception-energy-planner</a> 上下载。<details>
<summary>Abstract</summary>
Global navigation satellite systems (GNSS) denied environments/conditions require unmanned aerial vehicles (UAVs) to energy-efficiently and reliably fly. To this end, this study presents perception-and-energy-aware motion planning for UAVs in GNSS-denied environments. The proposed planner solves the trajectory planning problem by optimizing a cost function consisting of two indices: the total energy consumption of a UAV and the perception quality of light detection and ranging (LiDAR) sensor mounted on the UAV. Before online navigation, a high-fidelity simulator acquires a flight dataset to learn energy consumption for the UAV and heteroscedastic uncertainty associated with LiDAR measurements, both as functions of the horizontal velocity of the UAV. The learned models enable the online planner to estimate energy consumption and perception quality, reducing UAV battery usage and localization errors. Simulation experiments in a photorealistic environment confirm that the proposed planner can address the trade-off between energy efficiency and perception quality under heteroscedastic uncertainty. The open-source code is released at https://gitlab.com/ReI08/perception-energy-planner.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unsupervised-correspondence-with-combined-geometric-learning-and-imaging-for-radiotherapy-applications"><a href="#Unsupervised-correspondence-with-combined-geometric-learning-and-imaging-for-radiotherapy-applications" class="headerlink" title="Unsupervised correspondence with combined geometric learning and imaging for radiotherapy applications"></a>Unsupervised correspondence with combined geometric learning and imaging for radiotherapy applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14269">http://arxiv.org/abs/2309.14269</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rrr-uom-projects/unsup-rt-corr-net">https://github.com/rrr-uom-projects/unsup-rt-corr-net</a></li>
<li>paper_authors: Edward G. A. Henderson, Marcel van Herk, Andrew F. Green, Eliana M. Vasquez Osorio</li>
<li>For: The paper aims to develop a model for accurately identifying corresponding points between organ segmentations of different patients for radiotherapy applications.* Methods: The model uses a combination of 3D shape information and imaging information to estimate correspondences and perform interpolation. The model was trained with head and neck organ segmentations from planning CT scans, and two approaches were used to incorporate imaging information: extracting features directly from image patches and including the mean square error between patches as part of the loss function.* Results: The correspondence and interpolation performance were evaluated using several metrics, including geodesic error, chamfer distance, and conformal distortion. The best performing model configuration incorporated imaging information as part of the loss function, which produced more anatomically plausible correspondences. The model outperformed a baseline non-rigid registration approach and the original model with direct inclusion of image features.Here is the same information in Simplified Chinese:* For: 这篇论文的目标是为了准确地标注不同患者的器官分割中的对应点，以便在放疗应用中使用。* Methods: 该模型使用了3D形状信息和成像信息来估算对应点并进行插值。模型通过使用规划CT扫描图像的头颈器官分割来进行训练，并采用了两种方法来包含成像信息：直接从图像块中提取特征，以及将图像块之间的平均方差作为损失函数的一部分。* Results: 对应点和插值性能被评估使用了几种指标，包括 геодезиック误差、斜截距离和几何扭曲误差。最佳配置中包含了成像信息作为损失函数的一部分，生成了更 Plausible的对应点。模型比非rigid registration方法和原始模型 WITH direct inclusion of image features更好。<details>
<summary>Abstract</summary>
The aim of this study was to develop a model to accurately identify corresponding points between organ segmentations of different patients for radiotherapy applications. A model for simultaneous correspondence and interpolation estimation in 3D shapes was trained with head and neck organ segmentations from planning CT scans. We then extended the original model to incorporate imaging information using two approaches: 1) extracting features directly from image patches, and 2) including the mean square error between patches as part of the loss function. The correspondence and interpolation performance were evaluated using the geodesic error, chamfer distance and conformal distortion metrics, as well as distances between anatomical landmarks. Each of the models produced significantly better correspondences than the baseline non-rigid registration approach. The original model performed similarly to the model with direct inclusion of image features. The best performing model configuration incorporated imaging information as part of the loss function which produced more anatomically plausible correspondences. We will use the best performing model to identify corresponding anatomical points on organs to improve spatial normalisation, an important step in outcome modelling, or as an initialisation for anatomically informed registrations. All our code is publicly available at https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net
</details>
<details>
<summary>摘要</summary>
“本研究的目标是开发一种能够准确标注不同病人器官分割的模型，以便在放射治疗应用中进行空间Normalization。我们使用了头和 neck器官分割的规划CT扫描图进行模型训练。然后，我们将原始模型扩展以包括影像信息，使用两种方法：1）直接从图像块中提取特征，2）在损失函数中包括图像块的平均方差。对于每个模型，我们评估了各种维度的比较，包括地odesic error、Chamfer distance和conformal distortion metric，以及器官标志点之间的距离。每个模型都生成了较好的对应关系，比基eline非rigid registration方法更好。原始模型和直接包括图像特征的模型的性能相似。最佳配置是将影像信息作为损失函数的一部分来，生成更符合解剖学的对应关系。我们将使用最佳配置来标注器官之间的对应点，以提高结果模型中的空间Normalization，或者作为初始化 для解剖学指导的registrations。我们的代码都公开在https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net上”
</details></li>
</ul>
<hr>
<h2 id="Date-Driven-Approach-for-Identifying-State-of-Hemodialysis-Fistulas-Entropy-Complexity-and-Formal-Concept-Analysis"><a href="#Date-Driven-Approach-for-Identifying-State-of-Hemodialysis-Fistulas-Entropy-Complexity-and-Formal-Concept-Analysis" class="headerlink" title="Date-Driven Approach for Identifying State of Hemodialysis Fistulas: Entropy-Complexity and Formal Concept Analysis"></a>Date-Driven Approach for Identifying State of Hemodialysis Fistulas: Entropy-Complexity and Formal Concept Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14399">http://arxiv.org/abs/2309.14399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasilii A. Gromov, E. I. Zvorykina, Yurii N. Beschastnov, Majid Sohrabi</li>
<li>for: 这种研究旨在为诊断病理性尿道采用数学方法进行分类。</li>
<li>methods: 这种方法基于laminar blood flow的假设，认为正常功能的尿道会出现单普液流，而病理性尿道会出现湍流。这种方法包括在 entropy-complexity 平面上将时序列映射，并与已知集合进行比较，以及使用正式概念分析构建 concepts-objects 图。</li>
<li>results: 这两种方法具有高效性，可以准确地确定尿道的状态。<details>
<summary>Abstract</summary>
The paper explores mathematical methods that differentiate regular and chaotic time series, specifically for identifying pathological fistulas. It proposes a noise-resistant method for classifying responding rows of normally and pathologically functioning fistulas. This approach is grounded in the hypothesis that laminar blood flow signifies normal function, while turbulent flow indicates pathology. The study explores two distinct methods for distinguishing chaotic from regular time series. The first method involves mapping the time series onto the entropy-complexity plane and subsequently comparing it to established clusters. The second method, introduced by the authors, constructs a concepts-objects graph using formal concept analysis. Both of these methods exhibit high efficiency in determining the state of the fistula.
</details>
<details>
<summary>摘要</summary>
文章研究了用数学方法分辨常规和异常时间序列，特别是用于识别病理性尿道。它提出了一种对应行的响应类型进行分类的听力抗噪方法，这种方法基于假设：在正常情况下，液体血流表示正常功能，而在异常情况下，液体血流表示疾病。文章研究了两种方法来分辨混乱和常规时间序列：首先，将时间序列映射到复杂度-自 entropy 平面，然后与已知的集群进行比较；其次，通过正式概念分析构建一个概念物件图。两种方法都能高效地确定尿道的状态。
</details></li>
</ul>
<hr>
<h2 id="OmniEvent-A-Comprehensive-Fair-and-Easy-to-Use-Toolkit-for-Event-Understanding"><a href="#OmniEvent-A-Comprehensive-Fair-and-Easy-to-Use-Toolkit-for-Event-Understanding" class="headerlink" title="OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event Understanding"></a>OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14258">http://arxiv.org/abs/2309.14258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-keg/omnievent">https://github.com/thu-keg/omnievent</a></li>
<li>paper_authors: Hao Peng, Xiaozhi Wang, Feng Yao, Zimu Wang, Chuzhao Zhu, Kaisheng Zeng, Lei Hou, Juanzi Li</li>
<li>for: 本研究开发了一个全面的事件理解工具kit OmniEvent，用于解决文本中事件检测、事件Argument提取和事件关系提取等复杂的信息提取任务。</li>
<li>methods: OmniEvent支持主流的模型化方法，并处理了Peng et al. (2023)所报告的隐藏评估坑，以确保公平的比较。</li>
<li>results: OmniEvent提供了一个可直接用于生产环境的Web服务，并提供了可修改的模块化框架，以便用户根据需要进行自定义模型评估。<details>
<summary>Abstract</summary>
Event understanding aims at understanding the content and relationship of events within texts, which covers multiple complicated information extraction tasks: event detection, event argument extraction, and event relation extraction. To facilitate related research and application, we present an event understanding toolkit OmniEvent, which features three desiderata: (1) Comprehensive. OmniEvent supports mainstream modeling paradigms of all the event understanding tasks and the processing of 15 widely-used English and Chinese datasets. (2) Fair. OmniEvent carefully handles the inconspicuous evaluation pitfalls reported in Peng et al. (2023), which ensures fair comparisons between different models. (3) Easy-to-use. OmniEvent is designed to be easily used by users with varying needs. We provide off-the-shelf models that can be directly deployed as web services. The modular framework also enables users to easily implement and evaluate new event understanding models with OmniEvent. The toolkit (https://github.com/THU-KEG/OmniEvent) is publicly released along with the demonstration website and video (https://omnievent.xlore.cn/).
</details>
<details>
<summary>摘要</summary>
Event理解目标是理解文本中的事件内容和关系，包括多种复杂信息提取任务：事件检测、事件参数提取和事件关系提取。为推动相关研究和应用，我们提供了一套事件理解工具包 OmniEvent，具有以下三个目标：1. 全面。OmniEvent支持主流模型化思路所有的事件理解任务，并处理15种常用的英文和中文数据集。2. 公平。OmniEvent通过彻底处理报告在Peng et al. (2023)中报道的隐藏评估坑，以确保比较不同模型的公平。3. 易用。OmniEvent设计便于用户们根据需要使用。我们提供了直接可以部署为网服务的准备好的模型，框架也允许用户轻松实现和评估新的事件理解模型。工具kit（https://github.com/THU-KEG/OmniEvent）公开发布，并提供了示例网站和视频（https://omnievent.xlore.cn/）。
</details></li>
</ul>
<hr>
<h2 id="Prediction-Model-For-Wordle-Game-Results-With-High-Robustness"><a href="#Prediction-Model-For-Wordle-Game-Results-With-High-Robustness" class="headerlink" title="Prediction Model For Wordle Game Results With High Robustness"></a>Prediction Model For Wordle Game Results With High Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14250">http://arxiv.org/abs/2309.14250</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeniSoida/pl1">https://github.com/zeniSoida/pl1</a></li>
<li>paper_authors: Jiaqi Weng, Chunlin Feng</li>
<li>for: 本研究用数据分析和机器学习方法研究Wordle游戏的动态。</li>
<li>methods: 我们使用ARIMAX模型和反射神经网络模型来预测词语的难度，并使用K-means归一化来分类词语的数值。</li>
<li>results: 我们的研究发现，在2023年3月1日，约有12,884个结果将被提交，词语”尴尬”的平均尝试次数为4.8，属于最难的分数 cluster。此外，我们还研究了玩家的忠诚度和他们是否做日常挑战的比例。我们的模型经过了严格的敏感分析和验证，确认其稳定性。总的来说，本研究提供了基于日期或给定的五个字词语的Wordle游戏预测框架，结果已经提交给纽约时报游戏编辑。<details>
<summary>Abstract</summary>
In this study, we delve into the dynamics of Wordle using data analysis and machine learning. Our analysis initially focused on the correlation between the date and the number of submitted results. Due to initial popularity bias, we modeled stable data using an ARIMAX model with coefficient values of 9, 0, 2, and weekdays/weekends as the exogenous variable. We found no significant relationship between word attributes and hard mode results.   To predict word difficulty, we employed a Backpropagation Neural Network, overcoming overfitting via feature engineering. We also used K-means clustering, optimized at five clusters, to categorize word difficulty numerically. Our findings indicate that on March 1st, 2023, around 12,884 results will be submitted and the word "eerie" averages 4.8 attempts, falling into the hardest difficulty cluster.   We further examined the percentage of loyal players and their propensity to undertake daily challenges. Our models underwent rigorous sensitivity analyses, including ADF, ACF, PACF tests, and cross-validation, confirming their robustness. Overall, our study provides a predictive framework for Wordle gameplay based on date or a given five-letter word. Results have been summarized and submitted to the Puzzle Editor of the New York Times.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们使用数据分析和机器学习来研究Wordle的动态。我们首先查看了日期和提交结果之间的相关性。由于初始的受欢迎偏见，我们使用ARIMAX模型，其含有9, 0, 2的系数值和星期天/星期六作为外生变量。我们发现没有显著的词属性和困难模式之间的关系。  为预测词难度，我们使用反射神经网络，并通过特征工程来避免过拟合。我们还使用K-means聚类算法，并优化为五个分类。我们发现，在2023年3月1日，约有12,884个结果将被提交，并且词“幽默”的平均尝试次数为4.8，属于最难的分类。  我们进一步研究了忠诚玩家的百分比和他们的日常挑战的倾向。我们的模型经过了严格的敏感分析，包括ADF、ACF、PACF测试和批处理，以确认其可靠性。总的来说，我们的研究提供了基于日期或给定的五个字的Wordle游戏玩法预测框架。结果已经总结并提交给纽约时报游戏编辑。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Internet-Communication-Through-LLMs-How-Close-Are-We"><a href="#Rethinking-Internet-Communication-Through-LLMs-How-Close-Are-We" class="headerlink" title="Rethinking Internet Communication Through LLMs: How Close Are We?"></a>Rethinking Internet Communication Through LLMs: How Close Are We?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14247">http://arxiv.org/abs/2309.14247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sifat Ut Taki, Spyridon Mastorakis</li>
<li>for: 重新思考互联网上用户之间的交流方式，以便更好地捕捉用户对另一端通信频道的认知。</li>
<li>methods: 提出使用大语言模型（LLM）代表用户之间的交流，并提出了实现这种通信架构的方法。</li>
<li>results: 对现有技术的可行性进行了 reality check，并讨论了未来研究的挑战和有趣的方向。<details>
<summary>Abstract</summary>
In this paper, we rethink the way that communication among users over the Internet, one of the fundamental outcomes of the Internet evolution, takes place. Instead of users communicating directly over the Internet, we explore an architecture that enables users to communicate with (query) Large Language Models (LLMs) that capture the cognition of users on the other end of the communication channel. We present an architecture to achieve such LLM-based communication and we perform a reality check to assess how close we are today to realizing such a communication architecture from a technical point of view. Finally, we discuss several research challenges and identify interesting directions for future research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们重新思考互联网上用户之间的通信方式，这是互联网进化的一个基本结果。而不是直接通过互联网进行用户之间的通信，我们研究了一种使用大自然语言模型（LLM）来捕捉用户对另一端通信频道的认知。我们提出了实现这种 LLM-based 通信架构的方案，并进行了技术实现的现实性检查。最后，我们讨论了一些研究挑战和未来研究的有趣方向。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-data-efficiency-in-reinforcement-learning-a-novel-imagination-mechanism-based-on-mesh-information-propagation"><a href="#Enhancing-data-efficiency-in-reinforcement-learning-a-novel-imagination-mechanism-based-on-mesh-information-propagation" class="headerlink" title="Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation"></a>Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14243">http://arxiv.org/abs/2309.14243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ouazusakou/imagination_mechanism">https://github.com/ouazusakou/imagination_mechanism</a></li>
<li>paper_authors: Zihang Wang, Maowei Jiang</li>
<li>for: 提高深度学习强化学习（RL）算法的数据效率，特别是面临高维状态空间和大规模问题时。</li>
<li>methods: 引入一种人类类似的想象机制（Imagination Mechanism，IM），用于在不同话题间共享样本信息，从而提高RL算法的学习效率。</li>
<li>results: 在四种主流SOTA RL算法（SAC、PPO、DDPG和DQN）上，IM可以带来显著的提高，最终导致不同任务上的表现均得到提高。<details>
<summary>Abstract</summary>
Reinforcement learning(RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most of RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states across episodes, instead of simply transmitting in the same episode. This capability enhances the model's comprehension of state interdependencies and facilitates more efficient learning of limited sample information. To promote versatility, we extend the IM to function as a plug-and-play module that can be seamlessly and fluidly integrated into other widely adopted RL algorithms. Our experiments demonstrate that IM consistently boosts four mainstream SOTA RL algorithms, such as SAC, PPO, DDPG, and DQN, by a considerable margin, ultimately leading to superior performance than before across various tasks. For access to our code and data, please visit https://github.com/OuAzusaKou/imagination_mechanism
</details>
<details>
<summary>摘要</summary>
利用人类类似的想象能力，我们引入了一种新的网格信息传递机制，称为“想象机制”（IM），以提高深度学习束缚学习（RL）算法的数据效率。Specifically，IM使得单个样本生成的信息可以有效地在不同话数据集中传递，而不是仅在同一话数据集中传递。这种能力提高模型对状态之间的相互关系的理解，并且使得学习有限样本信息更加高效。为了推广可用性，我们将IM作为一个可插入式和可靠地Integrate into other widely adopted RL algorithms。我们的实验表明，IM可以持续地提高四种主流SOTA RL算法，如SAC、PPO、DDPG和DQN，并 ultimately leading to superior performance across various tasks. For access to our code and data, please visit https://github.com/OuAzusaKou/imagination_mechanism。
</details></li>
</ul>
<hr>
<h2 id="Seeing-and-hearing-what-has-not-been-said-A-multimodal-client-behavior-classifier-in-Motivational-Interviewing-with-interpretable-fusion"><a href="#Seeing-and-hearing-what-has-not-been-said-A-multimodal-client-behavior-classifier-in-Motivational-Interviewing-with-interpretable-fusion" class="headerlink" title="Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion"></a>Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14398">http://arxiv.org/abs/2309.14398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucie Galland, Catherine Pelachaud, Florian Pecune</li>
<li>for: 评估动机听讲的质量，以便提高治疗效果。</li>
<li>methods: 利用多Modal特征，如文本、语音、脸部表情和身体表情，建立一个准确地分类客户话语的模型。</li>
<li>results: 通过对AnnoMI数据集进行注解，收集多Modal信息，并确定最重要的Modalities在决策过程中的扮演。<details>
<summary>Abstract</summary>
Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights into the interplay of different modalities during a MI conversation.
</details>
<details>
<summary>摘要</summary>
《动机导向会议》（MI）是一种帮助客户改变行为的医疗方法。为评估MI会议质量，客户的语言可以被分类为变化语言、维持语言或跟随/中立语言。变化语言的比例和治疗效果正相关，因此正确地分类客户语言非常重要。在这篇论文中，我们提出了一种精准地分类客户语言的分类器，利用多Modal特征，如文本、 просодия、 facial expressivity 和 body expressivity。为了训练我们的模型，我们对公共可用的 AnnoMI 数据集进行了标注，以收集多Modal信息，包括文本、音频、 facial expressivity 和 body expressivity。此外，我们还确定了决策过程中最重要的Modalities，提供了有价值的发现，描述了不同Modalities在MI会议中的协作。
</details></li>
</ul>
<hr>
<h2 id="MoDem-V2-Visuo-Motor-World-Models-for-Real-World-Robot-Manipulation"><a href="#MoDem-V2-Visuo-Motor-World-Models-for-Real-World-Robot-Manipulation" class="headerlink" title="MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation"></a>MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14236">http://arxiv.org/abs/2309.14236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Lancaster, Nicklas Hansen, Aravind Rajeswaran, Vikash Kumar<br>for:* 本研究旨在开发一个能够在无instrumented real-world environments中学习 contact-rich manipulation的系统，以提高现代机器人系统的可靠性和安全性。methods:* 该系统基于latest algorithmic advancements in model-based reinforcement learning (MBRL), demo-bootstrapping, and effective exploration，并使用 visual pixels directly for learning。results:* 该系统能够在实际世界中学习 contact-rich dexterous manipulation skills，并在四个复杂的visuo-motor manipulation问题中进行了 empirical demonstration。这是首个直接在实际世界中学习的 demonstration-augmented visual MBRL系统。<details>
<summary>Abstract</summary>
Robotic systems that aspire to operate in uninstrumented real-world environments must perceive the world directly via onboard sensing. Vision-based learning systems aim to eliminate the need for environment instrumentation by building an implicit understanding of the world based on raw pixels, but navigating the contact-rich high-dimensional search space from solely sparse visual reward signals significantly exacerbates the challenge of exploration. The applicability of such systems is thus typically restricted to simulated or heavily engineered environments since agent exploration in the real-world without the guidance of explicit state estimation and dense rewards can lead to unsafe behavior and safety faults that are catastrophic. In this study, we isolate the root causes behind these limitations to develop a system, called MoDem-V2, capable of learning contact-rich manipulation directly in the uninstrumented real world. Building on the latest algorithmic advancements in model-based reinforcement learning (MBRL), demo-bootstrapping, and effective exploration, MoDem-V2 can acquire contact-rich dexterous manipulation skills directly in the real world. We identify key ingredients for leveraging demonstrations in model learning while respecting real-world safety considerations -- exploration centering, agency handover, and actor-critic ensembles. We empirically demonstrate the contribution of these ingredients in four complex visuo-motor manipulation problems in both simulation and the real world. To the best of our knowledge, our work presents the first successful system for demonstration-augmented visual MBRL trained directly in the real world. Visit https://sites.google.com/view/modem-v2 for videos and more details.
</details>
<details>
<summary>摘要</summary>
роботизированные системы, которые стремятся работать в неинструментированных реальных средах, должны воспринимать мир непосредственно с помощью наборного зрения. Системы обучения на основе зрения стремятся отказаться от необходимости в инструментированной среде, построив implicit понимание мира на основе raw пикселей, но навигация высокомерных пространств по solely sparse visual reward signals значительно увеличивает вызов эксплорации. Поэтому применение таких систем ограничено симулированными или инженерными средами, так как исследуние агента в реальном мире без руководства эксплицитных state estimation и dense reward может привести к небезопасному поведению и фатальным ошибкам.В этом исследовании мы изолируем корни этих ограничений, чтобы разработать систему, называемую MoDem-V2, которая может научиться контактным манипуляциям непосредственно в неинструментированном реальном мире. На основе последних достижений в области алгоритмов моделируемого обучения (MBRL), демо-ботстроппинга и эффективного исследувания, MoDem-V2 может приобрести контактные манипулятивные навыки в реальном мире. Мы идентифицируем ключевые ингредиенты для использования демонстраций в модельном обучении, уважая considertions безопасности реального мира -- exploration centering, handover agency и actor-critic ensembles. Мы экспериментально подтверждаем вклад этих ингредиентов в решении четырех сложных визуометрических манипулятивных задач в обеих симуляции и реальном мире. По нашему знанию, наша работа представляет первую успешную систему demonstration-augmented visual MBRL, обученную непосредственно в реальном мире. Посетите https://sites.google.com/view/modem-v2 для видео и дополнительные детали.
</details></li>
</ul>
<hr>
<h2 id="Stackelberg-Driver-Model-for-Continual-Policy-Improvement-in-Scenario-Based-Closed-Loop-Autonomous-Driving"><a href="#Stackelberg-Driver-Model-for-Continual-Policy-Improvement-in-Scenario-Based-Closed-Loop-Autonomous-Driving" class="headerlink" title="Stackelberg Driver Model for Continual Policy Improvement in Scenario-Based Closed-Loop Autonomous Driving"></a>Stackelberg Driver Model for Continual Policy Improvement in Scenario-Based Closed-Loop Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14235">http://arxiv.org/abs/2309.14235</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/BlueCat-de/SDM">https://github.com/BlueCat-de/SDM</a></li>
<li>paper_authors: Haoyi Niu, Qimao Chen, Yingyue Li, Jianming Hu</li>
<li>for: 本研究旨在提高自动驾驶车辆（AV）的性能和可靠性，通过针对极其罕见 yet critical corner cases 的优化。</li>
<li>methods: 该研究使用 adversarial generation 方法生成安全关键的驾驶场景，并通过 Stackelberg Driver Model（SDM）模型准确描述了车辆之间的层次结构，以实现 AV 的不断改进。</li>
<li>results: 实验表明，该算法在高维场景中表现出色，比基准方法更高效，导致了 AV 的显著进步，同时 continually generating progressively challenging scenarios。<details>
<summary>Abstract</summary>
The deployment of autonomous vehicles (AVs) has faced hurdles due to the dominance of rare but critical corner cases within the long-tail distribution of driving scenarios, which negatively affects their overall performance. To address this challenge, adversarial generation methods have emerged as a class of efficient approaches to synthesize safety-critical scenarios for AV testing. However, these generated scenarios are often underutilized for AV training, resulting in the potential for continual AV policy improvement remaining untapped, along with a deficiency in the closed-loop design needed to achieve it. Therefore, we tailor the Stackelberg Driver Model (SDM) to accurately characterize the hierarchical nature of vehicle interaction dynamics, facilitating iterative improvement by engaging background vehicles (BVs) and AV in a sequential game-like interaction paradigm. With AV acting as the leader and BVs as followers, this leader-follower modeling ensures that AV would consistently refine its policy, always taking into account the additional information that BVs play the best response to challenge AV. Extensive experiments have shown that our algorithm exhibits superior performance compared to several baselines especially in higher dimensional scenarios, leading to substantial advancements in AV capabilities while continually generating progressively challenging scenarios. Code is available at https://github.com/BlueCat-de/SDM.
</details>
<details>
<summary>摘要</summary>
自带驱动自动车 (AV) 的部署面临了由罕见而重要的角度案例所带来的阻碍，这些角度案例会影响 AV 的总性表现。为解决这个挑战， adversarial 生成方法在 AV 测试中出现了，这些方法可以生成安全关键的驾驶enario。然而，这些生成的场景通常不被用于 AV 训练，导致 AV 政策的持续改进 remained untapped，以及closed-loop 设计的缺失。因此，我们将 Stackelberg 驾驶器模型 (SDM) 改进，以便准确地描述车辆交互动力学的层次结构，从而实现了 iterative 改进，让 AV 在 background 车辆 (BV) 的支持下，通过 sequential 交互模式来精细调整其策略，并且总是考虑 BV 的最佳回应，以挑战 AV。我们的算法在高维度enario中表现出色，比如基eline 特别出色，从而实现了 AV 的重要进步，同时 continually 生成进一步挑战 AV 的场景。代码可以在 <https://github.com/BlueCat-de/SDM> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Combined-sizing-and-layout-optimization-of-truss-structures-via-update-Monte-Carlo-tree-search-UMCTS-algorithm"><a href="#Combined-sizing-and-layout-optimization-of-truss-structures-via-update-Monte-Carlo-tree-search-UMCTS-algorithm" class="headerlink" title="Combined sizing and layout optimization of truss structures via update Monte Carlo tree search (UMCTS) algorithm"></a>Combined sizing and layout optimization of truss structures via update Monte Carlo tree search (UMCTS) algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14231">http://arxiv.org/abs/2309.14231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fu-Yao Ko, Katsuyuki Suzuki, Kazuo Yonekura</li>
<li>for: 本研究的主要目标是找到螺栓结构的最佳设计，同时考虑尺寸和布局变量。</li>
<li>methods: 本研究使用了一种强化学习方法，名为更新 Monte Carlo 搜索（UMCTS），用于解决螺栓结构的尺寸和布局优化问题。</li>
<li>results: 研究表明，使用 UMCTS 方法可以减少计算时间，并且稳定地实现较好的解决方案，比传统方法更好。<details>
<summary>Abstract</summary>
The main concern of this study is to find the optimal design of truss structures considering sizing and layout variables simultaneously. As compared to purely sizing optimization problems, this problem is more challenging since the two types of variables involved are fundamentally different in nature. In this paper, a reinforcement learning method combining the update process and Monte Carlo tree search called the update Monte Carlo tree search (UMCTS) for sizing optimization problems is applied to solve combined sizing and layout optimization for truss structures. This study proposes a novel update process for nodal coordinates with two features. (1) The allowed range of each coordinate varies in each round. (2) Accelerators for the number of entries in the allowed range and iteration numbers are introduced to reduce the computation time. Furthermore, nodal coordinates and member areas are determined at the same time with only one search tree in each round. The validation and efficiency of the UMCTS are tested on benchmark problems of planar and spatial trusses with discrete sizing variables and continuous layout variables. It is shown that the CPU time of the UMCTS is two times faster than the branch and bound method. The numerical results demonstrate that the proposed method stably achieves a better solution than other traditional methods.
</details>
<details>
<summary>摘要</summary>
本研究的主要担忧是查找螺栓结构的最优设计，同时考虑大小和布局变量。与纯粹的大小优化问题相比，这个问题更加具有挑战性，因为这两种变量的本质不同。在这篇论文中，我们应用了一种combined reinforcement learning method，called update Monte Carlo tree search (UMCTS)，解决螺栓结构的大小和布局优化问题。我们提出了一种新的更新过程，其中每个坐标的允许范围在每一轮都不同，同时还引入了加速器来减少计算时间。此外，每一轮都只需要一个搜索树来确定节点坐标和部件面积。我们对标准问题进行验证和效率测试，结果显示，UMCTS的计算时间比branch and bound方法快两倍。数值结果表明，我们提出的方法可稳定地实现更好的解决方案，比传统方法更好。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Sensing-in-Traffic-Optimization-Advanced-Deep-Reinforcement-Learning-Techniques"><a href="#Implicit-Sensing-in-Traffic-Optimization-Advanced-Deep-Reinforcement-Learning-Techniques" class="headerlink" title="Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques"></a>Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14395">http://arxiv.org/abs/2309.14395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emanuel Figetakis, Yahuza Bello, Ahmed Refaey, Lei Lei, Medhat Moussa<br>for: 这个论文的目的是解决高速公路突然出现堵塞的问题，使用自动驾驶车辆（AV）的感知器来做出智能决策，以避免因堵塞而导致的延迟。methods: 这个论文使用了深度强化学习（DRL）技术，基于Markov决策过程（MDP）模型，训练RL代理人以适应实际驾驶情况。具体来说，使用了SUMO仿真器和OPENAI GYM评估工具来评估提议模型的性能。results: 结果表明，使用{\epsilon}-抽象策略训练DQN代理人后，其性能明显超过使用Boltzmann策略训练的DQN代理人。<details>
<summary>Abstract</summary>
A sudden roadblock on highways due to many reasons such as road maintenance, accidents, and car repair is a common situation we encounter almost daily. Autonomous Vehicles (AVs) equipped with sensors that can acquire vehicle dynamics such as speed, acceleration, and location can make intelligent decisions to change lanes before reaching a roadblock. A number of literature studies have examined car-following models and lane-changing models. However, only a few studies proposed an integrated car-following and lane-changing model, which has the potential to model practical driving maneuvers. Hence, in this paper, we present an integrated car-following and lane-changing decision-control system based on Deep Reinforcement Learning (DRL) to address this issue. Specifically, we consider a scenario where sudden construction work will be carried out along a highway. We model the scenario as a Markov Decision Process (MDP) and employ the well-known DQN algorithm to train the RL agent to make the appropriate decision accordingly (i.e., either stay in the same lane or change lanes). To overcome the delay and computational requirement of DRL algorithms, we adopt an MEC-assisted architecture where the RL agents are trained on MEC servers. We utilize the highly reputable SUMO simulator and OPENAI GYM to evaluate the performance of the proposed model under two policies; {\epsilon}-greedy policy and Boltzmann policy. The results unequivocally demonstrate that the DQN agent trained using the {\epsilon}-greedy policy significantly outperforms the one trained with the Boltzmann policy.
</details>
<details>
<summary>摘要</summary>
高速公路上突然出现堵塞，常见的情况之一，可能是道路维护、事故或车辆维修等多种原因。自动驾驶车（AV）配备感知器可以获取车辆动态状态，如速度、加速度和位置，可以做出智能决策，以避免堵塞。许多文献研究了车辆随驾模型和车道变更模型，但只有一些研究提出了集成车辆随驾和车道变更模型，这种模型具有实际驾驶行为的潜在优势。因此，在这篇论文中，我们提出了基于深度强化学习（DRL）的集成车辆随驾和车道变更决策控制系统，以解决这个问题。具体来说，我们考虑了高速公路上突然进行建设工程的情况。我们将这种情况模型为马克夫满度决策过程（MDP），并使用了知名的DQN算法来训练RL代理人进行适当决策（即留在同一个车道或变更车道）。为了解决DRL算法的延迟和计算资源的问题，我们采用了MEC助け的架构，其中RL代理人在MEC服务器上进行训练。我们使用了非常可靠的SUMO仿真器和OPENAI GYM来评估提出的模型的性能，并对两种策略进行评估：{\epsilon}-抽象策略和博尔ツ曼策略。结果明确表明，使用{\epsilon}-抽象策略训练的DQN代理人明显超越使用博尔ツ曼策略训练的DQN代理人。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Noises-in-Diffusion-Model-for-Semi-Supervised-Multi-Domain-Translation"><a href="#Multiple-Noises-in-Diffusion-Model-for-Semi-Supervised-Multi-Domain-Translation" class="headerlink" title="Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation"></a>Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14394">http://arxiv.org/abs/2309.14394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tsiry Mayet, Simon Bernard, Clement Chatelain, Romain Herault</li>
<li>for: 这 paper 的目的是提出一种多个频道的域转换方法，用于在半指导下进行多个域之间的域转换。</li>
<li>methods: 这 paper 使用了一种名为 Multi-Domain Diffusion (MDD) 的噪声扩散框架，它不需要定义输入和输出域，可以在任意的域分配中进行域转换（如 $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, 等等），而不需要额外训练每个域配置的模型。</li>
<li>results: 这 paper 在一个多个域的Synthetic image translation dataset上进行了实验，并得到了一些有趣的结果。<details>
<summary>Abstract</summary>
Domain-to-domain translation involves generating a target domain sample given a condition in the source domain. Most existing methods focus on fixed input and output domains, i.e. they only work for specific configurations (i.e. for two domains, either $D_1\rightarrow{}D_2$ or $D_2\rightarrow{}D_1$). This paper proposes Multi-Domain Diffusion (MDD), a conditional diffusion framework for multi-domain translation in a semi-supervised context. Unlike previous methods, MDD does not require defining input and output domains, allowing translation between any partition of domains within a set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for 3 domains), without the need to train separate models for each domain configuration. The key idea behind MDD is to leverage the noise formulation of diffusion models by incorporating one noise level per domain, which allows missing domains to be modeled with noise in a natural way. This transforms the training task from a simple reconstruction task to a domain translation task, where the model relies on less noisy domains to reconstruct more noisy domains. We present results on a multi-domain (with more than two domains) synthetic image translation dataset with challenging semantic domain inversion.
</details>
<details>
<summary>摘要</summary>
域到域翻译（Domain-to-domain translation）是生成目标域样本，给定源域的条件。现有的方法都是针对固定的输入和输出域，即只能处理特定的配置（例如 $D_1\to D_2$ 或 $D_2\to D_1$）。这篇论文提出了多域扩散（Multi-Domain Diffusion，MDD），一种基于半supervised的域扩散框架。与先前的方法不同，MDD不需要定义输入和输出域，可以在一个集合（例如 $(D_1, D_2)\to D_3$，$D_2\to (D_1, D_3)$，$D_3\to D_1$ 等）中进行翻译，无需为每个域配置单独训练模型。MDD的关键思想是利用扩散模型的噪声表示，每个域都有一个噪声水平，这使得缺失的域可以自然地被噪声表示。这将训练任务从一个简单的重建任务变为域翻译任务，其中模型通过更加净化的域来重建更加噪声的域。我们在多域（包括更多于两个域）的Synthetic image翻译dataset上进行了实验，并取得了具有挑战性的semantic domain inversion的结果。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Machine-Learning-Algorithms-with-Adaptive-Sampling"><a href="#Accelerating-Machine-Learning-Algorithms-with-Adaptive-Sampling" class="headerlink" title="Accelerating Machine Learning Algorithms with Adaptive Sampling"></a>Accelerating Machine Learning Algorithms with Adaptive Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14221">http://arxiv.org/abs/2309.14221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mo Tiwari</li>
<li>for: 提高大规模数据处理中机器学习算法的效率。</li>
<li>methods: 使用Randomized counterparts instead of computationally intensive subroutines to improve computational efficiency.</li>
<li>results: 几乎没有质量下降，但可以大幅提高计算效率。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The era of huge data necessitates highly efficient machine learning algorithms. Many common machine learning algorithms, however, rely on computationally intensive subroutines that are prohibitively expensive on large datasets. Oftentimes, existing techniques subsample the data or use other methods to improve computational efficiency, at the expense of incurring some approximation error. This thesis demonstrates that it is often sufficient, instead, to substitute computationally intensive subroutines with a special kind of randomized counterparts that results in almost no degradation in quality.
</details>
<details>
<summary>摘要</summary>
era of big data 需要非常高效的机器学习算法。然而，许多常见的机器学习算法却依赖于计算昂贵的子routine，对大量数据来说是不可接受的。有时候，现有的技术会采用采样或其他方法来提高计算效率，但这会导致一定的近似错误。这个论文示出，可以在代之前 substitute computationally intensive subroutines with a special kind of randomized counterparts，而不会导致质量下降。
</details></li>
</ul>
<hr>
<h2 id="MemDA-Forecasting-Urban-Time-Series-with-Memory-based-Drift-Adaptation"><a href="#MemDA-Forecasting-Urban-Time-Series-with-Memory-based-Drift-Adaptation" class="headerlink" title="MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation"></a>MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14216">http://arxiv.org/abs/2309.14216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deepkashiwa20/Urban_Concept_Drift">https://github.com/deepkashiwa20/Urban_Concept_Drift</a></li>
<li>paper_authors: Zekun Cai, Renhe Jiang, Xinyu Yang, Zhaonan Wang, Diansheng Guo, Hiroki Kobayashi, Xuan Song, Ryosuke Shibasaki</li>
<li>for: 本研究旨在解决城市时间序列预测中的概念漂移问题，以提高城市智能化的可持续发展。</li>
<li>methods: 本研究提出了一种新的城市时间序列预测模型，该模型通过考虑数据周期性并在预测过程中进行协调调整，以适应概念漂移。</li>
<li>results: 实验结果表明，本研究的设计在实际数据上显著超越了现有方法，并且可以通过减少预测模型对数据分布变化的敏感性，提高模型的可重用性和泛化能力。<details>
<summary>Abstract</summary>
Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.
</details>
<details>
<summary>摘要</summary>
城市时序数据预测 featuring 重要贡献于可持续发展是智能城市广泛研究的必要任务。然而，随着世界环境的剧变和快速变化，假设数据遵循独立同分布（ID）的假设被后续数据分布变化所推翻，导致模型的弱复现和传输性，从而使得随变问题在实际场景中并不得到好的解决。在本研究中，我们提出了一种新的城市时序预测模型，该模型通过考虑数据中的周期性来编码随变，并在随变过程中进行实时调整，使用元动态网络。实验表明，我们的设计在实际数据集上显著超越了现有方法，并且可以将现有预测基础结构降低其对分布变化的敏感性。
</details></li>
</ul>
<hr>
<h2 id="Continual-Driving-Policy-Optimization-with-Closed-Loop-Individualized-Curricula"><a href="#Continual-Driving-Policy-Optimization-with-Closed-Loop-Individualized-Curricula" class="headerlink" title="Continual Driving Policy Optimization with Closed-Loop Individualized Curricula"></a>Continual Driving Policy Optimization with Closed-Loop Individualized Curricula</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14209">http://arxiv.org/abs/2309.14209</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YizhouXu-THU/CLIC">https://github.com/YizhouXu-THU/CLIC</a></li>
<li>paper_authors: Haoyi Niu, Yizhou Xu, Xingjian Jiang, Jianming Hu<br>for: This paper aims to improve the safety of autonomous vehicles (AVs) by developing a continual driving policy optimization framework called Closed-Loop Individualized Curricula (CLIC).methods: The CLIC framework uses a collision prediction task to estimate the chance of AV failures in pre-collected scenarios, and then tailors individualized curricula for downstream training based on these failure probabilities.results: The experimental results show that CLIC surpasses other curriculum-based training strategies in managing risky scenarios while maintaining proficiency in handling simpler cases, demonstrating the effectiveness of the CLIC framework in improving the safety of AVs.Here is the answer in Simplified Chinese text:for: 这篇论文目的是提高自动驾驶车辆（AV）的安全性，通过开发一种循环驾驶政策优化框架——封闭循环个性化课程（CLIC）。methods: CLIC框架使用碰撞预测任务来估计AV失败的可能性，然后基于这些失败概率而tailor个性化课程 для下游训练。results: 实验结果表明，CLIC超过了其他课程基本训练策略，在管理危险场景方面达到了显著改进，而且仍能保持处理简单场景的能力，这表明CLIC框架可以有效地提高AV的安全性。<details>
<summary>Abstract</summary>
The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for flexible implementation choices: AV Evaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as a collision prediction task, where it estimates the chance of AV failures in these scenarios at each iteration. Subsequently, by re-sampling from historical scenarios based on these failure probabilities, CLIC tailors individualized curricula for downstream training, aligning them with the evaluated capability of AV. Accordingly, CLIC not only maximizes the utilization of the vast pre-collected scenario library for closed-loop driving policy optimization but also facilitates AV improvement by individualizing its training with more challenging cases out of those poorly organized scenarios. Experimental results clearly indicate that CLIC surpasses other curriculum-based training strategies, showing substantial improvement in managing risky scenarios, while still maintaining proficiency in handling simpler cases.
</details>
<details>
<summary>摘要</summary>
自动驾驶车辆（AV）的安全性问题一直是长期的主要担忧，这是因为自然驾驶驾驶分布中罕见的危险和安全关键场景的缺失。为解决这个挑战，自动驾驶场景研究有了很大的干预，关注生成高风险驾驶场景，并应用其进行安全检测自动驾驶模型。然而，有限的研究是关于重复这些广泛的场景来进一步改进AV模型。此外，从其他AV模型的巨大场景库中挑选有用信息是困难和挑战的。因此，我们开发了一个基于closed-loop个性化课程（CLIC）的驱动策略优化框架，它可以分解为以下几个标准化子模块：AV评估、场景选择和AV培训。在CLIC中，AV评估被设置为预测AV失败的概率任务，每轮评估AV在这些场景中的失败概率，然后根据这些概率重新采样历史场景，为下游培训生成个性化课程，使AV的培训更加个性化，与评估其能力相匹配。因此，CLIC不仅可以最大化已收集的历史场景库的利用，同时也可以通过个性化培训，提高AV在危险场景中的管理能力，而不会妨碍其在简单场景中的运作。实验结果表明，CLIC超越了其他课程基本培训策略，在管理危险场景方面显示了明显的改进，而且仍能保持简单场景中的运作效率。
</details></li>
</ul>
<hr>
<h2 id="Framework-based-on-complex-networks-to-model-and-mine-patient-pathways"><a href="#Framework-based-on-complex-networks-to-model-and-mine-patient-pathways" class="headerlink" title="Framework based on complex networks to model and mine patient pathways"></a>Framework based on complex networks to model and mine patient pathways</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14208">http://arxiv.org/abs/2309.14208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caroline-rosa/framework_patient_pathways">https://github.com/caroline-rosa/framework_patient_pathways</a></li>
<li>paper_authors: Caroline de Oliveira Costa Souza Rosa, Márcia Ito, Alex Borges Vieira, Klaus Wehmuth, Antônio Tadeu Azevedo Gomes</li>
<li>for: 这个研究旨在自动发现患者群体的医疗系统历史记录，以提高医疗质量和效率。</li>
<li>methods: 该研究提出了一个框架，包括多方面图模型、基于时间的不同程度衡量方法和基于传统中心度指标的挖掘方法。</li>
<li>results: 研究在孕综和糖尿病两个例子中证明了该框架的有用性，可以找到相似路径集合、简洁表示路径和按照多个视角显示最重要的 Pattern。<details>
<summary>Abstract</summary>
The automatic discovery of a model to represent the history of encounters of a group of patients with the healthcare system -- the so-called "pathway of patients" -- is a new field of research that supports clinical and organisational decisions to improve the quality and efficiency of the treatment provided. The pathways of patients with chronic conditions tend to vary significantly from one person to another, have repetitive tasks, and demand the analysis of multiple perspectives (interventions, diagnoses, medical specialities, among others) influencing the results. Therefore, modelling and mining those pathways is still a challenging task. In this work, we propose a framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a novel dissimilarity measurement to compare pathways taking the elapsed time into account, and (iii) a mining method based on traditional centrality measures to discover the most relevant steps of the pathways. We evaluated the framework using the study cases of pregnancy and diabetes, which revealed its usefulness in finding clusters of similar pathways, representing them in an easy-to-interpret way, and highlighting the most significant patterns according to multiple perspectives.
</details>
<details>
<summary>摘要</summary>
自动发现患者群体对医疗系统的互动历史模型 -- 称之为"患者路径" -- 是一个新的研究领域，用于支持临床和组织决策，以提高治疗质量和效率。患者的路径通常在不同人群中有很大差异，具有重复的任务和多个视角（如 intervenciones、诊断、医学专业等）的影响。因此，模型和挖掘这些路径仍然是一项挑战。在这项工作中，我们提出了以下框架：（i）基于多方面图的路径模型，（ii）基于时间因素的不同度量来比较路径，以及（iii）基于传统中心度量来挖掘路径中最重要的步骤。我们使用了孕期和糖尿病两个案例进行评估，发现该框架可以快速找到相似路径集，将其易于理解地表示出来，并高亮多个视角中的重要特征。
</details></li>
</ul>
<hr>
<h2 id="LLMCarbon-Modeling-the-end-to-end-Carbon-Footprint-of-Large-Language-Models"><a href="#LLMCarbon-Modeling-the-end-to-end-Carbon-Footprint-of-Large-Language-Models" class="headerlink" title="LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models"></a>LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14393">http://arxiv.org/abs/2309.14393</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sotarokaneda/mlcarbon">https://github.com/sotarokaneda/mlcarbon</a></li>
<li>paper_authors: Ahmad Faiz, Sotaro Kaneda, Ruhan Wang, Rita Osi, Parteek Sharma, Fan Chen, Lei Jiang</li>
<li>for: 这研究旨在提供一个能够精准计算大语言模型（LLM）训练过程中的碳脚印，包括操作和嵌入碳脚印，以及新的 нейрон网络设计的碳脚印预测模型。</li>
<li>methods: 该研究使用了一种名为\textit{LLMCarbon}的端到端碳脚印预测模型，可以对 dense 和 mixture-of-experts（MoE） LLMs 进行碳脚印预测。与之前的研究mlco2相比，\textit{LLMCarbon} 能够更好地预测不同 LLMs 的碳脚印。</li>
<li>results: 对于不同的 LLMs，\textit{LLMCarbon} 能够提供更高的预测精度，并且可以模型出操作和嵌入碳脚印，以及新的 нейрон网络设计的碳脚印。<details>
<summary>Abstract</summary>
The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{LLMCarbon}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly enhances the accuracy of carbon footprint estimations for various LLMs.
</details>
<details>
<summary>摘要</summary>
Large language models (LLMs) 的碳 hoofprint 是一个重要的问题，包括训练、推理、实验和存储过程中的碳排放，包括运行和嵌入碳排放。一个重要的方面是在新的 LLM 出现之前已经准确地估算其碳影响，这主要取决于 GPU 使用情况。现有的研究已经报告了 LLM 训练的碳排放，但只有一个工具，mlco2，可以在物理训练之前预测新的神经网络的碳排放。然而，mlco2 有多个严重的限制。它无法扩展到 dense 或 mixture-of-experts (MoE) LLMs，忽略了关键的建筑 Parameters，围绕 GPU 进行固定的注意力，并不能模拟嵌入碳排放。为了解决这些缺陷，我们介绍了 \textit{LLMCarbon}，一个针对 dense 和 MoE LLMs 的碳排放预测模型。与 mlco2 相比，LLMCarbon 可以对不同类型的 LLMs 提供更高精度的碳排放估算。
</details></li>
</ul>
<hr>
<h2 id="Species196-A-One-Million-Semi-supervised-Dataset-for-Fine-grained-Species-Recognition"><a href="#Species196-A-One-Million-Semi-supervised-Dataset-for-Fine-grained-Species-Recognition" class="headerlink" title="Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition"></a>Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14183">http://arxiv.org/abs/2309.14183</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Species-Dataset/species-dataset.github.io">https://github.com/Species-Dataset/species-dataset.github.io</a></li>
<li>paper_authors: Wei He, Kai Han, Ying Nie, Chengcheng Wang, Yunhe Wang</li>
<li>for: 本研究旨在提供大规模的 semi-supervised 数据集，用于驱逐物种识别领域的深度学习基础模型开发。</li>
<li>methods: 本研究使用 semi-supervised 学习方法，包括 Species196-L 和 Species196-U 两个数据集，以及四种 эксперименталь设定：超级vised 学习、semi-supervised 学习、自我supervised 预训练和 zero-shot 推理。</li>
<li>results: 本研究通过对 Species196 数据集的 represntative 方法进行实证研究，以评估这些方法在驱逐物种识别领域的表现。<details>
<summary>Abstract</summary>
The development of foundation vision models has pushed the general visual recognition to a high level, but cannot well address the fine-grained recognition in specialized domain such as invasive species classification. Identifying and managing invasive species has strong social and ecological value. Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems. To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species. It collects over 19K images with expert-level accurate annotations Species196-L, and 1.2M unlabeled images of invasive species Species196-U. The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi-modal models. To facilitate future research on these four learning paradigms, we conduct an empirical study of the representative methods on the introduced dataset. The dataset is publicly available at https://species-dataset.github.io/.
</details>
<details>
<summary>摘要</summary>
开发基础视觉模型已经提高了普通视识能力到高水平，但无法良好地解决特殊领域的细腻识别。识别和管理入侵物种有着强烈的社会和生态价值。目前，大多数入侵物种数据集都具有有限的规模和局部的种类覆盖率，这限制了深入学习基于入侵生物ometrics系统的发展。为了填补这一领域的空白，我们引入了Species196数据集，这是一个大规模的半指导式数据集，收集了196类入侵物种的19K多张图像，其中Expert-level准确标注 Species196-L，以及1.2万张不标注的入侵物种图像 Species196-U。该数据集提供了四种实验设置，用于测试现有模型和算法的性能，即：指导学习、半指导学习、自动预训练和大多模式模型的零码推理能力。为了促进未来关于这四种学习方法的研究，我们进行了 Species196 数据集上的实验研究。该数据集公开可用于 <https://species-dataset.github.io/>。
</details></li>
</ul>
<hr>
<h2 id="Q-Bench-A-Benchmark-for-General-Purpose-Foundation-Models-on-Low-level-Vision"><a href="#Q-Bench-A-Benchmark-for-General-Purpose-Foundation-Models-on-Low-level-Vision" class="headerlink" title="Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision"></a>Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14181">http://arxiv.org/abs/2309.14181</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Q-Future/Q-Bench">https://github.com/Q-Future/Q-Bench</a></li>
<li>paper_authors: Haoning Wu, Zicheng Zhang, Erli Zhang, Chaofeng Chen, Liang Liao, Annan Wang, Chunyi Li, Wenxiu Sun, Qiong Yan, Guangtao Zhai, Weisi Lin</li>
<li>for: 这个论文是为了评估多Modal Large Language Models (MLLMs)在低级别视觉理解和描述能力方面的能力而写的。</li>
<li>methods: 这个论文使用了以下方法：constructed LLVisionQA dataset，proposed LLDescribe dataset，和一种基于GPT的比较管道来评估MLLMs的描述能力。</li>
<li>results: 这个论文的结果表明MLLMs具有初步的低级别视觉能力，但这些能力还是不稳定和不准确的，需要进一步的提升。<details>
<summary>Abstract</summary>
The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions. c) Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess preliminary low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs. Project Page: https://vqassessment.github.io/Q-Bench.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>多Modal Large Language Models（MLLMs）的快速EVOLUTION catalyzed a shift from specialized models to general-purpose foundation models in computer vision. However, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a comprehensive benchmark crafted to systematically evaluate the potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment.a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions.b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions.c) Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess preliminary low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs. Project Page: <https://vqassessment.github.io/Q-Bench>.
</details></li>
</ul>
<hr>
<h2 id="Data-Upcycling-Knowledge-Distillation-for-Image-Super-Resolution"><a href="#Data-Upcycling-Knowledge-Distillation-for-Image-Super-Resolution" class="headerlink" title="Data Upcycling Knowledge Distillation for Image Super-Resolution"></a>Data Upcycling Knowledge Distillation for Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14162">http://arxiv.org/abs/2309.14162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Zhang, Wei Li, Simiao Li, Jie Hu, Hanting Chen, Hailing Wang, Zhijun Tu, Wenjia Wang, Bingyi Jing, Yunhe Wang</li>
<li>for: 这个论文旨在提出一种基于有效数据利用的知识储存抽象（DUKD）方法，以提高单个图像超分解（SISR）学习模型的表现。</li>
<li>methods: 该方法利用了两种有效的图像缩放操作和可逆数据增强操作，通过引入标签一致常数化来加强知识储存抽象的效果。</li>
<li>results: 对于多个 benchmark 测试，DUKD 方法可以明显超过基eline方法，例如PSNR 指标提高0.5dB，并且减少了 RCAN 模型的参数量，但是其表现与 RCAN 教师模型相当。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) emerges as a challenging yet promising technique for compressing deep learning models, characterized by the transmission of extensive learning representations from proficient and computationally intensive teacher models to compact student models. However, only a handful of studies have endeavored to compress the models for single image super-resolution (SISR) through KD, with their effects on student model enhancement remaining marginal. In this paper, we put forth an approach from the perspective of efficient data utilization, namely, the Data Upcycling Knowledge Distillation (DUKD) which facilitates the student model by the prior knowledge teacher provided via upcycled in-domain data derived from their inputs. This upcycling process is realized through two efficient image zooming operations and invertible data augmentations which introduce the label consistency regularization to the field of KD for SISR and substantially boosts student model's generalization. The DUKD, due to its versatility, can be applied across a broad spectrum of teacher-student architectures. Comprehensive experiments across diverse benchmarks demonstrate that our proposed DUKD method significantly outperforms previous art, exemplified by an increase of up to 0.5dB in PSNR over baselines methods, and a 67% parameters reduced RCAN model's performance remaining on par with that of the RCAN teacher model.
</details>
<details>
<summary>摘要</summary>
知识储备（KD）技术为深度学习模型压缩，涉及教师模型传递丰富的学习表示，以提高学生模型的表达能力。然而，只有一些研究利用KD技术进行单张图像超分辨（SISR）压缩，其影响于学生模型的提高仍然较有限。本文提出了一种基于有效数据利用的方法，即数据升级知识储备（DUKD），通过教师模型提供的先前知识，对学生模型进行升级。这个升级过程通过两种高效的图像缩放操作和可逆数据增强来实现，并在KD领域中引入标签一致化规则。DUKD方法因其灵活性，可以应用于多种教师-学生架构。实验结果表明，我们提出的DUKD方法在多个标准benchmark上达到了 significanly更高的PSNR水平，相比基eline方法，提高了67%的参数量，而RCAN教师模型的性能仍然与RCAN教师模型相当。
</details></li>
</ul>
<hr>
<h2 id="SPIRT-A-Fault-Tolerant-and-Reliable-Peer-to-Peer-Serverless-ML-Training-Architecture"><a href="#SPIRT-A-Fault-Tolerant-and-Reliable-Peer-to-Peer-Serverless-ML-Training-Architecture" class="headerlink" title="SPIRT: A Fault-Tolerant and Reliable Peer-to-Peer Serverless ML Training Architecture"></a>SPIRT: A Fault-Tolerant and Reliable Peer-to-Peer Serverless ML Training Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14148">http://arxiv.org/abs/2309.14148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amine Barrak, Mayssa Jaziri, Ranim Trabelsi, Fehmi Jaafar, Fabio Petrillo</li>
<li>for: 这篇论文旨在探讨 Parametric Serverless Distributed Machine Learning (PSDML) 技术，尤其是在 P2P 分布式学习环境中。</li>
<li>methods: 这篇论文提出了一种基于 RedisAI 的 P2P 分布式学习架构，名为 SPIRT，以实现 fault-tolerant、可靠和安全的分布式机器学习训练。</li>
<li>results: SPIRT 架构可以减少模型更新和梯度平均所需时间的82%，并且具有抗坏 peer 和新 peer 集成的能力，同时保证了分布式机器学习任务的安全性。<details>
<summary>Abstract</summary>
The advent of serverless computing has ushered in notable advancements in distributed machine learning, particularly within parameter server-based architectures. Yet, the integration of serverless features within peer-to-peer (P2P) distributed networks remains largely uncharted. In this paper, we introduce SPIRT, a fault-tolerant, reliable, and secure serverless P2P ML training architecture. designed to bridge this existing gap.   Capitalizing on the inherent robustness and reliability innate to P2P systems, SPIRT employs RedisAI for in-database operations, leading to an 82\% reduction in the time required for model updates and gradient averaging across a variety of models and batch sizes. This architecture showcases resilience against peer failures and adeptly manages the integration of new peers, thereby highlighting its fault-tolerant characteristics and scalability. Furthermore, SPIRT ensures secure communication between peers, enhancing the reliability of distributed machine learning tasks. Even in the face of Byzantine attacks, the system's robust aggregation algorithms maintain high levels of accuracy. These findings illuminate the promising potential of serverless architectures in P2P distributed machine learning, offering a significant stride towards the development of more efficient, scalable, and resilient applications.
</details>
<details>
<summary>摘要</summary>
来自服务器无法 computing的启示，导致分布式机器学习中的分布式机器学习架构得到了重要的进步，特别是在基于参数服务器的架构中。然而，在对等（P2P）分布式网络中 интеGRATION of serverless特性仍然largely unexplored。在这篇论文中，我们引入SPIRT，一个可靠、可靠性和安全的服务器无法分布式机器学习训练架构。通过利用P2P系统的自然强大和可靠性，SPIRT使用RedisAI进行库操作，从而实现82%的模型更新和梯度平均时间优化。这个架构展示了对 peer 失败的抗衰变和新 peer 的适应能力，彰显其可靠性和可扩展性。此外，SPIRT确保了peer之间的安全通信，进一步提高了分布式机器学习任务的可靠性。甚至在面对拜尼黑攻击时，系统的坚固的总和算法可以保持高水平的准确性。这些发现探讨了服务器无法架构在P2P分布式机器学习中的应用前景，提供了一个重要的进步。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Impact-of-Serverless-Computing-on-Peer-To-Peer-Training-Machine-Learning"><a href="#Exploring-the-Impact-of-Serverless-Computing-on-Peer-To-Peer-Training-Machine-Learning" class="headerlink" title="Exploring the Impact of Serverless Computing on Peer To Peer Training Machine Learning"></a>Exploring the Impact of Serverless Computing on Peer To Peer Training Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14139">http://arxiv.org/abs/2309.14139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aminebarrak/peertopeerserverless">https://github.com/aminebarrak/peertopeerserverless</a></li>
<li>paper_authors: Amine Barrak, Ranim Trabelsi, Fehmi Jaafar, Fabio Petrillo</li>
<li>for: 该论文主要旨在提出一种基于服务器レス计算和分布式训练的新架构，以提高分布式训练的可扩展性和容错性。</li>
<li>methods: 该论文使用了分布式 gradient computation 技术，并提出了一种基于 serverless computing 的高效并发分布式训练方法。</li>
<li>results: 研究发现，与传统分布式训练方法相比，该方法可以提高分布式训练的 gradient computation 时间，最高可达 97.34% 的提升。然而，在资源约束下，服务器レス架构可能带来更高的成本，最高达 5.4 倍于实例基础架构。<details>
<summary>Abstract</summary>
The increasing demand for computational power in big data and machine learning has driven the development of distributed training methodologies. Among these, peer-to-peer (P2P) networks provide advantages such as enhanced scalability and fault tolerance. However, they also encounter challenges related to resource consumption, costs, and communication overhead as the number of participating peers grows. In this paper, we introduce a novel architecture that combines serverless computing with P2P networks for distributed training and present a method for efficient parallel gradient computation under resource constraints.   Our findings show a significant enhancement in gradient computation time, with up to a 97.34\% improvement compared to conventional P2P distributed training methods. As for costs, our examination confirmed that the serverless architecture could incur higher expenses, reaching up to 5.4 times more than instance-based architectures. It is essential to consider that these higher costs are associated with marked improvements in computation time, particularly under resource-constrained scenarios. Despite the cost-time trade-off, the serverless approach still holds promise due to its pay-as-you-go model. Utilizing dynamic resource allocation, it enables faster training times and optimized resource utilization, making it a promising candidate for a wide range of machine learning applications.
</details>
<details>
<summary>摘要</summary>
随着大数据和机器学习的需求增长，分布式训练方法得到了广泛应用。在这些方法中，点对点（P2P）网络具有提高可扩展性和fault tolerance的优势。然而，随着参与者的增加，P2P网络也面临资源占用、成本和通信开销的挑战。在这篇论文中，我们介绍了一种新的架构，即无服务器计算与P2P网络的结合，用于分布式训练。我们还提出了一种高效的并发梯度计算方法，以适应资源限制的情况。我们的研究表明，在资源限制情况下，使用无服务器架构可以提高梯度计算时间，最多达97.34%。相比传统的P2P分布式训练方法。虽然无服务器架构可能会增加成本，但是这些成本与计算时间之间的trade-off很明显。尤其是在资源受限的情况下，无服务器架构仍然保持了优势。通过动态资源分配，它可以减少训练时间并优化资源利用，使其成为许多机器学习应用的优选。
</details></li>
</ul>
<hr>
<h2 id="Small-Objects-Matters-in-Weakly-supervised-Semantic-Segmentation"><a href="#Small-Objects-Matters-in-Weakly-supervised-Semantic-Segmentation" class="headerlink" title="Small Objects Matters in Weakly-supervised Semantic Segmentation"></a>Small Objects Matters in Weakly-supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14117">http://arxiv.org/abs/2309.14117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheolhyun Mun, Sanghuk Lee, Youngjung Uh, Junsuk Choe, Hyeran Byun</li>
<li>for: 本研究旨在提供一种全面评估不同 объек 大小的 semantic segmentation 方法的评价指标，以及一个大小均衡的评估集，以便评估不同的 object size 下的 semantic segmentation 方法表现。</li>
<li>methods: 本研究提出了一种新的评价指标，以及一种大小均衡的 cross-entropy 损失函数，以及一种适当的训练策略，以解决现有的 semantic segmentation 方法在小对象上的表现不佳问题。</li>
<li>results: 对于十个基准方法在三个不同的 datasets 上进行了评估，研究发现现有的 semantic segmentation 方法在小对象上的表现不佳，而新提出的大小均衡 cross-entropy 损失函数和适当的训练策略可以改善现有的 semantic segmentation 方法表现。<details>
<summary>Abstract</summary>
Weakly-supervised semantic segmentation (WSSS) performs pixel-wise classification given only image-level labels for training. Despite the difficulty of this task, the research community has achieved promising results over the last five years. Still, current WSSS literature misses the detailed sense of how well the methods perform on different sizes of objects. Thus we propose a novel evaluation metric to provide a comprehensive assessment across different object sizes and collect a size-balanced evaluation set to complement PASCAL VOC. With these two gadgets, we reveal that the existing WSSS methods struggle in capturing small objects. Furthermore, we propose a size-balanced cross-entropy loss coupled with a proper training strategy. It generally improves existing WSSS methods as validated upon ten baselines on three different datasets.
</details>
<details>
<summary>摘要</summary>
弱监督semantic segmentation（WSSS）在给定图像级别标签的情况下进行像素级分类。虽然这是一项复杂的任务，但过去五年研究社区已经取得了可喜的成果。然而，现有WSSS литераature缺乏对不同物体大小的详细评估。因此，我们提出了一种新的评估度量，并收集了一个Size-balanced评估集，以完善PASCAL VOC。通过这两个工具，我们发现现有WSSS方法在捕捉小物体方面努力不足。此外，我们提出了一种Size-balancedcross-entropy损失函数，并与适当的训练策略相结合。它通常会改进现有WSSS方法，并在三个不同的dataset上验证了十个基elines。
</details></li>
</ul>
<hr>
<h2 id="Semi-Abstract-Value-Based-Argumentation-Framework"><a href="#Semi-Abstract-Value-Based-Argumentation-Framework" class="headerlink" title="Semi-Abstract Value-Based Argumentation Framework"></a>Semi-Abstract Value-Based Argumentation Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14112">http://arxiv.org/abs/2309.14112</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jovan Jeromela</li>
<li>for: 本论文主要研究的是abstract argumentation frameworks的扩展和应用。</li>
<li>methods: 本论文使用了value-based argumentation framework和semi-abstract argumentation framework两种扩展，它们增加了对Arguments的结构化表示。</li>
<li>results: 本论文提出了一种新的semi-abstract value-based argumentation framework，该框架可以将 Proposition associate with individual arguments映射到一组排序的值上，并通过新引入的攻击原则来使得隐式攻击变得明确。此外，本论文还使用了这两种框架来形ulate一个复杂的道德困境。<details>
<summary>Abstract</summary>
In his seminal paper, Phan Minh Dung (1995) proposed abstract argumentation framework, which models argumentation using directed graphs where structureless arguments are the nodes and attacks among the arguments are the edges. In the following years, many extensions of this framework were introduced. These extensions typically add a certain form of structure to the arguments. This thesis showcases two such extensions -- value-based argumentation framework by Trevor Bench-Capon (2002) and semi-abstract argumentation framework by Esther Anna Corsi and Christian Ferm\"uller (2017). The former introduces a mapping function that links individual arguments to a set of ordered values, enabling a distinction between objectively and subjectively acceptable arguments. The latter links claims of individual arguments to propositional formulae and then applies newly-introduced attack principles in order to make implicit attacks explicit and to enable a definition of a consequence relation that relies on neither the truth values nor the interpretations in the usual sense.   The contribution of this thesis is two-fold. Firstly, the new semi-abstract value-based argumentation framework is introduced. This framework maps propositional formulae associated with individual arguments to a set of ordered values. Secondly, a complex moral dilemma is formulated using the original and the value-based argumentation frameworks showcasing the expressivity of these formalisms.
</details>
<details>
<summary>摘要</summary>
Phan Minh Dung（1995）提出了抽象论证框架，该框架使用导航图模型了论证，其中无结构的论证是图节点，而论证之间的攻击是图边。后来，许多对这种框架的扩展都被引入。这些扩展通常增加了论证的某种结构。本论文介绍了两种这种扩展：基于值的论证框架（Trevor Bench-Capon，2002）和半抽象论证框架（Esther Anna Corsi和Christian Fermüller，2017）。前者引入了一个映射函数，该函数将 individuak 论证映射到一个排序的值集中，以便分辨 объекively 和 subjectively 可接受的论证。后者将各个论证的laims链接到 propositional 式中，然后应用新引入的攻击原则，以使隐式攻击显式化，并使得定义一种基于真值和解释的后果关系。本论文的贡献有两个方面。首先，本论文引入了一种新的半抽象值基论证框架，该框架将 propositional 式与值集相关联。其次，通过原始论证框架和值基论证框架，形ulated 一个复杂的道德困境示例，以示这两种形式主义的表达能力。
</details></li>
</ul>
<hr>
<h2 id="Comprehensive-Overview-of-Named-Entity-Recognition-Models-Domain-Specific-Applications-and-Challenges"><a href="#Comprehensive-Overview-of-Named-Entity-Recognition-Models-Domain-Specific-Applications-and-Challenges" class="headerlink" title="Comprehensive Overview of Named Entity Recognition: Models, Domain-Specific Applications and Challenges"></a>Comprehensive Overview of Named Entity Recognition: Models, Domain-Specific Applications and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14084">http://arxiv.org/abs/2309.14084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kalyani Pakhale</li>
<li>for: 本文旨在探讨Named Entity Recognition（NER）技术的发展和应用，尤其是将传统rule-based策略与当今AI技术相结合，以提高NER的准确率和泛化能力。</li>
<li>methods: 本文涵盖了NER的基本概念、传统技术和当今AI技术的应用，包括BERT、LSTM和CNN等。特别是在领域化NER模型方面，本文强调了适应性的重要性，并提出了域специфи互调模型的概念。</li>
<li>results: 本文通过实践示例和数据分析，证明了NER技术在金融和生物医学等领域的应用，提高了自动化文本分类和结构化抽取的精度和效率。同时，本文还探讨了NER技术的未来发展和挑战，提出了一些未来研究的可能性和方向。<details>
<summary>Abstract</summary>
In the domain of Natural Language Processing (NLP), Named Entity Recognition (NER) stands out as a pivotal mechanism for extracting structured insights from unstructured text. This manuscript offers an exhaustive exploration into the evolving landscape of NER methodologies, blending foundational principles with contemporary AI advancements. Beginning with the rudimentary concepts of NER, the study spans a spectrum of techniques from traditional rule-based strategies to the contemporary marvels of transformer architectures, particularly highlighting integrations such as BERT with LSTM and CNN. The narrative accentuates domain-specific NER models, tailored for intricate areas like finance, legal, and healthcare, emphasizing their specialized adaptability. Additionally, the research delves into cutting-edge paradigms including reinforcement learning, innovative constructs like E-NER, and the interplay of Optical Character Recognition (OCR) in augmenting NER capabilities. Grounding its insights in practical realms, the paper sheds light on the indispensable role of NER in sectors like finance and biomedicine, addressing the unique challenges they present. The conclusion outlines open challenges and avenues, marking this work as a comprehensive guide for those delving into NER research and applications.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）领域，命名实体识别（NER）作为提取结构化知识从未结构化文本中的重要机制，这篇论文对NER方法的发展进行了极其广泛的探讨，结合了基础原则和当代人工智能技术。这篇论文从传统的规则基础的斜笔概念开始，涵盖了从传统的字符串处理技术到当代的变换器架构，特别是BERT与LSTM和CNN的集成。研究着重点在各个领域中特化的NER模型，如金融、法律和医疗等，强调其特殊适应性。此外，研究还探讨了当前的前沿方法，如强化学习、创新的构造和E-NER，以及Optical Character Recognition（OCR）在NER能力的增强中的作用。以实际场景为基础，论文探讨了NER在金融和生物医学等领域的不可或缺的作用，解决这些领域所存在的特殊挑战。结尾，论文概述了目前的开放挑战和前瞻，用作NER研究和应用的全面指南。
</details></li>
</ul>
<hr>
<h2 id="ODE-based-Recurrent-Model-free-Reinforcement-Learning-for-POMDPs"><a href="#ODE-based-Recurrent-Model-free-Reinforcement-Learning-for-POMDPs" class="headerlink" title="ODE-based Recurrent Model-free Reinforcement Learning for POMDPs"></a>ODE-based Recurrent Model-free Reinforcement Learning for POMDPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14078">http://arxiv.org/abs/2309.14078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanle Zhao, Duzhen Zhang, Liyuan Han, Tielin Zhang, Bo Xu</li>
<li>for: 解决部分可见（PO）环境中的不可见信息推理问题，提高agent的决策能力。</li>
<li>methods: 使用循环策略与紧凑上下文，基于上下文抽象学习（Context-based reinforcement learning）来提取历史转移中的不可见信息。</li>
<li>results: 通过结合ODEs和无约束RL框架，在POMDPs中解决部分可见控制和meta-RL任务，并在不规则观察数据上进行了实验验证。<details>
<summary>Abstract</summary>
Neural ordinary differential equations (ODEs) are widely recognized as the standard for modeling physical mechanisms, which help to perform approximate inference in unknown physical or biological environments. In partially observable (PO) environments, how to infer unseen information from raw observations puzzled the agents. By using a recurrent policy with a compact context, context-based reinforcement learning provides a flexible way to extract unobservable information from historical transitions. To help the agent extract more dynamics-related information, we present a novel ODE-based recurrent model combines with model-free reinforcement learning (RL) framework to solve partially observable Markov decision processes (POMDPs). We experimentally demonstrate the efficacy of our methods across various PO continuous control and meta-RL tasks. Furthermore, our experiments illustrate that our method is robust against irregular observations, owing to the ability of ODEs to model irregularly-sampled time series.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Maximum-Likelihood-Estimation-of-Latent-Variable-Structural-Equation-Models-A-Neural-Network-Approach"><a href="#Maximum-Likelihood-Estimation-of-Latent-Variable-Structural-Equation-Models-A-Neural-Network-Approach" class="headerlink" title="Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach"></a>Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14073">http://arxiv.org/abs/2309.14073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehrzad Saremi</li>
<li>for: 这个论文是为了提出一种稳定的图形结构模型，可以在linearity和Gaussianity假设下保持稳定。</li>
<li>methods: 该论文使用了一种基于GPU的算法，用于计算最大 likelihood estimation 的这些模型。</li>
<li>results: 该论文表明，计算最大 likelihood estimation 的这些模型等价于训练一个神经网络。<details>
<summary>Abstract</summary>
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种图解结构，用于结构方程模型，该结构在 Linearity 和 Gaussianity 假设下是稳定的。我们表明计算最大likelihood估计这种模型的过程与训练神经网络相同。我们实现了基于GPU的算法，用于计算这种模型的最大likelihood估计。Note: "Linearity" and "Gaussianity" are not exact translations of the English words, but they are commonly used terms in statistics and machine learning to refer to the assumptions of linearity and normality, respectively.
</details></li>
</ul>
<hr>
<h2 id="Adapt-then-Unlearn-Exploiting-Parameter-Space-Semantics-for-Unlearning-in-Generative-Adversarial-Networks"><a href="#Adapt-then-Unlearn-Exploiting-Parameter-Space-Semantics-for-Unlearning-in-Generative-Adversarial-Networks" class="headerlink" title="Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning in Generative Adversarial Networks"></a>Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning in Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14054">http://arxiv.org/abs/2309.14054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Tiwary, Atri Guha, Subhodip Panda, Prathosh A. P</li>
<li>for: 防止深度生成模型生成包含不良、袋陋或危险内容的输出。</li>
<li>methods: 基于用户提供的负例进行适应，然后使用排斥正则化训练已经适应模型，以快速忘记特定不良特征。</li>
<li>results: 验证了方法的有效性，能够快速、高效地忘记深度生成模型中不良特征，同时保持生成样本质量。<details>
<summary>Abstract</summary>
The increased attention to regulating the outputs of deep generative models, driven by growing concerns about privacy and regulatory compliance, has highlighted the need for effective control over these models. This necessity arises from instances where generative models produce outputs containing undesirable, offensive, or potentially harmful content. To tackle this challenge, the concept of machine unlearning has emerged, aiming to forget specific learned information or to erase the influence of undesired data subsets from a trained model. The objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained GAN where the underlying training data set is inaccessible. Our approach is inspired by a crucial observation: the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. This method unfolds in two stages: in the initial stage, we adapt the pre-trained GAN using negative samples provided by the user, while in the subsequent stage, we focus on unlearning the undesired feature. During the latter phase, we train the pre-trained GAN using positive samples, incorporating a repulsion regularizer. This regularizer encourages the model's parameters to be away from the parameters associated with the adapted model from the first stage while also maintaining the quality of generated samples. To the best of our knowledge, our approach stands as first method addressing unlearning in GANs. We validate the effectiveness of our method through comprehensive experiments.
</details>
<details>
<summary>摘要</summary>
“随着深度生成模型的输出控制需求的增加，导致了关于隐私和合规遵循的担忧。这些担忧的来源是深度生成模型生成的内容中可能包含不适合、歧视或可能危害的内容。为了解决这个挑战，机器忘记（Machine Unlearning）的概念已经出现，旨在忘记特定学习的信息或从已训练的模型中除去不适合的数据子集。我们的目标是防止从已训练的GAN（生成推导网络）中生成包含不适合特征的出力。我们的方法是根据GAN的参数空间展现意义的方向来抑制不适合的特征。但是，这些方向通常会导致生成的样本质量下降。我们的提案方法，称为“Adapt-then-Unlearn”，能够忘记不适合的特征而保持生成的质量。这个方法分成两个阶段：在首先阶段，我们适应已训练的GAN使用用户提供的负面样本，而在后续阶段，我们专注于忘记不适合的特征。在这个阶段中，我们使用正常化器来训练已训练的GAN，并且将这些参数导向远离已适应的模型参数。我们的方法是首个对GAN进行忘记的方法。我们透过广泛的实验证明了我们的方法的有效性。”
</details></li>
</ul>
<hr>
<h2 id="Revisiting-LARS-for-Large-Batch-Training-Generalization-of-Neural-Networks"><a href="#Revisiting-LARS-for-Large-Batch-Training-Generalization-of-Neural-Networks" class="headerlink" title="Revisiting LARS for Large Batch Training Generalization of Neural Networks"></a>Revisiting LARS for Large Batch Training Generalization of Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14053">http://arxiv.org/abs/2309.14053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khoi Do, Duong Nguyen, Hoa Nguyen, Long Tran-Thanh, Quoc-Viet Pham</li>
<li>for: 本文旨在研究Large Batch Learning（LBL）中的稳定性问题，特别是AI训练过程中捕捉到锐 minimum 的问题。</li>
<li>methods: 本文使用了LARS和LAMB两种广泛使用的技术，以及一种热启动策略。</li>
<li>results: 实验表明，TVLARS可以在不使用热启动策略的情况下实现稳定的训练，并且在使用热启动策略时可以与LARS和LAMB相比赢得竞争性的成绩。<details>
<summary>Abstract</summary>
LARS and LAMB have emerged as prominent techniques in Large Batch Learning (LBL), ensuring the stability of AI training. One of the primary challenges in LBL is convergence stability, where the AI agent usually gets trapped into the sharp minimizer. Addressing this challenge, a relatively recent technique, known as warm-up, has been employed. However, warm-up lacks a strong theoretical foundation, leaving the door open for further exploration of more efficacious algorithms. In light of this situation, we conduct empirical experiments to analyze the behaviors of the two most popular optimizers in the LARS family: LARS and LAMB, with and without a warm-up strategy. Our analyses give us a comprehension of the novel LARS, LAMB, and the necessity of a warm-up technique in LBL. Building upon these insights, we propose a novel algorithm called Time Varying LARS (TVLARS), which facilitates robust training in the initial phase without the need for warm-up. Experimental evaluation demonstrates that TVLARS achieves competitive results with LARS and LAMB when warm-up is utilized while surpassing their performance without the warm-up technique.
</details>
<details>
<summary>摘要</summary>
LARS和LAMB已成为大批学习（LBL）中显著的技术，确保训练稳定性。LBL的一个主要挑战是稳定性，AI代理通常会被拥堵在细小的最小值中。为解决这个挑战，一种相对较新的技术——暖身法——已经被采用。然而，暖身法没有强有力的理论基础，留下了进一步探索更有效的算法的门户。在这种情况下，我们进行了实验研究，分析了LARS和LAMB两个最受欢迎的优化器在LBL中的行为。我们的分析帮助我们更好地理解LARS、LAMB和暖身法的必要性，并在这些基础上提出了一种新的算法——时间变化LARS（TVLARS）。TVLARS可以在初始阶段实现稳定训练，不需要暖身法。实验评估表明，TVLARS在使用暖身法时与LARS和LAMB具有竞争性的性能，而无需暖身法时则超越它们。
</details></li>
</ul>
<hr>
<h2 id="An-automatic-selection-of-optimal-recurrent-neural-network-architecture-for-processes-dynamics-modelling-purposes"><a href="#An-automatic-selection-of-optimal-recurrent-neural-network-architecture-for-processes-dynamics-modelling-purposes" class="headerlink" title="An automatic selection of optimal recurrent neural network architecture for processes dynamics modelling purposes"></a>An automatic selection of optimal recurrent neural network architecture for processes dynamics modelling purposes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14037">http://arxiv.org/abs/2309.14037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krzysztof Laddach, Rafał Łangowski, Tomasz A. Rutkowski, Bartosz Puchalski</li>
<li>for: 这个论文是为了解决人工神经网络用于行为（黑盒）模型Selected动态过程的开发问题。</li>
<li>methods: 本研究包括四种原创的神经网络架构搜索算法，基于 известные优化技术如进化算法和梯度下降方法。</li>
<li>results: 在使用了扩展验证研究的数据，研究人员通过提出特殊化的进化操作来优化神经网络架构，实现了神经网络的尺寸和准确性之间的变换。<details>
<summary>Abstract</summary>
A problem related to the development of algorithms designed to find the structure of artificial neural network used for behavioural (black-box) modelling of selected dynamic processes has been addressed in this paper. The research has included four original proposals of algorithms dedicated to neural network architecture search. Algorithms have been based on well-known optimisation techniques such as evolutionary algorithms and gradient descent methods. In the presented research an artificial neural network of recurrent type has been used, whose architecture has been selected in an optimised way based on the above-mentioned algorithms. The optimality has been understood as achieving a trade-off between the size of the neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. During the optimisation, original specialised evolutionary operators have been proposed. The research involved an extended validation study based on data generated from a mathematical model of the fast processes occurring in a pressurised water nuclear reactor.
</details>
<details>
<summary>摘要</summary>
In the research, an artificial neural network of recurrent type is used, and its architecture is selected in an optimized way based on the above-mentioned algorithms. The optimality is understood as achieving a trade-off between the size of the neural network and its accuracy in capturing the response of the mathematical model under which it has been learned.During the optimization, original specialized evolutionary operators are proposed. The research involves an extended validation study based on data generated from a mathematical model of the fast processes occurring in a pressurized water nuclear reactor.Translated into Simplified Chinese:这篇论文关注了人工神经网络（ANN）用于Behavioral（黑盒）模型选择动态过程的开发算法问题。研究包括四种原创的算法提案，基于常见的优化技术 such as evolutionary algorithms和梯度下降方法。在研究中，使用了一个人工神经网络的回归类型，其架构通过上述算法进行优化。优化的目标是在神经网络的大小和学习模型的响应之间寻找一个平衡点。在优化过程中，提出了原创的特殊演化算法。研究还包括一个扩展验证研究，基于核电站压力水堆受控核反应的数学模型生成的数据。
</details></li>
</ul>
<hr>
<h2 id="DeepACO-Neural-enhanced-Ant-Systems-for-Combinatorial-Optimization"><a href="#DeepACO-Neural-enhanced-Ant-Systems-for-Combinatorial-Optimization" class="headerlink" title="DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization"></a>DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14032">http://arxiv.org/abs/2309.14032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/henry-yeh/DeepACO">https://github.com/henry-yeh/DeepACO</a></li>
<li>paper_authors: Haoran Ye, Jiarui Wang, Zhiguang Cao, Helan Liang, Yong Li</li>
<li>for: 本研究提出了一种基于深度学习的ACO框架，以自动化ACO算法中的规则设计。</li>
<li>methods: 该框架使用深度学习来强化ACO算法中的优化策略，并且只需一个神经网络和一组超参数来应用于多种具体问题。</li>
<li>results: 对八种具体问题进行测试，DeepACO consistently outperforms传统的ACO算法，并且在许多情况下比特定问题的方法更好或与其相当。<details>
<summary>Abstract</summary>
Ant Colony Optimization (ACO) is a meta-heuristic algorithm that has been successfully applied to various Combinatorial Optimization Problems (COPs). Traditionally, customizing ACO for a specific problem requires the expert design of knowledge-driven heuristics. In this paper, we propose DeepACO, a generic framework that leverages deep reinforcement learning to automate heuristic designs. DeepACO serves to strengthen the heuristic measures of existing ACO algorithms and dispense with laborious manual design in future ACO applications. As a neural-enhanced meta-heuristic, DeepACO consistently outperforms its ACO counterparts on eight COPs using a single neural model and a single set of hyperparameters. As a Neural Combinatorial Optimization method, DeepACO performs better than or on par with problem-specific methods on canonical routing problems. Our code is publicly available at https://github.com/henry-yeh/DeepACO.
</details>
<details>
<summary>摘要</summary>
《蟑螂群体优化（ACO）是一种元规则算法，已经成功应用于多种 combinatorial optimization problems（COPs）。传统上，为特定问题自定义 ACO 需要专家设计知识驱动的规则。在这篇论文中，我们提议了 DeepACO，一种通用框架，利用深度强化学习自动化规则设计。DeepACO 可以增强现有 ACO 算法的规则措施，并减少未来 ACO 应用中的劳动密集设计。作为一种神经元规则优化方法，DeepACO 在八种 COPs 上以单个神经网络和单个超参数表现出色，并且在 canonical routing problems 中表现更好或与专门方法一样。我们的代码公开在 GitHub 上，请参考 <https://github.com/henry-yeh/DeepACO>。》
</details></li>
</ul>
<hr>
<h2 id="Diffeomorphic-Transformations-for-Time-Series-Analysis-An-Efficient-Approach-to-Nonlinear-Warping"><a href="#Diffeomorphic-Transformations-for-Time-Series-Analysis-An-Efficient-Approach-to-Nonlinear-Warping" class="headerlink" title="Diffeomorphic Transformations for Time Series Analysis: An Efficient Approach to Nonlinear Warping"></a>Diffeomorphic Transformations for Time Series Analysis: An Efficient Approach to Nonlinear Warping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14029">http://arxiv.org/abs/2309.14029</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iñigo Martinez</li>
<li>for: 这个论文主要针对的是如何处理时间序列数据，以及设计特有的时间序列相似性、分类和对应方法。</li>
<li>methods: 本论文提出了一些新的柔性对焦方法，使用参数化和对焦变换来扩展和改进传统的时间序列相似性计量方法。这些方法是可微的、可逆的、敏感度高且可以应对噪音和异常值。</li>
<li>results: 本论文的结果显示，这些新的柔性对焦方法可以实现高精度的时间序列相似性计量，并且可以与深度学习架构结合，以提高时间序列分类和对应的性能。此外，论文还提出了一些进一步的技术，例如增强的时间transformer网络、深度学习基于时间序列分类模型、可扩展的时间序列对焦分群算法和可扩展的时间序列对焦模型。<details>
<summary>Abstract</summary>
The proliferation and ubiquity of temporal data across many disciplines has sparked interest for similarity, classification and clustering methods specifically designed to handle time series data. A core issue when dealing with time series is determining their pairwise similarity, i.e., the degree to which a given time series resembles another. Traditional distance measures such as the Euclidean are not well-suited due to the time-dependent nature of the data. Elastic metrics such as dynamic time warping (DTW) offer a promising approach, but are limited by their computational complexity, non-differentiability and sensitivity to noise and outliers. This thesis proposes novel elastic alignment methods that use parametric \& diffeomorphic warping transformations as a means of overcoming the shortcomings of DTW-based metrics. The proposed method is differentiable \& invertible, well-suited for deep learning architectures, robust to noise and outliers, computationally efficient, and is expressive and flexible enough to capture complex patterns. Furthermore, a closed-form solution was developed for the gradient of these diffeomorphic transformations, which allows an efficient search in the parameter space, leading to better solutions at convergence. Leveraging the benefits of these closed-form diffeomorphic transformations, this thesis proposes a suite of advancements that include: (a) an enhanced temporal transformer network for time series alignment and averaging, (b) a deep-learning based time series classification model to simultaneously align and classify signals with high accuracy, (c) an incremental time series clustering algorithm that is warping-invariant, scalable and can operate under limited computational and time resources, and finally, (d) a normalizing flow model that enhances the flexibility of affine transformations in coupling and autoregressive layers.
</details>
<details>
<summary>摘要</summary>
“随着时间数据的普遍和多元化，对时间序列资料的相似性、分类和对应方法已经引起了广泛的关注。时间序列之间的相似度决定是一个核心问题，因为传统的距离度量如欧几何距离（Euclidean distance）不适合时间序列资料。弹性度量如动态时间截弯（DTW）提供了一个有前途的方法，但是它们受到计算复杂度、非断统和干扰和噪音的影响。本论文提出了一些新的弹性对称方法，使用参数和 diffeomorphic 截弯变换来超越 DTW 基础的缺陷。这些方法是可微和可逆的，适合深度学习架构，具有较高的计算效率，并且具有较好的抗干扰和噪音性。此外，这些方法还具有关于参数空间的关注解，可以实现更好的搜索和更高的精度。本论文提出了以下几个提升：（a）改进的时间序列变换网络，用于时间序列Alignment和平均（b）使用深度学习的时间序列分类模型，同时进行时间序列Alignment和分类，（c）可扩展的时间序列集群分析算法，可以在有限的计算和时间资源下进行扩展和可扩展，（d）使用流形变换来增强时间序列的弹性和自适应性。”
</details></li>
</ul>
<hr>
<h2 id="LORD-Low-Rank-Decomposition-Of-Monolingual-Code-LLMs-For-One-Shot-Compression"><a href="#LORD-Low-Rank-Decomposition-Of-Monolingual-Code-LLMs-For-One-Shot-Compression" class="headerlink" title="LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression"></a>LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14021">http://arxiv.org/abs/2309.14021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayush Kaushal, Tejas Vaidhya, Irina Rish</li>
<li>for: 这篇论文探讨了如何使用低阶分解（LoRD）来压缩大语言模型（LLM），以提高执行速度。</li>
<li>methods: 论文使用了低阶分解（LoRD）方法，将大量的Linear层分解为两个较小的Matrix，以减少模型的参数数量，并且保持了完全可微和所有参数可训练。</li>
<li>results: 论文的实验结果显示，使用LoRD压缩StarCoder 16B模型，可以将其变数数量从16B降至13.2B，而且只需要少于10分钟的时间，且没有Drop的情况下，对于推导速度有22.35%的提升。此外，LoRD模型可以与现有的高效缓存方法进行并行优化，以提高推导速度。<details>
<summary>Abstract</summary>
Low Rank Decomposition of matrix - splitting a large matrix into a product of two smaller matrix offers a means for compression that reduces the parameters of a model without sparsification, and hence delivering more speedup on modern hardware. Moreover, unlike quantization, the compressed linear layers remain fully differentiable and all the parameters trainable, while being able to leverage the existing highly efficient kernels over floating point matrices. We study the potential to compress Large Language Models (LLMs) for monolingual Code generation via Low Rank Decomposition (LoRD) and observe that ranks for the linear layers in these models can be reduced by upto 39.58% with less than 1% increase in perplexity. We then use Low Rank Decomposition (LoRD) to compress StarCoder 16B to 13.2B parameter with no drop and to 12.3B with minimal drop in HumanEval Pass@1 score, in less than 10 minutes on a single A100. The compressed models speeds up inference by up to 22.35% with just a single line of change in code over huggingface's implementation with pytorch backend. Low Rank Decomposition (LoRD) models remain compatible with state of the art near-lossless quantization method such as SpQR, which allows leveraging further compression gains of quantization. Lastly, QLoRA over Low Rank Decomposition (LoRD) model further reduces memory requirements by as much as 21.2% over vanilla QLoRA while offering similar gains from parameter efficient fine tuning. Our work shows Low Rank Decomposition (LoRD) as a promising new paradigm for LLM compression.
</details>
<details>
<summary>摘要</summary>
LOW Rank Decomposition of matrix - 将大Matrix split into two smaller matrices 提供了压缩方法，可以减少模型参数而不是简化，从而在现代硬件上提高速度。此外，与量化不同，压缩的线性层保持完全可导和所有参数可训练，同时可以利用浮点数矩阵的高效内核。我们研究了使用LOW Rank Decomposition (LoRD)压缩大型自然语言模型（LLMs），并发现可以将线性层的排名减少到39.58%，并且影响下降小于1%。然后，我们使用LoRD压缩StarCoder 16B 到 13.2B 参数，在单个 A100 上在 less than 10 分钟内完成，而无需Drop的情况下，带有 minimal Drop 的 HumanEval Pass@1 分数。压缩后的模型可以提高推理速度，达到22.35%的提升，只需要在代码中进行单行修改。LoRD 模型与现有的高效 near-lossless 量化方法相容，例如 SpQR，可以进一步减少压缩参数。最后，QLoRA over LoRD 模型可以减少内存需求，达到21.2%的减少，同时保持与参数高效 fine-tuning 的相同减少。我们的工作表明LOW Rank Decomposition (LoRD) 是一种有前途的新方法 для LLM 压缩。
</details></li>
</ul>
<hr>
<h2 id="Morphological-Computing-as-Logic-Underlying-Cognition-in-Human-Animal-and-Intelligent-Machine"><a href="#Morphological-Computing-as-Logic-Underlying-Cognition-in-Human-Animal-and-Intelligent-Machine" class="headerlink" title="Morphological Computing as Logic Underlying Cognition in Human, Animal, and Intelligent Machine"></a>Morphological Computing as Logic Underlying Cognition in Human, Animal, and Intelligent Machine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13979">http://arxiv.org/abs/2309.13979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gordana Dodig-Crnkovic</li>
<li>for: 本文探讨了自然主义传统下的逻辑、 epistemology 和科学之间的关系。</li>
<li>methods: 文章提出了一种连接逻辑、数学、物理、化学、生物和认知的方案，强调自然 proceses 中的缩减不变的、自组织的动力学。</li>
<li>results: 文章表明了生物体的逻辑存在于自然过程中，并且 humans, animals 和 artifactual agents 都具有内在的逻辑。人类中心的、基于自然语言的逻辑是生物体演化出来的复杂逻辑的 simplest form。因此, cognitive 逻辑来自物理、化学和生物逻辑的演化。在一个自组织的计算框架中，可以使用基于形态&#x2F;物理&#x2F;自然计算的创新计算框架来解释人类中心的逻辑的起源。extend Evolutionary Synthesis 是理解人类逻辑的起源和逻辑与信息处理&#x2F;计算 epistemology 之间的关系的关键。<details>
<summary>Abstract</summary>
This work examines the interconnections between logic, epistemology, and sciences within the Naturalist tradition. It presents a scheme that connects logic, mathematics, physics, chemistry, biology, and cognition, emphasizing scale-invariant, self-organizing dynamics across organizational tiers of nature. The inherent logic of agency exists in natural processes at various levels, under information exchanges. It applies to humans, animals, and artifactual agents. The common human-centric, natural language-based logic is an example of complex logic evolved by living organisms that already appears in the simplest form at the level of basal cognition of unicellular organisms. Thus, cognitive logic stems from the evolution of physical, chemical, and biological logic. In a computing nature framework with a self-organizing agency, innovative computational frameworks grounded in morphological/physical/natural computation can be used to explain the genesis of human-centered logic through the steps of naturalized logical processes at lower levels of organization. The Extended Evolutionary Synthesis of living agents is essential for understanding the emergence of human-level logic and the relationship between logic and information processing/computational epistemology. We conclude that more research is needed to elucidate the details of the mechanisms linking natural phenomena with the logic of agency in nature.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detecting-Sexual-Content-at-the-Sentence-Level-in-First-Millennium-Latin-Texts"><a href="#Detecting-Sexual-Content-at-the-Sentence-Level-in-First-Millennium-Latin-Texts" class="headerlink" title="Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts"></a>Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14974">http://arxiv.org/abs/2309.14974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lascivaroma/seligator">https://github.com/lascivaroma/seligator</a></li>
<li>paper_authors: Thibault Clérice</li>
<li>for: 这个研究旨在使用深度学习方法对句子水平进行Semantic classification，以加速人文学科和语言学科中 tradicional和时间consuming的Corpus建设。</li>
<li>methods: 我们引入了一个新的Corpus，包括约2500句文本，从300BCE到900CE，涵盖性 semantics（医学、 эротика等）。我们评估了各种句子分类方法和不同的输入嵌入层，并显示它们都能够超越简单的符号based搜索。</li>
<li>results: 我们的结果表明，这种方法有效，具有高精度和真正的正确率（TPR），分别为70.60%和86.33% using HAN。我们也评估了数据集大小对模型性能的影响（420个 вместо 2013），并显示，虽然我们的模型性能下降，但仍然可以提供高准确率和TPR，甚至无需MLM。<details>
<summary>Abstract</summary>
In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models perform worse, they still offer a high enough precision and TPR, even without MLM, respectively 69% and 51%. Given the result, we provide an analysis of the attention mechanism as a supporting added value for humanists in order to produce more data.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提议使用深度学习方法进行含义分类，以加速人文科学和语言学领域的 корпу文建设，这是传统的时间消耗性任务。我们介绍了一个新的词库，包含约2500个句子，从300年前至900年前，涵盖性 semantics（医学、 эротиче、等）。我们评估了不同句子分类方法和输入嵌入层，发现它们都能够持续性地超越简单的token-based搜索。我们探索了idiololectal和sociolectic metadata嵌入（世纪、作者、类型的写作）的集成，但发现它会导致过拟合。我们的结果表明这种方法的有效性，卷积率分别为70.60%和86.33%使用HAN。我们评估了数据集大小对模型性能的影响（420个 вместо2013），发现，虽然我们的模型表现不佳，但它们仍然可以提供高准确率和TPR，甚至没有MLM，分别为69%和51%。 giventhe result，我们提供了关注机制的分析，作为支持的加值，以便人文科学家生产更多数据。
</details></li>
</ul>
<hr>
<h2 id="Audio-classification-with-Dilated-Convolution-with-Learnable-Spacings"><a href="#Audio-classification-with-Dilated-Convolution-with-Learnable-Spacings" class="headerlink" title="Audio classification with Dilated Convolution with Learnable Spacings"></a>Audio classification with Dilated Convolution with Learnable Spacings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13972">http://arxiv.org/abs/2309.13972</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k-h-ismail/dcls-audio">https://github.com/k-h-ismail/dcls-audio</a></li>
<li>paper_authors: Ismail Khalfaoui-Hassani, Timothée Masquelier, Thomas Pellegrini</li>
<li>for: 这个论文是关于音频标注的研究，使用了增宽 convolution 方法来提高音频分类的准确率。</li>
<li>methods: 这个论文使用了 learnable spacings 的增宽 convolution 方法（DCLS），将 DSC 层替换为 DCLS 层，以提高 AudioSet 分类 benchmark 的准确率。</li>
<li>results: 研究发现，使用 DCLS 方法可以在不增加参数数量和只增加低成本的情况下，提高音频分类的准确率。<details>
<summary>Abstract</summary>
Dilated convolution with learnable spacings (DCLS) is a recent convolution method in which the positions of the kernel elements are learned throughout training by backpropagation. Its interest has recently been demonstrated in computer vision (ImageNet classification and downstream tasks). Here we show that DCLS is also useful for audio tagging using the AudioSet classification benchmark. We took two state-of-the-art convolutional architectures using depthwise separable convolutions (DSC), ConvNeXt and ConvFormer, and a hybrid one using attention in addition, FastViT, and drop-in replaced all the DSC layers by DCLS ones. This significantly improved the mean average precision (mAP) with the three architectures without increasing the number of parameters and with only a low cost on the throughput. The method code is based on PyTorch and is available at https://github.com/K-H-Ismail/DCLS-Audio
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>最近的扩展 convolution 方法之一是learned spacings dilated convolution (DCLS)，它在训练过程中通过反传播学习kernel元素的位置。在计算机视觉中（ImageNet分类和下游任务），DCLS的利用得到了广泛的关注。在这篇文章中，我们表明DCLS也是有用的 для音频标注，我们使用了两个现代 convolutional 架构（DSC），ConvNeXt和ConvFormer，以及一个hybrid架构使用注意力，FastViT，并将所有DSC层换为DCLS层。这会显著提高mAP值，而无需增加参数数量和只增加低成本的通过put Throughput。代码基于PyTorch，可在https://github.com/K-H-Ismail/DCLS-Audio 上下载。
</details></li>
</ul>
<hr>
<h2 id="An-AI-Chatbot-for-Explaining-Deep-Reinforcement-Learning-Decisions-of-Service-oriented-Systems"><a href="#An-AI-Chatbot-for-Explaining-Deep-Reinforcement-Learning-Decisions-of-Service-oriented-Systems" class="headerlink" title="An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems"></a>An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14391">http://arxiv.org/abs/2309.14391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/xrl2/chat4xai">https://gitlab.com/xrl2/chat4xai</a></li>
<li>paper_authors: Andreas Metzger, Jone Bartel, Jan Laufer</li>
<li>for: 本研究旨在帮助服务开发人员、服务提供者和服务用户更好地理解深度强化学习（Deep Reinforcement Learning，简称Deep RL）的决策过程，以便在服务系统中应用Deep RL。</li>
<li>methods: 本研究使用了现代人工智能对话系统技术和专门的提问工程来实现自然语言解释。相比于传统的软件基于对话系统，使用AI对话系统可以消除需要抽象出问题和答案的过程。</li>
<li>results: 本研究通过使用OpenAI的ChatGPT API实现了Chat4XAI，并评估了其解释的准确性和稳定性，结果表明，使用自然语言解释可以提高服务开发人员、服务提供者和服务用户对Deep RL决策过程的理解，并且可以提高服务用户对服务的信任和接受度。<details>
<summary>Abstract</summary>
Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more efficient explanations. Chat4XAI leverages modern AI chatbot technology and dedicated prompt engineering. Compared to earlier work on natural-language explanations using classical software-based dialogue systems, using an AI chatbot eliminates the need for eliciting and defining potential questions and answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API and evaluate the fidelity and stability of its explanations using an adaptive service exemplar.
</details>
<details>
<summary>摘要</summary>
深度强化学习（深度RL）在服务 ориентирован系统中得到广泛应用，以应对开放世界假设。深度RL在动态服务组合、作业调度和下载等问题上取得了成功，同时也应用于服务适应性。然而，深度RL的决策过程理解具有挑战，因为它的学习决策策略看起来就像黑盒子。然而，理解深度RL的决策过程是关键，以帮助服务开发人员进行调试、支持服务提供者遵守相关法规，并促进服务用户建立信任。我们介绍了 Chat4XAI，用于促进深度RL 决策过程的理解，提供自然语言解释。与视觉解释相比，报告的优点包括更好的可读性 для非技术用户、更高的用户接受度和信任度，以及更高效的解释。 Chat4XAI 利用现代人工智能聊天机器人技术和专门的推荐工程。与先前的классиical软件基础的对话系统相比，使用 AI 聊天机器人解除了需要提取和定义 potential questions and answers 的需求。我们使用 OpenAI 的 ChatGPT API 实现 Chat4XAI，并评估其解释的准确性和稳定性使用适应服务示例。
</details></li>
</ul>
<hr>
<h2 id="May-I-Ask-a-Follow-up-Question-Understanding-the-Benefits-of-Conversations-in-Neural-Network-Explainability"><a href="#May-I-Ask-a-Follow-up-Question-Understanding-the-Benefits-of-Conversations-in-Neural-Network-Explainability" class="headerlink" title="May I Ask a Follow-up Question? Understanding the Benefits of Conversations in Neural Network Explainability"></a>May I Ask a Follow-up Question? Understanding the Benefits of Conversations in Neural Network Explainability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13965">http://arxiv.org/abs/2309.13965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Zhang, X. Jessie Yang, Boyang Li</li>
<li>for: 提高用户理解和信任AI模型的决策过程</li>
<li>methods: 使用自由形态对话提高用户理解和信任</li>
<li>results: 对话可以提高用户的理解、acceptance和信任，并促进人机合作<details>
<summary>Abstract</summary>
Research in explainable AI (XAI) aims to provide insights into the decision-making process of opaque AI models. To date, most XAI methods offer one-off and static explanations, which cannot cater to the diverse backgrounds and understanding levels of users. With this paper, we investigate if free-form conversations can enhance users' comprehension of static explanations, improve acceptance and trust in the explanation methods, and facilitate human-AI collaboration. Participants are presented with static explanations, followed by a conversation with a human expert regarding the explanations. We measure the effect of the conversation on participants' ability to choose, from three machine learning models, the most accurate one based on explanations and their self-reported comprehension, acceptance, and trust. Empirical results show that conversations significantly improve comprehension, acceptance, trust, and collaboration. Our findings highlight the importance of customized model explanations in the format of free-form conversations and provide insights for the future design of conversational explanations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Early-Churn-Prediction-from-Large-Scale-User-Product-Interaction-Time-Series"><a href="#Early-Churn-Prediction-from-Large-Scale-User-Product-Interaction-Time-Series" class="headerlink" title="Early Churn Prediction from Large Scale User-Product Interaction Time Series"></a>Early Churn Prediction from Large Scale User-Product Interaction Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14390">http://arxiv.org/abs/2309.14390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Bhattacharjee, Utkarsh Thukral, Nilesh Patil</li>
<li>For: The paper aims to predict user churn in business-to-customer scenarios, with a focus on fantasy sports, and to provide insights for businesses to formulate effective retention plans.* Methods: The paper uses historical data and combines user activity with deep neural networks for multivariate time series classification, demonstrating remarkable results for churn prediction in complex contexts.* Results: The paper achieves high accuracy in predicting customer churn likelihood, providing valuable insights for businesses to understand attrition trends and develop effective retention strategies.Here’s the simplified Chinese text for the three information points:* For: 这篇论文目标是预测商业到客户场景中的用户弃用，特别是在幻想体育中，以便为企业提供有价值的归属趋势和退休计划。* Methods: 该论文使用历史数据，将用户活动与深度神经网络结合，实现多变量时间序列分类，在复杂的商业到客户场景中达到了Remarkable的弃用预测结果。* Results: 该论文在预测客户弃用可能性方面实现了高精度，为企业提供有价值的归属趋势和退休计划。<details>
<summary>Abstract</summary>
User churn, characterized by customers ending their relationship with a business, has profound economic consequences across various Business-to-Customer scenarios. For numerous system-to-user actions, such as promotional discounts and retention campaigns, predicting potential churners stands as a primary objective. In volatile sectors like fantasy sports, unpredictable factors such as international sports events can influence even regular spending habits. Consequently, while transaction history and user-product interaction are valuable in predicting churn, they demand deep domain knowledge and intricate feature engineering. Additionally, feature development for churn prediction systems can be resource-intensive, particularly in production settings serving 200m+ users, where inference pipelines largely focus on feature engineering. This paper conducts an exhaustive study on predicting user churn using historical data. We aim to create a model forecasting customer churn likelihood, facilitating businesses in comprehending attrition trends and formulating effective retention plans. Our approach treats churn prediction as multivariate time series classification, demonstrating that combining user activity and deep neural networks yields remarkable results for churn prediction in complex business-to-customer contexts.
</details>
<details>
<summary>摘要</summary>
用户卷退，指客户与企业结束业务关系，对各种商业到客户场景产生深刻的经济影响。在多种系统到用户行为中，预测可能卷退者为primary objective。在投机领域如虚拟运动，国际运动赛事的不可预测因素可能对常规支付习惯产生影响。因此，对卷退预测系统的特征工程可能会占用资源，特别是在服务2000万用户以上的生产环境中，where inference pipelines largely focus on feature engineering。本文通过对历史数据进行广泛的研究，旨在创建一个预测用户卷退可能性的模型，帮助企业理解卷退趋势并制定有效的保留计划。我们的方法将卷退预测视为多变量时间系列分类，示出将用户活动和深度神经网络结合可以在复杂的商业到客户场景中实现remarkable的卷退预测结果。
</details></li>
</ul>
<hr>
<h2 id="VidChapters-7M-Video-Chapters-at-Scale"><a href="#VidChapters-7M-Video-Chapters-at-Scale" class="headerlink" title="VidChapters-7M: Video Chapters at Scale"></a>VidChapters-7M: Video Chapters at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13952">http://arxiv.org/abs/2309.13952</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antoyang/VidChapters">https://github.com/antoyang/VidChapters</a></li>
<li>paper_authors: Antoine Yang, Arsha Nagrani, Ivan Laptev, Josef Sivic, Cordelia Schmid</li>
<li>for: 该论文旨在提供一个大规模的视频分章数据集，以便进行视频分章任务的研究。</li>
<li>methods: 该论文使用了自动抓取视频网站上的用户标注的分章信息，自动生成了817万个视频和7万个分章的数据集。</li>
<li>results: 该论文通过对这些数据进行分析，实现了三个任务：视频分章生成、视频分章grounding和 dense video captioning。 Results show that pretraining on VidChapters-7M transfers well to dense video captioning tasks, largely improving the state of the art on the YouCook2 and ViTT benchmarks.<details>
<summary>Abstract</summary>
Segmenting long videos into chapters enables users to quickly navigate to the information of their interest. This important topic has been understudied due to the lack of publicly released datasets. To address this issue, we present VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters in total. VidChapters-7M is automatically created from videos online in a scalable manner by scraping user-annotated chapters and hence without any additional manual annotation. We introduce the following three tasks based on this data. First, the video chapter generation task consists of temporally segmenting the video and generating a chapter title for each segment. To further dissect the problem, we also define two variants of this task: video chapter generation given ground-truth boundaries, which requires generating a chapter title given an annotated video segment, and video chapter grounding, which requires temporally localizing a chapter given its annotated title. We benchmark both simple baselines and state-of-the-art video-language models for these three tasks. We also show that pretraining on VidChapters-7M transfers well to dense video captioning tasks in both zero-shot and finetuning settings, largely improving the state of the art on the YouCook2 and ViTT benchmarks. Finally, our experiments reveal that downstream performance scales well with the size of the pretraining dataset. Our dataset, code, and models are publicly available at https://antoyang.github.io/vidchapters.html.
</details>
<details>
<summary>摘要</summary>
“将长片 видео分成章节可以让用户快速导航到他们所需的信息。这个重要主题一直未被充分研究，原因是公共释出的数据缺乏。为解决这个问题，我们提出了 VidChapters-7M  dataset，包含 817 万个用户分成的影片和 7 百万个章节。 VidChapters-7M 是通过自动抓取网络上的影片而实现的，无需任何额外的手动标注。我们提出了以下三个任务：影片章节生成任务，包括时间段分影片和生成每个段落的章节标题；以及两个这个任务的变化：影片章节生成基于预设边界，需要根据预设的影片段落标注生成章节标题，以及影片章节固定，需要根据章节标题进行时间位置local化。我们在这些三个任务上评估了基本的基础模型和现有的影词组言模型，并证明了这些模型在零shot和调整设定下具有优秀的表现。此外，我们的实验显示，下游性能与预训练数据的大小成正比。我们的 dataset、代码和模型都可以在 <https://antoyang.github.io/vidchapters.html> 获取。”
</details></li>
</ul>
<hr>
<h2 id="The-Time-Traveler’s-Guide-to-Semantic-Web-Research-Analyzing-Fictitious-Research-Themes-in-the-ESWC-“Next-20-Years”-Track"><a href="#The-Time-Traveler’s-Guide-to-Semantic-Web-Research-Analyzing-Fictitious-Research-Themes-in-the-ESWC-“Next-20-Years”-Track" class="headerlink" title="The Time Traveler’s Guide to Semantic Web Research: Analyzing Fictitious Research Themes in the ESWC “Next 20 Years” Track"></a>The Time Traveler’s Guide to Semantic Web Research: Analyzing Fictitious Research Themes in the ESWC “Next 20 Years” Track</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13939">http://arxiv.org/abs/2309.13939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irene Celino, Heiko Paulheim</li>
<li>for: The paper is written to explore the future research directions and themes of the Semantic Web community in the late 2040s and early 2050s.</li>
<li>methods: The paper uses fictitious research papers as a way to gather ideas from the community on potential future research themes and topics, and analyzes the research methods applied by the authors in these submissions.</li>
<li>results: The paper provides a survey of the “science fiction” papers submitted to the “Next 20 years” track of ESWC 2023, including the emerging research themes and topics, and investigates the most fictitious parts of the submissions.<details>
<summary>Abstract</summary>
What will Semantic Web research focus on in 20 years from now? We asked this question to the community and collected their visions in the "Next 20 years" track of ESWC 2023. We challenged the participants to submit "future" research papers, as if they were submitting to the 2043 edition of the conference. The submissions - entirely fictitious - were expected to be full scientific papers, with research questions, state of the art references, experimental results and future work, with the goal to get an idea of the research agenda for the late 2040s and early 2050s. We received ten submissions, eight of which were accepted for presentation at the conference, that mixed serious ideas of potential future research themes and discussion topics with some fun and irony.   In this paper, we intend to provide a survey of those "science fiction" papers, considering the emerging research themes and topics, analysing the research methods applied by the authors in these very special submissions, and investigating also the most fictitious parts (e.g., neologisms, fabricated references). Our goal is twofold: on the one hand, we investigate what this special track tells us about the Semantic Web community and, on the other hand, we aim at getting some insights on future research practices and directions.
</details>
<details>
<summary>摘要</summary>
在未来20年，semantic web研究将集中焦点在什么？我们问了社区，收集了他们的见解在“未来20年”track of ESWC 2023中。我们邀请 particiants to submitting“未来”研究论文，如果他们是在2043年版本的会议上提交的。提交的“未来”论文应包括研究问题、现场研究、实验结果和未来工作，以获得2040年代和2050年代的研究训练。我们收到了10篇提交，8篇被接受到会议上，其中有一些具有可能性的未来研究主题和讨论topic。在这篇文章中，我们将对这10篇“科幻”论文进行调查，探讨这些论文中的emerging research theme和topic，分析作者所应用的研究方法，以及一些虚构的部分（例如， neologisms和 fabricated references）。我们的目标是twofold：一方面，我们想要了解这个特别track的semantic web社区，另一方面，我们希望透过这些未来研究方法和方向获得一些预见。
</details></li>
</ul>
<hr>
<h2 id="SPOTS-Stable-Placement-of-Objects-with-Reasoning-in-Semi-Autonomous-Teleoperation-Systems"><a href="#SPOTS-Stable-Placement-of-Objects-with-Reasoning-in-Semi-Autonomous-Teleoperation-Systems" class="headerlink" title="SPOTS: Stable Placement of Objects with Reasoning in Semi-Autonomous Teleoperation Systems"></a>SPOTS: Stable Placement of Objects with Reasoning in Semi-Autonomous Teleoperation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13937">http://arxiv.org/abs/2309.13937</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joonhyung-lee/spots">https://github.com/joonhyung-lee/spots</a></li>
<li>paper_authors: Joonhyung Lee, Sangbeom Park, Jeongeun Park, Kyungjae Lee, Sungjoon Choi</li>
<li>for: 本研究主要针对pick-and-place任务中的“place”任务，即在人工智能框架下将物品放置在合适的位置。</li>
<li>methods: 本研究提出一种结合实验驱动的物理稳定验证和大语言模型的 semantic reasoning 能力，以生成基于Contextual reasonableness和物理稳定性的物品放置候选者概率分布。</li>
<li>results: 对于两个实验环境和一个实际世界环境进行了广泛的评估，表明OUR方法可以大幅提高物品放置的物理可行性和上下文合理性，同时考虑用户首选。<details>
<summary>Abstract</summary>
Pick-and-place is one of the fundamental tasks in robotics research. However, the attention has been mostly focused on the ``pick'' task, leaving the ``place'' task relatively unexplored. In this paper, we address the problem of placing objects in the context of a teleoperation framework. Particularly, we focus on two aspects of the place task: stability robustness and contextual reasonableness of object placements. Our proposed method combines simulation-driven physical stability verification via real-to-sim and the semantic reasoning capability of large language models. In other words, given place context information (e.g., user preferences, object to place, and current scene information), our proposed method outputs a probability distribution over the possible placement candidates, considering the robustness and reasonableness of the place task. Our proposed method is extensively evaluated in two simulation and one real world environments and we show that our method can greatly increase the physical plausibility of the placement as well as contextual soundness while considering user preferences.
</details>
<details>
<summary>摘要</summary>
Pick-and-place 是 robotics 研究中的基本任务之一，但是它们的注意力主要集中在“捕获”任务上，剩下的“放置”任务则得到了更少的关注。在这篇论文中，我们对置物任务进行了研究，特别是在电子操作框架中。我们关注了放置物品的两个方面：稳定性和上下文合理性。我们提出的方法结合了实际驱动的物理稳定性验证和大语言模型的Semantic reasoning能力。具体来说，我们根据放置上下文信息（例如用户偏好、要放置的物品和当前场景信息）输出一个可能的放置候选者概率分布，考虑放置任务的稳定性和上下文合理性。我们的方法在三个 simulations 和一个真实世界环境中进行了广泛的评估，并显示了我们的方法可以大幅提高物理可能性以及上下文合理性。
</details></li>
</ul>
<hr>
<h2 id="Fairness-and-Bias-in-Algorithmic-Hiring"><a href="#Fairness-and-Bias-in-Algorithmic-Hiring" class="headerlink" title="Fairness and Bias in Algorithmic Hiring"></a>Fairness and Bias in Algorithmic Hiring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13933">http://arxiv.org/abs/2309.13933</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Alessandro Fabris, Nina Baranowska, Matthew J. Dennis, Philipp Hacker, Jorge Saldivar, Frederik Zuiderveen Borgesius, Asia J. Biega</li>
<li>for: 这篇论文是为了探讨算法招聘技术在招聘过程中的应用和公平性问题。</li>
<li>methods: 本论文使用了多学科的方法，包括系统评估、偏见检测、数据分析等，以探讨算法招聘技术的优劣和应用场景。</li>
<li>results: 本论文结果表明，算法招聘技术可以减少招聘过程中的偏见和不公平，但是现有的数据和方法有限制，需要进一步的研究和开发以确保这些技术的公平性和可靠性。<details>
<summary>Abstract</summary>
Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of, algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.
</details>
<details>
<summary>摘要</summary>
雇主正在整个招聘过程中广泛采用算法招聘技术。算法公平特别适用于这个领域，因为它具有高的重要性和结构性不平等。然而，大多数工作在这个领域都提供了半路处理，经常受到两种竞争的观点所限制：一是乐观地关注代表人员偏见的替换，另一是悲观地指出自动化歧视。无论算法招聘能否更不偏袋更有利于社会，以及哪种类型的算法招聘可以更加不偏袋，目前仍未得到答案。这个多学科调查旨在为实践者和研究人员提供一个平衡和一致的涵盖系统、偏见、测量、缓减策略、数据集和法律方面的算法招聘公平问题的全面覆盖。我们的工作旨在支持Contextualized理解和管理这种技术，通过强调当前的机会和限制，提供未来工作的建议，以确保所有参与者共享利益。
</details></li>
</ul>
<hr>
<h2 id="UCF-Crime-Annotation-A-Benchmark-for-Surveillance-Video-and-Language-Understanding"><a href="#UCF-Crime-Annotation-A-Benchmark-for-Surveillance-Video-and-Language-Understanding" class="headerlink" title="UCF-Crime Annotation: A Benchmark for Surveillance Video-and-Language Understanding"></a>UCF-Crime Annotation: A Benchmark for Surveillance Video-and-Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13925">http://arxiv.org/abs/2309.13925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuange923/uca-dataset">https://github.com/xuange923/uca-dataset</a></li>
<li>paper_authors: Tongtong Yuan, Xuange Zhang, Kun Liu, Bo Liu, Jian Jin, Zhenzhen Jiao</li>
<li>for: 本研究旨在提供一个新的多模态Surveillance视频数据集，以便进行多模态Surveillance视频分析。</li>
<li>methods: 我们使用了手动标注的实际世界Surveillance视频数据集UCF-Crime，并将其注解为细腻事件内容和时间。我们的新创建的数据集UCA（UCF-Crime Annotation）提供了一个新的benchmark для多模态Surveillance视频分析。</li>
<li>results: 我们在这个新创建的数据集上测试了当前主流的多模态任务模型，发现这些模型在多模态Surveillance视频场景下表现不佳，这 highlights the necessity of constructing this dataset。<details>
<summary>Abstract</summary>
Surveillance videos are an essential component of daily life with various critical applications, particularly in public security. However, current surveillance video tasks mainly focus on classifying and localizing anomalous events. Existing methods are limited to detecting and classifying the predefined events with unsatisfactory generalization ability and semantic understanding, although they have obtained considerable performance. To address this issue, we propose constructing the first multimodal surveillance video dataset by manually annotating the real-world surveillance dataset UCF-Crime with fine-grained event content and timing. Our newly annotated dataset, UCA (UCF-Crime Annotation), provides a novel benchmark for multimodal surveillance video analysis. It not only describes events in detailed descriptions but also provides precise temporal grounding of the events in 0.1-second intervals. UCA contains 20,822 sentences, with an average length of 23 words, and its annotated videos are as long as 102 hours. Furthermore, we benchmark the state-of-the-art models of multiple multimodal tasks on this newly created dataset, including temporal sentence grounding in videos, video captioning, and dense video captioning. Through our experiments, we found that mainstream models used in previously publicly available datasets perform poorly on multimodal surveillance video scenarios, which highlights the necessity of constructing this dataset. The link to our dataset and code is provided at: https://github.com/Xuange923/UCA-dataset.
</details>
<details>
<summary>摘要</summary>
侦查视频是我们日常生活中的一个重要组成部分，尤其在公共安全领域。然而，现有的侦查视频任务主要集中在异常事件的分类和地点化。现有的方法具有不满足的泛化能力和 semantics理解，尽管它们在性能方面已经取得了一定的进步。为解决这个问题，我们提议创建了首个多模态侦查视频数据集，通过手动标注实际世界的侦查视频数据集UCF-Crime，并将其注解为细化事件内容和时间。我们新创建的数据集，UCAC（UCF-Crime Annotation），不仅描述事件的内容，还提供精确的时间地标，每个事件在0.1秒间隔内进行标注。UCAC包含20822句话，平均长度为23个单词，其注解视频的长度为102小时。此外，我们在这个新创建的数据集上测试了当今主流的多模态任务模型，包括视频句子注释、视频句子注释和稠密视频句子注释。我们的实验结果显示，主流在多模态侦查视频场景下表现糟糕，这 highlights 了我们构建这个数据集的必要性。数据集和代码的链接可以在 GitHub 上找到：https://github.com/Xuange923/UCA-dataset。
</details></li>
</ul>
<hr>
<h2 id="A-comparison-of-controller-architectures-and-learning-mechanisms-for-arbitrary-robot-morphologies"><a href="#A-comparison-of-controller-architectures-and-learning-mechanisms-for-arbitrary-robot-morphologies" class="headerlink" title="A comparison of controller architectures and learning mechanisms for arbitrary robot morphologies"></a>A comparison of controller architectures and learning mechanisms for arbitrary robot morphologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13908">http://arxiv.org/abs/2309.13908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Luo, Jakub Tomczak, Karine Miras, Agoston E. Eiben</li>
<li>for: 这个论文的主要问题是：如果机器人的形态不知道先天，那么哪种控制器和学习方法应该使用？作者们的兴趣是基于模块化演化的机器人，但问题也适用于广泛的系统设计者，寻找可重用的解决方案。</li>
<li>methods: 作者们使用了三种控制器和学习方法的组合：一种基于动物 lokomootion 模型（中央 Pattern Generators，CPG）和一个进化算法学习者，另一种使用强化学习（RL）和一个神经网络控制器架构，以及一种 combining 的方法，其中控制器是神经网络，学习者是进化算法。</li>
<li>results: 作者们对一组模块化机器人进行了测试，并对三种组合的有效性、效率和稳定性进行了比较。结果显示，通常的 CPG 和 RL 方法被外围的 combining 组合所超越，这个组合更加稳定和高效。<details>
<summary>Abstract</summary>
The main question this paper addresses is: What combination of a robot controller and a learning method should be used, if the morphology of the learning robot is not known in advance? Our interest is rooted in the context of morphologically evolving modular robots, but the question is also relevant in general, for system designers interested in widely applicable solutions. We perform an experimental comparison of three controller-and-learner combinations: one approach where controllers are based on modelling animal locomotion (Central Pattern Generators, CPG) and the learner is an evolutionary algorithm, a completely different method using Reinforcement Learning (RL) with a neural network controller architecture, and a combination `in-between' where controllers are neural networks and the learner is an evolutionary algorithm. We apply these three combinations to a test suite of modular robots and compare their efficacy, efficiency, and robustness. Surprisingly, the usual CPG-based and RL-based options are outperformed by the in-between combination that is more robust and efficient than the other two setups.
</details>
<details>
<summary>摘要</summary>
本文探讨的主要问题是：在不知道机器人形态的情况下，应用哪种控制器和学习方法？我们的兴趣基于模块化 robots 的形态演化，但这个问题也适用于更广泛的系统设计师，寻找通用的解决方案。我们通过实验比较三种控制器和学习方法的组合：一种使用动物步态模型（中央 Pattern Generators，CPG）和进化算法学习者，一种完全不同的方法使用奖励学习（RL）和神经网络控制器架构，以及一种混合“中间”的方法，其中控制器是神经网络，学习者是进化算法。我们将这三种组合应用到一组模块 robots 上，并比较其效果、效率和稳定性。结果各种意外地发现，通常的 CPG-based 和 RL-based 选项被“中间”组合所超越，这种组合更加稳定和高效。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-the-Efficacy-of-an-LLM-Only-Approach-for-Image-based-Document-Question-Answering"><a href="#Analyzing-the-Efficacy-of-an-LLM-Only-Approach-for-Image-based-Document-Question-Answering" class="headerlink" title="Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering"></a>Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14389">http://arxiv.org/abs/2309.14389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nidhi Hegde, Sujoy Paul, Gagan Madan, Gaurav Aggarwal</li>
<li>for: 这个论文的目的是研究文档问答模型中的两个关键组件：视觉编码器和大型自然语言模型（LLM），以及这两个组件之间的相对贡献。</li>
<li>methods: 这篇论文使用了一种叫做“LLM-只”的方法，即直接将文档图像中的文本信息序列化并传递给一个受训练的 LLM，以便不需要显式的视觉编码器。</li>
<li>results: 论文的结果表明，使用这种“LLM-只”方法可以在多种 datasets 上达到与或接近领先性水平的表现。<details>
<summary>Abstract</summary>
Recent document question answering models consist of two key components: the vision encoder, which captures layout and visual elements in images, and a Large Language Model (LLM) that helps contextualize questions to the image and supplements them with external world knowledge to generate accurate answers. However, the relative contributions of the vision encoder and the language model in these tasks remain unclear. This is especially interesting given the effectiveness of instruction-tuned LLMs, which exhibit remarkable adaptability to new tasks. To this end, we explore the following aspects in this work: (1) The efficacy of an LLM-only approach on document question answering tasks (2) strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder (3) thorough quantitative analysis on the feasibility of such an approach. Our comprehensive analysis encompasses six diverse benchmark datasets, utilizing LLMs of varying scales. Our findings reveal that a strategy exclusively reliant on the LLM yields results that are on par with or closely approach state-of-the-art performance across a range of datasets. We posit that this evaluation framework will serve as a guiding resource for selecting appropriate datasets for future research endeavors that emphasize the fundamental importance of layout and image content information.
</details>
<details>
<summary>摘要</summary>
现代文档问答模型通常包括两个关键组件：视觉编码器，用于捕捉图像中的布局和视觉元素，以及一个大语言模型（LLM），用于将问题与图像相关联并补充问题以外的知识来生成准确的答案。然而，视觉编码器和语言模型在这些任务中的相对贡献还不清楚。这 especially interesting， given the effectiveness of instruction-tuned LLMs，which exhibit remarkable adaptability to new tasks。为此，我们在这项工作中进行了以下三个方面的研究：1. 使用LLM-only方法解决文档问答任务的效果（2）， Serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder。我们的全面分析涵盖了六个多样化的 benchmarck 数据集，使用不同规模的LLM。我们的发现表明，一种仅依靠LLM的方法可以在多个数据集上达到或接近状态艺术性的表现。我们认为这种评价框架将成为未来研究着重于图像布局和内容信息的关键资源。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Robot-Morphology-Spaces-through-Breadth-First-Search-and-Random-Query"><a href="#Exploring-Robot-Morphology-Spaces-through-Breadth-First-Search-and-Random-Query" class="headerlink" title="Exploring Robot Morphology Spaces through Breadth-First Search and Random Query"></a>Exploring Robot Morphology Spaces through Breadth-First Search and Random Query</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14387">http://arxiv.org/abs/2309.14387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Luo</li>
<li>for: 这项研究旨在 Investigating the role of query mechanisms in the brain-body co-evolution of modular robots, and comparing the effectiveness of two different query mechanisms (BFS and Random Query) in evolving robot morphologies.</li>
<li>methods: 该研究使用了 CPPNs and robot controllers using tensors,以及两种不同的查询机制（BFS和随机查询），在两种演化框架（LAMARCK和达尔沃尼系统）中进行了对比性分析。</li>
<li>results: 研究发现，BFS 比 Random Query 更有效率地生成高性能的机器人体，并且在达尔沃尼系统中，BFS 导致机器人体的演化和性能具有更高的多样性和特征。<details>
<summary>Abstract</summary>
Evolutionary robotics offers a powerful framework for designing and evolving robot morphologies, particularly in the context of modular robots. However, the role of query mechanisms during the genotype-to-phenotype mapping process has been largely overlooked. This research addresses this gap by conducting a comparative analysis of query mechanisms in the brain-body co-evolution of modular robots. Using two different query mechanisms, Breadth-First Search (BFS) and Random Query, within the context of evolving robot morphologies using CPPNs and robot controllers using tensors, and testing them in two evolutionary frameworks, Lamarckian and Darwinian systems, this study investigates their influence on evolutionary outcomes and performance. The findings demonstrate the impact of the two query mechanisms on the evolution and performance of modular robot bodies, including morphological intelligence, diversity, and morphological traits. This study suggests that BFS is both more effective and efficient in producing highly performing robots. It also reveals that initially, robot diversity was higher with BFS compared to Random Query, but in the Lamarckian system, it declines faster, converging to superior designs, while in the Darwinian system, BFS led to higher end-process diversity.
</details>
<details>
<summary>摘要</summary>
生态进化机器人学提供了一个强大的框架 для设计和演化机器人体形，特别在模块化机器人中。然而，在基因型-到形态映射过程中 Query 机制的角色被大量遗弃。这种研究填补了这个遗弃，通过对 CPPN 和机器人控制器使用矩阵进行演化 robots 的脑体进行比较分析。使用 BFS 和随机 Query 两种不同的 Query 机制，在拉马克思主义和达尔文主义两种演化框架下测试它们，这种研究研究它们对演化结果和性能的影响。发现 BFS 比Random Query 更有效和高效地生成高性能机器人体形，并且发现在拉马克思主义系统中，BFS 初始时 robot 多样性比 Random Query 高，但随着演化，它快速下降，转化为优秀设计，而达尔文主义系统中，BFS 导致最终的多样性高于 Random Query。
</details></li>
</ul>
<hr>
<h2 id="Scene-Informer-Anchor-based-Occlusion-Inference-and-Trajectory-Prediction-in-Partially-Observable-Environments"><a href="#Scene-Informer-Anchor-based-Occlusion-Inference-and-Trajectory-Prediction-in-Partially-Observable-Environments" class="headerlink" title="Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments"></a>Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13893">http://arxiv.org/abs/2309.13893</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sisl/sceneinformer">https://github.com/sisl/sceneinformer</a></li>
<li>paper_authors: Bernard Lange, Jiachen Li, Mykel J. Kochenderfer</li>
<li>for: 本研究旨在提高自动驾驶汽车在部分可见环境中的导航能力，包括预测 observable agents 的未来运动和推断 occluded agents。</li>
<li>methods: 我们引入了 Scene Informer，一种统一的方法，可以同时预测 observable agents 的运动和推断 occluded agents。Scene Informer 使用 transformer 来聚合不同输入模式，并提供选择性查询 occlusions 可能与 AV 计划路径相交。</li>
<li>results: 我们的方法在 Waymo Open Motion Dataset 上的部分可见设置下表现出色，超过了现有方法在 occupancy 预测和 trajectory 预测方面。<details>
<summary>Abstract</summary>
Navigating complex and dynamic environments requires autonomous vehicles (AVs) to reason about both visible and occluded regions. This involves predicting the future motion of observed agents, inferring occluded ones, and modeling their interactions based on vectorized scene representations of the partially observable environment. However, prior work on occlusion inference and trajectory prediction have developed in isolation, with the former based on simplified rasterized methods and the latter assuming full environment observability. We introduce the Scene Informer, a unified approach for predicting both observed agent trajectories and inferring occlusions in a partially observable setting. It uses a transformer to aggregate various input modalities and facilitate selective queries on occlusions that might intersect with the AV's planned path. The framework estimates occupancy probabilities and likely trajectories for occlusions, as well as forecast motion for observed agents. We explore common observability assumptions in both domains and their performance impact. Our approach outperforms existing methods in both occupancy prediction and trajectory prediction in partially observable setting on the Waymo Open Motion Dataset.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:自适应环境需要自动驾驶车 (AV) 能够理解可见和遮盖的区域。这些区域包括预测可见的代理人的未来运动、推理遮盖的人和基于可见环境的场景表示的Vectorization。然而，先前的遮盖推断和轨迹预测工作都是分离的，前者基于简化的扫描方法，后者假设环境完全可见。我们介绍了Scene Informer，一种统一的方法，可以预测可见代理人的轨迹和预测遮盖物的存在。它使用 transformer 来聚合不同的输入模式，并且可以根据预测轨迹的可能性进行选择性的查询遮盖物。框架可以估算遮盖物的存在概率和可能的轨迹，以及可见代理人的预测运动。我们探讨了两个域的共同可见假设和其影响性。我们的方法在 partially observable 环境中的 Waymo Open Motion Dataset 上比过去的方法表现出色。
</details></li>
</ul>
<hr>
<h2 id="TouchUp-G-Improving-Feature-Representation-through-Graph-Centric-Finetuning"><a href="#TouchUp-G-Improving-Feature-Representation-through-Graph-Centric-Finetuning" class="headerlink" title="TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning"></a>TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13885">http://arxiv.org/abs/2309.13885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Zhu, Xiang Song, Vassilis N. Ioannidis, Danai Koutra, Christos Faloutsos</li>
<li>for: 提高下游图学任务中节点特征的质量，以提高图 neural network（GNN）的表现。</li>
<li>methods: 使用TOUCHUP-G方法，该方法是一种通用的、多Modal的、原则正的方法，可以提高任何下游图任务中节点特征的质量。</li>
<li>results: TOUCHUP-G方法可以在四个真实世界数据集上达到状态的最佳结果，这些数据集包括不同的任务和modal。<details>
<summary>Abstract</summary>
How can we enhance the node features acquired from Pretrained Models (PMs) to better suit downstream graph learning tasks? Graph Neural Networks (GNNs) have become the state-of-the-art approach for many high-impact, real-world graph applications. For feature-rich graphs, a prevalent practice involves utilizing a PM directly to generate features, without incorporating any domain adaptation techniques. Nevertheless, this practice is suboptimal because the node features extracted from PM are graph-agnostic and prevent GNNs from fully utilizing the potential correlations between the graph structure and node features, leading to a decline in GNNs performance. In this work, we seek to improve the node features obtained from a PM for downstream graph tasks and introduce TOUCHUP-G, which has several advantages. It is (a) General: applicable to any downstream graph task, including link prediction which is often employed in recommender systems; (b) Multi-modal: able to improve raw features of any modality (e.g. images, texts, audio); (c) Principled: it is closely related to a novel metric, feature homophily, which we propose to quantify the potential correlations between the graph structure and node features and we show that TOUCHUP-G can effectively shrink the discrepancy between the graph structure and node features; (d) Effective: achieving state-of-the-art results on four real-world datasets spanning different tasks and modalities.
</details>
<details>
<summary>摘要</summary>
如何增强从预训练模型（PM）获取的节点特征以更适合下游图学任务？图神经网络（GNNs）已成为许多高impact、实际世界图应用的州立艺术。对于具有丰富特征的图，一种常见做法是直接使用PM生成特征，不 incorporating任何领域适应技术。然而，这种做法是不优化的，因为PM中的节点特征是图无关的，不能让GNNs完全利用图结构和节点特征之间的潜在相关性，导致GNNs的性能下降。在这项工作中，我们想要改进从PM获取的节点特征，并引入了TOUCHUP-G，它具有以下优势：* 通用：适用于任何下游图任务，包括常用的链接预测任务（常用于推荐系统）。* 多模式：能够提高任何类型的原始特征（例如图像、文本、音频）。* 原则性：与我们提出的一种新的度量（特征同化度）有紧密关系，我们表明了TOUCHUP-G可以有效缩小图结构和节点特征之间的差异。* 有效：在四个实际数据集上达到了状态之最的结果，这些数据集来自不同的任务和模式。
</details></li>
</ul>
<hr>
<h2 id="PRiSM-Enhancing-Low-Resource-Document-Level-Relation-Extraction-with-Relation-Aware-Score-Calibration"><a href="#PRiSM-Enhancing-Low-Resource-Document-Level-Relation-Extraction-with-Relation-Aware-Score-Calibration" class="headerlink" title="PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration"></a>PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13869">http://arxiv.org/abs/2309.13869</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brightjade/prism">https://github.com/brightjade/prism</a></li>
<li>paper_authors: Minseok Choi, Hyesu Lim, Jaegul Choo</li>
<li>for:  DocRE是为了提取文档中所有实体对的关系而设计的。</li>
<li>methods: 我们使用了一种叫做PRiSM的方法，它可以根据关系Semantic信息来适应logits。</li>
<li>results: 我们在三个DocRE数据集上进行评估，结果表明，将现有模型与PRiSM结合可以提高表达度，而且在训练时使用的数据量只需要3%。同时，我们发现在训练过程中，PRiSM可以降低偏差错误的数量，达到36倍的提升。<details>
<summary>Abstract</summary>
Document-level relation extraction (DocRE) aims to extract relations of all entity pairs in a document. A key challenge in DocRE is the cost of annotating such data which requires intensive human effort. Thus, we investigate the case of DocRE in a low-resource setting, and we find that existing models trained on low data overestimate the NA ("no relation") label, causing limited performance. In this work, we approach the problem from a calibration perspective and propose PRiSM, which learns to adapt logits based on relation semantic information. We evaluate our method on three DocRE datasets and demonstrate that integrating existing models with PRiSM improves performance by as much as 26.38 F1 score, while the calibration error drops as much as 36 times when trained with about 3% of data. The code is publicly available at https://github.com/brightjade/PRiSM.
</details>
<details>
<summary>摘要</summary>
文档级关系提取（DocRE）目标是在文档中提取所有实体对的关系。一个主要挑战在DocRE中是获取数据 annotating 的成本，需要卷积的人工劳动。因此，我们在低资源设定下调查DocRE问题，发现现有模型在低数据上训练后过度估计NA("无关")标签，导致性能有限。在这种情况下，我们从抽象角度出发，提出了PRiSM，它学习基于关系semantic信息来调整logits。我们对三个DocRE数据集进行评估，并证明了将现有模型与PRiSM结合使用可以提高性能，最高提高26.38准确率，同时抽象错误下降了36倍，只需训练约3%的数据。代码可以在https://github.com/brightjade/PRiSM上获取。
</details></li>
</ul>
<hr>
<h2 id="Fast-HuBERT-An-Efficient-Training-Framework-for-Self-Supervised-Speech-Representation-Learning"><a href="#Fast-HuBERT-An-Efficient-Training-Framework-for-Self-Supervised-Speech-Representation-Learning" class="headerlink" title="Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech Representation Learning"></a>Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13860">http://arxiv.org/abs/2309.13860</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanghaha0908/fasthubert">https://github.com/yanghaha0908/fasthubert</a></li>
<li>paper_authors: Guanrou Yang, Ziyang Ma, Zhisheng Zheng, Yakun Song, Zhikang Niu, Xie Chen</li>
<li>for: 这篇论文主要是为了提高自动标注学习（SSL）方法在语音处理任务中的效率，并且测试这些方法在不同的下游任务中的表现。</li>
<li>methods: 本论文使用了HuBERT模型，并进行了多个效率优化，包括范例删除、批评迭代、条件更新、等。</li>
<li>results: 相比原始实现， Fast-HuBERT可以在1.1天内训练完成，并且无损性能，实现了5.2倍的速度提升。此外， authors 还 explore了两种已知技术，并证明了这些技术可以获得类似的改进。<details>
<summary>Abstract</summary>
Recent years have witnessed significant advancements in self-supervised learning (SSL) methods for speech-processing tasks. Various speech-based SSL models have been developed and present promising performance on a range of downstream tasks including speech recognition. However, existing speech-based SSL models face a common dilemma in terms of computational cost, which might hinder their potential application and in-depth academic research. To address this issue, we first analyze the computational cost of different modules during HuBERT pre-training and then introduce a stack of efficiency optimizations, which is named Fast-HuBERT in this paper. The proposed Fast-HuBERT can be trained in 1.1 days with 8 V100 GPUs on the Librispeech 960h benchmark, without performance degradation, resulting in a 5.2x speedup, compared to the original implementation. Moreover, we explore two well-studied techniques in the Fast-HuBERT and demonstrate consistent improvements as reported in previous work.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)近年来，自动学习（Self-Supervised Learning，SSL）方法在语音处理任务中得到了 significative 进步。许多基于语音的 SSL 模型已经被开发出来，并在各种下游任务中表现出色，包括语音识别。然而，现有的语音基于 SSL 模型面临着计算成本的问题，这可能会限制它们的应用和学术研究的深度。为解决这个问题，我们首先分析了不同模块的计算成本在 HuBERT 预训练过程中，然后引入了一堆性能优化技术，称之为 Fast-HuBERT。我们的 Fast-HuBERT 可以在 1.1 天内使用 8 个 V100 GPU 在 Librispeech 960h 测试集上进行预训练，无需性能下降，相比原始实现，实现了 5.2 倍的速度提升。此外，我们还探索了两种已经广泛研究的技术，并在 Fast-HuBERT 中进行了详细的实验，并发现了一致的改进。
</details></li>
</ul>
<hr>
<h2 id="Can-neural-networks-count-digit-frequency"><a href="#Can-neural-networks-count-digit-frequency" class="headerlink" title="Can neural networks count digit frequency?"></a>Can neural networks count digit frequency?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.04431">http://arxiv.org/abs/2310.04431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PadmakshKhandelwal/Can-neural-networks-count">https://github.com/PadmakshKhandelwal/Can-neural-networks-count</a></li>
<li>paper_authors: Padmaksh Khandelwal</li>
<li>for: 本研究旨在比较不同的古典机器学习模型和神经网络在识别每个数字的频率出现的问题上的性能。这有各种应用场景，如获取视频场景中目标对象的频率。</li>
<li>methods: 我们在这个问题上采用了一种混合的分类和回归任务，并且特意制作了自己的数据集来观察系统性的差异。我们使用不同的度量来评估每种方法的性能，并且在多个数据集上进行了评估。</li>
<li>results: 我们发现，决策树和Random Forest具有内在的偏见，导致它们无法泛化好。同时，神经网络在分类和回归两个任务上都明显超过了古典机器学习模型，尤其是在6位和10位数据集上。数据集和代码在github上公开。<details>
<summary>Abstract</summary>
In this research, we aim to compare the performance of different classical machine learning models and neural networks in identifying the frequency of occurrence of each digit in a given number. It has various applications in machine learning and computer vision, e.g. for obtaining the frequency of a target object in a visual scene. We considered this problem as a hybrid of classification and regression tasks. We carefully create our own datasets to observe systematic differences between different methods. We evaluate each of the methods using different metrics across multiple datasets.The metrics of performance used were the root mean squared error and mean absolute error for regression evaluation, and accuracy for classification performance evaluation. We observe that decision trees and random forests overfit to the dataset, due to their inherent bias, and are not able to generalize well. We also observe that the neural networks significantly outperform the classical machine learning models in terms of both the regression and classification metrics for both the 6-digit and 10-digit number datasets. Dataset and code are available on github.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们目标是比较不同的古典机器学习模型和神经网络在识别每个数字的频率出现的性能。它在机器学习和计算机视觉等领域有各种应用，例如获取视觉场景中目标对象的频率。我们将这个问题视为分类和回归任务的混合问题。我们仔细制作了自己的数据集，以观察不同方法之间的系统差异。我们对每种方法使用不同的指标进行评估，并在多个数据集上进行评估。我们发现决策树和随机森林因数据集的偏袋而过拟合，无法通过泛化而表现出色。我们还发现神经网络在分类和回归指标方面对6位和10位数据集都有显著的优势。数据集和代码可以在github上下载。
</details></li>
</ul>
<hr>
<h2 id="Sampling-Variational-Auto-Encoder-Ensemble-In-the-Quest-of-Explainable-Artificial-Intelligence"><a href="#Sampling-Variational-Auto-Encoder-Ensemble-In-the-Quest-of-Explainable-Artificial-Intelligence" class="headerlink" title="Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence"></a>Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14385">http://arxiv.org/abs/2309.14385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarit Maitra, Vivek Mishra, Pratima Verma, Manav Chopra, Priyanka Nath</li>
<li>for: 这篇论文的目的是提出一种新的可解释人工智能（XAI）框架，用于解释人工智能模型的输出。</li>
<li>methods: 这篇论文使用了一种新的混合架构，称为Sampling-Variational Auto Encoder-Ensemble Anomaly Detection（SVEAD），它将Variational Auto Encoder（VAE）与集成折衔和SHapley Additive exPlanations（SHAP）相结合，用于解决不平衡分类问题。</li>
<li>results: 研究发现，将VAE、集成折衔和SHAP结合使用可以不仅提高模型性能，还可以提供一个简单易于解释的框架。此外，研究还使用SHAP与排序重要性和个体条件预期结合，创造了一个强大的模型解释方法。这些发现对实际应用中的XAI具有重要的意义，可以增强人工智能应用的信任度。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence (XAI) models have recently attracted a great deal of interest from a variety of application sectors. Despite significant developments in this area, there are still no standardized methods or approaches for understanding AI model outputs. A systematic and cohesive framework is also increasingly necessary to incorporate new techniques like discriminative and generative models to close the gap. This paper contributes to the discourse on XAI by presenting an empirical evaluation based on a novel framework: Sampling - Variational Auto Encoder (VAE) - Ensemble Anomaly Detection (SVEAD). It is a hybrid architecture where VAE combined with ensemble stacking and SHapley Additive exPlanations are used for imbalanced classification. The finding reveals that combining ensemble stacking, VAE, and SHAP can. not only lead to better model performance but also provide an easily explainable framework. This work has used SHAP combined with Permutation Importance and Individual Conditional Expectations to create a powerful interpretability of the model. The finding has an important implication in the real world, where the need for XAI is paramount to boost confidence in AI applications.
</details>
<details>
<summary>摘要</summary>
《可解释人工智能（XAI）模型在不同应用领域引起了很大的关注。虽然这一领域已经取得了很大的进步，但是还没有标准化的方法或方法来理解人工智能模型的输出。一个系统和一致的框架也在增加，以整合新技术如探测和生成模型，以填补这一空白。这篇论文对XAI进行了评估，通过提出了一个新的框架：采样-自适应变换器-ensemble异常检测（SVEAD）。这是一种混合体系，其中变换器与ensemble栈和SHapley Additive exPlanations（SHAP）结合使用，用于处理不均衡的分类。研究发现，将ensemble栈、变换器和SHAP结合使用，不仅可以提高模型性能，还可以提供一个简单易理解的框架。本研究使用SHAP与排序重要性和个体条件预期结合，创造了一个强大的模型解释能力。这种发现对现实中的XAI需求具有重要意义，以增加人工智能应用的信任度。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is done using a machine translation tool, and may not be perfect. Please note that the translation may not capture all the nuances and idiomatic expressions of the original text.
</details></li>
</ul>
<hr>
<h2 id="Prior-Bilinear-Based-Models-for-Knowledge-Graph-Completion"><a href="#Prior-Bilinear-Based-Models-for-Knowledge-Graph-Completion" class="headerlink" title="Prior Bilinear Based Models for Knowledge Graph Completion"></a>Prior Bilinear Based Models for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13834">http://arxiv.org/abs/2309.13834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayi Li, Ruilin Luo, Jiaqi Sun, Jing Xiao, Yujiu Yang</li>
<li>for: 本文主要针对知识图（KG）完成任务，探讨bilinear模型忽略了先前属性的问题。</li>
<li>methods: 作者提出了一种解决方案called Unit Ball Bilinear Model (UniBi)，该模型不仅有理论上的优势，还提供了更好的解释性和性能，通过最小化无用学习的约束来减少不必要的学习。</li>
<li>results: 实验表明，UniBi模型能够capture先前属性，并且verify其解释性和性能。<details>
<summary>Abstract</summary>
Bilinear based models are powerful and widely used approaches for Knowledge Graphs Completion (KGC). Although bilinear based models have achieved significant advances, these studies mainly concentrate on posterior properties (based on evidence, e.g. symmetry pattern) while neglecting the prior properties. In this paper, we find a prior property named "the law of identity" that cannot be captured by bilinear based models, which hinders them from comprehensively modeling the characteristics of KGs. To address this issue, we introduce a solution called Unit Ball Bilinear Model (UniBi). This model not only achieves theoretical superiority but also offers enhanced interpretability and performance by minimizing ineffective learning through minimal constraints. Experiments demonstrate that UniBi models the prior property and verify its interpretability and performance.
</details>
<details>
<summary>摘要</summary>
bilinear基于模型在知识图完成（KGC）领域是非常强大和广泛使用的方法。虽然bilinear基于模型已经取得了显著的进步，但这些研究主要集中于后果性质（基于证据，例如对称模式）而忽略了先前性质。在这篇论文中，我们发现了一种先前性质名为“同一性法律”，这种法律不能被bilinear基于模型捕捉，这会限制它们完全模型知识图的特点。为解决这个问题，我们介绍了一种解决方案called Unit Ball Bilinear Model（UniBi）。这个模型不仅具有理论上的优越性，也提供了更好的解释性和性能，通过最小化不必要的学习来减少不必要的约束。实验表明，UniBi模型了先前性质并证明了其解释性和性能。
</details></li>
</ul>
<hr>
<h2 id="Dual-Feature-Augmentation-Network-for-Generalized-Zero-shot-Learning"><a href="#Dual-Feature-Augmentation-Network-for-Generalized-Zero-shot-Learning" class="headerlink" title="Dual Feature Augmentation Network for Generalized Zero-shot Learning"></a>Dual Feature Augmentation Network for Generalized Zero-shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13833">http://arxiv.org/abs/2309.13833</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sion1/dfan">https://github.com/sion1/dfan</a></li>
<li>paper_authors: Lei Xiang, Yuan Zhou, Haoran Duan, Yang Long</li>
<li>for: 这篇论文主要针对零例学习（Zero-shot learning）问题，旨在无需训练样本就能够推断未经训练的类别。</li>
<li>methods: 该论文提出了一种新的DUAL Feature Augmentation Network（DFAN），包括两个特征增强模块，一个用于视觉特征，另一个用于语义特征。视觉特征增强模块通过学习特征特性，使用高 cosine 距离来强化特征表示。语义特征增强模块则通过提出了一个偏置学习器，捕捉数据集的偏移，使得预测值与实际值之间的差距更小。此外，我们还引入了两个预测器，以冲突地解决本地和全局特征之间的冲突。</li>
<li>results: 实验结果表明，我们的方法在三个 benchmark 上表现出了明显的进步，与现有方法相比，具有更高的准确率和更好的一致性。<details>
<summary>Abstract</summary>
Zero-shot learning (ZSL) aims to infer novel classes without training samples by transferring knowledge from seen classes. Existing embedding-based approaches for ZSL typically employ attention mechanisms to locate attributes on an image. However, these methods often ignore the complex entanglement among different attributes' visual features in the embedding space. Additionally, these methods employ a direct attribute prediction scheme for classification, which does not account for the diversity of attributes in images of the same category. To address these issues, we propose a novel Dual Feature Augmentation Network (DFAN), which comprises two feature augmentation modules, one for visual features and the other for semantic features. The visual feature augmentation module explicitly learns attribute features and employs cosine distance to separate them, thus enhancing attribute representation. In the semantic feature augmentation module, we propose a bias learner to capture the offset that bridges the gap between actual and predicted attribute values from a dataset's perspective. Furthermore, we introduce two predictors to reconcile the conflicts between local and global features. Experimental results on three benchmarks demonstrate the marked advancement of our method compared to state-of-the-art approaches. Our code is available at https://github.com/Sion1/DFAN.
</details>
<details>
<summary>摘要</summary>
为了解决这些问题，我们提出了一个新的对应网络（DFAN），其包括两个对应模组：一个用于可视特征，另一个用于 semantic 特征。可视特征增强模组会明确地学习属性特征，并使用做 Cosine 距离来分离它们，这样提高了属性表示。另一方面，semantic 增强模组中，我们提出了一个偏置学习器，以捕捉实际数据集的偏移，将预测的属性值与实际值匹配。此外，我们引入了两个预测器，以调解本地和全局特征之间的冲突。实验结果显示，我们的方法与现有的方法相比，在三个 benchmark 上有明显的进步。我们的代码可以在 GitHub 上获取：https://github.com/Sion1/DFAN。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Cognitive-Maps-and-Planning-in-Large-Language-Models-with-CogEval"><a href="#Evaluating-Cognitive-Maps-and-Planning-in-Large-Language-Models-with-CogEval" class="headerlink" title="Evaluating Cognitive Maps and Planning in Large Language Models with CogEval"></a>Evaluating Cognitive Maps and Planning in Large Language Models with CogEval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15129">http://arxiv.org/abs/2309.15129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ida Momennejad, Hosein Hasanbeig, Felipe Vieira, Hiteshi Sharma, Robert Osazuwa Ness, Nebojsa Jojic, Hamid Palangi, Jonathan Larson</li>
<li>for: 这研究的目的是系统evaluate大语言模型（LLM）的认知能力。</li>
<li>methods: 该研究使用了一种基于认知科学的评估协议，称为CogEval，来评估 LLM 的认知能力。</li>
<li>results: 研究发现， LL M 在一些简单的规划任务上表现出 Competence，但在更复杂的规划任务上存在 Failure modes，包括hallucination 和循环。这些发现不支持 LL M 具有出色的规划能力。<details>
<summary>Abstract</summary>
Recently an influx of studies claim emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in Large Language Models. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show apparent competence in a few planning tasks with simpler structures, systematic evaluation reveals striking failure modes in planning tasks, including hallucinations of invalid trajectories and getting trapped in loops. These findings do not support the idea of emergent out-of-the-box planning ability in LLMs. This could be because LLMs do not understand the latent relational structures underlying planning problems, known as cognitive maps, and fail at unrolling goal-directed trajectories based on the underlying structure. Implications for application and future directions are discussed.
</details>
<details>
<summary>摘要</summary>
近期有多个研究表明大语言模型（LLM）具有新的认知能力。然而，大多数研究仅仅基于启示，忽略训练集的杂乱，或者缺乏多个任务、控制条件、多个迭代和统计学robustness测试。我们在这里作出了两个主要贡献。首先，我们提议了一种认知科学途径 protocol for the systematic evaluation of cognitive capacities in Large Language Models，可以用于评估多种能力。其次，我们遵循这种协议来系统地评估 eight LLMs（OpenAI GPT-4、GPT-3.5-turbo-175B、davinci-003-175B、Google Bard、Cohere-xlarge-52.4B、Anthropic Claude-1-52B、LLaMA-13B和Alpaca-7B）的认知地图和规划能力。我们基于人类实验的任务提示，这些任务具有建立的验证有效性，且不存在在 LLM 训练集中。我们发现，虽然 LLMs 在一些规划任务中显示出一定的能力，但系统性评估表明，LLMs 在规划任务中存在明显的失败模式，包括hallucination 无效的轨迹和gets trapped in loops。这些发现不支持 LLMS 具有出 Box 的规划能力。这可能是因为 LLMS 不理解规划问题下的隐藏关系结构，并且无法基于这种结构推导目标导向的轨迹。我们的发现有很多应用和未来方向的意义。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Local-Robustness-of-High-Accuracy-Binary-Neural-Networks-for-Enhanced-Traffic-Sign-Recognition"><a href="#Benchmarking-Local-Robustness-of-High-Accuracy-Binary-Neural-Networks-for-Enhanced-Traffic-Sign-Recognition" class="headerlink" title="Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition"></a>Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03033">http://arxiv.org/abs/2310.03033</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/christopherbrix/vnncomp2023_benchmarks">https://github.com/christopherbrix/vnncomp2023_benchmarks</a></li>
<li>paper_authors: Andreea Postovan, Mădălina Eraşcu</li>
<li>for: 本研究旨在提高自动驾驶系统中的道路标志识别精度，并且面临着实际中的挑战，如抗抗例和遮挡。</li>
<li>methods: 本研究使用了二进制神经网络（BNN）来构建精度高的道路标志识别模型，并且强调了模型的尺寸和计算资源的有效使用。</li>
<li>results: 本研究发现，使用BNN模型可以在实际中提高道路标志识别精度，但是存在一些地区的异常输出和错误结果。<details>
<summary>Abstract</summary>
Traffic signs play a critical role in road safety and traffic management for autonomous driving systems. Accurate traffic sign classification is essential but challenging due to real-world complexities like adversarial examples and occlusions. To address these issues, binary neural networks offer promise in constructing classifiers suitable for resource-constrained devices.   In our previous work, we proposed high-accuracy BNN models for traffic sign recognition, focusing on compact size for limited computation and energy resources. To evaluate their local robustness, this paper introduces a set of benchmark problems featuring layers that challenge state-of-the-art verification tools. These layers include binarized convolutions, max pooling, batch normalization, fully connected. The difficulty of the verification problem is given by the high number of network parameters (905k - 1.7 M), of the input dimension (2.7k-12k), and of the number of regions (43) as well by the fact that the neural networks are not sparse.   The proposed BNN models and local robustness properties can be checked at https://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition.   The results of the 4th International Verification of Neural Networks Competition (VNN-COMP'23) revealed the fact that 4, out of 7, solvers can handle many of our benchmarks randomly selected (minimum is 6, maximum is 36, out of 45). Surprisingly, tools output also wrong results or missing counterexample (ranging from 1 to 4). Currently, our focus lies in exploring the possibility of achieving a greater count of solved instances by extending the allotted time (previously set at 8 minutes). Furthermore, we are intrigued by the reasons behind the erroneous outcomes provided by the tools for certain benchmarks.
</details>
<details>
<summary>摘要</summary>
traffic signs 对道路安全和交通管理具有关键作用，因此精准的交通标志分类是非常重要，但又是具有挑战性的。为了解决这些问题， binary neural networks（BNN）提供了一种可能性，它们可以在有限的计算和能源资源下构建高精度的分类器。在我们的前一项工作中，我们已经提出了高精度的BNN模型，专注于模型的紧凑性，以适应有限的计算资源。为了评估这些模型的本地稳定性，这篇论文引入了一组 benchmark 问题，这些问题挑战了当前的验证工具。这些问题包括缩进几何学层、最大池化层、批量常量层和归一化层，它们的难度来自于网络参数的大量（905k-1.7M）、输入维度的大量（2.7k-12k）和区域的数量（43）以及网络不是稀疏的性。可以在 <https://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition> 中查看我们的模型和本地稳定性性质。 competition 的结果表明，4个出 из 7个解决方案可以随机选择的 benchmark 中的许多（最小值是6，最大值是36，总共45）。尽管有些工具输出了错误的结果或缺失Counterexample（从1到4），但我们目前的注意力是探索可以通过延长时间（原先设置为8分钟）来提高解决的数量。此外，我们也对工具输出错误的原因产生了极大的兴趣。
</details></li>
</ul>
<hr>
<h2 id="Privacy-preserving-Linear-Computations-in-Spiking-Neural-P-Systems"><a href="#Privacy-preserving-Linear-Computations-in-Spiking-Neural-P-Systems" class="headerlink" title="Privacy-preserving Linear Computations in Spiking Neural P Systems"></a>Privacy-preserving Linear Computations in Spiking Neural P Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13803">http://arxiv.org/abs/2309.13803</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Mihail-Iulian Plesa, Marian Gheorghe, Florentin Ipate</li>
<li>for: 这个论文旨在提出一种基于生物神经元的启发式计算模型，以及这种模型在不同领域的应用，如正式验证、人工智能和加密等。</li>
<li>methods: 作者提出了一种基于SN P系统的隐私保护协议，允许客户端使用远程服务器来计算线性函数，而无需把函数参数和结果泄露给服务器。</li>
<li>results: 作者采用了SN P系统实现任意自然数上的线性函数，并评估了协议的安全性在“诚实但偷 curios”安全模型下。<details>
<summary>Abstract</summary>
Spiking Neural P systems are a class of membrane computing models inspired directly by biological neurons. Besides the theoretical progress made in this new computational model, there are also numerous applications of P systems in fields like formal verification, artificial intelligence, or cryptography. Motivated by all the use cases of SN P systems, in this paper, we present a new privacy-preserving protocol that enables a client to compute a linear function using an SN P system hosted on a remote server. Our protocol allows the client to use the server to evaluate functions of the form t_1k + t_2 without revealing t_1, t_2 or k and without the server knowing the result. We also present an SN P system to implement any linear function over natural numbers and some security considerations of our protocol in the honest-but-curious security model.
</details>
<details>
<summary>摘要</summary>
��Spiking Neural P Systems是一种基于生物神经元的计算模型。除了这种新的计算模型的理论进步之外，P系统还有很多应用于领域如正式验证、人工智能和加密等。在这篇论文中，我们提出了一种新的隐私保护协议，使得客户可以使用远程服务器上的SN P系统来计算函数形式为t_1k + t_2，而无需抛出t_1, t_2或k的报告，也无需服务器知道结果。我们还提出了一种实现任意自然数上的线性函数的SN P系统，以及一些安全考虑在诚实但叛逆安全模型中。
</details></li>
</ul>
<hr>
<h2 id="Can-LLM-Generated-Misinformation-Be-Detected"><a href="#Can-LLM-Generated-Misinformation-Be-Detected" class="headerlink" title="Can LLM-Generated Misinformation Be Detected?"></a>Can LLM-Generated Misinformation Be Detected?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13788">http://arxiv.org/abs/2309.13788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llm-misinformation/llm-misinformation">https://github.com/llm-misinformation/llm-misinformation</a></li>
<li>paper_authors: Canyu Chen, Kai Shu</li>
<li>for:  investigates whether LLM-generated misinformation can cause more harm than human-written misinformation</li>
<li>methods: builds a taxonomy of LLM-generated misinformation and categorizes potential real-world methods for generating misinformation with LLMs, and employs extensive empirical investigation to study the detection difficulty of LLM-generated misinformation</li>
<li>results: discovers that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, suggesting it can have more deceptive styles and potentially cause more harm<details>
<summary>Abstract</summary>
The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures.
</details>
<details>
<summary>摘要</summary>
LLMs 的出现对社交媒体和网络安全带来了重大影响。然而， LLMS 如 ChatGPT 可能会被滥用来生成谣言，这对于在线安全和公众信任造成了严重的问题。我们提出了一个基本研究问题： LLMS 生成的谣言是人类写的谣言更可能导致更多的伤害吗？我们从检测困难性的角度来回答这个问题。我们首先构建了 LLMS 生成谣言的分类体系，然后将可能在实际情况下使用 LLMS 生成谣言的方法分类和验证。经过广泛的实验研究，我们发现 LLMS 生成的谣言比人类写的谣言更难以检测，它们可能具有更多的欺骗性和误导性，从而可能导致更多的伤害。我们还讨论了我们的发现对于在 LLMS 时代战击谣言的应用和对策的影响。
</details></li>
</ul>
<hr>
<h2 id="On-the-Computational-Benefit-of-Multimodal-Learning"><a href="#On-the-Computational-Benefit-of-Multimodal-Learning" class="headerlink" title="On the Computational Benefit of Multimodal Learning"></a>On the Computational Benefit of Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13782">http://arxiv.org/abs/2309.13782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Lu</li>
<li>for: 本研究目的是调查多模态学习是否具有计算优势？</li>
<li>methods: 我们使用一种基于 intersecting two half-spaces 问题的新修改来实现多模态学习。</li>
<li>results: 我们发现，在某些条件下，多模态学习可以在计算上赶超单模态学习，具体来说是可以在幂时间内解决NP困难的学习任务。<details>
<summary>Abstract</summary>
Human perception inherently operates in a multimodal manner. Similarly, as machines interpret the empirical world, their learning processes ought to be multimodal. The recent, remarkable successes in empirical multimodal learning underscore the significance of understanding this paradigm. Yet, a solid theoretical foundation for multimodal learning has eluded the field for some time. While a recent study by Lu (2023) has shown the superior sample complexity of multimodal learning compared to its unimodal counterpart, another basic question remains: does multimodal learning also offer computational advantages over unimodal learning? This work initiates a study on the computational benefit of multimodal learning. We demonstrate that, under certain conditions, multimodal learning can outpace unimodal learning exponentially in terms of computation. Specifically, we present a learning task that is NP-hard for unimodal learning but is solvable in polynomial time by a multimodal algorithm. Our construction is based on a novel modification to the intersection of two half-spaces problem.
</details>
<details>
<summary>摘要</summary>
人类感知自然地进行多模态的处理。 Similarly，机器在观察现实世界时，其学习过程也应该是多模态的。当前， empirical multimodal learning的成功表明了这个思想的重要性。然而，领域中对多模态学习的基础理论还没有得到充分的解决。一些研究（如Lu 2023）已经表明了多模态学习的样本复杂性比单模态学习更低，但另一个基本问题仍然没有得到答案：多模态学习是否也提供了计算上的优势？本研究开始了对多模态学习的计算优势的研究。我们证明，在某些条件下，多模态学习可以在计算上赶超单模态学习，并且可以在计算时间方面呈指数增长。特别是，我们提出了一个NP困难的学习任务，但是通过多模态算法可以在 polynomial time 内解决。我们的构造基于一种新的两个半空间的交叉问题的修改。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Machine-Learning-for-ICU-Readmission-Prediction"><a href="#Explainable-Machine-Learning-for-ICU-Readmission-Prediction" class="headerlink" title="Explainable Machine Learning for ICU Readmission Prediction"></a>Explainable Machine Learning for ICU Readmission Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13781">http://arxiv.org/abs/2309.13781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex G. C. de Sá, Daniel Gould, Anna Fedyukova, Mitchell Nicholas, Lucy Dockrell, Calvin Fletcher, David Pilcher, Daniel Capurro, David B. Ascher, Khaled El-Khawas, Douglas E. V. Pires</li>
<li>For: The paper aims to develop a standardized and explainable machine learning pipeline to predict patient readmission in the intensive care unit (ICU) using a multicentric database.* Methods: The paper uses a machine learning approach with a Random Forest classification model to predict patient readmission, and validates the model on both monocentric and multicentric settings. The authors also provide explanations for the constructed models to derive insightful conclusions.* Results: The paper achieves predictive performance with an area under the receiver operating characteristic curve (AUC) up to 0.7, and demonstrates good calibration and consistency on validation sets. The authors also identify a set of variables related to vital signs, blood tests, demographics, and ICU-associated variables that are associated with patient readmission.<details>
<summary>Abstract</summary>
The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 admissions and 6,021 readmissions) while validating it on monocentric (i.e., the MIMIC IV cohort with 382,278 patients, 523,740 admissions and 5,984 readmissions) and multicentric settings. Our machine learning pipeline achieved predictive performance in terms of the area of the receiver operating characteristic curve (AUC) up to 0.7 with a Random Forest classification model, yielding an overall good calibration and consistency on validation sets. From explanations provided by the constructed models, we could also derive a set of insightful conclusions, primarily on variables related to vital signs and blood tests (e.g., albumin, blood urea nitrogen and hemoglobin levels), demographics (e.g., age, and admission height and weight), and ICU-associated variables (e.g., unit type). These insights provide an invaluable source of information during clinicians' decision-making while discharging ICU patients.
</details>
<details>
<summary>摘要</summary>
医院快速病区（ICU）是一个复杂的医疗环境，医生的决策对患者生命的风险很高。为了降低复杂性和风险，一个完整的护理路径必须采取。不确定、竞争和不计划的因素在这个环境中增加了困难，使得一致性地实施护理路径变得更加困难。重复入院是这个护理路径的一个主要障碍物，入院次数较多，导致高死亡率和资源利用率高。许多研究已经尝试预测重复入院，但这些研究并没有充分评估、描述和理解重复入院预测。本文提出了一个标准化和可解释的机器学习管道，用于在多中心数据库（i.e., eICU cohort）上预测患者重复入院，并在多中心和单中心设置上验证。我们的机器学习管道在预测重复入院方面达到了AUC0.7的水平，并在验证集上表现出了一致性和准确性。从构建的模型中提供的解释中，我们也得到了一些有价值的结论，主要关注于生命指标和血液测试（如蛋白质、尿氨酸和血红细胞含量）、人口学特征（如年龄和入院高度和重量）以及ICU相关变量（如单元类型）。这些结论可以提供医生决策时的很有价值的信息。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/25/cs.AI_2023_09_25/" data-id="clogyj8vj004x7cra77xaf0ez" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/26/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="page-number" href="/page/26/">26</a><span class="page-number current">27</span><a class="page-number" href="/page/28/">28</a><a class="page-number" href="/page/29/">29</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/28/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
