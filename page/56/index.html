
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/56/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.LG_2023_08_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/14/cs.LG_2023_08_14/" class="article-date">
  <time datetime="2023-08-14T10:00:00.000Z" itemprop="datePublished">2023-08-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/14/cs.LG_2023_08_14/">cs.LG - 2023-08-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distance-Matters-For-Improving-Performance-Estimation-Under-Covariate-Shift"><a href="#Distance-Matters-For-Improving-Performance-Estimation-Under-Covariate-Shift" class="headerlink" title="Distance Matters For Improving Performance Estimation Under Covariate Shift"></a>Distance Matters For Improving Performance Estimation Under Covariate Shift</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07223">http://arxiv.org/abs/2308.07223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/melanibe/distance_matters_performance_estimation">https://github.com/melanibe/distance_matters_performance_estimation</a></li>
<li>paper_authors: Mélanie Roschewitz, Ben Glocker</li>
<li>for: 本文旨在提出一种基于距离测试样本预期的训练分布的性能估计方法，以便在数据变换时进行安全的 AI 模型部署。</li>
<li>methods: 本文使用了一种基于距离测试样本预期的训练分布的方法，通过检查样本与预期的训练分布之间的距离，以避免在数据变换时取得不可靠的模型输出。</li>
<li>results:  experiments 表明，该方法可以在13种图像分类任务上提供 statistically 显著的性能估计改进（相对于最佳基准），并在10种任务上达到最佳性能。 code 可以在 <a target="_blank" rel="noopener" href="https://github.com/melanibe/distance_matters_performance_estimation">https://github.com/melanibe/distance_matters_performance_estimation</a> 中找到。<details>
<summary>Abstract</summary>
Performance estimation under covariate shift is a crucial component of safe AI model deployment, especially for sensitive use-cases. Recently, several solutions were proposed to tackle this problem, most leveraging model predictions or softmax confidence to derive accuracy estimates. However, under dataset shifts, confidence scores may become ill-calibrated if samples are too far from the training distribution. In this work, we show that taking into account distances of test samples to their expected training distribution can significantly improve performance estimation under covariate shift. Precisely, we introduce a "distance-check" to flag samples that lie too far from the expected distribution, to avoid relying on their untrustworthy model outputs in the accuracy estimation step. We demonstrate the effectiveness of this method on 13 image classification tasks, across a wide-range of natural and synthetic distribution shifts and hundreds of models, with a median relative MAE improvement of 27% over the best baseline across all tasks, and SOTA performance on 10 out of 13 tasks. Our code is publicly available at https://github.com/melanibe/distance_matters_performance_estimation.
</details>
<details>
<summary>摘要</summary>
In this work, we show that taking into account the distances of test samples to their expected training distribution can significantly improve performance estimation under covariate shift. Specifically, we introduce a "distance-check" to flag samples that lie too far from the expected distribution, in order to avoid relying on their untrustworthy model outputs in the accuracy estimation step.We demonstrate the effectiveness of this method on 13 image classification tasks, across a wide range of natural and synthetic distribution shifts and hundreds of models. Our results show a median relative MAE improvement of 27% over the best baseline across all tasks, and SOTA performance on 10 out of 13 tasks. Our code is publicly available at <https://github.com/melanibe/distance_matters_performance_estimation>.
</details></li>
</ul>
<hr>
<h2 id="AudioFormer-Audio-Transformer-learns-audio-feature-representations-from-discrete-acoustic-codes"><a href="#AudioFormer-Audio-Transformer-learns-audio-feature-representations-from-discrete-acoustic-codes" class="headerlink" title="AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes"></a>AudioFormer: Audio Transformer learns audio feature representations from discrete acoustic codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07221">http://arxiv.org/abs/2308.07221</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LZH-0225/AudioFormer">https://github.com/LZH-0225/AudioFormer</a></li>
<li>paper_authors: Zhaohui Li, Haitao Wang, Xinghua Jiang</li>
<li>for: 本研究旨在提出一种名为AudioFormer的方法，该方法通过获得隐藏的音频编码并在其基础之上进行微调，以便为音频分类任务进行特征表示。</li>
<li>methods: 我们首先提出一种新的思路，即将音频分类任务看作自然语言理解（NLU）的一种形式。然后，我们利用现有的神经网络音频编码器模型，生成隐藏的音频编码，并将其用于训练一个假名句语言模型（MLM），从而获得音频特征表示。此外，我们还提出了一种多 positivesample contrastive（MPC）学习方法，该方法可以学习多个隐藏的音频编码之间的共同表示。</li>
<li>results: 在我们的实验中，我们将隐藏的音频编码视为文本数据，并使用cloze-like方法训练一个假名句语言模型，最终获得高质量的音频表示。特别是，MPC学习技术可以有效地捕捉多个正样本之间的协同表示。我们的研究结果表明，AudioFormer在多个数据集上达到了 significatively improved的性能，甚至超过了一些音视频多模态分类模型。具体的表现为：在AudioSet（2M,20K）、FSD50K等数据集上，AudioFormer的性能分别为53.9、45.1和65.6。我们已经公开分享了代码和模型：<a target="_blank" rel="noopener" href="https://github.com/LZH-0225/AudioFormer.git%E3%80%82">https://github.com/LZH-0225/AudioFormer.git。</a><details>
<summary>Abstract</summary>
We propose a method named AudioFormer,which learns audio feature representations through the acquisition of discrete acoustic codes and subsequently fine-tunes them for audio classification tasks. Initially,we introduce a novel perspective by considering the audio classification task as a form of natural language understanding (NLU). Leveraging an existing neural audio codec model,we generate discrete acoustic codes and utilize them to train a masked language model (MLM),thereby obtaining audio feature representations. Furthermore,we pioneer the integration of a Multi-Positive sample Contrastive (MPC) learning approach. This method enables the learning of joint representations among multiple discrete acoustic codes within the same audio input. In our experiments,we treat discrete acoustic codes as textual data and train a masked language model using a cloze-like methodology,ultimately deriving high-quality audio representations. Notably,the MPC learning technique effectively captures collaborative representations among distinct positive samples. Our research outcomes demonstrate that AudioFormer attains significantly improved performance compared to prevailing monomodal audio classification models across multiple datasets,and even outperforms audio-visual multimodal classification models on select datasets. Specifically,our approach achieves remarkable results on datasets including AudioSet (2M,20K),and FSD50K,with performance scores of 53.9,45.1,and 65.6,respectively. We have openly shared both the code and models: https://github.com/LZH-0225/AudioFormer.git.
</details>
<details>
<summary>摘要</summary>
我们提出一种方法 named AudioFormer，它通过获取批量音频编码并进行精细调整，以便为音频分类任务学习音频特征表示。我们首先提出一种新的视角，即视音频分类任务为自然语言理解（NLU）的一种形式。利用现有的神经网络音频编码器模型，我们生成了批量音频编码，并使用它们训练一个隐藏状态语言模型（MLM），从而获得音频特征表示。此外，我们开拓了多个正样本对比（MPC）学习方法的 интеграción。这种方法使得在同一个音频输入中学习多个批量音频编码的联合表示。在我们的实验中，我们将批量音频编码视为文本数据，并使用cloze-like方法训练一个隐藏状态语言模型，最终得到高质量的音频表示。各种实验结果表明，AudioFormer在多个数据集上达到了 significativamente提高的性能，并在一些数据集上 even outperform 音频-视觉多模态分类模型。具体来说，我们的方法在AudioSet（2M,20K）、FSD50K 等数据集上达到了性能分数为 53.9、45.1 和 65.6 等。我们已经在 GitHub 上公开分享了代码和模型：https://github.com/LZH-0225/AudioFormer.git。
</details></li>
</ul>
<hr>
<h2 id="Generating-Individual-Trajectories-Using-GPT-2-Trained-from-Scratch-on-Encoded-Spatiotemporal-Data"><a href="#Generating-Individual-Trajectories-Using-GPT-2-Trained-from-Scratch-on-Encoded-Spatiotemporal-Data" class="headerlink" title="Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data"></a>Generating Individual Trajectories Using GPT-2 Trained from Scratch on Encoded Spatiotemporal Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07940">http://arxiv.org/abs/2308.07940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taizo Horikomi, Shouji Fujimoto, Atushi Ishikawa, Takayuki Mizuno</li>
<li>for: 本研究使用GPT-2语言模型来生成个人日常路径序列，以考虑环境因素和个人特征的影响。</li>
<li>methods: 研究人员使用了坐标转换技术将地理坐标表示为特定的位置符号，并将每天的路径序列表示为一系列这些位置符号。特定的时间间隔符号和环境因素符号也被添加到序列中，以便在GPT-2架构上进行训练。</li>
<li>results: 通过训练这些位置符号和时间间隔符号，研究人员可以生成受环境因素和个人特征影响的个人日常路径序列。<details>
<summary>Abstract</summary>
Following Mizuno, Fujimoto, and Ishikawa's research (Front. Phys. 2022), we transpose geographical coordinates expressed in latitude and longitude into distinctive location tokens that embody positions across varied spatial scales. We encapsulate an individual daily trajectory as a sequence of tokens by adding unique time interval tokens to the location tokens. Using the architecture of an autoregressive language model, GPT-2, this sequence of tokens is trained from scratch, allowing us to construct a deep learning model that sequentially generates an individual daily trajectory. Environmental factors such as meteorological conditions and individual attributes such as gender and age are symbolized by unique special tokens, and by training these tokens and trajectories on the GPT-2 architecture, we can generate trajectories that are influenced by both environmental factors and individual attributes.
</details>
<details>
<summary>摘要</summary>
根据米泽野、藤本和石川等人的研究（Front. Phys. 2022），我们将地理坐标表示为纬度和经度转换为特征化的位置标记，这些标记表示在不同的空间尺度上的位置。我们将每天的行走路径序列为一系列标记，并将具有特定时间间隔的唯一标记添加到位置标记中。使用GPT-2架构的自然语言模型，我们从头开始训练这些标记和路径，以生成基于环境因素和个人特征的各天行走路径。特殊的环境因素和个人特征被象化为唯一的特殊标记，通过训练这些标记和路径，我们可以生成受环境因素和个人特征影响的行走路径。
</details></li>
</ul>
<hr>
<h2 id="Automated-Ensemble-Based-Segmentation-of-Pediatric-Brain-Tumors-A-Novel-Approach-Using-the-CBTN-CONNECT-ASNR-MICCAI-BraTS-PEDs-2023-Challenge-Data"><a href="#Automated-Ensemble-Based-Segmentation-of-Pediatric-Brain-Tumors-A-Novel-Approach-Using-the-CBTN-CONNECT-ASNR-MICCAI-BraTS-PEDs-2023-Challenge-Data" class="headerlink" title="Automated Ensemble-Based Segmentation of Pediatric Brain Tumors: A Novel Approach Using the CBTN-CONNECT-ASNR-MICCAI BraTS-PEDs 2023 Challenge Data"></a>Automated Ensemble-Based Segmentation of Pediatric Brain Tumors: A Novel Approach Using the CBTN-CONNECT-ASNR-MICCAI BraTS-PEDs 2023 Challenge Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07212">http://arxiv.org/abs/2308.07212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashidhar Reddy Javaji, Sovesh Mohapatra, Advait Gosai, Gottfried Schlaug</li>
<li>for: 这个研究旨在发展deep learning技术，对于脑癌诊断和治疗方法进行改进。</li>
<li>methods: 这个研究使用了深度学习技术，包括ONet和modified UNet，以及新的损失函数。</li>
<li>results:  ensemble方法可以实现更高的精度和更好的特征捕捉，实现lesion_wise dice scores的0.52、0.72和0.78，并且可以更好地覆盖肿瘤区域。<details>
<summary>Abstract</summary>
Brain tumors remain a critical global health challenge, necessitating advancements in diagnostic techniques and treatment methodologies. In response to the growing need for age-specific segmentation models, particularly for pediatric patients, this study explores the deployment of deep learning techniques using magnetic resonance imaging (MRI) modalities. By introducing a novel ensemble approach using ONet and modified versions of UNet, coupled with innovative loss functions, this study achieves a precise segmentation model for the BraTS-PEDs 2023 Challenge. Data augmentation, including both single and composite transformations, ensures model robustness and accuracy across different scanning protocols. The ensemble strategy, integrating the ONet and UNet models, shows greater effectiveness in capturing specific features and modeling diverse aspects of the MRI images which result in lesion_wise dice scores of 0.52, 0.72 and 0.78 for enhancing tumor, tumor core and whole tumor labels respectively. Visual comparisons further confirm the superiority of the ensemble method in accurate tumor region coverage. The results indicate that this advanced ensemble approach, building upon the unique strengths of individual models, offers promising prospects for enhanced diagnostic accuracy and effective treatment planning for brain tumors in pediatric brains.
</details>
<details>
<summary>摘要</summary>
�� funcionado global health challenge, requiring advancements in diagnostic techniques and treatment methodologies. In response to the growing need for age-specific segmentation models, particularly for pediatric patients, this study explores the deployment of deep learning techniques using magnetic resonance imaging (MRI) modalities. By introducing a novel ensemble approach using ONet and modified versions of UNet, coupled with innovative loss functions, this study achieves a precise segmentation model for the BraTS-PEDs 2023 Challenge. Data augmentation, including both single and composite transformations, ensures model robustness and accuracy across different scanning protocols. The ensemble strategy, integrating the ONet and UNet models, shows greater effectiveness in capturing specific features and modeling diverse aspects of the MRI images which result in lesion_wise dice scores of 0.52, 0.72 and 0.78 for enhancing tumor, tumor core and whole tumor labels respectively. Visual comparisons further confirm the superiority of the ensemble method in accurate tumor region coverage. The results indicate that this advanced ensemble approach, building upon the unique strengths of individual models, offers promising prospects for enhanced diagnostic accuracy and effective treatment planning for brain tumors in pediatric brains.Here's the word-for-word translation:�Git tumors remain a critical global health challenge, necessitating advancements in diagnostic techniques and treatment methodologies. In response to the growing need for age-specific segmentation models, particularly for pediatric patients, this study explores the deployment of deep learning techniques using magnetic resonance imaging (MRI) modalities. By introducing a novel ensemble approach using ONet and modified versions of UNet, coupled with innovative loss functions, this study achieves a precise segmentation model for the BraTS-PEDs 2023 Challenge. Data augmentation, including both single and composite transformations, ensures model robustness and accuracy across different scanning protocols. The ensemble strategy, integrating the ONet and UNet models, shows greater effectiveness in capturing specific features and modeling diverse aspects of the MRI images which result in lesion_wise dice scores of 0.52, 0.72 and 0.78 for enhancing tumor, tumor core and whole tumor labels respectively. Visual comparisons further confirm the superiority of the ensemble method in accurate tumor region coverage. The results indicate that this advanced ensemble approach, building upon the unique strengths of individual models, offers promising prospects for enhanced diagnostic accuracy and effective treatment planning for brain tumors in pediatric brains.
</details></li>
</ul>
<hr>
<h2 id="Unified-Data-Free-Compression-Pruning-and-Quantization-without-Fine-Tuning"><a href="#Unified-Data-Free-Compression-Pruning-and-Quantization-without-Fine-Tuning" class="headerlink" title="Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning"></a>Unified Data-Free Compression: Pruning and Quantization without Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07209">http://arxiv.org/abs/2308.07209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shipeng Bai, Jun Chen, Xintian Shen, Yixuan Qian, Yong Liu</li>
<li>for: 提高神经网络的推理时间和内存占用的压缩和量化方法，但大多数现有方法需要原始训练集来微调模型，带来负担重大并不适用于敏感或商业化数据的应用。</li>
<li>methods: 提出了一些数据自由方法，但它们分别进行数据自由压缩和量化，而不是同时进行压缩和量化。</li>
<li>results: 在大规模图像分类任务中，我们的方法（Unified Data-Free Compression，UDFC）可以在不需要数据和微调过程的情况下，同时进行压缩和量化，并实现了与现有方法相当的性能提升。例如，在ImageNet dataset上，我们对ResNet-34网络进行30%压缩和6比特量化后，与最佳方法相比，我们的方法可以达到20.54%的精度提升。<details>
<summary>Abstract</summary>
Structured pruning and quantization are promising approaches for reducing the inference time and memory footprint of neural networks. However, most existing methods require the original training dataset to fine-tune the model. This not only brings heavy resource consumption but also is not possible for applications with sensitive or proprietary data due to privacy and security concerns. Therefore, a few data-free methods are proposed to address this problem, but they perform data-free pruning and quantization separately, which does not explore the complementarity of pruning and quantization. In this paper, we propose a novel framework named Unified Data-Free Compression(UDFC), which performs pruning and quantization simultaneously without any data and fine-tuning process. Specifically, UDFC starts with the assumption that the partial information of a damaged(e.g., pruned or quantized) channel can be preserved by a linear combination of other channels, and then derives the reconstruction form from the assumption to restore the information loss due to compression. Finally, we formulate the reconstruction error between the original network and its compressed network, and theoretically deduce the closed-form solution. We evaluate the UDFC on the large-scale image classification task and obtain significant improvements over various network architectures and compression methods. For example, we achieve a 20.54% accuracy improvement on ImageNet dataset compared to SOTA method with 30% pruning ratio and 6-bit quantization on ResNet-34.
</details>
<details>
<summary>摘要</summary>
《结构化剪辑和量化是减少神经网络推理时间和内存占用的有效方法。然而，大多数现有方法需要原始训练集来精度调整模型，这不仅带来重要资源占用，还不可能 для涉及隐私或商业机密的应用程序 due to privacy and security concerns。因此，一些无数据方法被提议，但它们分别进行无数据剪辑和量化，而不是探索剪辑和量化的共同优势。在这篇论文中，我们提出了一个名为统一无数据压缩（UDFC）的新框架，它在无数据情况下同时进行剪辑和量化。具体来说，UDFC从假设部分频道（例如剪辑或量化）的信息可以通过其他频道的线性组合来保留一些信息，然后 derive 恢复形式来恢复因压缩而产生的信息损失。最后，我们将重建误差 между 原始网络和压缩后的网络，并 theoretically 递归解决。我们在大规模图像分类任务上评估了UDFC，并实现了对不同网络架构和压缩方法的显著改进。例如，我们在 ImageNet 数据集上实现了与 SOTA 方法相比的 20.54% 的准确率提升，其中 ResNet-34 网络的 30% 剪辑率和 6 位量化。
</details></li>
</ul>
<hr>
<h2 id="Algorithms-for-the-Training-of-Neural-Support-Vector-Machines"><a href="#Algorithms-for-the-Training-of-Neural-Support-Vector-Machines" class="headerlink" title="Algorithms for the Training of Neural Support Vector Machines"></a>Algorithms for the Training of Neural Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07204">http://arxiv.org/abs/2308.07204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sayantann11/all-classification-templetes-for-ML">https://github.com/sayantann11/all-classification-templetes-for-ML</a></li>
<li>paper_authors: Lars Simon, Manuel Radons</li>
<li>for: 本文旨在探讨基于域知识的神经支持向量机（NSVM）模型的设计，以及一些基于Pegasos算法的训练算法。</li>
<li>methods: 本文使用Pegasos算法和一些基于神经网络的训练算法来训练NSVM模型。</li>
<li>results: 本文通过解决一些标准机器学习任务来证明NSVM模型的可行性。<details>
<summary>Abstract</summary>
Neural support vector machines (NSVMs) allow for the incorporation of domain knowledge in the design of the model architecture. In this article we introduce a set of training algorithms for NSVMs that leverage the Pegasos algorithm and provide a proof of concept by solving a set of standard machine learning tasks.
</details>
<details>
<summary>摘要</summary>
神经支持向量机器 (NSVM) 允许在模型建立之处 incorporate 领域知识。在这篇文章中，我们介绍了一组用 Pegasos 算法进行训练 NSVM 的算法，并通过解决一组标准机器学习任务来提供证明。Note that "神经支持向量机器" (NSVM) is the Simplified Chinese term for "neural support vector machine".
</details></li>
</ul>
<hr>
<h2 id="Neural-Categorical-Priors-for-Physics-Based-Character-Control"><a href="#Neural-Categorical-Priors-for-Physics-Based-Character-Control" class="headerlink" title="Neural Categorical Priors for Physics-Based Character Control"></a>Neural Categorical Priors for Physics-Based Character Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07200">http://arxiv.org/abs/2308.07200</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Tencent-RoboticsX/NCP">https://github.com/Tencent-RoboticsX/NCP</a></li>
<li>paper_authors: Qingxu Zhu, He Zhang, Mengting Lan, Lei Han</li>
<li>for: 本研究目的是提出一种新的学习框架，用于控制基于物理学的人工智能角色，以实现更高质量和多样性的运动。</li>
<li>methods: 本研究使用了强化学习（RL）来跟踪和模仿生命力运动的精准信息，并使用了量化自适应变换器（VQ-VAE）来压缩运动clip中的最重要信息。</li>
<li>results: 研究结果表明，提出的方法可以控制人工智能角色进行高质量、多样化的运动，并且可以在两个复杂的下游任务中表现出色，包括剑盾攻击和两个玩家拳击游戏。<details>
<summary>Abstract</summary>
Recent advances in learning reusable motion priors have demonstrated their effectiveness in generating naturalistic behaviors. In this paper, we propose a new learning framework in this paradigm for controlling physics-based characters with significantly improved motion quality and diversity over existing state-of-the-art methods. The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure compresses the most relevant information from the motion clips into a compact yet informative latent space, i.e., a discrete space over vector quantized codes. By sampling codes in the space from a trained categorical prior distribution, high-quality life-like behaviors can be generated, similar to the usage of VQ-VAE in computer vision. Although this prior distribution can be trained with the supervision of the encoder's output, it follows the original motion clip distribution in the dataset and could lead to imbalanced behaviors in our setting. To address the issue, we further propose a technique named prior shifting to adjust the prior distribution using curiosity-driven RL. The outcome distribution is demonstrated to offer sufficient behavioral diversity and significantly facilitates upper-level policy learning for downstream tasks. We conduct comprehensive experiments using humanoid characters on two challenging downstream tasks, sword-shield striking and two-player boxing game. Our results demonstrate that the proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism. Videos, codes, and data are available at https://tencent-roboticsx.github.io/NCP/.
</details>
<details>
<summary>摘要</summary>
近期研究生成可重用运动先验的进步已经证明了它们在生成自然化行为方面的效果。在这篇论文中，我们提出了一种新的学习框架，用于控制基于物理学的角色，并提高了现有状态艺术方法的运动质量和多样性。我们的方法使用了奖励学习（RL）来初始化并模仿生命体运动，使用不结构化运动片段中的精炼信息，并使用Vector Quantized Variational AutoEncoder（VQ-VAE）结构压缩运动片段中的最重要信息。这种结构将运动片段中的信息压缩成一个紧凑而有用的秘密空间中，通过从已经训练的分类先验分布中采样代码，可以生成高质量的生命体运动。虽然这种先验分布可以通过Encoder的输出进行超vision训练，但它遵循原始运动片段分布，可能会导致行为偏好。为解决这个问题，我们进一步提出了一种名为“先验偏移”的技术，通过吸引力驱动RL来调整先验分布。结果显示，我们的框架可以控制角色进行高质量的运动，包括行为策略、多样性和真实性。我们在人iform机器人上进行了广泛的实验，并在剑盾战和两个玩家盒子游戏中进行了两个下游任务。我们的结果表明，我们的框架可以控制角色进行较高质量的运动，并且可以提高下游任务的性能。视频、代码和数据可以在https://tencent-roboticsx.github.io/NCP/上获取。
</details></li>
</ul>
<hr>
<h2 id="Explaining-Black-Box-Models-through-Counterfactuals"><a href="#Explaining-Black-Box-Models-through-Counterfactuals" class="headerlink" title="Explaining Black-Box Models through Counterfactuals"></a>Explaining Black-Box Models through Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07198">http://arxiv.org/abs/2308.07198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliatrustworthyai/counterfactualexplanations.jl">https://github.com/juliatrustworthyai/counterfactualexplanations.jl</a></li>
<li>paper_authors: Patrick Altmeyer, Arie van Deursen, Cynthia C. S. Liem</li>
<li>for: 这篇论文是用于解释人工智能的Explainable Artificial Intelligence（ExplaI）。</li>
<li>methods: 这篇论文使用Counterfactual Explanations（CE）和Algorithmic Recourse（AR）来解释黑盒模型的预测结果。</li>
<li>results: 这篇论文提供了一个用于Julia语言的CounterfactualExplanations.jl包，可以生成Counterfactual Explanations和Algorithmic Recourse，并且可以用于解释任何黑盒模型的预测结果。<details>
<summary>Abstract</summary>
We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.
</details>
<details>
<summary>摘要</summary>
我们介绍CounterfactualExplanations.jl：一个用于生成Counterfactual Explanations（CE）和Algorithmic Recourse（AR）的套件，用于黑盒模型中的Julia。CE解释了如何让模型的输入变化以获得具体预测。这些解释可以提供AR：一组建议行动，以改善不愉快的结果。在这篇文章中，我们讨论了Counterfactual Explanations在可解释人工智能中的用途，并详细介绍了我们的套件。套件易于使用，设计了一个重点在自定义和扩展。我们将这个套件作为Julia中解释任意预测模型的首选场所。
</details></li>
</ul>
<hr>
<h2 id="gSASRec-Reducing-Overconfidence-in-Sequential-Recommendation-Trained-with-Negative-Sampling"><a href="#gSASRec-Reducing-Overconfidence-in-Sequential-Recommendation-Trained-with-Negative-Sampling" class="headerlink" title="gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling"></a>gSASRec: Reducing Overconfidence in Sequential Recommendation Trained with Negative Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07192">http://arxiv.org/abs/2308.07192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asash/gsasrec">https://github.com/asash/gsasrec</a></li>
<li>paper_authors: Aleksandr Petrov, Craig Macdonald</li>
<li>for: 这篇论文旨在解释为何SASRec模型在比较BERT4Rec模型时表现不佳，并提出一种新的总体二进制十字Entropy损失函数（gBCE）以及改进后的gSASRec模型，以 Mitigate overconfidence问题。</li>
<li>methods: 这篇论文使用了SASRec模型和BERT4Rec模型，并对它们进行了比较。它还提出了一种新的总体二进制十字Entropy损失函数（gBCE），并证明了它可以降低overconfidence问题。</li>
<li>results: 这篇论文通过了详细的实验表明，gSASRec模型可以在三个 datasets上不受overconfidence问题的影响，并且可以超越BERT4Rec模型（例如，MovieLens-1M数据集上的NDCG提高了9.47%），同时需要更少的训练时间（例如，MovieLens-1M数据集上的训练时间减少了73%）。<details>
<summary>Abstract</summary>
A large catalogue size is one of the central challenges in training recommendation models: a large number of items makes them memory and computationally inefficient to compute scores for all items during training, forcing these models to deploy negative sampling. However, negative sampling increases the proportion of positive interactions in the training data, and therefore models trained with negative sampling tend to overestimate the probabilities of positive interactions a phenomenon we call overconfidence. While the absolute values of the predicted scores or probabilities are not important for the ranking of retrieved recommendations, overconfident models may fail to estimate nuanced differences in the top-ranked items, resulting in degraded performance. In this paper, we show that overconfidence explains why the popular SASRec model underperforms when compared to BERT4Rec. This is contrary to the BERT4Rec authors explanation that the difference in performance is due to the bi-directional attention mechanism. To mitigate overconfidence, we propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) and theoretically prove that it can mitigate overconfidence. We further propose the gSASRec model, an improvement over SASRec that deploys an increased number of negatives and the gBCE loss. We show through detailed experiments on three datasets that gSASRec does not exhibit the overconfidence problem. As a result, gSASRec can outperform BERT4Rec (e.g. +9.47% NDCG on the MovieLens-1M dataset), while requiring less training time (e.g. -73% training time on MovieLens-1M). Moreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that contain more than 1 million items.
</details>
<details>
<summary>摘要</summary>
大型目录大小是训练推荐模型的中心挑战之一：大量的项目使得计算和存储成本增加，使得这些模型在训练期间计算所有项目的得分变得不可能。然而，使用负样本增加了正交互动的比例在训练数据中，因此模型受负样本部署后会过度估计正交互动的现象，我们称之为过信任。虽然绝对值的预测分数或概率不重要于推荐结果的排序，但过信任的模型可能无法估计顶层推荐的细微差异，导致性能下降。在这篇论文中，我们表明了过信任问题导致SASRec模型在比较BERT4Rec时表现不佳。这与BERT4Rec作者的解释不同，即Bi-directional attention机制导致的差异。为了消除过信任，我们提出一种通用二进制十进制损失函数（gBCE），并论证它可以消除过信任。此外，我们还提出了gSASRec模型，它在SASRec模型的基础上增加了更多的负样本和gBCE损失函数。我们通过三个数据集的详细实验表明，gSASRec模型不会出现过信任问题。因此，gSASRec可以超过BERT4Rec（例如，MovieLens-1M数据集上的NDCG提高9.47%），同时需要较少的训练时间（例如，MovieLens-1M数据集上的训练时间减少73%）。此外，gSASRec模型适用于包含更多 чем100万个项目的大型数据集。
</details></li>
</ul>
<hr>
<h2 id="Improving-ICD-based-semantic-similarity-by-accounting-for-varying-degrees-of-comorbidity"><a href="#Improving-ICD-based-semantic-similarity-by-accounting-for-varying-degrees-of-comorbidity" class="headerlink" title="Improving ICD-based semantic similarity by accounting for varying degrees of comorbidity"></a>Improving ICD-based semantic similarity by accounting for varying degrees of comorbidity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07359">http://arxiv.org/abs/2308.07359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Janosch Schneider, Marius Adler, Christoph Ammer-Herrmenau, Alexander Otto König, Ulrich Sax, Jonas Hügel<br>for: 这篇论文的目的是什么？* 这篇论文的目的是找出类似的病人，以便评估治疗结果和促进临床决策。methods: 这篇论文使用了哪些方法？* 这篇论文使用了 semantic similarity algorithms，包括 level-based information content、Leacock &amp; Chodorow concept similarity 和 bipartite graph matching。results: 这篇论文的结果是什么？* 这篇论文的结果表明， Accounting for comorbidity variance can significantly improve the performance of semantic similarity algorithms。最佳结果为 level-based information content、Leacock &amp; Chodorow concept similarity 和 bipartite graph matching的 комbination，与专家评验的真实值相符。<details>
<summary>Abstract</summary>
Finding similar patients is a common objective in precision medicine, facilitating treatment outcome assessment and clinical decision support. Choosing widely-available patient features and appropriate mathematical methods for similarity calculations is crucial. International Statistical Classification of Diseases and Related Health Problems (ICD) codes are used worldwide to encode diseases and are available for nearly all patients. Aggregated as sets consisting of primary and secondary diagnoses they can display a degree of comorbidity and reveal comorbidity patterns. It is possible to compute the similarity of patients based on their ICD codes by using semantic similarity algorithms. These algorithms have been traditionally evaluated using a single-term expert rated data set.   However, real-word patient data often display varying degrees of documented comorbidities that might impair algorithm performance. To account for this, we present a scale term that considers documented comorbidity-variance. In this work, we compared the performance of 80 combinations of established algorithms in terms of semantic similarity based on ICD-code sets. The sets have been extracted from patients with a C25.X (pancreatic cancer) primary diagnosis and provide a variety of different combinations of ICD-codes. Using our scale term we yielded the best results with a combination of level-based information content, Leacock & Chodorow concept similarity and bipartite graph matching for the set similarities reaching a correlation of 0.75 with our expert's ground truth. Our results highlight the importance of accounting for comorbidity variance while demonstrating how well current semantic similarity algorithms perform.
</details>
<details>
<summary>摘要</summary>
寻找类似病人是精准医学中常见的目标，可以促进治疗结果评估和临床决策支持。选择广泛可用的病人特征和适当的数学方法进行相似性计算是关键。国际疾病分类和相关医学问题（ICD）代码是全球通用的疾病编码，可以为大多数病人提供。将这些代码集成为主要和次要诊断的集合，可以显示疾病复杂性和潜在的疾病模式。可以使用语义相似算法计算病人之间的相似性。这些算法traditionally被评估使用专家评分的单个数据集。但是，实际的病人数据经常具有不同程度的记录的相关疾病，这可能会影响算法性能。为了考虑这一点，我们提出了一个权重因子，以考虑记录的相关疾病差异。在这种情况下，我们比较了80组已知算法的语义相似性，基于ICD代码集。这些代码集来自悉尼癌病（C25.X）主诊断的病人，并提供了不同的ICD代码组合。通过我们的权重因子，我们得到了最佳的结果，其中包括水平基本信息内容、Leacock & Chodorow概念相似和 биipartite图匹配算法，达到了专家的参考真实值的0.75相似度。我们的结果 highlights the importance of accounting for comorbidity variance while demonstrating the current state-of-the-art semantic similarity algorithms perform well.
</details></li>
</ul>
<hr>
<h2 id="Conformal-Predictions-Enhanced-Expert-guided-Meshing-with-Graph-Neural-Networks"><a href="#Conformal-Predictions-Enhanced-Expert-guided-Meshing-with-Graph-Neural-Networks" class="headerlink" title="Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks"></a>Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07358">http://arxiv.org/abs/2308.07358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahnobari/autosurf">https://github.com/ahnobari/autosurf</a></li>
<li>paper_authors: Amin Heyrani Nobari, Justin Rey, Suhas Kodali, Matthew Jones, Faez Ahmed<br>for:This paper aims to develop a machine learning-based scheme for automatically generating high-quality meshes for computational fluid dynamics (CFD) simulations, with a focus on aircraft models.methods:The proposed method utilizes graph neural networks (GNN) and expert guidance to generate CFD meshes. A new 3D segmentation algorithm is introduced, which outperforms two state-of-the-art models, PointNet++ and PointMLP, for surface classification. The conformal predictions method is used to project predictions from 3D mesh segmentation models to CAD surfaces, providing marginal statistical guarantees and robust uncertainty quantification and handling.results:The proposed approach is demonstrated through a real-world case study, showing that the automatically generated mesh is comparable in quality to expert-generated meshes and enables the solver to converge and produce accurate results. Additionally, the approach is found to be 5 times faster than adaptive remeshing in the overall process of simulation. The code and data for this project are made publicly available at <a target="_blank" rel="noopener" href="https://github.com/ahnobari/AutoSurf">https://github.com/ahnobari/AutoSurf</a>.<details>
<summary>Abstract</summary>
Computational Fluid Dynamics (CFD) is widely used in different engineering fields, but accurate simulations are dependent upon proper meshing of the simulation domain. While highly refined meshes may ensure precision, they come with high computational costs. Similarly, adaptive remeshing techniques require multiple simulations and come at a great computational cost. This means that the meshing process is reliant upon expert knowledge and years of experience. Automating mesh generation can save significant time and effort and lead to a faster and more efficient design process. This paper presents a machine learning-based scheme that utilizes Graph Neural Networks (GNN) and expert guidance to automatically generate CFD meshes for aircraft models. In this work, we introduce a new 3D segmentation algorithm that outperforms two state-of-the-art models, PointNet++ and PointMLP, for surface classification. We also present a novel approach to project predictions from 3D mesh segmentation models to CAD surfaces using the conformal predictions method, which provides marginal statistical guarantees and robust uncertainty quantification and handling. We demonstrate that the addition of conformal predictions effectively enables the model to avoid under-refinement, hence failure, in CFD meshing even for weak and less accurate models. Finally, we demonstrate the efficacy of our approach through a real-world case study that demonstrates that our automatically generated mesh is comparable in quality to expert-generated meshes and enables the solver to converge and produce accurate results. Furthermore, we compare our approach to the alternative of adaptive remeshing in the same case study and find that our method is 5 times faster in the overall process of simulation. The code and data for this project are made publicly available at https://github.com/ahnobari/AutoSurf.
</details>
<details>
<summary>摘要</summary>
computational fluid dynamics (CFD) 广泛应用于不同的工程领域，但准确的 simulations 受到 mesh 的限制。高精度的 mesh 可以确保精度，但是来自计算成本的代价很高。 adaptive remeshing 技术也需要多次 simulations 和大量计算成本。这意味着 meshing 过程依赖于专家知识和多年的经验。自动生成 mesh 可以保存很多时间和努力，并且导致更快的设计过程。本文提出了一种基于 machine learning 的 scheme，使用 graph neural networks (GNN) 和专家指导生成 CFD mesh  для飞机模型。在这种工作中，我们提出了一种新的 3D 分割算法，其在 surface classification 方面超过了两个 state-of-the-art 模型：PointNet++ 和 PointMLP。我们还提出了一种将 predictions 从 3D mesh 分割模型项project 到 CAD 表面的新方法，使用 conformal predictions 方法，该方法提供了边缘统计保证和稳定的 uncertainty quantification 和处理。我们示示了添加 conformal predictions 可以使模型避免 under-refinement 和失败，即CFD  meshing中的负面刻。 finally，我们通过一个实际的案例研究证明了我们自动生成的 mesh 与专家生成的 mesh 相当，并且使得解除器能够 converges 并生成准确的结果。此外，我们与 adaptive remeshing 的相对比较发现，我们的方法在整个 simulations 过程中速度比 adaptive remeshing 5 倍。代码和数据可以在 https://github.com/ahnobari/AutoSurf 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Learning-of-Quantum-States-Prepared-With-Few-Non-Clifford-Gates-II-Single-Copy-Measurements"><a href="#Efficient-Learning-of-Quantum-States-Prepared-With-Few-Non-Clifford-Gates-II-Single-Copy-Measurements" class="headerlink" title="Efficient Learning of Quantum States Prepared With Few Non-Clifford Gates II: Single-Copy Measurements"></a>Efficient Learning of Quantum States Prepared With Few Non-Clifford Gates II: Single-Copy Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07175">http://arxiv.org/abs/2308.07175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang</li>
<li>for: 学习 $n$-qubit 量子状态，输出由最多 $t$ 单位 qubit 非截归 gate 生成的 circuits，可以使用 $\mathsf{poly}(n,2^t,1&#x2F;\epsilon)$ 时间和样本来达到 trace distance $\epsilon$。</li>
<li>methods: 使用单复本测量来学习该类状态，而不需要双复本测量。</li>
<li>results: 实现了同样高效的学习算法，但使用单复本测量而不需要双复本测量。<details>
<summary>Abstract</summary>
Recent work has shown that $n$-qubit quantum states output by circuits with at most $t$ single-qubit non-Clifford gates can be learned to trace distance $\epsilon$ using $\mathsf{poly}(n,2^t,1/\epsilon)$ time and samples. All prior algorithms achieving this runtime use entangled measurements across two copies of the input state. In this work, we give a similarly efficient algorithm that learns the same class of states using only single-copy measurements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PitchNet-A-Fully-Convolutional-Neural-Network-for-Pitch-Estimation"><a href="#PitchNet-A-Fully-Convolutional-Neural-Network-for-Pitch-Estimation" class="headerlink" title="PitchNet: A Fully Convolutional Neural Network for Pitch Estimation"></a>PitchNet: A Fully Convolutional Neural Network for Pitch Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07170">http://arxiv.org/abs/2308.07170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeremy Cochoy</li>
<li>for: 用于提高音乐和声音处理中的抽取音高精度</li>
<li>methods: 使用卷积神经网络和自相关函数优化抽取音高精度</li>
<li>results: 在各种数据集上（包括合唱、歌剧录音和时间压缩的元音）进行评估，达到了更高的抽取音高精度<details>
<summary>Abstract</summary>
In the domain of music and sound processing, pitch extraction plays a pivotal role. This research introduces "PitchNet", a convolutional neural network tailored for pitch extraction from the human singing voice, including acapella performances. Integrating autocorrelation with deep learning techniques, PitchNet aims to optimize the accuracy of pitch detection. Evaluation across datasets comprising synthetic sounds, opera recordings, and time-stretched vowels demonstrates its efficacy. This work paves the way for enhanced pitch extraction in both music and voice settings.
</details>
<details>
<summary>摘要</summary>
在音乐和声音处理领域中，抓取高度扮演着关键性的角色。这项研究介绍了“抓取网络”（PitchNet），一种针对人声 singing voice 的卷积神经网络，包括 acapella 表演。通过与深度学习技术结合自相关性，PitchNet 目标优化抓取精度。对于各种数据集，包括 sintetic 声音、歌剧录音和时间压缩的元音，评估表明 PitchNet 的可行性。这项工作将为音乐和声音设置中的抓取提供新的 возможности。
</details></li>
</ul>
<hr>
<h2 id="SPEGTI-Structured-Prediction-for-Efficient-Generative-Text-to-Image-Models"><a href="#SPEGTI-Structured-Prediction-for-Efficient-Generative-Text-to-Image-Models" class="headerlink" title="SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models"></a>SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10997">http://arxiv.org/abs/2308.10997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadeep Jayasumana, Daniel Glasner, Srikumar Ramalingam, Andreas Veit, Ayan Chakrabarti, Sanjiv Kumar</li>
<li>for: 提高文本图像生成模型的计算效率，以便在不输出质量下降的情况下提高图像生成速度。</li>
<li>methods: 使用MarkovRandomField（MRF）模型来编码图像各个位置的图像元素之间的兼容性，并使用这个MRF模型与之前提出的Muse模型结合使用，以便减少Muse预测步骤数量，从而提高图像生成速度。</li>
<li>results: 通过使用MRF模型，可以在不输出质量下降的情况下，提高文本图像生成模型的计算效率，并且可以在不需要多次预测的情况下，提高图像生成速度。<details>
<summary>Abstract</summary>
Modern text-to-image generation models produce high-quality images that are both photorealistic and faithful to the text prompts. However, this quality comes at significant computational cost: nearly all of these models are iterative and require running inference multiple times with large models. This iterative process is needed to ensure that different regions of the image are not only aligned with the text prompt, but also compatible with each other. In this work, we propose a light-weight approach to achieving this compatibility between different regions of an image, using a Markov Random Field (MRF) model. This method is shown to work in conjunction with the recently proposed Muse model. The MRF encodes the compatibility among image tokens at different spatial locations and enables us to significantly reduce the required number of Muse prediction steps. Inference with the MRF is significantly cheaper, and its parameters can be quickly learned through back-propagation by modeling MRF inference as a differentiable neural-network layer. Our full model, SPEGTI, uses this proposed MRF model to speed up Muse by 1.5X with no loss in output image quality.
</details>
<details>
<summary>摘要</summary>
现代文本到图像生成模型可以生成高质量的图像，这些图像不仅具有高度的真实性，还具有与文本提示符的准确性。然而，这些高质量图像的生成需要大量的计算成本：大多数这些模型都是迭代的，需要多次运行推理。这种迭代过程是为了确保图像中的不同区域不仅与文本提示符吻合，而且也与其他区域吻合。在这种工作中，我们提出了一种轻量级的方法来实现图像中不同区域之间的吻合，使用Markov随机场（MRF）模型。这种方法可以与最近提出的Muse模型结合使用，并且可以在推理过程中减少Muse预测步骤的数量。MRF模型可以编码图像元素之间的空间位置的兼容性，从而使得推理过程中的计算成本得到了显著减少。我们的全模型SPEGTI使用这种提议的MRF模型，可以在推理过程中加速Muse的执行，而无需减少输出图像质量。
</details></li>
</ul>
<hr>
<h2 id="Pairing-interacting-protein-sequences-using-masked-language-modeling"><a href="#Pairing-interacting-protein-sequences-using-masked-language-modeling" class="headerlink" title="Pairing interacting protein sequences using masked language modeling"></a>Pairing interacting protein sequences using masked language modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07136">http://arxiv.org/abs/2308.07136</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bitbol-lab/diffpalm">https://github.com/bitbol-lab/diffpalm</a></li>
<li>paper_authors: Umberto Lupo, Damiano Sgarbossa, Anne-Florence Bitbol</li>
<li>for: The paper aims to predict which proteins interact together from their amino-acid sequences, which is an important task in protein structure prediction and function prediction.</li>
<li>methods: The paper develops a method called DiffPALM that leverages protein language models trained on multiple sequence alignments to pair interacting protein sequences. The method uses MSA Transformer and the EvoFormer module of AlphaFold to fill in masked amino acids in multiple sequence alignments and capture inter-chain coevolution.</li>
<li>results: The paper shows that DiffPALM outperforms existing coevolution-based pairing methods on difficult benchmarks of shallow multiple sequence alignments and achieves competitive performance with using orthology-based pairing. Additionally, DiffPALM improves the structure prediction of some eukaryotic protein complexes by AlphaFold-Multimer without significantly deteriorating any of those tested.Here is the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文目标是从蛋白质序列中预测哪些蛋白质相互作用，这是蛋白质结构预测和功能预测中非常重要的任务。</li>
<li>methods: 论文提出了一种名为DiffPALM的方法，它利用蛋白质语言模型在多个序列对上进行训练，以对相互作用的蛋白质序列进行对应。该方法使用MSA Transformer和AlphaFold中的EvoFormer模块来填充多个序列对中的遮盖氨基酸，并capture氨基酸之间的跨链共演化。</li>
<li>results: 论文表明，DiffPALM比现有的相互作用基于共演化的对应方法在困难的多个序列对上表现出色，并达到与使用同源蛋白质对应的竞争性表现。此外，DiffPALM还可以提高一些细胞蛋白质复合物的结构预测，无需进行较major fine-tuning。<details>
<summary>Abstract</summary>
Predicting which proteins interact together from amino-acid sequences is an important task. We develop a method to pair interacting protein sequences which leverages the power of protein language models trained on multiple sequence alignments, such as MSA Transformer and the EvoFormer module of AlphaFold. We formulate the problem of pairing interacting partners among the paralogs of two protein families in a differentiable way. We introduce a method called DiffPALM that solves it by exploiting the ability of MSA Transformer to fill in masked amino acids in multiple sequence alignments using the surrounding context. MSA Transformer encodes coevolution between functionally or structurally coupled amino acids. We show that it captures inter-chain coevolution, while it was trained on single-chain data, which means that it can be used out-of-distribution. Relying on MSA Transformer without fine-tuning, DiffPALM outperforms existing coevolution-based pairing methods on difficult benchmarks of shallow multiple sequence alignments extracted from ubiquitous prokaryotic protein datasets. It also outperforms an alternative method based on a state-of-the-art protein language model trained on single sequences. Paired alignments of interacting protein sequences are a crucial ingredient of supervised deep learning methods to predict the three-dimensional structure of protein complexes. DiffPALM substantially improves the structure prediction of some eukaryotic protein complexes by AlphaFold-Multimer, without significantly deteriorating any of those we tested. It also achieves competitive performance with using orthology-based pairing.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>预测蛋白质之间的互作是一项重要任务。我们开发了一种方法来对蛋白质序列进行互作对应，利用蛋白质语言模型在多个序列对alignment中学习的力量，如MSA transformer和AlphaFold中的EvoFormer模块。我们将对蛋白质家族中的参数进行分配的问题进行形式化。我们提出了一种名为DiffPALM的方法，它利用MSA transformer填充多个序列对alignment中的masked amino酸的能力，以获得更好的互作对应。MSA transformer编码了功能或结构相关的氨基酸之间的共演化，我们表明它可以在单链数据上进行填充，并且在多个序列对alignment中提取深层次的数据时表现出色。与现有的共演化基于方法相比，DiffPALM在具有深度多个序列对alignment的困难benchmark上表现出色，并且在使用不需要微调的情况下，也能够与一种基于state-of-the-art蛋白质语言模型的方法相比。对于一些细菌蛋白质复合物的三维结构预测，DiffPALM提供了显著改善，而不是显著下降任何已测试的结构。它还可以与基于orthology的对应方法相比。
</details></li>
</ul>
<hr>
<h2 id="Natural-Language-is-All-a-Graph-Needs"><a href="#Natural-Language-is-All-a-Graph-Needs" class="headerlink" title="Natural Language is All a Graph Needs"></a>Natural Language is All a Graph Needs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07134">http://arxiv.org/abs/2308.07134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang</li>
<li>for: 本研究旨在探讨whether large language models (LLMs) can replace graph neural networks (GNNs) as the foundation model for graphs.</li>
<li>methods: 本研究提出了InstructGLM（Instruction-finetuned Graph Language Model），通过自然语言指令设计了高度扩展的提示，并使用自然语言描述图像的几何结构和节点特征。</li>
<li>results: 研究结果表明，InstructGLM在ogbn-arxiv、Cora和PubMed datasets上都超过了所有竞争GNN基elines，这证明了我们的方法的有效性，同时也释放了大语言模型作为图机器学习基础模型的潜在性。<details>
<summary>Abstract</summary>
The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scalable prompts based on natural language instructions, and use natural language to describe the geometric structure and node features of the graph for instruction tuning an LLM to perform learning and inference on graphs in a generative manner. Our method exceeds all competitive GNN baselines on ogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of our method and sheds light on generative large language models as the foundation model for graph machine learning.
</details>
<details>
<summary>摘要</summary>
大型预训语言模型，如ChatGPT，的出现对人工智能多个研究领域产生了革命性的影响。基于Transformers的大型语言模型（LLMs）逐渐取代了CNNs和RNNs，统一了计算机视觉和自然语言处理的领域。相比于独立存在的数据，如图像、视频或文本，图表是一种包含丰富结构和关系信息的数据类型。同时，自然语言作为最有表达力的媒体，在描述复杂结构方面表现出色。然而，将图学问题 incorporated into the generative language modeling framework 的现有工作很有限。随着大语言模型的重要性不断增长，我们需要探索是否可以将LLMs作为图像学习的基础模型。在这篇论文中，我们提出了InstructGLM（基于自然语言指令的图语言模型），系统地设计了可扩展的自然语言指令，并使用自然语言来描述图形结构和节点特征。通过这种方式，我们使用大语言模型进行图像学习和推理，并达到了在ogbn-arxiv、Cora和PubMed数据集上的所有竞争GNN基elines的超越。这说明了我们的方法的有效性，并且推照到了大语言模型作为图像学习的基础模型。
</details></li>
</ul>
<hr>
<h2 id="Implementation-of-The-Future-of-Drug-Discovery-QuantumBased-Machine-Learning-Simulation-QMLS"><a href="#Implementation-of-The-Future-of-Drug-Discovery-QuantumBased-Machine-Learning-Simulation-QMLS" class="headerlink" title="Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS)"></a>Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08561">http://arxiv.org/abs/2308.08561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yew Kee Wong, Yifan Zhou, Yan Shing Liang, Haichuan Qiu, Yu Xi Wu, Bin He</li>
<li>For: 这篇论文主要目的是提出一种新的药物开发研究与发展（R&amp;D）阶段缩短方法，使其从原来的几年和十万美元降低到只需三到六个月和五万到八千美元。* Methods: 这篇论文使用的方法包括机器学习分子生成（MLMG）和量子 simulate（QS）。 MLMG 根据目标蛋白质的分子结构生成可能的吸引者，而 QS 根据反应和绑定效果从原始试剂中筛选出符合条件的分子。* Results: 这篇论文的结果是提出了一种基于机器学习和量子 simulate 的药物开发研究方法，可以在三到六个月和五万到八千美元的范围内缩短 R&amp;D 阶段，并且可以生成多达几十个前期临床试验准备的药物。<details>
<summary>Abstract</summary>
The Research & Development (R&D) phase of drug development is a lengthy and costly process. To revolutionize this process, we introduce our new concept QMLS to shorten the whole R&D phase to three to six months and decrease the cost to merely fifty to eighty thousand USD. For Hit Generation, Machine Learning Molecule Generation (MLMG) generates possible hits according to the molecular structure of the target protein while the Quantum Simulation (QS) filters molecules from the primary essay based on the reaction and binding effectiveness with the target protein. Then, For Lead Optimization, the resultant molecules generated and filtered from MLMG and QS are compared, and molecules that appear as a result of both processes will be made into dozens of molecular variations through Machine Learning Molecule Variation (MLMV), while others will only be made into a few variations. Lastly, all optimized molecules would undergo multiple rounds of QS filtering with a high standard for reaction effectiveness and safety, creating a few dozen pre-clinical-trail-ready drugs. This paper is based on our first paper, where we pitched the concept of machine learning combined with quantum simulations. In this paper we will go over the detailed design and framework of QMLS, including MLMG, MLMV, and QS.
</details>
<details>
<summary>摘要</summary>
研发（R&D）阶段是药品开发的 longest 和最昂贵的阶段。为了革新这个过程，我们介绍了一新的概念——QMLS，它可以缩短整个R&D阶段的时间至3-6个月，并将成本降至50-80万美元。在hit生成阶段，机器学习分子生成（MLMG）根据目标蛋白质分子结构生成可能的hit，而量子 simulations（QS）则从首轮试验中筛选出符合反应和结合效果的分子。在Lead优化阶段，由MLMG和QS生成的结果分子进行比较，并生成几十个分子变化through machine learning分子变化（MLMV），而其他分子则只生成几个变化。最后，所有优化的分子都会经过多轮QS筛选，以确保反应效果和安全性。通过这种方式，我们可以在几个月内生成数十个前期临床药物。这篇文章是我们之前的第一篇论文中提出的概念的详细设计和框架，包括MLMG、MLMV和QS。
</details></li>
</ul>
<hr>
<h2 id="A-Time-aware-tensor-decomposition-for-tracking-evolving-patterns"><a href="#A-Time-aware-tensor-decomposition-for-tracking-evolving-patterns" class="headerlink" title="A Time-aware tensor decomposition for tracking evolving patterns"></a>A Time-aware tensor decomposition for tracking evolving patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07126">http://arxiv.org/abs/2308.07126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christos Chatzis, Max Pfeffer, Pedro Lind, Evrim Acar</li>
<li>for: 这篇论文主要旨在提出一种基于PARAFAC2的时间 regularization方法，用于从时间数据中提取慢慢发展的模式。</li>
<li>methods: 该方法使用时间 regularization来防止时间点的重新排序，并使用PARAFAC2进行tensor factorization来捕捉时间数据中的下降模式。</li>
<li>results: 经过广泛的实验表明，tPARAFAC2能够准确地捕捉时间数据中的下降模式，并在表现上超过PARAFAC2和 coupling matrix factorization with temporal smoothness regularization。<details>
<summary>Abstract</summary>
Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regularization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化字符串。<</SYS>>时间演化数据集经常可以被视为高阶张量，其中一个模式是时间模式。而张量分解技术已经成功地捕捉了高阶数据集中的下面纹理，但是忽略了时间方面，允许时间点的重新排序。在最近的研究中，人们尝试将时间正则化添加到时间模式中，以解决这个问题。然而，现有的方法仍然不允许下面纹理在时间上发生变化（例如，脑中的空间变化，话题中的上下文变化）。在这篇论文中，我们提出了时间PARAFAC2（tPARAFAC2）：一种基于PARAFAC2的张量分解方法，带有时间正则化来提取时间演化的慢慢发展模式。通过对synthetic数据进行了广泛的实验，我们示出了tPARAFAC2可以准确地捕捉到时间演化中的下面纹理，并且比PARAFAC2和联合矩阵因子化 WITH 时间平滑正则化更好。
</details></li>
</ul>
<hr>
<h2 id="Active-Bird2Vec-Towards-End-to-End-Bird-Sound-Monitoring-with-Transformers"><a href="#Active-Bird2Vec-Towards-End-to-End-Bird-Sound-Monitoring-with-Transformers" class="headerlink" title="Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with Transformers"></a>Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07121">http://arxiv.org/abs/2308.07121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Rauch, Raphael Schwinger, Moritz Wirth, Bernhard Sick, Sven Tomforde, Christoph Scholz</li>
<li>for: 鸟叫声监测的终端学习shift，结合自动学习(SSL)和深度活动学习(DAL)。</li>
<li>methods: 利用 transformer 模型，直接处理原始音频数据，不需要传统的spectrogram转换。</li>
<li>results: 通过 SSL 生成高质量鸟叫声表示，可能加速环境变化评估和风力 farm 决策过程。同时，通过 DAL 利用鸟类 vocals 的多样性，减少人工标注数据的依赖，提高生物听音研究的可比性和可重现性。<details>
<summary>Abstract</summary>
We propose a shift towards end-to-end learning in bird sound monitoring by combining self-supervised (SSL) and deep active learning (DAL). Leveraging transformer models, we aim to bypass traditional spectrogram conversions, enabling direct raw audio processing. ActiveBird2Vec is set to generate high-quality bird sound representations through SSL, potentially accelerating the assessment of environmental changes and decision-making processes for wind farms. Additionally, we seek to utilize the wide variety of bird vocalizations through DAL, reducing the reliance on extensively labeled datasets by human experts. We plan to curate a comprehensive set of tasks through Huggingface Datasets, enhancing future comparability and reproducibility of bioacoustic research. A comparative analysis between various transformer models will be conducted to evaluate their proficiency in bird sound recognition tasks. We aim to accelerate the progression of avian bioacoustic research and contribute to more effective conservation strategies.
</details>
<details>
<summary>摘要</summary>
我们提议将学习方法转向终端学习（End-to-End Learning），将自我超级vised学习（Self-Supervised Learning）和深度活动学习（Deep Active Learning）相结合。通过使用转换器模型，我们希望直接处理原始音频数据，并不需要传统的spectrogram转换。活动鸟2Vec可以通过SSL生成高质量鸟叫表示，可能加速环境变化评估和风轮农场决策过程。此外，我们计划利用鸟类 vocals 的多样性，减少人工标注数据的依赖性。我们将使用Huggingface Datasets框架，实现未来比较性和可重复性的生物声学研究。我们计划对不同的转换器模型进行比较分析，以评估它们在鸟叫识别任务中的效果。我们希望通过加速鸟类生物声学研究，为更有效的保护策略做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Neural-radiance-fields-in-the-industrial-and-robotics-domain-applications-research-opportunities-and-use-cases"><a href="#Neural-radiance-fields-in-the-industrial-and-robotics-domain-applications-research-opportunities-and-use-cases" class="headerlink" title="Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases"></a>Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07118">http://arxiv.org/abs/2308.07118</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maftej/iisnerf">https://github.com/maftej/iisnerf</a></li>
<li>paper_authors: Eugen Šlapak, Enric Pardo, Matúš Dopiriak, Taras Maksymyuk, Juraj Gazda</li>
<li>for: 本研究旨在探讨基于提供训练图像的神经辐射场（NeRF）在各种工业领域的应用潜力，并提供未来研究方向。</li>
<li>methods: 本研究使用NeRF来实现3D场景表示，并在视频压缩和3D动作估计等领域进行证明。</li>
<li>results: 研究显示，使用NeRF进行视频压缩可以达到48%和74%的压缩率提升，而在3D动作估计中，使用D-NeRF实现的 disparity map PSNR值达到23 dB，SSIM值为0.97。<details>
<summary>Abstract</summary>
The proliferation of technologies, such as extended reality (XR), has increased the demand for high-quality three-dimensional (3D) graphical representations. Industrial 3D applications encompass computer-aided design (CAD), finite element analysis (FEA), scanning, and robotics. However, current methods employed for industrial 3D representations suffer from high implementation costs and reliance on manual human input for accurate 3D modeling. To address these challenges, neural radiance fields (NeRFs) have emerged as a promising approach for learning 3D scene representations based on provided training 2D images. Despite a growing interest in NeRFs, their potential applications in various industrial subdomains are still unexplored. In this paper, we deliver a comprehensive examination of NeRF industrial applications while also providing direction for future research endeavors. We also present a series of proof-of-concept experiments that demonstrate the potential of NeRFs in the industrial domain. These experiments include NeRF-based video compression techniques and using NeRFs for 3D motion estimation in the context of collision avoidance. In the video compression experiment, our results show compression savings up to 48\% and 74\% for resolutions of 1920x1080 and 300x168, respectively. The motion estimation experiment used a 3D animation of a robotic arm to train Dynamic-NeRF (D-NeRF) and achieved an average peak signal-to-noise ratio (PSNR) of disparity map with the value of 23 dB and an structural similarity index measure (SSIM) 0.97.
</details>
<details>
<summary>摘要</summary>
“技术的普及，如扩展现实（XR），已经提高了高品质三维图形的需求。工业三维应用包括计算机支持设计（CAD）、finite element分析（FEA）、扫描和机器人。然而，现有的工业三维表示方法受到高实施成本和人工输入的假设，以获得准确的三维模型。为了解决这些挑战，神经辐射场（NeRF）已经出现为了学习基于提供训练图像的三维场景表示。尽管NeRF在不同领域产生了增长的兴趣，但它们在不同的工业子领域的潜在应用还未得到了足够的探索。在这篇论文中，我们提供了对NeRF工业应用的全面评估，并为未来研究提供方向。我们还进行了一系列的证明性实验，以示NeRF在工业领域的潜在应用。这些实验包括基于NeRF的视频压缩技术和使用NeRF进行3D运动估计，以避免碰撞。在视频压缩实验中，我们得到了1920x1080和300x168的分辨率下的压缩率为48%和74%。在运动估计实验中，我们使用了一个3D动画的机械臂进行训练，并获得了23 dB的平均峰值信号噪声比（PSNR）和0.97的结构相似度指标（SSIM）。”
</details></li>
</ul>
<hr>
<h2 id="iSTFTNet2-Faster-and-More-Lightweight-iSTFT-Based-Neural-Vocoder-Using-1D-2D-CNN"><a href="#iSTFTNet2-Faster-and-More-Lightweight-iSTFT-Based-Neural-Vocoder-Using-1D-2D-CNN" class="headerlink" title="iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN"></a>iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07117">http://arxiv.org/abs/2308.07117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Shogo Seki</li>
<li>for: 高速、轻量级、高精度的语音合成</li>
<li>methods: 使用快速、轻量级的1D CNN作为基础网络，并将一些神经过程替换为iSTFT，以提高速度和精度。</li>
<li>results: iSTFTNet2比iSTFTNet更快、更轻量级，且音质相对保持不变。<details>
<summary>Abstract</summary>
The inverse short-time Fourier transform network (iSTFTNet) has garnered attention owing to its fast, lightweight, and high-fidelity speech synthesis. It obtains these characteristics using a fast and lightweight 1D CNN as the backbone and replacing some neural processes with iSTFT. Owing to the difficulty of a 1D CNN to model high-dimensional spectrograms, the frequency dimension is reduced via temporal upsampling. However, this strategy compromises the potential to enhance the speed. Therefore, we propose iSTFTNet2, an improved variant of iSTFTNet with a 1D-2D CNN that employs 1D and 2D CNNs to model temporal and spectrogram structures, respectively. We designed a 2D CNN that performs frequency upsampling after conversion in a few-frequency space. This design facilitates the modeling of high-dimensional spectrograms without compromising the speed. The results demonstrated that iSTFTNet2 made iSTFTNet faster and more lightweight with comparable speech quality. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/.
</details>
<details>
<summary>摘要</summary>
它的快速、轻量级和高精度语音合成使得倒时傅立卷网络（iSTFTNet）受到了关注。它使用了快速和轻量级的1D CNN作为核心，并将一些神经过程替换为iSTFT。由于1D CNNDifficulty modeling高维spectrograms，因此在频率维度上做了时间upsampling。然而，这种策略会减少速度的潜在提高。因此，我们提出了iSTFTNet2，它是iSTFTNet的改进版本，使用1D-2D CNN来模型时间和spectrogram结构。我们设计了一个2D CNN，它在几个频率空间中进行频率upsampling。这种设计可以模型高维spectrograms，而不会减少速度。结果表明，iSTFTNet2使得iSTFTNet更快速和轻量级，并且与相同的语音质量相对。音频样本可以在https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/上获取。
</details></li>
</ul>
<hr>
<h2 id="Ada-QPacknet-–-adaptive-pruning-with-bit-width-reduction-as-an-efficient-continual-learning-method-without-forgetting"><a href="#Ada-QPacknet-–-adaptive-pruning-with-bit-width-reduction-as-an-efficient-continual-learning-method-without-forgetting" class="headerlink" title="Ada-QPacknet – adaptive pruning with bit width reduction as an efficient continual learning method without forgetting"></a>Ada-QPacknet – adaptive pruning with bit width reduction as an efficient continual learning method without forgetting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07939">http://arxiv.org/abs/2308.07939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcin Pietroń, Dominik Żurek, Kamil Faber, Roberto Corizzo</li>
<li>for: 这篇论文主要针对各种各样的动态和复杂环境下的Continual Learning（CL）问题。</li>
<li>methods: 该论文提出了一种基于架构的CL方法，称为Ada-QPacknet，它通过减少模型大小来实现CL。该方法使用有效的线性和非线性归一化方法来减少模型的权重的位数据类型。</li>
<li>results: 根据实验结果，hybrid 8和4位归一化的混合归一化方法可以达到类似于浮点子网络的准确率，而且在任务和类增量场景中比大多数CL策略表现更好。<details>
<summary>Abstract</summary>
Continual Learning (CL) is a process in which there is still huge gap between human and deep learning model efficiency. Recently, many CL algorithms were designed. Most of them have many problems with learning in dynamic and complex environments. In this work new architecture based approach Ada-QPacknet is described. It incorporates the pruning for extracting the sub-network for each task. The crucial aspect in architecture based CL methods is theirs capacity. In presented method the size of the model is reduced by efficient linear and nonlinear quantisation approach. The method reduces the bit-width of the weights format. The presented results shows that hybrid 8 and 4-bit quantisation achieves similar accuracy as floating-point sub-network on a well-know CL scenarios. To our knowledge it is the first CL strategy which incorporates both compression techniques pruning and quantisation for generating task sub-networks. The presented algorithm was tested on well-known episode combinations and compared with most popular algorithms. Results show that proposed approach outperforms most of the CL strategies in task and class incremental scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Age-Stratified-Differences-in-Morphological-Connectivity-Patterns-in-ASD-An-sMRI-and-Machine-Learning-Approach"><a href="#Age-Stratified-Differences-in-Morphological-Connectivity-Patterns-in-ASD-An-sMRI-and-Machine-Learning-Approach" class="headerlink" title="Age-Stratified Differences in Morphological Connectivity Patterns in ASD: An sMRI and Machine Learning Approach"></a>Age-Stratified Differences in Morphological Connectivity Patterns in ASD: An sMRI and Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07356">http://arxiv.org/abs/2308.07356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gokul Manoj, Sandeep Singh Sengar, Jac Fredo Agastinose Ronickom</li>
<li>for: 本研究的目的是用 morphological features (MF) 和 morphological connectivity features (MCF) 来分类 autism spectrum disorder (ASD)，并比较不同年龄组的分类效果。</li>
<li>methods: 研究使用了 two publicly available databases, ABIDE-I 和 ABIDE-II, 获取了 structural magnetic resonance imaging (sMRI) 数据，并对数据进行了标准化处理。然后，将数据分割成 148 个不同区域，根据 Destrieux  Atlases，并从每个区域提取了面积、厚度、体积和平均弯曲信息。使用了统计学 t-test (p&lt;0.05) 来选择特征，然后使用 random forest (RF) 分类器进行训练。</li>
<li>results: 研究结果表明，6-11 岁的年龄组的表现最高，然后是 6-18 岁和 11-18 岁的年龄组。总的来说，MCF 与 RF 在 6-11 岁的年龄组中表现最好，其中的准确率、 F1 分数、回归率和精度分别为 75.8%、83.1%、86% 和 80.4%。结论：本研究因此表明，使用 morphological connectivity 和年龄相关的诊断模型可以有效地分类 ASD。<details>
<summary>Abstract</summary>
Purpose: Age biases have been identified as an essential factor in the diagnosis of ASD. The objective of this study was to compare the effect of different age groups in classifying ASD using morphological features (MF) and morphological connectivity features (MCF). Methods: The structural magnetic resonance imaging (sMRI) data for the study was obtained from the two publicly available databases, ABIDE-I and ABIDE-II. We considered three age groups, 6 to 11, 11 to 18, and 6 to 18, for our analysis. The sMRI data was pre-processed using a standard pipeline and was then parcellated into 148 different regions according to the Destrieux atlas. The area, thickness, volume, and mean curvature information was then extracted for each region which was used to create a total of 592 MF and 10,878 MCF for each subject. Significant features were identified using a statistical t-test (p<0.05) which was then used to train a random forest (RF) classifier. Results: The results of our study suggested that the performance of the 6 to 11 age group was the highest, followed by the 6 to 18 and 11 to 18 ages in both MF and MCF. Overall, the MCF with RF in the 6 to 11 age group performed better in the classification than the other groups and produced an accuracy, F1 score, recall, and precision of 75.8%, 83.1%, 86%, and 80.4%, respectively. Conclusion: Our study thus demonstrates that morphological connectivity and age-related diagnostic model could be an effective approach to discriminating ASD.
</details>
<details>
<summary>摘要</summary>
目的：识别自适应发育障碍（ASD）的年龄因素有所重要。本研究的目标是比较不同年龄组的ASD诊断使用形态特征（MF）和形态连接特征（MCF）的效果。方法：我们使用ABIDE-I和ABIDE-II两个公共数据库获取了structural magnetic resonance imaging（sMRI）数据。我们分为三个年龄组：6-11岁、11-18岁和6-18岁进行分析。sMRI数据经过标准化处理后，使用Destrieux Atlas将数据分割成148个区域。然后提取每个区域的面积、厚度、体积和平均曲率信息，共计592个MF和10878个MCF。使用统计t检测test（p<0.05）标识特征，然后使用随机森林（RF）分类器进行训练。结果：我们的研究发现，6-11岁年龄组的表现最高，其次是6-18岁和11-18岁年龄组。总的来说，MCF与RF在6-11岁年龄组中表现较好，其准确率、F1分数、报告率和准确率分别为75.8%、83.1%、86%和80.4%。结论：因此，我们的研究表明，形态连接和年龄相关的诊断模型可以有效地识别ASD。
</details></li>
</ul>
<hr>
<h2 id="InsTag-Instruction-Tagging-for-Analyzing-Supervised-Fine-tuning-of-Large-Language-Models"><a href="#InsTag-Instruction-Tagging-for-Analyzing-Supervised-Fine-tuning-of-Large-Language-Models" class="headerlink" title="#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"></a>#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07074">http://arxiv.org/abs/2308.07074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ofa-sys/instag">https://github.com/ofa-sys/instag</a></li>
<li>paper_authors: Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, Jingren Zhou</li>
<li>for: 这个论文的目的是提高基础模型的命令遵从能力，并通过量化分析定义命令多样性和复杂性。</li>
<li>methods: 本文使用了一种名为InsTag的开放集 Fine-grained tagger，通过Semantics和Intention来标签SFT数据集中的样本，并定义命令多样性和复杂性。</li>
<li>results: 根据MT-Bench的评价，使用InsTag选择的6K多样性和复杂性的样本进行微调，可以使基础模型的命令遵从能力得到显著提高。<details>
<summary>Abstract</summary>
Foundation language models obtain the instruction-following ability through supervised fine-tuning (SFT). Diversity and complexity are considered critical factors of a successful SFT dataset, while their definitions remain obscure and lack quantitative analyses. In this work, we propose InsTag, an open-set fine-grained tagger, to tag samples within SFT datasets based on semantics and intentions and define instruction diversity and complexity regarding tags. We obtain 6.6K tags to describe comprehensive user queries. Then we analyze popular open-sourced SFT datasets and find that the model ability grows with more diverse and complex data. Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data. The resulting models, TagLM, outperform open-source models based on considerably larger SFT data evaluated by MT-Bench, echoing the importance of query diversity and complexity. We open-source InsTag in https://github.com/OFA-Sys/InsTag.
</details>
<details>
<summary>摘要</summary>
基于监督精度（SFT）的基础语言模型获得了指令遵循能力，但是关键因素如多样性和复杂性的定义尚未得到准确的量化分析。在这项工作中，我们提出了InsTag，一个开放集成细词标注器，用于在SFT数据集中标注样本基于含义和目标，并定义指令多样性和复杂性的标签。我们获得了6.6K个标签来描述用户查询的全面性。然后我们分析了一些常用的开源SFT数据集，发现模型能力随着数据集的多样性和复杂性增加而增长。基于这一观察，我们提出了基于InsTag的数据选择器，用于从开源数据集中选择6K个多样性和复杂性最高的样本，并在InsTag-选择的数据上精度 fine-tune 模型。得到的模型TagLM在MT-Bench上评估得到了较大的SFT数据集的较好的性能，证明了查询多样性和复杂性的重要性。我们将InsTag开源在https://github.com/OFA-Sys/InsTag。
</details></li>
</ul>
<hr>
<h2 id="Machine-Unlearning-Solutions-and-Challenges"><a href="#Machine-Unlearning-Solutions-and-Challenges" class="headerlink" title="Machine Unlearning: Solutions and Challenges"></a>Machine Unlearning: Solutions and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07061">http://arxiv.org/abs/2308.07061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia</li>
<li>for: 本研究旨在Addressing privacy and security concerns in machine learning by selectively removing specific training data points’ influence on trained models.</li>
<li>methods: 本研究 categorizes existing machine unlearning research into two types: exact unlearning和approximate unlearning, and reviews state-of-the-art solutions with their advantages and limitations.</li>
<li>results: 本研究提出了未来研究方向，并鼓励研究人员通过Addressing open problems to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning.<details>
<summary>Abstract</summary>
Machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy violations, security breaches, and performance deterioration. To address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. This paper provides a comprehensive taxonomy and analysis of machine unlearning research. We categorize existing research into exact unlearning that algorithmically removes data influence entirely and approximate unlearning that efficiently minimizes influence through limited parameter updates. By reviewing the state-of-the-art solutions, we critically discuss their advantages and limitations. Furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning. This paper provides researchers with a roadmap of open problems, encouraging impactful contributions to address real-world needs for selective data removal.
</details>
<details>
<summary>摘要</summary>
Translation notes:* " Machine learning models" is translated as "机器学习模型" (jī zhī xué xí mó delè)* "inadvertently" is translated as "无意" (wú yì)* "sensitive, unauthorized, or malicious" is translated as "敏感、未授权或黑客" (mǐn gǎn, wèi shèng qián, hēi kè)* "privacy violations" is translated as "隐私侵犯" (yǐn wèi qiāng fāng)* "security breaches" is translated as "安全泄露" (ān què lù)* "performance deterioration" is translated as "性能下降" (xìng néng xià gōng)* "machine unlearning" is translated as "机器忘记" (jī zhī wàng jī)* "selectively remove" is translated as "选择性地移除" (选择性地移除)* "specific training data points" is translated as "特定训练数据点" (特定训练数据点)* "influence" is translated as "影响" (yìng xiǎng)* "entirely" is translated as "完全" (quán zhèng)* "efficiently" is translated as "高效" (gāo yù)* "minimizes" is translated as "最小化" (zuì xiǎo hóu)* "limited parameter updates" is translated as "有限参数更新" (yǒu xiàn paramètres jīn gòu)* "state-of-the-art solutions" is translated as "现状的解决方案" (xiàn zhèng de jiě jīng fāng àn)* "advantages and limitations" is translated as "优点和缺点" (yòu dòng hé qiòng diǎn)* "future directions" is translated as "未来方向" (wèi lāi fāng dìng)* "trustworthy and adaptive machine learning" is translated as "可靠性和适应性机器学习" (kě zuò xìng yì jī zhī xué xí)* "open problems" is translated as "开放问题" (kāi fàng wèn tí)* "impactful contributions" is translated as "有影响的贡献" (yǒu yìng xiǎng de gōng jìn)
</details></li>
</ul>
<hr>
<h2 id="Diagnosis-of-Scalp-Disorders-using-Machine-Learning-and-Deep-Learning-Approach-–-A-Review"><a href="#Diagnosis-of-Scalp-Disorders-using-Machine-Learning-and-Deep-Learning-Approach-–-A-Review" class="headerlink" title="Diagnosis of Scalp Disorders using Machine Learning and Deep Learning Approach – A Review"></a>Diagnosis of Scalp Disorders using Machine Learning and Deep Learning Approach – A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07052">http://arxiv.org/abs/2308.07052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishabh Tiwari, Jatin Moolchandani, Shamla Mantri</li>
<li>for: 这个研究是为了提高皮肤病诊断的准确率和效率。</li>
<li>methods: 这个研究使用了深度学习模型，包括CNN和FCN，以及一个APP来识别皮肤和scalp疾病。</li>
<li>results: 研究结果表明，使用深度学习模型可以准确地识别皮肤和scalp疾病，其中最高准确率达97.41%-99.09%。<details>
<summary>Abstract</summary>
The morbidity of scalp diseases is minuscule compared to other diseases, but the impact on the patient's life is enormous. It is common for people to experience scalp problems that include Dandruff, Psoriasis, Tinea-Capitis, Alopecia and Atopic-Dermatitis. In accordance with WHO research, approximately 70% of adults have problems with their scalp. It has been demonstrated in descriptive research that hair quality is impaired by impaired scalp, but these impacts are reversible with early diagnosis and treatment. Deep Learning advances have demonstrated the effectiveness of CNN paired with FCN in diagnosing scalp and skin disorders. In one proposed Deep-Learning-based scalp inspection and diagnosis system, an imaging microscope and a trained model are combined with an app that classifies scalp disorders accurately with an average precision of 97.41%- 99.09%. Another research dealt with classifying the Psoriasis using the CNN with an accuracy of 82.9%. As part of another study, an ML based algorithm was also employed. It accurately classified the healthy scalp and alopecia areata with 91.4% and 88.9% accuracy with SVM and KNN algorithms. Using deep learning models to diagnose scalp related diseases has improved due to advancements i computation capabilities and computer vision, but there remains a wide horizon for further improvements.
</details>
<details>
<summary>摘要</summary>
scalp病的感染率相对其他疾病较低，但对病人生活的影响却很大。人们常常会经历头皮问题，包括痤疮、 Psoriasis、脚抄螯、脱发和过敏性皮肤炎。根据Who的研究，大约70%的成年人都有头皮问题。研究表明，损害的头皮质量可以通过早期诊断和治疗来改善，但这些影响可以逆转。深度学习技术的发展使得 CNN 和 FCN 的结合可以准确地诊断头皮和皮肤疾病。一种提议的深度学习基于的头皮检查和诊断系统使用了一个升级的探针和训练模型，并与一个APP结合，可以准确地分类头皮疾病，其精度为97.41%-99.09%。另一项研究用到 CNN 分类痤疮，精度为82.9%。另外一项研究使用 ML 算法，可以准确地分类健康的头皮和脱发症，精度分别为91.4%和88.9%。使用深度学习模型诊断头皮相关疾病，因计算能力和计算视觉的进步而得到改善，但还有很大的发展空间。
</details></li>
</ul>
<hr>
<h2 id="Fourier-neural-operator-for-learning-solutions-to-macroscopic-traffic-flow-models-Application-to-the-forward-and-inverse-problems"><a href="#Fourier-neural-operator-for-learning-solutions-to-macroscopic-traffic-flow-models-Application-to-the-forward-and-inverse-problems" class="headerlink" title="Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems"></a>Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07051">http://arxiv.org/abs/2308.07051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bilal Thonnam Thodi, Sai Venkata Ramana Ambadipudi, Saif Eddin Jabari</li>
<li>for: 本研究使用深度学习方法解决非线性散射方程的问题，具体是用神经网络扩散算法来学习宏观交通流模型中的全部交通状态。</li>
<li>methods: 本研究使用的是一种名为 физи学 Informed Fourier Neural Operator（π-FNO）的神经网络算法，该算法在训练过程中添加了物理损失函数来补做冲击预测，以提高冲击预测的准确性。</li>
<li>results: 实验结果表明，使用本研究的神经网络算法可以高度准确地预测环路交通网络和城市信号灯控制下的density dynamics，并且可以适应不同的车辆队列分布和多个交通信号周期。此外，研究还发现，使用physics regularizer可以帮助学习长期交通状态的预测，特别是在periodic boundary data的情况下。<details>
<summary>Abstract</summary>
Deep learning methods are emerging as popular computational tools for solving forward and inverse problems in traffic flow. In this paper, we study a neural operator framework for learning solutions to nonlinear hyperbolic partial differential equations with applications in macroscopic traffic flow models. In this framework, an operator is trained to map heterogeneous and sparse traffic input data to the complete macroscopic traffic state in a supervised learning setting. We chose a physics-informed Fourier neural operator ($\pi$-FNO) as the operator, where an additional physics loss based on a discrete conservation law regularizes the problem during training to improve the shock predictions. We also propose to use training data generated from random piecewise constant input data to systematically capture the shock and rarefied solutions. From experiments using the LWR traffic flow model, we found superior accuracy in predicting the density dynamics of a ring-road network and urban signalized road. We also found that the operator can be trained using simple traffic density dynamics, e.g., consisting of $2-3$ vehicle queues and $1-2$ traffic signal cycles, and it can predict density dynamics for heterogeneous vehicle queue distributions and multiple traffic signal cycles $(\geq 2)$ with an acceptable error. The extrapolation error grew sub-linearly with input complexity for a proper choice of the model architecture and training data. Adding a physics regularizer aided in learning long-term traffic density dynamics, especially for problems with periodic boundary data.
</details>
<details>
<summary>摘要</summary>
深度学习方法在交通流动中应用得更加广泛，用于解决前向和反向问题。在这篇论文中，我们研究了一种神经运算框架，用于学习解决非线性偏微分方程的解。在这个框架中，一个运算被训练来将各种不同和稀缺的交通输入数据映射到完整的宏观交通状态中。我们选择了一种physics-informed Fourier neural operator（$\pi$-FNO）作为运算，其中添加了物理损失，以便在训练过程中进行辐射预测。我们还提议使用来自随机划分输入数据的训练数据，以系统地捕捉冲击和稀缺解。在使用LWR交通流模型的实验中，我们发现了在密度动力学中的高精度预测，特别是在环路网络和城市控制措施下。我们还发现，运算可以通过简单的交通密度动力学，例如由2-3辆汽车队列和1-2个交通信号循环组成的，来预测密度动力学。并且可以在多个交通信号循环和不同车辆队列分布下进行预测，并且误差在输入复杂性增加时呈线性增长。添加物理正则化有助于学习长期交通密度动力学，特别是在 Periodic boundary data 下。
</details></li>
</ul>
<hr>
<h2 id="UIPC-MF-User-Item-Prototype-Connection-Matrix-Factorization-for-Explainable-Collaborative-Filtering"><a href="#UIPC-MF-User-Item-Prototype-Connection-Matrix-Factorization-for-Explainable-Collaborative-Filtering" class="headerlink" title="UIPC-MF: User-Item Prototype Connection Matrix Factorization for Explainable Collaborative Filtering"></a>UIPC-MF: User-Item Prototype Connection Matrix Factorization for Explainable Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07048">http://arxiv.org/abs/2308.07048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Pan, Von-Wun Soo</li>
<li>for: 提供可解释的用户行为推荐（Recommending items to potentially interested users with explainable user behavior）</li>
<li>methods: 使用prototype-based matrix factorization方法（UIPC-MF），用户和Item分别与一组prototype相关联，以提高推荐的可解释性。</li>
<li>results: 在三个 dataset 上比基eline方法高效，并且提供更好的透明度（Hit Ratio和Normalized Discounted Cumulative Gain）。<details>
<summary>Abstract</summary>
Recommending items to potentially interested users has been an important commercial task that faces two main challenges: accuracy and explainability. While most collaborative filtering models rely on statistical computations on a large scale of interaction data between users and items and can achieve high performance, they often lack clear explanatory power. We propose UIPC-MF, a prototype-based matrix factorization method for explainable collaborative filtering recommendations. In UIPC-MF, both users and items are associated with sets of prototypes, capturing general collaborative attributes. To enhance explainability, UIPC-MF learns connection weights that reflect the associative relations between user and item prototypes for recommendations. UIPC-MF outperforms other prototype-based baseline methods in terms of Hit Ratio and Normalized Discounted Cumulative Gain on three datasets, while also providing better transparency.
</details>
<details>
<summary>摘要</summary>
推荐预测已成为商业中的一个重要任务，面临两大挑战：准确率和可解释性。大多数共同推荐模型基于大规模的用户和项目互动数据进行统计计算，可以达到高性能，但往往缺乏明确的解释力。我们提出了UIPC-MF，一种基于Matrix Factorization的原型基于方法，用于可解释的共同推荐。在UIPC-MF中，用户和项目都关联有一组概念prototype，捕捉用户和项目之间的共同特征。为了增强可解释性，UIPC-MF学习用户和项目概念之间的关联关系，以便为推荐提供更好的透明性。UIPC-MF在三个数据集上相比其他原型基本方法而言，有较高的 Hit Ratio 和 Normalized Discounted Cumulative Gain，同时也提供更好的透明性。
</details></li>
</ul>
<hr>
<h2 id="No-Regularization-is-Needed-An-Efficient-and-Effective-Model-for-Incomplete-Label-Distribution-Learning"><a href="#No-Regularization-is-Needed-An-Efficient-and-Effective-Model-for-Incomplete-Label-Distribution-Learning" class="headerlink" title="No Regularization is Needed: An Efficient and Effective Model for Incomplete Label Distribution Learning"></a>No Regularization is Needed: An Efficient and Effective Model for Incomplete Label Distribution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07047">http://arxiv.org/abs/2308.07047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Songcan Chen</li>
<li>for: This paper focuses on addressing the problem of Incomplete Label Distribution Learning (InLDL), where the labels are incomplete or unobserved for some samples.</li>
<li>methods: The authors propose a new method that uses the prior of label distribution to solve the InLDL problem without any explicit regularization. They define a weighted empirical risk and derive upper bounds to reveal the implicit regularization role of weighting.</li>
<li>results: The proposed method has four advantages: 1) it is model selection free, 2) it has a closed form solution and is easy to implement, 3) it has linear computational complexity, and 4) it is competitive with state-of-the-art methods even without any explicit regularization.<details>
<summary>Abstract</summary>
Label Distribution Learning (LDL) assigns soft labels, a.k.a. degrees, to a sample. In reality, it is always laborious to obtain complete degrees, giving birth to the Incomplete LDL (InLDL). However, InLDL often suffers from performance degeneration. To remedy it, existing methods need one or more explicit regularizations, leading to burdensome parameter tuning and extra computation. We argue that label distribution itself may provide useful prior, when used appropriately, the InLDL problem can be solved without any explicit regularization. In this paper, we offer a rational alternative to use such a prior. Our intuition is that large degrees are likely to get more concern, the small ones are easily overlooked, whereas the missing degrees are completely neglected in InLDL. To learn an accurate label distribution, it is crucial not to ignore the small observed degrees but to give them properly large weights, while gradually increasing the weights of the missing degrees. To this end, we first define a weighted empirical risk and derive upper bounds between the expected risk and the weighted empirical risk, which reveals in principle that weighting plays an implicit regularization role. Then, by using the prior of degrees, we design a weighted scheme and verify its effectiveness. To sum up, our model has four advantages, it is 1) model selection free, as no explicit regularization is imposed; 2) with closed form solution (sub-problem) and easy-to-implement (a few lines of codes); 3) with linear computational complexity in the number of samples, thus scalable to large datasets; 4) competitive with state-of-the-arts even without any explicit regularization.
</details>
<details>
<summary>摘要</summary>
Label Distribution Learning (LDL)  assigns 软标签，即学习度，到一个样本上。在实际应用中，通常难以获得完整的学习度，从而产生了不完整的LDL（InLDL）问题。然而，InLDL经常会导致性能下降。为了解决这个问题，现有方法通常需要一或多个显式正则化，从而增加参数调整的复杂性和计算量。我们认为标签分布本身可以提供有用的先验知识，当用于适当的情况时，InLDL问题可以解决无需显式正则化。在这篇论文中，我们提出了一种有理的方法，使用这种先验知识来解决InLDL问题。我们的假设是，大的学习度更有可能得到更多的注意力，小的学习度容易被忽略，而缺失的学习度完全被InLDL忽略。为了学习准确的标签分布，非常重要不要忽略小 observed 的学习度，而是给它们分配正确的大小，同时逐渐增加缺失的学习度的权重。我们首先定义一个权重 empirical risk，并 deriv 上下文中的预期风险和权重 empirical risk 之间的Upper bound，这表明了权重在本质上扮演了隐式正则化的角色。然后，我们使用学习度的先验知识来设计一种权重方案，并证明其效果。总之，我们的模型具有以下四个优点：1) 无需显式正则化，因为不需要在数据上添加任何正则化项；2) 具有关闭式解决方案和易于实现（只需一些代码）；3) 计算复杂度为数据集的线性时间，因此可扩展到大型数据集；4) 可与当前的状态艺技相比，甚至没有任何显式正则化。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-Flow-Networks"><a href="#Bayesian-Flow-Networks" class="headerlink" title="Bayesian Flow Networks"></a>Bayesian Flow Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07037">http://arxiv.org/abs/2308.07037</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stefanradev93/BayesFlow">https://github.com/stefanradev93/BayesFlow</a></li>
<li>paper_authors: Alex Graves, Rupesh Kumar Srivastava, Timothy Atkinson, Faustino Gomez</li>
<li>for: 本研究旨在提出一种新的生成模型—权当流网络（BFN），它通过bayesian推理在噪声数据样本的指导下修改参数集中的独立分布，然后将这些分布作为输入传递给神经网络，从而生成第二个相互关联的分布。</li>
<li>methods: 本研究使用了权当流网络（BFN），它们的生成过程类似于反射模型的逆过程，但是更加简单，不需要前向过程。研究者还 derive了离散和连续时间的损失函数，以及批量生成过程。</li>
<li>results: 实验表明，BFNs可以在 dynamical binarized MNIST 和 CIFAR-10 图像模型任务上 achieve 竞争力的 log-likelihood，并且在 text8 字符级语言模型任务上超越了所有已知的杂分 diffusion 模型。<details>
<summary>Abstract</summary>
This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no restrictions on the network architecture. In our experiments BFNs achieve competitive log-likelihoods for image modelling on dynamically binarized MNIST and CIFAR-10, and outperform all known discrete diffusion models on the text8 character-level language modelling task.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="S3IM-Stochastic-Structural-SIMilarity-and-Its-Unreasonable-Effectiveness-for-Neural-Fields"><a href="#S3IM-Stochastic-Structural-SIMilarity-and-Its-Unreasonable-Effectiveness-for-Neural-Fields" class="headerlink" title="S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields"></a>S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07032">http://arxiv.org/abs/2308.07032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/madaoer/s3im_nerf">https://github.com/madaoer/s3im_nerf</a></li>
<li>paper_authors: Zeke Xie, Xindi Yang, Yujie Yang, Qi Sun, Yixiang Jiang, Haoran Wang, Yunfeng Cai, Mingming Sun</li>
<li>For: The paper aims to improve the quality of Neural Radiance Field (NeRF) and related neural field methods for novel-view image synthesis and surface reconstruction tasks.* Methods: The paper introduces a nonlocal multiplex training paradigm for NeRF and related neural field methods, using a novel Stochastic Structural SIMilarity (S3IM) loss that processes multiple data points as a whole set instead of processing multiple inputs independently.* Results: The paper shows that the proposed S3IM loss leads to significant improvements in quality metrics for NeRF and neural surface representation, particularly for difficult tasks such as novel view synthesis and surface reconstruction. The improvements are robust even with sparse inputs, corrupted images, and dynamic scenes.<details>
<summary>Abstract</summary>
Recently, Neural Radiance Field (NeRF) has shown great success in rendering novel-view images of a given scene by learning an implicit representation with only posed RGB images. NeRF and relevant neural field methods (e.g., neural surface representation) typically optimize a point-wise loss and make point-wise predictions, where one data point corresponds to one pixel. Unfortunately, this line of research failed to use the collective supervision of distant pixels, although it is known that pixels in an image or scene can provide rich structural information. To the best of our knowledge, we are the first to design a nonlocal multiplex training paradigm for NeRF and relevant neural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss that processes multiple data points as a whole set instead of process multiple inputs independently. Our extensive experiments demonstrate the unreasonable effectiveness of S3IM in improving NeRF and neural surface representation for nearly free. The improvements of quality metrics can be particularly significant for those relatively difficult tasks: e.g., the test MSE loss unexpectedly drops by more than 90% for TensoRF and DVGO over eight novel view synthesis tasks; a 198% F-score gain and a 64% Chamfer $L_{1}$ distance reduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is consistently robust even with sparse inputs, corrupted images, and dynamic scenes.
</details>
<details>
<summary>摘要</summary>
最近，神经辐射场（NeRF）已经取得了大成功，通过学习含义表示的唯一RGB图像来生成新视图图像。NeRF和相关的神经场方法（例如神经表面表示）通常通过点级损失来优化和预测点级数据，而这些数据点与每个像素相对应。然而，这一线索的研究忽略了远程像素的共同监督，尽管知道图像或场景中的像素可以提供丰富的结构信息。据我们所知，我们是第一个设计非本地多重训练方法via一种新的随机结构相似性（S3IM）损失，该损失处理多个数据点作为整体而不是独立处理多个输入。我们的广泛实验表明S3IM在改进NeRF和神经表面表示方法方面具有不可思议的效果，并且这些改进的质量指标可以特别显著，例如在八个新视图合成任务中，测试MSE损失意外下降了More than 90%  дляTensoRF和DVGO; NeuS在八个表面重建任务中获得了198%的F-score提升和64%的L1距离减少。此外，S3IM具有对于稀缺输入、损坏图像和动态场景的一致性。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-Physics-Informed-Neural-Network-for-the-Forward-and-Inverse-Simulation-of-Engineered-Nano-particles-Mobility-in-a-Contaminated-Aquifer"><a href="#Bayesian-Physics-Informed-Neural-Network-for-the-Forward-and-Inverse-Simulation-of-Engineered-Nano-particles-Mobility-in-a-Contaminated-Aquifer" class="headerlink" title="Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer"></a>Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07352">http://arxiv.org/abs/2308.07352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikhar Nilabh, Fidel Grandia</li>
<li>for: 这项研究的目的是为了开发一种能够在地下水域中有效地预测粒子的移动和停留行为，以便开发一种有效的地下水恢复策略。</li>
<li>methods: 这项研究使用了一种bayesian physics-informed neural network（B-PINN）框架，通过对模拟粒子在aquifer中的移动进行前向模型，并通过对模型输出进行逆向模型，来量化粒子的移动和停留行为。</li>
<li>results: 研究表明，B-PINN框架可以准确地预测粒子的移动和停留行为，并且可以量化这些行为的不确定性。此外，研究还发现了一些关键参数，可以用于控制粒子的移动和停留。这些结果表明，B-PINN框架可以提供有用的预测情况，以便开发有效的地下水恢复策略。<details>
<summary>Abstract</summary>
Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility and quantifying the uncertainty. The inverse model output is then used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="IOB-Integrating-Optimization-Transfer-and-Behavior-Transfer-for-Multi-Policy-Reuse"><a href="#IOB-Integrating-Optimization-Transfer-and-Behavior-Transfer-for-Multi-Policy-Reuse" class="headerlink" title="IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse"></a>IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07351">http://arxiv.org/abs/2308.07351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyuan Li, Hao Li, Jin Zhang, Zhen Wang, Peng Liu, Chongjie Zhang</li>
<li>for: 本研究旨在解决选择适当的源策略以促进目标策略学习的挑战，提出了一种新的转移学习RL方法。</li>
<li>methods: 该方法利用actor-critic框架中的Q函数引导策略选择，选择源策略可以提供最大一步改进。另外，该方法还结合了优化转移和行为转移（IOB），通过规范学习的策略来模仿指导策略，并将其与行为策略相结合。</li>
<li>results: 该方法在标准任务中超过了状态艺术RL基线，并在连续学习场景中提高了最终性和知识传递性。此外，该方法的优化转移技术保证了目标策略学习的提高。<details>
<summary>Abstract</summary>
Humans have the ability to reuse previously learned policies to solve new tasks quickly, and reinforcement learning (RL) agents can do the same by transferring knowledge from source policies to a related target task. Transfer RL methods can reshape the policy optimization objective (optimization transfer) or influence the behavior policy (behavior transfer) using source policies. However, selecting the appropriate source policy with limited samples to guide target policy learning has been a challenge. Previous methods introduce additional components, such as hierarchical policies or estimations of source policies' value functions, which can lead to non-stationary policy optimization or heavy sampling costs, diminishing transfer effectiveness. To address this challenge, we propose a novel transfer RL method that selects the source policy without training extra components. Our method utilizes the Q function in the actor-critic framework to guide policy selection, choosing the source policy with the largest one-step improvement over the current target policy. We integrate optimization transfer and behavior transfer (IOB) by regularizing the learned policy to mimic the guidance policy and combining them as the behavior policy. This integration significantly enhances transfer effectiveness, surpasses state-of-the-art transfer RL baselines in benchmark tasks, and improves final performance and knowledge transferability in continual learning scenarios. Additionally, we show that our optimization transfer technique is guaranteed to improve target policy learning.
</details>
<details>
<summary>摘要</summary>
人类有能力快速解决新任务使用已经学习过的策略，而强化学习（RL）代理也可以通过将来源策略中的知识传递到相关的目标任务中来实现此目的。传输RL方法可以修改策略优化目标（优化传递）或影响行为策略（行为传递）使用源策略。然而，选择适当的源策略可以受有限样本数的限制，从而影响目标策略的学习。先前的方法通过引入层次政策或估计源策略的价值函数等附加组件，可能导致非站点策略优化或重大的样本成本，减弱传输效果。为解决这个挑战，我们提出了一种新的传输RL方法，不需要训练附加组件。我们利用actor-critic框架中的Q函数来导引策选择，选择目标策略中最大化一步改进的源策略。我们将优化传递和行为传递（IOB）相结合，通过规范学习的策略来模仿指导策略，并将其与之相结合。这种结合显著提高了传输效果，超越了基准测试RL方法，并在持续学习场景中提高了最终性和知识传递性。此外，我们证明我们的优化传递技术是 garantizado 提高目标策略学习。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Neural-PDE-Solvers-using-Quantization-Aware-Training"><a href="#Efficient-Neural-PDE-Solvers-using-Quantization-Aware-Training" class="headerlink" title="Efficient Neural PDE-Solvers using Quantization Aware Training"></a>Efficient Neural PDE-Solvers using Quantization Aware Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07350">http://arxiv.org/abs/2308.07350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Winfried van den Dool, Tijmen Blankevoort, Max Welling, Yuki M. Asano</li>
<li>for: 解决Partial Differential Equations（PDE）中的计算成本问题，以减少计算成本并维持性能。</li>
<li>methods: 使用现有的量化方法来减少计算成本，包括量化网络参数和活动。</li>
<li>results: 对四个标准PDE数据集和三种网络架构进行了训练，并证明了量化意识训练可以降低计算成本，同时维持性能。最终，我们实际示出，只有通过量化来实现Pareto优化计算成本与性能的平衡。<details>
<summary>Abstract</summary>
In the past years, the application of neural networks as an alternative to classical numerical methods to solve Partial Differential Equations has emerged as a potential paradigm shift in this century-old mathematical field. However, in terms of practical applicability, computational cost remains a substantial bottleneck. Classical approaches try to mitigate this challenge by limiting the spatial resolution on which the PDEs are defined. For neural PDE solvers, we can do better: Here, we investigate the potential of state-of-the-art quantization methods on reducing computational costs. We show that quantizing the network weights and activations can successfully lower the computational cost of inference while maintaining performance. Our results on four standard PDE datasets and three network architectures show that quantization-aware training works across settings and three orders of FLOPs magnitudes. Finally, we empirically demonstrate that Pareto-optimality of computational cost vs performance is almost always achieved only by incorporating quantization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-to-Optimize-LSM-trees-Towards-A-Reinforcement-Learning-based-Key-Value-Store-for-Dynamic-Workloads"><a href="#Learning-to-Optimize-LSM-trees-Towards-A-Reinforcement-Learning-based-Key-Value-Store-for-Dynamic-Workloads" class="headerlink" title="Learning to Optimize LSM-trees: Towards A Reinforcement Learning based Key-Value Store for Dynamic Workloads"></a>Learning to Optimize LSM-trees: Towards A Reinforcement Learning based Key-Value Store for Dynamic Workloads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07013">http://arxiv.org/abs/2308.07013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingheng Mo, Fanchao Chen, Siqiang Luo, Caihua Shan</li>
<li>for: 提高静态工作负荷下的系统性能优化。</li>
<li>methods: 使用Reinforcement Learning（RL）导向LSM树变换，并提出新的LSM树设计——FLSM树，以便在不同的压缩策略之间进行高效的过渡。</li>
<li>results: 在多种工作负荷下，RusKey可以达到4倍的终端性能优化，比RocksDB系统更强。<details>
<summary>Abstract</summary>
LSM-trees are widely adopted as the storage backend of key-value stores. However, optimizing the system performance under dynamic workloads has not been sufficiently studied or evaluated in previous work. To fill the gap, we present RusKey, a key-value store with the following new features: (1) RusKey is a first attempt to orchestrate LSM-tree structures online to enable robust performance under the context of dynamic workloads; (2) RusKey is the first study to use Reinforcement Learning (RL) to guide LSM-tree transformations; (3) RusKey includes a new LSM-tree design, named FLSM-tree, for an efficient transition between different compaction policies -- the bottleneck of dynamic key-value stores. We justify the superiority of the new design with theoretical analysis; (4) RusKey requires no prior workload knowledge for system adjustment, in contrast to state-of-the-art techniques. Experiments show that RusKey exhibits strong performance robustness in diverse workloads, achieving up to 4x better end-to-end performance than the RocksDB system under various settings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>RusKey是首次在线上预约LSM-树结构，以确保在动态负荷下的稳定性表现。2. RusKey是首次使用强化学习（RL）引导LSM-树变换的研究。3. RusKey包含一种新的LSM-树设计，称为FLSM-树，可以有效地在不同的压缩策略之间进行过渡。4. RusKey不需要先知系统负荷特性，与现有技术不同。我们通过理论分析证明了新设计的优越性。实验结果表明，RusKey在多种工作负荷下表现出了强大的性能稳定性，与RocksDB系统在不同设置下实现了最高的终端性能，达到4倍之多。</details></li>
</ol>
<hr>
<h2 id="Greedy-online-change-point-detection"><a href="#Greedy-online-change-point-detection" class="headerlink" title="Greedy online change point detection"></a>Greedy online change point detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07012">http://arxiv.org/abs/2308.07012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jou-Hui Ho, Felipe Tobar</li>
<li>for: 提高 online Change Point Detection（CPD）方法的精度和准确性。</li>
<li>methods: 使用 Greedy Online Change Point Detection（GOCPD）方法，通过最大化数据来自两个独立模型（temporal）的概率，以找到时间序列中的变化点。</li>
<li>results: 在单个变化点的情况下，使用ternary搜索，逻辑复杂度为对数。在synthetic数据和实际世界 univariate和multivariate设置中，证明GOCPD的有效性。<details>
<summary>Abstract</summary>
Standard online change point detection (CPD) methods tend to have large false discovery rates as their detections are sensitive to outliers. To overcome this drawback, we propose Greedy Online Change Point Detection (GOCPD), a computationally appealing method which finds change points by maximizing the probability of the data coming from the (temporal) concatenation of two independent models. We show that, for time series with a single change point, this objective is unimodal and thus CPD can be accelerated via ternary search with logarithmic complexity. We demonstrate the effectiveness of GOCPD on synthetic data and validate our findings on real-world univariate and multivariate settings.
</details>
<details>
<summary>摘要</summary>
标准在线变点检测（CPD）方法通常会有较大的假阳性率，因为它们对异常值敏感。为了解决这个缺点，我们提议了Greedy Online Change Point Detection（GOCPD），一种计算效率高的方法，它通过最大化数据来自（时间）拼接两个独立模型的概率来检测变点。我们显示，对于具有单个变点的时间序列，这个目标函数是单峰性的，因此可以通过ternary search进行加速，其复杂度为对数型。我们在 synthetic 数据上证明了 GOCPD 的效果，并在实际世界的单variate 和多variate 设置中验证了我们的结论。
</details></li>
</ul>
<hr>
<h2 id="Aggregating-Intrinsic-Information-to-Enhance-BCI-Performance-through-Federated-Learning"><a href="#Aggregating-Intrinsic-Information-to-Enhance-BCI-Performance-through-Federated-Learning" class="headerlink" title="Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning"></a>Aggregating Intrinsic Information to Enhance BCI Performance through Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11636">http://arxiv.org/abs/2308.11636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Liu, Yuanyuan Chen, Anran Li, Yi Ding, Han Yu, Cuntai Guan</li>
<li>for: 这个研究旨在解决脑computer接口（BCI）建立高性能深度学习模型所面临的长期挑战，即脑电图（EEG）数据的共享。</li>
<li>methods: 本研究提出了一个层次化个性化联合学习（FLEEG）框架，以解决EEG数据之间的不同格式问题。每个客户端都被指派特定的数据集，并训练层次化个性化模型，以管理不同数据格式并促进信息交换。服务器则处理训练过程，将来自所有数据集的知识融合，以提高总表现。</li>
<li>results: 研究将在脑意念（MI）类别任务上进行了评估，使用了9个由不同设备收集的EEG数据集。结果显示，提出的框架可以提高类别性能达16.7%，尤其是 для较小的数据集。可视化结果也显示出该框架可以让本地模型对任务相关区域进行稳定的注意力集中，从而提高表现。<details>
<summary>Abstract</summary>
Insufficient data is a long-standing challenge for Brain-Computer Interface (BCI) to build a high-performance deep learning model. Though numerous research groups and institutes collect a multitude of EEG datasets for the same BCI task, sharing EEG data from multiple sites is still challenging due to the heterogeneity of devices. The significance of this challenge cannot be overstated, given the critical role of data diversity in fostering model robustness. However, existing works rarely discuss this issue, predominantly centering their attention on model training within a single dataset, often in the context of inter-subject or inter-session settings. In this work, we propose a hierarchical personalized Federated Learning EEG decoding (FLEEG) framework to surmount this challenge. This innovative framework heralds a new learning paradigm for BCI, enabling datasets with disparate data formats to collaborate in the model training process. Each client is assigned a specific dataset and trains a hierarchical personalized model to manage diverse data formats and facilitate information exchange. Meanwhile, the server coordinates the training procedure to harness knowledge gleaned from all datasets, thus elevating overall performance. The framework has been evaluated in Motor Imagery (MI) classification with nine EEG datasets collected by different devices but implementing the same MI task. Results demonstrate that the proposed frame can boost classification performance up to 16.7% by enabling knowledge sharing between multiple datasets, especially for smaller datasets. Visualization results also indicate that the proposed framework can empower the local models to put a stable focus on task-related areas, yielding better performance. To the best of our knowledge, this is the first end-to-end solution to address this important challenge.
</details>
<details>
<summary>摘要</summary>
BCIs 长期面临缺乏数据的挑战，建立高性能的深度学习模型。虽然多个研究组织和机构收集了大量的 EEG 数据，但是在不同设备上分享 EEG 数据仍然具有挑战性，这是因为设备之间存在差异。这种挑战的重要性无法被低估，因为数据多样性对模型的稳定性具有关键作用。然而，现有的研究很少讨论这个问题，通常在单一数据集上进行模型训练，通常在 между Subject 或 Session 上进行。在这种情况下，我们提出了一种层次个性化 Federated Learning EEG 解码（FLEEG）框架，以超越这个挑战。这种创新的框架标识了一种新的学习模式 для BCIs，使得不同数据格式的数据可以在模型训练过程中合作。每个客户端都被分配了特定的数据集，并训练了一个层次个性化模型来管理多样的数据格式并促进信息交换。同时，服务器协调训练过程，以利用所有数据集中所获得的知识，从而提高总性能。我们在 Motor Imagery （MI） 分类任务中使用九个 EEG 数据集，每个数据集都是由不同的设备收集的，但是实现了同一个 MI 任务。结果表明，我们的框架可以提高分类性能达到 16.7%，尤其是对小数据集的提高。视觉结果还表明，我们的框架可以让本地模型固定焦点于任务相关的区域，从而提高表现。到目前为止，这是我们知道的首个综合解决这个重要挑战的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Deep-convolutional-neural-networks-for-cyclic-sensor-data"><a href="#Deep-convolutional-neural-networks-for-cyclic-sensor-data" class="headerlink" title="Deep convolutional neural networks for cyclic sensor data"></a>Deep convolutional neural networks for cyclic sensor data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06987">http://arxiv.org/abs/2308.06987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Payman Goodarzi, Yannick Robin, Andreas Schütze, Tizian Schneider</li>
<li>for: 本研究旨在探讨基于感知器的维保维护，并使用深度学习技术对一个液压系统测试平台数据进行应用。</li>
<li>methods: 本研究使用了三个模型：基线模型使用传统方法、单个CNN模型使用早期感知融合、以及两个CNN模型（2L-CNN）使用晚期感知融合。</li>
<li>results: 基线模型使用晚期感知融合实现了低于1%的测试错误率，而CNN模型由于感知器之间的多样性而遇到挑战，导致错误率高达20.5%。在进一步调查这个问题时，我们发现了每个感知器都需要独立进行特征提取的问题。此外，我们还评估了2L-CNN模型，并发现它可以将最佳和最差的感知器组合起来，以减少错误率33%。这种研究认真地面对了多感知器系统中的复杂性。<details>
<summary>Abstract</summary>
Predictive maintenance plays a critical role in ensuring the uninterrupted operation of industrial systems and mitigating the potential risks associated with system failures. This study focuses on sensor-based condition monitoring and explores the application of deep learning techniques using a hydraulic system testbed dataset. Our investigation involves comparing the performance of three models: a baseline model employing conventional methods, a single CNN model with early sensor fusion, and a two-lane CNN model (2L-CNN) with late sensor fusion. The baseline model achieves an impressive test error rate of 1% by employing late sensor fusion, where feature extraction is performed individually for each sensor. However, the CNN model encounters challenges due to the diverse sensor characteristics, resulting in an error rate of 20.5%. To further investigate this issue, we conduct separate training for each sensor and observe variations in accuracy. Additionally, we evaluate the performance of the 2L-CNN model, which demonstrates significant improvement by reducing the error rate by 33% when considering the combination of the least and most optimal sensors. This study underscores the importance of effectively addressing the complexities posed by multi-sensor systems in sensor-based condition monitoring.
</details>
<details>
<summary>摘要</summary>
预测维护在工业系统不间断运行和降低系统故障的风险方面扮演着关键角色。本研究利用液压系统测试平台数据进行了深度学习技术的应用，并对三种模型进行比较：基线模型使用传统方法、单个CNN模型使用早期感知融合，以及两个CNN模型（2L-CNN）使用晚期感知融合。基线模型通过使用晚期感知融合实现了测试错误率为1%，但CNN模型由于感知器的多样性而遇到问题，导致错误率为20.5%。为了更深入了解这个问题，我们对每个感知器进行了分别的训练，并观察到了减少精度的变化。此外，我们还评估了2L-CNN模型的性能，其能够在考虑最佳和最差感知器的组合下降低错误率33%。这个研究重申了对多感知器系统的预测维护存在多样性和复杂性的挑战。
</details></li>
</ul>
<hr>
<h2 id="pNNCLR-Stochastic-Pseudo-Neighborhoods-for-Contrastive-Learning-based-Unsupervised-Representation-Learning-Problems"><a href="#pNNCLR-Stochastic-Pseudo-Neighborhoods-for-Contrastive-Learning-based-Unsupervised-Representation-Learning-Problems" class="headerlink" title="pNNCLR: Stochastic Pseudo Neighborhoods for Contrastive Learning based Unsupervised Representation Learning Problems"></a>pNNCLR: Stochastic Pseudo Neighborhoods for Contrastive Learning based Unsupervised Representation Learning Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06983">http://arxiv.org/abs/2308.06983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Momojit Biswas, Himanshu Buckchash, Dilip K. Prasad</li>
<li>for: 本研究的目的是提高 nearest neighbor 基于自助学习（SSL）的图像识别问题中的 semantic variation。</li>
<li>methods: 本研究使用 nearest neighbor  sampling 方法，并引入 pseudo nearest neighbors（pNN）来控制支持集质量。此外，通过随机抽样和平滑重量更新方法来稳定 nearest neighbor 基于学习的不确定性。</li>
<li>results: 对多个公共图像识别和医学图像识别数据集进行评估，本研究的提案方法可以与基准 nearest neighbor 方法相比，并与其他先前提出的 SSL 方法相当。<details>
<summary>Abstract</summary>
Nearest neighbor (NN) sampling provides more semantic variations than pre-defined transformations for self-supervised learning (SSL) based image recognition problems. However, its performance is restricted by the quality of the support set, which holds positive samples for the contrastive loss. In this work, we show that the quality of the support set plays a crucial role in any nearest neighbor based method for SSL. We then provide a refined baseline (pNNCLR) to the nearest neighbor based SSL approach (NNCLR). To this end, we introduce pseudo nearest neighbors (pNN) to control the quality of the support set, wherein, rather than sampling the nearest neighbors, we sample in the vicinity of hard nearest neighbors by varying the magnitude of the resultant vector and employing a stochastic sampling strategy to improve the performance. Additionally, to stabilize the effects of uncertainty in NN-based learning, we employ a smooth-weight-update approach for training the proposed network. Evaluation of the proposed method on multiple public image recognition and medical image recognition datasets shows that it performs up to 8 percent better than the baseline nearest neighbor method, and is comparable to other previously proposed SSL methods.
</details>
<details>
<summary>摘要</summary>
近邻采样（NN）提供更多语义变化，对自助学习（SSL）基于图像识别问题的性能有较好的影响。然而，其性能受支持集质量的限制。在这种情况下，我们表明支持集质量对任何近邻基于SSL方法的性能具有关键作用。我们然后提供一种精度的基线（pNNCLR），用于改进近邻基于SSL方法（NNCLR）。为此，我们引入 pseudo 近邻（pNN），以控制支持集质量。具体来说，而不是直接采样最近邻，我们采样邻近硬邻邻的附近，通过变化结果向量的大小和使用随机采样策略来提高性能。此外，为了稳定NN基于学习中的uncertainty的效果，我们使用了平滑Weight更新方法进行网络训练。多个公共图像识别和医疗图像识别数据集上的评估表明，我们提出的方法与基eline最近邻方法相比，性能提高达8%，与其他之前提出的SSL方法相当。
</details></li>
</ul>
<hr>
<h2 id="Routing-Recovery-for-UAV-Networks-with-Deliberate-Attacks-A-Reinforcement-Learning-based-Approach"><a href="#Routing-Recovery-for-UAV-Networks-with-Deliberate-Attacks-A-Reinforcement-Learning-based-Approach" class="headerlink" title="Routing Recovery for UAV Networks with Deliberate Attacks: A Reinforcement Learning based Approach"></a>Routing Recovery for UAV Networks with Deliberate Attacks: A Reinforcement Learning based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06973">http://arxiv.org/abs/2308.06973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sijie He, Ziye Jia, Chao Dong, Wei Wang, Yilu Cao, Yang Yang, Qihui Wu</li>
<li>for: 本研究强调路由计划和恢复方法，以适应无人机网络受到攻击的情况。</li>
<li>methods: 该研究提出了一种基于节点重要性的攻击模型，并实现了节点重要性排名机制。此外，基于强化学习算法的智能路由方法也被提出，以恢复路由路径在无人机网络受到攻击时。</li>
<li>results: 数据示，提出的方法比其他相关方法更为有效。<details>
<summary>Abstract</summary>
The unmanned aerial vehicle (UAV) network is popular these years due to its various applications. In the UAV network, routing is significantly affected by the distributed network topology, leading to the issue that UAVs are vulnerable to deliberate damage. Hence, this paper focuses on the routing plan and recovery for UAV networks with attacks. In detail, a deliberate attack model based on the importance of nodes is designed to represent enemy attacks. Then, a node importance ranking mechanism is presented, considering the degree of nodes and link importance. However, it is intractable to handle the routing problem by traditional methods for UAV networks, since link connections change with the UAV availability. Hence, an intelligent algorithm based on reinforcement learning is proposed to recover the routing path when UAVs are attacked. Simulations are conducted and numerical results verify the proposed mechanism performs better than other referred methods.
</details>
<details>
<summary>摘要</summary>
“无人航空器（UAV）网络在这些年变得非常流行，它在各种应用方面表现出了优异的表现。然而，UAV网络中的路由却受到分布式网络架构的影响，导致UAV易受到意外攻击。因此，本文关注UAV网络中的路由计划和恢复，以适应攻击。具体来说，我们设计了一种基于节点重要性的攻击模型，并提出了一种考虑节点和链接重要性的节点重要性排名机制。然而，由于UAV网络中的链接连接随着UAV可用性的变化，传统的路由方法无法处理UAV网络的路由问题。因此，我们提出了基于强化学习算法的智能路由恢复方法，以便在UAV被攻击时恢复路由路径。我们对此进行了仿真和数值分析，结果表明我们的提案在恢复路由路径方面表现出了更好的性能。”Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="AutoAssign-Automatic-Shared-Embedding-Assignment-in-Streaming-Recommendation"><a href="#AutoAssign-Automatic-Shared-Embedding-Assignment-in-Streaming-Recommendation" class="headerlink" title="AutoAssign+: Automatic Shared Embedding Assignment in Streaming Recommendation"></a>AutoAssign+: Automatic Shared Embedding Assignment in Streaming Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06965">http://arxiv.org/abs/2308.06965</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Applied-Machine-Learning-Lab/AutoAssign-Plus">https://github.com/Applied-Machine-Learning-Lab/AutoAssign-Plus</a></li>
<li>paper_authors: Ziru Liu, Kecheng Chen, Fengyi Song, Bo Chen, Xiangyu Zhao, Huifeng Guo, Ruiming Tang</li>
<li>For: The paper aims to address the challenges of assigning initial ID embeddings randomly in streaming recommender systems, which can result in suboptimal prediction performance for items or users with limited interactive data, and lead to unnecessary memory consumption.* Methods: The paper proposes a reinforcement learning-driven framework called AutoAssign+, which utilizes an Identity Agent to represent low-frequency IDs field-wise with a small set of shared embeddings, and dynamically determine which ID features should be retained or eliminated in the embedding table.* Results: The paper demonstrates that AutoAssign+ is capable of significantly enhancing recommendation performance by mitigating the cold-start problem, and yields a reduction in memory usage of approximately 20-30%, verifying its practical effectiveness and efficiency for streaming recommender systems.Here’s the simplified Chinese text for the three key points:* For: 这篇论文目标是解决流动推荐系统中 randomly 分配初始 ID 嵌入的问题，这可能导致有限交互数据的用户或物品预测性能下降，并且需要不断扩展嵌入表，从而导致过度的内存消耗。* Methods: 论文提出一种基于强化学习的框架，即 AutoAssign+，该框架利用一个 Identity Agent 作为actor网络，该网络在两个角色下运行：一是用一小组共享嵌入来代表低频 ID，以提高嵌入初始化；二是在嵌入表中决定应保留或消除哪些 ID 特征。批评网络对策优化。* Results: 实验结果表明，AutoAssign+ 能够显著提高推荐性能，减轻冷启 проблеme，并且减少内存使用量约 20-30%，证明其在流动推荐系统中的实用性和效率。<details>
<summary>Abstract</summary>
In the domain of streaming recommender systems, conventional methods for addressing new user IDs or item IDs typically involve assigning initial ID embeddings randomly. However, this practice results in two practical challenges: (i) Items or users with limited interactive data may yield suboptimal prediction performance. (ii) Embedding new IDs or low-frequency IDs necessitates consistently expanding the embedding table, leading to unnecessary memory consumption. In light of these concerns, we introduce a reinforcement learning-driven framework, namely AutoAssign+, that facilitates Automatic Shared Embedding Assignment Plus. To be specific, AutoAssign+ utilizes an Identity Agent as an actor network, which plays a dual role: (i) Representing low-frequency IDs field-wise with a small set of shared embeddings to enhance the embedding initialization, and (ii) Dynamically determining which ID features should be retained or eliminated in the embedding table. The policy of the agent is optimized with the guidance of a critic network. To evaluate the effectiveness of our approach, we perform extensive experiments on three commonly used benchmark datasets. Our experiment results demonstrate that AutoAssign+ is capable of significantly enhancing recommendation performance by mitigating the cold-start problem. Furthermore, our framework yields a reduction in memory usage of approximately 20-30%, verifying its practical effectiveness and efficiency for streaming recommender systems.
</details>
<details>
<summary>摘要</summary>
在流动推荐系统领域，传统方法通常是随机分配初始ID embedding。然而，这种做法会导致两个实际挑戦：（i）有限交互数据的物品或用户可能会得到低效预测性能。（ii）添加新ID或低频ID需要不断扩大 embedding 表，从而导致不必要的内存浪费。为了解决这些问题，我们介绍了一个基于强化学习的框架，即AutoAssign+，它实现了自动共享 embedding 分配加 plus。具体来说，AutoAssign+ 使用一个 Identity Agent 作为actor网络，该网络在两个角色中进行表达：（i）在 embeddings 中场景化低频 ID 使用一小组共享 embedding 进行增强初始化。（ii）在 embedding 表中决定保留或 eliminating ID 特征。Identity Agent 的策略通过批评网络的指导优化。为了评估我们的方法的有效性，我们在三个常用的标准数据集上进行了广泛的实验。实验结果表明，AutoAssign+ 能够有效地缓解冷启点问题，并且它的内存使用率比传统方法减少了约20-30%，证明了它在流动推荐系统中的实际效果和效率。
</details></li>
</ul>
<hr>
<h2 id="Graph-Structural-Residuals-A-Learning-Approach-to-Diagnosis"><a href="#Graph-Structural-Residuals-A-Learning-Approach-to-Diagnosis" class="headerlink" title="Graph Structural Residuals: A Learning Approach to Diagnosis"></a>Graph Structural Residuals: A Learning Approach to Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06961">http://arxiv.org/abs/2308.06961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Lukas Augustin, Oliver Niggemann</li>
<li>for: This paper proposes a novel framework for model-based diagnosis that combines concepts of model-based diagnosis with deep graph structure learning, aiming to facilitate a seamless integration of graph structure learning with model-based diagnosis.</li>
<li>methods: The proposed framework uses two distinct graph adjacency matrices to represent the system’s underlying structure and provide dynamic observations. Additionally, the paper introduces two versions of a self-supervised graph structure learning model architecture.</li>
<li>results: The authors demonstrate the potential of their data-driven diagnostic method through experiments on a system of coupled oscillators.<details>
<summary>Abstract</summary>
Traditional model-based diagnosis relies on constructing explicit system models, a process that can be laborious and expertise-demanding. In this paper, we propose a novel framework that combines concepts of model-based diagnosis with deep graph structure learning. This data-driven approach leverages data to learn the system's underlying structure and provide dynamic observations, represented by two distinct graph adjacency matrices. Our work facilitates a seamless integration of graph structure learning with model-based diagnosis by making three main contributions: (i) redefining the constructs of system representation, observations, and faults (ii) introducing two distinct versions of a self-supervised graph structure learning model architecture and (iii) demonstrating the potential of our data-driven diagnostic method through experiments on a system of coupled oscillators.
</details>
<details>
<summary>摘要</summary>
传统的模型基于诊断方法是通过构建明确的系统模型来进行，这可能是一项劳动密集且需要专家知识的过程。在这篇论文中，我们提出了一种新的框架，它将模型基于诊断与深度图结构学习结合起来。这种数据驱动的方法利用数据来学习系统的下面结构，并提供动态观察结果，表示为两个不同的图邻接矩阵。我们的工作使得图结构学习与模型基于诊断的集成变得自然和简单，我们的主要贡献包括：1. 重新定义系统表示、观察和缺陷的构造2. 提出两种自动学习图结构模型建立方法3. 通过对振荡器系统的实验，证明我们的数据驱动诊断方法的潜力。
</details></li>
</ul>
<hr>
<h2 id="Search-to-Fine-tune-Pre-trained-Graph-Neural-Networks-for-Graph-level-Tasks"><a href="#Search-to-Fine-tune-Pre-trained-Graph-Neural-Networks-for-Graph-level-Tasks" class="headerlink" title="Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks"></a>Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06960">http://arxiv.org/abs/2308.06960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili Wang, Shimin Di, Lei Chen, Xiaofang Zhou<br>for: 这paper是为了提出一种更好的微调策略来改进预训练的graph neural network (GNN)的性能，以便在下游任务上提高模型性能。methods: 这paper使用了针对大规模未标注图数据进行预训练，并通过限制数据量的微调来适应目标下游任务。具体来说，它们提出了一种名为S2PGNN的搜索式微调策略，可以在各种下游任务上实现更好的性能。results: 这paper的实验结果表明，S2PGNN可以在10种著名的预训练GNN上实现性能提升，并且在预训练GNN的内部和外部比较其他微调策略的情况下都有更好的性能。codes可以在\url{<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/code_icde2024-A9CB/%7D%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://anonymous.4open.science/r/code_icde2024-A9CB/}上获取。</a><details>
<summary>Abstract</summary>
Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search to fine-tune pre-trained graph neural networks for graph-level tasks (S2PGNN), which adaptively design a suitable fine-tuning framework for the given labeled data on the downstream task. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at \url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.
</details>
<details>
<summary>摘要</summary>
近期，图 нейрон网络（GNNs）在许多图关联任务中显示了无前例的成功。然而，GNNs面临标签缺乏问题，与其他神经网络一样。因此，当前努力通过大规模无标签图进行Pre-training GNNs，并将知识从无标签图传递到目标下游任务。适应通常通过精度调整Pre-trained GNNs中的一部分参数来实现。 despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only a few works have started to investigate a better fine-tuning strategy for pre-trained GNNs, but their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search for a fine-tuning framework that adaptively designs a suitable fine-tuning strategy for the given labeled data on the downstream task. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at \url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Allocation-of-Preventive-Care-With-Application-to-Diabetes-Mellitus-Type-II"><a href="#Data-Driven-Allocation-of-Preventive-Care-With-Application-to-Diabetes-Mellitus-Type-II" class="headerlink" title="Data-Driven Allocation of Preventive Care With Application to Diabetes Mellitus Type II"></a>Data-Driven Allocation of Preventive Care With Application to Diabetes Mellitus Type II</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06959">http://arxiv.org/abs/2308.06959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Kraus, Stefan Feuerriegel, Maytal Saar-Tsechansky</li>
<li>for: 预防疾病的效果性评估和决策支持</li>
<li>methods: 结合Counterfactual推理、机器学习和优化技术，建立可扩展的数据驱动决策模型，可以利用现代电子医疗记录中的高维医疗数据</li>
<li>results: 对89,191名 prediabetic 患者的电子医疗记录进行评估，与现有医疗实践相比，我们的数据驱动决策模型可以每年节省11亿美元。并且在不同预算水平下进行成本效果分析。<details>
<summary>Abstract</summary>
Problem Definition. Increasing costs of healthcare highlight the importance of effective disease prevention. However, decision models for allocating preventive care are lacking.   Methodology/Results. In this paper, we develop a data-driven decision model for determining a cost-effective allocation of preventive treatments to patients at risk. Specifically, we combine counterfactual inference, machine learning, and optimization techniques to build a scalable decision model that can exploit high-dimensional medical data, such as the data found in modern electronic health records. Our decision model is evaluated based on electronic health records from 89,191 prediabetic patients. We compare the allocation of preventive treatments (metformin) prescribed by our data-driven decision model with that of current practice. We find that if our approach is applied to the U.S. population, it can yield annual savings of $1.1 billion. Finally, we analyze the cost-effectiveness under varying budget levels.   Managerial Implications. Our work supports decision-making in health management, with the goal of achieving effective disease prevention at lower costs. Importantly, our decision model is generic and can thus be used for effective allocation of preventive care for other preventable diseases.
</details>
<details>
<summary>摘要</summary>
问题定义：医疗成本的增长强调了疾病预防的重要性。然而，决策模型用于分配预防治疗的缺失。方法ология/结果：在这篇论文中，我们开发了一种基于数据的决策模型，用于确定有效分配预防治疗给患有风险的病人。具体来说，我们结合Counterfactual推理、机器学习和优化技术，构建了可扩展的决策模型，可以利用现代电子医疗记录中的高维医疗数据。我们的决策模型在89191名 prediabetic 患者的电子医疗记录上进行评估。我们将比较我们的数据驱动的决策模型与现有做法分配预防治疗（metformin）的分配方式。我们发现，如果我们的方法应用于美国人口，可以每年节省11亿美元。最后，我们分析了不同预算水平下的成本效果。管理意义：我们的工作支持医疗管理决策，以实现更有效的疾病预防，并降低成本。重要的是，我们的决策模型是通用的，可以用于有效地分配预防治疗其他预防性疾病。
</details></li>
</ul>
<hr>
<h2 id="CEmb-SAM-Segment-Anything-Model-with-Condition-Embedding-for-Joint-Learning-from-Heterogeneous-Datasets"><a href="#CEmb-SAM-Segment-Anything-Model-with-Condition-Embedding-for-Joint-Learning-from-Heterogeneous-Datasets" class="headerlink" title="CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets"></a>CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06957">http://arxiv.org/abs/2308.06957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongik Shin, Beomsuk Kim, Seungjun Baek</li>
<li>for: 助 медицин专家进行诊断和治疗过程中的自动图像分割。</li>
<li>methods: 使用多modal ultrasound图像，并将不同的 анатомиче结构或癌变分为不同的子集，以便使用单一模型进行学习和泛化。</li>
<li>results: 在实验中，使用 Condition Embedding block (CEmb-SAM) 可以有效地适应不同的子集，并且在 peripheral nerves 和 breast cancer 图像分割任务中表现出色，比基eline方法有更好的效果。<details>
<summary>Abstract</summary>
Automated segmentation of ultrasound images can assist medical experts with diagnostic and therapeutic procedures. Although using the common modality of ultrasound, one typically needs separate datasets in order to segment, for example, different anatomical structures or lesions with different levels of malignancy. In this paper, we consider the problem of jointly learning from heterogeneous datasets so that the model can improve generalization abilities by leveraging the inherent variability among datasets. We merge the heterogeneous datasets into one dataset and refer to each component dataset as a subgroup. We propose to train a single segmentation model so that the model can adapt to each sub-group. For robust segmentation, we leverage recently proposed Segment Anything model (SAM) in order to incorporate sub-group information into the model. We propose SAM with Condition Embedding block (CEmb-SAM) which encodes sub-group conditions and combines them with image embeddings from SAM. The conditional embedding block effectively adapts SAM to each image sub-group by incorporating dataset properties through learnable parameters for normalization. Experiments show that CEmb-SAM outperforms the baseline methods on ultrasound image segmentation for peripheral nerves and breast cancer. The experiments highlight the effectiveness of Cemb-SAM in learning from heterogeneous datasets in medical image segmentation tasks.
</details>
<details>
<summary>摘要</summary>
自动 segmentation of ultrasound images 可以帮助医疗专家进行诊断和治疗过程。 although using the common modality of ultrasound, one typically needs separate datasets in order to segment, for example, different anatomical structures or lesions with different levels of malignancy. 在这篇论文中，我们考虑了将异类数据集合在一起，以便模型可以利用数据集之间的自然变化来提高泛化能力。 we merge the heterogeneous datasets into one dataset and refer to each component dataset as a subgroup. we propose to train a single segmentation model so that the model can adapt to each sub-group. for robust segmentation, we leverage recently proposed Segment Anything model (SAM) in order to incorporate sub-group information into the model. we propose SAM with Condition Embedding block (CEmb-SAM) which encodes sub-group conditions and combines them with image embeddings from SAM. the conditional embedding block effectively adapts SAM to each image sub-group by incorporating dataset properties through learnable parameters for normalization. experiments show that CEmb-SAM outperforms the baseline methods on ultrasound image segmentation for peripheral nerves and breast cancer. the experiments highlight the effectiveness of Cemb-SAM in learning from heterogeneous datasets in medical image segmentation tasks.
</details></li>
</ul>
<hr>
<h2 id="Channel-Wise-Contrastive-Learning-for-Learning-with-Noisy-Labels"><a href="#Channel-Wise-Contrastive-Learning-for-Learning-with-Noisy-Labels" class="headerlink" title="Channel-Wise Contrastive Learning for Learning with Noisy Labels"></a>Channel-Wise Contrastive Learning for Learning with Noisy Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06952">http://arxiv.org/abs/2308.06952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Kang, Sheng Liu, Huaxi Huang, Tongliang Liu</li>
<li>for: 本研究旨在Addressing the challenge of learning with noisy labels (LNL), 即训练一个能够从给定的实例中分辨真实的类别信息的分类器。</li>
<li>methods: 本研究提出了一种频道 wise contrastive learning (CWCL) 方法，通过在多个频道上进行对比学习，以分离真实的标签信息和噪声。</li>
<li>results: 对多个 benchmark 数据集进行评估，研究发现 CWCL 方法比既有的方法更高效，能够提取更加细腻和鲜明的特征，以便更好地分辨真实的标签信息。<details>
<summary>Abstract</summary>
In real-world datasets, noisy labels are pervasive. The challenge of learning with noisy labels (LNL) is to train a classifier that discerns the actual classes from given instances. For this, the model must identify features indicative of the authentic labels. While research indicates that genuine label information is embedded in the learned features of even inaccurately labeled data, it's often intertwined with noise, complicating its direct application. Addressing this, we introduce channel-wise contrastive learning (CWCL). This method distinguishes authentic label information from noise by undertaking contrastive learning across diverse channels. Unlike conventional instance-wise contrastive learning (IWCL), CWCL tends to yield more nuanced and resilient features aligned with the authentic labels. Our strategy is twofold: firstly, using CWCL to extract pertinent features to identify cleanly labeled samples, and secondly, progressively fine-tuning using these samples. Evaluations on several benchmark datasets validate our method's superiority over existing approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Knowing-Where-to-Focus-Event-aware-Transformer-for-Video-Grounding"><a href="#Knowing-Where-to-Focus-Event-aware-Transformer-for-Video-Grounding" class="headerlink" title="Knowing Where to Focus: Event-aware Transformer for Video Grounding"></a>Knowing Where to Focus: Event-aware Transformer for Video Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06947">http://arxiv.org/abs/2308.06947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinhyunj/eatr">https://github.com/jinhyunj/eatr</a></li>
<li>paper_authors: Jinhyun Jang, Jungin Park, Jin Kim, Hyeongjun Kwon, Kwanghoon Sohn</li>
<li>for: This paper aims to improve video grounding models by incorporating event-aware dynamic moment queries to better capture the temporal structure of videos and provide more accurate moment timestamps.</li>
<li>methods: The proposed method uses a slot attention mechanism for event reasoning and a gated fusion transformer layer for moment reasoning, which fuses the moment queries with the video-sentence representations to predict moment timestamps.</li>
<li>results: The proposed approach outperforms state-of-the-art video grounding models on several benchmarks, demonstrating its effectiveness and efficiency.Here’s the simplified Chinese text:</li>
<li>for: 这篇论文目的是提高视频落实模型，通过包含事件相关的动态时刻查询来更好地捕捉视频的时间结构，并提供更准确的时刻查询。</li>
<li>methods: 该方法使用槽注意机制进行事件理解，并使用阀门融合变换层与视频句子表示之间的交互来预测时刻查询。</li>
<li>results: 该方法在多个benchmark上表现出色，超越了现有的视频落实模型，证明其效果和效率。<details>
<summary>Abstract</summary>
Recent DETR-based video grounding models have made the model directly predict moment timestamps without any hand-crafted components, such as a pre-defined proposal or non-maximum suppression, by learning moment queries. However, their input-agnostic moment queries inevitably overlook an intrinsic temporal structure of a video, providing limited positional information. In this paper, we formulate an event-aware dynamic moment query to enable the model to take the input-specific content and positional information of the video into account. To this end, we present two levels of reasoning: 1) Event reasoning that captures distinctive event units constituting a given video using a slot attention mechanism; and 2) moment reasoning that fuses the moment queries with a given sentence through a gated fusion transformer layer and learns interactions between the moment queries and video-sentence representations to predict moment timestamps. Extensive experiments demonstrate the effectiveness and efficiency of the event-aware dynamic moment queries, outperforming state-of-the-art approaches on several video grounding benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Event reasoning that captures distinctive event units constituting a given video using a slot attention mechanism.2. Moment reasoning that fuses the moment queries with a given sentence through a gated fusion transformer layer and learns interactions between the moment queries and video-sentence representations to predict moment timestamps.Extensive experiments demonstrate the effectiveness and efficiency of the event-aware dynamic moment queries, outperforming state-of-the-art approaches on several video grounding benchmarks.Translation notes:* DETR-based: 基于DETR的 (DETR是一种引入了 transformer 的 Object Detection 模型)* input-agnostic: 无关输入的 (ignore the input)* event-aware: 事件意识的 (aware of events)* dynamic moment queries: 动态时刻查询 (query the moment of an event)* gated fusion transformer layer: 阻塞融合变换层 (a type of transformer layer that combines multiple inputs)* video-sentence representations: 视频句子表示 (representations of video and sentence)* moment timestamps: 时刻查询 (query the moment of an event)</details></li>
</ol>
<hr>
<h2 id="Semantic-aware-Network-for-Aerial-to-Ground-Image-Synthesis"><a href="#Semantic-aware-Network-for-Aerial-to-Ground-Image-Synthesis" class="headerlink" title="Semantic-aware Network for Aerial-to-Ground Image Synthesis"></a>Semantic-aware Network for Aerial-to-Ground Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06945">http://arxiv.org/abs/2308.06945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinhyunj/sanet">https://github.com/jinhyunj/sanet</a></li>
<li>paper_authors: Jinhyun Jang, Taeyong Song, Kwanghoon Sohn</li>
<li>for: 本文 targets  Aerial-to-ground image synthesis, an emerging and challenging problem that aims to synthesize a ground image from an aerial image.</li>
<li>methods: 本文提出了一个 novel framework，通过强化结构对运算和 semantic awareness 来解决这个问题。具体来说，本文引入了一个新的 semantic-attentive feature transformation module，可以将 aerial 特征转换为 ground 的 complex geographic structures。此外，本文还提出了 semantic-aware loss functions，通过利用预训练的 segmentation network，让网络 Synthesize  realistic objects across various classes，并对不同类别进行分别计算损失和均衡。</li>
<li>results: 实验结果显示，提出的 framework 能够实现高品质的 Aerial-to-ground image synthesis，并与先前的方法进行比较和范例研究。<details>
<summary>Abstract</summary>
Aerial-to-ground image synthesis is an emerging and challenging problem that aims to synthesize a ground image from an aerial image. Due to the highly different layout and object representation between the aerial and ground images, existing approaches usually fail to transfer the components of the aerial scene into the ground scene. In this paper, we propose a novel framework to explore the challenges by imposing enhanced structural alignment and semantic awareness. We introduce a novel semantic-attentive feature transformation module that allows to reconstruct the complex geographic structures by aligning the aerial feature to the ground layout. Furthermore, we propose semantic-aware loss functions by leveraging a pre-trained segmentation network. The network is enforced to synthesize realistic objects across various classes by separately calculating losses for different classes and balancing them. Extensive experiments including comparisons with previous methods and ablation studies show the effectiveness of the proposed framework both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
空中图像与地面图像合成是一个emerging和挑战性的问题，目标是将空中图像转换为地面图像。由于空中和地面图像之间的 Layout和对象表示差异极大，现有的方法通常无法将空中场景中的组件迁移到地面场景中。在这篇论文中，我们提出了一个新的框架，以探讨这些挑战。我们引入了一个新的semantic-attentive特征变换模块，该模块可以将空中特征与地面布局相互对应，并且我们提出了Semantic-aware的损失函数，该函数通过使用预训练的分割网络来适应不同类别的物体，以实现Synthesize realistic的对象。我们进行了广泛的实验，包括与之前的方法进行比较和简要的ablation study，以证明我们的框架的效果。
</details></li>
</ul>
<hr>
<h2 id="Insurance-pricing-on-price-comparison-websites-via-reinforcement-learning"><a href="#Insurance-pricing-on-price-comparison-websites-via-reinforcement-learning" class="headerlink" title="Insurance pricing on price comparison websites via reinforcement learning"></a>Insurance pricing on price comparison websites via reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06935">http://arxiv.org/abs/2308.06935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanut Treetanthiploet, Yufei Zhang, Lukasz Szpruch, Isaac Bowers-Barnard, Henrietta Ridley, James Hickey, Chris Pearce</li>
<li>for: This paper aims to address the challenges of formulating effective pricing strategies for insurers on price comparison websites (PCWs) by introducing a reinforcement learning (RL) framework that integrates model-based and model-free methods.</li>
<li>methods: The proposed methodology uses a model-based component to train agents in an offline setting, and model-free algorithms in a contextual bandit (CB) manner to dynamically update the pricing policy and maximize expected revenue.</li>
<li>results: The paper demonstrates the superiority of the proposed methodology over existing off-the-shelf RL&#x2F;CB approaches using synthetic data, and shows that the hybrid agent outperforms benchmarks in terms of sample efficiency and cumulative reward.<details>
<summary>Abstract</summary>
The emergence of price comparison websites (PCWs) has presented insurers with unique challenges in formulating effective pricing strategies. Operating on PCWs requires insurers to strike a delicate balance between competitive premiums and profitability, amidst obstacles such as low historical conversion rates, limited visibility of competitors' actions, and a dynamic market environment. In addition to this, the capital intensive nature of the business means pricing below the risk levels of customers can result in solvency issues for the insurer. To address these challenges, this paper introduces reinforcement learning (RL) framework that learns the optimal pricing policy by integrating model-based and model-free methods. The model-based component is used to train agents in an offline setting, avoiding cold-start issues, while model-free algorithms are then employed in a contextual bandit (CB) manner to dynamically update the pricing policy to maximise the expected revenue. This facilitates quick adaptation to evolving market dynamics and enhances algorithm efficiency and decision interpretability. The paper also highlights the importance of evaluating pricing policies using an offline dataset in a consistent fashion and demonstrates the superiority of the proposed methodology over existing off-the-shelf RL/CB approaches. We validate our methodology using synthetic data, generated to reflect private commercially available data within real-world insurers, and compare against 6 other benchmark approaches. Our hybrid agent outperforms these benchmarks in terms of sample efficiency and cumulative reward with the exception of an agent that has access to perfect market information which would not be available in a real-world set-up.
</details>
<details>
<summary>摘要</summary>
随着价格比较网站（PCW）的出现，保险公司面临着独特的价格策略形成挑战。在PCW上运营需要保险公司坚持细致的平衡，同时综合考虑竞争价格、利润和市场环境的变化。此外，保险业务具有资本密集的特点，如果价格低于客户风险水平，可能会导致保险公司的资本危机。为 Addressing these challenges, this paper proposes a reinforcement learning (RL) framework that learns the optimal pricing policy by integrating model-based and model-free methods. The model-based component is used to train agents in an offline setting, avoiding cold-start issues, while model-free algorithms are then employed in a contextual bandit (CB) manner to dynamically update the pricing policy to maximize the expected revenue. This facilitates quick adaptation to evolving market dynamics and enhances algorithm efficiency and decision interpretability. The paper also highlights the importance of evaluating pricing policies using an offline dataset in a consistent fashion and demonstrates the superiority of the proposed methodology over existing off-the-shelf RL/CB approaches. We validate our methodology using synthetic data, generated to reflect private commercially available data within real-world insurers, and compare against 6 other benchmark approaches. Our hybrid agent outperforms these benchmarks in terms of sample efficiency and cumulative reward, with the exception of an agent that has access to perfect market information, which is not available in a real-world setting.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Listing-Prices-In-Dynamic-Short-Term-Rental-Markets-Using-Machine-Learning-Models"><a href="#Predicting-Listing-Prices-In-Dynamic-Short-Term-Rental-Markets-Using-Machine-Learning-Models" class="headerlink" title="Predicting Listing Prices In Dynamic Short Term Rental Markets Using Machine Learning Models"></a>Predicting Listing Prices In Dynamic Short Term Rental Markets Using Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06929">http://arxiv.org/abs/2308.06929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Chapman, Seifey Mohammad, Kimberly Villegas</li>
<li>For: The paper aims to predict the prices of Airbnb rentals in Austin, Texas using a machine learning modeling approach, with the primary objective of constructing an accurate model and the secondary objective of identifying the key factors that drive rental prices.* Methods: The paper uses a machine learning approach and incorporates sentiment analysis into the feature engineering to gain a deeper understanding of periodic changes in Airbnb rental prices.* Results: The paper aims to provide accurate predictions of Airbnb rental prices in Austin, Texas and identify the key factors that drive these prices, with a focus on understanding how these factors vary across different locations and property types.Here is the same information in Simplified Chinese:* For: 这篇论文目标是预测美国得克萨斯州奥斯汀的空bnb租赁价格，使用机器学习模型方法，主要目标是构建准确的模型，并且次要目标是确定租赁价格的关键因素。* Methods: 论文使用机器学习方法，并将情感分析integrated into feature engineering，以更深入理解 periodic change in Airbnb租赁价格。* Results: 论文期望提供准确的空bnb租赁价格预测，并确定租赁价格关键因素，特别是在不同的地点和房型上。<details>
<summary>Abstract</summary>
Our research group wanted to take on the difficult task of predicting prices in a dynamic market. And short term rentals such as Airbnb listings seemed to be the perfect proving ground to do such a thing. Airbnb has revolutionized the travel industry by providing a platform for homeowners to rent out their properties to travelers. The pricing of Airbnb rentals is prone to high fluctuations, with prices changing frequently based on demand, seasonality, and other factors. Accurate prediction of Airbnb rental prices is crucial for hosts to optimize their revenue and for travelers to make informed booking decisions. In this project, we aim to predict the prices of Airbnb rentals using a machine learning modeling approach.   Our project expands on earlier research in the area of analyzing Airbnb rental prices by taking a methodical machine learning approach as well as incorporating sentiment analysis into our feature engineering. We intend to gain a deeper understanding on periodic changes of Airbnb rental prices. The primary objective of this study is to construct an accurate machine learning model for predicting Airbnb rental prices specifically in Austin, Texas. Our project's secondary objective is to identify the key factors that drive Airbnb rental prices and to investigate how these factors vary across different locations and property types.
</details>
<details>
<summary>摘要</summary>
我们的研究小组想要解决动态市场中价格预测的复杂任务。短期租赁如 Airbnb 列表似乎是完美的证明场地。 Airbnb 为旅行者提供了一个平台，让房东租出他们的房屋给旅行者。 Airbnb 租赁价格受到高涨的影响，价格频繁变化，与需求、季节和其他因素有关。正确预测 Airbnb 租赁价格是hosts 优化收益和旅行者做出 Informed 预订决策的关键。在这个项目中，我们使用机器学习模型方法来预测 Airbnb 租赁价格。我们的项目在分析 Airbnb 租赁价格方面进一步发展了之前的研究。我们采用了系统的机器学习方法，同时还包括了情感分析在feature工程中。我们想要更深入了解 periodic 变化 Airbnb 租赁价格。我们项目的主要目标是在奥斯汀、得克萨斯建立准确的机器学习模型，预测 Airbnb 租赁价格。我们项目的次要目标是确定 Airbnb 租赁价格的关键因素，以及这些因素在不同的地点和房型上如何变化。
</details></li>
</ul>
<hr>
<h2 id="CBA-Improving-Online-Continual-Learning-via-Continual-Bias-Adaptor"><a href="#CBA-Improving-Online-Continual-Learning-via-Continual-Bias-Adaptor" class="headerlink" title="CBA: Improving Online Continual Learning via Continual Bias Adaptor"></a>CBA: Improving Online Continual Learning via Continual Bias Adaptor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06925">http://arxiv.org/abs/2308.06925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wqza/cba-online-cl">https://github.com/wqza/cba-online-cl</a></li>
<li>paper_authors: Quanziang Wang, Renzhen Wang, Yichen Wu, Xixi Jia, Deyu Meng</li>
<li>for: 提高在非站ARY数据流中进行在线 continual learning（CL）的能力，以抵御数据流中的 Distribution shift 问题。</li>
<li>methods: 提出了一种 Continual Bias Adaptor（CBA）模块，用于在训练过程中增强分类器网络，以适应不断变化的数据分布，从而保持 previously learned tasks 的稳定整合。</li>
<li>results: 通过理论分析和实验测试，证明了 CBA 模块的有效性，并与四种基eline和三个公共的 continual learning  benchmark 进行了广泛的比较。<details>
<summary>Abstract</summary>
Online continual learning (CL) aims to learn new knowledge and consolidate previously learned knowledge from non-stationary data streams. Due to the time-varying training setting, the model learned from a changing distribution easily forgets the previously learned knowledge and biases toward the newly received task. To address this problem, we propose a Continual Bias Adaptor (CBA) module to augment the classifier network to adapt to catastrophic distribution change during training, such that the classifier network is able to learn a stable consolidation of previously learned tasks. In the testing stage, CBA can be removed which introduces no additional computation cost and memory overhead. We theoretically reveal the reason why the proposed method can effectively alleviate catastrophic distribution shifts, and empirically demonstrate its effectiveness through extensive experiments based on four rehearsal-based baselines and three public continual learning benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Novel-Ehanced-Move-Recognition-Algorithm-Based-on-Pre-trained-Models-with-Positional-Embeddings"><a href="#A-Novel-Ehanced-Move-Recognition-Algorithm-Based-on-Pre-trained-Models-with-Positional-Embeddings" class="headerlink" title="A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models with Positional Embeddings"></a>A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models with Positional Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10822">http://arxiv.org/abs/2308.10822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wen, Jie Wang, Xiaodong Qiao</li>
<li>for: 本研究旨在提高中文科技论文摘要中的 Move 识别精度。</li>
<li>methods: 该算法使用了改进的预训练模型和笛卡尔网络听力机制，以获取摘要中的字符位信息，进而提高深度 semantics 学习和targeted 特征提取。</li>
<li>results: 实验结果表明，提案的算法相比原始数据集，在分割数据集上达到了13.37% 高的准确率，并与基础对比模型相比，提高了7.55%。<details>
<summary>Abstract</summary>
The recognition of abstracts is crucial for effectively locating the content and clarifying the article. Existing move recognition algorithms lack the ability to learn word position information to obtain contextual semantics. This paper proposes a novel enhanced move recognition algorithm with an improved pre-trained model and a gated network with attention mechanism for unstructured abstracts of Chinese scientific and technological papers. The proposed algorithm first performs summary data segmentation and vocabulary training. The EP-ERNIE$\_$AT-GRU framework is leveraged to incorporate word positional information, facilitating deep semantic learning and targeted feature extraction. Experimental results demonstrate that the proposed algorithm achieves 13.37$\%$ higher accuracy on the split dataset than on the original dataset and a 7.55$\%$ improvement in accuracy over the basic comparison model.
</details>
<details>
<summary>摘要</summary>
“摘要识别是对中文科技论文内容的效果搜索和解释的关键。现有的移动识别算法缺乏 Contextual semantics 的学习能力。本文提出了一种新的增强移动识别算法，包括改进的预训练模型和闭合网络带有注意力机制，以提高中文科技论文的摘要中的字位信息。提议的算法首先执行摘要数据分 segmentation 和词汇训练。EP-ERNIE $\_$ AT-GRU 框架被利用，以包括字位信息，促进深层 semantic learning 和targeted feature extraction。实验结果表明，提议的算法在分 Split 集上比原始集上的准确率高出 13.37%，与基本比较模型的准确率高出 7.55%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="CausalLM-is-not-optimal-for-in-context-learning"><a href="#CausalLM-is-not-optimal-for-in-context-learning" class="headerlink" title="CausalLM is not optimal for in-context learning"></a>CausalLM is not optimal for in-context learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06912">http://arxiv.org/abs/2308.06912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Ding, Tomer Levinboim, Jialin Wu, Sebastian Goodman, Radu Soricut</li>
<li>for: 本研究旨在理解 prefixLM 和 causalLM 在理论上的异同，以及它们在不同任务上的表现。</li>
<li>methods: 本研究使用了一种特定的参数构造来分析 prefixLM 和 causalLM 的收敛行为。</li>
<li>results: 我们的分析显示，prefixLM 在Linear Regression的优点点上收敛，而 causalLM 的收敛 dynamics 类似于在线 gradient descent 算法，不是 garantied 为优化的，即使样本数量在无穷大。我们的实验结果也表明， causalLM 在所有任务上一直下perform prefixLM。<details>
<summary>Abstract</summary>
Recent empirical evidence indicates that transformer based in-context learning performs better when using a prefix language model (prefixLM), in which in-context samples can all attend to each other, compared to causal language models (causalLM), which use auto-regressive attention that prohibits in-context samples to attend to future samples. While this result is intuitive, it is not understood from a theoretical perspective. In this paper we take a theoretical approach and analyze the convergence behavior of prefixLM and causalLM under a certain parameter construction. Our analysis shows that both LM types converge to their stationary points at a linear rate, but that while prefixLM converges to the optimal solution of linear regression, causalLM convergence dynamics follows that of an online gradient descent algorithm, which is not guaranteed to be optimal even as the number of samples grows infinitely. We supplement our theoretical claims with empirical experiments over synthetic and real tasks and using various types of transformers. Our experiments verify that causalLM consistently underperforms prefixLM in all settings.
</details>
<details>
<summary>摘要</summary>
近期实验证据表明，基于转换器的受Context学习（prefixLM）在比 causalLM（causalLM）的情况下表现更好，这两种语言模型的区别在于，前一种使用预测语言模型，可以让所有的受Context样本都可以互相注意，而后一种使用自动递归注意力，这会禁止受Context样本注意到未来的样本。虽然这个结果很直观，但是从理论角度来看还不够了解。在这篇论文中，我们采用理论方法，分析了 prefixLM 和 causalLM 两种语言模型在某些参数构造下的收敛行为。我们的分析表明，两种LM类型在线性收敛，但是 prefixLM  converge 到线性回归的优秀解，而 causalLM 的收敛动态类似于在线上梯度下降算法，这并不是 garantate 为INF 多个样本收敛到优秀解。我们在实验中验证了这些理论声明，通过在 sintetic 和实际任务上进行了多种 transformer 的实验，并发现 causalLM 在所有设置下 consistently underperform prefixLM。
</details></li>
</ul>
<hr>
<h2 id="GIT-Mol-A-Multi-modal-Large-Language-Model-for-Molecular-Science-with-Graph-Image-and-Text"><a href="#GIT-Mol-A-Multi-modal-Large-Language-Model-for-Molecular-Science-with-Graph-Image-and-Text" class="headerlink" title="GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"></a>GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06911">http://arxiv.org/abs/2308.06911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengfei Liu, Yiming Ren, Zhixiang Ren</li>
<li>for: 本研究旨在开发一种多模态大语言模型，以捕捉分子数据中的丰富和复杂信息。</li>
<li>methods: 本研究使用GIT-Mol模型，该模型结合结构图、图像和文本信息，包括简化分子输入线Entry系统（SMILES）和分子caption。为了实现多Modal数据的集成，我们提出了GIT-Former模型，可以将所有模式映射到一个统一的幽默空间。</li>
<li>results: 我们开发了一种创新的任意语言分子翻译策略，比基线或单模态模型提高了10%-15%的分子描述率，提高了5%-10%的物理预测精度，并提高了20%的分子生成有效性。<details>
<summary>Abstract</summary>
Large language models have made significant strides in natural language processing, paving the way for innovative applications including molecular representation and generation. However, most existing single-modality approaches cannot capture the abundant and complex information in molecular data. Here, we introduce GIT-Mol, a multi-modal large language model that integrates the structure Graph, Image, and Text information, including the Simplified Molecular Input Line Entry System (SMILES) and molecular captions. To facilitate the integration of multi-modal molecular data, we propose GIT-Former, a novel architecture capable of mapping all modalities into a unified latent space. Our study develops an innovative any-to-language molecular translation strategy and achieves a 10%-15% improvement in molecular captioning, a 5%-10% accuracy increase in property prediction, and a 20% boost in molecule generation validity compared to baseline or single-modality models.
</details>
<details>
<summary>摘要</summary>
大型语言模型已经做出了很大的进步，导致了创新的应用，如分子表示和生成。但是，现有的单一模式方法通常无法捕捉分子数据中的实际和复杂的信息。在这里，我们介绍GIT-Mol，一个多模式大语言模型，它统合了分子结构graph、图像和文本信息，包括简润分子输入语系 (SMILES) 和分子描述。为了促进多模式分子数据的集成，我们提出GIT-Former，一个新的架构，可以将所有模式转换到一个统一的隐藏空间中。我们的研究开发了一种创新的任意语言分子翻译策略，并在分子描述、性能预测和分子生成效果上实现了10%-15%的改善、5%-10%的精度提高和20%的效果提高，相比基准或单一模式模型。
</details></li>
</ul>
<hr>
<h2 id="Generative-Interpretation"><a href="#Generative-Interpretation" class="headerlink" title="Generative Interpretation"></a>Generative Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06907">http://arxiv.org/abs/2308.06907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yonathanarbel/generativeinterpretation">https://github.com/yonathanarbel/generativeinterpretation</a></li>
<li>paper_authors: Yonathan A. Arbel, David Hoffman</li>
<li>for:  This paper aims to introduce a new approach to estimating contractual meaning using large language models.</li>
<li>methods: The paper uses grounded case studies to illustrate the capabilities of these novel tools in distinct ways, such as ascertaining ordinary meaning in context, quantifying ambiguity, filling gaps in parties’ agreements, and calculating the probative value of individual pieces of extrinsic evidence.</li>
<li>results: The paper shows that AI models can help factfinders accurately estimate what the parties intended, and that generative interpretation can unsettle the current interpretative stalemate between efficiency-minded textualists and justice-oriented contextualists.<details>
<summary>Abstract</summary>
We introduce generative interpretation, a new approach to estimating contractual meaning using large language models. As AI triumphalism is the order of the day, we proceed by way of grounded case studies, each illustrating the capabilities of these novel tools in distinct ways. Taking well-known contracts opinions, and sourcing the actual agreements that they adjudicated, we show that AI models can help factfinders ascertain ordinary meaning in context, quantify ambiguity, and fill gaps in parties' agreements. We also illustrate how models can calculate the probative value of individual pieces of extrinsic evidence. After offering best practices for the use of these models given their limitations, we consider their implications for judicial practice and contract theory. Using LLMs permits courts to estimate what the parties intended cheaply and accurately, and as such generative interpretation unsettles the current interpretative stalemate. Their use responds to efficiency-minded textualists and justice-oriented contextualists, who argue about whether parties will prefer cost and certainty or accuracy and fairness. Parties--and courts--would prefer a middle path, in which adjudicators strive to predict what the contract really meant, admitting just enough context to approximate reality while avoiding unguided and biased assimilation of evidence. As generative interpretation offers this possibility, we argue it can become the new workhorse of contractual interpretation.
</details>
<details>
<summary>摘要</summary>
我们介绍生成解释，一种新的合约解释方法使用大型自然语言模型。随着人工智能豪语气势日益增长，我们透过实际案例进行grounded的应用，每个案例都展示了这些新工具在不同方面的能力。从知名合约案例和实际契约中获取了诉讼官员可能需要了解的资讯，我们示出AI模型可以帮助诉讼官员了解合约的内容意义，衡量内容的模糊性，填充点数和契约中的漏洞。我们还示出了AI模型可以评估个别外部证据的证据价值。在提供了最佳实践方法后，我们考虑了这些模型的局限性和影响，并探讨它们对法律实践和合约理论的影响。使用LLMs可以让法院估算合约的意思便宜且精确，因此生成解释会使现有的解释僵局破产。这种方法可以满足效率主义者和正义主义者的需求，他们认为党籍人将偏好成本和可靠性或精确和公正。党籍人和法院都偏好一条中路，在这条路上，仲裁官员将努力预测合约的真正意思，接受足够的文本背景，以避免无方向和偏袋的证据融合。因此，我们认为生成解释将成为未来合约解释的主要工具。
</details></li>
</ul>
<hr>
<h2 id="Federated-Classification-in-Hyperbolic-Spaces-via-Secure-Aggregation-of-Convex-Hulls"><a href="#Federated-Classification-in-Hyperbolic-Spaces-via-Secure-Aggregation-of-Convex-Hulls" class="headerlink" title="Federated Classification in Hyperbolic Spaces via Secure Aggregation of Convex Hulls"></a>Federated Classification in Hyperbolic Spaces via Secure Aggregation of Convex Hulls</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06895">http://arxiv.org/abs/2308.06895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurav Prakash, Jin Sima, Chao Pan, Eli Chien, Olgica Milenkovic</li>
<li>for: 这个论文旨在解决在分布式和隐私化的设置下进行 Federated Learning 的问题，特别是在 hyperbolic spaces 中进行分类。</li>
<li>methods: 本文提出了一种首次在 hyperbolic spaces 中进行 Federated Classification 的方法，包括分布式版本的 convex SVM 分类器，integer $B_h$ 序列来解决标签替换问题，以及基于 Poincaré 盘的量化方法来限制数据泄露。</li>
<li>results: 本文通过测试多种多样化的数据集，包括具有层次结构的单元细胞 RNA-seq 数据，demonstrated 该方法可以提高分类精度，比其欧几何空间中的对应方法更好。<details>
<summary>Abstract</summary>
Hierarchical and tree-like data sets arise in many applications, including language processing, graph data mining, phylogeny and genomics. It is known that tree-like data cannot be embedded into Euclidean spaces of finite dimension with small distortion. This problem can be mitigated through the use of hyperbolic spaces. When such data also has to be processed in a distributed and privatized setting, it becomes necessary to work with new federated learning methods tailored to hyperbolic spaces. As an initial step towards the development of the field of federated learning in hyperbolic spaces, we propose the first known approach to federated classification in hyperbolic spaces. Our contributions are as follows. First, we develop distributed versions of convex SVM classifiers for Poincar\'e discs. In this setting, the information conveyed from clients to the global classifier are convex hulls of clusters present in individual client data. Second, to avoid label switching issues, we introduce a number-theoretic approach for label recovery based on the so-called integer $B_h$ sequences. Third, we compute the complexity of the convex hulls in hyperbolic spaces to assess the extent of data leakage; at the same time, in order to limit the communication cost for the hulls, we propose a new quantization method for the Poincar\'e disc coupled with Reed-Solomon-like encoding. Fourth, at server level, we introduce a new approach for aggregating convex hulls of the clients based on balanced graph partitioning. We test our method on a collection of diverse data sets, including hierarchical single-cell RNA-seq data from different patients distributed across different repositories that have stringent privacy constraints. The classification accuracy of our method is up to $\sim 11\%$ better than its Euclidean counterpart, demonstrating the importance of privacy-preserving learning in hyperbolic spaces.
</details>
<details>
<summary>摘要</summary>
随着应用领域的发展，树状和树状数据在语言处理、图数据挖掘、phylogeny和 genomics 等领域中变得越来越普遍。然而，树状数据无法在有限维度的欧式空间中嵌入，这会导致数据泄露问题。为解决这问题，我们可以使用拥有不同维度的几何空间。在分布式和隐私化的设置下，我们需要采用特有的联邦学习方法，以适应几何空间中的树状数据。为开拓联邦学习在几何空间中的领域，我们提出了首个已知的联邦分类方法。我们的贡献如下：1. 我们开发了分布式版本的 convex SVM 分类器，适用于Poincaré盘中的数据。在这个设置下，客户端上的信息都是各个客户端数据中的凸集。2. 为避免标签交换问题，我们引入了一种数学基础的方法，基于 so-called 整数 $B_h$ 序列。3. 我们计算了几何空间中凸集的复杂度，以评估数据泄露的程度。同时，我们提出了一种新的量化方法，用于压缩 Poincaré 盘。4. 在服务器端，我们引入了一种新的方法，用于将客户端上的凸集聚合到 Balanced Graph Partitioning 中。我们对一些多样化的数据集进行测试，包括不同病人的单元细胞 RNA-seq 数据，分布在不同的存储库中，具有严格的隐私限制。我们的方法的分类精度比其欧式对应方法高出至多 11%，这说明了隐私保护在几何空间中的重要性。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Offline-Online-Evaluation-with-a-Time-dependent-and-Popularity-Bias-free-Offline-Metric-for-Recommenders"><a href="#Bridging-Offline-Online-Evaluation-with-a-Time-dependent-and-Popularity-Bias-free-Offline-Metric-for-Recommenders" class="headerlink" title="Bridging Offline-Online Evaluation with a Time-dependent and Popularity Bias-free Offline Metric for Recommenders"></a>Bridging Offline-Online Evaluation with a Time-dependent and Popularity Bias-free Offline Metric for Recommenders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06885">http://arxiv.org/abs/2308.06885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Petr Kasalický, Rodrigo Alves, Pavel Kordík</li>
<li>for: 评估推荐系统的效果是一项复杂的任务。在线和离线评估指标对推荐系统的真正目标存在偏误。大多数最近发表的论文使用不精准的离线评估方法来评估其方法的性能，从而削弱了学术研究对实际应用的影响。</li>
<li>methods: 我们研究了和评估推荐系统在线性能相关的离线评估指标。我们发现，惩罚受欢迎的Item和考虑交易时间在评估中可以提高我们选择最佳推荐模型的能力。</li>
<li>results: 我们对五个大规模的实际应用数据进行了测试，并发现，使用我们提出的离线评估指标可以更好地反映推荐系统在线性能。这些结果可以帮助学术界更好地理解离线评估和优化的标准，以便更好地应用推荐系统。<details>
<summary>Abstract</summary>
The evaluation of recommendation systems is a complex task. The offline and online evaluation metrics for recommender systems are ambiguous in their true objectives. The majority of recently published papers benchmark their methods using ill-posed offline evaluation methodology that often fails to predict true online performance. Because of this, the impact that academic research has on the industry is reduced. The aim of our research is to investigate and compare the online performance of offline evaluation metrics. We show that penalizing popular items and considering the time of transactions during the evaluation significantly improves our ability to choose the best recommendation model for a live recommender system. Our results, averaged over five large-size real-world live data procured from recommenders, aim to help the academic community to understand better offline evaluation and optimization criteria that are more relevant for real applications of recommender systems.
</details>
<details>
<summary>摘要</summary>
评估推荐系统的复杂性使得评估方法存在各种问题。在线和离线评估指标对于推荐系统来说是不确定的。大多数最近发表的论文使用不精准的离线评估方法来评估自己的方法，这会导致实际在线性能与评估结果存在差异。这种情况使得学术研究对于实际应用的影响减少。我们的研究目标是研究和比较在线评估指标的表现。我们发现，对 популяр item 进行 penalty 和在评估过程中考虑交易时间可以显著改善我们选择最佳推荐模型的能力。我们的结果，基于五个大型实际生产环境中的真实数据， hopes to help学术界更好地理解推荐系统的离线评估和优化标准，以便更好地应用于实际推荐系统中。
</details></li>
</ul>
<hr>
<h2 id="Multi-Receiver-Task-Oriented-Communications-via-Multi-Task-Deep-Learning"><a href="#Multi-Receiver-Task-Oriented-Communications-via-Multi-Task-Deep-Learning" class="headerlink" title="Multi-Receiver Task-Oriented Communications via Multi-Task Deep Learning"></a>Multi-Receiver Task-Oriented Communications via Multi-Task Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06884">http://arxiv.org/abs/2308.06884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus</li>
<li>for: 本研究探讨了任务导向的通信系统，在 transmitter 与多个接收器之间进行交互，每个接收器都需要完成自己的任务，例如图像分类等，并在 transmitter 上训练共享encoder和每个接收器上的专门decoder。</li>
<li>methods: 该方法使用多任务深度学习来实现多任务的共同优化和多接收器之间的通信，并通过在边缘的6G网络中进行有效的资源分配，以适应不同的通信频道条件，并最小化传输过程中的过载。</li>
<li>results: 实验结果表明，相比单任务导向的通信系统，多任务导向的通信系统可以更好地适应不同的任务和通信环境，并且可以提高图像分类精度和资源利用率。<details>
<summary>Abstract</summary>
This paper studies task-oriented, otherwise known as goal-oriented, communications, in a setting where a transmitter communicates with multiple receivers, each with its own task to complete on a dataset, e.g., images, available at the transmitter. A multi-task deep learning approach that involves training a common encoder at the transmitter and individual decoders at the receivers is presented for joint optimization of completing multiple tasks and communicating with multiple receivers. By providing efficient resource allocation at the edge of 6G networks, the proposed approach allows the communications system to adapt to varying channel conditions and achieves task-specific objectives while minimizing transmission overhead. Joint training of the encoder and decoders using multi-task learning captures shared information across tasks and optimizes the communication process accordingly. By leveraging the broadcast nature of wireless communications, multi-receiver task-oriented communications (MTOC) reduces the number of transmissions required to complete tasks at different receivers. Performance evaluation conducted on the MNIST, Fashion MNIST, and CIFAR-10 datasets (with image classification considered for different tasks) demonstrates the effectiveness of MTOC in terms of classification accuracy and resource utilization compared to single-task-oriented communication systems.
</details>
<details>
<summary>摘要</summary>
Performance evaluation on the MNIST, Fashion MNIST, and CIFAR-10 datasets (with image classification considered for different tasks) demonstrates the effectiveness of task-oriented communication in terms of classification accuracy and resource utilization.
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Outlierness-of-Funds-from-their-Categories-using-Supervised-Similarity"><a href="#Quantifying-Outlierness-of-Funds-from-their-Categories-using-Supervised-Similarity" class="headerlink" title="Quantifying Outlierness of Funds from their Categories using Supervised Similarity"></a>Quantifying Outlierness of Funds from their Categories using Supervised Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06882">http://arxiv.org/abs/2308.06882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhruv Desai, Ashmita Dhiman, Tushar Sharma, Deepika Sharma, Dhagash Mehta, Stefano Pasquali</li>
<li>For: 本研究旨在量化基金分类错误的影响，并提出一种基于机器学习的方法来检测和识别基金分类错误。* Methods: 本研究使用Random Forest方法进行距离度量学习，计算每个数据点的类别异常指标，以识别基金分类错误。* Results: 研究发现基金分类错误与未来回报之间存在强相关关系，并讨论了这些结果的意义。<details>
<summary>Abstract</summary>
Mutual fund categorization has become a standard tool for the investment management industry and is extensively used by allocators for portfolio construction and manager selection, as well as by fund managers for peer analysis and competitive positioning. As a result, a (unintended) miscategorization or lack of precision can significantly impact allocation decisions and investment fund managers. Here, we aim to quantify the effect of miscategorization of funds utilizing a machine learning based approach. We formulate the problem of miscategorization of funds as a distance-based outlier detection problem, where the outliers are the data-points that are far from the rest of the data-points in the given feature space. We implement and employ a Random Forest (RF) based method of distance metric learning, and compute the so-called class-wise outlier measures for each data-point to identify outliers in the data. We test our implementation on various publicly available data sets, and then apply it to mutual fund data. We show that there is a strong relationship between the outlier measures of the funds and their future returns and discuss the implications of our findings.
</details>
<details>
<summary>摘要</summary>
资金基金分类已成为投资管理industry的标准工具，广泛用于分配和资金经理选择，以及资金管理人员用于对比分析和竞争位置。因此，任意错误分类或缺乏精度可能对分配决策和投资基金产生深远的影响。在这里，我们想要量化基金分类错误的影响，使用机器学习基于的方法。我们将基金分类问题定义为一个距离度量学习问题，其中异常数据点是与其他数据点在给定特征空间的距离最远的数据点。我们实现了Random Forest（RF）基于的距离度量学习方法，并计算每个数据点的类别异常度量来标识异常数据点。我们在各种公开可用的数据集上测试了我们的实现，然后应用于基金数据。我们发现，基金异常度量和未来回报之间存在强相关关系，并讨论了我们的发现的意义。
</details></li>
</ul>
<hr>
<h2 id="AutoSeqRec-Autoencoder-for-Efficient-Sequential-Recommendation"><a href="#AutoSeqRec-Autoencoder-for-Efficient-Sequential-Recommendation" class="headerlink" title="AutoSeqRec: Autoencoder for Efficient Sequential Recommendation"></a>AutoSeqRec: Autoencoder for Efficient Sequential Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06878">http://arxiv.org/abs/2308.06878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sliu675/autoseqrec">https://github.com/sliu675/autoseqrec</a></li>
<li>paper_authors: Sijia Liu, Jiahao Liu, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu</li>
<li>for: 这篇论文主要针对继承推荐任务，旨在提供一种高效可靠的继承推荐方法。</li>
<li>methods: 该方法基于自适应器，包括一个编码器和三个解码器，它们考虑了用户-项交互矩阵和项过渡矩阵的行列。</li>
<li>results: 对比其他方法，AutoSeqRec显示了更高的准确率，同时具有更好的可靠性和效率。<details>
<summary>Abstract</summary>
Sequential recommendation demonstrates the capability to recommend items by modeling the sequential behavior of users. Traditional methods typically treat users as sequences of items, overlooking the collaborative relationships among them. Graph-based methods incorporate collaborative information by utilizing the user-item interaction graph. However, these methods sometimes face challenges in terms of time complexity and computational efficiency. To address these limitations, this paper presents AutoSeqRec, an incremental recommendation model specifically designed for sequential recommendation tasks. AutoSeqRec is based on autoencoders and consists of an encoder and three decoders within the autoencoder architecture. These components consider both the user-item interaction matrix and the rows and columns of the item transition matrix. The reconstruction of the user-item interaction matrix captures user long-term preferences through collaborative filtering. In addition, the rows and columns of the item transition matrix represent the item out-degree and in-degree hopping behavior, which allows for modeling the user's short-term interests. When making incremental recommendations, only the input matrices need to be updated, without the need to update parameters, which makes AutoSeqRec very efficient. Comprehensive evaluations demonstrate that AutoSeqRec outperforms existing methods in terms of accuracy, while showcasing its robustness and efficiency.
</details>
<details>
<summary>摘要</summary>
带有顺序推荐的模型可以根据用户的顺序行为来推荐项目。传统方法通常将用户看作为序列中的项目，忽略了用户之间的协同关系。基于图的方法可以包含协同信息，但是它们有时会面临时间复杂度和计算效率的限制。为了解决这些限制，这篇论文提出了 AutoSeqRec，一种特点是适用于顺序推荐任务的增量推荐模型。AutoSeqRec基于自适应器，包括一个Encoder和三个解码器。这些组件考虑了用户-项目交互矩阵和行列式的项目过渡矩阵。重建用户-项目交互矩阵可以捕捉用户长期的偏好，通过协同筛选。此外，行列式的项目过渡矩阵表示用户短期的兴趣，允许模型化用户的短期偏好。在进行增量推荐时，只需更新输入矩阵，无需更新参数，这使得AutoSeqRec非常高效。 comprehensive评估表明，AutoSeqRec在准确性方面超过了现有方法，并展示了其稳定性和高效性。
</details></li>
</ul>
<hr>
<h2 id="SpeechX-Neural-Codec-Language-Model-as-a-Versatile-Speech-Transformer"><a href="#SpeechX-Neural-Codec-Language-Model-as-a-Versatile-Speech-Transformer" class="headerlink" title="SpeechX: Neural Codec Language Model as a Versatile Speech Transformer"></a>SpeechX: Neural Codec Language Model as a Versatile Speech Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06873">http://arxiv.org/abs/2308.06873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaofei Wang, Manthan Thakker, Zhuo Chen, Naoyuki Kanda, Sefik Emre Eskimez, Sanyuan Chen, Min Tang, Shujie Liu, Jinyu Li, Takuya Yoshioka</li>
<li>for: 高质量零批text-to-speech创新和多种语音转换任务</li>
<li>methods:  neural codec语言模型+多任务学习+任务dependent prompting</li>
<li>results: 在多种任务中表现优秀，包括零批TTS、噪声抑制、目标 speaker提取、speech removing和speech editing等，与专门模型相当或更高的性能<details>
<summary>Abstract</summary>
Recent advancements in generative speech models based on audio-text prompts have enabled remarkable innovations like high-quality zero-shot text-to-speech. However, existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions. This paper introduces SpeechX, a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals. SpeechX combines neural codec language modeling with multi-task learning using task-dependent prompting, enabling unified and extensible modeling and providing a consistent way for leveraging textual input in speech enhancement and transformation tasks. Experimental results show SpeechX's efficacy in various tasks, including zero-shot TTS, noise suppression, target speaker extraction, speech removal, and speech editing with or without background noise, achieving comparable or superior performance to specialized models across tasks. See https://aka.ms/speechx for demo samples.
</details>
<details>
<summary>摘要</summary>
近期，基于音频文本提示的生成术语模型得到了很大的进步，可以实现高质量的零shot文本至语音转化。然而，现有模型仍然面临着处理多样化音频文本术语生成任务的限制，包括转化输入语音和处理附带噪声的audio捕获条件。本文介绍SpeechX，一种通用的术语生成模型，可以实现零shot TTS和多种术语转换任务，并处理干净和噪声信号。SpeechX通过神经编码语言模型和多任务学习，使用任务特定的提示，实现了一个统一和可扩展的模型，可以通过文本输入来进行语音提高和转换任务。实验结果表明SpeechX在多种任务中具有优秀的表现，包括零shot TTS、噪声减少、目标说话人EXTRACTION、语音删除和语音编辑等，与专门的模型相比，在任务中表现相当或更高。请参考https://aka.ms/speechx查看示例样本。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Dual-Stream-Self-Attentive-Adversarial-Graph-Contrastive-Learning-for-Cross-Subject-EEG-based-Emotion-Recognition"><a href="#Semi-Supervised-Dual-Stream-Self-Attentive-Adversarial-Graph-Contrastive-Learning-for-Cross-Subject-EEG-based-Emotion-Recognition" class="headerlink" title="Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive Learning for Cross-Subject EEG-based Emotion Recognition"></a>Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive Learning for Cross-Subject EEG-based Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11635">http://arxiv.org/abs/2308.11635</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weishan Ye, Zhiguo Zhang, Min Zhang, Fei Teng, Li Zhang, Linling Li, Gan Huang, Jianhong Wang, Dong Ni, Zhen Liang<br>for: 本研究旨在解决脑波Emotion recognition中数据标注率的限制问题，提高脑波Emotion recognition的精度和可靠性。methods: 本研究提出了一种基于Self-Attentive Adversarial Graph Contrastive learning的半supervised Dual-stream架构（简称DS-AGC），包括两个平行流处理非结构和结构脑波特征。非结构流使用半supervised多域适应方法来减轻来源频率域和目标频率域之间的分布差异。结构流开发了图像异构学习方法来提取多个EEG渠道之间的有效特征表示。此外，一种自注意 fusion模块也被提出，用于特征融合、样本选择和情绪识别，其中更加注重EEG特征与数据样本在标签源频率域中更加相关的部分。results: 经过对两个 benchmark数据库（SEED和SEED-IV）进行了大规模的实验，结果表明，提出的模型在不同的受测 incomplete label 条件下（包括标签率不同的情况）表现出了5.83%和6.99%的提高在SEED和SEED-IV数据库上，证明了该模型在跨主体EEG Emotion recognition中有效地解决了标签稀缺问题。<details>
<summary>Abstract</summary>
Electroencephalography (EEG) is an objective tool for emotion recognition with promising applications. However, the scarcity of labeled data remains a major challenge in this field, limiting the widespread use of EEG-based emotion recognition. In this paper, a semi-supervised Dual-stream Self-Attentive Adversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed to tackle the challenge of limited labeled data in cross-subject EEG-based emotion recognition. The DS-AGC framework includes two parallel streams for extracting non-structural and structural EEG features. The non-structural stream incorporates a semi-supervised multi-domain adaptation method to alleviate distribution discrepancy among labeled source domain, unlabeled source domain, and unknown target domain. The structural stream develops a graph contrastive learning method to extract effective graph-based feature representation from multiple EEG channels in a semi-supervised manner. Further, a self-attentive fusion module is developed for feature fusion, sample selection, and emotion recognition, which highlights EEG features more relevant to emotions and data samples in the labeled source domain that are closer to the target domain. Extensive experiments conducted on two benchmark databases (SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out cross-validation evaluation scheme show that the proposed model outperforms existing methods under different incomplete label conditions (with an average improvement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its effectiveness in addressing the label scarcity problem in cross-subject EEG-based emotion recognition.
</details>
<details>
<summary>摘要</summary>
电子脑电图像 (EEG) 是一种客观工具 для情感识别，具有广泛的应用前景。然而，有限的标签数据仍然是这一领域的主要挑战，限制了 EEG 基于情感识别的普及使用。在这篇论文中，一种半supervised dual-stream自我注意力对抗图像学习框架（简称 DS-AGC）被提出，以解决跨主体 EEG 基于情感识别的标签稀缺问题。DS-AGC 框架包括两个并行的流动，用于提取非结构化和结构化 EEG 特征。非结构化流动利用半supervised多域适应方法，以减轻不同标签领域之间的分布差异。结构化流动开发了图像学习方法，以提取多个 EEG 通道之间的有效图像特征表示。此外，一个自我注意力融合模块被开发，用于特征融合、样本选择和情感识别，并强调 EEG 特征更加 relevante 于情感和数据样本在标签领域中更加接近的目标领域。广泛的实验在两个标准数据库（SEED 和 SEED-IV）上进行，使用半supervised cross-subject leave-one-subject-out 跨领域验证方式，显示提出的模型在不同的标签缺失情况下（SEED 上的平均提升率为 5.83%，SEED-IV 上的平均提升率为 6.99%），表明其能够有效地解决跨主体 EEG 基于情感识别的标签稀缺问题。
</details></li>
</ul>
<hr>
<h2 id="Effect-of-Choosing-Loss-Function-when-Using-T-batching-for-Representation-Learning-on-Dynamic-Networks"><a href="#Effect-of-Choosing-Loss-Function-when-Using-T-batching-for-Representation-Learning-on-Dynamic-Networks" class="headerlink" title="Effect of Choosing Loss Function when Using T-batching for Representation Learning on Dynamic Networks"></a>Effect of Choosing Loss Function when Using T-batching for Representation Learning on Dynamic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06862">http://arxiv.org/abs/2308.06862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/erfanloghmani/effect-of-loss-function-tbatching">https://github.com/erfanloghmani/effect-of-loss-function-tbatching</a></li>
<li>paper_authors: Erfan Loghmani, MohammadAmin Fazli</li>
<li>for: 这篇论文旨在探讨静态网络模型的动态学习方法，以提高网络模型的训练效率和准确性。</li>
<li>methods: 本论文提出了两种替代训练损失函数，并通过数学分析显示了这些损失函数可以解决训练损失函数中的问题，提高训练性能。</li>
<li>results: 实验结果显示，将这两种替代损失函数应用于训练静态网络模型可以提高模型的训练效率和准确性，特别是在实际世界的动态网络上。<details>
<summary>Abstract</summary>
Representation learning methods have revolutionized machine learning on networks by converting discrete network structures into continuous domains. However, dynamic networks that evolve over time pose new challenges. To address this, dynamic representation learning methods have gained attention, offering benefits like reduced learning time and improved accuracy by utilizing temporal information.   T-batching is a valuable technique for training dynamic network models that reduces training time while preserving vital conditions for accurate modeling. However, we have identified a limitation in the training loss function used with t-batching. Through mathematical analysis, we propose two alternative loss functions that overcome these issues, resulting in enhanced training performance.   We extensively evaluate the proposed loss functions on synthetic and real-world dynamic networks. The results consistently demonstrate superior performance compared to the original loss function. Notably, in a real-world network characterized by diverse user interaction histories, the proposed loss functions achieved more than 26.9% enhancement in Mean Reciprocal Rank (MRR) and more than 11.8% improvement in Recall@10. These findings underscore the efficacy of the proposed loss functions in dynamic network modeling.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>机器学习在网络上进行了革命，通过将分类网络结构转换为连续域。然而，时间演化的网络却提出了新的挑战。为此，动态表示学习方法在抓取到关注。这些方法可以减少学习时间，并使用时间信息提高准确性。 T-批处理是训练动态网络模型的有价值技术，可以降低训练时间，保持模型准确的条件。然而，我们发现在使用 t-批处理时的训练损失函数中存在一定的限制。通过数学分析，我们提出了两种替代的损失函数，可以解决这些问题，从而提高训练性能。我们对提出的损失函数进行了广泛的评估，在 sintetic 和实际的动态网络上进行了测试。结果表明，提出的损失函数在动态网络模型训练中具有显著优势，与原始损失函数相比，可以提高 Mean Reciprocal Rank（MRR）的表现至少26.9%，并提高 Recall@10 的表现至少11.8%。这些发现证明了我们提出的损失函数在动态网络模型中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Offensive-Gameplan-in-the-National-Basketball-Association-with-Machine-Learning"><a href="#Optimizing-Offensive-Gameplan-in-the-National-Basketball-Association-with-Machine-Learning" class="headerlink" title="Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning"></a>Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06851">http://arxiv.org/abs/2308.06851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eamon Mukhopadhyay</li>
<li>for: 本研究的目的是确认Stats的有效性，以及将Stats与NBA比赛类型之间建立关联性。</li>
<li>methods: 本研究使用了机器学习技术，选择了一组特定的特征，以评估Stats的有效性。 linear regression 模型和对应性网络模型都被用来检验Stats 的跟踪能力。</li>
<li>results: 研究发现，使用ORTG 的 linear regression 模型和对应性网络模型都能够与不同的NBA比赛类型建立关联性。然而，使用对应性网络模型的精度较高。通过对模型的调整，研究人员发现了一组特定的特征，可以帮助建立一个高效的进攻策略。<details>
<summary>Abstract</summary>
Throughout the analytical revolution that has occurred in the NBA, the development of specific metrics and formulas has given teams, coaches, and players a new way to see the game. However - the question arises - how can we verify any metrics? One method would simply be eyeball approximation (trying out many different gameplans) and/or trial and error - an estimation-based and costly approach. Another approach is to try to model already existing metrics with a unique set of features using machine learning techniques. The key to this approach is that with these features that are selected, we can try to gauge the effectiveness of these features combined, rather than using individual analysis in simple metric evaluation. If we have an accurate model, it can particularly help us determine the specifics of gameplan execution. In this paper, the statistic ORTG (Offensive Rating, developed by Dean Oliver) was found to have a correlation with different NBA playtypes using both a linear regression model and a neural network regression model, although ultimately, a neural network worked slightly better than linear regression. Using the accuracy of the models as a justification, the next step was to optimize the output of the model with test examples, which would demonstrate the combination of features to best achieve a highly functioning offense.
</details>
<details>
<summary>摘要</summary>
在NBA的分析革命中，开发特定的指标和公式为球队、教练和球员提供了一种新的视角。然而，问题出现：如何证明这些指标？一种方法是通过观察和尝试多种战斗策略来估算，这是一种估算性的和昂贵的方法。另一种方法是使用机器学习技术来模型现有的指标，并使用这些特定的特征来评估这些指标的效果。如果我们有一个准确的模型，那么它可以帮助我们确定游戏计划的具体执行方式。根据这篇论文，由Dean Oliver开发的ORTG指标（进攻评估指标）与不同的NBA战斗类型之间存在正相关关系，使用线性回归模型和神经网络回归模型进行评估，最终神经网络模型的性能略高于线性回归模型。使用模型的准确性为正当化，接下来的步骤是使用测试例子来优化模型的输出，以达到高效的攻击战斗。
</details></li>
</ul>
<hr>
<h2 id="When-Monte-Carlo-Dropout-Meets-Multi-Exit-Optimizing-Bayesian-Neural-Networks-on-FPGA"><a href="#When-Monte-Carlo-Dropout-Meets-Multi-Exit-Optimizing-Bayesian-Neural-Networks-on-FPGA" class="headerlink" title="When Monte-Carlo Dropout Meets Multi-Exit: Optimizing Bayesian Neural Networks on FPGA"></a>When Monte-Carlo Dropout Meets Multi-Exit: Optimizing Bayesian Neural Networks on FPGA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06849">http://arxiv.org/abs/2308.06849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/os-hxfan/bayesnn_fpga">https://github.com/os-hxfan/bayesnn_fpga</a></li>
<li>paper_authors: Hongxiang Fan, Hao Chen, Liam Castelli, Zhiqiang Que, He Li, Kenneth Long, Wayne Luk</li>
<li>for: 提高安全应用中的投机率预测，如医学影像和自动驾驶。</li>
<li>methods: 提出了一种基于多出口Monte Carlo Dropout（MCD）的 bayesian neural network，实现了准确预测，同时降低了算法复杂性。</li>
<li>results: 对比CPU、GPU和其他当前硬件实现，自动生成的加速器实现了更高的能效率。<details>
<summary>Abstract</summary>
Bayesian Neural Networks (BayesNNs) have demonstrated their capability of providing calibrated prediction for safety-critical applications such as medical imaging and autonomous driving. However, the high algorithmic complexity and the poor hardware performance of BayesNNs hinder their deployment in real-life applications. To bridge this gap, this paper proposes a novel multi-exit Monte-Carlo Dropout (MCD)-based BayesNN that achieves well-calibrated predictions with low algorithmic complexity. To further reduce the barrier to adopting BayesNNs, we propose a transformation framework that can generate FPGA-based accelerators for multi-exit MCD-based BayesNNs. Several novel optimization techniques are introduced to improve hardware performance. Our experiments demonstrate that our auto-generated accelerator achieves higher energy efficiency than CPU, GPU, and other state-of-the-art hardware implementations.
</details>
<details>
<summary>摘要</summary>
bayesian neural networks (bayesNNs) 有显示出在安全关键应用，如医疗成像和自动驾驶中提供了调整后预测的能力。然而，高算法复杂性和 BayesNNs 的硬件性能问题使得它们在实际应用中困难得 deployment。为bridge这个差距，本文提出了一种基于多出口 Monte Carlo Dropout (MCD) 的 BayesNN ，可以实现低算法复杂性下的准确预测。此外，我们还提出了一种转换框架，可以生成 FPGA 基于的加速器，以便快速采用 BayesNNs。我们还引入了一些新的优化技术，以提高硬件性能。我们的实验表明，我们自动生成的加速器在能耗效率方面高于 CPU、GPU 和其他现有硬件实现。Note: "BayesNNs" is a abbreviation of "Bayesian Neural Networks" in English, and "bayesNNs" is the pinyin Romanization of "拜耳 нейрон网络" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Generalizing-Topological-Graph-Neural-Networks-with-Paths"><a href="#Generalizing-Topological-Graph-Neural-Networks-with-Paths" class="headerlink" title="Generalizing Topological Graph Neural Networks with Paths"></a>Generalizing Topological Graph Neural Networks with Paths</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06838">http://arxiv.org/abs/2308.06838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang Truong, Peter Chin</li>
<li>for: 本文主要研究Graph Neural Networks (GNNs)的限制和提高。</li>
<li>methods: 本文提出了一种以路径为中心的方法，该方法可以在不假设图structure的情况下提高GNNs的性能。</li>
<li>results: 本文的方法在多个 benchmark 上达到了状态之artefact的表现。<details>
<summary>Abstract</summary>
While Graph Neural Networks (GNNs) have made significant strides in diverse areas, they are hindered by a theoretical constraint known as the 1-Weisfeiler-Lehmann test. Even though latest advancements in higher-order GNNs can overcome this boundary, they typically center around certain graph components like cliques or cycles. However, our investigation goes a different route. We put emphasis on paths, which are inherent in every graph. We are able to construct a more general topological perspective and form a bridge to certain established theories about other topological domains. Interestingly, without any assumptions on graph sub-structures, our approach surpasses earlier techniques in this field, achieving state-of-the-art performance on several benchmarks.
</details>
<details>
<summary>摘要</summary>
GNNS （图 neural network）在多种领域取得了重要进步，但它们受到一种理论限制，称为Weisfeiler-Lehmann测试。 latest advancements in higher-order GNNs 可以突破这个限制，但它们通常围绕 graf 组件如 clique 或 cycle 进行中心。 然而，我们的研究采取了不同的方向。 我们强调 path，这些是所有 graf 的内在特征。 我们可以构建一个更通用的 topological 视角，并与其他已确立的 topological 领域之间建立桥梁。 很有趣的是，不需要任何关于 graf 子结构的假设，我们的方法可以在这个领域中超越之前的技术，在多个 benchmark 上达到状态的表现。
</details></li>
</ul>
<hr>
<h2 id="InTune-Reinforcement-Learning-based-Data-Pipeline-Optimization-for-Deep-Recommendation-Models"><a href="#InTune-Reinforcement-Learning-based-Data-Pipeline-Optimization-for-Deep-Recommendation-Models" class="headerlink" title="InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models"></a>InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08500">http://arxiv.org/abs/2308.08500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kabir Nagrecha, Lingyi Liu, Pablo Delgado, Prasanna Padmanabhan</li>
<li>for: 这个论文的目的是探讨深度学习推荐模型（DLRM）的训练过程中的数据接收问题，以及这个问题在现实世界中的瓶颈和挑战。</li>
<li>methods: 这篇论文使用了人工智能的强化学习（RL）技术来解决数据接收问题，RL机器学习agent可以学习如何在DLRM数据管道中分配CPU资源，以更好地并行数据加载和提高throughput。</li>
<li>results: 实验表明，使用InTune可以在只需几分钟之内构建优化数据管道配置，并且可以轻松地与现有训练工作流 integrate。InTune可以提高在线数据接收率，从而减少模型执行时间的浪费和提高效率。在实际世界中应用InTune后，发现它可以提高数据接收 durchput 比现有数据管道优化器高出2.29倍，同时也提高CPU和GPU资源的利用率。<details>
<summary>Abstract</summary>
Deep learning-based recommender models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- and time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning training jobs are dominated by model execution, the most important factor in DLRM training performance is often online data ingestion.   In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into DLRM training pipeline bottlenecks and challenges. We study real-world DLRM data processing pipelines taken from our compute cluster at Netflix to observe the performance impacts of online ingestion and to identify shortfalls in existing pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization to adopt. Our studies lead us to design and build a new solution for data pipeline optimization, InTune.   InTune employs a reinforcement learning (RL) agent to learn how to distribute the CPU resources of a trainer machine across a DLRM data pipeline to more effectively parallelize data loading and improve throughput. Our experiments show that InTune can build an optimized data pipeline configuration within only a few minutes, and can easily be integrated into existing training workflows. By exploiting the responsiveness and adaptability of RL, InTune achieves higher online data ingestion rates than existing optimizers, thus reducing idle times in model execution and increasing efficiency. We apply InTune to our real-world cluster, and find that it increases data ingestion throughput by as much as 2.29X versus state-of-the-art data pipeline optimizers while also improving both CPU & GPU utilization.
</details>
<details>
<summary>摘要</summary>
现代推荐系统中的深度学习基于模型（DLRM）已成为关键组件。许多公司正在建立专门用于DLRM训练的大型计算集群，导致新的成本和时间OPTIMIZATION的兴趣。这种系统中的挑战是唯一的；通常的深度学习训练任务由模型执行所主导，而DLRM训练中最重要的因素则是在线数据接收。在这篇论文中，我们探讨DLRM数据接收问题的独特特点，并对DLRM训练管道中的瓶颈和挑战提供了新的视角。我们研究了Netflix的计算集群中的真实DLRM数据处理管道，以观察在线接收的性能影响和标准化管道优化器的缺陷。我们发现现有的工具可以提供低效率、频繁崩溃或者需要重新组织集群的优化。为了解决这些问题，我们设计了一种新的数据管道优化解决方案——InTune。InTune使用了强化学习（RL）代理来学习如何在DLRM数据管道中分配训练机器的CPU资源，以更好地并行数据加载并提高吞吐量。我们的实验表明，InTune可以在只需几分钟之内构建优化后的数据管道配置，并可以轻松地与现有训练工作流 integrate。通过强化学习的响应和适应性，InTune可以在现有优化器的基础上提高在线数据接收速率，从而降低模型执行时间的浪费和提高效率。我们在实际 cluster 中应用InTune，发现它可以提高数据接收吞吐量，最高可达2.29倍于当前状态艺术数据管道优化器，同时也提高CPU和GPU资源的利用率。
</details></li>
</ul>
<hr>
<h2 id="An-Ensemble-Approach-to-Question-Classification-Integrating-Electra-Transformer-GloVe-and-LSTM"><a href="#An-Ensemble-Approach-to-Question-Classification-Integrating-Electra-Transformer-GloVe-and-LSTM" class="headerlink" title="An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM"></a>An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06828">http://arxiv.org/abs/2308.06828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass, Osama Dorgham</li>
<li>for: 本研究提出了一种新的集成方法，用于问题分类任务。</li>
<li>methods: 该模型使用了现代化的 Electra、GloVe 和 LSTM 模型，并将其集成起来，以提高问题分类的精度和效率。</li>
<li>results: 对于 TREC 数据集上的问题分类任务，我们的模型实现了以下成果： accuracy 0.8 。这些结果表明，集成方法在问题分类任务中具有显著的优势，并且鼓励进一步探索 ensemble 方法在自然语言处理中的应用。<details>
<summary>Abstract</summary>
This paper introduces a novel ensemble approach for question classification using state-of-the-art models -- Electra, GloVe, and LSTM. The proposed model is trained and evaluated on the TREC dataset, a well-established benchmark for question classification tasks. The ensemble model combines the strengths of Electra, a transformer-based model for language understanding, GloVe, a global vectors for word representation, and LSTM, a recurrent neural network variant, providing a robust and efficient solution for question classification. Extensive experiments were carried out to compare the performance of the proposed ensemble approach with other cutting-edge models, such as BERT, RoBERTa, and DistilBERT. Our results demonstrate that the ensemble model outperforms these models across all evaluation metrics, achieving an accuracy of 0.8 on the test set. These findings underscore the effectiveness of the ensemble approach in enhancing the performance of question classification tasks, and invite further exploration of ensemble methods in natural language processing.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的ensemble方法 для问题分类，使用当今最佳模型——Electra、GloVe和LSTM。提议的模型在TREC数据集上进行训练和评估，TREC数据集是问题分类任务的可靠的标准 benchmark。 ensemble模型结合了Electra、GloVe和LSTM的优势，提供了一种强大和高效的问题分类解决方案。我们进行了广泛的实验，比较了提议的ensemble方法与其他最新的模型，如BERT、RoBERTa和DistilBERT的性能。我们的结果表明， ensemble模型在所有评价指标上都超过了这些模型，在测试集上达到了0.8的准确率。这些发现证明了 ensemble方法在问题分类任务中的效果，并邀请了进一步的ensemble方法在自然语言处理领域的探索。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Graph-Clustering-with-Unknown-Cluster-Number"><a href="#Reinforcement-Graph-Clustering-with-Unknown-Cluster-Number" class="headerlink" title="Reinforcement Graph Clustering with Unknown Cluster Number"></a>Reinforcement Graph Clustering with Unknown Cluster Number</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06827">http://arxiv.org/abs/2308.06827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yueliu1999/awesome-deep-graph-clustering">https://github.com/yueliu1999/awesome-deep-graph-clustering</a></li>
<li>paper_authors: Yue Liu, Ke Liang, Jun Xia, Xihong Yang, Sihang Zhou, Meng Liu, Xinwang Liu, Stan Z. Li</li>
<li>for: 这个论文的目标是提出一种无监督的深度图 clustering 方法，以便在实际场景中不需要预先定义群集数量。</li>
<li>methods: 该方法使用了强化学习机制，将集群数量决定和无监督表示学习集成到一个统一框架中。首先学习出了强化表示，然后考虑了节点和集群状态，并使用了质量网络评估不同群集数量的质量。最后，通过强化学习机制来确定最佳的群集数量。</li>
<li>results: 实验表明，提出的方法可以有效地进行深度图 clustering，并且比既有方法更加高效。code 和数据集可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Deep graph clustering, which aims to group nodes into disjoint clusters by neural networks in an unsupervised manner, has attracted great attention in recent years. Although the performance has been largely improved, the excellent performance of the existing methods heavily relies on an accurately predefined cluster number, which is not always available in the real-world scenario. To enable the deep graph clustering algorithms to work without the guidance of the predefined cluster number, we propose a new deep graph clustering method termed Reinforcement Graph Clustering (RGC). In our proposed method, cluster number determination and unsupervised representation learning are unified into a uniform framework by the reinforcement learning mechanism. Concretely, the discriminative node representations are first learned with the contrastive pretext task. Then, to capture the clustering state accurately with both local and global information in the graph, both node and cluster states are considered. Subsequently, at each state, the qualities of different cluster numbers are evaluated by the quality network, and the greedy action is executed to determine the cluster number. In order to conduct feedback actions, the clustering-oriented reward function is proposed to enhance the cohesion of the same clusters and separate the different clusters. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method. The source code of RGC is shared at https://github.com/yueliu1999/RGC and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github.
</details>
<details>
<summary>摘要</summary>
深度图 clustering，目标是通过神经网络在无监督情况下将节点分组成不重叠的分组，在过去几年内吸引了很大的关注。虽然现有的方法已经提高了性能，但是它们的出色表现受到准确预定的分组数量的限制，这在实际应用场景中并不总是可用。为了让深度图 clustering 算法不受预定分组数量的限制，我们提出了一种新的深度图 clustering 方法，称为奖励图 clustering（RGC）。在我们的提议方法中，帧定分组数量和无监督表示学习被统一到一个奖励学习机制中。具体来说，首先通过对比预文本任务来学习描述性节点表示。然后，为了准确地捕捉图中节点和分组的相互关系，在每个状态下考虑节点和分组状态。接着，在每个状态下，通过质量网络评估不同分组数量的质量，并执行贪婪的动作来确定分组数量。为了进行反馈动作，我们提出了一种集成吸引函数，以提高同分组内节点之间的凝聚力和不同分组内节点之间的分离力。我们的实验表明，RGC 方法可以具有高效率和高效性。RGC 的源代码可以在 GitHub 上获取（https://github.com/yueliu1999/RGC），并且我们在 GitHub 上分享了一个包含深度图 clustering 相关论文、代码和数据集的集成（https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering）。
</details></li>
</ul>
<hr>
<h2 id="Approximate-and-Weighted-Data-Reconstruction-Attack-in-Federated-Learning"><a href="#Approximate-and-Weighted-Data-Reconstruction-Attack-in-Federated-Learning" class="headerlink" title="Approximate and Weighted Data Reconstruction Attack in Federated Learning"></a>Approximate and Weighted Data Reconstruction Attack in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06822">http://arxiv.org/abs/2308.06822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Wang, Yongcun Song, Enrique Zuazua</li>
<li>for: 该研究旨在攻击基于 horizontal Federated Averaging（FedAvg）的分布式学习（Federated Learning，FL）场景，以便在无需分享客户端数据的情况下，攻击者可以recover客户端的训练数据。</li>
<li>methods: 该研究提出了一种 interpolation-based approximation 方法，通过生成客户端的本地训练过程中的中间模型更新，使得攻击 FedAvg 场景变得可行。此外，该研究还提出了一种层wise weighted loss function，用于提高数据重建的质量。</li>
<li>results: 实验结果表明，该研究的提出的 Approximate and Weighted Attack（AWA）方法在不同的评价指标中具有显著的改善，特别是在图像数据重建中。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed learning paradigm that enables multiple clients to collaborate on building a machine learning model without sharing their private data. Although FL is considered privacy-preserved by design, recent data reconstruction attacks demonstrate that an attacker can recover clients' training data based on the parameters shared in FL. However, most existing methods fail to attack the most widely used horizontal Federated Averaging (FedAvg) scenario, where clients share model parameters after multiple local training steps. To tackle this issue, we propose an interpolation-based approximation method, which makes attacking FedAvg scenarios feasible by generating the intermediate model updates of the clients' local training processes. Then, we design a layer-wise weighted loss function to improve the data quality of reconstruction. We assign different weights to model updates in different layers concerning the neural network structure, with the weights tuned by Bayesian optimization. Finally, experimental results validate the superiority of our proposed approximate and weighted attack (AWA) method over the other state-of-the-art methods, as demonstrated by the substantial improvement in different evaluation metrics for image data reconstructions.
</details>
<details>
<summary>摘要</summary>
federated learning（FL）是一种分布式学习模式，允许多个客户端共同构建一个机器学习模型，而无需分享他们的私人数据。虽然FL被视为隐私保护的设计，但是最近的数据重建攻击表明，攻击者可以根据在FL中共享的参数恢复客户端的训练数据。然而，现有的方法无法攻击最常用的水平联合平均（FedAvg）场景，在这里，客户端在多个本地训练步骤后共享模型参数。为解决这个问题，我们提议一种 interpolation-based 近似方法，使得在客户端的本地训练过程中生成Intermediate模型更新。然后，我们设计了层weise weighted 损失函数，以提高数据重建的质量。我们对模型更新在不同层中分配不同的权重，并通过抽样优化得到最佳权重。最后，我们的提出的近似和权重攻击（AWA）方法在不同评价指标中具有显著的提高，与其他当前state-of-the-art方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="SoK-Realistic-Adversarial-Attacks-and-Defenses-for-Intelligent-Network-Intrusion-Detection"><a href="#SoK-Realistic-Adversarial-Attacks-and-Defenses-for-Intelligent-Network-Intrusion-Detection" class="headerlink" title="SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection"></a>SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06819">http://arxiv.org/abs/2308.06819</a></li>
<li>repo_url: None</li>
<li>paper_authors: João Vitorino, Isabel Praça, Eva Maia</li>
<li>for: 本研究旨在汇总当前领域中 adversarial 学习的应用情况，以及对 realistic 的攻击示例的生成方法。</li>
<li>methods: 本研究使用了多种 adversarial 攻击方法，包括黑盒测试、灰盒测试、探测隐蔽攻击等。</li>
<li>results: 本研究通过对多种 adversarial 攻击方法进行分析和评估，提出了一些 open challenges 和 future research directions，以及一些实际应用场景的推荐。<details>
<summary>Abstract</summary>
Machine Learning (ML) can be incredibly valuable to automate anomaly detection and cyber-attack classification, improving the way that Network Intrusion Detection (NID) is performed. However, despite the benefits of ML models, they are highly susceptible to adversarial cyber-attack examples specifically crafted to exploit them. A wide range of adversarial attacks have been created and researchers have worked on various defense strategies to safeguard ML models, but most were not intended for the specific constraints of a communication network and its communication protocols, so they may lead to unrealistic examples in the NID domain. This Systematization of Knowledge (SoK) consolidates and summarizes the state-of-the-art adversarial learning approaches that can generate realistic examples and could be used in real ML development and deployment scenarios with real network traffic flows. This SoK also describes the open challenges regarding the use of adversarial ML in the NID domain, defines the fundamental properties that are required for an adversarial example to be realistic, and provides guidelines for researchers to ensure that their future experiments are adequate for a real communication network.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:机器学习（ML）可以极其有价值地自动检测异常和识别攻击，提高网络入侵检测（NID）的方式。然而，尽管ML模型具有各种优点，但它们又受到特制的攻击示例的威胁。有许多攻击方法被创造出来，研究人员也为了保护ML模型而努力了很多，但大多数这些方法不适用于通信网络和其通信协议的特定限制，因此可能导致NID领域中的不真实的示例。这个系统化知识（SoK）总结了当前领域中最佳的抗击学习方法，这些方法可以生成真实的示例，并可以在实际的ML开发和部署场景中使用实际的网络流量。这个SoK还描述了使用抗击学习在NID领域的开放挑战，定义了真实示例所需的基本属性，并提供了指导方针，以便未来研究人员可以在真正的通信网络中进行合适的实验。
</details></li>
</ul>
<hr>
<h2 id="SAILOR-Structural-Augmentation-Based-Tail-Node-Representation-Learning"><a href="#SAILOR-Structural-Augmentation-Based-Tail-Node-Representation-Learning" class="headerlink" title="SAILOR: Structural Augmentation Based Tail Node Representation Learning"></a>SAILOR: Structural Augmentation Based Tail Node Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06801">http://arxiv.org/abs/2308.06801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jie-re/sailor">https://github.com/jie-re/sailor</a></li>
<li>paper_authors: Jie Liao, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, Zibin Zheng<br>for: 本文是为了提高图像中的尾节点表示性而提出的一种框架，即SAILOR，该框架可以同时学习图像的结构增强和尾节点表示提取更多的信息。methods: 本文使用的方法包括message propagation和structural augmentation，这两种方法可以帮助提高尾节点的表示性。results: 实验结果表明，SAILOR可以显著提高尾节点的表示性，并超越现有的基elines。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes since they lack structural information. In the pursuit of promoting the expressiveness of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general Structural Augmentation based taIL nOde Representation learning framework, dubbed as SAILOR, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on public benchmark datasets demonstrate that SAILOR can significantly improve the tail node representations and outperform the state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
格raph神经网络（GNNs）在近期 representation learning 中取得了状态理想的表现。然而，GNNs 的效果，它们基于消息传递操作，具体取决于图结构质量。大多数实际场景中的图都遵循一个长尾分布，即图中的大多数节点是tail节点，只有几个连接的边。GNNs 对tail节点进行表示不够，因为它们缺乏结构信息。为了提高 GNNs 对tail节点的表示能力，我们研究了tail节点表示力下降的原因，并提出了一种通用的结构扩充基于 taIL nOde Representation 学习框架，名为 SAILOR，可以同时学习扩充图结构并提取更有用的表示信息。我们对公共 benchmark 数据集进行了广泛的实验，结果显示，SAILOR 可以明显提高tail节点表示能力，并超过当前的基elines。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/14/cs.LG_2023_08_14/" data-id="clon21is400nar588hdys4z3s" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/14/eess.IV_2023_08_14/" class="article-date">
  <time datetime="2023-08-14T09:00:00.000Z" itemprop="datePublished">2023-08-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/14/eess.IV_2023_08_14/">eess.IV - 2023-08-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Automated-Ensemble-Based-Segmentation-of-Adult-Brain-Tumors-A-Novel-Approach-Using-the-BraTS-AFRICA-Challenge-Data"><a href="#Automated-Ensemble-Based-Segmentation-of-Adult-Brain-Tumors-A-Novel-Approach-Using-the-BraTS-AFRICA-Challenge-Data" class="headerlink" title="Automated Ensemble-Based Segmentation of Adult Brain Tumors: A Novel Approach Using the BraTS AFRICA Challenge Data"></a>Automated Ensemble-Based Segmentation of Adult Brain Tumors: A Novel Approach Using the BraTS AFRICA Challenge Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07214">http://arxiv.org/abs/2308.07214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chiranjeewee Prasad Koirala, Sovesh Mohapatra, Advait Gosai, Gottfried Schlaug</li>
<li>for: 这篇论文旨在探讨使用深度学习技术来提高脑肿瘤分割精度，尤其是在 SUB-SAHARAN AFRICA 地区患者群体中。</li>
<li>methods: 这篇论文使用了多种多Modal MRI 数据，并提出了一种ensemble方法，包括eleven个不同的变体，基于三种核心架构：UNet3D、ONet3D 和 SphereNet3D，以及修改的损失函数。</li>
<li>results: 研究发现， ensemble方法可以在不同的核心架构和修改后的损失函数下提高评估指标，例如 Dice 分数为0.82、0.82和0.87分别用于提高肿瘤、肿瘤核心和全肿瘤标签。<details>
<summary>Abstract</summary>
Brain tumors, particularly glioblastoma, continue to challenge medical diagnostics and treatments globally. This paper explores the application of deep learning to multi-modality magnetic resonance imaging (MRI) data for enhanced brain tumor segmentation precision in the Sub-Saharan Africa patient population. We introduce an ensemble method that comprises eleven unique variations based on three core architectures: UNet3D, ONet3D, SphereNet3D and modified loss functions. The study emphasizes the need for both age- and population-based segmentation models, to fully account for the complexities in the brain. Our findings reveal that the ensemble approach, combining different architectures, outperforms single models, leading to improved evaluation metrics. Specifically, the results exhibit Dice scores of 0.82, 0.82, and 0.87 for enhancing tumor, tumor core, and whole tumor labels respectively. These results underline the potential of tailored deep learning techniques in precisely segmenting brain tumors and lay groundwork for future work to fine-tune models and assess performance across different brain regions.
</details>
<details>
<summary>摘要</summary>
脑肿、特别是 glioblastoma，在全球医学诊断和治疗中仍然存在挑战。这篇论文探讨了深度学习在多modal磁共振成像（MRI）数据上的应用，以提高脑肿分 segmentation精度在非洲南部患者人口中。我们介绍了一个集成方法，包括eleven个独特变种，基于三种核心架构：UNet3D、ONet3D 和 SphereNet3D，以及修改的损失函数。研究强调了需要Age和Population基于的分 segmentation模型，以全面考虑脑部的复杂性。我们的发现表明，ensemble方法，将不同架构相结合，可以提高评价指标。具体来说，结果表明，整合ensemble方法可以提高评价指标，达到0.82、0.82和0.87的Dice分数。这些结果证明了深度学习技术在精确地分 segmentation脑肿中的潜力，并为未来细化模型和评估不同脑部区域的性能奠定基础。
</details></li>
</ul>
<hr>
<h2 id="SAM-Meets-Robotic-Surgery-An-Empirical-Study-on-Generalization-Robustness-and-Adaptation"><a href="#SAM-Meets-Robotic-Surgery-An-Empirical-Study-on-Generalization-Robustness-and-Adaptation" class="headerlink" title="SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation"></a>SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07156">http://arxiv.org/abs/2308.07156</a></li>
<li>repo_url: None</li>
<li>paper_authors: An Wang, Mobarakol Islam, Mengya Xu, Yang Zhang, Hongliang Ren</li>
<li>for: 这个论文主要研究的是semantic segmentation模型Segment Anything Model（SAM）在Robotic Surgery领域的Robustness和零shot泛化能力。</li>
<li>methods: 这个论文使用了SAM模型，以及不同的提示方法，包括bounding box和点提示。</li>
<li>results: 研究发现，SAM在bounding box提示下表现出remarkable的零shot泛化能力，但在点提示和无提示情况下表现不佳，特别是在复杂的外科手术场景下。此外，SAM也存在对数据损害的敏感性和难以在不同情况下维持高性能的问题。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) serves as a fundamental model for semantic segmentation and demonstrates remarkable generalization capabilities across a wide range of downstream scenarios. In this empirical study, we examine SAM's robustness and zero-shot generalizability in the field of robotic surgery. We comprehensively explore different scenarios, including prompted and unprompted situations, bounding box and points-based prompt approaches, as well as the ability to generalize under corruptions and perturbations at five severity levels. Additionally, we compare the performance of SAM with state-of-the-art supervised models. We conduct all the experiments with two well-known robotic instrument segmentation datasets from MICCAI EndoVis 2017 and 2018 challenges. Our extensive evaluation results reveal that although SAM shows remarkable zero-shot generalization ability with bounding box prompts, it struggles to segment the whole instrument with point-based prompts and unprompted settings. Furthermore, our qualitative figures demonstrate that the model either failed to predict certain parts of the instrument mask (e.g., jaws, wrist) or predicted parts of the instrument as wrong classes in the scenario of overlapping instruments within the same bounding box or with the point-based prompt. In fact, SAM struggles to identify instruments in complex surgical scenarios characterized by the presence of blood, reflection, blur, and shade. Additionally, SAM is insufficiently robust to maintain high performance when subjected to various forms of data corruption. We also attempt to fine-tune SAM using Low-rank Adaptation (LoRA) and propose SurgicalSAM, which shows the capability in class-wise mask prediction without prompt. Therefore, we can argue that, without further domain-specific fine-tuning, SAM is not ready for downstream surgical tasks.
</details>
<details>
<summary>摘要</summary>
Segment Anything Model (SAM)  acted as a fundamental model for semantic segmentation and demonstrated remarkable generalization capabilities across a wide range of downstream scenarios. In this empirical study, we examined SAM's robustness and zero-shot generalizability in the field of robotic surgery. We comprehensively explored different scenarios, including prompted and unprompted situations, bounding box and points-based prompt approaches, as well as the ability to generalize under corruptions and perturbations at five severity levels. Additionally, we compared the performance of SAM with state-of-the-art supervised models. We conducted all the experiments with two well-known robotic instrument segmentation datasets from MICCAI EndoVis 2017 and 2018 challenges. Our extensive evaluation results showed that although SAM showed remarkable zero-shot generalization ability with bounding box prompts, it struggled to segment the whole instrument with point-based prompts and unprompted settings. Furthermore, our qualitative figures demonstrated that the model either failed to predict certain parts of the instrument mask (e.g., jaws, wrist) or predicted parts of the instrument as wrong classes in the scenario of overlapping instruments within the same bounding box or with the point-based prompt. In fact, SAM struggled to identify instruments in complex surgical scenarios characterized by the presence of blood, reflection, blur, and shade. Additionally, SAM was insufficiently robust to maintain high performance when subjected to various forms of data corruption. We also attempted to fine-tune SAM using Low-rank Adaptation (LoRA) and proposed SurgicalSAM, which showed the capability in class-wise mask prediction without prompt. Therefore, we can argue that, without further domain-specific fine-tuning, SAM is not ready for downstream surgical tasks.
</details></li>
</ul>
<hr>
<h2 id="FocusFlow-Boosting-Key-Points-Optical-Flow-Estimation-for-Autonomous-Driving"><a href="#FocusFlow-Boosting-Key-Points-Optical-Flow-Estimation-for-Autonomous-Driving" class="headerlink" title="FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving"></a>FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07104">http://arxiv.org/abs/2308.07104</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhonghuayi/focusflow_official">https://github.com/zhonghuayi/focusflow_official</a></li>
<li>paper_authors: Zhonghua Yi, Hao Shi, Kailun Yang, Qi Jiang, Yaozu Ye, Ze Wang, Kaiwei Wang<br>for:The paper is focused on improving the performance of optical flow estimation in key-point-critical scenarios for autonomous driving applications.methods:The proposed method, called FocusFlow, uses a points-based modeling approach that explicitly learns key-point-related priors. It also introduces a new loss function called Conditional Point Control Loss (CPCL) and a Condition Control Encoder (CCE) to improve the performance of the model.results:The proposed FocusFlow framework shows outstanding performance with up to +44.5% precision improvement on various key points such as ORB, SIFT, and even learning-based SiLK, and exceptional scalability for most existing data-driven optical flow methods. It also yields competitive or superior performances rivaling the original models on the whole frame.<details>
<summary>Abstract</summary>
Key-point-based scene understanding is fundamental for autonomous driving applications. At the same time, optical flow plays an important role in many vision tasks. However, due to the implicit bias of equal attention on all points, classic data-driven optical flow estimation methods yield less satisfactory performance on key points, limiting their implementations in key-point-critical safety-relevant scenarios. To address these issues, we introduce a points-based modeling method that requires the model to learn key-point-related priors explicitly. Based on the modeling method, we present FocusFlow, a framework consisting of 1) a mix loss function combined with a classic photometric loss function and our proposed Conditional Point Control Loss (CPCL) function for diverse point-wise supervision; 2) a conditioned controlling model which substitutes the conventional feature encoder by our proposed Condition Control Encoder (CCE). CCE incorporates a Frame Feature Encoder (FFE) that extracts features from frames, a Condition Feature Encoder (CFE) that learns to control the feature extraction behavior of FFE from input masks containing information of key points, and fusion modules that transfer the controlling information between FFE and CFE. Our FocusFlow framework shows outstanding performance with up to +44.5% precision improvement on various key points such as ORB, SIFT, and even learning-based SiLK, along with exceptional scalability for most existing data-driven optical flow methods like PWC-Net, RAFT, and FlowFormer. Notably, FocusFlow yields competitive or superior performances rivaling the original models on the whole frame. The source code will be available at https://github.com/ZhonghuaYi/FocusFlow_official.
</details>
<details>
<summary>摘要</summary>
基点 centered scene understanding 是自动驾驶应用的基础。同时，光流扮演了许多视觉任务中重要的角色。然而，由于约定性偏袋所有点都具有相同的注意力， класси的数据驱动光流估计方法在关键点上的表现不如预期，这限制了它们在关键点关键的安全相关场景中的实现。为解决这些问题，我们介绍了一种点 cloud 模型化方法，要求模型直接学习关键点相关的前置知识。基于该方法，我们提出了 FOCUSFLOW 框架，包括以下两个部分：1. 一种 mix 损失函数，与 класси的光学损失函数和我们所提出的 Conditional Point Control Loss (CPCL) 函数进行多样化点wise 超vision;2. 一种受控制的模型，替换了传统的特征编码器，我们提出的 Condition Control Encoder (CCE)。CCE 包括 Frame Feature Encoder (FFE)、Condition Feature Encoder (CFE) 和 fusion module，CFE 通过输入Mask 中关键点信息来学习控制 FFE 提取特征的行为，并将控制信息传递给 FFE。我们的 FOCUSFLOW 框架在多个关键点上（包括 ORB、SIFT 和学习基于 SiLK 的）表现出色，同时具有出色的扩展性，可以与大多数现有的数据驱动光流估计方法（如 PWC-Net、RAFT 和 FlowFormer）进行比较。特别是，FOCUSFLOW 在整个帧上的表现与原始模型相当或更好。源代码将在 GitHub 上发布，详情请参考 <https://github.com/ZhonghuaYi/FocusFlow_official>。
</details></li>
</ul>
<hr>
<h2 id="When-Deep-Learning-Meets-Multi-Task-Learning-in-SAR-ATR-Simultaneous-Target-Recognition-and-Segmentation"><a href="#When-Deep-Learning-Meets-Multi-Task-Learning-in-SAR-ATR-Simultaneous-Target-Recognition-and-Segmentation" class="headerlink" title="When Deep Learning Meets Multi-Task Learning in SAR ATR: Simultaneous Target Recognition and Segmentation"></a>When Deep Learning Meets Multi-Task Learning in SAR ATR: Simultaneous Target Recognition and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07093">http://arxiv.org/abs/2308.07093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Jifang Pei, Zhiyong Wang, Yulin Huang, Junjie Wu, Haiguang Yang, Jianyu Yang</li>
<li>for: 本文旨在提出一种基于多任务学习的Synthetic Aperture Radar（SAR）自动目标识别（ATR）方法，以便同时提取多种目标特征。</li>
<li>methods: 本文提出了一种基于深度学习理论的多任务学习框架，包括两个主要结构：编码器和解码器。编码器用于提取不同尺度的图像特征，而解码器则是一种任务特有的结构，它使用这些提取的特征进行适应性和优化性地进行识别和分割。</li>
<li>results: 根据Moving and Stationary Target Acquisition and Recognition（MSTAR） dataset的实验结果表明，提出的方法在识别和分割方面具有优秀的性能。<details>
<summary>Abstract</summary>
With the recent advances of deep learning, automatic target recognition (ATR) of synthetic aperture radar (SAR) has achieved superior performance. By not being limited to the target category, the SAR ATR system could benefit from the simultaneous extraction of multifarious target attributes. In this paper, we propose a new multi-task learning approach for SAR ATR, which could obtain the accurate category and precise shape of the targets simultaneously. By introducing deep learning theory into multi-task learning, we first propose a novel multi-task deep learning framework with two main structures: encoder and decoder. The encoder is constructed to extract sufficient image features in different scales for the decoder, while the decoder is a tasks-specific structure which employs these extracted features adaptively and optimally to meet the different feature demands of the recognition and segmentation. Therefore, the proposed framework has the ability to achieve superior recognition and segmentation performance. Based on the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset, experimental results show the superiority of the proposed framework in terms of recognition and segmentation.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)随着深度学习的进步，激光探测器自动目标识别（ATR）已经达到了出色的性能。由于不受目标类别的限制，SAR ATR系统可以从同时提取多种目标属性中受益。在这篇论文中，我们提出了一种新的多任务学习方法 для SAR ATR，可以同时获得目标的准确分类和精确的形状信息。通过将深度学习理论引入多任务学习中，我们首先提出了一种新的多任务深度学习框架，包括编码器和解码器两部分。编码器用于抽取不同缩放级别的图像特征，以便解码器使用这些抽取的特征进行适应性和优化的处理。因此，我们提出的框架具有提高认知和分割性能的能力。基于MSTAR数据集，我们的实验结果表明，我们的方法在认知和分割方面具有优越性。
</details></li>
</ul>
<hr>
<h2 id="Deepbet-Fast-brain-extraction-of-T1-weighted-MRI-using-Convolutional-Neural-Networks"><a href="#Deepbet-Fast-brain-extraction-of-T1-weighted-MRI-using-Convolutional-Neural-Networks" class="headerlink" title="Deepbet: Fast brain extraction of T1-weighted MRI using Convolutional Neural Networks"></a>Deepbet: Fast brain extraction of T1-weighted MRI using Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07003">http://arxiv.org/abs/2308.07003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Fisch, Stefan Zumdick, Carlotta Barkhau, Daniel Emden, Jan Ernsting, Ramona Leenings, Kelvin Sarink, Nils R. Winter, Benjamin Risse, Udo Dannlowski, Tim Hahn</li>
<li>for: 这个论文的目的是提出一种高精度、快速的脑部EXTRACTION方法，用于多种神经成像预处理管道中。</li>
<li>methods: 该方法使用了现代的深度学习方法，包括LinkNet网络，在两个预测过程中进行两个阶段预测，从而提高了 segmentation 性能。</li>
<li>results: 该方法在跨验证中得到了 novel state-of-the-art 性能， median Dice 分数 (DSC) 为 99.0%，超过当前状态的艺术模型 (DSC &#x3D; 97.8% 和 DSC &#x3D; 97.9%)。此外，该方法能够更好地抗抑异常值，Dice 分数大于 96.9%  для所有样本。最后，该模型可以加速脑部EXTRACTION的速度，比现有方法快约 10 倍，可以在低级别硬件上处理一个图像只需 ~2 秒。<details>
<summary>Abstract</summary>
Brain extraction in magnetic resonance imaging (MRI) data is an important segmentation step in many neuroimaging preprocessing pipelines. Image segmentation is one of the research fields in which deep learning had the biggest impact in recent years enabling high precision segmentation with minimal compute. Consequently, traditional brain extraction methods are now being replaced by deep learning-based methods. Here, we used a unique dataset comprising 568 T1-weighted (T1w) MR images from 191 different studies in combination with cutting edge deep learning methods to build a fast, high-precision brain extraction tool called deepbet. deepbet uses LinkNet, a modern UNet architecture, in a two stage prediction process. This increases its segmentation performance, setting a novel state-of-the-art performance during cross-validation with a median Dice score (DSC) of 99.0% on unseen datasets, outperforming current state of the art models (DSC = 97.8% and DSC = 97.9%). While current methods are more sensitive to outliers, resulting in Dice scores as low as 76.5%, deepbet manages to achieve a Dice score of > 96.9% for all samples. Finally, our model accelerates brain extraction by a factor of ~10 compared to current methods, enabling the processing of one image in ~2 seconds on low level hardware.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging（MRI）数据中的脑部提取是许多神经成像预处理管道中重要的分 segmentation步骤。图像分 segmentation是深度学习过去几年内最大的影响领域之一，使得传统的脑部提取方法被取代了深度学习基于方法。我们使用了568张T1-weighted（T1w）MR图像从191个不同的研究中的独特数据集，并使用最新的深度学习方法来构建一个高速、高精度的脑部提取工具called deepbet。deepbet使用了LinkNet，一种现代的UNet架构，在两个预测过程中进行两个阶段预测。这使得它的分 segmentation性能得到了提升，在批处理中 median Dice score（DSC）达到了99.0%，超越当前状态的艺术模型（DSC = 97.8%和DSC = 97.9%）。而当前方法更敏感于异常值，导致Dice score只有76.5%，而deepbet则可以达到> 96.9%的Dice score。最后，我们的模型可以将脑部提取加速了约10倍，使得一张图像在低级别硬件上只需2秒钟左右。
</details></li>
</ul>
<hr>
<h2 id="How-inter-rater-variability-relates-to-aleatoric-and-epistemic-uncertainty-a-case-study-with-deep-learning-based-paraspinal-muscle-segmentation"><a href="#How-inter-rater-variability-relates-to-aleatoric-and-epistemic-uncertainty-a-case-study-with-deep-learning-based-paraspinal-muscle-segmentation" class="headerlink" title="How inter-rater variability relates to aleatoric and epistemic uncertainty: a case study with deep learning-based paraspinal muscle segmentation"></a>How inter-rater variability relates to aleatoric and epistemic uncertainty: a case study with deep learning-based paraspinal muscle segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06964">http://arxiv.org/abs/2308.06964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parinaz Roshanzamir, Hassan Rivaz, Joshua Ahn, Hamza Mirza, Neda Naghdi, Meagan Anstruther, Michele C. Battié, Maryse Fortin, Yiming Xiao<br>for: This paper aims to explore the relationship between inter-rater variability and uncertainty in deep learning models for medical image segmentation, and to compare the performance of different DL models and label fusion strategies.methods: The authors use test-time augmentation (TTA), test-time dropout (TTD), and deep ensemble to measure aleatoric and epistemic uncertainties, and compare the performance of UNet and TransUNet with two label fusion strategies.results: The study reveals the interplay between inter-rater variability and uncertainties, and shows that the choice of label fusion strategies and DL models can affect the performance and uncertainty of the resulting algorithms.<details>
<summary>Abstract</summary>
Recent developments in deep learning (DL) techniques have led to great performance improvement in medical image segmentation tasks, especially with the latest Transformer model and its variants. While labels from fusing multi-rater manual segmentations are often employed as ideal ground truths in DL model training, inter-rater variability due to factors such as training bias, image noise, and extreme anatomical variability can still affect the performance and uncertainty of the resulting algorithms. Knowledge regarding how inter-rater variability affects the reliability of the resulting DL algorithms, a key element in clinical deployment, can help inform better training data construction and DL models, but has not been explored extensively. In this paper, we measure aleatoric and epistemic uncertainties using test-time augmentation (TTA), test-time dropout (TTD), and deep ensemble to explore their relationship with inter-rater variability. Furthermore, we compare UNet and TransUNet to study the impacts of Transformers on model uncertainty with two label fusion strategies. We conduct a case study using multi-class paraspinal muscle segmentation from T2w MRIs. Our study reveals the interplay between inter-rater variability and uncertainties, affected by choices of label fusion strategies and DL models.
</details>
<details>
<summary>摘要</summary>
In this paper, we investigate the relationship between inter-rater variability and the reliability of DL algorithms by measuring aleatoric and epistemic uncertainties using test-time augmentation (TTA), test-time dropout (TTD), and deep ensemble. We also compare UNet and TransUNet to study the impact of Transformers on model uncertainty with two label fusion strategies. Our case study focuses on multi-class paraspinal muscle segmentation from T2w MRIs.Our findings reveal an interplay between inter-rater variability and uncertainties, which are influenced by the choice of label fusion strategies and DL models. By understanding these relationships, we can better construct training data and develop more reliable DL models for clinical applications.
</details></li>
</ul>
<hr>
<h2 id="Robustness-Stress-Testing-in-Medical-Image-Classification"><a href="#Robustness-Stress-Testing-in-Medical-Image-Classification" class="headerlink" title="Robustness Stress Testing in Medical Image Classification"></a>Robustness Stress Testing in Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06889">http://arxiv.org/abs/2308.06889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mobarakol/robustness_stress_testing">https://github.com/mobarakol/robustness_stress_testing</a></li>
<li>paper_authors: Mobarakol Islam, Zeju Li, Ben Glocker<br>for:  This paper aims to assess the robustness and equity of disease detection models using progressive stress testing.methods: The authors use five different bidirectional and unidirectional image perturbations with six different severity levels to test the models’ robustness.results: The authors find that some models may yield more robust and equitable performance than others, and pretraining characteristics play an important role in downstream robustness.<details>
<summary>Abstract</summary>
Deep neural networks have shown impressive performance for image-based disease detection. Performance is commonly evaluated through clinical validation on independent test sets to demonstrate clinically acceptable accuracy. Reporting good performance metrics on test sets, however, is not always a sufficient indication of the generalizability and robustness of an algorithm. In particular, when the test data is drawn from the same distribution as the training data, the iid test set performance can be an unreliable estimate of the accuracy on new data. In this paper, we employ stress testing to assess model robustness and subgroup performance disparities in disease detection models. We design progressive stress testing using five different bidirectional and unidirectional image perturbations with six different severity levels. As a use case, we apply stress tests to measure the robustness of disease detection models for chest X-ray and skin lesion images, and demonstrate the importance of studying class and domain-specific model behaviour. Our experiments indicate that some models may yield more robust and equitable performance than others. We also find that pretraining characteristics play an important role in downstream robustness. We conclude that progressive stress testing is a viable and important tool and should become standard practice in the clinical validation of image-based disease detection models.
</details>
<details>
<summary>摘要</summary>
深度神经网络在图像基于疾病检测方面表现出色。性能通常通过临床验证方法进行评估，以证明在临床上达到可接受的准确率。然而，只是在测试数据集上报告好的性能指标不一定是一个可靠的指示器，特别是当测试数据集来自同一个分布为训练数据集时，iid测试集性能可能是一个不可靠的准确率估计。在这篇论文中，我们使用压力测试来评估模型的可靠性和 subgroup 性能差异。我们设计了进行逆向和直向的图像扰动，并使用六个不同的严重程度。作为一个使用场景，我们将压力测试应用于肺X射线和皮肤损伤图像中的疾病检测模型，并证明了研究类和领域特定的模型行为的重要性。我们的实验表示某些模型可能具有更高的可靠性和公平性。我们还发现预训练特征对下游可靠性具有重要作用。我们结论，进行进程式压力测试是一种可靠的和重要的工具，应成为临床验证图像基于疾病检测模型的标准实践。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/14/eess.IV_2023_08_14/" data-id="clon21ixy013mr588bi9c8ja4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.CV_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T13:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.CV_2023_08_13/">cs.CV - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Modified-Topological-Image-Preprocessing-for-Skin-Lesion-Classifications"><a href="#Modified-Topological-Image-Preprocessing-for-Skin-Lesion-Classifications" class="headerlink" title="Modified Topological Image Preprocessing for Skin Lesion Classifications"></a>Modified Topological Image Preprocessing for Skin Lesion Classifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06796">http://arxiv.org/abs/2308.06796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Cheng, Rebekah Leamons, Ahmad Al Shami</li>
<li>for: 这个论文是为了提出一种修改了拓扑数据分析模型，用于精确地处理皮肤图像的预处理和优化。</li>
<li>methods: 该模型使用了修改后的拓扑数据分析方法，并在使用深度卷积神经网络和视transformer模型进行训练。</li>
<li>results: 实验结果表明，使用修改后的拓扑数据分析方法可以在皮肤图像预处理中提高性能。<details>
<summary>Abstract</summary>
This paper proposes a modified Topological Data Analysis model for skin images preprocessing and enhancements. The skin lesion dataset HAM10000 used with the intention of identifying the important objects in relevant regions of the images. In order to evaluate both the original dataset and the preprocessed dataset, Deep Convolutional Neural Network and Vision Transformer models were utilized to train both models. After training, the experimental results demonstrate that the images preprocessed using the Modified Topological Data Analysis consistently perform better.
</details>
<details>
<summary>摘要</summary>
这个论文提出了一种修改后的拓扑数据分析模型，用于皮肤图像的预处理和改进。使用了悬峰10000个皮肤病变数据集，以便在相关区域中标识重要对象。为了评估原始数据集和预处理后的数据集，使用了深度卷积神经网络和视 traducción transformer 模型进行训练。经训练后，实验结果表明，使用修改后的拓扑数据分析后的图像预处理 consistently perform better。Note: "拓扑数据分析" (topological data analysis) is a bit of a mouthful in Chinese, so I've shortened it to "拓扑分析" (topological analysis) in the translation.
</details></li>
</ul>
<hr>
<h2 id="PV-SSD-A-Projection-and-Voxel-based-Double-Branch-Single-Stage-3D-Object-Detector"><a href="#PV-SSD-A-Projection-and-Voxel-based-Double-Branch-Single-Stage-3D-Object-Detector" class="headerlink" title="PV-SSD: A Projection and Voxel-based Double Branch Single-Stage 3D Object Detector"></a>PV-SSD: A Projection and Voxel-based Double Branch Single-Stage 3D Object Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06791">http://arxiv.org/abs/2308.06791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongxin Shao, Aihong Tan, Zhetao Sun, Enhui Zheng, Tianhong Yan</li>
<li>for: 提高LIDAR数据的3D对象检测和分类精度，以便自动驾驶。</li>
<li>methods: 提出基于精度抽象和投影叠加的double branch特征提取方法（PV-SSD），以减少投影过程中的信息损失。</li>
<li>results: 与之前的工作相比，本方法实现了良好的性能，并且提出了多个贡献，包括：1）基于精度抽象的粒子特征提取方法；2）基于重要性抽象的特征点抽取方法；3）基于SSFA模块的MSSFA模块。<details>
<summary>Abstract</summary>
LIDAR-based 3D object detection and classification is crucial for autonomous driving. However, inference in real-time from extremely sparse 3D data poses a formidable challenge. To address this issue, a common approach is to project point clouds onto a bird's-eye or perspective view, effectively converting them into an image-like data format. However, this excessive compression of point cloud data often leads to the loss of information. This paper proposes a 3D object detector based on voxel and projection double branch feature extraction (PV-SSD) to address the problem of information loss. We add voxel features input containing rich local semantic information, which is fully fused with the projected features in the feature extraction stage to reduce the local information loss caused by projection. A good performance is achieved compared to the previous work. In addition, this paper makes the following contributions: 1) a voxel feature extraction method with variable receptive fields is proposed; 2) a feature point sampling method by weight sampling is used to filter out the feature points that are more conducive to the detection task; 3) the MSSFA module is proposed based on the SSFA module. To verify the effectiveness of our method, we designed comparison experiments.
</details>
<details>
<summary>摘要</summary>
LIDAR-based 3D对象检测和分类是自动驾驶中关键。然而，在实时推理从极其稀疏3D数据中却成为一大挑战。为解决这个问题，一种常见的方法是将点云 proyect onto a bird's-eye or perspective view，实际上将其转换成图像类数据格式。然而，这种压缩点云数据的方法经常会导致信息损失。这篇论文提出了基于voxel和投影双分支特征提取（PV-SSD）的3D对象检测器，以解决信息损失问题。我们添加了包含丰富本地语义信息的voxel特征输入，并将其完全与投影特征在特征提取阶段进行了完全融合，以降低由投影所导致的本地信息损失。我们实现了与之前的工作相比的良好性能。此外，本文还做出了以下贡献：1）基于voxel特征提取方法中的可变感知场被提出；2）通过重点抽样来筛选更适合检测任务的特征点；3）基于SSFA模块的MSSFA模块被提出。为证明我们的方法的有效性，我们设计了对比实验。
</details></li>
</ul>
<hr>
<h2 id="RMP-Loss-Regularizing-Membrane-Potential-Distribution-for-Spiking-Neural-Networks"><a href="#RMP-Loss-Regularizing-Membrane-Potential-Distribution-for-Spiking-Neural-Networks" class="headerlink" title="RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks"></a>RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06787">http://arxiv.org/abs/2308.06787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufei Guo, Xiaode Liu, Yuanpei Chen, Liwen Zhang, Weihang Peng, Yuhan Zhang, Xuhui Huang, Zhe Ma</li>
<li>for: 这篇论文是为了解决神经网络中的数字化错误问题，并提出一个简单且直观的训练方法来减少这种错误的影响。</li>
<li>methods: 本论文使用的方法是一种叫做Regularizing membrane potential loss (RMP-Loss)的调整项，可以将数字化错误的影响降到最小化。这个方法实现非常简单，并且可以轻松地训练神经网络。</li>
<li>results: 本论文的实验结果显示，使用RMP-Loss训练神经网络可以对数字化错误问题做出有效的降低，并且可以与其他已知的方法相比，在不同的网络架构和数据集上表现更好。<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) as one of the biology-inspired models have received much attention recently. It can significantly reduce energy consumption since they quantize the real-valued membrane potentials to 0/1 spikes to transmit information thus the multiplications of activations and weights can be replaced by additions when implemented on hardware. However, this quantization mechanism will inevitably introduce quantization error, thus causing catastrophic information loss. To address the quantization error problem, we propose a regularizing membrane potential loss (RMP-Loss) to adjust the distribution which is directly related to quantization error to a range close to the spikes. Our method is extremely simple to implement and straightforward to train an SNN. Furthermore, it is shown to consistently outperform previous state-of-the-art methods over different network architectures and datasets.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）作为生物体系静脉模型，最近受到了非常多的关注。它可以减少能耗，因为它将实际值膜电压转换为0/1气压来传输信息，因此硬件实现中的多Multiplications of activations and weights可以被替换为加法运算。然而，这种归一化机制会不可避免地导致归一化错误，从而导致重大的信息损失。为解决这个问题，我们提议一种调整膜电压损失（RMP-Loss）来调整直接与归一化错误相关的分布，使其落在近距离气压范围内。我们的方法非常简单易于实现，并且可以 straightforwardly 训练一个 SNN。此外，我们的方法在不同的网络架构和数据集上都能够 consistently outperform 前一代的方法。
</details></li>
</ul>
<hr>
<h2 id="Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature"><a href="#Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature" class="headerlink" title="Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature"></a>Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06781">http://arxiv.org/abs/2308.06781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yash Deo, Haoran Dou, Nishant Ravikumar, Alejandro F. Frangi, Toni Lassila</li>
<li>for: 该研究旨在提高对脑血管疾病的研究和临床 intervención中对脑血管的理解，通过生成真实的3D脑血管分割图像，包括较少见的脑血管变化。</li>
<li>methods: 该研究使用了一种新的生成模型，基于 conditional latent diffusion model，具有形态和解剖指导，以生成真实的3D脑血管分割图像，包括不同的脑血管变化。</li>
<li>results: 研究结果显示，该模型生成的脑血管分割图像比较真实，与其他生成模型，如 conditional GAN和 conditional VAE，具有更高的视觉准确性，FID分数比best-performing GAN-based model高53%。<details>
<summary>Abstract</summary>
The Circle of Willis (CoW) is the part of cerebral vasculature responsible for delivering blood to the brain. Understanding the diverse anatomical variations and configurations of the CoW is paramount to advance research on cerebrovascular diseases and refine clinical interventions. However, comprehensive investigation of less prevalent CoW variations remains challenging because of the dominance of a few commonly occurring configurations. We propose a novel generative approach utilising a conditional latent diffusion model with shape and anatomical guidance to generate realistic 3D CoW segmentations, including different phenotypical variations. Our conditional latent diffusion model incorporates shape guidance to better preserve vessel continuity and demonstrates superior performance when compared to alternative generative models, including conditional variants of 3D GAN and 3D VAE. We observed that our model generated CoW variants that are more realistic and demonstrate higher visual fidelity than competing approaches with an FID score 53\% better than the best-performing GAN-based model.
</details>
<details>
<summary>摘要</summary>
圆形 Wille （CoW）是脑血管系统中听取血液到脑部的部分。 了解不同的 anatomical 变化和配置的 CoW 对于进展研究脑血管疾病和细化临床 intervención 至关重要。 然而，对于 menos prevalence CoW 变化的全面调查仍然具有挑战，因为一些常见的配置占据了主导地位。 我们提出了一种新的生成方法，使用 conditioned 潜在扩散模型，包括形态和解剖指导来生成真实的 3D CoW 分割，包括不同的现象变化。 我们的 conditioned 潜在扩散模型 包括形态指导，以更好地保持血管连续性，并在与其他生成模型进行比较时，表现出更高的性能。 我们观察到，我们的模型生成的 CoW 变化更加真实，与竞争方法相比，FID 分数高达 53% 更高。
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-at-a-Fraction-with-Pruned-Quaternions"><a href="#Neural-Networks-at-a-Fraction-with-Pruned-Quaternions" class="headerlink" title="Neural Networks at a Fraction with Pruned Quaternions"></a>Neural Networks at a Fraction with Pruned Quaternions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06780">http://arxiv.org/abs/2308.06780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/quartLT22">https://github.com/smlab-niser/quartLT22</a></li>
<li>paper_authors: Sahel Mohammad Iqbal, Subhankar Mishra</li>
<li>for: 这个研究目的是实现具有限制的计算能力的装置上进行深度学习模型的部署。</li>
<li>methods: 这个研究使用删减技术来删除不必要的参数，以减少训练和推导的资源需求。另外，使用高维度数据嵌入，如复数或四元数，可以降低模型的参数数量，保持精度。</li>
<li>results: 研究发现，在某些架构和任务上，这些复数模型在高给定率下具有更高的准确性，比如在CIFAR-10上的图像分类任务中，使用Conv-4架构，删减后的复数模型比同架构的实际模型提高了超过10%。实验结果显示，在极限的资源环境下，一个简短的复数网络可能比同架构的实际简短模型更适合进行部署。<details>
<summary>Abstract</summary>
Contemporary state-of-the-art neural networks have increasingly large numbers of parameters, which prevents their deployment on devices with limited computational power. Pruning is one technique to remove unnecessary weights and reduce resource requirements for training and inference. In addition, for ML tasks where the input data is multi-dimensional, using higher-dimensional data embeddings such as complex numbers or quaternions has been shown to reduce the parameter count while maintaining accuracy. In this work, we conduct pruning on real and quaternion-valued implementations of different architectures on classification tasks. We find that for some architectures, at very high sparsity levels, quaternion models provide higher accuracies than their real counterparts. For example, at the task of image classification on CIFAR-10 using Conv-4, at $3\%$ of the number of parameters as the original model, the pruned quaternion version outperforms the pruned real by more than $10\%$. Experiments on various network architectures and datasets show that for deployment in extremely resource-constrained environments, a sparse quaternion network might be a better candidate than a real sparse model of similar architecture.
</details>
<details>
<summary>摘要</summary>
现代神经网络在训练和推理过程中的参数数量逐渐增加，这限制了它们在计算机能力有限的设备上进行部署。折射是一种技术来移除不必要的权重，以降低训练和推理所需的资源。此外，在多维输入数据的机器学习任务中，使用高维数域嵌入，如复数或四元数，可以降低参数数量而保持准确性。在这项工作中，我们对实际值和四元数值实现的不同架构进行了折射。我们发现，在某些架构上，在非常高的稀疏程度下，四元数模型可以提供更高的准确性。例如，在使用Conv-4架构进行图像分类任务时，在原始模型的3%的参数数量下，折射后的四元数模型高于原始实际模型的准确性超过10%。在不同的网络架构和数据集上进行了多种实验，我们发现在极限的资源环境下，一个稀疏的四元数网络可能比同类架构的实际稀疏模型更适合进行部署。
</details></li>
</ul>
<hr>
<h2 id="Shrinking-Class-Space-for-Enhanced-Certainty-in-Semi-Supervised-Learning"><a href="#Shrinking-Class-Space-for-Enhanced-Certainty-in-Semi-Supervised-Learning" class="headerlink" title="Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning"></a>Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06777">http://arxiv.org/abs/2308.06777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LiheYoung/ShrinkMatch">https://github.com/LiheYoung/ShrinkMatch</a></li>
<li>paper_authors: Lihe Yang, Zhen Zhao, Lei Qi, Yu Qiao, Yinghuan Shi, Hengshuang Zhao</li>
<li>for: 本文针对semi-supervised learning中的问题提出了一个新的方法，即ShrinkMatch，以解决过去的 Pseudo label 可能不准确问题。</li>
<li>methods: 本文使用了一个新的方法，即ShrinkMatch，它可以将uncertain samples转换为certain samples，并且运用了一个consistency regularization来实现更好的表现。</li>
<li>results: 本文的实验结果显示了ShrinkMatch方法在各个 benchmark 上的出色表现，并且与其他state-of-the-art方法相比，它的表现更好。<details>
<summary>Abstract</summary>
Semi-supervised learning is attracting blooming attention, due to its success in combining unlabeled data. To mitigate potentially incorrect pseudo labels, recent frameworks mostly set a fixed confidence threshold to discard uncertain samples. This practice ensures high-quality pseudo labels, but incurs a relatively low utilization of the whole unlabeled set. In this work, our key insight is that these uncertain samples can be turned into certain ones, as long as the confusion classes for the top-1 class are detected and removed. Invoked by this, we propose a novel method dubbed ShrinkMatch to learn uncertain samples. For each uncertain sample, it adaptively seeks a shrunk class space, which merely contains the original top-1 class, as well as remaining less likely classes. Since the confusion ones are removed in this space, the re-calculated top-1 confidence can satisfy the pre-defined threshold. We then impose a consistency regularization between a pair of strongly and weakly augmented samples in the shrunk space to strive for discriminative representations. Furthermore, considering the varied reliability among uncertain samples and the gradually improved model during training, we correspondingly design two reweighting principles for our uncertain loss. Our method exhibits impressive performance on widely adopted benchmarks. Code is available at https://github.com/LiheYoung/ShrinkMatch.
</details>
<details>
<summary>摘要</summary>
semi-supervised learning 已经吸引了大量的注意力，因为它可以将无标签数据与标签数据结合起来。为了避免 potential incorrect pseudo labels，现有的框架通常设置固定的信任度reshold来抛弃不确定的样本。这种做法可以保证高质量的 pseudo labels，但是会导致未利用整个无标签集的资源。在这项工作中，我们的关键发现是，这些不确定的样本可以被转化为确定的样本，只要检测并移除混淆类。驱使这个想法，我们提出了一种名为 ShrinkMatch 的新方法。对于每个不确定的样本，它可以适应地寻找一个缩小的类空间，这个类空间只包含原始的 top-1 类，以及剩下的 less likely 类。由于混淆类被移除在这个空间中，重新计算的 top-1 信任度可以满足预定的阈值。然后，我们对一对强制和弱制的扩展样本之间的一致性regularization进行强制。此外，考虑到不确定样本之间的不同可靠性和在训练过程中逐渐提高的模型，我们采用了两种不同的 uncertain loss 重量原则。我们的方法在广泛采用的 benchmark 上表现出色。代码可以在 <https://github.com/LiheYoung/ShrinkMatch> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches"><a href="#Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches" class="headerlink" title="Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches"></a>Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06776">http://arxiv.org/abs/2308.06776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxin0/scpgabnet">https://github.com/linxin0/scpgabnet</a></li>
<li>paper_authors: Xin Lin, Chao Ren, Xiao Liu, Jie Huang, Yinjie Lei</li>
<li>for: 提高无标注数据集上的图像去噪性能，不需要大量的训练数据。</li>
<li>methods: 基于生成对抗网络的无supervised方法，通过在filter-guided噪音提取模块中逐次更新denoiser来提高噪音提取性能。</li>
<li>results: 与state-of-the-art无supervised方法相比，本方法实现了更高的噪音提取性能，而且不需要增加训练数据量或计算复杂度。<details>
<summary>Abstract</summary>
Deep learning methods have shown remarkable performance in image denoising, particularly when trained on large-scale paired datasets. However, acquiring such paired datasets for real-world scenarios poses a significant challenge. Although unsupervised approaches based on generative adversarial networks offer a promising solution for denoising without paired datasets, they are difficult in surpassing the performance limitations of conventional GAN-based unsupervised frameworks without significantly modifying existing structures or increasing the computational complexity of denoisers. To address this problem, we propose a SC strategy for multiple denoisers. This strategy can achieve significant performance improvement without increasing the inference complexity of the GAN-based denoising framework. Its basic idea is to iteratively replace the previous less powerful denoiser in the filter-guided noise extraction module with the current powerful denoiser. This process generates better synthetic clean-noisy image pairs, leading to a more powerful denoiser for the next iteration. This baseline ensures the stability and effectiveness of the training network. The experimental results demonstrate the superiority of our method over state-of-the-art unsupervised methods.
</details>
<details>
<summary>摘要</summary>
深度学习方法在图像去噪中表现出了惊人的表现，特别是在大规模对应数据集上训练。然而，在实际场景中获得这些对应数据集是一项巨大的挑战。although generative adversarial networks（GAN）基于的无监督方法可以提供去噪无需对应数据集的解决方案，但是它们在不改变现有结构或提高去噪器的计算复杂度下难以超越传统GAN基于无监督框架的性能限制。为解决这个问题，我们提出了SC策略。这种策略可以在GAN基于的去噪框架中实现显著性能提升，无需提高去噪器的计算复杂度。它的基本思想是在滤波器指导噪音EXTRACTION模块中，逐次替换以前较弱的去噪器，使得当前更强的去噪器生成更好的干涉clean-noisy图像对。这个基准确保了训练网络的稳定性和效果。实验结果表明，我们的方法在无监督去噪方法中表现出了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations"><a href="#A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations" class="headerlink" title="A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations"></a>A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06767">http://arxiv.org/abs/2308.06767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrcheng1066/awesome-pruning">https://github.com/hrcheng1066/awesome-pruning</a></li>
<li>paper_authors: Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi</li>
<li>for: 本研究寻求解决现代深度神经网络的大型模型需要大量计算和存储资源的问题，以便在有限的资源环境下部署和加速推理。</li>
<li>methods: 本文对现有的深度神经网络剪辑技术进行了一个权威的综述，包括1) 通用&#x2F;特定加速、2) 何时剪辑、3) 如何剪辑、4) 剪辑与其他压缩技术的融合。</li>
<li>results: 本文对7对不同的剪辑设置进行了比较分析，并探讨了一些新的话题，如后处理剪辑、不同水平的监督剪辑和应用于不同领域（如对抗攻击），以便更好地了解现有方法的共同点和不同点，并为未来的研究提供基础。<details>
<summary>Abstract</summary>
Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources. To enable the deployment of modern models on resource-constrained environments and accelerate inference time, researchers have increasingly explored pruning techniques as a popular research direction in neural network compression. However, there is a dearth of up-to-date comprehensive review papers on pruning. To address this issue, in this survey, we provide a comprehensive review of existing research works on deep neural network pruning in a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to prune, and 4) fusion of pruning and other compression techniques. We then provide a thorough comparative analysis of seven pairs of contrast settings for pruning (e.g., unstructured/structured) and explore emerging topics, including post-training pruning, different levels of supervision for pruning, and broader applications (e.g., adversarial robustness) to shed light on the commonalities and differences of existing methods and lay the foundation for further method development. To facilitate future research, we build a curated collection of datasets, networks, and evaluations on different applications. Finally, we provide some valuable recommendations on selecting pruning methods and prospect promising research directions. We build a repository at https://github.com/hrcheng1066/awesome-pruning.
</details>
<details>
<summary>摘要</summary>
现代深度神经网络，特别是最近的大语言模型，具有庞大的模型大小，需要显著的计算和存储资源。为了在有限资源环境中部署现代模型和加速推理时间，研究人员逐渐探索剪枝技术作为神经网络压缩的流行研究方向。然而，有很多相关研究的报告是不够全面的。为了解决这个问题，在这个调查中，我们提供了一份完整的剪枝技术评论，包括1) 通用/特定速度，2) 何时剪枝，3) 如何剪枝，和4) 剪枝与其他压缩技术的融合。然后，我们进行了7对7的对比分析，探讨不同的设定（例如，无结构/结构），并探索了新的主题，如后期剪枝、不同水平的监督、以及更广泛的应用（例如，对抗攻击），以便更好地了解现有方法的共同点和差异，并为未来的研究提供基础。为便于未来的研究，我们创建了一个汇总的数据集、网络和评估的库，并提供了一些有价值的建议，以及一些前景探索的可能性。
</details></li>
</ul>
<hr>
<h2 id="Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes"><a href="#Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes" class="headerlink" title="Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes"></a>Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06762">http://arxiv.org/abs/2308.06762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Huang, Xukun Zhang, Zhiming Cui, He Zhang, Geng Chen, Dinggang Shen</li>
<li>for: 这个论文的目的是为了提高胎儿大脑磁共振成像（MR）扫描中的精准组织分割。</li>
<li>methods: 这篇论文使用了域适应技术，将高质量的ISO体磁共振图像（和其相应的注解）作为指导，以提高胎儿大脑磁共振扫描中的精准组织分割。</li>
<li>results: 这篇论文的实验结果表明，使用C2DA-Net可以在胎儿大脑磁共振扫描中提高精准组织分割的性能，并且比前Edge的方法更好。<details>
<summary>Abstract</summary>
Accurate tissue segmentation of thick-slice fetal brain magnetic resonance (MR) scans is crucial for both reconstruction of isotropic brain MR volumes and the quantification of fetal brain development. However, this task is challenging due to the use of thick-slice scans in clinically-acquired fetal brain data. To address this issue, we propose to leverage high-quality isotropic fetal brain MR volumes (and also their corresponding annotations) as guidance for segmentation of thick-slice scans. Due to existence of significant domain gap between high-quality isotropic volume (i.e., source data) and thick-slice scans (i.e., target data), we employ a domain adaptation technique to achieve the associated knowledge transfer (from high-quality <source> volumes to thick-slice <target> scans). Specifically, we first register the available high-quality isotropic fetal brain MR volumes across different gestational weeks to construct longitudinally-complete source data. To capture domain-invariant information, we then perform Fourier decomposition to extract image content and style codes. Finally, we propose a novel Cycle-Consistent Domain Adaptation Network (C2DA-Net) to efficiently transfer the knowledge learned from high-quality isotropic volumes for accurate tissue segmentation of thick-slice scans. Our C2DA-Net can fully utilize a small set of annotated isotropic volumes to guide tissue segmentation on unannotated thick-slice scans. Extensive experiments on a large-scale dataset of 372 clinically acquired thick-slice MR scans demonstrate that our C2DA-Net achieves much better performance than cutting-edge methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
准确的脏部分 segmentation thick-slice 胎 Mind Magnetic Resonance（MR）扫描是关键的，以重建是otropic 胎 Mind MR 体积以及胎 Mind 发展评估。然而，这项任务受到thick-slice 扫描的使用带来挑战，因为这些扫描通常具有低分辨率。为了解决这个问题，我们提议利用高质量的 isotropic 胎 Mind MR 体积（以及其相应的注释）作为指导，以提高 thick-slice 扫描的 segmentation 精度。由于源数据和目标数据之间存在显著的领域差异，我们采用领域适应技术来实现相关的知识传递。具体来说，我们首先将可用的高质量 isotropic 胎 Mind MR 体积进行注册，以构建不同 Gestational Week 的 longitudinally-complete 源数据。然后，我们使用 Fourier 分解来提取图像内容和样式代码。最后，我们提议一种新的 Cycle-Consistent Domain Adaptation Network（C2DA-Net），以高效地将高质量 isotropic 体积中学到的知识传递到 thick-slice 扫描中。我们的 C2DA-Net 可以充分利用一小组注释的 isotropic 体积来导引脏部分 segmentation on unannotated thick-slice scans。我们在一个大规模的数据集上进行了广泛的实验，并证明了我们的 C2DA-Net 在量和质量上都有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Influence-Function-Based-Second-Order-Channel-Pruning-Evaluating-True-Loss-Changes-For-Pruning-Is-Possible-Without-Retraining"><a href="#Influence-Function-Based-Second-Order-Channel-Pruning-Evaluating-True-Loss-Changes-For-Pruning-Is-Possible-Without-Retraining" class="headerlink" title="Influence Function Based Second-Order Channel Pruning-Evaluating True Loss Changes For Pruning Is Possible Without Retraining"></a>Influence Function Based Second-Order Channel Pruning-Evaluating True Loss Changes For Pruning Is Possible Without Retraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06755">http://arxiv.org/abs/2308.06755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrcheng1066/ifso">https://github.com/hrcheng1066/ifso</a></li>
<li>paper_authors: Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi</li>
<li>for: 这篇论文旨在提出一种新的通道缩减方法，以更有效地选择需要缩减的通道。</li>
<li>methods: 该方法使用了Influence Function（影响函数）来评估通道的真实损失变化，而不需要重新训练权重。</li>
<li>results: 实验表明，该方法可以更加准确地选择需要缩减的通道，并且比exististing方法更快速。此外，该方法还开拓出了一些新的可能性，例如可以不需要重新训练权重来评估true损失变化。<details>
<summary>Abstract</summary>
A challenge of channel pruning is designing efficient and effective criteria to select channels to prune. A widely used criterion is minimal performance degeneration. To accurately evaluate the truth performance degeneration requires retraining the survived weights to convergence, which is prohibitively slow. Hence existing pruning methods use previous weights (without retraining) to evaluate the performance degeneration. However, we observe the loss changes differ significantly with and without retraining. It motivates us to develop a technique to evaluate true loss changes without retraining, with which channels to prune can be selected more reliably and confidently. We first derive a closed-form estimator of the true loss change per pruning mask change, using influence functions without retraining. Influence function which is from robust statistics reveals the impacts of a training sample on the model's prediction and is repurposed by us to assess impacts on true loss changes. We then show how to assess the importance of all channels simultaneously and develop a novel global channel pruning algorithm accordingly. We conduct extensive experiments to verify the effectiveness of the proposed algorithm. To the best of our knowledge, we are the first that shows evaluating true loss changes for pruning without retraining is possible. This finding will open up opportunities for a series of new paradigms to emerge that differ from existing pruning methods. The code is available at https://github.com/hrcheng1066/IFSO.
</details>
<details>
<summary>摘要</summary>
一个频道剔除挑战是设计高效、有效的选择频道的 критеририи。广泛使用的标准是最小性能倒退。然而，要准确评估真正的性能倒退，需要重新训练存活的权重，这是非常慢的。因此，现有的剔除方法使用前一个 weights（无需重新训练）来评估性能倒退。但我们发现，无需重新训练时的损失变化很大。这种发现使我们开发一种评估真正的损失变化的技术，以更加可靠和自信地选择剔除频道。我们首先 deriv 一个关闭式估计器，用于评估每个剔除面积变化后的真正损失变化。我们使用 robust 统计中的影响函数，无需重新训练，可以准确地评估频道对模型预测的影响。然后，我们可以同时评估所有频道的重要性，并开发了一种全局频道剔除算法。我们进行了广泛的实验，证明了我们的提案的有效性。根据我们所知，我们是第一个证明可以无需重新训练评估真正的损失变化的人。这一发现将开启一系列的新思想，与现有的剔除方法不同。我们的代码可以在 <https://github.com/hrcheng1066/IFSO> 上找到。
</details></li>
</ul>
<hr>
<h2 id="FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table"><a href="#FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table" class="headerlink" title="FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table"></a>FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06749">http://arxiv.org/abs/2308.06749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenhao-li-777/fastllve">https://github.com/wenhao-li-777/fastllve</a></li>
<li>paper_authors: Wenhao Li, Guangyang Wu, Wenyi Wang, Peiran Ren, Xiaohong Liu</li>
<li>for: 提高低光照视频质量</li>
<li>methods: 使用Look-Up-Table（LUT）技术维护间帧亮度一致性，并设计了学习型Intensity-Aware LUT（IA-LUT）模块进行自适应增强。</li>
<li>results: 实验结果表明，我们的方法在质量和间帧亮度一致性两个方面均达到了领先水平，并且可以在1080p视频上实现50+帧&#x2F;秒的处理速度，比SOTA CNN基于方法更快。<details>
<summary>Abstract</summary>
Low-Light Video Enhancement (LLVE) has received considerable attention in recent years. One of the critical requirements of LLVE is inter-frame brightness consistency, which is essential for maintaining the temporal coherence of the enhanced video. However, most existing single-image-based methods fail to address this issue, resulting in flickering effect that degrades the overall quality after enhancement. Moreover, 3D Convolution Neural Network (CNN)-based methods, which are designed for video to maintain inter-frame consistency, are computationally expensive, making them impractical for real-time applications. To address these issues, we propose an efficient pipeline named FastLLVE that leverages the Look-Up-Table (LUT) technique to maintain inter-frame brightness consistency effectively. Specifically, we design a learnable Intensity-Aware LUT (IA-LUT) module for adaptive enhancement, which addresses the low-dynamic problem in low-light scenarios. This enables FastLLVE to perform low-latency and low-complexity enhancement operations while maintaining high-quality results. Experimental results on benchmark datasets demonstrate that our method achieves the State-Of-The-Art (SOTA) performance in terms of both image quality and inter-frame brightness consistency. More importantly, our FastLLVE can process 1,080p videos at $\mathit{50+}$ Frames Per Second (FPS), which is $\mathit{2 \times}$ faster than SOTA CNN-based methods in inference time, making it a promising solution for real-time applications. The code is available at https://github.com/Wenhao-Li-777/FastLLVE.
</details>
<details>
<summary>摘要</summary>
低光照视频提升（LLVE）在最近几年内获得了广泛关注。一个关键的需求是 между帧亮度一致性，这是维护提升后视频的时间一致性的关键。然而，大多数现有的单图像基方法无法解决这个问题，导致提升后的视频呈现出抖抖的效果，从而降低总质量。此外，基于视频的3D卷积神经网络（CNN）方法，尽管可以维护间帧一致性，但是计算成本高昂，使其不适合实时应用。为解决这些问题，我们提出了一个高效的排序名为快速LLVE，它利用了Look-Up-Table（LUT）技术来保证间帧亮度一致性。我们特别设计了一个可学习的Intensity-Aware LUT（IA-LUT）模块，用于自适应增强，解决低动态问题在低光照场景下。这使得快速LLVE可以在低延迟和低复杂度下进行增强操作，同时保持高质量结果。实验结果表明，我们的方法在标准测试集上达到了领先的性能水平， both image quality和间帧亮度一致性。此外，我们的快速LLVE可以处理1080p视频，并在50+帧每秒进行加速，这比SOTA CNN基于方法的推理时间快速2倍。代码可以在https://github.com/Wenhao-Li-777/FastLLVE中找到。
</details></li>
</ul>
<hr>
<h2 id="Target-before-Shooting-Accurate-Anomaly-Detection-and-Localization-under-One-Millisecond-via-Cascade-Patch-Retrieval"><a href="#Target-before-Shooting-Accurate-Anomaly-Detection-and-Localization-under-One-Millisecond-via-Cascade-Patch-Retrieval" class="headerlink" title="Target before Shooting: Accurate Anomaly Detection and Localization under One Millisecond via Cascade Patch Retrieval"></a>Target before Shooting: Accurate Anomaly Detection and Localization under One Millisecond via Cascade Patch Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06748">http://arxiv.org/abs/2308.06748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flyinghu123/cpr">https://github.com/flyinghu123/cpr</a></li>
<li>paper_authors: Hanxi Li, Jianfei Hu, Bo Li, Hao Chen, Yongbin Zheng, Chunhua Shen</li>
<li>for: 提出了一种新的异常检测框架，实现了同时保证异常检测精度和运行速度的两个目标。</li>
<li>methods: 该框架通过粗细匹配方法选择测试图像各个小块的最佳对比图像，然后使用地区匹配方法在这些地区找到最佳的地方匹配。最后，计算每个测试图像块的异常分数基于地方匹配距离和非背景概率。</li>
<li>results: 在MVTec AD、BTAD和MVTec-3D AD等三个评测 dataset 上，提出的方法与所有参照方法进行比较，具有显著的优势，测试结果表明，该方法在不同的异常检测任务中具有较高的精度和较低的时间复杂度。<details>
<summary>Abstract</summary>
In this work, by re-examining the "matching" nature of Anomaly Detection (AD), we propose a new AD framework that simultaneously enjoys new records of AD accuracy and dramatically high running speed. In this framework, the anomaly detection problem is solved via a cascade patch retrieval procedure that retrieves the nearest neighbors for each test image patch in a coarse-to-fine fashion. Given a test sample, the top-K most similar training images are first selected based on a robust histogram matching process. Secondly, the nearest neighbor of each test patch is retrieved over the similar geometrical locations on those "global nearest neighbors", by using a carefully trained local metric. Finally, the anomaly score of each test image patch is calculated based on the distance to its "local nearest neighbor" and the "non-background" probability. The proposed method is termed "Cascade Patch Retrieval" (CPR) in this work. Different from the conventional patch-matching-based AD algorithms, CPR selects proper "targets" (reference images and locations) before "shooting" (patch-matching). On the well-acknowledged MVTec AD, BTAD and MVTec-3D AD datasets, the proposed algorithm consistently outperforms all the comparing SOTA methods by remarkable margins, measured by various AD metrics. Furthermore, CPR is extremely efficient. It runs at the speed of 113 FPS with the standard setting while its simplified version only requires less than 1 ms to process an image at the cost of a trivial accuracy drop. The code of CPR is available at https://github.com/flyinghu123/CPR.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们重新审视了异常检测（AD）的“匹配”性质，并提出了一种新的AD框架，该框架同时具有新纪录级AD准确率和极高的运行速度。在该框架中，异常检测问题通过一种层次补丁检索过程来解决，首先选择测试样本中最相似的训练图像集，然后在这些“全球最似图像”上进行精心训练的本地度量来检索测试补丁的最近邻居。最后，测试图像补丁的异常分数根据补丁与“本地最似图像”以及“非背景”概率来计算。我们称这种方法为“层次补丁检索”（CPR）。与传统的补丁匹配基于AD算法不同，CPR在选择“目标”（参考图像和位置）之前已经选择了合适的“目标”。在广泛承认的MVTec AD、BTAD和MVTec-3D AD数据集上，我们的提案方法与所有比较参考方法的较大胜利差度相比，按照不同的AD指标进行评价。此外，CPR非常高效，它在标准设置下运行速度达113帧/秒，而其简化版本只需0.1毫秒来处理一幅图像，而且只有一rivial的准确率下降。CPR的代码可以在GitHub上找到：https://github.com/flyinghu123/CPR。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising"><a href="#Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising" class="headerlink" title="Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising"></a>Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06746">http://arxiv.org/abs/2308.06746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyuan01/self-supervised-noise2noise-for-ldct">https://github.com/xyuan01/self-supervised-noise2noise-for-ldct</a></li>
<li>paper_authors: Yuting Zhu, Qiang He, Yudong Yao, Yueyang Teng</li>
<li>for: 这篇论文旨在提出一种基于单簇 Computed Tomography (CT) 影像的自动降噪方法，不需要配对的陌生资料。</li>
<li>methods: 这篇论文使用了一种组合方法，包括自我指导的噪声2噪声模型和陌生噪声策略。首先，我们将 LDCT 影像重复地添加了一种相似的噪声。然后，我们使用只有次要损坏的影像进行训练。我们选择了一个模组化 U-Net 结构来进行任务，这样可以增加讯号场的视野而无需增加参数数。</li>
<li>results: 实验结果显示，提案的方法比过去的深度学习方法更有效率，在 Mayo LDCT 数据集上得到了好的效果。<details>
<summary>Abstract</summary>
Deep learning is a very promising technique for low-dose computed tomography (LDCT) image denoising. However, traditional deep learning methods require paired noisy and clean datasets, which are often difficult to obtain. This paper proposes a new method for performing LDCT image denoising with only LDCT data, which means that normal-dose CT (NDCT) is not needed. We adopt a combination including the self-supervised noise2noise model and the noisy-as-clean strategy. First, we add a second yet similar type of noise to LDCT images multiple times. Note that we use LDCT images based on the noisy-as-clean strategy for corruption instead of NDCT images. Then, the noise2noise model is executed with only the secondary corrupted images for training. We select a modular U-Net structure from several candidates with shared parameters to perform the task, which increases the receptive field without increasing the parameter size. The experimental results obtained on the Mayo LDCT dataset show the effectiveness of the proposed method compared with that of state-of-the-art deep learning methods. The developed code is available at https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT.
</details>
<details>
<summary>摘要</summary>
深度学习是LDCT图像锈除的非常有前途的技术。然而，传统的深度学习方法需要配备附近的噪声和清洁数据集，这经常很难以获得。这篇论文提出了一种使用仅LDCT数据进行LDCT图像锈除的新方法。我们采用了混合自我supervised随机噪声模型和噪声作为清洁策略。首先，我们将LDCT图像添加了多个相似的噪声。注意，我们使用LDCT图像作为噪声Strategy instead ofNDCT图像。然后，我们执行了噪声2噪声模型，只使用次要损害的图像进行训练。我们选择了一种模块化U-Net结构从多个候选结构中，以增加感知场而不是增加参数大小。实验结果在Mayo LDCT数据集上表明了提议的方法的有效性，比对现有的深度学习方法更好。开发代码可以在https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT中下载。
</details></li>
</ul>
<hr>
<h2 id="TextDiff-Mask-Guided-Residual-Diffusion-Models-for-Scene-Text-Image-Super-Resolution"><a href="#TextDiff-Mask-Guided-Residual-Diffusion-Models-for-Scene-Text-Image-Super-Resolution" class="headerlink" title="TextDiff: Mask-Guided Residual Diffusion Models for Scene Text Image Super-Resolution"></a>TextDiff: Mask-Guided Residual Diffusion Models for Scene Text Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06743">http://arxiv.org/abs/2308.06743</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lenubolim/textdiff">https://github.com/lenubolim/textdiff</a></li>
<li>paper_authors: Baolin Liu, Zongyuan Yang, Pengfei Wang, Junjie Zhou, Ziqi Liu, Ziyi Song, Yan Liu, Yongping Xiong</li>
<li>For: The paper aims to improve the readability and recognizability of scene text images by proposing a diffusion-based framework for scene text image super-resolution.* Methods: The proposed method, called TextDiff, consists of two modules: the Text Enhancement Module (TEM) and the Mask-Guided Residual Diffusion Module (MRD). The TEM generates an initial deblurred text image and a mask that encodes the spatial location of the text, while the MRD effectively sharpenes the text edge by modeling the residuals between the ground-truth images and the initial deblurred images.* Results: The proposed TextDiff achieves state-of-the-art (SOTA) performance on public benchmark datasets and can improve the readability of scene text images. Additionally, the MRD module is plug-and-play and can effectively sharpens the text edges produced by SOTA methods without requiring any additional joint training.<details>
<summary>Abstract</summary>
The goal of scene text image super-resolution is to reconstruct high-resolution text-line images from unrecognizable low-resolution inputs. The existing methods relying on the optimization of pixel-level loss tend to yield text edges that exhibit a notable degree of blurring, thereby exerting a substantial impact on both the readability and recognizability of the text. To address these issues, we propose TextDiff, the first diffusion-based framework tailored for scene text image super-resolution. It contains two modules: the Text Enhancement Module (TEM) and the Mask-Guided Residual Diffusion Module (MRD). The TEM generates an initial deblurred text image and a mask that encodes the spatial location of the text. The MRD is responsible for effectively sharpening the text edge by modeling the residuals between the ground-truth images and the initial deblurred images. Extensive experiments demonstrate that our TextDiff achieves state-of-the-art (SOTA) performance on public benchmark datasets and can improve the readability of scene text images. Moreover, our proposed MRD module is plug-and-play that effectively sharpens the text edges produced by SOTA methods. This enhancement not only improves the readability and recognizability of the results generated by SOTA methods but also does not require any additional joint training. Available Codes:https://github.com/Lenubolim/TextDiff.
</details>
<details>
<summary>摘要</summary>
目标是帮助您将低分辨率的场景文本图像转换成高分辨率文本线图像。现有的方法通常通过像素级损失优化来实现文本边缘的增强，但这会导致文本边缘变得模糊，从而影响文本的可读性和识别性。为了解决这些问题，我们提出了 TextDiff，首个适用于场景文本图像超分辨率的扩散框架。它包括两个模块：文本增强模块（TEM）和帮助器导向残差扩散模块（MRD）。TEM 生成了初始的去噪文本图像和一个描述文本的空间位置的面罩。MRD 负责通过模拟实际图像和初始去噪图像之间的差异来有效地尖锐文本边缘。我们进行了广泛的实验，结果表明 TextDiff 在公共测试集上达到了领先的表现水平（SOTA），并可以提高场景文本图像的可读性。此外，我们提出的 MRD 模块可以很好地增强 SOTA 方法生成的文本边缘，无需额外的联合训练。可以在 GitHub 上下载代码：https://github.com/Lenubolim/TextDiff。
</details></li>
</ul>
<hr>
<h2 id="Free-ATM-Exploring-Unsupervised-Learning-on-Diffusion-Generated-Images-with-Free-Attention-Masks"><a href="#Free-ATM-Exploring-Unsupervised-Learning-on-Diffusion-Generated-Images-with-Free-Attention-Masks" class="headerlink" title="Free-ATM: Exploring Unsupervised Learning on Diffusion-Generated Images with Free Attention Masks"></a>Free-ATM: Exploring Unsupervised Learning on Diffusion-Generated Images with Free Attention Masks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06739">http://arxiv.org/abs/2308.06739</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Junhao Zhang, Mutian Xu, Chuhui Xue, Wenqing Zhang, Xiaoguang Han, Song Bai, Mike Zheng Shou</li>
<li>for: 本研究旨在解决无监督学习在视觉表示中的快速进步，尽管需要训练大规模数据集，但这会导致数据采集成本高昂，并且存在数据隐私问题。</li>
<li>methods: 我们开始通过探索 diffusion models 的 cross-attention层内置的annotation-free注意力掩模来解决这一问题。我们还investigate了三种常见的无监督学习技术（即对比学习、遮盖模型和视觉语言预训练），并提出了专门采用这些自由注意力掩模的解决方案。</li>
<li>results: 我们通过了广泛的实验，证明了我们的方法可以在不同的下游任务中提高基eline模型的性能，包括图像分类、检测、分割和图像文本检索。通过使用我们的方法，可以将无监督预训练在synthetic数据上的性能与实际场景中的性能趋同。<details>
<summary>Abstract</summary>
Despite the rapid advancement of unsupervised learning in visual representation, it requires training on large-scale datasets that demand costly data collection, and pose additional challenges due to concerns regarding data privacy. Recently, synthetic images generated by text-to-image diffusion models, have shown great potential for benefiting image recognition. Although promising, there has been inadequate exploration dedicated to unsupervised learning on diffusion-generated images. To address this, we start by uncovering that diffusion models' cross-attention layers inherently provide annotation-free attention masks aligned with corresponding text inputs on generated images. We then investigate the problems of three prevalent unsupervised learning techniques ( i.e., contrastive learning, masked modeling, and vision-language pretraining) and introduce customized solutions by fully exploiting the aforementioned free attention masks. Our approach is validated through extensive experiments that show consistent improvements in baseline models across various downstream tasks, including image classification, detection, segmentation, and image-text retrieval. By utilizing our method, it is possible to close the performance gap between unsupervised pretraining on synthetic data and real-world scenarios.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管Unsupervised learning在视觉表示方面进步 Rapidly, but it still requires expensive data collection and raises additional concerns about data privacy. Recently, text-to-image diffusion models generated synthetic images have shown great potential for image recognition. Although promising, there has been inadequate exploration of unsupervised learning on diffusion-generated images. To address this, we start by discovering that diffusion models' cross-attention layers inherently provide annotation-free attention masks aligned with corresponding text inputs on generated images. We then investigate the problems of three prevalent unsupervised learning techniques (i.e., contrastive learning, masked modeling, and vision-language pretraining) and introduce customized solutions by fully exploiting the aforementioned free attention masks. Our approach is validated through extensive experiments that show consistent improvements in baseline models across various downstream tasks, including image classification, detection, segmentation, and image-text retrieval. By utilizing our method, it is possible to close the performance gap between unsupervised pretraining on synthetic data and real-world scenarios.Translated into Traditional Chinese:尽管Unsupervised learning在视觉表示方面进步 Rapidly, but it still requires expensive data collection and raises additional concerns about data privacy. Recently, text-to-image diffusion models generated synthetic images have shown great potential for image recognition. Although promising, there has been inadequate exploration of unsupervised learning on diffusion-generated images. To address this, we start by discovering that diffusion models' cross-attention layers inherently provide annotation-free attention masks aligned with corresponding text inputs on generated images. We then investigate the problems of three prevalent unsupervised learning techniques (i.e., contrastive learning, masked modeling, and vision-language pretraining) and introduce customized solutions by fully exploiting the aforementioned free attention masks. Our approach is validated through extensive experiments that show consistent improvements in baseline models across various downstream tasks, including image classification, detection, segmentation, and image-text retrieval. By utilizing our method, it is possible to close the performance gap between unsupervised pretraining on synthetic data and real-world scenarios.
</details></li>
</ul>
<hr>
<h2 id="3D-Scene-Graph-Prediction-on-Point-Clouds-Using-Knowledge-Graphs"><a href="#3D-Scene-Graph-Prediction-on-Point-Clouds-Using-Knowledge-Graphs" class="headerlink" title="3D Scene Graph Prediction on Point Clouds Using Knowledge Graphs"></a>3D Scene Graph Prediction on Point Clouds Using Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06719">http://arxiv.org/abs/2308.06719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiding Qiu, Henrik I. Christensen</li>
<li>for:  scene graph prediction in 3D environments</li>
<li>methods: message-passing method with commonsense knowledge graphs</li>
<li>results: 15.0% improvement in scene graph prediction accuracy with external knowledge, 7.96% improvement with internal knowledge compared to state-of-the-art algorithms, and real-world testing with 10 frames per second for scene graph generation.Here’s the full text in Simplified Chinese:</li>
<li>for: scene graph prediction在3D环境中</li>
<li>methods: message-passing方法与常识知识图</li>
<li>results: 外部知识Integration leads to 15.0% improvement in scene graph prediction accuracy, 7.96% improvement with internal knowledge compared to state-of-the-art algorithms, and real-world testing with 10 frames per second for scene graph generation.<details>
<summary>Abstract</summary>
3D scene graph prediction is a task that aims to concurrently predict object classes and their relationships within a 3D environment. As these environments are primarily designed by and for humans, incorporating commonsense knowledge regarding objects and their relationships can significantly constrain and enhance the prediction of the scene graph. In this paper, we investigate the application of commonsense knowledge graphs for 3D scene graph prediction on point clouds of indoor scenes. Through experiments conducted on a real-world indoor dataset, we demonstrate that integrating external commonsense knowledge via the message-passing method leads to a 15.0 % improvement in scene graph prediction accuracy with external knowledge and $7.96\%$ with internal knowledge when compared to state-of-the-art algorithms. We also tested in the real world with 10 frames per second for scene graph generation to show the usage of the model in a more realistic robotics setting.
</details>
<details>
<summary>摘要</summary>
三维场景图预测是一项任务，旨在同时预测场景中对象的类别和其之间的关系。由于这些环境主要由人类设计和使用，因此包含常识知识对场景图预测具有明显的约束和优化作用。在这篇论文中，我们调查了在点云indoor场景中使用commonsense知识图进行三维场景图预测的应用。通过对实际indoor数据集进行实验，我们表明了将外部常识知识integrated到消息传递方法中可以提高场景图预测精度，比对 estado-of-the-art算法提高15.0%。此外，我们还在真实的 robotics 环境中测试了Scene Graph生成，以示模型的应用。
</details></li>
</ul>
<hr>
<h2 id="StairNetV3-Depth-aware-Stair-Modeling-using-Deep-Learning"><a href="#StairNetV3-Depth-aware-Stair-Modeling-using-Deep-Learning" class="headerlink" title="StairNetV3: Depth-aware Stair Modeling using Deep Learning"></a>StairNetV3: Depth-aware Stair Modeling using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06715">http://arxiv.org/abs/2308.06715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Wang, Zhongcai Pei, Shuang Qiu, Yachun Wang, Zhiyong Tang</li>
<li>for: 这 paper 的目的是提出一种基于视觉的自主移动 робоット climb 楼梯的技术，尤其是在不熟悉的环境中。</li>
<li>methods: 该 paper 使用了一种基于 convolutional neural network (CNN) 的 depth-aware stair modeling 方法，包括提取楼梯几何特征和预测深度图像为联合任务，并使用设计的信息传播架构以实现有效的超视觉学习。</li>
<li>results: 实验表明，该方法与之前最佳的单目视觉方法相比，有一个显著的提升（IOU 提升3.4%），并且Lightweight 版本具有快速检测速度，可满足大多数实时应用的需求。<details>
<summary>Abstract</summary>
Vision-based stair perception can help autonomous mobile robots deal with the challenge of climbing stairs, especially in unfamiliar environments. To address the problem that current monocular vision methods are difficult to model stairs accurately without depth information, this paper proposes a depth-aware stair modeling method for monocular vision. Specifically, we take the extraction of stair geometric features and the prediction of depth images as joint tasks in a convolutional neural network (CNN), with the designed information propagation architecture, we can achieve effective supervision for stair geometric feature learning by depth information. In addition, to complete the stair modeling, we take the convex lines, concave lines, tread surfaces and riser surfaces as stair geometric features and apply Gaussian kernels to enable the network to predict contextual information within the stair lines. Combined with the depth information obtained by depth sensors, we propose a stair point cloud reconstruction method that can quickly get point clouds belonging to the stair step surfaces. Experiments on our dataset show that our method has a significant improvement over the previous best monocular vision method, with an intersection over union (IOU) increase of 3.4 %, and the lightweight version has a fast detection speed and can meet the requirements of most real-time applications. Our dataset is available at https://data.mendeley.com/datasets/6kffmjt7g2/1.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用视觉技术，自动移动Robot可以更好地处理楼梯，特别是在未知环境中。为了解决目前的单目视觉方法难以准确地模型楼梯 without depth information，这篇论文提出了一种基于深度信息的楼梯模型方法。具体来说，我们将提取楼梯的 geometric 特征和预测深度图作为一个 convolutional neural network (CNN) 中的联合任务，通过我们设计的信息传递架构，可以实现有效的监督楼梯 geometric 特征学习。此外，为了完成楼梯模型，我们将楼梯的 convex 线、拱线、踏板面和踏梯面作为楼梯的 geometric 特征，并应用 Gaussian kernels，使网络可以预测楼梯内部的信息。与depth sensor获取的深度信息结合，我们提出了一种可以快速获取楼梯步骤表面的点云重建方法。实验结果表明，我们的方法与前一个最佳单目视觉方法相比，IOU 提高了 3.4%，轻量版本具有快速检测速度，可满足大多数实时应用的需求。我们的数据集可以在 <https://data.mendeley.com/datasets/6kffmjt7g2/1> 中下载。
</details></li>
</ul>
<hr>
<h2 id="LAW-Diffusion-Complex-Scene-Generation-by-Diffusion-with-Layouts"><a href="#LAW-Diffusion-Complex-Scene-Generation-by-Diffusion-with-Layouts" class="headerlink" title="LAW-Diffusion: Complex Scene Generation by Diffusion with Layouts"></a>LAW-Diffusion: Complex Scene Generation by Diffusion with Layouts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06713">http://arxiv.org/abs/2308.06713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Binbin Yang, Yi Luo, Ziliang Chen, Guangrun Wang, Xiaodan Liang, Liang Lin</li>
<li>for: 这篇研究是为了实现高品质的复杂场景生成，以优化现有的散射模型。</li>
<li>methods: 这篇研究提出了一个具有 semantic control 的 Layout-Aware 散射模型（LAW-Diffusion），通过内置的空间依赖解析和位置意识的跨物体注意力模组，实现了具有属地对应性和空间相互关联的场景生成。</li>
<li>results:  compared to previous Layout-to-Image（L2I）方法，LAW-Diffusion 可以更好地生成具有内在逻辑和空间相互关联的场景，并且可以实现实际中的实例重新构成。<details>
<summary>Abstract</summary>
Thanks to the rapid development of diffusion models, unprecedented progress has been witnessed in image synthesis. Prior works mostly rely on pre-trained linguistic models, but a text is often too abstract to properly specify all the spatial properties of an image, e.g., the layout configuration of a scene, leading to the sub-optimal results of complex scene generation. In this paper, we achieve accurate complex scene generation by proposing a semantically controllable Layout-AWare diffusion model, termed LAW-Diffusion. Distinct from the previous Layout-to-Image generation (L2I) methods that only explore category-aware relationships, LAW-Diffusion introduces a spatial dependency parser to encode the location-aware semantic coherence across objects as a layout embedding and produces a scene with perceptually harmonious object styles and contextual relations. To be specific, we delicately instantiate each object's regional semantics as an object region map and leverage a location-aware cross-object attention module to capture the spatial dependencies among those disentangled representations. We further propose an adaptive guidance schedule for our layout guidance to mitigate the trade-off between the regional semantic alignment and the texture fidelity of generated objects. Moreover, LAW-Diffusion allows for instance reconfiguration while maintaining the other regions in a synthesized image by introducing a layout-aware latent grafting mechanism to recompose its local regional semantics. To better verify the plausibility of generated scenes, we propose a new evaluation metric for the L2I task, dubbed Scene Relation Score (SRS) to measure how the images preserve the rational and harmonious relations among contextual objects. Comprehensive experiments demonstrate that our LAW-Diffusion yields the state-of-the-art generative performance, especially with coherent object relations.
</details>
<details>
<summary>摘要</summary>
due to the rapid development of diffusion models, there have been unprecedented advances in image synthesis. previous works mainly rely on pre-trained linguistic models, but a text is often too abstract to properly specify all the spatial properties of an image, such as the layout configuration of a scene, leading to sub-optimal results of complex scene generation. in this paper, we achieve accurate complex scene generation by proposing a semantically controllable Layout-AWare diffusion model, termed LAW-Diffusion. unlike previous Layout-to-Image (L2I) methods that only explore category-aware relationships, LAW-Diffusion introduces a spatial dependency parser to encode the location-aware semantic coherence across objects as a layout embedding and produces a scene with perceptually harmonious object styles and contextual relations. specifically, we delicately instantiate each object's regional semantics as an object region map and leverage a location-aware cross-object attention module to capture the spatial dependencies among those disentangled representations. we also propose an adaptive guidance schedule for our layout guidance to mitigate the trade-off between the regional semantic alignment and the texture fidelity of generated objects. furthermore, LAW-Diffusion allows for instance reconfiguration while maintaining the other regions in a synthesized image by introducing a layout-aware latent grafting mechanism to recompose its local regional semantics. to better verify the plausibility of generated scenes, we propose a new evaluation metric for the L2I task, dubbed Scene Relation Score (SRS) to measure how the images preserve the rational and harmonious relations among contextual objects. comprehensive experiments demonstrate that our LAW-Diffusion yields the state-of-the-art generative performance, especially with coherent object relations.
</details></li>
</ul>
<hr>
<h2 id="Compositional-Feature-Augmentation-for-Unbiased-Scene-Graph-Generation"><a href="#Compositional-Feature-Augmentation-for-Unbiased-Scene-Graph-Generation" class="headerlink" title="Compositional Feature Augmentation for Unbiased Scene Graph Generation"></a>Compositional Feature Augmentation for Unbiased Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06712">http://arxiv.org/abs/2308.06712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Li, Guikun Chen, Jun Xiao, Yi Yang, Chunping Wang, Long Chen</li>
<li>for: 本研究旨在探讨如何更好地探测图像中的视觉关系 triplets &lt;sub, pred, obj&gt;，以提高Scene Graph Generation (SGG) 的性能。</li>
<li>methods: 本文提出了一种新的Compositional Feature Augmentation (CFA)策略，该策略可以增加每个 predicate 的关系 triplet 特征的多样性，从而提高 SGG 的鲁棒性。CFA 包括将每个关系 triplet 特征分解成两部分：内在特征和外在特征，然后通过将这些特征与其他样本的特征进行替换或混合来增加 triplet 特征的多样性。</li>
<li>results: 对比于现有的重新权衡策略，CFA 可以更好地增加每个 predicate 的关系 triplet 特征的多样性，从而提高 SGG 的性能。经过广泛的ablation研究，我们发现CFA 可以在不同的 metrics 之间取得新的状态公共表现。<details>
<summary>Abstract</summary>
Scene Graph Generation (SGG) aims to detect all the visual relation triplets <sub, pred, obj> in a given image. With the emergence of various advanced techniques for better utilizing both the intrinsic and extrinsic information in each relation triplet, SGG has achieved great progress over the recent years. However, due to the ubiquitous long-tailed predicate distributions, today's SGG models are still easily biased to the head predicates. Currently, the most prevalent debiasing solutions for SGG are re-balancing methods, e.g., changing the distributions of original training samples. In this paper, we argue that all existing re-balancing strategies fail to increase the diversity of the relation triplet features of each predicate, which is critical for robust SGG. To this end, we propose a novel Compositional Feature Augmentation (CFA) strategy, which is the first unbiased SGG work to mitigate the bias issue from the perspective of increasing the diversity of triplet features. Specifically, we first decompose each relation triplet feature into two components: intrinsic feature and extrinsic feature, which correspond to the intrinsic characteristics and extrinsic contexts of a relation triplet, respectively. Then, we design two different feature augmentation modules to enrich the feature diversity of original relation triplets by replacing or mixing up either their intrinsic or extrinsic features from other samples. Due to its model-agnostic nature, CFA can be seamlessly incorporated into various SGG frameworks. Extensive ablations have shown that CFA achieves a new state-of-the-art performance on the trade-off between different metrics.
</details>
<details>
<summary>摘要</summary>
Specifically, we first decompose each relation triplet feature into two components: intrinsic feature and extrinsic feature, which correspond to the intrinsic characteristics and extrinsic contexts of a relation triplet, respectively. Then, we design two different feature augmentation modules to enrich the feature diversity of original relation triplets by replacing or mixing up either their intrinsic or extrinsic features from other samples. Due to its model-agnostic nature, CFA can be seamlessly incorporated into various SGG frameworks. Extensive ablations have shown that CFA achieves a new state-of-the-art performance on the trade-off between different metrics.
</details></li>
</ul>
<hr>
<h2 id="Condition-Adaptive-Graph-Convolution-Learning-for-Skeleton-Based-Gait-Recognition"><a href="#Condition-Adaptive-Graph-Convolution-Learning-for-Skeleton-Based-Gait-Recognition" class="headerlink" title="Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait Recognition"></a>Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06707">http://arxiv.org/abs/2308.06707</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oliverhxh/cag">https://github.com/oliverhxh/cag</a></li>
<li>paper_authors: Xiaohu Huang, Xinggang Wang, Zhidianqiu Jin, Bo Yang, Botao He, Bin Feng, Wenyu Liu</li>
<li>for: 本研究旨在提高skeleton-based gait认知 task中的个人识别率，使用graph convolutional networks (GCNs)来提取多视角下不同人体姿势的特征。</li>
<li>methods: 我们提出了一种condition-adaptive graph (CAG) convolution network，具有自适应特征和视角的能力。CAG网络包括joint-specific filter learning (JSFL)模块和view-adaptive topology learning (VATL)模块。JSFL模块生成每个关节独特的滤波器， capture细腻的姿势特征；VATL模块生成适应视角的图学结构，对关节进行相应的相关处理。</li>
<li>results: 实验结果表明，CAG网络在CASIA-B和OU-MVLP两个最常用的数据集上都超过了所有之前的skeleton-based方法。此外，通过与视觉基本方法相结合，CAG网络可以提供有用的补充信息，提高了识别率。<details>
<summary>Abstract</summary>
Graph convolutional networks have been widely applied in skeleton-based gait recognition. A key challenge in this task is to distinguish the individual walking styles of different subjects across various views. Existing state-of-the-art methods employ uniform convolutions to extract features from diverse sequences and ignore the effects of viewpoint changes. To overcome these limitations, we propose a condition-adaptive graph (CAG) convolution network that can dynamically adapt to the specific attributes of each skeleton sequence and the corresponding view angle. In contrast to using fixed weights for all joints and sequences, we introduce a joint-specific filter learning (JSFL) module in the CAG method, which produces sequence-adaptive filters at the joint level. The adaptive filters capture fine-grained patterns that are unique to each joint, enabling the extraction of diverse spatial-temporal information about body parts. Additionally, we design a view-adaptive topology learning (VATL) module that generates adaptive graph topologies. These graph topologies are used to correlate the joints adaptively according to the specific view conditions. Thus, CAG can simultaneously adjust to various walking styles and viewpoints. Experiments on the two most widely used datasets (i.e., CASIA-B and OU-MVLP) show that CAG surpasses all previous skeleton-based methods. Moreover, the recognition performance can be enhanced by simply combining CAG with appearance-based methods, demonstrating the ability of CAG to provide useful complementary information.The source code will be available at https://github.com/OliverHxh/CAG.
</details>
<details>
<summary>摘要</summary>
“几何卷积网络在人体骨架基于步行识别中广泛应用。一个关键挑战在这个任务中是在不同的视角下分辨别人的步行风格。现有的状态艺术方法使用固定的权重来抽取不同序列中的特征，并忽略视角变化的影响。为了解决这些限制，我们提议一种可适应条件的几何卷积网络（CAG），可以动态适应每个骨架序列和相应的视角。而不是使用所有关节和序列中的固定权重，我们引入了关节特定的缓冲学（JSFL）模块，该模块生成序列特有的缓冲。这些缓冲能够捕捉每个关节细腻的特征，并提取不同的空间-时间信息。此外，我们设计了视角适应图学（VATL）模块，该模块生成适应视角的图学结构。这些图学结构用于相互相关关节，以适应特定的视角条件。因此，CAG可以同时适应不同的步行风格和视角。实验结果表明，CAG超过了所有之前的骨架基于方法，并且可以通过简单地将CAG与外观基于方法相结合，进一步提高识别性能。代码将在 GitHub 上发布，请参考 <https://github.com/OliverHxh/CAG>。”
</details></li>
</ul>
<hr>
<h2 id="Isomer-Isomerous-Transformer-for-Zero-shot-Video-Object-Segmentation"><a href="#Isomer-Isomerous-Transformer-for-Zero-shot-Video-Object-Segmentation" class="headerlink" title="Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation"></a>Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06693">http://arxiv.org/abs/2308.06693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dlut-yyc/isomer">https://github.com/dlut-yyc/isomer</a></li>
<li>paper_authors: Yichen Yuan, Yifan Wang, Lijun Wang, Xiaoqi Zhao, Huchuan Lu, Yu Wang, Weibo Su, Lei Zhang</li>
<li>for: 这个论文主要针对 Zero-Shot Video Object Segmentation (ZVOS) 任务，即在不使用任何 annotated video data 的情况下，将视频中的 объекты segmentation 到准确的位置和类别。</li>
<li>methods: 该论文提出了两种基于 Transformer 的方法，分别是 Context-Sharing Transformer (CST) 和 Semantic Gathering-Scattering Transformer (SGST)，以提高 ZVOS 的性能和计算效率。</li>
<li>results: 与基eline相比，该论文的方法在 ZVOS 任务中具有新的 state-of-the-art 性能，同时提高了计算效率，相比基eline的 13 倍。 Code 可以在 <a target="_blank" rel="noopener" href="https://github.com/DLUT-yyc/Isomer">https://github.com/DLUT-yyc/Isomer</a> 上下载。<details>
<summary>Abstract</summary>
Recent leading zero-shot video object segmentation (ZVOS) works devote to integrating appearance and motion information by elaborately designing feature fusion modules and identically applying them in multiple feature stages. Our preliminary experiments show that with the strong long-range dependency modeling capacity of Transformer, simply concatenating the two modality features and feeding them to vanilla Transformers for feature fusion can distinctly benefit the performance but at a cost of heavy computation. Through further empirical analysis, we find that attention dependencies learned in Transformer in different stages exhibit completely different properties: global query-independent dependency in the low-level stages and semantic-specific dependency in the high-level stages. Motivated by the observations, we propose two Transformer variants: i) Context-Sharing Transformer (CST) that learns the global-shared contextual information within image frames with a lightweight computation. ii) Semantic Gathering-Scattering Transformer (SGST) that models the semantic correlation separately for the foreground and background and reduces the computation cost with a soft token merging mechanism. We apply CST and SGST for low-level and high-level feature fusions, respectively, formulating a level-isomerous Transformer framework for ZVOS task. Compared with the baseline that uses vanilla Transformers for multi-stage fusion, ours significantly increase the speed by 13 times and achieves new state-of-the-art ZVOS performance. Code is available at https://github.com/DLUT-yyc/Isomer.
</details>
<details>
<summary>摘要</summary>
现代领先的零shot视频对象分割（ZVOS）方法强调 интеграción appeared和动作信息，通过设计优化的特征融合模块来实现。我们的初步实验表明，使用强大的长距离依赖模型Transformer可以明显提高性能，但是需要高计算成本。通过进一步的实验分析，我们发现Transformer中不同阶段的注意力关系都有不同性质：低阶段的全局缺省关系和高阶段的Semantic特定关系。这些发现驱动我们提出两种Transformer变体：i) 共享上下文Transformer（CST），通过轻量级计算学习图像帧中的全局共享上下文信息。ii)  semantic聚合散发Transformer（SGST），通过软token合并机制模型对eground和background的semantic相关性，减少计算成本。我们在不同阶段使用CST和SGST进行特征融合，组成了级别异谱Transformer框架，与基eline相比，我们的方法可以提高13倍的速度，并达到新的ZVOS性能记录。代码可以在https://github.com/DLUT-yyc/Isomer上下载。
</details></li>
</ul>
<hr>
<h2 id="SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency"><a href="#SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency" class="headerlink" title="SimMatchV2: Semi-Supervised Learning with Graph Consistency"></a>SimMatchV2: Semi-Supervised Learning with Graph Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06692">http://arxiv.org/abs/2308.06692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingkai-zheng/simmatchv2">https://github.com/mingkai-zheng/simmatchv2</a></li>
<li>paper_authors: Mingkai Zheng, Shan You, Lang Huang, Chen Luo, Fei Wang, Chen Qian, Chang Xu</li>
<li>for: 这个论文目的是提出一种新的半监督学习算法，以解决计算机视觉领域中的半监督图像分类问题。</li>
<li>methods: 该算法基于图 teoría的消息传递和节点分类，并提出了四种一致性，包括节点-节点一致性、节点-边一致性、边-边一致性和边-节点一致性。</li>
<li>results: 该算法在多个半监督学习benchmark上进行验证，与ResNet-50作为背景网络和300个训练 epoch，SimMatchV2实现了71.9%和76.2%的Top-1准确率，分别使用1%和10%的标注样本。这些成果在之前的方法中显著超越，达到了状态作准的性能。<details>
<summary>Abstract</summary>
Semi-Supervised image classification is one of the most fundamental problem in computer vision, which significantly reduces the need for human labor. In this paper, we introduce a new semi-supervised learning algorithm - SimMatchV2, which formulates various consistency regularizations between labeled and unlabeled data from the graph perspective. In SimMatchV2, we regard the augmented view of a sample as a node, which consists of a label and its corresponding representation. Different nodes are connected with the edges, which are measured by the similarity of the node representations. Inspired by the message passing and node classification in graph theory, we propose four types of consistencies, namely 1) node-node consistency, 2) node-edge consistency, 3) edge-edge consistency, and 4) edge-node consistency. We also uncover that a simple feature normalization can reduce the gaps of the feature norm between different augmented views, significantly improving the performance of SimMatchV2. Our SimMatchV2 has been validated on multiple semi-supervised learning benchmarks. Notably, with ResNet-50 as our backbone and 300 epochs of training, SimMatchV2 achieves 71.9\% and 76.2\% Top-1 Accuracy with 1\% and 10\% labeled examples on ImageNet, which significantly outperforms the previous methods and achieves state-of-the-art performance. Code and pre-trained models are available at \href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2}.
</details>
<details>
<summary>摘要</summary>
semi-supervised图像分类是计算机视觉中最基本的问题之一，可以减少人工劳动。在这篇论文中，我们介绍了一种新的semi-supervised学习算法——SimMatchV2，它在图像视角下对各个样本进行了不同的拓展视图，并在图表视角下定义了多种一致性规范。在SimMatchV2中，我们将每个样本的拓展视图看作一个节点，这些节点之间通过 Edge 连接， Edge 的 Similarity 度量节点表示的一致性。我们提出了四种一致性类型：1）节点-节点一致性，2）节点-边一致性，3）边-边一致性，4）边-节点一致性。我们还发现，一个简单的特征Normalization可以降低不同拓展视图特征的差异，从而提高SimMatchV2的性能。我们的SimMatchV2在多个 semi-supervised 学习 benchmark 上进行了验证，与 ResNet-50 作为背景网络和 300  epoch 训练，SimMatchV2 在 ImageNet 上 achieve 71.9% 和 76.2% Top-1 Accuracy  WITH 1% 和 10% 标注样本，显著超过先前的方法，实现了状态的最佳性能。代码和预训练模型可以在 \href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Estimator-Meets-Equilibrium-Perspective-A-Rectified-Straight-Through-Estimator-for-Binary-Neural-Networks-Training"><a href="#Estimator-Meets-Equilibrium-Perspective-A-Rectified-Straight-Through-Estimator-for-Binary-Neural-Networks-Training" class="headerlink" title="Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training"></a>Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06689">http://arxiv.org/abs/2308.06689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dravenalg/reste">https://github.com/dravenalg/reste</a></li>
<li>paper_authors: Xiao-Ming Wu, Dian Zheng, Zuhao Liu, Wei-Shi Zheng</li>
<li>for: 这个论文的目的是提出一种能够充分考虑条件对应网络的训练稳定性的条件对应网络训练方法。</li>
<li>methods: 这个论文使用了一种名为Rectified Straight Through Estimator（ReSTE）的新的条件对应网络训练方法，它可以充分考虑条件对应网络的训练稳定性。</li>
<li>results: 实验结果显示，ReSTE可以在CIFAR-10和ImageNet datasets上 achieve excellent performance，并且比其他方法（不含任何辅助模组或损失）还要好。<details>
<summary>Abstract</summary>
Binarization of neural networks is a dominant paradigm in neural networks compression. The pioneering work BinaryConnect uses Straight Through Estimator (STE) to mimic the gradients of the sign function, but it also causes the crucial inconsistency problem. Most of the previous methods design different estimators instead of STE to mitigate it. However, they ignore the fact that when reducing the estimating error, the gradient stability will decrease concomitantly. These highly divergent gradients will harm the model training and increase the risk of gradient vanishing and gradient exploding. To fully take the gradient stability into consideration, we present a new perspective to the BNNs training, regarding it as the equilibrium between the estimating error and the gradient stability. In this view, we firstly design two indicators to quantitatively demonstrate the equilibrium phenomenon. In addition, in order to balance the estimating error and the gradient stability well, we revise the original straight through estimator and propose a power function based estimator, Rectified Straight Through Estimator (ReSTE for short). Comparing to other estimators, ReSTE is rational and capable of flexibly balancing the estimating error with the gradient stability. Extensive experiments on CIFAR-10 and ImageNet datasets show that ReSTE has excellent performance and surpasses the state-of-the-art methods without any auxiliary modules or losses.
</details>
<details>
<summary>摘要</summary>
neural networks 的归纳化是现代神经网络压缩的主导方法。 BinaryConnect 开创性的工作使用 Straight Through Estimator (STE) 模仿签名函数的梯度，但也会导致重要的不一致问题。 前一些方法设计不同的估计器来缓解这个问题，但它们忽略了当减少估计错误时，模型的梯度稳定性会降低。这些高度不同梯度会危害模型的训练和梯度涨落和爆炸。为了充分考虑梯度稳定性，我们提出了一新的审视方法，将 BNNs 训练视为梯度稳定性和估计错误之间的平衡。在这种视角下，我们首先设计了两个指标来量化平衡现象。此外，为了平衡估计错误和梯度稳定性，我们修改了原始的直通估计器，并提出了一个功能基于 rectified straight through estimator (ReSTE)。与其他估计器相比，ReSTE 是理性的，可以很好地平衡估计错误和梯度稳定性。我们对 CIFAR-10 和 ImageNet  dataset 进行了广泛的实验，结果表明 ReSTE 表现出色，超过了当前的状态艺术方法，不需要任何辅助模块或损失。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges"><a href="#Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges" class="headerlink" title="Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges"></a>Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06668">http://arxiv.org/abs/2308.06668</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiajiali04/agriculture-foundation-models">https://github.com/jiajiali04/agriculture-foundation-models</a></li>
<li>paper_authors: Jiajia Li, Mingle Xu, Lirong Xiang, Dong Chen, Weichao Zhuang, Xunyuan Yin, Zhaojian Li</li>
<li>for: 本研究旨在探讨基础模型（Foundation Model，FM）在智能农业领域的潜力。</li>
<li>methods: 本研究首先对最新的FM进行了 обзор，并将其分为四类：语言FM、视觉FM、多模态FM和强化学习FM。然后，我们详细介绍了在农业领域开发农业FM的过程，以及其在智能农业中的潜在应用。</li>
<li>results: 本研究通过对FM的探讨，提供了一个新的AI在农业领域的发展方向，即基于FM的智能农业系统。这种系统可以减少大量标注数据的依赖，提高效率和通用性。同时，我们还描述了在开发农业FM时的独特挑战，包括模型训练、验证和部署。<details>
<summary>Abstract</summary>
The past decade has witnessed the rapid development of ML and DL methodologies in agricultural systems, showcased by great successes in variety of agricultural applications. However, these conventional ML/DL models have certain limitations: They heavily rely on large, costly-to-acquire labeled datasets for training, require specialized expertise for development and maintenance, and are mostly tailored for specific tasks, thus lacking generalizability. Recently, foundation models have demonstrated remarkable successes in language and vision tasks across various domains. These models are trained on a vast amount of data from multiple domains and modalities. Once trained, they can accomplish versatile tasks with just minor fine-tuning and minimal task-specific labeled data. Despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture fields. Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, we present conceptual tools and technical background to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, we first review recent FMs in the general computer science domain and categorize them into four categories: language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs. Subsequently, we outline the process of developing agriculture FMs and discuss their potential applications in smart agriculture. We also discuss the unique challenges associated with developing AFMs, including model training, validation, and deployment. Through this study, we contribute to the advancement of AI in agriculture by introducing AFMs as a promising paradigm that can significantly mitigate the reliance on extensive labeled datasets and enhance the efficiency, effectiveness, and generalization of agricultural AI systems.
</details>
<details>
<summary>摘要</summary>
过去一代，机器学习（ML）和深度学习（DL）方法在农业系统中得到了迅速发展，在各种农业应用中显示出了很大成功。然而，传统的ML/DL模型有一些局限性：它们需要大量、成本高的标注数据进行训练，需要专业知识进行开发和维护，而且主要针对特定任务，缺乏总体化性。在最近的几年，基础模型（FM）在语言和视觉任务中获得了很大成功。这些模型在多个领域和模式上训练了庞大数据。一旦训练完成，它们可以通过微调和微量标注数据完成多种任务。despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture fields. Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, we present conceptual tools and technical background to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, we first review recent FMs in the general computer science domain and categorize them into four categories: language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs. Subsequently, we outline the process of developing agriculture FMs and discuss their potential applications in smart agriculture. We also discuss the unique challenges associated with developing AFMs, including model training, validation, and deployment. Through this study, we contribute to the advancement of AI in agriculture by introducing AFMs as a promising paradigm that can significantly mitigate the reliance on extensive labeled datasets and enhance the efficiency, effectiveness, and generalization of agricultural AI systems.
</details></li>
</ul>
<hr>
<h2 id="Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks"><a href="#Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks" class="headerlink" title="Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks"></a>Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06654">http://arxiv.org/abs/2308.06654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: 预测步行人的轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与步行人共享空间时。步行人运动在共享空间中受到汽车和其他步行人的影响，因此可以更好地模型步行人-汽车和步行人之间的交互，从而提高步行人轨迹预测模型的准确性。</li>
<li>methods: 我们提出了一种基于启发的方法，通过计算碰撞风险来选择交互对象。我们将关注与目标步行人之间可能碰撞的两个代理的时间到碰撞和方向角来编码交互效果。我们还 introduce了一种新的方向角坐标系，以便更好地表示交互对象之间的位势。</li>
<li>results: 我们的结果显示，与基eline方法（用作比较）相比，我们的方法在HBS数据集上预测的轨迹更加准确。<details>
<summary>Abstract</summary>
Predicting pedestrians' trajectories is a crucial capability for autonomous vehicles' safe navigation, especially in spaces shared with pedestrians. Pedestrian motion in shared spaces is influenced by both the presence of vehicles and other pedestrians. Therefore, effectively modelling both pedestrian-pedestrian and pedestrian-vehicle interactions can increase the accuracy of the pedestrian trajectory prediction models. Despite the huge literature on ways to encode the effect of interacting agents on a pedestrian's predicted trajectory using deep-learning models, limited effort has been put into the effective selection of interacting agents. In the majority of cases, the interaction features used are mainly based on relative distances while paying less attention to the effect of the velocity and approaching direction in the interaction formulation. In this paper, we propose a heuristic-based process of selecting the interacting agents based on collision risk calculation. Focusing on interactions of potentially colliding agents with a target pedestrian, we propose the use of time-to-collision and the approach direction angle of two agents for encoding the interaction effect. This is done by introducing a novel polar collision grid map. Our results have shown predicted trajectories closer to the ground truth compared to existing methods (used as a baseline) on the HBS dataset.
</details>
<details>
<summary>摘要</summary>
预测行人轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与行人共享空间时。行人运动在共享空间中受到车辆和其他行人的影响。因此，可以准确地模拟行人与车辆和其他行人之间的交互，可以提高行人轨迹预测模型的准确性。虽然有很大的文献研究了使用深度学习模型来编码交互代理的影响，但是对选择交互代理的有效选择尚未得到足够的关注。大多数情况下，交互特征 mainly based on relative distances，而忽略了交互形式中 velocities和接近方向的影响。在这篇论文中，我们提出了一种基于冲突风险计算的交互代理选择规则。关注可能发生冲突的两个代理之间的时间差距和接近方向角，以编码交互效果。我们通过引入一种新的圆形冲突网格地图来实现这一点。我们的结果显示，与基eline方法（作为参照）相比，我们的方法在HBS数据集上预测轨迹更加准确。
</details></li>
</ul>
<hr>
<h2 id="Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition"><a href="#Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition" class="headerlink" title="Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition"></a>Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11633">http://arxiv.org/abs/2308.11633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Sheffield, Frank E. Bobe III, Bradley Marchand, Matthew S. Emigh</li>
<li>for: 提高水下探测技术的精度和效率</li>
<li>methods: 使用自主学习方法（SSL）处理SAS数据，进行分类和特征识别</li>
<li>results: 实验结果表明，MoCo-SAS在F1分数方面表现 significanly better than传统的指导学习方法，这表明SSL在SAS数据处理中具有潜在的应用前景和可能性。<details>
<summary>Abstract</summary>
Synthetic Aperture Sonar (SAS) imaging has become a crucial technology for underwater exploration because of its unique ability to maintain resolution at increasing ranges, a characteristic absent in conventional sonar techniques. However, the effective application of deep learning to SAS data processing is often limited due to the scarcity of labeled data. To address this challenge, this paper proposes MoCo-SAS that leverages self-supervised learning (SSL) for SAS data processing, classification, and pattern recognition. The experimental results demonstrate that MoCo-SAS significantly outperforms traditional supervised learning methods, as evidenced by significant improvements observed in terms of the F1-score. These findings highlight the potential of SSL in advancing the state-of-the-art in SAS data processing, offering promising avenues for enhanced underwater object detection and classification.
</details>
<details>
<summary>摘要</summary>
美式 Synthetic Aperture Sonar（SAS）成像技术在水下探索中变得非常重要，因为它可以保持分辨率随距离增长，这是传统sonar技术缺乏的特点。然而，通常的深度学习应用于SAS数据处理中频繁受限因为标注数据的罕见。为解决这个挑战，这篇论文提议了MoCo-SAS，它利用自动标注学习（SSL）进行SAS数据处理、分类和模式识别。实验结果表明，MoCo-SAS在F1分数方面有显著提高，比传统监督学习方法要好。这些发现表明SSL在SAS数据处理中具有潜在的潜力，提供了更好的水下对象检测和分类技术。
</details></li>
</ul>
<hr>
<h2 id="3DMOTFormer-Graph-Transformer-for-Online-3D-Multi-Object-Tracking"><a href="#3DMOTFormer-Graph-Transformer-for-Online-3D-Multi-Object-Tracking" class="headerlink" title="3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking"></a>3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06635">http://arxiv.org/abs/2308.06635</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dsx0511/3dmotformer">https://github.com/dsx0511/3dmotformer</a></li>
<li>paper_authors: Shuxiao Ding, Eike Rehder, Lukas Schneider, Marius Cordts, Juergen Gall</li>
<li>for: 这篇论文的目的是提出一种学习基于 transformer 架构的三维物体跟踪（3DMOT）方法，以提高自动驾驶 vehicle 的精度和可靠性。</li>
<li>methods: 本文使用 Edge-Augmented Graph Transformer 来在帧帧基础上进行 track-detection 图грамreasoning，并通过边类划分进行数据归一化。在线上训练中，我们提出了一种novel的自适应训练策略，包括循环和回归的前进 pass，以及顺序批量优化。</li>
<li>results: 使用 CenterPoint 检测结果，本文的方法实现了 71.2% 和 68.2% AMOTA 在 nuScenes 验证和测试分别，并且一个训练好的 3DMOTFormer 模型可以在不同的物体检测器上进行泛化。<details>
<summary>Abstract</summary>
Tracking 3D objects accurately and consistently is crucial for autonomous vehicles, enabling more reliable downstream tasks such as trajectory prediction and motion planning. Based on the substantial progress in object detection in recent years, the tracking-by-detection paradigm has become a popular choice due to its simplicity and efficiency. State-of-the-art 3D multi-object tracking (MOT) approaches typically rely on non-learned model-based algorithms such as Kalman Filter but require many manually tuned parameters. On the other hand, learning-based approaches face the problem of adapting the training to the online setting, leading to inevitable distribution mismatch between training and inference as well as suboptimal performance. In this work, we propose 3DMOTFormer, a learned geometry-based 3D MOT framework building upon the transformer architecture. We use an Edge-Augmented Graph Transformer to reason on the track-detection bipartite graph frame-by-frame and conduct data association via edge classification. To reduce the distribution mismatch between training and inference, we propose a novel online training strategy with an autoregressive and recurrent forward pass as well as sequential batch optimization. Using CenterPoint detections, our approach achieves 71.2% and 68.2% AMOTA on the nuScenes validation and test split, respectively. In addition, a trained 3DMOTFormer model generalizes well across different object detectors. Code is available at: https://github.com/dsx0511/3DMOTFormer.
</details>
<details>
<summary>摘要</summary>
Tracking 3D 物体 precisely 和 consistently 是自动驾驶车辆中关键的，允许更可靠的下游任务，如轨迹预测和运动规划。基于近年来对 объек detection 的重要进步，跟踪-by-detection 方法在现场中变得越来越受欢迎，因为它的简单性和效率。当前的 3D 多对象跟踪（MOT）方法通常采用非学习基于模型的方法，如卡尔曼筛滤器，但是需要许多手动调整的参数。在另一方面，学习基于approaches 在线设定中遇到了适应训练的问题，导致在执行和训练之间的分布差异，以及不佳的性能。在这种情况下，我们提出了 3DMOTFormer，一种基于 transformer 架构的学习geometry-based 3D MOT 框架。我们使用 Edge-Augmented Graph Transformer 来在每帧上对跟踪-检测二分图进行理解，并通过边类别进行数据关联。为了减少训练和执行之间的分布差异，我们提出了一种新的在线训练策略，包括自适应循环和回归前进 pass，以及顺序批量优化。使用 CenterPoint 检测，我们的方法实现了 71.2% 和 68.2% AMOTA 在 nuScenes 验证和测试分割中，并且一个训练过的 3DMOTFormer 模型具有良好的泛化性。代码可以在 GitHub 上找到：https://github.com/dsx0511/3DMOTFormer。
</details></li>
</ul>
<hr>
<h2 id="Fusion-GRU-A-Deep-Learning-Model-for-Future-Bounding-Box-Prediction-of-Traffic-Agents-in-Risky-Driving-Videos"><a href="#Fusion-GRU-A-Deep-Learning-Model-for-Future-Bounding-Box-Prediction-of-Traffic-Agents-in-Risky-Driving-Videos" class="headerlink" title="Fusion-GRU: A Deep Learning Model for Future Bounding Box Prediction of Traffic Agents in Risky Driving Videos"></a>Fusion-GRU: A Deep Learning Model for Future Bounding Box Prediction of Traffic Agents in Risky Driving Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06628">http://arxiv.org/abs/2308.06628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Monjurul Karim, Ruwen Qin, Yinhai Wang</li>
<li>for: 预测周围交通代理人员未来矩形 bounding box 以确保自动驾驶车辆和高级驾驶协助系统在复杂交通场景中安全和高效 navigate.</li>
<li>methods: 本文提出了一种 novel encoder-decoder 架构 called Fusion-GRU, which accounts for the mutual and complex interactions among input features, and uses an intermediary estimator coupled with a self-attention aggregation layer to learn sequential dependencies for long-range prediction.</li>
<li>results: 实验结果表明 Fusion-GRU 能够有效地预测交通代理人员未来矩形 bounding box, 并且在 ROL 和 HEV-I 两个公共数据集上达到了出色的表现。<details>
<summary>Abstract</summary>
To ensure the safe and efficient navigation of autonomous vehicles and advanced driving assistance systems in complex traffic scenarios, predicting the future bounding boxes of surrounding traffic agents is crucial. However, simultaneously predicting the future location and scale of target traffic agents from the egocentric view poses challenges due to the vehicle's egomotion causing considerable field-of-view changes. Moreover, in anomalous or risky situations, tracking loss or abrupt motion changes limit the available observation time, requiring learning of cues within a short time window. Existing methods typically use a simple concatenation operation to combine different cues, overlooking their dynamics over time. To address this, this paper introduces the Fusion-Gated Recurrent Unit (Fusion-GRU) network, a novel encoder-decoder architecture for future bounding box localization. Unlike traditional GRUs, Fusion-GRU accounts for mutual and complex interactions among input features. Moreover, an intermediary estimator coupled with a self-attention aggregation layer is also introduced to learn sequential dependencies for long range prediction. Finally, a GRU decoder is employed to predict the future bounding boxes. The proposed method is evaluated on two publicly available datasets, ROL and HEV-I. The experimental results showcase the promising performance of the Fusion-GRU, demonstrating its effectiveness in predicting future bounding boxes of traffic agents.
</details>
<details>
<summary>摘要</summary>
要确保自动驾驶车和高级驾驶帮助系统在复杂交通场景中安全和高效地导航，预测周围交通代理的未来矩形框是关键。然而，同时预测目标交通代理的未来位置和Scale从 egocentric 视图出现困难，由于车辆的 egomotion 导致了 considrable 视场变化。此外，在异常或危险情况下，跟踪损失或突然运动变化限制了可用观察时间，需要学习在短时间窗口内的信号。现有方法通常使用简单的 concatenation 操作将不同的信号组合起来，忽略他们在时间上的动态变化。为解决这个问题，本文提出了 Fusion-Gated Recurrent Unit (Fusion-GRU) 网络，一种新的编码器-解码器架构 для 未来矩形框 Localization。与传统 GRU 不同，Fusion-GRU 考虑了输入特征之间的相互和复杂交互。此外，一个中间估计器和一个自我注意汇聚层也是引入，以学习长距离预测的时间序列关系。最后，一个 GRU 解码器用于预测未来矩形框。提案的方法在 ROL 和 HEV-I 两个公共可用数据集上进行了测试，实验结果表明 Fusion-GRU 的批处理能力很出色，证明其在预测交通代理未来矩形框方面的效果是非常有 Promise。
</details></li>
</ul>
<hr>
<h2 id="ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss"><a href="#ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss" class="headerlink" title="ADRMX: Additive Disentanglement of Domain Features with Remix Loss"></a>ADRMX: Additive Disentanglement of Domain Features with Remix Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06624">http://arxiv.org/abs/2308.06624</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/berkerdemirel/ADRMX">https://github.com/berkerdemirel/ADRMX</a></li>
<li>paper_authors: Berker Demirel, Erchan Aptoula, Huseyin Ozkan</li>
<li>for: 这个研究目的是为了实现多域领域对应，即将模型从多个来源领域中撷取具有通用性的特征，以减少域别的分布变化对模型的影响。</li>
<li>methods: 本研究使用了一种名为“添加式分离”的新架构，将域别特征与域共通特征整合在一起，以实现域variant特征的捕捉。此外，还引入了一种新的数据增强技术，将不同域的样本混合在维度空间中，以进一步支持模型的通用能力。</li>
<li>results: 经过广泛的DomainBed experiments，ADRMX模型在竞争性的情况下实现了州际状态的表现，并且超过了现有的模型。代码将会在GitHub上公开。<details>
<summary>Abstract</summary>
The common assumption that train and test sets follow similar distributions is often violated in deployment settings. Given multiple source domains, domain generalization aims to create robust models capable of generalizing to new unseen domains. To this end, most of existing studies focus on extracting domain invariant features across the available source domains in order to mitigate the effects of inter-domain distributional changes. However, this approach may limit the model's generalization capacity by relying solely on finding common features among the source domains. It overlooks the potential presence of domain-specific characteristics that could be prevalent in a subset of domains, potentially containing valuable information. In this work, a novel architecture named Additive Disentanglement of Domain Features with Remix Loss (ADRMX) is presented, which addresses this limitation by incorporating domain variant features together with the domain invariant ones using an original additive disentanglement strategy. Moreover, a new data augmentation technique is introduced to further support the generalization capacity of ADRMX, where samples from different domains are mixed within the latent space. Through extensive experiments conducted on DomainBed under fair conditions, ADRMX is shown to achieve state-of-the-art performance. Code will be made available at GitHub after the revision process.
</details>
<details>
<summary>摘要</summary>
通常假设训练集和测试集都遵循相似的分布是在部署场景下常被违反的。面对多个源领域，领域泛化目标是创建可以泛化到新未经见过的领域的Robust模型。为此，大多数现有的研究都是EXTRACTING DOMAIN INVARIANT FEATURES ACROSS AVAILABLE SOURCE DOMAINS，以减少INTER-DOMAIN分布变化的影响。然而，这种方法可能会限制模型的泛化能力，因为它只是在多个源领域中找到共同特征。这会忽略可能在一些领域中具有价值信息的领域特有特征。在这种工作中，一种新的架构被提出，即Additive Disentanglement of Domain Features with Remix Loss（ADRMX），它解决了这个限制。ADRMX通过将领域特征与领域 invariant 特征相加来实现这一点。此外，一种新的数据增强技术也被引入，其中来自不同领域的样本被混合在离散空间中。经过了EXTENSIVE EXPERIMENTS CONDUCTED ON DOMAINBED UNDER FAIR CONDITIONS，ADRMX得到了状态机器的表现。代码将在GitHub上公布后进行修订。
</details></li>
</ul>
<hr>
<h2 id="Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation"><a href="#Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation" class="headerlink" title="Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?"></a>Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06623">http://arxiv.org/abs/2308.06623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RisabBiswas/Polyp-SAM-PlusPlus">https://github.com/RisabBiswas/Polyp-SAM-PlusPlus</a></li>
<li>paper_authors: Risab Biswas</li>
<li>for: The paper is written for the task of polyp segmentation in medical images, with the goal of improving the accuracy and robustness of the segmentation process.</li>
<li>methods: The paper uses the Segment Anything Model (SAM) as the base model for polyp segmentation, and incorporates text prompting to guide the segmentation process.</li>
<li>results: The paper evaluates the performance of the text-guided SAM on benchmark datasets and compares the results with unprompted SAM. The results show that the text-guided SAM achieves better segmentation accuracy and robustness than unprompted SAM.Here are the three points in Simplified Chinese text:</li>
<li>for: 本文是为医疗图像中的肿吸分 segmentation任务而写的，目标是提高分 segmentation的准确性和稳定性。</li>
<li>methods: 本文使用 Segment Anything Model (SAM) 作为基本模型，并通过文本提示来导引分 segmentation 过程。</li>
<li>results: 本文对 benchmark 数据集进行评估，并比较文本提示 SAM 和无提示 SAM 的结果。结果显示，文本提示 SAM 在分 segmentation 任务上的性能更高、更稳定。<details>
<summary>Abstract</summary>
Meta recently released SAM (Segment Anything Model) which is a general-purpose segmentation model. SAM has shown promising results in a wide variety of segmentation tasks including medical image segmentation. In the field of medical image segmentation, polyp segmentation holds a position of high importance, thus creating a model which is robust and precise is quite challenging. Polyp segmentation is a fundamental task to ensure better diagnosis and cure of colorectal cancer. As such in this study, we will see how Polyp-SAM++, a text prompt-aided SAM, can better utilize a SAM using text prompting for robust and more precise polyp segmentation. We will evaluate the performance of a text-guided SAM on the polyp segmentation task on benchmark datasets. We will also compare the results of text-guided SAM vs unprompted SAM. With this study, we hope to advance the field of polyp segmentation and inspire more, intriguing research. The code and other details will be made publically available soon at https://github.com/RisabBiswas/Polyp-SAM++.
</details>
<details>
<summary>摘要</summary>
meta 最近发布了 SAM（ Segment Anything Model），这是一个通用分割模型。 SAM 在多种分割任务中表现出色，包括医疗图像分割。在医疗图像分割领域，肿瘤分割具有非常高的重要性，因此创建一个稳定和精准的模型非常具有挑战性。肿瘤分割是检测和治疗潜肿瘤的基础任务。在这项研究中，我们将研究如何使用文本提示来更好地使用 SAM 进行肿瘤分割。我们将对文本引导 SAM 在标准数据集上进行评估，并与不引导 SAM 进行比较。我们希望通过这项研究，推动肿瘤分割领域的发展，并鼓励更多的激动人心的研究。代码和其他细节将在 https://github.com/RisabBiswas/Polyp-SAM++ 上公开。
</details></li>
</ul>
<hr>
<h2 id="DFM-X-Augmentation-by-Leveraging-Prior-Knowledge-of-Shortcut-Learning"><a href="#DFM-X-Augmentation-by-Leveraging-Prior-Knowledge-of-Shortcut-Learning" class="headerlink" title="DFM-X: Augmentation by Leveraging Prior Knowledge of Shortcut Learning"></a>DFM-X: Augmentation by Leveraging Prior Knowledge of Shortcut Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06622">http://arxiv.org/abs/2308.06622</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nis-research/dfmx-augmentation">https://github.com/nis-research/dfmx-augmentation</a></li>
<li>paper_authors: Shunxin Wang, Christoph Brune, Raymond Veldhuis, Nicola Strisciuglio</li>
<li>for: 提高模型的普适性和鲁棒性，防止神经网络学习 superficiale 的统计学特征，从而提高模型的泛化能力和鲁棒性。</li>
<li>methods: 提出了一种数据增强策略，称为DFM-X，该策略利用了预测模型中的主导频率图（DFM）来避免神经网络学习快捷解决方案。</li>
<li>results: 实验结果表明，DFM-X 可以提高模型对常见损害和攻击的Robustness，并且可以轻松地与其他增强技术结合使用，以进一步提高模型的泛化能力和鲁棒性。<details>
<summary>Abstract</summary>
Neural networks are prone to learn easy solutions from superficial statistics in the data, namely shortcut learning, which impairs generalization and robustness of models. We propose a data augmentation strategy, named DFM-X, that leverages knowledge about frequency shortcuts, encoded in Dominant Frequencies Maps computed for image classification models. We randomly select X% training images of certain classes for augmentation, and process them by retaining the frequencies included in the DFMs of other classes. This strategy compels the models to leverage a broader range of frequencies for classification, rather than relying on specific frequency sets. Thus, the models learn more deep and task-related semantics compared to their counterpart trained with standard setups. Unlike other commonly used augmentation techniques which focus on increasing the visual variations of training data, our method targets exploiting the original data efficiently, by distilling prior knowledge about destructive learning behavior of models from data. Our experimental results demonstrate that DFM-X improves robustness against common corruptions and adversarial attacks. It can be seamlessly integrated with other augmentation techniques to further enhance the robustness of models.
</details>
<details>
<summary>摘要</summary>
We use Dominant Frequencies Maps (DFMs) to identify the frequency shortcuts that image classification models are prone to learning. We then select a percentage of training images from certain classes and process them by retaining the frequencies included in the DFMs of other classes. This forces the models to use a broader range of frequencies for classification, rather than relying on specific frequency sets.Unlike other augmentation techniques that focus on increasing visual variations in the training data, DFM-X targets the efficient use of the original data by leveraging prior knowledge about the destructive learning behavior of models. Our experimental results show that DFM-X improves the robustness of models against common corruptions and adversarial attacks. It can be easily integrated with other augmentation techniques to further enhance the robustness of models.
</details></li>
</ul>
<hr>
<h2 id="LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net"><a href="#LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net" class="headerlink" title="LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net"></a>LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06603">http://arxiv.org/abs/2308.06603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ach-1914/ladlenet">https://github.com/ach-1914/ladlenet</a></li>
<li>paper_authors: Tonghui Zou</li>
<li>for: 这 paper 的目的是将thermal infrared (TIR) 图像转换成可见光 (VI) 图像，并且可以应用于多个领域，如TIR-VI 图像registratin 和融合。</li>
<li>methods: 这 paper 使用了一种基于 U-Net 架构的算法，称为 LadleNet，其包括 ‘Handle’ 模块和 ‘Bowl’ 模块。 Handle 模块constructs an abstract semantic space，而 Bowl 模块 decode这 semantic space来生成 mapped VI 图像。 Handle 模块可以通过使用semantic segmentation networks来扩展其网络架构，从而提高模型性能。</li>
<li>results:  comparative experiments 表明， compared to existing methodologies, our approach achieves state-of-the-art performance in terms of image clarity and perceptual quality。<details>
<summary>Abstract</summary>
The translation of thermal infrared (TIR) images to visible light (VI) images presents a challenging task with potential applications spanning various domains such as TIR-VI image registration and fusion. Leveraging supplementary information derived from TIR image conversions can significantly enhance model performance and generalization across these applications. However, prevailing issues within this field include suboptimal image fidelity and limited model scalability. In this paper, we introduce an algorithm, LadleNet, based on the U-Net architecture. LadleNet employs a two-stage U-Net concatenation structure, augmented with skip connections and refined feature aggregation techniques, resulting in a substantial enhancement in model performance. Comprising 'Handle' and 'Bowl' modules, LadleNet's Handle module facilitates the construction of an abstract semantic space, while the Bowl module decodes this semantic space to yield mapped VI images. The Handle module exhibits extensibility by allowing the substitution of its network architecture with semantic segmentation networks, thereby establishing more abstract semantic spaces to bolster model performance. Consequently, we propose LadleNet+, which replaces LadleNet's Handle module with the pre-trained DeepLabv3+ network, thereby endowing the model with enhanced semantic space construction capabilities. The proposed method is evaluated and tested on the KAIST dataset, accompanied by quantitative and qualitative analyses. Compared to existing methodologies, our approach achieves state-of-the-art performance in terms of image clarity and perceptual quality. The source code will be made available at https://github.com/Ach-1914/LadleNet/tree/main/.
</details>
<details>
<summary>摘要</summary>
通过将热成像（TIR）图像转换成可见光（VI）图像，提供了一些应用领域的挑战，如TIR-VI图像匹配和融合。利用TIR图像转换生成的补充信息可以significantly enhance模型性能和泛化性。然而，现有的问题包括低效图像准确性和有限的模型扩展性。在这篇文章中，我们提出了一种算法，即LadleNet，基于U-Net架构。LadleNet使用了两个阶段的U-Net堆叠结构，并添加了跳过连接和精细特征聚合技术，从而实现了显著提高模型性能。LadleNet由“ Handle”和“Bowl”模块组成，其中“ Handle”模块建立了一个抽象的 semantic space，而“Bowl”模块将这个semantic space解码成生成的VI图像。“ Handle”模块具有扩展性，可以通过更改其网络架构来使用semantic segmentation网络，从而建立更加抽象的semantic spaces，以提高模型性能。因此，我们提出了LadleNet+，其替换了LadleNet的“ Handle”模块为预训练的DeepLabv3+网络，从而使模型具有更高的semantic space建立能力。我们的方法在KAIST数据集上进行了评估和测试，并进行了量化和质量分析。相比现有的方法，我们的方法在图像清晰度和感知质量方面达到了状态态的性能。模型源代码将在https://github.com/Ach-1914/LadleNet/tree/main/下提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.CV_2023_08_13/" data-id="clon21ipq00g0r5886ze29xdg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.AI_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T12:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.AI_2023_08_13/">cs.AI - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Dual-Meta-Learning-with-Longitudinally-Generalized-Regularization-for-One-Shot-Brain-Tissue-Segmentation-Across-the-Human-Lifespan"><a href="#Dual-Meta-Learning-with-Longitudinally-Generalized-Regularization-for-One-Shot-Brain-Tissue-Segmentation-Across-the-Human-Lifespan" class="headerlink" title="Dual Meta-Learning with Longitudinally Generalized Regularization for One-Shot Brain Tissue Segmentation Across the Human Lifespan"></a>Dual Meta-Learning with Longitudinally Generalized Regularization for One-Shot Brain Tissue Segmentation Across the Human Lifespan</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06774">http://arxiv.org/abs/2308.06774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongheng Sun, Fan Wang, Jun Shu, Haifeng Wang, Li Wang. Deyu Meng, Chunfeng Lian</li>
<li>for: 这个论文旨在提出一种用于批处理数据的脑细胞分割方法，以便于 neuroscience 和临床研究。</li>
<li>methods: 该方法使用 dual meta-learning 模型，包括一个 plug-and-play 特征提取器和一个 initializer 任务头，以学习 longitudinally 一致的表示。此外，两种类 aware 正则化也是提出来鼓励 longitudinal 一致性。</li>
<li>results: 实验结果表明，该方法在 iSeg2019 和 ADNI 数据集上具有效果。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/ladderlab-xjtu/DuMeta">https://github.com/ladderlab-xjtu/DuMeta</a> 上下载。<details>
<summary>Abstract</summary>
Brain tissue segmentation is essential for neuroscience and clinical studies. However, segmentation on longitudinal data is challenging due to dynamic brain changes across the lifespan. Previous researches mainly focus on self-supervision with regularizations and will lose longitudinal generalization when fine-tuning on a specific age group. In this paper, we propose a dual meta-learning paradigm to learn longitudinally consistent representations and persist when fine-tuning. Specifically, we learn a plug-and-play feature extractor to extract longitudinal-consistent anatomical representations by meta-feature learning and a well-initialized task head for fine-tuning by meta-initialization learning. Besides, two class-aware regularizations are proposed to encourage longitudinal consistency. Experimental results on the iSeg2019 and ADNI datasets demonstrate the effectiveness of our method. Our code is available at https://github.com/ladderlab-xjtu/DuMeta.
</details>
<details>
<summary>摘要</summary>
��rett�Brain tissue segmentation是 neuroscience 和 clinical studies 中必备的一环。然而，对 longitudinal 数据进行 segmentation 是一个挑战，因为大脑在生长过程中会发生 dynamically 的变化。先前的研究主要集中在自我超vised 的 regularization 上，这会导致 fine-tuning 时失去 longitudinal 一致性。在这篇论文中，我们提出了 dual meta-learning  парадигма，以学习 longitudinally 一致的表示和 fine-tuning  persist。具体来说，我们学习了一个可插入的 feature extractor，用于抽取 longitudinally 一致的 anatomical 表示，以及一个 Well-Initialized 任务头，用于 fine-tuning。此外，我们还提出了两种类型 aware 的 regularization，以促进 longitudinal 一致性。我们的实验结果在 iSeg2019 和 ADNI 数据集上表明了我们的方法的有效性。我们的代码可以在 https://github.com/ladderlab-xjtu/DuMeta 上获取。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Class-incremental-Learning-A-Survey"><a href="#Few-shot-Class-incremental-Learning-A-Survey" class="headerlink" title="Few-shot Class-incremental Learning: A Survey"></a>Few-shot Class-incremental Learning: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06764">http://arxiv.org/abs/2308.06764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinghua Zhang, Li Liu, Olli Silven, Matti Pietikäinen, Dewen Hu</li>
<li>for: 这篇论文旨在提供关于几拟学习（Few-shot Class-Incremental Learning，FSCIL）的系统性和深入的评论。</li>
<li>methods: 本论文涵盖了FSCIL中的多种方法，包括数据基于、结构基于和优化基于的分类方法以及锚点基于和锚点自由的对象检测方法。</li>
<li>results: 本论文提供了一个彻底的检查和评估的 benchmark 数据集和评价指标，以及一些在FSCIL中的推荐的研究方向。<details>
<summary>Abstract</summary>
Few-shot Class-Incremental Learning (FSCIL) presents a unique challenge in machine learning, as it necessitates the continuous learning of new classes from sparse labeled training samples without forgetting previous knowledge. While this field has seen recent progress, it remains an active area of exploration. This paper aims to provide a comprehensive and systematic review of FSCIL. In our in-depth examination, we delve into various facets of FSCIL, encompassing the problem definition, the discussion of primary challenges of unreliable empirical risk minimization and the stability-plasticity dilemma, general schemes, and relevant problems of incremental learning and few-shot learning. Besides, we offer an overview of benchmark datasets and evaluation metrics. Furthermore, we introduce the classification methods in FSCIL from data-based, structure-based, and optimization-based approaches and the object detection methods in FSCIL from anchor-free and anchor-based approaches. Beyond these, we illuminate several promising research directions within FSCIL that merit further investigation.
</details>
<details>
<summary>摘要</summary>
《几个示例学习（Few-shot Class-Incremental Learning，FSCIL）》是机器学习领域的一个独特挑战，它需要在缺乏标注训练样本的情况下，不断学习新的类型，而不会忘记之前的知识。虽然这一领域已经有了相应的进步，但仍然是一个活跃的探索领域。本文的目的是提供关于FSCIL的全面和系统性的综述，我们在这里进行了深入的检查，涵盖了FSCIL的问题定义、主要挑战、基本方案、相关的增量学习和几个示例学习方法等方面。此外，我们还介绍了FSCIL中的标准数据集和评价指标。在FSCIL中，我们分析了数据基于、结构基于和优化基于的分类方法，以及anchor-free和anchor-based的对应检测方法。此外，我们还透出了FSCIL中一些有前途的研究方向，以便进一步探索和发展这一领域。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-anticipated-outcomes-of-MRI-seizure-image-from-open-source-tool-Prototype-approach"><a href="#Evaluating-the-anticipated-outcomes-of-MRI-seizure-image-from-open-source-tool-Prototype-approach" class="headerlink" title="Evaluating the anticipated outcomes of MRI seizure image from open-source tool- Prototype approach"></a>Evaluating the anticipated outcomes of MRI seizure image from open-source tool- Prototype approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07762">http://arxiv.org/abs/2308.07762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayanthi Vajiram, Aishwarya Senthil, Utkarsh Maurya</li>
<li>for: 这个论文主要用于描述世界各地约70亿人口中 epilepsy 病人的脑部功能障碍和分析。</li>
<li>methods: 本文使用了多种开源神经成像工具，包括 MATLAB、Slicer 3D、Brain Suite21a、SPM 和 MedCalc，以进行脑部功能障碍的检查和分析。大约 60% 的研究人员使用了 MATLAB 进行图像处理，而其他 30% 使用了其他开源软件工具。</li>
<li>results: 根据本文的报告，大约 70% 的研究人员使用了 MATLAB 进行图像处理，而其他 30% 使用了其他开源软件工具。<details>
<summary>Abstract</summary>
Epileptic Seizure is an abnormal neuronal exertion in the brain, affecting nearly 70 million of the world's population (Ngugi et al., 2010). So many open-source neuroimaging tools are used for metabolism checkups and analysis purposes. The scope of open-source tools like MATLAB, Slicer 3D, Brain Suite21a, SPM, and MedCalc are explained in this paper. MATLAB was used by 60% of the researchers for their image processing and 10% of them use their proprietary software. More than 30% of the researchers use other open-source software tools with their processing techniques for the study of magnetic resonance seizure images
</details>
<details>
<summary>摘要</summary>
эпилептический приступ是脑内部不正常的神经舒张，影响全球约70亿人口（ Ngugi et al., 2010）。这么多个开源神经成像工具用于 метаболизма检查和分析。这篇论文中 explain了开源工具如MATLAB、Slicer 3D、Brain Suite21a、SPM 和 MedCalc 的范围。MATLAB 被60%的研究人员用于图像处理，而10%的他们使用自己的专有软件。 более30%的研究人员使用其他开源软件工具进行频率逐点图像的研究
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization"><a href="#Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization" class="headerlink" title="Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization"></a>Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06741">http://arxiv.org/abs/2308.06741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Mehdi Nasiri, Mansoor Rezghi</li>
<li>for: solving cooperative Multi-Agent Reinforcement Learning (MARL) problems with varying agent abilities and individual policies</li>
<li>methods: Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO) algorithm, which utilizes the multi-agent advantage decomposition lemma for efficient policy updates and guarantees stability and performance improvements</li>
<li>results: superiority over state-of-the-art algorithms such as HATRPO and HAPPO, demonstrated through experiments on Multi-Agent MuJoCo and StarCraftII tasks<details>
<summary>Abstract</summary>
This paper presents an extension of the Mirror Descent method to overcome challenges in cooperative Multi-Agent Reinforcement Learning (MARL) settings, where agents have varying abilities and individual policies. The proposed Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO) algorithm utilizes the multi-agent advantage decomposition lemma to enable efficient policy updates for each agent while ensuring overall performance improvements. By iteratively updating agent policies through an approximate solution of the trust-region problem, HAMDPO guarantees stability and improves performance. Moreover, the HAMDPO algorithm is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. We evaluate HAMDPO on Multi-Agent MuJoCo and StarCraftII tasks, demonstrating its superiority over state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.
</details>
<details>
<summary>摘要</summary>
HAMDPO uses the multi-agent advantage decomposition lemma to efficiently update agent policies while ensuring improved overall performance. The algorithm iteratively updates agent policies using an approximate solution of the trust-region problem, which guarantees stability and improves performance.HAMDPO is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. The authors evaluate HAMDPO on Multi-Agent MuJoCo and StarCraftII tasks and show that it outperforms state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.Here is the Simplified Chinese translation of the text:这篇论文提出了一种新的方法 called Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO)，用于解决多体决策学习（MARL）中的合作问题。该方法是为了处理每个代理机器人有不同能力和个性政策的情况。HAMDPO 使用多体优势分解证明来有效地更新代理机器人的策略，同时保证总体性能提高。该算法通过迭代更新代理机器人的策略，使用approxSolution 的信任区问题的解决方案，保证稳定性和性能提高。HAMDPO 可以处理不同的连续和离散动作空间，并在多种 MARL 问题上进行应用。作者们通过在 Multi-Agent MuJoCo 和 StarCraftII 任务上评估 HAMDPO，发现它比state-of-the-art 算法如 HATRPO 和 HAPPO 表现出色。这些结果表明，HAMDPO 是一种有前途的方法，可以解决多体决策学习中的合作问题，并可能扩展到其他难题。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data"><a href="#Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data" class="headerlink" title="Probabilistic Imputation for Time-series Classification with Missing Data"></a>Probabilistic Imputation for Time-series Classification with Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06738">http://arxiv.org/abs/2308.06738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout">https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout</a></li>
<li>paper_authors: SeungHyun Kim, Hyunsu Kim, EungGu Yun, Hwangrae Lee, Jaehun Lee, Juho Lee</li>
<li>For: This paper proposes a novel probabilistic framework for classification with multivariate time series data that contains missing values.* Methods: The proposed method consists of two parts: a deep generative model for missing value imputation and a classifier. The generative model is trained to impute the missing values in multiple plausible ways, effectively modeling the uncertainty of the imputation. The classifier takes the time series data along with the imputed missing values and classifies signals, and is trained to capture the predictive uncertainty due to the multiple possibilities of imputations.* Results: The proposed method is demonstrated to be effective through extensive experiments on real-world time series data with missing values.<details>
<summary>Abstract</summary>
Multivariate time series data for real-world applications typically contain a significant amount of missing values. The dominant approach for classification with such missing values is to impute them heuristically with specific values (zero, mean, values of adjacent time-steps) or learnable parameters. However, these simple strategies do not take the data generative process into account, and more importantly, do not effectively capture the uncertainty in prediction due to the multiple possibilities for the missing values. In this paper, we propose a novel probabilistic framework for classification with multivariate time series data with missing values. Our model consists of two parts; a deep generative model for missing value imputation and a classifier. Extending the existing deep generative models to better capture structures of time-series data, our deep generative model part is trained to impute the missing values in multiple plausible ways, effectively modeling the uncertainty of the imputation. The classifier part takes the time series data along with the imputed missing values and classifies signals, and is trained to capture the predictive uncertainty due to the multiple possibilities of imputations. Importantly, we show that na\"ively combining the generative model and the classifier could result in trivial solutions where the generative model does not produce meaningful imputations. To resolve this, we present a novel regularization technique that can promote the model to produce useful imputation values that help classification. Through extensive experiments on real-world time series data with missing values, we demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
多变量时间序列数据在实际应用中通常含有大量缺失值。现有的主流方法为这些缺失值是采用各种各样的归纳法（如零、平均值、邻近时间步的值）或学习参数。然而，这些简单策略并不考虑数据生成过程，更重要的是，它们不能有效地捕捉预测中的不确定性。在这篇论文中，我们提出了一种新的概率 frameworks  для类型化多变量时间序列数据中的缺失值。我们的模型包括两部分：深度生成模型和分类器。我们在深度生成模型部分使用了多种可能性的填充方法，以模型缺失值的不确定性。分类器部分接受了时间序列数据以及填充后的缺失值，并将信号分类，并且在不同的填充情况下预测不确定性。我们发现，将生成模型和分类器直接组合可能会导致生成模型不生成有意义的填充值，从而影响分类的准确性。为解决这个问题，我们提出了一种新的规范技术，可以促进模型生成有用的填充值，以便于分类。我们通过对实际时间序列数据中缺失值的广泛实验，证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="AerialVLN-Vision-and-Language-Navigation-for-UAVs"><a href="#AerialVLN-Vision-and-Language-Navigation-for-UAVs" class="headerlink" title="AerialVLN: Vision-and-Language Navigation for UAVs"></a>AerialVLN: Vision-and-Language Navigation for UAVs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06735">http://arxiv.org/abs/2308.06735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubo Liu, Hongsheng Zhang, Yuankai Qi, Peng Wang, Yaning Zhang, Qi Wu</li>
<li>for: 这个论文的目的是为了提出一个新的机器人任务，即空中视语Navigation（AerialVLN），用于研究机器人在开放空间中 navigation 的问题。</li>
<li>methods: 这篇论文使用了一种基于 cross-modal-alignment（CMA）方法的扩展基线模型，并使用了一个3D simulator，其中包括25个城市级别的enario，以支持连续导航、环境扩展和配置。</li>
<li>results: 论文发现，基于CMA方法的扩展基线模型与人类表现之间仍然存在一定的差距，这表明空中视语Navigation（AerialVLN）是一个新的挑战性任务。<details>
<summary>Abstract</summary>
Recently emerged Vision-and-Language Navigation (VLN) tasks have drawn significant attention in both computer vision and natural language processing communities. Existing VLN tasks are built for agents that navigate on the ground, either indoors or outdoors. However, many tasks require intelligent agents to carry out in the sky, such as UAV-based goods delivery, traffic/security patrol, and scenery tour, to name a few. Navigating in the sky is more complicated than on the ground because agents need to consider the flying height and more complex spatial relationship reasoning. To fill this gap and facilitate research in this field, we propose a new task named AerialVLN, which is UAV-based and towards outdoor environments. We develop a 3D simulator rendered by near-realistic pictures of 25 city-level scenarios. Our simulator supports continuous navigation, environment extension and configuration. We also proposed an extended baseline model based on the widely-used cross-modal-alignment (CMA) navigation methods. We find that there is still a significant gap between the baseline model and human performance, which suggests AerialVLN is a new challenging task. Dataset and code is available at https://github.com/AirVLN/AirVLN.
</details>
<details>
<summary>摘要</summary>
现在刚刚出现的视力语言导航（VLN）任务已经吸引了计算机视觉和自然语言处理领域的广泛关注。现有的VLN任务都是为地面上的agent进行定位 navigating，但是许多任务需要在天空中进行，如用UAV进行物资交通/安全巡查和景色游览等。在天空中导航比在地面上更加复杂，因为代理需要考虑飞行高度和更复杂的空间关系理解。为了填补这个空白和促进这一领域的研究，我们提出了一个新任务名为空中VLN，它是基于UAV的和向外部环境。我们开发了25个城市级的enario的3D模拟器，模拟器支持连续导航、环境扩展和配置。我们还提出了一种基于协调多modal（CMA）导航方法的扩展基线模型。我们发现，与人类性能相比，基线模型还有一定的差距，这表明空中VLN是一个新的挑战性任务。数据集和代码可以在https://github.com/AirVLN/AirVLN上获取。
</details></li>
</ul>
<hr>
<h2 id="Precipitation-nowcasting-with-generative-diffusion-models"><a href="#Precipitation-nowcasting-with-generative-diffusion-models" class="headerlink" title="Precipitation nowcasting with generative diffusion models"></a>Precipitation nowcasting with generative diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06733">http://arxiv.org/abs/2308.06733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models">https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models</a></li>
<li>paper_authors: Andrea Asperti, Fabio Merizzi, Alberto Paparella, Giorgio Pedrazzi, Matteo Angelinelli, Stefano Colamonaco</li>
<li>for: 该研究旨在检验气候预测中 diffusion models 的可行性，特别是在降水预测（precipitation nowcasting）方面。</li>
<li>methods: 该研究使用了一种生成ensemble diffusion（GED）模型，通过生成多个可能的天气enario，然后使用post-processing网络将其融合成可能性最高的预测。</li>
<li>results: 相比之前的深度学习模型，GED模型在总性能方面显著提高了。<details>
<summary>Abstract</summary>
In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely prediction.   In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data pertaining to Central Europe from the years 2016 to 2021. Within this context, we examine the efficacy of diffusion models in handling the task of precipitation nowcasting. Our work is conducted in comparison to the performance of well-established U-Net models, as documented in the existing literature. Our proposed approach of Generative Ensemble Diffusion (GED) utilizes a diffusion model to generate a set of possible weather scenarios which are then amalgamated into a probable prediction via the use of a post-processing network. This approach, in comparison to recent deep learning models, substantially outperformed them in terms of overall performance.
</details>
<details>
<summary>摘要</summary>
在最近几年，传统的数学方法 для准确的天气预测逐渐面临深度学习方法的挑战。历史数据集用于短距离和中距离天气预测通常有规则的空间格局结构，这种设置与图像非常相似，每种天气变量都可以被视为地图或者在考虑时间轴的情况下为视频。多种生成模型，包括生成对抗网络、变量自动编码器和最近的干扰扩散模型，在下一帧预测问题上有广泛的应用，因此自然地测试它们的性能在天气预测中。干扰扩散模型在这种情况下特别吸引人，因为天气预测的本质是probabilistic的：我们实际上是希望模型可以描述天气指标的概率分布，其期望值是最有可能的预测。在我们的研究中，我们专注于ERA-5数据集的一个子集，包括2016-2021年中欧每小时的数据。在这个上下文中，我们研究了干扰扩散模型在降水预测方面的能力。我们的方法与文献中已有的U-Net模型相比，并使用生成ensemble扩散（GED）模型。这种方法使用扩散模型生成一组可能的天气情况，然后使用Post处理网络将这些情况融合成一个可能的预测。与最近的深度学习模型相比，我们的方法在总性能方面表现得更好。
</details></li>
</ul>
<hr>
<h2 id="Transforming-Sentiment-Analysis-in-the-Financial-Domain-with-ChatGPT"><a href="#Transforming-Sentiment-Analysis-in-the-Financial-Domain-with-ChatGPT" class="headerlink" title="Transforming Sentiment Analysis in the Financial Domain with ChatGPT"></a>Transforming Sentiment Analysis in the Financial Domain with ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07935">http://arxiv.org/abs/2308.07935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Fatouros, John Soldatos, Kalliopi Kouroumali, Georgios Makridis, Dimosthenis Kyriazis</li>
<li>for: 本研究旨在探讨大语言模型ChatGPT 3.5在金融情感分析中的潜力, 特别是在外汇市场（forex）中。</li>
<li>methods: 本研究使用了零shot提示方法，对手动抽取的forex相关新闻标题进行了多个ChatGPT提问的测试，并使用了精度、准确率、f1score和 Mean Absolute Error（MAE）来衡量情感分类的性能。此外，还进行了对预测的情感和股票市场回报的相关性的评估。</li>
<li>results: ChatGPT比FinBERT更高级的情感分类性能提升约35%，并且与股票市场回报之间的相关性提高约36%。这些结果表明，提示工程在零shot上是非常重要的，并且指出了ChatGPT在金融应用中的潜力。<details>
<summary>Abstract</summary>
Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero-shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1-score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an additional evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35\% enhanced performance in sentiment classification and a 36\% higher correlation with market returns. By underlining the significance of prompt engineering, particularly in zero-shot contexts, this study spotlights ChatGPT's potential to substantially boost sentiment analysis in financial applications. By sharing the utilized dataset, our intention is to stimulate further research and advancements in the field of financial services.
</details>
<details>
<summary>摘要</summary>
Note:* "Financial sentiment analysis" Financial sentiment analysis (FSAs) is the process of analyzing text data to determine the sentiment of investors, analysts, and other market participants towards a particular financial asset or market event.* "Zero-shot prompting" Zero-shot prompting refers to the use of language models to perform tasks or generate text based on prompts that are not present in the training data.* "ChatGPT" ChatGPT is a type of large language model that uses a transformer architecture and is trained on a large corpus of text data to generate human-like text.* "FinBERT" FinBERT is a pre-trained language model that is specifically designed for financial text analysis.
</details></li>
</ul>
<hr>
<h2 id="CLE-Diffusion-Controllable-Light-Enhancement-Diffusion-Model"><a href="#CLE-Diffusion-Controllable-Light-Enhancement-Diffusion-Model" class="headerlink" title="CLE Diffusion: Controllable Light Enhancement Diffusion Model"></a>CLE Diffusion: Controllable Light Enhancement Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06725">http://arxiv.org/abs/2308.06725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuyang Yin, Dejia Xu, Chuangchuang Tan, Ping Liu, Yao Zhao, Yunchao Wei</li>
<li>For: 提高低光照图像质量，提供用户rich的控制能力* Methods: 使用 conditional diffusion model 和 Segment-Anything Model (SAM) 实现用户定制的光照增强* Results: 在量值、质量和可控性三个方面达到竞争性表现，并且提供了rich的用户控制能力<details>
<summary>Abstract</summary>
Low light enhancement has gained increasing importance with the rapid development of visual creation and editing. However, most existing enhancement algorithms are designed to homogeneously increase the brightness of images to a pre-defined extent, limiting the user experience. To address this issue, we propose Controllable Light Enhancement Diffusion Model, dubbed CLE Diffusion, a novel diffusion framework to provide users with rich controllability. Built with a conditional diffusion model, we introduce an illumination embedding to let users control their desired brightness level. Additionally, we incorporate the Segment-Anything Model (SAM) to enable user-friendly region controllability, where users can click on objects to specify the regions they wish to enhance. Extensive experiments demonstrate that CLE Diffusion achieves competitive performance regarding quantitative metrics, qualitative results, and versatile controllability. Project page: \url{https://yuyangyin.github.io/CLEDiffusion/}
</details>
<details>
<summary>摘要</summary>
低光照增强在视觉创作和编辑领域的快速发展中得到了越来越重要的注目。然而，现有的增强算法大多采用一致性提高图像亮度，限制用户体验。为解决这个问题，我们提出了可控光增强扩散模型（CLE Diffusion），这是一种新的扩散框架，提供了用户 Rich 控制性。通过加入条件扩散模型，我们引入了照明嵌入，让用户控制自己的需要的亮度水平。此外，我们还 incorporate了 Segment-Anything Model（SAM），使得用户可以通过点击对象来指定需要增强的区域。广泛的实验表明，CLE Diffusion 在量化指标、质量效果和多样性控制方面具有竞争力。项目页面：<https://yuyangyin.github.io/CLEDiffusion/>
</details></li>
</ul>
<hr>
<h2 id="IP-Adapter-Text-Compatible-Image-Prompt-Adapter-for-Text-to-Image-Diffusion-Models"><a href="#IP-Adapter-Text-Compatible-Image-Prompt-Adapter-for-Text-to-Image-Diffusion-Models" class="headerlink" title="IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models"></a>IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06721">http://arxiv.org/abs/2308.06721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, Wei Yang</li>
<li>for: 这篇论文旨在提出一种可靠且轻量级的适配器，使得预训练的文本到图像扩散模型可以使用图像提示来生成图像。</li>
<li>methods: 该适配器使用了解coupled crossed attention机制，将文本特征和图像特征分开处理，以提高生成图像的精度和效率。</li>
<li>results:  experiments show that IP-Adapter可以与预训练的图像提示模型相比，在生成图像方面达到相当或更好的性能，并且可以与文本提示结合使用，实现多模态图像生成。<details>
<summary>Abstract</summary>
Recent years have witnessed the strong power of large text-to-image diffusion models for the impressive generative capability to create high-fidelity images. However, it is very tricky to generate desired images using only text prompt as it often involves complex prompt engineering. An alternative to text prompt is image prompt, as the saying goes: "an image is worth a thousand words". Although existing methods of direct fine-tuning from pretrained models are effective, they require large computing resources and are not compatible with other base models, text prompt, and structural controls. In this paper, we present IP-Adapter, an effective and lightweight adapter to achieve image prompt capability for the pretrained text-to-image diffusion models. The key design of our IP-Adapter is decoupled cross-attention mechanism that separates cross-attention layers for text features and image features. Despite the simplicity of our method, an IP-Adapter with only 22M parameters can achieve comparable or even better performance to a fully fine-tuned image prompt model. As we freeze the pretrained diffusion model, the proposed IP-Adapter can be generalized not only to other custom models fine-tuned from the same base model, but also to controllable generation using existing controllable tools. With the benefit of the decoupled cross-attention strategy, the image prompt can also work well with the text prompt to achieve multimodal image generation. The project page is available at \url{https://ip-adapter.github.io}.
</details>
<details>
<summary>摘要</summary>
近年来，大型文本到图像扩散模型的强大能力吸引了广泛的关注，这些模型可以生成高效的图像。然而，使用仅文本提示来生成愿景图像是非常困难，因为这通常需要复杂的提示工程。一种alternative是使用图像提示，以示人们所说的“一个图像值得一千个话”。 although existing methods of direct fine-tuning from pretrained models are effective, they require large computing resources and are not compatible with other base models, text prompt, and structural controls. 在这篇论文中，我们提出了IP-Adapter，一种高效且轻量级的适配器，可以使得预训练的文本到图像扩散模型具备图像提示能力。我们的键要设计是分离的交叉关注机制，它将文本特征和图像特征的交叉关注层分离开来。尽管我们的方法简单，一个只有22M参数的IP-Adapter仍可以达到与完全 fine-tune 的图像提示模型相当或更好的性能。由于我们冻结了预训练的扩散模型，我们的IP-Adapter可以被普遍化到其他自定义模型，以及使用现有的可控生成工具进行可控生成。此外，使用分离的交叉关注策略，图像提示还可以与文本提示共同工作，以实现多modal图像生成。相关项目页面可以查看于 \url{https://ip-adapter.github.io}。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables"><a href="#Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables" class="headerlink" title="Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables"></a>Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06718">http://arxiv.org/abs/2308.06718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Xie, Biwei Huang, Zhengming Chen, Ruichu Cai, Clark Glymour, Zhi Geng, Kun Zhang</li>
<li>For: The paper is focused on learning the causal structure of a system with latent variables, including identifying the number of latent variables and their relationships with observed variables.* Methods: The authors propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models with latent variables, which is used to identify the causal relationships between the observed and latent variables. They also develop a search procedure to efficiently estimate the underlying causal structure.* Results: The authors show that the proposed approach can identify the causal structure of a system with latent variables, and demonstrate its effectiveness through experimental results. Additionally, they find that the independent noise condition can be seen as a special case of the GIN condition, which provides a connection between the two concepts.<details>
<summary>Abstract</summary>
We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
我们研究一个复杂任务：在含有隐变量的情况下学习 causal 结构。其中包括找到隐变量的位置和它们的数量，以及确定隐变量和观测变量之间的 causal 关系。为此，我们提出一个通用独立噪声（GIN）条件，该条件用于线性非常 Gaussian 隐含 causal 模型中的隐变量，并且可以独立地测试隐变量的存在和数量。 Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^\intercal \mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details></li>
</ul>
<hr>
<h2 id="Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards"><a href="#Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards" class="headerlink" title="Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards"></a>Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06717">http://arxiv.org/abs/2308.06717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilgin Dogan, Zuo-Jun Max Shen, Anil Aswani</li>
<li>for: 本研究探讨了一种复杂的主-代理人游戏，在该游戏中，代理人不能直接观察代理人的奖励实现情况，这与许多主-代理人模型不同。这种信息不均衡使得代理人困难地估计代理人的未知奖励，这种问题在各种实际场景中都有广泛的应用，如绿色能源存储合同和个性化奖励等。</li>
<li>methods: 本研究使用了多臂抽象（MAB）问题和学习代理人的方法来解决这种复杂的主-代理人游戏。在这个框架中，代理人通过学习来决定选择，而代理人则通过训练并采用了一种并行的算法来估计代理人的未知奖励。</li>
<li>results: 本研究证明了在非 Parametric 模型下，可以使用历史记录来估计代理人的未知奖励，并且可以通过一种数据驱动的奖励策略来实现这一目标。此外，我们还证明了代理人的 regret bound，即代理人在选择奖励策略时的误差 bound。最后，我们通过 simulations 来证明我们的框架在绿色能源集成合同中的实用性。<details>
<summary>Abstract</summary>
In practice, incentive providers (i.e., principals) often cannot observe the reward realizations of incentivized agents, which is in contrast to many principal-agent models that have been previously studied. This information asymmetry challenges the principal to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, which becomes even more challenging when the agent has to learn its own rewards. This complex setting is observed in various real-life scenarios ranging from renewable energy storage contracts to personalized healthcare incentives. Hence, it offers not only interesting theoretical questions but also wide practical relevance. This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal. The agent tackles a multi-armed bandit (MAB) problem to maximize their expected reward plus incentive. On top of the agent's learning, the principal trains a parallel algorithm and faces a trade-off between consistently estimating the agent's unknown rewards and maximizing their own utility by offering adaptive incentives to lead the agent. For a non-parametric model, we introduce an estimator whose only input is the history of principal's incentives and agent's choices. We unite this estimator with a proposed data-driven incentive policy within a MAB framework. Without restricting the type of the agent's algorithm, we prove finite-sample consistency of the estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent. Lastly, our theoretical results are reinforced by simulations justifying applicability of our framework to green energy aggregator contracts.
</details>
<details>
<summary>摘要</summary>
在实践中，奖励提供者（即主体）经常无法观察奖励的实现，这与许多主体-代理模型不同。这种信息不均衡使得主体Difficult to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, especially when the agent needs to learn its own rewards. This complex setting is observed in various real-life scenarios, such as renewable energy storage contracts and personalized healthcare incentives. Therefore, it not only raises interesting theoretical questions but also has wide practical relevance.本文研究了一个反复的反选择游戏，在这个游戏中，一个自利益的学习代理和一个学习的主体之间进行交互。代理面临着一个多重武器问题（MAB），以最大化其预期奖励加上奖励。同时，主体也在学习，面临着一种奖励的适应性和自己的利用率之间的负担。为一个非 Parametric 模型，我们引入了一个仅基于主体的奖励历史和代理的选择的估计器。我们将这个估计器与一种基于 MAB 的数据驱动奖励策略结合。不Restricting the type of the agent's algorithm, we prove the finite-sample consistency of the estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent.最后，我们的理论结果被实践中的 simulations 证明了我们的框架在绿色能源聚合合同中的应用可行性。
</details></li>
</ul>
<hr>
<h2 id="Learning-on-Graphs-with-Out-of-Distribution-Nodes"><a href="#Learning-on-Graphs-with-Out-of-Distribution-Nodes" class="headerlink" title="Learning on Graphs with Out-of-Distribution Nodes"></a>Learning on Graphs with Out-of-Distribution Nodes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06714">http://arxiv.org/abs/2308.06714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/songyyyy/kdd22-oodgat">https://github.com/songyyyy/kdd22-oodgat</a></li>
<li>paper_authors: Yu Song, Donglin Wang</li>
<li>for: 本研究旨在 Addressing the problem of graph learning with out-of-distribution nodes, aiming to detect outliers and classify remaining nodes to known classes.</li>
<li>methods: 提出了一种新的 Graph Attention Network (GAT) 模型，称为 Out-of-Distribution Graph Attention Network (OODGAT)，该模型通过Explicitly modeling the interaction between different kinds of nodes and separating inliers from outliers during feature propagation,以便检测异常节点和分类正常节点。</li>
<li>results: 对多个实验 dataset 进行了extensive experiments，结果表明 OODGAT 比现有的异常检测方法具有更大的优势，同时与正常分类 Task 的性能相当。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model which explicitly models the interaction between different kinds of nodes and separate inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 是当今最先进的图数据预测模型。而现有的 GNN 模型在各种图数据任务上已经表现出色，但是对于图数据中存在 OUT-OF-DISTRIBUTION（OOD）节点的情况却得到了相对的少的关注。从 Computer Vision 和自然语言处理中借鉴的概念，我们定义 OOD 节点为训练集中未出现过的标签。实际上，由于许多网络是通过程序自动构建的，真实世界中的图数据经常具有噪音和未知分布的特点，因此在这种情况下，我们定义了图学习 WITH OUT-OF-DISTRIBUTION NODES 的问题。特别是，我们希望完成两个任务：1）检测图中不属于已知分布的节点，2）分类剩下的节点为已知类别中的一个。我们表明了图中连接 patrern 可以为 OUTLIER 检测提供信息，并提出了一种新的 GNN 模型，即 Out-of-Distribution Graph Attention Network (OODGAT)，该模型在传播特征时显式地处理不同类型的节点之间的交互，以分离异常节点和常见节点。我们进行了广泛的实验，并证明了 OODGAT 在 OUTLIER 检测方面比现有的方法有大幅度的提升，而且在可见分类方面也是或等于于比较好的。
</details></li>
</ul>
<hr>
<h2 id="Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection"><a href="#Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection" class="headerlink" title="Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection"></a>Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06701">http://arxiv.org/abs/2308.06701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haichao Zhang, Can Qin, Yu Yin, Yun Fu</li>
<li>for: 提高掩蔽物检测的深度学习模型性能</li>
<li>methods: 使用生成模型生成真实的掩蔽图像，并将其用于训练现有的对象检测模型</li>
<li>results: 在三个数据集（COD10k、CAMO和CHAMELEON）上超越当前状态的方法， demonstarting 其在掩蔽物检测中的有效性<details>
<summary>Abstract</summary>
Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-and-play data generation and augmentation module for existing camouflaged object detection tasks and provides a novel way to introduce more diversity and distributions into current camouflage datasets.
</details>
<details>
<summary>摘要</summary>
伪装物体在自然场景中混合是深度学习模型检测和synthesize的重要挑战。伪装物体检测是计算机视觉中重要的应用领域之一，但这一研究领域受到有限的数据可用性的限制。我们提出了一种框架，用于增强自然场景中的伪装物体检测。我们的方法使用生成模型生成真实的伪装图像，这些图像可以用来训练现有的对象检测模型。具体来说，我们使用一个伪装环境生成器，它是根据伪装分布分类器进行监督的。我们的框架在三个数据集（COD10k、CAMO和CHAMELEON）上表现出了比前一个状态的方法更好的性能，这说明了我们的方法的有效性。这种方法可以作为现有伪装物体检测任务的数据生成和增强模块，并提供了一种新的多样性和分布的引入方式，以便为当前的伪装数据集增加更多的多样性。
</details></li>
</ul>
<hr>
<h2 id="MACO-A-Modality-Adversarial-and-Contrastive-Framework-for-Modality-missing-Multi-modal-Knowledge-Graph-Completion"><a href="#MACO-A-Modality-Adversarial-and-Contrastive-Framework-for-Modality-missing-Multi-modal-Knowledge-Graph-Completion" class="headerlink" title="MACO: A Modality Adversarial and Contrastive Framework for Modality-missing Multi-modal Knowledge Graph Completion"></a>MACO: A Modality Adversarial and Contrastive Framework for Modality-missing Multi-modal Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06696">http://arxiv.org/abs/2308.06696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zjukg/maco">https://github.com/zjukg/maco</a></li>
<li>paper_authors: Yichi Zhang, Zhuo Chen, Wen Zhang</li>
<li>for: 提高大规模知识图（KG）中缺失模态信息的问题，以便更好地完成知识图完成（KGC）任务。</li>
<li>methods: 提出了一种模态对抗和对比框架（MACO），通过对Generator和Discriminator进行对抗训练，生成缺失模态特征，以便在MMKGC模型中使用。同时，我们设计了交叉模态对比损失，以提高生成器的性能。</li>
<li>results: 在公共benchmark上进行了实验，并进行了进一步的探索，结果显示MACO可以达到状态机器人的 результаats，并且可以用于强化多种MMKGC模型。我们的代码和benchmark数据可以在<a target="_blank" rel="noopener" href="https://github.com/zjukg/MACO%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/zjukg/MACO上获取。</a><details>
<summary>Abstract</summary>
Recent years have seen significant advancements in multi-modal knowledge graph completion (MMKGC). MMKGC enhances knowledge graph completion (KGC) by integrating multi-modal entity information, thereby facilitating the discovery of unobserved triples in the large-scale knowledge graphs (KGs). Nevertheless, existing methods emphasize the design of elegant KGC models to facilitate modality interaction, neglecting the real-life problem of missing modalities in KGs. The missing modality information impedes modal interaction, consequently undermining the model's performance. In this paper, we propose a modality adversarial and contrastive framework (MACO) to solve the modality-missing problem in MMKGC. MACO trains a generator and discriminator adversarially to generate missing modality features that can be incorporated into the MMKGC model. Meanwhile, we design a cross-modal contrastive loss to improve the performance of the generator. Experiments on public benchmarks with further explorations demonstrate that MACO could achieve state-of-the-art results and serve as a versatile framework to bolster various MMKGC models. Our code and benchmark data are available at https://github.com/zjukg/MACO.
</details>
<details>
<summary>摘要</summary>
近年来，多模式知识图完成（MMKGC）技术得到了 significiant 进步。 MMKGC 可以将多种模式实体信息集成到知识图中，从而促进发现大规模知识图中的未观察 triple。然而，现有的方法强调设计美观的 KGC 模型，以便模态之间的互动，忽略了实际生活中的缺失模态问题。缺失模态信息会阻碍模态之间的互动，从而降低模型的性能。在这篇论文中，我们提出了一种模态对抗和对比框架（MACO），用于解决 MMKGC 中缺失模态问题。MACO 通过对generator和discriminator进行对抗训练，生成缺失模态特征，以便在 MMKGC 模型中添加。同时，我们设计了对比架构来提高生成器的性能。实验结果表明，MACO 可以达到领先的Result和服务为多种 MMKGC 模型的可靠框架。我们的代码和 benchmark 数据可以在 https://github.com/zjukg/MACO 中下载。
</details></li>
</ul>
<hr>
<h2 id="Video-Captioning-with-Aggregated-Features-Based-on-Dual-Graphs-and-Gated-Fusion"><a href="#Video-Captioning-with-Aggregated-Features-Based-on-Dual-Graphs-and-Gated-Fusion" class="headerlink" title="Video Captioning with Aggregated Features Based on Dual Graphs and Gated Fusion"></a>Video Captioning with Aggregated Features Based on Dual Graphs and Gated Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06685">http://arxiv.org/abs/2308.06685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yutao Jin, Bin Liu, Jing Wang</li>
<li>for: 本研究旨在提高视频captioning模型的准确性和完整性，通过使用 dual graphs和gated fusion来生成多维度特征表示。</li>
<li>methods: 我们提出了基于 dual graphs和gated fusion的视频captioning模型，包括 dual-graphs reasoning和gated fusion两部分。 dual-graphs reasoning通过两种图来生成视频内容的多个方面特征，而gated fusion则是将多个特征表示之间的信息聚合以提高视频内容的全面理解。</li>
<li>results: 我们在MSVD和MSR-VTT两个常用 dataset上进行了实验，并取得了当前领域最佳表现。<details>
<summary>Abstract</summary>
The application of video captioning models aims at translating the content of videos by using accurate natural language. Due to the complex nature inbetween object interaction in the video, the comprehensive understanding of spatio-temporal relations of objects remains a challenging task. Existing methods often fail in generating sufficient feature representations of video content. In this paper, we propose a video captioning model based on dual graphs and gated fusion: we adapt two types of graphs to generate feature representations of video content and utilize gated fusion to further understand these different levels of information. Using a dual-graphs model to generate appearance features and motion features respectively can utilize the content correlation in frames to generate various features from multiple perspectives. Among them, dual-graphs reasoning can enhance the content correlation in frame sequences to generate advanced semantic features; The gated fusion, on the other hand, aggregates the information in multiple feature representations for comprehensive video content understanding. The experiments conducted on worldly used datasets MSVD and MSR-VTT demonstrate state-of-the-art performance of our proposed approach.
</details>
<details>
<summary>摘要</summary>
视频captioning模型的应用目标是将视频内容翻译成准确的自然语言。由于视频中对象之间的复杂交互，理解视频内容的空间时间关系是一项具有挑战性的任务。现有方法通常无法生成足够的视频内容特征表示。在这篇论文中，我们提出了基于双图和闭合融合的视频captioning模型：我们采用两种类型的图来生成视频内容的特征表示，并使用闭合融合来进一步理解这些不同水平的信息。使用双图模型生成出现特征和运动特征分别可以利用帧序列中的内容相关性来生成多种特征从多个角度。其中，双图理解可以增强帧序列中的内容相关性，生成更高级别的 semantic 特征；而闭合融合则可以将多个特征表示的信息聚合在一起，实现视频内容全面理解。我们在MSVD和MSR-VTT等世界 commonly 使用的数据集上进行了实验，并达到了当前最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent"><a href="#Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent" class="headerlink" title="Law of Balance and Stationary Distribution of Stochastic Gradient Descent"></a>Law of Balance and Stationary Distribution of Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06671">http://arxiv.org/abs/2308.06671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Ziyin, Hongchao Li, Masahito Ueda<br>for: 这个论文的目的是解释如何使用权重学习来训练神经网络，以及神经网络训练过程中SGD算法的工作机制。methods: 这篇论文使用了权重学习和SGD算法来训练神经网络，并通过分批训练来证明SGD算法可以带来对神经网络的稳定化。results: 这篇论文的结果表明，当损失函数具有对称性时，SGD算法会带来对神经网络的稳定化，并且可以带来复杂的非线性现象，如阶梯过程中的相态转变、缺失ерgodicity和振荡倒转。这些现象只存在于深度很大的神经网络中，这表明了深度神经网络和浅度神经网络之间的根本区别。<details>
<summary>Abstract</summary>
The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundamental difference between deep and shallow models.
</details>
<details>
<summary>摘要</summary>
Stochastic gradient descent（SGD）算法是我们用来训练神经网络的算法。但是，SGD在神经网络的高度非线性和潜在的异常点的搜索方面仍然不甚了解。在这项工作中，我们证明了SGD中的小批处理噪声规范化神经网络的解决方案，当损失函数包含对称性时。因为在对称性存在时，SGD的动态和普通液体流动的差异最大，我们的理论意味着损失函数的对称性是SGD工作的重要检验。我们then使用这个结果来Derive stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. Stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundamental difference between deep and shallow models.Note that Simplified Chinese is a simplified version of Chinese that uses shorter words and sentences, and is often used in informal writing and online communication. Traditional Chinese is a more formal version of Chinese that is used in formal writing and in most printed materials.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Adaptation-of-Polyp-Segmentation-Models-via-Coarse-to-Fine-Self-Supervision"><a href="#Unsupervised-Adaptation-of-Polyp-Segmentation-Models-via-Coarse-to-Fine-Self-Supervision" class="headerlink" title="Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine Self-Supervision"></a>Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06665">http://arxiv.org/abs/2308.06665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiexiang Wang, Chaoqi Chen</li>
<li>for: 本研究实验为了解决受隐私和安全问题限制的对应领域自适应<del>(UDA) 问题，专注于不需要源数据的对应领域自适应</del>(SFDA) 方法。</li>
<li>methods: 本研究提出了一个名为 Region-to-Pixel Adaptation Network~(RPANet) 的新 SFDA 框架，通过均衡粗细自我监督学习，从粗细到细节层次掌握区域和像素层次的标识表现。RPANet 包括两个模组：Foreground-aware Contrastive Learning (FCL) 和 Confidence-Calibrated Pseudo-Labeling (CCPL)，它们分别解决了“如何区别”和“如何调整”的关键挑战。</li>
<li>results: 实验结果显示，RPANet 在三个跨领域肿瘤分类任务上具有优秀的表现，较以前SFDA和UDA方法无法达到的水准，显示了SFDA在医疗应用中的潜力。<details>
<summary>Abstract</summary>
Unsupervised Domain Adaptation~(UDA) has attracted a surge of interest over the past decade but is difficult to be used in real-world applications. Considering the privacy-preservation issues and security concerns, in this work, we study a practical problem of Source-Free Domain Adaptation (SFDA), which eliminates the reliance on annotated source data. Current SFDA methods focus on extracting domain knowledge from the source-trained model but neglects the intrinsic structure of the target domain. Moreover, they typically utilize pseudo labels for self-training in the target domain, but suffer from the notorious error accumulation problem. To address these issues, we propose a new SFDA framework, called Region-to-Pixel Adaptation Network~(RPANet), which learns the region-level and pixel-level discriminative representations through coarse-to-fine self-supervision. The proposed RPANet consists of two modules, Foreground-aware Contrastive Learning (FCL) and Confidence-Calibrated Pseudo-Labeling (CCPL), which explicitly address the key challenges of ``how to distinguish'' and ``how to refine''. To be specific, FCL introduces a supervised contrastive learning paradigm in the region level to contrast different region centroids across different target images, which efficiently involves all pseudo labels while robust to noisy samples. CCPL designs a novel fusion strategy to reduce the overconfidence problem of pseudo labels by fusing two different target predictions without introducing any additional network modules. Extensive experiments on three cross-domain polyp segmentation tasks reveal that RPANet significantly outperforms state-of-the-art SFDA and UDA methods without access to source data, revealing the potential of SFDA in medical applications.
</details>
<details>
<summary>摘要</summary>
自然语言处理中的Unsupervised Domain Adaptation~(UDA)在过去的一个十年里引起了广泛的关注，但在实际应用中却难以使用。 Considering the privacy-preservation issues和安全问题，在这种工作中，我们研究了一个实用的源无需采用Domain Adaptation~(SFDA)问题，该问题消除了源数据的注释。Current SFDA方法通过提取源模型中的领域知识来解决问题，但忽略了目标频谱的内在结构。另外，它们通常通过pseudo标签进行自我训练在目标频谱中，但受到误差积累问题的困扰。为了解决这些问题，我们提出了一个新的SFDA框架，calledRegion-to-Pixel Adaptation Network~(RPANet)，该框架通过粗细自动supervised contrastive learning和Confidence-Calibrated Pseudo-Labeling（CCPL）模块来学习区域水平和像素级别的抑制表示。RPANet包括两个模块：Foreground-aware Contrastive Learning（FCL）和Confidence-Calibrated Pseudo-Labeling（CCPL），这两个模块直接解决了“如何 отличи出”和“如何精细化”的关键问题。具体来说，FCL引入了一种监督对照学习 парадигмы，在不同的目标图像中对不同的区域中心进行对比，以fficiently利用所有pseudo标签，并且对噪声样本具有鲁棒性。CCPL设计了一种新的融合策略，通过将两个不同的目标预测融合而不引入任何额外网络模块，以减少pseudo标签过度自信的问题。经验表明，RPANet在三个跨频谱肠segmentation任务上显著超过了state-of-the-art SFDA和UDA方法，无需访问源数据，探明SFDA在医疗应用中的潜力。
</details></li>
</ul>
<hr>
<h2 id="ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN"><a href="#ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN" class="headerlink" title="ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN"></a>ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06663">http://arxiv.org/abs/2308.06663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Abul Bashar, Richi Nayak</li>
<li>for: 这篇论文旨在应用生成对抗网络（GAN）方法来探测时间序列资料中的异常点。</li>
<li>methods: 这篇论文提出了一个新的GAN模型，名为调整LSTM GAN（ALGAN），它可以在无supervision的情况下提高时间序列资料中的异常点探测精度。</li>
<li>results: 论文的实验结果显示，ALGAN在46个真实世界单变时间序列数据集和多个领域的大量多变时间序列数据集上的异常点探测精度高于传统、神经网络基于的和其他GAN基于的方法。<details>
<summary>Abstract</summary>
Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data.
</details>
<details>
<summary>摘要</summary>
“时间序列资料中的偏差探测，以探测不同于常规行为的点，是不同领域中的一个常见问题，例如生产、医疗影像和 cybersecurity。在最近的研究中，生成对抗网络（GANs）已经被证明能够优化时间序列资料中的偏差探测精度。这个神经网络架构（i.e. 生成器和识别器）可以在无监督下提高偏差探测精度。在这篇论文中，我们提出了一个新的 GAN 模型，名为 Adjusted-LSTM GAN（ALGAN），它可以在无监督下对时间序列资料进行优化的偏差探测。我们将这个模型评估在 46 个真实的时间序列资料集和一个大的多重时间序列资料集中，结果显示 ALGAN 可以在无监督下优化时间序列资料中的偏差探测精度，并且比较传统的神经网络、神经网络基于的方法和其他 GAN 基于的方法更高。”
</details></li>
</ul>
<hr>
<h2 id="Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features"><a href="#Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features" class="headerlink" title="Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features"></a>Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08482">http://arxiv.org/abs/2308.08482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yiiizhang/shortcutDebiasing">https://github.com/yiiizhang/shortcutDebiasing</a></li>
<li>paper_authors: Yi Zhang, Jitao Sang, Junyang Wang, Dongmei Jiang, Yaowei Wang</li>
<li>for: 这篇论文旨在解决机器学习模型对敏感社会特征（如性别和种族）的预测问题，以确保在社会应用中保持公平性。</li>
<li>methods: 这篇论文提出了一种称为“Shortcut Debiasing”的方法，将偏见特征（如性别）转换为快捷特征（ Shortcut Features），然后使用 causal intervention 方法删除这些快捷特征 durante 推断过程。</li>
<li>results: 这篇论文在多个 benchmark 数据集上实现了与现有debiasing方法相比的重要改善， both 精度和公平性方面。<details>
<summary>Abstract</summary>
Machine learning models often learn to make predictions that rely on sensitive social attributes like gender and race, which poses significant fairness risks, especially in societal applications, such as hiring, banking, and criminal justice. Existing work tackles this issue by minimizing the employed information about social attributes in models for debiasing. However, the high correlation between target task and these social attributes makes learning on the target task incompatible with debiasing. Given that model bias arises due to the learning of bias features (\emph{i.e}., gender) that help target task optimization, we explore the following research question: \emph{Can we leverage shortcut features to replace the role of bias feature in target task optimization for debiasing?} To this end, we propose \emph{Shortcut Debiasing}, to first transfer the target task's learning of bias attributes from bias features to shortcut features, and then employ causal intervention to eliminate shortcut features during inference. The key idea of \emph{Shortcut Debiasing} is to design controllable shortcut features to on one hand replace bias features in contributing to the target task during the training stage, and on the other hand be easily removed by intervention during the inference stage. This guarantees the learning of the target task does not hinder the elimination of bias features. We apply \emph{Shortcut Debiasing} to several benchmark datasets, and achieve significant improvements over the state-of-the-art debiasing methods in both accuracy and fairness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Smart-Knowledge-Transfer-using-Google-like-Search"><a href="#Smart-Knowledge-Transfer-using-Google-like-Search" class="headerlink" title="Smart Knowledge Transfer using Google-like Search"></a>Smart Knowledge Transfer using Google-like Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06653">http://arxiv.org/abs/2308.06653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srijoni Majumdar, Partha Pratim Das</li>
<li>for: Addressing the issue of rising software maintenance cost due to program comprehension challenges.</li>
<li>methods: Proposes SMARTKT (Smart Knowledge Transfer), a search framework that extracts and integrates knowledge related to various aspects of an application in the form of a semantic graph, supporting syntax and semantic queries and converting the process of program comprehension into a “google-like” search problem.</li>
<li>results: Not specified in the abstract, but the paper likely presents the effectiveness of SMARTKT in improving program comprehension and reducing software maintenance costs.<details>
<summary>Abstract</summary>
To address the issue of rising software maintenance cost due to program comprehension challenges, we propose SMARTKT (Smart Knowledge Transfer), a search framework, which extracts and integrates knowledge related to various aspects of an application in form of a semantic graph. This graph supports syntax and semantic queries and converts the process of program comprehension into a {\em google-like} search problem.
</details>
<details>
<summary>摘要</summary>
Here's the breakdown of the translation:* "rising software maintenance cost" is translated as "软件维护成本的增加"* "due to program comprehension challenges" is translated as "由程序理解困难引起"* "we propose SMARTKT" is translated as "我们提出智能知识传输"* "a search framework" is translated as "一个搜索框架"* "which extracts and integrates knowledge related to various aspects of an application" is translated as "可以提取和集成各个方面的应用程序知识"* "in the form of a semantic graph" is translated as "以semantic graph的形式"* "This graph supports syntax and semantic queries" is translated as "这个图表支持语法和 semantics 查询"* "and converts the process of program comprehension into a 'Google-like' search problem" is translated as "并将程序理解过程转化为一个"Google-like"搜索问题"Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Stationary-Algorithmic-Balancing-For-Dynamic-Email-Re-Ranking-Problem"><a href="#Stationary-Algorithmic-Balancing-For-Dynamic-Email-Re-Ranking-Problem" class="headerlink" title="Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem"></a>Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08460">http://arxiv.org/abs/2308.08460</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jylevangeline/mosr">https://github.com/jylevangeline/mosr</a></li>
<li>paper_authors: Jiayi Liu, Jennifer Neville</li>
<li>for: 这个研究旨在提出一个基于多重目标的电子邮件推荐系统，以满足用户在不同时间的偏好变化。</li>
<li>methods: 这个研究使用了一个适应控制模型来动态均衡多重目标，包括 sender和topic的相关性、时间新鲜度和信息简洁度。</li>
<li>results: 研究结果显示，MOSR在非站ARY preferences下表现更好，特别是在用户偏好变化时。另外，MOSR在不同样本中的稳定性也得到了证明。<details>
<summary>Abstract</summary>
Email platforms need to generate personalized rankings of emails that satisfy user preferences, which may vary over time. We approach this as a recommendation problem based on three criteria: closeness (how relevant the sender and topic are to the user), timeliness (how recent the email is), and conciseness (how brief the email is). We propose MOSR (Multi-Objective Stationary Recommender), a novel online algorithm that uses an adaptive control model to dynamically balance these criteria and adapt to preference changes. We evaluate MOSR on the Enron Email Dataset, a large collection of real emails, and compare it with other baselines. The results show that MOSR achieves better performance, especially under non-stationary preferences, where users value different criteria more or less over time. We also test MOSR's robustness on a smaller down-sampled dataset that exhibits high variance in email characteristics, and show that it maintains stable rankings across different samples. Our work offers novel insights into how to design email re-ranking systems that account for multiple objectives impacting user satisfaction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation"><a href="#Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation" class="headerlink" title="Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation"></a>Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06644">http://arxiv.org/abs/2308.06644</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation">https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation</a></li>
<li>paper_authors: Junwei Huang, Zhiqing Sun, Yiming Yang</li>
<li>for: 提高NP-完全 combinatorial优化（CO）问题的解决质量和搜索效率</li>
<li>methods: 使用进步浸泡法加速推理，通过在推理过程中采取 fewer steps 来减少推理时间</li>
<li>results: 实验结果显示，使用进步浸泡法可以提高推理速度 16 倍，只带来 0.019% 的性能下降在 TSP-50 数据集上<details>
<summary>Abstract</summary>
Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
</details>
<details>
<summary>摘要</summary>
几何基于的扩散模型已经在解决NP完备（NPC） combinatorial优化（CO）问题中显示出了可观的成果，但是这些模型往往在推断中效率低下，因为推断过程是迭代评估的。本文提议使用进步养分来加速推断，在推断过程中只需要几步（例如在单步中预测两步）。我们的实验结果显示，使用进步养分的模型可以在TSP-50 dataset上实现16倍的推断速度，仅带来0.019%的性能下降。
</details></li>
</ul>
<hr>
<h2 id="Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks"><a href="#Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks" class="headerlink" title="Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?"></a>Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06619">http://arxiv.org/abs/2308.06619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Liao, Victor Quétu, Van-Tam Nguyen, Enzo Tartaglione</li>
<li>for: 降低深度神经网络大小而保持性能</li>
<li>methods: 使用Entropy Guided Pruning算法（EGP），主要是根据层次 entropy 来决定 Connection 的缩减和完全删除</li>
<li>results: 对 популяр的模型 ResNet-18 和 Swin-T 进行了广泛的实验，发现 EGP 能够有效地压缩深度神经网络，同时保持竞争性能水平。<details>
<summary>Abstract</summary>
Pruning is a widely used technique for reducing the size of deep neural networks while maintaining their performance. However, such a technique, despite being able to massively compress deep models, is hardly able to remove entire layers from a model (even when structured): is this an addressable task? In this study, we introduce EGP, an innovative Entropy Guided Pruning algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relationship between entropy, pruning techniques, and deep learning performance. The EGP algorithm and its insights hold great promise for advancing the field of network compression and optimization. The source code for EGP is released open-source.
</details>
<details>
<summary>摘要</summary>
剪辑是一种广泛使用的技术，用于减少深度神经网络的大小，保持其性能。然而，这种技术，即使能够压缩深度模型，几乎无法完全移除层（即使是结构化的）：是这个任务可行吗？在这项研究中，我们介绍了EGP算法，一种创新的熵导向剪辑算法，用于减少深度神经网络的大小，保持其性能。EGP的关键焦点在于优先剪辑层中的低熵连接，最终导致它们的完全移除。经过对流行的模型如ResNet-18和Swin-T进行了广泛的实验，我们的发现表明EGP有效地压缩深度神经网络，保持竞争力的性能水平。我们的结果不仅解释了剪辑技术的优势，还开创了进一步研究熵、剪辑技术和深度学习性能之间的复杂关系。EGP算法和其发现将对神经网络压缩和优化领域的发展带来巨大的潜力。EGP算法的源代码已经开源发布。
</details></li>
</ul>
<hr>
<h2 id="On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness"><a href="#On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness" class="headerlink" title="On the Interplay of Convolutional Padding and Adversarial Robustness"></a>On the Interplay of Convolutional Padding and Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06612">http://arxiv.org/abs/2308.06612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
<li>for: 本研究探讨了 padding 对 adversarial attack 的影响，并 analyzed 了不同的 padding 模式对 adversarial robustness 的影响。</li>
<li>methods: 本研究使用了 Convolutional Neural Networks (CNN)，并对 input 进行 padding 以 preserve 特征图像的分辨率。</li>
<li>results: 研究发现， adversarial attacks 通常会在图像边缘产生偏差异常，这些偏差异常与 padding 使用的边界有关。<details>
<summary>Abstract</summary>
It is common practice to apply padding prior to convolution operations to preserve the resolution of feature-maps in Convolutional Neural Networks (CNN). While many alternatives exist, this is often achieved by adding a border of zeros around the inputs. In this work, we show that adversarial attacks often result in perturbation anomalies at the image boundaries, which are the areas where padding is used. Consequently, we aim to provide an analysis of the interplay between padding and adversarial attacks and seek an answer to the question of how different padding modes (or their absence) affect adversarial robustness in various scenarios.
</details>
<details>
<summary>摘要</summary>
通常来说，在卷积神经网络（CNN）中，会在特征地图前加padding以保持特征地图的分辨率。虽然有很多选择，通常是通过添加边框中 zeros 来实现。在这项工作中，我们发现了敌意攻击通常会在图像边界上产生异常的扰动，这 precisamente 是 padding 使用的地方。因此，我们想进行 padding 和敌意攻击之间的分析，并查找不同 padding 模式（或其缺失）对敌意Robustness 在不同情况下的影响。
</details></li>
</ul>
<hr>
<h2 id="Bio-SIEVE-Exploring-Instruction-Tuning-Large-Language-Models-for-Systematic-Review-Automation"><a href="#Bio-SIEVE-Exploring-Instruction-Tuning-Large-Language-Models-for-Systematic-Review-Automation" class="headerlink" title="Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation"></a>Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06610">http://arxiv.org/abs/2308.06610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ambroser53/bio-sieve">https://github.com/ambroser53/bio-sieve</a></li>
<li>paper_authors: Ambrose Robinson, William Thorne, Ben P. Wu, Abdullah Pandor, Munira Essat, Mark Stevenson, Xingyi Song</li>
<li>for: 这个研究旨在探讨如何使用大自然语言模型（LLMs）支持和训练，以便在提供明确的选择标准下进行文献屏选。</li>
<li>methods: 研究使用了 instruction tuning 方法来训练 LLaMA 和 Guanaco 模型，以进行摘要屏选。</li>
<li>results: 研究发现，使用 Bio-SIEVE 模型可以超越 ChatGPT 和经过训练的传统方法，并在医学领域中更好地泛化。然而，在安全性优先的场景下，模型仍然需要进一步适应。此外，研究还探讨了多任务训练 Bio-SIEVE-Multi 模型，包括 PICO 提取和排除逻辑等任务，但发现它无法与单任务 Bio-SIEVE 的性能相比。<details>
<summary>Abstract</summary>
Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically, we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model, Bio-SIEVE, outperforms both ChatGPT and trained traditional approaches, and generalises better across medical domains. However, there remains the challenge of adapting the model to safety-first scenarios. We also explore the impact of multi-task training with Bio-SIEVE-Multi, including tasks such as PICO extraction and exclusion reasoning, but find that it is unable to match single-task Bio-SIEVE's performance. We see Bio-SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models, code and a list of DOIs to reconstruct our dataset for reproducibility.
</details>
<details>
<summary>摘要</summary>
医学系统atic review可以非常昂贵和资源占用。我们探讨如何使用大型自然语言模型（LLM）支持和训练来执行文献屏选。特别是我们 instrucion 调整 LLaMA 和 Guanaco 模型来执行医学系统atic review的摘要屏选。我们的最佳模型，生物-SIEVE，超过了 ChatGPT 和训练过的传统方法，并在医学领域中更好地泛化。然而，还有一个适应模型到安全第一的挑战。我们还探讨 Bio-SIEVE 多任务训练的影响，包括 PICO 提取和排除逻辑任务，但发现它无法与单任务 Bio-SIEVE 的性能匹配。我们认为 Bio-SIEVE 是特циализиing LLMs  для医学系统atic review过程中的重要一步，并探讨其未来发展机遇。我们发布我们的模型、代码和 DOIs 以便重现我们的数据集。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.AI_2023_08_13/" data-id="clon21iiy0029r58880fjd3j0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.CL_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T11:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.CL_2023_08_13/">cs.CL - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP"><a href="#Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP" class="headerlink" title="Faithful to Whom? Questioning Interpretability Measures in NLP"></a>Faithful to Whom? Questioning Interpretability Measures in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06795">http://arxiv.org/abs/2308.06795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Crothers, Herna Viktor, Nathalie Japkowicz</li>
<li>for: 这 paper 的目的是探讨现有的 faithfulness metrics 是否适用于比较不同的神经网络文本分类器的解释性。</li>
<li>methods: 作者使用 iterative masking 方法测试 faithfulness metrics，并发现这些度量在不同的模型之间存在很大的变化。</li>
<li>results: 作者发现 masked samples frequently 外部训练数据分布，并且 iterative masking 可能导致 faithfulness scores 的巨大变化。 另外，作者还研究了对 faithfulness scores 的影响，包括 adversarial attacks 和 adversarial training。<details>
<summary>Abstract</summary>
A common approach to quantifying model interpretability is to calculate faithfulness metrics based on iteratively masking input tokens and measuring how much the predicted label changes as a result. However, we show that such metrics are generally not suitable for comparing the interpretability of different neural text classifiers as the response to masked inputs is highly model-specific. We demonstrate that iterative masking can produce large variation in faithfulness scores between comparable models, and show that masked samples are frequently outside the distribution seen during training. We further investigate the impact of adversarial attacks and adversarial training on faithfulness scores, and demonstrate the relevance of faithfulness measures for analyzing feature salience in text adversarial attacks. Our findings provide new insights into the limitations of current faithfulness metrics and key considerations to utilize them appropriately.
</details>
<details>
<summary>摘要</summary>
一种常见的方法量化模型解释性是通过 iteratively masking input token 并测量预测标签变化的方式来计算 faithfulness 度量。然而，我们显示这些度量不适合比较不同的神经网络文本分类器的解释性，因为模型具有很高的特定性。我们示出了 iterative 遮盖可能会导致大量的 faithfulness 分数变化，并且遮盖样本通常不在训练时间段内。我们进一步研究了对 faithfulness 度量的影响和对文本对抗攻击的分析，并证明了 faithfulness 度量的重要性。我们的发现提供了新的理解现有 faithfulness 度量的限制和使其正确使用的关键考虑因素。
</details></li>
</ul>
<hr>
<h2 id="Modeling-the-Dashboard-Provenance"><a href="#Modeling-the-Dashboard-Provenance" class="headerlink" title="Modeling the Dashboard Provenance"></a>Modeling the Dashboard Provenance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06788">http://arxiv.org/abs/2308.06788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johne Jarske, Jorge Rady, Lucia V. L. Filgueiras, Leandro M. Velloso, Tania L. Santos</li>
<li>For: The paper aims to provide a provenance representation model for dashboards and its visual and data components, which can help organizations evaluate the quality, consistency, and reliability of the information presented on dashboards.* Methods: The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the context in which a specific dashboard was developed, including information about people, organizations, entities, and activities involved in the production, influence, or delivery of the data or object.* Results: The paper aims to provide a standardized and visualized representation of provenance metadata for dashboards, which can help users make better decisions based on the quality and reliability of the information presented.<details>
<summary>Abstract</summary>
Organizations of all kinds, whether public or private, profit-driven or non-profit, and across various industries and sectors, rely on dashboards for effective data visualization. However, the reliability and efficacy of these dashboards rely on the quality of the visual and data they present. Studies show that less than a quarter of dashboards provide information about their sources, which is just one of the expected metadata when provenance is seriously considered. Provenance is a record that describes people, organizations, entities, and activities that had a role in the production, influence, or delivery of a piece of data or an object. This paper aims to provide a provenance representation model, that entitles standardization, modeling, generation, capture, and visualization, specifically designed for dashboards and its visual and data components. The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the quality, consistency, and reliability of the information presented on dashboards. This will allow a clear and precise understanding of the context in which a specific dashboard was developed, ultimately leading to better decision-making.
</details>
<details>
<summary>摘要</summary>
Provenance is a record that describes people, organizations, entities, and activities that had a role in the production, influence, or delivery of a piece of data or an object. This paper aims to provide a provenance representation model, that entitles standardization, modeling, generation, capture, and visualization, specifically designed for dashboards and its visual and data components. The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the quality, consistency, and reliability of the information presented on dashboards. This will allow a clear and precise understanding of the context in which a specific dashboard was developed, ultimately leading to better decision-making.
</details></li>
</ul>
<hr>
<h2 id="Token-Scaled-Logit-Distillation-for-Ternary-Weight-Generative-Language-Models"><a href="#Token-Scaled-Logit-Distillation-for-Ternary-Weight-Generative-Language-Models" class="headerlink" title="Token-Scaled Logit Distillation for Ternary Weight Generative Language Models"></a>Token-Scaled Logit Distillation for Ternary Weight Generative Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06744">http://arxiv.org/abs/2308.06744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsoo Kim, Sihwa Lee, Janghwan Lee, Sukjin Hong, Du-Seong Chang, Wonyong Sung, Jungwook Choi</li>
<li>for: 这个研究是为了解决生成模型在实际应用中的大型模型问题。</li>
<li>methods: 这个研究使用了量化测试敏感训练（QAT）方法，并提出了一个专门适用于生成模型的知识传递法。</li>
<li>results: 这个研究获得了较少于1.0倍的衰落和无损失的推理任务结果，表明了这个方法的成功。<details>
<summary>Abstract</summary>
Generative Language Models (GLMs) have shown impressive performance in tasks such as text generation, understanding, and reasoning. However, the large model size poses challenges for practical deployment. To solve this problem, Quantization-Aware Training (QAT) has become increasingly popular. However, current QAT methods for generative models have resulted in a noticeable loss of accuracy. To counteract this issue, we propose a novel knowledge distillation method specifically designed for GLMs. Our method, called token-scaled logit distillation, prevents overfitting and provides superior learning from the teacher model and ground truth. This research marks the first evaluation of ternary weight quantization-aware training of large-scale GLMs with less than 1.0 degradation in perplexity and no loss of accuracy in a reasoning task.
</details>
<details>
<summary>摘要</summary>
生成语言模型（GLM）在文本生成、理解和推理等任务中表现出色，但模型大小带来实际部署的挑战。为解决这个问题，量化意识训练（QAT）在生成模型中变得越来越流行。然而，现有的QAT方法对生成模型带来明显的精度损失。为此，我们提出了一种特有的知识储存方法，称为Token扩展LOGIT储存。该方法防止过拟合，并从教师模型和真实数据中提取优质知识。这项研究标志着大规模GLM的三进制重量量化意识训练的首次评估，并达到了低于1.0的质量下降和无损失的理解任务准确率。
</details></li>
</ul>
<hr>
<h2 id="Emergent-communication-for-AR"><a href="#Emergent-communication-for-AR" class="headerlink" title="Emergent communication for AR"></a>Emergent communication for AR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07342">http://arxiv.org/abs/2308.07342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruxiao Chen, Shuaishuai Guo</li>
<li>for: 这篇论文旨在提出一种用于Mobile Augmented Reality（MAR）的 emergent semantic communication 框架，以便在 MAR 中提高通信效率。</li>
<li>methods: 作者使用了两个代理人通过修改了 Lewis 信号游戏进行训练，以便自动生成一种简短的通信协议。</li>
<li>results: 实验表明，提出的方案在不可见对象上具有更好的泛化性，并且可以通过使用小型消息来提高通信效率。<details>
<summary>Abstract</summary>
Mobile augmented reality (MAR) is widely acknowledged as one of the ubiquitous interfaces to the digital twin and Metaverse, demanding unparalleled levels of latency, computational power, and energy efficiency. The existing solutions for realizing MAR combine multiple technologies like edge, cloud computing, and fifth-generation (5G) networks. However, the inherent communication latency of visual data imposes apparent limitations on the quality of experience (QoE). To address the challenge, we propose an emergent semantic communication framework to learn the communication protocols in MAR. Specifically, we train two agents through a modified Lewis signaling game to emerge a discrete communication protocol spontaneously. Based on this protocol, two agents can communicate about the abstract idea of visual data through messages with extremely small data sizes in a noisy channel, which leads to message errors. To better simulate real-world scenarios, we incorporate channel uncertainty into our training process. Experiments have shown that the proposed scheme has better generalization on unseen objects than traditional object recognition used in MAR and can effectively enhance communication efficiency through the utilization of small-size messages.
</details>
<details>
<summary>摘要</summary>
移动增强现实（MAR）被广泛承认为数字双胞迷和Metaverse的一种普遍的界面，需要无 précédent 的延迟、计算能力和能效率。现有的 MAR 实现方案 combining 多种技术，如边缘计算、云计算和 fifth-generation（5G）网络。然而，视觉数据的自然通信延迟带来明显的用户体验质量（QoE）限制。为 Addressing 这个挑战，我们提出了一种emergent semantic communication框架，用于在 MAR 中学习通信协议。具体来说，我们通过 modify 了 Lewis 信号游戏来训练两个代理人，从而自然地生成一个精简的通信协议。根据这个协议，两个代理人可以通过 messages  WITH  extremely small data sizes 在噪音频道中交换信息，这会导致消息错误。为更好地模拟实际情况，我们将频率uncertainty  incorporated 到我们的训练过程中。实验结果表明，我们的方案在未看到对象时比传统 MAR 中使用的对象识别更好地 generalization ，并可以通过利用小型消息来提高通信效率。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.CL_2023_08_13/" data-id="clon21inj0096r5885slza1lg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.LG_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T10:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.LG_2023_08_13/">cs.LG - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP"><a href="#Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP" class="headerlink" title="Faithful to Whom? Questioning Interpretability Measures in NLP"></a>Faithful to Whom? Questioning Interpretability Measures in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06795">http://arxiv.org/abs/2308.06795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Crothers, Herna Viktor, Nathalie Japkowicz</li>
<li>for: 这 paper 是为了评估不同神经网络文本分类器的解释性而写的。</li>
<li>methods: 这 paper 使用了基于层次遮盖的 faithfulness 度量来评估模型的解释性，并证明了这些度量不适合比较不同模型的解释性。</li>
<li>results: 研究发现，基于层次遮盖的 faithfulness 度量在不同模型之间可能会带来很大的差异，而且遮盖样本经常处于训练期间所未见 Distribution 之外。<details>
<summary>Abstract</summary>
A common approach to quantifying model interpretability is to calculate faithfulness metrics based on iteratively masking input tokens and measuring how much the predicted label changes as a result. However, we show that such metrics are generally not suitable for comparing the interpretability of different neural text classifiers as the response to masked inputs is highly model-specific. We demonstrate that iterative masking can produce large variation in faithfulness scores between comparable models, and show that masked samples are frequently outside the distribution seen during training. We further investigate the impact of adversarial attacks and adversarial training on faithfulness scores, and demonstrate the relevance of faithfulness measures for analyzing feature salience in text adversarial attacks. Our findings provide new insights into the limitations of current faithfulness metrics and key considerations to utilize them appropriately.
</details>
<details>
<summary>摘要</summary>
一种常见的方法量化模型解释性是通过逐渐遮盖输入符号来计算输出标签变化的程度。然而，我们显示这些度量不适合比较不同的神经网络文本分类器的解释性，因为遮盖输入的响应是高度模型特定的。我们示出了遮盖样本会导致大量的 faithfulness 分数变化，并且显示遮盖样本 frequently 外部训练数据分布。我们进一步调查了对抗攻击和对抗训练对 faithfulness 度量的影响，并证明了 faithfulness 度量对文本对抗攻击中的特征突出性进行分析具有重要意义。我们的发现为现有的 faithfulness 度量带来新的理解和使用其应用中的关键考虑因素。
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-at-a-Fraction-with-Pruned-Quaternions"><a href="#Neural-Networks-at-a-Fraction-with-Pruned-Quaternions" class="headerlink" title="Neural Networks at a Fraction with Pruned Quaternions"></a>Neural Networks at a Fraction with Pruned Quaternions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06780">http://arxiv.org/abs/2308.06780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/quartLT22">https://github.com/smlab-niser/quartLT22</a></li>
<li>paper_authors: Sahel Mohammad Iqbal, Subhankar Mishra</li>
<li>for: 这个研究旨在测试在极端资源受限的环境中，使用简单的神经网络来进行预测。</li>
<li>methods: 研究使用删减来简化神经网络中的参数数量，并使用高维数据嵌入来维持预测精度。</li>
<li>results: 研究发现，在某些架构和 dataset 上，删减后的数值网络可以超过相同架构的实际网络。例如，在 CIFAR-10 上使用 Conv-4 架构时，删减后的数值网络在 $3%$ 的参数数量下，可以比实际网络高于 $10%$。<details>
<summary>Abstract</summary>
Contemporary state-of-the-art neural networks have increasingly large numbers of parameters, which prevents their deployment on devices with limited computational power. Pruning is one technique to remove unnecessary weights and reduce resource requirements for training and inference. In addition, for ML tasks where the input data is multi-dimensional, using higher-dimensional data embeddings such as complex numbers or quaternions has been shown to reduce the parameter count while maintaining accuracy. In this work, we conduct pruning on real and quaternion-valued implementations of different architectures on classification tasks. We find that for some architectures, at very high sparsity levels, quaternion models provide higher accuracies than their real counterparts. For example, at the task of image classification on CIFAR-10 using Conv-4, at $3\%$ of the number of parameters as the original model, the pruned quaternion version outperforms the pruned real by more than $10\%$. Experiments on various network architectures and datasets show that for deployment in extremely resource-constrained environments, a sparse quaternion network might be a better candidate than a real sparse model of similar architecture.
</details>
<details>
<summary>摘要</summary>
当代最先进的神经网络具有越来越多的参数，这限制了它们在计算能力有限的设备上进行训练和推理的可行性。剪枝是一种技术，可以从神经网络中移除不必要的权重，以降低训练和推理的资源需求。此外，在多维输入数据的机器学习任务中，使用高维数域嵌入，如复数或四元数，可以降低参数数量而保持准确性。在这项工作中，我们对实际值和四元数值实现的不同架构进行剪枝处理，并发现在某些架构上，难以架构的四元数模型在高度精简率下提供更高的准确性。例如，在使用Conv-4架构进行图像分类任务时，采用了$3\%$的参数数量的剪枝后，四元数模型的准确性高于实际值模型的准确性超过$10\%$。经过了不同的网络架构和数据集的实验，我们发现在极其有限的资源环境中，一个稀疏的四元数网络可能比同类架构的实际稀疏模型更适合进行部署。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations"><a href="#A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations" class="headerlink" title="A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations"></a>A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06767">http://arxiv.org/abs/2308.06767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrcheng1066/awesome-pruning">https://github.com/hrcheng1066/awesome-pruning</a></li>
<li>paper_authors: Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi</li>
<li>for: 本文提供了现代深度神经网络压缩的综述，尤其是最新的大型语言模型，以及压缩方法的批判和评价。</li>
<li>methods: 本文分类了现有的压缩研究工作，包括一般&#x2F;特定加速、压缩时机、压缩方法和压缩与其他压缩技术的融合。</li>
<li>results: 本文提供了七对对比设定的深度神经网络压缩的比较分析，并探讨了emerging topics such as post-training pruning, different levels of supervision for pruning, and broader applications。<details>
<summary>Abstract</summary>
Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources. To enable the deployment of modern models on resource-constrained environments and accelerate inference time, researchers have increasingly explored pruning techniques as a popular research direction in neural network compression. However, there is a dearth of up-to-date comprehensive review papers on pruning. To address this issue, in this survey, we provide a comprehensive review of existing research works on deep neural network pruning in a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to prune, and 4) fusion of pruning and other compression techniques. We then provide a thorough comparative analysis of seven pairs of contrast settings for pruning (e.g., unstructured/structured) and explore emerging topics, including post-training pruning, different levels of supervision for pruning, and broader applications (e.g., adversarial robustness) to shed light on the commonalities and differences of existing methods and lay the foundation for further method development. To facilitate future research, we build a curated collection of datasets, networks, and evaluations on different applications. Finally, we provide some valuable recommendations on selecting pruning methods and prospect promising research directions. We build a repository at https://github.com/hrcheng1066/awesome-pruning.
</details>
<details>
<summary>摘要</summary>
现代深度神经网络，特别是最近的大型语言模型，具有庞大的计算和存储资源需求。为实现资源约束环境中部署现代模型和加速推理时间，研究人员开始了压缩神经网络的研究，成为现代神经网络压缩的流行研究方向。然而，当前存在相对落后的压缩研究报告。为解决这问题，在这篇评论中，我们提供了一个包括1)通用/特定速度、2)何时压缩、3)如何压缩和4)压缩与其他压缩技术融合的taxonomy的全面评论。然后，我们对7对对比设定进行了综合分析（例如，无结构/结构），并探讨了emerging topics（例如，后处理压缩、不同级别的监督压缩和更广泛的应用，例如对抗攻击），以抛光现有方法的相似性和差异，并为未来的研究提供了基础。为便于未来的研究，我们创建了一个 curaated 的数据集、网络和评估集。最后，我们提供了一些有价值的建议，包括选择压缩方法和前景探索的可能性，以及未来研究的可能性。我们在 <https://github.com/hrcheng1066/awesome-pruning> 上建立了一个存储库。
</details></li>
</ul>
<hr>
<h2 id="Conic-Descent-Redux-for-Memory-Efficient-Optimization"><a href="#Conic-Descent-Redux-for-Memory-Efficient-Optimization" class="headerlink" title="Conic Descent Redux for Memory-Efficient Optimization"></a>Conic Descent Redux for Memory-Efficient Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07343">http://arxiv.org/abs/2308.07343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingcong Li, Georgios B. Giannakis</li>
<li>for: 本研究探讨了一种最近发展的首项凹降（CD）解决方案，并在三个方面进行了改进：intuition、理论和算法实现。</li>
<li>methods: 本研究发现CD可以提供一种直观的几何 derivation，来自对准题的 dual 问题。这开启了新的算法设计的门户，其中一个是旋转 variant of CD（MOCO）的示例。透过分析 CD 和 MOCO 的双重行为，发现：i) 可以分析性地确定停止标准；ii) 可以设计预conditioners 以加速双方的准确。</li>
<li>results: 最后，本研究开发了一种内存效率高的 MOCO 变体，用于扩展 SDP 特别是低级解。numerical validation 表明，这种变体可以快速和精准地解决 SDP 问题。<details>
<summary>Abstract</summary>
Conic programming has well-documented merits in a gamut of signal processing and machine learning tasks. This contribution revisits a recently developed first-order conic descent (CD) solver, and advances it in three aspects: intuition, theory, and algorithmic implementation. It is found that CD can afford an intuitive geometric derivation that originates from the dual problem. This opens the door to novel algorithmic designs, with a momentum variant of CD, momentum conic descent (MOCO) exemplified. Diving deeper into the dual behavior CD and MOCO reveals: i) an analytically justified stopping criterion; and, ii) the potential to design preconditioners to speed up dual convergence. Lastly, to scale semidefinite programming (SDP) especially for low-rank solutions, a memory efficient MOCO variant is developed and numerically validated.
</details>
<details>
<summary>摘要</summary>
带形编程在信号处理和机器学习任务中有良好的记录。这篇论文探讨了最近开发的首项对数算法（CD）解决方案，并在三个方面提高：直观、理论和算法实现。发现CD可以提供直观的几何 derivation，这开启了新的算法设计的门户，例如帕摩散度降低（MOCO）。透过对CD和MOCO的分析，发现：一、分析正确的停止标准；二、设计加速对偶速度的预处理器。最后，为了扩大低级解的SDP，我们开发了内存有效的MOCO变体，并在数值上验证了其正确性。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Class-incremental-Learning-A-Survey"><a href="#Few-shot-Class-incremental-Learning-A-Survey" class="headerlink" title="Few-shot Class-incremental Learning: A Survey"></a>Few-shot Class-incremental Learning: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06764">http://arxiv.org/abs/2308.06764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinghua Zhang, Li Liu, Olli Silven, Matti Pietikäinen, Dewen Hu</li>
<li>for: 本文提供了一个系统性的和深入的简要评论，涵盖了多类增量学习（Few-shot Class-Incremental Learning，FSCIL）领域的各种方面，包括问题定义、基本挑战、一般方案、相关逻辑和评价指标等。</li>
<li>methods: 本文总结了FSCIL中的一些常见方法，包括基于数据、基于结构和优化基的方法，以及对象检测方法的各种改进方法，如 anchor-free 和 anchor-based 方法。</li>
<li>results: 本文提供了一些在FSCIL领域的研究方向，包括数据-based、结构-based 和优化-based 方法，以及一些需要进一步探索的研究方向。<details>
<summary>Abstract</summary>
Few-shot Class-Incremental Learning (FSCIL) presents a unique challenge in machine learning, as it necessitates the continuous learning of new classes from sparse labeled training samples without forgetting previous knowledge. While this field has seen recent progress, it remains an active area of exploration. This paper aims to provide a comprehensive and systematic review of FSCIL. In our in-depth examination, we delve into various facets of FSCIL, encompassing the problem definition, the discussion of primary challenges of unreliable empirical risk minimization and the stability-plasticity dilemma, general schemes, and relevant problems of incremental learning and few-shot learning. Besides, we offer an overview of benchmark datasets and evaluation metrics. Furthermore, we introduce the classification methods in FSCIL from data-based, structure-based, and optimization-based approaches and the object detection methods in FSCIL from anchor-free and anchor-based approaches. Beyond these, we illuminate several promising research directions within FSCIL that merit further investigation.
</details>
<details>
<summary>摘要</summary>
《几个示例学习（Few-shot Class-Incremental Learning，FSCIL）》是机器学习领域中的一个独特挑战，它需要在缺乏标注训练样本的情况下，不断学习新的类型，而不会忘记之前的知识。尽管这一领域在最近几年内已经取得了一些进展，但仍然是一个活跃的探索领域。本文的目标是提供一个全面和系统的FSCIL评审，包括问题定义、主要挑战的不可靠的实际风险最小化和稳定性-柔软性之间的矛盾、通用方案和相关的增量学习和几个示例学习的问题。此外，我们还介绍了评价指标和标准测试集。进而，我们介绍了FSCIL中的分类方法，包括数据基于、结构基于和优化基于的方法，以及对象检测方法，包括无锚和锚基的方法。此外，我们还逐光了一些在FSCIL中的有前途的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Discovering-the-Symptom-Patterns-of-COVID-19-from-Recovered-and-Deceased-Patients-Using-Apriori-Association-Rule-Mining"><a href="#Discovering-the-Symptom-Patterns-of-COVID-19-from-Recovered-and-Deceased-Patients-Using-Apriori-Association-Rule-Mining" class="headerlink" title="Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased Patients Using Apriori Association Rule Mining"></a>Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased Patients Using Apriori Association Rule Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06763">http://arxiv.org/abs/2308.06763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Dehghani, Zahra Yazdanparast, Mobin Mohammadi</li>
<li>for: 该研究用于挖掘COVID-19患者的症状模式，以帮助临床医生更好地诊断和治疗疾病。</li>
<li>methods: 该研究使用了Apriori算法进行协会规则挖掘，从COVID-19患者的临床数据中挖掘出最常见的症状。</li>
<li>results: 研究结果显示，COVID-19患者最常见的症状包括呼吸停止（72%）、咳嗽（64%）、发热（59%）、衰弱（18%）、肌肉疼痛（14.5%）和喉咙痛（12%）。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has a devastating impact globally, claiming millions of lives and causing significant social and economic disruptions. In order to optimize decision-making and allocate limited resources, it is essential to identify COVID-19 symptoms and determine the severity of each case. Machine learning algorithms offer a potent tool in the medical field, particularly in mining clinical datasets for useful information and guiding scientific decisions. Association rule mining is a machine learning technique for extracting hidden patterns from data. This paper presents an application of association rule mining based Apriori algorithm to discover symptom patterns from COVID-19 patients. The study, using 2875 records of patient, identified the most common symptoms as apnea (72%), cough (64%), fever (59%), weakness (18%), myalgia (14.5%), and sore throat (12%). The proposed method provides clinicians with valuable insight into disease that can assist them in managing and treating it effectively.
</details>
<details>
<summary>摘要</summary>
COVID-19 流行病在全球产生了毁灭性的影响，让数百万人丧生，引起了重大的社会和经济干扰。为了优化决策和分配有限的资源，必须识别 COVID-19 症状并评估每个病例的严重程度。机器学习算法在医疗领域中提供了一个强大的工具，特别是在挖掘医疗数据中找到有用信息和导引科学决策。在这篇文章中，我们使用 Apriori 算法进行协会规则挖掘，以找到 COVID-19 患者的症状模式。研究使用了 2875 份病例数据，发现最常见的症状包括呼吸抑制（72%）、咳嗽（64%）、高烧（59%）、衰弱（18%）、肌痛（14.5%）和喉咙痛（12%）。我们的方法可以帮助医生更好地理解这种疾病，从而更有效地诊治和治疗。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization"><a href="#Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization" class="headerlink" title="Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization"></a>Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06741">http://arxiv.org/abs/2308.06741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Mehdi Nasiri, Mansoor Rezghi</li>
<li>for: 这个研究旨在解决多智能机器人学习（Multi-Agent Reinforcement Learning，MARL）中参与者的不同能力和个人策略问题。</li>
<li>methods: 提案的Heterogeneous-Agent Mirror Descent Policy Optimization（HAMDPO）算法利用多智能机器人优势分解定理来实现每个代理策略的有效更新，并确保总性表现提高。HAMDPO通过迭代更新代理策略的近似解决信任区域问题，以确保稳定性和表现改善。</li>
<li>results: 在Multi-Agent MuJoCo和StarCraftII任务中，HAMDPO比state-of-the-art算法HATRPO和HAPPO表现出色，实现了稳定性和表现提高。这些结果显示HAMDPO是解决合作MARL问题的有望方法，可能会扩展到其他MARL领域中的挑战性问题。<details>
<summary>Abstract</summary>
This paper presents an extension of the Mirror Descent method to overcome challenges in cooperative Multi-Agent Reinforcement Learning (MARL) settings, where agents have varying abilities and individual policies. The proposed Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO) algorithm utilizes the multi-agent advantage decomposition lemma to enable efficient policy updates for each agent while ensuring overall performance improvements. By iteratively updating agent policies through an approximate solution of the trust-region problem, HAMDPO guarantees stability and improves performance. Moreover, the HAMDPO algorithm is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. We evaluate HAMDPO on Multi-Agent MuJoCo and StarCraftII tasks, demonstrating its superiority over state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.
</details>
<details>
<summary>摘要</summary>
The HAMDPO algorithm uses the multi-agent advantage decomposition lemma to efficiently update agent policies while ensuring overall performance improvements. The algorithm iteratively updates agent policies through an approximate solution of the trust-region problem, which guarantees stability and improves performance.HAMDPO is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. The authors evaluate the algorithm on Multi-Agent MuJoCo and StarCraftII tasks and show that it outperforms state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.
</details></li>
</ul>
<hr>
<h2 id="Weighted-Sparse-Partial-Least-Squares-for-Joint-Sample-and-Feature-Selection"><a href="#Weighted-Sparse-Partial-Least-Squares-for-Joint-Sample-and-Feature-Selection" class="headerlink" title="Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection"></a>Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06740">http://arxiv.org/abs/2308.06740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenwenmin/wspls">https://github.com/wenwenmin/wspls</a></li>
<li>paper_authors: Wenwen Min, Taosheng Xu, Chris Ding</li>
<li>for: 这种研究旨在扩展sPLS的应用范围，通过特定subset of samples和减少异常值来检测稀疏的数据集。</li>
<li>methods: 该研究提出了一种$\ell_\infty&#x2F;\ell_0$-norm压缩权重稀疏PLS（wsPLS）方法，通过$\ell_\infty&#x2F;\ell_0$-norm压缩来选择一个subset of samples，并使用多视图数据可以处理多个数据集。</li>
<li>results: 研究人员通过数值和生物医学数据实验表明，提出的方法可以减少数据维度，提高数据融合的稳定性和准确性。<details>
<summary>Abstract</summary>
Sparse Partial Least Squares (sPLS) is a common dimensionality reduction technique for data fusion, which projects data samples from two views by seeking linear combinations with a small number of variables with the maximum variance. However, sPLS extracts the combinations between two data sets with all data samples so that it cannot detect latent subsets of samples. To extend the application of sPLS by identifying a specific subset of samples and remove outliers, we propose an $\ell_\infty/\ell_0$-norm constrained weighted sparse PLS ($\ell_\infty/\ell_0$-wsPLS) method for joint sample and feature selection, where the $\ell_\infty/\ell_0$-norm constrains are used to select a subset of samples. We prove that the $\ell_\infty/\ell_0$-norm constrains have the Kurdyka-\L{ojasiewicz}~property so that a globally convergent algorithm is developed to solve it. Moreover, multi-view data with a same set of samples can be available in various real problems. To this end, we extend the $\ell_\infty/\ell_0$-wsPLS model and propose two multi-view wsPLS models for multi-view data fusion. We develop an efficient iterative algorithm for each multi-view wsPLS model and show its convergence property. As well as numerical and biomedical data experiments demonstrate the efficiency of the proposed methods.
</details>
<details>
<summary>摘要</summary>
“罕缺部分最小方差（sPLS）是一种常见的维度减少技术，用于数据融合，它通过寻找两个视图中数据样本的线性组合，以实现最大差异。然而，sPLS不能检测隐藏的样本集。为了扩展sPLS的应用，我们提出了一种$\ell_\infty/\ell_0$-norm受限的重量 sparse PLS（$\ell_\infty/\ell_0$-wsPLS）方法，用于联合样本和特征选择。我们证明了$\ell_\infty/\ell_0$-norm受限有 Kurdyka-\L{ojasiewicz} 性质，因此可以开发一个全球收敛的算法来解决它。此外，多视图数据中的样本可能是同一个集合的。为此，我们扩展了$\ell_\infty/\ell_0$-wsPLS模型，并提出了两种多视图wsPLS模型 для多视图数据融合。我们开发了一个高效的迭代算法，并证明其收敛性。数值和生物医学数据实验 demonstrate了我们提出的方法的效率。”Note: Simplified Chinese is a written form of Chinese that uses simpler characters and grammar than Traditional Chinese. It is commonly used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data"><a href="#Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data" class="headerlink" title="Probabilistic Imputation for Time-series Classification with Missing Data"></a>Probabilistic Imputation for Time-series Classification with Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06738">http://arxiv.org/abs/2308.06738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout">https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout</a></li>
<li>paper_authors: SeungHyun Kim, Hyunsu Kim, EungGu Yun, Hwangrae Lee, Jaehun Lee, Juho Lee</li>
<li>for: 这个论文主要是为了解决多重时间序列资料中的缺失价值问题。</li>
<li>methods: 我们提出了一个新的机会统计学 frameworks，它包括两个部分：一个深度生成模型来填写缺失价值，以及一个分类器。我们将深度生成模型扩展到更好地捕捉时间序列资料的结构，并将分类器训练为将时间序列资料与填写的缺失价值分类。</li>
<li>results: 我们通过实际实验表明，我们的方法可以有效地解决多重时间序列资料中的缺失价值问题，并且可以提供更好的预测结果。<details>
<summary>Abstract</summary>
Multivariate time series data for real-world applications typically contain a significant amount of missing values. The dominant approach for classification with such missing values is to impute them heuristically with specific values (zero, mean, values of adjacent time-steps) or learnable parameters. However, these simple strategies do not take the data generative process into account, and more importantly, do not effectively capture the uncertainty in prediction due to the multiple possibilities for the missing values. In this paper, we propose a novel probabilistic framework for classification with multivariate time series data with missing values. Our model consists of two parts; a deep generative model for missing value imputation and a classifier. Extending the existing deep generative models to better capture structures of time-series data, our deep generative model part is trained to impute the missing values in multiple plausible ways, effectively modeling the uncertainty of the imputation. The classifier part takes the time series data along with the imputed missing values and classifies signals, and is trained to capture the predictive uncertainty due to the multiple possibilities of imputations. Importantly, we show that na\"ively combining the generative model and the classifier could result in trivial solutions where the generative model does not produce meaningful imputations. To resolve this, we present a novel regularization technique that can promote the model to produce useful imputation values that help classification. Through extensive experiments on real-world time series data with missing values, we demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
多变量时间序列数据在实际应用中通常含有大量缺失值。现有的主流方法为这种缺失值是轮廓性地填充它们（零、平均值、邻近时间步颗度）或学习参数。然而，这些简单策略并不考虑数据生成过程，更重要的是，它们不能有效捕捉预测中的不确定性，因为缺失值的多种可能性。在这篇论文中，我们提出了一种新的概率 Framework for classification with multivariate time series data containing missing values.我们的模型包括两部分：深度生成模型和分类器。我们对深度生成模型进行了扩展，以更好地捕捉时间序列数据的结构，并训练它们以生成多种可能的缺失值，以模拟缺失值的uncertainty。分类器部分接受了时间序列数据以及填充后的缺失值，并分类信号，并训练它们以捕捉多种缺失值的预测不确定性。然而，我们发现，直接组合生成模型和分类器可能会导致轻微的解决方案，其中生成模型不会生成有用的填充值。为解决这个问题，我们提出了一种新的规范技术，可以促进模型生成有用的填充值，以便分类。通过对实际时间序列数据进行了广泛的实验，我们证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Precipitation-nowcasting-with-generative-diffusion-models"><a href="#Precipitation-nowcasting-with-generative-diffusion-models" class="headerlink" title="Precipitation nowcasting with generative diffusion models"></a>Precipitation nowcasting with generative diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06733">http://arxiv.org/abs/2308.06733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models">https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models</a></li>
<li>paper_authors: Andrea Asperti, Fabio Merizzi, Alberto Paparella, Giorgio Pedrazzi, Matteo Angelinelli, Stefano Colamonaco</li>
<li>For: 这个研究是用来测试深度学习方法在气象预报中的精度。* Methods: 这个研究使用了数种深度学习模型，包括生成模型、Variational Autoencoders和抑制算法。* Results: 研究发现，使用生成ensemble扩展（GED）模型可以对于降水预报提供更高的精度，比起现有的深度学习模型。<details>
<summary>Abstract</summary>
In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely prediction.   In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data pertaining to Central Europe from the years 2016 to 2021. Within this context, we examine the efficacy of diffusion models in handling the task of precipitation nowcasting. Our work is conducted in comparison to the performance of well-established U-Net models, as documented in the existing literature. Our proposed approach of Generative Ensemble Diffusion (GED) utilizes a diffusion model to generate a set of possible weather scenarios which are then amalgamated into a probable prediction via the use of a post-processing network. This approach, in comparison to recent deep learning models, substantially outperformed them in terms of overall performance.
</details>
<details>
<summary>摘要</summary>
Recently, traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Historical weather data used for short and medium-range forecasts are typically organized into a regular spatial grid structure, resembling images or videos when considering the temporal axis. Generative models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Denoising Diffusion Models (DDMs) have shown great potential in predicting the next frame of weather patterns. Diffusion models are particularly appealing in this context, as weather forecasting is inherently probabilistic and what we are really interested in modeling is the probability distribution of weather indicators.In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data for Central Europe from 2016 to 2021. We examine the efficacy of diffusion models in handling the task of precipitation nowcasting and compare their performance to well-established U-Net models. Our proposed approach, Generative Ensemble Diffusion (GED), utilizes a diffusion model to generate a set of possible weather scenarios, which are then combined into a probable prediction using a post-processing network. This approach outperforms recent deep learning models in terms of overall performance.
</details></li>
</ul>
<hr>
<h2 id="Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables"><a href="#Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables" class="headerlink" title="Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables"></a>Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06718">http://arxiv.org/abs/2308.06718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Xie, Biwei Huang, Zhengming Chen, Ruichu Cai, Clark Glymour, Zhi Geng, Kun Zhang</li>
<li>for: The paper is written for learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables.</li>
<li>methods: The paper proposes a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. The paper also provides necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models.</li>
<li>results: The paper shows that the proposed GIN condition, together with a well-designed search procedure, can be used to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. The paper also demonstrates the effectiveness of the proposed approach through experimental results.<details>
<summary>Abstract</summary>
We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:我们研究一个复杂的任务，即在存在隐变量的情况下学习 causal 结构，包括找到隐变量的位置和量，以及确定隐变量和观测变量之间的 causal 关系。为此，我们提出了一种 Generalized Independent Noise (GIN) 条件，用于 linear non-Gaussian 隐变量模型，该条件 garanties that a linear combination of certain observed variables and some other observed variables are independent. Specifically, for two observed random vectors $\mathbf{Y}$ and $\mathbf{Z}$, GIN holds if and only if $\omega^\top \mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then provide necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details></li>
</ul>
<hr>
<h2 id="Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards"><a href="#Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards" class="headerlink" title="Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards"></a>Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06717">http://arxiv.org/abs/2308.06717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilgin Dogan, Zuo-Jun Max Shen, Anil Aswani<br>for: This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal in a setting where the principal cannot observe the agent’s reward realizations.methods: The paper uses a multi-armed bandit (MAB) problem to model the agent’s learning and a parallel algorithm for the principal to consistently estimate the agent’s unknown rewards while maximizing their own utility.results: The paper proves finite-sample consistency of an estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent, and simulations justify the applicability of the framework to green energy aggregator contracts.<details>
<summary>Abstract</summary>
In practice, incentive providers (i.e., principals) often cannot observe the reward realizations of incentivized agents, which is in contrast to many principal-agent models that have been previously studied. This information asymmetry challenges the principal to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, which becomes even more challenging when the agent has to learn its own rewards. This complex setting is observed in various real-life scenarios ranging from renewable energy storage contracts to personalized healthcare incentives. Hence, it offers not only interesting theoretical questions but also wide practical relevance. This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal. The agent tackles a multi-armed bandit (MAB) problem to maximize their expected reward plus incentive. On top of the agent's learning, the principal trains a parallel algorithm and faces a trade-off between consistently estimating the agent's unknown rewards and maximizing their own utility by offering adaptive incentives to lead the agent. For a non-parametric model, we introduce an estimator whose only input is the history of principal's incentives and agent's choices. We unite this estimator with a proposed data-driven incentive policy within a MAB framework. Without restricting the type of the agent's algorithm, we prove finite-sample consistency of the estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent. Lastly, our theoretical results are reinforced by simulations justifying applicability of our framework to green energy aggregator contracts.
</details>
<details>
<summary>摘要</summary>
在实践中，奖励提供者（即主体）经常无法观察奖励的实现情况，这与许多主体-代理模型不同，这种信息不均衡会让主体难以透过决策来估计代理人的未知奖励，这变得更加复杂，当代理人需要学习自己的奖励时。这种复杂的设定在各种实际场景中出现，包括可再生能源存储合同和个性化医疗奖励。因此，它不仅存在许多理论问题，还有广泛的实际应用。本文研究了一个反复的对抗选择游戏，其中一个自利主义学习代理人与一个学习主体之间进行交互。代理人面临多支枪战（MAB）问题，以最大化他们的预期奖励加上奖励。除了代理人的学习之外，主体还需要训练一个平行算法，并面临一种奖励优化和代理人奖励的负担。为了不假设代理人的算法类型，我们提出了一种无参数的估计器，其唯一的输入是主体的奖励历史和代理人的选择。我们将这种估计器与一种基于MAB框架的数据驱动奖励策略联系起来。我们证明了这种估计器的finite-sample consistent性和对主体的正确做出约束。最后，我们通过实验证明了我们的框架在绿色能源总包合同中的应用可行性。
</details></li>
</ul>
<hr>
<h2 id="CDR-Conservative-Doubly-Robust-Learning-for-Debiased-Recommendation"><a href="#CDR-Conservative-Doubly-Robust-Learning-for-Debiased-Recommendation" class="headerlink" title="CDR: Conservative Doubly Robust Learning for Debiased Recommendation"></a>CDR: Conservative Doubly Robust Learning for Debiased Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08461">http://arxiv.org/abs/2308.08461</a></li>
<li>repo_url: None</li>
<li>paper_authors: ZiJie Song, JiaWei Chen, Sheng Zhou, QiHao Shi, Yan Feng, Chun Chen, Can Wang</li>
<li>for: 提高推荐系统中偏见的稳定性和性能</li>
<li>methods: 使用 Conservative Doubly Robust 策略（CDR），包括对填充值进行筛选和分析，以减少偏见的影响</li>
<li>results: 比较 experiments 表明，CDR 可以提高推荐系统的性能，同时减少偏见的频率<details>
<summary>Abstract</summary>
In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.   To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.
</details>
<details>
<summary>摘要</summary>
在推荐系统（RS）中，用户行为数据是观察性的而不是实验性的，导致数据中存在普遍的偏见。因此，解决偏见问题已成为推荐系统领域的主要挑战。近些年来，双重稳健学习（DR）已经受到了广泛关注，因为它的表现良好和稳健性。然而，我们的实验结果表明，现有的DR方法受到 socalled "poisonous imputation" 的影响，其中的填充数据显著不符合事实，甚至变得counterproductive。为解决这个问题，本工作提出了 Conservative Doubly Robust 策略（CDR），该策略通过评估填充数据的mean和variance来筛选填充。理论分析表明，CDR可以降低方差和提高尾 bounds。此外，我们的实验研究表明，CDR可以显著提高性能，并可以减少poisonous imputation的频率。
</details></li>
</ul>
<hr>
<h2 id="Learning-on-Graphs-with-Out-of-Distribution-Nodes"><a href="#Learning-on-Graphs-with-Out-of-Distribution-Nodes" class="headerlink" title="Learning on Graphs with Out-of-Distribution Nodes"></a>Learning on Graphs with Out-of-Distribution Nodes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06714">http://arxiv.org/abs/2308.06714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/songyyyy/kdd22-oodgat">https://github.com/songyyyy/kdd22-oodgat</a></li>
<li>paper_authors: Yu Song, Donglin Wang</li>
<li>for: 本文旨在Addressing the problem of graph learning with out-of-distribution nodes, including detecting nodes that do not belong to the known distribution and classifying the remaining nodes to be one of the known classes.</li>
<li>methods: 本文提出了一种新的Graph Attention Network（GAT）模型，即Out-of-Distribution Graph Attention Network（OODGAT），该模型可以Explicitly model the interaction between different kinds of nodes and separate inliers from outliers during feature propagation.</li>
<li>results: 实验表明，OODGAT比现有的异常检测方法表现出较大的优势，同时与现有的分类方法相比，OODGAT的分类性能也是比较良好的。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model which explicitly models the interaction between different kinds of nodes and separate inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
</details>
<details>
<summary>摘要</summary>
图ael Neural Networks (GNNs) 是当前最佳模型 для图ael任务中的预测模型。 Although existing GNNs have shown great performance on various graph-related tasks, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Based on the concept from CV and NLP, we define OOD nodes as nodes with labels not seen in the training set. Since many networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes that do not belong to the known distribution and 2) classify the remaining nodes as one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model that explicitly models the interaction between different types of nodes and separates inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
</details></li>
</ul>
<hr>
<h2 id="The-Hard-Constraint-PINNs-for-Interface-Optimal-Control-Problems"><a href="#The-Hard-Constraint-PINNs-for-Interface-Optimal-Control-Problems" class="headerlink" title="The Hard-Constraint PINNs for Interface Optimal Control Problems"></a>The Hard-Constraint PINNs for Interface Optimal Control Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06709">http://arxiv.org/abs/2308.06709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tianyouzeng/pinns-interface-optimal-control">https://github.com/tianyouzeng/pinns-interface-optimal-control</a></li>
<li>paper_authors: Ming-Chih Lai, Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng</li>
<li>for:  solves optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints.</li>
<li>methods:  combines physics-informed neural networks (PINNs) with recently developed discontinuity capturing neural networks to solve the problems.</li>
<li>results:  guarantees that both the boundary and interface conditions can be satisfied exactly, and is efficient for elliptic and parabolic interface optimal control problems.Here’s the full summary in Simplified Chinese:</li>
<li>for:  solves optimal control problems subject to PDEs with interfaces and control constraints.</li>
<li>methods:  combines PINNs with discontinuity capturing neural networks.</li>
<li>results:  guarantees exact satisfaction of boundary and interface conditions, and is efficient for elliptic and parabolic interface optimal control problems.<details>
<summary>Abstract</summary>
We show that the physics-informed neural networks (PINNs), in combination with some recently developed discontinuity capturing neural networks, can be applied to solve optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints. The resulting algorithm is mesh-free and scalable to different PDEs, and it ensures the control constraints rigorously. Since the boundary and interface conditions, as well as the PDEs, are all treated as soft constraints by lumping them into a weighted loss function, it is necessary to learn them simultaneously and there is no guarantee that the boundary and interface conditions can be satisfied exactly. This immediately causes difficulties in tuning the weights in the corresponding loss function and training the neural networks. To tackle these difficulties and guarantee the numerical accuracy, we propose to impose the boundary and interface conditions as hard constraints in PINNs by developing a novel neural network architecture. The resulting hard-constraint PINNs approach guarantees that both the boundary and interface conditions can be satisfied exactly and they are decoupled from the learning of the PDEs. Its efficiency is promisingly validated by some elliptic and parabolic interface optimal control problems.
</details>
<details>
<summary>摘要</summary>
我们显示了物理学 Informed Neural Networks (PINNs) 可以与最近发展的破碎点捕捉神经网络 (DCNNs) 结合，以解决具有界面和一些控制约束的最佳控制问题。这个算法是无网格的和可扩展的，并且保证控制约束的严格性。由于边界和界面条件，以及PDEs，都是软的约束，因此需要同时学习它们，并且没有保证边界和界面条件可以精确地满足。这会导致调整约束的预测条件和神经网络训练中的困难。为了解决这些困难并保证数值精度，我们提出了将边界和界面条件作为硬的约束在PINNs中，通过开发一种新的神经网络架构。这种硬约束PINNs方法可以保证边界和界面条件可以精确地满足，并且与PDEs的学习分离开来。我们在一些椭圆和带形interface最佳控制问题中调查了这种方法的效率，并证明了其可靠性。
</details></li>
</ul>
<hr>
<h2 id="Generating-observation-guided-ensembles-for-data-assimilation-with-denoising-diffusion-probabilistic-model"><a href="#Generating-observation-guided-ensembles-for-data-assimilation-with-denoising-diffusion-probabilistic-model" class="headerlink" title="Generating observation guided ensembles for data assimilation with denoising diffusion probabilistic model"></a>Generating observation guided ensembles for data assimilation with denoising diffusion probabilistic model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06708">http://arxiv.org/abs/2308.06708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yasahi-hpc/generative-enkf">https://github.com/yasahi-hpc/generative-enkf</a></li>
<li>paper_authors: Yuuichi Asahi, Yuta Hasegawa, Naoyuki Onodera, Takashi Shimokawabe, Hayato Shiba, Yasuhiro Idomura</li>
<li>for: 这 paper 用于 ensemble data assimilation，使用 pseudo ensemble 生成的 denoising diffusion  probabilistic model。</li>
<li>methods: 该方法使用模型对含杂和罕见观测数据进行训练，生成多个不同的 Ensemble，并利用这些 Ensemble 的差异来进行数据融合。</li>
<li>results: 比较 conventional ensemble data assimilation 方法，这种方法在模型不完善时显示出更好的性能。<details>
<summary>Abstract</summary>
This paper presents an ensemble data assimilation method using the pseudo ensembles generated by denoising diffusion probabilistic model. Since the model is trained against noisy and sparse observation data, this model can produce divergent ensembles close to observations. Thanks to the variance in generated ensembles, our proposed method displays better performance than the well-established ensemble data assimilation method when the simulation model is imperfect.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种ensemble数据融合方法，使用pseudo ensemble生成于噪声扩散概率模型。由于模型对噪声和稀缺观测数据进行训练，因此这个模型可以生成与观测数据相近的多个分布。由于这些生成的分布之间的差异，我们提议的方法在模型不完美时表现更好 than traditional ensemble数据融合方法。Note: "pseudo ensemble" in Chinese is "假集合" (fǎ jiéhù), and "denoising diffusion probabilistic model" in Chinese is "噪声扩散概率模型" (zāi shēng kuò shiān yù jì mó delè).
</details></li>
</ul>
<hr>
<h2 id="Understanding-the-robustness-difference-between-stochastic-gradient-descent-and-adaptive-gradient-methods"><a href="#Understanding-the-robustness-difference-between-stochastic-gradient-descent-and-adaptive-gradient-methods" class="headerlink" title="Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods"></a>Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06703">http://arxiv.org/abs/2308.06703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avery Ma, Yangchen Pan, Amir-massoud Farahmand</li>
<li>for: 论述了使用权重更新法（SGD）和自适应梯度方法（Adam、RMSProp）训练深度神经网络的研究。</li>
<li>methods: 使用SGD和自适应梯度方法训练深度神经网络。</li>
<li>results: 对于自然数据集，SGD训练的模型对输入扰动 exhibit 较好的Robustness，而使用自适应梯度方法训练的模型则对于这些扰动 exhibit 较差的Robustness。这种差异可以通过学习动态研究和synthetic dataset的实验来解释。<details>
<summary>Abstract</summary>
Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risks close to zero but vary in their adversarial risks. Our result shows that linear models' robustness to $\ell_2$-norm bounded changes is inversely proportional to the model parameters' weight norm: a smaller weight norm implies better robustness. In the context of deep learning, our experiments show that SGD-trained neural networks show smaller Lipschitz constants, explaining the better robustness to input perturbations than those trained with adaptive gradient methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection"><a href="#Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection" class="headerlink" title="Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection"></a>Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06701">http://arxiv.org/abs/2308.06701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haichao Zhang, Can Qin, Yu Yin, Yun Fu</li>
<li>for: 提高深度学习模型对涂抹式对象检测的能力</li>
<li>methods: 使用生成模型生成涂抹式图像，以增强现有对象检测模型的识别能力</li>
<li>results: 比现有方法高效，在COD10k、CAMO和CHAMELEON三个数据集上达到了更高的检测精度<details>
<summary>Abstract</summary>
Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-and-play data generation and augmentation module for existing camouflaged object detection tasks and provides a novel way to introduce more diversity and distributions into current camouflage datasets.
</details>
<details>
<summary>摘要</summary>
伪装物体在自然场景中混合很困难对深度学习模型进行检测和生成。隐身物体检测是计算机视觉中重要的任务，它在各种实际应用中具有广泛的意义。然而，这一研究领域受到有限的数据可用性的限制。我们提出了一种框架，用于增强自然场景中隐身物体的检测。我们的方法使用生成模型生成真实的伪装图像，这些图像可以用来训练现有的物体检测模型。具体来说，我们使用一个伪装环境生成器，该生成器被监督于伪装分布分类器，以生成伪装图像。这些图像然后被我们的生成器扩展，以增加数据集。我们的框架在COD10k、CAMO和CHAMELEON三个数据集上表现出色，超越当前状态的方法，证明了我们的方法的有效性。这种方法可以作为现有隐身物体检测任务的数据生成和增强模块，并提供一种新的多样性和分布引入现有的伪装数据集的方法。
</details></li>
</ul>
<hr>
<h2 id="SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency"><a href="#SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency" class="headerlink" title="SimMatchV2: Semi-Supervised Learning with Graph Consistency"></a>SimMatchV2: Semi-Supervised Learning with Graph Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06692">http://arxiv.org/abs/2308.06692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingkai-zheng/simmatchv2">https://github.com/mingkai-zheng/simmatchv2</a></li>
<li>paper_authors: Mingkai Zheng, Shan You, Lang Huang, Chen Luo, Fei Wang, Chen Qian, Chang Xu</li>
<li>for: 这个研究目的是为了提出一个新的半supervised learning算法，以减少人工劳动。</li>
<li>methods: 这个算法叫做SimMatchV2，它利用图论的观点来设计了多种一致规律，以确保labeled和unlabeled数据之间的一致性。</li>
<li>results: 这个算法在多个半supervised learningbenchmark上进行验证，以300次训练和ResNet-50底层，SimMatchV2在ImageNet上得到71.9%和76.2%的Top-1准确率，优于之前的方法，并达到了现有的最佳性能。<details>
<summary>Abstract</summary>
Semi-Supervised image classification is one of the most fundamental problem in computer vision, which significantly reduces the need for human labor. In this paper, we introduce a new semi-supervised learning algorithm - SimMatchV2, which formulates various consistency regularizations between labeled and unlabeled data from the graph perspective. In SimMatchV2, we regard the augmented view of a sample as a node, which consists of a label and its corresponding representation. Different nodes are connected with the edges, which are measured by the similarity of the node representations. Inspired by the message passing and node classification in graph theory, we propose four types of consistencies, namely 1) node-node consistency, 2) node-edge consistency, 3) edge-edge consistency, and 4) edge-node consistency. We also uncover that a simple feature normalization can reduce the gaps of the feature norm between different augmented views, significantly improving the performance of SimMatchV2. Our SimMatchV2 has been validated on multiple semi-supervised learning benchmarks. Notably, with ResNet-50 as our backbone and 300 epochs of training, SimMatchV2 achieves 71.9\% and 76.2\% Top-1 Accuracy with 1\% and 10\% labeled examples on ImageNet, which significantly outperforms the previous methods and achieves state-of-the-art performance. Code and pre-trained models are available at \href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2}.
</details>
<details>
<summary>摘要</summary>
《半指导Image Classification》是计算机视觉中的一个基本问题，它可以减少人工劳动量。在这篇论文中，我们介绍了一种新的半指导学习算法——SimMatchV2，它在图像视角下划定了不同类别的样本。在SimMatchV2中，我们将每个样本视为一个节点，每个节点有一个标签和对应的表示。不同的节点之间连接了边，边的 Similarity 度量节点表示之间的相似性。我们还提出了四种一致性，即1）节点-节点一致性，2）节点-边一致性，3）边-边一致性，4）边-节点一致性。我们还发现了一种简单的特征归一化可以减少不同扩展视图之间的特征范围差异，从而显著提高SimMatchV2的性能。我们的SimMatchV2在多个半指导学习标准benchmark上进行验证，与ResNet-50作为背景和300个训练周期，SimMatchV2在ImageNet上 achieve 71.9%和76.2%的Top-1准确率，与先前的方法相比显著超越，实现了状态的最佳性能。代码和预训练模型可以在 <https://github.com/mingkai-zheng/SimMatchV2> 中获取。
</details></li>
</ul>
<hr>
<h2 id="MDB-Interactively-Querying-Datasets-and-Models"><a href="#MDB-Interactively-Querying-Datasets-and-Models" class="headerlink" title="MDB: Interactively Querying Datasets and Models"></a>MDB: Interactively Querying Datasets and Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06686">http://arxiv.org/abs/2308.06686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaditya Naik, Adam Stein, Yinjun Wu, Eric Wong, Mayur Naik</li>
<li>for: 这篇论文是为了提供一个Debugging框架，帮助开发者在机器学习管道中系统地调试错误。</li>
<li>methods: 这篇论文使用了函数编程和关系代数来构建表达式查询数据集和模型预测。查询可重用和轻松修改，帮助调试员快速缩小查询错误和模型行为。</li>
<li>results:  experiments show that MDB可以提供更快（10倍）和更短（40%）的查询，并且在用户研究中，开发者可以成功构建复杂的查询来描述机器学习模型的错误。<details>
<summary>Abstract</summary>
As models are trained and deployed, developers need to be able to systematically debug errors that emerge in the machine learning pipeline. We present MDB, a debugging framework for interactively querying datasets and models. MDB integrates functional programming with relational algebra to build expressive queries over a database of datasets and model predictions. Queries are reusable and easily modified, enabling debuggers to rapidly iterate and refine queries to discover and characterize errors and model behaviors. We evaluate MDB on object detection, bias discovery, image classification, and data imputation tasks across self-driving videos, large language models, and medical records. Our experiments show that MDB enables up to 10x faster and 40\% shorter queries than other baselines. In a user study, we find developers can successfully construct complex queries that describe errors of machine learning models.
</details>
<details>
<summary>摘要</summary>
models 是在训练和部署过程中，开发人员需要系统地调试出现在机器学习管道中的错误。我们提出了 MDB，一个用于交互查询数据集和模型的调试框架。MDB将函数编程与关系代数结合，以构建表达式查询数据库中的数据集和模型预测。查询可重复使用，易于修改，让调试者可以快速灵活地 iteratively 修改查询，以描述和揭示错误和模型行为。我们在对自动驾驶视频、大语言模型和医疗记录进行对象检测、偏见发现、图像分类和数据补充任务上进行了实验，发现 MDB 可以提高查询速度和查询长度，相比于其他基eline。在用户研究中，我们发现开发人员可以成功地构建复杂的查询，以描述机器学习模型的错误。
</details></li>
</ul>
<hr>
<h2 id="Separable-Gaussian-Neural-Networks-Structure-Analysis-and-Function-Approximations"><a href="#Separable-Gaussian-Neural-Networks-Structure-Analysis-and-Function-Approximations" class="headerlink" title="Separable Gaussian Neural Networks: Structure, Analysis, and Function Approximations"></a>Separable Gaussian Neural Networks: Structure, Analysis, and Function Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06679">http://arxiv.org/abs/2308.06679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyuan Xing, Jianqiao Sun</li>
<li>For: 这个论文想要解决高维输入数据的快速 interpolate和分类问题，提出了一种新的前向网络模型 - 分解 Gaussian 神经网络（SGNN）。* Methods: SGNN 利用 Gaussian 函数的分解性，将输入数据分割成多列，然后在并行层中进行批量处理，从而将计算量从 GRBFNN 的 O(N^d) 减少到 O(dN)，速度增长 linear 地。* Results: 实验表明，SGNN 可以与 GRBFNN 相比，在 tri-variate 函数近似中实现 100 倍的速度提升，并且保持 GRBFNN 的级别准确性。 SGNN 还比 DNNs  WITH RuLU 和 Sigmoid 函数更易于训练和调整。 在approximating 函数 WITH complex geometry 时，SGNN 可以达到三个数量级更高的准确性。<details>
<summary>Abstract</summary>
The Gaussian-radial-basis function neural network (GRBFNN) has been a popular choice for interpolation and classification. However, it is computationally intensive when the dimension of the input vector is high. To address this issue, we propose a new feedforward network - Separable Gaussian Neural Network (SGNN) by taking advantage of the separable property of Gaussian functions, which splits input data into multiple columns and sequentially feeds them into parallel layers formed by uni-variate Gaussian functions. This structure reduces the number of neurons from O(N^d) of GRBFNN to O(dN), which exponentially improves the computational speed of SGNN and makes it scale linearly as the input dimension increases. In addition, SGNN can preserve the dominant subspace of the Hessian matrix of GRBFNN in gradient descent training, leading to a similar level of accuracy to GRBFNN. It is experimentally demonstrated that SGNN can achieve 100 times speedup with a similar level of accuracy over GRBFNN on tri-variate function approximations. The SGNN also has better trainability and is more tuning-friendly than DNNs with RuLU and Sigmoid functions. For approximating functions with complex geometry, SGNN can lead to three orders of magnitude more accurate results than a RuLU-DNN with twice the number of layers and the number of neurons per layer.
</details>
<details>
<summary>摘要</summary>
Gaussian-radial-basis函数神经网络（GRBFNN）已经是选择 interpolation和分类的受欢迎选择。然而，当输入向量维度高时，它会占用大量计算资源。为解决这个问题，我们提出了一个新的前向网络——分解 Gaussian 神经网络（SGNN），利用 Gaussian 函数的分解性，将输入数据分解成多列，然后将它们顺序输入到由单variate Gaussian 函数组成的并行层中。这种结构将 GRBFNN 中的 neuron 数由 O(N^d) 降低到 O(dN)，从而 exponential 提高 SGNN 的计算速度，使其与输入维度增加时呈线性增长。此外，SGNN 还可以保留 GRBFNN 的主要子空间，从而在梯度下降训练中达到类似精度水平。实验表明，SGNN 可以在 tri-variate 函数拟合中实现 100 倍的速度提升，同时保持精度水平。此外，SGNN 还比 DNNs  WITH RuLU 和 sigmoid 函数更易于训练和调整。对于拟合复杂几何函数的情况，SGNN 可以 achieve 三个排名的精度提升。
</details></li>
</ul>
<hr>
<h2 id="A-deep-learning-framework-for-multi-scale-models-based-on-physics-informed-neural-networks"><a href="#A-deep-learning-framework-for-multi-scale-models-based-on-physics-informed-neural-networks" class="headerlink" title="A deep learning framework for multi-scale models based on physics-informed neural networks"></a>A deep learning framework for multi-scale models based on physics-informed neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06672">http://arxiv.org/abs/2308.06672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong Wang, Yanzhong Yao, Jiawei Guo, Zhiming Gao</li>
<li>for: 解决多级别问题（multi-scale problems）</li>
<li>methods: 基于深度神经网络（deep neural networks）和解决partial differential equations（PDEs）的physics-informed neural networks（PINN）方法</li>
<li>results: 提出了一种新的框架，可以同时优化多级别的损失项，并且可以处理不同子域的问题变化。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINN) combine deep neural networks with the solution of partial differential equations (PDEs), creating a new and promising research area for numerically solving PDEs. Faced with a class of multi-scale problems that include loss terms of different orders of magnitude in the loss function, it is challenging for standard PINN methods to obtain an available prediction. In this paper, we propose a new framework for solving multi-scale problems by reconstructing the loss function. The framework is based on the standard PINN method, and it modifies the loss function of the standard PINN method by applying different numbers of power operations to the loss terms of different magnitudes, so that the individual loss terms composing the loss function have approximately the same order of magnitude among themselves. In addition, we give a grouping regularization strategy, and this strategy can deal well with the problem which varies significantly in different subdomains. The proposed method enables loss terms with different magnitudes to be optimized simultaneously, and it advances the application of PINN for multi-scale problems.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks (PINN) combine deep neural networks with partial differential equations (PDEs) 的解决方法，创造了一个新的研究领域，用于数值解决 PDEs。面临多个层次问题，其中loss函数中的损失项有不同的级别，标准的PINN方法难以获得可用的预测。在这篇论文中，我们提出了一种新的多层次问题解决框架。这种框架基于标准的PINN方法，对loss函数中的各个损失项应用不同的数量的power操作，使得各个损失项的级别相对较同。此外，我们提出了一种分组常见化策略，该策略可以处理不同子领域中变化很大的问题。提出的方法可以同时优化不同级别的损失项，并提高PINN在多层次问题上的应用。
</details></li>
</ul>
<hr>
<h2 id="Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent"><a href="#Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent" class="headerlink" title="Law of Balance and Stationary Distribution of Stochastic Gradient Descent"></a>Law of Balance and Stationary Distribution of Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06671">http://arxiv.org/abs/2308.06671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Ziyin, Hongchao Li, Masahito Ueda</li>
<li>for: This paper aims to understand how the stochastic gradient descent (SGD) algorithm navigates the highly nonlinear and degenerate loss landscape of a neural network.</li>
<li>methods: The paper uses theoretical analysis to prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry.</li>
<li>results: The paper derives the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width, and shows that the stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion, which are unique to deep networks.Here is the answer in Simplified Chinese text:</li>
<li>for: 这篇论文目标是理解权重梯度下降（SGD）算法在神经网络的高非线性和平衡梯度图像中的探索。</li>
<li>methods: 论文使用理论分析，证明SGD中批处理噪声对于包含扩缩尺度Symmetry的损失函数的解决方法。</li>
<li>results: 论文Derive diagonally linear network with arbitrary depth and width的stationary distribution of stochastic gradient flow，并显示其站立分布具有复杂非线性现象，如相转变、破碎Ergodicity和振荡反转，这些现象只存在于深度很大的网络中。<details>
<summary>Abstract</summary>
The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundamental difference between deep and shallow models.
</details>
<details>
<summary>摘要</summary>
SGD算法是我们用来训练神经网络的算法，但是它在神经网络的高度非线性和缺乏稳定性的损失函数空间中 navigation 仍然不够了解。在这个工作中，我们证明了SGD中的小批量噪声规范化解决方案，当损失函数具有扩展对称性时。由于噪声和SGD动力学的差异最大化在对称性存在时，我们的理论 imply 损失函数对称性是SGD工作的重要探测器。我们然后使用这结果来 derive 神经网络的站点分布，并证明了深度神经网络存在复杂非线性现象，如相对稳定性、破坏性和异常倒振。这些现象仅存在深度神经网络中，表明深度和浅度模型之间存在根本的差异。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges"><a href="#Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges" class="headerlink" title="Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges"></a>Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06668">http://arxiv.org/abs/2308.06668</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiajiali04/agriculture-foundation-models">https://github.com/jiajiali04/agriculture-foundation-models</a></li>
<li>paper_authors: Jiajia Li, Mingle Xu, Lirong Xiang, Dong Chen, Weichao Zhuang, Xunyuan Yin, Zhaojian Li</li>
<li>for: 本研究旨在探讨基于machine learning和deep learning的智能农业领域中的应用Foundation Model（FM）。</li>
<li>methods: 本研究首先对现代计算机科学领域的FM进行了综述，并将其分为四类：语言FM、视觉FM、多模态FM和奖励学习FM。然后，我们详细介绍了在农业领域开发农业FM的过程，并讨论了其在智能农业中的潜在应用。</li>
<li>results: 本研究通过引入基于FM的应用方法，可以减少农业AI系统的依赖于大量标注数据，提高效率、有效性和通用性。此外，本研究还提出了开发农业FM的一些挑战，包括模型训练、验证和部署。<details>
<summary>Abstract</summary>
The past decade has witnessed the rapid development of ML and DL methodologies in agricultural systems, showcased by great successes in variety of agricultural applications. However, these conventional ML/DL models have certain limitations: They heavily rely on large, costly-to-acquire labeled datasets for training, require specialized expertise for development and maintenance, and are mostly tailored for specific tasks, thus lacking generalizability. Recently, foundation models have demonstrated remarkable successes in language and vision tasks across various domains. These models are trained on a vast amount of data from multiple domains and modalities. Once trained, they can accomplish versatile tasks with just minor fine-tuning and minimal task-specific labeled data. Despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture fields. Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, we present conceptual tools and technical background to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, we first review recent FMs in the general computer science domain and categorize them into four categories: language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs. Subsequently, we outline the process of developing agriculture FMs and discuss their potential applications in smart agriculture. We also discuss the unique challenges associated with developing AFMs, including model training, validation, and deployment. Through this study, we contribute to the advancement of AI in agriculture by introducing AFMs as a promising paradigm that can significantly mitigate the reliance on extensive labeled datasets and enhance the efficiency, effectiveness, and generalization of agricultural AI systems.
</details>
<details>
<summary>摘要</summary>
过去一代，机器学习（ML）和深度学习（DL）方法在农业系统中得到了迅速发展，在多种农业应用中显示出了很大成功。然而，这些传统的ML/DL模型具有一些限制：它们需要大量、昂贵的标签数据进行训练，需要专门的专业知识进行开发和维护，而且主要是为特定任务设计，因此缺乏普适性。在最近的几年里，基础模型（FM）在语言和视觉任务中获得了惊人的成功。这些模型通过大量的数据来自多个领域和模式进行训练，一旦训练完成，就可以完成多种任务，只需要微小的调整和微小的任务特定的标签数据。尽管它们的可效性和潜在的潜力很大，但在农业领域中还没有多少探索基础模型的应用。因此，本研究旨在探讨基础模型在智能农业领域的潜力。具体来说，我们首先将最近的FM在通用计算机科学领域中进行了综述，并将其分为四类：语言FM、视觉FM、多模式FM和奖励学习FM。然后，我们详细介绍了在农业领域开发农业FM的过程，并讨论了它们在智能农业中的潜在应用。我们还讨论了开发AFM的独特挑战，包括模型训练、验证和部署。通过本研究，我们为农业AI的发展做出了贡献，将基础模型作为一种可能的解决方案，可以减少农业AI系统的依赖于大量标签数据，提高效率、有效性和普适性。
</details></li>
</ul>
<hr>
<h2 id="ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN"><a href="#ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN" class="headerlink" title="ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN"></a>ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06663">http://arxiv.org/abs/2308.06663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Abul Bashar, Richi Nayak</li>
<li>For: Anomaly detection in time series data, specifically in univariate and multivariate datasets in an unsupervised setting.* Methods: Proposes a new GAN model called Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection accuracy.* Results: Outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data, as demonstrated through experiments on 46 real-world univariate time series datasets and a large multivariate dataset.<details>
<summary>Abstract</summary>
Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data.
</details>
<details>
<summary>摘要</summary>
<<SYS>>时间序列数据中异常检测，以识别不同于常规行为的点，是多个领域中的一个常见问题，包括制造、医疗影像和网络安全等。最近，生成对抗网络（GANs）在时间序列数据中的异常检测中表现出色。GANs的神经网络架构（即生成器和识别器）可以显著提高异常检测精度。在本文中，我们提出了一种新的GAN模型，名为调整LSTM GAN（ALGAN），该模型可以在无监督的情况下，对单变量和多变量时间序列数据进行改进的异常检测。我们对46个真实的单变量时间序列数据集和多个领域的大量多变量数据集进行了试验，结果表明，ALGAN比传统的神经网络基于的方法、神经网络GAN方法和其他GAN方法在时间序列数据中的异常检测方面表现出色。Note: "LSTM" stands for Long Short-Term Memory, which is a type of Recurrent Neural Network (RNN) designed to handle time series data.
</details></li>
</ul>
<hr>
<h2 id="Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features"><a href="#Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features" class="headerlink" title="Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features"></a>Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08482">http://arxiv.org/abs/2308.08482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yiiizhang/shortcutDebiasing">https://github.com/yiiizhang/shortcutDebiasing</a></li>
<li>paper_authors: Yi Zhang, Jitao Sang, Junyang Wang, Dongmei Jiang, Yaowei Wang</li>
<li>for: 降低机器学习模型中的偏见风险，特别是在社会应用中，如雇用、银行和刑事司法等。</li>
<li>methods: 我们提出了一种简洁处理方法，称为“快捷偏见处理”（Shortcut Debiasing），它首先将偏见特征 transferred to快捷特征，然后使用 causal intervention 把快捷特征 eliminated during inference。</li>
<li>results: 我们将此方法应用到多个 benchmark 数据集上，并与现有的偏见处理方法进行比较，获得了显著的改善。<details>
<summary>Abstract</summary>
Machine learning models often learn to make predictions that rely on sensitive social attributes like gender and race, which poses significant fairness risks, especially in societal applications, such as hiring, banking, and criminal justice. Existing work tackles this issue by minimizing the employed information about social attributes in models for debiasing. However, the high correlation between target task and these social attributes makes learning on the target task incompatible with debiasing. Given that model bias arises due to the learning of bias features (\emph{i.e}., gender) that help target task optimization, we explore the following research question: \emph{Can we leverage shortcut features to replace the role of bias feature in target task optimization for debiasing?} To this end, we propose \emph{Shortcut Debiasing}, to first transfer the target task's learning of bias attributes from bias features to shortcut features, and then employ causal intervention to eliminate shortcut features during inference. The key idea of \emph{Shortcut Debiasing} is to design controllable shortcut features to on one hand replace bias features in contributing to the target task during the training stage, and on the other hand be easily removed by intervention during the inference stage. This guarantees the learning of the target task does not hinder the elimination of bias features. We apply \emph{Shortcut Debiasing} to several benchmark datasets, and achieve significant improvements over the state-of-the-art debiasing methods in both accuracy and fairness.
</details>
<details>
<summary>摘要</summary>
机器学习模型经常学习依赖敏感社会特征如性别和种族的预测，这会带来公平风险，特别是在社会应用中，如招聘、银行和刑事司法。现有的工作解决这个问题，是通过减少模型使用的社会特征来减少模型的偏见。然而，目标任务和社会特征之间的高相关性使得学习目标任务与减少偏见不兼容。基于模型偏见来自偏见特征（例如性别）的学习，我们提出了以下研究问题：“可以通过剪辑特征来替代偏见特征的角色来优化目标任务吗？”为此，我们提出了短Circuit Debiasing，即在训练阶段通过将目标任务学习的偏见特征转移到剪辑特征上，然后通过 causal intervention 在推理阶段消除剪辑特征。短Circuit Debiasing 的关键思想是设计可控的剪辑特征，以便在训练阶段替代偏见特征，并在推理阶段通过 intervention 轻松消除。这 garantizes 学习目标任务不会阻碍减少偏见。我们在多个标准数据集上应用短Circuit Debiasing，并在准确率和公平性两个方面获得了 significan 的改进。
</details></li>
</ul>
<hr>
<h2 id="Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks"><a href="#Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks" class="headerlink" title="Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks"></a>Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06654">http://arxiv.org/abs/2308.06654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: 预测行人轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与行人共享空间时。行人运动在共享空间中受到车辆和其他行人的影响，因此可以更好地模型行人-车辆和行人-行人交互，从而提高行人轨迹预测模型的准确性。</li>
<li>methods: 我们提出了一种基于启发的交互代理选择过程，利用碰撞风险计算来选择交互代理。我们关注与可能碰撞的代理之间的时间到碰撞和接近方向的影响，并通过引入一种新的极地增量增量Grid Map来编码交互效果。</li>
<li>results: 我们的结果表明，使用我们提出的方法可以比基eline方法（作为参考）在HBS数据集上预测轨迹更加准确。<details>
<summary>Abstract</summary>
Predicting pedestrians' trajectories is a crucial capability for autonomous vehicles' safe navigation, especially in spaces shared with pedestrians. Pedestrian motion in shared spaces is influenced by both the presence of vehicles and other pedestrians. Therefore, effectively modelling both pedestrian-pedestrian and pedestrian-vehicle interactions can increase the accuracy of the pedestrian trajectory prediction models. Despite the huge literature on ways to encode the effect of interacting agents on a pedestrian's predicted trajectory using deep-learning models, limited effort has been put into the effective selection of interacting agents. In the majority of cases, the interaction features used are mainly based on relative distances while paying less attention to the effect of the velocity and approaching direction in the interaction formulation. In this paper, we propose a heuristic-based process of selecting the interacting agents based on collision risk calculation. Focusing on interactions of potentially colliding agents with a target pedestrian, we propose the use of time-to-collision and the approach direction angle of two agents for encoding the interaction effect. This is done by introducing a novel polar collision grid map. Our results have shown predicted trajectories closer to the ground truth compared to existing methods (used as a baseline) on the HBS dataset.
</details>
<details>
<summary>摘要</summary>
预测行人轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与行人共享空间时。行人运动在共享空间中受到车辆和其他行人的影响。因此，可以准确地模拟行人与车辆和其他行人之间的互动，可以提高行人轨迹预测模型的准确性。Despite the extensive literature on using deep-learning models to encode the effect of interacting agents on a pedestrian's predicted trajectory, there has been limited effort put into selecting the interacting agents effectively. Most existing methods use relative distance as the main factor in the interaction formulation, while ignoring the effect of velocity and approaching direction.在这篇论文中，我们提出了一种基于启发的互动代理选择过程，通过计算碰撞风险来选择互动代理。我们将注意力集中在可能碰撞的代理与目标行人之间的互动效应上，并通过引入一种新的极地碰撞格图来编码这种互动效应。我们的结果表明，与基eline方法相比，我们的方法可以在HBS数据集上预测轨迹更加准确。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation"><a href="#Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation" class="headerlink" title="Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation"></a>Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06644">http://arxiv.org/abs/2308.06644</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation">https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation</a></li>
<li>paper_authors: Junwei Huang, Zhiqing Sun, Yiming Yang</li>
<li>for: 提高 NP-完全 combinatorial 优化问题的解决速度</li>
<li>methods: 使用进步干涤法加速推理，在杂化过程中采取 fewer steps，如在单步内预测两步</li>
<li>results: 实验结果显示，使用进步干涤模型可以将推理速度提高 16 倍，而性能下降仅 0.019%，在 TSP-50 数据集上。<details>
<summary>Abstract</summary>
Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
</details>
<details>
<summary>摘要</summary>
GRaph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.Here's the translation in Traditional Chinese: GRaph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
</details></li>
</ul>
<hr>
<h2 id="Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition"><a href="#Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition" class="headerlink" title="Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition"></a>Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11633">http://arxiv.org/abs/2308.11633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Sheffield, Frank E. Bobe III, Bradley Marchand, Matthew S. Emigh</li>
<li>for: 本研究旨在提高水下探索中SAS数据处理、分类和 Pattern recognition的效果，通过使用自助学习（SSL）技术。</li>
<li>methods: 本研究提出了MoCo-SAS，一种基于SSL的SAS数据处理方法，包括数据预处理、特征提取、模型训练和测试。</li>
<li>results: 实验结果表明，MoCo-SAS与传统的指导学习方法相比，在F1分数上有显著提高，表明SSL可以在SAS数据处理中提高效果，并且具有潜在的应用前景。<details>
<summary>Abstract</summary>
Synthetic Aperture Sonar (SAS) imaging has become a crucial technology for underwater exploration because of its unique ability to maintain resolution at increasing ranges, a characteristic absent in conventional sonar techniques. However, the effective application of deep learning to SAS data processing is often limited due to the scarcity of labeled data. To address this challenge, this paper proposes MoCo-SAS that leverages self-supervised learning (SSL) for SAS data processing, classification, and pattern recognition. The experimental results demonstrate that MoCo-SAS significantly outperforms traditional supervised learning methods, as evidenced by significant improvements observed in terms of the F1-score. These findings highlight the potential of SSL in advancing the state-of-the-art in SAS data processing, offering promising avenues for enhanced underwater object detection and classification.
</details>
<details>
<summary>摘要</summary>
射频成像技术（SAS）已成为水下探测中不可或缺的一种重要技术，因其可以维持分辨率随距离增长，这是传统声纳技术缺乏的特点。然而，各种深度学习在SAS数据处理中的有效应用却受到标注数据的罕见性的限制。为解决这个挑战，本文提出了MoCo-SAS，利用自动编程学习（SSL）进行SAS数据处理、分类和模式识别。实验结果表明，MoCo-SAS在F1分数方面显著超越传统监督学习方法，这表明SSL在SAS数据处理中具有潜在的潜在优势。这些发现表明SSL在SAS数据处理中可能提供新的突破口，用于提高水下对象检测和分类的精度。
</details></li>
</ul>
<hr>
<h2 id="ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss"><a href="#ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss" class="headerlink" title="ADRMX: Additive Disentanglement of Domain Features with Remix Loss"></a>ADRMX: Additive Disentanglement of Domain Features with Remix Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06624">http://arxiv.org/abs/2308.06624</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/berkerdemirel/ADRMX">https://github.com/berkerdemirel/ADRMX</a></li>
<li>paper_authors: Berker Demirel, Erchan Aptoula, Huseyin Ozkan</li>
<li>for: 这个研究旨在创建能够在新不同预设范围中具有普遍化能力的模型，以减少因为不同预设范围之间的分布变化对模型的影响。</li>
<li>methods: 这个研究使用了一种名为“Additive Disentanglement of Domain Features with Remix Loss”的新架构，并 introduce了一种新的数据增强技术，将不同预设范围中的数据混合在潜在空间中。</li>
<li>results: 这个研究透过对DomainBed进行了EXTENSIVE的实验，展示了ADRMX可以实现现场的表现，并且比以前的研究得到更好的结果。<details>
<summary>Abstract</summary>
The common assumption that train and test sets follow similar distributions is often violated in deployment settings. Given multiple source domains, domain generalization aims to create robust models capable of generalizing to new unseen domains. To this end, most of existing studies focus on extracting domain invariant features across the available source domains in order to mitigate the effects of inter-domain distributional changes. However, this approach may limit the model's generalization capacity by relying solely on finding common features among the source domains. It overlooks the potential presence of domain-specific characteristics that could be prevalent in a subset of domains, potentially containing valuable information. In this work, a novel architecture named Additive Disentanglement of Domain Features with Remix Loss (ADRMX) is presented, which addresses this limitation by incorporating domain variant features together with the domain invariant ones using an original additive disentanglement strategy. Moreover, a new data augmentation technique is introduced to further support the generalization capacity of ADRMX, where samples from different domains are mixed within the latent space. Through extensive experiments conducted on DomainBed under fair conditions, ADRMX is shown to achieve state-of-the-art performance. Code will be made available at GitHub after the revision process.
</details>
<details>
<summary>摘要</summary>
通常的假设是训练集和测试集都follow相似的分布是在部署设置中常常被违反。给定多个源领域，领域泛化目标是创建抗衰假设模型，以便在新未经见过的领域中泛化。为此，大多数现有的研究都是EXTRACTING DOMAIN INVARIANT FEATURES ACROSS AVAILABLE SOURCE DOMAINS，以mitigate INTER-DOMAIN distributional changes的影响。然而，这种方法可能会限制模型的泛化能力，因为它只是在 source domains 中找到共同特征。它忽略了可能存在一些领域特有的特征，这些特征可能在一些领域中具有价值信息。在这项工作中，一种新的架构名为 Additive Disentanglement of Domain Features with Remix Loss (ADRMX) 被提出，它解决了这种限制，通过将领域特征和领域 invariants 相加拼接在一起。此外，一种新的数据增强技术也被引入，用于进一步支持 ADRMX 的泛化能力，其中不同领域的样本在离散空间中混合。通过对 DomainBed 进行了广泛的实验，ADRMX 在 fair 的条件下显示出了状态的表现。代码将在 GitHub 上提供。
</details></li>
</ul>
<hr>
<h2 id="Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks"><a href="#Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks" class="headerlink" title="Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?"></a>Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06619">http://arxiv.org/abs/2308.06619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Liao, Victor Quétu, Van-Tam Nguyen, Enzo Tartaglione</li>
<li>for: 降低深度神经网络大小 while maintaining performance</li>
<li>methods: 基于Entropy Guided Pruning算法，优先遍历层次 entropy 低的连接，进行完全移除</li>
<li>results: 成功地压缩深度神经网络，保持竞争力水平，并提供了关于不结构压缩的机制和深度学习性能之间的新的视角。<details>
<summary>Abstract</summary>
Pruning is a widely used technique for reducing the size of deep neural networks while maintaining their performance. However, such a technique, despite being able to massively compress deep models, is hardly able to remove entire layers from a model (even when structured): is this an addressable task? In this study, we introduce EGP, an innovative Entropy Guided Pruning algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relationship between entropy, pruning techniques, and deep learning performance. The EGP algorithm and its insights hold great promise for advancing the field of network compression and optimization. The source code for EGP is released open-source.
</details>
<details>
<summary>摘要</summary>
剪辑是一种广泛使用的技术，用于降低深度神经网络的大小，保持性能。然而，这种技术，即使可以压缩深度模型，几乎不能完全移除层（即使是结构化的）：是这个任务可行吗？在这项研究中，我们介绍了EGP算法，一种创新的熵导向剪辑算法，用于减少深度神经网络的大小，保持性能。EGP的关键点在于优先剪辑层中的熵低的连接，以便完全移除它们。我们在popular模型如ResNet-18和Swin-T等模型上进行了广泛的实验，发现EGP有效地减少深度神经网络的大小，保持竞争力水平。我们的研究不仅解释了不结构化剪辑的优势，还为深度学习性能和剪辑技术之间的复杂关系开辟了新的可能性。EGP算法和其洞见拥有很大的潜力，可以推动深度神经网络压缩和优化领域的进步。EGP算法的源代码已经开源。
</details></li>
</ul>
<hr>
<h2 id="On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness"><a href="#On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness" class="headerlink" title="On the Interplay of Convolutional Padding and Adversarial Robustness"></a>On the Interplay of Convolutional Padding and Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06612">http://arxiv.org/abs/2308.06612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
<li>for: 本文旨在研究padding和敌意攻击之间的交互关系，以及不同padding模式对敌意Robustness的影响。</li>
<li>methods: 本文使用Convolutional Neural Networks (CNN)进行研究，并对不同padding模式进行比较。</li>
<li>results: 本文发现，敌意攻击通常会导致图像边界上的异常，这些异常与padding有关。此外，本文还发现不同padding模式对敌意Robustness的影响不同。<details>
<summary>Abstract</summary>
It is common practice to apply padding prior to convolution operations to preserve the resolution of feature-maps in Convolutional Neural Networks (CNN). While many alternatives exist, this is often achieved by adding a border of zeros around the inputs. In this work, we show that adversarial attacks often result in perturbation anomalies at the image boundaries, which are the areas where padding is used. Consequently, we aim to provide an analysis of the interplay between padding and adversarial attacks and seek an answer to the question of how different padding modes (or their absence) affect adversarial robustness in various scenarios.
</details>
<details>
<summary>摘要</summary>
通常来说，在卷积神经网络（CNN）中， pading 被用来保持特征地图的分辨率。虽然有很多方法可供选择，但通常是通过在输入添加一个边界的零值来实现。在这项工作中，我们发现了一个现象：攻击者经常在图像边界处引起异常的杂变，这些区域 precisly 是在 padding 中使用的地方。因此，我们想进行 padding 和攻击者之间的分析，并问到不同的 padding 模式（或其缺失）对于不同的场景中的鲁棒性有什么影响。
</details></li>
</ul>
<hr>
<h2 id="LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net"><a href="#LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net" class="headerlink" title="LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net"></a>LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06603">http://arxiv.org/abs/2308.06603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ach-1914/ladlenet">https://github.com/ach-1914/ladlenet</a></li>
<li>paper_authors: Tonghui Zou</li>
<li>for: 该 paper 的目的是提出一种基于 U-Net 架构的算法，用于将thermal infrared（TIR）图像转换为可见光（VI）图像，以满足不同领域的应用需求。</li>
<li>methods: 该算法使用了两个阶段的 U-Net  concatenation结构，以及缺省连接和精细特征聚合技术，从而提高模型性能。该算法包括 ‘Handle’ 模块和 ‘Bowl’ 模块，其中 ‘Handle’ 模块建立了一个抽象的 semantic space，而 ‘Bowl’ 模块将该 semantic space 转换为封装的 VI 图像。</li>
<li>results:  comparing to existing methodologies, 该方法在 KAIST 数据集上测试得到了最佳性能，包括图像清晰度和感知质量。<details>
<summary>Abstract</summary>
The translation of thermal infrared (TIR) images to visible light (VI) images presents a challenging task with potential applications spanning various domains such as TIR-VI image registration and fusion. Leveraging supplementary information derived from TIR image conversions can significantly enhance model performance and generalization across these applications. However, prevailing issues within this field include suboptimal image fidelity and limited model scalability. In this paper, we introduce an algorithm, LadleNet, based on the U-Net architecture. LadleNet employs a two-stage U-Net concatenation structure, augmented with skip connections and refined feature aggregation techniques, resulting in a substantial enhancement in model performance. Comprising 'Handle' and 'Bowl' modules, LadleNet's Handle module facilitates the construction of an abstract semantic space, while the Bowl module decodes this semantic space to yield mapped VI images. The Handle module exhibits extensibility by allowing the substitution of its network architecture with semantic segmentation networks, thereby establishing more abstract semantic spaces to bolster model performance. Consequently, we propose LadleNet+, which replaces LadleNet's Handle module with the pre-trained DeepLabv3+ network, thereby endowing the model with enhanced semantic space construction capabilities. The proposed method is evaluated and tested on the KAIST dataset, accompanied by quantitative and qualitative analyses. Compared to existing methodologies, our approach achieves state-of-the-art performance in terms of image clarity and perceptual quality. The source code will be made available at https://github.com/Ach-1914/LadleNet/tree/main/.
</details>
<details>
<summary>摘要</summary>
文本翻译：thermal infrared（TIR）图像到可见光（VI）图像的翻译问题具有广泛的应用领域，如TIR-VI图像匹配和融合。利用TIR图像的补充信息可以大幅提高模型性能和泛化性。然而，现有的问题包括图像质量不佳和模型缺乏扩展性。本文介绍一种算法，叫做LadleNet，基于U-Net架构。LadleNet使用了两个阶段的U-Net concatenation结构，加上了跳过连接和细化特征聚合技术，从而实现了显著提高模型性能。LadleNet包括“ Handle”和“Bowl”模块，其中“ Handle”模块建立了一个抽象的语义空间，而“Bowl”模块将这个语义空间转换成VI图像。“ Handle”模块具有扩展性，可以将其网络架构替换为语义分割网络，从而建立更加抽象的语义空间，提高模型性能。因此，我们提出了LadleNet+，其替换了LadleNet的“ Handle”模块，使用了预训练的DeepLabv3+网络，从而为模型增加了更多的语义空间建构能力。我们的方法在KAIST数据集上进行了评估和测试，并进行了量化和质量分析。与现有方法相比，我们的方法在图像清晰度和感知质量方面达到了国际前ier的性能。代码将在https://github.com/Ach-1914/LadleNet/tree/main/中提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.LG_2023_08_13/" data-id="clon21is000mur5883t0a217q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/eess.IV_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T09:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/eess.IV_2023_08_13/">eess.IV - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature"><a href="#Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature" class="headerlink" title="Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature"></a>Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06781">http://arxiv.org/abs/2308.06781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yash Deo, Haoran Dou, Nishant Ravikumar, Alejandro F. Frangi, Toni Lassila</li>
<li>for: 了解脑血管系统中圆形封闭（Circle of Willis，CoW）的多样性和配置，以提高脑血管疾病研究和临床 intervención的精度。</li>
<li>methods: 使用条件潜在扩散模型（conditional latent diffusion model），包括形态和解剖指导，生成真实的3D CoW分割结果，包括不同的现象型变化。</li>
<li>results: 比较 conditional variants of 3D GAN和3D VAE的模型，发现我们的模型能够更好地保持血管连续性，并且生成的CoW变化更加真实，FID分数比最佳performing GAN-based model高53%。<details>
<summary>Abstract</summary>
The Circle of Willis (CoW) is the part of cerebral vasculature responsible for delivering blood to the brain. Understanding the diverse anatomical variations and configurations of the CoW is paramount to advance research on cerebrovascular diseases and refine clinical interventions. However, comprehensive investigation of less prevalent CoW variations remains challenging because of the dominance of a few commonly occurring configurations. We propose a novel generative approach utilising a conditional latent diffusion model with shape and anatomical guidance to generate realistic 3D CoW segmentations, including different phenotypical variations. Our conditional latent diffusion model incorporates shape guidance to better preserve vessel continuity and demonstrates superior performance when compared to alternative generative models, including conditional variants of 3D GAN and 3D VAE. We observed that our model generated CoW variants that are more realistic and demonstrate higher visual fidelity than competing approaches with an FID score 53\% better than the best-performing GAN-based model.
</details>
<details>
<summary>摘要</summary>
圆形维利斯（CoW）是脑血管系统的一部分，负责将血液传递到脑中。了解不同的静脉维利斯变化和配置是研究脑血管疾病的前进和精细化临床 intervención的关键。然而，对于较少seen CoW变化的全面调查仍然是挑战，因为一些常见的配置占据了主导地位。我们提出了一种新的生成方法，使用conditioned latent diffusion模型，包含形态指导，以生成真实的3D CoW分割，包括不同的现象变化。我们的conditioned latent diffusion模型能够更好地保持血管连续性，并与其他生成模型相比，如3D GAN和3D VAE的conditioned变种，显示出更高的性能。我们发现，我们的模型生成的CoW变化比competing approach更真实，Visual fidelity高于53%。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches"><a href="#Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches" class="headerlink" title="Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches"></a>Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06776">http://arxiv.org/abs/2308.06776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxin0/scpgabnet">https://github.com/linxin0/scpgabnet</a></li>
<li>paper_authors: Xin Lin, Chao Ren, Xiao Liu, Jie Huang, Yinjie Lei</li>
<li>for: 提高无监督图像净化的性能，不需要大量的对称数据。</li>
<li>methods: 基于生成敌对网络的Unsupervised Approach， iteratively replace previous less powerful denoiser with current powerful denoiser， generate better synthetic clean-noisy image pairs。</li>
<li>results: 比 state-of-the-art unsupervised方法有更好的性能。<details>
<summary>Abstract</summary>
Deep learning methods have shown remarkable performance in image denoising, particularly when trained on large-scale paired datasets. However, acquiring such paired datasets for real-world scenarios poses a significant challenge. Although unsupervised approaches based on generative adversarial networks offer a promising solution for denoising without paired datasets, they are difficult in surpassing the performance limitations of conventional GAN-based unsupervised frameworks without significantly modifying existing structures or increasing the computational complexity of denoisers. To address this problem, we propose a SC strategy for multiple denoisers. This strategy can achieve significant performance improvement without increasing the inference complexity of the GAN-based denoising framework. Its basic idea is to iteratively replace the previous less powerful denoiser in the filter-guided noise extraction module with the current powerful denoiser. This process generates better synthetic clean-noisy image pairs, leading to a more powerful denoiser for the next iteration. This baseline ensures the stability and effectiveness of the training network. The experimental results demonstrate the superiority of our method over state-of-the-art unsupervised methods.
</details>
<details>
<summary>摘要</summary>
深度学习方法在图像噪声除除表现出了惊人的表现，特别是在大规模对应数据集上训练的情况下。然而，在真实世界场景中获得对应数据集的获得是一项重要挑战。 Although 无监督方法基于生成对抗网络提供了一种噪声除除无需对应数据集的解决方案，但它们在不改变现有结构或提高噪声除除器的计算复杂度下难以超越传统GAN基于无监督框架的性能限制。为解决这个问题，我们提议了SC策略 для多个噪声除除器。这种策略可以在不增加GAN基于噪声除除框架的推理复杂度下实现显著性能提高。其基本思想是在滤波器引导噪声提取模块中，逐次将前一个较弱的噪声除除器 replaced 为当前更强的噪声除除器。这个过程生成了更好的人工干扰净损像对，导致更强的噪声除除器。这个基准保证了训练网络的稳定性和效果。实验结果表明，我们的方法在无监督方法中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes"><a href="#Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes" class="headerlink" title="Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes"></a>Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06762">http://arxiv.org/abs/2308.06762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Huang, Xukun Zhang, Zhiming Cui, He Zhang, Geng Chen, Dinggang Shen</li>
<li>for: 这个研究的目的是提高胎儿脑MR扫描中的组织分类精度，以便重建iso类型脑MR扫描 volume 和评估胎儿脑发展。</li>
<li>methods: 这个研究使用了域 adaptation 技术，将高品质的iso类型脑MR扫描 volume 作为指导，对厚层扫描进行组织分类。</li>
<li>results: 实验结果显示，这个方法可以对胎儿脑MR扫描中的组织分类进行高精度的调整，并且与现有的方法相比，表现更加出色。<details>
<summary>Abstract</summary>
Accurate tissue segmentation of thick-slice fetal brain magnetic resonance (MR) scans is crucial for both reconstruction of isotropic brain MR volumes and the quantification of fetal brain development. However, this task is challenging due to the use of thick-slice scans in clinically-acquired fetal brain data. To address this issue, we propose to leverage high-quality isotropic fetal brain MR volumes (and also their corresponding annotations) as guidance for segmentation of thick-slice scans. Due to existence of significant domain gap between high-quality isotropic volume (i.e., source data) and thick-slice scans (i.e., target data), we employ a domain adaptation technique to achieve the associated knowledge transfer (from high-quality <source> volumes to thick-slice <target> scans). Specifically, we first register the available high-quality isotropic fetal brain MR volumes across different gestational weeks to construct longitudinally-complete source data. To capture domain-invariant information, we then perform Fourier decomposition to extract image content and style codes. Finally, we propose a novel Cycle-Consistent Domain Adaptation Network (C2DA-Net) to efficiently transfer the knowledge learned from high-quality isotropic volumes for accurate tissue segmentation of thick-slice scans. Our C2DA-Net can fully utilize a small set of annotated isotropic volumes to guide tissue segmentation on unannotated thick-slice scans. Extensive experiments on a large-scale dataset of 372 clinically acquired thick-slice MR scans demonstrate that our C2DA-Net achieves much better performance than cutting-edge methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
幼虫脑magnetic resonance（MR）扫描的粗层扫描是重要的，因为它们可以提供高级别的脑部MR影像Volume，并且可以量化胎儿脑部发展的进度。然而，这个任务具有挑战性，因为在临床中获取的胎儿脑部MR扫描通常使用粗层扫描。为解决这个问题，我们提议使用高质量的ISO分布式胎儿脑MR影像（以及其相应的标注）作为指导，以实现粗层扫描的准确分割。由于源数据和目标数据之间存在很大的领域差异，我们采用领域适应技术来实现相关的知识传递。具体来说，我们首先将可用的高质量ISO分布式胎儿脑MR影像长itudinally完整地注册，以构建不同 gestational weeks的源数据。然后，我们使用快速 Fourier 分解来提取图像内容和风格代码。最后，我们提出了一种名为C2DA-Net的循环一致领域适应网络，以高效地传递从高质量ISO分布式胎儿脑MR影像中学习的知识，以便在无标注的粗层扫描中进行准确的组织分割。我们的C2DA-Net可以全面利用一小组标注的ISO分布式胎儿脑MR影像来导导粗层扫描中的组织分割。我们在372个临床获取的粗层扫描中进行了广泛的实验，并证明了我们的C2DA-Net可以在量化和质量上superior于当前的方法。
</details></li>
</ul>
<hr>
<h2 id="FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table"><a href="#FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table" class="headerlink" title="FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table"></a>FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06749">http://arxiv.org/abs/2308.06749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenhao-li-777/fastllve">https://github.com/wenhao-li-777/fastllve</a></li>
<li>paper_authors: Wenhao Li, Guangyang Wu, Wenyi Wang, Peiran Ren, Xiaohong Liu</li>
<li>for: 提高低光照视频质量</li>
<li>methods: 利用Look-Up-Table（LUT）技术维护 между帧亮度一致性，并设计了一个可学习的Intensity-Aware LUT（IA-LUT）模块进行自适应增强。</li>
<li>results: 实验结果表明，我们的方法可以在标准数据集上达到最新状态的性能，同时在帧速和计算复杂度方面也具有优势。 Code available at <a target="_blank" rel="noopener" href="https://github.com/Wenhao-Li-777/FastLLVE">https://github.com/Wenhao-Li-777/FastLLVE</a>.<details>
<summary>Abstract</summary>
Low-Light Video Enhancement (LLVE) has received considerable attention in recent years. One of the critical requirements of LLVE is inter-frame brightness consistency, which is essential for maintaining the temporal coherence of the enhanced video. However, most existing single-image-based methods fail to address this issue, resulting in flickering effect that degrades the overall quality after enhancement. Moreover, 3D Convolution Neural Network (CNN)-based methods, which are designed for video to maintain inter-frame consistency, are computationally expensive, making them impractical for real-time applications. To address these issues, we propose an efficient pipeline named FastLLVE that leverages the Look-Up-Table (LUT) technique to maintain inter-frame brightness consistency effectively. Specifically, we design a learnable Intensity-Aware LUT (IA-LUT) module for adaptive enhancement, which addresses the low-dynamic problem in low-light scenarios. This enables FastLLVE to perform low-latency and low-complexity enhancement operations while maintaining high-quality results. Experimental results on benchmark datasets demonstrate that our method achieves the State-Of-The-Art (SOTA) performance in terms of both image quality and inter-frame brightness consistency. More importantly, our FastLLVE can process 1,080p videos at $\mathit{50+}$ Frames Per Second (FPS), which is $\mathit{2 \times}$ faster than SOTA CNN-based methods in inference time, making it a promising solution for real-time applications. The code is available at https://github.com/Wenhao-Li-777/FastLLVE.
</details>
<details>
<summary>摘要</summary>
低光照视频增强（LLVE）在最近几年内受到了广泛关注。一个关键的要求是 между帧亮度一致性，以保持视频增强后的时间一致性。然而，大多数现有的单张图像基的方法无法解决这个问题，导致幻灯效应，从而降低了整体质量。此外，基于3D卷积神经网络（CNN）的方法，它们是为视频维护 между帧一致性而设计的，但是计算成本高，使其不适用于实时应用。为解决这些问题，我们提出了高效的渠道名为快速LLVE，利用Look-Up-Table（LUT）技术来维护between帧亮度一致性。我们特制了可学习的Intensity-Aware LUT（IA-LUT）模块，用于适应增强，解决低动态问题在低光照场景中。这使得快速LLVE可以在低延迟和低复杂度下进行增强操作，同时维护高质量结果。实验结果表明，我们的方法在标准数据集上达到了状态之作（SOTA）的性能， both图像质量和between帧亮度一致性方面。此外，我们的快速LLVE可以处理1080P视频，在50+帧每秒（FPS）处理速度，高于SOTA CNN基于方法的两倍即2倍的执行速度，这使得它在实时应用中成为一个有前途的解决方案。代码可以在https://github.com/Wenhao-Li-777/FastLLVE中找到。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising"><a href="#Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising" class="headerlink" title="Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising"></a>Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06746">http://arxiv.org/abs/2308.06746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyuan01/self-supervised-noise2noise-for-ldct">https://github.com/xyuan01/self-supervised-noise2noise-for-ldct</a></li>
<li>paper_authors: Yuting Zhu, Qiang He, Yudong Yao, Yueyang Teng</li>
<li>for: 这个研究旨在提出一种基于单束 Computed Tomography (CT) 影像的自我监督噪声降低方法，不需要对CT影像进行训练。</li>
<li>methods: 本研究使用了一种组合自我监督噪声模型和降低噪声的方法，首先将LDCT影像添加了两种相似的噪声，然后使用这些降低噪声的影像进行训练。</li>
<li>results: 实验结果显示，提出的方法比前一代深度学习方法更有效地进行LDCT影像降低噪声。<details>
<summary>Abstract</summary>
Deep learning is a very promising technique for low-dose computed tomography (LDCT) image denoising. However, traditional deep learning methods require paired noisy and clean datasets, which are often difficult to obtain. This paper proposes a new method for performing LDCT image denoising with only LDCT data, which means that normal-dose CT (NDCT) is not needed. We adopt a combination including the self-supervised noise2noise model and the noisy-as-clean strategy. First, we add a second yet similar type of noise to LDCT images multiple times. Note that we use LDCT images based on the noisy-as-clean strategy for corruption instead of NDCT images. Then, the noise2noise model is executed with only the secondary corrupted images for training. We select a modular U-Net structure from several candidates with shared parameters to perform the task, which increases the receptive field without increasing the parameter size. The experimental results obtained on the Mayo LDCT dataset show the effectiveness of the proposed method compared with that of state-of-the-art deep learning methods. The developed code is available at https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT.
</details>
<details>
<summary>摘要</summary>
深度学习是LDCT图像减噪的非常有前途的技术。然而，传统的深度学习方法通常需要配备零噪和干净的数据集，这些数据集往往很难获得。这篇论文提出了一种只使用LDCT数据进行LDCT图像减噪的新方法。我们采用了一种组合，包括自我监督的噪声2噪模型和噪声作为干净策略。首先，我们将LDCT图像添加了多次相似的噪声。注意我们使用LDCT图像来代替NDCT图像进行损害。然后，我们在噪声2噪模型中进行训练，只使用第二次损害的图像。我们选择了一个模块化U-Net结构，从多个候选者中选择了共享参数来完成任务，这样可以增加感知范围而不是增加参数大小。实验结果表明，提出的方法在Mayo LDCT数据集上比州前的深度学习方法更有效。代码可以在https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT上下载。
</details></li>
</ul>
<hr>
<h2 id="Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation"><a href="#Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation" class="headerlink" title="Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?"></a>Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06623">http://arxiv.org/abs/2308.06623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RisabBiswas/Polyp-SAM-PlusPlus">https://github.com/RisabBiswas/Polyp-SAM-PlusPlus</a></li>
<li>paper_authors: Risab Biswas</li>
<li>for: 这个论文的目的是提高肿瘤 segmentation 的精度和稳定性，并通过文本提示来使用 SAM 模型进行肿瘤 segmentation。</li>
<li>methods: 这个论文使用的方法是使用文本提示来提高 SAM 模型的精度和稳定性，并在 benchmark 数据集上进行评估。</li>
<li>results: 研究发现，使用文本提示可以提高 SAM 模型的肿瘤 segmentation 精度和稳定性，并且比不使用文本提示的情况下更好。<details>
<summary>Abstract</summary>
Meta recently released SAM (Segment Anything Model) which is a general-purpose segmentation model. SAM has shown promising results in a wide variety of segmentation tasks including medical image segmentation. In the field of medical image segmentation, polyp segmentation holds a position of high importance, thus creating a model which is robust and precise is quite challenging. Polyp segmentation is a fundamental task to ensure better diagnosis and cure of colorectal cancer. As such in this study, we will see how Polyp-SAM++, a text prompt-aided SAM, can better utilize a SAM using text prompting for robust and more precise polyp segmentation. We will evaluate the performance of a text-guided SAM on the polyp segmentation task on benchmark datasets. We will also compare the results of text-guided SAM vs unprompted SAM. With this study, we hope to advance the field of polyp segmentation and inspire more, intriguing research. The code and other details will be made publically available soon at https://github.com/RisabBiswas/Polyp-SAM++.
</details>
<details>
<summary>摘要</summary>
meta 最近发布了 SAM（分割任务模型），这是一种通用的分割模型。SAM 在多种分割任务中表现出色，包括医疗影像分割。在医疗影像分割领域，肿瘤分割具有非常高的重要性，因此创建一个精度高和可靠的模型是非常挑战性的。肿瘤分割是诊断和治疗抑郁癌的基本任务。在本研究中，我们将看到 Polyp-SAM++，一种使用文本提示的 SAM，如何更好地利用 SAM 进行肿瘤分割。我们将对 Polyp-SAM++ 在标准数据集上进行评估，并与不提示 SAM 进行比较。我们希望通过这项研究，推动肿瘤分割领域的进步，并鼓励更多的感人研究。代码和其他细节将在https://github.com/RisabBiswas/Polyp-SAM++ 上公开。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/eess.IV_2023_08_13/" data-id="clon21ixw013ir5880twaa6kx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.SD_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T15:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.SD_2023_08_12/">cs.SD - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition"><a href="#Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition" class="headerlink" title="Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition"></a>Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06547">http://arxiv.org/abs/2308.06547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zhu, Dongji Gao, Gaofeng Cheng, Daniel Povey, Pengyuan Zhang, Yonghong Yan</li>
<li>for: 提高自动语音识别器的性能在半监督学习中，当 Label 缺乏时</li>
<li>methods: 提议一种新的替代 pseudo-labeling 框架，包括一种通用的 CTC 损失函数、一种 confidence-based 错误检测方法和一种自动调整 threshold 方法</li>
<li>results: 对比 traditional CTC 损失函数和 confidence-based 错误检测方法，提议的替代 pseudo-labeling 框架可以更好地处理含有错误 tokens 的 pseudo-Label，并且不需要手动调整 threshold<details>
<summary>Abstract</summary>
When labeled data is insufficient, semi-supervised learning with the pseudo-labeling technique can significantly improve the performance of automatic speech recognition. However, pseudo-labels are often noisy, containing numerous incorrect tokens. Taking noisy labels as ground-truth in the loss function results in suboptimal performance. Previous works attempted to mitigate this issue by either filtering out the nosiest pseudo-labels or improving the overall quality of pseudo-labels. While these methods are effective to some extent, it is unrealistic to entirely eliminate incorrect tokens in pseudo-labels. In this work, we propose a novel framework named alternative pseudo-labeling to tackle the issue of noisy pseudo-labels from the perspective of the training objective. The framework comprises several components. Firstly, a generalized CTC loss function is introduced to handle noisy pseudo-labels by accepting alternative tokens in the positions of incorrect tokens. Applying this loss function in pseudo-labeling requires detecting incorrect tokens in the predicted pseudo-labels. In this work, we adopt a confidence-based error detection method that identifies the incorrect tokens by comparing their confidence scores with a given threshold, thus necessitating the confidence score to be discriminative. Hence, the second proposed technique is the contrastive CTC loss function that widens the confidence gap between the correctly and incorrectly predicted tokens, thereby improving the error detection ability. Additionally, obtaining satisfactory performance with confidence-based error detection typically requires extensive threshold tuning. Instead, we propose an automatic thresholding method that uses labeled data as a proxy for determining the threshold, thus saving the pain of manual tuning.
</details>
<details>
<summary>摘要</summary>
当标注数据短缺时，半超vised学习采用pseudo-标签技术可以显著提高自动语音识别的性能。然而，pseudo-标签经常含有许多错误的token。将含有错误token的pseudo-标签作为真实标签在损失函数中使用会导致优化性能下降。前一些工作尝试了通过过滤 pseudo-标签中最含糟糕的token或提高总体pseudo-标签质量来缓解这个问题。虽然这些方法有一定的效果，但是完全消除pseudo-标签中的错误token是不现实的。在这种情况下，我们提出了一种新的框架名为代理 pseudo-标签。该框架包括以下几个组成部分。首先，我们引入一种通用的CTC损失函数，可以处理含有错误token的pseudo-标签。在使用这种损失函数进行pseudo-标签时，需要检测pseudo-标签中的错误token。在这种情况下，我们采用一种 confidence-based 错误检测方法，通过比较错误token的信任分数与一个给定的阈值，以确定错误token的存在。因此，第二个提出的技术是增强CTC损失函数，以增强错误检测的能力。此外，通过 confidence-based 错误检测获得良好性能通常需要进行广泛的阈值调整。而我们提出的自动阈值调整方法，通过使用标注数据作为代理，自动地调整阈值，从而避免了手动调整的痛苦。
</details></li>
</ul>
<hr>
<h2 id="BigWavGAN-A-Wave-To-Wave-Generative-Adversarial-Network-for-Music-Super-Resolution"><a href="#BigWavGAN-A-Wave-To-Wave-Generative-Adversarial-Network-for-Music-Super-Resolution" class="headerlink" title="BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music Super-Resolution"></a>BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06483">http://arxiv.org/abs/2308.06483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yenan Zhang, Hiroshi Watanabe</li>
<li>for: 这个论文目的是提高音乐超解析（SR）领域中深度神经网络（DNN）的性能。</li>
<li>methods: 这个论文使用了大型DNN模型，并结合了State-Of-The-Art（SOTA）的激励函数和对抗训练策略。它的权衡器包括多尺度权衡器（MSD）和多分辨率权衡器（MRD）。</li>
<li>results: 对于音乐SR问题，BigWavGAN模型表现出色，超过了基eline模型和State-Of-The-Art（SOTA）音乐SR模型。它还能够处理异常数据，并且有较好的总体化能力。<details>
<summary>Abstract</summary>
Generally, Deep Neural Networks (DNNs) are expected to have high performance when their model size is large. However, large models failed to produce high-quality results commensurate with their scale in music Super-Resolution (SR). We attribute this to that DNNs cannot learn information commensurate with their size from standard mean square error losses. To unleash the potential of large DNN models in music SR, we propose BigWavGAN, which incorporates Demucs, a large-scale wave-to-wave model, with State-Of-The-Art (SOTA) discriminators and adversarial training strategies. Our discriminator consists of Multi-Scale Discriminator (MSD) and Multi-Resolution Discriminator (MRD). During inference, since only the generator is utilized, there are no additional parameters or computational resources required compared to the baseline model Demucs. Objective evaluation affirms the effectiveness of BigWavGAN in music SR. Subjective evaluations indicate that BigWavGAN can generate music with significantly high perceptual quality over the baseline model. Notably, BigWavGAN surpasses the SOTA music SR model in both simulated and real-world scenarios. Moreover, BigWavGAN represents its superior generalization ability to address out-of-distribution data. The conducted ablation study reveals the importance of our discriminators and training strategies. Samples are available on the demo page.
</details>
<details>
<summary>摘要</summary>
通常情况下，深度神经网络（DNNs）预期会在模型大小增加时表现出色。然而，大型模型在音乐超分解（SR）中并没有达到预期的高质量效果。我们认为这是因为DNNs无法从标准方差误差损失中学习足够的信息。为了解放大型DNN模型在音乐SR中的潜力，我们提出了BigWavGAN，它将大规模涉及的wave-to-wave模型Demucs融合到了领先的推误器和对抗训练策略中。我们的推误器包括多尺度推误器（MSD）和多分辨率推误器（MRD）。在推理过程中，由于只有生成器被使用，因此没有额外的参数或计算资源的需求，与基线模型Demucs相比。对象评估表明BigWavGAN在音乐SR中的效果非常高。主观评估表明BigWavGAN可以生成具有显著高媒体质量的音乐，比基线模型高。此外，BigWavGAN在实际和 simulate 的情况下都能够超越领先的音乐SR模型。此外，BigWavGAN在处理异常数据的能力方面表现出了superior的普适性。进行的ablation研究表明我们的推误器和训练策略的重要性。样例可以在 demo 页面中找到。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss"><a href="#Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss" class="headerlink" title="Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss"></a>Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06327">http://arxiv.org/abs/2308.06327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Soleymanpour, Mahmoud Al Ismail, Fahimeh Bahmaninezhad, Kshitiz Kumar, Jian Wu</li>
<li>for: 支持英语为次要地区的半自动语音识别（ASR）设置</li>
<li>methods: 使用全双语对照模型、双流Transformer模型、并行编码结构和语言标识（LID）损失</li>
<li>results: 提高英语混合码能力，对代码混合ES和IT应用进行大规模训练和测试，并显示出优于LID损失的特点<details>
<summary>Abstract</summary>
We introduce a bilingual solution to support English as secondary locale for most primary locales in hybrid automatic speech recognition (ASR) settings. Our key developments constitute: (a) pronunciation lexicon with grapheme units instead of phone units, (b) a fully bilingual alignment model and subsequently bilingual streaming transformer model, (c) a parallel encoder structure with language identification (LID) loss, (d) parallel encoder with an auxiliary loss for monolingual projections. We conclude that in comparison to LID loss, our proposed auxiliary loss is superior in specializing the parallel encoders to respective monolingual locales, and that contributes to stronger bilingual learning. We evaluate our work on large-scale training and test tasks for bilingual Spanish (ES) and bilingual Italian (IT) applications. Our bilingual models demonstrate strong English code-mixing capability. In particular, the bilingual IT model improves the word error rate (WER) for a code-mix IT task from 46.5% to 13.8%, while also achieving a close parity (9.6%) with the monolingual IT model (9.5%) over IT tests.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种双语解决方案，以支持英语为次要地区的多地点自动语音识别（ASR）设置。我们的关键发展包括：(a) 使用字节单位 вместоPhone单位的发音词典。(b)一个完全双语对应模型和随后的双语流transformer模型。(c)一个并行编码结构，并且添加语言标识（LID）损失。(d)并行编码器，并且添加一个辅助损失来特化到各自的单语言本地。我们结合了这些发展，并进行了大规模的训练和测试任务，以评估我们的方法在双语西班牙（ES）和双语意大利（IT）应用中的性能。我们的双语模型在英语混合码中表现出色，特别是双语IT模型在一个混合IT任务中，从46.5%降低到13.8%，同时也与单语意大利模型（9.5%）在意大利测试上凑平。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.SD_2023_08_12/" data-id="clon21iu600tmr588e17o7na6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.CV_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T13:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.CV_2023_08_12/">cs.CV - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Cyclic-Test-Time-Adaptation-on-Monocular-Video-for-3D-Human-Mesh-Reconstruction"><a href="#Cyclic-Test-Time-Adaptation-on-Monocular-Video-for-3D-Human-Mesh-Reconstruction" class="headerlink" title="Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction"></a>Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06554">http://arxiv.org/abs/2308.06554</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hygenie1228/cycleadapt_release">https://github.com/hygenie1228/cycleadapt_release</a></li>
<li>paper_authors: Hyeongjin Nam, Daniel Sungho Jung, Yeonguk Oh, Kyoung Mu Lee</li>
<li>for:  addresses the domain gap problem in 3D human mesh reconstruction by proposing a cyclic adaptation method that leverages both 2D and 3D evidence.</li>
<li>methods:  the proposed method consists of two networks: a human mesh reconstruction network (HMRNet) and a human motion denoising network (MDNet), which are cyclically adapted given a test video. The 3D supervision targets generated by MDNet are used to fully supervise HMRNet, reducing the reliance on 2D evidence.</li>
<li>results:  the proposed method achieves state-of-the-art performance compared to previous test-time adaptation methods, demonstrating the effectiveness of the cyclic adaptation scheme in addressing the domain gap problem.<details>
<summary>Abstract</summary>
Despite recent advances in 3D human mesh reconstruction, domain gap between training and test data is still a major challenge. Several prior works tackle the domain gap problem via test-time adaptation that fine-tunes a network relying on 2D evidence (e.g., 2D human keypoints) from test images. However, the high reliance on 2D evidence during adaptation causes two major issues. First, 2D evidence induces depth ambiguity, preventing the learning of accurate 3D human geometry. Second, 2D evidence is noisy or partially non-existent during test time, and such imperfect 2D evidence leads to erroneous adaptation. To overcome the above issues, we introduce CycleAdapt, which cyclically adapts two networks: a human mesh reconstruction network (HMRNet) and a human motion denoising network (MDNet), given a test video. In our framework, to alleviate high reliance on 2D evidence, we fully supervise HMRNet with generated 3D supervision targets by MDNet. Our cyclic adaptation scheme progressively elaborates the 3D supervision targets, which compensate for imperfect 2D evidence. As a result, our CycleAdapt achieves state-of-the-art performance compared to previous test-time adaptation methods. The codes are available at https://github.com/hygenie1228/CycleAdapt_RELEASE.
</details>
<details>
<summary>摘要</summary>
尽管最近的3D人体渲染技术得到了进步，但域外差问题仍然是主要挑战。一些先前的工作通过测试时适应来解决域外差问题，但高度依赖于2D证据（例如2D人体关键点）的适应会导致两个主要问题。首先，2D证据引入深度不确定性，阻碍学习准确的3D人体几何学。其次，2D证据在测试时可能受到噪声或部分损失，这会导致错误的适应。为解决以上问题，我们介绍了CyclesAdapt，它将两个网络——人体渲染网络（HMRNet）和人体动作净化网络（MDNet）——在测试视频基础上进行循环适应。在我们的框架中，为了减少依赖于2D证据，我们完全supervise HMRNet 的生成3D目标，使其能够学习准确的3D人体几何学。我们的循环适应方案逐渐填充3D目标，以补做受到噪声或部分损失的2D证据。因此，我们的CyclesAdapt可以与之前的测试时适应方法相比，实现最新的表现。代码可以在https://github.com/hygenie1228/CycleAdapt_RELEASE 中找到。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Vision-Transformer-from-the-View-of-Path-Ensemble"><a href="#Revisiting-Vision-Transformer-from-the-View-of-Path-Ensemble" class="headerlink" title="Revisiting Vision Transformer from the View of Path Ensemble"></a>Revisiting Vision Transformer from the View of Path Ensemble</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06548">http://arxiv.org/abs/2308.06548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuning Chang, Pichao Wang, Hao Luo, Fan Wang, Mike Zheng Shou</li>
<li>for: 本文提出了一种新的视点，认为 transformer 层可以被看作是多个并行的路径 ensemble network。</li>
<li>methods: 将传统的多头自注意力（MSA）和Feed Forward Network（FFN）替换为三个并行的路径，并使用 identify connection 将这些路径转换为明确的多路ensemble network。</li>
<li>results: 通过调查每个路径对最终预测的影响，发现一些路径甚至会降低性能。因此，提出了路径裁剪和 EnsembleScale 技术来优化路径组合，以便允许短路专注提供高质量表示。此外，通过自馈沟通来增强 paths 服务后续路径的表示。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) are normally regarded as a stack of transformer layers. In this work, we propose a novel view of ViTs showing that they can be seen as ensemble networks containing multiple parallel paths with different lengths. Specifically, we equivalently transform the traditional cascade of multi-head self-attention (MSA) and feed-forward network (FFN) into three parallel paths in each transformer layer. Then, we utilize the identity connection in our new transformer form and further transform the ViT into an explicit multi-path ensemble network. From the new perspective, these paths perform two functions: the first is to provide the feature for the classifier directly, and the second is to provide the lower-level feature representation for subsequent longer paths. We investigate the influence of each path for the final prediction and discover that some paths even pull down the performance. Therefore, we propose the path pruning and EnsembleScale skills for improvement, which cut out the underperforming paths and re-weight the ensemble components, respectively, to optimize the path combination and make the short paths focus on providing high-quality representation for subsequent paths. We also demonstrate that our path combination strategies can help ViTs go deeper and act as high-pass filters to filter out partial low-frequency signals. To further enhance the representation of paths served for subsequent paths, self-distillation is applied to transfer knowledge from the long paths to the short paths. This work calls for more future research to explain and design ViTs from new perspectives.
</details>
<details>
<summary>摘要</summary>
视transformer（ViT）通常被看作是一 stack of transformer层。在这项工作中，我们提出了一种新的视图，显示了ViT可以被看作是一个多路网络，每个层包含多个平行的路径。 Specifically, we可以将传统的多头自注意（MSA）和Feed-Forward Network（FFN）转化为每个transformer层中的三个平行路径。然后，我们利用我们新的transformer形式中的标识连接，并将ViT转化为一个显式多路ensemble网络。从这种新的视角来看，这些路径在两个功能：第一是提供分类器所需的特征，第二是提供后续更长的路径所需的下一个特征表示。我们调查每个路径对最终预测的影响，发现一些路径甚至会降低性能。因此，我们提出了路径剔除和EnsembleScale技巧来优化路径组合，即将不良表现的路径剔除，并重新权重ensemble组件。我们还证明了我们的路径组合策略可以帮助ViT深入探索，并作为高通过滤器来过滤部分低频信号。为了进一步增强路径服务后续路径的表示，我们应用了自适应知识传递，将长路径中的知识传递给短路径。这项工作呼吁了更多的未来研究，以解释和设计ViT从新的视角。
</details></li>
</ul>
<hr>
<h2 id="SegPrompt-Boosting-Open-world-Segmentation-via-Category-level-Prompt-Learning"><a href="#SegPrompt-Boosting-Open-world-Segmentation-via-Category-level-Prompt-Learning" class="headerlink" title="SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning"></a>SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06531">http://arxiv.org/abs/2308.06531</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aim-uofa/segprompt">https://github.com/aim-uofa/segprompt</a></li>
<li>paper_authors: Muzhi Zhu, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, Chenchen Jing, Yifan Liu, Chunhua Shen</li>
<li>for: 提高closed-set实例分割模型对未知类别的检测能力</li>
<li>methods: 使用类别信息进行训练 Mechanism，提高模型对已知和未知类别的检测能力</li>
<li>results: 在新的开放世界数据集上，SegPrompt可以提高总和未知检测性能by 5.6%和6.1%，而无需影响推理效率。在 existed cross-dataset transfer和强烈监督设置下，我们的方法也得到了5.5%和12.3%的相对改进。<details>
<summary>Abstract</summary>
Current closed-set instance segmentation models rely on pre-defined class labels for each mask during training and evaluation, largely limiting their ability to detect novel objects. Open-world instance segmentation (OWIS) models address this challenge by detecting unknown objects in a class-agnostic manner. However, previous OWIS approaches completely erase category information during training to keep the model's ability to generalize to unknown objects. In this work, we propose a novel training mechanism termed SegPrompt that uses category information to improve the model's class-agnostic segmentation ability for both known and unknown categories. In addition, the previous OWIS training setting exposes the unknown classes to the training set and brings information leakage, which is unreasonable in the real world. Therefore, we provide a new open-world benchmark closer to a real-world scenario by dividing the dataset classes into known-seen-unseen parts. For the first time, we focus on the model's ability to discover objects that never appear in the training set images.   Experiments show that SegPrompt can improve the overall and unseen detection performance by 5.6% and 6.1% in AR on our new benchmark without affecting the inference efficiency. We further demonstrate the effectiveness of our method on existing cross-dataset transfer and strongly supervised settings, leading to 5.5% and 12.3% relative improvement.
</details>
<details>
<summary>摘要</summary>
当前的闭erset实例分割模型依赖于在训练和评估中预先定义的类标签，这限制了它们的能力检测新的对象。开放世界实例分割（OWIS）模型解决了这个挑战，它在无类别情况下检测未知对象。然而，前一些OWIS方法完全抹除了类型信息在训练中，以保持模型对未知类型的泛化能力。在这种情况下，我们提出了一种新的训练机制，称为SegPrompt，它使用类型信息来提高模型在已知和未知类型之间的无类别分割能力。此外，前一些OWIS训练设置会泄露信息，这不符合实际世界的情况。因此，我们提供了一个更加真实的开放世界 benchmark，将数据集分为已知、未seen和未知三部分。我们首次关注模型能够在训练集图像中不出现的对象检测能力。实验结果显示，SegPrompt可以在AR上提高总和未seen检测性能5.6%和6.1%，而不影响推理效率。我们还证明我们的方法在现有的跨数据集转移和强烈监督设置下有5.5%和12.3%的相对改进。
</details></li>
</ul>
<hr>
<h2 id="BEV-DG-Cross-Modal-Learning-under-Bird’s-Eye-View-for-Domain-Generalization-of-3D-Semantic-Segmentation"><a href="#BEV-DG-Cross-Modal-Learning-under-Bird’s-Eye-View-for-Domain-Generalization-of-3D-Semantic-Segmentation" class="headerlink" title="BEV-DG: Cross-Modal Learning under Bird’s-Eye View for Domain Generalization of 3D Semantic Segmentation"></a>BEV-DG: Cross-Modal Learning under Bird’s-Eye View for Domain Generalization of 3D Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06530">http://arxiv.org/abs/2308.06530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miaoyu Li, Yachao Zhang, Xu MA, Yanyun Qu, Yun Fu</li>
<li>for: 这篇论文旨在提高频率域执行3D semantic segmentation的预测性和灵活性，并且在新的频率域中进行预测，而不需要训练数据集。</li>
<li>methods: 这篇论文提出了一种基于鸟瞰看的cross-modal learning架构，具有更高的错误耐受性和稳定性，并且可以实现频率域内的预测。</li>
<li>results: 这篇论文透过三个不同的3D数据集进行评估，结果显示BEV-DG在所有设定中具有显著的性能优势，与现有的竞争者相比，BEV-DG的性能优势为10%左右。<details>
<summary>Abstract</summary>
Cross-modal Unsupervised Domain Adaptation (UDA) aims to exploit the complementarity of 2D-3D data to overcome the lack of annotation in a new domain. However, UDA methods rely on access to the target domain during training, meaning the trained model only works in a specific target domain. In light of this, we propose cross-modal learning under bird's-eye view for Domain Generalization (DG) of 3D semantic segmentation, called BEV-DG. DG is more challenging because the model cannot access the target domain during training, meaning it needs to rely on cross-modal learning to alleviate the domain gap. Since 3D semantic segmentation requires the classification of each point, existing cross-modal learning is directly conducted point-to-point, which is sensitive to the misalignment in projections between pixels and points. To this end, our approach aims to optimize domain-irrelevant representation modeling with the aid of cross-modal learning under bird's-eye view. We propose BEV-based Area-to-area Fusion (BAF) to conduct cross-modal learning under bird's-eye view, which has a higher fault tolerance for point-level misalignment. Furthermore, to model domain-irrelevant representations, we propose BEV-driven Domain Contrastive Learning (BDCL) with the help of cross-modal learning under bird's-eye view. We design three domain generalization settings based on three 3D datasets, and BEV-DG significantly outperforms state-of-the-art competitors with tremendous margins in all settings.
</details>
<details>
<summary>摘要</summary>
cross-modal无监督领域适应（UDA）目标是利用2D-3D数据的补充性来缺乏目标领域的标注。然而，UDA方法需要训练时有Target领域的存在，因此训练的模型只能在特定的Target领域中工作。为了解决这个问题，我们提出了基于鸟瞰视的cross-modal学习 для领域总结（DG）的3D语义分割，称为BEV-DG。DG比UDA更加困难，因为模型在训练时无法访问目标领域，因此它需要通过cross-modal学习来减少领域差距。由于3D语义分割需要每个点的分类，现有的cross-modal学习是直接进行点对点的，这是 projection between pixels and points 的不一致敏感。为此，我们的方法是通过cross-modal学习下鸟瞰视模型化领域无关表示，使用BEV-based Area-to-area Fusion（BAF）来进行cross-modal学习，这种方法具有更高的错误忍容度。此外，我们还提出了基于鸟瞰视的BEV-driven Domain Contrastive Learning（BDCL），通过cross-modal学习来模型领域无关表示。我们设计了基于三个3D数据集的三个领域总结设置，BEV-DG在所有设置中都以很大的优势超越了当前的竞争对手。
</details></li>
</ul>
<hr>
<h2 id="Seed-Feature-Maps-based-CNN-Models-for-LEO-Satellite-Remote-Sensing-Services"><a href="#Seed-Feature-Maps-based-CNN-Models-for-LEO-Satellite-Remote-Sensing-Services" class="headerlink" title="Seed Feature Maps-based CNN Models for LEO Satellite Remote Sensing Services"></a>Seed Feature Maps-based CNN Models for LEO Satellite Remote Sensing Services</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06515">http://arxiv.org/abs/2308.06515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Lu, Chuntao Ding, Shangguang Wang, Ran Cheng, Felix Juefei-Xu, Vishnu Naresh Boddeti</li>
<li>for: 这篇研究是为了提出一个基于ground-station server的框架，以实现高性能的卷积神经网络模型在低地球轨道（LEO）卫星上的快速遥测图像处理。</li>
<li>methods: 本研究使用了一个基于seed feature map的框架，具体是每个层的卷积神经网络模型仅包含一个可学习的特征图（seed feature map），并通过特定规律生成其他特征图。此外，这个框架还使用了Random Hyperparameter Generation（RHG）技术，实现在LEO卫星上更新卷积神经网络模型。</li>
<li>results: 实验结果显示，提出的框架可以与现有的State-of-the-art方法相比，在ISPRS Vaihingen、ISPRS Potsdam、UAVid和LoveDA等数据集上实现更高的mIoU，特别是在UAVid数据集上，SineFM-based模型的mIoU高于UNetFormer，仅使用3.3倍少的参数和2.2倍少的FLOPs。<details>
<summary>Abstract</summary>
Deploying high-performance convolutional neural network (CNN) models on low-earth orbit (LEO) satellites for rapid remote sensing image processing has attracted significant interest from industry and academia. However, the limited resources available on LEO satellites contrast with the demands of resource-intensive CNN models, necessitating the adoption of ground-station server assistance for training and updating these models. Existing approaches often require large floating-point operations (FLOPs) and substantial model parameter transmissions, presenting considerable challenges. To address these issues, this paper introduces a ground-station server-assisted framework. With the proposed framework, each layer of the CNN model contains only one learnable feature map (called the seed feature map) from which other feature maps are generated based on specific rules. The hyperparameters of these rules are randomly generated instead of being trained, thus enabling the generation of multiple feature maps from the seed feature map and significantly reducing FLOPs. Furthermore, since the random hyperparameters can be saved using a few random seeds, the ground station server assistance can be facilitated in updating the CNN model deployed on the LEO satellite. Experimental results on the ISPRS Vaihingen, ISPRS Potsdam, UAVid, and LoveDA datasets for semantic segmentation services demonstrate that the proposed framework outperforms existing state-of-the-art approaches. In particular, the SineFM-based model achieves a higher mIoU than the UNetFormer on the UAVid dataset, with 3.3x fewer parameters and 2.2x fewer FLOPs.
</details>
<details>
<summary>摘要</summary>
deploying high-performance convolutional neural network (CNN) models on low-earth orbit (LEO) satellites for rapid remote sensing image processing has attracted significant interest from industry and academia. However, the limited resources available on LEO satellites contrast with the demands of resource-intensive CNN models, necessitating the adoption of ground-station server assistance for training and updating these models. existing approaches often require large floating-point operations (FLOPs) and substantial model parameter transmissions, presenting considerable challenges. to address these issues, this paper introduces a ground-station server-assisted framework. with the proposed framework, each layer of the CNN model contains only one learnable feature map (called the seed feature map) from which other feature maps are generated based on specific rules. the hyperparameters of these rules are randomly generated instead of being trained, thus enabling the generation of multiple feature maps from the seed feature map and significantly reducing FLOPs. furthermore, since the random hyperparameters can be saved using a few random seeds, the ground station server assistance can be facilitated in updating the CNN model deployed on the LEO satellite. experimental results on the ISPRS Vaihingen, ISPRS Potsdam, UAVid, and LoveDA datasets for semantic segmentation services demonstrate that the proposed framework outperforms existing state-of-the-art approaches. in particular, the SineFM-based model achieves a higher mIoU than the UNetFormer on the UAVid dataset, with 3.3x fewer parameters and 2.2x fewer FLOPs.
</details></li>
</ul>
<hr>
<h2 id="Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection"><a href="#Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection" class="headerlink" title="Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection"></a>Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06481">http://arxiv.org/abs/2308.06481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alvaro Fernandez-Quilez, Linas Vidziunas, Ørjan Kløvfjell Thoresen, Ketil Oppedal, Svein Reidar Kjosavik, Trygve Eftestøl</li>
<li>for: 这篇论文目的是为了提出一种基于对外域检测的潜在医疗影像识别方法，并且运用不同T2w方向的多条流进行检测，以提高肝癌潜在病变检测的精确度。</li>
<li>methods: 本论文使用的方法包括对外域检测和多条流方法，以探索肝癌潜在病变检测的可能性。</li>
<li>results: 本论文的结果显示，使用多条流方法可以提高肝癌潜在病变检测的精确度，并且在一个公共可用数据集上获得了更高的检测精确度（AUC），具体为73.1%和82.3%之间。<details>
<summary>Abstract</summary>
Traditional deep learning (DL) approaches based on supervised learning paradigms require large amounts of annotated data that are rarely available in the medical domain. Unsupervised Out-of-distribution (OOD) detection is an alternative that requires less annotated data. Further, OOD applications exploit the class skewness commonly present in medical data. Magnetic resonance imaging (MRI) has proven to be useful for prostate cancer (PCa) diagnosis and management, but current DL approaches rely on T2w axial MRI, which suffers from low out-of-plane resolution. We propose a multi-stream approach to accommodate different T2w directions to improve the performance of PCa lesion detection in an OOD approach. We evaluate our approach on a publicly available data-set, obtaining better detection results in terms of AUC when compared to a single direction approach (73.1 vs 82.3). Our results show the potential of OOD approaches for PCa lesion detection based on MRI.
</details>
<details>
<summary>摘要</summary>
传统的深度学习（DL）方法基于指导学习 paradigma需要大量的标注数据，而这些数据在医疗领域很难获得。不supervised Out-of-distribution（OOD）检测是一种alternative，它需要更少的标注数据。另外，OOD应用可以利用医疗数据的类偏好。核磁共振成像（MRI）已经证明是肠癌（PCa）诊断和管理的有用工具，但当前的DL方法仅仅采用T2w极向MRI，这会受到低外平面分辨率的限制。我们提议一种多流程approach来满足不同的T2w方向，以提高PCa患部检测的性能。我们对公共可用数据集进行评估，并获得了与单向approach相比的更好的检测结果（AUC=73.1 vs AUC=82.3）。我们的结果表明OOD方法在MRI上进行PCa患部检测具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach"><a href="#Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach" class="headerlink" title="Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach"></a>Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06477">http://arxiv.org/abs/2308.06477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Nikolass Lindeijer, Tord Martin Ytredal, Trygve Eftestøl, Tobias Nordström, Fredrik Jäderling, Martin Eklund, Alvaro Fernandez-Quilez</li>
<li>for: 提高 automatic prostate segmentation 的精度和可靠性，使用 multi-view MRI 数据和 contrastive learning 技术。</li>
<li>methods: 提posed 一种 triplet encoder and single decoder network 基于 U-Net，称为 tU-Net (triplet U-Net)，可以利用不需要注意力的 sagittal 和 coronal 视图来提高 segmentation 的精度。</li>
<li>results: tU-Net 显示在 dice score 指标上 statistically 提高了精度 (91.25+-0.52% 比 86.40+-1.50%,P&lt;.001)，并且在不同视图的数据上进行了可靠的总体骨骼变换。<details>
<summary>Abstract</summary>
An accurate prostate delineation and volume characterization can support the clinical assessment of prostate cancer. A large amount of automatic prostate segmentation tools consider exclusively the axial MRI direction in spite of the availability as per acquisition protocols of multi-view data. Further, when multi-view data is exploited, manual annotations and availability at test time for all the views is commonly assumed. In this work, we explore a contrastive approach at training time to leverage multi-view data without annotations and provide flexibility at deployment time in the event of missing views. We propose a triplet encoder and single decoder network based on U-Net, tU-Net (triplet U-Net). Our proposed architecture is able to exploit non-annotated sagittal and coronal views via contrastive learning to improve the segmentation from a volumetric perspective. For that purpose, we introduce the concept of inter-view similarity in the latent space. To guide the training, we combine a dice score loss calculated with respect to the axial view and its manual annotations together with a multi-view contrastive loss. tU-Net shows statistical improvement in dice score coefficient (DSC) with respect to only axial view (91.25+-0.52% compared to 86.40+-1.50%,P<.001). Sensitivity analysis reveals the volumetric positive impact of the contrastive loss when paired with tU-Net (2.85+-1.34% compared to 3.81+-1.88%,P<.001). Further, our approach shows good external volumetric generalization in an in-house dataset when tested with multi-view data (2.76+-1.89% compared to 3.92+-3.31%,P=.002), showing the feasibility of exploiting non-annotated multi-view data through contrastive learning whilst providing flexibility at deployment in the event of missing views.
</details>
<details>
<summary>摘要</summary>
通过增强多视图数据的利用，我们提出了一种基于对照学习的三元Encoder-单元网络（tU-Net），用于提高肾脏细分。我们在训练时使用了非标注的架子视图和仰视图，通过对照学习来利用这些视图，从而提高 segmentation 的精度。为了引导训练，我们组合了axial视图和其手动注释的 dice score 损失函数，以及多视图对照损失函数。 results 表明，tU-Net 比只使用axial视图的情况提高了 dice score 系数（DSC）（91.25±0.52% vs 86.40±1.50%,P<0.001）。另外，我们的方法还在不同的混合率下进行了敏感性分析，发现对照学习损失函数对于与 tU-Net 结合使用时产生的卷积效应具有 Statistical significance（2.85±1.34% vs 3.81±1.88%,P<0.001）。此外，我们的方法还在一个自有的数据集上进行了 external volumetric 一致性测试，并发现在使用多视图数据时，tU-Net 的性能较好（2.76±1.89% vs 3.92±3.31%,P=.002），这表明了我们的方法可以在实际应用中利用非标注的多视图数据进行对照学习，并且在部署时可以避免 missing views 的问题。
</details></li>
</ul>
<hr>
<h2 id="Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization"><a href="#Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization" class="headerlink" title="Tiny and Efficient Model for the Edge Detection Generalization"></a>Tiny and Efficient Model for the Edge Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06468">http://arxiv.org/abs/2308.06468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xavysp/teed">https://github.com/xavysp/teed</a></li>
<li>paper_authors: Xavier Soria, Yachuan Li, Mohammad Rouhani, Angel D. Sappa</li>
<li>for: 本文 targets at addressing the issue of edge detection in computer vision, with the objectives of simplicity, efficiency, and generalization.</li>
<li>methods: 本文提出了一种轻量级卷积神经网络（TEED），具有只有58K参数，比现状态 искусственный智能模型少。通过在BIPED dataset上训练，可以在less than 30分钟内完成训练，每个epoch仅需less than 5分钟。</li>
<li>results: 本文的提出的模型可以快速 converges within the first few epochs，并且预测的边映射具有高质量。此外，本文还提出了一个新的测试数据集，用于测试边检测模型的通用性。I hope this helps!<details>
<summary>Abstract</summary>
Most high-level computer vision tasks rely on low-level image operations as their initial processes. Operations such as edge detection, image enhancement, and super-resolution, provide the foundations for higher level image analysis. In this work we address the edge detection considering three main objectives: simplicity, efficiency, and generalization since current state-of-the-art (SOTA) edge detection models are increased in complexity for better accuracy. To achieve this, we present Tiny and Efficient Edge Detector (TEED), a light convolutional neural network with only $58K$ parameters, less than $0.2$% of the state-of-the-art models. Training on the BIPED dataset takes $less than 30 minutes$, with each epoch requiring $less than 5 minutes$. Our proposed model is easy to train and it quickly converges within very first few epochs, while the predicted edge-maps are crisp and of high quality. Additionally, we propose a new dataset to test the generalization of edge detection, which comprises samples from popular images used in edge detection and image segmentation. The source code is available in https://github.com/xavysp/TEED.
</details>
<details>
<summary>摘要</summary>
大多数高级计算机视觉任务都基于低级图像操作作为初始过程。操作如图像提高、图像增强和超分辨率，为更高级图像分析提供基础。在这项工作中，我们考虑了三个主要目标：简单、高效和泛化，因为当前状态体系（SOTA）的边检测模型在精度方面增加了复杂度。为达到这个目标，我们提出了简单高效的边检测器（TEED），这是一个具有58000个参数的轻量级卷积神经网络，比状态体系模型少了99.8%的参数。在BIPE dataset上训练时间只需要少于30分钟，每个epoch只需要少于5分钟。我们的提出的模型轻松训练，快速 converges，并且预测的边映射具有高质量。此外，我们还提出了一个新的测试泛化边检测的数据集，该数据集包括流行的图像used in edge detection和图像分类中的样本。源代码可以在https://github.com/xavysp/TEED上获取。
</details></li>
</ul>
<hr>
<h2 id="Improved-YOLOv8-Detection-Algorithm-in-Security-Inspection-Image"><a href="#Improved-YOLOv8-Detection-Algorithm-in-Security-Inspection-Image" class="headerlink" title="Improved YOLOv8 Detection Algorithm in Security Inspection Image"></a>Improved YOLOv8 Detection Algorithm in Security Inspection Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06452">http://arxiv.org/abs/2308.06452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyao Lu</li>
<li>for: 本研究旨在解决X射线图像检测中的重叠检测对象、假阳性货物检测和检测失败问题。</li>
<li>methods: 本研究提出了基于YOLOv8s的改进X射线财物检测算法CSS-YOLO。</li>
<li>results: 实验结果表明，CSS-YOLO算法能够提高检测精度，降低假阳性率和 missed detection 率，提高安全检查效果。<details>
<summary>Abstract</summary>
Security inspection is the first line of defense to ensure the safety of people's lives and property, and intelligent security inspection is an inevitable trend in the future development of the security inspection industry. Aiming at the problems of overlapping detection objects, false detection of contraband, and missed detection in the process of X-ray image detection, an improved X-ray contraband detection algorithm CSS-YOLO based on YOLOv8s is proposed.
</details>
<details>
<summary>摘要</summary>
安全检查是人们生命和财产安全的首列防御，未来安全检查行业的发展将具有智能化特点。面临检测对象重叠、质控违禁品和检测失败等问题，我们提出了基于YOLOv8s的改进X射线质控检测算法CSS-YOLO。
</details></li>
</ul>
<hr>
<h2 id="TongueSAM-An-Universal-Tongue-Segmentation-Model-Based-on-SAM-with-Zero-Shot"><a href="#TongueSAM-An-Universal-Tongue-Segmentation-Model-Based-on-SAM-with-Zero-Shot" class="headerlink" title="TongueSAM: An Universal Tongue Segmentation Model Based on SAM with Zero-Shot"></a>TongueSAM: An Universal Tongue Segmentation Model Based on SAM with Zero-Shot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06444">http://arxiv.org/abs/2308.06444</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cshan-github/tonguesam">https://github.com/cshan-github/tonguesam</a></li>
<li>paper_authors: Shan Cao, Qunsheng Ruan, Qingfeng Wu</li>
<li>for: 本研究旨在提出一种通用的舌部分 segmentation模型，以解决现有的舌部分 segmentation方法在不同舌型图像上表现 mediocre 的问题。</li>
<li>methods: 本研究使用的是一种名为 SAM（Segment Anything Model）的大规模预训练交互分割模型，该模型具有强大的零shot泛化能力。通过应用 SAM 到舌部分分割，可以实现零shot 分割不同类型的舌型图像。此外，本研究还使用了一种基于对象检测的 Prompt Generator，以实现一个端到端自动化的舌部分分割方法。</li>
<li>results: 实验表明，TongueSAM 在不同舌部分分割数据集上表现出色，特别是在零shot 下表现。此外，TongueSAM 可以 direct 应用于其他数据集无需 fine-tuning。据我们知道，这是首次应用大规模预训练模型于舌部分分割。研究成果和预训练模型将在：<a target="_blank" rel="noopener" href="https://github.com/cshan-github/TongueSAM">https://github.com/cshan-github/TongueSAM</a> 上公布。<details>
<summary>Abstract</summary>
Tongue segmentation serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.
</details>
<details>
<summary>摘要</summary>
叙述分割 serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.Here's the translation in Traditional Chinese: tonguesegmentation serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Optimization-and-Invariant-Representation-Learning-for-Addressing-Subgroup-Underrepresentation-Mechanisms-and-Limitations"><a href="#Distributionally-Robust-Optimization-and-Invariant-Representation-Learning-for-Addressing-Subgroup-Underrepresentation-Mechanisms-and-Limitations" class="headerlink" title="Distributionally Robust Optimization and Invariant Representation Learning for Addressing Subgroup Underrepresentation: Mechanisms and Limitations"></a>Distributionally Robust Optimization and Invariant Representation Learning for Addressing Subgroup Underrepresentation: Mechanisms and Limitations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06434">http://arxiv.org/abs/2308.06434</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilesh Kumar, Ruby Shrestha, Zhiyuan Li, Linwei Wang</li>
<li>For: This paper aims to address the issue of spurious correlation due to subgroup underrepresentation in medical image classification, specifically by exploring the use of robust optimization to learn invariant representations.* Methods: The paper proposes a novel approach that leverages robust optimization to facilitate the learning of invariant representations, and evaluates the effectiveness of this approach through a comprehensive study.* Results: The proposed approach is shown to improve the performance of classifiers on underrepresented subgroups, while maintaining high average and worst-group performance, compared to existing methods such as generalized reweighting and naive invariant representation learning.<details>
<summary>Abstract</summary>
Spurious correlation caused by subgroup underrepresentation has received increasing attention as a source of bias that can be perpetuated by deep neural networks (DNNs). Distributionally robust optimization has shown success in addressing this bias, although the underlying working mechanism mostly relies on upweighting under-performing samples as surrogates for those underrepresented in data. At the same time, while invariant representation learning has been a powerful choice for removing nuisance-sensitive features, it has been little considered in settings where spurious correlations are caused by significant underrepresentation of subgroups. In this paper, we take the first step to better understand and improve the mechanisms for debiasing spurious correlation due to subgroup underrepresentation in medical image classification. Through a comprehensive evaluation study, we first show that 1) generalized reweighting of under-performing samples can be problematic when bias is not the only cause for poor performance, while 2) naive invariant representation learning suffers from spurious correlations itself. We then present a novel approach that leverages robust optimization to facilitate the learning of invariant representations at the presence of spurious correlations. Finetuned classifiers utilizing such representation demonstrated improved abilities to reduce subgroup performance disparity, while maintaining high average and worst-group performance.
</details>
<details>
<summary>摘要</summary>
假设对于小分支的参数不足，导致深度神经网络（DNNs）中的伪正相关。 Distributionally robust optimization 已经在解决这种偏见方面取得成功，但是其主要运作机制是通过增重下performing samples 作为没有在数据中受到代表的样本。 在这篇研究中，我们对对于小分支参数不足导致的伪正相关的推导和改进方法进行了首次的研究。我们首先显示了以下两个结果：1）通过增重下performing samples 并不一定能够解决伪正相关，而2）简单的对称表现学习方法本身受到了伪正相关的影响。我们然后提出了一种新的方法，利用Robust optimization 来促进对伪正相关的推导。我们继续调整这些表现，以便在存在伪正相关的情况下维持高的平均和最差分支性能。
</details></li>
</ul>
<hr>
<h2 id="Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration"><a href="#Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration" class="headerlink" title="Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration"></a>Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06432">http://arxiv.org/abs/2308.06432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Zhang, Kun Huang, Mingchao Li, Songtao Yuan, Qiang Chen</li>
<li>for: 预测 age-related macular degeneration (nAMD) 疾病进程和效果。</li>
<li>methods: 提posed a single-horizon disease evolution network (SHENet)，使用 feature encoder、graph evolution module 和 feature decoder，并通过 adversarial training 确保疾病进程学习的有效性。</li>
<li>results: 与其他生成方法相比，SHENet 生成的 SD-OCT 图像质量最高，同时保持结构保护和内容预测。 Qualitative evaluations 也表明 SHENet 的视觉效果较好。<details>
<summary>Abstract</summary>
Most of the existing disease prediction methods in the field of medical image processing fall into two classes, namely image-to-category predictions and image-to-parameter predictions. Few works have focused on image-to-image predictions. Different from multi-horizon predictions in other fields, ophthalmologists prefer to show more confidence in single-horizon predictions due to the low tolerance of predictive risk. We propose a single-horizon disease evolution network (SHENet) to predictively generate post-therapeutic SD-OCT images by inputting pre-therapeutic SD-OCT images with neovascular age-related macular degeneration (nAMD). In SHENet, a feature encoder converts the input SD-OCT images to deep features, then a graph evolution module predicts the process of disease evolution in high-dimensional latent space and outputs the predicted deep features, and lastly, feature decoder recovers the predicted deep features to SD-OCT images. We further propose an evolution reinforcement module to ensure the effectiveness of disease evolution learning and obtain realistic SD-OCT images by adversarial training. SHENet is validated on 383 SD-OCT cubes of 22 nAMD patients based on three well-designed schemes based on the quantitative and qualitative evaluations. Compared with other generative methods, the generative SD-OCT images of SHENet have the highest image quality. Besides, SHENet achieves the best structure protection and content prediction. Qualitative evaluations also demonstrate that SHENet has a better visual effect than other methods. SHENet can generate post-therapeutic SD-OCT images with both high prediction performance and good image quality, which has great potential to help ophthalmologists forecast the therapeutic effect of nAMD.
</details>
<details>
<summary>摘要</summary>
现有的疾病预测方法在医学图像处理领域主要分为两类：图像到类别预测和图像到参数预测，其中少数工作关注到图像到图像预测。与其他多个预测horizon不同，眼科医生更偏好单个预测horizon，因为预测风险的低忍性。我们提出了单个预测疾病演化网络（SHENet），用于预测基于前治疗SD-OCT图像的后治疗SD-OCT图像。在SHENet中，一个特征编码器将输入SD-OCT图像转化为深度特征，然后一个图像演化模块预测疾病演化过程在高维潜在空间中，并输出预测的深度特征。最后，特征解码器重建预测的深度特征为SD-OCT图像。我们还提出了演化增强模块，以确保疾病演化学习的有效性并获得真实的SD-OCT图像，通过对抗训练。SHENet在383个SD-OCT立方体上的22例nAMD患者基于三种有效的方案进行验证，并通过量化和质量评估。与其他生成方法相比，SHENet生成的SD-OCT图像的生成质量最高。此外，SHENet保持了最佳的结构保护和内容预测。质量评估还表明，SHENet在视觉效果方面表现更好。SHENet可以预测nAMD后治疗SD-OCT图像，具有高预测性和良好的图像质量，这对眼科医生预测nAMD治疗效果具有很大潜力。
</details></li>
</ul>
<hr>
<h2 id="M-M-Tackling-False-Positives-in-Mammography-with-a-Multi-view-and-Multi-instance-Learning-Sparse-Detector"><a href="#M-M-Tackling-False-Positives-in-Mammography-with-a-Multi-view-and-Multi-instance-Learning-Sparse-Detector" class="headerlink" title="M&amp;M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector"></a>M&amp;M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06420">http://arxiv.org/abs/2308.06420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yen Nhi Truong Vu, Dan Guo, Ahmed Taha, Jason Su, Thomas Paul Matthews</li>
<li>for: 提高诊断率和避免假阳性结果</li>
<li>methods: 使用 sparse R-CNN，包括多视图交叉注意模块和多实例学习</li>
<li>results: 提高了检测和预测性能，并通过精细的ablation study证明每个组件的效果<details>
<summary>Abstract</summary>
Deep-learning-based object detection methods show promise for improving screening mammography, but high rates of false positives can hinder their effectiveness in clinical practice. To reduce false positives, we identify three challenges: (1) unlike natural images, a malignant mammogram typically contains only one malignant finding; (2) mammography exams contain two views of each breast, and both views ought to be considered to make a correct assessment; (3) most mammograms are negative and do not contain any findings. In this work, we tackle the three aforementioned challenges by: (1) leveraging Sparse R-CNN and showing that sparse detectors are more appropriate than dense detectors for mammography; (2) including a multi-view cross-attention module to synthesize information from different views; (3) incorporating multi-instance learning (MIL) to train with unannotated images and perform breast-level classification. The resulting model, M&M, is a Multi-view and Multi-instance learning system that can both localize malignant findings and provide breast-level predictions. We validate M&M's detection and classification performance using five mammography datasets. In addition, we demonstrate the effectiveness of each proposed component through comprehensive ablation studies.
</details>
<details>
<summary>摘要</summary>
深度学习基于对象检测方法在萤幕检查中显示出优秀表现，但高 false positive 率可能会阻碍其在临床实践中的效iveness。为了减少 false positive，我们标识了三个挑战：（1）癌症肺像素通常只包含一个癌症发现;（2）萤幕检查包括两个视图每一个乳腺，需要考虑两个视图来确定正确的评估;（3）大多数萤幕检查为正常图像，没有任何发现。在这种情况下，我们解决了这三个挑战，通过：（1）利用稀疏 R-CNN，并证明稀疏检测器更适合萤幕检查;（2）添加多视图交叉注意模块，以将不同视图的信息相互协同;（3）采用多例学习（MIL），以使用无注释图像进行训练，并在乳腺级别进行预测。得到的模型称为 M&M，它可以同时localize 癌症发现和进行乳腺级别预测。我们验证 M&M 的检测和预测性能使用五个萤幕检查 dataset。此外，我们还通过完整的减少研究，证明每一个提案的效果。
</details></li>
</ul>
<hr>
<h2 id="Improving-Pseudo-Labels-for-Open-Vocabulary-Object-Detection"><a href="#Improving-Pseudo-Labels-for-Open-Vocabulary-Object-Detection" class="headerlink" title="Improving Pseudo Labels for Open-Vocabulary Object Detection"></a>Improving Pseudo Labels for Open-Vocabulary Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06412">http://arxiv.org/abs/2308.06412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyu Zhao, Samuel Schulter, Long Zhao, Zhixing Zhang, Vijay Kumar B. G, Yumin Suh, Manmohan Chandraker, Dimitris N. Metaxas</li>
<li>for: 提高开放词汇物体检测（OVD）中使用预先训练的视觉语言模型（VLM）生成的假标签（PL）的性能。</li>
<li>methods: 提出在线自我训练和拆分并融合头（SAS-Det）方法，包括自我训练VLMs生成高质量PL，并利用拆分并融合头除去PL的地方噪声，同时 fusion complementary knowledge learned from precise ground truth和噪声PL。</li>
<li>results: 在COCO和LVISbenchmark上 achieved 37.4 AP$_{50}$和27.3 AP$_r$，胜过先前的状态艺术模型，并且 Pseudo labeling 速度比过去的方法快三倍。<details>
<summary>Abstract</summary>
Recent studies show promising performance in open-vocabulary object detection (OVD) using pseudo labels (PLs) from pretrained vision and language models (VLMs). However, PLs generated by VLMs are extremely noisy due to the gap between the pretraining objective of VLMs and OVD, which blocks further advances on PLs. In this paper, we aim to reduce the noise in PLs and propose a method called online Self-training And a Split-and-fusion head for OVD (SAS-Det). First, the self-training finetunes VLMs to generate high quality PLs while prevents forgetting the knowledge learned in the pretraining. Second, a split-and-fusion (SAF) head is designed to remove the noise in localization of PLs, which is usually ignored in existing methods. It also fuses complementary knowledge learned from both precise ground truth and noisy pseudo labels to boost the performance. Extensive experiments demonstrate SAS-Det is both efficient and effective. Our pseudo labeling is 3 times faster than prior methods. SAS-Det outperforms prior state-of-the-art models of the same scale by a clear margin and achieves 37.4 AP$_{50}$ and 27.3 AP$_r$ on novel categories of the COCO and LVIS benchmarks, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models"><a href="#Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models" class="headerlink" title="Detecting and Preventing Hallucinations in Large Vision Language Models"></a>Detecting and Preventing Hallucinations in Large Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06394">http://arxiv.org/abs/2308.06394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anisha Gunjal, Jihan Yin, Erhan Bas<br>for:The paper aims to address the issue of hallucinations in instruction-tuned large vision language models (LVLMs) for visual question answering (VQA).methods:The authors introduce a new dataset called M-HalDetect, which consists of 16,000 fine-grained annotations on VQA examples to train and benchmark models for hallucination detection and prevention. They also propose a novel optimization method called Fine-grained Direct Preference Optimization (FDPO) to reduce hallucinations in LVLMs.results:The authors evaluate the effectiveness of M-HalDetect and FDPO using human evaluation and find that they reduce hallucination rates in InstructBLIP by 41% and 55%, respectively. They also find that their reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57%, respectively, and has strong correlation with human evaluated accuracy scores.<details>
<summary>Abstract</summary>
Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a (M)ultimodal (Hal)lucination (Detect)ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling. We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores.
</details>
<details>
<summary>摘要</summary>
干脆大视语言模型（LVLM）在多modal任务上 generalized 了，特别是对于视觉问答（VQA）。然而，生成视觉固有的回答仍然是current state-of-the-art LVLMs（InstructBLIP）中的挑战。我们发现，甚至当前最佳LVLMs中还有30%的hallucination text，包括不存在的物体、不准确的描述和关系。为了解决这个问题，我们提出了M-HalDetect数据集，可以用于训练和对比模型，以检测和避免hallucination。M-HalDetect包括16k精细的VQA示例注释，使其成为首个多modal hallucination detection数据集。不同于之前的工作，我们不仅考虑物体hallucination，还注释了不准确的实体描述和关系。为了证明M-HalDetect的可用性，我们对InstructBLIP进行了novel Fine-grained Direct Preference Optimization（FDPO）优化。我们还使用InstructBLIP中的精细多modal奖励模型进行训练，并使用best-of-n拒绝采样来评估其效果。我们对FDPO和拒绝采样进行了人工评估，发现它们可以降低InstructBLIP中的hallucination率41%和55%。此外，我们发现我们的奖励模型可以普适化到其他多modal模型，降低LLaVA和mPLUG-OWL中的hallucination率15%和57%，并与人类评估精度成对。
</details></li>
</ul>
<hr>
<h2 id="R2S100K-Road-Region-Segmentation-Dataset-For-Semi-Supervised-Autonomous-Driving-in-the-Wild"><a href="#R2S100K-Road-Region-Segmentation-Dataset-For-Semi-Supervised-Autonomous-Driving-in-the-Wild" class="headerlink" title="R2S100K: Road-Region Segmentation Dataset For Semi-Supervised Autonomous Driving in the Wild"></a>R2S100K: Road-Region Segmentation Dataset For Semi-Supervised Autonomous Driving in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06393">http://arxiv.org/abs/2308.06393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Atif Butt, Hassan Ali, Adnan Qayyum, Waqas Sultani, Ala Al-Fuqaha, Junaid Qadir</li>
<li>for: 这项研究的目的是提供一个大规模的、多样化的道路区域分割数据集，以便为自动驾驶技术的发展提供更好的支持。</li>
<li>methods: 这项研究使用了一种名为Efficient Data Sampling（EDS）的自我教学框架，通过利用无标注数据来提高学习效果，同时还使用了 semi-supervised learning 方法。</li>
<li>results: 实验结果表明，提出的方法可以显著改善 semantic segmentation 任务的泛化能力，同时也可以降低标注成本。<details>
<summary>Abstract</summary>
Semantic understanding of roadways is a key enabling factor for safe autonomous driving. However, existing autonomous driving datasets provide well-structured urban roads while ignoring unstructured roadways containing distress, potholes, water puddles, and various kinds of road patches i.e., earthen, gravel etc. To this end, we introduce Road Region Segmentation dataset (R2S100K) -- a large-scale dataset and benchmark for training and evaluation of road segmentation in aforementioned challenging unstructured roadways. R2S100K comprises 100K images extracted from a large and diverse set of video sequences covering more than 1000 KM of roadways. Out of these 100K privacy respecting images, 14,000 images have fine pixel-labeling of road regions, with 86,000 unlabeled images that can be leveraged through semi-supervised learning methods. Alongside, we present an Efficient Data Sampling (EDS) based self-training framework to improve learning by leveraging unlabeled data. Our experimental results demonstrate that the proposed method significantly improves learning methods in generalizability and reduces the labeling cost for semantic segmentation tasks. Our benchmark will be publicly available to facilitate future research at https://r2s100k.github.io/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>路径理解是自驾投控车中关键的能力因素。然而，现有的自驾投控车数据集只提供了有效的城市路径，而忽略了不结构化的路径中的压力、沟壑、水泥等等。为此，我们介绍了路径区域分割数据集（R2S100K）——一个大规模的数据集和标准 для训练和评估路径分割在上述挑战性的路径上。R2S100K包含100K张图像，其中14,000张图像有细腻的像素标注路径区域，剩下86,000张图像可以通过半有结构学习方法进行利用。此外，我们提出了一种效率的数据采样（EDS）基于的自动训练框架，以提高学习的通用性和减少标注成本。我们的实验结果表明，提posed方法可以显著提高学习方法的通用性和减少标注成本。我们的标准将在https://r2s100k.github.io/上公开，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="U-RED-Unsupervised-3D-Shape-Retrieval-and-Deformation-for-Partial-Point-Clouds"><a href="#U-RED-Unsupervised-3D-Shape-Retrieval-and-Deformation-for-Partial-Point-Clouds" class="headerlink" title="U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds"></a>U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06383">http://arxiv.org/abs/2308.06383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangcyg/u-red">https://github.com/zhangcyg/u-red</a></li>
<li>paper_authors: Yan Di, Chenyangguang Zhang, Ruida Zhang, Fabian Manhardt, Yongzhi Su, Jason Rambach, Didier Stricker, Xiangyang Ji, Federico Tombari</li>
<li>for: 本文提出了一种不supervised shape retrieval和扭形管道，用于从已有的CAD模型库中检索和扭形匹配目标对象。</li>
<li>methods: 该管道使用了一种新的点级差异指导度量来抗随机变量，并通过将所有可能的全形对象投影到单位球面上来处理一个部分观察的一对多关系。</li>
<li>results: 在PartNet、ComplementMe和Scan2CAD等 sintetic和实际数据集上，U-RED比前状态艺术方法提高47.3%、16.7%和31.6%。<details>
<summary>Abstract</summary>
In this paper, we propose U-RED, an Unsupervised shape REtrieval and Deformation pipeline that takes an arbitrary object observation as input, typically captured by RGB images or scans, and jointly retrieves and deforms the geometrically similar CAD models from a pre-established database to tightly match the target. Considering existing methods typically fail to handle noisy partial observations, U-RED is designed to address this issue from two aspects. First, since one partial shape may correspond to multiple potential full shapes, the retrieval method must allow such an ambiguous one-to-many relationship. Thereby U-RED learns to project all possible full shapes of a partial target onto the surface of a unit sphere. Then during inference, each sampling on the sphere will yield a feasible retrieval. Second, since real-world partial observations usually contain noticeable noise, a reliable learned metric that measures the similarity between shapes is necessary for stable retrieval. In U-RED, we design a novel point-wise residual-guided metric that allows noise-robust comparison. Extensive experiments on the synthetic datasets PartNet, ComplementMe and the real-world dataset Scan2CAD demonstrate that U-RED surpasses existing state-of-the-art approaches by 47.3%, 16.7% and 31.6% respectively under Chamfer Distance.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了无监督的形状检索和扭曲管道（U-RED），它可以将从RGB图像或扫描得到的任意物体观察作为输入，并将相似的CAD模型从预设的数据库中检索出来，以便与目标物体紧密匹配。现有的方法通常无法处理干扰性的部分观察，因此U-RED在两个方面进行了改进。首先，由于一个部分形状可能对应多个可能的全形状，因此检索方法必须允许这种杂乱的一对多关系。U-RED通过将所有可能的全形状 проек到单位球上来解决这个问题。然后，在推理时，每个样本在球上的抽象都将产生一个可能的检索。其次，由于实际的部分观察通常含有显著的干扰，因此需要一个可靠的学习的形状相似度量表，以确保稳定的检索。在U-RED中，我们设计了一种新的点级差异导向的形状相似度量表，允许比较干扰的形状。我们在PartNet、ComplementMe和Scan2CAD等 sintetic和实际数据集上进行了广泛的实验，结果显示，U-RED在Chamfer Distance下比现有状态的方法提高47.3%、16.7%和31.6%。
</details></li>
</ul>
<hr>
<h2 id="CATS-v2-Hybrid-encoders-for-robust-medical-segmentation"><a href="#CATS-v2-Hybrid-encoders-for-robust-medical-segmentation" class="headerlink" title="CATS v2: Hybrid encoders for robust medical segmentation"></a>CATS v2: Hybrid encoders for robust medical segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06377">http://arxiv.org/abs/2308.06377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoli12345/cats">https://github.com/haoli12345/cats</a></li>
<li>paper_authors: Hao Li, Han Liu, Dewei Hu, Xing Yao, Jiacheng Wang, Ipek Oguz</li>
<li>for: 这个研究的目的是提出一个以CATS为基础的对� части�内部构成，以提高医疗影像分类�的精度和意义性。</li>
<li>methods: 这个研究使用了CATS v2模型，其中包括一个具有传播�的 Hybrid 构成，该构成包括一个 CNN 基础的 Encoder 路径和一个传播�的 Transformer 路径。</li>
<li>results: 在两个公共挑战赛 datasets 上进行评估，CATS v2 模型在分类 VS 和肾脏癌等项目上表现出较高的 Dice  scores，较以前的方法为高。<details>
<summary>Abstract</summary>
Convolutional Neural Networks (CNNs) have exhibited strong performance in medical image segmentation tasks by capturing high-level (local) information, such as edges and textures. However, due to the limited field of view of convolution kernel, it is hard for CNNs to fully represent global information. Recently, transformers have shown good performance for medical image segmentation due to their ability to better model long-range dependencies. Nevertheless, transformers struggle to capture high-level spatial features as effectively as CNNs. A good segmentation model should learn a better representation from local and global features to be both precise and semantically accurate. In our previous work, we proposed CATS, which is a U-shaped segmentation network augmented with transformer encoder. In this work, we further extend this model and propose CATS v2 with hybrid encoders. Specifically, hybrid encoders consist of a CNN-based encoder path paralleled to a transformer path with a shifted window, which better leverage both local and global information to produce robust 3D medical image segmentation. We fuse the information from the convolutional encoder and the transformer at the skip connections of different resolutions to form the final segmentation. The proposed method is evaluated on two public challenge datasets: Cross-Modality Domain Adaptation (CrossMoDA) and task 5 of Medical Segmentation Decathlon (MSD-5), to segment vestibular schwannoma (VS) and prostate, respectively. Compared with the state-of-the-art methods, our approach demonstrates superior performance in terms of higher Dice scores.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在医疗图像分割任务中表现出色，捕捉到高级（本地）信息，如边缘和 тексту层。然而，由于卷积核的视野有限，使得CNN难以完全表征全局信息。近些年来， transformer 在医疗图像分割中表现良好，主要是因为它们能够更好地模型长距离依赖关系。然而， transformer 在捕捉高级空间特征方面表现不如 CNN 好。为了建立一个好的分割模型，需要学习更好的 Representation 来兼顾本地和全局特征，以确保准确和Semantic 准确。在我们之前的工作中，我们提出了CATS，它是一个 U-shaped 分割网络，通过添加 transformer 编码器来提高性能。在这个工作中，我们进一步扩展了CATS 模型，并提出了CATS v2 模型，它使用了混合编码器。具体来说，混合编码器包括一个 CNN 基于编码器路径和一个 shifted window 的 transformer 路径，这两者可以更好地利用本地和全局信息，以生成Robust 3D 医疗图像分割。我们在不同的分辨率之间进行 skip 连接，将 convolutional 编码器和 transformer 的信息融合起来，以生成最终的分割。我们在 Cross-Modality Domain Adaptation（CrossMoDA）和 Medical Segmentation Decathlon 任务（MSD-5）上进行了评估，对 vestibular schwannoma 和 prostate 进行了分割。与当前的状态艺术方法相比，我们的方法在 Dice 分数方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Surrogate-Model-for-Geological-CO2-Storage-and-Its-Use-in-MCMC-based-History-Matching"><a href="#Surrogate-Model-for-Geological-CO2-Storage-and-Its-Use-in-MCMC-based-History-Matching" class="headerlink" title="Surrogate Model for Geological CO2 Storage and Its Use in MCMC-based History Matching"></a>Surrogate Model for Geological CO2 Storage and Its Use in MCMC-based History Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06341">http://arxiv.org/abs/2308.06341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifu Han, Francois P. Hamon, Su Jiang, Louis J. Durlofsky</li>
<li>for: 这个研究targets an important application in geological carbon storage operations, specifically history matching of storage systems with high prior geological uncertainty.</li>
<li>methods: The authors extend a recently introduced recurrent R-U-Net surrogate model to treat geomodel realizations drawn from a wide range of geological scenarios, using flow simulation results and a Markov chain Monte Carlo history matching workflow.</li>
<li>results: The surrogate model provides accurate predictions for new realizations over the full range of geological scenarios, with median relative error of 1.3% in pressure and 4.5% in saturation. The incorporation of the surrogate model into the history matching workflow reduces geological uncertainty and leads to posterior 3D pressure and saturation fields that display much closer agreement with the true-model responses than prior predictions.<details>
<summary>Abstract</summary>
Deep-learning-based surrogate models show great promise for use in geological carbon storage operations. In this work we target an important application - the history matching of storage systems characterized by a high degree of (prior) geological uncertainty. Toward this goal, we extend the recently introduced recurrent R-U-Net surrogate model to treat geomodel realizations drawn from a wide range of geological scenarios. These scenarios are defined by a set of metaparameters, which include the mean and standard deviation of log-permeability, permeability anisotropy ratio, horizontal correlation length, etc. An infinite number of realizations can be generated for each set of metaparameters, so the range of prior uncertainty is large. The surrogate model is trained with flow simulation results, generated using the open-source simulator GEOS, for 2000 random realizations. The flow problems involve four wells, each injecting 1 Mt CO2/year, for 30 years. The trained surrogate model is shown to provide accurate predictions for new realizations over the full range of geological scenarios, with median relative error of 1.3% in pressure and 4.5% in saturation. The surrogate model is incorporated into a Markov chain Monte Carlo history matching workflow, where the goal is to generate history matched realizations and posterior estimates of the metaparameters. We show that, using observed data from monitoring wells in synthetic `true' models, geological uncertainty is reduced substantially. This leads to posterior 3D pressure and saturation fields that display much closer agreement with the true-model responses than do prior predictions.
</details>
<details>
<summary>摘要</summary>
深度学习基本的代理模型在地质碳存储操作中表现出了极大的承诺。在这项工作中，我们target了一个重要应用 - 地质风险很高的存储系统历史匹配。为达到这个目标，我们将Recurrent R-U-Net代理模型扩展到处理各种不同的地质场景。这些场景是通过一组元参数来定义的，其中包括含量风险的平均值和标准差、滤 filtering ratio、水平相关长度等。可以生成无数量的实例 для每个元参数，因此地质风险的范围是非常广泛。我们使用GEOS开源模拟器对2000个随机实例进行流体模拟，并将模型训练于这些实例。训练后，代理模型能够准确预测新的实例，并且在全面的地质场景下显示了 median相对误差为1.3%的压力和4.5%的浓度。这个代理模型被 incorporated into Markov chain Monte Carlo历史匹配工作流程中，以生成历史匹配实例和 posterior 的元参数估计。我们显示，使用 synthetic 'true' 模型中的观测数据，地质风险可以减少得非常多。这导致了 posterior 3D 压力和浓度场 displaying much closer agreement with the true-model responses than prior predictions。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis"><a href="#Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis" class="headerlink" title="Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis"></a>Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06333">http://arxiv.org/abs/2308.06333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrlblab/open-eoe">https://github.com/hrlblab/open-eoe</a></li>
<li>paper_authors: Juming Xiong, Yilin Liu, Ruining Deng, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo<br>for:This paper aims to develop an open-source toolkit for automated detection of eosinophils in whole slide images for the diagnosis of eosinophilic esophagitis.methods:The toolkit uses deep learning-based object detection models and ensemble learning to improve the accuracy and reliability of eosinophil detection.results:The toolkit was tested on a set of 289 whole slide images and achieved an accuracy of 91% in detecting eosinophils at the widely accepted threshold of &gt;&#x3D; 15 per high power field for diagnosing eosinophilic esophagitis.<details>
<summary>Abstract</summary>
Eosinophilic Esophagitis (EoE) is a chronic, immune/antigen-mediated esophageal disease, characterized by symptoms related to esophageal dysfunction and histological evidence of eosinophil-dominant inflammation. Owing to the intricate microscopic representation of EoE in imaging, current methodologies which depend on manual identification are not only labor-intensive but also prone to inaccuracies. In this study, we develop an open-source toolkit, named Open-EoE, to perform end-to-end whole slide image (WSI) level eosinophil (Eos) detection using one line of command via Docker. Specifically, the toolkit supports three state-of-the-art deep learning-based object detection models. Furthermore, Open-EoE further optimizes the performance by implementing an ensemble learning strategy, and enhancing the precision and reliability of our results. The experimental results demonstrated that the Open-EoE toolkit can efficiently detect Eos on a testing set with 289 WSIs. At the widely accepted threshold of >= 15 Eos per high power field (HPF) for diagnosing EoE, the Open-EoE achieved an accuracy of 91%, showing decent consistency with pathologist evaluations. This suggests a promising avenue for integrating machine learning methodologies into the diagnostic process for EoE. The docker and source code has been made publicly available at https://github.com/hrlblab/Open-EoE.
</details>
<details>
<summary>摘要</summary>
《Eosinophilic Esophagitis (EoE)是一种慢性、免疫/抗原诱导的食道疾病，表现为食道功能障碍和 Histological 证据显示的吸收性黑色素细胞滥多性Inflammation。由于EoE的微scopic表现在成像中复杂，目前的方法ologies依靠 manual identification 不仅劳累也容易出错。本研究中，我们开发了一个开源工具kit，名为 Open-EoE，通过一行命令 via Docker 来实现整个扫描图像 (WSI) 层的吸收性黑色素细胞 (Eos) 检测。Specifically，工具kit 支持三种 state-of-the-art deep learning-based object detection 模型。此外，Open-EoE 还进一步优化了性能，通过实现 ensemble learning 策略，并提高了结果的精度和可靠性。实验结果表明，Open-EoE 工具kit 可以有效地检测 Eos 在289个 WSIs 上。在 widely accepted 的 >= 15 Eos per high power field (HPF) 的标准下，Open-EoE 达到了 91% 的准确率，与Pathologist 评估相当一致。这表明可以将机器学习方法 integrate 到 EoE 诊断过程中，并且 Open-EoE 的 Docker 和源代码已经在 https://github.com/hrlblab/Open-EoE 上公开 released。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology"><a href="#Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology" class="headerlink" title="Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology"></a>Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06332">http://arxiv.org/abs/2308.06332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FarihaHossain/SwinFSR">https://github.com/FarihaHossain/SwinFSR</a></li>
<li>paper_authors: Khondker Fariha Hossain, Sharif Amit Kamran, Joshua Ong, Andrew G. Lee, Alireza Tavakkoli<br>for: 这paper是为了提出一种基于SwinTransformer的眼内画像超分辨模型，用于解决在各种各样的眼内图像识别任务中的数据传输压缩问题。methods: 这paper使用了SwinTransformer搭配空间和深度精度注意力来实现眼内图像超分辨。results: 这paper在三个公共数据集上达到了Peak signal-to-noise-ratio（PSNR）47.89、49.00和45.32，并在NASA提供的一个专用数据集上达到了相当的比较结果。<details>
<summary>Abstract</summary>
The rapid accessibility of portable and affordable retinal imaging devices has made early differential diagnosis easier. For example, color funduscopy imaging is readily available in remote villages, which can help to identify diseases like age-related macular degeneration (AMD), glaucoma, or pathological myopia (PM). On the other hand, astronauts at the International Space Station utilize this camera for identifying spaceflight-associated neuro-ocular syndrome (SANS). However, due to the unavailability of experts in these locations, the data has to be transferred to an urban healthcare facility (AMD and glaucoma) or a terrestrial station (e.g, SANS) for more precise disease identification. Moreover, due to low bandwidth limits, the imaging data has to be compressed for transfer between these two places. Different super-resolution algorithms have been proposed throughout the years to address this. Furthermore, with the advent of deep learning, the field has advanced so much that x2 and x4 compressed images can be decompressed to their original form without losing spatial information. In this paper, we introduce a novel model called Swin-FSR that utilizes Swin Transformer with spatial and depth-wise attention for fundus image super-resolution. Our architecture achieves Peak signal-to-noise-ratio (PSNR) of 47.89, 49.00 and 45.32 on three public datasets, namely iChallenge-AMD, iChallenge-PM, and G1020. Additionally, we tested the model's effectiveness on a privately held dataset for SANS provided by NASA and achieved comparable results against previous architectures.
</details>
<details>
<summary>摘要</summary>
“快速访问可携带便宜的肉眼成像设备，使得早期差异诊断变得更加容易。例如，颜色基准成像技术可以在偏远的村庄中提供，以帮助诊断年龄相关macular degeneration（AMD）、高压病（glaucoma）或 PATHOLOGICAL MYOPIA（PM）等疾病。然而，由于这些地点缺乏专业人士，因此数据必须被传输到城市医疗机构（AMD和 glaucoma）或地面站（例如，SANS）进行更加精确的疾病诊断。此外，由于带宽限制，成像数据必须进行压缩传输。过去数年，一些超分辨算法已经提出来解决这个问题。此外，随着深度学习的发展，这一领域已经进步到了非常高的水平，可以使得压缩后的成像数据被 decompress 到原始形式，而不会产生空间信息损失。本文提出了一种名为 Swin-FSR 的新模型，该模型使用 Swin Transformer 与空间和深度宽度注意来进行肉眼成像超分辨。我们的架构实现了 Peak signal-to-noise-ratio（PSNR）的 47.89、49.00 和 45.32 在三个公共数据集上，namely iChallenge-AMD、iChallenge-PM 和 G1020。此外，我们对 NASA 提供的一个私人保留数据集进行测试，并实现了与前一代架构相当的效果。”
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies"><a href="#A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies" class="headerlink" title="A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies"></a>A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07337">http://arxiv.org/abs/2308.07337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Halid Ziya Yerebakan, Yoshihisa Shinagawa, Mahesh Ranganath, Simon Allen-Raffl, Gerardo Hermosillo Valadez</li>
<li>for: 医疗图像 longitudinal 比较中匹配 анатомиче位置</li>
<li>methods: 使用 hierarchical sparse sampling 计算查询点描述符，然后使用 hierarchical search 找到最相似的点在目标图像中</li>
<li>results: 实现了减少计算时间至毫秒级单个CPU上，可以帮助医生在实时比较相似的 анатомиче位置而无需额外建筑或存储变换场景Is there anything else I can help you with?<details>
<summary>Abstract</summary>
We propose a method to match anatomical locations between pairs of medical images in longitudinal comparisons. The matching is made possible by computing a descriptor of the query point in a source image based on a hierarchical sparse sampling of image intensities that encode the location information. Then, a hierarchical search operation finds the corresponding point with the most similar descriptor in the target image. This simple yet powerful strategy reduces the computational time of mapping points to a millisecond scale on a single CPU. Thus, radiologists can compare similar anatomical locations in near real-time without requiring extra architectural costs for precomputing or storing deformation fields from registrations. Our algorithm does not require prior training, resampling, segmentation, or affine transformation steps. We have tested our algorithm on the recently published Deep Lesion Tracking dataset annotations. We observed more accurate matching compared to Deep Lesion Tracker while being 24 times faster than the most precise algorithm reported therein. We also investigated the matching accuracy on CT and MR modalities and compared the proposed algorithm's accuracy against ground truth consolidated from multiple radiologists.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，用于在医疗影像对比中匹配解剖位置。该方法基于源图像中计算查询点的特征器，该特征器是基于层次稀疏抽象的图像强度值，这些值编码了位置信息。然后，使用层次搜索操作找到目标图像中最相似的点。这种简单 yet 强大的策略可以在单个 CPU 上减少比较时间到毫秒级，因此让 radiologist 可以在实时比较相似的解剖位置，无需额外的建筑成本或存储扭变场的预计算或存储。我们的算法不需要先行训练、扩充、分割或非对映变换步骤。我们在最近发布的 Deep Lesion Tracking 数据集注释中进行了测试，并观察到比 Deep Lesion Tracker 更准确的匹配，同时比最精确的算法 report 在其中的 24 倍 faster。我们还 investigate 了该算法的匹配精度在 CT 和 MR Modalities 上，并与多名医生共同协调的ground truth进行比较。
</details></li>
</ul>
<hr>
<h2 id="FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods"><a href="#FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods" class="headerlink" title="FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods"></a>FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06248">http://arxiv.org/abs/2308.06248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/visinf/funnybirds">https://github.com/visinf/funnybirds</a></li>
<li>paper_authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth</li>
<li>for: 这个论文的目的是解释人工智能（XAI）领域中复杂的深度神经网络模型的内部工作方式。</li>
<li>methods: 这篇论文使用了一种新的Synthetic vision dataset，叫做FunnyBirds，以及一系列自动评估协议来解决XAI中缺乏ground truth解释的挑战。</li>
<li>results: 通过使用FunnyBirds dataset和自动评估协议，这篇论文报告了24种不同的神经网络模型和XAI方法的结果，并证明了这些方法在一种完全自动和系统的方式下的优缺点。<details>
<summary>Abstract</summary>
The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
</details>
<details>
<summary>摘要</summary>
field of explainable artificial intelligence (XAI) 目的是暴露复杂深度神经网络模型的内部工作原理。而这种技术在安全关键领域非常重要，但XAI本身缺乏真实的解释，这使得自动评估成为一个未解决的问题。我们解决这个挑战 by proposing a novel synthetic vision dataset， named FunnyBirds，以及相应的自动评估协议。我们的数据集允许执行Semantically meaningful image interventions，例如 removing individual object parts，这有三个重要的后果。首先，它允许分析解释的部级划分，这更加接近人类的理解，而不是现有的方法，它们会评估像素级划分。其次，通过比较模型输出的各个部分输入，我们可以估算出各个部分的真实重要性，这些重要性应该反映在解释中。最后，我们可以将各种不同类型的解释映射到一个共同的部分重要性空间中，以便分析多种不同的解释类型在单一的框架中。使用我们的工具，我们报告了24种不同的神经网络模型和XAI方法的结果，这些结果 demonstrate了评估方法的优劣点在一个完全自动和系统的方式上。
</details></li>
</ul>
<hr>
<h2 id="Continual-Face-Forgery-Detection-via-Historical-Distribution-Preserving"><a href="#Continual-Face-Forgery-Detection-via-Historical-Distribution-Preserving" class="headerlink" title="Continual Face Forgery Detection via Historical Distribution Preserving"></a>Continual Face Forgery Detection via Historical Distribution Preserving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06217">http://arxiv.org/abs/2308.06217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Sun, Shen Chen, Taiping Yao, Xiaoshuai Sun, Shouhong Ding, Rongrong Ji</li>
<li>for: 防止面部伪造攻击的安全威胁</li>
<li>methods: 使用普遍攻击伪造模型、知识传递和历史分布保持等方法</li>
<li>results: 比前一代方法高效地检测新的伪造攻击，并维持了面部伪造 distribuition的稳定性<details>
<summary>Abstract</summary>
Face forgery techniques have advanced rapidly and pose serious security threats. Existing face forgery detection methods try to learn generalizable features, but they still fall short of practical application. Additionally, finetuning these methods on historical training data is resource-intensive in terms of time and storage. In this paper, we focus on a novel and challenging problem: Continual Face Forgery Detection (CFFD), which aims to efficiently learn from new forgery attacks without forgetting previous ones. Specifically, we propose a Historical Distribution Preserving (HDP) framework that reserves and preserves the distributions of historical faces. To achieve this, we use universal adversarial perturbation (UAP) to simulate historical forgery distribution, and knowledge distillation to maintain the distribution variation of real faces across different models. We also construct a new benchmark for CFFD with three evaluation protocols. Our extensive experiments on the benchmarks show that our method outperforms the state-of-the-art competitors.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Face forgery techniques have advanced rapidly and pose serious security threats. Existing face forgery detection methods try to learn generalizable features, but they still fall short of practical application. Additionally, finetuning these methods on historical training data is resource-intensive in terms of time and storage. In this paper, we focus on a novel and challenging problem: Continual Face Forgery Detection (CFFD), which aims to efficiently learn from new forgery attacks without forgetting previous ones. Specifically, we propose a Historical Distribution Preserving (HDP) framework that reserves and preserves the distributions of historical faces. To achieve this, we use universal adversarial perturbation (UAP) to simulate historical forgery distribution, and knowledge distillation to maintain the distribution variation of real faces across different models. We also construct a new benchmark for CFFD with three evaluation protocols. Our extensive experiments on the benchmarks show that our method outperforms the state-of-the-art competitors."中文简体版：现代面孔伪造技术得到了快速发展，对安全提供了严重的威胁。现有的面孔伪造检测方法尝试学习通用特征，但 ainda fall short of practical application。此外，在历史训练数据上进行finetuning这些方法是费时和占用存储空间的。在这篇论文中，我们关注一个新和挑战的问题： continual face forgery detection（CFFD），该问题的目标是高效地从新的伪造攻击中学习，而不是忘记之前的。我们提出了一个历史分布保持（HDP）框架，该框架保留和保持历史面孔的分布。为了实现这一目标，我们使用通用对抗扰动（UAP）来模拟历史伪造分布，并使用知识蒸馏来保持实际面孔的分布变化。我们还建立了一个新的CFFD数据集和三个评估协议。我们的广泛实验表明，我们的方法在CFFD中表现出了优于当前竞争者。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.CV_2023_08_12/" data-id="clon21ipo00fsr588hzqwfkc8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.AI_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T12:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.AI_2023_08_12/">cs.AI - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="VisIT-Bench-A-Benchmark-for-Vision-Language-Instruction-Following-Inspired-by-Real-World-Use"><a href="#VisIT-Bench-A-Benchmark-for-Vision-Language-Instruction-Following-Inspired-by-Real-World-Use" class="headerlink" title="VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use"></a>VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06595">http://arxiv.org/abs/2308.06595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonatan Bitton, Hritik Bansal, Jack Hessel, Rulin Shao, Wanrong Zhu, Anas Awadalla, Josh Gardner, Rohan Taori, Ludwig Schimdt</li>
<li>for: 评估视觉语言模型在真实世界中的 instrucion-following 能力（evaluate vision-language models’ ability to follow instructions in real-world scenarios）</li>
<li>methods: 使用 70 个 ‘instruction families’ 和 592 个测试查询（use 70 instruction families and 592 test queries），包括从基本认知到游戏和创意生成等多种任务（including tasks such as basic recognition, game playing, and creative generation）</li>
<li>results: 使用人工和自动评估方法，发现现有模型与参考模型之间的质量差距 relativelly large（using both human and automatic evaluation methods, the quality gap between existing models and reference models is relatively large），提供了一个动态参与的项目，让实验室和研究人员可以简单地在项目网站上提交自己的模型答案（providing a dynamic project that allows researchers and practitioners to simply submit their model’s responses on the project website）<details>
<summary>Abstract</summary>
We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps between models and references using both human and automatic evaluations; e.g., the top-performing instruction-following model wins against the GPT-4 reference in just 27% of the comparison. VisIT-Bench is dynamic to participate, practitioners simply submit their model's response on the project website; Data, code and leaderboard is available at visit-bench.github.io.
</details>
<details>
<summary>摘要</summary>
我们介绍VisIT-Bench（视觉指令比赛），一个用于评估视觉语言模型的实际应用场景的 benchmark。我们开始于精心选择70个“指令家庭”，我们认为视觉语言模型应该能够解决这些指令。我们的数据集包括592个测试查询，每个查询都有一个人工生成的指令条件描述。这些描述包括指令特有的因素，例如一个指令要求关于轮椅用户是否可以进入商店的访问性，描述了斜坡/潜在障碍物。这些描述允许我们收集人工验证的参考输出 для每个实例，并使用文本 только LLM 自动评估候选的多Modal生成。我们使用人工和自动评估来衡量模型和参考之间的质量差距，例如，最高级别的指令遵循模型只在与 GPT-4 参考的比赛中赢得27%。VisIT-Bench 是开放的，参与者可以在项目网站上提交他们的模型的回答。数据、代码和排名信息可以在 visit-bench.github.io 上获得。
</details></li>
</ul>
<hr>
<h2 id="Value-Distributional-Model-Based-Reinforcement-Learning"><a href="#Value-Distributional-Model-Based-Reinforcement-Learning" class="headerlink" title="Value-Distributional Model-Based Reinforcement Learning"></a>Value-Distributional Model-Based Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06590">http://arxiv.org/abs/2308.06590</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters</li>
<li>for: 这个论文目的是为了解决sequential decision-making任务中的uncertainty quantification问题。</li>
<li>methods: 这个论文使用了model-based Bayesian reinforcement learning的方法，其中的目标是学习Markov决策过程中参数不确定性induced的 posterior distribution over value functions。</li>
<li>results: 论文的实验表明，EQR算法可以在 continuous-control tasks 中比Established model-based和model-free算法表现出性能优势。<details>
<summary>Abstract</summary>
Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>量化政策长期表现的不确定性是解决sequential decision-making任务的重要问题。我们从model-based Bayesian reinforcement learning的视角 изуча这个问题，目标是学习Markov决策过程中参数（эпистемиче）不确定性引起的 posterior distribution over value functions。先前的工作只考虑了这些分布的一些瞬间或假设了特定的分布形式，例如 Gaussian。 inspirited by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function。 Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. 评估在多个连续控制任务上表现出与已有的model-based和model-free算法相比的性能优势。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Approximate-Answering-of-Graph-Queries"><a href="#Approximate-Answering-of-Graph-Queries" class="headerlink" title="Approximate Answering of Graph Queries"></a>Approximate Answering of Graph Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06585">http://arxiv.org/abs/2308.06585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Cochez, Dimitrios Alivanistos, Erik Arakelyan, Max Berrendorf, Daniel Daza, Mikhail Galkin, Pasquale Minervini, Mathias Niepert, Hongyu Ren</li>
<li>for: 本文旨在介绍几种方法，以帮助回答含有不完整信息的知识图（KG）中的查询。</li>
<li>methods: 本文提出了多种方法，包括基于预测、基于潜在相似性、基于证据等方法，以满足不同类型的查询需求。</li>
<li>results: 这些方法可以帮助解决各种查询问题，如答案推断、 Entity Disambiguation、 Relation extraction 等。但是，这些方法受到图数据不完整和不准确的限制。<details>
<summary>Abstract</summary>
Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.
</details>
<details>
<summary>摘要</summary>
知识图（KG）自然而然地是不完整的，因为世界知识的不完整和输入KG中的偏见。此外，世界知识不断扩展和发展，使现有的事实过时或引入新的事实。然而，我们仍然希望能够回答问题，作为如果图完整一样。在这章中，我们将给出不同类型的查询支持的方法的概述，以及通常用于评估的数据集，以及这些方法的局限性。然后，我们将对不同的方法进行描述，包括表达力、支持的图类型和推理能力。
</details></li>
</ul>
<hr>
<h2 id="4DRVO-Net-Deep-4D-Radar-Visual-Odometry-Using-Multi-Modal-and-Multi-Scale-Adaptive-Fusion"><a href="#4DRVO-Net-Deep-4D-Radar-Visual-Odometry-Using-Multi-Modal-and-Multi-Scale-Adaptive-Fusion" class="headerlink" title="4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion"></a>4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06573">http://arxiv.org/abs/2308.06573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guirong Zhuo, Shouyi Lu, Huanyu Zhou, Lianqing Zheng, Lu Xiong<br>for:* 4D radar–visual odometry (4DRVO) is an attractive solution for achieving accurate and robust pose estimation by integrating complementary information from 4D radar and cameras.methods:* 4DRVO-Net leverages a feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses, with a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information.* An adaptive 4D radar–camera fusion module (A-RCFM) is designed to automatically select image features based on 4D radar point features, facilitating multi-scale cross-modal feature interaction and adaptive multi-modal feature fusion.results:* Our method outperforms all learning-based and geometry-based methods for most sequences in the VoD dataset, and has exhibited promising performance that closely approaches that of the 64-line LiDAR odometry results of A-LOAM without mapping optimization.<details>
<summary>Abstract</summary>
Four-dimensional (4D) radar--visual odometry (4DRVO) integrates complementary information from 4D radar and cameras, making it an attractive solution for achieving accurate and robust pose estimation. However, 4DRVO may exhibit significant tracking errors owing to three main factors: 1) sparsity of 4D radar point clouds; 2) inaccurate data association and insufficient feature interaction between the 4D radar and camera; and 3) disturbances caused by dynamic objects in the environment, affecting odometry estimation. In this paper, we present 4DRVO-Net, which is a method for 4D radar--visual odometry. This method leverages the feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses. Specifically, we propose a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information, enabling fine-grained learning for sparse 4D radar point clouds. To effectively integrate the two modalities, we design an adaptive 4D radar--camera fusion module (A-RCFM) that automatically selects image features based on 4D radar point features, facilitating multi-scale cross-modal feature interaction and adaptive multi-modal feature fusion. In addition, we introduce a velocity-guided point-confidence estimation module to measure local motion patterns, reduce the influence of dynamic objects and outliers, and provide continuous updates during pose refinement. We demonstrate the excellent performance of our method and the effectiveness of each module design on both the VoD and in-house datasets. Our method outperforms all learning-based and geometry-based methods for most sequences in the VoD dataset. Furthermore, it has exhibited promising performance that closely approaches that of the 64-line LiDAR odometry results of A-LOAM without mapping optimization.
</details>
<details>
<summary>摘要</summary>
四维度（4D）雷达--视觉协调（4DRVO）结合了不同信息，使得它成为了精度和可靠性很高的pose estimation的有力解决方案。然而，4DRVO可能会出现严重的跟踪错误，这些错误主要来自于以下三个原因：1）4D雷达点云稀疏; 2）摄像头和雷达数据的不准确相关和不足的特征互动; 3）环境中的动态对象的干扰，影响 pose estimation。在这篇文章中，我们提出了4DRVO-Net，这是一种4D雷达--视觉协调方法。这种方法利用了特征层、pose扭曲和成本量网络架构，逐步估算和精化pose。我们提出了一种多尺度特征提取网络，叫做Radar-PointNet++,该网络可以全面考虑4D雷达点云的丰富信息，以便细化学习稀疏4D雷达点云。为了有效地结合两种模式，我们设计了自适应4D雷达--摄像头融合模块（A-RCFM），该模块可以根据4D雷达点云特征自动选择摄像头特征，实现了多尺度交互和自适应多模式特征融合。此外，我们引入了速度导向点信任度估计模块，可以测量本地运动趋势，减少动态对象和异常点的影响，并在pose精化过程中提供连续更新。我们在VoD和自有 dataset上展示了我们的方法的优秀性和每个模块设计的有效性。我们的方法在大多数序列上超过了所有学习基于和几何基于的方法，并且在64行LiDAR odometry结果的A-LOAM不需要地图优化的情况下，表现出了可观的表现。
</details></li>
</ul>
<hr>
<h2 id="ModelScope-Text-to-Video-Technical-Report"><a href="#ModelScope-Text-to-Video-Technical-Report" class="headerlink" title="ModelScope Text-to-Video Technical Report"></a>ModelScope Text-to-Video Technical Report</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06571">http://arxiv.org/abs/2308.06571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, Shiwei Zhang</li>
<li>for: 这个论文旨在描述一种基于文本-图像合成模型（即Stable Diffusion）的文本-视频合成模型（ModelScopeT2V）。</li>
<li>methods: 该模型采用了空间-时间块来保证渠道生成顺序和运动过渡的一致性，并且可以在训练和推理阶段适应不同的帧数。模型包括三个组件（即VQGAN、文本编码器和杂噪UNet），总共含1.7亿个参数，其中0.5亿个参数专门用于时间能力。</li>
<li>results: 模型在三个评价指标上表现出优于当前状态艺术方法。代码和在线demo可以在\url{<a target="_blank" rel="noopener" href="https://modelscope.cn/models/damo/text-to-video-synthesis/summary%7D%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://modelscope.cn/models/damo/text-to-video-synthesis/summary}中找到。</a><details>
<summary>Abstract</summary>
This paper introduces ModelScopeT2V, a text-to-video synthesis model that evolves from a text-to-image synthesis model (i.e., Stable Diffusion). ModelScopeT2V incorporates spatio-temporal blocks to ensure consistent frame generation and smooth movement transitions. The model could adapt to varying frame numbers during training and inference, rendering it suitable for both image-text and video-text datasets. ModelScopeT2V brings together three components (i.e., VQGAN, a text encoder, and a denoising UNet), totally comprising 1.7 billion parameters, in which 0.5 billion parameters are dedicated to temporal capabilities. The model demonstrates superior performance over state-of-the-art methods across three evaluation metrics. The code and an online demo are available at \url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary}.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了ModelScopeT2V，一种文本到视频合成模型，它从文本到图像合成模型（即稳定扩散）中演化出来。ModelScopeT2V包含空间-时间块来保证 Frame 生成的一致性和平滑的运动过渡。模型可以在训练和推理过程中适应不同的帧数，因此适用于图像-文本和视频-文本数据集。ModelScopeT2V由三个组件（即 VQGAN、文本编码器和杂净 UNet）组成，总共含有1.7亿参数，其中0.5亿参数专门用于时间能力。模型在三个评价指标上表现出色，超过了当前最佳方法。代码和在线示例可以在 \url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MC-DRE-Multi-Aspect-Cross-Integration-for-Drug-Event-Entity-Extraction"><a href="#MC-DRE-Multi-Aspect-Cross-Integration-for-Drug-Event-Entity-Extraction" class="headerlink" title="MC-DRE: Multi-Aspect Cross Integration for Drug Event&#x2F;Entity Extraction"></a>MC-DRE: Multi-Aspect Cross Integration for Drug Event&#x2F;Entity Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06546">http://arxiv.org/abs/2308.06546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Yang, Soyeon Caren Han, Siqu Long, Josiah Poon, Goran Nenadic</li>
<li>For: This paper proposes a new multi-aspect cross-integration framework for drug entity&#x2F;event detection in drug-related documents.* Methods: The proposed framework uses multi-aspect encoders to describe semantic, syntactic, and medical document contextual information, and conducts cross-integration of different contextual information in three ways: key-value cross, attention cross, and feedforward cross.* Results: The proposed model outperforms all state-of-the-art (SOTA) models on two widely used tasks, flat entity detection and discontinuous event extraction.<details>
<summary>Abstract</summary>
Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADEs are reported via an unstructured conversation with the medical context, so applying a general entity recognition approach is not sufficient enough. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross-integration with other contextual information in three ways: the key-value cross, attention cross, and feedforward cross, so the multi-encoders are integrated in depth. Our model outperforms all SOTA on two widely used tasks, flat entity detection and discontinuous event extraction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>提取有用的药物相关信息块，如负面影响（ADE），对避免负担和拯救生命非常重要。大多数ADE都是通过不结构化的医疗讨论报告的方式报告的，因此使用一般的实体识别方法不够。在这篇论文中，我们提议一种新的多方面融合框架，用于药物实体/事件检测，通过捕捉和对照不同语言/知识/文档上下文的信息来描述药物相关文档。我们首先构建多方面编码器，用于描述语义、语法和医疗文档上下文信息，包括插槽标注任务、主药物实体/事件检测、语法标注和普通医学实体识别。然后，每个编码器进行了三种跨integration：键值跨、注意力跨和Feedforward跨，以融合多个上下文信息。我们的模型在两个常用任务上都超过了所有SOTA的性能。
</details></li>
</ul>
<hr>
<h2 id="Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters"><a href="#Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters" class="headerlink" title="Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters"></a>Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06545">http://arxiv.org/abs/2308.06545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chukwuma Okolie, Jon Mills, Adedayo Adeleke, Julian Smit</li>
<li>For: The paper aims to enhance the accuracy of medium-resolution digital elevation models (DEMs) in urban areas, specifically in Cape Town, South Africa, for hydrological and environmental modelling.* Methods: The authors use the extreme gradient boosting (XGBoost) ensemble algorithm to correct the DEMs, with eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, and more.* Results: The corrected DEMs achieved significant accuracy gains, with a root mean square error (RMSE) improvement of 46-53% for Copernicus DEM and 72-73% for AW3D DEM, compared to other proposed methods. These results demonstrate the potential of gradient boosted trees for enhancing DEM quality and improving hydrological modelling in urban catchments.Here is the same information in Simplified Chinese text, as requested:* For: 这个论文的目的是提高城市区域中的数字高程模型（DEM）的准确性，以便于水文和环境模型。* Methods: 作者使用极限Gradient Boosting（XGBoost）ensemble算法来修正DEM，使用的predictor变量包括高程、城市脚印、坡度、方向、表面荒凉、地形位置指数、地形荒凉指数、地形表面 текстура等 eleven个变量。* Results: 修正后的DEM实现了显著的准确性提高，比如 Copernicus DEM的RMSE提高46-53%，AW3D DEM的RMSE提高72-73%，与其他提议的方法相比。这些结果表明极限Gradient Boosting树可以提高DEM的质量，并且为城市catchments中的水文模型提供改善。<details>
<summary>Abstract</summary>
The accuracy of digital elevation models (DEMs) in urban areas is influenced by numerous factors including land cover and terrain irregularities. Moreover, building artifacts in global DEMs cause artificial blocking of surface flow pathways. This compromises their quality and adequacy for hydrological and environmental modelling in urban landscapes where precise and accurate terrain information is needed. In this study, the extreme gradient boosting (XGBoost) ensemble algorithm is adopted for enhancing the accuracy of two medium-resolution 30m DEMs over Cape Town, South Africa: Copernicus GLO-30 and ALOS World 3D (AW3D). XGBoost is a scalable, portable and versatile gradient boosting library that can solve many environmental modelling problems. The training datasets are comprised of eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, topographic position index, terrain ruggedness index, terrain surface texture, vector roughness measure, forest cover and bare ground cover. The target variable (elevation error) was calculated with respect to highly accurate airborne LiDAR. After training and testing, the model was applied for correcting the DEMs at two implementation sites. The correction achieved significant accuracy gains which are competitive with other proposed methods. The root mean square error (RMSE) of Copernicus DEM improved by 46 to 53% while the RMSE of AW3D DEM improved by 72 to 73%. These results showcase the potential of gradient boosted trees for enhancing the quality of DEMs, and for improved hydrological modelling in urban catchments.
</details>
<details>
<summary>摘要</summary>
地数模型（DEM）在城市地区的准确性受到多种因素的影响，包括地表覆盖物和地形 irregularities。此外，全球 DEM 中的建筑物略导致表面流道路径的人工堵塞，从而降低其质量和适用性 для水文环境模型在城市景观中，需要精准和准确的地形信息。在这种研究中，我们采用了极限拟合搅拌（XGBoost）ensemble算法来提高两个中等分辨率 30 m DEM 的准确性，即 Copernicus GLO-30 和 ALOS World 3D（AW3D）。XGBoost 是一种可扩展、可移植和多样的拟合搅拌库，可以解决许多环境模型问题。训练数据集包括 eleven 个预测变量，包括高程、城市脚印、坡度、方向、表面粗糙度、地形坡度指数、地形表面文化、向量粗糙度度量、森林覆盖率和裸地覆盖率。target variable （高程误差）与高精度飞行 LiDAR 进行计算。之后，模型被应用于修正 DEM 的两个实施场景。修正后，DEM 的Root Mean Square Error（RMSE）提高了46%到53%，AW3D DEM 的 RMSE 提高了72%到73%。这些结果显示了拟合搅拌树的潜在可能性，以及对城市流域水文模型的改进。
</details></li>
</ul>
<hr>
<h2 id="Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models"><a href="#Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models" class="headerlink" title="Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models"></a>Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06534">http://arxiv.org/abs/2308.06534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wolfda95/ssl-medicalimagining-cl-mae">https://github.com/wolfda95/ssl-medicalimagining-cl-mae</a></li>
<li>paper_authors: Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Timo Ropinski, Michael Götz</li>
<li>for: 这篇论文旨在探讨deep learning在医疗影像领域中的应用，以减少诊断错误、轻量化医生工作负担，并加快诊断。</li>
<li>methods: 这篇论文使用了自动标注学习方法，包括对大量无标注影像进行自动标注。</li>
<li>results: 研究发现，使用SparK预训方法可以更好地适应小型标注数据，并且在诊断任务中表现更好。<details>
<summary>Abstract</summary>
Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task. The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares state-of-the-art contrastive learning methods with the recently introduced masked autoencoder approach "SparK" for convolutional neural networks (CNNs) on medical images. Therefore we pre-train on a large unannotated CT image dataset and fine-tune on several CT classification tasks. Due to the challenge of obtaining sufficient annotated training data in medical imaging, it is of particular interest to evaluate how the self-supervised pre-training methods perform when fine-tuning on small datasets. By experimenting with gradually reducing the training dataset size for fine-tuning, we find that the reduction has different effects depending on the type of pre-training chosen. The SparK pre-training method is more robust to the training dataset size than the contrastive methods. Based on our results, we propose the SparK pre-training for medical imaging tasks with only small annotated datasets.
</details>
<details>
<summary>摘要</summary>
深度学习在医疗影像领域可能减少诊断错误风险，减轻放射学家的工作负担，并加速诊断。深度学习模型的训练需要大量和准确的数据集，并将所有训练样本标注。然而，在医疗影像领域，特定任务的标注数据集经常很小，这可能由标注的复杂性、访问限制或疾病的罕见性引起。为解决这个挑战，可以使用自动标注学习的方法进行深度学习模型的预训练。在预训练后，只需要小量的标注数据集来精度地调整模型 для特定任务。医疗影像领域最受欢迎的自动标注预训练方法是对比学习。然而，最近的自然图像处理研究表明，遮盲 autoencoder 方法有很强的潜在性。我们的工作比较了当前状态的对比学习方法和新引入的遮盲 autoencoder 方法 "SparK" 在医疗影像中的 convolutional neural networks (CNNs) 上。因此，我们预训练在大量无注释 CT 图像数据集上，并在多个 CT 分类任务上进行精度调整。由于医疗影像领域获得足够的注释训练数据是困难的，因此特别关心自动标注预训练方法在小型注释数据集上的性能。通过逐渐减少 fine-tuning 数据集大小的实验，我们发现降低的效果与预训练方法的类型有很大的差异。SparK 预训练方法在训练数据集尺寸减少后表现更加稳定。根据我们的结果，我们建议使用 SparK 预训练方法进行医疗影像任务，只需要小量的注释训练数据。
</details></li>
</ul>
<hr>
<h2 id="Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices"><a href="#Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices" class="headerlink" title="Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices"></a>Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06528">http://arxiv.org/abs/2308.06528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jakubkwiatkowski/abstract_compositional_transformer">https://github.com/jakubkwiatkowski/abstract_compositional_transformer</a></li>
<li>paper_authors: Jakub Kwiatkowski, Krzysztof Krawiec</li>
<li>for: The paper aims to improve the performance of solving Raven Progressive Matrices (RPM) tasks using deep learning.</li>
<li>methods: The proposed method uses a transformer-based architecture to predict the visual properties of individual objects and their arrangements, rather than directly choosing the answer. The model parses the visual input into tokens and is trained using self-supervised methods with various masking regimes.</li>
<li>results: The proposed method outperforms state-of-the-art methods and provides interesting insights and partial explanations about the inference. Additionally, the design of the method is immune to biases that exist in some RPM benchmarks.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文目的是使用深度学习方法改进解决Raven Progressive Matrices (RPM)任务。</li>
<li>methods: 提议的方法使用 transformer 架构，而不是直接选择答案，而是预测图像中对象的视觉属性和排列。模型将视觉输入解析成 токен，并使用自我超vised 训练方法，包括不同的掩蔽方式。</li>
<li>results: 提议的方法不仅超越了当前的方法，还提供了有趣的解释和偏好。此外，方法的设计也免备了一些 RPM 数据集中的偏见。<details>
<summary>Abstract</summary>
One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details>
<details>
<summary>摘要</summary>
一个learning抽象逻辑的挑战是问题经常被提出为单一任务，没有中间目标。在Raven进步矩阵（RPM）中，任务是根据上下文选择一个可用的答案，上下文和答案都是复杂的图像组合，包括多个物体在不同的空间排列。由于这个高级目标是唯一的指导，学习是困难的，大多数当代解决方案都是透明的。在这项研究中，我们提议一种基于转换器蓝图的深度学习架构，而不是直接选择上述选择，而是预测图像中对象的视觉属性和排列。得到的多维预测可以直接相互对比，从而选择答案。我们考虑了一些将视觉输入分解成токен的方法，以及在自然supervised训练中隐藏部分输入的方法。在实验评估中，模型不仅超越了当前的方法，还提供了有趣的结论和部分解释，关于推理过程。此外，方法的设计还使其免受一些RPMbenchmark中已知的偏见。
</details></li>
</ul>
<hr>
<h2 id="SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models"><a href="#SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models" class="headerlink" title="SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models"></a>SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06522">http://arxiv.org/abs/2308.06522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Qingfeng Liu, Kee-Bong Song, Mostafa El-Khamy, Salman Avestimehr</li>
<li>for: 这篇论文目的是探讨在 Federated Learning（FL）中使用已经预训练的 transformer 模型进行调整，以获得最佳的语言任务结果。</li>
<li>methods: 这篇论文使用的方法包括 parameter efficient fine-tuning（PEFT）和一个名为 SLoRA 的新方法，用于在高度多标的数据情况下bridge the performance gap between PEFT 和全部调整。</li>
<li>results: 实验结果显示，SLoRA 可以 дости持比 full fine-tuning 相似的性能，并在大约 $\sim 1%$ 的稀疏更新下实现大约 $90%$ 的训练时间减少。<details>
<summary>Abstract</summary>
Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese: Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.Transfer learning via fine-tuning pre-trained transformer models 在各种 NLP 任务中取得了很大的成功，但在没有中央数据的情况下，Federated Learning (FL) 可以利用分布式和私有的 FL 边缘客户端数据进行 fine-tuning。然而，由于边缘设备的限制性，包括通信、计算和存储能力，以及流行的 transformer 模型的巨大大小，fficient fine-tuning 是使 federated 训练可行的关键。这个工作探讨了在不同的 FL 设置下，用于语言任务的 PEFT 方法所面临的机会和挑战。我们的调查发现，随着用户数据的多样化，完全 fine-tuning 和 PEFT 方法之间的性能差距逐渐扩大。为了弥补这个性能差距，我们提议一种名为 SLoRA 的方法，通过一种新的数据驱动初始化技术，超越 LoRA 在高多样性数据场景中的关键局限性。我们的实验结果表明，SLoRA 可以与完全 fine-tuning 相比，在 $\sim 1\%$ 杂点上实现相似的性能，同时减少训练时间达到 $90\%$。
</details></li>
</ul>
<hr>
<h2 id="One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training"><a href="#One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training" class="headerlink" title="One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training"></a>One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07934">http://arxiv.org/abs/2308.07934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianshuod/tba">https://github.com/jianshuod/tba</a></li>
<li>paper_authors: Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia</li>
<li>For: This paper aims to propose a training-assisted bit flip attack on deep neural networks (DNNs) to compromise their security.* Methods: The attack exploits memory fault inject techniques such as row hammer and involves the adversary in the training stage to build a high-risk model. The attack can convert the high-risk model to a malicious one on the victim’s side by flipping only one critical bit on average in the deployment stage.* Results: The attack poses a significant threat even when defenses are employed, and the adversary can easily convert the high-risk model to a malicious one by flipping only one critical bit on average.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是提出一种基于训练的位置攻击，用于攻击深度神经网络（DNNs）的安全性。</li>
<li>methods: 该攻击利用了内存错误注入技术，如行撞击，并在训练阶段由敌方参与建立高风险模型。攻击者可以在部署阶段通过只flipping一个关键位来将高风险模型转换为恶意模型。</li>
<li>results: 该攻击可以快速地转换高风险模型为恶意模型，并且对防御措施仍然构成了一定的威胁。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \textbf{flipping only one critical bit} on average in the deployment stage. Moreover, our attack still poses a significant threat even when defenses are employed. The codes for reproducing main experiments are available at \url{https://github.com/jianshuod/TBA}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HyperFormer-Enhancing-Entity-and-Relation-Interaction-for-Hyper-Relational-Knowledge-Graph-Completion"><a href="#HyperFormer-Enhancing-Entity-and-Relation-Interaction-for-Hyper-Relational-Knowledge-Graph-Completion" class="headerlink" title="HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion"></a>HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06512">http://arxiv.org/abs/2308.06512</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiweihu1103/hkgc-hyperformer">https://github.com/zhiweihu1103/hkgc-hyperformer</a></li>
<li>paper_authors: Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan</li>
<li>for: 这个论文主要目标是完善具有 attribute-value 赋值的高级知识图（HKG），以推理未知 triple 而考虑其赋值。</li>
<li>methods: 这个论文提出了 HyperFormer 模型，该模型利用了本地级别的序列信息，包括实体、关系和赋值的内容，以提高 triple 预测的精度。模型包括三个不同模块：实体邻居聚合模块、关系赋值聚合模块和卷积推理模块。</li>
<li>results: 经过广泛的实验 validate 了 HyperFormer 模型在三个知识图 datasets 上的效果，并且在不同的条件下进行了比较。模型在实验中表现出了明显的优势。代码和数据可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by associating attribute-value qualifiers to triples, which effectively represent additional fine-grained information about its associated triple. Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown triples while considering its qualifiers. Most existing approaches to HKGC exploit a global-level graph structure to encode hyper-relational knowledge into the graph convolution message passing process. However, the addition of multi-hop information might bring noise into the triple prediction process. To address this problem, we propose HyperFormer, a model that considers local-level sequential information, which encodes the content of the entities, relations and qualifiers of a triple. More precisely, HyperFormer is composed of three different modules: an entity neighbor aggregator module allowing to integrate the information of the neighbors of an entity to capture different perspectives of it; a relation qualifier aggregator module to integrate hyper-relational knowledge into the corresponding relation to refine the representation of relational content; a convolution-based bidirectional interaction module based on a convolutional operation, capturing pairwise bidirectional interactions of entity-relation, entity-qualifier, and relation-qualifier. realize the depth perception of the content related to the current statement. Furthermore, we introduce a Mixture-of-Experts strategy into the feed-forward layers of HyperFormer to strengthen its representation capabilities while reducing the amount of model parameters and computation. Extensive experiments on three well-known datasets with four different conditions demonstrate HyperFormer's effectiveness. Datasets and code are available at https://github.com/zhiweihu1103/HKGC-HyperFormer.
</details>
<details>
<summary>摘要</summary>
超过标准知识 graphs (HKGs) 将 attribute-value 资讯 associates 到 triplets, 实际表示了对应 triplets 的详细信息。 hyper-relational 知识图完成 (HKGC) 目标是预测未知 triplets, 考虑其资讯。现有大多数 HKGC 方法利用全局级图结构编码 hyper-relational 知识到图 convolution 消息传递过程中。然而，添加多个跳跃信息可能会带来 triple 预测过程中的噪声。为解决这个问题，我们提出了 HyperFormer，一种模型，考虑本地级别的顺序信息，对 entitites、关系和资讯的内容进行编码。更加准确地说，HyperFormer 由三个不同模块组成：一个 entity neighbor aggregator 模块，用于将 entity 的 neighborgraph 信息集成，以 Capture 不同的 perspective of it; 一个 relation qualifier aggregator 模块，用于将 hyper-relational 知识 integrate 到对应关系中，以 Refine 关系内容的表示; 一个基于 convolution 操作的 bidirectional interaction module，用于 Capture entity-relation、entity-qualifier 和 relation-qualifier 对的 pairwise bidirectional interactions, 实现对当前声明的深度认知。此外，我们在 HyperFormer 的 feed-forward 层中引入 Mixture-of-Experts 策略，以增强其表示能力，同时减少模型参数和计算量。extensive experiments 表明 HyperFormer 有效。数据集和代码可以在 <https://github.com/zhiweihu1103/HKGC-HyperFormer> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Three-Ways-of-Using-Large-Language-Models-to-Evaluate-Chat"><a href="#Three-Ways-of-Using-Large-Language-Models-to-Evaluate-Chat" class="headerlink" title="Three Ways of Using Large Language Models to Evaluate Chat"></a>Three Ways of Using Large Language Models to Evaluate Chat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06502">http://arxiv.org/abs/2308.06502</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oplatek/chateval-llm">https://github.com/oplatek/chateval-llm</a></li>
<li>paper_authors: Ondřej Plátek, Vojtěch Hudeček, Patricia Schmidtová, Mateusz Lango, Ondřej Dušek</li>
<li>for: 这个论文描述了由team6提交的ChatEval竞赛中的系统，包括三种基于大语言模型（LLMs）预测对话机器人回复质量的方法。</li>
<li>methods: 论文描述了三种方法，包括使用动态少量示例从矢量存储中提取提示，以及对其他两种方法的分析和未来工作的需求。</li>
<li>results: 论文报告了基于这三种方法的改进，包括使用动态少量示例从矢量存储中提取提示的改进。同时，论文还报告了其他两种方法的性能分析和未来工作的需求。<details>
<summary>Abstract</summary>
This paper describes the systems submitted by team6 for ChatEval, the DSTC 11 Track 4 competition. We present three different approaches to predicting turn-level qualities of chatbot responses based on large language models (LLMs). We report improvement over the baseline using dynamic few-shot examples from a vector store for the prompts for ChatGPT. We also analyze the performance of the other two approaches and report needed improvements for future work. We developed the three systems over just two weeks, showing the potential of LLMs for this task. An ablation study conducted after the challenge deadline shows that the new Llama 2 models are closing the performance gap between ChatGPT and open-source LLMs. However, we find that the Llama 2 models do not benefit from few-shot examples in the same way as ChatGPT.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了团队6在ChatEval DSTC 11 Track 4比赛中提交的三种不同方法来预测对话机器人响应质量。我们使用大型自然语言模型（LLM）来预测对话机器人响应的每个转折质量。我们发现使用动态少量示例从向量存储中提取的Prompt对ChatGPT的性能有所提升。我们还分析了其他两种方法的性能并报告了未来工作中所需的改进。我们在只有两周时间内开发了这三种系统，这表明LLMs在这个任务中的潜力。经过比赛结束后的抽象研究发现，新的Llama 2模型在关键性能方面追近ChatGPT和开源LLMs的性能。然而，我们发现Llama 2模型不如ChatGPT那样受益于少量示例。
</details></li>
</ul>
<hr>
<h2 id="Latent-Emission-Augmented-Perspective-Taking-LEAPT-for-Human-Robot-Interaction"><a href="#Latent-Emission-Augmented-Perspective-Taking-LEAPT-for-Human-Robot-Interaction" class="headerlink" title="Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction"></a>Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06498">http://arxiv.org/abs/2308.06498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiqi Chen, Jing Yu Lim, Kingsley Kuan, Harold Soh</li>
<li>for: 本文是为了帮助机器人进行视角理解，即理解人类的视角和信念。</li>
<li>methods: 本文使用了深度世界模型，允许机器人进行视觉和概念上的视角理解，即能够推断人类看到和信任的内容。</li>
<li>results: 实验表明，本方法在三个半可见人机交互任务中表现出色，与现有的基准值进行比较，显著超越了基准值。<details>
<summary>Abstract</summary>
Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and beliefs on three partially-observable HRI tasks. Experiments show that our method significantly outperforms existing baselines and is able to infer visual observations available to other agent and their internal beliefs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="EgoPoser-Robust-Real-Time-Ego-Body-Pose-Estimation-in-Large-Scenes"><a href="#EgoPoser-Robust-Real-Time-Ego-Body-Pose-Estimation-in-Large-Scenes" class="headerlink" title="EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes"></a>EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06493">http://arxiv.org/abs/2308.06493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Jiang, Paul Streli, Manuel Meier, Christian Holz</li>
<li>for: 这篇论文旨在解决headset上的 egopose估计问题，即只使用头和手部位的位姿来估计全身姿态。</li>
<li>methods: 该论文提出了一种新的输入表示方法和一种新的运动分解方法，以估计全身姿态独立于全局位置。此外，它还能够对不同用户的体型进行robust模型。</li>
<li>results: 实验表明，该论文在质量和量化上都有较好的表现，而且可以保持高速推断速度（大于600帧&#x2F;秒）。这篇论文为将来的工作提供了一个可靠的基线，即全身姿态估计不再需要外部捕捉，并可以在大景观环境中扩展。<details>
<summary>Abstract</summary>
Full-body ego-pose estimation from head and hand poses alone has become an active area of research to power articulate avatar representation on headset-based platforms. However, existing methods over-rely on the confines of the motion-capture spaces in which datasets were recorded, while simultaneously assuming continuous capture of joint motions and uniform body dimensions. In this paper, we propose EgoPoser, which overcomes these limitations by 1) rethinking the input representation for headset-based ego-pose estimation and introducing a novel motion decomposition method that predicts full-body pose independent of global positions, 2) robustly modeling body pose from intermittent hand position and orientation tracking only when inside a headset's field of view, and 3) generalizing across various body sizes for different users. Our experiments show that EgoPoser outperforms state-of-the-art methods both qualitatively and quantitatively, while maintaining a high inference speed of over 600 fps. EgoPoser establishes a robust baseline for future work, where full-body pose estimation needs no longer rely on outside-in capture and can scale to large-scene environments.
</details>
<details>
<summary>摘要</summary>
全身ego姿 estimation从头和手姿alone已成为研究的活跃领域，以提供头盔平台上的人物表现。然而，现有方法受到数据采集空间的限制，同时假设持续采集 JOINT 动作和一致体 dimensions。在这篇论文中，我们提出了 EgoPoser，它缓解了这些限制，通过：1. 重新定义头盔基于的输入表示，并 introduce 一种新的运动分解方法，可以独立地预测全身姿。2. 可靠地模型体姿从头盔视野内部的间歇手姿和方向追踪。3. 对不同用户的体型进行一致化。我们的实验表明，EgoPoser 超过了现有方法的质量和量化表现，同时保持了高速度推断速度超过 600 fps。EgoPoser 建立了一个可靠的基线，将全身姿推断带到大景景环境中。
</details></li>
</ul>
<hr>
<h2 id="Generating-Faithful-Text-From-a-Knowledge-Graph-with-Noisy-Reference-Text"><a href="#Generating-Faithful-Text-From-a-Knowledge-Graph-with-Noisy-Reference-Text" class="headerlink" title="Generating Faithful Text From a Knowledge Graph with Noisy Reference Text"></a>Generating Faithful Text From a Knowledge Graph with Noisy Reference Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06488">http://arxiv.org/abs/2308.06488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tahsina Hashem, Weiqing Wang, Derry Tanti Wijaya, Mohammed Eunus Ali, Yuan-Fang Li</li>
<li>for: 这个论文的目的是提出一种基于知识图（KG）的自然语言生成模型，能够生成准确表示知识图信息的自然语言文本。</li>
<li>methods: 该模型使用了对抗学习和可控文本生成技术，以提高模型对 faithful 信息的识别和控制。</li>
<li>results: 论文的实验结果表明，该模型在 faithfulness 方面表现出色，超过了现有的状态艺文。<details>
<summary>Abstract</summary>
Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.
</details>
<details>
<summary>摘要</summary>
知识图（KG）-to-文本生成目标是生成流畅自然语言文本，准确表达给定知识图中的信息。虽然现有模型通过利用适当的前训练语言模型（PLMs）和合适的图结构意识模块，已经取得了显著的进步，但现有模型仍然无法生成准确的文本，特别是当参考文本中含有不在知识图中的信息时。在这篇论文中，我们开发了一种KG-to-文本生成模型，可以从给定图生成准确的自然语言文本，并在参考文本中含有噪音时提供 faithful 的文本生成。我们的框架包括两个核心想法：首先，我们利用对比学习增强模型的能力，在文本中划分 faithful 和幻想信息，从而让解码器生成与输入图相关的文本。其次，我们赋予解码器控制幻想度的能力，通过使用可控文本生成技术。我们通过标准的量化度量以及基于 ChatGPT 的量化和质量分析进行评估。我们的评估结果表明，我们的模型在准确性方面与当前状态的 KG-to-文本模型相比，表现出优异的性能。
</details></li>
</ul>
<hr>
<h2 id="Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks"><a href="#Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks" class="headerlink" title="Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks"></a>Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06467">http://arxiv.org/abs/2308.06467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Garaev, Bader Rasheed, Adil Khan<br>for: This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks.methods: The study explores the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. The study employs canonical correlation analysis, visualizes the representations, and calculates the mean distance between these representations and various DNN decision boundaries.results: The study finds a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the impact of adversarial attack norms on DNN representations, focusing on samples subjected to $L_2$ and $L_{\infty}$ norm attacks. Further, we employ canonical correlation analysis, visualize the representations, and calculate the mean distance between these representations and various DNN decision boundaries. Our results reveal a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Label-Knowledge-Distillation"><a href="#Multi-Label-Knowledge-Distillation" class="headerlink" title="Multi-Label Knowledge Distillation"></a>Multi-Label Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06453">http://arxiv.org/abs/2308.06453</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/penghui-yang/l2d">https://github.com/penghui-yang/l2d</a></li>
<li>paper_authors: Penghui Yang, Ming-Kun Xie, Chen-Chen Zong, Lei Feng, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang</li>
<li>for: 这篇论文主要针对多标签学习问题，旨在提出一种基于知识储存技术的多标签知识传递方法。</li>
<li>methods: 该方法首先将多标签学习问题分解成多个二分类问题，然后通过分别对每个二分类问题进行知识储存来增强学习的特征表示。同时，该方法还利用标签嵌入结构来提高特征表示的独特性。</li>
<li>results: 实验结果表明，提出的方法可以减少标签之间的知识冲突，并且在多个 benchmark 数据集上达到了较高的性能水平，比较于其他比较方法。<details>
<summary>Abstract</summary>
Existing knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the proposed method can avoid knowledge counteraction among labels, thus achieving superior performance against diverse comparing methods. Our code is available at: https://github.com/penghui-yang/L2D
</details>
<details>
<summary>摘要</summary>
现有的知识传授方法通常是将教师网络的输出几何或中间特征图形知识传授到学生网络，这很成功在多类单 Label 学习中。但这些方法几乎无法扩展到多Label学习情况下，因为预测概率不会加总到一，且特征图形全例可能忽略次要类别。在本文中，我们提出了一个新的多Label知识传授方法。一方面，它利用多Label学习问题中的 semantic 知识，将问题分成多个二分类问题；另一方面，它利用类别对称信息来强化学习的特征表现。实验结果显示，提案的方法可以避免知识抵触 Label 之间，因此在多个比较方法面上获得了更好的性能。我们的代码可以在：https://github.com/penghui-yang/L2D 中找到。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Equivariant-Mixup"><a href="#Semantic-Equivariant-Mixup" class="headerlink" title="Semantic Equivariant Mixup"></a>Semantic Equivariant Mixup</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06451">http://arxiv.org/abs/2308.06451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zongbo Han, Tianchi Xie, Bingzhe Wu, Qinghua Hu, Changqing Zhang</li>
<li>for: 提高模型对分布Shift的 Robustness，通过在表示空间强制保持输入数据的结构不变。</li>
<li>methods: 基于semantic-equivariance assumption的generic mixup regularization，使得模型在混合样本中学习更多的semantic information。</li>
<li>results: 经过extensive empirical studies和qualitative analyzes，表明提出的方法可以提高模型的Robustness和Generalization能力。<details>
<summary>Abstract</summary>
Mixup is a well-established data augmentation technique, which can extend the training distribution and regularize the neural networks by creating ''mixed'' samples based on the label-equivariance assumption, i.e., a proportional mixup of the input data results in the corresponding labels being mixed in the same proportion. However, previous mixup variants may fail to exploit the label-independent information in mixed samples during training, which usually contains richer semantic information. To further release the power of mixup, we first improve the previous label-equivariance assumption by the semantic-equivariance assumption, which states that the proportional mixup of the input data should lead to the corresponding representation being mixed in the same proportion. Then a generic mixup regularization at the representation level is proposed, which can further regularize the model with the semantic information in mixed samples. At a high level, the proposed semantic equivariant mixup (sem) encourages the structure of the input data to be preserved in the representation space, i.e., the change of input will result in the obtained representation information changing in the same way. Different from previous mixup variants, which tend to over-focus on the label-related information, the proposed method aims to preserve richer semantic information in the input with semantic-equivariance assumption, thereby improving the robustness of the model against distribution shifts. We conduct extensive empirical studies and qualitative analyzes to demonstrate the effectiveness of our proposed method. The code of the manuscript is in the supplement.
</details>
<details>
<summary>摘要</summary>
混合是一种已有的数据增强技术，可以使得训练分布延伸并规范神经网络，通过创建基于标签相似性假设的混合样本。然而，先前的混合变体可能会忽略混合样本中的标签独立信息，这些信息通常含有更加丰富的 semantics。为了更好地发挥混合的力量，我们首先提高了先前的标签相似性假设，使其转化为 semantics相似性假设，即混合输入数据时，应该对应的表示也在同样的比例进行混合。然后，我们提出了一种通用的混合规范，可以在表示层进行规范，以更加规范模型。总的来说，我们的 semantic equivariant mixup（sem）方法要求输入数据的结构在表示空间保持不变，即输入变化后，获得的表示信息也会在同样的比例进行变化。与先前的混合变体不同，我们的方法更关注于保持输入中更加丰富的 semantics信息，从而提高模型对分布偏移的Robustness。我们进行了广泛的实验和质量分析，以证明我们的提议的效iveness。代码在附录中。
</details></li>
</ul>
<hr>
<h2 id="A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing"><a href="#A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing" class="headerlink" title="A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing"></a>A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06447">http://arxiv.org/abs/2308.06447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miladramzy/sequentialmetatransferpinns">https://github.com/miladramzy/sequentialmetatransferpinns</a></li>
<li>paper_authors: Milad Ramezankhani, Abbas S. Milani</li>
<li>for: 解决非线性偏微分方程（PDE）问题，提高物理学法的泛化能力。</li>
<li>methods: 使用sequential meta-transfer（SMT）学习框架，将时间域分解成小时段，每个时间段使用meta-学习器进行快速适应。</li>
<li>results: 在一个复杂系统中，通过使用SMT学习框架，可以明显提高PINNs的适应能力，同时减少计算成本，提高效率。<details>
<summary>Abstract</summary>
Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100.
</details>
<details>
<summary>摘要</summary>
物理学教导神经网络（PINNs）在解决非线性偏微分方程（PDEs）中得到了广泛应用，通过将物理法则 integrate到神经网络训练中，使其在科学和工程应用中优于传统方法。然而，传统的PINNs在处理复杂系统中仍然缺乏精度，特别是在长时间域内。此外，由于PINNs是为某种特定的PDE系统进行适应，因此缺乏可重用的扩展性，需要在新系统配置时重新从零开始训练，这会增加计算成本。为了解决这些缺陷，本文提出了一种新的时序顺序多模式学习（SMT）框架，用于快速训练和高效适应PINNs在非线性系统中。特别是，该框架将时间域 decomposes 为 smaller time segments，以创建"更容易"的PDE问题，以便PINNs的快速训练。然后，每个时间段中分配了一个meta-学习器，并在快速适应一系列相关任务的基础上进行了优化。然后，通过转移学习原理，在时间间隔内进行了进一步的计算成本减少。通过一个复杂材料自动炉处理案例研究，显示SMT可以明显提高PINNs的适应性，同时显著减少计算成本，比例为100。
</details></li>
</ul>
<hr>
<h2 id="Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation"><a href="#Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation" class="headerlink" title="Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation"></a>Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06422">http://arxiv.org/abs/2308.06422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedarmin Azizi, Mahdi Nazemi, Arash Fayyazi, Massoud Pedram</li>
<li>for: 这篇论文的目的是提出一种自动选择神经网络层的最佳位元数和层宽的搜寻方法，以提高深度学习模型的效率。</li>
<li>methods: 这篇论文使用的方法包括对神经网络层的位元数和层宽进行自动选择，并使用希瑟尔基于删除的搜寻范围缩小技术，以便快速寻找最佳设计。它还使用树结构的Parzen估计器来建立代表性模型，以便快速探索不同的架构可能性。</li>
<li>results: 这篇论文的结果显示，与现有的压缩策略相比，这种方法可以实现20%的模型大小减少，不会对准确性产生影响。另外，这种方法的搜寻时间仅需12倍于目前最佳搜寻策略，使得快速设计和实现深度学习解决方案成为可能。<details>
<summary>Abstract</summary>
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 20% decrease in model size without compromising accuracy. Additionally, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available. As a result, our proposed method represents a leap forward in neural network design optimization, paving the way for quick model design and implementation in settings with limited resources, thereby propelling the potential of scalable deep learning solutions.
</details>
<details>
<summary>摘要</summary>
“深度学习模型的复杂性和计算需求逐渐增加，因此有效地优化神经网络设计的搜索方法变得非常重要。这项工作提出了一种新的搜索机制，可以自动选择神经网络层的最佳位数和宽度。这会导致深度神经网络的效率得到明显提高。在搜索空间中，我们利用希腊拟合法（Hessian-based pruning）缩小搜索范围，以便快速消除不重要的参数。然后，我们采用分布式树结构的Parzen估计器来构建代表性模型，以便快速探索不同的建筑方案。这种策略可以快速寻找最佳设计，并且可以保证模型的准确性不受影响。我们对知名的数据集进行了严格的测试，并证明了我们的方法与现有方法相比，可以录入20%的模型大小减少，同时保持准确性不变。此外，我们的方法可以在搜索时间方面实现12倍的提升，相比于目前最佳的搜索焦点策略。因此，我们的提议方法代表了神经网络设计优化领域的一大突破，为具有限制资源的场景中快速实现神经网络设计，铺平深度学习解决方案的可能性。”
</details></li>
</ul>
<hr>
<h2 id="Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review"><a href="#Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review" class="headerlink" title="Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review"></a>Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06419">http://arxiv.org/abs/2308.06419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: The paper is written for the development of practical pedestrian trajectory prediction algorithms for autonomous vehicles (AVs) in unstructured environments.</li>
<li>methods: The paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in the presence of vehicles, and investigates specific considerations for pedestrian-vehicle interaction.</li>
<li>results: The paper provides an overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers, and discusses research gaps and directions for future work, such as the need for more effective definition of interacting agents in deep learning methods and the need for more datasets of mixed traffic in unstructured environments.Here are the three points in Simplified Chinese text:</li>
<li>for: 本文是为了开发可行的步行者轨迹预测算法，用于自动驾驶车辆（AV）在无结构环境中。</li>
<li>methods: 本文系统地查询了Literature中的不同方法，用于模拟步行者轨迹预测在车辆存在下。</li>
<li>results: 本文提供了各种数据集，包括步行者和车辆的轨迹数据，并讨论了未来研究的潜在空间，如深度学习方法中的交互代理定义和无结构环境中混合交通数据的收集。<details>
<summary>Abstract</summary>
Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed.
</details>
<details>
<summary>摘要</summary>
планирование пути автономного транспортного средства (АВ) в пространстве, разделенном с пешеходами, требует расчета будущих траекторий пешеходов. практический алгоритм предсказания траекторий пешеходов для использования АВ должен учитывать влияние взаимодействия автомобиля с пешеходами на будущие движения людей. в этом смысле, этот папяр систематически обзорывает разные методы, предложенные в литературе для моделирования предсказания траекторий пешеходов в присутствии автомобилей, которые могут быть применены в неструктурированных средах. папяр также рассматривает специфические условия для взаимодействия пешеходов и автомобилей (в сравнении с взаимодействием пешеходов-пешеходов) и обзоры, как различные переменные, такие как неопределенности предсказаний и различия в поведении, учитываются в предыдущих предсказательных моделях. following PRISMA guidelines, articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. a total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. an overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments, are discussed.
</details></li>
</ul>
<hr>
<h2 id="Dialogue-Possibilities-between-a-Human-Supervisor-and-UAM-Air-Traffic-Management-Route-Alteration"><a href="#Dialogue-Possibilities-between-a-Human-Supervisor-and-UAM-Air-Traffic-Management-Route-Alteration" class="headerlink" title="Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration"></a>Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06411">http://arxiv.org/abs/2308.06411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeongseok Kim, Kangjin Kim</li>
<li>for: 本研究旨在提出一种基于知识表示和逻辑的城市航空交通管理（UATM）拓扑管理方法，以便快速Identify safe和高效的 Routes in a carefully sampled environment.</li>
<li>methods: 本方法使用Answer Set Programming（ASP）实现，其中包括非 monotonic reasoning和两个阶段对话，考虑安全和可能的影响因素。</li>
<li>results: 经过多个查询从两个 simulations scenarios， validate了提出的方法的可靠性和有效性。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
This paper introduces a novel approach to detour management in Urban Air Traffic Management (UATM) using knowledge representation and reasoning. It aims to understand the complexities and requirements of UAM detours, enabling a method that quickly identifies safe and efficient routes in a carefully sampled environment. This method implemented in Answer Set Programming uses non-monotonic reasoning and a two-phase conversation between a human manager and the UATM system, considering factors like safety and potential impacts. The robustness and efficacy of the proposed method were validated through several queries from two simulation scenarios, contributing to the symbiosis of human knowledge and advanced AI techniques. The paper provides an introduction, citing relevant studies, problem formulation, solution, discussions, and concluding comments.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的偏航管理方法（Detour Management），用于城市空中交通管理（UATM），利用知识表示和推理。它旨在理解城市垂直飞行偏航的复杂性和需求，以便快速地确定安全和高效的路径，并在精心采样的环境中进行。这种方法使用了非 monotonic 推理和两个阶段的人工管理和UATM系统之间的对话，考虑了安全和可能的影响因素。该方法的可靠性和有效性通过多个查询来 validate，来自两个 simulate enario。这篇论文提供了引言、相关研究、问题表述、解决方案、讨论和结论。
</details></li>
</ul>
<hr>
<h2 id="A-Brain-Computer-Interface-Augmented-Reality-Framework-with-Auto-Adaptive-SSVEP-Recognition"><a href="#A-Brain-Computer-Interface-Augmented-Reality-Framework-with-Auto-Adaptive-SSVEP-Recognition" class="headerlink" title="A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition"></a>A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06401">http://arxiv.org/abs/2308.06401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasmine Mustafa, Mohamed Elmahallawy, Tie Luo, Seif Eldawlatly</li>
<li>for: 该研究旨在开发一种可以满足不同个体的脑电信号特点的简单适应集合分类系统，以便在脑机接口（BCI）和增强现实（AR）技术的应用中提高抗骚抗振性能。</li>
<li>methods: 该研究使用了稳态视觉谱波（SSVEP）信号 Pattern，并提出了一种简单的BCI-AR框架，以支持广泛的SSVEP-based BCI-AR应用程序的开发。</li>
<li>results: 测试结果显示，我们的ensemble分类方法在SSVEP-based BCI-AR应用程序中表现出了Robust性，并且与之前的研究相比，我们的方法在包括头部运动的情况下仍然能够达到80%的正确率（在PC上）和77%的正确率（使用HoloLens AR头盔）。此外，我们的视觉刺激时间为5秒，相对较短。<details>
<summary>Abstract</summary>
Brain-Computer Interface (BCI) initially gained attention for developing applications that aid physically impaired individuals. Recently, the idea of integrating BCI with Augmented Reality (AR) emerged, which uses BCI not only to enhance the quality of life for individuals with disabilities but also to develop mainstream applications for healthy users. One commonly used BCI signal pattern is the Steady-state Visually-evoked Potential (SSVEP), which captures the brain's response to flickering visual stimuli. SSVEP-based BCI-AR applications enable users to express their needs/wants by simply looking at corresponding command options. However, individuals are different in brain signals and thus require per-subject SSVEP recognition. Moreover, muscle movements and eye blinks interfere with brain signals, and thus subjects are required to remain still during BCI experiments, which limits AR engagement. In this paper, we (1) propose a simple adaptive ensemble classification system that handles the inter-subject variability, (2) present a simple BCI-AR framework that supports the development of a wide range of SSVEP-based BCI-AR applications, and (3) evaluate the performance of our ensemble algorithm in an SSVEP-based BCI-AR application with head rotations which has demonstrated robustness to the movement interference. Our testing on multiple subjects achieved a mean accuracy of 80\% on a PC and 77\% using the HoloLens AR headset, both of which surpass previous studies that incorporate individual classifiers and head movements. In addition, our visual stimulation time is 5 seconds which is relatively short. The statistically significant results show that our ensemble classification approach outperforms individual classifiers in SSVEP-based BCIs.
</details>
<details>
<summary>摘要</summary>
Initially, Brain-Computer Interface (BCI) 引起关注的应用是为Physically impaired individuals 提高生活质量。然而， BCIs 的潜在应用不仅限于这些人群，还可以为健康用户开发主流应用程序。 BCIs 使用 Steady-state Visually-evoked Potential (SSVEP) 信号模式， capture 脑的响应，并使用 BCIs 来表达需求或愿望。然而，每个人的脑信号不同，因此需要每个人SSVEP 认知。此外，肌肉运动和眼睛跳动会干扰脑信号，因此需要用户在BCI实验中保持静止，限制了AR的应用。在这篇论文中，我们提出了一种简单的适应集成分类系统，可以处理每个人的差异。我们还提出了一种支持广泛SSVEP 基于 BCIs 应用程序的简单AR框架。我们的结果表明，我们的集成分类方法在SSVEP 基于 BCIs 的AR应用程序中，可以快速响应用户的需求或愿望，并且在多个测试人群中表现出 statistically significant 的表现。我们的测试结果显示，我们的集成分类方法在PC 和 HoloLens AR 头盔中都可以达到80%和77%的准确率，这 beiden超过了以个体分类器和头部运动混合的前一 Studies。此外，我们的视觉刺激时间为5秒，相对较短。总之，我们的研究表明，集成分类方法在SSVEP 基于 BCIs 的AR应用程序中表现出了优于个体分类器的表现。这 suggets that our ensemble classification approach can be a promising solution for developing mainstream BCI-AR applications.
</details></li>
</ul>
<hr>
<h2 id="ZYN-Zero-Shot-Reward-Models-with-Yes-No-Questions"><a href="#ZYN-Zero-Shot-Reward-Models-with-Yes-No-Questions" class="headerlink" title="ZYN: Zero-Shot Reward Models with Yes-No Questions"></a>ZYN: Zero-Shot Reward Models with Yes-No Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06385">http://arxiv.org/abs/2308.06385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vicgalle/zero-shot-reward-models">https://github.com/vicgalle/zero-shot-reward-models</a></li>
<li>paper_authors: Victor Gallego</li>
<li>for: 本文提出了一种解决方案，用于指导语言模型生成文本，以便与人类操作员的偏好相align。</li>
<li>methods: 该方法使用另一个语言模型作为批评者和奖励模型，通过一个Yes-No问题的提问来表达用户偏好，无需进一步的标注数据。</li>
<li>results: 在不同的文本生成领域中，包括毒瘤化、修正电影评论的情感、控制模型对某个话题的看法，以及个性化文本生成器的推荐等方面，实验证明了提议的ZYN框架的可能性。<details>
<summary>Abstract</summary>
In this work, we address the problem of directing the text generations of a LLM towards a desired behavior, aligning the generated text with the preferences of the human operator. We propose using another language model as a critic, reward model in a zero-shot way thanks to the prompt of a Yes-No question that represents the user preferences, without requiring further labeled data. This zero-shot reward model provides the learning signal to further fine-tune the base LLM using reinforcement learning, as in RLAIF; yet our approach is also compatible in other contexts such as quality-diversity search. Extensive evidence of the capabilities of the proposed ZYN framework is provided through experiments in different domains related to text generation, including detoxification; optimizing sentiment of movie reviews, or any other attribute; steering the opinion about a particular topic the model may have; and personalizing prompt generators for text-to-image tasks. Code to be released at \url{https://github.com/vicgalle/zero-shot-reward-models/}.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们解决了直接将语言生成模型（LLM）引导到所需行为的问题，将生成的文本与人类运行员的偏好相align。我们提议使用另一个语言模型作为批评者、奖励模型，通过Zero-shot manner，只需通过问题提示（Yes-No问题）表示用户偏好，无需更多的标注数据。这种Zero-shot奖励模型为基础LLM进行了进一步微调，使用束缚学习，类似RLAIF;而我们的方法也可以在其他上下文中使用，如质量多样性搜索。我们通过不同领域的文本生成实验提供了广泛的证据，包括毒瘤化、修改电影评论的情感、控制模型对某个话题的看法，以及个性化提示生成器 для文本到图像任务。代码将在 \url{https://github.com/vicgalle/zero-shot-reward-models/} 上发布。
</details></li>
</ul>
<hr>
<h2 id="DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System"><a href="#DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System" class="headerlink" title="DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System"></a>DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06378">http://arxiv.org/abs/2308.06378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojtaba Yeganejou, Kimia Honari, Ryan Kluzinski, Scott Dick, Michael Lipsett, James Miller</li>
<li>for: 该研究旨在提出一种新的深度学习模型，以提高模型的透明度而不增加准确性的损失。</li>
<li>methods: 该研究使用了深度 convolutional neuro-fuzzy inference system (DCNFIS)，即将深度学习模型和逻辑学习模型相结合，以提高模型的透明度。</li>
<li>results: 研究发现，DCNFIS可以与现有的三种 convolutional neural networks 相比，在四个公共数据集上表现相当准确。此外，DCNFIS还可以超过当前的深度逻辑系统的性能。此外，通过解释来源于逻辑规则的质量分析，该研究还发现了一些有用的特性。<details>
<summary>Abstract</summary>
A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释人工智能是论文质量和直观性之间的交换。我们报告了一种新的深度网络的设计，该网络可以提高直观性而无需牺牲准确性。我们将深度 convolutional neuro-fuzzy inference system (DCNFIS) 设计为混合深度学习和规则逻辑模型，并证明 DCNFIS 在四个常见数据集上表现和三种现有的 convolutional neural networks 相同。此外，我们还证明 DCNFIS 在深度逻辑系统中表现更出色。然后，我们利用规则逻辑的透明性，从 DCNFIS 中提取出解释，以幻灯片的形式表示。我们在 Fashion-MNIST 数据集中进一步调查了这些解释的性质。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Knowledge-Graphs-Opportunities-and-Challenges"><a href="#Large-Language-Models-and-Knowledge-Graphs-Opportunities-and-Challenges" class="headerlink" title="Large Language Models and Knowledge Graphs: Opportunities and Challenges"></a>Large Language Models and Knowledge Graphs: Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06374">http://arxiv.org/abs/2308.06374</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Jeff Z. Pan, Simon Razniewski, Jan-Christoph Kalo, Sneha Singhania, Jiaoyan Chen, Stefan Dietze, Hajira Jabeen, Janna Omeliyanenko, Wen Zhang, Matteo Lissandrini, Russa Biswas, Gerard de Melo, Angela Bonifati, Edlira Vakaj, Mauro Dragoni, Damien Graux</li>
<li>for: 本研究论文探讨了大语言模型（LLM）在知识表示方面的发展，以及这些模型对知识图和 parametric knowledge 的影响。</li>
<li>methods: 本文使用了许多现有的知识表示方法，如知识图和Parametric knowledge，以及一些新的研究方法。</li>
<li>results: 本文总结了一些关于 LLMs 和知识图的共识和观点，并提出了一些可能的研究方向和挑战。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have taken Knowledge Representation -- and the world -- by storm. This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge. In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Wireless-Federated-k-Means-Clustering-with-Non-coherent-Over-the-Air-Computation"><a href="#Wireless-Federated-k-Means-Clustering-with-Non-coherent-Over-the-Air-Computation" class="headerlink" title="Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation"></a>Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06371">http://arxiv.org/abs/2308.06371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alphan Sahin</li>
<li>for: 降低无线网络上实现 Federated k-means 算法时的每次通信延迟</li>
<li>methods: 使用 Over-the-air computation（OAC）方案，通过编码器利用数字征在均匀数系统中的表示，通过无线多访问通道的信号积加性性质消除精确时钟和频率同步需求</li>
<li>results: 对客户位置 clustering 场景进行 demonstration，比较标准 k-means  clustering 和提议方法的性能，结果显示提议方法与标准 k-means 性能相似，同时降低了通信延迟<details>
<summary>Abstract</summary>
In this study, we propose using an over-the-air computation (OAC) scheme for the federated k-means clustering algorithm to reduce the per-round communication latency when it is implemented over a wireless network. The OAC scheme relies on an encoder exploiting the representation of a number in a balanced number system and computes the sum of the updates for the federated k-means via signal superposition property of wireless multiple-access channels non-coherently to eliminate the need for precise phase and time synchronization. Also, a reinitialization method for ineffectively used centroids is proposed to improve the performance of the proposed method for heterogeneous data distribution. For a customer-location clustering scenario, we demonstrate the performance of the proposed algorithm and compare it with the standard k-means clustering. Our results show that the proposed approach performs similarly to the standard k-means while reducing communication latency.
</details>
<details>
<summary>摘要</summary>
在这种研究中，我们提议使用无线电 computation（OAC）方案来降低在无线网络上实现 federated k-means 算法时的每轮通信延迟。 OAC 方案利用一个编码器利用数字 representation 在平衡数系统中的特性，通过无线多接入通道的信号重叠性性质来消除精确的时钟和相位同步需求。此外，我们还提出了一种重新初始化不合适使用的中心点方法，以提高提案方法在不同数据分布情况下的性能。为一个客户位置 clustering 场景，我们展示了提案的算法性能和标准 k-means 集群算法的比较，我们的结果表明，提案的方法与标准 k-means 集群算法性能相似，同时降低了通信延迟。
</details></li>
</ul>
<hr>
<h2 id="Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems"><a href="#Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems" class="headerlink" title="Topic-Level Bayesian Surprise and Serendipity for Recommender Systems"></a>Topic-Level Bayesian Surprise and Serendipity for Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06368">http://arxiv.org/abs/2308.06368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ton-moy/surprise-and-serendipity">https://github.com/ton-moy/surprise-and-serendipity</a></li>
<li>paper_authors: Tonmoy Hasan, Razvan Bunescu</li>
<li>for: 提高推荐系统的多样性，使用高度可能性的推荐项，让用户体验到新、未看过的类别。</li>
<li>methods: 使用 bayesian 惊喜来衡量item的意外性，并结合协同推荐算法来找到相似用户。</li>
<li>results: 实验结果表明，使用 bayesian 惊喜与距离基于的优化方法相比，对于时间和主题层次的意外性的评估更加准确，并且在推荐高度可能性的项目方面获得更好的性能。<details>
<summary>Abstract</summary>
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.
</details>
<details>
<summary>摘要</summary>
一个推荐系统仅将推荐项目调整为用户的预先消耗项目历史，可能会创建一个范例弹性泡箱，让用户无法体验到未看过的类别。为了解决这个问题，可以推荐有高可能性的意外项目，即吸引用户高度评价的项目。在这篇论文中，我们提出了基于bayesian surprise的内容基于的serendipity表现，并使用它来衡量项目被用户过后评价后的surprise程度。当与相似用户的协同组件一起使用时，这将允许推荐高可能性的意外项目。为了评估主题层模型的惊喜和意外性表现，我们引入了Goodreads上的阅读历史数据集，包括26,000名用户和1,300,000本书，其中我们 manually annotate 449本被4名用户阅读的书籍，以时间依赖的主题层惊喜作为标准。实验评估显示，使用bayesian surprise的模型与距离基于的规律来的模型相比，具有更高的惊喜和意外性表现，并且在serendipity项目推荐上也有更好的表现。
</details></li>
</ul>
<hr>
<h2 id="Causally-Linking-Health-Application-Data-and-Personal-Information-Management-Tools"><a href="#Causally-Linking-Health-Application-Data-and-Personal-Information-Management-Tools" class="headerlink" title="Causally Linking Health Application Data and Personal Information Management Tools"></a>Causally Linking Health Application Data and Personal Information Management Tools</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08556">http://arxiv.org/abs/2308.08556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saturnino Luz, Masood Masoodian</li>
<li>for: 本研究旨在开发一种整合多种数据源、分析和可见化工具，以帮助用户更好地理解健康变量之间的 causal 连接。</li>
<li>methods: 本研究使用了数据挖掘、时间序列分析和可见化技术，并将这些技术与各种健康应用程序集成。</li>
<li>results: 研究人员通过提供用户可见化时间序列数据，使用者可以更好地理解健康变量之间的关系，从而帮助用户更好地管理健康。<details>
<summary>Abstract</summary>
The proliferation of consumer health devices such as smart watches, sleep monitors, smart scales, etc, in many countries, has not only led to growing interest in health monitoring, but also to the development of a countless number of ``smart'' applications to support the exploration of such data by members of the general public, sometimes with integration into professional health services. While a variety of health data streams has been made available by such devices to users, these streams are often presented as separate time-series visualizations, in which the potential relationships between health variables are not explicitly made visible. Furthermore, despite the fact that other aspects of life, such as work and social connectivity, have become increasingly digitised, health and well-being applications make little use of the potentially useful contextual information provided by widely used personal information management tools, such as shared calendar and email systems. This paper presents a framework for the integration of these diverse data sources, analytic and visualization tools, with inference methods and graphical user interfaces to help users by highlighting causal connections among such time-series.
</details>
<details>
<summary>摘要</summary>
“随着各国消费者医疗设备的普及，如智能手表、睡眠监测仪、智能秤 scales 等，人们对健康监测的兴趣不 только增加，而且促使了大量的``智能''应用程序的开发，以支持公众成员对健康数据的探索，并有时与专业医疗服务集成。而这些医疗设备提供的健康数据流量，经常以分开的时间序列视图方式显示出来，无法直观地显示健康变量之间的可能关系。此外，尽管其他方面的生活，如工作和社交连接，已经 Digitized，健康和福祉应用却几乎不使用广泛使用的个人信息管理工具，如共享日历和邮件系统，具有可营利的上下文信息。本文提出了将这些多种数据源、分析和视图工具、推理方法和图形用户界面集成起来，以帮助用户更好地探索健康数据的关系。”
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-to-Identify-Social-Determinants-of-Health-in-Electronic-Health-Records"><a href="#Large-Language-Models-to-Identify-Social-Determinants-of-Health-in-Electronic-Health-Records" class="headerlink" title="Large Language Models to Identify Social Determinants of Health in Electronic Health Records"></a>Large Language Models to Identify Social Determinants of Health in Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06354">http://arxiv.org/abs/2308.06354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aim-harvard/sdoh">https://github.com/aim-harvard/sdoh</a></li>
<li>paper_authors: Marco Guevara, Shan Chen, Spencer Thomas, Tafadzwa L. Chaunzwa, Idalid Franco, Benjamin Kann, Shalini Moningi, Jack Qian, Madeleine Goldstein, Susan Harper, Hugo JWL Aerts, Guergana K. Savova, Raymond H. Mak, Danielle S. Bitterman</li>
<li>For: The paper aims to extract social determinants of health (SDoH) from electronic health records (EHRs) to improve patient outcomes.* Methods: The study uses large language models to extract SDoH from free text in EHRs, and experiments with synthetic data generation to improve the extraction of scarce SDoH data.* Results: The best-performing models were fine-tuned Flan-T5 XL and Flan-T5 XXL, which outperformed zero- and few-shot performance of ChatGPT-family models and showed less algorithmic bias. The models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured only 2.0%.Here’s the information in Simplified Chinese text:* 为：本研究用大语言模型提取电子医疗记录中社会determinants of health（SDoH），以提高患者结果。* 方法：研究使用自由文本中的SDoH，并对缺乏SDoH数据进行生成数据的尝试。* 结果：最佳表现的模型是精细调整后的Flan-T5 XL和Flan-T5 XXL，它们在比较shot setting下表现得更好，并且表现出较少的算法偏见。模型可以准确地提取93.8%的患者有不良SDoH，而ICD-10代码只能捕捉2.0%。<details>
<summary>Abstract</summary>
Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance was similar on the in-hospital system dataset but worse on the MIMIC-III dataset. Our best-performing fine-tuned models outperformed zero- and few-shot performance of ChatGPT-family models for both tasks. These fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors were added to the text, suggesting less algorithmic bias (p<0.05). At the patient-level, our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured 2.0%. Our method can effectively extracted SDoH information from clinic notes, performing better compare to GPT zero- and few-shot settings. These models could enhance real-world evidence on SDoH and aid in identifying patients needing social support.
</details>
<details>
<summary>摘要</summary>
社会 determinants of health (SDoH) 有重要的影响 på patient outcomes，但是它们从电子健康记录 (EHR) 中 incomplete 收集。这项研究检查了大型自然语言模型能否从自由文本中提取 SDoH，其中最常见的位置是 EHR 中。研究还检查了使用生成的Synthetic clinical text 来提高提取这些罕见 yet extremely valuable 的临床数据的能力。研究采用了800份病人笔记，并评估了多种 transformer-based 模型。研究还进行了生成数据的评估和算法偏见的检查。我们的最佳表现模型是 Fine-tuned Flan-T5 XL (macro-F1 0.71) 和 Fine-tuned Flan-T5 XXL (macro-F1 0.70)。使用生成数据进行 augmentation 的效果因模型结构和大小而异，小型 Flan-T5 模型（基本和大型）在性能提升中表现最佳（delta F1 +0.12到 +0.23）。模型在医院内系统数据集上的表现相似，但在 MIMIC-III 数据集上表现更差。我们的最佳精度调整模型在 zero-和 few-shot 任务上表现更好，并且比 ChatGPT 家族模型更少改变其预测结果，这表明它们更少受到算法偏见（p<0.05）。在 patient 级别上，我们的模型可以识别93.8%的患者拥有不利的 SDoH，而 ICD-10 代码只能识别2.0%。我们的方法可以有效地从临床笔记中提取 SDoH 信息，并在 GPT zero-和 few-shot 设置下表现更好。这些模型可以增强实际证据，并帮助 indentify 需要社会支持的患者。
</details></li>
</ul>
<hr>
<h2 id="Combining-feature-aggregation-and-geometric-similarity-for-re-identification-of-patterned-animals"><a href="#Combining-feature-aggregation-and-geometric-similarity-for-re-identification-of-patterned-animals" class="headerlink" title="Combining feature aggregation and geometric similarity for re-identification of patterned animals"></a>Combining feature aggregation and geometric similarity for re-identification of patterned animals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06335">http://arxiv.org/abs/2308.06335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veikka Immonen, Ekaterina Nepovinnykh, Tuomas Eerola, Charles V. Stewart, Heikki Kälviäinen</li>
<li>For: The paper is written for studying animal populations by using image-based re-identification of individual animals.* Methods: The paper combines two types of pattern similarity metrics: pattern appearance similarity and geometric pattern similarity.* Results: The proposed combination of pattern similarity metrics achieves promising re-identification accuracies for Saimaa ringed seals and whale sharks.Here’s the text in Simplified Chinese:</li>
<li>for: 研究动物种群，通过图像基于个体重新识别。</li>
<li>methods:  combining两种 patrern similarity metrics： patrern appearance similarity和几何 patrern similarity。</li>
<li>results: 提议的combinaison achieve promising的重新识别精度 дляSaimaa环形海豹和鲸鱼。<details>
<summary>Abstract</summary>
Image-based re-identification of animal individuals allows gathering of information such as migration patterns of the animals over time. This, together with large image volumes collected using camera traps and crowdsourcing, opens novel possibilities to study animal populations. For many species, the re-identification can be done by analyzing the permanent fur, feather, or skin patterns that are unique to each individual. In this paper, we address the re-identification by combining two types of pattern similarity metrics: 1) pattern appearance similarity obtained by pattern feature aggregation and 2) geometric pattern similarity obtained by analyzing the geometric consistency of pattern similarities. The proposed combination allows to efficiently utilize both the local and global pattern features, providing a general re-identification approach that can be applied to a wide variety of different pattern types. In the experimental part of the work, we demonstrate that the method achieves promising re-identification accuracies for Saimaa ringed seals and whale sharks.
</details>
<details>
<summary>摘要</summary>
图像基于个体重新识别动物，可以获取动物迁徙趋势的信息，并且通过摄像头和人员参与投票，收集大量图像。这些图像可以用于研究动物种群。许多物种的重新识别可以通过分析永久性毛发、羽毛或皮肤特征来完成，这些特征是每个个体唯一的。在这篇论文中，我们提出了结合两种模式相似度度量的方法：1）图像出现相似度度量，通过图像特征聚合获得，2）几何模式相似度度量，通过分析模式相似度的几何一致性来获得。该方法可以有效利用本地和全局模式特征，提供一种通用的重新识别方法，可以应用于多种不同的模式类型。在实验部分，我们示例了对Saimaa环形鳐和鲸鱼等动物的重新识别准确率。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector"><a href="#Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector" class="headerlink" title="Foundation Model is Efficient Multimodal Multitask Model Selector"></a>Foundation Model is Efficient Multimodal Multitask Model Selector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06262">http://arxiv.org/abs/2308.06262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/multitask-model-selector">https://github.com/opengvlab/multitask-model-selector</a></li>
<li>paper_authors: Fanqing Meng, Wenqi Shao, Zhanglin Peng, Chonghe Jiang, Kaipeng Zhang, Yu Qiao, Ping Luo</li>
<li>For: 本文研究了一个未得到充分研究的问题：给一个集合 pré-trained neural networks，预测它们在每个多 modal 任务上的性能，而不需要 fine-tuning 它们。* Methods: 本文提出了一种高效的多任务模型选择器（EMMS），使用大规模基础模型将多个下游任务的多种标签格式转化为一个统一的噪声标签嵌入。EMMS 可以通过一种简单的负权重回归来估计模型的传输性能，可以高效地解决一个 Alternating Minimization 算法。* Results: 广泛的实验表明，EMMS 是一种快速、有效和通用的模型选择器，可以高效地评估 pré-trained 模型的传输性能。例如，相比之前的 state-of-the-art 方法 LogME 增强我们的标签嵌入，EMMS 在图像识别、引用、描述、视觉问答和文本问答等五个下游任务上实现了9.0%、26.3%、20.1%、54.8% 和12.2% 的性能提升，同时带来5.13x、6.29x、3.59x、6.19x 和5.66x 的速度提升。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/Multitask-Model-Selector">https://github.com/OpenGVLab/Multitask-Model-Selector</a> 上获取。<details>
<summary>Abstract</summary>
This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0\%, 26.3\%, 20.1\%, 54.8\%, 12.2\% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-Network-Management-Using-Code-Generated-by-Large-Language-Models"><a href="#Enhancing-Network-Management-Using-Code-Generated-by-Large-Language-Models" class="headerlink" title="Enhancing Network Management Using Code Generated by Large Language Models"></a>Enhancing Network Management Using Code Generated by Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06261">http://arxiv.org/abs/2308.06261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Sathiya Kumaran Mani, Yajie Zhou, Kevin Hsieh, Santiago Segarra, Ranveer Chandra, Srikanth Kandula</li>
<li>for: This paper aims to provide a novel approach for natural-language-based network management, leveraging large language models (LLMs) to generate task-specific code from natural language queries.</li>
<li>methods: The proposed approach utilizes LLMs to generate code, addressing the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code and eliminating the need to share network data with LLMs.</li>
<li>results: The prototype system designed and evaluated in the paper demonstrates high accuracy, cost-effectiveness, and potential for further enhancements using complementary program synthesis techniques.<details>
<summary>Abstract</summary>
Analyzing network topologies and communication graphs plays a crucial role in contemporary network management. However, the absence of a cohesive approach leads to a challenging learning curve, heightened errors, and inefficiencies. In this paper, we introduce a novel approach to facilitate a natural-language-based network management experience, utilizing large language models (LLMs) to generate task-specific code from natural language queries. This method tackles the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, eliminating the need to share network data with LLMs, and concentrating on application-specific requests combined with general program synthesis techniques. We design and evaluate a prototype system using benchmark applications, showcasing high accuracy, cost-effectiveness, and the potential for further enhancements using complementary program synthesis techniques.
</details>
<details>
<summary>摘要</summary>
现代网络管理中分析网络拓扑和通信图是关键。然而，由于缺乏一致的方法，会导致学习曲线困难、错误高伸和不效率。在这篇论文中，我们介绍一种新的方法，使得网络管理人员可以通过自然语言查询来获得任务特定的代码。这种方法解决了解释性、可扩展性和隐私问题，因为网络数据不需要与大语言模型（LLMs）分享，而是专注于应用特定的请求，并结合通用程序生成技术。我们设计并评估了一个原型系统，使用标准套件应用程序进行评估，显示高精度、成本效果和可能性。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-based-Investment-Portfolio-Selection"><a href="#ChatGPT-based-Investment-Portfolio-Selection" class="headerlink" title="ChatGPT-based Investment Portfolio Selection"></a>ChatGPT-based Investment Portfolio Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06260">http://arxiv.org/abs/2308.06260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oleksandr Romanko, Akhilesh Narayan, Roy H. Kwon</li>
<li>for: 投资组合选择（portfolio selection）</li>
<li>methods: 使用生成AI模型（ChatGPT）获取S&amp;P500市场指数中可能有潜力的股票，并对这些股票进行优化配置</li>
<li>results: 结果表明，使用ChatGPT进行股票选择可以带来更好的回报，但是在分配股票重量方面可能不如量化优化模型。但是将AI生成的股票选择与量化优化模型相结合，可以获得更好的投资效果，建议将来投资决策中采用协同approach。<details>
<summary>Abstract</summary>
In this paper, we explore potential uses of generative AI models, such as ChatGPT, for investment portfolio selection. Trusting investment advice from Generative Pre-Trained Transformer (GPT) models is a challenge due to model "hallucinations", necessitating careful verification and validation of the output. Therefore, we take an alternative approach. We use ChatGPT to obtain a universe of stocks from S&P500 market index that are potentially attractive for investing. Subsequently, we compared various portfolio optimization strategies that utilized this AI-generated trading universe, evaluating those against quantitative portfolio optimization models as well as comparing to some of the popular investment funds. Our findings indicate that ChatGPT is effective in stock selection but may not perform as well in assigning optimal weights to stocks within the portfolio. But when stocks selection by ChatGPT is combined with established portfolio optimization models, we achieve even better results. By blending strengths of AI-generated stock selection with advanced quantitative optimization techniques, we observed the potential for more robust and favorable investment outcomes, suggesting a hybrid approach for more effective and reliable investment decision-making in the future.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们探讨了使用生成AI模型，如ChatGPT，来选择投资 portefolio的可能性。因为GPT模型的“幻觉”问题，使得对模型输出的信任具有挑战性，因此我们采取了一种不同的方法。我们使用ChatGPT来获取S&P500市场指数中可能有吸引力的股票，然后比较了不同的投资组合优化策略，包括使用这些AI生成的交易宇宙，与量化投资优化模型进行比较，以及与一些流行的投资基金进行比较。我们的发现表明，ChatGPT在股票选择方面是有效的，但可能不如在分配股票 weights 方面表现好。但当ChatGPT生成的股票选择与已有的量化优化模型相结合时，我们可以获得更好的投资结果。通过融合AI生成的股票选择和已有的量化优化技术，我们发现了一种更加有效和可靠的投资决策方法，建议将这种方法应用于未来的投资决策中。
</details></li>
</ul>
<hr>
<h2 id="Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms"><a href="#Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms" class="headerlink" title="Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms"></a>Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06221">http://arxiv.org/abs/2308.06221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kanishka Tyagi, Chinmay Rane, Michael Manry</li>
<li>For: 本研究旨在提出一种多步训练方法，用于设计通用线性分类器。* Methods: 首先，通过回归获得初始多类线性分类器。然后，通过减少无用输入的方式，降低验证错误。同时，通过类似于霍-卡什洛夫规则的方法，提高 DESIRED 输出。接着，输出推定器被扩展为一个通用的线性分类器中的多层感知器。* Results: 通过组合剪枝和增长策略，提高输入单元的推定器，并将输出单元扩展为一个通用的线性分类器中的多层感知器。最后，通过改进每个深度学习块，提高整体深度学习模型的性能。<details>
<summary>Abstract</summary>
We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for deep autoencoders. We investigate several problems in deep autoencoders networks including training issues, the theoretical, mathematical and experimental justification that the networks are linear, optimizing the number of hidden units in each layer and determining the depth of the deep learning model. A direct implication of the current work is the ability to construct fast deep learning models using desktop level computational resources. This, in our opinion, promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi layer perceptron and deep learners reported in the literature.
</details>
<details>
<summary>摘要</summary>
我们提出了一种多步训练方法用于设计通用线性分类器。首先，通过回归获得初始多类线性分类器。然后，通过减少不必要的输入，降低验证错误。同时，通过类似于霍-卡什纳规则的方法，提高期望的输出。接着，输出推定器被映射到通用线性分类器中的sigmoid输出单元。然后，我们开发了一家批处理训练算法，用于最优化多层感知器的隐藏层大小和训练轮次数。接着，我们结合剪除和增长方法。最后，输入单元被映射到sigmoid输出单元的网络中，并且这些输入单元被用作多层感知器的输入。我们then propose  several improvements in each deep learning block, leading to improved overall performance of the deep architecture. We discuss the principles and formulation of learning algorithms for deep autoencoders, and investigate several problems in deep autoencoder networks, including training issues, theoretical, mathematical, and experimental justification that the networks are linear, optimizing the number of hidden units in each layer, and determining the depth of the deep learning model. A direct implication of our work is the ability to construct fast deep learning models using desktop-level computational resources, which promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten-fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi-layer perceptron, and deep learners reported in the literature.
</details></li>
</ul>
<hr>
<h2 id="Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey"><a href="#Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey" class="headerlink" title="Safety in Traffic Management Systems: A Comprehensive Survey"></a>Safety in Traffic Management Systems: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06204">http://arxiv.org/abs/2308.06204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlu Du, Ankan Dash, Jing Li, Hua Wei, Guiling Wang</li>
<li>for: 这篇论文旨在提供对交通管理系统安全性的全面回顾，包括交通管理系统中出现的各种安全问题、当前研究的状况以及提高交通管理系统安全性的技术和方法。</li>
<li>methods: 论文使用了文献综述的方法，概括了交通管理系统中的安全问题，并分析了当前研究的状况和提议。</li>
<li>results: 论文总结了当前研究的结果和限制，并提出了未来研究的方向。<details>
<summary>Abstract</summary>
Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.
</details>
<details>
<summary>摘要</summary>
交通管理系统在公路上的交通运输中发挥了关键作用，但是使用先进技术的交通管理系统引入了新的安全挑战。因此，确保交通管理系统的安全性是非常重要的，以避免事故和减少它们对公路用户的影响。在这份调查中，我们提供了交通管理系统安全的全面评论。 Specifically，我们讨论了交通管理系统中不同的安全问题，当前的研究进展、以及为确保交通管理系统安全的技术和方法。我们还识别了现有研究的限制，并建议未来的研究方向。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.AI_2023_08_12/" data-id="clon21iiy002br588gmvica5b" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/55/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/54/">54</a><a class="page-number" href="/page/55/">55</a><span class="page-number current">56</span><a class="page-number" href="/page/57/">57</a><a class="page-number" href="/page/58/">58</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/57/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">123</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">113</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">63</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
