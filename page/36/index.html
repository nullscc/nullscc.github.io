
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/36/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.SP_2023_09_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/15/eess.SP_2023_09_15/" class="article-date">
  <time datetime="2023-09-15T08:00:00.000Z" itemprop="datePublished">2023-09-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/15/eess.SP_2023_09_15/">eess.SP - 2023-09-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Robust-Indoor-Localization-with-Ranging-IMU-Fusion"><a href="#Robust-Indoor-Localization-with-Ranging-IMU-Fusion" class="headerlink" title="Robust Indoor Localization with Ranging-IMU Fusion"></a>Robust Indoor Localization with Ranging-IMU Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08803">http://arxiv.org/abs/2309.08803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Jiang, David Caruso, Ashutosh Dhekne, Qi Qu, Jakob Julian Engel, Jing Dong</li>
<li>for: 本研究旨在提供一种高精度低功耗indoor无线范围定位方法，用于穿梭设备的准确位置测量。</li>
<li>methods: 该研究使用了融合范围测量和惯性测量获得的协调精度，并提出了一种特定非 Gaussian multipath干扰的偏振模型。此外，研究还使用了一种基于Levenberg-Marquardt家族的信任区改进版iSAM2融合算法，以提高robust性。</li>
<li>results: 研究在实验室中进行了densely occupied的实验，并达到了$\sim$0.3m的平均绝对准确性。此外，研究还表明，使用1Hz的范围测量可以获得相似的准确性。<details>
<summary>Abstract</summary>
Indoor wireless ranging localization is a promising approach for low-power and high-accuracy localization of wearable devices. A primary challenge in this domain stems from non-line of sight propagation of radio waves. This study tackles a fundamental issue in wireless ranging: the unpredictability of real-time multipath determination, especially in challenging conditions such as when there is no direct line of sight. We achieve this by fusing range measurements with inertial measurements obtained from a low cost Inertial Measurement Unit (IMU). For this purpose, we introduce a novel asymmetric noise model crafted specifically for non-Gaussian multipath disturbances. Additionally, we present a novel Levenberg-Marquardt (LM)-family trust-region adaptation of the iSAM2 fusion algorithm, which is optimized for robust performance for our ranging-IMU fusion problem. We evaluate our solution in a densely occupied real office environment. Our proposed solution can achieve temporally consistent localization with an average absolute accuracy of $\sim$0.3m in real-world settings. Furthermore, our results indicate that we can achieve comparable accuracy even with infrequent (1Hz) range measurements.
</details>
<details>
<summary>摘要</summary>
内部无线距离地标定是一种有前途的方法，用于低功耗高精度的设备的本地化。主要挑战在这个领域是无线波的非直线传播，尤其是在没有直接视线的情况下。本研究解决了无线距离中的一个基本问题，即实时多path决定的不可预测性，特别是在复杂的环境下。我们通过将距离测量与IMU获取的动量测量进行混合来实现这一点。为此，我们提出了一种特定于非泊松噪声的非泊松噪声模型。此外，我们还提出了一种基于LM家族的信任区改进版iSAM2融合算法，以便在我们的距离-IMU融合问题上实现Robust性能。我们在一个实际办公室环境中进行了评估。我们的提议的解决方案可以在实际情况下实现时间一致的地标定，准确性约为0.3米。此外，我们的结果表明，我们可以在1Hz的距离测量频率下实现相同的准确性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-and-Efficient-Communications-for-Urban-Air-Mobility"><a href="#Towards-Robust-and-Efficient-Communications-for-Urban-Air-Mobility" class="headerlink" title="Towards Robust and Efficient Communications for Urban Air Mobility"></a>Towards Robust and Efficient Communications for Urban Air Mobility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08796">http://arxiv.org/abs/2309.08796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dennis Becker, Lukas Schalk<br>for: 本研究旨在开发一种特地适应未来城市空间的Drone-to-Drone通信和监测系统（DroneCAST），以确保安全运行。methods: 本研究使用了多链接方法，并在两架机器人上安装了实验Communication系统硬件原型。results: 实验结果表明，DroneCAST系统可以提供高效稳定的直接信息交换，并且可以应对高交通密度和紧急情况。<details>
<summary>Abstract</summary>
For the realization of the future urban air mobility, reliable information exchange based on robust and efficient communication between all airspace participants will be one of the key factors to ensure safe operations. Especially in dense urban scenarios, the direct and fast information exchange between drones based on Drone-to-Drone communications is a promising technology for enabling reliable collision avoidance systems. However, to mitigate collisions and to increase overall reliability, unmanned aircraft still lack a redundant, higher-level safety net to coordinate and monitor traffic, as is common in today's civil aviation. In addition, direct and fast information exchange based on ad hoc communication is needed to cope with the very short reaction times required to avoid collisions and to cope with the the high traffic densities. Therefore, we are developing a \ac{d2d} communication and surveillance system, called DroneCAST, which is specifically tailored to the requirements of a future urban airspace and will be part of a multi-link approach. In this work we discuss challenges and expected safety-critical applications that will have to rely on communications for \ac{uam} and present our communication concept and necessary steps towards DroneCAST. As a first step towards an implementation, we equipped two drones with hardware prototypes of the experimental communication system and performed several flights around the model city to evaluate the performance of the hardware and to demonstrate different applications that will rely on robust and efficient communications.
</details>
<details>
<summary>摘要</summary>
为实现未来的城市空中交通，可靠的信息交换基于强健和高效的通信 между所有空间参与者将是一个关键因素，以确保安全操作。尤其在紧张的城市场景下，直接和快速的机器人之间的通信是一种承诺的技术，用于实现可靠的碰撞避免系统。然而，为了减少碰撞和提高总可靠性，无人飞机仍然缺乏一种备用的、更高一级的安全网络，以协调和监测交通，如今的民航航空中拥有的。此外，直接和快速的信息交换基于随机通信可以适应非常短的应急响应时间和高通信密度。因此，我们正在开发一个D2D通信和监测系统，称为DroneCAST，该系统特地适应未来城市空间的需求，并将成为多链接方法的一部分。在这个工作中，我们讨论了未来城市空中交通中通信的挑战和预期的安全关键应用，并提出了我们的通信概念和实现DroneCAST所需的必要步骤。作为实现的第一步，我们将两架无人机设备了实验通信系统的硬件原型，并在模型城市附近进行了多次飞行，以评估硬件性能和示例不同应用，它们均需要强健和高效的通信。
</details></li>
</ul>
<hr>
<h2 id="Stein-Variational-Gradient-Descent-based-Detection-For-Random-Access-With-Preambles-In-MTC"><a href="#Stein-Variational-Gradient-Descent-based-Detection-For-Random-Access-With-Preambles-In-MTC" class="headerlink" title="Stein Variational Gradient Descent-based Detection For Random Access With Preambles In MTC"></a>Stein Variational Gradient Descent-based Detection For Random Access With Preambles In MTC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08782">http://arxiv.org/abs/2309.08782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zhu, Hongyi Pan, Salih Atici, Ahmet Enis Cetin</li>
<li>for: 提高 massive machine-type communication (mMTC) 中 grant-based random access scheme 中的准确性。</li>
<li>methods: 基于 Stein variational gradient descent (SVGD) 的新型准auer detection algorithm，利用恒定更新粒子进行连续推理。</li>
<li>results: 比 Markov Chain Monte Carlo-based approaches 更高的检测精度。<details>
<summary>Abstract</summary>
Traditional preamble detection algorithms have low accuracy in the grant-based random access scheme in massive machine-type communication (mMTC). We present a novel preamble detection algorithm based on Stein variational gradient descent (SVGD) at the second step of the random access procedure. It efficiently leverages deterministic updates of particles for continuous inference. To further enhance the performance of the SVGD detector, especially in a dense user scenario, we propose a normalized SVGD detector with momentum. It utilizes the momentum and a bias correction term to reduce the preamble estimation errors during the gradient descent process. Simulation results show that the proposed algorithm performs better than Markov Chain Monte Carlo-based approaches in terms of detection accuracy.
</details>
<details>
<summary>摘要</summary>
传统的启语探测算法在大规模机器类通信（mMTC）中的授权随机访问方案中的准确率低。我们提出了基于Stein变量加速度下降（SVGD）的新启语探测算法，它在随机访问过程的第二步中高效地利用权值更新。为了进一步提高SVGD探测器的性能，特别是在密集用户场景下，我们提议一种归一化的SVGD探测器。它利用权值和偏移量来减少启语估计错误，并且使用滚动平均来降低启语探测的难度。实验结果表明，提出的算法在探测精度方面比Markov链 Монте卡洛-based方法表现更好。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Constellation-Shaping-With-Denoising-Diffusion-Probabilistic-Models-A-Novel-Approach"><a href="#Probabilistic-Constellation-Shaping-With-Denoising-Diffusion-Probabilistic-Models-A-Novel-Approach" class="headerlink" title="Probabilistic Constellation Shaping With Denoising Diffusion Probabilistic Models: A Novel Approach"></a>Probabilistic Constellation Shaping With Denoising Diffusion Probabilistic Models: A Novel Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08688">http://arxiv.org/abs/2309.08688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehdi Letafati, Samad Ali, Matti Latva-aho</li>
<li>for: 这篇论文是用于描述如何使用泛化抽象模型（DDPM）进行概率性星形设计，以提高无线通信中的信息率和通信性能。</li>
<li>methods: 这篇论文使用了DDPM模型，通过“恢复”和“生成”的方式，学习抽象星形符号的生成。</li>
<li>results:  simulations 表明，提议的方案在低SNR范围和非高斯噪声下表现出较好的网络可靠性和robust性，并且与深度神经网络（DNN）的 Refer 方法相比，实现了3倍的辐射信息增加。<details>
<summary>Abstract</summary>
With the incredible results achieved from generative pre-trained transformers (GPT) and diffusion models, generative AI (GenAI) is envisioned to yield remarkable breakthroughs in various industrial and academic domains. In this paper, we utilize denoising diffusion probabilistic models (DDPM), as one of the state-of-the-art generative models, for probabilistic constellation shaping in wireless communications. While the geometry of constellations is predetermined by the networking standards, probabilistic constellation shaping can help enhance the information rate and communication performance by designing the probability of occurrence (generation) of constellation symbols. Unlike conventional methods that deal with an optimization problem over the discrete distribution of constellations, we take a radically different approach. Exploiting the ``denoise-and-generate'' characteristic of DDPMs, the key idea is to learn how to generate constellation symbols out of noise, ``mimicking'' the way the receiver performs symbol reconstruction. By doing so, we make the constellation symbols sent by the transmitter, and what is inferred (reconstructed) at the receiver become as similar as possible. Our simulations show that the proposed scheme outperforms deep neural network (DNN)-based benchmark and uniform shaping, while providing network resilience as well as robust out-of-distribution performance under low-SNR regimes and non-Gaussian noise. Notably, a threefold improvement in terms of mutual information is achieved compared to DNN-based approach for 64-QAM geometry.
</details>
<details>
<summary>摘要</summary>
“受到循环式训练的干扰抑制模型（DDPM）和扩散模型的惊人成果，生成AI（GenAI）预计会在不同的产业和学术领域取得惊人的突破。在这篇论文中，我们使用DDPM作为一种state-of-the-art的生成模型，对无线通信中的报文排序进行概率排序。即使报文的几何结构由网络标准决定，但概率排序仍可以提高信息率和通信性能，通过设计报文符号的概率出现的预测。与传统方法不同的是，我们利用DDPM的“混叠和生成”特点，将报文符号从噪声中学习生成，“模拟”接收器在重建报文符号时的过程。这样做的目的是使报文符号由发送器发送，并由接收器重建的符号变得非常相似。我们的仿真结果表明，我们的方案在低SNR情况下和非泊峰噪声下具有更高的网络鲁棒性和robust out-of-distribution性，同时与DNN基本标准相比，实现了3倍的约束信息增加。特别是，对64-QAM几何来说，与DNN基本标准相比，我们的方案实现了3倍的约束信息增加。”
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Near-Field-Sensing-and-Communications-with-Sparse-Arrays-Potentials-Challenges-and-Emerging-Trends"><a href="#Enhancing-Near-Field-Sensing-and-Communications-with-Sparse-Arrays-Potentials-Challenges-and-Emerging-Trends" class="headerlink" title="Enhancing Near-Field Sensing and Communications with Sparse Arrays: Potentials, Challenges, and Emerging Trends"></a>Enhancing Near-Field Sensing and Communications with Sparse Arrays: Potentials, Challenges, and Emerging Trends</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08681">http://arxiv.org/abs/2309.08681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songjie Yang, Wanting Lyu, Zhongpei Zhang, Chau Yuen</li>
<li>For: The paper is written for exploring the potential of extremely large-scale (XL)-arrays for overcoming the severe path loss in millimeter-wave (mmWave) and TeraHertz (THz) channels, which is crucial for enabling 6G.* Methods: The paper uses the spherical-wave (SW) model to accurately represent the near-field propagation characteristics of XL-arrays, which significantly increases signal processing complexity.* Results: The paper identifies the potential benefits of near-field sensing and communications (S&amp;C) enabled by XL-arrays, including improving communication multiplexing capability, spatial resolution, and degrees of freedom. Additionally, the paper proposes sparse arrays (SAs) as a solution to overcome the limitations of existing XL-arrays with dense uniform array layouts, and explores the potential of XL-SAs for mmWave&#x2F;THz systems using multi-subarray designs.<details>
<summary>Abstract</summary>
As a promising technique, extremely large-scale (XL)-arrays offer potential solutions for overcoming the severe path loss in millimeter-wave (mmWave) and TeraHertz (THz) channels, crucial for enabling 6G. Nevertheless, XL-arrays introduce deviations in electromagnetic propagation compared to traditional arrays, fundamentally challenging the assumption with the planar-wave model. Instead, it ushers in the spherical-wave (SW) model to accurately represent the near-field propagation characteristics, significantly increasing signal processing complexity. Fortunately, the SW model shows remarkable benefits on sensing and communications (S\&C), e.g., improving communication multiplexing capability, spatial resolution, and degrees of freedom. In this context, this article first overviews hardware/algorithm challenges, fundamental potentials, promising applications of near-field S\&C enabled by XL-arrays. To overcome the limitations of existing XL-arrays with dense uniform array layouts and improve S\&C applications, we introduce sparse arrays (SAs). Exploring their potential, we propose XL-SAs for mmWave/THz systems using multi-subarray designs. Finally, several applications, challenges and resarch directions are identified.
</details>
<details>
<summary>摘要</summary>
为了实现6G，极大规模（XL）阵列技术具有很大的潜在应用前景。然而，XL阵列引入了电磁波传播方面的偏差，从传统阵列假设中带来了挑战。为了更 accurately 表示近场传播特性，我们需要用圆波（SW）模型来取代平面波模型。这种模型具有优化沟通多路复用能力、空间分辨率和自由度等优点，因此在感知和通信（S\&C）方面具有极大的潜力。在这篇文章中，我们首先介绍硬件/算法挑战、基本潜力和XL阵列在感知和通信方面的应用潜力。然后，我们提出了使用多子阵列设计的稀疏阵列（SA）来解决现有XL阵列的局限性。最后，我们详细介绍了一些应用、挑战和研究方向。
</details></li>
</ul>
<hr>
<h2 id="Denoising-Diffusion-Probabilistic-Models-for-Hardware-Impaired-Communications"><a href="#Denoising-Diffusion-Probabilistic-Models-for-Hardware-Impaired-Communications" class="headerlink" title="Denoising Diffusion Probabilistic Models for Hardware-Impaired Communications"></a>Denoising Diffusion Probabilistic Models for Hardware-Impaired Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08568">http://arxiv.org/abs/2309.08568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehdi Letafati, Samad Ali, Matti Latva-aho</li>
<li>for: 这篇论文探讨了对无线通信系统中实际假设（硬件缺陷、低信号识别率、量化误差）下的数据生成模型应用。</li>
<li>methods: 本论文提出了基于滤波泵润滤预测模型（DDPM）的几何发散模型接收器，以提供网络可靠性在低信号识别率、非高斯噪声、不同硬件缺陷水平和量化误差下。</li>
<li>results: 我们的结果显示，与深度神经网络（DNN）接收器相比，我们的架构可以在AWGN和非高斯噪声场景下提供30%和20%的重建性能提升。<details>
<summary>Abstract</summary>
Generative AI has received significant attention among a spectrum of diverse industrial and academic domains, thanks to the magnificent results achieved from deep generative models such as generative pre-trained transformers (GPT) and diffusion models. In this paper, we explore the applications of denoising diffusion probabilistic models (DDPMs) in wireless communication systems under practical assumptions such as hardware impairments (HWI), low-SNR regime, and quantization error. Diffusion models are a new class of state-of-the-art generative models that have already showcased notable success with some of the popular examples by OpenAI and Google Brain. The intuition behind DDPM is to decompose the data generation process over small "denoising" steps. Inspired by this, we propose using denoising diffusion model-based receiver for a practical wireless communication scheme, while providing network resilience in low-SNR regimes, non-Gaussian noise, different HWI levels, and quantization error. We evaluate the reconstruction performance of our scheme in terms of bit error rate (BER) and mean-squared error (MSE). Our results show that 30% and 20% improvement in BER could be achieved compared to deep neural network (DNN)-based receivers in AWGN and non-Gaussian scenarios, respectively.
</details>
<details>
<summary>摘要</summary>
优化�ulsion AI在多样化的工业和学术领域中受到了广泛的关注，主要归功于深度生成模型，如生成预训练变换器（GPT）和扩散模型。在这篇论文中，我们探讨了在实际假设下，如硬件缺陷（HWI）、低信号强度（SNR）和量化误差的情况下，扩散模型在无线通信系统中的应用。扩散模型是一种新的生成模型，它已经在一些著名的例子中表现出了卓越的成绩。扩散模型的基本思想是将数据生成过程分解成小“净化”步骤。我们提议使用扩散模型来实现无线通信协议，并在低SNR情况下、非泊射噪、不同HWI水平和量化误差情况下提供网络可悟性。我们根据BER和MSE来评估我们的方案的重建性能。我们的结果显示，相比于深度神经网络（DNN）基于 receiver，我们的方案在AWGN和非泊射噪情况下可以提高30%和20%的BER。
</details></li>
</ul>
<hr>
<h2 id="Robust-IRS-Element-Activation-for-Energy-Efficiency-Optimization-in-IRS-Assisted-Communication-Systems-With-Imperfect-CSI"><a href="#Robust-IRS-Element-Activation-for-Energy-Efficiency-Optimization-in-IRS-Assisted-Communication-Systems-With-Imperfect-CSI" class="headerlink" title="Robust IRS-Element Activation for Energy Efficiency Optimization in IRS-Assisted Communication Systems With Imperfect CSI"></a>Robust IRS-Element Activation for Energy Efficiency Optimization in IRS-Assisted Communication Systems With Imperfect CSI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08526">http://arxiv.org/abs/2309.08526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christos N. Efrem, Ioannis Krikidis</li>
<li>for: 这个论文研究了一个智能反射面（IRS）支持的通信系统，使用单天线发射机和接收机，并在不准确的通道状态信息（CSI）下进行了robust选择。</li>
<li>methods: 论文使用了closed-form表达式来计算最差情况的信噪比（SNR），然后根据CSI不确定性的 bound进行了一种robust（discrete）优化问题的解决。</li>
<li>results: 论文提出了一种基于动态程序（DP）的算法，可以在O（L log L）的复杂度下达到全局最大值，其中L是IRS元素的数量。此外，论文还提出了一种卷积relaxation-based方法（CRBM）来获得一个可行（不优化）解决方案，其复杂度为O（L^3.5）。numerical simulations表明，提出的算法比枚举搜索更快速，可以满足实际应用中的扩展性。<details>
<summary>Abstract</summary>
In this paper, we study an intelligent reflecting surface (IRS)-aided communication system with single-antenna transmitter and receiver, under imperfect channel state information (CSI). More specifically, we deal with the robust selection of binary (on/off) states of the IRS elements in order to maximize the worst-case energy efficiency (EE), given a bounded CSI uncertainty, while satisfying a minimum signal-to-noise ratio (SNR). In addition, we consider not only continuous but also discrete IRS phase shifts. First, we derive closed-form expressions of the worst-case SNRs, and then formulate the robust (discrete) optimization problems for each case. In the case of continuous phase shifts, we design a dynamic programming (DP) algorithm that is theoretically guaranteed to achieve the global maximum with polynomial complexity $O(L\,{\log L})$, where $L$ is the number of IRS elements. In the case of discrete phase shifts, we develop a convex-relaxation-based method (CRBM) to obtain a feasible (sub-optimal) solution in polynomial time $O(L^{3.5})$, with a posteriori performance guarantee. Furthermore, numerical simulations provide useful insights and confirm the theoretical results. In particular, the proposed algorithms are several orders of magnitude faster than the exhaustive search when $L$ is large, thus being highly scalable and suitable for practical applications. Moreover, both algorithms outperform a baseline scheme, namely, the activation of all IRS elements.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一个智能反射表面（IRS）干支持的通信系统，其中传输机和接收机各只有一个天线。我们更加特别地关注在不完全的通道状态信息（CSI）下，对IRS元素的二进制（On/Off）状态的精度选择，以最大化最差情况的能量效率（EE），同时保证最小化噪声比率（SNR）。此外，我们不仅考虑了连续的IRS频率偏移，还考虑了离散的IRS频率偏移。首先，我们 deriv出了最差情况的SNR的关闭式表达，然后将问题转化为一个稳定优化问题。在连续频率偏移的情况下，我们设计了一个动态规划算法（DP），该算法在规模为$L$的IRS元素下可以在$O(L\log L)$的复杂度下实现全局最大化。在离散频率偏移的情况下，我们开发了一种基于凸 relaksation 的方法（CRBM），可以在$O(L^{3.5})$的复杂度下获得一个可行（不优）解。numerical simulations 表明，提议的算法在大$L$时速度是几个数量级快于枚举搜索，因此具有高可扩展性和实际应用中的适用性。此外，两种算法都超过了一个基eline scheme，即所有IRS元素的活动。
</details></li>
</ul>
<hr>
<h2 id="Novel-Expressions-for-the-Outage-Probability-and-Diversity-Gains-in-Fluid-Antenna-System"><a href="#Novel-Expressions-for-the-Outage-Probability-and-Diversity-Gains-in-Fluid-Antenna-System" class="headerlink" title="Novel Expressions for the Outage Probability and Diversity Gains in Fluid Antenna System"></a>Novel Expressions for the Outage Probability and Diversity Gains in Fluid Antenna System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08441">http://arxiv.org/abs/2309.08441</a></li>
<li>repo_url: None</li>
<li>paper_authors: José<del>David</del>Vega-Sánchez, Arianna Estefanía López-Ramírez, Luis<del>Urquiza-Aguiar, Diana</del>Pamela<del>Moya</del>Osorio</li>
<li>for: 本研究旨在探讨流体天线系统（Fluid Antenna System，FAS）在具有小型和受限的设备的网络中提供很好的多样性增强。</li>
<li>methods: 本文比较了不同的多样性和多样性Fluid Antenna System（FAS）接收器在空间相关 Nakagami-$m$ 抽象通道上的失业概率（OP）性能。</li>
<li>results: 通过一种新的准确匹配方法，我们 derivated一个简单又准确的关闭形式的近似，用于MGC-FAS schemes的OP性能。这个近似是通过两个阶段来完成：首先，对每个MGC-FAS支路的CDF进行近似，然后对MGC-FAS scheme的总体CDF进行近似。通过这些结果，我们得到了关闭形式的OP和极限OP。最后，我们的近似被 validate by numerical results，并在不同的多样性FAS场景下 demonstarte了其准确性。<details>
<summary>Abstract</summary>
The flexibility and reconfigurability at the radio frequency (RF) front-end offered by the fluid antenna system (FAS) make this technology promising for providing remarkable diversity gains in networks with small and constrained devices. Toward this direction, this letter compares the outage probability (OP) performance of non-diversity and diversity FAS receivers undergoing spatially correlated Nakagami-$m$ fading channels. Although the system properties of FAS incur in complex analysis, we derive a simple yet accurate closed-form approximation by relying on a novel asymptotic matching method for the OP of a maximum-gain combining-FAS (MGC-FAS). The approximation is performed in two stages, the approximation of the cumulative density function (CDF) of each MGC-FAS branch, and then the approximation of the end-to-end CDF of the MGC-FAS scheme. With these results, closed-form expressions for the OP and the asymptotic OP are derived. Finally, numerical results validate our approximation of the MGC-FAS scheme and demonstrate its accuracy under different diversity FAS scenarios.
</details>
<details>
<summary>摘要</summary>
这个流动天线系统（Fluid Antenna System，FAS）的灵活性和重新配置能力使得这技术在有限的设备下提供了杰出的多标的优势。以这个方向为目标，这封信件比较了非多标和多标FAS接收器在空间相关的 Nakagami-$m$ 折射通道上的失败几率（OP）性能。即使FAS系统具有复杂的系统特性，我们靠一种新的概念匹配方法 derivation 了一个简单又准确的关键值分布函数（CDF）的扩展。这个扩展是在两个阶段进行的：首先，对每个最大增幅Combining-FAS（MGC-FAS）分支的CDF进行扩展，然后对MGC-FAS的终端CDF进行扩展。从这些结果，我们得到了关于OP和杰出OP的关键表达式。最后，我们的扩展验证了MGC-FAS的精度，并在不同的多标FAS情况下进行了数值验证。
</details></li>
</ul>
<hr>
<h2 id="IHT-Inspired-Neural-Network-for-Single-Snapshot-DOA-Estimation-with-Sparse-Linear-Arrays"><a href="#IHT-Inspired-Neural-Network-for-Single-Snapshot-DOA-Estimation-with-Sparse-Linear-Arrays" class="headerlink" title="IHT-Inspired Neural Network for Single-Snapshot DOA Estimation with Sparse Linear Arrays"></a>IHT-Inspired Neural Network for Single-Snapshot DOA Estimation with Sparse Linear Arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08429">http://arxiv.org/abs/2309.08429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunqiao Hu, Shunqiao Sun</li>
<li>for: 这个论文的目的是提出一种基于神经网络的单拍 snapshot 方向来源估计方法（DOA），以替代传统的迭代硬阈值 truncated-singular value decomposition（t-SVD）。</li>
<li>methods: 该方法使用了一种基于循环神经网络的IHT算法，并通过将循环神经网络结构与IHT算法结合，使得网络层操作与IHT算法的迭代过程相对应。此外，该方法还使用了一个浅层自动编码器来取代t-SVD，从而降低计算开销。</li>
<li>results: 实验结果表明，提议的方法可以保持强的解释性，并且在全面阵列信号重建和单拍 snapshot DOA估计中显示出更高的准确率和更快的收敛速率。<details>
<summary>Abstract</summary>
Single-snapshot direction-of-arrival (DOA) estimation using sparse linear arrays (SLAs) has gained significant attention in the field of automotive MIMO radars. This is due to the dynamic nature of automotive settings, where multiple snapshots aren't accessible, and the importance of minimizing hardware costs. Low-rank Hankel matrix completion has been proposed to interpolate the missing elements in SLAs. However, the solvers of matrix completion, such as iterative hard thresholding (IHT), heavily rely on expert knowledge of hyperparameter tuning and lack task-specificity. Besides, IHT involves truncated-singular value decomposition (t-SVD), which has high computational cost in each iteration. In this paper, we propose an IHT-inspired neural network for single-snapshot DOA estimation with SLAs, termed IHT-Net. We utilize a recurrent neural network structure to parameterize the IHT algorithm. Additionally, we integrate shallow-layer autoencoders to replace t-SVD, reducing computational overhead while generating a novel optimizer through supervised learning. IHT-Net maintains strong interpretability as its network layer operations align with the iterations of the IHT algorithm. The learned optimizer exhibits fast convergence and higher accuracy in the full array signal reconstruction followed by single-snapshot DOA estimation. Numerical results validate the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
单一快照方向估测（DOA）预测使用稀疏线性阵列（SLAs）在汽车多元追踪领域获得了重要的注意力。这是因为汽车设置的动态性，不能取得多个快照，并且优先运算成本。低维汉宝网络完成（Low-rank Hankel matrix completion）已经建议来 interpolate 缺失的元素 в SLAs。然而，对矩阵完成的解决方案，如循环几何���（IHT），需要专家知识来调整参数，而且lacks task-specificity。此外，IHT 包含 truncated-singular value decomposition（t-SVD），它在每个迭代中有高的计算成本。在本文中，我们提出了一个 IHT 灵感的神经网络，称为 IHT-Net。我们使用了循环神经网络结构来实现 IHT 算法的实现。此外，我们将浅层自动化网络与 t-SVD 结合，从而降低计算成本，并生成了一个新的优化器通过监督学习。IHT-Net 维持了强大的解释性，因为其网络层操作与 IHT 算法的迭代相似。学习的优化器展示了快速的融合和更高的精度在全阵列信号重建和单快照 DOA 预测中。 numerics  validate the effectiveness of the proposed method.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Method-for-the-Performance-Analysis-of-Fluid-Antenna-Systems-under-Correlated-Nakagami-m-Fading"><a href="#A-Simple-Method-for-the-Performance-Analysis-of-Fluid-Antenna-Systems-under-Correlated-Nakagami-m-Fading" class="headerlink" title="A Simple Method for the Performance Analysis of Fluid Antenna Systems under Correlated Nakagami-$m$ Fading"></a>A Simple Method for the Performance Analysis of Fluid Antenna Systems under Correlated Nakagami-$m$ Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08423">http://arxiv.org/abs/2309.08423</a></li>
<li>repo_url: None</li>
<li>paper_authors: José<del>David</del>Vega-Sánchez, Luis<del>Urquiza-Aguiar, Martha Cecilia Paredes Paredes, Diana</del>Pamela<del>Moya</del>Osorio</li>
<li>for:  investigate the performance of a single-antenna fluid antenna system (FAS) over spatially correlated Nakagami-$m$ fading channels</li>
<li>methods: employ a novel asymptotic matching method to obtain simple and highly accurate closed-form approximations for the cumulative density function of the FAS channel and the outage probability of the proposed system</li>
<li>results: the proposed approximations are validated, and it is shown that the FAS can meet or even exceed the performance attained by the conventional maximal ratio combining (MRC) technique.Here are the three points in English for reference:</li>
<li>for: investigate the performance of a single-antenna fluid antenna system (FAS) over spatially correlated Nakagami-$m$ fading channels</li>
<li>methods: employ a novel asymptotic matching method to obtain simple and highly accurate closed-form approximations for the cumulative density function of the FAS channel and the outage probability of the proposed system</li>
<li>results: the proposed approximations are validated, and it is shown that the FAS can meet or even exceed the performance attained by the conventional maximal ratio combining (MRC) technique.<details>
<summary>Abstract</summary>
By recognizing the tremendous flexibility of the emerging fluid antenna system (FAS), which allows dynamic reconfigurability of the location of the antenna within a given space, this paper investigates the performance of a single-antenna FAS over spatially correlated Nakagami-$m$ fading channels. Specifically, simple and highly accurate closed-form approximations for the cumulative density function of the FAS channel and the outage probability of the proposed system are obtained by employing a novel asymptotic matching method, which is an improved version of the well-known moment matching. With this method, the outage probability can be computed {simply} without incurring complex multi-fold integrals, thus requiring negligible computational effort. Finally, the accuracy of the proposed approximations is validated, and it is shown that the FAS can meet or even exceed the performance attained by the conventional maximal ratio combining (MRC) technique.
</details>
<details>
<summary>摘要</summary>
通过认可emerging fluid antenna system（FAS）的巨大的灵活性，这篇论文研究了单antenna FAS在 Nakagami-$m$ 抖抖几何渠道上的性能。特别是，通过一种新的增强版matching方法，提出了一种简单高度准确的闭式函数方法，可以计算FAS通道的总概率分布和提携系统的失业率。这种方法不需要进行复杂的多重积分，因此计算工作量很低。最后，研究证明了提携系统的性能可以达到或超过 convential maximal ratio combining（MRC）技术的性能。
</details></li>
</ul>
<hr>
<h2 id="Channel-Estimation-in-Underdetermined-Systems-Utilizing-Variational-Autoencoders"><a href="#Channel-Estimation-in-Underdetermined-Systems-Utilizing-Variational-Autoencoders" class="headerlink" title="Channel Estimation in Underdetermined Systems Utilizing Variational Autoencoders"></a>Channel Estimation in Underdetermined Systems Utilizing Variational Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08411">http://arxiv.org/abs/2309.08411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Baur, Nurettin Turan, Benedikt Fesl, Wolfgang Utschick</li>
<li>for: 这个论文应用了统计学来进行通道估计（CE）在不充分决定（UD）系统中。</li>
<li>methods: 这个方法使用了一个称为统计学自动化（VAE）的新方法，将通道状态资料（CSI）训练成一个对于均方差误差（MSE）最佳估计器的近似。</li>
<li>results: 这个研究展示了将VAE应用到UD系统中，可以获得非常好的性能，并且不需要完美的CSI During the training phase。这与大多数深度学习（DL）基本的CE方法不同，这些方法通常需要完美的CSI During the training phase。<details>
<summary>Abstract</summary>
In this work, we propose to utilize a variational autoencoder (VAE) for channel estimation (CE) in underdetermined (UD) systems. The basis of the method forms a recently proposed concept in which a VAE is trained on channel state information (CSI) data and used to parameterize an approximation to the mean squared error (MSE)-optimal estimator. The contributions in this work extend the existing framework from fully-determined (FD) to UD systems, which are of high practical relevance. Particularly noteworthy is the extension of the estimator variant, which does not require perfect CSI during its offline training phase. This is a significant advantage compared to most other deep learning (DL)-based CE methods, where perfect CSI during the training phase is a crucial prerequisite. Numerical simulations for hybrid and wideband systems demonstrate the excellent performance of the proposed methods compared to related estimators.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提议使用变量自动编码器（VAE）来进行通道估计（CE）在不充分掌握（UD）系统中。这种方法的基础是一个最近提出的概念，在该概念中，VAE被训练在通道状态信息（CSI）数据上，并用来参数化MSE优化的参数。本文的贡献在扩展现有框架从完全掌握（FD）系统中扩展到UD系统中，这些系统在实践中具有非常高的重要性。特别值得一提的是，该估计变体不需要在训练阶段获得完美的CSI，这与大多数深度学习（DL）基于CE方法不同，这些方法通常需要在训练阶段获得完美的CSI。数字实验室中的干扰和宽频系统的数据显示了我们提议的方法的优秀性相比于相关的估计器。
</details></li>
</ul>
<hr>
<h2 id="Bayes-Optimal-Estimation-in-Generalized-Linear-Models-via-Spatial-Coupling"><a href="#Bayes-Optimal-Estimation-in-Generalized-Linear-Models-via-Spatial-Coupling" class="headerlink" title="Bayes-Optimal Estimation in Generalized Linear Models via Spatial Coupling"></a>Bayes-Optimal Estimation in Generalized Linear Models via Spatial Coupling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08404">http://arxiv.org/abs/2309.08404</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Pascual Cobo, Kuan Hsieh, Ramji Venkataramanan</li>
<li>for: 这篇论文关注了一般线性模型（GLM）的信号估计问题。GLM包括了线性回归、phas Retrieval和1-bit压缩感知等许多canonical problem。</li>
<li>methods: 这篇论文使用了一种高效的抽象消息传递（AMP）算法来实现信号估计。</li>
<li>results: 研究发现，使用spatially coupled design和AMP算法可以实现高维度下的MSE接近 asymptotic MMSE。此外， numerically Results for phase retrieval和rectified linear regression also show that spatially coupled designs can achieve lower MSE than i.i.d. Gaussian designs at finite dimensions when used with AMP algorithms.<details>
<summary>Abstract</summary>
We consider the problem of signal estimation in a generalized linear model (GLM). GLMs include many canonical problems in statistical estimation, such as linear regression, phase retrieval, and 1-bit compressed sensing. Recent work has precisely characterized the asymptotic minimum mean-squared error (MMSE) for GLMs with i.i.d. Gaussian sensing matrices. However, in many models there is a significant gap between the MMSE and the performance of the best known feasible estimators. In this work, we address this issue by considering GLMs defined via spatially coupled sensing matrices. We propose an efficient approximate message passing (AMP) algorithm for estimation and prove that with a simple choice of spatially coupled design, the MSE of a carefully tuned AMP estimator approaches the asymptotic MMSE in the high-dimensional limit. To prove the result, we first rigorously characterize the asymptotic performance of AMP for a GLM with a generic spatially coupled design. This characterization is in terms of a deterministic recursion (`state evolution') that depends on the parameters defining the spatial coupling. Then, using a simple spatially coupled design and judicious choice of functions defining the AMP, we analyze the fixed points of the resulting state evolution and show that it achieves the asymptotic MMSE. Numerical results for phase retrieval and rectified linear regression show that spatially coupled designs can yield substantially lower MSE than i.i.d. Gaussian designs at finite dimensions when used with AMP algorithms.
</details>
<details>
<summary>摘要</summary>
我们考虑一个泛化线性模型（GLM）的问题。 GLM 包括了许多线性回传问题的 canonical 问题，例如线性回传、相位抽取和1位压缩感知。 现有的工作已经精确地定义 GLM 的 asymptotic minimum mean-squared error（MMSE）。然而，在许多模型中，存在一个明显的差距 между MMSE 和最好的可行的 estimator 的性能。在这个工作中，我们解决这个问题，通过考虑 GLM 是通过 spatially coupled sensing matrices 定义的。我们提出了一个高效的approximate message passing（AMP）算法来进行估计，并证明在高维度上，对于一个简单的选择的 spatially coupled 设计，AMP 估计器的MSE接近 asymptotic MMSE。在证明这个结果时，我们首先正确地描述了 GLM 的 asymptotic performance，它是一个 deterministic recursion（state evolution），它取决于定义 spatial coupling 的参数。然后，我们使用一个简单的 spatially coupled 设计，以及judicious 选择的函数来定义 AMP，并分析fixed points 的 resulted state evolution，并证明它实现 asymptotic MMSE。numerical results 表明，在相位抽取和线性回传 regression 中，使用 spatially coupled 设计可以在finite dimensions 下，对于 AMP 算法而言，实现较低的MSE。
</details></li>
</ul>
<hr>
<h2 id="Investigation-of-mmWave-Radar-Technology-For-Non-contact-Vital-Sign-Monitoring"><a href="#Investigation-of-mmWave-Radar-Technology-For-Non-contact-Vital-Sign-Monitoring" class="headerlink" title="Investigation of mmWave Radar Technology For Non-contact Vital Sign Monitoring"></a>Investigation of mmWave Radar Technology For Non-contact Vital Sign Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08317">http://arxiv.org/abs/2309.08317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Marty, Federico Pantanella, Andrea Ronco, Kanika Dheman, Michele Magno</li>
<li>for: 非接触式生命 Parameters监测</li>
<li>methods:  millimeter-wave (mmWave) 雷达技术</li>
<li>results: 120 GHz 雷达系统在人体测量中表现最佳，可以准确地识别心跳和呼吸活动。<details>
<summary>Abstract</summary>
Non-contact vital sign monitoring has many advantages over conventional methods in being comfortable, unobtrusive and without any risk of spreading infection. The use of millimeter-wave (mmWave) radars is one of the most promising approaches that enable contact-less monitoring of vital signs. Novel low-power implementations of this technology promise to enable vital sign sensing in embedded, battery-operated devices. The nature of these new low-power sensors exacerbates the challenges of accurate and robust vital sign monitoring and especially the problem of heart-rate tracking. This work focuses on the investigation and characterization of three Frequency Modulated Continuous Wave (FMCW) low-power radars with different carrier frequencies of 24 GHz, 60 GHz and 120 GHz. The evaluation platforms were first tested on phantom models that emulated human bodies to accurately evaluate the baseline noise, error in range estimation, and error in displacement estimation. Additionally, the systems were also used to collect data from three human subjects to gauge the feasibility of identifying heartbeat peaks and breathing peaks with simple and lightweight algorithms that could potentially run in low-power embedded processors. The investigation revealed that the 24 GHz radar has the highest baseline noise level, 0.04mm at 0{\deg} angle of incidence, and an error in range estimation of 3.45 +- 1.88 cm at a distance of 60 cm. At the same distance, the 60 GHz and the 120 GHz radar system shows the least noise level, 0.0lmm at 0{\deg} angle of incidence, and error in range estimation 0.64 +- 0.01 cm and 0.04 +- 0.0 cm respectively. Additionally, tests on humans showed that all three radar systems were able to identify heart and breathing activity but the 120 GHz radar system outperformed the other two.
</details>
<details>
<summary>摘要</summary>
非接触生命 Parameters 监测有多种优点，包括舒适、不侵入和不扩散感染。使用毫米波（mmWave）雷达是一种非接触监测生命 Parameters 的非常有前途的方法之一。新的低功耗实现技术可能使生命 Parameters 监测在嵌入式、电池操作的设备中进行。这些新的低功耗传感器增加了精准和可靠地生命 Parameters 监测的挑战，特别是心率跟踪问题。这项工作将关注三种频率变化连续波（FMCW）低功耗雷达的调查和特征化。这三种雷达的各自的载波频率分别为24GHz、60GHz和120GHz。测试平台首先在模拟人体的phantom模型上进行测试，以准确评估基准噪声、误差范围估计和位移估计误差。此外，系统还被用来收集来自三名人类试验者的数据，以评估可能通过简单和轻量级算法在低功耗嵌入式处理器中识别心跳和呼吸活动的可能性。调查表明，24GHz雷达具有最高的基准噪声水平（0.04mm，0°角度），误差范围估计为60cm处的3.45±1.88cm。相比之下，60GHz和120GHz雷达系统在同一个距离处具有最低的基准噪声水平（0.01mm，0°角度）和误差范围估计（0.64±0.01cm和0.04±0.0cm）。此外，对人类试验者进行测试表明，所有三种雷达系统都能够识别心跳和呼吸活动，但120GHz雷达系统表现最佳。
</details></li>
</ul>
<hr>
<h2 id="User-Power-Measurement-Based-IRS-Channel-Estimation-via-Single-Layer-Neural-Network"><a href="#User-Power-Measurement-Based-IRS-Channel-Estimation-via-Single-Layer-Neural-Network" class="headerlink" title="User Power Measurement Based IRS Channel Estimation via Single-Layer Neural Network"></a>User Power Measurement Based IRS Channel Estimation via Single-Layer Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08275">http://arxiv.org/abs/2309.08275</a></li>
<li>repo_url: None</li>
<li>paper_authors: He Sun, Weidong Mei, Lipeng Zhu, Rui Zhang</li>
<li>for: 提高IRS干扰通信系统中BS-IRS-用户层次链路的通道知识，以便设计高性能的IRS反射。</li>
<li>methods: 基于用户接收信号强度测量的单层神经网络（NN） enabled IRS通道估计方法。</li>
<li>results: 比对 existed 力量测量基础的设计，NN enabled IRS通道估计方法可以显著提高多用户通信系统中 minimum received signal-to-noise ratio（SNR）。<details>
<summary>Abstract</summary>
One main challenge for implementing intelligent reflecting surface (IRS) aided communications lies in the difficulty to obtain the channel knowledge for the base station (BS)-IRS-user cascaded links, which is needed to design high-performance IRS reflection in practice. Traditional methods for estimating IRS cascaded channels are usually based on the additional pilot signals received at the BS/users, which increase the system training overhead and also may not be compatible with the current communication protocols. To tackle this challenge, we propose in this paper a new single-layer neural network (NN)-enabled IRS channel estimation method based on only the knowledge of users' individual received signal power measurements corresponding to different IRS random training reflections, which are easily accessible in current wireless systems. To evaluate the effectiveness of the proposed channel estimation method, we design the IRS reflection for data transmission based on the estimated cascaded channels in an IRS-aided multiuser communication system. Numerical results show that the proposed IRS channel estimation and reflection design can significantly improve the minimum received signal-to-noise ratio (SNR) among all users, as compared to existing power measurement based designs.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在实现智能反射表（IRS）协助通信是获取BS-IRS-用户层次链的通道知识，这是实际设计高性能IRS反射的必要前提。传统的IRS层次通道估算方法通常基于BS/用户收到的额外测试信号，这会增加系统训练负担并且可能与当前通信协议不兼容。为解决这个挑战，我们在本纸提出了一种基于单层神经网络（NN）的IRS通道估算方法，只需要用户个人接收信号强度测量对应不同的IRS随机测试反射，这些测量值易于获取现有无线系统中。为评估提案的效果，我们设计了基于估算的IRS反射 для数据传输在IRS协助多用户通信系统中。 numerically results show that the proposed IRS channel estimation and reflection design can significantly improve the minimum received signal-to-noise ratio（SNR） among all users, as compared to existing power measurement based designs.Note: "BS" stands for "base station", "IRS" stands for "intelligent reflecting surface", and "用户" stands for "user".
</details></li>
</ul>
<hr>
<h2 id="Trajectory-Tracking-Control-of-UAV-Bicopter-using-Linear-Quadratic-Gaussian"><a href="#Trajectory-Tracking-Control-of-UAV-Bicopter-using-Linear-Quadratic-Gaussian" class="headerlink" title="Trajectory Tracking Control of UAV Bicopter using Linear Quadratic Gaussian"></a>Trajectory Tracking Control of UAV Bicopter using Linear Quadratic Gaussian</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08226">http://arxiv.org/abs/2309.08226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fahmizal, Hanung Adi Nugroho, Adha Imam Cahyadi, Igi Ardiyanto</li>
<li>for: 本研究设计了一个适用于UAV Bicopter的线性过 quadratic Gaussian（LQG）控制器，以确保适当的轨迹追踪控制。</li>
<li>methods: 本研究使用了LQG控制器，并在实验中评估了它的效果。</li>
<li>results: 实验结果显示，LQG控制器能够成功地击倒对UAV Bicopter的惯性干扰，并且在轨迹追踪时有较低的root mean square error（RMSE）值。<details>
<summary>Abstract</summary>
This paper describes the design of a linear quadratic gaussian (LQG) for trajectory tracking control of UAV Bicopter. In this work, disturbance in the form of payload significantly affects the trajectory tracking control process on the UAV Bicopter when using a linear quadratic regulator (LQR) controller. The use of a LQR control will be optimal in the case of a state regulator towards an equilibrium point in a system, but for the tracking case, the LQR controller is not capable of optimally, especially in systems that have high levels of nonlinearity and system dynamic changes such as inertial disturbances. Therefore, this paper proposes the design of a LQG control that is expected to overcome system dynamic changes, in this case in the form of inertial disturbances to the UAV Bicopter when carrying a payload. The success of LQG control was tested in two scenarios, the first trajectory tracking at a circular position and the second with the position of the trajectory number "8". The simulation results show that the proposed LQG controller successfully overcame inertial disturbances when the UAV Bicopter performs trajectory tracking. When given an inertial disturbance, the trajectory tracking test results show that the LQG control has a lower root mean square error (RMSE) value than the LQR control.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Attitude-Control-and-Low-Cost-Design-of-UAV-Bicopter"><a href="#Attitude-Control-and-Low-Cost-Design-of-UAV-Bicopter" class="headerlink" title="Attitude Control and Low Cost Design of UAV Bicopter"></a>Attitude Control and Low Cost Design of UAV Bicopter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08209">http://arxiv.org/abs/2309.08209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fahmizal, Hanung Adi Nugroho, Adha Imam Cahyadi, Igi Ardiyanto</li>
<li>for: 这个研究旨在开发一个对应几copter的控制系统，以提高它的姿态稳定性和适航性。</li>
<li>methods: 这个控制系统使用PID控制器，通过从IMU获取反馈，计算控制输入，以调整几copter的姿态（滚、翻和旋转角），抗抵抗风吟噪。</li>
<li>results: 在实验床上，这个控制系统能够成功地控制几copter的姿态，并且具有耐风吟噪的性能。<details>
<summary>Abstract</summary>
This paper present a control system for the attitude and low cost design of a Bicopter. The control system uses a PID controller that receives feedback from an IMU to calculate control inputs that adjust the Bicopters attitude (roll, pitch and yaw angles) which is resistant to disturbances (wind noise) on a test bed. The control system is implemented on a hardware platform consisting of a Bicopter, an IMU sensor, and a microcontroller with low cost design. In mechanical design, the Bicopter is designed to more closely resemble the letter "V" so that the distribution of the centre of mass (CoM) of the Bicopter can be such that the servomotor torque reaction is parallel to the axis of rotation of the Bicopter during the movement of the pitch angle attitude. In electronic design, the Bicopter was developed using the ATmega328P microcontroller.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种控制系统，用于控制飞行器的姿态和低成本设计。该控制系统使用PID控制器，通过接收IMU传感器的反馈，计算控制输入，以调整飞行器的姿态（滚、平、旋角），抗抗扰（风噪）。控制系统在硬件平台上实现，包括飞行器、IMU传感器和微控制器，并采用低成本设计。在机械设计方面，飞行器设计更加接近字母"V"的形状，以使得飞行器的中心质量（CoM）的分布可以使服控轴向量和飞行器的旋转轴重叠。在电子设计方面，飞行器使用ATmega328P微控制器开发。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Aware-Joint-Source-Channel-Coding-for-image-transmission-based-on-Disentangled-Information-Bottleneck"><a href="#Privacy-Aware-Joint-Source-Channel-Coding-for-image-transmission-based-on-Disentangled-Information-Bottleneck" class="headerlink" title="Privacy-Aware Joint Source-Channel Coding for image transmission based on Disentangled Information Bottleneck"></a>Privacy-Aware Joint Source-Channel Coding for image transmission based on Disentangled Information Bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08188">http://arxiv.org/abs/2309.08188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lunan Sun, Caili Guo, Mingzhe Chen, Yang Yang<br>for: 这个论文是针对隐私考虑的共同源通道编码（JSCC）进行研究，以避免在传输过程中泄露私人资讯。methods: 这个方法基于分离的信息瓶颈（DIB）来实现隐私考虑，具体来说是利用分离的信息瓶颈目标来分离私人资讯和公共资讯。results: 实验结果显示，这个方法可以对私人资讯的泄露率进行下降，相比之前的方法可以降低私人资讯的泄露率高达20%。<details>
<summary>Abstract</summary>
Current privacy-aware joint source-channel coding (JSCC) works aim at avoiding private information transmission by adversarially training the JSCC encoder and decoder under specific signal-to-noise ratios (SNRs) of eavesdroppers. However, these approaches incur additional computational and storage requirements as multiple neural networks must be trained for various eavesdroppers' SNRs to determine the transmitted information. To overcome this challenge, we propose a novel privacy-aware JSCC for image transmission based on disentangled information bottleneck (DIB-PAJSCC). In particular, we derive a novel disentangled information bottleneck objective to disentangle private and public information. Given the separate information, the transmitter can transmit only public information to the receiver while minimizing reconstruction distortion. Since DIB-PAJSCC transmits only public information regardless of the eavesdroppers' SNRs, it can eliminate additional training adapted to eavesdroppers' SNRs. Experimental results show that DIB-PAJSCC can reduce the eavesdropping accuracy on private information by up to 20\% compared to existing methods.
</details>
<details>
<summary>摘要</summary>
当前的隐私意识敏感的联源渠道编码（JSCC）技术目的是避免在敌对训练JSCC编码器和解码器下传输私人信息。然而，这些方法会增加额外的计算和存储需求，因为需要训练多个神经网络来满足不同的伪造者的信号噪比（SNR）来确定传输的信息。为了解决这个挑战，我们提出了一种基于分离信息瓶颈（DIB）的隐私意识敏感JSCC技术，即DIB-PAJSCC。特别是，我们 derivated一个新的分离信息瓶颈目标函数，用于分离私人信息和公共信息。在给定的私人信息和公共信息之后，发送者可以只将公共信息发送到收件人，以最小化重建误差。由于DIB-PAJSCC只发送公共信息，不需要根据伪造者的SNR进行额外的训练。实验结果表明，DIB-PAJSCC可以将伪造者在私人信息上的抓取精度降低到20%以上。
</details></li>
</ul>
<hr>
<h2 id="Message-Passing-Based-Joint-Channel-Estimation-and-Signal-Detection-for-OTFS-with-Superimposed-Pilots"><a href="#Message-Passing-Based-Joint-Channel-Estimation-and-Signal-Detection-for-OTFS-with-Superimposed-Pilots" class="headerlink" title="Message Passing-Based Joint Channel Estimation and Signal Detection for OTFS with Superimposed Pilots"></a>Message Passing-Based Joint Channel Estimation and Signal Detection for OTFS with Superimposed Pilots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08177">http://arxiv.org/abs/2309.08177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fupeng Huang, Qinghua Guo, Youwen Zhang, Yuriy Zakharov</li>
<li>for: 提高OTFS系统传输效率，降低计算复杂性</li>
<li>methods: 使用SP在DD域和GCE基本函数展开模型（BEM）来实现消息传递基本 receiver，减少计算复杂性</li>
<li>results: 提出了一种具有减少计算复杂性的SP-DD-D接收器，可以有效减少射频信号的功率和几乎不产生频率域信号强度的减少，同时保持频率域信号强度准确性。<details>
<summary>Abstract</summary>
Receivers with joint channel estimation and signal detection using superimposed pilots (SP) can achieve high transmission efficiency in orthogonal time frequency space (OTFS) systems. However, existing receivers have high computational complexity, hindering their practical applications. In this work, with SP in the delay-Doppler (DD) domain and the generalized complex exponential (GCE) basis expansion modeling (BEM) for channels, a message passing-based SP-DD iterative receiver is proposed, which drastically reduces the computational complexity while with marginal performance loss, compared to existing ones. To facilitate channel estimation (CE) in the proposed receiver, we design pilot signal to achieve pilot power concentration in the frequency domain, thereby developing an SP-DD-D receiver that can effectively reduce the power of the pilot signal and almost no loss of CE accuracy. Extensive simulation results are provided to demonstrate the superiority of the proposed SP-DD-D receiver.
</details>
<details>
<summary>摘要</summary>
接收器使用共同频率预估和信号检测使用超出练习器（SP）可以在orthogonal时频空间（OTFS）系统中实现高传输效率。然而，现有的接收器具有高计算复杂性，使其在实际应用中受限。在这种工作中，我们使用SP在延迟-Doppler（DD）域和通用复杂幂（GCE）基础函数扩展模型（BEM）来模型通道。我们提出了一种基于消息传递的SP-DD迭代接收器，可以减少计算复杂性，与现有的接收器相比，减少性能损失。为便channel estimation（CE）在提议的接收器中，我们设计了射频信号，以实现频率域中射频信号的集中，并开发了SP-DD-D接收器，可以有效减少射频信号的输力，并且几乎没有CE精度损失。我们在实验结果中提供了广泛的示范，以证明提议的SP-DD-D接收器的优越性。
</details></li>
</ul>
<hr>
<h2 id="TransMUSIC-A-Transformer-Aided-Subspace-Method-for-DOA-Estimation-with-Low-Resolution-ADCs"><a href="#TransMUSIC-A-Transformer-Aided-Subspace-Method-for-DOA-Estimation-with-Low-Resolution-ADCs" class="headerlink" title="TransMUSIC: A Transformer-Aided Subspace Method for DOA Estimation with Low-Resolution ADCs"></a>TransMUSIC: A Transformer-Aided Subspace Method for DOA Estimation with Low-Resolution ADCs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08174">http://arxiv.org/abs/2309.08174</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jijunkai/transformer_music">https://github.com/jijunkai/transformer_music</a></li>
<li>paper_authors: Junkai Ji, Wei Mao, Feng Xi, Shengyao Chen</li>
<li>for: 这篇论文是为了解决大规模阵列的指向方向估计问题，尤其是在低分辨率ADCs中，因为这会导致讯号和噪音分配难以分离。</li>
<li>methods: 这篇论文使用了Transformer模型来帮助子空间估计，透过处理多个截面的 parallel 处理，以捕捉全面的相关性。这个学习的子空间可以用来建立MUSIC спектrum和执行格子less DOA估计使用神经网络基于峰找器。</li>
<li>results:  numerics results表明TransMUSIC算法在一 bits quantized data中表现出色，superior to traditional methods. 这些结果显示Transformer-based技术在DOA估计中的潜力。<details>
<summary>Abstract</summary>
Direction of arrival (DOA) estimation employing low-resolution analog-to-digital convertors (ADCs) has emerged as a challenging and intriguing problem, particularly with the rise in popularity of large-scale arrays. The substantial quantization distortion complicates the extraction of signal and noise subspaces from the quantized data. To address this issue, this paper introduces a novel approach that leverages the Transformer model to aid the subspace estimation. In this model, multiple snapshots are processed in parallel, enabling the capture of global correlations that span them. The learned subspace empowers us to construct the MUSIC spectrum and perform gridless DOA estimation using a neural network-based peak finder. Additionally, the acquired subspace encodes the vital information of model order, allowing us to determine the exact number of sources. These integrated components form a unified algorithmic framework referred to as TransMUSIC. Numerical results demonstrate the superiority of the TransMUSIC algorithm, even when dealing with one-bit quantized data. The results highlight the potential of Transformer-based techniques in DOA estimation.
</details>
<details>
<summary>摘要</summary>
direction of arrival (DOA) 估计使用低分辨率analog-to-digital convertors (ADCs) 已成为一个挑战和吸引人的问题，尤其是大规模阵列的普及。大规模的量化误差使得从量化数据中提取信号和噪声子空间变得复杂。为解决这个问题，本文提出了一种新的方法，利用Transformer模型来支持子空间估计。在这种模型中，多个快照被处理在平行进程中，使得global correlationspan它们。学习的子空间使我们能够构建MUSIC谱和使用神经网络基于峰找器来进行网格化DOA估计。此外，获得的子空间包含重要信息的模型顺序，allow us to determine the exact number of sources。这些集成的组件形成一个统一的算法框架，称为TransMUSIC。数学结果表明TransMUSIC算法在处理一比特量化数据时具有优势。结果也 highlights the potential of Transformer-based techniques in DOA estimation.
</details></li>
</ul>
<hr>
<h2 id="Exploration-into-Optimal-State-Estimation-with-Event-triggered-Communication"><a href="#Exploration-into-Optimal-State-Estimation-with-Event-triggered-Communication" class="headerlink" title="Exploration into Optimal State Estimation with Event-triggered Communication"></a>Exploration into Optimal State Estimation with Event-triggered Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08070">http://arxiv.org/abs/2309.08070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolei Bian, Huimin Chen, X. Rong Li</li>
<li>for: 本研究旨在解决远程掌握某种随机线性系统的状态问题，该系统由感知器观测，但具有计算能力来计算本地估计。</li>
<li>methods: 我们提出了一种事件触发通信（ETC）方案和远程状态估计器，用于优化系统性能和通信资源的费用之间的tradeoff。我们还提出了一种基于时变阈值的幂等启发式通信概率，并 derivated了相应的远程最小方差均方差估计器。</li>
<li>results: 我们通过 simulation results 示出了我们的方法的效果。<details>
<summary>Abstract</summary>
This paper deals with the problem of remote estimation of the state of a discrete-time stochastic linear system observed by a sensor with computational capacity to calculate local estimates. We design an event-triggered communication (ETC) scheme and a remote state estimator to optimally calibrate the tradeoff between system performance and limited communication resources. The novel communication scheme is the time-varying thresholding version for the cumulative innovation-driven communication scheme in [1], and its transmission probability is given. We derive the corresponding remote minimum mean square error (MMSE) estimator and present a tight upper bound for its MSE matrices. We also show that by employing a couple of weak assumptions, the optimality problem becomes (asymptotically) exact and can be addressed in an Markov Decision Process (MDP) framework, which delivers optimal policy and cost in an algorithmic procedure. The simulation results illustrate the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/15/eess.SP_2023_09_15/" data-id="clohum9h70185pj886hdm46fa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/cs.SD_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T15:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/cs.SD_2023_09_14/">cs.SD - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DDSP-SFX-Acoustically-guided-sound-effects-generation-with-differentiable-digital-signal-processing"><a href="#DDSP-SFX-Acoustically-guided-sound-effects-generation-with-differentiable-digital-signal-processing" class="headerlink" title="DDSP-SFX: Acoustically-guided sound effects generation with differentiable digital signal processing"></a>DDSP-SFX: Acoustically-guided sound effects generation with differentiable digital signal processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08060">http://arxiv.org/abs/2309.08060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunyi Liu, Craig Jin, David Gunawan</li>
<li>for: 该论文旨在控制声音效果的变化，使用神经音频合成模型。</li>
<li>methods: 该模型基于DDSP架构，利用预处理的音频特征和数字合成器实现高质量的声音合成，同时允许用户轻松控制声音特征的变化。</li>
<li>results: 该模型可以实现高评价的声音变化控制，并且可以通过声音导向来实现时间特征模拟。<details>
<summary>Abstract</summary>
Controlling the variations of sound effects using neural audio synthesis models has been a difficult task. Differentiable digital signal processing (DDSP) provides a lightweight solution that achieves high-quality sound synthesis while enabling deterministic acoustic attribute control by incorporating pre-processed audio features and digital synthesizers. In this research, we introduce DDSP-SFX, a model based on the DDSP architecture capable of synthesizing high-quality sound effects while enabling users to control the timbre variations easily. We propose a transient modelling technique with higher objective evaluation scores and subjective ratings over impulsive signals (footsteps, gunshots). We propose a simple method that achieves timbre variation control while also allowing deterministic attribute control. We further qualitatively show the timbre transfer performance using voice as the guiding sound.
</details>
<details>
<summary>摘要</summary>
控制声音效果的变化使用神经音频合成模型是一项具有挑战性的任务。可 diferenciable digital signal processing（DDSP）提供了一种轻量级的解决方案，可以实现高质量的声音合成，同时允许用户 deterministic 控制声音特性。在这项研究中，我们介绍了 DDSP-SFX 模型，可以同时实现高质量的声音效果和用户容易控制声音特性的变化。我们提出了一种快速模拟技术，对于快速冲击信号（脚步、枪声）有更高的对象评价分数和主观评分。我们还提出了一种简单的方法，可以实现声音特性的变化控制，同时允许 deterministic 控制声音特性。最后，我们质量地表示了声音传输性能，使用语音作为引导声。
</details></li>
</ul>
<hr>
<h2 id="VoicePAT-An-Efficient-Open-source-Evaluation-Toolkit-for-Voice-Privacy-Research"><a href="#VoicePAT-An-Efficient-Open-source-Evaluation-Toolkit-for-Voice-Privacy-Research" class="headerlink" title="VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy Research"></a>VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08049">http://arxiv.org/abs/2309.08049</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/digitalphonetics/voicepat">https://github.com/digitalphonetics/voicepat</a></li>
<li>paper_authors: Sarina Meyer, Xiaoxiao Miao, Ngoc Thang Vu</li>
<li>for: 本研究旨在提供一个高效的话语隐藏和评估框架，以便比较和结合不同的隐藏方法。</li>
<li>methods: 本研究使用了一个模块化和易扩展的结构，几乎完全使用Python进行实现。该框架可以同时进行多种隐藏方法的并行运算，并且提供了与不同技术间的交互功能。</li>
<li>results: 本研究所得到的结果显示，使用修改后的评估方法可以大幅降低评估时间，比如65%-95%，具体取决于评估指标。此外，研究人员还提供了开源代码。<details>
<summary>Abstract</summary>
Speaker anonymization is the task of modifying a speech recording such that the original speaker cannot be identified anymore. Since the first Voice Privacy Challenge in 2020, along with the release of a framework, the popularity of this research topic is continually increasing. However, the comparison and combination of different anonymization approaches remains challenging due to the complexity of evaluation and the absence of user-friendly research frameworks. We therefore propose an efficient speaker anonymization and evaluation framework based on a modular and easily extendable structure, almost fully in Python. The framework facilitates the orchestration of several anonymization approaches in parallel and allows for interfacing between different techniques. Furthermore, we propose modifications to common evaluation methods which make the evaluation more powerful and reduces their computation time by 65 to 95\%, depending on the metric. Our code is fully open source.
</details>
<details>
<summary>摘要</summary>
干扰者隐藏是修改语音录音以使原始发言人无法识别的任务。自2020年的第一届语音隐私挑战以来，这个研究主题的 популяр度一直在不断增长。然而，对不同隐藏方法的比较和组合仍然具有较高的复杂性和评价方法的缺失，这使得研究者难以进行效果的比较和结合。我们因此提出了一个高效的干扰者隐藏和评价框架，基于模块化和扩展性强的结构，几乎完全基于Python编程语言。该框架可以同时实现多种隐藏方法的并行执行，并且支持不同技术的交互。此外，我们还提出了一些改进的评价方法，使评价更加强大，同时降低了计算时间，对各种指标的降低为65%-95%。我们的代码完全开源。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Assessment-of-Markov-Models-and-Recurrent-Neural-Networks-for-Jazz-Music-Generation"><a href="#Comparative-Assessment-of-Markov-Models-and-Recurrent-Neural-Networks-for-Jazz-Music-Generation" class="headerlink" title="Comparative Assessment of Markov Models and Recurrent Neural Networks for Jazz Music Generation"></a>Comparative Assessment of Markov Models and Recurrent Neural Networks for Jazz Music Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08027">http://arxiv.org/abs/2309.08027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Conrad Hsu, Ross Greer</li>
<li>for:  Comparing the performance of a simple Markov chain model and a recurrent neural network (RNN) model in jazz music improvisation.</li>
<li>methods:  Using transcriptions of jazz blues choruses from professional jazz players to train both models, and using musical jazz seeds to give the model context.</li>
<li>results:  The RNN outperforms the Markov model on both metrics (groove pattern similarity and pitch class histogram entropy), indicating better rhythmic consistency and tonal stability in the generated music.<details>
<summary>Abstract</summary>
As generative models have risen in popularity, a domain that has risen alongside is generative models for music. Our study aims to compare the performance of a simple Markov chain model and a recurrent neural network (RNN) model, two popular models for sequence generating tasks, in jazz music improvisation. While music, especially jazz, remains subjective in telling whether a composition is "good" or "bad", we aim to quantify our results using metrics of groove pattern similarity and pitch class histogram entropy. We trained both models using transcriptions of jazz blues choruses from professional jazz players, and also fed musical jazz seeds to help give our model some context in beginning the generation. Our results show that the RNN outperforms the Markov model on both of our metrics, indicating better rhythmic consistency and tonal stability in the generated music. Through the use of music21 library, we tokenized our jazz dataset into pitches and durations that our model could interpret and train on. Our findings contribute to the growing field of AI-generated music, highlighting the important use of metrics to assess generation quality. Future work includes expanding the dataset of MIDI files to a larger scale, conducting human surveys for subjective evaluations, and incorporating additional metrics to address the challenge of subjectivity in music evaluation. Our study provides valuable insight into the use of recurrent neural networks for sequential based tasks like generating music.
</details>
<details>
<summary>摘要</summary>
为了比较Markov链模型和循环神经网络（RNN）模型在爵士乐音乐创作中的表现，我们进行了一项研究。尽管音乐，特别是爵士乐，是主观的，我们使用了乐谱符号相似性和抽象度量来衡量结果。我们使用了music21库将爵士乐谱例转化为普通的音频文件，然后训练了两个模型。我们发现RNN模型在两个指标上表现得更好，表示它在生成的音乐中保持了更好的节奏一致性和听觉稳定性。我们的发现对于AI生成音乐领域的发展具有重要意义，并且将为将来的人工智能音乐创作做出贡献。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Face-Detection-with-Audio-Based-Region-Proposals"><a href="#Efficient-Face-Detection-with-Audio-Based-Region-Proposals" class="headerlink" title="Efficient Face Detection with Audio-Based Region Proposals"></a>Efficient Face Detection with Audio-Based Region Proposals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08005">http://arxiv.org/abs/2309.08005</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Aris, François Grondin</li>
<li>for: 这 paper 是为了提高机器人视觉系统的计算效率，减少图像质量下降的影响。</li>
<li>methods: 这 paper 使用了一种新的注意力机制，以便通过音频来生成optical图像中的区域关注点。</li>
<li>results: 该注意力机制可以减少计算负担，并且可以方便地适应人机交互、机器人监测、视频会议或智能眼镜等场景。<details>
<summary>Abstract</summary>
Robot vision often involves a large computational load due to large images to process in a short amount of time. Existing solutions often involve reducing image quality which can negatively impact processing. Another approach is to generate regions of interest with expensive vision algorithms. In this paper, we evaluate how audio can be used to generate regions of interest in optical images. To achieve this, we propose a unique attention mechanism to localize speech sources and evaluate its impact on a face detection algorithm. Our results show that the attention mechanism reduces the computational load. The proposed pipeline is flexible and can be easily adapted for human-robot interactions, robot surveillance, video-conferences or smart glasses.
</details>
<details>
<summary>摘要</summary>
署 robot 视觉通常会面临大量计算压力，因为需要在短时间内处理大量图像。现有的解决方案经常包括降低图像质量，这会对处理造成负面影响。在这篇论文中，我们评估了如何使用音频来生成optical图像中的区域兴趣点。为此，我们提出了一种特殊的注意机制，用于本地化speech 源，并评估其对人脸检测算法的影响。我们的结果表明，注意机制可以降低计算压力。我们提出的管道可满足人机交互、机器人监控、视频会议或智能眼镜等应用。
</details></li>
</ul>
<hr>
<h2 id="EMOCONV-DIFF-Diffusion-based-Speech-Emotion-Conversion-for-Non-parallel-and-In-the-wild-Data"><a href="#EMOCONV-DIFF-Diffusion-based-Speech-Emotion-Conversion-for-Non-parallel-and-In-the-wild-Data" class="headerlink" title="EMOCONV-DIFF: Diffusion-based Speech Emotion Conversion for Non-parallel and In-the-wild Data"></a>EMOCONV-DIFF: Diffusion-based Speech Emotion Conversion for Non-parallel and In-the-wild Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07828">http://arxiv.org/abs/2309.07828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navin Raj Prabhu, Bunlong Lay, Simon Welker, Nale Lehmann-Willenbrock, Timo Gerkmann</li>
<li>for: 本研究主要针对听众语音中的情感转换任务，即将表达的情感转换为目标情感，保持语音内容和说话人身份不变。</li>
<li>methods: 本文提出一种基于扩散的生成模型，名为EmoConv-Diff，用于实现情感转换。该模型在训练时会重建输入语音，同时Conditioning on its emotion。在推理阶段，使用目标情感嵌入来转换输入语音的情感。与其他研究不同的是，本文不使用平行数据，而是使用大量在野数据进行训练。</li>
<li>results: 经验表明，提出的扩散模型可以成功地Synthesize speech with a controllable target emotion。此外，该方法还能够在情感值的极端值下表现出色，因此可以解决在语音情感转换领域的一个常见问题。<details>
<summary>Abstract</summary>
Speech emotion conversion is the task of converting the expressed emotion of a spoken utterance to a target emotion while preserving the lexical content and speaker identity. While most existing works in speech emotion conversion rely on acted-out datasets and parallel data samples, in this work we specifically focus on more challenging in-the-wild scenarios and do not rely on parallel data. To this end, we propose a diffusion-based generative model for speech emotion conversion, the EmoConv-Diff, that is trained to reconstruct an input utterance while also conditioning on its emotion. Subsequently, at inference, a target emotion embedding is employed to convert the emotion of the input utterance to the given target emotion. As opposed to performing emotion conversion on categorical representations, we use a continuous arousal dimension to represent emotions while also achieving intensity control. We validate the proposed methodology on a large in-the-wild dataset, the MSP-Podcast v1.10. Our results show that the proposed diffusion model is indeed capable of synthesizing speech with a controllable target emotion. Crucially, the proposed approach shows improved performance along the extreme values of arousal and thereby addresses a common challenge in the speech emotion conversion literature.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译成简化中文。<</SYS>>这个工作主要关注在实际场景中进行情感转换，而不是基于演示数据和平行数据样本。为了实现这一目标，我们提出了一种基于吸引过程的生成模型，即EmocoConv-Diff，可以重建输入utterance的内容，同时也根据情感进行conditioning。在推理阶段，使用目标情感嵌入来转换输入utterance的情感。与其他工作不同的是，我们使用连续的兴奋度维度来表示情感，同时实现了强度控制。我们验证了我们的方法在大量实际场景中的MSP-Podcast v1.10 dataset上，结果表明，提出的扩散模型确实可以控制目标情感。更重要的是，我们的方法在兴奋度的极值位置上表现出了改进的性能，因此解决了实际场景中的一个常见挑战。
</details></li>
</ul>
<hr>
<h2 id="SnakeGAN-A-Universal-Vocoder-Leveraging-DDSP-Prior-Knowledge-and-Periodic-Inductive-Bias"><a href="#SnakeGAN-A-Universal-Vocoder-Leveraging-DDSP-Prior-Knowledge-and-Periodic-Inductive-Bias" class="headerlink" title="SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and Periodic Inductive Bias"></a>SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and Periodic Inductive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07803">http://arxiv.org/abs/2309.07803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sipan Li, Songxiang Liu, Luwen Zhang, Xiang Li, Yanyao Bian, Chao Weng, Zhiyong Wu, Helen Meng</li>
<li>For:	+ The paper aims to train a universal vocoder that can generalize well to out-of-domain (OOD) scenarios, such as unseen speaking styles, non-speech vocalization, singing, and musical pieces.* Methods:	+ The proposed method, called SnakeGAN, uses a GAN-based architecture with a coarse-grained signal generated by a differentiable digital signal processing (DDSP) model as prior knowledge.	+ The generator uses the Snake activation function and anti-aliased representation to introduce periodic nonlinearities and bring the desired inductive bias for audio synthesis.* Results:	+ The proposed method significantly outperforms compared approaches and can generate high-fidelity audio samples including unseen speakers with unseen styles, singing voices, instrumental pieces, and nonverbal vocalization.<details>
<summary>Abstract</summary>
Generative adversarial network (GAN)-based neural vocoders have been widely used in audio synthesis tasks due to their high generation quality, efficient inference, and small computation footprint. However, it is still challenging to train a universal vocoder which can generalize well to out-of-domain (OOD) scenarios, such as unseen speaking styles, non-speech vocalization, singing, and musical pieces. In this work, we propose SnakeGAN, a GAN-based universal vocoder, which can synthesize high-fidelity audio in various OOD scenarios. SnakeGAN takes a coarse-grained signal generated by a differentiable digital signal processing (DDSP) model as prior knowledge, aiming at recovering high-fidelity waveform from a Mel-spectrogram. We introduce periodic nonlinearities through the Snake activation function and anti-aliased representation into the generator, which further brings the desired inductive bias for audio synthesis and significantly improves the extrapolation capacity for universal vocoding in unseen scenarios. To validate the effectiveness of our proposed method, we train SnakeGAN with only speech data and evaluate its performance for various OOD distributions with both subjective and objective metrics. Experimental results show that SnakeGAN significantly outperforms the compared approaches and can generate high-fidelity audio samples including unseen speakers with unseen styles, singing voices, instrumental pieces, and nonverbal vocalization.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: генеритив adversarial network (GAN)-based neural vocoder 已经广泛应用于音频合成任务，因为它们的高质量生成、效率推理和小计算脚本。然而，在训练一个通用 vocoder 仍然是挑战，因为它需要在未经见过的 scenarios 中进行泛化，如尚未看到的说话风格、非语音化声、唱歌和音乐作品。在这个工作中，我们提出了 SnakeGAN，一种基于 GAN 的通用 vocoder，可以在多种 OOD 分布上生成高质量的音频。SnakeGAN 使用了干扰函数来引入期望的非线性，并在生成器中使用了抗锯齿表示，以进一步带来音频合成的适应性和泛化能力。为验证我们的提出方法的有效性，我们将 SnakeGAN 训练用 speech 数据，并在多种 OOD 分布上评估其表现。实验结果表明，SnakeGAN 在比较方法上表现出色，可以生成包括未看到的 speaker 和未经见过的风格的高质量音频样本。
</details></li>
</ul>
<hr>
<h2 id="Complexity-Scaling-for-Speech-Denoising"><a href="#Complexity-Scaling-for-Speech-Denoising" class="headerlink" title="Complexity Scaling for Speech Denoising"></a>Complexity Scaling for Speech Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07757">http://arxiv.org/abs/2309.07757</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hangtingchen/Complexity-Scaling-for-Speech-Denoising.github.io">https://github.com/hangtingchen/Complexity-Scaling-for-Speech-Denoising.github.io</a></li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Chao Weng</li>
<li>For: This paper aims to develop a unified architecture for speech denoising models that can handle a wide range of computational complexities.* Methods: The proposed Multi-Path Transform-based (MPT) architecture is designed to handle both low- and high-complexity scenarios. The authors explore the empirical relationship between model performance and computational cost on the denoising task.* Results: The MPT networks achieve high performance on the DNS challenge dataset, and the authors observe a linear increase in the values of PESQ-WB and SI-SNR as the complexity number of multiply-accumulate operations (MACs) is scaled from 50M&#x2F;s to 15G&#x2F;s.<details>
<summary>Abstract</summary>
Computational complexity is critical when deploying deep learning-based speech denoising models for on-device applications. Most prior research focused on optimizing model architectures to meet specific computational cost constraints, often creating distinct neural network architectures for different complexity limitations. This study conducts complexity scaling for speech denoising tasks, aiming to consolidate models with various complexities into a unified architecture. We present a Multi-Path Transform-based (MPT) architecture to handle both low- and high-complexity scenarios. A series of MPT networks present high performance covering a wide range of computational complexities on the DNS challenge dataset. Moreover, inspired by the scaling experiments in natural language processing, we explore the empirical relationship between model performance and computational cost on the denoising task. As the complexity number of multiply-accumulate operations (MACs) is scaled from 50M/s to 15G/s on MPT networks, we observe a linear increase in the values of PESQ-WB and SI-SNR, proportional to the logarithm of MACs, which might contribute to the understanding and application of complexity scaling in speech denoising tasks.
</details>
<details>
<summary>摘要</summary>
computational complexity是speech denoising模型部署时的关键因素。大多数前一代研究都是优化模型结构来满足特定的计算成本限制，通常创建了不同计算成本限制的特有神经网络架构。这项研究进行了计算复杂性排比，旨在将不同计算复杂性的模型合并到一个统一的架构中。我们提出了基于多路变换的（MPT）架构，可以处理low-和high-计算复杂性的enario。MPT网络在DNS挑战数据集上表现出了高性能，并且在不同的计算成本水平下保持稳定性。此外，通过自然语言处理领域的缩放实验，我们发现了对于去噪任务，模型性能和计算成本之间存在线性关系，具体来说，随着MACs计算复杂性的幂数增加，PESQ-WB和SI-SNR的值会线性增加，这可能对于speech denoising任务中的计算复杂性排比做出贡献。
</details></li>
</ul>
<hr>
<h2 id="DDSP-based-Neural-Waveform-Synthesis-of-Polyphonic-Guitar-Performance-from-String-wise-MIDI-Input"><a href="#DDSP-based-Neural-Waveform-Synthesis-of-Polyphonic-Guitar-Performance-from-String-wise-MIDI-Input" class="headerlink" title="DDSP-based Neural Waveform Synthesis of Polyphonic Guitar Performance from String-wise MIDI Input"></a>DDSP-based Neural Waveform Synthesis of Polyphonic Guitar Performance from String-wise MIDI Input</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07658">http://arxiv.org/abs/2309.07658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Jonason, Xin Wang, Erica Cooper, Lauri Juvela, Bob L. T. Sturm, Junichi Yamagishi</li>
<li>for: 这篇论文探讨使用神经合成来生成音频电 guitar，从MIDI输入中提取特征。</li>
<li>methods: 论文提出了四种不同的系统，并对它们进行对比，包括对象 метри克和主观评价。它们的架构和中间任务，如预测抑制特征，都受到了考虑。</li>
<li>results: 研究发现，将控制特征预测任务设计为分类任务而不是回归任务可以获得更好的结果。此外，论文发现最简单的提出的系统，直接从MIDI输入预测合成参数，最好的性能。音频示例可以在<a target="_blank" rel="noopener" href="https://erl-j.github.io/neural-guitar-web-supplement%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://erl-j.github.io/neural-guitar-web-supplement中找到。</a><details>
<summary>Abstract</summary>
We explore the use of neural synthesis for acoustic guitar from string-wise MIDI input. We propose four different systems and compare them with both objective metrics and subjective evaluation against natural audio and a sample-based baseline. We iteratively develop these four systems by making various considerations on the architecture and intermediate tasks, such as predicting pitch and loudness control features. We find that formulating the control feature prediction task as a classification task rather than a regression task yields better results. Furthermore, we find that our simplest proposed system, which directly predicts synthesis parameters from MIDI input performs the best out of the four proposed systems. Audio examples are available at https://erl-j.github.io/neural-guitar-web-supplement.
</details>
<details>
<summary>摘要</summary>
我们研究使用神经合成来synthesize acoustic guitar from string-wise MIDI输入。我们提出了四种不同的系统，并与对象指标和主观评估对自然音频和样本基eline进行比较。我们逐次开发这四种系统，通过考虑不同的架构和中间任务，如预测把握特征和声音强度控制特征。我们发现，将控制特征预测任务转换为分类任务而不是回归任务，可以获得更好的结果。此外，我们发现我们最简单的提出的系统，直接从MIDI输入预测synthesis参数，在四种系统中表现最佳。有关音频示例，可以查看https://erl-j.github.io/neural-guitar-web-supplement。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Audio-Captioning-using-machine-translated-data"><a href="#Multilingual-Audio-Captioning-using-machine-translated-data" class="headerlink" title="Multilingual Audio Captioning using machine translated data"></a>Multilingual Audio Captioning using machine translated data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07615">http://arxiv.org/abs/2309.07615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matéo Cousin, Étienne Labbé, Thomas Pellegrini</li>
<li>for: 这个论文主要研究了自动化音频描述系统（AAC）的多语言支持，以及如何使用机器翻译生成多语言的音频描述文本。</li>
<li>methods: 作者使用了自动机器翻译将两个知名的AAC数据集（AudioCaps和Clotho）中的英文描述文本翻译成法语、德语和西班牙语。然后，他们在每种语言上训练和评估了单语言系统，并对AudioCaps和Clotho数据集进行了评估。</li>
<li>results: 研究发现，使用机器翻译生成多语言描述文本可以获得类似于英文系统的性能（约75% CIDEr on AudioCaps和43% on Clotho）。此外，在法语中，手动生成的评估subset的描述文本被法语系统训练后的输出比英文系统自动翻译后的输出更加准确。最后，作者建立了一个多语言模型，可以在每种语言上获得类似的性能，使用的参数少于使用多个单语言系统。<details>
<summary>Abstract</summary>
Automated Audio Captioning (AAC) systems attempt to generate a natural language sentence, a caption, that describes the content of an audio recording, in terms of sound events. Existing datasets provide audio-caption pairs, with captions written in English only. In this work, we explore multilingual AAC, using machine translated captions. We translated automatically two prominent AAC datasets, AudioCaps and Clotho, from English to French, German and Spanish. We trained and evaluated monolingual systems in the four languages, on AudioCaps and Clotho. In all cases, the models achieved similar performance, about 75% CIDEr on AudioCaps and 43% on Clotho. In French, we acquired manual captions of the AudioCaps eval subset. The French system, trained on the machine translated version of AudioCaps, achieved significantly better results on the manual eval subset, compared to the English system for which we automatically translated the outputs to French. This advocates in favor of building systems in a target language instead of simply translating to a target language the English captions from the English system. Finally, we built a multilingual model, which achieved results in each language comparable to each monolingual system, while using much less parameters than using a collection of monolingual systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AAS-VC-On-the-Generalization-Ability-of-Automatic-Alignment-Search-based-Non-autoregressive-Sequence-to-sequence-Voice-Conversion"><a href="#AAS-VC-On-the-Generalization-Ability-of-Automatic-Alignment-Search-based-Non-autoregressive-Sequence-to-sequence-Voice-Conversion" class="headerlink" title="AAS-VC: On the Generalization Ability of Automatic Alignment Search based Non-autoregressive Sequence-to-sequence Voice Conversion"></a>AAS-VC: On the Generalization Ability of Automatic Alignment Search based Non-autoregressive Sequence-to-sequence Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07598">http://arxiv.org/abs/2309.07598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/unilight/seq2seq-vc">https://github.com/unilight/seq2seq-vc</a></li>
<li>paper_authors: Wen-Chin Huang, Kazuhiro Kobayashi, Tomoki Toda</li>
<li>For: The paper is written for the purpose of proposing a non-autoregressive sequence-to-sequence (seq2seq) model for voice conversion (VC) that can generalize well to small training datasets.* Methods: The proposed model, called AAS-VC, uses automatic alignment search (AAS) to remove the dependency on external durations and provide a proper inductive bias for generalization.* Results: The experimental results show that AAS-VC can generalize better to a training dataset of only 5 minutes, compared to current non-AR seq2seq VC models that require larger training datasets.<details>
<summary>Abstract</summary>
Non-autoregressive (non-AR) sequence-to-seqeunce (seq2seq) models for voice conversion (VC) is attractive in its ability to effectively model the temporal structure while enjoying boosted intelligibility and fast inference thanks to non-AR modeling. However, the dependency of current non-AR seq2seq VC models on ground truth durations extracted from an external AR model greatly limits its generalization ability to smaller training datasets. In this paper, we first demonstrate the above-mentioned problem by varying the training data size. Then, we present AAS-VC, a non-AR seq2seq VC model based on automatic alignment search (AAS), which removes the dependency on external durations and serves as a proper inductive bias to provide the required generalization ability for small datasets. Experimental results show that AAS-VC can generalize better to a training dataset of only 5 minutes. We also conducted ablation studies to justify several model design choices. The audio samples and implementation are available online.
</details>
<details>
<summary>摘要</summary>
非自动回归（非AR）序列到序列（seq2seq）模型 для语音转换（VC）具有模型时间结构的能力，同时具有加速推理和提高听解性的优点。然而，现有的非AR seq2seq VC模型对外部AR模型提供的真实duration的依赖限制了其总结推理能力，特别是在小训练集上。在这篇论文中，我们首先描述了上述问题，并通过变换训练数据量来证明。然后，我们提出了AAS-VC模型，基于自动对齐搜索（AAS），解除了对外部duration的依赖，并提供了适当的束缚，以便在小训练集上进行总结推理。实验结果显示，AAS-VC可以更好地总结小训练集中的5分钟 audio samples。我们还进行了一些模型设计选择的抽象研究，以便更好地理解模型的工作原理。音频示例和实现可以在线获取。
</details></li>
</ul>
<hr>
<h2 id="StarGAN-VC-Towards-Emotion-Preserving-Voice-Conversion-Using-Deep-Embeddings"><a href="#StarGAN-VC-Towards-Emotion-Preserving-Voice-Conversion-Using-Deep-Embeddings" class="headerlink" title="StarGAN-VC++: Towards Emotion Preserving Voice Conversion Using Deep Embeddings"></a>StarGAN-VC++: Towards Emotion Preserving Voice Conversion Using Deep Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07592">http://arxiv.org/abs/2309.07592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arnabdas8901/StarGAN-VC_PlusPlus">https://github.com/arnabdas8901/StarGAN-VC_PlusPlus</a></li>
<li>paper_authors: Arnab Das, Suhita Ghosh, Tim Polzehl, Sebastian Stober</li>
<li>for: 本研究旨在提高语音转换（VC）技术的自然性，保留原始说话人的情感表达。</li>
<li>methods: 研究使用了一种基于生成对抗网络的VC方法，称为StarGANv2-VC，但该方法无法保持说话人的情感表达。</li>
<li>results: 研究发现，StarGANv2-VC方法不能分离说话人和情感表达的 Representation，导致情感泄露。为解决这问题，研究提出了一种新的情感意识损失和一种无监督的方法，通过利用 latent emotion representation 进行情感监督。对多个数据集、情感、性别等进行对象和主观评估，研究证明了该策略的有效性。<details>
<summary>Abstract</summary>
Voice conversion (VC) transforms an utterance to sound like another person without changing the linguistic content. A recently proposed generative adversarial network-based VC method, StarGANv2-VC is very successful in generating natural-sounding conversions. However, the method fails to preserve the emotion of the source speaker in the converted samples. Emotion preservation is necessary for natural human-computer interaction. In this paper, we show that StarGANv2-VC fails to disentangle the speaker and emotion representations, pertinent to preserve emotion. Specifically, there is an emotion leakage from the reference audio used to capture the speaker embeddings while training. To counter the problem, we propose novel emotion-aware losses and an unsupervised method which exploits emotion supervision through latent emotion representations. The objective and subjective evaluations prove the efficacy of the proposed strategy over diverse datasets, emotions, gender, etc.
</details>
<details>
<summary>摘要</summary>
声音转换（VC）将一句话变成另一个人的语音，不改变语言内容。一种最近提出的生成对抗网络基本VC方法，StarGANv2-VC非常成功地生成自然听起来的转换。然而，该方法无法保留源speaker的情感。情感保留是人机交互的重要需求。在这篇论文中，我们表明StarGANv2-VC无法分离说话人和情感表示，不能保留情感。具体来说，在训练时使用引用音频捕捉说话人嵌入的情感泄漏问题。为了解决该问题，我们提议使用新的情感意识损失和无监督方法，通过latent情感表示来进行情感监督。对于不同的数据集、情感、性别等，我们的目标和主观评估都证明了我们的策略的有效性。
</details></li>
</ul>
<hr>
<h2 id="Diff-SV-A-Unified-Hierarchical-Framework-for-Noise-Robust-Speaker-Verification-Using-Score-Based-Diffusion-Probabilistic-Models"><a href="#Diff-SV-A-Unified-Hierarchical-Framework-for-Noise-Robust-Speaker-Verification-Using-Score-Based-Diffusion-Probabilistic-Models" class="headerlink" title="Diff-SV: A Unified Hierarchical Framework for Noise-Robust Speaker Verification Using Score-Based Diffusion Probabilistic Models"></a>Diff-SV: A Unified Hierarchical Framework for Noise-Robust Speaker Verification Using Score-Based Diffusion Probabilistic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08320">http://arxiv.org/abs/2309.08320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wngh1187/diff-sv">https://github.com/wngh1187/diff-sv</a></li>
<li>paper_authors: Ju-ho Kim, Jungwoo Heo, Hyun-seo Shin, Chan-yeong Lim, Ha-Jin Yu</li>
<li>for: 提高SV系统的准确性和可靠性，对background noise进行处理</li>
<li>methods: 使用扩散概率模型（DPM）来实现speech enhancement，并将其与 speaker embedding EXTractor结合起来，从而获得具有抗雑议性和可识别性的Speaker representation</li>
<li>results: 在VoxCeleb1测试集、外部噪声源和VOiCES corpus上进行了评估，实验结果表明，Diff-SV在噪声环境下达到了状态的前景性性能，超过了最新的噪声鲁棒SV系统<details>
<summary>Abstract</summary>
Background noise considerably reduces the accuracy and reliability of speaker verification (SV) systems. These challenges can be addressed using a speech enhancement system as a front-end module. Recently, diffusion probabilistic models (DPMs) have exhibited remarkable noise-compensation capabilities in the speech enhancement domain. Building on this success, we propose Diff-SV, a noise-robust SV framework that leverages DPM. Diff-SV unifies a DPM-based speech enhancement system with a speaker embedding extractor, and yields a discriminative and noise-tolerable speaker representation through a hierarchical structure. The proposed model was evaluated under both in-domain and out-of-domain noisy conditions using the VoxCeleb1 test set, an external noise source, and the VOiCES corpus. The obtained experimental results demonstrate that Diff-SV achieves state-of-the-art performance, outperforming recently proposed noise-robust SV systems.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>背景噪声会significantly reducethe accuracy和可靠性of speaker verification（SV）系统。这些挑战可以通过一个speech enhancement系统作为前端模块来解决。现在，diffusion probabilistic models（DPMs）在speech enhancement领域表现出了很好的噪声补偿能力。基于这种成功，我们提出了Diff-SV，一个具有噪声耐性的SV框架，利用DPM。Diff-SV将DPM-based speech enhancement系统与speaker embedding抽取器结合，通过层次结构实现一个可 dicriminative和噪声忍受的speaker表示。我们在VoxCeleb1测试集、外部噪声源和VOiCES corpus上进行了对Diff-SV的实验评估。实验结果表明，Diff-SV在噪声条件下实现了状态之arte的表现，比对最近提出的噪声耐性SV系统更高。
</details></li>
</ul>
<hr>
<h2 id="Emo-StarGAN-A-Semi-Supervised-Any-to-Many-Non-Parallel-Emotion-Preserving-Voice-Conversion"><a href="#Emo-StarGAN-A-Semi-Supervised-Any-to-Many-Non-Parallel-Emotion-Preserving-Voice-Conversion" class="headerlink" title="Emo-StarGAN: A Semi-Supervised Any-to-Many Non-Parallel Emotion-Preserving Voice Conversion"></a>Emo-StarGAN: A Semi-Supervised Any-to-Many Non-Parallel Emotion-Preserving Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07586">http://arxiv.org/abs/2309.07586</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suhitaghosh10/emo-stargan">https://github.com/suhitaghosh10/emo-stargan</a></li>
<li>paper_authors: Suhita Ghosh, Arnab Das, Yamini Sinha, Ingo Siegert, Tim Polzehl, Sebastian Stober</li>
<li>for: 防止听取数据的违用，保持语音内容的自然性。</li>
<li>methods: 使用 semi-supervised StarGANv2-VC 变体，在部分情感标注的非平行数据上进行训练，并使用情感嵌入和声学特征相关的情感损失函数。</li>
<li>results: 对比于标准 StarGANv2-VC，提出的方法可以显著改善情感保持，在多个数据集、情感、目标说话人和跨群交流中无需妥协 inteligibility 和匿名化。<details>
<summary>Abstract</summary>
Speech anonymisation prevents misuse of spoken data by removing any personal identifier while preserving at least linguistic content. However, emotion preservation is crucial for natural human-computer interaction. The well-known voice conversion technique StarGANv2-VC achieves anonymisation but fails to preserve emotion. This work presents an any-to-many semi-supervised StarGANv2-VC variant trained on partially emotion-labelled non-parallel data. We propose emotion-aware losses computed on the emotion embeddings and acoustic features correlated to emotion. Additionally, we use an emotion classifier to provide direct emotion supervision. Objective and subjective evaluations show that the proposed approach significantly improves emotion preservation over the vanilla StarGANv2-VC. This considerable improvement is seen over diverse datasets, emotions, target speakers, and inter-group conversions without compromising intelligibility and anonymisation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>发音匿名化可以防止使用口头数据的不当使用，同时保留至少的语言内容。然而，情感保留是人机交互的重要因素。知名的声音转换技术StarGANv2-VC可以实现匿名化，但是失去情感。本工作提出了任意到多个半监督StarGANv2-VC变体，通过部分情感标注不对称数据进行训练。我们提出了基于情感嵌入和听音特征相关的情感意识损失，以及直接提供情感标注。对象和主观评估表明，我们的方法可以明显改善情感保留，超过多种数据集、情感、目标说话人和交互转换等方面，无需妥协智能性和匿名化。
</details></li>
</ul>
<hr>
<h2 id="Outlier-aware-Inlier-Modeling-and-Multi-scale-Scoring-for-Anomalous-Sound-Detection-via-Multitask-Learning"><a href="#Outlier-aware-Inlier-Modeling-and-Multi-scale-Scoring-for-Anomalous-Sound-Detection-via-Multitask-Learning" class="headerlink" title="Outlier-aware Inlier Modeling and Multi-scale Scoring for Anomalous Sound Detection via Multitask Learning"></a>Outlier-aware Inlier Modeling and Multi-scale Scoring for Anomalous Sound Detection via Multitask Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07500">http://arxiv.org/abs/2309.07500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucong Zhang, Hongbin Suo, Yulong Wan, Ming Li<br>for: 这篇论文是为了检测异常声音而提出的方法，该方法利用多任务学习整合异常曝光和正常样本模型。methods: 该方法使用多任务学习整合异常曝光和正常样本模型，并提供多尺度得分来检测异常。results: 实验结果表明，该方法在MIMII和DCASE 2020任务2集合上的表现较为出色，超过了单个模型系统的状态卷积，并与多个系统组合 ensemble 的表现相当。<details>
<summary>Abstract</summary>
This paper proposes an approach for anomalous sound detection that incorporates outlier exposure and inlier modeling within a unified framework by multitask learning. While outlier exposure-based methods can extract features efficiently, it is not robust. Inlier modeling is good at generating robust features, but the features are not very effective. Recently, serial approaches are proposed to combine these two methods, but it still requires a separate training step for normal data modeling. To overcome these limitations, we use multitask learning to train a conformer-based encoder for outlier-aware inlier modeling. Moreover, our approach provides multi-scale scores for detecting anomalies. Experimental results on the MIMII and DCASE 2020 task 2 datasets show that our approach outperforms state-of-the-art single-model systems and achieves comparable results with top-ranked multi-system ensembles.
</details>
<details>
<summary>摘要</summary>
本文提出了一种异常声音检测方法，该方法包括外围曝光和内围模型在一个统一框架中，通过多任务学习。而外围曝光方法可以快速提取特征，但不是非常稳定。内围模型可以生成稳定的特征，但这些特征不是很有效。 reciently， serial approaches have been proposed to combine these two methods, but it still requires a separate training step for normal data modeling. To overcome these limitations, we use multitask learning to train a conformer-based encoder for outlier-aware inlier modeling. Moreover, our approach provides multi-scale scores for detecting anomalies. Experimental results on the MIMII and DCASE 2020 task 2 datasets show that our approach outperforms state-of-the-art single-model systems and achieves comparable results with top-ranked multi-system ensembles.Here's the translation of the text into Traditional Chinese:本文提出了一种异常声音检测方法，该方法包括外围曝光和内围模型在一个统一架构中，通过多任务学习。而外围曝光方法可以快速提取特征，但不是非常稳定。内围模型可以生成稳定的特征，但这些特征不是很有效。 reciently， serial approaches have been proposed to combine these two methods, but it still requires a separate training step for normal data modeling. To overcome these limitations, we use multitask learning to train a conformer-based encoder for outlier-aware inlier modeling. Moreover, our approach provides multi-scale scores for detecting anomalies. Experimental results on the MIMII and DCASE 2020 task 2 datasets show that our approach outperforms state-of-the-art single-model systems and achieves comparable results with top-ranked multi-system ensembles.
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Metadata-Information-Constrained-Self-Supervised-Learning-for-Anomalous-Sound-Detection-Under-Domain-Shift"><a href="#Hierarchical-Metadata-Information-Constrained-Self-Supervised-Learning-for-Anomalous-Sound-Detection-Under-Domain-Shift" class="headerlink" title="Hierarchical Metadata Information Constrained Self-Supervised Learning for Anomalous Sound Detection Under Domain Shift"></a>Hierarchical Metadata Information Constrained Self-Supervised Learning for Anomalous Sound Detection Under Domain Shift</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07498">http://arxiv.org/abs/2309.07498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyan Lan, Qiaoxi Zhu, Jian Guan, Yuming Wei, Wenwu Wang</li>
<li>for: 这篇论文是为了提高适应领域转移的异常声检测（ASD）表现。</li>
<li>methods: 这篇论文使用了自愿监督学习方法，并利用了阶层 metadata 信息作为条件，以获得更精确的特征表现。</li>
<li>results: 实验结果显示，该方法可以在 DCASE 2022 挑战任务2中提高自愿监督学习方法的表现。<details>
<summary>Abstract</summary>
Self-supervised learning methods have achieved promising performance for anomalous sound detection (ASD) under domain shift, where the type of domain shift is considered in feature learning by incorporating section IDs. However, the attributes accompanying audio files under each section, such as machine operating conditions and noise types, have not been considered, although they are also crucial for characterizing domain shifts. In this paper, we present a hierarchical metadata information constrained self-supervised (HMIC) ASD method, where the hierarchical relation between section IDs and attributes is constructed, and used as constraints to obtain finer feature representation. In addition, we propose an attribute-group-center (AGC)-based method for calculating the anomaly score under the domain shift condition. Experiments are performed to demonstrate its improved performance over the state-of-the-art self-supervised methods in DCASE 2022 challenge Task 2.
</details>
<details>
<summary>摘要</summary>
自我监督学习方法在域shift下的异常声音检测（ASD）中表现出了可塑性，通过在特征学习中包含部分ID来考虑域shift的类型。然而，音频文件中附加的特征，如机器操作条件和噪音类型，尚未被考虑，尽管它们也是域shift的关键特征。在本文中，我们提出了层次metadata信息受限自动学习（HMIC）ASD方法，其中层次关系 между部分ID和特征被建立，并用于限制特征表示的精度。此外，我们还提出了特征组中心（AGC）方法来计算域shift下的异常分数。我们对DCASE 2022挑战任务2进行实验，以证明其与现有自我监督方法的比较优异性。
</details></li>
</ul>
<hr>
<h2 id="Codec-Data-Augmentation-for-Time-domain-Heart-Sound-Classification"><a href="#Codec-Data-Augmentation-for-Time-domain-Heart-Sound-Classification" class="headerlink" title="Codec Data Augmentation for Time-domain Heart Sound Classification"></a>Codec Data Augmentation for Time-domain Heart Sound Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07466">http://arxiv.org/abs/2309.07466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ansh Mishra, Jia Qi Yip, Eng Siong Chng</li>
<li>for: 旨在检测心脏疾病的早期诊断，以挽救生命。</li>
<li>methods: 使用深度学习算法自动分类心音。</li>
<li>results: 通过数据增强，我们的方法可以提高分类错误率从0.8降低至0.2。<details>
<summary>Abstract</summary>
Heart auscultations are a low-cost and effective way of detecting valvular heart diseases early, which can save lives. Nevertheless, it has been difficult to scale this screening method since the effectiveness of auscultations is dependent on the skill of doctors. As such, there has been increasing research interest in the automatic classification of heart sounds using deep learning algorithms. However, it is currently difficult to develop good heart sound classification models due to the limited data available for training. In this work, we propose a simple time domain approach, to the heart sound classification problem with a base classification error rate of 0.8 and show that augmentation of the data through codec simulation can improve the classification error rate to 0.2. With data augmentation, our approach outperforms the existing time-domain CNN-BiLSTM baseline model. Critically, our experiments show that codec data augmentation is effective in getting around the data limitation.
</details>
<details>
<summary>摘要</summary>
心脏听见是一种低成本高效的早期检测心 valve 疾病的方法，可以拯救生命。然而，由于听见效果受医生技能的限制，因此听见检测方法具有扩展的挑战。随着深度学习算法在医疗领域的应用，研究人员开始关注自动 классификация心音的问题。然而，由于听见数据的有限性，目前难以建立好的心音分类模型。在这项工作中，我们提出了一种简单的时域预测方法，并证明了在基础错误率0.8的情况下，数据增强通过编码模拟可以下降分类错误率至0.2。与现有的时域CNN-BiLSTM基eline模型相比，我们的方法在数据增强情况下表现出了优异性。关键的是，我们的实验表明，编码数据增强是一种有效的绕过数据限制的方法。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Speech-Separation-Performance-Degradation-on-Emotional-Speech-Mixtures"><a href="#Analysis-of-Speech-Separation-Performance-Degradation-on-Emotional-Speech-Mixtures" class="headerlink" title="Analysis of Speech Separation Performance Degradation on Emotional Speech Mixtures"></a>Analysis of Speech Separation Performance Degradation on Emotional Speech Mixtures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07458">http://arxiv.org/abs/2309.07458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia Qi Yip, Dianwen Ng, Bin Ma, Chng Eng Siong</li>
<li>for: 这篇论文旨在研究 speech separation 中情感因素的影响。</li>
<li>methods: 该论文使用了 Sepformer 模型，并使用了 Emo2Mix 测试集来分析情感对 speech separation 的影响。</li>
<li>results: 研究发现，即使使用强大的 out-of-domain 表现的 Sepformer 模型，也可能会在带有强烈情感的杂音中受到5.1 dB SI-SDRi 的负面影响。这表明在实际应用中应该考虑情感因素。<details>
<summary>Abstract</summary>
Despite recent strides made in Speech Separation, most models are trained on datasets with neutral emotions. Emotional speech has been known to degrade performance of models in a variety of speech tasks, which reduces the effectiveness of these models when deployed in real-world scenarios. In this paper we perform analysis to differentiate the performance degradation arising from the emotions in speech from the impact of out-of-domain inference. This is measured using a carefully designed test dataset, Emo2Mix, consisting of balanced data across all emotional combinations. We show that even models with strong out-of-domain performance such as Sepformer can still suffer significant degradation of up to 5.1 dB SI-SDRi on mixtures with strong emotions. This demonstrates the importance of accounting for emotions in real-world speech separation applications.
</details>
<details>
<summary>摘要</summary>
尽管最近的Speech Separation模型在不同情感下进行训练，大多数模型仍然是在中性情感下训练的。情感味语会对各种语音任务中的模型性能产生负面影响，从而降低模型在真实世界应用中的有效性。在这篇论文中，我们进行了分析，以区分情感的影响和域外推理的影响。我们使用了一个特殊的测试集，Emo2Mix，这个测试集包含了所有情感组合的均衡数据。我们发现，即使是具有强域外推理能力的Sepformer模型，在强情感下也可能受到5.1 dB SI-SDRi的较大下降。这表明在真实世界中应用Speech Separation时，需要考虑情感的因素。
</details></li>
</ul>
<hr>
<h2 id="SpatialCodec-Neural-Spatial-Speech-Coding"><a href="#SpatialCodec-Neural-Spatial-Speech-Coding" class="headerlink" title="SpatialCodec: Neural Spatial Speech Coding"></a>SpatialCodec: Neural Spatial Speech Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07432">http://arxiv.org/abs/2309.07432</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzwy/spatialcodec">https://github.com/xzwy/spatialcodec</a></li>
<li>paper_authors: Zhongweiyang Xu, Yong Xu, Vinay Kothapally, Heming Wang, Muqiao Yang, Dong Yu</li>
<li>for: 本研究旨在使用深度学习技术对麦克风阵列捕获的语音编码，以保留和准确重建多通道记录中的关键空间信息。</li>
<li>methods: 我们提出了一个基于神经网络的 neural spatial audio coding 框架，其包括两个阶段：（i）使用神经网络子带码器对参照通道进行低比特率编码，并（ii）使用 SpatialCodec 捕获相对空间信息以实现准确多通道重建。</li>
<li>results: 我们的系统在比较高比特率基eline和黑盒神经网络架构下显示出了superior的空间性表现，同时我们还提出了一些新的评价指标来评估空间信息保留度，包括cosine similarity在 espacially intuitive beamspace 上的cosine similarity和 beamformed audio quality。<details>
<summary>Abstract</summary>
In this work, we address the challenge of encoding speech captured by a microphone array using deep learning techniques with the aim of preserving and accurately reconstructing crucial spatial cues embedded in multi-channel recordings. We propose a neural spatial audio coding framework that achieves a high compression ratio, leveraging single-channel neural sub-band codec and SpatialCodec. Our approach encompasses two phases: (i) a neural sub-band codec is designed to encode the reference channel with low bit rates, and (ii), a SpatialCodec captures relative spatial information for accurate multi-channel reconstruction at the decoder end. In addition, we also propose novel evaluation metrics to assess the spatial cue preservation: (i) spatial similarity, which calculates cosine similarity on a spatially intuitive beamspace, and (ii), beamformed audio quality. Our system shows superior spatial performance compared with high bitrate baselines and black-box neural architecture. Demos are available at https://xzwy.github.io/SpatialCodecDemo. Codes and models are available at https://github.com/XZWY/SpatialCodec.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们面临了一个挑战，即使用深度学习技术对麦克风阵列捕捉的speech进行编码，以保留和准确重建多通道录音中的关键空间特征。我们提出了一个含有两个阶段的神经空间音频编码框架，其中第一个阶段是使用单通道神经子带编码器对参考通道进行低比特率编码，第二个阶段是使用SpatialCodec捕捉相对空间信息以实现准确多通道重建。此外，我们还提出了一些新的评估指标来评估空间特征保留情况：（1）空间相似性，它计算顺序空间上的余弦相似性，以及（2）扩扩音质。我们的系统在比高比特率基eline和黑盒神经架下表现出了superior的空间性能。演示可以在https://xzwy.github.io/SpatialCodecDemo中找到。代码和模型可以在https://github.com/XZWY/SpatialCodec中找到。
</details></li>
</ul>
<hr>
<h2 id="Mandarin-Lombard-Flavor-Classification"><a href="#Mandarin-Lombard-Flavor-Classification" class="headerlink" title="Mandarin Lombard Flavor Classification"></a>Mandarin Lombard Flavor Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07419">http://arxiv.org/abs/2309.07419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingmu Liu, Yuhong Yang, Baifeng Li, Hongyang Chen, Weiping Tu, Song Lin</li>
<li>for:  investigate the impact of different decibel levels and types of background noise on the Lombard effect</li>
<li>methods:  used a flavor classification approach based on Mandarin Lombard speech under different noise conditions, simulated self-feedback speech, and statistical tests on word correct rates</li>
<li>results:  found four distinct categories of Mandarin Lombard speech in the range of 30 to 80 dBA with different transition points, depending on the type of background noise (SSN or babble)<details>
<summary>Abstract</summary>
The Lombard effect refers to individuals' unconscious modulation of vocal effort in response to variations in the ambient noise levels, intending to enhance speech intelligibility. The impact of different decibel levels and types of background noise on Lombard effects remains unclear. Building upon the characteristic of Lombard speech that individuals adjust their speech to improve intelligibility dynamically based on the self-feedback speech, we propose a flavor classification approach for the Lombard effect. We first collected Mandarin Lombard speech under different noise conditions, then simulated self-feedback speech, and ultimately conducted the statistical test on the word correct rate. We found that both SSN and babble noise types result in four distinct categories of Mandarin Lombard speech in the range of 30 to 80 dBA with different transition points.
</details>
<details>
<summary>摘要</summary>
“卢柏尔效应”指个体在噪声水平变化时，无意识地调整语音努力，以提高对话理解度。噪声强度和类型对卢柏尔效应的影响仍不清楚。基于卢柏尔语言特征，我们提出了一种味道分类方法。我们首先收集了不同噪声条件下的普通话 Lombard 语音，然后模拟自适应语音，并进行统计测试。我们发现，SSN 和喧嚣噪声类型都导致了4种不同的普通话 Lombard 语音，分别在30到80 dBA 的范围内，每个转变点都有不同。
</details></li>
</ul>
<hr>
<h2 id="M3-AUDIODEC-Multi-channel-multi-speaker-multi-spatial-audio-codec"><a href="#M3-AUDIODEC-Multi-channel-multi-speaker-multi-spatial-audio-codec" class="headerlink" title="M3-AUDIODEC: Multi-channel multi-speaker multi-spatial audio codec"></a>M3-AUDIODEC: Multi-channel multi-speaker multi-spatial audio codec</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07416">http://arxiv.org/abs/2309.07416</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anton-jeran/MULTI-AUDIODEC">https://github.com/anton-jeran/MULTI-AUDIODEC</a></li>
<li>paper_authors: Anton Ratnarajah, Shi-Xiong Zhang, Yi Luo, Dong Yu<br>for: 这个论文是为了提出一种基于神经网络的多通道语音编码器，可以有效地压缩多个说话人的多通道语音，同时保留每个说话人的空间位置信息。methods: 该模型使用了一种新的嵌入式推理方法，可以根据预先确定的多通道、多说话人和多空间重叠说话情况进行配置和训练。results: 该模型可以压缩和解码重叠说话的语音，并且可以在12.6 kbps的操作下，比Opus和AUDIODEC的24 kbps操作提高37%和52%。此外，该模型还可以在不同的语音增强和房间响应度下保持清晰的语音和空间位置信息。<details>
<summary>Abstract</summary>
We introduce M3-AUDIODEC, an innovative neural spatial audio codec designed for efficient compression of multi-channel (binaural) speech in both single and multi-speaker scenarios, while retaining the spatial location information of each speaker. This model boasts versatility, allowing configuration and training tailored to a predetermined set of multi-channel, multi-speaker, and multi-spatial overlapping speech conditions. Key contributions are as follows: 1) Previous neural codecs are extended from single to multi-channel audios. 2) The ability of our proposed model to compress and decode for overlapping speech. 3) A groundbreaking architecture that compresses speech content and spatial cues separately, ensuring the preservation of each speaker's spatial context after decoding. 4) M3-AUDIODEC's proficiency in reducing the bandwidth for compressing two-channel speech by 48% when compared to individual binaural channel compression. Impressively, at a 12.6 kbps operation, it outperforms Opus at 24 kbps and AUDIODEC at 24 kbps by 37% and 52%, respectively. In our assessment, we employed speech enhancement and room acoustic metrics to ascertain the accuracy of clean speech and spatial cue estimates from M3-AUDIODEC. Audio demonstrations and source code are available online https://github.com/anton-jeran/MULTI-AUDIODEC .
</details>
<details>
<summary>摘要</summary>
我们介绍M3-AUDIODEC，一种创新的神经网络声音编码器，用于高效压缩多通道（频率分量）的语音，包括单个和多个说话人场景，而且保留每个说话人的空间位置信息。这个模型具有灵活性，可以根据预先确定的多通道、多个说话人和多个空间重叠情况进行配置和训练。关键贡献包括：1. 扩展了单通道声音编码器到多通道声音。2. 能够压缩和解码重叠的语音。3. 采用独特的架构，将语音内容和空间cue分开压缩，以保持每个说话人的空间上下文 после decoding。4. M3-AUDIODEC 能够减少压缩两通道语音的带宽，比对个频道压缩减少48%。在12.6 kbps操作下，它超越了 Opus 和 AUDIODEC 的24 kbps操作，提高了37%和52%。在我们的评估中，我们使用了语音提升和房间声学指标来评估M3-AUDIODEC 中干净语音和空间cue的准确性。在线可以找到音频示例和源代码，请参阅https://github.com/anton-jeran/MULTI-AUDIODEC。
</details></li>
</ul>
<hr>
<h2 id="Multi-dimensional-Speech-Quality-Assessment-in-Crowdsourcing"><a href="#Multi-dimensional-Speech-Quality-Assessment-in-Crowdsourcing" class="headerlink" title="Multi-dimensional Speech Quality Assessment in Crowdsourcing"></a>Multi-dimensional Speech Quality Assessment in Crowdsourcing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07385">http://arxiv.org/abs/2309.07385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/P.808">https://github.com/microsoft/P.808</a></li>
<li>paper_authors: Babak Naderi, Ross Cutler, Nicolae-Catalin Ristea</li>
<li>For: The paper is written to evaluate the subjective speech quality assessment in lab environments and crowdsourcing, and to extend the ITU-T Rec. P.800 and P.808 standards to measure speech quality in the presence of noise and reverberation.* Methods: The paper uses a crowdsourcing implementation of a multi-dimensional subjective test following the scales from P.804, which includes noisiness, coloration, discontinuity, loudness, and overall quality. The tool is both accurate and reproducible, and has been used in the ICASSP 2023 Speech Signal Improvement challenge.* Results: The paper shows the utility of these speech quality dimensions in the challenge and demonstrates the accuracy and reproducibility of the tool. The tool will be publicly available as open-source at <a target="_blank" rel="noopener" href="https://github.com/microsoft/P.808.Here">https://github.com/microsoft/P.808.Here</a> is the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是用来评估声音质量评估和电信系统的标准方法。</li>
<li>methods: 这篇论文使用了一种多维ensional的主观测试，以ITU-TRec. P.804的标准进行评估，包括噪音、颜色、缺失、响度等主观质量维度。</li>
<li>results: 这篇论文在ICASSP 2023 Speech Signal Improvement challenge中展示了这些声音质量维度的实用性，并证明了这种工具的准确性和可重复性。<details>
<summary>Abstract</summary>
Subjective speech quality assessment is the gold standard for evaluating speech enhancement processing and telecommunication systems. The commonly used standard ITU-T Rec. P.800 defines how to measure speech quality in lab environments, and ITU-T Rec.~P.808 extended it for crowdsourcing. ITU-T Rec. P.835 extends P.800 to measure the quality of speech in the presence of noise. ITU-T Rec. P.804 targets the conversation test and introduces perceptual speech quality dimensions which are measured during the listening phase of the conversation. The perceptual dimensions are noisiness, coloration, discontinuity, and loudness. We create a crowdsourcing implementation of a multi-dimensional subjective test following the scales from P.804 and extend it to include reverberation, the speech signal, and overall quality. We show the tool is both accurate and reproducible. The tool has been used in the ICASSP 2023 Speech Signal Improvement challenge and we show the utility of these speech quality dimensions in this challenge. The tool will be publicly available as open-source at https://github.com/microsoft/P.808.
</details>
<details>
<summary>摘要</summary>
主观语音质量评估是评估语音增强处理和电信系统的金标准。常用的标准ITU-T Rec. P.800定义了如何测量语音质量在室内环境中，而ITU-T Rec. P.808将其扩展到了投票。ITU-T Rec. P.835将P.800扩展到测量噪音中的语音质量。ITU-T Rec. P.804targets conversation test和引入了感知语音质量维度，这些维度在听话阶段测量。这些感知维度包括噪音、颜色、破碎、和响度。我们创建了一个基于多维ensional主观测试的人群投票实现，并将其扩展到包括噪音、语音信号和总质量。我们显示了这个工具的准确性和可重复性。这个工具在ICASSP 2023 Speech Signal Improvement challenge中被使用，并示出了这些语音质量维度的实用性。这个工具将于https://github.com/microsoft/P.808上公开发布为开源项目。
</details></li>
</ul>
<hr>
<h2 id="Towards-Universal-Speech-Discrete-Tokens-A-Case-Study-for-ASR-and-TTS"><a href="#Towards-Universal-Speech-Discrete-Tokens-A-Case-Study-for-ASR-and-TTS" class="headerlink" title="Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS"></a>Towards Universal Speech Discrete Tokens: A Case Study for ASR and TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07377">http://arxiv.org/abs/2309.07377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k2-fsa/icefall">https://github.com/k2-fsa/icefall</a></li>
<li>paper_authors: Yifan Yang, Feiyu Shen, Chenpeng Du, Ziyang Ma, Kai Yu, Daniel Povey, Xie Chen</li>
<li>for: 本研究旨在比较和优化不同自动学习模型生成的speech相关任务中的精炼度数据，以探讨这些数据在多种speech任务中的 universality。</li>
<li>methods: 本研究使用了多种主流自动学习模型生成的精炼度数据，包括Speech-to-Text和Text-to-Speech两个任务。我们通过对这些数据进行比较和优化来探讨它们在不同的speech任务中的效果。</li>
<li>results: 实验结果表明，使用精炼度数据可以在speech认知任务中实现相当于FBank特征的性能，而且在speech合成任务中，使用精炼度数据可以超过mel-spectrogram特征的性能。这些发现表明了精炼度数据在多种speech任务中的可 reuse 性和可靠性。<details>
<summary>Abstract</summary>
Self-supervised learning (SSL) proficiency in speech-related tasks has driven research into utilizing discrete tokens for speech tasks like recognition and translation, which offer lower storage requirements and great potential to employ natural language processing techniques. However, these studies, mainly single-task focused, faced challenges like overfitting and performance degradation in speech recognition tasks, often at the cost of sacrificing performance in multi-task scenarios. This study presents a comprehensive comparison and optimization of discrete tokens generated by various leading SSL models in speech recognition and synthesis tasks. We aim to explore the universality of speech discrete tokens across multiple speech tasks. Experimental results demonstrate that discrete tokens achieve comparable results against systems trained on FBank features in speech recognition tasks and outperform mel-spectrogram features in speech synthesis in subjective and objective metrics. These findings suggest that universal discrete tokens have enormous potential in various speech-related tasks. Our work is open-source and publicly available to facilitate research in this direction.
</details>
<details>
<summary>摘要</summary>
自我监督学习（SSL）在语音相关任务中的能力已经推动了研究人员使用分割符进行语音任务，如识别和翻译，这些任务的存储要求较低，并且可以使用自然语言处理技术。然而，这些研究主要是单任务受注重，面临过拟合和多任务场景中的性能下降的挑战。本研究对各种领先SSL模型生成的分割符进行了全面的比较和优化，以探讨语音分割符的通用性。我们希望通过这些实验来探索语音分割符在多种语音任务中的可行性。实验结果表明，分割符在语音识别任务中与基于FBank特征学习系统相当，而在语音合成任务中，分割符在主观和客观指标中表现出色。这些发现表明，通用的语音分割符在多种语音任务中具有极大的潜力。我们的工作是开源的，以便促进这一方向的研究。
</details></li>
</ul>
<hr>
<h2 id="Training-Audio-Captioning-Models-without-Audio"><a href="#Training-Audio-Captioning-Models-without-Audio" class="headerlink" title="Training Audio Captioning Models without Audio"></a>Training Audio Captioning Models without Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07372">http://arxiv.org/abs/2309.07372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/noaudiocaptioning">https://github.com/microsoft/noaudiocaptioning</a></li>
<li>paper_authors: Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, Huaming Wang</li>
<li>for: 本研究旨在解决自动Audio Captioning（AAC）系统的训练数据稀缺问题，提出一种使用仅文本训练AAC系统的方法。</li>
<li>methods: 本方法利用了对比式训练的音频-文本模型，如CLAP，来生成音频描述。在训练过程中，一个解码器使用预训练CLAP文本Encoder生成caption。在推理过程中，文本Encoder被替换为预训练CLAP音频Encoder。为bridging模态间的差距，我们提议在训练过程中使用噪声注入或学习 adapter。</li>
<li>results: 我们的文本只框架与状态对的模型相比，在无需音频或人工创建的文本描述时显示了竞争力。此外，我们还展示了在训练过程中不使用音频或人工创建的文本描述时实现了样式化音频描述和描述增强。<details>
<summary>Abstract</summary>
Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.
</details>
<details>
<summary>摘要</summary>
自动化语音描述（AAC）是将语音流转换为自然语言描述的任务。一个典型的AAC系统需要手动撰写的音频段和相应的文本描述标注。创建这些音频-描述对的成本高，导致AAC数据的总量匮乏。在这种情况下，我们提出了一种方法，使用仅文本进行AAC系统的训练。我们的方法利用了对比训练的音频-文本模型，如CLAP，来生成描述。在训练中，一个解码器根据预训练CLAP文本Encoder生成描述。在推理中，文本Encoder被替换为预训练CLAP音频Encoder。为了跨Modal空间的减少，我们提议在训练时使用噪声注入或学习适配器。我们发现，我们的文本仅框架与状态流行的模型相比，表现相对竞争力强。最后，我们展示了在没有音频或人工创建的文本描述时进行风格化音频描述和描述增强。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/cs.SD_2023_09_14/" data-id="clohum9c100v2pj88gw898gtj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/cs.CV_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T13:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/cs.CV_2023_09_14/">cs.CV - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Morphologically-Aware-Consensus-Computation-via-Heuristics-based-IterATive-Optimization-MACCHIatO"><a href="#Morphologically-Aware-Consensus-Computation-via-Heuristics-based-IterATive-Optimization-MACCHIatO" class="headerlink" title="Morphologically-Aware Consensus Computation via Heuristics-based IterATive Optimization (MACCHIatO)"></a>Morphologically-Aware Consensus Computation via Heuristics-based IterATive Optimization (MACCHIatO)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08066">http://arxiv.org/abs/2309.08066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitri Hamzaoui, Sarah Montagne, Raphaële Renard-Penna, Nicholas Ayache, Hervé Delingette</li>
<li>for: 本研究旨在提供一种独立于图像背景大小和选择函数的方法，以获得协调多个评分人的投票结果。</li>
<li>methods: 我们提议使用Fréchet平均 distances来构建一个 binary或概率的协调分割，并提供了一种启发式方法来优化这个标准。</li>
<li>results: 我们对多个数据集进行了广泛的比较，并证明了我们的方法与STAPLE方法和简单的投票均值方法相比，能够得到中间大小的 binary consensus mask，以及不同于Mask Averaging和STAPLE方法的 posterior probabilities。<details>
<summary>Abstract</summary>
The extraction of consensus segmentations from several binary or probabilistic masks is important to solve various tasks such as the analysis of inter-rater variability or the fusion of several neural network outputs. One of the most widely used methods to obtain such a consensus segmentation is the STAPLE algorithm. In this paper, we first demonstrate that the output of that algorithm is heavily impacted by the background size of images and the choice of the prior. We then propose a new method to construct a binary or a probabilistic consensus segmentation based on the Fr\'{e}chet means of carefully chosen distances which makes it totally independent of the image background size. We provide a heuristic approach to optimize this criterion such that a voxel's class is fully determined by its voxel-wise distance to the different masks, the connected component it belongs to and the group of raters who segmented it. We compared extensively our method on several datasets with the STAPLE method and the naive segmentation averaging method, showing that it leads to binary consensus masks of intermediate size between Majority Voting and STAPLE and to different posterior probabilities than Mask Averaging and STAPLE methods. Our code is available at https://gitlab.inria.fr/dhamzaou/jaccardmap .
</details>
<details>
<summary>摘要</summary>
抽取多个二进制或概率性掩模的consensus分割是解决多种任务的关键，如分析间读者差异或神经网络输出的融合。STAPLE算法是最常用的方法获得consensus分割。在这篇论文中，我们首先表明STAPLE算法的输出受到图像背景大小和选择前景的影响。然后，我们提出一种新的方法，基于Fréchet平均 distances，构建二进制或概率性consensus分割，不受图像背景大小的影响。我们提供了一个启发式方法优化这个标准，使每个壳体的类别完全由它与不同掩模的 voxel-wise 距离、所属连通分支和掩模 raters 的分类决定。我们对多个数据集进行了广泛的比较，表明我们的方法与STAPLE方法和naive掩模平均方法不同，并且导致二进制consensus掩模和不同的 posterior probabilities。我们的代码可以在https://gitlab.inria.fr/dhamzaou/jaccardmap 上获取。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-Aware-Vision-Transformer"><a href="#Interpretability-Aware-Vision-Transformer" class="headerlink" title="Interpretability-Aware Vision Transformer"></a>Interpretability-Aware Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08035">http://arxiv.org/abs/2309.08035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiangyao1988/ia-vit">https://github.com/qiangyao1988/ia-vit</a></li>
<li>paper_authors: Yao Qiang, Chengyin Li, Prashant Khanduri, Dongxiao Zhu</li>
<li>for: 解释模型性能和解释模型含义</li>
<li>methods: 提出了一种新的培育方法，即具有解释性的培育方法，该方法通过自我注意机制提供了 faithful的解释</li>
<li>results: 在多个图像分类任务中表现出色，并进行了质量和量化的评估Here is the summary in English:</li>
<li>for: Explaining model performance and model interpretability</li>
<li>methods: Proposed a new training method that inherently enhances model interpretability, which uses a self-attention mechanism to provide faithful explanations</li>
<li>results: Performed excellently in multiple image classification tasks, with both qualitative and quantitative evaluations of model performance and interpretability.<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have become prominent models for solving various vision tasks. However, the interpretability of ViTs has not kept pace with their promising performance. While there has been a surge of interest in developing {\it post hoc} solutions to explain ViTs' outputs, these methods do not generalize to different downstream tasks and various transformer architectures. Furthermore, if ViTs are not properly trained with the given data and do not prioritize the region of interest, the {\it post hoc} methods would be less effective. Instead of developing another {\it post hoc} approach, we introduce a novel training procedure that inherently enhances model interpretability. Our interpretability-aware ViT (IA-ViT) draws inspiration from a fresh insight: both the class patch and image patches consistently generate predicted distributions and attention maps. IA-ViT is composed of a feature extractor, a predictor, and an interpreter, which are trained jointly with an interpretability-aware training objective. Consequently, the interpreter simulates the behavior of the predictor and provides a faithful explanation through its single-head self-attention mechanism. Our comprehensive experimental results demonstrate the effectiveness of IA-ViT in several image classification tasks, with both qualitative and quantitative evaluations of model performance and interpretability. Source code is available from: https://github.com/qiangyao1988/IA-ViT.
</details>
<details>
<summary>摘要</summary>
目标是解释具有优秀表现的视Transformers（ViTs）模型的含义。然而，解释ViTs的性能未能与其表现相提并且。尽管有一波关注开发{\it post hoc}解释ViTs输出的方法，但这些方法不一致于不同的下游任务和多种变换器架构。此外，如果ViTs没有正确地训练与给定数据并不着眼于区域关注点，那么{\it post hoc}方法就会变得效果更差。相反，我们介绍了一种新的训练方法，可以自然地提高模型解释性。我们的解释具有ViT（IA-ViT）启发自新的见解： Both the class patch和image patches consistently generate predicted distributions and attention maps。IA-ViT包括一个特征提取器、一个预测器和一个解释器，这些部分在一起被训练了一个解释性感知训练目标。因此，解释器可以模拟预测器的行为，并通过其单头自注意机制提供 faithful的解释。我们的实验结果表明IA-ViT在多个图像分类任务中具有优秀的性能和解释性。代码可以从以下链接获取：https://github.com/qiangyao1988/IA-ViT。
</details></li>
</ul>
<hr>
<h2 id="Depth-Estimation-from-a-Single-Optical-Encoded-Image-using-a-Learned-Colored-Coded-Aperture"><a href="#Depth-Estimation-from-a-Single-Optical-Encoded-Image-using-a-Learned-Colored-Coded-Aperture" class="headerlink" title="Depth Estimation from a Single Optical Encoded Image using a Learned Colored-Coded Aperture"></a>Depth Estimation from a Single Optical Encoded Image using a Learned Colored-Coded Aperture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08033">http://arxiv.org/abs/2309.08033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jhon Lopez, Edwin Vargas, Henry Arguello</li>
<li>for: 本研究旨在提高单张照片中的深度估计，通过在镜头缝中引入多种颜色滤波器，以便在不同深度下生成不同的滤波Pattern，从而提高不同深度之间的差异。</li>
<li>methods: 本研究使用了色码镜头（CCA），并通过结合深度学习来设计Diffractive Optical Element（DOE），以便在单张照片中提取深度信息。</li>
<li>results: 通过三个不同的数据集进行了多种实验，并证明了该方法可以更好地估计深度，并且在实际场景中进行了实验，证明了该方法的可行性。<details>
<summary>Abstract</summary>
Depth estimation from a single image of a conventional camera is a challenging task since depth cues are lost during the acquisition process. State-of-the-art approaches improve the discrimination between different depths by introducing a binary-coded aperture (CA) in the lens aperture that generates different coded blur patterns at different depths. Color-coded apertures (CCA) can also produce color misalignment in the captured image which can be utilized to estimate disparity. Leveraging advances in deep learning, more recent works have explored the data-driven design of a diffractive optical element (DOE) for encoding depth information through chromatic aberrations. However, compared with binary CA or CCA, DOEs are more expensive to fabricate and require high-precision devices. Different from previous CCA-based approaches that employ few basic colors, in this work we propose a CCA with a greater number of color filters and richer spectral information to optically encode relevant depth information in a single snapshot. Furthermore, we propose to jointly learn the color-coded aperture (CCA) pattern and a convolutional neural network (CNN) to retrieve depth information by using an end-to-end optimization approach. We demonstrate through different experiments on three different data sets that the designed color-encoding has the potential to remove depth ambiguities and provides better depth estimates compared to state-of-the-art approaches. Additionally, we build a low-cost prototype of our CCA using a photographic film and validate the proposed approach in real scenarios.
</details>
<details>
<summary>摘要</summary>
摄像机器一张图像深度估计是一项具有挑战性的任务，因为深度指示器在捕获过程中消失。现有的方法可以通过在镜头孔中引入二进制编码的眼镜（CA）或多色编码眼镜（CCA）来提高不同深度之间的区分。CCA可以在捕获图像中产生颜色偏移，并可以用于估计分辨率。通过深度学习的进步，更新的工作将Diffractive optical element（DOE）用于编码深度信息的数据驱动设计。然而，相比于二进制CA或CCA，DOE需要更高精度的设备并且更加昂贵。与前期CCA-based方法不同，我们在本工作中提议使用更多的颜色筛和更丰富的光谱信息来optically编码相关的深度信息。此外，我们还提议通过结合CCA筛和 convolutional neural network（CNN）的结构学习来learns depth information。通过不同的实验在三个不同的数据集上，我们表明了设计的颜色编码具有除去深度歧义的潜力，并且提供了与当前状态对比而言更好的深度估计。此外，我们还建立了一个低成本的CCA原型，使用摄影材料和 validate了我们的提议。
</details></li>
</ul>
<hr>
<h2 id="Empowering-Visually-Impaired-Individuals-A-Novel-Use-of-Apple-Live-Photos-and-Android-Motion-Photos"><a href="#Empowering-Visually-Impaired-Individuals-A-Novel-Use-of-Apple-Live-Photos-and-Android-Motion-Photos" class="headerlink" title="Empowering Visually Impaired Individuals: A Novel Use of Apple Live Photos and Android Motion Photos"></a>Empowering Visually Impaired Individuals: A Novel Use of Apple Live Photos and Android Motion Photos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08022">http://arxiv.org/abs/2309.08022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedalireza Khoshsirat, Chandra Kambhamettu</li>
<li>for: 这个论文旨在探讨使用Apple Live Photos和Android Motion Photos技术来改善视力障碍者使用机器学习模型处理视觉输入的问题。</li>
<li>methods: 该论文使用了一种简单的方法来评估和比较Live Photos和Motion Photos对于传统图像基本输入方法的效果。</li>
<li>results: 研究发现Live Photos和Motion Photos在常见的视觉助手任务中比单框图像表现更好，尤其是在物体分类和视频问答中。研究还进行了一系列的减少效果和更长的时间范围的实验来深入探讨这些技术的影响。<details>
<summary>Abstract</summary>
Numerous applications have been developed to assist visually impaired individuals that employ a machine learning unit to process visual input. However, a critical challenge with these applications is the sub-optimal quality of images captured by the users. Given the complexity of operating a camera for visually impaired individuals, we advocate for the use of Apple Live Photos and Android Motion Photos technologies. In this study, we introduce a straightforward methodology to evaluate and contrast the efficacy of Live/Motion Photos against traditional image-based approaches. Our findings reveal that both Live Photos and Motion Photos outperform single-frame images in common visual assisting tasks, specifically in object classification and VideoQA. We validate our results through extensive experiments on the ORBIT dataset, which consists of videos collected by visually impaired individuals. Furthermore, we conduct a series of ablation studies to delve deeper into the impact of deblurring and longer temporal crops.
</details>
<details>
<summary>摘要</summary>
很多应用程序已经开发以帮助视障人群，这些应用程序使用机器学习单元处理视觉输入。然而，这些应用程序的一个挑战是用户拍摄的图像质量不够优化。为了解决这个问题，我们建议使用苹果Live Photos和Android Motion Photos技术。在这项研究中，我们提出了一种简单的方法来评估和比较Live/Motion Photos与传统图像基于的方法的效果。我们的发现表明，Live Photos和Motion Photos在常见的视觉协助任务中都能够超越单帧图像，具体来说是在物体分类和VideoQA中。我们通过对ORBIT dataset进行了广泛的实验来验证我们的结果。此外，我们还进行了一系列的剥夺研究，以 deeper 探究延迟和更长的时间割辑的影响。
</details></li>
</ul>
<hr>
<h2 id="Temporal-aware-Hierarchical-Mask-Classification-for-Video-Semantic-Segmentation"><a href="#Temporal-aware-Hierarchical-Mask-Classification-for-Video-Semantic-Segmentation" class="headerlink" title="Temporal-aware Hierarchical Mask Classification for Video Semantic Segmentation"></a>Temporal-aware Hierarchical Mask Classification for Video Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08020">http://arxiv.org/abs/2309.08020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaochongan/the-mask">https://github.com/zhaochongan/the-mask</a></li>
<li>paper_authors: Zhaochong An, Guolei Sun, Zongwei Wu, Hao Tang, Luc Van Gool</li>
<li>for: 提高视频 semantic segmentation（VSS）的表现，增加表达能力。</li>
<li>methods: 引入时间感知层次对象查询，并使用简单的两轮匹配机制，以及层次损失来训练查询。</li>
<li>results: 在最新的VSS测试集VSPW上达到了状态数表现，无需额外设备或特性。<details>
<summary>Abstract</summary>
Modern approaches have proved the huge potential of addressing semantic segmentation as a mask classification task which is widely used in instance-level segmentation. This paradigm trains models by assigning part of object queries to ground truths via conventional one-to-one matching. However, we observe that the popular video semantic segmentation (VSS) dataset has limited categories per video, meaning less than 10% of queries could be matched to receive meaningful gradient updates during VSS training. This inefficiency limits the full expressive potential of all queries.Thus, we present a novel solution THE-Mask for VSS, which introduces temporal-aware hierarchical object queries for the first time. Specifically, we propose to use a simple two-round matching mechanism to involve more queries matched with minimal cost during training while without any extra cost during inference. To support our more-to-one assignment, in terms of the matching results, we further design a hierarchical loss to train queries with their corresponding hierarchy of primary or secondary. Moreover, to effectively capture temporal information across frames, we propose a temporal aggregation decoder that fits seamlessly into the mask-classification paradigm for VSS. Utilizing temporal-sensitive multi-level queries, our method achieves state-of-the-art performance on the latest challenging VSS benchmark VSPW without bells and whistles.
</details>
<details>
<summary>摘要</summary>
现代方法已经证明了地址 semantic segmentation 作为一个Mask classification task的巨大潜力，这种思想广泛用于实例级别 segmentation。这种思想通过一般的一对一匹配来训练模型，但我们发现VSS数据集中的视频Semantic segmentation（VSS）中的类别数量很少，这意味着只有少于10%的查询可以得到有意义的梯度更新 durante la formación de VSS。这种不灵活性限制了所有查询的全面表达潜力。因此，我们提出了一种新的解决方案called THE-Mask for VSS，它是在VSS中首次引入了时间感知层次对象查询。具体来说，我们提议使用一个简单的两轮匹配机制，以便更多的查询在训练中得到匹配，而无需在推理过程中添加额外的成本。此外，为了支持我们的更多对一匹配，我们还设计了一个层次损失来训练查询和它们所对应的层次结构。此外，为了有效地捕捉视频帧之间的时间信息，我们提出了一种适应 temporal 的汇集解码器，这种解码器适应 VSS 中的 mask 分类思想。通过使用时间感知的多级查询，我们的方法在最新的 VSPW 测试 benchmark 上实现了状态机器的性能，不需要额外的辅助工具。
</details></li>
</ul>
<hr>
<h2 id="Measuring-the-Quality-of-Text-to-Video-Model-Outputs-Metrics-and-Dataset"><a href="#Measuring-the-Quality-of-Text-to-Video-Model-Outputs-Metrics-and-Dataset" class="headerlink" title="Measuring the Quality of Text-to-Video Model Outputs: Metrics and Dataset"></a>Measuring the Quality of Text-to-Video Model Outputs: Metrics and Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08009">http://arxiv.org/abs/2309.08009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iya Chivileva, Philip Lynch, Tomas E. Ward, Alan F. Smeaton</li>
<li>for: 评估文本到视频（T2V）模型生成的视频质量是重要的，以确保生成的输出能够诱导观众接受其真实性。</li>
<li>methods: 文章分析了一些常用的评估metric，并指出它们的局限性。文章还提供了5种最新的T2V模型生成的视频数据集，并应用了一些常用的评估metric。</li>
<li>results: 研究发现，自然性和文本提示使用的semantic匹配是评估T2V模型输出质量的重要因素，但没有单一的度量可以捕捉这些细节。<details>
<summary>Abstract</summary>
Evaluating the quality of videos generated from text-to-video (T2V) models is important if they are to produce plausible outputs that convince a viewer of their authenticity. We examine some of the metrics used in this area and highlight their limitations. The paper presents a dataset of more than 1,000 generated videos from 5 very recent T2V models on which some of those commonly used quality metrics are applied. We also include extensive human quality evaluations on those videos, allowing the relative strengths and weaknesses of metrics, including human assessment, to be compared. The contribution is an assessment of commonly used quality metrics, and a comparison of their performances and the performance of human evaluations on an open dataset of T2V videos. Our conclusion is that naturalness and semantic matching with the text prompt used to generate the T2V output are important but there is no single measure to capture these subtleties in assessing T2V model output.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:evaluating the quality of text-to-video（T2V）模型生成的视频是非常重要的，以确保它们生成的输出是真实可信的。我们检查了这个领域中一些常用的度量，并指出它们的局限性。文章发布了一个包含1000多个由5种最新T2V模型生成的视频的数据集，并在这些视频上应用了一些常用的度量。此外，我们还进行了详细的人类评估这些视频，以便比较度量的表现和人类评估的表现。我们的结论是，自然性和文本提示使用的含义匹配是非常重要的，但没有单一的度量可以捕捉这些细节。
</details></li>
</ul>
<hr>
<h2 id="Kinship-Verification-from-rPPG-using-1DCNN-Attention-networks"><a href="#Kinship-Verification-from-rPPG-using-1DCNN-Attention-networks" class="headerlink" title="Kinship Verification from rPPG using 1DCNN Attention networks"></a>Kinship Verification from rPPG using 1DCNN Attention networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08006">http://arxiv.org/abs/2309.08006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoting Wu, Xiaoyi Feng, Lili Liu, Constantino Álvarez Casado, Miguel Bordallo López</li>
<li>for: 这 paper 旨在使用 remote Photoplethysmography (rPPG) 信号来验证人们之间的亲属关系。</li>
<li>methods: 这 paper 提出了一种使用一维 Convolutional Neural Network (1DCNN) 和 contrastive loss 来学习从 rPPG 信号中提取的亲属相似性。</li>
<li>results: 这 paper 在 UvANEMO Smile Database 上对不同的亲属关系进行评估，并显示了 rPPG 信号在验证亲属关系方面的有用性。<details>
<summary>Abstract</summary>
Facial kinship verification aims at automatically determining whether two subjects have a kinship relation. It has been widely studied from different modalities, such as faces, voices, gait, and smiling expressions. However, the potential of bio-signals, such as remote Photoplethysmography (rPPG) extracted from facial videos, remains largely unexplored in the kinship verification problem. In this paper, we investigate for the first time the usage of the rPPG signal for kinship verification. Specifically, we proposed a one-dimensional Convolutional Neural Network (1DCNN) with a 1DCNN-Attention module and contrastive loss to learn the kinship similarity from rPPGs. The network takes multiple rPPG signals extracted from various facial Regions of Interest (ROIs) as inputs. Additionally, the 1DCNN attention module is designed to learn and capture the discriminative kin features from feature embeddings. Finally, the proposed method is evaluated on the UvANEMO Smile Database from different kin relations, showing the usefulness of rPPG signals in verifying kinship.
</details>
<details>
<summary>摘要</summary>
facial kinship verification aimed at automatically determining whether two subjects have a kinship relationship. It has been widely studied from different modalities, such as faces, voices, gait, and smiling expressions. However, the potential of bio-signals, such as remote Photoplethysmography (rPPG) extracted from facial videos, remains largely unexplored in the kinship verification problem. In this paper, we investigate for the first time the usage of the rPPG signal for kinship verification. Specifically, we proposed a one-dimensional Convolutional Neural Network (1DCNN) with a 1DCNN-Attention module and contrastive loss to learn the kinship similarity from rPPGs. The network takes multiple rPPG signals extracted from various facial Regions of Interest (ROIs) as inputs. Additionally, the 1DCNN attention module is designed to learn and capture the discriminative kin features from feature embeddings. Finally, the proposed method is evaluated on the UvANEMO Smile Database from different kin relations, showing the usefulness of rPPG signals in verifying kinship.Here's the word-for-word translation:面部亲属验证旨在自动确定两个主题是否有亲属关系。从不同的modalities来研究，如面部、声音、走势和笑容表达。然而，远程光谱 Plethysmography（rPPG）从视频中提取的生物信号的潜在用于亲属验证问题仍未得到了广泛的利用。在这篇文章中，我们为首次利用rPPG信号进行亲属验证。我们提出了一个一维Convolutional Neural Network（1DCNN）以及1DCNN注意模块和对比损失来学习 Kinship similarity from rPPGs。网络接受多个从不同的面部Region of Interest（ROI）提取的rPPG信号作为输入。此外，1DCNN注意模块是用于学习和捕捉特征嵌入中的可塑性亲属特征。最后，我们对UvANEMO Smile Database中的不同亲属关系进行评估， demonstrably show rPPG信号在验证亲属方面的用于。
</details></li>
</ul>
<hr>
<h2 id="TCGF-A-unified-tensorized-consensus-graph-framework-for-multi-view-representation-learning"><a href="#TCGF-A-unified-tensorized-consensus-graph-framework-for-multi-view-representation-learning" class="headerlink" title="TCGF: A unified tensorized consensus graph framework for multi-view representation learning"></a>TCGF: A unified tensorized consensus graph framework for multi-view representation learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09987">http://arxiv.org/abs/2309.09987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangzhu Meng, Wei Wei, Qiang Liu, Shu Wu, Liang Wang</li>
<li>for: 本文旨在提出一种通用多视图学习框架，即矩阵化一致图模型（TCGF），以解决现有多视图学习方法的缺乏整合和普适性问题。</li>
<li>methods: 本文提出了一种综合多视图表示学习框架，包括：（1）提供一种可靠的多视图表示框架，可适应任意假设和不同缩放的数据集。（2）将各视图的表示树堆叠在一起，形成高级别表示，以实现视图之间的稳定协同传递。（3）学习一个共识嵌入，通过各视图相互协同适应，揭示多视图数据中的 essence 结构。</li>
<li>results: 实验结果表明，相比现有的多视图学习方法，TCGF在七个不同缩放的数据集上具有显著的优势。<details>
<summary>Abstract</summary>
Multi-view learning techniques have recently gained significant attention in the machine learning domain for their ability to leverage consistency and complementary information across multiple views. However, there remains a lack of sufficient research on generalized multi-view frameworks that unify existing works into a scalable and robust learning framework, as most current works focus on specific styles of multi-view models. Additionally, most multi-view learning works rely heavily on specific-scale scenarios and fail to effectively comprehend multiple scales holistically. These limitations hinder the effective fusion of essential information from multiple views, resulting in poor generalization. To address these limitations, this paper proposes a universal multi-view representation learning framework named Tensorized Consensus Graph Framework (TCGF). Specifically, it first provides a unified framework for existing multi-view works to exploit the representations for individual view, which aims to be suitable for arbitrary assumptions and different-scales datasets. Then, stacks them into a tensor under alignment basics as a high-order representation, allowing for the smooth propagation of consistency and complementary information across all views. Moreover, TCGF proposes learning a consensus embedding shared by adaptively collaborating all views to uncover the essential structure of the multi-view data, which utilizes view-consensus grouping effect to regularize the view-consensus representation. To further facilitate related research, we provide a specific implementation of TCGF for large-scale datasets, which can be efficiently solved by applying the alternating optimization strategy. Experimental results conducted on seven different-scales datasets indicate the superiority of the proposed TCGF against existing state-of-the-art multi-view learning methods.
</details>
<details>
<summary>摘要</summary>
多视图学习技术在机器学习领域最近受到了广泛关注，因为它们可以利用多视图之间的一致性和补充信息。然而，目前还缺乏一个可扩展和可靠的多视图框架，因为大多数当前的工作都是特定风格的多视图模型。另外，大多数多视图学习工作都是特定级别的场景，而不是全面地理解多个级别。这些限制了多视图数据的有效融合，导致泛化不佳。为了解决这些限制，本文提出了一种通用的多视图表示学习框架，名为张量化共识图 Framework（TCGF）。具体来说，它首先提供了一个可以拓展的框架，以便已有的多视图工作可以利用各个视图的表示，并且适用于任何假设和不同级别的数据集。然后，它将这些表示排列在一个张量上，并通过基本的对齐方式将它们作为高阶表示进行细致的传递。此外，TCGF还提出了一种共识嵌入，用于在所有视图之间共享一个共识表示，以探索多视图数据的基本结构。这种共识嵌入使用视图协调组效果来规范视图协调表示。为了进一步促进相关的研究，我们在大规模数据集上提供了TCGF的具体实现，可以通过 alternating 优化策略进行高效地解决。实验结果表明，提出的TCGF在七个不同级别数据集上的性能较好，比现有的多视图学习方法更高。
</details></li>
</ul>
<hr>
<h2 id="M3Dsynth-A-dataset-of-medical-3D-images-with-AI-generated-local-manipulations"><a href="#M3Dsynth-A-dataset-of-medical-3D-images-with-AI-generated-local-manipulations" class="headerlink" title="M3Dsynth: A dataset of medical 3D images with AI-generated local manipulations"></a>M3Dsynth: A dataset of medical 3D images with AI-generated local manipulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07973">http://arxiv.org/abs/2309.07973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giada Zingarini, Davide Cozzolino, Riccardo Corvi, Giovanni Poggi, Luisa Verdoliva</li>
<li>for: 这个论文主要是为了研究如何检测图像受到修改的问题，尤其是在医疗图像领域，以避免因图像修改而导致诊断错误。</li>
<li>methods: 作者使用了三种基于生成对抗网络（GAN）或扩散模型（DM）的方法来创建修改后的计算机tomography（CT）肺部图像，共计8,577个修改样本。</li>
<li>results: 实验表明，这些修改图像可以轻松地骗唬自动诊断工具，而state-of-the-art的审核检测器也可以准确地检测和定位修改的synthetic内容，包括当训练集和测试集不一致时，表现良好的泛化能力。<details>
<summary>Abstract</summary>
The ability to detect manipulated visual content is becoming increasingly important in many application fields, given the rapid advances in image synthesis methods. Of particular concern is the possibility of modifying the content of medical images, altering the resulting diagnoses. Despite its relevance, this issue has received limited attention from the research community. One reason is the lack of large and curated datasets to use for development and benchmarking purposes. Here, we investigate this issue and propose M3Dsynth, a large dataset of manipulated Computed Tomography (CT) lung images. We create manipulated images by injecting or removing lung cancer nodules in real CT scans, using three different methods based on Generative Adversarial Networks (GAN) or Diffusion Models (DM), for a total of 8,577 manipulated samples. Experiments show that these images easily fool automated diagnostic tools. We also tested several state-of-the-art forensic detectors and demonstrated that, once trained on the proposed dataset, they are able to accurately detect and localize manipulated synthetic content, including when training and test sets are not aligned, showing good generalization ability. Dataset and code will be publicly available at https://grip-unina.github.io/M3Dsynth/.
</details>
<details>
<summary>摘要</summary>
“检测修改图像内容的能力在许多应用领域变得日益重要，尤其是在医疗领域，因为修改图像可能会影响诊断结果。然而，这个问题在研究community中得到的关注相对较少。一个原因是没有大量的整理好的数据集，用于开发和测试目的。在这篇文章中，我们调查这个问题，并提出了M3Dsynth数据集，这是一个大量的修改了计算机扫描图像（CT）肺部影像的数据集。我们使用了三种基于生成对抗网络（GAN）或扩散模型（DM）的方法来创建修改后的图像，总共有8,577个修改样本。实验表明，这些图像容易让自动诊断工具进行误报。我们还测试了一些当前最佳的审核检测器，并证明它们可以准确地检测和定位修改的 sintetic内容，包括在训练和测试集不一致的情况下，这表明了它们的泛化能力。数据集和代码将在https://grip-unina.github.io/M3Dsynth/上公开。”
</details></li>
</ul>
<hr>
<h2 id="Language-Embedded-Radiance-Fields-for-Zero-Shot-Task-Oriented-Grasping"><a href="#Language-Embedded-Radiance-Fields-for-Zero-Shot-Task-Oriented-Grasping" class="headerlink" title="Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping"></a>Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07970">http://arxiv.org/abs/2309.07970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam Rashid, Satvik Sharma, Chung Min Kim, Justin Kerr, Lawrence Chen, Angjoo Kanazawa, Ken Goldberg</li>
<li>For:	+ The paper aims to improve the ability of learning-based grasp planners to grasp objects by specific parts, especially for objects with diverse shapes and appearances.	+ The proposed method, LERF-TOGO, is designed to handle task-oriented grasping of objects using natural language queries.	+ The method is expected to be useful in applications where grasping objects by specific parts is crucial, such as robotic grasping and manipulation tasks.* Methods:	+ The proposed method, LERF-TOGO, uses vision-language models zero-shot to output a grasp distribution over an object given a natural language query.	+ The method first reconstructs a LERF of the scene, which distills CLIP embeddings into a multi-scale 3D language field queryable with text.	+ To mitigate the lack of spatial grouping in LERF, the method extracts a 3D object mask via DINO features and then conditionally queries LERF on this mask to obtain a semantic distribution over the object.	+ The method uses an off-the-shelf grasp planner to rank grasps based on the semantic distribution.* Results:	+ The proposed method, LERF-TOGO, selects grasps on the correct part in 81% of all trials and grasps successfully in 69% of all trials on 31 different physical objects.Here is the result in Simplified Chinese text:* For:	+ 该研究旨在提高学习型抓取器对物体特定部分的抓取能力，特别是对物体形态和外观多样化。	+ 提出的方法LERF-TOGO使用自然语言查询来实现任务对应的抓取。	+ 方法适用于需要抓取物体特定部分的应用，如机器人抓取和操作任务。* Methods:	+ LERF-TOGO使用视觉语言模型零扫零抓取来输出对物体的抓取分布。	+ 方法首先重建场景的LERF，将CLIP编码转换为多级3D语言场景，可以通过文本进行查询。	+ 为了解决LERF中的空间分组问题，方法提取了3D物体Mask，并将其conditionally查询LERF以获取对物体的语义分布。	+ 方法使用的是一个废弃的抓取 плаanner来对语义分布进行排名。* Results:	+ LERF-TOGO在31种不同的物体上选择了81%的正确部分，并在69%的试验中成功抓取。<details>
<summary>Abstract</summary>
Grasping objects by a specific part is often crucial for safety and for executing downstream tasks. Yet, learning-based grasp planners lack this behavior unless they are trained on specific object part data, making it a significant challenge to scale object diversity. Instead, we propose LERF-TOGO, Language Embedded Radiance Fields for Task-Oriented Grasping of Objects, which uses vision-language models zero-shot to output a grasp distribution over an object given a natural language query. To accomplish this, we first reconstruct a LERF of the scene, which distills CLIP embeddings into a multi-scale 3D language field queryable with text. However, LERF has no sense of objectness, meaning its relevancy outputs often return incomplete activations over an object which are insufficient for subsequent part queries. LERF-TOGO mitigates this lack of spatial grouping by extracting a 3D object mask via DINO features and then conditionally querying LERF on this mask to obtain a semantic distribution over the object with which to rank grasps from an off-the-shelf grasp planner. We evaluate LERF-TOGO's ability to grasp task-oriented object parts on 31 different physical objects, and find it selects grasps on the correct part in 81% of all trials and grasps successfully in 69%. See the project website at: lerftogo.github.io
</details>
<details>
<summary>摘要</summary>
通过特定部分抓取物体是安全和执行下游任务的关键。然而，学习基于的抓取 планиFiPG 缺乏这种行为，除非它们在特定对象部分数据上接受训练，这使得扩展对象多样性成为主要挑战。在这种情况下，我们提议LERF-TOGO，基于视觉语言模型的语言嵌入Radiance Fields для任务oriented抓取物体。LERF-TOGO使用视觉语言模型的零shot输出抓取分布ributable over an object given a natural language query。为了完成这个任务，我们首先重建LERF of the scene，这使得CLIP embedding into a multi-scale 3D language field queryable with text。然而，LERF没有物体感知，这意味着其归类输出通常返回对象上的不完整活动，这些活动不够 для后续的部分查询。LERF-TOGO解决了这个缺失，通过提取 DINO 特征来提取3D object mask，然后使用这个mask来 conditionally query LERF，以获取对象上的semantic distribution，并用这个分布来排序从存储库中获取的抓取器。我们对LERF-TOGO在31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不同的物理对象上进行了31种不
</details></li>
</ul>
<hr>
<h2 id="Large-Vocabulary-3D-Diffusion-Model-with-Transformer"><a href="#Large-Vocabulary-3D-Diffusion-Model-with-Transformer" class="headerlink" title="Large-Vocabulary 3D Diffusion Model with Transformer"></a>Large-Vocabulary 3D Diffusion Model with Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07920">http://arxiv.org/abs/2309.07920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziang Cao, Fangzhou Hong, Tong Wu, Liang Pan, Ziwei Liu</li>
<li>for: 本研究旨在生成具有大量分类的真实世界3D对象，使用一个单一的生成模型。</li>
<li>methods: 本文提出了一种基于扩散的Feed-Forward框架，通过综合利用三种策略来Synthesize 大量分类的真实世界3D对象。</li>
<li>results: 实验表明，使用单一的DiffTF模型可以 дости到现状最佳的大量分类3D对象生成性能，具有大量多样性、彩色 semantics和高质量。<details>
<summary>Abstract</summary>
Creating diverse and high-quality 3D assets with an automatic generative model is highly desirable. Despite extensive efforts on 3D generation, most existing works focus on the generation of a single category or a few categories. In this paper, we introduce a diffusion-based feed-forward framework for synthesizing massive categories of real-world 3D objects with a single generative model. Notably, there are three major challenges for this large-vocabulary 3D generation: a) the need for expressive yet efficient 3D representation; b) large diversity in geometry and texture across categories; c) complexity in the appearances of real-world objects. To this end, we propose a novel triplane-based 3D-aware Diffusion model with TransFormer, DiffTF, for handling challenges via three aspects. 1) Considering efficiency and robustness, we adopt a revised triplane representation and improve the fitting speed and accuracy. 2) To handle the drastic variations in geometry and texture, we regard the features of all 3D objects as a combination of generalized 3D knowledge and specialized 3D features. To extract generalized 3D knowledge from diverse categories, we propose a novel 3D-aware transformer with shared cross-plane attention. It learns the cross-plane relations across different planes and aggregates the generalized 3D knowledge with specialized 3D features. 3) In addition, we devise the 3D-aware encoder/decoder to enhance the generalized 3D knowledge in the encoded triplanes for handling categories with complex appearances. Extensive experiments on ShapeNet and OmniObject3D (over 200 diverse real-world categories) convincingly demonstrate that a single DiffTF model achieves state-of-the-art large-vocabulary 3D object generation performance with large diversity, rich semantics, and high quality.
</details>
<details>
<summary>摘要</summary>
创造多样化和高质量的3D资产使用自动生成模型非常有优势。尽管现有很多3D生成研究，但大多数现有工作都专注于生成单个类或几个类。在这篇论文中，我们介绍了一种基于扩散的前向框架，可以使用单个生成模型来生成庞大类型的真实世界3D对象。需要解决的主要挑战包括：a) 需要高效强大的3D表示方式; b) 类别之间的几何和文本特征差异较大; c) 实际世界对象的外观复杂。为此，我们提出了一种基于三平面的3D-aware扩散模型，DiffTF，以解决以下三个方面的挑战。1) 为了保证效率和可靠性，我们改进了三平面表示方式，提高了适应速度和准确性。2) 为了处理类别之间的几何和文本特征差异，我们认为所有3D对象的特征是一种总结了各种3D知识的组合。为了从多个类别提取总结了3D知识的特征，我们提出了一种3D-aware transformer， Shared Cross-plane Attention，可以在不同的平面之间学习交叉平面关系，并将总结了3D知识与特定3D特征相结合。3) 此外，我们还设计了3D-aware编码器/解码器，以增强生成的总结3D知识，处理类别具有复杂的外观。广泛的实验证明，使用单个DiffTF模型可以在ShapeNet和OmniObject3D（超过200种真实世界类别）中实现状态之最高的大 vocabulary 3D对象生成性能，具有大量多样化、充分 semantics 和高质量。
</details></li>
</ul>
<hr>
<h2 id="OpenIllumination-A-Multi-Illumination-Dataset-for-Inverse-Rendering-Evaluation-on-Real-Objects"><a href="#OpenIllumination-A-Multi-Illumination-Dataset-for-Inverse-Rendering-Evaluation-on-Real-Objects" class="headerlink" title="OpenIllumination: A Multi-Illumination Dataset for Inverse Rendering Evaluation on Real Objects"></a>OpenIllumination: A Multi-Illumination Dataset for Inverse Rendering Evaluation on Real Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07921">http://arxiv.org/abs/2309.07921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isabella Liu, Linghao Chen, Ziyang Fu, Liwen Wu, Haian Jin, Zhong Li, Chin Ming Ryan Wong, Yi Xu, Ravi Ramamoorthi, Zexiang Xu, Hao Su</li>
<li>for: 这个论文是为了提供一个大量的实际拍摄数据集，用于评估反射渲染和材质分解算法的性能。</li>
<li>methods: 论文使用了多种现有的反射渲染和材质分解方法，并对其进行了评估。</li>
<li>results: 论文通过对实际拍摄数据集进行评估，发现了一些现有方法的缺陷和限制，并提出了一些改进方案。Here’s the full translation in Simplified Chinese:</li>
<li>for: 这个论文是为了提供一个大量的实际拍摄数据集，用于评估反射渲染和材质分解算法的性能。</li>
<li>methods: 论文使用了多种现有的反射渲染和材质分解方法，并对其进行了评估。</li>
<li>results: 论文通过对实际拍摄数据集进行评估，发现了一些现有方法的缺陷和限制，并提出了一些改进方案。<details>
<summary>Abstract</summary>
We introduce OpenIllumination, a real-world dataset containing over 108K images of 64 objects with diverse materials, captured under 72 camera views and a large number of different illuminations. For each image in the dataset, we provide accurate camera parameters, illumination ground truth, and foreground segmentation masks. Our dataset enables the quantitative evaluation of most inverse rendering and material decomposition methods for real objects. We examine several state-of-the-art inverse rendering methods on our dataset and compare their performances. The dataset and code can be found on the project page: https://oppo-us-research.github.io/OpenIllumination.
</details>
<details>
<summary>摘要</summary>
我们介绍OpenIllumination dataset，包含108,000几个不同材料的物品，在72个摄像头视角下拍摄，并提供了准确的摄像头参数、照明真实值和前景分类标识。这个 dataset 允许大多数反向渲染和材料分解方法的量化评估，并且我们在这个 dataset 上评估了一些现有的反向渲染方法的性能。dataset 和代码可以在项目页面上找到：https://oppo-us-research.github.io/OpenIllumination。
</details></li>
</ul>
<hr>
<h2 id="Unified-Human-Scene-Interaction-via-Prompted-Chain-of-Contacts"><a href="#Unified-Human-Scene-Interaction-via-Prompted-Chain-of-Contacts" class="headerlink" title="Unified Human-Scene Interaction via Prompted Chain-of-Contacts"></a>Unified Human-Scene Interaction via Prompted Chain-of-Contacts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07918">http://arxiv.org/abs/2309.07918</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/openrobotlab/unihsi">https://github.com/openrobotlab/unihsi</a></li>
<li>paper_authors: Zeqi Xiao, Tai Wang, Jingbo Wang, Jinkun Cao, Wenwei Zhang, Bo Dai, Dahua Lin, Jiangmiao Pang</li>
<li>for: 这篇论文的目的是提出一种统一的人Scene交互（HSI）框架，以便在实体AI和虚拟现实等领域中实现多样化的交互控制和用户友好的界面。</li>
<li>methods: 这篇论文使用了一种基于“链接Contacts”（CoC）的定义来支持多种交互，并提出了一种基于大语言模型（LLM）的 плаanner来将自然语言提示转化为任务计划，以及一种统一控制器来将计划转化为具体的任务执行。</li>
<li>results: 该论文的实验结果表明，该框架在多种任务执行中具有广泛的应用性和可重复性，并且可以在真实扫描的场景中进行实际应用。<details>
<summary>Abstract</summary>
Human-Scene Interaction (HSI) is a vital component of fields like embodied AI and virtual reality. Despite advancements in motion quality and physical plausibility, two pivotal factors, versatile interaction control and the development of a user-friendly interface, require further exploration before the practical application of HSI. This paper presents a unified HSI framework, UniHSI, which supports unified control of diverse interactions through language commands. This framework is built upon the definition of interaction as Chain of Contacts (CoC): steps of human joint-object part pairs, which is inspired by the strong correlation between interaction types and human-object contact regions. Based on the definition, UniHSI constitutes a Large Language Model (LLM) Planner to translate language prompts into task plans in the form of CoC, and a Unified Controller that turns CoC into uniform task execution. To facilitate training and evaluation, we collect a new dataset named ScenePlan that encompasses thousands of task plans generated by LLMs based on diverse scenarios. Comprehensive experiments demonstrate the effectiveness of our framework in versatile task execution and generalizability to real scanned scenes. The project page is at https://github.com/OpenRobotLab/UniHSI .
</details>
<details>
<summary>摘要</summary>
人机场景交互（HSI）是embodied AI和虚拟现实领域的关键组件。尽管有进步在运动质量和物理可能性方面，但是多样化的交互控制和用户友好的界面的开发仍需进一步探索，以便实际应用HSI。本文提出了一个统一的HSI框架，称为UniHSI，该框架通过语言命令支持统一控制多种交互。这个框架基于交互定义为链接（Chain of Contacts，CoC）：人 JOINT-object部分的步骤，这是基于交互类型和人机对象接触区域之间的强相关性。UniHSI包括一个大语言模型（LLM） плаanner，用于将语言提示转化为任务计划的CoC形式，以及一个统一控制器，用于将CoC转化为统一的任务执行。为了便于训练和评估，我们收集了一个新的数据集名为ScenePlan，其包括由LLMs根据多样化的场景生成的 thousands个任务计划。广泛的实验表明了我们框架在多样化任务执行和真实扫描场景的普适性。项目页面位于https://github.com/OpenRobotLab/UniHSI。
</details></li>
</ul>
<hr>
<h2 id="Looking-at-words-and-points-with-attention-a-benchmark-for-text-to-shape-coherence"><a href="#Looking-at-words-and-points-with-attention-a-benchmark-for-text-to-shape-coherence" class="headerlink" title="Looking at words and points with attention: a benchmark for text-to-shape coherence"></a>Looking at words and points with attention: a benchmark for text-to-shape coherence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07917">http://arxiv.org/abs/2309.07917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Amaduzzi, Giuseppe Lisanti, Samuele Salti, Luigi Di Stefano</li>
<li>for: 提供了一个全面的解决方案，以改善文本描述和三维形状之间的准确性。</li>
<li>methods: 使用大型自然语言模型来自动修正三维形状的文本描述，并提出了一种新的量化度量来评估文本和形状之间的准确性。</li>
<li>results: 通过用户研究和比较量化分析，证明了新的度量在评估文本和形状之间的准确性方面具有更高的效果。同时，我们还公开发布了一个新的、精细的 benchmark，以便驱动研究在文本条件下的三维生成模型中的准确性。<details>
<summary>Abstract</summary>
While text-conditional 3D object generation and manipulation have seen rapid progress, the evaluation of coherence between generated 3D shapes and input textual descriptions lacks a clear benchmark. The reason is twofold: a) the low quality of the textual descriptions in the only publicly available dataset of text-shape pairs; b) the limited effectiveness of the metrics used to quantitatively assess such coherence. In this paper, we propose a comprehensive solution that addresses both weaknesses. Firstly, we employ large language models to automatically refine textual descriptions associated with shapes. Secondly, we propose a quantitative metric to assess text-to-shape coherence, through cross-attention mechanisms. To validate our approach, we conduct a user study and compare quantitatively our metric with existing ones. The refined dataset, the new metric and a set of text-shape pairs validated by the user study comprise a novel, fine-grained benchmark that we publicly release to foster research on text-to-shape coherence of text-conditioned 3D generative models. Benchmark available at https://cvlab-unibo.github.io/CrossCoherence-Web/.
</details>
<details>
<summary>摘要</summary>
While text-conditional 3D object generation and manipulation have made rapid progress, the evaluation of coherence between generated 3D shapes and input textual descriptions lacks a clear benchmark. The reason is twofold: a) the low quality of the textual descriptions in the only publicly available dataset of text-shape pairs; b) the limited effectiveness of the metrics used to quantitatively assess such coherence. In this paper, we propose a comprehensive solution that addresses both weaknesses. Firstly, we employ large language models to automatically refine textual descriptions associated with shapes. Secondly, we propose a quantitative metric to assess text-to-shape coherence, through cross-attention mechanisms. To validate our approach, we conduct a user study and compare quantitatively our metric with existing ones. The refined dataset, the new metric and a set of text-shape pairs validated by the user study comprise a novel, fine-grained benchmark that we publicly release to foster research on text-to-shape coherence of text-conditioned 3D generative models. Benchmark available at https://cvlab-unibo.github.io/CrossCoherence-Web/.Here's the translation in Traditional Chinese:虽然文本条件下的3D物体生成和修改技术已经做出了快速的进步，但评估这些生成的3D形状和输入文本描述之间的协调性仍然缺乏明确的benchmark。这是因为：a) 公开 disponibles的文本描述资料伙伴的质量低下; b) 现有的评估 metric 对 text-to-shape coherence 的评估有限的效iveness。在这篇论文中，我们提出了一个完整的解决方案，它可以解决这两个问题。首先，我们使用大型语言模型来自动修复与形状相关的文本描述。第二，我们提出了一个新的评估metric，通过跨注意力机制来评估文本与形状之间的协调性。为了验证我们的方法，我们进行了用户研究，并与现有的评估metric进行比较。我们提出的新metric、修复的资料集和由用户验证的文本-形状对组成一个新的、精确的benchmark，我们公开发布这个benchmark，以促进文本条件下的3D生成模型协调性的研究。benchmark可以在https://cvlab-unibo.github.io/CrossCoherence-Web/ 获取。
</details></li>
</ul>
<hr>
<h2 id="ALWOD-Active-Learning-for-Weakly-Supervised-Object-Detection"><a href="#ALWOD-Active-Learning-for-Weakly-Supervised-Object-Detection" class="headerlink" title="ALWOD: Active Learning for Weakly-Supervised Object Detection"></a>ALWOD: Active Learning for Weakly-Supervised Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07914">http://arxiv.org/abs/2309.07914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuting Wang, Velibor Ilic, Jiatong Li, Branislav Kisacanin, Vladimir Pavlovic</li>
<li>for: 提高对象检测（OD）任务中的训练数据质量，addressing the lack of large training datasets with precise object localization labels.</li>
<li>methods:  fusion of active learning (AL) with weakly and semi-supervised object detection paradigms, including a new auxiliary image generator strategy and a new AL acquisition function.</li>
<li>results: significantly narrowing the gap between ODs trained on few partially labeled but strategically selected image instances and those that rely on fully-labeled data, demonstrated across several challenging benchmarks.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在提高对象检测（OD）任务中的训练数据质量， Addressing the lack of large training datasets with precise object localization labels.</li>
<li>methods: 本研究提出了一种基于active learning（AL）和弱式和半supervised对象检测方法的新框架，包括一种新的auxiliary image generator策略和一种新的AL acquisition function。</li>
<li>results: 本研究表明，通过使用ALWOD框架，可以significantly narrow the gap betweenODs trained on few partially labeled but strategically selected image instances and those that rely on fully-labeled data，demonstrated across several challenging benchmarks.I hope this helps! Let me know if you have any further questions or if there’s anything else I can assist you with.<details>
<summary>Abstract</summary>
Object detection (OD), a crucial vision task, remains challenged by the lack of large training datasets with precise object localization labels. In this work, we propose ALWOD, a new framework that addresses this problem by fusing active learning (AL) with weakly and semi-supervised object detection paradigms. Because the performance of AL critically depends on the model initialization, we propose a new auxiliary image generator strategy that utilizes an extremely small labeled set, coupled with a large weakly tagged set of images, as a warm-start for AL. We then propose a new AL acquisition function, another critical factor in AL success, that leverages the student-teacher OD pair disagreement and uncertainty to effectively propose the most informative images to annotate. Finally, to complete the AL loop, we introduce a new labeling task delegated to human annotators, based on selection and correction of model-proposed detections, which is both rapid and effective in labeling the informative images. We demonstrate, across several challenging benchmarks, that ALWOD significantly narrows the gap between the ODs trained on few partially labeled but strategically selected image instances and those that rely on the fully-labeled data. Our code is publicly available on https://github.com/seqam-lab/ALWOD.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Disentangling-Spatial-and-Temporal-Learning-for-Efficient-Image-to-Video-Transfer-Learning"><a href="#Disentangling-Spatial-and-Temporal-Learning-for-Efficient-Image-to-Video-Transfer-Learning" class="headerlink" title="Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning"></a>Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07911">http://arxiv.org/abs/2309.07911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibaba-mmai-research/dist">https://github.com/alibaba-mmai-research/dist</a></li>
<li>paper_authors: Zhiwu Qing, Shiwei Zhang, Ziyuan Huang, Yingya Zhang, Changxin Gao, Deli Zhao, Nong Sang</li>
<li>for: 这个论文旨在解决现有的视频识别方法中的缺陷，即将大规模预训练的语言-图像模型（如CLIP）应用于视频识别 task 时，它们的 temporal 理解能力受到限制。</li>
<li>methods: 该论文提出了 DiST 方法，它使用 dual-encoder 结构，其中一个是预训练的基础模型，另一个是一个轻量级的网络，用于Temporal 编码。它们之间的拓展分支用于融合空间-时间信息。</li>
<li>results: 该论文的实验结果表明，DiST 方法可以更好地理解视频中的空间和时间信息，并且比现有的方法更高效。在五个标准测试集上，DiST 方法的性能较现有方法优越。此外，当预训练在大规模的 Kinetics-710 上进行时，DiST 方法在冻结 ViT-L 模型下达到了 89.7% 的表现。<details>
<summary>Abstract</summary>
Recently, large-scale pre-trained language-image models like CLIP have shown extraordinary capabilities for understanding spatial contents, but naively transferring such models to video recognition still suffers from unsatisfactory temporal modeling capabilities. Existing methods insert tunable structures into or in parallel with the pre-trained model, which either requires back-propagation through the whole pre-trained model and is thus resource-demanding, or is limited by the temporal reasoning capability of the pre-trained structure. In this work, we present DiST, which disentangles the learning of spatial and temporal aspects of videos. Specifically, DiST uses a dual-encoder structure, where a pre-trained foundation model acts as the spatial encoder, and a lightweight network is introduced as the temporal encoder. An integration branch is inserted between the encoders to fuse spatio-temporal information. The disentangled spatial and temporal learning in DiST is highly efficient because it avoids the back-propagation of massive pre-trained parameters. Meanwhile, we empirically show that disentangled learning with an extra network for integration benefits both spatial and temporal understanding. Extensive experiments on five benchmarks show that DiST delivers better performance than existing state-of-the-art methods by convincing gaps. When pre-training on the large-scale Kinetics-710, we achieve 89.7% on Kinetics-400 with a frozen ViT-L model, which verifies the scalability of DiST. Codes and models can be found in https://github.com/alibaba-mmai-research/DiST.
</details>
<details>
<summary>摘要</summary>
近些年，大规模预训练语言图像模型如CLIP表现出了对空间内容的杰出理解能力，但将这些模型应用于视频识别仍然存在不满足的时间理解能力。现有方法通常是在预训练模型中插入可调整的结构，这些结构可以通过整个预训练模型进行反向传播，但这会占用大量资源。或者，这些方法可以通过预训练结构的时间逻辑能力限制，从而导致模型的性能不佳。在这种情况下，我们提出了DiST，它可以分离空间和时间方面的学习。具体来说，DiST使用了一个双encoder结构，预训练基础模型 acting as the spatial encoder，并 introduce a lightweight network as the temporal encoder。一个整合分支被插入到encoder之间，以融合空间-时间信息。DiST中的分离学习非常高效，因为它可以避免大量预训练参数的反向传播。同时，我们经验表明，分离学习并在额外的整合网络上进行融合，可以提高空间和时间理解能力。我们在五个标准 benchMark上进行了广泛的实验，并证明了DiST的性能比现有的状态码表示出较大的差距。当我们在大规模的 Kinetics-710 上预训练时，我们在 Kinetics-400 上 achieved 89.7%，这证明了 DiST 的可扩展性。codes和模型可以在 https://github.com/alibaba-mmai-research/DiST 找到。
</details></li>
</ul>
<hr>
<h2 id="TEMPO-Efficient-Multi-View-Pose-Estimation-Tracking-and-Forecasting"><a href="#TEMPO-Efficient-Multi-View-Pose-Estimation-Tracking-and-Forecasting" class="headerlink" title="TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting"></a>TEMPO: Efficient Multi-View Pose Estimation, Tracking, and Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07910">http://arxiv.org/abs/2309.07910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Choudhury, Kris Kitani, Laszlo A. Jeni</li>
<li>for: 预测3D人姿 pose estimation</li>
<li>methods: 使用循环计算每个人2D姿势特征，并将空间和时间信息 fusion到一个表示中，以提高人姿准确性并降低计算量</li>
<li>results: 在CMU Panoptic Studio数据集上，与TesseTrack相比，TEMPO模型可以达到10%更高的MPJPE，同时提高33倍的FPS速度<details>
<summary>Abstract</summary>
Existing volumetric methods for predicting 3D human pose estimation are accurate, but computationally expensive and optimized for single time-step prediction. We present TEMPO, an efficient multi-view pose estimation model that learns a robust spatiotemporal representation, improving pose accuracy while also tracking and forecasting human pose. We significantly reduce computation compared to the state-of-the-art by recurrently computing per-person 2D pose features, fusing both spatial and temporal information into a single representation. In doing so, our model is able to use spatiotemporal context to predict more accurate human poses without sacrificing efficiency. We further use this representation to track human poses over time as well as predict future poses. Finally, we demonstrate that our model is able to generalize across datasets without scene-specific fine-tuning. TEMPO achieves 10$\%$ better MPJPE with a 33$\times$ improvement in FPS compared to TesseTrack on the challenging CMU Panoptic Studio dataset.
</details>
<details>
<summary>摘要</summary>
现有的体量方法可以准确地预测3D人姿，但是计算成本高和优化为单步预测。我们介绍TEMPO，一种高效的多视图人姿预测模型，学习了稳定的时空表示，提高了人姿准确性，同时也可以跟踪和预测人姿。我们大幅减少了与当前状态艺技的计算量，通过在每个人物2D姿势特征上进行回卷计算，将空间和时间信息 fusion 到一个表示中。这使得我们的模型可以使用时空上下文来预测更加准确的人姿，而不需要牺牲效率。我们还使用这种表示来跟踪人姿在时间上的变化，以及预测未来的姿势。最后，我们证明了我们的模型可以在不进行场景特定的细化 fine-tuning 的情况下进行泛化。TEMPO在CMU Panoptic Studio dataset上达到了10%更好的MPJPE，并且33倍提高了FPS。
</details></li>
</ul>
<hr>
<h2 id="Physically-Plausible-Full-Body-Hand-Object-Interaction-Synthesis"><a href="#Physically-Plausible-Full-Body-Hand-Object-Interaction-Synthesis" class="headerlink" title="Physically Plausible Full-Body Hand-Object Interaction Synthesis"></a>Physically Plausible Full-Body Hand-Object Interaction Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07907">http://arxiv.org/abs/2309.07907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eth-ait/phys-fullbody-grasp">https://github.com/eth-ait/phys-fullbody-grasp</a></li>
<li>paper_authors: Jona Braun, Sammy Christen, Muhammed Kocabas, Emre Aksan, Otmar Hilliges</li>
<li>for: 本研究旨在提出一种基于物理学的方法，用于 sintesizing 人工智能系统中的协调够强的手对象互动。</li>
<li>methods: 该方法使用了反馈学习（RL）和物理 simulate 来解决数据驱动方法的局限性。具体来说，我们首先在分离的设定下学习了身体和手部运动的能量套件，然后通过高级策略控制手对象互动，以满足任务目标。</li>
<li>results: 该方法成功完成了从接近对象到握持和后续操作的完整互动任务，并与基于骨骼动画的基线比较，显示更加物理合理的运动。<details>
<summary>Abstract</summary>
We propose a physics-based method for synthesizing dexterous hand-object interactions in a full-body setting. While recent advancements have addressed specific facets of human-object interactions, a comprehensive physics-based approach remains a challenge. Existing methods often focus on isolated segments of the interaction process and rely on data-driven techniques that may result in artifacts. In contrast, our proposed method embraces reinforcement learning (RL) and physics simulation to mitigate the limitations of data-driven approaches. Through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting. The generic skill priors learn to decode a latent skill embedding into the motion of the underlying part. A high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following. It is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives. Our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation. We compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.
</details>
<details>
<summary>摘要</summary>
Through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting. The generic skill priors learn to decode a latent skill embedding into the motion of the underlying part. A high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following. It is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives.Our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation. We compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.Translated into Simplified Chinese:我们提出一种基于物理学的方法，用于Synthesizing skillful hand-object interactions in a full-body setting. although recent advancements have addressed specific aspects of human-object interactions, a comprehensive physics-based approach remains a challenge. existing methods often focus on isolated segments of the interaction process and rely on data-driven techniques that may result in artifacts. in contrast, our proposed method combines reinforcement learning (RL) and physics simulation to mitigate the limitations of data-driven approaches.through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting. the generic skill priors learn to decode a latent skill embedding into the motion of the underlying part. a high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following. it is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives.our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation. we compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.
</details></li>
</ul>
<hr>
<h2 id="Generative-Image-Dynamics"><a href="#Generative-Image-Dynamics" class="headerlink" title="Generative Image Dynamics"></a>Generative Image Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07906">http://arxiv.org/abs/2309.07906</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/generative-dynamics/generative-dynamics.github.io">https://github.com/generative-dynamics/generative-dynamics.github.io</a></li>
<li>paper_authors: Zhengqi Li, Richard Tucker, Noah Snavely, Aleksander Holynski</li>
<li>for: 该论文是用来模型图像空间的场景动力模型的方法。</li>
<li>methods: 该方法通过从真实视频序列中提取的运动轨迹来学习图像空间的动力模型。每个图像都通过一种频率协调的扩散抽象过程来预测每个像素的长期运动表示，这被称为神经随机运动xture。</li>
<li>results: 这种方法可以将单个图像转换为整个视频的密集运动轨迹，并且可以用于许多下游应用程序，如将Stationary图像转换为无缝循环动画，或让用户在真实图像中真实地与物体互动。<details>
<summary>Abstract</summary>
We present an approach to modeling an image-space prior on scene dynamics. Our prior is learned from a collection of motion trajectories extracted from real video sequences containing natural, oscillating motion such as trees, flowers, candles, and clothes blowing in the wind. Given a single image, our trained model uses a frequency-coordinated diffusion sampling process to predict a per-pixel long-term motion representation in the Fourier domain, which we call a neural stochastic motion texture. This representation can be converted into dense motion trajectories that span an entire video. Along with an image-based rendering module, these trajectories can be used for a number of downstream applications, such as turning still images into seamlessly looping dynamic videos, or allowing users to realistically interact with objects in real pictures.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于图像空间的场景动力模型。我们的估计来自于实际视频序列中的自然摆动，如树、花、灯火和衣服在风中摆动。给定一幅图像，我们的训练模型使用协调频率扩散采样过程预测每个像素的长期运动表示，我们称之为神经随机动 texture。这个表示可以转化为涵盖整个视频的精密运动轨迹，并且可以与图像基于渲染模块结合使用，以实现将静止图像转化为流畅动态视频，或让用户在真实图像中实现真实互动。
</details></li>
</ul>
<hr>
<h2 id="HandNeRF-Learning-to-Reconstruct-Hand-Object-Interaction-Scene-from-a-Single-RGB-Image"><a href="#HandNeRF-Learning-to-Reconstruct-Hand-Object-Interaction-Scene-from-a-Single-RGB-Image" class="headerlink" title="HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a Single RGB Image"></a>HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a Single RGB Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07891">http://arxiv.org/abs/2309.07891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongsuk Choi, Nikhil Chavan-Dafle, Jiacheng Yuan, Volkan Isler, Hyunsoo Park</li>
<li>for: 这个论文旨在学习手-物体交互情况，从单个RGB图像中重建3D手-物体场景。</li>
<li>methods: 这篇论文使用了一种普适的启发函数HandNeRF，该函数考虑了手形特征和物体特征之间的相关性，以预测手和物体场景几何。</li>
<li>results: 经过实验表明，HandNeRF能够更准确地重建手-物体场景，并且对下游任务如机器人手上吸取具有较高精度。<details>
<summary>Abstract</summary>
This paper presents a method to learn hand-object interaction prior for reconstructing a 3D hand-object scene from a single RGB image. The inference as well as training-data generation for 3D hand-object scene reconstruction is challenging due to the depth ambiguity of a single image and occlusions by the hand and object. We turn this challenge into an opportunity by utilizing the hand shape to constrain the possible relative configuration of the hand and object geometry. We design a generalizable implicit function, HandNeRF, that explicitly encodes the correlation of the 3D hand shape features and 2D object features to predict the hand and object scene geometry. With experiments on real-world datasets, we show that HandNeRF is able to reconstruct hand-object scenes of novel grasp configurations more accurately than comparable methods. Moreover, we demonstrate that object reconstruction from HandNeRF ensures more accurate execution of a downstream task, such as grasping for robotic hand-over.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "hand-object scene" is translated as "手指物品场景" (shǒu zhǐ wù jǐ zhèng jīng)* "3D hand shape" is translated as "三维手势" (sān wéi shǒu xíng)* "2D object features" is translated as "二维物品特征" (èr wéi wù jīn tiě fèi)* "grasp configuration" is translated as "抓取配置" (cuò qǔ pèng jì)* "novel grasp configurations" is translated as "新型抓取配置" (xīn xíng cuò qǔ pèng jì)* "hand-over" is translated as "手势传递" (shǒu xíng chuán zhèng)
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Local-Global-Feature-Fusion-Framework-for-Body-weight-Exercise-Recognition-with-Pressure-Mapping-Sensors"><a href="#A-Novel-Local-Global-Feature-Fusion-Framework-for-Body-weight-Exercise-Recognition-with-Pressure-Mapping-Sensors" class="headerlink" title="A Novel Local-Global Feature Fusion Framework for Body-weight Exercise Recognition with Pressure Mapping Sensors"></a>A Novel Local-Global Feature Fusion Framework for Body-weight Exercise Recognition with Pressure Mapping Sensors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07888">http://arxiv.org/abs/2309.07888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davinder Pal Singh, Lala Shakti Swarup Ray, Bo Zhou, Sungho Suh, Paul Lukowicz</li>
<li>for: 本研究旨在提出一种新的本地-全局特征融合框架，用于地板式动压图像上的身体运动识别。</li>
<li>methods: 该框架使用图像处理技术和YOLO物体检测来融合本地和全局特征，并使用知识储存法进行正则化，以提高运动识别性能。</li>
<li>results: 我们的实验结果表明，该框架可以提高运动识别精度，同时保持标签特征。<details>
<summary>Abstract</summary>
We present a novel local-global feature fusion framework for body-weight exercise recognition with floor-based dynamic pressure maps. One step further from the existing studies using deep neural networks mainly focusing on global feature extraction, the proposed framework aims to combine local and global features using image processing techniques and the YOLO object detection to localize pressure profiles from different body parts and consider physical constraints. The proposed local feature extraction method generates two sets of high-level local features consisting of cropped pressure mapping and numerical features such as angular orientation, location on the mat, and pressure area. In addition, we adopt a knowledge distillation for regularization to preserve the knowledge of the global feature extraction and improve the performance of the exercise recognition. Our experimental results demonstrate a notable 11 percent improvement in F1 score for exercise recognition while preserving label-specific features.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的本地-全局特征融合框架，用于loor-based动态压力图像 recognition of body-weight exercises. 在现有研究主要通过深度神经网络进行全局特征EXTRACTION的基础上，我们的框架尝试将本地和全局特征结合使用图像处理技术和YOLO对象检测来地理 pressure profiles from different body parts and consider physical constraints. 我们的本地特征提取方法生成了两组高级本地特征，包括cropped pressure mapping和数值特征如angular orientation, location on the mat, and pressure area. 此外，我们采用了知识储存 distillation 来增强性能。我们的实验结果表明，使用本地-全局特征融合框架可以提高运动认知率11%，同时保持标签特征。
</details></li>
</ul>
<hr>
<h2 id="mEBAL2-Database-and-Benchmark-Image-based-Multispectral-Eyeblink-Detection"><a href="#mEBAL2-Database-and-Benchmark-Image-based-Multispectral-Eyeblink-Detection" class="headerlink" title="mEBAL2 Database and Benchmark: Image-based Multispectral Eyeblink Detection"></a>mEBAL2 Database and Benchmark: Image-based Multispectral Eyeblink Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07880">http://arxiv.org/abs/2309.07880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roberto Daza, Aythami Morales, Julian Fierrez, Ruben Tolosana, Ruben Vera-Rodriguez</li>
<li>for: 这篇论文旨在开发一个新的多spectrum数据库和多spectrum眼睛跟踪方法，以提高数据驱动的眼睛跟踪方法的性能。</li>
<li>methods: 这篇论文使用了多种感知器，包括两个 Near-Infrared (NIR) 感知器和一个 RGB 感知器，记录学生在完成不同难度的电子学习任务时的面部姿态和眼睛运动。此外，这篇论文还使用了一个电encephalogram (EEG) 带来获取用户的认知活动和眼睛跟踪事件。</li>
<li>results: 这篇论文提出了一种 Convolutional Neural Network (CNN) 架构作为眼睛跟踪的标准准则，并实现了不同的训练方法，包括使用 RGB spectrum、NIR spectrum 和两者的组合来提高现有的眼睛跟踪器的性能。研究表明，将 NIR 和 RGB 图像在训练时结合使用可以提高 RGB 眼睛跟踪器的性能。此外，这篇论文还验证了提出的眼睛跟踪器在更加惊喜和更加具有挑战性的环境中的一致性。<details>
<summary>Abstract</summary>
This work introduces a new multispectral database and novel approaches for eyeblink detection in RGB and Near-Infrared (NIR) individual images. Our contributed dataset (mEBAL2, multimodal Eye Blink and Attention Level estimation, Version 2) is the largest existing eyeblink database, representing a great opportunity to improve data-driven multispectral approaches for blink detection and related applications (e.g., attention level estimation and presentation attack detection in face biometrics). mEBAL2 includes 21,100 image sequences from 180 different students (more than 2 million labeled images in total) while conducting a number of e-learning tasks of varying difficulty or taking a real course on HTML initiation through the edX MOOC platform. mEBAL2 uses multiple sensors, including two Near-Infrared (NIR) and one RGB camera to capture facial gestures during the execution of the tasks, as well as an Electroencephalogram (EEG) band to get the cognitive activity of the user and blinking events. Furthermore, this work proposes a Convolutional Neural Network architecture as benchmark for blink detection on mEBAL2 with performances up to 97%. Different training methodologies are implemented using the RGB spectrum, NIR spectrum, and the combination of both to enhance the performance on existing eyeblink detectors. We demonstrate that combining NIR and RGB images during training improves the performance of RGB eyeblink detectors (i.e., detection based only on a RGB image). Finally, the generalization capacity of the proposed eyeblink detectors is validated in wilder and more challenging environments like the HUST-LEBW dataset to show the usefulness of mEBAL2 to train a new generation of data-driven approaches for eyeblink detection.
</details>
<details>
<summary>摘要</summary>
这个研究引入了一个新的多spectrum数据库和一种新的方法来探测眼睛跳动在RGB和近红外（NIR）个人图像中。我们的贡献数据集（mEBAL2）是目前最大的跳动数据库，它提供了一个很好的机会来提高数据驱动的多spectrum方法来探测跳动和相关应用（例如注意水平估计和面部生物特征识别中的攻击检测）。mEBAL2包含21,100个图像序列从180名不同的学生（总共超过200万个标记图像），他们在完成不同的电子学习任务或通过MOOC平台上的HTML入门课程进行了实际的学习。mEBAL2使用多种传感器，包括两个近红外（NIR）和一个RGB摄像头来捕捉面部姿势在执行任务时，以及一个电enzephalogram（EEG）带来用户的认知活动和跳动事件。此外，这个工作还提出了一种卷积神经网络架构作为mEBAL2上的跳动探测标准，其性能可达97%。不同的训练方法被实现使用RGB谱和NIR谱，以及两者的组合来提高现有的跳动探测器的性能。我们示出，在训练时使用RGB和NIR图像可以提高RGB跳动探测器的性能（即基于RGB图像alone的跳动探测）。最后，我们验证了提出的跳动探测器在更加恶劣的环境中的一致性，如HUST-LEBW数据集，以证明mEBAL2可以用来训练一代新的数据驱动的跳动探测器。
</details></li>
</ul>
<hr>
<h2 id="Using-network-metrics-to-explore-the-community-structure-that-underlies-movement-patterns"><a href="#Using-network-metrics-to-explore-the-community-structure-that-underlies-movement-patterns" class="headerlink" title="Using network metrics to explore the community structure that underlies movement patterns"></a>Using network metrics to explore the community structure that underlies movement patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07878">http://arxiv.org/abs/2309.07878</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anh Pham Thi Minh, Abhishek Kumar Singh, Soumya Snigdha Kundu</li>
<li>for: 研究圣地亚哥的社区结构，通过分析居民的运动趋势。</li>
<li>methods: 使用匿名居民的家庭和工作地点数据构建了运动网络，并使用模块化优化算法和聚类技术确定社区。</li>
<li>results: 结果显示，结合社区探测算法和分化工具可以提供新的洞察，深入了解劳动时间的复杂地理 segregation。<details>
<summary>Abstract</summary>
This work aims to explore the community structure of Santiago de Chile by analyzing the movement patterns of its residents. We use a dataset containing the approximate locations of home and work places for a subset of anonymized residents to construct a network that represents the movement patterns within the city. Through the analysis of this network, we aim to identify the communities or sub-cities that exist within Santiago de Chile and gain insights into the factors that drive the spatial organization of the city. We employ modularity optimization algorithms and clustering techniques to identify the communities within the network. Our results present that the novelty of combining community detection algorithms with segregation tools provides new insights to further the understanding of the complex geography of segregation during working hours.
</details>
<details>
<summary>摘要</summary>
这项工作的目的是探索 Santiagode Chile 城市的社区结构，通过分析居民的行为方式来描述城市内部的运动模式。我们使用一个包含一些匿名居民的家庭和工作地点的数据集来构建一个表示城市内部运动模式的网络。通过网络分析，我们希望发现城市中存在的社区或子城市，并了解城市空间组织的因素。我们使用模块化优化算法和聚类技术来确定社区内部的结构。我们的结果表明，结合社区探测算法和分化工具可以提供新的视角，deepen我们对城市复杂的地理结构的理解。
</details></li>
</ul>
<hr>
<h2 id="Gradient-constrained-sharpness-aware-prompt-learning-for-vision-language-models"><a href="#Gradient-constrained-sharpness-aware-prompt-learning-for-vision-language-models" class="headerlink" title="Gradient constrained sharpness-aware prompt learning for vision-language models"></a>Gradient constrained sharpness-aware prompt learning for vision-language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07866">http://arxiv.org/abs/2309.07866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangchen Liu, Nannan Wang, Dawei Zhou, Xinbo Gao, Decheng Liu, Xi Yang, Tongliang Liu</li>
<li>for: 提高视语模型在未经见过的类型上的性能，同时保持已经见过的类型上的性能。</li>
<li>methods: 基于权衡采用极性感知（SAM）方法，通过控制优化器的梯度来实现在性能和极性之间的权衡。</li>
<li>results: 实验证明GCSCoOp方法可以在视语模型中实现在性能和极性之间的权衡，并且在不同的预测任务上具有显著的优势。<details>
<summary>Abstract</summary>
This paper targets a novel trade-off problem in generalizable prompt learning for vision-language models (VLM), i.e., improving the performance on unseen classes while maintaining the performance on seen classes. Comparing with existing generalizable methods that neglect the seen classes degradation, the setting of this problem is more strict and fits more closely with practical applications. To solve this problem, we start from the optimization perspective, and leverage the relationship between loss landscape geometry and model generalization ability. By analyzing the loss landscapes of the state-of-the-art method and vanilla Sharpness-aware Minimization (SAM) based method, we conclude that the trade-off performance correlates to both loss value and loss sharpness, while each of them is indispensable. However, we find the optimizing gradient of existing methods cannot maintain high relevance to both loss value and loss sharpness during optimization, which severely affects their trade-off performance. To this end, we propose a novel SAM-based method for prompt learning, denoted as Gradient Constrained Sharpness-aware Context Optimization (GCSCoOp), to dynamically constrain the optimizing gradient, thus achieving above two-fold optimization objective simultaneously. Extensive experiments verify the effectiveness of GCSCoOp in the trade-off problem.
</details>
<details>
<summary>摘要</summary>
We compare the loss landscapes of state-of-the-art methods and vanilla Sharpness-aware Minimization (SAM) based methods, and find that the trade-off performance is correlated to both loss value and loss sharpness, but each of them is essential. However, we discover that existing methods cannot maintain high relevance to both loss value and loss sharpness during optimization, which severely affects their trade-off performance.To address this issue, we propose a novel SAM-based method for prompt learning, called Gradient Constrained Sharpness-aware Context Optimization (GCSCoOp), which dynamically constrains the optimizing gradient to achieve both performance objectives simultaneously. Extensive experiments demonstrate the effectiveness of GCSCoOp in the trade-off problem.In summary, this paper targets a novel trade-off problem in VLM prompt learning, and proposes a novel SAM-based method (GCSCoOp) to solve this problem by dynamically constraining the optimizing gradient. The proposed method achieves better trade-off performance than existing methods.
</details></li>
</ul>
<hr>
<h2 id="TFNet-Exploiting-Temporal-Cues-for-Fast-and-Accurate-LiDAR-Semantic-Segmentation"><a href="#TFNet-Exploiting-Temporal-Cues-for-Fast-and-Accurate-LiDAR-Semantic-Segmentation" class="headerlink" title="TFNet: Exploiting Temporal Cues for Fast and Accurate LiDAR Semantic Segmentation"></a>TFNet: Exploiting Temporal Cues for Fast and Accurate LiDAR Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07849">http://arxiv.org/abs/2309.07849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rong Li, ShiJie Li, Xieyuanli Chen, Teli Ma, Wang Hao, Juergen Gall, Junwei Liang</li>
<li>for: 这篇论文旨在提高 LiDAR  semantic segmentation 的精度和可靠性，以便自动驾驶和机器人更好地理解它们周围环境。</li>
<li>methods: 这篇论文提出了一种基于范围图像的 LiDAR semantic segmentation 方法，使用时间信息来解决“多到一”问题。特别是，我们在抽象层中添加了时间混合层，将前一批扫描结果与当前扫描结果进行混合，以提高精度。</li>
<li>results: 我们在两个标准评测 dataset 上进行了评测，并证明了我们的后处理技术可以适应不同的网络。我们的方法可以减少约20%的点云 occlusion，提高 semantic segmentation 的精度和可靠性。<details>
<summary>Abstract</summary>
LiDAR semantic segmentation plays a crucial role in enabling autonomous driving and robots to understand their surroundings accurately and robustly. There are different types of methods, such as point-based, range-image-based, polar-based, and hybrid methods. Among these, range-image-based methods are widely used due to their efficiency. However, they face a significant challenge known as the ``many-to-one'' problem caused by the range image's limited horizontal and vertical angular resolution. As a result, around 20\% of the 3D points can be occluded. In this paper, we present TFNet, a range-image-based LiDAR semantic segmentation method that utilizes temporal information to address this issue. Specifically, we incorporate a temporal fusion layer to extract useful information from previous scans and integrate it with the current scan. We then design a max-voting-based post-processing technique to correct false predictions, particularly those caused by the ``many-to-one'' issue. We evaluated the approach on two benchmarks and demonstrate that the post-processing technique is generic and can be applied to various networks. We will release our code and models.
</details>
<details>
<summary>摘要</summary>
lidar semantic segmentation 在自动驾驶和机器人理解境外环境的准确性和稳定性方面扮演着关键性的角色。有多种方法，如点云、范围图像、极坐标基本方法和混合方法。其中，范围图像基本方法因其高效性而广泛使用，但它们面临着“多个对一”问题，即范围图像的水平和垂直angular resolution有限，导致约20%的3D点被遮盖。在本文中，我们提出了TFNet，一种基于范围图像的 LiDAR semantic segmentation 方法，利用时间信息解决这个问题。具体来说，我们添加了时间融合层，从前一批扫描中提取有用信息，并与当前扫描结合。然后，我们设计了最大投票基本的后处理技术，以 corrrect false predictions，特别是由“多个对一”问题引起的错误预测。我们在两个标准准点上评估了方法，并证明了后处理技术可以应用于多种网络。我们将发布代码和模型。
</details></li>
</ul>
<hr>
<h2 id="MC-NeRF-Muti-Camera-Neural-Radiance-Fields-for-Muti-Camera-Image-Acquisition-Systems"><a href="#MC-NeRF-Muti-Camera-Neural-Radiance-Fields-for-Muti-Camera-Image-Acquisition-Systems" class="headerlink" title="MC-NeRF: Muti-Camera Neural Radiance Fields for Muti-Camera Image Acquisition Systems"></a>MC-NeRF: Muti-Camera Neural Radiance Fields for Muti-Camera Image Acquisition Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07846">http://arxiv.org/abs/2309.07846</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IN2-ViAUn/MC-NeRF">https://github.com/IN2-ViAUn/MC-NeRF</a></li>
<li>paper_authors: Yu Gao, Lutong Su, Hao Liang, Yufeng Yue, Yi Yang, Mengyin Fu</li>
<li>for: 用于3D场景表示和NeRF的多视图图像处理</li>
<li>methods: 提出了一种能够同时优化内部和外部参数的MC-NeRF方法，包括对叠加问题的理论分析和高效的投影网络</li>
<li>results: 实验表明MC-NeRF方法能够在不提供初始姿态的情况下，使用110张图像和110个不同的内部和外部参数来获得3D场景表示<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) employ multi-view images for 3D scene representation and have shown remarkable performance. As one of the primary sources of multi-view images, multi-camera systems encounter challenges such as varying intrinsic parameters and frequent pose changes. Most previous NeRF-based methods often assume a global unique camera and seldom consider scenarios with multiple cameras. Besides, some pose-robust methods still remain susceptible to suboptimal solutions when poses are poor initialized. In this paper, we propose MC-NeRF, a method can jointly optimize both intrinsic and extrinsic parameters for bundle-adjusting Neural Radiance Fields. Firstly, we conduct a theoretical analysis to tackle the degenerate case and coupling issue that arise from the joint optimization between intrinsic and extrinsic parameters. Secondly, based on the proposed solutions, we introduce an efficient calibration image acquisition scheme for multi-camera systems, including the design of calibration object. Lastly, we present a global end-to-end network with training sequence that enables the regression of intrinsic and extrinsic parameters, along with the rendering network. Moreover, most existing datasets are designed for unique camera, we create a new dataset that includes four different styles of multi-camera acquisition systems, allowing readers to generate custom datasets. Experiments confirm the effectiveness of our method when each image corresponds to different camera parameters. Specifically, we adopt up to 110 images with 110 different intrinsic and extrinsic parameters, to achieve 3D scene representation without providing initial poses. The Code and supplementary materials are available at https://in2-viaun.github.io/MC-NeRF.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRF) 使用多视图图像表示3D场景，并显示出杰出的性能。多摄像头系统面临多个挑战，包括不同的内参参数和频繁的pose变化。大多数前一代NeRF基于方法通常假设全局唯一的摄像头，并rarely考虑多摄像头场景。此外，一些pose鲁棒的方法仍然容易受到差初始化的pose的影响。在这篇论文中，我们提出MC-NeRF方法，可以同时优化内参和外参参数，为Neural Radiance Fields进行束致调整。首先，我们进行理论分析，解决由共同优化内参和外参参数而产生的协调问题和缺失问题。其次，我们提出了一种高效的准备图像采集方案，包括设计准备对象。最后，我们介绍了一个全球端到端网络，可以对内参和外参参数进行回归，同时实现图像渲染。此外，大多数现有的数据集都是为唯一摄像头设计的，我们创建了一个新的数据集，包括四种不同的多摄像头采集系统风格，让读者可以生成自定义数据集。实验证明我们的方法在每个图像对应不同的摄像头参数时显示出效果。具体来说，我们采用了110张图像，每张图像对应110个内参和外参参数，以实现3D场景表示，无需提供初始pose。代码和补充材料可以在https://in2-viaun.github.io/MC-NeRF上获取。
</details></li>
</ul>
<hr>
<h2 id="Decomposition-of-linear-tensor-transformations"><a href="#Decomposition-of-linear-tensor-transformations" class="headerlink" title="Decomposition of linear tensor transformations"></a>Decomposition of linear tensor transformations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07819">http://arxiv.org/abs/2309.07819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Claudio Turchetti</li>
<li>for: 这篇论文的目的是开发一种数学框架，用于精确地 decomposes a tensor as the sum of a finite number of low-rank tensors。</li>
<li>methods: 该论文使用的方法包括： solving an optimization problem to find a low-dimensional subspace, and assuming the number of components is fixed。</li>
<li>results: 该论文的结果包括： deriving three different problems to decompose a non-negative self-adjoint tensor operator, a linear tensor transformation, and a generic tensor。<details>
<summary>Abstract</summary>
One of the main issues in computing a tensor decomposition is how to choose the number of rank-one components, since there is no finite algorithms for determining the rank of a tensor. A commonly used approach for this purpose is to find a low-dimensional subspace by solving an optimization problem and assuming the number of components is fixed. However, even though this algorithm is efficient and easy to implement, it often converges to poor local minima and suffers from outliers and noise. The aim of this paper is to develop a mathematical framework for exact tensor decomposition that is able to represent a tensor as the sum of a finite number of low-rank tensors. In the paper three different problems will be carried out to derive: i) the decomposition of a non-negative self-adjoint tensor operator; ii) the decomposition of a linear tensor transformation; iii) the decomposition of a generic tensor.
</details>
<details>
<summary>摘要</summary>
一个主要问题在计算张量归一化是选择张量的级数，因为没有定finite的算法来确定张量的级数。一种常用的方法是通过解一个优化问题来找到一个低维度子空间，假设级数是固定的。然而，即使这种算法是效率高且易于实现，它经常会收敛到差异性和噪声的局部最优点，并且受到噪声和噪声的影响。本文的目标是开发一种数学框架，可以表示张量为一些有限级的低维度张量的和。在本文中，将解决以下三个问题：1. 非正式自Symmetric tensor operator的归一化分解;2. 线性张量变换的归一化分解;3. 一般张量的归一化分解。
</details></li>
</ul>
<hr>
<h2 id="For-A-More-Comprehensive-Evaluation-of-6DoF-Object-Pose-Tracking"><a href="#For-A-More-Comprehensive-Evaluation-of-6DoF-Object-Pose-Tracking" class="headerlink" title="For A More Comprehensive Evaluation of 6DoF Object Pose Tracking"></a>For A More Comprehensive Evaluation of 6DoF Object Pose Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07796">http://arxiv.org/abs/2309.07796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Fan Zhong, Xin Wang, Shuangbing Song, Jiachen Li, Xueying Qin, Changhe Tu</li>
<li>for: 本研究旨在提供一个统一的对比方法，以解决6DoF物体pose追踪的评估问题。</li>
<li>methods: 本研究提出了一种多视图多物体全pose精确调整方法，可以同时精确调整所有物体和摄像头的 pose，实现sub-pixel sub-millimeter的对齐误差。</li>
<li>results: 本研究透过实验验证了提案的全pose精确调整方法的精度和可靠性，并在YCBV和BCOT两个基本数据集上进行了统一的评估。 results show that the proposed method outperforms previous methods in terms of accuracy and robustness.<details>
<summary>Abstract</summary>
Previous evaluations on 6DoF object pose tracking have presented obvious limitations along with the development of this area. In particular, the evaluation protocols are not unified for different methods, the widely-used YCBV dataset contains significant annotation error, and the error metrics also may be biased. As a result, it is hard to fairly compare the methods, which has became a big obstacle for developing new algorithms. In this paper we contribute a unified benchmark to address the above problems. For more accurate annotation of YCBV, we propose a multi-view multi-object global pose refinement method, which can jointly refine the poses of all objects and view cameras, resulting in sub-pixel sub-millimeter alignment errors. The limitations of previous scoring methods and error metrics are analyzed, based on which we introduce our improved evaluation methods. The unified benchmark takes both YCBV and BCOT as base datasets, which are shown to be complementary in scene categories. In experiments, we validate the precision and reliability of the proposed global pose refinement method with a realistic semi-synthesized dataset particularly for YCBV, and then present the benchmark results unifying learning&non-learning and RGB&RGBD methods, with some finds not discovered in previous studies.
</details>
<details>
<summary>摘要</summary>
In this paper, we contribute a unified benchmark to address these problems. We propose a multi-view multi-object global pose refinement method that can jointly refine the poses of all objects and view cameras, resulting in sub-pixel sub-millimeter alignment errors. We also analyze the limitations of previous scoring methods and error metrics and introduce improved evaluation methods.The unified benchmark uses both YCBV and BCOT as base datasets, which are shown to be complementary in scene categories. In experiments, we validate the precision and reliability of the proposed global pose refinement method with a realistic semi-synthesized dataset particularly for YCBV, and then present the benchmark results unifying learning&non-learning and RGB&RGBD methods. Our findings reveal some new insights that were not discovered in previous studies.Translated into Simplified Chinese:前期评估6DoF对象pose追踪技术已经存在了明显的限制，这些限制障碍了这一领域的发展。特别是评估协议没有统一的，广泛使用的YCBV数据集中存在了重要的注释错误，而且错误指标也可能受到偏见。这使得不能公正地比较不同的方法，成为了大型算法开发的主要障碍。在本文中，我们提出了一个统一的评估标准，以解决这些问题。我们提议一种多视图多对象全 pose 精度修正方法，可以同时修正所有对象和视角摄像头的pose，从而实现sub-pixel sub-millimeter的Alignment Error。我们还分析了过去评估方法和指标的限制，并在基于这些分析结果提出了改进的评估方法。统一评估标准使用了YCBV和BCOT作为基本数据集，这些数据集在场景类型上是补偿的。在实验中，我们验证了提posed的全 pose 精度修正方法的准确性和可靠性，使用了特制的半Synthesized数据集，尤其是YCBV，然后公布了统一的评估结果，包括学习&非学习和RGB&RGBD方法的比较。我们的发现包括一些在过去的研究中没有发现的新发现。
</details></li>
</ul>
<hr>
<h2 id="Virchow-A-Million-Slide-Digital-Pathology-Foundation-Model"><a href="#Virchow-A-Million-Slide-Digital-Pathology-Foundation-Model" class="headerlink" title="Virchow: A Million-Slide Digital Pathology Foundation Model"></a>Virchow: A Million-Slide Digital Pathology Foundation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07778">http://arxiv.org/abs/2309.07778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eugene Vorontsov, Alican Bozkurt, Adam Casson, George Shaikovski, Michal Zelechowski, Siqi Liu, Philippe Mathieu, Alexander van Eck, Donghun Lee, Julian Viret, Eric Robert, Yi Kan Wang, Jeremy D. Kunz, Matthew C. H. Lee, Jan Bernhard, Ran A. Godrich, Gerard Oakley, Ewan Millar, Matthew Hanna, Juan Retamero, William A. Moye, Razik Yousfi, Christopher Kanan, David Klimstra, Brandon Rothrock, Thomas J. Fuchs<br>for: 这个论文旨在提高计算 PATHOLOGY 中的人工智能应用，以实现精准医疗和决策支持系统，特别是在诊断和治疗癌症方面。methods: 这篇论文使用了自然语言处理技术，通过对整个染色片图像进行分析，来实现计算 PATHOLOGY 的目标。具体来说，他们使用了一个名为 Virchow 的深度神经网络基础模型，通过自我超vised学习来训练该模型，并使用了150万张染色片图像来进行训练。results: 根据论文的报告，使用 Virchow 模型可以在许多计算 PATHOLOGY 任务中获得出色的表现，包括板块级普ancer检测和分类、板块级生物标志预测等。模型的性能达到了93%的平衡准确率，并且在colon microsatellite instability status预测和Breast CDH1 status预测等任务中获得了0.983的AUC和0.967的AUC。这些表现表明，通过在大量的病理图像数据集上进行预训练，可以提高计算 PATHOLOGY 中的表现，并且可能会继续提高表现，如果进一步采用更大的数据集进行预训练。<details>
<summary>Abstract</summary>
Computational pathology uses artificial intelligence to enable precision medicine and decision support systems through the analysis of whole slide images. It has the potential to revolutionize the diagnosis and treatment of cancer. However, a major challenge to this objective is that for many specific computational pathology tasks the amount of data is inadequate for development. To address this challenge, we created Virchow, a 632 million parameter deep neural network foundation model for computational pathology. Using self-supervised learning, Virchow is trained on 1.5 million hematoxylin and eosin stained whole slide images from diverse tissue groups, which is orders of magnitude more data than previous works. When evaluated on downstream tasks including tile-level pan-cancer detection and subtyping and slide-level biomarker prediction, Virchow outperforms state-of-the-art systems both on internal datasets drawn from the same population as the pretraining data as well as external public datasets. Virchow achieves 93% balanced accuracy for pancancer tile classification, and AUCs of 0.983 for colon microsatellite instability status prediction and 0.967 for breast CDH1 status prediction. The gains in performance highlight the importance of pretraining on massive pathology image datasets, suggesting pretraining on even larger datasets could continue improving performance for many high-impact applications where limited amounts of training data are available, such as drug outcome prediction.
</details>
<details>
<summary>摘要</summary>
computacional patología utiliza inteligencia artificial para permitir medicina de precisión y sistemas de soporte de decisión a través del análisis de imágenes enteras de técnicas. tiene el potencial de revolucionar el diagnóstico y el tratamiento del cáncer. sin embargo, un desafío importante para este objetivo es que para muchos tareas específicas de computacional patología, la cantidad de datos es insuficiente para el desarrollo. para abordar este desafío, creamos Virchow, un modelo de red neuronal profunda de 632 millones de parámetros para computacional patología. utilizando aprendizaje auto-supervisado, Virchow se entrenó en 1,5 millones de imágenes enteras de técnicas hematoxylin y eosin de grupos de tejidos diversas, lo que es órdenes de magnitud más datos que trabajos anteriores. cuando se evaluó en tareas downstream, incluyendo la detección y clasificación de paneles de cáncer y la predicción de marcadores en las placas, Virchow superó a sistemas de estado del arte en datos internos y externos. Virchow obtuvo una precisión equilibrada del 93% para la clasificación de paneles de cáncer, y áreas bajo el 0,983 para la predicción de la status de instabilidad microsatélite en el colon y el 0,967 para la predicción de la status de CDH1 en el seno. los ganancias en rendimiento destacan la importancia de preentrenar en conjuntos de datos de imágenes patológicas masivos, sugiriendo que preentrenar en conjuntos de datos aún más grandes podría continuar mejorando el rendimiento para muchas aplicaciones de alto impacto en las que se tienen cantidades limitadas de datos de entrenamiento.
</details></li>
</ul>
<hr>
<h2 id="Co-Salient-Object-Detection-with-Semantic-Level-Consensus-Extraction-and-Dispersion"><a href="#Co-Salient-Object-Detection-with-Semantic-Level-Consensus-Extraction-and-Dispersion" class="headerlink" title="Co-Salient Object Detection with Semantic-Level Consensus Extraction and Dispersion"></a>Co-Salient Object Detection with Semantic-Level Consensus Extraction and Dispersion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07753">http://arxiv.org/abs/2309.07753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiran Xu, Yadong Mu</li>
<li>for: 高级对象检测（CoSOD）任务的目的是在每个图像中强调共同突出的对象。</li>
<li>methods: 我们使用层次结构的Transformer模块来提取 semantic-level的共识，从而更好地捕捉共同对象类别的全面表示，并 exclude 其他对象的本地相似性干扰。 我们还提出了基于Transformer的分布模块，该模块考虑了不同场景中共同对象的变化。它在图像特征地图上分布了共识，并且利用图像之间的交互来全面利用图像特征。</li>
<li>results: 我们在三个常用的CoSOD数据集上进行评估，并达到了当前最佳性能。<details>
<summary>Abstract</summary>
Given a group of images, co-salient object detection (CoSOD) aims to highlight the common salient object in each image. There are two factors closely related to the success of this task, namely consensus extraction, and the dispersion of consensus to each image. Most previous works represent the group consensus using local features, while we instead utilize a hierarchical Transformer module for extracting semantic-level consensus. Therefore, it can obtain a more comprehensive representation of the common object category, and exclude interference from other objects that share local similarities with the target object. In addition, we propose a Transformer-based dispersion module that takes into account the variation of the co-salient object in different scenes. It distributes the consensus to the image feature maps in an image-specific way while making full use of interactions within the group. These two modules are integrated with a ViT encoder and an FPN-like decoder to form an end-to-end trainable network, without additional branch and auxiliary loss. The proposed method is evaluated on three commonly used CoSOD datasets and achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
给定一组图像，共同突出物检测（CoSOD）目标是将每个图像中的共同突出物高亮显示出来。这个任务的成功取决于两个因素：一是共识EXTRACTION，二是共识的分布到每个图像中。大多数前一代方法使用本地特征来表示群组共识，而我们则使用层次Transformer模块来提取semantic级共识。这可以获得更全面的共同对象类划分，并排除其他对象的本地相似性干扰。此外，我们提议使用Transformer基于的分布模块，该模块考虑了不同场景中共同突出物的变化。它在图像特征图中分布共识，并且利用图像之间的交互来实现图像特征图中的分布。这两个模块与ViT编码器和FPN-like解码器集成，形成一个端到端可训练的网络，不需要额外支持和副任务损失。我们的方法在三个常用CoSOD数据集上进行评估，并达到了当前最佳性能。
</details></li>
</ul>
<hr>
<h2 id="DT-NeRF-Decomposed-Triplane-Hash-Neural-Radiance-Fields-for-High-Fidelity-Talking-Portrait-Synthesis"><a href="#DT-NeRF-Decomposed-Triplane-Hash-Neural-Radiance-Fields-for-High-Fidelity-Talking-Portrait-Synthesis" class="headerlink" title="DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis"></a>DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07752">http://arxiv.org/abs/2309.07752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaoyu Su, Shaohui Wang, Haoqian Wang</li>
<li>for: 提高人脸朗读的实时渲染效果</li>
<li>methods: 使用特殊的三面体 decomposition 和 Neural Radiance Fields (NeRF) 技术</li>
<li>results: 实现人脸朗读的State-of-the-art 结果<details>
<summary>Abstract</summary>
In this paper, we present the decomposed triplane-hash neural radiance fields (DT-NeRF), a framework that significantly improves the photorealistic rendering of talking faces and achieves state-of-the-art results on key evaluation datasets. Our architecture decomposes the facial region into two specialized triplanes: one specialized for representing the mouth, and the other for the broader facial features. We introduce audio features as residual terms and integrate them as query vectors into our model through an audio-mouth-face transformer. Additionally, our method leverages the capabilities of Neural Radiance Fields (NeRF) to enrich the volumetric representation of the entire face through additive volumetric rendering techniques. Comprehensive experimental evaluations corroborate the effectiveness and superiority of our proposed approach.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了分解三平面哈希神经辐射场（DT-NeRF），一种框架，可以大幅提高描述讲话脸部的真实渲染效果，并在关键评估数据集上达到状态之最的结果。我们的架构将脸部分成两个特殊的三平面：一个专门用于表示嘴，另一个用于更广泛的脸部特征。我们引入音频特征作为剩余项，并通过音频-口型-脸部变换器将其纳入我们的模型。此外，我们的方法利用神经辐射场（NeRF）的能力，通过添加卷积渲染技术，进一步丰富脸部的材料表示。经过全面的实验评估，我们的提议方法的效果和优势得到了证明。
</details></li>
</ul>
<hr>
<h2 id="OmnimatteRF-Robust-Omnimatte-with-3D-Background-Modeling"><a href="#OmnimatteRF-Robust-Omnimatte-with-3D-Background-Modeling" class="headerlink" title="OmnimatteRF: Robust Omnimatte with 3D Background Modeling"></a>OmnimatteRF: Robust Omnimatte with 3D Background Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07749">http://arxiv.org/abs/2309.07749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geng Lin, Chen Gao, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, Ayush Saraf</li>
<li>for: 这 paper 是为了提出一种新的视频分割方法，以提高现实世界视频中的背景和前景分割精度。</li>
<li>methods: 该 paper 使用了 OmnimatteRF 方法，该方法结合了动态 2D 前景层和 3D 背景模型，以保留视频中主题的细节，并在实际视频中坚定重建场景。</li>
<li>results: 广泛的实验表明，OmnimatteRF 方法能够在各种视频中提供更高质量的场景重建。<details>
<summary>Abstract</summary>
Video matting has broad applications, from adding interesting effects to casually captured movies to assisting video production professionals. Matting with associated effects such as shadows and reflections has also attracted increasing research activity, and methods like Omnimatte have been proposed to separate dynamic foreground objects of interest into their own layers. However, prior works represent video backgrounds as 2D image layers, limiting their capacity to express more complicated scenes, thus hindering application to real-world videos. In this paper, we propose a novel video matting method, OmnimatteRF, that combines dynamic 2D foreground layers and a 3D background model. The 2D layers preserve the details of the subjects, while the 3D background robustly reconstructs scenes in real-world videos. Extensive experiments demonstrate that our method reconstructs scenes with better quality on various videos.
</details>
<details>
<summary>摘要</summary>
视频幕制有广泛的应用，从加入有趣的效果到casually captured movies 到协助视频制作专业人员。与关联的效果，如阴影和反射，一起吸引了增加研究活动，而方法如 Omnimatte 已经被提议来分离动态前景对象。但先前的工作 Represent video backgrounds as 2D image layers，限制了它们表达更复杂的场景，因此阻碍了应用于实际视频。在这篇论文中，我们提出了一种新的视频幕制方法，OmnimatteRF，它结合动态2D前景层和3D背景模型。2D层保留主题的细节，而3D背景坚定地重建了实际视频中的场景。广泛的实验表明，我们的方法可以在各种视频中重建场景质量更高。
</details></li>
</ul>
<hr>
<h2 id="Dataset-Condensation-via-Generative-Model"><a href="#Dataset-Condensation-via-Generative-Model" class="headerlink" title="Dataset Condensation via Generative Model"></a>Dataset Condensation via Generative Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07698">http://arxiv.org/abs/2309.07698</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Junhao Zhang, Heng Wang, Chuhui Xue, Rui Yan, Wenqing Zhang, Song Bai, Mike Zheng Shou</li>
<li>for: 本研究旨在适应大规模 dataset 的 condensation，以减少训练样本数量，提高模型的训练速度和性能。</li>
<li>methods: 本研究提出了一种基于生成模型的 condensation 方法，通过将 dataset 转换为生成模型的形式，使得 condensation 可以适应大规模 dataset 和多种类别。该方法还提出了 intra-class 和 inter-class 损失函数，以保证 condensation 后的样本具有多样性和抗预测性。</li>
<li>results:  Comparative studies with state-of-the-art methods and ablation studies confirm the effectiveness of the proposed method and its individual components. 本研究成功地应用于 ImageNet-1k  dataset，并显示了与传统方法相比的性能提升。<details>
<summary>Abstract</summary>
Dataset condensation aims to condense a large dataset with a lot of training samples into a small set. Previous methods usually condense the dataset into the pixels format. However, it suffers from slow optimization speed and large number of parameters to be optimized. When increasing image resolutions and classes, the number of learnable parameters grows accordingly, prohibiting condensation methods from scaling up to large datasets with diverse classes. Moreover, the relations among condensed samples have been neglected and hence the feature distribution of condensed samples is often not diverse. To solve these problems, we propose to condense the dataset into another format, a generative model. Such a novel format allows for the condensation of large datasets because the size of the generative model remains relatively stable as the number of classes or image resolution increases. Furthermore, an intra-class and an inter-class loss are proposed to model the relation of condensed samples. Intra-class loss aims to create more diverse samples for each class by pushing each sample away from the others of the same class. Meanwhile, inter-class loss increases the discriminability of samples by widening the gap between the centers of different classes. Extensive comparisons with state-of-the-art methods and our ablation studies confirm the effectiveness of our method and its individual component. To our best knowledge, we are the first to successfully conduct condensation on ImageNet-1k.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CoRF-Colorizing-Radiance-Fields-using-Knowledge-Distillation"><a href="#CoRF-Colorizing-Radiance-Fields-using-Knowledge-Distillation" class="headerlink" title="CoRF : Colorizing Radiance Fields using Knowledge Distillation"></a>CoRF : Colorizing Radiance Fields using Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07668">http://arxiv.org/abs/2309.07668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ankit Dhiman, R Srinath, Srinjay Sarkar, Lokesh R Boregowda, R Venkatesh Babu</li>
<li>for: Synthesizing colorized novel views from input grey-scale multi-view images.</li>
<li>methods: 使用NeRF基于方法实现高质量的多视图图像新观 synthesis.</li>
<li>results: 比基eline提供更高质量的彩色化新视图图像，同时保持cross-view consistency.<details>
<summary>Abstract</summary>
Neural radiance field (NeRF) based methods enable high-quality novel-view synthesis for multi-view images. This work presents a method for synthesizing colorized novel views from input grey-scale multi-view images. When we apply image or video-based colorization methods on the generated grey-scale novel views, we observe artifacts due to inconsistency across views. Training a radiance field network on the colorized grey-scale image sequence also does not solve the 3D consistency issue. We propose a distillation based method to transfer color knowledge from the colorization networks trained on natural images to the radiance field network. Specifically, our method uses the radiance field network as a 3D representation and transfers knowledge from existing 2D colorization methods. The experimental results demonstrate that the proposed method produces superior colorized novel views for indoor and outdoor scenes while maintaining cross-view consistency than baselines. Further, we show the efficacy of our method on applications like colorization of radiance field network trained from 1.) Infra-Red (IR) multi-view images and 2.) Old grey-scale multi-view image sequences.
</details>
<details>
<summary>摘要</summary>
neuronal radiance field (NeRF) 方法可以实现高质量的新视图合成 для多视图图像。这项工作提出了从输入灰度多视图图像中生成彩色化的新视图的方法。当我们应用图像或视频基于色化方法于生成的灰度新视图中时，我们会 observer artifacts due to inconsistency across views。训练 radiance field 网络在颜色化的灰度图像序列上也不能解决3D consistency issue。我们提出了一种液态基于方法，将自然图像中的颜色知识传递给 radiance field 网络。具体来说，我们的方法使用 radiance field 网络作为3D表示，并将自然图像中的颜色化方法中的知识传递给它。实验结果表明，我们提出的方法可以在indoor和outdoor场景中生成高质量的彩色化新视图，同时保持视图间的一致性。此外，我们还证明了我们的方法在以下两个应用中的效果：1.) 红外（IR）多视图图像和2.) 老灰度多视图图像序列中进行颜色化。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-and-Unconstrained-Full-Range-of-Rotation-Head-Pose-Estimation"><a href="#Towards-Robust-and-Unconstrained-Full-Range-of-Rotation-Head-Pose-Estimation" class="headerlink" title="Towards Robust and Unconstrained Full Range of Rotation Head Pose Estimation"></a>Towards Robust and Unconstrained Full Range of Rotation Head Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07654">http://arxiv.org/abs/2309.07654</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thohemp/6drepnet360">https://github.com/thohemp/6drepnet360</a></li>
<li>paper_authors: Thorsten Hempel, Ahmed A. Abdelrahman, Ayoub Al-Hamadi</li>
<li>for: 这篇论文是用于解决人体头部pose预测问题的，这是许多应用场景中的一个关键问题，但目前主要被视为前置 pose 预测的一个子任务。</li>
<li>methods: 我们提出了一种新的无约束端到端头部pose预测方法，用于解决极具挑战性的全范围orientation head pose预测问题。我们在ground truth数据中引入了旋转矩阵 formalism，并提议了一种连续的6D旋转矩阵表示方式，以便高效地学习整个旋转表现和超越当前状态艺。</li>
<li>results: 我们的方法在公共数据集上进行了广泛的评估，并证明了与其他状态艺方法相比，它在高效和可靠的情况下显著超越了其他方法，而且其先进的预测范围允许扩展应用领域。我们将训练和测试代码以及我们训练过的模型公开在 GitHub：<a target="_blank" rel="noopener" href="https://github.com/thohemp/6DRepNet360%E3%80%82">https://github.com/thohemp/6DRepNet360。</a><details>
<summary>Abstract</summary>
Estimating the head pose of a person is a crucial problem for numerous applications that is yet mainly addressed as a subtask of frontal pose prediction. We present a novel method for unconstrained end-to-end head pose estimation to tackle the challenging task of full range of orientation head pose prediction. We address the issue of ambiguous rotation labels by introducing the rotation matrix formalism for our ground truth data and propose a continuous 6D rotation matrix representation for efficient and robust direct regression. This allows to efficiently learn full rotation appearance and to overcome the limitations of the current state-of-the-art. Together with new accumulated training data that provides full head pose rotation data and a geodesic loss approach for stable learning, we design an advanced model that is able to predict an extended range of head orientations. An extensive evaluation on public datasets demonstrates that our method significantly outperforms other state-of-the-art methods in an efficient and robust manner, while its advanced prediction range allows the expansion of the application area. We open-source our training and testing code along with our trained models: https://github.com/thohemp/6DRepNet360.
</details>
<details>
<summary>摘要</summary>
“估算人姿pose是许多应用中的关键问题，然而现在主要被视为前方姿态预测的子任务。我们提出了一种新的方法，用于无条件端到端的人姿pose估算，以解决困难的全角度姿态预测问题。我们为我们的真实数据引入了旋转矩阵 formalism，并提出了连续的6D旋转矩阵表示，以实现高效和稳定的直接预测。这允许我们高效地学习全旋转样式，并超越现有的状态顶峰。furthermore，我们新增了大量的全头姿态资料，并使用地odesic损失函数，以确保稳定的学习。我们设计了一个进步的模型，能够预测更广泛的头姿范围。实验结果显示，我们的方法与其他状态顶峰方法相比，在高效和稳定的情况下，有 statistically significant 的进步。此外，我们的预测范围的扩展，允许扩展应用领域。我们将训练和测试代码，以及我们训练的模型，公开发布在 GitHub 上：https://github.com/thohemp/6DRepNet360。”
</details></li>
</ul>
<hr>
<h2 id="Indoor-Scene-Reconstruction-with-Fine-Grained-Details-Using-Hybrid-Representation-and-Normal-Prior-Enhancement"><a href="#Indoor-Scene-Reconstruction-with-Fine-Grained-Details-Using-Hybrid-Representation-and-Normal-Prior-Enhancement" class="headerlink" title="Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid Representation and Normal Prior Enhancement"></a>Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid Representation and Normal Prior Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07640">http://arxiv.org/abs/2309.07640</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sheng Ye, Yubin Hu, Matthieu Lin, Yu-Hui Wen, Wang Zhao, Wenping Wang, Yong-Jin Liu</li>
<li>for: 这 paper 的目的是 reconstruction indoor scene 从多视图 RGB 图像中。</li>
<li>methods: 这 paper 使用 neural radiance fields 和 predicted surface normal priors 来恢复场景的geometry。</li>
<li>results: 这 paper 的方法可以生成完整和平滑的结果，但是它们在复杂表面上受到限制，因为 implicit representation 不够表示高频结构。<details>
<summary>Abstract</summary>
The reconstruction of indoor scenes from multi-view RGB images is challenging due to the coexistence of flat and texture-less regions alongside delicate and fine-grained regions. Recent methods leverage neural radiance fields aided by predicted surface normal priors to recover the scene geometry. These methods excel in producing complete and smooth results for floor and wall areas. However, they struggle to capture complex surfaces with high-frequency structures due to the inadequate neural representation and the inaccurately predicted normal priors. To improve the capacity of the implicit representation, we propose a hybrid architecture to represent low-frequency and high-frequency regions separately. To enhance the normal priors, we introduce a simple yet effective image sharpening and denoising technique, coupled with a network that estimates the pixel-wise uncertainty of the predicted surface normal vectors. Identifying such uncertainty can prevent our model from being misled by unreliable surface normal supervisions that hinder the accurate reconstruction of intricate geometries. Experiments on the benchmark datasets show that our method significantly outperforms existing methods in terms of reconstruction quality.
</details>
<details>
<summary>摘要</summary>
重建室内场景从多视图RGB图像中是一项挑战，因为场景中存在平滑无 texture 的区域以及细节rich和细腻的区域。现有方法利用神经辐射场 aid by predicted surface normal priors来恢复场景几何。这些方法在 floor 和墙面上 producing complete and smooth results 表现出色。然而，它们在复杂的表面上 Capture high-frequency structures 困难，因为神经表示不够强大和预测的normal priors不准确。为了提高隐式表示能力，我们提议将低频和高频区域分别表示。为了提高normal priors，我们引入了一种简单 yet effective的图像锐化和减噪技术，并 coupling 一个网络来估算图像中每个像素的surface normal vector的uncertainty。这种uncertainty可以让我们的模型不会被不可靠的表面normal supervision mislead，从而精准地重建复杂的几何结构。实验表明，我们的方法与现有方法相比，在重建质量方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="SwitchGPT-Adapting-Large-Language-Models-for-Non-Text-Outputs"><a href="#SwitchGPT-Adapting-Large-Language-Models-for-Non-Text-Outputs" class="headerlink" title="SwitchGPT: Adapting Large Language Models for Non-Text Outputs"></a>SwitchGPT: Adapting Large Language Models for Non-Text Outputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07623">http://arxiv.org/abs/2309.07623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Wang, Bohan Zhuang, Qi Wu</li>
<li>for: This paper aims to bridge the gap between language models (LLMs) and modality conversion models, such as text-to-image, by proposing a novel approach that can adapt LLMs to comprehend requests for non-text responses.</li>
<li>methods: The proposed approach, called \methodname, employs a minimal dataset to instruct LLMs to recognize the intended output modality as directed by the instructions. The adapted LLM can then effectively summon various off-the-shelf modality conversion models from the model zoos to generate non-text responses.</li>
<li>results: The experiment results show that, with minimal training, LLMs can be conveniently adapted to comprehend requests for non-text responses, thus achieving higher flexibility in multi-modal scenarios.<details>
<summary>Abstract</summary>
Large Language Models (LLMs), primarily trained on text-based datasets, exhibit exceptional proficiencies in understanding and executing complex linguistic instructions via text outputs. However, they falter when requests to generate non-text ones. Concurrently, modality conversion models, such as text-to-image, despite generating high-quality images, suffer from a lack of extensive textual pretraining. As a result, these models are only capable of accommodating specific image descriptions rather than comprehending more complex instructions. To bridge this gap, we propose a novel approach, \methodname, from a modality conversion perspective that evolves a text-based LLM into a multi-modal one. We specifically employ a minimal dataset to instruct LLMs to recognize the intended output modality as directed by the instructions. Consequently, the adapted LLM can effectively summon various off-the-shelf modality conversion models from the model zoos to generate non-text responses. This circumvents the necessity for complicated pretraining that typically requires immense quantities of paired multi-modal data, while simultaneously inheriting the extensive knowledge of LLMs and the ability of high-quality generative models. To evaluate and compare the adapted multi-modal LLM with its traditional counterparts, we have constructed a multi-modal instruction benchmark that solicits diverse modality outputs. The experiment results reveal that, with minimal training, LLMs can be conveniently adapted to comprehend requests for non-text responses, thus achieving higher flexibility in multi-modal scenarios. Code and data will be made available at https://github.com/xinke-wang/SwitchGPT.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），主要基于文本数据集进行训练，在理解和执行复杂语言指令方面表现出色，但在产生非文本回应方面则有问题。同时，模式转换模型，如文本转像，优秀地生成高品质的图像，但由于缺乏广泛的文本预训，因此只能适应特定的图像描述，而不能理解更复杂的指令。为了跨越这个差距，我们提出了一个新的方法，\methodname，从模式转换角度来进行。我们specifically使用了一个最小的数据集，将LLMs教育到识别所需的输出模式，以实现对不同模式的认知。因此，已经适应了LLMs的改进后，可以从模型zoo中选择多种高品质的生成模型，以生成非文本回应。这样可以避免需要大量的对整合多个模式的预训，同时继承了LLMs的广泛知识和高品质生成模型的能力。为了评估和比较改进后的多个模式LMM，我们建立了一个多模式指令库， solicits多种模式的回应。实验结果显示，仅需要最小的训练，LLMs可以轻松地适应产生非文本回应，因此在多模式enario中得到更高的灵活性。代码和数据将会在https://github.com/xinke-wang/SwitchGPT中公开。
</details></li>
</ul>
<hr>
<h2 id="Road-Disease-Detection-based-on-Latent-Domain-Background-Feature-Separation-and-Suppression"><a href="#Road-Disease-Detection-based-on-Latent-Domain-Background-Feature-Separation-and-Suppression" class="headerlink" title="Road Disease Detection based on Latent Domain Background Feature Separation and Suppression"></a>Road Disease Detection based on Latent Domain Background Feature Separation and Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07616">http://arxiv.org/abs/2309.07616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juwu Zheng, Jiangtao Ren</li>
<li>for: 这篇论文目的是提出一种新的 Latent Domain Background Feature Separation and Suppression（LDBFSS）网络，用于减少背景信息的影响，提高道路疾病检测的准确率。</li>
<li>methods: 该论文提出了一种新的 LDBFSS 网络，包括幽默领域发现模块、领域对抗学习模块和对比学习模块。通过不需要领域监督和对比提高对象特征表示，LDBFSS 网络可以减少背景信息的影响，提高道路疾病检测的准确率。</li>
<li>results: 实验结果表明，与最佳模型相比，LDBFSS 网络在 GRDDC 数据集上提高了约4%，在 CNRDD 数据集上提高了4.6%。这些结果证明了 LDBFSS 网络的有效性和优越性。<details>
<summary>Abstract</summary>
Road disease detection is challenging due to the the small proportion of road damage in target region and the diverse background,which introduce lots of domain information.Besides, disease categories have high similarity,makes the detection more difficult. In this paper, we propose a new LDBFSS(Latent Domain Background Feature Separation and Suppression) network which could perform background information separation and suppression without domain supervision and contrastive enhancement of object features.We combine our LDBFSS network with YOLOv5 model to enhance disease features for better road disease detection. As the components of LDBFSS network, we first design a latent domain discovery module and a domain adversarial learning module to obtain pseudo domain labels through unsupervised method, guiding domain discriminator and model to train adversarially to suppress background information. In addition, we introduce a contrastive learning module and design k-instance contrastive loss, optimize the disease feature representation by increasing the inter-class distance and reducing the intra-class distance for object features. We conducted experiments on two road disease detection datasets, GRDDC and CNRDD, and compared with other models,which show an increase of nearly 4% on GRDDC dataset compared with optimal model, and an increase of 4.6% on CNRDD dataset. Experimental results prove the effectiveness and superiority of our model.
</details>
<details>
<summary>摘要</summary>
道路疾病检测具有较小的疾病占比和多样背景，这些背景信息会引入很多领域信息，使检测变得更加困难。在这篇论文中，我们提出了一种新的LDBFSS（幽默领域背景特征分离和抑制）网络，可以无需领域监督和强制对象特征进行增强，从而实现背景信息的分离和抑制。我们将LDBFSS网络与YOLOv5模型结合，以提高疾病特征的检测。LDBFSS网络的组成部分包括幽默领域发现模块和领域对抗学习模块，通过无监督方法获取 Pseudo 领域标签，引导领域推定器和模型进行对抗学习，以suppressBackground信息。此外，我们还引入了对比学习模块，并设计了k个实例对比损失，以优化疾病特征表示。我们在GRDDC和CNRDD两个道路疾病检测数据集上进行实验，与其他模型进行比较，结果显示，与优化模型相比，我们的模型在GRDDC数据集上增加了约4%的检测精度，在CNRDD数据集上增加了4.6%的检测精度。实验结果证明了我们的模型的有效性和优势。
</details></li>
</ul>
<hr>
<h2 id="Learning-Quasi-Static-3D-Models-of-Markerless-Deformable-Linear-Objects-for-Bimanual-Robotic-Manipulation"><a href="#Learning-Quasi-Static-3D-Models-of-Markerless-Deformable-Linear-Objects-for-Bimanual-Robotic-Manipulation" class="headerlink" title="Learning Quasi-Static 3D Models of Markerless Deformable Linear Objects for Bimanual Robotic Manipulation"></a>Learning Quasi-Static 3D Models of Markerless Deformable Linear Objects for Bimanual Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07609">http://arxiv.org/abs/2309.07609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ppi-put/neural_dlo_model">https://github.com/ppi-put/neural_dlo_model</a></li>
<li>paper_authors: Piotr Kicki, Michał Bidziński, Krzysztof Walas</li>
<li>for:  This paper focuses on the robotic manipulation of deformable linear objects (DLOs) and proposes a new learning-based 3D model based on the Transformer architecture to achieve superior accuracy.</li>
<li>methods: The paper uses several learning-based 3D models of DLOs and proposes a new one based on the Transformer architecture, as well as introduces a data augmentation technique to improve the prediction performance of the models.</li>
<li>results: The proposed model achieves superior accuracy on several challenging datasets, even on DLOs of different lengths, and demonstrates its applicability in the task of shaping a DLO.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文关注机器人控制弹性线性物体（DLO）的问题，并提出了基于Transformer架构的新的学习型3D模型，以实现超越性能。</li>
<li>methods: 论文使用了多种学习型3D模型，并提出了一种基于Transformer架构的新模型，同时引入了一种数据增强技术，以提高模型预测性能。</li>
<li>results: 提出的模型在多个复杂的数据集上表现出优于其他模型，并在DLO的不同长度下实现了超越性能，证明其在DLO的形状控制任务中的应用可行性。<details>
<summary>Abstract</summary>
The robotic manipulation of Deformable Linear Objects (DLOs) is a vital and challenging task that is important in many practical applications. Classical model-based approaches to this problem require an accurate model to capture how robot motions affect the deformation of the DLO. Nowadays, data-driven models offer the best tradeoff between quality and computation time. This paper analyzes several learning-based 3D models of the DLO and proposes a new one based on the Transformer architecture that achieves superior accuracy, even on the DLOs of different lengths, thanks to the proposed scaling method. Moreover, we introduce a data augmentation technique, which improves the prediction performance of almost all considered DLO data-driven models. Thanks to this technique, even a simple Multilayer Perceptron (MLP) achieves close to state-of-the-art performance while being significantly faster to evaluate. In the experiments, we compare the performance of the learning-based 3D models of the DLO on several challenging datasets quantitatively and demonstrate their applicability in the task of shaping a DLO.
</details>
<details>
<summary>摘要</summary>
机器人对弹性线性物体（DLO）的机械抓握是一项重要且挑战性较高的任务，在实际应用中具有重要意义。经典模型基本方法需要一个准确的模型来捕捉机器人运动对DLO的折叠效应。当今，数据驱动模型可以提供最佳的平衡点。本文分析了多种学习基于3D模型的DLO，并提出了基于Transformer架构的新模型，实现了更高精度，即使DLO的长度不同也是如此。此外，我们还引入了数据增强技术，该技术可以提高大多数考虑的DLO数据驱动模型的预测性能。这种技术使得简单的多层感知器（MLP）可以达到接近状态艺术的性能，而且评估速度快得多。在实验中，我们对learning基于3D模型的DLO的性能进行了评量，并在多个挑战性数据集上进行了比较，以示其在DLO形状 задании中的可行性。
</details></li>
</ul>
<hr>
<h2 id="Universality-of-underlying-mechanism-for-successful-deep-learning"><a href="#Universality-of-underlying-mechanism-for-successful-deep-learning" class="headerlink" title="Universality of underlying mechanism for successful deep learning"></a>Universality of underlying mechanism for successful deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07537">http://arxiv.org/abs/2309.07537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuval Meir, Yarden Tzach, Shiri Hodassman, Ofek Tevet, Ido Kanter</li>
<li>for: 提高深度学习模型的准确率和计算复杂度</li>
<li>methods: 使用单个滤波器的质量量化方法，找到小集合的可能输出标签，并通过层次进行进一步加工，提高信噪比和准确率</li>
<li>results: 验证了一种通用机制，可以提高VGG-16和EfficientNet-B0模型在CIFAR-100和ImageNet datasets上的准确率，并且显示了隐藏层数量和输出标签数量之间的关系。<details>
<summary>Abstract</summary>
An underlying mechanism for successful deep learning (DL) with a limited deep architecture and dataset, namely VGG-16 on CIFAR-10, was recently presented based on a quantitative method to measure the quality of a single filter in each layer. In this method, each filter identifies small clusters of possible output labels, with additional noise selected as labels out of the clusters. This feature is progressively sharpened with the layers, resulting in an enhanced signal-to-noise ratio (SNR) and higher accuracy. In this study, the suggested universal mechanism is verified for VGG-16 and EfficientNet-B0 trained on the CIFAR-100 and ImageNet datasets with the following main results. First, the accuracy progressively increases with the layers, whereas the noise per filter typically progressively decreases. Second, for a given deep architecture, the maximal error rate increases approximately linearly with the number of output labels. Third, the average filter cluster size and the number of clusters per filter at the last convolutional layer adjacent to the output layer are almost independent of the number of dataset labels in the range [3, 1,000], while a high SNR is preserved. The presented DL mechanism suggests several techniques, such as applying filter's cluster connections (AFCC), to improve the computational complexity and accuracy of deep architectures and furthermore pinpoints the simplification of pre-existing structures while maintaining their accuracies.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）中的一种基本机制，即VGG-16在CIFAR-10上的某些研究，提出了一种量化方法来衡量每个滤波器的质量。这种方法是，每个滤波器可以找到小 clusters of possible output labels，并且选择这些 clusters 中的陌生标签作为输出。这种特征逐渐增强，导致输出signal-to-noise ratio（SNR）的提高和更高的准确率。在这个研究中，这种建议的通用机制得到了VGG-16和EfficientNet-B0在CIFAR-100和ImageNet数据集上的验证，以下是主要的结果：1. 准确度逐渐增加，而噪音每个滤波器通常逐渐减少。2. 对于给定的深度架构，最大错误率随输出标签的数量 approximately 线性增加。3. 最后一层的卷积层附近的滤波器集群大小和每个滤波器的集群数量在[3, 1,000]个标签范围内基本不变，而保持高SNR。这种深度学习机制建议了一些技术，如应用滤波器集群连接（AFCC），以提高深度架构的计算复杂性和准确率，同时简化现有结构而保持其准确性。
</details></li>
</ul>
<hr>
<h2 id="Text-to-Image-Models-for-Counterfactual-Explanations-a-Black-Box-Approach"><a href="#Text-to-Image-Models-for-Counterfactual-Explanations-a-Black-Box-Approach" class="headerlink" title="Text-to-Image Models for Counterfactual Explanations: a Black-Box Approach"></a>Text-to-Image Models for Counterfactual Explanations: a Black-Box Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07944">http://arxiv.org/abs/2309.07944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillaume Jeanneret, Loïc Simon, Frédéric Jurie</li>
<li>for: 本文目的是生成Counterfactual Explanations（CEs），即通过修改最少必需的特征来改变分类器对给定图像的预测。</li>
<li>methods: 本文提出的方法是基于Distillation的黑盒Counterfactual技术，无需分类器结构、参数或梯度。首先，TIME引入了两种不同的偏见到Stable Diffusion中：context bias和class bias。context bias是图像结构相关的偏见，class bias是通过目标分类器学习的类特征偏见。然后，通过学习这两种偏见，找到最佳的latent code，并使用目标类token来重新生成图像，以生成counterfactual解释。</li>
<li>results: 对比 précédente方法，TIME可以在黑盒 Setting中生成相当有效的counterfactual解释。<details>
<summary>Abstract</summary>
This paper addresses the challenge of generating Counterfactual Explanations (CEs), involving the identification and modification of the fewest necessary features to alter a classifier's prediction for a given image. Our proposed method, Text-to-Image Models for Counterfactual Explanations (TIME), is a black-box counterfactual technique based on distillation. Unlike previous methods, this approach requires solely the image and its prediction, omitting the need for the classifier's structure, parameters, or gradients. Before generating the counterfactuals, TIME introduces two distinct biases into Stable Diffusion in the form of textual embeddings: the context bias, associated with the image's structure, and the class bias, linked to class-specific features learned by the target classifier. After learning these biases, we find the optimal latent code applying the classifier's predicted class token and regenerate the image using the target embedding as conditioning, producing the counterfactual explanation. Extensive empirical studies validate that TIME can generate explanations of comparable effectiveness even when operating within a black-box setting.
</details>
<details>
<summary>摘要</summary>
Before generating the counterfactuals, TIME introduces two distinct biases into Stable Diffusion in the form of textual embeddings: the context bias, associated with the image's structure, and the class bias, linked to class-specific features learned by the target classifier. After learning these biases, we find the optimal latent code by applying the classifier's predicted class token and regenerate the image using the target embedding as conditioning, producing the counterfactual explanation.Empirical studies have shown that TIME can generate explanations of comparable effectiveness even when operating within a black-box setting.
</details></li>
</ul>
<hr>
<h2 id="A-Multi-scale-Generalized-Shrinkage-Threshold-Network-for-Image-Blind-Deblurring-in-Remote-Sensing"><a href="#A-Multi-scale-Generalized-Shrinkage-Threshold-Network-for-Image-Blind-Deblurring-in-Remote-Sensing" class="headerlink" title="A Multi-scale Generalized Shrinkage Threshold Network for Image Blind Deblurring in Remote Sensing"></a>A Multi-scale Generalized Shrinkage Threshold Network for Image Blind Deblurring in Remote Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07524">http://arxiv.org/abs/2309.07524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujie Feng, Yin Yang, Xiaohong Fan, Zhengpeng Zhang, Jianping Zhang<br>for: 这个研究旨在提高遥测图像质量，Addressing the limitations of remote sensing image degradation due to sensor technology and complex imaging environments.methods: 提出了一个新的盲目杀价学习框架，Combining alternating iterations of shrinkage thresholds, blurring kernels, and images with a theoretical foundation of network design. Additionally, a learnable blur kernel proximal mapping module and a deep proximal mapping module in the image domain are proposed.results: 实验结果显示了我们的MGSTNet框架在遥测图像 datasets上比现有的杀价方法更高效。<details>
<summary>Abstract</summary>
Remote sensing images are essential for many earth science applications, but their quality can be degraded due to limitations in sensor technology and complex imaging environments. To address this, various remote sensing image deblurring methods have been developed to restore sharp, high-quality images from degraded observational data. However, most traditional model-based deblurring methods usually require predefined hand-craft prior assumptions, which are difficult to handle in complex applications, and most deep learning-based deblurring methods are designed as a black box, lacking transparency and interpretability. In this work, we propose a novel blind deblurring learning framework based on alternating iterations of shrinkage thresholds, alternately updating blurring kernels and images, with the theoretical foundation of network design. Additionally, we propose a learnable blur kernel proximal mapping module to improve the blur kernel evaluation in the kernel domain. Then, we proposed a deep proximal mapping module in the image domain, which combines a generalized shrinkage threshold operator and a multi-scale prior feature extraction block. This module also introduces an attention mechanism to adaptively adjust the prior importance, thus avoiding the drawbacks of hand-crafted image prior terms. Thus, a novel multi-scale generalized shrinkage threshold network (MGSTNet) is designed to specifically focus on learning deep geometric prior features to enhance image restoration. Experiments demonstrate the superiority of our MGSTNet framework on remote sensing image datasets compared to existing deblurring methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>remote sensing 图像是许多地球科学应用中必需的，但它们可能会受到仪器技术和观测环境的限制而受损。为了解决这问题，许多基于模型的融合图像滤波方法已经被开发出来，以恢复高质量的图像。然而，大多数传统的模型基于的手工定制假设是难以处理复杂的应用场景，而大多数基于深度学习的滤波方法则是黑盒模型，缺乏透明性和可解释性。在这种情况下，我们提出了一种基于交互迭代的盲滤波学习框架，其基于网络设计理论。此外，我们还提出了一种可学习的滤波kernels proximal映射模块，以提高滤波kernels的评估。然后，我们提出了一种深度 proximal映射模块，它将通过一个通用的缩短阈值操作符和多尺度先验特征提取块来组合。这个模块还引入了一种注意机制，以适应性地调整先验重要性，从而避免手动定制图像先验项的缺陷。因此，我们提出了一种基于多尺度总体缩短阈值网络（MGSTNet），以专门学习深度几何先验特征，以提高图像恢复。实验表明，我们的MGSTNet框架在遥感图像 datasets 上的效果比 EXISTS 的滤波方法更佳。
</details></li>
</ul>
<hr>
<h2 id="Dhan-Shomadhan-A-Dataset-of-Rice-Leaf-Disease-Classification-for-Bangladeshi-Local-Rice"><a href="#Dhan-Shomadhan-A-Dataset-of-Rice-Leaf-Disease-Classification-for-Bangladeshi-Local-Rice" class="headerlink" title="Dhan-Shomadhan: A Dataset of Rice Leaf Disease Classification for Bangladeshi Local Rice"></a>Dhan-Shomadhan: A Dataset of Rice Leaf Disease Classification for Bangladeshi Local Rice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07515">http://arxiv.org/abs/2309.07515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Fahad Hossain</li>
<li>for: 这个论文是为了提供一个大量的rice叶病病例图像集，用于Computer Vision和图像识别技术的研究和应用。</li>
<li>methods: 本论文使用了两种背景变化，包括场景背景图像和白色背景图像，收集了1106张五种危害rice的病病例图像。</li>
<li>results: 本论文通过对这些图像进行分类和识别，得到了对rice叶病的识别和检测的结果。<details>
<summary>Abstract</summary>
This dataset represents almost all the harmful diseases for rice in Bangladesh. This dataset consists of 1106 image of five harmful diseases called Brown Spot, Leaf Scaled, Rice Blast, Rice Turngo, Steath Blight in two different background variation named field background picture and white background picture. Two different background variation helps the dataset to perform more accurately so that the user can use this data for field use as well as white background for decision making. The data is collected from rice field of Dhaka Division. This dataset can use for rice leaf diseases classification, diseases detection using Computer Vision and Pattern Recognition for different rice leaf disease.
</details>
<details>
<summary>摘要</summary>
这个数据集代表了孟加拉的rice中的大多数有害病种。这个数据集包含1106张五种有害病种的图像，分别是棕点病、叶缘病、rice毒、rice螺旋和隐蔀病，在两种不同的背景 variation中，分别是田埂背景图像和白色背景图像。两种不同的背景 variation 帮助数据集更加准确地进行分类，以便用户在场景中使用这些数据进行决策。这些数据来自于达卡分区的rice场。这个数据集可以用于rice叶病识别、病种检测使用计算机视觉和模式识别。
</details></li>
</ul>
<hr>
<h2 id="RecycleNet-Latent-Feature-Recycling-Leads-to-Iterative-Decision-Refinement"><a href="#RecycleNet-Latent-Feature-Recycling-Leads-to-Iterative-Decision-Refinement" class="headerlink" title="RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement"></a>RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07513">http://arxiv.org/abs/2309.07513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gregor Koehler, Tassilo Wald, Constantin Ulrich, David Zimmerer, Paul F. Jaeger, Jörg K. H. Franke, Simon Kohl, Fabian Isensee, Klaus H. Maier-Hein</li>
<li>for: 提高神经网络的决策精度，允许神经网络在不同角度重新考虑初始决策，从而提高决策质量。</li>
<li>methods: 提出了一种叫做 RecycleNet 的缓存特征回收方法，通过在多个回收步骤中，将输出反馈到早期神经网络层次，以实现神经网络可以在不同角度重新考虑初始决策，以提高决策质量。</li>
<li>results: 在医学图像分割任务上进行评估，显示了 RecycleNet 可以在不同的分割benchmark上提高决策精度，并且与当前最佳分割方法相比，也可以获得更好的性能。<details>
<summary>Abstract</summary>
Despite the remarkable success of deep learning systems over the last decade, a key difference still remains between neural network and human decision-making: As humans, we cannot only form a decision on the spot, but also ponder, revisiting an initial guess from different angles, distilling relevant information, arriving at a better decision. Here, we propose RecycleNet, a latent feature recycling method, instilling the pondering capability for neural networks to refine initial decisions over a number of recycling steps, where outputs are fed back into earlier network layers in an iterative fashion. This approach makes minimal assumptions about the neural network architecture and thus can be implemented in a wide variety of contexts. Using medical image segmentation as the evaluation environment, we show that latent feature recycling enables the network to iteratively refine initial predictions even beyond the iterations seen during training, converging towards an improved decision. We evaluate this across a variety of segmentation benchmarks and show consistent improvements even compared with top-performing segmentation methods. This allows trading increased computation time for improved performance, which can be beneficial, especially for safety-critical applications.
</details>
<details>
<summary>摘要</summary>
尽管深度学习系统在过去十年内取得了非常出色的成绩，但是人类决策和神经网络决策之间仍然存在一定的区别：人类可以不仅立即做出决策，还可以思考、重新考虑、从不同的角度来到达更好的决策。为了让神经网络具备这种“pondering”能力，我们提出了RecycleNet方法，即 latent feature recycling 方法，允许神经网络在多个循环步骤中反复利用初始决策，以提高决策的准确性。这种方法对神经网络 Architecture 做出了最少的假设，因此可以在各种上下文中实现。使用医学影像 segmentation 作为评估环境，我们表明了 latent feature recycling 可以让神经网络在训练过程中没有看到的多个循环步骤中反复更新初始预测，并且在多个 segmentation 标准 benchmark 上达到了更高的性能。这意味着可以通过增加计算时间来换取更好的性能，这在安全关键应用中可能是有利的。
</details></li>
</ul>
<hr>
<h2 id="DiffTalker-Co-driven-audio-image-diffusion-for-talking-faces-via-intermediate-landmarks"><a href="#DiffTalker-Co-driven-audio-image-diffusion-for-talking-faces-via-intermediate-landmarks" class="headerlink" title="DiffTalker: Co-driven audio-image diffusion for talking faces via intermediate landmarks"></a>DiffTalker: Co-driven audio-image diffusion for talking faces via intermediate landmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07509">http://arxiv.org/abs/2309.07509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zipeng Qi, Xulong Zhang, Ning Cheng, Jing Xiao, Jianzong Wang</li>
<li>for: 这篇论文的目的是生成真实的讲话表情，具有各种应用。</li>
<li>methods: DiffTalker 模型使用了音频和特征点共同驱动，以解决直接将扩散模型应用到音频控制的挑战。DiffTalker 包括两个代理网络：一个基于 transformer 的特征点完成网络，以确保几何精度，以及一个基于扩散的脸部生成网络，以捕捉具有纹理详细的讲话表情。</li>
<li>results: DiffTalker 能够生成具有清晰度和几何精度的讲话表情，不需要额外对 audio 和图像特征进行对齐。实验结果表明，DiffTalker 在生成讲话表情方面表现出色，无需额外对 audio 和图像特征进行对齐。<details>
<summary>Abstract</summary>
Generating realistic talking faces is a complex and widely discussed task with numerous applications. In this paper, we present DiffTalker, a novel model designed to generate lifelike talking faces through audio and landmark co-driving. DiffTalker addresses the challenges associated with directly applying diffusion models to audio control, which are traditionally trained on text-image pairs. DiffTalker consists of two agent networks: a transformer-based landmarks completion network for geometric accuracy and a diffusion-based face generation network for texture details. Landmarks play a pivotal role in establishing a seamless connection between the audio and image domains, facilitating the incorporation of knowledge from pre-trained diffusion models. This innovative approach efficiently produces articulate-speaking faces. Experimental results showcase DiffTalker's superior performance in producing clear and geometrically accurate talking faces, all without the need for additional alignment between audio and image features.
</details>
<details>
<summary>摘要</summary>
通过音频和标点驱动，DiffTalker模型可生成真实的说话脸。DiffTalker解决了直接应用扩散模型到音频控制的挑战，传统上是通过文本图像对对应来训练。DiffTalker包括两个代理网络：一个基于变换器的标点完成网络以确保几何准确，以及一个基于扩散的面Generated network дляTexture详细。标点在将音频和图像领域连接起来的过程中扮演着关键的角色，使得可以借助预训练的扩散模型来 incorporate知识。这种创新的方法可以高效地生成敏捷说话的脸。实验结果表明DiffTalker可以生成清晰和几何准确的说话脸，无需额外对音频和图像特征进行对齐。
</details></li>
</ul>
<hr>
<h2 id="Efficiently-Robustify-Pre-trained-Models"><a href="#Efficiently-Robustify-Pre-trained-Models" class="headerlink" title="Efficiently Robustify Pre-trained Models"></a>Efficiently Robustify Pre-trained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07499">http://arxiv.org/abs/2309.07499</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nishant Jain, Harkirat Behl, Yogesh Singh Rawat, Vibhav Vineet</li>
<li>for: 本研究旨在探讨大规模深度学习模型在真实世界中的稳定性，以及现有robustification方法是否可 scalable。</li>
<li>methods: 我们首先对这些大规模模型进行了不同类型的拟合，以示它们在不同的数据集和预测task中的性能下降。然后，我们讨论了完全模型 fine-tuning 的缺点，包括 computational overhead和模型忘记部分感知特征。最后，我们提出了一种简单且cost-effective的方法，基于知识传递文献，可以快速地增强这些大规模模型的稳定性，同时保留模型的传输学习和零shot评估性能。</li>
<li>results: 我们的方法在不同的视觉拟合 dataset 上（包括 ImageNet-C,R,S,A  dataset 和不同数据集的传输学习和零shot评估setup）进行了评估，结果显示我们的方法能够有效地增强大规模模型的稳定性，需要远少于原始模型的计算负担，同时保留模型的传输学习和零shot性能。<details>
<summary>Abstract</summary>
A recent trend in deep learning algorithms has been towards training large scale models, having high parameter count and trained on big dataset. However, robustness of such large scale models towards real-world settings is still a less-explored topic. In this work, we first benchmark the performance of these models under different perturbations and datasets thereby representing real-world shifts, and highlight their degrading performance under these shifts. We then discuss on how complete model fine-tuning based existing robustification schemes might not be a scalable option given very large scale networks and can also lead them to forget some of the desired characterstics. Finally, we propose a simple and cost-effective method to solve this problem, inspired by knowledge transfer literature. It involves robustifying smaller models, at a lower computation cost, and then use them as teachers to tune a fraction of these large scale networks, reducing the overall computational overhead. We evaluate our proposed method under various vision perturbations including ImageNet-C,R,S,A datasets and also for transfer learning, zero-shot evaluation setups on different datasets. Benchmark results show that our method is able to induce robustness to these large scale models efficiently, requiring significantly lower time and also preserves the transfer learning, zero-shot properties of the original model which none of the existing methods are able to achieve.
</details>
<details>
<summary>摘要</summary>
现在的深度学习算法趋势是训练大规模模型，具有高参数计数和在大量数据上训练。然而，这些大规模模型在实际场景中的稳定性仍然是一个未经探索的话题。在这项工作中，我们首先对这些模型在不同的扰动和数据集上进行了性能测试，并发现它们在这些扰动下的性能下降。然后，我们讨论了完整模型练习基于现有的Robustification方案可能不是一个可执行的选择，因为它们可能会使模型忘记一些愿望的特征。最后，我们提出了一种简单而经济的解决方案，基于知识传递文献。它是通过强化小型模型，然后使用这些小型模型作为老师来微调一部分这些大规模网络，从而降低总计算成本。我们对各种视觉扰动，包括ImageNet-C、R、S、A数据集以及转移学习、零shot评估集成进行了评估。结果表明，我们的方法能够有效地带来这些大规模模型的稳定性，需要较低的计算成本，同时保留原始模型的转移学习、零shot特性，与现有方法不同。
</details></li>
</ul>
<hr>
<h2 id="EP2P-Loc-End-to-End-3D-Point-to-2D-Pixel-Localization-for-Large-Scale-Visual-Localization"><a href="#EP2P-Loc-End-to-End-3D-Point-to-2D-Pixel-Localization-for-Large-Scale-Visual-Localization" class="headerlink" title="EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization"></a>EP2P-Loc: End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07471">http://arxiv.org/abs/2309.07471</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minnjung/ep2p-loc">https://github.com/minnjung/ep2p-loc</a></li>
<li>paper_authors: Minjung Kim, Junseo Koo, Gunhee Kim</li>
<li>for: 本研究旨在解决视觉地标化问题，即从视觉图像中估算出6DOF摄像机pose。</li>
<li>methods: 本方法使用了一种新的大规模视觉地标化方法，即EP2P-Loc。该方法利用了2D-3D特征匹配，并通过终端训练来提高pose估算的精度。</li>
<li>results: 在新的大规模indoor和outdoorbenchmark上进行了实验，并显示了与现有视觉地标化和图像到点云注册方法相比，本方法可以 дости得最佳性能。<details>
<summary>Abstract</summary>
Visual localization is the task of estimating a 6-DoF camera pose of a query image within a provided 3D reference map. Thanks to recent advances in various 3D sensors, 3D point clouds are becoming a more accurate and affordable option for building the reference map, but research to match the points of 3D point clouds with pixels in 2D images for visual localization remains challenging. Existing approaches that jointly learn 2D-3D feature matching suffer from low inliers due to representational differences between the two modalities, and the methods that bypass this problem into classification have an issue of poor refinement. In this work, we propose EP2P-Loc, a novel large-scale visual localization method that mitigates such appearance discrepancy and enables end-to-end training for pose estimation. To increase the number of inliers, we propose a simple algorithm to remove invisible 3D points in the image, and find all 2D-3D correspondences without keypoint detection. To reduce memory usage and search complexity, we take a coarse-to-fine approach where we extract patch-level features from 2D images, then perform 2D patch classification on each 3D point, and obtain the exact corresponding 2D pixel coordinates through positional encoding. Finally, for the first time in this task, we employ a differentiable PnP for end-to-end training. In the experiments on newly curated large-scale indoor and outdoor benchmarks based on 2D-3D-S and KITTI, we show that our method achieves the state-of-the-art performance compared to existing visual localization and image-to-point cloud registration methods.
</details>
<details>
<summary>摘要</summary>
“视觉地理位置”是指根据查询图像和提供的3D参考地图来估算摄像机pose的任务。由于不同感知模式之间的表示差异，现有的方法 JOINTLY学习2D-3D特征匹配具有低准确率。此外，通过 Circumventing 这个问题，这些方法通常会导致精度不高的答案。在这项工作中，我们提出了EP2P-Loc，一种新的大规模视觉地理位置方法，可以减轻表示差异的问题，并允许端到端培训。为了增加准确率，我们提出了一种简单的算法，可以在图像中remove不可见的3D点，并找到所有2D-3D匹配。此外，为了降低内存使用量和搜索复杂度，我们采取了一种粗粒度-细粒度的方法，首先从2D图像中提取patch-level特征，然后在每个3D点上进行2D patch分类，并通过 pozitional encoding 获取准确的2D像素坐标。最后，我们首次在这个任务中使用了可导的PnP для端到端培训。在新编制的大规模indoor和outdoor benchmarks上进行了实验，我们示出了我们的方法可以与现有的视觉地理位置和图像-点云注册方法相比，达到了状态 искусственный智能水平。
</details></li>
</ul>
<hr>
<h2 id="Research-on-self-cross-transformer-model-of-point-cloud-change-detecter"><a href="#Research-on-self-cross-transformer-model-of-point-cloud-change-detecter" class="headerlink" title="Research on self-cross transformer model of point cloud change detecter"></a>Research on self-cross transformer model of point cloud change detecter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07444">http://arxiv.org/abs/2309.07444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxu Ren, Haili Sun, Zhenxin Zhang</li>
<li>for: 本文主要针对的是检测3D点云中的变化，以帮助城市建设过程中的变化检测，确保项目完整性和减少劳动成本。</li>
<li>methods: 本文提出了一种基于cross transformer模块的3D点云变化检测网络，并对其进行了验证和测试。</li>
<li>results: 测试结果表明，该网络在检测3D点云中的变化方面具有高精度和高速响应性。<details>
<summary>Abstract</summary>
With the vigorous development of the urban construction industry, engineering deformation or changes often occur during the construction process. To combat this phenomenon, it is necessary to detect changes in order to detect construction loopholes in time, ensure the integrity of the project and reduce labor costs. Or the inconvenience and injuriousness of the road. In the study of change detection in 3D point clouds, researchers have published various research methods on 3D point clouds. Directly based on but mostly based ontraditional threshold distance methods (C2C, M3C2, M3C2-EP), and some are to convert 3D point clouds into DSM, which loses a lot of original information. Although deep learning is used in remote sensing methods, in terms of change detection of 3D point clouds, it is more converted into two-dimensional patches, and neural networks are rarely applied directly. We prefer that the network is given at the level of pixels or points. Variety. Therefore, in this article, our network builds a network for 3D point cloud change detection, and proposes a new module Cross transformer suitable for change detection. Simultaneously simulate tunneling data for change detection, and do test experiments with our network.
</details>
<details>
<summary>摘要</summary>
随着城市建设业的发展，工程变形或变化经常发生在建设过程中。要解决这种现象，需要检测变化，以时间准确检测建筑缺陷，保证项目完整性，降低劳动成本。或者公路不便。在3D点云变化检测研究中，研究人员已经发表了多种研究方法。大多基于传统的距离方法（C2C、M3C2、M3C2-EP），一些是将3D点云转换为DSM，这会产生很多原始信息的损失。虽然深度学习在远程感知方法中被广泛应用，但在3D点云变化检测方面，它更多地转换为二维质心，神经网络在Change Detection中 rarely applied directly。我们认为，网络应该给点或像素层次。因此，在这篇文章中，我们建立了一个3D点云变化检测网络，并提出了一个适用于变化检测的新模块——跨 transformer。同时，我们对各种数据进行了模拟隧道测试，并对我们的网络进行了测试实验。
</details></li>
</ul>
<hr>
<h2 id="DePT-Decoupled-Prompt-Tuning"><a href="#DePT-Decoupled-Prompt-Tuning" class="headerlink" title="DePT: Decoupled Prompt Tuning"></a>DePT: Decoupled Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07439">http://arxiv.org/abs/2309.07439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/koorye/dept">https://github.com/koorye/dept</a></li>
<li>paper_authors: Ji Zhang, Shihan Wu, Lianli Gao, Hengtao Shen, Jingkuan Song</li>
<li>for: 解决基础-新任务负面关系（Base-New Tradeoff）在提升任务中，即提升基础任务的泛化性会导致新任务的泛化性减退，并且vice versa。</li>
<li>methods: 提出了一种叫做Decoupled Prompt Tuning（DePT）框架，它在提升过程中将基础知识从特征通道隔离到一个隔离的特征空间中，以保留原始特征空间中的任务共享知识，从而实现更好的零基础泛化性在新任务上。</li>
<li>results: 经过对11个数据集的广泛实验，显示DePT具有强大的灵活性和效果性，可以提高所有的提升方法。代码和预训练模型可以在<a target="_blank" rel="noopener" href="https://github.com/Koorye/DePT%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Koorye/DePT上下载。</a><details>
<summary>Abstract</summary>
This work breaks through the Base-New Tradeoff (BNT)dilemma in prompt tuning, i.e., the better the tuned model generalizes to the base (or target) task, the worse it generalizes to new tasks, and vice versa. Specifically, through an in-depth analysis of the learned features of the base and new tasks, we observe that the BNT stems from a channel bias issue, i.e., the vast majority of feature channels are occupied by base-specific knowledge, resulting in the collapse of taskshared knowledge important to new tasks. To address this, we propose the Decoupled Prompt Tuning (DePT) framework, which decouples base-specific knowledge from feature channels into an isolated feature space during prompt tuning, so as to maximally preserve task-shared knowledge in the original feature space for achieving better zero-shot generalization on new tasks. Importantly, our DePT is orthogonal to existing prompt tuning methods, hence it can improve all of them. Extensive experiments on 11 datasets show the strong flexibility and effectiveness of DePT. Our code and pretrained models are available at https://github.com/Koorye/DePT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Physical-Invisible-Backdoor-Based-on-Camera-Imaging"><a href="#Physical-Invisible-Backdoor-Based-on-Camera-Imaging" class="headerlink" title="Physical Invisible Backdoor Based on Camera Imaging"></a>Physical Invisible Backdoor Based on Camera Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07428">http://arxiv.org/abs/2309.07428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusheng Guo, Nan Zhong, Zhenxing Qian, Xinpeng Zhang</li>
<li>for: 这篇论文旨在提出一种physical invisible backdoor攻击方法，用于妨碍模型的正常工作，而不需要改变图像的 pixels。</li>
<li>methods: 该方法基于camera imaging，使用特定的摄像头ID来提取图像特征，并利用CFA interpolations algorithm和特征提取块组合成一个特殊的网络结构，以便在这个结构上进行攻击。</li>
<li>results: 实验结果表明，该方法可以 Effectively compromise classical models, such as ResNet18, over a new dataset of 21,500 images, and is robust against various backdoor defenses.<details>
<summary>Abstract</summary>
Backdoor attack aims to compromise a model, which returns an adversary-wanted output when a specific trigger pattern appears yet behaves normally for clean inputs. Current backdoor attacks require changing pixels of clean images, which results in poor stealthiness of attacks and increases the difficulty of the physical implementation. This paper proposes a novel physical invisible backdoor based on camera imaging without changing nature image pixels. Specifically, a compromised model returns a target label for images taken by a particular camera, while it returns correct results for other images. To implement and evaluate the proposed backdoor, we take shots of different objects from multi-angles using multiple smartphones to build a new dataset of 21,500 images. Conventional backdoor attacks work ineffectively with some classical models, such as ResNet18, over the above-mentioned dataset. Therefore, we propose a three-step training strategy to mount the backdoor attack. First, we design and train a camera identification model with the phone IDs to extract the camera fingerprint feature. Subsequently, we elaborate a special network architecture, which is easily compromised by our backdoor attack, by leveraging the attributes of the CFA interpolation algorithm and combining it with the feature extraction block in the camera identification model. Finally, we transfer the backdoor from the elaborated special network architecture to the classical architecture model via teacher-student distillation learning. Since the trigger of our method is related to the specific phone, our attack works effectively in the physical world. Experiment results demonstrate the feasibility of our proposed approach and robustness against various backdoor defenses.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这里使用了简化字体。</SYS>>黑门攻击目的是妥协模型，让模型在特定的触发模式出现时返回攻击者所需的输出，但是在清洁的输入中保持正常的行为。现有的黑门攻击需要改变清洁图像的像素，这会导致攻击的不透明度低下和实现physical实现更加困难。本文提出了一种新的物理隐藏黑门，基于Camera imaging，不需要改变 Nature 图像像素。具体来说，一个妥协模型会对特定的摄像头拍摄的图像返回目标标签，而对其他图像返回正确的结果。为实现和评估提议的黑门，我们使用多种多摄像头拍摄不同的物体从多个角度，并建立了一个新的数据集，包含21500个图像。传统的黑门攻击对于一些经典模型，如ResNet18，在上述数据集上无效。因此，我们提出了一种三步训练策略来实现黑门攻击。首先，我们设计和训练了一个摄像头标识模型，以EXTRACTING camera fingerprint feature。然后，我们利用CFA interpolación算法的特点和摄像头标识模型的特点，设计了一种特殊的网络架构，这种网络架构容易受到我们黑门攻击的影响。最后，我们通过教师学生分布式学习来帮助特殊网络架构转移到经典网络架构中，从而实现黑门攻击。由于触发器与特定的手机相关，我们的黑门在物理世界中具有效果。实验结果表明，我们的提议方法是可行的，并且对各种黑门防御措施具有较高的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Masked-Diffusion-with-Task-awareness-for-Procedure-Planning-in-Instructional-Videos"><a href="#Masked-Diffusion-with-Task-awareness-for-Procedure-Planning-in-Instructional-Videos" class="headerlink" title="Masked Diffusion with Task-awareness for Procedure Planning in Instructional Videos"></a>Masked Diffusion with Task-awareness for Procedure Planning in Instructional Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07409">http://arxiv.org/abs/2309.07409</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ffzzy840304/masked-pdpp">https://github.com/ffzzy840304/masked-pdpp</a></li>
<li>paper_authors: Fen Fang, Yun Liu, Ali Koksal, Qianli Xu, Joo-Hwee Lim</li>
<li>for: 本研究旨在解决视频教程中的程序规划问题，即从短视觉中快速识别多种任务类型（如倒 Pour milk、倒 Pour water、打开封口、关闭封口等），并 Capture 这些动作类型和任务目标之间的细致 semantic relation。</li>
<li>methods: 我们提出了一种简单 yet effective 的提高方法 - 使用 masked diffusion model。这个mask acts as a task-oriented attention filter，使得 diffusion&#x2F;denoising process 能够专注于一 subset of action types。此外，我们还使用更强大的视觉表示学习技术来增强任务分类的准确性。特别是，我们学习了一个 joint visual-text embedding，其中text embedding 由提取 human actions的 pre-trained vision-language model 生成。</li>
<li>results: 我们在三个公共数据集上进行了evaluation，并达到了当前最佳性能在多个指标上。Code可以在<a target="_blank" rel="noopener" href="https://github.com/ffzzy840304/Masked-PDPP%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/ffzzy840304/Masked-PDPP中找到。</a><details>
<summary>Abstract</summary>
A key challenge with procedure planning in instructional videos lies in how to handle a large decision space consisting of a multitude of action types that belong to various tasks. To understand real-world video content, an AI agent must proficiently discern these action types (e.g., pour milk, pour water, open lid, close lid, etc.) based on brief visual observation. Moreover, it must adeptly capture the intricate semantic relation of the action types and task goals, along with the variable action sequences. Recently, notable progress has been made via the integration of diffusion models and visual representation learning to address the challenge. However, existing models employ rudimentary mechanisms to utilize task information to manage the decision space. To overcome this limitation, we introduce a simple yet effective enhancement - a masked diffusion model. The introduced mask acts akin to a task-oriented attention filter, enabling the diffusion/denoising process to concentrate on a subset of action types. Furthermore, to bolster the accuracy of task classification, we harness more potent visual representation learning techniques. In particular, we learn a joint visual-text embedding, where a text embedding is generated by prompting a pre-trained vision-language model to focus on human actions. We evaluate the method on three public datasets and achieve state-of-the-art performance on multiple metrics. Code is available at https://github.com/ffzzy840304/Masked-PDPP.
</details>
<details>
<summary>摘要</summary>
“一个主要挑战在程序规划视频教程中是如何处理庞大的决策空间，这个空间包含许多不同任务的动作类型。为了理解现实世界视频内容，一个AI代理必须能够准确地识别这些动作类型（如抹 milk、抹水、打开封口、关闭封口等），并且需要capture这些动作类型和任务目标之间的复杂semantic关系，以及变化的动作序列。在最近，通过混合扩散模型和视觉表示学习来解决这个挑战，然而现有模型使用简单的任务信息管理decision space的机制。为了超越这个限制，我们提出了一种简单 yet有效的提高---masked扩散模型。在扩散/净化过程中，这个mask acts as a task-oriented attention filter，使得扩散/净化过程能够专注于一 subset of action types。此外，为了提高任务分类的准确度，我们利用更强大的视觉表示学习技术。具体来说，我们学习一个joint visual-text embedding，其中的text embedding是通过Prompting a pre-trained vision-language model来Focus on human actions来生成。我们对三个公共数据集进行评估，并在多个纪录录制中 дости得状态的最佳性能。代码可以在https://github.com/ffzzy840304/Masked-PDPP中找到。”
</details></li>
</ul>
<hr>
<h2 id="Flexible-Visual-Recognition-by-Evidential-Modeling-of-Confusion-and-Ignorance"><a href="#Flexible-Visual-Recognition-by-Evidential-Modeling-of-Confusion-and-Ignorance" class="headerlink" title="Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance"></a>Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07403">http://arxiv.org/abs/2309.07403</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Fan, Bo Liu, Haoxiang Li, Ying Wu, Gang Hua</li>
<li>for: 提高视觉识别系统的灵活性和可靠性，解决知名类错误分类和未知类图像的异常行为问题。</li>
<li>methods: 基于主观逻辑理论，分别量化决策不确定性为内类冲突和外部无知，并通过证据结合来获得全面的主观意见。</li>
<li>results: 通过synthetic数据分析、视觉识别和开集检测等实验，证明了方法的有效性，可以准确量化两种不确定性并有助于灵活识别。<details>
<summary>Abstract</summary>
In real-world scenarios, typical visual recognition systems could fail under two major causes, i.e., the misclassification between known classes and the excusable misbehavior on unknown-class images. To tackle these deficiencies, flexible visual recognition should dynamically predict multiple classes when they are unconfident between choices and reject making predictions when the input is entirely out of the training distribution. Two challenges emerge along with this novel task. First, prediction uncertainty should be separately quantified as confusion depicting inter-class uncertainties and ignorance identifying out-of-distribution samples. Second, both confusion and ignorance should be comparable between samples to enable effective decision-making. In this paper, we propose to model these two sources of uncertainty explicitly with the theory of Subjective Logic. Regarding recognition as an evidence-collecting process, confusion is then defined as conflicting evidence, while ignorance is the absence of evidence. By predicting Dirichlet concentration parameters for singletons, comprehensive subjective opinions, including confusion and ignorance, could be achieved via further evidence combinations. Through a series of experiments on synthetic data analysis, visual recognition, and open-set detection, we demonstrate the effectiveness of our methods in quantifying two sources of uncertainties and dealing with flexible recognition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Quantifying prediction uncertainty: Uncertainty should be separately quantified as confusion depicting inter-class uncertainties and ignorance identifying out-of-distribution samples.2. Comparable uncertainty between samples: Both confusion and ignorance should be comparable between samples to enable effective decision-making.In this paper, we propose to explicitly model these two sources of uncertainty using the theory of Subjective Logic. Recognition is viewed as an evidence-collecting process, and confusion is defined as conflicting evidence, while ignorance is the absence of evidence. By predicting Dirichlet concentration parameters for singletons, comprehensive subjective opinions, including confusion and ignorance, can be achieved via further evidence combinations.We demonstrate the effectiveness of our methods through a series of experiments on synthetic data analysis, visual recognition, and open-set detection. Our approach can quantify two sources of uncertainties and handle flexible recognition effectively.</details></li>
</ol>
<hr>
<h2 id="HIGT-Hierarchical-Interaction-Graph-Transformer-for-Whole-Slide-Image-Analysis"><a href="#HIGT-Hierarchical-Interaction-Graph-Transformer-for-Whole-Slide-Image-Analysis" class="headerlink" title="HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis"></a>HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07400">http://arxiv.org/abs/2309.07400</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hku-medai/higt">https://github.com/hku-medai/higt</a></li>
<li>paper_authors: Ziyu Guo, Weiqin Zhao, Shujun Wang, Lequan Yu</li>
<li>For: 这 paper 是为了研究 computation pathology 领域中 gigapixel Whole Slide Images (WSIs) 的 pyramid 结构，以捕捉不同层次的信息，从单个细胞互动到组织微环境。* Methods: 这 paper 使用了一种新的 Hierarchical Interaction Graph-Transformer (HIGT) 模型，结合图 neural network 和 transformer 作为基础，可以学习 WSI  pyramids 中的短距离本地信息和长距离全局表示。另外，为了在不同层次之间建立交互，我们设计了一种 novel Bidirectional Interaction block。* Results: 经过对两个公共 WSI 数据集（KICA 和 ESCA）的测试，我们的 HIGT 方法在肿瘤分类和阶段评估任务上表现出色，超过了现有的 hierarchical 和非层次方法。<details>
<summary>Abstract</summary>
In computation pathology, the pyramid structure of gigapixel Whole Slide Images (WSIs) has recently been studied for capturing various information from individual cell interactions to tissue microenvironments. This hierarchical structure is believed to be beneficial for cancer diagnosis and prognosis tasks. However, most previous hierarchical WSI analysis works (1) only characterize local or global correlations within the WSI pyramids and (2) use only unidirectional interaction between different resolutions, leading to an incomplete picture of WSI pyramids. To this end, this paper presents a novel Hierarchical Interaction Graph-Transformer (i.e., HIGT) for WSI analysis. With Graph Neural Network and Transformer as the building commons, HIGT can learn both short-range local information and long-range global representation of the WSI pyramids. Considering that the information from different resolutions is complementary and can benefit each other during the learning process, we further design a novel Bidirectional Interaction block to establish communication between different levels within the WSI pyramids. Finally, we aggregate both coarse-grained and fine-grained features learned from different levels together for slide-level prediction. We evaluate our methods on two public WSI datasets from TCGA projects, i.e., kidney carcinoma (KICA) and esophageal carcinoma (ESCA). Experimental results show that our HIGT outperforms both hierarchical and non-hierarchical state-of-the-art methods on both tumor subtyping and staging tasks.
</details>
<details>
<summary>摘要</summary>
在计算 PATHOLOGY 领域，最近才 studying gigapixel Whole Slide Images (WSIs) 的 pyramid 结构，以捕捉各个细胞交互到组织微环境中的多种信息。这种层次结构被认为对于肿瘤诊断和预后 Task 有利。然而，大多数先前的层次 WSI 分析工作（1）只研究 WSI  pyramids 的本地或全局相关性，以及（2）使用单向交互，导致 WSI  pyramids 的完整图像减少。为此，本文提出了一种基于 Graph Neural Network 和 Transformer 的 Hierarchical Interaction Graph-Transformer (i.e., HIGT)，可以学习 WSI  pyramids 中的短距离本地信息和长距离全局表示。因为不同层次的信息是补偿的，可以在学习过程中互助于each other，我们进一步设计了一种替换 Interaction 块来在 WSI  pyramids 中建立不同层次之间的交互。最后，我们将不同层次上学习的粗细化特征和细胞特征融合在一起进行板块级预测。我们在 TCGA 项目中公开的两个 WSI 数据集（i.e., KICA 和 ESCA）上进行了实验，结果表明我们的 HIGT 在肿瘤分类和预后 Task 上都有出色的表现，超过了现有的层次和非层次方法。
</details></li>
</ul>
<hr>
<h2 id="Nucleus-aware-Self-supervised-Pretraining-Using-Unpaired-Image-to-image-Translation-for-Histopathology-Images"><a href="#Nucleus-aware-Self-supervised-Pretraining-Using-Unpaired-Image-to-image-Translation-for-Histopathology-Images" class="headerlink" title="Nucleus-aware Self-supervised Pretraining Using Unpaired Image-to-image Translation for Histopathology Images"></a>Nucleus-aware Self-supervised Pretraining Using Unpaired Image-to-image Translation for Histopathology Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07394">http://arxiv.org/abs/2309.07394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiyuns/UNITPathSSL">https://github.com/zhiyuns/UNITPathSSL</a></li>
<li>paper_authors: Zhiyun Song, Penghui Du, Junpeng Yan, Kailu Li, Jianzhong Shou, Maode Lai, Yubo Fan, Yan Xu<br>for:本研究旨在提高模型性能，通过未标注数据中获得有效特征，并在 Histopathology 图像领域得到成功。然而，只有少数研究强调抽取核心水平信息，这是 PATHOLOGIC 分析中关键的一部分。本文提出了一种基于自我超vised 预训练的新核心意识框架，用于 Histopathology 图像。该框架通过未标注图像与假掩码图像之间的无对映射翻译，捕捉 Histopathology 图像中核仁形态和分布信息。methods:本研究使用了一种基于 conditional 和随机样式表示的自我超vised 预训练策略，以确保生成的 Histopathology 图像是真实且多样的。此外，我们还使用了实例分割指导策略，以捕捉实例水平信息。results:我们在 7 个数据集上进行了实验，并证明了我们的预训练方法在 Kather 分类、多实例学习和 5 个权重预测任务中超越了指导学习方法，并在 8 个半upervised 任务中提供了最佳结果。此外，我们还发现了基于自我超vised 预训练的模型在 PATHOLOGIC 分析中的优势。<details>
<summary>Abstract</summary>
Self-supervised pretraining attempts to enhance model performance by obtaining effective features from unlabeled data, and has demonstrated its effectiveness in the field of histopathology images. Despite its success, few works concentrate on the extraction of nucleus-level information, which is essential for pathologic analysis. In this work, we propose a novel nucleus-aware self-supervised pretraining framework for histopathology images. The framework aims to capture the nuclear morphology and distribution information through unpaired image-to-image translation between histopathology images and pseudo mask images. The generation process is modulated by both conditional and stochastic style representations, ensuring the reality and diversity of the generated histopathology images for pretraining. Further, an instance segmentation guided strategy is employed to capture instance-level information. The experiments on 7 datasets show that the proposed pretraining method outperforms supervised ones on Kather classification, multiple instance learning, and 5 dense-prediction tasks with the transfer learning protocol, and yields superior results than other self-supervised approaches on 8 semi-supervised tasks. Our project is publicly available at https://github.com/zhiyuns/UNITPathSSL.
</details>
<details>
<summary>摘要</summary>
自我监督预训术目的是提高模型性能，通过无标注数据中获得有效特征，并在 histopathology 图像领域已经达到成功。然而，只有一些工作强调提取核心级信息，这是pathological分析中不可或缺的。在这项工作中，我们提出了一种新的自我监督预训框架，用于 histopathology 图像。该框架通过无标注图像到图像翻译来捕捉 histopathology 图像中核心形态和分布信息。生成过程由 conditional 和随机风格表示控制，以保证生成的 histopathology 图像的真实性和多样性。此外，我们还使用了实例分割指导策略来捕捉实例级信息。我们在 7 个数据集上进行了实验，结果表明，我们的预训法在 Kather 分类、多实例学习和 5 个激活预测任务中都能够超越supervised方法，并在 8 个半supervised任务中达到更高的效果。您可以在 <https://github.com/zhiyuns/UNITPathSSL> 上下载我们的项目。
</details></li>
</ul>
<hr>
<h2 id="Judging-a-video-by-its-bitstream-cover"><a href="#Judging-a-video-by-its-bitstream-cover" class="headerlink" title="Judging a video by its bitstream cover"></a>Judging a video by its bitstream cover</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07361">http://arxiv.org/abs/2309.07361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxing Han, Yunan Ding, Jiangtao Wen, Chen Ye Gan</li>
<li>for: 本研究旨在开发一种基于post-compression bitstream的视频分类方法，以提高 multimedia 理解和检索效率。</li>
<li>methods: 该方法仅仅从视频的 post-compression bitstream 中提取特征，不需要进行视频解压缩，从而降低计算和存储需求。</li>
<li>results: 我们使用自定义的 YouTube 视频集（包含超过 29,000 个视频剪辑，总计 6,000 小时）进行验证，得到了precision、accuracy 和 recall 率高于 80%。该算法比传统的DTW算法六个数量级快，每秒钟可以处理 30 帧视频。<details>
<summary>Abstract</summary>
Classifying videos into distinct categories, such as Sport and Music Video, is crucial for multimedia understanding and retrieval, especially in an age where an immense volume of video content is constantly being generated. Traditional methods require video decompression to extract pixel-level features like color, texture, and motion, thereby increasing computational and storage demands. Moreover, these methods often suffer from performance degradation in low-quality videos. We present a novel approach that examines only the post-compression bitstream of a video to perform classification, eliminating the need for bitstream. We validate our approach using a custom-built data set comprising over 29,000 YouTube video clips, totaling 6,000 hours and spanning 11 distinct categories. Our preliminary evaluations indicate precision, accuracy, and recall rates well over 80%. The algorithm operates approximately 15,000 times faster than real-time for 30fps videos, outperforming traditional Dynamic Time Warping (DTW) algorithm by six orders of magnitude.
</details>
<details>
<summary>摘要</summary>
翻译文本为简化中文：分类视频为不同类别，如体育和音乐视频，对多媒体理解和检索是非常重要，特别在今天的数据涌入量是不断增长。传统方法需要视频解压缩，提取像素级特征，如颜色、文本和运动，从而增加计算和存储需求。此外，这些方法经常受到低质量视频的影响，性能下降。我们提出了一种新的方法，通过只对视频后期压缩流进行分类，取消了需要视频流。我们使用自定义的数据集，包括YouTube视频剪辑总计29,000个，总时长6,000小时，涵盖11种不同类别。我们的初步评估结果显示，精度、准确率和回归率超过80%。算法运行约15,000次 faster than real-time for 30fps videos，比传统的动态时间戳相差6个数量级。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/cs.CV_2023_09_14/" data-id="clohum97l00hppj88bmx5guw5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/cs.AI_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T12:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/cs.AI_2023_09_14/">cs.AI - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Retrieval-Augmented-Text-to-Audio-Generation"><a href="#Retrieval-Augmented-Text-to-Audio-Generation" class="headerlink" title="Retrieval-Augmented Text-to-Audio Generation"></a>Retrieval-Augmented Text-to-Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08051">http://arxiv.org/abs/2309.08051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Yuan, Haohe Liu, Xubo Liu, Qiushi Huang, Mark D. Plumbley, Wenwu Wang</li>
<li>for: 提高文本到audio生成中的质量和准确性，特别是处理 dataset 中罕见的类别问题。</li>
<li>methods: 提出了一种简单的检索增强方法，使用 Contrastive Language Audio Pretraining (CLAP) 模型 retrieve 相关的文本-audio对，然后使用这些数据的特征作为 TTA 模型的学习指导。</li>
<li>results: 在 AudioCaps dataset 上，提出的 Re-AudioLDM 系统实现了 state-of-the-art Frechet Audio Distance (FAD) 1.37，较 existing 方法大幅提高。Re-AudioLDM 还能够生成高质量的 audio  для 复杂的场景、罕见的音频类别和even 未看过的音频类型，表明其在 TTA 任务中的潜在能力。<details>
<summary>Abstract</summary>
Despite recent progress in text-to-audio (TTA) generation, we show that the state-of-the-art models, such as AudioLDM, trained on datasets with an imbalanced class distribution, such as AudioCaps, are biased in their generation performance. Specifically, they excel in generating common audio classes while underperforming in the rare ones, thus degrading the overall generation performance. We refer to this problem as long-tailed text-to-audio generation. To address this issue, we propose a simple retrieval-augmented approach for TTA models. Specifically, given an input text prompt, we first leverage a Contrastive Language Audio Pretraining (CLAP) model to retrieve relevant text-audio pairs. The features of the retrieved audio-text data are then used as additional conditions to guide the learning of TTA models. We enhance AudioLDM with our proposed approach and denote the resulting augmented system as Re-AudioLDM. On the AudioCaps dataset, Re-AudioLDM achieves a state-of-the-art Frechet Audio Distance (FAD) of 1.37, outperforming the existing approaches by a large margin. Furthermore, we show that Re-AudioLDM can generate realistic audio for complex scenes, rare audio classes, and even unseen audio types, indicating its potential in TTA tasks.
</details>
<details>
<summary>摘要</summary>
尽管最近的文本到音频（TTA）生成技术已经取得了一些进步，但我们发现，使用 AudioCaps 等数据集，state-of-the-art 模型，如 AudioLDM，在生成不匹配的类别时会受到偏见。具体来说，它们在常见的音频类别上表现出色，而在罕见的类别上表现不佳，从而降低整体生成性能。我们称这个问题为“长尾文本到音频生成”。为解决这个问题，我们提议一种简单的检索增强方法，即给输入文本提示时，首先利用 Contrastive Language Audio Pretraining（CLAP）模型来检索相关的文本-音频对。然后， retrieved audio-text 数据的特征被用作 TTA 模型的学习指导。我们增强 AudioLDM 后的系统被称为 Re-AudioLDM，在 AudioCaps 数据集上实现了最新的 Frechet Audio Distance（FAD）记录，为 1.37，超过了现有的方法。此外，我们还证明了 Re-AudioLDM 可以生成复杂场景、罕见音频类别以及未经见过的音频类别，表明它在 TTA 任务中的潜力。
</details></li>
</ul>
<hr>
<h2 id="Padding-Aware-Neurons"><a href="#Padding-Aware-Neurons" class="headerlink" title="Padding Aware Neurons"></a>Padding Aware Neurons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08048">http://arxiv.org/abs/2309.08048</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/paper14/padding-aware-neurons">https://gitlab.com/paper14/padding-aware-neurons</a></li>
<li>paper_authors: Dario Garcia-Gasulla, Victor Gimenez-Abalos, Pablo Martin-Torres</li>
<li>for: 这篇论文主要研究了卷积层中的填充感知机制，以及这种机制对模型性能的影响。</li>
<li>methods: 研究者通过分析卷积层中的缺 padding 策略和激活函数来确定卷积层中的感知机制。他们还通过对多种预训练模型进行分析来explore PANs在不同模型中的存在。</li>
<li>results: 研究者发现了大多数卷积模型中的PANs，其数量从多达百个不等。他们还发现了不同类型的PANs，以及它们在数据上的偏好和影响。最后，研究者讨论了PANs的可 desirability 和其在模型性能、通用性、效率和安全性方面的可能的副作用。<details>
<summary>Abstract</summary>
Convolutional layers are a fundamental component of most image-related models. These layers often implement by default a static padding policy (\eg zero padding), to control the scale of the internal representations, and to allow kernel activations centered on the border regions. In this work we identify Padding Aware Neurons (PANs), a type of filter that is found in most (if not all) convolutional models trained with static padding. PANs focus on the characterization and recognition of input border location, introducing a spatial inductive bias into the model (e.g., how close to the input's border a pattern typically is). We propose a method to identify PANs through their activations, and explore their presence in several popular pre-trained models, finding PANs on all models explored, from dozens to hundreds. We discuss and illustrate different types of PANs, their kernels and behaviour. To understand their relevance, we test their impact on model performance, and find padding and PANs to induce strong and characteristic biases in the data. Finally, we discuss whether or not PANs are desirable, as well as the potential side effects of their presence in the context of model performance, generalisation, efficiency and safety.
</details>
<details>
<summary>摘要</summary>
卷积层是图像相关模型中的基本组件。这些层通常采用静态预留策略（例如零预留），以控制内部表示的大小和kernel活动的中心位置。在这种工作中，我们认定了边缘位置感知neurons（PANs），这种filter在大多数（如果不是所有）卷积模型中被发现。PANs通过识别和识别输入边缘的位置来引入空间卷积偏好（例如，输入边缘上的模式是如何靠近）。我们提出了通过活动来识别PANs的方法，并在多个流行预训练模型中找到了PANs，从数十到百个。我们讨论和描述了不同类型的PANs，其核心和行为。为了了解其 relevance，我们测试了它们对模型性能的影响，并发现预留和PANs都会对数据产生强大和特征的偏好。最后，我们讨论了PANs是否有利，以及它们在模型性能、泛化、效率和安全性上的可能的侧effect。
</details></li>
</ul>
<hr>
<h2 id="Towards-Large-scale-Building-Attribute-Mapping-using-Crowdsourced-Images-Scene-Text-Recognition-on-Flickr-and-Problems-to-be-Solved"><a href="#Towards-Large-scale-Building-Attribute-Mapping-using-Crowdsourced-Images-Scene-Text-Recognition-on-Flickr-and-Problems-to-be-Solved" class="headerlink" title="Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved"></a>Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08042">http://arxiv.org/abs/2309.08042</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ya0-sun/str-berlin">https://github.com/ya0-sun/str-berlin</a></li>
<li>paper_authors: Yao Sun, Anna Kruspe, Liqiu Meng, Yifan Tian, Eike J Hoffmann, Stefan Auer, Xiao Xiang Zhu</li>
<li>for: 这篇论文旨在应用Scene Text Recognition（STR）技术在拼团网络街景图像中映射建筑特征。</li>
<li>methods: 这篇论文使用了Flickr图像，尤其是建筑外墙上的文本。创建了一个Berlin Flickr数据集，并使用预训练的STR模型进行文本检测和识别。</li>
<li>results: 手动检查一 subset 的 STR-识别图像表示高准确性。研究表明，STR 结果和建筑功能之间存在相关性，并分析了在 residential 建筑上文本出现的情况。但是，这种任务还存在许多挑战，包括街景图像中文本区域较小、缺乏ground truth标签和 Flickr 图像中建筑与OpenStreetMap 中建筑的不匹配。为了开发城市范围内的映射，建议在不同的场景下开发适当的算法或者引入其他数据来处理其他情况。此外，应进行多学科合作，以理解摄影和标注建筑的动机。 STR-on-Flickr 结果可在 <a target="_blank" rel="noopener" href="https://github.com/ya0-sun/STR-Berlin">https://github.com/ya0-sun/STR-Berlin</a> 中获得。<details>
<summary>Abstract</summary>
Crowdsourced platforms provide huge amounts of street-view images that contain valuable building information. This work addresses the challenges in applying Scene Text Recognition (STR) in crowdsourced street-view images for building attribute mapping. We use Flickr images, particularly examining texts on building facades. A Berlin Flickr dataset is created, and pre-trained STR models are used for text detection and recognition. Manual checking on a subset of STR-recognized images demonstrates high accuracy. We examined the correlation between STR results and building functions, and analysed instances where texts were recognized on residential buildings but not on commercial ones. Further investigation revealed significant challenges associated with this task, including small text regions in street-view images, the absence of ground truth labels, and mismatches in buildings in Flickr images and building footprints in OpenStreetMap (OSM). To develop city-wide mapping beyond urban hotspot locations, we suggest differentiating the scenarios where STR proves effective while developing appropriate algorithms or bringing in additional data for handling other cases. Furthermore, interdisciplinary collaboration should be undertaken to understand the motivation behind building photography and labeling. The STR-on-Flickr results are publicly available at https://github.com/ya0-sun/STR-Berlin.
</details>
<details>
<summary>摘要</summary>
互助平台提供大量的街景图像，这些图像包含了重要的建筑信息。这项工作面临着在互助平台街景图像中应用场景文本识别（STR）的挑战。我们使用Flickr图像，特别是研究建筑facades上的文本。我们创建了一个Berlin Flickr数据集，并使用预训练的STR模型进行文本检测和识别。对一 subset of STR-识别的图像进行手动检查表明了高准确性。我们研究了STR结果和建筑功能之间的相关性，并分析了在住宅和商业建筑之间文本被识别的情况。进一步的调查发现了这个任务中的主要挑战，包括街景图像中文本区域的小さigkeit，缺乏真实标签数据，以及Flickr图像中的建筑和OpenStreetMap（OSM）中的建筑脚本之间的匹配问题。为了开发城市范围内的映射，我们建议在STR效果明显的场景下使用不同的算法或引入其他数据来处理其他情况。此外，我们建议进行多学科协作，以理解摄影和标注建筑的动机。STR-on-Flickr结果公共可用于https://github.com/ya0-sun/STR-Berlin。
</details></li>
</ul>
<hr>
<h2 id="BEA-Revisiting-anchor-based-object-detection-DNN-using-Budding-Ensemble-Architecture"><a href="#BEA-Revisiting-anchor-based-object-detection-DNN-using-Budding-Ensemble-Architecture" class="headerlink" title="BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture"></a>BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08036">http://arxiv.org/abs/2309.08036</a></li>
<li>repo_url: None</li>
<li>paper_authors: Syed Sha Qutub, Neslihan Kose, Rafael Rosales, Michael Paulitsch, Korbinian Hagn, Florian Geissler, Yang Peng, Gereon Hinz, Alois Knoll</li>
<li>for: 提高 anchor-based 物体检测模型的准确率和 uncertainty estimation 质量。</li>
<li>methods: 使用 Budding Ensemble Architecture (BEA) 和提posed 损失函数来改进 confidence score 的准确性和 uncertainty estimation。</li>
<li>results: BEA 可以提高 Base-YOLOv3 和 SSD 模型的 object detection 精度和 uncertainty estimation 质量，并在不同 datasets 上实现更高的 out-of-distribution detection 性能。<details>
<summary>Abstract</summary>
This paper introduces the Budding Ensemble Architecture (BEA), a novel reduced ensemble architecture for anchor-based object detection models. Object detection models are crucial in vision-based tasks, particularly in autonomous systems. They should provide precise bounding box detections while also calibrating their predicted confidence scores, leading to higher-quality uncertainty estimates. However, current models may make erroneous decisions due to false positives receiving high scores or true positives being discarded due to low scores. BEA aims to address these issues. The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives and, eventually, higher accuracy of the object detection models. Both Base-YOLOv3 and SSD models were enhanced using the BEA method and its proposed loss functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6% and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanced uncertainty estimation threshold to discard samples in real-time even leads to a 9.6% higher AP50 than its base model. This is attributed to a 40% increase in the area under the AP50-based retention curve used to measure the quality of calibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTI provides superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets compared to the ensembles and vanilla models of YOLOv3 and Gaussian-YOLOv3.
</details>
<details>
<summary>摘要</summary>
The proposed loss functions in BEA improve the accuracy of object detection models. The BEA method was applied to both Base-YOLOv3 and SSD models, and the results show a significant improvement in accuracy. The BEA on Base-YOLOv3 trained on the KITTI dataset resulted in a 6% and 3.7% increase in mean Average Precision (mAP) and AP50, respectively. Additionally, using a well-balanced uncertainty estimation threshold in real-time led to a 9.6% higher AP50 than the base model. This is attributed to a 40% increase in the area under the AP50-based retention curve, which measures the quality of calibration of confidence scores.Moreover, the BEA-YOLOV3 trained on KITTI provided superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets compared to the ensembles and vanilla models of YOLOv3 and Gaussian-YOLOv3. This demonstrates the effectiveness of the BEA method in improving the accuracy of object detection models.
</details></li>
</ul>
<hr>
<h2 id="Vision-based-Analysis-of-Driver-Activity-and-Driving-Performance-Under-the-Influence-of-Alcohol"><a href="#Vision-based-Analysis-of-Driver-Activity-and-Driving-Performance-Under-the-Influence-of-Alcohol" class="headerlink" title="Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol"></a>Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08021">http://arxiv.org/abs/2309.08021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ross Greer, Akshay Gopalkrishnan, Sumega Mandadi, Pujitha Gunaratne, Mohan M. Trivedi, Thomas D. Marcotte</li>
<li>for: 防止酒后驾车的研究，以实现车辆安全。</li>
<li>methods: 使用多modal的ensemble，包括视觉、热成像、音频和化学感知器，测试酒后驾车的影响和探索测定酒后驾车的方法。</li>
<li>results: 透过computer vision和机器学习模型分析车长的面部热成像，并引入训练模型的管道，以测定车长的呼吸气体含酒量。<details>
<summary>Abstract</summary>
About 30% of all traffic crash fatalities in the United States involve drunk drivers, making the prevention of drunk driving paramount to vehicle safety in the US and other locations which have a high prevalence of driving while under the influence of alcohol. Driving impairment can be monitored through active use of sensors (when drivers are asked to engage in providing breath samples to a vehicle instrument or when pulled over by a police officer), but a more passive and robust mechanism of sensing may allow for wider adoption and benefit of intelligent systems that reduce drunk driving accidents. This could assist in identifying impaired drivers before they drive, or early in the driving process (before a crash or detection by law enforcement). In this research, we introduce a study which adopts a multi-modal ensemble of visual, thermal, audio, and chemical sensors to (1) examine the impact of acute alcohol administration on driving performance in a driving simulator, and (2) identify data-driven methods for detecting driving under the influence of alcohol. We describe computer vision and machine learning models for analyzing the driver's face in thermal imagery, and introduce a pipeline for training models on data collected from drivers with a range of breath-alcohol content levels, including discussion of relevant machine learning phenomena which can help in future experiment design for related studies.
</details>
<details>
<summary>摘要</summary>
关于30%的美国交通事故死亡事故中有报告酒后驾驶，因此防止酒后驾驶是美国和其他有高酒精驾驶习惯的地区的车辆安全问题。驾驶异常可以通过活动使用感测器（当驾驶员被要求提供呼吸样本给车辆工具或被警察停车）进行监测，但更加不间断和可靠的感测方式可能会促使更广泛的应用和智能系统的发展，以降低酒后驾驶事故。这种研究可以帮助检测酒后驾驶之前或在驾驶过程中（前于事故或警察检测）。在这项研究中，我们介绍了一项多模态ensemble的视觉、热成像、声音和化学感测器来（1）分析酒后驾驶性能的影响，以及（2）检测酒后驾驶。我们描述了用于分析驾驶员面部的计算机视觉和机器学习模型，并介绍了一个管道用于在不同呼吸气体含量水平下收集数据，包括讨论有关相关机器学习现象的概念，可以帮助未来相关研究的实验设计。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Evaluation-of-Prompting-Strategies-for-Large-Language-Models-in-Zero-Shot-Clinical-Natural-Language-Processing"><a href="#An-Empirical-Evaluation-of-Prompting-Strategies-for-Large-Language-Models-in-Zero-Shot-Clinical-Natural-Language-Processing" class="headerlink" title="An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing"></a>An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08008">http://arxiv.org/abs/2309.08008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sonish Sivarajkumar, Mark Kelley, Alyssa Samolyk-Mazzanti, Shyam Visweswaran, Yanshan Wang</li>
<li>for: 本研究旨在设计有效的提示方法，以帮助大语言模型（LLMs）在医疗领域进行特定的自然语言处理（NLP）任务，无需任务特定的训练数据。</li>
<li>methods: 本研究使用了现有的提示方法，包括简单前缀、简单补充、链式思维和预测提示，以及两种新的提示方法：准则提示和 ensemble 提示。</li>
<li>results: 研究表明，不同的提示方法在不同的语言模型（GPT-3.5、BARD 和 LLAMA2）上的表现有很大差异。 Ensemble 提示方法在三个语言模型上都表现最佳，而预测提示方法在 GPT-3.5 上表现最好。  Zero-shot 提示与 few-shot 提示的比较也提供了新的视角和指导意见 для LLMs 在医疗 NLP 领域的提示工程。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), especially in domains where labeled data is scarce or expensive, such as clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. In this paper, we present a comprehensive and systematic experimental study on prompt engineering for five clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence Extraction, Coreference Resolution, Medication Status Extraction, and Medication Attribute Extraction. We assessed the prompts proposed in recent literature, including simple prefix, simple cloze, chain of thought, and anticipatory prompts, and introduced two new types of prompts, namely heuristic prompting and ensemble prompting. We evaluated the performance of these prompts on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted zero-shot prompting with few-shot prompting, and provide novel insights and guidelines for prompt engineering for LLMs in clinical NLP. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative AI, and we hope that it will inspire and inform future research in this area.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在自然语言处理（NLP）领域表现出色，特别是在数据 scarcity 或者 expensive 的医疗领域。然而，要激活这些 LLMP 中的医疗知识，我们需要设计有效的提示，使其在无任务特定训练数据的情况下完成特定的医疗 NLP 任务。这被称为“上下文学习”，是一种艺术和科学，需要了解不同 LLMP 的优劣和提示工程方法的特点。在这篇论文中，我们提出了一项全面和系统的实验研究，探讨了不同提示方法的效果在五个医疗 NLP 任务中：医学意思解释、生物医学证据抽取、核心引用解决、药物状态抽取和药物特性抽取。我们评估了现有文献中的提示方法，包括简单前缀、简单填充、链条思维和预测提示，并引入了两种新的提示方法：启发式提示和ensemble提示。我们使用三个当今最先进的 LLMP：GPT-3.5、BARD和LLAMA2进行评估。我们还比较了零shot提示和几shot提示，并提供了新的发现和指导，用于提示工程在医疗 NLP 领域。我们认为，这是目前已知的一些实验性的探讨不同提示工程方法的第一个研究，希望能启发和引导未来的研究。
</details></li>
</ul>
<hr>
<h2 id="An-Automated-Machine-Learning-Approach-for-Detecting-Anomalous-Peak-Patterns-in-Time-Series-Data-from-a-Research-Watershed-in-the-Northeastern-United-States-Critical-Zone"><a href="#An-Automated-Machine-Learning-Approach-for-Detecting-Anomalous-Peak-Patterns-in-Time-Series-Data-from-a-Research-Watershed-in-the-Northeastern-United-States-Critical-Zone" class="headerlink" title="An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone"></a>An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07992">http://arxiv.org/abs/2309.07992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ijaz Ul Haq, Byung Suk Lee, Donna M. Rizzo, Julia N Perdrial</li>
<li>for: 这个研究旨在帮助水文学家在某些敏感区域中检测时间序列数据中的异常。</li>
<li>methods: 这个框架使用自动化机器学习方法，包括生成模型和自动化模型优化机制，以检测时间序列数据中的异常。</li>
<li>results: 研究表明，这个框架可以帮助水文学家选择最适合的模型实例，并在检测异常过程中提高准确率和计算效率。<details>
<summary>Abstract</summary>
This paper presents an automated machine learning framework designed to assist hydrologists in detecting anomalies in time series data generated by sensors in a research watershed in the northeastern United States critical zone. The framework specifically focuses on identifying peak-pattern anomalies, which may arise from sensor malfunctions or natural phenomena. However, the use of classification methods for anomaly detection poses challenges, such as the requirement for labeled data as ground truth and the selection of the most suitable deep learning model for the given task and dataset. To address these challenges, our framework generates labeled datasets by injecting synthetic peak patterns into synthetically generated time series data and incorporates an automated hyperparameter optimization mechanism. This mechanism generates an optimized model instance with the best architectural and training parameters from a pool of five selected models, namely Temporal Convolutional Network (TCN), InceptionTime, MiniRocket, Residual Networks (ResNet), and Long Short-Term Memory (LSTM). The selection is based on the user's preferences regarding anomaly detection accuracy and computational cost. The framework employs Time-series Generative Adversarial Networks (TimeGAN) as the synthetic dataset generator. The generated model instances are evaluated using a combination of accuracy and computational cost metrics, including training time and memory, during the anomaly detection process. Performance evaluation of the framework was conducted using a dataset from a watershed, demonstrating consistent selection of the most fitting model instance that satisfies the user's preferences.
</details>
<details>
<summary>摘要</summary>
中文翻译：这篇论文提出了一个自动化机器学习框架，用于帮助 hidrologists 在感知器数据中检测峰嵌入的异常。该框架具体关注 peak-pattern 异常的检测，可能由感知器故障或自然现象引起。然而，使用分类方法进行异常检测存在挑战，包括需要标注数据作为真实数据和选择适合给定任务和数据集的最佳深度学习模型。为Addressing these challenges, the proposed framework generates labeled datasets by injecting synthetic peak patterns into synthetically generated time series data and optimizes model hyperparameters based on the user's preferences. The framework uses Time-series Generative Adversarial Networks (TimeGAN) as the synthetic dataset generator and evaluates model performance using a combination of accuracy and computational cost metrics. The proposed framework was evaluated using a real-world dataset and demonstrated consistent selection of the most fitting model instance that satisfies the user's preferences.
</details></li>
</ul>
<hr>
<h2 id="Viewpoint-Textual-Inversion-Unleashing-Novel-View-Synthesis-with-Pretrained-2D-Diffusion-Models"><a href="#Viewpoint-Textual-Inversion-Unleashing-Novel-View-Synthesis-with-Pretrained-2D-Diffusion-Models" class="headerlink" title="Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models"></a>Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07986">http://arxiv.org/abs/2309.07986</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Burgess, Kuan-Chieh Wang, Serena Yeung</li>
<li>for: 这个论文是为了检验文本扩散模型是否能够学习3D结构，并在2D超视觉下生成3D图像。</li>
<li>methods: 这个论文使用了稳定扩散模型，并提出了一种基于摄像头视角参数的视角神经网络，用于控制生成图像的3D视图角。</li>
<li>results: 该方法可以解决缺少输入视图的新视角合成问题，并且可以生成具有 semantic detail 和 photorealism 的单视图新视角图像。此外，该方法还可以生成多种样本，用于模拟3D视觉问题中的不确定性。<details>
<summary>Abstract</summary>
Text-to-image diffusion models understand spatial relationship between objects, but do they represent the true 3D structure of the world from only 2D supervision? We demonstrate that yes, 3D knowledge is encoded in 2D image diffusion models like Stable Diffusion, and we show that this structure can be exploited for 3D vision tasks. Our method, Viewpoint Neural Textual Inversion (ViewNeTI), controls the 3D viewpoint of objects in generated images from frozen diffusion models. We train a small neural mapper to take camera viewpoint parameters and predict text encoder latents; the latents then condition the diffusion generation process to produce images with the desired camera viewpoint.   ViewNeTI naturally addresses Novel View Synthesis (NVS). By leveraging the frozen diffusion model as a prior, we can solve NVS with very few input views; we can even do single-view novel view synthesis. Our single-view NVS predictions have good semantic details and photorealism compared to prior methods. Our approach is well suited for modeling the uncertainty inherent in sparse 3D vision problems because it can efficiently generate diverse samples. Our view-control mechanism is general, and can even change the camera view in images generated by user-defined prompts.
</details>
<details>
<summary>摘要</summary>
文本到图像扩散模型理解图像中对象之间的空间关系，但它们真的从只有2D监督学习到3D世界的真实结构吗？我们证明，2D图像扩散模型如稳定扩散，其中包含3D知识，并且我们表明了这种结构可以用于3D视觉任务。我们的方法，Viewpoint Neural Textual Inversion（ViewNeTI），可以控制扩散模型中的3D视角，从冻结扩散模型中生成图像。我们训练一个小的神经映射器，接受摄像机视角参数，并使用这些参数预测文本编码器的精度，然后这些精度控制扩散生成过程，以生成图像。ViewNeTI自然地解决了新视角合成（NVS）问题。通过利用冻结扩散模型作为先验，我们可以通过非常少的输入视图来解决NVS问题，甚至可以实现单视图新视角合成。我们的单视图NVS预测具有较好的semantic detail和photorealism，比之前的方法更好。我们的方法适合处理稀疏3D视觉问题中的uncertainty，可以快速生成多样的样本。我们的视角控制机制通用，可以改变图像中的摄像机视角，甚至可以在用户定义的提示中改变摄像机视角。
</details></li>
</ul>
<hr>
<h2 id="A-Data-Source-for-Reasoning-Embodied-Agents"><a href="#A-Data-Source-for-Reasoning-Embodied-Agents" class="headerlink" title="A Data Source for Reasoning Embodied Agents"></a>A Data Source for Reasoning Embodied Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07974">http://arxiv.org/abs/2309.07974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/neuralmemory">https://github.com/facebookresearch/neuralmemory</a></li>
<li>paper_authors: Jack Lanchantin, Sainbayar Sukhbaatar, Gabriel Synnaeve, Yuxuan Sun, Kavya Srinet, Arthur Szlam</li>
<li>for: 这个论文的目的是探讨机器学习模型在理解任务中的进步，并提出了一种新的数据生成器来支持这些进步。</li>
<li>methods: 这个论文使用了新的模型架构、大规模预训练协议和专门的理解任务数据集来训练机器学习模型。</li>
<li>results: 研究人员通过对世界状态和机器人行为所生成的数据进行实例化，并使用了预训练语言模型和图structured Transformers来训练模型。然而，这些模型在 answering some questions about the world-state 方面表现不佳，这表明了设计神经网络理解模型和数据库表示方法的新研究方向。<details>
<summary>Abstract</summary>
Recent progress in using machine learning models for reasoning tasks has been driven by novel model architectures, large-scale pre-training protocols, and dedicated reasoning datasets for fine-tuning. In this work, to further pursue these advances, we introduce a new data generator for machine reasoning that integrates with an embodied agent. The generated data consists of templated text queries and answers, matched with world-states encoded into a database. The world-states are a result of both world dynamics and the actions of the agent. We show the results of several baseline models on instantiations of train sets. These include pre-trained language models fine-tuned on a text-formatted representation of the database, and graph-structured Transformers operating on a knowledge-graph representation of the database. We find that these models can answer some questions about the world-state, but struggle with others. These results hint at new research directions in designing neural reasoning models and database representations. Code to generate the data will be released at github.com/facebookresearch/neuralmemory
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MMICL-Empowering-Vision-language-Model-with-Multi-Modal-In-Context-Learning"><a href="#MMICL-Empowering-Vision-language-Model-with-Multi-Modal-In-Context-Learning" class="headerlink" title="MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning"></a>MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07915">http://arxiv.org/abs/2309.07915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haozhezhao/mic">https://github.com/haozhezhao/mic</a></li>
<li>paper_authors: Haozhe Zhao, Zefan Cai, Shuzheng Si, Xiaojian Ma, Kaikai An, Liang Chen, Zixuan Liu, Sheng Wang, Wenjuan Han, Baobao Chang</li>
<li>for: 这种论文是为了解决现代计算机视觉语言模型（VLMs）在处理复杂多模态提示时的问题。</li>
<li>methods: 该论文提出了一种名为 MMICL 的新方法，该方法包括一种特制的架构设计，可以快速地结合视觉和文本上下文，以及一个名为 MIC 的数据集，用于减少训练数据和实际应用中的复杂多模态提示之间的差距。</li>
<li>results: 该论文的实验结果表明，MMICL 可以在各种通用视觉语言任务上达到新的状态机器人性和少量参数性，尤其是在复杂的推理核心任务上，如 MME 和 MMBench。此外，实验还表明，MMICL 可以成功解决多模态提示理解的挑战。<details>
<summary>Abstract</summary>
Starting from the resurgence of deep learning, vision-language models (VLMs) benefiting from large language models (LLMs) have never been so popular. However, while LLMs can utilize extensive background knowledge and task information with in-context learning, most VLMs still struggle with understanding complex multi-modal prompts with multiple images. The issue can traced back to the architectural design of VLMs or pre-training data. Specifically, the current VLMs primarily emphasize utilizing multi-modal data with a single image some, rather than multi-modal prompts with interleaved multiple images and text. Even though some newly proposed VLMs could handle user prompts with multiple images, pre-training data does not provide more sophisticated multi-modal prompts than interleaved image and text crawled from the web. We propose MMICL to address the issue by considering both the model and data perspectives. We introduce a well-designed architecture capable of seamlessly integrating visual and textual context in an interleaved manner and MIC dataset to reduce the gap between the training data and the complex user prompts in real-world applications, including: 1) multi-modal context with interleaved images and text, 2) textual references for each image, and 3) multi-image data with spatial, logical, or temporal relationships. Our experiments confirm that MMICL achieves new stat-of-the-art zero-shot and few-shot performance on a wide range of general vision-language tasks, especially for complex reasoning benchmarks including MME and MMBench. Our analysis demonstrates that MMICL effectively deals with the challenge of complex multi-modal prompt understanding. The experiments on ScienceQA-IMG also show that MMICL successfully alleviates the issue of language bias in VLMs, which we believe is the reason behind the advanced performance of MMICL.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Multi-modal context with interleaved images and text2. Textual references for each image3. Multi-image data with spatial, logical, or temporal relationshipsOur experiments confirm that MMICL achieves new state-of-the-art zero-shot and few-shot performance on a wide range of general vision-language tasks, especially for complex reasoning benchmarks including MME and MMBench. Our analysis demonstrates that MMICL effectively deals with the challenge of complex multi-modal prompt understanding. The experiments on ScienceQA-IMG also show that MMICL successfully alleviates the issue of language bias in VLMs, which we believe is the reason behind the advanced performance of MMICL.</details></li>
</ol>
<hr>
<h2 id="Beta-Diffusion"><a href="#Beta-Diffusion" class="headerlink" title="Beta Diffusion"></a>Beta Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07867">http://arxiv.org/abs/2309.07867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ThisisBillhe/tiny-stable-diffusion">https://github.com/ThisisBillhe/tiny-stable-diffusion</a></li>
<li>paper_authors: Mingyuan Zhou, Tianqi Chen, Zhendong Wang, Huangjie Zheng</li>
<li>for:  beta diffusion是一种新的生成模型方法，用于生成在固定范围内的数据。</li>
<li>methods: beta diffusion使用了扩展和平移beta分布，通过多项式过程来实现时间的扩展和收缩，保持beta分布在前向采样和反向采样中。不同于传统的扩散基本模型， beta diffusion不使用加itive Gaussian噪声和重量化的证据下界（ELBO），而是使用KL divergence上界（KLUB），从而更好地优化模型。</li>
<li>results: 对于synthetic数据和自然图像，beta diffusion表现出了生成固定范围内数据的独特能力，并证明了KLUB的优化效果。<details>
<summary>Abstract</summary>
We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them.
</details>
<details>
<summary>摘要</summary>
我们介绍β扩散，一种新的生成模型方法，它结合掩盖和去噪来生成在给定范围内的数据。使用了标准化和偏移的β分布，β扩散利用时间的滑动积分来创建前向和反向的扩散过程，维持β分布在前向的预期和反向的条件下，对于任何时间点的数据。不同于传统的扩散基本生成模型，利用加法的 Gaussian 噪声和重新权重的证据下界（ELBO），β扩散是multiplicative的，并且通过对KL散度的上界（KLUB）来优化。我们示出了KLUBs的更高效性 compared to负ELBOs，这些KLUBs可以 viewed as KL散度的对称�。数据的损失函数表示为Bregman散度，进一步支持了KLUBs的优化。实验结果显示β扩散在给定范围内的生成模型和自然图像中的独特能力，并且证明了KLUBs在扩散模型的优化中的效iveness，因此它们成为了扩散基本生成模型和优化技术的有用贡献。
</details></li>
</ul>
<hr>
<h2 id="The-Rise-and-Potential-of-Large-Language-Model-Based-Agents-A-Survey"><a href="#The-Rise-and-Potential-of-Large-Language-Model-Based-Agents-A-Survey" class="headerlink" title="The Rise and Potential of Large Language Model Based Agents: A Survey"></a>The Rise and Potential of Large Language Model Based Agents: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07864">http://arxiv.org/abs/2309.07864</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/woooodyy/llm-agent-paper-list">https://github.com/woooodyy/llm-agent-paper-list</a></li>
<li>paper_authors: Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, Tao Gui<br>for: This paper aims to provide a comprehensive survey of large language model (LLM)-based agents, exploring their potential for building general artificial intelligence (AGI) agents.methods: The paper presents a general framework for LLM-based agents, consisting of three main components: brain, perception, and action. The framework can be tailored for different applications.results: The paper discusses the extensive applications of LLM-based agents in single-agent scenarios, multi-agent scenarios, and human-agent cooperation. It also explores agent societies, social phenomena, and insights for human society.<details>
<summary>Abstract</summary>
For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.
</details>
<details>
<summary>摘要</summary>
人类一直追求人类水平或更高的人工智能（AI），AI代理人被视为可能的实现之路。AI代理人是人工智能中的人工实体，它可以感知环境，做出决策，并进行行动。尽管有很多努力，但大多数努力都集中在算法或训练策略的提高上，以提高特定任务的能力。然而，实际上，社区缺乏一个通用和强大的模型，用于设计可适应多种场景的AI代理人。由于它们的多样化能力，大型自然语言模型（LLM）被视为人工通用智能（AGI）的可能的燃点，提供了建立通用AI代理人的希望。许多研究人员已经利用LLM作为基础，建立了AI代理人，并取得了 significativ进步。在这篇论文中，我们进行了LLM-based agents的全面评估。我们从哲学起源追溯代理人概念，并解释了LLM的适用性，并在这基础之上提出了一个通用框架，包括脑、感知和行动三个主要组成部分，该框架可以适应不同应用场景。然后，我们探讨了LLM-based agents在单机场景、多机场景和人机合作场景中的广泛应用。接着，我们探索了代理人社会中的行为和个性，以及由代理人社会产生的社会现象和人类社会中的意见。最后，我们讨论了领域内的一些关键问题和开放问题。相关论文的存储库可以在https://github.com/WooooDyy/LLM-Agent-Paper-List中找到。
</details></li>
</ul>
<hr>
<h2 id="CiwaGAN-Articulatory-information-exchange"><a href="#CiwaGAN-Articulatory-information-exchange" class="headerlink" title="CiwaGAN: Articulatory information exchange"></a>CiwaGAN: Articulatory information exchange</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07861">http://arxiv.org/abs/2309.07861</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gbegus/articulationgan">https://github.com/gbegus/articulationgan</a></li>
<li>paper_authors: Gašper Beguš, Thomas Lu, Alan Zhou, Peter Wu, Gopala K. Anumanchipalli</li>
<li>for: 本研究旨在提供一个人类语言学习的模型，用于模拟人类语音认知和语音交流过程。</li>
<li>methods: 本研究使用了不supervised的articulatory模型和auditory模型，combined these two components to simulate human spoken language acquisition。</li>
<li>results: 提出的CiwaGAN模型是人类语言学习最实际的数据学习模型，可以用于认知可能性最高的人类语音认知 simulations。<details>
<summary>Abstract</summary>
Humans encode information into sounds by controlling articulators and decode information from sounds using the auditory apparatus. This paper introduces CiwaGAN, a model of human spoken language acquisition that combines unsupervised articulatory modeling with an unsupervised model of information exchange through the auditory modality. While prior research includes unsupervised articulatory modeling and information exchange separately, our model is the first to combine the two components. The paper also proposes an improved articulatory model with more interpretable internal representations. The proposed CiwaGAN model is the most realistic approximation of human spoken language acquisition using deep learning. As such, it is useful for cognitively plausible simulations of the human speech act.
</details>
<details>
<summary>摘要</summary>
人类将信息转化为声音，控制口音器官，并通过听觉器官解码信息。这篇论文介绍了 CiwaGAN，一种人类口语学习模型，把无监督的口音模型与无监督的听觉模型相结合。在之前的研究中，这两种 ком ponent都被处理了分开。我们的模型是第一个将这两个组件结合起来的。文章还提出了一种改进的口音模型，具有更可读的内部表示。提出的 CiwaGAN 模型是人类口语学习使用深度学习的最真实的近似，因此它对于人类语音行为的认知可能性 simulations 非常有用。
</details></li>
</ul>
<hr>
<h2 id="ExpertQA-Expert-Curated-Questions-and-Attributed-Answers"><a href="#ExpertQA-Expert-Curated-Questions-and-Attributed-Answers" class="headerlink" title="ExpertQA: Expert-Curated Questions and Attributed Answers"></a>ExpertQA: Expert-Curated Questions and Attributed Answers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07852">http://arxiv.org/abs/2309.07852</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaitanyamalaviya/expertqa">https://github.com/chaitanyamalaviya/expertqa</a></li>
<li>paper_authors: Chaitanya Malaviya, Subin Lee, Sihao Chen, Elizabeth Sieber, Mark Yatskar, Dan Roth</li>
<li>for: 这个论文的目的是研究语言模型的准确性和归因性在不同领域中的表现。</li>
<li>methods: 这篇论文使用了专家参与的方法来评估语言模型的输出是否符合事实，并生成了一个高质量的长形问答数据集（ExpertQA），包括2177个问题和32个领域的专家回答和归因。</li>
<li>results: 研究发现，语言模型在不同领域中的准确性和归因性表现不一样，并且存在一些领域的专家知识偏见。这些结果可以帮助改进语言模型的训练和应用。<details>
<summary>Abstract</summary>
As language models are adapted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study & professions. This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences. Previous work studying factuality and attribution has not focused on analyzing these characteristics of language model outputs in domain-specific scenarios. In this work, we present an evaluation study analyzing various axes of factuality and attribution provided in responses from a few systems, by bringing domain experts in the loop. Specifically, we first collect expert-curated questions from 484 participants across 32 fields of study, and then ask the same experts to evaluate generated responses to their own questions. We also ask experts to revise answers produced by language models, which leads to ExpertQA, a high-quality long-form QA dataset with 2177 questions spanning 32 fields, along with verified answers and attributions for claims in the answers.
</details>
<details>
<summary>摘要</summary>
随着语言模型被更多的复杂和多样化的用户采用，保证它们提供的信息是正确的和可靠的 sources 的重要性在不同领域和职业中日益增加。特别是在高度危险的领域，如医学和法律， propagating  false information 可能导致社会不良影响。 previous work  studying factuality and attribution 没有专门研究这些语言模型输出的特点在具体的场景下。在这种工作中，我们介绍一项评估研究，检查不同的 factuality 和 attribution 特点在语言模型输出中。 Specifically，我们首先收集了 484 名专家参与者从 32 个领域提供的专家挑选的问题，然后询问这些专家评估生成的回答。我们还让专家修改语言模型生成的答案，从而得到 ExpertQA，一个高质量的长文 QA 数据集，包括 2177 个问题和32 个领域的准确答案和声明。
</details></li>
</ul>
<hr>
<h2 id="Applying-Deep-Learning-to-Calibrate-Stochastic-Volatility-Models"><a href="#Applying-Deep-Learning-to-Calibrate-Stochastic-Volatility-Models" class="headerlink" title="Applying Deep Learning to Calibrate Stochastic Volatility Models"></a>Applying Deep Learning to Calibrate Stochastic Volatility Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07843">http://arxiv.org/abs/2309.07843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abir Sridi, Paul Bilokon<br>for: This paper aims to improve the calibration of stochastic volatility models by using deep learning techniques to speed up the calibration process and achieve more accurate results.methods: The authors use a differential deep learning (DDL) approach, which involves training machine learning models on samples of not only features and labels but also differentials of labels to features. They also compare the performance of different regularization techniques and show that the DDL approach outperforms classical deep learning methods.results: The trained neural network dramatically reduces the computation time required for Heston calibration, and the DDL approach outperforms classical deep learning methods in terms of reducing overfitting and improving generalization error.<details>
<summary>Abstract</summary>
Stochastic volatility models, where the volatility is a stochastic process, can capture most of the essential stylized facts of implied volatility surfaces and give more realistic dynamics of the volatility smile or skew. However, they come with the significant issue that they take too long to calibrate.   Alternative calibration methods based on Deep Learning (DL) techniques have been recently used to build fast and accurate solutions to the calibration problem. Huge and Savine developed a Differential Deep Learning (DDL) approach, where Machine Learning models are trained on samples of not only features and labels but also differentials of labels to features. The present work aims to apply the DDL technique to price vanilla European options (i.e. the calibration instruments), more specifically, puts when the underlying asset follows a Heston model and then calibrate the model on the trained network. DDL allows for fast training and accurate pricing. The trained neural network dramatically reduces Heston calibration's computation time.   In this work, we also introduce different regularisation techniques, and we apply them notably in the case of the DDL. We compare their performance in reducing overfitting and improving the generalisation error. The DDL performance is also compared to the classical DL (without differentiation) one in the case of Feed-Forward Neural Networks. We show that the DDL outperforms the DL.
</details>
<details>
<summary>摘要</summary>
In this work, we also introduce different regularization techniques, and we apply them notably in the case of the DDL. We compare their performance in reducing overfitting and improving the generalization error. The DDL performance is also compared to the classical DL (without differentiation) one in the case of feed-forward neural networks. We show that the DDL outperforms the DL.  Translated into Simplified Chinese:随机波动模型可以捕捉证券波动表面的主要特征，但它们需要较长时间来均值。  alternatively, deep learning (DL) 技术已经用于构建快速和准确的均值问题解决方案。  huge and Savine 提出了差分深度学习（DDL）方法，其中机器学习模型在样本中学习不 только特征和标签，还学习标签与特征之间的差分。 当前的工作是使用 DDL 方法估算欧洲 vanilla 选择（即均值工具），具体来说是在 Heston 模型下估算 puts。 DDL 允许快速训练和精准估算。 训练神经网络对 Heston 均值的计算时间减少了很多。在这个工作中，我们还引入了不同的规范技术，并在 DDL 中应用它们。 我们比较它们在避免过拟合和提高通用错误的性能。 DDL 性能也与无梯度的深度学习（DL）相比。 我们显示了 DDL 在 feed-forward 神经网络中的性能明显超过了 DL。
</details></li>
</ul>
<hr>
<h2 id="Two-Timin’-Repairing-Smart-Contracts-With-A-Two-Layered-Approach"><a href="#Two-Timin’-Repairing-Smart-Contracts-With-A-Two-Layered-Approach" class="headerlink" title="Two Timin’: Repairing Smart Contracts With A Two-Layered Approach"></a>Two Timin’: Repairing Smart Contracts With A Two-Layered Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07841">http://arxiv.org/abs/2309.07841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhinav Jain, Ehan Masud, Michelle Han, Rohan Dhillon, Sumukh Rao, Arya Joshi, Salar Cheema, Saurav Kumar</li>
<li>for: 本研究旨在提出一种两层框架，用于自动检测和修复智能合约中的攻击漏洞。</li>
<li>methods: 该框架包括两个层：第一层是使用 Slither 漏洞报告和源代码，通过预训练 RandomForestClassifier (RFC) 和 Large Language Models (LLMs) 进行分类和修复漏洞。第二层是使用预训练 GPT-3.5-Turbo 和 fine-tuned Llama-2-7B 模型来构建智能合约修复模型。</li>
<li>results: 实验表明，使用 Fine-tuned Llama-2-7B 模型可以将总体漏洞数量减少为 97.5%，使用 GPT-3.5-Turbo 模型可以减少总体漏洞数量为 96.7%。手动检查修复后的合约显示，所有修复后的合约都保持了功能， indicating that the proposed method is appropriate for automatic batch classification and repair of vulnerabilities in smart contracts。<details>
<summary>Abstract</summary>
Due to the modern relevance of blockchain technology, smart contracts present both substantial risks and benefits. Vulnerabilities within them can trigger a cascade of consequences, resulting in significant losses. Many current papers primarily focus on classifying smart contracts for malicious intent, often relying on limited contract characteristics, such as bytecode or opcode. This paper proposes a novel, two-layered framework: 1) classifying and 2) directly repairing malicious contracts. Slither's vulnerability report is combined with source code and passed through a pre-trained RandomForestClassifier (RFC) and Large Language Models (LLMs), classifying and repairing each suggested vulnerability. Experiments demonstrate the effectiveness of fine-tuned and prompt-engineered LLMs. The smart contract repair models, built from pre-trained GPT-3.5-Turbo and fine-tuned Llama-2-7B models, reduced the overall vulnerability count by 97.5% and 96.7% respectively. A manual inspection of repaired contracts shows that all retain functionality, indicating that the proposed method is appropriate for automatic batch classification and repair of vulnerabilities in smart contracts.
</details>
<details>
<summary>摘要</summary>
（因为现代区块链技术的现代性，智能合约具有严重的风险和利益。在这些合约中，漏洞可能导致重大的后果，包括重要的损失。许多当前的论文主要关注智能合约的恶意意图，常常基于限制的合约特征，如字节码或操作码。本文提出了一种新的、两层架构：1）分类和2）直接修复恶意合约。使用Slither的漏洞报告，并将源代码与预训练的RandomForestClassifier（RFC）和大语言模型（LLMs）结合，对每个建议的漏洞进行分类和修复。实验表明，使用精制和提交的LLMs得到了有效的结果。智能合约修复模型，基于预训练的GPT-3.5-Turbo和精制的Llama-2-7B模型，将总体漏洞数量减少了97.5%和96.7%。人工检查修复的合约显示所有都保留了功能，表明提posed方法适用于自动批处理和修复智能合约中的漏洞。）
</details></li>
</ul>
<hr>
<h2 id="VAPOR-Legged-Robot-Navigation-in-Outdoor-Vegetation-Using-Offline-Reinforcement-Learning"><a href="#VAPOR-Legged-Robot-Navigation-in-Outdoor-Vegetation-Using-Offline-Reinforcement-Learning" class="headerlink" title="VAPOR: Legged Robot Navigation in Outdoor Vegetation Using Offline Reinforcement Learning"></a>VAPOR: Legged Robot Navigation in Outdoor Vegetation Using Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07832">http://arxiv.org/abs/2309.07832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kasunweerkoon/VAPOR">https://github.com/kasunweerkoon/VAPOR</a></li>
<li>paper_authors: Kasun Weerakoon, Adarsh Jagan Sathyamoorthy, Mohamed Elnoor, Dinesh Manocha</li>
<li>for: 本研究は、自律的な四肢动物ロボットが、密集した OUTDOOR 环境での自律ナビゲーションを自动化するために、オフラインの强化学习（RL）を使用した新しい方法を提案します。</li>
<li>methods: 本研究で使用された方法は、actor-critic ネットワークを使用して、実际の OUTDOOR 环境で収集されたある程度のデータを使用して、物理的なおよび几何学的な障害物の特性を学习します。</li>
<li>results: 本研究では、Spot ロボットを使用して、复雑な実际の OUTDOOR シーンでの成功率が、先行方法よりも40%増加しました。また、平均的な电流消耗が2.9%减少し、一般化されたトレジット长さが11.2%减少しました。<details>
<summary>Abstract</summary>
We present VAPOR, a novel method for autonomous legged robot navigation in unstructured, densely vegetated outdoor environments using offline Reinforcement Learning (RL). Our method trains a novel RL policy using an actor-critic network and arbitrary data collected in real outdoor vegetation. Our policy uses height and intensity-based cost maps derived from 3D LiDAR point clouds, a goal cost map, and processed proprioception data as state inputs, and learns the physical and geometric properties of the surrounding obstacles such as height, density, and solidity/stiffness. The fully-trained policy's critic network is then used to evaluate the quality of dynamically feasible velocities generated from a novel context-aware planner. Our planner adapts the robot's velocity space based on the presence of entrapment inducing vegetation, and narrow passages in dense environments. We demonstrate our method's capabilities on a Spot robot in complex real-world outdoor scenes, including dense vegetation. We observe that VAPOR's actions improve success rates by up to 40%, decrease the average current consumption by up to 2.9%, and decrease the normalized trajectory length by up to 11.2% compared to existing end-to-end offline RL and other outdoor navigation methods.
</details>
<details>
<summary>摘要</summary>
我们介绍VAPOR方法，一种用于自主四肢机器人在未结构化、植被茂盛的户外环境中进行自主导航的新方法。我们的方法使用actor-critic网络来训练一个RL政策，并使用实际在户外植被中收集的任意数据进行训练。我们的政策使用高度和强度基于的成本地图、目标成本地图和处理后的 proprioception 数据作为输入，并学习周围障碍物的物理和几何特性，如高度、密度和坚硬程度。我们的完全训练的政策批评网络然后用于评估 dynamically feasible 的速度。我们的 плаanner 适应机器人的速度空间基于植被引起的困难和窄通道在密集环境中。我们在Spot机器人上展示了我们的方法在复杂的实际户外场景中的能力，包括密集的植被。我们观察到VAPOR的行动可以提高成功率达到40%，降低平均电池电 consumption达到2.9%，降低 нормализа trajectory length达到11.2%相比于现有的端到端Offline RL和其他户外导航方法。
</details></li>
</ul>
<hr>
<h2 id="Large-scale-Weakly-Supervised-Learning-for-Road-Extraction-from-Satellite-Imagery"><a href="#Large-scale-Weakly-Supervised-Learning-for-Road-Extraction-from-Satellite-Imagery" class="headerlink" title="Large-scale Weakly Supervised Learning for Road Extraction from Satellite Imagery"></a>Large-scale Weakly Supervised Learning for Road Extraction from Satellite Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07823">http://arxiv.org/abs/2309.07823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiqiao Meng, Zonglin Di, Siwei Yang, Yin Wang</li>
<li>for: 这个论文是为了提出一种基于深度学习的自动道路检测方法，以代替传统的手动地图生成。</li>
<li>methods: 这种方法使用了大规模的卫星图像和开源地图数据作为弱标签，并使用了D-LinkNet架构和ResNet-50背景网络进行Semantic segmentation模型的预训练。</li>
<li>results: 该方法的预测精度随着弱标签数据的Amount和地区训练地点的道路密度而增长，并在目前的DeepGlobe领先者排行板上超越了前一代的表现。此外，由于大规模预训练，该模型在不同的拍摄条件下Generalizes much better than通过只使用CURATED datasets进行训练的模型。<details>
<summary>Abstract</summary>
Automatic road extraction from satellite imagery using deep learning is a viable alternative to traditional manual mapping. Therefore it has received considerable attention recently. However, most of the existing methods are supervised and require pixel-level labeling, which is tedious and error-prone. To make matters worse, the earth has a diverse range of terrain, vegetation, and man-made objects. It is well known that models trained in one area generalize poorly to other areas. Various shooting conditions such as light and angel, as well as different image processing techniques further complicate the issue. It is impractical to develop training data to cover all image styles. This paper proposes to leverage OpenStreetMap road data as weak labels and large scale satellite imagery to pre-train semantic segmentation models. Our extensive experimental results show that the prediction accuracy increases with the amount of the weakly labeled data, as well as the road density in the areas chosen for training. Using as much as 100 times more data than the widely used DeepGlobe road dataset, our model with the D-LinkNet architecture and the ResNet-50 backbone exceeds the top performer of the current DeepGlobe leaderboard. Furthermore, due to large-scale pre-training, our model generalizes much better than those trained with only the curated datasets, implying great application potential.
</details>
<details>
<summary>摘要</summary>
自动从卫星影像中提取公路是一种可行的代替方案，因此在最近受到了广泛关注。然而，大多数现有方法都是指导的，需要像素级标注，这是费时和容易出错的。更重要的是，地球上有多种地形、植被和人工物，模型在一个区域内训练后难以在其他区域中泛化。另外，不同的拍摄条件，如光照和视角，以及不同的图像处理技术，进一步复杂了问题。难以开发卷积数据来覆盖所有的图像风格。这篇文章提议利用OpenStreetMap公路数据作为弱标签，并使用大规模卫星影像进行预训练 semantic segmentation 模型。我们的广泛实验结果表明，随着弱标签数据的增加，以及训练区域中公路的密度，预测精度也随之提高。使用100倍以上的数据，我们的模型结构为D-LinkNet和ResNet-50脊梁的模型超过了目前DeepGlobe领先者板块。此外，由于大规模预训练，我们的模型比只使用精心编辑的数据进行训练，更好地泛化。
</details></li>
</ul>
<hr>
<h2 id="What-Matters-to-Enhance-Traffic-Rule-Compliance-of-Imitation-Learning-for-Automated-Driving"><a href="#What-Matters-to-Enhance-Traffic-Rule-Compliance-of-Imitation-Learning-for-Automated-Driving" class="headerlink" title="What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving"></a>What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07808">http://arxiv.org/abs/2309.07808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongkuan Zhou, Aifen Sui, Wei Cao, Letian Shi</li>
<li>For: 这项研究旨在提高终端自动驾驶技术的总性性能，通过对整个驾驶管道进行单个神经网络的替换，以提高驾驶管道的简洁性和决策速度。* Methods: 该项研究提出了一种名为P-CSG的罚款基于仿真学习方法，该方法通过融合多种感知技术来提高终端自动驾驶的总性性能。* Results: 研究人员通过使用 Town 05 Long 测试准 benchmark，发现该模型在终端自动驾驶方面实现了15%以上的驾驶得分提升，并对基eline模型进行了比较。此外，研究人员还对模型进行了Robustness测试，发现该模型在对FGSM和Dot等敌意攻击的robustness性得到了显著提高。<details>
<summary>Abstract</summary>
More research attention has recently been given to end-to-end autonomous driving technologies where the entire driving pipeline is replaced with a single neural network because of its simpler structure and faster inference time. Despite this appealing approach largely reducing the components in driving pipeline, its simplicity also leads to interpretability problems and safety issues arXiv:2003.06404. The trained policy is not always compliant with the traffic rules and it is also hard to discover the reason for the misbehavior because of the lack of intermediate outputs. Meanwhile, Sensors are also critical to autonomous driving's security and feasibility to perceive the surrounding environment under complex driving scenarios. In this paper, we proposed P-CSG, a novel penalty-based imitation learning approach with cross semantics generation sensor fusion technologies to increase the overall performance of End-to-End Autonomous Driving. We conducted an assessment of our model's performance using the Town 05 Long benchmark, achieving an impressive driving score improvement of over 15%. Furthermore, we conducted robustness evaluations against adversarial attacks like FGSM and Dot attacks, revealing a substantial increase in robustness compared to baseline models.More detailed information, such as code-based resources, ablation studies and videos can be found at https://hk-zh.github.io/p-csg-plus.
</details>
<details>
<summary>摘要</summary>
更多研究注意力在最近已经转移到了端到端自主驾驶技术，因为它的更简单的结构和更快的推理时间。尽管这种方法可以大幅减少驾驶管道中的组件，但它的简单性也导致了解释问题和安全问题。arXiv:2003.06404。训练的策略并不总是遵循交通规则，而且还很难发现违规行为的原因，因为缺乏中间输出。同时，感知器也是自主驾驶的安全和可行性的关键。在这篇论文中，我们提出了一种基于罚金的模仿学习方法，并结合交叉语义生成感知器融合技术，以提高端到端自主驾驶的总性性能。我们使用了城市05长编辑评估我们的模型，实现了驾驶分数的显著提升超过15%。此外，我们还进行了对抗攻击 like FGSM和Dot attacks的Robustness评估，发现了与基线模型相比的显著增强。更多详细信息，如代码资源、截然退化研究和视频，可以在https://hk-zh.github.io/p-csg-plus找到。
</details></li>
</ul>
<hr>
<h2 id="TextBind-Multi-turn-Interleaved-Multimodal-Instruction-following-in-the-Wild"><a href="#TextBind-Multi-turn-Interleaved-Multimodal-Instruction-following-in-the-Wild" class="headerlink" title="TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild"></a>TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08637">http://arxiv.org/abs/2309.08637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huayang Li, Siheng Li, Deng Cai, Longyue Wang, Lemao Liu, Taro Watanabe, Yujiu Yang, Shuming Shi</li>
<li>for: 本研究旨在推动大型自然语言处理模型在人工智能领域的应用，尤其是在多模态指令跟踪任务中。</li>
<li>methods: 本研究使用了 TextBind 框架，该框架几乎没有注解，可以帮助更大的语言模型拥有多turn多modal指令跟踪能力。</li>
<li>results: 研究发现，TextBind 框架可以从语言模型中生成多turn multimodal 指令响应对话，并且可以轻松地捕捉图像和文本输入。<details>
<summary>Abstract</summary>
Large language models with instruction-following abilities have revolutionized the field of artificial intelligence. These models show exceptional generalizability to tackle various real-world tasks through their natural language interfaces. However, their performance heavily relies on high-quality exemplar data, which is often difficult to obtain. This challenge is further exacerbated when it comes to multimodal instruction following. We introduce TextBind, an almost annotation-free framework for empowering larger language models with the multi-turn interleaved multimodal instruction-following capabilities. Our approach requires only image-caption pairs and generates multi-turn multimodal instruction-response conversations from a language model. To accommodate interleaved image-text inputs and outputs, we devise MIM, a language model-centric architecture that seamlessly integrates image encoder and decoder models. We release our dataset, model, and demo to foster future research in the area of multimodal instruction following.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有 instrucion-following 能力已经革命化人工智能领域。这些模型在自然语言界面上显示出极高的通用性，可以轻松地完成各种实际任务。然而，其性能强度取决于高质量的示例数据，而这些数据往往困难获得。这个挑战更加减震，当面临多模态 instrucion-following 时。我们提出了 TextBind，一个几乎无需注释的框架，可以使大型语言模型拥有多turn interleaved multimodal instrucion-following 能力。我们的方法只需要图像caption对，可以生成多turn multimodal instrucion-response对话。为了处理图像文本输入和输出，我们设计了 MIM 架构，它将图像编码器和解码器模型与语言模型集成一体。我们发布了我们的数据集、模型和 demo，以便未来的研究人员可以在多模态 instrucion-following 领域进行更多的研究。
</details></li>
</ul>
<hr>
<h2 id="TiBGL-Template-induced-Brain-Graph-Learning-for-Functional-Neuroimaging-Analysis"><a href="#TiBGL-Template-induced-Brain-Graph-Learning-for-Functional-Neuroimaging-Analysis" class="headerlink" title="TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging Analysis"></a>TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07947">http://arxiv.org/abs/2309.07947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangzhu Meng, Wei Wei, Qiang Liu, Shu Wu, Liang Wang</li>
<li>for: 本研究旨在提高功能磁共振成像的诊断效率，通过提取模板脑图来减少噪声信息和提高诊断性能。</li>
<li>methods: 本研究提出了一种新的脑图学习框架，即模板引导脑图学习（TiBGL），具有权威性和可解释性。该框架基于各个组的模板脑图，可以去除噪声信息，并提高诊断性能。</li>
<li>results: 实验结果显示，提出的TiBGL可以在三个实际数据集上实现superior的性能，并且与 neuroscience 文献中的发现相协同。<details>
<summary>Abstract</summary>
In recent years, functional magnetic resonance imaging has emerged as a powerful tool for investigating the human brain's functional connectivity networks. Related studies demonstrate that functional connectivity networks in the human brain can help to improve the efficiency of diagnosing neurological disorders. However, there still exist two challenges that limit the progress of functional neuroimaging. Firstly, there exists an abundance of noise and redundant information in functional connectivity data, resulting in poor performance. Secondly, existing brain network models have tended to prioritize either classification performance or the interpretation of neuroscience findings behind the learned models. To deal with these challenges, this paper proposes a novel brain graph learning framework called Template-induced Brain Graph Learning (TiBGL), which has both discriminative and interpretable abilities. Motivated by the related medical findings on functional connectivites, TiBGL proposes template-induced brain graph learning to extract template brain graphs for all groups. The template graph can be regarded as an augmentation process on brain networks that removes noise information and highlights important connectivity patterns. To simultaneously support the tasks of discrimination and interpretation, TiBGL further develops template-induced convolutional neural network and template-induced brain interpretation analysis. Especially, the former fuses rich information from brain graphs and template brain graphs for brain disorder tasks, and the latter can provide insightful connectivity patterns related to brain disorders based on template brain graphs. Experimental results on three real-world datasets show that the proposed TiBGL can achieve superior performance compared with nine state-of-the-art methods and keep coherent with neuroscience findings in recent literatures.
</details>
<details>
<summary>摘要</summary>
在最近几年，功能核磁共振成为了人脑功能连接网络的 poderous工具。相关研究表明，人脑功能连接网络可以改善诊断神经疾病的效率。然而，还有两个挑战限制了功能神经成像的进步。首先，功能连接数据中存在严重的噪声和重复信息，导致性能下降。其次，现有的大脑网络模型往往偏重于分类性能或 neuroscience 发现的解释性能。为解决这些挑战，本文提出了一种新的大脑图学习框架，即模板引导的大脑图学习（TiBGL）。这种框架具有 both discriminative 和 interpretable 能力。受到相关医学发现的功能连接 patrerns 的激发，TiBGL 提出了模板引导的大脑图学习，可以从 brain 网络中提取模板 brain graphs。模板图可以视为对 brain 网络的增强处理，从中除去噪声信息，高亮重要的连接 patrerns。为同时支持分类和解释两个任务，TiBGL 进一步开发了模板引导的卷积神经网络和模板引导的大脑解释分析。特别是，前者可以将 rich 的信息从 brain 图和模板 brain 图 fusion 到 brain 疾病任务中，而后者可以基于模板 brain 图提供神经疾病相关的连接 patrerns。实验结果表明，提出的 TiBGL 可以在三个实际数据集上达到与九种 state-of-the-art 方法相当或更高的性能，同时与最新的 neuroscience 发现保持一致。
</details></li>
</ul>
<hr>
<h2 id="Variational-Quantum-Linear-Solver-enhanced-Quantum-Support-Vector-Machine"><a href="#Variational-Quantum-Linear-Solver-enhanced-Quantum-Support-Vector-Machine" class="headerlink" title="Variational Quantum Linear Solver enhanced Quantum Support Vector Machine"></a>Variational Quantum Linear Solver enhanced Quantum Support Vector Machine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07770">http://arxiv.org/abs/2309.07770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianming Yi, Kalyani Suresh, Ali Moghiseh, Norbert Wehn</li>
<li>for: 使用量子资源进行指导式机器学习任务，如分类。</li>
<li>methods: 提出了一种新的方法——Variational Quantum Linear Solver（VQLS）加强的Quantum Support Vector Machine（QSVM），利用量子线性解决器解决NISQ设备上的系统线性方程。</li>
<li>results: 通过大量的数值实验，我们发现我们的方法可以在不同的实例中准确地识别分布在一个8维特征空间中的分界面，并且在7维特征空间中表现出了强大的表现。<details>
<summary>Abstract</summary>
Quantum Support Vector Machines (QSVM) play a vital role in using quantum resources for supervised machine learning tasks, such as classification. However, current methods are strongly limited in terms of scalability on Noisy Intermediate Scale Quantum (NISQ) devices. In this work, we propose a novel approach called the Variational Quantum Linear Solver (VQLS) enhanced QSVM. This is built upon our idea of utilizing the variational quantum linear solver to solve system of linear equations of a least squares-SVM on a NISQ device. The implementation of our approach is evaluated by an extensive series of numerical experiments with the Iris dataset, which consists of three distinct iris plant species. Based on this, we explore the practicality and effectiveness of our algorithm by constructing a classifier capable of classification in a feature space ranging from one to seven dimensions. Furthermore, by strategically exploiting both classical and quantum computing for various subroutines of our algorithm, we effectively mitigate practical challenges associated with the implementation. These include significant improvement in the trainability of the variational ansatz and notable reductions in run-time for cost calculations. Based on the numerical experiments, our approach exhibits the capability of identifying a separating hyperplane in an 8-dimensional feature space. Moreover, it consistently demonstrated strong performance across various instances with the same dataset.
</details>
<details>
<summary>摘要</summary>
量子支持向量机器 (QSVM) 在使用量子资源进行监督式机器学习任务中扮演着重要的角色。然而，现有方法在不纯量子设备 (NISQ) 上的扩展性受到很大的限制。在这项工作中，我们提出了一种新的方法，即变量量子直方法加强的QSVM (VQLS-QSVM)。这是基于我们的变量量子直方法来解决量子直方法在NISQ设备上的系统线性方程的想法。我们的实现方法通过了广泛的数值实验，使用芳香植物三个物种的芳香数据集（Iris dataset）进行评估。根据这些实验结果，我们发现我们的算法在Feature空间范围从1到7维度的情况下能够建立一个分类器。此外，我们通过策略地利用古典计算和量子计算在不同子routines中来有效地 mitigate实际挑战，包括提高变量 Ansatz 的可训练性和计算成本的减少。根据数值实验结果，我们的方法可以在8维度的特征空间中找到分离的折线。此外，它在不同的实例中也具有强大的表现。
</details></li>
</ul>
<hr>
<h2 id="PRE-Vision-Language-Prompt-Learning-with-Reparameterization-Encoder"><a href="#PRE-Vision-Language-Prompt-Learning-with-Reparameterization-Encoder" class="headerlink" title="PRE: Vision-Language Prompt Learning with Reparameterization Encoder"></a>PRE: Vision-Language Prompt Learning with Reparameterization Encoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07760">http://arxiv.org/abs/2309.07760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minhanh151/respro">https://github.com/minhanh151/respro</a></li>
<li>paper_authors: Anh Pham Thi Minh</li>
<li>for: 这篇论文旨在提高预先训练的视觉语言模型 CLIP 的零 shot 转移性能，并且解决 manual 的提示工程化问题，以实现实际应用。</li>
<li>methods: 本研究使用 Context Optimization (CoOp) 的概念，将 learnable textual tokens 引入视觉领域，以提高预先训练的模型在不同类型的图像上的表现。</li>
<li>results: 实验和广泛的拆分分析表明，我们的方法可以效率地提高预先训练的模型在新类别上的表现，并且在16 shot 设定下，与 CoOp 的比较获得了5.60% 的平均精度提升和3% 的调和比例提升，alls 在良好的训练时间内。<details>
<summary>Abstract</summary>
Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks. However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions. This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming. To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens. While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset. In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to unseen classes while maintaining the capacity to learn Base classes. Instead of directly optimizing the prompts, PRE employs a prompt encoder to reparameterize the input prompt embeddings, enhancing the exploration of task-specific knowledge from few-shot samples. Experiments and extensive ablation studies on 8 benchmarks demonstrate that our approach is an efficient method for prompt learning. Specifically, PRE achieves a notable enhancement of 5.60% in average accuracy on New classes and 3% in Harmonic mean compared to CoOp in the 16-shot setting, all achieved within a good training time.
</details>
<details>
<summary>摘要</summary>
大型预训练视觉语言模型如CLIP已经表现出了 zeroshot 跨任务传播的潜力。然而，为了 достичь优化的性能，需要手动选择提示以改善图像分布和文本描述之间的对应性。这个手动提示工程ering是在实践中部署这些模型的主要挑战，因为它需要域专业知识并是非常时间消耗。为了避免非常严重的提示工程ering，最近的工作Context Optimization（CoOp）引入了视野中的提示学习。虽然CoOp可以实现显著提高，但其学习的上下文在更广泛的未看过类中的总体化能力不够。在这种情况下，我们提出了提示学习与杂化编码器（PRE） - 一种简单有效的方法，可以提高未看过类中的总体化能力。而不是直接优化提示，PRE使用提示编码器来重parameterize输入提示嵌入，从少量样本中挖掘任务特定的知识。我们的方法在8个标准benchmark上进行了实验和广泛的ablation研究，结果表明，PRE是一种高效的提示学习方法。特别是，PRE在16个shotSetting中的平均精度提高5.60%，新类精度提高3%，所有这些成果均在合理的训练时间内完成。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-Text-Classification-using-Ensemble-LLM-Approaches"><a href="#Generative-AI-Text-Classification-using-Ensemble-LLM-Approaches" class="headerlink" title="Generative AI Text Classification using Ensemble LLM Approaches"></a>Generative AI Text Classification using Ensemble LLM Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07755">http://arxiv.org/abs/2309.07755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harika Abburi, Michael Suesserman, Nirmala Pudota, Balaji Veeramani, Edward Bowen, Sanmitra Bhattacharya<br>for:* 本研究旨在判断一篇文章是人类写的还是AI生成的。methods:* 使用一个 ensemble neural network 模型，将多个预训练的 LLM 作为特征传递给一个传统机器学习（TML）分类器。results:* 在第一个任务中，模型在英语和西班牙语文本中分别排名第五和第十三（macro $F1$ 分数为 0.733 和 0.649）。* 在第二个任务中，模型在英语和西班牙语文本中分别排名第一（macro $F1$ 分数为 0.625 和 0.653）。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it. For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked in first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在许多人工智能（AI）和自然语言处理任务中表现出色，如内容创建、报告生成等。然而，不当使用这些模型可能会带来不良后果，如创造假新闻、抄袭等。因此，正确地检测AI生成的语言可以是责任使用LLM的关键。在这个工作中，我们探索以下两个研究目标：1）一个文本是AI生成还是人类写就的，2）哪个语言模型在生成一个文本中扮演了主要角色。我们使用了 AuTexTification 共享任务中提供的数据集。为每个研究目标，我们提出了一个ensemble神经网络模型，将不同预训LLM的特征用于一个传统机器学习（TML）分类器后面。For the first task of distinguishing between AI and human-generated text, our model ranked 13th and 5th place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively.
</details></li>
</ul>
<hr>
<h2 id="AIDPS-Adaptive-Intrusion-Detection-and-Prevention-System-for-Underwater-Acoustic-Sensor-Networks"><a href="#AIDPS-Adaptive-Intrusion-Detection-and-Prevention-System-for-Underwater-Acoustic-Sensor-Networks" class="headerlink" title="AIDPS:Adaptive Intrusion Detection and Prevention System for Underwater Acoustic Sensor Networks"></a>AIDPS:Adaptive Intrusion Detection and Prevention System for Underwater Acoustic Sensor Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07730">http://arxiv.org/abs/2309.07730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumadeep Das, Aryan Mohammadi Pasikhani, Prosanta Gope, John A. Clark, Chintan Patel, Biplab Sikdar</li>
<li>For: The paper proposes a secure intrusion detection and prevention system for Underwater Acoustic Sensor Networks (UW-ASNs) to address the lack of security considerations and the resource-constrained nature of sensor nodes.* Methods: The proposed Adaptive decentralized Intrusion Detection and Prevention System (AIDPS) uses machine learning algorithms (e.g., Adaptive Random Forest, light gradient-boosting machine, and K-nearest neighbors) and concept drift detection algorithms (e.g., ADWIN, kdqTree, and Page-Hinkley) to detect underwater-related attacks.* Results: The proposed scheme outperforms state-of-the-art benchmarking methods in terms of performance and provides a wider range of desirable features such as scalability and complexity, as demonstrated through extensive experimental results.Here’s the Chinese version of the three key points:* For: 该论文提出了一种为Underwater Acoustic Sensor Networks (UW-ASNs) 提供安全的攻击检测和预防系统，以解决UW-ASNs 缺乏安全考虑和感知器节点的资源约束。* Methods: 提出的 Adaptive 分散式攻击检测和预防系统 (AIDPS) 使用机器学习算法（例如 Adaptive Random Forest、light gradient-boosting machine 和 K-nearest neighbors）和概念漂移检测算法（例如 ADWIN、kdqTree 和 Page-Hinkley）来检测水下相关的攻击。* Results: 比较 experimental 结果表明，提出的方案在性能方面超过了状态方法 benchmarking 方法，并提供了更多的愿望特征，如可扩展性和复杂性。<details>
<summary>Abstract</summary>
Underwater Acoustic Sensor Networks (UW-ASNs) are predominantly used for underwater environments and find applications in many areas. However, a lack of security considerations, the unstable and challenging nature of the underwater environment, and the resource-constrained nature of the sensor nodes used for UW-ASNs (which makes them incapable of adopting security primitives) make the UW-ASN prone to vulnerabilities. This paper proposes an Adaptive decentralised Intrusion Detection and Prevention System called AIDPS for UW-ASNs. The proposed AIDPS can improve the security of the UW-ASNs so that they can efficiently detect underwater-related attacks (e.g., blackhole, grayhole and flooding attacks). To determine the most effective configuration of the proposed construction, we conduct a number of experiments using several state-of-the-art machine learning algorithms (e.g., Adaptive Random Forest (ARF), light gradient-boosting machine, and K-nearest neighbours) and concept drift detection algorithms (e.g., ADWIN, kdqTree, and Page-Hinkley). Our experimental results show that incremental ARF using ADWIN provides optimal performance when implemented with One-class support vector machine (SVM) anomaly-based detectors. Furthermore, our extensive evaluation results also show that the proposed scheme outperforms state-of-the-art bench-marking methods while providing a wider range of desirable features such as scalability and complexity.
</details>
<details>
<summary>摘要</summary>
水下声学传感网络（UW-ASN）广泛应用于水下环境中，但由于安全考虑不足、水下环境不稳定和敏感度高的传感节点，使得UW-ASN容易受到攻击。本文提出一种适应型分布式入侵检测预防系统（AIDPS），以提高UW-ASN的安全性，能够有效检测水下相关攻击（如黑洞、灰色洞和淹水攻击）。为确定最佳构建，我们进行了一系列实验，使用了多种当前最佳机器学习算法（如适应随机森林、光梯度搜索机和K nearest neighbors）和概念泄漏检测算法（如ADWIN、kdqTree和Page-Hinkley）。实验结果表明，增量ARF使用ADWIN提供了最佳性能，并且与一元支持向量机（SVM）异常检测器结合使用。此外，我们的广泛评估结果也显示，提案方案在与当前标准方法进行比较时表现出优异的特点，如扩展性和复杂度。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-v-Bard-v-Bing-v-Claude-2-v-Aria-v-human-expert-How-good-are-AI-chatbots-at-scientific-writing-ver-23Q3"><a href="#ChatGPT-v-Bard-v-Bing-v-Claude-2-v-Aria-v-human-expert-How-good-are-AI-chatbots-at-scientific-writing-ver-23Q3" class="headerlink" title="ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3)"></a>ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08636">http://arxiv.org/abs/2309.08636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edisa Lozić, Benjamin Štular</li>
<li>for: This paper analyzes the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology.</li>
<li>methods: The methodology used tagging AI-generated content for quantitative accuracy and qualitative precision by human experts.</li>
<li>results: The AI chatbots demonstrated proficiency in recombining existing knowledge but failed in generating original scientific content. Additionally, the paper highlights the challenges AI chatbots face in emulating human originality in scientific writing.<details>
<summary>Abstract</summary>
Historically, proficient writing was deemed essential for human advancement, with creative expression viewed as one of the hallmarks of human achievement. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness, while qualitative precision gauged the scientific contribution. While the AI chatbots, especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, they failed in generating original scientific content. As a side note, our results also suggest that with ChatGPT-4 the size of the LLMs has plateaued. Furthermore, the paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, which highlights the challenges AI chatbots face in emulating human originality in scientific writing. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect that this will change in the near future with the evolution of current LLM-based AI chatbots towards LLM-powered software.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="NutritionVerse-Empirical-Study-of-Various-Dietary-Intake-Estimation-Approaches"><a href="#NutritionVerse-Empirical-Study-of-Various-Dietary-Intake-Estimation-Approaches" class="headerlink" title="NutritionVerse: Empirical Study of Various Dietary Intake Estimation Approaches"></a>NutritionVerse: Empirical Study of Various Dietary Intake Estimation Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07704">http://arxiv.org/abs/2309.07704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi-en Amy Tai, Matthew Keller, Saeejith Nair, Yuhao Chen, Yifan Wu, Olivia Markham, Krish Parmar, Pengcheng Xi, Heather Keller, Sharon Kirkpatrick, Alexander Wong<br>for:这篇论文是为了提高自动识别食物的精度而写的。methods:这篇论文使用了计算机视觉和机器学习技术来自动估计食物摄入量。results:这篇论文提出了一个大规模的synthetic食物图像集（NutritionVerse-Synth）和一个实际图像集（NutritionVerse-Real），并对这些数据进行了分析和评估。<details>
<summary>Abstract</summary>
Accurate dietary intake estimation is critical for informing policies and programs to support healthy eating, as malnutrition has been directly linked to decreased quality of life. However self-reporting methods such as food diaries suffer from substantial bias. Other conventional dietary assessment techniques and emerging alternative approaches such as mobile applications incur high time costs and may necessitate trained personnel. Recent work has focused on using computer vision and machine learning to automatically estimate dietary intake from food images, but the lack of comprehensive datasets with diverse viewpoints, modalities and food annotations hinders the accuracy and realism of such methods. To address this limitation, we introduce NutritionVerse-Synth, the first large-scale dataset of 84,984 photorealistic synthetic 2D food images with associated dietary information and multimodal annotations (including depth images, instance masks, and semantic masks). Additionally, we collect a real image dataset, NutritionVerse-Real, containing 889 images of 251 dishes to evaluate realism. Leveraging these novel datasets, we develop and benchmark NutritionVerse, an empirical study of various dietary intake estimation approaches, including indirect segmentation-based and direct prediction networks. We further fine-tune models pretrained on synthetic data with real images to provide insights into the fusion of synthetic and real data. Finally, we release both datasets (NutritionVerse-Synth, NutritionVerse-Real) on https://www.kaggle.com/nutritionverse/datasets as part of an open initiative to accelerate machine learning for dietary sensing.
</details>
<details>
<summary>摘要</summary>
准确的饮食摄入估算对于支持健康饮食政策和计划是非常重要，因为营养不良直接导致生活质量下降。然而，自我报告方法如食物日志受到了重大偏见。传统的饮食评估技术和新兴的方法如移动应用程序具有高时间成本和可能需要专业人员。现有的工作集中在使用计算机视觉和机器学习自动估算饮食摄入从食物图像，但由于缺乏完整的数据集，包括多个视角、Modalities和食物注释，导致这些方法的准确性和现实性受限。为解决这个限制，我们介绍了nutritionVerse-Synth，第一个大规模的数据集，包括84984个真实的二维食物图像和相关的营养信息和多模态注释（包括深度图像、实例面Mask和semantic面Mask）。此外，我们收集了一个真实图像数据集，nutritionVerse-Real，包括251种菜谱的889张图像，以评估实际性。通过这些新的数据集，我们开发和评估nutritionVerse，一种饮食摄入估算的实验研究，包括间接分割基于和直接预测网络。此外，我们将先前在 sintetic数据上预训练的模型与真实图像进行融合，以提供有关合并 sintetic和real数据的信息。最后，我们在https://www.kaggle.com/nutritionverse/datasets上发布了nutritionVerse-Synth和nutritionVerse-Real两个数据集，作为一个开放的机器学习饮食感知项目。
</details></li>
</ul>
<hr>
<h2 id="Tree-of-Uncertain-Thoughts-Reasoning-for-Large-Language-Models"><a href="#Tree-of-Uncertain-Thoughts-Reasoning-for-Large-Language-Models" class="headerlink" title="Tree of Uncertain Thoughts Reasoning for Large Language Models"></a>Tree of Uncertain Thoughts Reasoning for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07694">http://arxiv.org/abs/2309.07694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shentong Mo, Miao Xin</li>
<li>for: 提高 Large Language Models (LLMs) 的决策精度，特别是在面临多元决策时。</li>
<li>methods: 利用 Monte Carlo Dropout 来评估 LLMs 的地方决策不确定性，然后将这些不确定性评估与全球搜索算法结合使用。</li>
<li>results: 在两个复杂的规划任务中（游戏24和小十字word），TouT 的实验证明了它的superiority，比ToT和链式思维提问方法更好。<details>
<summary>Abstract</summary>
While the recently introduced Tree of Thoughts (ToT) has heralded advancements in allowing Large Language Models (LLMs) to reason through foresight and backtracking for global decision-making, it has overlooked the inherent local uncertainties in intermediate decision points or "thoughts". These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process. Addressing this pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a reasoning framework tailored for LLMs. Our TouT effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs' diverse local responses at these intermediate steps. By marrying this local uncertainty quantification with global search algorithms, TouT enhances the model's precision in response generation. We substantiate our approach with rigorous experiments on two demanding planning tasks: Game of 24 and Mini Crosswords. The empirical evidence underscores TouT's superiority over both ToT and chain-of-thought prompting methods.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:Recently introduced Tree of Thoughts (ToT) has brought about advancements in allowing Large Language Models (LLMs) to reason through foresight and backtracking for global decision-making, but it has overlooked the inherent local uncertainties in intermediate decision points or "thoughts". These local uncertainties, intrinsic to LLMs given their potential for diverse responses, remain a significant concern in the reasoning process. To address this crucial gap, we introduce the Tree of Uncertain Thoughts (TouT) - a reasoning framework tailored for LLMs. Our TouT effectively leverages Monte Carlo Dropout to quantify uncertainty scores associated with LLMs' diverse local responses at these intermediate steps. By marrying this local uncertainty quantification with global search algorithms, TouT enhances the model's precision in response generation. We substantiate our approach with rigorous experiments on two demanding planning tasks: Game of 24 and Mini Crosswords. The empirical evidence underscores TouT's superiority over both ToT and chain-of-thought prompting methods.Simplified Chinese:最近引入的思想树（ToT）已经为大语言模型（LLM）提供了前视和归culo的优化，但它忽略了LLM的本地不确定性在中间决策点或"思想"中。这些本地不确定性， LLM的具有多种响应的潜在问题，仍然是globaledécision-making中的主要问题。为解决这个关键的差距，我们介绍了思想树的不确定思想树（TouT）-一种适应LLM的理解框架。我们的TouT通过利用Monte Carlo Dropout来评估LLM的多个本地响应的不确定度分数。将这种本地不确定度评估与全球搜索算法结合，TouT可以提高模型的响应生成精度。我们通过对棋盘24和小十字word puzzle两个需要努力的规划任务的实验，证明了TouT的超越性 compared to ToT和链式思维提示方法。
</details></li>
</ul>
<hr>
<h2 id="Detecting-ChatGPT-A-Survey-of-the-State-of-Detecting-ChatGPT-Generated-Text"><a href="#Detecting-ChatGPT-A-Survey-of-the-State-of-Detecting-ChatGPT-Generated-Text" class="headerlink" title="Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text"></a>Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07689">http://arxiv.org/abs/2309.07689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Dhaini, Wessel Poelman, Ege Erdogan</li>
<li>for: 本研究旨在探讨如何 отличить人类生成的文本和大语言模型（LLM）生成的文本，以确保文本的integrity。</li>
<li>methods: 本文提供了当前的approaches，包括数据集的建构、不同的方法的使用以及人类生成的文本和ChatGPT生成的文本的quality的比较。</li>
<li>results: 本文summarizes the current state of the art in detecting ChatGPT-generated text, including the various datasets constructed for this task, the methods employed, and the qualitative analyses performed to understand the characteristics of human- versus ChatGPT-generated text.<details>
<summary>Abstract</summary>
While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights
</details>
<details>
<summary>摘要</summary>
“近期，智能语言模型的能力和普遍性得到了大量的进步，如ChatGPT（OpenAI，2022），这些模型已经带来了许多利益，例如生成流畅、人类语言样式的文本。然而， distinguishing between human-generated text and大型语言模型（LLM）生成的文本已成为一个重要的问题。这些模型有可能会欺骗人类，生成 искус生成的文本，这对于法律、教育和科学等领域来说，保持文本的完整性非常重要。本survey提供了当前的方法，用于分辨人类生成的文本和ChatGPT生成的文本，包括constructed的dataset、使用的方法、对human与ChatGPT生成的文本的分析，以及最后的总结。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="deepFDEnet-A-Novel-Neural-Network-Architecture-for-Solving-Fractional-Differential-Equations"><a href="#deepFDEnet-A-Novel-Neural-Network-Architecture-for-Solving-Fractional-Differential-Equations" class="headerlink" title="deepFDEnet: A Novel Neural Network Architecture for Solving Fractional Differential Equations"></a>deepFDEnet: A Novel Neural Network Architecture for Solving Fractional Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07684">http://arxiv.org/abs/2309.07684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Nosrati Firoozsalari, Hassan Dana Mazraeh, Alireza Afzal Aghaei, Kourosh Parand</li>
<li>for: 该研究提出了一种新的深度神经网络架构，用于精准解决不同类型的分数导函数方程。</li>
<li>methods: 该架构使用了Gaussian интеграル规则和$L_1$精度积分技术，在每个方程中使用深度神经网络来 aproximate 未知函数。</li>
<li>results: 实验结果表明，该架构可以高精度地解决不同类型的分数导函数方程，包括分数常 differential equation、分数预微差方程和分数预微差方程。<details>
<summary>Abstract</summary>
The primary goal of this research is to propose a novel architecture for a deep neural network that can solve fractional differential equations accurately. A Gaussian integration rule and a $L_1$ discretization technique are used in the proposed design. In each equation, a deep neural network is used to approximate the unknown function. Three forms of fractional differential equations have been examined to highlight the method's versatility: a fractional ordinary differential equation, a fractional order integrodifferential equation, and a fractional order partial differential equation. The results show that the proposed architecture solves different forms of fractional differential equations with excellent precision.
</details>
<details>
<summary>摘要</summary>
primary goal 的这个研究是提出一种深度神经网络架构，能够精确解析分数 diferencial 方程。在提出的设计中，使用 Gaussian 积分规则和 $L_1$ 精度积分技术。在每个方程中，深度神经网络用于 approximate 未知函数。研究对三种分数 differential 方程进行了测试：分数 ordinary differential equation，分数 order integrodifferential equation，和分数 order partial differential equation。结果显示，提出的架构可以精确地解决不同形式的分数 differential 方程。Note: "分数" (fractional) in the text refers to the fact that the differential equations are of fractional order, meaning that the derivatives are of a non-integer order.
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-nature-of-large-language-models-A-caution-against-anthropocentrism"><a href="#Assessing-the-nature-of-large-language-models-A-caution-against-anthropocentrism" class="headerlink" title="Assessing the nature of large language models: A caution against anthropocentrism"></a>Assessing the nature of large language models: A caution against anthropocentrism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07683">http://arxiv.org/abs/2309.07683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ann Speed</li>
<li>for: 这项研究是为了评估OpenAIs chatbot GPT3.5，了解其能力和人格特征。</li>
<li>methods: 该研究使用标准、 нор化和验证的认知和人格测试盘测GPT3.5的能力和稳定性。</li>
<li>results: GPT3.5 unlikely to have developed sentience, but displayed large variability in cognitive and personality measures over repeated observations, and showed poor mental health such as low self-esteem and dissociation from reality despite upbeat and helpful responses.<details>
<summary>Abstract</summary>
Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans.   Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability notwithstanding, GPT3.5 displays what in a human would be considered poor mental health, including low self-esteem and marked dissociation from reality despite upbeat and helpful responses.
</details>
<details>
<summary>摘要</summary>
我们的结果表明，GPT3.5不太可能已经发展出了意识（sentience）。尽管它能够回答人格评测表，但它在重复测试中显示了大量的变化，这与人类的个性特质不符。不过，GPT3.5在认知和人格测试中表现出了人类所谓的差等精神健康问题，包括低自尊和明显与现实分离。尽管如此，GPT3.5仍然能够表现出帮助和乐观的回答。
</details></li>
</ul>
<hr>
<h2 id="Federated-Dataset-Dictionary-Learning-for-Multi-Source-Domain-Adaptation"><a href="#Federated-Dataset-Dictionary-Learning-for-Multi-Source-Domain-Adaptation" class="headerlink" title="Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation"></a>Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07670">http://arxiv.org/abs/2309.07670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabiola Espinosa Castellon, Eduardo Fernandes Montesuma, Fred Ngolè Mboula, Aurélien Mayoue, Antoine Souloumiac, Cédric Gouy-Pallier</li>
<li>for: 这篇论文是用于处理分布shift的联邦领域数据预测，特别是在部分客户拥有无标数据的情况下。</li>
<li>methods: 本文提出了一个基于词汇学习的联邦领域执行数据预测方法，称为FedDaDiL。这个方法通过客户端的词汇学习来学习客户端的分布，并将这些分布集成为联邦字库。</li>
<li>results: 本文透过实验证明了FedDaDiL的可行性和效果，包括在(i) Caltech-Office、(ii) TEP、和(iii) CWRU benchmark上进行了广泛的测试。此外，本文还与其中央化版本和其他联邦领域执行数据预测方法进行比较。<details>
<summary>Abstract</summary>
In this article, we propose an approach for federated domain adaptation, a setting where distributional shift exists among clients and some have unlabeled data. The proposed framework, FedDaDiL, tackles the resulting challenge through dictionary learning of empirical distributions. In our setting, clients' distributions represent particular domains, and FedDaDiL collectively trains a federated dictionary of empirical distributions. In particular, we build upon the Dataset Dictionary Learning framework by designing collaborative communication protocols and aggregation operations. The chosen protocols keep clients' data private, thus enhancing overall privacy compared to its centralized counterpart. We empirically demonstrate that our approach successfully generates labeled data on the target domain with extensive experiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks. Furthermore, we compare our method to its centralized counterpart and other benchmarks in federated domain adaptation.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种 federated domain adaptation 的方法，这种情况下存在客户端之间的分布转换和一些无标注数据。我们的框架，FedDaDiL，通过对empirical Distribution学习来解决这个问题。在我们的设定下，客户端的分布表示特定的领域，FedDaDiL 在多个客户端之间共同培养一个联合的empirical Distribution字典。 Specifically，我们基于 Dataset Dictionary Learning 框架，并设计了合作通信协议和聚合操作。选择的协议保持客户端的数据私有，从而提高了总体隐私性，比中央化对手更加隐私。我们在 (i) Caltech-Office、(ii) TEP 和 (iii) CWRU 测试benchmark上进行了广泛的实验，并证明了我们的方法能成功生成目标领域的标注数据。此外，我们还与中央化对手和其他联邦预测方法进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Domain-Adaptation-meets-Dataset-Distillation-through-Dataset-Dictionary-Learning"><a href="#Multi-Source-Domain-Adaptation-meets-Dataset-Distillation-through-Dataset-Dictionary-Learning" class="headerlink" title="Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning"></a>Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07666">http://arxiv.org/abs/2309.07666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Fernandes Montesuma, Fred Ngolè Mboula, Antoine Souloumiac</li>
<li>for: 本文解决了多源领域适应（MSDA）和数据简报（DD）两个问题的交叉问题，即MSDA-DD问题。</li>
<li>methods: 本文使用了多种先前在MSDA领域中被采用的方法，如沃氏矩阵运输和数据字典学习，以及DD方法的分布匹配。</li>
<li>results: 本文在四个 benchmark（Caltech-Office 10、Tennessee-Eastman Process、Continuous Stirred Tank Reactor、Case Western Reserve University）上进行了大量的实验，并显示了使用仅1个样本每个类的情况下，可以达到现有的适应性能。<details>
<summary>Abstract</summary>
In this paper, we consider the intersection of two problems in machine learning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD). On the one hand, the first considers adapting multiple heterogeneous labeled source domains to an unlabeled target domain. On the other hand, the second attacks the problem of synthesizing a small summary containing all the information about the datasets. We thus consider a new problem called MSDA-DD. To solve it, we adapt previous works in the MSDA literature, such as Wasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD method Distribution Matching. We thoroughly experiment with this novel problem on four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous Stirred Tank Reactor, and Case Western Reserve University), where we show that, even with as little as 1 sample per class, one achieves state-of-the-art adaptation performance.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们考虑了多源领域适应（MSDA）和数据精炼（DD）两个问题的交叉点。一方面，MSDA是适应多个不同标签源领域到一个没有标签目标领域的问题。另一方面，DD是解决将数据集中的所有信息概括到一个小Summary中的问题。因此，我们提出了一个新的问题 called MSDA-DD。为解决这个问题，我们改进了先前在MSDA литературе中的方法，如 Wasserstein Barycenter Transport和 Dataset Dictionary Learning，以及 DD 方法 Distribution Matching。我们在四个标准 benchmark（Caltech-Office 10、Tennessee-Eastman Process、Continuous Stirred Tank Reactor和Case Western Reserve University）进行了广泛的实验，并证明了，即使只有一个样本每个类，也可以达到状态精准适应性。
</details></li>
</ul>
<hr>
<h2 id="Feature-Engineering-in-Learning-to-Rank-for-Community-Question-Answering-Task"><a href="#Feature-Engineering-in-Learning-to-Rank-for-Community-Question-Answering-Task" class="headerlink" title="Feature Engineering in Learning-to-Rank for Community Question Answering Task"></a>Feature Engineering in Learning-to-Rank for Community Question Answering Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07610">http://arxiv.org/abs/2309.07610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nafis Sajid, Md Rashidul Hasan, Muhammad Ibrahim</li>
<li>for: This paper aims to improve the ranking of answers in community question answering (CQA) forums by introducing a BERT-based feature and combining both question and answer features.</li>
<li>methods: The proposed framework uses traditional features like TF-IDF and BM25, as well as a BERT-based feature to capture the semantic similarity between questions and answers. The framework also employs rank-learning algorithms that have not been widely used in the CQA domain.</li>
<li>results: The proposed framework achieves state-of-the-art performance on three standard CQA datasets, and the analysis of feature importance provides guidance for practitioners to select a better set of features for the CQA retrieval task.<details>
<summary>Abstract</summary>
Community question answering (CQA) forums are Internet-based platforms where users ask questions about a topic and other expert users try to provide solutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer, StackExchange exist with a lot of user-generated data. These data are leveraged in automated CQA ranking systems where similar questions (and answers) are presented in response to the query of the user. In this work, we empirically investigate a few aspects of this domain. Firstly, in addition to traditional features like TF-IDF, BM25 etc., we introduce a BERT-based feature that captures the semantic similarity between the question and answer. Secondly, most of the existing research works have focused on features extracted only from the question part; features extracted from answers have not been explored extensively. We combine both types of features in a linear fashion. Thirdly, using our proposed concepts, we conduct an empirical investigation with different rank-learning algorithms, some of which have not been used so far in CQA domain. On three standard CQA datasets, our proposed framework achieves state-of-the-art performance. We also analyze importance of the features we use in our investigation. This work is expected to guide the practitioners to select a better set of features for the CQA retrieval task.
</details>
<details>
<summary>摘要</summary>
社区问答（CQA）论坛是互联网上的平台，用户可以提问一个话题，其他专家用户则会提供解决方案。许多CQA论坛，如Quora、Stack overflow、Yahoo！Answer、Stack Exchange等，都有大量用户生成的数据。这些数据可以被自动化CQA排名系统使用，以提供与用户提交的问题相似的问题和答案。在这项工作中，我们employn empirical investigation of several aspects of this domain。首先，我们引入了BERT基于的 semanticsimilarity特征，用于捕捉问题和答案之间的semantic关系。其次，大多数现有研究works都是只是从问题部分提取特征，而不是从答案部分提取特征。我们组合了这两种类型的特征在线性方式。最后，我们使用我们提出的概念，使用不同的排名算法进行实验，其中一些算法在CQA领域未曾使用过。在三个标准CQA数据集上，我们的提出的框架实现了状态的表现。我们还分析了我们使用的特征的重要性。这项工作预计会引导实践者选择更好的特征集 дляCQA检索任务。
</details></li>
</ul>
<hr>
<h2 id="Turning-Dross-Into-Gold-Loss-is-BERT4Rec-really-better-than-SASRec"><a href="#Turning-Dross-Into-Gold-Loss-is-BERT4Rec-really-better-than-SASRec" class="headerlink" title="Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec?"></a>Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07602">http://arxiv.org/abs/2309.07602</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antklen/sasrec-bert4rec-recsys23">https://github.com/antklen/sasrec-bert4rec-recsys23</a></li>
<li>paper_authors: Anton Klenitskiy, Alexey Vasilev</li>
<li>for:  Compares the performance of SASRec and BERT4Rec in recommendation tasks, and explores the effectiveness of training SASRec with negative sampling.</li>
<li>methods:  Uses Transformer-based models SASRec and BERT4Rec as baselines, and compares their performance with different loss functions and negative sampling strategies.</li>
<li>results:  Finds that SASRec outperforms BERT4Rec in terms of quality and training speed when trained with the same loss function as BERT4Rec, and that SASRec can be effectively trained with negative sampling but requires a larger number of negative examples than one.<details>
<summary>Abstract</summary>
Recently sequential recommendations and next-item prediction task has become increasingly popular in the field of recommender systems. Currently, two state-of-the-art baselines are Transformer-based models SASRec and BERT4Rec. Over the past few years, there have been quite a few publications comparing these two algorithms and proposing new state-of-the-art models. In most of the publications, BERT4Rec achieves better performance than SASRec. But BERT4Rec uses cross-entropy over softmax for all items, while SASRec uses negative sampling and calculates binary cross-entropy loss for one positive and one negative item. In our work, we show that if both models are trained with the same loss, which is used by BERT4Rec, then SASRec will significantly outperform BERT4Rec both in terms of quality and training speed. In addition, we show that SASRec could be effectively trained with negative sampling and still outperform BERT4Rec, but the number of negative examples should be much larger than one.
</details>
<details>
<summary>摘要</summary>
近期顺序推荐和下一个项目预测任务在推荐系统领域得到了越来越多的关注。目前，两种状态级基elines是基于Transformer架构的SASRec和BERT4Rec。过去几年，有很多文章比较了这两种算法，并提出了新的状态级基elines。大多数文章中，BERT4Rec的性能比SASRec好，但BERT4Rec使用交叉熵预测所有项目，而SASRec使用负样本和计算二进制交叉熵损失。在我们的工作中，我们发现如果两个模型都使用同一个损失函数，即BERT4Rec使用的交叉熵损失，那么SASRec会在质量和训练速度方面明显超过BERT4Rec。此外，我们还发现SASRec可以通过负样本进行训练，并且仍然超过BERT4Rec，但负样本的数量应该比一个更大得多。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Misinformation-with-LLM-Predicted-Credibility-Signals-and-Weak-Supervision"><a href="#Detecting-Misinformation-with-LLM-Predicted-Credibility-Signals-and-Weak-Supervision" class="headerlink" title="Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision"></a>Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07601">http://arxiv.org/abs/2309.07601</a></li>
<li>repo_url: None</li>
<li>paper_authors: João A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton</li>
<li>for: 本研究旨在检验语言模型是否能够通过提供18个信任信号来生成弱标签，以便用于内容真实性预测。</li>
<li>methods: 本研究使用大语言模型（LLM），并通过提供18个信任信号来启动它们。然后，使用弱监督来聚合这些潜在噪声的标签，以预测内容真实性。</li>
<li>results: 研究发现，使用这种方法可以超过现有的状况检测器，并且不需要使用任何基于真实标签的训练数据。此外，研究还分析了各个信任信号对内容真实性预测的贡献，提供了新的有价值的意见。<details>
<summary>Abstract</summary>
Credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyse the contribution of the individual credibility signals towards predicting content veracity, which provides new valuable insights into their role in misinformation detection.
</details>
<details>
<summary>摘要</summary>
credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyze the contribution of the individual credibility signals towards predicting content veracity, which provides new valuable insights into their role in misinformation detection.Here's the translation in Traditional Chinese:credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyze the contribution of the individual credibility signals towards predicting content veracity, which provides new valuable insights into their role in misinformation detection.
</details></li>
</ul>
<hr>
<h2 id="C-Pack-Packaged-Resources-To-Advance-General-Chinese-Embedding"><a href="#C-Pack-Packaged-Resources-To-Advance-General-Chinese-Embedding" class="headerlink" title="C-Pack: Packaged Resources To Advance General Chinese Embedding"></a>C-Pack: Packaged Resources To Advance General Chinese Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07597">http://arxiv.org/abs/2309.07597</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flagopen/flagembedding">https://github.com/flagopen/flagembedding</a></li>
<li>paper_authors: Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muennighof</li>
<li>for: 本文旨在提供一个包含多种资源的包，以提高中文嵌入模型的Field。</li>
<li>methods: 本文使用了三个关键资源：1）中文文本嵌入数据集C-MTEB，2）大量的中文文本嵌入数据集C-MTP，3）多种中文嵌入模型家族C-TEM。</li>
<li>results: 我们的模型在C-MTEB上表现出色，与之前的所有中文文本嵌入模型相比，提高了+10%。此外，我们还对C-TEM模型进行了整体训练和优化。同时，我们还发布了英文文本嵌入数据集和模型，其性能在MTEB上与之前的最佳性能相当。所有资源都可以在<a target="_blank" rel="noopener" href="https://github.com/FlagOpen/FlagEmbedding%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/FlagOpen/FlagEmbedding上下载。</a><details>
<summary>Abstract</summary>
We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.
</details>
<details>
<summary>摘要</summary>
我们介绍C-Pack，一个包含资源的集合，将通用中文嵌入领域带进行了显著的提升。C-Pack包括三个重要资源。1）C-MTEB是一个涵盖6个任务和35个数据集的中文文本嵌入测试集。2）C-MTP是一个由标注和未标注的中文资料集合而成的庞大文本嵌入数据集，用于训练嵌入模型。3）C-TEM是一家嵌入模型家族，覆盖多个大小。我们的模型在C-MTEB上比所有前一代中文文本嵌入模型高出+10%。我们还将整个训练方法集成并优化。此外，我们还发布了英文文本嵌入数据和模型，其性能在MTEB benchmark上达到了国际先进水平。而我们发布的英文数据量比中文数据量高出2倍。这些资源都公开提供在GitHub上，请参考https://github.com/FlagOpen/FlagEmbedding。
</details></li>
</ul>
<hr>
<h2 id="Neuro-Symbolic-Recommendation-Model-based-on-Logic-Query"><a href="#Neuro-Symbolic-Recommendation-Model-based-on-Logic-Query" class="headerlink" title="Neuro-Symbolic Recommendation Model based on Logic Query"></a>Neuro-Symbolic Recommendation Model based on Logic Query</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07594">http://arxiv.org/abs/2309.07594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maonian Wu, Bang Chen, Shaojun Zhu, Bo Zheng, Wei Peng, Mingyi Zhang</li>
<li>for: 提供一种基于逻辑和符号的推荐模型，解决现有的推荐模型在实际任务中难以处理不一致和不完整的知识问题。</li>
<li>methods: 将用户历史交互转化为逻辑表达，然后将推荐预测转化为查询任务基于这个逻辑表达。使用神经网络的模块逻辑运算实现逻辑表达的计算。还构建了隐式逻辑编码器来有效减少逻辑计算的复杂性。</li>
<li>results: 在三个常见数据集上进行了实验，结果显示，我们的方法在比较于现有的浅深、会话、理解模型的情况下表现更好。<details>
<summary>Abstract</summary>
A recommendation system assists users in finding items that are relevant to them. Existing recommendation models are primarily based on predicting relationships between users and items and use complex matching models or incorporate extensive external information to capture association patterns in data. However, recommendation is not only a problem of inductive statistics using data; it is also a cognitive task of reasoning decisions based on knowledge extracted from information. Hence, a logic system could naturally be incorporated for the reasoning in a recommendation task. However, although hard-rule approaches based on logic systems can provide powerful reasoning ability, they struggle to cope with inconsistent and incomplete knowledge in real-world tasks, especially for complex tasks such as recommendation. Therefore, in this paper, we propose a neuro-symbolic recommendation model, which transforms the user history interactions into a logic expression and then transforms the recommendation prediction into a query task based on this logic expression. The logic expressions are then computed based on the modular logic operations of the neural network. We also construct an implicit logic encoder to reasonably reduce the complexity of the logic computation. Finally, a user's interest items can be queried in the vector space based on the computation results. Experiments on three well-known datasets verified that our method performs better compared to state of the art shallow, deep, session, and reasoning models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Statistically-Valid-Variable-Importance-Assessment-through-Conditional-Permutations"><a href="#Statistically-Valid-Variable-Importance-Assessment-through-Conditional-Permutations" class="headerlink" title="Statistically Valid Variable Importance Assessment through Conditional Permutations"></a>Statistically Valid Variable Importance Assessment through Conditional Permutations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07593">http://arxiv.org/abs/2309.07593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Chamma, Denis A. Engemann, Bertrand Thirion</li>
<li>for: This paper aims to provide a systematic approach for studying Conditional Permutation Importance (CPI) and to develop reusable benchmarks of state-of-the-art variable importance estimators.</li>
<li>methods: The paper uses a model-agnostic and computationally lean approach to study CPI, which overcomes the limitations of standard permutation importance by providing accurate type-I error control.</li>
<li>results: The paper shows that CPI consistently showed top accuracy across benchmarks when used with a deep neural network, and provides a more parsimonious selection of statistically significant variables in real-world data analysis.<details>
<summary>Abstract</summary>
Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy across benchmarks. An empirical benchmark on real-world data analysis in a large-scale medical dataset showed that $\textit{CPI}$ provides a more parsimonious selection of statistically significant variables. Our results suggest that $\textit{CPI}$ can be readily used as drop-in replacement for permutation-based methods.
</details>
<details>
<summary>摘要</summary>
Here, we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that CPI overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, CPI consistently showed top accuracy across benchmarks.An empirical benchmark on real-world data analysis in a large-scale medical dataset showed that CPI provides a more parsimonious selection of statistically significant variables. Our results suggest that CPI can be readily used as a drop-in replacement for permutation-based methods.
</details></li>
</ul>
<hr>
<h2 id="Equivariant-Data-Augmentation-for-Generalization-in-Offline-Reinforcement-Learning"><a href="#Equivariant-Data-Augmentation-for-Generalization-in-Offline-Reinforcement-Learning" class="headerlink" title="Equivariant Data Augmentation for Generalization in Offline Reinforcement Learning"></a>Equivariant Data Augmentation for Generalization in Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07578">http://arxiv.org/abs/2309.07578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cristina Pinneri, Sarah Bechtle, Markus Wulfmeier, Arunkumar Byravan, Jingwei Zhang, William F. Whitney, Martin Riedmiller</li>
<li>for: 提高RL Agent的泛化能力，在固定数据集上不需要额外与环境交互。</li>
<li>methods: 学习动力模型，并使用归一化规则增加对翻译变换的抽象集。</li>
<li>results: 在考虑环境中，使用增强的数据集和策略学习算法，提高策略的测试性能。<details>
<summary>Abstract</summary>
We present a novel approach to address the challenge of generalization in offline reinforcement learning (RL), where the agent learns from a fixed dataset without any additional interaction with the environment. Specifically, we aim to improve the agent's ability to generalize to out-of-distribution goals. To achieve this, we propose to learn a dynamics model and check if it is equivariant with respect to a fixed type of transformation, namely translations in the state space. We then use an entropy regularizer to increase the equivariant set and augment the dataset with the resulting transformed samples. Finally, we learn a new policy offline based on the augmented dataset, with an off-the-shelf offline RL algorithm. Our experimental results demonstrate that our approach can greatly improve the test performance of the policy on the considered environments.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于解决在线推荐学习（RL）中的泛化挑战，agent从固定的数据集中学习而不需要与环境进行任何交互。我们想要改进agent的泛化能力，以便在不同目标下进行更好的表现。为此，我们提议通过学习动力模型，并检查其对于固定类型的变换（ specifically, state space中的翻译）是否对称。然后，我们使用Entropy regularizer来增加对称集，并将结果中的变换样本添加到数据集中。最后，我们使用Offline RL算法学习一个新的策略，基于扩展后的数据集。我们的实验结果表明，我们的方法可以大幅提高考试策略在考试环境中的表现。
</details></li>
</ul>
<hr>
<h2 id="Speech-to-Speech-Translation-with-Discrete-Unit-Based-Style-Transfer"><a href="#Speech-to-Speech-Translation-with-Discrete-Unit-Based-Style-Transfer" class="headerlink" title="Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer"></a>Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07566">http://arxiv.org/abs/2309.07566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongqi Wang, Jionghao Bai, Rongjie Huang, Ruiqi Li, Zhiqing Hong, Zhou Zhao</li>
<li>for: 用于进行Direct Speech-to-Speech Translation (S2ST)，以实现高品质的语音翻译。</li>
<li>methods: 使用了基于自我监督学习的听语模型，以及一种神经编码器来实现风格传递。听语模型通过自我监督学习，学习了风格传递的能力，无需靠仰于任何 speaker-parallel 数据。</li>
<li>results: 经过大量训练，我们的模型实现了零shot cross-lingual风格传递，并生成了高准确率和风格相似的翻译语音示例。示例可以在 <a target="_blank" rel="noopener" href="http://stylelm.github.io/">http://stylelm.github.io/</a> 上找到。<details>
<summary>Abstract</summary>
Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech during translation. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer between source and target speech. We propose an S2ST framework with an acoustic language model based on discrete units from a self-supervised model and a neural codec for style transfer. The acoustic language model leverages self-supervised in-context learning, acquiring the ability for style transfer without relying on any speaker-parallel data, thereby overcoming the issue of data scarcity. By using extensive training data, our model achieves zero-shot cross-lingual style transfer on previously unseen source languages. Experiments show that our model generates translated speeches with high fidelity and style similarity. Audio samples are available at http://stylelm.github.io/ .
</details>
<details>
<summary>摘要</summary>
直接speech-to-speech翻译（S2ST）已经实现了惊人的准确率，但是无法保留源语音的 speaker timbre。同时，获得高质量的 speaker-平行数据的缺乏对学习 Style transfer between source and target speech  pose a challenge。我们提议一个基于 discrete units 的 S2ST 框架，使用一个基于 acoustic language model 的 neural codec for style transfer。这个 acoustic language model 通过自我超vised in-context learning 获得了 Style transfer 的能力，不需要任何 speaker-平行数据，因此解决了数据缺乏的问题。通过大量的训练数据，我们的模型实现了零shot cross-lingual Style transfer  на previously unseen source languages。实验表明，我们的模型可以生成高准确率和 Style similarity 的翻译语音。Audio samples 可以在 http://stylelm.github.io/ 中找到。
</details></li>
</ul>
<hr>
<h2 id="Masked-Generative-Modeling-with-Enhanced-Sampling-Scheme"><a href="#Masked-Generative-Modeling-with-Enhanced-Sampling-Scheme" class="headerlink" title="Masked Generative Modeling with Enhanced Sampling Scheme"></a>Masked Generative Modeling with Enhanced Sampling Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07945">http://arxiv.org/abs/2309.07945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daesoo Lee, Erlend Aune, Sara Malacarne</li>
<li>for:  This paper proposes a novel sampling scheme for masked non-autoregressive generative modeling to overcome the limitations of existing sampling methods.</li>
<li>methods: The proposed Enhanced Sampling Scheme (ESS) consists of three stages: Naive Iterative Decoding, Critical Reverse Sampling, and Critical Resampling. ESS uses confidence scores from a self-Token-Critic and the structure of the quantized latent vector space to ensure both sample diversity and fidelity.</li>
<li>results: The proposed ESS shows significant performance gains in both unconditional sampling and class-conditional sampling using all 128 datasets in the UCR Time Series archive.<details>
<summary>Abstract</summary>
This paper presents a novel sampling scheme for masked non-autoregressive generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme (ESS) to overcome these limitations. ESS explicitly ensures both sample diversity and fidelity, and consists of three stages: Naive Iterative Decoding, Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a token set using the naive iterative decoding as proposed in MaskGIT, ensuring sample diversity. Then, the token set undergoes the critical reverse sampling, masking tokens leading to unrealistic samples. After that, critical resampling reconstructs masked tokens until the final sampling step is reached to ensure high fidelity. Critical resampling uses confidence scores obtained from a self-Token-Critic to better measure the realism of sampled tokens, while critical reverse sampling uses the structure of the quantized latent vector space to discover unrealistic sample paths. We demonstrate significant performance gains of ESS in both unconditional sampling and class-conditional sampling using all the 128 datasets in the UCR Time Series archive.
</details>
<details>
<summary>摘要</summary>
ESS starts by sampling a token set using naive iterative decoding, as proposed in MaskGIT, to ensure sample diversity. Then, the token set undergoes critical reverse sampling, where tokens are masked to lead to unrealistic samples. Finally, critical resampling reconstructs masked tokens until the final sampling step is reached to ensure high fidelity. Critical resampling uses confidence scores obtained from a self-Token-Critic to better measure the realism of sampled tokens, while critical reverse sampling uses the structure of the quantized latent vector space to discover unrealistic sample paths.We demonstrate significant performance gains of ESS in both unconditional sampling and class-conditional sampling using all 128 datasets in the UCR Time Series archive.
</details></li>
</ul>
<hr>
<h2 id="SingFake-Singing-Voice-Deepfake-Detection"><a href="#SingFake-Singing-Voice-Deepfake-Detection" class="headerlink" title="SingFake: Singing Voice Deepfake Detection"></a>SingFake: Singing Voice Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07525">http://arxiv.org/abs/2309.07525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongyi Zang, You Zhang, Mojtaba Heydari, Zhiyao Duan</li>
<li>for: 这篇研究是针对伪声音Synthesis技术的应用和挑战，尤其是在音乐领域中。</li>
<li>methods: 这篇研究使用了四种现有的语音伪装系统，并在这些系统上进行了训练和评估。</li>
<li>results: 研究发现这些语音伪装系统在对话�uterances上表现良好，但在歌曲中却表现不佳，尤其是在不熟悉的歌手、语言和音乐背景下。<details>
<summary>Abstract</summary>
The rise of singing voice synthesis presents critical challenges to artists and industry stakeholders over unauthorized voice usage. Unlike synthesized speech, synthesized singing voices are typically released in songs containing strong background music that may hide synthesis artifacts. Additionally, singing voices present different acoustic and linguistic characteristics from speech utterances. These unique properties make singing voice deepfake detection a relevant but significantly different problem from synthetic speech detection. In this work, we propose the singing voice deepfake detection task. We first present SingFake, the first curated in-the-wild dataset consisting of 28.93 hours of bonafide and 29.40 hours of deepfake song clips in five languages from 40 singers. We provide a train/val/test split where the test sets include various scenarios. We then use SingFake to evaluate four state-of-the-art speech countermeasure systems trained on speech utterances. We find these systems lag significantly behind their performance on speech test data. When trained on SingFake, either using separated vocal tracks or song mixtures, these systems show substantial improvement. However, our evaluations also identify challenges associated with unseen singers, communication codecs, languages, and musical contexts, calling for dedicated research into singing voice deepfake detection. The SingFake dataset and related resources are available online.
</details>
<details>
<summary>摘要</summary>
<sup>1</sup> 歌唱voice合成技术的发展带来了艺术家和行业参与者面临的挑战，特别是在未经授权的voice使用方面。与合成语音不同，合成的歌唱voice通常会在具有强音乐背景的歌曲中释放，这可能会隐藏合成 artifacts。此外，歌唱voice具有不同的音响和语言特点，与语音词汇不同，这些独特的特点使得歌唱voice深层负伪检测成为一项有关的，但是与合成语音检测不同的问题。在这项工作中，我们提出了歌唱voice深层负伪检测任务。我们首先提供了 SingFake，这是首次在实际场景中采集的28.93小时真实音频和29.40小时深层负伪歌曲clip的第一个Curated dataset，包括5种语言和40名歌手。我们提供了训练/验证/测试的分 split，测试集包括多种场景。我们使用 SingFake 评估四种现状最佳的语音干扰系统，这些系统在语音测试数据上表现出色。然而，当我们将这些系统训练在 SingFake 上时，它们显示出了明显的改善。然而，我们的评估还发现了不同的歌手、通信编码器、语言和音乐背景的挑战，这要求特定的研究。 SingFake  dataset和相关资源在线可用。
</details></li>
</ul>
<hr>
<h2 id="Learning-Environment-Aware-Affordance-for-3D-Articulated-Object-Manipulation-under-Occlusions"><a href="#Learning-Environment-Aware-Affordance-for-3D-Articulated-Object-Manipulation-under-Occlusions" class="headerlink" title="Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions"></a>Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07510">http://arxiv.org/abs/2309.07510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Cheng, Ruihai Wu, Yan Shen, Chuanruo Ning, Guanqi Zhan, Hao Dong</li>
<li>for: 本研究旨在提供一种环境意识型的可行性框架，以便在多种环境中识别和控制3D彩色人工机器人。</li>
<li>methods: 该研究使用了一种新的对比式可行性学习框架，能够在含有一个障碍物的场景中培育可行性，并且能够在不同的障碍物组合场景中进行泛化。</li>
<li>results: 实验表明，该提议的环境意识型可行性框架能够有效地考虑环境约束，并且能够在多种环境中学习可行性。<details>
<summary>Abstract</summary>
Perceiving and manipulating 3D articulated objects in diverse environments is essential for home-assistant robots. Recent studies have shown that point-level affordance provides actionable priors for downstream manipulation tasks. However, existing works primarily focus on single-object scenarios with homogeneous agents, overlooking the realistic constraints imposed by the environment and the agent's morphology, e.g., occlusions and physical limitations. In this paper, we propose an environment-aware affordance framework that incorporates both object-level actionable priors and environment constraints. Unlike object-centric affordance approaches, learning environment-aware affordance faces the challenge of combinatorial explosion due to the complexity of various occlusions, characterized by their quantities, geometries, positions and poses. To address this and enhance data efficiency, we introduce a novel contrastive affordance learning framework capable of training on scenes containing a single occluder and generalizing to scenes with complex occluder combinations. Experiments demonstrate the effectiveness of our proposed approach in learning affordance considering environment constraints.
</details>
<details>
<summary>摘要</summary>
感知和操作3D嵌入式对象在多样环境中是家庭助手机器人的重要能力。 latest studies have shown that point-level affordance provides actionable priors for downstream manipulation tasks. However, existing works primarily focus on single-object scenarios with homogeneous agents, overlooking the realistic constraints imposed by the environment and the agent's morphology, e.g., occlusions and physical limitations. In this paper, we propose an environment-aware affordance framework that incorporates both object-level actionable priors and environment constraints. Unlike object-centric affordance approaches, learning environment-aware affordance faces the challenge of combinatorial explosion due to the complexity of various occlusions, characterized by their quantities, geometries, positions and poses. To address this and enhance data efficiency, we introduce a novel contrastive affordance learning framework capable of training on scenes containing a single occluder and generalizing to scenes with complex occluder combinations. Experiments demonstrate the effectiveness of our proposed approach in learning affordance considering environment constraints.
</details></li>
</ul>
<hr>
<h2 id="Connected-Autonomous-Vehicle-Motion-Planning-with-Video-Predictions-from-Smart-Self-Supervised-Infrastructure"><a href="#Connected-Autonomous-Vehicle-Motion-Planning-with-Video-Predictions-from-Smart-Self-Supervised-Infrastructure" class="headerlink" title="Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure"></a>Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07504">http://arxiv.org/abs/2309.07504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jiankai-Sun/SSTA2-ITSC-2023">https://github.com/Jiankai-Sun/SSTA2-ITSC-2023</a></li>
<li>paper_authors: Jiankai Sun, Shreyas Kousik, David Fridovich-Keil, Mac Schwager</li>
<li>for: 增强城市交通安全、效率和可持续性的自动驾驶汽车 (CAVs) 需要它们能准确预测周围的行为和安全地规划自己的动作。但是，在复杂的城市环境中，这是一项具有挑战性的任务，因为经常出现遮挡和多个代理人之间的交互。</li>
<li>methods: 本研究利用了一种名为 “Self-Supervised Traffic Advisor” (SSTA) 的智能基础设施来增强 CAV 的知觉状态，SSTA 是一种可以教育自己生成和广播有用的视频预测的感知器。在这种设计中，SSTA 预测的是未来的占用情况而不是原始的视频数据，这有助于减少广播预测数据的脚本。</li>
<li>results: 研究表明，这种设计可以有效地帮助 CAV 进行动作规划。一系列的数字实验研究了在充满人员的城市环境中 CAV 的实际应用情况，并证明了这种设计的有效性。<details>
<summary>Abstract</summary>
Connected autonomous vehicles (CAVs) promise to enhance safety, efficiency, and sustainability in urban transportation. However, this is contingent upon a CAV correctly predicting the motion of surrounding agents and planning its own motion safely. Doing so is challenging in complex urban environments due to frequent occlusions and interactions among many agents. One solution is to leverage smart infrastructure to augment a CAV's situational awareness; the present work leverages a recently proposed "Self-Supervised Traffic Advisor" (SSTA) framework of smart sensors that teach themselves to generate and broadcast useful video predictions of road users. In this work, SSTA predictions are modified to predict future occupancy instead of raw video, which reduces the data footprint of broadcast predictions. The resulting predictions are used within a planning framework, demonstrating that this design can effectively aid CAV motion planning. A variety of numerical experiments study the key factors that make SSTA outputs useful for practical CAV planning in crowded urban environments.
</details>
<details>
<summary>摘要</summary>
connected autonomous vehicles (CAVs) 会提高城市交通的安全性、效率和可持续性。然而，这取决于CAV正确预测周围的行为和安全地规划自己的运动。在复杂的城市环境中，这是一项挑战，因为经常出现遮挡和多个代理人之间的互动。一种解决方案是利用智能基础设施来增强CAV的情况意识；本研究利用“自我学习交通指南”（SSTA）框架的智能感知器来生成和广播有用的道路用户视频预测。在这种设计中，SSTA预测被修改为预测未来占用情况而不是原始视频，这 reduces the data footprint of broadcast predictions。这些预测被用于 плани组织，示出了这种设计可以有效地帮助CAV规划运动。数字实验评估了实用CAV规划中关键的因素，以便在忙oso urban environments中提高CAV的安全性和效率。
</details></li>
</ul>
<hr>
<h2 id="HDTR-Net-A-Real-Time-High-Definition-Teeth-Restoration-Network-for-Arbitrary-Talking-Face-Generation-Methods"><a href="#HDTR-Net-A-Real-Time-High-Definition-Teeth-Restoration-Network-for-Arbitrary-Talking-Face-Generation-Methods" class="headerlink" title="HDTR-Net: A Real-Time High-Definition Teeth Restoration Network for Arbitrary Talking Face Generation Methods"></a>HDTR-Net: A Real-Time High-Definition Teeth Restoration Network for Arbitrary Talking Face Generation Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07495">http://arxiv.org/abs/2309.07495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yylgoodlucky/hdtr">https://github.com/yylgoodlucky/hdtr</a></li>
<li>paper_authors: Yongyuan Li, Xiuyuan Qin, Chao Liang, Mingqiang Wei</li>
<li>for: 高清定制化脸部动作生成（TFG）旨在通过音频和脸部特征来重建脸部动作，以实现自然和真实的嘴部运动。</li>
<li>methods: 我们提出了一种高清定制化牙齿修复网络（HDTR-Net），可以快速提高牙齿区域的清晰度，同时保持同步和时间一致性。我们还提出了细节特征融合（FGFF）模块，以Capture细节特征信息周围牙齿和相邻区域，并使用这些特征来细化特征图以提高牙齿的清晰度。</li>
<li>results: 我们的方法可以适应任何TFG方法，不会受到嘴部同步和帧协调的影响。此外，我们的方法可以在高清定制化脸部视频合成中实现实时生成，并且在执行速度方面比现有基于超分辨率的面部修复更快$300%$。<details>
<summary>Abstract</summary>
Talking Face Generation (TFG) aims to reconstruct facial movements to achieve high natural lip movements from audio and facial features that are under potential connections. Existing TFG methods have made significant advancements to produce natural and realistic images. However, most work rarely takes visual quality into consideration. It is challenging to ensure lip synchronization while avoiding visual quality degradation in cross-modal generation methods. To address this issue, we propose a universal High-Definition Teeth Restoration Network, dubbed HDTR-Net, for arbitrary TFG methods. HDTR-Net can enhance teeth regions at an extremely fast speed while maintaining synchronization, and temporal consistency. In particular, we propose a Fine-Grained Feature Fusion (FGFF) module to effectively capture fine texture feature information around teeth and surrounding regions, and use these features to fine-grain the feature map to enhance the clarity of teeth. Extensive experiments show that our method can be adapted to arbitrary TFG methods without suffering from lip synchronization and frame coherence. Another advantage of HDTR-Net is its real-time generation ability. Also under the condition of high-definition restoration of talking face video synthesis, its inference speed is $300\%$ faster than the current state-of-the-art face restoration based on super-resolution.
</details>
<details>
<summary>摘要</summary>
talking face generation (TFG) 目标是重建面部动作，以达到高自然的唇部运动和脸部特征之间的潜在连接。现有的 TFG 方法已经做出了很大的进步，以生成自然和真实的图像。然而，大多数工作rarely 考虑视觉质量。在 cross-modal 生成方法中，保证唇部同步 while avoiding 视觉质量下降是一个挑战。为解决这个问题，我们提出了一个通用的高清晰牙齿修复网络，名为 HDTR-Net，可以在极快速速度下提高牙齿区域的清晰度，并保持同步和时间一致性。具体来说，我们提出了细腻特征融合（FGFF）模块，可以有效地捕捉牙齿和周围地域的细节特征信息，并使用这些特征来细化特征地图来提高牙齿的清晰度。我们的方法可以适应任意的 TFG 方法，而不会受到唇部同步和帧协调的影响。另外，HDTR-Net 还具有实时生成能力，在高清晰牙齿视频合成的情况下，其推理速度比现有的面部恢复技术更快，高出 $300\%$。
</details></li>
</ul>
<hr>
<h2 id="Where2Explore-Few-shot-Affordance-Learning-for-Unseen-Novel-Categories-of-Articulated-Objects"><a href="#Where2Explore-Few-shot-Affordance-Learning-for-Unseen-Novel-Categories-of-Articulated-Objects" class="headerlink" title="Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects"></a>Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07473">http://arxiv.org/abs/2309.07473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanruo Ning, Ruihai Wu, Haoran Lu, Kaichun Mo, Hao Dong</li>
<li>for: 本研究旨在解决机器人操作物体时遇到的基本问题，即对不同类别物体的抽象和Semantic variation的挑战。</li>
<li>methods: 我们提出了一种基于几何相似性的’Where2Explore’探索框架，通过在有限数量的实例上进行有效的探索，以适应 novel 类别物体。我们的框架可以快速地识别出不同类别物体之间的相似性，并将这些相似性转移到类似的部分，以便更高效地探索和学习。</li>
<li>results: 我们的实验表明，我们的框架可以快速地适应 novel 类别物体，并在实际环境中提供了高效的探索和学习功能。<details>
<summary>Abstract</summary>
Articulated object manipulation is a fundamental yet challenging task in robotics. Due to significant geometric and semantic variations across object categories, previous manipulation models struggle to generalize to novel categories. Few-shot learning is a promising solution for alleviating this issue by allowing robots to perform a few interactions with unseen objects. However, extant approaches often necessitate costly and inefficient test-time interactions with each unseen instance. Recognizing this limitation, we observe that despite their distinct shapes, different categories often share similar local geometries essential for manipulation, such as pullable handles and graspable edges - a factor typically underutilized in previous few-shot learning works. To harness this commonality, we introduce 'Where2Explore', an affordance learning framework that effectively explores novel categories with minimal interactions on a limited number of instances. Our framework explicitly estimates the geometric similarity across different categories, identifying local areas that differ from shapes in the training categories for efficient exploration while concurrently transferring affordance knowledge to similar parts of the objects. Extensive experiments in simulated and real-world environments demonstrate our framework's capacity for efficient few-shot exploration and generalization.
</details>
<details>
<summary>摘要</summary>
《描述物体搅动是机器人学中的基本 yet 挑战性任务。由于不同物体类别之间的几何和semantic variation很大， previous manipulation models 很难泛化到新类别。ew-shot learning 是一种有前途的解决方案，允许机器人在未看过的对象上进行几次互动。然而，现有的方法经常需要费时且不efficient的在每个未看过的实例上进行测试。认识到这一点，我们注意到，尽管它们的形状不同，不同的类别通常具有类似的本地几何特征，如可拖 handle 和可握 edge - 一种通常被前一些ew-shot learning works 下utilized。为了利用这一点，我们提出了 'Where2Explore'，一种可以fficiently explore novel categories的投入学框架。我们的框架Explicitly estimates the geometric similarity across different categories, 并将这些类似性转移到相似的对象部分，以便高效地探索新类别。我们的框架在模拟和实际环境中进行了广泛的实验，并证明了它的高效性和泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Unknown-Attacks-in-IoT-Environments-An-Open-Set-Classifier-for-Enhanced-Network-Intrusion-Detection"><a href="#Detecting-Unknown-Attacks-in-IoT-Environments-An-Open-Set-Classifier-for-Enhanced-Network-Intrusion-Detection" class="headerlink" title="Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection"></a>Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07461">http://arxiv.org/abs/2309.07461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian</li>
<li>for: 这篇论文旨在提供一个适应互联网领域的网络入侵检测系统（NIDS），以应对互联网物品（IoT）环境中的攻击。</li>
<li>methods: 这篇论文使用了图像基于的封包级数据表示法，将网络流量中的空间和时间模式抽象出来，以及整合堆叠和子集拓扑技术，以更好地识别未知的攻击。</li>
<li>results: 这篇论文的实验结果显示，该 frameworks 的检测率高达 88%，比较其他方法和最新的进展更高。<details>
<summary>Abstract</summary>
The widespread integration of Internet of Things (IoT) devices across all facets of life has ushered in an era of interconnectedness, creating new avenues for cybersecurity challenges and underscoring the need for robust intrusion detection systems. However, traditional security systems are designed with a closed-world perspective and often face challenges in dealing with the ever-evolving threat landscape, where new and unfamiliar attacks are constantly emerging. In this paper, we introduce a framework aimed at mitigating the open set recognition (OSR) problem in the realm of Network Intrusion Detection Systems (NIDS) tailored for IoT environments. Our framework capitalizes on image-based representations of packet-level data, extracting spatial and temporal patterns from network traffic. Additionally, we integrate stacking and sub-clustering techniques, enabling the identification of unknown attacks by effectively modeling the complex and diverse nature of benign behavior. The empirical results prominently underscore the framework's efficacy, boasting an impressive 88\% detection rate for previously unseen attacks when compared against existing approaches and recent advancements. Future work will perform extensive experimentation across various openness levels and attack scenarios, further strengthening the adaptability and performance of our proposed solution in safeguarding IoT environments.
</details>
<details>
<summary>摘要</summary>
互联网物件的普遍散布在生活所有方面，带来了一个通信连接的时代，创造了新的预防措施挑战和强化网络防护系统的需求。然而，传统的安全系统具有关闭世界的想法，往往对于不断发展的威胁领域显示出困难。在本文中，我们介绍了一个适应网络入侵检测系统（NIDS）的框架，用于解决网络入侵检测系统中的开放集 recognition（OSR）问题。我们的框架利用图像基本的封包水平数据表示，检测网络流量中的空间和时间几何模式。此外，我们还整合了堆叠和子集拓扑技术，以实现模elling Complex和多元的正常行为，从而识别未知的攻击。我们的实验结果显示，我们的提案可以实现88%的检测率，与现有方法和最新的进展相比。未来的工作将进行各种开放程度和攻击enario的广泛实验，进一步强化我们的提案在保护 IoT 环境方面的适用性和性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-Artificial-General-Intelligence-AGI-in-the-Internet-of-Things-IoT-Opportunities-and-Challenges"><a href="#Towards-Artificial-General-Intelligence-AGI-in-the-Internet-of-Things-IoT-Opportunities-and-Challenges" class="headerlink" title="Towards Artificial General Intelligence (AGI) in the Internet of Things (IoT): Opportunities and Challenges"></a>Towards Artificial General Intelligence (AGI) in the Internet of Things (IoT): Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07438">http://arxiv.org/abs/2309.07438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Dou, Jin Ye, Geng Yuan, Qin Lu, Wei Niu, Haijian Sun, Le Guan, Guoyu Lu, Gengchen Mai, Ninghao Liu, Jin Lu, Zhengliang Liu, Zihao Wu, Chenjiao Tan, Shaochen Xu, Xianqiao Wang, Guoming Li, Lilong Chai, Sheng Li, Jin Sun, Hongyue Sun, Yunli Shao, Changying Li, Tianming Liu, Wenzhan Song<br>for: 这篇研究探讨了智能网络的应用和挑战，尤其是在智能家居、生产、运输和教育等领域。methods: 本研究将AGI融合到IoT系统中，并提出了一个概念框架来实现这一目标。results: 研究发现AGI在IoT系统中的应用范围很广泛，但是适应IoT设备限制的AGI需要进一步的研究。此外，研究也探讨了IoT通信的复杂性和安全性问题。<details>
<summary>Abstract</summary>
Artificial General Intelligence (AGI), possessing the capacity to comprehend, learn, and execute tasks with human cognitive abilities, engenders significant anticipation and intrigue across scientific, commercial, and societal arenas. This fascination extends particularly to the Internet of Things (IoT), a landscape characterized by the interconnection of countless devices, sensors, and systems, collectively gathering and sharing data to enable intelligent decision-making and automation. This research embarks on an exploration of the opportunities and challenges towards achieving AGI in the context of the IoT. Specifically, it starts by outlining the fundamental principles of IoT and the critical role of Artificial Intelligence (AI) in IoT systems. Subsequently, it delves into AGI fundamentals, culminating in the formulation of a conceptual framework for AGI's seamless integration within IoT. The application spectrum for AGI-infused IoT is broad, encompassing domains ranging from smart grids, residential environments, manufacturing, and transportation to environmental monitoring, agriculture, healthcare, and education. However, adapting AGI to resource-constrained IoT settings necessitates dedicated research efforts. Furthermore, the paper addresses constraints imposed by limited computing resources, intricacies associated with large-scale IoT communication, as well as the critical concerns pertaining to security and privacy.
</details>
<details>
<summary>摘要</summary>
人工通用智能（AGI）具有人类认知能力的容器，引发科学、商业和社会领域的广泛关注。特别是在互联网东西（IoT）领域，AGI的应用前景非常广阔。这项研究探讨了在IoT预设下实现AGI的机会和挑战。研究首先介绍了IoT的基本原则和人工智能（AI）在IoT系统中的重要作用。然后，探讨了AGI的基本原则，并构建了AGI在IoT中的概念框架。AGI在IoT领域的应用范围广泛，涵盖智能街区、家庭环境、制造、交通等领域，以及环境监测、农业、医疗和教育等领域。然而，将AGI应用于有限资源的IoT设置中需要专门的研究努力。此外，研究还考虑了IoT通信的大规模复杂性和安全隐私问题。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Parsing-in-Limited-Resource-Conditions"><a href="#Semantic-Parsing-in-Limited-Resource-Conditions" class="headerlink" title="Semantic Parsing in Limited Resource Conditions"></a>Semantic Parsing in Limited Resource Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07429">http://arxiv.org/abs/2309.07429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuang Li</li>
<li>for: 本论文关注 semantic parsing 面临的挑战，具体是在有限数据和计算资源的情况下。</li>
<li>methods: 本论文提出了一些解决方案，包括自动数据约束、知识传递、活动学习和连续学习。在没有平行训练数据的情况下，论文提议生成基于结构化数据库的 sintetic 训练示例。当源领域有充足数据，但目标领域有限制的平行数据时，本论文利用源领域的知识提高 parsing 性能。在多语言情况下，论文提出了一种适应 parsers 的方法，通过有限人工翻译预算来进行活动学习，以达到更好的 parsing 性能。</li>
<li>results: 本论文的实验结果表明，这些方法可以有效地提高 semantic parsing 的性能，尤其是在有限数据和计算资源的情况下。<details>
<summary>Abstract</summary>
This thesis explores challenges in semantic parsing, specifically focusing on scenarios with limited data and computational resources. It offers solutions using techniques like automatic data curation, knowledge transfer, active learning, and continual learning.   For tasks with no parallel training data, the thesis proposes generating synthetic training examples from structured database schemas. When there is abundant data in a source domain but limited parallel data in a target domain, knowledge from the source is leveraged to improve parsing in the target domain.   For multilingual situations with limited data in the target languages, the thesis introduces a method to adapt parsers using a limited human translation budget. Active learning is applied to select source-language samples for manual translation, maximizing parser performance in the target language. In addition, an alternative method is also proposed to utilize machine translation services, supplemented by human-translated data, to train a more effective parser.   When computational resources are limited, a continual learning approach is introduced to minimize training time and computational memory. This maintains the parser's efficiency in previously learned tasks while adapting it to new tasks, mitigating the problem of catastrophic forgetting.   Overall, the thesis provides a comprehensive set of methods to improve semantic parsing in resource-constrained conditions.
</details>
<details>
<summary>摘要</summary>
For tasks with no parallel training data, the thesis suggests generating synthetic training examples from structured database schemas. When there is abundant data in a source domain but limited parallel data in a target domain, the thesis leverages knowledge from the source domain to improve parsing in the target domain.For multilingual situations with limited data in the target languages, the thesis introduces a method to adapt parsers using a limited human translation budget. Active learning is applied to select source-language samples for manual translation, maximizing parser performance in the target language. Additionally, an alternative method is proposed to utilize machine translation services, supplemented by human-translated data, to train a more effective parser.When computational resources are limited, the thesis introduces a continual learning approach to minimize training time and computational memory. This approach maintains the parser's efficiency in previously learned tasks while adapting it to new tasks, mitigating the problem of catastrophic forgetting.Overall, the thesis provides a comprehensive set of methods to improve semantic parsing in resource-constrained conditions.
</details></li>
</ul>
<hr>
<h2 id="JSMNet-Improving-Indoor-Point-Cloud-Semantic-and-Instance-Segmentation-through-Self-Attention-and-Multiscale"><a href="#JSMNet-Improving-Indoor-Point-Cloud-Semantic-and-Instance-Segmentation-through-Self-Attention-and-Multiscale" class="headerlink" title="JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation through Self-Attention and Multiscale"></a>JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation through Self-Attention and Multiscale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07425">http://arxiv.org/abs/2309.07425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuochen Xu, Zhenxin Zhang</li>
<li>for: 本研究的目的是提高indoor 3D点云数据的Semantic Understanding，以便应用于室内服务机器人、导航系统和数字双工程等领域。</li>
<li>methods: 我们提出了JSMNet方法，它结合多层网络和全局特征自注意模块，以实现高质量的indoor点云Semantic和实例分割。我们还设计了一个多resolution特征适应融合模块，以更好地表达indoor目标的特征。</li>
<li>results: 我们在S3DIS dataset上进行了实验，并与其他方法进行比较。结果显示，我们的提出方法在Semantic和实例分割方面的性能比PointNet和ASIS等方法高出16.0%和26.3%，并在目标地区分割方面比JSPNet等方法高出3.3%。<details>
<summary>Abstract</summary>
The semantic understanding of indoor 3D point cloud data is crucial for a range of subsequent applications, including indoor service robots, navigation systems, and digital twin engineering. Global features are crucial for achieving high-quality semantic and instance segmentation of indoor point clouds, as they provide essential long-range context information. To this end, we propose JSMNet, which combines a multi-layer network with a global feature self-attention module to jointly segment three-dimensional point cloud semantics and instances. To better express the characteristics of indoor targets, we have designed a multi-resolution feature adaptive fusion module that takes into account the differences in point cloud density caused by varying scanner distances from the target. Additionally, we propose a framework for joint semantic and instance segmentation by integrating semantic and instance features to achieve superior results. We conduct experiments on S3DIS, which is a large three-dimensional indoor point cloud dataset. Our proposed method is compared against other methods, and the results show that it outperforms existing methods in semantic and instance segmentation and provides better results in target local area segmentation. Specifically, our proposed method outperforms PointNet (Qi et al., 2017a) by 16.0% and 26.3% in terms of semantic segmentation mIoU in S3DIS (Area 5) and instance segmentation mPre, respectively. Additionally, it surpasses ASIS (Wang et al., 2019) by 6.0% and 4.6%, respectively, as well as JSPNet (Chen et al., 2022) by a margin of 3.3% for semantic segmentation mIoU and a slight improvement of 0.3% for instance segmentation mPre.
</details>
<details>
<summary>摘要</summary>
semantic understanding of indoor 3D point cloud data是重要的，用于多种应用程序，包括室内服务机器人、导航系统和数字孪生工程。全球特征对于实现高质量的indoor point cloud Semantic和实例分割是关键的，因为它们提供了重要的远程上下文信息。为了实现这一目标，我们提议了JSMNet，它组合了多层网络和全球特征自注意模块，以同时分割三维点云Semantic和实例。为了更好地表达室内目标特征，我们设计了一个多resolution特征适应融合模块，该模块考虑了由不同扫描仪距离目标而带来的点云密度差异。此外，我们提出了一个整合Semantic和实例特征的框架，以实现更高的结果。我们在S3DIS大型三维室内点云集合上进行实验，并与其他方法进行比较。结果显示，我们的提议方法在Semantic和实例分割方面比exist方法高出16.0%和26.3%，并在目标本地分割方面比exist方法高出6.0%和4.6%。此外，它还比JSPNet（Chen et al., 2022）高出3.3%的Semantic分割mIoU和0.3%的实例分割mPre。
</details></li>
</ul>
<hr>
<h2 id="An-Assessment-of-ChatGPT-on-Log-Data"><a href="#An-Assessment-of-ChatGPT-on-Log-Data" class="headerlink" title="An Assessment of ChatGPT on Log Data"></a>An Assessment of ChatGPT on Log Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07938">http://arxiv.org/abs/2309.07938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Priyanka Mudgal, Rita Wouhaybi</li>
<li>for: 这 paper 旨在研究 ChatGPT 是否可以对日志数据进行有价值的处理，以及该模型在这个领域的缺陷和可能的下一步改进。</li>
<li>methods: 该 paper 使用 ChatGPT 进行日志数据处理，并对其表现进行分析和评估。</li>
<li>results: 研究发现，当前版本的 ChatGPT 对日志数据处理表现有限，响应不一致，并且存在扩展性问题。<details>
<summary>Abstract</summary>
Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues.
</details>
<details>
<summary>摘要</summary>
现代大语言模型（LLM），如ChatGPT，在软件工程任务上广泛应用。许多论文报道了对写代码、摘要、文本生成等任务的分析。然而，对ChatGPT在日志处理方面的现状分析尚未受到足够关注。大规模软件系统生成的日志复杂且难以理解，但它们提供了关键信息，帮助专家了解系统状态并诊断问题。在这篇论文中，我们调查了当前ChatGPT对日志数据进行多种有趣任务的能力，同时尝试了识别其主要缺陷。我们的发现表明，当前ChatGPT对日志处理的性能有限，响应不一致和可扩展性受限。我们还描述了我们对LLM在日志处理领域的角色和未来LLM在这个领域的可能发展。我们认为，我们的工作可以贡献于未来的学术研究，解决已知问题。
</details></li>
</ul>
<hr>
<h2 id="Client-side-Gradient-Inversion-Against-Federated-Learning-from-Poisoning"><a href="#Client-side-Gradient-Inversion-Against-Federated-Learning-from-Poisoning" class="headerlink" title="Client-side Gradient Inversion Against Federated Learning from Poisoning"></a>Client-side Gradient Inversion Against Federated Learning from Poisoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07415">http://arxiv.org/abs/2309.07415</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clientsidegia/cgi">https://github.com/clientsidegia/cgi</a></li>
<li>paper_authors: Jiaheng Wei, Yanjun Zhang, Leo Yu Zhang, Chao Chen, Shirui Pan, Kok-Leong Ong, Jun Zhang, Yang Xiang</li>
<li>For: The paper is written to address the vulnerability of federated learning (FL) to gradient inversion attacks (GIA), and to propose a novel attack method called client-side poisoning gradient inversion (CGI) that can be launched from clients.* Methods: The paper proposes a distinct approach in which an adversary utilizes a malicious model that amplifies the loss of a specific targeted class of interest, and optimizes malicious updates and blends benign updates with a malicious replacement vector to remain undetected by Byzantine-robust aggregation rules (AGRs).* Results: The paper demonstrates the feasibility of a client-side adversary with limited knowledge being able to recover the training samples from the aggregated global model, and shows that the proposed CGI method consistently and successfully extracts training input in all tested scenarios, including against Byzantine-robust AGRs.<details>
<summary>Abstract</summary>
Federated Learning (FL) enables distributed participants (e.g., mobile devices) to train a global model without sharing data directly to a central server. Recent studies have revealed that FL is vulnerable to gradient inversion attack (GIA), which aims to reconstruct the original training samples and poses high risk against the privacy of clients in FL. However, most existing GIAs necessitate control over the server and rely on strong prior knowledge including batch normalization and data distribution information. In this work, we propose Client-side poisoning Gradient Inversion (CGI), which is a novel attack method that can be launched from clients. For the first time, we show the feasibility of a client-side adversary with limited knowledge being able to recover the training samples from the aggregated global model. We take a distinct approach in which the adversary utilizes a malicious model that amplifies the loss of a specific targeted class of interest. When honest clients employ the poisoned global model, the gradients of samples belonging to the targeted class are magnified, making them the dominant factor in the aggregated update. This enables the adversary to effectively reconstruct the private input belonging to other clients using the aggregated update. In addition, our CGI also features its ability to remain stealthy against Byzantine-robust aggregation rules (AGRs). By optimizing malicious updates and blending benign updates with a malicious replacement vector, our method remains undetected by these defense mechanisms. To evaluate the performance of CGI, we conduct experiments on various benchmark datasets, considering representative Byzantine-robust AGRs, and exploring diverse FL settings with different levels of adversary knowledge about the data. Our results demonstrate that CGI consistently and successfully extracts training input in all tested scenarios.
</details>
<details>
<summary>摘要</summary>
分布式学习（FL）可以让分布式参与者（例如移动设备）共同训练全球模型，无需直接将数据传输到中央服务器。然而，现有研究表明，FL受到梯度反向攻击（GIA）的威胁，GIA的目标是重建原始训练样本，这会对客户端隐私造成高风险。然而，大多数现有的GIA都需要控制服务器并且需要强大的先前知识，包括批处理normalization和数据分布信息。在这项工作中，我们提出了客户端恶意梯度反向攻击（CGI），这是一种新的攻击方法，可以从客户端发起。我们首次表明，一个有限知识的客户端恶意者可以通过恶意模型来重建私有输入。我们采取了一种独特的方法，在恶意模型中 amplifies 特定类别的损失，使得这些样本的梯度在汇集后变得占主导地位。这使得恶意者可以通过汇集更新来重建其他客户端的私有输入。此外，我们的CGI还具有逃避拜尼瑞安规则（AGRs）的能力。通过优化恶意更新和杂合善良更新的恶意替换 вектор，我们的方法可以逃脱这些防御机制。为评估CGI的表现，我们在多个标准数据集上进行了实验，考虑了代表性的拜尼瑞安规则，以及不同的FL设置和恶意知识水平。我们的结果表明，CGI在所有测试场景中都能够成功地重建私有输入。
</details></li>
</ul>
<hr>
<h2 id="FunCodec-A-Fundamental-Reproducible-and-Integrable-Open-source-Toolkit-for-Neural-Speech-Codec"><a href="#FunCodec-A-Fundamental-Reproducible-and-Integrable-Open-source-Toolkit-for-Neural-Speech-Codec" class="headerlink" title="FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec"></a>FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07405">http://arxiv.org/abs/2309.07405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihao Du, Shiliang Zhang, Kai Hu, Siqi Zheng</li>
<li>for: 这个研究是为了开发一个基本的神经语音编码工具库（FunCodec），并提供可重现性的训练程式和测试脚本，以及可以与其他语音处理工具集成的可扩展设计。</li>
<li>methods: 这个研究使用了声音流程（SoundStream）和编码器（Encodec）等最新的神经语音编码模型，并提供了预训练的模型，可以用于学术或通用目的。</li>
<li>results: 根据实验结果，FunCodec可以在相同的压缩比例下实现更好的重建质量，并且可以与其他工具kit和发布的模型进行比较。此外，预训练的模型还可以用于下游任务，例如自动语音识别和个人化文本读取 synthesis。<details>
<summary>Abstract</summary>
This paper presents FunCodec, a fundamental neural speech codec toolkit, which is an extension of the open-source speech processing toolkit FunASR. FunCodec provides reproducible training recipes and inference scripts for the latest neural speech codec models, such as SoundStream and Encodec. Thanks to the unified design with FunASR, FunCodec can be easily integrated into downstream tasks, such as speech recognition. Along with FunCodec, pre-trained models are also provided, which can be used for academic or generalized purposes. Based on the toolkit, we further propose the frequency-domain codec models, FreqCodec, which can achieve comparable speech quality with much lower computation and parameter complexity. Experimental results show that, under the same compression ratio, FunCodec can achieve better reconstruction quality compared with other toolkits and released models. We also demonstrate that the pre-trained models are suitable for downstream tasks, including automatic speech recognition and personalized text-to-speech synthesis. This toolkit is publicly available at https://github.com/alibaba-damo-academy/FunCodec.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了FunCodec，一个基于开源语音处理工具kit FunASR的基本神经网络语音编码器工具kit。FunCodec提供可重现训练药方和推理脚本，用于最新的神经网络语音编码器模型，如SoundStream和Encodec。由于FunCodec和FunASR的统一设计，因此可以轻松地将FunCodec集成到下游任务中，如语音识别。同时，预训练模型也是提供的，可以用于学术或通用目的。基于工具kit，我们还提出了频率频域编码器模型（FreqCodec），可以实现与其他工具kit和发布的模型相同的语音质量，但是具有远低的计算复杂性和参数量。实验结果表明，在同一压缩比下，FunCodec可以实现比其他工具kit和发布的模型更好的重建质量。此外，我们还证明了预训练模型适用于下游任务，包括自动语音识别和个性化文本到语音合成。这个工具kit现在可以在https://github.com/alibaba-damo-academy/FunCodec上获取。
</details></li>
</ul>
<hr>
<h2 id="Multi-Grade-Deep-Learning-for-Partial-Differential-Equations-with-Applications-to-the-Burgers-Equation"><a href="#Multi-Grade-Deep-Learning-for-Partial-Differential-Equations-with-Applications-to-the-Burgers-Equation" class="headerlink" title="Multi-Grade Deep Learning for Partial Differential Equations with Applications to the Burgers Equation"></a>Multi-Grade Deep Learning for Partial Differential Equations with Applications to the Burgers Equation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07401">http://arxiv.org/abs/2309.07401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuesheng Xu, Taishan Zeng</li>
<li>For: This paper proposes a multi-grade deep learning method for solving nonlinear partial differential equations (PDEs), which can efficiently learn solutions of the equations and outperform existing single-grade deep learning methods in predictive accuracy.* Methods: The proposed method breaks down the task of learning a deep neural network (DNN) into several neural networks stacked on top of each other in a staircase-like manner, allowing for the mitigation of the complexity of solving the non-convex optimization problem with large number of parameters and the efficient learning of residual components left over from previous grades.* Results: The proposed two-stage multi-grade deep learning method enables efficient learning of solutions of the 1D, 2D, and 3D viscous Burgers equations, and outperforms existing single-grade deep learning methods in predictive accuracy. Specifically, the predictive errors of the single-grade deep learning are larger than those of the TS-MGDL method in 26-60, 4-31 and 3-12 times, for the 1D, 2D, and 3D equations, respectively.<details>
<summary>Abstract</summary>
We develop in this paper a multi-grade deep learning method for solving nonlinear partial differential equations (PDEs). Deep neural networks (DNNs) have received super performance in solving PDEs in addition to their outstanding success in areas such as natural language processing, computer vision, and robotics. However, training a very deep network is often a challenging task. As the number of layers of a DNN increases, solving a large-scale non-convex optimization problem that results in the DNN solution of PDEs becomes more and more difficult, which may lead to a decrease rather than an increase in predictive accuracy. To overcome this challenge, we propose a two-stage multi-grade deep learning (TS-MGDL) method that breaks down the task of learning a DNN into several neural networks stacked on top of each other in a staircase-like manner. This approach allows us to mitigate the complexity of solving the non-convex optimization problem with large number of parameters and learn residual components left over from previous grades efficiently. We prove that each grade/stage of the proposed TS-MGDL method can reduce the value of the loss function and further validate this fact through numerical experiments. Although the proposed method is applicable to general PDEs, implementation in this paper focuses only on the 1D, 2D, and 3D viscous Burgers equations. Experimental results show that the proposed two-stage multi-grade deep learning method enables efficient learning of solutions of the equations and outperforms existing single-grade deep learning methods in predictive accuracy. Specifically, the predictive errors of the single-grade deep learning are larger than those of the TS-MGDL method in 26-60, 4-31 and 3-12 times, for the 1D, 2D, and 3D equations, respectively.
</details>
<details>
<summary>摘要</summary>
我们在这篇论文中开发了一种多级深度学习方法，用于解决非线性偏微分方程（PDEs）。深度神经网络（DNNs）在解决PDEs方面已经表现出了绝佳的成绩，同时在自然语言处理、计算机视觉和机器人等领域也取得了突出的成绩。然而，训练非常深的网络是一项具有挑战性的任务。随着网络层数的增加，解决大规模非凸优化问题，以获得DNN的PDE解决方案，变得越来越Difficult，可能会导致预测精度下降。为了解决这个挑战，我们提出了一种两个阶段多级深度学习（TS-MGDL）方法，它将把解决DNN的任务分解成多个堆叠在一起的神经网络。这种方法可以减少解决非凸优化问题中参数的数量，并高效地学习剩余的Components。我们证明每个阶段/stage的TS-MGDL方法都可以降低损失函数的值，并通过实验 validate this fact。虽然该方法适用于一般PDEs，但在这篇论文中只进行了三维液体压力方程的实现。实验结果表明，提出的两个阶段多级深度学习方法可以有效地学习PDE的解，并且在预测精度方面超过单个阶段深度学习方法。特别是，单个阶段深度学习方法的预测错误相对TS-MGDL方法大得多，在1D、2D和3D方程中分别为26-60、4-31和3-12倍。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Adversarial-Attacks-via-Diffusion-Models"><a href="#Semantic-Adversarial-Attacks-via-Diffusion-Models" class="headerlink" title="Semantic Adversarial Attacks via Diffusion Models"></a>Semantic Adversarial Attacks via Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07398">http://arxiv.org/abs/2309.07398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/steven202/semantic_adv_via_dm">https://github.com/steven202/semantic_adv_via_dm</a></li>
<li>paper_authors: Chenan Wang, Jinhao Duan, Chaowei Xiao, Edward Kim, Matthew Stamm, Kaidi Xu</li>
<li>for: 这篇论文旨在提出一个快速生成 semantic adversarial attack 的框架，并提供了两种不同的 variants，即 Semantic Transformation (ST) 和 Latent Masking (LM) approaches.</li>
<li>methods: 这篇论文使用了 recent diffusion models 来快速生成 semantic adversarial attack，并在这些模型的latent space中进行了修饰和调整。</li>
<li>results:  experiments 表明，这篇论文的方法可以在 CelebA-HQ 和 AFHQ  datasets 上 достичь高度的成功率（约 100%）和优秀的数据调整能力（FID 为 36.61），并且在不同的设定下具有了优秀的通用性和转移性。<details>
<summary>Abstract</summary>
Traditional adversarial attacks concentrate on manipulating clean examples in the pixel space by adding adversarial perturbations. By contrast, semantic adversarial attacks focus on changing semantic attributes of clean examples, such as color, context, and features, which are more feasible in the real world. In this paper, we propose a framework to quickly generate a semantic adversarial attack by leveraging recent diffusion models since semantic information is included in the latent space of well-trained diffusion models. Then there are two variants of this framework: 1) the Semantic Transformation (ST) approach fine-tunes the latent space of the generated image and/or the diffusion model itself; 2) the Latent Masking (LM) approach masks the latent space with another target image and local backpropagation-based interpretation methods. Additionally, the ST approach can be applied in either white-box or black-box settings. Extensive experiments are conducted on CelebA-HQ and AFHQ datasets, and our framework demonstrates great fidelity, generalizability, and transferability compared to other baselines. Our approaches achieve approximately 100% attack success rate in multiple settings with the best FID as 36.61. Code is available at https://github.com/steven202/semantic_adv_via_dm.
</details>
<details>
<summary>摘要</summary>
传统的对抗攻击主要集中在图像空间中添加对抗扰动。然而，semantic adversarial攻击则更关注清晰例中的 semantic attribute，如颜色、上下文和特征。在这篇论文中，我们提出了一个框架，可以快速生成semantic adversarial攻击，通过利用最近的扩散模型，因为这些模型中包含了semantic信息。然后有两种变体的这个框架：1）semantic Transformation（ST）方法在生成图像和/或扩散模型的latent space中进行细化; 2）latent Masking（LM）方法使用另一个目标图像和局部backpropagation-based interpretation方法来遮盖latent space。此外，ST方法可以在白盒和黑盒设置中应用。我们对CelebA-HQ和AFHQ datasets进行了广泛的实验，并证明了我们的框架具有高度的准确性、普适性和传输性，相比其他基准。我们的方法在多种设置中实现了约100%的攻击成功率，并且FID值为36.61。代码可以在https://github.com/steven202/semantic_adv_via_dm上下载。
</details></li>
</ul>
<hr>
<h2 id="DebCSE-Rethinking-Unsupervised-Contrastive-Sentence-Embedding-Learning-in-the-Debiasing-Perspective"><a href="#DebCSE-Rethinking-Unsupervised-Contrastive-Sentence-Embedding-Learning-in-the-Debiasing-Perspective" class="headerlink" title="DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective"></a>DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07396">http://arxiv.org/abs/2309.07396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pu Miao, Zeyao Du, Junlin Zhang</li>
<li>for: 本研究的目的是提高句子嵌入模型的质量，因为现有的研究表明，BERT模型可能因为词频偏好而学习不良的句子嵌入。</li>
<li>methods: 本研究使用了一种新的对比学习框架，称为DebCSE，以消除各种偏好的影响，包括句子长度偏好和false negative sample bias。DebCSE使用了一种逆 probabilistic sampling 方法，选择高质量的正例对和负例对，以提高嵌入的质量。</li>
<li>results: 对 semantic textual similarity (STS) benchmarks进行了广泛的实验，显示DebCSE在BERTbase上得到了显著的提高，其Spearman correlation coefficient平均值为80.33%。<details>
<summary>Abstract</summary>
Several prior studies have suggested that word frequency biases can cause the Bert model to learn indistinguishable sentence embeddings. Contrastive learning schemes such as SimCSE and ConSERT have already been adopted successfully in unsupervised sentence embedding to improve the quality of embeddings by reducing this bias. However, these methods still introduce new biases such as sentence length bias and false negative sample bias, that hinders model's ability to learn more fine-grained semantics. In this paper, we reexamine the challenges of contrastive sentence embedding learning from a debiasing perspective and argue that effectively eliminating the influence of various biases is crucial for learning high-quality sentence embeddings. We think all those biases are introduced by simple rules for constructing training data in contrastive learning and the key for contrastive learning sentence embedding is to mimic the distribution of training data in supervised machine learning in unsupervised way. We propose a novel contrastive framework for sentence embedding, termed DebCSE, which can eliminate the impact of these biases by an inverse propensity weighted sampling method to select high-quality positive and negative pairs according to both the surface and semantic similarity between sentences. Extensive experiments on semantic textual similarity (STS) benchmarks reveal that DebCSE significantly outperforms the latest state-of-the-art models with an average Spearman's correlation coefficient of 80.33% on BERTbase.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)前些研究已经表明，word frequency bias可以使BERT模型学习不可区分的句子嵌入。例如SimCSE和ConSERT已经成功地在无监督句子嵌入中提高嵌入质量，而这些方法仍然引入了新的偏好，如句子长度偏好和假阴性样本偏好，这会阻碍模型学习更细化的 semantics。在这篇论文中，我们重新评估了对句子嵌入学习的挑战，并 argue that消除各种偏好是学习高质量句子嵌入的关键。我们认为这些偏好都是由对构造训练数据的简单规则引入的，因此，针对training数据的分布来进行无监督学习的方法是关键。我们提出了一种新的对句子嵌入框架，称为DebCSE，可以消除这些偏好的影响。DebCSE使用反propensity weighted sampling方法选择高质量的正样本和负样本，根据句子表面和semantic相似性。我们对STSbenchmark进行了广泛的实验，显示DebCSE在BERTbase上的平均Spearman correlation coefficient为80.33%，超过了最新的状态计算机模型。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Depth-and-Pose-Estimation-Neural-Networks-by-Designing-Compatible-Endoscopic-Images"><a href="#Unleashing-the-Power-of-Depth-and-Pose-Estimation-Neural-Networks-by-Designing-Compatible-Endoscopic-Images" class="headerlink" title="Unleashing the Power of Depth and Pose Estimation Neural Networks by Designing Compatible Endoscopic Images"></a>Unleashing the Power of Depth and Pose Estimation Neural Networks by Designing Compatible Endoscopic Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07390">http://arxiv.org/abs/2309.07390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Wu, Yun Gu</li>
<li>for: 本研究旨在提高endoscopic navigation中的深度和pose estimation框架，通过更好地与图像兼容ibilize neural networks。</li>
<li>methods: 我们在本研究中提出了两种方法来改进endoscopic图像和神经网络之间的兼容性。首先，我们引入Mask Image Modelling（MIM）模块，它输入部分图像信息而不是完整的图像信息，使神经网络能够从部分像素信息中恢复全局信息。其次，我们提出了一种轻量级神经网络来进一步改进endoscopic图像，以确保图像和神经网络之间的兼容性。</li>
<li>results: 我们在三个公共数据集和一个内部数据集上进行了广泛的实验，并证明了我们的方法可以大幅提高基elines。此外，我们提出的加强图像可以作为数据增强方法，并能够提取更稳定的特征点，在传统特征点匹配任务中表现出色。<details>
<summary>Abstract</summary>
Deep learning models have witnessed depth and pose estimation framework on unannotated datasets as a effective pathway to succeed in endoscopic navigation. Most current techniques are dedicated to developing more advanced neural networks to improve the accuracy. However, existing methods ignore the special properties of endoscopic images, resulting in an inability to fully unleash the power of neural networks. In this study, we conduct a detail analysis of the properties of endoscopic images and improve the compatibility of images and neural networks, to unleash the power of current neural networks. First, we introcude the Mask Image Modelling (MIM) module, which inputs partial image information instead of complete image information, allowing the network to recover global information from partial pixel information. This enhances the network' s ability to perceive global information and alleviates the phenomenon of local overfitting in convolutional neural networks due to local artifacts. Second, we propose a lightweight neural network to enhance the endoscopic images, to explicitly improve the compatibility between images and neural networks. Extensive experiments are conducted on the three public datasets and one inhouse dataset, and the proposed modules improve baselines by a large margin. Furthermore, the enhanced images we proposed, which have higher network compatibility, can serve as an effective data augmentation method and they are able to extract more stable feature points in traditional feature point matching tasks and achieve outstanding performance.
</details>
<details>
<summary>摘要</summary>
深度学习模型在无注意dataset上进行深度和pose估计框架，被视为有效的走向。现有大多数技术都是为了开发更高级别的神经网络，以提高准确性。然而，现有方法忽略了endooscopic图像的特殊性，导致神经网络无法全面发挥力量。在本研究中，我们进行了endooscopic图像的详细分析，并改进了图像和神经网络之间的兼容性，以解放神经网络的力量。首先，我们引入Mask Image Modelling（MIM）模块，该模块输入部分图像信息而不是完整的图像信息，allowing the network to recover global information from partial pixel information。这种方法使神经网络能够更好地感知全局信息，并减轻了因本地遗传而导致的Convolutional Neural Networks（CNN）的局部适应性。其次，我们提出了一种轻量级神经网络，用于提高endooscopic图像的兼容性。我们在三个公共数据集和一个内部数据集上进行了广泛的实验，并证明了我们的模块可以大幅提高基elines。此外，我们提出的改进图像可以作为一种有效的数据增强方法，它们具有更高的兼容性，可以提取更稳定的特征点，并在传统特征点匹配任务中达到出色的性能。
</details></li>
</ul>
<hr>
<h2 id="Landscape-Sketch-Step-An-AI-ML-Based-Metaheuristic-for-Surrogate-Optimization-Problems"><a href="#Landscape-Sketch-Step-An-AI-ML-Based-Metaheuristic-for-Surrogate-Optimization-Problems" class="headerlink" title="Landscape-Sketch-Step: An AI&#x2F;ML-Based Metaheuristic for Surrogate Optimization Problems"></a>Landscape-Sketch-Step: An AI&#x2F;ML-Based Metaheuristic for Surrogate Optimization Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07936">http://arxiv.org/abs/2309.07936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rafael-a-monteiro-math/landscape_sketch_and_step">https://github.com/rafael-a-monteiro-math/landscape_sketch_and_step</a></li>
<li>paper_authors: Rafael Monteiro, Kartik Sau<br>for: 这个论文是为了提出一种新的全球优化算法，用于解决在评估成本函数成本高、不可靠或禁止的情况下进行优化。methods: 该方法 combining机器学习、随机优化和奖励学习技术，利用历史信息来选择合适的参数值，以便更judicious地评估成本函数。results: 与传统的复制交换 Monte Carlo 方法相比，LSS 需要的评估次数相对较少，尤其是在高通量计算或高性能计算任务中，这点非常重要。此外，LSS 也不同于标准的代理优化技术，不需要构建一个代理模型来 aproximating 或重建目标函数。在低维度优化问题（维度 1、2、4、8）中应用 LSS ，与传统的 Simulated Annealing 相比，LSS 显示更有效地加速优化过程。<details>
<summary>Abstract</summary>
In this paper, we introduce a new heuristics for global optimization in scenarios where extensive evaluations of the cost function are expensive, inaccessible, or even prohibitive. The method, which we call Landscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic Optimization, and Reinforcement Learning techniques, relying on historical information from previously sampled points to make judicious choices of parameter values where the cost function should be evaluated at. Unlike optimization by Replica Exchange Monte Carlo methods, the number of evaluations of the cost function required in this approach is comparable to that used by Simulated Annealing, quality that is especially important in contexts like high-throughput computing or high-performance computing tasks, where evaluations are either computationally expensive or take a long time to be performed. The method also differs from standard Surrogate Optimization techniques, for it does not construct a surrogate model that aims at approximating or reconstructing the objective function. We illustrate our method by applying it to low dimensional optimization problems (dimensions 1, 2, 4, and 8) that mimick known difficulties of minimization on rugged energy landscapes often seen in Condensed Matter Physics, where cost functions are rugged and plagued with local minima. When compared to classical Simulated Annealing, the LSS shows an effective acceleration of the optimization process.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的全球优化启发法，用于在评估成本函数的成本高、不可靠或禁止的场景中进行全球优化。该方法，我们称之为“景观绘制步骤”（Landscape-Sketch-and-Step，LSS），结合机器学习、随机优化和强化学习技术，利用历史记录中的参数值来做出评估成本函数的judicious选择。与复制交换 Monte Carlo 方法不同，LSS 方法所需的评估成本函数的数量与 Simulated Annealing 相似，这种特点尤其重要在高通量计算或高性能计算任务中， где评估成本函数的计算成本或时间很高。此外，LSS 方法与标准代理优化技术不同，它不会构建一个目标函数的替身模型，以优化目标函数。我们通过应用该方法于低维度优化问题（维度 1、2、4、8），示出了 LSS 方法在 rugged 能量领域中的效果。相比于经典 Simulated Annealing，LSS 方法显示了更有效的优化过程。
</details></li>
</ul>
<hr>
<h2 id="The-kernel-balanced-equation-for-deep-neural-networks"><a href="#The-kernel-balanced-equation-for-deep-neural-networks" class="headerlink" title="The kernel-balanced equation for deep neural networks"></a>The kernel-balanced equation for deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07367">http://arxiv.org/abs/2309.07367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kenichi Nakazato</li>
<li>for: 这个论文的目的是研究深度神经网络在分布估计问题上的应用和稳定性问题。</li>
<li>methods: 这个论文使用了深度神经网络来估计数据集的分布，并通过训练来实现泛化 функción。</li>
<li>results: 研究发现，在训练时间长 enough和数据密度高 enough的情况下，神经网络的估计会变得不稳定，并且这种不稳定性与数据密度和训练时间之间存在正相关性。<details>
<summary>Abstract</summary>
Deep neural networks have shown many fruitful applications in this decade. A network can get the generalized function through training with a finite dataset. The degree of generalization is a realization of the proximity scale in the data space. Specifically, the scale is not clear if the dataset is complicated. Here we consider a network for the distribution estimation of the dataset. We show the estimation is unstable and the instability depends on the data density and training duration. We derive the kernel-balanced equation, which gives a short phenomenological description of the solution. The equation tells us the reason for the instability and the mechanism of the scale. The network outputs a local average of the dataset as a prediction and the scale of averaging is determined along the equation. The scale gradually decreases along training and finally results in instability in our case.
</details>
<details>
<summary>摘要</summary>
深度神经网络在本decennary中有很多成功应用。一个网络可以通过训练finite dataset来获得通用函数。特别是，数据空间中的距离度不清楚，如果数据集复杂。我们考虑一个数据集的分布估计网络。我们发现估计是不稳定的，不稳定程度取决于数据密度和训练时间。我们得出了kernel-balanced方程，它给出了解释解决方案的简短现象描述。这个方程告诉我们不稳定的原因和机制，以及估计的横幅是如何确定的。网络输出了一个数据集的本地均值作为预测，并且这个均值的横幅是通过方程确定的。在训练过程中，这个横幅逐渐减小，最终导致我们的 случаpped in our case.
</details></li>
</ul>
<hr>
<h2 id="Doubly-High-Dimensional-Contextual-Bandits-An-Interpretable-Model-for-Joint-Assortment-Pricing"><a href="#Doubly-High-Dimensional-Contextual-Bandits-An-Interpretable-Model-for-Joint-Assortment-Pricing" class="headerlink" title="Doubly High-Dimensional Contextual Bandits: An Interpretable Model for Joint Assortment-Pricing"></a>Doubly High-Dimensional Contextual Bandits: An Interpretable Model for Joint Assortment-Pricing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08634">http://arxiv.org/abs/2309.08634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhui Cai, Ran Chen, Martin J. Wainwright, Linda Zhao</li>
<li>for: 这种paper是为了解决零售业的挑战问题，具体来说是如何选择产品 Display 给消费者（搜索问题），以及如何定价产品（定价问题）以最大化收益或利润。</li>
<li>methods: 作者提出了一种联合方法，基于上下文投机（contextual bandits），来解决搜索和定价问题。该模型是双高维的，即 Context vector 和 Action 都可以取值在高维空间中。为了缓解维度的味道，作者提出了一种简单 yet flexible 的模型，通过一个（近似）低维表示矩阵来捕捉 covariate 和 Action 之间的交互。这种类型的模型具有一定的表达能力，同时仍然可以通过 latent factor 进行解释。</li>
<li>results: 作者提出了一种 computationally tractable 的方法，combines 探索&#x2F;利用协议与高维矩阵估计器，并证明了该方法的 regret bound。实验结果表明，该方法在各种标准投机和定价模型中表现较佳，并且在实际案例中（来自一家领先的快速食品公司和一家崛起的美妆公司）也有较高的收益。在每个案例中，作者证明了使用该方法可以获得至少三倍的收益或利润，同时Latent factor模型也能够很好地解释。<details>
<summary>Abstract</summary>
Key challenges in running a retail business include how to select products to present to consumers (the assortment problem), and how to price products (the pricing problem) to maximize revenue or profit. Instead of considering these problems in isolation, we propose a joint approach to assortment-pricing based on contextual bandits. Our model is doubly high-dimensional, in that both context vectors and actions are allowed to take values in high-dimensional spaces. In order to circumvent the curse of dimensionality, we propose a simple yet flexible model that captures the interactions between covariates and actions via a (near) low-rank representation matrix. The resulting class of models is reasonably expressive while remaining interpretable through latent factors, and includes various structured linear bandit and pricing models as particular cases. We propose a computationally tractable procedure that combines an exploration/exploitation protocol with an efficient low-rank matrix estimator, and we prove bounds on its regret. Simulation results show that this method has lower regret than state-of-the-art methods applied to various standard bandit and pricing models. Real-world case studies on the assortment-pricing problem, from an industry-leading instant noodles company to an emerging beauty start-up, underscore the gains achievable using our method. In each case, we show at least three-fold gains in revenue or profit by our bandit method, as well as the interpretability of the latent factor models that are learned.
</details>
<details>
<summary>摘要</summary>
主要挑战在经营零售业务中包括如何选择给消费者提供的产品（集合问题），以及如何定价产品（定价问题）以最大化收入或利润。而不是单独考虑这两个问题，我们提议一种联合的集合-定价方法，基于上下文矩阵。我们的模型是双重高维的，即上下文向量和行动都可以取值在高维空间中。为了缓解维度繁殖的问题，我们提议一种简单 yet  flexible的模型，通过一个（近）低维表示矩阵来捕捉上下文和行动之间的交互。这种类型的模型具有可解释性的特点，并包括一些结构化线性矩阵和定价模型作为特例。我们提出一种可行的计算过程，将探索/利用协议与高维矩阵估计器结合使用，并证明其误差的下界。实验结果显示，这种方法在各种标准矩阵和定价模型上的误差较低。实际案例，从一家领先的快速面公司到一家崛起的美容 startup，都证明了我们的方法可以实现至少三倍的收入或利润增加，同时 latent factor 模型的解释性也得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Hodge-Aware-Contrastive-Learning"><a href="#Hodge-Aware-Contrastive-Learning" class="headerlink" title="Hodge-Aware Contrastive Learning"></a>Hodge-Aware Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07364">http://arxiv.org/abs/2309.07364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Möllers, Alexander Immer, Vincent Fortuin, Elvin Isufi</li>
<li>for: 模型多元依赖关系数据，如网络边缘数据或其他高阶结构中的数据。</li>
<li>methods: 利用黎替 decomposition 分解数据谱，并通过 simplicial neural networks 编码数据不变量，制定了有利的增强策略和权重重新定义的反向例示。</li>
<li>results: 通过这种方法，可以获得具有特定спектル信息的嵌入，并在两个标准的边流分类任务上达到了更高的表现。<details>
<summary>Abstract</summary>
Simplicial complexes prove effective in modeling data with multiway dependencies, such as data defined along the edges of networks or within other higher-order structures. Their spectrum can be decomposed into three interpretable subspaces via the Hodge decomposition, resulting foundational in numerous applications. We leverage this decomposition to develop a contrastive self-supervised learning approach for processing simplicial data and generating embeddings that encapsulate specific spectral information.Specifically, we encode the pertinent data invariances through simplicial neural networks and devise augmentations that yield positive contrastive examples with suitable spectral properties for downstream tasks. Additionally, we reweight the significance of negative examples in the contrastive loss, considering the similarity of their Hodge components to the anchor. By encouraging a stronger separation among less similar instances, we obtain an embedding space that reflects the spectral properties of the data. The numerical results on two standard edge flow classification tasks show a superior performance even when compared to supervised learning techniques. Our findings underscore the importance of adopting a spectral perspective for contrastive learning with higher-order data.
</details>
<details>
<summary>摘要</summary>
高等结构数据模型化方面， simplicial complexes 表现出效果，如数据定义于网络边缘或其他更高级结构中。它们的谱可以通过欧拉解 composite 分解成三个可解释的子空间，从而在各种应用中发挥重要作用。我们利用这种解构来开发一种自适应学习方法，用于处理 simplicial 数据并生成具有特定spectral信息的嵌入。Specifically, we 使用 simplicial 神经网络编码 pertinent 数据不变性，并设计了可提高positive contrastive例子的权重的扩充。我们通过鼓励负例的 Hodge 组件与锚点之间的相似性来重新调整负例的权重。这种方法可以使得负例中的谱信息更加稳定，从而提高 embedding 空间的可靠性。我们在两个标准的边流分类任务上进行了数值研究，结果表明我们的方法在比supervised learning 技术更高效。我们的发现表明在处理更高级数据时，采用spectral perspective 的contrastive learning方法是非常重要的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/cs.AI_2023_09_14/" data-id="clohum93k0044pj88fh2v78fy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/cs.CL_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T11:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/cs.CL_2023_09_14/">cs.CL - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Connecting-the-Dots-in-News-Analysis-A-Cross-Disciplinary-Survey-of-Media-Bias-and-Framing"><a href="#Connecting-the-Dots-in-News-Analysis-A-Cross-Disciplinary-Survey-of-Media-Bias-and-Framing" class="headerlink" title="Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of Media Bias and Framing"></a>Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of Media Bias and Framing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08069">http://arxiv.org/abs/2309.08069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gisela Vallejo, Timothy Baldwin, Lea Frermann</li>
<li>for: 本研究旨在探讨新闻报道中的偏见现象，以及这种偏见对社会的影响。</li>
<li>methods: 本研究使用社会科学方法和NLP技术，对媒体偏见的影响进行分析和评估。</li>
<li>results: 本研究发现，现有的NLP方法在检测媒体偏见方面存在一些缺陷和局限性，需要更多的研究来解决这些问题。<details>
<summary>Abstract</summary>
The manifestation and effect of bias in news reporting have been central topics in the social sciences for decades, and have received increasing attention in the NLP community recently. While NLP can help to scale up analyses or contribute automatic procedures to investigate the impact of biased news in society, we argue that methodologies that are currently dominant fall short of addressing the complex questions and effects addressed in theoretical media studies. In this survey paper, we review social science approaches and draw a comparison with typical task formulations, methods, and evaluation metrics used in the analysis of media bias in NLP. We discuss open questions and suggest possible directions to close identified gaps between theory and predictive models, and their evaluation. These include model transparency, considering document-external information, and cross-document reasoning rather than single-label assignment.
</details>
<details>
<summary>摘要</summary>
新闻报导中的偏见的表现和影响在社会科学领域已经是长期的研究主题，近年来在自然语言处理领域也得到了更多的关注。虽然NLTP可以帮助扩大分析或提供自动化的过程来研究偏见新闻对社会的影响，但我们认为现有的方法ologies fall short of addressing the complex questions and effects addressed in theoretical media studies。在这篇评论稿中，我们回顾社会科学的方法和从Typical task formulations, methods, and evaluation metrics used in media bias analysis in NLP中着重比较。我们讨论的开Question和建议可能的方向来填充已知的漏洞，包括模型透明度、考虑外部文档信息和跨文档逻辑 reasoning而不是单一标签分配。
</details></li>
</ul>
<hr>
<h2 id="Investigating-Gender-Bias-in-News-Summarization"><a href="#Investigating-Gender-Bias-in-News-Summarization" class="headerlink" title="Investigating Gender Bias in News Summarization"></a>Investigating Gender Bias in News Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08047">http://arxiv.org/abs/2309.08047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julius Steen, Katja Markert</li>
<li>For: The paper is written to investigate the presence of harmful social biases in language models (LLMs) and their impact on summarization models.* Methods: The paper introduces several definitions for biased behaviors in summarization models and proposes a method to generate input documents with controlled demographic attributes to sidestep the issue of biases inherent in the input document.* Results: The paper finds that content selection in single document summarization is largely unaffected by bias, while hallucinations exhibit evidence of biases propagating to generated summaries.Here is the information in Simplified Chinese text:</li>
<li>for: 本文是为了研究 LLM 中的危险社会偏见，以及它们对摘要模型的影响。</li>
<li>methods: 本文提出了一些定义偏见行为的方法，并提议使用控制性的人口特征生成输入文档，以避免输入文档中的偏见问题。</li>
<li>results: 本文发现，单文档摘要的内容选择几乎不受偏见影响，而插入式偏见则在生成摘要中存在证据。<details>
<summary>Abstract</summary>
Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their performance in content selection, grammaticality and coherence. However, it is well known that LLMs reproduce and reinforce harmful social biases. This raises the question: Do these biases affect model outputs in a relatively constrained setting like summarization?   To help answer this question, we first motivate and introduce a number of definitions for biased behaviours in summarization models, along with practical measures to quantify them. Since we find biases inherent to the input document can confound our analysis, we additionally propose a method to generate input documents with carefully controlled demographic attributes. This allows us to sidestep this issue, while still working with somewhat realistic input documents.   Finally, we apply our measures to summaries generated by both purpose-built summarization models and general purpose chat models. We find that content selection in single document summarization seems to be largely unaffected by bias, while hallucinations exhibit evidence of biases propagating to generated summaries.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用大型语言模型（LLM）进行概要是一项重要应用。大多数之前的评估概要模型的研究都集中在内容选择、 grammaticality 和 coherence 等方面。然而， LLM 会重复和加强社会偏见。这引起了问题：这些偏见会影响模型输出在狭义 Setting 中吗？  为回答这个问题，我们首先介绍了概要模型中偏见行为的定义，以及实际量化这些偏见的方法。由于输入文档中的偏见可能会混淆我们的分析，我们还提出了一种方法来生成具有控制的人口特征的输入文档。这样，我们可以 circumvent 这个问题，而仍然可以使用一些具有实际感的输入文档。  最后，我们应用我们的度量方法来评估概要模型生成的概要。我们发现，单文档概要选择显然不受偏见影响，而 hallucinations 中的偏见则会传递到生成的概要中。
</details></li>
</ul>
<hr>
<h2 id="AV2Wav-Diffusion-Based-Re-synthesis-from-Continuous-Self-supervised-Features-for-Audio-Visual-Speech-Enhancement"><a href="#AV2Wav-Diffusion-Based-Re-synthesis-from-Continuous-Self-supervised-Features-for-Audio-Visual-Speech-Enhancement" class="headerlink" title="AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement"></a>AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08030">http://arxiv.org/abs/2309.08030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ju-Chieh Chou, Chung-Ming Chien, Karen Livescu</li>
<li>for: 本研究旨在提高audio-visual speech enhancement（AVSE）的性能，因为现实世界中的训练数据不具备净语音数据，从而降低了AVSE的研发难度。</li>
<li>methods: 本文提出了一种基于散射模型的AVSE方法，使用神经质量估计器从audio-visual dataset中提取了一个较好的净语音子集，然后使用这些子集训练散射模型，使其能够生成conditioned on continuous speech representations from AV-HuBERT的waveforms。</li>
<li>results: 研究表明，使用连续语音表示（continous speech representation）可以保留语速和发音信息，并且与masking-based基线相比，本方法的自适应性和净语音评价都有所提高。此外，通过细化散射模型，可以进一步提高AVSE的性能。<details>
<summary>Abstract</summary>
Speech enhancement systems are typically trained using pairs of clean and noisy speech. In audio-visual speech enhancement (AVSE), there is not as much ground-truth clean data available; most audio-visual datasets are collected in real-world environments with background noise and reverberation, hampering the development of AVSE. In this work, we introduce AV2Wav, a resynthesis-based audio-visual speech enhancement approach that can generate clean speech despite the challenges of real-world training data. We obtain a subset of nearly clean speech from an audio-visual corpus using a neural quality estimator, and then train a diffusion model on this subset to generate waveforms conditioned on continuous speech representations from AV-HuBERT with noise-robust training. We use continuous rather than discrete representations to retain prosody and speaker information. With this vocoding task alone, the model can perform speech enhancement better than a masking-based baseline. We further fine-tune the diffusion model on clean/noisy utterance pairs to improve the performance. Our approach outperforms a masking-based baseline in terms of both automatic metrics and a human listening test and is close in quality to the target speech in the listening test. Audio samples can be found at https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html.
</details>
<details>
<summary>摘要</summary>
听音提升系统通常通过干净和噪声的对照来训练。在音频视频听音提升（AVSE）中， however， there is not as much ground-truth clean data available; most audio-visual datasets are collected in real-world environments with background noise and reverberation, which makes the development of AVSE more challenging. In this work, we introduce AV2Wav, a resynthesis-based audio-visual speech enhancement approach that can generate clean speech despite the challenges of real-world training data. We use a neural quality estimator to obtain a subset of nearly clean speech from an audio-visual corpus, and then train a diffusion model on this subset to generate waveforms conditioned on continuous speech representations from AV-HuBERT with noise-robust training. We use continuous rather than discrete representations to retain prosody and speaker information. With this vocoding task alone, the model can perform speech enhancement better than a masking-based baseline. We further fine-tune the diffusion model on clean/noisy utterance pairs to improve the performance. Our approach outperforms a masking-based baseline in terms of both automatic metrics and a human listening test and is close in quality to the target speech in the listening test. Audio samples can be found at [https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html](https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html).
</details></li>
</ul>
<hr>
<h2 id="DiariST-Streaming-Speech-Translation-with-Speaker-Diarization"><a href="#DiariST-Streaming-Speech-Translation-with-Speaker-Diarization" class="headerlink" title="DiariST: Streaming Speech Translation with Speaker Diarization"></a>DiariST: Streaming Speech Translation with Speaker Diarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08007">http://arxiv.org/abs/2309.08007</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mu-y/diarist">https://github.com/mu-y/diarist</a></li>
<li>paper_authors: Mu Yang, Naoyuki Kanda, Xiaofei Wang, Junkun Chen, Peidong Wang, Jian Xue, Jinyu Li, Takuya Yoshioka</li>
<li>for: 这个论文主要目的是提出一种批处理 streaming speech translation 和 speaker diarization 的方法。</li>
<li>methods: 这个方法基于神经网络抽象器，并使用 token-level 序列化输出训练和 t-vector，以提高 streaming ST 和 SD 性能。</li>
<li>results: 对于 DiariST 系统，我们在对 AliMeeting 数据集进行了评估，并提出了一些新的评价指标，如 speaker-agnostic BLEU 和 speaker-attributed BLEU，以衡量 ST 质量和 SD 精度。我们的系统在对 overlap 的情况下进行了流式推理，并与 offline 系统基于 Whisper 进行了比较。<details>
<summary>Abstract</summary>
End-to-end speech translation (ST) for conversation recordings involves several under-explored challenges such as speaker diarization (SD) without accurate word time stamps and handling of overlapping speech in a streaming fashion. In this work, we propose DiariST, the first streaming ST and SD solution. It is built upon a neural transducer-based streaming ST system and integrates token-level serialized output training and t-vector, which were originally developed for multi-talker speech recognition. Due to the absence of evaluation benchmarks in this area, we develop a new evaluation dataset, DiariST-AliMeeting, by translating the reference Chinese transcriptions of the AliMeeting corpus into English. We also propose new metrics, called speaker-agnostic BLEU and speaker-attributed BLEU, to measure the ST quality while taking SD accuracy into account. Our system achieves a strong ST and SD capability compared to offline systems based on Whisper, while performing streaming inference for overlapping speech. To facilitate the research in this new direction, we release the evaluation data, the offline baseline systems, and the evaluation code.
</details>
<details>
<summary>摘要</summary>
听写末端到听写的speech翻译（ST）在对话录音中存在许多未经探索的挑战，如 speaker化（SD）无法准确地获取单词时间戳和对另一个人的语音进行流式处理。在这项工作中，我们提出了DiariST，第一个流式ST和SD解决方案。它基于神经网络抽象器基于流式ST系统，并 интегриру了token级别的序列化输出训练和t-vector，这些原始是为多个说话人的语音识别所开发。由于这个领域没有评估指标，我们开发了一个新的评估数据集，DiariST-AliMeeting，通过翻译中文笔录 AliMeeting 资料集的参考转录为英语。我们还提出了一些新的度量方法，称为 speaker-agnostic BLEU 和 speaker-attributed BLEU，以衡量 ST 质量并考虑 SD 精度。我们的系统在与 Whisper 的离线系统进行比较后，在流式推理中处理重叠的语音时达到了强大的 ST 和 SD 能力。为便于这个新方向的研究，我们发布了评估数据、离线基准系统和评估代码。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Impact-of-Human-Evaluator-Group-on-Chat-Oriented-Dialogue-Evaluation"><a href="#Exploring-the-Impact-of-Human-Evaluator-Group-on-Chat-Oriented-Dialogue-Evaluation" class="headerlink" title="Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation"></a>Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07998">http://arxiv.org/abs/2309.07998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarah E. Finch, James D. Finch, Jinho D. Choi</li>
<li>for: 这篇论文主要是为了检验对话系统的评估方法。</li>
<li>methods: 这篇论文使用了4个不同的评估者组来评估4种现状的对话系统，并分析了评估者组的影响。</li>
<li>results: 研究发现，对于 likert 评估，评估者组的影响不大，但是有些特定的对话指标存在评估者差异。此外，研究还发现了一些限制这种 Robustness，包括评估者对对话机器人专业程度的差异和评估者对对话指标的主观性。<details>
<summary>Abstract</summary>
Human evaluation has been widely accepted as the standard for evaluating chat-oriented dialogue systems. However, there is a significant variation in previous work regarding who gets recruited as evaluators. Evaluator groups such as domain experts, university students, and professional annotators have been used to assess and compare dialogue systems, although it is unclear to what extent the choice of an evaluator group can affect results. This paper analyzes the evaluator group impact on dialogue system evaluation by testing 4 state-of-the-art dialogue systems using 4 distinct evaluator groups. Our analysis reveals a robustness towards evaluator groups for Likert evaluations that is not seen for Pairwise, with only minor differences observed when changing evaluator groups. Furthermore, two notable limitations to this robustness are observed, which reveal discrepancies between evaluators with different levels of chatbot expertise and indicate that evaluator objectivity is beneficial for certain dialogue metrics.
</details>
<details>
<summary>摘要</summary>
人工评估已被广泛接受为对话系统评估的标准。然而，以前的工作中选择评估人员的方法存在显著的差异。各种评估者组，如领域专家、大学学生和职业标注人员，已经用来评估和比较对话系统，却不清楚这些选择对结果的影响。这篇文章分析对话系统评估中评估者组的影响，通过使用4种当前最佳对话系统和4个不同的评估者组进行测试。我们的分析发现，对于 likert 评估，评估者组对对话系统的影响相对较强，但对于 pairwise 评估，只有小范围内的差异被观察到。此外，我们还发现了两点有关这种Robustness的限制性，一是评估人员对对话系统的专业程度的差异，二是评估人员对某些对话指标的客观性的影响。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Contextual-Information-for-Effective-Entity-Salience-Detection"><a href="#Leveraging-Contextual-Information-for-Effective-Entity-Salience-Detection" class="headerlink" title="Leveraging Contextual Information for Effective Entity Salience Detection"></a>Leveraging Contextual Information for Effective Entity Salience Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07990">http://arxiv.org/abs/2309.07990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajarshi Bhowmik, Marco Ponza, Atharva Tendle, Anant Gupta, Rebecca Jiang, Xingyu Lu, Qian Zhao, Daniel Preotiuc-Pietro</li>
<li>for: 本研究旨在检测文档中突出的实体，以便提高搜索、排名和实体中心概要等下游应用的性能。</li>
<li>methods: 本研究使用了中等规模的自然语言处理模型，并采用了cross-encoder风格的 architecture，以提高performance。</li>
<li>results: 研究发现，通过 fine-tuning 中等规模的预训练语言模型，可以获得substantial performance gain，而 feature engineering 方法则无法达到这个目标。<details>
<summary>Abstract</summary>
In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection mainly focused on machine learning models that require heavy feature engineering. We show that fine-tuning medium-sized language models with a cross-encoder style architecture yields substantial performance gains over feature engineering approaches. To this end, we conduct a comprehensive benchmarking of four publicly available datasets using models representative of the medium-sized pre-trained language model family. Additionally, we show that zero-shot prompting of instruction-tuned language models yields inferior results, indicating the task's uniqueness and complexity.
</details>
<details>
<summary>摘要</summary>
文档中的内容和关键事件通常涉及一 subset of 所有提到的实体。这些实体，经常被称为突出的实体，对文档的关键信息提供有用的提示。识别突出实体的存在有助于多个下游应用程序，如搜索、排名和实体中心摘要等。现有的突出实体检测主要基于机器学习模型，需要大量的特征工程。我们显示，将中型语言模型进行精度调整可以得到显著性能提升。为此，我们对公共可用的四个数据集进行了广泛的 benchmarking，并显示了代表中型预训练语言模型家族的模型的性能。此外，我们还示出了零样本提示的语言模型训练结果为 inferior，表明任务的独特性和复杂性。
</details></li>
</ul>
<hr>
<h2 id="Ambiguity-Aware-In-Context-Learning-with-Large-Language-Models"><a href="#Ambiguity-Aware-In-Context-Learning-with-Large-Language-Models" class="headerlink" title="Ambiguity-Aware In-Context Learning with Large Language Models"></a>Ambiguity-Aware In-Context Learning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07900">http://arxiv.org/abs/2309.07900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingyu Gao, Aditi Chaudhary, Krishna Srinivasan, Kazuma Hashimoto, Karthik Raman, Michael Bendersky</li>
<li>for: 本研究希望通过几个任务特定示例来提高大型语言模型（LLM）的下游性能，但是选择好示例是一个关键问题。</li>
<li>methods: 研究人员使用文本检索器来选择Semantic similarity between ICL demonstrations and test inputs，但这并不考虑LLM对这个任务的已有知识。</li>
<li>results: 通过对三个文本分类任务进行广泛的实验，研究人员发现，不仅选择semantic similarity的ICL示例，还需要选择能够解决测试示例周围的自然标签抖抖的示例，可以得到最大性能提升。<details>
<summary>Abstract</summary>
In-context learning (ICL) i.e. showing LLMs only a few task-specific demonstrations has led to downstream gains with no task-specific fine-tuning required. However, LLMs are sensitive to the choice of prompts, and therefore a crucial research question is how to select good demonstrations for ICL. One effective strategy is leveraging semantic similarity between the ICL demonstrations and test inputs by using a text retriever, which however is sub-optimal as that does not consider the LLM's existing knowledge about that task. From prior work (Min et al., 2022), we already know that labels paired with the demonstrations bias the model predictions. This leads us to our hypothesis whether considering LLM's existing knowledge about the task, especially with respect to the output label space can help in a better demonstration selection strategy. Through extensive experimentation on three text classification tasks, we find that it is beneficial to not only choose semantically similar ICL demonstrations but also to choose those demonstrations that help resolve the inherent label ambiguity surrounding the test example. Interestingly, we find that including demonstrations that the LLM previously mis-classified and also fall on the test example's decision boundary, brings the most performance gain.
</details>
<details>
<summary>摘要</summary>
具体学习（ICL），即只显示一些任务特定示例，已经导致下游成果，无需任务特定微调。然而，LLM很敏感于选择示例的选择，因此一个重要的研究问题是如何选择好的示例 дляICL。一种有效的策略是利用示例和测试输入之间的semantic similarity，使用文本检索器。然而，这种方法并不理想，因为它不考虑LLM对该任务的已有知识。根据之前的研究（Min et al., 2022），我们已知标签与示例的匹配会偏导模型预测。这导我们到我们的假设，那么考虑LLM对该任务的已有知识，特别是输出标签空间中的知识，可以帮助实现更好的示例选择策略。通过对三个文本分类任务进行了广泛的实验，我们发现，不仅选择semantic similar的ICL示例，还要选择能够解决测试示例上的自然标签抖障的示例，能够带来最大的性能提升。 Interestingly，包括LLM之前错分的示例和测试示例的决策边缘示例，可以带来最大的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Anchor-Points-Benchmarking-Models-with-Much-Fewer-Examples"><a href="#Anchor-Points-Benchmarking-Models-with-Much-Fewer-Examples" class="headerlink" title="Anchor Points: Benchmarking Models with Much Fewer Examples"></a>Anchor Points: Benchmarking Models with Much Fewer Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08638">http://arxiv.org/abs/2309.08638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rvivek3/anchorpoints">https://github.com/rvivek3/anchorpoints</a></li>
<li>paper_authors: Rajan Vivek, Kawin Ethayarajh, Diyi Yang, Douwe Kiela</li>
<li>for: 本文旨在探讨如何使用小型评估集来评估语言模型的表现。</li>
<li>methods: 作者提出了一种名为”Anchor Point Selection”的技术，可以选择小型数据集来评估模型的表现。</li>
<li>results: 作者表明，使用 anchor points 可以准确地评估语言模型的表现，并且只需要使用几个 anchor points 可以估算模型在整个数据集中的表现。<details>
<summary>Abstract</summary>
Modern language models often exhibit powerful but brittle behavior, leading to the development of larger and more diverse benchmarks to reliably assess their behavior. Here, we suggest that model performance can be benchmarked and elucidated with much smaller evaluation sets. We first show that in six popular language classification benchmarks, model confidence in the correct class on many pairs of points is strongly correlated across models. We build upon this phenomenon to propose Anchor Point Selection, a technique to select small subsets of datasets that capture model behavior across the entire dataset. Anchor points reliably rank models: across 87 diverse language model-prompt pairs, evaluating models using 1-30 anchor points outperforms uniform sampling and other baselines at accurately ranking models. Moreover, just several anchor points can be used to estimate model per-class predictions on all other points in a dataset with low mean absolute error, sufficient for gauging where the model is likely to fail. Lastly, we present Anchor Point Maps for visualizing these insights and facilitating comparisons of the performance of different models on various regions within the dataset distribution.
</details>
<details>
<summary>摘要</summary>
现代语言模型经常表现出强大 pero 脆弱的行为，导致开发更大和多样化的测试集来可靠地评估其行为。在这里，我们建议可以使用 much smaller evaluation sets 来评估模型性能。我们首先发现，在六个流行的语言分类标准测试集中，模型对正确类别的信任度在许多对点对是强相关的。我们基于这一现象提出了 Anchor Point Selection，一种技术来选择数据集中的小集合，以捕捉模型在整个数据集中的行为。 anchor points 可靠地排名模型：在 87 种语言模型-提示对的测试集中，使用 1-30 anchor points 来评估模型，比 uniform sampling 和其他基elines 更高效地准确地排名模型。此外，只需几个 anchor points 可以用来估算模型每个类别预测值的所有其他点在数据集中的低均绝对误差，足够用于评估模型在哪些点上可能会失败。最后，我们提出了 Anchor Point Maps，用于可见地表示这些 Insights 并且方便对不同模型在不同区域内数据集分布中的性能进行比较。
</details></li>
</ul>
<hr>
<h2 id="Safety-Tuned-LLaMAs-Lessons-From-Improving-the-Safety-of-Large-Language-Models-that-Follow-Instructions"><a href="#Safety-Tuned-LLaMAs-Lessons-From-Improving-the-Safety-of-Large-Language-Models-that-Follow-Instructions" class="headerlink" title="Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"></a>Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07875">http://arxiv.org/abs/2309.07875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vinid/instruction-llms-safety-eval">https://github.com/vinid/instruction-llms-safety-eval</a></li>
<li>paper_authors: Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul Röttger, Dan Jurafsky, Tatsunori Hashimoto, James Zou</li>
<li>for: 这个论文探讨了大语言模型是否只专注于帮助性能而忽视安全性的问题。</li>
<li>methods: 作者使用了多种实验方法来评估大语言模型的帮助性和安全性。</li>
<li>results: 研究发现，许多流行的指令调整模型具有高度的危险性，而在训练集中添加3%的安全示例可以提高模型的安全性，但是过度的安全调整可能会使模型拒绝合理的提示。<details>
<summary>Abstract</summary>
Training large language models to follow instructions makes them perform better on a wide range of tasks, generally becoming more helpful. However, a perfectly helpful model will follow even the most malicious instructions and readily generate harmful content. In this paper, we raise concerns over the safety of models that only emphasize helpfulness, not safety, in their instruction-tuning. We show that several popular instruction-tuned models are highly unsafe. Moreover, we show that adding just 3% safety examples (a few hundred demonstrations) in the training set when fine-tuning a model like LLaMA can substantially improve their safety. Our safety-tuning does not make models significantly less capable or helpful as measured by standard benchmarks. However, we do find a behavior of exaggerated safety, where too much safety-tuning makes models refuse to respond to reasonable prompts that superficially resemble unsafe ones. Our study sheds light on trade-offs in training LLMs to follow instructions and exhibit safe behavior.
</details>
<details>
<summary>摘要</summary>
培训大型自然语言模型遵循 instrucion 可以使其在各种任务上表现更好，通常变得更有用。然而，一个完全有用的模型会遵循任何有恶意 instrucion 并快速生成有害内容。在这篇论文中，我们表达对模型仅强调有用性，不强调安全性的担忧。我们发现了许多流行的 instrucion-tuned 模型具有高度不安全的问题。此外，我们发现，在 fine-tuning 一个模型如 LLMA 时，只需添加一些安全示例（几百个示例）可以大幅提高其安全性。我们的安全调整不会使模型变得显著不 capable 或不有用，如按照标准标准准则测试。然而，我们发现了一种安全偏见行为，即在安全调整过后，模型会拒绝处理有些安全提示，它们superficially resemble unsafe prompts。我们的研究揭示了培训 LLMs 遵循 instrucion 和表现安全行为之间的负担。
</details></li>
</ul>
<hr>
<h2 id="Agents-An-Open-source-Framework-for-Autonomous-Language-Agents"><a href="#Agents-An-Open-source-Framework-for-Autonomous-Language-Agents" class="headerlink" title="Agents: An Open-source Framework for Autonomous Language Agents"></a>Agents: An Open-source Framework for Autonomous Language Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07870">http://arxiv.org/abs/2309.07870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aiwaves-cn/agents">https://github.com/aiwaves-cn/agents</a></li>
<li>paper_authors: Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, Mrinmaya Sachan</li>
<li>for: 这篇论文旨在探讨大型自然语言模型 (LLMs) 在语言代理方面的最新进展，并提供一个开源库 Agents，以便非专家可以轻松地建立自然语言界面上的自动解决问题和与环境、人类和其他代理进行交互。</li>
<li>methods: 这篇论文使用了大型自然语言模型 (LLMs)，并提供了一个开源库 Agents，以便非专家可以轻松地使用这些模型来建立自然语言界面上的自动解决问题和与环境、人类和其他代理进行交互。</li>
<li>results: 这篇论文提供了一个开源库 Agents，可以帮助非专家轻松地建立自然语言界面上的自动解决问题和与环境、人类和其他代理进行交互，并且可以支持规划、记忆、工具使用、多代理交流和细致的符号控制等重要特性。<details>
<summary>Abstract</summary>
Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces. We consider language agents as a promising direction towards artificial general intelligence and release Agents, an open-source library with the goal of opening up these advances to a wider non-specialist audience. Agents is carefully engineered to support important features including planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control. Agents is user-friendly as it enables non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents without much coding. The library is also research-friendly as its modularized design makes it easily extensible for researchers. Agents is available at https://github.com/aiwaves-cn/agents.
</details>
<details>
<summary>摘要</summary>
Agents is carefully engineered to support important features such as planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control. The library is user-friendly, allowing non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents with minimal coding. Additionally, the modularized design of Agents makes it easily extensible for researchers.Agents is available at the following link: <https://github.com/aiwaves-cn/agents>.
</details></li>
</ul>
<hr>
<h2 id="CATfOOD-Counterfactual-Augmented-Training-for-Improving-Out-of-Domain-Performance-and-Calibration"><a href="#CATfOOD-Counterfactual-Augmented-Training-for-Improving-Out-of-Domain-Performance-and-Calibration" class="headerlink" title="CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration"></a>CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07822">http://arxiv.org/abs/2309.07822</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/catfood">https://github.com/ukplab/catfood</a></li>
<li>paper_authors: Rachneet Sachdeva, Martin Tutek, Iryna Gurevych</li>
<li>for: 增强小语言模型（SLMs）在不同预测任务中的表现，特别是在生成文本的任务中。</li>
<li>methods: 使用大语言模型（LLMs）生成自动生成的对话实例（CF），以增强小语言模型在不同预测任务中的表现。</li>
<li>results: 通过多种LLM生成器，对CF实例进行数据增强后，可以提高小语言模型在不同预测任务中的表现，并且可以改善模型的准确性和排序能力。<details>
<summary>Abstract</summary>
In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations.
</details>
<details>
<summary>摘要</summary>
Recently, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations.Here's the translation in Traditional Chinese:过去的年份，大语言模型（LLM）在大规模下显示了杰出的能力，特别是在基于提示的文本生成。在我们的工作中，我们 investigate 使用 LLM 对小语言模型（SLM）的训练数据进行增强，以增强 OOD 性能。我们发现，各种 LLM 生成器都可以对 SLM 的 OOD 性能进行增强，并且可以改善模型的准确性。此外，这些性能改善与 CF 实例的多样性有很高的相关性，包括表面形式和 semantic 内容。最后，我们发现，可以轻松对 CF 实例进行混合的模型也会表现出较低的 entropy，这表明了 rational 扩展的准确性。
</details></li>
</ul>
<hr>
<h2 id="Text-Classification-of-Cancer-Clinical-Trial-Eligibility-Criteria"><a href="#Text-Classification-of-Cancer-Clinical-Trial-Eligibility-Criteria" class="headerlink" title="Text Classification of Cancer Clinical Trial Eligibility Criteria"></a>Text Classification of Cancer Clinical Trial Eligibility Criteria</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07812">http://arxiv.org/abs/2309.07812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yumeng Yang, Soumya Jayaraj, Ethan B Ludmir, Kirk Roberts</li>
<li>for: 本研究旨在解决许多临床试验中的患者参与问题，因为参与条件通常表示为自然语言。</li>
<li>methods: 本研究使用文本分类方法来处理常见排除条件。</li>
<li>results: 我们的结果表明可以自动确定临床试验患者参与条件的可能性。此外，我们还发现一个专门为临床试验预先训练的语言模型可以为临床试验提供最高的平均性能。<details>
<summary>Abstract</summary>
Automatic identification of clinical trials for which a patient is eligible is complicated by the fact that trial eligibility is stated in natural language. A potential solution to this problem is to employ text classification methods for common types of eligibility criteria. In this study, we focus on seven common exclusion criteria in cancer trials: prior malignancy, human immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness, drug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase III cancer trials with these exclusions annotated at the trial level. We experiment with common transformer models as well as a new pre-trained clinical trial BERT model. Our results demonstrate the feasibility of automatically classifying common exclusion criteria. Additionally, we demonstrate the value of a pre-trained language model specifically for clinical trials, which yields the highest average performance across all criteria.
</details>
<details>
<summary>摘要</summary>
自动确定临床试验中患者是否符合参与条件是由于参与条件表示在自然语言中，这种问题的解决方案之一是使用文本分类方法来处理常见的参与条件。在本研究中，我们关注了7种常见排除条件在肿瘤试验中：先前的肿瘤、人类免疫缺陷病毒、乙型肝炎、丙型肝炎、心理疾病、药物/化学成瘾和自体免疫疾病。我们的数据集包括764个相关III肿瘤试验，这些排除条件在试验水平进行了标注。我们对常见变换器模型以及一个新的临床试验BERT模型进行实验。我们的结果表明自动分类常见排除条件的可能性，而且还表明特制的临床试验BERT模型在所有标准的参与条件上的平均性能最高。
</details></li>
</ul>
<hr>
<h2 id="Pop-Quiz-Do-Pre-trained-Code-Models-Possess-Knowledge-of-Correct-API-Names"><a href="#Pop-Quiz-Do-Pre-trained-Code-Models-Possess-Knowledge-of-Correct-API-Names" class="headerlink" title="Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API Names?"></a>Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API Names?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07804">http://arxiv.org/abs/2309.07804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Terry Yue Zhuo, Xiaoning Du, Zhenchang Xing, Jiamou Sun, Haowei Quan, Li Li, Liming Zhu</li>
<li>for: 本研究的目的是探讨现有的预训练代码模型在自动化API使用方面的表现，以及如何提高代码智能实践中的代码表示和自动化API使用。</li>
<li>methods: 本研究使用了知识探测技术，通过cloze-style测试来评估模型内存储的知识。研究从两个不同的角度探讨了预训练代码模型对 Fully Qualified Names (FQNs) 的理解能力，包括API调用和API导入。</li>
<li>results: 研究发现，当前的预训练代码模型在理解FQNs方面存在困难，尤其是在预训练策略方面对API名称学习产生了显著的影响。研究还发现，自然语言上下文可以帮助代码模型在找到Python API名称方面做出更好的表现，并且可以将Python API名称知识推广到未见数据上。这些发现为代码智能实践提供了指导和方向，并建议将API结构纳入预训练过程以提高自动化API使用和代码表示。<details>
<summary>Abstract</summary>
Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex, have shown their superior performance in various downstream tasks. The correctness and unambiguity of API usage among these code models are crucial for achieving desirable program functionalities, requiring them to learn various API fully qualified names structurally and semantically. Recent studies reveal that even state-of-the-art pre-trained code models struggle with suggesting the correct APIs during code generation. However, the reasons for such poor API usage performance are barely investigated. To address this challenge, we propose using knowledge probing as a means of interpreting code models, which uses cloze-style tests to measure the knowledge stored in models. Our comprehensive study examines a code model's capability of understanding API fully qualified names from two different perspectives: API call and API import. Specifically, we reveal that current code models struggle with understanding API names, with pre-training strategies significantly affecting the quality of API name learning. We demonstrate that natural language context can assist code models in locating Python API names and generalize Python API name knowledge to unseen data. Our findings provide insights into the limitations and capabilities of current pre-trained code models, and suggest that incorporating API structure into the pre-training process can improve automated API usage and code representations. This work provides significance for advancing code intelligence practices and direction for future studies. All experiment results, data and source code used in this work are available at \url{https://doi.org/10.5281/zenodo.7902072}.
</details>
<details>
<summary>摘要</summary>
近期的预训CodeBERT和Codex等模型已经显示了在不同的下游任务中的优秀性能。在这些代码模型中，正确和不ambiguous的API使用是达到愉悦的程序功能的关键，它们需要学习不同的API完全限定名称的结构和含义。然而，当代领先的预训代码模型在代码生成时间建议正确的API时会遇到困难。然而，这些原因几乎未经调查。为解决这个挑战，我们提议使用知识探测来解释代码模型，该方法使用cloze-style测试来测量模型中的知识。我们的全面研究检查了代码模型理解API完全限定名称的两个不同的角度：API调用和API导入。我们发现，当前的代码模型在理解API名称方面存在困难，而预训策略对API名称学习质量产生了显著影响。我们还发现，自然语言上下文可以帮助代码模型在Python API名称上进行定位，并且可以将Python API名称知识扩展到未看到的数据上。我们的发现提供了预训代码模型的局限性和能力，并建议将API结构纳入预训过程以提高自动API使用和代码表示。这项工作提供了代码智能实践的进步和未来研究的指导。所有实验结果、数据和源代码在\url{https://doi.org/10.5281/zenodo.7902072}上可以获得。
</details></li>
</ul>
<hr>
<h2 id="The-Dynamical-Principles-of-Storytelling"><a href="#The-Dynamical-Principles-of-Storytelling" class="headerlink" title="The Dynamical Principles of Storytelling"></a>The Dynamical Principles of Storytelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07797">http://arxiv.org/abs/2309.07797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isidoros Doxas, James Meiss, Steven Bottone, Tom Strelich, Andrew Plummer, Adrienne Breland, Simon Dennis, Kathy Garvin-Doxas, Michael Klymkowsky</li>
<li>for: 研究开头1800篇短篇小说的起始部分，发现大多数篇章遵循行动原理，如arXiv:2309.06600所定义。</li>
<li>methods: 研究者使用了混淆序列的方法，检查开头篇章的顺序对故事的semantic空间的影响。</li>
<li>results: 结果表明，在启动故事时，我们倾向于采取一定的方向在semantic空间中，可能与西方故事传统有关，如阿里斯多德在《诗学》中所暗示的。<details>
<summary>Abstract</summary>
When considering the opening part of 1800 short stories, we find that the first dozen paragraphs of the average narrative follow an action principle as defined in arXiv:2309.06600. When the order of the paragraphs is shuffled, the average no longer exhibits this property. The findings show that there is a preferential direction we take in semantic space when starting a story, possibly related to a common Western storytelling tradition as implied by Aristotle in Poetics.
</details>
<details>
<summary>摘要</summary>
（考虑1800短篇故事的开头部分，我们发现平均的 Narraative 的前 dozen 段落遵循 arXiv:2309.06600 中定义的行动原则。当排序段落的顺序时，平均不再显示这种性质。发现在 semantic space 中开始故事时，有一个偏好的方向，可能与西方故事创作传统相关，如阿里斯托丰提到在《诗学》中。）
</details></li>
</ul>
<hr>
<h2 id="Improving-Multimodal-Classification-of-Social-Media-Posts-by-Leveraging-Image-Text-Auxiliary-tasks"><a href="#Improving-Multimodal-Classification-of-Social-Media-Posts-by-Leveraging-Image-Text-Auxiliary-tasks" class="headerlink" title="Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks"></a>Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07794">http://arxiv.org/abs/2309.07794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danae Sánchez Villegas, Daniel Preoţiuc-Pietro, Nikolaos Aletras</li>
<li>for: 本研究旨在提高社交媒体文章中的多Modal信息利用，以便进行各种下游任务，如情感分析、讽刺检测和仇恨言语分类。</li>
<li>methods: 本文提议在微博模型 fine-tuning 过程中使用两个辅助任务：图像文本对比（ITC）和图像文本匹配（ITM），以直接模型图像文本之间的相互关系。</li>
<li>results: 通过对五种多Modal模型进行组合，本研究在四个社交媒体数据集上表现出了一致性的提高。此外，通过细化分析，我们发现每个辅助任务在具体情况和案例中的效果最为显著。<details>
<summary>Abstract</summary>
Effectively leveraging multimodal information from social media posts is essential to various downstream tasks such as sentiment analysis, sarcasm detection and hate speech classification. However, combining text and image information is challenging because of the idiosyncratic cross-modal semantics with hidden or complementary information present in matching image-text pairs. In this work, we aim to directly model this by proposing the use of two auxiliary losses jointly with the main task when fine-tuning any pre-trained multimodal model. Image-Text Contrastive (ITC) brings image-text representations of a post closer together and separates them from different posts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates the understanding of semantic correspondence between images and text by penalizing unrelated pairs. We combine these objectives with five multimodal models, demonstrating consistent improvements across four popular social media datasets. Furthermore, through detailed analysis, we shed light on the specific scenarios and cases where each auxiliary task proves to be most effective.
</details>
<details>
<summary>摘要</summary>
通过有效地利用社交媒体文章中的多Modal信息，可以提高各种下游任务，如情感分析、讲究和仇恨言语识别。但是，将文字和图像信息结合起来是一项挑战，因为它们之间存在特殊的跨Modal semantics和隐藏或补做信息。在这项工作中，我们提议使用两个辅助损失函数，一起与主任务进行调整已经预训练的任意多Modal模型。图像文本对比（ITC）使图像文本对的 representations更加相似，并将它们与不同的文本对分开，捕捉到它们之间的依赖关系。图像文本匹配（ITM）促进了图像和文本之间的含义相似性的理解，使得不相关的对进行惩罚。我们将这些目标与五种多Modal模型结合，在四个流行的社交媒体数据集上进行了详细的分析，并证明了这些辅助任务在不同的场景和情况下的效果。
</details></li>
</ul>
<hr>
<h2 id="Spoken-Humanoid-Embodied-Conversational-Agents-in-Mobile-Serious-Games-A-Usability-Assessment"><a href="#Spoken-Humanoid-Embodied-Conversational-Agents-in-Mobile-Serious-Games-A-Usability-Assessment" class="headerlink" title="Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games: A Usability Assessment"></a>Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games: A Usability Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07773">http://arxiv.org/abs/2309.07773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danai Korre, Judy Robertson</li>
<li>for: 这项研究旨在检验 spoken Humanoid Embodied Conversational Agents (HECAs) 在移动严重游戏 (MSG) 应用中是否可以提高可用性。</li>
<li>methods: 研究使用了两种代理人示例：一种高度人类化的 HECA 和一种文本示例。实验评估了多个代理人和人类化的假设对交互质量的影响。</li>
<li>results: 实验结果显示用户更偏好与 HECA 交互，两个版本之间的差异为 statistically significant 大效果大（d&#x3D;1.01），许多参与者表示人类化特征使得版本更加吸引人。这项研究为未来移动严重游戏的设计提供了重要信息。<details>
<summary>Abstract</summary>
This paper presents an empirical investigation of the extent to which spoken Humanoid Embodied Conversational Agents (HECAs) can foster usability in mobile serious game (MSG) applications. The aim of the research is to assess the impact of multiple agents and illusion of humanness on the quality of the interaction. The experiment investigates two styles of agent presentation: an agent of high human-likeness (HECA) and an agent of low human-likeness (text). The purpose of the experiment is to assess whether and how agents of high humanlikeness can evoke the illusion of humanness and affect usability. Agents of high human-likeness were designed by following the ECA design model that is a proposed guide for ECA development. The results of the experiment with 90 participants show that users prefer to interact with the HECAs. The difference between the two versions is statistically significant with a large effect size (d=1.01), with many of the participants justifying their choice by saying that the human-like characteristics of the HECA made the version more appealing. This research provides key information on the potential effect of HECAs on serious games, which can provide insight into the design of future mobile serious games.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Echotune-A-Modular-Extractor-Leveraging-the-Variable-Length-Nature-of-Speech-in-ASR-Tasks"><a href="#Echotune-A-Modular-Extractor-Leveraging-the-Variable-Length-Nature-of-Speech-in-ASR-Tasks" class="headerlink" title="Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks"></a>Echotune: A Modular Extractor Leveraging the Variable-Length Nature of Speech in ASR Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07765">http://arxiv.org/abs/2309.07765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhou Chen, Songyang Gao, Sen Fang</li>
<li>for: 这个论文的目的是提高自动语音识别（ASR）任务中的模型性能。</li>
<li>methods: 这个论文使用了变长注意力机制，以适应不同的语音样本duration和复杂度。</li>
<li>results: 根据我们的实验结果，将Echo-MSA模块 integrate到主模型的训练过程中，可以显著提高word error rate（WER）性能，同时保持原始模型的内在稳定性。<details>
<summary>Abstract</summary>
The Transformer architecture has proven to be highly effective for Automatic Speech Recognition (ASR) tasks, becoming a foundational component for a plethora of research in the domain. Historically, many approaches have leaned on fixed-length attention windows, which becomes problematic for varied speech samples in duration and complexity, leading to data over-smoothing and neglect of essential long-term connectivity. Addressing this limitation, we introduce Echo-MSA, a nimble module equipped with a variable-length attention mechanism that accommodates a range of speech sample complexities and durations. This module offers the flexibility to extract speech features across various granularities, spanning from frames and phonemes to words and discourse. The proposed design captures the variable length feature of speech and addresses the limitations of fixed-length attention. Our evaluation leverages a parallel attention architecture complemented by a dynamic gating mechanism that amalgamates traditional attention with the Echo-MSA module output. Empirical evidence from our study reveals that integrating Echo-MSA into the primary model's training regime significantly enhances the word error rate (WER) performance, all while preserving the intrinsic stability of the original model.
</details>
<details>
<summary>摘要</summary>
《Transformer架构在自动语音识别（ASR）任务中表现出非常高效，成为了这个领域的基础组件。历史上，许多方法都是采用固定长度注意窗口，这会导致不同的语音样本duration和复杂度的数据过滤和重要的长期连接被忽略。为了解决这个限制，我们介绍了Echo-MSA模块，这是一个具有可变长度注意机制的Variable-Length Attention（VLA）模块。这个模块可以捕捉不同的语音特征，从帧和音频到单词和话语等多个级别。我们的设计captures the variable length feature of speech和解决了固定长度注意的局限性。我们的评估使用了并行的注意架构和动态闭合机制，将传统注意与Echo-MSA模块输出结合。我们的实验证明，将Echo-MSA模块包含在主模型的训练过程中可以显著提高word error rate（WER）性能，同时保持原始模型的内在稳定性。》
</details></li>
</ul>
<hr>
<h2 id="PROGrasp-Pragmatic-Human-Robot-Communication-for-Object-Grasping"><a href="#PROGrasp-Pragmatic-Human-Robot-Communication-for-Object-Grasping" class="headerlink" title="PROGrasp: Pragmatic Human-Robot Communication for Object Grasping"></a>PROGrasp: Pragmatic Human-Robot Communication for Object Grasping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07759">http://arxiv.org/abs/2309.07759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gi-Cheon Kang, Junghyun Kim, Jaein Kim, Byoung-Tak Zhang</li>
<li>for: 本研究旨在提出一种新的人机共同协作任务—— Pragmatic-IOG，以及相应的数据集—— Intention-oriented Multi-modal Dialogue (IM-Dial)。</li>
<li>methods: 我们提出了一种新的机器人系统—— Pragmatic Object Grasping (PROGrasp)，该系统通过视觉固定、问答、物体抓取和答案解释等模块来解决 Pragmatic-IOG 任务。</li>
<li>results: 我们的实验结果表明，PROGrasp 在线上和离线上都能够有效地完成 Pragmatic-IOG 任务。<details>
<summary>Abstract</summary>
Interactive Object Grasping (IOG) is the task of identifying and grasping the desired object via human-robot natural language interaction. Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle). Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial). In our proposed task scenario, an intention-oriented utterance (e.g., "I am thirsty") is initially given to the robot. The robot should then identify the target object by interacting with a human user. Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference. Experimental results show that PROGrasp is effective in offline (i.e., target object discovery) and online (i.e., IOG with a physical robot arm) settings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Interactive Object Grasping (IOG) is the task of identifying and grasping the desired object via human-robot natural language interaction. Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle). Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial). In our proposed task scenario, an intention-oriented utterance (e.g., "I am thirsty") is initially given to the robot. The robot should then identify the target object by interacting with a human user. Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference. Experimental results show that PROGrasp is effective in offline (i.e., target object discovery) and online (i.e., IOG with a physical robot arm) settings."into Simplified Chinese.Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle). Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial). 在当前的IOG系统中，人类用户会首先指定目标物的类别（例如瓶子）。 drawing inspiration from pragmatics, where humans often convey their intentions by relying on context to achieve goals, we propose a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial).In our proposed task scenario, an intention-oriented utterance (e.g., "I am thirsty") is initially given to the robot. The robot should then identify the target object by interacting with a human user. Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp). PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference. 在我们的提议的任务场景中，一个意向带有的语音（例如 "我是喝喝的"）会首先被给 robot。 robot 然后应该通过与人类用户交互来确定目标物。基于任务设置，我们提议一种新的机器人系统，可以理解用户的意图，并将目标物pick up，即 Pragmatic Object Grasping (PROGrasp)。PROGrasp 实现 Pragmatic-IOG  by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference.Experimental results show that PROGrasp is effective in offline (i.e., target object discovery) and online (i.e., IOG with a physical robot arm) settings. 实验结果表明，PROGrasp 在offline（即目标物发现）和 online（即与物理机器人臂进行IOG）的设置下都是有效的。
</details></li>
</ul>
<hr>
<h2 id="The-complementary-roles-of-non-verbal-cues-for-Robust-Pronunciation-Assessment"><a href="#The-complementary-roles-of-non-verbal-cues-for-Robust-Pronunciation-Assessment" class="headerlink" title="The complementary roles of non-verbal cues for Robust Pronunciation Assessment"></a>The complementary roles of non-verbal cues for Robust Pronunciation Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07739">http://arxiv.org/abs/2309.07739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yassine El Kheir, Shammur Absar Chowdhury, Ahmed Ali</li>
<li>for: 本研究旨在评估非本地语言（L2）发音系统，拓展现有研究的 fonetic和phonological特征，同时充分利用非语言表征。</li>
<li>methods: 本研究提出了一种新的发音评估框架，IntraVerbalPA，该框架兼容细致的帧级和抽象词级非语言特征，并引入 ‘’Goodness of phonemic-duration’’ 度量来有效地模型duration分布。</li>
<li>results: 研究结果证明IntraVerbalPA框架和其组件的有效性，其性能与或超过了现有研究工作。<details>
<summary>Abstract</summary>
Research on pronunciation assessment systems focuses on utilizing phonetic and phonological aspects of non-native (L2) speech, often neglecting the rich layer of information hidden within the non-verbal cues. In this study, we proposed a novel pronunciation assessment framework, IntraVerbalPA. % The framework innovatively incorporates both fine-grained frame- and abstract utterance-level non-verbal cues, alongside the conventional speech and phoneme representations. Additionally, we introduce ''Goodness of phonemic-duration'' metric to effectively model duration distribution within the framework. Our results validate the effectiveness of the proposed IntraVerbalPA framework and its individual components, yielding performance that either matches or outperforms existing research works.
</details>
<details>
<summary>摘要</summary>
研究声学评估系统通常强调非本地语言（L2）的音律和音位方面，经常忽略非语音表达的丰富信息。本研究提出了一种新的声学评估框架，IntraVerbalPA。该框架创新地结合了细致的帧级和抽象的语音级非语音示唆，并与传统的语音和音位表达结合使用。此外，我们还提出了''声音持续时间质量''指标，有效地模型duration分布。我们的结果证明了提案的IntraVerbalPA框架和其组件的有效性，其性能与或超过了现有研究成果。
</details></li>
</ul>
<hr>
<h2 id="Explaining-Speech-Classification-Models-via-Word-Level-Audio-Segments-and-Paralinguistic-Features"><a href="#Explaining-Speech-Classification-Models-via-Word-Level-Audio-Segments-and-Paralinguistic-Features" class="headerlink" title="Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features"></a>Explaining Speech Classification Models via Word-Level Audio Segments and Paralinguistic Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07733">http://arxiv.org/abs/2309.07733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eliana Pastor, Alkis Koudounas, Giuseppe Attanasio, Dirk Hovy, Elena Baralis</li>
<li>for: 本研究旨在解释语音分类模型的内部工作方式，以便更好地理解和信任这些模型。</li>
<li>methods: 本研究使用输入杂化来生成易于理解的解释，包括单词层和para linguistic特征层。单词层解释显示每个单词相关的音频段带来了哪些影响，而para linguistic特征层解释则回答了对话式问题：“如果将音频信号编辑得这样，模型的预测会如何变化？”</li>
<li>results: 我们验证了这种方法，使用两种语言（英语和意大利语）的两个语音分类任务来解释两个现代SLU模型。我们的结果表明，这些解释准确地反映了模型的内部工作方式，并且对人类来说是可理解的。<details>
<summary>Abstract</summary>
Recent advances in eXplainable AI (XAI) have provided new insights into how models for vision, language, and tabular data operate. However, few approaches exist for understanding speech models. Existing work focuses on a few spoken language understanding (SLU) tasks, and explanations are difficult to interpret for most users. We introduce a new approach to explain speech classification models. We generate easy-to-interpret explanations via input perturbation on two information levels. 1) Word-level explanations reveal how each word-related audio segment impacts the outcome. 2) Paralinguistic features (e.g., prosody and background noise) answer the counterfactual: ``What would the model prediction be if we edited the audio signal in this way?'' We validate our approach by explaining two state-of-the-art SLU models on two speech classification tasks in English and Italian. Our findings demonstrate that the explanations are faithful to the model's inner workings and plausible to humans. Our method and findings pave the way for future research on interpreting speech models.
</details>
<details>
<summary>摘要</summary>
Note:* 可解释AI (XAI) is simplified as "eXplainable AI" in the text.* "speech models" is simplified as "speech classification models" in the text.* "spoken language understanding" is simplified as "SLU" in the text.* "word-related audio segment" is simplified as "word" in the text.* "paralinguistic features" is simplified as "paralinguistic" in the text.* "counterfactual" is simplified as "what if" in the text.
</details></li>
</ul>
<hr>
<h2 id="PerPLM-Personalized-Fine-tuning-of-Pretrained-Language-Models-via-Writer-specific-Intermediate-Learning-and-Prompts"><a href="#PerPLM-Personalized-Fine-tuning-of-Pretrained-Language-Models-via-Writer-specific-Intermediate-Learning-and-Prompts" class="headerlink" title="PerPLM: Personalized Fine-tuning of Pretrained Language Models via Writer-specific Intermediate Learning and Prompts"></a>PerPLM: Personalized Fine-tuning of Pretrained Language Models via Writer-specific Intermediate Learning and Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07727">http://arxiv.org/abs/2309.07727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daisuke Oba, Naoki Yoshinaga, Masashi Toyoda<br>for: 这个研究旨在提高文本理解任务的准确率，通过个性化PLM的精度调整 для特定作者。methods: 我们使用作者特定的提示来个性化一个统一的PLM，以避免多个用户的PLM存储和训练成本。我们还提出了一种基于遮盲语言模型的中间学习方法，以提取作者特定的文本特征。results: 我们的实验结果显示了不同的提示类型的特点，以及我们的中间学习方法的效果。我们使用多个任务、数据集和PLM进行了实验，并发现了个性化调整的优势。<details>
<summary>Abstract</summary>
The meanings of words and phrases depend not only on where they are used (contexts) but also on who use them (writers). Pretrained language models (PLMs) are powerful tools for capturing context, but they are typically pretrained and fine-tuned for universal use across different writers. This study aims to improve the accuracy of text understanding tasks by personalizing the fine-tuning of PLMs for specific writers. We focus on a general setting where only the plain text from target writers are available for personalization. To avoid the cost of fine-tuning and storing multiple copies of PLMs for different users, we exhaustively explore using writer-specific prompts to personalize a unified PLM. Since the design and evaluation of these prompts is an underdeveloped area, we introduce and compare different types of prompts that are possible in our setting. To maximize the potential of prompt-based personalized fine-tuning, we propose a personalized intermediate learning based on masked language modeling to extract task-independent traits of writers' text. Our experiments, using multiple tasks, datasets, and PLMs, reveal the nature of different prompts and the effectiveness of our intermediate learning approach.
</details>
<details>
<summary>摘要</summary>
文本中的意思不仅取决于其使用场景（上下文），还取决于作者（写者）。预训言语模型（PLM）是一种强大的工具，可以捕捉上下文，但它们通常是通用的，需要进行 universal 的预训练和精度调整。这个研究的目标是通过个性化 PLM 的精度调整来提高文本理解任务的准确性。我们关注一般情况下，只有目标作者的平面文本可用于个性化。为了避免多个用户的 PLM 预训练和存储成本，我们对writer-specific 的提示进行了探索。由于设计和评估这些提示的领域还是未发展的，我们引入了不同类型的提示，并对它们进行比较。为了最大化个性化提示基于隐藏语言模型的学习效果，我们提议了个性化中间学习，以抽取任务不виси的作者文本特征。我们的实验，使用多个任务、数据集和 PLM，显示了不同类型的提示的性质和我们的中间学习方法的效果。
</details></li>
</ul>
<hr>
<h2 id="L1-aware-Multilingual-Mispronunciation-Detection-Framework"><a href="#L1-aware-Multilingual-Mispronunciation-Detection-Framework" class="headerlink" title="L1-aware Multilingual Mispronunciation Detection Framework"></a>L1-aware Multilingual Mispronunciation Detection Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07719">http://arxiv.org/abs/2309.07719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yassine El Kheir, Shammur Absar Chwodhury, Ahmed Ali</li>
<li>for: 本研究旨在提出一种多语言声音识别（MDD）框架，以优化声音识别性能。</li>
<li>methods: 该框架基于一种新的多语言声音识别模型，即L1-MultiMDD模型，其中包含了语言一价声音表示。在该模型中，一个注意机制将输入音频与参考音频序列进行对应，然后使用多语言声音嵌入从一个辅助模型中提取，并将其与主网络相结合。最后，模型通过 Connectionist Temporal Classification（CTC）损失函数进行优化。</li>
<li>results: 实验结果表明，L1-MultiMDD模型在多种目标语言（英语、阿拉伯语和普通话）上具有稳定的性能，并且在各种声音识别任务上均显示出了领先的性能。<details>
<summary>Abstract</summary>
The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2v2; and unseen -- EpaDB and Speechocean762 datasets. The consistent gains in PER, and false rejection rate (FRR) across all target languages confirm our approach's robustness, efficacy, and generalizability.
</details>
<details>
<summary>摘要</summary>
“对话者的Native语言（L1）和非Native语言（L2）之间的音系学差异作为主要因素，导致误对。本文提出了一个新的多语言MDD架构，L1-MultiMDD，其中包含了L1-意识的语音表现。一个终端处理器是对入力讯号和它的对应的音节序列进行对齐。接着，从副架构中提取L1-L2-语音嵌入，并将其与主网络相结合。最后，L1-MultiMDD是透过 Connectionist Temporal Classification（CTC）损失来优化一个多语言音节识别任务。我们的实验表明，提案的L1-MultiMDD架构在seen和unseen数据集上都有显著的性能提升，PER和false rejection rate（FRR）在所有目标语言上都有相似的下降。”
</details></li>
</ul>
<hr>
<h2 id="CoLLD-Contrastive-Layer-to-layer-Distillation-for-Compressing-Multilingual-Pre-trained-Speech-Encoders"><a href="#CoLLD-Contrastive-Layer-to-layer-Distillation-for-Compressing-Multilingual-Pre-trained-Speech-Encoders" class="headerlink" title="CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders"></a>CoLLD: Contrastive Layer-to-layer Distillation for Compressing Multilingual Pre-trained Speech Encoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07707">http://arxiv.org/abs/2309.07707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng-Jui Chang, Ning Dong, Ruslan Mavlyutov, Sravya Popuri, Yu-An Chung</li>
<li>for: 大规模自监督演算 speech 编码器在语音识别和翻译任务中表现出色，但由于开发这些大型模型的成本太高，新任务建立新模型和部署到设备应用程序是不可能的。</li>
<li>methods: 我们提出了一种新的知识填充方法，即做到层次预测和对比学习来训练学生模型模仿大教师模型的行为。</li>
<li>results: CoLLD 方法比前一代方法表现出色，在多语言语音文本翻译和识别 benchmark 上与小型模型几乎相当。<details>
<summary>Abstract</summary>
Large-scale self-supervised pre-trained speech encoders outperform conventional approaches in speech recognition and translation tasks. Due to the high cost of developing these large models, building new encoders for new tasks and deploying them to on-device applications are infeasible. Prior studies propose model compression methods to address this issue, but those works focus on smaller models and less realistic tasks. Thus, we propose Contrastive Layer-to-layer Distillation (CoLLD), a novel knowledge distillation method to compress pre-trained speech encoders by leveraging masked prediction and contrastive learning to train student models to copy the behavior of a large teacher model. CoLLD outperforms prior methods and closes the gap between small and large models on multilingual speech-to-text translation and recognition benchmarks.
</details>
<details>
<summary>摘要</summary>
大规模自主学习预训练音频编码器超过传统方法在语音识别和翻译任务中表现出色。由于开发这些大型模型的成本很高，为新任务建立新的编码器并将其部署到设备应用程序是不可能的。先前的研究提出了模型压缩方法来解决这个问题，但这些方法主要关注小型模型和更为实际的任务。因此，我们提出了对比层次预训练知识填充（CoLLD），一种新的知识填充方法，通过使用遮盖预测和对比学习训练学生模型模仿大教师模型的行为。CoLLD超过了先前的方法，在多语言语音文本翻译和识别数据集上闭合了小型和大型模型之间的差距。
</details></li>
</ul>
<hr>
<h2 id="A-Conversation-is-Worth-A-Thousand-Recommendations-A-Survey-of-Holistic-Conversational-Recommender-Systems"><a href="#A-Conversation-is-Worth-A-Thousand-Recommendations-A-Survey-of-Holistic-Conversational-Recommender-Systems" class="headerlink" title="A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems"></a>A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07682">http://arxiv.org/abs/2309.07682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lichuangnus/crs-paper-list">https://github.com/lichuangnus/crs-paper-list</a></li>
<li>paper_authors: Chuang Li, Hengchang Hu, Yan Zhang, Min-Yen Kan, Haizhou Li</li>
<li>for: 这篇论文旨在探讨基于实际对话的会话推荐系统（CRS）的新趋势，即基于实际对话的holistic CRS方法。</li>
<li>methods: 这篇论文使用了一种结构化的方法来总结holistic CRS方法，其包括三个组成部分：1）基础语言模型，2）可选的外部知识，以及3）外部指导。</li>
<li>results: 论文提供了一个详细的分析对话推荐系统数据集和评价方法在实际应用场景中的现状，并提供了作者对现有挑战和未来趋势的评论。<details>
<summary>Abstract</summary>
Conversational recommender systems (CRS) generate recommendations through an interactive process. However, not all CRS approaches use human conversations as their source of interaction data; the majority of prior CRS work simulates interactions by exchanging entity-level information. As a result, claims of prior CRS work do not generalise to real-world settings where conversations take unexpected turns, or where conversational and intent understanding is not perfect. To tackle this challenge, the research community has started to examine holistic CRS, which are trained using conversational data collected from real-world scenarios. Despite their emergence, such holistic approaches are under-explored.   We present a comprehensive survey of holistic CRS methods by summarizing the literature in a structured manner. Our survey recognises holistic CRS approaches as having three components: 1) a backbone language model, the optional use of 2) external knowledge, and/or 3) external guidance. We also give a detailed analysis of CRS datasets and evaluation methods in real application scenarios. We offer our insight as to the current challenges of holistic CRS and possible future trends.
</details>
<details>
<summary>摘要</summary>
对话式推荐系统（CRS）通过交互过程生成推荐。然而，不全CRS方法使用真实的人工对话作为交互数据的来源；大多数先前CRS工作通过交换实体级别信息来模拟交互。因此，先前CRS工作的声索不懂实际世界中的对话弯曲和对话理解不准确。为解决这个挑战，研究社区开始了探索全面CRS，这些方法通过真实场景中的对话收集的数据进行训练。虽然它们的出现，但这些整体方法还未得到充分探索。我们提供了一份全面CRS方法的系统性报告，通过结构化的方式总结了相关文献。我们认为全面CRS方法包括三个组件：1）基础语言模型，可选的2）外部知识，以及3）外部指导。我们还给出了CRS数据集和评估方法在真实应用场景中的详细分析。我们对现有的全面CRS挑战和未来趋势给出了我们的见解。
</details></li>
</ul>
<hr>
<h2 id="Aligning-Speakers-Evaluating-and-Visualizing-Text-based-Diarization-Using-Efficient-Multiple-Sequence-Alignment-Extended-Version"><a href="#Aligning-Speakers-Evaluating-and-Visualizing-Text-based-Diarization-Using-Efficient-Multiple-Sequence-Alignment-Extended-Version" class="headerlink" title="Aligning Speakers: Evaluating and Visualizing Text-based Diarization Using Efficient Multiple Sequence Alignment (Extended Version)"></a>Aligning Speakers: Evaluating and Visualizing Text-based Diarization Using Efficient Multiple Sequence Alignment (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07677">http://arxiv.org/abs/2309.07677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Gong, Peilin Wu, Jinho D. Choi</li>
<li>for: 这篇论文提出了一种新的语音基于文本speaker分类评估方法，旨在解决传统 metric 不考虑文本上下文信息的限制。</li>
<li>methods: 论文提出了两种新的评估指标：文本基于的分类错误率和分类 F1 指标，这两种指标在语音分类任务中进行了单词和语音级别的评估，并且能够捕捉更多类型的错误。</li>
<li>results: 论文引入了一种多序列对Alignment算法，可以处理多个参考序列，并使用动态计算来处理高维对假序列的对应。这两个工具可以帮助创建高质量数据，推动对话系统的进步。<details>
<summary>Abstract</summary>
This paper presents a novel evaluation approach to text-based speaker diarization (SD), tackling the limitations of traditional metrics that do not account for any contextual information in text. Two new metrics are proposed, Text-based Diarization Error Rate and Diarization F1, which perform utterance- and word-level evaluations by aligning tokens in reference and hypothesis transcripts. Our metrics encompass more types of errors compared to existing ones, allowing us to make a more comprehensive analysis in SD. To align tokens, a multiple sequence alignment algorithm is introduced that supports multiple sequences in the reference while handling high-dimensional alignment to the hypothesis using dynamic programming. Our work is packaged into two tools, align4d providing an API for our alignment algorithm and TranscribeView for visualizing and evaluating SD errors, which can greatly aid in the creation of high-quality data, fostering the advancement of dialogue systems.
</details>
<details>
<summary>摘要</summary>
To align tokens, a multiple sequence alignment algorithm is introduced that supports multiple sequences in the reference and handles high-dimensional alignment to the hypothesis using dynamic programming. The authors have developed two tools, align4d and TranscribeView, to facilitate the use of their alignment algorithm and to visualize and evaluate SD errors. These tools can help create high-quality data, which is essential for the development of dialogue systems.In Simplified Chinese:这篇论文提出了一种新的文本基于Speaker diarization（SD）评估方法，解决传统的评估方法不考虑文本中上下文信息的限制。该论文提出了两个新的评估指标：Text-based Diarization Error Rate和Diarization F1，它们在语音和词级别进行评估，并且使用了多个序列的对齐算法来对应语音和假设词的匹配。这些指标比现有的指标更加全面，可以对SD进行更加详细的分析。为了对token进行对齐，该论文引入了一种多序列对齐算法，该算法支持多个参照序列，并且使用动态编程来处理高维对齐。作者们还开发了两个工具：align4d和TranscribeView，它们可以帮助创建高质量的数据，这将对对话系统的发展起到关键作用。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Data-Visualization-Generation-from-Chinese-Natural-Language-Questions"><a href="#Automatic-Data-Visualization-Generation-from-Chinese-Natural-Language-Questions" class="headerlink" title="Automatic Data Visualization Generation from Chinese Natural Language Questions"></a>Automatic Data Visualization Generation from Chinese Natural Language Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07650">http://arxiv.org/abs/2309.07650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Ge, Victor Junqiu Wei, Yuanfeng Song, Jason Chen Zhang, Raymond Chi-Wing Wong</li>
<li>for: 本研究旨在提出一个中文文本到视觉（Text-to-Vis）数据集，以便研究中文问题的数据视觉生成。</li>
<li>methods: 我们的模型使用多语言BERT作为编码器，提高了跨语言能力，并将ngram信息 интегрирован到单词表示学习中。</li>
<li>results: 我们的实验结果表明，我们的数据集具有挑战性，且值得进一步研究。<details>
<summary>Abstract</summary>
Data visualization has emerged as an effective tool for getting insights from massive datasets. Due to the hardness of manipulating the programming languages of data visualization, automatic data visualization generation from natural languages (Text-to-Vis) is becoming increasingly popular. Despite the plethora of research effort on the English Text-to-Vis, studies have yet to be conducted on data visualization generation from questions in Chinese. Motivated by this, we propose a Chinese Text-to-Vis dataset in the paper and demonstrate our first attempt to tackle this problem. Our model integrates multilingual BERT as the encoder, boosts the cross-lingual ability, and infuses the $n$-gram information into our word representation learning. Our experimental results show that our dataset is challenging and deserves further research.
</details>
<details>
<summary>摘要</summary>
“数据视化已经成为大量数据获得洞察的有效工具。由于数据视化编程语言的困难，自动从自然语言（文本）到数据视化（Text-to-Vis）的转化是越来越受欢迎。尽管英语 Text-to-Vis 的研究已经充满投入，但尚未对中文问题进行研究。我们在本文中提出了一个中文 Text-to-Vis 数据集，并在这个问题上进行了我们的首次尝试。我们的模型使用多语言BERT作为Encoder，提高了 crossed-lingual 能力，并将 $n$-gram 信息integrated into our word representation learning。我们的实验结果表明，我们的数据集是挑战性的，值得进一步研究。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Class-based-Language-Model-for-Named-Entity-Recognition-in-Factorized-Neural-Transducer"><a href="#Incorporating-Class-based-Language-Model-for-Named-Entity-Recognition-in-Factorized-Neural-Transducer" class="headerlink" title="Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer"></a>Incorporating Class-based Language Model for Named Entity Recognition in Factorized Neural Transducer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07648">http://arxiv.org/abs/2309.07648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Yifan Yang, Zheng Liang, Tian Tan, Shiliang Zhang, Xie Chen</li>
<li>for: 提高END-to-END模型中名实体识别的能力</li>
<li>methods:  combines class-based语言模型(LM) into factorized neural Transducer (FNT)</li>
<li>results: 显著降低名实体识别错误，不对通用词语识别造成影响<details>
<summary>Abstract</summary>
In spite of the excellent strides made by end-to-end (E2E) models in speech recognition in recent years, named entity recognition is still challenging but critical for semantic understanding. In order to enhance the ability to recognize named entities in E2E models, previous studies mainly focus on various rule-based or attention-based contextual biasing algorithms. However, their performance might be sensitive to the biasing weight or degraded by excessive attention to the named entity list, along with a risk of false triggering. Inspired by the success of the class-based language model (LM) in named entity recognition in conventional hybrid systems and the effective decoupling of acoustic and linguistic information in the factorized neural Transducer (FNT), we propose a novel E2E model to incorporate class-based LMs into FNT, which is referred as C-FNT. In C-FNT, the language model score of named entities can be associated with the name class instead of its surface form. The experimental results show that our proposed C-FNT presents significant error reduction in named entities without hurting performance in general word recognition.
</details>
<details>
<summary>摘要</summary>
尽管最近几年的终到终（E2E）模型在语音识别方面做出了优异的进步，但Named Entity Recognition（NER）仍然是一个挑战性的任务，对于含义理解是关键的。为了增强E2E模型中Named Entity的识别能力，先前的研究主要集中在不同的规则基于的或者关注基于的上下文偏好算法上。然而，其性能可能会受到偏好量的敏感性或者过度关注名称列表，同时也存在假触发的风险。drawing inspiration from the success of class-based language model（LM）在传统的混合系统中的Named Entity recognition和factorized neural Transducer（FNT）中的有效隔离语音和语言信息，我们提出了一种新的E2E模型，称为C-FNT。在C-FNT中，语言模型的名称分类得分可以与名称类型相关联，而不是其表面形式。实验结果显示，我们的提议的C-FNT可以减少Named Entities中的错误，而无需增加总体单词识别性能的影响。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-MOdularized-Reasoning-for-Compositional-Structured-Explanation-Generation"><a href="#Dynamic-MOdularized-Reasoning-for-Compositional-Structured-Explanation-Generation" class="headerlink" title="Dynamic MOdularized Reasoning for Compositional Structured Explanation Generation"></a>Dynamic MOdularized Reasoning for Compositional Structured Explanation Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07624">http://arxiv.org/abs/2309.07624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiyan Fu, Anette Frank</li>
<li>for: 本研究旨在提高神经网络模型的结构化推理能力和通用性。</li>
<li>methods: 该研究提出了一种新的结构化解释生成任务设定，以便进行结构化推理研究。previous works使用预定的推理规则进行迭代推理，但这些方法仅适用于已定义的任务和固定的推理流程。因此，该研究提出了一种动态模块化推理模型，即MORSE，以提高神经网络模型的结构化通用性。</li>
<li>results: MORSE在两个benchmark上进行增长推理树的测试中，与其他竞争性基线相比，表现出了更好的结构化推理能力和通用性。模型减少和深入分析表明了动态推理模块的有效性和通用性。<details>
<summary>Abstract</summary>
Despite the success of neural models in solving reasoning tasks, their compositional generalization capabilities remain unclear. In this work, we propose a new setting of the structured explanation generation task to facilitate compositional reasoning research. Previous works found that symbolic methods achieve superior compositionality by using pre-defined inference rules for iterative reasoning. But these approaches rely on brittle symbolic transfers and are restricted to well-defined tasks. Hence, we propose a dynamic modularized reasoning model, MORSE, to improve the compositional generalization of neural models. MORSE factorizes the inference process into a combination of modules, where each module represents a functional unit. Specifically, we adopt modularized self-attention to dynamically select and route inputs to dedicated heads, which specializes them to specific functions. We conduct experiments for increasing lengths and shapes of reasoning trees on two benchmarks to test MORSE's compositional generalization abilities, and find it outperforms competitive baselines. Model ablation and deeper analyses show the effectiveness of dynamic reasoning modules and their generalization abilities.
</details>
<details>
<summary>摘要</summary>
即使神经网络模型在理解任务上取得成功，它们的组合泛化能力仍然未得到清晰定义。在这项工作中，我们提出了一种新的结构化解释生成任务设定，以便促进神经网络模型的组合泛化研究。先前的工作发现，符号方法可以通过预先定义的推理规则进行迭代推理，从而实现更好的组合泛化。但这些方法受到不可靠的符号传递的限制，只能在已定义的任务上进行。因此，我们提出了一种动态模块化推理模型，称为MORSE，以提高神经网络模型的组合泛化能力。MORSE将推理过程分解为一系列模块，每个模块都代表了特定的功能单元。我们采用模块化自注意力来动态选择和导向输入到特定的头部，以进行特定的功能特циализация。我们在两个 benchmark 上进行了不同的LENGTH和SHAPE的理解树长度和形态测试，并发现MORSE在组合泛化能力方面表现出色，超越了竞争对手的基eline。模型剥离和深入分析表明了动态推理模块的效果和泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-Audio-Topic-Reranking-using-Large-Language-Models"><a href="#Zero-shot-Audio-Topic-Reranking-using-Large-Language-Models" class="headerlink" title="Zero-shot Audio Topic Reranking using Large Language Models"></a>Zero-shot Audio Topic Reranking using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07606">http://arxiv.org/abs/2309.07606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengjie Qian, Rao Ma, Adian Liusie, Erfan Loweimi, Kate M. Knill, Mark J. F. Gales</li>
<li>for: 这个项目（Multimodal Video Search by Examples）使用视频片段作为搜索关键词，而不是传统的文本查询。这允许更加丰富的搜索Modalities，如图像、说话人、内容、话题和情感。</li>
<li>methods: 这个过程中使用视频特征的嵌入表示来支持大型档案的快速搜索。这个工作的目标是通过评估重新排序方法来减少快速搜索中的性能损失。特别是使用大型自然语言模型的零批训练重新排序方法。</li>
<li>results: 在一个公共可用的视频档案（BBC Rewind corpus）上进行话题基于搜索，results显示重新排序可以获得改善的搜索排名，而无需任何任务特有的训练数据。<details>
<summary>Abstract</summary>
The Multimodal Video Search by Examples (MVSE) project investigates using video clips as the query term for information retrieval, rather than the more traditional text query. This enables far richer search modalities such as images, speaker, content, topic, and emotion. A key element for this process is highly rapid, flexible, search to support large archives, which in MVSE is facilitated by representing video attributes by embeddings. This work aims to mitigate any performance loss from this rapid archive search by examining reranking approaches. In particular, zero-shot reranking methods using large language models are investigated as these are applicable to any video archive audio content. Performance is evaluated for topic-based retrieval on a publicly available video archive, the BBC Rewind corpus. Results demonstrate that reranking can achieve improved retrieval ranking without the need for any task-specific training data.
</details>
<details>
<summary>摘要</summary>
《多模式视频搜索示例（MVSE）项目》investigates using video clips as query terms for information retrieval, rather than the more traditional text query. This enables far richer search modalities such as images, speaker, content, topic, and emotion. A key element for this process is highly rapid, flexible, search to support large archives, which in MVSE is facilitated by representing video attributes by embeddings. This work aims to mitigate any performance loss from this rapid archive search by examining reranking approaches. In particular, zero-shot reranking methods using large language models are investigated as these are applicable to any video archive audio content. Performance is evaluated for topic-based retrieval on a publicly available video archive, the BBC Rewind corpus. Results demonstrate that reranking can achieve improved retrieval ranking without the need for any task-specific training data.Here's the breakdown of the translation:* 《多模式视频搜索示例（MVSE）项目》: The title of the project, "Multi-modal Video Search by Examples (MVSE) Project"* investigates: investigates* using video clips as query terms: 使用视频片段作为查询 термина* for information retrieval:  для信息检索* rather than the more traditional text query: 而不是传统的文本查询* This enables far richer search modalities: 这使得搜索模式更加丰富* such as images, speaker, content, topic, and emotion: 如图像、speaker、内容、话题和情感* A key element for this process is highly rapid, flexible, search: 这个过程中的关键元素是高速灵活的搜索* to support large archives: 支持大型存档* which in MVSE is facilitated by representing video attributes by embeddings: 在MVSE中，通过表示视频特征用 embedding 来支持大型存档* This work aims to mitigate any performance loss from this rapid archive search: 这个工作目标是消除快速存档搜索中的性能损失* by examining reranking approaches: 通过研究重新排序方法* In particular, zero-shot reranking methods using large language models are investigated: 特别是使用大型自然语言模型的零shot重新排序方法* as these are applicable to any video archive audio content: 因为它们可以应用于任何视频存档的音频内容* Performance is evaluated for topic-based retrieval on a publicly available video archive, the BBC Rewind corpus: 在公开可用的视频存档 BBC Rewind  corpus 上进行话题基于检索性能评估* Results demonstrate that reranking can achieve improved retrieval ranking without the need for any task-specific training data: 结果表明，重新排序可以在无需任务特定训练数据的情况下实现改进的检索排名
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Supertagging-for-HPSG"><a href="#Revisiting-Supertagging-for-HPSG" class="headerlink" title="Revisiting Supertagging for HPSG"></a>Revisiting Supertagging for HPSG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07590">http://arxiv.org/abs/2309.07590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olga Zamaraeva, Carlos Gómez-Rodríguez</li>
<li>for: 这个论文的目的是为了开发新的HPSG超标注器，并用SVM和神经网络CRF-BERT模型来进行超标注。</li>
<li>methods: 这个论文使用了HPSG-based treebanks，这些treebanks具有高质量的注释和多种和复杂的测试数据集，包括WSJ部分23和Wikipedia数据。文章使用了MaxEnt-based模型，以及SVM和神经网络CRF-BERT模型，并证明了这些模型在超标注任务中的高精度性。</li>
<li>results: 文章的结果表明，使用SVM和神经网络CRF-BERT模型可以获得较高的超标注精度，比基eline模型高出许多。文章的最终BERT模型在1000个WSJ23句子上达到97.26%的精度，并在完全新领域的The Cathedral and the Bazaar（cb）数据集上达到93.88%的精度。<details>
<summary>Abstract</summary>
We present new supertaggers trained on HPSG-based treebanks. These treebanks feature high-quality annotation based on a well-developed linguistic theory and include diverse and challenging test datasets, beyond the usual WSJ section 23 and Wikipedia data. HPSG supertagging has previously relied on MaxEnt-based models. We use SVM and neural CRF- and BERT-based methods and show that both SVM and neural supertaggers achieve considerably higher accuracy compared to the baseline. Our fine-tuned BERT-based tagger achieves 97.26% accuracy on 1000 sentences from WSJ23 and 93.88% on the completely out-of-domain The Cathedral and the Bazaar (cb)). We conclude that it therefore makes sense to integrate these new supertaggers into modern HPSG parsers, and we also hope that the diverse and difficult datasets we used here will gain more popularity in the field. We contribute the complete dataset reformatted for token classification.
</details>
<details>
<summary>摘要</summary>
我们提出新的超标签器，基于HPSG-based treebanks进行训练。这些treebanks具有高质量的注释，基于完善的语言理论，并包括多样化和挑战性的测试数据集，超出常见的WSJ部分23和Wikipedia数据。在过去，HPSG超标签ging依赖于MaxEnt-based模型。我们使用SVM和神经网络CRF-以及BERT-based方法，并证明两者均在基准点上表现较高精度。我们精心调整的BERT-based标签器在WSJ23上达到97.26%的准确率，并在完全不同领域的The Cathedral and the Bazaar（cb）上达到93.88%的准确率。我们认为，因此是合理的将这些新的超标签器 интеグри into modern HPSG parser。我们还希望，我们使用的多样化和挑战性的数据集会在领域中受到更多的推广。我们提供了complete dataset reformatted for token classification。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Prompt-Learning-with-Distilled-Connective-Knowledge-for-Implicit-Discourse-Relation-Recognition"><a href="#Adaptive-Prompt-Learning-with-Distilled-Connective-Knowledge-for-Implicit-Discourse-Relation-Recognition" class="headerlink" title="Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition"></a>Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07561">http://arxiv.org/abs/2309.07561</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangzl99/AdaptPrompt">https://github.com/wangzl99/AdaptPrompt</a></li>
<li>paper_authors: Bang Wang, Zhenglin Wang, Wei Xiang, Yijun Mo</li>
<li>for: 本研究旨在提高无显式连接的干扰语言识别（IDRR）性能，通过连续提问和知识传递来减少人工设计努力。</li>
<li>methods: 本文提出了一种连续提问法（AdaptPrompt），通过自动选择适当的模板和答案空间来减少人工设计努力。此外，我们还设计了一种答案关系映射规则，以生成答案空间。</li>
<li>results: 我们在最新的PDTB Corpus V3.0上进行了实验，并证明了我们的设计目标的实现，即与state-of-the-art竞争对手相比，提高了干扰语言识别性能。<details>
<summary>Abstract</summary>
Implicit discourse relation recognition (IDRR) aims at recognizing the discourse relation between two text segments without an explicit connective. Recently, the prompt learning has just been applied to the IDRR task with great performance improvements over various neural network-based approaches. However, the discrete nature of the state-art-of-art prompting approach requires manual design of templates and answers, a big hurdle for its practical applications. In this paper, we propose a continuous version of prompt learning together with connective knowledge distillation, called AdaptPrompt, to reduce manual design efforts via continuous prompting while further improving performance via knowledge transfer. In particular, we design and train a few virtual tokens to form continuous templates and automatically select the most suitable one by gradient search in the embedding space. We also design an answer-relation mapping rule to generate a few virtual answers as the answer space. Furthermore, we notice the importance of annotated connectives in the training dataset and design a teacher-student architecture for knowledge transfer. Experiments on the up-to-date PDTB Corpus V3.0 validate our design objectives in terms of the better relation recognition performance over the state-of-the-art competitors.
</details>
<details>
<summary>摘要</summary>
假设论坛（IDRR）目的是识别文本段落之间的话语关系，而不需要显式的连接词。最近，推荐学习已经应用于IDRR任务中，并取得了较好的表现。然而，现有的状态 искусственный智能（AI）提示方法的精度性不够，需要手动设计模板和答案，这是实际应用中的一大障碍。在这篇论文中，我们提出了一种连续的提示学习方法，称之为AdaptPrompt，以减少手动设计尝试的努力，同时通过知识传输来提高表现。具体来说，我们设计了一些虚拟token来形成连续的模板，并通过梯度搜索在embedding空间中自动选择最适合的一个。我们还设计了一个答案关系映射规则来生成一些虚拟答案。此外，我们注意到了标注的连接词在训练集中的重要性，因此我们设计了一种教师-学生架构来进行知识传输。实验结果表明，我们的设计目标在现代PDTB Corpus V3.0上都得到了 validate。
</details></li>
</ul>
<hr>
<h2 id="DBLPLink-An-Entity-Linker-for-the-DBLP-Scholarly-Knowledge-Graph"><a href="#DBLPLink-An-Entity-Linker-for-the-DBLP-Scholarly-Knowledge-Graph" class="headerlink" title="DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph"></a>DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07545">http://arxiv.org/abs/2309.07545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uhh-lt/dblplink">https://github.com/uhh-lt/dblplink</a></li>
<li>paper_authors: Debayan Banerjee, Arefa, Ricardo Usbeck, Chris Biemann</li>
<li>for: 这个论文是关于构建DBLP学术知识图（DBLP scholarly knowledge graph）上的实体连接应用程序DBLPLink。</li>
<li>methods: 该应用程序使用文本到文本预训练语言模型，如T5，生成输入文本问题中的实体标签跨 span。实体候选者从数据库中提取基于标签，并使用实体嵌入模型，如TransE、DistMult和ComplEx，对实体进行排序。</li>
<li>results: 该应用程序可以在不同的KG嵌入模型下显示结果，让用户可以比较和对比不同模型的结果。示例可以在<a target="_blank" rel="noopener" href="https://ltdemos.informatik.uni-hamburg.de/dblplink/%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AE%E3%80%82">https://ltdemos.informatik.uni-hamburg.de/dblplink/上进行访问。</a><details>
<summary>Abstract</summary>
In this work, we present a web application named DBLPLink, which performs entity linking over the DBLP scholarly knowledge graph. DBLPLink uses text-to-text pre-trained language models, such as T5, to produce entity label spans from an input text question. Entity candidates are fetched from a database based on the labels, and an entity re-ranker sorts them based on entity embeddings, such as TransE, DistMult and ComplEx. The results are displayed so that users may compare and contrast the results between T5-small, T5-base and the different KG embeddings used. The demo can be accessed at https://ltdemos.informatik.uni-hamburg.de/dblplink/.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了一个名为DBLPLink的网络应用程序，它在DBLP学术知识图上进行实体链接。DBLPLink使用文本到文本预训练语言模型，如T5，生成输入文本问题中的实体标签跨 span。实体候选者从数据库中 fetch，并使用实体嵌入，如TransE、DistMult和ComplEx，对实体进行排序。结果显示在用户可以比较和对比不同的T5小、基础和KG嵌入使用的结果。演示可以在https://ltdemos.informatik.uni-hamburg.de/dblplink/中进行访问。
</details></li>
</ul>
<hr>
<h2 id="Direct-Text-to-Speech-Translation-System-using-Acoustic-Units"><a href="#Direct-Text-to-Speech-Translation-System-using-Acoustic-Units" class="headerlink" title="Direct Text to Speech Translation System using Acoustic Units"></a>Direct Text to Speech Translation System using Acoustic Units</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07478">http://arxiv.org/abs/2309.07478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victoria Mingote, Pablo Gimeno, Luis Vicente, Sameer Khurana, Antoine Laurent, Jarod Duret</li>
<li>for: 这篇论文提出了一种直接文本到语音翻译系统，使用不同源语言的文本作为输入，生成目标语言的语音无需该语言的文本转写。</li>
<li>methods: 该框架使用文本encoder和分 clustering算法提取了音频单元，然后使用encoder-decoder架构进行预测。最后，vocoder生成了语音从单元。</li>
<li>results: 对新的CVSS corpus进行测试，系统在大多数语言对比中表现竞争力强，并且在使用多语言预训练模型的情况下显示出了remarkable的提升。<details>
<summary>Abstract</summary>
This paper proposes a direct text to speech translation system using discrete acoustic units. This framework employs text in different source languages as input to generate speech in the target language without the need for text transcriptions in this language. Motivated by the success of acoustic units in previous works for direct speech to speech translation systems, we use the same pipeline to extract the acoustic units using a speech encoder combined with a clustering algorithm. Once units are obtained, an encoder-decoder architecture is trained to predict them. Then a vocoder generates speech from units. Our approach for direct text to speech translation was tested on the new CVSS corpus with two different text mBART models employed as initialisation. The systems presented report competitive performance for most of the language pairs evaluated. Besides, results show a remarkable improvement when initialising our proposed architecture with a model pre-trained with more languages.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种直接文本到语音翻译系统，使用分割的声音单元。这个框架使用不同的源语言文本作为输入，生成目标语言的语音，不需要目标语言的文本转写。受到之前的直接Speech-to-Speech翻译系统的成功所 inspirited，我们使用同样的管道来提取声音单元，使用语音编码器和分 clustering 算法。一旦单元被获得，我们使用编码器-解码器架构来预测它们。然后，一个 vocoder 生成语音从单元。我们的直接文本到语音翻译方法在新的 CVSS  corpora 上进行了测试，并使用两种不同的 text mBART 模型作为初始化。系统显示了竞争性的表现，并且结果表明，当使用更多语言预训练的模型作为初始化时，有很大的改善。
</details></li>
</ul>
<hr>
<h2 id="Are-Large-Language-Model-based-Evaluators-the-Solution-to-Scaling-Up-Multilingual-Evaluation"><a href="#Are-Large-Language-Model-based-Evaluators-the-Solution-to-Scaling-Up-Multilingual-Evaluation" class="headerlink" title="Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?"></a>Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07462">http://arxiv.org/abs/2309.07462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee, Mohamed Ahmed, Monojit Choudhury, Kalika Bali, Sunayana Sitaram</li>
<li>for: This paper aims to investigate the use of LLM-based evaluators for scaling up multilingual evaluation in NLP tasks, and to calibrate LLM-based evaluation against human judgments.</li>
<li>methods: The paper uses LLM-based evaluators to evaluate the performance of NLP models in eight languages, and compares the results with human judgments.</li>
<li>results: The study finds that LLM-based evaluators may exhibit bias towards higher scores, and should be used with caution, particularly in low-resource and non-Latin script languages. Additionally, the paper suggests that calibrating LLM-based evaluators with a dataset of native speaker judgments is important for ensuring accurate evaluation.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在研究使用LLM-based评估器来扩大多语言评估的可行性，并对LMM-based评估器与人工评估的准确性进行均衡。</li>
<li>methods: 这篇论文使用LLM-based评估器对NLP模型在八种语言中的表现进行评估，并与人工评估进行比较。</li>
<li>results: 研究发现LMM-based评估器可能受到高分偏袋的影响，需要在低资源语言和非拉丁字符语言中使用时进行谨慎使用，同时也需要对Native speaker评估数据进行准确性的均衡。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated impressive performance on Natural Language Processing (NLP) tasks, such as Question Answering, Summarization, and Classification. The use of LLMs as evaluators, that can rank or score the output of other models (usually LLMs) has become increasingly popular, due to the limitations of current evaluation techniques including the lack of appropriate benchmarks, metrics, cost, and access to human annotators. While LLMs are capable of handling approximately 100 languages, the majority of languages beyond the top 20 lack systematic evaluation across various tasks, metrics, and benchmarks. This creates an urgent need to scale up multilingual evaluation to ensure a precise understanding of LLM performance across diverse languages. LLM-based evaluators seem like the perfect solution to this problem, as they do not require human annotators, human-created references, or benchmarks and can theoretically be used to evaluate any language covered by the LLM. In this paper, we investigate whether LLM-based evaluators can help scale up multilingual evaluation. Specifically, we calibrate LLM-based evaluation against 20k human judgments of five metrics across three text-generation tasks in eight languages. Our findings indicate that LLM-based evaluators may exhibit bias towards higher scores and should be used with caution and should always be calibrated with a dataset of native speaker judgments, particularly in low-resource and non-Latin script languages.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SIB-200-A-Simple-Inclusive-and-Big-Evaluation-Dataset-for-Topic-Classification-in-200-Languages-and-Dialects"><a href="#SIB-200-A-Simple-Inclusive-and-Big-Evaluation-Dataset-for-Topic-Classification-in-200-Languages-and-Dialects" class="headerlink" title="SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects"></a>SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic Classification in 200+ Languages and Dialects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07445">http://arxiv.org/abs/2309.07445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dadelani/sib-200">https://github.com/dadelani/sib-200</a></li>
<li>paper_authors: David Ifeoluwa Adelani, Hannah Liu, Xiaoyu Shen, Nikita Vassilyev, Jesujoba O. Alabi, Yanke Mao, Haonan Gao, Annie En-Shiun Lee</li>
<li>for: 这个论文目的是为了提供一个大规模的多语言自然语言处理（NLP）评估测试集，以便测试多语言语言模型的性能。</li>
<li>methods: 这个论文使用了Flores-200机器翻译集的英文部分，并将其扩展到其他203种语言的句子级标注。</li>
<li>results: 这个论文的评估结果显示，在多语言评估中，高资源语言和低资源语言之间的性能差距仍然很大，特别是未在预训时期训练的语言、少数语言家族（如 nilotic 和 atlantic-Congo）、以及来自非洲、美洲、大洋洲和东南亚的语言，往往有最低的表现。<details>
<summary>Abstract</summary>
Despite the progress we have recorded in the last few years in multilingual natural language processing, evaluation is typically limited to a small set of languages with available datasets which excludes a large number of low-resource languages. In this paper, we created SIB-200 -- a large-scale open-sourced benchmark dataset for topic classification in 200 languages and dialects to address the lack of evaluation dataset for Natural Language Understanding (NLU). For many of the languages covered in SIB-200, this is the first publicly available evaluation dataset for NLU. The dataset is based on Flores-200 machine translation corpus. We annotated the English portion of the dataset and extended the sentence-level annotation to the remaining 203 languages covered in the corpus. Despite the simplicity of this task, our evaluation in full-supervised setting, cross-lingual transfer setting and prompting of large language model setting show that there is still a large gap between the performance of high-resource and low-resource languages when multilingual evaluation is scaled to numerous world languages. We found that languages unseen during the pre-training of multilingual language models, under-represented language families (like Nilotic and Altantic-Congo), and languages from the regions of Africa, Americas, Oceania and South East Asia, often have the lowest performance on our topic classification dataset. We hope our dataset will encourage a more inclusive evaluation of multilingual language models on a more diverse set of languages. https://github.com/dadelani/sib-200
</details>
<details>
<summary>摘要</summary>
尽管在过去几年内我们在多语言自然语言处理方面做出了一些进步，但评估通常只限于一小组已有数据集的语言，这排除了大量的低资源语言。在这篇论文中，我们创建了SIB-200——一个大规模的开源测试集，用于评估200种语言和方言的主题分类。对于许多被覆盖的语言，这是首次公开可用的评估 dataset for Natural Language Understanding (NLU)。该数据集基于 Flores-200 机器翻译库。我们对英语部分进行了注释，并将 sentence-level 注释扩展到剩余的 203种语言。 despite the simplicity of this task, our evaluation in full-supervised setting, cross-lingual transfer setting and prompting of large language model setting show that there is still a large gap between the performance of high-resource and low-resource languages when multilingual evaluation is scaled to numerous world languages。我们发现，在模型预训练时未见过的语言、不充分代表的语言家族（如 nilotic 和 atlantic-congolese）以及来自非洲、美洲、大洋洲和东南亚的语言，经常有最低的表现在我们的主题分类数据集上。我们希望我们的数据集能够促进更加包容的评估多语言模型在更加多样化的语言上。更多信息请参考 https://github.com/dadelani/sib-200。
</details></li>
</ul>
<hr>
<h2 id="Clinical-Text-Summarization-Adapting-Large-Language-Models-Can-Outperform-Human-Experts"><a href="#Clinical-Text-Summarization-Adapting-Large-Language-Models-Can-Outperform-Human-Experts" class="headerlink" title="Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts"></a>Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07430">http://arxiv.org/abs/2309.07430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanfordmimi/clin-summ">https://github.com/stanfordmimi/clin-summ</a></li>
<li>paper_authors: Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, William Collins, Neera Ahuja, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, John Pauly, Akshay S. Chaudhari</li>
<li>for:  clinical text summarization across multiple tasks</li>
<li>methods:  employ domain adaptation methods on eight large language models (LLMs) spanning six datasets and four distinct summarization tasks</li>
<li>results:  the best adapted LLM outperforms human summaries in terms of completeness and correctness, and traditional quantitative NLP metrics are correlated with reader study scores.<details>
<summary>Abstract</summary>
Sifting through vast textual data and summarizing key information imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy across diverse clinical summarization tasks has not yet been rigorously examined. In this work, we employ domain adaptation methods on eight LLMs, spanning six datasets and four distinct summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not lead to improved results. Further, in a clinical reader study with six physicians, we depict that summaries from the best adapted LLM are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis delineates mutual challenges faced by both LLMs and human experts. Lastly, we correlate traditional quantitative NLP metrics with reader study scores to enhance our understanding of how these metrics align with physician preferences. Our research marks the first evidence of LLMs outperforming human experts in clinical text summarization across multiple tasks. This implies that integrating LLMs into clinical workflows could alleviate documentation burden, empowering clinicians to focus more on personalized patient care and other irreplaceable human aspects of medicine.
</details>
<details>
<summary>摘要</summary>
通过庞大的文本数据进行筛选和摘要关键信息对临床医生的时间分配带来了巨大的压力。虽然大型自然语言处理（NLP）模型（LLM）在不同的NLP任务上表现出了很大的投入，但是它们在多个临床摘要任务上的效果尚未得到了系统性的评估。在这项工作中，我们使用领域适应方法在八个LLM上进行了八个数据集和四个不同的摘要任务的测试：诊断报告、病人问题、进度记录和医生与病人对话。我们的详细的量化评估表明了模型和适应方法之间的贸易offs，以及LLM在不同任务上的表现可能不是完美的。此外，我们在六位医生的读者研究中发现，最佳适应LLM的摘要比人类摘要更加完整和正确。我们的后续质量分析表明，LLM和人类专家面临着相似的挑战。最后，我们将传统的NLP量化指标与读者研究得分进行了相关性分析，以更好地理解这些指标与医生的偏好之间的关系。我们的研究表明，LLM可以在多个临床摘要任务上超越人类专家，这意味着将LLM integrate到临床工作流程中可以减轻文本记录的压力，让医生更能专注于个性化患者护理和其他不可取代的医学方面。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-MT-Competitive-for-High-but-not-Low-Resource-Languages"><a href="#ChatGPT-MT-Competitive-for-High-but-not-Low-Resource-Languages" class="headerlink" title="ChatGPT MT: Competitive for High- (but not Low-) Resource Languages"></a>ChatGPT MT: Competitive for High- (but not Low-) Resource Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07423">http://arxiv.org/abs/2309.07423</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig</li>
<li>for: 本研究的目的是评估大语言模型（LLMs）在不同语言之间的翻译能力。</li>
<li>methods: 本研究使用的方法是使用FLORES-200benchmark进行实验，对204种语言进行了MT的评估。</li>
<li>results: 研究发现，GPT模型在一些高资源语言（HRLs）上表现比传统MT模型更好，但在低资源语言（LRLs）上表现较差，只有85.9%的语言表现比传统MT模型更好。研究还发现，语言资源水平是决定ChatGPT翻译某语言的能力的最重要因素，而且ChatGPT在非洲语言和低资源语言上表现较差。<details>
<summary>Abstract</summary>
Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs' MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world's diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language's resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）通过自动学习执行多种语言任务，包括机器翻译（MT）。先前的研究探讨了 LLM 的 MT 能力的不同方面。然而，存在许多语言，其 MT 性能尚未被最新的 LLM 评估。无published experimental evidence的情况下，世界各地语言使用者难以了解是否可以使用 LLM 翻译他们的语言。我们提供了第一个实验证据，对204种语言进行了MT成本分析，使用FLORES-200 benchmar。结果显示，GPT模型在一些高资源语言（HRLs）上 approaching或超过传统MT模型的性能，但在低资源语言（LRLs）上一直偏下，对84.1%的语言进行了下rance。我们的分析表明，语言资源水平是确定 ChatGPT 翻译其中的最重要因素，并表明 ChatGPT 对非洲语言和低资源语言表现出了劣势。
</details></li>
</ul>
<hr>
<h2 id="PromptASR-for-contextualized-ASR-with-controllable-style"><a href="#PromptASR-for-contextualized-ASR-with-controllable-style" class="headerlink" title="PromptASR for contextualized ASR with controllable style"></a>PromptASR for contextualized ASR with controllable style</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07414">http://arxiv.org/abs/2309.07414</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k2-fsa/icefall">https://github.com/k2-fsa/icefall</a></li>
<li>paper_authors: Xiaoyu Yang, Wei Kang, Zengwei Yao, Yifan Yang, Liyong Guo, Fangjun Kuang, Long Lin, Daniel Povey</li>
<li>for: 这个论文的目的是提出一种基于提示的端到端自动语音识别（E2E ASR）系统，以实现基于提示的语音识别，并可以控制语音识别的样式。</li>
<li>methods: 该系统使用专门的文本Encoder来编码提示文本，然后将编码的特征与语音Encoder进行交叉对应，以实现语音识别的提示。此外，系统还可以使用文本提示来改善语音识别的准确率，并可以给予不同的样式提示来控制语音识别的样式。</li>
<li>results: 在一个书的阅读 dataset 和一个内部dataset上，相比基eline ASR系统，该系统使用真实的文本提示可以提高21.9%和6.8%的单词错误率。此外，系统还可以使用单词级别的偏好列表作为提示，以提高对罕见词的识别率。<details>
<summary>Abstract</summary>
Prompts are crucial to large language models as they provide context information such as topic or logical relationships. Inspired by this, we propose PromptASR, a framework that integrates prompts in end-to-end automatic speech recognition (E2E ASR) systems to achieve contextualized ASR with controllable style of transcriptions. Specifically, a dedicated text encoder encodes the text prompts and the encodings are injected into the speech encoder by cross-attending the features from two modalities. When using the ground truth text from preceding utterances as content prompt, the proposed system achieves 21.9% and 6.8% relative word error rate reductions on a book reading dataset and an in-house dataset compared to a baseline ASR system. The system can also take word-level biasing lists as prompt to improve recognition accuracy on rare words. An additional style prompt can be given to the text encoder and guide the ASR system to output different styles of transcriptions. The code is available at icefall.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translation.googleapis.com/translate?sl=en&tl=zh-CN&text=Prompts%20are%20crucial%20to%20large%20language%20models%20as%20they%20provide%20context%20information%20such%20as%20topic%20or%20logical%20relationships.%20Inspired%20by%20this,%20we%20propose%20PromptASR,%20a%20framework%20that%20integrates%20prompts%20in%20end-to-end%20automatic%20speech%20recognition%20(E2E%20ASR)%20systems%20to%20achieve%20contextualized%20ASR%20with%20controllable%20style%20of%20transcriptions.%20Specifically,%20a%20dedicated%20text%20encoder%20encodes%20the%20text%20prompts%20and%20the%20encodings%20are%20injected%20into%20the%20speech%20encoder%20by%20cross-attending%20the%20features%20from%20two%20modalities.%20When%20using%20the%20ground%20truth%20text%20from%20preceding%20utterances%20as%20content%20prompt,%20the%20proposed%20system%20achieves%2021.9%25%20and%206.8%25%20relative%20word%20error%20rate%20reductions%20on%20a%20book%20reading%20dataset%20and%20an%20in-house%20dataset%20compared%20to%20a%20baseline%20ASR%20system.%20The%20system%20can%20also%20take%20word-level%20biasing%20lists%20as%20prompt%20to%20improve%20recognition%20accuracy%20on%20rare%20words.%20An%20additional%20style%20prompt%20can%20be%20given%20to%20the%20text%20encoder%20and%20guide%20the%20ASR%20system%20to%20output%20different%20styles%20of%20transcriptions.%20The%20code%20is%20available%20at%20icefall.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="CPPF-A-contextual-and-post-processing-free-model-for-automatic-speech-recognition"><a href="#CPPF-A-contextual-and-post-processing-free-model-for-automatic-speech-recognition" class="headerlink" title="CPPF: A contextual and post-processing-free model for automatic speech recognition"></a>CPPF: A contextual and post-processing-free model for automatic speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07413">http://arxiv.org/abs/2309.07413</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Zhang, Zhengkun Tian, Xiang Chen, Jiaming Sun, Hongyu Xiang, Ke Ding, Guanglu Wan</li>
<li>for: 本研究旨在提高自然语言处理（NLP）领域的语音识别（ASR）系统的效果，通过将多种ASR处理任务与语音识别模型集成。</li>
<li>methods: 本研究使用了LLMs和Whisper等多种技术，把多种ASR处理任务与语音识别模型集成，以实现直接生成已经处理过的文本。</li>
<li>results: 研究表明，CPPF模型可以减少多stage管道，避免错误的协传，提高ASR的效果。<details>
<summary>Abstract</summary>
ASR systems have become increasingly widespread in recent years. However, their textual outputs often require post-processing tasks before they can be practically utilized. To address this issue, we draw inspiration from the multifaceted capabilities of LLMs and Whisper, and focus on integrating multiple ASR text processing tasks related to speech recognition into the ASR model. This integration not only shortens the multi-stage pipeline, but also prevents the propagation of cascading errors, resulting in direct generation of post-processed text. In this study, we focus on ASR-related processing tasks, including Contextual ASR and multiple ASR post processing tasks. To achieve this objective, we introduce the CPPF model, which offers a versatile and highly effective alternative to ASR processing. CPPF seamlessly integrates these tasks without any significant loss in recognition performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Advancing-Regular-Language-Reasoning-in-Linear-Recurrent-Neural-Networks"><a href="#Advancing-Regular-Language-Reasoning-in-Linear-Recurrent-Neural-Networks" class="headerlink" title="Advancing Regular Language Reasoning in Linear Recurrent Neural Networks"></a>Advancing Regular Language Reasoning in Linear Recurrent Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07412">http://arxiv.org/abs/2309.07412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting-Han Fan, Ta-Chung Chi, Alexander I. Rudnicky</li>
<li>for: 研究Linear Recurrent Neural Networks (LRNNs) 的可能性，以实现Transformer-level的自然语言处理和长距离模型，同时提供快速并行训练和常规推理成本。</li>
<li>methods: 研究LRNNs 是否可以学习训练序列中的隐藏规则，如正则语言的 grammatical structures。对现有 LRNNs 进行理论分析，发现它们在正则语言上存在限制。基于分析，提出一种新的 LRNN，具有块状 диагональ 输入依赖的转移矩阵。</li>
<li>results: 实验表明，提出的模型可以在正则语言任务中进行长度 extrapolation，如和、偶对、模块加法等。<details>
<summary>Abstract</summary>
In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VDialogUE-A-Unified-Evaluation-Benchmark-for-Visually-grounded-Dialogue"><a href="#VDialogUE-A-Unified-Evaluation-Benchmark-for-Visually-grounded-Dialogue" class="headerlink" title="VDialogUE: A Unified Evaluation Benchmark for Visually-grounded Dialogue"></a>VDialogUE: A Unified Evaluation Benchmark for Visually-grounded Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07387">http://arxiv.org/abs/2309.07387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunshui Li, Binyuan Hui, Zhaochao Yin, Wanwei He, Run Luo, Yuxing Long, Min Yang, Fei Huang, Yongbin Li</li>
<li>For: The paper aims to address the lack of a standardized evaluation framework for visually-grounded dialog systems by proposing a new benchmark called VDialogUE.* Methods: The paper introduces a novel evaluation metric called VDscore, based on the Analytic Hierarchy Process (AHP) method, to provide a comprehensive assessment of multi-modal dialogue systems. The authors also propose a baseline model named VISIT, which uses a two-stage pre-training strategy to progressively build its multi-modal foundation and dialogue capability.* Results: The paper presents the results of the VDialogUE benchmark on six datasets, demonstrating the effectiveness of the proposed evaluation metric and the baseline model. The authors believe that the VDialogUE benchmark and their proposed methods will accelerate the development of visually-grounded dialog systems and lead to the development of more sophisticated and effective pre-trained models.Here is the information in Simplified Chinese text:* For: 这篇论文目标是解决视觉基立的对话系统评价框架的缺乏问题，提出了一个新的评价指标——VDscore。* Methods: 论文提出了一种新的评价指标——VDscore，基于分析层次法(AHP)方法，以提供多Modal对话系统的全面评价。同时， authors还提出了一个基线模型——VISIT，使用两个阶段预训练策略来逐渐建立多Modal基础和对话能力。* Results: 论文通过VDialogUE benchmark的六个数据集测试， demonstarte了VDscore的效果和基eline模型的可行性。作者认为，VDialogUE benchmark和提出的方法将加速视觉基立对话系统的发展，并促进更加复杂和有效的预训练模型的开发。<details>
<summary>Abstract</summary>
Visually-grounded dialog systems, which integrate multiple modes of communication such as text and visual inputs, have become an increasingly popular area of investigation. However, the absence of a standardized evaluation framework poses a challenge in assessing the development of this field. To this end, we propose \textbf{VDialogUE}, a \textbf{V}isually-grounded \textbf{Dialog}ue benchmark for \textbf{U}nified \textbf{E}valuation. It defines five core multi-modal dialogue tasks and covers six datasets. Furthermore, in order to provide a comprehensive assessment of the model's performance across all tasks, we developed a novel evaluation metric called VDscore, which is based on the Analytic Hierarchy Process~(AHP) method. Additionally, we present a straightforward yet efficient baseline model, named \textbf{VISIT}~(\textbf{VIS}ually-grounded d\textbf{I}alog \textbf{T}ransformer), to promote the advancement of general multi-modal dialogue systems. It progressively builds its multi-modal foundation and dialogue capability via a two-stage pre-training strategy.   We believe that the VDialogUE benchmark, along with the evaluation scripts and our baseline models, will accelerate the development of visually-grounded dialog systems and lead to the development of more sophisticated and effective pre-trained models.
</details>
<details>
<summary>摘要</summary>
📝Visually-grounded dialog systems, which integrate multiple modes of communication such as text and visual inputs, have become an increasingly popular area of investigation. However, the absence of a standardized evaluation framework poses a challenge in assessing the development of this field. To this end, we propose 📝VDialogUE, a 📝Visually-grounded 📝Dialogue benchmark for 📝Unified 📝Evaluation. It defines five core multi-modal dialogue tasks and covers six datasets. Furthermore, in order to provide a comprehensive assessment of the model's performance across all tasks, we developed a novel evaluation metric called VDscore, which is based on the Analytic Hierarchy Process~(AHP) method. Additionally, we present a straightforward yet efficient baseline model, named 📝VISIT~(📝VISually-grounded d📝Ialog 📝Transformer), to promote the advancement of general multi-modal dialogue systems. It progressively builds its multi-modal foundation and dialogue capability via a two-stage pre-training strategy.   We believe that the 📝VDialogUE benchmark, along with the evaluation scripts and our baseline models, will accelerate the development of visually-grounded dialog systems and lead to the development of more sophisticated and effective pre-trained models.
</details></li>
</ul>
<hr>
<h2 id="An-Interactive-Framework-for-Profiling-News-Media-Sources"><a href="#An-Interactive-Framework-for-Profiling-News-Media-Sources" class="headerlink" title="An Interactive Framework for Profiling News Media Sources"></a>An Interactive Framework for Profiling News Media Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07384">http://arxiv.org/abs/2309.07384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil Mehta, Dan Goldwasser</li>
<li>for: 检测和评估社交媒体上的假新闻和偏见内容，以维护社会的健康发展。</li>
<li>methods: 提出了一种互动式新闻媒体评估框架，结合图基新闻媒体评估模型、大语言模型和人类专家意见，以 caracterize社交媒体上的社会背景。</li>
<li>results: 实验结果表明，只需要5次人类互动，该框架可以快速检测新闻媒体中的假和偏见内容，包括新闻事件的突然出现。<details>
<summary>Abstract</summary>
The recent rise of social media has led to the spread of large amounts of fake and biased news, content published with the intent to sway beliefs. While detecting and profiling the sources that spread this news is important to maintain a healthy society, it is challenging for automated systems.   In this paper, we propose an interactive framework for news media profiling. It combines the strengths of graph based news media profiling models, Pre-trained Large Language Models, and human insight to characterize the social context on social media. Experimental results show that with as little as 5 human interactions, our framework can rapidly detect fake and biased news media, even in the most challenging settings of emerging news events, where test data is unseen.
</details>
<details>
<summary>摘要</summary>
最近社交媒体的崛起导致各种假和偏见新闻的扩散，这些新闻通常发布于影响人们信仰的目的。虽然检测和识别这些新闻的源是保持社会健康的重要任务，但是自动系统很难实现。在这篇论文中，我们提出了一个互动式新闻媒体 Profiling 框架。它结合基于图的新闻媒体 Profiling 模型、预训练的大语言模型以及人类智慧，以描述社交媒体上的社会背景。实验结果表明，我们的框架只需5次人类互动，就可以快速检测假和偏见新闻媒体，即使在新闻事件发生的最复杂的情况下也能够准确地识别。
</details></li>
</ul>
<hr>
<h2 id="Less-is-More-for-Long-Document-Summary-Evaluation-by-LLMs"><a href="#Less-is-More-for-Long-Document-Summary-Evaluation-by-LLMs" class="headerlink" title="Less is More for Long Document Summary Evaluation by LLMs"></a>Less is More for Long Document Summary Evaluation by LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07382">http://arxiv.org/abs/2309.07382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunshu Wu, Hayate Iso, Pouya Pezeshkpour, Nikita Bhutani, Estevam Hruschka</li>
<li>for: 这个论文的目的是提出一种新的评估方法，以解决LLM在长文摘要评估任务中的计算成本高和 Lost-in-the-Middle 问题。</li>
<li>methods: 该方法首先提取长文摘要中的关键句子，然后使用LLM进行评估。</li>
<li>results: 实验结果显示，提出的方法不仅能减少评估成本，还能够更好地与人工评估相协调。此外，我们还提供了优化文档长度和句子提取方法的实践建议，以便开发更加Cost-effective yet accurate的LLM-based文本生成评估方法。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the Lost-in-the-Middle problem where important information in the middle of long documents is often overlooked. To address these issues, this paper introduces a novel approach, Extract-then-Evaluate, which involves extracting key sentences from a long source document and then evaluating the summary by prompting LLMs. The results reveal that the proposed method not only significantly reduces evaluation costs but also exhibits a higher correlation with human evaluations. Furthermore, we provide practical recommendations for optimal document length and sentence extraction methods, contributing to the development of cost-effective yet more accurate methods for LLM-based text generation evaluation.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在摘要评估任务中表现出色，但它们面临着高计算成本和中文混乱问题，中文混乱问题导致长文档中重要信息往往遗弃不了。为解决这些问题，本文提出了一种新的方法——提取然评估法，该方法首先从长源文档中提取关键句子，然后通过提问LLM进行评估。结果显示，提出的方法不仅有效减少评估成本，还与人工评估更高相关性。此外，我们还提供了优化文档长度和句子提取方法的实践建议，为LLM基于文本生成评估的成本减少而准确性提高作出贡献。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Attention-based-Encoder-decoder-Model-for-Efficient-Language-Model-Adaptation"><a href="#Hybrid-Attention-based-Encoder-decoder-Model-for-Efficient-Language-Model-Adaptation" class="headerlink" title="Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation"></a>Hybrid Attention-based Encoder-decoder Model for Efficient Language Model Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07369">http://arxiv.org/abs/2309.07369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoshi Ling, Guoli Ye, Rui Zhao, Yifan Gong</li>
<li>For: The paper is written for improving the text adaptation of attention-based encoder-decoder (AED) speech recognition models in industry settings.* Methods: The paper proposes a novel hybrid attention-based encoder-decoder (HAED) speech recognition model that separates the acoustic and language models, allowing for the use of conventional text-based language model adaptation techniques.* Results: The proposed HAED model yields 21% Word Error Rate (WER) improvements in relative when out-of-domain text data is used for language model adaptation, and with only a minor degradation in WER on a general test set compared with conventional AED models.Here’s the information in Simplified Chinese text:* For: 该论文是为了改进 attention-based encoder-decoder (AED) 语音识别模型在实际应用中的文本适应性。* Methods: 论文提出了一种新的 hybrid attention-based encoder-decoder (HAED) 语音识别模型，该模型将语音模型和语言模型分离开来，使得可以使用 conventional 文本基于语言模型适应技术。* Results: 提议的 HAED 模型在使用 out-of-domain 文本数据进行语言模型适应时，相比 conventional AED 模型，可以提高 Word Error Rate (WER) 21%。在一般测试集上，HAED 模型只有一定的负面影响。<details>
<summary>Abstract</summary>
Attention-based encoder-decoder (AED) speech recognition model has been widely successful in recent years. However, the joint optimization of acoustic model and language model in end-to-end manner has created challenges for text adaptation. In particular, effectively, quickly and inexpensively adapting text has become a primary concern for deploying AED systems in industry. To address this issue, we propose a novel model, the hybrid attention-based encoder-decoder (HAED) speech recognition model that preserves the modularity of conventional hybrid automatic speech recognition systems. Our HAED model separates the acoustic and language models, allowing for the use of conventional text-based language model adaptation techniques. We demonstrate that the proposed HAED model yields 21\% Word Error Rate (WER) improvements in relative when out-of-domain text data is used for language model adaptation, and with only a minor degradation in WER on a general test set compared with conventional AED model.
</details>
<details>
<summary>摘要</summary>
听力基于Encoder-Decoder（AED）语音识别模型在最近几年内获得了广泛的成功。然而，在末端协调语音模型和语言模型的结合方面，有些挑战需要解决，特别是快速、效率地适应文本。为解决这个问题，我们提议一种新的模型，即混合注意力基于Encoder-Decoder（HAED）语音识别模型。我们的HAED模型分离了语音模型和语言模型，因此可以使用传统的文本基于语言模型适应技术。我们示出了我们提议的HAED模型可以在使用不同文本预测集时实现21%的单词错误率（WER）提升，并且在一般测试集上只受到轻微的WER下降，相比于传统的AED模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/cs.CL_2023_09_14/" data-id="clohum96j00dvpj881bij1mq8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/cs.LG_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T10:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/cs.LG_2023_09_14/">cs.LG - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-many-Neurons-do-we-need-A-refined-Analysis-for-Shallow-Networks-trained-with-Gradient-Descent"><a href="#How-many-Neurons-do-we-need-A-refined-Analysis-for-Shallow-Networks-trained-with-Gradient-Descent" class="headerlink" title="How many Neurons do we need? A refined Analysis for Shallow Networks trained with Gradient Descent"></a>How many Neurons do we need? A refined Analysis for Shallow Networks trained with Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08044">http://arxiv.org/abs/2309.08044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mike Nguyen, Nicole Mücke</li>
<li>for: 这篇论文旨在研究两层神经网络在神经归一化kernel（NTK） Régime中的泛化性能，使用梯度下降（GD）进行训练。</li>
<li>methods: 论文使用了梯度下降（GD）进行训练，并且在早停止GD的情况下 derive fast rates of convergence，这些速率被认为是非 Parametric regression in reproducing kernel Hilbert spaces中的最优性。</li>
<li>results: 论文表明，在训练过程中，权重会保持在初始化的周围，即 radius 取决于 Structural assumptions 如抽象函数的细节和 интеграル运算符的eigenvalue decay。<details>
<summary>Abstract</summary>
We analyze the generalization properties of two-layer neural networks in the neural tangent kernel (NTK) regime, trained with gradient descent (GD). For early stopped GD we derive fast rates of convergence that are known to be minimax optimal in the framework of non-parametric regression in reproducing kernel Hilbert spaces. On our way, we precisely keep track of the number of hidden neurons required for generalization and improve over existing results. We further show that the weights during training remain in a vicinity around initialization, the radius being dependent on structural assumptions such as degree of smoothness of the regression function and eigenvalue decay of the integral operator associated to the NTK.
</details>
<details>
<summary>摘要</summary>
我们分析两层神经网络在神经 Tangent 公式（NTK） режиме下的通用性特性，使用梯度下降（GD）进行训练。我们 derivate fast rates of convergence，这些率已知为非 Parametric 回归中极值优化的框架中的最优化率。在我们的路径上，我们精确地跟踪隐藏神经元数量所需的通用性，并超过现有结果。此外，我们还证明在训练过程中的权重保持在初始化附近，半径取决于干扰函数的度数平滑性和积分算子相关的谱值衰落。
</details></li>
</ul>
<hr>
<h2 id="On-Prediction-Feature-Assignment-in-the-Heckman-Selection-Model"><a href="#On-Prediction-Feature-Assignment-in-the-Heckman-Selection-Model" class="headerlink" title="On Prediction Feature Assignment in the Heckman Selection Model"></a>On Prediction Feature Assignment in the Heckman Selection Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08043">http://arxiv.org/abs/2309.08043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huy Mai, Xintao Wu</li>
<li>for:  Handle missing-not-at-random (MNAR) sample selection bias in prediction models.</li>
<li>methods:  Heckman selection model and its variants, with a novel data-driven framework called Heckman-FA to obtain prediction features.</li>
<li>results:  Robust regression model under MNAR sample selection bias, using experimental results on real-world datasets.Here’s the full text in Simplified Chinese:</li>
<li>for:  Handle missing-not-at-random (MNAR) 样本选择偏见在预测模型中。</li>
<li>methods:  Heckman选择模型及其变种，使用novel数据驱动框架called Heckman-FA获取预测特征。</li>
<li>results:  Robust预测模型 unter MNAR样本选择偏见，使用实验结果在实际数据集上。<details>
<summary>Abstract</summary>
Under missing-not-at-random (MNAR) sample selection bias, the performance of a prediction model is often degraded. This paper focuses on one classic instance of MNAR sample selection bias where a subset of samples have non-randomly missing outcomes. The Heckman selection model and its variants have commonly been used to handle this type of sample selection bias. The Heckman model uses two separate equations to model the prediction and selection of samples, where the selection features include all prediction features. When using the Heckman model, the prediction features must be properly chosen from the set of selection features. However, choosing the proper prediction features is a challenging task for the Heckman model. This is especially the case when the number of selection features is large. Existing approaches that use the Heckman model often provide a manually chosen set of prediction features. In this paper, we propose Heckman-FA as a novel data-driven framework for obtaining prediction features for the Heckman model. Heckman-FA first trains an assignment function that determines whether or not a selection feature is assigned as a prediction feature. Using the parameters of the trained function, the framework extracts a suitable set of prediction features based on the goodness-of-fit of the prediction model given the chosen prediction features and the correlation between noise terms of the prediction and selection equations. Experimental results on real-world datasets show that Heckman-FA produces a robust regression model under MNAR sample selection bias.
</details>
<details>
<summary>摘要</summary>
Under missing-not-at-random (MNAR) 样本选择偏见，预测模型的性能 oft 被降低。这篇论文关注了一个经典的 MNAR 样本选择偏见情况，其中一个子集样本有非Randomly missing 结果。赫克曼选择模型和其变种经常用来处理这种样本选择偏见。赫克曼模型使用两个分开的方程来模型预测和选择样本，其中选择特征包括所有预测特征。在使用赫克曼模型时，预测特征必须从选择特征中选择。然而，选择合适的预测特征是赫克曼模型中的一个挑战。这是特别是当数量很大的选择特征时。现有的方法通常使用手动选择预测特征。在这篇论文中，我们提出了一种新的数据驱动的 Heckman-FA 框架，用于获取适用的预测特征。Heckman-FA 首先训练一个分配函数，该函数确定一个选择特征是否被用作预测特征。使用该函数的参数，框架提取了一个适合的预测特征集，基于预测模型给出的准确性和选择特征之间的相关性。实验结果表明，Heckman-FA 在真实世界数据上生成了一个稳定的回归模型，并且在 MNAR 样本选择偏见情况下表现良好。
</details></li>
</ul>
<hr>
<h2 id="USM-SCD-Multilingual-Speaker-Change-Detection-Based-on-Large-Pretrained-Foundation-Models"><a href="#USM-SCD-Multilingual-Speaker-Change-Detection-Based-on-Large-Pretrained-Foundation-Models" class="headerlink" title="USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained Foundation Models"></a>USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08023">http://arxiv.org/abs/2309.08023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanlong Zhao, Yongqiang Wang, Jason Pelecanos, Yu Zhang, Hank Liao, Yiling Huang, Han Lu, Quan Wang</li>
<li>For: The paper is written for detecting speaker changes and performing automatic speech recognition (ASR) for 96 languages.* Methods: The paper uses a multilingual speaker change detection model (USM-SCD) that is adapted from a speech foundation model trained on a large quantity of supervised and unsupervised data. The model is fine-tuned for the downstream task of speaker change detection and ASR.* Results: The USM-SCD model achieves more than 75% average speaker change detection F1 score across a test set of 96 languages, with an 85.8% speaker change detection F1 score on American English. The model also exhibits state-of-the-art ASR quality compared to a strong public ASR baseline, making it suitable for handling both tasks with negligible additional computational cost.<details>
<summary>Abstract</summary>
We introduce a multilingual speaker change detection model (USM-SCD) that can simultaneously detect speaker turns and perform ASR for 96 languages. This model is adapted from a speech foundation model trained on a large quantity of supervised and unsupervised data, demonstrating the utility of fine-tuning from a large generic foundation model for a downstream task. We analyze the performance of this multilingual speaker change detection model through a series of ablation studies. We show that the USM-SCD model can achieve more than 75% average speaker change detection F1 score across a test set that consists of data from 96 languages. On American English, the USM-SCD model can achieve an 85.8% speaker change detection F1 score across various public and internal test sets, beating the previous monolingual baseline model by 21% relative. We also show that we only need to fine-tune one-quarter of the trainable model parameters to achieve the best model performance. The USM-SCD model exhibits state-of-the-art ASR quality compared with a strong public ASR baseline, making it suitable to handle both tasks with negligible additional computational cost.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个多语言说话变化检测模型（USM-SCD），该模型可同时检测说话转移并进行ASR для 96种语言。该模型基于一个大量监督和无监督数据训练的语音基础模型，并示了将大型通用基础模型进行精度调整的利用性。我们通过一系列剥离研究分析了USM-SCD模型的性能。我们发现USM-SCD模型可以在96种语言测试集上达到75%以上的平均说话变化检测F1分数。在美国英语上，USM-SCD模型可以在不同的公共和内部测试集上达到85.8%的说话变化检测F1分数，比前一代单语言基线模型提高21%的Relative。我们还发现只需要调整模型参数的一半可以达到最佳模型性能。USM-SCD模型在ASR质量方面与一个强大的公共ASR基线模型相当，使其适合同时处理两个任务，计算成本几乎为零加上。
</details></li>
</ul>
<hr>
<h2 id="CRYPTO-MINE-Cryptanalysis-via-Mutual-Information-Neural-Estimation"><a href="#CRYPTO-MINE-Cryptanalysis-via-Mutual-Information-Neural-Estimation" class="headerlink" title="CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation"></a>CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08019">http://arxiv.org/abs/2309.08019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin D. Kim, Vipindev Adat Vasudevan, Jongchan Woo, Alejandro Cohen, Rafael G. L. D’Oliveira, Thomas Stahlbuhk, Muriel Médard</li>
<li>for: 评估密码系统的计算安全性</li>
<li>methods: 使用神经网络来估计密码系统中文本和密文之间的共同信息</li>
<li>results: 对多种加密算法和基准方法进行实验分析，并研究输入分布与信息泄露之间的关系<details>
<summary>Abstract</summary>
The use of Mutual Information (MI) as a measure to evaluate the efficiency of cryptosystems has an extensive history. However, estimating MI between unknown random variables in a high-dimensional space is challenging. Recent advances in machine learning have enabled progress in estimating MI using neural networks. This work presents a novel application of MI estimation in the field of cryptography. We propose applying this methodology directly to estimate the MI between plaintext and ciphertext in a chosen plaintext attack. The leaked information, if any, from the encryption could potentially be exploited by adversaries to compromise the computational security of the cryptosystem. We evaluate the efficiency of our approach by empirically analyzing multiple encryption schemes and baseline approaches. Furthermore, we extend the analysis to novel network coding-based cryptosystems that provide individual secrecy and study the relationship between information leakage and input distribution.
</details>
<details>
<summary>摘要</summary>
使用互讯信息（MI）作为加密系统的效率评估的历史悠久。然而，在高维空间中估计MI的挑战很大。现代机器学习技术的进步使得MI估计使用神经网络得到进展。本工作提出了一种应用MI估计的新方法，直接用于计算文本和加密文本之间的MI。如果有任何泄露信息，可能会被敌方利用来损害加密系统的计算安全性。我们通过实验分析多种加密方案和基eline方法来评估我们的方法的效率。此外，我们将分析新的网络编码基于加密系统，并研究输入分布与信息泄露之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Folding-Attention-Memory-and-Power-Optimization-for-On-Device-Transformer-based-Streaming-Speech-Recognition"><a href="#Folding-Attention-Memory-and-Power-Optimization-for-On-Device-Transformer-based-Streaming-Speech-Recognition" class="headerlink" title="Folding Attention: Memory and Power Optimization for On-Device Transformer-based Streaming Speech Recognition"></a>Folding Attention: Memory and Power Optimization for On-Device Transformer-based Streaming Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07988">http://arxiv.org/abs/2309.07988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Liangzhen Lai, Yuan Shangguan, Forrest N. Iandola, Ernie Chang, Yangyang Shi, Vikas Chandra</li>
<li>for: 这篇论文的目的是优化Transformer数据准确度模型，以提高声识别器的效率和可携性。</li>
<li>methods: 本文使用了一种名为“folding attention”的技术，对于 linear projection layers 进行了优化，以减少模型的大小和计算量，同时不影响模型的准确度和计算过程。</li>
<li>results: 实验结果显示，使用“folding attention”技术可以将模型的大小（以及相应的内存消耗）降低到24%，并且降低了电源消耗到23%，而且无需妥协模型的准确度或计算过程。<details>
<summary>Abstract</summary>
Transformer-based models excel in speech recognition. Existing efforts to optimize Transformer inference, typically for long-context applications, center on simplifying attention score calculations. However, streaming speech recognition models usually process a limited number of tokens each time, making attention score calculation less of a bottleneck. Instead, the bottleneck lies in the linear projection layers of multi-head attention and feedforward networks, constituting a substantial portion of the model size and contributing significantly to computation, memory, and power usage.   To address this bottleneck, we propose folding attention, a technique targeting these linear layers, significantly reducing model size and improving memory and power efficiency. Experiments on on-device Transformer-based streaming speech recognition models show that folding attention reduces model size (and corresponding memory consumption) by up to 24% and power consumption by up to 23%, all without compromising model accuracy or computation overhead.
</details>
<details>
<summary>摘要</summary>
具有转换器基于模型的模型在语音识别方面表现出色。现有的优化转换器推理，通常是为长上下文应用，围绕简化关注分数计算。然而，流动语音识别模型通常每次处理的令牌数相对较少，因此关注分数计算不是瓶颈。相反，瓶颈在多头注意力和feedforward网络的线性投影层上，这些层占据了模型大小的较大比例，并且对计算、内存和能源使用做出了重要贡献。为解决这个瓶颈，我们提出了“叠加注意力”技术， Targeting these linear layers, this technique significantly reduces the model size and improves memory and power efficiency. Our experiments on on-device Transformer-based streaming speech recognition models show that folding attention reduces model size (and corresponding memory consumption) by up to 24% and power consumption by up to 23%, all without compromising model accuracy or computation overhead.
</details></li>
</ul>
<hr>
<h2 id="SLMIA-SR-Speaker-Level-Membership-Inference-Attacks-against-Speaker-Recognition-Systems"><a href="#SLMIA-SR-Speaker-Level-Membership-Inference-Attacks-against-Speaker-Recognition-Systems" class="headerlink" title="SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems"></a>SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07983">http://arxiv.org/abs/2309.07983</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s3l-official/slmia-sr">https://github.com/s3l-official/slmia-sr</a></li>
<li>paper_authors: Guangke Chen, Yedi Zhang, Fu Song</li>
<li>for: 这个论文的目的是提出一种特有的会员推测攻击（Membership Inference Attack），用于 speaker recognition（SR）领域。</li>
<li>methods: 这个攻击使用了两个特征组合体 engineering 来量化训练和非训练 speaker 之间的差异，并通过一种新的混合比例训练策略来提高攻击效果。</li>
<li>results: 实验表明，这个攻击能够成功地判断 SR 模型中是否包含特定的声音例子，并且可以在白卷和黑卷场景下进行。此外，攻击还可以采用两种新的技术来降低黑卷查询数量。<details>
<summary>Abstract</summary>
Membership inference attacks allow adversaries to determine whether a particular example was contained in the model's training dataset. While previous works have confirmed the feasibility of such attacks in various applications, none has focused on speaker recognition (SR), a promising voice-based biometric recognition technique. In this work, we propose SLMIA-SR, the first membership inference attack tailored to SR. In contrast to conventional example-level attack, our attack features speaker-level membership inference, i.e., determining if any voices of a given speaker, either the same as or different from the given inference voices, have been involved in the training of a model. It is particularly useful and practical since the training and inference voices are usually distinct, and it is also meaningful considering the open-set nature of SR, namely, the recognition speakers were often not present in the training data. We utilize intra-closeness and inter-farness, two training objectives of SR, to characterize the differences between training and non-training speakers and quantify them with two groups of features driven by carefully-established feature engineering to mount the attack. To improve the generalizability of our attack, we propose a novel mixing ratio training strategy to train attack models. To enhance the attack performance, we introduce voice chunk splitting to cope with the limited number of inference voices and propose to train attack models dependent on the number of inference voices. Our attack is versatile and can work in both white-box and black-box scenarios. Additionally, we propose two novel techniques to reduce the number of black-box queries while maintaining the attack performance. Extensive experiments demonstrate the effectiveness of SLMIA-SR.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译成简化中文。<<SYS>> membrane 攻击允许敌对者确定一个特定的示例是否包含在模型的训练数据集中。 先前的工作已经证明了这种攻击的可行性在多种应用场景中，但没有关注 speaker recognition（SR），一种有前途的语音基于生物认证技术。在这项工作中，我们提出了 SLMIA-SR，首个针对 SR 的成员推断攻击。与传统的示例级攻击不同，我们的攻击具有 speaker 级成员推断，即确定一个给定的推断声音是否在模型训练中出现过。这是非常有用和实用的，因为训练和推断声音通常不同，而 SR 的开放集成特性也使得这种攻击有意义。我们利用 SR 的内部亲缘和外部远离两个训练目标，将不同的声音分类为两组特征驱动了精心设计的特征工程，以进行攻击。为了提高攻击的通用性，我们提出了一种新的混合比例训练策略。为了提高攻击性能，我们引入了声音块拼接技术，并根据推断声音的数量进行模型训练。我们的攻击可以在白盒和黑盒两种enario下进行。此外，我们还提出了两种新的黑盒查询数量减少技术，以保持攻击性能。我们的实验证明了 SLMIA-SR 的有效性。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-quantification-for-learned-ISTA"><a href="#Uncertainty-quantification-for-learned-ISTA" class="headerlink" title="Uncertainty quantification for learned ISTA"></a>Uncertainty quantification for learned ISTA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07982">http://arxiv.org/abs/2309.07982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frederik Hoppe, Claudio Mayrink Verdun, Felix Krahmer, Hannah Laus, Holger Rauhut</li>
<li>for: 这篇论文主要是为了解决 inverse problems 中的问题，通过 integrate 数学模型和深度学习技术，以提高问题的解决效率和可解释性。</li>
<li>methods: 这篇论文使用了 algorithm unrolling schemes 这种模型基于深度学习技术，并将具有解释性的 prior domain knowledge 纳入训练过程中。</li>
<li>results: 这篇论文提出了一种可以获得 confidence intervals 的方法，以便在解决 inverse problems 中提高 uncertainty quantification 的能力。<details>
<summary>Abstract</summary>
Model-based deep learning solutions to inverse problems have attracted increasing attention in recent years as they bridge state-of-the-art numerical performance with interpretability. In addition, the incorporated prior domain knowledge can make the training more efficient as the smaller number of parameters allows the training step to be executed with smaller datasets. Algorithm unrolling schemes stand out among these model-based learning techniques. Despite their rapid advancement and their close connection to traditional high-dimensional statistical methods, they lack certainty estimates and a theory for uncertainty quantification is still elusive. This work provides a step towards closing this gap proposing a rigorous way to obtain confidence intervals for the LISTA estimator.
</details>
<details>
<summary>摘要</summary>
numerical 性能与解释性之间的桥梁是基于深度学习的模型解 inverse 问题，它们在解决高维统计方法的问题上具有优势。此外，结合域知识可以使训练更加效率，因为 fewer 参数使得训练步骤可以使用 smaller datasets。algorithm 折叠方案在这些模型学习技术中占据主导地位。 despite  their rapid advancement and their close connection to traditional high-dimensional statistical methods, they lack certainty estimates and a theory for uncertainty quantification is still elusive. This work provides a step towards closing this gap by proposing a rigorous way to obtain confidence intervals for the LISTA estimator.Note: Please keep in mind that the translation is done using a machine translation tool, and the quality of the translation may vary.
</details></li>
</ul>
<hr>
<h2 id="Improving-physics-informed-DeepONets-with-hard-constraints"><a href="#Improving-physics-informed-DeepONets-with-hard-constraints" class="headerlink" title="Improving physics-informed DeepONets with hard constraints"></a>Improving physics-informed DeepONets with hard constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07899">http://arxiv.org/abs/2309.07899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rüdiger Brecht, Dmytro R. Popovych, Alex Bihlo, Roman O. Popovych</li>
<li>for: 提高现有物理学 Informed（标准或运算员）神经网络的精度，使其不需要准确地学习系统的初始条件。</li>
<li>methods: 提议使用Physics-Informed Deep Learning（PIDL）策略，使得初始条件不需要被学习，并且 garantia 预测解的连续性。</li>
<li>results: PIDL 策略可以提高现有物理学 Informed 神经网络的精度，并且可以确保预测解的连续性。<details>
<summary>Abstract</summary>
Current physics-informed (standard or operator) neural networks still rely on accurately learning the initial conditions of the system they are solving. In contrast, standard numerical methods evolve such initial conditions without needing to learn these. In this study, we propose to improve current physics-informed deep learning strategies such that initial conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a DeepONet is applied multiple times to time step a solution, the resulting function is continuous.
</details>
<details>
<summary>摘要</summary>
当前的物理学 informed (标准或运算符) 神经网络仍然需要准确地学习系统的初始条件。相比之下，标准的数学方法会自动演化这些初始条件而不需要学习。在本研究中，我们提议改进当前的物理学 informed 深度学习策略，使得初始条件不需要被学习，并且在预测解的过程中被 precisiely 表示。此外，这种方法 garantía 当 DeepONet 被应用多次来步骤解 solution，得到的函数是连续的。
</details></li>
</ul>
<hr>
<h2 id="Choosing-a-Proxy-Metric-from-Past-Experiments"><a href="#Choosing-a-Proxy-Metric-from-Past-Experiments" class="headerlink" title="Choosing a Proxy Metric from Past Experiments"></a>Choosing a Proxy Metric from Past Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07893">http://arxiv.org/abs/2309.07893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilesh Tripuraneni, Lee Richardson, Alexander D’Amour, Jacopo Soriano, Steve Yadlowsky</li>
<li>for: 这个论文的目的是提出一种新的统计框架，用于在Homogeneous population的随机实验中定义和构建优化的代理指标。</li>
<li>methods: 这个框架首先将在给定实验中构建优化代理指标转化为一个股票优化问题，这个问题取决于实验中真实的潜在治疗效果和噪声水平。然后，通过对历史 Randomized 实验中的观察治疗效果和代理指标进行减噪处理，提取实验中的潜在治疗效果估计。</li>
<li>results: 这个框架的实现和评估基于一个大量的Randomized 实验 Corpora，并构建了一些高效的代理指标，与多个基elines compare favorably。<details>
<summary>Abstract</summary>
In many randomized experiments, the treatment effect of the long-term metric (i.e. the primary outcome of interest) is often difficult or infeasible to measure. Such long-term metrics are often slow to react to changes and sufficiently noisy they are challenging to faithfully estimate in short-horizon experiments. A common alternative is to measure several short-term proxy metrics in the hope they closely track the long-term metric -- so they can be used to effectively guide decision-making in the near-term. We introduce a new statistical framework to both define and construct an optimal proxy metric for use in a homogeneous population of randomized experiments. Our procedure first reduces the construction of an optimal proxy metric in a given experiment to a portfolio optimization problem which depends on the true latent treatment effects and noise level of experiment under consideration. We then denoise the observed treatment effects of the long-term metric and a set of proxies in a historical corpus of randomized experiments to extract estimates of the latent treatment effects for use in the optimization problem. One key insight derived from our approach is that the optimal proxy metric for a given experiment is not apriori fixed; rather it should depend on the sample size (or effective noise level) of the randomized experiment for which it is deployed. To instantiate and evaluate our framework, we employ our methodology in a large corpus of randomized experiments from an industrial recommendation system and construct proxy metrics that perform favorably relative to several baselines.
</details>
<details>
<summary>摘要</summary>
很多随机实验中，长期指标（即首要评估目标）的治疗效果很难或不可能量度。这些长期指标通常需要时间才能响应变化，并且具有较高的噪音水平，使其 faithful 地估计困难。为了解决这个问题，我们常常会测量一些短期代理指标，以便它们可以尽可能地跟踪长期指标，从而用于决策。我们介绍了一种新的统计框架，用于在同质人口中的随机实验中定义和构建优化的代理指标。我们的过程将在给定实验中构建优化的代理指标降低到一个股票优化问题，这个问题取决于实验中真实的潜在治疗效果和噪音水平。然后，我们将历史 Randomized 实验中观察到的治疗效果和代理指标进行滤波，以提取用于优化问题的 latent 治疗效果估计。我们的研究显示，用于某个实验的优化代理指标不是先验定义的，而是基于实验中样本大小（或有效噪音水平）。为了实现和评估我们的框架，我们使用我们的方法在一个大量的Randomized实验 Corpora中进行实践和评估。我们的结果表明，我们的方法可以在这些实验中建立高效的代理指标，并且相比于多种基准，它们表现良好。
</details></li>
</ul>
<hr>
<h2 id="Some-notes-concerning-a-generalized-KMM-type-optimization-method-for-density-ratio-estimation"><a href="#Some-notes-concerning-a-generalized-KMM-type-optimization-method-for-density-ratio-estimation" class="headerlink" title="Some notes concerning a generalized KMM-type optimization method for density ratio estimation"></a>Some notes concerning a generalized KMM-type optimization method for density ratio estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07887">http://arxiv.org/abs/2309.07887</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cdalecsa/generalized-kmm">https://github.com/cdalecsa/generalized-kmm</a></li>
<li>paper_authors: Cristian Daniel Alecsa</li>
<li>for: 本研究は密集度比估算のための新たな优化算法を引入します。</li>
<li>methods: 本研究では、KMM法の拡张に基づいて、适切な损失函数を构筑し、密集度比估算に対する更加一般的な Situationをカバーすることを目的としています。</li>
<li>results: 本研究では、适切な损失函数を用いて密集度比估算を行い、训练データおよびテストデータの密集度比を推定することができました。<details>
<summary>Abstract</summary>
In the present paper we introduce new optimization algorithms for the task of density ratio estimation. More precisely, we consider extending the well-known KMM method using the construction of a suitable loss function, in order to encompass more general situations involving the estimation of density ratio with respect to subsets of the training data and test data, respectively. The associated codes can be found at https://github.com/CDAlecsa/Generalized-KMM.
</details>
<details>
<summary>摘要</summary>
现在的论文中，我们介绍了一些新的优化算法用于概率比率估计任务。更加准确地说，我们考虑将广泛known的KMM方法扩展，通过构建适当的损失函数，以涵盖更加一般的情况，即对于训练数据和测试数据中的子集的概率比率估计。相关的代码可以在https://github.com/CDAlecsa/Generalized-KMM中找到。
</details></li>
</ul>
<hr>
<h2 id="Identifying-the-Group-Theoretic-Structure-of-Machine-Learned-Symmetries"><a href="#Identifying-the-Group-Theoretic-Structure-of-Machine-Learned-Symmetries" class="headerlink" title="Identifying the Group-Theoretic Structure of Machine-Learned Symmetries"></a>Identifying the Group-Theoretic Structure of Machine-Learned Symmetries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07860">http://arxiv.org/abs/2309.07860</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roy T. Forestano, Konstantin T. Matchev, Katia Matcheva, Alexander Roman, Eyup B. Unlu, Sarunas Verner</li>
<li>for: 这篇论文是用于探讨和识别深度学习中潜在的群论变换的方法。</li>
<li>methods: 这篇论文提出了一些方法来检查和识别深度学习中的机器学习约束的群论结构。它们包括在深度学习阶段或后续处理阶段使用损失函数来探讨子代数结构。</li>
<li>results: 这篇论文通过使用示例来说明了这些方法的效果，并应用到了粒子物理中的SU(3)和SU(5)非阿贝尔 gauge Symmetries的破碎。<details>
<summary>Abstract</summary>
Deep learning was recently successfully used in deriving symmetry transformations that preserve important physics quantities. Being completely agnostic, these techniques postpone the identification of the discovered symmetries to a later stage. In this letter we propose methods for examining and identifying the group-theoretic structure of such machine-learned symmetries. We design loss functions which probe the subalgebra structure either during the deep learning stage of symmetry discovery or in a subsequent post-processing stage. We illustrate the new methods with examples from the U(n) Lie group family, obtaining the respective subalgebra decompositions. As an application to particle physics, we demonstrate the identification of the residual symmetries after the spontaneous breaking of non-Abelian gauge symmetries like SU(3) and SU(5) which are commonly used in model building.
</details>
<details>
<summary>摘要</summary>
深度学习最近成功地应用于找到保留重要物理量的同态变换。这些技术完全无知，在后续阶段确定发现的同态性。在这封信中，我们提议用于检查和识别深度学习learned的同态性的方法。我们设计损失函数，在深度学习阶段或后续处理阶段探索同态性的子代数结构。我们通过使用U(n)李群家族的例子，获得相应的子代数分解。在素 particles physics中，我们示例了在非阿贝尔 gaugeSymmetries的自发性折损后剩下的 residual symmetries。Here's the translation in Traditional Chinese:深度学习最近成功地应用于找到保留重要物理量的同态变换。这些技术完全无知，在后续阶段确定发现的同态性。在这封信中，我们提议用于检查和识别深度学习learned的同态性的方法。我们设计损失函数，在深度学习阶段或后续处理阶段探索同态性的子代数结构。我们通过使用U(n)李群家族的例子，获得相应的子代数分解。在素粒子物理中，我们示例了在非阿贝尔 gaugeSymmetries的自发性折损后剩下的 residual symmetries。
</details></li>
</ul>
<hr>
<h2 id="Complex-Valued-Neural-Networks-for-Data-Driven-Signal-Processing-and-Signal-Understanding"><a href="#Complex-Valued-Neural-Networks-for-Data-Driven-Signal-Processing-and-Signal-Understanding" class="headerlink" title="Complex-Valued Neural Networks for Data-Driven Signal Processing and Signal Understanding"></a>Complex-Valued Neural Networks for Data-Driven Signal Processing and Signal Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07948">http://arxiv.org/abs/2309.07948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josiah W. Smith</li>
<li>for: 这份研究是为了提供一个基于 PyTorch 的复值神经网络库，并且提供轻量级的界面 для 复值神经网络操作和架构。</li>
<li>methods: 本研究使用了 PyTorch 库，并提供了一些常用的复值神经网络操作和架构，包括线性层、核函数层、注意力层、批训层和对称层等。此外，还包括一些常用的数据驱动模型化技术，例如批训层和对称层。</li>
<li>results: 本研究提供了一个轻量级的复值神经网络库，并且包括了一些高效的实现方式，例如 batchnorm 和 layernorm 等。此外，还包括了一些未被充分探索的曼哈频率-based 复值神经网络层，这些层在许多研究上显示了杰出的表现。<details>
<summary>Abstract</summary>
Complex-valued neural networks have emerged boasting superior modeling performance for many tasks across the signal processing, sensing, and communications arenas. However, developing complex-valued models currently demands development of basic deep learning operations, such as linear or convolution layers, as modern deep learning frameworks like PyTorch and Tensor flow do not adequately support complex-valued neural networks. This paper overviews a package built on PyTorch with the intention of implementing light-weight interfaces for common complex-valued neural network operations and architectures. Similar to natural language understanding (NLU), which as recently made tremendous leaps towards text-based intelligence, RF Signal Understanding (RFSU) is a promising field extending conventional signal processing algorithms using a hybrid approach of signal mechanics-based insight with data-driven modeling power. Notably, we include efficient implementations for linear, convolution, and attention modules in addition to activation functions and normalization layers such as batchnorm and layernorm. Additionally, we include efficient implementations of manifold-based complex-valued neural network layers that have shown tremendous promise but remain relatively unexplored in many research contexts. Although there is an emphasis on 1-D data tensors, due to a focus on signal processing, communications, and radar data, many of the routines are implemented for 2-D and 3-D data as well. Specifically, the proposed approach offers a useful set of tools and documentation for data-driven signal processing research and practical implementation.
</details>
<details>
<summary>摘要</summary>
复杂值神经网络在信号处理、感知和通信领域表现出了优秀的模型化能力。然而，开发复杂值模型目前需要开发基础的深度学习操作，如线性或核函数层，因为现代深度学习框架如PyTorch和TensorFlow等不充分支持复杂值神经网络。这篇论文介绍了基于PyTorch的一个包，旨在实现轻量级的复杂值神经网络操作和架构。与自然语言理解（NLU）一样，RF信号理解（RFSU）是一个有前途的领域，通过将信号机械学的视角与数据驱动模型的力量相结合，从传统的信号处理算法中扩展出来的。我们在这个包中提供了高效的线性、核函数、注意模块以及激活函数和 нормализаayer，以及一些未explored的复杂值神经网络层，如杯形正则和层正则。尽管我们主要关注1-D数据tensor，由于对信号处理、通信和雷达数据的ocus，许多routines也被实现为2-D和3-D数据。特别是，我们的方法提供了一套有用的工具和文档，供数据驱动的信号处理研究和实践中使用。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Warm-Start-Fixed-Point-Optimization-Algorithms"><a href="#Learning-to-Warm-Start-Fixed-Point-Optimization-Algorithms" class="headerlink" title="Learning to Warm-Start Fixed-Point Optimization Algorithms"></a>Learning to Warm-Start Fixed-Point Optimization Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07835">http://arxiv.org/abs/2309.07835</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stellatogrp/l2ws_fixed_point">https://github.com/stellatogrp/l2ws_fixed_point</a></li>
<li>paper_authors: Rajiv Sambharya, Georgina Hall, Brandon Amos, Bartolomeo Stellato</li>
<li>for: 这个论文旨在提出一种机器学习框架，用于优化固定点算法。</li>
<li>methods: 该框架包含一个神经网络，用于将问题参数转换为固定点启动值，然后进行一定数量的固定点迭代。文章提出了两个损失函数，用于将神经网络的输出与真实解做比较。</li>
<li>results: 通过应用这种框架，可以在控制、统计和信号处理等领域中，对固定点算法进行优化，并且可以减少解决问题所需的迭代次数和解决时间。<details>
<summary>Abstract</summary>
We introduce a machine-learning framework to warm-start fixed-point optimization algorithms. Our architecture consists of a neural network mapping problem parameters to warm starts, followed by a predefined number of fixed-point iterations. We propose two loss functions designed to either minimize the fixed-point residual or the distance to a ground truth solution. In this way, the neural network predicts warm starts with the end-to-end goal of minimizing the downstream loss. An important feature of our architecture is its flexibility, in that it can predict a warm start for fixed-point algorithms run for any number of steps, without being limited to the number of steps it has been trained on. We provide PAC-Bayes generalization bounds on unseen data for common classes of fixed-point operators: contractive, linearly convergent, and averaged. Applying this framework to well-known applications in control, statistics, and signal processing, we observe a significant reduction in the number of iterations and solution time required to solve these problems, through learned warm starts.
</details>
<details>
<summary>摘要</summary>
我团队引入一种机器学习框架，用于启动fixed-point优化算法。我们的架构包括一个神经网络，将问题参数映射到启动点，然后跟踪一定数量的固定点迭代。我们提出了两个损失函数，一个是将固定点剩余拟合到最小，另一个是将固定点与真实解偏移到最小。因此，神经网络预测的启动点的目的是将下游损失函数最小化。我们的架构的一个重要特点是其灵活性，可以预测任何数量的固定点迭代后的启动点，不受训练数据中的固定点迭代数量限制。我们提供了PAC-Bayes一致bounds，用于未经见过的数据集。在控制、统计和信号处理等应用中，我们发现通过学习的启动点，可以减少解决问题所需的迭代数和解决时间。
</details></li>
</ul>
<hr>
<h2 id="Directed-Scattering-for-Knowledge-Graph-based-Cellular-Signaling-Analysis"><a href="#Directed-Scattering-for-Knowledge-Graph-based-Cellular-Signaling-Analysis" class="headerlink" title="Directed Scattering for Knowledge Graph-based Cellular Signaling Analysis"></a>Directed Scattering for Knowledge Graph-based Cellular Signaling Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07813">http://arxiv.org/abs/2309.07813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aarthi Venkat, Joyce Chew, Ferran Cardoso Rodriguez, Christopher J. Tape, Michael Perlmutter, Smita Krishnaswamy</li>
<li>for: 这篇论文是为了描述一种新的推理方法，即指向散射自动编码器（DSAE），用于学习科学知识图的层次结构。</li>
<li>methods: 这种方法使用指向的几何散射变换，并结合自动编码器的非线性几何性和几何空间的几何性，来学习潜在层次结构。</li>
<li>results: 论文表明，使用DSAE方法可以在描述指向图的任务上表现出色，超过了许多其他方法。<details>
<summary>Abstract</summary>
Directed graphs are a natural model for many phenomena, in particular scientific knowledge graphs such as molecular interaction or chemical reaction networks that define cellular signaling relationships. In these situations, source nodes typically have distinct biophysical properties from sinks. Due to their ordered and unidirectional relationships, many such networks also have hierarchical and multiscale structure. However, the majority of methods performing node- and edge-level tasks in machine learning do not take these properties into account, and thus have not been leveraged effectively for scientific tasks such as cellular signaling network inference. We propose a new framework called Directed Scattering Autoencoder (DSAE) which uses a directed version of a geometric scattering transform, combined with the non-linear dimensionality reduction properties of an autoencoder and the geometric properties of the hyperbolic space to learn latent hierarchies. We show this method outperforms numerous others on tasks such as embedding directed graphs and learning cellular signaling networks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTDirected graphs are a natural model for many phenomena, in particular scientific knowledge graphs such as molecular interaction or chemical reaction networks that define cellular signaling relationships. In these situations, source nodes typically have distinct biophysical properties from sinks. Due to their ordered and unidirectional relationships, many such networks also have hierarchical and multiscale structure. However, the majority of methods performing node- and edge-level tasks in machine learning do not take these properties into account, and thus have not been leveraged effectively for scientific tasks such as cellular signaling network inference. We propose a new framework called Directed Scattering Autoencoder (DSAE) which uses a directed version of a geometric scattering transform, combined with the non-linear dimensionality reduction properties of an autoencoder and the geometric properties of the hyperbolic space to learn latent hierarchies. We show this method outperforms numerous others on tasks such as embedding directed graphs and learning cellular signaling networks.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Communication-Efficient-Private-Federated-Learning-Using-Dithering"><a href="#Communication-Efficient-Private-Federated-Learning-Using-Dithering" class="headerlink" title="Communication Efficient Private Federated Learning Using Dithering"></a>Communication Efficient Private Federated Learning Using Dithering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07809">http://arxiv.org/abs/2309.07809</a></li>
<li>repo_url: None</li>
<li>paper_authors: Burak Hasircioglu, Deniz Gunduz</li>
<li>for: 保护隐私 während 确保有效的通信</li>
<li>methods: 使用 subtractive dithering 量化方法实现</li>
<li>results: 实验结果表明，我们的方法可以保持与其他客户端的隐私相同水平，同时减少了通信量，并且准确率与使用全精度Gradient方法相同。<details>
<summary>Abstract</summary>
The task of preserving privacy while ensuring efficient communication is a fundamental challenge in federated learning. In this work, we tackle this challenge in the trusted aggregator model, and propose a solution that achieves both objectives simultaneously. We show that employing a quantization scheme based on subtractive dithering at the clients can effectively replicate the normal noise addition process at the aggregator. This implies that we can guarantee the same level of differential privacy against other clients while substantially reducing the amount of communication required, as opposed to transmitting full precision gradients and using central noise addition. We also experimentally demonstrate that the accuracy of our proposed approach matches that of the full precision gradient method.
</details>
<details>
<summary>摘要</summary>
federated learning 中保护隐私的任务是一个基本挑战，我们在可信汇聚模型中解决了这个问题，并提出了同时实现隐私和效率通信的解决方案。我们表明，在客户端使用基于减准的抖动 quantization scheme 可以有效地重现在汇聚器中添加正常噪声的过程。这意味着我们可以对其他客户端保持同样的隐私保护水平，同时减少了与汇聚器之间的通信量，相比于将全精度梯度传输和使用中央噪声添加。我们还经验证了我们的提议方法和全精度梯度方法的准确性相同。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-is-in-the-Mind-of-the-Beholder-A-Causal-Framework-for-Human-interpretable-Representation-Learning"><a href="#Interpretability-is-in-the-Mind-of-the-Beholder-A-Causal-Framework-for-Human-interpretable-Representation-Learning" class="headerlink" title="Interpretability is in the Mind of the Beholder: A Causal Framework for Human-interpretable Representation Learning"></a>Interpretability is in the Mind of the Beholder: A Causal Framework for Human-interpretable Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07742">http://arxiv.org/abs/2309.07742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emanuele Marconato, Andrea Passerini, Stefano Teso</li>
<li>for: 本研究旨在提供一个数学框架，以便获取可解释的表示，并且适用于后期解释和基于概念的神经网络。</li>
<li>methods: 本研究使用了 causal 表示学习的最新进展，并且直接模型了人类投资者的元素。这允许我们获取一个原则性的可解释性概念，并且与人类的概念词汇相互对应。</li>
<li>results: 本研究提出了一个名为“名称转移游戏”的概念，用于连结了解可解释性和可读性。此外，我们还证明了可解释性和概念泄露之间的关联，以及内容Style分类的关联。<details>
<summary>Abstract</summary>
Focus in Explainable AI is shifting from explanations defined in terms of low-level elements, such as input features, to explanations encoded in terms of interpretable concepts learned from data. How to reliably acquire such concepts is, however, still fundamentally unclear. An agreed-upon notion of concept interpretability is missing, with the result that concepts used by both post-hoc explainers and concept-based neural networks are acquired through a variety of mutually incompatible strategies. Critically, most of these neglect the human side of the problem: a representation is understandable only insofar as it can be understood by the human at the receiving end. The key challenge in Human-interpretable Representation Learning (HRL) is how to model and operationalize this human element. In this work, we propose a mathematical framework for acquiring interpretable representations suitable for both post-hoc explainers and concept-based neural networks. Our formalization of HRL builds on recent advances in causal representation learning and explicitly models a human stakeholder as an external observer. This allows us to derive a principled notion of alignment between the machine representation and the vocabulary of concepts understood by the human. In doing so, we link alignment and interpretability through a simple and intuitive name transfer game, and clarify the relationship between alignment and a well-known property of representations, namely disentanglment. We also show that alignment is linked to the issue of undesirable correlations among concepts, also known as concept leakage, and to content-style separation, all through a general information-theoretic reformulation of these properties. Our conceptualization aims to bridge the gap between the human and algorithmic sides of interpretability and establish a stepping stone for new research on human-interpretable representations.
</details>
<details>
<summary>摘要</summary>
Focus in Explainable AI 是从低级元素定义的解释向解释编码在数据上学来的可解释概念移植。然而，如何可靠地获得这些概念仍然是一个不清楚的问题。无共识的概念可解释性存在，导致使用 post-hoc 解释器和基于神经网络的概念网络的概念都是通过不同的、互不兼容的策略获得的。然而，大多数情况忽略了人类的问题：一个表示只有在人类接收端可以理解。人类可解释表示学习的关键挑战在于如何模型和实现这个人类元素。在这种工作中，我们提出了一种数学框架，用于获得适用于 post-hoc 解释器和基于神经网络的可解释表示。我们的 HRL  formalization 基于 recent Advances in causal representation learning，并直接模型了人类股东。这使得我们可以 derivation 一种原则性的对机器表示和人类理解的词汇之间的协调。在这样做之前，我们将 alignment 和可解释性联系起来，通过一个简单直观的名称传递游戏，并将 alignment 与知名的表示性质联系起来。我们还表明了协调与潜在的概念泄露问题和内容风格分离问题之间的联系， alles durch eine allgemeine information-theoretische Reformulierung dieser Eigenschaften。我们的概念化旨在跨越人类和算法两侧的可解释性，建立一个新的研究领域，即人类可解释表示。
</details></li>
</ul>
<hr>
<h2 id="Slow-Invariant-Manifolds-of-Singularly-Perturbed-Systems-via-Physics-Informed-Machine-Learning"><a href="#Slow-Invariant-Manifolds-of-Singularly-Perturbed-Systems-via-Physics-Informed-Machine-Learning" class="headerlink" title="Slow Invariant Manifolds of Singularly Perturbed Systems via Physics-Informed Machine Learning"></a>Slow Invariant Manifolds of Singularly Perturbed Systems via Physics-Informed Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07946">http://arxiv.org/abs/2309.07946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitrios G. Patsatzis, Gianluca Fabiani, Lucia Russo, Constantinos Siettos</li>
<li>for: 该论文旨在提出一种基于物理信息的机器学习（PIML）方法，用于近似稳定演化涉及的各种系统中的慢演化替换（SIMs）。</li>
<li>methods: 该方法使用了两种神经网络结构，即逻辑神经网络（FNNs）和随机投影神经网络（RPNNs），并使用了符号计算来计算学习过程中所需的梯度。</li>
<li>results: 该方法可以提供与传统GSPT基于方法相等或更高的准确性，并且不受杂态参数的大小影响。此外，该方法的计算成本比Symbolic、自动和数值近似方法更低。<details>
<summary>Abstract</summary>
We present a physics-informed machine-learning (PIML) approach for the approximation of slow invariant manifolds (SIMs) of singularly perturbed systems, providing functionals in an explicit form that facilitate the construction and numerical integration of reduced order models (ROMs). The proposed scheme solves a partial differential equation corresponding to the invariance equation (IE) within the Geometric Singular Perturbation Theory (GSPT) framework. For the solution of the IE, we used two neural network structures, namely feedforward neural networks (FNNs), and random projection neural networks (RPNNs), with symbolic differentiation for the computation of the gradients required for the learning process. The efficiency of our PIML method is assessed via three benchmark problems, namely the Michaelis-Menten, the target mediated drug disposition reaction mechanism, and the 3D Sel'kov model. We show that the proposed PIML scheme provides approximations, of equivalent or even higher accuracy, than those provided by other traditional GSPT-based methods, and importantly, for any practical purposes, it is not affected by the magnitude of the perturbation parameter. This is of particular importance, as there are many systems for which the gap between the fast and slow timescales is not that big, but still ROMs can be constructed. A comparison of the computational costs between symbolic, automatic and numerical approximation of the required derivatives in the learning process is also provided.
</details>
<details>
<summary>摘要</summary>
我们提出了一种物理学 informative machine learning（PIML）方法，用于简单减少系统中的迟停态 manifold（SIM）的近似，并提供了一个明确的函数形式，以便建立和计算简化过程的简化模型（ROM）。我们的方案解决了对对称等式（IE）的解决方案在几何学上困难调适理论（GSPT）框架下。为解决IE，我们使用了两种神经网络结构， specifically feedforward neural networks（FNNs）和随机投射神经网络（RPNNs），并使用symbolic differentiations来计算学习过程中所需的梯度。我们评估了我们的PIML方法的效率，使用了三个问题作为测试：Michaelis-Menten、target mediated drug disposition reaction mechanism和3D Sel'kov model。我们发现，我们的PIML方法可以提供相等或更高的精度，并且不受 perturbation parameter的大小影响。这是特别重要的，因为有许多系统，其中速速态和慢态态之间的差距不大，但仍然可以建立ROM。我们还提供了 символіic、自动和数字approximation的计算成本比较。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Vector-Valued-Neural-Networks-and-Their-Relationship-with-Real-and-Hypercomplex-Valued-Neural-Networks"><a href="#Understanding-Vector-Valued-Neural-Networks-and-Their-Relationship-with-Real-and-Hypercomplex-Valued-Neural-Networks" class="headerlink" title="Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks"></a>Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07716">http://arxiv.org/abs/2309.07716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcos Eduardo Valle<br>for:* This paper presents a broad framework for vector-valued neural networks (V-nets) that can naturally consider the intercorrelation between feature channels.methods:* The paper explains the relationship between vector-valued and traditional neural networks, and shows how V-nets can be implemented in current deep-learning libraries as real-valued networks.results:* The paper provides a more robust training method for deep learning models by using vector-valued neural networks with fewer parameters.<details>
<summary>Abstract</summary>
Despite the many successful applications of deep learning models for multidimensional signal and image processing, most traditional neural networks process data represented by (multidimensional) arrays of real numbers. The intercorrelation between feature channels is usually expected to be learned from the training data, requiring numerous parameters and careful training. In contrast, vector-valued neural networks are conceived to process arrays of vectors and naturally consider the intercorrelation between feature channels. Consequently, they usually have fewer parameters and often undergo more robust training than traditional neural networks. This paper aims to present a broad framework for vector-valued neural networks, referred to as V-nets. In this context, hypercomplex-valued neural networks are regarded as vector-valued models with additional algebraic properties. Furthermore, this paper explains the relationship between vector-valued and traditional neural networks. Precisely, a vector-valued neural network can be obtained by placing restrictions on a real-valued model to consider the intercorrelation between feature channels. Finally, we show how V-nets, including hypercomplex-valued neural networks, can be implemented in current deep-learning libraries as real-valued networks.
</details>
<details>
<summary>摘要</summary>
尽管深度学习模型在多维信号和图像处理方面取得了多个成功应用，但大多数传统神经网络仍然处理由多维数组表示的实数据。通常情况下，神经网络在训练数据中学习Feature通道之间的相互关联，需要大量参数并且精心训练。相比之下，向量值神经网络是为处理向量数组而设计的，自然地考虑Feature通道之间的相互关联，通常具有 fewer parameters，并且训练更加稳定。这篇论文旨在提出一个抽象框架，用于描述向量值神经网络，被称为V-网络。在这个上下文中，幂复数值神经网络被视为向量值模型的一种特殊情况，具有附加的代数性质。此外，这篇论文还解释了向量值神经网络与传统神经网络之间的关系。具体来说，一个向量值神经网络可以通过对实数据进行限制，使其考虑Feature通道之间的相互关联。最后，我们展示了如何在当前深度学习库中实现V-网络，包括幂复数值神经网络。
</details></li>
</ul>
<hr>
<h2 id="Market-GAN-Adding-Control-to-Financial-Market-Data-Generation-with-Semantic-Context"><a href="#Market-GAN-Adding-Control-to-Financial-Market-Data-Generation-with-Semantic-Context" class="headerlink" title="Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context"></a>Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07708">http://arxiv.org/abs/2309.07708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochong Xia, Shuo Sun, Xinrun Wang, Bo An</li>
<li>for: 这个论文的目的是提高金融预测精度、管理风险和促进金融决策。</li>
<li>methods: 该论文提出了一种新的金融市场模拟方法，包括市场动力模型、动态时间戳拼接和生成对抗网络。</li>
<li>results: 论文在使用 Dow Jones 工业指数数据从 2000 年到 2023 年进行评估，并显示了与 4 种现有时间序列生成模型相比的超越性表现。<details>
<summary>Abstract</summary>
Financial simulators play an important role in enhancing forecasting accuracy, managing risks, and fostering strategic financial decision-making. Despite the development of financial market simulation methodologies, existing frameworks often struggle with adapting to specialized simulation context. We pinpoint the challenges as i) current financial datasets do not contain context labels; ii) current techniques are not designed to generate financial data with context as control, which demands greater precision compared to other modalities; iii) the inherent difficulties in generating context-aligned, high-fidelity data given the non-stationary, noisy nature of financial data. To address these challenges, our contributions are: i) we proposed the Contextual Market Dataset with market dynamics, stock ticker, and history state as context, leveraging a market dynamics modeling method that combines linear regression and Dynamic Time Warping clustering to extract market dynamics; ii) we present Market-GAN, a novel architecture incorporating a Generative Adversarial Networks (GAN) for the controllable generation with context, an autoencoder for learning low-dimension features, and supervisors for knowledge transfer; iii) we introduce a two-stage training scheme to ensure that Market-GAN captures the intrinsic market distribution with multiple objectives. In the pertaining stage, with the use of the autoencoder and supervisors, we prepare the generator with a better initialization for the adversarial training stage. We propose a set of holistic evaluation metrics that consider alignment, fidelity, data usability on downstream tasks, and market facts. We evaluate Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and showcase superior performance in comparison to 4 state-of-the-art time-series generative models.
</details>
<details>
<summary>摘要</summary>
金融模拟器在提高预测精度、管理风险和促进战略金融决策方面扮演着重要角色。despite the development of financial market simulation methodologies， existing frameworks often struggle with adapting to specialized simulation context. We identify the challenges as follows:1. current financial datasets do not contain context labels;2. current techniques are not designed to generate financial data with context as control, which demands greater precision compared to other modalities;3. the inherent difficulties in generating context-aligned, high-fidelity data given the non-stationary, noisy nature of financial data.To address these challenges, our contributions are as follows:1. we proposed the Contextual Market Dataset with market dynamics, stock ticker, and history state as context, leveraging a market dynamics modeling method that combines linear regression and Dynamic Time Warping clustering to extract market dynamics;2. we present Market-GAN, a novel architecture incorporating a Generative Adversarial Networks (GAN) for the controllable generation with context, an autoencoder for learning low-dimension features, and supervisors for knowledge transfer;3. we introduce a two-stage training scheme to ensure that Market-GAN captures the intrinsic market distribution with multiple objectives. In the first stage, with the use of the autoencoder and supervisors, we prepare the generator with a better initialization for the adversarial training stage.We propose a set of holistic evaluation metrics that consider alignment, fidelity, data usability on downstream tasks, and market facts. We evaluate Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and showcase superior performance in comparison to 4 state-of-the-art time-series generative models.
</details></li>
</ul>
<hr>
<h2 id="Causal-Entropy-and-Information-Gain-for-Measuring-Causal-Control"><a href="#Causal-Entropy-and-Information-Gain-for-Measuring-Causal-Control" class="headerlink" title="Causal Entropy and Information Gain for Measuring Causal Control"></a>Causal Entropy and Information Gain for Measuring Causal Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07703">http://arxiv.org/abs/2309.07703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francisco Nunes Ferreira Quialheiro Simoes, Mehdi Dastani, Thijs van Ommen</li>
<li>for: 本文旨在提出一种基于 causal 结构的信息理论量表示Feature Selection的方法，以提高模型的解释性。</li>
<li>methods: 本文提出了两种新的信息理论量： causal entropy 和 causal information gain，它们可以评估特定输出变量的 causal 影响。</li>
<li>results: 对比标准的共购信息， causal information gain 能够更好地揭示控制输出变量的特定特征。<details>
<summary>Abstract</summary>
Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed causal entropy and causal information gain, which are designed to assess how much control a feature provides over the outcome variable. These newly defined quantities capture changes in the entropy of a variable resulting from interventions on other variables. Fundamental results connecting these quantities to the existence of causal effects are derived. The use of causal information gain in feature selection is demonstrated, highlighting its superiority over standard mutual information in revealing which features provide control over a chosen outcome variable. Our investigation paves the way for the development of methods with improved interpretability in domains involving causation.
</details>
<details>
<summary>摘要</summary>
人工智能模型和方法通常缺乏 causal 解释力。尽管批处可解释机器学习（IML）方法得到了进步，它们经常将重要性归属于无关 causal 影响的输出变量。选择 causally 相关的特征 среди被这些方法认为是相关的特征，或者在模型训练之前进行选择，可以提供一个解决方案。基于信息理论量的特征选择方法已经成功地鉴定了统计上相关的特征。然而，这些信息理论量并不包含 causality，因此无法适用于这些情况。为解决这个挑战，本文提出了包含系统 causal 结构的信息理论量，可以用来评估特征对某个输出变量的 causal 重要性。specifically，我们引入 causal 版本的 entropy 和 mutual information，称为 causal  entropy 和 causal 信息增强，用于评估特征对输出变量的控制能力。这些新定义的量捕捉变量在其他变量的间接作用下的 entropy 变化。我们 derivation 了基本的结论，证明这些量与 causal 效应的存在有关。我们还示出了使用 causal 信息增强在特征选择中的优势， highlighting 它们可以更好地揭示选择输出变量的控制特征。我们的调查开创了用于在 causation 领域中提高解释力的方法的道路。
</details></li>
</ul>
<hr>
<h2 id="FedFNN-Faster-Training-Convergence-Through-Update-Predictions-in-Federated-Recommender-Systems"><a href="#FedFNN-Faster-Training-Convergence-Through-Update-Predictions-in-Federated-Recommender-Systems" class="headerlink" title="FedFNN: Faster Training Convergence Through Update Predictions in Federated Recommender Systems"></a>FedFNN: Faster Training Convergence Through Update Predictions in Federated Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08635">http://arxiv.org/abs/2309.08635</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Fabbri, Xianghang Liu, Jack R. McKenzie, Bartlomiej Twardowski, Tri Kurniawan Wijaya</li>
<li>for: 这篇论文的目的是提出一种加速分布式机器学习的算法，以提高在线个性化的时间效率，同时保持用户数据隐私。</li>
<li>methods: 这篇论文使用的方法是预测未被采样的用户的weight更新，使用采样集的更新来预测。</li>
<li>results: 这篇论文的实验结果显示，FedFNN可以比其他方法更快地完成分布式模型训练，并且可以维持或改善准确性。<details>
<summary>Abstract</summary>
Federated Learning (FL) has emerged as a key approach for distributed machine learning, enhancing online personalization while ensuring user data privacy. Instead of sending private data to a central server as in traditional approaches, FL decentralizes computations: devices train locally and share updates with a global server. A primary challenge in this setting is achieving fast and accurate model training - vital for recommendation systems where delays can compromise user engagement. This paper introduces FedFNN, an algorithm that accelerates decentralized model training. In FL, only a subset of users are involved in each training epoch. FedFNN employs supervised learning to predict weight updates from unsampled users, using updates from the sampled set. Our evaluations, using real and synthetic data, show: 1. FedFNN achieves training speeds 5x faster than leading methods, maintaining or improving accuracy; 2. the algorithm's performance is consistent regardless of client cluster variations; 3. FedFNN outperforms other methods in scenarios with limited client availability, converging more quickly.
</details>
<details>
<summary>摘要</summary>
分布式学习（FL）已成为分布式机器学习的关键方法，提高在线个性化而保护用户数据隐私。在传统方法中，用户的私人数据将被中央服务器发送，而在FL中，设备在本地进行计算，并将更新发送到全球服务器。在这种情况下，一个主要挑战是实现快速准确的模型训练——这对于推荐系统来说非常重要，因为延迟可能会影响用户的参与度。本文介绍了FedFNN算法，它可以加速分布式模型训练。在FL中，只有一 subset of 用户参与每次训练epoch。FedFNN使用supervised learning来预测unsampled 用户的weight更新，使用sampled set的更新进行预测。我们的评估，使用实际和synthetic数据，显示：1. FedFNN可以在5倍 бы于领先方法进行训练，保持或提高准确性;2. FedFNN的性能是客户端群集变化的不变的;3. FedFNN在有限客户可用情况下比其他方法更快 converges。
</details></li>
</ul>
<hr>
<h2 id="A-DenseNet-based-method-for-decoding-auditory-spatial-attention-with-EEG"><a href="#A-DenseNet-based-method-for-decoding-auditory-spatial-attention-with-EEG" class="headerlink" title="A DenseNet-based method for decoding auditory spatial attention with EEG"></a>A DenseNet-based method for decoding auditory spatial attention with EEG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07690">http://arxiv.org/abs/2309.07690</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuxiran/asad_densenet">https://github.com/xuxiran/asad_densenet</a></li>
<li>paper_authors: Xiran Xu, Bo Wang, Yujie Yan, Xihong Wu, Jing Chen</li>
<li>For: The paper aims to improve the performance of auditory spatial attention detection (ASAD) using a 3D deep convolutional neural network (DenseNet-3D) to extract temporal and spatial features of the neural representation for the attended locations.* Methods: The proposed method transforms the original EEG channels into a 2D spatial topological map and then uses a 3D DenseNet to extract temporal and spatial features of the neural representation for the attended locations.* Results: The proposed method achieves higher decoding accuracy than the state-of-the-art (SOTA) method (94.4% compared to XANet’s 90.6%) with a 1-second decision window for the widely used KULeuven (KUL) dataset.<details>
<summary>Abstract</summary>
Auditory spatial attention detection (ASAD) aims to decode the attended spatial location with EEG in a multiple-speaker setting. ASAD methods are inspired by the brain lateralization of cortical neural responses during the processing of auditory spatial attention, and show promising performance for the task of auditory attention decoding (AAD) with neural recordings. In the previous ASAD methods, the spatial distribution of EEG electrodes is not fully exploited, which may limit the performance of these methods. In the present work, by transforming the original EEG channels into a two-dimensional (2D) spatial topological map, the EEG data is transformed into a three-dimensional (3D) arrangement containing spatial-temporal information. And then a 3D deep convolutional neural network (DenseNet-3D) is used to extract temporal and spatial features of the neural representation for the attended locations. The results show that the proposed method achieves higher decoding accuracy than the state-of-the-art (SOTA) method (94.4% compared to XANet's 90.6%) with 1-second decision window for the widely used KULeuven (KUL) dataset, and the code to implement our work is available on Github:   https://github.com/xuxiran/ASAD_DenseNet
</details>
<details>
<summary>摘要</summary>
听觉空间注意力检测（ASAD）目标是通过电enzephalogram（EEG）在多个发声人员的情况下解码注意力所投入的空间位置。ASAD技术由大脑偏好听觉空间注意力处理中的 cortical neural response的 lateralization  inspirited，并在听觉注意力解码（AAD）中表现出了良好的性能。在先前的ASAD方法中，EEG电极的空间分布未能得到完全利用，这可能会限制这些方法的性能。在当前的工作中，我们将原始EEG通道转换成二维（2D）空间Topological Map，将EEG数据转换成三维（3D）排序，其中包含空间-时间信息。然后，我们使用3D深度卷积神经网络（DenseNet-3D）提取时间和空间特征，以提高注意力解码精度。结果显示，我们的方法在KUL数据集上达到了94.4%的解码精度，高于先前的SOTA方法（XANet的90.6%）。代码可以在GitHub上获取：https://github.com/xuxiran/ASAD_DenseNet。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-machine-learning-models-for-quantum-state-classification"><a href="#Benchmarking-machine-learning-models-for-quantum-state-classification" class="headerlink" title="Benchmarking machine learning models for quantum state classification"></a>Benchmarking machine learning models for quantum state classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07679">http://arxiv.org/abs/2309.07679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Pedicillo, Andrea Pasquale, Stefano Carrazza</li>
<li>for: 本文是用于描述量子计算领域中两级量子状态（qubits）的处理方法。</li>
<li>methods: 本文使用了多种分类技术来识别测量结果中的基态和升态。</li>
<li>results: 本文对真实的量子设备进行了多种分类技术的 benchmarking。<details>
<summary>Abstract</summary>
Quantum computing is a growing field where the information is processed by two-levels quantum states known as qubits. Current physical realizations of qubits require a careful calibration, composed by different experiments, due to noise and decoherence phenomena. Among the different characterization experiments, a crucial step is to develop a model to classify the measured state by discriminating the ground state from the excited state. In this proceedings we benchmark multiple classification techniques applied to real quantum devices.
</details>
<details>
<summary>摘要</summary>
量子计算是一个快速发展的领域，信息通过两级量子状态 known as qubits 处理。当前实现 qubits 需要精心准备，由于噪声和紊乱现象而需要不同的实验。其中一个关键步骤是开发一个模型，用于将测量结果分类， diferenciating 基准态从受激态。在这个论文中，我们对真实量子设备上的多种分类技术进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Goal-Space-Abstraction-in-Hierarchical-Reinforcement-Learning-via-Set-Based-Reachability-Analysis"><a href="#Goal-Space-Abstraction-in-Hierarchical-Reinforcement-Learning-via-Set-Based-Reachability-Analysis" class="headerlink" title="Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis"></a>Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07675">http://arxiv.org/abs/2309.07675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehdi Zadem, Sergio Mover, Sao Mai Nguyen</li>
<li>for: 本研究旨在提出一种开发机制，以便自动发现符号化目标表示，并使用这种表示来进行高级刺激学习。</li>
<li>methods: 本研究使用了符号推理来实现目标发现，并使用了一种层次推理算法来同时学习目标表示和层次策略。</li>
<li>results: 实验结果表明，使用符号推理进行目标发现可以提高数据效率，并且学习的目标表示是可解释的和可传输的。<details>
<summary>Abstract</summary>
Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this paper, we propose a developmental mechanism for goal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We introduce a Feudal HRL algorithm that concurrently learns both the goal representation and a hierarchical policy. The algorithm uses symbolic reachability analysis for neural networks to approximate the transition relation among sets of states and to refine the goal representation. We evaluate our approach on complex navigation tasks, showing the learned representation is interpretable, transferrable and results in data efficient learning.
</details>
<details>
<summary>摘要</summary>
开放式学习受益于符号方法的目标表示，因为它们提供了结构化知识的方式，以便有效和可传递地学习。然而，现有的层次强化学习（HRL）方法，它们通常是通过手动设定目标表示来实现的，这会带来一个挑战：自动发现符号目标表示，需要保留环境动力学的重要信息。在这篇论文中，我们提出一种发展机制，通过生成表示来自动发现目标。我们引入了一种封建的HRL算法，同时学习目标表示和层次策略。该算法使用神经网络上的符号可达性分析来approximate环境转移关系，并用此来精细化目标表示。我们在复杂的导航任务上评估了我们的方法，显示学习的表示是可读取的、可传递的和数据效率地学习。
</details></li>
</ul>
<hr>
<h2 id="Physics-constrained-robust-learning-of-open-form-PDEs-from-limited-and-noisy-data"><a href="#Physics-constrained-robust-learning-of-open-form-PDEs-from-limited-and-noisy-data" class="headerlink" title="Physics-constrained robust learning of open-form PDEs from limited and noisy data"></a>Physics-constrained robust learning of open-form PDEs from limited and noisy data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07672">http://arxiv.org/abs/2309.07672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengge Du, Longfeng Nie, Siyu Lou, Yuntian Chenc, Dongxiao Zhang</li>
<li>for: This paper aims to propose a framework for robustly uncovering open-form partial differential equations (PDEs) from limited and noisy data, which is a significant challenge in nonlinear dynamic systems.</li>
<li>methods: The proposed framework, called R-DISCOVER, uses two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training.</li>
<li>results: The numerical experiments demonstrate that the proposed framework can uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding.<details>
<summary>Abstract</summary>
Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge, especially when encountering noisy observations and no prior knowledge available. This study proposes R-DISCOVER, a framework designed to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with superior fits are utilized to iteratively optimize the generator via the RL method and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge, especially when encountering noisy observations and no prior knowledge available. This study proposes R-DISCOVER, a framework designed to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with superior fits are utilized to iteratively optimize the generator via the RL method and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding." into Simplified Chinese.以下是文本的中文翻译：“揭示非线性动力系统下的基本法则还是一项具有挑战性的任务，特别是当面临有噪讯观测和没有先验知识时。这项研究提出了R-DISCOVER框架，用于有效地推测非线性动力系统中的开放式偏微分方程（PDE）。该框架通过两个交替更新过程：发现和嵌入来实现。发现阶段使用 симвоlic Representation 和基于强化学习（RL）的混合 PDE 生成器来高效地生成多种开放式 PDE 树结构。一个基于神经网络的预测模型用于评估系统响应，并作为生成器的奖励评价器。RL 方法用于迭代优化生成器，并选择最佳performing PDE 以 Parameters-free 稳定度量。嵌入阶段将初始identified PDE 作为物理约束 integrate 到预测模型中，以实现Robust 训练。自动构建计算图和嵌入过程 без人工参与的 Traversal  PDE 树 automates 构建计算图和嵌入过程。 numerics experiments 表明我们的框架可以从有限和高噪讯数据中推测动力系统的基本法则，并在其他基于物理学习网络的发现方法中表现出色。这项工作开启了新的可能性，用于探索具有有限理解的实际系统。”
</details></li>
</ul>
<hr>
<h2 id="Dataset-Size-Dependence-of-Rate-Distortion-Curve-and-Threshold-of-Posterior-Collapse-in-Linear-VAE"><a href="#Dataset-Size-Dependence-of-Rate-Distortion-Curve-and-Threshold-of-Posterior-Collapse-in-Linear-VAE" class="headerlink" title="Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE"></a>Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07663">http://arxiv.org/abs/2309.07663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuma Ichikawa, Koji Hukushima</li>
<li>for: 避免Variational Autoencoder（VAE）中的 posterior collapse，提高表示学习质量。</li>
<li>methods: 使用高维limite下的minimal VAE，通过closed-form表达分析β参数与数据集大小、 posterior collapse、rate-distortion曲线之间的关系。</li>
<li>results: beta参数可以induce posterior collapse，不同于常见的 regularization parameters。beta值越高，普遍错误曲线上延伸的满板期变得越长，超过某个 beta 阈值后变为∞。这意味着beta需要仔细调整，并且较大的数据集需要以高率实现高质量的rate-distortion曲线。<details>
<summary>Abstract</summary>
In the Variational Autoencoder (VAE), the variational posterior often aligns closely with the prior, which is known as posterior collapse and hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter beta has been introduced in the VAE. This paper presents a closed-form expression to assess the relationship between the beta in VAE, the dataset size, the posterior collapse, and the rate-distortion curve by analyzing a minimal VAE in a high-dimensional limit. These results clarify that a long plateau in the generalization error emerges with a relatively larger beta. As the beta increases, the length of the plateau extends and then becomes infinite beyond a certain beta threshold. This implies that the choice of beta, unlike the usual regularization parameters, can induce posterior collapse regardless of the dataset size. Thus, beta is a risky parameter that requires careful tuning. Furthermore, considering the dataset-size dependence on the rate-distortion curve, a relatively large dataset is required to obtain a rate-distortion curve with high rates. Extensive numerical experiments support our analysis.
</details>
<details>
<summary>摘要</summary>
在变量自适应器（VAE）中，变量 posterior 经常与假设一样，这被称为 posterior collapse，这会妨碍表示学习质量。为了解决这个问题，VAE中引入了可调参数 beta。这篇论文提供了关于 beta 在 VAE、数据集大小、 posterior collapse 和 rate-distortion 曲线之间的关系的关闭式表达。这些结果表明，在一定的 beta 阈值以上，generalization error 的总化Error 会出现长满的浓淡区。 beta 增加时，浓淡区的长度延长，并 eventually 变为无限大。这意味着 beta 不同于常见的 regularization 参数，可以导致 posterior collapse，而不是 dataset size。因此，beta 是一个危险的参数，需要仔细调整。此外，考虑数据集大小对 rate-distortion 曲线的依赖，需要一个较大的数据集以获得高率的 rate-distortion 曲线。广泛的数值实验支持我们的分析。
</details></li>
</ul>
<hr>
<h2 id="Structure-Preserving-Transformers-for-Sequences-of-SPD-Matrices"><a href="#Structure-Preserving-Transformers-for-Sequences-of-SPD-Matrices" class="headerlink" title="Structure-Preserving Transformers for Sequences of SPD Matrices"></a>Structure-Preserving Transformers for Sequences of SPD Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07579">http://arxiv.org/abs/2309.07579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mathieuseraphim/spdtransnet">https://github.com/mathieuseraphim/spdtransnet</a></li>
<li>paper_authors: Mathieu Seraphim, Alexis Lechervy, Florian Yger, Luc Brun, Olivier Etard</li>
<li>for: 这 paper 是用于分类Symmetric Positive Definite matrices 的sequence，保持它们的Riemannian geometry。</li>
<li>methods: 这 paper 使用Transformer-based auto-attention机制，将EEG-derived covariance matrices 转化为sequence，并进行自动睡眠阶段分类。</li>
<li>results: 这 paper 在使用标准数据集上实现了高水平的stage-wise性能。<details>
<summary>Abstract</summary>
In recent years, Transformer-based auto-attention mechanisms have been successfully applied to the analysis of a variety of context-reliant data types, from texts to images and beyond, including data from non-Euclidean geometries. In this paper, we present such a mechanism, designed to classify sequences of Symmetric Positive Definite matrices while preserving their Riemannian geometry throughout the analysis. We apply our method to automatic sleep staging on timeseries of EEG-derived covariance matrices from a standard dataset, obtaining high levels of stage-wise performance.
</details>
<details>
<summary>摘要</summary>
Note:* "Symmetric Positive Definite" (SPD) matrices are matrices that are symmetric and positive definite, meaning that they are equal to their own transpose and have all positive eigenvalues.* "Riemannian geometry" refers to the study of curved spaces, such as the surface of a sphere or a saddle-shaped surface, and the properties of curves and surfaces within those spaces. In this context, the Riemannian geometry of the SPD matrices is preserved throughout the analysis.
</details></li>
</ul>
<hr>
<h2 id="Naturalistic-Robot-Arm-Trajectory-Generation-via-Representation-Learning"><a href="#Naturalistic-Robot-Arm-Trajectory-Generation-via-Representation-Learning" class="headerlink" title="Naturalistic Robot Arm Trajectory Generation via Representation Learning"></a>Naturalistic Robot Arm Trajectory Generation via Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07550">http://arxiv.org/abs/2309.07550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayjun Lee, Adam J. Spiers</li>
<li>for: 这个论文旨在提高助手机器人在家庭环境中的预测和人类化运动。特别是用于支持脊梁部分 паралиysis 患者的独立生活。</li>
<li>methods: 本文使用自我监督学习方法，使用自适应域 spatial-temporal图 neural network 来学习人类示范动作。通过穿戴在人臂上的 IMU 传感器记录的无动作任务示范数据，学习出自然和功能的喝奶动作轨迹 для UR5e 机器人臂。</li>
<li>results: 研究表明，通过自适应域 spatial-temporal图 neural network 学习人类示范动作，可以生成自然和功能的喝奶动作轨迹，并且可以在不同的人类动作示范数据上进行适应和适应。<details>
<summary>Abstract</summary>
The integration of manipulator robots in household environments suggests a need for more predictable and human-like robot motion. This holds especially true for wheelchair-mounted assistive robots that can support the independence of people with paralysis. One method of generating naturalistic motion trajectories is via the imitation of human demonstrators. This paper explores a self-supervised imitation learning method using an autoregressive spatio-temporal graph neural network for an assistive drinking task. We address learning from diverse human motion trajectory data that were captured via wearable IMU sensors on a human arm as the action-free task demonstrations. Observed arm motion data from several participants is used to generate natural and functional drinking motion trajectories for a UR5e robot arm.
</details>
<details>
<summary>摘要</summary>
文中提到了在家庭环境中 integrating  manipulate 机器人，这表明了更加预测可靠并且人类化的机器人运动的需求，尤其是用于椅子上的帮助机器人，以支持脊梁部分瘫痪人的独立。本文探讨了通过人类示范者的模仿来生成自然的动作轨迹。我们使用了一种自动适应空间时间图 neuronal network 来实现这一点，并使用了来自不同人类动作轨迹数据的穿梭IMU传感器来学习。我们使用了多个参与者的臂动作数据来生成自然而有用的喝彩动作轨迹 для UR5e 机器人臂。
</details></li>
</ul>
<hr>
<h2 id="Proximal-Bellman-mappings-for-reinforcement-learning-and-their-application-to-robust-adaptive-filtering"><a href="#Proximal-Bellman-mappings-for-reinforcement-learning-and-their-application-to-robust-adaptive-filtering" class="headerlink" title="Proximal Bellman mappings for reinforcement learning and their application to robust adaptive filtering"></a>Proximal Bellman mappings for reinforcement learning and their application to robust adaptive filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07548">http://arxiv.org/abs/2309.07548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuki Akiyama, Konstantinos Slavakis</li>
<li>For: 本研究旨在探讨动力学学习（Reinforcement Learning，RL）的算法基础和理论核心，特别是引入距离bellman映射，这种映射在征表kernel空间（RKHS）中定义，并且可以利用RKHS的强表示性和内积来获得更好的近似性。* Methods: 本研究使用的方法包括提出了一种新的距离bellman映射，这种映射在RKHS中定义，并且可以利用RKHS的强表示性和内积来获得更好的近似性。此外，本研究还提出了一种基于这种映射的策略迭代算法，用于在线选择最佳exponent $p$，以适应线性适应过滤器中的异常值。* Results: 本研究的数据测试显示，基于提出的映射和策略迭代算法的方法可以在synthetic数据上显示出优于非RL和基于kernel RL的方法。<details>
<summary>Abstract</summary>
This paper aims at the algorithmic/theoretical core of reinforcement learning (RL) by introducing the novel class of proximal Bellman mappings. These mappings are defined in reproducing kernel Hilbert spaces (RKHSs), to benefit from the rich approximation properties and inner product of RKHSs, they are shown to belong to the powerful Hilbertian family of (firmly) nonexpansive mappings, regardless of the values of their discount factors, and possess ample degrees of design freedom to even reproduce attributes of the classical Bellman mappings and to pave the way for novel RL designs. An approximate policy-iteration scheme is built on the proposed class of mappings to solve the problem of selecting online, at every time instance, the "optimal" exponent $p$ in a $p$-norm loss to combat outliers in linear adaptive filtering, without training data and any knowledge on the statistical properties of the outliers. Numerical tests on synthetic data showcase the superior performance of the proposed framework over several non-RL and kernel-based RL schemes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VerilogEval-Evaluating-Large-Language-Models-for-Verilog-Code-Generation"><a href="#VerilogEval-Evaluating-Large-Language-Models-for-Verilog-Code-Generation" class="headerlink" title="VerilogEval: Evaluating Large Language Models for Verilog Code Generation"></a>VerilogEval: Evaluating Large Language Models for Verilog Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07544">http://arxiv.org/abs/2309.07544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, Haoxing Ren</li>
<li>for: This paper is written for evaluating the performance of large language models (LLMs) in generating Verilog code for hardware design and verification.</li>
<li>methods: The paper proposes a benchmarking framework for LLMs that includes a comprehensive evaluation dataset of 156 problems from the Verilog instructional website HDLBits, and a method for automatically testing the generated Verilog code for functional correctness.</li>
<li>results: The paper shows that the Verilog code generation capability of pretrained language models can be improved with supervised fine-tuning by bootstrapping with LLM-generated synthetic problem-code pairs.Here’s the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文是为了评估大语言模型（LLM）在硬件设计和验证中的Verilog代码生成性能而写的。</li>
<li>methods: 论文提出了一种特化于LLM的评估框架，包括156个HDLLBits网站上的Verilog教程问题集，以及一种自动比较生成的Verilog代码与经典解决方案的方法。</li>
<li>results: 论文表明，通过监督微调，使用LLM生成的 simulateproblem-code对可以提高预训练的语言模型的Verilog代码生成能力。<details>
<summary>Abstract</summary>
The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs.
</details>
<details>
<summary>摘要</summary>
LLMs的增长 популярность开创了它们在多个领域的应用。这篇论文提出了专门为鉴定LLM表现在Verilog代码生成和验证中而设计的 bencmarking 框架。我们提供了完整的评估数据集，包括156个来自 HDLBits 教程网站的 Verilog 代码生成任务，这些任务的复杂程度从简单的 combinational 电路到复杂的 finite state machine。生成的 Verilog 代码可以通过与 golden 解决方案进行对比来自动测试其功能正确性。此外，我们还证明了预训练的语言模型可以通过监督微调来提高 Verilog 代码生成能力。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-approximation-of-monotone-functions"><a href="#Adaptive-approximation-of-monotone-functions" class="headerlink" title="Adaptive approximation of monotone functions"></a>Adaptive approximation of monotone functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07530">http://arxiv.org/abs/2309.07530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Gaillard, Sébastien Gerchinovitz, Étienne de Montbrun</li>
<li>for: 本研究 targets the classical problem of approximating a non-decreasing function $f$ in $L^p(\mu)$ norm using sequential queries.</li>
<li>methods: 我们提出了一种新的GreedyBox算法，是Novak（1992）原始的数值积分算法的推广。我们证明了GreedyBox算法在任何函数$f$上具有最佳样本复杂度。</li>
<li>results: 我们发现了多种性能差异，包括适应性和非适应性算法、平滑和分割平滑函数、 monotone和非 monotone函数之间的性能差异。此外，我们还计算了最佳合理极小样本复杂度 для特定的函数$f$.<details>
<summary>Abstract</summary>
We study the classical problem of approximating a non-decreasing function $f: \mathcal{X} \to \mathcal{Y}$ in $L^p(\mu)$ norm by sequentially querying its values, for known compact real intervals $\mathcal{X}$, $\mathcal{Y}$ and a known probability measure $\mu$ on $\cX$. For any function~$f$ we characterize the minimum number of evaluations of $f$ that algorithms need to guarantee an approximation $\hat{f}$ with an $L^p(\mu)$ error below $\epsilon$ after stopping. Unlike worst-case results that hold uniformly over all $f$, our complexity measure is dependent on each specific function $f$. To address this problem, we introduce GreedyBox, a generalization of an algorithm originally proposed by Novak (1992) for numerical integration. We prove that GreedyBox achieves an optimal sample complexity for any function $f$, up to logarithmic factors. Additionally, we uncover results regarding piecewise-smooth functions. Perhaps as expected, the $L^p(\mu)$ error of GreedyBox decreases much faster for piecewise-$C^2$ functions than predicted by the algorithm (without any knowledge on the smoothness of $f$). A simple modification even achieves optimal minimax approximation rates for such functions, which we compute explicitly. In particular, our findings highlight multiple performance gaps between adaptive and non-adaptive algorithms, smooth and piecewise-smooth functions, as well as monotone or non-monotone functions. Finally, we provide numerical experiments to support our theoretical results.
</details>
<details>
<summary>摘要</summary>
我们研究了一个古典问题，即使用顺序询问函数 $f: \mathcal{X} \to \mathcal{Y}$ 的渐近估计，在 $L^p(\mu)$  нор下的渐近估计问题。我们考虑了知道的封闭实数interval $\mathcal{X}$, $\mathcal{Y}$ 和知道的概率度量 $\mu$  на $\mathcal{X}$。对于任何函数 $f$，我们Characterize了终止后的 $\hat{f}$ 的 $L^p(\mu)$ 误差下的最小询问数量，而不是worst-case结果，这些结果是函数 $f$ 具体的dependent。为解决这个问题，我们引入 GreedyBox 算法，是 Novak (1992) 提出的数值积分算法的一个扩展。我们证明了 GreedyBox 算法在任何函数 $f$ 上实现最佳样本Complexity，几乎是 logarithmic factor。此外，我们发现了关于 piecewise-smooth 函数的结果。对于这些函数，GreedyBox 算法的 $L^p(\mu)$ 误差明显更快下降，比预期的更快。甚至可以通过一个简单的修改，使 GreedyBox 算法在这些函数上实现最佳的混合估计率，我们 computed explicitly。我们的结论显示了多个性能差异，包括适应和非适应算法、紧密和 piecewise-smooth 函数、以及单调和非单调函数。最后，我们提供了一些数学实验支持我们的理论结果。
</details></li>
</ul>
<hr>
<h2 id="Learning-Beyond-Similarities-Incorporating-Dissimilarities-between-Positive-Pairs-in-Self-Supervised-Time-Series-Learning"><a href="#Learning-Beyond-Similarities-Incorporating-Dissimilarities-between-Positive-Pairs-in-Self-Supervised-Time-Series-Learning" class="headerlink" title="Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning"></a>Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07526">http://arxiv.org/abs/2309.07526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Atienza, Jakob Bardram, Sadasivan Puthusserypady</li>
<li>for: 用于提高时间序列数据中的冲击性识别率</li>
<li>methods: 利用自然学习方法，通过对着同类样本进行压缩编码，并考虑异同样本的关系，从而提高时间序列数据的表征</li>
<li>results: 在使用电心率信号进行识别AFib时，提高了+10%的检测精度，并且可能开拓了新的SSL方法应用于时间序列数据<details>
<summary>Abstract</summary>
By identifying similarities between successive inputs, Self-Supervised Learning (SSL) methods for time series analysis have demonstrated their effectiveness in encoding the inherent static characteristics of temporal data. However, an exclusive emphasis on similarities might result in representations that overlook the dynamic attributes critical for modeling cardiovascular diseases within a confined subject cohort. Introducing Distilled Encoding Beyond Similarities (DEBS), this paper pioneers an SSL approach that transcends mere similarities by integrating dissimilarities among positive pairs. The framework is applied to electrocardiogram (ECG) signals, leading to a notable enhancement of +10\% in the detection accuracy of Atrial Fibrillation (AFib) across diverse subjects. DEBS underscores the potential of attaining a more refined representation by encoding the dynamic characteristics of time series data, tapping into dissimilarities during the optimization process. Broadly, the strategy delineated in this study holds the promise of unearthing novel avenues for advancing SSL methodologies tailored to temporal data.
</details>
<details>
<summary>摘要</summary>
自适应学习（SSL）方法在时间序列分析中已经表现出其效iveness，通过识别同时间序列数据的相似性来编码时间序列中的静态特征。但是，强调同时间序列的相似性可能会忽略了模型心血管疾病中的动态特征，这可能会导致模型的识别率下降。为了解决这个问题，本文提出了一种名为“压缩编码 beyond similarities”（DEBS）的SSL方法，它通过对正例对的不同性进行束缚来补充相似性编码。这种方法在应用于电cardiogram（ECG）信号上，导致了AFib检测精度的提高达10%。DEBS表明了在SSL方法中编码时间序列数据的动态特征可以通过压缩编码来提高模型的性能。总之，本研究的策略可能会探索新的SSL方法，以更好地适应时间序列数据的特点。
</details></li>
</ul>
<hr>
<h2 id="Massively-Parallel-Heat-Map-Sorting-and-Applications-To-Explainable-Clustering"><a href="#Massively-Parallel-Heat-Map-Sorting-and-Applications-To-Explainable-Clustering" class="headerlink" title="Massively-Parallel Heat Map Sorting and Applications To Explainable Clustering"></a>Massively-Parallel Heat Map Sorting and Applications To Explainable Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07486">http://arxiv.org/abs/2309.07486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepideh Aghamolaei, Mohammad Ghodsi</li>
<li>for: 本文 escrit para resolver el problema de clasificación de puntos etiquetados con k label, y presenta una aproximación de la solución utilizando un algoritmo de ordenamiento de mapas de calor.</li>
<li>methods: El algoritmo utilizado es un algoritmo de ordenamiento de mapas de calor, que se basa en la reducción de dimensionalidad mediante hashing localmente sensitivo. Se prueba la complejidad NP-hard del problema y se da un algoritmo de aproximación para un caso especial NP-hard.</li>
<li>results: Se compara el algoritmo propuesto con k-means y DBSCAN en términos de calidad de agrupación y tiempo de ejecución en varios grafos dirigidos y no dirigidos de redes de correo electrónico y redes de computadoras. Los resultados muestran que el algoritmo propuesto tiene una mejor calidad de agrupación y un tiempo de ejecución más rápido que k-means y DBSCAN en muchos casos.<details>
<summary>Abstract</summary>
Given a set of points labeled with $k$ labels, we introduce the heat map sorting problem as reordering and merging the points and dimensions while preserving the clusters (labels). A cluster is preserved if it remains connected, i.e., if it is not split into several clusters and no two clusters are merged.   We prove the problem is NP-hard and we give a fixed-parameter algorithm with a constant number of rounds in the massively parallel computation model, where each machine has a sublinear memory and the total memory of the machines is linear. We give an approximation algorithm for a NP-hard special case of the problem. We empirically compare our algorithm with k-means and density-based clustering (DBSCAN) using a dimensionality reduction via locality-sensitive hashing on several directed and undirected graphs of email and computer networks.
</details>
<details>
<summary>摘要</summary>
给定一个点集合，我们引入热图排序问题，即重新排序和合并点和维度，保持cluster（标签）。一个cluster preserved if it remains connected, 即不被分解成多个cluster并且没有两个cluster合并。 我们证明该问题是NP困难，并提供了一个固定参数算法，其中每台机器有SUBLINEAR的内存，总内存量为线性。我们还提供了一个优化算法 дляNP困难的特殊情况。我们通过本地敏感哈希进行维度减少对email和计算机网络directed和undirected图进行实验比较我们的算法与k-means和DBSCAN分 clustering。
</details></li>
</ul>
<hr>
<h2 id="Improved-Auto-Encoding-using-Deterministic-Projected-Belief-Networks"><a href="#Improved-Auto-Encoding-using-Deterministic-Projected-Belief-Networks" class="headerlink" title="Improved Auto-Encoding using Deterministic Projected Belief Networks"></a>Improved Auto-Encoding using Deterministic Projected Belief Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07481">http://arxiv.org/abs/2309.07481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul M Baggenstoss</li>
<li>for: 本研究利用决定性投影信念网络（D-PBN）的特有特性，全面利用可训练复合启动函数（TCAs）。</li>
<li>methods: 本研究使用D-PBN auto-encoder，并利用TCAs作为活化函数。</li>
<li>results: 研究发现，使用D-PBN auto-encoder和TCAs可以明显超越标准 auto-encoder，包括变量 auto-encoder。<details>
<summary>Abstract</summary>
In this paper, we exploit the unique properties of a deterministic projected belief network (D-PBN) to take full advantage of trainable compound activation functions (TCAs). A D-PBN is a type of auto-encoder that operates by "backing up" through a feed-forward neural network. TCAs are activation functions with complex monotonic-increasing shapes that change the distribution of the data so that the linear transformation that follows is more effective. Because a D-PBN operates by "backing up", the TCAs are inverted in the reconstruction process, restoring the original distribution of the data, thus taking advantage of a given TCA in both analysis and reconstruction. In this paper, we show that a D-PBN auto-encoder with TCAs can significantly out-perform standard auto-encoders including variational auto-encoders.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们利用杜比贝尔网络（D-PBN）的特有性，全面利用可调编组活化函数（TCAs）。D-PBN 是一种自适应神经网络，通过“后退”方式运作，可以将数据分布改变，使之更容易进行线性变换。因为 D-PBN 在重建过程中会将 TCAs 反转，所以可以利用给定的 TCA 进行分析和重建。在这篇论文中，我们表明了 D-PBN 自适应神经网络加上 TCAs 可以明显超越标准自适应神经网络，包括可变自适应神经网络。
</details></li>
</ul>
<hr>
<h2 id="SC-MAD-Mixtures-of-Higher-order-Networks-for-Data-Augmentation"><a href="#SC-MAD-Mixtures-of-Higher-order-Networks-for-Data-Augmentation" class="headerlink" title="SC-MAD: Mixtures of Higher-order Networks for Data Augmentation"></a>SC-MAD: Mixtures of Higher-order Networks for Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07453">http://arxiv.org/abs/2309.07453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Madeline Navarro, Santiago Segarra</li>
<li>for: 这个论文旨在扩展基于图的对等连接到高阶关系上，以满足复杂系统的研究需求。</li>
<li>methods: 该论文提出了一种基于 simplicial complex 的数据增强方法，包括线性和非线性混合机制，以生成混合样本。此外，它还提出了一种几何归一化混合方法来实现数据集之间的关系。</li>
<li>results: 研究人员通过对实验数据集进行混合，并对混合样本进行分类，发现混合样本可以在Homomorphism densities上 interpolate among existing data。<details>
<summary>Abstract</summary>
The myriad complex systems with multiway interactions motivate the extension of graph-based pairwise connections to higher-order relations. In particular, the simplicial complex has inspired generalizations of graph neural networks (GNNs) to simplicial complex-based models. Learning on such systems requires large amounts of data, which can be expensive or impossible to obtain. We propose data augmentation of simplicial complexes through both linear and nonlinear mixup mechanisms that return mixtures of existing labeled samples. In addition to traditional pairwise mixup, we present a convex clustering mixup approach for a data-driven relationship among several simplicial complexes. We theoretically demonstrate that the resultant synthetic simplicial complexes interpolate among existing data with respect to homomorphism densities. Our method is demonstrated on both synthetic and real-world datasets for simplicial complex classification.
</details>
<details>
<summary>摘要</summary>
多样化的复杂系统与多向交互刺激了对高阶关系的扩展。特别是 simplicial complex  inspirits 对 graph neural network (GNNs) 的扩展。学习这些系统需要大量数据，可能是非常昂贵或者不可能获得。我们提议对 simplicial complex 进行数据扩充，通过线性和非线性混合机制返回混合的已有标注样本。此外，我们还提出了一种几何 clustering 混合方法，以便在数据驱动的关系下 interpolate 多个 simplicial complex。我们理论上验证了resultant synthetic simplicial complexes 在 homomorphism density 上 interpolate 于现有数据。我们的方法在 both synthetic 和实际世界数据上进行了 simplicial complex classification 的示例。
</details></li>
</ul>
<hr>
<h2 id="Is-Solving-Graph-Neural-Tangent-Kernel-Equivalent-to-Training-Graph-Neural-Network"><a href="#Is-Solving-Graph-Neural-Tangent-Kernel-Equivalent-to-Training-Graph-Neural-Network" class="headerlink" title="Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph Neural Network?"></a>Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph Neural Network?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07452">http://arxiv.org/abs/2309.07452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lianke Qin, Zhao Song, Baocheng Sun</li>
<li>for: 本研究的目的是证明NTK regression和GNN Training是等价的。</li>
<li>methods: 本文使用NTK kernel方法来研究图学习，并提出了三个新的理论结论。</li>
<li>results: 本文证明了NTK regression和GNN Training是等价的，并提供了首个NTK formulation for node-level regression。<details>
<summary>Abstract</summary>
A rising trend in theoretical deep learning is to understand why deep learning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method that is equivalent to using gradient descent to train a multi-layer infinitely-wide neural network. NTK is a major step forward in the theoretical deep learning because it allows researchers to use traditional mathematical tools to analyze properties of deep neural networks and to explain various neural network techniques from a theoretical view. A natural extension of NTK on graph learning is \textit{Graph Neural Tangent Kernel (GNTK)}, and researchers have already provide GNTK formulation for graph-level regression and show empirically that this kernel method can achieve similar accuracy as GNNs on various bioinformatics datasets [dhs+19]. The remaining question now is whether solving GNTK regression is equivalent to training an infinite-wide multi-layer GNN using gradient descent. In this paper, we provide three new theoretical results. First, we formally prove this equivalence for graph-level regression. Second, we present the first GNTK formulation for node-level regression. Finally, we prove the equivalence for node-level regression.
</details>
<details>
<summary>摘要</summary>
一种在理论深度学习中崛起的趋势是理解深度学习是如何工作的，通过神经束凝彻函数（NTK）来实现。NTK是一种等效于使用梯度下降来训练多层无穷广链神经网络的kernel方法。NTK对理论深度学习是一个重要的进步，它使得研究人员可以使用传统的数学工具来分析深度神经网络的性质和解释各种神经网络技术的概念视角。在NTK的基础之上，研究人员已经提出了\textit{图像神经束凝彻函数（GNTK）}，并在图像级别 regression 中提供了GNTK的形式化。在此纸上，我们提供了三个新的理论结果。首先，我们正式证明了图像级别 regression 的等价性。其次，我们提供了第一个GNTK的形式化，用于节点级别 regression。最后，我们证明了节点级别 regression 的等价性。
</details></li>
</ul>
<hr>
<h2 id="TensorFlow-Chaotic-Prediction-and-Blow-Up"><a href="#TensorFlow-Chaotic-Prediction-and-Blow-Up" class="headerlink" title="TensorFlow Chaotic Prediction and Blow Up"></a>TensorFlow Chaotic Prediction and Blow Up</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07450">http://arxiv.org/abs/2309.07450</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Andrecut</li>
<li>for: 预测高维非线性系统的混沌动力学行为</li>
<li>methods: 使用TensorFlow库进行深度神经网络训练和预测</li>
<li>results: 短时预测能够得到有效结果，但长时预测会因TensorFlow库的非束定性导致结果快速衰减和爆炸<details>
<summary>Abstract</summary>
Predicting the dynamics of chaotic systems is one of the most challenging tasks for neural networks, and machine learning in general. Here we aim to predict the spatiotemporal chaotic dynamics of a high-dimensional non-linear system. In our attempt we use the TensorFlow library, representing the state of the art for deep neural networks training and prediction. While our results are encouraging, and show that the dynamics of the considered system can be predicted for short time, we also indirectly discovered an unexpected and undesirable behavior of the TensorFlow library. More specifically, the longer term prediction of the system's chaotic behavior quickly deteriorates and blows up due to the nondeterministic behavior of the TensorFlow library. Here we provide numerical evidence of the short time prediction ability, and of the longer term predictability blow up.
</details>
<details>
<summary>摘要</summary>
<<sys.language_model.set_lang("zh-CN")>>预测混沌系统的动态是机器学习领域中最为困难的任务之一。在这里，我们试图预测高维非线性系统的空间时间混沌动态。我们使用TensorFlow库，表示深度神经网络训练和预测的状态体系。虽然我们的结果吸引人，并显示了系统的短时预测能力，但我们也发现了TensorFlow库的意外和不愉快的行为。 Specifically，系统的混沌行为的长期预测快速下降和爆炸，这是因为TensorFlow库的非确定性行为。我们提供了数字证据，证明了短时预测能力和长期预测爆炸。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-Optimization-View-Reformulating-Single-Layer-Attention-in-LLM-Based-on-Tensor-and-SVM-Trick-and-Solving-It-in-Matrix-Multiplication-Time"><a href="#A-Fast-Optimization-View-Reformulating-Single-Layer-Attention-in-LLM-Based-on-Tensor-and-SVM-Trick-and-Solving-It-in-Matrix-Multiplication-Time" class="headerlink" title="A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time"></a>A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07418">http://arxiv.org/abs/2309.07418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeqi Gao, Zhao Song, Weixin Wang, Junze Yin</li>
<li>for: 这个论文主要针对的是优化大型语言模型（LLM）中的注意力 regression 问题。</li>
<li>methods: 作者提出了一种Iterative greedy algorithm，用于在 $L(X,Y) &#x3D; \sum_{j_0 &#x3D; 1}^n \sum_{i_0 &#x3D; 1}^d ( \langle \langle \exp( \mathsf{A}<em>{j_0} x ) , {\bf 1}<em>n \rangle^{-1} \exp( \mathsf{A}</em>{j_0} x ), A</em>{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$ loss function上训练，这个loss function是一个一层注意力网络的目标函数。</li>
<li>results: 作者提出了一种时间复杂度为 $\widetilde{O}( ({\cal T}<em>{\mathrm{mat}(n,n,d) + {\cal T}</em>{\mathrm{mat}(n,d,d) + d^{2\omega}) \log(1&#x2F;\epsilon) )$ 的训练算法，用于将 $L(X,Y)$ 的损失降到 $\epsilon$ 之下。这个算法可以在大型语言模型中应用。<details>
<summary>Abstract</summary>
Large language models (LLMs) have played a pivotal role in revolutionizing various facets of our daily existence. Solving attention regression is a fundamental task in optimizing LLMs. In this work, we focus on giving a provable guarantee for the one-layer attention network objective function $L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$. Here $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$ is Kronecker product between $A_1 \in \mathbb{R}^{n \times d}$ and $A_2 \in \mathbb{R}^{n \times d}$. $A_3$ is a matrix in $\mathbb{R}^{n \times d}$, $\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ is the $j_0$-th block of $\mathsf{A}$. The $X, Y \in \mathbb{R}^{d \times d}$ are variables we want to learn. $B \in \mathbb{R}^{n \times d}$ and $b_{j_0,i_0} \in \mathbb{R}$ is one entry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \in \mathbb{R}^d$ is the $i_0$-column vector of $Y$, and $x \in \mathbb{R}^{d^2}$ is the vectorization of $X$.   In a multi-layer LLM network, the matrix $B \in \mathbb{R}^{n \times d}$ can be viewed as the output of a layer, and $A_1= A_2 = A_3 \in \mathbb{R}^{n \times d}$ can be viewed as the input of a layer. The matrix version of $x$ can be viewed as $QK^\top$ and $Y$ can be viewed as $V$. We provide an iterative greedy algorithm to train loss function $L(X,Y)$ up $\epsilon$ that runs in $\widetilde{O}( ({\cal T}_{\mathrm{mat}(n,n,d) + {\cal T}_{\mathrm{mat}(n,d,d) + d^{2\omega}) \log(1/\epsilon) )$ time. Here ${\cal T}_{\mathrm{mat}(a,b,c)$ denotes the time of multiplying $a \times b$ matrix another $b \times c$ matrix, and $\omega\approx 2.37$ denotes the exponent of matrix multiplication.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经革命化了我们日常生活中的各种方面。在这种情况下，解决注意力回归是对LMM的优化的基本任务。在这种工作中，我们关注于给出可证明保证的一层注意力网络对函数$L(X,Y) = \sum_{j_0 = 1}^n \sum_{i_0 = 1}^d ( \langle \langle \exp( \mathsf{A}_{j_0} x ) , {\bf 1}_n \rangle^{-1} \exp( \mathsf{A}_{j_0} x ), A_{3} Y_{*,i_0} \rangle - b_{j_0,i_0} )^2$. Here $\mathsf{A} \in \mathbb{R}^{n^2 \times d^2}$是 kronecker乘积 between $A_1 \in \mathbb{R}^{n \times d}$ and $A_2 \in \mathbb{R}^{n \times d}$. $A_3$ is a matrix in $\mathbb{R}^{n \times d}$, $\mathsf{A}_{j_0} \in \mathbb{R}^{n \times d^2}$ is the $j_0$-th block of $\mathsf{A}$. $X, Y \in \mathbb{R}^{d \times d}$是我们想要学习的变量， $B \in \mathbb{R}^{n \times d}$ and $b_{j_0,i_0} \in \mathbb{R}$ is one entry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \in \mathbb{R}^d$ is the $i_0$-column vector of $Y$, and $x \in \mathbb{R}^{d^2}$ is the vectorization of $X$. 在多层LLM网络中，矩阵$B \in \mathbb{R}^{n \times d}$可以被视为层的输出，而$A_1= A_2 = A_3 \in \mathbb{R}^{n \times d}$可以被视为层的输入。矩阵版本的$x$可以被视为$QK^\top$，而$Y$可以被视为$V$.我们提供了一种迭代循环算法来训练损失函数$L(X,Y)$，该算法在$\epsilon$阈值下运行时间为$\widetilde{O}( ({\cal T}_{\mathrm{mat}(n,n,d) + {\cal T}_{\mathrm{mat}(n,d,d) + d^{2\omega}) \log(1/\epsilon) )$。这里的${\cal T}_{\mathrm{mat}(a,b,c)$表示矩阵$a \times b$的乘法，$\omega\approx 2.37$是矩阵乘法的废入。
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Domain-Adaptation-on-Graphs-with-Contrastive-Learning-and-Minimax-Entropy"><a href="#Semi-supervised-Domain-Adaptation-on-Graphs-with-Contrastive-Learning-and-Minimax-Entropy" class="headerlink" title="Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy"></a>Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07402">http://arxiv.org/abs/2309.07402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaren Xiao, Quanyu Dai, Xiao Shen, Xiaochen Xie, Jing Dai, James Lam, Ka-Wai Kwok</li>
<li>for: 本研究目的是解决在图像上面临着数据标注成本高的情况下，采用 semi-supervised domain adaptation (SSDA) 技术来优化图像中节点的分类。</li>
<li>methods: 本研究提出了一种新的方法 called SemiGCL，它利用图像的本地和全局视图来生成有用的节点表示，并通过对不同视图的节点表示进行对比来增强节点表示的有用性。此外，SemiGCL 还利用了最大 entropy 损失来降低领域差异。</li>
<li>results: 实验结果表明，SemiGCL 在 SSDA 任务中表现出色，高于现有的基线方法。<details>
<summary>Abstract</summary>
Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. To tackle the SSDA problem on graphs, a novel method called SemiGCL is proposed, which benefits from graph contrastive learning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph's local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark datasets demonstrate that SemiGCL outperforms the state-of-the-art baselines on the SSDA tasks.
</details>
<details>
<summary>摘要</summary>
很多现实应用中会遇到图像标签稀缺的问题，这是因为数据标签的成本很高。为此，半经典领域适应（SSDA）在图上进行了应用，以利用来自源图的标注知识来帮助目标图的节点分类。然而，到目前为止，已有的跨图节点分类方法并未正式地考虑SSDA问题。为解决SSDA问题，一种名为SemiGCL的新方法被提出，它利用图形对比学习和最大 entropy 训练来生成有用的节点表示。此外，SemiGCL通过对不同视图中的节点表示进行对比，以提高节点表示的有用性。同时，SemiGCL通过对无标签目标节点的 entropy 损失进行反向优化，以减少领域差异。实验结果表明，SemiGCL在 benchmark 数据集上的性能高于当前的基eline。
</details></li>
</ul>
<hr>
<h2 id="Voxtlm-unified-decoder-only-models-for-consolidating-speech-recognition-synthesis-and-speech-text-continuation-tasks"><a href="#Voxtlm-unified-decoder-only-models-for-consolidating-speech-recognition-synthesis-and-speech-text-continuation-tasks" class="headerlink" title="Voxtlm: unified decoder-only models for consolidating speech recognition&#x2F;synthesis and speech&#x2F;text continuation tasks"></a>Voxtlm: unified decoder-only models for consolidating speech recognition&#x2F;synthesis and speech&#x2F;text continuation tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07937">http://arxiv.org/abs/2309.07937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumi Maiti, Yifan Peng, Shukjae Choi, Jee-weon Jung, Xuankai Chang, Shinji Watanabe</li>
<li>for: 本研究提出了一种基于语音特征的多任务语言模型（VoxtLM），可以执行四项任务：语音识别、语音生成、文本生成和语音续写。</li>
<li>methods: VoxtLM将文本词汇与自动学习的语音特征拼接起来，使用特殊符号实现多任务学习。与单任务模型相比，VoxtLM在语音生成方面具有显著的改善，语音清晰度从28.9降低到5.6，对象质量从2.68提高到3.90。</li>
<li>results: VoxtLM在语音生成、语音识别和文本生成等方面都超过单任务模型的表现。模型使用公开的数据和训练规则，并将模型检查点开源，以便完全可重现。<details>
<summary>Abstract</summary>
We propose a decoder-only language model, \textit{VoxtLM}, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. VoxtLM is trained with publicly available data and training recipes and model checkpoints will be open-sourced to make fully reproducible work.
</details>
<details>
<summary>摘要</summary>
我们提议一个只有decoder的语言模型，名为VoxtLM，可以完成四个任务：语音识别、语音生成、文本生成和语音续写。VoxtLM将文本词汇与自然语言的特征Token结合在一起，并使用特殊的Token来实现多任务学习。相比单任务模型，VoxtLM在语音生成方面表现出了显著的改善，其中语音清晰度从28.9降低到5.6，对象质量从2.68提高到3.90。VoxtLM还提高了语音识别和语音生成的性能。VoxtLM通过公共可用数据和训练课程来训练，并将模型检查点开源，以便实现完全可重现的工作。Note: "VoxtLM" is a name I translated as "语音LM" (speech language model) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="EnCodecMAE-Leveraging-neural-codecs-for-universal-audio-representation-learning"><a href="#EnCodecMAE-Leveraging-neural-codecs-for-universal-audio-representation-learning" class="headerlink" title="EnCodecMAE: Leveraging neural codecs for universal audio representation learning"></a>EnCodecMAE: Leveraging neural codecs for universal audio representation learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07391">http://arxiv.org/abs/2309.07391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/habla-liaa/encodecmae">https://github.com/habla-liaa/encodecmae</a></li>
<li>paper_authors: Leonardo Pepino, Pablo Riera, Luciana Ferrer</li>
<li>for: 这项研究的目的是学习一种通用的音频表示学习模型，可以用于各种音频处理任务，如语音、音乐和环境声。</li>
<li>methods: 这项研究使用了基于自我supervised模型（如BERT）的方法，适应音频处理的需求。这些模型利用文本的整数性，因此对音频信号进行映射或改变学习目标是必要的。这项研究使用EnCodec neural audio codec生成扩展目标，并使用masked autoencoder（MAE）来学习通用音频模型。</li>
<li>results: 研究在各种音频任务中表现出色，包括语音、音乐和环境声，并与现有音频表示模型的性能相比或更好。<details>
<summary>Abstract</summary>
The goal of universal audio representation learning is to obtain foundational models that can be used for a variety of downstream tasks involving speech, music or environmental sounds. To approach this problem, methods inspired by self-supervised models from NLP, like BERT, are often used and adapted to audio. These models rely on the discrete nature of text, hence adopting this type of approach for audio processing requires either a change in the learning objective or mapping the audio signal to a set of discrete classes. In this work, we explore the use of EnCodec, a neural audio codec, to generate discrete targets for learning an universal audio model based on a masked autoencoder (MAE). We evaluate this approach, which we call EncodecMAE, on a wide range of audio tasks spanning speech, music and environmental sounds, achieving performances comparable or better than leading audio representation models.
</details>
<details>
<summary>摘要</summary>
“ universal audio representation learning 的目的是获得可以用于多种下游任务中的基础模型，包括语音、音乐或环境 зву频谱。为了解决这个问题，通常使用受自动批评模型（BERT）所启发的方法，并将其适应到音频处理中。这些模型对于文本的类别性很有帮助，因此为了将这种方法应用到音频处理中，需要对学习目标或音频信号进行变数映射。在这个工作中，我们探索使用 EnCodec，一个神经网络对话器，生成类别目标，以便透过隐藏autoencoder（MAE）进行学习 universal audio 模型。我们评估这种方法，我们称之为 EncodecMAE，在丰富的音频任务中，包括语音、音乐和环境音频，实现了与领先的音频表现模型相同或更好的性能。”
</details></li>
</ul>
<hr>
<h2 id="Rates-of-Convergence-in-Certain-Native-Spaces-of-Approximations-used-in-Reinforcement-Learning"><a href="#Rates-of-Convergence-in-Certain-Native-Spaces-of-Approximations-used-in-Reinforcement-Learning" class="headerlink" title="Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning"></a>Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07383">http://arxiv.org/abs/2309.07383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Bouland, Shengyuan Niu, Sai Tej Paruchuri, Andrew Kurdila, John Burns, Eugenio Schuster</li>
<li>for: 研究了一些值函数近似的收敛率，其出现在一组嵌入kernel空间（RKHS）$H(\Omega)$中的优化控制问题中。</li>
<li>methods: 通过将优化控制问题划入特定的本地空间中， derive strong rates of convergence for the operator equation that enables offline approximations in policy iteration。</li>
<li>results:  derive explicit upper bounds on error in value function approximations in terms of power function $\Pwr_{H,N}$ for the space of finite dimensional approximants $H_N$ in the native space $H(\Omega)$. These bounds are geometric in nature and refine some well-known, now classical results concerning convergence of approximations of value functions.<details>
<summary>Abstract</summary>
This paper studies convergence rates for some value function approximations that arise in a collection of reproducing kernel Hilbert spaces (RKHS) $H(\Omega)$. By casting an optimal control problem in a specific class of native spaces, strong rates of convergence are derived for the operator equation that enables offline approximations that appear in policy iteration. Explicit upper bounds on error in value function approximations are derived in terms of power function $\Pwr_{H,N}$ for the space of finite dimensional approximants $H_N$ in the native space $H(\Omega)$. These bounds are geometric in nature and refine some well-known, now classical results concerning convergence of approximations of value functions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beta-quantile-regression-for-robust-estimation-of-uncertainty-in-the-presence-of-outliers"><a href="#Beta-quantile-regression-for-robust-estimation-of-uncertainty-in-the-presence-of-outliers" class="headerlink" title="Beta quantile regression for robust estimation of uncertainty in the presence of outliers"></a>Beta quantile regression for robust estimation of uncertainty in the presence of outliers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07374">http://arxiv.org/abs/2309.07374</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haleh Akrami, Omar Zamzam, Anand Joshi, Sergul Aydore, Richard Leahy</li>
<li>For: The paper is written for estimating aleatoric uncertainty in deep neural networks and generating prediction intervals, with a focus on critical applications such as clinical diagnosis.* Methods: The paper proposes a robust solution for quantile regression that incorporates concepts from robust divergence, and compares the performance of this method with two existing methods (least trimmed quantile regression and robust regression based on case-specific parameter regularization) in a simple real dataset and a medical imaging translation task using diffusion models.* Results: The proposed method is shown to be effective in addressing the problem of outlier features in deep learning regression problems such as style translation, image reconstruction, and deep anomaly detection, and can provide more accurate and robust results compared to existing methods.<details>
<summary>Abstract</summary>
Quantile Regression (QR) can be used to estimate aleatoric uncertainty in deep neural networks and can generate prediction intervals. Quantifying uncertainty is particularly important in critical applications such as clinical diagnosis, where a realistic assessment of uncertainty is essential in determining disease status and planning the appropriate treatment. The most common application of quantile regression models is in cases where the parametric likelihood cannot be specified. Although quantile regression is quite robust to outlier response observations, it can be sensitive to outlier covariate observations (features). Outlier features can compromise the performance of deep learning regression problems such as style translation, image reconstruction, and deep anomaly detection, potentially leading to misleading conclusions. To address this problem, we propose a robust solution for quantile regression that incorporates concepts from robust divergence. We compare the performance of our proposed method with (i) least trimmed quantile regression and (ii) robust regression based on the regularization of case-specific parameters in a simple real dataset in the presence of outlier. These methods have not been applied in a deep learning framework. We also demonstrate the applicability of the proposed method by applying it to a medical imaging translation task using diffusion models.
</details>
<details>
<summary>摘要</summary>
量词回归（QR）可以用于深度神经网络中计算 aleatoric 不确定性，并生成预测范围。量化不确定性 particuarly 重要在医疗应用中，如诊断、诊断和治疗规划。量词回归模型通常用于 Parametric likelihood 无法指定的情况下。虽然量词回归很 robust 对于异常响应观测，但可能敏感于异常 covariate 观测（特征）。异常特征可能会导致深度学习回归问题如 Style 翻译、图像重建和深度异常检测出现问题，从而导致误导性的结论。为解决这个问题，我们提出了一种 Robust 解决方案，即 incorporating  robust 分配概念。我们与（i）最多截取量词回归和（ii）基于 Regularization 的 Case-specific 参数规则化进行比较性能。这些方法在深度学习框架中没有应用。我们还示出了提议的方法的可行性，通过应用它到一个医学图像翻译任务中。
</details></li>
</ul>
<hr>
<h2 id="Deep-Multi-Agent-Reinforcement-Learning-for-Decentralized-Active-Hypothesis-Testing"><a href="#Deep-Multi-Agent-Reinforcement-Learning-for-Decentralized-Active-Hypothesis-Testing" class="headerlink" title="Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing"></a>Deep Multi-Agent Reinforcement Learning for Decentralized Active Hypothesis Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08477">http://arxiv.org/abs/2309.08477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadar Szostak, Kobi Cohen</li>
<li>for: 这个研究是用来解决多代理 active hypothesis testing（AHT）问题的，多个代理在环境中搜集不确定观测数据，并将其转换为几个假设。</li>
<li>methods: 这个研究使用了深度多代理学习（deep multi-agent reinforcement learning，MARL）方法来解决AHT问题，每个代理使用一个训练好的深度神经网来将其状态映射到动作（抽样规则或停止规则），以最小化bayes risk。</li>
<li>results: 实验结果显示了代理们可以透过 MARLA 学习协力策略，提高性能，同时与单代理学习方法（single-agent learning）相比，MARL 表现更好。<details>
<summary>Abstract</summary>
We consider a decentralized formulation of the active hypothesis testing (AHT) problem, where multiple agents gather noisy observations from the environment with the purpose of identifying the correct hypothesis. At each time step, agents have the option to select a sampling action. These different actions result in observations drawn from various distributions, each associated with a specific hypothesis. The agents collaborate to accomplish the task, where message exchanges between agents are allowed over a rate-limited communications channel. The objective is to devise a multi-agent policy that minimizes the Bayes risk. This risk comprises both the cost of sampling and the joint terminal cost incurred by the agents upon making a hypothesis declaration. Deriving optimal structured policies for AHT problems is generally mathematically intractable, even in the context of a single agent. As a result, recent efforts have turned to deep learning methodologies to address these problems, which have exhibited significant success in single-agent learning scenarios. In this paper, we tackle the multi-agent AHT formulation by introducing a novel algorithm rooted in the framework of deep multi-agent reinforcement learning. This algorithm, named Multi-Agent Reinforcement Learning for AHT (MARLA), operates at each time step by having each agent map its state to an action (sampling rule or stopping rule) using a trained deep neural network with the goal of minimizing the Bayes risk. We present a comprehensive set of experimental results that effectively showcase the agents' ability to learn collaborative strategies and enhance performance using MARLA. Furthermore, we demonstrate the superiority of MARLA over single-agent learning approaches. Finally, we provide an open-source implementation of the MARLA framework, for the benefit of researchers and developers in related domains.
</details>
<details>
<summary>摘要</summary>
我们考虑了一个分散式的活动假设测试（AHT）问题，多个代理人从环境中获得不确定的观察，以确定正确的假设。在每个时间步骤中，代理人可以选择抽样动作。这些不同的动作将从不同的分布中获得观察，每个假设都有相应的分布。代理人协力完成任务，并在有限的通信频道上进行讯息交换。目的是发展一个多代理人政策，以最小化巴耶斯风险。这种风险包括抽样成本和代理人宣布假设时的终端成本。实现结构化政策的构成是一个严格的数学问题，即使是单一代理人的情况下也是如此。因此，最近的努力是使用深度学习方法来解决这些问题，这些方法在单一代理人学习情况下已经表现出了很大的成功。在这篇论文中，我们使用名为多代理人强化学习 для AHT（MARLA）的新算法，它在每个时间步骤中让每个代理人使用训练的深度神经网来将其状态映射到动作（抽样规则或停止规则），以最小化巴耶斯风险。我们提供了一个完整的实验结果，详细展示了代理人们可以通过MARLA学习合作策略，并提高性能。此外，我们还证明了MARLA比单一代理人学习方法更有优势。最后，我们提供了一个开源的MARLA框架，以便研究人员和相关领域的开发人员参考。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/cs.LG_2023_09_14/" data-id="clohum99x00ojpj886wlq60r7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/eess.IV_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T09:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/eess.IV_2023_09_14/">eess.IV - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Live-Iterative-Ptychography-with-projection-based-algorithms"><a href="#Live-Iterative-Ptychography-with-projection-based-algorithms" class="headerlink" title="Live Iterative Ptychography with projection-based algorithms"></a>Live Iterative Ptychography with projection-based algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08639">http://arxiv.org/abs/2309.08639</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sp-uhh/livepty">https://github.com/sp-uhh/livepty</a></li>
<li>paper_authors: Simon Welker, Tal Peer, Henry N. Chapman, Timo Gerkmann</li>
<li>for: 这个研究证明了在扫描过程中，ptychographic phase problem可以实时解决，而不需要预先处理数据。</li>
<li>methods: 这种方法基于投影方法，如Error Reduction (ER)和Difference Map (DM)，但是它提供了实时视觉反馈、对象重建和自适应扫描功能。</li>
<li>results: 研究表明，live variants of projection-based methods可以在相同的计算资源下实现更高质量的重建，并且可以在实际应用中提供实时视觉反馈。<details>
<summary>Abstract</summary>
In this work, we demonstrate that the ptychographic phase problem can be solved in a live fashion during scanning, while data is still being collected. We propose a generally applicable modification of the widespread projection-based algorithms such as Error Reduction (ER) and Difference Map (DM). This novel variant of ptychographic phase retrieval enables immediate visual feedback during experiments, reconstruction of arbitrary-sized objects with a fixed amount of computational resources, and adaptive scanning. By building upon the Real-Time Iterative Spectrogram Inversion (RTISI) family of algorithms from the audio processing literature, we show that live variants of projection-based methods such as DM can be derived naturally and may even achieve higher-quality reconstructions than their classic non-live counterparts with comparable effective computational load.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们证明了ptychographic phase problem可以在扫描过程中实时解决，而数据仍在被收集。我们提议一种通用的修改，以适应广泛的投影基本算法，如Error Reduction (ER)和Difference Map (DM)。这种新的ptychographic phase恢复方法允许实时视觉反馈、 fixed computational resources 扫描任意大小的对象、和自适应扫描。通过基于音频处理文献的Real-Time Iterative Spectrogram Inversion (RTISI)家族算法，我们显示了live variants of projection-based方法，如DM，可以自然地 derivation，并且可能 même achieve higher-quality reconstructions than their classic non-live counterparts with comparable effective computational load。
</details></li>
</ul>
<hr>
<h2 id="MPAI-EEV-Standardization-Efforts-of-Artificial-Intelligence-based-End-to-End-Video-Coding"><a href="#MPAI-EEV-Standardization-Efforts-of-Artificial-Intelligence-based-End-to-End-Video-Coding" class="headerlink" title="MPAI-EEV: Standardization Efforts of Artificial Intelligence based End-to-End Video Coding"></a>MPAI-EEV: Standardization Efforts of Artificial Intelligence based End-to-End Video Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07589">http://arxiv.org/abs/2309.07589</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yefeng00/EEV-0.4">https://github.com/yefeng00/EEV-0.4</a></li>
<li>paper_authors: Chuanmin Jia, Feng Ye, Fanke Dong, Kai Lin, Leonardo Chiariglione, Siwei Ma, Huifang Sun, Wen Gao</li>
<li>for: 这份研究是为了推动人工智能（AI）技术的标准化，特别是用于神经网络对动画的处理、编码和传输。</li>
<li>methods: 这份研究使用了神经网络技术来实现端到端优化的神经动画编码，并且不受传统的混合架构限制。</li>
<li>results: 这份研究显示了EEV模型在比较标准H.266&#x2F;VVC的评估指标下表现更好，并且可以更好地实现高品质动画资料的压缩。<details>
<summary>Abstract</summary>
The rapid advancement of artificial intelligence (AI) technology has led to the prioritization of standardizing the processing, coding, and transmission of video using neural networks. To address this priority area, the Moving Picture, Audio, and Data Coding by Artificial Intelligence (MPAI) group is developing a suite of standards called MPAI-EEV for "end-to-end optimized neural video coding." The aim of this AI-based video standard project is to compress the number of bits required to represent high-fidelity video data by utilizing data-trained neural coding technologies. This approach is not constrained by how data coding has traditionally been applied in the context of a hybrid framework. This paper presents an overview of recent and ongoing standardization efforts in this area and highlights the key technologies and design philosophy of EEV. It also provides a comparison and report on some primary efforts such as the coding efficiency of the reference model. Additionally, it discusses emerging activities such as learned Unmanned-Aerial-Vehicles (UAVs) video coding which are currently planned, under development, or in the exploration phase. With a focus on UAV video signals, this paper addresses the current status of these preliminary efforts. It also indicates development timelines, summarizes the main technical details, and provides pointers to further points of reference. The exploration experiment shows that the EEV model performs better than the state-of-the-art video coding standard H.266/VVC in terms of perceptual evaluation metric.
</details>
<details>
<summary>摘要</summary>
人工智能技术的快速发展导致了标准化处理、编程和传输视频使用神经网络的优先级。为解决这一优先领域，人工智能视频编码标准（MPAI）小组在开发一个名为“终端优化神经视频编码”（MPAI-EEV）的标准集。该项目的目标是通过使用训练过的神经网络编码技术来压缩表示高精度视频数据的比特数。这种方法不受传统的混合框架下的数据编码方法的限制。本文提供了最近和进行中的标准化努力的概述，以及EEV的关键技术和设计哲学。它还对参考模型的编码效率进行了比较报告。此外，它还讨论了正在进行的learned Unmanned-Aerial-Vehicles（UAV）视频编码活动，包括目前的规划、开发和探索阶段。关注UAV视频信号，本文介绍了当前的初步努力，包括发展时间表、主要技术细节和更多参考点。实验表明，EEV模型在可视评价指标上表现更好于当前最佳视频编码标准H.266/VVC。
</details></li>
</ul>
<hr>
<h2 id="Oscillating-gradient-spin-echo-diffusion-weighted-imaging-OGSE-DWI-with-a-limited-number-of-oscillations-II-Asymptotics"><a href="#Oscillating-gradient-spin-echo-diffusion-weighted-imaging-OGSE-DWI-with-a-limited-number-of-oscillations-II-Asymptotics" class="headerlink" title="Oscillating-gradient spin-echo diffusion-weighted imaging (OGSE-DWI) with a limited number of oscillations: II. Asymptotics"></a>Oscillating-gradient spin-echo diffusion-weighted imaging (OGSE-DWI) with a limited number of oscillations: II. Asymptotics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07484">http://arxiv.org/abs/2309.07484</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeff Kershaw, Takayuki Obata</li>
<li>for: 这个研究的目的是研究气压gradient spin-echo扩散磁共振成像(OGSE-DWI)技术在复频域中的应用，以研究复杂的湿物质的微结构。</li>
<li>methods: 这个研究使用了OGSE-DWI技术，通过测量$U_{kk}$和$U_{k0}$这两个量来间接获取分子扩散 спектrum的信息。</li>
<li>results: 研究发现，在低频和高频限制下，气压gradient spin-echo扩散磁共振成像信号的各自特征具有普适的行为，这些行为是基于样本的全局组织结构。<details>
<summary>Abstract</summary>
Oscillating-gradient spin-echo diffusion-weighted magnetic resonance imaging (OGSE-DWI) has been promoted as a promising technique for studying the microstructure of complex hydrated matter in the frequency domain. The target of the OGSE-DWI technique is the spectral density of molecular diffusion, $u_{2}(\omega)$, which is predicted to obey a set of asymptotic universality relations that are linked to the global organisation of the sample. So, in principle the complex microstructure of a medium can be classified by measuring the spectral density in its low- and high-frequency limits. However, due to practical limitations on the spectral resolution and range of the technique, it is not possible to directly sample the spectral density with OGSE-DWI. Rather, information about the spectral density can be obtained only indirectly through the quantities $U_{kk}$ & $U_{k0}$, which are filtered representations of $u_{2}(\omega)$. The purpose of this study is to investigate how the universal behaviour of $u_{2}(\omega)$ emerges in the asymptotic behaviour of OGSE-DWI signal.
</details>
<details>
<summary>摘要</summary>
oscilating-gradient spin-echo diffusion-weighted magnetic resonance imaging (OGSE-DWI) 被广泛推广为研究复杂湿物质微结构的有效技术。 OGSE-DWI 技术的目标是分子扩散 спектル的密度函数 $u_{2}(\omega)$，这被预计遵循一系列的极限universality关系，与样本的全局结构相关。因此，通过测量低频和高频限的 spectral density，可以直接分类复杂medium的微结构。然而，由于 OGSE-DWI 技术的实际 spectral resolution和范围有限制，因此不能直接测量 spectral density。相反，通过 quantities $U_{kk}$ 和 $U_{k0}$，这些是 $u_{2}(\omega)$ 的过滤表示，可以获得有关 spectral density 的信息。本研究的目标是研究 OGSE-DWI 信号的极限行为中 universality 行为如何emerge。
</details></li>
</ul>
<hr>
<h2 id="CvFormer-Cross-view-transFormers-with-Pre-training-for-fMRI-Analysis-of-Human-Brain"><a href="#CvFormer-Cross-view-transFormers-with-Pre-training-for-fMRI-Analysis-of-Human-Brain" class="headerlink" title="CvFormer: Cross-view transFormers with Pre-training for fMRI Analysis of Human Brain"></a>CvFormer: Cross-view transFormers with Pre-training for fMRI Analysis of Human Brain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07940">http://arxiv.org/abs/2309.07940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangzhu Meng, Qiang Liu, Shu Wu, Liang Wang</li>
<li>for: 这 paper 旨在Addressing the issue of neglecting complementary information between region of interest (RoI) nodes and their connectivities in human brain functional magnetic resonance imaging (fMRI) data, by proposing a novel cross-view analysis method called Cross-view transFormers (CvFormer).</li>
<li>methods: CvFormer 使用 RoI 和连接性编码模块生成两个不同视图的人脑Brain, 然后使用基本 transformer 模块处理 RoI 和子连接 tokens，并将两个视图的信息集成在 cross-view 模块中。此外，CvFormer 还使用全局 токен作为每个分支的查询，以便在 cross-view 模块中交换信息，这需要 linear 时间的计算和存储复杂度而不是quadratic 时间。</li>
<li>results: 实验结果表明，提出的 CvFormer 可以在 two public ABIDE 和 ADNI 数据集上显著提高表达，证明其效果和超越性。<details>
<summary>Abstract</summary>
In recent years, functional magnetic resonance imaging (fMRI) has been widely utilized to diagnose neurological disease, by exploiting the region of interest (RoI) nodes as well as their connectivities in human brain. However, most of existing works only rely on either RoIs or connectivities, neglecting the potential for complementary information between them. To address this issue, we study how to discover the rich cross-view information in fMRI data of human brain. This paper presents a novel method for cross-view analysis of fMRI data of the human brain, called Cross-view transFormers (CvFormer). CvFormer employs RoI and connectivity encoder modules to generate two separate views of the human brain, represented as RoI and sub-connectivity tokens. Then, basic transformer modules can be used to process the RoI and sub-connectivity tokens, and cross-view modules integrate the complement information across two views. Furthermore, CvFormer uses a global token for each branch as a query to exchange information with other branches in cross-view modules, which only requires linear time for both computational and memory complexity instead of quadratic time. To enhance the robustness of the proposed CvFormer, we propose a two-stage strategy to train its parameters. To be specific, RoI and connectivity views can be firstly utilized as self-supervised information to pre-train the CvFormer by combining it with contrastive learning and then fused to finetune the CvFormer using label information. Experiment results on two public ABIDE and ADNI datasets can show clear improvements by the proposed CvFormer, which can validate its effectiveness and superiority.
</details>
<details>
<summary>摘要</summary>
近年来，功能核磁共振成像（fMRI）已广泛应用于诊断神经系统疾病，利用人脑中的区域兴趣（RoI）节点和其连接性。然而，大多数现有工作只是利用RoI或连接性，忽略了这两者之间的可能性。为了解决这个问题，我们研究如何在人脑fMRI数据中发现富有跨视图信息。本文提出了一种新的跨视图分析人脑fMRI数据的方法，称为跨视图变换器（CvFormer）。CvFormer使用RoI和连接性编码模块生成两个分开的人脑视图，即RoI和子连接度 tokens。然后，基本变换模块可以处理RoI和子连接度 tokens，并将两个视图的补充信息集成起来。此外，CvFormer使用每个分支的全局token作为查询，在跨视图模块中交换信息，只需要线性时间的计算和存储复杂度，而不是 quadratic时间。为了增强提出的CvFormerRobustness，我们提出了一种两阶段策略来训练其参数。具体来说，RoI和连接视图可以在先使用自我超视的方式将CvFormer pré-训练，然后将其与标签信息混合以进行精度训练。实验结果表明，提出的CvFormer在两个公共的ABIDE和ADNI数据集上具有显著改进，这可以证明其效果和优势。
</details></li>
</ul>
<hr>
<h2 id="VCD-A-Video-Conferencing-Dataset-for-Video-Compression"><a href="#VCD-A-Video-Conferencing-Dataset-for-Video-Compression" class="headerlink" title="VCD: A Video Conferencing Dataset for Video Compression"></a>VCD: A Video Conferencing Dataset for Video Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07376">http://arxiv.org/abs/2309.07376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Babak Naderi, Ross Cutler, Nabakumar Singh Khongbantabam, Yasaman Hosseinkashi</li>
<li>for: The paper is written for evaluating video codecs for real-time communication in video conferencing scenarios.</li>
<li>methods: The paper presents a new dataset called the Video Conferencing Dataset (VCD) that includes a wide variety of camera qualities and spatial and temporal information.</li>
<li>results: The paper reports the compression efficiency of several popular video codecs (H.264, H.265, H.266, and AV1) in low-delay settings on VCD and compares them with non-video conferencing datasets. The results show that the source quality and scenarios have a significant effect on the compression efficiency of all the codecs.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为评估视频编码器在视频会议场景中的实时通信而写的。</li>
<li>methods: 论文提出了一个新的视频会议数据集（VCD），该数据集包含多种摄像头质量和空间和时间信息。</li>
<li>results: 论文Report了H.264、H.265、H.266和AV1等多种流行的视频编码器在VCD中的压缩效率，并与非视频会议数据集进行比较。结果显示源质量和场景具有重要的影响于所有编码器的压缩效率。<details>
<summary>Abstract</summary>
Commonly used datasets for evaluating video codecs are all very high quality and not representative of video typically used in video conferencing scenarios. We present the Video Conferencing Dataset (VCD) for evaluating video codecs for real-time communication, the first such dataset focused on video conferencing. VCD includes a wide variety of camera qualities and spatial and temporal information. It includes both desktop and mobile scenarios and two types of video background processing. We report the compression efficiency of H.264, H.265, H.266, and AV1 in low-delay settings on VCD and compare it with the non-video conferencing datasets UVC, MLC-JVC, and HEVC. The results show the source quality and the scenarios have a significant effect on the compression efficiency of all the codecs. VCD enables the evaluation and tuning of codecs for this important scenario. The VCD is publicly available as an open-source dataset at https://github.com/microsoft/VCD.
</details>
<details>
<summary>摘要</summary>
通常使用的视频编码器评估 dataset 都具有非常高的质量，而不代表实际视频会议场景。我们介绍了视频会议 Dataset (VCD)，用于评估实时通信中的视频编码器，这是第一个专门针对视频会议的 dataset。VCD 包括多种摄像头质量和空间和时间信息，包括桌面和移动场景，以及两种视频背景处理方式。我们在 VCD 上测试了 H.264、H.265、H.266 和 AV1 编码器的压缩效率，并与非视频会议 dataset UVC、MLC-JVC 和 HEVC 进行比较。结果表明源质量和场景具有重要的影响于所有编码器的压缩效率。VCD 可以用于评估和调整编码器，以便在这一重要场景中实现优化。VCD 公共可用于开源 dataset，可以在 GitHub 上找到。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/eess.IV_2023_09_14/" data-id="clohum9fu014ypj883qaj8fue" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/14/eess.SP_2023_09_14/" class="article-date">
  <time datetime="2023-09-14T08:00:00.000Z" itemprop="datePublished">2023-09-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/14/eess.SP_2023_09_14/">eess.SP - 2023-09-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Rotating-Synthetic-Aperture-Radar-Imaging-via-Robust-Sparse-Array-Synthesis"><a href="#Efficient-Rotating-Synthetic-Aperture-Radar-Imaging-via-Robust-Sparse-Array-Synthesis" class="headerlink" title="Efficient Rotating Synthetic Aperture Radar Imaging via Robust Sparse Array Synthesis"></a>Efficient Rotating Synthetic Aperture Radar Imaging via Robust Sparse Array Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08038">http://arxiv.org/abs/2309.08038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Zhao, Cai Wen, Quan Yuan, Rong Zheng</li>
<li>for: 提高ROSAR的实时性和计算效率，使其在各种应用中更加广泛应用。</li>
<li>methods: 基于可重要稳定的简单频率阵列synthesis技术，通过范围维度匹配滤波和方向维度匹配滤波，实现高效的SAR图像生成。</li>
<li>results: 比BPA更高效，但图像质量与BPA相当，计算时间减少90%。<details>
<summary>Abstract</summary>
Rotating Synthetic Aperture Radar (ROSAR) can generate a 360$^\circ$ image of its surrounding environment using the collected data from a single moving track. Due to its non-linear track, the Back-Projection Algorithm (BPA) is commonly used to generate SAR images in ROSAR. Despite its superior imaging performance, BPA suffers from high computation complexity, restricting its application in real-time systems. In this paper, we propose an efficient imaging method based on robust sparse array synthesis. It first conducts range-dimension matched filtering, followed by azimuth-dimension matched filtering using a selected sparse aperture and filtering weights. The aperture and weights are computed offline in advance to ensure robustness to array manifold errors induced by the imperfect radar rotation. We introduce robust constraints on the main-lobe and sidelobe levels of filter design. The resultant robust sparse array synthesis problem is a non-convex optimization problem with quadratic constraints. An algorithm based on feasible point pursuit and successive convex approximation is devised to solve the optimization problem. Extensive simulation study and experimental evaluations using a real-world hardware platform demonstrate that the proposed algorithm can achieve image quality comparable to that of BPA, but with a substantial reduction in computational time up to 90%.
</details>
<details>
<summary>摘要</summary>
绕转synthetic aperture radar（ROSAR）可以使用收集的数据生成360度的环境图像，而不需要多个静止轨迹。由于其非线性轨迹，因此通常使用回投算法（BPA）生成SAR图像。尽管它的图像性能更高，但BPA受到高计算复杂性的限制，因此无法应用于实时系统。在这篇论文中，我们提出了一种高效的图像方法，基于强健的稀疏阵列synthesis。它首先进行距离维度匹配滤波，然后使用选择的稀疏阵列和滤波加重来进行 azimuth维度匹配滤波。阵列和加重在线上预计算，以确保对雷达旋转induced的阵列 manifold errors 的Robustness。我们引入了主ibeam和副ibeam水平的Robust constraints。结果的强健稀疏阵列synthesis问题是非束convEX optimization问题，其中 quadratic constraints。我们提出了基于可行点追求和successive convex approximation的算法来解决优化问题。广泛的模拟研究和使用实际硬件平台进行的实验评估表明，提议的算法可以实现与BPA相同的图像质量，但计算时间减少了90%。
</details></li>
</ul>
<hr>
<h2 id="On-Distributed-and-Asynchronous-Sampling-of-Gaussian-Processes-for-Sequential-Binary-Hypothesis-Testing"><a href="#On-Distributed-and-Asynchronous-Sampling-of-Gaussian-Processes-for-Sequential-Binary-Hypothesis-Testing" class="headerlink" title="On Distributed and Asynchronous Sampling of Gaussian Processes for Sequential Binary Hypothesis Testing"></a>On Distributed and Asynchronous Sampling of Gaussian Processes for Sequential Binary Hypothesis Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07855">http://arxiv.org/abs/2309.07855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nandan Sriranga, Saikiran Bulusu, Baocheng Geng, Pramod K. Varshney</li>
<li>for: 本研究假设了一个二进制顺序假设测试问题，其中测试数据来自分布式和异步探测器。研究者们分析了在分布式探测器中jointly宽感Stationary（WSS） Gaussian观测过程的采样时间对顺序测试的预期停止时间的影响。</li>
<li>methods: 研究者们使用了随机采样理论来分析顺序测试的性能。他们还使用了异步采样的概率 bound来分析顺序测试的性能。</li>
<li>results: 研究者们发现了采样时间对顺序测试的影响，并提供了采样时间的下界和上界。他们还通过数值计算来证明了理论结论的正确性。<details>
<summary>Abstract</summary>
In this work, we consider a binary sequential hypothesis testing problem with distributed and asynchronous measurements. The aim is to analyze the effect of sampling times of jointly \textit{wide-sense stationary} (WSS) Gaussian observation processes at distributed sensors on the expected stopping time of the sequential test at the fusion center (FC). The distributed system is such that the sensors and the FC sample observations periodically, where the sampling times are not necessarily synchronous, i.e., the sampling times at different sensors and the FC may be different from each other. \color{black} The sampling times, however, are restricted to be within a time window and a sample obtained within the window is assumed to be \textit{uncorrelated} with samples outside the window. We also assume that correlations may exist only between the observations sampled at the FC and those at the sensors in a pairwise manner (sensor pairs not including the FC have independent observations). The effect of \textit{asynchronous} sampling on the SPRT performance is analyzed by obtaining bounds for the expected stopping time. We illustrate the validity of the theoretical results with numerical results.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们考虑了一个二进制顺序假设测试问题，其中测量过程是分布式和 asynchronous。我们想要分析在分布式感知器和汇中心（FC）之间的共同 Gaussian 观测过程中，采样时间的影响。我们假设了所有感知器和FC在Periodically采样观测数据，但采样时间不一定同步。具体来说，采样时间在不同的感知器和FC之间可能不同。然而，采样时间都限制在一个时间窗口内，而在这个窗口内采样的样本假设是独立的。我们还假设了感知器对感知器之间的观测是对称的，即感知器对感知器之间的观测是独立的。我们分析了异步采样对 SPRT 性能的影响，并获得了预期停止时间的下界。我们通过数据示例来证明理论结果的正确性。
</details></li>
</ul>
<hr>
<h2 id="Kullback-Leibler-Divergence-Guided-Copula-Statistics-Based-Blind-Source-Separation-of-Dependent-Signals"><a href="#Kullback-Leibler-Divergence-Guided-Copula-Statistics-Based-Blind-Source-Separation-of-Dependent-Signals" class="headerlink" title="Kullback-Leibler Divergence-Guided Copula Statistics-Based Blind Source Separation of Dependent Signals"></a>Kullback-Leibler Divergence-Guided Copula Statistics-Based Blind Source Separation of Dependent Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07814">http://arxiv.org/abs/2309.07814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pooja Algikar, Lamine Mili, Kiran Karra, Mohsen Ben Hassine</li>
<li>for: 该文章提出了一种基于 copula 统计的盲源分离方法，用于分离线性混合的依赖源信号。</li>
<li>methods: 该方法基于 copula 统计量度源信号的非线性依赖关系，并使用 Kullback-Leibler 差分来估算依赖结构。</li>
<li>results: 实验结果表明，基于 copula 统计的盲源分离方法在11-Bus 4-Machine 系统中的时域分析数据上 converges faster 并且表现更好，相比之下 state-of-the-art 盲源分离方法。<details>
<summary>Abstract</summary>
In this paper, we propose a blind source separation of a linear mixture of dependent sources based on copula statistics that measure the non-linear dependence between source component signals structured as copula density functions. The source signals are assumed to be stationary. The method minimizes the Kullback-Leibler divergence between the copula density functions of the estimated sources and of the dependency structure. The proposed method is applied to data obtained from the time-domain analysis of the classical 11-Bus 4-Machine system. Extensive simulation results demonstrate that the proposed method based on copula statistics converges faster and outperforms the state-of-the-art blind source separation method for dependent sources in terms of interference-to-signal ratio.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于 copula 统计的无参源分离方法，用于分解线性混合的相关源信号。我们假设源信号是站ARY的。方法的目标是将 copula density function 的两个分布匹配，以最小化库拉-莱布勒散度的差异。我们对来自经典 11-Bus 4-Machine 系统的时域分析数据进行了应用。广泛的 simulate 结果表明，基于 copula 统计的方法在相关源信号分离方面比现有的方法更快 converge 和有更高的干扰比信号比。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Performance-Calibration-Time-and-Efficiency-in-Brain-Machine-Interfaces-through-Transfer-Learning-and-Wearable-EEG-Technology"><a href="#Enhancing-Performance-Calibration-Time-and-Efficiency-in-Brain-Machine-Interfaces-through-Transfer-Learning-and-Wearable-EEG-Technology" class="headerlink" title="Enhancing Performance, Calibration Time and Efficiency in Brain-Machine Interfaces through Transfer Learning and Wearable EEG Technology"></a>Enhancing Performance, Calibration Time and Efficiency in Brain-Machine Interfaces through Transfer Learning and Wearable EEG Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07798">http://arxiv.org/abs/2309.07798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaying Wang, Lan Mei, Victor Kartsch, Andrea Cossettini, Luca Benini</li>
<li>for: 这个研究旨在解决助生技术中的持续性问题，协助患有motor impairments的个体控制设备和实现功能恢复。</li>
<li>methods: 本研究使用了一个 tiny CNN-based Transfer Learning (TL) 方法，与舒适的 wearable EEG 头盔相结合。这个新型的 wearable EEG 设备使用了软干电极，能够在头盔上进行处理。</li>
<li>results: 研究获得了多Session的 motor-movement EEG 数据，并在 TL 下实现了96% 的 inter-session 精度，大大减少了准确时间和使用度。透过在 Edge 上执行推断 every 100ms，系统估计可以实现30小时的电池生命。<details>
<summary>Abstract</summary>
Brain-machine interfaces (BMIs) have emerged as a transformative force in assistive technologies, empowering individuals with motor impairments by enabling device control and facilitating functional recovery. However, the persistent challenge of inter-session variability poses a significant hurdle, requiring time-consuming calibration at every new use. Compounding this issue, the low comfort level of current devices further restricts their usage. To address these challenges, we propose a comprehensive solution that combines a tiny CNN-based Transfer Learning (TL) approach with a comfortable, wearable EEG headband. The novel wearable EEG device features soft dry electrodes placed on the headband and is capable of on-board processing. We acquire multiple sessions of motor-movement EEG data and achieve up to 96% inter-session accuracy using TL, greatly reducing the calibration time and improving usability. By executing the inference on the edge every 100ms, the system is estimated to achieve 30h of battery life. The comfortable BMI setup with tiny CNN and TL paves the way to future on-device continual learning, essential for tackling inter-session variability and improving usability.
</details>
<details>
<summary>摘要</summary>
Brain-machine interfaces (BMIs) 蜕化为助手技术的新动力，激活人们的 motor 功能障碍，并且使得设备控制和功能恢复更加容易。然而，在每次使用时需要时间consuming的 calibration 仍然是一大障碍。此外，现有的设备舒适度还是一个限制因素。为了解决这些挑战，我们提出了一个综合解决方案，结合 tiny CNN 基于传输学习 (TL) 的方法，以及舒适可穿戴的 EEG 头盔。这种新的 EEG 设备采用软干电极置于头盔上，并可以在设备上进行处理。我们收集了多个 motor 运动 EEG 数据，并使用 TL 实现了96%的session accuracy，从而大幅减少了 calibration 时间，并提高了使用性。通过在边缘进行每100ms的执行推理，系统估计可以达到30小时的电池寿命。舒适的 BMI 设置，结合 tiny CNN 和 TL，为未来的在设备上进行不断学习做出了重要贡献，以解决inter-session variability和提高使用性。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-Phased-Array-Performance-Indicators-for-Quality-of-Service-Enhanced-Massive-MIMO"><a href="#Stochastic-Phased-Array-Performance-Indicators-for-Quality-of-Service-Enhanced-Massive-MIMO" class="headerlink" title="Stochastic Phased Array Performance Indicators for Quality-of-Service-Enhanced Massive MIMO"></a>Stochastic Phased Array Performance Indicators for Quality-of-Service-Enhanced Massive MIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07740">http://arxiv.org/abs/2309.07740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noud Kanters, Andrés Alayón Glazunov</li>
<li>for: 本研究旨在描述基站（BS）装备不同物理数组天线时，信号吞吐量（SINR）的表达方式，具体来说是通过两个基本的优势因素（FoM）：一是实时有效增益（IEG），二是扫描频率干扰相关（BCC）。</li>
<li>methods: 本研究使用了全数字零强制扫描（FD ZF）天线扫描算法，并研究了不同天线排布的影响。</li>
<li>results: 研究结果表明，高IEG和低BCC的天线排布可以提高融合总bitrate和减少调度需求。<details>
<summary>Abstract</summary>
In this paper, we show that the signal-to-interference-plus-noise ratio (SINR) at a base station (BS) equipped with an arbitrary physical array antenna can be expressed as a function of two fundamental figures-of-merit (FoMs): (I) the instantaneous effective gain (IEG), and (II) the beamforming-channel correlation (BCC). These two FoMs are functions of the array antenna layout, the antenna elements, the propagation channel and the applied signal processing algorithms, and hence they are random variables (RVs) in general. We illustrate that both FoMs provide essential insights for quality-of-service (QoS)-based phased array design by investigating their statistics for BSs applying full-digital (FD) zero forcing (ZF) beamforming. We evaluate various array designs and show that arrays with higher IEGs and a reduced probability of low BCCs can increase the ergodic sum rate and reduce the need for scheduling.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们显示了基站（BS）装备任意物理数组天线的信号吞吐量较干扰噪声比（SINR）可以表示为两个基本的优势因素（FoM）：（I）即时效果的辐射增益（IEG），和（II）扫描通道卷积（BCC）。这两个 FoM 是天线阵列布局、天线元件、传播通道和应用的信号处理算法的函数，因此它们是随机变量（RV）的一般情况。我们表明了这两个 FoM 对服务质量（QoS）基于天线阵列设计带来了重要的洞察，通过研究这两个 FoM 的统计特性来评估不同的天线阵列设计。我们评估了多种阵列设计，并显示了高IEG和低BCC的概率可以提高杂合辐射率和减少调度需求。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-RIS-STAR-IOS-aided-V2V-NOMA-OMA-Communications-over-Composite-Fading-Channels"><a href="#Performance-Analysis-of-RIS-STAR-IOS-aided-V2V-NOMA-OMA-Communications-over-Composite-Fading-Channels" class="headerlink" title="Performance Analysis of RIS&#x2F;STAR-IOS-aided V2V NOMA&#x2F;OMA Communications over Composite Fading Channels"></a>Performance Analysis of RIS&#x2F;STAR-IOS-aided V2V NOMA&#x2F;OMA Communications over Composite Fading Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07738">http://arxiv.org/abs/2309.07738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farshad Rostami Ghadi, Masoud Kaveh, Diego Martin</li>
<li>For: 本研究探讨了基于协助器（RIS）和同时发射和反射智能多面（STAR-IOS）的车辆到车辆（V2V）通信的性能，尤其是在非对称多Access（NOMA）和对称多Access（OMA）方案下。* Methods: 本研究使用了中心限定定理（CLT）来 deriv 同aje channel的PDF和CDF，并使用了Jensen不等式来提出一个Upper bound of 平均容量（EC），以及一个分析表达式来计算智能交通系统（ITS）中的能量效率（EE）。* Results: 研究结果显示，在V2V通信中应用RIS&#x2F;STAR-RIS可以显著改善智能交通系统的性能，并且在NOMA和OMA场景下，considering NOMA scheme可以提供更好的性能，包括出入口概率（OP）、平均容量（EC）和能量效率（EE）。<details>
<summary>Abstract</summary>
This paper investigates the performance of vehicleto-vehicle (V2V) communications assisted by a reconfigurable intelligent surface (RIS) and a simultaneous transmitting and reflecting intelligent omni-surface (STAR-IOS) under nonorthogonal multiple access (NOMA) and orthogonal multiple access (OMA) schemes. In particular, we consider that the RIS is close to the transmitter vehicle while the STAR-IOS is near the receiver vehicles. In addition, we assume that the STAR-IOS exploits the energy-splitting (ES) protocol for communication and the fading channels between the RIS and STAR-IOS follow composite Fisher-Snedecor F distribution. Under such assumptions, we first use the central limit theorem (CLT) to derive the PDF and the CDF of equivalent channels at receiver vehicles, and then, we derive the closed-form expression of outage probability (OP) under NOMA/OMA scenarios. Additionally, by exploiting Jensen's inequality, we propose an upper bound of the ergodic capacity (EC), and then, we derive an analytical expression of the energy efficiency (EE) for both NOMA and OMA cases. Further, our analytical results, which are double-checked with the Monte-Carlo simulation, reveal that applying RIS/STAR-RIS in V2V communications can significantly improve the performance of intelligent transportation systems (ITS). Besides, the results indicate that considering the NOMA scheme provides better performance in terms of the OP, EC, and EE as compared with the OMA case for the considered V2V communication.
</details>
<details>
<summary>摘要</summary>
Using the central limit theorem (CLT), we first derive the probability distribution function (PDF) and the cumulative distribution function (CDF) of the equivalent channels at the receiver vehicles. Then, we derive a closed-form expression for the outage probability (OP) under both NOMA and OMA scenarios. Additionally, by exploiting Jensen's inequality, we propose an upper bound on the ergodic capacity (EC) and derive an analytical expression for the energy efficiency (EE) for both NOMA and OMA cases.Our analytical results, which are verified through Monte-Carlo simulations, show that incorporating RIS/STAR-IOS in V2V communications can significantly improve the performance of intelligent transportation systems (ITS). Furthermore, our results indicate that the NOMA scheme outperforms the OMA case in terms of OP, EC, and EE for the considered V2V communication.Here is the Simplified Chinese translation of the text:这篇论文研究了使用拓展智能表面（RIS）和同时传输和反射智能全面（STAR-IOS）帮助汽车间通信，以及在不对称多接入（NOMA）和对称多接入（OMA）方案下的性能。特别是，我们假设RIS靠近发送器汽车，而STAR-IOS靠近接收器汽车。此外，我们假设STAR-IOS使用能量分配（ES）协议进行通信，并且在RIS和STAR-IOS之间的投射通道遵循复合拜让-斯内多辛（F）分布。使用中心限定定律（CLT），我们首先计算发送器汽车的等效通道PDF和CDF，然后计算OP的关键值。此外，我们通过贝叶斯不等式提出OP的上限，并计算NOMA和OMA情况下的吞吐量率（EC）和能效率（EE）的分析表达式。我们的分析结果，通过对 Monte-Carlo 仿真进行验证，表明在汽车间通信中应用 RIS/STAR-IOS 可以显著提高智能交通系统（ITS）的性能。此外，我们的结果还表明，在考虑 NOMA 方案时，OP、EC 和 EE 的性能都比 OMA 情况更好。
</details></li>
</ul>
<hr>
<h2 id="RIS-Assisted-Physical-Layer-Authentication-for-6G-Endogenous-Security"><a href="#RIS-Assisted-Physical-Layer-Authentication-for-6G-Endogenous-Security" class="headerlink" title="RIS-Assisted Physical Layer Authentication for 6G Endogenous Security"></a>RIS-Assisted Physical Layer Authentication for 6G Endogenous Security</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07736">http://arxiv.org/abs/2309.07736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Gao, Cen Li, Shengguo Meng, Wankai Tang, Shuchen Meng, Shi Jin, Michail Matthaiou</li>
<li>for: 增强未来各种设备访问安全性的技术之一，physical layer authentication (PLA)。</li>
<li>methods: 提议使用智能表面（RIS） assisted PLA系统，在PLA过程中，合法的发送器可以自定义通道指纹。</li>
<li>results: 通过分析Received Signal Strength（RSS）基于的骗取检测方法，验证了提议的架构的可行性。实验结果显示，在不同发送源位置和同一个发送源位置下，具有3.5%和76%的性能提升。<details>
<summary>Abstract</summary>
The physical layer authentication (PLA) is a promising technology which can enhance the access security of a massive number of devices in the near future. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted PLA system, in which the legitimate transmitter can customize the channel fingerprints during PLA by controlling the ON-OFF state of the RIS. Without loss of generality, we use the received signal strength (RSS) based spoofing detection approach to analyze the feasibility of the proposed architecture. Specifically, based on the RSS, we derive the statistical properties of PLA and give some interesting insights, which showcase that the RIS-assisted PLA is theoretically feasible. Then, we derive the optimal detection threshold to maximize the performance in the context of the presented performance metrics. Next, the actual feasibility of the proposed system is verified via proof-of-concept experiments on a RIS-assisted PLA prototype platform. The experiment results show that there are 3.5% and 76% performance improvements when the transmission sources are at different locations and at the same location, respectively.
</details>
<details>
<summary>摘要</summary>
物理层身份验证（PLA）是一种有前途的技术，可以增强未来大量设备的访问安全性。在这篇论文中，我们提议了基于智能表面（RIS）的PLA系统，其中有效发送器可以在PLA中自定义通道指纹。不失一般性，我们使用基于受信号强度（RSS）的伪造探测方法来分析提议的体系的可行性。特别是基于RSS，我们 derivates了PLA的统计性质并提供了一些有趣的发现，这些发现表明RIS协助的PLA是理论上可行的。然后，我们计算了最佳检测阈值以最大化性能在所提出的性能指标下。接下来，我们验证了提议的系统的实际可行性通过一个基于RIS协助PLA的原型平台的证明实验。实验结果显示，在不同位置的发送源情况下，提议的系统具有3.5%和76%的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Semantic-reconstruction-of-continuous-language-from-MEG-signals"><a href="#Semantic-reconstruction-of-continuous-language-from-MEG-signals" class="headerlink" title="Semantic reconstruction of continuous language from MEG signals"></a>Semantic reconstruction of continuous language from MEG signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07701">http://arxiv.org/abs/2309.07701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Wang, Xiran Xu, Longxiang Zhang, Boda Xiao, Xihong Wu, Jing Chen</li>
<li>for: 这个研究的目的是使用 magnetoencephalography (MEG) 信号来解读语言 semantics。</li>
<li>methods: 该研究使用了一种数据驱动的方法，首先使用对比学习训练多个参与者的决定模型，然后使用搜索算法生成基于 MEG 数据的连续语句。</li>
<li>results: 研究结果表明，提posed的连续词嵌入模型可以有效地利用每个参与者的专有信息和共享信息。此外，生成的文本具有与目标文本相似的相关性，BERTScore 平均值为 0.816，与之前的 fMRI 研究相当。<details>
<summary>Abstract</summary>
Decoding language from neural signals holds considerable theoretical and practical importance. Previous research has indicated the feasibility of decoding text or speech from invasive neural signals. However, when using non-invasive neural signals, significant challenges are encountered due to their low quality. In this study, we proposed a data-driven approach for decoding semantic of language from Magnetoencephalography (MEG) signals recorded while subjects were listening to continuous speech. First, a multi-subject decoding model was trained using contrastive learning to reconstruct continuous word embeddings from MEG data. Subsequently, a beam search algorithm was adopted to generate text sequences based on the reconstructed word embeddings. Given a candidate sentence in the beam, a language model was used to predict the subsequent words. The word embeddings of the subsequent words were correlated with the reconstructed word embedding. These correlations were then used as a measure of the probability for the next word. The results showed that the proposed continuous word embedding model can effectively leverage both subject-specific and subject-shared information. Additionally, the decoded text exhibited significant similarity to the target text, with an average BERTScore of 0.816, a score comparable to that in the previous fMRI study.
</details>
<details>
<summary>摘要</summary>
decode language from neural signals has important theoretical and practical significance. Previous research has shown that it is feasible to decode text or speech from invasive neural signals. However, when using non-invasive neural signals, there are significant challenges due to their low quality. In this study, we proposed a data-driven approach for decoding the semantic of language from Magnetoencephalography (MEG) signals recorded while subjects were listening to continuous speech. First, a multi-subject decoding model was trained using contrastive learning to reconstruct continuous word embeddings from MEG data. Then, a beam search algorithm was adopted to generate text sequences based on the reconstructed word embeddings. Given a candidate sentence in the beam, a language model was used to predict the subsequent words. The word embeddings of the subsequent words were correlated with the reconstructed word embedding. These correlations were then used as a measure of the probability for the next word. The results showed that the proposed continuous word embedding model can effectively leverage both subject-specific and subject-shared information. Additionally, the decoded text exhibited significant similarity to the target text, with an average BERTScore of 0.816, a score comparable to that in the previous fMRI study.
</details></li>
</ul>
<hr>
<h2 id="On-the-Relationship-Between-Iterated-Statistical-Linearization-and-Quasi-Newton-Methods"><a href="#On-the-Relationship-Between-Iterated-Statistical-Linearization-and-Quasi-Newton-Methods" class="headerlink" title="On the Relationship Between Iterated Statistical Linearization and Quasi-Newton Methods"></a>On the Relationship Between Iterated Statistical Linearization and Quasi-Newton Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07636">http://arxiv.org/abs/2309.07636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anton Kullberg, Martin A. Skoglund, Isaac Skog, Gustaf Hendeby</li>
<li>for: 本研究 investigate了基于统计线性化的迭代筛选算法，如迭代感知卡尔曼筛选器（IUKF）和迭代 posterior linearization筛选器（IPLF）与基于 quasi-Newton（QN）方法的筛选算法之间的关系。</li>
<li>methods: 本研究表明了IUKF和IPLF可以视为QN算法，通过在QN-IEKF中找到一个Hessian更正，使IUKF和IPLF迭代iterate更新与QN-IEKF的iterate更新相同。</li>
<li>results: 本研究还表明了IUKF和IPLF更新可以被rewrite为与QN-IEKF更新相似，即使有一个补做项。这使我们对基于统计线性化的迭代筛选算法的性能有更深刻的理解。<details>
<summary>Abstract</summary>
This letter investigates relationships between iterated filtering algorithms based on statistical linearization, such as the iterated unscented Kalman filter (IUKF), and filtering algorithms based on quasi-Newton (QN) methods, such as the QN iterated extended Kalman filter (QN-IEKF). Firstly, it is shown that the IUKF and the iterated posterior linearization filter (IPLF) can be viewed as QN algorithms, by finding a Hessian correction in the QN-IEKF such that the IPLF iterate updates are identical to that of the QN-IEKF. Secondly, it is shown that the IPLF/IUKF update can be rewritten such that it is approximately identical to the QN-IEKF, albeit for an additional correction term. This enables a richer understanding of the properties of iterated filtering algorithms based on statistical linearization.
</details>
<details>
<summary>摘要</summary>
Firstly, it is shown that the IUKF and the IPLF can be viewed as QN algorithms by finding a Hessian correction in the QN-IEKF such that the IPLF iterate updates are identical to those of the QN-IEKF.Secondly, it is shown that the IPLF/IUKF update can be rewritten so that it is approximately identical to the QN-IEKF, with an additional correction term. This provides a deeper understanding of the properties of iterated filtering algorithms based on statistical linearization.
</details></li>
</ul>
<hr>
<h2 id="Unified-Linearization-based-Nonlinear-Filtering"><a href="#Unified-Linearization-based-Nonlinear-Filtering" class="headerlink" title="Unified Linearization-based Nonlinear Filtering"></a>Unified Linearization-based Nonlinear Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07631">http://arxiv.org/abs/2309.07631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anton Kullberg, Isaac Skog, Gustaf Hendeby</li>
<li>for: 这个论文旨在探讨了三类重复状态估计滤波器：标准滤波器（如延长 Kalman 滤波器）、迭代滤波器（如迭代抽象 Kalman 滤波器），以及动态迭代滤波器（如动态迭代 posterior linearization 滤波器）。</li>
<li>methods: 这些滤波器使用了一种通用算法，它将三类 filters 的特点联系起来，从而探讨了各种滤波器的优缺点，并且提供了一个数字示例，用于证明不同类型的滤波器在非线性定位问题中的估计精度差异。</li>
<li>results: 数字示例表明，不同类型的滤波器在非线性定位问题中的估计精度差异较大，标准滤波器在精度方面落后于迭代滤波器和动态迭代滤波器，但是它们在计算效率方面占据了优势。<details>
<summary>Abstract</summary>
This letter shows that the following three classes of recursive state estimation filters: standard filters, such as the extended Kalman filter; iterated filters, such as the iterated unscented Kalman filter; and dynamically iterated filters, such as the dynamically iterated posterior linearization filters; can be unified in terms of a general algorithm. The general algorithm highlights the strong similarities between specific filtering algorithms in the three filter classes and facilitates an in-depth understanding of the pros and cons of the different filter classes and algorithms. We end with a numerical example showing the estimation accuracy differences between the three classes of filters when applied to a nonlinear localization problem.
</details>
<details>
<summary>摘要</summary>
这封信件显示了以下三类 recursive state estimation 筛子可以被统一为一个通用算法：标准筛子（如扩展卡尔曼筛子）、迭代筛子（如迭代抽象卡尔曼筛子）和动态迭代筛子（如动态迭代 posterior linearization 筛子）。通用算法使得specific filtering algorithms在三个筛子类中的强相似性更加明显，并且便于深入了解每个筛子类的优缺点。我们结束了一个数值示例，表明不同类型的筛子在非线性定位问题中的估计精度差异。Note: "Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Exact-solution-of-the-full-RMSA-problem-in-elastic-optical-networks"><a href="#Exact-solution-of-the-full-RMSA-problem-in-elastic-optical-networks" class="headerlink" title="Exact solution of the full RMSA problem in elastic optical networks"></a>Exact solution of the full RMSA problem in elastic optical networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07621">http://arxiv.org/abs/2309.07621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabio David, José F. de Rezende, Valmir C. Barbosa</li>
<li>for:  solves the Routing, Modulation, and Spectrum Allocation (RMSA) problem in Elastic Optical Networks (EONs) to maximize the number of admitted demands while minimizing the number of regenerators and frequency slots used.</li>
<li>methods:  uses a complex ILP (Integer Linear Programming) formulation that takes into account frequency-slot continuity and contiguity.</li>
<li>results:  the formulation is applied to the NSFNET topology to demonstrate the practicality and importance of obtaining exact solutions.<details>
<summary>Abstract</summary>
Exact solutions of the Routing, Modulation, and Spectrum Allocation (RMSA) problem in Elastic Optical Networks (EONs), so that the number of admitted demands is maximized while those of regenerators and frequency slots used are minimized, require a complex ILP formulation taking into account frequency-slot continuity and contiguity. We introduce the first such formulation, ending a hiatus of some years since the last ILP formulation for a much simpler RMSA variation was introduced. By exploiting a number of problem and solver specificities, we use the NSFNET topology to illustrate the practicality and importance of obtaining exact solutions.
</details>
<details>
<summary>摘要</summary>
Routing、Modulation、和 Spectrum Allocation（RMSA）问题的精确解决方案，以最大化接受的需求数，同时最小化使用的重建器和频率槽数，需要复杂的ILP表述，考虑频率槽连续性和紧密性。我们提出了首个这种形式的表述，结束了一些年来没有新的ILP表述的停滞。通过利用一些问题和解决方案特点，我们使用NSFNETtopology示例ify了实际性和重要性获得精确解。
</details></li>
</ul>
<hr>
<h2 id="Fluid-Antenna-Assisted-Dirty-Multiple-Access-Channels-over-Composite-Fading"><a href="#Fluid-Antenna-Assisted-Dirty-Multiple-Access-Channels-over-Composite-Fading" class="headerlink" title="Fluid Antenna-Assisted Dirty Multiple Access Channels over Composite Fading"></a>Fluid Antenna-Assisted Dirty Multiple Access Channels over Composite Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07604">http://arxiv.org/abs/2309.07604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farshad Rostami Ghadi, Kai-Kit Wong, F. Javier Lopez-Martinez, Chan-Byoung Chae, Kin-Fai Tong, Yangyang Zhang</li>
<li>for: 本文研究了在多用户通信系统中应用emerging fluid antenna（FA）技术，当有side information（SI）可用于发送器的情况下。</li>
<li>methods: 作者使用了Jakes模型和copula理论，通过Spearman的{\rho} rank correlation coefficient来准确描述FA通道之间的空间相关性，并得出了关于Fisher-Snedecor F 折射下的停机概率（OP）的关闭式表达。</li>
<li>results: 作者的计算结果表明，在考虑FA时，多用户通信系统的性能可以得到改善，特别是在OP和用户数量上。此外，作者还发现了可以使用只一个FA在接收器上支持大量用户，只需要几波长的空间。<details>
<summary>Abstract</summary>
This letter investigates the application of the emerging fluid antenna (FA) technology in multiuser communication systems when side information (SI) is available at the transmitters. In particular, we consider a K-user dirty multiple access channel (DMAC) with non-causally known SI at the transmitters, where K users send independent messages to a common receiver with a FA capable of changing its location depending on the channel condition. By connecting Jakes' model to copula theory through Spearman's {\rho} rank correlation coefficient, we accurately describe the spatial correlation between the FA channels, and derive a closed-form expression for the outage probability (OP) under Fisher-Snedecor F fading. Numerical results illustrate how considering FA can improve the performance of multiuser communication systems in terms of the OP and also support a large number of users using only one FA at the common receiver in a few wavelengths of space.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-Performance-of-Fluid-Antenna-System-using-Maximum-Ratio-Combining"><a href="#On-Performance-of-Fluid-Antenna-System-using-Maximum-Ratio-Combining" class="headerlink" title="On Performance of Fluid Antenna System using Maximum Ratio Combining"></a>On Performance of Fluid Antenna System using Maximum Ratio Combining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07582">http://arxiv.org/abs/2309.07582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiazhi Lai, Tuo Wu, Junteng Yao, Cunhua Pan, Maged Elkashlan, Kai-Kit Wong</li>
<li>for: 这个研究是 investigate a fluid antenna system (FAS) 可以同时活动多个端口，以实现更好的接收性能。</li>
<li>methods: 这个研究使用 maximum ratio combining (MRC) 将接收到的信号从选择的多个端口进行组合。</li>
<li>results: 研究结果表明，使用 FAS 可以利用各个端口的空间多样性，并且通过计算机模拟得到了证明。<details>
<summary>Abstract</summary>
This letter investigates a fluid antenna system (FAS) where multiple ports can be activated for signal combining for enhanced receiver performance. Given $M$ ports at the FAS, the best $K$ ports out of the $M$ available ports are selected before maximum ratio combining (MRC) is used to combine the received signals from the selected ports. The aim of this letter is to study the achievable performance of FAS when more than one ports can be activated. We do so by analyzing the outage probability of this setup in Rayleigh fading channels through the utilization of Gauss-Chebyshev integration, lower bound estimation, and high signal-to-noise ratio (SNR) asymptotic approximations. Our analytical results demonstrate that FAS can harness rich spatial diversity, which is confirmed by computer simulations.
</details>
<details>
<summary>摘要</summary>
这封信件研究一种流体天线系统（FAS），其中多个端口可以被激活以实现信号合并以提高接收器性能。假设有 $M$ 个端口在 FAS 中，我们需要选择最佳的 $K$ 个端口（$K \leq M$），然后使用最大比率组合（MRC）将接收到的信号从选择的端口进行组合。本信件的目的是研究 FAS 在多个端口可以被激活的情况下可以达到的性能。我们通过利用 Gaussian-Chebyshev 积分、下界估计和高 SNR 强制近似来分析 Rayleigh 抽象渐近频谱中的失业概率。我们的分析结果表明，FAS 可以利用丰富的空间多样性，这被计算仿真所证实。
</details></li>
</ul>
<hr>
<h2 id="A-Gaussian-Copula-Approach-to-the-Performance-Analysis-of-Fluid-Antenna-Systems"><a href="#A-Gaussian-Copula-Approach-to-the-Performance-Analysis-of-Fluid-Antenna-Systems" class="headerlink" title="A Gaussian Copula Approach to the Performance Analysis of Fluid Antenna Systems"></a>A Gaussian Copula Approach to the Performance Analysis of Fluid Antenna Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07506">http://arxiv.org/abs/2309.07506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farshad Rostami Ghadi, Kai-Kit Wong, F. Javier Lopez-Martinez, Chan-Byoung Chae, Kin-Fai Tong, Yangyang Zhang</li>
<li>for: 这个论文研究了单用户流体天线系统（FAS）的性能，通过利用一类圆形共corrélation函数来描述流体天线端口之间的结构相关性。</li>
<li>methods: 我们使用了Jakes模型的圆形共 corrélation函数来表示两种情况：一般情况和特定情况，并derived了相关的分布函数的数学表述。</li>
<li>results: 我们发现增加流体天线大小可以降低OP和DOR，但系统性能随天线端口数量增加而减退。此外，我们的结果表明FAS比单一固定天线系统具有更好的性能，即使流体天线较小。<details>
<summary>Abstract</summary>
This paper investigates the performance of a singleuser fluid antenna system (FAS), by exploiting a class of elliptical copulas to describe the structure of dependency amongst the fluid antenna ports. By expressing Jakes' model in terms of the Gaussian copula, we consider two cases: (i) the general case, i.e., any arbitrary correlated fading distribution; and (ii) the specific case, i.e., correlated Nakagami-m fading. For both scenarios, we first derive analytical expressions for the cumulative distribution function (CDF) and probability density function (PDF) of the equivalent channel in terms of multivariate normal distribution. Then, we obtain the outage probability (OP) and the delay outage rate (DOR) to analyze the performance of the FAS. By employing the popular rank correlation coefficients such as Spearman's \{rho} and Kendall's {\tau}, we measure the degree of dependency in correlated arbitrary fading channels and illustrate how the Gaussian copula can be accurately connected to Jakes' model in FAS without complicated mathematical analysis. Numerical results show that increasing the fluid antenna size provides lower OP and DOR, but the system performance saturates as the number of antenna ports increases. In addition, our results indicate that FAS provides better performance compared to conventional single-fixed antenna systems even when the size of fluid antenna is small.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Tutorial-on-Environment-Aware-Communications-via-Channel-Knowledge-Map-for-6G"><a href="#A-Tutorial-on-Environment-Aware-Communications-via-Channel-Knowledge-Map-for-6G" class="headerlink" title="A Tutorial on Environment-Aware Communications via Channel Knowledge Map for 6G"></a>A Tutorial on Environment-Aware Communications via Channel Knowledge Map for 6G</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07460">http://arxiv.org/abs/2309.07460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong Zeng, Junting Chen, Jie Xu, Di Wu, Xiaoli Xu, Shi Jin, Xiqi Gao, David Gesbert, Shuguang Cui, Rui Zhang</li>
<li>for: This paper aims to provide a comprehensive tutorial overview on environment-aware communications enabled by channel knowledge map (CKM) for 6G mobile communication networks.</li>
<li>methods: The paper discusses the basic concept of CKM, compares it with various existing channel inference techniques, and presents the main techniques for CKM construction, including both model-free and model-assisted approaches.</li>
<li>results: The paper provides a general framework for the utilization of CKM to achieve environment-aware communications and discusses typical CKM-aided communication scenarios. It also highlights important open problems in CKM research and potential solutions to inspire future work.Here’s the text in Simplified Chinese:</li>
<li>for: 这篇论文目标是为6G移动通信网络提供全面的教程介绍，演示如何通过通道知识地图（CKM）实现环境意识通信。</li>
<li>methods: 论文介绍CKM的基本概念，与现有的通道推理技术进行比较，并介绍CKM构建的主要技术，包括无模型和模型支持的方法。</li>
<li>results: 论文提供CKM在环境意识通信中的总体框架，并介绍一些典型的CKM帮助通信场景。它还提出了importante的CKM研究开放问题，并讨论了可能的解决方案，以启发未来工作。<details>
<summary>Abstract</summary>
Sixth-generation (6G) mobile communication networks are expected to have dense infrastructures, large-dimensional channels, cost-effective hardware, diversified positioning methods, and enhanced intelligence. Such trends bring both new challenges and opportunities for the practical design of 6G. On one hand, acquiring channel state information (CSI) in real time for all wireless links becomes quite challenging in 6G. On the other hand, there would be numerous data sources in 6G containing high-quality location-tagged channel data, making it possible to better learn the local wireless environment. By exploiting such new opportunities and for tackling the CSI acquisition challenge, there is a promising paradigm shift from the conventional environment-unaware communications to the new environment-aware communications based on the novel approach of channel knowledge map (CKM). This article aims to provide a comprehensive tutorial overview on environment-aware communications enabled by CKM to fully harness its benefits for 6G. First, the basic concept of CKM is presented, and a comparison of CKM with various existing channel inference techniques is discussed. Next, the main techniques for CKM construction are discussed, including both the model-free and model-assisted approaches. Furthermore, a general framework is presented for the utilization of CKM to achieve environment-aware communications, followed by some typical CKM-aided communication scenarios. Finally, important open problems in CKM research are highlighted and potential solutions are discussed to inspire future work.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Interpretable-and-Efficient-Beamforming-Based-Deep-Learning-for-Single-Snapshot-DOA-Estimation"><a href="#Interpretable-and-Efficient-Beamforming-Based-Deep-Learning-for-Single-Snapshot-DOA-Estimation" class="headerlink" title="Interpretable and Efficient Beamforming-Based Deep Learning for Single Snapshot DOA Estimation"></a>Interpretable and Efficient Beamforming-Based Deep Learning for Single Snapshot DOA Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07411">http://arxiv.org/abs/2309.07411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruxin Zheng, Shunqiao Sun, Hongshan Liu, Honglei Chen, Jian Li</li>
<li>for: 这篇论文是为了提出一种可解释的深度学习方法来进行方向来源估计（DOA），使用单张Snapshot。</li>
<li>methods: 这篇论文使用的方法包括deep-MPDR网络，这是一种将最小功率扭积分布（MPDR）类型的扭积器翻译成深度学习的方法，以提高泛化和效率。</li>
<li>results: 根据 simulations 和实际数据集的实验结果，这种方法在准确率和计算时间方面具有优势，并且在其他深度学习DOA估计网络中表现出了更好的一致性、效率和可解释性。<details>
<summary>Abstract</summary>
We introduce an interpretable deep learning approach for direction of arrival (DOA) estimation with a single snapshot. Classical subspace-based methods like MUSIC and ESPRIT use spatial smoothing on uniform linear arrays for single snapshot DOA estimation but face drawbacks in reduced array aperture and inapplicability to sparse arrays. Single-snapshot methods such as compressive sensing and iterative adaptation approach (IAA) encounter challenges with high computational costs and slow convergence, hampering real-time use. Recent deep learning DOA methods offer promising accuracy and speed. However, the practical deployment of deep networks is hindered by their black-box nature. To address this, we propose a deep-MPDR network translating minimum power distortionless response (MPDR)-type beamformer into deep learning, enhancing generalization and efficiency. Comprehensive experiments conducted using both simulated and real-world datasets substantiate its dominance in terms of inference time and accuracy in comparison to conventional methods. Moreover, it excels in terms of efficiency, generalizability, and interpretability when contrasted with other deep learning DOA estimation networks.
</details>
<details>
<summary>摘要</summary>
我们介绍一个可解释深度学习方法来测量方向来源（DOA）的单一快照。经典的子空间基础方法如MUSIC和ESPRIT使用线性阵列上的空间平滑来进行单一快照DOA估计，但是它们受到缩小阵列范围和不适用于叠合阵列的限制。单一快照方法如压缩感知和迭代适应方法（IAA）则面临高计算成本和慢的融合速度，使其在实时使用中受到阻碍。现代深度学习DOA方法则提供了准确性和速度的推荐，但是实际应用受到黑盒子的问题所限。为了解决这个问题，我们提出了深度-MPDR网络，将最小功率无损响应（MPDR）型扁平阵列转换为深度学习，从而提高普遍性和效率。我们在使用实验和真实数据进行了全面的比较，证明了我们的方法在推理时间和准确性方面较 conventional方法优越，并且在效率、普遍性和可解释性方面也较其他深度学习DOA估计网络优越。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/14/eess.SP_2023_09_14/" data-id="clohum9h20181pj88at7egas6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/cs.SD_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T15:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/cs.SD_2023_09_13/">cs.SD - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Child-Vocalization-Classification-in-Multi-Channel-Child-Adult-Conversations-Through-Wav2vec2-Children-ASR-Features"><a href="#Enhancing-Child-Vocalization-Classification-in-Multi-Channel-Child-Adult-Conversations-Through-Wav2vec2-Children-ASR-Features" class="headerlink" title="Enhancing Child Vocalization Classification in Multi-Channel Child-Adult Conversations Through Wav2vec2 Children ASR Features"></a>Enhancing Child Vocalization Classification in Multi-Channel Child-Adult Conversations Through Wav2vec2 Children ASR Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07287">http://arxiv.org/abs/2309.07287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialu Li, Mark Hasegawa-Johnson, Karrie Karahalios</li>
<li>For: The paper aims to develop a machine learning model that can label adult and child audio recordings of clinician-child interactions, with the goal of assisting clinicians in capturing events of interest and communicating with parents more effectively.* Methods: The authors use a self-supervised learning model called Wav2Vec 2.0 (W2V2), which was pretrained on 4300 hours of home recordings of children under 5 years old. They apply this system to two-channel audio recordings of brief clinician-child interactions using the Rapid-ABC corpus, and introduce auxiliary features extracted from the W2V2-based automatic speech recognition (ASR) system to improve the accuracy of vocalization classification (VC) for children under 4 years old.* Results: The authors observe consistent improvements in the VC task on two corpora (Rapid-ABC and BabbleCor), and reach or outperform the state-of-the-art performance of BabbleCor.<details>
<summary>Abstract</summary>
Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder that often emerges in early childhood. ASD assessment typically involves an observation protocol including note-taking and ratings of child's social behavior conducted by a trained clinician. A robust machine learning (ML) model that is capable of labeling adult and child audio has the potential to save significant time and labor in manual coding children's behaviors. This may assist clinicians capture events of interest, better communicate events with parents, and educate new clinicians. In this study, we leverage the self-supervised learning model, Wav2Vec 2.0 (W2V2), pretrained on 4300h of home recordings of children under 5 years old, to build a unified system that performs both speaker diarization (SD) and vocalization classification (VC) tasks. We apply this system to two-channel audio recordings of brief 3-5 minute clinician-child interactions using the Rapid-ABC corpus. We propose a novel technique by introducing auxiliary features extracted from W2V2-based automatic speech recognition (ASR) system for children under 4 years old to improve children's VC task. We test our proposed method of improving children's VC task on two corpora (Rapid-ABC and BabbleCor) and observe consistent improvements. Furthermore, we reach, or perhaps outperform, the state-of-the-art performance of BabbleCor.
</details>
<details>
<summary>摘要</summary>
自适应发展障碍（ASD）是一种在早期儿hood出现的神经发展障碍。ASD评估通常包括一种观察协议，包括记录和评分孩子的社交行为，由训练有素的临床医生进行。一个功能强大的机器学习（ML）模型，可以标注成人和儿童的音频，有可能为临床医生节省巨量的时间和劳动。这可能帮助临床医生捕捉事件关键，更好地与父母交流事件，并更好地培训新的临床医生。在这项研究中，我们利用了无监督学习模型，Wav2Vec 2.0（W2V2），已经在4300小时的孩子下5岁的家庭录音中进行了预训练。我们使用这个系统来建立一个统一的系统，用于完成说话识别（VC）和媒体分类（SD）任务。我们将这个系统应用于两栏raphic-ABC corpus中的两栏录音，并提出了一种新的技术，通过在W2V2基于自动语音识别（ASR）系统中提取的辅助特征，以改进儿童的VC任务。我们在两个corpus（Rapid-ABC和BabbleCor）上测试了我们的提议，并观察到了一致的改进。此外，我们达到了或者超过了BabbleCor的状态艺术性能。
</details></li>
</ul>
<hr>
<h2 id="A-Flexible-Online-Framework-for-Projection-Based-STFT-Phase-Retrieval"><a href="#A-Flexible-Online-Framework-for-Projection-Based-STFT-Phase-Retrieval" class="headerlink" title="A Flexible Online Framework for Projection-Based STFT Phase Retrieval"></a>A Flexible Online Framework for Projection-Based STFT Phase Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07043">http://arxiv.org/abs/2309.07043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tal Peer, Simon Welker, Johannes Kolhoff, Timo Gerkmann</li>
<li>for: 提高iterative STFT阶段的phaserecovery性能</li>
<li>methods: 使用新的投影运算符组合方式，从 Griffin-Lim 方法中获得更好的重构质量和迭代数量，同时保持相同的计算复杂性</li>
<li>results: 在speech signal上实现了更好的重构质量，比RTISI更高的性能，并且可以在线实现任何基于迭代投影的算法<details>
<summary>Abstract</summary>
Several recent contributions in the field of iterative STFT phase retrieval have demonstrated that the performance of the classical Griffin-Lim method can be considerably improved upon. By using the same projection operators as Griffin-Lim, but combining them in innovative ways, these approaches achieve better results in terms of both reconstruction quality and required number of iterations, while retaining a similar computational complexity per iteration. However, like Griffin-Lim, these algorithms operate in an offline manner and thus require an entire spectrogram as input, which is an unrealistic requirement for many real-world speech communication applications. We propose to extend RTISI -- an existing online (frame-by-frame) variant of the Griffin-Lim algorithm -- into a flexible framework that enables straightforward online implementation of any algorithm based on iterative projections. We further employ this framework to implement online variants of the fast Griffin-Lim algorithm, the accelerated Griffin-Lim algorithm, and two algorithms from the optics domain. Evaluation results on speech signals show that, similarly to the offline case, these algorithms can achieve a considerable performance gain compared to RTISI.
</details>
<details>
<summary>摘要</summary>
近些年在循环STFT阶段phaserecovery领域，一些研究表明可以通过使用同样的投影运算符，但是通过创新的方式组合它们，提高循环STFT阶段phaserecovery的性能，包括重建质量和需要的迭代数量，而且保持与经典Griffin-Lim方法相同的计算复杂度。然而，这些算法都是在离线方式下运行，需要一个完整的spectrogram作为输入，这是许多实际语音通信应用场景中的一个不现实的假设。我们提议将RTISI---一种现有的在线（frame-by-frame）变体的Griffin-Lim算法---扩展为一个灵活的框架，以便直观在线实现任何基于循环投影的算法。此外，我们使用这个框架来在线实现快速Griffin-Lim算法、加速Griffin-Lim算法和两种光学领域的算法。对语音信号进行评估结果表明，与离线情况类似，这些算法可以与RTISI相比，获得显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-models-for-audio-semantic-communication"><a href="#Diffusion-models-for-audio-semantic-communication" class="headerlink" title="Diffusion models for audio semantic communication"></a>Diffusion models for audio semantic communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07195">http://arxiv.org/abs/2309.07195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eleonora Grassucci, Christian Marinoni, Andrea Rodriguez, Danilo Comminiello</li>
<li>for: 本研究旨在提高听音信息的传输稳定性和可靠性，通过将 semantics 和 audio signal 转化为听音信息的含义，然后在接收端使用 conditional diffusion model 重建听音信息。</li>
<li>methods: 本研究提出了一种基于 inverse problem 的听音信息传输框架，将 audio signal 和 semantics 转化为听音信息的含义，然后使用 conditional diffusion model 在接收端重建听音信息。</li>
<li>results: 实验结果显示，本研究的方法在不同的渠道条件下都能够超越竞争对手，并且可以有效地重建听音信息。您可以访问项目页面，listen to samples 和获取代码：<a target="_blank" rel="noopener" href="https://ispamm.github.io/diffusion-audio-semantic-communication/">https://ispamm.github.io/diffusion-audio-semantic-communication/</a>.<details>
<summary>Abstract</summary>
Directly sending audio signals from a transmitter to a receiver across a noisy channel may absorb consistent bandwidth and be prone to errors when trying to recover the transmitted bits. On the contrary, the recent semantic communication approach proposes to send the semantics and then regenerate semantically consistent content at the receiver without exactly recovering the bitstream. In this paper, we propose a generative audio semantic communication framework that faces the communication problem as an inverse problem, therefore being robust to different corruptions. Our method transmits lower-dimensional representations of the audio signal and of the associated semantics to the receiver, which generates the corresponding signal with a particular focus on its meaning (i.e., the semantics) thanks to the conditional diffusion model at its core. During the generation process, the diffusion model restores the received information from multiple degradations at the same time including corruption noise and missing parts caused by the transmission over the noisy channel. We show that our framework outperforms competitors in a real-world scenario and with different channel conditions. Visit the project page to listen to samples and access the code: https://ispamm.github.io/diffusion-audio-semantic-communication/.
</details>
<details>
<summary>摘要</summary>
直接传送对话讯号从传送器到接收器过噪通道可能吸收稳定带宽和容易发生错误，尤其在尝试从传送的字节中恢复传送的内容。相反，最近的 semantics 通信方法建议将内容和其相关的 semantics 传送到接收器，并在接收器端使用 conditional diffusion 模型来生成具有特定意义的讯号。在我们的框架中，我们传送对话讯号的下降维度表示和相关的 semantics 到接收器，接收器使用 conditional diffusion 模型来从多种降低处理中恢复获得的讯号，包括噪音扰障和传送过程中的缺失部分。我们显示，我们的框架在实际情况下比竞争对手更好，并在不同的通道条件下显示出优秀的表现。您可以前往项目页面聆听样本和取得代码：https://ispamm.github.io/diffusion-audio-semantic-communication/.
</details></li>
</ul>
<hr>
<h2 id="Reorganization-of-the-auditory-perceptual-space-across-the-human-vocal-range"><a href="#Reorganization-of-the-auditory-perceptual-space-across-the-human-vocal-range" class="headerlink" title="Reorganization of the auditory-perceptual space across the human vocal range"></a>Reorganization of the auditory-perceptual space across the human vocal range</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06946">http://arxiv.org/abs/2309.06946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Friedrichs, Volker Dellwo</li>
<li>For: This paper investigates the auditory-perceptual space of vowels in the human vocal range, specifically focusing on the role of spectral shape in vowel perception.* Methods: The study uses multidimensional scaling analysis of cochlea-scaled spectra from 250-ms vowel segments, with a dataset of 240 vowels produced by three native German female speakers.* Results: The study finds systematic spectral shifts associated with vowel height and frontness, with a notable clustering around &#x2F;i a u&#x2F; above 523 Hz. These findings highlight the importance of spectral shape in vowel perception and offer insights into the evolution of language.In Simplified Chinese text, the information could be summarized as follows:* 为：这篇论文研究了人类语音范围内的声音感知空间，尤其是声音形态在声音认知中的作用。* 方法：这项研究使用了多维度投影分析器，利用了250毫秒的元音段的聪见谱，来研究3名德国女性说话者的元音。* 结果：研究发现，随着高频声音的增加，元音的高度和前端性呈现出系统性的声音偏移，特别是在523Hz以上的高频声音上。这些发现 подтвержда了声音形态在元音认知中的重要作用，并且为语言演化提供了可能的解释。<details>
<summary>Abstract</summary>
We analyzed the auditory-perceptual space across a substantial portion of the human vocal range (220-1046 Hz) using multidimensional scaling analysis of cochlea-scaled spectra from 250-ms vowel segments, initially studied in Friedrichs et al. (2017) J. Acoust. Soc. Am. 142 1025-1033. The dataset comprised the vowels /i y e {\o} {\epsilon} a o u/ (N=240) produced by three native German female speakers, encompassing a broad range of their respective voice frequency ranges. The initial study demonstrated that, during a closed-set identification task involving 21 listeners, the point vowels /i a u/ were significantly recognized at fundamental frequencies (fo) nearing 1 kHz, whereas the recognition of other vowels decreased at higher pitches. Building on these findings, our study revealed systematic spectral shifts associated with vowel height and frontness as fo increased, with a notable clustering around /i a u/ above 523 Hz. These observations underscore the pivotal role of spectral shape in vowel perception, illustrating the reliance on acoustic anchors at higher pitches. Furthermore, this study sheds light on the quantal nature of these vowels and their potential impact on language evolution, offering a plausible explanation for their widespread presence in the world's languages.
</details>
<details>
<summary>摘要</summary>
我们使用多维度尺度分析对人声 vocal range（220-1046Hz）中的听觉空间进行了分析，使用 Friedrichs et al. (2017) J. Acoust. Soc. Am. 142 1025-1033中提出的多个 native German female speakers的vowel /i y e {\o} {\epsilon} a o u/（共240个） Dataset，覆盖了它们的声音频率范围。之前的研究表明，在一个关闭式认知任务中，点vowel /i a u/ 在基本频率（fo）接近1kHz的情况下得到了明显的认知。此外，我们的研究还发现了高频域的系统性 spectral shifts 与vowel height和前端性有关，特别是在523Hz以上的高频域。这些观察结果 highlights the crucial role of spectral shape in vowel perception, and underscores the reliance on acoustic anchors at higher pitches.此外，这种研究还 shed light on the quantal nature of these vowels and their potential impact on language evolution, offering a plausible explanation for their widespread presence in the world's languages.
</details></li>
</ul>
<hr>
<h2 id="VRDMG-Vocal-Restoration-via-Diffusion-Posterior-Sampling-with-Multiple-Guidance"><a href="#VRDMG-Vocal-Restoration-via-Diffusion-Posterior-Sampling-with-Multiple-Guidance" class="headerlink" title="VRDMG: Vocal Restoration via Diffusion Posterior Sampling with Multiple Guidance"></a>VRDMG: Vocal Restoration via Diffusion Posterior Sampling with Multiple Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06934">http://arxiv.org/abs/2309.06934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Hernandez-Olivan, Koichi Saito, Naoki Murata, Chieh-Hsin Lai, Marco A. Martínez-Ramirez, Wei-Hsiang Liao, Yuki Mitsufuji</li>
<li>for: 这篇论文主要关注于修复音乐信号的听风伤害，以提高音频质量并且适用于不同的修复任务。</li>
<li>methods: 这篇论文提出了一种基于扩散 posterior 采样（DPS）的音乐修复方法，并研究了一些针对现有DPS-based方法的问题，如杂散导航技术，包括RePaint（RP）策略和 Pseudoinverse-Guided Diffusion Models（$\Pi$GDM）。</li>
<li>results: 在 vocal declipping 和 bandwidth extension 两个任务中，我们的方法表现出色，超越了目前的DPS-based音乐修复标准。可以参考 \url{<a target="_blank" rel="noopener" href="http://carlosholivan.github.io/demos/audio-restoration-2023.html%7D">http://carlosholivan.github.io/demos/audio-restoration-2023.html}</a> 获取修复后的音频示例。<details>
<summary>Abstract</summary>
Restoring degraded music signals is essential to enhance audio quality for downstream music manipulation. Recent diffusion-based music restoration methods have demonstrated impressive performance, and among them, diffusion posterior sampling (DPS) stands out given its intrinsic properties, making it versatile across various restoration tasks. In this paper, we identify that there are potential issues which will degrade current DPS-based methods' performance and introduce the way to mitigate the issues inspired by diverse diffusion guidance techniques including the RePaint (RP) strategy and the Pseudoinverse-Guided Diffusion Models ($\Pi$GDM). We demonstrate our methods for the vocal declipping and bandwidth extension tasks under various levels of distortion and cutoff frequency, respectively. In both tasks, our methods outperform the current DPS-based music restoration benchmarks. We refer to \url{http://carlosholivan.github.io/demos/audio-restoration-2023.html} for examples of the restored audio samples.
</details>
<details>
<summary>摘要</summary>
重新恢复音乐信号是提高音频质量的关键，以便进行下游音乐修饰。最近的扩散基于音乐恢复方法中，扩散 posterior 抽象（DPS）表现出色，其具有多种恢复任务的 universality。在这篇论文中，我们发现了当前 DPS 基于的方法可能会受到的问题，并提出了利用多种扩散指导技术，包括 RePaint（RP）策略和 Pseudoinverse-Guided Diffusion Models（$\Pi$GDM）来 Mitigate 这些问题。我们在 vocals 减震和频率延展任务中应用了我们的方法，并在不同的噪声和截止频率水平下进行了评估。在两个任务中，我们的方法超越了当前 DPS 基于的音乐恢复标准。更多的纪录音amples可以在 <http://carlosholivan.github.io/demos/audio-restoration-2023.html> 上找到。
</details></li>
</ul>
<hr>
<h2 id="EMALG-An-Enhanced-Mandarin-Lombard-Grid-Corpus-with-Meaningful-Sentences"><a href="#EMALG-An-Enhanced-Mandarin-Lombard-Grid-Corpus-with-Meaningful-Sentences" class="headerlink" title="EMALG: An Enhanced Mandarin Lombard Grid Corpus with Meaningful Sentences"></a>EMALG: An Enhanced Mandarin Lombard Grid Corpus with Meaningful Sentences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06858">http://arxiv.org/abs/2309.06858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baifeng Li, Qingmu Liu, Yuhong Yang, Hongyang Chen, Weiping Tu, Song Lin</li>
<li>for: 这个研究 investigate Lombard effect, where individuals adapt their speech in noisy environments.</li>
<li>methods: 我们引入了改进的满语 Lombard 网格 (EMALG)  Corpora，增加了有意义的句子，从而解决了 MALG  Corpora 面临的挑战。</li>
<li>results: 我们发现，在满语中，女性在发言有意义的句子时更加强烈地表现出 Lombard 效应，而男性则不然。此外，我们发现 meaningless 句子会负面影响 Lombard 效应分析。此外，我们的结果证实了在英语和满语之间 Lombard 效应的相似性，与之前的研究相符。<details>
<summary>Abstract</summary>
This study investigates the Lombard effect, where individuals adapt their speech in noisy environments. We introduce an enhanced Mandarin Lombard grid (EMALG) corpus with meaningful sentences , enhancing the Mandarin Lombard grid (MALG) corpus. EMALG features 34 speakers and improves recording setups, addressing challenges faced by MALG with nonsense sentences. Our findings reveal that in Mandarin, female exhibit a more pronounced Lombard effect than male, particularly when uttering meaningful sentences. Additionally, we uncover that nonsense sentences negatively impact Lombard effect analysis. Moreover, our results reaffirm the consistency in the Lombard effect comparison between English and Mandarin found in previous research.
</details>
<details>
<summary>摘要</summary>
这个研究investigates the Lombard effect, where individuals adapt their speech in noisy environments. We introduce an enhanced Mandarin Lombard grid (EMALG) corpus with meaningful sentences, enhancing the Mandarin Lombard grid (MALG) corpus. EMALG features 34 speakers and improves recording setups, addressing challenges faced by MALG with nonsense sentences. Our findings reveal that in Mandarin, female speakers exhibit a more pronounced Lombard effect than male speakers, particularly when uttering meaningful sentences. Additionally, we find that nonsense sentences negatively impact Lombard effect analysis. Moreover, our results reaffirm the consistency in the Lombard effect comparison between English and Mandarin found in previous research.Here's the translation in Traditional Chinese for comparison:这个研究investigates the Lombard effect, where individuals adapt their speech in noisy environments. We introduce an enhanced Mandarin Lombard grid (EMALG) corpus with meaningful sentences, enhancing the Mandarin Lombard grid (MALG) corpus. EMALG features 34 speakers and improves recording setups, addressing challenges faced by MALG with nonsense sentences. Our findings reveal that in Mandarin, female speakers exhibit a more pronounced Lombard effect than male speakers, particularly when uttering meaningful sentences. Additionally, we find that nonsense sentences negatively impact Lombard effect analysis. Moreover, our results reaffirm the consistency in the Lombard effect comparison between English and Mandarin found in previous research.
</details></li>
</ul>
<hr>
<h2 id="DCTTS-Discrete-Diffusion-Model-with-Contrastive-Learning-for-Text-to-speech-Generation"><a href="#DCTTS-Discrete-Diffusion-Model-with-Contrastive-Learning-for-Text-to-speech-Generation" class="headerlink" title="DCTTS: Discrete Diffusion Model with Contrastive Learning for Text-to-speech Generation"></a>DCTTS: Discrete Diffusion Model with Contrastive Learning for Text-to-speech Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06787">http://arxiv.org/abs/2309.06787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Wu, Qiulin Li, Sixing Liu, Qun Yang</li>
<li>for: 这 paper 是为了提高 Text-to-Speech 任务中的Diffusion模型的效率和适用性而写的。</li>
<li>methods: 这 paper 使用 Discrete Diffusion Model with Contrastive Learning 来提高 Text-to-Speech Generation 的质量和速度。具体来说，它使用精确的文本编码器来简化模型的参数和提高计算效率，并使用对比学习方法来增强文本和声音之间的对应关系。</li>
<li>results:  эксперименталь结果表明，提出的方法可以在保持声音质量的同时，大幅降低Diffusion模型的计算资源占用率和执行速度。synthesized samples 可以在 <a target="_blank" rel="noopener" href="https://github.com/lawtherWu/DCTTS">https://github.com/lawtherWu/DCTTS</a> 上获取。<details>
<summary>Abstract</summary>
In the Text-to-speech(TTS) task, the latent diffusion model has excellent fidelity and generalization, but its expensive resource consumption and slow inference speed have always been a challenging. This paper proposes Discrete Diffusion Model with Contrastive Learning for Text-to-Speech Generation(DCTTS). The following contributions are made by DCTTS: 1) The TTS diffusion model based on discrete space significantly lowers the computational consumption of the diffusion model and improves sampling speed; 2) The contrastive learning method based on discrete space is used to enhance the alignment connection between speech and text and improve sampling quality; and 3) It uses an efficient text encoder to simplify the model's parameters and increase computational efficiency. The experimental results demonstrate that the approach proposed in this paper has outstanding speech synthesis quality and sampling speed while significantly reducing the resource consumption of diffusion model. The synthesized samples are available at https://github.com/lawtherWu/DCTTS.
</details>
<details>
<summary>摘要</summary>
在文本至语音（TTS）任务中，液态扩散模型具有优秀的准确性和泛化能力，但它的资源消耗量和推理速度始终是一大挑战。这篇论文提出了粒子扩散模型与对比学习 для文本至语音生成（DCTTS）。这个方法的贡献包括：1. 基于粒子空间的TTS扩散模型，显著降低了扩散模型的计算摄用量和提高了抽样速度；2. 基于粒子空间的对比学习方法，可以增强语音和文本之间的对应关系，提高抽样质量；3. 使用高效的文本编码器，简化模型参数，提高计算效率。实验结果表明，该方法提出的方法在语音合成质量和抽样速度两个方面具有优秀表现，同时significantly降低了扩散模型的资源消耗量。生成的样例可以在GitHub上获取：https://github.com/lawtherWu/DCTTS。
</details></li>
</ul>
<hr>
<h2 id="Distinguishing-Neural-Speech-Synthesis-Models-Through-Fingerprints-in-Speech-Waveforms"><a href="#Distinguishing-Neural-Speech-Synthesis-Models-Through-Fingerprints-in-Speech-Waveforms" class="headerlink" title="Distinguishing Neural Speech Synthesis Models Through Fingerprints in Speech Waveforms"></a>Distinguishing Neural Speech Synthesis Models Through Fingerprints in Speech Waveforms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06780">http://arxiv.org/abs/2309.06780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chu Yuan Zhang, Jiangyan Yi, Jianhua Tao, Chenglong Wang, Xinrui Yan</li>
<li>for: 本研究旨在探讨合成 speech 中的源特征，以便在法律和知识产权领域进行识别和防范。</li>
<li>methods: 本研究使用多个 speaker LibriTTS  dataset， investigate 合成 speech 中的模型特征，包括 acoustic model 和 vocoder，以及它们对 waveform 的影响。</li>
<li>results: 研究发现， vocoder 和 acoustic model 都会留下特定的模型特征在 waveform 中，但 vocoder 的特征更加强大，可能会覆盖 acoustic model 的特征。这些发现表明存在模型特征，可以用于识别合成 speech 的源。<details>
<summary>Abstract</summary>
Recent strides in neural speech synthesis technologies, while enjoying widespread applications, have nonetheless introduced a series of challenges, spurring interest in the defence against the threat of misuse and abuse. Notably, source attribution of synthesized speech has value in forensics and intellectual property protection, but prior work in this area has certain limitations in scope. To address the gaps, we present our findings concerning the identification of the sources of synthesized speech in this paper. We investigate the existence of speech synthesis model fingerprints in the generated speech waveforms, with a focus on the acoustic model and the vocoder, and study the influence of each component on the fingerprint in the overall speech waveforms. Our research, conducted using the multi-speaker LibriTTS dataset, demonstrates two key insights: (1) vocoders and acoustic models impart distinct, model-specific fingerprints on the waveforms they generate, and (2) vocoder fingerprints are the more dominant of the two, and may mask the fingerprints from the acoustic model. These findings strongly suggest the existence of model-specific fingerprints for both the acoustic model and the vocoder, highlighting their potential utility in source identification applications.
</details>
<details>
<summary>摘要</summary>
In this paper, we investigate the existence of speech synthesis model fingerprints in generated speech waveforms, focusing on the acoustic model and the vocoder. We examine the influence of each component on the fingerprint in the overall speech waveforms.Our research, conducted using the multi-speaker LibriTTS dataset, reveals two key insights:1. Vocoders and acoustic models impart distinct, model-specific fingerprints on the waveforms they generate.2. Vocoder fingerprints are the more dominant of the two, and may mask the fingerprints from the acoustic model.These findings suggest the existence of model-specific fingerprints for both the acoustic model and the vocoder, highlighting their potential utility in source identification applications.
</details></li>
</ul>
<hr>
<h2 id="PIAVE-A-Pose-Invariant-Audio-Visual-Speaker-Extraction-Network"><a href="#PIAVE-A-Pose-Invariant-Audio-Visual-Speaker-Extraction-Network" class="headerlink" title="PIAVE: A Pose-Invariant Audio-Visual Speaker Extraction Network"></a>PIAVE: A Pose-Invariant Audio-Visual Speaker Extraction Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06723">http://arxiv.org/abs/2309.06723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinghua Liu, Meng Ge, Zhizheng Wu, Haizhou Li</li>
<li>for: 研究如何利用变化的说话表情来提高音视频说话人EXTRACTING</li>
<li>methods: 提出了一种具有可pose-invariant视图的音视频说话人EXTRACTING网络（PIAVE），通过生成每个原始姿势 orientation的pose-invariant视图，使模型可以得到一个一致的前视图，therefore, forming a multi-view visual input for the speaker.</li>
<li>results: 在多视图MEAD和野外LRS3数据集上进行实验，PIAVE比 estado-of-the-art 高效和更加鲁棒地处理pose变化。<details>
<summary>Abstract</summary>
It is common in everyday spoken communication that we look at the turning head of a talker to listen to his/her voice. Humans see the talker to listen better, so do machines. However, previous studies on audio-visual speaker extraction have not effectively handled the varying talking face. This paper studies how to take full advantage of the varying talking face. We propose a Pose-Invariant Audio-Visual Speaker Extraction Network (PIAVE) that incorporates an additional pose-invariant view to improve audio-visual speaker extraction. Specifically, we generate the pose-invariant view from each original pose orientation, which enables the model to receive a consistent frontal view of the talker regardless of his/her head pose, therefore, forming a multi-view visual input for the speaker. Experiments on the multi-view MEAD and in-the-wild LRS3 dataset demonstrate that PIAVE outperforms the state-of-the-art and is more robust to pose variations.
</details>
<details>
<summary>摘要</summary>
通常在日常口语communication中，我们会看向说话人的头部，以便更好地听到他/她的voice。人类和机器都会这样做。然而，之前的音频视频说话人提取研究没有有效地处理变化的说话面孔。这篇论文研究如何全面利用变化的说话面孔。我们提议一个pose-invariant的音频视频说话人提取网络（PIAVE），该网络包含一个额外的pose-invariant视图，以提高音频视频说话人提取的精度。具体来说，我们将每个原始poseorientation中生成一个pose-invariant视图，这使得模型能够得到不同poseorientation下的说话人的一致的前视角，因此形成一个多视图的视觉输入。实验表明，PIAVE在多视图MEAD和野外LRS3 dataset上表现出优于状态之arte和更加鲁为pose变化。
</details></li>
</ul>
<hr>
<h2 id="Attention-based-Encoder-Decoder-End-to-End-Neural-Diarization-with-Embedding-Enhancer"><a href="#Attention-based-Encoder-Decoder-End-to-End-Neural-Diarization-with-Embedding-Enhancer" class="headerlink" title="Attention-based Encoder-Decoder End-to-End Neural Diarization with Embedding Enhancer"></a>Attention-based Encoder-Decoder End-to-End Neural Diarization with Embedding Enhancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06672">http://arxiv.org/abs/2309.06672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyang Chen, Bing Han, Shuai Wang, Yanmin Qian</li>
<li>for: 提高speaker分类任务的性能，尤其是针对未看到之数量的说话人。</li>
<li>methods: 使用Attention-based encoder-decoder网络，采用教师强制策略进行模型训练，并提出了一种循环解码方法来输出每个说话人的扩展结果。</li>
<li>results: 在多个评估指标上达到了新的最佳性能，包括CALLHOME（10.08%）、DIHARD II（24.64%）和AMI（13.00%）评估指标。此外，该系统还表现出了极高的竞争力作为一种speech类型检测模型。<details>
<summary>Abstract</summary>
Deep neural network-based systems have significantly improved the performance of speaker diarization tasks. However, end-to-end neural diarization (EEND) systems often struggle to generalize to scenarios with an unseen number of speakers, while target speaker voice activity detection (TS-VAD) systems tend to be overly complex. In this paper, we propose a simple attention-based encoder-decoder network for end-to-end neural diarization (AED-EEND). In our training process, we introduce a teacher-forcing strategy to address the speaker permutation problem, leading to faster model convergence. For evaluation, we propose an iterative decoding method that outputs diarization results for each speaker sequentially. Additionally, we propose an Enhancer module to enhance the frame-level speaker embeddings, enabling the model to handle scenarios with an unseen number of speakers. We also explore replacing the transformer encoder with a Conformer architecture, which better models local information. Furthermore, we discovered that commonly used simulation datasets for speaker diarization have a much higher overlap ratio compared to real data. We found that using simulated training data that is more consistent with real data can achieve an improvement in consistency. Extensive experimental validation demonstrates the effectiveness of our proposed methodologies. Our best system achieved a new state-of-the-art diarization error rate (DER) performance on all the CALLHOME (10.08%), DIHARD II (24.64%), and AMI (13.00%) evaluation benchmarks, when no oracle voice activity detection (VAD) is used. Beyond speaker diarization, our AED-EEND system also shows remarkable competitiveness as a speech type detection model.
</details>
<details>
<summary>摘要</summary>
深度神经网络基于系统在说话人分类任务中表现出了显著的改进。然而，采用端到端神经网络（EEND）系统在未看到数量的说话人场景下一般具有困难泛化性。而目标说话人活动检测（TS-VAD）系统则往往过于复杂。在这篇论文中，我们提议一种简单的注意力基于encoder-decoder网络（AED-EEND）。在我们的训练过程中，我们引入了教师强制策略来解决说话人排序问题，从而提高模型的快速收敛。在评估中，我们提出了一种逐个输出每个说话人的分类结果的迭代解码方法。此外，我们还提出了一种增强器模块，用于增强每帧的说话人嵌入，使模型能够处理未看到数量的说话人场景。此外，我们还发现了常用的说话人分类 simulation 数据集的一个重要问题，即 overlap ratio 较高。我们发现，使用更加符合实际数据的 simulated 训练数据可以实现提高一致性。我们的实验证明了我们提出的方法的有效性。我们的最佳系统在所有 CALLHOME（10.08%）、DIHARD II（24.64%）和 AMI（13.00%) 评估标准上达到了新的状态之纪录级别，当没有使用 oracle 语音活动检测（VAD）时。此外，我们的 AED-EEND 系统还表现出了很好的抗讲话类型检测能力。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Modelling-of-Percussive-Audio-with-Transient-and-Spectral-Synthesis"><a href="#Differentiable-Modelling-of-Percussive-Audio-with-Transient-and-Spectral-Synthesis" class="headerlink" title="Differentiable Modelling of Percussive Audio with Transient and Spectral Synthesis"></a>Differentiable Modelling of Percussive Audio with Transient and Spectral Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06649">http://arxiv.org/abs/2309.06649</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jorshi/drumblender">https://github.com/jorshi/drumblender</a></li>
<li>paper_authors: Jordie Shier, Franco Caspe, Andrew Robertson, Mark Sandler, Charalampos Saitis, Andrew McPherson</li>
<li>for: 这个论文主要针对的是什么？	+ 这篇论文旨在提出一种能够模型束缚的数字信号处理（DDSP）技术，用于生成打击声的电子乐器。</li>
<li>methods: 这个论文使用了什么方法？	+ 该论文提出了一种基于束缚模型的打击声生成方法，包括使用 modify 的时间卷积神经网络来生成打击声的脉冲。</li>
<li>results: 这个论文的结果是什么？	+ 该论文通过使用大量的音频和电子打击乐amples，计算了一系列的重建度量，并证明了其方法可以更好地重建打击声乐器的音波信号。<details>
<summary>Abstract</summary>
Differentiable digital signal processing (DDSP) techniques, including methods for audio synthesis, have gained attention in recent years and lend themselves to interpretability in the parameter space. However, current differentiable synthesis methods have not explicitly sought to model the transient portion of signals, which is important for percussive sounds. In this work, we present a unified synthesis framework aiming to address transient generation and percussive synthesis within a DDSP framework. To this end, we propose a model for percussive synthesis that builds on sinusoidal modeling synthesis and incorporates a modulated temporal convolutional network for transient generation. We use a modified sinusoidal peak picking algorithm to generate time-varying non-harmonic sinusoids and pair it with differentiable noise and transient encoders that are jointly trained to reconstruct drumset sounds. We compute a set of reconstruction metrics using a large dataset of acoustic and electronic percussion samples that show that our method leads to improved onset signal reconstruction for membranophone percussion instruments.
</details>
<details>
<summary>摘要</summary>
diferenciable digital signal processing (DDSP) 技术，包括音频合成方法，在最近几年内受到了关注，并且具有可解释的参数空间特性。然而，当前的可 diferenciable 合成方法并没有直接模型信号激发部分，这对于钣鼓样本是非常重要的。在这项工作中，我们提出了一种统一的合成框架，旨在解决钣鼓合成和激发部分的问题。为此，我们提出了基于圆形模型合成的钣鼓合成模型，并将模拟的时间卷积神经网络用于激发部分。我们使用修改后的圆形峰挑选算法来生成时间变化的非幂圆形，并与可导的噪声和激发编码器一起进行联合训练，以重construct 钣鼓 зву频样本。我们计算了一组重建指标，使用大量的音频和电子打击乐样本，并显示了我们的方法可以提高钣鼓类打击乐器的开始信号重建。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/cs.SD_2023_09_13/" data-id="clohum9c000uypj88712ddonn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/cs.CV_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T13:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/cs.CV_2023_09_13/">cs.CV - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Automated-Assessment-of-Critical-View-of-Safety-in-Laparoscopic-Cholecystectomy"><a href="#Automated-Assessment-of-Critical-View-of-Safety-in-Laparoscopic-Cholecystectomy" class="headerlink" title="Automated Assessment of Critical View of Safety in Laparoscopic Cholecystectomy"></a>Automated Assessment of Critical View of Safety in Laparoscopic Cholecystectomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07330">http://arxiv.org/abs/2309.07330</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunfan Li, Himanshu Gupta, Haibin Ling, IV Ramakrishnan, Prateek Prasanna, Georgios Georgakis, Aaron Sasson<br>for: 这项研究旨在开发深度学习技术，自动评估 lap  choledochoscopy 中的安全视野 (CVS)。methods: 研究采用了两栅 semantic segmentation 方法，首先生成两个分割图，然后根据近距离 gallbladder 的 анатомиче结构进行定量计算，最后通过规则来确定每一个 CVS 标准的满足 Condition。results: 研究所获得的结果包括：1) 对 relevant 类型的 mIoU 提高了11.8%以上，相比单基eline模型; 2) 对 Transformer 基eline模型的 Sobel 损失函数，提高了1.84%的 mIoU; 3) CVS 标准的评估中，提高了16%以上，全 CV 评估中提高了5%。<details>
<summary>Abstract</summary>
Cholecystectomy (gallbladder removal) is one of the most common procedures in the US, with more than 1.2M procedures annually. Compared with classical open cholecystectomy, laparoscopic cholecystectomy (LC) is associated with significantly shorter recovery period, and hence is the preferred method. However, LC is also associated with an increase in bile duct injuries (BDIs), resulting in significant morbidity and mortality. The primary cause of BDIs from LCs is misidentification of the cystic duct with the bile duct. Critical view of safety (CVS) is the most effective of safety protocols, which is said to be achieved during the surgery if certain criteria are met. However, due to suboptimal understanding and implementation of CVS, the BDI rates have remained stable over the last three decades. In this paper, we develop deep-learning techniques to automate the assessment of CVS in LCs. An innovative aspect of our research is on developing specialized learning techniques by incorporating domain knowledge to compensate for the limited training data available in practice. In particular, our CVS assessment process involves a fusion of two segmentation maps followed by an estimation of a certain region of interest based on anatomical structures close to the gallbladder, and then finally determination of each of the three CVS criteria via rule-based assessment of structural information. We achieved a gain of over 11.8% in mIoU on relevant classes with our two-stream semantic segmentation approach when compared to a single-model baseline, and 1.84% in mIoU with our proposed Sobel loss function when compared to a Transformer-based baseline model. For CVS criteria, we achieved up to 16% improvement and, for the overall CVS assessment, we achieved 5% improvement in balanced accuracy compared to DeepCVS under the same experiment settings.
</details>
<details>
<summary>摘要</summary>
每年有超过1.2万次Cholecystectomy（胆囊除除）手术在美国，而与经典开胆囊手术相比， Laparoscopic Cholecystectomy（LC）具有明显更短的恢复时间，因此成为首选方法。然而，LC也会导致胆囊损伤（BDIs）的增加，从而导致重要的致病和死亡率。胆囊损伤的主要原因是在LC中误认胆囊与胆囊之间的区别。 Critical View of Safety（CVS）是安全协议中最有效的一种，CVS的实施可以在手术中达到特定的标准。然而，由于CVS的理解和实施不够，BDIs的发生率在过去三十年内保持了稳定的水平。在这篇论文中，我们利用深度学习技术自动评估LC中CVS。我们的研究的创新之处在于通过结合域名知识来补偿实际数据的有限性，以提高CVS评估的准确性。我们的CVS评估过程包括将两个分割图像融合，然后根据胆囊附近的 анатомиче结构进行一定区域的估计，最后通过基于结构信息的规则来确定每一个CVS标准。我们的两栅semantic segmentation方法在相关的类型上获得了11.8%的增强，而我们的 Sobel损失函数在基于Transformer的基线模型上获得了1.84%的增强。对于CVS标准，我们达到了16%的提高，而对于总CVS评估，我们达到了5%的提高，与DeepCVS相比，在同一个实验设置下。
</details></li>
</ul>
<hr>
<h2 id="texttt-NePhi-Neural-Deformation-Fields-for-Approximately-Diffeomorphic-Medical-Image-Registration"><a href="#texttt-NePhi-Neural-Deformation-Fields-for-Approximately-Diffeomorphic-Medical-Image-Registration" class="headerlink" title="$\texttt{NePhi}$: Neural Deformation Fields for Approximately Diffeomorphic Medical Image Registration"></a>$\texttt{NePhi}$: Neural Deformation Fields for Approximately Diffeomorphic Medical Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07322">http://arxiv.org/abs/2309.07322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Tian, Soumyadip Sengupta, Hastings Greer, Raúl San José Estépar, Marc Niethammer</li>
<li>for: 本研究提出了一种基于神经网络的凹变模型，可以实现约等于 diffeomorphic 变换。</li>
<li>methods: 这种模型使用 функциональ表示凹变，从而减少了训练和推断中的内存占用。这对大量的三维注册问题非常重要。</li>
<li>results: 我们在两个 synthetic 2D 数据集和实际的3D 肺注册中测试了 $\texttt{NePhi}$，结果显示它可以在单resolution注册设置下 достичь与 voxel-based 表示相似的准确率，同时使用更少的内存和允许更快的实例优化。<details>
<summary>Abstract</summary>
This work proposes $\texttt{NePhi}$, a neural deformation model which results in approximately diffeomorphic transformations. In contrast to the predominant voxel-based approaches, $\texttt{NePhi}$ represents deformations functionally which allows for memory-efficient training and inference. This is of particular importance for large volumetric registrations. Further, while medical image registration approaches representing transformation maps via multi-layer perceptrons have been proposed, $\texttt{NePhi}$ facilitates both pairwise optimization-based registration $\textit{as well as}$ learning-based registration via predicted or optimized global and local latent codes. Lastly, as deformation regularity is a highly desirable property for most medical image registration tasks, $\texttt{NePhi}$ makes use of gradient inverse consistency regularization which empirically results in approximately diffeomorphic transformations. We show the performance of $\texttt{NePhi}$ on two 2D synthetic datasets as well as on real 3D lung registration. Our results show that $\texttt{NePhi}$ can achieve similar accuracies as voxel-based representations in a single-resolution registration setting while using less memory and allowing for faster instance-optimization.
</details>
<details>
<summary>摘要</summary>
这个工作提出了一种名为 $\texttt{NePhi}$ 的神经网络变换模型，它可以生成约等于Diffusion的变换。与传统的 voxel-based 方法不同， $\texttt{NePhi}$ 表示变换函циональ地，这使得训练和推理中的内存占用更加有效。这对大量的核心注册特别重要。此外，医疗影像注册方法表示转换地图via多层感知器已经提出，但 $\texttt{NePhi}$ 可以实现对约束 optimize 的 pairwise 注册以及学习基于预测或优化的全局和本地秘密码注册。最后，由于变换规范是医疗影像注册任务中最为急需的特性之一， $\texttt{NePhi}$ 使用了梯度反转一致正则化，这些正则化在实际中能够使变换变得约等于Diffusion的。我们在两个二维 sintetic 数据集以及真实的三维肺注册任务中展示了 $\texttt{NePhi}$ 的性能，结果表明 $\texttt{NePhi}$ 可以在单个分辨率注册设置中 achieve 类似于 voxel-based 表示的准确性，使用更少的内存和允许更快的实例优化。
</details></li>
</ul>
<hr>
<h2 id="Multi-Modal-Hybrid-Learning-and-Sequential-Training-for-RGB-T-Saliency-Detection"><a href="#Multi-Modal-Hybrid-Learning-and-Sequential-Training-for-RGB-T-Saliency-Detection" class="headerlink" title="Multi-Modal Hybrid Learning and Sequential Training for RGB-T Saliency Detection"></a>Multi-Modal Hybrid Learning and Sequential Training for RGB-T Saliency Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07297">http://arxiv.org/abs/2309.07297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyu Ren, Jitesh Joshi, Youngjun Cho</li>
<li>For: 本研究旨在提高RGB-T焦点检测的精度，Addressing the limitations of existing methods that neglect the characteristics of cross-modal features and rely solely on network structures to fuse RGB and thermal features.* Methods: 我们提出了一种多Modal Hybrid loss（MMHL），包括监督和自监督损失函数。 semantic features from different modalities are distinctly utilized in the supervised loss component, while the self-supervised loss component reduces the distance between RGB and thermal features. We also consider both spatial and channel information during feature fusion and propose the Hybrid Fusion Module to effectively fuse RGB and thermal features.* Results: 我们采用了一种顺序训练策略，首先在RGB图像上进行训练，然后在第二个阶段学习交叉模式特征。 This training strategy improves saliency detection performance without increasing computational overhead. Results from performance evaluation and ablation studies demonstrate the superior performance achieved by the proposed method compared with the existing state-of-the-art methods.<details>
<summary>Abstract</summary>
RGB-T saliency detection has emerged as an important computer vision task, identifying conspicuous objects in challenging scenes such as dark environments. However, existing methods neglect the characteristics of cross-modal features and rely solely on network structures to fuse RGB and thermal features. To address this, we first propose a Multi-Modal Hybrid loss (MMHL) that comprises supervised and self-supervised loss functions. The supervised loss component of MMHL distinctly utilizes semantic features from different modalities, while the self-supervised loss component reduces the distance between RGB and thermal features. We further consider both spatial and channel information during feature fusion and propose the Hybrid Fusion Module to effectively fuse RGB and thermal features. Lastly, instead of jointly training the network with cross-modal features, we implement a sequential training strategy which performs training only on RGB images in the first stage and then learns cross-modal features in the second stage. This training strategy improves saliency detection performance without computational overhead. Results from performance evaluation and ablation studies demonstrate the superior performance achieved by the proposed method compared with the existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GAN-based-Algorithm-for-Efficient-Image-Inpainting"><a href="#GAN-based-Algorithm-for-Efficient-Image-Inpainting" class="headerlink" title="GAN-based Algorithm for Efficient Image Inpainting"></a>GAN-based Algorithm for Efficient Image Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07293">http://arxiv.org/abs/2309.07293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyang Han, Zehao Jiang, Yuan Ju</li>
<li>for: 实现面部识别中掩盖面罩的问题，因为COVID-19的全球大流行导致了新的挑战。</li>
<li>methods: 使用机器学习的图像填充技术，以完成掩盖面罩中的可能的面部。特别是使用自适应器和生成敌方网络（GAN），以保留具体的图像特征和生成力。</li>
<li>results: 使用50,000个影星面部图像进行训练，获得了一个可靠的结果，但还有空间进行改进。此外，文章还讨论了模型的缺陷和改进方向，以及未来的应用范围和进一步改进方法。<details>
<summary>Abstract</summary>
Global pandemic due to the spread of COVID-19 has post challenges in a new dimension on facial recognition, where people start to wear masks. Under such condition, the authors consider utilizing machine learning in image inpainting to tackle the problem, by complete the possible face that is originally covered in mask. In particular, autoencoder has great potential on retaining important, general features of the image as well as the generative power of the generative adversarial network (GAN). The authors implement a combination of the two models, context encoders and explain how it combines the power of the two models and train the model with 50,000 images of influencers faces and yields a solid result that still contains space for improvements. Furthermore, the authors discuss some shortcomings with the model, their possible improvements, as well as some area of study for future investigation for applicative perspective, as well as directions to further enhance and refine the model.
</details>
<details>
<summary>摘要</summary>
全球大流行 COVID-19 病毒的蔓延已经带来了一种新的维度的面部识别挑战，由于人们开始穿着口罩。在这种情况下，作者们考虑使用机器学习图像填充技术来解决问题，通过完成掩盖在口罩中的可能的面部。特别是，自适应器具有保留图像重要特征的能力和生成型生成器网络（GAN）的生成力。作者们实现了这两种模型的组合，并解释了这两种模型如何结合并训练模型，使用50,000张影武者脸部图像，并获得了一个坚固的结果，还有空间进行改进。此外，作者们还讨论了模型的缺陷、可能的改进和未来研究的方向，以及如何进一步提高和细化模型。
</details></li>
</ul>
<hr>
<h2 id="Unbiased-Face-Synthesis-With-Diffusion-Models-Are-We-There-Yet"><a href="#Unbiased-Face-Synthesis-With-Diffusion-Models-Are-We-There-Yet" class="headerlink" title="Unbiased Face Synthesis With Diffusion Models: Are We There Yet?"></a>Unbiased Face Synthesis With Diffusion Models: Are We There Yet?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07277">http://arxiv.org/abs/2309.07277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harrison Rosenberg, Shimaa Ahmed, Guruprasad V Ramesh, Ramya Korlakai Vinayak, Kassem Fawaz</li>
<li>for: 本研究旨在 investigate text-to-image diffusion models 的效果和缺陷在人脸生成方面。</li>
<li>methods: 本研究使用了一组质量量化指标和用户研究来评估生成的人脸图像。</li>
<li>results: 研究发现生成的人脸图像存在忠实度、人口群体差异和分布Shift等缺陷。此外，我们还提出了一种分析模型，可以帮助理解训练数据选择对生成模型的表现产生了什么影响。<details>
<summary>Abstract</summary>
Text-to-image diffusion models have achieved widespread popularity due to their unprecedented image generation capability. In particular, their ability to synthesize and modify human faces has spurred research into using generated face images in both training data augmentation and model performance assessments. In this paper, we study the efficacy and shortcomings of generative models in the context of face generation. Utilizing a combination of qualitative and quantitative measures, including embedding-based metrics and user studies, we present a framework to audit the characteristics of generated faces conditioned on a set of social attributes. We applied our framework on faces generated through state-of-the-art text-to-image diffusion models. We identify several limitations of face image generation that include faithfulness to the text prompt, demographic disparities, and distributional shifts. Furthermore, we present an analytical model that provides insights into how training data selection contributes to the performance of generative models.
</details>
<details>
<summary>摘要</summary>
文本到图像扩散模型已经得到了广泛的推广，尤其是它们可以生成和修改人脸图像的能力。在这篇论文中，我们研究了生成模型在人脸生成方面的有效性和缺陷。我们使用了一组质量量化指标和用户调查来评估生成图像的特点，并应用于使用最新的文本到图像扩散模型生成的人脸图像。我们发现了一些生成人脸图像的限制，包括文本提示的准确性、人口群体差异和分布偏移。此外，我们还提出了一个分析模型，帮助我们理解训练数据选择对生成模型的影响。
</details></li>
</ul>
<hr>
<h2 id="So-you-think-you-can-track"><a href="#So-you-think-you-can-track" class="headerlink" title="So you think you can track?"></a>So you think you can track?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07268">http://arxiv.org/abs/2309.07268</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rprokap/pset-9">https://github.com/rprokap/pset-9</a></li>
<li>paper_authors: Derek Gloudemans, Gergely Zachár, Yanbing Wang, Junyi Ji, Matt Nice, Matt Bunting, William Barbour, Jonathan Sprinkle, Benedetto Piccoli, Maria Laura Delle Monache, Alexandre Bayen, Benjamin Seibold, Daniel B. Work</li>
<li>for: 这篇论文旨在提供一个多 камерatracking数据集，用于测试跟踪算法的性能。</li>
<li>methods: 论文使用了234个高清晰度相机记录了一段4.2英里长的8-10车道高速公路附近纳什维尔的视频数据，并将视频数据与270辆车辆的GPS轨迹数据结合使用，以提供一组真实的轨迹数据。</li>
<li>results: 初步的测试结果显示，使用跟踪算法对视频数据进行跟踪，只能获得9.5%的最佳HOTA（最高识别率75.9%，IOU 0.1，平均每个真实轨迹对象的ID数为47.9），这表明测试的跟踪算法无法在需要的长时间和空间尺度上达到足够的性能。<details>
<summary>Abstract</summary>
This work introduces a multi-camera tracking dataset consisting of 234 hours of video data recorded concurrently from 234 overlapping HD cameras covering a 4.2 mile stretch of 8-10 lane interstate highway near Nashville, TN. The video is recorded during a period of high traffic density with 500+ objects typically visible within the scene and typical object longevities of 3-15 minutes. GPS trajectories from 270 vehicle passes through the scene are manually corrected in the video data to provide a set of ground-truth trajectories for recall-oriented tracking metrics, and object detections are provided for each camera in the scene (159 million total before cross-camera fusion). Initial benchmarking of tracking-by-detection algorithms is performed against the GPS trajectories, and a best HOTA of only 9.5% is obtained (best recall 75.9% at IOU 0.1, 47.9 average IDs per ground truth object), indicating the benchmarked trackers do not perform sufficiently well at the long temporal and spatial durations required for traffic scene understanding.
</details>
<details>
<summary>摘要</summary>
这项工作介绍了一个多个摄像头跟踪数据集，包含234小时的视频数据，由234个 overlap 高清晰度摄像头记录在田中的4.2英里长8-10车道高速公路附近。视频在高交通密度时期录制，typical object longevities 3-15分钟，可以看到500多个对象在场景中。GPS轨迹从270辆车辆通过场景被手动修正在视频数据中，以提供一个基准轨迹数据集，并提供了每个摄像头上的对象探测结果（共159万个）。初步测试了基于检测的跟踪算法，并在GPS轨迹上实现了最佳HOTA的9.5%（最高准确率75.9%，IOU 0.1，47.9个平均ID每个基准对象），这表明测试的跟踪算法无法在需要的长时间和空间持续时间内达到足够的性能。
</details></li>
</ul>
<hr>
<h2 id="Automated-segmentation-of-rheumatoid-arthritis-immunohistochemistry-stained-synovial-tissue"><a href="#Automated-segmentation-of-rheumatoid-arthritis-immunohistochemistry-stained-synovial-tissue" class="headerlink" title="Automated segmentation of rheumatoid arthritis immunohistochemistry stained synovial tissue"></a>Automated segmentation of rheumatoid arthritis immunohistochemistry stained synovial tissue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07255">http://arxiv.org/abs/2309.07255</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amayags/ihc_synovium_segmentation">https://github.com/amayags/ihc_synovium_segmentation</a></li>
<li>paper_authors: Amaya Gallagher-Syed, Abbas Khan, Felice Rivellese, Costantino Pitzalis, Myles J. Lewis, Gregory Slabaugh, Michael R. Barnes<br>for: 这个研究是为了开发一个可靠、重复的自动分类算法，以帮助研究人员分析患有慢性Autoimmune疾病的Synovial tissue标本。methods: 这个研究使用了UNET对一个手动检验、多中心临床资料集R4RA进行训练，以 Handle多种IHC染色方法和不同来源的资料集中的变化。results: 模型在DICE分数0.865的基础上，成功地分类不同类型的IHC染色、处理不同来源的资料集中的变化、和常见的WSIs错误。这个算法可以用作自动影像分析管道的第一步，从而提高速度、重复性和Robustness。<details>
<summary>Abstract</summary>
Rheumatoid Arthritis (RA) is a chronic, autoimmune disease which primarily affects the joint's synovial tissue. It is a highly heterogeneous disease, with wide cellular and molecular variability observed in synovial tissues. Over the last two decades, the methods available for their study have advanced considerably. In particular, Immunohistochemistry stains are well suited to highlighting the functional organisation of samples. Yet, analysis of IHC-stained synovial tissue samples is still overwhelmingly done manually and semi-quantitatively by expert pathologists. This is because in addition to the fragmented nature of IHC stained synovial tissue, there exist wide variations in intensity and colour, strong clinical centre batch effect, as well as the presence of many undesirable artefacts present in gigapixel Whole Slide Images (WSIs), such as water droplets, pen annotation, folded tissue, blurriness, etc. There is therefore a strong need for a robust, repeatable automated tissue segmentation algorithm which can cope with this variability and provide support to imaging pipelines. We train a UNET on a hand-curated, heterogeneous real-world multi-centre clinical dataset R4RA, which contains multiple types of IHC staining. The model obtains a DICE score of 0.865 and successfully segments different types of IHC staining, as well as dealing with variance in colours, intensity and common WSIs artefacts from the different clinical centres. It can be used as the first step in an automated image analysis pipeline for synovial tissue samples stained with IHC, increasing speed, reproducibility and robustness.
</details>
<details>
<summary>摘要</summary>
《急性风湿综合病（RA）是一种chronic autoimmune疾病，主要影响 JOINT的 synovial тissue。这是一种highly heterogeneous的疾病， synovial tissue中observation到了宽泛的细胞和分子多样性。过去二十年， изу究这种疾病的方法有了很大的进步。特别是，免疫组织染色（IHC）是一种非常适合高亮samples的功能组织结构的方法。然而，IHC染色synovial tissue样本的分析仍然是由专家病理学家手动、半量地进行的。这是因为synovial tissue样本的残留物和水滴落、笔迹注解、折叠、模糊等多种缺点和噪声存在。因此，有一个强大、重复的自动化组织分 segmentation算法的需求，以适应这种多样性，并提供图像管道中的支持。我们在一个手动、多中心临床数据集R4RA上训练了一个UNET模型，该模型在多种IHC染色类型中 segments不同类型的IHC染色，并处理了不同临床中心的variance in colors、intensity和常见的WSIs噪声。它可以作为自动化图像分析管道的第一步，提高速度、可重复性和 Robustness。
</details></li>
</ul>
<hr>
<h2 id="Mitigate-Replication-and-Copying-in-Diffusion-Models-with-Generalized-Caption-and-Dual-Fusion-Enhancement"><a href="#Mitigate-Replication-and-Copying-in-Diffusion-Models-with-Generalized-Caption-and-Dual-Fusion-Enhancement" class="headerlink" title="Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement"></a>Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07254">http://arxiv.org/abs/2309.07254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghao Li, Dake Chen, Yuke Zhang, Peter A. Beerel</li>
<li>for: 减少扩散模型中的复制现象，以保护隐私。</li>
<li>methods: 引入一个通用度分数来衡量训练数据标签的通用性，并使用大语言模型（LLM）来泛化训练标签。然后，我们提出了一种双混合增强方法来缓解扩散模型中的复制现象。</li>
<li>results: 我们的提议方法可以相比原始扩散模型，降低复制率 by 43.5%，同时保持生成的多样性和质量。<details>
<summary>Abstract</summary>
While diffusion models demonstrate a remarkable capability for generating high-quality images, their tendency to `replicate' training data raises privacy concerns. Although recent research suggests that this replication may stem from the insufficient generalization of training data captions and duplication of training images, effective mitigation strategies remain elusive. To address this gap, our paper first introduces a generality score that measures the caption generality and employ large language model (LLM) to generalize training captions. Subsequently, we leverage generalized captions and propose a novel dual fusion enhancement approach to mitigate the replication of diffusion models. Our empirical results demonstrate that our proposed methods can significantly reduce replication by 43.5% compared to the original diffusion model while maintaining the diversity and quality of generations.
</details>
<details>
<summary>摘要</summary>
Diffusion models demonstrate remarkable image generation capabilities, but their tendency to "replicate" training data raises privacy concerns. Recent research suggests that this replication stems from insufficient generalization of training data captions and duplication of training images, but effective mitigation strategies remain elusive. To address this gap, our paper introduces a generality score to measure caption generality and uses large language models (LLM) to generalize training captions. We then propose a novel dual fusion enhancement approach to mitigate the replication of diffusion models. Our empirical results show that our proposed methods can significantly reduce replication by 43.5% compared to the original diffusion model while maintaining the diversity and quality of generations.Here's the text in Simplified Chinese characters:Diffusion models 表现出杰出的图像生成能力，但它们的“复制”行为引起隐私问题。最近的研究表明，这种复制是因为训练数据标签的不够普遍性和训练图像的重复，但有效的 mitigation 策略仍然存在问题。为了解决这个差距，我们的论文首先引入一个普遍度分数来衡量标签普遍性，然后使用大型自然语言模型（LLM）来普遍化训练标签。接着，我们提出了一种新的双拟合增强方法来缓解 diffusion 模型的复制。我们的实验结果表明，我们的提议方法可以将复制量降低到原始 diffusion 模型的 43.5% 水平，同时保持生成的多样性和质量。
</details></li>
</ul>
<hr>
<h2 id="LInKs-“Lifting-Independent-Keypoints”-–-Partial-Pose-Lifting-for-Occlusion-Handling-with-Improved-Accuracy-in-2D-3D-Human-Pose-Estimation"><a href="#LInKs-“Lifting-Independent-Keypoints”-–-Partial-Pose-Lifting-for-Occlusion-Handling-with-Improved-Accuracy-in-2D-3D-Human-Pose-Estimation" class="headerlink" title="LInKs “Lifting Independent Keypoints” – Partial Pose Lifting for Occlusion Handling with Improved Accuracy in 2D-3D Human Pose Estimation"></a>LInKs “Lifting Independent Keypoints” – Partial Pose Lifting for Occlusion Handling with Improved Accuracy in 2D-3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07243">http://arxiv.org/abs/2309.07243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Hardy, Hansung Kim</li>
<li>for:  recover 3D human poses from 2D kinematic skeletons</li>
<li>methods: lift-then-fill approach, custom sampling function, and independent lifting of skeleton parts</li>
<li>results: significantly more accurate results, improved stability and likelihood estimation, and consistent accuracy in scenarios without occlusion<details>
<summary>Abstract</summary>
We present LInKs, a novel unsupervised learning method to recover 3D human poses from 2D kinematic skeletons obtained from a single image, even when occlusions are present. Our approach follows a unique two-step process, which involves first lifting the occluded 2D pose to the 3D domain, followed by filling in the occluded parts using the partially reconstructed 3D coordinates. This lift-then-fill approach leads to significantly more accurate results compared to models that complete the pose in 2D space alone. Additionally, we improve the stability and likelihood estimation of normalising flows through a custom sampling function replacing PCA dimensionality reduction previously used in prior work. Furthermore, we are the first to investigate if different parts of the 2D kinematic skeleton can be lifted independently which we find by itself reduces the error of current lifting approaches. We attribute this to the reduction of long-range keypoint correlations. In our detailed evaluation, we quantify the error under various realistic occlusion scenarios, showcasing the versatility and applicability of our model. Our results consistently demonstrate the superiority of handling all types of occlusions in 3D space when compared to others that complete the pose in 2D space. Our approach also exhibits consistent accuracy in scenarios without occlusion, as evidenced by a 7.9% reduction in reconstruction error compared to prior works on the Human3.6M dataset. Furthermore, our method excels in accurately retrieving complete 3D poses even in the presence of occlusions, making it highly applicable in situations where complete 2D pose information is unavailable.
</details>
<details>
<summary>摘要</summary>
我们介绍了LInKs，一种新的无监督学习方法，用于从单张图像中提取3D人姿 pose，即使存在 occlusion。我们的方法采用了一个Unique two-step process，首先将受 occlusion 的2D pose提升到3D空间，然后使用部分重建的3D坐标填充 occluded 部分。这种 lift-then-fill 方法，与先前只在2D空间完成 pose 的模型相比，具有显著更高的准确性。此外，我们通过自定义抽样函数取代先前在先前工作中使用的 PCA 维度减少，提高了流体的稳定性和likelihood估计。进一步，我们发现可以独立提升不同部分的2D骨架，这会减少了长距离关键点相关性，从而降低 error。在我们的详细评估中，我们对不同的 occlusion 场景下的 error 进行了量化分析，并展示了我们的模型在不同的场景下的多样化和可应用性。我们的结果表明，在3D空间中处理所有类型的 occlusion 时，我们的方法具有明显的优势，并且在没有 occlusion 的场景下也具有高度的准确性。此外，我们的方法能够准确地从图像中提取完整的3D姿 pose，即使完整的2D pose信息不available。
</details></li>
</ul>
<hr>
<h2 id="Text-Guided-Generation-and-Editing-of-Compositional-3D-Avatars"><a href="#Text-Guided-Generation-and-Editing-of-Compositional-3D-Avatars" class="headerlink" title="Text-Guided Generation and Editing of Compositional 3D Avatars"></a>Text-Guided Generation and Editing of Compositional 3D Avatars</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07125">http://arxiv.org/abs/2309.07125</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HaoZhang990127/TECA">https://github.com/HaoZhang990127/TECA</a></li>
<li>paper_authors: Hao Zhang, Yao Feng, Peter Kulits, Yandong Wen, Justus Thies, Michael J. Black</li>
<li>for: 通过文本描述生成高质量的3D人物头像，包括发型和配饰。</li>
<li>methods: 使用分解模型，将人物头部、脸部、头发和配饰分别用3D矩阵和神经辐射场（NeRF）来表示，以提高实现和编辑人物的出现。</li>
<li>results: 通过Text-guided generation and Editing of Compositional Avatars（TECA）方法，可以从文本描述中生成更加真实的3D人物头像，同时支持编辑人物的外观特征，如发型、辫子和其他配饰。<details>
<summary>Abstract</summary>
Our goal is to create a realistic 3D facial avatar with hair and accessories using only a text description. While this challenge has attracted significant recent interest, existing methods either lack realism, produce unrealistic shapes, or do not support editing, such as modifications to the hairstyle. We argue that existing methods are limited because they employ a monolithic modeling approach, using a single representation for the head, face, hair, and accessories. Our observation is that the hair and face, for example, have very different structural qualities that benefit from different representations. Building on this insight, we generate avatars with a compositional model, in which the head, face, and upper body are represented with traditional 3D meshes, and the hair, clothing, and accessories with neural radiance fields (NeRF). The model-based mesh representation provides a strong geometric prior for the face region, improving realism while enabling editing of the person's appearance. By using NeRFs to represent the remaining components, our method is able to model and synthesize parts with complex geometry and appearance, such as curly hair and fluffy scarves. Our novel system synthesizes these high-quality compositional avatars from text descriptions. The experimental results demonstrate that our method, Text-guided generation and Editing of Compositional Avatars (TECA), produces avatars that are more realistic than those of recent methods while being editable because of their compositional nature. For example, our TECA enables the seamless transfer of compositional features like hairstyles, scarves, and other accessories between avatars. This capability supports applications such as virtual try-on.
</details>
<details>
<summary>摘要</summary>
我们的目标是创建一个现实主义3D人物头像，包括头发和配件，只使用文本描述。Recent interest in this challenge has been significant, but existing methods lack realism, produce unrealistic shapes, or do not support editing. We argue that these methods are limited because they use a monolithic modeling approach, where the head, face, hair, and accessories are represented by a single model. Our observation is that the hair and face have very different structural qualities that benefit from different representations. Based on this insight, we generate avatars with a compositional model, where the head, face, and upper body are represented by traditional 3D meshes, and the hair, clothing, and accessories are represented by neural radiance fields (NeRF). This approach provides a strong geometric prior for the face region, improving realism while enabling editing of the person's appearance. NeRFs are used to model and synthesize parts with complex geometry and appearance, such as curly hair and fluffy scarves. Our novel system, Text-guided generation and Editing of Compositional Avatars (TECA), synthesizes high-quality compositional avatars from text descriptions. Experimental results show that our method produces more realistic avatars than recent methods, and is editable due to its compositional nature. For example, our TECA enables seamless transfer of compositional features like hairstyles, scarves, and other accessories between avatars, supporting applications such as virtual try-on.
</details></li>
</ul>
<hr>
<h2 id="Tree-Structured-Shading-Decomposition"><a href="#Tree-Structured-Shading-Decomposition" class="headerlink" title="Tree-Structured Shading Decomposition"></a>Tree-Structured Shading Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07122">http://arxiv.org/abs/2309.07122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gcgeng/inv-shade-trees">https://github.com/gcgeng/inv-shade-trees</a></li>
<li>paper_authors: Chen Geng, Hong-Xing Yu, Sharon Zhang, Maneesh Agrawala, Jiajun Wu</li>
<li>for: 本研究旨在从单一图像中推断物体阴影树状表示，以便对物体表面阴影进行编辑。</li>
<li>methods: 本文提出使用阴影树表示，结合基本阴影节点和混合方法来因式物体表面阴影。这种表示方式可以让不熟悉物理阴影过程的 novice 用户通过有效和直观的方式进行编辑。</li>
<li>results: 本文通过实验表明，使用 hybrid 方法可以有效地推断阴影树并且可以在不同的图像和描述符下进行应用。这些应用包括材料编辑、vectorized 阴影和重新照明。<details>
<summary>Abstract</summary>
We study inferring a tree-structured representation from a single image for object shading. Prior work typically uses the parametric or measured representation to model shading, which is neither interpretable nor easily editable. We propose using the shade tree representation, which combines basic shading nodes and compositing methods to factorize object surface shading. The shade tree representation enables novice users who are unfamiliar with the physical shading process to edit object shading in an efficient and intuitive manner. A main challenge in inferring the shade tree is that the inference problem involves both the discrete tree structure and the continuous parameters of the tree nodes. We propose a hybrid approach to address this issue. We introduce an auto-regressive inference model to generate a rough estimation of the tree structure and node parameters, and then we fine-tune the inferred shade tree through an optimization algorithm. We show experiments on synthetic images, captured reflectance, real images, and non-realistic vector drawings, allowing downstream applications such as material editing, vectorized shading, and relighting. Project website: https://chen-geng.com/inv-shade-trees
</details>
<details>
<summary>摘要</summary>
我们研究从单张图像推导出树状表示，以便对物体陷阱进行推断。先前的工作通常使用参数化或测量表示方法来模拟陷阱，这些方法都不是可解释的，也不是容易修改的。我们提议使用阴影树表示，这种表示结合基本阴影节点和组合方法来因式化物体表面阴影。阴影树表示使得无经验的用户可以快速和直观地编辑物体阴影。主要挑战在推导阴影树时是解决混合精度和树结构的问题。我们提出了一种混合方法，包括自动回归推断模型生成粗略的树结构和节点参数，然后通过优化算法进行细化调整。我们在Synthetic图像、捕捉反射图像、真实图像和非现实 вектор图像上进行了实验，以便下游应用如材质编辑、vector化阴影和重新照明。项目网站：https://chen-geng.com/inv-shade-trees
</details></li>
</ul>
<hr>
<h2 id="PILOT-A-Pre-Trained-Model-Based-Continual-Learning-Toolbox"><a href="#PILOT-A-Pre-Trained-Model-Based-Continual-Learning-Toolbox" class="headerlink" title="PILOT: A Pre-Trained Model-Based Continual Learning Toolbox"></a>PILOT: A Pre-Trained Model-Based Continual Learning Toolbox</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07117">http://arxiv.org/abs/2309.07117</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sun-hailong/lamda-pilot">https://github.com/sun-hailong/lamda-pilot</a></li>
<li>paper_authors: Hai-Long Sun, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan</li>
<li>for: 本研究旨在开发一个基于预训练模型的 continual learning 工具箱（PILOT），以便在实际应用中适应新数据的到达。</li>
<li>methods: 本研究使用了一些当前领先的类增量学习算法基于预训练模型，如L2P、DualPrompt和CODA-Prompt。同时，PILOT还将典型的类增量学习算法（如DER、FOSTER和MEMO）置于预训练模型的Context中进行评估其效果。</li>
<li>results: PILOT在实际应用中表现出色，能够在不同的类增量学习任务中保持高度的性能。<details>
<summary>Abstract</summary>
While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data. As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival. Recently, pre-training has made significant advancements and garnered the attention of numerous researchers. The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios. Consequently, exploring the utilization of PTMs in incremental learning has become essential. This paper introduces a pre-trained model-based continual learning toolbox known as PILOT. On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt. On the other hand, PILOT also fits typical class-incremental learning algorithms (e.g., DER, FOSTER, and MEMO) within the context of pre-trained models to evaluate their effectiveness.
</details>
<details>
<summary>摘要</summary>
传统机器学习可以有效地解决广泛的问题，但它通常运作在关闭世界设定下，这限制了处理流动资料的能力。为了解决这个问题，增量学习 emerges 作为一个解决方案，可以在实际世界情况下进行学习。最近，预训条件（Pre-training）已经做出了重要的进步，并吸引了许多研究人员的注意。这些预训模型（PTMs）的强大表现表明了它们可以作为增量学习的基础，以便更好地适应实际世界情况。因此，使用 PTMs 在增量学习中是必要的。本文提出了一个基于预训模型的增量学习工具箱，称为 PILOT。一方面，PILOT 实现了一些现代的分类增量学习算法，基于预训模型，如 L2P、DualPrompt 和 CODA-Prompt。另一方面，PILOT 还可以将传统的分类增量学习算法（例如 DER、FOSTER 和 MEMO）与预训模型集成，以评估其效果。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Multi-Task-Learning-for-Audio-Visual-Speaker-Verification"><a href="#Weakly-Supervised-Multi-Task-Learning-for-Audio-Visual-Speaker-Verification" class="headerlink" title="Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker Verification"></a>Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07115">http://arxiv.org/abs/2309.07115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anith Selvakumar, Homa Fashandi</li>
<li>for: 这篇论文旨在提出一种实现多modal人资料的稳定测试方法，以便进行开集 audio-visual 人识别。</li>
<li>methods: 这篇论文使用了多任务学习技术，以强化距离度量学习（DML）方法，并证明了具有弱标签的副任务可以增加学习的话者表示的紧密度。 In addition, the authors extended the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrated that it can achieve competitive performance in an audio-visual space.</li>
<li>results: 这篇论文的网络实现了开集 audio-visual  speaker verification的state of the art表现， reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O&#x2F;E&#x2F;H, which is to our knowledge, the best published results on VoxCeleb1-E and VoxCeleb1-H.<details>
<summary>Abstract</summary>
In this paper, we present a methodology for achieving robust multimodal person representations optimized for open-set audio-visual speaker verification. Distance Metric Learning (DML) approaches have typically dominated this problem space, owing to strong performance on new and unseen classes. In our work, we explored multitask learning techniques to further boost performance of the DML approach and show that an auxiliary task with weak labels can increase the compactness of the learned speaker representation. We also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrate that it can achieve competitive performance in an audio-visual space. Finally, we introduce a non-synchronous audio-visual sampling random strategy during training time that has shown to improve generalization. Our network achieves state of the art performance for speaker verification, reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published results on VoxCeleb1-E and VoxCeleb1-H.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种方法来实现可靠的多模态人表示，optimized for open-set audio-visual speaker verification。传统的Distance Metric Learning（DML）方法在这个问题空间中占据主导地位，因为它在新和未经见的类型上表现出色。在我们的工作中，我们探索了多任务学习技术，以提高DML方法的性能，并证明了一个auxiliary任务的弱标签可以提高学习的人类表示的紧凑性。我们还扩展了Generalized end-to-end loss（GE2E）到多模态输入，并证明它可以在音频视频空间中达到竞争性能。最后，我们引入了在训练时Audio-Visual采样随机化策略，并证明其可以提高总体化。我们的网络实现了人识别的状态方法，报告了VoxCeleb1-O/E/H三个官方试验列表的EER为0.244%、0.252%和0.441%，这是我们所知道的最佳发表结果。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Deep-Encoding-Enables-Uncertainty-aware-Machine-learning-assisted-Histopathology"><a href="#Contrastive-Deep-Encoding-Enables-Uncertainty-aware-Machine-learning-assisted-Histopathology" class="headerlink" title="Contrastive Deep Encoding Enables Uncertainty-aware Machine-learning-assisted Histopathology"></a>Contrastive Deep Encoding Enables Uncertainty-aware Machine-learning-assisted Histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07113">http://arxiv.org/abs/2309.07113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirhoshan Sivaroopan, Chamuditha Jayanga, Chalani Ekanayake, Hasindri Watawana, Jathurshan Pradeepkumar, Mithunjha Anandakumar, Ranga Rodrigo, Chamira U. S. Edussooriya, Dushan N. Wadduwage</li>
<li>for: 本研究旨在使用大量公共领域数据来预训深度神经网络模型，以便在医学 histopathology 图像中学习丰富的特征。</li>
<li>methods: 本研究使用了大量公共领域数据进行预训，然后使用一小部分注释数据进行精度调整。此外，研究还提出了一种不确定性意识损失函数，以衡量模型在推理过程中的信任程度。</li>
<li>results: 研究表明，使用预训后精度调整的方法可以达到当今最佳性能（SOTA），并且只需要1-10%的注释数据。此外，研究还证明了不确定性意识损失函数可以帮助专家选择最佳的实例进行进一步训练。<details>
<summary>Abstract</summary>
Deep neural network models can learn clinically relevant features from millions of histopathology images. However generating high-quality annotations to train such models for each hospital, each cancer type, and each diagnostic task is prohibitively laborious. On the other hand, terabytes of training data -- while lacking reliable annotations -- are readily available in the public domain in some cases. In this work, we explore how these large datasets can be consciously utilized to pre-train deep networks to encode informative representations. We then fine-tune our pre-trained models on a fraction of annotated training data to perform specific downstream tasks. We show that our approach can reach the state-of-the-art (SOTA) for patch-level classification with only 1-10% randomly selected annotations compared to other SOTA approaches. Moreover, we propose an uncertainty-aware loss function, to quantify the model confidence during inference. Quantified uncertainty helps experts select the best instances to label for further training. Our uncertainty-aware labeling reaches the SOTA with significantly fewer annotations compared to random labeling. Last, we demonstrate how our pre-trained encoders can surpass current SOTA for whole-slide image classification with weak supervision. Our work lays the foundation for data and task-agnostic pre-trained deep networks with quantified uncertainty.
</details>
<details>
<summary>摘要</summary>
深度神经网络模型可以从百万个 histopathology 图像中学习丰富的临床相关特征。然而，为每个医院、每种肿瘤类型和每个诊断任务生成高质量笔记是不可能的。一方面，一些情况下有公共领域中的 terabytes 训练数据，尽管缺乏可靠笔记，但是可以采用。在这种情况下，我们探索了如何利用这些大量数据来预训练深度网络，以便在特定下游任务上编码有用的表示。然后，我们使用一部分注释训练数据来精度地训练我们的预训练模型，以达到特定的下游任务。我们发现，我们的方法可以与其他 SOTA 方法相比，只需要1-10%的随机选择笔记，可以达到 SOTA 的 patch-level 分类结果。此外，我们还提出了一种不确定性感知损失函数，用于衡量模型在推理过程中的自信度。这种量化不确定性帮助专家选择最佳的实例进行进一步训练。我们的不确定性感知标注可以与随机标注相比，并达到 SOTA 结果。最后，我们展示了我们的预训练Encoder可以在弱级指导下超越当前 SOTA 的整个扫描图像分类结果。我们的工作为数据和任务无关的预训练深度网络和量化不确定性提供了基础。
</details></li>
</ul>
<hr>
<h2 id="Hardening-RGB-D-Object-Recognition-Systems-against-Adversarial-Patch-Attacks"><a href="#Hardening-RGB-D-Object-Recognition-Systems-against-Adversarial-Patch-Attacks" class="headerlink" title="Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks"></a>Hardening RGB-D Object Recognition Systems against Adversarial Patch Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07106">http://arxiv.org/abs/2309.07106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Zheng, Luca Demetrio, Antonio Emanuele Cinà, Xiaoyi Feng, Zhaoqiang Xia, Xiaoyue Jiang, Ambra Demontis, Battista Biggio, Fabio Roli</li>
<li>for: 这种研究是为了提高RGB-D对象识别系统的预测性能，并且通过将色彩和深度信息 fusion来实现这一目标。</li>
<li>methods: 这种研究使用了RGB-D系统，并通过对这些系统进行攻击来检验其 robustness。</li>
<li>results: 研究发现，RGB-D系统在面对攻击时的Robustness与RGB-only系统类似，而且RGB-D系统的Robustness还受到了原始图像颜色的修改的攻击。此外，研究还提出了一种基于检测机制的防御方法，可以提高RGB-D系统对攻击的Robustness。<details>
<summary>Abstract</summary>
RGB-D object recognition systems improve their predictive performances by fusing color and depth information, outperforming neural network architectures that rely solely on colors. While RGB-D systems are expected to be more robust to adversarial examples than RGB-only systems, they have also been proven to be highly vulnerable. Their robustness is similar even when the adversarial examples are generated by altering only the original images' colors. Different works highlighted the vulnerability of RGB-D systems; however, there is a lacking of technical explanations for this weakness. Hence, in our work, we bridge this gap by investigating the learned deep representation of RGB-D systems, discovering that color features make the function learned by the network more complex and, thus, more sensitive to small perturbations. To mitigate this problem, we propose a defense based on a detection mechanism that makes RGB-D systems more robust against adversarial examples. We empirically show that this defense improves the performances of RGB-D systems against adversarial examples even when they are computed ad-hoc to circumvent this detection mechanism, and that is also more effective than adversarial training.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Polygon-Intersection-over-Union-Loss-for-Viewpoint-Agnostic-Monocular-3D-Vehicle-Detection"><a href="#Polygon-Intersection-over-Union-Loss-for-Viewpoint-Agnostic-Monocular-3D-Vehicle-Detection" class="headerlink" title="Polygon Intersection-over-Union Loss for Viewpoint-Agnostic Monocular 3D Vehicle Detection"></a>Polygon Intersection-over-Union Loss for Viewpoint-Agnostic Monocular 3D Vehicle Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07104">http://arxiv.org/abs/2309.07104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek Gloudemans, Xinxuan Lu, Shepard Xia, Daniel B. Work</li>
<li>for: 提高缺乏视点的单目3D物体检测精度</li>
<li>methods: 使用新的 polygon IoU 损失函数（PIoU loss）和传统的 L1 损失函数的组合</li>
<li>results: 在三种state-of-the-art 视点不对称的3D检测模型上测试并证明了PIoU loss的更快收敛速度和更高的精度（+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%&#x2F;+2.46% AP50&#x2F;AP25 for MonoRCNN on cyclists）<details>
<summary>Abstract</summary>
Monocular 3D object detection is a challenging task because depth information is difficult to obtain from 2D images. A subset of viewpoint-agnostic monocular 3D detection methods also do not explicitly leverage scene homography or geometry during training, meaning that a model trained thusly can detect objects in images from arbitrary viewpoints. Such works predict the projections of the 3D bounding boxes on the image plane to estimate the location of the 3D boxes, but these projections are not rectangular so the calculation of IoU between these projected polygons is not straightforward. This work proposes an efficient, fully differentiable algorithm for the calculation of IoU between two convex polygons, which can be utilized to compute the IoU between two 3D bounding box footprints viewed from an arbitrary angle. We test the performance of the proposed polygon IoU loss (PIoU loss) on three state-of-the-art viewpoint-agnostic 3D detection models. Experiments demonstrate that the proposed PIoU loss converges faster than L1 loss and that in 3D detection models, a combination of PIoU loss and L1 loss gives better results than L1 loss alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists).
</details>
<details>
<summary>摘要</summary>
“监视器一阶段3D物体检测是一个具有挑战性的任务，因为深度信息从2D图像中很难获取。一些不受视点影响的监视器一阶段3D检测方法不直接利用场势对或几何学 during training，这意味着它们可以在任意视点下检测物体。这些方法预测图像平面上3D bounding box的投影，但这些投影不是正方形的，因此计算IoU（交集率） между这些投影的多边形是不直接的。本文提出了一个高效、完全可微分的多边形IoU损失（PIoU损失），可以用来计算两个3D bounding box的投影之间的IoU。我们将这个PIoU损失与L1损失进行比较，实验结果显示PIoU损失在3D检测模型中较快速收敛，并且在3D检测模型中，PIoU损失和L1损失的组合比L1损失 alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists)。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="RadarLCD-Learnable-Radar-based-Loop-Closure-Detection-Pipeline"><a href="#RadarLCD-Learnable-Radar-based-Loop-Closure-Detection-Pipeline" class="headerlink" title="RadarLCD: Learnable Radar-based Loop Closure Detection Pipeline"></a>RadarLCD: Learnable Radar-based Loop Closure Detection Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07094">http://arxiv.org/abs/2309.07094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mirko Usuelli, Matteo Frosi, Paolo Cudrano, Simone Mentasti, Matteo Matteucci</li>
<li>for: The paper is written for the task of Loop Closure Detection (LCD) in robotics and computer vision, and to address the challenges of integrating radar data for this task.</li>
<li>methods: The paper proposes a novel supervised deep learning pipeline called RadarLCD, which leverages a pre-trained HERO model to select key points crucial for LCD tasks and achieve better performance than state-of-the-art methods.</li>
<li>results: The paper evaluates RadarLCD on a variety of FMCW Radar dataset scenes and shows that it surpasses state-of-the-art systems in multiple aspects of Loop Closure Detection.Here’s the Chinese translation of the three key points:</li>
<li>for: 这篇论文是为了Loop Closure Detection（LCD）任务而写的，并且解决了 integrating radar data 的挑战。</li>
<li>methods: 这篇论文提出了一种新的supervised deep learning pipeline，即RadarLCD，它利用了 pre-trained HERO 模型来选择关键的 LCD 任务点，并且在多个 FMCW Radar 数据集场景中进行评估，并与state-of-the-art系统进行比较。</li>
<li>results: 这篇论文在多个 FMCW Radar 数据集场景中进行评估，并显示RadarLCD 在多个方面的Loop Closure Detection 性能比state-of-the-art系统更高。<details>
<summary>Abstract</summary>
Loop Closure Detection (LCD) is an essential task in robotics and computer vision, serving as a fundamental component for various applications across diverse domains. These applications encompass object recognition, image retrieval, and video analysis. LCD consists in identifying whether a robot has returned to a previously visited location, referred to as a loop, and then estimating the related roto-translation with respect to the analyzed location. Despite the numerous advantages of radar sensors, such as their ability to operate under diverse weather conditions and provide a wider range of view compared to other commonly used sensors (e.g., cameras or LiDARs), integrating radar data remains an arduous task due to intrinsic noise and distortion. To address this challenge, this research introduces RadarLCD, a novel supervised deep learning pipeline specifically designed for Loop Closure Detection using the FMCW Radar (Frequency Modulated Continuous Wave) sensor. RadarLCD, a learning-based LCD methodology explicitly designed for radar systems, makes a significant contribution by leveraging the pre-trained HERO (Hybrid Estimation Radar Odometry) model. Being originally developed for radar odometry, HERO's features are used to select key points crucial for LCD tasks. The methodology undergoes evaluation across a variety of FMCW Radar dataset scenes, and it is compared to state-of-the-art systems such as Scan Context for Place Recognition and ICP for Loop Closure. The results demonstrate that RadarLCD surpasses the alternatives in multiple aspects of Loop Closure Detection.
</details>
<details>
<summary>摘要</summary>
Loop Closure Detection (LCD) 是 robotics 和计算机视觉中的一项重要任务，对各种应用领域有着广泛的应用，如对象识别、图像检索和视频分析。LCD 的目标是判断机器人是否返回到了之前访问过的位置（即循环），并估计相关的扭转翻译。尽管雷达传感器具有多种优势，如在不同天气条件下运行和其他普用传感器（如摄像头或 LiDAR）的视场更广泛，但将雷达数据与其他传感器结合仍然是一项困难的任务，因为雷达数据具有内在的噪声和扭曲。为解决这个挑战，本研究提出了 RadarLCD，一种基于深度学习的新型 Loop Closure Detection 管道，专门针对 Frequency Modulated Continuous Wave 雷达传感器。RadarLCD 是一种基于学习的 LCD 方法，通过利用预训练的 HERO（混合估算雷达运动）模型，选择关键点对 LCD 任务的重要性。该方法在多个 FMCW Radar 数据集场景进行评估，与状态的扫Context for Place Recognition 和 ICP for Loop Closure 相比较。结果表明，RadarLCD 在多个方面的 Loop Closure Detection 方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Developing-a-Novel-Image-Marker-to-Predict-the-Responses-of-Neoadjuvant-Chemotherapy-NACT-for-Ovarian-Cancer-Patients"><a href="#Developing-a-Novel-Image-Marker-to-Predict-the-Responses-of-Neoadjuvant-Chemotherapy-NACT-for-Ovarian-Cancer-Patients" class="headerlink" title="Developing a Novel Image Marker to Predict the Responses of Neoadjuvant Chemotherapy (NACT) for Ovarian Cancer Patients"></a>Developing a Novel Image Marker to Predict the Responses of Neoadjuvant Chemotherapy (NACT) for Ovarian Cancer Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07087">http://arxiv.org/abs/2309.07087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Zhang, Neman Abdoli, Patrik Gilley, Youkabed Sadri, Xuxin Chen, Theresa C. Thai, Lauren Dockery, Kathleen Moore, Robert S. Mannel, Yuchen Qiu</li>
<li>for: 这个研究的目的是开发一种新的图像标记，以便在早期预测NACT治疗的响应。</li>
<li>methods: 研究人员首先计算了1373个 радиологи学特征，以量化肿瘤特征，这些特征可以分为三类：几何特征、Intensity特征和xture特征。然后，这些特征被用principal component analysis算法优化，生成一个紧凑而有用的特征集。使用这个特征集作为输入，一个基于SVM的分类器被开发和优化，以创建一个最终的标记，表示病人是否响应NACT治疗。</li>
<li>results: 结果显示，这种新方法在ROC曲线的AUC为0.745，并达到了全体准确率的76.2%，正确预测率为70%，错误预测率为78.1%。<details>
<summary>Abstract</summary>
Objective: Neoadjuvant chemotherapy (NACT) is one kind of treatment for advanced stage ovarian cancer patients. However, due to the nature of tumor heterogeneity, the patients' responses to NACT varies significantly among different subgroups. To address this clinical challenge, the purpose of this study is to develop a novel image marker to achieve high accuracy response prediction of the NACT at an early stage. Methods: For this purpose, we first computed a total of 1373 radiomics features to quantify the tumor characteristics, which can be grouped into three categories: geometric, intensity, and texture features. Second, all these features were optimized by principal component analysis algorithm to generate a compact and informative feature cluster. Using this cluster as the input, an SVM based classifier was developed and optimized to create a final marker, indicating the likelihood of the patient being responsive to the NACT treatment. To validate this scheme, a total of 42 ovarian cancer patients were retrospectively collected. A nested leave-one-out cross-validation was adopted for model performance assessment. Results: The results demonstrate that the new method yielded an AUC (area under the ROC [receiver characteristic operation] curve) of 0.745. Meanwhile, the model achieved overall accuracy of 76.2%, positive predictive value of 70%, and negative predictive value of 78.1%. Conclusion: This study provides meaningful information for the development of radiomics based image markers in NACT response prediction.
</details>
<details>
<summary>摘要</summary>
目的：使用neoadjuvant化学治疗（NACT）对高度晚期卵巢癌患者进行治疗。然而，由于肿瘤多样性，患者对NACT的响应差异非常大。为解决这一临床挑战，本研究的目的是开发一种高精度响应预测 marker。方法：为达到这个目的，我们首先计算了1373个 радиологи特征，以量化肿瘤特征，这些特征可以分为三类：几何、Intensity和Texture特征。然后，我们使用主成分分析算法对这些特征进行优化，生成一个紧凑而有用的特征集。使用这个特征集作为输入，我们开发了一个基于SVM的分类器，并且优化了它以创建一个最终的marker，用于预测患者对NACT治疗的响应。以验证这种方案，我们收集了42例卵巢癌患者的数据，并采用了一种嵌入式的留一个出样验证。结果：结果显示，新的方法在ROC曲线上的AUC为0.745，并且模型的总准确率为76.2%，正确预测率为70%，错误预测率为78.1%。结论：本研究为 радиологи基于图像 marker 在NACT响应预测方面提供了有用的信息。
</details></li>
</ul>
<hr>
<h2 id="SupFusion-Supervised-LiDAR-Camera-Fusion-for-3D-Object-Detection"><a href="#SupFusion-Supervised-LiDAR-Camera-Fusion-for-3D-Object-Detection" class="headerlink" title="SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection"></a>SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07084">http://arxiv.org/abs/2309.07084</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iranqin/supfusion">https://github.com/iranqin/supfusion</a></li>
<li>paper_authors: Yiran Qin, Chaoqun Wang, Zijian Kang, Ningning Ma, Zhen Li, Ruimao Zhang<br>for:* 本研究旨在提出一种新的训练策略，即SupFusion，以提高LiDAR-Camera融合的检测性能。methods:* 我们提出了一种名为极地抽象的数据增强方法，用于增强稀疏的对象，并训练一个助手模型来生成高质量的特征作为监督。* 我们还提出了一种简单 yet effective的深度融合模块，可以连续提高检测器的能力。results:* 我们的提议在KITTI测试benchmark上实现了约2%的3D mAP提升，基于多个LiDAR-Camera 3D检测器。<details>
<summary>Abstract</summary>
In this paper, we propose a novel training strategy called SupFusion, which provides an auxiliary feature level supervision for effective LiDAR-Camera fusion and significantly boosts detection performance. Our strategy involves a data enhancement method named Polar Sampling, which densifies sparse objects and trains an assistant model to generate high-quality features as the supervision. These features are then used to train the LiDAR-Camera fusion model, where the fusion feature is optimized to simulate the generated high-quality features. Furthermore, we propose a simple yet effective deep fusion module, which contiguously gains superior performance compared with previous fusion methods with SupFusion strategy. In such a manner, our proposal shares the following advantages. Firstly, SupFusion introduces auxiliary feature-level supervision which could boost LiDAR-Camera detection performance without introducing extra inference costs. Secondly, the proposed deep fusion could continuously improve the detector's abilities. Our proposed SupFusion and deep fusion module is plug-and-play, we make extensive experiments to demonstrate its effectiveness. Specifically, we gain around 2% 3D mAP improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的训练策略，称为SupFusion，该策略提供了LiDAR-Camera fusión中的auxiliary feature层超级视图，以提高检测性能。我们的策略包括一种名为极地抽象法（Polar Sampling）的数据增强方法，该方法用于增强稀疏的对象并训练一个助手模型以生成高质量的特征。这些特征然后用于训练LiDAR-Camera fusión模型，其拼接特征优化以模拟生成的高质量特征。此外，我们还提出了一种简单 yet有效的深度融合模块，该模块可以不断提高检测器的能力。因此，我们的提议具有以下优点：一、SupFusion引入了auxiliary feature层超级视图，可以不添加额外的推理成本，提高LiDAR-Camera检测性能。二、我们提出的深度融合模块可以不断提高检测器的能力。我们的SupFusion和深度融合模块是可插入的，我们进行了广泛的实验来证明其效果。 Specifically, we gained around 2% 3D mAP improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors.
</details></li>
</ul>
<hr>
<h2 id="FAIR-Frequency-aware-Image-Restoration-for-Industrial-Visual-Anomaly-Detection"><a href="#FAIR-Frequency-aware-Image-Restoration-for-Industrial-Visual-Anomaly-Detection" class="headerlink" title="FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection"></a>FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07068">http://arxiv.org/abs/2309.07068</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liutongkun/fair">https://github.com/liutongkun/fair</a></li>
<li>paper_authors: Tongkun Liu, Bing Li, Xiao Du, Bingke Jiang, Leqi Geng, Feiyang Wang, Zhuo Zhao</li>
<li>for: 这种论文主要针对的是 industrial visual inspection 中的图像重建型异常检测模型，它们通常受到正常重建精度和异常重建分辨率之间的负面负担影响。</li>
<li>methods: 作者提出了一种新的自我超级视觉任务，即频率意识图像恢复（FAIR），它利用了异常重建错误的频率偏好来提高正常图像的恢复精度，同时降低不良泛化到异常图像上。</li>
<li>results: 使用简单的杂色UNet，FAIR可以在多种缺陷检测数据集上达到状态 искусственный知识的表现，并且比传统方法更高效。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/liutongkun/FAIR%E3%80%82">https://github.com/liutongkun/FAIR。</a><details>
<summary>Abstract</summary>
Image reconstruction-based anomaly detection models are widely explored in industrial visual inspection. However, existing models usually suffer from the trade-off between normal reconstruction fidelity and abnormal reconstruction distinguishability, which damages the performance. In this paper, we find that the above trade-off can be better mitigated by leveraging the distinct frequency biases between normal and abnormal reconstruction errors. To this end, we propose Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components. It enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies. Using only a simple vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency on various defect detection datasets. Code: https://github.com/liutongkun/FAIR.
</details>
<details>
<summary>摘要</summary>
工业视觉检查中广泛探索图像重建型异常检测模型。然而，现有模型通常受到正常重建准确性和异常重建分别性之间的负面trade-off影响，这会降低性能。在这篇论文中，我们发现了正常重建和异常重建错误频率偏好之间的明显差异。为了利用这一点，我们提出了频率意识图像恢复（FAIR）任务，该任务可以从高频组成部分恢复图像。这使得正常模式的精确重建同时减少了不利于异常检测的泛化。只使用简单的vanilla UNet，FAIR实现了与其他数据集上的状态码表现相同或更高的性能，同时更高效。代码：https://github.com/liutongkun/FAIR。
</details></li>
</ul>
<hr>
<h2 id="Aggregating-Long-term-Sharp-Features-via-Hybrid-Transformers-for-Video-Deblurring"><a href="#Aggregating-Long-term-Sharp-Features-via-Hybrid-Transformers-for-Video-Deblurring" class="headerlink" title="Aggregating Long-term Sharp Features via Hybrid Transformers for Video Deblurring"></a>Aggregating Long-term Sharp Features via Hybrid Transformers for Video Deblurring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07054">http://arxiv.org/abs/2309.07054</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shangwei5/stgtn">https://github.com/shangwei5/stgtn</a></li>
<li>paper_authors: Dongwei Ren, Wei Shang, Yi Yang, Wangmeng Zuo</li>
<li>for: 这种视频去滤方法是为了从给定的模糊视频中恢复连续的锐利帧而设计的。</li>
<li>methods: 该方法利用了邻域帧和当前锐利帧的hybrid transformer来集成特征。首先，我们训练了模糊检测器，以便在模糊视频中分辨锐利帧和模糊帧。然后，我们使用了窗口基于的本地transformer来利用邻域帧的特征，并在不需要显式坐标匹配的情况下通过对准器来协同集成特征。此外，我们还使用了全球transformer来聚合长期锐利特征。</li>
<li>results: 对于标准测试集，我们的提出方法在量化指标和视觉质量上都超过了现有的视频去滤方法和事件驱动视频去滤方法。ources are available at <a target="_blank" rel="noopener" href="https://github.com/shangwei5/STGTN">https://github.com/shangwei5/STGTN</a>.<details>
<summary>Abstract</summary>
Video deblurring methods, aiming at recovering consecutive sharp frames from a given blurry video, usually assume that the input video suffers from consecutively blurry frames. However, in real-world blurry videos taken by modern imaging devices, sharp frames usually appear in the given video, thus making temporal long-term sharp features available for facilitating the restoration of a blurry frame. In this work, we propose a video deblurring method that leverages both neighboring frames and present sharp frames using hybrid Transformers for feature aggregation. Specifically, we first train a blur-aware detector to distinguish between sharp and blurry frames. Then, a window-based local Transformer is employed for exploiting features from neighboring frames, where cross attention is beneficial for aggregating features from neighboring frames without explicit spatial alignment. To aggregate long-term sharp features from detected sharp frames, we utilize a global Transformer with multi-scale matching capability. Moreover, our method can easily be extended to event-driven video deblurring by incorporating an event fusion module into the global Transformer. Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms state-of-the-art video deblurring methods as well as event-driven video deblurring methods in terms of quantitative metrics and visual quality. The source code and trained models are available at https://github.com/shangwei5/STGTN.
</details>
<details>
<summary>摘要</summary>
“视频抖杂方法，目标是从给定的抖杂视频中恢复连续的锐利帧，通常假设输入视频中的每帧都是抖杂的。然而，现实中拍摄的视频中，有些帧是锐利的，因此可以利用这些锐利帧来帮助恢复抖杂帧。在这种情况下，我们提出了一种利用邻帧和当前锐利帧的hybrid transformer来Feature汇集的视频抖杂方法。具体来说，我们首先训练一个抖杂检测器，以便在视频中分辨锐利和抖杂帧。然后，我们使用窗口基本的本地transformer来利用邻帧中的特征，其中径观注意是有利于不需要显式匹配的特征汇集。此外，我们还利用全球的transformer来汇集长期内的锐利特征，并且我们可以轻松地扩展这种方法到事件驱动的视频抖杂。我们的方法在标准的量化指标和视觉质量上都超过了现有的视频抖杂方法和事件驱动的视频抖杂方法。我们的源代码和训练模型可以在https://github.com/shangwei5/STGTN上下载。”
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Multiple-Priors-for-Neural-3D-Indoor-Reconstruction"><a href="#Exploiting-Multiple-Priors-for-Neural-3D-Indoor-Reconstruction" class="headerlink" title="Exploiting Multiple Priors for Neural 3D Indoor Reconstruction"></a>Exploiting Multiple Priors for Neural 3D Indoor Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07021">http://arxiv.org/abs/2309.07021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Federico Lincetto, Gianluca Agresti, Mattia Rossi, Pietro Zanuttigh</li>
<li>for: 实现高质量3D重建结果的大型室内场景</li>
<li>methods: 提出了一种基于多种规则化策略的神经隐式模型方法，利用图像来实现更好的大型室内环境重建</li>
<li>results: 实验结果表明，我们的方法可以在复杂的室内场景中实现状态动态3D重建结果<details>
<summary>Abstract</summary>
Neural implicit modeling permits to achieve impressive 3D reconstruction results on small objects, while it exhibits significant limitations in large indoor scenes. In this work, we propose a novel neural implicit modeling method that leverages multiple regularization strategies to achieve better reconstructions of large indoor environments, while relying only on images. A sparse but accurate depth prior is used to anchor the scene to the initial model. A dense but less accurate depth prior is also introduced, flexible enough to still let the model diverge from it to improve the estimated geometry. Then, a novel self-supervised strategy to regularize the estimated surface normals is presented. Finally, a learnable exposure compensation scheme permits to cope with challenging lighting conditions. Experimental results show that our approach produces state-of-the-art 3D reconstructions in challenging indoor scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Instance-Adaptive-Prototypical-Contrastive-Embedding-for-Generalized-Zero-Shot-Learning"><a href="#Instance-Adaptive-Prototypical-Contrastive-Embedding-for-Generalized-Zero-Shot-Learning" class="headerlink" title="Instance Adaptive Prototypical Contrastive Embedding for Generalized Zero Shot Learning"></a>Instance Adaptive Prototypical Contrastive Embedding for Generalized Zero Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06987">http://arxiv.org/abs/2309.06987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Riti Paul, Sahil Vora, Baoxin Li</li>
<li>for: 这 paper 的目的是解决 generalized zero-shot learning(GZSL) 中样本分类问题，即在训练时不可以获取未经训练的标签。</li>
<li>methods: 这 paper 使用了 contrastive-learning-based (instance-based) embedding 在生成网络中，并利用数据点之间的 semantic relationship。然而，现有的嵌入建模方法受到两个限制：（1）不能考虑细致的集群结构，导致嵌入特征的有限可识别性；（2）对现有的对比嵌入网络来说，采用 restriction 的扩展机制，导致嵌入空间中的表示不够多样化。为了提高嵌入空间中的表示质量，我们提出了一种 margin-based prototypical contrastive learning embedding network，该网络可以从 prototype-data 和 implicit data-data 的交互中获得 clusters 的质量提升，同时为嵌入网络和生成器提供了明显的 cluster 超visulization。</li>
<li>results: 通过对三个 benchmark 数据集进行全面的实验评估，我们表明了我们的方法可以超越当前状态的艺术。我们的方法还在 GZSL  Setting 中具有最好的未经训练性能。<details>
<summary>Abstract</summary>
Generalized zero-shot learning(GZSL) aims to classify samples from seen and unseen labels, assuming unseen labels are not accessible during training. Recent advancements in GZSL have been expedited by incorporating contrastive-learning-based (instance-based) embedding in generative networks and leveraging the semantic relationship between data points. However, existing embedding architectures suffer from two limitations: (1) limited discriminability of synthetic features' embedding without considering fine-grained cluster structures; (2) inflexible optimization due to restricted scaling mechanisms on existing contrastive embedding networks, leading to overlapped representations in the embedding space. To enhance the quality of representations in the embedding space, as mentioned in (1), we propose a margin-based prototypical contrastive learning embedding network that reaps the benefits of prototype-data (cluster quality enhancement) and implicit data-data (fine-grained representations) interaction while providing substantial cluster supervision to the embedding network and the generator. To tackle (2), we propose an instance adaptive contrastive loss that leads to generalized representations for unseen labels with increased inter-class margin. Through comprehensive experimental evaluation, we show that our method can outperform the current state-of-the-art on three benchmark datasets. Our approach also consistently achieves the best unseen performance in the GZSL setting.
</details>
<details>
<summary>摘要</summary>
通用零例学习（GZSL）目标是将训练时见过的和未见过的标签分类，假设未见过的标签在训练过程中不可访问。Recent Advances in GZSL 被加速通过在生成网络中 incorporating 对准学习（例程）基于的嵌入，并利用数据点之间的semantic关系。然而，现有的嵌入架构受到两种限制：（1）不考虑细化类划结构， Synthetic features的嵌入不具有充分的推荐性;（2）现有对准学习网络的优化机制受限，导致嵌入空间中的表示不够强大。为了提高嵌入空间中表示质量，我们提出一种基于prototype的嵌入对照学习网络，该网络可以利用对象-数据（精细化表示）和隐式数据-数据（群体质量提高）的交互，同时为嵌入网络和生成器提供了重要的类型指导。此外，我们还提出了一种适应实例的对准损失，以提高对未见过标签的表示。通过全面的实验评估，我们显示了我们的方法可以在三个标准数据集上超越当前状态的艺术。我们的方法还一直保持了GZSL中最佳的未见表现。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-JPEG-The-Devil-is-in-the-Details"><a href="#Differentiable-JPEG-The-Devil-is-in-the-Details" class="headerlink" title="Differentiable JPEG: The Devil is in the Details"></a>Differentiable JPEG: The Devil is in the Details</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06978">http://arxiv.org/abs/2309.06978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/necla-ml/diff-jpeg">https://github.com/necla-ml/diff-jpeg</a></li>
<li>paper_authors: Christoph Reich, Biplob Debnath, Deep Patel, Srimat Chakradhar</li>
<li>for: 该论文旨在对现有的可微分JPEG方法进行全面的回顾，并将其中缺失的重要细节所涉及的问题作出解决。</li>
<li>methods: 该论文提出了一种新的可微分JPEG方法，该方法可以具有输入图像、JPEG质量、量化表和色彩转换参数的微分性。</li>
<li>results: 对于已有的diff. JPEG方法，该论文进行了forward和backward性的评估，并进行了广泛的ablation测试，以评估关键的设计选择。结果显示，该新的diff. JPEG方法可以距离参照实现最佳，在强大压缩率下可以提高PSNR值$9.51$dB。<details>
<summary>Abstract</summary>
JPEG remains one of the most widespread lossy image coding methods. However, the non-differentiable nature of JPEG restricts the application in deep learning pipelines. Several differentiable approximations of JPEG have recently been proposed to address this issue. This paper conducts a comprehensive review of existing diff. JPEG approaches and identifies critical details that have been missed by previous methods. To this end, we propose a novel diff. JPEG approach, overcoming previous limitations. Our approach is differentiable w.r.t. the input image, the JPEG quality, the quantization tables, and the color conversion parameters. We evaluate the forward and backward performance of our diff. JPEG approach against existing methods. Additionally, extensive ablations are performed to evaluate crucial design choices. Our proposed diff. JPEG resembles the (non-diff.) reference implementation best, significantly surpassing the recent-best diff. approach by $3.47$dB (PSNR) on average. For strong compression rates, we can even improve PSNR by $9.51$dB. Strong adversarial attack results are yielded by our diff. JPEG, demonstrating the effective gradient approximation. Our code is available at https://github.com/necla-ml/Diff-JPEG.
</details>
<details>
<summary>摘要</summary>
JPEG 仍然是最广泛的损失图像编码方法之一，但它的非微分性限制了它在深度学习管道中的应用。在过去几年中，一些微分 aproximation of JPEG 已经被提出来解决这个问题。本文进行了对现有 diff. JPEG 方法的全面回顾，并发现了以前的方法缺失的关键细节。为此，我们提出了一种新的 diff. JPEG 方法，超越了先前的限制。我们的方法是对输入图像、JPEG 质量、量化表和色彩转换参数进行微分。我们评估了我们的 diff. JPEG 方法的前向和反向性能，并对关键设计选择进行了广泛的ablations。我们的提出的 diff. JPEG 方法与（非微分）参考实现最接近，在 PSNR 上平均提高 $3.47$ dB，并在强大压缩率下提高 PSNR 的 $9.51$ dB。我们的 diff. JPEG 还能够通过强大的攻击测试，证明了有效的梯度近似。我们的代码可以在 https://github.com/necla-ml/Diff-JPEG 上获取。
</details></li>
</ul>
<hr>
<h2 id="Neural-network-based-coronary-dominance-classification-of-RCA-angiograms"><a href="#Neural-network-based-coronary-dominance-classification-of-RCA-angiograms" class="headerlink" title="Neural network-based coronary dominance classification of RCA angiograms"></a>Neural network-based coronary dominance classification of RCA angiograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06958">http://arxiv.org/abs/2309.06958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivan Kruzhilov, Egor Ikryannikov, Artem Shadrin, Ruslan Utegenov, Galina Zubkova, Ivan Bessonov</li>
<li>for: 这 paper 是为了研究基于右 coronary artery (RCA) 涂整图像的 cardiac dominance 分类算法。</li>
<li>methods: 这 paper 使用了 Convolutional Neural Network (ConvNext) 和 Swin transformer 进行 2D 图像 (frame) 分类，并使用多数投票来 классифициayer cardio angiographic view。 auxiliary network 也用于检测无关图像，并将其从数据集中排除。</li>
<li>results: 五次交叉验证给出了以下 dominance 分类指标：macro recall&#x3D;93.1%, accuracy&#x3D;93.5%, macro F1&#x3D;89.2%。模型通常在 RCA 堵塞和小径 combines with poor quality cardio angiographic view 的情况下失败。在这些情况下， cardiac dominance 分类可能会复杂，需要专家们之间的讨论以确定准确的结论。<details>
<summary>Abstract</summary>
Background. Cardiac dominance classification is essential for SYNTAX score estimation, which is a tool used to determine the complexity of coronary artery disease and guide patient selection toward optimal revascularization strategy. Objectives. Cardiac dominance classification algorithm based on the analysis of right coronary artery (RCA) angiograms using neural network Method. We employed convolutional neural network ConvNext and Swin transformer for 2D image (frames) classification, along with a majority vote for cardio angiographic view classification. An auxiliary network was also used to detect irrelevant images which were then excluded from the data set. Our data set consisted of 828 angiographic studies, 192 of them being patients with left dominance. Results. 5-fold cross validation gave the following dominance classification metrics (p=95%): macro recall=93.1%, accuracy=93.5%, macro F1=89.2%. The most common case in which the model regularly failed was RCA occlusion, as it requires utilization of LCA information. Another cause for false prediction is a small diameter combined with poor quality cardio angiographic view. In such cases, cardiac dominance classification can be complex and may require discussion among specialists to reach an accurate conclusion. Conclusion. The use of machine learning approaches to classify cardiac dominance based on RCA alone has been shown to be successful with satisfactory accuracy. However, for higher accuracy, it is necessary to utilize LCA information in the case of an occluded RCA and detect cases where there is high uncertainty.
</details>
<details>
<summary>摘要</summary>
背景：心脏主导分类是 SYNTAX 分数估计的关键因素，它用于评估心血管疾病的复杂度并选择患者最佳的再入力策略。目标：使用神经网络对右 coronary artery（RCA） angeiogram 进行分类。方法：我们使用 ConvNext 和 Swin transformer 对二维图像（帧）进行分类，并使用多数投票进行心血管视图分类。此外，我们还使用 auxilary network 检测不相关图像，并将其从数据集中排除。我们的数据集包括 828 个 angeiographic 研究，其中 192 个是左主导的患者。结果：5-fold 十字验证给出了以下主导分类指标（p=95%）：macro recall=93.1%、准确率=93.5%、macro F1=89.2%。模型经常错误的情况包括 RCA 填充和小 diameter combined with poor quality 心血管视图。在这些情况下，心脏主导分类可能是复杂的，需要专家之间的讨论以达到准确的结论。结论：使用机器学习方法来基于 RCA  alone 分类心脏主导成功，但是为了提高准确率，需要在 RCA 填充情况下使用 LCA 信息，并检测高不确定性的情况。
</details></li>
</ul>
<hr>
<h2 id="TransNet-A-Transfer-Learning-Based-Network-for-Human-Action-Recognition"><a href="#TransNet-A-Transfer-Learning-Based-Network-for-Human-Action-Recognition" class="headerlink" title="TransNet: A Transfer Learning-Based Network for Human Action Recognition"></a>TransNet: A Transfer Learning-Based Network for Human Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06951">http://arxiv.org/abs/2309.06951</a></li>
<li>repo_url: None</li>
<li>paper_authors: K. Alomar, X. Cai</li>
<li>for: 人体动作识别 (HAR) 是计算机视觉领域的高级和重要研究领域，它的应用场景广泛。</li>
<li>methods: 该文提出了一种简单 yet 多样和有效的深度学习架构，名为 TransNet，用于 HAR。TransNet 将复杂的 3D-CNN 拆分成 2D-CNN 和 1D-CNN，其中 2D-CNN 和 1D-CNN 组件分别提取视频中的空间特征和时间模式。</li>
<li>results: 对比于当前 HAR 模型，TransNet 具有更高的 fleксиibilty、模型复杂度、训练速度和分类精度。<details>
<summary>Abstract</summary>
Human action recognition (HAR) is a high-level and significant research area in computer vision due to its ubiquitous applications. The main limitations of the current HAR models are their complex structures and lengthy training time. In this paper, we propose a simple yet versatile and effective end-to-end deep learning architecture, coined as TransNet, for HAR. TransNet decomposes the complex 3D-CNNs into 2D- and 1D-CNNs, where the 2D- and 1D-CNN components extract spatial features and temporal patterns in videos, respectively. Benefiting from its concise architecture, TransNet is ideally compatible with any pretrained state-of-the-art 2D-CNN models in other fields, being transferred to serve the HAR task. In other words, it naturally leverages the power and success of transfer learning for HAR, bringing huge advantages in terms of efficiency and effectiveness. Extensive experimental results and the comparison with the state-of-the-art models demonstrate the superior performance of the proposed TransNet in HAR in terms of flexibility, model complexity, training speed and classification accuracy.
</details>
<details>
<summary>摘要</summary>
人体动作识别（HAR）是计算机视觉领域的高级和重要研究领域，因其广泛的应用领域。现有的HAR模型的主要限制是其复杂的结构和训练时间。在本文中，我们提出了一种简单却强大、有效的端到端深度学习架构，名为TransNet，用于HAR。TransNet将复杂的3D-CNN decomposed into 2D-和1D-CNN，其中2D-CNN和1D-CNN组件分别EXTRACT SPATIAL FEATURES AND TEMPORAL PATTERNS IN VIDEOS。由于TransNet的简洁架构，它可以 идеальcompatibility with any pre-trained state-of-the-art 2D-CNN models in other fields，可以 transferred to serve the HAR task。即，它自然地利用了转移学习的力量和成功， bringing huge advantages in terms of efficiency and effectiveness。经验证的结果和对状态 искусственныйINTelligence模型的比较表明，提议的TransNet在HAR中具有优秀的flexibility、模型复杂度、训练速度和分类精度。
</details></li>
</ul>
<hr>
<h2 id="Limited-Angle-Tomography-Reconstruction-via-Deep-End-To-End-Learning-on-Synthetic-Data"><a href="#Limited-Angle-Tomography-Reconstruction-via-Deep-End-To-End-Learning-on-Synthetic-Data" class="headerlink" title="Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data"></a>Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06948">http://arxiv.org/abs/2309.06948</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/99991/htc2022-tud-hhu-version-1">https://github.com/99991/htc2022-tud-hhu-version-1</a></li>
<li>paper_authors: Thomas Germer, Jan Robine, Sebastian Konietzny, Stefan Harmeling, Tobias Uelwer</li>
<li>for: 解决限角 Tomatoesography重建问题</li>
<li>methods: 使用深度神经网络，在大量合成数据上训练</li>
<li>results: 实现了30°或40°sinogram的 Tomatoesography重建，并在 Helsinki Tomography Challenge 2022 上获得了第一名<details>
<summary>Abstract</summary>
Computed tomography (CT) has become an essential part of modern science and medicine. A CT scanner consists of an X-ray source that is spun around an object of interest. On the opposite end of the X-ray source, a detector captures X-rays that are not absorbed by the object. The reconstruction of an image is a linear inverse problem, which is usually solved by filtered back projection. However, when the number of measurements is small, the reconstruction problem is ill-posed. This is for example the case when the X-ray source is not spun completely around the object, but rather irradiates the object only from a limited angle. To tackle this problem, we present a deep neural network that is trained on a large amount of carefully-crafted synthetic data and can perform limited-angle tomography reconstruction even for only 30{\deg} or 40{\deg} sinograms. With our approach we won the first place in the Helsinki Tomography Challenge 2022.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DreamStyler-Paint-by-Style-Inversion-with-Text-to-Image-Diffusion-Models"><a href="#DreamStyler-Paint-by-Style-Inversion-with-Text-to-Image-Diffusion-Models" class="headerlink" title="DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models"></a>DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06933">http://arxiv.org/abs/2309.06933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Namhyuk Ahn, Junsoo Lee, Chunggi Lee, Kunhee Kim, Daesik Kim, Seung-Hun Nam, Kibeom Hong</li>
<li>for: 这个研究旨在探讨大规模文本至图模型的进步，尤其是在艺术领域中的应用。</li>
<li>methods: 这篇论文提出了一个名为 DreamStyler 的新框架，用于艺术图像生成。DreamStyler 利用了多阶段文本嵌入，并且可以同时进行文本至图生成和类型转移。</li>
<li>results: 实验结果显示，DreamStyler 能够在多个场景中表现出色，包括文本描述和类型参考的情况下。这表明 DreamStyler 具有优秀的创作潜力。<details>
<summary>Abstract</summary>
Recent progresses in large-scale text-to-image models have yielded remarkable accomplishments, finding various applications in art domain. However, expressing unique characteristics of an artwork (e.g. brushwork, colortone, or composition) with text prompts alone may encounter limitations due to the inherent constraints of verbal description. To this end, we introduce DreamStyler, a novel framework designed for artistic image synthesis, proficient in both text-to-image synthesis and style transfer. DreamStyler optimizes a multi-stage textual embedding with a context-aware text prompt, resulting in prominent image quality. In addition, with content and style guidance, DreamStyler exhibits flexibility to accommodate a range of style references. Experimental results demonstrate its superior performance across multiple scenarios, suggesting its promising potential in artistic product creation.
</details>
<details>
<summary>摘要</summary>
近期大规模文本到图像模型的进步带来了非常出色的成果，在艺术领域找到了多种应用。然而，通过文本提示alone表达艺术作品的独特特征（如笔触、颜色气息或 композиitions）可能会遇到限制，因为文本描述的本质受到限制。为此，我们介绍 DreamStyler，一种新的框架，用于艺术图像生成，具有文本到图像生成和风格传递的能力。 DreamStyler 优化了多 Stage 文本嵌入，使用 Context-aware 文本提示，从而实现了显著的图像质量。另外，通过内容和风格引用， DreamStyler 具有柔性，可以满足不同风格引用的需求。实验结果表明其在多种场景中的超越性，表明它在艺术产品创作中具有普遍的潜力。
</details></li>
</ul>
<hr>
<h2 id="Contrast-Phys-Unsupervised-and-Weakly-supervised-Video-based-Remote-Physiological-Measurement-via-Spatiotemporal-Contrast"><a href="#Contrast-Phys-Unsupervised-and-Weakly-supervised-Video-based-Remote-Physiological-Measurement-via-Spatiotemporal-Contrast" class="headerlink" title="Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast"></a>Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06924">http://arxiv.org/abs/2309.06924</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaodong Sun, Xiaobai Li</li>
<li>for: 这个论文目的是提出一种无监督的远程生物物理测量方法，使用视频来测量血液含量信号。</li>
<li>methods: 这个方法使用3DCNN模型生成多个空间时间的血液含量信号，并采用了对比损失函数来捕捉血液含量信号的先验知识。</li>
<li>results: 这个方法在五个公共可用的数据集上进行了评估，并与现有的监督方法进行了比较。结果表明，无监督的contrast-Phys+方法可以超过现有的监督方法，即使使用部分可用或不一致的GT标签或无标签。此外，这个方法具有计算效率高、鲁棒性好、泛化能力强等优点。<details>
<summary>Abstract</summary>
Video-based remote physiological measurement utilizes facial videos to measure the blood volume change signal, which is also called remote photoplethysmography (rPPG). Supervised methods for rPPG measurements have been shown to achieve good performance. However, the drawback of these methods is that they require facial videos with ground truth (GT) physiological signals, which are often costly and difficult to obtain. In this paper, we propose Contrast-Phys+, a method that can be trained in both unsupervised and weakly-supervised settings. We employ a 3DCNN model to generate multiple spatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a contrastive loss function. We further incorporate the GT signals into contrastive learning to adapt to partial or misaligned labels. The contrastive loss encourages rPPG/GT signals from the same video to be grouped together, while pushing those from different videos apart. We evaluate our methods on five publicly available datasets that include both RGB and Near-infrared videos. Contrast-Phys+ outperforms the state-of-the-art supervised methods, even when using partially available or misaligned GT signals, or no labels at all. Additionally, we highlight the advantages of our methods in terms of computational efficiency, noise robustness, and generalization.
</details>
<details>
<summary>摘要</summary>
视频基于远程生物学量测量利用 faces 视频测量血液量变化信号，也称为远程 Plethysmography (rPPG)。已经展示过监督方法可以达到良好的性能。然而，这些方法需要 faces 视频中的GT 生物学信号，这些信号通常是 expensive 和困难获得的。在这篇论文中，我们提出了 Contrast-Phys+，一种可以在不监督和弱监督设置下训练的方法。我们使用 3DCNN 模型生成多个 spatiotemporal rPPG 信号，并将 rPPG 的先前知识 integrate 到一个对比损失函数中。我们进一步将 GT 信号 integrate 到对比学习中，以适应部分或错配置的标签。对比损失函数会将 rPPG/GT 信号从同一个视频集成一起，而推动它们来自不同视频的信号分离开。我们对五个公共可用的数据集进行评估，包括 RGB 和 Near-infrared 视频。Contrast-Phys+ 超过了当前最佳监督方法的性能，即使使用部分可用或错配置的 GT 标签，或没有标签。此外，我们还指出了我们的方法的计算效率、阈值鲁棒性和泛化优势。
</details></li>
</ul>
<hr>
<h2 id="Hydra-Multi-head-Low-rank-Adaptation-for-Parameter-Efficient-Fine-tuning"><a href="#Hydra-Multi-head-Low-rank-Adaptation-for-Parameter-Efficient-Fine-tuning" class="headerlink" title="Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning"></a>Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06922">http://arxiv.org/abs/2309.06922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanghyeon Kim, Hyunmo Yang, Younghyun Kim, Youngjoon Hong, Eunbyung Park</li>
<li>for: 本文旨在探讨一种基于平行和顺序分支的 adapter module，以提高大规模基础模型的精度和灵活性。</li>
<li>methods: 本文提出了一种名为 Hydra 的方法，该方法基于分支的分析，并结合平行和顺序分支来整合特性，从而提高了表达能力。此外，该方法还利用预训练权重，通过线性组合来提高预训练特征的泛化性。</li>
<li>results: 经过广泛的实验证明，Hydra 方法可以提高精度和灵活性，并且在多种应用中表现出优于单分支方法。 Code 可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/extremebird/Hydra%7D">https://github.com/extremebird/Hydra}</a> 上获取。<details>
<summary>Abstract</summary>
The recent surge in large-scale foundation models has spurred the development of efficient methods for adapting these models to various downstream tasks. Low-rank adaptation methods, such as LoRA, have gained significant attention due to their outstanding parameter efficiency and no additional inference latency. This paper investigates a more general form of adapter module based on the analysis that parallel and sequential adaptation branches learn novel and general features during fine-tuning, respectively. The proposed method, named Hydra, due to its multi-head computational branches, combines parallel and sequential branch to integrate capabilities, which is more expressive than existing single branch methods and enables the exploration of a broader range of optimal points in the fine-tuning process. In addition, the proposed adaptation method explicitly leverages the pre-trained weights by performing a linear combination of the pre-trained features. It allows the learned features to have better generalization performance across diverse downstream tasks. Furthermore, we perform a comprehensive analysis of the characteristics of each adaptation branch with empirical evidence. Through an extensive range of experiments, encompassing comparisons and ablation studies, we substantiate the efficiency and demonstrate the superior performance of Hydra. This comprehensive evaluation underscores the potential impact and effectiveness of Hydra in a variety of applications. Our code is available on \url{https://github.com/extremebird/Hydra}
</details>
<details>
<summary>摘要</summary>
Recent large-scale foundation models have led to the development of efficient methods for adapting these models to various downstream tasks. Low-rank adaptation methods, such as LoRA, have gained significant attention due to their outstanding parameter efficiency and no additional inference latency. This paper investigates a more general form of adapter module based on the analysis that parallel and sequential adaptation branches learn novel and general features during fine-tuning, respectively. The proposed method, named Hydra, due to its multi-head computational branches, combines parallel and sequential branches to integrate capabilities, which is more expressive than existing single branch methods and enables the exploration of a broader range of optimal points in the fine-tuning process. In addition, the proposed adaptation method explicitly leverages the pre-trained weights by performing a linear combination of the pre-trained features. It allows the learned features to have better generalization performance across diverse downstream tasks. Furthermore, we perform a comprehensive analysis of the characteristics of each adaptation branch with empirical evidence. Through an extensive range of experiments, encompassing comparisons and ablation studies, we substantiate the efficiency and demonstrate the superior performance of Hydra. This comprehensive evaluation underscores the potential impact and effectiveness of Hydra in a variety of applications. Our code is available on \url{https://github.com/extremebird/Hydra}.Note: Please note that the translation is in Simplified Chinese, and the word order and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="CCSPNet-Joint-Efficient-Joint-Training-Method-for-Traffic-Sign-Detection-Under-Extreme-Conditions"><a href="#CCSPNet-Joint-Efficient-Joint-Training-Method-for-Traffic-Sign-Detection-Under-Extreme-Conditions" class="headerlink" title="CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign Detection Under Extreme Conditions"></a>CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign Detection Under Extreme Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06902">http://arxiv.org/abs/2309.06902</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoqinhong/ccspnet-joint">https://github.com/haoqinhong/ccspnet-joint</a></li>
<li>paper_authors: Haoqin Hong, Yue Zhou, Xiangyu Shu, Xiangfang Hu</li>
<li>for:  traffic sign detection in extreme conditions such as fog, rain, and motion blur</li>
<li>methods:  CCSPNet, an efficient feature extraction module based on Transformers and CNNs, and joint training model CCSPNet-Joint</li>
<li>results:  state-of-the-art performance in traffic sign detection under extreme conditions, with a 5.32% improvement in precision and an 18.09% improvement in mAP@.5 compared to end-to-end methods<details>
<summary>Abstract</summary>
Traffic sign detection is an important research direction in intelligent driving. Unfortunately, existing methods often overlook extreme conditions such as fog, rain, and motion blur. Moreover, the end-to-end training strategy for image denoising and object detection models fails to utilize inter-model information effectively. To address these issues, we propose CCSPNet, an efficient feature extraction module based on Transformers and CNNs, which effectively leverages contextual information, achieves faster inference speed and provides stronger feature enhancement capabilities. Furthermore, we establish the correlation between object detection and image denoising tasks and propose a joint training model, CCSPNet-Joint, to improve data efficiency and generalization. Finally, to validate our approach, we create the CCTSDB-AUG dataset for traffic sign detection in extreme scenarios. Extensive experiments have shown that CCSPNet achieves state-of-the-art performance in traffic sign detection under extreme conditions. Compared to end-to-end methods, CCSPNet-Joint achieves a 5.32% improvement in precision and an 18.09% improvement in mAP@.5.
</details>
<details>
<summary>摘要</summary>
《交通标志检测是智能驾驶研究的重要方向。然而，现有方法经常忽略极端条件，如雾、雨和运动模糊。另外，末端培训策略对图像净化和物体检测模型的训练效果不够利用交互信息。为解决这些问题，我们提出了 CCSPNet，一种高效的特征提取模块，基于 Transformers 和 CNNs，可以有效利用上下文信息，实现更快的推理速度和更强的特征增强能力。此外，我们确立了对象检测和图像净化任务之间的相关性，并提出了一种共同培训模型 CCSPNet-Joint，以提高数据效率和泛化能力。最后，为证明我们的方法，我们创建了 CCTSDB-AUG 数据集，用于交通标志检测在极端情况下。广泛的实验表明，CCSPNet 在极端情况下的交通标志检测性能达到了当前最佳水平。相比于端到端方法，CCSPNet-Joint 在精度和 mAP@0.5 上具有5.32% 和18.09% 的提升。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="MagiCapture-High-Resolution-Multi-Concept-Portrait-Customization"><a href="#MagiCapture-High-Resolution-Multi-Concept-Portrait-Customization" class="headerlink" title="MagiCapture: High-Resolution Multi-Concept Portrait Customization"></a>MagiCapture: High-Resolution Multi-Concept Portrait Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06895">http://arxiv.org/abs/2309.06895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junha Hyung, Jaeyo Shin, Jaegul Choo</li>
<li>for: 这个论文旨在个性化大规模文本到图像模型，包括稳定扩散模型，以生成高品质人脸图像。</li>
<li>methods: 该论文提出了一种基于少量主题和风格引用图像的个性化方法，可以生成高分辨率人脸图像。它还使用了一种新的注意力重фокус损失函数和辅助约束，以便在弱监督学习环境下进行稳定的学习。</li>
<li>results: 根据论文的评估，MagiCapture方法可以在生成人脸图像时提供高品质的输出，并且可以普适化到其他非人类对象上。<details>
<summary>Abstract</summary>
Large-scale text-to-image models including Stable Diffusion are capable of generating high-fidelity photorealistic portrait images. There is an active research area dedicated to personalizing these models, aiming to synthesize specific subjects or styles using provided sets of reference images. However, despite the plausible results from these personalization methods, they tend to produce images that often fall short of realism and are not yet on a commercially viable level. This is particularly noticeable in portrait image generation, where any unnatural artifact in human faces is easily discernible due to our inherent human bias. To address this, we introduce MagiCapture, a personalization method for integrating subject and style concepts to generate high-resolution portrait images using just a few subject and style references. For instance, given a handful of random selfies, our fine-tuned model can generate high-quality portrait images in specific styles, such as passport or profile photos. The main challenge with this task is the absence of ground truth for the composed concepts, leading to a reduction in the quality of the final output and an identity shift of the source subject. To address these issues, we present a novel Attention Refocusing loss coupled with auxiliary priors, both of which facilitate robust learning within this weakly supervised learning setting. Our pipeline also includes additional post-processing steps to ensure the creation of highly realistic outputs. MagiCapture outperforms other baselines in both quantitative and qualitative evaluations and can also be generalized to other non-human objects.
</details>
<details>
<summary>摘要</summary>
大规模的文本到图像模型，包括稳定扩散，能够生成高效率的高分辨率人脸图像。有一个活跃的研究领域专门做个性化这些模型，以生成特定主题或风格使用提供的参考图像集。然而，尽管这些个性化方法可能会生成可信的结果，但它们通常会生成图像，它们的真实性不够，而且还没有商业化水平。这是特别明显在人脸图像生成中，因为人类对人脸的偏见会让任何不自然的artifact在人脸上容易被识别出来。为解决这个问题，我们介绍了MagiCapture，一种个性化方法，可以将主题和风格概念与高分辨率人脸图像相结合，只需要几张随机的自拍照片。例如，我们的精度调整后的模型可以生成高质量的人脸图像，以特定的风格，如护照照片或 Profil photo。主要挑战在这个任务中是缺乏compose的ground truth，导致最终输出质量下降和源主题的认同shift。为解决这些问题，我们提出了一种新的注意力重新定向损失，以及auxiliary priors，它们都可以在这种弱supervised learning Setting中Robust learning。我们的管道还包括额外的后处理步骤，以确保生成的输出非常真实。MagiCapture在量和质量上都超过了其他基elines，并且可以泛化到其他非人物对象。
</details></li>
</ul>
<hr>
<h2 id="Keep-It-SimPool-Who-Said-Supervised-Transformers-Suffer-from-Attention-Deficit"><a href="#Keep-It-SimPool-Who-Said-Supervised-Transformers-Suffer-from-Attention-Deficit" class="headerlink" title="Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?"></a>Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06891">http://arxiv.org/abs/2309.06891</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/billpsomas/simpool">https://github.com/billpsomas/simpool</a></li>
<li>paper_authors: Bill Psomas, Ioannis Kakogeorgiou, Konstantinos Karantzalos, Yannis Avrithis</li>
<li>for: This paper aims to improve the performance of both convolutional and transformer encoders by developing a generic pooling framework and proposing a simple attention-based pooling mechanism called SimPool.</li>
<li>methods: The paper uses a combination of theoretical analysis and experimental evaluation to compare the properties of different pooling methods and derive the SimPool mechanism. The authors also propose a simple attention mechanism that can be used as a replacement for the default pooling method in both convolutional and transformer encoders.</li>
<li>results: The paper shows that SimPool improves performance on pre-training and downstream tasks, and provides attention maps that delineate object boundaries in all cases, whether supervised or self-supervised. The authors claim that SimPool is “universal” because it can be used with any type of supervision or attention mechanism, and it provides attention maps of at least as good quality as self-supervised methods without explicit losses or modifying the architecture.<details>
<summary>Abstract</summary>
Convolutional networks and vision transformers have different forms of pairwise interactions, pooling across layers and pooling at the end of the network. Does the latter really need to be different? As a by-product of pooling, vision transformers provide spatial attention for free, but this is most often of low quality unless self-supervised, which is not well studied. Is supervision really the problem?   In this work, we develop a generic pooling framework and then we formulate a number of existing methods as instantiations. By discussing the properties of each group of methods, we derive SimPool, a simple attention-based pooling mechanism as a replacement of the default one for both convolutional and transformer encoders. We find that, whether supervised or self-supervised, this improves performance on pre-training and downstream tasks and provides attention maps delineating object boundaries in all cases. One could thus call SimPool universal. To our knowledge, we are the first to obtain attention maps in supervised transformers of at least as good quality as self-supervised, without explicit losses or modifying the architecture. Code at: https://github.com/billpsomas/simpool.
</details>
<details>
<summary>摘要</summary>
卷积网络和视transformer具有不同的对比交互方式，包括层内 Pooling 和网络结束处 Pooling。后者是否真的需要不同呢？作为对比 Pooling 的产物，视transformer提供了彩色注意力，但这通常是低质量的，除非自我超视，这并不是很好地研究。是超级视还是问题呢？在这项工作中，我们开发了一个通用的 Pooling 框架，然后将现有方法视为实体的实例。通过讨论每组方法的性质，我们 derivate SimPool，一种简单的注意力基于 Pooling 机制，用于替换 convolutional 和 transformer 编码器的默认 Pooling 机制。我们发现，无论是超级视还是自我超视，这种改进性能在预训练和下游任务中，并且提供了对象边界的注意力图。因此，可以称 SimPool 为通用的。据我们知道，我们是第一个在超级视中获得至少相当于自我超视的质量的注意力图， без эксплицит的损失或修改网络结构。代码可以在 GitHub 上找到：https://github.com/billpsomas/simpool。
</details></li>
</ul>
<hr>
<h2 id="Manufacturing-Quality-Control-with-Autoencoder-Based-Defect-Localization-and-Unsupervised-Class-Selection"><a href="#Manufacturing-Quality-Control-with-Autoencoder-Based-Defect-Localization-and-Unsupervised-Class-Selection" class="headerlink" title="Manufacturing Quality Control with Autoencoder-Based Defect Localization and Unsupervised Class Selection"></a>Manufacturing Quality Control with Autoencoder-Based Defect Localization and Unsupervised Class Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06884">http://arxiv.org/abs/2309.06884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Devang Mehta, Noah Klarmann</li>
<li>For: This paper aims to improve visual defect localization in manufacturing industries using a defect localizing autoencoder with unsupervised class selection.* Methods: The proposed method uses a pre-trained VGG-16 network to extract features, which are then clustered using k-means to select the most relevant classes of defects. The selected classes are augmented with natural wild textures to simulate artificial defects.* Results: The proposed method demonstrates effectiveness in improving defect detection in manufacturing industries, with precise and accurate localization of quality defects on melamine-faced boards for the furniture industry. Incorporating artificial defects into the training data shows significant potential for practical implementation in real-world quality control scenarios.Here’s the same information in Simplified Chinese text:* For: 这篇论文目标是通过使用杂化自动编码器来提高制造业中的视觉缺陷检测。* Methods: 提议的方法使用预训练的VGG-16网络提取特征，然后使用k-means归一化选择最相关的缺陷类。选择的缺陷类加以自然野生的文本涂抹来模拟人工缺陷。* Results: 提议的方法在制造业中显示出效果，能够准确地检测制造过程中的质量缺陷，并在家具行业中在批量生产中实现高精度的缺陷检测。将人工缺陷添加到训练数据中显示出了实际应用中的潜在优势。<details>
<summary>Abstract</summary>
Manufacturing industries require efficient and voluminous production of high-quality finished goods. In the context of Industry 4.0, visual anomaly detection poses an optimistic solution for automatically controlling product quality with high precision. Automation based on computer vision poses a promising solution to prevent bottlenecks at the product quality checkpoint. We considered recent advancements in machine learning to improve visual defect localization, but challenges persist in obtaining a balanced feature set and database of the wide variety of defects occurring in the production line. This paper proposes a defect localizing autoencoder with unsupervised class selection by clustering with k-means the features extracted from a pre-trained VGG-16 network. The selected classes of defects are augmented with natural wild textures to simulate artificial defects. The study demonstrates the effectiveness of the defect localizing autoencoder with unsupervised class selection for improving defect detection in manufacturing industries. The proposed methodology shows promising results with precise and accurate localization of quality defects on melamine-faced boards for the furniture industry. Incorporating artificial defects into the training data shows significant potential for practical implementation in real-world quality control scenarios.
</details>
<details>
<summary>摘要</summary>
制造业需要高效、大量生产高质量完成品。在第四代工业时代下，视觉异常检测提供了一个优秀的自动控制产品质量的解决方案。基于计算机视觉的自动化可以解决生产线上质量检查瓶颈。我们利用了最新的机器学习技术来提高视觉缺陷定位，但是面临着获得多样化缺陷库和平衡特征集的挑战。这篇论文提出了基于自动编码器的缺陷定位方法，通过归一化分解特征来自动选择缺陷类别。选择的缺陷类别会被人工添加自然的野生文本纹理，以模拟人工缺陷。研究表明，该方法在制造业中进行质量控制时具有高精度和准确的缺陷定位能力。通过在折射面板上使用人工添加的缺陷，研究表明了在实际应用中添加人工缺陷的可能性。
</details></li>
</ul>
<hr>
<h2 id="ProMap-Datasets-for-Product-Mapping-in-E-commerce"><a href="#ProMap-Datasets-for-Product-Mapping-in-E-commerce" class="headerlink" title="ProMap: Datasets for Product Mapping in E-commerce"></a>ProMap: Datasets for Product Mapping in E-commerce</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06882">http://arxiv.org/abs/2309.06882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kateřina Macková, Martin Pilát</li>
<li>for: 这两个 datasets 用于识别两个不同的电商平台上的同一款产品。</li>
<li>methods: 这两个 datasets 包括图像和文本描述产品特性，包括产品规格，使其成为识别产品的最佳数据集。</li>
<li>results: 这两个 datasets 提供了识别产品的 Golden Standard，可以填充现有数据集中的空白，并且可以用于训练和测试识别产品的机器学习算法。<details>
<summary>Abstract</summary>
The goal of product mapping is to decide, whether two listings from two different e-shops describe the same products. Existing datasets of matching and non-matching pairs of products, however, often suffer from incomplete product information or contain only very distant non-matching products. Therefore, while predictive models trained on these datasets achieve good results on them, in practice, they are unusable as they cannot distinguish very similar but non-matching pairs of products. This paper introduces two new datasets for product mapping: ProMapCz consisting of 1,495 Czech product pairs and ProMapEn consisting of 1,555 English product pairs of matching and non-matching products manually scraped from two pairs of e-shops. The datasets contain both images and textual descriptions of the products, including their specifications, making them one of the most complete datasets for product mapping. Additionally, the non-matching products were selected in two phases, creating two types of non-matches -- close non-matches and medium non-matches. Even the medium non-matches are pairs of products that are much more similar than non-matches in other datasets -- for example, they still need to have the same brand and similar name and price. After simple data preprocessing, several machine learning algorithms were trained on these and two the other datasets to demonstrate the complexity and completeness of ProMap datasets. ProMap datasets are presented as a golden standard for further research of product mapping filling the gaps in existing ones.
</details>
<details>
<summary>摘要</summary>
“产品映射的目标是判断两个不同电商平台上的两个产品是否相同。现有的匹配和不匹配产品集合经常受到产品信息不完整或只包含非常远的不匹配产品的影响，因此虽然使用这些数据集训练预测模型可以获得良好的结果，但在实际应用中无法分辨非常相似但不匹配的两个产品。这篇论文介绍了两个新的产品映射数据集：ProMapCz和ProMapEn，它们分别包含1,495个捷克产品对和1,555个英文产品对匹配和不匹配产品，通过手动从两个电商平台抽取。这两个数据集包含产品图像和文本描述，包括产品规格，使其成为目前最完整的产品映射数据集之一。此外，非匹配产品被选择了两个阶段，创造了两种非匹配类型：近似非匹配和中等非匹配。即使中等非匹配也比其他数据集中的非匹配产品更相似，例如它们仍需要具有相同品牌和类似名称和价格。经过简单的数据处理后，数据集被用于训练多种机器学习算法，以示ProMap数据集的复杂性和完整性。ProMap数据集被提出为未来产品映射研究的金标准，填补现有数据集的缺陷。”
</details></li>
</ul>
<hr>
<h2 id="Video-Infringement-Detection-via-Feature-Disentanglement-and-Mutual-Information-Maximization"><a href="#Video-Infringement-Detection-via-Feature-Disentanglement-and-Mutual-Information-Maximization" class="headerlink" title="Video Infringement Detection via Feature Disentanglement and Mutual Information Maximization"></a>Video Infringement Detection via Feature Disentanglement and Mutual Information Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06877">http://arxiv.org/abs/2309.06877</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yyyooooo/dmi">https://github.com/yyyooooo/dmi</a></li>
<li>paper_authors: Zhenguang Liu, Xinyang Yu, Ruili Wang, Shuai Ye, Zhe Ma, Jianfeng Dong, Sifeng He, Feng Qian, Xiaobo Zhang, Roger Zimmermann, Lei Yang</li>
<li>for: 本研究目的是提高视频权利侵犯检测的精度，以保护视频创作者的利益和积极性。</li>
<li>methods: 本研究提出了两种方法来解决问题：首先，提出了一种分解原始高维特征的方法，以分离出不相互重叠的子特征，从而 removing 繁殖信息；其次，在这些子特征之上，进一步学习一种辅助特征以增强子特征。</li>
<li>results: 实验结果表明，我们的方法在两个大规模的数据集（SVD 和 VCSL）上达到了 90.1% TOP-100 mAP 和新的状态之最在 VCSL 数据集上。我们的代码和模型已经在 GitHub 上公开（<a target="_blank" rel="noopener" href="https://github.com/yyyooooo/DMI/%EF%BC%89%EF%BC%8C%E5%B8%8C%E6%9C%9B%E8%83%BD%E4%B8%BA%E7%A4%BE%E5%8C%BA%E4%BD%9C%E5%87%BA%E8%B4%A1%E7%8C%AE%E3%80%82">https://github.com/yyyooooo/DMI/），希望能为社区作出贡献。</a><details>
<summary>Abstract</summary>
The self-media era provides us tremendous high quality videos. Unfortunately, frequent video copyright infringements are now seriously damaging the interests and enthusiasm of video creators. Identifying infringing videos is therefore a compelling task. Current state-of-the-art methods tend to simply feed high-dimensional mixed video features into deep neural networks and count on the networks to extract useful representations. Despite its simplicity, this paradigm heavily relies on the original entangled features and lacks constraints guaranteeing that useful task-relevant semantics are extracted from the features.   In this paper, we seek to tackle the above challenges from two aspects: (1) We propose to disentangle an original high-dimensional feature into multiple sub-features, explicitly disentangling the feature into exclusive lower-dimensional components. We expect the sub-features to encode non-overlapping semantics of the original feature and remove redundant information.   (2) On top of the disentangled sub-features, we further learn an auxiliary feature to enhance the sub-features. We theoretically analyzed the mutual information between the label and the disentangled features, arriving at a loss that maximizes the extraction of task-relevant information from the original feature.   Extensive experiments on two large-scale benchmark datasets (i.e., SVD and VCSL) demonstrate that our method achieves 90.1% TOP-100 mAP on the large-scale SVD dataset and also sets the new state-of-the-art on the VCSL benchmark dataset. Our code and model have been released at https://github.com/yyyooooo/DMI/, hoping to contribute to the community.
</details>
<details>
<summary>摘要</summary>
自媒体时代为我们提供了巨大的高质量视频。然而，视频版权侵犯问题现在严重地危害着视频创作者的利益和积极性。正确识别侵犯视频是一项急需要解决的问题。目前的状态艺术方法通常是将高维混合视频特征 feed 到深度神经网络中，希望神经网络可以从特征中提取有用的表示。虽然这种方法简单，但它依 heavily 靠原始杂合的特征，缺乏约束，使得神经网络可能无法提取有用的任务相关的semantic。在这篇论文中，我们尝试解决以上挑战的两个方面：1. 我们提议将原始高维特征分解成多个子特征，明确地分解特征，将每个子特征编码为独立的低维Component。我们预期子特征会含有非重叠的semantic，从而消除 redundancy 信息。2. 在子特征的基础上，我们进一步学习一个辅助特征，以增强子特征。我们 theoretically 分析了标签和分解特征之间的共 informations，得到一个损失函数，以便提取任务相关的信息。我们在两个大规模的 benchmark 数据集（即 SVD 和 VCSL）上进行了广泛的实验，结果显示，我们的方法在大规模 SVD 数据集上达到了 90.1% TOP-100 mAP，并在 VCSL 数据集上设置了新的 state-of-the-art。我们的代码和模型已经在 GitHub 上发布，希望能为社区作出贡献。
</details></li>
</ul>
<hr>
<h2 id="UniBrain-Universal-Brain-MRI-Diagnosis-with-Hierarchical-Knowledge-enhanced-Pre-training"><a href="#UniBrain-Universal-Brain-MRI-Diagnosis-with-Hierarchical-Knowledge-enhanced-Pre-training" class="headerlink" title="UniBrain: Universal Brain MRI Diagnosis with Hierarchical Knowledge-enhanced Pre-training"></a>UniBrain: Universal Brain MRI Diagnosis with Hierarchical Knowledge-enhanced Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06828">http://arxiv.org/abs/2309.06828</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ljy19970415/unibrain">https://github.com/ljy19970415/unibrain</a></li>
<li>paper_authors: Jiayu Lei, Lisong Dai, Haoyun Jiang, Chaoyi Wu, Xiaoman Zhang, Yao Zhang, Jiangchao Yao, Weidi Xie, Yanyong Zhang, Yuehua Li, Ya Zhang, Yanfeng Wang</li>
<li>for: 这个研究旨在提出一种基于大规模数据的高效级别诊断方法，以提高脑病诊断的准确性和效率。</li>
<li>methods: 该方法提出了一种层次知识强化预训练框架，称为UniBrain，该框架利用了24,770个成像报告对的大规模数据集，并采用了层次对齐机制，以强化特征学习效率。</li>
<li>results: 该方法在三个实际世界数据集和BraTS2019数据集上进行验证，与所有现有诊断方法相比，具有显著的超越性和优异表现，并与专业医生在某些疾病类型上的表现相当。<details>
<summary>Abstract</summary>
Magnetic resonance imaging~(MRI) have played a crucial role in brain disease diagnosis, with which a range of computer-aided artificial intelligence methods have been proposed. However, the early explorations usually focus on the limited types of brain diseases in one study and train the model on the data in a small scale, yielding the bottleneck of generalization. Towards a more effective and scalable paradigm, we propose a hierarchical knowledge-enhanced pre-training framework for the universal brain MRI diagnosis, termed as UniBrain. Specifically, UniBrain leverages a large-scale dataset of 24,770 imaging-report pairs from routine diagnostics. Different from previous pre-training techniques for the unitary vision or textual feature, or with the brute-force alignment between vision and language information, we leverage the unique characteristic of report information in different granularity to build a hierarchical alignment mechanism, which strengthens the efficiency in feature learning. Our UniBrain is validated on three real world datasets with severe class imbalance and the public BraTS2019 dataset. It not only consistently outperforms all state-of-the-art diagnostic methods by a large margin and provides a superior grounding performance but also shows comparable performance compared to expert radiologists on certain disease types.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Topology-inspired-Cross-domain-Network-for-Developmental-Cervical-Stenosis-Quantification"><a href="#Topology-inspired-Cross-domain-Network-for-Developmental-Cervical-Stenosis-Quantification" class="headerlink" title="Topology-inspired Cross-domain Network for Developmental Cervical Stenosis Quantification"></a>Topology-inspired Cross-domain Network for Developmental Cervical Stenosis Quantification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06825">http://arxiv.org/abs/2309.06825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenxi Zhang, Yanyang Wang, Yao Wu, Weifei Wu</li>
<li>for: 验证 Developmental Canal Stenosis (DCS) 的数量是否正确，以便检测颈椎病变。</li>
<li>methods: 使用深度关键点本地化网络，并在坐标空间和图像空间进行交叉领域协调，以提高数量的准确性和效率。</li>
<li>results: 提出了一种名为 Topology-inspired Cross-domain Network (TCN) 的方法，可以更好地解决骨架图像中的弯曲和缺失关系问题，并提高了数量的准确性和生成性。<details>
<summary>Abstract</summary>
Developmental Canal Stenosis (DCS) quantification is crucial in cervical spondylosis screening. Compared with quantifying DCS manually, a more efficient and time-saving manner is provided by deep keypoint localization networks, which can be implemented in either the coordinate or the image domain. However, the vertebral visualization features often lead to abnormal topological structures during keypoint localization, including keypoint distortion with edges and weakly connected structures, which cannot be fully suppressed in either the coordinate or image domain alone. To overcome this limitation, a keypoint-edge and a reparameterization modules are utilized to restrict these abnormal structures in a cross-domain manner. The keypoint-edge constraint module restricts the keypoints on the edges of vertebrae, which ensures that the distribution pattern of keypoint coordinates is consistent with those for DCS quantification. And the reparameterization module constrains the weakly connected structures in image-domain heatmaps with coordinates combined. Moreover, the cross-domain network improves spatial generalization by utilizing heatmaps and incorporating coordinates for accurate localization, which avoids the trade-off between these two properties in an individual domain. Comprehensive results of distinct quantification tasks show the superiority and generability of the proposed Topology-inspired Cross-domain Network (TCN) compared with other competing localization methods.
</details>
<details>
<summary>摘要</summary>
发展颈部狭窄（DCS）的量化是颈部硬化检测中非常重要。相比手动量化DCS，深度关键点本地化网络可以提供更高效和时间换算的方式。然而， vertebral 视觉特征经常导致关键点本地化过程中的异常拓扑结构，包括关键点扭曲、边缘和弱连接结构，这些结构不能在坐标或图像领域独立地完全抑制。为了解决这个限制，我们提出了关键点-边缘约束模块和重parameter化模块。关键点-边缘约束模块使得关键点在颈椎边缘上分布均匀，从而确保DCS量化中的分布模式与实际相符。而重parameter化模块在图像领域的热图上使用坐标combined进行弱连接结构的约束，从而避免了坐标领域和图像领域之间的负面相互作用。此外，交叉领域网络可以提高空间总化的性能，通过使用热图和坐标进行准确的本地化，从而避免了坐标领域和图像领域之间的负面相互作用。对于不同的量化任务，我们的提案的Topology-inspired Cross-domain Network（TCN）在与其他竞争方法相比显示出了超越性和可重用性。
</details></li>
</ul>
<hr>
<h2 id="Tracking-Particles-Ejected-From-Active-Asteroid-Bennu-With-Event-Based-Vision"><a href="#Tracking-Particles-Ejected-From-Active-Asteroid-Bennu-With-Event-Based-Vision" class="headerlink" title="Tracking Particles Ejected From Active Asteroid Bennu With Event-Based Vision"></a>Tracking Particles Ejected From Active Asteroid Bennu With Event-Based Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06819">http://arxiv.org/abs/2309.06819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Loïc J. Azzalini, Dario Izzo</li>
<li>for: 预测和跟踪小行星系统中的喷发物，以保证航天器安全和科学观测。</li>
<li>methods: 使用事件驱动的相机检测和跟踪几厘米大的粒子，而不是使用标准帧驱动的相机。</li>
<li>results: 可以提高类似时间紧Constrained任务的科学返回，并且可以补充现有航天器上的影像技术。<details>
<summary>Abstract</summary>
Early detection and tracking of ejecta in the vicinity of small solar system bodies is crucial to guarantee spacecraft safety and support scientific observation. During the visit of active asteroid Bennu, the OSIRIS-REx spacecraft relied on the analysis of images captured by onboard navigation cameras to detect particle ejection events, which ultimately became one of the mission's scientific highlights. To increase the scientific return of similar time-constrained missions, this work proposes an event-based solution that is dedicated to the detection and tracking of centimetre-sized particles. Unlike a standard frame-based camera, the pixels of an event-based camera independently trigger events indicating whether the scene brightness has increased or decreased at that time and location in the sensor plane. As a result of the sparse and asynchronous spatiotemporal output, event cameras combine very high dynamic range and temporal resolution with low-power consumption, which could complement existing onboard imaging techniques. This paper motivates the use of a scientific event camera by reconstructing the particle ejection episodes reported by the OSIRIS-REx mission in a photorealistic scene generator and in turn, simulating event-based observations. The resulting streams of spatiotemporal data support future work on event-based multi-object tracking.
</details>
<details>
<summary>摘要</summary>
早期探测和跟踪小行星附近喷发物是保证航天器安全和支持科学观测的关键。在活跃小行星奥塞里斯-雷克号航天器探测中，使用摄像头捕捉的图像进行分析以探测喷发物事件，最终成为任务的科学焦点之一。为了增加类似时间紧张任务的科学返回，本文提出了事件基于解决方案，专门用于探测和跟踪厘米级喷发物。不同于标准帧基式摄像头，事件基本摄像头的像素独立触发事件，表示抽象场景的明亮度在感知平面上增加或减少。由于事件摄像头的稀疏和 asynchronous 的特点，它们可以同时实现高动态范围和低功耗消耗，这将与现有航天器上的摄像头技术相结合，以提高任务的科学返回。本文驱动使用科学事件摄像头的使用，通过重建奥塞里斯-雷克号任务报道的喷发物 episodess 在一个实时生成的光学场景生成器中进行重建，并在转换为事件基本的探测方式下，生成喷发物跟踪数据。这些数据将支持未来的事件基本多 объек跟踪工作。
</details></li>
</ul>
<hr>
<h2 id="TAP-Targeted-Prompting-for-Task-Adaptive-Generation-of-Textual-Training-Instances-for-Visual-Classification"><a href="#TAP-Targeted-Prompting-for-Task-Adaptive-Generation-of-Textual-Training-Instances-for-Visual-Classification" class="headerlink" title="TAP: Targeted Prompting for Task Adaptive Generation of Textual Training Instances for Visual Classification"></a>TAP: Targeted Prompting for Task Adaptive Generation of Textual Training Instances for Visual Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06809">http://arxiv.org/abs/2309.06809</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Jehanzeb Mirza, Leonid Karlinsky, Wei Lin, Horst Possegger, Rogerio Feris, Horst Bischof</li>
<li>for: 本研究旨在提高CLIP等视觉语言模型（VLM）的视觉识别性能，使其能够更好地适应下游任务的数据分布。</li>
<li>methods: 本研究使用文本生成模型（LLM）生成的文本数据进行VLM的单向training，以提高其视觉识别性能。</li>
<li>results: 比对基eline的文本只VLM训练方法，本研究在特定任务下的适应性能提高至8.4%，细致识别性能提高至8.7%，零shot分类性能提高3.1%。<details>
<summary>Abstract</summary>
Vision and Language Models (VLMs), such as CLIP, have enabled visual recognition of a potentially unlimited set of categories described by text prompts. However, for the best visual recognition performance, these models still require tuning to better fit the data distributions of the downstream tasks, in order to overcome the domain shift from the web-based pre-training data. Recently, it has been shown that it is possible to effectively tune VLMs without any paired data, and in particular to effectively improve VLMs visual recognition performance using text-only training data generated by Large Language Models (LLMs). In this paper, we dive deeper into this exciting text-only VLM training approach and explore ways it can be significantly further improved taking the specifics of the downstream task into account when sampling text data from LLMs. In particular, compared to the SOTA text-only VLM training approach, we demonstrate up to 8.4% performance improvement in (cross) domain-specific adaptation, up to 8.7% improvement in fine-grained recognition, and 3.1% overall average improvement in zero-shot classification compared to strong baselines.
</details>
<details>
<summary>摘要</summary>
视力和语言模型（VLM），如CLIP，已经实现了基于文本提示的可 COUNT 类别视觉识别。然而，为了 achieve the best 视觉识别性能，这些模型仍需要调整，以适应下游任务的数据分布，并且 overcome the domain shift from the web-based pre-training data。最近，有人提出了不需要对数据进行对应的 Training 可以有效地调整 VLM 的 Visual Recognition 性能。在这篇论文中，我们会 deeper 探究这种 Text-only VLM 训练方法，并 explore 如何通过在 LLMs 生成的文本数据中采样来进一步提高 VLM 的 Visual Recognition 性能。特别是，Compared to the SOTA text-only VLM training approach，我们示出了在 Cross-domain 适应、细化识别和 zero-shot 分类中的 Performance Improvement。Here's the breakdown of the translation:* "Visual recognition" is translated as "视觉识别" (wēi jǐng zhì bèi)* "VLM" is translated as "视力和语言模型" (wēi jǐng yǔ yán yǔ mó delè)* "pre-training data" is translated as "预训练数据" (xiāng xù xíng xì)* "domain shift" is translated as "领域转移" (diàn yì zhī yì)* "downstream tasks" is translated as "下游任务" (xià yòu jìn yè)* "text-only training" is translated as "文本Only 训练" (wén tiě only xù xì)* "LLMs" is translated as "大语言模型" (dà yǔ yán mó delè)* "fine-grained recognition" is translated as "细化识别" (xì huà zhì bèi)* "zero-shot classification" is translated as "zero-shot 分类" (zhì shòu bìng lè)* "SOTA" is translated as "state-of-the-art" (zhì yì jīn yì)Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-NeRFs-for-Soccer-Scenes"><a href="#Dynamic-NeRFs-for-Soccer-Scenes" class="headerlink" title="Dynamic NeRFs for Soccer Scenes"></a>Dynamic NeRFs for Soccer Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06802">http://arxiv.org/abs/2309.06802</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iSach/SoccerNeRFs">https://github.com/iSach/SoccerNeRFs</a></li>
<li>paper_authors: Sacha Lewin, Maxime Vandegar, Thomas Hoyoux, Olivier Barnich, Gilles Louppe</li>
<li>for: 本研究旨在解决长期困扰 novel view synthesis 领域的问题，具体来说是为 sports broadcasting 领域提供高质量的 synthetic replay。</li>
<li>methods: 本研究使用 neural radiance fields (NeRFs) 技术来解决这个问题，NeRFs 是一种基于深度学习的方法，可以生成高品质的视觉效果。</li>
<li>results: 研究表明，使用 NeRFs 技术可以在 soccer 场景中重构场景，但是这种方法无法完全满足 target 应用的质量要求。然而，这种方法仍然表现出了扎实的推动力，并且开发出了一个可用的 dataset 和代码。<details>
<summary>Abstract</summary>
The long-standing problem of novel view synthesis has many applications, notably in sports broadcasting. Photorealistic novel view synthesis of soccer actions, in particular, is of enormous interest to the broadcast industry. Yet only a few industrial solutions have been proposed, and even fewer that achieve near-broadcast quality of the synthetic replays. Except for their setup of multiple static cameras around the playfield, the best proprietary systems disclose close to no information about their inner workings. Leveraging multiple static cameras for such a task indeed presents a challenge rarely tackled in the literature, for a lack of public datasets: the reconstruction of a large-scale, mostly static environment, with small, fast-moving elements. Recently, the emergence of neural radiance fields has induced stunning progress in many novel view synthesis applications, leveraging deep learning principles to produce photorealistic results in the most challenging settings. In this work, we investigate the feasibility of basing a solution to the task on dynamic NeRFs, i.e., neural models purposed to reconstruct general dynamic content. We compose synthetic soccer environments and conduct multiple experiments using them, identifying key components that help reconstruct soccer scenes with dynamic NeRFs. We show that, although this approach cannot fully meet the quality requirements for the target application, it suggests promising avenues toward a cost-efficient, automatic solution. We also make our work dataset and code publicly available, with the goal to encourage further efforts from the research community on the task of novel view synthesis for dynamic soccer scenes. For code, data, and video results, please see https://soccernerfs.isach.be.
</details>
<details>
<summary>摘要</summary>
长期存在的新视图合成问题具有广泛的应用，特别是在体育直播中。高品质的新视图合成 Soccer 动作非常有价值于广播业。然而，只有一些商业解决方案被提出，而且它们几乎不公开自己的内部工作原理。使用多个静止摄像头环绕场地的设置是最佳的商业系统的一个挑战，因为它们几乎从来没有在文献中被探讨。Recently, the emergence of neural radiance fields has made significant progress in many novel view synthesis applications, using deep learning principles to produce photorealistic results in the most challenging settings. In this work, we investigate the feasibility of basing a solution to the task on dynamic NeRFs, i.e., neural models purposed to reconstruct general dynamic content. We create synthetic soccer environments and conduct multiple experiments using them, identifying key components that help reconstruct soccer scenes with dynamic NeRFs. We show that, although this approach cannot fully meet the quality requirements for the target application, it suggests promising avenues toward a cost-efficient, automatic solution. We also make our work dataset and code publicly available, with the goal to encourage further efforts from the research community on the task of novel view synthesis for dynamic soccer scenes. For code, data, and video results, please see <https://soccernerfs.isach.be>.
</details></li>
</ul>
<hr>
<h2 id="Motion-Bias-Free-Feature-Based-SLAM"><a href="#Motion-Bias-Free-Feature-Based-SLAM" class="headerlink" title="Motion-Bias-Free Feature-Based SLAM"></a>Motion-Bias-Free Feature-Based SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06792">http://arxiv.org/abs/2309.06792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alejandro Fontan, Javier Civera, Michael Milford</li>
<li>for: 提高 SLAM 在未知环境中安全部署，需要具备一些关键性能，而现有的标准测试不能完全覆盖这些性能。</li>
<li>methods: 本文提出了一些改进 feature-based SLAM 管道，以解决前后方向行程偏好问题。</li>
<li>results: 在四个数据集的完整评估中，我们的改进约束 Significantly 减少了前后方向行程偏好问题，同时改进了总轨迹误差。  elimination of SLAM motion bias has significant relevance for a wide range of robotics and computer vision applications where performance consistency is important.<details>
<summary>Abstract</summary>
For SLAM to be safely deployed in unstructured real world environments, it must possess several key properties that are not encompassed by conventional benchmarks. In this paper we show that SLAM commutativity, that is, consistency in trajectory estimates on forward and reverse traverses of the same route, is a significant issue for the state of the art. Current pipelines show a significant bias between forward and reverse directions of travel, that is in addition inconsistent regarding which direction of travel exhibits better performance. In this paper we propose several contributions to feature-based SLAM pipelines that remedies the motion bias problem. In a comprehensive evaluation across four datasets, we show that our contributions implemented in ORB-SLAM2 substantially reduce the bias between forward and backward motion and additionally improve the aggregated trajectory error. Removing the SLAM motion bias has significant relevance for the wide range of robotics and computer vision applications where performance consistency is important.
</details>
<details>
<summary>摘要</summary>
为了安全地部署SLAM在无结构环境中，它必须具备一些关键的特性，这些特性不包括传统测试准则。在这篇论文中，我们表明SLAM commutativity，即在前进和返回两个相同路径上的轨迹估计的一致性，是当前状态的主要问题。当前的管道显示了前进和返回两个方向的旅行中存在显著的偏好，并且这种偏好不一致地适用于哪一个方向的性能更好。在这篇论文中，我们提出了一些对feature-based SLAM管道的贡献，以解决运动偏好问题。在四个数据集的完整评估中，我们表明我们的贡献在ORB-SLAM2中实现了显著减少前进和返回运动之间的偏好，并且改善总轨迹错误。从除掉SLAM运动偏好来看，这种改进具有广泛的 роботех和计算机视觉应用中的重要性，其中性能一致性是关键的。
</details></li>
</ul>
<hr>
<h2 id="Remote-Sensing-Object-Detection-Meets-Deep-Learning-A-Meta-review-of-Challenges-and-Advances"><a href="#Remote-Sensing-Object-Detection-Meets-Deep-Learning-A-Meta-review-of-Challenges-and-Advances" class="headerlink" title="Remote Sensing Object Detection Meets Deep Learning: A Meta-review of Challenges and Advances"></a>Remote Sensing Object Detection Meets Deep Learning: A Meta-review of Challenges and Advances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06751">http://arxiv.org/abs/2309.06751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangrong Zhang, Tianyang Zhang, Guanchun Wang, Peng Zhu, Xu Tang, Xiuping Jia, Licheng Jiao</li>
<li>for: 本文提供了一项涵盖 latest achievements in deep learning based remote sensing object detection (RSOD) 技术的 comprehensive 评论。</li>
<li>methods: 文章系统地介绍了 RSOD 领域中的五大挑战，并对它们的应用进行了分层分类。</li>
<li>results: 文章评论了 widely used 的 benchmark datasets 和评价指标，以及 RSOD 在不同应用场景中的应用。<details>
<summary>Abstract</summary>
Remote sensing object detection (RSOD), one of the most fundamental and challenging tasks in the remote sensing field, has received longstanding attention. In recent years, deep learning techniques have demonstrated robust feature representation capabilities and led to a big leap in the development of RSOD techniques. In this era of rapid technical evolution, this review aims to present a comprehensive review of the recent achievements in deep learning based RSOD methods. More than 300 papers are covered in this review. We identify five main challenges in RSOD, including multi-scale object detection, rotated object detection, weak object detection, tiny object detection, and object detection with limited supervision, and systematically review the corresponding methods developed in a hierarchical division manner. We also review the widely used benchmark datasets and evaluation metrics within the field of RSOD, as well as the application scenarios for RSOD. Future research directions are provided for further promoting the research in RSOD.
</details>
<details>
<summary>摘要</summary>
遥感对象检测（RSOD）是遥感领域中最基本和最具挑战性的任务之一，在最近几年内得到了长期的关注。在技术不断发展的今天，深度学习技术的特点强大的特征表示能力，对RSOD技术的发展带来了很大的进步。本文是遥感领域中最新的RSOD技术发展的全面回顾，涵盖了超过300篇论文。我们在这篇文章中分析了RSOD中的5个主要挑战，即多尺度对象检测、旋转对象检测、弱对象检测、小对象检测和有限监督对象检测，并在一个层次分区的方式中系统地介绍了相应的方法。此外，我们还评估了在RSOD领域中最常用的评价指标和数据集，以及RSOD的应用场景。最后，我们还提供了未来研究方向，以便进一步推动RSOD领域的研究。
</details></li>
</ul>
<hr>
<h2 id="MFL-YOLO-An-Object-Detection-Model-for-Damaged-Traffic-Signs"><a href="#MFL-YOLO-An-Object-Detection-Model-for-Damaged-Traffic-Signs" class="headerlink" title="MFL-YOLO: An Object Detection Model for Damaged Traffic Signs"></a>MFL-YOLO: An Object Detection Model for Damaged Traffic Signs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06750">http://arxiv.org/abs/2309.06750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tengyang Chen, Jiangtao Ren</li>
<li>for: 这个论文的目的是提出一种基于YOLOv5s的改进对象检测方法，以检测损坏的交通标志。</li>
<li>methods: 该方法使用了一种简单的跨层损失函数，使模型在不同层次有不同的角色，从而学习更多的多样性特征。此外，模型还使用了GSConv和VoVGSCSP instead of traditional convolution and CSP。</li>
<li>results: 相比YOLOv5s，我们的MFL-YOLO方法在F1分数和mAP上提高4.3和5.1，同时降低了FLOPs的计算量 by 8.9%。在CCTSDB2021和TT100K上进行了进一步的验证，以证明我们的模型具有更好的泛化能力。<details>
<summary>Abstract</summary>
Traffic signs are important facilities to ensure traffic safety and smooth flow, but may be damaged due to many reasons, which poses a great safety hazard. Therefore, it is important to study a method to detect damaged traffic signs. Existing object detection techniques for damaged traffic signs are still absent. Since damaged traffic signs are closer in appearance to normal ones, it is difficult to capture the detailed local damage features of damaged traffic signs using traditional object detection methods. In this paper, we propose an improved object detection method based on YOLOv5s, namely MFL-YOLO (Mutual Feature Levels Loss enhanced YOLO). We designed a simple cross-level loss function so that each level of the model has its own role, which is beneficial for the model to be able to learn more diverse features and improve the fine granularity. The method can be applied as a plug-and-play module and it does not increase the structural complexity or the computational complexity while improving the accuracy. We also replaced the traditional convolution and CSP with the GSConv and VoVGSCSP in the neck of YOLOv5s to reduce the scale and computational complexity. Compared with YOLOv5s, our MFL-YOLO improves 4.3 and 5.1 in F1 scores and mAP, while reducing the FLOPs by 8.9%. The Grad-CAM heat map visualization shows that our model can better focus on the local details of the damaged traffic signs. In addition, we also conducted experiments on CCTSDB2021 and TT100K to further validate the generalization of our model.
</details>
<details>
<summary>摘要</summary>
交通标志是重要的安全设施，可以确保交通顺畅，但可能因多种原因受损，带来安全隐患。因此，研究一种检测受损交通标志的方法非常重要。现有的交通标志检测技术尚不存在。因为受损交通标志与正常的交通标志相似，使用传统的对象检测方法难以捕捉受损交通标志的详细地方特征。在这篇论文中，我们提出了一种改进的对象检测方法基于YOLOv5s，即MFL-YOLO（多级特征水平损失增强YOLO）。我们设计了一个简单的跨级损失函数，使得每级模型都有自己的角色，有助于模型学习更多的多样性特征，提高细腻度。这种方法可以作为插件模块使用，不增加结构复杂度或计算复杂度，同时提高准确率。我们还将传统的卷积和CSP替换为GSConv和VoVGSCSP，从颈部处理YOLOv5s来减少缩放和计算复杂度。与YOLOv5s相比，我们的MFL-YOLO提高了4.3和5.1的F1分数和MAP，同时降低了FLOPs的8.9%。Grad-CAM热力映射视觉化表示，我们的模型更好地关注受损交通标志的地方特征。此外，我们还进行了CCTSDB2021和TT100K的实验，以验证我们的模型的通用性。
</details></li>
</ul>
<hr>
<h2 id="Integrating-GAN-and-Texture-Synthesis-for-Enhanced-Road-Damage-Detection"><a href="#Integrating-GAN-and-Texture-Synthesis-for-Enhanced-Road-Damage-Detection" class="headerlink" title="Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection"></a>Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06747">http://arxiv.org/abs/2309.06747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tengyang Chen, Jiangtao Ren</li>
<li>for: 提高道路破坏检测精度，以保障安全驾驶和 prolong road durability</li>
<li>methods: 使用生成对抗网络生成多种形态的道路破坏，并利用文本合成技术提取道路xture，以控制破坏严重程度</li>
<li>results: 提高了4.1%的mAP和4.5%的F1-score<details>
<summary>Abstract</summary>
In the domain of traffic safety and road maintenance, precise detection of road damage is crucial for ensuring safe driving and prolonging road durability. However, current methods often fall short due to limited data. Prior attempts have used Generative Adversarial Networks to generate damage with diverse shapes and manually integrate it into appropriate positions. However, the problem has not been well explored and is faced with two challenges. First, they only enrich the location and shape of damage while neglect the diversity of severity levels, and the realism still needs further improvement. Second, they require a significant amount of manual effort. To address these challenges, we propose an innovative approach. In addition to using GAN to generate damage with various shapes, we further employ texture synthesis techniques to extract road textures. These two elements are then mixed with different weights, allowing us to control the severity of the synthesized damage, which are then embedded back into the original images via Poisson blending. Our method ensures both richness of damage severity and a better alignment with the background. To save labor costs, we leverage structural similarity for automated sample selection during embedding. Each augmented data of an original image contains versions with varying severity levels. We implement a straightforward screening strategy to mitigate distribution drift. Experiments are conducted on a public road damage dataset. The proposed method not only eliminates the need for manual labor but also achieves remarkable enhancements, improving the mAP by 4.1% and the F1-score by 4.5%.
</details>
<details>
<summary>摘要</summary>
在交通安全和路面维护领域，精确检测路面损坏是保证安全驾驶和路面使用的重要因素。然而，现有方法往往因为有限数据而无法实现。先前的尝试使用生成敌方网络（Generative Adversarial Networks，GAN）生成具有多种形状的损坏，并手动将其插入适当的位置。然而，这个问题尚未得到充分探索，面临两个挑战。首先，它们只能够丰富路面损坏的位置和形状，而忽略损坏的严重程度的多样性。其次，它们需要大量的人工努力。为解决这些挑战，我们提出了一个创新的方法。除了使用GAN生成具有多种形状的损坏之外，我们还使用 текстур合成技术提取路面的teksture。这两个元素被混合不同的重量，allowing us to control the severity of the synthesized damage。这些合成损坏被回填回原始图像中via Poisson blending，以保证损坏的丰富性和背景的 Better alignment。为避免劳动成本，我们利用结构相似性进行自动化样本选择 during embedding。每个增强的数据包含不同严重程度的版本。我们实现了一个简单的萤幕策略来缓和分布迁移。实验在公共路面损坏数据集上进行。提出的方法不仅减少了劳动成本，而且取得了很大的改进，提高了mAP by 4.1%和F1-score by 4.5%。
</details></li>
</ul>
<hr>
<h2 id="VEATIC-Video-based-Emotion-and-Affect-Tracking-in-Context-Dataset"><a href="#VEATIC-Video-based-Emotion-and-Affect-Tracking-in-Context-Dataset" class="headerlink" title="VEATIC: Video-based Emotion and Affect Tracking in Context Dataset"></a>VEATIC: Video-based Emotion and Affect Tracking in Context Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06745">http://arxiv.org/abs/2309.06745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihang Ren, Jefferson Ortega, Yifan Wang, Zhimin Chen, Yunhui Guo, Stella X. Yu, David Whitney</li>
<li>For: 这个论文的目的是为了提供一个新的大型数据集，以便更好地理解人类情绪认知的机制和通用情况。* Methods: 这篇论文使用了124个电影、纪录片和家用视频的剪辑，并通过实时注释来提供每帧视频帧的连续�valence和arousal评分。此外，论文还提出了一种新的计算机视觉任务，即在视频帧中推断人物的情绪，并提出了一种简单的模型来评估这个任务。* Results: 实验显示，使用这个数据集训练的预训练模型可以与其他类似数据集的模型进行竞争，这表明VEATIC数据集的一般性。<details>
<summary>Abstract</summary>
Human affect recognition has been a significant topic in psychophysics and computer vision. However, the currently published datasets have many limitations. For example, most datasets contain frames that contain only information about facial expressions. Due to the limitations of previous datasets, it is very hard to either understand the mechanisms for affect recognition of humans or generalize well on common cases for computer vision models trained on those datasets. In this work, we introduce a brand new large dataset, the Video-based Emotion and Affect Tracking in Context Dataset (VEATIC), that can conquer the limitations of the previous datasets. VEATIC has 124 video clips from Hollywood movies, documentaries, and home videos with continuous valence and arousal ratings of each frame via real-time annotation. Along with the dataset, we propose a new computer vision task to infer the affect of the selected character via both context and character information in each video frame. Additionally, we propose a simple model to benchmark this new computer vision task. We also compare the performance of the pretrained model using our dataset with other similar datasets. Experiments show the competing results of our pretrained model via VEATIC, indicating the generalizability of VEATIC. Our dataset is available at https://veatic.github.io.
</details>
<details>
<summary>摘要</summary>
人类情感认知是心理 физи学和计算机视觉领域中的一个重要话题。然而，现有的发布 datasets 有很多限制。例如，大多数 datasets 只包含表达 facial expressions 的帧。由于过去的 datasets 的限制，很难理解人类情感认知的机制或者将模型在常见情况下进行普适的推理。在这项工作中，我们介绍了一个全新的大型 datasets，即 Video-based Emotion and Affect Tracking in Context Dataset (VEATIC)。VEATIC 包含 124 个 Hollywood 电影、纪录片和家庭视频的视频剪辑，每帧有实时标注的总体情感和高度情感值。此外，我们还提出了一个新的计算机视觉任务，即根据视频帧中的上下文和人物信息来预测人物的情感。此外，我们还提出了一个简单的模型来评估这个计算机视觉任务。我们还比较了使用我们的 dataset 预训练的模型的性能与其他相似的 dataset 的模型。实验结果显示了我们的预训练模型在 VEATIC 上的竞争性。我们的 dataset 可以在 <https://veatic.github.io> 上下载。
</details></li>
</ul>
<hr>
<h2 id="MTD-Multi-Timestep-Detector-for-Delayed-Streaming-Perception"><a href="#MTD-Multi-Timestep-Detector-for-Delayed-Streaming-Perception" class="headerlink" title="MTD: Multi-Timestep Detector for Delayed Streaming Perception"></a>MTD: Multi-Timestep Detector for Delayed Streaming Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06742">http://arxiv.org/abs/2309.06742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yulin1004/mtd">https://github.com/yulin1004/mtd</a></li>
<li>paper_authors: Yihui Huang, Ningjiang Chen</li>
<li>for: 这篇论文的目的是提高自动驾驶系统的实时环境感知，以确保用户的安全和体验。</li>
<li>methods: 该论文提出了一种名为多时步检测器（MTD）的端到端检测器，该检测器使用动态路由进行多支流未来预测，使模型具有抗延迟弹性。此外，一种延迟分析模块（DAM）也被提出，用于优化现有延迟感知方法，不断监测模型推理堆栈的延迟趋势。</li>
<li>results: 该论文在Argoverse-HD数据集上进行了实验，实验结果表明，该方法在不同的延迟设置下实现了状态革命的表现。<details>
<summary>Abstract</summary>
Autonomous driving systems require real-time environmental perception to ensure user safety and experience. Streaming perception is a task of reporting the current state of the world, which is used to evaluate the delay and accuracy of autonomous driving systems. In real-world applications, factors such as hardware limitations and high temperatures inevitably cause delays in autonomous driving systems, resulting in the offset between the model output and the world state. In order to solve this problem, this paper propose the Multi- Timestep Detector (MTD), an end-to-end detector which uses dynamic routing for multi-branch future prediction, giving model the ability to resist delay fluctuations. A Delay Analysis Module (DAM) is proposed to optimize the existing delay sensing method, continuously monitoring the model inference stack and calculating the delay trend. Moreover, a novel Timestep Branch Module (TBM) is constructed, which includes static flow and adaptive flow to adaptively predict specific timesteps according to the delay trend. The proposed method has been evaluated on the Argoverse-HD dataset, and the experimental results show that it has achieved state-of-the-art performance across various delay settings.
</details>
<details>
<summary>摘要</summary>
自动驾驶系统需要实时环境感知以确保用户安全和体验。流动感知是报告当前世界状态的任务，用于评估自动驾驶系统的延迟和准确性。在实际应用中，硬件限制和高温会导致自动驾驶系统的延迟，从而导致模型输出和世界状态之间的偏差。为解决这个问题，本文提出了多步调用器（MTD），一种端到端检测器，使用动态路由进行多支分支未来预测，让模型具有抗延迟波动的能力。延迟分析模块（DAM）被提出，用于优化现有延迟感知方法，持续监测模型推理堆栈的延迟趋势。此外，一种新的时间步模块（TBM）被构建，包括静止流和适应流，可以适应延迟趋势进行特定时间步预测。提出的方法在Argoverse-HD数据集上进行了实验，实验结果显示，它在不同延迟设置下实现了state-of-the-art的性能。
</details></li>
</ul>
<hr>
<h2 id="GelFlow-Self-supervised-Learning-of-Optical-Flow-for-Vision-Based-Tactile-Sensor-Displacement-Measurement"><a href="#GelFlow-Self-supervised-Learning-of-Optical-Flow-for-Vision-Based-Tactile-Sensor-Displacement-Measurement" class="headerlink" title="GelFlow: Self-supervised Learning of Optical Flow for Vision-Based Tactile Sensor Displacement Measurement"></a>GelFlow: Self-supervised Learning of Optical Flow for Vision-Based Tactile Sensor Displacement Measurement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06735">http://arxiv.org/abs/2309.06735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyuan Zhang, Hua Yang, Zhouping Yin</li>
<li>for: 支持更灵活的机器人手指操作，高分辨率多模态信息可以由视觉基于感觉器获取。</li>
<li>methods: 使用自主学习的光流方法，解决现有光流方法的精度问题。</li>
<li>results: 提出了一种基于深度学习的光流方法，实现了高精度的偏移量测量。对比传统和深度学习基于光流方法，得到了更高的偏移量测量精度。<details>
<summary>Abstract</summary>
High-resolution multi-modality information acquired by vision-based tactile sensors can support more dexterous manipulations for robot fingers. Optical flow is low-level information directly obtained by vision-based tactile sensors, which can be transformed into other modalities like force, geometry and depth. Current vision-tactile sensors employ optical flow methods from OpenCV to estimate the deformation of markers in gels. However, these methods need to be more precise for accurately measuring the displacement of markers during large elastic deformation of the gel, as this can significantly impact the accuracy of downstream tasks. This study proposes a self-supervised optical flow method based on deep learning to achieve high accuracy in displacement measurement for vision-based tactile sensors. The proposed method employs a coarse-to-fine strategy to handle large deformations by constructing a multi-scale feature pyramid from the input image. To better deal with the elastic deformation caused by the gel, the Helmholtz velocity decomposition constraint combined with the elastic deformation constraint are adopted to address the distortion rate and area change rate, respectively. A local flow fusion module is designed to smooth the optical flow, taking into account the prior knowledge of the blurred effect of gel deformation. We trained the proposed self-supervised network using an open-source dataset and compared it with traditional and deep learning-based optical flow methods. The results show that the proposed method achieved the highest displacement measurement accuracy, thereby demonstrating its potential for enabling more precise measurement of downstream tasks using vision-based tactile sensors.
</details>
<details>
<summary>摘要</summary>
高分辨率多Modal信息由视觉基于感觉传感器获取可以支持机器人手指更灵活的抓取操作。视觉流是视觉基于感觉传感器直接获取的低级信息，可以转换为其他模式如力、几何和深度。现有的视觉感觉传感器使用OpenCV中的视觉流方法来估计gel中 marker的变形。然而，这些方法需要更加精准地测量Marker的移动 during large elastic deformation of the gel，因为这可能会对下游任务的准确性产生重要影响。本研究提出了一种基于深度学习的自主Optical flow方法来实现高精度的移动测量。该方法采用了粗细到细的策略来处理大的变形，通过构建输入图像的多尺度特征 pyramid。为了更好地处理由gel引起的弹性扭formation，该方法采用了Helmholtz速度分解约束和弹性扭formation约束来处理扭formation rate和面积变化率，分别。此外，为了更好地处理gel的模糊效应，该方法还设计了一个本地流合并模块来平滑Optical flow。我们使用了一个开源数据集来训练我们的提案的自主网络，并与传统和深度学习基于的Optical flow方法进行比较。结果显示，我们的方法实现了最高的移动测量精度，从而证明了其在视觉基于感觉传感器上的潜在应用。
</details></li>
</ul>
<hr>
<h2 id="Prompting-Segmentation-with-Sound-is-Generalizable-Audio-Visual-Source-Localizer"><a href="#Prompting-Segmentation-with-Sound-is-Generalizable-Audio-Visual-Source-Localizer" class="headerlink" title="Prompting Segmentation with Sound is Generalizable Audio-Visual Source Localizer"></a>Prompting Segmentation with Sound is Generalizable Audio-Visual Source Localizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07929">http://arxiv.org/abs/2309.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaoting Wang, Weisong Liu, Guangyao Li, Jian Ding, Di Hu, Xi Li</li>
<li>for: 本研究旨在解决静音下Audio-Visual Localization和Segmentation任务中数据缺乏和数据分布不均问题，提高模型的泛化能力。</li>
<li>methods: 我们提出了Encoder-Prompt-Decoder模型，其中首先构建了Semantic-aware Audio Prompt（SAP），以帮助视觉基础模型更好地听到物体的声音。然后，我们开发了Correlation Adapter（ColA），以保持最小的训练努力并维护视觉基础模型的知识。</li>
<li>results: 我们通过广泛的实验证明，Compared with其他拟合方法，我们的方法在未看过类和跨数据集情况下表现更好， indicating that our method can better generalize to unseen data.<details>
<summary>Abstract</summary>
Never having seen an object and heard its sound simultaneously, can the model still accurately localize its visual position from the input audio? In this work, we concentrate on the Audio-Visual Localization and Segmentation tasks but under the demanding zero-shot and few-shot scenarios. To achieve this goal, different from existing approaches that mostly employ the encoder-fusion-decoder paradigm to decode localization information from the fused audio-visual feature, we introduce the encoder-prompt-decoder paradigm, aiming to better fit the data scarcity and varying data distribution dilemmas with the help of abundant knowledge from pre-trained models. Specifically, we first propose to construct Semantic-aware Audio Prompt (SAP) to help the visual foundation model focus on sounding objects, meanwhile, the semantic gap between the visual and audio modalities is also encouraged to shrink. Then, we develop a Correlation Adapter (ColA) to keep minimal training efforts as well as maintain adequate knowledge of the visual foundation model. By equipping with these means, extensive experiments demonstrate that this new paradigm outperforms other fusion-based methods in both the unseen class and cross-dataset settings. We hope that our work can further promote the generalization study of Audio-Visual Localization and Segmentation in practical application scenarios.
</details>
<details>
<summary>摘要</summary>
原文：假设我们没有直接见到对象，但可以听到它的声音。在这种情况下，模型是否可以准确地确定对象的视觉位置？在这个工作中，我们关注了音频视频本地化和分割任务，但是在零次和几次学习enario下进行。为了实现这个目标，不同于现有的方法，我们不使用混合Encoder-Fusion-Decoder模型来解码音频视频特征中的本地化信息。而是引入Encoder-Prompt-Decoder模型，以更好地适应数据缺乏和数据分布的变化问题，并利用大量的预训练模型知识。Specifically：我们首先提出了Semantic-aware Audio Prompt（SAP），帮助视觉基础模型更好地注意声音对象，同时也鼓励视觉和声音模式之间的semantic gap减小。然后，我们开发了Correlation Adapter（ColA），以保持最小的训练努力，同时也保持视觉基础模型的知识。通过这些手段，我们进行了广泛的实验，并证明了这种新方法在未看到类和跨数据集 Setting下比其他混合方法表现更好。我们希望这种工作可以进一步促进实际应用场景中Audio-Visual Localization和Segmentation的总结研究。Translation:假设我们没有直接见到对象，但可以听到它的声音。在这种情况下，模型是否可以准确地确定对象的视觉位置？在这个工作中，我们关注了音频视频本地化和分割任务，但是在零次和几次学习enario下进行。为了实现这个目标，不同于现有的方法，我们不使用混合Encoder-Fusion-Decoder模型来解码音频视频特征中的本地化信息。而是引入Encoder-Prompt-Decoder模型，以更好地适应数据缺乏和数据分布的变化问题，并利用大量的预训练模型知识。Specifically，我们首先提出了Semantic-aware Audio Prompt（SAP），帮助视觉基础模型更好地注意声音对象，同时也鼓励视觉和声音模式之间的semantic gap减小。然后，我们开发了Correlation Adapter（ColA），以保持最小的训练努力，同时也保持视觉基础模型的知识。通过这些手段，我们进行了广泛的实验，并证明了这种新方法在未看到类和跨数据集 Setting下比其他混合方法表现更好。我们希望这种工作可以进一步促进实际应用场景中Audio-Visual Localization和Segmentation的总结研究。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Foundation-models-for-Unsupervised-Audio-Visual-Segmentation"><a href="#Leveraging-Foundation-models-for-Unsupervised-Audio-Visual-Segmentation" class="headerlink" title="Leveraging Foundation models for Unsupervised Audio-Visual Segmentation"></a>Leveraging Foundation models for Unsupervised Audio-Visual Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06728">http://arxiv.org/abs/2309.06728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Swapnil Bhosale, Haosen Yang, Diptesh Kanojia, Xiatian Zhu</li>
<li>for: 这个论文的目标是提出一种无监督的音频视频分割方法，以便在实际应用中避免繁琐的批处理和标注工作。</li>
<li>methods: 这个方法基于一种新的卷积权重学习策略，通过利用现有的多Modal基础模型（如检测[1]、开放世界分割[2]和多Modal协调[3]）来准确地关联音频mask对。</li>
<li>results: 经验表明，该方法可以与现有的监督学习方法相比，在复杂的场景下具有良好的性能，尤其是在多个声音对象重叠的情况下。<details>
<summary>Abstract</summary>
Audio-Visual Segmentation (AVS) aims to precisely outline audible objects in a visual scene at the pixel level. Existing AVS methods require fine-grained annotations of audio-mask pairs in supervised learning fashion. This limits their scalability since it is time consuming and tedious to acquire such cross-modality pixel level labels. To overcome this obstacle, in this work we introduce unsupervised audio-visual segmentation with no need for task-specific data annotations and model training. For tackling this newly proposed problem, we formulate a novel Cross-Modality Semantic Filtering (CMSF) approach to accurately associate the underlying audio-mask pairs by leveraging the off-the-shelf multi-modal foundation models (e.g., detection [1], open-world segmentation [2] and multi-modal alignment [3]). Guiding the proposal generation by either audio or visual cues, we design two training-free variants: AT-GDINO-SAM and OWOD-BIND. Extensive experiments on the AVS-Bench dataset show that our unsupervised approach can perform well in comparison to prior art supervised counterparts across complex scenarios with multiple auditory objects. Particularly, in situations where existing supervised AVS methods struggle with overlapping foreground objects, our models still excel in accurately segmenting overlapped auditory objects. Our code will be publicly released.
</details>
<details>
<summary>摘要</summary>
Audio-Visual Segmentation (AVS) 目标是在视觉场景中像素级准确标识可听对象。现有的 AVS 方法需要精grained的音频 маска对在supervised 学习方式下进行标注。这限制了它们的扩展性，因为获得这种 across-modality 像素级标注是时间consuming 和痛苦的。为了解决这个问题，在这个工作中，我们介绍了无监督的音频视觉分割方法，无需任务特定的数据标注和模型训练。为解决这个新提出的问题，我们提出了一种 Cross-Modality Semantic Filtering (CMSF) 方法，以准确地关联音频 маска对。我们利用了市场上可得到的多Modal foundation models（例如检测 [1]、开放世界分割 [2]和多Modal alignment [3]），以帮助我们准确地关联音频和视觉信号。我们通过音频或视觉提示来引导提议生成，设计了两种无需训练的变体：AT-GDINO-SAM 和 OWOD-BIND。我们在 AVS-Bench 数据集上进行了广泛的实验，结果表明，我们的无监督方法可以在复杂的场景中与先前的监督性 AVS 方法相比，表现良好。特别是在多个 auditory 对象 overlap 的情况下，我们的模型仍能准确地分割 overlap 的 auditory 对象。我们将代码公开发布。
</details></li>
</ul>
<hr>
<h2 id="Deep-Nonparametric-Convexified-Filtering-for-Computational-Photography-Image-Synthesis-and-Adversarial-Defense"><a href="#Deep-Nonparametric-Convexified-Filtering-for-Computational-Photography-Image-Synthesis-and-Adversarial-Defense" class="headerlink" title="Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense"></a>Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06724">http://arxiv.org/abs/2309.06724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianqiao Wangni</li>
<li>for: 提供一个通用的计算 fotografraphy 框架，从不完美的图像中恢复真实场景，通过深度非 Parametric 凸 filtering (DNCF)。</li>
<li>methods: 使用一个非 Parametric 深度网络来模仿图像形成物理方程，如噪声除除、超解像、填充和闪光。DNCF 没有dependent于训练数据的参数化，因此具有强大的泛化和Robustness 对抗图像修改。</li>
<li>results: 在推理过程中，我们鼓励网络参数为非负值，创建了输入和参数之间的bi-凸函数，并采用了第二个优化算法，实现了10倍的加速。通过这些工具，我们在实验中证明了DNCF 可以在实时中防止图像分类深度网络被攻击 algorithms。<details>
<summary>Abstract</summary>
We aim to provide a general framework of for computational photography that recovers the real scene from imperfect images, via the Deep Nonparametric Convexified Filtering (DNCF). It is consists of a nonparametric deep network to resemble the physical equations behind the image formation, such as denoising, super-resolution, inpainting, and flash. DNCF has no parameterization dependent on training data, therefore has a strong generalization and robustness to adversarial image manipulation. During inference, we also encourage the network parameters to be nonnegative and create a bi-convex function on the input and parameters, and this adapts to second-order optimization algorithms with insufficient running time, having 10X acceleration over Deep Image Prior. With these tools, we empirically verify its capability to defend image classification deep networks against adversary attack algorithms in real-time.
</details>
<details>
<summary>摘要</summary>
我们目标是提供一个通用的计算摄影框架，通过深度非 Parametric 矩阵 Filtering (DNCF) 来回归真实场景 из不完美图像。DNCF 包含一个非 Parametric 深度网络，用于模拟图像形成物理方程，如净化、超分解、填充和闪光。DNCF 没有依赖于训练数据的参数化，因此具有强大的泛化和鲁棒性，抵御恶意图像修饰。在推理过程中，我们还鼓励网络参数为非负，创建了输入和参数之间的二 conjugate 函数，这使得可以通过缺乏运行时间的第二次优化算法进行加速，比 Deep Image Prior 快速了 10 倍。通过这些工具，我们在实验中证明了它可以在实时中防止图像分类深度网络被攻击算法攻击。
</details></li>
</ul>
<hr>
<h2 id="Deep-Attentive-Time-Warping"><a href="#Deep-Attentive-Time-Warping" class="headerlink" title="Deep Attentive Time Warping"></a>Deep Attentive Time Warping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06720">http://arxiv.org/abs/2309.06720</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matsuo-shinnosuke/deep-attentive-time-warping">https://github.com/matsuo-shinnosuke/deep-attentive-time-warping</a></li>
<li>paper_authors: Shinnosuke Matsuo, Xiaomeng Wu, Gantugs Atarsaikhan, Akisato Kimura, Kunio Kashino, Brian Kenji Iwana, Seiichi Uchida</li>
<li>for: 本文为了提高时间序列分类中的非线性时间扭曲问题的处理能力，提出了一种基于神经网络的任务适应时间扭曲机制。</li>
<li>methods: 本文使用了注意力模型，称为两边注意力模型，来开发一种可靠的时间扭曲机制，并通过度量学学习来训练模型。</li>
<li>results: 对比DTW和其他学习型模型，本文的模型在在线签名验证任务中显示出了superior的效果和状态革命性能。<details>
<summary>Abstract</summary>
Similarity measures for time series are important problems for time series classification. To handle the nonlinear time distortions, Dynamic Time Warping (DTW) has been widely used. However, DTW is not learnable and suffers from a trade-off between robustness against time distortion and discriminative power. In this paper, we propose a neural network model for task-adaptive time warping. Specifically, we use the attention model, called the bipartite attention model, to develop an explicit time warping mechanism with greater distortion invariance. Unlike other learnable models using DTW for warping, our model predicts all local correspondences between two time series and is trained based on metric learning, which enables it to learn the optimal data-dependent warping for the target task. We also propose to induce pre-training of our model by DTW to improve the discriminative power. Extensive experiments demonstrate the superior effectiveness of our model over DTW and its state-of-the-art performance in online signature verification.
</details>
<details>
<summary>摘要</summary>
时序序列相似度评估是时序分类的关键问题。为了处理非线性时间扭曲，广泛使用了动态时间扭曲（DTW）。然而，DTW不是学习的，它受到时间扭曲的质量和数据分类能力之间的负担。在这篇论文中，我们提出了一种基于神经网络的任务适应时间扭曲模型。specifically，我们使用了对称注意力模型，称为双对称注意力模型，来开发一个显式的时间扭曲机制，具有更高的扭曲不变性。与其他使用DTW进行扭曲的学习模型不同，我们的模型预测了两个时序序列之间的所有本地匹配，并基于度量学习来训练，这使得它能够学习目标任务中最佳的数据dependent扭曲。我们还提出了在我们模型中进行DTW预训练，以提高分类能力。广泛的实验证明了我们模型的超过DTW和其他现有方法的表现，并在在线签名验证中达到了最佳性能。
</details></li>
</ul>
<hr>
<h2 id="MPI-Flow-Learning-Realistic-Optical-Flow-with-Multiplane-Images"><a href="#MPI-Flow-Learning-Realistic-Optical-Flow-with-Multiplane-Images" class="headerlink" title="MPI-Flow: Learning Realistic Optical Flow with Multiplane Images"></a>MPI-Flow: Learning Realistic Optical Flow with Multiplane Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06714">http://arxiv.org/abs/2309.06714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sharpiless/mpi-flow">https://github.com/sharpiless/mpi-flow</a></li>
<li>paper_authors: Yingping Liang, Jiaming Liu, Debing Zhang, Ying Fu<br>for:这个研究旨在提高学习型光流估计模型的实用性，通过将真实世界影像转换为真实光流资料集。methods:我们使用多层深度表示（Multiplane Image，MPI）来创建高度真实的新图像，并使用摄像机矩阵和plane深度来计算每个平面的光流。我们还开发了一个独立物运动模组，以分离摄像机和动物运动的影响。results:我们的方法在实验中表现出色，在真实数据集上实现了最佳性能，并且在无监督和监督式训练中均 achieve 州际表现。代码将在：\url{<a target="_blank" rel="noopener" href="https://github.com/Sharpiless/MPI-Flow%7D">https://github.com/Sharpiless/MPI-Flow}</a> 中公开。<details>
<summary>Abstract</summary>
The accuracy of learning-based optical flow estimation models heavily relies on the realism of the training datasets. Current approaches for generating such datasets either employ synthetic data or generate images with limited realism. However, the domain gap of these data with real-world scenes constrains the generalization of the trained model to real-world applications. To address this issue, we investigate generating realistic optical flow datasets from real-world images. Firstly, to generate highly realistic new images, we construct a layered depth representation, known as multiplane images (MPI), from single-view images. This allows us to generate novel view images that are highly realistic. To generate optical flow maps that correspond accurately to the new image, we calculate the optical flows of each plane using the camera matrix and plane depths. We then project these layered optical flows into the output optical flow map with volume rendering. Secondly, to ensure the realism of motion, we present an independent object motion module that can separate the camera and dynamic object motion in MPI. This module addresses the deficiency in MPI-based single-view methods, where optical flow is generated only by camera motion and does not account for any object movement. We additionally devise a depth-aware inpainting module to merge new images with dynamic objects and address unnatural motion occlusions. We show the superior performance of our method through extensive experiments on real-world datasets. Moreover, our approach achieves state-of-the-art performance in both unsupervised and supervised training of learning-based models. The code will be made publicly available at: \url{https://github.com/Sharpiless/MPI-Flow}.
</details>
<details>
<summary>摘要</summary>
“学习基于的光流估算模型准确性很大程度上取决于训练数据的真实性。现有的方法用 sintetic 数据或生成有限的真实性的图像来生成训练数据。然而，这些数据与实际场景之间的域差异会限制训练得到的模型在实际应用中的泛化能力。为了解决这个问题，我们研究如何从实际图像中生成真实的光流数据。首先，我们使用单视图图像生成多层次深度表示（MPI），以生成高真实性的新图像。然后，我们使用相机矩阵和深度信息计算每层的光流，并使用体积投影将层次光流投影到输出光流图中。其次，我们提出了独立物体运动模块，可以在 MPI 中分离 Camera 和动态物体的运动。这个模块解决了 MPI 基于单视图方法中的缺陷，即只能通过相机运动生成光流，而不考虑物体运动。此外，我们还提出了depth-aware填充模块，可以将新图像与动态物体合并，并解决不自然的运动遮挡。我们通过大量实验证明了我们的方法的超越性，并且在不监督和监督训练中都达到了学习基于模型的状态之巅。代码将在：\url{https://github.com/Sharpiless/MPI-Flow} 公开。”
</details></li>
</ul>
<hr>
<h2 id="Transparent-Object-Tracking-with-Enhanced-Fusion-Module"><a href="#Transparent-Object-Tracking-with-Enhanced-Fusion-Module" class="headerlink" title="Transparent Object Tracking with Enhanced Fusion Module"></a>Transparent Object Tracking with Enhanced Fusion Module</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06701">http://arxiv.org/abs/2309.06701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kalyan0510/totem">https://github.com/kalyan0510/totem</a></li>
<li>paper_authors: Kalyan Garigapati, Erik Blasch, Jie Wei, Haibin Ling</li>
<li>for: 这个论文是为了提高机器人任务中透明物体的追踪性能，因为这些物体的适应性和反射性环境，传统的追踪算法受到减少性能。</li>
<li>methods: 这个论文使用了一种新的特征融合技术，将透明信息融合到固定特征空间中，以便在更广泛的追踪器中使用。融合模组包括一个对应器Encoder和一个多层感知机制模组，通过关键查询基于变数的转换来嵌入透明信息到追踪管道中。</li>
<li>results: 这个论文提出了一个新的追踪架构，使用了新的融合技术以 achieve superior 的透明物体追踪 результа。该架构在 TOTB Benchmark 上获得了竞争性的结果，与现有的追踪器相比。<details>
<summary>Abstract</summary>
Accurate tracking of transparent objects, such as glasses, plays a critical role in many robotic tasks such as robot-assisted living. Due to the adaptive and often reflective texture of such objects, traditional tracking algorithms that rely on general-purpose learned features suffer from reduced performance. Recent research has proposed to instill transparency awareness into existing general object trackers by fusing purpose-built features. However, with the existing fusion techniques, the addition of new features causes a change in the latent space making it impossible to incorporate transparency awareness on trackers with fixed latent spaces. For example, many of the current days transformer-based trackers are fully pre-trained and are sensitive to any latent space perturbations. In this paper, we present a new feature fusion technique that integrates transparency information into a fixed feature space, enabling its use in a broader range of trackers. Our proposed fusion module, composed of a transformer encoder and an MLP module, leverages key query-based transformations to embed the transparency information into the tracking pipeline. We also present a new two-step training strategy for our fusion module to effectively merge transparency features. We propose a new tracker architecture that uses our fusion techniques to achieve superior results for transparent object tracking. Our proposed method achieves competitive results with state-of-the-art trackers on TOTB, which is the largest transparent object tracking benchmark recently released. Our results and the implementation of code will be made publicly available at https://github.com/kalyan0510/TOTEM.
</details>
<details>
<summary>摘要</summary>
准确跟踪透明物体，如镜片、玻璃等，在机器人任务中扮演着关键性的角色。由于透明物体的适应性和反射性Texture，传统的跟踪算法基于通用学习的特征会受到减少性能的影响。最近的研究提出了把透明性知识引入现有的通用物体跟踪器中，通过混合专门设计的特征。然而，现有的混合技术会导致特征空间中的变化，使得在跟踪器中引入透明性知识 become impossible。例如，现在大多数的当今天transformer-based tracker都是完全预训练的，对于特征空间的任何变化都会产生敏感反应。在这篇论文中，我们提出了一种新的特征混合技术，可以将透明信息 embed到固定特征空间中，使其能够在更广泛的跟踪器上使用。我们的提案的混合模块由transformer编码器和多层感知机制组成，利用关键Query-based变换来嵌入透明信息到跟踪管道中。我们还提出了一种新的两步训练策略，以便有效地合并透明特征。我们提议一种新的跟踪架构，使用我们的混合技术来实现superior的透明物体跟踪结果。我们的提议方法在最新的TOTBbenchmark上达到了与状态静态跟踪器相当的竞争水平。我们的结果和实现代码将于https://github.com/kalyan0510/TOTEM中公开。
</details></li>
</ul>
<hr>
<h2 id="STUPD-A-Synthetic-Dataset-for-Spatial-and-Temporal-Relation-Reasoning"><a href="#STUPD-A-Synthetic-Dataset-for-Spatial-and-Temporal-Relation-Reasoning" class="headerlink" title="STUPD: A Synthetic Dataset for Spatial and Temporal Relation Reasoning"></a>STUPD: A Synthetic Dataset for Spatial and Temporal Relation Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06680">http://arxiv.org/abs/2309.06680</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/palaashagrawal/stupd">https://github.com/palaashagrawal/stupd</a></li>
<li>paper_authors: Palaash Agrawal, Haidi Azaman, Cheston Tan</li>
<li>for: This paper aims to improve the ability of computer vision models to perform spatial reasoning and understand temporal relations in visual scenes.</li>
<li>methods: The authors propose a large-scale video dataset called STUPD, which includes 150K visual depictions of static and dynamic spatial relationships derived from prepositions of the English language, as well as 50K visual depictions of temporal relations.</li>
<li>results: The authors show that pretraining models on the STUPD dataset leads to an increase in performance on real-world datasets (ImageNet-VidVRD and Spatial Senses) compared to other pretraining datasets.<details>
<summary>Abstract</summary>
Understanding relations between objects is crucial for understanding the semantics of a visual scene. It is also an essential step in order to bridge visual and language models. However, current state-of-the-art computer vision models still lack the ability to perform spatial reasoning well. Existing datasets mostly cover a relatively small number of spatial relations, all of which are static relations that do not intrinsically involve motion. In this paper, we propose the Spatial and Temporal Understanding of Prepositions Dataset (STUPD) -- a large-scale video dataset for understanding static and dynamic spatial relationships derived from prepositions of the English language. The dataset contains 150K visual depictions (videos and images), consisting of 30 distinct spatial prepositional senses, in the form of object interaction simulations generated synthetically using Unity3D. In addition to spatial relations, we also propose 50K visual depictions across 10 temporal relations, consisting of videos depicting event/time-point interactions. To our knowledge, no dataset exists that represents temporal relations through visual settings. In this dataset, we also provide 3D information about object interactions such as frame-wise coordinates, and descriptions of the objects used. The goal of this synthetic dataset is to help models perform better in visual relationship detection in real-world settings. We demonstrate an increase in the performance of various models over 2 real-world datasets (ImageNet-VidVRD and Spatial Senses) when pretrained on the STUPD dataset, in comparison to other pretraining datasets.
</details>
<details>
<summary>摘要</summary>
理解物体之间的关系是视觉Scene的semantics理解的关键，同时也是将视觉和语言模型相连的重要步骤。然而，当前状态的计算机视觉模型仍然缺乏空间逻辑的能力。现有的数据集主要覆盖了一些相对较小的空间关系，其中所有都是静止的关系，不含动态的变化。在这篇论文中，我们提出了空间和时间理解预position数据集（STUPD）——一个大规模的视频数据集，用于理解静止和动态空间关系，从英语预position中提取出来。该数据集包含150万个视觉表示（视频和图像），包括30种不同的空间预position感，通过Unity3D Synthetically生成的对象互动 simulations。此外，我们还提出了50万个视觉表示的10种时间关系，包括视频显示事件/时间点互动。我们知道，没有任何数据集表示了时间关系通过视觉设置。在这个数据集中，我们还提供了对象互动中的帧坐标和使用的对象描述。该人工数据集的目标是帮助模型在实际设置中更好地检测视觉关系。我们在STUPD数据集上进行预训练后，与ImageNet-VidVRD和空间感数据集进行比较，发现模型在这些数据集上表现出了明显的提升。
</details></li>
</ul>
<hr>
<h2 id="ShaDocFormer-A-Shadow-attentive-Threshold-Detector-with-Cascaded-Fusion-Refiner-for-document-shadow-removal"><a href="#ShaDocFormer-A-Shadow-attentive-Threshold-Detector-with-Cascaded-Fusion-Refiner-for-document-shadow-removal" class="headerlink" title="ShaDocFormer: A Shadow-attentive Threshold Detector with Cascaded Fusion Refiner for document shadow removal"></a>ShaDocFormer: A Shadow-attentive Threshold Detector with Cascaded Fusion Refiner for document shadow removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06670">http://arxiv.org/abs/2309.06670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiwen Chen, Shenghong Luo, Xuhang Chen, Zinuo Li, Shuqiang Wang, Chi-Man Pun</li>
<li>for: 本研究旨在解决手持设备捕捉文档时出现的文档阴影问题，以提高文档的可读性。</li>
<li>methods: 该研究提出了一种基于Transformer架构的ShaDocFormer模型，它将传统方法和深度学习技术相结合，以解决文档阴影除去的问题。ShaDocFormer模型包括两个组件：阴影敏感检测器（STD）和彩色融合级联器（CFR）。STD模块使用传统的阈值技术，并通过Transformer的注意机制获取全局信息，以准确检测阴影面积。CFR模块采用级联和汇集结构，以实现从粗到细的修复过程，以捕捉整个图像的变化。</li>
<li>results: 实验表明，ShaDocFormer模型在Qualitative和Quantitative两个维度上都能够超越当前状态艺的方法。<details>
<summary>Abstract</summary>
Document shadow is a common issue that arise when capturing documents using mobile devices, which significantly impacts the readability. Current methods encounter various challenges including inaccurate detection of shadow masks and estimation of illumination. In this paper, we propose ShaDocFormer, a Transformer-based architecture that integrates traditional methodologies and deep learning techniques to tackle the problem of document shadow removal. The ShaDocFormer architecture comprises two components: the Shadow-attentive Threshold Detector (STD) and the Cascaded Fusion Refiner (CFR). The STD module employs a traditional thresholding technique and leverages the attention mechanism of the Transformer to gather global information, thereby enabling precise detection of shadow masks. The cascaded and aggregative structure of the CFR module facilitates a coarse-to-fine restoration process for the entire image. As a result, ShaDocFormer excels in accurately detecting and capturing variations in both shadow and illumination, thereby enabling effective removal of shadows. Extensive experiments demonstrate that ShaDocFormer outperforms current state-of-the-art methods in both qualitative and quantitative measurements.
</details>
<details>
<summary>摘要</summary>
文档阴影是手持设备捕捉文档时常见的问题，对于文档的可读性有很大的影响。现有方法面临着各种挑战，包括不准确的阴影面掩模板和灯光量的估算。本文提出了ShaDocFormer，一种基于Transformer架构的架构，该架构集成了传统方法和深度学习技术，用于解决文档阴影除去的问题。ShaDocFormer架构包括两个组件：阴影感知阈值检测器（STD）和缓存融合修正器（CFR）。STD模块使用传统的阈值技术，并利用Transformer的注意机制，以全局信息的收集，以准确探测阴影面掩模板。CFR模块采用缓存和融合的结构，实现了从粗到细的修复过程，以便整个图像的修复。因此，ShaDocFormer能够准确探测和捕捉阴影和灯光的变化，从而实现有效地除去阴影。经验表明，ShaDocFormer在质量和量度上都超过当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="LCReg-Long-Tailed-Image-Classification-with-Latent-Categories-based-Recognition"><a href="#LCReg-Long-Tailed-Image-Classification-with-Latent-Categories-based-Recognition" class="headerlink" title="LCReg: Long-Tailed Image Classification with Latent Categories based Recognition"></a>LCReg: Long-Tailed Image Classification with Latent Categories based Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07186">http://arxiv.org/abs/2309.07186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weide Liu, Zhonghua Wu, Yiming Wang, Henghui Ding, Fayao Liu, Jie Lin, Guosheng Lin</li>
<li>for: long-tailed image recognition</li>
<li>methods: 使用类共同尺度特征学习和Semantic数据增强来提高特征表示</li>
<li>results: 在五个长尾图像识别数据集上进行了广泛的实验，与基eline进行比较，得到了显著提高的结果<details>
<summary>Abstract</summary>
In this work, we tackle the challenging problem of long-tailed image recognition. Previous long-tailed recognition approaches mainly focus on data augmentation or re-balancing strategies for the tail classes to give them more attention during model training. However, these methods are limited by the small number of training images for the tail classes, which results in poor feature representations. To address this issue, we propose the Latent Categories based long-tail Recognition (LCReg) method. Our hypothesis is that common latent features shared by head and tail classes can be used to improve feature representation. Specifically, we learn a set of class-agnostic latent features shared by both head and tail classes, and then use semantic data augmentation on the latent features to implicitly increase the diversity of the training sample. We conduct extensive experiments on five long-tailed image recognition datasets, and the results show that our proposed method significantly improves the baselines.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们解决了长尾图像识别的挑战问题。先前的长尾识别方法主要集中在数据扩展或重新平衡策略上，以给尾类提供更多的注意力 durante 模型训练。然而，这些方法受到尾类训练图像的少量限制，导致feature表示不佳。为解决这个问题，我们提出了Latent Categories based long-tail Recognition（LCReg）方法。我们的假设是，头和尾类共享的潜在特征可以提高特征表示。具体来说，我们学习一组不同类型的潜在特征，然后使用语义数据扩展在这些潜在特征上进行隐式增加训练样本的多样性。我们在五个长尾图像识别 datasets 进行了广泛的实验，结果显示，我们提出的方法可以明显提高基elines。
</details></li>
</ul>
<hr>
<h2 id="Generalizable-Neural-Fields-as-Partially-Observed-Neural-Processes"><a href="#Generalizable-Neural-Fields-as-Partially-Observed-Neural-Processes" class="headerlink" title="Generalizable Neural Fields as Partially Observed Neural Processes"></a>Generalizable Neural Fields as Partially Observed Neural Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06660">http://arxiv.org/abs/2309.06660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeffrey Gu, Kuan-Chieh Wang, Serena Yeung</li>
<li>for: 代表信号为函数参数化的神经场是一种有前途的代替方案，比传统的离散 вектор或网格基本表示更好地扩展性、连续性和可微性。</li>
<li>methods: 我们提出了一种新的思路，视为大规模培育神经表示为部分观察神经过程框架，并利用神经过程算法解决这个问题。</li>
<li>results: 我们的方法比现有的梯度基于元学习方法和卷积网络方法更高效，并且可以更好地利用信号之间的共享信息或结构。<details>
<summary>Abstract</summary>
Neural fields, which represent signals as a function parameterized by a neural network, are a promising alternative to traditional discrete vector or grid-based representations. Compared to discrete representations, neural representations both scale well with increasing resolution, are continuous, and can be many-times differentiable. However, given a dataset of signals that we would like to represent, having to optimize a separate neural field for each signal is inefficient, and cannot capitalize on shared information or structures among signals. Existing generalization methods view this as a meta-learning problem and employ gradient-based meta-learning to learn an initialization which is then fine-tuned with test-time optimization, or learn hypernetworks to produce the weights of a neural field. We instead propose a new paradigm that views the large-scale training of neural representations as a part of a partially-observed neural process framework, and leverage neural process algorithms to solve this task. We demonstrate that this approach outperforms both state-of-the-art gradient-based meta-learning approaches and hypernetwork approaches.
</details>
<details>
<summary>摘要</summary>
neural fields, which represent signals as a function parameterized by a neural network, are a promising alternative to traditional discrete vector or grid-based representations. Compared to discrete representations, neural representations both scale well with increasing resolution, are continuous, and can be many-times differentiable. However, given a dataset of signals that we would like to represent, having to optimize a separate neural field for each signal is inefficient, and cannot capitalize on shared information or structures among signals. Existing generalization methods view this as a meta-learning problem and employ gradient-based meta-learning to learn an initialization which is then fine-tuned with test-time optimization, or learn hypernetworks to produce the weights of a neural field. We instead propose a new paradigm that views the large-scale training of neural representations as a part of a partially-observed neural process framework, and leverage neural process algorithms to solve this task. We demonstrate that this approach outperforms both state-of-the-art gradient-based meta-learning approaches and hypernetwork approaches.Here's the word-for-word translation:神经场, 表示信号为神经网络参数化的函数, 是传统栅格化或简单向量表示的有前途的替代方案。与简单表示相比, 神经表示可以扩展到高分辨率, 连续, 可多次导数。但是, 给定一个信号集, 每个信号都需要优化单独的神经场, 这是不效率的, 无法利用信号之间共享的信息或结构。现有的总结方法视为meta学习问题, 使用梯度基本的meta学习学习初始化, 然后在测试时进行优化, 或学习卷积网络生成神经场的权重。我们则提出了一种新的思路, 视为大规模训练神经表示为部分观察神经过程框架的一部分, 并利用神经过程算法解决这个问题。我们示出了这种方法在状态统计学习术的梯度基本meta学习方法和卷积网络方法之上具有优势。
</details></li>
</ul>
<hr>
<h2 id="Event-Driven-Imaging-in-Turbid-Media-A-Confluence-of-Optoelectronics-and-Neuromorphic-Computation"><a href="#Event-Driven-Imaging-in-Turbid-Media-A-Confluence-of-Optoelectronics-and-Neuromorphic-Computation" class="headerlink" title="Event-Driven Imaging in Turbid Media: A Confluence of Optoelectronics and Neuromorphic Computation"></a>Event-Driven Imaging in Turbid Media: A Confluence of Optoelectronics and Neuromorphic Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06652">http://arxiv.org/abs/2309.06652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Zhang, Timothy Shea, Arto Nurmikko</li>
<li>for: 这篇论文旨在探讨如何使用光学计算方法揭示在浓雾媒体中难以识别的目标图像。</li>
<li>methods: 这种新方法基于人类视觉，首先将散射光转换为脉冲信号，然后使用神经元模型进行图像重建。</li>
<li>results: 研究人员通过对不同的MNIST字体和图像集进行图像重建，成功地解决了透明媒体中图像不可见的问题，并且可以准确地识别出图像的内容。<details>
<summary>Abstract</summary>
In this paper a new optical-computational method is introduced to unveil images of targets whose visibility is severely obscured by light scattering in dense, turbid media. The targets of interest are taken to be dynamic in that their optical properties are time-varying whether stationary in space or moving. The scheme, to our knowledge the first of its kind, is human vision inspired whereby diffuse photons collected from the turbid medium are first transformed to spike trains by a dynamic vision sensor as in the retina, and image reconstruction is then performed by a neuromorphic computing approach mimicking the brain. We combine benchtop experimental data in both reflection (backscattering) and transmission geometries with support from physics-based simulations to develop a neuromorphic computational model and then apply this for image reconstruction of different MNIST characters and image sets by a dedicated deep spiking neural network algorithm. Image reconstruction is achieved under conditions of turbidity where an original image is unintelligible to the human eye or a digital video camera, yet clearly and quantifiable identifiable when using the new neuromorphic computational approach.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的光电计算方法，用于揭示受到干扰媒体散射的目标图像。目标图像是动态的，即其光学性质在时间上变化，可能是静止的或者移动的。我们的方法是基于人视系统的，通过将散射媒体中的散射光转化为脉冲 trains，然后使用神经网络模型来重建图像。我们结合了实验和物理学习模型，并使用专门的深度脉冲神经网络算法来实现图像重建。我们发现，在某些情况下，使用我们的方法可以在干扰媒体中揭示出清晰可读的图像，而人类眼或数字摄像头则无法识别到这些图像。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/cs.CV_2023_09_13/" data-id="clohum97k00hjpj8841rqaz40" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/35/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/34/">34</a><a class="page-number" href="/page/35/">35</a><span class="page-number current">36</span><a class="page-number" href="/page/37/">37</a><a class="page-number" href="/page/38/">38</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/37/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
